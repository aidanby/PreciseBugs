{"buggy_code": ["#!/usr/bin/env python3\n\n# Allow direct execution\nimport os\nimport sys\n\nimport pytest\n\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport gzip\nimport http.client\nimport http.cookiejar\nimport http.server\nimport io\nimport pathlib\nimport random\nimport ssl\nimport tempfile\nimport threading\nimport time\nimport urllib.error\nimport urllib.request\nimport warnings\nimport zlib\nfrom email.message import Message\nfrom http.cookiejar import CookieJar\n\nfrom test.helper import FakeYDL, http_server_port\nfrom yt_dlp.cookies import YoutubeDLCookieJar\nfrom yt_dlp.dependencies import brotli, requests, urllib3\nfrom yt_dlp.networking import (\n    HEADRequest,\n    PUTRequest,\n    Request,\n    RequestDirector,\n    RequestHandler,\n    Response,\n)\nfrom yt_dlp.networking._urllib import UrllibRH\nfrom yt_dlp.networking.exceptions import (\n    CertificateVerifyError,\n    HTTPError,\n    IncompleteRead,\n    NoSupportingHandlers,\n    ProxyError,\n    RequestError,\n    SSLError,\n    TransportError,\n    UnsupportedRequest,\n)\nfrom yt_dlp.utils._utils import _YDLLogger as FakeLogger\nfrom yt_dlp.utils.networking import HTTPHeaderDict\n\nTEST_DIR = os.path.dirname(os.path.abspath(__file__))\n\n\ndef _build_proxy_handler(name):\n    class HTTPTestRequestHandler(http.server.BaseHTTPRequestHandler):\n        proxy_name = name\n\n        def log_message(self, format, *args):\n            pass\n\n        def do_GET(self):\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/plain; charset=utf-8')\n            self.end_headers()\n            self.wfile.write('{self.proxy_name}: {self.path}'.format(self=self).encode())\n    return HTTPTestRequestHandler\n\n\nclass HTTPTestRequestHandler(http.server.BaseHTTPRequestHandler):\n    protocol_version = 'HTTP/1.1'\n\n    def log_message(self, format, *args):\n        pass\n\n    def _headers(self):\n        payload = str(self.headers).encode()\n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.send_header('Content-Length', str(len(payload)))\n        self.end_headers()\n        self.wfile.write(payload)\n\n    def _redirect(self):\n        self.send_response(int(self.path[len('/redirect_'):]))\n        self.send_header('Location', '/method')\n        self.send_header('Content-Length', '0')\n        self.end_headers()\n\n    def _method(self, method, payload=None):\n        self.send_response(200)\n        self.send_header('Content-Length', str(len(payload or '')))\n        self.send_header('Method', method)\n        self.end_headers()\n        if payload:\n            self.wfile.write(payload)\n\n    def _status(self, status):\n        payload = f'<html>{status} NOT FOUND</html>'.encode()\n        self.send_response(int(status))\n        self.send_header('Content-Type', 'text/html; charset=utf-8')\n        self.send_header('Content-Length', str(len(payload)))\n        self.end_headers()\n        self.wfile.write(payload)\n\n    def _read_data(self):\n        if 'Content-Length' in self.headers:\n            return self.rfile.read(int(self.headers['Content-Length']))\n\n    def do_POST(self):\n        data = self._read_data() + str(self.headers).encode()\n        if self.path.startswith('/redirect_'):\n            self._redirect()\n        elif self.path.startswith('/method'):\n            self._method('POST', data)\n        elif self.path.startswith('/headers'):\n            self._headers()\n        else:\n            self._status(404)\n\n    def do_HEAD(self):\n        if self.path.startswith('/redirect_'):\n            self._redirect()\n        elif self.path.startswith('/method'):\n            self._method('HEAD')\n        else:\n            self._status(404)\n\n    def do_PUT(self):\n        data = self._read_data() + str(self.headers).encode()\n        if self.path.startswith('/redirect_'):\n            self._redirect()\n        elif self.path.startswith('/method'):\n            self._method('PUT', data)\n        else:\n            self._status(404)\n\n    def do_GET(self):\n        if self.path == '/video.html':\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path == '/vid.mp4':\n            payload = b'\\x00\\x00\\x00\\x00\\x20\\x66\\x74[video]'\n            self.send_response(200)\n            self.send_header('Content-Type', 'video/mp4')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path == '/%E4%B8%AD%E6%96%87.html':\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path == '/%c7%9f':\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path.startswith('/redirect_loop'):\n            self.send_response(301)\n            self.send_header('Location', self.path)\n            self.send_header('Content-Length', '0')\n            self.end_headers()\n        elif self.path == '/redirect_dotsegments':\n            self.send_response(301)\n            # redirect to /headers but with dot segments before\n            self.send_header('Location', '/a/b/./../../headers')\n            self.send_header('Content-Length', '0')\n            self.end_headers()\n        elif self.path.startswith('/redirect_'):\n            self._redirect()\n        elif self.path.startswith('/method'):\n            self._method('GET', str(self.headers).encode())\n        elif self.path.startswith('/headers'):\n            self._headers()\n        elif self.path.startswith('/308-to-headers'):\n            self.send_response(308)\n            self.send_header('Location', '/headers')\n            self.send_header('Content-Length', '0')\n            self.end_headers()\n        elif self.path == '/trailing_garbage':\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Encoding', 'gzip')\n            buf = io.BytesIO()\n            with gzip.GzipFile(fileobj=buf, mode='wb') as f:\n                f.write(payload)\n            compressed = buf.getvalue() + b'trailing garbage'\n            self.send_header('Content-Length', str(len(compressed)))\n            self.end_headers()\n            self.wfile.write(compressed)\n        elif self.path == '/302-non-ascii-redirect':\n            new_url = f'http://127.0.0.1:{http_server_port(self.server)}/\u4e2d\u6587.html'\n            self.send_response(301)\n            self.send_header('Location', new_url)\n            self.send_header('Content-Length', '0')\n            self.end_headers()\n        elif self.path == '/content-encoding':\n            encodings = self.headers.get('ytdl-encoding', '')\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            for encoding in filter(None, (e.strip() for e in encodings.split(','))):\n                if encoding == 'br' and brotli:\n                    payload = brotli.compress(payload)\n                elif encoding == 'gzip':\n                    buf = io.BytesIO()\n                    with gzip.GzipFile(fileobj=buf, mode='wb') as f:\n                        f.write(payload)\n                    payload = buf.getvalue()\n                elif encoding == 'deflate':\n                    payload = zlib.compress(payload)\n                elif encoding == 'unsupported':\n                    payload = b'raw'\n                    break\n                else:\n                    self._status(415)\n                    return\n            self.send_response(200)\n            self.send_header('Content-Encoding', encodings)\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path.startswith('/gen_'):\n            payload = b'<html></html>'\n            self.send_response(int(self.path[len('/gen_'):]))\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path.startswith('/incompleteread'):\n            payload = b'<html></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', '234234')\n            self.end_headers()\n            self.wfile.write(payload)\n            self.finish()\n        elif self.path.startswith('/timeout_'):\n            time.sleep(int(self.path[len('/timeout_'):]))\n            self._headers()\n        elif self.path == '/source_address':\n            payload = str(self.client_address[0]).encode()\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n            self.finish()\n        else:\n            self._status(404)\n\n    def send_header(self, keyword, value):\n        \"\"\"\n        Forcibly allow HTTP server to send non percent-encoded non-ASCII characters in headers.\n        This is against what is defined in RFC 3986, however we need to test we support this\n        since some sites incorrectly do this.\n        \"\"\"\n        if keyword.lower() == 'connection':\n            return super().send_header(keyword, value)\n\n        if not hasattr(self, '_headers_buffer'):\n            self._headers_buffer = []\n\n        self._headers_buffer.append(f'{keyword}: {value}\\r\\n'.encode())\n\n\ndef validate_and_send(rh, req):\n    rh.validate(req)\n    return rh.send(req)\n\n\nclass TestRequestHandlerBase:\n    @classmethod\n    def setup_class(cls):\n        cls.http_httpd = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), HTTPTestRequestHandler)\n        cls.http_port = http_server_port(cls.http_httpd)\n        cls.http_server_thread = threading.Thread(target=cls.http_httpd.serve_forever)\n        # FIXME: we should probably stop the http server thread after each test\n        # See: https://github.com/yt-dlp/yt-dlp/pull/7094#discussion_r1199746041\n        cls.http_server_thread.daemon = True\n        cls.http_server_thread.start()\n\n        # HTTPS server\n        certfn = os.path.join(TEST_DIR, 'testcert.pem')\n        cls.https_httpd = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), HTTPTestRequestHandler)\n        sslctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        sslctx.load_cert_chain(certfn, None)\n        cls.https_httpd.socket = sslctx.wrap_socket(cls.https_httpd.socket, server_side=True)\n        cls.https_port = http_server_port(cls.https_httpd)\n        cls.https_server_thread = threading.Thread(target=cls.https_httpd.serve_forever)\n        cls.https_server_thread.daemon = True\n        cls.https_server_thread.start()\n\n\nclass TestHTTPRequestHandler(TestRequestHandlerBase):\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_verify_cert(self, handler):\n        with handler() as rh:\n            with pytest.raises(CertificateVerifyError):\n                validate_and_send(rh, Request(f'https://127.0.0.1:{self.https_port}/headers'))\n\n        with handler(verify=False) as rh:\n            r = validate_and_send(rh, Request(f'https://127.0.0.1:{self.https_port}/headers'))\n            assert r.status == 200\n            r.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_ssl_error(self, handler):\n        # HTTPS server with too old TLS version\n        # XXX: is there a better way to test this than to create a new server?\n        https_httpd = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), HTTPTestRequestHandler)\n        sslctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        https_httpd.socket = sslctx.wrap_socket(https_httpd.socket, server_side=True)\n        https_port = http_server_port(https_httpd)\n        https_server_thread = threading.Thread(target=https_httpd.serve_forever)\n        https_server_thread.daemon = True\n        https_server_thread.start()\n\n        with handler(verify=False) as rh:\n            with pytest.raises(SSLError, match='sslv3 alert handshake failure') as exc_info:\n                validate_and_send(rh, Request(f'https://127.0.0.1:{https_port}/headers'))\n            assert not issubclass(exc_info.type, CertificateVerifyError)\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_percent_encode(self, handler):\n        with handler() as rh:\n            # Unicode characters should be encoded with uppercase percent-encoding\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/\u4e2d\u6587.html'))\n            assert res.status == 200\n            res.close()\n            # don't normalize existing percent encodings\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/%c7%9f'))\n            assert res.status == 200\n            res.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_remove_dot_segments(self, handler):\n        with handler() as rh:\n            # This isn't a comprehensive test,\n            # but it should be enough to check whether the handler is removing dot segments\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/a/b/./../../headers'))\n            assert res.status == 200\n            assert res.url == f'http://127.0.0.1:{self.http_port}/headers'\n            res.close()\n\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/redirect_dotsegments'))\n            assert res.status == 200\n            assert res.url == f'http://127.0.0.1:{self.http_port}/headers'\n            res.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_unicode_path_redirection(self, handler):\n        with handler() as rh:\n            r = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/302-non-ascii-redirect'))\n            assert r.url == f'http://127.0.0.1:{self.http_port}/%E4%B8%AD%E6%96%87.html'\n            r.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_raise_http_error(self, handler):\n        with handler() as rh:\n            for bad_status in (400, 500, 599, 302):\n                with pytest.raises(HTTPError):\n                    validate_and_send(rh, Request('http://127.0.0.1:%d/gen_%d' % (self.http_port, bad_status)))\n\n            # Should not raise an error\n            validate_and_send(rh, Request('http://127.0.0.1:%d/gen_200' % self.http_port)).close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_response_url(self, handler):\n        with handler() as rh:\n            # Response url should be that of the last url in redirect chain\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/redirect_301'))\n            assert res.url == f'http://127.0.0.1:{self.http_port}/method'\n            res.close()\n            res2 = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/gen_200'))\n            assert res2.url == f'http://127.0.0.1:{self.http_port}/gen_200'\n            res2.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_redirect(self, handler):\n        with handler() as rh:\n            def do_req(redirect_status, method, assert_no_content=False):\n                data = b'testdata' if method in ('POST', 'PUT') else None\n                res = validate_and_send(\n                    rh, Request(f'http://127.0.0.1:{self.http_port}/redirect_{redirect_status}', method=method, data=data))\n\n                headers = b''\n                data_sent = b''\n                if data is not None:\n                    data_sent += res.read(len(data))\n                    if data_sent != data:\n                        headers += data_sent\n                        data_sent = b''\n\n                headers += res.read()\n\n                if assert_no_content or data is None:\n                    assert b'Content-Type' not in headers\n                    assert b'Content-Length' not in headers\n                else:\n                    assert b'Content-Type' in headers\n                    assert b'Content-Length' in headers\n\n                return data_sent.decode(), res.headers.get('method', '')\n\n            # A 303 must either use GET or HEAD for subsequent request\n            assert do_req(303, 'POST', True) == ('', 'GET')\n            assert do_req(303, 'HEAD') == ('', 'HEAD')\n\n            assert do_req(303, 'PUT', True) == ('', 'GET')\n\n            # 301 and 302 turn POST only into a GET\n            assert do_req(301, 'POST', True) == ('', 'GET')\n            assert do_req(301, 'HEAD') == ('', 'HEAD')\n            assert do_req(302, 'POST', True) == ('', 'GET')\n            assert do_req(302, 'HEAD') == ('', 'HEAD')\n\n            assert do_req(301, 'PUT') == ('testdata', 'PUT')\n            assert do_req(302, 'PUT') == ('testdata', 'PUT')\n\n            # 307 and 308 should not change method\n            for m in ('POST', 'PUT'):\n                assert do_req(307, m) == ('testdata', m)\n                assert do_req(308, m) == ('testdata', m)\n\n            assert do_req(307, 'HEAD') == ('', 'HEAD')\n            assert do_req(308, 'HEAD') == ('', 'HEAD')\n\n            # These should not redirect and instead raise an HTTPError\n            for code in (300, 304, 305, 306):\n                with pytest.raises(HTTPError):\n                    do_req(code, 'GET')\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_request_cookie_header(self, handler):\n        # We should accept a Cookie header being passed as in normal headers and handle it appropriately.\n        with handler() as rh:\n            # Specified Cookie header should be used\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/headers',\n                    headers={'Cookie': 'test=test'})).read().decode()\n            assert 'Cookie: test=test' in res\n\n            # Specified Cookie header should be removed on any redirect\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/308-to-headers',\n                    headers={'Cookie': 'test=test'})).read().decode()\n            assert 'Cookie: test=test' not in res\n\n        # Specified Cookie header should override global cookiejar for that request\n        cookiejar = YoutubeDLCookieJar()\n        cookiejar.set_cookie(http.cookiejar.Cookie(\n            version=0, name='test', value='ytdlp', port=None, port_specified=False,\n            domain='127.0.0.1', domain_specified=True, domain_initial_dot=False, path='/',\n            path_specified=True, secure=False, expires=None, discard=False, comment=None,\n            comment_url=None, rest={}))\n\n        with handler(cookiejar=cookiejar) as rh:\n            data = validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/headers', headers={'cookie': 'test=test'})).read()\n            assert b'Cookie: test=ytdlp' not in data\n            assert b'Cookie: test=test' in data\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_redirect_loop(self, handler):\n        with handler() as rh:\n            with pytest.raises(HTTPError, match='redirect loop'):\n                validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/redirect_loop'))\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_incompleteread(self, handler):\n        with handler(timeout=2) as rh:\n            with pytest.raises(IncompleteRead):\n                validate_and_send(rh, Request('http://127.0.0.1:%d/incompleteread' % self.http_port)).read()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_cookies(self, handler):\n        cookiejar = YoutubeDLCookieJar()\n        cookiejar.set_cookie(http.cookiejar.Cookie(\n            0, 'test', 'ytdlp', None, False, '127.0.0.1', True,\n            False, '/headers', True, False, None, False, None, None, {}))\n\n        with handler(cookiejar=cookiejar) as rh:\n            data = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/headers')).read()\n            assert b'Cookie: test=ytdlp' in data\n\n        # Per request\n        with handler() as rh:\n            data = validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/headers', extensions={'cookiejar': cookiejar})).read()\n            assert b'Cookie: test=ytdlp' in data\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_headers(self, handler):\n\n        with handler(headers=HTTPHeaderDict({'test1': 'test', 'test2': 'test2'})) as rh:\n            # Global Headers\n            data = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/headers')).read()\n            assert b'Test1: test' in data\n\n            # Per request headers, merged with global\n            data = validate_and_send(rh, Request(\n                f'http://127.0.0.1:{self.http_port}/headers', headers={'test2': 'changed', 'test3': 'test3'})).read()\n            assert b'Test1: test' in data\n            assert b'Test2: changed' in data\n            assert b'Test2: test2' not in data\n            assert b'Test3: test3' in data\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_timeout(self, handler):\n        with handler() as rh:\n            # Default timeout is 20 seconds, so this should go through\n            validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/timeout_3'))\n\n        with handler(timeout=0.5) as rh:\n            with pytest.raises(TransportError):\n                validate_and_send(\n                    rh, Request(f'http://127.0.0.1:{self.http_port}/timeout_1'))\n\n            # Per request timeout, should override handler timeout\n            validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/timeout_1', extensions={'timeout': 4}))\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_source_address(self, handler):\n        source_address = f'127.0.0.{random.randint(5, 255)}'\n        with handler(source_address=source_address) as rh:\n            data = validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/source_address')).read().decode()\n            assert source_address == data\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_gzip_trailing_garbage(self, handler):\n        with handler() as rh:\n            data = validate_and_send(rh, Request(f'http://localhost:{self.http_port}/trailing_garbage')).read().decode()\n            assert data == '<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    @pytest.mark.skipif(not brotli, reason='brotli support is not installed')\n    def test_brotli(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/content-encoding',\n                    headers={'ytdl-encoding': 'br'}))\n            assert res.headers.get('Content-Encoding') == 'br'\n            assert res.read() == b'<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_deflate(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/content-encoding',\n                    headers={'ytdl-encoding': 'deflate'}))\n            assert res.headers.get('Content-Encoding') == 'deflate'\n            assert res.read() == b'<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_gzip(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/content-encoding',\n                    headers={'ytdl-encoding': 'gzip'}))\n            assert res.headers.get('Content-Encoding') == 'gzip'\n            assert res.read() == b'<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_multiple_encodings(self, handler):\n        with handler() as rh:\n            for pair in ('gzip,deflate', 'deflate, gzip', 'gzip, gzip', 'deflate, deflate'):\n                res = validate_and_send(\n                    rh, Request(\n                        f'http://127.0.0.1:{self.http_port}/content-encoding',\n                        headers={'ytdl-encoding': pair}))\n                assert res.headers.get('Content-Encoding') == pair\n                assert res.read() == b'<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_unsupported_encoding(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/content-encoding',\n                    headers={'ytdl-encoding': 'unsupported'}))\n            assert res.headers.get('Content-Encoding') == 'unsupported'\n            assert res.read() == b'raw'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_read(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/headers'))\n            assert res.readable()\n            assert res.read(1) == b'H'\n            assert res.read(3) == b'ost'\n\n\nclass TestHTTPProxy(TestRequestHandlerBase):\n    @classmethod\n    def setup_class(cls):\n        super().setup_class()\n        # HTTP Proxy server\n        cls.proxy = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), _build_proxy_handler('normal'))\n        cls.proxy_port = http_server_port(cls.proxy)\n        cls.proxy_thread = threading.Thread(target=cls.proxy.serve_forever)\n        cls.proxy_thread.daemon = True\n        cls.proxy_thread.start()\n\n        # Geo proxy server\n        cls.geo_proxy = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), _build_proxy_handler('geo'))\n        cls.geo_port = http_server_port(cls.geo_proxy)\n        cls.geo_proxy_thread = threading.Thread(target=cls.geo_proxy.serve_forever)\n        cls.geo_proxy_thread.daemon = True\n        cls.geo_proxy_thread.start()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_http_proxy(self, handler):\n        http_proxy = f'http://127.0.0.1:{self.proxy_port}'\n        geo_proxy = f'http://127.0.0.1:{self.geo_port}'\n\n        # Test global http proxy\n        # Test per request http proxy\n        # Test per request http proxy disables proxy\n        url = 'http://foo.com/bar'\n\n        # Global HTTP proxy\n        with handler(proxies={'http': http_proxy}) as rh:\n            res = validate_and_send(rh, Request(url)).read().decode()\n            assert res == f'normal: {url}'\n\n            # Per request proxy overrides global\n            res = validate_and_send(rh, Request(url, proxies={'http': geo_proxy})).read().decode()\n            assert res == f'geo: {url}'\n\n            # and setting to None disables all proxies for that request\n            real_url = f'http://127.0.0.1:{self.http_port}/headers'\n            res = validate_and_send(\n                rh, Request(real_url, proxies={'http': None})).read().decode()\n            assert res != f'normal: {real_url}'\n            assert 'Accept' in res\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_noproxy(self, handler):\n        with handler(proxies={'proxy': f'http://127.0.0.1:{self.proxy_port}'}) as rh:\n            # NO_PROXY\n            for no_proxy in (f'127.0.0.1:{self.http_port}', '127.0.0.1', 'localhost'):\n                nop_response = validate_and_send(\n                    rh, Request(f'http://127.0.0.1:{self.http_port}/headers', proxies={'no': no_proxy})).read().decode(\n                    'utf-8')\n                assert 'Accept' in nop_response\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_allproxy(self, handler):\n        url = 'http://foo.com/bar'\n        with handler() as rh:\n            response = validate_and_send(rh, Request(url, proxies={'all': f'http://127.0.0.1:{self.proxy_port}'})).read().decode(\n                'utf-8')\n            assert response == f'normal: {url}'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_http_proxy_with_idn(self, handler):\n        with handler(proxies={\n            'http': f'http://127.0.0.1:{self.proxy_port}',\n        }) as rh:\n            url = 'http://\u4e2d\u6587.tw/'\n            response = rh.send(Request(url)).read().decode()\n            # b'xn--fiq228c' is '\u4e2d\u6587'.encode('idna')\n            assert response == 'normal: http://xn--fiq228c.tw/'\n\n\nclass TestClientCertificate:\n\n    @classmethod\n    def setup_class(cls):\n        certfn = os.path.join(TEST_DIR, 'testcert.pem')\n        cls.certdir = os.path.join(TEST_DIR, 'testdata', 'certificate')\n        cacertfn = os.path.join(cls.certdir, 'ca.crt')\n        cls.httpd = http.server.ThreadingHTTPServer(('127.0.0.1', 0), HTTPTestRequestHandler)\n        sslctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        sslctx.verify_mode = ssl.CERT_REQUIRED\n        sslctx.load_verify_locations(cafile=cacertfn)\n        sslctx.load_cert_chain(certfn, None)\n        cls.httpd.socket = sslctx.wrap_socket(cls.httpd.socket, server_side=True)\n        cls.port = http_server_port(cls.httpd)\n        cls.server_thread = threading.Thread(target=cls.httpd.serve_forever)\n        cls.server_thread.daemon = True\n        cls.server_thread.start()\n\n    def _run_test(self, handler, **handler_kwargs):\n        with handler(\n            # Disable client-side validation of unacceptable self-signed testcert.pem\n            # The test is of a check on the server side, so unaffected\n            verify=False,\n            **handler_kwargs,\n        ) as rh:\n            validate_and_send(rh, Request(f'https://127.0.0.1:{self.port}/video.html')).read().decode()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_certificate_combined_nopass(self, handler):\n        self._run_test(handler, client_cert={\n            'client_certificate': os.path.join(self.certdir, 'clientwithkey.crt'),\n        })\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_certificate_nocombined_nopass(self, handler):\n        self._run_test(handler, client_cert={\n            'client_certificate': os.path.join(self.certdir, 'client.crt'),\n            'client_certificate_key': os.path.join(self.certdir, 'client.key'),\n        })\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_certificate_combined_pass(self, handler):\n        self._run_test(handler, client_cert={\n            'client_certificate': os.path.join(self.certdir, 'clientwithencryptedkey.crt'),\n            'client_certificate_password': 'foobar',\n        })\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_certificate_nocombined_pass(self, handler):\n        self._run_test(handler, client_cert={\n            'client_certificate': os.path.join(self.certdir, 'client.crt'),\n            'client_certificate_key': os.path.join(self.certdir, 'clientencrypted.key'),\n            'client_certificate_password': 'foobar',\n        })\n\n\nclass TestUrllibRequestHandler(TestRequestHandlerBase):\n    @pytest.mark.parametrize('handler', ['Urllib'], indirect=True)\n    def test_file_urls(self, handler):\n        # See https://github.com/ytdl-org/youtube-dl/issues/8227\n        tf = tempfile.NamedTemporaryFile(delete=False)\n        tf.write(b'foobar')\n        tf.close()\n        req = Request(pathlib.Path(tf.name).as_uri())\n        with handler() as rh:\n            with pytest.raises(UnsupportedRequest):\n                rh.validate(req)\n\n            # Test that urllib never loaded FileHandler\n            with pytest.raises(TransportError):\n                rh.send(req)\n\n        with handler(enable_file_urls=True) as rh:\n            res = validate_and_send(rh, req)\n            assert res.read() == b'foobar'\n            res.close()\n\n        os.unlink(tf.name)\n\n    @pytest.mark.parametrize('handler', ['Urllib'], indirect=True)\n    def test_http_error_returns_content(self, handler):\n        # urllib HTTPError will try close the underlying response if reference to the HTTPError object is lost\n        def get_response():\n            with handler() as rh:\n                # headers url\n                try:\n                    validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/gen_404'))\n                except HTTPError as e:\n                    return e.response\n\n        assert get_response().read() == b'<html></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib'], indirect=True)\n    def test_verify_cert_error_text(self, handler):\n        # Check the output of the error message\n        with handler() as rh:\n            with pytest.raises(\n                CertificateVerifyError,\n                match=r'\\[SSL: CERTIFICATE_VERIFY_FAILED\\] certificate verify failed: self.signed certificate'\n            ):\n                validate_and_send(rh, Request(f'https://127.0.0.1:{self.https_port}/headers'))\n\n    @pytest.mark.parametrize('handler', ['Urllib'], indirect=True)\n    @pytest.mark.parametrize('req,match,version_check', [\n        # https://github.com/python/cpython/blob/987b712b4aeeece336eed24fcc87a950a756c3e2/Lib/http/client.py#L1256\n        # bpo-39603: Check implemented in 3.7.9+, 3.8.5+\n        (\n            Request('http://127.0.0.1', method='GET\\n'),\n            'method can\\'t contain control characters',\n            lambda v: v < (3, 7, 9) or (3, 8, 0) <= v < (3, 8, 5)\n        ),\n        # https://github.com/python/cpython/blob/987b712b4aeeece336eed24fcc87a950a756c3e2/Lib/http/client.py#L1265\n        # bpo-38576: Check implemented in 3.7.8+, 3.8.3+\n        (\n            Request('http://127.0.0. 1', method='GET'),\n            'URL can\\'t contain control characters',\n            lambda v: v < (3, 7, 8) or (3, 8, 0) <= v < (3, 8, 3)\n        ),\n        # https://github.com/python/cpython/blob/987b712b4aeeece336eed24fcc87a950a756c3e2/Lib/http/client.py#L1288C31-L1288C50\n        (Request('http://127.0.0.1', headers={'foo\\n': 'bar'}), 'Invalid header name', None),\n    ])\n    def test_httplib_validation_errors(self, handler, req, match, version_check):\n        if version_check and version_check(sys.version_info):\n            pytest.skip(f'Python {sys.version} version does not have the required validation for this test.')\n\n        with handler() as rh:\n            with pytest.raises(RequestError, match=match) as exc_info:\n                validate_and_send(rh, req)\n            assert not isinstance(exc_info.value, TransportError)\n\n\nclass TestRequestsRequestHandler(TestRequestHandlerBase):\n    @pytest.mark.parametrize('raised,expected', [\n        (lambda: requests.exceptions.ConnectTimeout(), TransportError),\n        (lambda: requests.exceptions.ReadTimeout(), TransportError),\n        (lambda: requests.exceptions.Timeout(), TransportError),\n        (lambda: requests.exceptions.ConnectionError(), TransportError),\n        (lambda: requests.exceptions.ProxyError(), ProxyError),\n        (lambda: requests.exceptions.SSLError('12[CERTIFICATE_VERIFY_FAILED]34'), CertificateVerifyError),\n        (lambda: requests.exceptions.SSLError(), SSLError),\n        (lambda: requests.exceptions.InvalidURL(), RequestError),\n        (lambda: requests.exceptions.InvalidHeader(), RequestError),\n        # catch-all: https://github.com/psf/requests/blob/main/src/requests/adapters.py#L535\n        (lambda: urllib3.exceptions.HTTPError(), TransportError),\n        (lambda: requests.exceptions.RequestException(), RequestError)\n        #  (lambda: requests.exceptions.TooManyRedirects(), HTTPError) - Needs a response object\n    ])\n    @pytest.mark.parametrize('handler', ['Requests'], indirect=True)\n    def test_request_error_mapping(self, handler, monkeypatch, raised, expected):\n        with handler() as rh:\n            def mock_get_instance(*args, **kwargs):\n                class MockSession:\n                    def request(self, *args, **kwargs):\n                        raise raised()\n                return MockSession()\n\n            monkeypatch.setattr(rh, '_get_instance', mock_get_instance)\n\n            with pytest.raises(expected) as exc_info:\n                rh.send(Request('http://fake'))\n\n            assert exc_info.type is expected\n\n    @pytest.mark.parametrize('raised,expected,match', [\n        (lambda: urllib3.exceptions.SSLError(), SSLError, None),\n        (lambda: urllib3.exceptions.TimeoutError(), TransportError, None),\n        (lambda: urllib3.exceptions.ReadTimeoutError(None, None, None), TransportError, None),\n        (lambda: urllib3.exceptions.ProtocolError(), TransportError, None),\n        (lambda: urllib3.exceptions.DecodeError(), TransportError, None),\n        (lambda: urllib3.exceptions.HTTPError(), TransportError, None),  # catch-all\n        (\n            lambda: urllib3.exceptions.ProtocolError('error', http.client.IncompleteRead(partial=b'abc', expected=4)),\n            IncompleteRead,\n            '3 bytes read, 4 more expected'\n        ),\n        (\n            lambda: urllib3.exceptions.ProtocolError('error', urllib3.exceptions.IncompleteRead(partial=3, expected=5)),\n            IncompleteRead,\n            '3 bytes read, 5 more expected'\n        ),\n    ])\n    @pytest.mark.parametrize('handler', ['Requests'], indirect=True)\n    def test_response_error_mapping(self, handler, monkeypatch, raised, expected, match):\n        from urllib3.response import HTTPResponse as Urllib3Response\n        from requests.models import Response as RequestsResponse\n        from yt_dlp.networking._requests import RequestsResponseAdapter\n        requests_res = RequestsResponse()\n        requests_res.raw = Urllib3Response(body=b'', status=200)\n        res = RequestsResponseAdapter(requests_res)\n\n        def mock_read(*args, **kwargs):\n            raise raised()\n        monkeypatch.setattr(res.fp, 'read', mock_read)\n\n        with pytest.raises(expected, match=match) as exc_info:\n            res.read()\n\n        assert exc_info.type is expected\n\n\ndef run_validation(handler, error, req, **handler_kwargs):\n    with handler(**handler_kwargs) as rh:\n        if error:\n            with pytest.raises(error):\n                rh.validate(req)\n        else:\n            rh.validate(req)\n\n\nclass TestRequestHandlerValidation:\n\n    class ValidationRH(RequestHandler):\n        def _send(self, request):\n            raise RequestError('test')\n\n    class NoCheckRH(ValidationRH):\n        _SUPPORTED_FEATURES = None\n        _SUPPORTED_PROXY_SCHEMES = None\n        _SUPPORTED_URL_SCHEMES = None\n\n        def _check_extensions(self, extensions):\n            extensions.clear()\n\n    class HTTPSupportedRH(ValidationRH):\n        _SUPPORTED_URL_SCHEMES = ('http',)\n\n    URL_SCHEME_TESTS = [\n        # scheme, expected to fail, handler kwargs\n        ('Urllib', [\n            ('http', False, {}),\n            ('https', False, {}),\n            ('data', False, {}),\n            ('ftp', False, {}),\n            ('file', UnsupportedRequest, {}),\n            ('file', False, {'enable_file_urls': True}),\n        ]),\n        ('Requests', [\n            ('http', False, {}),\n            ('https', False, {}),\n        ]),\n        (NoCheckRH, [('http', False, {})]),\n        (ValidationRH, [('http', UnsupportedRequest, {})])\n    ]\n\n    PROXY_SCHEME_TESTS = [\n        # scheme, expected to fail\n        ('Urllib', [\n            ('http', False),\n            ('https', UnsupportedRequest),\n            ('socks4', False),\n            ('socks4a', False),\n            ('socks5', False),\n            ('socks5h', False),\n            ('socks', UnsupportedRequest),\n        ]),\n        ('Requests', [\n            ('http', False),\n            ('https', False),\n            ('socks4', False),\n            ('socks4a', False),\n            ('socks5', False),\n            ('socks5h', False),\n        ]),\n        (NoCheckRH, [('http', False)]),\n        (HTTPSupportedRH, [('http', UnsupportedRequest)]),\n    ]\n\n    PROXY_KEY_TESTS = [\n        # key, expected to fail\n        ('Urllib', [\n            ('all', False),\n            ('unrelated', False),\n        ]),\n        ('Requests', [\n            ('all', False),\n            ('unrelated', False),\n        ]),\n        (NoCheckRH, [('all', False)]),\n        (HTTPSupportedRH, [('all', UnsupportedRequest)]),\n        (HTTPSupportedRH, [('no', UnsupportedRequest)]),\n    ]\n\n    EXTENSION_TESTS = [\n        ('Urllib', [\n            ({'cookiejar': 'notacookiejar'}, AssertionError),\n            ({'cookiejar': YoutubeDLCookieJar()}, False),\n            ({'cookiejar': CookieJar()}, AssertionError),\n            ({'timeout': 1}, False),\n            ({'timeout': 'notatimeout'}, AssertionError),\n            ({'unsupported': 'value'}, UnsupportedRequest),\n        ]),\n        ('Requests', [\n            ({'cookiejar': 'notacookiejar'}, AssertionError),\n            ({'cookiejar': YoutubeDLCookieJar()}, False),\n            ({'timeout': 1}, False),\n            ({'timeout': 'notatimeout'}, AssertionError),\n            ({'unsupported': 'value'}, UnsupportedRequest),\n        ]),\n        (NoCheckRH, [\n            ({'cookiejar': 'notacookiejar'}, False),\n            ({'somerandom': 'test'}, False),  # but any extension is allowed through\n        ]),\n    ]\n\n    @pytest.mark.parametrize('handler,scheme,fail,handler_kwargs', [\n        (handler_tests[0], scheme, fail, handler_kwargs)\n        for handler_tests in URL_SCHEME_TESTS\n        for scheme, fail, handler_kwargs in handler_tests[1]\n\n    ], indirect=['handler'])\n    def test_url_scheme(self, handler, scheme, fail, handler_kwargs):\n        run_validation(handler, fail, Request(f'{scheme}://'), **(handler_kwargs or {}))\n\n    @pytest.mark.parametrize('handler,fail', [('Urllib', False), ('Requests', False)], indirect=['handler'])\n    def test_no_proxy(self, handler, fail):\n        run_validation(handler, fail, Request('http://', proxies={'no': '127.0.0.1,github.com'}))\n        run_validation(handler, fail, Request('http://'), proxies={'no': '127.0.0.1,github.com'})\n\n    @pytest.mark.parametrize('handler,proxy_key,fail', [\n        (handler_tests[0], proxy_key, fail)\n        for handler_tests in PROXY_KEY_TESTS\n        for proxy_key, fail in handler_tests[1]\n    ], indirect=['handler'])\n    def test_proxy_key(self, handler, proxy_key, fail):\n        run_validation(handler, fail, Request('http://', proxies={proxy_key: 'http://example.com'}))\n        run_validation(handler, fail, Request('http://'), proxies={proxy_key: 'http://example.com'})\n\n    @pytest.mark.parametrize('handler,scheme,fail', [\n        (handler_tests[0], scheme, fail)\n        for handler_tests in PROXY_SCHEME_TESTS\n        for scheme, fail in handler_tests[1]\n    ], indirect=['handler'])\n    def test_proxy_scheme(self, handler, scheme, fail):\n        run_validation(handler, fail, Request('http://', proxies={'http': f'{scheme}://example.com'}))\n        run_validation(handler, fail, Request('http://'), proxies={'http': f'{scheme}://example.com'})\n\n    @pytest.mark.parametrize('handler', ['Urllib', HTTPSupportedRH, 'Requests'], indirect=True)\n    def test_empty_proxy(self, handler):\n        run_validation(handler, False, Request('http://', proxies={'http': None}))\n        run_validation(handler, False, Request('http://'), proxies={'http': None})\n\n    @pytest.mark.parametrize('proxy_url', ['//example.com', 'example.com', '127.0.0.1', '/a/b/c'])\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_invalid_proxy_url(self, handler, proxy_url):\n        run_validation(handler, UnsupportedRequest, Request('http://', proxies={'http': proxy_url}))\n\n    @pytest.mark.parametrize('handler,extensions,fail', [\n        (handler_tests[0], extensions, fail)\n        for handler_tests in EXTENSION_TESTS\n        for extensions, fail in handler_tests[1]\n    ], indirect=['handler'])\n    def test_extension(self, handler, extensions, fail):\n        run_validation(\n            handler, fail, Request('http://', extensions=extensions))\n\n    def test_invalid_request_type(self):\n        rh = self.ValidationRH(logger=FakeLogger())\n        for method in (rh.validate, rh.send):\n            with pytest.raises(TypeError, match='Expected an instance of Request'):\n                method('not a request')\n\n\nclass FakeResponse(Response):\n    def __init__(self, request):\n        # XXX: we could make request part of standard response interface\n        self.request = request\n        super().__init__(fp=io.BytesIO(b''), headers={}, url=request.url)\n\n\nclass FakeRH(RequestHandler):\n\n    def _validate(self, request):\n        return\n\n    def _send(self, request: Request):\n        if request.url.startswith('ssl://'):\n            raise SSLError(request.url[len('ssl://'):])\n        return FakeResponse(request)\n\n\nclass FakeRHYDL(FakeYDL):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._request_director = self.build_request_director([FakeRH])\n\n\nclass TestRequestDirector:\n\n    def test_handler_operations(self):\n        director = RequestDirector(logger=FakeLogger())\n        handler = FakeRH(logger=FakeLogger())\n        director.add_handler(handler)\n        assert director.handlers.get(FakeRH.RH_KEY) is handler\n\n        # Handler should overwrite\n        handler2 = FakeRH(logger=FakeLogger())\n        director.add_handler(handler2)\n        assert director.handlers.get(FakeRH.RH_KEY) is not handler\n        assert director.handlers.get(FakeRH.RH_KEY) is handler2\n        assert len(director.handlers) == 1\n\n        class AnotherFakeRH(FakeRH):\n            pass\n        director.add_handler(AnotherFakeRH(logger=FakeLogger()))\n        assert len(director.handlers) == 2\n        assert director.handlers.get(AnotherFakeRH.RH_KEY).RH_KEY == AnotherFakeRH.RH_KEY\n\n        director.handlers.pop(FakeRH.RH_KEY, None)\n        assert director.handlers.get(FakeRH.RH_KEY) is None\n        assert len(director.handlers) == 1\n\n        # RequestErrors should passthrough\n        with pytest.raises(SSLError):\n            director.send(Request('ssl://something'))\n\n    def test_send(self):\n        director = RequestDirector(logger=FakeLogger())\n        with pytest.raises(RequestError):\n            director.send(Request('any://'))\n        director.add_handler(FakeRH(logger=FakeLogger()))\n        assert isinstance(director.send(Request('http://')), FakeResponse)\n\n    def test_unsupported_handlers(self):\n        class SupportedRH(RequestHandler):\n            _SUPPORTED_URL_SCHEMES = ['http']\n\n            def _send(self, request: Request):\n                return Response(fp=io.BytesIO(b'supported'), headers={}, url=request.url)\n\n        director = RequestDirector(logger=FakeLogger())\n        director.add_handler(SupportedRH(logger=FakeLogger()))\n        director.add_handler(FakeRH(logger=FakeLogger()))\n\n        # First should take preference\n        assert director.send(Request('http://')).read() == b'supported'\n        assert director.send(Request('any://')).read() == b''\n\n        director.handlers.pop(FakeRH.RH_KEY)\n        with pytest.raises(NoSupportingHandlers):\n            director.send(Request('any://'))\n\n    def test_unexpected_error(self):\n        director = RequestDirector(logger=FakeLogger())\n\n        class UnexpectedRH(FakeRH):\n            def _send(self, request: Request):\n                raise TypeError('something')\n\n        director.add_handler(UnexpectedRH(logger=FakeLogger))\n        with pytest.raises(NoSupportingHandlers, match=r'1 unexpected error'):\n            director.send(Request('any://'))\n\n        director.handlers.clear()\n        assert len(director.handlers) == 0\n\n        # Should not be fatal\n        director.add_handler(FakeRH(logger=FakeLogger()))\n        director.add_handler(UnexpectedRH(logger=FakeLogger))\n        assert director.send(Request('any://'))\n\n    def test_preference(self):\n        director = RequestDirector(logger=FakeLogger())\n        director.add_handler(FakeRH(logger=FakeLogger()))\n\n        class SomeRH(RequestHandler):\n            _SUPPORTED_URL_SCHEMES = ['http']\n\n            def _send(self, request: Request):\n                return Response(fp=io.BytesIO(b'supported'), headers={}, url=request.url)\n\n        def some_preference(rh, request):\n            return (0 if not isinstance(rh, SomeRH)\n                    else 100 if 'prefer' in request.headers\n                    else -1)\n\n        director.add_handler(SomeRH(logger=FakeLogger()))\n        director.preferences.add(some_preference)\n\n        assert director.send(Request('http://')).read() == b''\n        assert director.send(Request('http://', headers={'prefer': '1'})).read() == b'supported'\n\n\n# XXX: do we want to move this to test_YoutubeDL.py?\nclass TestYoutubeDLNetworking:\n\n    @staticmethod\n    def build_handler(ydl, handler: RequestHandler = FakeRH):\n        return ydl.build_request_director([handler]).handlers.get(handler.RH_KEY)\n\n    def test_compat_opener(self):\n        with FakeYDL() as ydl:\n            with warnings.catch_warnings():\n                warnings.simplefilter('ignore', category=DeprecationWarning)\n                assert isinstance(ydl._opener, urllib.request.OpenerDirector)\n\n    @pytest.mark.parametrize('proxy,expected', [\n        ('http://127.0.0.1:8080', {'all': 'http://127.0.0.1:8080'}),\n        ('', {'all': '__noproxy__'}),\n        (None, {'http': 'http://127.0.0.1:8081', 'https': 'http://127.0.0.1:8081'})  # env, set https\n    ])\n    def test_proxy(self, proxy, expected):\n        old_http_proxy = os.environ.get('HTTP_PROXY')\n        try:\n            os.environ['HTTP_PROXY'] = 'http://127.0.0.1:8081'  # ensure that provided proxies override env\n            with FakeYDL({'proxy': proxy}) as ydl:\n                assert ydl.proxies == expected\n        finally:\n            if old_http_proxy:\n                os.environ['HTTP_PROXY'] = old_http_proxy\n\n    def test_compat_request(self):\n        with FakeRHYDL() as ydl:\n            assert ydl.urlopen('test://')\n            urllib_req = urllib.request.Request('http://foo.bar', data=b'test', method='PUT', headers={'X-Test': '1'})\n            urllib_req.add_unredirected_header('Cookie', 'bob=bob')\n            urllib_req.timeout = 2\n            with warnings.catch_warnings():\n                warnings.simplefilter('ignore', category=DeprecationWarning)\n                req = ydl.urlopen(urllib_req).request\n                assert req.url == urllib_req.get_full_url()\n                assert req.data == urllib_req.data\n                assert req.method == urllib_req.get_method()\n                assert 'X-Test' in req.headers\n                assert 'Cookie' in req.headers\n                assert req.extensions.get('timeout') == 2\n\n            with pytest.raises(AssertionError):\n                ydl.urlopen(None)\n\n    def test_extract_basic_auth(self):\n        with FakeRHYDL() as ydl:\n            res = ydl.urlopen(Request('http://user:pass@foo.bar'))\n            assert res.request.headers['Authorization'] == 'Basic dXNlcjpwYXNz'\n\n    def test_sanitize_url(self):\n        with FakeRHYDL() as ydl:\n            res = ydl.urlopen(Request('httpss://foo.bar'))\n            assert res.request.url == 'https://foo.bar'\n\n    def test_file_urls_error(self):\n        # use urllib handler\n        with FakeYDL() as ydl:\n            with pytest.raises(RequestError, match=r'file:// URLs are disabled by default'):\n                ydl.urlopen('file://')\n\n    def test_legacy_server_connect_error(self):\n        with FakeRHYDL() as ydl:\n            for error in ('UNSAFE_LEGACY_RENEGOTIATION_DISABLED', 'SSLV3_ALERT_HANDSHAKE_FAILURE'):\n                with pytest.raises(RequestError, match=r'Try using --legacy-server-connect'):\n                    ydl.urlopen(f'ssl://{error}')\n\n            with pytest.raises(SSLError, match='testerror'):\n                ydl.urlopen('ssl://testerror')\n\n    @pytest.mark.parametrize('proxy_key,proxy_url,expected', [\n        ('http', '__noproxy__', None),\n        ('no', '127.0.0.1,foo.bar', '127.0.0.1,foo.bar'),\n        ('https', 'example.com', 'http://example.com'),\n        ('https', '//example.com', 'http://example.com'),\n        ('https', 'socks5://example.com', 'socks5h://example.com'),\n        ('http', 'socks://example.com', 'socks4://example.com'),\n        ('http', 'socks4://example.com', 'socks4://example.com'),\n        ('unrelated', '/bad/proxy', '/bad/proxy'),  # clean_proxies should ignore bad proxies\n    ])\n    def test_clean_proxy(self, proxy_key, proxy_url, expected):\n        # proxies should be cleaned in urlopen()\n        with FakeRHYDL() as ydl:\n            req = ydl.urlopen(Request('test://', proxies={proxy_key: proxy_url})).request\n            assert req.proxies[proxy_key] == expected\n\n        # and should also be cleaned when building the handler\n        env_key = f'{proxy_key.upper()}_PROXY'\n        old_env_proxy = os.environ.get(env_key)\n        try:\n            os.environ[env_key] = proxy_url  # ensure that provided proxies override env\n            with FakeYDL() as ydl:\n                rh = self.build_handler(ydl)\n                assert rh.proxies[proxy_key] == expected\n        finally:\n            if old_env_proxy:\n                os.environ[env_key] = old_env_proxy\n\n    def test_clean_proxy_header(self):\n        with FakeRHYDL() as ydl:\n            req = ydl.urlopen(Request('test://', headers={'ytdl-request-proxy': '//foo.bar'})).request\n            assert 'ytdl-request-proxy' not in req.headers\n            assert req.proxies == {'all': 'http://foo.bar'}\n\n        with FakeYDL({'http_headers': {'ytdl-request-proxy': '//foo.bar'}}) as ydl:\n            rh = self.build_handler(ydl)\n            assert 'ytdl-request-proxy' not in rh.headers\n            assert rh.proxies == {'all': 'http://foo.bar'}\n\n    def test_clean_header(self):\n        with FakeRHYDL() as ydl:\n            res = ydl.urlopen(Request('test://', headers={'Youtubedl-no-compression': True}))\n            assert 'Youtubedl-no-compression' not in res.request.headers\n            assert res.request.headers.get('Accept-Encoding') == 'identity'\n\n        with FakeYDL({'http_headers': {'Youtubedl-no-compression': True}}) as ydl:\n            rh = self.build_handler(ydl)\n            assert 'Youtubedl-no-compression' not in rh.headers\n            assert rh.headers.get('Accept-Encoding') == 'identity'\n\n    def test_build_handler_params(self):\n        with FakeYDL({\n            'http_headers': {'test': 'testtest'},\n            'socket_timeout': 2,\n            'proxy': 'http://127.0.0.1:8080',\n            'source_address': '127.0.0.45',\n            'debug_printtraffic': True,\n            'compat_opts': ['no-certifi'],\n            'nocheckcertificate': True,\n            'legacyserverconnect': True,\n        }) as ydl:\n            rh = self.build_handler(ydl)\n            assert rh.headers.get('test') == 'testtest'\n            assert 'Accept' in rh.headers  # ensure std_headers are still there\n            assert rh.timeout == 2\n            assert rh.proxies.get('all') == 'http://127.0.0.1:8080'\n            assert rh.source_address == '127.0.0.45'\n            assert rh.verbose is True\n            assert rh.prefer_system_certs is True\n            assert rh.verify is False\n            assert rh.legacy_ssl_support is True\n\n    @pytest.mark.parametrize('ydl_params', [\n        {'client_certificate': 'fakecert.crt'},\n        {'client_certificate': 'fakecert.crt', 'client_certificate_key': 'fakekey.key'},\n        {'client_certificate': 'fakecert.crt', 'client_certificate_key': 'fakekey.key', 'client_certificate_password': 'foobar'},\n        {'client_certificate_key': 'fakekey.key', 'client_certificate_password': 'foobar'},\n    ])\n    def test_client_certificate(self, ydl_params):\n        with FakeYDL(ydl_params) as ydl:\n            rh = self.build_handler(ydl)\n            assert rh._client_cert == ydl_params  # XXX: Too bound to implementation\n\n    def test_urllib_file_urls(self):\n        with FakeYDL({'enable_file_urls': False}) as ydl:\n            rh = self.build_handler(ydl, UrllibRH)\n            assert rh.enable_file_urls is False\n\n        with FakeYDL({'enable_file_urls': True}) as ydl:\n            rh = self.build_handler(ydl, UrllibRH)\n            assert rh.enable_file_urls is True\n\n    def test_compat_opt_prefer_urllib(self):\n        # This assumes urllib only has a preference when this compat opt is given\n        with FakeYDL({'compat_opts': ['prefer-legacy-http-handler']}) as ydl:\n            director = ydl.build_request_director([UrllibRH])\n            assert len(director.preferences) == 1\n            assert director.preferences.pop()(UrllibRH, None)\n\n\nclass TestRequest:\n\n    def test_query(self):\n        req = Request('http://example.com?q=something', query={'v': 'xyz'})\n        assert req.url == 'http://example.com?q=something&v=xyz'\n\n        req.update(query={'v': '123'})\n        assert req.url == 'http://example.com?q=something&v=123'\n        req.update(url='http://example.com', query={'v': 'xyz'})\n        assert req.url == 'http://example.com?v=xyz'\n\n    def test_method(self):\n        req = Request('http://example.com')\n        assert req.method == 'GET'\n        req.data = b'test'\n        assert req.method == 'POST'\n        req.data = None\n        assert req.method == 'GET'\n        req.data = b'test2'\n        req.method = 'PUT'\n        assert req.method == 'PUT'\n        req.data = None\n        assert req.method == 'PUT'\n        with pytest.raises(TypeError):\n            req.method = 1\n\n    def test_request_helpers(self):\n        assert HEADRequest('http://example.com').method == 'HEAD'\n        assert PUTRequest('http://example.com').method == 'PUT'\n\n    def test_headers(self):\n        req = Request('http://example.com', headers={'tesT': 'test'})\n        assert req.headers == HTTPHeaderDict({'test': 'test'})\n        req.update(headers={'teSt2': 'test2'})\n        assert req.headers == HTTPHeaderDict({'test': 'test', 'test2': 'test2'})\n\n        req.headers = new_headers = HTTPHeaderDict({'test': 'test'})\n        assert req.headers == HTTPHeaderDict({'test': 'test'})\n        assert req.headers is new_headers\n\n        # test converts dict to case insensitive dict\n        req.headers = new_headers = {'test2': 'test2'}\n        assert isinstance(req.headers, HTTPHeaderDict)\n        assert req.headers is not new_headers\n\n        with pytest.raises(TypeError):\n            req.headers = None\n\n    def test_data_type(self):\n        req = Request('http://example.com')\n        assert req.data is None\n        # test bytes is allowed\n        req.data = b'test'\n        assert req.data == b'test'\n        # test iterable of bytes is allowed\n        i = [b'test', b'test2']\n        req.data = i\n        assert req.data == i\n\n        # test file-like object is allowed\n        f = io.BytesIO(b'test')\n        req.data = f\n        assert req.data == f\n\n        # common mistake: test str not allowed\n        with pytest.raises(TypeError):\n            req.data = 'test'\n        assert req.data != 'test'\n\n        # common mistake: test dict is not allowed\n        with pytest.raises(TypeError):\n            req.data = {'test': 'test'}\n        assert req.data != {'test': 'test'}\n\n    def test_content_length_header(self):\n        req = Request('http://example.com', headers={'Content-Length': '0'}, data=b'')\n        assert req.headers.get('Content-Length') == '0'\n\n        req.data = b'test'\n        assert 'Content-Length' not in req.headers\n\n        req = Request('http://example.com', headers={'Content-Length': '10'})\n        assert 'Content-Length' not in req.headers\n\n    def test_content_type_header(self):\n        req = Request('http://example.com', headers={'Content-Type': 'test'}, data=b'test')\n        assert req.headers.get('Content-Type') == 'test'\n        req.data = b'test2'\n        assert req.headers.get('Content-Type') == 'test'\n        req.data = None\n        assert 'Content-Type' not in req.headers\n        req.data = b'test3'\n        assert req.headers.get('Content-Type') == 'application/x-www-form-urlencoded'\n\n    def test_update_req(self):\n        req = Request('http://example.com')\n        assert req.data is None\n        assert req.method == 'GET'\n        assert 'Content-Type' not in req.headers\n        # Test that zero-byte payloads will be sent\n        req.update(data=b'')\n        assert req.data == b''\n        assert req.method == 'POST'\n        assert req.headers.get('Content-Type') == 'application/x-www-form-urlencoded'\n\n    def test_proxies(self):\n        req = Request(url='http://example.com', proxies={'http': 'http://127.0.0.1:8080'})\n        assert req.proxies == {'http': 'http://127.0.0.1:8080'}\n\n    def test_extensions(self):\n        req = Request(url='http://example.com', extensions={'timeout': 2})\n        assert req.extensions == {'timeout': 2}\n\n    def test_copy(self):\n        req = Request(\n            url='http://example.com',\n            extensions={'cookiejar': CookieJar()},\n            headers={'Accept-Encoding': 'br'},\n            proxies={'http': 'http://127.0.0.1'},\n            data=[b'123']\n        )\n        req_copy = req.copy()\n        assert req_copy is not req\n        assert req_copy.url == req.url\n        assert req_copy.headers == req.headers\n        assert req_copy.headers is not req.headers\n        assert req_copy.proxies == req.proxies\n        assert req_copy.proxies is not req.proxies\n\n        # Data is not able to be copied\n        assert req_copy.data == req.data\n        assert req_copy.data is req.data\n\n        # Shallow copy extensions\n        assert req_copy.extensions is not req.extensions\n        assert req_copy.extensions['cookiejar'] == req.extensions['cookiejar']\n\n        # Subclasses are copied by default\n        class AnotherRequest(Request):\n            pass\n\n        req = AnotherRequest(url='http://127.0.0.1')\n        assert isinstance(req.copy(), AnotherRequest)\n\n    def test_url(self):\n        req = Request(url='https://\u0444test.example.com/ some space\u0432?\u00e4=c',)\n        assert req.url == 'https://xn--test-z6d.example.com/%20some%20space%D0%B2?%C3%A4=c'\n\n        assert Request(url='//example.com').url == 'http://example.com'\n\n        with pytest.raises(TypeError):\n            Request(url='https://').url = None\n\n\nclass TestResponse:\n\n    @pytest.mark.parametrize('reason,status,expected', [\n        ('custom', 200, 'custom'),\n        (None, 404, 'Not Found'),  # fallback status\n        ('', 403, 'Forbidden'),\n        (None, 999, None)\n    ])\n    def test_reason(self, reason, status, expected):\n        res = Response(io.BytesIO(b''), url='test://', headers={}, status=status, reason=reason)\n        assert res.reason == expected\n\n    def test_headers(self):\n        headers = Message()\n        headers.add_header('Test', 'test')\n        headers.add_header('Test', 'test2')\n        headers.add_header('content-encoding', 'br')\n        res = Response(io.BytesIO(b''), headers=headers, url='test://')\n        assert res.headers.get_all('test') == ['test', 'test2']\n        assert 'Content-Encoding' in res.headers\n\n    def test_get_header(self):\n        headers = Message()\n        headers.add_header('Set-Cookie', 'cookie1')\n        headers.add_header('Set-cookie', 'cookie2')\n        headers.add_header('Test', 'test')\n        headers.add_header('Test', 'test2')\n        res = Response(io.BytesIO(b''), headers=headers, url='test://')\n        assert res.get_header('test') == 'test, test2'\n        assert res.get_header('set-Cookie') == 'cookie1'\n        assert res.get_header('notexist', 'default') == 'default'\n\n    def test_compat(self):\n        res = Response(io.BytesIO(b''), url='test://', status=404, headers={'test': 'test'})\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore', category=DeprecationWarning)\n            assert res.code == res.getcode() == res.status\n            assert res.geturl() == res.url\n            assert res.info() is res.headers\n            assert res.getheader('test') == res.get_header('test')\n", "from .common import InfoExtractor\nfrom ..utils import (\n    ExtractorError,\n    smuggle_url,\n    str_or_none,\n    traverse_obj,\n    urlencode_postdata,\n)\n\n\nclass CybraryBaseIE(InfoExtractor):\n    _API_KEY = 'AIzaSyCX9ru6j70PX2My1Eq6Q1zoMAhuTdXlzSw'\n    _ENDPOINTS = {\n        'course': 'https://app.cybrary.it/courses/api/catalog/browse/course/{}',\n        'course_enrollment': 'https://app.cybrary.it/courses/api/catalog/{}/enrollment',\n        'enrollment': 'https://app.cybrary.it/courses/api/enrollment/{}',\n        'launch': 'https://app.cybrary.it/courses/api/catalog/{}/launch',\n        'vimeo_oembed': 'https://vimeo.com/api/oembed.json?url=https://vimeo.com/{}',\n    }\n    _NETRC_MACHINE = 'cybrary'\n    _TOKEN = None\n\n    def _perform_login(self, username, password):\n        CybraryBaseIE._TOKEN = self._download_json(\n            f'https://identitytoolkit.googleapis.com/v1/accounts:signInWithPassword?key={self._API_KEY}',\n            None, data=urlencode_postdata({'email': username, 'password': password, 'returnSecureToken': True}),\n            note='Logging in')['idToken']\n\n    def _real_initialize(self):\n        if not self._TOKEN:\n            self.raise_login_required(method='password')\n\n    def _call_api(self, endpoint, item_id):\n        return self._download_json(\n            self._ENDPOINTS[endpoint].format(item_id), item_id,\n            note=f'Downloading {endpoint} JSON metadata',\n            headers={'Authorization': f'Bearer {self._TOKEN}'})\n\n    def _get_vimeo_id(self, activity_id):\n        launch_api = self._call_api('launch', activity_id)\n\n        if launch_api.get('url'):\n            return self._search_regex(r'https?://player\\.vimeo\\.com/video/(?P<vimeo_id>[0-9]+)', launch_api['url'], 'vimeo_id')\n        return traverse_obj(launch_api, ('vendor_data', 'content', ..., 'videoId'), get_all=False)\n\n\nclass CybraryIE(CybraryBaseIE):\n    _VALID_URL = r'https?://app\\.cybrary\\.it/immersive/(?P<enrollment>[0-9]+)/activity/(?P<id>[0-9]+)'\n    _TESTS = [{\n        'url': 'https://app.cybrary.it/immersive/12487950/activity/63102',\n        'md5': '9ae12d37e555cb2ed554223a71a701d0',\n        'info_dict': {\n            'id': '646609770',\n            'ext': 'mp4',\n            'title': 'Getting Started',\n            'thumbnail': 'https://i.vimeocdn.com/video/1301817996-76a268f0c56cff18a5cecbbdc44131eb9dda0c80eb0b3a036_1280',\n            'series_id': '63111',\n            'uploader_url': 'https://vimeo.com/user30867300',\n            'duration': 88,\n            'uploader_id': 'user30867300',\n            'series': 'Cybrary Orientation',\n            'uploader': 'Cybrary',\n            'chapter': 'Cybrary Orientation Series',\n            'chapter_id': '63110'\n        },\n        'expected_warnings': ['No authenticators for vimeo']\n    }, {\n        'url': 'https://app.cybrary.it/immersive/12747143/activity/52686',\n        'md5': '62f26547dccc59c44363e2a13d4ad08d',\n        'info_dict': {\n            'id': '445638073',\n            'ext': 'mp4',\n            'title': 'Azure Virtual Network IP Addressing',\n            'thumbnail': 'https://i.vimeocdn.com/video/936667051-1647ace66c627d4a2382185e0dae8deb830309bfddd53f8b2367b2f91e92ed0e-d_1280',\n            'series_id': '52733',\n            'uploader_url': 'https://vimeo.com/user30867300',\n            'duration': 426,\n            'uploader_id': 'user30867300',\n            'series': 'AZ-500: Microsoft Azure Security Technologies',\n            'uploader': 'Cybrary',\n            'chapter': 'Implement Network Security',\n            'chapter_id': '52693'\n        },\n        'expected_warnings': ['No authenticators for vimeo']\n    }]\n\n    def _real_extract(self, url):\n        activity_id, enrollment_id = self._match_valid_url(url).group('id', 'enrollment')\n        course = self._call_api('enrollment', enrollment_id)['content']\n        activity = traverse_obj(course, ('learning_modules', ..., 'activities', lambda _, v: int(activity_id) == v['id']), get_all=False)\n\n        if activity.get('type') not in ['Video Activity', 'Lesson Activity']:\n            raise ExtractorError('The activity is not a video', expected=True)\n\n        module = next((m for m in course.get('learning_modules') or []\n                      if int(activity_id) in traverse_obj(m, ('activities', ..., 'id') or [])), None)\n\n        vimeo_id = self._get_vimeo_id(activity_id)\n\n        return {\n            '_type': 'url_transparent',\n            'series': traverse_obj(course, ('content_description', 'title')),\n            'series_id': str_or_none(traverse_obj(course, ('content_description', 'id'))),\n            'id': vimeo_id,\n            'chapter': module.get('title'),\n            'chapter_id': str_or_none(module.get('id')),\n            'title': activity.get('title'),\n            'url': smuggle_url(f'https://player.vimeo.com/video/{vimeo_id}', {'http_headers': {'Referer': 'https://api.cybrary.it'}})\n        }\n\n\nclass CybraryCourseIE(CybraryBaseIE):\n    _VALID_URL = r'https://app\\.cybrary\\.it/browse/course/(?P<id>[\\w-]+)/?(?:$|[#?])'\n    _TESTS = [{\n        'url': 'https://app.cybrary.it/browse/course/az-500-microsoft-azure-security-technologies',\n        'info_dict': {\n            'id': 898,\n            'title': 'AZ-500: Microsoft Azure Security Technologies',\n            'description': 'md5:69549d379c0fc1dec92926d4e8b6fbd4'\n        },\n        'playlist_count': 59\n    }, {\n        'url': 'https://app.cybrary.it/browse/course/cybrary-orientation',\n        'info_dict': {\n            'id': 1245,\n            'title': 'Cybrary Orientation',\n            'description': 'md5:9e69ff66b32fe78744e0ad4babe2e88e'\n        },\n        'playlist_count': 4\n    }]\n\n    def _real_extract(self, url):\n        course_id = self._match_id(url)\n        course = self._call_api('course', course_id)\n        enrollment_info = self._call_api('course_enrollment', course['id'])\n\n        entries = [self.url_result(\n            f'https://app.cybrary.it/immersive/{enrollment_info[\"id\"]}/activity/{activity[\"id\"]}')\n            for activity in traverse_obj(course, ('content_item', 'learning_modules', ..., 'activities', ...))]\n\n        return self.playlist_result(\n            entries,\n            traverse_obj(course, ('content_item', 'id'), expected_type=str_or_none),\n            course.get('title'), course.get('short_description'))\n", "import re\n\nfrom .common import InfoExtractor\nfrom ..compat import compat_urlparse\nfrom ..utils import (\n    clean_html,\n    extract_attributes,\n    ExtractorError,\n    get_elements_by_class,\n    int_or_none,\n    js_to_json,\n    smuggle_url,\n    unescapeHTML,\n)\n\n\ndef _get_elements_by_tag_and_attrib(html, tag=None, attribute=None, value=None, escape_value=True):\n    \"\"\"Return the content of the tag with the specified attribute in the passed HTML document\"\"\"\n\n    if tag is None:\n        tag = '[a-zA-Z0-9:._-]+'\n    if attribute is None:\n        attribute = ''\n    else:\n        attribute = r'\\s+(?P<attribute>%s)' % re.escape(attribute)\n    if value is None:\n        value = ''\n    else:\n        value = re.escape(value) if escape_value else value\n        value = '=[\\'\"]?(?P<value>%s)[\\'\"]?' % value\n\n    retlist = []\n    for m in re.finditer(r'''(?xs)\n        <(?P<tag>%s)\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|=\"[^\"]*\"|='[^']*'|))*?\n         %s%s\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|=\"[^\"]*\"|='[^']*'|))*?\n        \\s*>\n        (?P<content>.*?)\n        </\\1>\n    ''' % (tag, attribute, value), html):\n        retlist.append(m)\n\n    return retlist\n\n\ndef _get_element_by_tag_and_attrib(html, tag=None, attribute=None, value=None, escape_value=True):\n    retval = _get_elements_by_tag_and_attrib(html, tag, attribute, value, escape_value)\n    return retval[0] if retval else None\n\n\nclass DubokuIE(InfoExtractor):\n    IE_NAME = 'duboku'\n    IE_DESC = 'www.duboku.io'\n\n    _VALID_URL = r'(?:https?://[^/]+\\.duboku\\.io/vodplay/)(?P<id>[0-9]+-[0-9-]+)\\.html.*'\n    _TESTS = [{\n        'url': 'https://w.duboku.io/vodplay/1575-1-1.html',\n        'info_dict': {\n            'id': '1575-1-1',\n            'ext': 'mp4',\n            'series': '\u767d\u8272\u6708\u5149',\n            'title': 'contains:\u767d\u8272\u6708\u5149',\n            'season_number': 1,\n            'episode_number': 1,\n            'season': 'Season 1',\n            'episode_id': '1',\n            'season_id': '1',\n            'episode': 'Episode 1',\n        },\n        'params': {\n            'skip_download': 'm3u8 download',\n        },\n    }, {\n        'url': 'https://w.duboku.io/vodplay/1588-1-1.html',\n        'info_dict': {\n            'id': '1588-1-1',\n            'ext': 'mp4',\n            'series': '\u4eb2\u7231\u7684\u81ea\u5df1',\n            'title': 'contains:\u7b2c1\u96c6',\n            'season_number': 1,\n            'episode_number': 1,\n            'episode': 'Episode 1',\n            'season': 'Season 1',\n            'episode_id': '1',\n            'season_id': '1',\n        },\n        'params': {\n            'skip_download': 'm3u8 download',\n        },\n    }]\n\n    _PLAYER_DATA_PATTERN = r'player_data\\s*=\\s*(\\{\\s*(.*)})\\s*;?\\s*</script'\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        temp = video_id.split('-')\n        series_id = temp[0]\n        season_id = temp[1]\n        episode_id = temp[2]\n\n        webpage_url = 'https://w.duboku.io/vodplay/%s.html' % video_id\n        webpage_html = self._download_webpage(webpage_url, video_id)\n\n        # extract video url\n\n        player_data = self._search_regex(\n            self._PLAYER_DATA_PATTERN, webpage_html, 'player_data')\n        player_data = self._parse_json(player_data, video_id, js_to_json)\n\n        # extract title\n\n        temp = get_elements_by_class('title', webpage_html)\n        series_title = None\n        title = None\n        for html in temp:\n            mobj = re.search(r'<a\\s+.*>(.*)</a>', html)\n            if mobj:\n                href = extract_attributes(mobj.group(0)).get('href')\n                if href:\n                    mobj1 = re.search(r'/(\\d+)\\.html', href)\n                    if mobj1 and mobj1.group(1) == series_id:\n                        series_title = clean_html(mobj.group(0))\n                        series_title = re.sub(r'[\\s\\r\\n\\t]+', ' ', series_title)\n                        title = clean_html(html)\n                        title = re.sub(r'[\\s\\r\\n\\t]+', ' ', title)\n                        break\n\n        data_url = player_data.get('url')\n        if not data_url:\n            raise ExtractorError('Cannot find url in player_data')\n        data_from = player_data.get('from')\n\n        # if it is an embedded iframe, maybe it's an external source\n        headers = {'Referer': webpage_url}\n        if data_from == 'iframe':\n            # use _type url_transparent to retain the meaningful details\n            # of the video.\n            return {\n                '_type': 'url_transparent',\n                'url': smuggle_url(data_url, {'http_headers': headers}),\n                'id': video_id,\n                'title': title,\n                'series': series_title,\n                'season_number': int_or_none(season_id),\n                'season_id': season_id,\n                'episode_number': int_or_none(episode_id),\n                'episode_id': episode_id,\n            }\n\n        formats = self._extract_m3u8_formats(data_url, video_id, 'mp4', headers=headers)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'series': series_title,\n            'season_number': int_or_none(season_id),\n            'season_id': season_id,\n            'episode_number': int_or_none(episode_id),\n            'episode_id': episode_id,\n            'formats': formats,\n            'http_headers': headers\n        }\n\n\nclass DubokuPlaylistIE(InfoExtractor):\n    IE_NAME = 'duboku:list'\n    IE_DESC = 'www.duboku.io entire series'\n\n    _VALID_URL = r'(?:https?://[^/]+\\.duboku\\.io/voddetail/)(?P<id>[0-9]+)\\.html.*'\n    _TESTS = [{\n        'url': 'https://w.duboku.io/voddetail/1575.html',\n        'info_dict': {\n            'id': 'startswith:1575',\n            'title': '\u767d\u8272\u6708\u5149',\n        },\n        'playlist_count': 12,\n    }, {\n        'url': 'https://w.duboku.io/voddetail/1554.html',\n        'info_dict': {\n            'id': 'startswith:1554',\n            'title': '\u4ee5\u5bb6\u4eba\u4e4b\u540d',\n        },\n        'playlist_mincount': 30,\n    }]\n\n    def _real_extract(self, url):\n        mobj = self._match_valid_url(url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        series_id = mobj.group('id')\n        fragment = compat_urlparse.urlparse(url).fragment\n\n        webpage_url = 'https://w.duboku.io/voddetail/%s.html' % series_id\n        webpage_html = self._download_webpage(webpage_url, series_id)\n\n        # extract title\n\n        title = _get_element_by_tag_and_attrib(webpage_html, 'h1', 'class', 'title')\n        title = unescapeHTML(title.group('content')) if title else None\n        if not title:\n            title = self._html_search_meta('keywords', webpage_html)\n        if not title:\n            title = _get_element_by_tag_and_attrib(webpage_html, 'title')\n            title = unescapeHTML(title.group('content')) if title else None\n\n        # extract playlists\n\n        playlists = {}\n        for div in _get_elements_by_tag_and_attrib(\n                webpage_html, attribute='id', value='playlist\\\\d+', escape_value=False):\n            playlist_id = div.group('value')\n            playlist = []\n            for a in _get_elements_by_tag_and_attrib(\n                    div.group('content'), 'a', 'href', value='[^\\'\"]+?', escape_value=False):\n                playlist.append({\n                    'href': unescapeHTML(a.group('value')),\n                    'title': unescapeHTML(a.group('content'))\n                })\n            playlists[playlist_id] = playlist\n\n        # select the specified playlist if url fragment exists\n        playlist = None\n        playlist_id = None\n        if fragment:\n            playlist = playlists.get(fragment)\n            playlist_id = fragment\n        else:\n            first = next(iter(playlists.items()), None)\n            if first:\n                (playlist_id, playlist) = first\n        if not playlist:\n            raise ExtractorError(\n                'Cannot find %s' % fragment if fragment else 'Cannot extract playlist')\n\n        # return url results\n        return self.playlist_result([\n            self.url_result(\n                compat_urlparse.urljoin('https://w.duboku.io', x['href']),\n                ie=DubokuIE.ie_key(), video_title=x.get('title'))\n            for x in playlist], series_id + '#' + playlist_id, title)\n", "import re\nimport urllib.parse\n\nfrom .common import InfoExtractor\nfrom .youtube import YoutubeTabIE\nfrom ..utils import parse_qs, smuggle_url, traverse_obj\n\n\nclass EmbedlyIE(InfoExtractor):\n    _VALID_URL = r'https?://(?:www|cdn\\.)?embedly\\.com/widgets/media\\.html\\?(?:[^#]*?&)?(?:src|url)=(?:[^#&]+)'\n    _TESTS = [{\n        'url': 'https://cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DUUGLim4T2loE5rwCMdpCIPVg&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DSU4fj_aEMVw%26list%3DUUGLim4T2loE5rwCMdpCIPVg&image=http%3A%2F%2Fi.ytimg.com%2Fvi%2FSU4fj_aEMVw%2Fhqdefault.jpg&key=8ee8a2e6a8cc47aab1a5ee67f9a178e0&type=text%2Fhtml&schema=youtube&autoplay=1',\n        'info_dict': {\n            'id': 'UUGLim4T2loE5rwCMdpCIPVg',\n            'modified_date': '20221225',\n            'view_count': int,\n            'uploader_url': 'https://www.youtube.com/@TraciHinesMusic',\n            'channel_id': 'UCGLim4T2loE5rwCMdpCIPVg',\n            'uploader': 'TraciJHines',\n            'channel_url': 'https://www.youtube.com/@TraciHinesMusic',\n            'channel': 'TraciJHines',\n            'availability': 'public',\n            'uploader_id': 'UCGLim4T2loE5rwCMdpCIPVg',\n            'description': '',\n            'tags': [],\n            'title': 'Uploads from TraciJHines',\n        },\n        'playlist_mincount': 10,\n    }, {\n        'url': 'https://cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DUUGLim4T2loE5rwCMdpCIPVg&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DSU4fj_aEMVw%26list%3DUUGLim4T2loE5rwCMdpCIPVg&image=http%3A%2F%2Fi.ytimg.com%2Fvi%2FSU4fj_aEMVw%2Fhqdefault.jpg&key=8ee8a2e6a8cc47aab1a5ee67f9a178e0&type=text%2Fhtml&schema=youtube&autoplay=1',\n        'params': {'noplaylist': True},\n        'info_dict': {\n            'id': 'SU4fj_aEMVw',\n            'ext': 'mp4',\n            'title': 'I\\'m on Patreon!',\n            'age_limit': 0,\n            'categories': ['Entertainment'],\n            'thumbnail': 'https://i.ytimg.com/vi_webp/SU4fj_aEMVw/maxresdefault.webp',\n            'live_status': 'not_live',\n            'playable_in_embed': True,\n            'channel': 'TraciJHines',\n            'uploader_id': 'TraciJHines',\n            'channel_url': 'https://www.youtube.com/channel/UCGLim4T2loE5rwCMdpCIPVg',\n            'uploader_url': 'http://www.youtube.com/user/TraciJHines',\n            'upload_date': '20150211',\n            'duration': 282,\n            'availability': 'public',\n            'channel_follower_count': int,\n            'tags': 'count:39',\n            'view_count': int,\n            'comment_count': int,\n            'channel_id': 'UCGLim4T2loE5rwCMdpCIPVg',\n            'like_count': int,\n            'uploader': 'TraciJHines',\n            'description': 'md5:8af6425f50bd46fbf29f3db0fc3a8364',\n            'chapters': list,\n\n        },\n    }, {\n        'url': 'https://cdn.embedly.com/widgets/media.html?src=https://player.vimeo.com/video/1234567?h=abcdefgh',\n        'only_matching': True,\n    }]\n\n    _WEBPAGE_TESTS = [{\n        'url': 'http://www.permacultureetc.com/2022/12/comment-greffer-facilement-les-arbres-fruitiers.html',\n        'info_dict': {\n            'id': 'pfUK_ADTvgY',\n            'ext': 'mp4',\n            'title': 'Comment greffer facilement les arbres fruitiers ? (mois par mois)',\n            'description': 'md5:d3a876995e522f138aabb48e040bfb4c',\n            'view_count': int,\n            'upload_date': '20221210',\n            'comment_count': int,\n            'live_status': 'not_live',\n            'channel_id': 'UCsM4_jihNFYe4CtSkXvDR-Q',\n            'channel_follower_count': int,\n            'tags': ['permaculture', 'jardinage', 'dekarz', 'autonomie', 'greffe', 'fruitiers', 'arbres', 'jardin for\u00eat', 'for\u00eat comestible', 'damien'],\n            'playable_in_embed': True,\n            'uploader': 'permaculture agro\u00e9cologie etc...',\n            'channel': 'permaculture agro\u00e9cologie etc...',\n            'thumbnail': 'https://i.ytimg.com/vi/pfUK_ADTvgY/sddefault.jpg',\n            'duration': 1526,\n            'channel_url': 'https://www.youtube.com/channel/UCsM4_jihNFYe4CtSkXvDR-Q',\n            'age_limit': 0,\n            'uploader_id': 'permacultureetc',\n            'like_count': int,\n            'uploader_url': 'http://www.youtube.com/user/permacultureetc',\n            'categories': ['Education'],\n            'availability': 'public',\n        },\n    }]\n\n    @classmethod\n    def _extract_from_webpage(cls, url, webpage):\n        # Bypass \"ie=cls\" and suitable check\n        for mobj in re.finditer(r'class=[\"\\']embedly-card[\"\\'][^>]href=[\"\\'](?P<url>[^\"\\']+)', webpage):\n            yield cls.url_result(mobj.group('url'))\n\n        for mobj in re.finditer(r'class=[\"\\']embedly-embed[\"\\'][^>]src=[\"\\'][^\"\\']*url=(?P<url>[^&]+)', webpage):\n            yield cls.url_result(urllib.parse.unquote(mobj.group('url')))\n\n    def _real_extract(self, url):\n        qs = parse_qs(url)\n        src = urllib.parse.unquote(traverse_obj(qs, ('url', 0)) or '')\n        if src and YoutubeTabIE.suitable(src):\n            return self.url_result(src, YoutubeTabIE)\n        return self.url_result(smuggle_url(\n            urllib.parse.unquote(traverse_obj(qs, ('src', 0), ('url', 0))),\n            {'http_headers': {'Referer': url}}))\n", "import os\nimport re\nimport types\nimport urllib.parse\nimport xml.etree.ElementTree\n\nfrom .common import InfoExtractor  # isort: split\nfrom .commonprotocols import RtmpIE\nfrom .youtube import YoutubeIE\nfrom ..compat import compat_etree_fromstring\nfrom ..utils import (\n    KNOWN_EXTENSIONS,\n    MEDIA_EXTENSIONS,\n    ExtractorError,\n    UnsupportedError,\n    determine_ext,\n    determine_protocol,\n    dict_get,\n    extract_basic_auth,\n    format_field,\n    int_or_none,\n    is_html,\n    js_to_json,\n    merge_dicts,\n    mimetype2ext,\n    orderedSet,\n    parse_duration,\n    parse_resolution,\n    smuggle_url,\n    str_or_none,\n    traverse_obj,\n    try_call,\n    unescapeHTML,\n    unified_timestamp,\n    unsmuggle_url,\n    update_url_query,\n    urlhandle_detect_ext,\n    url_or_none,\n    urljoin,\n    variadic,\n    xpath_attr,\n    xpath_text,\n    xpath_with_ns,\n)\n\n\nclass GenericIE(InfoExtractor):\n    IE_DESC = 'Generic downloader that works on some sites'\n    _VALID_URL = r'.*'\n    IE_NAME = 'generic'\n    _NETRC_MACHINE = False  # Suppress username warning\n    _TESTS = [\n        # Direct link to a video\n        {\n            'url': 'http://media.w3.org/2010/05/sintel/trailer.mp4',\n            'md5': '67d406c2bcb6af27fa886f31aa934bbe',\n            'info_dict': {\n                'id': 'trailer',\n                'ext': 'mp4',\n                'title': 'trailer',\n                'upload_date': '20100513',\n                'direct': True,\n                'timestamp': 1273772943.0,\n            }\n        },\n        # Direct link to media delivered compressed (until Accept-Encoding is *)\n        {\n            'url': 'http://calimero.tk/muzik/FictionJunction-Parallel_Hearts.flac',\n            'md5': '128c42e68b13950268b648275386fc74',\n            'info_dict': {\n                'id': 'FictionJunction-Parallel_Hearts',\n                'ext': 'flac',\n                'title': 'FictionJunction-Parallel_Hearts',\n                'upload_date': '20140522',\n            },\n            'expected_warnings': [\n                'URL could be a direct video link, returning it as such.'\n            ],\n            'skip': 'URL invalid',\n        },\n        # Direct download with broken HEAD\n        {\n            'url': 'http://ai-radio.org:8000/radio.opus',\n            'info_dict': {\n                'id': 'radio',\n                'ext': 'opus',\n                'title': 'radio',\n            },\n            'params': {\n                'skip_download': True,  # infinite live stream\n            },\n            'expected_warnings': [\n                r'501.*Not Implemented',\n                r'400.*Bad Request',\n            ],\n        },\n        # Direct link with incorrect MIME type\n        {\n            'url': 'http://ftp.nluug.nl/video/nluug/2014-11-20_nj14/zaal-2/5_Lennart_Poettering_-_Systemd.webm',\n            'md5': '4ccbebe5f36706d85221f204d7eb5913',\n            'info_dict': {\n                'url': 'http://ftp.nluug.nl/video/nluug/2014-11-20_nj14/zaal-2/5_Lennart_Poettering_-_Systemd.webm',\n                'id': '5_Lennart_Poettering_-_Systemd',\n                'ext': 'webm',\n                'title': '5_Lennart_Poettering_-_Systemd',\n                'upload_date': '20141120',\n                'direct': True,\n                'timestamp': 1416498816.0,\n            },\n            'expected_warnings': [\n                'URL could be a direct video link, returning it as such.'\n            ]\n        },\n        # RSS feed\n        {\n            'url': 'http://phihag.de/2014/youtube-dl/rss2.xml',\n            'info_dict': {\n                'id': 'https://phihag.de/2014/youtube-dl/rss2.xml',\n                'title': 'Zero Punctuation',\n                'description': 're:.*groundbreaking video review series.*'\n            },\n            'playlist_mincount': 11,\n        },\n        # RSS feed with enclosure\n        {\n            'url': 'http://podcastfeeds.nbcnews.com/audio/podcast/MSNBC-MADDOW-NETCAST-M4V.xml',\n            'info_dict': {\n                'id': 'http://podcastfeeds.nbcnews.com/nbcnews/video/podcast/MSNBC-MADDOW-NETCAST-M4V.xml',\n                'title': 'MSNBC Rachel Maddow (video)',\n                'description': 're:.*her unique approach to storytelling.*',\n            },\n            'playlist': [{\n                'info_dict': {\n                    'ext': 'mov',\n                    'id': 'pdv_maddow_netcast_mov-12-03-2020-223726',\n                    'title': 'MSNBC Rachel Maddow (video) - 12-03-2020-223726',\n                    'description': 're:.*her unique approach to storytelling.*',\n                    'upload_date': '20201204',\n                },\n            }],\n            'skip': 'Dead link',\n        },\n        # RSS feed with item with description and thumbnails\n        {\n            'url': 'https://anchor.fm/s/dd00e14/podcast/rss',\n            'info_dict': {\n                'id': 'https://anchor.fm/s/dd00e14/podcast/rss',\n                'title': 're:.*100% Hydrogen.*',\n                'description': 're:.*In this episode.*',\n            },\n            'playlist': [{\n                'info_dict': {\n                    'ext': 'm4a',\n                    'id': '818a5d38-01cd-152f-2231-ee479677fa82',\n                    'title': 're:Hydrogen!',\n                    'description': 're:.*In this episode we are going.*',\n                    'timestamp': 1567977776,\n                    'upload_date': '20190908',\n                    'duration': 423,\n                    'thumbnail': r're:^https?://.*\\.jpg$',\n                    'episode_number': 1,\n                    'season_number': 1,\n                    'age_limit': 0,\n                    'season': 'Season 1',\n                    'direct': True,\n                    'episode': 'Episode 1',\n                },\n            }],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # RSS feed with enclosures and unsupported link URLs\n        {\n            'url': 'http://www.hellointernet.fm/podcast?format=rss',\n            'info_dict': {\n                'id': 'http://www.hellointernet.fm/podcast?format=rss',\n                'description': 'CGP Grey and Brady Haran talk about YouTube, life, work, whatever.',\n                'title': 'Hello Internet',\n            },\n            'playlist_mincount': 100,\n        },\n        # RSS feed with guid\n        {\n            'url': 'https://www.omnycontent.com/d/playlist/a7b4f8fe-59d9-4afc-a79a-a90101378abf/bf2c1d80-3656-4449-9d00-a903004e8f84/efbff746-e7c1-463a-9d80-a903004e8f8f/podcast.rss',\n            'info_dict': {\n                'id': 'https://www.omnycontent.com/d/playlist/a7b4f8fe-59d9-4afc-a79a-a90101378abf/bf2c1d80-3656-4449-9d00-a903004e8f84/efbff746-e7c1-463a-9d80-a903004e8f8f/podcast.rss',\n                'description': 'md5:be809a44b63b0c56fb485caf68685520',\n                'title': 'The Little Red Podcast',\n            },\n            'playlist_mincount': 76,\n        },\n        # SMIL from http://videolectures.net/promogram_igor_mekjavic_eng\n        {\n            'url': 'http://videolectures.net/promogram_igor_mekjavic_eng/video/1/smil.xml',\n            'info_dict': {\n                'id': 'smil',\n                'ext': 'mp4',\n                'title': 'Automatics, robotics and biocybernetics',\n                'description': 'md5:815fc1deb6b3a2bff99de2d5325be482',\n                'upload_date': '20130627',\n                'formats': 'mincount:16',\n                'subtitles': 'mincount:1',\n            },\n            'params': {\n                'force_generic_extractor': True,\n                'skip_download': True,\n            },\n        },\n        # SMIL from http://www1.wdr.de/mediathek/video/livestream/index.html\n        {\n            'url': 'http://metafilegenerator.de/WDR/WDR_FS/hds/hds.smil',\n            'info_dict': {\n                'id': 'hds',\n                'ext': 'flv',\n                'title': 'hds',\n                'formats': 'mincount:1',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # SMIL from https://www.restudy.dk/video/play/id/1637\n        {\n            'url': 'https://www.restudy.dk/awsmedia/SmilDirectory/video_1637.xml',\n            'info_dict': {\n                'id': 'video_1637',\n                'ext': 'flv',\n                'title': 'video_1637',\n                'formats': 'mincount:3',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # SMIL from http://adventure.howstuffworks.com/5266-cool-jobs-iditarod-musher-video.htm\n        {\n            'url': 'http://services.media.howstuffworks.com/videos/450221/smil-service.smil',\n            'info_dict': {\n                'id': 'smil-service',\n                'ext': 'flv',\n                'title': 'smil-service',\n                'formats': 'mincount:1',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # SMIL from http://new.livestream.com/CoheedandCambria/WebsterHall/videos/4719370\n        {\n            'url': 'http://api.new.livestream.com/accounts/1570303/events/1585861/videos/4719370.smil',\n            'info_dict': {\n                'id': '4719370',\n                'ext': 'mp4',\n                'title': '571de1fd-47bc-48db-abf9-238872a58d1f',\n                'formats': 'mincount:3',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # XSPF playlist from http://www.telegraaf.nl/tv/nieuws/binnenland/24353229/__Tikibad_ontruimd_wegens_brand__.html\n        {\n            'url': 'http://www.telegraaf.nl/xml/playlist/2015/8/7/mZlp2ctYIUEB.xspf',\n            'info_dict': {\n                'id': 'mZlp2ctYIUEB',\n                'ext': 'mp4',\n                'title': 'Tikibad ontruimd wegens brand',\n                'description': 'md5:05ca046ff47b931f9b04855015e163a4',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 33,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': '404 Not Found',\n        },\n        # MPD from http://dash-mse-test.appspot.com/media.html\n        {\n            'url': 'http://yt-dash-mse-test.commondatastorage.googleapis.com/media/car-20120827-manifest.mpd',\n            'md5': '4b57baab2e30d6eb3a6a09f0ba57ef53',\n            'info_dict': {\n                'id': 'car-20120827-manifest',\n                'ext': 'mp4',\n                'title': 'car-20120827-manifest',\n                'formats': 'mincount:9',\n                'upload_date': '20130904',\n                'timestamp': 1378272859.0,\n            },\n        },\n        # m3u8 served with Content-Type: audio/x-mpegURL; charset=utf-8\n        {\n            'url': 'http://once.unicornmedia.com/now/master/playlist/bb0b18ba-64f5-4b1b-a29f-0ac252f06b68/77a785f3-5188-4806-b788-0893a61634ed/93677179-2d99-4ef4-9e17-fe70d49abfbf/content.m3u8',\n            'info_dict': {\n                'id': 'content',\n                'ext': 'mp4',\n                'title': 'content',\n                'formats': 'mincount:8',\n            },\n            'params': {\n                # m3u8 downloads\n                'skip_download': True,\n            },\n            'skip': 'video gone',\n        },\n        # m3u8 served with Content-Type: text/plain\n        {\n            'url': 'http://www.nacentapps.com/m3u8/index.m3u8',\n            'info_dict': {\n                'id': 'index',\n                'ext': 'mp4',\n                'title': 'index',\n                'upload_date': '20140720',\n                'formats': 'mincount:11',\n            },\n            'params': {\n                # m3u8 downloads\n                'skip_download': True,\n            },\n            'skip': 'video gone',\n        },\n        # google redirect\n        {\n            'url': 'http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CCUQtwIwAA&url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DcmQHVoWB5FY&ei=F-sNU-LLCaXk4QT52ICQBQ&usg=AFQjCNEw4hL29zgOohLXvpJ-Bdh2bils1Q&bvm=bv.61965928,d.bGE',\n            'info_dict': {\n                'id': 'cmQHVoWB5FY',\n                'ext': 'mp4',\n                'upload_date': '20130224',\n                'uploader_id': '@TheVerge',\n                'description': r're:^Chris Ziegler takes a look at the\\.*',\n                'uploader': 'The Verge',\n                'title': 'First Firefox OS phones side-by-side',\n            },\n            'params': {\n                'skip_download': False,\n            }\n        },\n        {\n            # redirect in Refresh HTTP header\n            'url': 'https://www.facebook.com/l.php?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DpO8h3EaFRdo&h=TAQHsoToz&enc=AZN16h-b6o4Zq9pZkCCdOLNKMN96BbGMNtcFwHSaazus4JHT_MFYkAA-WARTX2kvsCIdlAIyHZjl6d33ILIJU7Jzwk_K3mcenAXoAzBNoZDI_Q7EXGDJnIhrGkLXo_LJ_pAa2Jzbx17UHMd3jAs--6j2zaeto5w9RTn8T_1kKg3fdC5WPX9Dbb18vzH7YFX0eSJmoa6SP114rvlkw6pkS1-T&s=1',\n            'info_dict': {\n                'id': 'pO8h3EaFRdo',\n                'ext': 'mp4',\n                'title': 'Tripeo Boiler Room x Dekmantel Festival DJ Set',\n                'description': 'md5:6294cc1af09c4049e0652b51a2df10d5',\n                'upload_date': '20150917',\n                'uploader_id': 'brtvofficial',\n                'uploader': 'Boiler Room',\n            },\n            'params': {\n                'skip_download': False,\n            },\n        },\n        {\n            'url': 'http://www.hodiho.fr/2013/02/regis-plante-sa-jeep.html',\n            'md5': '85b90ccc9d73b4acd9138d3af4c27f89',\n            'info_dict': {\n                'id': '13601338388002',\n                'ext': 'mp4',\n                'uploader': 'www.hodiho.fr',\n                'title': 'R\\u00e9gis plante sa Jeep',\n            }\n        },\n        # bandcamp page with custom domain\n        {\n            'add_ie': ['Bandcamp'],\n            'url': 'http://bronyrock.com/track/the-pony-mash',\n            'info_dict': {\n                'id': '3235767654',\n                'ext': 'mp3',\n                'title': 'The Pony Mash',\n                'uploader': 'M_Pallante',\n            },\n            'skip': 'There is a limit of 200 free downloads / month for the test song',\n        },\n        # ooyala video\n        {\n            'url': 'http://www.rollingstone.com/music/videos/norwegian-dj-cashmere-cat-goes-spartan-on-with-me-premiere-20131219',\n            'md5': '166dd577b433b4d4ebfee10b0824d8ff',\n            'info_dict': {\n                'id': 'BwY2RxaTrTkslxOfcan0UCf0YqyvWysJ',\n                'ext': 'mp4',\n                'title': '2cc213299525360.mov',  # that's what we get\n                'duration': 238.231,\n            },\n            'add_ie': ['Ooyala'],\n        },\n        {\n            # ooyala video embedded with http://player.ooyala.com/iframe.js\n            'url': 'http://www.macrumors.com/2015/07/24/steve-jobs-the-man-in-the-machine-first-trailer/',\n            'info_dict': {\n                'id': 'p0MGJndjoG5SOKqO_hZJuZFPB-Tr5VgB',\n                'ext': 'mp4',\n                'title': '\"Steve Jobs: Man in the Machine\" trailer',\n                'description': 'The first trailer for the Alex Gibney documentary \"Steve Jobs: Man in the Machine.\"',\n                'duration': 135.427,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'movie expired',\n        },\n        # ooyala video embedded with http://player.ooyala.com/static/v4/production/latest/core.min.js\n        {\n            'url': 'http://wnep.com/2017/07/22/steampunk-fest-comes-to-honesdale/',\n            'info_dict': {\n                'id': 'lwYWYxYzE6V5uJMjNGyKtwwiw9ZJD7t2',\n                'ext': 'mp4',\n                'title': 'Steampunk Fest Comes to Honesdale',\n                'duration': 43.276,\n            },\n            'params': {\n                'skip_download': True,\n            }\n        },\n        # embed.ly video\n        {\n            'url': 'http://www.tested.com/science/weird/460206-tested-grinding-coffee-2000-frames-second/',\n            'info_dict': {\n                'id': '9ODmcdjQcHQ',\n                'ext': 'mp4',\n                'title': 'Tested: Grinding Coffee at 2000 Frames Per Second',\n                'upload_date': '20140225',\n                'description': 'md5:06a40fbf30b220468f1e0957c0f558ff',\n                'uploader': 'Tested',\n                'uploader_id': 'testedcom',\n            },\n            # No need to test YoutubeIE here\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # funnyordie embed\n        {\n            'url': 'http://www.theguardian.com/world/2014/mar/11/obama-zach-galifianakis-between-two-ferns',\n            'info_dict': {\n                'id': '18e820ec3f',\n                'ext': 'mp4',\n                'title': 'Between Two Ferns with Zach Galifianakis: President Barack Obama',\n                'description': 'Episode 18: President Barack Obama sits down with Zach Galifianakis for his most memorable interview yet.',\n            },\n            # HEAD requests lead to endless 301, while GET is OK\n            'expected_warnings': ['301'],\n        },\n        # RUTV embed\n        {\n            'url': 'http://www.rg.ru/2014/03/15/reg-dfo/anklav-anons.html',\n            'info_dict': {\n                'id': '776940',\n                'ext': 'mp4',\n                'title': '\u041e\u0445\u043e\u0442\u0441\u043a\u043e\u0435 \u043c\u043e\u0440\u0435 \u0441\u0442\u0430\u043b\u043e \u0446\u0435\u043b\u0438\u043a\u043e\u043c \u0440\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u0438\u043c',\n                'description': 'md5:5ed62483b14663e2a95ebbe115eb8f43',\n            },\n            'params': {\n                # m3u8 download\n                'skip_download': True,\n            },\n        },\n        # TVC embed\n        {\n            'url': 'http://sch1298sz.mskobr.ru/dou_edu/karamel_ki/filial_galleries/video/iframe_src_http_tvc_ru_video_iframe_id_55304_isplay_false_acc_video_id_channel_brand_id_11_show_episodes_episode_id_32307_frameb/',\n            'info_dict': {\n                'id': '55304',\n                'ext': 'mp4',\n                'title': '\u0414\u043e\u0448\u043a\u043e\u043b\u044c\u043d\u043e\u0435 \u0432\u043e\u0441\u043f\u0438\u0442\u0430\u043d\u0438\u0435',\n            },\n        },\n        # SportBox embed\n        {\n            'url': 'http://www.vestifinance.ru/articles/25753',\n            'info_dict': {\n                'id': '25753',\n                'title': '\u041f\u0440\u044f\u043c\u044b\u0435 \u0442\u0440\u0430\u043d\u0441\u043b\u044f\u0446\u0438\u0438 \u0441 \u0424\u043e\u0440\u0443\u043c\u0430-\u0432\u044b\u0441\u0442\u0430\u0432\u043a\u0438 \"\u0413\u043e\u0441\u0437\u0430\u043a\u0430\u0437-2013\"',\n            },\n            'playlist': [{\n                'info_dict': {\n                    'id': '370908',\n                    'title': '\u0413\u043e\u0441\u0437\u0430\u043a\u0430\u0437. \u0414\u0435\u043d\u044c 3',\n                    'ext': 'mp4',\n                }\n            }, {\n                'info_dict': {\n                    'id': '370905',\n                    'title': '\u0413\u043e\u0441\u0437\u0430\u043a\u0430\u0437. \u0414\u0435\u043d\u044c 2',\n                    'ext': 'mp4',\n                }\n            }, {\n                'info_dict': {\n                    'id': '370902',\n                    'title': '\u0413\u043e\u0441\u0437\u0430\u043a\u0430\u0437. \u0414\u0435\u043d\u044c 1',\n                    'ext': 'mp4',\n                }\n            }],\n            'params': {\n                # m3u8 download\n                'skip_download': True,\n            },\n        },\n        # Myvi.ru embed\n        {\n            'url': 'http://www.kinomyvi.tv/news/detail/Pervij-dublirovannij-trejler--Uzhastikov-_nOw1',\n            'info_dict': {\n                'id': 'f4dafcad-ff21-423d-89b5-146cfd89fa1e',\n                'ext': 'mp4',\n                'title': '\u0423\u0436\u0430\u0441\u0442\u0438\u043a\u0438, \u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u0442\u0440\u0435\u0439\u043b\u0435\u0440 (2015)',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 153,\n            }\n        },\n        # XHamster embed\n        {\n            'url': 'http://www.numisc.com/forum/showthread.php?11696-FM15-which-pumiscer-was-this-%28-vid-%29-%28-alfa-as-fuck-srx-%29&s=711f5db534502e22260dec8c5e2d66d8',\n            'info_dict': {\n                'id': 'showthread',\n                'title': '[NSFL] [FM15] which pumiscer was this ( vid ) ( alfa as fuck srx )',\n            },\n            'playlist_mincount': 7,\n            # This forum does not allow <iframe> syntaxes anymore\n            # Now HTML tags are displayed as-is\n            'skip': 'No videos on this page',\n        },\n        # Embedded TED video\n        {\n            'url': 'http://en.support.wordpress.com/videos/ted-talks/',\n            'md5': '65fdff94098e4a607385a60c5177c638',\n            'info_dict': {\n                'id': '1969',\n                'ext': 'mp4',\n                'title': 'Hidden miracles of the natural world',\n                'uploader': 'Louie Schwartzberg',\n                'description': 'md5:8145d19d320ff3e52f28401f4c4283b9',\n            }\n        },\n        # nowvideo embed hidden behind percent encoding\n        {\n            'url': 'http://www.waoanime.tv/the-super-dimension-fortress-macross-episode-1/',\n            'md5': '2baf4ddd70f697d94b1c18cf796d5107',\n            'info_dict': {\n                'id': '06e53103ca9aa',\n                'ext': 'flv',\n                'title': 'Macross Episode 001  Watch Macross Episode 001 onl',\n                'description': 'No description',\n            },\n        },\n        # arte embed\n        {\n            'url': 'http://www.tv-replay.fr/redirection/20-03-14/x-enius-arte-10753389.html',\n            'md5': '7653032cbb25bf6c80d80f217055fa43',\n            'info_dict': {\n                'id': '048195-004_PLUS7-F',\n                'ext': 'flv',\n                'title': 'X:enius',\n                'description': 'md5:d5fdf32ef6613cdbfd516ae658abf168',\n                'upload_date': '20140320',\n            },\n            'params': {\n                'skip_download': 'Requires rtmpdump'\n            },\n            'skip': 'video gone',\n        },\n        # francetv embed\n        {\n            'url': 'http://www.tsprod.com/replay-du-concert-alcaline-de-calogero',\n            'info_dict': {\n                'id': 'EV_30231',\n                'ext': 'mp4',\n                'title': 'Alcaline, le concert avec Calogero',\n                'description': 'md5:61f08036dcc8f47e9cfc33aed08ffaff',\n                'upload_date': '20150226',\n                'timestamp': 1424989860,\n                'duration': 5400,\n            },\n            'params': {\n                # m3u8 downloads\n                'skip_download': True,\n            },\n            'expected_warnings': [\n                'Forbidden'\n            ]\n        },\n        # Cond\u00e9 Nast embed\n        {\n            'url': 'http://www.wired.com/2014/04/honda-asimo/',\n            'md5': 'ba0dfe966fa007657bd1443ee672db0f',\n            'info_dict': {\n                'id': '53501be369702d3275860000',\n                'ext': 'mp4',\n                'title': 'Honda\u2019s  New Asimo Robot Is More Human Than Ever',\n            }\n        },\n        # Dailymotion embed\n        {\n            'url': 'http://www.spi0n.com/zap-spi0n-com-n216/',\n            'md5': '441aeeb82eb72c422c7f14ec533999cd',\n            'info_dict': {\n                'id': 'k2mm4bCdJ6CQ2i7c8o2',\n                'ext': 'mp4',\n                'title': 'Le Zap de Spi0n n\u00b0216 - Zapping du Web',\n                'description': 'md5:faf028e48a461b8b7fad38f1e104b119',\n                'uploader': 'Spi0n',\n                'uploader_id': 'xgditw',\n                'upload_date': '20140425',\n                'timestamp': 1398441542,\n            },\n            'add_ie': ['Dailymotion'],\n        },\n        # DailyMail embed\n        {\n            'url': 'http://www.bumm.sk/krimi/2017/07/05/biztonsagi-kamera-buktatta-le-az-agg-ferfit-utlegelo-apolot',\n            'info_dict': {\n                'id': '1495629',\n                'ext': 'mp4',\n                'title': 'Care worker punches elderly dementia patient in head 11 times',\n                'description': 'md5:3a743dee84e57e48ec68bf67113199a5',\n            },\n            'add_ie': ['DailyMail'],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # YouTube embed\n        {\n            'url': 'http://www.badzine.de/ansicht/datum/2014/06/09/so-funktioniert-die-neue-englische-badminton-liga.html',\n            'info_dict': {\n                'id': 'FXRb4ykk4S0',\n                'ext': 'mp4',\n                'title': 'The NBL Auction 2014',\n                'uploader': 'BADMINTON England',\n                'uploader_id': 'BADMINTONEvents',\n                'upload_date': '20140603',\n                'description': 'md5:9ef128a69f1e262a700ed83edb163a73',\n            },\n            'add_ie': ['Youtube'],\n            'params': {\n                'skip_download': True,\n            }\n        },\n        # MTVServices embed\n        {\n            'url': 'http://www.vulture.com/2016/06/new-key-peele-sketches-released.html',\n            'md5': 'ca1aef97695ef2c1d6973256a57e5252',\n            'info_dict': {\n                'id': '769f7ec0-0692-4d62-9b45-0d88074bffc1',\n                'ext': 'mp4',\n                'title': 'Key and Peele|October 10, 2012|2|203|Liam Neesons - Uncensored',\n                'description': 'Two valets share their love for movie star Liam Neesons.',\n                'timestamp': 1349922600,\n                'upload_date': '20121011',\n            },\n        },\n        # YouTube embed via <data-embed-url=\"\">\n        {\n            'url': 'https://play.google.com/store/apps/details?id=com.gameloft.android.ANMP.GloftA8HM',\n            'info_dict': {\n                'id': '4vAffPZIT44',\n                'ext': 'mp4',\n                'title': 'Asphalt 8: Airborne - Update - Welcome to Dubai!',\n                'uploader': 'Gameloft',\n                'uploader_id': 'gameloft',\n                'upload_date': '20140828',\n                'description': 'md5:c80da9ed3d83ae6d1876c834de03e1c4',\n            },\n            'params': {\n                'skip_download': True,\n            }\n        },\n        # Flowplayer\n        {\n            'url': 'http://www.handjobhub.com/video/busty-blonde-siri-tit-fuck-while-wank-6313.html',\n            'md5': '9d65602bf31c6e20014319c7d07fba27',\n            'info_dict': {\n                'id': '5123ea6d5e5a7',\n                'ext': 'mp4',\n                'age_limit': 18,\n                'uploader': 'www.handjobhub.com',\n                'title': 'Busty Blonde Siri Tit Fuck While Wank at HandjobHub.com',\n            }\n        },\n        # MLB embed\n        {\n            'url': 'http://umpire-empire.com/index.php/topic/58125-laz-decides-no-thats-low/',\n            'md5': '96f09a37e44da40dd083e12d9a683327',\n            'info_dict': {\n                'id': '33322633',\n                'ext': 'mp4',\n                'title': 'Ump changes call to ball',\n                'description': 'md5:71c11215384298a172a6dcb4c2e20685',\n                'duration': 48,\n                'timestamp': 1401537900,\n                'upload_date': '20140531',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n            },\n        },\n        # Wistia standard embed (async)\n        {\n            'url': 'https://www.getdrip.com/university/brennan-dunn-drip-workshop/',\n            'info_dict': {\n                'id': '807fafadvk',\n                'ext': 'mp4',\n                'title': 'Drip Brennan Dunn Workshop',\n                'description': 'a JV Webinars video from getdrip-1',\n                'duration': 4986.95,\n                'timestamp': 1463607249,\n                'upload_date': '20160518',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'webpage 404 not found',\n        },\n        # Soundcloud embed\n        {\n            'url': 'http://nakedsecurity.sophos.com/2014/10/29/sscc-171-are-you-sure-that-1234-is-a-bad-password-podcast/',\n            'info_dict': {\n                'id': '174391317',\n                'ext': 'mp3',\n                'description': 'md5:ff867d6b555488ad3c52572bb33d432c',\n                'uploader': 'Sophos Security',\n                'title': 'Chet Chat 171 - Oct 29, 2014',\n                'upload_date': '20141029',\n            }\n        },\n        # Soundcloud multiple embeds\n        {\n            'url': 'http://www.guitarplayer.com/lessons/1014/legato-workout-one-hour-to-more-fluid-performance---tab/52809',\n            'info_dict': {\n                'id': '52809',\n                'title': 'Guitar Essentials: Legato Workout\u2014One-Hour to Fluid Performance  | TAB + AUDIO',\n            },\n            'playlist_mincount': 7,\n        },\n        # TuneIn station embed\n        {\n            'url': 'http://radiocnrv.com/promouvoir-radio-cnrv/',\n            'info_dict': {\n                'id': '204146',\n                'ext': 'mp3',\n                'title': 'CNRV',\n                'location': 'Paris, France',\n                'is_live': True,\n            },\n            'params': {\n                # Live stream\n                'skip_download': True,\n            },\n        },\n        # Livestream embed\n        {\n            'url': 'http://www.esa.int/Our_Activities/Space_Science/Rosetta/Philae_comet_touch-down_webcast',\n            'info_dict': {\n                'id': '67864563',\n                'ext': 'flv',\n                'upload_date': '20141112',\n                'title': 'Rosetta #CometLanding webcast HL 10',\n            }\n        },\n        # Another Livestream embed, without 'new.' in URL\n        {\n            'url': 'https://www.freespeech.org/',\n            'info_dict': {\n                'id': '123537347',\n                'ext': 'mp4',\n                'title': 're:^FSTV [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',\n            },\n            'params': {\n                # Live stream\n                'skip_download': True,\n            },\n        },\n        # LazyYT\n        {\n            'url': 'https://skiplagged.com/',\n            'info_dict': {\n                'id': 'skiplagged',\n                'title': 'Skiplagged: The smart way to find cheap flights',\n            },\n            'playlist_mincount': 1,\n            'add_ie': ['Youtube'],\n        },\n        # Cinchcast embed\n        {\n            'url': 'http://undergroundwellness.com/podcasts/306-5-steps-to-permanent-gut-healing/',\n            'info_dict': {\n                'id': '7141703',\n                'ext': 'mp3',\n                'upload_date': '20141126',\n                'title': 'Jack Tips: 5 Steps to Permanent Gut Healing',\n            }\n        },\n        # Cinerama player\n        {\n            'url': 'http://www.abc.net.au/7.30/content/2015/s4164797.htm',\n            'info_dict': {\n                'id': '730m_DandD_1901_512k',\n                'ext': 'mp4',\n                'uploader': 'www.abc.net.au',\n                'title': 'Game of Thrones with dice - Dungeons and Dragons fantasy role-playing game gets new life - 19/01/2015',\n            }\n        },\n        # embedded viddler video\n        {\n            'url': 'http://deadspin.com/i-cant-stop-watching-john-wall-chop-the-nuggets-with-th-1681801597',\n            'info_dict': {\n                'id': '4d03aad9',\n                'ext': 'mp4',\n                'uploader': 'deadspin',\n                'title': 'WALL-TO-GORTAT',\n                'timestamp': 1422285291,\n                'upload_date': '20150126',\n            },\n            'add_ie': ['Viddler'],\n        },\n        # Libsyn embed\n        {\n            'url': 'http://thedailyshow.cc.com/podcast/episodetwelve',\n            'info_dict': {\n                'id': '3377616',\n                'ext': 'mp3',\n                'title': \"The Daily Show Podcast without Jon Stewart - Episode 12: Bassem Youssef: Egypt's Jon Stewart\",\n                'description': 'md5:601cb790edd05908957dae8aaa866465',\n                'upload_date': '20150220',\n            },\n            'skip': 'All The Daily Show URLs now redirect to http://www.cc.com/shows/',\n        },\n        # jwplayer YouTube\n        {\n            'url': 'http://media.nationalarchives.gov.uk/index.php/webinar-using-discovery-national-archives-online-catalogue/',\n            'info_dict': {\n                'id': 'Mrj4DVp2zeA',\n                'ext': 'mp4',\n                'upload_date': '20150212',\n                'uploader': 'The National Archives UK',\n                'description': 'md5:8078af856dca76edc42910b61273dbbf',\n                'uploader_id': 'NationalArchives08',\n                'title': 'Webinar: Using Discovery, The National Archives\u2019 online catalogue',\n            },\n        },\n        # jwplayer rtmp\n        {\n            'url': 'http://www.suffolk.edu/sjc/live.php',\n            'info_dict': {\n                'id': 'live',\n                'ext': 'flv',\n                'title': 'Massachusetts Supreme Judicial Court Oral Arguments',\n                'uploader': 'www.suffolk.edu',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'Only has video a few mornings per month, see http://www.suffolk.edu/sjc/',\n        },\n        # jwplayer with only the json URL\n        {\n            'url': 'https://www.hollywoodreporter.com/news/general-news/dunkirk-team-reveals-what-christopher-nolan-said-oscar-win-meet-your-oscar-winner-1092454',\n            'info_dict': {\n                'id': 'TljWkvWH',\n                'ext': 'mp4',\n                'upload_date': '20180306',\n                'title': 'md5:91eb1862f6526415214f62c00b453936',\n                'description': 'md5:73048ae50ae953da10549d1d2fe9b3aa',\n                'timestamp': 1520367225,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # Complex jwplayer\n        {\n            'url': 'http://www.indiedb.com/games/king-machine/videos',\n            'info_dict': {\n                'id': 'videos',\n                'ext': 'mp4',\n                'title': 'king machine trailer 1',\n                'description': 'Browse King Machine videos & audio for sweet media. Your eyes will thank you.',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n            },\n        },\n        {\n            # Youtube embed, formerly: Video.js embed, multiple formats\n            'url': 'http://ortcam.com/solidworks-\u0443\u0440\u043e\u043a-6-\u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430-\u0447\u0435\u0440\u0442\u0435\u0436\u0430_33f9b7351.html',\n            'info_dict': {\n                'id': 'yygqldloqIk',\n                'ext': 'mp4',\n                'title': 'SolidWorks. \u0423\u0440\u043e\u043a 6 \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u0447\u0435\u0440\u0442\u0435\u0436\u0430',\n                'description': 'md5:baf95267792646afdbf030e4d06b2ab3',\n                'upload_date': '20130314',\n                'uploader': 'PRO\u0441\u0442\u043e\u04353D',\n                'uploader_id': 'PROstoe3D',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # Video.js embed, single format\n            'url': 'https://www.vooplayer.com/v3/watch/watch.php?v=NzgwNTg=',\n            'info_dict': {\n                'id': 'watch',\n                'ext': 'mp4',\n                'title': 'Step 1 -  Good Foundation',\n                'description': 'md5:d1e7ff33a29fc3eb1673d6c270d344f4',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': '404 Not Found',\n        },\n        # rtl.nl embed\n        {\n            'url': 'http://www.rtlnieuws.nl/nieuws/buitenland/aanslagen-kopenhagen',\n            'playlist_mincount': 5,\n            'info_dict': {\n                'id': 'aanslagen-kopenhagen',\n                'title': 'Aanslagen Kopenhagen',\n            }\n        },\n        # Zapiks embed\n        {\n            'url': 'http://www.skipass.com/news/116090-bon-appetit-s5ep3-baqueira-mi-cor.html',\n            'info_dict': {\n                'id': '118046',\n                'ext': 'mp4',\n                'title': 'EP3S5 - Bon App\u00e9tit - Baqueira Mi Corazon !',\n            }\n        },\n        # Kaltura embed (different embed code)\n        {\n            'url': 'http://www.premierchristianradio.com/Shows/Saturday/Unbelievable/Conference-Videos/Os-Guinness-Is-It-Fools-Talk-Unbelievable-Conference-2014',\n            'info_dict': {\n                'id': '1_a52wc67y',\n                'ext': 'flv',\n                'upload_date': '20150127',\n                'uploader_id': 'PremierMedia',\n                'timestamp': int,\n                'title': 'Os Guinness // Is It Fools Talk? // Unbelievable? Conference 2014',\n            },\n        },\n        # Kaltura embed with single quotes\n        {\n            'url': 'http://fod.infobase.com/p_ViewPlaylist.aspx?AssignmentID=NUN8ZY',\n            'info_dict': {\n                'id': '0_izeg5utt',\n                'ext': 'mp4',\n                'title': '35871',\n                'timestamp': 1355743100,\n                'upload_date': '20121217',\n                'uploader_id': 'cplapp@learn360.com',\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # Kaltura embedded via quoted entry_id\n            'url': 'https://www.oreilly.com/ideas/my-cloud-makes-pretty-pictures',\n            'info_dict': {\n                'id': '0_utuok90b',\n                'ext': 'mp4',\n                'title': '06_matthew_brender_raj_dutt',\n                'timestamp': 1466638791,\n                'upload_date': '20160622',\n            },\n            'add_ie': ['Kaltura'],\n            'expected_warnings': [\n                'Could not send HEAD request'\n            ],\n            'params': {\n                'skip_download': True,\n            }\n        },\n        {\n            # Kaltura embedded, some fileExt broken (#11480)\n            'url': 'http://www.cornell.edu/video/nima-arkani-hamed-standard-models-of-particle-physics',\n            'info_dict': {\n                'id': '1_sgtvehim',\n                'ext': 'mp4',\n                'title': 'Our \"Standard Models\" of particle physics and cosmology',\n                'description': 'md5:67ea74807b8c4fea92a6f38d6d323861',\n                'timestamp': 1321158993,\n                'upload_date': '20111113',\n                'uploader_id': 'kps1',\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # Kaltura iframe embed\n            'url': 'http://www.gsd.harvard.edu/event/i-m-pei-a-centennial-celebration/',\n            'md5': 'ae5ace8eb09dc1a35d03b579a9c2cc44',\n            'info_dict': {\n                'id': '0_f2cfbpwy',\n                'ext': 'mp4',\n                'title': 'I. M. Pei: A Centennial Celebration',\n                'description': 'md5:1db8f40c69edc46ca180ba30c567f37c',\n                'upload_date': '20170403',\n                'uploader_id': 'batchUser',\n                'timestamp': 1491232186,\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # Kaltura iframe embed, more sophisticated\n            'url': 'http://www.cns.nyu.edu/~eero/math-tools/Videos/lecture-05sep2017.html',\n            'info_dict': {\n                'id': '1_9gzouybz',\n                'ext': 'mp4',\n                'title': 'lecture-05sep2017',\n                'description': 'md5:40f347d91fd4ba047e511c5321064b49',\n                'upload_date': '20170913',\n                'uploader_id': 'eps2',\n                'timestamp': 1505340777,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # meta twitter:player\n            'url': 'http://thechive.com/2017/12/08/all-i-want-for-christmas-is-more-twerk/',\n            'info_dict': {\n                'id': '0_01b42zps',\n                'ext': 'mp4',\n                'title': 'Main Twerk (Video)',\n                'upload_date': '20171208',\n                'uploader_id': 'sebastian.salinas@thechive.com',\n                'timestamp': 1512713057,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Kaltura'],\n        },\n        # referrer protected EaglePlatform embed\n        {\n            'url': 'https://tvrain.ru/lite/teleshow/kak_vse_nachinalos/namin-418921/',\n            'info_dict': {\n                'id': '582306',\n                'ext': 'mp4',\n                'title': '\u0421\u0442\u0430\u0441 \u041d\u0430\u043c\u0438\u043d: \u00ab\u041c\u044b \u043d\u0430\u0440\u0443\u0448\u0438\u043b\u0438 \u0434\u0435\u0432\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u041a\u0440\u0435\u043c\u043b\u044f\u00bb',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 3382,\n                'view_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # ClipYou (EaglePlatform) embed (custom URL)\n        {\n            'url': 'http://muz-tv.ru/play/7129/',\n            # Not checking MD5 as sometimes the direct HTTP link results in 404 and HLS is used\n            'info_dict': {\n                'id': '12820',\n                'ext': 'mp4',\n                'title': \"'O Sole Mio\",\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 216,\n                'view_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'This video is unavailable.',\n        },\n        # Pladform embed\n        {\n            'url': 'http://muz-tv.ru/kinozal/view/7400/',\n            'info_dict': {\n                'id': '100183293',\n                'ext': 'mp4',\n                'title': '\u0422\u0430\u0439\u043d\u044b \u043f\u0435\u0440\u0435\u0432\u0430\u043b\u0430 \u0414\u044f\u0442\u043b\u043e\u0432\u0430 \u2022 1 \u0441\u0435\u0440\u0438\u044f 2 \u0447\u0430\u0441\u0442\u044c',\n                'description': '\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0435\u0440\u0438\u0430\u043b-\u0440\u0430\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0435 \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u0441\u0430\u043c\u044b\u0445 \u0436\u0443\u0442\u043a\u0438\u0445 \u0442\u0430\u0439\u043d \u0425\u0425 \u0432\u0435\u043a\u0430',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 694,\n                'age_limit': 0,\n            },\n            'skip': 'HTTP Error 404: Not Found',\n        },\n        # Playwire embed\n        {\n            'url': 'http://www.cinemablend.com/new/First-Joe-Dirt-2-Trailer-Teaser-Stupid-Greatness-70874.html',\n            'info_dict': {\n                'id': '3519514',\n                'ext': 'mp4',\n                'title': 'Joe Dirt 2 Beautiful Loser Teaser Trailer',\n                'thumbnail': r're:^https?://.*\\.png$',\n                'duration': 45.115,\n            },\n        },\n        # Crooks and Liars embed\n        {\n            'url': 'http://crooksandliars.com/2015/04/fox-friends-says-protecting-atheists',\n            'info_dict': {\n                'id': '8RUoRhRi',\n                'ext': 'mp4',\n                'title': \"Fox & Friends Says Protecting Atheists From Discrimination Is Anti-Christian!\",\n                'description': 'md5:e1a46ad1650e3a5ec7196d432799127f',\n                'timestamp': 1428207000,\n                'upload_date': '20150405',\n                'uploader': 'Heather',\n            },\n        },\n        # Crooks and Liars external embed\n        {\n            'url': 'http://theothermccain.com/2010/02/02/video-proves-that-bill-kristol-has-been-watching-glenn-beck/comment-page-1/',\n            'info_dict': {\n                'id': 'MTE3MjUtMzQ2MzA',\n                'ext': 'mp4',\n                'title': 'md5:5e3662a81a4014d24c250d76d41a08d5',\n                'description': 'md5:9b8e9542d6c3c5de42d6451b7d780cec',\n                'timestamp': 1265032391,\n                'upload_date': '20100201',\n                'uploader': 'Heather',\n            },\n        },\n        # NBC Sports vplayer embed\n        {\n            'url': 'http://www.riderfans.com/forum/showthread.php?121827-Freeman&s=e98fa1ea6dc08e886b1678d35212494a',\n            'info_dict': {\n                'id': 'ln7x1qSThw4k',\n                'ext': 'flv',\n                'title': \"PFT Live: New leader in the 'new-look' defense\",\n                'description': 'md5:65a19b4bbfb3b0c0c5768bed1dfad74e',\n                'uploader': 'NBCU-SPORTS',\n                'upload_date': '20140107',\n                'timestamp': 1389118457,\n            },\n            'skip': 'Invalid Page URL',\n        },\n        # NBC News embed\n        {\n            'url': 'http://www.vulture.com/2016/06/letterman-couldnt-care-less-about-late-night.html',\n            'md5': '1aa589c675898ae6d37a17913cf68d66',\n            'info_dict': {\n                'id': 'x_dtl_oa_LettermanliftPR_160608',\n                'ext': 'mp4',\n                'title': 'David Letterman: A Preview',\n                'description': 'A preview of Tom Brokaw\\'s interview with David Letterman as part of the On Assignment series powered by Dateline. Airs Sunday June 12 at 7/6c.',\n                'upload_date': '20160609',\n                'timestamp': 1465431544,\n                'uploader': 'NBCU-NEWS',\n            },\n        },\n        # UDN embed\n        {\n            'url': 'https://video.udn.com/news/300346',\n            'md5': 'fd2060e988c326991037b9aff9df21a6',\n            'info_dict': {\n                'id': '300346',\n                'ext': 'mp4',\n                'title': '\u4e2d\u4e00\u4e2d\u7537\u5e2b\u8b8a\u6027 \u5168\u6821\u5e2b\u751f\u529b\u633a',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n            },\n            'params': {\n                # m3u8 download\n                'skip_download': True,\n            },\n            'expected_warnings': ['Failed to parse JSON Expecting value'],\n        },\n        # Kinja embed\n        {\n            'url': 'http://www.clickhole.com/video/dont-understand-bitcoin-man-will-mumble-explanatio-2537',\n            'info_dict': {\n                'id': '106351',\n                'ext': 'mp4',\n                'title': 'Don\u2019t Understand Bitcoin? This Man Will Mumble An Explanation At You',\n                'description': 'Migrated from OnionStudios',\n                'thumbnail': r're:^https?://.*\\.jpe?g$',\n                'uploader': 'clickhole',\n                'upload_date': '20150527',\n                'timestamp': 1432744860,\n            }\n        },\n        # SnagFilms embed\n        {\n            'url': 'http://whilewewatch.blogspot.ru/2012/06/whilewewatch-whilewewatch-gripping.html',\n            'info_dict': {\n                'id': '74849a00-85a9-11e1-9660-123139220831',\n                'ext': 'mp4',\n                'title': '#whilewewatch',\n            }\n        },\n        # AdobeTVVideo embed\n        {\n            'url': 'https://helpx.adobe.com/acrobat/how-to/new-experience-acrobat-dc.html?set=acrobat--get-started--essential-beginners',\n            'md5': '43662b577c018ad707a63766462b1e87',\n            'info_dict': {\n                'id': '2456',\n                'ext': 'mp4',\n                'title': 'New experience with Acrobat DC',\n                'description': 'New experience with Acrobat DC',\n                'duration': 248.667,\n            },\n        },\n        # Another form of arte.tv embed\n        {\n            'url': 'http://www.tv-replay.fr/redirection/09-04-16/arte-reportage-arte-11508975.html',\n            'md5': '850bfe45417ddf221288c88a0cffe2e2',\n            'info_dict': {\n                'id': '030273-562_PLUS7-F',\n                'ext': 'mp4',\n                'title': 'ARTE Reportage - Nulle part, en France',\n                'description': 'md5:e3a0e8868ed7303ed509b9e3af2b870d',\n                'upload_date': '20160409',\n            },\n        },\n        # Duplicated embedded video URLs\n        {\n            'url': 'http://www.hudl.com/athlete/2538180/highlights/149298443',\n            'info_dict': {\n                'id': '149298443_480_16c25b74_2',\n                'ext': 'mp4',\n                'title': 'vs. Blue Orange Spring Game',\n                'uploader': 'www.hudl.com',\n            },\n        },\n        # twitter:player:stream embed\n        {\n            'url': 'http://www.rtl.be/info/video/589263.aspx?CategoryID=288',\n            'info_dict': {\n                'id': 'master',\n                'ext': 'mp4',\n                'title': 'Une nouvelle esp\u00e8ce de dinosaure d\u00e9couverte en Argentine',\n                'uploader': 'www.rtl.be',\n            },\n            'params': {\n                # m3u8 downloads\n                'skip_download': True,\n            },\n        },\n        # twitter:player embed\n        {\n            'url': 'http://www.theatlantic.com/video/index/484130/what-do-black-holes-sound-like/',\n            'md5': 'a3e0df96369831de324f0778e126653c',\n            'info_dict': {\n                'id': '4909620399001',\n                'ext': 'mp4',\n                'title': 'What Do Black Holes Sound Like?',\n                'description': 'what do black holes sound like',\n                'upload_date': '20160524',\n                'uploader_id': '29913724001',\n                'timestamp': 1464107587,\n                'uploader': 'TheAtlantic',\n            },\n            'skip': 'Private Youtube video',\n        },\n        # Facebook <iframe> embed\n        {\n            'url': 'https://www.hostblogger.de/blog/archives/6181-Auto-jagt-Betonmischer.html',\n            'md5': 'fbcde74f534176ecb015849146dd3aee',\n            'info_dict': {\n                'id': '599637780109885',\n                'ext': 'mp4',\n                'title': 'Facebook video #599637780109885',\n            },\n        },\n        # Facebook <iframe> embed, plugin video\n        {\n            'url': 'http://5pillarsuk.com/2017/06/07/tariq-ramadan-disagrees-with-pr-exercise-by-imams-refusing-funeral-prayers-for-london-attackers/',\n            'info_dict': {\n                'id': '1754168231264132',\n                'ext': 'mp4',\n                'title': 'About the Imams and Religious leaders refusing to perform funeral prayers for...',\n                'uploader': 'Tariq Ramadan (official)',\n                'timestamp': 1496758379,\n                'upload_date': '20170606',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # Facebook API embed\n        {\n            'url': 'http://www.lothype.com/blue-stars-2016-preview-standstill-full-show/',\n            'md5': 'a47372ee61b39a7b90287094d447d94e',\n            'info_dict': {\n                'id': '10153467542406923',\n                'ext': 'mp4',\n                'title': 'Facebook video #10153467542406923',\n            },\n        },\n        # Wordpress \"YouTube Video Importer\" plugin\n        {\n            'url': 'http://www.lothype.com/blue-devils-drumline-stanford-lot-2016/',\n            'md5': 'd16797741b560b485194eddda8121b48',\n            'info_dict': {\n                'id': 'HNTXWDXV9Is',\n                'ext': 'mp4',\n                'title': 'Blue Devils Drumline Stanford lot 2016',\n                'upload_date': '20160627',\n                'uploader_id': 'GENOCIDE8GENERAL10',\n                'uploader': 'cylus cyrus',\n            },\n        },\n        {\n            # video stored on custom kaltura server\n            'url': 'http://www.expansion.com/multimedia/videos.html?media=EQcM30NHIPv',\n            'md5': '537617d06e64dfed891fa1593c4b30cc',\n            'info_dict': {\n                'id': '0_1iotm5bh',\n                'ext': 'mp4',\n                'title': 'Elecciones brit\u00e1nicas: 5 lecciones para Rajoy',\n                'description': 'md5:435a89d68b9760b92ce67ed227055f16',\n                'uploader_id': 'videos.expansion@el-mundo.net',\n                'upload_date': '20150429',\n                'timestamp': 1430303472,\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # multiple kaltura embeds, nsfw\n            'url': 'https://www.quartier-rouge.be/prive/femmes/kamila-avec-video-jaime-sadomie.html',\n            'info_dict': {\n                'id': 'kamila-avec-video-jaime-sadomie',\n                'title': \"Kamila avec v\u00eddeo \u201cJ'aime sadomie\u201d\",\n            },\n            'playlist_count': 8,\n        },\n        {\n            # Non-standard Vimeo embed\n            'url': 'https://openclassrooms.com/courses/understanding-the-web',\n            'md5': '64d86f1c7d369afd9a78b38cbb88d80a',\n            'info_dict': {\n                'id': '148867247',\n                'ext': 'mp4',\n                'title': 'Understanding the web - Teaser',\n                'description': 'This is \"Understanding the web - Teaser\" by openclassrooms on Vimeo, the home for high quality videos and the people who love them.',\n                'upload_date': '20151214',\n                'uploader': 'OpenClassrooms',\n                'uploader_id': 'openclassrooms',\n            },\n            'add_ie': ['Vimeo'],\n        },\n        {\n            # generic vimeo embed that requires original URL passed as Referer\n            'url': 'http://racing4everyone.eu/2016/07/30/formula-1-2016-round12-germany/',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://support.arkena.com/display/PLAY/Ways+to+embed+your+video',\n            'md5': 'b96f2f71b359a8ecd05ce4e1daa72365',\n            'info_dict': {\n                'id': 'b41dda37-d8e7-4d3f-b1b5-9a9db578bdfe',\n                'ext': 'mp4',\n                'title': 'Big Buck Bunny',\n                'description': 'Royalty free test video',\n                'timestamp': 1432816365,\n                'upload_date': '20150528',\n                'is_live': False,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Arkena'],\n        },\n        {\n            'url': 'http://nova.bg/news/view/2016/08/16/156543/%D0%BD%D0%B0-%D0%BA%D0%BE%D1%81%D1%8A%D0%BC-%D0%BE%D1%82-%D0%B2%D0%B7%D1%80%D0%B8%D0%B2-%D0%BE%D1%82%D1%86%D0%B5%D0%BF%D0%B8%D1%85%D0%B0-%D1%86%D1%8F%D0%BB-%D0%BA%D0%B2%D0%B0%D1%80%D1%82%D0%B0%D0%BB-%D0%B7%D0%B0%D1%80%D0%B0%D0%B4%D0%B8-%D0%B8%D0%B7%D1%82%D0%B8%D1%87%D0%B0%D0%BD%D0%B5-%D0%BD%D0%B0-%D0%B3%D0%B0%D0%B7-%D0%B2-%D0%BF%D0%BB%D0%BE%D0%B2%D0%B4%D0%B8%D0%B2/',\n            'info_dict': {\n                'id': '1c7141f46c',\n                'ext': 'mp4',\n                'title': '\u041d\u0410 \u041a\u041e\u0421\u042a\u041c \u041e\u0422 \u0412\u0417\u0420\u0418\u0412: \u0418\u0437\u0442\u0438\u0447\u0430\u043d\u0435 \u043d\u0430 \u0433\u0430\u0437 \u043d\u0430 \u0431\u0435\u043d\u0437\u0438\u043d\u043e\u0441\u0442\u0430\u043d\u0446\u0438\u044f \u0432 \u041f\u043b\u043e\u0432\u0434\u0438\u0432',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Vbox7'],\n        },\n        {\n            # DBTV embeds\n            'url': 'http://www.dagbladet.no/2016/02/23/nyheter/nordlys/ski/troms/ver/43254897/',\n            'info_dict': {\n                'id': '43254897',\n                'title': 'Etter ett \u00e5rs planlegging, klaffet endelig alt: - Jeg m\u00e5tte ta en liten dans',\n            },\n            'playlist_mincount': 3,\n        },\n        {\n            # Videa embeds\n            'url': 'http://forum.dvdtalk.com/movie-talk/623756-deleted-magic-star-wars-ot-deleted-alt-scenes-docu-style.html',\n            'info_dict': {\n                'id': '623756-deleted-magic-star-wars-ot-deleted-alt-scenes-docu-style',\n                'title': 'Deleted Magic - Star Wars: OT Deleted / Alt. Scenes Docu. Style - DVD Talk Forum',\n            },\n            'playlist_mincount': 2,\n        },\n        {\n            # 20 minuten embed\n            'url': 'http://www.20min.ch/schweiz/news/story/So-kommen-Sie-bei-Eis-und-Schnee-sicher-an-27032552',\n            'info_dict': {\n                'id': '523629',\n                'ext': 'mp4',\n                'title': 'So kommen Sie bei Eis und Schnee sicher an',\n                'description': 'md5:117c212f64b25e3d95747e5276863f7d',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['TwentyMinuten'],\n        },\n        {\n            # VideoPress embed\n            'url': 'https://en.support.wordpress.com/videopress/',\n            'info_dict': {\n                'id': 'OcobLTqC',\n                'ext': 'm4v',\n                'title': 'IMG_5786',\n                'timestamp': 1435711927,\n                'upload_date': '20150701',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['VideoPress'],\n        },\n        {\n            # Rutube embed\n            'url': 'http://magazzino.friday.ru/videos/vipuski/kazan-2',\n            'info_dict': {\n                'id': '9b3d5bee0a8740bf70dfd29d3ea43541',\n                'ext': 'flv',\n                'title': '\u041c\u0430\u0433\u0430\u0437\u0437\u0438\u043d\u043e: \u041a\u0430\u0437\u0430\u043d\u044c 2',\n                'description': 'md5:99bccdfac2269f0e8fdbc4bbc9db184a',\n                'uploader': '\u041c\u0430\u0433\u0430\u0437\u0437\u0438\u043d\u043e',\n                'upload_date': '20170228',\n                'uploader_id': '996642',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Rutube'],\n        },\n        {\n            # glomex:embed\n            'url': 'https://www.skai.gr/news/world/iatrikos-syllogos-tourkias-to-turkovac-aplo-dialyma-erntogan-eiste-apateones-kai-pseytes',\n            'info_dict': {\n                'id': 'v-ch2nkhcirwc9-sf',\n                'ext': 'mp4',\n                'title': 'md5:786e1e24e06c55993cee965ef853a0c1',\n                'description': 'md5:8b517a61d577efe7e36fde72fd535995',\n                'timestamp': 1641885019,\n                'upload_date': '20220111',\n                'duration': 460000,\n                'thumbnail': 'https://i3thumbs.glomex.com/dC1idjJwdndiMjRzeGwvMjAyMi8wMS8xMS8wNy8xMF8zNV82MWRkMmQ2YmU5ZTgyLmpwZw==/profile:player-960x540',\n            },\n        },\n        {\n            # megatvcom:embed\n            'url': 'https://www.in.gr/2021/12/18/greece/apokalypsi-mega-poios-parelave-tin-ereyna-tsiodra-ek-merous-tis-kyvernisis-o-prothypourgos-telika-gnorize/',\n            'info_dict': {\n                'id': 'apokalypsi-mega-poios-parelave-tin-ereyna-tsiodra-ek-merous-tis-kyvernisis-o-prothypourgos-telika-gnorize',\n                'title': 'md5:5e569cf996ec111057c2764ec272848f',\n            },\n            'playlist': [{\n                'md5': '1afa26064ff00ccb91617957dbc73dc1',\n                'info_dict': {\n                    'ext': 'mp4',\n                    'id': '564916',\n                    'display_id': 'md5:6cdf22d3a2e7bacb274b7295089a1770',\n                    'title': 'md5:33b9dd39584685b62873043670eb52a6',\n                    'description': 'md5:c1db7310f390518ac36dd69d947ef1a1',\n                    'timestamp': 1639753145,\n                    'upload_date': '20211217',\n                    'thumbnail': 'https://www.megatv.com/wp-content/uploads/2021/12/prezerakos-1024x597.jpg',\n                },\n            }, {\n                'md5': '4a1c220695f1ef865a8b7966a53e2474',\n                'info_dict': {\n                    'ext': 'mp4',\n                    'id': '564905',\n                    'display_id': 'md5:ead15695e485e649aed2b81ebd699b88',\n                    'title': 'md5:2b71fd54249a3ca34609fe39ae31c47b',\n                    'description': 'md5:c42e12f638d0a97d6de4508e2c4df982',\n                    'timestamp': 1639753047,\n                    'upload_date': '20211217',\n                    'thumbnail': 'https://www.megatv.com/wp-content/uploads/2021/12/tsiodras-mitsotakis-1024x545.jpg',\n                },\n            }]\n        },\n        {\n            'url': 'https://www.ertnews.gr/video/manolis-goyalles-o-anthropos-piso-apo-ti-diadiktyaki-vasilopita/',\n            'info_dict': {\n                'id': '2022/tv/news-themata-ianouarios/20220114-apotis6-gouales-pita.mp4',\n                'ext': 'mp4',\n                'title': 'md5:df64f5b61c06d0e9556c0cdd5cf14464',\n                'thumbnail': 'https://www.ert.gr/themata/photos/2021/20220114-apotis6-gouales-pita.jpg',\n            },\n        },\n        {\n            # ThePlatform embedded with whitespaces in URLs\n            'url': 'http://www.golfchannel.com/topics/shows/golftalkcentral.htm',\n            'only_matching': True,\n        },\n        {\n            # Senate ISVP iframe https\n            'url': 'https://www.hsgac.senate.gov/hearings/canadas-fast-track-refugee-plan-unanswered-questions-and-implications-for-us-national-security',\n            'md5': 'fb8c70b0b515e5037981a2492099aab8',\n            'info_dict': {\n                'id': 'govtaff020316',\n                'ext': 'mp4',\n                'title': 'Integrated Senate Video Player',\n            },\n            'add_ie': ['SenateISVP'],\n        },\n        {\n            # Limelight embeds (1 channel embed + 4 media embeds)\n            'url': 'http://www.sedona.com/FacilitatorTraining2017',\n            'info_dict': {\n                'id': 'FacilitatorTraining2017',\n                'title': 'Facilitator Training 2017',\n            },\n            'playlist_mincount': 5,\n        },\n        {\n            # Limelight embed (LimelightPlayerUtil.embed)\n            'url': 'https://tv5.ca/videos?v=xuu8qowr291ri',\n            'info_dict': {\n                'id': '95d035dc5c8a401588e9c0e6bd1e9c92',\n                'ext': 'mp4',\n                'title': '07448641',\n                'timestamp': 1499890639,\n                'upload_date': '20170712',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['LimelightMedia'],\n        },\n        {\n            'url': 'http://kron4.com/2017/04/28/standoff-with-walnut-creek-murder-suspect-ends-with-arrest/',\n            'info_dict': {\n                'id': 'standoff-with-walnut-creek-murder-suspect-ends-with-arrest',\n                'title': 'Standoff with Walnut Creek murder suspect ends',\n                'description': 'md5:3ccc48a60fc9441eeccfc9c469ebf788',\n            },\n            'playlist_mincount': 4,\n        },\n        {\n            # WashingtonPost embed\n            'url': 'http://www.vanityfair.com/hollywood/2017/04/donald-trump-tv-pitches',\n            'info_dict': {\n                'id': '8caf6e88-d0ec-11e5-90d3-34c2c42653ac',\n                'ext': 'mp4',\n                'title': \"No one has seen the drama series based on Trump's life \\u2014 until now\",\n                'description': 'Donald Trump wanted a weekly TV drama based on his life. It never aired. But The Washington Post recently obtained a scene from the pilot script \u2014 and enlisted actors.',\n                'timestamp': 1455216756,\n                'uploader': 'The Washington Post',\n                'upload_date': '20160211',\n            },\n            'add_ie': ['WashingtonPost'],\n        },\n        {\n            # JOJ.sk embeds\n            'url': 'https://www.noviny.sk/slovensko/238543-slovenskom-sa-prehnala-vlna-silnych-burok',\n            'info_dict': {\n                'id': '238543-slovenskom-sa-prehnala-vlna-silnych-burok',\n                'title': 'Slovenskom sa prehnala vlna siln\u00fdch b\u00farok',\n            },\n            'playlist_mincount': 5,\n            'add_ie': ['Joj'],\n        },\n        {\n            # AMP embed (see https://www.ampproject.org/docs/reference/components/amp-video)\n            'url': 'https://tvrain.ru/amp/418921/',\n            'md5': 'cc00413936695987e8de148b67d14f1d',\n            'info_dict': {\n                'id': '418921',\n                'ext': 'mp4',\n                'title': '\u0421\u0442\u0430\u0441 \u041d\u0430\u043c\u0438\u043d: \u00ab\u041c\u044b \u043d\u0430\u0440\u0443\u0448\u0438\u043b\u0438 \u0434\u0435\u0432\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u041a\u0440\u0435\u043c\u043b\u044f\u00bb',\n            },\n        },\n        {\n            # vzaar embed\n            'url': 'http://help.vzaar.com/article/165-embedding-video',\n            'md5': '7e3919d9d2620b89e3e00bec7fe8c9d4',\n            'info_dict': {\n                'id': '8707641',\n                'ext': 'mp4',\n                'title': 'Building A Business Online: Principal Chairs Q & A',\n            },\n        },\n        {\n            # multiple HTML5 videos on one page\n            'url': 'https://www.paragon-software.com/home/rk-free/keyscenarios.html',\n            'info_dict': {\n                'id': 'keyscenarios',\n                'title': 'Rescue Kit 14 Free Edition - Getting started',\n            },\n            'playlist_count': 4,\n        },\n        {\n            # vshare embed\n            'url': 'https://youtube-dl-demo.neocities.org/vshare.html',\n            'md5': '17b39f55b5497ae8b59f5fbce8e35886',\n            'info_dict': {\n                'id': '0f64ce6',\n                'title': 'vl14062007715967',\n                'ext': 'mp4',\n            }\n        },\n        {\n            'url': 'http://www.heidelberg-laureate-forum.org/blog/video/lecture-friday-september-23-2016-sir-c-antony-r-hoare/',\n            'md5': 'aecd089f55b1cb5a59032cb049d3a356',\n            'info_dict': {\n                'id': '90227f51a80c4d8f86c345a7fa62bd9a1d',\n                'ext': 'mp4',\n                'title': 'Lecture: Friday, September 23, 2016 - Sir Tony Hoare',\n                'description': 'md5:5a51db84a62def7b7054df2ade403c6c',\n                'timestamp': 1474354800,\n                'upload_date': '20160920',\n            }\n        },\n        {\n            'url': 'http://www.kidzworld.com/article/30935-trolls-the-beat-goes-on-interview-skylar-astin-and-amanda-leighton',\n            'info_dict': {\n                'id': '1731611',\n                'ext': 'mp4',\n                'title': 'Official Trailer | TROLLS: THE BEAT GOES ON!',\n                'description': 'md5:eb5f23826a027ba95277d105f248b825',\n                'timestamp': 1516100691,\n                'upload_date': '20180116',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['SpringboardPlatform'],\n        },\n        {\n            'url': 'https://www.yapfiles.ru/show/1872528/690b05d3054d2dbe1e69523aa21bb3b1.mp4.html',\n            'info_dict': {\n                'id': 'vMDE4NzI1Mjgt690b',\n                'ext': 'mp4',\n                'title': '\u041a\u043e\u0442\u044f\u0442\u0430',\n            },\n            'add_ie': ['YapFiles'],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # CloudflareStream embed\n            'url': 'https://www.cloudflare.com/products/cloudflare-stream/',\n            'info_dict': {\n                'id': '31c9291ab41fac05471db4e73aa11717',\n                'ext': 'mp4',\n                'title': '31c9291ab41fac05471db4e73aa11717',\n            },\n            'add_ie': ['CloudflareStream'],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # PeerTube embed\n            'url': 'https://joinpeertube.org/fr/home/',\n            'info_dict': {\n                'id': 'home',\n                'title': 'Reprenez le contr\u00f4le de vos vid\u00e9os ! #JoinPeertube',\n            },\n            'playlist_count': 2,\n        },\n        {\n            # Indavideo embed\n            'url': 'https://streetkitchen.hu/receptek/igy_kell_otthon_hamburgert_sutni/',\n            'info_dict': {\n                'id': '1693903',\n                'ext': 'mp4',\n                'title': '\u00cdgy kell otthon hamburgert s\u00fctni',\n                'description': 'md5:f5a730ecf900a5c852e1e00540bbb0f7',\n                'timestamp': 1426330212,\n                'upload_date': '20150314',\n                'uploader': 'StreetKitchen',\n                'uploader_id': '546363',\n            },\n            'add_ie': ['IndavideoEmbed'],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # APA embed via JWPlatform embed\n            'url': 'http://www.vol.at/blue-man-group/5593454',\n            'info_dict': {\n                'id': 'jjv85FdZ',\n                'ext': 'mp4',\n                'title': '\"Blau ist mysteri\u00f6s\": Die Blue Man Group im Interview',\n                'description': 'md5:d41d8cd98f00b204e9800998ecf8427e',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 254,\n                'timestamp': 1519211149,\n                'upload_date': '20180221',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            'url': 'http://share-videos.se/auto/video/83645793?uid=13',\n            'md5': 'b68d276de422ab07ee1d49388103f457',\n            'info_dict': {\n                'id': '83645793',\n                'title': 'Lock up and get excited',\n                'ext': 'mp4'\n            },\n            'skip': 'TODO: fix nested playlists processing in tests',\n        },\n        {\n            # Viqeo embeds\n            'url': 'https://viqeo.tv/',\n            'info_dict': {\n                'id': 'viqeo',\n                'title': 'All-new video platform',\n            },\n            'playlist_count': 6,\n        },\n        # {\n        #     # Zype embed\n        #     'url': 'https://www.cookscountry.com/episode/554-smoky-barbecue-favorites',\n        #     'info_dict': {\n        #         'id': '5b400b834b32992a310622b9',\n        #         'ext': 'mp4',\n        #         'title': 'Smoky Barbecue Favorites',\n        #         'thumbnail': r're:^https?://.*\\.jpe?g',\n        #         'description': 'md5:5ff01e76316bd8d46508af26dc86023b',\n        #         'upload_date': '20170909',\n        #         'timestamp': 1504915200,\n        #     },\n        #     'add_ie': [ZypeIE.ie_key()],\n        #     'params': {\n        #         'skip_download': True,\n        #     },\n        # },\n        {\n            # videojs embed\n            'url': 'https://video.sibnet.ru/shell.php?videoid=3422904',\n            'info_dict': {\n                'id': 'shell',\n                'ext': 'mp4',\n                'title': '\u0414\u043e\u0441\u0442\u0430\u0432\u0449\u0438\u043a \u043f\u0438\u0446\u0446\u044b \u0441\u043f\u0440\u043e\u0441\u0438\u043b \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0441\u044b\u0433\u0440\u0430\u0442\u044c \u043d\u0430 \u0444\u043e\u0440\u0442\u0435\u043f\u0438\u0430\u043d\u043e',\n                'description': 'md5:89209cdc587dab1e4a090453dbaa2cb1',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'expected_warnings': ['Failed to download MPD manifest'],\n        },\n        {\n            # DailyMotion embed with DM.player\n            'url': 'https://www.beinsports.com/us/copa-del-rey/video/the-locker-room-valencia-beat-barca-in-copa/1203804',\n            'info_dict': {\n                'id': 'k6aKkGHd9FJs4mtJN39',\n                'ext': 'mp4',\n                'title': 'The Locker Room: Valencia Beat Barca In Copa del Rey Final',\n                'description': 'This video is private.',\n                'uploader_id': 'x1jf30l',\n                'uploader': 'beIN SPORTS USA',\n                'upload_date': '20190528',\n                'timestamp': 1559062971,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # tvopengr:embed\n            'url': 'https://www.ethnos.gr/World/article/190604/hparosiaxekinoynoisynomiliessthgeneyhmethskiatoypolemoypanoapothnoykrania',\n            'md5': 'eb0c3995d0a6f18f6538c8e057865d7d',\n            'info_dict': {\n                'id': '101119',\n                'ext': 'mp4',\n                'display_id': 'oikarpoitondiapragmateyseonhparosias',\n                'title': 'md5:b979f4d640c568617d6547035528a149',\n                'description': 'md5:e54fc1977c7159b01cc11cd7d9d85550',\n                'timestamp': 1641772800,\n                'upload_date': '20220110',\n                'thumbnail': 'https://opentv-static.siliconweb.com/imgHandler/1920/70bc39fa-895b-4918-a364-c39d2135fc6d.jpg',\n\n            }\n        },\n        {\n            # blogger embed\n            'url': 'https://blog.tomeuvizoso.net/2019/01/a-panfrost-milestone.html',\n            'md5': 'f1bc19b6ea1b0fd1d81e84ca9ec467ac',\n            'info_dict': {\n                'id': 'BLOGGER-video-3c740e3a49197e16-796',\n                'ext': 'mp4',\n                'title': 'Blogger',\n                'thumbnail': r're:^https?://.*',\n            },\n        },\n        # {\n        #     # TODO: find another test\n        #     # http://schema.org/VideoObject\n        #     'url': 'https://flipagram.com/f/nyvTSJMKId',\n        #     'md5': '888dcf08b7ea671381f00fab74692755',\n        #     'info_dict': {\n        #         'id': 'nyvTSJMKId',\n        #         'ext': 'mp4',\n        #         'title': 'Flipagram by sjuria101 featuring Midnight Memories by One Direction',\n        #         'description': '#love for cats.',\n        #         'timestamp': 1461244995,\n        #         'upload_date': '20160421',\n        #     },\n        #     'params': {\n        #         'force_generic_extractor': True,\n        #     },\n        # },\n        {\n            # VHX Embed\n            'url': 'https://demo.vhx.tv/category-c/videos/file-example-mp4-480-1-5mg-copy',\n            'info_dict': {\n                'id': '858208',\n                'ext': 'mp4',\n                'title': 'Untitled',\n                'uploader_id': 'user80538407',\n                'uploader': 'OTT Videos',\n            },\n        },\n        {\n            # ArcPublishing PoWa video player\n            'url': 'https://www.adn.com/politics/2020/11/02/video-senate-candidates-campaign-in-anchorage-on-eve-of-election-day/',\n            'md5': 'b03b2fac8680e1e5a7cc81a5c27e71b3',\n            'info_dict': {\n                'id': '8c99cb6e-b29c-4bc9-9173-7bf9979225ab',\n                'ext': 'mp4',\n                'title': 'Senate candidates wave to voters on Anchorage streets',\n                'description': 'md5:91f51a6511f090617353dc720318b20e',\n                'timestamp': 1604378735,\n                'upload_date': '20201103',\n                'duration': 1581,\n            },\n        },\n        {\n            # MyChannels SDK embed\n            # https://www.24kitchen.nl/populair/deskundige-dit-waarom-sommigen-gevoelig-zijn-voor-voedselallergieen\n            'url': 'https://www.demorgen.be/nieuws/burgemeester-rotterdam-richt-zich-in-videoboodschap-tot-relschoppers-voelt-het-goed~b0bcfd741/',\n            'md5': '90c0699c37006ef18e198c032d81739c',\n            'info_dict': {\n                'id': '194165',\n                'ext': 'mp4',\n                'title': 'Burgemeester Aboutaleb spreekt relschoppers toe',\n                'timestamp': 1611740340,\n                'upload_date': '20210127',\n                'duration': 159,\n            },\n        },\n        {\n            # Simplecast player embed\n            'url': 'https://www.bio.org/podcast',\n            'info_dict': {\n                'id': 'podcast',\n                'title': 'I AM BIO Podcast | BIO',\n            },\n            'playlist_mincount': 52,\n        }, {\n            # WimTv embed player\n            'url': 'http://www.msmotor.tv/wearefmi-pt-2-2021/',\n            'info_dict': {\n                'id': 'wearefmi-pt-2-2021',\n                'title': '#WEAREFMI \u2013 PT.2 \u2013 2021 \u2013 MsMotorTV',\n            },\n            'playlist_count': 1,\n        }, {\n            # KVS Player\n            'url': 'https://www.kvs-demo.com/videos/105/kelis-4th-of-july/',\n            'info_dict': {\n                'id': '105',\n                'display_id': 'kelis-4th-of-july',\n                'ext': 'mp4',\n                'title': 'Kelis - 4th Of July',\n                'description': 'Kelis - 4th Of July',\n                'thumbnail': r're:https://(?:www\\.)?kvs-demo.com/contents/videos_screenshots/0/105/preview.jpg',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'expected_warnings': ['Untested major version'],\n        }, {\n            # KVS Player\n            'url': 'https://www.kvs-demo.com/embed/105/',\n            'info_dict': {\n                'id': '105',\n                'display_id': 'kelis-4th-of-july',\n                'ext': 'mp4',\n                'title': 'Kelis - 4th Of July / Embed Player',\n                'thumbnail': r're:https://(?:www\\.)?kvs-demo.com/contents/videos_screenshots/0/105/preview.jpg',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        }, {\n            'url': 'https://youix.com/video/leningrad-zoj/',\n            'md5': '94f96ba95706dc3880812b27b7d8a2b8',\n            'info_dict': {\n                'id': '18485',\n                'display_id': 'leningrad-zoj',\n                'ext': 'mp4',\n                'title': '\u041a\u043b\u0438\u043f: \u041b\u0435\u043d\u0438\u043d\u0433\u0440\u0430\u0434 - \u0417\u041e\u0416 \u0441\u043a\u0430\u0447\u0430\u0442\u044c, \u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u043e\u043d\u043b\u0430\u0439\u043d | Youix.com',\n                'thumbnail': r're:https://youix.com/contents/videos_screenshots/18000/18485/preview(?:_480x320_youix_com.mp4)?\\.jpg',\n            },\n        }, {\n            # KVS Player\n            'url': 'https://youix.com/embed/18485',\n            'md5': '94f96ba95706dc3880812b27b7d8a2b8',\n            'info_dict': {\n                'id': '18485',\n                'display_id': 'leningrad-zoj',\n                'ext': 'mp4',\n                'title': '\u041b\u0435\u043d\u0438\u043d\u0433\u0440\u0430\u0434 - \u0417\u041e\u0416',\n                'thumbnail': r're:https://youix.com/contents/videos_screenshots/18000/18485/preview(?:_480x320_youix_com.mp4)?\\.jpg',\n            },\n        }, {\n            # KVS Player\n            'url': 'https://bogmedia.org/videos/21217/40-nochey-40-nights-2016/',\n            'md5': '94166bdb26b4cb1fb9214319a629fc51',\n            'info_dict': {\n                'id': '21217',\n                'display_id': '40-nochey-2016',\n                'ext': 'mp4',\n                'title': '40 \u043d\u043e\u0447\u0435\u0439 (2016) - BogMedia.org',\n                'description': 'md5:4e6d7d622636eb7948275432eb256dc3',\n                'thumbnail': 'https://bogmedia.org/contents/videos_screenshots/21000/21217/preview_480p.mp4.jpg',\n            },\n        },\n        {\n            # KVS Player (for sites that serve kt_player.js via non-https urls)\n            'url': 'http://www.camhub.world/embed/389508',\n            'md5': 'fbe89af4cfb59c8fd9f34a202bb03e32',\n            'info_dict': {\n                'id': '389508',\n                'display_id': 'syren-de-mer-onlyfans-05-07-2020have-a-happy-safe-holiday5f014e68a220979bdb8cd-source',\n                'ext': 'mp4',\n                'title': 'Syren De Mer onlyfans_05-07-2020Have_a_happy_safe_holiday5f014e68a220979bdb8cd_source / Embed \u043f\u043b\u0435\u0435\u0440',\n                'thumbnail': r're:https?://www\\.camhub\\.world/contents/videos_screenshots/389000/389508/preview\\.mp4\\.jpg',\n            },\n        },\n        {\n            # Reddit-hosted video that will redirect and be processed by RedditIE\n            # Redirects to https://www.reddit.com/r/videos/comments/6rrwyj/that_small_heart_attack/\n            'url': 'https://v.redd.it/zv89llsvexdz',\n            'md5': '87f5f02f6c1582654146f830f21f8662',\n            'info_dict': {\n                'id': 'zv89llsvexdz',\n                'ext': 'mp4',\n                'timestamp': 1501941939.0,\n                'title': 'That small heart attack.',\n                'upload_date': '20170805',\n                'uploader': 'Antw87'\n            }\n        },\n        {\n            # 1080p Reddit-hosted video that will redirect and be processed by RedditIE\n            'url': 'https://v.redd.it/33hgok7dfbz71/',\n            'md5': '7a1d587940242c9bb3bd6eb320b39258',\n            'info_dict': {\n                'id': '33hgok7dfbz71',\n                'ext': 'mp4',\n                'title': \"The game Didn't want me to Knife that Guy I guess\",\n                'uploader': 'paraf1ve',\n                'timestamp': 1636788683.0,\n                'upload_date': '20211113'\n            }\n        },\n        {\n            # MainStreaming player\n            'url': 'https://www.lactv.it/2021/10/03/lac-news24-la-settimana-03-10-2021/',\n            'info_dict': {\n                'id': 'EUlZfGWkGpOd',\n                'title': 'La Settimana ',\n                'description': '03 Ottobre ore 02:00',\n                'ext': 'mp4',\n                'live_status': 'not_live',\n                'thumbnail': r're:https?://[A-Za-z0-9-]*\\.msvdn.net/image/\\w+/poster',\n                'duration': 1512\n            }\n        },\n        {\n            # Multiple gfycat iframe embeds\n            'url': 'https://www.gezip.net/bbs/board.php?bo_table=entertaine&wr_id=613422',\n            'info_dict': {\n                'title': '\uc7ac\uc774, \uc724, \uc138\uc740 \ud669\uae08 \ub4dc\ub808\uc2a4\ub97c \uc785\uace0 \ube5b\ub09c\ub2e4',\n                'id': 'board'\n            },\n            'playlist_count': 8,\n        },\n        {\n            # Multiple gfycat gifs (direct links)\n            'url': 'https://www.gezip.net/bbs/board.php?bo_table=entertaine&wr_id=612199',\n            'info_dict': {\n                'title': '\uc633\uac8c \ub41c \ud06c\ub86d \ub2c8\ud2b8 \uc2a4\ud14c\uc774\uc528 \uc544\uc774\uc0ac',\n                'id': 'board'\n            },\n            'playlist_count': 6\n        },\n        {\n            # Multiple gfycat embeds, with uppercase \"IFR\" in urls\n            'url': 'https://kkzz.kr/?vid=2295',\n            'info_dict': {\n                'title': '\uc9c0\ubc29\uc2dc \uc570\ubc84\uc11c\ub354 \uc5d0\uc2a4\ud30c \uce74\ub9ac\ub098 \uc6c0\uc9e4',\n                'id': '?vid=2295'\n            },\n            'playlist_count': 9\n        },\n        {\n            # Panopto embeds\n            'url': 'https://www.monash.edu/learning-teaching/teachhq/learning-technologies/panopto/how-to/insert-a-quiz-into-a-panopto-video',\n            'info_dict': {\n                'ext': 'mp4',\n                'id': '0bd3f16c-824a-436a-8486-ac5900693aef',\n                'title': 'Quizzes in Panopto',\n            },\n        },\n        {\n            # Ruutu embed\n            'url': 'https://www.nelonen.fi/ohjelmat/madventures-suomi/2160731-riku-ja-tunna-lahtevat-peurajahtiin-tv-sta-tutun-biologin-kanssa---metsastysreissu-huipentuu-kasvissyojan-painajaiseen',\n            'md5': 'a2513a98d3496099e6eced40f7e6a14b',\n            'info_dict': {\n                'id': '4044426',\n                'ext': 'mp4',\n                'title': 'Riku ja Tunna l\u00e4htev\u00e4t peurajahtiin tv:st\u00e4 tutun biologin kanssa \u2013 mets\u00e4stysreissu huipentuu kasvissy\u00f6j\u00e4n painajaiseen!',\n                'thumbnail': r're:^https?://.+\\.jpg$',\n                'duration': 108,\n                'series': 'Madventures Suomi',\n                'description': 'md5:aa55b44bd06a1e337a6f1d0b46507381',\n                'categories': ['Matkailu', 'El\u00e4m\u00e4ntyyli'],\n                'age_limit': 0,\n                'upload_date': '20220308',\n            },\n        },\n        {\n            # Multiple Ruutu embeds\n            'url': 'https://www.hs.fi/kotimaa/art-2000008762560.html',\n            'info_dict': {\n                'title': 'Koronavirus | Epidemiahuippu voi olla Suomessa ohi, mutta koronaviruksen poistamista yleisvaarallisten tautien joukosta harkitaan vasta syksyll\u00e4',\n                'id': 'art-2000008762560'\n            },\n            'playlist_count': 3\n        },\n        {\n            # Ruutu embed in hs.fi with a single video\n            'url': 'https://www.hs.fi/kotimaa/art-2000008793421.html',\n            'md5': 'f8964e65d8fada6e8a562389bf366bb4',\n            'info_dict': {\n                'id': '4081841',\n                'ext': 'mp4',\n                'title': 'Puolustusvoimat siirsi panssariajoneuvoja harjoituksiin Niinisaloon 2.5.2022',\n                'thumbnail': r're:^https?://.+\\.jpg$',\n                'duration': 138,\n                'age_limit': 0,\n                'upload_date': '20220504',\n            },\n        },\n        {\n            # Webpage contains double BOM\n            'url': 'https://www.filmarkivet.se/movies/paris-d-moll/',\n            'md5': 'df02cadc719dcc63d43288366f037754',\n            'info_dict': {\n                'id': 'paris-d-moll',\n                'ext': 'mp4',\n                'upload_date': '20220518',\n                'title': 'Paris d-moll',\n                'description': 'md5:319e37ea5542293db37e1e13072fe330',\n                'thumbnail': 'https://www.filmarkivet.se/wp-content/uploads/parisdmoll2.jpg',\n                'timestamp': 1652833414,\n                'age_limit': 0,\n            }\n        },\n        {\n            'url': 'https://www.mollymovieclub.com/p/interstellar?s=r#details',\n            'md5': '198bde8bed23d0b23c70725c83c9b6d9',\n            'info_dict': {\n                'id': '53602801',\n                'ext': 'mpga',\n                'title': 'Interstellar',\n                'description': 'Listen now | Episode One',\n                'thumbnail': 'md5:c30d9c83f738e16d8551d7219d321538',\n                'uploader': 'Molly Movie Club',\n                'uploader_id': '839621',\n            },\n        },\n        {\n            'url': 'https://www.blockedandreported.org/p/episode-117-lets-talk-about-depp?s=r',\n            'md5': 'c0cc44ee7415daeed13c26e5b56d6aa0',\n            'info_dict': {\n                'id': '57962052',\n                'ext': 'mpga',\n                'title': 'md5:855b2756f0ee10f6723fa00b16266f8d',\n                'description': 'md5:fe512a5e94136ad260c80bde00ea4eef',\n                'thumbnail': 'md5:2218f27dfe517bb5ac16c47d0aebac59',\n                'uploader': 'Blocked and Reported',\n                'uploader_id': '500230',\n            },\n        },\n        {\n            'url': 'https://www.skimag.com/video/ski-people-1980/',\n            'md5': '022a7e31c70620ebec18deeab376ee03',\n            'info_dict': {\n                'id': 'YTmgRiNU',\n                'ext': 'mp4',\n                'title': '1980 Ski People',\n                'timestamp': 1610407738,\n                'description': 'md5:cf9c3d101452c91e141f292b19fe4843',\n                'thumbnail': 'https://cdn.jwplayer.com/v2/media/YTmgRiNU/poster.jpg?width=720',\n                'duration': 5688.0,\n                'upload_date': '20210111',\n            }\n        },\n        {\n            'note': 'JSON LD with multiple @type',\n            'url': 'https://www.nu.nl/280161/video/hoe-een-bladvlo-dit-verwoestende-japanse-onkruid-moet-vernietigen.html',\n            'md5': 'c7949f34f57273013fb7ccb1156393db',\n            'info_dict': {\n                'id': 'ipy2AcGL',\n                'ext': 'mp4',\n                'description': 'md5:6a9d644bab0dc2dc06849c2505d8383d',\n                'thumbnail': r're:https://media\\.nu\\.nl/m/.+\\.jpg',\n                'title': 'Hoe een bladvlo dit verwoestende Japanse onkruid moet vernietigen',\n                'timestamp': 1586577474,\n                'upload_date': '20200411',\n                'age_limit': 0,\n                'duration': 111.0,\n            }\n        },\n        {\n            'note': 'JSON LD with unexpected data type',\n            'url': 'https://www.autoweek.nl/autotests/artikel/porsche-911-gt3-rs-rij-impressie-2/',\n            'info_dict': {\n                'id': 'porsche-911-gt3-rs-rij-impressie-2',\n                'ext': 'mp4',\n                'title': 'Test: Porsche 911 GT3 RS',\n                'description': 'Je ziet het niet, maar het is er wel. Downforce, hebben we het dan over. En in de nieuwe Porsche 911 GT3 RS is er zelfs heel veel downforce.',\n                'timestamp': 1664920902,\n                'upload_date': '20221004',\n                'thumbnail': r're:^https://media.autoweek.nl/m/.+\\.jpg$',\n                'age_limit': 0,\n                'direct': True,\n            }\n        },\n        {\n            'note': 'server returns data in brotli compression by default if `accept-encoding: *` is specified.',\n            'url': 'https://www.extra.cz/cauky-lidi-70-dil-babis-predstavil-pohadky-prymulanek-nebo-andrejovy-nove-saty-ac867',\n            'info_dict': {\n                'id': 'cauky-lidi-70-dil-babis-predstavil-pohadky-prymulanek-nebo-andrejovy-nove-saty-ac867',\n                'ext': 'mp4',\n                'title': '\u010dauky lidi 70 finall',\n                'description': '\u010dauky lidi 70 finall',\n                'thumbnail': 'h',\n                'upload_date': '20220606',\n                'timestamp': 1654513791,\n                'duration': 318.0,\n                'direct': True,\n                'age_limit': 0,\n            },\n        },\n        {\n            'note': 'JW Player embed with unicode-escape sequences in URL',\n            'url': 'https://www.medici.tv/en/concerts/lahav-shani-mozart-mahler-israel-philharmonic-abu-dhabi-classics',\n            'info_dict': {\n                'id': 'm',\n                'ext': 'mp4',\n                'title': 'Lahav Shani conducts the Israel Philharmonic\\'s first-ever concert in Abu Dhabi',\n                'description': 'Mahler\\'s ',\n                'uploader': 'www.medici.tv',\n                'age_limit': 0,\n                'thumbnail': r're:^https?://.+\\.jpg',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            'url': 'https://shooshtime.com/videos/284002/just-out-of-the-shower-joi/',\n            'md5': 'e2f0a4c329f7986280b7328e24036d60',\n            'info_dict': {\n                'id': '284002',\n                'display_id': 'just-out-of-the-shower-joi',\n                'ext': 'mp4',\n                'title': 'Just Out Of The Shower JOI - Shooshtime',\n                'thumbnail': 'https://i.shoosh.co/contents/videos_screenshots/284000/284002/preview.mp4.jpg',\n                'height': 720,\n                'age_limit': 18,\n            },\n        },\n        {\n            'note': 'Live HLS direct link',\n            'url': 'https://d18j67ugtrocuq.cloudfront.net/out/v1/2767aec339144787926bd0322f72c6e9/index.m3u8',\n            'info_dict': {\n                'id': 'index',\n                'title': r're:index',\n                'ext': 'mp4',\n                'live_status': 'is_live',\n            },\n            'params': {\n                'skip_download': 'm3u8',\n            },\n        },\n        {\n            'note': 'Video.js VOD HLS',\n            'url': 'https://gist.githubusercontent.com/bashonly/2aae0862c50f4a4b84f220c315767208/raw/e3380d413749dabbe804c9c2d8fd9a45142475c7/videojs_hls_test.html',\n            'info_dict': {\n                'id': 'videojs_hls_test',\n                'title': 'video',\n                'ext': 'mp4',\n                'age_limit': 0,\n                'duration': 1800,\n            },\n            'params': {\n                'skip_download': 'm3u8',\n            },\n        },\n    ]\n\n    def report_following_redirect(self, new_url):\n        \"\"\"Report information extraction.\"\"\"\n        self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)\n\n    def report_detected(self, name, num=1, note=None):\n        if num > 1:\n            name += 's'\n        elif not num:\n            return\n        else:\n            num = 'a'\n\n        self._downloader.write_debug(f'Identified {num} {name}{format_field(note, None, \"; %s\")}')\n\n    def _extra_manifest_info(self, info, manifest_url):\n        fragment_query = self._configuration_arg('fragment_query', [None], casesense=True)[0]\n        if fragment_query is not None:\n            info['extra_param_to_segment_url'] = (\n                urllib.parse.urlparse(fragment_query).query or fragment_query\n                or urllib.parse.urlparse(manifest_url).query or None)\n\n        hex_or_none = lambda x: x if re.fullmatch(r'(0x)?[\\da-f]+', x, re.IGNORECASE) else None\n        info['hls_aes'] = traverse_obj(self._configuration_arg('hls_key', casesense=True), {\n            'uri': (0, {url_or_none}), 'key': (0, {hex_or_none}), 'iv': (1, {hex_or_none}),\n        }) or None\n\n        variant_query = self._configuration_arg('variant_query', [None], casesense=True)[0]\n        if variant_query is not None:\n            query = urllib.parse.parse_qs(\n                urllib.parse.urlparse(variant_query).query or variant_query\n                or urllib.parse.urlparse(manifest_url).query)\n            for fmt in self._downloader._get_formats(info):\n                fmt['url'] = update_url_query(fmt['url'], query)\n\n        # Attempt to detect live HLS or set VOD duration\n        m3u8_format = next((f for f in self._downloader._get_formats(info)\n                            if determine_protocol(f) == 'm3u8_native'), None)\n        if m3u8_format:\n            is_live = self._configuration_arg('is_live', [None])[0]\n            if is_live is not None:\n                info['live_status'] = 'not_live' if is_live == 'false' else 'is_live'\n                return\n            headers = m3u8_format.get('http_headers') or info.get('http_headers')\n            duration = self._extract_m3u8_vod_duration(\n                m3u8_format['url'], info.get('id'), note='Checking m3u8 live status',\n                errnote='Failed to download m3u8 media playlist', headers=headers)\n            if not duration:\n                info['live_status'] = 'is_live'\n            info['duration'] = info.get('duration') or duration\n\n    def _extract_rss(self, url, video_id, doc):\n        NS_MAP = {\n            'itunes': 'http://www.itunes.com/dtds/podcast-1.0.dtd',\n        }\n\n        entries = []\n        for it in doc.findall('./channel/item'):\n            next_url = next(\n                (e.attrib.get('url') for e in it.findall('./enclosure')),\n                xpath_text(it, 'link', fatal=False))\n            if not next_url:\n                continue\n\n            guid = try_call(lambda: it.find('guid').text)\n            if guid:\n                next_url = smuggle_url(next_url, {'force_videoid': guid})\n\n            def itunes(key):\n                return xpath_text(it, xpath_with_ns(f'./itunes:{key}', NS_MAP), default=None)\n\n            entries.append({\n                '_type': 'url_transparent',\n                'url': next_url,\n                'title': try_call(lambda: it.find('title').text),\n                'description': xpath_text(it, 'description', default=None),\n                'timestamp': unified_timestamp(xpath_text(it, 'pubDate', default=None)),\n                'duration': parse_duration(itunes('duration')),\n                'thumbnail': url_or_none(xpath_attr(it, xpath_with_ns('./itunes:image', NS_MAP), 'href')),\n                'episode': itunes('title'),\n                'episode_number': int_or_none(itunes('episode')),\n                'season_number': int_or_none(itunes('season')),\n                'age_limit': {'true': 18, 'yes': 18, 'false': 0, 'no': 0}.get((itunes('explicit') or '').lower()),\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': url,\n            'title': try_call(lambda: doc.find('./channel/title').text),\n            'description': try_call(lambda: doc.find('./channel/description').text),\n            'entries': entries,\n        }\n\n    @classmethod\n    def _kvs_get_real_url(cls, video_url, license_code):\n        if not video_url.startswith('function/0/'):\n            return video_url  # not obfuscated\n\n        parsed = urllib.parse.urlparse(video_url[len('function/0/'):])\n        license = cls._kvs_get_license_token(license_code)\n        urlparts = parsed.path.split('/')\n\n        HASH_LENGTH = 32\n        hash = urlparts[3][:HASH_LENGTH]\n        indices = list(range(HASH_LENGTH))\n\n        # Swap indices of hash according to the destination calculated from the license token\n        accum = 0\n        for src in reversed(range(HASH_LENGTH)):\n            accum += license[src]\n            dest = (src + accum) % HASH_LENGTH\n            indices[src], indices[dest] = indices[dest], indices[src]\n\n        urlparts[3] = ''.join(hash[index] for index in indices) + urlparts[3][HASH_LENGTH:]\n        return urllib.parse.urlunparse(parsed._replace(path='/'.join(urlparts)))\n\n    @staticmethod\n    def _kvs_get_license_token(license):\n        license = license.replace('$', '')\n        license_values = [int(char) for char in license]\n\n        modlicense = license.replace('0', '1')\n        center = len(modlicense) // 2\n        fronthalf = int(modlicense[:center + 1])\n        backhalf = int(modlicense[center:])\n        modlicense = str(4 * abs(fronthalf - backhalf))[:center + 1]\n\n        return [\n            (license_values[index + offset] + current) % 10\n            for index, current in enumerate(map(int, modlicense))\n            for offset in range(4)\n        ]\n\n    def _extract_kvs(self, url, webpage, video_id):\n        flashvars = self._search_json(\n            r'(?s:<script\\b[^>]*>.*?var\\s+flashvars\\s*=)',\n            webpage, 'flashvars', video_id, transform_source=js_to_json)\n\n        # extract the part after the last / as the display_id from the\n        # canonical URL.\n        display_id = self._search_regex(\n            r'(?:<link href=\"https?://[^\"]+/(.+?)/?\" rel=\"canonical\"\\s*/?>'\n            r'|<link rel=\"canonical\" href=\"https?://[^\"]+/(.+?)/?\"\\s*/?>)',\n            webpage, 'display_id', fatal=False)\n        title = self._html_search_regex(r'<(?:h1|title)>(?:Video: )?(.+?)</(?:h1|title)>', webpage, 'title')\n\n        thumbnail = flashvars['preview_url']\n        if thumbnail.startswith('//'):\n            protocol, _, _ = url.partition('/')\n            thumbnail = protocol + thumbnail\n\n        url_keys = list(filter(re.compile(r'^video_(?:url|alt_url\\d*)$').match, flashvars.keys()))\n        formats = []\n        for key in url_keys:\n            if '/get_file/' not in flashvars[key]:\n                continue\n            format_id = flashvars.get(f'{key}_text', key)\n            formats.append({\n                'url': urljoin(url, self._kvs_get_real_url(flashvars[key], flashvars['license_code'])),\n                'format_id': format_id,\n                'ext': 'mp4',\n                **(parse_resolution(format_id) or parse_resolution(flashvars[key])),\n                'http_headers': {'Referer': url},\n            })\n            if not formats[-1].get('height'):\n                formats[-1]['quality'] = 1\n\n        return {\n            'id': flashvars['video_id'],\n            'display_id': display_id,\n            'title': title,\n            'thumbnail': urljoin(url, thumbnail),\n            'formats': formats,\n        }\n\n    def _real_extract(self, url):\n        if url.startswith('//'):\n            return self.url_result(self.http_scheme() + url)\n\n        parsed_url = urllib.parse.urlparse(url)\n        if not parsed_url.scheme:\n            default_search = self.get_param('default_search')\n            if default_search is None:\n                default_search = 'fixup_error'\n\n            if default_search in ('auto', 'auto_warning', 'fixup_error'):\n                if re.match(r'^[^\\s/]+\\.[^\\s/]+/', url):\n                    self.report_warning('The url doesn\\'t specify the protocol, trying with http')\n                    return self.url_result('http://' + url)\n                elif default_search != 'fixup_error':\n                    if default_search == 'auto_warning':\n                        if re.match(r'^(?:url|URL)$', url):\n                            raise ExtractorError(\n                                'Invalid URL:  %r . Call yt-dlp like this:  yt-dlp -v \"https://www.youtube.com/watch?v=BaW_jenozKc\"  ' % url,\n                                expected=True)\n                        else:\n                            self.report_warning(\n                                'Falling back to youtube search for  %s . Set --default-search \"auto\" to suppress this warning.' % url)\n                    return self.url_result('ytsearch:' + url)\n\n            if default_search in ('error', 'fixup_error'):\n                raise ExtractorError(\n                    '%r is not a valid URL. '\n                    'Set --default-search \"ytsearch\" (or run  yt-dlp \"ytsearch:%s\" ) to search YouTube'\n                    % (url, url), expected=True)\n            else:\n                if ':' not in default_search:\n                    default_search += ':'\n                return self.url_result(default_search + url)\n\n        original_url = url\n        url, smuggled_data = unsmuggle_url(url, {})\n        force_videoid = None\n        is_intentional = smuggled_data.get('to_generic')\n        if 'force_videoid' in smuggled_data:\n            force_videoid = smuggled_data['force_videoid']\n            video_id = force_videoid\n        else:\n            video_id = self._generic_id(url)\n\n        # Some webservers may serve compressed content of rather big size (e.g. gzipped flac)\n        # making it impossible to download only chunk of the file (yet we need only 512kB to\n        # test whether it's HTML or not). According to yt-dlp default Accept-Encoding\n        # that will always result in downloading the whole file that is not desirable.\n        # Therefore for extraction pass we have to override Accept-Encoding to any in order\n        # to accept raw bytes and being able to download only a chunk.\n        # It may probably better to solve this by checking Content-Type for application/octet-stream\n        # after a HEAD request, but not sure if we can rely on this.\n        full_response = self._request_webpage(url, video_id, headers={\n            'Accept-Encoding': 'identity',\n            **smuggled_data.get('http_headers', {})\n        })\n        new_url = full_response.url\n        url = urllib.parse.urlparse(url)._replace(scheme=urllib.parse.urlparse(new_url).scheme).geturl()\n        if new_url != extract_basic_auth(url)[0]:\n            self.report_following_redirect(new_url)\n            if force_videoid:\n                new_url = smuggle_url(new_url, {'force_videoid': force_videoid})\n            return self.url_result(new_url)\n\n        info_dict = {\n            'id': video_id,\n            'title': self._generic_title(url),\n            'timestamp': unified_timestamp(full_response.headers.get('Last-Modified'))\n        }\n\n        # Check for direct link to a video\n        content_type = full_response.headers.get('Content-Type', '').lower()\n        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\\.apple\\.|x-)?mpegurl)))/(?P<format_id>[^;\\s]+)', content_type)\n        if m:\n            self.report_detected('direct video link')\n            headers = smuggled_data.get('http_headers', {})\n            format_id = str(m.group('format_id'))\n            ext = determine_ext(url, default_ext=None) or urlhandle_detect_ext(full_response)\n            subtitles = {}\n            if format_id.endswith('mpegurl') or ext == 'm3u8':\n                formats, subtitles = self._extract_m3u8_formats_and_subtitles(url, video_id, 'mp4', headers=headers)\n            elif format_id.endswith('mpd') or format_id.endswith('dash+xml') or ext == 'mpd':\n                formats, subtitles = self._extract_mpd_formats_and_subtitles(url, video_id, headers=headers)\n            elif format_id == 'f4m' or ext == 'f4m':\n                formats = self._extract_f4m_formats(url, video_id, headers=headers)\n            else:\n                formats = [{\n                    'format_id': format_id,\n                    'url': url,\n                    'ext': ext,\n                    'vcodec': 'none' if m.group('type') == 'audio' else None\n                }]\n                info_dict['direct'] = True\n            info_dict.update({\n                'formats': formats,\n                'subtitles': subtitles,\n                'http_headers': headers or None,\n            })\n            self._extra_manifest_info(info_dict, url)\n            return info_dict\n\n        if not self.get_param('test', False) and not is_intentional:\n            force = self.get_param('force_generic_extractor', False)\n            self.report_warning('%s generic information extractor' % ('Forcing' if force else 'Falling back on'))\n\n        first_bytes = full_response.read(512)\n\n        # Is it an M3U playlist?\n        if first_bytes.startswith(b'#EXTM3U'):\n            self.report_detected('M3U playlist')\n            info_dict['formats'], info_dict['subtitles'] = self._extract_m3u8_formats_and_subtitles(url, video_id, 'mp4')\n            self._extra_manifest_info(info_dict, url)\n            return info_dict\n\n        # Maybe it's a direct link to a video?\n        # Be careful not to download the whole thing!\n        if not is_html(first_bytes):\n            self.report_warning(\n                'URL could be a direct video link, returning it as such.')\n            info_dict.update({\n                'direct': True,\n                'url': url,\n            })\n            return info_dict\n\n        webpage = self._webpage_read_content(\n            full_response, url, video_id, prefix=first_bytes)\n\n        if '<title>DPG Media Privacy Gate</title>' in webpage:\n            webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        # Is it an RSS feed, a SMIL file, an XSPF playlist or a MPD manifest?\n        try:\n            try:\n                doc = compat_etree_fromstring(webpage)\n            except xml.etree.ElementTree.ParseError:\n                doc = compat_etree_fromstring(webpage.encode('utf-8'))\n            if doc.tag == 'rss':\n                self.report_detected('RSS feed')\n                return self._extract_rss(url, video_id, doc)\n            elif doc.tag == 'SmoothStreamingMedia':\n                info_dict['formats'], info_dict['subtitles'] = self._parse_ism_formats_and_subtitles(doc, url)\n                self.report_detected('ISM manifest')\n                return info_dict\n            elif re.match(r'^(?:{[^}]+})?smil$', doc.tag):\n                smil = self._parse_smil(doc, url, video_id)\n                self.report_detected('SMIL file')\n                return smil\n            elif doc.tag == '{http://xspf.org/ns/0/}playlist':\n                self.report_detected('XSPF playlist')\n                return self.playlist_result(\n                    self._parse_xspf(\n                        doc, video_id, xspf_url=url,\n                        xspf_base_url=full_response.url),\n                    video_id)\n            elif re.match(r'(?i)^(?:{[^}]+})?MPD$', doc.tag):\n                info_dict['formats'], info_dict['subtitles'] = self._parse_mpd_formats_and_subtitles(\n                    doc,\n                    mpd_base_url=full_response.url.rpartition('/')[0],\n                    mpd_url=url)\n                self._extra_manifest_info(info_dict, url)\n                self.report_detected('DASH manifest')\n                return info_dict\n            elif re.match(r'^{http://ns\\.adobe\\.com/f4m/[12]\\.0}manifest$', doc.tag):\n                info_dict['formats'] = self._parse_f4m_formats(doc, url, video_id)\n                self.report_detected('F4M manifest')\n                return info_dict\n        except xml.etree.ElementTree.ParseError:\n            pass\n\n        info_dict.update({\n            # it's tempting to parse this further, but you would\n            # have to take into account all the variations like\n            #   Video Title - Site Name\n            #   Site Name | Video Title\n            #   Video Title - Tagline | Site Name\n            # and so on and so forth; it's just not practical\n            'title': self._generic_title('', webpage, default='video'),\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'age_limit': self._rta_search(webpage),\n        })\n\n        self._downloader.write_debug('Looking for embeds')\n        embeds = list(self._extract_embeds(original_url, webpage, urlh=full_response, info_dict=info_dict))\n        if len(embeds) == 1:\n            return merge_dicts(embeds[0], info_dict)\n        elif embeds:\n            return self.playlist_result(embeds, **info_dict)\n        raise UnsupportedError(url)\n\n    def _extract_embeds(self, url, webpage, *, urlh=None, info_dict={}):\n        \"\"\"Returns an iterator of video entries\"\"\"\n        info_dict = types.MappingProxyType(info_dict)  # Prevents accidental mutation\n        video_id = traverse_obj(info_dict, 'display_id', 'id') or self._generic_id(url)\n        url, smuggled_data = unsmuggle_url(url, {})\n        actual_url = urlh.url if urlh else url\n\n        # Sometimes embedded video player is hidden behind percent encoding\n        # (e.g. https://github.com/ytdl-org/youtube-dl/issues/2448)\n        # Unescaping the whole page allows to handle those cases in a generic way\n        # FIXME: unescaping the whole page may break URLs, commenting out for now.\n        # There probably should be a second run of generic extractor on unescaped webpage.\n        # webpage = urllib.parse.unquote(webpage)\n\n        embeds = []\n        for ie in self._downloader._ies.values():\n            if ie.ie_key() in smuggled_data.get('block_ies', []):\n                continue\n            gen = ie.extract_from_webpage(self._downloader, url, webpage)\n            current_embeds = []\n            try:\n                while True:\n                    current_embeds.append(next(gen))\n            except self.StopExtraction:\n                self.report_detected(f'{ie.IE_NAME} exclusive embed', len(current_embeds),\n                                     embeds and 'discarding other embeds')\n                return current_embeds\n            except StopIteration:\n                self.report_detected(f'{ie.IE_NAME} embed', len(current_embeds))\n                embeds.extend(current_embeds)\n\n        if embeds:\n            return embeds\n\n        jwplayer_data = self._find_jwplayer_data(\n            webpage, video_id, transform_source=js_to_json)\n        if jwplayer_data:\n            if isinstance(jwplayer_data.get('playlist'), str):\n                self.report_detected('JW Player playlist')\n                return [self.url_result(jwplayer_data['playlist'], 'JWPlatform')]\n            try:\n                info = self._parse_jwplayer_data(\n                    jwplayer_data, video_id, require_title=False, base_url=url)\n                if traverse_obj(info, 'formats', ('entries', ..., 'formats')):\n                    self.report_detected('JW Player data')\n                    return [info]\n            except ExtractorError:\n                # See https://github.com/ytdl-org/youtube-dl/pull/16735\n                pass\n\n        # Video.js embed\n        mobj = re.search(\n            r'(?s)\\bvideojs\\s*\\(.+?([a-zA-Z0-9_$]+)\\.src\\s*\\(\\s*((?:\\[.+?\\]|{.+?}))\\s*\\)\\s*;',\n            webpage)\n        if mobj is not None:\n            varname = mobj.group(1)\n            sources = variadic(self._parse_json(\n                mobj.group(2), video_id, transform_source=js_to_json, fatal=False) or [])\n            formats, subtitles, src = [], {}, None\n            for source in sources:\n                src = source.get('src')\n                if not src or not isinstance(src, str):\n                    continue\n                src = urllib.parse.urljoin(url, src)\n                src_type = source.get('type')\n                if isinstance(src_type, str):\n                    src_type = src_type.lower()\n                ext = determine_ext(src).lower()\n                if src_type == 'video/youtube':\n                    return [self.url_result(src, YoutubeIE.ie_key())]\n                if src_type == 'application/dash+xml' or ext == 'mpd':\n                    fmts, subs = self._extract_mpd_formats_and_subtitles(\n                        src, video_id, mpd_id='dash', fatal=False)\n                    formats.extend(fmts)\n                    self._merge_subtitles(subs, target=subtitles)\n                elif src_type == 'application/x-mpegurl' or ext == 'm3u8':\n                    fmts, subs = self._extract_m3u8_formats_and_subtitles(\n                        src, video_id, 'mp4', entry_protocol='m3u8_native',\n                        m3u8_id='hls', fatal=False)\n                    formats.extend(fmts)\n                    self._merge_subtitles(subs, target=subtitles)\n\n                if not formats:\n                    formats.append({\n                        'url': src,\n                        'ext': (mimetype2ext(src_type)\n                                or ext if ext in KNOWN_EXTENSIONS else 'mp4'),\n                        'http_headers': {\n                            'Referer': actual_url,\n                        },\n                    })\n            # https://docs.videojs.com/player#addRemoteTextTrack\n            # https://html.spec.whatwg.org/multipage/media.html#htmltrackelement\n            for sub_match in re.finditer(rf'(?s){re.escape(varname)}' r'\\.addRemoteTextTrack\\(({.+?})\\s*,\\s*(?:true|false)\\)', webpage):\n                sub = self._parse_json(\n                    sub_match.group(1), video_id, transform_source=js_to_json, fatal=False) or {}\n                sub_src = str_or_none(sub.get('src'))\n                if not sub_src:\n                    continue\n                subtitles.setdefault(dict_get(sub, ('language', 'srclang')) or 'und', []).append({\n                    'url': urllib.parse.urljoin(url, sub_src),\n                    'name': sub.get('label'),\n                    'http_headers': {\n                        'Referer': actual_url,\n                    },\n                })\n            if formats or subtitles:\n                self.report_detected('video.js embed')\n                info_dict = {'formats': formats, 'subtitles': subtitles}\n                if formats:\n                    self._extra_manifest_info(info_dict, src)\n                return [info_dict]\n\n        # Look for generic KVS player (before json-ld bc of some urls that break otherwise)\n        found = self._search_regex((\n            r'<script\\b[^>]+?\\bsrc\\s*=\\s*([\"\\'])https?://(?:(?!\\1)[^?#])+/kt_player\\.js\\?v=(?P<ver>\\d+(?:\\.\\d+)+)\\1[^>]*>',\n            r'kt_player\\s*\\(\\s*([\"\\'])(?:(?!\\1)[\\w\\W])+\\1\\s*,\\s*([\"\\'])https?://(?:(?!\\2)[^?#])+/kt_player\\.swf\\?v=(?P<ver>\\d+(?:\\.\\d+)+)\\2\\s*,',\n        ), webpage, 'KVS player', group='ver', default=False)\n        if found:\n            self.report_detected('KVS Player')\n            if found.split('.')[0] not in ('4', '5', '6'):\n                self.report_warning(f'Untested major version ({found}) in player engine - download may fail.')\n            return [self._extract_kvs(url, webpage, video_id)]\n\n        # Looking for http://schema.org/VideoObject\n        json_ld = self._search_json_ld(webpage, video_id, default={})\n        if json_ld.get('url') not in (url, None):\n            self.report_detected('JSON LD')\n            is_direct = json_ld.get('ext') not in (None, *MEDIA_EXTENSIONS.manifests)\n            return [merge_dicts({\n                '_type': 'video' if is_direct else 'url_transparent',\n                'url': smuggle_url(json_ld['url'], {\n                    'force_videoid': video_id,\n                    'to_generic': True,\n                    'http_headers': {'Referer': url},\n                }),\n            }, json_ld)]\n\n        def check_video(vurl):\n            if YoutubeIE.suitable(vurl):\n                return True\n            if RtmpIE.suitable(vurl):\n                return True\n            vpath = urllib.parse.urlparse(vurl).path\n            vext = determine_ext(vpath, None)\n            return vext not in (None, 'swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml', 'js', 'xml')\n\n        def filter_video(urls):\n            return list(filter(check_video, urls))\n\n        # Start with something easy: JW Player in SWFObject\n        found = filter_video(re.findall(r'flashvars: [\\'\"](?:.*&)?file=(http[^\\'\"&]*)', webpage))\n        if found:\n            self.report_detected('JW Player in SFWObject')\n        else:\n            # Look for gorilla-vid style embedding\n            found = filter_video(re.findall(r'''(?sx)\n                (?:\n                    jw_plugins|\n                    JWPlayerOptions|\n                    jwplayer\\s*\\(\\s*[\"'][^'\"]+[\"']\\s*\\)\\s*\\.setup\n                )\n                .*?\n                ['\"]?file['\"]?\\s*:\\s*[\"\\'](.*?)[\"\\']''', webpage))\n            if found:\n                self.report_detected('JW Player embed')\n        if not found:\n            # Broaden the search a little bit\n            found = filter_video(re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\\'\"&]*)', webpage))\n            if found:\n                self.report_detected('video file')\n        if not found:\n            # Broaden the findall a little bit: JWPlayer JS loader\n            found = filter_video(re.findall(\n                r'[^A-Za-z0-9]?(?:file|video_url)[\"\\']?:\\s*[\"\\'](http(?![^\\'\"]+\\.[0-9]+[\\'\"])[^\\'\"]+)[\"\\']', webpage))\n            if found:\n                self.report_detected('JW Player JS loader')\n        if not found:\n            # Flow player\n            found = filter_video(re.findall(r'''(?xs)\n                flowplayer\\(\"[^\"]+\",\\s*\n                    \\{[^}]+?\\}\\s*,\n                    \\s*\\{[^}]+? [\"']?clip[\"']?\\s*:\\s*\\{\\s*\n                        [\"']?url[\"']?\\s*:\\s*[\"']([^\"']+)[\"']\n            ''', webpage))\n            if found:\n                self.report_detected('Flow Player')\n        if not found:\n            # Cinerama player\n            found = re.findall(\n                r\"cinerama\\.embedPlayer\\(\\s*\\'[^']+\\',\\s*'([^']+)'\", webpage)\n            if found:\n                self.report_detected('Cinerama player')\n        if not found:\n            # Try to find twitter cards info\n            # twitter:player:stream should be checked before twitter:player since\n            # it is expected to contain a raw stream (see\n            # https://dev.twitter.com/cards/types/player#On_twitter.com_via_desktop_browser)\n            found = filter_video(re.findall(\n                r'<meta (?:property|name)=\"twitter:player:stream\" (?:content|value)=\"(.+?)\"', webpage))\n            if found:\n                self.report_detected('Twitter card')\n        if not found:\n            # We look for Open Graph info:\n            # We have to match any number spaces between elements, some sites try to align them, e.g.: statigr.am\n            m_video_type = re.findall(r'<meta.*?property=\"og:video:type\".*?content=\"video/(.*?)\"', webpage)\n            # We only look in og:video if the MIME type is a video, don't try if it's a Flash player:\n            if m_video_type is not None:\n                found = filter_video(re.findall(r'<meta.*?property=\"og:(?:video|audio)\".*?content=\"(.*?)\"', webpage))\n                if found:\n                    self.report_detected('Open Graph video info')\n        if not found:\n            REDIRECT_REGEX = r'[0-9]{,2};\\s*(?:URL|url)=\\'?([^\\'\"]+)'\n            found = re.search(\n                r'(?i)<meta\\s+(?=(?:[a-z-]+=\"[^\"]+\"\\s+)*http-equiv=\"refresh\")'\n                r'(?:[a-z-]+=\"[^\"]+\"\\s+)*?content=\"%s' % REDIRECT_REGEX,\n                webpage)\n            if not found:\n                # Look also in Refresh HTTP header\n                refresh_header = urlh and urlh.headers.get('Refresh')\n                if refresh_header:\n                    found = re.search(REDIRECT_REGEX, refresh_header)\n            if found:\n                new_url = urllib.parse.urljoin(url, unescapeHTML(found.group(1)))\n                if new_url != url:\n                    self.report_following_redirect(new_url)\n                    return [self.url_result(new_url)]\n                else:\n                    found = None\n\n        if not found:\n            # twitter:player is a https URL to iframe player that may or may not\n            # be supported by yt-dlp thus this is checked the very last (see\n            # https://dev.twitter.com/cards/types/player#On_twitter.com_via_desktop_browser)\n            embed_url = self._html_search_meta('twitter:player', webpage, default=None)\n            if embed_url and embed_url != url:\n                self.report_detected('twitter:player iframe')\n                return [self.url_result(embed_url)]\n\n        if not found:\n            return []\n\n        domain_name = self._search_regex(r'^(?:https?://)?([^/]*)/.*', url, 'video uploader', default=None)\n\n        entries = []\n        for video_url in orderedSet(found):\n            video_url = video_url.encode().decode('unicode-escape')\n            video_url = unescapeHTML(video_url)\n            video_url = video_url.replace('\\\\/', '/')\n            video_url = urllib.parse.urljoin(url, video_url)\n            video_id = urllib.parse.unquote(os.path.basename(video_url))\n\n            # Sometimes, jwplayer extraction will result in a YouTube URL\n            if YoutubeIE.suitable(video_url):\n                entries.append(self.url_result(video_url, 'Youtube'))\n                continue\n\n            video_id = os.path.splitext(video_id)[0]\n            headers = {\n                'referer': actual_url\n            }\n\n            entry_info_dict = {\n                'id': video_id,\n                'uploader': domain_name,\n                'title': info_dict['title'],\n                'age_limit': info_dict['age_limit'],\n                'http_headers': headers,\n            }\n\n            if RtmpIE.suitable(video_url):\n                entry_info_dict.update({\n                    '_type': 'url_transparent',\n                    'ie_key': RtmpIE.ie_key(),\n                    'url': video_url,\n                })\n                entries.append(entry_info_dict)\n                continue\n\n            ext = determine_ext(video_url)\n            if ext == 'smil':\n                entry_info_dict = {**self._extract_smil_info(video_url, video_id), **entry_info_dict}\n            elif ext == 'xspf':\n                return [self._extract_xspf_playlist(video_url, video_id)]\n            elif ext == 'm3u8':\n                entry_info_dict['formats'], entry_info_dict['subtitles'] = self._extract_m3u8_formats_and_subtitles(video_url, video_id, ext='mp4', headers=headers)\n                self._extra_manifest_info(entry_info_dict, video_url)\n            elif ext == 'mpd':\n                entry_info_dict['formats'], entry_info_dict['subtitles'] = self._extract_mpd_formats_and_subtitles(video_url, video_id, headers=headers)\n                self._extra_manifest_info(entry_info_dict, video_url)\n            elif ext == 'f4m':\n                entry_info_dict['formats'] = self._extract_f4m_formats(video_url, video_id, headers=headers)\n            elif re.search(r'(?i)\\.(?:ism|smil)/manifest', video_url) and video_url != url:\n                # Just matching .ism/manifest is not enough to be reliably sure\n                # whether it's actually an ISM manifest or some other streaming\n                # manifest since there are various streaming URL formats\n                # possible (see [1]) as well as some other shenanigans like\n                # .smil/manifest URLs that actually serve an ISM (see [2]) and\n                # so on.\n                # Thus the most reasonable way to solve this is to delegate\n                # to generic extractor in order to look into the contents of\n                # the manifest itself.\n                # 1. https://azure.microsoft.com/en-us/documentation/articles/media-services-deliver-content-overview/#streaming-url-formats\n                # 2. https://svs.itworkscdn.net/lbcivod/smil:itwfcdn/lbci/170976.smil/Manifest\n                entry_info_dict = self.url_result(\n                    smuggle_url(video_url, {'to_generic': True}),\n                    GenericIE.ie_key())\n            else:\n                entry_info_dict['url'] = video_url\n\n            entries.append(entry_info_dict)\n\n        if len(entries) > 1:\n            for num, e in enumerate(entries, start=1):\n                # 'url' results don't have a title\n                if e.get('title') is not None:\n                    e['title'] = '%s (%d)' % (e['title'], num)\n        return entries\n", "import re\nimport urllib.parse\nimport xml.etree.ElementTree\n\nfrom .common import InfoExtractor\nfrom ..utils import (\n    ExtractorError,\n    int_or_none,\n    parse_qs,\n    smuggle_url,\n    traverse_obj,\n    unified_timestamp,\n    update_url_query,\n    url_or_none,\n    xpath_text,\n)\n\n\nclass SlidesLiveIE(InfoExtractor):\n    _VALID_URL = r'https?://slideslive\\.com/(?:embed/(?:presentation/)?)?(?P<id>[0-9]+)'\n    _TESTS = [{\n        # service_name = yoda, only XML slides info\n        'url': 'https://slideslive.com/38902413/gcc-ia16-backend',\n        'info_dict': {\n            'id': '38902413',\n            'ext': 'mp4',\n            'title': 'GCC IA16 backend',\n            'timestamp': 1648189972,\n            'upload_date': '20220325',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'thumbnails': 'count:42',\n            'chapters': 'count:41',\n            'duration': 1638,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # service_name = yoda, /v7/ slides\n        'url': 'https://slideslive.com/38935785',\n        'info_dict': {\n            'id': '38935785',\n            'ext': 'mp4',\n            'title': 'Offline Reinforcement Learning: From Algorithms to Practical Challenges',\n            'upload_date': '20211115',\n            'timestamp': 1636996003,\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:640',\n            'chapters': 'count:639',\n            'duration': 9832,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # service_name = yoda, /v1/ slides\n        'url': 'https://slideslive.com/38973182/how-should-a-machine-learning-researcher-think-about-ai-ethics',\n        'info_dict': {\n            'id': '38973182',\n            'ext': 'mp4',\n            'title': 'How Should a Machine Learning Researcher Think About AI Ethics?',\n            'upload_date': '20220201',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'timestamp': 1643728135,\n            'thumbnails': 'count:3',\n            'chapters': 'count:2',\n            'duration': 5889,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # service_name = youtube, only XML slides info\n        'url': 'https://slideslive.com/38897546/special-metaprednaska-petra-ludwiga-hodnoty-pro-lepsi-spolecnost',\n        'md5': '8a79b5e3d700837f40bd2afca3c8fa01',\n        'info_dict': {\n            'id': 'jmg02wCJD5M',\n            'display_id': '38897546',\n            'ext': 'mp4',\n            'title': 'SPECI\u00c1L: Meta-p\u0159edn\u00e1\u0161ka Petra Ludwiga - Hodnoty pro lep\u0161\u00ed spole\u010dnost',\n            'description': 'Watch full version of this video at https://slideslive.com/38897546.',\n            'channel_url': 'https://www.youtube.com/channel/UCZWdAkNYFncuX0khyvhqnxw',\n            'channel': 'SlidesLive Videos - G1',\n            'channel_id': 'UCZWdAkNYFncuX0khyvhqnxw',\n            'uploader_id': 'UCZWdAkNYFncuX0khyvhqnxw',\n            'uploader': 'SlidesLive Videos - G1',\n            'uploader_url': 'http://www.youtube.com/channel/UCZWdAkNYFncuX0khyvhqnxw',\n            'live_status': 'not_live',\n            'upload_date': '20160710',\n            'timestamp': 1618786715,\n            'duration': 6827,\n            'like_count': int,\n            'view_count': int,\n            'comment_count': int,\n            'channel_follower_count': int,\n            'age_limit': 0,\n            'thumbnail': r're:^https?://.*\\.(?:jpg|webp)',\n            'thumbnails': 'count:169',\n            'playable_in_embed': True,\n            'availability': 'unlisted',\n            'tags': [],\n            'categories': ['People & Blogs'],\n            'chapters': 'count:168',\n        },\n    }, {\n        # embed-only presentation, only XML slides info\n        'url': 'https://slideslive.com/embed/presentation/38925850',\n        'info_dict': {\n            'id': '38925850',\n            'ext': 'mp4',\n            'title': 'Towards a Deep Network Architecture for Structured Smoothness',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'thumbnails': 'count:8',\n            'timestamp': 1629671508,\n            'upload_date': '20210822',\n            'chapters': 'count:7',\n            'duration': 326,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # embed-only presentation, only JSON slides info, /v5/ slides (.png)\n        'url': 'https://slideslive.com/38979920/',\n        'info_dict': {\n            'id': '38979920',\n            'ext': 'mp4',\n            'title': 'MoReL: Multi-omics Relational Learning',\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:7',\n            'timestamp': 1654714970,\n            'upload_date': '20220608',\n            'chapters': 'count:6',\n            'duration': 171,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v2/ slides (.jpg)\n        'url': 'https://slideslive.com/38954074',\n        'info_dict': {\n            'id': '38954074',\n            'ext': 'mp4',\n            'title': 'Decentralized Attribution of Generative Models',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'thumbnails': 'count:16',\n            'timestamp': 1622806321,\n            'upload_date': '20210604',\n            'chapters': 'count:15',\n            'duration': 306,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v4/ slides (.png)\n        'url': 'https://slideslive.com/38979570/',\n        'info_dict': {\n            'id': '38979570',\n            'ext': 'mp4',\n            'title': 'Efficient Active Search for Combinatorial Optimization Problems',\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:9',\n            'timestamp': 1654714896,\n            'upload_date': '20220608',\n            'chapters': 'count:8',\n            'duration': 295,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v10/ slides\n        'url': 'https://slideslive.com/embed/presentation/38979880?embed_parent_url=https%3A%2F%2Fedit.videoken.com%2F',\n        'info_dict': {\n            'id': '38979880',\n            'ext': 'mp4',\n            'title': 'The Representation Power of Neural Networks',\n            'timestamp': 1654714962,\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:22',\n            'upload_date': '20220608',\n            'chapters': 'count:21',\n            'duration': 294,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v7/ slides, 2 video slides\n        'url': 'https://slideslive.com/embed/presentation/38979682?embed_container_origin=https%3A%2F%2Fedit.videoken.com',\n        'playlist_count': 3,\n        'info_dict': {\n            'id': '38979682-playlist',\n            'title': 'LoRA: Low-Rank Adaptation of Large Language Models',\n        },\n        'playlist': [{\n            'info_dict': {\n                'id': '38979682',\n                'ext': 'mp4',\n                'title': 'LoRA: Low-Rank Adaptation of Large Language Models',\n                'timestamp': 1654714920,\n                'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n                'thumbnails': 'count:30',\n                'upload_date': '20220608',\n                'chapters': 'count:31',\n                'duration': 272,\n            },\n        }, {\n            'info_dict': {\n                'id': '38979682-021',\n                'ext': 'mp4',\n                'title': 'LoRA: Low-Rank Adaptation of Large Language Models - Slide 021',\n                'duration': 3,\n                'timestamp': 1654714920,\n                'upload_date': '20220608',\n            },\n        }, {\n            'info_dict': {\n                'id': '38979682-024',\n                'ext': 'mp4',\n                'title': 'LoRA: Low-Rank Adaptation of Large Language Models - Slide 024',\n                'duration': 4,\n                'timestamp': 1654714920,\n                'upload_date': '20220608',\n            },\n        }],\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v6/ slides, 1 video slide, edit.videoken.com embed\n        'url': 'https://slideslive.com/38979481/',\n        'playlist_count': 2,\n        'info_dict': {\n            'id': '38979481-playlist',\n            'title': 'How to Train Your MAML to Excel in Few-Shot Classification',\n        },\n        'playlist': [{\n            'info_dict': {\n                'id': '38979481',\n                'ext': 'mp4',\n                'title': 'How to Train Your MAML to Excel in Few-Shot Classification',\n                'timestamp': 1654714877,\n                'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n                'thumbnails': 'count:43',\n                'upload_date': '20220608',\n                'chapters': 'count:43',\n                'duration': 315,\n            },\n        }, {\n            'info_dict': {\n                'id': '38979481-013',\n                'ext': 'mp4',\n                'title': 'How to Train Your MAML to Excel in Few-Shot Classification - Slide 013',\n                'duration': 3,\n                'timestamp': 1654714877,\n                'upload_date': '20220608',\n            },\n        }],\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v3/ slides, .jpg and .png, service_name = youtube\n        'url': 'https://slideslive.com/embed/38932460/',\n        'info_dict': {\n            'id': 'RTPdrgkyTiE',\n            'display_id': '38932460',\n            'ext': 'mp4',\n            'title': 'Active Learning for Hierarchical Multi-Label Classification',\n            'description': 'Watch full version of this video at https://slideslive.com/38932460.',\n            'channel': 'SlidesLive Videos - A',\n            'channel_id': 'UC62SdArr41t_-_fX40QCLRw',\n            'channel_url': 'https://www.youtube.com/channel/UC62SdArr41t_-_fX40QCLRw',\n            'uploader': 'SlidesLive Videos - A',\n            'uploader_id': 'UC62SdArr41t_-_fX40QCLRw',\n            'uploader_url': 'http://www.youtube.com/channel/UC62SdArr41t_-_fX40QCLRw',\n            'upload_date': '20200903',\n            'timestamp': 1602599092,\n            'duration': 942,\n            'age_limit': 0,\n            'live_status': 'not_live',\n            'playable_in_embed': True,\n            'availability': 'unlisted',\n            'categories': ['People & Blogs'],\n            'tags': [],\n            'channel_follower_count': int,\n            'like_count': int,\n            'view_count': int,\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png|webp)',\n            'thumbnails': 'count:21',\n            'chapters': 'count:20',\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v3/ slides, .png only, service_name = yoda\n        'url': 'https://slideslive.com/38983994',\n        'info_dict': {\n            'id': '38983994',\n            'ext': 'mp4',\n            'title': 'Zero-Shot AutoML with Pretrained Models',\n            'timestamp': 1662384834,\n            'upload_date': '20220905',\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:23',\n            'chapters': 'count:22',\n            'duration': 295,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # service_name = yoda\n        'url': 'https://slideslive.com/38903721/magic-a-scientific-resurrection-of-an-esoteric-legend',\n        'only_matching': True,\n    }, {\n        # dead link, service_name = url\n        'url': 'https://slideslive.com/38922070/learning-transferable-skills-1',\n        'only_matching': True,\n    }, {\n        # dead link, service_name = vimeo\n        'url': 'https://slideslive.com/38921896/retrospectives-a-venue-for-selfreflection-in-ml-research-3',\n        'only_matching': True,\n    }]\n\n    _WEBPAGE_TESTS = [{\n        # only XML slides info\n        'url': 'https://iclr.cc/virtual_2020/poster_Hklr204Fvr.html',\n        'info_dict': {\n            'id': '38925850',\n            'ext': 'mp4',\n            'title': 'Towards a Deep Network Architecture for Structured Smoothness',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'thumbnails': 'count:8',\n            'timestamp': 1629671508,\n            'upload_date': '20210822',\n            'chapters': 'count:7',\n            'duration': 326,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }]\n\n    @classmethod\n    def _extract_embed_urls(cls, url, webpage):\n        # Reference: https://slideslive.com/embed_presentation.js\n        for embed_id in re.findall(r'(?s)new\\s+SlidesLiveEmbed\\s*\\([^)]+\\bpresentationId:\\s*[\"\\'](\\d+)[\"\\']', webpage):\n            url_parsed = urllib.parse.urlparse(url)\n            origin = f'{url_parsed.scheme}://{url_parsed.netloc}'\n            yield update_url_query(\n                f'https://slideslive.com/embed/presentation/{embed_id}', {\n                    'embed_parent_url': url,\n                    'embed_container_origin': origin,\n                })\n\n    def _download_embed_webpage_handle(self, video_id, headers):\n        return self._download_webpage_handle(\n            f'https://slideslive.com/embed/presentation/{video_id}', video_id,\n            headers=headers, query=traverse_obj(headers, {\n                'embed_parent_url': 'Referer',\n                'embed_container_origin': 'Origin',\n            }))\n\n    def _extract_custom_m3u8_info(self, m3u8_data):\n        m3u8_dict = {}\n\n        lookup = {\n            'PRESENTATION-TITLE': 'title',\n            'PRESENTATION-UPDATED-AT': 'timestamp',\n            'PRESENTATION-THUMBNAIL': 'thumbnail',\n            'PLAYLIST-TYPE': 'playlist_type',\n            'VOD-VIDEO-SERVICE-NAME': 'service_name',\n            'VOD-VIDEO-ID': 'service_id',\n            'VOD-VIDEO-SERVERS': 'video_servers',\n            'VOD-SUBTITLES': 'subtitles',\n            'VOD-SLIDES-JSON-URL': 'slides_json_url',\n            'VOD-SLIDES-XML-URL': 'slides_xml_url',\n        }\n\n        for line in m3u8_data.splitlines():\n            if not line.startswith('#EXT-SL-'):\n                continue\n            tag, _, value = line.partition(':')\n            key = lookup.get(tag.lstrip('#EXT-SL-'))\n            if not key:\n                continue\n            m3u8_dict[key] = value\n\n        # Some values are stringified JSON arrays\n        for key in ('video_servers', 'subtitles'):\n            if key in m3u8_dict:\n                m3u8_dict[key] = self._parse_json(m3u8_dict[key], None, fatal=False) or []\n\n        return m3u8_dict\n\n    def _extract_formats_and_duration(self, cdn_hostname, path, video_id, skip_duration=False):\n        formats, duration = [], None\n\n        hls_formats = self._extract_m3u8_formats(\n            f'https://{cdn_hostname}/{path}/master.m3u8',\n            video_id, 'mp4', m3u8_id='hls', fatal=False, live=True)\n        if hls_formats:\n            if not skip_duration:\n                duration = self._extract_m3u8_vod_duration(\n                    hls_formats[0]['url'], video_id, note='Extracting duration from HLS manifest')\n            formats.extend(hls_formats)\n\n        dash_formats = self._extract_mpd_formats(\n            f'https://{cdn_hostname}/{path}/master.mpd', video_id, mpd_id='dash', fatal=False)\n        if dash_formats:\n            if not duration and not skip_duration:\n                duration = self._extract_mpd_vod_duration(\n                    f'https://{cdn_hostname}/{path}/master.mpd', video_id,\n                    note='Extracting duration from DASH manifest')\n            formats.extend(dash_formats)\n\n        return formats, duration\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage, urlh = self._download_embed_webpage_handle(\n            video_id, headers=traverse_obj(parse_qs(url), {\n                'Referer': ('embed_parent_url', -1),\n                'Origin': ('embed_container_origin', -1)}))\n        redirect_url = urlh.url\n        if 'domain_not_allowed' in redirect_url:\n            domain = traverse_obj(parse_qs(redirect_url), ('allowed_domains[]', ...), get_all=False)\n            if not domain:\n                raise ExtractorError(\n                    'This is an embed-only presentation. Try passing --referer', expected=True)\n            webpage, _ = self._download_embed_webpage_handle(video_id, headers={\n                'Referer': f'https://{domain}/',\n                'Origin': f'https://{domain}',\n            })\n\n        player_token = self._search_regex(r'data-player-token=\"([^\"]+)\"', webpage, 'player token')\n        player_data = self._download_webpage(\n            f'https://ben.slideslive.com/player/{video_id}', video_id,\n            note='Downloading player info', query={'player_token': player_token})\n        player_info = self._extract_custom_m3u8_info(player_data)\n\n        service_name = player_info['service_name'].lower()\n        assert service_name in ('url', 'yoda', 'vimeo', 'youtube')\n        service_id = player_info['service_id']\n\n        slide_url_template = 'https://slides.slideslive.com/%s/slides/original/%s%s'\n        slides, slides_info = {}, []\n\n        if player_info.get('slides_json_url'):\n            slides = self._download_json(\n                player_info['slides_json_url'], video_id, fatal=False,\n                note='Downloading slides JSON', errnote=False) or {}\n            slide_ext_default = '.png'\n            slide_quality = traverse_obj(slides, ('slide_qualities', 0))\n            if slide_quality:\n                slide_ext_default = '.jpg'\n                slide_url_template = f'https://cdn.slideslive.com/data/presentations/%s/slides/{slide_quality}/%s%s'\n            for slide_id, slide in enumerate(traverse_obj(slides, ('slides', ...), expected_type=dict), 1):\n                slides_info.append((\n                    slide_id, traverse_obj(slide, ('image', 'name')),\n                    traverse_obj(slide, ('image', 'extname'), default=slide_ext_default),\n                    int_or_none(slide.get('time'), scale=1000)))\n\n        if not slides and player_info.get('slides_xml_url'):\n            slides = self._download_xml(\n                player_info['slides_xml_url'], video_id, fatal=False,\n                note='Downloading slides XML', errnote='Failed to download slides info')\n            if isinstance(slides, xml.etree.ElementTree.Element):\n                slide_url_template = 'https://cdn.slideslive.com/data/presentations/%s/slides/big/%s%s'\n                for slide_id, slide in enumerate(slides.findall('./slide')):\n                    slides_info.append((\n                        slide_id, xpath_text(slide, './slideName', 'name'), '.jpg',\n                        int_or_none(xpath_text(slide, './timeSec', 'time'))))\n\n        chapters, thumbnails = [], []\n        if url_or_none(player_info.get('thumbnail')):\n            thumbnails.append({'id': 'cover', 'url': player_info['thumbnail']})\n        for slide_id, slide_path, slide_ext, start_time in slides_info:\n            if slide_path:\n                thumbnails.append({\n                    'id': f'{slide_id:03d}',\n                    'url': slide_url_template % (video_id, slide_path, slide_ext),\n                })\n            chapters.append({\n                'title': f'Slide {slide_id:03d}',\n                'start_time': start_time,\n            })\n\n        subtitles = {}\n        for sub in traverse_obj(player_info, ('subtitles', ...), expected_type=dict):\n            webvtt_url = url_or_none(sub.get('webvtt_url'))\n            if not webvtt_url:\n                continue\n            subtitles.setdefault(sub.get('language') or 'en', []).append({\n                'url': webvtt_url,\n                'ext': 'vtt',\n            })\n\n        info = {\n            'id': video_id,\n            'title': player_info.get('title') or self._html_search_meta('title', webpage, default=''),\n            'timestamp': unified_timestamp(player_info.get('timestamp')),\n            'is_live': player_info.get('playlist_type') != 'vod',\n            'thumbnails': thumbnails,\n            'chapters': chapters,\n            'subtitles': subtitles,\n        }\n\n        if service_name == 'url':\n            info['url'] = service_id\n        elif service_name == 'yoda':\n            formats, duration = self._extract_formats_and_duration(\n                player_info['video_servers'][0], service_id, video_id)\n            info.update({\n                'duration': duration,\n                'formats': formats,\n            })\n        else:\n            info.update({\n                '_type': 'url_transparent',\n                'url': service_id,\n                'ie_key': service_name.capitalize(),\n                'display_id': video_id,\n            })\n            if service_name == 'vimeo':\n                info['url'] = smuggle_url(\n                    f'https://player.vimeo.com/video/{service_id}',\n                    {'http_headers': {'Referer': url}})\n\n        video_slides = traverse_obj(slides, ('slides', ..., 'video', 'id'))\n        if not video_slides:\n            return info\n\n        def entries():\n            yield info\n\n            service_data = self._download_json(\n                f'https://ben.slideslive.com/player/{video_id}/slides_video_service_data',\n                video_id, fatal=False, query={\n                    'player_token': player_token,\n                    'videos': ','.join(video_slides),\n                }, note='Downloading video slides info', errnote='Failed to download video slides info') or {}\n\n            for slide_id, slide in enumerate(traverse_obj(slides, ('slides', ...)), 1):\n                if not traverse_obj(slide, ('video', 'service')) == 'yoda':\n                    continue\n                video_path = traverse_obj(slide, ('video', 'id'))\n                cdn_hostname = traverse_obj(service_data, (\n                    video_path, 'video_servers', ...), get_all=False)\n                if not cdn_hostname or not video_path:\n                    continue\n                formats, _ = self._extract_formats_and_duration(\n                    cdn_hostname, video_path, video_id, skip_duration=True)\n                if not formats:\n                    continue\n                yield {\n                    'id': f'{video_id}-{slide_id:03d}',\n                    'title': f'{info[\"title\"]} - Slide {slide_id:03d}',\n                    'timestamp': info['timestamp'],\n                    'duration': int_or_none(traverse_obj(slide, ('video', 'duration_ms')), scale=1000),\n                    'formats': formats,\n                }\n\n        return self.playlist_result(entries(), f'{video_id}-playlist', info['title'])\n", "import functools\n\nfrom .common import InfoExtractor\nfrom ..utils import (\n    format_field,\n    int_or_none,\n    OnDemandPagedList,\n    smuggle_url,\n)\n\n\nclass StoryFireBaseIE(InfoExtractor):\n    _VALID_URL_BASE = r'https?://(?:www\\.)?storyfire\\.com/'\n\n    def _call_api(self, path, video_id, resource, query=None):\n        return self._download_json(\n            'https://storyfire.com/app/%s/%s' % (path, video_id), video_id,\n            'Downloading %s JSON metadata' % resource, query=query)\n\n    def _parse_video(self, video):\n        title = video['title']\n        vimeo_id = self._search_regex(\n            r'https?://player\\.vimeo\\.com/external/(\\d+)',\n            video['vimeoVideoURL'], 'vimeo id')\n\n        uploader_id = video.get('hostID')\n\n        return {\n            '_type': 'url_transparent',\n            'id': vimeo_id,\n            'title': title,\n            'description': video.get('description'),\n            'url': smuggle_url(\n                'https://player.vimeo.com/video/' + vimeo_id, {\n                    'http_headers': {\n                        'Referer': 'https://storyfire.com/',\n                    }\n                }),\n            'thumbnail': video.get('storyImage'),\n            'view_count': int_or_none(video.get('views')),\n            'like_count': int_or_none(video.get('likesCount')),\n            'comment_count': int_or_none(video.get('commentsCount')),\n            'duration': int_or_none(video.get('videoDuration')),\n            'timestamp': int_or_none(video.get('publishDate')),\n            'uploader': video.get('username'),\n            'uploader_id': uploader_id,\n            'uploader_url': format_field(uploader_id, None, 'https://storyfire.com/user/%s/video'),\n            'episode_number': int_or_none(video.get('episodeNumber') or video.get('episode_number')),\n        }\n\n\nclass StoryFireIE(StoryFireBaseIE):\n    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'video-details/(?P<id>[0-9a-f]{24})'\n    _TEST = {\n        'url': 'https://storyfire.com/video-details/5df1d132b6378700117f9181',\n        'md5': 'caec54b9e4621186d6079c7ec100c1eb',\n        'info_dict': {\n            'id': '378954662',\n            'ext': 'mp4',\n            'title': 'Buzzfeed Teaches You About Memes',\n            'uploader_id': 'ntZAJFECERSgqHSxzonV5K2E89s1',\n            'timestamp': 1576129028,\n            'description': 'md5:0b4e28021548e144bed69bb7539e62ea',\n            'uploader': 'whang!',\n            'upload_date': '20191212',\n            'duration': 418,\n            'view_count': int,\n            'like_count': int,\n            'comment_count': int,\n        },\n        'params': {\n            'skip_download': True,\n        },\n        'expected_warnings': ['Unable to download JSON metadata']\n    }\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video = self._call_api(\n            'generic/video-detail', video_id, 'video')['video']\n        return self._parse_video(video)\n\n\nclass StoryFireUserIE(StoryFireBaseIE):\n    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'user/(?P<id>[^/]+)/video'\n    _TEST = {\n        'url': 'https://storyfire.com/user/UQ986nFxmAWIgnkZQ0ftVhq4nOk2/video',\n        'info_dict': {\n            'id': 'UQ986nFxmAWIgnkZQ0ftVhq4nOk2',\n        },\n        'playlist_mincount': 151,\n    }\n    _PAGE_SIZE = 20\n\n    def _fetch_page(self, user_id, page):\n        videos = self._call_api(\n            'publicVideos', user_id, 'page %d' % (page + 1), {\n                'skip': page * self._PAGE_SIZE,\n            })['videos']\n        for video in videos:\n            yield self._parse_video(video)\n\n    def _real_extract(self, url):\n        user_id = self._match_id(url)\n        entries = OnDemandPagedList(functools.partial(\n            self._fetch_page, user_id), self._PAGE_SIZE)\n        return self.playlist_result(entries, user_id)\n\n\nclass StoryFireSeriesIE(StoryFireBaseIE):\n    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'write/series/stories/(?P<id>[^/?&#]+)'\n    _TESTS = [{\n        'url': 'https://storyfire.com/write/series/stories/-Lq6MsuIHLODO6d2dDkr/',\n        'info_dict': {\n            'id': '-Lq6MsuIHLODO6d2dDkr',\n        },\n        'playlist_mincount': 13,\n    }, {\n        'url': 'https://storyfire.com/write/series/stories/the_mortal_one/',\n        'info_dict': {\n            'id': 'the_mortal_one',\n        },\n        'playlist_count': 0,\n    }]\n\n    def _extract_videos(self, stories):\n        for story in stories.values():\n            if story.get('hasVideo'):\n                yield self._parse_video(story)\n\n    def _real_extract(self, url):\n        series_id = self._match_id(url)\n        stories = self._call_api(\n            'seriesStories', series_id, 'series stories')\n        return self.playlist_result(self._extract_videos(stories), series_id)\n", "import base64\nimport functools\nimport re\nimport itertools\n\nfrom .common import InfoExtractor\nfrom ..compat import compat_str, compat_urlparse\nfrom ..networking import HEADRequest, Request\nfrom ..networking.exceptions import HTTPError\nfrom ..utils import (\n    clean_html,\n    determine_ext,\n    ExtractorError,\n    get_element_by_class,\n    js_to_json,\n    int_or_none,\n    merge_dicts,\n    OnDemandPagedList,\n    parse_filesize,\n    parse_iso8601,\n    parse_qs,\n    smuggle_url,\n    str_or_none,\n    try_get,\n    unified_timestamp,\n    unsmuggle_url,\n    urlencode_postdata,\n    urljoin,\n    urlhandle_detect_ext,\n)\n\n\nclass VimeoBaseInfoExtractor(InfoExtractor):\n    _NETRC_MACHINE = 'vimeo'\n    _LOGIN_REQUIRED = False\n    _LOGIN_URL = 'https://vimeo.com/log_in'\n\n    @staticmethod\n    def _smuggle_referrer(url, referrer_url):\n        return smuggle_url(url, {'http_headers': {'Referer': referrer_url}})\n\n    def _unsmuggle_headers(self, url):\n        \"\"\"@returns (url, smuggled_data, headers)\"\"\"\n        url, data = unsmuggle_url(url, {})\n        headers = self.get_param('http_headers').copy()\n        if 'http_headers' in data:\n            headers.update(data['http_headers'])\n        return url, data, headers\n\n    def _perform_login(self, username, password):\n        webpage = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login page')\n        token, vuid = self._extract_xsrft_and_vuid(webpage)\n        data = {\n            'action': 'login',\n            'email': username,\n            'password': password,\n            'service': 'vimeo',\n            'token': token,\n        }\n        self._set_vimeo_cookie('vuid', vuid)\n        try:\n            self._download_webpage(\n                self._LOGIN_URL, None, 'Logging in',\n                data=urlencode_postdata(data), headers={\n                    'Content-Type': 'application/x-www-form-urlencoded',\n                    'Referer': self._LOGIN_URL,\n                })\n        except ExtractorError as e:\n            if isinstance(e.cause, HTTPError) and e.cause.status == 418:\n                raise ExtractorError(\n                    'Unable to log in: bad username or password',\n                    expected=True)\n            raise ExtractorError('Unable to log in')\n\n    def _real_initialize(self):\n        if self._LOGIN_REQUIRED and not self._get_cookies('https://vimeo.com').get('vuid'):\n            self._raise_login_required()\n\n    def _get_video_password(self):\n        password = self.get_param('videopassword')\n        if password is None:\n            raise ExtractorError(\n                'This video is protected by a password, use the --video-password option',\n                expected=True)\n        return password\n\n    def _verify_video_password(self, url, video_id, password, token, vuid):\n        if url.startswith('http://'):\n            # vimeo only supports https now, but the user can give an http url\n            url = url.replace('http://', 'https://')\n        self._set_vimeo_cookie('vuid', vuid)\n        return self._download_webpage(\n            url + '/password', video_id, 'Verifying the password',\n            'Wrong password', data=urlencode_postdata({\n                'password': password,\n                'token': token,\n            }), headers={\n                'Content-Type': 'application/x-www-form-urlencoded',\n                'Referer': url,\n            })\n\n    def _extract_xsrft_and_vuid(self, webpage):\n        xsrft = self._search_regex(\n            r'(?:(?P<q1>[\"\\'])xsrft(?P=q1)\\s*:|xsrft\\s*[=:])\\s*(?P<q>[\"\\'])(?P<xsrft>.+?)(?P=q)',\n            webpage, 'login token', group='xsrft')\n        vuid = self._search_regex(\n            r'[\"\\']vuid[\"\\']\\s*:\\s*([\"\\'])(?P<vuid>.+?)\\1',\n            webpage, 'vuid', group='vuid')\n        return xsrft, vuid\n\n    def _extract_vimeo_config(self, webpage, video_id, *args, **kwargs):\n        vimeo_config = self._search_regex(\n            r'vimeo\\.config\\s*=\\s*(?:({.+?})|_extend\\([^,]+,\\s+({.+?})\\));',\n            webpage, 'vimeo config', *args, **kwargs)\n        if vimeo_config:\n            return self._parse_json(vimeo_config, video_id)\n\n    def _set_vimeo_cookie(self, name, value):\n        self._set_cookie('vimeo.com', name, value)\n\n    def _parse_config(self, config, video_id):\n        video_data = config['video']\n        video_title = video_data.get('title')\n        live_event = video_data.get('live_event') or {}\n        is_live = live_event.get('status') == 'started'\n        request = config.get('request') or {}\n\n        formats = []\n        subtitles = {}\n\n        config_files = video_data.get('files') or request.get('files') or {}\n        for f in (config_files.get('progressive') or []):\n            video_url = f.get('url')\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'format_id': 'http-%s' % f.get('quality'),\n                'source_preference': 10,\n                'width': int_or_none(f.get('width')),\n                'height': int_or_none(f.get('height')),\n                'fps': int_or_none(f.get('fps')),\n                'tbr': int_or_none(f.get('bitrate')),\n            })\n\n        # TODO: fix handling of 308 status code returned for live archive manifest requests\n        sep_pattern = r'/sep/video/'\n        for files_type in ('hls', 'dash'):\n            for cdn_name, cdn_data in (try_get(config_files, lambda x: x[files_type]['cdns']) or {}).items():\n                manifest_url = cdn_data.get('url')\n                if not manifest_url:\n                    continue\n                format_id = '%s-%s' % (files_type, cdn_name)\n                sep_manifest_urls = []\n                if re.search(sep_pattern, manifest_url):\n                    for suffix, repl in (('', 'video'), ('_sep', 'sep/video')):\n                        sep_manifest_urls.append((format_id + suffix, re.sub(\n                            sep_pattern, '/%s/' % repl, manifest_url)))\n                else:\n                    sep_manifest_urls = [(format_id, manifest_url)]\n                for f_id, m_url in sep_manifest_urls:\n                    if files_type == 'hls':\n                        fmts, subs = self._extract_m3u8_formats_and_subtitles(\n                            m_url, video_id, 'mp4', live=is_live, m3u8_id=f_id,\n                            note='Downloading %s m3u8 information' % cdn_name,\n                            fatal=False)\n                        formats.extend(fmts)\n                        self._merge_subtitles(subs, target=subtitles)\n                    elif files_type == 'dash':\n                        if 'json=1' in m_url:\n                            real_m_url = (self._download_json(m_url, video_id, fatal=False) or {}).get('url')\n                            if real_m_url:\n                                m_url = real_m_url\n                        fmts, subs = self._extract_mpd_formats_and_subtitles(\n                            m_url.replace('/master.json', '/master.mpd'), video_id, f_id,\n                            'Downloading %s MPD information' % cdn_name,\n                            fatal=False)\n                        formats.extend(fmts)\n                        self._merge_subtitles(subs, target=subtitles)\n\n        live_archive = live_event.get('archive') or {}\n        live_archive_source_url = live_archive.get('source_url')\n        if live_archive_source_url and live_archive.get('status') == 'done':\n            formats.append({\n                'format_id': 'live-archive-source',\n                'url': live_archive_source_url,\n                'quality': 10,\n            })\n\n        for tt in (request.get('text_tracks') or []):\n            subtitles.setdefault(tt['lang'], []).append({\n                'ext': 'vtt',\n                'url': urljoin('https://vimeo.com', tt['url']),\n            })\n\n        thumbnails = []\n        if not is_live:\n            for key, thumb in (video_data.get('thumbs') or {}).items():\n                thumbnails.append({\n                    'id': key,\n                    'width': int_or_none(key),\n                    'url': thumb,\n                })\n            thumbnail = video_data.get('thumbnail')\n            if thumbnail:\n                thumbnails.append({\n                    'url': thumbnail,\n                })\n\n        owner = video_data.get('owner') or {}\n        video_uploader_url = owner.get('url')\n\n        duration = int_or_none(video_data.get('duration'))\n        chapter_data = try_get(config, lambda x: x['embed']['chapters']) or []\n        chapters = [{\n            'title': current_chapter.get('title'),\n            'start_time': current_chapter.get('timecode'),\n            'end_time': next_chapter.get('timecode'),\n        } for current_chapter, next_chapter in zip(chapter_data, chapter_data[1:] + [{'timecode': duration}])]\n        if chapters and chapters[0]['start_time']:  # Chapters may not start from 0\n            chapters[:0] = [{'title': '<Untitled>', 'start_time': 0, 'end_time': chapters[0]['start_time']}]\n\n        return {\n            'id': str_or_none(video_data.get('id')) or video_id,\n            'title': video_title,\n            'uploader': owner.get('name'),\n            'uploader_id': video_uploader_url.split('/')[-1] if video_uploader_url else None,\n            'uploader_url': video_uploader_url,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'chapters': chapters or None,\n            'formats': formats,\n            'subtitles': subtitles,\n            'is_live': is_live,\n            # Note: Bitrates are completely broken. Single m3u8 may contain entries in kbps and bps\n            # at the same time without actual units specified.\n            '_format_sort_fields': ('quality', 'res', 'fps', 'hdr:12', 'source'),\n        }\n\n    def _extract_original_format(self, url, video_id, unlisted_hash=None):\n        query = {'action': 'load_download_config'}\n        if unlisted_hash:\n            query['unlisted_hash'] = unlisted_hash\n        download_data = self._download_json(\n            url, video_id, fatal=False, query=query,\n            headers={'X-Requested-With': 'XMLHttpRequest'},\n            expected_status=(403, 404)) or {}\n        source_file = download_data.get('source_file')\n        download_url = try_get(source_file, lambda x: x['download_url'])\n        if download_url and not source_file.get('is_cold') and not source_file.get('is_defrosting'):\n            source_name = source_file.get('public_name', 'Original')\n            if self._is_valid_url(download_url, video_id, '%s video' % source_name):\n                ext = (try_get(\n                    source_file, lambda x: x['extension'],\n                    compat_str) or determine_ext(\n                    download_url, None) or 'mp4').lower()\n                return {\n                    'url': download_url,\n                    'ext': ext,\n                    'width': int_or_none(source_file.get('width')),\n                    'height': int_or_none(source_file.get('height')),\n                    'filesize': parse_filesize(source_file.get('size')),\n                    'format_id': source_name,\n                    'quality': 1,\n                }\n\n        jwt_response = self._download_json(\n            'https://vimeo.com/_rv/viewer', video_id, note='Downloading jwt token', fatal=False) or {}\n        if not jwt_response.get('jwt'):\n            return\n        headers = {'Authorization': 'jwt %s' % jwt_response['jwt']}\n        original_response = self._download_json(\n            f'https://api.vimeo.com/videos/{video_id}', video_id,\n            headers=headers, fatal=False, expected_status=(403, 404)) or {}\n        for download_data in original_response.get('download') or []:\n            download_url = download_data.get('link')\n            if not download_url or download_data.get('quality') != 'source':\n                continue\n            ext = determine_ext(parse_qs(download_url).get('filename', [''])[0].lower(), default_ext=None)\n            if not ext:\n                urlh = self._request_webpage(\n                    HEADRequest(download_url), video_id, fatal=False, note='Determining source extension')\n                ext = urlh and urlhandle_detect_ext(urlh)\n            return {\n                'url': download_url,\n                'ext': ext or 'unknown_video',\n                'format_id': download_data.get('public_name', 'Original'),\n                'width': int_or_none(download_data.get('width')),\n                'height': int_or_none(download_data.get('height')),\n                'fps': int_or_none(download_data.get('fps')),\n                'filesize': int_or_none(download_data.get('size')),\n                'quality': 1,\n            }\n\n\nclass VimeoIE(VimeoBaseInfoExtractor):\n    \"\"\"Information extractor for vimeo.com.\"\"\"\n\n    # _VALID_URL matches Vimeo URLs\n    _VALID_URL = r'''(?x)\n                     https?://\n                         (?:\n                             (?:\n                                 www|\n                                 player\n                             )\n                             \\.\n                         )?\n                         vimeo\\.com/\n                         (?:\n                             (?P<u>user)|\n                             (?!(?:channels|album|showcase)/[^/?#]+/?(?:$|[?#])|[^/]+/review/|ondemand/)\n                             (?:.*?/)??\n                             (?P<q>\n                                 (?:\n                                     play_redirect_hls|\n                                     moogaloop\\.swf)\\?clip_id=\n                             )?\n                             (?:videos?/)?\n                         )\n                         (?P<id>[0-9]+)\n                         (?(u)\n                             /(?!videos|likes)[^/?#]+/?|\n                             (?(q)|/(?P<unlisted_hash>[\\da-f]{10}))?\n                         )\n                         (?:(?(q)[&]|(?(u)|/?)[?]).*?)?(?:[#].*)?$\n                 '''\n    IE_NAME = 'vimeo'\n    _EMBED_REGEX = [\n        # iframe\n        r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//player\\.vimeo\\.com/video/\\d+.*?)\\1',\n        # Embedded (swf embed) Vimeo player\n        r'<embed[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?vimeo\\.com/moogaloop\\.swf.+?)\\1',\n        # Non-standard embedded Vimeo player\n        r'<video[^>]+src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?vimeo\\.com/[0-9]+)\\1',\n    ]\n    _TESTS = [\n        {\n            'url': 'http://vimeo.com/56015672#at=0',\n            'md5': '8879b6cc097e987f02484baf890129e5',\n            'info_dict': {\n                'id': '56015672',\n                'ext': 'mp4',\n                'title': \"youtube-dl test video '' \u00e4\u21ad\ud835\udd50-BaW jenozKc\",\n                'description': 'md5:2d3305bad981a06ff79f027f19865021',\n                'timestamp': 1355990239,\n                'upload_date': '20121220',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/user7108434',\n                'uploader_id': 'user7108434',\n                'uploader': 'Filippo Valsorda',\n                'duration': 10,\n                'license': 'by-sa',\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n            },\n            'skip': 'No longer available'\n        },\n        {\n            'url': 'http://player.vimeo.com/video/54469442',\n            'md5': '619b811a4417aa4abe78dc653becf511',\n            'note': 'Videos that embed the url in the player page',\n            'info_dict': {\n                'id': '54469442',\n                'ext': 'mp4',\n                'title': 'Kathy Sierra: Building the minimum Badass User, Business of Software 2012',\n                'uploader': 'Business of Software',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/businessofsoftware',\n                'uploader_id': 'businessofsoftware',\n                'duration': 3610,\n                'description': None,\n                'thumbnail': 'https://i.vimeocdn.com/video/376682406-f34043e7b766af6bef2af81366eacd6724f3fc3173179a11a97a1e26587c9529-d_1280',\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n            },\n        },\n        {\n            'url': 'http://vimeo.com/68375962',\n            'md5': 'aaf896bdb7ddd6476df50007a0ac0ae7',\n            'note': 'Video protected with password',\n            'info_dict': {\n                'id': '68375962',\n                'ext': 'mp4',\n                'title': 'youtube-dl password protected test video',\n                'timestamp': 1371200155,\n                'upload_date': '20130614',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/user18948128',\n                'uploader_id': 'user18948128',\n                'uploader': 'Jaime Marqu\u00ednez Ferr\u00e1ndiz',\n                'duration': 10,\n                'description': 'md5:6173f270cd0c0119f22817204b3eb86c',\n                'thumbnail': 'https://i.vimeocdn.com/video/440665496-b2c5aee2b61089442c794f64113a8e8f7d5763c3e6b3ebfaf696ae6413f8b1f4-d_1280',\n                'view_count': int,\n                'comment_count': int,\n                'like_count': int,\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n                'videopassword': 'youtube-dl',\n            },\n        },\n        {\n            'url': 'http://vimeo.com/channels/keypeele/75629013',\n            'md5': '2f86a05afe9d7abc0b9126d229bbe15d',\n            'info_dict': {\n                'id': '75629013',\n                'ext': 'mp4',\n                'title': 'Key & Peele: Terrorist Interrogation',\n                'description': 'md5:6173f270cd0c0119f22817204b3eb86c',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/atencio',\n                'uploader_id': 'atencio',\n                'uploader': 'Peter Atencio',\n                'channel_id': 'keypeele',\n                'channel_url': r're:https?://(?:www\\.)?vimeo\\.com/channels/keypeele',\n                'timestamp': 1380339469,\n                'upload_date': '20130928',\n                'duration': 187,\n                'thumbnail': 'https://i.vimeocdn.com/video/450239872-a05512d9b1e55d707a7c04365c10980f327b06d966351bc403a5d5d65c95e572-d_1280',\n                'view_count': int,\n                'comment_count': int,\n                'like_count': int,\n            },\n            'params': {'format': 'http-1080p'},\n        },\n        {\n            'url': 'http://vimeo.com/76979871',\n            'note': 'Video with subtitles',\n            'info_dict': {\n                'id': '76979871',\n                'ext': 'mov',\n                'title': 'The New Vimeo Player (You Know, For Videos)',\n                'description': 'md5:2ec900bf97c3f389378a96aee11260ea',\n                'timestamp': 1381846109,\n                'upload_date': '20131015',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/staff',\n                'uploader_id': 'staff',\n                'uploader': 'Vimeo Staff',\n                'duration': 62,\n                'subtitles': {\n                    'de': [{'ext': 'vtt'}],\n                    'en': [{'ext': 'vtt'}],\n                    'es': [{'ext': 'vtt'}],\n                    'fr': [{'ext': 'vtt'}],\n                },\n            },\n            'expected_warnings': ['Ignoring subtitle tracks found in the HLS manifest'],\n        },\n        {\n            # from https://www.ouya.tv/game/Pier-Solar-and-the-Great-Architects/\n            'url': 'https://player.vimeo.com/video/98044508',\n            'note': 'The js code contains assignments to the same variable as the config',\n            'info_dict': {\n                'id': '98044508',\n                'ext': 'mp4',\n                'title': 'Pier Solar OUYA Official Trailer',\n                'uploader': 'Tulio Gon\u00e7alves',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/user28849593',\n                'uploader_id': 'user28849593',\n                'duration': 118,\n                'thumbnail': 'https://i.vimeocdn.com/video/478636036-c18440305ef3df9decfb6bf207a61fe39d2d17fa462a96f6f2d93d30492b037d-d_1280',\n            },\n        },\n        {\n            # contains original format\n            'url': 'https://vimeo.com/33951933',\n            'md5': '53c688fa95a55bf4b7293d37a89c5c53',\n            'info_dict': {\n                'id': '33951933',\n                'ext': 'mp4',\n                'title': 'FOX CLASSICS - Forever Classic ID - A Full Minute',\n                'uploader': 'The DMCI',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/dmci',\n                'uploader_id': 'dmci',\n                'timestamp': 1324343742,\n                'upload_date': '20111220',\n                'description': 'md5:ae23671e82d05415868f7ad1aec21147',\n                'duration': 60,\n                'comment_count': int,\n                'view_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/231174622-dd07f015e9221ff529d451e1cc31c982b5d87bfafa48c4189b1da72824ee289a-d_1280',\n                'like_count': int,\n            },\n        },\n        {\n            'note': 'Contains original format not accessible in webpage',\n            'url': 'https://vimeo.com/393756517',\n            'md5': 'c464af248b592190a5ffbb5d33f382b0',\n            'info_dict': {\n                'id': '393756517',\n                'ext': 'mov',\n                'timestamp': 1582642091,\n                'uploader_id': 'frameworkla',\n                'title': 'Straight To Hell - Sabrina: Netflix',\n                'uploader': 'Framework Studio',\n                'description': 'md5:f2edc61af3ea7a5592681ddbb683db73',\n                'upload_date': '20200225',\n                'duration': 176,\n                'thumbnail': 'https://i.vimeocdn.com/video/859377297-836494a4ef775e9d4edbace83937d9ad34dc846c688c0c419c0e87f7ab06c4b3-d_1280',\n                'uploader_url': 'https://vimeo.com/frameworkla',\n            },\n        },\n        {\n            # only available via https://vimeo.com/channels/tributes/6213729 and\n            # not via https://vimeo.com/6213729\n            'url': 'https://vimeo.com/channels/tributes/6213729',\n            'info_dict': {\n                'id': '6213729',\n                'ext': 'mp4',\n                'title': 'Vimeo Tribute: The Shining',\n                'uploader': 'Casey Donahue',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/caseydonahue',\n                'uploader_id': 'caseydonahue',\n                'channel_url': r're:https?://(?:www\\.)?vimeo\\.com/channels/tributes',\n                'channel_id': 'tributes',\n                'timestamp': 1250886430,\n                'upload_date': '20090821',\n                'description': 'md5:bdbf314014e58713e6e5b66eb252f4a6',\n                'duration': 321,\n                'comment_count': int,\n                'view_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/22728298-bfc22146f930de7cf497821c7b0b9f168099201ecca39b00b6bd31fcedfca7a6-d_1280',\n                'like_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # redirects to ondemand extractor and should be passed through it\n            # for successful extraction\n            'url': 'https://vimeo.com/73445910',\n            'info_dict': {\n                'id': '73445910',\n                'ext': 'mp4',\n                'title': 'The Reluctant Revolutionary',\n                'uploader': '10Ft Films',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/tenfootfilms',\n                'uploader_id': 'tenfootfilms',\n                'description': 'md5:0fa704e05b04f91f40b7f3ca2e801384',\n                'upload_date': '20130830',\n                'timestamp': 1377853339,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'this page is no longer available.',\n        },\n        {\n            'url': 'http://player.vimeo.com/video/68375962',\n            'md5': 'aaf896bdb7ddd6476df50007a0ac0ae7',\n            'info_dict': {\n                'id': '68375962',\n                'ext': 'mp4',\n                'title': 'youtube-dl password protected test video',\n                'timestamp': 1371200155,\n                'upload_date': '20130614',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/user18948128',\n                'uploader_id': 'user18948128',\n                'uploader': 'Jaime Marqu\u00ednez Ferr\u00e1ndiz',\n                'duration': 10,\n                'description': 'md5:6173f270cd0c0119f22817204b3eb86c',\n                'thumbnail': 'https://i.vimeocdn.com/video/440665496-b2c5aee2b61089442c794f64113a8e8f7d5763c3e6b3ebfaf696ae6413f8b1f4-d_1280',\n                'view_count': int,\n                'comment_count': int,\n                'like_count': int,\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n                'videopassword': 'youtube-dl',\n            },\n        },\n        {\n            'url': 'http://vimeo.com/moogaloop.swf?clip_id=2539741',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://vimeo.com/109815029',\n            'note': 'Video not completely processed, \"failed\" seed status',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://vimeo.com/groups/travelhd/videos/22439234',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://vimeo.com/album/2632481/video/79010983',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://vimeo.com/showcase/3253534/video/119195465',\n            'note': 'A video in a password protected album (showcase)',\n            'info_dict': {\n                'id': '119195465',\n                'ext': 'mp4',\n                'title': \"youtube-dl test video '' \u00e4\u21ad\ud835\udd50-BaW jenozKc\",\n                'uploader': 'Philipp Hagemeister',\n                'uploader_id': 'user20132939',\n                'description': 'md5:fa7b6c6d8db0bdc353893df2f111855b',\n                'upload_date': '20150209',\n                'timestamp': 1423518307,\n                'thumbnail': 'https://i.vimeocdn.com/video/default_1280',\n                'duration': 10,\n                'like_count': int,\n                'uploader_url': 'https://vimeo.com/user20132939',\n                'view_count': int,\n                'comment_count': int,\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n                'videopassword': 'youtube-dl',\n            },\n        },\n        {\n            # source file returns 403: Forbidden\n            'url': 'https://vimeo.com/7809605',\n            'only_matching': True,\n        },\n        {\n            'note': 'Direct URL with hash',\n            'url': 'https://vimeo.com/160743502/abd0e13fb4',\n            'info_dict': {\n                'id': '160743502',\n                'ext': 'mp4',\n                'uploader': 'Julian Tryba',\n                'uploader_id': 'aliniamedia',\n                'title': 'Harrisville New Hampshire',\n                'timestamp': 1459259666,\n                'upload_date': '20160329',\n                'release_timestamp': 1459259666,\n                'license': 'by-nc',\n                'duration': 159,\n                'comment_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/562802436-585eeb13b5020c6ac0f171a2234067938098f84737787df05ff0d767f6d54ee9-d_1280',\n                'like_count': int,\n                'uploader_url': 'https://vimeo.com/aliniamedia',\n                'release_date': '20160329',\n            },\n            'params': {'skip_download': True},\n        },\n        {\n            'url': 'https://vimeo.com/138909882',\n            'info_dict': {\n                'id': '138909882',\n                'ext': 'mp4',\n                'title': 'Eastnor Castle 2015 Firework Champions - The Promo!',\n                'description': 'md5:5967e090768a831488f6e74b7821b3c1',\n                'uploader_id': 'fireworkchampions',\n                'uploader': 'Firework Champions',\n                'upload_date': '20150910',\n                'timestamp': 1441901895,\n            },\n            'params': {\n                'skip_download': True,\n                'format': 'Original',\n            },\n        },\n        {\n            'url': 'https://vimeo.com/channels/staffpicks/143603739',\n            'info_dict': {\n                'id': '143603739',\n                'ext': 'mp4',\n                'uploader': 'Karim Huu Do',\n                'timestamp': 1445846953,\n                'upload_date': '20151026',\n                'title': 'The Shoes - Submarine Feat. Blaine Harrison',\n                'uploader_id': 'karimhd',\n                'description': 'md5:8e2eea76de4504c2e8020a9bcfa1e843',\n                'channel_id': 'staffpicks',\n                'duration': 336,\n                'comment_count': int,\n                'view_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/541243181-b593db36a16db2f0096f655da3f5a4dc46b8766d77b0f440df937ecb0c418347-d_1280',\n                'like_count': int,\n                'uploader_url': 'https://vimeo.com/karimhd',\n                'channel_url': 'https://vimeo.com/channels/staffpicks',\n            },\n            'params': {'skip_download': 'm3u8'},\n        },\n        {\n            # requires passing unlisted_hash(a52724358e) to load_download_config request\n            'url': 'https://vimeo.com/392479337/a52724358e',\n            'only_matching': True,\n        },\n        {\n            # similar, but all numeric: ID must be 581039021, not 9603038895\n            # issue #29690\n            'url': 'https://vimeo.com/581039021/9603038895',\n            'info_dict': {\n                'id': '581039021',\n                'ext': 'mp4',\n                'timestamp': 1627621014,\n                'release_timestamp': 1627621014,\n                'duration': 976,\n                'comment_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/1202249320-4ddb2c30398c0dc0ee059172d1bd5ea481ad12f0e0e3ad01d2266f56c744b015-d_1280',\n                'like_count': int,\n                'uploader_url': 'https://vimeo.com/txwestcapital',\n                'release_date': '20210730',\n                'uploader': 'Christopher Inks',\n                'title': 'Thursday, July 29, 2021 BMA Evening Video Update',\n                'uploader_id': 'txwestcapital',\n                'upload_date': '20210730',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # user playlist alias -> https://vimeo.com/258705797\n            'url': 'https://vimeo.com/user26785108/newspiritualguide',\n            'only_matching': True,\n        },\n        # https://gettingthingsdone.com/workflowmap/\n        # vimeo embed with check-password page protected by Referer header\n    ]\n\n    @classmethod\n    def _extract_embed_urls(cls, url, webpage):\n        for embed_url in super()._extract_embed_urls(url, webpage):\n            yield cls._smuggle_referrer(embed_url, url)\n\n    @classmethod\n    def _extract_url(cls, url, webpage):\n        return next(cls._extract_embed_urls(url, webpage), None)\n\n    def _verify_player_video_password(self, url, video_id, headers):\n        password = self._get_video_password()\n        data = urlencode_postdata({\n            'password': base64.b64encode(password.encode()),\n        })\n        headers = merge_dicts(headers, {\n            'Content-Type': 'application/x-www-form-urlencoded',\n        })\n        checked = self._download_json(\n            f'{compat_urlparse.urlsplit(url)._replace(query=None).geturl()}/check-password',\n            video_id, 'Verifying the password', data=data, headers=headers)\n        if checked is False:\n            raise ExtractorError('Wrong video password', expected=True)\n        return checked\n\n    def _extract_from_api(self, video_id, unlisted_hash=None):\n        token = self._download_json(\n            'https://vimeo.com/_rv/jwt', video_id, headers={\n                'X-Requested-With': 'XMLHttpRequest'\n            })['token']\n        api_url = 'https://api.vimeo.com/videos/' + video_id\n        if unlisted_hash:\n            api_url += ':' + unlisted_hash\n        video = self._download_json(\n            api_url, video_id, headers={\n                'Authorization': 'jwt ' + token,\n            }, query={\n                'fields': 'config_url,created_time,description,license,metadata.connections.comments.total,metadata.connections.likes.total,release_time,stats.plays',\n            })\n        info = self._parse_config(self._download_json(\n            video['config_url'], video_id), video_id)\n        get_timestamp = lambda x: parse_iso8601(video.get(x + '_time'))\n        info.update({\n            'description': video.get('description'),\n            'license': video.get('license'),\n            'release_timestamp': get_timestamp('release'),\n            'timestamp': get_timestamp('created'),\n            'view_count': int_or_none(try_get(video, lambda x: x['stats']['plays'])),\n        })\n        connections = try_get(\n            video, lambda x: x['metadata']['connections'], dict) or {}\n        for k in ('comment', 'like'):\n            info[k + '_count'] = int_or_none(try_get(connections, lambda x: x[k + 's']['total']))\n        return info\n\n    def _try_album_password(self, url):\n        album_id = self._search_regex(\n            r'vimeo\\.com/(?:album|showcase)/([^/]+)', url, 'album id', default=None)\n        if not album_id:\n            return\n        viewer = self._download_json(\n            'https://vimeo.com/_rv/viewer', album_id, fatal=False)\n        if not viewer:\n            webpage = self._download_webpage(url, album_id)\n            viewer = self._parse_json(self._search_regex(\n                r'bootstrap_data\\s*=\\s*({.+?})</script>',\n                webpage, 'bootstrap data'), album_id)['viewer']\n        jwt = viewer['jwt']\n        album = self._download_json(\n            'https://api.vimeo.com/albums/' + album_id,\n            album_id, headers={'Authorization': 'jwt ' + jwt},\n            query={'fields': 'description,name,privacy'})\n        if try_get(album, lambda x: x['privacy']['view']) == 'password':\n            password = self.get_param('videopassword')\n            if not password:\n                raise ExtractorError(\n                    'This album is protected by a password, use the --video-password option',\n                    expected=True)\n            self._set_vimeo_cookie('vuid', viewer['vuid'])\n            try:\n                self._download_json(\n                    'https://vimeo.com/showcase/%s/auth' % album_id,\n                    album_id, 'Verifying the password', data=urlencode_postdata({\n                        'password': password,\n                        'token': viewer['xsrft'],\n                    }), headers={\n                        'X-Requested-With': 'XMLHttpRequest',\n                    })\n            except ExtractorError as e:\n                if isinstance(e.cause, HTTPError) and e.cause.status == 401:\n                    raise ExtractorError('Wrong password', expected=True)\n                raise\n\n    def _real_extract(self, url):\n        url, data, headers = self._unsmuggle_headers(url)\n        if 'Referer' not in headers:\n            headers['Referer'] = url\n\n        # Extract ID from URL\n        mobj = self._match_valid_url(url).groupdict()\n        video_id, unlisted_hash = mobj['id'], mobj.get('unlisted_hash')\n        if unlisted_hash:\n            return self._extract_from_api(video_id, unlisted_hash)\n\n        if any(p in url for p in ('play_redirect_hls', 'moogaloop.swf')):\n            url = 'https://vimeo.com/' + video_id\n\n        self._try_album_password(url)\n        try:\n            # Retrieve video webpage to extract further information\n            webpage, urlh = self._download_webpage_handle(\n                url, video_id, headers=headers)\n            redirect_url = urlh.url\n        except ExtractorError as ee:\n            if isinstance(ee.cause, HTTPError) and ee.cause.status == 403:\n                errmsg = ee.cause.response.read()\n                if b'Because of its privacy settings, this video cannot be played here' in errmsg:\n                    raise ExtractorError(\n                        'Cannot download embed-only video without embedding '\n                        'URL. Please call yt-dlp with the URL of the page '\n                        'that embeds this video.',\n                        expected=True)\n            raise\n\n        if '://player.vimeo.com/video/' in url:\n            config = self._search_json(\n                r'\\b(?:playerC|c)onfig\\s*=', webpage, 'info section', video_id)\n            if config.get('view') == 4:\n                config = self._verify_player_video_password(\n                    redirect_url, video_id, headers)\n            return self._parse_config(config, video_id)\n\n        if re.search(r'<form[^>]+?id=\"pw_form\"', webpage):\n            video_password = self._get_video_password()\n            token, vuid = self._extract_xsrft_and_vuid(webpage)\n            webpage = self._verify_video_password(\n                redirect_url, video_id, video_password, token, vuid)\n\n        vimeo_config = self._extract_vimeo_config(webpage, video_id, default=None)\n        if vimeo_config:\n            seed_status = vimeo_config.get('seed_status') or {}\n            if seed_status.get('state') == 'failed':\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, seed_status['title']),\n                    expected=True)\n\n        cc_license = None\n        timestamp = None\n        video_description = None\n        info_dict = {}\n        config_url = None\n\n        channel_id = self._search_regex(\n            r'vimeo\\.com/channels/([^/]+)', url, 'channel id', default=None)\n        if channel_id:\n            config_url = self._html_search_regex(\n                r'\\bdata-config-url=\"([^\"]+)\"', webpage, 'config URL', default=None)\n            video_description = clean_html(get_element_by_class('description', webpage))\n            info_dict.update({\n                'channel_id': channel_id,\n                'channel_url': 'https://vimeo.com/channels/' + channel_id,\n            })\n        if not config_url:\n            page_config = self._parse_json(self._search_regex(\n                r'vimeo\\.(?:clip|vod_title)_page_config\\s*=\\s*({.+?});',\n                webpage, 'page config', default='{}'), video_id, fatal=False)\n            if not page_config:\n                return self._extract_from_api(video_id)\n            config_url = page_config['player']['config_url']\n            cc_license = page_config.get('cc_license')\n            clip = page_config.get('clip') or {}\n            timestamp = clip.get('uploaded_on')\n            video_description = clean_html(\n                clip.get('description') or page_config.get('description_html_escaped'))\n        config = self._download_json(config_url, video_id)\n        video = config.get('video') or {}\n        vod = video.get('vod') or {}\n\n        def is_rented():\n            if '>You rented this title.<' in webpage:\n                return True\n            if try_get(config, lambda x: x['user']['purchased']):\n                return True\n            for purchase_option in (vod.get('purchase_options') or []):\n                if purchase_option.get('purchased'):\n                    return True\n                label = purchase_option.get('label_string')\n                if label and (label.startswith('You rented this') or label.endswith(' remaining')):\n                    return True\n            return False\n\n        if is_rented() and vod.get('is_trailer'):\n            feature_id = vod.get('feature_id')\n            if feature_id and not data.get('force_feature_id', False):\n                return self.url_result(smuggle_url(\n                    'https://player.vimeo.com/player/%s' % feature_id,\n                    {'force_feature_id': True}), 'Vimeo')\n\n        if not video_description:\n            video_description = self._html_search_regex(\n                r'(?s)<div\\s+class=\"[^\"]*description[^\"]*\"[^>]*>(.*?)</div>',\n                webpage, 'description', default=None)\n        if not video_description:\n            video_description = self._html_search_meta(\n                ['description', 'og:description', 'twitter:description'],\n                webpage, default=None)\n        if not video_description:\n            self.report_warning('Cannot find video description')\n\n        if not timestamp:\n            timestamp = self._search_regex(\n                r'<time[^>]+datetime=\"([^\"]+)\"', webpage,\n                'timestamp', default=None)\n\n        view_count = int_or_none(self._search_regex(r'UserPlays:(\\d+)', webpage, 'view count', default=None))\n        like_count = int_or_none(self._search_regex(r'UserLikes:(\\d+)', webpage, 'like count', default=None))\n        comment_count = int_or_none(self._search_regex(r'UserComments:(\\d+)', webpage, 'comment count', default=None))\n\n        formats = []\n\n        source_format = self._extract_original_format(\n            'https://vimeo.com/' + video_id, video_id, video.get('unlisted_hash'))\n        if source_format:\n            formats.append(source_format)\n\n        info_dict_config = self._parse_config(config, video_id)\n        formats.extend(info_dict_config['formats'])\n        info_dict['_format_sort_fields'] = info_dict_config['_format_sort_fields']\n\n        json_ld = self._search_json_ld(webpage, video_id, default={})\n\n        if not cc_license:\n            cc_license = self._search_regex(\n                r'<link[^>]+rel=[\"\\']license[\"\\'][^>]+href=([\"\\'])(?P<license>(?:(?!\\1).)+)\\1',\n                webpage, 'license', default=None, group='license')\n\n        info_dict.update({\n            'formats': formats,\n            'timestamp': unified_timestamp(timestamp),\n            'description': video_description,\n            'webpage_url': url,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'license': cc_license,\n        })\n\n        return merge_dicts(info_dict, info_dict_config, json_ld)\n\n\nclass VimeoOndemandIE(VimeoIE):  # XXX: Do not subclass from concrete IE\n    IE_NAME = 'vimeo:ondemand'\n    _VALID_URL = r'https?://(?:www\\.)?vimeo\\.com/ondemand/(?:[^/]+/)?(?P<id>[^/?#&]+)'\n    _TESTS = [{\n        # ondemand video not available via https://vimeo.com/id\n        'url': 'https://vimeo.com/ondemand/20704',\n        'md5': 'c424deda8c7f73c1dfb3edd7630e2f35',\n        'info_dict': {\n            'id': '105442900',\n            'ext': 'mp4',\n            'title': '\u05d4\u05de\u05e2\u05d1\u05d3\u05d4 - \u05d1\u05de\u05d0\u05d9 \u05d9\u05d5\u05ea\u05dd \u05e4\u05dc\u05d3\u05de\u05df',\n            'uploader': '\u05d2\u05dd \u05e1\u05e8\u05d8\u05d9\u05dd',\n            'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/gumfilms',\n            'uploader_id': 'gumfilms',\n            'description': 'md5:aeeba3dbd4d04b0fa98a4fdc9c639998',\n            'upload_date': '20140906',\n            'timestamp': 1410032453,\n            'thumbnail': 'https://i.vimeocdn.com/video/488238335-d7bf151c364cff8d467f1b73784668fe60aae28a54573a35d53a1210ae283bd8-d_1280',\n            'comment_count': int,\n            'license': 'https://creativecommons.org/licenses/by-nc-nd/3.0/',\n            'duration': 53,\n            'view_count': int,\n            'like_count': int,\n        },\n        'params': {\n            'format': 'best[protocol=https]',\n        },\n        'expected_warnings': ['Unable to download JSON metadata'],\n    }, {\n        # requires Referer to be passed along with og:video:url\n        'url': 'https://vimeo.com/ondemand/36938/126682985',\n        'info_dict': {\n            'id': '126584684',\n            'ext': 'mp4',\n            'title': 'R\u00e4vlock, r\u00e4tt l\u00e4te p\u00e5 r\u00e4tt plats',\n            'uploader': 'Lindroth & Norin',\n            'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/lindrothnorin',\n            'uploader_id': 'lindrothnorin',\n            'description': 'md5:c3c46a90529612c8279fb6af803fc0df',\n            'upload_date': '20150502',\n            'timestamp': 1430586422,\n            'duration': 121,\n            'comment_count': int,\n            'view_count': int,\n            'thumbnail': 'https://i.vimeocdn.com/video/517077723-7066ae1d9a79d3eb361334fb5d58ec13c8f04b52f8dd5eadfbd6fb0bcf11f613-d_1280',\n            'like_count': int,\n        },\n        'params': {\n            'skip_download': True,\n        },\n        'expected_warnings': ['Unable to download JSON metadata'],\n    }, {\n        'url': 'https://vimeo.com/ondemand/nazmaalik',\n        'only_matching': True,\n    }, {\n        'url': 'https://vimeo.com/ondemand/141692381',\n        'only_matching': True,\n    }, {\n        'url': 'https://vimeo.com/ondemand/thelastcolony/150274832',\n        'only_matching': True,\n    }]\n\n\nclass VimeoChannelIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vimeo:channel'\n    _VALID_URL = r'https://vimeo\\.com/channels/(?P<id>[^/?#]+)/?(?:$|[?#])'\n    _MORE_PAGES_INDICATOR = r'<a.+?rel=\"next\"'\n    _TITLE = None\n    _TITLE_RE = r'<link rel=\"alternate\"[^>]+?title=\"(.*?)\"'\n    _TESTS = [{\n        'url': 'https://vimeo.com/channels/tributes',\n        'info_dict': {\n            'id': 'tributes',\n            'title': 'Vimeo Tributes',\n        },\n        'playlist_mincount': 22,\n    }]\n    _BASE_URL_TEMPL = 'https://vimeo.com/channels/%s'\n\n    def _page_url(self, base_url, pagenum):\n        return '%s/videos/page:%d/' % (base_url, pagenum)\n\n    def _extract_list_title(self, webpage):\n        return self._TITLE or self._html_search_regex(\n            self._TITLE_RE, webpage, 'list title', fatal=False)\n\n    def _title_and_entries(self, list_id, base_url):\n        for pagenum in itertools.count(1):\n            page_url = self._page_url(base_url, pagenum)\n            webpage = self._download_webpage(\n                page_url, list_id,\n                'Downloading page %s' % pagenum)\n\n            if pagenum == 1:\n                yield self._extract_list_title(webpage)\n\n            # Try extracting href first since not all videos are available via\n            # short https://vimeo.com/id URL (e.g. https://vimeo.com/channels/tributes/6213729)\n            clips = re.findall(\n                r'id=\"clip_(\\d+)\"[^>]*>\\s*<a[^>]+href=\"(/(?:[^/]+/)*\\1)(?:[^>]+\\btitle=\"([^\"]+)\")?', webpage)\n            if clips:\n                for video_id, video_url, video_title in clips:\n                    yield self.url_result(\n                        compat_urlparse.urljoin(base_url, video_url),\n                        VimeoIE.ie_key(), video_id=video_id, video_title=video_title)\n            # More relaxed fallback\n            else:\n                for video_id in re.findall(r'id=[\"\\']clip_(\\d+)', webpage):\n                    yield self.url_result(\n                        'https://vimeo.com/%s' % video_id,\n                        VimeoIE.ie_key(), video_id=video_id)\n\n            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:\n                break\n\n    def _extract_videos(self, list_id, base_url):\n        title_and_entries = self._title_and_entries(list_id, base_url)\n        list_title = next(title_and_entries)\n        return self.playlist_result(title_and_entries, list_id, list_title)\n\n    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n        return self._extract_videos(channel_id, self._BASE_URL_TEMPL % channel_id)\n\n\nclass VimeoUserIE(VimeoChannelIE):  # XXX: Do not subclass from concrete IE\n    IE_NAME = 'vimeo:user'\n    _VALID_URL = r'https://vimeo\\.com/(?!(?:[0-9]+|watchlater)(?:$|[?#/]))(?P<id>[^/]+)(?:/videos)?/?(?:$|[?#])'\n    _TITLE_RE = r'<a[^>]+?class=\"user\">([^<>]+?)</a>'\n    _TESTS = [{\n        'url': 'https://vimeo.com/nkistudio/videos',\n        'info_dict': {\n            'title': 'Nki',\n            'id': 'nkistudio',\n        },\n        'playlist_mincount': 66,\n    }, {\n        'url': 'https://vimeo.com/nkistudio/',\n        'only_matching': True,\n    }]\n    _BASE_URL_TEMPL = 'https://vimeo.com/%s'\n\n\nclass VimeoAlbumIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vimeo:album'\n    _VALID_URL = r'https://vimeo\\.com/(?:album|showcase)/(?P<id>\\d+)(?:$|[?#]|/(?!video))'\n    _TITLE_RE = r'<header id=\"page_header\">\\n\\s*<h1>(.*?)</h1>'\n    _TESTS = [{\n        'url': 'https://vimeo.com/album/2632481',\n        'info_dict': {\n            'id': '2632481',\n            'title': 'Staff Favorites: November 2013',\n        },\n        'playlist_mincount': 13,\n    }, {\n        'note': 'Password-protected album',\n        'url': 'https://vimeo.com/album/3253534',\n        'info_dict': {\n            'title': 'test',\n            'id': '3253534',\n        },\n        'playlist_count': 1,\n        'params': {\n            'videopassword': 'youtube-dl',\n        }\n    }]\n    _PAGE_SIZE = 100\n\n    def _fetch_page(self, album_id, authorization, hashed_pass, page):\n        api_page = page + 1\n        query = {\n            'fields': 'link,uri',\n            'page': api_page,\n            'per_page': self._PAGE_SIZE,\n        }\n        if hashed_pass:\n            query['_hashed_pass'] = hashed_pass\n        try:\n            videos = self._download_json(\n                'https://api.vimeo.com/albums/%s/videos' % album_id,\n                album_id, 'Downloading page %d' % api_page, query=query, headers={\n                    'Authorization': 'jwt ' + authorization,\n                })['data']\n        except ExtractorError as e:\n            if isinstance(e.cause, HTTPError) and e.cause.status == 400:\n                return\n        for video in videos:\n            link = video.get('link')\n            if not link:\n                continue\n            uri = video.get('uri')\n            video_id = self._search_regex(r'/videos/(\\d+)', uri, 'video_id', default=None) if uri else None\n            yield self.url_result(link, VimeoIE.ie_key(), video_id)\n\n    def _real_extract(self, url):\n        album_id = self._match_id(url)\n        viewer = self._download_json(\n            'https://vimeo.com/_rv/viewer', album_id, fatal=False)\n        if not viewer:\n            webpage = self._download_webpage(url, album_id)\n            viewer = self._parse_json(self._search_regex(\n                r'bootstrap_data\\s*=\\s*({.+?})</script>',\n                webpage, 'bootstrap data'), album_id)['viewer']\n        jwt = viewer['jwt']\n        album = self._download_json(\n            'https://api.vimeo.com/albums/' + album_id,\n            album_id, headers={'Authorization': 'jwt ' + jwt},\n            query={'fields': 'description,name,privacy'})\n        hashed_pass = None\n        if try_get(album, lambda x: x['privacy']['view']) == 'password':\n            password = self.get_param('videopassword')\n            if not password:\n                raise ExtractorError(\n                    'This album is protected by a password, use the --video-password option',\n                    expected=True)\n            self._set_vimeo_cookie('vuid', viewer['vuid'])\n            try:\n                hashed_pass = self._download_json(\n                    'https://vimeo.com/showcase/%s/auth' % album_id,\n                    album_id, 'Verifying the password', data=urlencode_postdata({\n                        'password': password,\n                        'token': viewer['xsrft'],\n                    }), headers={\n                        'X-Requested-With': 'XMLHttpRequest',\n                    })['hashed_pass']\n            except ExtractorError as e:\n                if isinstance(e.cause, HTTPError) and e.cause.status == 401:\n                    raise ExtractorError('Wrong password', expected=True)\n                raise\n        entries = OnDemandPagedList(functools.partial(\n            self._fetch_page, album_id, jwt, hashed_pass), self._PAGE_SIZE)\n        return self.playlist_result(\n            entries, album_id, album.get('name'), album.get('description'))\n\n\nclass VimeoGroupsIE(VimeoChannelIE):  # XXX: Do not subclass from concrete IE\n    IE_NAME = 'vimeo:group'\n    _VALID_URL = r'https://vimeo\\.com/groups/(?P<id>[^/]+)(?:/(?!videos?/\\d+)|$)'\n    _TESTS = [{\n        'url': 'https://vimeo.com/groups/meetup',\n        'info_dict': {\n            'id': 'meetup',\n            'title': 'Vimeo Meetup!',\n        },\n        'playlist_mincount': 27,\n    }]\n    _BASE_URL_TEMPL = 'https://vimeo.com/groups/%s'\n\n\nclass VimeoReviewIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vimeo:review'\n    IE_DESC = 'Review pages on vimeo'\n    _VALID_URL = r'(?P<url>https://vimeo\\.com/[^/]+/review/(?P<id>[^/]+)/[0-9a-f]{10})'\n    _TESTS = [{\n        'url': 'https://vimeo.com/user21297594/review/75524534/3c257a1b5d',\n        'md5': 'c507a72f780cacc12b2248bb4006d253',\n        'info_dict': {\n            'id': '75524534',\n            'ext': 'mp4',\n            'title': \"DICK HARDWICK 'Comedian'\",\n            'uploader': 'Richard Hardwick',\n            'uploader_id': 'user21297594',\n            'description': \"Comedian Dick Hardwick's five minute demo filmed in front of a live theater audience.\\nEdit by Doug Mattocks\",\n            'duration': 304,\n            'thumbnail': 'https://i.vimeocdn.com/video/450115033-43303819d9ebe24c2630352e18b7056d25197d09b3ae901abdac4c4f1d68de71-d_1280',\n            'uploader_url': 'https://vimeo.com/user21297594',\n        },\n    }, {\n        'note': 'video player needs Referer',\n        'url': 'https://vimeo.com/user22258446/review/91613211/13f927e053',\n        'md5': '6295fdab8f4bf6a002d058b2c6dce276',\n        'info_dict': {\n            'id': '91613211',\n            'ext': 'mp4',\n            'title': 're:(?i)^Death by dogma versus assembling agile . Sander Hoogendoorn',\n            'uploader': 'DevWeek Events',\n            'duration': 2773,\n            'thumbnail': r're:^https?://.*\\.jpg$',\n            'uploader_id': 'user22258446',\n        },\n        'skip': 'video gone',\n    }, {\n        'note': 'Password protected',\n        'url': 'https://vimeo.com/user37284429/review/138823582/c4d865efde',\n        'info_dict': {\n            'id': '138823582',\n            'ext': 'mp4',\n            'title': 'EFFICIENT PICKUP MASTERCLASS MODULE 1',\n            'uploader': 'TMB',\n            'uploader_id': 'user37284429',\n        },\n        'params': {\n            'videopassword': 'holygrail',\n        },\n        'skip': 'video gone',\n    }]\n\n    def _real_extract(self, url):\n        page_url, video_id = self._match_valid_url(url).groups()\n        data = self._download_json(\n            page_url.replace('/review/', '/review/data/'), video_id)\n        if data.get('isLocked') is True:\n            video_password = self._get_video_password()\n            viewer = self._download_json(\n                'https://vimeo.com/_rv/viewer', video_id)\n            webpage = self._verify_video_password(\n                'https://vimeo.com/' + video_id, video_id,\n                video_password, viewer['xsrft'], viewer['vuid'])\n            clip_page_config = self._parse_json(self._search_regex(\n                r'window\\.vimeo\\.clip_page_config\\s*=\\s*({.+?});',\n                webpage, 'clip page config'), video_id)\n            config_url = clip_page_config['player']['config_url']\n            clip_data = clip_page_config.get('clip') or {}\n        else:\n            clip_data = data['clipData']\n            config_url = clip_data['configUrl']\n        config = self._download_json(config_url, video_id)\n        info_dict = self._parse_config(config, video_id)\n        source_format = self._extract_original_format(\n            page_url + '/action', video_id)\n        if source_format:\n            info_dict['formats'].append(source_format)\n        info_dict['description'] = clean_html(clip_data.get('description'))\n        return info_dict\n\n\nclass VimeoWatchLaterIE(VimeoChannelIE):  # XXX: Do not subclass from concrete IE\n    IE_NAME = 'vimeo:watchlater'\n    IE_DESC = 'Vimeo watch later list, \":vimeowatchlater\" keyword (requires authentication)'\n    _VALID_URL = r'https://vimeo\\.com/(?:home/)?watchlater|:vimeowatchlater'\n    _TITLE = 'Watch Later'\n    _LOGIN_REQUIRED = True\n    _TESTS = [{\n        'url': 'https://vimeo.com/watchlater',\n        'only_matching': True,\n    }]\n\n    def _page_url(self, base_url, pagenum):\n        url = '%s/page:%d/' % (base_url, pagenum)\n        request = Request(url)\n        # Set the header to get a partial html page with the ids,\n        # the normal page doesn't contain them.\n        request.headers['X-Requested-With'] = 'XMLHttpRequest'\n        return request\n\n    def _real_extract(self, url):\n        return self._extract_videos('watchlater', 'https://vimeo.com/watchlater')\n\n\nclass VimeoLikesIE(VimeoChannelIE):  # XXX: Do not subclass from concrete IE\n    _VALID_URL = r'https://(?:www\\.)?vimeo\\.com/(?P<id>[^/]+)/likes/?(?:$|[?#]|sort:)'\n    IE_NAME = 'vimeo:likes'\n    IE_DESC = 'Vimeo user likes'\n    _TESTS = [{\n        'url': 'https://vimeo.com/user755559/likes/',\n        'playlist_mincount': 293,\n        'info_dict': {\n            'id': 'user755559',\n            'title': 'urza\u2019s Likes',\n        },\n    }, {\n        'url': 'https://vimeo.com/stormlapse/likes',\n        'only_matching': True,\n    }]\n\n    def _page_url(self, base_url, pagenum):\n        return '%s/page:%d/' % (base_url, pagenum)\n\n    def _real_extract(self, url):\n        user_id = self._match_id(url)\n        return self._extract_videos(user_id, 'https://vimeo.com/%s/likes' % user_id)\n\n\nclass VHXEmbedIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vhx:embed'\n    _VALID_URL = r'https?://embed\\.vhx\\.tv/videos/(?P<id>\\d+)'\n    _EMBED_REGEX = [r'<iframe[^>]+src=\"(?P<url>https?://embed\\.vhx\\.tv/videos/\\d+[^\"]*)\"']\n\n    @classmethod\n    def _extract_embed_urls(cls, url, webpage):\n        for embed_url in super()._extract_embed_urls(url, webpage):\n            yield cls._smuggle_referrer(embed_url, url)\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        url, _, headers = self._unsmuggle_headers(url)\n        webpage = self._download_webpage(url, video_id, headers=headers)\n        config_url = self._parse_json(self._search_regex(\n            r'window\\.OTTData\\s*=\\s*({.+})', webpage,\n            'ott data'), video_id, js_to_json)['config_url']\n        config = self._download_json(config_url, video_id)\n        info = self._parse_config(config, video_id)\n        info['id'] = video_id\n        return info\n\n\nclass VimeoProIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vimeo:pro'\n    _VALID_URL = r'https?://(?:www\\.)?vimeopro\\.com/[^/?#]+/(?P<slug>[^/?#]+)(?:(?:/videos?/(?P<id>[0-9]+)))?'\n    _TESTS = [{\n        # Vimeo URL derived from video_id\n        'url': 'http://vimeopro.com/openstreetmapus/state-of-the-map-us-2013/video/68093876',\n        'md5': '3b5ca6aa22b60dfeeadf50b72e44ed82',\n        'note': 'Vimeo Pro video (#1197)',\n        'info_dict': {\n            'id': '68093876',\n            'ext': 'mp4',\n            'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/openstreetmapus',\n            'uploader_id': 'openstreetmapus',\n            'uploader': 'OpenStreetMap US',\n            'title': 'Andy Allan - Putting the Carto into OpenStreetMap Cartography',\n            'description': 'md5:2c362968038d4499f4d79f88458590c1',\n            'duration': 1595,\n            'upload_date': '20130610',\n            'timestamp': 1370893156,\n            'license': 'by',\n            'thumbnail': 'https://i.vimeocdn.com/video/440260469-19b0d92fca3bd84066623b53f1eb8aaa3980c6c809e2d67b6b39ab7b4a77a344-d_960',\n            'view_count': int,\n            'comment_count': int,\n            'like_count': int,\n            'tags': 'count:1',\n        },\n        'params': {\n            'format': 'best[protocol=https]',\n        },\n    }, {\n        # password-protected VimeoPro page with Vimeo player embed\n        'url': 'https://vimeopro.com/cadfem/simulation-conference-mechanische-systeme-in-perfektion',\n        'info_dict': {\n            'id': '764543723',\n            'ext': 'mp4',\n            'title': 'Mechanische Systeme in Perfektion: Realit\u00e4t erfassen, Innovation treiben',\n            'thumbnail': 'https://i.vimeocdn.com/video/1543784598-a1a750494a485e601110136b9fe11e28c2131942452b3a5d30391cb3800ca8fd-d_1280',\n            'description': 'md5:2a9d195cd1b0f6f79827107dc88c2420',\n            'uploader': 'CADFEM',\n            'uploader_id': 'cadfem',\n            'uploader_url': 'https://vimeo.com/cadfem',\n            'duration': 12505,\n            'chapters': 'count:10',\n        },\n        'params': {\n            'videopassword': 'Conference2022',\n            'skip_download': True,\n        },\n    }]\n\n    def _real_extract(self, url):\n        display_id, video_id = self._match_valid_url(url).group('slug', 'id')\n        if video_id:\n            display_id = video_id\n        webpage = self._download_webpage(url, display_id)\n\n        password_form = self._search_regex(\n            r'(?is)<form[^>]+?method=[\"\\']post[\"\\'][^>]*>(.+?password.+?)</form>',\n            webpage, 'password form', default=None)\n        if password_form:\n            try:\n                webpage = self._download_webpage(url, display_id, data=urlencode_postdata({\n                    'password': self._get_video_password(),\n                    **self._hidden_inputs(password_form),\n                }), note='Logging in with video password')\n            except ExtractorError as e:\n                if isinstance(e.cause, HTTPError) and e.cause.status == 418:\n                    raise ExtractorError('Wrong video password', expected=True)\n                raise\n\n        description = None\n        # even if we have video_id, some videos require player URL with portfolio_id query param\n        # https://github.com/ytdl-org/youtube-dl/issues/20070\n        vimeo_url = VimeoIE._extract_url(url, webpage)\n        if vimeo_url:\n            description = self._html_search_meta('description', webpage, default=None)\n        elif video_id:\n            vimeo_url = f'https://vimeo.com/{video_id}'\n        else:\n            raise ExtractorError(\n                'No Vimeo embed or video ID could be found in VimeoPro page', expected=True)\n\n        return self.url_result(vimeo_url, VimeoIE, video_id, url_transparent=True,\n                               description=description)\n", "import collections\nimport random\nimport urllib.parse\nimport urllib.request\n\nfrom ._utils import remove_start\n\n\ndef random_user_agent():\n    _USER_AGENT_TPL = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/%s Safari/537.36'\n    _CHROME_VERSIONS = (\n        '90.0.4430.212',\n        '90.0.4430.24',\n        '90.0.4430.70',\n        '90.0.4430.72',\n        '90.0.4430.85',\n        '90.0.4430.93',\n        '91.0.4472.101',\n        '91.0.4472.106',\n        '91.0.4472.114',\n        '91.0.4472.124',\n        '91.0.4472.164',\n        '91.0.4472.19',\n        '91.0.4472.77',\n        '92.0.4515.107',\n        '92.0.4515.115',\n        '92.0.4515.131',\n        '92.0.4515.159',\n        '92.0.4515.43',\n        '93.0.4556.0',\n        '93.0.4577.15',\n        '93.0.4577.63',\n        '93.0.4577.82',\n        '94.0.4606.41',\n        '94.0.4606.54',\n        '94.0.4606.61',\n        '94.0.4606.71',\n        '94.0.4606.81',\n        '94.0.4606.85',\n        '95.0.4638.17',\n        '95.0.4638.50',\n        '95.0.4638.54',\n        '95.0.4638.69',\n        '95.0.4638.74',\n        '96.0.4664.18',\n        '96.0.4664.45',\n        '96.0.4664.55',\n        '96.0.4664.93',\n        '97.0.4692.20',\n    )\n    return _USER_AGENT_TPL % random.choice(_CHROME_VERSIONS)\n\n\nclass HTTPHeaderDict(collections.UserDict, dict):\n    \"\"\"\n    Store and access keys case-insensitively.\n    The constructor can take multiple dicts, in which keys in the latter are prioritised.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n        for dct in args:\n            if dct is not None:\n                self.update(dct)\n        self.update(kwargs)\n\n    def __setitem__(self, key, value):\n        if isinstance(value, bytes):\n            value = value.decode('latin-1')\n        super().__setitem__(key.title(), str(value))\n\n    def __getitem__(self, key):\n        return super().__getitem__(key.title())\n\n    def __delitem__(self, key):\n        super().__delitem__(key.title())\n\n    def __contains__(self, key):\n        return super().__contains__(key.title() if isinstance(key, str) else key)\n\n\nstd_headers = HTTPHeaderDict({\n    'User-Agent': random_user_agent(),\n    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n    'Accept-Language': 'en-us,en;q=0.5',\n    'Sec-Fetch-Mode': 'navigate',\n})\n\n\ndef clean_proxies(proxies: dict, headers: HTTPHeaderDict):\n    req_proxy = headers.pop('Ytdl-Request-Proxy', None)\n    if req_proxy:\n        proxies.clear()  # XXX: compat: Ytdl-Request-Proxy takes preference over everything, including NO_PROXY\n        proxies['all'] = req_proxy\n    for proxy_key, proxy_url in proxies.items():\n        if proxy_url == '__noproxy__':\n            proxies[proxy_key] = None\n            continue\n        if proxy_key == 'no':  # special case\n            continue\n        if proxy_url is not None:\n            # Ensure proxies without a scheme are http.\n            try:\n                proxy_scheme = urllib.request._parse_proxy(proxy_url)[0]\n            except ValueError:\n                # Ignore invalid proxy URLs. Sometimes these may be introduced through environment\n                # variables unrelated to proxy settings - e.g. Colab `COLAB_LANGUAGE_SERVER_PROXY`.\n                # If the proxy is going to be used, the Request Handler proxy validation will handle it.\n                continue\n            if proxy_scheme is None:\n                proxies[proxy_key] = 'http://' + remove_start(proxy_url, '//')\n\n            replace_scheme = {\n                'socks5': 'socks5h',  # compat: socks5 was treated as socks5h\n                'socks': 'socks4'  # compat: non-standard\n            }\n            if proxy_scheme in replace_scheme:\n                proxies[proxy_key] = urllib.parse.urlunparse(\n                    urllib.parse.urlparse(proxy_url)._replace(scheme=replace_scheme[proxy_scheme]))\n\n\ndef clean_headers(headers: HTTPHeaderDict):\n    if 'Youtubedl-No-Compression' in headers:  # compat\n        del headers['Youtubedl-No-Compression']\n        headers['Accept-Encoding'] = 'identity'\n\n\ndef remove_dot_segments(path):\n    # Implements RFC3986 5.2.4 remote_dot_segments\n    # Pseudo-code: https://tools.ietf.org/html/rfc3986#section-5.2.4\n    # https://github.com/urllib3/urllib3/blob/ba49f5c4e19e6bca6827282feb77a3c9f937e64b/src/urllib3/util/url.py#L263\n    output = []\n    segments = path.split('/')\n    for s in segments:\n        if s == '.':\n            continue\n        elif s == '..':\n            if output:\n                output.pop()\n        else:\n            output.append(s)\n    if not segments[0] and (not output or output[0]):\n        output.insert(0, '')\n    if segments[-1] in ('.', '..'):\n        output.append('')\n    return '/'.join(output)\n\n\ndef escape_rfc3986(s):\n    \"\"\"Escape non-ASCII characters as suggested by RFC 3986\"\"\"\n    return urllib.parse.quote(s, b\"%/;:@&=+$,!~*'()?#[]\")\n\n\ndef normalize_url(url):\n    \"\"\"Normalize URL as suggested by RFC 3986\"\"\"\n    url_parsed = urllib.parse.urlparse(url)\n    return url_parsed._replace(\n        netloc=url_parsed.netloc.encode('idna').decode('ascii'),\n        path=escape_rfc3986(remove_dot_segments(url_parsed.path)),\n        params=escape_rfc3986(url_parsed.params),\n        query=escape_rfc3986(url_parsed.query),\n        fragment=escape_rfc3986(url_parsed.fragment)\n    ).geturl()\n"], "fixing_code": ["#!/usr/bin/env python3\n\n# Allow direct execution\nimport os\nimport sys\n\nimport pytest\n\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\nimport gzip\nimport http.client\nimport http.cookiejar\nimport http.server\nimport io\nimport pathlib\nimport random\nimport ssl\nimport tempfile\nimport threading\nimport time\nimport urllib.error\nimport urllib.request\nimport warnings\nimport zlib\nfrom email.message import Message\nfrom http.cookiejar import CookieJar\n\nfrom test.helper import FakeYDL, http_server_port\nfrom yt_dlp.cookies import YoutubeDLCookieJar\nfrom yt_dlp.dependencies import brotli, requests, urllib3\nfrom yt_dlp.networking import (\n    HEADRequest,\n    PUTRequest,\n    Request,\n    RequestDirector,\n    RequestHandler,\n    Response,\n)\nfrom yt_dlp.networking._urllib import UrllibRH\nfrom yt_dlp.networking.exceptions import (\n    CertificateVerifyError,\n    HTTPError,\n    IncompleteRead,\n    NoSupportingHandlers,\n    ProxyError,\n    RequestError,\n    SSLError,\n    TransportError,\n    UnsupportedRequest,\n)\nfrom yt_dlp.utils._utils import _YDLLogger as FakeLogger\nfrom yt_dlp.utils.networking import HTTPHeaderDict\n\nTEST_DIR = os.path.dirname(os.path.abspath(__file__))\n\n\ndef _build_proxy_handler(name):\n    class HTTPTestRequestHandler(http.server.BaseHTTPRequestHandler):\n        proxy_name = name\n\n        def log_message(self, format, *args):\n            pass\n\n        def do_GET(self):\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/plain; charset=utf-8')\n            self.end_headers()\n            self.wfile.write('{self.proxy_name}: {self.path}'.format(self=self).encode())\n    return HTTPTestRequestHandler\n\n\nclass HTTPTestRequestHandler(http.server.BaseHTTPRequestHandler):\n    protocol_version = 'HTTP/1.1'\n\n    def log_message(self, format, *args):\n        pass\n\n    def _headers(self):\n        payload = str(self.headers).encode()\n        self.send_response(200)\n        self.send_header('Content-Type', 'application/json')\n        self.send_header('Content-Length', str(len(payload)))\n        self.end_headers()\n        self.wfile.write(payload)\n\n    def _redirect(self):\n        self.send_response(int(self.path[len('/redirect_'):]))\n        self.send_header('Location', '/method')\n        self.send_header('Content-Length', '0')\n        self.end_headers()\n\n    def _method(self, method, payload=None):\n        self.send_response(200)\n        self.send_header('Content-Length', str(len(payload or '')))\n        self.send_header('Method', method)\n        self.end_headers()\n        if payload:\n            self.wfile.write(payload)\n\n    def _status(self, status):\n        payload = f'<html>{status} NOT FOUND</html>'.encode()\n        self.send_response(int(status))\n        self.send_header('Content-Type', 'text/html; charset=utf-8')\n        self.send_header('Content-Length', str(len(payload)))\n        self.end_headers()\n        self.wfile.write(payload)\n\n    def _read_data(self):\n        if 'Content-Length' in self.headers:\n            return self.rfile.read(int(self.headers['Content-Length']))\n\n    def do_POST(self):\n        data = self._read_data() + str(self.headers).encode()\n        if self.path.startswith('/redirect_'):\n            self._redirect()\n        elif self.path.startswith('/method'):\n            self._method('POST', data)\n        elif self.path.startswith('/headers'):\n            self._headers()\n        else:\n            self._status(404)\n\n    def do_HEAD(self):\n        if self.path.startswith('/redirect_'):\n            self._redirect()\n        elif self.path.startswith('/method'):\n            self._method('HEAD')\n        else:\n            self._status(404)\n\n    def do_PUT(self):\n        data = self._read_data() + str(self.headers).encode()\n        if self.path.startswith('/redirect_'):\n            self._redirect()\n        elif self.path.startswith('/method'):\n            self._method('PUT', data)\n        else:\n            self._status(404)\n\n    def do_GET(self):\n        if self.path == '/video.html':\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path == '/vid.mp4':\n            payload = b'\\x00\\x00\\x00\\x00\\x20\\x66\\x74[video]'\n            self.send_response(200)\n            self.send_header('Content-Type', 'video/mp4')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path == '/%E4%B8%AD%E6%96%87.html':\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path == '/%c7%9f':\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path.startswith('/redirect_loop'):\n            self.send_response(301)\n            self.send_header('Location', self.path)\n            self.send_header('Content-Length', '0')\n            self.end_headers()\n        elif self.path == '/redirect_dotsegments':\n            self.send_response(301)\n            # redirect to /headers but with dot segments before\n            self.send_header('Location', '/a/b/./../../headers')\n            self.send_header('Content-Length', '0')\n            self.end_headers()\n        elif self.path.startswith('/redirect_'):\n            self._redirect()\n        elif self.path.startswith('/method'):\n            self._method('GET', str(self.headers).encode())\n        elif self.path.startswith('/headers'):\n            self._headers()\n        elif self.path.startswith('/308-to-headers'):\n            self.send_response(308)\n            self.send_header('Location', '/headers')\n            self.send_header('Content-Length', '0')\n            self.end_headers()\n        elif self.path == '/trailing_garbage':\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Encoding', 'gzip')\n            buf = io.BytesIO()\n            with gzip.GzipFile(fileobj=buf, mode='wb') as f:\n                f.write(payload)\n            compressed = buf.getvalue() + b'trailing garbage'\n            self.send_header('Content-Length', str(len(compressed)))\n            self.end_headers()\n            self.wfile.write(compressed)\n        elif self.path == '/302-non-ascii-redirect':\n            new_url = f'http://127.0.0.1:{http_server_port(self.server)}/\u4e2d\u6587.html'\n            self.send_response(301)\n            self.send_header('Location', new_url)\n            self.send_header('Content-Length', '0')\n            self.end_headers()\n        elif self.path == '/content-encoding':\n            encodings = self.headers.get('ytdl-encoding', '')\n            payload = b'<html><video src=\"/vid.mp4\" /></html>'\n            for encoding in filter(None, (e.strip() for e in encodings.split(','))):\n                if encoding == 'br' and brotli:\n                    payload = brotli.compress(payload)\n                elif encoding == 'gzip':\n                    buf = io.BytesIO()\n                    with gzip.GzipFile(fileobj=buf, mode='wb') as f:\n                        f.write(payload)\n                    payload = buf.getvalue()\n                elif encoding == 'deflate':\n                    payload = zlib.compress(payload)\n                elif encoding == 'unsupported':\n                    payload = b'raw'\n                    break\n                else:\n                    self._status(415)\n                    return\n            self.send_response(200)\n            self.send_header('Content-Encoding', encodings)\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path.startswith('/gen_'):\n            payload = b'<html></html>'\n            self.send_response(int(self.path[len('/gen_'):]))\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n        elif self.path.startswith('/incompleteread'):\n            payload = b'<html></html>'\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', '234234')\n            self.end_headers()\n            self.wfile.write(payload)\n            self.finish()\n        elif self.path.startswith('/timeout_'):\n            time.sleep(int(self.path[len('/timeout_'):]))\n            self._headers()\n        elif self.path == '/source_address':\n            payload = str(self.client_address[0]).encode()\n            self.send_response(200)\n            self.send_header('Content-Type', 'text/html; charset=utf-8')\n            self.send_header('Content-Length', str(len(payload)))\n            self.end_headers()\n            self.wfile.write(payload)\n            self.finish()\n        else:\n            self._status(404)\n\n    def send_header(self, keyword, value):\n        \"\"\"\n        Forcibly allow HTTP server to send non percent-encoded non-ASCII characters in headers.\n        This is against what is defined in RFC 3986, however we need to test we support this\n        since some sites incorrectly do this.\n        \"\"\"\n        if keyword.lower() == 'connection':\n            return super().send_header(keyword, value)\n\n        if not hasattr(self, '_headers_buffer'):\n            self._headers_buffer = []\n\n        self._headers_buffer.append(f'{keyword}: {value}\\r\\n'.encode())\n\n\ndef validate_and_send(rh, req):\n    rh.validate(req)\n    return rh.send(req)\n\n\nclass TestRequestHandlerBase:\n    @classmethod\n    def setup_class(cls):\n        cls.http_httpd = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), HTTPTestRequestHandler)\n        cls.http_port = http_server_port(cls.http_httpd)\n        cls.http_server_thread = threading.Thread(target=cls.http_httpd.serve_forever)\n        # FIXME: we should probably stop the http server thread after each test\n        # See: https://github.com/yt-dlp/yt-dlp/pull/7094#discussion_r1199746041\n        cls.http_server_thread.daemon = True\n        cls.http_server_thread.start()\n\n        # HTTPS server\n        certfn = os.path.join(TEST_DIR, 'testcert.pem')\n        cls.https_httpd = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), HTTPTestRequestHandler)\n        sslctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        sslctx.load_cert_chain(certfn, None)\n        cls.https_httpd.socket = sslctx.wrap_socket(cls.https_httpd.socket, server_side=True)\n        cls.https_port = http_server_port(cls.https_httpd)\n        cls.https_server_thread = threading.Thread(target=cls.https_httpd.serve_forever)\n        cls.https_server_thread.daemon = True\n        cls.https_server_thread.start()\n\n\nclass TestHTTPRequestHandler(TestRequestHandlerBase):\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_verify_cert(self, handler):\n        with handler() as rh:\n            with pytest.raises(CertificateVerifyError):\n                validate_and_send(rh, Request(f'https://127.0.0.1:{self.https_port}/headers'))\n\n        with handler(verify=False) as rh:\n            r = validate_and_send(rh, Request(f'https://127.0.0.1:{self.https_port}/headers'))\n            assert r.status == 200\n            r.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_ssl_error(self, handler):\n        # HTTPS server with too old TLS version\n        # XXX: is there a better way to test this than to create a new server?\n        https_httpd = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), HTTPTestRequestHandler)\n        sslctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        https_httpd.socket = sslctx.wrap_socket(https_httpd.socket, server_side=True)\n        https_port = http_server_port(https_httpd)\n        https_server_thread = threading.Thread(target=https_httpd.serve_forever)\n        https_server_thread.daemon = True\n        https_server_thread.start()\n\n        with handler(verify=False) as rh:\n            with pytest.raises(SSLError, match='sslv3 alert handshake failure') as exc_info:\n                validate_and_send(rh, Request(f'https://127.0.0.1:{https_port}/headers'))\n            assert not issubclass(exc_info.type, CertificateVerifyError)\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_percent_encode(self, handler):\n        with handler() as rh:\n            # Unicode characters should be encoded with uppercase percent-encoding\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/\u4e2d\u6587.html'))\n            assert res.status == 200\n            res.close()\n            # don't normalize existing percent encodings\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/%c7%9f'))\n            assert res.status == 200\n            res.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_remove_dot_segments(self, handler):\n        with handler() as rh:\n            # This isn't a comprehensive test,\n            # but it should be enough to check whether the handler is removing dot segments\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/a/b/./../../headers'))\n            assert res.status == 200\n            assert res.url == f'http://127.0.0.1:{self.http_port}/headers'\n            res.close()\n\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/redirect_dotsegments'))\n            assert res.status == 200\n            assert res.url == f'http://127.0.0.1:{self.http_port}/headers'\n            res.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_unicode_path_redirection(self, handler):\n        with handler() as rh:\n            r = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/302-non-ascii-redirect'))\n            assert r.url == f'http://127.0.0.1:{self.http_port}/%E4%B8%AD%E6%96%87.html'\n            r.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_raise_http_error(self, handler):\n        with handler() as rh:\n            for bad_status in (400, 500, 599, 302):\n                with pytest.raises(HTTPError):\n                    validate_and_send(rh, Request('http://127.0.0.1:%d/gen_%d' % (self.http_port, bad_status)))\n\n            # Should not raise an error\n            validate_and_send(rh, Request('http://127.0.0.1:%d/gen_200' % self.http_port)).close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_response_url(self, handler):\n        with handler() as rh:\n            # Response url should be that of the last url in redirect chain\n            res = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/redirect_301'))\n            assert res.url == f'http://127.0.0.1:{self.http_port}/method'\n            res.close()\n            res2 = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/gen_200'))\n            assert res2.url == f'http://127.0.0.1:{self.http_port}/gen_200'\n            res2.close()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_redirect(self, handler):\n        with handler() as rh:\n            def do_req(redirect_status, method, assert_no_content=False):\n                data = b'testdata' if method in ('POST', 'PUT') else None\n                res = validate_and_send(\n                    rh, Request(f'http://127.0.0.1:{self.http_port}/redirect_{redirect_status}', method=method, data=data))\n\n                headers = b''\n                data_sent = b''\n                if data is not None:\n                    data_sent += res.read(len(data))\n                    if data_sent != data:\n                        headers += data_sent\n                        data_sent = b''\n\n                headers += res.read()\n\n                if assert_no_content or data is None:\n                    assert b'Content-Type' not in headers\n                    assert b'Content-Length' not in headers\n                else:\n                    assert b'Content-Type' in headers\n                    assert b'Content-Length' in headers\n\n                return data_sent.decode(), res.headers.get('method', '')\n\n            # A 303 must either use GET or HEAD for subsequent request\n            assert do_req(303, 'POST', True) == ('', 'GET')\n            assert do_req(303, 'HEAD') == ('', 'HEAD')\n\n            assert do_req(303, 'PUT', True) == ('', 'GET')\n\n            # 301 and 302 turn POST only into a GET\n            assert do_req(301, 'POST', True) == ('', 'GET')\n            assert do_req(301, 'HEAD') == ('', 'HEAD')\n            assert do_req(302, 'POST', True) == ('', 'GET')\n            assert do_req(302, 'HEAD') == ('', 'HEAD')\n\n            assert do_req(301, 'PUT') == ('testdata', 'PUT')\n            assert do_req(302, 'PUT') == ('testdata', 'PUT')\n\n            # 307 and 308 should not change method\n            for m in ('POST', 'PUT'):\n                assert do_req(307, m) == ('testdata', m)\n                assert do_req(308, m) == ('testdata', m)\n\n            assert do_req(307, 'HEAD') == ('', 'HEAD')\n            assert do_req(308, 'HEAD') == ('', 'HEAD')\n\n            # These should not redirect and instead raise an HTTPError\n            for code in (300, 304, 305, 306):\n                with pytest.raises(HTTPError):\n                    do_req(code, 'GET')\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_request_cookie_header(self, handler):\n        # We should accept a Cookie header being passed as in normal headers and handle it appropriately.\n        with handler() as rh:\n            # Specified Cookie header should be used\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/headers',\n                    headers={'Cookie': 'test=test'})).read().decode()\n            assert 'Cookie: test=test' in res\n\n            # Specified Cookie header should be removed on any redirect\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/308-to-headers',\n                    headers={'Cookie': 'test=test'})).read().decode()\n            assert 'Cookie: test=test' not in res\n\n        # Specified Cookie header should override global cookiejar for that request\n        cookiejar = YoutubeDLCookieJar()\n        cookiejar.set_cookie(http.cookiejar.Cookie(\n            version=0, name='test', value='ytdlp', port=None, port_specified=False,\n            domain='127.0.0.1', domain_specified=True, domain_initial_dot=False, path='/',\n            path_specified=True, secure=False, expires=None, discard=False, comment=None,\n            comment_url=None, rest={}))\n\n        with handler(cookiejar=cookiejar) as rh:\n            data = validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/headers', headers={'cookie': 'test=test'})).read()\n            assert b'Cookie: test=ytdlp' not in data\n            assert b'Cookie: test=test' in data\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_redirect_loop(self, handler):\n        with handler() as rh:\n            with pytest.raises(HTTPError, match='redirect loop'):\n                validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/redirect_loop'))\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_incompleteread(self, handler):\n        with handler(timeout=2) as rh:\n            with pytest.raises(IncompleteRead):\n                validate_and_send(rh, Request('http://127.0.0.1:%d/incompleteread' % self.http_port)).read()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_cookies(self, handler):\n        cookiejar = YoutubeDLCookieJar()\n        cookiejar.set_cookie(http.cookiejar.Cookie(\n            0, 'test', 'ytdlp', None, False, '127.0.0.1', True,\n            False, '/headers', True, False, None, False, None, None, {}))\n\n        with handler(cookiejar=cookiejar) as rh:\n            data = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/headers')).read()\n            assert b'Cookie: test=ytdlp' in data\n\n        # Per request\n        with handler() as rh:\n            data = validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/headers', extensions={'cookiejar': cookiejar})).read()\n            assert b'Cookie: test=ytdlp' in data\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_headers(self, handler):\n\n        with handler(headers=HTTPHeaderDict({'test1': 'test', 'test2': 'test2'})) as rh:\n            # Global Headers\n            data = validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/headers')).read()\n            assert b'Test1: test' in data\n\n            # Per request headers, merged with global\n            data = validate_and_send(rh, Request(\n                f'http://127.0.0.1:{self.http_port}/headers', headers={'test2': 'changed', 'test3': 'test3'})).read()\n            assert b'Test1: test' in data\n            assert b'Test2: changed' in data\n            assert b'Test2: test2' not in data\n            assert b'Test3: test3' in data\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_timeout(self, handler):\n        with handler() as rh:\n            # Default timeout is 20 seconds, so this should go through\n            validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/timeout_3'))\n\n        with handler(timeout=0.5) as rh:\n            with pytest.raises(TransportError):\n                validate_and_send(\n                    rh, Request(f'http://127.0.0.1:{self.http_port}/timeout_1'))\n\n            # Per request timeout, should override handler timeout\n            validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/timeout_1', extensions={'timeout': 4}))\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_source_address(self, handler):\n        source_address = f'127.0.0.{random.randint(5, 255)}'\n        with handler(source_address=source_address) as rh:\n            data = validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/source_address')).read().decode()\n            assert source_address == data\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_gzip_trailing_garbage(self, handler):\n        with handler() as rh:\n            data = validate_and_send(rh, Request(f'http://localhost:{self.http_port}/trailing_garbage')).read().decode()\n            assert data == '<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    @pytest.mark.skipif(not brotli, reason='brotli support is not installed')\n    def test_brotli(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/content-encoding',\n                    headers={'ytdl-encoding': 'br'}))\n            assert res.headers.get('Content-Encoding') == 'br'\n            assert res.read() == b'<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_deflate(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/content-encoding',\n                    headers={'ytdl-encoding': 'deflate'}))\n            assert res.headers.get('Content-Encoding') == 'deflate'\n            assert res.read() == b'<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_gzip(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/content-encoding',\n                    headers={'ytdl-encoding': 'gzip'}))\n            assert res.headers.get('Content-Encoding') == 'gzip'\n            assert res.read() == b'<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_multiple_encodings(self, handler):\n        with handler() as rh:\n            for pair in ('gzip,deflate', 'deflate, gzip', 'gzip, gzip', 'deflate, deflate'):\n                res = validate_and_send(\n                    rh, Request(\n                        f'http://127.0.0.1:{self.http_port}/content-encoding',\n                        headers={'ytdl-encoding': pair}))\n                assert res.headers.get('Content-Encoding') == pair\n                assert res.read() == b'<html><video src=\"/vid.mp4\" /></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_unsupported_encoding(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(\n                    f'http://127.0.0.1:{self.http_port}/content-encoding',\n                    headers={'ytdl-encoding': 'unsupported'}))\n            assert res.headers.get('Content-Encoding') == 'unsupported'\n            assert res.read() == b'raw'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_read(self, handler):\n        with handler() as rh:\n            res = validate_and_send(\n                rh, Request(f'http://127.0.0.1:{self.http_port}/headers'))\n            assert res.readable()\n            assert res.read(1) == b'H'\n            assert res.read(3) == b'ost'\n\n\nclass TestHTTPProxy(TestRequestHandlerBase):\n    @classmethod\n    def setup_class(cls):\n        super().setup_class()\n        # HTTP Proxy server\n        cls.proxy = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), _build_proxy_handler('normal'))\n        cls.proxy_port = http_server_port(cls.proxy)\n        cls.proxy_thread = threading.Thread(target=cls.proxy.serve_forever)\n        cls.proxy_thread.daemon = True\n        cls.proxy_thread.start()\n\n        # Geo proxy server\n        cls.geo_proxy = http.server.ThreadingHTTPServer(\n            ('127.0.0.1', 0), _build_proxy_handler('geo'))\n        cls.geo_port = http_server_port(cls.geo_proxy)\n        cls.geo_proxy_thread = threading.Thread(target=cls.geo_proxy.serve_forever)\n        cls.geo_proxy_thread.daemon = True\n        cls.geo_proxy_thread.start()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_http_proxy(self, handler):\n        http_proxy = f'http://127.0.0.1:{self.proxy_port}'\n        geo_proxy = f'http://127.0.0.1:{self.geo_port}'\n\n        # Test global http proxy\n        # Test per request http proxy\n        # Test per request http proxy disables proxy\n        url = 'http://foo.com/bar'\n\n        # Global HTTP proxy\n        with handler(proxies={'http': http_proxy}) as rh:\n            res = validate_and_send(rh, Request(url)).read().decode()\n            assert res == f'normal: {url}'\n\n            # Per request proxy overrides global\n            res = validate_and_send(rh, Request(url, proxies={'http': geo_proxy})).read().decode()\n            assert res == f'geo: {url}'\n\n            # and setting to None disables all proxies for that request\n            real_url = f'http://127.0.0.1:{self.http_port}/headers'\n            res = validate_and_send(\n                rh, Request(real_url, proxies={'http': None})).read().decode()\n            assert res != f'normal: {real_url}'\n            assert 'Accept' in res\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_noproxy(self, handler):\n        with handler(proxies={'proxy': f'http://127.0.0.1:{self.proxy_port}'}) as rh:\n            # NO_PROXY\n            for no_proxy in (f'127.0.0.1:{self.http_port}', '127.0.0.1', 'localhost'):\n                nop_response = validate_and_send(\n                    rh, Request(f'http://127.0.0.1:{self.http_port}/headers', proxies={'no': no_proxy})).read().decode(\n                    'utf-8')\n                assert 'Accept' in nop_response\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_allproxy(self, handler):\n        url = 'http://foo.com/bar'\n        with handler() as rh:\n            response = validate_and_send(rh, Request(url, proxies={'all': f'http://127.0.0.1:{self.proxy_port}'})).read().decode(\n                'utf-8')\n            assert response == f'normal: {url}'\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_http_proxy_with_idn(self, handler):\n        with handler(proxies={\n            'http': f'http://127.0.0.1:{self.proxy_port}',\n        }) as rh:\n            url = 'http://\u4e2d\u6587.tw/'\n            response = rh.send(Request(url)).read().decode()\n            # b'xn--fiq228c' is '\u4e2d\u6587'.encode('idna')\n            assert response == 'normal: http://xn--fiq228c.tw/'\n\n\nclass TestClientCertificate:\n\n    @classmethod\n    def setup_class(cls):\n        certfn = os.path.join(TEST_DIR, 'testcert.pem')\n        cls.certdir = os.path.join(TEST_DIR, 'testdata', 'certificate')\n        cacertfn = os.path.join(cls.certdir, 'ca.crt')\n        cls.httpd = http.server.ThreadingHTTPServer(('127.0.0.1', 0), HTTPTestRequestHandler)\n        sslctx = ssl.SSLContext(ssl.PROTOCOL_TLS_SERVER)\n        sslctx.verify_mode = ssl.CERT_REQUIRED\n        sslctx.load_verify_locations(cafile=cacertfn)\n        sslctx.load_cert_chain(certfn, None)\n        cls.httpd.socket = sslctx.wrap_socket(cls.httpd.socket, server_side=True)\n        cls.port = http_server_port(cls.httpd)\n        cls.server_thread = threading.Thread(target=cls.httpd.serve_forever)\n        cls.server_thread.daemon = True\n        cls.server_thread.start()\n\n    def _run_test(self, handler, **handler_kwargs):\n        with handler(\n            # Disable client-side validation of unacceptable self-signed testcert.pem\n            # The test is of a check on the server side, so unaffected\n            verify=False,\n            **handler_kwargs,\n        ) as rh:\n            validate_and_send(rh, Request(f'https://127.0.0.1:{self.port}/video.html')).read().decode()\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_certificate_combined_nopass(self, handler):\n        self._run_test(handler, client_cert={\n            'client_certificate': os.path.join(self.certdir, 'clientwithkey.crt'),\n        })\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_certificate_nocombined_nopass(self, handler):\n        self._run_test(handler, client_cert={\n            'client_certificate': os.path.join(self.certdir, 'client.crt'),\n            'client_certificate_key': os.path.join(self.certdir, 'client.key'),\n        })\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_certificate_combined_pass(self, handler):\n        self._run_test(handler, client_cert={\n            'client_certificate': os.path.join(self.certdir, 'clientwithencryptedkey.crt'),\n            'client_certificate_password': 'foobar',\n        })\n\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_certificate_nocombined_pass(self, handler):\n        self._run_test(handler, client_cert={\n            'client_certificate': os.path.join(self.certdir, 'client.crt'),\n            'client_certificate_key': os.path.join(self.certdir, 'clientencrypted.key'),\n            'client_certificate_password': 'foobar',\n        })\n\n\nclass TestUrllibRequestHandler(TestRequestHandlerBase):\n    @pytest.mark.parametrize('handler', ['Urllib'], indirect=True)\n    def test_file_urls(self, handler):\n        # See https://github.com/ytdl-org/youtube-dl/issues/8227\n        tf = tempfile.NamedTemporaryFile(delete=False)\n        tf.write(b'foobar')\n        tf.close()\n        req = Request(pathlib.Path(tf.name).as_uri())\n        with handler() as rh:\n            with pytest.raises(UnsupportedRequest):\n                rh.validate(req)\n\n            # Test that urllib never loaded FileHandler\n            with pytest.raises(TransportError):\n                rh.send(req)\n\n        with handler(enable_file_urls=True) as rh:\n            res = validate_and_send(rh, req)\n            assert res.read() == b'foobar'\n            res.close()\n\n        os.unlink(tf.name)\n\n    @pytest.mark.parametrize('handler', ['Urllib'], indirect=True)\n    def test_http_error_returns_content(self, handler):\n        # urllib HTTPError will try close the underlying response if reference to the HTTPError object is lost\n        def get_response():\n            with handler() as rh:\n                # headers url\n                try:\n                    validate_and_send(rh, Request(f'http://127.0.0.1:{self.http_port}/gen_404'))\n                except HTTPError as e:\n                    return e.response\n\n        assert get_response().read() == b'<html></html>'\n\n    @pytest.mark.parametrize('handler', ['Urllib'], indirect=True)\n    def test_verify_cert_error_text(self, handler):\n        # Check the output of the error message\n        with handler() as rh:\n            with pytest.raises(\n                CertificateVerifyError,\n                match=r'\\[SSL: CERTIFICATE_VERIFY_FAILED\\] certificate verify failed: self.signed certificate'\n            ):\n                validate_and_send(rh, Request(f'https://127.0.0.1:{self.https_port}/headers'))\n\n    @pytest.mark.parametrize('handler', ['Urllib'], indirect=True)\n    @pytest.mark.parametrize('req,match,version_check', [\n        # https://github.com/python/cpython/blob/987b712b4aeeece336eed24fcc87a950a756c3e2/Lib/http/client.py#L1256\n        # bpo-39603: Check implemented in 3.7.9+, 3.8.5+\n        (\n            Request('http://127.0.0.1', method='GET\\n'),\n            'method can\\'t contain control characters',\n            lambda v: v < (3, 7, 9) or (3, 8, 0) <= v < (3, 8, 5)\n        ),\n        # https://github.com/python/cpython/blob/987b712b4aeeece336eed24fcc87a950a756c3e2/Lib/http/client.py#L1265\n        # bpo-38576: Check implemented in 3.7.8+, 3.8.3+\n        (\n            Request('http://127.0.0. 1', method='GET'),\n            'URL can\\'t contain control characters',\n            lambda v: v < (3, 7, 8) or (3, 8, 0) <= v < (3, 8, 3)\n        ),\n        # https://github.com/python/cpython/blob/987b712b4aeeece336eed24fcc87a950a756c3e2/Lib/http/client.py#L1288C31-L1288C50\n        (Request('http://127.0.0.1', headers={'foo\\n': 'bar'}), 'Invalid header name', None),\n    ])\n    def test_httplib_validation_errors(self, handler, req, match, version_check):\n        if version_check and version_check(sys.version_info):\n            pytest.skip(f'Python {sys.version} version does not have the required validation for this test.')\n\n        with handler() as rh:\n            with pytest.raises(RequestError, match=match) as exc_info:\n                validate_and_send(rh, req)\n            assert not isinstance(exc_info.value, TransportError)\n\n\nclass TestRequestsRequestHandler(TestRequestHandlerBase):\n    @pytest.mark.parametrize('raised,expected', [\n        (lambda: requests.exceptions.ConnectTimeout(), TransportError),\n        (lambda: requests.exceptions.ReadTimeout(), TransportError),\n        (lambda: requests.exceptions.Timeout(), TransportError),\n        (lambda: requests.exceptions.ConnectionError(), TransportError),\n        (lambda: requests.exceptions.ProxyError(), ProxyError),\n        (lambda: requests.exceptions.SSLError('12[CERTIFICATE_VERIFY_FAILED]34'), CertificateVerifyError),\n        (lambda: requests.exceptions.SSLError(), SSLError),\n        (lambda: requests.exceptions.InvalidURL(), RequestError),\n        (lambda: requests.exceptions.InvalidHeader(), RequestError),\n        # catch-all: https://github.com/psf/requests/blob/main/src/requests/adapters.py#L535\n        (lambda: urllib3.exceptions.HTTPError(), TransportError),\n        (lambda: requests.exceptions.RequestException(), RequestError)\n        #  (lambda: requests.exceptions.TooManyRedirects(), HTTPError) - Needs a response object\n    ])\n    @pytest.mark.parametrize('handler', ['Requests'], indirect=True)\n    def test_request_error_mapping(self, handler, monkeypatch, raised, expected):\n        with handler() as rh:\n            def mock_get_instance(*args, **kwargs):\n                class MockSession:\n                    def request(self, *args, **kwargs):\n                        raise raised()\n                return MockSession()\n\n            monkeypatch.setattr(rh, '_get_instance', mock_get_instance)\n\n            with pytest.raises(expected) as exc_info:\n                rh.send(Request('http://fake'))\n\n            assert exc_info.type is expected\n\n    @pytest.mark.parametrize('raised,expected,match', [\n        (lambda: urllib3.exceptions.SSLError(), SSLError, None),\n        (lambda: urllib3.exceptions.TimeoutError(), TransportError, None),\n        (lambda: urllib3.exceptions.ReadTimeoutError(None, None, None), TransportError, None),\n        (lambda: urllib3.exceptions.ProtocolError(), TransportError, None),\n        (lambda: urllib3.exceptions.DecodeError(), TransportError, None),\n        (lambda: urllib3.exceptions.HTTPError(), TransportError, None),  # catch-all\n        (\n            lambda: urllib3.exceptions.ProtocolError('error', http.client.IncompleteRead(partial=b'abc', expected=4)),\n            IncompleteRead,\n            '3 bytes read, 4 more expected'\n        ),\n        (\n            lambda: urllib3.exceptions.ProtocolError('error', urllib3.exceptions.IncompleteRead(partial=3, expected=5)),\n            IncompleteRead,\n            '3 bytes read, 5 more expected'\n        ),\n    ])\n    @pytest.mark.parametrize('handler', ['Requests'], indirect=True)\n    def test_response_error_mapping(self, handler, monkeypatch, raised, expected, match):\n        from urllib3.response import HTTPResponse as Urllib3Response\n        from requests.models import Response as RequestsResponse\n        from yt_dlp.networking._requests import RequestsResponseAdapter\n        requests_res = RequestsResponse()\n        requests_res.raw = Urllib3Response(body=b'', status=200)\n        res = RequestsResponseAdapter(requests_res)\n\n        def mock_read(*args, **kwargs):\n            raise raised()\n        monkeypatch.setattr(res.fp, 'read', mock_read)\n\n        with pytest.raises(expected, match=match) as exc_info:\n            res.read()\n\n        assert exc_info.type is expected\n\n\ndef run_validation(handler, error, req, **handler_kwargs):\n    with handler(**handler_kwargs) as rh:\n        if error:\n            with pytest.raises(error):\n                rh.validate(req)\n        else:\n            rh.validate(req)\n\n\nclass TestRequestHandlerValidation:\n\n    class ValidationRH(RequestHandler):\n        def _send(self, request):\n            raise RequestError('test')\n\n    class NoCheckRH(ValidationRH):\n        _SUPPORTED_FEATURES = None\n        _SUPPORTED_PROXY_SCHEMES = None\n        _SUPPORTED_URL_SCHEMES = None\n\n        def _check_extensions(self, extensions):\n            extensions.clear()\n\n    class HTTPSupportedRH(ValidationRH):\n        _SUPPORTED_URL_SCHEMES = ('http',)\n\n    URL_SCHEME_TESTS = [\n        # scheme, expected to fail, handler kwargs\n        ('Urllib', [\n            ('http', False, {}),\n            ('https', False, {}),\n            ('data', False, {}),\n            ('ftp', False, {}),\n            ('file', UnsupportedRequest, {}),\n            ('file', False, {'enable_file_urls': True}),\n        ]),\n        ('Requests', [\n            ('http', False, {}),\n            ('https', False, {}),\n        ]),\n        (NoCheckRH, [('http', False, {})]),\n        (ValidationRH, [('http', UnsupportedRequest, {})])\n    ]\n\n    PROXY_SCHEME_TESTS = [\n        # scheme, expected to fail\n        ('Urllib', [\n            ('http', False),\n            ('https', UnsupportedRequest),\n            ('socks4', False),\n            ('socks4a', False),\n            ('socks5', False),\n            ('socks5h', False),\n            ('socks', UnsupportedRequest),\n        ]),\n        ('Requests', [\n            ('http', False),\n            ('https', False),\n            ('socks4', False),\n            ('socks4a', False),\n            ('socks5', False),\n            ('socks5h', False),\n        ]),\n        (NoCheckRH, [('http', False)]),\n        (HTTPSupportedRH, [('http', UnsupportedRequest)]),\n    ]\n\n    PROXY_KEY_TESTS = [\n        # key, expected to fail\n        ('Urllib', [\n            ('all', False),\n            ('unrelated', False),\n        ]),\n        ('Requests', [\n            ('all', False),\n            ('unrelated', False),\n        ]),\n        (NoCheckRH, [('all', False)]),\n        (HTTPSupportedRH, [('all', UnsupportedRequest)]),\n        (HTTPSupportedRH, [('no', UnsupportedRequest)]),\n    ]\n\n    EXTENSION_TESTS = [\n        ('Urllib', [\n            ({'cookiejar': 'notacookiejar'}, AssertionError),\n            ({'cookiejar': YoutubeDLCookieJar()}, False),\n            ({'cookiejar': CookieJar()}, AssertionError),\n            ({'timeout': 1}, False),\n            ({'timeout': 'notatimeout'}, AssertionError),\n            ({'unsupported': 'value'}, UnsupportedRequest),\n        ]),\n        ('Requests', [\n            ({'cookiejar': 'notacookiejar'}, AssertionError),\n            ({'cookiejar': YoutubeDLCookieJar()}, False),\n            ({'timeout': 1}, False),\n            ({'timeout': 'notatimeout'}, AssertionError),\n            ({'unsupported': 'value'}, UnsupportedRequest),\n        ]),\n        (NoCheckRH, [\n            ({'cookiejar': 'notacookiejar'}, False),\n            ({'somerandom': 'test'}, False),  # but any extension is allowed through\n        ]),\n    ]\n\n    @pytest.mark.parametrize('handler,scheme,fail,handler_kwargs', [\n        (handler_tests[0], scheme, fail, handler_kwargs)\n        for handler_tests in URL_SCHEME_TESTS\n        for scheme, fail, handler_kwargs in handler_tests[1]\n\n    ], indirect=['handler'])\n    def test_url_scheme(self, handler, scheme, fail, handler_kwargs):\n        run_validation(handler, fail, Request(f'{scheme}://'), **(handler_kwargs or {}))\n\n    @pytest.mark.parametrize('handler,fail', [('Urllib', False), ('Requests', False)], indirect=['handler'])\n    def test_no_proxy(self, handler, fail):\n        run_validation(handler, fail, Request('http://', proxies={'no': '127.0.0.1,github.com'}))\n        run_validation(handler, fail, Request('http://'), proxies={'no': '127.0.0.1,github.com'})\n\n    @pytest.mark.parametrize('handler,proxy_key,fail', [\n        (handler_tests[0], proxy_key, fail)\n        for handler_tests in PROXY_KEY_TESTS\n        for proxy_key, fail in handler_tests[1]\n    ], indirect=['handler'])\n    def test_proxy_key(self, handler, proxy_key, fail):\n        run_validation(handler, fail, Request('http://', proxies={proxy_key: 'http://example.com'}))\n        run_validation(handler, fail, Request('http://'), proxies={proxy_key: 'http://example.com'})\n\n    @pytest.mark.parametrize('handler,scheme,fail', [\n        (handler_tests[0], scheme, fail)\n        for handler_tests in PROXY_SCHEME_TESTS\n        for scheme, fail in handler_tests[1]\n    ], indirect=['handler'])\n    def test_proxy_scheme(self, handler, scheme, fail):\n        run_validation(handler, fail, Request('http://', proxies={'http': f'{scheme}://example.com'}))\n        run_validation(handler, fail, Request('http://'), proxies={'http': f'{scheme}://example.com'})\n\n    @pytest.mark.parametrize('handler', ['Urllib', HTTPSupportedRH, 'Requests'], indirect=True)\n    def test_empty_proxy(self, handler):\n        run_validation(handler, False, Request('http://', proxies={'http': None}))\n        run_validation(handler, False, Request('http://'), proxies={'http': None})\n\n    @pytest.mark.parametrize('proxy_url', ['//example.com', 'example.com', '127.0.0.1', '/a/b/c'])\n    @pytest.mark.parametrize('handler', ['Urllib', 'Requests'], indirect=True)\n    def test_invalid_proxy_url(self, handler, proxy_url):\n        run_validation(handler, UnsupportedRequest, Request('http://', proxies={'http': proxy_url}))\n\n    @pytest.mark.parametrize('handler,extensions,fail', [\n        (handler_tests[0], extensions, fail)\n        for handler_tests in EXTENSION_TESTS\n        for extensions, fail in handler_tests[1]\n    ], indirect=['handler'])\n    def test_extension(self, handler, extensions, fail):\n        run_validation(\n            handler, fail, Request('http://', extensions=extensions))\n\n    def test_invalid_request_type(self):\n        rh = self.ValidationRH(logger=FakeLogger())\n        for method in (rh.validate, rh.send):\n            with pytest.raises(TypeError, match='Expected an instance of Request'):\n                method('not a request')\n\n\nclass FakeResponse(Response):\n    def __init__(self, request):\n        # XXX: we could make request part of standard response interface\n        self.request = request\n        super().__init__(fp=io.BytesIO(b''), headers={}, url=request.url)\n\n\nclass FakeRH(RequestHandler):\n\n    def _validate(self, request):\n        return\n\n    def _send(self, request: Request):\n        if request.url.startswith('ssl://'):\n            raise SSLError(request.url[len('ssl://'):])\n        return FakeResponse(request)\n\n\nclass FakeRHYDL(FakeYDL):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self._request_director = self.build_request_director([FakeRH])\n\n\nclass TestRequestDirector:\n\n    def test_handler_operations(self):\n        director = RequestDirector(logger=FakeLogger())\n        handler = FakeRH(logger=FakeLogger())\n        director.add_handler(handler)\n        assert director.handlers.get(FakeRH.RH_KEY) is handler\n\n        # Handler should overwrite\n        handler2 = FakeRH(logger=FakeLogger())\n        director.add_handler(handler2)\n        assert director.handlers.get(FakeRH.RH_KEY) is not handler\n        assert director.handlers.get(FakeRH.RH_KEY) is handler2\n        assert len(director.handlers) == 1\n\n        class AnotherFakeRH(FakeRH):\n            pass\n        director.add_handler(AnotherFakeRH(logger=FakeLogger()))\n        assert len(director.handlers) == 2\n        assert director.handlers.get(AnotherFakeRH.RH_KEY).RH_KEY == AnotherFakeRH.RH_KEY\n\n        director.handlers.pop(FakeRH.RH_KEY, None)\n        assert director.handlers.get(FakeRH.RH_KEY) is None\n        assert len(director.handlers) == 1\n\n        # RequestErrors should passthrough\n        with pytest.raises(SSLError):\n            director.send(Request('ssl://something'))\n\n    def test_send(self):\n        director = RequestDirector(logger=FakeLogger())\n        with pytest.raises(RequestError):\n            director.send(Request('any://'))\n        director.add_handler(FakeRH(logger=FakeLogger()))\n        assert isinstance(director.send(Request('http://')), FakeResponse)\n\n    def test_unsupported_handlers(self):\n        class SupportedRH(RequestHandler):\n            _SUPPORTED_URL_SCHEMES = ['http']\n\n            def _send(self, request: Request):\n                return Response(fp=io.BytesIO(b'supported'), headers={}, url=request.url)\n\n        director = RequestDirector(logger=FakeLogger())\n        director.add_handler(SupportedRH(logger=FakeLogger()))\n        director.add_handler(FakeRH(logger=FakeLogger()))\n\n        # First should take preference\n        assert director.send(Request('http://')).read() == b'supported'\n        assert director.send(Request('any://')).read() == b''\n\n        director.handlers.pop(FakeRH.RH_KEY)\n        with pytest.raises(NoSupportingHandlers):\n            director.send(Request('any://'))\n\n    def test_unexpected_error(self):\n        director = RequestDirector(logger=FakeLogger())\n\n        class UnexpectedRH(FakeRH):\n            def _send(self, request: Request):\n                raise TypeError('something')\n\n        director.add_handler(UnexpectedRH(logger=FakeLogger))\n        with pytest.raises(NoSupportingHandlers, match=r'1 unexpected error'):\n            director.send(Request('any://'))\n\n        director.handlers.clear()\n        assert len(director.handlers) == 0\n\n        # Should not be fatal\n        director.add_handler(FakeRH(logger=FakeLogger()))\n        director.add_handler(UnexpectedRH(logger=FakeLogger))\n        assert director.send(Request('any://'))\n\n    def test_preference(self):\n        director = RequestDirector(logger=FakeLogger())\n        director.add_handler(FakeRH(logger=FakeLogger()))\n\n        class SomeRH(RequestHandler):\n            _SUPPORTED_URL_SCHEMES = ['http']\n\n            def _send(self, request: Request):\n                return Response(fp=io.BytesIO(b'supported'), headers={}, url=request.url)\n\n        def some_preference(rh, request):\n            return (0 if not isinstance(rh, SomeRH)\n                    else 100 if 'prefer' in request.headers\n                    else -1)\n\n        director.add_handler(SomeRH(logger=FakeLogger()))\n        director.preferences.add(some_preference)\n\n        assert director.send(Request('http://')).read() == b''\n        assert director.send(Request('http://', headers={'prefer': '1'})).read() == b'supported'\n\n\n# XXX: do we want to move this to test_YoutubeDL.py?\nclass TestYoutubeDLNetworking:\n\n    @staticmethod\n    def build_handler(ydl, handler: RequestHandler = FakeRH):\n        return ydl.build_request_director([handler]).handlers.get(handler.RH_KEY)\n\n    def test_compat_opener(self):\n        with FakeYDL() as ydl:\n            with warnings.catch_warnings():\n                warnings.simplefilter('ignore', category=DeprecationWarning)\n                assert isinstance(ydl._opener, urllib.request.OpenerDirector)\n\n    @pytest.mark.parametrize('proxy,expected', [\n        ('http://127.0.0.1:8080', {'all': 'http://127.0.0.1:8080'}),\n        ('', {'all': '__noproxy__'}),\n        (None, {'http': 'http://127.0.0.1:8081', 'https': 'http://127.0.0.1:8081'})  # env, set https\n    ])\n    def test_proxy(self, proxy, expected):\n        old_http_proxy = os.environ.get('HTTP_PROXY')\n        try:\n            os.environ['HTTP_PROXY'] = 'http://127.0.0.1:8081'  # ensure that provided proxies override env\n            with FakeYDL({'proxy': proxy}) as ydl:\n                assert ydl.proxies == expected\n        finally:\n            if old_http_proxy:\n                os.environ['HTTP_PROXY'] = old_http_proxy\n\n    def test_compat_request(self):\n        with FakeRHYDL() as ydl:\n            assert ydl.urlopen('test://')\n            urllib_req = urllib.request.Request('http://foo.bar', data=b'test', method='PUT', headers={'X-Test': '1'})\n            urllib_req.add_unredirected_header('Cookie', 'bob=bob')\n            urllib_req.timeout = 2\n            with warnings.catch_warnings():\n                warnings.simplefilter('ignore', category=DeprecationWarning)\n                req = ydl.urlopen(urllib_req).request\n                assert req.url == urllib_req.get_full_url()\n                assert req.data == urllib_req.data\n                assert req.method == urllib_req.get_method()\n                assert 'X-Test' in req.headers\n                assert 'Cookie' in req.headers\n                assert req.extensions.get('timeout') == 2\n\n            with pytest.raises(AssertionError):\n                ydl.urlopen(None)\n\n    def test_extract_basic_auth(self):\n        with FakeRHYDL() as ydl:\n            res = ydl.urlopen(Request('http://user:pass@foo.bar'))\n            assert res.request.headers['Authorization'] == 'Basic dXNlcjpwYXNz'\n\n    def test_sanitize_url(self):\n        with FakeRHYDL() as ydl:\n            res = ydl.urlopen(Request('httpss://foo.bar'))\n            assert res.request.url == 'https://foo.bar'\n\n    def test_file_urls_error(self):\n        # use urllib handler\n        with FakeYDL() as ydl:\n            with pytest.raises(RequestError, match=r'file:// URLs are disabled by default'):\n                ydl.urlopen('file://')\n\n    def test_legacy_server_connect_error(self):\n        with FakeRHYDL() as ydl:\n            for error in ('UNSAFE_LEGACY_RENEGOTIATION_DISABLED', 'SSLV3_ALERT_HANDSHAKE_FAILURE'):\n                with pytest.raises(RequestError, match=r'Try using --legacy-server-connect'):\n                    ydl.urlopen(f'ssl://{error}')\n\n            with pytest.raises(SSLError, match='testerror'):\n                ydl.urlopen('ssl://testerror')\n\n    @pytest.mark.parametrize('proxy_key,proxy_url,expected', [\n        ('http', '__noproxy__', None),\n        ('no', '127.0.0.1,foo.bar', '127.0.0.1,foo.bar'),\n        ('https', 'example.com', 'http://example.com'),\n        ('https', '//example.com', 'http://example.com'),\n        ('https', 'socks5://example.com', 'socks5h://example.com'),\n        ('http', 'socks://example.com', 'socks4://example.com'),\n        ('http', 'socks4://example.com', 'socks4://example.com'),\n        ('unrelated', '/bad/proxy', '/bad/proxy'),  # clean_proxies should ignore bad proxies\n    ])\n    def test_clean_proxy(self, proxy_key, proxy_url, expected):\n        # proxies should be cleaned in urlopen()\n        with FakeRHYDL() as ydl:\n            req = ydl.urlopen(Request('test://', proxies={proxy_key: proxy_url})).request\n            assert req.proxies[proxy_key] == expected\n\n        # and should also be cleaned when building the handler\n        env_key = f'{proxy_key.upper()}_PROXY'\n        old_env_proxy = os.environ.get(env_key)\n        try:\n            os.environ[env_key] = proxy_url  # ensure that provided proxies override env\n            with FakeYDL() as ydl:\n                rh = self.build_handler(ydl)\n                assert rh.proxies[proxy_key] == expected\n        finally:\n            if old_env_proxy:\n                os.environ[env_key] = old_env_proxy\n\n    def test_clean_proxy_header(self):\n        with FakeRHYDL() as ydl:\n            req = ydl.urlopen(Request('test://', headers={'ytdl-request-proxy': '//foo.bar'})).request\n            assert 'ytdl-request-proxy' not in req.headers\n            assert req.proxies == {'all': 'http://foo.bar'}\n\n        with FakeYDL({'http_headers': {'ytdl-request-proxy': '//foo.bar'}}) as ydl:\n            rh = self.build_handler(ydl)\n            assert 'ytdl-request-proxy' not in rh.headers\n            assert rh.proxies == {'all': 'http://foo.bar'}\n\n    def test_clean_header(self):\n        with FakeRHYDL() as ydl:\n            res = ydl.urlopen(Request('test://', headers={'Youtubedl-no-compression': True}))\n            assert 'Youtubedl-no-compression' not in res.request.headers\n            assert res.request.headers.get('Accept-Encoding') == 'identity'\n\n        with FakeYDL({'http_headers': {'Youtubedl-no-compression': True}}) as ydl:\n            rh = self.build_handler(ydl)\n            assert 'Youtubedl-no-compression' not in rh.headers\n            assert rh.headers.get('Accept-Encoding') == 'identity'\n\n        with FakeYDL({'http_headers': {'Ytdl-socks-proxy': 'socks://localhost:1080'}}) as ydl:\n            rh = self.build_handler(ydl)\n            assert 'Ytdl-socks-proxy' not in rh.headers\n\n    def test_build_handler_params(self):\n        with FakeYDL({\n            'http_headers': {'test': 'testtest'},\n            'socket_timeout': 2,\n            'proxy': 'http://127.0.0.1:8080',\n            'source_address': '127.0.0.45',\n            'debug_printtraffic': True,\n            'compat_opts': ['no-certifi'],\n            'nocheckcertificate': True,\n            'legacyserverconnect': True,\n        }) as ydl:\n            rh = self.build_handler(ydl)\n            assert rh.headers.get('test') == 'testtest'\n            assert 'Accept' in rh.headers  # ensure std_headers are still there\n            assert rh.timeout == 2\n            assert rh.proxies.get('all') == 'http://127.0.0.1:8080'\n            assert rh.source_address == '127.0.0.45'\n            assert rh.verbose is True\n            assert rh.prefer_system_certs is True\n            assert rh.verify is False\n            assert rh.legacy_ssl_support is True\n\n    @pytest.mark.parametrize('ydl_params', [\n        {'client_certificate': 'fakecert.crt'},\n        {'client_certificate': 'fakecert.crt', 'client_certificate_key': 'fakekey.key'},\n        {'client_certificate': 'fakecert.crt', 'client_certificate_key': 'fakekey.key', 'client_certificate_password': 'foobar'},\n        {'client_certificate_key': 'fakekey.key', 'client_certificate_password': 'foobar'},\n    ])\n    def test_client_certificate(self, ydl_params):\n        with FakeYDL(ydl_params) as ydl:\n            rh = self.build_handler(ydl)\n            assert rh._client_cert == ydl_params  # XXX: Too bound to implementation\n\n    def test_urllib_file_urls(self):\n        with FakeYDL({'enable_file_urls': False}) as ydl:\n            rh = self.build_handler(ydl, UrllibRH)\n            assert rh.enable_file_urls is False\n\n        with FakeYDL({'enable_file_urls': True}) as ydl:\n            rh = self.build_handler(ydl, UrllibRH)\n            assert rh.enable_file_urls is True\n\n    def test_compat_opt_prefer_urllib(self):\n        # This assumes urllib only has a preference when this compat opt is given\n        with FakeYDL({'compat_opts': ['prefer-legacy-http-handler']}) as ydl:\n            director = ydl.build_request_director([UrllibRH])\n            assert len(director.preferences) == 1\n            assert director.preferences.pop()(UrllibRH, None)\n\n\nclass TestRequest:\n\n    def test_query(self):\n        req = Request('http://example.com?q=something', query={'v': 'xyz'})\n        assert req.url == 'http://example.com?q=something&v=xyz'\n\n        req.update(query={'v': '123'})\n        assert req.url == 'http://example.com?q=something&v=123'\n        req.update(url='http://example.com', query={'v': 'xyz'})\n        assert req.url == 'http://example.com?v=xyz'\n\n    def test_method(self):\n        req = Request('http://example.com')\n        assert req.method == 'GET'\n        req.data = b'test'\n        assert req.method == 'POST'\n        req.data = None\n        assert req.method == 'GET'\n        req.data = b'test2'\n        req.method = 'PUT'\n        assert req.method == 'PUT'\n        req.data = None\n        assert req.method == 'PUT'\n        with pytest.raises(TypeError):\n            req.method = 1\n\n    def test_request_helpers(self):\n        assert HEADRequest('http://example.com').method == 'HEAD'\n        assert PUTRequest('http://example.com').method == 'PUT'\n\n    def test_headers(self):\n        req = Request('http://example.com', headers={'tesT': 'test'})\n        assert req.headers == HTTPHeaderDict({'test': 'test'})\n        req.update(headers={'teSt2': 'test2'})\n        assert req.headers == HTTPHeaderDict({'test': 'test', 'test2': 'test2'})\n\n        req.headers = new_headers = HTTPHeaderDict({'test': 'test'})\n        assert req.headers == HTTPHeaderDict({'test': 'test'})\n        assert req.headers is new_headers\n\n        # test converts dict to case insensitive dict\n        req.headers = new_headers = {'test2': 'test2'}\n        assert isinstance(req.headers, HTTPHeaderDict)\n        assert req.headers is not new_headers\n\n        with pytest.raises(TypeError):\n            req.headers = None\n\n    def test_data_type(self):\n        req = Request('http://example.com')\n        assert req.data is None\n        # test bytes is allowed\n        req.data = b'test'\n        assert req.data == b'test'\n        # test iterable of bytes is allowed\n        i = [b'test', b'test2']\n        req.data = i\n        assert req.data == i\n\n        # test file-like object is allowed\n        f = io.BytesIO(b'test')\n        req.data = f\n        assert req.data == f\n\n        # common mistake: test str not allowed\n        with pytest.raises(TypeError):\n            req.data = 'test'\n        assert req.data != 'test'\n\n        # common mistake: test dict is not allowed\n        with pytest.raises(TypeError):\n            req.data = {'test': 'test'}\n        assert req.data != {'test': 'test'}\n\n    def test_content_length_header(self):\n        req = Request('http://example.com', headers={'Content-Length': '0'}, data=b'')\n        assert req.headers.get('Content-Length') == '0'\n\n        req.data = b'test'\n        assert 'Content-Length' not in req.headers\n\n        req = Request('http://example.com', headers={'Content-Length': '10'})\n        assert 'Content-Length' not in req.headers\n\n    def test_content_type_header(self):\n        req = Request('http://example.com', headers={'Content-Type': 'test'}, data=b'test')\n        assert req.headers.get('Content-Type') == 'test'\n        req.data = b'test2'\n        assert req.headers.get('Content-Type') == 'test'\n        req.data = None\n        assert 'Content-Type' not in req.headers\n        req.data = b'test3'\n        assert req.headers.get('Content-Type') == 'application/x-www-form-urlencoded'\n\n    def test_update_req(self):\n        req = Request('http://example.com')\n        assert req.data is None\n        assert req.method == 'GET'\n        assert 'Content-Type' not in req.headers\n        # Test that zero-byte payloads will be sent\n        req.update(data=b'')\n        assert req.data == b''\n        assert req.method == 'POST'\n        assert req.headers.get('Content-Type') == 'application/x-www-form-urlencoded'\n\n    def test_proxies(self):\n        req = Request(url='http://example.com', proxies={'http': 'http://127.0.0.1:8080'})\n        assert req.proxies == {'http': 'http://127.0.0.1:8080'}\n\n    def test_extensions(self):\n        req = Request(url='http://example.com', extensions={'timeout': 2})\n        assert req.extensions == {'timeout': 2}\n\n    def test_copy(self):\n        req = Request(\n            url='http://example.com',\n            extensions={'cookiejar': CookieJar()},\n            headers={'Accept-Encoding': 'br'},\n            proxies={'http': 'http://127.0.0.1'},\n            data=[b'123']\n        )\n        req_copy = req.copy()\n        assert req_copy is not req\n        assert req_copy.url == req.url\n        assert req_copy.headers == req.headers\n        assert req_copy.headers is not req.headers\n        assert req_copy.proxies == req.proxies\n        assert req_copy.proxies is not req.proxies\n\n        # Data is not able to be copied\n        assert req_copy.data == req.data\n        assert req_copy.data is req.data\n\n        # Shallow copy extensions\n        assert req_copy.extensions is not req.extensions\n        assert req_copy.extensions['cookiejar'] == req.extensions['cookiejar']\n\n        # Subclasses are copied by default\n        class AnotherRequest(Request):\n            pass\n\n        req = AnotherRequest(url='http://127.0.0.1')\n        assert isinstance(req.copy(), AnotherRequest)\n\n    def test_url(self):\n        req = Request(url='https://\u0444test.example.com/ some space\u0432?\u00e4=c',)\n        assert req.url == 'https://xn--test-z6d.example.com/%20some%20space%D0%B2?%C3%A4=c'\n\n        assert Request(url='//example.com').url == 'http://example.com'\n\n        with pytest.raises(TypeError):\n            Request(url='https://').url = None\n\n\nclass TestResponse:\n\n    @pytest.mark.parametrize('reason,status,expected', [\n        ('custom', 200, 'custom'),\n        (None, 404, 'Not Found'),  # fallback status\n        ('', 403, 'Forbidden'),\n        (None, 999, None)\n    ])\n    def test_reason(self, reason, status, expected):\n        res = Response(io.BytesIO(b''), url='test://', headers={}, status=status, reason=reason)\n        assert res.reason == expected\n\n    def test_headers(self):\n        headers = Message()\n        headers.add_header('Test', 'test')\n        headers.add_header('Test', 'test2')\n        headers.add_header('content-encoding', 'br')\n        res = Response(io.BytesIO(b''), headers=headers, url='test://')\n        assert res.headers.get_all('test') == ['test', 'test2']\n        assert 'Content-Encoding' in res.headers\n\n    def test_get_header(self):\n        headers = Message()\n        headers.add_header('Set-Cookie', 'cookie1')\n        headers.add_header('Set-cookie', 'cookie2')\n        headers.add_header('Test', 'test')\n        headers.add_header('Test', 'test2')\n        res = Response(io.BytesIO(b''), headers=headers, url='test://')\n        assert res.get_header('test') == 'test, test2'\n        assert res.get_header('set-Cookie') == 'cookie1'\n        assert res.get_header('notexist', 'default') == 'default'\n\n    def test_compat(self):\n        res = Response(io.BytesIO(b''), url='test://', status=404, headers={'test': 'test'})\n        with warnings.catch_warnings():\n            warnings.simplefilter('ignore', category=DeprecationWarning)\n            assert res.code == res.getcode() == res.status\n            assert res.geturl() == res.url\n            assert res.info() is res.headers\n            assert res.getheader('test') == res.get_header('test')\n", "from .common import InfoExtractor\nfrom ..utils import (\n    ExtractorError,\n    smuggle_url,\n    str_or_none,\n    traverse_obj,\n    urlencode_postdata,\n)\n\n\nclass CybraryBaseIE(InfoExtractor):\n    _API_KEY = 'AIzaSyCX9ru6j70PX2My1Eq6Q1zoMAhuTdXlzSw'\n    _ENDPOINTS = {\n        'course': 'https://app.cybrary.it/courses/api/catalog/browse/course/{}',\n        'course_enrollment': 'https://app.cybrary.it/courses/api/catalog/{}/enrollment',\n        'enrollment': 'https://app.cybrary.it/courses/api/enrollment/{}',\n        'launch': 'https://app.cybrary.it/courses/api/catalog/{}/launch',\n        'vimeo_oembed': 'https://vimeo.com/api/oembed.json?url=https://vimeo.com/{}',\n    }\n    _NETRC_MACHINE = 'cybrary'\n    _TOKEN = None\n\n    def _perform_login(self, username, password):\n        CybraryBaseIE._TOKEN = self._download_json(\n            f'https://identitytoolkit.googleapis.com/v1/accounts:signInWithPassword?key={self._API_KEY}',\n            None, data=urlencode_postdata({'email': username, 'password': password, 'returnSecureToken': True}),\n            note='Logging in')['idToken']\n\n    def _real_initialize(self):\n        if not self._TOKEN:\n            self.raise_login_required(method='password')\n\n    def _call_api(self, endpoint, item_id):\n        return self._download_json(\n            self._ENDPOINTS[endpoint].format(item_id), item_id,\n            note=f'Downloading {endpoint} JSON metadata',\n            headers={'Authorization': f'Bearer {self._TOKEN}'})\n\n    def _get_vimeo_id(self, activity_id):\n        launch_api = self._call_api('launch', activity_id)\n\n        if launch_api.get('url'):\n            return self._search_regex(r'https?://player\\.vimeo\\.com/video/(?P<vimeo_id>[0-9]+)', launch_api['url'], 'vimeo_id')\n        return traverse_obj(launch_api, ('vendor_data', 'content', ..., 'videoId'), get_all=False)\n\n\nclass CybraryIE(CybraryBaseIE):\n    _VALID_URL = r'https?://app\\.cybrary\\.it/immersive/(?P<enrollment>[0-9]+)/activity/(?P<id>[0-9]+)'\n    _TESTS = [{\n        'url': 'https://app.cybrary.it/immersive/12487950/activity/63102',\n        'md5': '9ae12d37e555cb2ed554223a71a701d0',\n        'info_dict': {\n            'id': '646609770',\n            'ext': 'mp4',\n            'title': 'Getting Started',\n            'thumbnail': 'https://i.vimeocdn.com/video/1301817996-76a268f0c56cff18a5cecbbdc44131eb9dda0c80eb0b3a036_1280',\n            'series_id': '63111',\n            'uploader_url': 'https://vimeo.com/user30867300',\n            'duration': 88,\n            'uploader_id': 'user30867300',\n            'series': 'Cybrary Orientation',\n            'uploader': 'Cybrary',\n            'chapter': 'Cybrary Orientation Series',\n            'chapter_id': '63110'\n        },\n        'expected_warnings': ['No authenticators for vimeo']\n    }, {\n        'url': 'https://app.cybrary.it/immersive/12747143/activity/52686',\n        'md5': '62f26547dccc59c44363e2a13d4ad08d',\n        'info_dict': {\n            'id': '445638073',\n            'ext': 'mp4',\n            'title': 'Azure Virtual Network IP Addressing',\n            'thumbnail': 'https://i.vimeocdn.com/video/936667051-1647ace66c627d4a2382185e0dae8deb830309bfddd53f8b2367b2f91e92ed0e-d_1280',\n            'series_id': '52733',\n            'uploader_url': 'https://vimeo.com/user30867300',\n            'duration': 426,\n            'uploader_id': 'user30867300',\n            'series': 'AZ-500: Microsoft Azure Security Technologies',\n            'uploader': 'Cybrary',\n            'chapter': 'Implement Network Security',\n            'chapter_id': '52693'\n        },\n        'expected_warnings': ['No authenticators for vimeo']\n    }]\n\n    def _real_extract(self, url):\n        activity_id, enrollment_id = self._match_valid_url(url).group('id', 'enrollment')\n        course = self._call_api('enrollment', enrollment_id)['content']\n        activity = traverse_obj(course, ('learning_modules', ..., 'activities', lambda _, v: int(activity_id) == v['id']), get_all=False)\n\n        if activity.get('type') not in ['Video Activity', 'Lesson Activity']:\n            raise ExtractorError('The activity is not a video', expected=True)\n\n        module = next((m for m in course.get('learning_modules') or []\n                      if int(activity_id) in traverse_obj(m, ('activities', ..., 'id') or [])), None)\n\n        vimeo_id = self._get_vimeo_id(activity_id)\n\n        return {\n            '_type': 'url_transparent',\n            'series': traverse_obj(course, ('content_description', 'title')),\n            'series_id': str_or_none(traverse_obj(course, ('content_description', 'id'))),\n            'id': vimeo_id,\n            'chapter': module.get('title'),\n            'chapter_id': str_or_none(module.get('id')),\n            'title': activity.get('title'),\n            'url': smuggle_url(f'https://player.vimeo.com/video/{vimeo_id}', {'referer': 'https://api.cybrary.it'})\n        }\n\n\nclass CybraryCourseIE(CybraryBaseIE):\n    _VALID_URL = r'https://app\\.cybrary\\.it/browse/course/(?P<id>[\\w-]+)/?(?:$|[#?])'\n    _TESTS = [{\n        'url': 'https://app.cybrary.it/browse/course/az-500-microsoft-azure-security-technologies',\n        'info_dict': {\n            'id': 898,\n            'title': 'AZ-500: Microsoft Azure Security Technologies',\n            'description': 'md5:69549d379c0fc1dec92926d4e8b6fbd4'\n        },\n        'playlist_count': 59\n    }, {\n        'url': 'https://app.cybrary.it/browse/course/cybrary-orientation',\n        'info_dict': {\n            'id': 1245,\n            'title': 'Cybrary Orientation',\n            'description': 'md5:9e69ff66b32fe78744e0ad4babe2e88e'\n        },\n        'playlist_count': 4\n    }]\n\n    def _real_extract(self, url):\n        course_id = self._match_id(url)\n        course = self._call_api('course', course_id)\n        enrollment_info = self._call_api('course_enrollment', course['id'])\n\n        entries = [self.url_result(\n            f'https://app.cybrary.it/immersive/{enrollment_info[\"id\"]}/activity/{activity[\"id\"]}')\n            for activity in traverse_obj(course, ('content_item', 'learning_modules', ..., 'activities', ...))]\n\n        return self.playlist_result(\n            entries,\n            traverse_obj(course, ('content_item', 'id'), expected_type=str_or_none),\n            course.get('title'), course.get('short_description'))\n", "import re\n\nfrom .common import InfoExtractor\nfrom ..compat import compat_urlparse\nfrom ..utils import (\n    clean_html,\n    extract_attributes,\n    ExtractorError,\n    get_elements_by_class,\n    int_or_none,\n    js_to_json,\n    smuggle_url,\n    unescapeHTML,\n)\n\n\ndef _get_elements_by_tag_and_attrib(html, tag=None, attribute=None, value=None, escape_value=True):\n    \"\"\"Return the content of the tag with the specified attribute in the passed HTML document\"\"\"\n\n    if tag is None:\n        tag = '[a-zA-Z0-9:._-]+'\n    if attribute is None:\n        attribute = ''\n    else:\n        attribute = r'\\s+(?P<attribute>%s)' % re.escape(attribute)\n    if value is None:\n        value = ''\n    else:\n        value = re.escape(value) if escape_value else value\n        value = '=[\\'\"]?(?P<value>%s)[\\'\"]?' % value\n\n    retlist = []\n    for m in re.finditer(r'''(?xs)\n        <(?P<tag>%s)\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|=\"[^\"]*\"|='[^']*'|))*?\n         %s%s\n         (?:\\s+[a-zA-Z0-9:._-]+(?:=[a-zA-Z0-9:._-]*|=\"[^\"]*\"|='[^']*'|))*?\n        \\s*>\n        (?P<content>.*?)\n        </\\1>\n    ''' % (tag, attribute, value), html):\n        retlist.append(m)\n\n    return retlist\n\n\ndef _get_element_by_tag_and_attrib(html, tag=None, attribute=None, value=None, escape_value=True):\n    retval = _get_elements_by_tag_and_attrib(html, tag, attribute, value, escape_value)\n    return retval[0] if retval else None\n\n\nclass DubokuIE(InfoExtractor):\n    IE_NAME = 'duboku'\n    IE_DESC = 'www.duboku.io'\n\n    _VALID_URL = r'(?:https?://[^/]+\\.duboku\\.io/vodplay/)(?P<id>[0-9]+-[0-9-]+)\\.html.*'\n    _TESTS = [{\n        'url': 'https://w.duboku.io/vodplay/1575-1-1.html',\n        'info_dict': {\n            'id': '1575-1-1',\n            'ext': 'mp4',\n            'series': '\u767d\u8272\u6708\u5149',\n            'title': 'contains:\u767d\u8272\u6708\u5149',\n            'season_number': 1,\n            'episode_number': 1,\n            'season': 'Season 1',\n            'episode_id': '1',\n            'season_id': '1',\n            'episode': 'Episode 1',\n        },\n        'params': {\n            'skip_download': 'm3u8 download',\n        },\n    }, {\n        'url': 'https://w.duboku.io/vodplay/1588-1-1.html',\n        'info_dict': {\n            'id': '1588-1-1',\n            'ext': 'mp4',\n            'series': '\u4eb2\u7231\u7684\u81ea\u5df1',\n            'title': 'contains:\u7b2c1\u96c6',\n            'season_number': 1,\n            'episode_number': 1,\n            'episode': 'Episode 1',\n            'season': 'Season 1',\n            'episode_id': '1',\n            'season_id': '1',\n        },\n        'params': {\n            'skip_download': 'm3u8 download',\n        },\n    }]\n\n    _PLAYER_DATA_PATTERN = r'player_data\\s*=\\s*(\\{\\s*(.*)})\\s*;?\\s*</script'\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        temp = video_id.split('-')\n        series_id = temp[0]\n        season_id = temp[1]\n        episode_id = temp[2]\n\n        webpage_url = 'https://w.duboku.io/vodplay/%s.html' % video_id\n        webpage_html = self._download_webpage(webpage_url, video_id)\n\n        # extract video url\n\n        player_data = self._search_regex(\n            self._PLAYER_DATA_PATTERN, webpage_html, 'player_data')\n        player_data = self._parse_json(player_data, video_id, js_to_json)\n\n        # extract title\n\n        temp = get_elements_by_class('title', webpage_html)\n        series_title = None\n        title = None\n        for html in temp:\n            mobj = re.search(r'<a\\s+.*>(.*)</a>', html)\n            if mobj:\n                href = extract_attributes(mobj.group(0)).get('href')\n                if href:\n                    mobj1 = re.search(r'/(\\d+)\\.html', href)\n                    if mobj1 and mobj1.group(1) == series_id:\n                        series_title = clean_html(mobj.group(0))\n                        series_title = re.sub(r'[\\s\\r\\n\\t]+', ' ', series_title)\n                        title = clean_html(html)\n                        title = re.sub(r'[\\s\\r\\n\\t]+', ' ', title)\n                        break\n\n        data_url = player_data.get('url')\n        if not data_url:\n            raise ExtractorError('Cannot find url in player_data')\n        data_from = player_data.get('from')\n\n        # if it is an embedded iframe, maybe it's an external source\n        headers = {'Referer': webpage_url}\n        if data_from == 'iframe':\n            # use _type url_transparent to retain the meaningful details\n            # of the video.\n            return {\n                '_type': 'url_transparent',\n                'url': smuggle_url(data_url, {'referer': webpage_url}),\n                'id': video_id,\n                'title': title,\n                'series': series_title,\n                'season_number': int_or_none(season_id),\n                'season_id': season_id,\n                'episode_number': int_or_none(episode_id),\n                'episode_id': episode_id,\n            }\n\n        formats = self._extract_m3u8_formats(data_url, video_id, 'mp4', headers=headers)\n\n        return {\n            'id': video_id,\n            'title': title,\n            'series': series_title,\n            'season_number': int_or_none(season_id),\n            'season_id': season_id,\n            'episode_number': int_or_none(episode_id),\n            'episode_id': episode_id,\n            'formats': formats,\n            'http_headers': headers\n        }\n\n\nclass DubokuPlaylistIE(InfoExtractor):\n    IE_NAME = 'duboku:list'\n    IE_DESC = 'www.duboku.io entire series'\n\n    _VALID_URL = r'(?:https?://[^/]+\\.duboku\\.io/voddetail/)(?P<id>[0-9]+)\\.html.*'\n    _TESTS = [{\n        'url': 'https://w.duboku.io/voddetail/1575.html',\n        'info_dict': {\n            'id': 'startswith:1575',\n            'title': '\u767d\u8272\u6708\u5149',\n        },\n        'playlist_count': 12,\n    }, {\n        'url': 'https://w.duboku.io/voddetail/1554.html',\n        'info_dict': {\n            'id': 'startswith:1554',\n            'title': '\u4ee5\u5bb6\u4eba\u4e4b\u540d',\n        },\n        'playlist_mincount': 30,\n    }]\n\n    def _real_extract(self, url):\n        mobj = self._match_valid_url(url)\n        if mobj is None:\n            raise ExtractorError('Invalid URL: %s' % url)\n        series_id = mobj.group('id')\n        fragment = compat_urlparse.urlparse(url).fragment\n\n        webpage_url = 'https://w.duboku.io/voddetail/%s.html' % series_id\n        webpage_html = self._download_webpage(webpage_url, series_id)\n\n        # extract title\n\n        title = _get_element_by_tag_and_attrib(webpage_html, 'h1', 'class', 'title')\n        title = unescapeHTML(title.group('content')) if title else None\n        if not title:\n            title = self._html_search_meta('keywords', webpage_html)\n        if not title:\n            title = _get_element_by_tag_and_attrib(webpage_html, 'title')\n            title = unescapeHTML(title.group('content')) if title else None\n\n        # extract playlists\n\n        playlists = {}\n        for div in _get_elements_by_tag_and_attrib(\n                webpage_html, attribute='id', value='playlist\\\\d+', escape_value=False):\n            playlist_id = div.group('value')\n            playlist = []\n            for a in _get_elements_by_tag_and_attrib(\n                    div.group('content'), 'a', 'href', value='[^\\'\"]+?', escape_value=False):\n                playlist.append({\n                    'href': unescapeHTML(a.group('value')),\n                    'title': unescapeHTML(a.group('content'))\n                })\n            playlists[playlist_id] = playlist\n\n        # select the specified playlist if url fragment exists\n        playlist = None\n        playlist_id = None\n        if fragment:\n            playlist = playlists.get(fragment)\n            playlist_id = fragment\n        else:\n            first = next(iter(playlists.items()), None)\n            if first:\n                (playlist_id, playlist) = first\n        if not playlist:\n            raise ExtractorError(\n                'Cannot find %s' % fragment if fragment else 'Cannot extract playlist')\n\n        # return url results\n        return self.playlist_result([\n            self.url_result(\n                compat_urlparse.urljoin('https://w.duboku.io', x['href']),\n                ie=DubokuIE.ie_key(), video_title=x.get('title'))\n            for x in playlist], series_id + '#' + playlist_id, title)\n", "import re\nimport urllib.parse\n\nfrom .common import InfoExtractor\nfrom .youtube import YoutubeTabIE\nfrom ..utils import parse_qs, smuggle_url, traverse_obj\n\n\nclass EmbedlyIE(InfoExtractor):\n    _VALID_URL = r'https?://(?:www|cdn\\.)?embedly\\.com/widgets/media\\.html\\?(?:[^#]*?&)?(?:src|url)=(?:[^#&]+)'\n    _TESTS = [{\n        'url': 'https://cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DUUGLim4T2loE5rwCMdpCIPVg&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DSU4fj_aEMVw%26list%3DUUGLim4T2loE5rwCMdpCIPVg&image=http%3A%2F%2Fi.ytimg.com%2Fvi%2FSU4fj_aEMVw%2Fhqdefault.jpg&key=8ee8a2e6a8cc47aab1a5ee67f9a178e0&type=text%2Fhtml&schema=youtube&autoplay=1',\n        'info_dict': {\n            'id': 'UUGLim4T2loE5rwCMdpCIPVg',\n            'modified_date': '20221225',\n            'view_count': int,\n            'uploader_url': 'https://www.youtube.com/@TraciHinesMusic',\n            'channel_id': 'UCGLim4T2loE5rwCMdpCIPVg',\n            'uploader': 'TraciJHines',\n            'channel_url': 'https://www.youtube.com/@TraciHinesMusic',\n            'channel': 'TraciJHines',\n            'availability': 'public',\n            'uploader_id': 'UCGLim4T2loE5rwCMdpCIPVg',\n            'description': '',\n            'tags': [],\n            'title': 'Uploads from TraciJHines',\n        },\n        'playlist_mincount': 10,\n    }, {\n        'url': 'https://cdn.embedly.com/widgets/media.html?src=http%3A%2F%2Fwww.youtube.com%2Fembed%2Fvideoseries%3Flist%3DUUGLim4T2loE5rwCMdpCIPVg&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DSU4fj_aEMVw%26list%3DUUGLim4T2loE5rwCMdpCIPVg&image=http%3A%2F%2Fi.ytimg.com%2Fvi%2FSU4fj_aEMVw%2Fhqdefault.jpg&key=8ee8a2e6a8cc47aab1a5ee67f9a178e0&type=text%2Fhtml&schema=youtube&autoplay=1',\n        'params': {'noplaylist': True},\n        'info_dict': {\n            'id': 'SU4fj_aEMVw',\n            'ext': 'mp4',\n            'title': 'I\\'m on Patreon!',\n            'age_limit': 0,\n            'categories': ['Entertainment'],\n            'thumbnail': 'https://i.ytimg.com/vi_webp/SU4fj_aEMVw/maxresdefault.webp',\n            'live_status': 'not_live',\n            'playable_in_embed': True,\n            'channel': 'TraciJHines',\n            'uploader_id': 'TraciJHines',\n            'channel_url': 'https://www.youtube.com/channel/UCGLim4T2loE5rwCMdpCIPVg',\n            'uploader_url': 'http://www.youtube.com/user/TraciJHines',\n            'upload_date': '20150211',\n            'duration': 282,\n            'availability': 'public',\n            'channel_follower_count': int,\n            'tags': 'count:39',\n            'view_count': int,\n            'comment_count': int,\n            'channel_id': 'UCGLim4T2loE5rwCMdpCIPVg',\n            'like_count': int,\n            'uploader': 'TraciJHines',\n            'description': 'md5:8af6425f50bd46fbf29f3db0fc3a8364',\n            'chapters': list,\n\n        },\n    }, {\n        'url': 'https://cdn.embedly.com/widgets/media.html?src=https://player.vimeo.com/video/1234567?h=abcdefgh',\n        'only_matching': True,\n    }]\n\n    _WEBPAGE_TESTS = [{\n        'url': 'http://www.permacultureetc.com/2022/12/comment-greffer-facilement-les-arbres-fruitiers.html',\n        'info_dict': {\n            'id': 'pfUK_ADTvgY',\n            'ext': 'mp4',\n            'title': 'Comment greffer facilement les arbres fruitiers ? (mois par mois)',\n            'description': 'md5:d3a876995e522f138aabb48e040bfb4c',\n            'view_count': int,\n            'upload_date': '20221210',\n            'comment_count': int,\n            'live_status': 'not_live',\n            'channel_id': 'UCsM4_jihNFYe4CtSkXvDR-Q',\n            'channel_follower_count': int,\n            'tags': ['permaculture', 'jardinage', 'dekarz', 'autonomie', 'greffe', 'fruitiers', 'arbres', 'jardin for\u00eat', 'for\u00eat comestible', 'damien'],\n            'playable_in_embed': True,\n            'uploader': 'permaculture agro\u00e9cologie etc...',\n            'channel': 'permaculture agro\u00e9cologie etc...',\n            'thumbnail': 'https://i.ytimg.com/vi/pfUK_ADTvgY/sddefault.jpg',\n            'duration': 1526,\n            'channel_url': 'https://www.youtube.com/channel/UCsM4_jihNFYe4CtSkXvDR-Q',\n            'age_limit': 0,\n            'uploader_id': 'permacultureetc',\n            'like_count': int,\n            'uploader_url': 'http://www.youtube.com/user/permacultureetc',\n            'categories': ['Education'],\n            'availability': 'public',\n        },\n    }]\n\n    @classmethod\n    def _extract_from_webpage(cls, url, webpage):\n        # Bypass \"ie=cls\" and suitable check\n        for mobj in re.finditer(r'class=[\"\\']embedly-card[\"\\'][^>]href=[\"\\'](?P<url>[^\"\\']+)', webpage):\n            yield cls.url_result(mobj.group('url'))\n\n        for mobj in re.finditer(r'class=[\"\\']embedly-embed[\"\\'][^>]src=[\"\\'][^\"\\']*url=(?P<url>[^&]+)', webpage):\n            yield cls.url_result(urllib.parse.unquote(mobj.group('url')))\n\n    def _real_extract(self, url):\n        qs = parse_qs(url)\n        src = urllib.parse.unquote(traverse_obj(qs, ('url', 0)) or '')\n        if src and YoutubeTabIE.suitable(src):\n            return self.url_result(src, YoutubeTabIE)\n        return self.url_result(smuggle_url(\n            urllib.parse.unquote(traverse_obj(qs, ('src', 0), ('url', 0))),\n            {'referer': url}))\n", "import os\nimport re\nimport types\nimport urllib.parse\nimport xml.etree.ElementTree\n\nfrom .common import InfoExtractor  # isort: split\nfrom .commonprotocols import RtmpIE\nfrom .youtube import YoutubeIE\nfrom ..compat import compat_etree_fromstring\nfrom ..utils import (\n    KNOWN_EXTENSIONS,\n    MEDIA_EXTENSIONS,\n    ExtractorError,\n    UnsupportedError,\n    determine_ext,\n    determine_protocol,\n    dict_get,\n    extract_basic_auth,\n    filter_dict,\n    format_field,\n    int_or_none,\n    is_html,\n    js_to_json,\n    merge_dicts,\n    mimetype2ext,\n    orderedSet,\n    parse_duration,\n    parse_resolution,\n    smuggle_url,\n    str_or_none,\n    traverse_obj,\n    try_call,\n    unescapeHTML,\n    unified_timestamp,\n    unsmuggle_url,\n    update_url_query,\n    urlhandle_detect_ext,\n    url_or_none,\n    urljoin,\n    variadic,\n    xpath_attr,\n    xpath_text,\n    xpath_with_ns,\n)\n\n\nclass GenericIE(InfoExtractor):\n    IE_DESC = 'Generic downloader that works on some sites'\n    _VALID_URL = r'.*'\n    IE_NAME = 'generic'\n    _NETRC_MACHINE = False  # Suppress username warning\n    _TESTS = [\n        # Direct link to a video\n        {\n            'url': 'http://media.w3.org/2010/05/sintel/trailer.mp4',\n            'md5': '67d406c2bcb6af27fa886f31aa934bbe',\n            'info_dict': {\n                'id': 'trailer',\n                'ext': 'mp4',\n                'title': 'trailer',\n                'upload_date': '20100513',\n                'direct': True,\n                'timestamp': 1273772943.0,\n            }\n        },\n        # Direct link to media delivered compressed (until Accept-Encoding is *)\n        {\n            'url': 'http://calimero.tk/muzik/FictionJunction-Parallel_Hearts.flac',\n            'md5': '128c42e68b13950268b648275386fc74',\n            'info_dict': {\n                'id': 'FictionJunction-Parallel_Hearts',\n                'ext': 'flac',\n                'title': 'FictionJunction-Parallel_Hearts',\n                'upload_date': '20140522',\n            },\n            'expected_warnings': [\n                'URL could be a direct video link, returning it as such.'\n            ],\n            'skip': 'URL invalid',\n        },\n        # Direct download with broken HEAD\n        {\n            'url': 'http://ai-radio.org:8000/radio.opus',\n            'info_dict': {\n                'id': 'radio',\n                'ext': 'opus',\n                'title': 'radio',\n            },\n            'params': {\n                'skip_download': True,  # infinite live stream\n            },\n            'expected_warnings': [\n                r'501.*Not Implemented',\n                r'400.*Bad Request',\n            ],\n        },\n        # Direct link with incorrect MIME type\n        {\n            'url': 'http://ftp.nluug.nl/video/nluug/2014-11-20_nj14/zaal-2/5_Lennart_Poettering_-_Systemd.webm',\n            'md5': '4ccbebe5f36706d85221f204d7eb5913',\n            'info_dict': {\n                'url': 'http://ftp.nluug.nl/video/nluug/2014-11-20_nj14/zaal-2/5_Lennart_Poettering_-_Systemd.webm',\n                'id': '5_Lennart_Poettering_-_Systemd',\n                'ext': 'webm',\n                'title': '5_Lennart_Poettering_-_Systemd',\n                'upload_date': '20141120',\n                'direct': True,\n                'timestamp': 1416498816.0,\n            },\n            'expected_warnings': [\n                'URL could be a direct video link, returning it as such.'\n            ]\n        },\n        # RSS feed\n        {\n            'url': 'http://phihag.de/2014/youtube-dl/rss2.xml',\n            'info_dict': {\n                'id': 'https://phihag.de/2014/youtube-dl/rss2.xml',\n                'title': 'Zero Punctuation',\n                'description': 're:.*groundbreaking video review series.*'\n            },\n            'playlist_mincount': 11,\n        },\n        # RSS feed with enclosure\n        {\n            'url': 'http://podcastfeeds.nbcnews.com/audio/podcast/MSNBC-MADDOW-NETCAST-M4V.xml',\n            'info_dict': {\n                'id': 'http://podcastfeeds.nbcnews.com/nbcnews/video/podcast/MSNBC-MADDOW-NETCAST-M4V.xml',\n                'title': 'MSNBC Rachel Maddow (video)',\n                'description': 're:.*her unique approach to storytelling.*',\n            },\n            'playlist': [{\n                'info_dict': {\n                    'ext': 'mov',\n                    'id': 'pdv_maddow_netcast_mov-12-03-2020-223726',\n                    'title': 'MSNBC Rachel Maddow (video) - 12-03-2020-223726',\n                    'description': 're:.*her unique approach to storytelling.*',\n                    'upload_date': '20201204',\n                },\n            }],\n            'skip': 'Dead link',\n        },\n        # RSS feed with item with description and thumbnails\n        {\n            'url': 'https://anchor.fm/s/dd00e14/podcast/rss',\n            'info_dict': {\n                'id': 'https://anchor.fm/s/dd00e14/podcast/rss',\n                'title': 're:.*100% Hydrogen.*',\n                'description': 're:.*In this episode.*',\n            },\n            'playlist': [{\n                'info_dict': {\n                    'ext': 'm4a',\n                    'id': '818a5d38-01cd-152f-2231-ee479677fa82',\n                    'title': 're:Hydrogen!',\n                    'description': 're:.*In this episode we are going.*',\n                    'timestamp': 1567977776,\n                    'upload_date': '20190908',\n                    'duration': 423,\n                    'thumbnail': r're:^https?://.*\\.jpg$',\n                    'episode_number': 1,\n                    'season_number': 1,\n                    'age_limit': 0,\n                    'season': 'Season 1',\n                    'direct': True,\n                    'episode': 'Episode 1',\n                },\n            }],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # RSS feed with enclosures and unsupported link URLs\n        {\n            'url': 'http://www.hellointernet.fm/podcast?format=rss',\n            'info_dict': {\n                'id': 'http://www.hellointernet.fm/podcast?format=rss',\n                'description': 'CGP Grey and Brady Haran talk about YouTube, life, work, whatever.',\n                'title': 'Hello Internet',\n            },\n            'playlist_mincount': 100,\n        },\n        # RSS feed with guid\n        {\n            'url': 'https://www.omnycontent.com/d/playlist/a7b4f8fe-59d9-4afc-a79a-a90101378abf/bf2c1d80-3656-4449-9d00-a903004e8f84/efbff746-e7c1-463a-9d80-a903004e8f8f/podcast.rss',\n            'info_dict': {\n                'id': 'https://www.omnycontent.com/d/playlist/a7b4f8fe-59d9-4afc-a79a-a90101378abf/bf2c1d80-3656-4449-9d00-a903004e8f84/efbff746-e7c1-463a-9d80-a903004e8f8f/podcast.rss',\n                'description': 'md5:be809a44b63b0c56fb485caf68685520',\n                'title': 'The Little Red Podcast',\n            },\n            'playlist_mincount': 76,\n        },\n        # SMIL from http://videolectures.net/promogram_igor_mekjavic_eng\n        {\n            'url': 'http://videolectures.net/promogram_igor_mekjavic_eng/video/1/smil.xml',\n            'info_dict': {\n                'id': 'smil',\n                'ext': 'mp4',\n                'title': 'Automatics, robotics and biocybernetics',\n                'description': 'md5:815fc1deb6b3a2bff99de2d5325be482',\n                'upload_date': '20130627',\n                'formats': 'mincount:16',\n                'subtitles': 'mincount:1',\n            },\n            'params': {\n                'force_generic_extractor': True,\n                'skip_download': True,\n            },\n        },\n        # SMIL from http://www1.wdr.de/mediathek/video/livestream/index.html\n        {\n            'url': 'http://metafilegenerator.de/WDR/WDR_FS/hds/hds.smil',\n            'info_dict': {\n                'id': 'hds',\n                'ext': 'flv',\n                'title': 'hds',\n                'formats': 'mincount:1',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # SMIL from https://www.restudy.dk/video/play/id/1637\n        {\n            'url': 'https://www.restudy.dk/awsmedia/SmilDirectory/video_1637.xml',\n            'info_dict': {\n                'id': 'video_1637',\n                'ext': 'flv',\n                'title': 'video_1637',\n                'formats': 'mincount:3',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # SMIL from http://adventure.howstuffworks.com/5266-cool-jobs-iditarod-musher-video.htm\n        {\n            'url': 'http://services.media.howstuffworks.com/videos/450221/smil-service.smil',\n            'info_dict': {\n                'id': 'smil-service',\n                'ext': 'flv',\n                'title': 'smil-service',\n                'formats': 'mincount:1',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # SMIL from http://new.livestream.com/CoheedandCambria/WebsterHall/videos/4719370\n        {\n            'url': 'http://api.new.livestream.com/accounts/1570303/events/1585861/videos/4719370.smil',\n            'info_dict': {\n                'id': '4719370',\n                'ext': 'mp4',\n                'title': '571de1fd-47bc-48db-abf9-238872a58d1f',\n                'formats': 'mincount:3',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # XSPF playlist from http://www.telegraaf.nl/tv/nieuws/binnenland/24353229/__Tikibad_ontruimd_wegens_brand__.html\n        {\n            'url': 'http://www.telegraaf.nl/xml/playlist/2015/8/7/mZlp2ctYIUEB.xspf',\n            'info_dict': {\n                'id': 'mZlp2ctYIUEB',\n                'ext': 'mp4',\n                'title': 'Tikibad ontruimd wegens brand',\n                'description': 'md5:05ca046ff47b931f9b04855015e163a4',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 33,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': '404 Not Found',\n        },\n        # MPD from http://dash-mse-test.appspot.com/media.html\n        {\n            'url': 'http://yt-dash-mse-test.commondatastorage.googleapis.com/media/car-20120827-manifest.mpd',\n            'md5': '4b57baab2e30d6eb3a6a09f0ba57ef53',\n            'info_dict': {\n                'id': 'car-20120827-manifest',\n                'ext': 'mp4',\n                'title': 'car-20120827-manifest',\n                'formats': 'mincount:9',\n                'upload_date': '20130904',\n                'timestamp': 1378272859.0,\n            },\n        },\n        # m3u8 served with Content-Type: audio/x-mpegURL; charset=utf-8\n        {\n            'url': 'http://once.unicornmedia.com/now/master/playlist/bb0b18ba-64f5-4b1b-a29f-0ac252f06b68/77a785f3-5188-4806-b788-0893a61634ed/93677179-2d99-4ef4-9e17-fe70d49abfbf/content.m3u8',\n            'info_dict': {\n                'id': 'content',\n                'ext': 'mp4',\n                'title': 'content',\n                'formats': 'mincount:8',\n            },\n            'params': {\n                # m3u8 downloads\n                'skip_download': True,\n            },\n            'skip': 'video gone',\n        },\n        # m3u8 served with Content-Type: text/plain\n        {\n            'url': 'http://www.nacentapps.com/m3u8/index.m3u8',\n            'info_dict': {\n                'id': 'index',\n                'ext': 'mp4',\n                'title': 'index',\n                'upload_date': '20140720',\n                'formats': 'mincount:11',\n            },\n            'params': {\n                # m3u8 downloads\n                'skip_download': True,\n            },\n            'skip': 'video gone',\n        },\n        # google redirect\n        {\n            'url': 'http://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&ved=0CCUQtwIwAA&url=http%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DcmQHVoWB5FY&ei=F-sNU-LLCaXk4QT52ICQBQ&usg=AFQjCNEw4hL29zgOohLXvpJ-Bdh2bils1Q&bvm=bv.61965928,d.bGE',\n            'info_dict': {\n                'id': 'cmQHVoWB5FY',\n                'ext': 'mp4',\n                'upload_date': '20130224',\n                'uploader_id': '@TheVerge',\n                'description': r're:^Chris Ziegler takes a look at the\\.*',\n                'uploader': 'The Verge',\n                'title': 'First Firefox OS phones side-by-side',\n            },\n            'params': {\n                'skip_download': False,\n            }\n        },\n        {\n            # redirect in Refresh HTTP header\n            'url': 'https://www.facebook.com/l.php?u=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DpO8h3EaFRdo&h=TAQHsoToz&enc=AZN16h-b6o4Zq9pZkCCdOLNKMN96BbGMNtcFwHSaazus4JHT_MFYkAA-WARTX2kvsCIdlAIyHZjl6d33ILIJU7Jzwk_K3mcenAXoAzBNoZDI_Q7EXGDJnIhrGkLXo_LJ_pAa2Jzbx17UHMd3jAs--6j2zaeto5w9RTn8T_1kKg3fdC5WPX9Dbb18vzH7YFX0eSJmoa6SP114rvlkw6pkS1-T&s=1',\n            'info_dict': {\n                'id': 'pO8h3EaFRdo',\n                'ext': 'mp4',\n                'title': 'Tripeo Boiler Room x Dekmantel Festival DJ Set',\n                'description': 'md5:6294cc1af09c4049e0652b51a2df10d5',\n                'upload_date': '20150917',\n                'uploader_id': 'brtvofficial',\n                'uploader': 'Boiler Room',\n            },\n            'params': {\n                'skip_download': False,\n            },\n        },\n        {\n            'url': 'http://www.hodiho.fr/2013/02/regis-plante-sa-jeep.html',\n            'md5': '85b90ccc9d73b4acd9138d3af4c27f89',\n            'info_dict': {\n                'id': '13601338388002',\n                'ext': 'mp4',\n                'uploader': 'www.hodiho.fr',\n                'title': 'R\\u00e9gis plante sa Jeep',\n            }\n        },\n        # bandcamp page with custom domain\n        {\n            'add_ie': ['Bandcamp'],\n            'url': 'http://bronyrock.com/track/the-pony-mash',\n            'info_dict': {\n                'id': '3235767654',\n                'ext': 'mp3',\n                'title': 'The Pony Mash',\n                'uploader': 'M_Pallante',\n            },\n            'skip': 'There is a limit of 200 free downloads / month for the test song',\n        },\n        # ooyala video\n        {\n            'url': 'http://www.rollingstone.com/music/videos/norwegian-dj-cashmere-cat-goes-spartan-on-with-me-premiere-20131219',\n            'md5': '166dd577b433b4d4ebfee10b0824d8ff',\n            'info_dict': {\n                'id': 'BwY2RxaTrTkslxOfcan0UCf0YqyvWysJ',\n                'ext': 'mp4',\n                'title': '2cc213299525360.mov',  # that's what we get\n                'duration': 238.231,\n            },\n            'add_ie': ['Ooyala'],\n        },\n        {\n            # ooyala video embedded with http://player.ooyala.com/iframe.js\n            'url': 'http://www.macrumors.com/2015/07/24/steve-jobs-the-man-in-the-machine-first-trailer/',\n            'info_dict': {\n                'id': 'p0MGJndjoG5SOKqO_hZJuZFPB-Tr5VgB',\n                'ext': 'mp4',\n                'title': '\"Steve Jobs: Man in the Machine\" trailer',\n                'description': 'The first trailer for the Alex Gibney documentary \"Steve Jobs: Man in the Machine.\"',\n                'duration': 135.427,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'movie expired',\n        },\n        # ooyala video embedded with http://player.ooyala.com/static/v4/production/latest/core.min.js\n        {\n            'url': 'http://wnep.com/2017/07/22/steampunk-fest-comes-to-honesdale/',\n            'info_dict': {\n                'id': 'lwYWYxYzE6V5uJMjNGyKtwwiw9ZJD7t2',\n                'ext': 'mp4',\n                'title': 'Steampunk Fest Comes to Honesdale',\n                'duration': 43.276,\n            },\n            'params': {\n                'skip_download': True,\n            }\n        },\n        # embed.ly video\n        {\n            'url': 'http://www.tested.com/science/weird/460206-tested-grinding-coffee-2000-frames-second/',\n            'info_dict': {\n                'id': '9ODmcdjQcHQ',\n                'ext': 'mp4',\n                'title': 'Tested: Grinding Coffee at 2000 Frames Per Second',\n                'upload_date': '20140225',\n                'description': 'md5:06a40fbf30b220468f1e0957c0f558ff',\n                'uploader': 'Tested',\n                'uploader_id': 'testedcom',\n            },\n            # No need to test YoutubeIE here\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # funnyordie embed\n        {\n            'url': 'http://www.theguardian.com/world/2014/mar/11/obama-zach-galifianakis-between-two-ferns',\n            'info_dict': {\n                'id': '18e820ec3f',\n                'ext': 'mp4',\n                'title': 'Between Two Ferns with Zach Galifianakis: President Barack Obama',\n                'description': 'Episode 18: President Barack Obama sits down with Zach Galifianakis for his most memorable interview yet.',\n            },\n            # HEAD requests lead to endless 301, while GET is OK\n            'expected_warnings': ['301'],\n        },\n        # RUTV embed\n        {\n            'url': 'http://www.rg.ru/2014/03/15/reg-dfo/anklav-anons.html',\n            'info_dict': {\n                'id': '776940',\n                'ext': 'mp4',\n                'title': '\u041e\u0445\u043e\u0442\u0441\u043a\u043e\u0435 \u043c\u043e\u0440\u0435 \u0441\u0442\u0430\u043b\u043e \u0446\u0435\u043b\u0438\u043a\u043e\u043c \u0440\u043e\u0441\u0441\u0438\u0439\u0441\u043a\u0438\u043c',\n                'description': 'md5:5ed62483b14663e2a95ebbe115eb8f43',\n            },\n            'params': {\n                # m3u8 download\n                'skip_download': True,\n            },\n        },\n        # TVC embed\n        {\n            'url': 'http://sch1298sz.mskobr.ru/dou_edu/karamel_ki/filial_galleries/video/iframe_src_http_tvc_ru_video_iframe_id_55304_isplay_false_acc_video_id_channel_brand_id_11_show_episodes_episode_id_32307_frameb/',\n            'info_dict': {\n                'id': '55304',\n                'ext': 'mp4',\n                'title': '\u0414\u043e\u0448\u043a\u043e\u043b\u044c\u043d\u043e\u0435 \u0432\u043e\u0441\u043f\u0438\u0442\u0430\u043d\u0438\u0435',\n            },\n        },\n        # SportBox embed\n        {\n            'url': 'http://www.vestifinance.ru/articles/25753',\n            'info_dict': {\n                'id': '25753',\n                'title': '\u041f\u0440\u044f\u043c\u044b\u0435 \u0442\u0440\u0430\u043d\u0441\u043b\u044f\u0446\u0438\u0438 \u0441 \u0424\u043e\u0440\u0443\u043c\u0430-\u0432\u044b\u0441\u0442\u0430\u0432\u043a\u0438 \"\u0413\u043e\u0441\u0437\u0430\u043a\u0430\u0437-2013\"',\n            },\n            'playlist': [{\n                'info_dict': {\n                    'id': '370908',\n                    'title': '\u0413\u043e\u0441\u0437\u0430\u043a\u0430\u0437. \u0414\u0435\u043d\u044c 3',\n                    'ext': 'mp4',\n                }\n            }, {\n                'info_dict': {\n                    'id': '370905',\n                    'title': '\u0413\u043e\u0441\u0437\u0430\u043a\u0430\u0437. \u0414\u0435\u043d\u044c 2',\n                    'ext': 'mp4',\n                }\n            }, {\n                'info_dict': {\n                    'id': '370902',\n                    'title': '\u0413\u043e\u0441\u0437\u0430\u043a\u0430\u0437. \u0414\u0435\u043d\u044c 1',\n                    'ext': 'mp4',\n                }\n            }],\n            'params': {\n                # m3u8 download\n                'skip_download': True,\n            },\n        },\n        # Myvi.ru embed\n        {\n            'url': 'http://www.kinomyvi.tv/news/detail/Pervij-dublirovannij-trejler--Uzhastikov-_nOw1',\n            'info_dict': {\n                'id': 'f4dafcad-ff21-423d-89b5-146cfd89fa1e',\n                'ext': 'mp4',\n                'title': '\u0423\u0436\u0430\u0441\u0442\u0438\u043a\u0438, \u0440\u0443\u0441\u0441\u043a\u0438\u0439 \u0442\u0440\u0435\u0439\u043b\u0435\u0440 (2015)',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 153,\n            }\n        },\n        # XHamster embed\n        {\n            'url': 'http://www.numisc.com/forum/showthread.php?11696-FM15-which-pumiscer-was-this-%28-vid-%29-%28-alfa-as-fuck-srx-%29&s=711f5db534502e22260dec8c5e2d66d8',\n            'info_dict': {\n                'id': 'showthread',\n                'title': '[NSFL] [FM15] which pumiscer was this ( vid ) ( alfa as fuck srx )',\n            },\n            'playlist_mincount': 7,\n            # This forum does not allow <iframe> syntaxes anymore\n            # Now HTML tags are displayed as-is\n            'skip': 'No videos on this page',\n        },\n        # Embedded TED video\n        {\n            'url': 'http://en.support.wordpress.com/videos/ted-talks/',\n            'md5': '65fdff94098e4a607385a60c5177c638',\n            'info_dict': {\n                'id': '1969',\n                'ext': 'mp4',\n                'title': 'Hidden miracles of the natural world',\n                'uploader': 'Louie Schwartzberg',\n                'description': 'md5:8145d19d320ff3e52f28401f4c4283b9',\n            }\n        },\n        # nowvideo embed hidden behind percent encoding\n        {\n            'url': 'http://www.waoanime.tv/the-super-dimension-fortress-macross-episode-1/',\n            'md5': '2baf4ddd70f697d94b1c18cf796d5107',\n            'info_dict': {\n                'id': '06e53103ca9aa',\n                'ext': 'flv',\n                'title': 'Macross Episode 001  Watch Macross Episode 001 onl',\n                'description': 'No description',\n            },\n        },\n        # arte embed\n        {\n            'url': 'http://www.tv-replay.fr/redirection/20-03-14/x-enius-arte-10753389.html',\n            'md5': '7653032cbb25bf6c80d80f217055fa43',\n            'info_dict': {\n                'id': '048195-004_PLUS7-F',\n                'ext': 'flv',\n                'title': 'X:enius',\n                'description': 'md5:d5fdf32ef6613cdbfd516ae658abf168',\n                'upload_date': '20140320',\n            },\n            'params': {\n                'skip_download': 'Requires rtmpdump'\n            },\n            'skip': 'video gone',\n        },\n        # francetv embed\n        {\n            'url': 'http://www.tsprod.com/replay-du-concert-alcaline-de-calogero',\n            'info_dict': {\n                'id': 'EV_30231',\n                'ext': 'mp4',\n                'title': 'Alcaline, le concert avec Calogero',\n                'description': 'md5:61f08036dcc8f47e9cfc33aed08ffaff',\n                'upload_date': '20150226',\n                'timestamp': 1424989860,\n                'duration': 5400,\n            },\n            'params': {\n                # m3u8 downloads\n                'skip_download': True,\n            },\n            'expected_warnings': [\n                'Forbidden'\n            ]\n        },\n        # Cond\u00e9 Nast embed\n        {\n            'url': 'http://www.wired.com/2014/04/honda-asimo/',\n            'md5': 'ba0dfe966fa007657bd1443ee672db0f',\n            'info_dict': {\n                'id': '53501be369702d3275860000',\n                'ext': 'mp4',\n                'title': 'Honda\u2019s  New Asimo Robot Is More Human Than Ever',\n            }\n        },\n        # Dailymotion embed\n        {\n            'url': 'http://www.spi0n.com/zap-spi0n-com-n216/',\n            'md5': '441aeeb82eb72c422c7f14ec533999cd',\n            'info_dict': {\n                'id': 'k2mm4bCdJ6CQ2i7c8o2',\n                'ext': 'mp4',\n                'title': 'Le Zap de Spi0n n\u00b0216 - Zapping du Web',\n                'description': 'md5:faf028e48a461b8b7fad38f1e104b119',\n                'uploader': 'Spi0n',\n                'uploader_id': 'xgditw',\n                'upload_date': '20140425',\n                'timestamp': 1398441542,\n            },\n            'add_ie': ['Dailymotion'],\n        },\n        # DailyMail embed\n        {\n            'url': 'http://www.bumm.sk/krimi/2017/07/05/biztonsagi-kamera-buktatta-le-az-agg-ferfit-utlegelo-apolot',\n            'info_dict': {\n                'id': '1495629',\n                'ext': 'mp4',\n                'title': 'Care worker punches elderly dementia patient in head 11 times',\n                'description': 'md5:3a743dee84e57e48ec68bf67113199a5',\n            },\n            'add_ie': ['DailyMail'],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # YouTube embed\n        {\n            'url': 'http://www.badzine.de/ansicht/datum/2014/06/09/so-funktioniert-die-neue-englische-badminton-liga.html',\n            'info_dict': {\n                'id': 'FXRb4ykk4S0',\n                'ext': 'mp4',\n                'title': 'The NBL Auction 2014',\n                'uploader': 'BADMINTON England',\n                'uploader_id': 'BADMINTONEvents',\n                'upload_date': '20140603',\n                'description': 'md5:9ef128a69f1e262a700ed83edb163a73',\n            },\n            'add_ie': ['Youtube'],\n            'params': {\n                'skip_download': True,\n            }\n        },\n        # MTVServices embed\n        {\n            'url': 'http://www.vulture.com/2016/06/new-key-peele-sketches-released.html',\n            'md5': 'ca1aef97695ef2c1d6973256a57e5252',\n            'info_dict': {\n                'id': '769f7ec0-0692-4d62-9b45-0d88074bffc1',\n                'ext': 'mp4',\n                'title': 'Key and Peele|October 10, 2012|2|203|Liam Neesons - Uncensored',\n                'description': 'Two valets share their love for movie star Liam Neesons.',\n                'timestamp': 1349922600,\n                'upload_date': '20121011',\n            },\n        },\n        # YouTube embed via <data-embed-url=\"\">\n        {\n            'url': 'https://play.google.com/store/apps/details?id=com.gameloft.android.ANMP.GloftA8HM',\n            'info_dict': {\n                'id': '4vAffPZIT44',\n                'ext': 'mp4',\n                'title': 'Asphalt 8: Airborne - Update - Welcome to Dubai!',\n                'uploader': 'Gameloft',\n                'uploader_id': 'gameloft',\n                'upload_date': '20140828',\n                'description': 'md5:c80da9ed3d83ae6d1876c834de03e1c4',\n            },\n            'params': {\n                'skip_download': True,\n            }\n        },\n        # Flowplayer\n        {\n            'url': 'http://www.handjobhub.com/video/busty-blonde-siri-tit-fuck-while-wank-6313.html',\n            'md5': '9d65602bf31c6e20014319c7d07fba27',\n            'info_dict': {\n                'id': '5123ea6d5e5a7',\n                'ext': 'mp4',\n                'age_limit': 18,\n                'uploader': 'www.handjobhub.com',\n                'title': 'Busty Blonde Siri Tit Fuck While Wank at HandjobHub.com',\n            }\n        },\n        # MLB embed\n        {\n            'url': 'http://umpire-empire.com/index.php/topic/58125-laz-decides-no-thats-low/',\n            'md5': '96f09a37e44da40dd083e12d9a683327',\n            'info_dict': {\n                'id': '33322633',\n                'ext': 'mp4',\n                'title': 'Ump changes call to ball',\n                'description': 'md5:71c11215384298a172a6dcb4c2e20685',\n                'duration': 48,\n                'timestamp': 1401537900,\n                'upload_date': '20140531',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n            },\n        },\n        # Wistia standard embed (async)\n        {\n            'url': 'https://www.getdrip.com/university/brennan-dunn-drip-workshop/',\n            'info_dict': {\n                'id': '807fafadvk',\n                'ext': 'mp4',\n                'title': 'Drip Brennan Dunn Workshop',\n                'description': 'a JV Webinars video from getdrip-1',\n                'duration': 4986.95,\n                'timestamp': 1463607249,\n                'upload_date': '20160518',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'webpage 404 not found',\n        },\n        # Soundcloud embed\n        {\n            'url': 'http://nakedsecurity.sophos.com/2014/10/29/sscc-171-are-you-sure-that-1234-is-a-bad-password-podcast/',\n            'info_dict': {\n                'id': '174391317',\n                'ext': 'mp3',\n                'description': 'md5:ff867d6b555488ad3c52572bb33d432c',\n                'uploader': 'Sophos Security',\n                'title': 'Chet Chat 171 - Oct 29, 2014',\n                'upload_date': '20141029',\n            }\n        },\n        # Soundcloud multiple embeds\n        {\n            'url': 'http://www.guitarplayer.com/lessons/1014/legato-workout-one-hour-to-more-fluid-performance---tab/52809',\n            'info_dict': {\n                'id': '52809',\n                'title': 'Guitar Essentials: Legato Workout\u2014One-Hour to Fluid Performance  | TAB + AUDIO',\n            },\n            'playlist_mincount': 7,\n        },\n        # TuneIn station embed\n        {\n            'url': 'http://radiocnrv.com/promouvoir-radio-cnrv/',\n            'info_dict': {\n                'id': '204146',\n                'ext': 'mp3',\n                'title': 'CNRV',\n                'location': 'Paris, France',\n                'is_live': True,\n            },\n            'params': {\n                # Live stream\n                'skip_download': True,\n            },\n        },\n        # Livestream embed\n        {\n            'url': 'http://www.esa.int/Our_Activities/Space_Science/Rosetta/Philae_comet_touch-down_webcast',\n            'info_dict': {\n                'id': '67864563',\n                'ext': 'flv',\n                'upload_date': '20141112',\n                'title': 'Rosetta #CometLanding webcast HL 10',\n            }\n        },\n        # Another Livestream embed, without 'new.' in URL\n        {\n            'url': 'https://www.freespeech.org/',\n            'info_dict': {\n                'id': '123537347',\n                'ext': 'mp4',\n                'title': 're:^FSTV [0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}$',\n            },\n            'params': {\n                # Live stream\n                'skip_download': True,\n            },\n        },\n        # LazyYT\n        {\n            'url': 'https://skiplagged.com/',\n            'info_dict': {\n                'id': 'skiplagged',\n                'title': 'Skiplagged: The smart way to find cheap flights',\n            },\n            'playlist_mincount': 1,\n            'add_ie': ['Youtube'],\n        },\n        # Cinchcast embed\n        {\n            'url': 'http://undergroundwellness.com/podcasts/306-5-steps-to-permanent-gut-healing/',\n            'info_dict': {\n                'id': '7141703',\n                'ext': 'mp3',\n                'upload_date': '20141126',\n                'title': 'Jack Tips: 5 Steps to Permanent Gut Healing',\n            }\n        },\n        # Cinerama player\n        {\n            'url': 'http://www.abc.net.au/7.30/content/2015/s4164797.htm',\n            'info_dict': {\n                'id': '730m_DandD_1901_512k',\n                'ext': 'mp4',\n                'uploader': 'www.abc.net.au',\n                'title': 'Game of Thrones with dice - Dungeons and Dragons fantasy role-playing game gets new life - 19/01/2015',\n            }\n        },\n        # embedded viddler video\n        {\n            'url': 'http://deadspin.com/i-cant-stop-watching-john-wall-chop-the-nuggets-with-th-1681801597',\n            'info_dict': {\n                'id': '4d03aad9',\n                'ext': 'mp4',\n                'uploader': 'deadspin',\n                'title': 'WALL-TO-GORTAT',\n                'timestamp': 1422285291,\n                'upload_date': '20150126',\n            },\n            'add_ie': ['Viddler'],\n        },\n        # Libsyn embed\n        {\n            'url': 'http://thedailyshow.cc.com/podcast/episodetwelve',\n            'info_dict': {\n                'id': '3377616',\n                'ext': 'mp3',\n                'title': \"The Daily Show Podcast without Jon Stewart - Episode 12: Bassem Youssef: Egypt's Jon Stewart\",\n                'description': 'md5:601cb790edd05908957dae8aaa866465',\n                'upload_date': '20150220',\n            },\n            'skip': 'All The Daily Show URLs now redirect to http://www.cc.com/shows/',\n        },\n        # jwplayer YouTube\n        {\n            'url': 'http://media.nationalarchives.gov.uk/index.php/webinar-using-discovery-national-archives-online-catalogue/',\n            'info_dict': {\n                'id': 'Mrj4DVp2zeA',\n                'ext': 'mp4',\n                'upload_date': '20150212',\n                'uploader': 'The National Archives UK',\n                'description': 'md5:8078af856dca76edc42910b61273dbbf',\n                'uploader_id': 'NationalArchives08',\n                'title': 'Webinar: Using Discovery, The National Archives\u2019 online catalogue',\n            },\n        },\n        # jwplayer rtmp\n        {\n            'url': 'http://www.suffolk.edu/sjc/live.php',\n            'info_dict': {\n                'id': 'live',\n                'ext': 'flv',\n                'title': 'Massachusetts Supreme Judicial Court Oral Arguments',\n                'uploader': 'www.suffolk.edu',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'Only has video a few mornings per month, see http://www.suffolk.edu/sjc/',\n        },\n        # jwplayer with only the json URL\n        {\n            'url': 'https://www.hollywoodreporter.com/news/general-news/dunkirk-team-reveals-what-christopher-nolan-said-oscar-win-meet-your-oscar-winner-1092454',\n            'info_dict': {\n                'id': 'TljWkvWH',\n                'ext': 'mp4',\n                'upload_date': '20180306',\n                'title': 'md5:91eb1862f6526415214f62c00b453936',\n                'description': 'md5:73048ae50ae953da10549d1d2fe9b3aa',\n                'timestamp': 1520367225,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # Complex jwplayer\n        {\n            'url': 'http://www.indiedb.com/games/king-machine/videos',\n            'info_dict': {\n                'id': 'videos',\n                'ext': 'mp4',\n                'title': 'king machine trailer 1',\n                'description': 'Browse King Machine videos & audio for sweet media. Your eyes will thank you.',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n            },\n        },\n        {\n            # Youtube embed, formerly: Video.js embed, multiple formats\n            'url': 'http://ortcam.com/solidworks-\u0443\u0440\u043e\u043a-6-\u043d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430-\u0447\u0435\u0440\u0442\u0435\u0436\u0430_33f9b7351.html',\n            'info_dict': {\n                'id': 'yygqldloqIk',\n                'ext': 'mp4',\n                'title': 'SolidWorks. \u0423\u0440\u043e\u043a 6 \u041d\u0430\u0441\u0442\u0440\u043e\u0439\u043a\u0430 \u0447\u0435\u0440\u0442\u0435\u0436\u0430',\n                'description': 'md5:baf95267792646afdbf030e4d06b2ab3',\n                'upload_date': '20130314',\n                'uploader': 'PRO\u0441\u0442\u043e\u04353D',\n                'uploader_id': 'PROstoe3D',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # Video.js embed, single format\n            'url': 'https://www.vooplayer.com/v3/watch/watch.php?v=NzgwNTg=',\n            'info_dict': {\n                'id': 'watch',\n                'ext': 'mp4',\n                'title': 'Step 1 -  Good Foundation',\n                'description': 'md5:d1e7ff33a29fc3eb1673d6c270d344f4',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': '404 Not Found',\n        },\n        # rtl.nl embed\n        {\n            'url': 'http://www.rtlnieuws.nl/nieuws/buitenland/aanslagen-kopenhagen',\n            'playlist_mincount': 5,\n            'info_dict': {\n                'id': 'aanslagen-kopenhagen',\n                'title': 'Aanslagen Kopenhagen',\n            }\n        },\n        # Zapiks embed\n        {\n            'url': 'http://www.skipass.com/news/116090-bon-appetit-s5ep3-baqueira-mi-cor.html',\n            'info_dict': {\n                'id': '118046',\n                'ext': 'mp4',\n                'title': 'EP3S5 - Bon App\u00e9tit - Baqueira Mi Corazon !',\n            }\n        },\n        # Kaltura embed (different embed code)\n        {\n            'url': 'http://www.premierchristianradio.com/Shows/Saturday/Unbelievable/Conference-Videos/Os-Guinness-Is-It-Fools-Talk-Unbelievable-Conference-2014',\n            'info_dict': {\n                'id': '1_a52wc67y',\n                'ext': 'flv',\n                'upload_date': '20150127',\n                'uploader_id': 'PremierMedia',\n                'timestamp': int,\n                'title': 'Os Guinness // Is It Fools Talk? // Unbelievable? Conference 2014',\n            },\n        },\n        # Kaltura embed with single quotes\n        {\n            'url': 'http://fod.infobase.com/p_ViewPlaylist.aspx?AssignmentID=NUN8ZY',\n            'info_dict': {\n                'id': '0_izeg5utt',\n                'ext': 'mp4',\n                'title': '35871',\n                'timestamp': 1355743100,\n                'upload_date': '20121217',\n                'uploader_id': 'cplapp@learn360.com',\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # Kaltura embedded via quoted entry_id\n            'url': 'https://www.oreilly.com/ideas/my-cloud-makes-pretty-pictures',\n            'info_dict': {\n                'id': '0_utuok90b',\n                'ext': 'mp4',\n                'title': '06_matthew_brender_raj_dutt',\n                'timestamp': 1466638791,\n                'upload_date': '20160622',\n            },\n            'add_ie': ['Kaltura'],\n            'expected_warnings': [\n                'Could not send HEAD request'\n            ],\n            'params': {\n                'skip_download': True,\n            }\n        },\n        {\n            # Kaltura embedded, some fileExt broken (#11480)\n            'url': 'http://www.cornell.edu/video/nima-arkani-hamed-standard-models-of-particle-physics',\n            'info_dict': {\n                'id': '1_sgtvehim',\n                'ext': 'mp4',\n                'title': 'Our \"Standard Models\" of particle physics and cosmology',\n                'description': 'md5:67ea74807b8c4fea92a6f38d6d323861',\n                'timestamp': 1321158993,\n                'upload_date': '20111113',\n                'uploader_id': 'kps1',\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # Kaltura iframe embed\n            'url': 'http://www.gsd.harvard.edu/event/i-m-pei-a-centennial-celebration/',\n            'md5': 'ae5ace8eb09dc1a35d03b579a9c2cc44',\n            'info_dict': {\n                'id': '0_f2cfbpwy',\n                'ext': 'mp4',\n                'title': 'I. M. Pei: A Centennial Celebration',\n                'description': 'md5:1db8f40c69edc46ca180ba30c567f37c',\n                'upload_date': '20170403',\n                'uploader_id': 'batchUser',\n                'timestamp': 1491232186,\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # Kaltura iframe embed, more sophisticated\n            'url': 'http://www.cns.nyu.edu/~eero/math-tools/Videos/lecture-05sep2017.html',\n            'info_dict': {\n                'id': '1_9gzouybz',\n                'ext': 'mp4',\n                'title': 'lecture-05sep2017',\n                'description': 'md5:40f347d91fd4ba047e511c5321064b49',\n                'upload_date': '20170913',\n                'uploader_id': 'eps2',\n                'timestamp': 1505340777,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # meta twitter:player\n            'url': 'http://thechive.com/2017/12/08/all-i-want-for-christmas-is-more-twerk/',\n            'info_dict': {\n                'id': '0_01b42zps',\n                'ext': 'mp4',\n                'title': 'Main Twerk (Video)',\n                'upload_date': '20171208',\n                'uploader_id': 'sebastian.salinas@thechive.com',\n                'timestamp': 1512713057,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Kaltura'],\n        },\n        # referrer protected EaglePlatform embed\n        {\n            'url': 'https://tvrain.ru/lite/teleshow/kak_vse_nachinalos/namin-418921/',\n            'info_dict': {\n                'id': '582306',\n                'ext': 'mp4',\n                'title': '\u0421\u0442\u0430\u0441 \u041d\u0430\u043c\u0438\u043d: \u00ab\u041c\u044b \u043d\u0430\u0440\u0443\u0448\u0438\u043b\u0438 \u0434\u0435\u0432\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u041a\u0440\u0435\u043c\u043b\u044f\u00bb',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 3382,\n                'view_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # ClipYou (EaglePlatform) embed (custom URL)\n        {\n            'url': 'http://muz-tv.ru/play/7129/',\n            # Not checking MD5 as sometimes the direct HTTP link results in 404 and HLS is used\n            'info_dict': {\n                'id': '12820',\n                'ext': 'mp4',\n                'title': \"'O Sole Mio\",\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 216,\n                'view_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'This video is unavailable.',\n        },\n        # Pladform embed\n        {\n            'url': 'http://muz-tv.ru/kinozal/view/7400/',\n            'info_dict': {\n                'id': '100183293',\n                'ext': 'mp4',\n                'title': '\u0422\u0430\u0439\u043d\u044b \u043f\u0435\u0440\u0435\u0432\u0430\u043b\u0430 \u0414\u044f\u0442\u043b\u043e\u0432\u0430 \u2022 1 \u0441\u0435\u0440\u0438\u044f 2 \u0447\u0430\u0441\u0442\u044c',\n                'description': '\u0414\u043e\u043a\u0443\u043c\u0435\u043d\u0442\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0435\u0440\u0438\u0430\u043b-\u0440\u0430\u0441\u0441\u043b\u0435\u0434\u043e\u0432\u0430\u043d\u0438\u0435 \u043e\u0434\u043d\u043e\u0439 \u0438\u0437 \u0441\u0430\u043c\u044b\u0445 \u0436\u0443\u0442\u043a\u0438\u0445 \u0442\u0430\u0439\u043d \u0425\u0425 \u0432\u0435\u043a\u0430',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 694,\n                'age_limit': 0,\n            },\n            'skip': 'HTTP Error 404: Not Found',\n        },\n        # Playwire embed\n        {\n            'url': 'http://www.cinemablend.com/new/First-Joe-Dirt-2-Trailer-Teaser-Stupid-Greatness-70874.html',\n            'info_dict': {\n                'id': '3519514',\n                'ext': 'mp4',\n                'title': 'Joe Dirt 2 Beautiful Loser Teaser Trailer',\n                'thumbnail': r're:^https?://.*\\.png$',\n                'duration': 45.115,\n            },\n        },\n        # Crooks and Liars embed\n        {\n            'url': 'http://crooksandliars.com/2015/04/fox-friends-says-protecting-atheists',\n            'info_dict': {\n                'id': '8RUoRhRi',\n                'ext': 'mp4',\n                'title': \"Fox & Friends Says Protecting Atheists From Discrimination Is Anti-Christian!\",\n                'description': 'md5:e1a46ad1650e3a5ec7196d432799127f',\n                'timestamp': 1428207000,\n                'upload_date': '20150405',\n                'uploader': 'Heather',\n            },\n        },\n        # Crooks and Liars external embed\n        {\n            'url': 'http://theothermccain.com/2010/02/02/video-proves-that-bill-kristol-has-been-watching-glenn-beck/comment-page-1/',\n            'info_dict': {\n                'id': 'MTE3MjUtMzQ2MzA',\n                'ext': 'mp4',\n                'title': 'md5:5e3662a81a4014d24c250d76d41a08d5',\n                'description': 'md5:9b8e9542d6c3c5de42d6451b7d780cec',\n                'timestamp': 1265032391,\n                'upload_date': '20100201',\n                'uploader': 'Heather',\n            },\n        },\n        # NBC Sports vplayer embed\n        {\n            'url': 'http://www.riderfans.com/forum/showthread.php?121827-Freeman&s=e98fa1ea6dc08e886b1678d35212494a',\n            'info_dict': {\n                'id': 'ln7x1qSThw4k',\n                'ext': 'flv',\n                'title': \"PFT Live: New leader in the 'new-look' defense\",\n                'description': 'md5:65a19b4bbfb3b0c0c5768bed1dfad74e',\n                'uploader': 'NBCU-SPORTS',\n                'upload_date': '20140107',\n                'timestamp': 1389118457,\n            },\n            'skip': 'Invalid Page URL',\n        },\n        # NBC News embed\n        {\n            'url': 'http://www.vulture.com/2016/06/letterman-couldnt-care-less-about-late-night.html',\n            'md5': '1aa589c675898ae6d37a17913cf68d66',\n            'info_dict': {\n                'id': 'x_dtl_oa_LettermanliftPR_160608',\n                'ext': 'mp4',\n                'title': 'David Letterman: A Preview',\n                'description': 'A preview of Tom Brokaw\\'s interview with David Letterman as part of the On Assignment series powered by Dateline. Airs Sunday June 12 at 7/6c.',\n                'upload_date': '20160609',\n                'timestamp': 1465431544,\n                'uploader': 'NBCU-NEWS',\n            },\n        },\n        # UDN embed\n        {\n            'url': 'https://video.udn.com/news/300346',\n            'md5': 'fd2060e988c326991037b9aff9df21a6',\n            'info_dict': {\n                'id': '300346',\n                'ext': 'mp4',\n                'title': '\u4e2d\u4e00\u4e2d\u7537\u5e2b\u8b8a\u6027 \u5168\u6821\u5e2b\u751f\u529b\u633a',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n            },\n            'params': {\n                # m3u8 download\n                'skip_download': True,\n            },\n            'expected_warnings': ['Failed to parse JSON Expecting value'],\n        },\n        # Kinja embed\n        {\n            'url': 'http://www.clickhole.com/video/dont-understand-bitcoin-man-will-mumble-explanatio-2537',\n            'info_dict': {\n                'id': '106351',\n                'ext': 'mp4',\n                'title': 'Don\u2019t Understand Bitcoin? This Man Will Mumble An Explanation At You',\n                'description': 'Migrated from OnionStudios',\n                'thumbnail': r're:^https?://.*\\.jpe?g$',\n                'uploader': 'clickhole',\n                'upload_date': '20150527',\n                'timestamp': 1432744860,\n            }\n        },\n        # SnagFilms embed\n        {\n            'url': 'http://whilewewatch.blogspot.ru/2012/06/whilewewatch-whilewewatch-gripping.html',\n            'info_dict': {\n                'id': '74849a00-85a9-11e1-9660-123139220831',\n                'ext': 'mp4',\n                'title': '#whilewewatch',\n            }\n        },\n        # AdobeTVVideo embed\n        {\n            'url': 'https://helpx.adobe.com/acrobat/how-to/new-experience-acrobat-dc.html?set=acrobat--get-started--essential-beginners',\n            'md5': '43662b577c018ad707a63766462b1e87',\n            'info_dict': {\n                'id': '2456',\n                'ext': 'mp4',\n                'title': 'New experience with Acrobat DC',\n                'description': 'New experience with Acrobat DC',\n                'duration': 248.667,\n            },\n        },\n        # Another form of arte.tv embed\n        {\n            'url': 'http://www.tv-replay.fr/redirection/09-04-16/arte-reportage-arte-11508975.html',\n            'md5': '850bfe45417ddf221288c88a0cffe2e2',\n            'info_dict': {\n                'id': '030273-562_PLUS7-F',\n                'ext': 'mp4',\n                'title': 'ARTE Reportage - Nulle part, en France',\n                'description': 'md5:e3a0e8868ed7303ed509b9e3af2b870d',\n                'upload_date': '20160409',\n            },\n        },\n        # Duplicated embedded video URLs\n        {\n            'url': 'http://www.hudl.com/athlete/2538180/highlights/149298443',\n            'info_dict': {\n                'id': '149298443_480_16c25b74_2',\n                'ext': 'mp4',\n                'title': 'vs. Blue Orange Spring Game',\n                'uploader': 'www.hudl.com',\n            },\n        },\n        # twitter:player:stream embed\n        {\n            'url': 'http://www.rtl.be/info/video/589263.aspx?CategoryID=288',\n            'info_dict': {\n                'id': 'master',\n                'ext': 'mp4',\n                'title': 'Une nouvelle esp\u00e8ce de dinosaure d\u00e9couverte en Argentine',\n                'uploader': 'www.rtl.be',\n            },\n            'params': {\n                # m3u8 downloads\n                'skip_download': True,\n            },\n        },\n        # twitter:player embed\n        {\n            'url': 'http://www.theatlantic.com/video/index/484130/what-do-black-holes-sound-like/',\n            'md5': 'a3e0df96369831de324f0778e126653c',\n            'info_dict': {\n                'id': '4909620399001',\n                'ext': 'mp4',\n                'title': 'What Do Black Holes Sound Like?',\n                'description': 'what do black holes sound like',\n                'upload_date': '20160524',\n                'uploader_id': '29913724001',\n                'timestamp': 1464107587,\n                'uploader': 'TheAtlantic',\n            },\n            'skip': 'Private Youtube video',\n        },\n        # Facebook <iframe> embed\n        {\n            'url': 'https://www.hostblogger.de/blog/archives/6181-Auto-jagt-Betonmischer.html',\n            'md5': 'fbcde74f534176ecb015849146dd3aee',\n            'info_dict': {\n                'id': '599637780109885',\n                'ext': 'mp4',\n                'title': 'Facebook video #599637780109885',\n            },\n        },\n        # Facebook <iframe> embed, plugin video\n        {\n            'url': 'http://5pillarsuk.com/2017/06/07/tariq-ramadan-disagrees-with-pr-exercise-by-imams-refusing-funeral-prayers-for-london-attackers/',\n            'info_dict': {\n                'id': '1754168231264132',\n                'ext': 'mp4',\n                'title': 'About the Imams and Religious leaders refusing to perform funeral prayers for...',\n                'uploader': 'Tariq Ramadan (official)',\n                'timestamp': 1496758379,\n                'upload_date': '20170606',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        # Facebook API embed\n        {\n            'url': 'http://www.lothype.com/blue-stars-2016-preview-standstill-full-show/',\n            'md5': 'a47372ee61b39a7b90287094d447d94e',\n            'info_dict': {\n                'id': '10153467542406923',\n                'ext': 'mp4',\n                'title': 'Facebook video #10153467542406923',\n            },\n        },\n        # Wordpress \"YouTube Video Importer\" plugin\n        {\n            'url': 'http://www.lothype.com/blue-devils-drumline-stanford-lot-2016/',\n            'md5': 'd16797741b560b485194eddda8121b48',\n            'info_dict': {\n                'id': 'HNTXWDXV9Is',\n                'ext': 'mp4',\n                'title': 'Blue Devils Drumline Stanford lot 2016',\n                'upload_date': '20160627',\n                'uploader_id': 'GENOCIDE8GENERAL10',\n                'uploader': 'cylus cyrus',\n            },\n        },\n        {\n            # video stored on custom kaltura server\n            'url': 'http://www.expansion.com/multimedia/videos.html?media=EQcM30NHIPv',\n            'md5': '537617d06e64dfed891fa1593c4b30cc',\n            'info_dict': {\n                'id': '0_1iotm5bh',\n                'ext': 'mp4',\n                'title': 'Elecciones brit\u00e1nicas: 5 lecciones para Rajoy',\n                'description': 'md5:435a89d68b9760b92ce67ed227055f16',\n                'uploader_id': 'videos.expansion@el-mundo.net',\n                'upload_date': '20150429',\n                'timestamp': 1430303472,\n            },\n            'add_ie': ['Kaltura'],\n        },\n        {\n            # multiple kaltura embeds, nsfw\n            'url': 'https://www.quartier-rouge.be/prive/femmes/kamila-avec-video-jaime-sadomie.html',\n            'info_dict': {\n                'id': 'kamila-avec-video-jaime-sadomie',\n                'title': \"Kamila avec v\u00eddeo \u201cJ'aime sadomie\u201d\",\n            },\n            'playlist_count': 8,\n        },\n        {\n            # Non-standard Vimeo embed\n            'url': 'https://openclassrooms.com/courses/understanding-the-web',\n            'md5': '64d86f1c7d369afd9a78b38cbb88d80a',\n            'info_dict': {\n                'id': '148867247',\n                'ext': 'mp4',\n                'title': 'Understanding the web - Teaser',\n                'description': 'This is \"Understanding the web - Teaser\" by openclassrooms on Vimeo, the home for high quality videos and the people who love them.',\n                'upload_date': '20151214',\n                'uploader': 'OpenClassrooms',\n                'uploader_id': 'openclassrooms',\n            },\n            'add_ie': ['Vimeo'],\n        },\n        {\n            # generic vimeo embed that requires original URL passed as Referer\n            'url': 'http://racing4everyone.eu/2016/07/30/formula-1-2016-round12-germany/',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://support.arkena.com/display/PLAY/Ways+to+embed+your+video',\n            'md5': 'b96f2f71b359a8ecd05ce4e1daa72365',\n            'info_dict': {\n                'id': 'b41dda37-d8e7-4d3f-b1b5-9a9db578bdfe',\n                'ext': 'mp4',\n                'title': 'Big Buck Bunny',\n                'description': 'Royalty free test video',\n                'timestamp': 1432816365,\n                'upload_date': '20150528',\n                'is_live': False,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Arkena'],\n        },\n        {\n            'url': 'http://nova.bg/news/view/2016/08/16/156543/%D0%BD%D0%B0-%D0%BA%D0%BE%D1%81%D1%8A%D0%BC-%D0%BE%D1%82-%D0%B2%D0%B7%D1%80%D0%B8%D0%B2-%D0%BE%D1%82%D1%86%D0%B5%D0%BF%D0%B8%D1%85%D0%B0-%D1%86%D1%8F%D0%BB-%D0%BA%D0%B2%D0%B0%D1%80%D1%82%D0%B0%D0%BB-%D0%B7%D0%B0%D1%80%D0%B0%D0%B4%D0%B8-%D0%B8%D0%B7%D1%82%D0%B8%D1%87%D0%B0%D0%BD%D0%B5-%D0%BD%D0%B0-%D0%B3%D0%B0%D0%B7-%D0%B2-%D0%BF%D0%BB%D0%BE%D0%B2%D0%B4%D0%B8%D0%B2/',\n            'info_dict': {\n                'id': '1c7141f46c',\n                'ext': 'mp4',\n                'title': '\u041d\u0410 \u041a\u041e\u0421\u042a\u041c \u041e\u0422 \u0412\u0417\u0420\u0418\u0412: \u0418\u0437\u0442\u0438\u0447\u0430\u043d\u0435 \u043d\u0430 \u0433\u0430\u0437 \u043d\u0430 \u0431\u0435\u043d\u0437\u0438\u043d\u043e\u0441\u0442\u0430\u043d\u0446\u0438\u044f \u0432 \u041f\u043b\u043e\u0432\u0434\u0438\u0432',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Vbox7'],\n        },\n        {\n            # DBTV embeds\n            'url': 'http://www.dagbladet.no/2016/02/23/nyheter/nordlys/ski/troms/ver/43254897/',\n            'info_dict': {\n                'id': '43254897',\n                'title': 'Etter ett \u00e5rs planlegging, klaffet endelig alt: - Jeg m\u00e5tte ta en liten dans',\n            },\n            'playlist_mincount': 3,\n        },\n        {\n            # Videa embeds\n            'url': 'http://forum.dvdtalk.com/movie-talk/623756-deleted-magic-star-wars-ot-deleted-alt-scenes-docu-style.html',\n            'info_dict': {\n                'id': '623756-deleted-magic-star-wars-ot-deleted-alt-scenes-docu-style',\n                'title': 'Deleted Magic - Star Wars: OT Deleted / Alt. Scenes Docu. Style - DVD Talk Forum',\n            },\n            'playlist_mincount': 2,\n        },\n        {\n            # 20 minuten embed\n            'url': 'http://www.20min.ch/schweiz/news/story/So-kommen-Sie-bei-Eis-und-Schnee-sicher-an-27032552',\n            'info_dict': {\n                'id': '523629',\n                'ext': 'mp4',\n                'title': 'So kommen Sie bei Eis und Schnee sicher an',\n                'description': 'md5:117c212f64b25e3d95747e5276863f7d',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['TwentyMinuten'],\n        },\n        {\n            # VideoPress embed\n            'url': 'https://en.support.wordpress.com/videopress/',\n            'info_dict': {\n                'id': 'OcobLTqC',\n                'ext': 'm4v',\n                'title': 'IMG_5786',\n                'timestamp': 1435711927,\n                'upload_date': '20150701',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['VideoPress'],\n        },\n        {\n            # Rutube embed\n            'url': 'http://magazzino.friday.ru/videos/vipuski/kazan-2',\n            'info_dict': {\n                'id': '9b3d5bee0a8740bf70dfd29d3ea43541',\n                'ext': 'flv',\n                'title': '\u041c\u0430\u0433\u0430\u0437\u0437\u0438\u043d\u043e: \u041a\u0430\u0437\u0430\u043d\u044c 2',\n                'description': 'md5:99bccdfac2269f0e8fdbc4bbc9db184a',\n                'uploader': '\u041c\u0430\u0433\u0430\u0437\u0437\u0438\u043d\u043e',\n                'upload_date': '20170228',\n                'uploader_id': '996642',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['Rutube'],\n        },\n        {\n            # glomex:embed\n            'url': 'https://www.skai.gr/news/world/iatrikos-syllogos-tourkias-to-turkovac-aplo-dialyma-erntogan-eiste-apateones-kai-pseytes',\n            'info_dict': {\n                'id': 'v-ch2nkhcirwc9-sf',\n                'ext': 'mp4',\n                'title': 'md5:786e1e24e06c55993cee965ef853a0c1',\n                'description': 'md5:8b517a61d577efe7e36fde72fd535995',\n                'timestamp': 1641885019,\n                'upload_date': '20220111',\n                'duration': 460000,\n                'thumbnail': 'https://i3thumbs.glomex.com/dC1idjJwdndiMjRzeGwvMjAyMi8wMS8xMS8wNy8xMF8zNV82MWRkMmQ2YmU5ZTgyLmpwZw==/profile:player-960x540',\n            },\n        },\n        {\n            # megatvcom:embed\n            'url': 'https://www.in.gr/2021/12/18/greece/apokalypsi-mega-poios-parelave-tin-ereyna-tsiodra-ek-merous-tis-kyvernisis-o-prothypourgos-telika-gnorize/',\n            'info_dict': {\n                'id': 'apokalypsi-mega-poios-parelave-tin-ereyna-tsiodra-ek-merous-tis-kyvernisis-o-prothypourgos-telika-gnorize',\n                'title': 'md5:5e569cf996ec111057c2764ec272848f',\n            },\n            'playlist': [{\n                'md5': '1afa26064ff00ccb91617957dbc73dc1',\n                'info_dict': {\n                    'ext': 'mp4',\n                    'id': '564916',\n                    'display_id': 'md5:6cdf22d3a2e7bacb274b7295089a1770',\n                    'title': 'md5:33b9dd39584685b62873043670eb52a6',\n                    'description': 'md5:c1db7310f390518ac36dd69d947ef1a1',\n                    'timestamp': 1639753145,\n                    'upload_date': '20211217',\n                    'thumbnail': 'https://www.megatv.com/wp-content/uploads/2021/12/prezerakos-1024x597.jpg',\n                },\n            }, {\n                'md5': '4a1c220695f1ef865a8b7966a53e2474',\n                'info_dict': {\n                    'ext': 'mp4',\n                    'id': '564905',\n                    'display_id': 'md5:ead15695e485e649aed2b81ebd699b88',\n                    'title': 'md5:2b71fd54249a3ca34609fe39ae31c47b',\n                    'description': 'md5:c42e12f638d0a97d6de4508e2c4df982',\n                    'timestamp': 1639753047,\n                    'upload_date': '20211217',\n                    'thumbnail': 'https://www.megatv.com/wp-content/uploads/2021/12/tsiodras-mitsotakis-1024x545.jpg',\n                },\n            }]\n        },\n        {\n            'url': 'https://www.ertnews.gr/video/manolis-goyalles-o-anthropos-piso-apo-ti-diadiktyaki-vasilopita/',\n            'info_dict': {\n                'id': '2022/tv/news-themata-ianouarios/20220114-apotis6-gouales-pita.mp4',\n                'ext': 'mp4',\n                'title': 'md5:df64f5b61c06d0e9556c0cdd5cf14464',\n                'thumbnail': 'https://www.ert.gr/themata/photos/2021/20220114-apotis6-gouales-pita.jpg',\n            },\n        },\n        {\n            # ThePlatform embedded with whitespaces in URLs\n            'url': 'http://www.golfchannel.com/topics/shows/golftalkcentral.htm',\n            'only_matching': True,\n        },\n        {\n            # Senate ISVP iframe https\n            'url': 'https://www.hsgac.senate.gov/hearings/canadas-fast-track-refugee-plan-unanswered-questions-and-implications-for-us-national-security',\n            'md5': 'fb8c70b0b515e5037981a2492099aab8',\n            'info_dict': {\n                'id': 'govtaff020316',\n                'ext': 'mp4',\n                'title': 'Integrated Senate Video Player',\n            },\n            'add_ie': ['SenateISVP'],\n        },\n        {\n            # Limelight embeds (1 channel embed + 4 media embeds)\n            'url': 'http://www.sedona.com/FacilitatorTraining2017',\n            'info_dict': {\n                'id': 'FacilitatorTraining2017',\n                'title': 'Facilitator Training 2017',\n            },\n            'playlist_mincount': 5,\n        },\n        {\n            # Limelight embed (LimelightPlayerUtil.embed)\n            'url': 'https://tv5.ca/videos?v=xuu8qowr291ri',\n            'info_dict': {\n                'id': '95d035dc5c8a401588e9c0e6bd1e9c92',\n                'ext': 'mp4',\n                'title': '07448641',\n                'timestamp': 1499890639,\n                'upload_date': '20170712',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['LimelightMedia'],\n        },\n        {\n            'url': 'http://kron4.com/2017/04/28/standoff-with-walnut-creek-murder-suspect-ends-with-arrest/',\n            'info_dict': {\n                'id': 'standoff-with-walnut-creek-murder-suspect-ends-with-arrest',\n                'title': 'Standoff with Walnut Creek murder suspect ends',\n                'description': 'md5:3ccc48a60fc9441eeccfc9c469ebf788',\n            },\n            'playlist_mincount': 4,\n        },\n        {\n            # WashingtonPost embed\n            'url': 'http://www.vanityfair.com/hollywood/2017/04/donald-trump-tv-pitches',\n            'info_dict': {\n                'id': '8caf6e88-d0ec-11e5-90d3-34c2c42653ac',\n                'ext': 'mp4',\n                'title': \"No one has seen the drama series based on Trump's life \\u2014 until now\",\n                'description': 'Donald Trump wanted a weekly TV drama based on his life. It never aired. But The Washington Post recently obtained a scene from the pilot script \u2014 and enlisted actors.',\n                'timestamp': 1455216756,\n                'uploader': 'The Washington Post',\n                'upload_date': '20160211',\n            },\n            'add_ie': ['WashingtonPost'],\n        },\n        {\n            # JOJ.sk embeds\n            'url': 'https://www.noviny.sk/slovensko/238543-slovenskom-sa-prehnala-vlna-silnych-burok',\n            'info_dict': {\n                'id': '238543-slovenskom-sa-prehnala-vlna-silnych-burok',\n                'title': 'Slovenskom sa prehnala vlna siln\u00fdch b\u00farok',\n            },\n            'playlist_mincount': 5,\n            'add_ie': ['Joj'],\n        },\n        {\n            # AMP embed (see https://www.ampproject.org/docs/reference/components/amp-video)\n            'url': 'https://tvrain.ru/amp/418921/',\n            'md5': 'cc00413936695987e8de148b67d14f1d',\n            'info_dict': {\n                'id': '418921',\n                'ext': 'mp4',\n                'title': '\u0421\u0442\u0430\u0441 \u041d\u0430\u043c\u0438\u043d: \u00ab\u041c\u044b \u043d\u0430\u0440\u0443\u0448\u0438\u043b\u0438 \u0434\u0435\u0432\u0441\u0442\u0432\u0435\u043d\u043d\u043e\u0441\u0442\u044c \u041a\u0440\u0435\u043c\u043b\u044f\u00bb',\n            },\n        },\n        {\n            # vzaar embed\n            'url': 'http://help.vzaar.com/article/165-embedding-video',\n            'md5': '7e3919d9d2620b89e3e00bec7fe8c9d4',\n            'info_dict': {\n                'id': '8707641',\n                'ext': 'mp4',\n                'title': 'Building A Business Online: Principal Chairs Q & A',\n            },\n        },\n        {\n            # multiple HTML5 videos on one page\n            'url': 'https://www.paragon-software.com/home/rk-free/keyscenarios.html',\n            'info_dict': {\n                'id': 'keyscenarios',\n                'title': 'Rescue Kit 14 Free Edition - Getting started',\n            },\n            'playlist_count': 4,\n        },\n        {\n            # vshare embed\n            'url': 'https://youtube-dl-demo.neocities.org/vshare.html',\n            'md5': '17b39f55b5497ae8b59f5fbce8e35886',\n            'info_dict': {\n                'id': '0f64ce6',\n                'title': 'vl14062007715967',\n                'ext': 'mp4',\n            }\n        },\n        {\n            'url': 'http://www.heidelberg-laureate-forum.org/blog/video/lecture-friday-september-23-2016-sir-c-antony-r-hoare/',\n            'md5': 'aecd089f55b1cb5a59032cb049d3a356',\n            'info_dict': {\n                'id': '90227f51a80c4d8f86c345a7fa62bd9a1d',\n                'ext': 'mp4',\n                'title': 'Lecture: Friday, September 23, 2016 - Sir Tony Hoare',\n                'description': 'md5:5a51db84a62def7b7054df2ade403c6c',\n                'timestamp': 1474354800,\n                'upload_date': '20160920',\n            }\n        },\n        {\n            'url': 'http://www.kidzworld.com/article/30935-trolls-the-beat-goes-on-interview-skylar-astin-and-amanda-leighton',\n            'info_dict': {\n                'id': '1731611',\n                'ext': 'mp4',\n                'title': 'Official Trailer | TROLLS: THE BEAT GOES ON!',\n                'description': 'md5:eb5f23826a027ba95277d105f248b825',\n                'timestamp': 1516100691,\n                'upload_date': '20180116',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'add_ie': ['SpringboardPlatform'],\n        },\n        {\n            'url': 'https://www.yapfiles.ru/show/1872528/690b05d3054d2dbe1e69523aa21bb3b1.mp4.html',\n            'info_dict': {\n                'id': 'vMDE4NzI1Mjgt690b',\n                'ext': 'mp4',\n                'title': '\u041a\u043e\u0442\u044f\u0442\u0430',\n            },\n            'add_ie': ['YapFiles'],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # CloudflareStream embed\n            'url': 'https://www.cloudflare.com/products/cloudflare-stream/',\n            'info_dict': {\n                'id': '31c9291ab41fac05471db4e73aa11717',\n                'ext': 'mp4',\n                'title': '31c9291ab41fac05471db4e73aa11717',\n            },\n            'add_ie': ['CloudflareStream'],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # PeerTube embed\n            'url': 'https://joinpeertube.org/fr/home/',\n            'info_dict': {\n                'id': 'home',\n                'title': 'Reprenez le contr\u00f4le de vos vid\u00e9os ! #JoinPeertube',\n            },\n            'playlist_count': 2,\n        },\n        {\n            # Indavideo embed\n            'url': 'https://streetkitchen.hu/receptek/igy_kell_otthon_hamburgert_sutni/',\n            'info_dict': {\n                'id': '1693903',\n                'ext': 'mp4',\n                'title': '\u00cdgy kell otthon hamburgert s\u00fctni',\n                'description': 'md5:f5a730ecf900a5c852e1e00540bbb0f7',\n                'timestamp': 1426330212,\n                'upload_date': '20150314',\n                'uploader': 'StreetKitchen',\n                'uploader_id': '546363',\n            },\n            'add_ie': ['IndavideoEmbed'],\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # APA embed via JWPlatform embed\n            'url': 'http://www.vol.at/blue-man-group/5593454',\n            'info_dict': {\n                'id': 'jjv85FdZ',\n                'ext': 'mp4',\n                'title': '\"Blau ist mysteri\u00f6s\": Die Blue Man Group im Interview',\n                'description': 'md5:d41d8cd98f00b204e9800998ecf8427e',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n                'duration': 254,\n                'timestamp': 1519211149,\n                'upload_date': '20180221',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            'url': 'http://share-videos.se/auto/video/83645793?uid=13',\n            'md5': 'b68d276de422ab07ee1d49388103f457',\n            'info_dict': {\n                'id': '83645793',\n                'title': 'Lock up and get excited',\n                'ext': 'mp4'\n            },\n            'skip': 'TODO: fix nested playlists processing in tests',\n        },\n        {\n            # Viqeo embeds\n            'url': 'https://viqeo.tv/',\n            'info_dict': {\n                'id': 'viqeo',\n                'title': 'All-new video platform',\n            },\n            'playlist_count': 6,\n        },\n        # {\n        #     # Zype embed\n        #     'url': 'https://www.cookscountry.com/episode/554-smoky-barbecue-favorites',\n        #     'info_dict': {\n        #         'id': '5b400b834b32992a310622b9',\n        #         'ext': 'mp4',\n        #         'title': 'Smoky Barbecue Favorites',\n        #         'thumbnail': r're:^https?://.*\\.jpe?g',\n        #         'description': 'md5:5ff01e76316bd8d46508af26dc86023b',\n        #         'upload_date': '20170909',\n        #         'timestamp': 1504915200,\n        #     },\n        #     'add_ie': [ZypeIE.ie_key()],\n        #     'params': {\n        #         'skip_download': True,\n        #     },\n        # },\n        {\n            # videojs embed\n            'url': 'https://video.sibnet.ru/shell.php?videoid=3422904',\n            'info_dict': {\n                'id': 'shell',\n                'ext': 'mp4',\n                'title': '\u0414\u043e\u0441\u0442\u0430\u0432\u0449\u0438\u043a \u043f\u0438\u0446\u0446\u044b \u0441\u043f\u0440\u043e\u0441\u0438\u043b \u0440\u0430\u0437\u0440\u0435\u0448\u0435\u043d\u0438\u044f \u0441\u044b\u0433\u0440\u0430\u0442\u044c \u043d\u0430 \u0444\u043e\u0440\u0442\u0435\u043f\u0438\u0430\u043d\u043e',\n                'description': 'md5:89209cdc587dab1e4a090453dbaa2cb1',\n                'thumbnail': r're:^https?://.*\\.jpg$',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'expected_warnings': ['Failed to download MPD manifest'],\n        },\n        {\n            # DailyMotion embed with DM.player\n            'url': 'https://www.beinsports.com/us/copa-del-rey/video/the-locker-room-valencia-beat-barca-in-copa/1203804',\n            'info_dict': {\n                'id': 'k6aKkGHd9FJs4mtJN39',\n                'ext': 'mp4',\n                'title': 'The Locker Room: Valencia Beat Barca In Copa del Rey Final',\n                'description': 'This video is private.',\n                'uploader_id': 'x1jf30l',\n                'uploader': 'beIN SPORTS USA',\n                'upload_date': '20190528',\n                'timestamp': 1559062971,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # tvopengr:embed\n            'url': 'https://www.ethnos.gr/World/article/190604/hparosiaxekinoynoisynomiliessthgeneyhmethskiatoypolemoypanoapothnoykrania',\n            'md5': 'eb0c3995d0a6f18f6538c8e057865d7d',\n            'info_dict': {\n                'id': '101119',\n                'ext': 'mp4',\n                'display_id': 'oikarpoitondiapragmateyseonhparosias',\n                'title': 'md5:b979f4d640c568617d6547035528a149',\n                'description': 'md5:e54fc1977c7159b01cc11cd7d9d85550',\n                'timestamp': 1641772800,\n                'upload_date': '20220110',\n                'thumbnail': 'https://opentv-static.siliconweb.com/imgHandler/1920/70bc39fa-895b-4918-a364-c39d2135fc6d.jpg',\n\n            }\n        },\n        {\n            # blogger embed\n            'url': 'https://blog.tomeuvizoso.net/2019/01/a-panfrost-milestone.html',\n            'md5': 'f1bc19b6ea1b0fd1d81e84ca9ec467ac',\n            'info_dict': {\n                'id': 'BLOGGER-video-3c740e3a49197e16-796',\n                'ext': 'mp4',\n                'title': 'Blogger',\n                'thumbnail': r're:^https?://.*',\n            },\n        },\n        # {\n        #     # TODO: find another test\n        #     # http://schema.org/VideoObject\n        #     'url': 'https://flipagram.com/f/nyvTSJMKId',\n        #     'md5': '888dcf08b7ea671381f00fab74692755',\n        #     'info_dict': {\n        #         'id': 'nyvTSJMKId',\n        #         'ext': 'mp4',\n        #         'title': 'Flipagram by sjuria101 featuring Midnight Memories by One Direction',\n        #         'description': '#love for cats.',\n        #         'timestamp': 1461244995,\n        #         'upload_date': '20160421',\n        #     },\n        #     'params': {\n        #         'force_generic_extractor': True,\n        #     },\n        # },\n        {\n            # VHX Embed\n            'url': 'https://demo.vhx.tv/category-c/videos/file-example-mp4-480-1-5mg-copy',\n            'info_dict': {\n                'id': '858208',\n                'ext': 'mp4',\n                'title': 'Untitled',\n                'uploader_id': 'user80538407',\n                'uploader': 'OTT Videos',\n            },\n        },\n        {\n            # ArcPublishing PoWa video player\n            'url': 'https://www.adn.com/politics/2020/11/02/video-senate-candidates-campaign-in-anchorage-on-eve-of-election-day/',\n            'md5': 'b03b2fac8680e1e5a7cc81a5c27e71b3',\n            'info_dict': {\n                'id': '8c99cb6e-b29c-4bc9-9173-7bf9979225ab',\n                'ext': 'mp4',\n                'title': 'Senate candidates wave to voters on Anchorage streets',\n                'description': 'md5:91f51a6511f090617353dc720318b20e',\n                'timestamp': 1604378735,\n                'upload_date': '20201103',\n                'duration': 1581,\n            },\n        },\n        {\n            # MyChannels SDK embed\n            # https://www.24kitchen.nl/populair/deskundige-dit-waarom-sommigen-gevoelig-zijn-voor-voedselallergieen\n            'url': 'https://www.demorgen.be/nieuws/burgemeester-rotterdam-richt-zich-in-videoboodschap-tot-relschoppers-voelt-het-goed~b0bcfd741/',\n            'md5': '90c0699c37006ef18e198c032d81739c',\n            'info_dict': {\n                'id': '194165',\n                'ext': 'mp4',\n                'title': 'Burgemeester Aboutaleb spreekt relschoppers toe',\n                'timestamp': 1611740340,\n                'upload_date': '20210127',\n                'duration': 159,\n            },\n        },\n        {\n            # Simplecast player embed\n            'url': 'https://www.bio.org/podcast',\n            'info_dict': {\n                'id': 'podcast',\n                'title': 'I AM BIO Podcast | BIO',\n            },\n            'playlist_mincount': 52,\n        }, {\n            # WimTv embed player\n            'url': 'http://www.msmotor.tv/wearefmi-pt-2-2021/',\n            'info_dict': {\n                'id': 'wearefmi-pt-2-2021',\n                'title': '#WEAREFMI \u2013 PT.2 \u2013 2021 \u2013 MsMotorTV',\n            },\n            'playlist_count': 1,\n        }, {\n            # KVS Player\n            'url': 'https://www.kvs-demo.com/videos/105/kelis-4th-of-july/',\n            'info_dict': {\n                'id': '105',\n                'display_id': 'kelis-4th-of-july',\n                'ext': 'mp4',\n                'title': 'Kelis - 4th Of July',\n                'description': 'Kelis - 4th Of July',\n                'thumbnail': r're:https://(?:www\\.)?kvs-demo.com/contents/videos_screenshots/0/105/preview.jpg',\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'expected_warnings': ['Untested major version'],\n        }, {\n            # KVS Player\n            'url': 'https://www.kvs-demo.com/embed/105/',\n            'info_dict': {\n                'id': '105',\n                'display_id': 'kelis-4th-of-july',\n                'ext': 'mp4',\n                'title': 'Kelis - 4th Of July / Embed Player',\n                'thumbnail': r're:https://(?:www\\.)?kvs-demo.com/contents/videos_screenshots/0/105/preview.jpg',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        }, {\n            'url': 'https://youix.com/video/leningrad-zoj/',\n            'md5': '94f96ba95706dc3880812b27b7d8a2b8',\n            'info_dict': {\n                'id': '18485',\n                'display_id': 'leningrad-zoj',\n                'ext': 'mp4',\n                'title': '\u041a\u043b\u0438\u043f: \u041b\u0435\u043d\u0438\u043d\u0433\u0440\u0430\u0434 - \u0417\u041e\u0416 \u0441\u043a\u0430\u0447\u0430\u0442\u044c, \u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u043e\u043d\u043b\u0430\u0439\u043d | Youix.com',\n                'thumbnail': r're:https://youix.com/contents/videos_screenshots/18000/18485/preview(?:_480x320_youix_com.mp4)?\\.jpg',\n            },\n        }, {\n            # KVS Player\n            'url': 'https://youix.com/embed/18485',\n            'md5': '94f96ba95706dc3880812b27b7d8a2b8',\n            'info_dict': {\n                'id': '18485',\n                'display_id': 'leningrad-zoj',\n                'ext': 'mp4',\n                'title': '\u041b\u0435\u043d\u0438\u043d\u0433\u0440\u0430\u0434 - \u0417\u041e\u0416',\n                'thumbnail': r're:https://youix.com/contents/videos_screenshots/18000/18485/preview(?:_480x320_youix_com.mp4)?\\.jpg',\n            },\n        }, {\n            # KVS Player\n            'url': 'https://bogmedia.org/videos/21217/40-nochey-40-nights-2016/',\n            'md5': '94166bdb26b4cb1fb9214319a629fc51',\n            'info_dict': {\n                'id': '21217',\n                'display_id': '40-nochey-2016',\n                'ext': 'mp4',\n                'title': '40 \u043d\u043e\u0447\u0435\u0439 (2016) - BogMedia.org',\n                'description': 'md5:4e6d7d622636eb7948275432eb256dc3',\n                'thumbnail': 'https://bogmedia.org/contents/videos_screenshots/21000/21217/preview_480p.mp4.jpg',\n            },\n        },\n        {\n            # KVS Player (for sites that serve kt_player.js via non-https urls)\n            'url': 'http://www.camhub.world/embed/389508',\n            'md5': 'fbe89af4cfb59c8fd9f34a202bb03e32',\n            'info_dict': {\n                'id': '389508',\n                'display_id': 'syren-de-mer-onlyfans-05-07-2020have-a-happy-safe-holiday5f014e68a220979bdb8cd-source',\n                'ext': 'mp4',\n                'title': 'Syren De Mer onlyfans_05-07-2020Have_a_happy_safe_holiday5f014e68a220979bdb8cd_source / Embed \u043f\u043b\u0435\u0435\u0440',\n                'thumbnail': r're:https?://www\\.camhub\\.world/contents/videos_screenshots/389000/389508/preview\\.mp4\\.jpg',\n            },\n        },\n        {\n            # Reddit-hosted video that will redirect and be processed by RedditIE\n            # Redirects to https://www.reddit.com/r/videos/comments/6rrwyj/that_small_heart_attack/\n            'url': 'https://v.redd.it/zv89llsvexdz',\n            'md5': '87f5f02f6c1582654146f830f21f8662',\n            'info_dict': {\n                'id': 'zv89llsvexdz',\n                'ext': 'mp4',\n                'timestamp': 1501941939.0,\n                'title': 'That small heart attack.',\n                'upload_date': '20170805',\n                'uploader': 'Antw87'\n            }\n        },\n        {\n            # 1080p Reddit-hosted video that will redirect and be processed by RedditIE\n            'url': 'https://v.redd.it/33hgok7dfbz71/',\n            'md5': '7a1d587940242c9bb3bd6eb320b39258',\n            'info_dict': {\n                'id': '33hgok7dfbz71',\n                'ext': 'mp4',\n                'title': \"The game Didn't want me to Knife that Guy I guess\",\n                'uploader': 'paraf1ve',\n                'timestamp': 1636788683.0,\n                'upload_date': '20211113'\n            }\n        },\n        {\n            # MainStreaming player\n            'url': 'https://www.lactv.it/2021/10/03/lac-news24-la-settimana-03-10-2021/',\n            'info_dict': {\n                'id': 'EUlZfGWkGpOd',\n                'title': 'La Settimana ',\n                'description': '03 Ottobre ore 02:00',\n                'ext': 'mp4',\n                'live_status': 'not_live',\n                'thumbnail': r're:https?://[A-Za-z0-9-]*\\.msvdn.net/image/\\w+/poster',\n                'duration': 1512\n            }\n        },\n        {\n            # Multiple gfycat iframe embeds\n            'url': 'https://www.gezip.net/bbs/board.php?bo_table=entertaine&wr_id=613422',\n            'info_dict': {\n                'title': '\uc7ac\uc774, \uc724, \uc138\uc740 \ud669\uae08 \ub4dc\ub808\uc2a4\ub97c \uc785\uace0 \ube5b\ub09c\ub2e4',\n                'id': 'board'\n            },\n            'playlist_count': 8,\n        },\n        {\n            # Multiple gfycat gifs (direct links)\n            'url': 'https://www.gezip.net/bbs/board.php?bo_table=entertaine&wr_id=612199',\n            'info_dict': {\n                'title': '\uc633\uac8c \ub41c \ud06c\ub86d \ub2c8\ud2b8 \uc2a4\ud14c\uc774\uc528 \uc544\uc774\uc0ac',\n                'id': 'board'\n            },\n            'playlist_count': 6\n        },\n        {\n            # Multiple gfycat embeds, with uppercase \"IFR\" in urls\n            'url': 'https://kkzz.kr/?vid=2295',\n            'info_dict': {\n                'title': '\uc9c0\ubc29\uc2dc \uc570\ubc84\uc11c\ub354 \uc5d0\uc2a4\ud30c \uce74\ub9ac\ub098 \uc6c0\uc9e4',\n                'id': '?vid=2295'\n            },\n            'playlist_count': 9\n        },\n        {\n            # Panopto embeds\n            'url': 'https://www.monash.edu/learning-teaching/teachhq/learning-technologies/panopto/how-to/insert-a-quiz-into-a-panopto-video',\n            'info_dict': {\n                'ext': 'mp4',\n                'id': '0bd3f16c-824a-436a-8486-ac5900693aef',\n                'title': 'Quizzes in Panopto',\n            },\n        },\n        {\n            # Ruutu embed\n            'url': 'https://www.nelonen.fi/ohjelmat/madventures-suomi/2160731-riku-ja-tunna-lahtevat-peurajahtiin-tv-sta-tutun-biologin-kanssa---metsastysreissu-huipentuu-kasvissyojan-painajaiseen',\n            'md5': 'a2513a98d3496099e6eced40f7e6a14b',\n            'info_dict': {\n                'id': '4044426',\n                'ext': 'mp4',\n                'title': 'Riku ja Tunna l\u00e4htev\u00e4t peurajahtiin tv:st\u00e4 tutun biologin kanssa \u2013 mets\u00e4stysreissu huipentuu kasvissy\u00f6j\u00e4n painajaiseen!',\n                'thumbnail': r're:^https?://.+\\.jpg$',\n                'duration': 108,\n                'series': 'Madventures Suomi',\n                'description': 'md5:aa55b44bd06a1e337a6f1d0b46507381',\n                'categories': ['Matkailu', 'El\u00e4m\u00e4ntyyli'],\n                'age_limit': 0,\n                'upload_date': '20220308',\n            },\n        },\n        {\n            # Multiple Ruutu embeds\n            'url': 'https://www.hs.fi/kotimaa/art-2000008762560.html',\n            'info_dict': {\n                'title': 'Koronavirus | Epidemiahuippu voi olla Suomessa ohi, mutta koronaviruksen poistamista yleisvaarallisten tautien joukosta harkitaan vasta syksyll\u00e4',\n                'id': 'art-2000008762560'\n            },\n            'playlist_count': 3\n        },\n        {\n            # Ruutu embed in hs.fi with a single video\n            'url': 'https://www.hs.fi/kotimaa/art-2000008793421.html',\n            'md5': 'f8964e65d8fada6e8a562389bf366bb4',\n            'info_dict': {\n                'id': '4081841',\n                'ext': 'mp4',\n                'title': 'Puolustusvoimat siirsi panssariajoneuvoja harjoituksiin Niinisaloon 2.5.2022',\n                'thumbnail': r're:^https?://.+\\.jpg$',\n                'duration': 138,\n                'age_limit': 0,\n                'upload_date': '20220504',\n            },\n        },\n        {\n            # Webpage contains double BOM\n            'url': 'https://www.filmarkivet.se/movies/paris-d-moll/',\n            'md5': 'df02cadc719dcc63d43288366f037754',\n            'info_dict': {\n                'id': 'paris-d-moll',\n                'ext': 'mp4',\n                'upload_date': '20220518',\n                'title': 'Paris d-moll',\n                'description': 'md5:319e37ea5542293db37e1e13072fe330',\n                'thumbnail': 'https://www.filmarkivet.se/wp-content/uploads/parisdmoll2.jpg',\n                'timestamp': 1652833414,\n                'age_limit': 0,\n            }\n        },\n        {\n            'url': 'https://www.mollymovieclub.com/p/interstellar?s=r#details',\n            'md5': '198bde8bed23d0b23c70725c83c9b6d9',\n            'info_dict': {\n                'id': '53602801',\n                'ext': 'mpga',\n                'title': 'Interstellar',\n                'description': 'Listen now | Episode One',\n                'thumbnail': 'md5:c30d9c83f738e16d8551d7219d321538',\n                'uploader': 'Molly Movie Club',\n                'uploader_id': '839621',\n            },\n        },\n        {\n            'url': 'https://www.blockedandreported.org/p/episode-117-lets-talk-about-depp?s=r',\n            'md5': 'c0cc44ee7415daeed13c26e5b56d6aa0',\n            'info_dict': {\n                'id': '57962052',\n                'ext': 'mpga',\n                'title': 'md5:855b2756f0ee10f6723fa00b16266f8d',\n                'description': 'md5:fe512a5e94136ad260c80bde00ea4eef',\n                'thumbnail': 'md5:2218f27dfe517bb5ac16c47d0aebac59',\n                'uploader': 'Blocked and Reported',\n                'uploader_id': '500230',\n            },\n        },\n        {\n            'url': 'https://www.skimag.com/video/ski-people-1980/',\n            'md5': '022a7e31c70620ebec18deeab376ee03',\n            'info_dict': {\n                'id': 'YTmgRiNU',\n                'ext': 'mp4',\n                'title': '1980 Ski People',\n                'timestamp': 1610407738,\n                'description': 'md5:cf9c3d101452c91e141f292b19fe4843',\n                'thumbnail': 'https://cdn.jwplayer.com/v2/media/YTmgRiNU/poster.jpg?width=720',\n                'duration': 5688.0,\n                'upload_date': '20210111',\n            }\n        },\n        {\n            'note': 'JSON LD with multiple @type',\n            'url': 'https://www.nu.nl/280161/video/hoe-een-bladvlo-dit-verwoestende-japanse-onkruid-moet-vernietigen.html',\n            'md5': 'c7949f34f57273013fb7ccb1156393db',\n            'info_dict': {\n                'id': 'ipy2AcGL',\n                'ext': 'mp4',\n                'description': 'md5:6a9d644bab0dc2dc06849c2505d8383d',\n                'thumbnail': r're:https://media\\.nu\\.nl/m/.+\\.jpg',\n                'title': 'Hoe een bladvlo dit verwoestende Japanse onkruid moet vernietigen',\n                'timestamp': 1586577474,\n                'upload_date': '20200411',\n                'age_limit': 0,\n                'duration': 111.0,\n            }\n        },\n        {\n            'note': 'JSON LD with unexpected data type',\n            'url': 'https://www.autoweek.nl/autotests/artikel/porsche-911-gt3-rs-rij-impressie-2/',\n            'info_dict': {\n                'id': 'porsche-911-gt3-rs-rij-impressie-2',\n                'ext': 'mp4',\n                'title': 'Test: Porsche 911 GT3 RS',\n                'description': 'Je ziet het niet, maar het is er wel. Downforce, hebben we het dan over. En in de nieuwe Porsche 911 GT3 RS is er zelfs heel veel downforce.',\n                'timestamp': 1664920902,\n                'upload_date': '20221004',\n                'thumbnail': r're:^https://media.autoweek.nl/m/.+\\.jpg$',\n                'age_limit': 0,\n                'direct': True,\n            }\n        },\n        {\n            'note': 'server returns data in brotli compression by default if `accept-encoding: *` is specified.',\n            'url': 'https://www.extra.cz/cauky-lidi-70-dil-babis-predstavil-pohadky-prymulanek-nebo-andrejovy-nove-saty-ac867',\n            'info_dict': {\n                'id': 'cauky-lidi-70-dil-babis-predstavil-pohadky-prymulanek-nebo-andrejovy-nove-saty-ac867',\n                'ext': 'mp4',\n                'title': '\u010dauky lidi 70 finall',\n                'description': '\u010dauky lidi 70 finall',\n                'thumbnail': 'h',\n                'upload_date': '20220606',\n                'timestamp': 1654513791,\n                'duration': 318.0,\n                'direct': True,\n                'age_limit': 0,\n            },\n        },\n        {\n            'note': 'JW Player embed with unicode-escape sequences in URL',\n            'url': 'https://www.medici.tv/en/concerts/lahav-shani-mozart-mahler-israel-philharmonic-abu-dhabi-classics',\n            'info_dict': {\n                'id': 'm',\n                'ext': 'mp4',\n                'title': 'Lahav Shani conducts the Israel Philharmonic\\'s first-ever concert in Abu Dhabi',\n                'description': 'Mahler\\'s ',\n                'uploader': 'www.medici.tv',\n                'age_limit': 0,\n                'thumbnail': r're:^https?://.+\\.jpg',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            'url': 'https://shooshtime.com/videos/284002/just-out-of-the-shower-joi/',\n            'md5': 'e2f0a4c329f7986280b7328e24036d60',\n            'info_dict': {\n                'id': '284002',\n                'display_id': 'just-out-of-the-shower-joi',\n                'ext': 'mp4',\n                'title': 'Just Out Of The Shower JOI - Shooshtime',\n                'thumbnail': 'https://i.shoosh.co/contents/videos_screenshots/284000/284002/preview.mp4.jpg',\n                'height': 720,\n                'age_limit': 18,\n            },\n        },\n        {\n            'note': 'Live HLS direct link',\n            'url': 'https://d18j67ugtrocuq.cloudfront.net/out/v1/2767aec339144787926bd0322f72c6e9/index.m3u8',\n            'info_dict': {\n                'id': 'index',\n                'title': r're:index',\n                'ext': 'mp4',\n                'live_status': 'is_live',\n            },\n            'params': {\n                'skip_download': 'm3u8',\n            },\n        },\n        {\n            'note': 'Video.js VOD HLS',\n            'url': 'https://gist.githubusercontent.com/bashonly/2aae0862c50f4a4b84f220c315767208/raw/e3380d413749dabbe804c9c2d8fd9a45142475c7/videojs_hls_test.html',\n            'info_dict': {\n                'id': 'videojs_hls_test',\n                'title': 'video',\n                'ext': 'mp4',\n                'age_limit': 0,\n                'duration': 1800,\n            },\n            'params': {\n                'skip_download': 'm3u8',\n            },\n        },\n    ]\n\n    def report_following_redirect(self, new_url):\n        \"\"\"Report information extraction.\"\"\"\n        self._downloader.to_screen('[redirect] Following redirect to %s' % new_url)\n\n    def report_detected(self, name, num=1, note=None):\n        if num > 1:\n            name += 's'\n        elif not num:\n            return\n        else:\n            num = 'a'\n\n        self._downloader.write_debug(f'Identified {num} {name}{format_field(note, None, \"; %s\")}')\n\n    def _extra_manifest_info(self, info, manifest_url):\n        fragment_query = self._configuration_arg('fragment_query', [None], casesense=True)[0]\n        if fragment_query is not None:\n            info['extra_param_to_segment_url'] = (\n                urllib.parse.urlparse(fragment_query).query or fragment_query\n                or urllib.parse.urlparse(manifest_url).query or None)\n\n        hex_or_none = lambda x: x if re.fullmatch(r'(0x)?[\\da-f]+', x, re.IGNORECASE) else None\n        info['hls_aes'] = traverse_obj(self._configuration_arg('hls_key', casesense=True), {\n            'uri': (0, {url_or_none}), 'key': (0, {hex_or_none}), 'iv': (1, {hex_or_none}),\n        }) or None\n\n        variant_query = self._configuration_arg('variant_query', [None], casesense=True)[0]\n        if variant_query is not None:\n            query = urllib.parse.parse_qs(\n                urllib.parse.urlparse(variant_query).query or variant_query\n                or urllib.parse.urlparse(manifest_url).query)\n            for fmt in self._downloader._get_formats(info):\n                fmt['url'] = update_url_query(fmt['url'], query)\n\n        # Attempt to detect live HLS or set VOD duration\n        m3u8_format = next((f for f in self._downloader._get_formats(info)\n                            if determine_protocol(f) == 'm3u8_native'), None)\n        if m3u8_format:\n            is_live = self._configuration_arg('is_live', [None])[0]\n            if is_live is not None:\n                info['live_status'] = 'not_live' if is_live == 'false' else 'is_live'\n                return\n            headers = m3u8_format.get('http_headers') or info.get('http_headers')\n            duration = self._extract_m3u8_vod_duration(\n                m3u8_format['url'], info.get('id'), note='Checking m3u8 live status',\n                errnote='Failed to download m3u8 media playlist', headers=headers)\n            if not duration:\n                info['live_status'] = 'is_live'\n            info['duration'] = info.get('duration') or duration\n\n    def _extract_rss(self, url, video_id, doc):\n        NS_MAP = {\n            'itunes': 'http://www.itunes.com/dtds/podcast-1.0.dtd',\n        }\n\n        entries = []\n        for it in doc.findall('./channel/item'):\n            next_url = next(\n                (e.attrib.get('url') for e in it.findall('./enclosure')),\n                xpath_text(it, 'link', fatal=False))\n            if not next_url:\n                continue\n\n            guid = try_call(lambda: it.find('guid').text)\n            if guid:\n                next_url = smuggle_url(next_url, {'force_videoid': guid})\n\n            def itunes(key):\n                return xpath_text(it, xpath_with_ns(f'./itunes:{key}', NS_MAP), default=None)\n\n            entries.append({\n                '_type': 'url_transparent',\n                'url': next_url,\n                'title': try_call(lambda: it.find('title').text),\n                'description': xpath_text(it, 'description', default=None),\n                'timestamp': unified_timestamp(xpath_text(it, 'pubDate', default=None)),\n                'duration': parse_duration(itunes('duration')),\n                'thumbnail': url_or_none(xpath_attr(it, xpath_with_ns('./itunes:image', NS_MAP), 'href')),\n                'episode': itunes('title'),\n                'episode_number': int_or_none(itunes('episode')),\n                'season_number': int_or_none(itunes('season')),\n                'age_limit': {'true': 18, 'yes': 18, 'false': 0, 'no': 0}.get((itunes('explicit') or '').lower()),\n            })\n\n        return {\n            '_type': 'playlist',\n            'id': url,\n            'title': try_call(lambda: doc.find('./channel/title').text),\n            'description': try_call(lambda: doc.find('./channel/description').text),\n            'entries': entries,\n        }\n\n    @classmethod\n    def _kvs_get_real_url(cls, video_url, license_code):\n        if not video_url.startswith('function/0/'):\n            return video_url  # not obfuscated\n\n        parsed = urllib.parse.urlparse(video_url[len('function/0/'):])\n        license = cls._kvs_get_license_token(license_code)\n        urlparts = parsed.path.split('/')\n\n        HASH_LENGTH = 32\n        hash = urlparts[3][:HASH_LENGTH]\n        indices = list(range(HASH_LENGTH))\n\n        # Swap indices of hash according to the destination calculated from the license token\n        accum = 0\n        for src in reversed(range(HASH_LENGTH)):\n            accum += license[src]\n            dest = (src + accum) % HASH_LENGTH\n            indices[src], indices[dest] = indices[dest], indices[src]\n\n        urlparts[3] = ''.join(hash[index] for index in indices) + urlparts[3][HASH_LENGTH:]\n        return urllib.parse.urlunparse(parsed._replace(path='/'.join(urlparts)))\n\n    @staticmethod\n    def _kvs_get_license_token(license):\n        license = license.replace('$', '')\n        license_values = [int(char) for char in license]\n\n        modlicense = license.replace('0', '1')\n        center = len(modlicense) // 2\n        fronthalf = int(modlicense[:center + 1])\n        backhalf = int(modlicense[center:])\n        modlicense = str(4 * abs(fronthalf - backhalf))[:center + 1]\n\n        return [\n            (license_values[index + offset] + current) % 10\n            for index, current in enumerate(map(int, modlicense))\n            for offset in range(4)\n        ]\n\n    def _extract_kvs(self, url, webpage, video_id):\n        flashvars = self._search_json(\n            r'(?s:<script\\b[^>]*>.*?var\\s+flashvars\\s*=)',\n            webpage, 'flashvars', video_id, transform_source=js_to_json)\n\n        # extract the part after the last / as the display_id from the\n        # canonical URL.\n        display_id = self._search_regex(\n            r'(?:<link href=\"https?://[^\"]+/(.+?)/?\" rel=\"canonical\"\\s*/?>'\n            r'|<link rel=\"canonical\" href=\"https?://[^\"]+/(.+?)/?\"\\s*/?>)',\n            webpage, 'display_id', fatal=False)\n        title = self._html_search_regex(r'<(?:h1|title)>(?:Video: )?(.+?)</(?:h1|title)>', webpage, 'title')\n\n        thumbnail = flashvars['preview_url']\n        if thumbnail.startswith('//'):\n            protocol, _, _ = url.partition('/')\n            thumbnail = protocol + thumbnail\n\n        url_keys = list(filter(re.compile(r'^video_(?:url|alt_url\\d*)$').match, flashvars.keys()))\n        formats = []\n        for key in url_keys:\n            if '/get_file/' not in flashvars[key]:\n                continue\n            format_id = flashvars.get(f'{key}_text', key)\n            formats.append({\n                'url': urljoin(url, self._kvs_get_real_url(flashvars[key], flashvars['license_code'])),\n                'format_id': format_id,\n                'ext': 'mp4',\n                **(parse_resolution(format_id) or parse_resolution(flashvars[key])),\n                'http_headers': {'Referer': url},\n            })\n            if not formats[-1].get('height'):\n                formats[-1]['quality'] = 1\n\n        return {\n            'id': flashvars['video_id'],\n            'display_id': display_id,\n            'title': title,\n            'thumbnail': urljoin(url, thumbnail),\n            'formats': formats,\n        }\n\n    def _real_extract(self, url):\n        if url.startswith('//'):\n            return self.url_result(self.http_scheme() + url)\n\n        parsed_url = urllib.parse.urlparse(url)\n        if not parsed_url.scheme:\n            default_search = self.get_param('default_search')\n            if default_search is None:\n                default_search = 'fixup_error'\n\n            if default_search in ('auto', 'auto_warning', 'fixup_error'):\n                if re.match(r'^[^\\s/]+\\.[^\\s/]+/', url):\n                    self.report_warning('The url doesn\\'t specify the protocol, trying with http')\n                    return self.url_result('http://' + url)\n                elif default_search != 'fixup_error':\n                    if default_search == 'auto_warning':\n                        if re.match(r'^(?:url|URL)$', url):\n                            raise ExtractorError(\n                                'Invalid URL:  %r . Call yt-dlp like this:  yt-dlp -v \"https://www.youtube.com/watch?v=BaW_jenozKc\"  ' % url,\n                                expected=True)\n                        else:\n                            self.report_warning(\n                                'Falling back to youtube search for  %s . Set --default-search \"auto\" to suppress this warning.' % url)\n                    return self.url_result('ytsearch:' + url)\n\n            if default_search in ('error', 'fixup_error'):\n                raise ExtractorError(\n                    '%r is not a valid URL. '\n                    'Set --default-search \"ytsearch\" (or run  yt-dlp \"ytsearch:%s\" ) to search YouTube'\n                    % (url, url), expected=True)\n            else:\n                if ':' not in default_search:\n                    default_search += ':'\n                return self.url_result(default_search + url)\n\n        original_url = url\n        url, smuggled_data = unsmuggle_url(url, {})\n        force_videoid = None\n        is_intentional = smuggled_data.get('to_generic')\n        if 'force_videoid' in smuggled_data:\n            force_videoid = smuggled_data['force_videoid']\n            video_id = force_videoid\n        else:\n            video_id = self._generic_id(url)\n\n        # Some webservers may serve compressed content of rather big size (e.g. gzipped flac)\n        # making it impossible to download only chunk of the file (yet we need only 512kB to\n        # test whether it's HTML or not). According to yt-dlp default Accept-Encoding\n        # that will always result in downloading the whole file that is not desirable.\n        # Therefore for extraction pass we have to override Accept-Encoding to any in order\n        # to accept raw bytes and being able to download only a chunk.\n        # It may probably better to solve this by checking Content-Type for application/octet-stream\n        # after a HEAD request, but not sure if we can rely on this.\n        full_response = self._request_webpage(url, video_id, headers=filter_dict({\n            'Accept-Encoding': 'identity',\n            'Referer': smuggled_data.get('referer'),\n        }))\n        new_url = full_response.url\n        url = urllib.parse.urlparse(url)._replace(scheme=urllib.parse.urlparse(new_url).scheme).geturl()\n        if new_url != extract_basic_auth(url)[0]:\n            self.report_following_redirect(new_url)\n            if force_videoid:\n                new_url = smuggle_url(new_url, {'force_videoid': force_videoid})\n            return self.url_result(new_url)\n\n        info_dict = {\n            'id': video_id,\n            'title': self._generic_title(url),\n            'timestamp': unified_timestamp(full_response.headers.get('Last-Modified'))\n        }\n\n        # Check for direct link to a video\n        content_type = full_response.headers.get('Content-Type', '').lower()\n        m = re.match(r'^(?P<type>audio|video|application(?=/(?:ogg$|(?:vnd\\.apple\\.|x-)?mpegurl)))/(?P<format_id>[^;\\s]+)', content_type)\n        if m:\n            self.report_detected('direct video link')\n            headers = filter_dict({'Referer': smuggled_data.get('referer')})\n            format_id = str(m.group('format_id'))\n            ext = determine_ext(url, default_ext=None) or urlhandle_detect_ext(full_response)\n            subtitles = {}\n            if format_id.endswith('mpegurl') or ext == 'm3u8':\n                formats, subtitles = self._extract_m3u8_formats_and_subtitles(url, video_id, 'mp4', headers=headers)\n            elif format_id.endswith('mpd') or format_id.endswith('dash+xml') or ext == 'mpd':\n                formats, subtitles = self._extract_mpd_formats_and_subtitles(url, video_id, headers=headers)\n            elif format_id == 'f4m' or ext == 'f4m':\n                formats = self._extract_f4m_formats(url, video_id, headers=headers)\n            else:\n                formats = [{\n                    'format_id': format_id,\n                    'url': url,\n                    'ext': ext,\n                    'vcodec': 'none' if m.group('type') == 'audio' else None\n                }]\n                info_dict['direct'] = True\n            info_dict.update({\n                'formats': formats,\n                'subtitles': subtitles,\n                'http_headers': headers or None,\n            })\n            self._extra_manifest_info(info_dict, url)\n            return info_dict\n\n        if not self.get_param('test', False) and not is_intentional:\n            force = self.get_param('force_generic_extractor', False)\n            self.report_warning('%s generic information extractor' % ('Forcing' if force else 'Falling back on'))\n\n        first_bytes = full_response.read(512)\n\n        # Is it an M3U playlist?\n        if first_bytes.startswith(b'#EXTM3U'):\n            self.report_detected('M3U playlist')\n            info_dict['formats'], info_dict['subtitles'] = self._extract_m3u8_formats_and_subtitles(url, video_id, 'mp4')\n            self._extra_manifest_info(info_dict, url)\n            return info_dict\n\n        # Maybe it's a direct link to a video?\n        # Be careful not to download the whole thing!\n        if not is_html(first_bytes):\n            self.report_warning(\n                'URL could be a direct video link, returning it as such.')\n            info_dict.update({\n                'direct': True,\n                'url': url,\n            })\n            return info_dict\n\n        webpage = self._webpage_read_content(\n            full_response, url, video_id, prefix=first_bytes)\n\n        if '<title>DPG Media Privacy Gate</title>' in webpage:\n            webpage = self._download_webpage(url, video_id)\n\n        self.report_extraction(video_id)\n\n        # Is it an RSS feed, a SMIL file, an XSPF playlist or a MPD manifest?\n        try:\n            try:\n                doc = compat_etree_fromstring(webpage)\n            except xml.etree.ElementTree.ParseError:\n                doc = compat_etree_fromstring(webpage.encode('utf-8'))\n            if doc.tag == 'rss':\n                self.report_detected('RSS feed')\n                return self._extract_rss(url, video_id, doc)\n            elif doc.tag == 'SmoothStreamingMedia':\n                info_dict['formats'], info_dict['subtitles'] = self._parse_ism_formats_and_subtitles(doc, url)\n                self.report_detected('ISM manifest')\n                return info_dict\n            elif re.match(r'^(?:{[^}]+})?smil$', doc.tag):\n                smil = self._parse_smil(doc, url, video_id)\n                self.report_detected('SMIL file')\n                return smil\n            elif doc.tag == '{http://xspf.org/ns/0/}playlist':\n                self.report_detected('XSPF playlist')\n                return self.playlist_result(\n                    self._parse_xspf(\n                        doc, video_id, xspf_url=url,\n                        xspf_base_url=full_response.url),\n                    video_id)\n            elif re.match(r'(?i)^(?:{[^}]+})?MPD$', doc.tag):\n                info_dict['formats'], info_dict['subtitles'] = self._parse_mpd_formats_and_subtitles(\n                    doc,\n                    mpd_base_url=full_response.url.rpartition('/')[0],\n                    mpd_url=url)\n                self._extra_manifest_info(info_dict, url)\n                self.report_detected('DASH manifest')\n                return info_dict\n            elif re.match(r'^{http://ns\\.adobe\\.com/f4m/[12]\\.0}manifest$', doc.tag):\n                info_dict['formats'] = self._parse_f4m_formats(doc, url, video_id)\n                self.report_detected('F4M manifest')\n                return info_dict\n        except xml.etree.ElementTree.ParseError:\n            pass\n\n        info_dict.update({\n            # it's tempting to parse this further, but you would\n            # have to take into account all the variations like\n            #   Video Title - Site Name\n            #   Site Name | Video Title\n            #   Video Title - Tagline | Site Name\n            # and so on and so forth; it's just not practical\n            'title': self._generic_title('', webpage, default='video'),\n            'description': self._og_search_description(webpage, default=None),\n            'thumbnail': self._og_search_thumbnail(webpage, default=None),\n            'age_limit': self._rta_search(webpage),\n        })\n\n        self._downloader.write_debug('Looking for embeds')\n        embeds = list(self._extract_embeds(original_url, webpage, urlh=full_response, info_dict=info_dict))\n        if len(embeds) == 1:\n            return merge_dicts(embeds[0], info_dict)\n        elif embeds:\n            return self.playlist_result(embeds, **info_dict)\n        raise UnsupportedError(url)\n\n    def _extract_embeds(self, url, webpage, *, urlh=None, info_dict={}):\n        \"\"\"Returns an iterator of video entries\"\"\"\n        info_dict = types.MappingProxyType(info_dict)  # Prevents accidental mutation\n        video_id = traverse_obj(info_dict, 'display_id', 'id') or self._generic_id(url)\n        url, smuggled_data = unsmuggle_url(url, {})\n        actual_url = urlh.url if urlh else url\n\n        # Sometimes embedded video player is hidden behind percent encoding\n        # (e.g. https://github.com/ytdl-org/youtube-dl/issues/2448)\n        # Unescaping the whole page allows to handle those cases in a generic way\n        # FIXME: unescaping the whole page may break URLs, commenting out for now.\n        # There probably should be a second run of generic extractor on unescaped webpage.\n        # webpage = urllib.parse.unquote(webpage)\n\n        embeds = []\n        for ie in self._downloader._ies.values():\n            if ie.ie_key() in smuggled_data.get('block_ies', []):\n                continue\n            gen = ie.extract_from_webpage(self._downloader, url, webpage)\n            current_embeds = []\n            try:\n                while True:\n                    current_embeds.append(next(gen))\n            except self.StopExtraction:\n                self.report_detected(f'{ie.IE_NAME} exclusive embed', len(current_embeds),\n                                     embeds and 'discarding other embeds')\n                return current_embeds\n            except StopIteration:\n                self.report_detected(f'{ie.IE_NAME} embed', len(current_embeds))\n                embeds.extend(current_embeds)\n\n        if embeds:\n            return embeds\n\n        jwplayer_data = self._find_jwplayer_data(\n            webpage, video_id, transform_source=js_to_json)\n        if jwplayer_data:\n            if isinstance(jwplayer_data.get('playlist'), str):\n                self.report_detected('JW Player playlist')\n                return [self.url_result(jwplayer_data['playlist'], 'JWPlatform')]\n            try:\n                info = self._parse_jwplayer_data(\n                    jwplayer_data, video_id, require_title=False, base_url=url)\n                if traverse_obj(info, 'formats', ('entries', ..., 'formats')):\n                    self.report_detected('JW Player data')\n                    return [info]\n            except ExtractorError:\n                # See https://github.com/ytdl-org/youtube-dl/pull/16735\n                pass\n\n        # Video.js embed\n        mobj = re.search(\n            r'(?s)\\bvideojs\\s*\\(.+?([a-zA-Z0-9_$]+)\\.src\\s*\\(\\s*((?:\\[.+?\\]|{.+?}))\\s*\\)\\s*;',\n            webpage)\n        if mobj is not None:\n            varname = mobj.group(1)\n            sources = variadic(self._parse_json(\n                mobj.group(2), video_id, transform_source=js_to_json, fatal=False) or [])\n            formats, subtitles, src = [], {}, None\n            for source in sources:\n                src = source.get('src')\n                if not src or not isinstance(src, str):\n                    continue\n                src = urllib.parse.urljoin(url, src)\n                src_type = source.get('type')\n                if isinstance(src_type, str):\n                    src_type = src_type.lower()\n                ext = determine_ext(src).lower()\n                if src_type == 'video/youtube':\n                    return [self.url_result(src, YoutubeIE.ie_key())]\n                if src_type == 'application/dash+xml' or ext == 'mpd':\n                    fmts, subs = self._extract_mpd_formats_and_subtitles(\n                        src, video_id, mpd_id='dash', fatal=False)\n                    formats.extend(fmts)\n                    self._merge_subtitles(subs, target=subtitles)\n                elif src_type == 'application/x-mpegurl' or ext == 'm3u8':\n                    fmts, subs = self._extract_m3u8_formats_and_subtitles(\n                        src, video_id, 'mp4', entry_protocol='m3u8_native',\n                        m3u8_id='hls', fatal=False)\n                    formats.extend(fmts)\n                    self._merge_subtitles(subs, target=subtitles)\n\n                if not formats:\n                    formats.append({\n                        'url': src,\n                        'ext': (mimetype2ext(src_type)\n                                or ext if ext in KNOWN_EXTENSIONS else 'mp4'),\n                        'http_headers': {\n                            'Referer': actual_url,\n                        },\n                    })\n            # https://docs.videojs.com/player#addRemoteTextTrack\n            # https://html.spec.whatwg.org/multipage/media.html#htmltrackelement\n            for sub_match in re.finditer(rf'(?s){re.escape(varname)}' r'\\.addRemoteTextTrack\\(({.+?})\\s*,\\s*(?:true|false)\\)', webpage):\n                sub = self._parse_json(\n                    sub_match.group(1), video_id, transform_source=js_to_json, fatal=False) or {}\n                sub_src = str_or_none(sub.get('src'))\n                if not sub_src:\n                    continue\n                subtitles.setdefault(dict_get(sub, ('language', 'srclang')) or 'und', []).append({\n                    'url': urllib.parse.urljoin(url, sub_src),\n                    'name': sub.get('label'),\n                    'http_headers': {\n                        'Referer': actual_url,\n                    },\n                })\n            if formats or subtitles:\n                self.report_detected('video.js embed')\n                info_dict = {'formats': formats, 'subtitles': subtitles}\n                if formats:\n                    self._extra_manifest_info(info_dict, src)\n                return [info_dict]\n\n        # Look for generic KVS player (before json-ld bc of some urls that break otherwise)\n        found = self._search_regex((\n            r'<script\\b[^>]+?\\bsrc\\s*=\\s*([\"\\'])https?://(?:(?!\\1)[^?#])+/kt_player\\.js\\?v=(?P<ver>\\d+(?:\\.\\d+)+)\\1[^>]*>',\n            r'kt_player\\s*\\(\\s*([\"\\'])(?:(?!\\1)[\\w\\W])+\\1\\s*,\\s*([\"\\'])https?://(?:(?!\\2)[^?#])+/kt_player\\.swf\\?v=(?P<ver>\\d+(?:\\.\\d+)+)\\2\\s*,',\n        ), webpage, 'KVS player', group='ver', default=False)\n        if found:\n            self.report_detected('KVS Player')\n            if found.split('.')[0] not in ('4', '5', '6'):\n                self.report_warning(f'Untested major version ({found}) in player engine - download may fail.')\n            return [self._extract_kvs(url, webpage, video_id)]\n\n        # Looking for http://schema.org/VideoObject\n        json_ld = self._search_json_ld(webpage, video_id, default={})\n        if json_ld.get('url') not in (url, None):\n            self.report_detected('JSON LD')\n            is_direct = json_ld.get('ext') not in (None, *MEDIA_EXTENSIONS.manifests)\n            return [merge_dicts({\n                '_type': 'video' if is_direct else 'url_transparent',\n                'url': smuggle_url(json_ld['url'], {\n                    'force_videoid': video_id,\n                    'to_generic': True,\n                    'referer': url,\n                }),\n            }, json_ld)]\n\n        def check_video(vurl):\n            if YoutubeIE.suitable(vurl):\n                return True\n            if RtmpIE.suitable(vurl):\n                return True\n            vpath = urllib.parse.urlparse(vurl).path\n            vext = determine_ext(vpath, None)\n            return vext not in (None, 'swf', 'png', 'jpg', 'srt', 'sbv', 'sub', 'vtt', 'ttml', 'js', 'xml')\n\n        def filter_video(urls):\n            return list(filter(check_video, urls))\n\n        # Start with something easy: JW Player in SWFObject\n        found = filter_video(re.findall(r'flashvars: [\\'\"](?:.*&)?file=(http[^\\'\"&]*)', webpage))\n        if found:\n            self.report_detected('JW Player in SFWObject')\n        else:\n            # Look for gorilla-vid style embedding\n            found = filter_video(re.findall(r'''(?sx)\n                (?:\n                    jw_plugins|\n                    JWPlayerOptions|\n                    jwplayer\\s*\\(\\s*[\"'][^'\"]+[\"']\\s*\\)\\s*\\.setup\n                )\n                .*?\n                ['\"]?file['\"]?\\s*:\\s*[\"\\'](.*?)[\"\\']''', webpage))\n            if found:\n                self.report_detected('JW Player embed')\n        if not found:\n            # Broaden the search a little bit\n            found = filter_video(re.findall(r'[^A-Za-z0-9]?(?:file|source)=(http[^\\'\"&]*)', webpage))\n            if found:\n                self.report_detected('video file')\n        if not found:\n            # Broaden the findall a little bit: JWPlayer JS loader\n            found = filter_video(re.findall(\n                r'[^A-Za-z0-9]?(?:file|video_url)[\"\\']?:\\s*[\"\\'](http(?![^\\'\"]+\\.[0-9]+[\\'\"])[^\\'\"]+)[\"\\']', webpage))\n            if found:\n                self.report_detected('JW Player JS loader')\n        if not found:\n            # Flow player\n            found = filter_video(re.findall(r'''(?xs)\n                flowplayer\\(\"[^\"]+\",\\s*\n                    \\{[^}]+?\\}\\s*,\n                    \\s*\\{[^}]+? [\"']?clip[\"']?\\s*:\\s*\\{\\s*\n                        [\"']?url[\"']?\\s*:\\s*[\"']([^\"']+)[\"']\n            ''', webpage))\n            if found:\n                self.report_detected('Flow Player')\n        if not found:\n            # Cinerama player\n            found = re.findall(\n                r\"cinerama\\.embedPlayer\\(\\s*\\'[^']+\\',\\s*'([^']+)'\", webpage)\n            if found:\n                self.report_detected('Cinerama player')\n        if not found:\n            # Try to find twitter cards info\n            # twitter:player:stream should be checked before twitter:player since\n            # it is expected to contain a raw stream (see\n            # https://dev.twitter.com/cards/types/player#On_twitter.com_via_desktop_browser)\n            found = filter_video(re.findall(\n                r'<meta (?:property|name)=\"twitter:player:stream\" (?:content|value)=\"(.+?)\"', webpage))\n            if found:\n                self.report_detected('Twitter card')\n        if not found:\n            # We look for Open Graph info:\n            # We have to match any number spaces between elements, some sites try to align them, e.g.: statigr.am\n            m_video_type = re.findall(r'<meta.*?property=\"og:video:type\".*?content=\"video/(.*?)\"', webpage)\n            # We only look in og:video if the MIME type is a video, don't try if it's a Flash player:\n            if m_video_type is not None:\n                found = filter_video(re.findall(r'<meta.*?property=\"og:(?:video|audio)\".*?content=\"(.*?)\"', webpage))\n                if found:\n                    self.report_detected('Open Graph video info')\n        if not found:\n            REDIRECT_REGEX = r'[0-9]{,2};\\s*(?:URL|url)=\\'?([^\\'\"]+)'\n            found = re.search(\n                r'(?i)<meta\\s+(?=(?:[a-z-]+=\"[^\"]+\"\\s+)*http-equiv=\"refresh\")'\n                r'(?:[a-z-]+=\"[^\"]+\"\\s+)*?content=\"%s' % REDIRECT_REGEX,\n                webpage)\n            if not found:\n                # Look also in Refresh HTTP header\n                refresh_header = urlh and urlh.headers.get('Refresh')\n                if refresh_header:\n                    found = re.search(REDIRECT_REGEX, refresh_header)\n            if found:\n                new_url = urllib.parse.urljoin(url, unescapeHTML(found.group(1)))\n                if new_url != url:\n                    self.report_following_redirect(new_url)\n                    return [self.url_result(new_url)]\n                else:\n                    found = None\n\n        if not found:\n            # twitter:player is a https URL to iframe player that may or may not\n            # be supported by yt-dlp thus this is checked the very last (see\n            # https://dev.twitter.com/cards/types/player#On_twitter.com_via_desktop_browser)\n            embed_url = self._html_search_meta('twitter:player', webpage, default=None)\n            if embed_url and embed_url != url:\n                self.report_detected('twitter:player iframe')\n                return [self.url_result(embed_url)]\n\n        if not found:\n            return []\n\n        domain_name = self._search_regex(r'^(?:https?://)?([^/]*)/.*', url, 'video uploader', default=None)\n\n        entries = []\n        for video_url in orderedSet(found):\n            video_url = video_url.encode().decode('unicode-escape')\n            video_url = unescapeHTML(video_url)\n            video_url = video_url.replace('\\\\/', '/')\n            video_url = urllib.parse.urljoin(url, video_url)\n            video_id = urllib.parse.unquote(os.path.basename(video_url))\n\n            # Sometimes, jwplayer extraction will result in a YouTube URL\n            if YoutubeIE.suitable(video_url):\n                entries.append(self.url_result(video_url, 'Youtube'))\n                continue\n\n            video_id = os.path.splitext(video_id)[0]\n            headers = {\n                'referer': actual_url\n            }\n\n            entry_info_dict = {\n                'id': video_id,\n                'uploader': domain_name,\n                'title': info_dict['title'],\n                'age_limit': info_dict['age_limit'],\n                'http_headers': headers,\n            }\n\n            if RtmpIE.suitable(video_url):\n                entry_info_dict.update({\n                    '_type': 'url_transparent',\n                    'ie_key': RtmpIE.ie_key(),\n                    'url': video_url,\n                })\n                entries.append(entry_info_dict)\n                continue\n\n            ext = determine_ext(video_url)\n            if ext == 'smil':\n                entry_info_dict = {**self._extract_smil_info(video_url, video_id), **entry_info_dict}\n            elif ext == 'xspf':\n                return [self._extract_xspf_playlist(video_url, video_id)]\n            elif ext == 'm3u8':\n                entry_info_dict['formats'], entry_info_dict['subtitles'] = self._extract_m3u8_formats_and_subtitles(video_url, video_id, ext='mp4', headers=headers)\n                self._extra_manifest_info(entry_info_dict, video_url)\n            elif ext == 'mpd':\n                entry_info_dict['formats'], entry_info_dict['subtitles'] = self._extract_mpd_formats_and_subtitles(video_url, video_id, headers=headers)\n                self._extra_manifest_info(entry_info_dict, video_url)\n            elif ext == 'f4m':\n                entry_info_dict['formats'] = self._extract_f4m_formats(video_url, video_id, headers=headers)\n            elif re.search(r'(?i)\\.(?:ism|smil)/manifest', video_url) and video_url != url:\n                # Just matching .ism/manifest is not enough to be reliably sure\n                # whether it's actually an ISM manifest or some other streaming\n                # manifest since there are various streaming URL formats\n                # possible (see [1]) as well as some other shenanigans like\n                # .smil/manifest URLs that actually serve an ISM (see [2]) and\n                # so on.\n                # Thus the most reasonable way to solve this is to delegate\n                # to generic extractor in order to look into the contents of\n                # the manifest itself.\n                # 1. https://azure.microsoft.com/en-us/documentation/articles/media-services-deliver-content-overview/#streaming-url-formats\n                # 2. https://svs.itworkscdn.net/lbcivod/smil:itwfcdn/lbci/170976.smil/Manifest\n                entry_info_dict = self.url_result(\n                    smuggle_url(video_url, {'to_generic': True}),\n                    GenericIE.ie_key())\n            else:\n                entry_info_dict['url'] = video_url\n\n            entries.append(entry_info_dict)\n\n        if len(entries) > 1:\n            for num, e in enumerate(entries, start=1):\n                # 'url' results don't have a title\n                if e.get('title') is not None:\n                    e['title'] = '%s (%d)' % (e['title'], num)\n        return entries\n", "import re\nimport urllib.parse\nimport xml.etree.ElementTree\n\nfrom .common import InfoExtractor\nfrom ..utils import (\n    ExtractorError,\n    int_or_none,\n    parse_qs,\n    smuggle_url,\n    traverse_obj,\n    unified_timestamp,\n    update_url_query,\n    url_or_none,\n    xpath_text,\n)\n\n\nclass SlidesLiveIE(InfoExtractor):\n    _VALID_URL = r'https?://slideslive\\.com/(?:embed/(?:presentation/)?)?(?P<id>[0-9]+)'\n    _TESTS = [{\n        # service_name = yoda, only XML slides info\n        'url': 'https://slideslive.com/38902413/gcc-ia16-backend',\n        'info_dict': {\n            'id': '38902413',\n            'ext': 'mp4',\n            'title': 'GCC IA16 backend',\n            'timestamp': 1648189972,\n            'upload_date': '20220325',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'thumbnails': 'count:42',\n            'chapters': 'count:41',\n            'duration': 1638,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # service_name = yoda, /v7/ slides\n        'url': 'https://slideslive.com/38935785',\n        'info_dict': {\n            'id': '38935785',\n            'ext': 'mp4',\n            'title': 'Offline Reinforcement Learning: From Algorithms to Practical Challenges',\n            'upload_date': '20211115',\n            'timestamp': 1636996003,\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:640',\n            'chapters': 'count:639',\n            'duration': 9832,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # service_name = yoda, /v1/ slides\n        'url': 'https://slideslive.com/38973182/how-should-a-machine-learning-researcher-think-about-ai-ethics',\n        'info_dict': {\n            'id': '38973182',\n            'ext': 'mp4',\n            'title': 'How Should a Machine Learning Researcher Think About AI Ethics?',\n            'upload_date': '20220201',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'timestamp': 1643728135,\n            'thumbnails': 'count:3',\n            'chapters': 'count:2',\n            'duration': 5889,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # service_name = youtube, only XML slides info\n        'url': 'https://slideslive.com/38897546/special-metaprednaska-petra-ludwiga-hodnoty-pro-lepsi-spolecnost',\n        'md5': '8a79b5e3d700837f40bd2afca3c8fa01',\n        'info_dict': {\n            'id': 'jmg02wCJD5M',\n            'display_id': '38897546',\n            'ext': 'mp4',\n            'title': 'SPECI\u00c1L: Meta-p\u0159edn\u00e1\u0161ka Petra Ludwiga - Hodnoty pro lep\u0161\u00ed spole\u010dnost',\n            'description': 'Watch full version of this video at https://slideslive.com/38897546.',\n            'channel_url': 'https://www.youtube.com/channel/UCZWdAkNYFncuX0khyvhqnxw',\n            'channel': 'SlidesLive Videos - G1',\n            'channel_id': 'UCZWdAkNYFncuX0khyvhqnxw',\n            'uploader_id': 'UCZWdAkNYFncuX0khyvhqnxw',\n            'uploader': 'SlidesLive Videos - G1',\n            'uploader_url': 'http://www.youtube.com/channel/UCZWdAkNYFncuX0khyvhqnxw',\n            'live_status': 'not_live',\n            'upload_date': '20160710',\n            'timestamp': 1618786715,\n            'duration': 6827,\n            'like_count': int,\n            'view_count': int,\n            'comment_count': int,\n            'channel_follower_count': int,\n            'age_limit': 0,\n            'thumbnail': r're:^https?://.*\\.(?:jpg|webp)',\n            'thumbnails': 'count:169',\n            'playable_in_embed': True,\n            'availability': 'unlisted',\n            'tags': [],\n            'categories': ['People & Blogs'],\n            'chapters': 'count:168',\n        },\n    }, {\n        # embed-only presentation, only XML slides info\n        'url': 'https://slideslive.com/embed/presentation/38925850',\n        'info_dict': {\n            'id': '38925850',\n            'ext': 'mp4',\n            'title': 'Towards a Deep Network Architecture for Structured Smoothness',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'thumbnails': 'count:8',\n            'timestamp': 1629671508,\n            'upload_date': '20210822',\n            'chapters': 'count:7',\n            'duration': 326,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # embed-only presentation, only JSON slides info, /v5/ slides (.png)\n        'url': 'https://slideslive.com/38979920/',\n        'info_dict': {\n            'id': '38979920',\n            'ext': 'mp4',\n            'title': 'MoReL: Multi-omics Relational Learning',\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:7',\n            'timestamp': 1654714970,\n            'upload_date': '20220608',\n            'chapters': 'count:6',\n            'duration': 171,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v2/ slides (.jpg)\n        'url': 'https://slideslive.com/38954074',\n        'info_dict': {\n            'id': '38954074',\n            'ext': 'mp4',\n            'title': 'Decentralized Attribution of Generative Models',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'thumbnails': 'count:16',\n            'timestamp': 1622806321,\n            'upload_date': '20210604',\n            'chapters': 'count:15',\n            'duration': 306,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v4/ slides (.png)\n        'url': 'https://slideslive.com/38979570/',\n        'info_dict': {\n            'id': '38979570',\n            'ext': 'mp4',\n            'title': 'Efficient Active Search for Combinatorial Optimization Problems',\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:9',\n            'timestamp': 1654714896,\n            'upload_date': '20220608',\n            'chapters': 'count:8',\n            'duration': 295,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v10/ slides\n        'url': 'https://slideslive.com/embed/presentation/38979880?embed_parent_url=https%3A%2F%2Fedit.videoken.com%2F',\n        'info_dict': {\n            'id': '38979880',\n            'ext': 'mp4',\n            'title': 'The Representation Power of Neural Networks',\n            'timestamp': 1654714962,\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:22',\n            'upload_date': '20220608',\n            'chapters': 'count:21',\n            'duration': 294,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v7/ slides, 2 video slides\n        'url': 'https://slideslive.com/embed/presentation/38979682?embed_container_origin=https%3A%2F%2Fedit.videoken.com',\n        'playlist_count': 3,\n        'info_dict': {\n            'id': '38979682-playlist',\n            'title': 'LoRA: Low-Rank Adaptation of Large Language Models',\n        },\n        'playlist': [{\n            'info_dict': {\n                'id': '38979682',\n                'ext': 'mp4',\n                'title': 'LoRA: Low-Rank Adaptation of Large Language Models',\n                'timestamp': 1654714920,\n                'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n                'thumbnails': 'count:30',\n                'upload_date': '20220608',\n                'chapters': 'count:31',\n                'duration': 272,\n            },\n        }, {\n            'info_dict': {\n                'id': '38979682-021',\n                'ext': 'mp4',\n                'title': 'LoRA: Low-Rank Adaptation of Large Language Models - Slide 021',\n                'duration': 3,\n                'timestamp': 1654714920,\n                'upload_date': '20220608',\n            },\n        }, {\n            'info_dict': {\n                'id': '38979682-024',\n                'ext': 'mp4',\n                'title': 'LoRA: Low-Rank Adaptation of Large Language Models - Slide 024',\n                'duration': 4,\n                'timestamp': 1654714920,\n                'upload_date': '20220608',\n            },\n        }],\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v6/ slides, 1 video slide, edit.videoken.com embed\n        'url': 'https://slideslive.com/38979481/',\n        'playlist_count': 2,\n        'info_dict': {\n            'id': '38979481-playlist',\n            'title': 'How to Train Your MAML to Excel in Few-Shot Classification',\n        },\n        'playlist': [{\n            'info_dict': {\n                'id': '38979481',\n                'ext': 'mp4',\n                'title': 'How to Train Your MAML to Excel in Few-Shot Classification',\n                'timestamp': 1654714877,\n                'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n                'thumbnails': 'count:43',\n                'upload_date': '20220608',\n                'chapters': 'count:43',\n                'duration': 315,\n            },\n        }, {\n            'info_dict': {\n                'id': '38979481-013',\n                'ext': 'mp4',\n                'title': 'How to Train Your MAML to Excel in Few-Shot Classification - Slide 013',\n                'duration': 3,\n                'timestamp': 1654714877,\n                'upload_date': '20220608',\n            },\n        }],\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v3/ slides, .jpg and .png, service_name = youtube\n        'url': 'https://slideslive.com/embed/38932460/',\n        'info_dict': {\n            'id': 'RTPdrgkyTiE',\n            'display_id': '38932460',\n            'ext': 'mp4',\n            'title': 'Active Learning for Hierarchical Multi-Label Classification',\n            'description': 'Watch full version of this video at https://slideslive.com/38932460.',\n            'channel': 'SlidesLive Videos - A',\n            'channel_id': 'UC62SdArr41t_-_fX40QCLRw',\n            'channel_url': 'https://www.youtube.com/channel/UC62SdArr41t_-_fX40QCLRw',\n            'uploader': 'SlidesLive Videos - A',\n            'uploader_id': 'UC62SdArr41t_-_fX40QCLRw',\n            'uploader_url': 'http://www.youtube.com/channel/UC62SdArr41t_-_fX40QCLRw',\n            'upload_date': '20200903',\n            'timestamp': 1602599092,\n            'duration': 942,\n            'age_limit': 0,\n            'live_status': 'not_live',\n            'playable_in_embed': True,\n            'availability': 'unlisted',\n            'categories': ['People & Blogs'],\n            'tags': [],\n            'channel_follower_count': int,\n            'like_count': int,\n            'view_count': int,\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png|webp)',\n            'thumbnails': 'count:21',\n            'chapters': 'count:20',\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # /v3/ slides, .png only, service_name = yoda\n        'url': 'https://slideslive.com/38983994',\n        'info_dict': {\n            'id': '38983994',\n            'ext': 'mp4',\n            'title': 'Zero-Shot AutoML with Pretrained Models',\n            'timestamp': 1662384834,\n            'upload_date': '20220905',\n            'thumbnail': r're:^https?://.*\\.(?:jpg|png)',\n            'thumbnails': 'count:23',\n            'chapters': 'count:22',\n            'duration': 295,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }, {\n        # service_name = yoda\n        'url': 'https://slideslive.com/38903721/magic-a-scientific-resurrection-of-an-esoteric-legend',\n        'only_matching': True,\n    }, {\n        # dead link, service_name = url\n        'url': 'https://slideslive.com/38922070/learning-transferable-skills-1',\n        'only_matching': True,\n    }, {\n        # dead link, service_name = vimeo\n        'url': 'https://slideslive.com/38921896/retrospectives-a-venue-for-selfreflection-in-ml-research-3',\n        'only_matching': True,\n    }]\n\n    _WEBPAGE_TESTS = [{\n        # only XML slides info\n        'url': 'https://iclr.cc/virtual_2020/poster_Hklr204Fvr.html',\n        'info_dict': {\n            'id': '38925850',\n            'ext': 'mp4',\n            'title': 'Towards a Deep Network Architecture for Structured Smoothness',\n            'thumbnail': r're:^https?://.*\\.jpg',\n            'thumbnails': 'count:8',\n            'timestamp': 1629671508,\n            'upload_date': '20210822',\n            'chapters': 'count:7',\n            'duration': 326,\n        },\n        'params': {\n            'skip_download': 'm3u8',\n        },\n    }]\n\n    @classmethod\n    def _extract_embed_urls(cls, url, webpage):\n        # Reference: https://slideslive.com/embed_presentation.js\n        for embed_id in re.findall(r'(?s)new\\s+SlidesLiveEmbed\\s*\\([^)]+\\bpresentationId:\\s*[\"\\'](\\d+)[\"\\']', webpage):\n            url_parsed = urllib.parse.urlparse(url)\n            origin = f'{url_parsed.scheme}://{url_parsed.netloc}'\n            yield update_url_query(\n                f'https://slideslive.com/embed/presentation/{embed_id}', {\n                    'embed_parent_url': url,\n                    'embed_container_origin': origin,\n                })\n\n    def _download_embed_webpage_handle(self, video_id, headers):\n        return self._download_webpage_handle(\n            f'https://slideslive.com/embed/presentation/{video_id}', video_id,\n            headers=headers, query=traverse_obj(headers, {\n                'embed_parent_url': 'Referer',\n                'embed_container_origin': 'Origin',\n            }))\n\n    def _extract_custom_m3u8_info(self, m3u8_data):\n        m3u8_dict = {}\n\n        lookup = {\n            'PRESENTATION-TITLE': 'title',\n            'PRESENTATION-UPDATED-AT': 'timestamp',\n            'PRESENTATION-THUMBNAIL': 'thumbnail',\n            'PLAYLIST-TYPE': 'playlist_type',\n            'VOD-VIDEO-SERVICE-NAME': 'service_name',\n            'VOD-VIDEO-ID': 'service_id',\n            'VOD-VIDEO-SERVERS': 'video_servers',\n            'VOD-SUBTITLES': 'subtitles',\n            'VOD-SLIDES-JSON-URL': 'slides_json_url',\n            'VOD-SLIDES-XML-URL': 'slides_xml_url',\n        }\n\n        for line in m3u8_data.splitlines():\n            if not line.startswith('#EXT-SL-'):\n                continue\n            tag, _, value = line.partition(':')\n            key = lookup.get(tag.lstrip('#EXT-SL-'))\n            if not key:\n                continue\n            m3u8_dict[key] = value\n\n        # Some values are stringified JSON arrays\n        for key in ('video_servers', 'subtitles'):\n            if key in m3u8_dict:\n                m3u8_dict[key] = self._parse_json(m3u8_dict[key], None, fatal=False) or []\n\n        return m3u8_dict\n\n    def _extract_formats_and_duration(self, cdn_hostname, path, video_id, skip_duration=False):\n        formats, duration = [], None\n\n        hls_formats = self._extract_m3u8_formats(\n            f'https://{cdn_hostname}/{path}/master.m3u8',\n            video_id, 'mp4', m3u8_id='hls', fatal=False, live=True)\n        if hls_formats:\n            if not skip_duration:\n                duration = self._extract_m3u8_vod_duration(\n                    hls_formats[0]['url'], video_id, note='Extracting duration from HLS manifest')\n            formats.extend(hls_formats)\n\n        dash_formats = self._extract_mpd_formats(\n            f'https://{cdn_hostname}/{path}/master.mpd', video_id, mpd_id='dash', fatal=False)\n        if dash_formats:\n            if not duration and not skip_duration:\n                duration = self._extract_mpd_vod_duration(\n                    f'https://{cdn_hostname}/{path}/master.mpd', video_id,\n                    note='Extracting duration from DASH manifest')\n            formats.extend(dash_formats)\n\n        return formats, duration\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        webpage, urlh = self._download_embed_webpage_handle(\n            video_id, headers=traverse_obj(parse_qs(url), {\n                'Referer': ('embed_parent_url', -1),\n                'Origin': ('embed_container_origin', -1)}))\n        redirect_url = urlh.url\n        if 'domain_not_allowed' in redirect_url:\n            domain = traverse_obj(parse_qs(redirect_url), ('allowed_domains[]', ...), get_all=False)\n            if not domain:\n                raise ExtractorError(\n                    'This is an embed-only presentation. Try passing --referer', expected=True)\n            webpage, _ = self._download_embed_webpage_handle(video_id, headers={\n                'Referer': f'https://{domain}/',\n                'Origin': f'https://{domain}',\n            })\n\n        player_token = self._search_regex(r'data-player-token=\"([^\"]+)\"', webpage, 'player token')\n        player_data = self._download_webpage(\n            f'https://ben.slideslive.com/player/{video_id}', video_id,\n            note='Downloading player info', query={'player_token': player_token})\n        player_info = self._extract_custom_m3u8_info(player_data)\n\n        service_name = player_info['service_name'].lower()\n        assert service_name in ('url', 'yoda', 'vimeo', 'youtube')\n        service_id = player_info['service_id']\n\n        slide_url_template = 'https://slides.slideslive.com/%s/slides/original/%s%s'\n        slides, slides_info = {}, []\n\n        if player_info.get('slides_json_url'):\n            slides = self._download_json(\n                player_info['slides_json_url'], video_id, fatal=False,\n                note='Downloading slides JSON', errnote=False) or {}\n            slide_ext_default = '.png'\n            slide_quality = traverse_obj(slides, ('slide_qualities', 0))\n            if slide_quality:\n                slide_ext_default = '.jpg'\n                slide_url_template = f'https://cdn.slideslive.com/data/presentations/%s/slides/{slide_quality}/%s%s'\n            for slide_id, slide in enumerate(traverse_obj(slides, ('slides', ...), expected_type=dict), 1):\n                slides_info.append((\n                    slide_id, traverse_obj(slide, ('image', 'name')),\n                    traverse_obj(slide, ('image', 'extname'), default=slide_ext_default),\n                    int_or_none(slide.get('time'), scale=1000)))\n\n        if not slides and player_info.get('slides_xml_url'):\n            slides = self._download_xml(\n                player_info['slides_xml_url'], video_id, fatal=False,\n                note='Downloading slides XML', errnote='Failed to download slides info')\n            if isinstance(slides, xml.etree.ElementTree.Element):\n                slide_url_template = 'https://cdn.slideslive.com/data/presentations/%s/slides/big/%s%s'\n                for slide_id, slide in enumerate(slides.findall('./slide')):\n                    slides_info.append((\n                        slide_id, xpath_text(slide, './slideName', 'name'), '.jpg',\n                        int_or_none(xpath_text(slide, './timeSec', 'time'))))\n\n        chapters, thumbnails = [], []\n        if url_or_none(player_info.get('thumbnail')):\n            thumbnails.append({'id': 'cover', 'url': player_info['thumbnail']})\n        for slide_id, slide_path, slide_ext, start_time in slides_info:\n            if slide_path:\n                thumbnails.append({\n                    'id': f'{slide_id:03d}',\n                    'url': slide_url_template % (video_id, slide_path, slide_ext),\n                })\n            chapters.append({\n                'title': f'Slide {slide_id:03d}',\n                'start_time': start_time,\n            })\n\n        subtitles = {}\n        for sub in traverse_obj(player_info, ('subtitles', ...), expected_type=dict):\n            webvtt_url = url_or_none(sub.get('webvtt_url'))\n            if not webvtt_url:\n                continue\n            subtitles.setdefault(sub.get('language') or 'en', []).append({\n                'url': webvtt_url,\n                'ext': 'vtt',\n            })\n\n        info = {\n            'id': video_id,\n            'title': player_info.get('title') or self._html_search_meta('title', webpage, default=''),\n            'timestamp': unified_timestamp(player_info.get('timestamp')),\n            'is_live': player_info.get('playlist_type') != 'vod',\n            'thumbnails': thumbnails,\n            'chapters': chapters,\n            'subtitles': subtitles,\n        }\n\n        if service_name == 'url':\n            info['url'] = service_id\n        elif service_name == 'yoda':\n            formats, duration = self._extract_formats_and_duration(\n                player_info['video_servers'][0], service_id, video_id)\n            info.update({\n                'duration': duration,\n                'formats': formats,\n            })\n        else:\n            info.update({\n                '_type': 'url_transparent',\n                'url': service_id,\n                'ie_key': service_name.capitalize(),\n                'display_id': video_id,\n            })\n            if service_name == 'vimeo':\n                info['url'] = smuggle_url(\n                    f'https://player.vimeo.com/video/{service_id}',\n                    {'referer': url})\n\n        video_slides = traverse_obj(slides, ('slides', ..., 'video', 'id'))\n        if not video_slides:\n            return info\n\n        def entries():\n            yield info\n\n            service_data = self._download_json(\n                f'https://ben.slideslive.com/player/{video_id}/slides_video_service_data',\n                video_id, fatal=False, query={\n                    'player_token': player_token,\n                    'videos': ','.join(video_slides),\n                }, note='Downloading video slides info', errnote='Failed to download video slides info') or {}\n\n            for slide_id, slide in enumerate(traverse_obj(slides, ('slides', ...)), 1):\n                if not traverse_obj(slide, ('video', 'service')) == 'yoda':\n                    continue\n                video_path = traverse_obj(slide, ('video', 'id'))\n                cdn_hostname = traverse_obj(service_data, (\n                    video_path, 'video_servers', ...), get_all=False)\n                if not cdn_hostname or not video_path:\n                    continue\n                formats, _ = self._extract_formats_and_duration(\n                    cdn_hostname, video_path, video_id, skip_duration=True)\n                if not formats:\n                    continue\n                yield {\n                    'id': f'{video_id}-{slide_id:03d}',\n                    'title': f'{info[\"title\"]} - Slide {slide_id:03d}',\n                    'timestamp': info['timestamp'],\n                    'duration': int_or_none(traverse_obj(slide, ('video', 'duration_ms')), scale=1000),\n                    'formats': formats,\n                }\n\n        return self.playlist_result(entries(), f'{video_id}-playlist', info['title'])\n", "import functools\n\nfrom .common import InfoExtractor\nfrom ..utils import (\n    format_field,\n    int_or_none,\n    OnDemandPagedList,\n    smuggle_url,\n)\n\n\nclass StoryFireBaseIE(InfoExtractor):\n    _VALID_URL_BASE = r'https?://(?:www\\.)?storyfire\\.com/'\n\n    def _call_api(self, path, video_id, resource, query=None):\n        return self._download_json(\n            'https://storyfire.com/app/%s/%s' % (path, video_id), video_id,\n            'Downloading %s JSON metadata' % resource, query=query)\n\n    def _parse_video(self, video):\n        title = video['title']\n        vimeo_id = self._search_regex(\n            r'https?://player\\.vimeo\\.com/external/(\\d+)',\n            video['vimeoVideoURL'], 'vimeo id')\n\n        uploader_id = video.get('hostID')\n\n        return {\n            '_type': 'url_transparent',\n            'id': vimeo_id,\n            'title': title,\n            'description': video.get('description'),\n            'url': smuggle_url(\n                'https://player.vimeo.com/video/' + vimeo_id, {\n                    'referer': 'https://storyfire.com/',\n                }),\n            'thumbnail': video.get('storyImage'),\n            'view_count': int_or_none(video.get('views')),\n            'like_count': int_or_none(video.get('likesCount')),\n            'comment_count': int_or_none(video.get('commentsCount')),\n            'duration': int_or_none(video.get('videoDuration')),\n            'timestamp': int_or_none(video.get('publishDate')),\n            'uploader': video.get('username'),\n            'uploader_id': uploader_id,\n            'uploader_url': format_field(uploader_id, None, 'https://storyfire.com/user/%s/video'),\n            'episode_number': int_or_none(video.get('episodeNumber') or video.get('episode_number')),\n        }\n\n\nclass StoryFireIE(StoryFireBaseIE):\n    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'video-details/(?P<id>[0-9a-f]{24})'\n    _TEST = {\n        'url': 'https://storyfire.com/video-details/5df1d132b6378700117f9181',\n        'md5': 'caec54b9e4621186d6079c7ec100c1eb',\n        'info_dict': {\n            'id': '378954662',\n            'ext': 'mp4',\n            'title': 'Buzzfeed Teaches You About Memes',\n            'uploader_id': 'ntZAJFECERSgqHSxzonV5K2E89s1',\n            'timestamp': 1576129028,\n            'description': 'md5:0b4e28021548e144bed69bb7539e62ea',\n            'uploader': 'whang!',\n            'upload_date': '20191212',\n            'duration': 418,\n            'view_count': int,\n            'like_count': int,\n            'comment_count': int,\n        },\n        'params': {\n            'skip_download': True,\n        },\n        'expected_warnings': ['Unable to download JSON metadata']\n    }\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        video = self._call_api(\n            'generic/video-detail', video_id, 'video')['video']\n        return self._parse_video(video)\n\n\nclass StoryFireUserIE(StoryFireBaseIE):\n    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'user/(?P<id>[^/]+)/video'\n    _TEST = {\n        'url': 'https://storyfire.com/user/UQ986nFxmAWIgnkZQ0ftVhq4nOk2/video',\n        'info_dict': {\n            'id': 'UQ986nFxmAWIgnkZQ0ftVhq4nOk2',\n        },\n        'playlist_mincount': 151,\n    }\n    _PAGE_SIZE = 20\n\n    def _fetch_page(self, user_id, page):\n        videos = self._call_api(\n            'publicVideos', user_id, 'page %d' % (page + 1), {\n                'skip': page * self._PAGE_SIZE,\n            })['videos']\n        for video in videos:\n            yield self._parse_video(video)\n\n    def _real_extract(self, url):\n        user_id = self._match_id(url)\n        entries = OnDemandPagedList(functools.partial(\n            self._fetch_page, user_id), self._PAGE_SIZE)\n        return self.playlist_result(entries, user_id)\n\n\nclass StoryFireSeriesIE(StoryFireBaseIE):\n    _VALID_URL = StoryFireBaseIE._VALID_URL_BASE + r'write/series/stories/(?P<id>[^/?&#]+)'\n    _TESTS = [{\n        'url': 'https://storyfire.com/write/series/stories/-Lq6MsuIHLODO6d2dDkr/',\n        'info_dict': {\n            'id': '-Lq6MsuIHLODO6d2dDkr',\n        },\n        'playlist_mincount': 13,\n    }, {\n        'url': 'https://storyfire.com/write/series/stories/the_mortal_one/',\n        'info_dict': {\n            'id': 'the_mortal_one',\n        },\n        'playlist_count': 0,\n    }]\n\n    def _extract_videos(self, stories):\n        for story in stories.values():\n            if story.get('hasVideo'):\n                yield self._parse_video(story)\n\n    def _real_extract(self, url):\n        series_id = self._match_id(url)\n        stories = self._call_api(\n            'seriesStories', series_id, 'series stories')\n        return self.playlist_result(self._extract_videos(stories), series_id)\n", "import base64\nimport functools\nimport re\nimport itertools\n\nfrom .common import InfoExtractor\nfrom ..compat import compat_str, compat_urlparse\nfrom ..networking import HEADRequest, Request\nfrom ..networking.exceptions import HTTPError\nfrom ..utils import (\n    clean_html,\n    determine_ext,\n    ExtractorError,\n    get_element_by_class,\n    js_to_json,\n    int_or_none,\n    merge_dicts,\n    OnDemandPagedList,\n    parse_filesize,\n    parse_iso8601,\n    parse_qs,\n    smuggle_url,\n    str_or_none,\n    try_get,\n    unified_timestamp,\n    unsmuggle_url,\n    urlencode_postdata,\n    urljoin,\n    urlhandle_detect_ext,\n)\n\n\nclass VimeoBaseInfoExtractor(InfoExtractor):\n    _NETRC_MACHINE = 'vimeo'\n    _LOGIN_REQUIRED = False\n    _LOGIN_URL = 'https://vimeo.com/log_in'\n\n    @staticmethod\n    def _smuggle_referrer(url, referrer_url):\n        return smuggle_url(url, {'referer': referrer_url})\n\n    def _unsmuggle_headers(self, url):\n        \"\"\"@returns (url, smuggled_data, headers)\"\"\"\n        url, data = unsmuggle_url(url, {})\n        headers = self.get_param('http_headers').copy()\n        if 'referer' in data:\n            headers['Referer'] = data['referer']\n        return url, data, headers\n\n    def _perform_login(self, username, password):\n        webpage = self._download_webpage(\n            self._LOGIN_URL, None, 'Downloading login page')\n        token, vuid = self._extract_xsrft_and_vuid(webpage)\n        data = {\n            'action': 'login',\n            'email': username,\n            'password': password,\n            'service': 'vimeo',\n            'token': token,\n        }\n        self._set_vimeo_cookie('vuid', vuid)\n        try:\n            self._download_webpage(\n                self._LOGIN_URL, None, 'Logging in',\n                data=urlencode_postdata(data), headers={\n                    'Content-Type': 'application/x-www-form-urlencoded',\n                    'Referer': self._LOGIN_URL,\n                })\n        except ExtractorError as e:\n            if isinstance(e.cause, HTTPError) and e.cause.status == 418:\n                raise ExtractorError(\n                    'Unable to log in: bad username or password',\n                    expected=True)\n            raise ExtractorError('Unable to log in')\n\n    def _real_initialize(self):\n        if self._LOGIN_REQUIRED and not self._get_cookies('https://vimeo.com').get('vuid'):\n            self._raise_login_required()\n\n    def _get_video_password(self):\n        password = self.get_param('videopassword')\n        if password is None:\n            raise ExtractorError(\n                'This video is protected by a password, use the --video-password option',\n                expected=True)\n        return password\n\n    def _verify_video_password(self, url, video_id, password, token, vuid):\n        if url.startswith('http://'):\n            # vimeo only supports https now, but the user can give an http url\n            url = url.replace('http://', 'https://')\n        self._set_vimeo_cookie('vuid', vuid)\n        return self._download_webpage(\n            url + '/password', video_id, 'Verifying the password',\n            'Wrong password', data=urlencode_postdata({\n                'password': password,\n                'token': token,\n            }), headers={\n                'Content-Type': 'application/x-www-form-urlencoded',\n                'Referer': url,\n            })\n\n    def _extract_xsrft_and_vuid(self, webpage):\n        xsrft = self._search_regex(\n            r'(?:(?P<q1>[\"\\'])xsrft(?P=q1)\\s*:|xsrft\\s*[=:])\\s*(?P<q>[\"\\'])(?P<xsrft>.+?)(?P=q)',\n            webpage, 'login token', group='xsrft')\n        vuid = self._search_regex(\n            r'[\"\\']vuid[\"\\']\\s*:\\s*([\"\\'])(?P<vuid>.+?)\\1',\n            webpage, 'vuid', group='vuid')\n        return xsrft, vuid\n\n    def _extract_vimeo_config(self, webpage, video_id, *args, **kwargs):\n        vimeo_config = self._search_regex(\n            r'vimeo\\.config\\s*=\\s*(?:({.+?})|_extend\\([^,]+,\\s+({.+?})\\));',\n            webpage, 'vimeo config', *args, **kwargs)\n        if vimeo_config:\n            return self._parse_json(vimeo_config, video_id)\n\n    def _set_vimeo_cookie(self, name, value):\n        self._set_cookie('vimeo.com', name, value)\n\n    def _parse_config(self, config, video_id):\n        video_data = config['video']\n        video_title = video_data.get('title')\n        live_event = video_data.get('live_event') or {}\n        is_live = live_event.get('status') == 'started'\n        request = config.get('request') or {}\n\n        formats = []\n        subtitles = {}\n\n        config_files = video_data.get('files') or request.get('files') or {}\n        for f in (config_files.get('progressive') or []):\n            video_url = f.get('url')\n            if not video_url:\n                continue\n            formats.append({\n                'url': video_url,\n                'format_id': 'http-%s' % f.get('quality'),\n                'source_preference': 10,\n                'width': int_or_none(f.get('width')),\n                'height': int_or_none(f.get('height')),\n                'fps': int_or_none(f.get('fps')),\n                'tbr': int_or_none(f.get('bitrate')),\n            })\n\n        # TODO: fix handling of 308 status code returned for live archive manifest requests\n        sep_pattern = r'/sep/video/'\n        for files_type in ('hls', 'dash'):\n            for cdn_name, cdn_data in (try_get(config_files, lambda x: x[files_type]['cdns']) or {}).items():\n                manifest_url = cdn_data.get('url')\n                if not manifest_url:\n                    continue\n                format_id = '%s-%s' % (files_type, cdn_name)\n                sep_manifest_urls = []\n                if re.search(sep_pattern, manifest_url):\n                    for suffix, repl in (('', 'video'), ('_sep', 'sep/video')):\n                        sep_manifest_urls.append((format_id + suffix, re.sub(\n                            sep_pattern, '/%s/' % repl, manifest_url)))\n                else:\n                    sep_manifest_urls = [(format_id, manifest_url)]\n                for f_id, m_url in sep_manifest_urls:\n                    if files_type == 'hls':\n                        fmts, subs = self._extract_m3u8_formats_and_subtitles(\n                            m_url, video_id, 'mp4', live=is_live, m3u8_id=f_id,\n                            note='Downloading %s m3u8 information' % cdn_name,\n                            fatal=False)\n                        formats.extend(fmts)\n                        self._merge_subtitles(subs, target=subtitles)\n                    elif files_type == 'dash':\n                        if 'json=1' in m_url:\n                            real_m_url = (self._download_json(m_url, video_id, fatal=False) or {}).get('url')\n                            if real_m_url:\n                                m_url = real_m_url\n                        fmts, subs = self._extract_mpd_formats_and_subtitles(\n                            m_url.replace('/master.json', '/master.mpd'), video_id, f_id,\n                            'Downloading %s MPD information' % cdn_name,\n                            fatal=False)\n                        formats.extend(fmts)\n                        self._merge_subtitles(subs, target=subtitles)\n\n        live_archive = live_event.get('archive') or {}\n        live_archive_source_url = live_archive.get('source_url')\n        if live_archive_source_url and live_archive.get('status') == 'done':\n            formats.append({\n                'format_id': 'live-archive-source',\n                'url': live_archive_source_url,\n                'quality': 10,\n            })\n\n        for tt in (request.get('text_tracks') or []):\n            subtitles.setdefault(tt['lang'], []).append({\n                'ext': 'vtt',\n                'url': urljoin('https://vimeo.com', tt['url']),\n            })\n\n        thumbnails = []\n        if not is_live:\n            for key, thumb in (video_data.get('thumbs') or {}).items():\n                thumbnails.append({\n                    'id': key,\n                    'width': int_or_none(key),\n                    'url': thumb,\n                })\n            thumbnail = video_data.get('thumbnail')\n            if thumbnail:\n                thumbnails.append({\n                    'url': thumbnail,\n                })\n\n        owner = video_data.get('owner') or {}\n        video_uploader_url = owner.get('url')\n\n        duration = int_or_none(video_data.get('duration'))\n        chapter_data = try_get(config, lambda x: x['embed']['chapters']) or []\n        chapters = [{\n            'title': current_chapter.get('title'),\n            'start_time': current_chapter.get('timecode'),\n            'end_time': next_chapter.get('timecode'),\n        } for current_chapter, next_chapter in zip(chapter_data, chapter_data[1:] + [{'timecode': duration}])]\n        if chapters and chapters[0]['start_time']:  # Chapters may not start from 0\n            chapters[:0] = [{'title': '<Untitled>', 'start_time': 0, 'end_time': chapters[0]['start_time']}]\n\n        return {\n            'id': str_or_none(video_data.get('id')) or video_id,\n            'title': video_title,\n            'uploader': owner.get('name'),\n            'uploader_id': video_uploader_url.split('/')[-1] if video_uploader_url else None,\n            'uploader_url': video_uploader_url,\n            'thumbnails': thumbnails,\n            'duration': duration,\n            'chapters': chapters or None,\n            'formats': formats,\n            'subtitles': subtitles,\n            'is_live': is_live,\n            # Note: Bitrates are completely broken. Single m3u8 may contain entries in kbps and bps\n            # at the same time without actual units specified.\n            '_format_sort_fields': ('quality', 'res', 'fps', 'hdr:12', 'source'),\n        }\n\n    def _extract_original_format(self, url, video_id, unlisted_hash=None):\n        query = {'action': 'load_download_config'}\n        if unlisted_hash:\n            query['unlisted_hash'] = unlisted_hash\n        download_data = self._download_json(\n            url, video_id, fatal=False, query=query,\n            headers={'X-Requested-With': 'XMLHttpRequest'},\n            expected_status=(403, 404)) or {}\n        source_file = download_data.get('source_file')\n        download_url = try_get(source_file, lambda x: x['download_url'])\n        if download_url and not source_file.get('is_cold') and not source_file.get('is_defrosting'):\n            source_name = source_file.get('public_name', 'Original')\n            if self._is_valid_url(download_url, video_id, '%s video' % source_name):\n                ext = (try_get(\n                    source_file, lambda x: x['extension'],\n                    compat_str) or determine_ext(\n                    download_url, None) or 'mp4').lower()\n                return {\n                    'url': download_url,\n                    'ext': ext,\n                    'width': int_or_none(source_file.get('width')),\n                    'height': int_or_none(source_file.get('height')),\n                    'filesize': parse_filesize(source_file.get('size')),\n                    'format_id': source_name,\n                    'quality': 1,\n                }\n\n        jwt_response = self._download_json(\n            'https://vimeo.com/_rv/viewer', video_id, note='Downloading jwt token', fatal=False) or {}\n        if not jwt_response.get('jwt'):\n            return\n        headers = {'Authorization': 'jwt %s' % jwt_response['jwt']}\n        original_response = self._download_json(\n            f'https://api.vimeo.com/videos/{video_id}', video_id,\n            headers=headers, fatal=False, expected_status=(403, 404)) or {}\n        for download_data in original_response.get('download') or []:\n            download_url = download_data.get('link')\n            if not download_url or download_data.get('quality') != 'source':\n                continue\n            ext = determine_ext(parse_qs(download_url).get('filename', [''])[0].lower(), default_ext=None)\n            if not ext:\n                urlh = self._request_webpage(\n                    HEADRequest(download_url), video_id, fatal=False, note='Determining source extension')\n                ext = urlh and urlhandle_detect_ext(urlh)\n            return {\n                'url': download_url,\n                'ext': ext or 'unknown_video',\n                'format_id': download_data.get('public_name', 'Original'),\n                'width': int_or_none(download_data.get('width')),\n                'height': int_or_none(download_data.get('height')),\n                'fps': int_or_none(download_data.get('fps')),\n                'filesize': int_or_none(download_data.get('size')),\n                'quality': 1,\n            }\n\n\nclass VimeoIE(VimeoBaseInfoExtractor):\n    \"\"\"Information extractor for vimeo.com.\"\"\"\n\n    # _VALID_URL matches Vimeo URLs\n    _VALID_URL = r'''(?x)\n                     https?://\n                         (?:\n                             (?:\n                                 www|\n                                 player\n                             )\n                             \\.\n                         )?\n                         vimeo\\.com/\n                         (?:\n                             (?P<u>user)|\n                             (?!(?:channels|album|showcase)/[^/?#]+/?(?:$|[?#])|[^/]+/review/|ondemand/)\n                             (?:.*?/)??\n                             (?P<q>\n                                 (?:\n                                     play_redirect_hls|\n                                     moogaloop\\.swf)\\?clip_id=\n                             )?\n                             (?:videos?/)?\n                         )\n                         (?P<id>[0-9]+)\n                         (?(u)\n                             /(?!videos|likes)[^/?#]+/?|\n                             (?(q)|/(?P<unlisted_hash>[\\da-f]{10}))?\n                         )\n                         (?:(?(q)[&]|(?(u)|/?)[?]).*?)?(?:[#].*)?$\n                 '''\n    IE_NAME = 'vimeo'\n    _EMBED_REGEX = [\n        # iframe\n        r'<iframe[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//player\\.vimeo\\.com/video/\\d+.*?)\\1',\n        # Embedded (swf embed) Vimeo player\n        r'<embed[^>]+?src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?vimeo\\.com/moogaloop\\.swf.+?)\\1',\n        # Non-standard embedded Vimeo player\n        r'<video[^>]+src=([\"\\'])(?P<url>(?:https?:)?//(?:www\\.)?vimeo\\.com/[0-9]+)\\1',\n    ]\n    _TESTS = [\n        {\n            'url': 'http://vimeo.com/56015672#at=0',\n            'md5': '8879b6cc097e987f02484baf890129e5',\n            'info_dict': {\n                'id': '56015672',\n                'ext': 'mp4',\n                'title': \"youtube-dl test video '' \u00e4\u21ad\ud835\udd50-BaW jenozKc\",\n                'description': 'md5:2d3305bad981a06ff79f027f19865021',\n                'timestamp': 1355990239,\n                'upload_date': '20121220',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/user7108434',\n                'uploader_id': 'user7108434',\n                'uploader': 'Filippo Valsorda',\n                'duration': 10,\n                'license': 'by-sa',\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n            },\n            'skip': 'No longer available'\n        },\n        {\n            'url': 'http://player.vimeo.com/video/54469442',\n            'md5': '619b811a4417aa4abe78dc653becf511',\n            'note': 'Videos that embed the url in the player page',\n            'info_dict': {\n                'id': '54469442',\n                'ext': 'mp4',\n                'title': 'Kathy Sierra: Building the minimum Badass User, Business of Software 2012',\n                'uploader': 'Business of Software',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/businessofsoftware',\n                'uploader_id': 'businessofsoftware',\n                'duration': 3610,\n                'description': None,\n                'thumbnail': 'https://i.vimeocdn.com/video/376682406-f34043e7b766af6bef2af81366eacd6724f3fc3173179a11a97a1e26587c9529-d_1280',\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n            },\n        },\n        {\n            'url': 'http://vimeo.com/68375962',\n            'md5': 'aaf896bdb7ddd6476df50007a0ac0ae7',\n            'note': 'Video protected with password',\n            'info_dict': {\n                'id': '68375962',\n                'ext': 'mp4',\n                'title': 'youtube-dl password protected test video',\n                'timestamp': 1371200155,\n                'upload_date': '20130614',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/user18948128',\n                'uploader_id': 'user18948128',\n                'uploader': 'Jaime Marqu\u00ednez Ferr\u00e1ndiz',\n                'duration': 10,\n                'description': 'md5:6173f270cd0c0119f22817204b3eb86c',\n                'thumbnail': 'https://i.vimeocdn.com/video/440665496-b2c5aee2b61089442c794f64113a8e8f7d5763c3e6b3ebfaf696ae6413f8b1f4-d_1280',\n                'view_count': int,\n                'comment_count': int,\n                'like_count': int,\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n                'videopassword': 'youtube-dl',\n            },\n        },\n        {\n            'url': 'http://vimeo.com/channels/keypeele/75629013',\n            'md5': '2f86a05afe9d7abc0b9126d229bbe15d',\n            'info_dict': {\n                'id': '75629013',\n                'ext': 'mp4',\n                'title': 'Key & Peele: Terrorist Interrogation',\n                'description': 'md5:6173f270cd0c0119f22817204b3eb86c',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/atencio',\n                'uploader_id': 'atencio',\n                'uploader': 'Peter Atencio',\n                'channel_id': 'keypeele',\n                'channel_url': r're:https?://(?:www\\.)?vimeo\\.com/channels/keypeele',\n                'timestamp': 1380339469,\n                'upload_date': '20130928',\n                'duration': 187,\n                'thumbnail': 'https://i.vimeocdn.com/video/450239872-a05512d9b1e55d707a7c04365c10980f327b06d966351bc403a5d5d65c95e572-d_1280',\n                'view_count': int,\n                'comment_count': int,\n                'like_count': int,\n            },\n            'params': {'format': 'http-1080p'},\n        },\n        {\n            'url': 'http://vimeo.com/76979871',\n            'note': 'Video with subtitles',\n            'info_dict': {\n                'id': '76979871',\n                'ext': 'mov',\n                'title': 'The New Vimeo Player (You Know, For Videos)',\n                'description': 'md5:2ec900bf97c3f389378a96aee11260ea',\n                'timestamp': 1381846109,\n                'upload_date': '20131015',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/staff',\n                'uploader_id': 'staff',\n                'uploader': 'Vimeo Staff',\n                'duration': 62,\n                'subtitles': {\n                    'de': [{'ext': 'vtt'}],\n                    'en': [{'ext': 'vtt'}],\n                    'es': [{'ext': 'vtt'}],\n                    'fr': [{'ext': 'vtt'}],\n                },\n            },\n            'expected_warnings': ['Ignoring subtitle tracks found in the HLS manifest'],\n        },\n        {\n            # from https://www.ouya.tv/game/Pier-Solar-and-the-Great-Architects/\n            'url': 'https://player.vimeo.com/video/98044508',\n            'note': 'The js code contains assignments to the same variable as the config',\n            'info_dict': {\n                'id': '98044508',\n                'ext': 'mp4',\n                'title': 'Pier Solar OUYA Official Trailer',\n                'uploader': 'Tulio Gon\u00e7alves',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/user28849593',\n                'uploader_id': 'user28849593',\n                'duration': 118,\n                'thumbnail': 'https://i.vimeocdn.com/video/478636036-c18440305ef3df9decfb6bf207a61fe39d2d17fa462a96f6f2d93d30492b037d-d_1280',\n            },\n        },\n        {\n            # contains original format\n            'url': 'https://vimeo.com/33951933',\n            'md5': '53c688fa95a55bf4b7293d37a89c5c53',\n            'info_dict': {\n                'id': '33951933',\n                'ext': 'mp4',\n                'title': 'FOX CLASSICS - Forever Classic ID - A Full Minute',\n                'uploader': 'The DMCI',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/dmci',\n                'uploader_id': 'dmci',\n                'timestamp': 1324343742,\n                'upload_date': '20111220',\n                'description': 'md5:ae23671e82d05415868f7ad1aec21147',\n                'duration': 60,\n                'comment_count': int,\n                'view_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/231174622-dd07f015e9221ff529d451e1cc31c982b5d87bfafa48c4189b1da72824ee289a-d_1280',\n                'like_count': int,\n            },\n        },\n        {\n            'note': 'Contains original format not accessible in webpage',\n            'url': 'https://vimeo.com/393756517',\n            'md5': 'c464af248b592190a5ffbb5d33f382b0',\n            'info_dict': {\n                'id': '393756517',\n                'ext': 'mov',\n                'timestamp': 1582642091,\n                'uploader_id': 'frameworkla',\n                'title': 'Straight To Hell - Sabrina: Netflix',\n                'uploader': 'Framework Studio',\n                'description': 'md5:f2edc61af3ea7a5592681ddbb683db73',\n                'upload_date': '20200225',\n                'duration': 176,\n                'thumbnail': 'https://i.vimeocdn.com/video/859377297-836494a4ef775e9d4edbace83937d9ad34dc846c688c0c419c0e87f7ab06c4b3-d_1280',\n                'uploader_url': 'https://vimeo.com/frameworkla',\n            },\n        },\n        {\n            # only available via https://vimeo.com/channels/tributes/6213729 and\n            # not via https://vimeo.com/6213729\n            'url': 'https://vimeo.com/channels/tributes/6213729',\n            'info_dict': {\n                'id': '6213729',\n                'ext': 'mp4',\n                'title': 'Vimeo Tribute: The Shining',\n                'uploader': 'Casey Donahue',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/caseydonahue',\n                'uploader_id': 'caseydonahue',\n                'channel_url': r're:https?://(?:www\\.)?vimeo\\.com/channels/tributes',\n                'channel_id': 'tributes',\n                'timestamp': 1250886430,\n                'upload_date': '20090821',\n                'description': 'md5:bdbf314014e58713e6e5b66eb252f4a6',\n                'duration': 321,\n                'comment_count': int,\n                'view_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/22728298-bfc22146f930de7cf497821c7b0b9f168099201ecca39b00b6bd31fcedfca7a6-d_1280',\n                'like_count': int,\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # redirects to ondemand extractor and should be passed through it\n            # for successful extraction\n            'url': 'https://vimeo.com/73445910',\n            'info_dict': {\n                'id': '73445910',\n                'ext': 'mp4',\n                'title': 'The Reluctant Revolutionary',\n                'uploader': '10Ft Films',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/tenfootfilms',\n                'uploader_id': 'tenfootfilms',\n                'description': 'md5:0fa704e05b04f91f40b7f3ca2e801384',\n                'upload_date': '20130830',\n                'timestamp': 1377853339,\n            },\n            'params': {\n                'skip_download': True,\n            },\n            'skip': 'this page is no longer available.',\n        },\n        {\n            'url': 'http://player.vimeo.com/video/68375962',\n            'md5': 'aaf896bdb7ddd6476df50007a0ac0ae7',\n            'info_dict': {\n                'id': '68375962',\n                'ext': 'mp4',\n                'title': 'youtube-dl password protected test video',\n                'timestamp': 1371200155,\n                'upload_date': '20130614',\n                'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/user18948128',\n                'uploader_id': 'user18948128',\n                'uploader': 'Jaime Marqu\u00ednez Ferr\u00e1ndiz',\n                'duration': 10,\n                'description': 'md5:6173f270cd0c0119f22817204b3eb86c',\n                'thumbnail': 'https://i.vimeocdn.com/video/440665496-b2c5aee2b61089442c794f64113a8e8f7d5763c3e6b3ebfaf696ae6413f8b1f4-d_1280',\n                'view_count': int,\n                'comment_count': int,\n                'like_count': int,\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n                'videopassword': 'youtube-dl',\n            },\n        },\n        {\n            'url': 'http://vimeo.com/moogaloop.swf?clip_id=2539741',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://vimeo.com/109815029',\n            'note': 'Video not completely processed, \"failed\" seed status',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://vimeo.com/groups/travelhd/videos/22439234',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://vimeo.com/album/2632481/video/79010983',\n            'only_matching': True,\n        },\n        {\n            'url': 'https://vimeo.com/showcase/3253534/video/119195465',\n            'note': 'A video in a password protected album (showcase)',\n            'info_dict': {\n                'id': '119195465',\n                'ext': 'mp4',\n                'title': \"youtube-dl test video '' \u00e4\u21ad\ud835\udd50-BaW jenozKc\",\n                'uploader': 'Philipp Hagemeister',\n                'uploader_id': 'user20132939',\n                'description': 'md5:fa7b6c6d8db0bdc353893df2f111855b',\n                'upload_date': '20150209',\n                'timestamp': 1423518307,\n                'thumbnail': 'https://i.vimeocdn.com/video/default_1280',\n                'duration': 10,\n                'like_count': int,\n                'uploader_url': 'https://vimeo.com/user20132939',\n                'view_count': int,\n                'comment_count': int,\n            },\n            'params': {\n                'format': 'best[protocol=https]',\n                'videopassword': 'youtube-dl',\n            },\n        },\n        {\n            # source file returns 403: Forbidden\n            'url': 'https://vimeo.com/7809605',\n            'only_matching': True,\n        },\n        {\n            'note': 'Direct URL with hash',\n            'url': 'https://vimeo.com/160743502/abd0e13fb4',\n            'info_dict': {\n                'id': '160743502',\n                'ext': 'mp4',\n                'uploader': 'Julian Tryba',\n                'uploader_id': 'aliniamedia',\n                'title': 'Harrisville New Hampshire',\n                'timestamp': 1459259666,\n                'upload_date': '20160329',\n                'release_timestamp': 1459259666,\n                'license': 'by-nc',\n                'duration': 159,\n                'comment_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/562802436-585eeb13b5020c6ac0f171a2234067938098f84737787df05ff0d767f6d54ee9-d_1280',\n                'like_count': int,\n                'uploader_url': 'https://vimeo.com/aliniamedia',\n                'release_date': '20160329',\n            },\n            'params': {'skip_download': True},\n        },\n        {\n            'url': 'https://vimeo.com/138909882',\n            'info_dict': {\n                'id': '138909882',\n                'ext': 'mp4',\n                'title': 'Eastnor Castle 2015 Firework Champions - The Promo!',\n                'description': 'md5:5967e090768a831488f6e74b7821b3c1',\n                'uploader_id': 'fireworkchampions',\n                'uploader': 'Firework Champions',\n                'upload_date': '20150910',\n                'timestamp': 1441901895,\n            },\n            'params': {\n                'skip_download': True,\n                'format': 'Original',\n            },\n        },\n        {\n            'url': 'https://vimeo.com/channels/staffpicks/143603739',\n            'info_dict': {\n                'id': '143603739',\n                'ext': 'mp4',\n                'uploader': 'Karim Huu Do',\n                'timestamp': 1445846953,\n                'upload_date': '20151026',\n                'title': 'The Shoes - Submarine Feat. Blaine Harrison',\n                'uploader_id': 'karimhd',\n                'description': 'md5:8e2eea76de4504c2e8020a9bcfa1e843',\n                'channel_id': 'staffpicks',\n                'duration': 336,\n                'comment_count': int,\n                'view_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/541243181-b593db36a16db2f0096f655da3f5a4dc46b8766d77b0f440df937ecb0c418347-d_1280',\n                'like_count': int,\n                'uploader_url': 'https://vimeo.com/karimhd',\n                'channel_url': 'https://vimeo.com/channels/staffpicks',\n            },\n            'params': {'skip_download': 'm3u8'},\n        },\n        {\n            # requires passing unlisted_hash(a52724358e) to load_download_config request\n            'url': 'https://vimeo.com/392479337/a52724358e',\n            'only_matching': True,\n        },\n        {\n            # similar, but all numeric: ID must be 581039021, not 9603038895\n            # issue #29690\n            'url': 'https://vimeo.com/581039021/9603038895',\n            'info_dict': {\n                'id': '581039021',\n                'ext': 'mp4',\n                'timestamp': 1627621014,\n                'release_timestamp': 1627621014,\n                'duration': 976,\n                'comment_count': int,\n                'thumbnail': 'https://i.vimeocdn.com/video/1202249320-4ddb2c30398c0dc0ee059172d1bd5ea481ad12f0e0e3ad01d2266f56c744b015-d_1280',\n                'like_count': int,\n                'uploader_url': 'https://vimeo.com/txwestcapital',\n                'release_date': '20210730',\n                'uploader': 'Christopher Inks',\n                'title': 'Thursday, July 29, 2021 BMA Evening Video Update',\n                'uploader_id': 'txwestcapital',\n                'upload_date': '20210730',\n            },\n            'params': {\n                'skip_download': True,\n            },\n        },\n        {\n            # user playlist alias -> https://vimeo.com/258705797\n            'url': 'https://vimeo.com/user26785108/newspiritualguide',\n            'only_matching': True,\n        },\n        # https://gettingthingsdone.com/workflowmap/\n        # vimeo embed with check-password page protected by Referer header\n    ]\n\n    @classmethod\n    def _extract_embed_urls(cls, url, webpage):\n        for embed_url in super()._extract_embed_urls(url, webpage):\n            yield cls._smuggle_referrer(embed_url, url)\n\n    @classmethod\n    def _extract_url(cls, url, webpage):\n        return next(cls._extract_embed_urls(url, webpage), None)\n\n    def _verify_player_video_password(self, url, video_id, headers):\n        password = self._get_video_password()\n        data = urlencode_postdata({\n            'password': base64.b64encode(password.encode()),\n        })\n        headers = merge_dicts(headers, {\n            'Content-Type': 'application/x-www-form-urlencoded',\n        })\n        checked = self._download_json(\n            f'{compat_urlparse.urlsplit(url)._replace(query=None).geturl()}/check-password',\n            video_id, 'Verifying the password', data=data, headers=headers)\n        if checked is False:\n            raise ExtractorError('Wrong video password', expected=True)\n        return checked\n\n    def _extract_from_api(self, video_id, unlisted_hash=None):\n        token = self._download_json(\n            'https://vimeo.com/_rv/jwt', video_id, headers={\n                'X-Requested-With': 'XMLHttpRequest'\n            })['token']\n        api_url = 'https://api.vimeo.com/videos/' + video_id\n        if unlisted_hash:\n            api_url += ':' + unlisted_hash\n        video = self._download_json(\n            api_url, video_id, headers={\n                'Authorization': 'jwt ' + token,\n            }, query={\n                'fields': 'config_url,created_time,description,license,metadata.connections.comments.total,metadata.connections.likes.total,release_time,stats.plays',\n            })\n        info = self._parse_config(self._download_json(\n            video['config_url'], video_id), video_id)\n        get_timestamp = lambda x: parse_iso8601(video.get(x + '_time'))\n        info.update({\n            'description': video.get('description'),\n            'license': video.get('license'),\n            'release_timestamp': get_timestamp('release'),\n            'timestamp': get_timestamp('created'),\n            'view_count': int_or_none(try_get(video, lambda x: x['stats']['plays'])),\n        })\n        connections = try_get(\n            video, lambda x: x['metadata']['connections'], dict) or {}\n        for k in ('comment', 'like'):\n            info[k + '_count'] = int_or_none(try_get(connections, lambda x: x[k + 's']['total']))\n        return info\n\n    def _try_album_password(self, url):\n        album_id = self._search_regex(\n            r'vimeo\\.com/(?:album|showcase)/([^/]+)', url, 'album id', default=None)\n        if not album_id:\n            return\n        viewer = self._download_json(\n            'https://vimeo.com/_rv/viewer', album_id, fatal=False)\n        if not viewer:\n            webpage = self._download_webpage(url, album_id)\n            viewer = self._parse_json(self._search_regex(\n                r'bootstrap_data\\s*=\\s*({.+?})</script>',\n                webpage, 'bootstrap data'), album_id)['viewer']\n        jwt = viewer['jwt']\n        album = self._download_json(\n            'https://api.vimeo.com/albums/' + album_id,\n            album_id, headers={'Authorization': 'jwt ' + jwt},\n            query={'fields': 'description,name,privacy'})\n        if try_get(album, lambda x: x['privacy']['view']) == 'password':\n            password = self.get_param('videopassword')\n            if not password:\n                raise ExtractorError(\n                    'This album is protected by a password, use the --video-password option',\n                    expected=True)\n            self._set_vimeo_cookie('vuid', viewer['vuid'])\n            try:\n                self._download_json(\n                    'https://vimeo.com/showcase/%s/auth' % album_id,\n                    album_id, 'Verifying the password', data=urlencode_postdata({\n                        'password': password,\n                        'token': viewer['xsrft'],\n                    }), headers={\n                        'X-Requested-With': 'XMLHttpRequest',\n                    })\n            except ExtractorError as e:\n                if isinstance(e.cause, HTTPError) and e.cause.status == 401:\n                    raise ExtractorError('Wrong password', expected=True)\n                raise\n\n    def _real_extract(self, url):\n        url, data, headers = self._unsmuggle_headers(url)\n        if 'Referer' not in headers:\n            headers['Referer'] = url\n\n        # Extract ID from URL\n        mobj = self._match_valid_url(url).groupdict()\n        video_id, unlisted_hash = mobj['id'], mobj.get('unlisted_hash')\n        if unlisted_hash:\n            return self._extract_from_api(video_id, unlisted_hash)\n\n        if any(p in url for p in ('play_redirect_hls', 'moogaloop.swf')):\n            url = 'https://vimeo.com/' + video_id\n\n        self._try_album_password(url)\n        try:\n            # Retrieve video webpage to extract further information\n            webpage, urlh = self._download_webpage_handle(\n                url, video_id, headers=headers)\n            redirect_url = urlh.url\n        except ExtractorError as ee:\n            if isinstance(ee.cause, HTTPError) and ee.cause.status == 403:\n                errmsg = ee.cause.response.read()\n                if b'Because of its privacy settings, this video cannot be played here' in errmsg:\n                    raise ExtractorError(\n                        'Cannot download embed-only video without embedding '\n                        'URL. Please call yt-dlp with the URL of the page '\n                        'that embeds this video.',\n                        expected=True)\n            raise\n\n        if '://player.vimeo.com/video/' in url:\n            config = self._search_json(\n                r'\\b(?:playerC|c)onfig\\s*=', webpage, 'info section', video_id)\n            if config.get('view') == 4:\n                config = self._verify_player_video_password(\n                    redirect_url, video_id, headers)\n            return self._parse_config(config, video_id)\n\n        if re.search(r'<form[^>]+?id=\"pw_form\"', webpage):\n            video_password = self._get_video_password()\n            token, vuid = self._extract_xsrft_and_vuid(webpage)\n            webpage = self._verify_video_password(\n                redirect_url, video_id, video_password, token, vuid)\n\n        vimeo_config = self._extract_vimeo_config(webpage, video_id, default=None)\n        if vimeo_config:\n            seed_status = vimeo_config.get('seed_status') or {}\n            if seed_status.get('state') == 'failed':\n                raise ExtractorError(\n                    '%s said: %s' % (self.IE_NAME, seed_status['title']),\n                    expected=True)\n\n        cc_license = None\n        timestamp = None\n        video_description = None\n        info_dict = {}\n        config_url = None\n\n        channel_id = self._search_regex(\n            r'vimeo\\.com/channels/([^/]+)', url, 'channel id', default=None)\n        if channel_id:\n            config_url = self._html_search_regex(\n                r'\\bdata-config-url=\"([^\"]+)\"', webpage, 'config URL', default=None)\n            video_description = clean_html(get_element_by_class('description', webpage))\n            info_dict.update({\n                'channel_id': channel_id,\n                'channel_url': 'https://vimeo.com/channels/' + channel_id,\n            })\n        if not config_url:\n            page_config = self._parse_json(self._search_regex(\n                r'vimeo\\.(?:clip|vod_title)_page_config\\s*=\\s*({.+?});',\n                webpage, 'page config', default='{}'), video_id, fatal=False)\n            if not page_config:\n                return self._extract_from_api(video_id)\n            config_url = page_config['player']['config_url']\n            cc_license = page_config.get('cc_license')\n            clip = page_config.get('clip') or {}\n            timestamp = clip.get('uploaded_on')\n            video_description = clean_html(\n                clip.get('description') or page_config.get('description_html_escaped'))\n        config = self._download_json(config_url, video_id)\n        video = config.get('video') or {}\n        vod = video.get('vod') or {}\n\n        def is_rented():\n            if '>You rented this title.<' in webpage:\n                return True\n            if try_get(config, lambda x: x['user']['purchased']):\n                return True\n            for purchase_option in (vod.get('purchase_options') or []):\n                if purchase_option.get('purchased'):\n                    return True\n                label = purchase_option.get('label_string')\n                if label and (label.startswith('You rented this') or label.endswith(' remaining')):\n                    return True\n            return False\n\n        if is_rented() and vod.get('is_trailer'):\n            feature_id = vod.get('feature_id')\n            if feature_id and not data.get('force_feature_id', False):\n                return self.url_result(smuggle_url(\n                    'https://player.vimeo.com/player/%s' % feature_id,\n                    {'force_feature_id': True}), 'Vimeo')\n\n        if not video_description:\n            video_description = self._html_search_regex(\n                r'(?s)<div\\s+class=\"[^\"]*description[^\"]*\"[^>]*>(.*?)</div>',\n                webpage, 'description', default=None)\n        if not video_description:\n            video_description = self._html_search_meta(\n                ['description', 'og:description', 'twitter:description'],\n                webpage, default=None)\n        if not video_description:\n            self.report_warning('Cannot find video description')\n\n        if not timestamp:\n            timestamp = self._search_regex(\n                r'<time[^>]+datetime=\"([^\"]+)\"', webpage,\n                'timestamp', default=None)\n\n        view_count = int_or_none(self._search_regex(r'UserPlays:(\\d+)', webpage, 'view count', default=None))\n        like_count = int_or_none(self._search_regex(r'UserLikes:(\\d+)', webpage, 'like count', default=None))\n        comment_count = int_or_none(self._search_regex(r'UserComments:(\\d+)', webpage, 'comment count', default=None))\n\n        formats = []\n\n        source_format = self._extract_original_format(\n            'https://vimeo.com/' + video_id, video_id, video.get('unlisted_hash'))\n        if source_format:\n            formats.append(source_format)\n\n        info_dict_config = self._parse_config(config, video_id)\n        formats.extend(info_dict_config['formats'])\n        info_dict['_format_sort_fields'] = info_dict_config['_format_sort_fields']\n\n        json_ld = self._search_json_ld(webpage, video_id, default={})\n\n        if not cc_license:\n            cc_license = self._search_regex(\n                r'<link[^>]+rel=[\"\\']license[\"\\'][^>]+href=([\"\\'])(?P<license>(?:(?!\\1).)+)\\1',\n                webpage, 'license', default=None, group='license')\n\n        info_dict.update({\n            'formats': formats,\n            'timestamp': unified_timestamp(timestamp),\n            'description': video_description,\n            'webpage_url': url,\n            'view_count': view_count,\n            'like_count': like_count,\n            'comment_count': comment_count,\n            'license': cc_license,\n        })\n\n        return merge_dicts(info_dict, info_dict_config, json_ld)\n\n\nclass VimeoOndemandIE(VimeoIE):  # XXX: Do not subclass from concrete IE\n    IE_NAME = 'vimeo:ondemand'\n    _VALID_URL = r'https?://(?:www\\.)?vimeo\\.com/ondemand/(?:[^/]+/)?(?P<id>[^/?#&]+)'\n    _TESTS = [{\n        # ondemand video not available via https://vimeo.com/id\n        'url': 'https://vimeo.com/ondemand/20704',\n        'md5': 'c424deda8c7f73c1dfb3edd7630e2f35',\n        'info_dict': {\n            'id': '105442900',\n            'ext': 'mp4',\n            'title': '\u05d4\u05de\u05e2\u05d1\u05d3\u05d4 - \u05d1\u05de\u05d0\u05d9 \u05d9\u05d5\u05ea\u05dd \u05e4\u05dc\u05d3\u05de\u05df',\n            'uploader': '\u05d2\u05dd \u05e1\u05e8\u05d8\u05d9\u05dd',\n            'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/gumfilms',\n            'uploader_id': 'gumfilms',\n            'description': 'md5:aeeba3dbd4d04b0fa98a4fdc9c639998',\n            'upload_date': '20140906',\n            'timestamp': 1410032453,\n            'thumbnail': 'https://i.vimeocdn.com/video/488238335-d7bf151c364cff8d467f1b73784668fe60aae28a54573a35d53a1210ae283bd8-d_1280',\n            'comment_count': int,\n            'license': 'https://creativecommons.org/licenses/by-nc-nd/3.0/',\n            'duration': 53,\n            'view_count': int,\n            'like_count': int,\n        },\n        'params': {\n            'format': 'best[protocol=https]',\n        },\n        'expected_warnings': ['Unable to download JSON metadata'],\n    }, {\n        # requires Referer to be passed along with og:video:url\n        'url': 'https://vimeo.com/ondemand/36938/126682985',\n        'info_dict': {\n            'id': '126584684',\n            'ext': 'mp4',\n            'title': 'R\u00e4vlock, r\u00e4tt l\u00e4te p\u00e5 r\u00e4tt plats',\n            'uploader': 'Lindroth & Norin',\n            'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/lindrothnorin',\n            'uploader_id': 'lindrothnorin',\n            'description': 'md5:c3c46a90529612c8279fb6af803fc0df',\n            'upload_date': '20150502',\n            'timestamp': 1430586422,\n            'duration': 121,\n            'comment_count': int,\n            'view_count': int,\n            'thumbnail': 'https://i.vimeocdn.com/video/517077723-7066ae1d9a79d3eb361334fb5d58ec13c8f04b52f8dd5eadfbd6fb0bcf11f613-d_1280',\n            'like_count': int,\n        },\n        'params': {\n            'skip_download': True,\n        },\n        'expected_warnings': ['Unable to download JSON metadata'],\n    }, {\n        'url': 'https://vimeo.com/ondemand/nazmaalik',\n        'only_matching': True,\n    }, {\n        'url': 'https://vimeo.com/ondemand/141692381',\n        'only_matching': True,\n    }, {\n        'url': 'https://vimeo.com/ondemand/thelastcolony/150274832',\n        'only_matching': True,\n    }]\n\n\nclass VimeoChannelIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vimeo:channel'\n    _VALID_URL = r'https://vimeo\\.com/channels/(?P<id>[^/?#]+)/?(?:$|[?#])'\n    _MORE_PAGES_INDICATOR = r'<a.+?rel=\"next\"'\n    _TITLE = None\n    _TITLE_RE = r'<link rel=\"alternate\"[^>]+?title=\"(.*?)\"'\n    _TESTS = [{\n        'url': 'https://vimeo.com/channels/tributes',\n        'info_dict': {\n            'id': 'tributes',\n            'title': 'Vimeo Tributes',\n        },\n        'playlist_mincount': 22,\n    }]\n    _BASE_URL_TEMPL = 'https://vimeo.com/channels/%s'\n\n    def _page_url(self, base_url, pagenum):\n        return '%s/videos/page:%d/' % (base_url, pagenum)\n\n    def _extract_list_title(self, webpage):\n        return self._TITLE or self._html_search_regex(\n            self._TITLE_RE, webpage, 'list title', fatal=False)\n\n    def _title_and_entries(self, list_id, base_url):\n        for pagenum in itertools.count(1):\n            page_url = self._page_url(base_url, pagenum)\n            webpage = self._download_webpage(\n                page_url, list_id,\n                'Downloading page %s' % pagenum)\n\n            if pagenum == 1:\n                yield self._extract_list_title(webpage)\n\n            # Try extracting href first since not all videos are available via\n            # short https://vimeo.com/id URL (e.g. https://vimeo.com/channels/tributes/6213729)\n            clips = re.findall(\n                r'id=\"clip_(\\d+)\"[^>]*>\\s*<a[^>]+href=\"(/(?:[^/]+/)*\\1)(?:[^>]+\\btitle=\"([^\"]+)\")?', webpage)\n            if clips:\n                for video_id, video_url, video_title in clips:\n                    yield self.url_result(\n                        compat_urlparse.urljoin(base_url, video_url),\n                        VimeoIE.ie_key(), video_id=video_id, video_title=video_title)\n            # More relaxed fallback\n            else:\n                for video_id in re.findall(r'id=[\"\\']clip_(\\d+)', webpage):\n                    yield self.url_result(\n                        'https://vimeo.com/%s' % video_id,\n                        VimeoIE.ie_key(), video_id=video_id)\n\n            if re.search(self._MORE_PAGES_INDICATOR, webpage, re.DOTALL) is None:\n                break\n\n    def _extract_videos(self, list_id, base_url):\n        title_and_entries = self._title_and_entries(list_id, base_url)\n        list_title = next(title_and_entries)\n        return self.playlist_result(title_and_entries, list_id, list_title)\n\n    def _real_extract(self, url):\n        channel_id = self._match_id(url)\n        return self._extract_videos(channel_id, self._BASE_URL_TEMPL % channel_id)\n\n\nclass VimeoUserIE(VimeoChannelIE):  # XXX: Do not subclass from concrete IE\n    IE_NAME = 'vimeo:user'\n    _VALID_URL = r'https://vimeo\\.com/(?!(?:[0-9]+|watchlater)(?:$|[?#/]))(?P<id>[^/]+)(?:/videos)?/?(?:$|[?#])'\n    _TITLE_RE = r'<a[^>]+?class=\"user\">([^<>]+?)</a>'\n    _TESTS = [{\n        'url': 'https://vimeo.com/nkistudio/videos',\n        'info_dict': {\n            'title': 'Nki',\n            'id': 'nkistudio',\n        },\n        'playlist_mincount': 66,\n    }, {\n        'url': 'https://vimeo.com/nkistudio/',\n        'only_matching': True,\n    }]\n    _BASE_URL_TEMPL = 'https://vimeo.com/%s'\n\n\nclass VimeoAlbumIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vimeo:album'\n    _VALID_URL = r'https://vimeo\\.com/(?:album|showcase)/(?P<id>\\d+)(?:$|[?#]|/(?!video))'\n    _TITLE_RE = r'<header id=\"page_header\">\\n\\s*<h1>(.*?)</h1>'\n    _TESTS = [{\n        'url': 'https://vimeo.com/album/2632481',\n        'info_dict': {\n            'id': '2632481',\n            'title': 'Staff Favorites: November 2013',\n        },\n        'playlist_mincount': 13,\n    }, {\n        'note': 'Password-protected album',\n        'url': 'https://vimeo.com/album/3253534',\n        'info_dict': {\n            'title': 'test',\n            'id': '3253534',\n        },\n        'playlist_count': 1,\n        'params': {\n            'videopassword': 'youtube-dl',\n        }\n    }]\n    _PAGE_SIZE = 100\n\n    def _fetch_page(self, album_id, authorization, hashed_pass, page):\n        api_page = page + 1\n        query = {\n            'fields': 'link,uri',\n            'page': api_page,\n            'per_page': self._PAGE_SIZE,\n        }\n        if hashed_pass:\n            query['_hashed_pass'] = hashed_pass\n        try:\n            videos = self._download_json(\n                'https://api.vimeo.com/albums/%s/videos' % album_id,\n                album_id, 'Downloading page %d' % api_page, query=query, headers={\n                    'Authorization': 'jwt ' + authorization,\n                })['data']\n        except ExtractorError as e:\n            if isinstance(e.cause, HTTPError) and e.cause.status == 400:\n                return\n        for video in videos:\n            link = video.get('link')\n            if not link:\n                continue\n            uri = video.get('uri')\n            video_id = self._search_regex(r'/videos/(\\d+)', uri, 'video_id', default=None) if uri else None\n            yield self.url_result(link, VimeoIE.ie_key(), video_id)\n\n    def _real_extract(self, url):\n        album_id = self._match_id(url)\n        viewer = self._download_json(\n            'https://vimeo.com/_rv/viewer', album_id, fatal=False)\n        if not viewer:\n            webpage = self._download_webpage(url, album_id)\n            viewer = self._parse_json(self._search_regex(\n                r'bootstrap_data\\s*=\\s*({.+?})</script>',\n                webpage, 'bootstrap data'), album_id)['viewer']\n        jwt = viewer['jwt']\n        album = self._download_json(\n            'https://api.vimeo.com/albums/' + album_id,\n            album_id, headers={'Authorization': 'jwt ' + jwt},\n            query={'fields': 'description,name,privacy'})\n        hashed_pass = None\n        if try_get(album, lambda x: x['privacy']['view']) == 'password':\n            password = self.get_param('videopassword')\n            if not password:\n                raise ExtractorError(\n                    'This album is protected by a password, use the --video-password option',\n                    expected=True)\n            self._set_vimeo_cookie('vuid', viewer['vuid'])\n            try:\n                hashed_pass = self._download_json(\n                    'https://vimeo.com/showcase/%s/auth' % album_id,\n                    album_id, 'Verifying the password', data=urlencode_postdata({\n                        'password': password,\n                        'token': viewer['xsrft'],\n                    }), headers={\n                        'X-Requested-With': 'XMLHttpRequest',\n                    })['hashed_pass']\n            except ExtractorError as e:\n                if isinstance(e.cause, HTTPError) and e.cause.status == 401:\n                    raise ExtractorError('Wrong password', expected=True)\n                raise\n        entries = OnDemandPagedList(functools.partial(\n            self._fetch_page, album_id, jwt, hashed_pass), self._PAGE_SIZE)\n        return self.playlist_result(\n            entries, album_id, album.get('name'), album.get('description'))\n\n\nclass VimeoGroupsIE(VimeoChannelIE):  # XXX: Do not subclass from concrete IE\n    IE_NAME = 'vimeo:group'\n    _VALID_URL = r'https://vimeo\\.com/groups/(?P<id>[^/]+)(?:/(?!videos?/\\d+)|$)'\n    _TESTS = [{\n        'url': 'https://vimeo.com/groups/meetup',\n        'info_dict': {\n            'id': 'meetup',\n            'title': 'Vimeo Meetup!',\n        },\n        'playlist_mincount': 27,\n    }]\n    _BASE_URL_TEMPL = 'https://vimeo.com/groups/%s'\n\n\nclass VimeoReviewIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vimeo:review'\n    IE_DESC = 'Review pages on vimeo'\n    _VALID_URL = r'(?P<url>https://vimeo\\.com/[^/]+/review/(?P<id>[^/]+)/[0-9a-f]{10})'\n    _TESTS = [{\n        'url': 'https://vimeo.com/user21297594/review/75524534/3c257a1b5d',\n        'md5': 'c507a72f780cacc12b2248bb4006d253',\n        'info_dict': {\n            'id': '75524534',\n            'ext': 'mp4',\n            'title': \"DICK HARDWICK 'Comedian'\",\n            'uploader': 'Richard Hardwick',\n            'uploader_id': 'user21297594',\n            'description': \"Comedian Dick Hardwick's five minute demo filmed in front of a live theater audience.\\nEdit by Doug Mattocks\",\n            'duration': 304,\n            'thumbnail': 'https://i.vimeocdn.com/video/450115033-43303819d9ebe24c2630352e18b7056d25197d09b3ae901abdac4c4f1d68de71-d_1280',\n            'uploader_url': 'https://vimeo.com/user21297594',\n        },\n    }, {\n        'note': 'video player needs Referer',\n        'url': 'https://vimeo.com/user22258446/review/91613211/13f927e053',\n        'md5': '6295fdab8f4bf6a002d058b2c6dce276',\n        'info_dict': {\n            'id': '91613211',\n            'ext': 'mp4',\n            'title': 're:(?i)^Death by dogma versus assembling agile . Sander Hoogendoorn',\n            'uploader': 'DevWeek Events',\n            'duration': 2773,\n            'thumbnail': r're:^https?://.*\\.jpg$',\n            'uploader_id': 'user22258446',\n        },\n        'skip': 'video gone',\n    }, {\n        'note': 'Password protected',\n        'url': 'https://vimeo.com/user37284429/review/138823582/c4d865efde',\n        'info_dict': {\n            'id': '138823582',\n            'ext': 'mp4',\n            'title': 'EFFICIENT PICKUP MASTERCLASS MODULE 1',\n            'uploader': 'TMB',\n            'uploader_id': 'user37284429',\n        },\n        'params': {\n            'videopassword': 'holygrail',\n        },\n        'skip': 'video gone',\n    }]\n\n    def _real_extract(self, url):\n        page_url, video_id = self._match_valid_url(url).groups()\n        data = self._download_json(\n            page_url.replace('/review/', '/review/data/'), video_id)\n        if data.get('isLocked') is True:\n            video_password = self._get_video_password()\n            viewer = self._download_json(\n                'https://vimeo.com/_rv/viewer', video_id)\n            webpage = self._verify_video_password(\n                'https://vimeo.com/' + video_id, video_id,\n                video_password, viewer['xsrft'], viewer['vuid'])\n            clip_page_config = self._parse_json(self._search_regex(\n                r'window\\.vimeo\\.clip_page_config\\s*=\\s*({.+?});',\n                webpage, 'clip page config'), video_id)\n            config_url = clip_page_config['player']['config_url']\n            clip_data = clip_page_config.get('clip') or {}\n        else:\n            clip_data = data['clipData']\n            config_url = clip_data['configUrl']\n        config = self._download_json(config_url, video_id)\n        info_dict = self._parse_config(config, video_id)\n        source_format = self._extract_original_format(\n            page_url + '/action', video_id)\n        if source_format:\n            info_dict['formats'].append(source_format)\n        info_dict['description'] = clean_html(clip_data.get('description'))\n        return info_dict\n\n\nclass VimeoWatchLaterIE(VimeoChannelIE):  # XXX: Do not subclass from concrete IE\n    IE_NAME = 'vimeo:watchlater'\n    IE_DESC = 'Vimeo watch later list, \":vimeowatchlater\" keyword (requires authentication)'\n    _VALID_URL = r'https://vimeo\\.com/(?:home/)?watchlater|:vimeowatchlater'\n    _TITLE = 'Watch Later'\n    _LOGIN_REQUIRED = True\n    _TESTS = [{\n        'url': 'https://vimeo.com/watchlater',\n        'only_matching': True,\n    }]\n\n    def _page_url(self, base_url, pagenum):\n        url = '%s/page:%d/' % (base_url, pagenum)\n        request = Request(url)\n        # Set the header to get a partial html page with the ids,\n        # the normal page doesn't contain them.\n        request.headers['X-Requested-With'] = 'XMLHttpRequest'\n        return request\n\n    def _real_extract(self, url):\n        return self._extract_videos('watchlater', 'https://vimeo.com/watchlater')\n\n\nclass VimeoLikesIE(VimeoChannelIE):  # XXX: Do not subclass from concrete IE\n    _VALID_URL = r'https://(?:www\\.)?vimeo\\.com/(?P<id>[^/]+)/likes/?(?:$|[?#]|sort:)'\n    IE_NAME = 'vimeo:likes'\n    IE_DESC = 'Vimeo user likes'\n    _TESTS = [{\n        'url': 'https://vimeo.com/user755559/likes/',\n        'playlist_mincount': 293,\n        'info_dict': {\n            'id': 'user755559',\n            'title': 'urza\u2019s Likes',\n        },\n    }, {\n        'url': 'https://vimeo.com/stormlapse/likes',\n        'only_matching': True,\n    }]\n\n    def _page_url(self, base_url, pagenum):\n        return '%s/page:%d/' % (base_url, pagenum)\n\n    def _real_extract(self, url):\n        user_id = self._match_id(url)\n        return self._extract_videos(user_id, 'https://vimeo.com/%s/likes' % user_id)\n\n\nclass VHXEmbedIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vhx:embed'\n    _VALID_URL = r'https?://embed\\.vhx\\.tv/videos/(?P<id>\\d+)'\n    _EMBED_REGEX = [r'<iframe[^>]+src=\"(?P<url>https?://embed\\.vhx\\.tv/videos/\\d+[^\"]*)\"']\n\n    @classmethod\n    def _extract_embed_urls(cls, url, webpage):\n        for embed_url in super()._extract_embed_urls(url, webpage):\n            yield cls._smuggle_referrer(embed_url, url)\n\n    def _real_extract(self, url):\n        video_id = self._match_id(url)\n        url, _, headers = self._unsmuggle_headers(url)\n        webpage = self._download_webpage(url, video_id, headers=headers)\n        config_url = self._parse_json(self._search_regex(\n            r'window\\.OTTData\\s*=\\s*({.+})', webpage,\n            'ott data'), video_id, js_to_json)['config_url']\n        config = self._download_json(config_url, video_id)\n        info = self._parse_config(config, video_id)\n        info['id'] = video_id\n        return info\n\n\nclass VimeoProIE(VimeoBaseInfoExtractor):\n    IE_NAME = 'vimeo:pro'\n    _VALID_URL = r'https?://(?:www\\.)?vimeopro\\.com/[^/?#]+/(?P<slug>[^/?#]+)(?:(?:/videos?/(?P<id>[0-9]+)))?'\n    _TESTS = [{\n        # Vimeo URL derived from video_id\n        'url': 'http://vimeopro.com/openstreetmapus/state-of-the-map-us-2013/video/68093876',\n        'md5': '3b5ca6aa22b60dfeeadf50b72e44ed82',\n        'note': 'Vimeo Pro video (#1197)',\n        'info_dict': {\n            'id': '68093876',\n            'ext': 'mp4',\n            'uploader_url': r're:https?://(?:www\\.)?vimeo\\.com/openstreetmapus',\n            'uploader_id': 'openstreetmapus',\n            'uploader': 'OpenStreetMap US',\n            'title': 'Andy Allan - Putting the Carto into OpenStreetMap Cartography',\n            'description': 'md5:2c362968038d4499f4d79f88458590c1',\n            'duration': 1595,\n            'upload_date': '20130610',\n            'timestamp': 1370893156,\n            'license': 'by',\n            'thumbnail': 'https://i.vimeocdn.com/video/440260469-19b0d92fca3bd84066623b53f1eb8aaa3980c6c809e2d67b6b39ab7b4a77a344-d_960',\n            'view_count': int,\n            'comment_count': int,\n            'like_count': int,\n            'tags': 'count:1',\n        },\n        'params': {\n            'format': 'best[protocol=https]',\n        },\n    }, {\n        # password-protected VimeoPro page with Vimeo player embed\n        'url': 'https://vimeopro.com/cadfem/simulation-conference-mechanische-systeme-in-perfektion',\n        'info_dict': {\n            'id': '764543723',\n            'ext': 'mp4',\n            'title': 'Mechanische Systeme in Perfektion: Realit\u00e4t erfassen, Innovation treiben',\n            'thumbnail': 'https://i.vimeocdn.com/video/1543784598-a1a750494a485e601110136b9fe11e28c2131942452b3a5d30391cb3800ca8fd-d_1280',\n            'description': 'md5:2a9d195cd1b0f6f79827107dc88c2420',\n            'uploader': 'CADFEM',\n            'uploader_id': 'cadfem',\n            'uploader_url': 'https://vimeo.com/cadfem',\n            'duration': 12505,\n            'chapters': 'count:10',\n        },\n        'params': {\n            'videopassword': 'Conference2022',\n            'skip_download': True,\n        },\n    }]\n\n    def _real_extract(self, url):\n        display_id, video_id = self._match_valid_url(url).group('slug', 'id')\n        if video_id:\n            display_id = video_id\n        webpage = self._download_webpage(url, display_id)\n\n        password_form = self._search_regex(\n            r'(?is)<form[^>]+?method=[\"\\']post[\"\\'][^>]*>(.+?password.+?)</form>',\n            webpage, 'password form', default=None)\n        if password_form:\n            try:\n                webpage = self._download_webpage(url, display_id, data=urlencode_postdata({\n                    'password': self._get_video_password(),\n                    **self._hidden_inputs(password_form),\n                }), note='Logging in with video password')\n            except ExtractorError as e:\n                if isinstance(e.cause, HTTPError) and e.cause.status == 418:\n                    raise ExtractorError('Wrong video password', expected=True)\n                raise\n\n        description = None\n        # even if we have video_id, some videos require player URL with portfolio_id query param\n        # https://github.com/ytdl-org/youtube-dl/issues/20070\n        vimeo_url = VimeoIE._extract_url(url, webpage)\n        if vimeo_url:\n            description = self._html_search_meta('description', webpage, default=None)\n        elif video_id:\n            vimeo_url = f'https://vimeo.com/{video_id}'\n        else:\n            raise ExtractorError(\n                'No Vimeo embed or video ID could be found in VimeoPro page', expected=True)\n\n        return self.url_result(vimeo_url, VimeoIE, video_id, url_transparent=True,\n                               description=description)\n", "import collections\nimport random\nimport urllib.parse\nimport urllib.request\n\nfrom ._utils import remove_start\n\n\ndef random_user_agent():\n    _USER_AGENT_TPL = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/%s Safari/537.36'\n    _CHROME_VERSIONS = (\n        '90.0.4430.212',\n        '90.0.4430.24',\n        '90.0.4430.70',\n        '90.0.4430.72',\n        '90.0.4430.85',\n        '90.0.4430.93',\n        '91.0.4472.101',\n        '91.0.4472.106',\n        '91.0.4472.114',\n        '91.0.4472.124',\n        '91.0.4472.164',\n        '91.0.4472.19',\n        '91.0.4472.77',\n        '92.0.4515.107',\n        '92.0.4515.115',\n        '92.0.4515.131',\n        '92.0.4515.159',\n        '92.0.4515.43',\n        '93.0.4556.0',\n        '93.0.4577.15',\n        '93.0.4577.63',\n        '93.0.4577.82',\n        '94.0.4606.41',\n        '94.0.4606.54',\n        '94.0.4606.61',\n        '94.0.4606.71',\n        '94.0.4606.81',\n        '94.0.4606.85',\n        '95.0.4638.17',\n        '95.0.4638.50',\n        '95.0.4638.54',\n        '95.0.4638.69',\n        '95.0.4638.74',\n        '96.0.4664.18',\n        '96.0.4664.45',\n        '96.0.4664.55',\n        '96.0.4664.93',\n        '97.0.4692.20',\n    )\n    return _USER_AGENT_TPL % random.choice(_CHROME_VERSIONS)\n\n\nclass HTTPHeaderDict(collections.UserDict, dict):\n    \"\"\"\n    Store and access keys case-insensitively.\n    The constructor can take multiple dicts, in which keys in the latter are prioritised.\n    \"\"\"\n\n    def __init__(self, *args, **kwargs):\n        super().__init__()\n        for dct in args:\n            if dct is not None:\n                self.update(dct)\n        self.update(kwargs)\n\n    def __setitem__(self, key, value):\n        if isinstance(value, bytes):\n            value = value.decode('latin-1')\n        super().__setitem__(key.title(), str(value))\n\n    def __getitem__(self, key):\n        return super().__getitem__(key.title())\n\n    def __delitem__(self, key):\n        super().__delitem__(key.title())\n\n    def __contains__(self, key):\n        return super().__contains__(key.title() if isinstance(key, str) else key)\n\n\nstd_headers = HTTPHeaderDict({\n    'User-Agent': random_user_agent(),\n    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n    'Accept-Language': 'en-us,en;q=0.5',\n    'Sec-Fetch-Mode': 'navigate',\n})\n\n\ndef clean_proxies(proxies: dict, headers: HTTPHeaderDict):\n    req_proxy = headers.pop('Ytdl-Request-Proxy', None)\n    if req_proxy:\n        proxies.clear()  # XXX: compat: Ytdl-Request-Proxy takes preference over everything, including NO_PROXY\n        proxies['all'] = req_proxy\n    for proxy_key, proxy_url in proxies.items():\n        if proxy_url == '__noproxy__':\n            proxies[proxy_key] = None\n            continue\n        if proxy_key == 'no':  # special case\n            continue\n        if proxy_url is not None:\n            # Ensure proxies without a scheme are http.\n            try:\n                proxy_scheme = urllib.request._parse_proxy(proxy_url)[0]\n            except ValueError:\n                # Ignore invalid proxy URLs. Sometimes these may be introduced through environment\n                # variables unrelated to proxy settings - e.g. Colab `COLAB_LANGUAGE_SERVER_PROXY`.\n                # If the proxy is going to be used, the Request Handler proxy validation will handle it.\n                continue\n            if proxy_scheme is None:\n                proxies[proxy_key] = 'http://' + remove_start(proxy_url, '//')\n\n            replace_scheme = {\n                'socks5': 'socks5h',  # compat: socks5 was treated as socks5h\n                'socks': 'socks4'  # compat: non-standard\n            }\n            if proxy_scheme in replace_scheme:\n                proxies[proxy_key] = urllib.parse.urlunparse(\n                    urllib.parse.urlparse(proxy_url)._replace(scheme=replace_scheme[proxy_scheme]))\n\n\ndef clean_headers(headers: HTTPHeaderDict):\n    if 'Youtubedl-No-Compression' in headers:  # compat\n        del headers['Youtubedl-No-Compression']\n        headers['Accept-Encoding'] = 'identity'\n    headers.pop('Ytdl-socks-proxy', None)\n\n\ndef remove_dot_segments(path):\n    # Implements RFC3986 5.2.4 remote_dot_segments\n    # Pseudo-code: https://tools.ietf.org/html/rfc3986#section-5.2.4\n    # https://github.com/urllib3/urllib3/blob/ba49f5c4e19e6bca6827282feb77a3c9f937e64b/src/urllib3/util/url.py#L263\n    output = []\n    segments = path.split('/')\n    for s in segments:\n        if s == '.':\n            continue\n        elif s == '..':\n            if output:\n                output.pop()\n        else:\n            output.append(s)\n    if not segments[0] and (not output or output[0]):\n        output.insert(0, '')\n    if segments[-1] in ('.', '..'):\n        output.append('')\n    return '/'.join(output)\n\n\ndef escape_rfc3986(s):\n    \"\"\"Escape non-ASCII characters as suggested by RFC 3986\"\"\"\n    return urllib.parse.quote(s, b\"%/;:@&=+$,!~*'()?#[]\")\n\n\ndef normalize_url(url):\n    \"\"\"Normalize URL as suggested by RFC 3986\"\"\"\n    url_parsed = urllib.parse.urlparse(url)\n    return url_parsed._replace(\n        netloc=url_parsed.netloc.encode('idna').decode('ascii'),\n        path=escape_rfc3986(remove_dot_segments(url_parsed.path)),\n        params=escape_rfc3986(url_parsed.params),\n        query=escape_rfc3986(url_parsed.query),\n        fragment=escape_rfc3986(url_parsed.fragment)\n    ).geturl()\n"], "filenames": ["test/test_networking.py", "yt_dlp/extractor/cybrary.py", "yt_dlp/extractor/duboku.py", "yt_dlp/extractor/embedly.py", "yt_dlp/extractor/generic.py", "yt_dlp/extractor/slideslive.py", "yt_dlp/extractor/storyfire.py", "yt_dlp/extractor/vimeo.py", "yt_dlp/utils/networking.py"], "buggy_code_start_loc": [1295, 108, 141, 109, 19, 533, 35, 40, 125], "buggy_code_end_loc": [1295, 109, 142, 110, 2714, 534, 38, 48, 125], "fixing_code_start_loc": [1296, 108, 141, 109, 20, 533, 35, 40, 126], "fixing_code_end_loc": [1300, 109, 142, 110, 2715, 534, 36, 48, 127], "type": "CWE-444", "message": "yt-dlp is a youtube-dl fork with additional features and fixes. The Generic Extractor in yt-dlp is vulnerable to an attacker setting an arbitrary proxy for a request to an arbitrary url, allowing the attacker to MITM the request made from yt-dlp's HTTP session. This could lead to cookie exfiltration in some cases. Version 2023.11.14 removed the ability to smuggle `http_headers` to the Generic extractor, as well as other extractors that use the same pattern. Users are advised to upgrade. Users unable to upgrade should disable the Ggneric extractor (or only pass trusted sites with trusted content) and ake caution when using `--no-check-certificate`.", "other": {"cve": {"id": "CVE-2023-46121", "sourceIdentifier": "security-advisories@github.com", "published": "2023-11-15T00:15:09.470", "lastModified": "2023-11-22T15:05:37.027", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "yt-dlp is a youtube-dl fork with additional features and fixes. The Generic Extractor in yt-dlp is vulnerable to an attacker setting an arbitrary proxy for a request to an arbitrary url, allowing the attacker to MITM the request made from yt-dlp's HTTP session. This could lead to cookie exfiltration in some cases. Version 2023.11.14 removed the ability to smuggle `http_headers` to the Generic extractor, as well as other extractors that use the same pattern. Users are advised to upgrade. Users unable to upgrade should disable the Ggneric extractor (or only pass trusted sites with trusted content) and ake caution when using `--no-check-certificate`."}, {"lang": "es", "value": "yt-dlp es una bifurcaci\u00f3n de youtube-dl con funciones y correcciones adicionales. The Generic Extractor en yt-dlp es vulnerable a que un atacante configure un proxy arbitrario para una solicitud en una URL arbitraria, lo que le permite al atacante realizar MITM la solicitud realizada desde la sesi\u00f3n HTTP de yt-dlp. En algunos casos, esto podr\u00eda provocar la exfiltraci\u00f3n de cookies. La versi\u00f3n 2023.11.14 elimin\u00f3 la capacidad de pasar de contrabando `http_headers` al extractor gen\u00e9rico, as\u00ed como a otros extractores que usan el mismo patr\u00f3n. Se recomienda a los usuarios que actualicen. Los usuarios que no puedan actualizar deben desactivar el extractor Ggneric (o solo pasar por sitios confiables con contenido confiable) y tener cuidado al usar `--no-check-certificate`."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:L/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 3.7, "baseSeverity": "LOW"}, "exploitabilityScore": 2.2, "impactScore": 1.4}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:U/C:L/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 5.0, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.6, "impactScore": 3.4}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-444"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:yt-dlp_project:yt-dlp:*:*:*:*:*:*:*:*", "versionStartIncluding": "2022.10.04", "versionEndExcluding": "2023.11.14", "matchCriteriaId": "3FC3CE4C-A093-449A-BB70-CFB7A7FD1EF0"}]}]}], "references": [{"url": "https://github.com/yt-dlp/yt-dlp/commit/f04b5bedad7b281bee9814686bba1762bae092eb", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/yt-dlp/yt-dlp/releases/tag/2023.11.14", "source": "security-advisories@github.com", "tags": ["Release Notes"]}, {"url": "https://github.com/yt-dlp/yt-dlp/security/advisories/GHSA-3ch3-jhc6-5r8x", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/yt-dlp/yt-dlp/commit/f04b5bedad7b281bee9814686bba1762bae092eb"}}
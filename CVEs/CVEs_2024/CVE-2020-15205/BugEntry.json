{"buggy_code": ["/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <locale>\n#include <string>\n\n#include \"absl/strings/ascii.h\"\n#include \"absl/strings/str_cat.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nnamespace tensorflow {\nnamespace text {\n\nnamespace {\ntemplate <typename SPLITS_TYPE>\nclass StringNGramsOp : public tensorflow::OpKernel {\n public:\n  explicit StringNGramsOp(tensorflow::OpKernelConstruction* context)\n      : tensorflow::OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"separator\", &separator_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"ngram_widths\", &ngram_widths_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"left_pad\", &left_pad_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"right_pad\", &right_pad_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"pad_width\", &pad_width_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"preserve_short_sequences\",\n                                             &preserve_short_));\n  }\n\n  int get_pad_width(const int ngram_width) const {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'pad_width' arg, but in no case should the padding\n    // ever be wider than 'ngram_width' - 1.\n    return std::min(pad_width_ < 0 ? ngram_width - 1 : pad_width_,\n                    ngram_width - 1);\n  }\n\n  int get_num_ngrams(const int length, const int ngram_width) const {\n    int pad_width = get_pad_width(ngram_width);\n    return std::max(0, ((length + 2 * pad_width) - ngram_width) + 1);\n  }\n\n  void Compute(tensorflow::OpKernelContext* context) override {\n    const tensorflow::Tensor* data;\n    OP_REQUIRES_OK(context, context->input(\"data\", &data));\n    const auto& input_data = data->flat<tstring>().data();\n\n    const tensorflow::Tensor* splits;\n    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n    const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n\n    int num_batch_items = splits_vec.size() - 1;\n    tensorflow::Tensor* ngrams_splits;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(1, splits->shape(), &ngrams_splits));\n    auto ngrams_splits_data = ngrams_splits->flat<SPLITS_TYPE>().data();\n\n    // If there is no data or size, return an empty RT.\n    if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {\n      tensorflow::Tensor* empty;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, data->shape(), &empty));\n      for (int i = 0; i <= num_batch_items; ++i) {\n        ngrams_splits_data[i] = 0;\n      }\n      return;\n    }\n\n    ngrams_splits_data[0] = 0;\n    for (int i = 1; i <= num_batch_items; ++i) {\n      int length = splits_vec(i) - splits_vec(i - 1);\n      int num_ngrams = 0;\n      for (int ngram_width : ngram_widths_)\n        num_ngrams += get_num_ngrams(length, ngram_width);\n      if (preserve_short_ && length > 0 && num_ngrams == 0) {\n        num_ngrams = 1;\n      }\n      ngrams_splits_data[i] = ngrams_splits_data[i - 1] + num_ngrams;\n    }\n\n    tensorflow::Tensor* ngrams;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({ngrams_splits_data[num_batch_items]}), &ngrams));\n    auto ngrams_data = ngrams->flat<tstring>().data();\n\n    for (int i = 0; i < num_batch_items; ++i) {\n      auto data_start = &input_data[splits_vec(i)];\n      int output_start_idx = ngrams_splits_data[i];\n      for (int ngram_width : ngram_widths_) {\n        auto output_start = &ngrams_data[output_start_idx];\n        int length = splits_vec(i + 1) - splits_vec(i);\n        int num_ngrams = get_num_ngrams(length, ngram_width);\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n        output_start_idx += num_ngrams;\n      }\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (ngram_splits_data). If no ngrams were generated, then they will\n      // be equal (since we increment output_start_idx by num_ngrams every\n      // time we create a set of ngrams.)\n      if (preserve_short_ && output_start_idx == ngrams_splits_data[i]) {\n        int data_length = splits_vec(i + 1) - splits_vec(i);\n        // One legitimate reason to not have any ngrams when preserve_short_\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (data_length == 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one ngram.\n        int ngram_width = data_length + 2 * pad_width_;\n        auto output_start = &ngrams_data[output_start_idx];\n        int num_ngrams = 1;\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n      }\n    }\n  }\n\n  void CreateNgrams(const tstring* data, tstring* output, int num_ngrams,\n                    int ngram_width) const {\n    for (int ngram_index = 0; ngram_index < num_ngrams; ++ngram_index) {\n      int pad_width = get_pad_width(ngram_width);\n      int left_padding = std::max(0, pad_width - ngram_index);\n      int right_padding =\n          std::max(0, pad_width - (num_ngrams - (ngram_index + 1)));\n      int num_tokens = ngram_width - (left_padding + right_padding);\n      int data_start_index = left_padding > 0 ? 0 : ngram_index - pad_width;\n\n      // Calculate the total expected size of the ngram so we can reserve the\n      // correct amount of space in the string.\n      int ngram_size = 0;\n      // Size of the left padding.\n      ngram_size += left_padding * left_pad_.length();\n      // Size of the tokens.\n      for (int n = 0; n < num_tokens; ++n) {\n        ngram_size += data[data_start_index + n].length();\n      }\n      // Size of the right padding.\n      ngram_size += right_padding * right_pad_.length();\n      // Size of the separators.\n      int num_separators = left_padding + right_padding + num_tokens - 1;\n      ngram_size += num_separators * separator_.length();\n\n      // Build the ngram.\n      tstring* ngram = &output[ngram_index];\n      ngram->reserve(ngram_size);\n      for (int n = 0; n < left_padding; ++n) {\n        ngram->append(left_pad_);\n        ngram->append(separator_);\n      }\n      for (int n = 0; n < num_tokens - 1; ++n) {\n        ngram->append(data[data_start_index + n]);\n        ngram->append(separator_);\n      }\n      ngram->append(data[data_start_index + num_tokens - 1]);\n      for (int n = 0; n < right_padding; ++n) {\n        ngram->append(separator_);\n        ngram->append(right_pad_);\n      }\n\n      // In debug mode only: validate that we've reserved enough space for the\n      // ngram.\n      DCHECK_EQ(ngram_size, ngram->size());\n    }\n  }\n\n  string separator_;\n  string left_pad_;\n  string right_pad_;\n  bool use_pad_;\n  bool extend_pad_;\n  bool preserve_short_;\n\n  std::vector<int> ngram_widths_;\n  int pad_width_;\n};\n\n}  // namespace\nREGISTER_KERNEL_BUILDER(Name(\"StringNGrams\")\n                            .Device(tensorflow::DEVICE_CPU)\n                            .TypeConstraint<int32>(\"Tsplits\"),\n                        StringNGramsOp<int32>);\nREGISTER_KERNEL_BUILDER(Name(\"StringNGrams\")\n                            .Device(tensorflow::DEVICE_CPU)\n                            .TypeConstraint<int64>(\"Tsplits\"),\n                        StringNGramsOp<int64>);\n\n}  // namespace text\n}  // namespace tensorflow\n", "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Raw ops tests.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import gen_math_ops\nfrom tensorflow.python.platform import test\n\n\n@test_util.run_all_in_graph_and_eager_modes\nclass RawOpsTest(test.TestCase):\n\n  def testSimple(self):\n    x = constant_op.constant(1)\n    self.assertEqual([2], self.evaluate(gen_math_ops.Add(x=x, y=x)))\n\n  def testRequiresKwargs(self):\n    with self.assertRaisesRegex(TypeError, \"only takes keyword args\"):\n      gen_math_ops.Add(1., 1.)\n\n  def testRequiresKwargs_providesSuggestion(self):\n    msg = \"possible keys: \\\\['x', 'y', 'name'\\\\]\"\n    with self.assertRaisesRegex(TypeError, msg):\n      gen_math_ops.Add(1., y=2.)\n\n  def testName(self):\n    x = constant_op.constant(1)\n    op = gen_math_ops.Add(x=x, y=x, name=\"double\")\n    if not context.executing_eagerly():\n      # `Tensor.name` is not available in eager.\n      self.assertEqual(op.name, \"double:0\")\n\n  def testDoc(self):\n    self.assertEqual(gen_math_ops.add.__doc__, gen_math_ops.Add.__doc__)\n\n  def testDefaults(self):\n    x = constant_op.constant([[True]])\n    self.assertAllClose(\n        gen_math_ops.Any(input=x, axis=0),\n        gen_math_ops.Any(input=x, axis=0, keep_dims=False))\n\n\nif __name__ == \"__main__\":\n  ops.enable_eager_execution()\n  test.main()\n"], "fixing_code": ["/* Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include <locale>\n#include <string>\n\n#include \"absl/strings/ascii.h\"\n#include \"absl/strings/str_cat.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/platform/errors.h\"\n\nnamespace tensorflow {\nnamespace text {\n\nnamespace {\ntemplate <typename SPLITS_TYPE>\nclass StringNGramsOp : public tensorflow::OpKernel {\n public:\n  explicit StringNGramsOp(tensorflow::OpKernelConstruction* context)\n      : tensorflow::OpKernel(context) {\n    OP_REQUIRES_OK(context, context->GetAttr(\"separator\", &separator_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"ngram_widths\", &ngram_widths_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"left_pad\", &left_pad_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"right_pad\", &right_pad_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"pad_width\", &pad_width_));\n    OP_REQUIRES_OK(context, context->GetAttr(\"preserve_short_sequences\",\n                                             &preserve_short_));\n  }\n\n  int get_pad_width(const int ngram_width) const {\n    // Ngrams can be padded with either a fixed pad width or a dynamic pad\n    // width depending on the 'pad_width' arg, but in no case should the padding\n    // ever be wider than 'ngram_width' - 1.\n    return std::min(pad_width_ < 0 ? ngram_width - 1 : pad_width_,\n                    ngram_width - 1);\n  }\n\n  int get_num_ngrams(const int length, const int ngram_width) const {\n    int pad_width = get_pad_width(ngram_width);\n    return std::max(0, ((length + 2 * pad_width) - ngram_width) + 1);\n  }\n\n  void Compute(tensorflow::OpKernelContext* context) override {\n    const tensorflow::Tensor* data;\n    OP_REQUIRES_OK(context, context->input(\"data\", &data));\n    const auto& input_data = data->flat<tstring>().data();\n\n    const tensorflow::Tensor* splits;\n    OP_REQUIRES_OK(context, context->input(\"data_splits\", &splits));\n    const auto& splits_vec = splits->flat<SPLITS_TYPE>();\n\n    // Validate that the splits are valid indices into data\n    const int input_data_size = data->flat<tstring>().size();\n    const int splits_vec_size = splits_vec.size();\n    for (int i = 0; i < splits_vec_size; ++i) {\n      bool valid_splits = splits_vec(i) >= 0;\n      valid_splits = valid_splits && (splits_vec(i) <= input_data_size);\n      OP_REQUIRES(\n          context, valid_splits,\n          errors::InvalidArgument(\"Invalid split value \", splits_vec(i),\n                                  \", must be in [0,\", input_data_size, \"]\"));\n    }\n\n    int num_batch_items = splits_vec.size() - 1;\n    tensorflow::Tensor* ngrams_splits;\n    OP_REQUIRES_OK(\n        context, context->allocate_output(1, splits->shape(), &ngrams_splits));\n    auto ngrams_splits_data = ngrams_splits->flat<SPLITS_TYPE>().data();\n\n    // If there is no data or size, return an empty RT.\n    if (data->flat<tstring>().size() == 0 || splits_vec.size() == 0) {\n      tensorflow::Tensor* empty;\n      OP_REQUIRES_OK(context,\n                     context->allocate_output(0, data->shape(), &empty));\n      for (int i = 0; i <= num_batch_items; ++i) {\n        ngrams_splits_data[i] = 0;\n      }\n      return;\n    }\n\n    ngrams_splits_data[0] = 0;\n    for (int i = 1; i <= num_batch_items; ++i) {\n      int length = splits_vec(i) - splits_vec(i - 1);\n      int num_ngrams = 0;\n      for (int ngram_width : ngram_widths_)\n        num_ngrams += get_num_ngrams(length, ngram_width);\n      if (preserve_short_ && length > 0 && num_ngrams == 0) {\n        num_ngrams = 1;\n      }\n      ngrams_splits_data[i] = ngrams_splits_data[i - 1] + num_ngrams;\n    }\n\n    tensorflow::Tensor* ngrams;\n    OP_REQUIRES_OK(\n        context,\n        context->allocate_output(\n            0, TensorShape({ngrams_splits_data[num_batch_items]}), &ngrams));\n    auto ngrams_data = ngrams->flat<tstring>().data();\n\n    for (int i = 0; i < num_batch_items; ++i) {\n      auto data_start = &input_data[splits_vec(i)];\n      int output_start_idx = ngrams_splits_data[i];\n      for (int ngram_width : ngram_widths_) {\n        auto output_start = &ngrams_data[output_start_idx];\n        int length = splits_vec(i + 1) - splits_vec(i);\n        int num_ngrams = get_num_ngrams(length, ngram_width);\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n        output_start_idx += num_ngrams;\n      }\n      // If we're preserving short sequences, check to see if no sequence was\n      // generated by comparing the current output start idx to the original\n      // one (ngram_splits_data). If no ngrams were generated, then they will\n      // be equal (since we increment output_start_idx by num_ngrams every\n      // time we create a set of ngrams.)\n      if (preserve_short_ && output_start_idx == ngrams_splits_data[i]) {\n        int data_length = splits_vec(i + 1) - splits_vec(i);\n        // One legitimate reason to not have any ngrams when preserve_short_\n        // is true is if the sequence itself is empty. In that case, move on.\n        if (data_length == 0) {\n          continue;\n        }\n        // We don't have to worry about dynamic padding sizes here: if padding\n        // was dynamic, every sequence would have had sufficient padding to\n        // generate at least one ngram.\n        int ngram_width = data_length + 2 * pad_width_;\n        auto output_start = &ngrams_data[output_start_idx];\n        int num_ngrams = 1;\n        CreateNgrams(data_start, output_start, num_ngrams, ngram_width);\n      }\n    }\n  }\n\n  void CreateNgrams(const tstring* data, tstring* output, int num_ngrams,\n                    int ngram_width) const {\n    for (int ngram_index = 0; ngram_index < num_ngrams; ++ngram_index) {\n      int pad_width = get_pad_width(ngram_width);\n      int left_padding = std::max(0, pad_width - ngram_index);\n      int right_padding =\n          std::max(0, pad_width - (num_ngrams - (ngram_index + 1)));\n      int num_tokens = ngram_width - (left_padding + right_padding);\n      int data_start_index = left_padding > 0 ? 0 : ngram_index - pad_width;\n\n      // Calculate the total expected size of the ngram so we can reserve the\n      // correct amount of space in the string.\n      int ngram_size = 0;\n      // Size of the left padding.\n      ngram_size += left_padding * left_pad_.length();\n      // Size of the tokens.\n      for (int n = 0; n < num_tokens; ++n) {\n        ngram_size += data[data_start_index + n].length();\n      }\n      // Size of the right padding.\n      ngram_size += right_padding * right_pad_.length();\n      // Size of the separators.\n      int num_separators = left_padding + right_padding + num_tokens - 1;\n      ngram_size += num_separators * separator_.length();\n\n      // Build the ngram.\n      tstring* ngram = &output[ngram_index];\n      ngram->reserve(ngram_size);\n      for (int n = 0; n < left_padding; ++n) {\n        ngram->append(left_pad_);\n        ngram->append(separator_);\n      }\n      for (int n = 0; n < num_tokens - 1; ++n) {\n        ngram->append(data[data_start_index + n]);\n        ngram->append(separator_);\n      }\n      ngram->append(data[data_start_index + num_tokens - 1]);\n      for (int n = 0; n < right_padding; ++n) {\n        ngram->append(separator_);\n        ngram->append(right_pad_);\n      }\n\n      // In debug mode only: validate that we've reserved enough space for the\n      // ngram.\n      DCHECK_EQ(ngram_size, ngram->size());\n    }\n  }\n\n  string separator_;\n  string left_pad_;\n  string right_pad_;\n  bool use_pad_;\n  bool extend_pad_;\n  bool preserve_short_;\n\n  std::vector<int> ngram_widths_;\n  int pad_width_;\n};\n\n}  // namespace\nREGISTER_KERNEL_BUILDER(Name(\"StringNGrams\")\n                            .Device(tensorflow::DEVICE_CPU)\n                            .TypeConstraint<int32>(\"Tsplits\"),\n                        StringNGramsOp<int32>);\nREGISTER_KERNEL_BUILDER(Name(\"StringNGrams\")\n                            .Device(tensorflow::DEVICE_CPU)\n                            .TypeConstraint<int64>(\"Tsplits\"),\n                        StringNGramsOp<int64>);\n\n}  // namespace text\n}  // namespace tensorflow\n", "# Copyright 2019 The TensorFlow Authors. All Rights Reserved.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# ==============================================================================\n\"\"\"Raw ops tests.\"\"\"\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nfrom absl.testing import parameterized\n\nfrom tensorflow.python.eager import context\nfrom tensorflow.python.framework import constant_op\nfrom tensorflow.python.framework import errors\nfrom tensorflow.python.framework import ops\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.ops import gen_math_ops\nfrom tensorflow.python.ops import gen_string_ops\nfrom tensorflow.python.platform import test\n\n\n@test_util.run_all_in_graph_and_eager_modes\n@test_util.disable_tfrt\nclass RawOpsTest(test.TestCase, parameterized.TestCase):\n\n  def testSimple(self):\n    x = constant_op.constant(1)\n    self.assertEqual([2], self.evaluate(gen_math_ops.Add(x=x, y=x)))\n\n  def testRequiresKwargs(self):\n    with self.assertRaisesRegex(TypeError, \"only takes keyword args\"):\n      gen_math_ops.Add(1., 1.)\n\n  def testRequiresKwargs_providesSuggestion(self):\n    msg = \"possible keys: \\\\['x', 'y', 'name'\\\\]\"\n    with self.assertRaisesRegex(TypeError, msg):\n      gen_math_ops.Add(1., y=2.)\n\n  def testName(self):\n    x = constant_op.constant(1)\n    op = gen_math_ops.Add(x=x, y=x, name=\"double\")\n    if not context.executing_eagerly():\n      # `Tensor.name` is not available in eager.\n      self.assertEqual(op.name, \"double:0\")\n\n  def testDoc(self):\n    self.assertEqual(gen_math_ops.add.__doc__, gen_math_ops.Add.__doc__)\n\n  def testDefaults(self):\n    x = constant_op.constant([[True]])\n    self.assertAllClose(\n        gen_math_ops.Any(input=x, axis=0),\n        gen_math_ops.Any(input=x, axis=0, keep_dims=False))\n\n  @parameterized.parameters([[0, 8]], [[-1, 6]])\n  def testStringNGramsBadDataSplits(self, splits):\n    data = [\"aa\", \"bb\", \"cc\", \"dd\", \"ee\", \"ff\"]\n    with self.assertRaisesRegex(errors.InvalidArgumentError,\n                                \"Invalid split value\"):\n      self.evaluate(\n          gen_string_ops.string_n_grams(\n              data=data,\n              data_splits=splits,\n              separator=\"\",\n              ngram_widths=[2],\n              left_pad=\"\",\n              right_pad=\"\",\n              pad_width=0,\n              preserve_short_sequences=False))\n\n\nif __name__ == \"__main__\":\n  ops.enable_eager_execution()\n  test.main()\n"], "filenames": ["tensorflow/core/kernels/string_ngrams_op.cc", "tensorflow/python/ops/raw_ops_test.py"], "buggy_code_start_loc": [21, 20], "buggy_code_end_loc": [61, 60], "fixing_code_start_loc": [22, 21], "fixing_code_end_loc": [75, 82], "type": "CWE-787", "message": "In Tensorflow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1, the `data_splits` argument of `tf.raw_ops.StringNGrams` lacks validation. This allows a user to pass values that can cause heap overflow errors and even leak contents of memory In the linked code snippet, all the binary strings after `ee ff` are contents from the memory stack. Since these can contain return addresses, this data leak can be used to defeat ASLR. The issue is patched in commit 0462de5b544ed4731aa2fb23946ac22c01856b80, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1.", "other": {"cve": {"id": "CVE-2020-15205", "sourceIdentifier": "security-advisories@github.com", "published": "2020-09-25T19:15:15.823", "lastModified": "2021-11-18T17:27:14.957", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In Tensorflow before versions 1.15.4, 2.0.3, 2.1.2, 2.2.1 and 2.3.1, the `data_splits` argument of `tf.raw_ops.StringNGrams` lacks validation. This allows a user to pass values that can cause heap overflow errors and even leak contents of memory In the linked code snippet, all the binary strings after `ee ff` are contents from the memory stack. Since these can contain return addresses, this data leak can be used to defeat ASLR. The issue is patched in commit 0462de5b544ed4731aa2fb23946ac22c01856b80, and is released in TensorFlow versions 1.15.4, 2.0.3, 2.1.2, 2.2.1, or 2.3.1."}, {"lang": "es", "value": "En Tensorflow versiones anteriores a 1.15.4, 2.0.3, 2.1.2, 2.2.1 y 2.3.1, el argumento \"data_splits\" de \"tf.raw_ops.StringNGrams\" carece de comprobaci\u00f3n.&#xa0;Esto permite a un usuario pasar valores que pueden causar errores de desbordamiento de la pila e incluso filtrar el contenido de la memoria. En el fragmento de c\u00f3digo vinculado, todas las cadenas binarias despu\u00e9s de \"ee ff\" son contenidos desde la pila de memoria.&#xa0;Dado que estos pueden contener direcciones de retorno, este filtrado de datos se puede utilizar para anular ASLR.&#xa0;El problema es parcheado en el commit 0462de5b544ed4731aa2fb23946ac22c01856b80 y es publicado en TensorFlow versiones 1.15.4, 2.0.3, 2.1.2, 2.2.1 o 2.3.1"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.0, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 2.2, "impactScore": 6.0}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-119"}, {"lang": "en", "value": "CWE-122"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:-:*:*:*", "versionEndExcluding": "1.15.4", "matchCriteriaId": "EC688B44-17B7-462D-B6E3-BAAF99334782"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:-:*:*:*", "versionStartIncluding": "2.0.0", "versionEndExcluding": "2.0.3", "matchCriteriaId": "B6271763-8DFA-4A8F-9596-F1148961ECC5"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:-:*:*:*", "versionStartIncluding": "2.1.0", "versionEndExcluding": "2.1.2", "matchCriteriaId": "AA3FD62B-13CB-4EB5-939F-C848DE9AE071"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:-:*:*:*", "versionStartIncluding": "2.2.0", "versionEndExcluding": "2.2.1", "matchCriteriaId": "029CB8A9-ED3D-486D-967C-4CE0AF8D8FAD"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:-:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.1", "matchCriteriaId": "B617650A-B5A1-44BB-BB3A-2EF83648B100"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.2:*:*:*:*:*:*:*", "matchCriteriaId": "B009C22E-30A4-4288-BCF6-C3E81DEAF45A"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2020-10/msg00065.html", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/0462de5b544ed4731aa2fb23946ac22c01856b80", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/releases/tag/v2.3.1", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-g7p5-5759-qv46", "source": "security-advisories@github.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/0462de5b544ed4731aa2fb23946ac22c01856b80"}}
{"buggy_code": ["/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/platform/file_system_helper.h\"\n\n#include <deque>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/platform/cpu_info.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/file_system.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/core/platform/path.h\"\n#include \"tensorflow/core/platform/platform.h\"\n#include \"tensorflow/core/platform/status.h\"\n#include \"tensorflow/core/platform/str_util.h\"\n#include \"tensorflow/core/platform/threadpool.h\"\n\nnamespace tensorflow {\nnamespace internal {\n\nnamespace {\n\nconst int kNumThreads = port::NumSchedulableCPUs();\n\n// Run a function in parallel using a ThreadPool, but skip the ThreadPool\n// on the iOS platform due to its problems with more than a few threads.\nvoid ForEach(int first, int last, const std::function<void(int)>& f) {\n#if TARGET_OS_IPHONE\n  for (int i = first; i < last; i++) {\n    f(i);\n  }\n#else\n  int num_threads = std::min(kNumThreads, last - first);\n  thread::ThreadPool threads(Env::Default(), \"ForEach\", num_threads);\n  for (int i = first; i < last; i++) {\n    threads.Schedule([f, i] { f(i); });\n  }\n#endif\n}\n\n}  // namespace\n\nStatus GetMatchingPaths(FileSystem* fs, Env* env, const string& pattern,\n                        std::vector<string>* results) {\n  results->clear();\n  if (pattern.empty()) {\n    return Status::OK();\n  }\n\n  string fixed_prefix = pattern.substr(0, pattern.find_first_of(\"*?[\\\\\"));\n  string eval_pattern = pattern;\n  string dir(io::Dirname(fixed_prefix));\n  // If dir is empty then we need to fix up fixed_prefix and eval_pattern to\n  // include . as the top level directory.\n  if (dir.empty()) {\n    dir = \".\";\n    fixed_prefix = io::JoinPath(dir, fixed_prefix);\n    eval_pattern = io::JoinPath(dir, eval_pattern);\n  }\n  bool is_directory = pattern[pattern.size() - 1] == '/';\n#ifdef PLATFORM_WINDOWS\n  is_directory = is_directory || pattern[pattern.size() - 1] == '\\\\';\n#endif\n  std::vector<string> dirs;\n  if (!is_directory) {\n    dirs.emplace_back(eval_pattern);\n  }\n  StringPiece tmp_dir(io::Dirname(eval_pattern));\n  while (tmp_dir.size() > dir.size()) {\n    dirs.emplace_back(string(tmp_dir));\n    tmp_dir = io::Dirname(tmp_dir);\n  }\n  dirs.emplace_back(dir);\n  std::reverse(dirs.begin(), dirs.end());\n  // Setup a parallel BFS to explore everything under dir.\n  std::deque<std::pair<string, int>> dir_q;\n  std::deque<std::pair<string, int>> next_dir_q;\n  dir_q.emplace_back(std::make_pair(dirs[0], 0));\n  Status ret;  // Status to return.\n  mutex results_mutex;\n  condition_variable results_cond;\n  mutex next_que_mutex;\n  condition_variable next_que_cond;\n  while (!dir_q.empty()) {\n    next_dir_q.clear();\n    std::vector<Status> new_rets(dir_q.size());\n    auto handle_level = [fs, &results, &dir_q, &next_dir_q, &new_rets,\n                         &is_directory, &dirs, &results_mutex, &results_cond,\n                         &next_que_mutex, &next_que_cond](int i) {\n      string current_dir = dir_q.at(i).first;\n      int dir_index = dir_q.at(i).second;\n      dir_index++;\n      std::vector<string> children;\n      Status s = fs->GetChildren(current_dir, &children);\n      // In case PERMISSION_DENIED is encountered, we bail here.\n      if (s.code() == tensorflow::error::PERMISSION_DENIED) {\n        return;\n      }\n      new_rets[i] = s;\n      if (children.empty()) return;\n\n      // children_dir_status holds is_dir status for children. It can have three\n      // possible values: OK for true; FAILED_PRECONDITION for false; CANCELLED\n      // if we don't calculate IsDirectory (we might do that because there isn't\n      // any point in exploring that child path).\n      std::vector<Status> children_dir_status;\n\n      // This IsDirectory call can be expensive for some FS. Parallelizing it.\n      children_dir_status.resize(children.size());\n      auto handle_children = [fs, &current_dir, &children, &dirs, dir_index,\n                              is_directory, &children_dir_status](int j) {\n        const string child_path = io::JoinPath(current_dir, children[j]);\n        if (!fs->Match(child_path, dirs[dir_index])) {\n          children_dir_status[j] =\n              Status(tensorflow::error::CANCELLED, \"Operation not needed\");\n        } else if (dir_index != dirs.size() - 1) {\n          children_dir_status[j] = fs->IsDirectory(child_path);\n        } else {\n          children_dir_status[j] =\n              is_directory ? fs->IsDirectory(child_path) : Status::OK();\n        }\n      };\n      ForEach(0, children.size(), handle_children);\n\n      for (size_t j = 0; j < children.size(); ++j) {\n        const string child_path = io::JoinPath(current_dir, children[j]);\n        // If the IsDirectory call was cancelled we bail.\n        if (children_dir_status[j].code() == tensorflow::error::CANCELLED) {\n          continue;\n        }\n        if (children_dir_status[j].ok()) {\n          if (dir_index != dirs.size() - 1) {\n            mutex_lock lk(next_que_mutex);\n            next_dir_q.emplace_back(std::make_pair(child_path, dir_index));\n            next_que_cond.notify_one();\n          } else {\n            mutex_lock lk(results_mutex);\n            results->emplace_back(child_path);\n            results_cond.notify_one();\n          }\n        }\n      }\n    };\n    ForEach(0, dir_q.size(), handle_level);\n\n    ret.Update(new_rets[dir_q.size() - 1]);\n    std::swap(dir_q, next_dir_q);\n  }\n  return ret;\n}\n\n}  // namespace internal\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/platform/file_system_helper.h\"\n\n#include <deque>\n#include <string>\n#include <vector>\n\n#include \"tensorflow/core/platform/cpu_info.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/file_system.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/core/platform/path.h\"\n#include \"tensorflow/core/platform/platform.h\"\n#include \"tensorflow/core/platform/status.h\"\n#include \"tensorflow/core/platform/str_util.h\"\n#include \"tensorflow/core/platform/threadpool.h\"\n\nnamespace tensorflow {\nnamespace internal {\n\nnamespace {\n\nconst int kNumThreads = port::NumSchedulableCPUs();\n\n// Run a function in parallel using a ThreadPool, but skip the ThreadPool\n// on the iOS platform due to its problems with more than a few threads.\nvoid ForEach(int first, int last, const std::function<void(int)>& f) {\n#if TARGET_OS_IPHONE\n  for (int i = first; i < last; i++) {\n    f(i);\n  }\n#else\n  int num_threads = std::min(kNumThreads, last - first);\n  thread::ThreadPool threads(Env::Default(), \"ForEach\", num_threads);\n  for (int i = first; i < last; i++) {\n    threads.Schedule([f, i] { f(i); });\n  }\n#endif\n}\n\n// A globbing pattern can only start with these characters:\nstatic const char kGlobbingChars[] = \"*?[\\\\\";\n\nstatic inline bool IsGlobbingPattern(const std::string& pattern) {\n  return (pattern.find_first_of(kGlobbingChars) != std::string::npos);\n}\n\n// Make sure that the first entry in `dirs` during glob expansion does not\n// contain a glob pattern. This is to prevent a corner-case bug where\n// `<pattern>` would be treated differently than `./<pattern>`.\nstatic std::string PatchPattern(const std::string& pattern) {\n  const std::string fixed_prefix =\n      pattern.substr(0, pattern.find_first_of(kGlobbingChars));\n\n  // Patching is needed when there is no directory part in `prefix`\n  if (io::Dirname(fixed_prefix).empty()) {\n    return io::JoinPath(\".\", pattern);\n  }\n\n  // No patching needed\n  return pattern;\n}\n\nstatic std::vector<std::string> AllDirectoryPrefixes(const std::string& d) {\n  std::vector<std::string> dirs;\n  const std::string patched = PatchPattern(d);\n  StringPiece dir(patched);\n\n  // If the pattern ends with a `/` (or `\\\\` on Windows), we need to strip it\n  // otherwise we would have one additional matching step and the result set\n  // would be empty.\n  bool is_directory = d[d.size() - 1] == '/';\n#ifdef PLATFORM_WINDOWS\n  is_directory = is_directory || (d[d.size() - 1] == '\\\\');\n#endif\n  if (is_directory) {\n    dir = io::Dirname(dir);\n  }\n\n  while (!dir.empty()) {\n    dirs.emplace_back(dir);\n    StringPiece new_dir(io::Dirname(dir));\n    // io::Dirname(\"/\") returns \"/\" so we need to break the loop.\n    // On Windows, io::Dirname(\"C:\\\\\") would return \"C:\\\\\", so we check for\n    // identity of the result instead of checking for dir[0] == `/`.\n    if (dir == new_dir) break;\n    dir = new_dir;\n  }\n\n  // Order the array from parent to ancestor (reverse order).\n  std::reverse(dirs.begin(), dirs.end());\n\n  return dirs;\n}\n\nstatic inline int GetFirstGlobbingEntry(const std::vector<std::string>& dirs) {\n  int i = 0;\n  for (const auto& d : dirs) {\n    if (IsGlobbingPattern(d)) {\n      break;\n    }\n    i++;\n  }\n  return i;\n}\n\n}  // namespace\n\nStatus GetMatchingPaths(FileSystem* fs, Env* env, const string& pattern,\n                        std::vector<string>* results) {\n  // Check that `fs`, `env` and `results` are non-null.\n  if (fs == nullptr || env == nullptr || results == nullptr) {\n    return Status(tensorflow::error::INVALID_ARGUMENT,\n                  \"Filesystem calls GetMatchingPaths with nullptr arguments\");\n  }\n\n  // By design, we don't match anything on empty pattern\n  results->clear();\n  if (pattern.empty()) {\n    return Status::OK();\n  }\n\n  // The pattern can contain globbing characters at multiple levels, e.g.:\n  //\n  //   foo/ba?/baz/f*r\n  //\n  // To match the full pattern, we must match every prefix subpattern and then\n  // operate on the children for each match. Thus, we separate all subpatterns\n  // in the `dirs` vector below.\n  std::vector<std::string> dirs = AllDirectoryPrefixes(pattern);\n\n  // We can have patterns that have several parents where no globbing is being\n  // done, for example, `foo/bar/baz/*`. We don't need to expand the directories\n  // which don't contain the globbing characters.\n  int matching_index = GetFirstGlobbingEntry(dirs);\n\n  // If we don't have globbing characters in the pattern then it specifies a\n  // path in the filesystem. We add it to the result set if it exists.\n  if (matching_index == dirs.size()) {\n    if (fs->FileExists(pattern).ok()) {\n      results->emplace_back(pattern);\n    }\n    return Status::OK();\n  }\n\n  // To expand the globbing, we do a BFS from `dirs[matching_index-1]`.\n  // At every step, we work on a pair `{dir, ix}` such that `dir` is a real\n  // directory, `ix < dirs.size() - 1` and `dirs[ix+1]` is a globbing pattern.\n  // To expand the pattern, we select from all the children of `dir` only those\n  // that match against `dirs[ix+1]`.\n  // If there are more entries in `dirs` after `dirs[ix+1]` this mean we have\n  // more patterns to match. So, we add to the queue only those children that\n  // are also directories, paired with `ix+1`.\n  // If there are no more entries in `dirs`, we return all children as part of\n  // the answer.\n  // Since we can get into a combinatorial explosion issue (e.g., pattern\n  // `/*/*/*`), we process the queue in parallel. Each parallel processing takes\n  // elements from `expand_queue` and adds them to `next_expand_queue`, after\n  // which we swap these two queues (similar to double buffering algorithms).\n  // PRECONDITION: `IsGlobbingPattern(dirs[0]) == false`\n  // PRECONDITION: `matching_index > 0`\n  // INVARIANT: If `{d, ix}` is in queue, then `d` and `dirs[ix]` are at the\n  //            same level in the filesystem tree.\n  // INVARIANT: If `{d, _}` is in queue, then `IsGlobbingPattern(d) == false`.\n  // INVARIANT: If `{d, _}` is in queue, then `d` is a real directory.\n  // INVARIANT: If `{_, ix}` is in queue, then `ix < dirs.size() - 1`.\n  // INVARIANT: If `{_, ix}` is in queue, `IsGlobbingPattern(dirs[ix + 1])`.\n  std::deque<std::pair<string, int>> expand_queue;\n  std::deque<std::pair<string, int>> next_expand_queue;\n  expand_queue.emplace_back(dirs[matching_index - 1], matching_index - 1);\n\n  // Adding to `result` or `new_expand_queue` need to be protected by mutexes\n  // since there are multiple threads writing to these.\n  mutex result_mutex;\n  mutex queue_mutex;\n\n  while (!expand_queue.empty()) {\n    next_expand_queue.clear();\n\n    // The work item for every item in `expand_queue`.\n    // pattern, we process them in parallel.\n    auto handle_level = [&fs, &results, &dirs, &expand_queue,\n                         &next_expand_queue, &result_mutex,\n                         &queue_mutex](int i) {\n      // See invariants above, all of these are valid accesses.\n      const auto& queue_item = expand_queue.at(i);\n      const std::string& parent = queue_item.first;\n      const int index = queue_item.second + 1;\n      const std::string& match_pattern = dirs[index];\n\n      // Get all children of `parent`. If this fails, return early.\n      std::vector<std::string> children;\n      Status s = fs->GetChildren(parent, &children);\n      if (s.code() == tensorflow::error::PERMISSION_DENIED) {\n        return;\n      }\n\n      // Also return early if we don't have any children\n      if (children.empty()) {\n        return;\n      }\n\n      // Since we can get extremely many children here and on some filesystems\n      // `IsDirectory` is expensive, we process the children in parallel.\n      // We also check that children match the pattern in parallel, for speedup.\n      // We store the status of the match and `IsDirectory` in\n      // `children_status` array, one element for each children.\n      std::vector<Status> children_status(children.size());\n      auto handle_children = [&fs, &match_pattern, &parent, &children,\n                              &children_status](int j) {\n        const std::string path = io::JoinPath(parent, children[j]);\n        if (!fs->Match(path, match_pattern)) {\n          children_status[j] =\n              Status(tensorflow::error::CANCELLED, \"Operation not needed\");\n        } else {\n          children_status[j] = fs->IsDirectory(path);\n        }\n      };\n      ForEach(0, children.size(), handle_children);\n\n      // At this point, pairing `children` with `children_status` will tell us\n      // if a children:\n      //   * does not match the pattern\n      //   * matches the pattern and is a directory\n      //   * matches the pattern and is not a directory\n      // We fully ignore the first case.\n      // If we matched the last pattern (`index == dirs.size() - 1`) then all\n      // remaining children get added to the result.\n      // Otherwise, only the directories get added to the next queue.\n      for (size_t j = 0; j < children.size(); j++) {\n        if (children_status[j].code() == tensorflow::error::CANCELLED) {\n          continue;\n        }\n\n        const std::string path = io::JoinPath(parent, children[j]);\n        if (index == dirs.size() - 1) {\n          mutex_lock l(result_mutex);\n          results->emplace_back(path);\n        } else if (children_status[j].ok()) {\n          mutex_lock l(queue_mutex);\n          next_expand_queue.emplace_back(path, index);\n        }\n      }\n    };\n    ForEach(0, expand_queue.size(), handle_level);\n\n    // After evaluating one level, swap the \"buffers\"\n    std::swap(expand_queue, next_expand_queue);\n  }\n\n  return Status::OK();\n}\n\n}  // namespace internal\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/platform/file_system_helper.cc"], "buggy_code_start_loc": [54], "buggy_code_end_loc": [164], "fixing_code_start_loc": [55], "fixing_code_end_loc": [266], "type": "CWE-125", "message": "In TensorFlow release candidate versions 2.4.0rc*, the general implementation for matching filesystem paths to globbing pattern is vulnerable to an access out of bounds of the array holding the directories. There are multiple invariants and preconditions that are assumed by the parallel implementation of GetMatchingPaths but are not verified by the PRs introducing it (#40861 and #44310). Thus, we are completely rewriting the implementation to fully specify and validate these. This is patched in version 2.4.0. This issue only impacts master branch and the release candidates for TF version 2.4. The final release of the 2.4 release will be patched.", "other": {"cve": {"id": "CVE-2020-26269", "sourceIdentifier": "security-advisories@github.com", "published": "2020-12-10T23:15:12.910", "lastModified": "2021-08-17T13:21:49.300", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In TensorFlow release candidate versions 2.4.0rc*, the general implementation for matching filesystem paths to globbing pattern is vulnerable to an access out of bounds of the array holding the directories. There are multiple invariants and preconditions that are assumed by the parallel implementation of GetMatchingPaths but are not verified by the PRs introducing it (#40861 and #44310). Thus, we are completely rewriting the implementation to fully specify and validate these. This is patched in version 2.4.0. This issue only impacts master branch and the release candidates for TF version 2.4. The final release of the 2.4 release will be patched."}, {"lang": "es", "value": "En las versiones candidatas a lanzamiento de TensorFlow 2.4.0rc*, la implementaci\u00f3n general para hacer coincidir las rutas del sistema de archivos con el patr\u00f3n globbing es vulnerable a un acceso fuera de l\u00edmites de la matriz que contiene los directorios.&#xa0;Existen m\u00faltiples invariantes y condiciones previas que son asumidas por la implementaci\u00f3n paralela de GetMatchingPaths pero no son verificadas por los RP que lo presentan (#40861 y #44310).&#xa0;Por lo tanto, estamos reescribiendo completamente la implementaci\u00f3n para especificarlos y validarlos completamente.&#xa0;Esto est\u00e1 parcheado en la versi\u00f3n 2.4.0.&#xa0;Este problema solo afecta a la rama maestra y a los candidatas de lanzamiento para TF versi\u00f3n 2.4.&#xa0;La versi\u00f3n final de la versi\u00f3n 2.4 ser\u00e1 parcheada."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.4.0:rc0:*:*:*:*:*:*", "matchCriteriaId": "282DEFCC-C624-4BE0-B3D8-0E36A64910A2"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.4.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "6C14D966-92B3-47A6-B2D3-7A296FE60840"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.4.0:rc2:*:*:*:*:*:*", "matchCriteriaId": "72C6C072-43AA-434C-9D5B-3ED310170DA4"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.4.0:rc3:*:*:*:*:*:*", "matchCriteriaId": "5F9D2583-48BB-4AE5-803C-4A9BEBE9B000"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.4.0:rc4:*:*:*:*:*:*", "matchCriteriaId": "77D52D6F-1833-4C9C-9AE2-C9D500E20AAC"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/8b5b9dc96666a3a5d27fad7179ff215e3b74b67c", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-9jjw-hf72-3mxw", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/8b5b9dc96666a3a5d27fad7179ff215e3b74b67c"}}
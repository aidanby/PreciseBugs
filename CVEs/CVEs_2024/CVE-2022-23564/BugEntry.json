{"buggy_code": ["load(\n    \"//tensorflow/core/platform:build_config.bzl\",\n    \"tf_kernel_tests_linkstatic\",\n    \"tf_proto_library\",\n    \"tf_pyclif_proto_library\",\n)\nload(\n    \"//tensorflow:tensorflow.bzl\",\n    \"tf_cc_test\",\n    \"tf_cc_tests\",\n    \"tf_copts\",\n    \"tf_cuda_library\",\n)\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"filegroup\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_cuda_cc_test\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_generate_proto_text_sources\")\n\n# buildifier: disable=same-origin-load\nload(\n    \"//tensorflow/core/platform:build_config_root.bzl\",\n    \"if_static\",\n    \"tf_cuda_tests_tags\",\n)\nload(\n    \"//tensorflow/core/platform:rules_cc.bzl\",\n    \"cc_library\",\n)\n\npackage(\n    default_visibility = [\n        \"//tensorflow/core:__subpackages__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n    licenses = [\"notice\"],\n)\n\n# Export all header files for which we do not yet provide a dedicated build\n# rule. This avoids breaking all the rules in tensorflow/core/BUILD.\nexports_files(\n    srcs = [\n        \"allocator_registry.h\",\n        \"cancellation.h\",\n        \"collective.h\",\n        \"control_flow.h\",\n        \"dataset.h\",\n        \"dataset_stateful_op_allowlist.h\",\n        \"device.h\",\n        \"device_base.h\",\n        \"device_factory.h\",\n        \"function.h\",\n        \"function_handle_cache.h\",\n        \"graph_def_util.h\",\n        \"graph_to_functiondef.h\",\n        \"kernel_def_builder.h\",\n        \"kernel_def_util.h\",\n        \"logging.h\",\n        \"lookup_interface.h\",\n        \"memory_types.h\",\n        \"metrics.h\",\n        \"model.h\",\n        \"node_def_builder.h\",\n        \"numeric_op.h\",\n        \"op_kernel.h\",\n        \"op_requires.h\",\n        \"op_segment.h\",\n        \"ops_util.h\",\n        \"partial_tensor_shape.h\",\n        \"queue_interface.h\",\n        \"reader_interface.h\",\n        \"reader_op_kernel.h\",\n        \"register_types_traits.h\",\n        \"rendezvous.h\",\n        \"resource_mgr.h\",\n        \"resource_op_kernel.h\",\n        \"resource_var.h\",\n        \"rng_alg.h\",\n        \"run_handler.h\",\n        \"run_handler_util.h\",\n        \"session_state.h\",\n        \"shared_ptr_variant.h\",\n        \"stats_aggregator.h\",\n        \"tensor_reference.h\",\n        \"tensor_slice.h\",\n        \"tensor_util.h\",\n        \"thread_factory.h\",\n        \"tracking_allocator.h\",\n        \"versions.h\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__pkg__\",\n        \"//tensorflow/core/common_runtime:__pkg__\",\n    ],\n)\n\n# List of exported test source files that do not yet have local build rules.\nexports_files(\n    srcs = [\n        \"op_gen_lib_test.cc\",\n        \"op_segment_test.cc\",\n        \"run_handler_test.cc\",\n        \"run_handler_util_test.cc\",\n        \"variant_op_copy_test.cc\",\n    ],\n    visibility = [\"//tensorflow/core:__pkg__\"],\n)\n\n# List of exported proto source files.\nexports_files(\n    srcs = [\n        \"allocation_description.proto\",\n        \"api_def.proto\",\n        \"attr_value.proto\",\n        \"cost_graph.proto\",\n        \"dataset_metadata.proto\",\n        \"dataset_options.proto\",\n        \"device_attributes.proto\",\n        \"full_type.proto\",\n        \"function.proto\",\n        \"graph.proto\",\n        \"graph_transfer_info.proto\",\n        \"kernel_def.proto\",\n        \"log_memory.proto\",\n        \"model.proto\",\n        \"node_def.proto\",\n        \"op_def.proto\",\n        \"reader_base.proto\",\n        \"resource_handle.proto\",\n        \"step_stats.proto\",\n        \"summary.proto\",\n        \"tensor.proto\",\n        \"tensor_description.proto\",\n        \"tensor_shape.proto\",\n        \"tensor_slice.proto\",\n        \"types.proto\",\n        \"variable.proto\",\n        \"versions.proto\",\n    ],\n    visibility = [\n        \"//tensorflow:internal\",\n        \"//tensorflow/core:__pkg__\",\n    ],\n)\n\nexports_files(\n    [\n        \"attr_value_util.h\",\n        \"common_shape_fns.h\",\n        \"kernel_shape_util.h\",\n        \"node_def_util.h\",\n        \"node_properties.h\",\n        \"op.h\",\n        \"op_def_builder.h\",\n        \"full_type_util.h\",\n        \"full_type_inference_util.h\",\n        \"op_def_util.h\",\n        \"shape_inference.h\",\n    ],\n    visibility = [\"//tensorflow/core:__subpackages__\"],\n)\n\n# The following filegroups are needed since globbing across packages boundaries\n# will just fail silently (see 3rd caveat at\n# https://docs.bazel.build/versions/master/be/functions.html#glob).\n\n# Files needed for core:framework_internal_impl.\nfilegroup(\n    name = \"framework_internal_private_hdrs\",\n    srcs = [\n        \"allocator.h\",\n        \"allocator_registry.h\",\n        \"attr_value_util.h\",\n        \"bfloat16.h\",\n        \"bounds_check.h\",\n        \"cancellation.h\",\n        \"collective.h\",\n        \"common_shape_fns.h\",\n        \"control_flow.h\",\n        \"dataset.h\",\n        \"dataset_stateful_op_allowlist.h\",\n        \"device.h\",\n        \"device_base.h\",\n        \"device_factory.h\",\n        \"full_type_inference_util.h\",\n        \"full_type_util.h\",\n        \"function.h\",\n        \"function_handle_cache.h\",\n        \"graph_def_util.h\",\n        \"graph_to_functiondef.h\",\n        \"kernel_def_builder.h\",\n        \"kernel_def_util.h\",\n        \"kernel_shape_util.h\",\n        \"local_rendezvous.h\",\n        \"log_memory.h\",\n        \"logging.h\",\n        \"lookup_interface.h\",\n        \"memory_types.h\",\n        \"metrics.h\",\n        \"model.h\",\n        \"node_def_builder.h\",\n        \"node_def_util.h\",\n        \"node_properties.h\",\n        \"numeric_op.h\",\n        \"numeric_types.h\",\n        \"op.h\",\n        \"op_def_builder.h\",\n        \"op_def_util.h\",\n        \"op_kernel.h\",\n        \"op_requires.h\",\n        \"op_segment.h\",\n        \"ops_util.h\",\n        \"partial_tensor_shape.h\",\n        \"queue_interface.h\",\n        \"reader_interface.h\",\n        \"reader_op_kernel.h\",\n        \"register_types.h\",\n        \"register_types_traits.h\",\n        \"rendezvous.h\",\n        \"resource_base.h\",\n        \"resource_handle.h\",\n        \"resource_mgr.h\",\n        \"resource_op_kernel.h\",\n        \"resource_var.h\",\n        \"run_handler.h\",\n        \"run_handler_util.h\",\n        \"session_state.h\",\n        \"shape_inference.h\",\n        \"shared_ptr_variant.h\",\n        \"stats_aggregator.h\",\n        \"tensor.h\",\n        \"tensor_key.h\",\n        \"tensor_reference.h\",\n        \"tensor_shape.h\",\n        \"tensor_slice.h\",\n        \"tensor_types.h\",\n        \"tensor_util.h\",\n        \"thread_factory.h\",\n        \"tracking_allocator.h\",\n        \"type_index.h\",\n        \"type_traits.h\",\n        \"typed_allocator.h\",\n        \"types.h\",\n        \"variant.h\",\n        \"variant_encode_decode.h\",\n        \"variant_op_registry.h\",\n        \"variant_tensor_data.h\",\n        \"versions.h\",\n        \"//tensorflow/core/framework/registration:options.h\",\n        \"//tensorflow/core/framework/registration:registration.h\",\n    ],\n)\n\nfilegroup(\n    name = \"framework_internal_impl_srcs\",\n    srcs = [\n        \"cancellation.cc\",\n        \"collective.cc\",\n        \"dataset.cc\",\n        \"device.cc\",\n        \"device_base.cc\",\n        \"device_factory.cc\",\n        \"function.cc\",\n        \"function_handle_cache.cc\",\n        \"graph_def_util.cc\",\n        \"graph_to_functiondef.cc\",\n        \"kernel_def_builder.cc\",\n        \"kernel_def_util.cc\",\n        \"load_library.cc\",\n        \"local_rendezvous.cc\",\n        \"logging.cc\",\n        \"lookup_interface.cc\",\n        \"memory_types.cc\",\n        \"metrics.cc\",\n        \"model.cc\",\n        \"node_def_builder.cc\",\n        \"op_kernel.cc\",\n        \"op_segment.cc\",\n        \"ops_util.cc\",\n        \"rendezvous.cc\",\n        \"resource_mgr.cc\",\n        \"resource_var.cc\",\n        \"run_handler.cc\",\n        \"run_handler_util.cc\",\n        \"tensor_slice.cc\",\n        \"tensor_util.cc\",\n        \"versions.cc\",\n    ],\n)\n\n# Files needed for core:mobile_srcs_(no|only)_runtime.\nfilegroup(\n    name = \"mobile_srcs_no_runtime\",\n    srcs = [\n        \"allocator.cc\",\n        \"allocator.h\",\n        \"allocator_registry.cc\",\n        \"allocator_registry.h\",\n        \"bfloat16.cc\",\n        \"bfloat16.h\",\n        \"bounds_check.h\",\n        \"cpu_allocator_impl.cc\",\n        \"kernel_shape_util.cc\",\n        \"kernel_shape_util.h\",\n        \"log_memory.cc\",\n        \"log_memory.h\",\n        \"numeric_types.h\",\n        \"op_requires.h\",\n        \"ops_util.cc\",\n        \"ops_util.h\",\n        \"register_types.h\",\n        \"resource_base.h\",\n        \"resource_handle.cc\",\n        \"resource_handle.h\",\n        \"tensor.cc\",\n        \"tensor.h\",\n        \"tensor_key.h\",\n        \"tensor_shape.cc\",\n        \"tensor_shape.h\",\n        \"tensor_types.h\",\n        \"tracking_allocator.cc\",\n        \"tracking_allocator.h\",\n        \"type_index.h\",\n        \"type_traits.h\",\n        \"typed_allocator.cc\",\n        \"typed_allocator.h\",\n        \"types.cc\",\n        \"types.h\",\n        \"variant.cc\",\n        \"variant.h\",\n        \"variant_encode_decode.h\",\n        \"variant_op_registry.cc\",\n        \"variant_op_registry.h\",\n        \"variant_tensor_data.cc\",\n        \"variant_tensor_data.h\",\n    ],\n)\n\nfilegroup(\n    name = \"mobile_srcs_only_runtime\",\n    srcs = [\n        \"attr_value_util.cc\",\n        \"attr_value_util.h\",\n        \"cancellation.cc\",\n        \"cancellation.h\",\n        \"collective.cc\",\n        \"collective.h\",\n        \"common_shape_fns.cc\",\n        \"common_shape_fns.h\",\n        \"control_flow.h\",\n        \"dataset.cc\",\n        \"dataset.h\",\n        \"dataset_stateful_op_allowlist.h\",\n        \"device.cc\",\n        \"device.h\",\n        \"device_base.cc\",\n        \"device_base.h\",\n        \"device_factory.cc\",\n        \"device_factory.h\",\n        \"full_type_inference_util.cc\",\n        \"full_type_inference_util.h\",\n        \"full_type_util.cc\",\n        \"full_type_util.h\",\n        \"function.cc\",\n        \"function.h\",\n        \"function_handle_cache.cc\",\n        \"function_handle_cache.h\",\n        \"graph_def_util.cc\",\n        \"graph_def_util.h\",\n        \"graph_to_functiondef.cc\",\n        \"graph_to_functiondef.h\",\n        \"kernel_def_builder.cc\",\n        \"kernel_def_builder.h\",\n        \"kernel_def_util.cc\",\n        \"kernel_def_util.h\",\n        \"load_library.cc\",\n        \"local_rendezvous.cc\",\n        \"local_rendezvous.h\",\n        \"logging.cc\",\n        \"logging.h\",\n        \"lookup_interface.cc\",\n        \"lookup_interface.h\",\n        \"memory_types.cc\",\n        \"memory_types.h\",\n        \"metrics.cc\",\n        \"metrics.h\",\n        \"model.cc\",\n        \"model.h\",\n        \"node_def_builder.cc\",\n        \"node_def_builder.h\",\n        \"node_def_util.cc\",\n        \"node_def_util.h\",\n        \"node_properties.cc\",\n        \"node_properties.h\",\n        \"numeric_op.h\",\n        \"op.cc\",\n        \"op.h\",\n        \"op_def_builder.cc\",\n        \"op_def_builder.h\",\n        \"op_def_util.cc\",\n        \"op_def_util.h\",\n        \"op_kernel.cc\",\n        \"op_kernel.h\",\n        \"op_segment.cc\",\n        \"op_segment.h\",\n        \"partial_tensor_shape.h\",\n        \"queue_interface.h\",\n        \"reader_base.cc\",\n        \"reader_base.h\",\n        \"reader_interface.h\",\n        \"reader_op_kernel.h\",\n        \"register_types_traits.h\",\n        \"rendezvous.cc\",\n        \"rendezvous.h\",\n        \"resource_mgr.cc\",\n        \"resource_mgr.h\",\n        \"resource_op_kernel.h\",\n        \"resource_var.cc\",\n        \"resource_var.h\",\n        \"rng_alg.h\",\n        \"run_handler.cc\",\n        \"run_handler.h\",\n        \"run_handler_util.cc\",\n        \"run_handler_util.h\",\n        \"session_state.h\",\n        \"shape_inference.cc\",\n        \"shape_inference.h\",\n        \"stats_aggregator.h\",\n        \"tensor_reference.h\",\n        \"tensor_slice.cc\",\n        \"tensor_slice.h\",\n        \"tensor_util.cc\",\n        \"tensor_util.h\",\n        \"thread_factory.h\",\n        \"versions.cc\",\n        \"versions.h\",\n        \"//tensorflow/core/framework/registration:options.h\",\n        \"//tensorflow/core/framework/registration:registration.h\",\n    ],\n)\n\nfilegroup(\n    name = \"android_test_hdrs\",\n    srcs = [\n        \"fake_input.h\",\n        \"shape_inference_testutil.h\",\n        \"tensor_testutil.h\",\n    ],\n)\n\nfilegroup(\n    name = \"android_test_srcs\",\n    srcs = [\n        \"fake_input.cc\",\n        \":android_test_srcs_no_core\",\n    ],\n)\n\nfilegroup(\n    name = \"android_test_srcs_no_core\",\n    srcs = [\n        \"shape_inference_testutil.cc\",\n        \"tensor_testutil.cc\",\n    ],\n)\n\n# Individual targets. These should be preferred over tensorflow/core:framework\n# whenever possible.\n\n# This is redundant with the \"tensorflow/core:framework\" target. It's useful for\n# applications that want to depend on a minimal subset of TensorFlow (e.g. XLA).\ncc_library(\n    name = \"allocator\",\n    srcs = [\n        \"allocator.cc\",\n        \"allocator_registry.h\",\n        \"tracking_allocator.cc\",\n        \"tracking_allocator.h\",\n    ],\n    hdrs = [\n        \"allocator.h\",\n    ],\n    features = [\"parse_headers\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":numeric_types\",\n        \":type_traits\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ] + if_static(\n        extra_deps = [\n            \":allocator_registry_impl\",\n            \"//tensorflow/core/lib/gtl:inlined_vector\",\n            \"//tensorflow/core/lib/strings:strcat\",\n            \"//tensorflow/core/lib/strings:stringprintf\",\n            \"//tensorflow/core/platform:env\",\n            \"//tensorflow/core/platform:env_impl\",\n            \"//tensorflow/core/platform:logging\",\n            \"//tensorflow/core/platform:macros\",\n            \"//tensorflow/core/platform:mutex\",\n            \"//tensorflow/core/platform:platform_port\",\n            \"//tensorflow/core/platform:thread_annotations\",\n            \"//tensorflow/core/platform:types\",\n        ],\n        otherwise = [\n            \"//tensorflow/core:lib\",\n        ],\n    ),\n    alwayslink = 1,\n)\n\n# This target will be included in libtensorflow_framework.so via the\n# framework_internal_impl target.\n# All other dependencies on this target need to go through if_static guard,\n# as otherwise duplicate registration in the registry will cause crashes.\ncc_library(\n    name = \"allocator_registry_impl\",\n    srcs = [\n        \"allocator.h\",\n        \"allocator_registry.cc\",\n        \"allocator_registry.h\",\n        \"cpu_allocator_impl.cc\",\n        \"tracking_allocator.h\",\n    ],\n    visibility = [\"//tensorflow/core:__subpackages__\"],\n    deps = [\n        \":numeric_types\",\n        \":type_traits\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/lib/strings:stringprintf\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:mutex\",\n        \"//tensorflow/core/platform:platform_port\",\n        \"//tensorflow/core/platform:thread_annotations\",\n        \"//tensorflow/core/platform:types\",\n        \"//tensorflow/core/profiler/lib:scoped_memory_debug_annotation\",\n        \"//tensorflow/core/profiler/lib:traceme\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"tensor_testutil\",\n    testonly = 1,\n    srcs = [\"tensor_testutil.cc\"],\n    hdrs = [\"tensor_testutil.h\"],\n    copts = tf_copts(),\n    visibility = [\"//tensorflow:internal\"],\n    deps = [\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:test\",\n    ],\n)\n\ncc_library(\n    name = \"shape_inference_testutil\",\n    testonly = 1,\n    srcs = [\"shape_inference_testutil.cc\"],\n    hdrs = [\"shape_inference_testutil.h\"],\n    copts = tf_copts(),\n    visibility = [\"//tensorflow:internal\"],\n    deps = [\n        \":node_def_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n    ],\n)\n\ncc_library(\n    name = \"reader_base\",\n    srcs = [\"reader_base.cc\"],\n    hdrs = [\"reader_base.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":reader_base_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"op_gen_lib\",\n    srcs = [\"op_gen_lib.cc\"],\n    hdrs = [\"op_gen_lib.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":api_def_proto_cc\",\n        \":attr_value_proto_cc\",\n        \":op_def_proto_cc\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core/util/proto:proto_utils\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"fake_input\",\n    testonly = 1,\n    srcs = [\"fake_input.cc\"],\n    hdrs = [\"fake_input.h\"],\n    visibility = [\"//tensorflow:__subpackages__\"],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":op_def_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"function_testlib\",\n    testonly = 1,\n    srcs = [\"function_testlib.cc\"],\n    hdrs = [\"function_testlib.h\"],\n    visibility = [\"//tensorflow/core:__subpackages__\"],\n    deps = [\n        \":function_proto_cc\",\n        \":graph_proto_cc\",\n        \":node_def_proto_cc\",\n        \":tensor_testutil\",\n        \":versions_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"bfloat16\",\n    srcs = [\"bfloat16.cc\"],\n    hdrs = [\"bfloat16.h\"],\n    visibility = [\n        \"//tensorflow/core:__subpackages__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n    deps = [\n        \":numeric_types\",\n        \"//tensorflow/core/platform:byte_order\",\n        \"//tensorflow/core/platform:types\",\n        \"//third_party/eigen3\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"numeric_types\",\n    hdrs = [\"numeric_types.h\"],\n    visibility = [\n        \"//tensorflow/compiler:__subpackages__\",\n        \"//tensorflow/core:__subpackages__\",\n    ],\n    deps = [\n        \"//tensorflow/core/platform:types\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ncc_library(\n    name = \"bounds_check\",\n    hdrs = [\"bounds_check.h\"],\n    visibility = [\"//tensorflow/core/kernels:friends\"],\n    deps = [\n        \"//tensorflow/core/platform:macros\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ncc_library(\n    name = \"tensor_shape\",\n    srcs = [\"tensor_shape.cc\"],\n    hdrs = [\n        \"partial_tensor_shape.h\",\n        \"tensor_shape.h\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__pkg__\",\n        \"//tensorflow/core/runtime_fallback:__subpackages__\",\n        \"//tensorflow/core/tfrt/utils:__subpackages__\",\n    ],\n    deps = [\n        \":bounds_check\",\n        \":tensor_shape_proto_cc\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/util:overflow\",\n        \"//third_party/eigen3\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"resource_base\",\n    hdrs = [\"resource_base.h\"],\n    deps = [\n        \"//tensorflow/core/lib/core:refcount\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/platform:errors\",\n    ],\n)\n\ncc_library(\n    name = \"resource_handle\",\n    srcs = [\"resource_handle.cc\"],\n    hdrs = [\"resource_handle.h\"],\n    visibility = [\n        \"//tensorflow/compiler/mlir/tensorflow:__subpackages__\",\n        \"//tensorflow/core:__pkg__\",\n    ],\n    deps = [\n        \":resource_base\",\n        \":resource_handle_proto_cc\",\n        \":tensor_shape\",\n        \":type_index\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:casts\",\n        \"//tensorflow/core/platform:intrusive_ptr\",\n        \"//tensorflow/core/platform:statusor\",\n        \"//tensorflow/core/platform:tensor_coding\",\n        \"//tensorflow/core/platform:types\",\n        \"//tensorflow/core/util:managed_stack_trace\",\n        \"@com_google_absl//absl/strings:str_format\",\n    ],\n    alwayslink = 1,\n)\n\ntf_cc_test(\n    name = \"resource_handle_test\",\n    size = \"small\",\n    srcs = [\"resource_handle_test.cc\"],\n    deps = [\n        \":resource_handle\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"type_index\",\n    hdrs = [\"type_index.h\"],\n    visibility = [\"//visibility:private\"],\n    deps = [\n        \"//tensorflow/core/platform:hash\",\n        \"//tensorflow/core/platform:stringpiece\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ncc_library(\n    name = \"tensor_types\",\n    hdrs = [\"tensor_types.h\"],\n    visibility = [\"//visibility:private\"],\n    deps = [\n        \"//tensorflow/core/platform:logging\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ncc_library(\n    name = \"type_traits\",\n    hdrs = [\"type_traits.h\"],\n    visibility = [\"//visibility:private\"],\n    deps = [\n        \":numeric_types\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ntf_cuda_library(\n    name = \"tensor\",\n    srcs = [\n        \"log_memory.cc\",\n        \"tensor.cc\",\n        \"typed_allocator.cc\",\n        \"types.cc\",\n        \"variant.cc\",\n        \"variant_op_registry.cc\",\n        \"variant_tensor_data.cc\",\n    ],\n    hdrs = [\n        \"log_memory.h\",\n        \"register_types.h\",\n        \"tensor.h\",\n        \"typed_allocator.h\",\n        \"types.h\",\n        \"variant.h\",\n        \"variant_encode_decode.h\",\n        \"variant_op_registry.h\",\n        \"variant_tensor_data.h\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__pkg__\",\n        \"//tensorflow/core/runtime_fallback:__subpackages__\",\n        \"//tensorflow/core/tfrt/utils:__subpackages__\",\n        \"//tensorflow/core/util:__pkg__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n    deps = [\n        \":allocation_description_proto_cc\",\n        \":allocator\",\n        \":bfloat16\",\n        \":full_type_proto_cc\",\n        \":log_memory_proto_cc\",\n        \":numeric_types\",\n        \":resource_handle\",\n        \":resource_handle_proto_cc\",\n        \":tensor_description_proto_cc\",\n        \":tensor_proto_cc\",\n        \":tensor_shape\",\n        \":tensor_types\",\n        \":type_index\",\n        \":type_traits\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/core:coding\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:refcount\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/gtl:flatmap\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/lib/hash\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:abi\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:platform_port\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:strcat\",\n        \"//tensorflow/core/platform:tensor_coding\",\n        \"//tensorflow/core/platform:types\",\n        \"//tensorflow/core/public:version\",\n        \"//tensorflow/core/util:managed_stack_trace\",\n        \"//third_party/eigen3\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"shape_inference\",\n    srcs = [\"shape_inference.cc\"],\n    hdrs = [\"shape_inference.h\"],\n    deps = [\n        \":bounds_check\",\n        \":full_type_proto_cc\",\n        \":full_type_util\",\n        \":node_def_proto_cc\",\n        \":node_def_util\",\n        \":op_def_proto_cc\",\n        \":tensor\",\n        \":tensor_shape\",\n        \":tensor_shape_proto_cc\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/lib/strings:numbers\",\n        \"//tensorflow/core/lib/strings:scanner\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/platform:macros\",\n        \"@com_google_absl//absl/memory\",\n    ],\n)\n\ncc_library(\n    name = \"kernel_shape_util\",\n    srcs = [\"kernel_shape_util.cc\"],\n    hdrs = [\"kernel_shape_util.h\"],\n    deps = [\n        \":tensor\",\n        \":tensor_shape\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/platform:status\",\n        \"//tensorflow/core/util:padding\",\n    ],\n)\n\ncc_library(\n    name = \"common_shape_fns\",\n    srcs = [\"common_shape_fns.cc\"],\n    hdrs = [\"common_shape_fns.h\"],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":shape_inference\",\n        \":tensor\",\n        \":tensor_shape\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/util:einsum_op_util\",\n        \"//tensorflow/core/util:padding\",\n        \"//tensorflow/core/util:tensor_format\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"attr_value_util\",\n    srcs = [\"attr_value_util.cc\"],\n    hdrs = [\"attr_value_util.h\"],\n    deps = [\n        \":attr_value_proto_text\",\n        \":tensor\",\n        \":tensor_shape\",\n        \":tensor_shape_proto_cc\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/hash\",\n        \"//tensorflow/core/lib/strings:proto_serialization\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"op_def_util\",\n    srcs = [\"op_def_util.cc\"],\n    hdrs = [\"op_def_util.h\"],\n    deps = [\n        \":api_def_proto_cc\",\n        \":attr_value_proto_cc\",\n        \":attr_value_util\",\n        \":op_def_proto_cc\",\n        \":tensor\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:map_util\",\n        \"//tensorflow/core/lib/hash\",\n        \"//tensorflow/core/lib/strings:proto_serialization\",\n        \"//tensorflow/core/lib/strings:scanner\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:mutex\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ncc_library(\n    name = \"node_def_util\",\n    srcs = [\"node_def_util.cc\"],\n    hdrs = [\"node_def_util.h\"],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":attr_value_util\",\n        \":node_def_proto_cc\",\n        \":op_def_proto_cc\",\n        \":op_def_util\",\n        \":tensor\",\n        \":tensor_proto_cc\",\n        \":tensor_shape\",\n        \":tensor_shape_proto_cc\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/gtl:flatmap\",\n        \"//tensorflow/core/lib/gtl:map_util\",\n        \"//tensorflow/core/lib/hash\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:hash\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:scanner\",\n        \"//tensorflow/core/platform:status\",\n        \"//tensorflow/core/platform:strcat\",\n        \"//tensorflow/core/platform:stringpiece\",\n        \"//tensorflow/core/platform:types\",\n        \"//tensorflow/core/util:padding\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"node_properties\",\n    srcs = [\"node_properties.cc\"],\n    hdrs = [\"node_properties.h\"],\n    deps = [\n        \":full_type_proto_cc\",\n        \":node_def_proto_cc\",\n        \":node_def_util\",\n        \":op\",\n        \":op_def_builder\",\n        \":op_def_proto_cc\",\n        \":tensor\",\n        \"//tensorflow/core/lib/core:status\",\n    ],\n)\n\ncc_library(\n    name = \"op_def_builder\",\n    srcs = [\"op_def_builder.cc\"],\n    hdrs = [\"op_def_builder.h\"],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":attr_value_util\",\n        \":full_type_proto_cc\",\n        \":op_def_proto_cc\",\n        \":op_def_util\",\n        \":tensor\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/strings:scanner\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:macros\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\n# TODO(mdan): Move these into a separate directory.\ncc_library(\n    name = \"full_type_util\",\n    srcs = [\n        \"full_type_inference_util.cc\",\n        \"full_type_util.cc\",\n    ],\n    hdrs = [\n        \"full_type_inference_util.h\",\n        \"full_type_util.h\",\n    ],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":full_type_proto_cc\",\n        \":node_def_proto_cc\",\n        \":node_def_util\",\n        \":op_def_builder\",\n        \":op_def_proto_cc\",\n        \":tensor\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/platform:statusor\",\n        \"//tensorflow/core/protobuf:error_codes_proto_impl_cc\",\n    ],\n)\n\ncc_library(\n    name = \"op\",\n    srcs = [\"op.cc\"],\n    hdrs = [\"op.h\"],\n    deps = [\n        \":full_type_proto_cc\",\n        \":full_type_util\",\n        \":op_def_builder\",\n        \":op_def_util\",\n        \"//tensorflow/core/framework/registration\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/gtl:map_util\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:mutex\",\n        \"//tensorflow/core/platform:platform_port\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:thread_annotations\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ncc_library(\n    name = \"op_requires\",\n    hdrs = [\"op_requires.h\"],\n    deps = [\"//tensorflow/core/platform:macros\"],\n)\n\n# Files whose users still need to be migrated from core:framework to the\n# above targets.\n# TODO(gonnet): Remove these files once targets depending on them have\n# been cleaned up.\nexports_files(\n    srcs = [\n        \"allocator.h\",\n        \"bfloat16.h\",\n        \"bounds_check.h\",\n        \"fake_input.h\",\n        \"function_testlib.h\",\n        \"log_memory.h\",\n        \"numeric_types.h\",\n        \"op_gen_lib.h\",\n        \"reader_base.h\",\n        \"register_types.h\",\n        \"resource_base.h\",\n        \"resource_handle.h\",\n        \"shape_inference_testutil.h\",\n        \"tensor.h\",\n        \"tensor_interface.h\",\n        \"tensor_shape.h\",\n        \"tensor_testutil.h\",\n        \"tensor_types.h\",\n        \"type_index.h\",\n        \"type_traits.h\",\n        \"typed_allocator.h\",\n        \"types.h\",\n        \"variant.h\",\n        \"variant_encode_decode.h\",\n        \"variant_op_registry.h\",\n        \"variant_tensor_data.h\",\n    ],\n)\n\n# Framework tests.\ntf_cc_test(\n    name = \"framework_op_gen_lib_test\",\n    size = \"small\",\n    srcs = [\"op_gen_lib_test.cc\"],\n    deps = [\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core/framework:op_gen_lib\",\n    ],\n)\n\ntf_cuda_cc_test(\n    name = \"variant_op_copy_test\",\n    size = \"small\",\n    srcs = [\"variant_op_copy_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    tags = tf_cuda_tests_tags(),\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:client_session\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:direct_session\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/kernels:array\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ntf_cc_test(\n    name = \"framework_run_handler_util_test\",\n    size = \"small\",\n    srcs = [\"run_handler_util_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    deps = [\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ntf_cc_test(\n    name = \"framework_run_handler_test\",\n    size = \"small\",\n    srcs = [\"run_handler_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    deps = [\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:direct_session_internal\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/framework:tensor_testutil\",\n        \"//tensorflow/core/kernels:cwise_op\",\n        \"//tensorflow/core/kernels:matmul_op\",\n        \"//third_party/eigen3\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/synchronization\",\n    ],\n)\n\ntf_cc_test(\n    name = \"framework_op_segment_test\",\n    size = \"small\",\n    srcs = [\"op_segment_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/core\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:direct_session_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/kernels:cwise_op\",\n        \"//tensorflow/core/kernels:ops_util\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ntf_cc_test(\n    name = \"framework_resource_var_test\",\n    size = \"small\",\n    srcs = [\"resource_var_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    deps = [\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"op_kernel_test_base\",\n    testonly = True,\n    hdrs = [\n        \"op_kernel_test_base.h\",\n    ],\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:cc_ops_internal\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:sendrecv_ops\",\n        \"//tensorflow/core\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/common_runtime:direct_session_internal\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_tests(\n    name = \"higher_level_tests\",\n    size = \"small\",\n    srcs = [\n        \"allocator_test.cc\",\n        \"attr_value_util_test.cc\",\n        \"batch_util_test.cc\",\n        \"bfloat16_test.cc\",\n        \"cancellation_test.cc\",\n        \"common_shape_fns_test.cc\",\n        \"dataset_test.cc\",\n        \"device_base_test.cc\",\n        \"disable_jit_test.cc\",\n        \"full_type_inference_util_test.cc\",\n        \"function_test.cc\",\n        \"graph_def_util_test.cc\",\n        \"graph_to_functiondef_test.cc\",\n        \"kernel_def_builder_test.cc\",\n        \"kernel_def_util_test.cc\",\n        \"memory_types_test.cc\",\n        \"model_test.cc\",\n        \"node_def_builder_test.cc\",\n        \"node_def_util_test.cc\",\n        \"node_properties_test.cc\",\n        \"op_compatibility_test.cc\",\n        \"op_def_builder_test.cc\",\n        \"op_def_util_test.cc\",\n        \"op_kernel_test.cc\",\n        \"op_registration_test.cc\",\n        \"partial_tensor_shape_test.cc\",\n        \"rendezvous_test.cc\",\n        \"resource_mgr_test.cc\",\n        \"resource_op_kernel_test.cc\",\n        \"shape_inference_test.cc\",\n        \"shape_inference_testutil_test.cc\",\n        \"tensor_shape_test.cc\",\n        \"tensor_slice_test.cc\",\n        \"tensor_test.cc\",\n        \"tensor_testutil_test.cc\",\n        \"tensor_util_test.cc\",\n        \"tracking_allocator_test.cc\",\n        \"types_test.cc\",\n        \"variant_op_registry_test.cc\",\n        \"variant_test.cc\",\n    ],\n    linkopts = select({\n        \"//tensorflow:macos\": [\"-headerpad_max_install_names\"],\n        \"//conditions:default\": [],\n    }),\n    linkstatic = tf_kernel_tests_linkstatic(),\n    visibility = [\n        \"//tensorflow:internal\",\n        \"//tensorflow/core:__pkg__\",\n    ],\n    deps = [\n        \":op_kernel_test_base\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:cc_ops_internal\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/cc:sendrecv_ops\",\n        \"//tensorflow/cc:while_loop\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/core\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/common_runtime:direct_session_internal\",\n        \"//tensorflow/core/kernels:ops_util\",\n        \"//tensorflow/core/platform:regexp\",\n        \"//tensorflow/core/platform:status_matchers\",\n        \"//tensorflow/core/profiler/lib:profiler_session\",\n        \"//tensorflow/core/profiler/protobuf:memory_profile_proto_cc\",\n        \"//tensorflow/core/profiler/utils:xplane_schema\",\n        \"//tensorflow/core/profiler/utils:xplane_visitor\",\n        \"//tensorflow/core/util:protos_test_cc\",\n        \"//third_party/eigen3\",\n        \"@com_google_absl//absl/base\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"pywrap_required_hdrs\",\n    textual_hdrs = [\n        \"op_gen_lib.h\",\n        \"rendezvous.h\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__pkg__\",\n        \"//tensorflow/python:__pkg__\",\n        \"//tensorflow/python/client:__pkg__\",\n        \"//tensorflow/python/util:__pkg__\",\n    ],\n)\n\n# All framewrok protos are self-contained, i.e. they only import other\n# protos from the same package, so we can build the protos here and then\n# link them from core:protos_all without circular dependencies.\n\n# Generate the C++ sources for some of the protos.\ntf_generate_proto_text_sources(\n    name = \"attr_value_proto_text\",\n    srcs = [\n        \"attr_value.proto\",\n        \"resource_handle.proto\",\n        \"tensor.proto\",\n        \"tensor_shape.proto\",\n        \"types.proto\",\n    ],\n    srcs_relative_dir = \"tensorflow/core/framework/\",\n    deps = [\n        \":attr_value_proto_cc\",\n        \":resource_handle_proto_cc\",\n        \":tensor_proto_cc\",\n        \":tensor_shape_proto_cc\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/strings:proto_text_util\",\n        \"//tensorflow/core/lib/strings:scanner\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ntf_pyclif_proto_library(\n    name = \"cost_graph_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"cost_graph.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"tensor_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"tensor.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"kernel_def_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"kernel_def.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"node_def_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"node_def.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"function_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"function.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"graph_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"graph.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"step_stats_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"step_stats.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"types_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"types.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"variable_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"variable.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_proto_library(\n    name = \"log_memory_proto\",\n    srcs = [\"log_memory.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":allocation_description_proto\",\n        \":tensor_description_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"versions_proto\",\n    srcs = [\"versions.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"graph_proto\",\n    srcs = [\"graph.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":function_proto\",\n        \":node_def_proto\",\n        \":op_def_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n        \":versions_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"node_def_proto\",\n    srcs = [\"node_def.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":full_type_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"allocation_description_proto\",\n    srcs = [\"allocation_description.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"tensor_slice_proto\",\n    srcs = [\"tensor_slice.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"tensor_description_proto\",\n    srcs = [\"tensor_description.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":allocation_description_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"device_attributes_proto\",\n    srcs = [\"device_attributes.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"resource_handle_proto\",\n    srcs = [\"resource_handle.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"step_stats_proto\",\n    srcs = [\"step_stats.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":allocation_description_proto\",\n        \":tensor_description_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"reader_base_proto\",\n    srcs = [\"reader_base.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"kernel_def_proto\",\n    srcs = [\"kernel_def.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"op_def_proto\",\n    srcs = [\"op_def.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":full_type_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__subpackages__\",\n        \"//tensorflow/python:__pkg__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n)\n\ntf_proto_library(\n    name = \"attr_value_proto\",\n    srcs = [\"attr_value.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__subpackages__\",\n        \"//tensorflow/python:__pkg__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n)\n\ntf_proto_library(\n    name = \"full_type_proto\",\n    srcs = [\"full_type.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [],\n)\n\ntf_proto_library(\n    name = \"tensor_proto\",\n    srcs = [\"tensor.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":resource_handle_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"api_def_proto\",\n    srcs = [\"api_def.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"variable_proto\",\n    srcs = [\"variable.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"graph_transfer_info_proto\",\n    srcs = [\"graph_transfer_info.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"types_proto\",\n    srcs = [\"types.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"cost_graph_proto\",\n    srcs = [\"cost_graph.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"tensor_shape_proto\",\n    srcs = [\"tensor_shape.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"function_proto\",\n    srcs = [\"function.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":node_def_proto\",\n        \":op_def_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"summary_proto\",\n    srcs = [\"summary.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"model_proto\",\n    srcs = [\"model.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"dataset_metadata_proto\",\n    srcs = [\"dataset_metadata.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"dataset_options_proto\",\n    srcs = [\"dataset_options.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":model_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"protos_all\",\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":allocation_description_proto\",\n        \":api_def_proto\",\n        \":attr_value_proto\",\n        \":cost_graph_proto\",\n        \":dataset_metadata_proto\",\n        \":dataset_options_proto\",\n        \":device_attributes_proto\",\n        \":full_type_proto\",\n        \":function_proto\",\n        \":graph_proto\",\n        \":graph_transfer_info_proto\",\n        \":kernel_def_proto\",\n        \":log_memory_proto\",\n        \":model_proto\",\n        \":node_def_proto\",\n        \":op_def_proto\",\n        \":reader_base_proto\",\n        \":resource_handle_proto\",\n        \":step_stats_proto\",\n        \":summary_proto\",\n        \":tensor_description_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":tensor_slice_proto\",\n        \":types_proto\",\n        \":variable_proto\",\n        \":versions_proto\",\n    ],\n    tags = [\n        \"alt_dep=//third_party/tensorflow/core:protos_all\",\n    ],\n)\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/resource_handle.h\"\n\n#include \"absl/strings/str_format.h\"\n#include \"tensorflow/core/framework/resource_handle.pb.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/strings/strcat.h\"\n\nnamespace tensorflow {\n\n// Must be declared here for pre-C++17 compatibility.\n/* static */ constexpr const char* ResourceHandle::ANONYMOUS_NAME;\n\nResourceHandle::ResourceHandle() {}\n\nResourceHandle::ResourceHandle(const ResourceHandleProto& proto) {\n  FromProto(proto);\n}\n\nResourceHandle::~ResourceHandle() {}\n\nvoid ResourceHandle::AsProto(ResourceHandleProto* proto) const {\n  proto->set_device(device());\n  proto->set_container(container());\n  proto->set_name(name());\n  proto->set_hash_code(hash_code());\n  proto->set_maybe_type_name(maybe_type_name());\n  for (const auto& dtype_and_shape_pair : dtypes_and_shapes_) {\n    auto dtype_and_shape = proto->add_dtypes_and_shapes();\n    dtype_and_shape->set_dtype(dtype_and_shape_pair.dtype);\n    dtype_and_shape_pair.shape.AsProto(dtype_and_shape->mutable_shape());\n  }\n}\n\nvoid ResourceHandle::FromProto(const ResourceHandleProto& proto) {\n  set_device(proto.device());\n  set_container(proto.container());\n  set_name(proto.name());\n  set_hash_code(proto.hash_code());\n  set_maybe_type_name(proto.maybe_type_name());\n  std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes;\n  for (const auto& dtype_and_shape : proto.dtypes_and_shapes()) {\n    DataType dtype = dtype_and_shape.dtype();\n    PartialTensorShape shape(dtype_and_shape.shape());\n    dtypes_and_shapes.push_back(DtypeAndPartialTensorShape{dtype, shape});\n  }\n  dtypes_and_shapes_ = std::move(dtypes_and_shapes);\n}\n\nstring ResourceHandle::SerializeAsString() const {\n  ResourceHandleProto proto;\n  AsProto(&proto);\n  return proto.SerializeAsString();\n}\n\nbool ResourceHandle::ParseFromString(const string& s) {\n  ResourceHandleProto proto;\n  const bool status = proto.ParseFromString(s);\n  if (status) FromProto(proto);\n  return status;\n}\n\nstring ResourceHandle::DebugString() const {\n  return strings::StrCat(\"device: \", device(), \" container: \", container(),\n                         \" name: \", name(), \" hash_code: \", hash_code(),\n                         \" maybe_type_name: \", maybe_type_name());\n}\n\nResourceHandle ResourceHandle::MakeRefCountingHandle(\n    ResourceBase* resource, const string& device_name,\n    const TypeIndex& type_index,\n    const std::vector<DtypeAndPartialTensorShape>& dtypes_and_shapes,\n    const absl::optional<ManagedStackTrace>& definition_stack_trace) {\n  ResourceHandle result;\n  result.resource_.reset(resource, /*add_ref=*/false);\n  result.set_device(device_name);\n  // All resources owned by anonymous handles are put into the same container,\n  // and they get process-unique handle names.\n  result.set_container(\"Anonymous\");\n  result.set_definition_stack_trace(definition_stack_trace);\n  result.set_name(\n      absl::StrFormat(\"Resource-%d-at-%p\", GenerateUniqueId(), resource));\n  result.set_hash_code(type_index.hash_code());\n  result.set_maybe_type_name(type_index.name());\n  result.set_dtypes_and_shapes(dtypes_and_shapes);\n  return result;\n}\n\nStatus ResourceHandle::ValidateType(const TypeIndex& type_index) const {\n  if (type_index.hash_code() != hash_code()) {\n    return errors::InvalidArgument(\n        \"Trying to access a handle's resource using the wrong type. \",\n        \"The handle points to a resource (name '\", name(), \"') of type '\",\n        maybe_type_name(), \"' (hash code \", hash_code(),\n        \") but you are trying to access the resource as type '\",\n        type_index.name(), \"' (hash code \", type_index.hash_code(), \")\");\n  }\n  return Status::OK();\n}\n\nstd::atomic<int64_t> ResourceHandle::current_id_;\n\nint64_t ResourceHandle::GenerateUniqueId() { return current_id_.fetch_add(1); }\n\nstring ProtoDebugString(const ResourceHandle& handle) {\n  return handle.DebugString();\n}\n\nvoid EncodeResourceHandleList(const ResourceHandle* p, int64_t n,\n                              std::unique_ptr<port::StringListEncoder> e) {\n  ResourceHandleProto proto;\n  for (int i = 0; i < n; ++i) {\n    p[i].AsProto(&proto);\n    e->Append(proto);\n  }\n  e->Finalize();\n}\n\nbool DecodeResourceHandleList(std::unique_ptr<port::StringListDecoder> d,\n                              ResourceHandle* ps, int64_t n) {\n  std::vector<uint32> sizes(n);\n  if (!d->ReadSizes(&sizes)) return false;\n\n  ResourceHandleProto proto;\n  for (int i = 0; i < n; ++i) {\n    if (!proto.ParseFromArray(d->Data(sizes[i]), sizes[i])) {\n      return false;\n    }\n    ps[i].FromProto(proto);\n  }\n  return true;\n}\n\n}  // namespace tensorflow\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_\n#define TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_\n\n#include <string>\n\n#include \"tensorflow/core/framework/resource_base.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/type_index.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/platform/casts.h\"\n#include \"tensorflow/core/platform/intrusive_ptr.h\"\n#include \"tensorflow/core/platform/statusor.h\"\n#include \"tensorflow/core/platform/tensor_coding.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/managed_stack_trace.h\"\n\nnamespace tensorflow {\n\nclass ResourceHandleProto;\n\n// Class representing a handle to a tensorflow resource. Handles are\n// not valid across executions, but can be serialized back and forth from within\n// a single run (except for those created from MakeRefCountingHandle i.e. whose\n// resource_ field is not empty).\n//\n// This is the native C++ class equivalent of ResourceHandleProto.  They are\n// separate so that kernels do not need to depend on protos.\nclass ResourceHandle {\n public:\n  ResourceHandle();\n  ResourceHandle(const ResourceHandleProto& proto);\n  ~ResourceHandle();\n\n  // Unique name for the device containing the resource.\n  const std::string& device() const { return device_; }\n\n  void set_device(const std::string& device) { device_ = device; }\n\n  // Container in which this resource is placed.\n  const std::string& container() const { return container_; }\n  void set_container(const std::string& container) { container_ = container; }\n\n  // Unique name of this resource.\n  const std::string& name() const { return name_; }\n  void set_name(const std::string& name) { name_ = name; }\n\n  // Hash code for the type of the resource. Is only valid in the same device\n  // and in the same execution.\n  uint64 hash_code() const { return hash_code_; }\n  void set_hash_code(uint64 hash_code) { hash_code_ = hash_code; }\n\n  // For debug-only, the name of the type pointed to by this handle, if\n  // available.\n  const std::string& maybe_type_name() const { return maybe_type_name_; }\n  void set_maybe_type_name(const std::string& value) {\n    maybe_type_name_ = value;\n  }\n\n  // Data types and shapes for the underlying resource.\n  std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes() const {\n    return dtypes_and_shapes_;\n  }\n  void set_dtypes_and_shapes(\n      const std::vector<DtypeAndPartialTensorShape>& dtypes_and_shapes) {\n    dtypes_and_shapes_ = dtypes_and_shapes;\n  }\n\n  void set_definition_stack_trace(\n      const absl::optional<ManagedStackTrace>& definition_stack_trace) {\n    definition_stack_trace_ = definition_stack_trace;\n  }\n\n  const absl::optional<ManagedStackTrace>& definition_stack_trace() const {\n    return definition_stack_trace_;\n  }\n\n  // Conversion to and from ResourceHandleProto\n  void AsProto(ResourceHandleProto* proto) const;\n  void FromProto(const ResourceHandleProto& proto);\n\n  // Serialization via ResourceHandleProto\n  std::string SerializeAsString() const;\n  bool ParseFromString(const std::string& s);\n\n  std::string DebugString() const;\n\n  std::string SummarizeValue() const { return \"Resource Tensor\"; }\n\n  // GUID for anonymous resources. Resources with this shared_name will have\n  // their shared_name replaced with a GUID at creation time\n  static constexpr const char* ANONYMOUS_NAME =\n      \"cd2c89b7-88b7-44c8-ad83-06c2a9158347\";\n\n  // Creates a `ResourceHandle` that holds a pointer to a resource and takes\n  // ownership of it. Normally a `ResourceHandle` only contains the name (and\n  // some other metadata) of the resource. When created via this function,\n  // the handle will own the resource, in the sense that it will destroy the\n  // resource automatically when the resource is no longer needed. It does this\n  // via automatic ref-counting on the resource: when the handle is copied, it\n  // will call `Ref` on the resource (remember that all resources inherit from\n  // `ResourceBase` which inherits from `RefCounted`), and when the handle is\n  // destroyed, it will call `Unref` on the resource. When the last handle goes\n  // out of scope, the resource's ref-count will go down to zero and the\n  // resource will be destroyed. When calling this function, the `resource`\n  // argument should have a ref-count of one (which is the case when the\n  // resource is newly created).\n  //\n  // For those familiar with `ResourceMgr`, when you create a handle by the\n  // `MakeResourceHandle` function in resource_mgr.h, the handle doesn't hold a\n  // strong reference to the resource, and the resource is owned by the\n  // resource manager whose strong reference must be manually deleted by\n  // calling `ResourceMgr::Delete`. In contrast, a handle created by this\n  // function holds a strong reference to the resource. The resource manager\n  // does not hold a strong reference to the resource.\n  template <typename T>\n  static ResourceHandle MakeRefCountingHandle(\n      T* resource, const string& device_name,\n      const std::vector<DtypeAndPartialTensorShape>& dtypes_and_shapes = {},\n      const absl::optional<ManagedStackTrace>& definition_stack_trace = {}) {\n    return MakeRefCountingHandle(resource, device_name, TypeIndex::Make<T>(),\n                                 dtypes_and_shapes, definition_stack_trace);\n  }\n\n  static ResourceHandle MakeRefCountingHandle(\n      ResourceBase* resource, const string& device_name,\n      const TypeIndex& type_index,\n      const std::vector<DtypeAndPartialTensorShape>& dtypes_and_shapes = {},\n      const absl::optional<ManagedStackTrace>& definition_stack_trace = {});\n\n  // Pointer to the resource.\n  const core::IntrusivePtr<ResourceBase>& resource() const { return resource_; }\n\n  // Gets the resource pointer in `handle` as `T*`, or an error if the actual\n  // resource type is not `T`.\n  template <typename T>\n  StatusOr<T*> GetResource() const {\n    TF_RETURN_IF_ERROR(ValidateType<T>());\n    return down_cast<T*>(resource_.get());\n  }\n\n  // Returns True if the resource handle is ref-counting.\n  // See MakeRefCountingHandle.\n  bool IsRefCounting() const { return resource_.get() != nullptr; }\n\n  // Validates that the resource type in `handle` is `T`.\n  template <typename T>\n  Status ValidateType() const {\n    return ValidateType(TypeIndex::Make<T>());\n  }\n\n  Status ValidateType(const TypeIndex& type_index) const;\n\n  // Generates unique IDs (e.g. for names of anonymous variables)\n  static int64_t GenerateUniqueId();\n\n private:\n  std::string device_;\n  std::string container_;\n  std::string name_;\n  uint64 hash_code_ = 0;\n  std::string maybe_type_name_;\n  std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes_;\n  absl::optional<ManagedStackTrace> definition_stack_trace_;\n  // A smart pointer to the actual resource. When this field is not empty, the\n  // handle is in a \"ref-counting\" mode, owning the resource; otherwise it's in\n  // a \"weak-ref\" mode, only containing the name of the resource (conceptually a\n  // weak reference).\n  core::IntrusivePtr<ResourceBase> resource_;\n  static std::atomic<int64_t> current_id_;\n};\n\n// For backwards compatibility for when this was a proto\nstd::string ProtoDebugString(const ResourceHandle& handle);\n\n// Encodes a list of ResourceHandle protos in the given StringListEncoder.\nvoid EncodeResourceHandleList(const ResourceHandle* p, int64_t n,\n                              std::unique_ptr<port::StringListEncoder> e);\n\n// Decodes a list of ResourceHandle protos from the given StringListDecoder.\nbool DecodeResourceHandleList(std::unique_ptr<port::StringListDecoder> d,\n                              ResourceHandle* ps, int64_t n);\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Implementation notes:\n//\n// Tensor.cc uses a few templated classes and structs to facilitate\n// implementation of the Tensor class.\n//\n// * Buffer<T>: provides the implementation for a typed array T[n].\n//   The array is allocated by the given allocator. It runs T's\n//   default constructors and destructors when T is not a simple type\n//   (e.g., string.), and skips them otherwise.\n//\n// * Helper<T>: provides various routines given type T.  The routines\n//   includes running the constructor and destructor of T[], encoding\n//   an decoding T[] into/from a Cord, etc.\n\n#include \"tensorflow/core/framework/tensor.h\"\n\n#include <utility>\n\n#include \"absl/strings/escaping.h\"\n#include \"tensorflow/core/framework/allocation_description.pb.h\"\n#include \"tensorflow/core/framework/log_memory.h\"\n#include \"tensorflow/core/framework/resource_handle.h\"\n#include \"tensorflow/core/framework/resource_handle.pb.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/tensor_description.pb.h\"\n#include \"tensorflow/core/framework/type_traits.h\"\n#include \"tensorflow/core/framework/typed_allocator.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/framework/variant.h\"\n#include \"tensorflow/core/framework/variant_encode_decode.h\"\n#include \"tensorflow/core/framework/variant_op_registry.h\"\n#include \"tensorflow/core/framework/variant_tensor_data.h\"\n#include \"tensorflow/core/lib/core/coding.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/lib/strings/strcat.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/macros.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n#include \"tensorflow/core/platform/tensor_coding.h\"\n#include \"tensorflow/core/platform/types.h\"\n\nnamespace tensorflow {\n\n// Allow Tensors to be stored inside Variants with automatic\n// encoding/decoding when those Variants are themselves being decoded\n// in a Tensor's FromProto.\n//\n// NOTE(mrry): The corresponding \"copy function\" registrations can be found in\n// ../common_runtime/copy_tensor.cc (due to dependencies on other common_runtime\n// code).\nREGISTER_UNARY_VARIANT_DECODE_FUNCTION(Tensor, \"tensorflow::Tensor\");\n\nbool TensorBuffer::GetAllocatedBytes(size_t* out_bytes) const {\n  AllocationDescription allocation_description;\n  FillAllocationDescription(&allocation_description);\n  if (allocation_description.allocated_bytes() > 0) {\n    *out_bytes = allocation_description.allocated_bytes();\n    return true;\n  } else {\n    return false;\n  }\n}\n\nnamespace {\n\n// An un-templated base class for Buffer.\nclass BufferBase : public TensorBuffer {\n public:\n  explicit BufferBase(Allocator* alloc, void* data_ptr)\n      : TensorBuffer(data_ptr), alloc_(alloc) {}\n\n  TensorBuffer* root_buffer() override { return this; }\n\n  bool GetAllocatedBytes(size_t* out_bytes) const override {\n    if (alloc_->TracksAllocationSizes()) {\n      *out_bytes = alloc_->AllocatedSize(data());\n      return *out_bytes > 0;\n    } else {\n      return false;\n    }\n  }\n\n  void FillAllocationDescription(AllocationDescription* proto) const override {\n    void* data_ptr = data();\n    int64_t rb = size();\n    proto->set_requested_bytes(rb);\n    proto->set_allocator_name(alloc_->Name());\n    proto->set_ptr(reinterpret_cast<uintptr_t>(data_ptr));\n    if (alloc_->TracksAllocationSizes()) {\n      int64_t ab = alloc_->AllocatedSize(data_ptr);\n      proto->set_allocated_bytes(ab);\n      int64_t id = alloc_->AllocationId(data_ptr);\n      if (id > 0) {\n        proto->set_allocation_id(id);\n      }\n      if (RefCountIsOne()) {\n        proto->set_has_single_reference(true);\n      }\n    }\n  }\n\n protected:\n  void RecordDeallocation() {\n    LogMemory::RecordTensorDeallocation(alloc_->AllocationId(data()),\n                                        alloc_->Name());\n  }\n\n  Allocator* const alloc_;\n};\n\n// Typed ref-counted buffer: T[n].\ntemplate <typename T>\nclass Buffer : public BufferBase {\n public:\n  Buffer(Allocator* a, int64_t n);\n  Buffer(Allocator* a, int64_t n, const AllocationAttributes& allocation_attr);\n\n  size_t size() const override { return sizeof(T) * elem_; }\n\n private:\n  int64_t elem_;\n\n  ~Buffer() override;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(Buffer);\n};\n\nvoid LogUnexpectedSize(int64_t actual, int64_t expected) {\n  LOG(ERROR) << \"Input size was \" << actual << \" and expected \" << expected;\n}\n\nbool MemoryLoggingEnabled() {\n  static bool memory_logging_enabled = LogMemory::IsEnabled();\n  return memory_logging_enabled;\n}\n\n// A set of helper functions depending on T.\ntemplate <typename T>\nstruct Helper {\n  // By default, we assume T is a simple type (float, int32, etc.)\n  static_assert(is_simple_type<T>::value, \"T is not a simple type.\");\n  typedef protobuf::RepeatedField<T> RepeatedFieldType;\n\n  // Encoder of simple type T to a string.  We do a copy.\n  template <typename Destination>\n  static void Encode(TensorBuffer* in, int64_t n, Destination* out) {\n    DCHECK_EQ(in->size(), sizeof(T) * n);\n    port::AssignRefCounted(StringPiece(in->base<const char>(), in->size()), in,\n                           out);\n  }\n\n  // Decoder of simple type T. Copy the bytes from \"in\" into the\n  // tensor buffer.\n  template <typename Source>\n  static TensorBuffer* Decode(Allocator* a, const Source& in, int64_t n) {\n    if (in.size() != sizeof(T) * n) {\n      LogUnexpectedSize(in.size(), sizeof(T) * n);\n      return nullptr;\n    }\n    Buffer<T>* buf = new Buffer<T>(a, n);\n    char* data = buf->template base<char>();\n    if (data == nullptr) {\n      buf->Unref();\n      return nullptr;\n    }\n    port::CopyToArray(in, data);\n    return buf;\n  }\n\n  // Memory usage.\n  static int64_t TotalBytes(TensorBuffer* in, int64_t n) {\n    DCHECK_EQ(in->size(), sizeof(T) * n);\n    return in->size();\n  }\n};\n\n// Helper specialization for string (the only non-simple type we\n// support).\ntemplate <>\nstruct Helper<tstring> {\n  // Proto message uses RepeatedFieldType to hold repeated T.\n  typedef protobuf::RepeatedPtrField<string> RepeatedFieldType;\n\n  // Encodes \"n\" elements of type string stored in \"in\" into Cord\n  // \"out\", which is usually the TensorProto::tensor_content.\n  template <typename Destination>\n  static void Encode(TensorBuffer* in, int64_t n, Destination* out) {\n    port::EncodeStringList(in->base<const tstring>(), n, out);\n  }\n\n  // Decodes \"n\" elements of type string from \"in\" and constructs a\n  // buffer out of it. Returns nullptr if the decoding fails. \"in\" is\n  // usually the TensorProto::tensor_content.\n  template <typename Source>\n  static TensorBuffer* Decode(Allocator* a, const Source& in, int64_t n) {\n    Buffer<tstring>* buf = new Buffer<tstring>(a, n);\n    tstring* strings = buf->template base<tstring>();\n    if (strings == nullptr || !port::DecodeStringList(in, strings, n)) {\n      buf->Unref();\n      return nullptr;\n    }\n    return buf;\n  }\n\n  // Returns the estimated memory usage of \"n\" elements of type T\n  // stored in buffer \"in\".\n  static int64_t TotalBytes(TensorBuffer* in, int n) {\n    int64_t tot = in->size();\n    DCHECK_EQ(tot, sizeof(tstring) * n);\n    const tstring* p = in->base<const tstring>();\n    for (int i = 0; i < n; ++i, ++p) tot += p->size();\n    return tot;\n  }\n};\n\ntemplate <>\nstruct Helper<ResourceHandle> {\n  // Proto message uses RepeatedFieldType to hold repeated T.\n  typedef protobuf::RepeatedPtrField<string> RepeatedFieldType;\n\n  // Encodes \"n\" elements of type ResourceHandle stored in \"in\" into destination\n  // \"out\", which is usually the TensorProto::tensor_content.\n  template <typename Destination>\n  static void Encode(TensorBuffer* in, int64_t n, Destination* out) {\n    EncodeResourceHandleList(in->base<const ResourceHandle>(), n,\n                             port::NewStringListEncoder(out));\n  }\n\n  // Decodes \"n\" elements of type string from \"in\" and constructs a\n  // buffer out of it. Returns nullptr if the decoding fails. \"in\" is\n  // usually the TensorProto::tensor_content.\n  template <typename Source>\n  static TensorBuffer* Decode(Allocator* a, const Source& in, int64_t n) {\n    auto* buf = new Buffer<ResourceHandle>(a, n);\n    ResourceHandle* ps = buf->template base<ResourceHandle>();\n    if (ps == nullptr ||\n        !DecodeResourceHandleList(port::NewStringListDecoder(in), ps, n)) {\n      buf->Unref();\n      return nullptr;\n    }\n    return buf;\n  }\n\n  // Returns the estimated memory usage of \"n\" elements of type T\n  // stored in buffer \"in\".\n  static int64_t TotalBytes(TensorBuffer* in, int n) {\n    return n * sizeof(ResourceHandle);\n  }\n};\n\ntemplate <>\nstruct Helper<Variant> {\n  // Encodes \"n\" elements of type Variant stored in \"in\" into destination\n  // \"out\", which is usually the TensorProto::tensor_content.\n  template <typename Destination>\n  static void Encode(TensorBuffer* in, int64_t n, Destination* out) {\n    EncodeVariantList(in->base<const Variant>(), n,\n                      port::NewStringListEncoder(out));\n  }\n\n  // Decodes \"n\" elements of type Variant from \"in\" and constructs a\n  // buffer out of it. Returns nullptr if the decoding fails. \"in\" is\n  // usually the TensorProto::tensor_content.\n  template <typename Source>\n  static TensorBuffer* Decode(Allocator* a, const Source& in, int64_t n) {\n    auto* buf = new Buffer<Variant>(a, n);\n    Variant* ps = buf->template base<Variant>();\n    if (ps == nullptr ||\n        !DecodeVariantList(port::NewStringListDecoder(in), ps, n)) {\n      buf->Unref();\n      return nullptr;\n    }\n    return buf;\n  }\n\n  // Returns the estimated memory usage of \"n\" elements of type T\n  // stored in buffer \"in\".\n  static int64_t TotalBytes(TensorBuffer* in, int n) {\n    return n * sizeof(Variant);\n  }\n};\n\ntemplate <typename T>\nstruct ProtoHelper {};\n\n// For a C++ type \"T\" (float, double, int32, etc.), the repeated field\n// \"N\"_val (float_val, int_val, label_val, etc.) of type \"F\" (float,\n// int32, string, etc) in the TensorProto is used for serializing the\n// tensor of type \"T\".\n#define PROTO_TRAITS(T, F, N)                                          \\\n  template <>                                                          \\\n  struct ProtoHelper<T> {                                              \\\n    typedef Helper<F>::RepeatedFieldType FieldType;                    \\\n    static FieldType::const_iterator Begin(const TensorProto& proto) { \\\n      return proto.N##_val().begin();                                  \\\n    }                                                                  \\\n    static size_t NumElements(const TensorProto& proto) {              \\\n      return proto.N##_val().size();                                   \\\n    }                                                                  \\\n    static void Fill(const T* data, size_t n, TensorProto* proto) {    \\\n      typename ProtoHelper<T>::FieldType copy(data, data + n);         \\\n      proto->mutable_##N##_val()->Swap(&copy);                         \\\n    }                                                                  \\\n  };\nPROTO_TRAITS(float, float, float);\nPROTO_TRAITS(double, double, double);\nPROTO_TRAITS(int32, int32, int);\nPROTO_TRAITS(uint8, int32, int);\nPROTO_TRAITS(uint16, int32, int);\nPROTO_TRAITS(uint32, uint32, uint32);\nPROTO_TRAITS(int16, int32, int);\nPROTO_TRAITS(int8, int32, int);\nPROTO_TRAITS(bool, bool, bool);\nPROTO_TRAITS(tstring, tstring, string);\nPROTO_TRAITS(qint8, int32, int);\nPROTO_TRAITS(quint8, int32, int);\nPROTO_TRAITS(qint16, int32, int);\nPROTO_TRAITS(quint16, int32, int);\n#undef PROTO_TRAITS\n\ntemplate <>\nstruct ProtoHelper<int64_t> {\n  static const int64_t* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const int64_t*>(proto.int64_val().begin());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.int64_val().size();\n  }\n  static void Fill(const int64_t* data, size_t n, TensorProto* proto) {\n    protobuf::RepeatedField<protobuf_int64> copy(data, data + n);\n    proto->mutable_int64_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<uint64> {\n  static const uint64* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const uint64*>(proto.uint64_val().begin());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.uint64_val().size();\n  }\n  static void Fill(const uint64* data, size_t n, TensorProto* proto) {\n    protobuf::RepeatedField<protobuf_uint64> copy(data, data + n);\n    proto->mutable_uint64_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<ResourceHandle> {\n  static protobuf::RepeatedPtrField<ResourceHandleProto>::const_iterator Begin(\n      const TensorProto& proto) {\n    return proto.resource_handle_val().begin();\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.resource_handle_val().size();\n  }\n  static void Fill(const ResourceHandle* data, size_t n, TensorProto* proto) {\n    auto* handles = proto->mutable_resource_handle_val();\n    handles->Clear();\n    for (size_t i = 0; i < n; i++) {\n      data[i].AsProto(handles->Add());\n    }\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<Variant> {\n  static protobuf::RepeatedPtrField<VariantTensorDataProto>::const_iterator\n  Begin(const TensorProto& proto) {\n    return proto.variant_val().begin();\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.variant_val().size();\n  }\n  static void Fill(const Variant* data, size_t n, TensorProto* proto) {\n    auto* variant_values = proto->mutable_variant_val();\n    variant_values->Clear();\n    for (size_t i = 0; i < n; ++i) {\n      VariantTensorData tmp;\n      data[i].Encode(&tmp);\n      tmp.ToProto(variant_values->Add());\n    }\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<complex64> {\n  typedef Helper<float>::RepeatedFieldType FieldType;\n  static const complex64* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const complex64*>(proto.scomplex_val().data());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.scomplex_val().size() / 2;\n  }\n  static void Fill(const complex64* data, size_t n, TensorProto* proto) {\n    const float* p = reinterpret_cast<const float*>(data);\n    FieldType copy(p, p + n * 2);\n    proto->mutable_scomplex_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<complex128> {\n  typedef Helper<double>::RepeatedFieldType FieldType;\n  static const complex128* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const complex128*>(proto.dcomplex_val().data());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.dcomplex_val().size() / 2;\n  }\n  static void Fill(const complex128* data, size_t n, TensorProto* proto) {\n    const double* p = reinterpret_cast<const double*>(data);\n    FieldType copy(p, p + n * 2);\n    proto->mutable_dcomplex_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<qint32> {\n  typedef Helper<int32>::RepeatedFieldType FieldType;\n  static const qint32* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const qint32*>(proto.int_val().data());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.int_val().size();\n  }\n  static void Fill(const qint32* data, size_t n, TensorProto* proto) {\n    const int32* p = reinterpret_cast<const int32*>(data);\n    FieldType copy(p, p + n);\n    proto->mutable_int_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<bfloat16> {\n  static void Fill(const bfloat16* data, size_t n, TensorProto* proto) {\n    proto->mutable_half_val()->Reserve(n);\n    for (size_t i = 0; i < n; ++i) {\n      proto->mutable_half_val()->AddAlreadyReserved(\n          Eigen::numext::bit_cast<uint16>(data[i]));\n    }\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<Eigen::half> {\n  static void Fill(const Eigen::half* data, size_t n, TensorProto* proto) {\n    proto->mutable_half_val()->Reserve(n);\n    for (size_t i = 0; i < n; ++i) {\n      proto->mutable_half_val()->AddAlreadyReserved(\n          Eigen::numext::bit_cast<uint16>(data[i]));\n    }\n  }\n};\n\ntemplate <typename T>\nBuffer<T>::Buffer(Allocator* a, int64_t n)\n    : BufferBase(a, TypedAllocator::Allocate<T>(a, n, AllocationAttributes())),\n      elem_(n) {}\n\ntemplate <typename T>\nBuffer<T>::Buffer(Allocator* a, int64_t n,\n                  const AllocationAttributes& allocation_attr)\n    : BufferBase(a, TypedAllocator::Allocate<T>(a, n, allocation_attr)),\n      elem_(n) {}\n\ntemplate <typename T>\nBuffer<T>::~Buffer() {\n  if (data()) {\n    if (MemoryLoggingEnabled()) {\n      RecordDeallocation();\n    }\n    TypedAllocator::Deallocate<T>(alloc_, static_cast<T*>(data()), elem_);\n  }\n}\n\n// Allocates a T[n] buffer. Fills in the buffer with repeated values\n// in \"in\".  If \"in\" has less values than \"n\", fills the rest of T[n]\n// with the last value. If \"in\" has no values, fills T[n] with the\n// default value for T.\n//\n// This routine is using the typed fields (float_val, etc.) in the\n// tensor proto as opposed to the untyped binary representation\n// (tensor_content). This is used when we expect the TensorProto is\n// used by a client program which may not know how to encode a tensor\n// in the compact binary representation.\ntemplate <typename T>\nTensorBuffer* FromProtoField(Allocator* a, const TensorProto& in, int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<T>* buf = new Buffer<T>(a, n);\n  T* data = buf->template base<T>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n\n  const int64_t in_n = ProtoHelper<T>::NumElements(in);\n  if (in_n <= 0) {\n    std::fill_n(data, n, T());\n  } else {\n    auto begin = ProtoHelper<T>::Begin(in);\n    if (n <= in_n) {\n      std::copy_n(begin, n, data);\n    } else {\n      std::copy_n(begin, in_n, data);\n      if (std::is_trivially_copyable<T>::value) {\n        const T last = *(data + in_n - 1);\n        std::fill_n(data + in_n, n - in_n, last);\n      } else {\n        const T& last = *(data + in_n - 1);\n        std::fill_n(data + in_n, n - in_n, last);\n      }\n    }\n  }\n\n  return buf;\n}\n\ntemplate <>\nTensorBuffer* FromProtoField<Variant>(Allocator* a, const TensorProto& in,\n                                      int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<Variant>* buf = new Buffer<Variant>(a, n);\n  Variant* data = buf->template base<Variant>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n  const int64_t in_n = ProtoHelper<Variant>::NumElements(in);\n  if (in_n <= 0) {\n    std::fill_n(data, n, Variant());\n  } else {\n    // If tensor shape says we have n < in_n elements in the output tensor\n    // then make sure to only decode the first n out of the in_n elements in the\n    // in tensors. In all other cases, we decode all in_n elements of in and set\n    // the remaining elements up to n to be the default Variant() value.\n    const int64_t real_n = n < in_n ? n : in_n;\n    for (int64_t i = 0; i < real_n; ++i) {\n      data[i] = in.variant_val(i);\n      if (!DecodeUnaryVariant(&data[i])) {\n        LOG(ERROR) << \"Could not decode variant with type_name: \\\"\"\n                   << data[i].TypeName()\n                   << \"\\\".  Perhaps you forgot to register a \"\n                      \"decoder via REGISTER_UNARY_VARIANT_DECODE_FUNCTION?\";\n        buf->Unref();\n        return nullptr;\n      }\n    }\n    for (int64_t i = in_n; i < n; ++i) {\n      data[i] = Variant();\n    }\n  }\n  return buf;\n}\n\n// fp16 and bfloat16 are opaque to the protobuf, so we deserialize these\n// identical to uint16 but with data stored in half_val instead of int_val (ie.,\n// we don't use ProtoHelper<uint16>).\ntemplate <>\nTensorBuffer* FromProtoField<Eigen::half>(Allocator* a, const TensorProto& in,\n                                          int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<Eigen::half>* buf = new Buffer<Eigen::half>(a, n);\n  uint16* data = buf->template base<uint16>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n  const int64_t in_n = in.half_val().size();\n  auto begin = in.half_val().begin();\n  if (n <= in_n) {\n    std::copy_n(begin, n, data);\n  } else if (in_n > 0) {\n    std::copy_n(begin, in_n, data);\n    const uint16 last = *(data + in_n - 1);\n    std::fill_n(data + in_n, n - in_n, last);\n  } else {\n    std::fill_n(data, n, 0);\n  }\n  return buf;\n}\n\ntemplate <>\nTensorBuffer* FromProtoField<bfloat16>(Allocator* a, const TensorProto& in,\n                                       int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<bfloat16>* buf = new Buffer<bfloat16>(a, n);\n  uint16* data = buf->template base<uint16>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n  const int64_t in_n = in.half_val().size();\n  auto begin = in.half_val().begin();\n  if (n <= in_n) {\n    std::copy_n(begin, n, data);\n  } else if (in_n > 0) {\n    std::copy_n(begin, in_n, data);\n    const uint16 last = *(data + in_n - 1);\n    std::fill_n(data + in_n, n - in_n, last);\n  } else {\n    std::fill_n(data, n, 0);\n  }\n  return buf;\n}\n\n// Copies T[n] stored in the buffer \"in\" into the repeated field in\n// \"out\" corresponding to type T.\ntemplate <typename T>\nvoid ToProtoField(const TensorBuffer& in, int64_t n, TensorProto* out) {\n  const T* data = in.base<const T>();\n  // NOTE: T may not the same as\n  // ProtoHelper<T>::FieldType::value_type.  E.g., T==int16,\n  // ProtoHelper<T>::FieldType::value_type==int32.  If performance is\n  // critical, we can specialize T=float and do memcpy directly.\n  ProtoHelper<T>::Fill(data, n, out);\n}\n\nvoid RefIfNonNull(core::RefCounted* buf) {\n  if (buf) buf->Ref();\n}\n\nvoid UnrefIfNonNull(core::RefCounted* buf) {\n  if (buf) buf->Unref();\n}\n\n}  // end namespace\n\nTensor::Tensor() : Tensor(DT_FLOAT) {}\n\nTensor::Tensor(DataType type) : shape_(type), buf_(nullptr) {}\n\nTensor::Tensor(DataType type, const TensorShape& shape, TensorBuffer* buf)\n    : shape_(shape), buf_(buf) {\n  set_dtype(type);\n  RefIfNonNull(buf);\n}\n\nTensor::Tensor(DataType type, TensorShape shape,\n               core::RefCountPtr<TensorBuffer> buf)\n    : shape_(std::move(shape)), buf_(buf.release()) {\n  set_dtype(type);\n}\n\nbool Tensor::IsInitialized() const {\n  return (buf_ != nullptr && buf_->data() != nullptr) ||\n         shape_.num_elements() == 0;\n}\n\nvoid Tensor::CheckType(DataType expected_dtype) const {\n  CHECK_EQ(dtype(), expected_dtype)\n      << \" \" << DataTypeString(expected_dtype) << \" expected, got \"\n      << DataTypeString(dtype());\n}\n\nvoid Tensor::CheckTypeAndIsAligned(DataType expected_dtype) const {\n  CHECK_EQ(dtype(), expected_dtype)\n      << \" \" << DataTypeString(expected_dtype) << \" expected, got \"\n      << DataTypeString(dtype());\n  CHECK(IsAligned()) << \"ptr = \" << base<void>();\n}\n\nvoid Tensor::CheckIsAlignedAndSingleElement() const {\n  CHECK(IsAligned()) << \"Aligned and single element\";\n  CHECK_EQ(1, NumElements()) << \"Must have a one element tensor\";\n}\n\nTensor::~Tensor() { UnrefIfNonNull(buf_); }\n\nStatus Tensor::BitcastFrom(const Tensor& other, DataType dtype,\n                           const TensorShape& shape) {\n  int in_size = DataTypeSize(other.dtype());\n  int out_size = DataTypeSize(dtype);\n  if (in_size == 0) {\n    return errors::InvalidArgument(\"other tensor has zero-sized data type\");\n  }\n  if (out_size == 0) {\n    return errors::InvalidArgument(\"specified output type is zero-sized\");\n  }\n  if (shape.num_elements() * out_size !=\n      other.shape().num_elements() * in_size) {\n    return errors::InvalidArgument(\n        \"input and output shapes/data type sizes are not compatible\");\n  }\n  shape_ = shape;\n  shape_.set_data_type(dtype);\n  if (buf_ != other.buf_) {\n    UnrefIfNonNull(buf_);\n    buf_ = other.buf_;\n    RefIfNonNull(buf_);\n  }\n  return Status::OK();\n}\n\n// Notice that buf_ either points to a regular TensorBuffer or a SubBuffer.\n// For the latter case, we have to make sure that the refcount is\n// one both for the SubBuffer _and_ the underlying TensorBuffer.\nbool Tensor::RefCountIsOne() const {\n  return buf_ != nullptr && buf_->RefCountIsOne() &&\n         buf_->root_buffer()->RefCountIsOne() && buf_->OwnsMemory();\n}\n\n// The macro CASES() expands to a switch statement conditioned on\n// TYPE_ENUM. Each case expands the STMTS after a typedef for T.\n#define SINGLE_ARG(...) __VA_ARGS__\n#define CASE(TYPE, STMTS)               \\\n  case DataTypeToEnum<TYPE>::value: {   \\\n    typedef TF_ATTRIBUTE_UNUSED TYPE T; \\\n    STMTS;                              \\\n    break;                              \\\n  }\n#define CASES_WITH_DEFAULT(TYPE_ENUM, STMTS, INVALID, DEFAULT) \\\n  switch (TYPE_ENUM) {                                         \\\n    CASE(float, SINGLE_ARG(STMTS))                             \\\n    CASE(double, SINGLE_ARG(STMTS))                            \\\n    CASE(int32, SINGLE_ARG(STMTS))                             \\\n    CASE(uint8, SINGLE_ARG(STMTS))                             \\\n    CASE(uint16, SINGLE_ARG(STMTS))                            \\\n    CASE(uint32, SINGLE_ARG(STMTS))                            \\\n    CASE(uint64, SINGLE_ARG(STMTS))                            \\\n    CASE(int16, SINGLE_ARG(STMTS))                             \\\n    CASE(int8, SINGLE_ARG(STMTS))                              \\\n    CASE(tstring, SINGLE_ARG(STMTS))                           \\\n    CASE(complex64, SINGLE_ARG(STMTS))                         \\\n    CASE(complex128, SINGLE_ARG(STMTS))                        \\\n    CASE(int64_t, SINGLE_ARG(STMTS))                           \\\n    CASE(bool, SINGLE_ARG(STMTS))                              \\\n    CASE(qint32, SINGLE_ARG(STMTS))                            \\\n    CASE(quint8, SINGLE_ARG(STMTS))                            \\\n    CASE(qint8, SINGLE_ARG(STMTS))                             \\\n    CASE(quint16, SINGLE_ARG(STMTS))                           \\\n    CASE(qint16, SINGLE_ARG(STMTS))                            \\\n    CASE(bfloat16, SINGLE_ARG(STMTS))                          \\\n    CASE(Eigen::half, SINGLE_ARG(STMTS))                       \\\n    CASE(ResourceHandle, SINGLE_ARG(STMTS))                    \\\n    CASE(Variant, SINGLE_ARG(STMTS))                           \\\n    case DT_INVALID:                                           \\\n      INVALID;                                                 \\\n      break;                                                   \\\n    default:                                                   \\\n      DEFAULT;                                                 \\\n      break;                                                   \\\n  }\n\n#define CASES(TYPE_ENUM, STMTS)                                      \\\n  CASES_WITH_DEFAULT(TYPE_ENUM, STMTS, LOG(FATAL) << \"Type not set\"; \\\n                     , LOG(FATAL) << \"Unexpected type: \" << TYPE_ENUM;)\n\nTensor::Tensor(Allocator* a, DataType type, const TensorShape& shape)\n    : shape_(shape), buf_(nullptr) {\n  set_dtype(type);\n  CHECK_NOTNULL(a);\n  if (shape_.num_elements() > 0 || a->AllocatesOpaqueHandle()) {\n    CASES(type, buf_ = new Buffer<T>(a, shape.num_elements()));\n  }\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown\", LogMemory::UNKNOWN_STEP_ID,\n                                      *this);\n  }\n}\n\nTensor::Tensor(Allocator* a, DataType type, const TensorShape& shape,\n               const AllocationAttributes& allocation_attr)\n    : shape_(shape), buf_(nullptr) {\n  set_dtype(type);\n  CHECK_NOTNULL(a);\n  if (shape_.num_elements() > 0 || a->AllocatesOpaqueHandle()) {\n    CASES(type, buf_ = new Buffer<T>(a, shape.num_elements(), allocation_attr));\n  }\n  if (MemoryLoggingEnabled() && !allocation_attr.allocation_will_be_logged &&\n      buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (with attributes)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n}\n\nStatus Tensor::BuildTensor(DataType type, const TensorShape& shape,\n                           Tensor* out_tensor) {\n  // Avoid crashes due to invalid or unsupported types.\n  CASES_WITH_DEFAULT(\n      type, {}, return errors::InvalidArgument(\"Type not set\"),\n      return errors::InvalidArgument(\"Unexpected type: \", DataType_Name(type)));\n  *out_tensor = Tensor(type, shape);\n  return Status::OK();\n}\n\n// NOTE(mrry): The default allocator for a Tensor (when none is specified) is\n// the default CPU allocator for NUMA zone 0. Accessing that currently involves\n// acquiring a lock, which guards initialization of the per-NUMA zone\n// allocators, and becomes highly contended.\n//\n// Note also that it would be better if all Tensor allocations required the user\n// to specify an allocator, for purposes of accounting, etc. However, the\n// default allocator is widely used throughout the codebase and in client code.\nstatic Allocator* get_default_cpu_allocator() {\n  static Allocator* default_cpu_allocator =\n      cpu_allocator(port::kNUMANoAffinity);\n  return default_cpu_allocator;\n}\n\nTensor::Tensor(DataType type, const TensorShape& shape)\n    : Tensor(get_default_cpu_allocator(), type, shape) {}\n\nbool Tensor::HostScalarTensorBufferBase::GetAllocatedBytes(\n    size_t* out_bytes) const {\n  // `this->FillAllocationDescription()` never sets allocated bytes information,\n  // so we can short-circuit the construction of an `AllocationDescription`.\n  return false;\n}\n\nvoid Tensor::HostScalarTensorBufferBase::FillAllocationDescription(\n    AllocationDescription* proto) const {\n  proto->set_requested_bytes(size());\n  proto->set_allocator_name(\"HostScalarTensorBuffer\");\n  proto->set_ptr(reinterpret_cast<uintptr_t>(data()));\n}\n\ntemplate <typename T>\nclass SubBuffer : public TensorBuffer {\n public:\n  // This buffer is an alias to buf[delta, delta + n).\n  SubBuffer(TensorBuffer* buf, int64_t delta, int64_t n)\n      : TensorBuffer(buf->base<T>() + delta),\n        root_(buf->root_buffer()),\n        elem_(n) {\n    // Sanity check. The caller should ensure the sub buffer is valid.\n    CHECK_LE(root_->base<T>(), this->base<T>());\n    T* root_limit = root_->base<T>() + root_->size() / sizeof(T);\n    CHECK_LE(this->base<T>(), root_limit);\n    CHECK_LE(this->base<T>() + n, root_limit);\n    // Hold a ref of the underlying root buffer.\n    // NOTE: 'buf' is a sub-buffer inside the 'root_' buffer.\n    root_->Ref();\n  }\n\n  size_t size() const override { return sizeof(T) * elem_; }\n  TensorBuffer* root_buffer() override { return root_; }\n  bool GetAllocatedBytes(size_t* out_bytes) const override {\n    return root_->GetAllocatedBytes(out_bytes);\n  }\n  void FillAllocationDescription(AllocationDescription* proto) const override {\n    root_->FillAllocationDescription(proto);\n  }\n\n private:\n  TensorBuffer* root_;\n  int64_t elem_;\n\n  ~SubBuffer() override { root_->Unref(); }\n\n  TF_DISALLOW_COPY_AND_ASSIGN(SubBuffer);\n};\n\nTensor Tensor::Slice(int64_t start, int64_t limit) const {\n  CHECK_GE(dims(), 1);\n  CHECK_LE(0, start);\n  CHECK_LE(start, limit);\n  int64_t dim0_size = shape_.dim_size(0);\n  CHECK_LE(limit, dim0_size);\n  if ((start == 0) && (limit == dim0_size)) {\n    return *this;\n  }\n  Tensor ret;\n  ret.shape_ = shape_;\n  ret.set_dtype(dtype());\n  ret.buf_ = nullptr;\n  if (dim0_size > 0) {\n    const int64_t elems_per_dim0 = NumElements() / dim0_size;\n    const int64_t delta = start * elems_per_dim0;\n    dim0_size = limit - start;\n    ret.shape_.set_dim(0, dim0_size);\n    const int64_t num_elems = dim0_size * elems_per_dim0;\n    if (buf_) {\n      DataType dt = dtype();\n      CASES(dt, ret.buf_ = new SubBuffer<T>(buf_, delta, num_elems));\n    }\n  }\n  return ret;\n}\n\nTensor Tensor::SubSlice(int64_t index) const {\n  CHECK_GE(dims(), 1);  // Crash ok.\n  CHECK_LE(0, index);   // Crash ok.\n  int64_t dim0_size = shape_.dim_size(0);\n  CHECK_LE(index, dim0_size);  // Crash ok.\n  Tensor ret;\n  ret.shape_ = shape_;\n  ret.shape_.RemoveDim(0);\n  ret.set_dtype(dtype());\n  ret.buf_ = nullptr;\n  if (dim0_size > 0) {\n    const int64_t elems_per_dim0 = NumElements() / dim0_size;\n    const int64_t delta = index * elems_per_dim0;\n    const int64_t num_elems = elems_per_dim0;\n    if (buf_) {\n      DataType dt = dtype();\n      CASES(dt, ret.buf_ = new SubBuffer<T>(buf_, delta, num_elems));\n    }\n  }\n  return ret;\n}\n\nbool Tensor::FromProto(const TensorProto& proto) {\n  return FromProto(get_default_cpu_allocator(), proto);\n}\n\nbool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n  CHECK_NOTNULL(a);\n  TensorBuffer* p = nullptr;\n  if (!TensorShape::IsValid(proto.tensor_shape())) return false;\n  if (proto.dtype() == DT_INVALID) return false;\n  TensorShape shape(proto.tensor_shape());\n  const int64_t N = shape.num_elements();\n  if (N > 0 && proto.dtype()) {\n    bool dtype_error = false;\n    if (!proto.tensor_content().empty()) {\n      const auto& content = proto.tensor_content();\n      CASES_WITH_DEFAULT(proto.dtype(), p = Helper<T>::Decode(a, content, N),\n                         dtype_error = true, dtype_error = true);\n    } else {\n      CASES_WITH_DEFAULT(proto.dtype(), p = FromProtoField<T>(a, proto, N),\n                         dtype_error = true, dtype_error = true);\n    }\n    if (dtype_error || p == nullptr) return false;\n  }\n  shape_ = shape;\n  set_dtype(proto.dtype());\n  UnrefIfNonNull(buf_);\n  buf_ = p;\n  // TODO(misard) add tracking of which kernels and steps are calling\n  // FromProto.\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (from Proto)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n  return true;\n}\n\nvoid Tensor::AsProtoField(TensorProto* proto) const {\n  proto->Clear();\n  shape_.AsProto(proto->mutable_tensor_shape());\n  proto->set_dtype(dtype());\n  if (buf_) {\n    CASES(dtype(), ToProtoField<T>(*buf_, shape_.num_elements(), proto));\n  }\n}\n\nvoid Tensor::AsProtoTensorContent(TensorProto* proto) const {\n  proto->Clear();\n  proto->set_dtype(dtype());\n  shape_.AsProto(proto->mutable_tensor_shape());\n  if (buf_) {\n    CASES(dtype(), Helper<T>::Encode(buf_, shape_.num_elements(),\n                                     proto->mutable_tensor_content()));\n  }\n}\n\nsize_t Tensor::TotalBytes() const {\n  if (shape_.num_elements() == 0) return 0;\n  CHECK(buf_) << \"null buf_ with non-zero shape size \" << shape_.num_elements();\n  CASES(dtype(), return Helper<T>::TotalBytes(buf_, shape_.num_elements()));\n  return 0;  // Makes compiler happy.\n}\n\nsize_t Tensor::AllocatedBytes() const {\n  if (buf_) {\n    size_t ret;\n    if (buf_->GetAllocatedBytes(&ret)) {\n      return ret;\n    }\n  }\n  return TotalBytes();\n}\n\nbool Tensor::CanUseDMA() const {\n  CASES(dtype(), return is_simple_type<T>::value);\n  return false;  // Makes compiler happy.\n}\n\n#undef CASES\n#undef CASE\n\nnamespace {\n\n// StrCat and StrAppend don't support Eigen::half directly at the moment, and\n// we would like to keep them compatible with their absl counterparts, for ease\n// of migration. We could rely on errors::internal::PrepareForStrCat() but the\n// logic is so simple we can just replicate it here, where it is close to its\n// usage and easy to change later. And there's the extra benefit of not\n// accessing an 'internal' namespace.\ninline const strings::AlphaNum& PrintOneElement(const strings::AlphaNum& a,\n                                                bool print_v2) {\n  return a;\n}\ninline string PrintOneElement(const tstring& a, bool print_v2) {\n  if (print_v2) {\n    return \"\\\"\" + absl::Utf8SafeCEscape(a) + \"\\\"\";\n  } else {\n    return absl::Utf8SafeCEscape(a);\n  }\n}\ninline float PrintOneElement(const Eigen::half& h, bool print_v2) {\n  return static_cast<float>(h);\n}\n\ninline float PrintOneElement(bfloat16 f, bool print_v2) {\n  return static_cast<float>(f);\n}\n\n// Print from left dim to right dim recursively.\ntemplate <typename T>\nvoid PrintOneDim(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n                 int64_t limit, int shape_size, const T* data,\n                 int64_t* data_index, string* result) {\n  if (*data_index >= limit) return;\n  int64_t element_count = shape[dim_index];\n  // We have reached the right-most dimension of the tensor.\n  if (dim_index == shape_size - 1) {\n    for (int64_t i = 0; i < element_count; i++) {\n      if (*data_index >= limit) {\n        // If not enough elements has been printed, append \"...\".\n        if (dim_index != 0) {\n          strings::StrAppend(result, \"...\");\n        }\n        return;\n      }\n      if (i > 0) strings::StrAppend(result, \" \");\n      strings::StrAppend(result, PrintOneElement(data[(*data_index)++], false));\n    }\n    return;\n  }\n  // Loop every element of one dim.\n  for (int64_t i = 0; i < element_count; i++) {\n    bool flag = false;\n    if (*data_index < limit) {\n      strings::StrAppend(result, \"[\");\n      flag = true;\n    }\n    // As for each element, print the sub-dim.\n    PrintOneDim(dim_index + 1, shape, limit, shape_size, data, data_index,\n                result);\n    if (*data_index < limit || flag) {\n      strings::StrAppend(result, \"]\");\n      flag = false;\n    }\n  }\n}\n\n// Appends the spacing between elements for a given dim onto a result string\nvoid PrintDimSpacing(int dim_index, int num_dims, string* result) {\n  if (dim_index == num_dims - 1) {\n    strings::StrAppend(result, \" \");\n    return;\n  }\n  for (int j = 0; j < num_dims - dim_index - 1; j++) {\n    strings::StrAppend(result, \"\\n\");\n  }\n  for (int j = 0; j <= dim_index; j++) {\n    strings::StrAppend(result, \" \");\n  }\n}\n\n// Print from left dim to right dim recursively.\ntemplate <typename T>\nvoid PrintOneDimV2(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n                   int64_t num_elts_at_ends, int num_dims, const T* data,\n                   int64_t data_index, string* result) {\n  // We have recursed beyond all the dimensions into a single element\n  // of the tensor.\n  if (dim_index == num_dims) {\n    strings::StrAppend(result, PrintOneElement(data[data_index], true));\n    return;\n  }\n\n  strings::StrAppend(result, \"[\");\n  int64_t element_count = shape[dim_index];\n  int64_t start_of_end =\n      std::max(num_elts_at_ends, element_count - num_elts_at_ends);\n\n  // Loop every element of one dim.\n  int64_t elements_per_iter = 1;\n  for (int i = dim_index + 1; i < num_dims; i++) {\n    elements_per_iter *= shape[i];\n  }\n  for (int64_t i = 0; (i < num_elts_at_ends) && (i < element_count); i++) {\n    if (i > 0) {\n      PrintDimSpacing(dim_index, num_dims, result);\n    }\n\n    // As for each element, print the sub-dim.\n    PrintOneDimV2(dim_index + 1, shape, num_elts_at_ends, num_dims, data,\n                  data_index + elements_per_iter * i, result);\n  }\n  if (element_count > 2 * num_elts_at_ends) {\n    PrintDimSpacing(dim_index, num_dims, result);\n    strings::StrAppend(result, \"...\");\n  }\n  for (int64_t i = start_of_end; i < element_count; i++) {\n    // As for each element, print the sub-dim.\n    PrintDimSpacing(dim_index, num_dims, result);\n    PrintOneDimV2(dim_index + 1, shape, num_elts_at_ends, num_dims, data,\n                  data_index + elements_per_iter * i, result);\n  }\n\n  strings::StrAppend(result, \"]\");\n}\n\ntemplate <typename T>\nstring SummarizeArray(int64_t limit, int64_t num_elts,\n                      const TensorShape& tensor_shape, const char* data,\n                      const bool print_v2) {\n  string ret;\n  const T* array = reinterpret_cast<const T*>(data);\n\n  const gtl::InlinedVector<int64_t, 4> shape = tensor_shape.dim_sizes();\n  if (shape.empty()) {\n    for (int64_t i = 0; i < limit; ++i) {\n      if (i > 0) strings::StrAppend(&ret, \" \");\n      strings::StrAppend(&ret, PrintOneElement(array[i], print_v2));\n    }\n    if (num_elts > limit) strings::StrAppend(&ret, \"...\");\n    return ret;\n  }\n  if (print_v2) {\n    const int num_dims = tensor_shape.dims();\n    PrintOneDimV2(0, shape, limit, num_dims, array, 0, &ret);\n  } else {\n    int64_t data_index = 0;\n    const int shape_size = tensor_shape.dims();\n    PrintOneDim(0, shape, limit, shape_size, array, &data_index, &ret);\n\n    if (num_elts > limit) strings::StrAppend(&ret, \"...\");\n  }\n\n  return ret;\n}\n}  // namespace\n\nstring Tensor::SummarizeValue(int64_t max_entries, bool print_v2) const {\n  const int64_t num_elts = NumElements();\n  if (max_entries < 0) {\n    max_entries = num_elts;\n  }\n  size_t limit = std::min(max_entries, num_elts);\n  if ((limit > 0) && (buf_ == nullptr)) {\n    return strings::StrCat(\"uninitialized Tensor of \", num_elts,\n                           \" elements of type \", dtype());\n  }\n  const char* data = limit > 0 ? tensor_data().data() : nullptr;\n  switch (dtype()) {\n    case DT_BFLOAT16:\n      return SummarizeArray<bfloat16>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_HALF:\n      return SummarizeArray<Eigen::half>(limit, num_elts, shape_, data,\n                                         print_v2);\n      break;\n    case DT_FLOAT:\n      return SummarizeArray<float>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_DOUBLE:\n      return SummarizeArray<double>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_UINT32:\n      return SummarizeArray<uint32>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_INT32:\n      return SummarizeArray<int32>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_UINT8:\n    case DT_QUINT8:\n      return SummarizeArray<uint8>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_UINT16:\n    case DT_QUINT16:\n      return SummarizeArray<uint16>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_INT16:\n    case DT_QINT16:\n      return SummarizeArray<int16>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_INT8:\n    case DT_QINT8:\n      return SummarizeArray<int8>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_UINT64:\n      return SummarizeArray<uint64>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_INT64:\n      return SummarizeArray<int64_t>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_BOOL:\n      // TODO(tucker): Is it better to emit \"True False...\"?  This\n      // will emit \"1 0...\" which is more compact.\n      return SummarizeArray<bool>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_STRING:\n      return SummarizeArray<tstring>(limit, num_elts, shape_, data, print_v2);\n      break;\n    default: {\n      // All irregular cases\n      string ret;\n      if (print_v2 && (dims() > 0)) {\n        strings::StrAppend(&ret, \"[\");\n      }\n      // TODO(irving): Don't call flat every time around this\n      // loop.\n      for (size_t i = 0; i < limit; ++i) {\n        if (i > 0) strings::StrAppend(&ret, \" \");\n        switch (dtype()) {\n          case DT_VARIANT: {\n            const Variant& v = flat<Variant>()(i);\n            strings::StrAppend(&ret, \"<\", v.SummarizeValue(), \">\");\n          } break;\n          case DT_RESOURCE: {\n            const ResourceHandle& r = flat<ResourceHandle>()(i);\n            strings::StrAppend(&ret, \"<\", r.SummarizeValue(), \">\");\n          } break;\n          default:\n            // TODO(zhifengc, josh11b): Pretty-print other types (bool,\n            // complex64, quantized).\n            strings::StrAppend(&ret, \"?\");\n        }\n      }\n      if (max_entries < num_elts) strings::StrAppend(&ret, \"...\");\n      if (print_v2 && (dims() > 0)) {\n        strings::StrAppend(&ret, \"]\");\n      }\n      return ret;\n    }\n  }\n}\n\nStringPiece Tensor::tensor_data() const {\n  if (buf_ == nullptr) return StringPiece();  // Don't die for empty tensors\n  return StringPiece(static_cast<char*>(buf_->data()), TotalBytes());\n}\n\nvoid* Tensor::data() const {\n  if (buf_ == nullptr) return nullptr;  // Don't die for empty tensors\n  return static_cast<void*>(buf_->data());\n}\n\nbool Tensor::SharesBufferWith(const Tensor& b) const {\n  return buf_ != nullptr && b.buf_ != nullptr &&\n         buf_->root_buffer() == b.buf_->root_buffer();\n}\n\nstring Tensor::DebugString(int num_values) const {\n  return strings::StrCat(\"Tensor<type: \", DataTypeString(dtype()),\n                         \" shape: \", shape().DebugString(),\n                         \" values: \", SummarizeValue(num_values), \">\");\n}\n\nstring Tensor::DeviceSafeDebugString() const {\n  return strings::StrCat(\"Tensor<type: \", DataTypeString(dtype()),\n                         \" shape: \", shape().DebugString(), \">\");\n}\n\nvoid Tensor::FillDescription(TensorDescription* description) const {\n  description->set_dtype(dtype());\n  shape().AsProto(description->mutable_shape());\n  if (buf_ != nullptr && buf_->data() != nullptr) {\n    buf_->FillAllocationDescription(\n        description->mutable_allocation_description());\n  }\n}\n\ngtl::InlinedVector<int64_t, 4> Tensor::ComputeFlatInnerDims(\n    gtl::ArraySlice<int64_t> orig, int64_t num_out_dims) {\n  gtl::InlinedVector<int64_t, 4> out_dims(num_out_dims, 0);\n  int64_t offset = orig.size() - num_out_dims;\n  for (int64_t out_dim = num_out_dims - 1; out_dim >= 0; --out_dim) {\n    const int64_t in_dim = out_dim + offset;\n    out_dims[out_dim] = in_dim < 0 ? 1 : orig[in_dim];\n  }\n  for (int64_t in_dim = 0; in_dim < offset; ++in_dim) {\n    out_dims[0] *= orig[in_dim];\n  }\n  return out_dims;\n}\n\ngtl::InlinedVector<int64_t, 4> Tensor::ComputeFlatOuterDims(\n    gtl::ArraySlice<int64_t> orig, int64_t num_out_dims) {\n  gtl::InlinedVector<int64_t, 4> out_dims(num_out_dims, 0);\n  for (int64_t out_dim = 0; out_dim <= num_out_dims - 1; ++out_dim) {\n    out_dims[out_dim] = out_dim >= orig.size() ? 1 : orig[out_dim];\n  }\n  for (int64_t in_dim = num_out_dims; in_dim < orig.size(); ++in_dim) {\n    out_dims[num_out_dims - 1] *= orig[in_dim];\n  }\n  return out_dims;\n}\n\n}  // namespace tensorflow\n"], "fixing_code": ["load(\n    \"//tensorflow/core/platform:build_config.bzl\",\n    \"tf_kernel_tests_linkstatic\",\n    \"tf_proto_library\",\n    \"tf_pyclif_proto_library\",\n)\nload(\n    \"//tensorflow:tensorflow.bzl\",\n    \"tf_cc_test\",\n    \"tf_cc_tests\",\n    \"tf_copts\",\n    \"tf_cuda_library\",\n)\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"filegroup\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_cuda_cc_test\")\n\n# buildifier: disable=same-origin-load\nload(\"//tensorflow:tensorflow.bzl\", \"tf_generate_proto_text_sources\")\n\n# buildifier: disable=same-origin-load\nload(\n    \"//tensorflow/core/platform:build_config_root.bzl\",\n    \"if_static\",\n    \"tf_cuda_tests_tags\",\n)\nload(\n    \"//tensorflow/core/platform:rules_cc.bzl\",\n    \"cc_library\",\n)\n\npackage(\n    default_visibility = [\n        \"//tensorflow/core:__subpackages__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n    licenses = [\"notice\"],\n)\n\n# Export all header files for which we do not yet provide a dedicated build\n# rule. This avoids breaking all the rules in tensorflow/core/BUILD.\nexports_files(\n    srcs = [\n        \"allocator_registry.h\",\n        \"cancellation.h\",\n        \"collective.h\",\n        \"control_flow.h\",\n        \"dataset.h\",\n        \"dataset_stateful_op_allowlist.h\",\n        \"device.h\",\n        \"device_base.h\",\n        \"device_factory.h\",\n        \"function.h\",\n        \"function_handle_cache.h\",\n        \"graph_def_util.h\",\n        \"graph_to_functiondef.h\",\n        \"kernel_def_builder.h\",\n        \"kernel_def_util.h\",\n        \"logging.h\",\n        \"lookup_interface.h\",\n        \"memory_types.h\",\n        \"metrics.h\",\n        \"model.h\",\n        \"node_def_builder.h\",\n        \"numeric_op.h\",\n        \"op_kernel.h\",\n        \"op_requires.h\",\n        \"op_segment.h\",\n        \"ops_util.h\",\n        \"partial_tensor_shape.h\",\n        \"queue_interface.h\",\n        \"reader_interface.h\",\n        \"reader_op_kernel.h\",\n        \"register_types_traits.h\",\n        \"rendezvous.h\",\n        \"resource_mgr.h\",\n        \"resource_op_kernel.h\",\n        \"resource_var.h\",\n        \"rng_alg.h\",\n        \"run_handler.h\",\n        \"run_handler_util.h\",\n        \"session_state.h\",\n        \"shared_ptr_variant.h\",\n        \"stats_aggregator.h\",\n        \"tensor_reference.h\",\n        \"tensor_slice.h\",\n        \"tensor_util.h\",\n        \"thread_factory.h\",\n        \"tracking_allocator.h\",\n        \"versions.h\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__pkg__\",\n        \"//tensorflow/core/common_runtime:__pkg__\",\n    ],\n)\n\n# List of exported test source files that do not yet have local build rules.\nexports_files(\n    srcs = [\n        \"op_gen_lib_test.cc\",\n        \"op_segment_test.cc\",\n        \"run_handler_test.cc\",\n        \"run_handler_util_test.cc\",\n        \"variant_op_copy_test.cc\",\n    ],\n    visibility = [\"//tensorflow/core:__pkg__\"],\n)\n\n# List of exported proto source files.\nexports_files(\n    srcs = [\n        \"allocation_description.proto\",\n        \"api_def.proto\",\n        \"attr_value.proto\",\n        \"cost_graph.proto\",\n        \"dataset_metadata.proto\",\n        \"dataset_options.proto\",\n        \"device_attributes.proto\",\n        \"full_type.proto\",\n        \"function.proto\",\n        \"graph.proto\",\n        \"graph_transfer_info.proto\",\n        \"kernel_def.proto\",\n        \"log_memory.proto\",\n        \"model.proto\",\n        \"node_def.proto\",\n        \"op_def.proto\",\n        \"reader_base.proto\",\n        \"resource_handle.proto\",\n        \"step_stats.proto\",\n        \"summary.proto\",\n        \"tensor.proto\",\n        \"tensor_description.proto\",\n        \"tensor_shape.proto\",\n        \"tensor_slice.proto\",\n        \"types.proto\",\n        \"variable.proto\",\n        \"versions.proto\",\n    ],\n    visibility = [\n        \"//tensorflow:internal\",\n        \"//tensorflow/core:__pkg__\",\n    ],\n)\n\nexports_files(\n    [\n        \"attr_value_util.h\",\n        \"common_shape_fns.h\",\n        \"kernel_shape_util.h\",\n        \"node_def_util.h\",\n        \"node_properties.h\",\n        \"op.h\",\n        \"op_def_builder.h\",\n        \"full_type_util.h\",\n        \"full_type_inference_util.h\",\n        \"op_def_util.h\",\n        \"shape_inference.h\",\n    ],\n    visibility = [\"//tensorflow/core:__subpackages__\"],\n)\n\n# The following filegroups are needed since globbing across packages boundaries\n# will just fail silently (see 3rd caveat at\n# https://docs.bazel.build/versions/master/be/functions.html#glob).\n\n# Files needed for core:framework_internal_impl.\nfilegroup(\n    name = \"framework_internal_private_hdrs\",\n    srcs = [\n        \"allocator.h\",\n        \"allocator_registry.h\",\n        \"attr_value_util.h\",\n        \"bfloat16.h\",\n        \"bounds_check.h\",\n        \"cancellation.h\",\n        \"collective.h\",\n        \"common_shape_fns.h\",\n        \"control_flow.h\",\n        \"dataset.h\",\n        \"dataset_stateful_op_allowlist.h\",\n        \"device.h\",\n        \"device_base.h\",\n        \"device_factory.h\",\n        \"full_type_inference_util.h\",\n        \"full_type_util.h\",\n        \"function.h\",\n        \"function_handle_cache.h\",\n        \"graph_def_util.h\",\n        \"graph_to_functiondef.h\",\n        \"kernel_def_builder.h\",\n        \"kernel_def_util.h\",\n        \"kernel_shape_util.h\",\n        \"local_rendezvous.h\",\n        \"log_memory.h\",\n        \"logging.h\",\n        \"lookup_interface.h\",\n        \"memory_types.h\",\n        \"metrics.h\",\n        \"model.h\",\n        \"node_def_builder.h\",\n        \"node_def_util.h\",\n        \"node_properties.h\",\n        \"numeric_op.h\",\n        \"numeric_types.h\",\n        \"op.h\",\n        \"op_def_builder.h\",\n        \"op_def_util.h\",\n        \"op_kernel.h\",\n        \"op_requires.h\",\n        \"op_segment.h\",\n        \"ops_util.h\",\n        \"partial_tensor_shape.h\",\n        \"queue_interface.h\",\n        \"reader_interface.h\",\n        \"reader_op_kernel.h\",\n        \"register_types.h\",\n        \"register_types_traits.h\",\n        \"rendezvous.h\",\n        \"resource_base.h\",\n        \"resource_handle.h\",\n        \"resource_mgr.h\",\n        \"resource_op_kernel.h\",\n        \"resource_var.h\",\n        \"run_handler.h\",\n        \"run_handler_util.h\",\n        \"session_state.h\",\n        \"shape_inference.h\",\n        \"shared_ptr_variant.h\",\n        \"stats_aggregator.h\",\n        \"tensor.h\",\n        \"tensor_key.h\",\n        \"tensor_reference.h\",\n        \"tensor_shape.h\",\n        \"tensor_slice.h\",\n        \"tensor_types.h\",\n        \"tensor_util.h\",\n        \"thread_factory.h\",\n        \"tracking_allocator.h\",\n        \"type_index.h\",\n        \"type_traits.h\",\n        \"typed_allocator.h\",\n        \"types.h\",\n        \"variant.h\",\n        \"variant_encode_decode.h\",\n        \"variant_op_registry.h\",\n        \"variant_tensor_data.h\",\n        \"versions.h\",\n        \"//tensorflow/core/framework/registration:options.h\",\n        \"//tensorflow/core/framework/registration:registration.h\",\n    ],\n)\n\nfilegroup(\n    name = \"framework_internal_impl_srcs\",\n    srcs = [\n        \"cancellation.cc\",\n        \"collective.cc\",\n        \"dataset.cc\",\n        \"device.cc\",\n        \"device_base.cc\",\n        \"device_factory.cc\",\n        \"function.cc\",\n        \"function_handle_cache.cc\",\n        \"graph_def_util.cc\",\n        \"graph_to_functiondef.cc\",\n        \"kernel_def_builder.cc\",\n        \"kernel_def_util.cc\",\n        \"load_library.cc\",\n        \"local_rendezvous.cc\",\n        \"logging.cc\",\n        \"lookup_interface.cc\",\n        \"memory_types.cc\",\n        \"metrics.cc\",\n        \"model.cc\",\n        \"node_def_builder.cc\",\n        \"op_kernel.cc\",\n        \"op_segment.cc\",\n        \"ops_util.cc\",\n        \"rendezvous.cc\",\n        \"resource_mgr.cc\",\n        \"resource_var.cc\",\n        \"run_handler.cc\",\n        \"run_handler_util.cc\",\n        \"tensor_slice.cc\",\n        \"tensor_util.cc\",\n        \"versions.cc\",\n    ],\n)\n\n# Files needed for core:mobile_srcs_(no|only)_runtime.\nfilegroup(\n    name = \"mobile_srcs_no_runtime\",\n    srcs = [\n        \"allocator.cc\",\n        \"allocator.h\",\n        \"allocator_registry.cc\",\n        \"allocator_registry.h\",\n        \"bfloat16.cc\",\n        \"bfloat16.h\",\n        \"bounds_check.h\",\n        \"cpu_allocator_impl.cc\",\n        \"kernel_shape_util.cc\",\n        \"kernel_shape_util.h\",\n        \"log_memory.cc\",\n        \"log_memory.h\",\n        \"numeric_types.h\",\n        \"op_requires.h\",\n        \"ops_util.cc\",\n        \"ops_util.h\",\n        \"register_types.h\",\n        \"resource_base.h\",\n        \"resource_handle.cc\",\n        \"resource_handle.h\",\n        \"tensor.cc\",\n        \"tensor.h\",\n        \"tensor_key.h\",\n        \"tensor_shape.cc\",\n        \"tensor_shape.h\",\n        \"tensor_types.h\",\n        \"tracking_allocator.cc\",\n        \"tracking_allocator.h\",\n        \"type_index.h\",\n        \"type_traits.h\",\n        \"typed_allocator.cc\",\n        \"typed_allocator.h\",\n        \"types.cc\",\n        \"types.h\",\n        \"variant.cc\",\n        \"variant.h\",\n        \"variant_encode_decode.h\",\n        \"variant_op_registry.cc\",\n        \"variant_op_registry.h\",\n        \"variant_tensor_data.cc\",\n        \"variant_tensor_data.h\",\n    ],\n)\n\nfilegroup(\n    name = \"mobile_srcs_only_runtime\",\n    srcs = [\n        \"attr_value_util.cc\",\n        \"attr_value_util.h\",\n        \"cancellation.cc\",\n        \"cancellation.h\",\n        \"collective.cc\",\n        \"collective.h\",\n        \"common_shape_fns.cc\",\n        \"common_shape_fns.h\",\n        \"control_flow.h\",\n        \"dataset.cc\",\n        \"dataset.h\",\n        \"dataset_stateful_op_allowlist.h\",\n        \"device.cc\",\n        \"device.h\",\n        \"device_base.cc\",\n        \"device_base.h\",\n        \"device_factory.cc\",\n        \"device_factory.h\",\n        \"full_type_inference_util.cc\",\n        \"full_type_inference_util.h\",\n        \"full_type_util.cc\",\n        \"full_type_util.h\",\n        \"function.cc\",\n        \"function.h\",\n        \"function_handle_cache.cc\",\n        \"function_handle_cache.h\",\n        \"graph_def_util.cc\",\n        \"graph_def_util.h\",\n        \"graph_to_functiondef.cc\",\n        \"graph_to_functiondef.h\",\n        \"kernel_def_builder.cc\",\n        \"kernel_def_builder.h\",\n        \"kernel_def_util.cc\",\n        \"kernel_def_util.h\",\n        \"load_library.cc\",\n        \"local_rendezvous.cc\",\n        \"local_rendezvous.h\",\n        \"logging.cc\",\n        \"logging.h\",\n        \"lookup_interface.cc\",\n        \"lookup_interface.h\",\n        \"memory_types.cc\",\n        \"memory_types.h\",\n        \"metrics.cc\",\n        \"metrics.h\",\n        \"model.cc\",\n        \"model.h\",\n        \"node_def_builder.cc\",\n        \"node_def_builder.h\",\n        \"node_def_util.cc\",\n        \"node_def_util.h\",\n        \"node_properties.cc\",\n        \"node_properties.h\",\n        \"numeric_op.h\",\n        \"op.cc\",\n        \"op.h\",\n        \"op_def_builder.cc\",\n        \"op_def_builder.h\",\n        \"op_def_util.cc\",\n        \"op_def_util.h\",\n        \"op_kernel.cc\",\n        \"op_kernel.h\",\n        \"op_segment.cc\",\n        \"op_segment.h\",\n        \"partial_tensor_shape.h\",\n        \"queue_interface.h\",\n        \"reader_base.cc\",\n        \"reader_base.h\",\n        \"reader_interface.h\",\n        \"reader_op_kernel.h\",\n        \"register_types_traits.h\",\n        \"rendezvous.cc\",\n        \"rendezvous.h\",\n        \"resource_mgr.cc\",\n        \"resource_mgr.h\",\n        \"resource_op_kernel.h\",\n        \"resource_var.cc\",\n        \"resource_var.h\",\n        \"rng_alg.h\",\n        \"run_handler.cc\",\n        \"run_handler.h\",\n        \"run_handler_util.cc\",\n        \"run_handler_util.h\",\n        \"session_state.h\",\n        \"shape_inference.cc\",\n        \"shape_inference.h\",\n        \"stats_aggregator.h\",\n        \"tensor_reference.h\",\n        \"tensor_slice.cc\",\n        \"tensor_slice.h\",\n        \"tensor_util.cc\",\n        \"tensor_util.h\",\n        \"thread_factory.h\",\n        \"versions.cc\",\n        \"versions.h\",\n        \"//tensorflow/core/framework/registration:options.h\",\n        \"//tensorflow/core/framework/registration:registration.h\",\n    ],\n)\n\nfilegroup(\n    name = \"android_test_hdrs\",\n    srcs = [\n        \"fake_input.h\",\n        \"shape_inference_testutil.h\",\n        \"tensor_testutil.h\",\n    ],\n)\n\nfilegroup(\n    name = \"android_test_srcs\",\n    srcs = [\n        \"fake_input.cc\",\n        \":android_test_srcs_no_core\",\n    ],\n)\n\nfilegroup(\n    name = \"android_test_srcs_no_core\",\n    srcs = [\n        \"shape_inference_testutil.cc\",\n        \"tensor_testutil.cc\",\n    ],\n)\n\n# Individual targets. These should be preferred over tensorflow/core:framework\n# whenever possible.\n\n# This is redundant with the \"tensorflow/core:framework\" target. It's useful for\n# applications that want to depend on a minimal subset of TensorFlow (e.g. XLA).\ncc_library(\n    name = \"allocator\",\n    srcs = [\n        \"allocator.cc\",\n        \"allocator_registry.h\",\n        \"tracking_allocator.cc\",\n        \"tracking_allocator.h\",\n    ],\n    hdrs = [\n        \"allocator.h\",\n    ],\n    features = [\"parse_headers\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":numeric_types\",\n        \":type_traits\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ] + if_static(\n        extra_deps = [\n            \":allocator_registry_impl\",\n            \"//tensorflow/core/lib/gtl:inlined_vector\",\n            \"//tensorflow/core/lib/strings:strcat\",\n            \"//tensorflow/core/lib/strings:stringprintf\",\n            \"//tensorflow/core/platform:env\",\n            \"//tensorflow/core/platform:env_impl\",\n            \"//tensorflow/core/platform:logging\",\n            \"//tensorflow/core/platform:macros\",\n            \"//tensorflow/core/platform:mutex\",\n            \"//tensorflow/core/platform:platform_port\",\n            \"//tensorflow/core/platform:thread_annotations\",\n            \"//tensorflow/core/platform:types\",\n        ],\n        otherwise = [\n            \"//tensorflow/core:lib\",\n        ],\n    ),\n    alwayslink = 1,\n)\n\n# This target will be included in libtensorflow_framework.so via the\n# framework_internal_impl target.\n# All other dependencies on this target need to go through if_static guard,\n# as otherwise duplicate registration in the registry will cause crashes.\ncc_library(\n    name = \"allocator_registry_impl\",\n    srcs = [\n        \"allocator.h\",\n        \"allocator_registry.cc\",\n        \"allocator_registry.h\",\n        \"cpu_allocator_impl.cc\",\n        \"tracking_allocator.h\",\n    ],\n    visibility = [\"//tensorflow/core:__subpackages__\"],\n    deps = [\n        \":numeric_types\",\n        \":type_traits\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/lib/strings:stringprintf\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:mutex\",\n        \"//tensorflow/core/platform:platform_port\",\n        \"//tensorflow/core/platform:thread_annotations\",\n        \"//tensorflow/core/platform:types\",\n        \"//tensorflow/core/profiler/lib:scoped_memory_debug_annotation\",\n        \"//tensorflow/core/profiler/lib:traceme\",\n        \"@com_google_absl//absl/strings\",\n        \"@com_google_absl//absl/types:optional\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"tensor_testutil\",\n    testonly = 1,\n    srcs = [\"tensor_testutil.cc\"],\n    hdrs = [\"tensor_testutil.h\"],\n    copts = tf_copts(),\n    visibility = [\"//tensorflow:internal\"],\n    deps = [\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:test\",\n    ],\n)\n\ncc_library(\n    name = \"shape_inference_testutil\",\n    testonly = 1,\n    srcs = [\"shape_inference_testutil.cc\"],\n    hdrs = [\"shape_inference_testutil.h\"],\n    copts = tf_copts(),\n    visibility = [\"//tensorflow:internal\"],\n    deps = [\n        \":node_def_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n    ],\n)\n\ncc_library(\n    name = \"reader_base\",\n    srcs = [\"reader_base.cc\"],\n    hdrs = [\"reader_base.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":reader_base_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"op_gen_lib\",\n    srcs = [\"op_gen_lib.cc\"],\n    hdrs = [\"op_gen_lib.h\"],\n    visibility = [\"//visibility:public\"],\n    deps = [\n        \":api_def_proto_cc\",\n        \":attr_value_proto_cc\",\n        \":op_def_proto_cc\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core/util/proto:proto_utils\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"fake_input\",\n    testonly = 1,\n    srcs = [\"fake_input.cc\"],\n    hdrs = [\"fake_input.h\"],\n    visibility = [\"//tensorflow:__subpackages__\"],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":op_def_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"function_testlib\",\n    testonly = 1,\n    srcs = [\"function_testlib.cc\"],\n    hdrs = [\"function_testlib.h\"],\n    visibility = [\"//tensorflow/core:__subpackages__\"],\n    deps = [\n        \":function_proto_cc\",\n        \":graph_proto_cc\",\n        \":node_def_proto_cc\",\n        \":tensor_testutil\",\n        \":versions_proto_cc\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:lib\",\n    ],\n)\n\ncc_library(\n    name = \"bfloat16\",\n    srcs = [\"bfloat16.cc\"],\n    hdrs = [\"bfloat16.h\"],\n    visibility = [\n        \"//tensorflow/core:__subpackages__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n    deps = [\n        \":numeric_types\",\n        \"//tensorflow/core/platform:byte_order\",\n        \"//tensorflow/core/platform:types\",\n        \"//third_party/eigen3\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"numeric_types\",\n    hdrs = [\"numeric_types.h\"],\n    visibility = [\n        \"//tensorflow/compiler:__subpackages__\",\n        \"//tensorflow/core:__subpackages__\",\n    ],\n    deps = [\n        \"//tensorflow/core/platform:types\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ncc_library(\n    name = \"bounds_check\",\n    hdrs = [\"bounds_check.h\"],\n    visibility = [\"//tensorflow/core/kernels:friends\"],\n    deps = [\n        \"//tensorflow/core/platform:macros\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ncc_library(\n    name = \"tensor_shape\",\n    srcs = [\"tensor_shape.cc\"],\n    hdrs = [\n        \"partial_tensor_shape.h\",\n        \"tensor_shape.h\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__pkg__\",\n        \"//tensorflow/core/runtime_fallback:__subpackages__\",\n        \"//tensorflow/core/tfrt/utils:__subpackages__\",\n    ],\n    deps = [\n        \":bounds_check\",\n        \":tensor_shape_proto_cc\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/util:overflow\",\n        \"//third_party/eigen3\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"resource_base\",\n    hdrs = [\"resource_base.h\"],\n    deps = [\n        \"//tensorflow/core/lib/core:refcount\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/platform:errors\",\n    ],\n)\n\ncc_library(\n    name = \"resource_handle\",\n    srcs = [\"resource_handle.cc\"],\n    hdrs = [\"resource_handle.h\"],\n    visibility = [\n        \"//tensorflow/compiler/mlir/tensorflow:__subpackages__\",\n        \"//tensorflow/core:__pkg__\",\n    ],\n    deps = [\n        \":resource_base\",\n        \":resource_handle_proto_cc\",\n        \":tensor_shape\",\n        \":type_index\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:casts\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:intrusive_ptr\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:statusor\",\n        \"//tensorflow/core/platform:tensor_coding\",\n        \"//tensorflow/core/platform:types\",\n        \"//tensorflow/core/util:managed_stack_trace\",\n        \"@com_google_absl//absl/strings:str_format\",\n    ],\n    alwayslink = 1,\n)\n\ntf_cc_test(\n    name = \"resource_handle_test\",\n    size = \"small\",\n    srcs = [\"resource_handle_test.cc\"],\n    deps = [\n        \":resource_handle\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"type_index\",\n    hdrs = [\"type_index.h\"],\n    visibility = [\"//visibility:private\"],\n    deps = [\n        \"//tensorflow/core/platform:hash\",\n        \"//tensorflow/core/platform:stringpiece\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ncc_library(\n    name = \"tensor_types\",\n    hdrs = [\"tensor_types.h\"],\n    visibility = [\"//visibility:private\"],\n    deps = [\n        \"//tensorflow/core/platform:logging\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ncc_library(\n    name = \"type_traits\",\n    hdrs = [\"type_traits.h\"],\n    visibility = [\"//visibility:private\"],\n    deps = [\n        \":numeric_types\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ntf_cuda_library(\n    name = \"tensor\",\n    srcs = [\n        \"log_memory.cc\",\n        \"tensor.cc\",\n        \"typed_allocator.cc\",\n        \"types.cc\",\n        \"variant.cc\",\n        \"variant_op_registry.cc\",\n        \"variant_tensor_data.cc\",\n    ],\n    hdrs = [\n        \"log_memory.h\",\n        \"register_types.h\",\n        \"tensor.h\",\n        \"typed_allocator.h\",\n        \"types.h\",\n        \"variant.h\",\n        \"variant_encode_decode.h\",\n        \"variant_op_registry.h\",\n        \"variant_tensor_data.h\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__pkg__\",\n        \"//tensorflow/core/runtime_fallback:__subpackages__\",\n        \"//tensorflow/core/tfrt/utils:__subpackages__\",\n        \"//tensorflow/core/util:__pkg__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n    deps = [\n        \":allocation_description_proto_cc\",\n        \":allocator\",\n        \":bfloat16\",\n        \":full_type_proto_cc\",\n        \":log_memory_proto_cc\",\n        \":numeric_types\",\n        \":resource_handle\",\n        \":resource_handle_proto_cc\",\n        \":tensor_description_proto_cc\",\n        \":tensor_proto_cc\",\n        \":tensor_shape\",\n        \":tensor_types\",\n        \":type_index\",\n        \":type_traits\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/core:coding\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:refcount\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/gtl:flatmap\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/lib/hash\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:abi\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:platform_port\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:strcat\",\n        \"//tensorflow/core/platform:tensor_coding\",\n        \"//tensorflow/core/platform:types\",\n        \"//tensorflow/core/public:version\",\n        \"//tensorflow/core/util:managed_stack_trace\",\n        \"//third_party/eigen3\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n    alwayslink = 1,\n)\n\ncc_library(\n    name = \"shape_inference\",\n    srcs = [\"shape_inference.cc\"],\n    hdrs = [\"shape_inference.h\"],\n    deps = [\n        \":bounds_check\",\n        \":full_type_proto_cc\",\n        \":full_type_util\",\n        \":node_def_proto_cc\",\n        \":node_def_util\",\n        \":op_def_proto_cc\",\n        \":tensor\",\n        \":tensor_shape\",\n        \":tensor_shape_proto_cc\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/lib/strings:numbers\",\n        \"//tensorflow/core/lib/strings:scanner\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/platform:macros\",\n        \"@com_google_absl//absl/memory\",\n    ],\n)\n\ncc_library(\n    name = \"kernel_shape_util\",\n    srcs = [\"kernel_shape_util.cc\"],\n    hdrs = [\"kernel_shape_util.h\"],\n    deps = [\n        \":tensor\",\n        \":tensor_shape\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/platform:status\",\n        \"//tensorflow/core/util:padding\",\n    ],\n)\n\ncc_library(\n    name = \"common_shape_fns\",\n    srcs = [\"common_shape_fns.cc\"],\n    hdrs = [\"common_shape_fns.h\"],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":shape_inference\",\n        \":tensor\",\n        \":tensor_shape\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/gtl:inlined_vector\",\n        \"//tensorflow/core/util:einsum_op_util\",\n        \"//tensorflow/core/util:padding\",\n        \"//tensorflow/core/util:tensor_format\",\n        \"@com_google_absl//absl/container:flat_hash_map\",\n        \"@com_google_absl//absl/container:flat_hash_set\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"attr_value_util\",\n    srcs = [\"attr_value_util.cc\"],\n    hdrs = [\"attr_value_util.h\"],\n    deps = [\n        \":attr_value_proto_text\",\n        \":tensor\",\n        \":tensor_shape\",\n        \":tensor_shape_proto_cc\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/hash\",\n        \"//tensorflow/core/lib/strings:proto_serialization\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"op_def_util\",\n    srcs = [\"op_def_util.cc\"],\n    hdrs = [\"op_def_util.h\"],\n    deps = [\n        \":api_def_proto_cc\",\n        \":attr_value_proto_cc\",\n        \":attr_value_util\",\n        \":op_def_proto_cc\",\n        \":tensor\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:map_util\",\n        \"//tensorflow/core/lib/hash\",\n        \"//tensorflow/core/lib/strings:proto_serialization\",\n        \"//tensorflow/core/lib/strings:scanner\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:mutex\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ncc_library(\n    name = \"node_def_util\",\n    srcs = [\"node_def_util.cc\"],\n    hdrs = [\"node_def_util.h\"],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":attr_value_util\",\n        \":node_def_proto_cc\",\n        \":op_def_proto_cc\",\n        \":op_def_util\",\n        \":tensor\",\n        \":tensor_proto_cc\",\n        \":tensor_shape\",\n        \":tensor_shape_proto_cc\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/gtl:flatmap\",\n        \"//tensorflow/core/lib/gtl:map_util\",\n        \"//tensorflow/core/lib/hash\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:hash\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:scanner\",\n        \"//tensorflow/core/platform:status\",\n        \"//tensorflow/core/platform:strcat\",\n        \"//tensorflow/core/platform:stringpiece\",\n        \"//tensorflow/core/platform:types\",\n        \"//tensorflow/core/util:padding\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"node_properties\",\n    srcs = [\"node_properties.cc\"],\n    hdrs = [\"node_properties.h\"],\n    deps = [\n        \":full_type_proto_cc\",\n        \":node_def_proto_cc\",\n        \":node_def_util\",\n        \":op\",\n        \":op_def_builder\",\n        \":op_def_proto_cc\",\n        \":tensor\",\n        \"//tensorflow/core/lib/core:status\",\n    ],\n)\n\ncc_library(\n    name = \"op_def_builder\",\n    srcs = [\"op_def_builder.cc\"],\n    hdrs = [\"op_def_builder.h\"],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":attr_value_util\",\n        \":full_type_proto_cc\",\n        \":op_def_proto_cc\",\n        \":op_def_util\",\n        \":tensor\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/core:stringpiece\",\n        \"//tensorflow/core/lib/gtl:array_slice\",\n        \"//tensorflow/core/lib/strings:scanner\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:errors\",\n        \"//tensorflow/core/platform:macros\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\n# TODO(mdan): Move these into a separate directory.\ncc_library(\n    name = \"full_type_util\",\n    srcs = [\n        \"full_type_inference_util.cc\",\n        \"full_type_util.cc\",\n    ],\n    hdrs = [\n        \"full_type_inference_util.h\",\n        \"full_type_util.h\",\n    ],\n    deps = [\n        \":attr_value_proto_cc\",\n        \":full_type_proto_cc\",\n        \":node_def_proto_cc\",\n        \":node_def_util\",\n        \":op_def_builder\",\n        \":op_def_proto_cc\",\n        \":tensor\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/platform:statusor\",\n        \"//tensorflow/core/protobuf:error_codes_proto_impl_cc\",\n    ],\n)\n\ncc_library(\n    name = \"op\",\n    srcs = [\"op.cc\"],\n    hdrs = [\"op.h\"],\n    deps = [\n        \":full_type_proto_cc\",\n        \":full_type_util\",\n        \":op_def_builder\",\n        \":op_def_util\",\n        \"//tensorflow/core/framework/registration\",\n        \"//tensorflow/core/lib/core:errors\",\n        \"//tensorflow/core/lib/core:status\",\n        \"//tensorflow/core/lib/gtl:map_util\",\n        \"//tensorflow/core/lib/strings:str_util\",\n        \"//tensorflow/core/lib/strings:strcat\",\n        \"//tensorflow/core/platform:logging\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:mutex\",\n        \"//tensorflow/core/platform:platform_port\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:thread_annotations\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ncc_library(\n    name = \"op_requires\",\n    hdrs = [\"op_requires.h\"],\n    deps = [\"//tensorflow/core/platform:macros\"],\n)\n\n# Files whose users still need to be migrated from core:framework to the\n# above targets.\n# TODO(gonnet): Remove these files once targets depending on them have\n# been cleaned up.\nexports_files(\n    srcs = [\n        \"allocator.h\",\n        \"bfloat16.h\",\n        \"bounds_check.h\",\n        \"fake_input.h\",\n        \"function_testlib.h\",\n        \"log_memory.h\",\n        \"numeric_types.h\",\n        \"op_gen_lib.h\",\n        \"reader_base.h\",\n        \"register_types.h\",\n        \"resource_base.h\",\n        \"resource_handle.h\",\n        \"shape_inference_testutil.h\",\n        \"tensor.h\",\n        \"tensor_interface.h\",\n        \"tensor_shape.h\",\n        \"tensor_testutil.h\",\n        \"tensor_types.h\",\n        \"type_index.h\",\n        \"type_traits.h\",\n        \"typed_allocator.h\",\n        \"types.h\",\n        \"variant.h\",\n        \"variant_encode_decode.h\",\n        \"variant_op_registry.h\",\n        \"variant_tensor_data.h\",\n    ],\n)\n\n# Framework tests.\ntf_cc_test(\n    name = \"framework_op_gen_lib_test\",\n    size = \"small\",\n    srcs = [\"op_gen_lib_test.cc\"],\n    deps = [\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core/framework:op_gen_lib\",\n    ],\n)\n\ntf_cuda_cc_test(\n    name = \"variant_op_copy_test\",\n    size = \"small\",\n    srcs = [\"variant_op_copy_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    tags = tf_cuda_tests_tags(),\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:client_session\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:direct_session\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/kernels:array\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ntf_cc_test(\n    name = \"framework_run_handler_util_test\",\n    size = \"small\",\n    srcs = [\"run_handler_util_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    deps = [\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ntf_cc_test(\n    name = \"framework_run_handler_test\",\n    size = \"small\",\n    srcs = [\"run_handler_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    deps = [\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:direct_session_internal\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/framework:tensor_testutil\",\n        \"//tensorflow/core/kernels:cwise_op\",\n        \"//tensorflow/core/kernels:matmul_op\",\n        \"//third_party/eigen3\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/synchronization\",\n    ],\n)\n\ntf_cc_test(\n    name = \"framework_op_segment_test\",\n    size = \"small\",\n    srcs = [\"op_segment_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/core\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:direct_session_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/kernels:cwise_op\",\n        \"//tensorflow/core/kernels:ops_util\",\n        \"//third_party/eigen3\",\n    ],\n)\n\ntf_cc_test(\n    name = \"framework_resource_var_test\",\n    size = \"small\",\n    srcs = [\"resource_var_test.cc\"],\n    linkstatic = tf_kernel_tests_linkstatic(),\n    deps = [\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n    ],\n)\n\ncc_library(\n    name = \"op_kernel_test_base\",\n    testonly = True,\n    hdrs = [\n        \"op_kernel_test_base.h\",\n    ],\n    deps = [\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:cc_ops_internal\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:sendrecv_ops\",\n        \"//tensorflow/core\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/common_runtime:direct_session_internal\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ntf_cc_tests(\n    name = \"higher_level_tests\",\n    size = \"small\",\n    srcs = [\n        \"allocator_test.cc\",\n        \"attr_value_util_test.cc\",\n        \"batch_util_test.cc\",\n        \"bfloat16_test.cc\",\n        \"cancellation_test.cc\",\n        \"common_shape_fns_test.cc\",\n        \"dataset_test.cc\",\n        \"device_base_test.cc\",\n        \"disable_jit_test.cc\",\n        \"full_type_inference_util_test.cc\",\n        \"function_test.cc\",\n        \"graph_def_util_test.cc\",\n        \"graph_to_functiondef_test.cc\",\n        \"kernel_def_builder_test.cc\",\n        \"kernel_def_util_test.cc\",\n        \"memory_types_test.cc\",\n        \"model_test.cc\",\n        \"node_def_builder_test.cc\",\n        \"node_def_util_test.cc\",\n        \"node_properties_test.cc\",\n        \"op_compatibility_test.cc\",\n        \"op_def_builder_test.cc\",\n        \"op_def_util_test.cc\",\n        \"op_kernel_test.cc\",\n        \"op_registration_test.cc\",\n        \"partial_tensor_shape_test.cc\",\n        \"rendezvous_test.cc\",\n        \"resource_mgr_test.cc\",\n        \"resource_op_kernel_test.cc\",\n        \"shape_inference_test.cc\",\n        \"shape_inference_testutil_test.cc\",\n        \"tensor_shape_test.cc\",\n        \"tensor_slice_test.cc\",\n        \"tensor_test.cc\",\n        \"tensor_testutil_test.cc\",\n        \"tensor_util_test.cc\",\n        \"tracking_allocator_test.cc\",\n        \"types_test.cc\",\n        \"variant_op_registry_test.cc\",\n        \"variant_test.cc\",\n    ],\n    linkopts = select({\n        \"//tensorflow:macos\": [\"-headerpad_max_install_names\"],\n        \"//conditions:default\": [],\n    }),\n    linkstatic = tf_kernel_tests_linkstatic(),\n    visibility = [\n        \"//tensorflow:internal\",\n        \"//tensorflow/core:__pkg__\",\n    ],\n    deps = [\n        \":op_kernel_test_base\",\n        \"//tensorflow/cc:cc_ops\",\n        \"//tensorflow/cc:cc_ops_internal\",\n        \"//tensorflow/cc:function_ops\",\n        \"//tensorflow/cc:ops\",\n        \"//tensorflow/cc:scope\",\n        \"//tensorflow/cc:sendrecv_ops\",\n        \"//tensorflow/cc:while_loop\",\n        \"//tensorflow/compiler/tf2xla/ops:xla_ops\",\n        \"//tensorflow/core\",\n        \"//tensorflow/core:core_cpu\",\n        \"//tensorflow/core:core_cpu_internal\",\n        \"//tensorflow/core:framework\",\n        \"//tensorflow/core:framework_internal\",\n        \"//tensorflow/core:lib\",\n        \"//tensorflow/core:lib_internal\",\n        \"//tensorflow/core:ops\",\n        \"//tensorflow/core:protos_all_cc\",\n        \"//tensorflow/core:test\",\n        \"//tensorflow/core:test_main\",\n        \"//tensorflow/core:testlib\",\n        \"//tensorflow/core/common_runtime:direct_session_internal\",\n        \"//tensorflow/core/kernels:ops_util\",\n        \"//tensorflow/core/platform:regexp\",\n        \"//tensorflow/core/platform:status_matchers\",\n        \"//tensorflow/core/profiler/lib:profiler_session\",\n        \"//tensorflow/core/profiler/protobuf:memory_profile_proto_cc\",\n        \"//tensorflow/core/profiler/utils:xplane_schema\",\n        \"//tensorflow/core/profiler/utils:xplane_visitor\",\n        \"//tensorflow/core/util:protos_test_cc\",\n        \"//third_party/eigen3\",\n        \"@com_google_absl//absl/base\",\n        \"@com_google_absl//absl/memory\",\n        \"@com_google_absl//absl/strings\",\n    ],\n)\n\ncc_library(\n    name = \"pywrap_required_hdrs\",\n    textual_hdrs = [\n        \"op_gen_lib.h\",\n        \"rendezvous.h\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__pkg__\",\n        \"//tensorflow/python:__pkg__\",\n        \"//tensorflow/python/client:__pkg__\",\n        \"//tensorflow/python/util:__pkg__\",\n    ],\n)\n\n# All framewrok protos are self-contained, i.e. they only import other\n# protos from the same package, so we can build the protos here and then\n# link them from core:protos_all without circular dependencies.\n\n# Generate the C++ sources for some of the protos.\ntf_generate_proto_text_sources(\n    name = \"attr_value_proto_text\",\n    srcs = [\n        \"attr_value.proto\",\n        \"resource_handle.proto\",\n        \"tensor.proto\",\n        \"tensor_shape.proto\",\n        \"types.proto\",\n    ],\n    srcs_relative_dir = \"tensorflow/core/framework/\",\n    deps = [\n        \":attr_value_proto_cc\",\n        \":resource_handle_proto_cc\",\n        \":tensor_proto_cc\",\n        \":tensor_shape_proto_cc\",\n        \":types_proto_cc\",\n        \"//tensorflow/core/lib/strings:proto_text_util\",\n        \"//tensorflow/core/lib/strings:scanner\",\n        \"//tensorflow/core/platform:macros\",\n        \"//tensorflow/core/platform:protobuf\",\n        \"//tensorflow/core/platform:types\",\n    ],\n)\n\ntf_pyclif_proto_library(\n    name = \"cost_graph_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"cost_graph.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"tensor_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"tensor.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"kernel_def_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"kernel_def.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"node_def_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"node_def.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"function_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"function.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"graph_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"graph.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"step_stats_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"step_stats.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"types_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"types.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_pyclif_proto_library(\n    name = \"variable_pyclif\",\n    proto_lib = \"//tensorflow/core:protos_all\",\n    proto_srcfile = \"variable.proto\",\n    visibility = [\"//visibility:public\"],\n)\n\ntf_proto_library(\n    name = \"log_memory_proto\",\n    srcs = [\"log_memory.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":allocation_description_proto\",\n        \":tensor_description_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"versions_proto\",\n    srcs = [\"versions.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"graph_proto\",\n    srcs = [\"graph.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":function_proto\",\n        \":node_def_proto\",\n        \":op_def_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n        \":versions_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"node_def_proto\",\n    srcs = [\"node_def.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":full_type_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"allocation_description_proto\",\n    srcs = [\"allocation_description.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"tensor_slice_proto\",\n    srcs = [\"tensor_slice.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"tensor_description_proto\",\n    srcs = [\"tensor_description.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":allocation_description_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"device_attributes_proto\",\n    srcs = [\"device_attributes.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"resource_handle_proto\",\n    srcs = [\"resource_handle.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"step_stats_proto\",\n    srcs = [\"step_stats.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":allocation_description_proto\",\n        \":tensor_description_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"reader_base_proto\",\n    srcs = [\"reader_base.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"kernel_def_proto\",\n    srcs = [\"kernel_def.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"op_def_proto\",\n    srcs = [\"op_def.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":full_type_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__subpackages__\",\n        \"//tensorflow/python:__pkg__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n)\n\ntf_proto_library(\n    name = \"attr_value_proto\",\n    srcs = [\"attr_value.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n    visibility = [\n        \"//tensorflow/core:__subpackages__\",\n        \"//tensorflow/python:__pkg__\",\n        \"//tensorflow/security/fuzzing:__subpackages__\",\n    ],\n)\n\ntf_proto_library(\n    name = \"full_type_proto\",\n    srcs = [\"full_type.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [],\n)\n\ntf_proto_library(\n    name = \"tensor_proto\",\n    srcs = [\"tensor.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":resource_handle_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"api_def_proto\",\n    srcs = [\"api_def.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"variable_proto\",\n    srcs = [\"variable.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"graph_transfer_info_proto\",\n    srcs = [\"graph_transfer_info.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"types_proto\",\n    srcs = [\"types.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"cost_graph_proto\",\n    srcs = [\"cost_graph.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"tensor_shape_proto\",\n    srcs = [\"tensor_shape.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"function_proto\",\n    srcs = [\"function.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":attr_value_proto\",\n        \":node_def_proto\",\n        \":op_def_proto\",\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"summary_proto\",\n    srcs = [\"summary.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":resource_handle_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":types_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"model_proto\",\n    srcs = [\"model.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"dataset_metadata_proto\",\n    srcs = [\"dataset_metadata.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n)\n\ntf_proto_library(\n    name = \"dataset_options_proto\",\n    srcs = [\"dataset_options.proto\"],\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":model_proto\",\n    ],\n)\n\ntf_proto_library(\n    name = \"protos_all\",\n    cc_api_version = 2,\n    make_default_target_header_only = True,\n    protodeps = [\n        \":allocation_description_proto\",\n        \":api_def_proto\",\n        \":attr_value_proto\",\n        \":cost_graph_proto\",\n        \":dataset_metadata_proto\",\n        \":dataset_options_proto\",\n        \":device_attributes_proto\",\n        \":full_type_proto\",\n        \":function_proto\",\n        \":graph_proto\",\n        \":graph_transfer_info_proto\",\n        \":kernel_def_proto\",\n        \":log_memory_proto\",\n        \":model_proto\",\n        \":node_def_proto\",\n        \":op_def_proto\",\n        \":reader_base_proto\",\n        \":resource_handle_proto\",\n        \":step_stats_proto\",\n        \":summary_proto\",\n        \":tensor_description_proto\",\n        \":tensor_proto\",\n        \":tensor_shape_proto\",\n        \":tensor_slice_proto\",\n        \":types_proto\",\n        \":variable_proto\",\n        \":versions_proto\",\n    ],\n    tags = [\n        \"alt_dep=//third_party/tensorflow/core:protos_all\",\n    ],\n)\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/framework/resource_handle.h\"\n\n#include \"absl/strings/str_format.h\"\n#include \"tensorflow/core/framework/resource_handle.pb.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/strings/strcat.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/macros.h\"\n\nnamespace tensorflow {\n\n// Must be declared here for pre-C++17 compatibility.\n/* static */ constexpr const char* ResourceHandle::ANONYMOUS_NAME;\n\nResourceHandle::ResourceHandle() {}\n\nResourceHandle::ResourceHandle(const ResourceHandleProto& proto) {\n  TF_CHECK_OK(FromProto(proto));\n}\n\nStatus ResourceHandle::BuildResourceHandle(const ResourceHandleProto& proto,\n                                           ResourceHandle* out) {\n  if (out == nullptr)\n    return errors::Internal(\n        \"BuildResourceHandle() was called with nullptr for the output\");\n  return out->FromProto(proto);\n}\n\nResourceHandle::~ResourceHandle() {}\n\nvoid ResourceHandle::AsProto(ResourceHandleProto* proto) const {\n  proto->set_device(device());\n  proto->set_container(container());\n  proto->set_name(name());\n  proto->set_hash_code(hash_code());\n  proto->set_maybe_type_name(maybe_type_name());\n  for (const auto& dtype_and_shape_pair : dtypes_and_shapes_) {\n    auto dtype_and_shape = proto->add_dtypes_and_shapes();\n    dtype_and_shape->set_dtype(dtype_and_shape_pair.dtype);\n    dtype_and_shape_pair.shape.AsProto(dtype_and_shape->mutable_shape());\n  }\n}\n\nStatus ResourceHandle::FromProto(const ResourceHandleProto& proto) {\n  set_device(proto.device());\n  set_container(proto.container());\n  set_name(proto.name());\n  set_hash_code(proto.hash_code());\n  set_maybe_type_name(proto.maybe_type_name());\n  std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes;\n  for (const auto& dtype_and_shape : proto.dtypes_and_shapes()) {\n    DataType dtype = dtype_and_shape.dtype();\n    PartialTensorShape shape;\n    Status s = PartialTensorShape::BuildPartialTensorShape(\n        dtype_and_shape.shape(), &shape);\n    if (!s.ok()) {\n      return s;\n    }\n    dtypes_and_shapes.push_back(DtypeAndPartialTensorShape{dtype, shape});\n  }\n  dtypes_and_shapes_ = std::move(dtypes_and_shapes);\n  return Status::OK();\n}\n\nstring ResourceHandle::SerializeAsString() const {\n  ResourceHandleProto proto;\n  AsProto(&proto);\n  return proto.SerializeAsString();\n}\n\nbool ResourceHandle::ParseFromString(const string& s) {\n  ResourceHandleProto proto;\n  return proto.ParseFromString(s) && FromProto(proto).ok();\n}\n\nstring ResourceHandle::DebugString() const {\n  return strings::StrCat(\"device: \", device(), \" container: \", container(),\n                         \" name: \", name(), \" hash_code: \", hash_code(),\n                         \" maybe_type_name: \", maybe_type_name());\n}\n\nResourceHandle ResourceHandle::MakeRefCountingHandle(\n    ResourceBase* resource, const string& device_name,\n    const TypeIndex& type_index,\n    const std::vector<DtypeAndPartialTensorShape>& dtypes_and_shapes,\n    const absl::optional<ManagedStackTrace>& definition_stack_trace) {\n  ResourceHandle result;\n  result.resource_.reset(resource, /*add_ref=*/false);\n  result.set_device(device_name);\n  // All resources owned by anonymous handles are put into the same container,\n  // and they get process-unique handle names.\n  result.set_container(\"Anonymous\");\n  result.set_definition_stack_trace(definition_stack_trace);\n  result.set_name(\n      absl::StrFormat(\"Resource-%d-at-%p\", GenerateUniqueId(), resource));\n  result.set_hash_code(type_index.hash_code());\n  result.set_maybe_type_name(type_index.name());\n  result.set_dtypes_and_shapes(dtypes_and_shapes);\n  return result;\n}\n\nStatus ResourceHandle::ValidateType(const TypeIndex& type_index) const {\n  if (type_index.hash_code() != hash_code()) {\n    return errors::InvalidArgument(\n        \"Trying to access a handle's resource using the wrong type. \",\n        \"The handle points to a resource (name '\", name(), \"') of type '\",\n        maybe_type_name(), \"' (hash code \", hash_code(),\n        \") but you are trying to access the resource as type '\",\n        type_index.name(), \"' (hash code \", type_index.hash_code(), \")\");\n  }\n  return Status::OK();\n}\n\nstd::atomic<int64_t> ResourceHandle::current_id_;\n\nint64_t ResourceHandle::GenerateUniqueId() { return current_id_.fetch_add(1); }\n\nstring ProtoDebugString(const ResourceHandle& handle) {\n  return handle.DebugString();\n}\n\nvoid EncodeResourceHandleList(const ResourceHandle* p, int64_t n,\n                              std::unique_ptr<port::StringListEncoder> e) {\n  ResourceHandleProto proto;\n  for (int i = 0; i < n; ++i) {\n    p[i].AsProto(&proto);\n    e->Append(proto);\n  }\n  e->Finalize();\n}\n\nbool DecodeResourceHandleList(std::unique_ptr<port::StringListDecoder> d,\n                              ResourceHandle* ps, int64_t n) {\n  std::vector<uint32> sizes(n);\n  if (!d->ReadSizes(&sizes)) return false;\n\n  ResourceHandleProto proto;\n  for (int i = 0; i < n; ++i) {\n    if (!proto.ParseFromArray(d->Data(sizes[i]), sizes[i])) {\n      return false;\n    }\n    if (!ps[i].FromProto(proto).ok()) {\n      return false;\n    }\n  }\n  return true;\n}\n\n}  // namespace tensorflow\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#ifndef TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_\n#define TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_\n\n#include <string>\n\n#include \"tensorflow/core/framework/resource_base.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/type_index.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/platform/casts.h\"\n#include \"tensorflow/core/platform/intrusive_ptr.h\"\n#include \"tensorflow/core/platform/statusor.h\"\n#include \"tensorflow/core/platform/tensor_coding.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/managed_stack_trace.h\"\n\nnamespace tensorflow {\n\nclass ResourceHandleProto;\n\n// Class representing a handle to a tensorflow resource. Handles are\n// not valid across executions, but can be serialized back and forth from within\n// a single run (except for those created from MakeRefCountingHandle i.e. whose\n// resource_ field is not empty).\n//\n// This is the native C++ class equivalent of ResourceHandleProto.  They are\n// separate so that kernels do not need to depend on protos.\nclass ResourceHandle {\n public:\n  ResourceHandle();\n  ResourceHandle(const ResourceHandleProto& proto);\n  ~ResourceHandle();\n\n  // Use this factory method if the `proto` comes from user controlled input, to\n  // prevent a denial of service.\n  static Status BuildResourceHandle(const ResourceHandleProto& proto,\n                                    ResourceHandle* out);\n\n  // Unique name for the device containing the resource.\n  const std::string& device() const { return device_; }\n\n  void set_device(const std::string& device) { device_ = device; }\n\n  // Container in which this resource is placed.\n  const std::string& container() const { return container_; }\n  void set_container(const std::string& container) { container_ = container; }\n\n  // Unique name of this resource.\n  const std::string& name() const { return name_; }\n  void set_name(const std::string& name) { name_ = name; }\n\n  // Hash code for the type of the resource. Is only valid in the same device\n  // and in the same execution.\n  uint64 hash_code() const { return hash_code_; }\n  void set_hash_code(uint64 hash_code) { hash_code_ = hash_code; }\n\n  // For debug-only, the name of the type pointed to by this handle, if\n  // available.\n  const std::string& maybe_type_name() const { return maybe_type_name_; }\n  void set_maybe_type_name(const std::string& value) {\n    maybe_type_name_ = value;\n  }\n\n  // Data types and shapes for the underlying resource.\n  std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes() const {\n    return dtypes_and_shapes_;\n  }\n  void set_dtypes_and_shapes(\n      const std::vector<DtypeAndPartialTensorShape>& dtypes_and_shapes) {\n    dtypes_and_shapes_ = dtypes_and_shapes;\n  }\n\n  void set_definition_stack_trace(\n      const absl::optional<ManagedStackTrace>& definition_stack_trace) {\n    definition_stack_trace_ = definition_stack_trace;\n  }\n\n  const absl::optional<ManagedStackTrace>& definition_stack_trace() const {\n    return definition_stack_trace_;\n  }\n\n  // Conversion to and from ResourceHandleProto\n  void AsProto(ResourceHandleProto* proto) const;\n  Status FromProto(const ResourceHandleProto& proto);\n\n  // Serialization via ResourceHandleProto\n  std::string SerializeAsString() const;\n  bool ParseFromString(const std::string& s);\n\n  std::string DebugString() const;\n\n  std::string SummarizeValue() const { return \"Resource Tensor\"; }\n\n  // GUID for anonymous resources. Resources with this shared_name will have\n  // their shared_name replaced with a GUID at creation time\n  static constexpr const char* ANONYMOUS_NAME =\n      \"cd2c89b7-88b7-44c8-ad83-06c2a9158347\";\n\n  // Creates a `ResourceHandle` that holds a pointer to a resource and takes\n  // ownership of it. Normally a `ResourceHandle` only contains the name (and\n  // some other metadata) of the resource. When created via this function,\n  // the handle will own the resource, in the sense that it will destroy the\n  // resource automatically when the resource is no longer needed. It does this\n  // via automatic ref-counting on the resource: when the handle is copied, it\n  // will call `Ref` on the resource (remember that all resources inherit from\n  // `ResourceBase` which inherits from `RefCounted`), and when the handle is\n  // destroyed, it will call `Unref` on the resource. When the last handle goes\n  // out of scope, the resource's ref-count will go down to zero and the\n  // resource will be destroyed. When calling this function, the `resource`\n  // argument should have a ref-count of one (which is the case when the\n  // resource is newly created).\n  //\n  // For those familiar with `ResourceMgr`, when you create a handle by the\n  // `MakeResourceHandle` function in resource_mgr.h, the handle doesn't hold a\n  // strong reference to the resource, and the resource is owned by the\n  // resource manager whose strong reference must be manually deleted by\n  // calling `ResourceMgr::Delete`. In contrast, a handle created by this\n  // function holds a strong reference to the resource. The resource manager\n  // does not hold a strong reference to the resource.\n  template <typename T>\n  static ResourceHandle MakeRefCountingHandle(\n      T* resource, const string& device_name,\n      const std::vector<DtypeAndPartialTensorShape>& dtypes_and_shapes = {},\n      const absl::optional<ManagedStackTrace>& definition_stack_trace = {}) {\n    return MakeRefCountingHandle(resource, device_name, TypeIndex::Make<T>(),\n                                 dtypes_and_shapes, definition_stack_trace);\n  }\n\n  static ResourceHandle MakeRefCountingHandle(\n      ResourceBase* resource, const string& device_name,\n      const TypeIndex& type_index,\n      const std::vector<DtypeAndPartialTensorShape>& dtypes_and_shapes = {},\n      const absl::optional<ManagedStackTrace>& definition_stack_trace = {});\n\n  // Pointer to the resource.\n  const core::IntrusivePtr<ResourceBase>& resource() const { return resource_; }\n\n  // Gets the resource pointer in `handle` as `T*`, or an error if the actual\n  // resource type is not `T`.\n  template <typename T>\n  StatusOr<T*> GetResource() const {\n    TF_RETURN_IF_ERROR(ValidateType<T>());\n    return down_cast<T*>(resource_.get());\n  }\n\n  // Returns True if the resource handle is ref-counting.\n  // See MakeRefCountingHandle.\n  bool IsRefCounting() const { return resource_.get() != nullptr; }\n\n  // Validates that the resource type in `handle` is `T`.\n  template <typename T>\n  Status ValidateType() const {\n    return ValidateType(TypeIndex::Make<T>());\n  }\n\n  Status ValidateType(const TypeIndex& type_index) const;\n\n  // Generates unique IDs (e.g. for names of anonymous variables)\n  static int64_t GenerateUniqueId();\n\n private:\n  std::string device_;\n  std::string container_;\n  std::string name_;\n  uint64 hash_code_ = 0;\n  std::string maybe_type_name_;\n  std::vector<DtypeAndPartialTensorShape> dtypes_and_shapes_;\n  absl::optional<ManagedStackTrace> definition_stack_trace_;\n  // A smart pointer to the actual resource. When this field is not empty, the\n  // handle is in a \"ref-counting\" mode, owning the resource; otherwise it's in\n  // a \"weak-ref\" mode, only containing the name of the resource (conceptually a\n  // weak reference).\n  core::IntrusivePtr<ResourceBase> resource_;\n  static std::atomic<int64_t> current_id_;\n};\n\n// For backwards compatibility for when this was a proto\nstd::string ProtoDebugString(const ResourceHandle& handle);\n\n// Encodes a list of ResourceHandle protos in the given StringListEncoder.\nvoid EncodeResourceHandleList(const ResourceHandle* p, int64_t n,\n                              std::unique_ptr<port::StringListEncoder> e);\n\n// Decodes a list of ResourceHandle protos from the given StringListDecoder.\nbool DecodeResourceHandleList(std::unique_ptr<port::StringListDecoder> d,\n                              ResourceHandle* ps, int64_t n);\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_FRAMEWORK_RESOURCE_HANDLE_H_\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Implementation notes:\n//\n// Tensor.cc uses a few templated classes and structs to facilitate\n// implementation of the Tensor class.\n//\n// * Buffer<T>: provides the implementation for a typed array T[n].\n//   The array is allocated by the given allocator. It runs T's\n//   default constructors and destructors when T is not a simple type\n//   (e.g., string.), and skips them otherwise.\n//\n// * Helper<T>: provides various routines given type T.  The routines\n//   includes running the constructor and destructor of T[], encoding\n//   an decoding T[] into/from a Cord, etc.\n\n#include \"tensorflow/core/framework/tensor.h\"\n\n#include <utility>\n\n#include \"absl/strings/escaping.h\"\n#include \"tensorflow/core/framework/allocation_description.pb.h\"\n#include \"tensorflow/core/framework/log_memory.h\"\n#include \"tensorflow/core/framework/resource_handle.h\"\n#include \"tensorflow/core/framework/resource_handle.pb.h\"\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/tensor_description.pb.h\"\n#include \"tensorflow/core/framework/type_traits.h\"\n#include \"tensorflow/core/framework/typed_allocator.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/framework/variant.h\"\n#include \"tensorflow/core/framework/variant_encode_decode.h\"\n#include \"tensorflow/core/framework/variant_op_registry.h\"\n#include \"tensorflow/core/framework/variant_tensor_data.h\"\n#include \"tensorflow/core/lib/core/coding.h\"\n#include \"tensorflow/core/lib/core/errors.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/gtl/inlined_vector.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/lib/strings/strcat.h\"\n#include \"tensorflow/core/platform/errors.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/macros.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n#include \"tensorflow/core/platform/tensor_coding.h\"\n#include \"tensorflow/core/platform/types.h\"\n\nnamespace tensorflow {\n\n// Allow Tensors to be stored inside Variants with automatic\n// encoding/decoding when those Variants are themselves being decoded\n// in a Tensor's FromProto.\n//\n// NOTE(mrry): The corresponding \"copy function\" registrations can be found in\n// ../common_runtime/copy_tensor.cc (due to dependencies on other common_runtime\n// code).\nREGISTER_UNARY_VARIANT_DECODE_FUNCTION(Tensor, \"tensorflow::Tensor\");\n\nbool TensorBuffer::GetAllocatedBytes(size_t* out_bytes) const {\n  AllocationDescription allocation_description;\n  FillAllocationDescription(&allocation_description);\n  if (allocation_description.allocated_bytes() > 0) {\n    *out_bytes = allocation_description.allocated_bytes();\n    return true;\n  } else {\n    return false;\n  }\n}\n\nnamespace {\n\n// An un-templated base class for Buffer.\nclass BufferBase : public TensorBuffer {\n public:\n  explicit BufferBase(Allocator* alloc, void* data_ptr)\n      : TensorBuffer(data_ptr), alloc_(alloc) {}\n\n  TensorBuffer* root_buffer() override { return this; }\n\n  bool GetAllocatedBytes(size_t* out_bytes) const override {\n    if (alloc_->TracksAllocationSizes()) {\n      *out_bytes = alloc_->AllocatedSize(data());\n      return *out_bytes > 0;\n    } else {\n      return false;\n    }\n  }\n\n  void FillAllocationDescription(AllocationDescription* proto) const override {\n    void* data_ptr = data();\n    int64_t rb = size();\n    proto->set_requested_bytes(rb);\n    proto->set_allocator_name(alloc_->Name());\n    proto->set_ptr(reinterpret_cast<uintptr_t>(data_ptr));\n    if (alloc_->TracksAllocationSizes()) {\n      int64_t ab = alloc_->AllocatedSize(data_ptr);\n      proto->set_allocated_bytes(ab);\n      int64_t id = alloc_->AllocationId(data_ptr);\n      if (id > 0) {\n        proto->set_allocation_id(id);\n      }\n      if (RefCountIsOne()) {\n        proto->set_has_single_reference(true);\n      }\n    }\n  }\n\n protected:\n  void RecordDeallocation() {\n    LogMemory::RecordTensorDeallocation(alloc_->AllocationId(data()),\n                                        alloc_->Name());\n  }\n\n  Allocator* const alloc_;\n};\n\n// Typed ref-counted buffer: T[n].\ntemplate <typename T>\nclass Buffer : public BufferBase {\n public:\n  Buffer(Allocator* a, int64_t n);\n  Buffer(Allocator* a, int64_t n, const AllocationAttributes& allocation_attr);\n\n  size_t size() const override { return sizeof(T) * elem_; }\n\n private:\n  int64_t elem_;\n\n  ~Buffer() override;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(Buffer);\n};\n\nvoid LogUnexpectedSize(int64_t actual, int64_t expected) {\n  LOG(ERROR) << \"Input size was \" << actual << \" and expected \" << expected;\n}\n\nbool MemoryLoggingEnabled() {\n  static bool memory_logging_enabled = LogMemory::IsEnabled();\n  return memory_logging_enabled;\n}\n\n// A set of helper functions depending on T.\ntemplate <typename T>\nstruct Helper {\n  // By default, we assume T is a simple type (float, int32, etc.)\n  static_assert(is_simple_type<T>::value, \"T is not a simple type.\");\n  typedef protobuf::RepeatedField<T> RepeatedFieldType;\n\n  // Encoder of simple type T to a string.  We do a copy.\n  template <typename Destination>\n  static void Encode(TensorBuffer* in, int64_t n, Destination* out) {\n    DCHECK_EQ(in->size(), sizeof(T) * n);\n    port::AssignRefCounted(StringPiece(in->base<const char>(), in->size()), in,\n                           out);\n  }\n\n  // Decoder of simple type T. Copy the bytes from \"in\" into the\n  // tensor buffer.\n  template <typename Source>\n  static TensorBuffer* Decode(Allocator* a, const Source& in, int64_t n) {\n    if (in.size() != sizeof(T) * n) {\n      LogUnexpectedSize(in.size(), sizeof(T) * n);\n      return nullptr;\n    }\n    Buffer<T>* buf = new Buffer<T>(a, n);\n    char* data = buf->template base<char>();\n    if (data == nullptr) {\n      buf->Unref();\n      return nullptr;\n    }\n    port::CopyToArray(in, data);\n    return buf;\n  }\n\n  // Memory usage.\n  static int64_t TotalBytes(TensorBuffer* in, int64_t n) {\n    DCHECK_EQ(in->size(), sizeof(T) * n);\n    return in->size();\n  }\n};\n\n// Helper specialization for string (the only non-simple type we\n// support).\ntemplate <>\nstruct Helper<tstring> {\n  // Proto message uses RepeatedFieldType to hold repeated T.\n  typedef protobuf::RepeatedPtrField<string> RepeatedFieldType;\n\n  // Encodes \"n\" elements of type string stored in \"in\" into Cord\n  // \"out\", which is usually the TensorProto::tensor_content.\n  template <typename Destination>\n  static void Encode(TensorBuffer* in, int64_t n, Destination* out) {\n    port::EncodeStringList(in->base<const tstring>(), n, out);\n  }\n\n  // Decodes \"n\" elements of type string from \"in\" and constructs a\n  // buffer out of it. Returns nullptr if the decoding fails. \"in\" is\n  // usually the TensorProto::tensor_content.\n  template <typename Source>\n  static TensorBuffer* Decode(Allocator* a, const Source& in, int64_t n) {\n    Buffer<tstring>* buf = new Buffer<tstring>(a, n);\n    tstring* strings = buf->template base<tstring>();\n    if (strings == nullptr || !port::DecodeStringList(in, strings, n)) {\n      buf->Unref();\n      return nullptr;\n    }\n    return buf;\n  }\n\n  // Returns the estimated memory usage of \"n\" elements of type T\n  // stored in buffer \"in\".\n  static int64_t TotalBytes(TensorBuffer* in, int n) {\n    int64_t tot = in->size();\n    DCHECK_EQ(tot, sizeof(tstring) * n);\n    const tstring* p = in->base<const tstring>();\n    for (int i = 0; i < n; ++i, ++p) tot += p->size();\n    return tot;\n  }\n};\n\ntemplate <>\nstruct Helper<ResourceHandle> {\n  // Proto message uses RepeatedFieldType to hold repeated T.\n  typedef protobuf::RepeatedPtrField<string> RepeatedFieldType;\n\n  // Encodes \"n\" elements of type ResourceHandle stored in \"in\" into destination\n  // \"out\", which is usually the TensorProto::tensor_content.\n  template <typename Destination>\n  static void Encode(TensorBuffer* in, int64_t n, Destination* out) {\n    EncodeResourceHandleList(in->base<const ResourceHandle>(), n,\n                             port::NewStringListEncoder(out));\n  }\n\n  // Decodes \"n\" elements of type string from \"in\" and constructs a\n  // buffer out of it. Returns nullptr if the decoding fails. \"in\" is\n  // usually the TensorProto::tensor_content.\n  template <typename Source>\n  static TensorBuffer* Decode(Allocator* a, const Source& in, int64_t n) {\n    auto* buf = new Buffer<ResourceHandle>(a, n);\n    ResourceHandle* ps = buf->template base<ResourceHandle>();\n    if (ps == nullptr ||\n        !DecodeResourceHandleList(port::NewStringListDecoder(in), ps, n)) {\n      buf->Unref();\n      return nullptr;\n    }\n    return buf;\n  }\n\n  // Returns the estimated memory usage of \"n\" elements of type T\n  // stored in buffer \"in\".\n  static int64_t TotalBytes(TensorBuffer* in, int n) {\n    return n * sizeof(ResourceHandle);\n  }\n};\n\ntemplate <>\nstruct Helper<Variant> {\n  // Encodes \"n\" elements of type Variant stored in \"in\" into destination\n  // \"out\", which is usually the TensorProto::tensor_content.\n  template <typename Destination>\n  static void Encode(TensorBuffer* in, int64_t n, Destination* out) {\n    EncodeVariantList(in->base<const Variant>(), n,\n                      port::NewStringListEncoder(out));\n  }\n\n  // Decodes \"n\" elements of type Variant from \"in\" and constructs a\n  // buffer out of it. Returns nullptr if the decoding fails. \"in\" is\n  // usually the TensorProto::tensor_content.\n  template <typename Source>\n  static TensorBuffer* Decode(Allocator* a, const Source& in, int64_t n) {\n    auto* buf = new Buffer<Variant>(a, n);\n    Variant* ps = buf->template base<Variant>();\n    if (ps == nullptr ||\n        !DecodeVariantList(port::NewStringListDecoder(in), ps, n)) {\n      buf->Unref();\n      return nullptr;\n    }\n    return buf;\n  }\n\n  // Returns the estimated memory usage of \"n\" elements of type T\n  // stored in buffer \"in\".\n  static int64_t TotalBytes(TensorBuffer* in, int n) {\n    return n * sizeof(Variant);\n  }\n};\n\ntemplate <typename T>\nstruct ProtoHelper {};\n\n// For a C++ type \"T\" (float, double, int32, etc.), the repeated field\n// \"N\"_val (float_val, int_val, label_val, etc.) of type \"F\" (float,\n// int32, string, etc) in the TensorProto is used for serializing the\n// tensor of type \"T\".\n#define PROTO_TRAITS(T, F, N)                                          \\\n  template <>                                                          \\\n  struct ProtoHelper<T> {                                              \\\n    typedef Helper<F>::RepeatedFieldType FieldType;                    \\\n    static FieldType::const_iterator Begin(const TensorProto& proto) { \\\n      return proto.N##_val().begin();                                  \\\n    }                                                                  \\\n    static size_t NumElements(const TensorProto& proto) {              \\\n      return proto.N##_val().size();                                   \\\n    }                                                                  \\\n    static void Fill(const T* data, size_t n, TensorProto* proto) {    \\\n      typename ProtoHelper<T>::FieldType copy(data, data + n);         \\\n      proto->mutable_##N##_val()->Swap(&copy);                         \\\n    }                                                                  \\\n  };\nPROTO_TRAITS(float, float, float);\nPROTO_TRAITS(double, double, double);\nPROTO_TRAITS(int32, int32, int);\nPROTO_TRAITS(uint8, int32, int);\nPROTO_TRAITS(uint16, int32, int);\nPROTO_TRAITS(uint32, uint32, uint32);\nPROTO_TRAITS(int16, int32, int);\nPROTO_TRAITS(int8, int32, int);\nPROTO_TRAITS(bool, bool, bool);\nPROTO_TRAITS(tstring, tstring, string);\nPROTO_TRAITS(qint8, int32, int);\nPROTO_TRAITS(quint8, int32, int);\nPROTO_TRAITS(qint16, int32, int);\nPROTO_TRAITS(quint16, int32, int);\n#undef PROTO_TRAITS\n\ntemplate <>\nstruct ProtoHelper<int64_t> {\n  static const int64_t* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const int64_t*>(proto.int64_val().begin());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.int64_val().size();\n  }\n  static void Fill(const int64_t* data, size_t n, TensorProto* proto) {\n    protobuf::RepeatedField<protobuf_int64> copy(data, data + n);\n    proto->mutable_int64_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<uint64> {\n  static const uint64* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const uint64*>(proto.uint64_val().begin());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.uint64_val().size();\n  }\n  static void Fill(const uint64* data, size_t n, TensorProto* proto) {\n    protobuf::RepeatedField<protobuf_uint64> copy(data, data + n);\n    proto->mutable_uint64_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<ResourceHandle> {\n  static protobuf::RepeatedPtrField<ResourceHandleProto>::const_iterator Begin(\n      const TensorProto& proto) {\n    return proto.resource_handle_val().begin();\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.resource_handle_val().size();\n  }\n  static void Fill(const ResourceHandle* data, size_t n, TensorProto* proto) {\n    auto* handles = proto->mutable_resource_handle_val();\n    handles->Clear();\n    for (size_t i = 0; i < n; i++) {\n      data[i].AsProto(handles->Add());\n    }\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<Variant> {\n  static protobuf::RepeatedPtrField<VariantTensorDataProto>::const_iterator\n  Begin(const TensorProto& proto) {\n    return proto.variant_val().begin();\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.variant_val().size();\n  }\n  static void Fill(const Variant* data, size_t n, TensorProto* proto) {\n    auto* variant_values = proto->mutable_variant_val();\n    variant_values->Clear();\n    for (size_t i = 0; i < n; ++i) {\n      VariantTensorData tmp;\n      data[i].Encode(&tmp);\n      tmp.ToProto(variant_values->Add());\n    }\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<complex64> {\n  typedef Helper<float>::RepeatedFieldType FieldType;\n  static const complex64* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const complex64*>(proto.scomplex_val().data());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.scomplex_val().size() / 2;\n  }\n  static void Fill(const complex64* data, size_t n, TensorProto* proto) {\n    const float* p = reinterpret_cast<const float*>(data);\n    FieldType copy(p, p + n * 2);\n    proto->mutable_scomplex_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<complex128> {\n  typedef Helper<double>::RepeatedFieldType FieldType;\n  static const complex128* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const complex128*>(proto.dcomplex_val().data());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.dcomplex_val().size() / 2;\n  }\n  static void Fill(const complex128* data, size_t n, TensorProto* proto) {\n    const double* p = reinterpret_cast<const double*>(data);\n    FieldType copy(p, p + n * 2);\n    proto->mutable_dcomplex_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<qint32> {\n  typedef Helper<int32>::RepeatedFieldType FieldType;\n  static const qint32* Begin(const TensorProto& proto) {\n    return reinterpret_cast<const qint32*>(proto.int_val().data());\n  }\n  static size_t NumElements(const TensorProto& proto) {\n    return proto.int_val().size();\n  }\n  static void Fill(const qint32* data, size_t n, TensorProto* proto) {\n    const int32* p = reinterpret_cast<const int32*>(data);\n    FieldType copy(p, p + n);\n    proto->mutable_int_val()->Swap(&copy);\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<bfloat16> {\n  static void Fill(const bfloat16* data, size_t n, TensorProto* proto) {\n    proto->mutable_half_val()->Reserve(n);\n    for (size_t i = 0; i < n; ++i) {\n      proto->mutable_half_val()->AddAlreadyReserved(\n          Eigen::numext::bit_cast<uint16>(data[i]));\n    }\n  }\n};\n\ntemplate <>\nstruct ProtoHelper<Eigen::half> {\n  static void Fill(const Eigen::half* data, size_t n, TensorProto* proto) {\n    proto->mutable_half_val()->Reserve(n);\n    for (size_t i = 0; i < n; ++i) {\n      proto->mutable_half_val()->AddAlreadyReserved(\n          Eigen::numext::bit_cast<uint16>(data[i]));\n    }\n  }\n};\n\ntemplate <typename T>\nBuffer<T>::Buffer(Allocator* a, int64_t n)\n    : BufferBase(a, TypedAllocator::Allocate<T>(a, n, AllocationAttributes())),\n      elem_(n) {}\n\ntemplate <typename T>\nBuffer<T>::Buffer(Allocator* a, int64_t n,\n                  const AllocationAttributes& allocation_attr)\n    : BufferBase(a, TypedAllocator::Allocate<T>(a, n, allocation_attr)),\n      elem_(n) {}\n\ntemplate <typename T>\nBuffer<T>::~Buffer() {\n  if (data()) {\n    if (MemoryLoggingEnabled()) {\n      RecordDeallocation();\n    }\n    TypedAllocator::Deallocate<T>(alloc_, static_cast<T*>(data()), elem_);\n  }\n}\n\n// Allocates a T[n] buffer. Fills in the buffer with repeated values\n// in \"in\".  If \"in\" has less values than \"n\", fills the rest of T[n]\n// with the last value. If \"in\" has no values, fills T[n] with the\n// default value for T.\n//\n// This routine is using the typed fields (float_val, etc.) in the\n// tensor proto as opposed to the untyped binary representation\n// (tensor_content). This is used when we expect the TensorProto is\n// used by a client program which may not know how to encode a tensor\n// in the compact binary representation.\ntemplate <typename T>\nTensorBuffer* FromProtoField(Allocator* a, const TensorProto& in, int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<T>* buf = new Buffer<T>(a, n);\n  T* data = buf->template base<T>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n\n  const int64_t in_n = ProtoHelper<T>::NumElements(in);\n  if (in_n <= 0) {\n    std::fill_n(data, n, T());\n  } else {\n    auto begin = ProtoHelper<T>::Begin(in);\n    if (n <= in_n) {\n      std::copy_n(begin, n, data);\n    } else {\n      std::copy_n(begin, in_n, data);\n      if (std::is_trivially_copyable<T>::value) {\n        const T last = *(data + in_n - 1);\n        std::fill_n(data + in_n, n - in_n, last);\n      } else {\n        const T& last = *(data + in_n - 1);\n        std::fill_n(data + in_n, n - in_n, last);\n      }\n    }\n  }\n\n  return buf;\n}\n\n// Separate implementation for `ResourceHandle` to handle the case when the\n// proto for the resource is invalid. See `resource_handle.h` constructor and\n// static factory builder.\ntemplate <>\nTensorBuffer* FromProtoField<ResourceHandle>(Allocator* a,\n                                             const TensorProto& in, int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<ResourceHandle>* buf = new Buffer<ResourceHandle>(a, n);\n  ResourceHandle* data = buf->template base<ResourceHandle>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n  const int64_t in_n = ProtoHelper<ResourceHandle>::NumElements(in);\n  if (in_n <= 0) {\n    std::fill_n(data, n, ResourceHandle());\n  } else {\n    // If tensor shape says we have n < in_n elements in the output tensor\n    // then make sure to only decode the first n out of the in_n elements in the\n    // in tensors. In all other cases, we decode all in_n elements of in and set\n    // the remaining elements up to n to be the default ResourceHandle() value.\n    const int64_t real_n = n < in_n ? n : in_n;\n    for (int64_t i = 0; i < real_n; ++i) {\n      Status s = ResourceHandle::BuildResourceHandle(in.resource_handle_val(i),\n                                                     &data[i]);\n      if (!s.ok()) {\n        LOG(ERROR) << \"Could not decode resource handle from proto \\\"\"\n                   << in.resource_handle_val(i).ShortDebugString()\n                   << \"\\\", returned status: \" << s.ToString();\n        buf->Unref();\n        return nullptr;\n      }\n    }\n    for (int64_t i = in_n; i < n; ++i) {\n      data[i] = ResourceHandle();\n    }\n  }\n  return buf;\n}\n\ntemplate <>\nTensorBuffer* FromProtoField<Variant>(Allocator* a, const TensorProto& in,\n                                      int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<Variant>* buf = new Buffer<Variant>(a, n);\n  Variant* data = buf->template base<Variant>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n  const int64_t in_n = ProtoHelper<Variant>::NumElements(in);\n  if (in_n <= 0) {\n    std::fill_n(data, n, Variant());\n  } else {\n    // If tensor shape says we have n < in_n elements in the output tensor\n    // then make sure to only decode the first n out of the in_n elements in the\n    // in tensors. In all other cases, we decode all in_n elements of in and set\n    // the remaining elements up to n to be the default Variant() value.\n    const int64_t real_n = n < in_n ? n : in_n;\n    for (int64_t i = 0; i < real_n; ++i) {\n      data[i] = in.variant_val(i);\n      if (!DecodeUnaryVariant(&data[i])) {\n        LOG(ERROR) << \"Could not decode variant with type_name: \\\"\"\n                   << data[i].TypeName()\n                   << \"\\\".  Perhaps you forgot to register a \"\n                      \"decoder via REGISTER_UNARY_VARIANT_DECODE_FUNCTION?\";\n        buf->Unref();\n        return nullptr;\n      }\n    }\n    for (int64_t i = in_n; i < n; ++i) {\n      data[i] = Variant();\n    }\n  }\n  return buf;\n}\n\n// fp16 and bfloat16 are opaque to the protobuf, so we deserialize these\n// identical to uint16 but with data stored in half_val instead of int_val (ie.,\n// we don't use ProtoHelper<uint16>).\ntemplate <>\nTensorBuffer* FromProtoField<Eigen::half>(Allocator* a, const TensorProto& in,\n                                          int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<Eigen::half>* buf = new Buffer<Eigen::half>(a, n);\n  uint16* data = buf->template base<uint16>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n  const int64_t in_n = in.half_val().size();\n  auto begin = in.half_val().begin();\n  if (n <= in_n) {\n    std::copy_n(begin, n, data);\n  } else if (in_n > 0) {\n    std::copy_n(begin, in_n, data);\n    const uint16 last = *(data + in_n - 1);\n    std::fill_n(data + in_n, n - in_n, last);\n  } else {\n    std::fill_n(data, n, 0);\n  }\n  return buf;\n}\n\ntemplate <>\nTensorBuffer* FromProtoField<bfloat16>(Allocator* a, const TensorProto& in,\n                                       int64_t n) {\n  CHECK_GT(n, 0);\n  Buffer<bfloat16>* buf = new Buffer<bfloat16>(a, n);\n  uint16* data = buf->template base<uint16>();\n  if (data == nullptr) {\n    buf->Unref();\n    return nullptr;\n  }\n  const int64_t in_n = in.half_val().size();\n  auto begin = in.half_val().begin();\n  if (n <= in_n) {\n    std::copy_n(begin, n, data);\n  } else if (in_n > 0) {\n    std::copy_n(begin, in_n, data);\n    const uint16 last = *(data + in_n - 1);\n    std::fill_n(data + in_n, n - in_n, last);\n  } else {\n    std::fill_n(data, n, 0);\n  }\n  return buf;\n}\n\n// Copies T[n] stored in the buffer \"in\" into the repeated field in\n// \"out\" corresponding to type T.\ntemplate <typename T>\nvoid ToProtoField(const TensorBuffer& in, int64_t n, TensorProto* out) {\n  const T* data = in.base<const T>();\n  // NOTE: T may not the same as\n  // ProtoHelper<T>::FieldType::value_type.  E.g., T==int16,\n  // ProtoHelper<T>::FieldType::value_type==int32.  If performance is\n  // critical, we can specialize T=float and do memcpy directly.\n  ProtoHelper<T>::Fill(data, n, out);\n}\n\nvoid RefIfNonNull(core::RefCounted* buf) {\n  if (buf) buf->Ref();\n}\n\nvoid UnrefIfNonNull(core::RefCounted* buf) {\n  if (buf) buf->Unref();\n}\n\n}  // end namespace\n\nTensor::Tensor() : Tensor(DT_FLOAT) {}\n\nTensor::Tensor(DataType type) : shape_(type), buf_(nullptr) {}\n\nTensor::Tensor(DataType type, const TensorShape& shape, TensorBuffer* buf)\n    : shape_(shape), buf_(buf) {\n  set_dtype(type);\n  RefIfNonNull(buf);\n}\n\nTensor::Tensor(DataType type, TensorShape shape,\n               core::RefCountPtr<TensorBuffer> buf)\n    : shape_(std::move(shape)), buf_(buf.release()) {\n  set_dtype(type);\n}\n\nbool Tensor::IsInitialized() const {\n  return (buf_ != nullptr && buf_->data() != nullptr) ||\n         shape_.num_elements() == 0;\n}\n\nvoid Tensor::CheckType(DataType expected_dtype) const {\n  CHECK_EQ(dtype(), expected_dtype)\n      << \" \" << DataTypeString(expected_dtype) << \" expected, got \"\n      << DataTypeString(dtype());\n}\n\nvoid Tensor::CheckTypeAndIsAligned(DataType expected_dtype) const {\n  CHECK_EQ(dtype(), expected_dtype)\n      << \" \" << DataTypeString(expected_dtype) << \" expected, got \"\n      << DataTypeString(dtype());\n  CHECK(IsAligned()) << \"ptr = \" << base<void>();\n}\n\nvoid Tensor::CheckIsAlignedAndSingleElement() const {\n  CHECK(IsAligned()) << \"Aligned and single element\";\n  CHECK_EQ(1, NumElements()) << \"Must have a one element tensor\";\n}\n\nTensor::~Tensor() { UnrefIfNonNull(buf_); }\n\nStatus Tensor::BitcastFrom(const Tensor& other, DataType dtype,\n                           const TensorShape& shape) {\n  int in_size = DataTypeSize(other.dtype());\n  int out_size = DataTypeSize(dtype);\n  if (in_size == 0) {\n    return errors::InvalidArgument(\"other tensor has zero-sized data type\");\n  }\n  if (out_size == 0) {\n    return errors::InvalidArgument(\"specified output type is zero-sized\");\n  }\n  if (shape.num_elements() * out_size !=\n      other.shape().num_elements() * in_size) {\n    return errors::InvalidArgument(\n        \"input and output shapes/data type sizes are not compatible\");\n  }\n  shape_ = shape;\n  shape_.set_data_type(dtype);\n  if (buf_ != other.buf_) {\n    UnrefIfNonNull(buf_);\n    buf_ = other.buf_;\n    RefIfNonNull(buf_);\n  }\n  return Status::OK();\n}\n\n// Notice that buf_ either points to a regular TensorBuffer or a SubBuffer.\n// For the latter case, we have to make sure that the refcount is\n// one both for the SubBuffer _and_ the underlying TensorBuffer.\nbool Tensor::RefCountIsOne() const {\n  return buf_ != nullptr && buf_->RefCountIsOne() &&\n         buf_->root_buffer()->RefCountIsOne() && buf_->OwnsMemory();\n}\n\n// The macro CASES() expands to a switch statement conditioned on\n// TYPE_ENUM. Each case expands the STMTS after a typedef for T.\n#define SINGLE_ARG(...) __VA_ARGS__\n#define CASE(TYPE, STMTS)               \\\n  case DataTypeToEnum<TYPE>::value: {   \\\n    typedef TF_ATTRIBUTE_UNUSED TYPE T; \\\n    STMTS;                              \\\n    break;                              \\\n  }\n#define CASES_WITH_DEFAULT(TYPE_ENUM, STMTS, INVALID, DEFAULT) \\\n  switch (TYPE_ENUM) {                                         \\\n    CASE(float, SINGLE_ARG(STMTS))                             \\\n    CASE(double, SINGLE_ARG(STMTS))                            \\\n    CASE(int32, SINGLE_ARG(STMTS))                             \\\n    CASE(uint8, SINGLE_ARG(STMTS))                             \\\n    CASE(uint16, SINGLE_ARG(STMTS))                            \\\n    CASE(uint32, SINGLE_ARG(STMTS))                            \\\n    CASE(uint64, SINGLE_ARG(STMTS))                            \\\n    CASE(int16, SINGLE_ARG(STMTS))                             \\\n    CASE(int8, SINGLE_ARG(STMTS))                              \\\n    CASE(tstring, SINGLE_ARG(STMTS))                           \\\n    CASE(complex64, SINGLE_ARG(STMTS))                         \\\n    CASE(complex128, SINGLE_ARG(STMTS))                        \\\n    CASE(int64_t, SINGLE_ARG(STMTS))                           \\\n    CASE(bool, SINGLE_ARG(STMTS))                              \\\n    CASE(qint32, SINGLE_ARG(STMTS))                            \\\n    CASE(quint8, SINGLE_ARG(STMTS))                            \\\n    CASE(qint8, SINGLE_ARG(STMTS))                             \\\n    CASE(quint16, SINGLE_ARG(STMTS))                           \\\n    CASE(qint16, SINGLE_ARG(STMTS))                            \\\n    CASE(bfloat16, SINGLE_ARG(STMTS))                          \\\n    CASE(Eigen::half, SINGLE_ARG(STMTS))                       \\\n    CASE(ResourceHandle, SINGLE_ARG(STMTS))                    \\\n    CASE(Variant, SINGLE_ARG(STMTS))                           \\\n    case DT_INVALID:                                           \\\n      INVALID;                                                 \\\n      break;                                                   \\\n    default:                                                   \\\n      DEFAULT;                                                 \\\n      break;                                                   \\\n  }\n\n#define CASES(TYPE_ENUM, STMTS)                                      \\\n  CASES_WITH_DEFAULT(TYPE_ENUM, STMTS, LOG(FATAL) << \"Type not set\"; \\\n                     , LOG(FATAL) << \"Unexpected type: \" << TYPE_ENUM;)\n\nTensor::Tensor(Allocator* a, DataType type, const TensorShape& shape)\n    : shape_(shape), buf_(nullptr) {\n  set_dtype(type);\n  CHECK_NOTNULL(a);\n  if (shape_.num_elements() > 0 || a->AllocatesOpaqueHandle()) {\n    CASES(type, buf_ = new Buffer<T>(a, shape.num_elements()));\n  }\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown\", LogMemory::UNKNOWN_STEP_ID,\n                                      *this);\n  }\n}\n\nTensor::Tensor(Allocator* a, DataType type, const TensorShape& shape,\n               const AllocationAttributes& allocation_attr)\n    : shape_(shape), buf_(nullptr) {\n  set_dtype(type);\n  CHECK_NOTNULL(a);\n  if (shape_.num_elements() > 0 || a->AllocatesOpaqueHandle()) {\n    CASES(type, buf_ = new Buffer<T>(a, shape.num_elements(), allocation_attr));\n  }\n  if (MemoryLoggingEnabled() && !allocation_attr.allocation_will_be_logged &&\n      buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (with attributes)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n}\n\nStatus Tensor::BuildTensor(DataType type, const TensorShape& shape,\n                           Tensor* out_tensor) {\n  // Avoid crashes due to invalid or unsupported types.\n  CASES_WITH_DEFAULT(\n      type, {}, return errors::InvalidArgument(\"Type not set\"),\n      return errors::InvalidArgument(\"Unexpected type: \", DataType_Name(type)));\n  *out_tensor = Tensor(type, shape);\n  return Status::OK();\n}\n\n// NOTE(mrry): The default allocator for a Tensor (when none is specified) is\n// the default CPU allocator for NUMA zone 0. Accessing that currently involves\n// acquiring a lock, which guards initialization of the per-NUMA zone\n// allocators, and becomes highly contended.\n//\n// Note also that it would be better if all Tensor allocations required the user\n// to specify an allocator, for purposes of accounting, etc. However, the\n// default allocator is widely used throughout the codebase and in client code.\nstatic Allocator* get_default_cpu_allocator() {\n  static Allocator* default_cpu_allocator =\n      cpu_allocator(port::kNUMANoAffinity);\n  return default_cpu_allocator;\n}\n\nTensor::Tensor(DataType type, const TensorShape& shape)\n    : Tensor(get_default_cpu_allocator(), type, shape) {}\n\nbool Tensor::HostScalarTensorBufferBase::GetAllocatedBytes(\n    size_t* out_bytes) const {\n  // `this->FillAllocationDescription()` never sets allocated bytes information,\n  // so we can short-circuit the construction of an `AllocationDescription`.\n  return false;\n}\n\nvoid Tensor::HostScalarTensorBufferBase::FillAllocationDescription(\n    AllocationDescription* proto) const {\n  proto->set_requested_bytes(size());\n  proto->set_allocator_name(\"HostScalarTensorBuffer\");\n  proto->set_ptr(reinterpret_cast<uintptr_t>(data()));\n}\n\ntemplate <typename T>\nclass SubBuffer : public TensorBuffer {\n public:\n  // This buffer is an alias to buf[delta, delta + n).\n  SubBuffer(TensorBuffer* buf, int64_t delta, int64_t n)\n      : TensorBuffer(buf->base<T>() + delta),\n        root_(buf->root_buffer()),\n        elem_(n) {\n    // Sanity check. The caller should ensure the sub buffer is valid.\n    CHECK_LE(root_->base<T>(), this->base<T>());\n    T* root_limit = root_->base<T>() + root_->size() / sizeof(T);\n    CHECK_LE(this->base<T>(), root_limit);\n    CHECK_LE(this->base<T>() + n, root_limit);\n    // Hold a ref of the underlying root buffer.\n    // NOTE: 'buf' is a sub-buffer inside the 'root_' buffer.\n    root_->Ref();\n  }\n\n  size_t size() const override { return sizeof(T) * elem_; }\n  TensorBuffer* root_buffer() override { return root_; }\n  bool GetAllocatedBytes(size_t* out_bytes) const override {\n    return root_->GetAllocatedBytes(out_bytes);\n  }\n  void FillAllocationDescription(AllocationDescription* proto) const override {\n    root_->FillAllocationDescription(proto);\n  }\n\n private:\n  TensorBuffer* root_;\n  int64_t elem_;\n\n  ~SubBuffer() override { root_->Unref(); }\n\n  TF_DISALLOW_COPY_AND_ASSIGN(SubBuffer);\n};\n\nTensor Tensor::Slice(int64_t start, int64_t limit) const {\n  CHECK_GE(dims(), 1);\n  CHECK_LE(0, start);\n  CHECK_LE(start, limit);\n  int64_t dim0_size = shape_.dim_size(0);\n  CHECK_LE(limit, dim0_size);\n  if ((start == 0) && (limit == dim0_size)) {\n    return *this;\n  }\n  Tensor ret;\n  ret.shape_ = shape_;\n  ret.set_dtype(dtype());\n  ret.buf_ = nullptr;\n  if (dim0_size > 0) {\n    const int64_t elems_per_dim0 = NumElements() / dim0_size;\n    const int64_t delta = start * elems_per_dim0;\n    dim0_size = limit - start;\n    ret.shape_.set_dim(0, dim0_size);\n    const int64_t num_elems = dim0_size * elems_per_dim0;\n    if (buf_) {\n      DataType dt = dtype();\n      CASES(dt, ret.buf_ = new SubBuffer<T>(buf_, delta, num_elems));\n    }\n  }\n  return ret;\n}\n\nTensor Tensor::SubSlice(int64_t index) const {\n  CHECK_GE(dims(), 1);  // Crash ok.\n  CHECK_LE(0, index);   // Crash ok.\n  int64_t dim0_size = shape_.dim_size(0);\n  CHECK_LE(index, dim0_size);  // Crash ok.\n  Tensor ret;\n  ret.shape_ = shape_;\n  ret.shape_.RemoveDim(0);\n  ret.set_dtype(dtype());\n  ret.buf_ = nullptr;\n  if (dim0_size > 0) {\n    const int64_t elems_per_dim0 = NumElements() / dim0_size;\n    const int64_t delta = index * elems_per_dim0;\n    const int64_t num_elems = elems_per_dim0;\n    if (buf_) {\n      DataType dt = dtype();\n      CASES(dt, ret.buf_ = new SubBuffer<T>(buf_, delta, num_elems));\n    }\n  }\n  return ret;\n}\n\nbool Tensor::FromProto(const TensorProto& proto) {\n  return FromProto(get_default_cpu_allocator(), proto);\n}\n\nbool Tensor::FromProto(Allocator* a, const TensorProto& proto) {\n  CHECK_NOTNULL(a);\n  TensorBuffer* p = nullptr;\n  if (!TensorShape::IsValid(proto.tensor_shape())) return false;\n  if (proto.dtype() == DT_INVALID) return false;\n  TensorShape shape(proto.tensor_shape());\n  const int64_t N = shape.num_elements();\n  if (N > 0 && proto.dtype()) {\n    bool dtype_error = false;\n    if (!proto.tensor_content().empty()) {\n      const auto& content = proto.tensor_content();\n      CASES_WITH_DEFAULT(proto.dtype(), p = Helper<T>::Decode(a, content, N),\n                         dtype_error = true, dtype_error = true);\n    } else {\n      CASES_WITH_DEFAULT(proto.dtype(), p = FromProtoField<T>(a, proto, N),\n                         dtype_error = true, dtype_error = true);\n    }\n    if (dtype_error || p == nullptr) return false;\n  }\n  shape_ = shape;\n  set_dtype(proto.dtype());\n  UnrefIfNonNull(buf_);\n  buf_ = p;\n  // TODO(misard) add tracking of which kernels and steps are calling\n  // FromProto.\n  if (MemoryLoggingEnabled() && buf_ != nullptr && buf_->data() != nullptr) {\n    LogMemory::RecordTensorAllocation(\"Unknown (from Proto)\",\n                                      LogMemory::UNKNOWN_STEP_ID, *this);\n  }\n  return true;\n}\n\nvoid Tensor::AsProtoField(TensorProto* proto) const {\n  proto->Clear();\n  shape_.AsProto(proto->mutable_tensor_shape());\n  proto->set_dtype(dtype());\n  if (buf_) {\n    CASES(dtype(), ToProtoField<T>(*buf_, shape_.num_elements(), proto));\n  }\n}\n\nvoid Tensor::AsProtoTensorContent(TensorProto* proto) const {\n  proto->Clear();\n  proto->set_dtype(dtype());\n  shape_.AsProto(proto->mutable_tensor_shape());\n  if (buf_) {\n    CASES(dtype(), Helper<T>::Encode(buf_, shape_.num_elements(),\n                                     proto->mutable_tensor_content()));\n  }\n}\n\nsize_t Tensor::TotalBytes() const {\n  if (shape_.num_elements() == 0) return 0;\n  CHECK(buf_) << \"null buf_ with non-zero shape size \" << shape_.num_elements();\n  CASES(dtype(), return Helper<T>::TotalBytes(buf_, shape_.num_elements()));\n  return 0;  // Makes compiler happy.\n}\n\nsize_t Tensor::AllocatedBytes() const {\n  if (buf_) {\n    size_t ret;\n    if (buf_->GetAllocatedBytes(&ret)) {\n      return ret;\n    }\n  }\n  return TotalBytes();\n}\n\nbool Tensor::CanUseDMA() const {\n  CASES(dtype(), return is_simple_type<T>::value);\n  return false;  // Makes compiler happy.\n}\n\n#undef CASES\n#undef CASE\n\nnamespace {\n\n// StrCat and StrAppend don't support Eigen::half directly at the moment, and\n// we would like to keep them compatible with their absl counterparts, for ease\n// of migration. We could rely on errors::internal::PrepareForStrCat() but the\n// logic is so simple we can just replicate it here, where it is close to its\n// usage and easy to change later. And there's the extra benefit of not\n// accessing an 'internal' namespace.\ninline const strings::AlphaNum& PrintOneElement(const strings::AlphaNum& a,\n                                                bool print_v2) {\n  return a;\n}\ninline string PrintOneElement(const tstring& a, bool print_v2) {\n  if (print_v2) {\n    return \"\\\"\" + absl::Utf8SafeCEscape(a) + \"\\\"\";\n  } else {\n    return absl::Utf8SafeCEscape(a);\n  }\n}\ninline float PrintOneElement(const Eigen::half& h, bool print_v2) {\n  return static_cast<float>(h);\n}\n\ninline float PrintOneElement(bfloat16 f, bool print_v2) {\n  return static_cast<float>(f);\n}\n\n// Print from left dim to right dim recursively.\ntemplate <typename T>\nvoid PrintOneDim(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n                 int64_t limit, int shape_size, const T* data,\n                 int64_t* data_index, string* result) {\n  if (*data_index >= limit) return;\n  int64_t element_count = shape[dim_index];\n  // We have reached the right-most dimension of the tensor.\n  if (dim_index == shape_size - 1) {\n    for (int64_t i = 0; i < element_count; i++) {\n      if (*data_index >= limit) {\n        // If not enough elements has been printed, append \"...\".\n        if (dim_index != 0) {\n          strings::StrAppend(result, \"...\");\n        }\n        return;\n      }\n      if (i > 0) strings::StrAppend(result, \" \");\n      strings::StrAppend(result, PrintOneElement(data[(*data_index)++], false));\n    }\n    return;\n  }\n  // Loop every element of one dim.\n  for (int64_t i = 0; i < element_count; i++) {\n    bool flag = false;\n    if (*data_index < limit) {\n      strings::StrAppend(result, \"[\");\n      flag = true;\n    }\n    // As for each element, print the sub-dim.\n    PrintOneDim(dim_index + 1, shape, limit, shape_size, data, data_index,\n                result);\n    if (*data_index < limit || flag) {\n      strings::StrAppend(result, \"]\");\n      flag = false;\n    }\n  }\n}\n\n// Appends the spacing between elements for a given dim onto a result string\nvoid PrintDimSpacing(int dim_index, int num_dims, string* result) {\n  if (dim_index == num_dims - 1) {\n    strings::StrAppend(result, \" \");\n    return;\n  }\n  for (int j = 0; j < num_dims - dim_index - 1; j++) {\n    strings::StrAppend(result, \"\\n\");\n  }\n  for (int j = 0; j <= dim_index; j++) {\n    strings::StrAppend(result, \" \");\n  }\n}\n\n// Print from left dim to right dim recursively.\ntemplate <typename T>\nvoid PrintOneDimV2(int dim_index, const gtl::InlinedVector<int64, 4>& shape,\n                   int64_t num_elts_at_ends, int num_dims, const T* data,\n                   int64_t data_index, string* result) {\n  // We have recursed beyond all the dimensions into a single element\n  // of the tensor.\n  if (dim_index == num_dims) {\n    strings::StrAppend(result, PrintOneElement(data[data_index], true));\n    return;\n  }\n\n  strings::StrAppend(result, \"[\");\n  int64_t element_count = shape[dim_index];\n  int64_t start_of_end =\n      std::max(num_elts_at_ends, element_count - num_elts_at_ends);\n\n  // Loop every element of one dim.\n  int64_t elements_per_iter = 1;\n  for (int i = dim_index + 1; i < num_dims; i++) {\n    elements_per_iter *= shape[i];\n  }\n  for (int64_t i = 0; (i < num_elts_at_ends) && (i < element_count); i++) {\n    if (i > 0) {\n      PrintDimSpacing(dim_index, num_dims, result);\n    }\n\n    // As for each element, print the sub-dim.\n    PrintOneDimV2(dim_index + 1, shape, num_elts_at_ends, num_dims, data,\n                  data_index + elements_per_iter * i, result);\n  }\n  if (element_count > 2 * num_elts_at_ends) {\n    PrintDimSpacing(dim_index, num_dims, result);\n    strings::StrAppend(result, \"...\");\n  }\n  for (int64_t i = start_of_end; i < element_count; i++) {\n    // As for each element, print the sub-dim.\n    PrintDimSpacing(dim_index, num_dims, result);\n    PrintOneDimV2(dim_index + 1, shape, num_elts_at_ends, num_dims, data,\n                  data_index + elements_per_iter * i, result);\n  }\n\n  strings::StrAppend(result, \"]\");\n}\n\ntemplate <typename T>\nstring SummarizeArray(int64_t limit, int64_t num_elts,\n                      const TensorShape& tensor_shape, const char* data,\n                      const bool print_v2) {\n  string ret;\n  const T* array = reinterpret_cast<const T*>(data);\n\n  const gtl::InlinedVector<int64_t, 4> shape = tensor_shape.dim_sizes();\n  if (shape.empty()) {\n    for (int64_t i = 0; i < limit; ++i) {\n      if (i > 0) strings::StrAppend(&ret, \" \");\n      strings::StrAppend(&ret, PrintOneElement(array[i], print_v2));\n    }\n    if (num_elts > limit) strings::StrAppend(&ret, \"...\");\n    return ret;\n  }\n  if (print_v2) {\n    const int num_dims = tensor_shape.dims();\n    PrintOneDimV2(0, shape, limit, num_dims, array, 0, &ret);\n  } else {\n    int64_t data_index = 0;\n    const int shape_size = tensor_shape.dims();\n    PrintOneDim(0, shape, limit, shape_size, array, &data_index, &ret);\n\n    if (num_elts > limit) strings::StrAppend(&ret, \"...\");\n  }\n\n  return ret;\n}\n}  // namespace\n\nstring Tensor::SummarizeValue(int64_t max_entries, bool print_v2) const {\n  const int64_t num_elts = NumElements();\n  if (max_entries < 0) {\n    max_entries = num_elts;\n  }\n  size_t limit = std::min(max_entries, num_elts);\n  if ((limit > 0) && (buf_ == nullptr)) {\n    return strings::StrCat(\"uninitialized Tensor of \", num_elts,\n                           \" elements of type \", dtype());\n  }\n  const char* data = limit > 0 ? tensor_data().data() : nullptr;\n  switch (dtype()) {\n    case DT_BFLOAT16:\n      return SummarizeArray<bfloat16>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_HALF:\n      return SummarizeArray<Eigen::half>(limit, num_elts, shape_, data,\n                                         print_v2);\n      break;\n    case DT_FLOAT:\n      return SummarizeArray<float>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_DOUBLE:\n      return SummarizeArray<double>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_UINT32:\n      return SummarizeArray<uint32>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_INT32:\n      return SummarizeArray<int32>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_UINT8:\n    case DT_QUINT8:\n      return SummarizeArray<uint8>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_UINT16:\n    case DT_QUINT16:\n      return SummarizeArray<uint16>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_INT16:\n    case DT_QINT16:\n      return SummarizeArray<int16>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_INT8:\n    case DT_QINT8:\n      return SummarizeArray<int8>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_UINT64:\n      return SummarizeArray<uint64>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_INT64:\n      return SummarizeArray<int64_t>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_BOOL:\n      // TODO(tucker): Is it better to emit \"True False...\"?  This\n      // will emit \"1 0...\" which is more compact.\n      return SummarizeArray<bool>(limit, num_elts, shape_, data, print_v2);\n      break;\n    case DT_STRING:\n      return SummarizeArray<tstring>(limit, num_elts, shape_, data, print_v2);\n      break;\n    default: {\n      // All irregular cases\n      string ret;\n      if (print_v2 && (dims() > 0)) {\n        strings::StrAppend(&ret, \"[\");\n      }\n      // TODO(irving): Don't call flat every time around this\n      // loop.\n      for (size_t i = 0; i < limit; ++i) {\n        if (i > 0) strings::StrAppend(&ret, \" \");\n        switch (dtype()) {\n          case DT_VARIANT: {\n            const Variant& v = flat<Variant>()(i);\n            strings::StrAppend(&ret, \"<\", v.SummarizeValue(), \">\");\n          } break;\n          case DT_RESOURCE: {\n            const ResourceHandle& r = flat<ResourceHandle>()(i);\n            strings::StrAppend(&ret, \"<\", r.SummarizeValue(), \">\");\n          } break;\n          default:\n            // TODO(zhifengc, josh11b): Pretty-print other types (bool,\n            // complex64, quantized).\n            strings::StrAppend(&ret, \"?\");\n        }\n      }\n      if (max_entries < num_elts) strings::StrAppend(&ret, \"...\");\n      if (print_v2 && (dims() > 0)) {\n        strings::StrAppend(&ret, \"]\");\n      }\n      return ret;\n    }\n  }\n}\n\nStringPiece Tensor::tensor_data() const {\n  if (buf_ == nullptr) return StringPiece();  // Don't die for empty tensors\n  return StringPiece(static_cast<char*>(buf_->data()), TotalBytes());\n}\n\nvoid* Tensor::data() const {\n  if (buf_ == nullptr) return nullptr;  // Don't die for empty tensors\n  return static_cast<void*>(buf_->data());\n}\n\nbool Tensor::SharesBufferWith(const Tensor& b) const {\n  return buf_ != nullptr && b.buf_ != nullptr &&\n         buf_->root_buffer() == b.buf_->root_buffer();\n}\n\nstring Tensor::DebugString(int num_values) const {\n  return strings::StrCat(\"Tensor<type: \", DataTypeString(dtype()),\n                         \" shape: \", shape().DebugString(),\n                         \" values: \", SummarizeValue(num_values), \">\");\n}\n\nstring Tensor::DeviceSafeDebugString() const {\n  return strings::StrCat(\"Tensor<type: \", DataTypeString(dtype()),\n                         \" shape: \", shape().DebugString(), \">\");\n}\n\nvoid Tensor::FillDescription(TensorDescription* description) const {\n  description->set_dtype(dtype());\n  shape().AsProto(description->mutable_shape());\n  if (buf_ != nullptr && buf_->data() != nullptr) {\n    buf_->FillAllocationDescription(\n        description->mutable_allocation_description());\n  }\n}\n\ngtl::InlinedVector<int64_t, 4> Tensor::ComputeFlatInnerDims(\n    gtl::ArraySlice<int64_t> orig, int64_t num_out_dims) {\n  gtl::InlinedVector<int64_t, 4> out_dims(num_out_dims, 0);\n  int64_t offset = orig.size() - num_out_dims;\n  for (int64_t out_dim = num_out_dims - 1; out_dim >= 0; --out_dim) {\n    const int64_t in_dim = out_dim + offset;\n    out_dims[out_dim] = in_dim < 0 ? 1 : orig[in_dim];\n  }\n  for (int64_t in_dim = 0; in_dim < offset; ++in_dim) {\n    out_dims[0] *= orig[in_dim];\n  }\n  return out_dims;\n}\n\ngtl::InlinedVector<int64_t, 4> Tensor::ComputeFlatOuterDims(\n    gtl::ArraySlice<int64_t> orig, int64_t num_out_dims) {\n  gtl::InlinedVector<int64_t, 4> out_dims(num_out_dims, 0);\n  for (int64_t out_dim = 0; out_dim <= num_out_dims - 1; ++out_dim) {\n    out_dims[out_dim] = out_dim >= orig.size() ? 1 : orig[out_dim];\n  }\n  for (int64_t in_dim = num_out_dims; in_dim < orig.size(); ++in_dim) {\n    out_dims[num_out_dims - 1] *= orig[in_dim];\n  }\n  return out_dims;\n}\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/framework/BUILD", "tensorflow/core/framework/resource_handle.cc", "tensorflow/core/framework/resource_handle.h", "tensorflow/core/framework/tensor.cc"], "buggy_code_start_loc": [736, 19, 48, 536], "buggy_code_end_loc": [737, 144, 95, 536], "fixing_code_start_loc": [737, 20, 49, 537], "fixing_code_end_loc": [740, 161, 100, 577], "type": "CWE-617", "message": "Tensorflow is an Open Source Machine Learning Framework. When decoding a resource handle tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2022-23564", "sourceIdentifier": "security-advisories@github.com", "published": "2022-02-04T23:15:13.953", "lastModified": "2022-02-09T17:49:57.790", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Tensorflow is an Open Source Machine Learning Framework. When decoding a resource handle tensor from protobuf, a TensorFlow process can encounter cases where a `CHECK` assertion is invalidated based on user controlled arguments. This allows attackers to cause denial of services in TensorFlow processes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range."}, {"lang": "es", "value": "Tensorflow es un Marco de Aprendizaje Autom\u00e1tico de C\u00f3digo Abierto. Cuando es decodificado un tensor de manejo de recursos desde protobuf, un proceso de TensorFlow puede encontrar casos en los que una aserci\u00f3n \"CHECK\" no es comprobada en base a argumentos controlados por el usuario. Esto permite a atacantes causar una denegaci\u00f3n de servicios en los procesos TensorFlow. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.8.0. Tambi\u00e9n seleccionaremos este commit en TensorFlow versi\u00f3n 2.7.1, TensorFlow versi\u00f3n 2.6.3, y TensorFlow versi\u00f3n 2.5.3, ya que estos tambi\u00e9n est\u00e1n afectados y a\u00fan est\u00e1n en el rango admitido"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 4.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-617"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.5.2", "matchCriteriaId": "688150BF-477C-48FC-9AEF-A79AC57A6DDC"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.0", "versionEndIncluding": "2.6.2", "matchCriteriaId": "C9E69B60-8C97-47E2-9027-9598B8392E5D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.7.0:*:*:*:*:*:*:*", "matchCriteriaId": "2EDFAAB8-799C-4259-9102-944D4760DA2C"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/14fea662350e7c26eb5fe1be2ac31704e5682ee6", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-8rcj-c8pj-v3m3", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/14fea662350e7c26eb5fe1be2ac31704e5682ee6"}}
{"buggy_code": ["/* SPDX-License-Identifier: (GPL-2.0 OR CDDL-1.0) */\n/*\n * vboxguest vmm-req and hgcm-call code, VBoxGuestR0LibHGCMInternal.cpp,\n * VBoxGuestR0LibGenericRequest.cpp and RTErrConvertToErrno.cpp in vbox svn.\n *\n * Copyright (C) 2006-2016 Oracle Corporation\n */\n\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/sizes.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/vbox_err.h>\n#include <linux/vbox_utils.h>\n#include \"vboxguest_core.h\"\n\n/* Get the pointer to the first parameter of a HGCM call request. */\n#define VMMDEV_HGCM_CALL_PARMS(a) \\\n\t((struct vmmdev_hgcm_function_parameter *)( \\\n\t\t(u8 *)(a) + sizeof(struct vmmdev_hgcm_call)))\n\n/* The max parameter buffer size for a user request. */\n#define VBG_MAX_HGCM_USER_PARM\t\t(24 * SZ_1M)\n/* The max parameter buffer size for a kernel request. */\n#define VBG_MAX_HGCM_KERNEL_PARM\t(16 * SZ_1M)\n\n#define VBG_DEBUG_PORT\t\t\t0x504\n\n/* This protects vbg_log_buf and serializes VBG_DEBUG_PORT accesses */\nstatic DEFINE_SPINLOCK(vbg_log_lock);\nstatic char vbg_log_buf[128];\n\n#define VBG_LOG(name, pr_func) \\\nvoid name(const char *fmt, ...)\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tunsigned long flags;\t\t\t\t\t\t\\\n\tva_list args;\t\t\t\t\t\t\t\\\n\tint i, count;\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tva_start(args, fmt);\t\t\t\t\t\t\\\n\tspin_lock_irqsave(&vbg_log_lock, flags);\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tcount = vscnprintf(vbg_log_buf, sizeof(vbg_log_buf), fmt, args);\\\n\tfor (i = 0; i < count; i++)\t\t\t\t\t\\\n\t\toutb(vbg_log_buf[i], VBG_DEBUG_PORT);\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tpr_func(\"%s\", vbg_log_buf);\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tspin_unlock_irqrestore(&vbg_log_lock, flags);\t\t\t\\\n\tva_end(args);\t\t\t\t\t\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\nEXPORT_SYMBOL(name)\n\nVBG_LOG(vbg_info, pr_info);\nVBG_LOG(vbg_warn, pr_warn);\nVBG_LOG(vbg_err, pr_err);\n#if defined(DEBUG) && !defined(CONFIG_DYNAMIC_DEBUG)\nVBG_LOG(vbg_debug, pr_debug);\n#endif\n\nvoid *vbg_req_alloc(size_t len, enum vmmdev_request_type req_type,\n\t\t    u32 requestor)\n{\n\tstruct vmmdev_request_header *req;\n\tint order = get_order(PAGE_ALIGN(len));\n\n\treq = (void *)__get_free_pages(GFP_KERNEL | GFP_DMA32, order);\n\tif (!req)\n\t\treturn NULL;\n\n\tmemset(req, 0xaa, len);\n\n\treq->size = len;\n\treq->version = VMMDEV_REQUEST_HEADER_VERSION;\n\treq->request_type = req_type;\n\treq->rc = VERR_GENERAL_FAILURE;\n\treq->reserved1 = 0;\n\treq->requestor = requestor;\n\n\treturn req;\n}\n\nvoid vbg_req_free(void *req, size_t len)\n{\n\tif (!req)\n\t\treturn;\n\n\tfree_pages((unsigned long)req, get_order(PAGE_ALIGN(len)));\n}\n\n/* Note this function returns a VBox status code, not a negative errno!! */\nint vbg_req_perform(struct vbg_dev *gdev, void *req)\n{\n\tunsigned long phys_req = virt_to_phys(req);\n\n\toutl(phys_req, gdev->io_port + VMMDEV_PORT_OFF_REQUEST);\n\t/*\n\t * The host changes the request as a result of the outl, make sure\n\t * the outl and any reads of the req happen in the correct order.\n\t */\n\tmb();\n\n\treturn ((struct vmmdev_request_header *)req)->rc;\n}\n\nstatic bool hgcm_req_done(struct vbg_dev *gdev,\n\t\t\t  struct vmmdev_hgcmreq_header *header)\n{\n\tunsigned long flags;\n\tbool done;\n\n\tspin_lock_irqsave(&gdev->event_spinlock, flags);\n\tdone = header->flags & VMMDEV_HGCM_REQ_DONE;\n\tspin_unlock_irqrestore(&gdev->event_spinlock, flags);\n\n\treturn done;\n}\n\nint vbg_hgcm_connect(struct vbg_dev *gdev, u32 requestor,\n\t\t     struct vmmdev_hgcm_service_location *loc,\n\t\t     u32 *client_id, int *vbox_status)\n{\n\tstruct vmmdev_hgcm_connect *hgcm_connect = NULL;\n\tint rc;\n\n\thgcm_connect = vbg_req_alloc(sizeof(*hgcm_connect),\n\t\t\t\t     VMMDEVREQ_HGCM_CONNECT, requestor);\n\tif (!hgcm_connect)\n\t\treturn -ENOMEM;\n\n\thgcm_connect->header.flags = 0;\n\tmemcpy(&hgcm_connect->loc, loc, sizeof(*loc));\n\thgcm_connect->client_id = 0;\n\n\trc = vbg_req_perform(gdev, hgcm_connect);\n\n\tif (rc == VINF_HGCM_ASYNC_EXECUTE)\n\t\twait_event(gdev->hgcm_wq,\n\t\t\t   hgcm_req_done(gdev, &hgcm_connect->header));\n\n\tif (rc >= 0) {\n\t\t*client_id = hgcm_connect->client_id;\n\t\trc = hgcm_connect->header.result;\n\t}\n\n\tvbg_req_free(hgcm_connect, sizeof(*hgcm_connect));\n\n\t*vbox_status = rc;\n\treturn 0;\n}\nEXPORT_SYMBOL(vbg_hgcm_connect);\n\nint vbg_hgcm_disconnect(struct vbg_dev *gdev, u32 requestor,\n\t\t\tu32 client_id, int *vbox_status)\n{\n\tstruct vmmdev_hgcm_disconnect *hgcm_disconnect = NULL;\n\tint rc;\n\n\thgcm_disconnect = vbg_req_alloc(sizeof(*hgcm_disconnect),\n\t\t\t\t\tVMMDEVREQ_HGCM_DISCONNECT,\n\t\t\t\t\trequestor);\n\tif (!hgcm_disconnect)\n\t\treturn -ENOMEM;\n\n\thgcm_disconnect->header.flags = 0;\n\thgcm_disconnect->client_id = client_id;\n\n\trc = vbg_req_perform(gdev, hgcm_disconnect);\n\n\tif (rc == VINF_HGCM_ASYNC_EXECUTE)\n\t\twait_event(gdev->hgcm_wq,\n\t\t\t   hgcm_req_done(gdev, &hgcm_disconnect->header));\n\n\tif (rc >= 0)\n\t\trc = hgcm_disconnect->header.result;\n\n\tvbg_req_free(hgcm_disconnect, sizeof(*hgcm_disconnect));\n\n\t*vbox_status = rc;\n\treturn 0;\n}\nEXPORT_SYMBOL(vbg_hgcm_disconnect);\n\nstatic u32 hgcm_call_buf_size_in_pages(void *buf, u32 len)\n{\n\tu32 size = PAGE_ALIGN(len + ((unsigned long)buf & ~PAGE_MASK));\n\n\treturn size >> PAGE_SHIFT;\n}\n\nstatic void hgcm_call_add_pagelist_size(void *buf, u32 len, size_t *extra)\n{\n\tu32 page_count;\n\n\tpage_count = hgcm_call_buf_size_in_pages(buf, len);\n\t*extra += offsetof(struct vmmdev_hgcm_pagelist, pages[page_count]);\n}\n\nstatic int hgcm_call_preprocess_linaddr(\n\tconst struct vmmdev_hgcm_function_parameter *src_parm,\n\tvoid **bounce_buf_ret, size_t *extra)\n{\n\tvoid *buf, *bounce_buf;\n\tbool copy_in;\n\tu32 len;\n\tint ret;\n\n\tbuf = (void *)src_parm->u.pointer.u.linear_addr;\n\tlen = src_parm->u.pointer.size;\n\tcopy_in = src_parm->type != VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT;\n\n\tif (len > VBG_MAX_HGCM_USER_PARM)\n\t\treturn -E2BIG;\n\n\tbounce_buf = kvmalloc(len, GFP_KERNEL);\n\tif (!bounce_buf)\n\t\treturn -ENOMEM;\n\n\tif (copy_in) {\n\t\tret = copy_from_user(bounce_buf, (void __user *)buf, len);\n\t\tif (ret)\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tmemset(bounce_buf, 0, len);\n\t}\n\n\t*bounce_buf_ret = bounce_buf;\n\thgcm_call_add_pagelist_size(bounce_buf, len, extra);\n\treturn 0;\n}\n\n/**\n * Preprocesses the HGCM call, validate parameters, alloc bounce buffers and\n * figure out how much extra storage we need for page lists.\n * Return: 0 or negative errno value.\n * @src_parm:         Pointer to source function call parameters\n * @parm_count:       Number of function call parameters.\n * @bounce_bufs_ret:  Where to return the allocated bouncebuffer array\n * @extra:            Where to return the extra request space needed for\n *                    physical page lists.\n */\nstatic int hgcm_call_preprocess(\n\tconst struct vmmdev_hgcm_function_parameter *src_parm,\n\tu32 parm_count, void ***bounce_bufs_ret, size_t *extra)\n{\n\tvoid *buf, **bounce_bufs = NULL;\n\tu32 i, len;\n\tint ret;\n\n\tfor (i = 0; i < parm_count; i++, src_parm++) {\n\t\tswitch (src_parm->type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\t\tif (!bounce_bufs) {\n\t\t\t\tbounce_bufs = kcalloc(parm_count,\n\t\t\t\t\t\t      sizeof(void *),\n\t\t\t\t\t\t      GFP_KERNEL);\n\t\t\t\tif (!bounce_bufs)\n\t\t\t\t\treturn -ENOMEM;\n\n\t\t\t\t*bounce_bufs_ret = bounce_bufs;\n\t\t\t}\n\n\t\t\tret = hgcm_call_preprocess_linaddr(src_parm,\n\t\t\t\t\t\t\t   &bounce_bufs[i],\n\t\t\t\t\t\t\t   extra);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_OUT:\n\t\t\tbuf = (void *)src_parm->u.pointer.u.linear_addr;\n\t\t\tlen = src_parm->u.pointer.size;\n\t\t\tif (WARN_ON(len > VBG_MAX_HGCM_KERNEL_PARM))\n\t\t\t\treturn -E2BIG;\n\n\t\t\thgcm_call_add_pagelist_size(buf, len, extra);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * Translates linear address types to page list direction flags.\n *\n * Return: page list flags.\n * @type:  The type.\n */\nstatic u32 hgcm_call_linear_addr_type_to_pagelist_flags(\n\tenum vmmdev_hgcm_function_parameter_type type)\n{\n\tswitch (type) {\n\tdefault:\n\t\tWARN_ON(1);\n\t\t/* Fall through */\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL:\n\t\treturn VMMDEV_HGCM_F_PARM_DIRECTION_BOTH;\n\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_IN:\n\t\treturn VMMDEV_HGCM_F_PARM_DIRECTION_TO_HOST;\n\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_OUT:\n\t\treturn VMMDEV_HGCM_F_PARM_DIRECTION_FROM_HOST;\n\t}\n}\n\nstatic void hgcm_call_init_linaddr(struct vmmdev_hgcm_call *call,\n\tstruct vmmdev_hgcm_function_parameter *dst_parm, void *buf, u32 len,\n\tenum vmmdev_hgcm_function_parameter_type type, u32 *off_extra)\n{\n\tstruct vmmdev_hgcm_pagelist *dst_pg_lst;\n\tstruct page *page;\n\tbool is_vmalloc;\n\tu32 i, page_count;\n\n\tdst_parm->type = type;\n\n\tif (len == 0) {\n\t\tdst_parm->u.pointer.size = 0;\n\t\tdst_parm->u.pointer.u.linear_addr = 0;\n\t\treturn;\n\t}\n\n\tdst_pg_lst = (void *)call + *off_extra;\n\tpage_count = hgcm_call_buf_size_in_pages(buf, len);\n\tis_vmalloc = is_vmalloc_addr(buf);\n\n\tdst_parm->type = VMMDEV_HGCM_PARM_TYPE_PAGELIST;\n\tdst_parm->u.page_list.size = len;\n\tdst_parm->u.page_list.offset = *off_extra;\n\tdst_pg_lst->flags = hgcm_call_linear_addr_type_to_pagelist_flags(type);\n\tdst_pg_lst->offset_first_page = (unsigned long)buf & ~PAGE_MASK;\n\tdst_pg_lst->page_count = page_count;\n\n\tfor (i = 0; i < page_count; i++) {\n\t\tif (is_vmalloc)\n\t\t\tpage = vmalloc_to_page(buf);\n\t\telse\n\t\t\tpage = virt_to_page(buf);\n\n\t\tdst_pg_lst->pages[i] = page_to_phys(page);\n\t\tbuf += PAGE_SIZE;\n\t}\n\n\t*off_extra += offsetof(struct vmmdev_hgcm_pagelist, pages[page_count]);\n}\n\n/**\n * Initializes the call request that we're sending to the host.\n * @call:            The call to initialize.\n * @client_id:       The client ID of the caller.\n * @function:        The function number of the function to call.\n * @src_parm:        Pointer to source function call parameters.\n * @parm_count:      Number of function call parameters.\n * @bounce_bufs:     The bouncebuffer array.\n */\nstatic void hgcm_call_init_call(\n\tstruct vmmdev_hgcm_call *call, u32 client_id, u32 function,\n\tconst struct vmmdev_hgcm_function_parameter *src_parm,\n\tu32 parm_count, void **bounce_bufs)\n{\n\tstruct vmmdev_hgcm_function_parameter *dst_parm =\n\t\tVMMDEV_HGCM_CALL_PARMS(call);\n\tu32 i, off_extra = (uintptr_t)(dst_parm + parm_count) - (uintptr_t)call;\n\tvoid *buf;\n\n\tcall->header.flags = 0;\n\tcall->header.result = VINF_SUCCESS;\n\tcall->client_id = client_id;\n\tcall->function = function;\n\tcall->parm_count = parm_count;\n\n\tfor (i = 0; i < parm_count; i++, src_parm++, dst_parm++) {\n\t\tswitch (src_parm->type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\t*dst_parm = *src_parm;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\t\thgcm_call_init_linaddr(call, dst_parm, bounce_bufs[i],\n\t\t\t\t\t       src_parm->u.pointer.size,\n\t\t\t\t\t       src_parm->type, &off_extra);\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_OUT:\n\t\t\tbuf = (void *)src_parm->u.pointer.u.linear_addr;\n\t\t\thgcm_call_init_linaddr(call, dst_parm, buf,\n\t\t\t\t\t       src_parm->u.pointer.size,\n\t\t\t\t\t       src_parm->type, &off_extra);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t\tdst_parm->type = VMMDEV_HGCM_PARM_TYPE_INVALID;\n\t\t}\n\t}\n}\n\n/**\n * Tries to cancel a pending HGCM call.\n *\n * Return: VBox status code\n */\nstatic int hgcm_cancel_call(struct vbg_dev *gdev, struct vmmdev_hgcm_call *call)\n{\n\tint rc;\n\n\t/*\n\t * We use a pre-allocated request for cancellations, which is\n\t * protected by cancel_req_mutex. This means that all cancellations\n\t * get serialized, this should be fine since they should be rare.\n\t */\n\tmutex_lock(&gdev->cancel_req_mutex);\n\tgdev->cancel_req->phys_req_to_cancel = virt_to_phys(call);\n\trc = vbg_req_perform(gdev, gdev->cancel_req);\n\tmutex_unlock(&gdev->cancel_req_mutex);\n\n\tif (rc == VERR_NOT_IMPLEMENTED) {\n\t\tcall->header.flags |= VMMDEV_HGCM_REQ_CANCELLED;\n\t\tcall->header.header.request_type = VMMDEVREQ_HGCM_CANCEL;\n\n\t\trc = vbg_req_perform(gdev, call);\n\t\tif (rc == VERR_INVALID_PARAMETER)\n\t\t\trc = VERR_NOT_FOUND;\n\t}\n\n\tif (rc >= 0)\n\t\tcall->header.flags |= VMMDEV_HGCM_REQ_CANCELLED;\n\n\treturn rc;\n}\n\n/**\n * Performs the call and completion wait.\n * Return: 0 or negative errno value.\n * @gdev:        The VBoxGuest device extension.\n * @call:        The call to execute.\n * @timeout_ms:  Timeout in ms.\n * @leak_it:     Where to return the leak it / free it, indicator.\n *               Cancellation fun.\n */\nstatic int vbg_hgcm_do_call(struct vbg_dev *gdev, struct vmmdev_hgcm_call *call,\n\t\t\t    u32 timeout_ms, bool *leak_it)\n{\n\tint rc, cancel_rc, ret;\n\tlong timeout;\n\n\t*leak_it = false;\n\n\trc = vbg_req_perform(gdev, call);\n\n\t/*\n\t * If the call failed, then pretend success. Upper layers will\n\t * interpret the result code in the packet.\n\t */\n\tif (rc < 0) {\n\t\tcall->header.result = rc;\n\t\treturn 0;\n\t}\n\n\tif (rc != VINF_HGCM_ASYNC_EXECUTE)\n\t\treturn 0;\n\n\t/* Host decided to process the request asynchronously, wait for it */\n\tif (timeout_ms == U32_MAX)\n\t\ttimeout = MAX_SCHEDULE_TIMEOUT;\n\telse\n\t\ttimeout = msecs_to_jiffies(timeout_ms);\n\n\ttimeout = wait_event_interruptible_timeout(\n\t\t\t\t\tgdev->hgcm_wq,\n\t\t\t\t\thgcm_req_done(gdev, &call->header),\n\t\t\t\t\ttimeout);\n\n\t/* timeout > 0 means hgcm_req_done has returned true, so success */\n\tif (timeout > 0)\n\t\treturn 0;\n\n\tif (timeout == 0)\n\t\tret = -ETIMEDOUT;\n\telse\n\t\tret = -EINTR;\n\n\t/* Cancel the request */\n\tcancel_rc = hgcm_cancel_call(gdev, call);\n\tif (cancel_rc >= 0)\n\t\treturn ret;\n\n\t/*\n\t * Failed to cancel, this should mean that the cancel has lost the\n\t * race with normal completion, wait while the host completes it.\n\t */\n\tif (cancel_rc == VERR_NOT_FOUND || cancel_rc == VERR_SEM_DESTROYED)\n\t\ttimeout = msecs_to_jiffies(500);\n\telse\n\t\ttimeout = msecs_to_jiffies(2000);\n\n\ttimeout = wait_event_timeout(gdev->hgcm_wq,\n\t\t\t\t     hgcm_req_done(gdev, &call->header),\n\t\t\t\t     timeout);\n\n\tif (WARN_ON(timeout == 0)) {\n\t\t/* We really should never get here */\n\t\tvbg_err(\"%s: Call timedout and cancellation failed, leaking the request\\n\",\n\t\t\t__func__);\n\t\t*leak_it = true;\n\t\treturn ret;\n\t}\n\n\t/* The call has completed normally after all */\n\treturn 0;\n}\n\n/**\n * Copies the result of the call back to the caller info structure and user\n * buffers.\n * Return: 0 or negative errno value.\n * @call:            HGCM call request.\n * @dst_parm:        Pointer to function call parameters destination.\n * @parm_count:      Number of function call parameters.\n * @bounce_bufs:     The bouncebuffer array.\n */\nstatic int hgcm_call_copy_back_result(\n\tconst struct vmmdev_hgcm_call *call,\n\tstruct vmmdev_hgcm_function_parameter *dst_parm,\n\tu32 parm_count, void **bounce_bufs)\n{\n\tconst struct vmmdev_hgcm_function_parameter *src_parm =\n\t\tVMMDEV_HGCM_CALL_PARMS(call);\n\tvoid __user *p;\n\tint ret;\n\tu32 i;\n\n\t/* Copy back parameters. */\n\tfor (i = 0; i < parm_count; i++, src_parm++, dst_parm++) {\n\t\tswitch (dst_parm->type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\t*dst_parm = *src_parm;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_PAGELIST:\n\t\t\tdst_parm->u.page_list.size = src_parm->u.page_list.size;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_OUT:\n\t\t\tdst_parm->u.pointer.size = src_parm->u.pointer.size;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\t\tdst_parm->u.pointer.size = src_parm->u.pointer.size;\n\n\t\t\tp = (void __user *)dst_parm->u.pointer.u.linear_addr;\n\t\t\tret = copy_to_user(p, bounce_bufs[i],\n\t\t\t\t\t   min(src_parm->u.pointer.size,\n\t\t\t\t\t       dst_parm->u.pointer.size));\n\t\t\tif (ret)\n\t\t\t\treturn -EFAULT;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint vbg_hgcm_call(struct vbg_dev *gdev, u32 requestor, u32 client_id,\n\t\t  u32 function, u32 timeout_ms,\n\t\t  struct vmmdev_hgcm_function_parameter *parms, u32 parm_count,\n\t\t  int *vbox_status)\n{\n\tstruct vmmdev_hgcm_call *call;\n\tvoid **bounce_bufs = NULL;\n\tbool leak_it;\n\tsize_t size;\n\tint i, ret;\n\n\tsize = sizeof(struct vmmdev_hgcm_call) +\n\t\t   parm_count * sizeof(struct vmmdev_hgcm_function_parameter);\n\t/*\n\t * Validate and buffer the parameters for the call. This also increases\n\t * call_size with the amount of extra space needed for page lists.\n\t */\n\tret = hgcm_call_preprocess(parms, parm_count, &bounce_bufs, &size);\n\tif (ret) {\n\t\t/* Even on error bounce bufs may still have been allocated */\n\t\tgoto free_bounce_bufs;\n\t}\n\n\tcall = vbg_req_alloc(size, VMMDEVREQ_HGCM_CALL, requestor);\n\tif (!call) {\n\t\tret = -ENOMEM;\n\t\tgoto free_bounce_bufs;\n\t}\n\n\thgcm_call_init_call(call, client_id, function, parms, parm_count,\n\t\t\t    bounce_bufs);\n\n\tret = vbg_hgcm_do_call(gdev, call, timeout_ms, &leak_it);\n\tif (ret == 0) {\n\t\t*vbox_status = call->header.result;\n\t\tret = hgcm_call_copy_back_result(call, parms, parm_count,\n\t\t\t\t\t\t bounce_bufs);\n\t}\n\n\tif (!leak_it)\n\t\tvbg_req_free(call, size);\n\nfree_bounce_bufs:\n\tif (bounce_bufs) {\n\t\tfor (i = 0; i < parm_count; i++)\n\t\t\tkvfree(bounce_bufs[i]);\n\t\tkfree(bounce_bufs);\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL(vbg_hgcm_call);\n\n#ifdef CONFIG_COMPAT\nint vbg_hgcm_call32(\n\tstruct vbg_dev *gdev, u32 requestor, u32 client_id, u32 function,\n\tu32 timeout_ms, struct vmmdev_hgcm_function_parameter32 *parm32,\n\tu32 parm_count, int *vbox_status)\n{\n\tstruct vmmdev_hgcm_function_parameter *parm64 = NULL;\n\tu32 i, size;\n\tint ret = 0;\n\n\t/* KISS allocate a temporary request and convert the parameters. */\n\tsize = parm_count * sizeof(struct vmmdev_hgcm_function_parameter);\n\tparm64 = kzalloc(size, GFP_KERNEL);\n\tif (!parm64)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < parm_count; i++) {\n\t\tswitch (parm32[i].type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\t\tparm64[i].type = VMMDEV_HGCM_PARM_TYPE_32BIT;\n\t\t\tparm64[i].u.value32 = parm32[i].u.value32;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\tparm64[i].type = VMMDEV_HGCM_PARM_TYPE_64BIT;\n\t\t\tparm64[i].u.value64 = parm32[i].u.value64;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\t\tparm64[i].type = parm32[i].type;\n\t\t\tparm64[i].u.pointer.size = parm32[i].u.pointer.size;\n\t\t\tparm64[i].u.pointer.u.linear_addr =\n\t\t\t    parm32[i].u.pointer.u.linear_addr;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t}\n\t\tif (ret < 0)\n\t\t\tgoto out_free;\n\t}\n\n\tret = vbg_hgcm_call(gdev, requestor, client_id, function, timeout_ms,\n\t\t\t    parm64, parm_count, vbox_status);\n\tif (ret < 0)\n\t\tgoto out_free;\n\n\t/* Copy back. */\n\tfor (i = 0; i < parm_count; i++, parm32++, parm64++) {\n\t\tswitch (parm64[i].type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\t\tparm32[i].u.value32 = parm64[i].u.value32;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\tparm32[i].u.value64 = parm64[i].u.value64;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\t\tparm32[i].u.pointer.size = parm64[i].u.pointer.size;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t\tret = -EINVAL;\n\t\t}\n\t}\n\nout_free:\n\tkfree(parm64);\n\treturn ret;\n}\n#endif\n\nstatic const int vbg_status_code_to_errno_table[] = {\n\t[-VERR_ACCESS_DENIED]                            = -EPERM,\n\t[-VERR_FILE_NOT_FOUND]                           = -ENOENT,\n\t[-VERR_PROCESS_NOT_FOUND]                        = -ESRCH,\n\t[-VERR_INTERRUPTED]                              = -EINTR,\n\t[-VERR_DEV_IO_ERROR]                             = -EIO,\n\t[-VERR_TOO_MUCH_DATA]                            = -E2BIG,\n\t[-VERR_BAD_EXE_FORMAT]                           = -ENOEXEC,\n\t[-VERR_INVALID_HANDLE]                           = -EBADF,\n\t[-VERR_TRY_AGAIN]                                = -EAGAIN,\n\t[-VERR_NO_MEMORY]                                = -ENOMEM,\n\t[-VERR_INVALID_POINTER]                          = -EFAULT,\n\t[-VERR_RESOURCE_BUSY]                            = -EBUSY,\n\t[-VERR_ALREADY_EXISTS]                           = -EEXIST,\n\t[-VERR_NOT_SAME_DEVICE]                          = -EXDEV,\n\t[-VERR_NOT_A_DIRECTORY]                          = -ENOTDIR,\n\t[-VERR_PATH_NOT_FOUND]                           = -ENOTDIR,\n\t[-VERR_INVALID_NAME]                             = -ENOENT,\n\t[-VERR_IS_A_DIRECTORY]                           = -EISDIR,\n\t[-VERR_INVALID_PARAMETER]                        = -EINVAL,\n\t[-VERR_TOO_MANY_OPEN_FILES]                      = -ENFILE,\n\t[-VERR_INVALID_FUNCTION]                         = -ENOTTY,\n\t[-VERR_SHARING_VIOLATION]                        = -ETXTBSY,\n\t[-VERR_FILE_TOO_BIG]                             = -EFBIG,\n\t[-VERR_DISK_FULL]                                = -ENOSPC,\n\t[-VERR_SEEK_ON_DEVICE]                           = -ESPIPE,\n\t[-VERR_WRITE_PROTECT]                            = -EROFS,\n\t[-VERR_BROKEN_PIPE]                              = -EPIPE,\n\t[-VERR_DEADLOCK]                                 = -EDEADLK,\n\t[-VERR_FILENAME_TOO_LONG]                        = -ENAMETOOLONG,\n\t[-VERR_FILE_LOCK_FAILED]                         = -ENOLCK,\n\t[-VERR_NOT_IMPLEMENTED]                          = -ENOSYS,\n\t[-VERR_NOT_SUPPORTED]                            = -ENOSYS,\n\t[-VERR_DIR_NOT_EMPTY]                            = -ENOTEMPTY,\n\t[-VERR_TOO_MANY_SYMLINKS]                        = -ELOOP,\n\t[-VERR_NO_MORE_FILES]\t\t\t\t = -ENODATA,\n\t[-VERR_NO_DATA]                                  = -ENODATA,\n\t[-VERR_NET_NO_NETWORK]                           = -ENONET,\n\t[-VERR_NET_NOT_UNIQUE_NAME]                      = -ENOTUNIQ,\n\t[-VERR_NO_TRANSLATION]                           = -EILSEQ,\n\t[-VERR_NET_NOT_SOCKET]                           = -ENOTSOCK,\n\t[-VERR_NET_DEST_ADDRESS_REQUIRED]                = -EDESTADDRREQ,\n\t[-VERR_NET_MSG_SIZE]                             = -EMSGSIZE,\n\t[-VERR_NET_PROTOCOL_TYPE]                        = -EPROTOTYPE,\n\t[-VERR_NET_PROTOCOL_NOT_AVAILABLE]               = -ENOPROTOOPT,\n\t[-VERR_NET_PROTOCOL_NOT_SUPPORTED]               = -EPROTONOSUPPORT,\n\t[-VERR_NET_SOCKET_TYPE_NOT_SUPPORTED]            = -ESOCKTNOSUPPORT,\n\t[-VERR_NET_OPERATION_NOT_SUPPORTED]              = -EOPNOTSUPP,\n\t[-VERR_NET_PROTOCOL_FAMILY_NOT_SUPPORTED]        = -EPFNOSUPPORT,\n\t[-VERR_NET_ADDRESS_FAMILY_NOT_SUPPORTED]         = -EAFNOSUPPORT,\n\t[-VERR_NET_ADDRESS_IN_USE]                       = -EADDRINUSE,\n\t[-VERR_NET_ADDRESS_NOT_AVAILABLE]                = -EADDRNOTAVAIL,\n\t[-VERR_NET_DOWN]                                 = -ENETDOWN,\n\t[-VERR_NET_UNREACHABLE]                          = -ENETUNREACH,\n\t[-VERR_NET_CONNECTION_RESET]                     = -ENETRESET,\n\t[-VERR_NET_CONNECTION_ABORTED]                   = -ECONNABORTED,\n\t[-VERR_NET_CONNECTION_RESET_BY_PEER]             = -ECONNRESET,\n\t[-VERR_NET_NO_BUFFER_SPACE]                      = -ENOBUFS,\n\t[-VERR_NET_ALREADY_CONNECTED]                    = -EISCONN,\n\t[-VERR_NET_NOT_CONNECTED]                        = -ENOTCONN,\n\t[-VERR_NET_SHUTDOWN]                             = -ESHUTDOWN,\n\t[-VERR_NET_TOO_MANY_REFERENCES]                  = -ETOOMANYREFS,\n\t[-VERR_TIMEOUT]                                  = -ETIMEDOUT,\n\t[-VERR_NET_CONNECTION_REFUSED]                   = -ECONNREFUSED,\n\t[-VERR_NET_HOST_DOWN]                            = -EHOSTDOWN,\n\t[-VERR_NET_HOST_UNREACHABLE]                     = -EHOSTUNREACH,\n\t[-VERR_NET_ALREADY_IN_PROGRESS]                  = -EALREADY,\n\t[-VERR_NET_IN_PROGRESS]                          = -EINPROGRESS,\n\t[-VERR_MEDIA_NOT_PRESENT]                        = -ENOMEDIUM,\n\t[-VERR_MEDIA_NOT_RECOGNIZED]                     = -EMEDIUMTYPE,\n};\n\nint vbg_status_code_to_errno(int rc)\n{\n\tif (rc >= 0)\n\t\treturn 0;\n\n\trc = -rc;\n\tif (rc >= ARRAY_SIZE(vbg_status_code_to_errno_table) ||\n\t    vbg_status_code_to_errno_table[rc] == 0) {\n\t\tvbg_warn(\"%s: Unhandled err %d\\n\", __func__, -rc);\n\t\treturn -EPROTO;\n\t}\n\n\treturn vbg_status_code_to_errno_table[rc];\n}\nEXPORT_SYMBOL(vbg_status_code_to_errno);\n"], "fixing_code": ["/* SPDX-License-Identifier: (GPL-2.0 OR CDDL-1.0) */\n/*\n * vboxguest vmm-req and hgcm-call code, VBoxGuestR0LibHGCMInternal.cpp,\n * VBoxGuestR0LibGenericRequest.cpp and RTErrConvertToErrno.cpp in vbox svn.\n *\n * Copyright (C) 2006-2016 Oracle Corporation\n */\n\n#include <linux/errno.h>\n#include <linux/kernel.h>\n#include <linux/mm.h>\n#include <linux/module.h>\n#include <linux/sizes.h>\n#include <linux/slab.h>\n#include <linux/uaccess.h>\n#include <linux/vmalloc.h>\n#include <linux/vbox_err.h>\n#include <linux/vbox_utils.h>\n#include \"vboxguest_core.h\"\n\n/* Get the pointer to the first parameter of a HGCM call request. */\n#define VMMDEV_HGCM_CALL_PARMS(a) \\\n\t((struct vmmdev_hgcm_function_parameter *)( \\\n\t\t(u8 *)(a) + sizeof(struct vmmdev_hgcm_call)))\n\n/* The max parameter buffer size for a user request. */\n#define VBG_MAX_HGCM_USER_PARM\t\t(24 * SZ_1M)\n/* The max parameter buffer size for a kernel request. */\n#define VBG_MAX_HGCM_KERNEL_PARM\t(16 * SZ_1M)\n\n#define VBG_DEBUG_PORT\t\t\t0x504\n\n/* This protects vbg_log_buf and serializes VBG_DEBUG_PORT accesses */\nstatic DEFINE_SPINLOCK(vbg_log_lock);\nstatic char vbg_log_buf[128];\n\n#define VBG_LOG(name, pr_func) \\\nvoid name(const char *fmt, ...)\t\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tunsigned long flags;\t\t\t\t\t\t\\\n\tva_list args;\t\t\t\t\t\t\t\\\n\tint i, count;\t\t\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tva_start(args, fmt);\t\t\t\t\t\t\\\n\tspin_lock_irqsave(&vbg_log_lock, flags);\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tcount = vscnprintf(vbg_log_buf, sizeof(vbg_log_buf), fmt, args);\\\n\tfor (i = 0; i < count; i++)\t\t\t\t\t\\\n\t\toutb(vbg_log_buf[i], VBG_DEBUG_PORT);\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tpr_func(\"%s\", vbg_log_buf);\t\t\t\t\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tspin_unlock_irqrestore(&vbg_log_lock, flags);\t\t\t\\\n\tva_end(args);\t\t\t\t\t\t\t\\\n}\t\t\t\t\t\t\t\t\t\\\nEXPORT_SYMBOL(name)\n\nVBG_LOG(vbg_info, pr_info);\nVBG_LOG(vbg_warn, pr_warn);\nVBG_LOG(vbg_err, pr_err);\n#if defined(DEBUG) && !defined(CONFIG_DYNAMIC_DEBUG)\nVBG_LOG(vbg_debug, pr_debug);\n#endif\n\nvoid *vbg_req_alloc(size_t len, enum vmmdev_request_type req_type,\n\t\t    u32 requestor)\n{\n\tstruct vmmdev_request_header *req;\n\tint order = get_order(PAGE_ALIGN(len));\n\n\treq = (void *)__get_free_pages(GFP_KERNEL | GFP_DMA32, order);\n\tif (!req)\n\t\treturn NULL;\n\n\tmemset(req, 0xaa, len);\n\n\treq->size = len;\n\treq->version = VMMDEV_REQUEST_HEADER_VERSION;\n\treq->request_type = req_type;\n\treq->rc = VERR_GENERAL_FAILURE;\n\treq->reserved1 = 0;\n\treq->requestor = requestor;\n\n\treturn req;\n}\n\nvoid vbg_req_free(void *req, size_t len)\n{\n\tif (!req)\n\t\treturn;\n\n\tfree_pages((unsigned long)req, get_order(PAGE_ALIGN(len)));\n}\n\n/* Note this function returns a VBox status code, not a negative errno!! */\nint vbg_req_perform(struct vbg_dev *gdev, void *req)\n{\n\tunsigned long phys_req = virt_to_phys(req);\n\n\toutl(phys_req, gdev->io_port + VMMDEV_PORT_OFF_REQUEST);\n\t/*\n\t * The host changes the request as a result of the outl, make sure\n\t * the outl and any reads of the req happen in the correct order.\n\t */\n\tmb();\n\n\treturn ((struct vmmdev_request_header *)req)->rc;\n}\n\nstatic bool hgcm_req_done(struct vbg_dev *gdev,\n\t\t\t  struct vmmdev_hgcmreq_header *header)\n{\n\tunsigned long flags;\n\tbool done;\n\n\tspin_lock_irqsave(&gdev->event_spinlock, flags);\n\tdone = header->flags & VMMDEV_HGCM_REQ_DONE;\n\tspin_unlock_irqrestore(&gdev->event_spinlock, flags);\n\n\treturn done;\n}\n\nint vbg_hgcm_connect(struct vbg_dev *gdev, u32 requestor,\n\t\t     struct vmmdev_hgcm_service_location *loc,\n\t\t     u32 *client_id, int *vbox_status)\n{\n\tstruct vmmdev_hgcm_connect *hgcm_connect = NULL;\n\tint rc;\n\n\thgcm_connect = vbg_req_alloc(sizeof(*hgcm_connect),\n\t\t\t\t     VMMDEVREQ_HGCM_CONNECT, requestor);\n\tif (!hgcm_connect)\n\t\treturn -ENOMEM;\n\n\thgcm_connect->header.flags = 0;\n\tmemcpy(&hgcm_connect->loc, loc, sizeof(*loc));\n\thgcm_connect->client_id = 0;\n\n\trc = vbg_req_perform(gdev, hgcm_connect);\n\n\tif (rc == VINF_HGCM_ASYNC_EXECUTE)\n\t\twait_event(gdev->hgcm_wq,\n\t\t\t   hgcm_req_done(gdev, &hgcm_connect->header));\n\n\tif (rc >= 0) {\n\t\t*client_id = hgcm_connect->client_id;\n\t\trc = hgcm_connect->header.result;\n\t}\n\n\tvbg_req_free(hgcm_connect, sizeof(*hgcm_connect));\n\n\t*vbox_status = rc;\n\treturn 0;\n}\nEXPORT_SYMBOL(vbg_hgcm_connect);\n\nint vbg_hgcm_disconnect(struct vbg_dev *gdev, u32 requestor,\n\t\t\tu32 client_id, int *vbox_status)\n{\n\tstruct vmmdev_hgcm_disconnect *hgcm_disconnect = NULL;\n\tint rc;\n\n\thgcm_disconnect = vbg_req_alloc(sizeof(*hgcm_disconnect),\n\t\t\t\t\tVMMDEVREQ_HGCM_DISCONNECT,\n\t\t\t\t\trequestor);\n\tif (!hgcm_disconnect)\n\t\treturn -ENOMEM;\n\n\thgcm_disconnect->header.flags = 0;\n\thgcm_disconnect->client_id = client_id;\n\n\trc = vbg_req_perform(gdev, hgcm_disconnect);\n\n\tif (rc == VINF_HGCM_ASYNC_EXECUTE)\n\t\twait_event(gdev->hgcm_wq,\n\t\t\t   hgcm_req_done(gdev, &hgcm_disconnect->header));\n\n\tif (rc >= 0)\n\t\trc = hgcm_disconnect->header.result;\n\n\tvbg_req_free(hgcm_disconnect, sizeof(*hgcm_disconnect));\n\n\t*vbox_status = rc;\n\treturn 0;\n}\nEXPORT_SYMBOL(vbg_hgcm_disconnect);\n\nstatic u32 hgcm_call_buf_size_in_pages(void *buf, u32 len)\n{\n\tu32 size = PAGE_ALIGN(len + ((unsigned long)buf & ~PAGE_MASK));\n\n\treturn size >> PAGE_SHIFT;\n}\n\nstatic void hgcm_call_add_pagelist_size(void *buf, u32 len, size_t *extra)\n{\n\tu32 page_count;\n\n\tpage_count = hgcm_call_buf_size_in_pages(buf, len);\n\t*extra += offsetof(struct vmmdev_hgcm_pagelist, pages[page_count]);\n}\n\nstatic int hgcm_call_preprocess_linaddr(\n\tconst struct vmmdev_hgcm_function_parameter *src_parm,\n\tvoid **bounce_buf_ret, size_t *extra)\n{\n\tvoid *buf, *bounce_buf;\n\tbool copy_in;\n\tu32 len;\n\tint ret;\n\n\tbuf = (void *)src_parm->u.pointer.u.linear_addr;\n\tlen = src_parm->u.pointer.size;\n\tcopy_in = src_parm->type != VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT;\n\n\tif (len > VBG_MAX_HGCM_USER_PARM)\n\t\treturn -E2BIG;\n\n\tbounce_buf = kvmalloc(len, GFP_KERNEL);\n\tif (!bounce_buf)\n\t\treturn -ENOMEM;\n\n\t*bounce_buf_ret = bounce_buf;\n\n\tif (copy_in) {\n\t\tret = copy_from_user(bounce_buf, (void __user *)buf, len);\n\t\tif (ret)\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tmemset(bounce_buf, 0, len);\n\t}\n\n\thgcm_call_add_pagelist_size(bounce_buf, len, extra);\n\treturn 0;\n}\n\n/**\n * Preprocesses the HGCM call, validate parameters, alloc bounce buffers and\n * figure out how much extra storage we need for page lists.\n * Return: 0 or negative errno value.\n * @src_parm:         Pointer to source function call parameters\n * @parm_count:       Number of function call parameters.\n * @bounce_bufs_ret:  Where to return the allocated bouncebuffer array\n * @extra:            Where to return the extra request space needed for\n *                    physical page lists.\n */\nstatic int hgcm_call_preprocess(\n\tconst struct vmmdev_hgcm_function_parameter *src_parm,\n\tu32 parm_count, void ***bounce_bufs_ret, size_t *extra)\n{\n\tvoid *buf, **bounce_bufs = NULL;\n\tu32 i, len;\n\tint ret;\n\n\tfor (i = 0; i < parm_count; i++, src_parm++) {\n\t\tswitch (src_parm->type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\t\tif (!bounce_bufs) {\n\t\t\t\tbounce_bufs = kcalloc(parm_count,\n\t\t\t\t\t\t      sizeof(void *),\n\t\t\t\t\t\t      GFP_KERNEL);\n\t\t\t\tif (!bounce_bufs)\n\t\t\t\t\treturn -ENOMEM;\n\n\t\t\t\t*bounce_bufs_ret = bounce_bufs;\n\t\t\t}\n\n\t\t\tret = hgcm_call_preprocess_linaddr(src_parm,\n\t\t\t\t\t\t\t   &bounce_bufs[i],\n\t\t\t\t\t\t\t   extra);\n\t\t\tif (ret)\n\t\t\t\treturn ret;\n\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_OUT:\n\t\t\tbuf = (void *)src_parm->u.pointer.u.linear_addr;\n\t\t\tlen = src_parm->u.pointer.size;\n\t\t\tif (WARN_ON(len > VBG_MAX_HGCM_KERNEL_PARM))\n\t\t\t\treturn -E2BIG;\n\n\t\t\thgcm_call_add_pagelist_size(buf, len, extra);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\n/**\n * Translates linear address types to page list direction flags.\n *\n * Return: page list flags.\n * @type:  The type.\n */\nstatic u32 hgcm_call_linear_addr_type_to_pagelist_flags(\n\tenum vmmdev_hgcm_function_parameter_type type)\n{\n\tswitch (type) {\n\tdefault:\n\t\tWARN_ON(1);\n\t\t/* Fall through */\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL:\n\t\treturn VMMDEV_HGCM_F_PARM_DIRECTION_BOTH;\n\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_IN:\n\t\treturn VMMDEV_HGCM_F_PARM_DIRECTION_TO_HOST;\n\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_OUT:\n\t\treturn VMMDEV_HGCM_F_PARM_DIRECTION_FROM_HOST;\n\t}\n}\n\nstatic void hgcm_call_init_linaddr(struct vmmdev_hgcm_call *call,\n\tstruct vmmdev_hgcm_function_parameter *dst_parm, void *buf, u32 len,\n\tenum vmmdev_hgcm_function_parameter_type type, u32 *off_extra)\n{\n\tstruct vmmdev_hgcm_pagelist *dst_pg_lst;\n\tstruct page *page;\n\tbool is_vmalloc;\n\tu32 i, page_count;\n\n\tdst_parm->type = type;\n\n\tif (len == 0) {\n\t\tdst_parm->u.pointer.size = 0;\n\t\tdst_parm->u.pointer.u.linear_addr = 0;\n\t\treturn;\n\t}\n\n\tdst_pg_lst = (void *)call + *off_extra;\n\tpage_count = hgcm_call_buf_size_in_pages(buf, len);\n\tis_vmalloc = is_vmalloc_addr(buf);\n\n\tdst_parm->type = VMMDEV_HGCM_PARM_TYPE_PAGELIST;\n\tdst_parm->u.page_list.size = len;\n\tdst_parm->u.page_list.offset = *off_extra;\n\tdst_pg_lst->flags = hgcm_call_linear_addr_type_to_pagelist_flags(type);\n\tdst_pg_lst->offset_first_page = (unsigned long)buf & ~PAGE_MASK;\n\tdst_pg_lst->page_count = page_count;\n\n\tfor (i = 0; i < page_count; i++) {\n\t\tif (is_vmalloc)\n\t\t\tpage = vmalloc_to_page(buf);\n\t\telse\n\t\t\tpage = virt_to_page(buf);\n\n\t\tdst_pg_lst->pages[i] = page_to_phys(page);\n\t\tbuf += PAGE_SIZE;\n\t}\n\n\t*off_extra += offsetof(struct vmmdev_hgcm_pagelist, pages[page_count]);\n}\n\n/**\n * Initializes the call request that we're sending to the host.\n * @call:            The call to initialize.\n * @client_id:       The client ID of the caller.\n * @function:        The function number of the function to call.\n * @src_parm:        Pointer to source function call parameters.\n * @parm_count:      Number of function call parameters.\n * @bounce_bufs:     The bouncebuffer array.\n */\nstatic void hgcm_call_init_call(\n\tstruct vmmdev_hgcm_call *call, u32 client_id, u32 function,\n\tconst struct vmmdev_hgcm_function_parameter *src_parm,\n\tu32 parm_count, void **bounce_bufs)\n{\n\tstruct vmmdev_hgcm_function_parameter *dst_parm =\n\t\tVMMDEV_HGCM_CALL_PARMS(call);\n\tu32 i, off_extra = (uintptr_t)(dst_parm + parm_count) - (uintptr_t)call;\n\tvoid *buf;\n\n\tcall->header.flags = 0;\n\tcall->header.result = VINF_SUCCESS;\n\tcall->client_id = client_id;\n\tcall->function = function;\n\tcall->parm_count = parm_count;\n\n\tfor (i = 0; i < parm_count; i++, src_parm++, dst_parm++) {\n\t\tswitch (src_parm->type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\t*dst_parm = *src_parm;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\t\thgcm_call_init_linaddr(call, dst_parm, bounce_bufs[i],\n\t\t\t\t\t       src_parm->u.pointer.size,\n\t\t\t\t\t       src_parm->type, &off_extra);\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_OUT:\n\t\t\tbuf = (void *)src_parm->u.pointer.u.linear_addr;\n\t\t\thgcm_call_init_linaddr(call, dst_parm, buf,\n\t\t\t\t\t       src_parm->u.pointer.size,\n\t\t\t\t\t       src_parm->type, &off_extra);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t\tdst_parm->type = VMMDEV_HGCM_PARM_TYPE_INVALID;\n\t\t}\n\t}\n}\n\n/**\n * Tries to cancel a pending HGCM call.\n *\n * Return: VBox status code\n */\nstatic int hgcm_cancel_call(struct vbg_dev *gdev, struct vmmdev_hgcm_call *call)\n{\n\tint rc;\n\n\t/*\n\t * We use a pre-allocated request for cancellations, which is\n\t * protected by cancel_req_mutex. This means that all cancellations\n\t * get serialized, this should be fine since they should be rare.\n\t */\n\tmutex_lock(&gdev->cancel_req_mutex);\n\tgdev->cancel_req->phys_req_to_cancel = virt_to_phys(call);\n\trc = vbg_req_perform(gdev, gdev->cancel_req);\n\tmutex_unlock(&gdev->cancel_req_mutex);\n\n\tif (rc == VERR_NOT_IMPLEMENTED) {\n\t\tcall->header.flags |= VMMDEV_HGCM_REQ_CANCELLED;\n\t\tcall->header.header.request_type = VMMDEVREQ_HGCM_CANCEL;\n\n\t\trc = vbg_req_perform(gdev, call);\n\t\tif (rc == VERR_INVALID_PARAMETER)\n\t\t\trc = VERR_NOT_FOUND;\n\t}\n\n\tif (rc >= 0)\n\t\tcall->header.flags |= VMMDEV_HGCM_REQ_CANCELLED;\n\n\treturn rc;\n}\n\n/**\n * Performs the call and completion wait.\n * Return: 0 or negative errno value.\n * @gdev:        The VBoxGuest device extension.\n * @call:        The call to execute.\n * @timeout_ms:  Timeout in ms.\n * @leak_it:     Where to return the leak it / free it, indicator.\n *               Cancellation fun.\n */\nstatic int vbg_hgcm_do_call(struct vbg_dev *gdev, struct vmmdev_hgcm_call *call,\n\t\t\t    u32 timeout_ms, bool *leak_it)\n{\n\tint rc, cancel_rc, ret;\n\tlong timeout;\n\n\t*leak_it = false;\n\n\trc = vbg_req_perform(gdev, call);\n\n\t/*\n\t * If the call failed, then pretend success. Upper layers will\n\t * interpret the result code in the packet.\n\t */\n\tif (rc < 0) {\n\t\tcall->header.result = rc;\n\t\treturn 0;\n\t}\n\n\tif (rc != VINF_HGCM_ASYNC_EXECUTE)\n\t\treturn 0;\n\n\t/* Host decided to process the request asynchronously, wait for it */\n\tif (timeout_ms == U32_MAX)\n\t\ttimeout = MAX_SCHEDULE_TIMEOUT;\n\telse\n\t\ttimeout = msecs_to_jiffies(timeout_ms);\n\n\ttimeout = wait_event_interruptible_timeout(\n\t\t\t\t\tgdev->hgcm_wq,\n\t\t\t\t\thgcm_req_done(gdev, &call->header),\n\t\t\t\t\ttimeout);\n\n\t/* timeout > 0 means hgcm_req_done has returned true, so success */\n\tif (timeout > 0)\n\t\treturn 0;\n\n\tif (timeout == 0)\n\t\tret = -ETIMEDOUT;\n\telse\n\t\tret = -EINTR;\n\n\t/* Cancel the request */\n\tcancel_rc = hgcm_cancel_call(gdev, call);\n\tif (cancel_rc >= 0)\n\t\treturn ret;\n\n\t/*\n\t * Failed to cancel, this should mean that the cancel has lost the\n\t * race with normal completion, wait while the host completes it.\n\t */\n\tif (cancel_rc == VERR_NOT_FOUND || cancel_rc == VERR_SEM_DESTROYED)\n\t\ttimeout = msecs_to_jiffies(500);\n\telse\n\t\ttimeout = msecs_to_jiffies(2000);\n\n\ttimeout = wait_event_timeout(gdev->hgcm_wq,\n\t\t\t\t     hgcm_req_done(gdev, &call->header),\n\t\t\t\t     timeout);\n\n\tif (WARN_ON(timeout == 0)) {\n\t\t/* We really should never get here */\n\t\tvbg_err(\"%s: Call timedout and cancellation failed, leaking the request\\n\",\n\t\t\t__func__);\n\t\t*leak_it = true;\n\t\treturn ret;\n\t}\n\n\t/* The call has completed normally after all */\n\treturn 0;\n}\n\n/**\n * Copies the result of the call back to the caller info structure and user\n * buffers.\n * Return: 0 or negative errno value.\n * @call:            HGCM call request.\n * @dst_parm:        Pointer to function call parameters destination.\n * @parm_count:      Number of function call parameters.\n * @bounce_bufs:     The bouncebuffer array.\n */\nstatic int hgcm_call_copy_back_result(\n\tconst struct vmmdev_hgcm_call *call,\n\tstruct vmmdev_hgcm_function_parameter *dst_parm,\n\tu32 parm_count, void **bounce_bufs)\n{\n\tconst struct vmmdev_hgcm_function_parameter *src_parm =\n\t\tVMMDEV_HGCM_CALL_PARMS(call);\n\tvoid __user *p;\n\tint ret;\n\tu32 i;\n\n\t/* Copy back parameters. */\n\tfor (i = 0; i < parm_count; i++, src_parm++, dst_parm++) {\n\t\tswitch (dst_parm->type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\t*dst_parm = *src_parm;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_PAGELIST:\n\t\t\tdst_parm->u.page_list.size = src_parm->u.page_list.size;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_IN:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_KERNEL_OUT:\n\t\t\tdst_parm->u.pointer.size = src_parm->u.pointer.size;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\t\tdst_parm->u.pointer.size = src_parm->u.pointer.size;\n\n\t\t\tp = (void __user *)dst_parm->u.pointer.u.linear_addr;\n\t\t\tret = copy_to_user(p, bounce_bufs[i],\n\t\t\t\t\t   min(src_parm->u.pointer.size,\n\t\t\t\t\t       dst_parm->u.pointer.size));\n\t\t\tif (ret)\n\t\t\t\treturn -EFAULT;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\treturn 0;\n}\n\nint vbg_hgcm_call(struct vbg_dev *gdev, u32 requestor, u32 client_id,\n\t\t  u32 function, u32 timeout_ms,\n\t\t  struct vmmdev_hgcm_function_parameter *parms, u32 parm_count,\n\t\t  int *vbox_status)\n{\n\tstruct vmmdev_hgcm_call *call;\n\tvoid **bounce_bufs = NULL;\n\tbool leak_it;\n\tsize_t size;\n\tint i, ret;\n\n\tsize = sizeof(struct vmmdev_hgcm_call) +\n\t\t   parm_count * sizeof(struct vmmdev_hgcm_function_parameter);\n\t/*\n\t * Validate and buffer the parameters for the call. This also increases\n\t * call_size with the amount of extra space needed for page lists.\n\t */\n\tret = hgcm_call_preprocess(parms, parm_count, &bounce_bufs, &size);\n\tif (ret) {\n\t\t/* Even on error bounce bufs may still have been allocated */\n\t\tgoto free_bounce_bufs;\n\t}\n\n\tcall = vbg_req_alloc(size, VMMDEVREQ_HGCM_CALL, requestor);\n\tif (!call) {\n\t\tret = -ENOMEM;\n\t\tgoto free_bounce_bufs;\n\t}\n\n\thgcm_call_init_call(call, client_id, function, parms, parm_count,\n\t\t\t    bounce_bufs);\n\n\tret = vbg_hgcm_do_call(gdev, call, timeout_ms, &leak_it);\n\tif (ret == 0) {\n\t\t*vbox_status = call->header.result;\n\t\tret = hgcm_call_copy_back_result(call, parms, parm_count,\n\t\t\t\t\t\t bounce_bufs);\n\t}\n\n\tif (!leak_it)\n\t\tvbg_req_free(call, size);\n\nfree_bounce_bufs:\n\tif (bounce_bufs) {\n\t\tfor (i = 0; i < parm_count; i++)\n\t\t\tkvfree(bounce_bufs[i]);\n\t\tkfree(bounce_bufs);\n\t}\n\n\treturn ret;\n}\nEXPORT_SYMBOL(vbg_hgcm_call);\n\n#ifdef CONFIG_COMPAT\nint vbg_hgcm_call32(\n\tstruct vbg_dev *gdev, u32 requestor, u32 client_id, u32 function,\n\tu32 timeout_ms, struct vmmdev_hgcm_function_parameter32 *parm32,\n\tu32 parm_count, int *vbox_status)\n{\n\tstruct vmmdev_hgcm_function_parameter *parm64 = NULL;\n\tu32 i, size;\n\tint ret = 0;\n\n\t/* KISS allocate a temporary request and convert the parameters. */\n\tsize = parm_count * sizeof(struct vmmdev_hgcm_function_parameter);\n\tparm64 = kzalloc(size, GFP_KERNEL);\n\tif (!parm64)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < parm_count; i++) {\n\t\tswitch (parm32[i].type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\t\tparm64[i].type = VMMDEV_HGCM_PARM_TYPE_32BIT;\n\t\t\tparm64[i].u.value32 = parm32[i].u.value32;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\tparm64[i].type = VMMDEV_HGCM_PARM_TYPE_64BIT;\n\t\t\tparm64[i].u.value64 = parm32[i].u.value64;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\t\tparm64[i].type = parm32[i].type;\n\t\t\tparm64[i].u.pointer.size = parm32[i].u.pointer.size;\n\t\t\tparm64[i].u.pointer.u.linear_addr =\n\t\t\t    parm32[i].u.pointer.u.linear_addr;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tret = -EINVAL;\n\t\t}\n\t\tif (ret < 0)\n\t\t\tgoto out_free;\n\t}\n\n\tret = vbg_hgcm_call(gdev, requestor, client_id, function, timeout_ms,\n\t\t\t    parm64, parm_count, vbox_status);\n\tif (ret < 0)\n\t\tgoto out_free;\n\n\t/* Copy back. */\n\tfor (i = 0; i < parm_count; i++, parm32++, parm64++) {\n\t\tswitch (parm64[i].type) {\n\t\tcase VMMDEV_HGCM_PARM_TYPE_32BIT:\n\t\t\tparm32[i].u.value32 = parm64[i].u.value32;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_64BIT:\n\t\t\tparm32[i].u.value64 = parm64[i].u.value64;\n\t\t\tbreak;\n\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_OUT:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR:\n\t\tcase VMMDEV_HGCM_PARM_TYPE_LINADDR_IN:\n\t\t\tparm32[i].u.pointer.size = parm64[i].u.pointer.size;\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tWARN_ON(1);\n\t\t\tret = -EINVAL;\n\t\t}\n\t}\n\nout_free:\n\tkfree(parm64);\n\treturn ret;\n}\n#endif\n\nstatic const int vbg_status_code_to_errno_table[] = {\n\t[-VERR_ACCESS_DENIED]                            = -EPERM,\n\t[-VERR_FILE_NOT_FOUND]                           = -ENOENT,\n\t[-VERR_PROCESS_NOT_FOUND]                        = -ESRCH,\n\t[-VERR_INTERRUPTED]                              = -EINTR,\n\t[-VERR_DEV_IO_ERROR]                             = -EIO,\n\t[-VERR_TOO_MUCH_DATA]                            = -E2BIG,\n\t[-VERR_BAD_EXE_FORMAT]                           = -ENOEXEC,\n\t[-VERR_INVALID_HANDLE]                           = -EBADF,\n\t[-VERR_TRY_AGAIN]                                = -EAGAIN,\n\t[-VERR_NO_MEMORY]                                = -ENOMEM,\n\t[-VERR_INVALID_POINTER]                          = -EFAULT,\n\t[-VERR_RESOURCE_BUSY]                            = -EBUSY,\n\t[-VERR_ALREADY_EXISTS]                           = -EEXIST,\n\t[-VERR_NOT_SAME_DEVICE]                          = -EXDEV,\n\t[-VERR_NOT_A_DIRECTORY]                          = -ENOTDIR,\n\t[-VERR_PATH_NOT_FOUND]                           = -ENOTDIR,\n\t[-VERR_INVALID_NAME]                             = -ENOENT,\n\t[-VERR_IS_A_DIRECTORY]                           = -EISDIR,\n\t[-VERR_INVALID_PARAMETER]                        = -EINVAL,\n\t[-VERR_TOO_MANY_OPEN_FILES]                      = -ENFILE,\n\t[-VERR_INVALID_FUNCTION]                         = -ENOTTY,\n\t[-VERR_SHARING_VIOLATION]                        = -ETXTBSY,\n\t[-VERR_FILE_TOO_BIG]                             = -EFBIG,\n\t[-VERR_DISK_FULL]                                = -ENOSPC,\n\t[-VERR_SEEK_ON_DEVICE]                           = -ESPIPE,\n\t[-VERR_WRITE_PROTECT]                            = -EROFS,\n\t[-VERR_BROKEN_PIPE]                              = -EPIPE,\n\t[-VERR_DEADLOCK]                                 = -EDEADLK,\n\t[-VERR_FILENAME_TOO_LONG]                        = -ENAMETOOLONG,\n\t[-VERR_FILE_LOCK_FAILED]                         = -ENOLCK,\n\t[-VERR_NOT_IMPLEMENTED]                          = -ENOSYS,\n\t[-VERR_NOT_SUPPORTED]                            = -ENOSYS,\n\t[-VERR_DIR_NOT_EMPTY]                            = -ENOTEMPTY,\n\t[-VERR_TOO_MANY_SYMLINKS]                        = -ELOOP,\n\t[-VERR_NO_MORE_FILES]\t\t\t\t = -ENODATA,\n\t[-VERR_NO_DATA]                                  = -ENODATA,\n\t[-VERR_NET_NO_NETWORK]                           = -ENONET,\n\t[-VERR_NET_NOT_UNIQUE_NAME]                      = -ENOTUNIQ,\n\t[-VERR_NO_TRANSLATION]                           = -EILSEQ,\n\t[-VERR_NET_NOT_SOCKET]                           = -ENOTSOCK,\n\t[-VERR_NET_DEST_ADDRESS_REQUIRED]                = -EDESTADDRREQ,\n\t[-VERR_NET_MSG_SIZE]                             = -EMSGSIZE,\n\t[-VERR_NET_PROTOCOL_TYPE]                        = -EPROTOTYPE,\n\t[-VERR_NET_PROTOCOL_NOT_AVAILABLE]               = -ENOPROTOOPT,\n\t[-VERR_NET_PROTOCOL_NOT_SUPPORTED]               = -EPROTONOSUPPORT,\n\t[-VERR_NET_SOCKET_TYPE_NOT_SUPPORTED]            = -ESOCKTNOSUPPORT,\n\t[-VERR_NET_OPERATION_NOT_SUPPORTED]              = -EOPNOTSUPP,\n\t[-VERR_NET_PROTOCOL_FAMILY_NOT_SUPPORTED]        = -EPFNOSUPPORT,\n\t[-VERR_NET_ADDRESS_FAMILY_NOT_SUPPORTED]         = -EAFNOSUPPORT,\n\t[-VERR_NET_ADDRESS_IN_USE]                       = -EADDRINUSE,\n\t[-VERR_NET_ADDRESS_NOT_AVAILABLE]                = -EADDRNOTAVAIL,\n\t[-VERR_NET_DOWN]                                 = -ENETDOWN,\n\t[-VERR_NET_UNREACHABLE]                          = -ENETUNREACH,\n\t[-VERR_NET_CONNECTION_RESET]                     = -ENETRESET,\n\t[-VERR_NET_CONNECTION_ABORTED]                   = -ECONNABORTED,\n\t[-VERR_NET_CONNECTION_RESET_BY_PEER]             = -ECONNRESET,\n\t[-VERR_NET_NO_BUFFER_SPACE]                      = -ENOBUFS,\n\t[-VERR_NET_ALREADY_CONNECTED]                    = -EISCONN,\n\t[-VERR_NET_NOT_CONNECTED]                        = -ENOTCONN,\n\t[-VERR_NET_SHUTDOWN]                             = -ESHUTDOWN,\n\t[-VERR_NET_TOO_MANY_REFERENCES]                  = -ETOOMANYREFS,\n\t[-VERR_TIMEOUT]                                  = -ETIMEDOUT,\n\t[-VERR_NET_CONNECTION_REFUSED]                   = -ECONNREFUSED,\n\t[-VERR_NET_HOST_DOWN]                            = -EHOSTDOWN,\n\t[-VERR_NET_HOST_UNREACHABLE]                     = -EHOSTUNREACH,\n\t[-VERR_NET_ALREADY_IN_PROGRESS]                  = -EALREADY,\n\t[-VERR_NET_IN_PROGRESS]                          = -EINPROGRESS,\n\t[-VERR_MEDIA_NOT_PRESENT]                        = -ENOMEDIUM,\n\t[-VERR_MEDIA_NOT_RECOGNIZED]                     = -EMEDIUMTYPE,\n};\n\nint vbg_status_code_to_errno(int rc)\n{\n\tif (rc >= 0)\n\t\treturn 0;\n\n\trc = -rc;\n\tif (rc >= ARRAY_SIZE(vbg_status_code_to_errno_table) ||\n\t    vbg_status_code_to_errno_table[rc] == 0) {\n\t\tvbg_warn(\"%s: Unhandled err %d\\n\", __func__, -rc);\n\t\treturn -EPROTO;\n\t}\n\n\treturn vbg_status_code_to_errno_table[rc];\n}\nEXPORT_SYMBOL(vbg_status_code_to_errno);\n"], "filenames": ["drivers/virt/vboxguest/vboxguest_utils.c"], "buggy_code_start_loc": [222], "buggy_code_end_loc": [232], "fixing_code_start_loc": [223], "fixing_code_end_loc": [232], "type": "CWE-401", "message": "A memory leak in the crypto_reportstat() function in drivers/virt/vboxguest/vboxguest_utils.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering copy_form_user() failures, aka CID-e0b0cb938864.", "other": {"cve": {"id": "CVE-2019-19048", "sourceIdentifier": "cve@mitre.org", "published": "2019-11-18T06:15:11.560", "lastModified": "2023-01-17T21:32:10.783", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A memory leak in the crypto_reportstat() function in drivers/virt/vboxguest/vboxguest_utils.c in the Linux kernel before 5.3.9 allows attackers to cause a denial of service (memory consumption) by triggering copy_form_user() failures, aka CID-e0b0cb938864."}, {"lang": "es", "value": "Una p\u00e9rdida de memoria en la funci\u00f3n crypto_reportstat() en el archivo drivers/virt/vboxguest/vboxguest_utils.c en el kernel de Linux versiones anteriores a la versi\u00f3n 5.3.9, permite a atacantes causar una denegaci\u00f3n de servicio (consumo de memoria) al desencadenar fallos de la funci\u00f3n copy_form_user(), tambi\u00e9n se conoce como CID-e0b0cb938864 ."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 7.8}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-401"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.16", "versionEndExcluding": "4.19.82", "matchCriteriaId": "275F3537-F1CC-4255-8F72-69754C622671"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.20", "versionEndExcluding": "5.3.9", "matchCriteriaId": "BC19B2E4-2B1F-44F3-9944-91396EAC744D"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:lts:*:*:*", "matchCriteriaId": "23A7C53F-B80F-4E6A-AFA9-58EEA84BE11D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:19.10:*:*:*:*:*:*:*", "matchCriteriaId": "A31C8344-3E02-4EB8-8BD8-4C84B7959624"}]}]}], "references": [{"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.3.9", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/e0b0cb9388642c104838fac100a4af32745621e2", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20191205-0001/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4208-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4226-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/e0b0cb9388642c104838fac100a4af32745621e2"}}
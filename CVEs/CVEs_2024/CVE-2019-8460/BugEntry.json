{"buggy_code": ["/*\t$OpenBSD: tcp.h,v 1.20 2013/08/12 21:57:16 bluhm Exp $\t*/\n/*\t$NetBSD: tcp.h,v 1.8 1995/04/17 05:32:58 cgd Exp $\t*/\n\n/*\n * Copyright (c) 1982, 1986, 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n *\t@(#)tcp.h\t8.1 (Berkeley) 6/10/93\n */\n\n#ifndef _NETINET_TCP_H_\n#define\t_NETINET_TCP_H_\n\n#include <sys/cdefs.h>\n\n#if __BSD_VISIBLE\n\ntypedef u_int32_t tcp_seq;\n\n/*\n * TCP header.\n * Per RFC 793, September, 1981.\n */\nstruct tcphdr {\n\tu_int16_t th_sport;\t\t/* source port */\n\tu_int16_t th_dport;\t\t/* destination port */\n\ttcp_seq\t  th_seq;\t\t/* sequence number */\n\ttcp_seq\t  th_ack;\t\t/* acknowledgement number */\n#if _BYTE_ORDER == _LITTLE_ENDIAN\n\tu_int32_t th_x2:4,\t\t/* (unused) */\n\t\t  th_off:4;\t\t/* data offset */\n#endif\n#if _BYTE_ORDER == _BIG_ENDIAN\n\tu_int32_t th_off:4,\t\t/* data offset */\n\t\t  th_x2:4;\t\t/* (unused) */\n#endif\n\tu_int8_t  th_flags;\n#define\tTH_FIN\t  0x01\n#define\tTH_SYN\t  0x02\n#define\tTH_RST\t  0x04\n#define\tTH_PUSH\t  0x08\n#define\tTH_ACK\t  0x10\n#define\tTH_URG\t  0x20\n#define\tTH_ECE\t  0x40\n#define\tTH_CWR\t  0x80\n\tu_int16_t th_win;\t\t\t/* window */\n\tu_int16_t th_sum;\t\t\t/* checksum */\n\tu_int16_t th_urp;\t\t\t/* urgent pointer */\n};\n#define th_reseqlen th_urp\t\t\t/* TCP data length for\n\t\t\t\t\t\t   resequencing/reassembly */\n\n#define\tTCPOPT_EOL\t\t0\n#define\tTCPOPT_NOP\t\t1\n#define\tTCPOPT_MAXSEG\t\t2\n#define\tTCPOLEN_MAXSEG\t\t4\n#define\tTCPOPT_WINDOW\t\t3\n#define\tTCPOLEN_WINDOW\t\t3\n#define\tTCPOPT_SACK_PERMITTED\t4\t\t/* Experimental */\n#define\tTCPOLEN_SACK_PERMITTED\t2\n#define\tTCPOPT_SACK\t\t5\t\t/* Experimental */\n#define\tTCPOLEN_SACK\t\t8\t\t/* 2*sizeof(tcp_seq) */\n#define\tTCPOPT_TIMESTAMP\t8\n#define\tTCPOLEN_TIMESTAMP\t\t10\n#define\tTCPOLEN_TSTAMP_APPA\t\t(TCPOLEN_TIMESTAMP+2) /* appendix A */\n#define\tTCPOPT_SIGNATURE\t19\n#define\tTCPOLEN_SIGNATURE\t\t18\n#define\tTCPOLEN_SIGLEN\t\t(TCPOLEN_SIGNATURE+2) /* padding */\n\n#define\tMAX_TCPOPTLEN\t\t40\t/* Absolute maximum TCP options len */\n\n#define\tTCPOPT_TSTAMP_HDR\t\\\n    (TCPOPT_NOP<<24|TCPOPT_NOP<<16|TCPOPT_TIMESTAMP<<8|TCPOLEN_TIMESTAMP)\n\n/* Option definitions */\n#define\tTCPOPT_SACK_PERMIT_HDR \\\n(TCPOPT_NOP<<24|TCPOPT_NOP<<16|TCPOPT_SACK_PERMITTED<<8|TCPOLEN_SACK_PERMITTED)\n#define\tTCPOPT_SACK_HDR   (TCPOPT_NOP<<24|TCPOPT_NOP<<16|TCPOPT_SACK<<8)\n/* Miscellaneous constants */\n#define\tMAX_SACK_BLKS\t6\t/* Max # SACK blocks stored at sender side */\n#define\tTCP_MAX_SACK\t3\t/* MAX # SACKs sent in any segment */\n\n#define\tTCP_MAXBURST\t4\t/* Max # packets after leaving Fast Rxmit */\n\n/*\n * Default maximum segment size for TCP.\n * With an IP MSS of 576, this is 536,\n * but 512 is probably more convenient.\n * This should be defined as min(512, IP_MSS - sizeof (struct tcpiphdr)).\n */\n#define\tTCP_MSS\t\t512\n\n#define\tTCP_MAXWIN\t65535\t/* largest value for (unscaled) window */\n\n#define\tTCP_MAX_WINSHIFT\t14\t/* maximum window shift */\n\n#endif /* __BSD_VISIBLE */\n\n/*\n * User-settable options (used with setsockopt).\n */\n#define\tTCP_NODELAY\t\t0x01   /* don't delay send to coalesce pkts */\n#define\tTCP_MAXSEG\t\t0x02   /* set maximum segment size */\n#define\tTCP_MD5SIG\t\t0x04   /* enable TCP MD5 signature option */\n#define\tTCP_SACK_ENABLE\t\t0x08   /* enable SACKs (if disabled by def.) */\n#define\tTCP_NOPUSH\t\t0x10   /* don't push last block of write */\n\n#endif /* _NETINET_TCP_H_ */\n", "/*\t$OpenBSD: tcp_input.c,v 1.359 2018/09/17 14:07:48 friehm Exp $\t*/\n/*\t$NetBSD: tcp_input.c,v 1.23 1996/02/13 23:43:44 christos Exp $\t*/\n\n/*\n * Copyright (c) 1982, 1986, 1988, 1990, 1993, 1994\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n *\t@(#)COPYRIGHT\t1.1 (NRL) 17 January 1995\n *\n * NRL grants permission for redistribution and use in source and binary\n * forms, with or without modification, of the software and documentation\n * created at NRL provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. All advertising materials mentioning features or use of this software\n *    must display the following acknowledgements:\n *\tThis product includes software developed by the University of\n *\tCalifornia, Berkeley and its contributors.\n *\tThis product includes software developed at the Information\n *\tTechnology Division, US Naval Research Laboratory.\n * 4. Neither the name of the NRL nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THE SOFTWARE PROVIDED BY NRL IS PROVIDED BY NRL AND CONTRIBUTORS ``AS\n * IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL NRL OR\n * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * The views and conclusions contained in the software and documentation\n * are those of the authors and should not be interpreted as representing\n * official policies, either expressed or implied, of the US Naval\n * Research Laboratory (NRL).\n */\n\n#include \"pf.h\"\n\n#include <sys/param.h>\n#include <sys/systm.h>\n#include <sys/mbuf.h>\n#include <sys/protosw.h>\n#include <sys/socket.h>\n#include <sys/socketvar.h>\n#include <sys/timeout.h>\n#include <sys/kernel.h>\n#include <sys/pool.h>\n\n#include <net/if.h>\n#include <net/if_var.h>\n#include <net/route.h>\n\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <netinet/in_pcb.h>\n#include <netinet/ip_var.h>\n#include <netinet/tcp.h>\n#include <netinet/tcp_fsm.h>\n#include <netinet/tcp_seq.h>\n#include <netinet/tcp_timer.h>\n#include <netinet/tcp_var.h>\n#include <netinet/tcp_debug.h>\n\n#if NPF > 0\n#include <net/pfvar.h>\n#endif\n\nstruct\ttcpiphdr tcp_saveti;\n\nint tcp_mss_adv(struct mbuf *, int);\nint tcp_flush_queue(struct tcpcb *);\n\n#ifdef INET6\n#include <netinet6/in6_var.h>\n#include <netinet6/nd6.h>\n\nstruct  tcpipv6hdr tcp_saveti6;\n\n/* for the packet header length in the mbuf */\n#define M_PH_LEN(m)      (((struct mbuf *)(m))->m_pkthdr.len)\n#define M_V6_LEN(m)      (M_PH_LEN(m) - sizeof(struct ip6_hdr))\n#define M_V4_LEN(m)      (M_PH_LEN(m) - sizeof(struct ip))\n#endif /* INET6 */\n\nint\ttcprexmtthresh = 3;\nint\ttcptv_keep_init = TCPTV_KEEP_INIT;\n\nint tcp_rst_ppslim = 100;\t\t/* 100pps */\nint tcp_rst_ppslim_count = 0;\nstruct timeval tcp_rst_ppslim_last;\n\nint tcp_ackdrop_ppslim = 100;\t\t/* 100pps */\nint tcp_ackdrop_ppslim_count = 0;\nstruct timeval tcp_ackdrop_ppslim_last;\n\n#define TCP_PAWS_IDLE\t(24 * 24 * 60 * 60 * PR_SLOWHZ)\n\n/* for modulo comparisons of timestamps */\n#define TSTMP_LT(a,b)\t((int)((a)-(b)) < 0)\n#define TSTMP_GEQ(a,b)\t((int)((a)-(b)) >= 0)\n\n/* for TCP SACK comparisons */\n#define\tSEQ_MIN(a,b)\t(SEQ_LT(a,b) ? (a) : (b))\n#define\tSEQ_MAX(a,b)\t(SEQ_GT(a,b) ? (a) : (b))\n\n/*\n * Neighbor Discovery, Neighbor Unreachability Detection Upper layer hint.\n */\n#ifdef INET6\n#define ND6_HINT(tp) \\\ndo { \\\n\tif (tp && tp->t_inpcb && (tp->t_inpcb->inp_flags & INP_IPV6) &&\t\\\n\t    rtisvalid(tp->t_inpcb->inp_route6.ro_rt)) {\t\t\t\\\n\t\tnd6_nud_hint(tp->t_inpcb->inp_route6.ro_rt);\t\t\\\n\t} \\\n} while (0)\n#else\n#define ND6_HINT(tp)\n#endif\n\n#ifdef TCP_ECN\n/*\n * ECN (Explicit Congestion Notification) support based on RFC3168\n * implementation note:\n *   snd_last is used to track a recovery phase.\n *   when cwnd is reduced, snd_last is set to snd_max.\n *   while snd_last > snd_una, the sender is in a recovery phase and\n *   its cwnd should not be reduced again.\n *   snd_last follows snd_una when not in a recovery phase.\n */\n#endif\n\n/*\n * Macro to compute ACK transmission behavior.  Delay the ACK unless\n * we have already delayed an ACK (must send an ACK every two segments).\n * We also ACK immediately if we received a PUSH and the ACK-on-PUSH\n * option is enabled or when the packet is coming from a loopback\n * interface.\n */\n#define\tTCP_SETUP_ACK(tp, tiflags, m) \\\ndo { \\\n\tstruct ifnet *ifp = NULL; \\\n\tif (m && (m->m_flags & M_PKTHDR)) \\\n\t\tifp = if_get(m->m_pkthdr.ph_ifidx); \\\n\tif (TCP_TIMER_ISARMED(tp, TCPT_DELACK) || \\\n\t    (tcp_ack_on_push && (tiflags) & TH_PUSH) || \\\n\t    (ifp && (ifp->if_flags & IFF_LOOPBACK))) \\\n\t\ttp->t_flags |= TF_ACKNOW; \\\n\telse \\\n\t\tTCP_TIMER_ARM_MSEC(tp, TCPT_DELACK, tcp_delack_msecs); \\\n\tif_put(ifp); \\\n} while (0)\n\nvoid\t tcp_sack_partialack(struct tcpcb *, struct tcphdr *);\nvoid\t tcp_newreno_partialack(struct tcpcb *, struct tcphdr *);\n\nvoid\t syn_cache_put(struct syn_cache *);\nvoid\t syn_cache_rm(struct syn_cache *);\nint\t syn_cache_respond(struct syn_cache *, struct mbuf *);\nvoid\t syn_cache_timer(void *);\nvoid\t syn_cache_reaper(void *);\nvoid\t syn_cache_insert(struct syn_cache *, struct tcpcb *);\nvoid\t syn_cache_reset(struct sockaddr *, struct sockaddr *,\n\t\tstruct tcphdr *, u_int);\nint\t syn_cache_add(struct sockaddr *, struct sockaddr *, struct tcphdr *,\n\t\tunsigned int, struct socket *, struct mbuf *, u_char *, int,\n\t\tstruct tcp_opt_info *, tcp_seq *);\nstruct socket *syn_cache_get(struct sockaddr *, struct sockaddr *,\n\t\tstruct tcphdr *, unsigned int, unsigned int, struct socket *,\n\t\tstruct mbuf *);\nstruct syn_cache *syn_cache_lookup(struct sockaddr *, struct sockaddr *,\n\t\tstruct syn_cache_head **, u_int);\n\n/*\n * Insert segment ti into reassembly queue of tcp with\n * control block tp.  Return TH_FIN if reassembly now includes\n * a segment with FIN.  The macro form does the common case inline\n * (segment is the next to be received on an established connection,\n * and the queue is empty), avoiding linkage into and removal\n * from the queue and repetition of various conversions.\n * Set DELACK for segments received in order, but ack immediately\n * when segments are out of order (so fast retransmit can work).\n */\n\nint\ntcp_reass(struct tcpcb *tp, struct tcphdr *th, struct mbuf *m, int *tlen)\n{\n\tstruct tcpqent *p, *q, *nq, *tiqe;\n\n\t/*\n\t * Allocate a new queue entry, before we throw away any data.\n\t * If we can't, just drop the packet.  XXX\n\t */\n\ttiqe = pool_get(&tcpqe_pool, PR_NOWAIT);\n\tif (tiqe == NULL) {\n\t\ttiqe = TAILQ_LAST(&tp->t_segq, tcpqehead);\n\t\tif (tiqe != NULL && th->th_seq == tp->rcv_nxt) {\n\t\t\t/* Reuse last entry since new segment fills a hole */\n\t\t\tm_freem(tiqe->tcpqe_m);\n\t\t\tTAILQ_REMOVE(&tp->t_segq, tiqe, tcpqe_q);\n\t\t}\n\t\tif (tiqe == NULL || th->th_seq != tp->rcv_nxt) {\n\t\t\t/* Flush segment queue for this connection */\n\t\t\ttcp_freeq(tp);\n\t\t\ttcpstat_inc(tcps_rcvmemdrop);\n\t\t\tm_freem(m);\n\t\t\treturn (0);\n\t\t}\n\t}\n\n\t/*\n\t * Find a segment which begins after this one does.\n\t */\n\tfor (p = NULL, q = TAILQ_FIRST(&tp->t_segq); q != NULL;\n\t    p = q, q = TAILQ_NEXT(q, tcpqe_q))\n\t\tif (SEQ_GT(q->tcpqe_tcp->th_seq, th->th_seq))\n\t\t\tbreak;\n\n\t/*\n\t * If there is a preceding segment, it may provide some of\n\t * our data already.  If so, drop the data from the incoming\n\t * segment.  If it provides all of our data, drop us.\n\t */\n\tif (p != NULL) {\n\t\tstruct tcphdr *phdr = p->tcpqe_tcp;\n\t\tint i;\n\n\t\t/* conversion to int (in i) handles seq wraparound */\n\t\ti = phdr->th_seq + phdr->th_reseqlen - th->th_seq;\n\t\tif (i > 0) {\n\t\t        if (i >= *tlen) {\n\t\t\t\ttcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte,\n\t\t\t\t    *tlen);\n\t\t\t\tm_freem(m);\n\t\t\t\tpool_put(&tcpqe_pool, tiqe);\n\t\t\t\treturn (0);\n\t\t\t}\n\t\t\tm_adj(m, i);\n\t\t\t*tlen -= i;\n\t\t\tth->th_seq += i;\n\t\t}\n\t}\n\ttcpstat_pkt(tcps_rcvoopack, tcps_rcvoobyte, *tlen);\n\n\t/*\n\t * While we overlap succeeding segments trim them or,\n\t * if they are completely covered, dequeue them.\n\t */\n\tfor (; q != NULL; q = nq) {\n\t\tstruct tcphdr *qhdr = q->tcpqe_tcp;\n\t\tint i = (th->th_seq + *tlen) - qhdr->th_seq;\n\n\t\tif (i <= 0)\n\t\t\tbreak;\n\t\tif (i < qhdr->th_reseqlen) {\n\t\t\tqhdr->th_seq += i;\n\t\t\tqhdr->th_reseqlen -= i;\n\t\t\tm_adj(q->tcpqe_m, i);\n\t\t\tbreak;\n\t\t}\n\t\tnq = TAILQ_NEXT(q, tcpqe_q);\n\t\tm_freem(q->tcpqe_m);\n\t\tTAILQ_REMOVE(&tp->t_segq, q, tcpqe_q);\n\t\tpool_put(&tcpqe_pool, q);\n\t}\n\n\t/* Insert the new segment queue entry into place. */\n\ttiqe->tcpqe_m = m;\n\tth->th_reseqlen = *tlen;\n\ttiqe->tcpqe_tcp = th;\n\tif (p == NULL) {\n\t\tTAILQ_INSERT_HEAD(&tp->t_segq, tiqe, tcpqe_q);\n\t} else {\n\t\tTAILQ_INSERT_AFTER(&tp->t_segq, p, tiqe, tcpqe_q);\n\t}\n\n\tif (th->th_seq != tp->rcv_nxt)\n\t\treturn (0);\n\n\treturn (tcp_flush_queue(tp));\n}\n\nint\ntcp_flush_queue(struct tcpcb *tp)\n{\n\tstruct socket *so = tp->t_inpcb->inp_socket;\n\tstruct tcpqent *q, *nq;\n\tint flags;\n\n\t/*\n\t * Present data to user, advancing rcv_nxt through\n\t * completed sequence space.\n\t */\n\tif (TCPS_HAVEESTABLISHED(tp->t_state) == 0)\n\t\treturn (0);\n\tq = TAILQ_FIRST(&tp->t_segq);\n\tif (q == NULL || q->tcpqe_tcp->th_seq != tp->rcv_nxt)\n\t\treturn (0);\n\tif (tp->t_state == TCPS_SYN_RECEIVED && q->tcpqe_tcp->th_reseqlen)\n\t\treturn (0);\n\tdo {\n\t\ttp->rcv_nxt += q->tcpqe_tcp->th_reseqlen;\n\t\tflags = q->tcpqe_tcp->th_flags & TH_FIN;\n\n\t\tnq = TAILQ_NEXT(q, tcpqe_q);\n\t\tTAILQ_REMOVE(&tp->t_segq, q, tcpqe_q);\n\t\tND6_HINT(tp);\n\t\tif (so->so_state & SS_CANTRCVMORE)\n\t\t\tm_freem(q->tcpqe_m);\n\t\telse\n\t\t\tsbappendstream(so, &so->so_rcv, q->tcpqe_m);\n\t\tpool_put(&tcpqe_pool, q);\n\t\tq = nq;\n\t} while (q != NULL && q->tcpqe_tcp->th_seq == tp->rcv_nxt);\n\ttp->t_flags |= TF_BLOCKOUTPUT;\n\tsorwakeup(so);\n\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\treturn (flags);\n}\n\n/*\n * TCP input routine, follows pages 65-76 of the\n * protocol specification dated September, 1981 very closely.\n */\nint\ntcp_input(struct mbuf **mp, int *offp, int proto, int af)\n{\n\tstruct mbuf *m = *mp;\n\tint iphlen = *offp;\n\tstruct ip *ip = NULL;\n\tstruct inpcb *inp = NULL;\n\tu_int8_t *optp = NULL;\n\tint optlen = 0;\n\tint tlen, off;\n\tstruct tcpcb *otp = NULL, *tp = NULL;\n\tint tiflags;\n\tstruct socket *so = NULL;\n\tint todrop, acked, ourfinisacked;\n\tint hdroptlen = 0;\n\tshort ostate;\n\tcaddr_t saveti;\n\ttcp_seq iss, *reuse = NULL;\n\tu_long tiwin;\n\tstruct tcp_opt_info opti;\n\tstruct tcphdr *th;\n#ifdef INET6\n\tstruct ip6_hdr *ip6 = NULL;\n#endif /* INET6 */\n#ifdef IPSEC\n\tstruct m_tag *mtag;\n\tstruct tdb_ident *tdbi;\n\tstruct tdb *tdb;\n\tint error;\n#endif /* IPSEC */\n#ifdef TCP_ECN\n\tu_char iptos;\n#endif\n\n\ttcpstat_inc(tcps_rcvtotal);\n\n\topti.ts_present = 0;\n\topti.maxseg = 0;\n\n\t/*\n\t * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN\n\t */\n\tif (m->m_flags & (M_BCAST|M_MCAST))\n\t\tgoto drop;\n\n\t/*\n\t * Get IP and TCP header together in first mbuf.\n\t * Note: IP leaves IP header in first mbuf.\n\t */\n\tIP6_EXTHDR_GET(th, struct tcphdr *, m, iphlen, sizeof(*th));\n\tif (!th) {\n\t\ttcpstat_inc(tcps_rcvshort);\n\t\treturn IPPROTO_DONE;\n\t}\n\n\ttlen = m->m_pkthdr.len - iphlen;\n\tswitch (af) {\n\tcase AF_INET:\n\t\tip = mtod(m, struct ip *);\n#ifdef TCP_ECN\n\t\t/* save ip_tos before clearing it for checksum */\n\t\tiptos = ip->ip_tos;\n#endif\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6 = mtod(m, struct ip6_hdr *);\n#ifdef TCP_ECN\n\t\tiptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;\n#endif\n\n\t\t/*\n\t\t * Be proactive about unspecified IPv6 address in source.\n\t\t * As we use all-zero to indicate unbounded/unconnected pcb,\n\t\t * unspecified IPv6 address can be used to confuse us.\n\t\t *\n\t\t * Note that packets with unspecified IPv6 destination is\n\t\t * already dropped in ip6_input.\n\t\t */\n\t\tif (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {\n\t\t\t/* XXX stat */\n\t\t\tgoto drop;\n\t\t}\n\n\t\t/* Discard packets to multicast */\n\t\tif (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst)) {\n\t\t\t/* XXX stat */\n\t\t\tgoto drop;\n\t\t}\n\t\tbreak;\n#endif\n\tdefault:\n\t\tunhandled_af(af);\n\t}\n\n\t/*\n\t * Checksum extended TCP header and data.\n\t */\n\tif ((m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_OK) == 0) {\n\t\tint sum;\n\n\t\tif (m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_BAD) {\n\t\t\ttcpstat_inc(tcps_rcvbadsum);\n\t\t\tgoto drop;\n\t\t}\n\t\ttcpstat_inc(tcps_inswcsum);\n\t\tswitch (af) {\n\t\tcase AF_INET:\n\t\t\tsum = in4_cksum(m, IPPROTO_TCP, iphlen, tlen);\n\t\t\tbreak;\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tsum = in6_cksum(m, IPPROTO_TCP, sizeof(struct ip6_hdr),\n\t\t\t    tlen);\n\t\t\tbreak;\n#endif\n\t\t}\n\t\tif (sum != 0) {\n\t\t\ttcpstat_inc(tcps_rcvbadsum);\n\t\t\tgoto drop;\n\t\t}\n\t}\n\n\t/*\n\t * Check that TCP offset makes sense,\n\t * pull out TCP options and adjust length.\t\tXXX\n\t */\n\toff = th->th_off << 2;\n\tif (off < sizeof(struct tcphdr) || off > tlen) {\n\t\ttcpstat_inc(tcps_rcvbadoff);\n\t\tgoto drop;\n\t}\n\ttlen -= off;\n\tif (off > sizeof(struct tcphdr)) {\n\t\tIP6_EXTHDR_GET(th, struct tcphdr *, m, iphlen, off);\n\t\tif (!th) {\n\t\t\ttcpstat_inc(tcps_rcvshort);\n\t\t\treturn IPPROTO_DONE;\n\t\t}\n\t\toptlen = off - sizeof(struct tcphdr);\n\t\toptp = (u_int8_t *)(th + 1);\n\t\t/*\n\t\t * Do quick retrieval of timestamp options (\"options\n\t\t * prediction?\").  If timestamp is the only option and it's\n\t\t * formatted as recommended in RFC 1323 appendix A, we\n\t\t * quickly get the values now and not bother calling\n\t\t * tcp_dooptions(), etc.\n\t\t */\n\t\tif ((optlen == TCPOLEN_TSTAMP_APPA ||\n\t\t     (optlen > TCPOLEN_TSTAMP_APPA &&\n\t\t\toptp[TCPOLEN_TSTAMP_APPA] == TCPOPT_EOL)) &&\n\t\t     *(u_int32_t *)optp == htonl(TCPOPT_TSTAMP_HDR) &&\n\t\t     (th->th_flags & TH_SYN) == 0) {\n\t\t\topti.ts_present = 1;\n\t\t\topti.ts_val = ntohl(*(u_int32_t *)(optp + 4));\n\t\t\topti.ts_ecr = ntohl(*(u_int32_t *)(optp + 8));\n\t\t\toptp = NULL;\t/* we've parsed the options */\n\t\t}\n\t}\n\ttiflags = th->th_flags;\n\n\t/*\n\t * Convert TCP protocol specific fields to host format.\n\t */\n\tth->th_seq = ntohl(th->th_seq);\n\tth->th_ack = ntohl(th->th_ack);\n\tth->th_win = ntohs(th->th_win);\n\tth->th_urp = ntohs(th->th_urp);\n\n\t/*\n\t * Locate pcb for segment.\n\t */\n#if NPF > 0\n\tinp = pf_inp_lookup(m);\n#endif\nfindpcb:\n\tif (inp == NULL) {\n\t\tswitch (af) {\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tinp = in6_pcbhashlookup(&tcbtable, &ip6->ip6_src,\n\t\t\t    th->th_sport, &ip6->ip6_dst, th->th_dport,\n\t\t\t    m->m_pkthdr.ph_rtableid);\n\t\t\tbreak;\n#endif\n\t\tcase AF_INET:\n\t\t\tinp = in_pcbhashlookup(&tcbtable, ip->ip_src,\n\t\t\t    th->th_sport, ip->ip_dst, th->th_dport,\n\t\t\t    m->m_pkthdr.ph_rtableid);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (inp == NULL) {\n\t\ttcpstat_inc(tcps_pcbhashmiss);\n\t\tswitch (af) {\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tinp = in6_pcblookup_listen(&tcbtable, &ip6->ip6_dst,\n\t\t\t    th->th_dport, m, m->m_pkthdr.ph_rtableid);\n\t\t\tbreak;\n#endif /* INET6 */\n\t\tcase AF_INET:\n\t\t\tinp = in_pcblookup_listen(&tcbtable, ip->ip_dst,\n\t\t\t    th->th_dport, m, m->m_pkthdr.ph_rtableid);\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * If the state is CLOSED (i.e., TCB does not exist) then\n\t\t * all data in the incoming segment is discarded.\n\t\t * If the TCB exists but is in CLOSED state, it is embryonic,\n\t\t * but should either do a listen or a connect soon.\n\t\t */\n\t\tif (inp == NULL) {\n\t\t\ttcpstat_inc(tcps_noport);\n\t\t\tgoto dropwithreset_ratelim;\n\t\t}\n\t}\n\tKASSERT(sotoinpcb(inp->inp_socket) == inp);\n\tKASSERT(intotcpcb(inp) == NULL || intotcpcb(inp)->t_inpcb == inp);\n\tsoassertlocked(inp->inp_socket);\n\n\t/* Check the minimum TTL for socket. */\n\tswitch (af) {\n\tcase AF_INET:\n\t\tif (inp->inp_ip_minttl && inp->inp_ip_minttl > ip->ip_ttl)\n\t\t\tgoto drop;\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tif (inp->inp_ip6_minhlim &&\n\t\t    inp->inp_ip6_minhlim > ip6->ip6_hlim)\n\t\t\tgoto drop;\n\t\tbreak;\n#endif\n\t}\n\n\ttp = intotcpcb(inp);\n\tif (tp == NULL)\n\t\tgoto dropwithreset_ratelim;\n\tif (tp->t_state == TCPS_CLOSED)\n\t\tgoto drop;\n\n\t/* Unscale the window into a 32-bit value. */\n\tif ((tiflags & TH_SYN) == 0)\n\t\ttiwin = th->th_win << tp->snd_scale;\n\telse\n\t\ttiwin = th->th_win;\n\n\tso = inp->inp_socket;\n\tif (so->so_options & (SO_DEBUG|SO_ACCEPTCONN)) {\n\t\tunion syn_cache_sa src;\n\t\tunion syn_cache_sa dst;\n\n\t\tbzero(&src, sizeof(src));\n\t\tbzero(&dst, sizeof(dst));\n\t\tswitch (af) {\n\t\tcase AF_INET:\n\t\t\tsrc.sin.sin_len = sizeof(struct sockaddr_in);\n\t\t\tsrc.sin.sin_family = AF_INET;\n\t\t\tsrc.sin.sin_addr = ip->ip_src;\n\t\t\tsrc.sin.sin_port = th->th_sport;\n\n\t\t\tdst.sin.sin_len = sizeof(struct sockaddr_in);\n\t\t\tdst.sin.sin_family = AF_INET;\n\t\t\tdst.sin.sin_addr = ip->ip_dst;\n\t\t\tdst.sin.sin_port = th->th_dport;\n\t\t\tbreak;\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tsrc.sin6.sin6_len = sizeof(struct sockaddr_in6);\n\t\t\tsrc.sin6.sin6_family = AF_INET6;\n\t\t\tsrc.sin6.sin6_addr = ip6->ip6_src;\n\t\t\tsrc.sin6.sin6_port = th->th_sport;\n\n\t\t\tdst.sin6.sin6_len = sizeof(struct sockaddr_in6);\n\t\t\tdst.sin6.sin6_family = AF_INET6;\n\t\t\tdst.sin6.sin6_addr = ip6->ip6_dst;\n\t\t\tdst.sin6.sin6_port = th->th_dport;\n\t\t\tbreak;\n#endif /* INET6 */\n\t\t}\n\n\t\tif (so->so_options & SO_DEBUG) {\n\t\t\totp = tp;\n\t\t\tostate = tp->t_state;\n\t\t\tswitch (af) {\n#ifdef INET6\n\t\t\tcase AF_INET6:\n\t\t\t\tsaveti = (caddr_t) &tcp_saveti6;\n\t\t\t\tmemcpy(&tcp_saveti6.ti6_i, ip6, sizeof(*ip6));\n\t\t\t\tmemcpy(&tcp_saveti6.ti6_t, th, sizeof(*th));\n\t\t\t\tbreak;\n#endif\n\t\t\tcase AF_INET:\n\t\t\t\tsaveti = (caddr_t) &tcp_saveti;\n\t\t\t\tmemcpy(&tcp_saveti.ti_i, ip, sizeof(*ip));\n\t\t\t\tmemcpy(&tcp_saveti.ti_t, th, sizeof(*th));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (so->so_options & SO_ACCEPTCONN) {\n\t\t\tswitch (tiflags & (TH_RST|TH_SYN|TH_ACK)) {\n\n\t\t\tcase TH_SYN|TH_ACK|TH_RST:\n\t\t\tcase TH_SYN|TH_RST:\n\t\t\tcase TH_ACK|TH_RST:\n\t\t\tcase TH_RST:\n\t\t\t\tsyn_cache_reset(&src.sa, &dst.sa, th,\n\t\t\t\t    inp->inp_rtableid);\n\t\t\t\tgoto drop;\n\n\t\t\tcase TH_SYN|TH_ACK:\n\t\t\t\t/*\n\t\t\t\t * Received a SYN,ACK.  This should\n\t\t\t\t * never happen while we are in\n\t\t\t\t * LISTEN.  Send an RST.\n\t\t\t\t */\n\t\t\t\tgoto badsyn;\n\n\t\t\tcase TH_ACK:\n\t\t\t\tso = syn_cache_get(&src.sa, &dst.sa,\n\t\t\t\t\tth, iphlen, tlen, so, m);\n\t\t\t\tif (so == NULL) {\n\t\t\t\t\t/*\n\t\t\t\t\t * We don't have a SYN for\n\t\t\t\t\t * this ACK; send an RST.\n\t\t\t\t\t */\n\t\t\t\t\tgoto badsyn;\n\t\t\t\t} else if (so == (struct socket *)(-1)) {\n\t\t\t\t\t/*\n\t\t\t\t\t * We were unable to create\n\t\t\t\t\t * the connection.  If the\n\t\t\t\t\t * 3-way handshake was\n\t\t\t\t\t * completed, and RST has\n\t\t\t\t\t * been sent to the peer.\n\t\t\t\t\t * Since the mbuf might be\n\t\t\t\t\t * in use for the reply,\n\t\t\t\t\t * do not free it.\n\t\t\t\t\t */\n\t\t\t\t\tm = *mp = NULL;\n\t\t\t\t\tgoto drop;\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * We have created a\n\t\t\t\t\t * full-blown connection.\n\t\t\t\t\t */\n\t\t\t\t\ttp = NULL;\n\t\t\t\t\tinp = sotoinpcb(so);\n\t\t\t\t\ttp = intotcpcb(inp);\n\t\t\t\t\tif (tp == NULL)\n\t\t\t\t\t\tgoto badsyn;\t/*XXX*/\n\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\t/*\n\t\t\t\t * None of RST, SYN or ACK was set.\n\t\t\t\t * This is an invalid packet for a\n\t\t\t\t * TCB in LISTEN state.  Send a RST.\n\t\t\t\t */\n\t\t\t\tgoto badsyn;\n\n\t\t\tcase TH_SYN:\n\t\t\t\t/*\n\t\t\t\t * Received a SYN.\n\t\t\t\t */\n#ifdef INET6\n\t\t\t\t/*\n\t\t\t\t * If deprecated address is forbidden, we do\n\t\t\t\t * not accept SYN to deprecated interface\n\t\t\t\t * address to prevent any new inbound\n\t\t\t\t * connection from getting established.\n\t\t\t\t * When we do not accept SYN, we send a TCP\n\t\t\t\t * RST, with deprecated source address (instead\n\t\t\t\t * of dropping it).  We compromise it as it is\n\t\t\t\t * much better for peer to send a RST, and\n\t\t\t\t * RST will be the final packet for the\n\t\t\t\t * exchange.\n\t\t\t\t *\n\t\t\t\t * If we do not forbid deprecated addresses, we\n\t\t\t\t * accept the SYN packet.  RFC2462 does not\n\t\t\t\t * suggest dropping SYN in this case.\n\t\t\t\t * If we decipher RFC2462 5.5.4, it says like\n\t\t\t\t * this:\n\t\t\t\t * 1. use of deprecated addr with existing\n\t\t\t\t *    communication is okay - \"SHOULD continue\n\t\t\t\t *    to be used\"\n\t\t\t\t * 2. use of it with new communication:\n\t\t\t\t *   (2a) \"SHOULD NOT be used if alternate\n\t\t\t\t *        address with sufficient scope is\n\t\t\t\t *        available\"\n\t\t\t\t *   (2b) nothing mentioned otherwise.\n\t\t\t\t * Here we fall into (2b) case as we have no\n\t\t\t\t * choice in our source address selection - we\n\t\t\t\t * must obey the peer.\n\t\t\t\t *\n\t\t\t\t * The wording in RFC2462 is confusing, and\n\t\t\t\t * there are multiple description text for\n\t\t\t\t * deprecated address handling - worse, they\n\t\t\t\t * are not exactly the same.  I believe 5.5.4\n\t\t\t\t * is the best one, so we follow 5.5.4.\n\t\t\t\t */\n\t\t\t\tif (ip6 && !ip6_use_deprecated) {\n\t\t\t\t\tstruct in6_ifaddr *ia6;\n\t\t\t\t\tstruct ifnet *ifp =\n\t\t\t\t\t    if_get(m->m_pkthdr.ph_ifidx);\n\n\t\t\t\t\tif (ifp &&\n\t\t\t\t\t    (ia6 = in6ifa_ifpwithaddr(ifp,\n\t\t\t\t\t    &ip6->ip6_dst)) &&\n\t\t\t\t\t    (ia6->ia6_flags &\n\t\t\t\t\t    IN6_IFF_DEPRECATED)) {\n\t\t\t\t\t\ttp = NULL;\n\t\t\t\t\t\tif_put(ifp);\n\t\t\t\t\t\tgoto dropwithreset;\n\t\t\t\t\t}\n\t\t\t\t\tif_put(ifp);\n\t\t\t\t}\n#endif\n\n\t\t\t\t/*\n\t\t\t\t * LISTEN socket received a SYN\n\t\t\t\t * from itself?  This can't possibly\n\t\t\t\t * be valid; drop the packet.\n\t\t\t\t */\n\t\t\t\tif (th->th_dport == th->th_sport) {\n\t\t\t\t\tswitch (af) {\n#ifdef INET6\n\t\t\t\t\tcase AF_INET6:\n\t\t\t\t\t\tif (IN6_ARE_ADDR_EQUAL(&ip6->ip6_src,\n\t\t\t\t\t\t    &ip6->ip6_dst)) {\n\t\t\t\t\t\t\ttcpstat_inc(tcps_badsyn);\n\t\t\t\t\t\t\tgoto drop;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n#endif /* INET6 */\n\t\t\t\t\tcase AF_INET:\n\t\t\t\t\t\tif (ip->ip_dst.s_addr == ip->ip_src.s_addr) {\n\t\t\t\t\t\t\ttcpstat_inc(tcps_badsyn);\n\t\t\t\t\t\t\tgoto drop;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * SYN looks ok; create compressed TCP\n\t\t\t\t * state for it.\n\t\t\t\t */\n\t\t\t\tif (so->so_qlen > so->so_qlimit ||\n\t\t\t\t    syn_cache_add(&src.sa, &dst.sa, th, iphlen,\n\t\t\t\t    so, m, optp, optlen, &opti, reuse) == -1) {\n\t\t\t\t\ttcpstat_inc(tcps_dropsyn);\n\t\t\t\t\tgoto drop;\n\t\t\t\t}\n\t\t\t\treturn IPPROTO_DONE;\n\t\t\t}\n\t\t}\n\t}\n\n#ifdef DIAGNOSTIC\n\t/*\n\t * Should not happen now that all embryonic connections\n\t * are handled with compressed state.\n\t */\n\tif (tp->t_state == TCPS_LISTEN)\n\t\tpanic(\"tcp_input: TCPS_LISTEN\");\n#endif\n\n#if NPF > 0\n\tpf_inp_link(m, inp);\n#endif\n\n#ifdef IPSEC\n\t/* Find most recent IPsec tag */\n\tmtag = m_tag_find(m, PACKET_TAG_IPSEC_IN_DONE, NULL);\n\tif (mtag != NULL) {\n\t\ttdbi = (struct tdb_ident *)(mtag + 1);\n\t        tdb = gettdb(tdbi->rdomain, tdbi->spi,\n\t\t    &tdbi->dst, tdbi->proto);\n\t} else\n\t\ttdb = NULL;\n\tipsp_spd_lookup(m, af, iphlen, &error, IPSP_DIRECTION_IN,\n\t    tdb, inp, 0);\n\tif (error) {\n\t\ttcpstat_inc(tcps_rcvnosec);\n\t\tgoto drop;\n\t}\n#endif /* IPSEC */\n\n\t/*\n\t * Segment received on connection.\n\t * Reset idle time and keep-alive timer.\n\t */\n\ttp->t_rcvtime = tcp_now;\n\tif (TCPS_HAVEESTABLISHED(tp->t_state))\n\t\tTCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);\n\n\tif (tp->sack_enable)\n\t\ttcp_del_sackholes(tp, th); /* Delete stale SACK holes */\n\n\t/*\n\t * Process options.\n\t */\n#ifdef TCP_SIGNATURE\n\tif (optp || (tp->t_flags & TF_SIGNATURE))\n#else\n\tif (optp)\n#endif\n\t\tif (tcp_dooptions(tp, optp, optlen, th, m, iphlen, &opti,\n\t\t    m->m_pkthdr.ph_rtableid))\n\t\t\tgoto drop;\n\n\tif (opti.ts_present && opti.ts_ecr) {\n\t\tint rtt_test;\n\n\t\t/* subtract out the tcp timestamp modulator */\n\t\topti.ts_ecr -= tp->ts_modulate;\n\n\t\t/* make sure ts_ecr is sensible */\n\t\trtt_test = tcp_now - opti.ts_ecr;\n\t\tif (rtt_test < 0 || rtt_test > TCP_RTT_MAX)\n\t\t\topti.ts_ecr = 0;\n\t}\n\n#ifdef TCP_ECN\n\t/* if congestion experienced, set ECE bit in subsequent packets. */\n\tif ((iptos & IPTOS_ECN_MASK) == IPTOS_ECN_CE) {\n\t\ttp->t_flags |= TF_RCVD_CE;\n\t\ttcpstat_inc(tcps_ecn_rcvce);\n\t}\n#endif\n\t/*\n\t * Header prediction: check for the two common cases\n\t * of a uni-directional data xfer.  If the packet has\n\t * no control flags, is in-sequence, the window didn't\n\t * change and we're not retransmitting, it's a\n\t * candidate.  If the length is zero and the ack moved\n\t * forward, we're the sender side of the xfer.  Just\n\t * free the data acked & wake any higher level process\n\t * that was blocked waiting for space.  If the length\n\t * is non-zero and the ack didn't move, we're the\n\t * receiver side.  If we're getting packets in-order\n\t * (the reassembly queue is empty), add the data to\n\t * the socket buffer and note that we need a delayed ack.\n\t */\n\tif (tp->t_state == TCPS_ESTABLISHED &&\n#ifdef TCP_ECN\n\t    (tiflags & (TH_SYN|TH_FIN|TH_RST|TH_URG|TH_ECE|TH_CWR|TH_ACK)) == TH_ACK &&\n#else\n\t    (tiflags & (TH_SYN|TH_FIN|TH_RST|TH_URG|TH_ACK)) == TH_ACK &&\n#endif\n\t    (!opti.ts_present || TSTMP_GEQ(opti.ts_val, tp->ts_recent)) &&\n\t    th->th_seq == tp->rcv_nxt &&\n\t    tiwin && tiwin == tp->snd_wnd &&\n\t    tp->snd_nxt == tp->snd_max) {\n\n\t\t/*\n\t\t * If last ACK falls within this segment's sequence numbers,\n\t\t *  record the timestamp.\n\t\t * Fix from Braden, see Stevens p. 870\n\t\t */\n\t\tif (opti.ts_present && SEQ_LEQ(th->th_seq, tp->last_ack_sent)) {\n\t\t\ttp->ts_recent_age = tcp_now;\n\t\t\ttp->ts_recent = opti.ts_val;\n\t\t}\n\n\t\tif (tlen == 0) {\n\t\t\tif (SEQ_GT(th->th_ack, tp->snd_una) &&\n\t\t\t    SEQ_LEQ(th->th_ack, tp->snd_max) &&\n\t\t\t    tp->snd_cwnd >= tp->snd_wnd &&\n\t\t\t    tp->t_dupacks == 0) {\n\t\t\t\t/*\n\t\t\t\t * this is a pure ack for outstanding data.\n\t\t\t\t */\n\t\t\t\ttcpstat_inc(tcps_predack);\n\t\t\t\tif (opti.ts_present && opti.ts_ecr)\n\t\t\t\t\ttcp_xmit_timer(tp, tcp_now - opti.ts_ecr);\n\t\t\t\telse if (tp->t_rtttime &&\n\t\t\t\t    SEQ_GT(th->th_ack, tp->t_rtseq))\n\t\t\t\t\ttcp_xmit_timer(tp,\n\t\t\t\t\t    tcp_now - tp->t_rtttime);\n\t\t\t\tacked = th->th_ack - tp->snd_una;\n\t\t\t\ttcpstat_pkt(tcps_rcvackpack, tcps_rcvackbyte,\n\t\t\t\t    acked);\n\t\t\t\tND6_HINT(tp);\n\t\t\t\tsbdrop(so, &so->so_snd, acked);\n\n\t\t\t\t/*\n\t\t\t\t * If we had a pending ICMP message that\n\t\t\t\t * refers to data that have just been\n\t\t\t\t * acknowledged, disregard the recorded ICMP\n\t\t\t\t * message.\n\t\t\t\t */\n\t\t\t\tif ((tp->t_flags & TF_PMTUD_PEND) &&\n\t\t\t\t    SEQ_GT(th->th_ack, tp->t_pmtud_th_seq))\n\t\t\t\t\ttp->t_flags &= ~TF_PMTUD_PEND;\n\n\t\t\t\t/*\n\t\t\t\t * Keep track of the largest chunk of data\n\t\t\t\t * acknowledged since last PMTU update\n\t\t\t\t */\n\t\t\t\tif (tp->t_pmtud_mss_acked < acked)\n\t\t\t\t\ttp->t_pmtud_mss_acked = acked;\n\n\t\t\t\ttp->snd_una = th->th_ack;\n\t\t\t\t/*\n\t\t\t\t * We want snd_last to track snd_una so\n\t\t\t\t * as to avoid sequence wraparound problems\n\t\t\t\t * for very large transfers.\n\t\t\t\t */\n#ifdef TCP_ECN\n\t\t\t\tif (SEQ_GT(tp->snd_una, tp->snd_last))\n#endif\n\t\t\t\ttp->snd_last = tp->snd_una;\n\t\t\t\tm_freem(m);\n\n\t\t\t\t/*\n\t\t\t\t * If all outstanding data are acked, stop\n\t\t\t\t * retransmit timer, otherwise restart timer\n\t\t\t\t * using current (possibly backed-off) value.\n\t\t\t\t * If process is waiting for space,\n\t\t\t\t * wakeup/selwakeup/signal.  If data\n\t\t\t\t * are ready to send, let tcp_output\n\t\t\t\t * decide between more output or persist.\n\t\t\t\t */\n\t\t\t\tif (tp->snd_una == tp->snd_max)\n\t\t\t\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\t\t\telse if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)\n\t\t\t\t\tTCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);\n\n\t\t\t\ttcp_update_sndspace(tp);\n\t\t\t\tif (sb_notify(so, &so->so_snd)) {\n\t\t\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\t\t\tsowwakeup(so);\n\t\t\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\t\t}\n\t\t\t\tif (so->so_snd.sb_cc ||\n\t\t\t\t    tp->t_flags & TF_NEEDOUTPUT)\n\t\t\t\t\t(void) tcp_output(tp);\n\t\t\t\treturn IPPROTO_DONE;\n\t\t\t}\n\t\t} else if (th->th_ack == tp->snd_una &&\n\t\t    TAILQ_EMPTY(&tp->t_segq) &&\n\t\t    tlen <= sbspace(so, &so->so_rcv)) {\n\t\t\t/*\n\t\t\t * This is a pure, in-sequence data packet\n\t\t\t * with nothing on the reassembly queue and\n\t\t\t * we have enough buffer space to take it.\n\t\t\t */\n\t\t\t/* Clean receiver SACK report if present */\n\t\t\tif (tp->sack_enable && tp->rcv_numsacks)\n\t\t\t\ttcp_clean_sackreport(tp);\n\t\t\ttcpstat_inc(tcps_preddat);\n\t\t\ttp->rcv_nxt += tlen;\n\t\t\ttcpstat_pkt(tcps_rcvpack, tcps_rcvbyte, tlen);\n\t\t\tND6_HINT(tp);\n\n\t\t\tTCP_SETUP_ACK(tp, tiflags, m);\n\t\t\t/*\n\t\t\t * Drop TCP, IP headers and TCP options then add data\n\t\t\t * to socket buffer.\n\t\t\t */\n\t\t\tif (so->so_state & SS_CANTRCVMORE)\n\t\t\t\tm_freem(m);\n\t\t\telse {\n\t\t\t\tif (opti.ts_present && opti.ts_ecr) {\n\t\t\t\t\tif (tp->rfbuf_ts < opti.ts_ecr &&\n\t\t\t\t\t    opti.ts_ecr - tp->rfbuf_ts < hz) {\n\t\t\t\t\t\ttcp_update_rcvspace(tp);\n\t\t\t\t\t\t/* Start over with next RTT. */\n\t\t\t\t\t\ttp->rfbuf_cnt = 0;\n\t\t\t\t\t\ttp->rfbuf_ts = 0;\n\t\t\t\t\t} else\n\t\t\t\t\t\ttp->rfbuf_cnt += tlen;\n\t\t\t\t}\n\t\t\t\tm_adj(m, iphlen + off);\n\t\t\t\tsbappendstream(so, &so->so_rcv, m);\n\t\t\t}\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsorwakeup(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\tif (tp->t_flags & (TF_ACKNOW|TF_NEEDOUTPUT))\n\t\t\t\t(void) tcp_output(tp);\n\t\t\treturn IPPROTO_DONE;\n\t\t}\n\t}\n\n\t/*\n\t * Compute mbuf offset to TCP data segment.\n\t */\n\thdroptlen = iphlen + off;\n\n\t/*\n\t * Calculate amount of space in receive window,\n\t * and then do TCP input processing.\n\t * Receive window is amount of space in rcv queue,\n\t * but not less than advertised window.\n\t */\n\t{ int win;\n\n\twin = sbspace(so, &so->so_rcv);\n\tif (win < 0)\n\t\twin = 0;\n\ttp->rcv_wnd = imax(win, (int)(tp->rcv_adv - tp->rcv_nxt));\n\t}\n\n\t/* Reset receive buffer auto scaling when not in bulk receive mode. */\n\ttp->rfbuf_cnt = 0;\n\ttp->rfbuf_ts = 0;\n\n\tswitch (tp->t_state) {\n\n\t/*\n\t * If the state is SYN_RECEIVED:\n\t * \tif seg contains SYN/ACK, send an RST.\n\t *\tif seg contains an ACK, but not for our SYN/ACK, send an RST\n\t */\n\n\tcase TCPS_SYN_RECEIVED:\n\t\tif (tiflags & TH_ACK) {\n\t\t\tif (tiflags & TH_SYN) {\n\t\t\t\ttcpstat_inc(tcps_badsyn);\n\t\t\t\tgoto dropwithreset;\n\t\t\t}\n\t\t\tif (SEQ_LEQ(th->th_ack, tp->snd_una) ||\n\t\t\t    SEQ_GT(th->th_ack, tp->snd_max))\n\t\t\t\tgoto dropwithreset;\n\t\t}\n\t\tbreak;\n\n\t/*\n\t * If the state is SYN_SENT:\n\t *\tif seg contains an ACK, but not for our SYN, drop the input.\n\t *\tif seg contains a RST, then drop the connection.\n\t *\tif seg does not contain SYN, then drop it.\n\t * Otherwise this is an acceptable SYN segment\n\t *\tinitialize tp->rcv_nxt and tp->irs\n\t *\tif seg contains ack then advance tp->snd_una\n\t *\tif SYN has been acked change to ESTABLISHED else SYN_RCVD state\n\t *\tarrange for segment to be acked (eventually)\n\t *\tcontinue processing rest of data/controls, beginning with URG\n\t */\n\tcase TCPS_SYN_SENT:\n\t\tif ((tiflags & TH_ACK) &&\n\t\t    (SEQ_LEQ(th->th_ack, tp->iss) ||\n\t\t     SEQ_GT(th->th_ack, tp->snd_max)))\n\t\t\tgoto dropwithreset;\n\t\tif (tiflags & TH_RST) {\n#ifdef TCP_ECN\n\t\t\t/* if ECN is enabled, fall back to non-ecn at rexmit */\n\t\t\tif (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))\n\t\t\t\tgoto drop;\n#endif\n\t\t\tif (tiflags & TH_ACK)\n\t\t\t\ttp = tcp_drop(tp, ECONNREFUSED);\n\t\t\tgoto drop;\n\t\t}\n\t\tif ((tiflags & TH_SYN) == 0)\n\t\t\tgoto drop;\n\t\tif (tiflags & TH_ACK) {\n\t\t\ttp->snd_una = th->th_ack;\n\t\t\tif (SEQ_LT(tp->snd_nxt, tp->snd_una))\n\t\t\t\ttp->snd_nxt = tp->snd_una;\n\t\t}\n\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\ttp->irs = th->th_seq;\n\t\ttcp_mss(tp, opti.maxseg);\n\t\t/* Reset initial window to 1 segment for retransmit */\n\t\tif (tp->t_rxtshift > 0)\n\t\t\ttp->snd_cwnd = tp->t_maxseg;\n\t\ttcp_rcvseqinit(tp);\n\t\ttp->t_flags |= TF_ACKNOW;\n                /*\n                 * If we've sent a SACK_PERMITTED option, and the peer\n                 * also replied with one, then TF_SACK_PERMIT should have\n                 * been set in tcp_dooptions().  If it was not, disable SACKs.\n                 */\n\t\tif (tp->sack_enable)\n\t\t\ttp->sack_enable = tp->t_flags & TF_SACK_PERMIT;\n#ifdef TCP_ECN\n\t\t/*\n\t\t * if ECE is set but CWR is not set for SYN-ACK, or\n\t\t * both ECE and CWR are set for simultaneous open,\n\t\t * peer is ECN capable.\n\t\t */\n\t\tif (tcp_do_ecn) {\n\t\t\tswitch (tiflags & (TH_ACK|TH_ECE|TH_CWR)) {\n\t\t\tcase TH_ACK|TH_ECE:\n\t\t\tcase TH_ECE|TH_CWR:\n\t\t\t\ttp->t_flags |= TF_ECN_PERMIT;\n\t\t\t\ttiflags &= ~(TH_ECE|TH_CWR);\n\t\t\t\ttcpstat_inc(tcps_ecn_accepts);\n\t\t\t}\n\t\t}\n#endif\n\n\t\tif (tiflags & TH_ACK && SEQ_GT(tp->snd_una, tp->iss)) {\n\t\t\ttcpstat_inc(tcps_connects);\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsoisconnected(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\ttp->t_state = TCPS_ESTABLISHED;\n\t\t\tTCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);\n\t\t\t/* Do window scaling on this connection? */\n\t\t\tif ((tp->t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==\n\t\t\t\t(TF_RCVD_SCALE|TF_REQ_SCALE)) {\n\t\t\t\ttp->snd_scale = tp->requested_s_scale;\n\t\t\t\ttp->rcv_scale = tp->request_r_scale;\n\t\t\t}\n\t\t\ttcp_flush_queue(tp);\n\n\t\t\t/*\n\t\t\t * if we didn't have to retransmit the SYN,\n\t\t\t * use its rtt as our initial srtt & rtt var.\n\t\t\t */\n\t\t\tif (tp->t_rtttime)\n\t\t\t\ttcp_xmit_timer(tp, tcp_now - tp->t_rtttime);\n\t\t\t/*\n\t\t\t * Since new data was acked (the SYN), open the\n\t\t\t * congestion window by one MSS.  We do this\n\t\t\t * here, because we won't go through the normal\n\t\t\t * ACK processing below.  And since this is the\n\t\t\t * start of the connection, we know we are in\n\t\t\t * the exponential phase of slow-start.\n\t\t\t */\n\t\t\ttp->snd_cwnd += tp->t_maxseg;\n\t\t} else\n\t\t\ttp->t_state = TCPS_SYN_RECEIVED;\n\n#if 0\ntrimthenstep6:\n#endif\n\t\t/*\n\t\t * Advance th->th_seq to correspond to first data byte.\n\t\t * If data, trim to stay within window,\n\t\t * dropping FIN if necessary.\n\t\t */\n\t\tth->th_seq++;\n\t\tif (tlen > tp->rcv_wnd) {\n\t\t\ttodrop = tlen - tp->rcv_wnd;\n\t\t\tm_adj(m, -todrop);\n\t\t\ttlen = tp->rcv_wnd;\n\t\t\ttiflags &= ~TH_FIN;\n\t\t\ttcpstat_pkt(tcps_rcvpackafterwin, tcps_rcvbyteafterwin,\n\t\t\t    todrop);\n\t\t}\n\t\ttp->snd_wl1 = th->th_seq - 1;\n\t\ttp->rcv_up = th->th_seq;\n\t\tgoto step6;\n\t/*\n\t * If a new connection request is received while in TIME_WAIT,\n\t * drop the old connection and start over if the if the\n\t * timestamp or the sequence numbers are above the previous\n\t * ones.\n\t */\n\tcase TCPS_TIME_WAIT:\n\t\tif (((tiflags & (TH_SYN|TH_ACK)) == TH_SYN) &&\n\t\t    ((opti.ts_present &&\n\t\t    TSTMP_LT(tp->ts_recent, opti.ts_val)) ||\n\t\t    SEQ_GT(th->th_seq, tp->rcv_nxt))) {\n#if NPF > 0\n\t\t\t/*\n\t\t\t * The socket will be recreated but the new state\n\t\t\t * has already been linked to the socket.  Remove the\n\t\t\t * link between old socket and new state.\n\t\t\t */\n\t\t\tpf_inp_unlink(inp);\n#endif\n\t\t\t/*\n\t\t\t* Advance the iss by at least 32768, but\n\t\t\t* clear the msb in order to make sure\n\t\t\t* that SEG_LT(snd_nxt, iss).\n\t\t\t*/\n\t\t\tiss = tp->snd_nxt +\n\t\t\t    ((arc4random() & 0x7fffffff) | 0x8000);\n\t\t\treuse = &iss;\n\t\t\ttp = tcp_close(tp);\n\t\t\tinp = NULL;\n\t\t\tgoto findpcb;\n\t\t}\n\t}\n\n\t/*\n\t * States other than LISTEN or SYN_SENT.\n\t * First check timestamp, if present.\n\t * Then check that at least some bytes of segment are within\n\t * receive window.  If segment begins before rcv_nxt,\n\t * drop leading data (and SYN); if nothing left, just ack.\n\t *\n\t * RFC 1323 PAWS: If we have a timestamp reply on this segment\n\t * and it's less than opti.ts_recent, drop it.\n\t */\n\tif (opti.ts_present && (tiflags & TH_RST) == 0 && tp->ts_recent &&\n\t    TSTMP_LT(opti.ts_val, tp->ts_recent)) {\n\n\t\t/* Check to see if ts_recent is over 24 days old.  */\n\t\tif ((int)(tcp_now - tp->ts_recent_age) > TCP_PAWS_IDLE) {\n\t\t\t/*\n\t\t\t * Invalidate ts_recent.  If this segment updates\n\t\t\t * ts_recent, the age will be reset later and ts_recent\n\t\t\t * will get a valid value.  If it does not, setting\n\t\t\t * ts_recent to zero will at least satisfy the\n\t\t\t * requirement that zero be placed in the timestamp\n\t\t\t * echo reply when ts_recent isn't valid.  The\n\t\t\t * age isn't reset until we get a valid ts_recent\n\t\t\t * because we don't want out-of-order segments to be\n\t\t\t * dropped when ts_recent is old.\n\t\t\t */\n\t\t\ttp->ts_recent = 0;\n\t\t} else {\n\t\t\ttcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte, tlen);\n\t\t\ttcpstat_inc(tcps_pawsdrop);\n\t\t\tif (tlen)\n\t\t\t\tgoto dropafterack;\n\t\t\tgoto drop;\n\t\t}\n\t}\n\n\ttodrop = tp->rcv_nxt - th->th_seq;\n\tif (todrop > 0) {\n\t\tif (tiflags & TH_SYN) {\n\t\t\ttiflags &= ~TH_SYN;\n\t\t\tth->th_seq++;\n\t\t\tif (th->th_urp > 1)\n\t\t\t\tth->th_urp--;\n\t\t\telse\n\t\t\t\ttiflags &= ~TH_URG;\n\t\t\ttodrop--;\n\t\t}\n\t\tif (todrop > tlen ||\n\t\t    (todrop == tlen && (tiflags & TH_FIN) == 0)) {\n\t\t\t/*\n\t\t\t * Any valid FIN must be to the left of the\n\t\t\t * window.  At this point, FIN must be a\n\t\t\t * duplicate or out-of-sequence, so drop it.\n\t\t\t */\n\t\t\ttiflags &= ~TH_FIN;\n\t\t\t/*\n\t\t\t * Send ACK to resynchronize, and drop any data,\n\t\t\t * but keep on processing for RST or ACK.\n\t\t\t */\n\t\t\ttp->t_flags |= TF_ACKNOW;\n\t\t\ttodrop = tlen;\n\t\t\ttcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte, todrop);\n\t\t} else {\n\t\t\ttcpstat_pkt(tcps_rcvpartduppack, tcps_rcvpartdupbyte,\n\t\t\t    todrop);\n\t\t}\n\t\thdroptlen += todrop;\t/* drop from head afterwards */\n\t\tth->th_seq += todrop;\n\t\ttlen -= todrop;\n\t\tif (th->th_urp > todrop)\n\t\t\tth->th_urp -= todrop;\n\t\telse {\n\t\t\ttiflags &= ~TH_URG;\n\t\t\tth->th_urp = 0;\n\t\t}\n\t}\n\n\t/*\n\t * If new data are received on a connection after the\n\t * user processes are gone, then RST the other end.\n\t */\n\tif ((so->so_state & SS_NOFDREF) &&\n\t    tp->t_state > TCPS_CLOSE_WAIT && tlen) {\n\t\ttp = tcp_close(tp);\n\t\ttcpstat_inc(tcps_rcvafterclose);\n\t\tgoto dropwithreset;\n\t}\n\n\t/*\n\t * If segment ends after window, drop trailing data\n\t * (and PUSH and FIN); if nothing left, just ACK.\n\t */\n\ttodrop = (th->th_seq + tlen) - (tp->rcv_nxt+tp->rcv_wnd);\n\tif (todrop > 0) {\n\t\ttcpstat_inc(tcps_rcvpackafterwin);\n\t\tif (todrop >= tlen) {\n\t\t\ttcpstat_add(tcps_rcvbyteafterwin, tlen);\n\t\t\t/*\n\t\t\t * If window is closed can only take segments at\n\t\t\t * window edge, and have to drop data and PUSH from\n\t\t\t * incoming segments.  Continue processing, but\n\t\t\t * remember to ack.  Otherwise, drop segment\n\t\t\t * and ack.\n\t\t\t */\n\t\t\tif (tp->rcv_wnd == 0 && th->th_seq == tp->rcv_nxt) {\n\t\t\t\ttp->t_flags |= TF_ACKNOW;\n\t\t\t\ttcpstat_inc(tcps_rcvwinprobe);\n\t\t\t} else\n\t\t\t\tgoto dropafterack;\n\t\t} else\n\t\t\ttcpstat_add(tcps_rcvbyteafterwin, todrop);\n\t\tm_adj(m, -todrop);\n\t\ttlen -= todrop;\n\t\ttiflags &= ~(TH_PUSH|TH_FIN);\n\t}\n\n\t/*\n\t * If last ACK falls within this segment's sequence numbers,\n\t * record its timestamp if it's more recent.\n\t * NOTE that the test is modified according to the latest\n\t * proposal of the tcplw@cray.com list (Braden 1993/04/26).\n\t */\n\tif (opti.ts_present && TSTMP_GEQ(opti.ts_val, tp->ts_recent) &&\n\t    SEQ_LEQ(th->th_seq, tp->last_ack_sent)) {\n\t\ttp->ts_recent_age = tcp_now;\n\t\ttp->ts_recent = opti.ts_val;\n\t}\n\n\t/*\n\t * If the RST bit is set examine the state:\n\t *    SYN_RECEIVED STATE:\n\t *\tIf passive open, return to LISTEN state.\n\t *\tIf active open, inform user that connection was refused.\n\t *    ESTABLISHED, FIN_WAIT_1, FIN_WAIT2, CLOSE_WAIT STATES:\n\t *\tInform user that connection was reset, and close tcb.\n\t *    CLOSING, LAST_ACK, TIME_WAIT STATES\n\t *\tClose the tcb.\n\t */\n\tif (tiflags & TH_RST) {\n\t\tif (th->th_seq != tp->last_ack_sent &&\n\t\t    th->th_seq != tp->rcv_nxt &&\n\t\t    th->th_seq != (tp->rcv_nxt + 1))\n\t\t\tgoto drop;\n\n\t\tswitch (tp->t_state) {\n\t\tcase TCPS_SYN_RECEIVED:\n#ifdef TCP_ECN\n\t\t\t/* if ECN is enabled, fall back to non-ecn at rexmit */\n\t\t\tif (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))\n\t\t\t\tgoto drop;\n#endif\n\t\t\tso->so_error = ECONNREFUSED;\n\t\t\tgoto close;\n\n\t\tcase TCPS_ESTABLISHED:\n\t\tcase TCPS_FIN_WAIT_1:\n\t\tcase TCPS_FIN_WAIT_2:\n\t\tcase TCPS_CLOSE_WAIT:\n\t\t\tso->so_error = ECONNRESET;\n\t\tclose:\n\t\t\ttp->t_state = TCPS_CLOSED;\n\t\t\ttcpstat_inc(tcps_drops);\n\t\t\ttp = tcp_close(tp);\n\t\t\tgoto drop;\n\t\tcase TCPS_CLOSING:\n\t\tcase TCPS_LAST_ACK:\n\t\tcase TCPS_TIME_WAIT:\n\t\t\ttp = tcp_close(tp);\n\t\t\tgoto drop;\n\t\t}\n\t}\n\n\t/*\n\t * If a SYN is in the window, then this is an\n\t * error and we ACK and drop the packet.\n\t */\n\tif (tiflags & TH_SYN)\n\t\tgoto dropafterack_ratelim;\n\n\t/*\n\t * If the ACK bit is off we drop the segment and return.\n\t */\n\tif ((tiflags & TH_ACK) == 0) {\n\t\tif (tp->t_flags & TF_ACKNOW)\n\t\t\tgoto dropafterack;\n\t\telse\n\t\t\tgoto drop;\n\t}\n\n\t/*\n\t * Ack processing.\n\t */\n\tswitch (tp->t_state) {\n\n\t/*\n\t * In SYN_RECEIVED state, the ack ACKs our SYN, so enter\n\t * ESTABLISHED state and continue processing.\n\t * The ACK was checked above.\n\t */\n\tcase TCPS_SYN_RECEIVED:\n\t\ttcpstat_inc(tcps_connects);\n\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\tsoisconnected(so);\n\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\ttp->t_state = TCPS_ESTABLISHED;\n\t\tTCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);\n\t\t/* Do window scaling? */\n\t\tif ((tp->t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==\n\t\t\t(TF_RCVD_SCALE|TF_REQ_SCALE)) {\n\t\t\ttp->snd_scale = tp->requested_s_scale;\n\t\t\ttp->rcv_scale = tp->request_r_scale;\n\t\t\ttiwin = th->th_win << tp->snd_scale;\n\t\t}\n\t\ttcp_flush_queue(tp);\n\t\ttp->snd_wl1 = th->th_seq - 1;\n\t\t/* fall into ... */\n\n\t/*\n\t * In ESTABLISHED state: drop duplicate ACKs; ACK out of range\n\t * ACKs.  If the ack is in the range\n\t *\ttp->snd_una < th->th_ack <= tp->snd_max\n\t * then advance tp->snd_una to th->th_ack and drop\n\t * data from the retransmission queue.  If this ACK reflects\n\t * more up to date window information we update our window information.\n\t */\n\tcase TCPS_ESTABLISHED:\n\tcase TCPS_FIN_WAIT_1:\n\tcase TCPS_FIN_WAIT_2:\n\tcase TCPS_CLOSE_WAIT:\n\tcase TCPS_CLOSING:\n\tcase TCPS_LAST_ACK:\n\tcase TCPS_TIME_WAIT:\n#ifdef TCP_ECN\n\t\t/*\n\t\t * if we receive ECE and are not already in recovery phase,\n\t\t * reduce cwnd by half but don't slow-start.\n\t\t * advance snd_last to snd_max not to reduce cwnd again\n\t\t * until all outstanding packets are acked.\n\t\t */\n\t\tif (tcp_do_ecn && (tiflags & TH_ECE)) {\n\t\t\tif ((tp->t_flags & TF_ECN_PERMIT) &&\n\t\t\t    SEQ_GEQ(tp->snd_una, tp->snd_last)) {\n\t\t\t\tu_int win;\n\n\t\t\t\twin = min(tp->snd_wnd, tp->snd_cwnd) / tp->t_maxseg;\n\t\t\t\tif (win > 1) {\n\t\t\t\t\ttp->snd_ssthresh = win / 2 * tp->t_maxseg;\n\t\t\t\t\ttp->snd_cwnd = tp->snd_ssthresh;\n\t\t\t\t\ttp->snd_last = tp->snd_max;\n\t\t\t\t\ttp->t_flags |= TF_SEND_CWR;\n\t\t\t\t\ttcpstat_inc(tcps_cwr_ecn);\n\t\t\t\t}\n\t\t\t}\n\t\t\ttcpstat_inc(tcps_ecn_rcvece);\n\t\t}\n\t\t/*\n\t\t * if we receive CWR, we know that the peer has reduced\n\t\t * its congestion window.  stop sending ecn-echo.\n\t\t */\n\t\tif ((tiflags & TH_CWR)) {\n\t\t\ttp->t_flags &= ~TF_RCVD_CE;\n\t\t\ttcpstat_inc(tcps_ecn_rcvcwr);\n\t\t}\n#endif /* TCP_ECN */\n\n\t\tif (SEQ_LEQ(th->th_ack, tp->snd_una)) {\n\t\t\t/*\n\t\t\t * Duplicate/old ACK processing.\n\t\t\t * Increments t_dupacks:\n\t\t\t *\tPure duplicate (same seq/ack/window, no data)\n\t\t\t * Doesn't affect t_dupacks:\n\t\t\t *\tData packets.\n\t\t\t *\tNormal window updates (window opens)\n\t\t\t * Resets t_dupacks:\n\t\t\t *\tNew data ACKed.\n\t\t\t *\tWindow shrinks\n\t\t\t *\tOld ACK\n\t\t\t */\n\t\t\tif (tlen) {\n\t\t\t\t/* Drop very old ACKs unless th_seq matches */\n\t\t\t\tif (th->th_seq != tp->rcv_nxt &&\n\t\t\t\t   SEQ_LT(th->th_ack,\n\t\t\t\t   tp->snd_una - tp->max_sndwnd)) {\n\t\t\t\t\ttcpstat_inc(tcps_rcvacktooold);\n\t\t\t\t\tgoto drop;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/*\n\t\t\t * If we get an old ACK, there is probably packet\n\t\t\t * reordering going on.  Be conservative and reset\n\t\t\t * t_dupacks so that we are less aggressive in\n\t\t\t * doing a fast retransmit.\n\t\t\t */\n\t\t\tif (th->th_ack != tp->snd_una) {\n\t\t\t\ttp->t_dupacks = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (tiwin == tp->snd_wnd) {\n\t\t\t\ttcpstat_inc(tcps_rcvdupack);\n\t\t\t\t/*\n\t\t\t\t * If we have outstanding data (other than\n\t\t\t\t * a window probe), this is a completely\n\t\t\t\t * duplicate ack (ie, window info didn't\n\t\t\t\t * change), the ack is the biggest we've\n\t\t\t\t * seen and we've seen exactly our rexmt\n\t\t\t\t * threshold of them, assume a packet\n\t\t\t\t * has been dropped and retransmit it.\n\t\t\t\t * Kludge snd_nxt & the congestion\n\t\t\t\t * window so we send only this one\n\t\t\t\t * packet.\n\t\t\t\t *\n\t\t\t\t * We know we're losing at the current\n\t\t\t\t * window size so do congestion avoidance\n\t\t\t\t * (set ssthresh to half the current window\n\t\t\t\t * and pull our congestion window back to\n\t\t\t\t * the new ssthresh).\n\t\t\t\t *\n\t\t\t\t * Dup acks mean that packets have left the\n\t\t\t\t * network (they're now cached at the receiver)\n\t\t\t\t * so bump cwnd by the amount in the receiver\n\t\t\t\t * to keep a constant cwnd packets in the\n\t\t\t\t * network.\n\t\t\t\t */\n\t\t\t\tif (TCP_TIMER_ISARMED(tp, TCPT_REXMT) == 0)\n\t\t\t\t\ttp->t_dupacks = 0;\n\t\t\t\telse if (++tp->t_dupacks == tcprexmtthresh) {\n\t\t\t\t\ttcp_seq onxt = tp->snd_nxt;\n\t\t\t\t\tu_long win =\n\t\t\t\t\t    ulmin(tp->snd_wnd, tp->snd_cwnd) /\n\t\t\t\t\t\t2 / tp->t_maxseg;\n\n\t\t\t\t\tif (SEQ_LT(th->th_ack, tp->snd_last)){\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * False fast retx after\n\t\t\t\t\t\t * timeout.  Do not cut window.\n\t\t\t\t\t\t */\n\t\t\t\t\t\ttp->t_dupacks = 0;\n\t\t\t\t\t\tgoto drop;\n\t\t\t\t\t}\n\t\t\t\t\tif (win < 2)\n\t\t\t\t\t\twin = 2;\n\t\t\t\t\ttp->snd_ssthresh = win * tp->t_maxseg;\n\t\t\t\t\ttp->snd_last = tp->snd_max;\n\t\t\t\t\tif (tp->sack_enable) {\n\t\t\t\t\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\t\t\t\t\ttp->t_rtttime = 0;\n#ifdef TCP_ECN\n\t\t\t\t\t\ttp->t_flags |= TF_SEND_CWR;\n#endif\n\t\t\t\t\t\ttcpstat_inc(tcps_cwr_frecovery);\n\t\t\t\t\t\ttcpstat_inc(tcps_sack_recovery_episode);\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * tcp_output() will send\n\t\t\t\t\t\t * oldest SACK-eligible rtx.\n\t\t\t\t\t\t */\n\t\t\t\t\t\t(void) tcp_output(tp);\n\t\t\t\t\t\ttp->snd_cwnd = tp->snd_ssthresh+\n\t\t\t\t\t           tp->t_maxseg * tp->t_dupacks;\n\t\t\t\t\t\tgoto drop;\n\t\t\t\t\t}\n\t\t\t\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\t\t\t\ttp->t_rtttime = 0;\n\t\t\t\t\ttp->snd_nxt = th->th_ack;\n\t\t\t\t\ttp->snd_cwnd = tp->t_maxseg;\n#ifdef TCP_ECN\n\t\t\t\t\ttp->t_flags |= TF_SEND_CWR;\n#endif\n\t\t\t\t\ttcpstat_inc(tcps_cwr_frecovery);\n\t\t\t\t\ttcpstat_inc(tcps_sndrexmitfast);\n\t\t\t\t\t(void) tcp_output(tp);\n\n\t\t\t\t\ttp->snd_cwnd = tp->snd_ssthresh +\n\t\t\t\t\t    tp->t_maxseg * tp->t_dupacks;\n\t\t\t\t\tif (SEQ_GT(onxt, tp->snd_nxt))\n\t\t\t\t\t\ttp->snd_nxt = onxt;\n\t\t\t\t\tgoto drop;\n\t\t\t\t} else if (tp->t_dupacks > tcprexmtthresh) {\n\t\t\t\t\ttp->snd_cwnd += tp->t_maxseg;\n\t\t\t\t\t(void) tcp_output(tp);\n\t\t\t\t\tgoto drop;\n\t\t\t\t}\n\t\t\t} else if (tiwin < tp->snd_wnd) {\n\t\t\t\t/*\n\t\t\t\t * The window was retracted!  Previous dup\n\t\t\t\t * ACKs may have been due to packets arriving\n\t\t\t\t * after the shrunken window, not a missing\n\t\t\t\t * packet, so play it safe and reset t_dupacks\n\t\t\t\t */\n\t\t\t\ttp->t_dupacks = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * If the congestion window was inflated to account\n\t\t * for the other side's cached packets, retract it.\n\t\t */\n\t\tif (tp->t_dupacks >= tcprexmtthresh) {\n\t\t\t/* Check for a partial ACK */\n\t\t\tif (SEQ_LT(th->th_ack, tp->snd_last)) {\n\t\t\t\tif (tp->sack_enable)\n\t\t\t\t\ttcp_sack_partialack(tp, th);\n\t\t\t\telse\n\t\t\t\t\ttcp_newreno_partialack(tp, th);\n\t\t\t} else {\n\t\t\t\t/* Out of fast recovery */\n\t\t\t\ttp->snd_cwnd = tp->snd_ssthresh;\n\t\t\t\tif (tcp_seq_subtract(tp->snd_max, th->th_ack) <\n\t\t\t\t    tp->snd_ssthresh)\n\t\t\t\t\ttp->snd_cwnd =\n\t\t\t\t\t    tcp_seq_subtract(tp->snd_max,\n\t\t\t\t\t    th->th_ack);\n\t\t\t\ttp->t_dupacks = 0;\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * Reset the duplicate ACK counter if we\n\t\t\t * were not in fast recovery.\n\t\t\t */\n\t\t\ttp->t_dupacks = 0;\n\t\t}\n\t\tif (SEQ_GT(th->th_ack, tp->snd_max)) {\n\t\t\ttcpstat_inc(tcps_rcvacktoomuch);\n\t\t\tgoto dropafterack_ratelim;\n\t\t}\n\t\tacked = th->th_ack - tp->snd_una;\n\t\ttcpstat_pkt(tcps_rcvackpack, tcps_rcvackbyte, acked);\n\n\t\t/*\n\t\t * If we have a timestamp reply, update smoothed\n\t\t * round trip time.  If no timestamp is present but\n\t\t * transmit timer is running and timed sequence\n\t\t * number was acked, update smoothed round trip time.\n\t\t * Since we now have an rtt measurement, cancel the\n\t\t * timer backoff (cf., Phil Karn's retransmit alg.).\n\t\t * Recompute the initial retransmit timer.\n\t\t */\n\t\tif (opti.ts_present && opti.ts_ecr)\n\t\t\ttcp_xmit_timer(tp, tcp_now - opti.ts_ecr);\n\t\telse if (tp->t_rtttime && SEQ_GT(th->th_ack, tp->t_rtseq))\n\t\t\ttcp_xmit_timer(tp, tcp_now - tp->t_rtttime);\n\n\t\t/*\n\t\t * If all outstanding data is acked, stop retransmit\n\t\t * timer and remember to restart (more output or persist).\n\t\t * If there is more data to be acked, restart retransmit\n\t\t * timer, using current (possibly backed-off) value.\n\t\t */\n\t\tif (th->th_ack == tp->snd_max) {\n\t\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\t\ttp->t_flags |= TF_NEEDOUTPUT;\n\t\t} else if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)\n\t\t\tTCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);\n\t\t/*\n\t\t * When new data is acked, open the congestion window.\n\t\t * If the window gives us less than ssthresh packets\n\t\t * in flight, open exponentially (maxseg per packet).\n\t\t * Otherwise open linearly: maxseg per window\n\t\t * (maxseg^2 / cwnd per packet).\n\t\t */\n\t\t{\n\t\tu_int cw = tp->snd_cwnd;\n\t\tu_int incr = tp->t_maxseg;\n\n\t\tif (cw > tp->snd_ssthresh)\n\t\t\tincr = incr * incr / cw;\n\t\tif (tp->t_dupacks < tcprexmtthresh)\n\t\t\ttp->snd_cwnd = ulmin(cw + incr,\n\t\t\t    TCP_MAXWIN << tp->snd_scale);\n\t\t}\n\t\tND6_HINT(tp);\n\t\tif (acked > so->so_snd.sb_cc) {\n\t\t\ttp->snd_wnd -= so->so_snd.sb_cc;\n\t\t\tsbdrop(so, &so->so_snd, (int)so->so_snd.sb_cc);\n\t\t\tourfinisacked = 1;\n\t\t} else {\n\t\t\tsbdrop(so, &so->so_snd, acked);\n\t\t\ttp->snd_wnd -= acked;\n\t\t\tourfinisacked = 0;\n\t\t}\n\n\t\ttcp_update_sndspace(tp);\n\t\tif (sb_notify(so, &so->so_snd)) {\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsowwakeup(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t}\n\n\t\t/*\n\t\t * If we had a pending ICMP message that referred to data\n\t\t * that have just been acknowledged, disregard the recorded\n\t\t * ICMP message.\n\t\t */\n\t\tif ((tp->t_flags & TF_PMTUD_PEND) &&\n\t\t    SEQ_GT(th->th_ack, tp->t_pmtud_th_seq))\n\t\t\ttp->t_flags &= ~TF_PMTUD_PEND;\n\n\t\t/*\n\t\t * Keep track of the largest chunk of data acknowledged\n\t\t * since last PMTU update\n\t\t */\n\t\tif (tp->t_pmtud_mss_acked < acked)\n\t\t\ttp->t_pmtud_mss_acked = acked;\n\n\t\ttp->snd_una = th->th_ack;\n#ifdef TCP_ECN\n\t\t/* sync snd_last with snd_una */\n\t\tif (SEQ_GT(tp->snd_una, tp->snd_last))\n\t\t\ttp->snd_last = tp->snd_una;\n#endif\n\t\tif (SEQ_LT(tp->snd_nxt, tp->snd_una))\n\t\t\ttp->snd_nxt = tp->snd_una;\n\n\t\tswitch (tp->t_state) {\n\n\t\t/*\n\t\t * In FIN_WAIT_1 STATE in addition to the processing\n\t\t * for the ESTABLISHED state if our FIN is now acknowledged\n\t\t * then enter FIN_WAIT_2.\n\t\t */\n\t\tcase TCPS_FIN_WAIT_1:\n\t\t\tif (ourfinisacked) {\n\t\t\t\t/*\n\t\t\t\t * If we can't receive any more\n\t\t\t\t * data, then closing user can proceed.\n\t\t\t\t * Starting the timer is contrary to the\n\t\t\t\t * specification, but if we don't get a FIN\n\t\t\t\t * we'll hang forever.\n\t\t\t\t */\n\t\t\t\tif (so->so_state & SS_CANTRCVMORE) {\n\t\t\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\t\t\tsoisdisconnected(so);\n\t\t\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, tcp_maxidle);\n\t\t\t\t}\n\t\t\t\ttp->t_state = TCPS_FIN_WAIT_2;\n\t\t\t}\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In CLOSING STATE in addition to the processing for\n\t\t * the ESTABLISHED state if the ACK acknowledges our FIN\n\t\t * then enter the TIME-WAIT state, otherwise ignore\n\t\t * the segment.\n\t\t */\n\t\tcase TCPS_CLOSING:\n\t\t\tif (ourfinisacked) {\n\t\t\t\ttp->t_state = TCPS_TIME_WAIT;\n\t\t\t\ttcp_canceltimers(tp);\n\t\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);\n\t\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\t\tsoisdisconnected(so);\n\t\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\t}\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In LAST_ACK, we may still be waiting for data to drain\n\t\t * and/or to be acked, as well as for the ack of our FIN.\n\t\t * If our FIN is now acknowledged, delete the TCB,\n\t\t * enter the closed state and return.\n\t\t */\n\t\tcase TCPS_LAST_ACK:\n\t\t\tif (ourfinisacked) {\n\t\t\t\ttp = tcp_close(tp);\n\t\t\t\tgoto drop;\n\t\t\t}\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In TIME_WAIT state the only thing that should arrive\n\t\t * is a retransmission of the remote FIN.  Acknowledge\n\t\t * it and restart the finack timer.\n\t\t */\n\t\tcase TCPS_TIME_WAIT:\n\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);\n\t\t\tgoto dropafterack;\n\t\t}\n\t}\n\nstep6:\n\t/*\n\t * Update window information.\n\t * Don't look at window if no ACK: TAC's send garbage on first SYN.\n\t */\n\tif ((tiflags & TH_ACK) &&\n\t    (SEQ_LT(tp->snd_wl1, th->th_seq) || (tp->snd_wl1 == th->th_seq &&\n\t    (SEQ_LT(tp->snd_wl2, th->th_ack) ||\n\t    (tp->snd_wl2 == th->th_ack && tiwin > tp->snd_wnd))))) {\n\t\t/* keep track of pure window updates */\n\t\tif (tlen == 0 &&\n\t\t    tp->snd_wl2 == th->th_ack && tiwin > tp->snd_wnd)\n\t\t\ttcpstat_inc(tcps_rcvwinupd);\n\t\ttp->snd_wnd = tiwin;\n\t\ttp->snd_wl1 = th->th_seq;\n\t\ttp->snd_wl2 = th->th_ack;\n\t\tif (tp->snd_wnd > tp->max_sndwnd)\n\t\t\ttp->max_sndwnd = tp->snd_wnd;\n\t\ttp->t_flags |= TF_NEEDOUTPUT;\n\t}\n\n\t/*\n\t * Process segments with URG.\n\t */\n\tif ((tiflags & TH_URG) && th->th_urp &&\n\t    TCPS_HAVERCVDFIN(tp->t_state) == 0) {\n\t\t/*\n\t\t * This is a kludge, but if we receive and accept\n\t\t * random urgent pointers, we'll crash in\n\t\t * soreceive.  It's hard to imagine someone\n\t\t * actually wanting to send this much urgent data.\n\t\t */\n\t\tif (th->th_urp + so->so_rcv.sb_cc > sb_max) {\n\t\t\tth->th_urp = 0;\t\t\t/* XXX */\n\t\t\ttiflags &= ~TH_URG;\t\t/* XXX */\n\t\t\tgoto dodata;\t\t\t/* XXX */\n\t\t}\n\t\t/*\n\t\t * If this segment advances the known urgent pointer,\n\t\t * then mark the data stream.  This should not happen\n\t\t * in CLOSE_WAIT, CLOSING, LAST_ACK or TIME_WAIT STATES since\n\t\t * a FIN has been received from the remote side.\n\t\t * In these states we ignore the URG.\n\t\t *\n\t\t * According to RFC961 (Assigned Protocols),\n\t\t * the urgent pointer points to the last octet\n\t\t * of urgent data.  We continue, however,\n\t\t * to consider it to indicate the first octet\n\t\t * of data past the urgent section as the original\n\t\t * spec states (in one of two places).\n\t\t */\n\t\tif (SEQ_GT(th->th_seq+th->th_urp, tp->rcv_up)) {\n\t\t\ttp->rcv_up = th->th_seq + th->th_urp;\n\t\t\tso->so_oobmark = so->so_rcv.sb_cc +\n\t\t\t    (tp->rcv_up - tp->rcv_nxt) - 1;\n\t\t\tif (so->so_oobmark == 0)\n\t\t\t\tso->so_state |= SS_RCVATMARK;\n\t\t\tsohasoutofband(so);\n\t\t\ttp->t_oobflags &= ~(TCPOOB_HAVEDATA | TCPOOB_HADDATA);\n\t\t}\n\t\t/*\n\t\t * Remove out of band data so doesn't get presented to user.\n\t\t * This can happen independent of advancing the URG pointer,\n\t\t * but if two URG's are pending at once, some out-of-band\n\t\t * data may creep in... ick.\n\t\t */\n\t\tif (th->th_urp <= (u_int16_t) tlen &&\n\t\t    (so->so_options & SO_OOBINLINE) == 0)\n\t\t        tcp_pulloutofband(so, th->th_urp, m, hdroptlen);\n\t} else\n\t\t/*\n\t\t * If no out of band data is expected,\n\t\t * pull receive urgent pointer along\n\t\t * with the receive window.\n\t\t */\n\t\tif (SEQ_GT(tp->rcv_nxt, tp->rcv_up))\n\t\t\ttp->rcv_up = tp->rcv_nxt;\ndodata:\t\t\t\t\t\t\t/* XXX */\n\n\t/*\n\t * Process the segment text, merging it into the TCP sequencing queue,\n\t * and arranging for acknowledgment of receipt if necessary.\n\t * This process logically involves adjusting tp->rcv_wnd as data\n\t * is presented to the user (this happens in tcp_usrreq.c,\n\t * case PRU_RCVD).  If a FIN has already been received on this\n\t * connection then we just ignore the text.\n\t */\n\tif ((tlen || (tiflags & TH_FIN)) &&\n\t    TCPS_HAVERCVDFIN(tp->t_state) == 0) {\n\t\ttcp_seq laststart = th->th_seq;\n\t\ttcp_seq lastend = th->th_seq + tlen;\n\n\t\tif (th->th_seq == tp->rcv_nxt && TAILQ_EMPTY(&tp->t_segq) &&\n\t\t    tp->t_state == TCPS_ESTABLISHED) {\n\t\t\tTCP_SETUP_ACK(tp, tiflags, m);\n\t\t\ttp->rcv_nxt += tlen;\n\t\t\ttiflags = th->th_flags & TH_FIN;\n\t\t\ttcpstat_pkt(tcps_rcvpack, tcps_rcvbyte, tlen);\n\t\t\tND6_HINT(tp);\n\t\t\tif (so->so_state & SS_CANTRCVMORE)\n\t\t\t\tm_freem(m);\n\t\t\telse {\n\t\t\t\tm_adj(m, hdroptlen);\n\t\t\t\tsbappendstream(so, &so->so_rcv, m);\n\t\t\t}\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsorwakeup(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t} else {\n\t\t\tm_adj(m, hdroptlen);\n\t\t\ttiflags = tcp_reass(tp, th, m, &tlen);\n\t\t\ttp->t_flags |= TF_ACKNOW;\n\t\t}\n\t\tif (tp->sack_enable)\n\t\t\ttcp_update_sack_list(tp, laststart, lastend);\n\n\t\t/*\n\t\t * variable len never referenced again in modern BSD,\n\t\t * so why bother computing it ??\n\t\t */\n#if 0\n\t\t/*\n\t\t * Note the amount of data that peer has sent into\n\t\t * our window, in order to estimate the sender's\n\t\t * buffer size.\n\t\t */\n\t\tlen = so->so_rcv.sb_hiwat - (tp->rcv_adv - tp->rcv_nxt);\n#endif /* 0 */\n\t} else {\n\t\tm_freem(m);\n\t\ttiflags &= ~TH_FIN;\n\t}\n\n\t/*\n\t * If FIN is received ACK the FIN and let the user know\n\t * that the connection is closing.  Ignore a FIN received before\n\t * the connection is fully established.\n\t */\n\tif ((tiflags & TH_FIN) && TCPS_HAVEESTABLISHED(tp->t_state)) {\n\t\tif (TCPS_HAVERCVDFIN(tp->t_state) == 0) {\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsocantrcvmore(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\ttp->t_flags |= TF_ACKNOW;\n\t\t\ttp->rcv_nxt++;\n\t\t}\n\t\tswitch (tp->t_state) {\n\n\t\t/*\n\t\t * In ESTABLISHED STATE enter the CLOSE_WAIT state.\n\t\t */\n\t\tcase TCPS_ESTABLISHED:\n\t\t\ttp->t_state = TCPS_CLOSE_WAIT;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If still in FIN_WAIT_1 STATE FIN has not been acked so\n\t\t * enter the CLOSING state.\n\t\t */\n\t\tcase TCPS_FIN_WAIT_1:\n\t\t\ttp->t_state = TCPS_CLOSING;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In FIN_WAIT_2 state enter the TIME_WAIT state,\n\t\t * starting the time-wait timer, turning off the other\n\t\t * standard timers.\n\t\t */\n\t\tcase TCPS_FIN_WAIT_2:\n\t\t\ttp->t_state = TCPS_TIME_WAIT;\n\t\t\ttcp_canceltimers(tp);\n\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsoisdisconnected(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In TIME_WAIT state restart the 2 MSL time_wait timer.\n\t\t */\n\t\tcase TCPS_TIME_WAIT:\n\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (otp)\n\t\ttcp_trace(TA_INPUT, ostate, tp, otp, saveti, 0, tlen);\n\n\t/*\n\t * Return any desired output.\n\t */\n\tif (tp->t_flags & (TF_ACKNOW|TF_NEEDOUTPUT))\n\t\t(void) tcp_output(tp);\n\treturn IPPROTO_DONE;\n\nbadsyn:\n\t/*\n\t * Received a bad SYN.  Increment counters and dropwithreset.\n\t */\n\ttcpstat_inc(tcps_badsyn);\n\ttp = NULL;\n\tgoto dropwithreset;\n\ndropafterack_ratelim:\n\tif (ppsratecheck(&tcp_ackdrop_ppslim_last, &tcp_ackdrop_ppslim_count,\n\t    tcp_ackdrop_ppslim) == 0) {\n\t\t/* XXX stat */\n\t\tgoto drop;\n\t}\n\t/* ...fall into dropafterack... */\n\ndropafterack:\n\t/*\n\t * Generate an ACK dropping incoming segment if it occupies\n\t * sequence space, where the ACK reflects our state.\n\t */\n\tif (tiflags & TH_RST)\n\t\tgoto drop;\n\tm_freem(m);\n\ttp->t_flags |= TF_ACKNOW;\n\t(void) tcp_output(tp);\n\treturn IPPROTO_DONE;\n\ndropwithreset_ratelim:\n\t/*\n\t * We may want to rate-limit RSTs in certain situations,\n\t * particularly if we are sending an RST in response to\n\t * an attempt to connect to or otherwise communicate with\n\t * a port for which we have no socket.\n\t */\n\tif (ppsratecheck(&tcp_rst_ppslim_last, &tcp_rst_ppslim_count,\n\t    tcp_rst_ppslim) == 0) {\n\t\t/* XXX stat */\n\t\tgoto drop;\n\t}\n\t/* ...fall into dropwithreset... */\n\ndropwithreset:\n\t/*\n\t * Generate a RST, dropping incoming segment.\n\t * Make ACK acceptable to originator of segment.\n\t * Don't bother to respond to RST.\n\t */\n\tif (tiflags & TH_RST)\n\t\tgoto drop;\n\tif (tiflags & TH_ACK) {\n\t\ttcp_respond(tp, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack,\n\t\t    TH_RST, m->m_pkthdr.ph_rtableid);\n\t} else {\n\t\tif (tiflags & TH_SYN)\n\t\t\ttlen++;\n\t\ttcp_respond(tp, mtod(m, caddr_t), th, th->th_seq + tlen,\n\t\t    (tcp_seq)0, TH_RST|TH_ACK, m->m_pkthdr.ph_rtableid);\n\t}\n\tm_freem(m);\n\treturn IPPROTO_DONE;\n\ndrop:\n\t/*\n\t * Drop space held by incoming segment and return.\n\t */\n\tif (otp)\n\t\ttcp_trace(TA_DROP, ostate, tp, otp, saveti, 0, tlen);\n\n\tm_freem(m);\n\treturn IPPROTO_DONE;\n}\n\nint\ntcp_dooptions(struct tcpcb *tp, u_char *cp, int cnt, struct tcphdr *th,\n    struct mbuf *m, int iphlen, struct tcp_opt_info *oi,\n    u_int rtableid)\n{\n\tu_int16_t mss = 0;\n\tint opt, optlen;\n#ifdef TCP_SIGNATURE\n\tcaddr_t sigp = NULL;\n\tstruct tdb *tdb = NULL;\n#endif /* TCP_SIGNATURE */\n\n\tfor (; cp && cnt > 0; cnt -= optlen, cp += optlen) {\n\t\topt = cp[0];\n\t\tif (opt == TCPOPT_EOL)\n\t\t\tbreak;\n\t\tif (opt == TCPOPT_NOP)\n\t\t\toptlen = 1;\n\t\telse {\n\t\t\tif (cnt < 2)\n\t\t\t\tbreak;\n\t\t\toptlen = cp[1];\n\t\t\tif (optlen < 2 || optlen > cnt)\n\t\t\t\tbreak;\n\t\t}\n\t\tswitch (opt) {\n\n\t\tdefault:\n\t\t\tcontinue;\n\n\t\tcase TCPOPT_MAXSEG:\n\t\t\tif (optlen != TCPOLEN_MAXSEG)\n\t\t\t\tcontinue;\n\t\t\tif (!(th->th_flags & TH_SYN))\n\t\t\t\tcontinue;\n\t\t\tif (TCPS_HAVERCVDSYN(tp->t_state))\n\t\t\t\tcontinue;\n\t\t\tmemcpy(&mss, cp + 2, sizeof(mss));\n\t\t\tmss = ntohs(mss);\n\t\t\toi->maxseg = mss;\n\t\t\tbreak;\n\n\t\tcase TCPOPT_WINDOW:\n\t\t\tif (optlen != TCPOLEN_WINDOW)\n\t\t\t\tcontinue;\n\t\t\tif (!(th->th_flags & TH_SYN))\n\t\t\t\tcontinue;\n\t\t\tif (TCPS_HAVERCVDSYN(tp->t_state))\n\t\t\t\tcontinue;\n\t\t\ttp->t_flags |= TF_RCVD_SCALE;\n\t\t\ttp->requested_s_scale = min(cp[2], TCP_MAX_WINSHIFT);\n\t\t\tbreak;\n\n\t\tcase TCPOPT_TIMESTAMP:\n\t\t\tif (optlen != TCPOLEN_TIMESTAMP)\n\t\t\t\tcontinue;\n\t\t\toi->ts_present = 1;\n\t\t\tmemcpy(&oi->ts_val, cp + 2, sizeof(oi->ts_val));\n\t\t\toi->ts_val = ntohl(oi->ts_val);\n\t\t\tmemcpy(&oi->ts_ecr, cp + 6, sizeof(oi->ts_ecr));\n\t\t\toi->ts_ecr = ntohl(oi->ts_ecr);\n\n\t\t\tif (!(th->th_flags & TH_SYN))\n\t\t\t\tcontinue;\n\t\t\tif (TCPS_HAVERCVDSYN(tp->t_state))\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * A timestamp received in a SYN makes\n\t\t\t * it ok to send timestamp requests and replies.\n\t\t\t */\n\t\t\ttp->t_flags |= TF_RCVD_TSTMP;\n\t\t\ttp->ts_recent = oi->ts_val;\n\t\t\ttp->ts_recent_age = tcp_now;\n\t\t\tbreak;\n\n\t\tcase TCPOPT_SACK_PERMITTED:\n\t\t\tif (!tp->sack_enable || optlen!=TCPOLEN_SACK_PERMITTED)\n\t\t\t\tcontinue;\n\t\t\tif (!(th->th_flags & TH_SYN))\n\t\t\t\tcontinue;\n\t\t\tif (TCPS_HAVERCVDSYN(tp->t_state))\n\t\t\t\tcontinue;\n\t\t\t/* MUST only be set on SYN */\n\t\t\ttp->t_flags |= TF_SACK_PERMIT;\n\t\t\tbreak;\n\t\tcase TCPOPT_SACK:\n\t\t\ttcp_sack_option(tp, th, cp, optlen);\n\t\t\tbreak;\n#ifdef TCP_SIGNATURE\n\t\tcase TCPOPT_SIGNATURE:\n\t\t\tif (optlen != TCPOLEN_SIGNATURE)\n\t\t\t\tcontinue;\n\n\t\t\tif (sigp && timingsafe_bcmp(sigp, cp + 2, 16))\n\t\t\t\treturn (-1);\n\n\t\t\tsigp = cp + 2;\n\t\t\tbreak;\n#endif /* TCP_SIGNATURE */\n\t\t}\n\t}\n\n#ifdef TCP_SIGNATURE\n\tif (tp->t_flags & TF_SIGNATURE) {\n\t\tunion sockaddr_union src, dst;\n\n\t\tmemset(&src, 0, sizeof(union sockaddr_union));\n\t\tmemset(&dst, 0, sizeof(union sockaddr_union));\n\n\t\tswitch (tp->pf) {\n\t\tcase 0:\n\t\tcase AF_INET:\n\t\t\tsrc.sa.sa_len = sizeof(struct sockaddr_in);\n\t\t\tsrc.sa.sa_family = AF_INET;\n\t\t\tsrc.sin.sin_addr = mtod(m, struct ip *)->ip_src;\n\t\t\tdst.sa.sa_len = sizeof(struct sockaddr_in);\n\t\t\tdst.sa.sa_family = AF_INET;\n\t\t\tdst.sin.sin_addr = mtod(m, struct ip *)->ip_dst;\n\t\t\tbreak;\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tsrc.sa.sa_len = sizeof(struct sockaddr_in6);\n\t\t\tsrc.sa.sa_family = AF_INET6;\n\t\t\tsrc.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_src;\n\t\t\tdst.sa.sa_len = sizeof(struct sockaddr_in6);\n\t\t\tdst.sa.sa_family = AF_INET6;\n\t\t\tdst.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;\n\t\t\tbreak;\n#endif /* INET6 */\n\t\t}\n\n\t\ttdb = gettdbbysrcdst(rtable_l2(rtableid),\n\t\t    0, &src, &dst, IPPROTO_TCP);\n\n\t\t/*\n\t\t * We don't have an SA for this peer, so we turn off\n\t\t * TF_SIGNATURE on the listen socket\n\t\t */\n\t\tif (tdb == NULL && tp->t_state == TCPS_LISTEN)\n\t\t\ttp->t_flags &= ~TF_SIGNATURE;\n\n\t}\n\n\tif ((sigp ? TF_SIGNATURE : 0) ^ (tp->t_flags & TF_SIGNATURE)) {\n\t\ttcpstat_inc(tcps_rcvbadsig);\n\t\treturn (-1);\n\t}\n\n\tif (sigp) {\n\t\tchar sig[16];\n\n\t\tif (tdb == NULL) {\n\t\t\ttcpstat_inc(tcps_rcvbadsig);\n\t\t\treturn (-1);\n\t\t}\n\n\t\tif (tcp_signature(tdb, tp->pf, m, th, iphlen, 1, sig) < 0)\n\t\t\treturn (-1);\n\n\t\tif (timingsafe_bcmp(sig, sigp, 16)) {\n\t\t\ttcpstat_inc(tcps_rcvbadsig);\n\t\t\treturn (-1);\n\t\t}\n\n\t\ttcpstat_inc(tcps_rcvgoodsig);\n\t}\n#endif /* TCP_SIGNATURE */\n\n\treturn (0);\n}\n\nu_long\ntcp_seq_subtract(u_long a, u_long b)\n{\n\treturn ((long)(a - b));\n}\n\n/*\n * This function is called upon receipt of new valid data (while not in header\n * prediction mode), and it updates the ordered list of sacks.\n */\nvoid\ntcp_update_sack_list(struct tcpcb *tp, tcp_seq rcv_laststart,\n    tcp_seq rcv_lastend)\n{\n\t/*\n\t * First reported block MUST be the most recent one.  Subsequent\n\t * blocks SHOULD be in the order in which they arrived at the\n\t * receiver.  These two conditions make the implementation fully\n\t * compliant with RFC 2018.\n\t */\n\tint i, j = 0, count = 0, lastpos = -1;\n\tstruct sackblk sack, firstsack, temp[MAX_SACK_BLKS];\n\n\t/* First clean up current list of sacks */\n\tfor (i = 0; i < tp->rcv_numsacks; i++) {\n\t\tsack = tp->sackblks[i];\n\t\tif (sack.start == 0 && sack.end == 0) {\n\t\t\tcount++; /* count = number of blocks to be discarded */\n\t\t\tcontinue;\n\t\t}\n\t\tif (SEQ_LEQ(sack.end, tp->rcv_nxt)) {\n\t\t\ttp->sackblks[i].start = tp->sackblks[i].end = 0;\n\t\t\tcount++;\n\t\t} else {\n\t\t\ttemp[j].start = tp->sackblks[i].start;\n\t\t\ttemp[j++].end = tp->sackblks[i].end;\n\t\t}\n\t}\n\ttp->rcv_numsacks -= count;\n\tif (tp->rcv_numsacks == 0) { /* no sack blocks currently (fast path) */\n\t\ttcp_clean_sackreport(tp);\n\t\tif (SEQ_LT(tp->rcv_nxt, rcv_laststart)) {\n\t\t\t/* ==> need first sack block */\n\t\t\ttp->sackblks[0].start = rcv_laststart;\n\t\t\ttp->sackblks[0].end = rcv_lastend;\n\t\t\ttp->rcv_numsacks = 1;\n\t\t}\n\t\treturn;\n\t}\n\t/* Otherwise, sack blocks are already present. */\n\tfor (i = 0; i < tp->rcv_numsacks; i++)\n\t\ttp->sackblks[i] = temp[i]; /* first copy back sack list */\n\tif (SEQ_GEQ(tp->rcv_nxt, rcv_lastend))\n\t\treturn;     /* sack list remains unchanged */\n\t/*\n\t * From here, segment just received should be (part of) the 1st sack.\n\t * Go through list, possibly coalescing sack block entries.\n\t */\n\tfirstsack.start = rcv_laststart;\n\tfirstsack.end = rcv_lastend;\n\tfor (i = 0; i < tp->rcv_numsacks; i++) {\n\t\tsack = tp->sackblks[i];\n\t\tif (SEQ_LT(sack.end, firstsack.start) ||\n\t\t    SEQ_GT(sack.start, firstsack.end))\n\t\t\tcontinue; /* no overlap */\n\t\tif (sack.start == firstsack.start && sack.end == firstsack.end){\n\t\t\t/*\n\t\t\t * identical block; delete it here since we will\n\t\t\t * move it to the front of the list.\n\t\t\t */\n\t\t\ttp->sackblks[i].start = tp->sackblks[i].end = 0;\n\t\t\tlastpos = i;    /* last posn with a zero entry */\n\t\t\tcontinue;\n\t\t}\n\t\tif (SEQ_LEQ(sack.start, firstsack.start))\n\t\t\tfirstsack.start = sack.start; /* merge blocks */\n\t\tif (SEQ_GEQ(sack.end, firstsack.end))\n\t\t\tfirstsack.end = sack.end;     /* merge blocks */\n\t\ttp->sackblks[i].start = tp->sackblks[i].end = 0;\n\t\tlastpos = i;    /* last posn with a zero entry */\n\t}\n\tif (lastpos != -1) {    /* at least one merge */\n\t\tfor (i = 0, j = 1; i < tp->rcv_numsacks; i++) {\n\t\t\tsack = tp->sackblks[i];\n\t\t\tif (sack.start == 0 && sack.end == 0)\n\t\t\t\tcontinue;\n\t\t\ttemp[j++] = sack;\n\t\t}\n\t\ttp->rcv_numsacks = j; /* including first blk (added later) */\n\t\tfor (i = 1; i < tp->rcv_numsacks; i++) /* now copy back */\n\t\t\ttp->sackblks[i] = temp[i];\n\t} else {        /* no merges -- shift sacks by 1 */\n\t\tif (tp->rcv_numsacks < MAX_SACK_BLKS)\n\t\t\ttp->rcv_numsacks++;\n\t\tfor (i = tp->rcv_numsacks-1; i > 0; i--)\n\t\t\ttp->sackblks[i] = tp->sackblks[i-1];\n\t}\n\ttp->sackblks[0] = firstsack;\n\treturn;\n}\n\n/*\n * Process the TCP SACK option.  tp->snd_holes is an ordered list\n * of holes (oldest to newest, in terms of the sequence space).\n */\nvoid\ntcp_sack_option(struct tcpcb *tp, struct tcphdr *th, u_char *cp, int optlen)\n{\n\tint tmp_olen;\n\tu_char *tmp_cp;\n\tstruct sackhole *cur, *p, *temp;\n\n\tif (!tp->sack_enable)\n\t\treturn;\n\t/* SACK without ACK doesn't make sense. */\n\tif ((th->th_flags & TH_ACK) == 0)\n\t       return;\n\t/* Make sure the ACK on this segment is in [snd_una, snd_max]. */\n\tif (SEQ_LT(th->th_ack, tp->snd_una) ||\n\t    SEQ_GT(th->th_ack, tp->snd_max))\n\t\treturn;\n\t/* Note: TCPOLEN_SACK must be 2*sizeof(tcp_seq) */\n\tif (optlen <= 2 || (optlen - 2) % TCPOLEN_SACK != 0)\n\t\treturn;\n\t/* Note: TCPOLEN_SACK must be 2*sizeof(tcp_seq) */\n\ttmp_cp = cp + 2;\n\ttmp_olen = optlen - 2;\n\ttcpstat_inc(tcps_sack_rcv_opts);\n\tif (tp->snd_numholes < 0)\n\t\ttp->snd_numholes = 0;\n\tif (tp->t_maxseg == 0)\n\t\tpanic(\"tcp_sack_option\"); /* Should never happen */\n\twhile (tmp_olen > 0) {\n\t\tstruct sackblk sack;\n\n\t\tmemcpy(&sack.start, tmp_cp, sizeof(tcp_seq));\n\t\tsack.start = ntohl(sack.start);\n\t\tmemcpy(&sack.end, tmp_cp + sizeof(tcp_seq), sizeof(tcp_seq));\n\t\tsack.end = ntohl(sack.end);\n\t\ttmp_olen -= TCPOLEN_SACK;\n\t\ttmp_cp += TCPOLEN_SACK;\n\t\tif (SEQ_LEQ(sack.end, sack.start))\n\t\t\tcontinue; /* bad SACK fields */\n\t\tif (SEQ_LEQ(sack.end, tp->snd_una))\n\t\t\tcontinue; /* old block */\n\t\tif (SEQ_GT(th->th_ack, tp->snd_una)) {\n\t\t\tif (SEQ_LT(sack.start, th->th_ack))\n\t\t\t\tcontinue;\n\t\t}\n\t\tif (SEQ_GT(sack.end, tp->snd_max))\n\t\t\tcontinue;\n\t\tif (tp->snd_holes == NULL) { /* first hole */\n\t\t\ttp->snd_holes = (struct sackhole *)\n\t\t\t    pool_get(&sackhl_pool, PR_NOWAIT);\n\t\t\tif (tp->snd_holes == NULL) {\n\t\t\t\t/* ENOBUFS, so ignore SACKed block for now*/\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tcur = tp->snd_holes;\n\t\t\tcur->start = th->th_ack;\n\t\t\tcur->end = sack.start;\n\t\t\tcur->rxmit = cur->start;\n\t\t\tcur->next = NULL;\n\t\t\ttp->snd_numholes = 1;\n\t\t\ttp->rcv_lastsack = sack.end;\n\t\t\t/*\n\t\t\t * dups is at least one.  If more data has been\n\t\t\t * SACKed, it can be greater than one.\n\t\t\t */\n\t\t\tcur->dups = min(tcprexmtthresh,\n\t\t\t    ((sack.end - cur->end)/tp->t_maxseg));\n\t\t\tif (cur->dups < 1)\n\t\t\t\tcur->dups = 1;\n\t\t\tcontinue; /* with next sack block */\n\t\t}\n\t\t/* Go thru list of holes:  p = previous,  cur = current */\n\t\tp = cur = tp->snd_holes;\n\t\twhile (cur) {\n\t\t\tif (SEQ_LEQ(sack.end, cur->start))\n\t\t\t\t/* SACKs data before the current hole */\n\t\t\t\tbreak; /* no use going through more holes */\n\t\t\tif (SEQ_GEQ(sack.start, cur->end)) {\n\t\t\t\t/* SACKs data beyond the current hole */\n\t\t\t\tcur->dups++;\n\t\t\t\tif (((sack.end - cur->end)/tp->t_maxseg) >=\n\t\t\t\t    tcprexmtthresh)\n\t\t\t\t\tcur->dups = tcprexmtthresh;\n\t\t\t\tp = cur;\n\t\t\t\tcur = cur->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (SEQ_LEQ(sack.start, cur->start)) {\n\t\t\t\t/* Data acks at least the beginning of hole */\n\t\t\t\tif (SEQ_GEQ(sack.end, cur->end)) {\n\t\t\t\t\t/* Acks entire hole, so delete hole */\n\t\t\t\t\tif (p != cur) {\n\t\t\t\t\t\tp->next = cur->next;\n\t\t\t\t\t\tpool_put(&sackhl_pool, cur);\n\t\t\t\t\t\tcur = p->next;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tcur = cur->next;\n\t\t\t\t\t\tpool_put(&sackhl_pool, p);\n\t\t\t\t\t\tp = cur;\n\t\t\t\t\t\ttp->snd_holes = p;\n\t\t\t\t\t}\n\t\t\t\t\ttp->snd_numholes--;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\t/* otherwise, move start of hole forward */\n\t\t\t\tcur->start = sack.end;\n\t\t\t\tcur->rxmit = SEQ_MAX(cur->rxmit, cur->start);\n\t\t\t\tp = cur;\n\t\t\t\tcur = cur->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* move end of hole backward */\n\t\t\tif (SEQ_GEQ(sack.end, cur->end)) {\n\t\t\t\tcur->end = sack.start;\n\t\t\t\tcur->rxmit = SEQ_MIN(cur->rxmit, cur->end);\n\t\t\t\tcur->dups++;\n\t\t\t\tif (((sack.end - cur->end)/tp->t_maxseg) >=\n\t\t\t\t    tcprexmtthresh)\n\t\t\t\t\tcur->dups = tcprexmtthresh;\n\t\t\t\tp = cur;\n\t\t\t\tcur = cur->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (SEQ_LT(cur->start, sack.start) &&\n\t\t\t    SEQ_GT(cur->end, sack.end)) {\n\t\t\t\t/*\n\t\t\t\t * ACKs some data in middle of a hole; need to\n\t\t\t\t * split current hole\n\t\t\t\t */\n\t\t\t\ttemp = (struct sackhole *)\n\t\t\t\t    pool_get(&sackhl_pool, PR_NOWAIT);\n\t\t\t\tif (temp == NULL)\n\t\t\t\t\tgoto done; /* ENOBUFS */\n\t\t\t\ttemp->next = cur->next;\n\t\t\t\ttemp->start = sack.end;\n\t\t\t\ttemp->end = cur->end;\n\t\t\t\ttemp->dups = cur->dups;\n\t\t\t\ttemp->rxmit = SEQ_MAX(cur->rxmit, temp->start);\n\t\t\t\tcur->end = sack.start;\n\t\t\t\tcur->rxmit = SEQ_MIN(cur->rxmit, cur->end);\n\t\t\t\tcur->dups++;\n\t\t\t\tif (((sack.end - cur->end)/tp->t_maxseg) >=\n\t\t\t\t\ttcprexmtthresh)\n\t\t\t\t\tcur->dups = tcprexmtthresh;\n\t\t\t\tcur->next = temp;\n\t\t\t\tp = temp;\n\t\t\t\tcur = p->next;\n\t\t\t\ttp->snd_numholes++;\n\t\t\t}\n\t\t}\n\t\t/* At this point, p points to the last hole on the list */\n\t\tif (SEQ_LT(tp->rcv_lastsack, sack.start)) {\n\t\t\t/*\n\t\t\t * Need to append new hole at end.\n\t\t\t * Last hole is p (and it's not NULL).\n\t\t\t */\n\t\t\ttemp = (struct sackhole *)\n\t\t\t    pool_get(&sackhl_pool, PR_NOWAIT);\n\t\t\tif (temp == NULL)\n\t\t\t\tgoto done; /* ENOBUFS */\n\t\t\ttemp->start = tp->rcv_lastsack;\n\t\t\ttemp->end = sack.start;\n\t\t\ttemp->dups = min(tcprexmtthresh,\n\t\t\t    ((sack.end - sack.start)/tp->t_maxseg));\n\t\t\tif (temp->dups < 1)\n\t\t\t\ttemp->dups = 1;\n\t\t\ttemp->rxmit = temp->start;\n\t\t\ttemp->next = 0;\n\t\t\tp->next = temp;\n\t\t\ttp->rcv_lastsack = sack.end;\n\t\t\ttp->snd_numholes++;\n\t\t}\n\t}\ndone:\n\treturn;\n}\n\n/*\n * Delete stale (i.e, cumulatively ack'd) holes.  Hole is deleted only if\n * it is completely acked; otherwise, tcp_sack_option(), called from\n * tcp_dooptions(), will fix up the hole.\n */\nvoid\ntcp_del_sackholes(struct tcpcb *tp, struct tcphdr *th)\n{\n\tif (tp->sack_enable && tp->t_state != TCPS_LISTEN) {\n\t\t/* max because this could be an older ack just arrived */\n\t\ttcp_seq lastack = SEQ_GT(th->th_ack, tp->snd_una) ?\n\t\t\tth->th_ack : tp->snd_una;\n\t\tstruct sackhole *cur = tp->snd_holes;\n\t\tstruct sackhole *prev;\n\t\twhile (cur)\n\t\t\tif (SEQ_LEQ(cur->end, lastack)) {\n\t\t\t\tprev = cur;\n\t\t\t\tcur = cur->next;\n\t\t\t\tpool_put(&sackhl_pool, prev);\n\t\t\t\ttp->snd_numholes--;\n\t\t\t} else if (SEQ_LT(cur->start, lastack)) {\n\t\t\t\tcur->start = lastack;\n\t\t\t\tif (SEQ_LT(cur->rxmit, cur->start))\n\t\t\t\t\tcur->rxmit = cur->start;\n\t\t\t\tbreak;\n\t\t\t} else\n\t\t\t\tbreak;\n\t\ttp->snd_holes = cur;\n\t}\n}\n\n/*\n * Delete all receiver-side SACK information.\n */\nvoid\ntcp_clean_sackreport(struct tcpcb *tp)\n{\n\tint i;\n\n\ttp->rcv_numsacks = 0;\n\tfor (i = 0; i < MAX_SACK_BLKS; i++)\n\t\ttp->sackblks[i].start = tp->sackblks[i].end=0;\n\n}\n\n/*\n * Partial ack handling within a sack recovery episode.  When a partial ack\n * arrives, turn off retransmission timer, deflate the window, do not clear\n * tp->t_dupacks.\n */\nvoid\ntcp_sack_partialack(struct tcpcb *tp, struct tcphdr *th)\n{\n\t/* Turn off retx. timer (will start again next segment) */\n\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\ttp->t_rtttime = 0;\n\t/*\n\t * Partial window deflation.  This statement relies on the\n\t * fact that tp->snd_una has not been updated yet.\n\t */\n\tif (tp->snd_cwnd > (th->th_ack - tp->snd_una)) {\n\t\ttp->snd_cwnd -= th->th_ack - tp->snd_una;\n\t\ttp->snd_cwnd += tp->t_maxseg;\n\t} else\n\t\ttp->snd_cwnd = tp->t_maxseg;\n\ttp->snd_cwnd += tp->t_maxseg;\n\ttp->t_flags |= TF_NEEDOUTPUT;\n}\n\n/*\n * Pull out of band byte out of a segment so\n * it doesn't appear in the user's data queue.\n * It is still reflected in the segment length for\n * sequencing purposes.\n */\nvoid\ntcp_pulloutofband(struct socket *so, u_int urgent, struct mbuf *m, int off)\n{\n        int cnt = off + urgent - 1;\n\n\twhile (cnt >= 0) {\n\t\tif (m->m_len > cnt) {\n\t\t\tchar *cp = mtod(m, caddr_t) + cnt;\n\t\t\tstruct tcpcb *tp = sototcpcb(so);\n\n\t\t\ttp->t_iobc = *cp;\n\t\t\ttp->t_oobflags |= TCPOOB_HAVEDATA;\n\t\t\tmemmove(cp, cp + 1, m->m_len - cnt - 1);\n\t\t\tm->m_len--;\n\t\t\treturn;\n\t\t}\n\t\tcnt -= m->m_len;\n\t\tm = m->m_next;\n\t\tif (m == NULL)\n\t\t\tbreak;\n\t}\n\tpanic(\"tcp_pulloutofband\");\n}\n\n/*\n * Collect new round-trip time estimate\n * and update averages and current timeout.\n */\nvoid\ntcp_xmit_timer(struct tcpcb *tp, int rtt)\n{\n\tshort delta;\n\tshort rttmin;\n\n\tif (rtt < 0)\n\t\trtt = 0;\n\telse if (rtt > TCP_RTT_MAX)\n\t\trtt = TCP_RTT_MAX;\n\n\ttcpstat_inc(tcps_rttupdated);\n\tif (tp->t_srtt != 0) {\n\t\t/*\n\t\t * delta is fixed point with 2 (TCP_RTT_BASE_SHIFT) bits\n\t\t * after the binary point (scaled by 4), whereas\n\t\t * srtt is stored as fixed point with 5 bits after the\n\t\t * binary point (i.e., scaled by 32).  The following magic\n\t\t * is equivalent to the smoothing algorithm in rfc793 with\n\t\t * an alpha of .875 (srtt = rtt/8 + srtt*7/8 in fixed\n\t\t * point).\n\t\t */\n\t\tdelta = (rtt << TCP_RTT_BASE_SHIFT) -\n\t\t    (tp->t_srtt >> TCP_RTT_SHIFT);\n\t\tif ((tp->t_srtt += delta) <= 0)\n\t\t\ttp->t_srtt = 1 << TCP_RTT_BASE_SHIFT;\n\t\t/*\n\t\t * We accumulate a smoothed rtt variance (actually, a\n\t\t * smoothed mean difference), then set the retransmit\n\t\t * timer to smoothed rtt + 4 times the smoothed variance.\n\t\t * rttvar is stored as fixed point with 4 bits after the\n\t\t * binary point (scaled by 16).  The following is\n\t\t * equivalent to rfc793 smoothing with an alpha of .75\n\t\t * (rttvar = rttvar*3/4 + |delta| / 4).  This replaces\n\t\t * rfc793's wired-in beta.\n\t\t */\n\t\tif (delta < 0)\n\t\t\tdelta = -delta;\n\t\tdelta -= (tp->t_rttvar >> TCP_RTTVAR_SHIFT);\n\t\tif ((tp->t_rttvar += delta) <= 0)\n\t\t\ttp->t_rttvar = 1 << TCP_RTT_BASE_SHIFT;\n\t} else {\n\t\t/*\n\t\t * No rtt measurement yet - use the unsmoothed rtt.\n\t\t * Set the variance to half the rtt (so our first\n\t\t * retransmit happens at 3*rtt).\n\t\t */\n\t\ttp->t_srtt = (rtt + 1) << (TCP_RTT_SHIFT + TCP_RTT_BASE_SHIFT);\n\t\ttp->t_rttvar = (rtt + 1) <<\n\t\t    (TCP_RTTVAR_SHIFT + TCP_RTT_BASE_SHIFT - 1);\n\t}\n\ttp->t_rtttime = 0;\n\ttp->t_rxtshift = 0;\n\n\t/*\n\t * the retransmit should happen at rtt + 4 * rttvar.\n\t * Because of the way we do the smoothing, srtt and rttvar\n\t * will each average +1/2 tick of bias.  When we compute\n\t * the retransmit timer, we want 1/2 tick of rounding and\n\t * 1 extra tick because of +-1/2 tick uncertainty in the\n\t * firing of the timer.  The bias will give us exactly the\n\t * 1.5 tick we need.  But, because the bias is\n\t * statistical, we have to test that we don't drop below\n\t * the minimum feasible timer (which is 2 ticks).\n\t */\n\trttmin = min(max(rtt + 2, tp->t_rttmin), TCPTV_REXMTMAX);\n\tTCPT_RANGESET(tp->t_rxtcur, TCP_REXMTVAL(tp), rttmin, TCPTV_REXMTMAX);\n\n\t/*\n\t * We received an ack for a packet that wasn't retransmitted;\n\t * it is probably safe to discard any error indications we've\n\t * received recently.  This isn't quite right, but close enough\n\t * for now (a route might have failed after we sent a segment,\n\t * and the return path might not be symmetrical).\n\t */\n\ttp->t_softerror = 0;\n}\n\n/*\n * Determine a reasonable value for maxseg size.\n * If the route is known, check route for mtu.\n * If none, use an mss that can be handled on the outgoing\n * interface without forcing IP to fragment; if bigger than\n * an mbuf cluster (MCLBYTES), round down to nearest multiple of MCLBYTES\n * to utilize large mbufs.  If no route is found, route has no mtu,\n * or the destination isn't local, use a default, hopefully conservative\n * size (usually 512 or the default IP max size, but no more than the mtu\n * of the interface), as we can't discover anything about intervening\n * gateways or networks.  We also initialize the congestion/slow start\n * window to be a single segment if the destination isn't local.\n * While looking at the routing entry, we also initialize other path-dependent\n * parameters from pre-set or cached values in the routing entry.\n *\n * Also take into account the space needed for options that we\n * send regularly.  Make maxseg shorter by that amount to assure\n * that we can send maxseg amount of data even when the options\n * are present.  Store the upper limit of the length of options plus\n * data in maxopd.\n *\n * NOTE: offer == -1 indicates that the maxseg size changed due to\n * Path MTU discovery.\n */\nint\ntcp_mss(struct tcpcb *tp, int offer)\n{\n\tstruct rtentry *rt;\n\tstruct ifnet *ifp = NULL;\n\tint mss, mssopt;\n\tint iphlen;\n\tstruct inpcb *inp;\n\n\tinp = tp->t_inpcb;\n\n\tmssopt = mss = tcp_mssdflt;\n\n\trt = in_pcbrtentry(inp);\n\n\tif (rt == NULL)\n\t\tgoto out;\n\n\tifp = if_get(rt->rt_ifidx);\n\tif (ifp == NULL)\n\t\tgoto out;\n\n\tswitch (tp->pf) {\n#ifdef INET6\n\tcase AF_INET6:\n\t\tiphlen = sizeof(struct ip6_hdr);\n\t\tbreak;\n#endif\n\tcase AF_INET:\n\t\tiphlen = sizeof(struct ip);\n\t\tbreak;\n\tdefault:\n\t\t/* the family does not support path MTU discovery */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * if there's an mtu associated with the route and we support\n\t * path MTU discovery for the underlying protocol family, use it.\n\t */\n\tif (rt->rt_mtu) {\n\t\t/*\n\t\t * One may wish to lower MSS to take into account options,\n\t\t * especially security-related options.\n\t\t */\n\t\tif (tp->pf == AF_INET6 && rt->rt_mtu < IPV6_MMTU) {\n\t\t\t/*\n\t\t\t * RFC2460 section 5, last paragraph: if path MTU is\n\t\t\t * smaller than 1280, use 1280 as packet size and\n\t\t\t * attach fragment header.\n\t\t\t */\n\t\t\tmss = IPV6_MMTU - iphlen - sizeof(struct ip6_frag) -\n\t\t\t    sizeof(struct tcphdr);\n\t\t} else {\n\t\t\tmss = rt->rt_mtu - iphlen -\n\t\t\t    sizeof(struct tcphdr);\n\t\t}\n\t} else if (ifp->if_flags & IFF_LOOPBACK) {\n\t\tmss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);\n\t} else if (tp->pf == AF_INET) {\n\t\tif (ip_mtudisc)\n\t\t\tmss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);\n\t}\n#ifdef INET6\n\telse if (tp->pf == AF_INET6) {\n\t\t/*\n\t\t * for IPv6, path MTU discovery is always turned on,\n\t\t * or the node must use packet size <= 1280.\n\t\t */\n\t\tmss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);\n\t}\n#endif /* INET6 */\n\n\t/* Calculate the value that we offer in TCPOPT_MAXSEG */\n\tif (offer != -1) {\n\t\tmssopt = ifp->if_mtu - iphlen - sizeof(struct tcphdr);\n\t\tmssopt = max(tcp_mssdflt, mssopt);\n\t}\n out:\n\tif_put(ifp);\n\t/*\n\t * The current mss, t_maxseg, is initialized to the default value.\n\t * If we compute a smaller value, reduce the current mss.\n\t * If we compute a larger value, return it for use in sending\n\t * a max seg size option, but don't store it for use\n\t * unless we received an offer at least that large from peer.\n\t *\n\t * However, do not accept offers lower than the minimum of\n\t * the interface MTU and 216.\n\t */\n\tif (offer > 0)\n\t\ttp->t_peermss = offer;\n\tif (tp->t_peermss)\n\t\tmss = min(mss, max(tp->t_peermss, 216));\n\n\t/* sanity - at least max opt. space */\n\tmss = max(mss, 64);\n\n\t/*\n\t * maxopd stores the maximum length of data AND options\n\t * in a segment; maxseg is the amount of data in a normal\n\t * segment.  We need to store this value (maxopd) apart\n\t * from maxseg, because now every segment carries options\n\t * and thus we normally have somewhat less data in segments.\n\t */\n\ttp->t_maxopd = mss;\n\n\tif ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&\n\t    (tp->t_flags & TF_RCVD_TSTMP) == TF_RCVD_TSTMP)\n\t\tmss -= TCPOLEN_TSTAMP_APPA;\n#ifdef TCP_SIGNATURE\n\tif (tp->t_flags & TF_SIGNATURE)\n\t\tmss -= TCPOLEN_SIGLEN;\n#endif\n\n\tif (offer == -1) {\n\t\t/* mss changed due to Path MTU discovery */\n\t\ttp->t_flags &= ~TF_PMTUD_PEND;\n\t\ttp->t_pmtud_mtu_sent = 0;\n\t\ttp->t_pmtud_mss_acked = 0;\n\t\tif (mss < tp->t_maxseg) {\n\t\t\t/*\n\t\t\t * Follow suggestion in RFC 2414 to reduce the\n\t\t\t * congestion window by the ratio of the old\n\t\t\t * segment size to the new segment size.\n\t\t\t */\n\t\t\ttp->snd_cwnd = ulmax((tp->snd_cwnd / tp->t_maxseg) *\n\t\t\t\t\t     mss, mss);\n\t\t}\n\t} else if (tcp_do_rfc3390 == 2) {\n\t\t/* increase initial window  */\n\t\ttp->snd_cwnd = ulmin(10 * mss, ulmax(2 * mss, 14600));\n\t} else if (tcp_do_rfc3390) {\n\t\t/* increase initial window  */\n\t\ttp->snd_cwnd = ulmin(4 * mss, ulmax(2 * mss, 4380));\n\t} else\n\t\ttp->snd_cwnd = mss;\n\n\ttp->t_maxseg = mss;\n\n\treturn (offer != -1 ? mssopt : mss);\n}\n\nu_int\ntcp_hdrsz(struct tcpcb *tp)\n{\n\tu_int hlen;\n\n\tswitch (tp->pf) {\n#ifdef INET6\n\tcase AF_INET6:\n\t\thlen = sizeof(struct ip6_hdr);\n\t\tbreak;\n#endif\n\tcase AF_INET:\n\t\thlen = sizeof(struct ip);\n\t\tbreak;\n\tdefault:\n\t\thlen = 0;\n\t\tbreak;\n\t}\n\thlen += sizeof(struct tcphdr);\n\n\tif ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&\n\t    (tp->t_flags & TF_RCVD_TSTMP) == TF_RCVD_TSTMP)\n\t\thlen += TCPOLEN_TSTAMP_APPA;\n#ifdef TCP_SIGNATURE\n\tif (tp->t_flags & TF_SIGNATURE)\n\t\thlen += TCPOLEN_SIGLEN;\n#endif\n\treturn (hlen);\n}\n\n/*\n * Set connection variables based on the effective MSS.\n * We are passed the TCPCB for the actual connection.  If we\n * are the server, we are called by the compressed state engine\n * when the 3-way handshake is complete.  If we are the client,\n * we are called when we receive the SYN,ACK from the server.\n *\n * NOTE: The t_maxseg value must be initialized in the TCPCB\n * before this routine is called!\n */\nvoid\ntcp_mss_update(struct tcpcb *tp)\n{\n\tint mss;\n\tu_long bufsize;\n\tstruct rtentry *rt;\n\tstruct socket *so;\n\n\tso = tp->t_inpcb->inp_socket;\n\tmss = tp->t_maxseg;\n\n\trt = in_pcbrtentry(tp->t_inpcb);\n\n\tif (rt == NULL)\n\t\treturn;\n\n\tbufsize = so->so_snd.sb_hiwat;\n\tif (bufsize < mss) {\n\t\tmss = bufsize;\n\t\t/* Update t_maxseg and t_maxopd */\n\t\ttcp_mss(tp, mss);\n\t} else {\n\t\tbufsize = roundup(bufsize, mss);\n\t\tif (bufsize > sb_max)\n\t\t\tbufsize = sb_max;\n\t\t(void)sbreserve(so, &so->so_snd, bufsize);\n\t}\n\n\tbufsize = so->so_rcv.sb_hiwat;\n\tif (bufsize > mss) {\n\t\tbufsize = roundup(bufsize, mss);\n\t\tif (bufsize > sb_max)\n\t\t\tbufsize = sb_max;\n\t\t(void)sbreserve(so, &so->so_rcv, bufsize);\n\t}\n\n}\n\n/*\n * When a partial ack arrives, force the retransmission of the\n * next unacknowledged segment.  Do not clear tp->t_dupacks.\n * By setting snd_nxt to ti_ack, this forces retransmission timer\n * to be started again.\n */\nvoid\ntcp_newreno_partialack(struct tcpcb *tp, struct tcphdr *th)\n{\n\t/*\n\t * snd_una has not been updated and the socket send buffer\n\t * not yet drained of the acked data, so we have to leave\n\t * snd_una as it was to get the correct data offset in\n\t * tcp_output().\n\t */\n\ttcp_seq onxt = tp->snd_nxt;\n\tu_long  ocwnd = tp->snd_cwnd;\n\n\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\ttp->t_rtttime = 0;\n\ttp->snd_nxt = th->th_ack;\n\t/*\n\t * Set snd_cwnd to one segment beyond acknowledged offset\n\t * (tp->snd_una not yet updated when this function is called)\n\t */\n\ttp->snd_cwnd = tp->t_maxseg + (th->th_ack - tp->snd_una);\n\t(void)tcp_output(tp);\n\ttp->snd_cwnd = ocwnd;\n\tif (SEQ_GT(onxt, tp->snd_nxt))\n\t\ttp->snd_nxt = onxt;\n\t/*\n\t * Partial window deflation.  Relies on fact that tp->snd_una\n\t * not updated yet.\n\t */\n\tif (tp->snd_cwnd > th->th_ack - tp->snd_una)\n\t\ttp->snd_cwnd -= th->th_ack - tp->snd_una;\n\telse\n\t\ttp->snd_cwnd = 0;\n\ttp->snd_cwnd += tp->t_maxseg;\n}\n\nint\ntcp_mss_adv(struct mbuf *m, int af)\n{\n\tint mss = 0;\n\tint iphlen;\n\tstruct ifnet *ifp = NULL;\n\n\tif (m && (m->m_flags & M_PKTHDR))\n\t\tifp = if_get(m->m_pkthdr.ph_ifidx);\n\n\tswitch (af) {\n\tcase AF_INET:\n\t\tif (ifp != NULL)\n\t\t\tmss = ifp->if_mtu;\n\t\tiphlen = sizeof(struct ip);\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tif (ifp != NULL)\n\t\t\tmss = ifp->if_mtu;\n\t\tiphlen = sizeof(struct ip6_hdr);\n\t\tbreak;\n#endif  \n\tdefault:\n\t\tunhandled_af(af);\n\t}\n\tif_put(ifp);\n\tmss = mss - iphlen - sizeof(struct tcphdr);\n\treturn (max(mss, tcp_mssdflt));\n}\n\n/*\n * TCP compressed state engine.  Currently used to hold compressed\n * state for SYN_RECEIVED.\n */\n\n/* syn hash parameters */\nint\ttcp_syn_hash_size = TCP_SYN_HASH_SIZE;\nint\ttcp_syn_cache_limit = TCP_SYN_HASH_SIZE*TCP_SYN_BUCKET_SIZE;\nint\ttcp_syn_bucket_limit = 3*TCP_SYN_BUCKET_SIZE;\nint\ttcp_syn_use_limit = 100000;\n\nstruct syn_cache_set tcp_syn_cache[2];\nint tcp_syn_cache_active;\n\n#define SYN_HASH(sa, sp, dp, rand) \\\n\t(((sa)->s_addr ^ (rand)[0]) *\t\t\t\t\\\n\t(((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp))) ^ (rand)[4]))\n#ifndef INET6\n#define\tSYN_HASHALL(hash, src, dst, rand) \\\ndo {\t\t\t\t\t\t\t\t\t\\\n\thash = SYN_HASH(&satosin(src)->sin_addr,\t\t\t\\\n\t\tsatosin(src)->sin_port,\t\t\t\t\t\\\n\t\tsatosin(dst)->sin_port, (rand));\t\t\t\\\n} while (/*CONSTCOND*/ 0)\n#else\n#define SYN_HASH6(sa, sp, dp, rand) \\\n\t(((sa)->s6_addr32[0] ^ (rand)[0]) *\t\t\t\\\n\t((sa)->s6_addr32[1] ^ (rand)[1]) *\t\t\t\\\n\t((sa)->s6_addr32[2] ^ (rand)[2]) *\t\t\t\\\n\t((sa)->s6_addr32[3] ^ (rand)[3]) *\t\t\t\\\n\t(((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp))) ^ (rand)[4]))\n\n#define SYN_HASHALL(hash, src, dst, rand) \\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tswitch ((src)->sa_family) {\t\t\t\t\t\\\n\tcase AF_INET:\t\t\t\t\t\t\t\\\n\t\thash = SYN_HASH(&satosin(src)->sin_addr,\t\t\\\n\t\t\tsatosin(src)->sin_port,\t\t\t\t\\\n\t\t\tsatosin(dst)->sin_port, (rand));\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase AF_INET6:\t\t\t\t\t\t\t\\\n\t\thash = SYN_HASH6(&satosin6(src)->sin6_addr,\t\t\\\n\t\t\tsatosin6(src)->sin6_port,\t\t\t\\\n\t\t\tsatosin6(dst)->sin6_port, (rand));\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tdefault:\t\t\t\t\t\t\t\\\n\t\thash = 0;\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (/*CONSTCOND*/0)\n#endif /* INET6 */\n\nvoid\nsyn_cache_rm(struct syn_cache *sc)\n{\n\tsc->sc_flags |= SCF_DEAD;\n\tTAILQ_REMOVE(&sc->sc_buckethead->sch_bucket, sc, sc_bucketq);\n\tsc->sc_tp = NULL;\n\tLIST_REMOVE(sc, sc_tpq);\n\tsc->sc_buckethead->sch_length--;\n\ttimeout_del(&sc->sc_timer);\n\tsc->sc_set->scs_count--;\n}\n\nvoid\nsyn_cache_put(struct syn_cache *sc)\n{\n\tm_free(sc->sc_ipopts);\n\tif (sc->sc_route4.ro_rt != NULL) {\n\t\trtfree(sc->sc_route4.ro_rt);\n\t\tsc->sc_route4.ro_rt = NULL;\n\t}\n\ttimeout_set(&sc->sc_timer, syn_cache_reaper, sc);\n\ttimeout_add(&sc->sc_timer, 0);\n}\n\nstruct pool syn_cache_pool;\n\n/*\n * We don't estimate RTT with SYNs, so each packet starts with the default\n * RTT and each timer step has a fixed timeout value.\n */\n#define\tSYN_CACHE_TIMER_ARM(sc)\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tTCPT_RANGESET((sc)->sc_rxtcur,\t\t\t\t\t\\\n\t    TCPTV_SRTTDFLT * tcp_backoff[(sc)->sc_rxtshift], TCPTV_MIN,\t\\\n\t    TCPTV_REXMTMAX);\t\t\t\t\t\t\\\n\tif (!timeout_initialized(&(sc)->sc_timer))\t\t\t\\\n\t\ttimeout_set_proc(&(sc)->sc_timer, syn_cache_timer, (sc)); \\\n\ttimeout_add(&(sc)->sc_timer, (sc)->sc_rxtcur * (hz / PR_SLOWHZ)); \\\n} while (/*CONSTCOND*/0)\n\n#define\tSYN_CACHE_TIMESTAMP(sc)\ttcp_now + (sc)->sc_modulate\n\nvoid\nsyn_cache_init(void)\n{\n\tint i;\n\n\t/* Initialize the hash buckets. */\n\ttcp_syn_cache[0].scs_buckethead = mallocarray(tcp_syn_hash_size,\n\t    sizeof(struct syn_cache_head), M_SYNCACHE, M_WAITOK|M_ZERO);\n\ttcp_syn_cache[1].scs_buckethead = mallocarray(tcp_syn_hash_size,\n\t    sizeof(struct syn_cache_head), M_SYNCACHE, M_WAITOK|M_ZERO);\n\ttcp_syn_cache[0].scs_size = tcp_syn_hash_size;\n\ttcp_syn_cache[1].scs_size = tcp_syn_hash_size;\n\tfor (i = 0; i < tcp_syn_hash_size; i++) {\n\t\tTAILQ_INIT(&tcp_syn_cache[0].scs_buckethead[i].sch_bucket);\n\t\tTAILQ_INIT(&tcp_syn_cache[1].scs_buckethead[i].sch_bucket);\n\t}\n\n\t/* Initialize the syn cache pool. */\n\tpool_init(&syn_cache_pool, sizeof(struct syn_cache), 0, IPL_SOFTNET,\n\t    0, \"syncache\", NULL);\n}\n\nvoid\nsyn_cache_insert(struct syn_cache *sc, struct tcpcb *tp)\n{\n\tstruct syn_cache_set *set = &tcp_syn_cache[tcp_syn_cache_active];\n\tstruct syn_cache_head *scp;\n\tstruct syn_cache *sc2;\n\tint i;\n\n\tNET_ASSERT_LOCKED();\n\n\t/*\n\t * If there are no entries in the hash table, reinitialize\n\t * the hash secrets.  To avoid useless cache swaps and\n\t * reinitialization, use it until the limit is reached.\n\t * An emtpy cache is also the oportunity to resize the hash.\n\t */\n\tif (set->scs_count == 0 && set->scs_use <= 0) {\n\t\tset->scs_use = tcp_syn_use_limit;\n\t\tif (set->scs_size != tcp_syn_hash_size) {\n\t\t\tscp = mallocarray(tcp_syn_hash_size, sizeof(struct\n\t\t\t    syn_cache_head), M_SYNCACHE, M_NOWAIT|M_ZERO);\n\t\t\tif (scp == NULL) {\n\t\t\t\t/* Try again next time. */\n\t\t\t\tset->scs_use = 0;\n\t\t\t} else {\n\t\t\t\tfree(set->scs_buckethead, M_SYNCACHE,\n\t\t\t\t    set->scs_size *\n\t\t\t\t    sizeof(struct syn_cache_head));\n\t\t\t\tset->scs_buckethead = scp;\n\t\t\t\tset->scs_size = tcp_syn_hash_size;\n\t\t\t\tfor (i = 0; i < tcp_syn_hash_size; i++)\n\t\t\t\t\tTAILQ_INIT(&scp[i].sch_bucket);\n\t\t\t}\n\t\t}\n\t\tarc4random_buf(set->scs_random, sizeof(set->scs_random));\n\t\ttcpstat_inc(tcps_sc_seedrandom);\n\t}\n\n\tSYN_HASHALL(sc->sc_hash, &sc->sc_src.sa, &sc->sc_dst.sa,\n\t    set->scs_random);\n\tscp = &set->scs_buckethead[sc->sc_hash % set->scs_size];\n\tsc->sc_buckethead = scp;\n\n\t/*\n\t * Make sure that we don't overflow the per-bucket\n\t * limit or the total cache size limit.\n\t */\n\tif (scp->sch_length >= tcp_syn_bucket_limit) {\n\t\ttcpstat_inc(tcps_sc_bucketoverflow);\n\t\t/*\n\t\t * Someone might attack our bucket hash function.  Reseed\n\t\t * with random as soon as the passive syn cache gets empty.\n\t\t */\n\t\tset->scs_use = 0;\n\t\t/*\n\t\t * The bucket is full.  Toss the oldest element in the\n\t\t * bucket.  This will be the first entry in the bucket.\n\t\t */\n\t\tsc2 = TAILQ_FIRST(&scp->sch_bucket);\n#ifdef DIAGNOSTIC\n\t\t/*\n\t\t * This should never happen; we should always find an\n\t\t * entry in our bucket.\n\t\t */\n\t\tif (sc2 == NULL)\n\t\t\tpanic(\"%s: bucketoverflow: impossible\", __func__);\n#endif\n\t\tsyn_cache_rm(sc2);\n\t\tsyn_cache_put(sc2);\n\t} else if (set->scs_count >= tcp_syn_cache_limit) {\n\t\tstruct syn_cache_head *scp2, *sce;\n\n\t\ttcpstat_inc(tcps_sc_overflowed);\n\t\t/*\n\t\t * The cache is full.  Toss the oldest entry in the\n\t\t * first non-empty bucket we can find.\n\t\t *\n\t\t * XXX We would really like to toss the oldest\n\t\t * entry in the cache, but we hope that this\n\t\t * condition doesn't happen very often.\n\t\t */\n\t\tscp2 = scp;\n\t\tif (TAILQ_EMPTY(&scp2->sch_bucket)) {\n\t\t\tsce = &set->scs_buckethead[set->scs_size];\n\t\t\tfor (++scp2; scp2 != scp; scp2++) {\n\t\t\t\tif (scp2 >= sce)\n\t\t\t\t\tscp2 = &set->scs_buckethead[0];\n\t\t\t\tif (! TAILQ_EMPTY(&scp2->sch_bucket))\n\t\t\t\t\tbreak;\n\t\t\t}\n#ifdef DIAGNOSTIC\n\t\t\t/*\n\t\t\t * This should never happen; we should always find a\n\t\t\t * non-empty bucket.\n\t\t\t */\n\t\t\tif (scp2 == scp)\n\t\t\t\tpanic(\"%s: cacheoverflow: impossible\",\n\t\t\t\t    __func__);\n#endif\n\t\t}\n\t\tsc2 = TAILQ_FIRST(&scp2->sch_bucket);\n\t\tsyn_cache_rm(sc2);\n\t\tsyn_cache_put(sc2);\n\t}\n\n\t/*\n\t * Initialize the entry's timer.\n\t */\n\tsc->sc_rxttot = 0;\n\tsc->sc_rxtshift = 0;\n\tSYN_CACHE_TIMER_ARM(sc);\n\n\t/* Link it from tcpcb entry */\n\tLIST_INSERT_HEAD(&tp->t_sc, sc, sc_tpq);\n\n\t/* Put it into the bucket. */\n\tTAILQ_INSERT_TAIL(&scp->sch_bucket, sc, sc_bucketq);\n\tscp->sch_length++;\n\tsc->sc_set = set;\n\tset->scs_count++;\n\tset->scs_use--;\n\n\ttcpstat_inc(tcps_sc_added);\n\n\t/*\n\t * If the active cache has exceeded its use limit and\n\t * the passive syn cache is empty, exchange their roles.\n\t */\n\tif (set->scs_use <= 0 &&\n\t    tcp_syn_cache[!tcp_syn_cache_active].scs_count == 0)\n\t\ttcp_syn_cache_active = !tcp_syn_cache_active;\n}\n\n/*\n * Walk the timer queues, looking for SYN,ACKs that need to be retransmitted.\n * If we have retransmitted an entry the maximum number of times, expire\n * that entry.\n */\nvoid\nsyn_cache_timer(void *arg)\n{\n\tstruct syn_cache *sc = arg;\n\n\tNET_LOCK();\n\tif (sc->sc_flags & SCF_DEAD)\n\t\tgoto out;\n\n\tif (__predict_false(sc->sc_rxtshift == TCP_MAXRXTSHIFT)) {\n\t\t/* Drop it -- too many retransmissions. */\n\t\tgoto dropit;\n\t}\n\n\t/*\n\t * Compute the total amount of time this entry has\n\t * been on a queue.  If this entry has been on longer\n\t * than the keep alive timer would allow, expire it.\n\t */\n\tsc->sc_rxttot += sc->sc_rxtcur;\n\tif (sc->sc_rxttot >= tcptv_keep_init)\n\t\tgoto dropit;\n\n\ttcpstat_inc(tcps_sc_retransmitted);\n\t(void) syn_cache_respond(sc, NULL);\n\n\t/* Advance the timer back-off. */\n\tsc->sc_rxtshift++;\n\tSYN_CACHE_TIMER_ARM(sc);\n\n out:\n\tNET_UNLOCK();\n\treturn;\n\n dropit:\n\ttcpstat_inc(tcps_sc_timed_out);\n\tsyn_cache_rm(sc);\n\tsyn_cache_put(sc);\n\tNET_UNLOCK();\n}\n\nvoid\nsyn_cache_reaper(void *arg)\n{\n\tstruct syn_cache *sc = arg;\n\n\tpool_put(&syn_cache_pool, (sc));\n\treturn;\n}\n\n/*\n * Remove syn cache created by the specified tcb entry,\n * because this does not make sense to keep them\n * (if there's no tcb entry, syn cache entry will never be used)\n */\nvoid\nsyn_cache_cleanup(struct tcpcb *tp)\n{\n\tstruct syn_cache *sc, *nsc;\n\n\tNET_ASSERT_LOCKED();\n\n\tLIST_FOREACH_SAFE(sc, &tp->t_sc, sc_tpq, nsc) {\n#ifdef DIAGNOSTIC\n\t\tif (sc->sc_tp != tp)\n\t\t\tpanic(\"invalid sc_tp in syn_cache_cleanup\");\n#endif\n\t\tsyn_cache_rm(sc);\n\t\tsyn_cache_put(sc);\n\t}\n\t/* just for safety */\n\tLIST_INIT(&tp->t_sc);\n}\n\n/*\n * Find an entry in the syn cache.\n */\nstruct syn_cache *\nsyn_cache_lookup(struct sockaddr *src, struct sockaddr *dst,\n    struct syn_cache_head **headp, u_int rtableid)\n{\n\tstruct syn_cache_set *sets[2];\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\tu_int32_t hash;\n\tint i;\n\n\tNET_ASSERT_LOCKED();\n\n\t/* Check the active cache first, the passive cache is likely emtpy. */\n\tsets[0] = &tcp_syn_cache[tcp_syn_cache_active];\n\tsets[1] = &tcp_syn_cache[!tcp_syn_cache_active];\n\tfor (i = 0; i < 2; i++) {\n\t\tif (sets[i]->scs_count == 0)\n\t\t\tcontinue;\n\t\tSYN_HASHALL(hash, src, dst, sets[i]->scs_random);\n\t\tscp = &sets[i]->scs_buckethead[hash % sets[i]->scs_size];\n\t\t*headp = scp;\n\t\tTAILQ_FOREACH(sc, &scp->sch_bucket, sc_bucketq) {\n\t\t\tif (sc->sc_hash != hash)\n\t\t\t\tcontinue;\n\t\t\tif (!bcmp(&sc->sc_src, src, src->sa_len) &&\n\t\t\t    !bcmp(&sc->sc_dst, dst, dst->sa_len) &&\n\t\t\t    rtable_l2(rtableid) == rtable_l2(sc->sc_rtableid))\n\t\t\t\treturn (sc);\n\t\t}\n\t}\n\treturn (NULL);\n}\n\n/*\n * This function gets called when we receive an ACK for a\n * socket in the LISTEN state.  We look up the connection\n * in the syn cache, and if its there, we pull it out of\n * the cache and turn it into a full-blown connection in\n * the SYN-RECEIVED state.\n *\n * The return values may not be immediately obvious, and their effects\n * can be subtle, so here they are:\n *\n *\tNULL\tSYN was not found in cache; caller should drop the\n *\t\tpacket and send an RST.\n *\n *\t-1\tWe were unable to create the new connection, and are\n *\t\taborting it.  An ACK,RST is being sent to the peer\n *\t\t(unless we got screwey sequence numbners; see below),\n *\t\tbecause the 3-way handshake has been completed.  Caller\n *\t\tshould not free the mbuf, since we may be using it.  If\n *\t\twe are not, we will free it.\n *\n *\tOtherwise, the return value is a pointer to the new socket\n *\tassociated with the connection.\n */\nstruct socket *\nsyn_cache_get(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,\n    u_int hlen, u_int tlen, struct socket *so, struct mbuf *m)\n{\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\tstruct inpcb *inp, *oldinp;\n\tstruct tcpcb *tp = NULL;\n\tstruct mbuf *am;\n\tstruct socket *oso;\n\n\tNET_ASSERT_LOCKED();\n\n\tsc = syn_cache_lookup(src, dst, &scp, sotoinpcb(so)->inp_rtableid);\n\tif (sc == NULL)\n\t\treturn (NULL);\n\n\t/*\n\t * Verify the sequence and ack numbers.  Try getting the correct\n\t * response again.\n\t */\n\tif ((th->th_ack != sc->sc_iss + 1) ||\n\t    SEQ_LEQ(th->th_seq, sc->sc_irs) ||\n\t    SEQ_GT(th->th_seq, sc->sc_irs + 1 + sc->sc_win)) {\n\t\t(void) syn_cache_respond(sc, m);\n\t\treturn ((struct socket *)(-1));\n\t}\n\n\t/* Remove this cache entry */\n\tsyn_cache_rm(sc);\n\n\t/*\n\t * Ok, create the full blown connection, and set things up\n\t * as they would have been set up if we had created the\n\t * connection when the SYN arrived.  If we can't create\n\t * the connection, abort it.\n\t */\n\toso = so;\n\tso = sonewconn(so, SS_ISCONNECTED);\n\tif (so == NULL)\n\t\tgoto resetandabort;\n\n\toldinp = sotoinpcb(oso);\n\tinp = sotoinpcb(so);\n\n#ifdef IPSEC\n\t/*\n\t * We need to copy the required security levels\n\t * from the old pcb. Ditto for any other\n\t * IPsec-related information.\n\t */\n\tmemcpy(inp->inp_seclevel, oldinp->inp_seclevel,\n\t    sizeof(oldinp->inp_seclevel));\n#endif /* IPSEC */\n#ifdef INET6\n\t/*\n\t * inp still has the OLD in_pcb stuff, set the\n\t * v6-related flags on the new guy, too.\n\t */\n\tinp->inp_flags |= (oldinp->inp_flags & INP_IPV6);\n\tif (inp->inp_flags & INP_IPV6) {\n\t\tinp->inp_ipv6.ip6_hlim = oldinp->inp_ipv6.ip6_hlim;\n\t\tinp->inp_hops = oldinp->inp_hops;\n\t} else\n#endif /* INET6 */\n\t{\n\t\tinp->inp_ip.ip_ttl = oldinp->inp_ip.ip_ttl;\n\t}\n\n#if NPF > 0\n\tif (m->m_pkthdr.pf.flags & PF_TAG_DIVERTED) {\n\t\tstruct pf_divert *divert;\n\n\t\tdivert = pf_find_divert(m);\n\t\tKASSERT(divert != NULL);\n\t\tinp->inp_rtableid = divert->rdomain;\n\t} else\n#endif\n\t/* inherit rtable from listening socket */\n\tinp->inp_rtableid = sc->sc_rtableid;\n\n\tinp->inp_lport = th->th_dport;\n\tswitch (src->sa_family) {\n#ifdef INET6\n\tcase AF_INET6:\n\t\tinp->inp_laddr6 = satosin6(dst)->sin6_addr;\n\t\tbreak;\n#endif /* INET6 */\n\tcase AF_INET:\n\t\tinp->inp_laddr = satosin(dst)->sin_addr;\n\t\tinp->inp_options = ip_srcroute(m);\n\t\tif (inp->inp_options == NULL) {\n\t\t\tinp->inp_options = sc->sc_ipopts;\n\t\t\tsc->sc_ipopts = NULL;\n\t\t}\n\t\tbreak;\n\t}\n\tin_pcbrehash(inp);\n\n\t/*\n\t * Give the new socket our cached route reference.\n\t */\n\tif (src->sa_family == AF_INET)\n\t\tinp->inp_route = sc->sc_route4;         /* struct assignment */\n#ifdef INET6\n\telse\n\t\tinp->inp_route6 = sc->sc_route6;\n#endif\n\tsc->sc_route4.ro_rt = NULL;\n\n\tam = m_get(M_DONTWAIT, MT_SONAME);\t/* XXX */\n\tif (am == NULL)\n\t\tgoto resetandabort;\n\tam->m_len = src->sa_len;\n\tmemcpy(mtod(am, caddr_t), src, src->sa_len);\n\tif (in_pcbconnect(inp, am)) {\n\t\t(void) m_free(am);\n\t\tgoto resetandabort;\n\t}\n\t(void) m_free(am);\n\n\ttp = intotcpcb(inp);\n\ttp->t_flags = sototcpcb(oso)->t_flags & (TF_NOPUSH|TF_NODELAY);\n\tif (sc->sc_request_r_scale != 15) {\n\t\ttp->requested_s_scale = sc->sc_requested_s_scale;\n\t\ttp->request_r_scale = sc->sc_request_r_scale;\n\t\ttp->t_flags |= TF_REQ_SCALE|TF_RCVD_SCALE;\n\t}\n\tif (sc->sc_flags & SCF_TIMESTAMP)\n\t\ttp->t_flags |= TF_REQ_TSTMP|TF_RCVD_TSTMP;\n\n\ttp->t_template = tcp_template(tp);\n\tif (tp->t_template == 0) {\n\t\ttp = tcp_drop(tp, ENOBUFS);\t/* destroys socket */\n\t\tso = NULL;\n\t\tgoto abort;\n\t}\n\ttp->sack_enable = sc->sc_flags & SCF_SACK_PERMIT;\n\ttp->ts_modulate = sc->sc_modulate;\n\ttp->ts_recent = sc->sc_timestamp;\n\ttp->iss = sc->sc_iss;\n\ttp->irs = sc->sc_irs;\n\ttcp_sendseqinit(tp);\n\ttp->snd_last = tp->snd_una;\n#ifdef TCP_ECN\n\tif (sc->sc_flags & SCF_ECN_PERMIT) {\n\t\ttp->t_flags |= TF_ECN_PERMIT;\n\t\ttcpstat_inc(tcps_ecn_accepts);\n\t}\n#endif\n\tif (sc->sc_flags & SCF_SACK_PERMIT)\n\t\ttp->t_flags |= TF_SACK_PERMIT;\n#ifdef TCP_SIGNATURE\n\tif (sc->sc_flags & SCF_SIGNATURE)\n\t\ttp->t_flags |= TF_SIGNATURE;\n#endif\n\ttcp_rcvseqinit(tp);\n\ttp->t_state = TCPS_SYN_RECEIVED;\n\ttp->t_rcvtime = tcp_now;\n\tTCP_TIMER_ARM(tp, TCPT_KEEP, tcptv_keep_init);\n\ttcpstat_inc(tcps_accepts);\n\n\ttcp_mss(tp, sc->sc_peermaxseg);\t /* sets t_maxseg */\n\tif (sc->sc_peermaxseg)\n\t\ttcp_mss_update(tp);\n\t/* Reset initial window to 1 segment for retransmit */\n\tif (sc->sc_rxtshift > 0)\n\t\ttp->snd_cwnd = tp->t_maxseg;\n\ttp->snd_wl1 = sc->sc_irs;\n\ttp->rcv_up = sc->sc_irs + 1;\n\n\t/*\n\t * This is what whould have happened in tcp_output() when\n\t * the SYN,ACK was sent.\n\t */\n\ttp->snd_up = tp->snd_una;\n\ttp->snd_max = tp->snd_nxt = tp->iss+1;\n\tTCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);\n\tif (sc->sc_win > 0 && SEQ_GT(tp->rcv_nxt + sc->sc_win, tp->rcv_adv))\n\t\ttp->rcv_adv = tp->rcv_nxt + sc->sc_win;\n\ttp->last_ack_sent = tp->rcv_nxt;\n\n\ttcpstat_inc(tcps_sc_completed);\n\tsyn_cache_put(sc);\n\treturn (so);\n\nresetandabort:\n\ttcp_respond(NULL, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack, TH_RST,\n\t    m->m_pkthdr.ph_rtableid);\nabort:\n\tm_freem(m);\n\tif (so != NULL)\n\t\t(void) soabort(so);\n\tsyn_cache_put(sc);\n\ttcpstat_inc(tcps_sc_aborted);\n\treturn ((struct socket *)(-1));\n}\n\n/*\n * This function is called when we get a RST for a\n * non-existent connection, so that we can see if the\n * connection is in the syn cache.  If it is, zap it.\n */\n\nvoid\nsyn_cache_reset(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,\n    u_int rtableid)\n{\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\n\tNET_ASSERT_LOCKED();\n\n\tif ((sc = syn_cache_lookup(src, dst, &scp, rtableid)) == NULL)\n\t\treturn;\n\tif (SEQ_LT(th->th_seq, sc->sc_irs) ||\n\t    SEQ_GT(th->th_seq, sc->sc_irs + 1))\n\t\treturn;\n\tsyn_cache_rm(sc);\n\ttcpstat_inc(tcps_sc_reset);\n\tsyn_cache_put(sc);\n}\n\nvoid\nsyn_cache_unreach(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,\n    u_int rtableid)\n{\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\n\tNET_ASSERT_LOCKED();\n\n\tif ((sc = syn_cache_lookup(src, dst, &scp, rtableid)) == NULL)\n\t\treturn;\n\t/* If the sequence number != sc_iss, then it's a bogus ICMP msg */\n\tif (ntohl (th->th_seq) != sc->sc_iss) {\n\t\treturn;\n\t}\n\n\t/*\n\t * If we've retransmitted 3 times and this is our second error,\n\t * we remove the entry.  Otherwise, we allow it to continue on.\n\t * This prevents us from incorrectly nuking an entry during a\n\t * spurious network outage.\n\t *\n\t * See tcp_notify().\n\t */\n\tif ((sc->sc_flags & SCF_UNREACH) == 0 || sc->sc_rxtshift < 3) {\n\t\tsc->sc_flags |= SCF_UNREACH;\n\t\treturn;\n\t}\n\n\tsyn_cache_rm(sc);\n\ttcpstat_inc(tcps_sc_unreach);\n\tsyn_cache_put(sc);\n}\n\n/*\n * Given a LISTEN socket and an inbound SYN request, add\n * this to the syn cache, and send back a segment:\n *\t<SEQ=ISS><ACK=RCV_NXT><CTL=SYN,ACK>\n * to the source.\n *\n * IMPORTANT NOTE: We do _NOT_ ACK data that might accompany the SYN.\n * Doing so would require that we hold onto the data and deliver it\n * to the application.  However, if we are the target of a SYN-flood\n * DoS attack, an attacker could send data which would eventually\n * consume all available buffer space if it were ACKed.  By not ACKing\n * the data, we avoid this DoS scenario.\n */\n\nint\nsyn_cache_add(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,\n    u_int iphlen, struct socket *so, struct mbuf *m, u_char *optp, int optlen,\n    struct tcp_opt_info *oi, tcp_seq *issp)\n{\n\tstruct tcpcb tb, *tp;\n\tlong win;\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\tstruct mbuf *ipopts;\n\n\ttp = sototcpcb(so);\n\n\t/*\n\t * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN\n\t *\n\t * Note this check is performed in tcp_input() very early on.\n\t */\n\n\t/*\n\t * Initialize some local state.\n\t */\n\twin = sbspace(so, &so->so_rcv);\n\tif (win > TCP_MAXWIN)\n\t\twin = TCP_MAXWIN;\n\n\tbzero(&tb, sizeof(tb));\n#ifdef TCP_SIGNATURE\n\tif (optp || (tp->t_flags & TF_SIGNATURE)) {\n#else\n\tif (optp) {\n#endif\n\t\ttb.pf = tp->pf;\n\t\ttb.sack_enable = tp->sack_enable;\n\t\ttb.t_flags = tcp_do_rfc1323 ? (TF_REQ_SCALE|TF_REQ_TSTMP) : 0;\n#ifdef TCP_SIGNATURE\n\t\tif (tp->t_flags & TF_SIGNATURE)\n\t\t\ttb.t_flags |= TF_SIGNATURE;\n#endif\n\t\ttb.t_state = TCPS_LISTEN;\n\t\tif (tcp_dooptions(&tb, optp, optlen, th, m, iphlen, oi,\n\t\t    sotoinpcb(so)->inp_rtableid))\n\t\t\treturn (-1);\n\t}\n\n\tswitch (src->sa_family) {\n\tcase AF_INET:\n\t\t/*\n\t\t * Remember the IP options, if any.\n\t\t */\n\t\tipopts = ip_srcroute(m);\n\t\tbreak;\n\tdefault:\n\t\tipopts = NULL;\n\t}\n\n\t/*\n\t * See if we already have an entry for this connection.\n\t * If we do, resend the SYN,ACK.  We do not count this\n\t * as a retransmission (XXX though maybe we should).\n\t */\n\tsc = syn_cache_lookup(src, dst, &scp, sotoinpcb(so)->inp_rtableid);\n\tif (sc != NULL) {\n\t\ttcpstat_inc(tcps_sc_dupesyn);\n\t\tif (ipopts) {\n\t\t\t/*\n\t\t\t * If we were remembering a previous source route,\n\t\t\t * forget it and use the new one we've been given.\n\t\t\t */\n\t\t\tm_free(sc->sc_ipopts);\n\t\t\tsc->sc_ipopts = ipopts;\n\t\t}\n\t\tsc->sc_timestamp = tb.ts_recent;\n\t\tif (syn_cache_respond(sc, m) == 0) {\n\t\t\ttcpstat_inc(tcps_sndacks);\n\t\t\ttcpstat_inc(tcps_sndtotal);\n\t\t}\n\t\treturn (0);\n\t}\n\n\tsc = pool_get(&syn_cache_pool, PR_NOWAIT|PR_ZERO);\n\tif (sc == NULL) {\n\t\tm_free(ipopts);\n\t\treturn (-1);\n\t}\n\n\t/*\n\t * Fill in the cache, and put the necessary IP and TCP\n\t * options into the reply.\n\t */\n\tmemcpy(&sc->sc_src, src, src->sa_len);\n\tmemcpy(&sc->sc_dst, dst, dst->sa_len);\n\tsc->sc_rtableid = sotoinpcb(so)->inp_rtableid;\n\tsc->sc_flags = 0;\n\tsc->sc_ipopts = ipopts;\n\tsc->sc_irs = th->th_seq;\n\n\tsc->sc_iss = issp ? *issp : arc4random();\n\tsc->sc_peermaxseg = oi->maxseg;\n\tsc->sc_ourmaxseg = tcp_mss_adv(m, sc->sc_src.sa.sa_family);\n\tsc->sc_win = win;\n\tsc->sc_timestamp = tb.ts_recent;\n\tif ((tb.t_flags & (TF_REQ_TSTMP|TF_RCVD_TSTMP)) ==\n\t    (TF_REQ_TSTMP|TF_RCVD_TSTMP)) {\n\t\tsc->sc_flags |= SCF_TIMESTAMP;\n\t\tsc->sc_modulate = arc4random();\n\t}\n\tif ((tb.t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==\n\t    (TF_RCVD_SCALE|TF_REQ_SCALE)) {\n\t\tsc->sc_requested_s_scale = tb.requested_s_scale;\n\t\tsc->sc_request_r_scale = 0;\n\t\t/*\n\t\t * Pick the smallest possible scaling factor that\n\t\t * will still allow us to scale up to sb_max.\n\t\t *\n\t\t * We do this because there are broken firewalls that\n\t\t * will corrupt the window scale option, leading to\n\t\t * the other endpoint believing that our advertised\n\t\t * window is unscaled.  At scale factors larger than\n\t\t * 5 the unscaled window will drop below 1500 bytes,\n\t\t * leading to serious problems when traversing these\n\t\t * broken firewalls.\n\t\t *\n\t\t * With the default sbmax of 256K, a scale factor\n\t\t * of 3 will be chosen by this algorithm.  Those who\n\t\t * choose a larger sbmax should watch out\n\t\t * for the compatiblity problems mentioned above.\n\t\t *\n\t\t * RFC1323: The Window field in a SYN (i.e., a <SYN>\n\t\t * or <SYN,ACK>) segment itself is never scaled.\n\t\t */\n\t\twhile (sc->sc_request_r_scale < TCP_MAX_WINSHIFT &&\n\t\t    (TCP_MAXWIN << sc->sc_request_r_scale) < sb_max)\n\t\t\tsc->sc_request_r_scale++;\n\t} else {\n\t\tsc->sc_requested_s_scale = 15;\n\t\tsc->sc_request_r_scale = 15;\n\t}\n#ifdef TCP_ECN\n\t/*\n\t * if both ECE and CWR flag bits are set, peer is ECN capable.\n\t */\n\tif (tcp_do_ecn &&\n\t    (th->th_flags & (TH_ECE|TH_CWR)) == (TH_ECE|TH_CWR))\n\t\tsc->sc_flags |= SCF_ECN_PERMIT;\n#endif\n\t/*\n\t * Set SCF_SACK_PERMIT if peer did send a SACK_PERMITTED option\n\t * (i.e., if tcp_dooptions() did set TF_SACK_PERMIT).\n\t */\n\tif (tb.sack_enable && (tb.t_flags & TF_SACK_PERMIT))\n\t\tsc->sc_flags |= SCF_SACK_PERMIT;\n#ifdef TCP_SIGNATURE\n\tif (tb.t_flags & TF_SIGNATURE)\n\t\tsc->sc_flags |= SCF_SIGNATURE;\n#endif\n\tsc->sc_tp = tp;\n\tif (syn_cache_respond(sc, m) == 0) {\n\t\tsyn_cache_insert(sc, tp);\n\t\ttcpstat_inc(tcps_sndacks);\n\t\ttcpstat_inc(tcps_sndtotal);\n\t} else {\n\t\tsyn_cache_put(sc);\n\t\ttcpstat_inc(tcps_sc_dropped);\n\t}\n\n\treturn (0);\n}\n\nint\nsyn_cache_respond(struct syn_cache *sc, struct mbuf *m)\n{\n\tu_int8_t *optp;\n\tint optlen, error;\n\tu_int16_t tlen;\n\tstruct ip *ip = NULL;\n#ifdef INET6\n\tstruct ip6_hdr *ip6 = NULL;\n#endif\n\tstruct tcphdr *th;\n\tu_int hlen;\n\tstruct inpcb *inp;\n\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\thlen = sizeof(struct ip);\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\thlen = sizeof(struct ip6_hdr);\n\t\tbreak;\n#endif\n\tdefault:\n\t\tm_freem(m);\n\t\treturn (EAFNOSUPPORT);\n\t}\n\n\t/* Compute the size of the TCP options. */\n\toptlen = 4 + (sc->sc_request_r_scale != 15 ? 4 : 0) +\n\t    ((sc->sc_flags & SCF_SACK_PERMIT) ? 4 : 0) +\n#ifdef TCP_SIGNATURE\n\t    ((sc->sc_flags & SCF_SIGNATURE) ? TCPOLEN_SIGLEN : 0) +\n#endif\n\t    ((sc->sc_flags & SCF_TIMESTAMP) ? TCPOLEN_TSTAMP_APPA : 0);\n\n\ttlen = hlen + sizeof(struct tcphdr) + optlen;\n\n\t/*\n\t * Create the IP+TCP header from scratch.\n\t */\n\tm_freem(m);\n#ifdef DIAGNOSTIC\n\tif (max_linkhdr + tlen > MCLBYTES)\n\t\treturn (ENOBUFS);\n#endif\n\tMGETHDR(m, M_DONTWAIT, MT_DATA);\n\tif (m && max_linkhdr + tlen > MHLEN) {\n\t\tMCLGET(m, M_DONTWAIT);\n\t\tif ((m->m_flags & M_EXT) == 0) {\n\t\t\tm_freem(m);\n\t\t\tm = NULL;\n\t\t}\n\t}\n\tif (m == NULL)\n\t\treturn (ENOBUFS);\n\n\t/* Fixup the mbuf. */\n\tm->m_data += max_linkhdr;\n\tm->m_len = m->m_pkthdr.len = tlen;\n\tm->m_pkthdr.ph_ifidx = 0;\n\tm->m_pkthdr.ph_rtableid = sc->sc_rtableid;\n\tmemset(mtod(m, u_char *), 0, tlen);\n\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\tip = mtod(m, struct ip *);\n\t\tip->ip_dst = sc->sc_src.sin.sin_addr;\n\t\tip->ip_src = sc->sc_dst.sin.sin_addr;\n\t\tip->ip_p = IPPROTO_TCP;\n\t\tth = (struct tcphdr *)(ip + 1);\n\t\tth->th_dport = sc->sc_src.sin.sin_port;\n\t\tth->th_sport = sc->sc_dst.sin.sin_port;\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6 = mtod(m, struct ip6_hdr *);\n\t\tip6->ip6_dst = sc->sc_src.sin6.sin6_addr;\n\t\tip6->ip6_src = sc->sc_dst.sin6.sin6_addr;\n\t\tip6->ip6_nxt = IPPROTO_TCP;\n\t\t/* ip6_plen will be updated in ip6_output() */\n\t\tth = (struct tcphdr *)(ip6 + 1);\n\t\tth->th_dport = sc->sc_src.sin6.sin6_port;\n\t\tth->th_sport = sc->sc_dst.sin6.sin6_port;\n\t\tbreak;\n#endif\n\tdefault:\n\t\tunhandled_af(sc->sc_src.sa.sa_family);\n\t}\n\n\tth->th_seq = htonl(sc->sc_iss);\n\tth->th_ack = htonl(sc->sc_irs + 1);\n\tth->th_off = (sizeof(struct tcphdr) + optlen) >> 2;\n\tth->th_flags = TH_SYN|TH_ACK;\n#ifdef TCP_ECN\n\t/* Set ECE for SYN-ACK if peer supports ECN. */\n\tif (tcp_do_ecn && (sc->sc_flags & SCF_ECN_PERMIT))\n\t\tth->th_flags |= TH_ECE;\n#endif\n\tth->th_win = htons(sc->sc_win);\n\t/* th_sum already 0 */\n\t/* th_urp already 0 */\n\n\t/* Tack on the TCP options. */\n\toptp = (u_int8_t *)(th + 1);\n\t*optp++ = TCPOPT_MAXSEG;\n\t*optp++ = 4;\n\t*optp++ = (sc->sc_ourmaxseg >> 8) & 0xff;\n\t*optp++ = sc->sc_ourmaxseg & 0xff;\n\n\t/* Include SACK_PERMIT_HDR option if peer has already done so. */\n\tif (sc->sc_flags & SCF_SACK_PERMIT) {\n\t\t*((u_int32_t *)optp) = htonl(TCPOPT_SACK_PERMIT_HDR);\n\t\toptp += 4;\n\t}\n\n\tif (sc->sc_request_r_scale != 15) {\n\t\t*((u_int32_t *)optp) = htonl(TCPOPT_NOP << 24 |\n\t\t    TCPOPT_WINDOW << 16 | TCPOLEN_WINDOW << 8 |\n\t\t    sc->sc_request_r_scale);\n\t\toptp += 4;\n\t}\n\n\tif (sc->sc_flags & SCF_TIMESTAMP) {\n\t\tu_int32_t *lp = (u_int32_t *)(optp);\n\t\t/* Form timestamp option as shown in appendix A of RFC 1323. */\n\t\t*lp++ = htonl(TCPOPT_TSTAMP_HDR);\n\t\t*lp++ = htonl(SYN_CACHE_TIMESTAMP(sc));\n\t\t*lp   = htonl(sc->sc_timestamp);\n\t\toptp += TCPOLEN_TSTAMP_APPA;\n\t}\n\n#ifdef TCP_SIGNATURE\n\tif (sc->sc_flags & SCF_SIGNATURE) {\n\t\tunion sockaddr_union src, dst;\n\t\tstruct tdb *tdb;\n\n\t\tbzero(&src, sizeof(union sockaddr_union));\n\t\tbzero(&dst, sizeof(union sockaddr_union));\n\t\tsrc.sa.sa_len = sc->sc_src.sa.sa_len;\n\t\tsrc.sa.sa_family = sc->sc_src.sa.sa_family;\n\t\tdst.sa.sa_len = sc->sc_dst.sa.sa_len;\n\t\tdst.sa.sa_family = sc->sc_dst.sa.sa_family;\n\n\t\tswitch (sc->sc_src.sa.sa_family) {\n\t\tcase 0:\t/*default to PF_INET*/\n\t\tcase AF_INET:\n\t\t\tsrc.sin.sin_addr = mtod(m, struct ip *)->ip_src;\n\t\t\tdst.sin.sin_addr = mtod(m, struct ip *)->ip_dst;\n\t\t\tbreak;\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tsrc.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_src;\n\t\t\tdst.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;\n\t\t\tbreak;\n#endif /* INET6 */\n\t\t}\n\n\t\ttdb = gettdbbysrcdst(rtable_l2(sc->sc_rtableid),\n\t\t    0, &src, &dst, IPPROTO_TCP);\n\t\tif (tdb == NULL) {\n\t\t\tm_freem(m);\n\t\t\treturn (EPERM);\n\t\t}\n\n\t\t/* Send signature option */\n\t\t*(optp++) = TCPOPT_SIGNATURE;\n\t\t*(optp++) = TCPOLEN_SIGNATURE;\n\n\t\tif (tcp_signature(tdb, sc->sc_src.sa.sa_family, m, th,\n\t\t    hlen, 0, optp) < 0) {\n\t\t\tm_freem(m);\n\t\t\treturn (EINVAL);\n\t\t}\n\t\toptp += 16;\n\n\t\t/* Pad options list to the next 32 bit boundary and\n\t\t * terminate it.\n\t\t */\n\t\t*optp++ = TCPOPT_NOP;\n\t\t*optp++ = TCPOPT_EOL;\n\t}\n#endif /* TCP_SIGNATURE */\n\n\t/* Compute the packet's checksum. */\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\tip->ip_len = htons(tlen - hlen);\n\t\tth->th_sum = 0;\n\t\tth->th_sum = in_cksum(m, tlen);\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6->ip6_plen = htons(tlen - hlen);\n\t\tth->th_sum = 0;\n\t\tth->th_sum = in6_cksum(m, IPPROTO_TCP, hlen, tlen - hlen);\n\t\tbreak;\n#endif\n\t}\n\n\t/* use IPsec policy and ttl from listening socket, on SYN ACK */\n\tinp = sc->sc_tp ? sc->sc_tp->t_inpcb : NULL;\n\n\t/*\n\t * Fill in some straggling IP bits.  Note the stack expects\n\t * ip_len to be in host order, for convenience.\n\t */\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\tip->ip_len = htons(tlen);\n\t\tip->ip_ttl = inp ? inp->inp_ip.ip_ttl : ip_defttl;\n\t\tif (inp != NULL)\n\t\t\tip->ip_tos = inp->inp_ip.ip_tos;\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6->ip6_vfc &= ~IPV6_VERSION_MASK;\n\t\tip6->ip6_vfc |= IPV6_VERSION;\n\t\tip6->ip6_plen = htons(tlen - hlen);\n\t\t/* ip6_hlim will be initialized afterwards */\n\t\t/* leave flowlabel = 0, it is legal and require no state mgmt */\n\t\tbreak;\n#endif\n\t}\n\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\terror = ip_output(m, sc->sc_ipopts, &sc->sc_route4,\n\t\t    (ip_mtudisc ? IP_MTUDISC : 0),  NULL, inp, 0);\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6->ip6_hlim = in6_selecthlim(inp);\n\n\t\terror = ip6_output(m, NULL /*XXX*/, &sc->sc_route6, 0,\n\t\t    NULL, NULL);\n\t\tbreak;\n#endif\n\tdefault:\n\t\terror = EAFNOSUPPORT;\n\t\tbreak;\n\t}\n\treturn (error);\n}\n"], "fixing_code": ["/*\t$OpenBSD: tcp.h,v 1.21 2019/07/10 18:45:31 bluhm Exp $\t*/\n/*\t$NetBSD: tcp.h,v 1.8 1995/04/17 05:32:58 cgd Exp $\t*/\n\n/*\n * Copyright (c) 1982, 1986, 1993\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n *\t@(#)tcp.h\t8.1 (Berkeley) 6/10/93\n */\n\n#ifndef _NETINET_TCP_H_\n#define\t_NETINET_TCP_H_\n\n#include <sys/cdefs.h>\n\n#if __BSD_VISIBLE\n\ntypedef u_int32_t tcp_seq;\n\n/*\n * TCP header.\n * Per RFC 793, September, 1981.\n */\nstruct tcphdr {\n\tu_int16_t th_sport;\t\t/* source port */\n\tu_int16_t th_dport;\t\t/* destination port */\n\ttcp_seq\t  th_seq;\t\t/* sequence number */\n\ttcp_seq\t  th_ack;\t\t/* acknowledgement number */\n#if _BYTE_ORDER == _LITTLE_ENDIAN\n\tu_int32_t th_x2:4,\t\t/* (unused) */\n\t\t  th_off:4;\t\t/* data offset */\n#endif\n#if _BYTE_ORDER == _BIG_ENDIAN\n\tu_int32_t th_off:4,\t\t/* data offset */\n\t\t  th_x2:4;\t\t/* (unused) */\n#endif\n\tu_int8_t  th_flags;\n#define\tTH_FIN\t  0x01\n#define\tTH_SYN\t  0x02\n#define\tTH_RST\t  0x04\n#define\tTH_PUSH\t  0x08\n#define\tTH_ACK\t  0x10\n#define\tTH_URG\t  0x20\n#define\tTH_ECE\t  0x40\n#define\tTH_CWR\t  0x80\n\tu_int16_t th_win;\t\t\t/* window */\n\tu_int16_t th_sum;\t\t\t/* checksum */\n\tu_int16_t th_urp;\t\t\t/* urgent pointer */\n};\n#define th_reseqlen th_urp\t\t\t/* TCP data length for\n\t\t\t\t\t\t   resequencing/reassembly */\n\n#define\tTCPOPT_EOL\t\t0\n#define\tTCPOPT_NOP\t\t1\n#define\tTCPOPT_MAXSEG\t\t2\n#define\tTCPOLEN_MAXSEG\t\t4\n#define\tTCPOPT_WINDOW\t\t3\n#define\tTCPOLEN_WINDOW\t\t3\n#define\tTCPOPT_SACK_PERMITTED\t4\t\t/* Experimental */\n#define\tTCPOLEN_SACK_PERMITTED\t2\n#define\tTCPOPT_SACK\t\t5\t\t/* Experimental */\n#define\tTCPOLEN_SACK\t\t8\t\t/* 2*sizeof(tcp_seq) */\n#define\tTCPOPT_TIMESTAMP\t8\n#define\tTCPOLEN_TIMESTAMP\t\t10\n#define\tTCPOLEN_TSTAMP_APPA\t\t(TCPOLEN_TIMESTAMP+2) /* appendix A */\n#define\tTCPOPT_SIGNATURE\t19\n#define\tTCPOLEN_SIGNATURE\t\t18\n#define\tTCPOLEN_SIGLEN\t\t(TCPOLEN_SIGNATURE+2) /* padding */\n\n#define\tMAX_TCPOPTLEN\t\t40\t/* Absolute maximum TCP options len */\n\n#define\tTCPOPT_TSTAMP_HDR\t\\\n    (TCPOPT_NOP<<24|TCPOPT_NOP<<16|TCPOPT_TIMESTAMP<<8|TCPOLEN_TIMESTAMP)\n\n/* Option definitions */\n#define\tTCPOPT_SACK_PERMIT_HDR \\\n(TCPOPT_NOP<<24|TCPOPT_NOP<<16|TCPOPT_SACK_PERMITTED<<8|TCPOLEN_SACK_PERMITTED)\n#define\tTCPOPT_SACK_HDR   (TCPOPT_NOP<<24|TCPOPT_NOP<<16|TCPOPT_SACK<<8)\n/* Miscellaneous constants */\n#define\tMAX_SACK_BLKS\t6\t/* Max # SACK blocks stored at sender side */\n#define\tTCP_MAX_SACK\t3\t/* Max # SACKs sent in any segment */\n#define\tTCP_SACKHOLE_LIMIT 128\t/* Max # SACK holes per connection */\n\n#define\tTCP_MAXBURST\t4\t/* Max # packets after leaving Fast Rxmit */\n\n/*\n * Default maximum segment size for TCP.\n * With an IP MSS of 576, this is 536,\n * but 512 is probably more convenient.\n * This should be defined as min(512, IP_MSS - sizeof (struct tcpiphdr)).\n */\n#define\tTCP_MSS\t\t512\n\n#define\tTCP_MAXWIN\t65535\t/* largest value for (unscaled) window */\n\n#define\tTCP_MAX_WINSHIFT\t14\t/* maximum window shift */\n\n#endif /* __BSD_VISIBLE */\n\n/*\n * User-settable options (used with setsockopt).\n */\n#define\tTCP_NODELAY\t\t0x01   /* don't delay send to coalesce pkts */\n#define\tTCP_MAXSEG\t\t0x02   /* set maximum segment size */\n#define\tTCP_MD5SIG\t\t0x04   /* enable TCP MD5 signature option */\n#define\tTCP_SACK_ENABLE\t\t0x08   /* enable SACKs (if disabled by def.) */\n#define\tTCP_NOPUSH\t\t0x10   /* don't push last block of write */\n\n#endif /* _NETINET_TCP_H_ */\n", "/*\t$OpenBSD: tcp_input.c,v 1.360 2019/07/10 18:45:31 bluhm Exp $\t*/\n/*\t$NetBSD: tcp_input.c,v 1.23 1996/02/13 23:43:44 christos Exp $\t*/\n\n/*\n * Copyright (c) 1982, 1986, 1988, 1990, 1993, 1994\n *\tThe Regents of the University of California.  All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. Neither the name of the University nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND\n * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE\n * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS\n * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)\n * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT\n * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY\n * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n *\n *\t@(#)COPYRIGHT\t1.1 (NRL) 17 January 1995\n *\n * NRL grants permission for redistribution and use in source and binary\n * forms, with or without modification, of the software and documentation\n * created at NRL provided that the following conditions are met:\n *\n * 1. Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n * 2. Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in the\n *    documentation and/or other materials provided with the distribution.\n * 3. All advertising materials mentioning features or use of this software\n *    must display the following acknowledgements:\n *\tThis product includes software developed by the University of\n *\tCalifornia, Berkeley and its contributors.\n *\tThis product includes software developed at the Information\n *\tTechnology Division, US Naval Research Laboratory.\n * 4. Neither the name of the NRL nor the names of its contributors\n *    may be used to endorse or promote products derived from this software\n *    without specific prior written permission.\n *\n * THE SOFTWARE PROVIDED BY NRL IS PROVIDED BY NRL AND CONTRIBUTORS ``AS\n * IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED\n * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A\n * PARTICULAR PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL NRL OR\n * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,\n * EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n * PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR\n * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF\n * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING\n * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS\n * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n *\n * The views and conclusions contained in the software and documentation\n * are those of the authors and should not be interpreted as representing\n * official policies, either expressed or implied, of the US Naval\n * Research Laboratory (NRL).\n */\n\n#include \"pf.h\"\n\n#include <sys/param.h>\n#include <sys/systm.h>\n#include <sys/mbuf.h>\n#include <sys/protosw.h>\n#include <sys/socket.h>\n#include <sys/socketvar.h>\n#include <sys/timeout.h>\n#include <sys/kernel.h>\n#include <sys/pool.h>\n\n#include <net/if.h>\n#include <net/if_var.h>\n#include <net/route.h>\n\n#include <netinet/in.h>\n#include <netinet/ip.h>\n#include <netinet/in_pcb.h>\n#include <netinet/ip_var.h>\n#include <netinet/tcp.h>\n#include <netinet/tcp_fsm.h>\n#include <netinet/tcp_seq.h>\n#include <netinet/tcp_timer.h>\n#include <netinet/tcp_var.h>\n#include <netinet/tcp_debug.h>\n\n#if NPF > 0\n#include <net/pfvar.h>\n#endif\n\nstruct\ttcpiphdr tcp_saveti;\n\nint tcp_mss_adv(struct mbuf *, int);\nint tcp_flush_queue(struct tcpcb *);\n\n#ifdef INET6\n#include <netinet6/in6_var.h>\n#include <netinet6/nd6.h>\n\nstruct  tcpipv6hdr tcp_saveti6;\n\n/* for the packet header length in the mbuf */\n#define M_PH_LEN(m)      (((struct mbuf *)(m))->m_pkthdr.len)\n#define M_V6_LEN(m)      (M_PH_LEN(m) - sizeof(struct ip6_hdr))\n#define M_V4_LEN(m)      (M_PH_LEN(m) - sizeof(struct ip))\n#endif /* INET6 */\n\nint\ttcprexmtthresh = 3;\nint\ttcptv_keep_init = TCPTV_KEEP_INIT;\n\nint tcp_rst_ppslim = 100;\t\t/* 100pps */\nint tcp_rst_ppslim_count = 0;\nstruct timeval tcp_rst_ppslim_last;\n\nint tcp_ackdrop_ppslim = 100;\t\t/* 100pps */\nint tcp_ackdrop_ppslim_count = 0;\nstruct timeval tcp_ackdrop_ppslim_last;\n\n#define TCP_PAWS_IDLE\t(24 * 24 * 60 * 60 * PR_SLOWHZ)\n\n/* for modulo comparisons of timestamps */\n#define TSTMP_LT(a,b)\t((int)((a)-(b)) < 0)\n#define TSTMP_GEQ(a,b)\t((int)((a)-(b)) >= 0)\n\n/* for TCP SACK comparisons */\n#define\tSEQ_MIN(a,b)\t(SEQ_LT(a,b) ? (a) : (b))\n#define\tSEQ_MAX(a,b)\t(SEQ_GT(a,b) ? (a) : (b))\n\n/*\n * Neighbor Discovery, Neighbor Unreachability Detection Upper layer hint.\n */\n#ifdef INET6\n#define ND6_HINT(tp) \\\ndo { \\\n\tif (tp && tp->t_inpcb && (tp->t_inpcb->inp_flags & INP_IPV6) &&\t\\\n\t    rtisvalid(tp->t_inpcb->inp_route6.ro_rt)) {\t\t\t\\\n\t\tnd6_nud_hint(tp->t_inpcb->inp_route6.ro_rt);\t\t\\\n\t} \\\n} while (0)\n#else\n#define ND6_HINT(tp)\n#endif\n\n#ifdef TCP_ECN\n/*\n * ECN (Explicit Congestion Notification) support based on RFC3168\n * implementation note:\n *   snd_last is used to track a recovery phase.\n *   when cwnd is reduced, snd_last is set to snd_max.\n *   while snd_last > snd_una, the sender is in a recovery phase and\n *   its cwnd should not be reduced again.\n *   snd_last follows snd_una when not in a recovery phase.\n */\n#endif\n\n/*\n * Macro to compute ACK transmission behavior.  Delay the ACK unless\n * we have already delayed an ACK (must send an ACK every two segments).\n * We also ACK immediately if we received a PUSH and the ACK-on-PUSH\n * option is enabled or when the packet is coming from a loopback\n * interface.\n */\n#define\tTCP_SETUP_ACK(tp, tiflags, m) \\\ndo { \\\n\tstruct ifnet *ifp = NULL; \\\n\tif (m && (m->m_flags & M_PKTHDR)) \\\n\t\tifp = if_get(m->m_pkthdr.ph_ifidx); \\\n\tif (TCP_TIMER_ISARMED(tp, TCPT_DELACK) || \\\n\t    (tcp_ack_on_push && (tiflags) & TH_PUSH) || \\\n\t    (ifp && (ifp->if_flags & IFF_LOOPBACK))) \\\n\t\ttp->t_flags |= TF_ACKNOW; \\\n\telse \\\n\t\tTCP_TIMER_ARM_MSEC(tp, TCPT_DELACK, tcp_delack_msecs); \\\n\tif_put(ifp); \\\n} while (0)\n\nvoid\t tcp_sack_partialack(struct tcpcb *, struct tcphdr *);\nvoid\t tcp_newreno_partialack(struct tcpcb *, struct tcphdr *);\n\nvoid\t syn_cache_put(struct syn_cache *);\nvoid\t syn_cache_rm(struct syn_cache *);\nint\t syn_cache_respond(struct syn_cache *, struct mbuf *);\nvoid\t syn_cache_timer(void *);\nvoid\t syn_cache_reaper(void *);\nvoid\t syn_cache_insert(struct syn_cache *, struct tcpcb *);\nvoid\t syn_cache_reset(struct sockaddr *, struct sockaddr *,\n\t\tstruct tcphdr *, u_int);\nint\t syn_cache_add(struct sockaddr *, struct sockaddr *, struct tcphdr *,\n\t\tunsigned int, struct socket *, struct mbuf *, u_char *, int,\n\t\tstruct tcp_opt_info *, tcp_seq *);\nstruct socket *syn_cache_get(struct sockaddr *, struct sockaddr *,\n\t\tstruct tcphdr *, unsigned int, unsigned int, struct socket *,\n\t\tstruct mbuf *);\nstruct syn_cache *syn_cache_lookup(struct sockaddr *, struct sockaddr *,\n\t\tstruct syn_cache_head **, u_int);\n\n/*\n * Insert segment ti into reassembly queue of tcp with\n * control block tp.  Return TH_FIN if reassembly now includes\n * a segment with FIN.  The macro form does the common case inline\n * (segment is the next to be received on an established connection,\n * and the queue is empty), avoiding linkage into and removal\n * from the queue and repetition of various conversions.\n * Set DELACK for segments received in order, but ack immediately\n * when segments are out of order (so fast retransmit can work).\n */\n\nint\ntcp_reass(struct tcpcb *tp, struct tcphdr *th, struct mbuf *m, int *tlen)\n{\n\tstruct tcpqent *p, *q, *nq, *tiqe;\n\n\t/*\n\t * Allocate a new queue entry, before we throw away any data.\n\t * If we can't, just drop the packet.  XXX\n\t */\n\ttiqe = pool_get(&tcpqe_pool, PR_NOWAIT);\n\tif (tiqe == NULL) {\n\t\ttiqe = TAILQ_LAST(&tp->t_segq, tcpqehead);\n\t\tif (tiqe != NULL && th->th_seq == tp->rcv_nxt) {\n\t\t\t/* Reuse last entry since new segment fills a hole */\n\t\t\tm_freem(tiqe->tcpqe_m);\n\t\t\tTAILQ_REMOVE(&tp->t_segq, tiqe, tcpqe_q);\n\t\t}\n\t\tif (tiqe == NULL || th->th_seq != tp->rcv_nxt) {\n\t\t\t/* Flush segment queue for this connection */\n\t\t\ttcp_freeq(tp);\n\t\t\ttcpstat_inc(tcps_rcvmemdrop);\n\t\t\tm_freem(m);\n\t\t\treturn (0);\n\t\t}\n\t}\n\n\t/*\n\t * Find a segment which begins after this one does.\n\t */\n\tfor (p = NULL, q = TAILQ_FIRST(&tp->t_segq); q != NULL;\n\t    p = q, q = TAILQ_NEXT(q, tcpqe_q))\n\t\tif (SEQ_GT(q->tcpqe_tcp->th_seq, th->th_seq))\n\t\t\tbreak;\n\n\t/*\n\t * If there is a preceding segment, it may provide some of\n\t * our data already.  If so, drop the data from the incoming\n\t * segment.  If it provides all of our data, drop us.\n\t */\n\tif (p != NULL) {\n\t\tstruct tcphdr *phdr = p->tcpqe_tcp;\n\t\tint i;\n\n\t\t/* conversion to int (in i) handles seq wraparound */\n\t\ti = phdr->th_seq + phdr->th_reseqlen - th->th_seq;\n\t\tif (i > 0) {\n\t\t        if (i >= *tlen) {\n\t\t\t\ttcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte,\n\t\t\t\t    *tlen);\n\t\t\t\tm_freem(m);\n\t\t\t\tpool_put(&tcpqe_pool, tiqe);\n\t\t\t\treturn (0);\n\t\t\t}\n\t\t\tm_adj(m, i);\n\t\t\t*tlen -= i;\n\t\t\tth->th_seq += i;\n\t\t}\n\t}\n\ttcpstat_pkt(tcps_rcvoopack, tcps_rcvoobyte, *tlen);\n\n\t/*\n\t * While we overlap succeeding segments trim them or,\n\t * if they are completely covered, dequeue them.\n\t */\n\tfor (; q != NULL; q = nq) {\n\t\tstruct tcphdr *qhdr = q->tcpqe_tcp;\n\t\tint i = (th->th_seq + *tlen) - qhdr->th_seq;\n\n\t\tif (i <= 0)\n\t\t\tbreak;\n\t\tif (i < qhdr->th_reseqlen) {\n\t\t\tqhdr->th_seq += i;\n\t\t\tqhdr->th_reseqlen -= i;\n\t\t\tm_adj(q->tcpqe_m, i);\n\t\t\tbreak;\n\t\t}\n\t\tnq = TAILQ_NEXT(q, tcpqe_q);\n\t\tm_freem(q->tcpqe_m);\n\t\tTAILQ_REMOVE(&tp->t_segq, q, tcpqe_q);\n\t\tpool_put(&tcpqe_pool, q);\n\t}\n\n\t/* Insert the new segment queue entry into place. */\n\ttiqe->tcpqe_m = m;\n\tth->th_reseqlen = *tlen;\n\ttiqe->tcpqe_tcp = th;\n\tif (p == NULL) {\n\t\tTAILQ_INSERT_HEAD(&tp->t_segq, tiqe, tcpqe_q);\n\t} else {\n\t\tTAILQ_INSERT_AFTER(&tp->t_segq, p, tiqe, tcpqe_q);\n\t}\n\n\tif (th->th_seq != tp->rcv_nxt)\n\t\treturn (0);\n\n\treturn (tcp_flush_queue(tp));\n}\n\nint\ntcp_flush_queue(struct tcpcb *tp)\n{\n\tstruct socket *so = tp->t_inpcb->inp_socket;\n\tstruct tcpqent *q, *nq;\n\tint flags;\n\n\t/*\n\t * Present data to user, advancing rcv_nxt through\n\t * completed sequence space.\n\t */\n\tif (TCPS_HAVEESTABLISHED(tp->t_state) == 0)\n\t\treturn (0);\n\tq = TAILQ_FIRST(&tp->t_segq);\n\tif (q == NULL || q->tcpqe_tcp->th_seq != tp->rcv_nxt)\n\t\treturn (0);\n\tif (tp->t_state == TCPS_SYN_RECEIVED && q->tcpqe_tcp->th_reseqlen)\n\t\treturn (0);\n\tdo {\n\t\ttp->rcv_nxt += q->tcpqe_tcp->th_reseqlen;\n\t\tflags = q->tcpqe_tcp->th_flags & TH_FIN;\n\n\t\tnq = TAILQ_NEXT(q, tcpqe_q);\n\t\tTAILQ_REMOVE(&tp->t_segq, q, tcpqe_q);\n\t\tND6_HINT(tp);\n\t\tif (so->so_state & SS_CANTRCVMORE)\n\t\t\tm_freem(q->tcpqe_m);\n\t\telse\n\t\t\tsbappendstream(so, &so->so_rcv, q->tcpqe_m);\n\t\tpool_put(&tcpqe_pool, q);\n\t\tq = nq;\n\t} while (q != NULL && q->tcpqe_tcp->th_seq == tp->rcv_nxt);\n\ttp->t_flags |= TF_BLOCKOUTPUT;\n\tsorwakeup(so);\n\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\treturn (flags);\n}\n\n/*\n * TCP input routine, follows pages 65-76 of the\n * protocol specification dated September, 1981 very closely.\n */\nint\ntcp_input(struct mbuf **mp, int *offp, int proto, int af)\n{\n\tstruct mbuf *m = *mp;\n\tint iphlen = *offp;\n\tstruct ip *ip = NULL;\n\tstruct inpcb *inp = NULL;\n\tu_int8_t *optp = NULL;\n\tint optlen = 0;\n\tint tlen, off;\n\tstruct tcpcb *otp = NULL, *tp = NULL;\n\tint tiflags;\n\tstruct socket *so = NULL;\n\tint todrop, acked, ourfinisacked;\n\tint hdroptlen = 0;\n\tshort ostate;\n\tcaddr_t saveti;\n\ttcp_seq iss, *reuse = NULL;\n\tu_long tiwin;\n\tstruct tcp_opt_info opti;\n\tstruct tcphdr *th;\n#ifdef INET6\n\tstruct ip6_hdr *ip6 = NULL;\n#endif /* INET6 */\n#ifdef IPSEC\n\tstruct m_tag *mtag;\n\tstruct tdb_ident *tdbi;\n\tstruct tdb *tdb;\n\tint error;\n#endif /* IPSEC */\n#ifdef TCP_ECN\n\tu_char iptos;\n#endif\n\n\ttcpstat_inc(tcps_rcvtotal);\n\n\topti.ts_present = 0;\n\topti.maxseg = 0;\n\n\t/*\n\t * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN\n\t */\n\tif (m->m_flags & (M_BCAST|M_MCAST))\n\t\tgoto drop;\n\n\t/*\n\t * Get IP and TCP header together in first mbuf.\n\t * Note: IP leaves IP header in first mbuf.\n\t */\n\tIP6_EXTHDR_GET(th, struct tcphdr *, m, iphlen, sizeof(*th));\n\tif (!th) {\n\t\ttcpstat_inc(tcps_rcvshort);\n\t\treturn IPPROTO_DONE;\n\t}\n\n\ttlen = m->m_pkthdr.len - iphlen;\n\tswitch (af) {\n\tcase AF_INET:\n\t\tip = mtod(m, struct ip *);\n#ifdef TCP_ECN\n\t\t/* save ip_tos before clearing it for checksum */\n\t\tiptos = ip->ip_tos;\n#endif\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6 = mtod(m, struct ip6_hdr *);\n#ifdef TCP_ECN\n\t\tiptos = (ntohl(ip6->ip6_flow) >> 20) & 0xff;\n#endif\n\n\t\t/*\n\t\t * Be proactive about unspecified IPv6 address in source.\n\t\t * As we use all-zero to indicate unbounded/unconnected pcb,\n\t\t * unspecified IPv6 address can be used to confuse us.\n\t\t *\n\t\t * Note that packets with unspecified IPv6 destination is\n\t\t * already dropped in ip6_input.\n\t\t */\n\t\tif (IN6_IS_ADDR_UNSPECIFIED(&ip6->ip6_src)) {\n\t\t\t/* XXX stat */\n\t\t\tgoto drop;\n\t\t}\n\n\t\t/* Discard packets to multicast */\n\t\tif (IN6_IS_ADDR_MULTICAST(&ip6->ip6_dst)) {\n\t\t\t/* XXX stat */\n\t\t\tgoto drop;\n\t\t}\n\t\tbreak;\n#endif\n\tdefault:\n\t\tunhandled_af(af);\n\t}\n\n\t/*\n\t * Checksum extended TCP header and data.\n\t */\n\tif ((m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_OK) == 0) {\n\t\tint sum;\n\n\t\tif (m->m_pkthdr.csum_flags & M_TCP_CSUM_IN_BAD) {\n\t\t\ttcpstat_inc(tcps_rcvbadsum);\n\t\t\tgoto drop;\n\t\t}\n\t\ttcpstat_inc(tcps_inswcsum);\n\t\tswitch (af) {\n\t\tcase AF_INET:\n\t\t\tsum = in4_cksum(m, IPPROTO_TCP, iphlen, tlen);\n\t\t\tbreak;\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tsum = in6_cksum(m, IPPROTO_TCP, sizeof(struct ip6_hdr),\n\t\t\t    tlen);\n\t\t\tbreak;\n#endif\n\t\t}\n\t\tif (sum != 0) {\n\t\t\ttcpstat_inc(tcps_rcvbadsum);\n\t\t\tgoto drop;\n\t\t}\n\t}\n\n\t/*\n\t * Check that TCP offset makes sense,\n\t * pull out TCP options and adjust length.\t\tXXX\n\t */\n\toff = th->th_off << 2;\n\tif (off < sizeof(struct tcphdr) || off > tlen) {\n\t\ttcpstat_inc(tcps_rcvbadoff);\n\t\tgoto drop;\n\t}\n\ttlen -= off;\n\tif (off > sizeof(struct tcphdr)) {\n\t\tIP6_EXTHDR_GET(th, struct tcphdr *, m, iphlen, off);\n\t\tif (!th) {\n\t\t\ttcpstat_inc(tcps_rcvshort);\n\t\t\treturn IPPROTO_DONE;\n\t\t}\n\t\toptlen = off - sizeof(struct tcphdr);\n\t\toptp = (u_int8_t *)(th + 1);\n\t\t/*\n\t\t * Do quick retrieval of timestamp options (\"options\n\t\t * prediction?\").  If timestamp is the only option and it's\n\t\t * formatted as recommended in RFC 1323 appendix A, we\n\t\t * quickly get the values now and not bother calling\n\t\t * tcp_dooptions(), etc.\n\t\t */\n\t\tif ((optlen == TCPOLEN_TSTAMP_APPA ||\n\t\t     (optlen > TCPOLEN_TSTAMP_APPA &&\n\t\t\toptp[TCPOLEN_TSTAMP_APPA] == TCPOPT_EOL)) &&\n\t\t     *(u_int32_t *)optp == htonl(TCPOPT_TSTAMP_HDR) &&\n\t\t     (th->th_flags & TH_SYN) == 0) {\n\t\t\topti.ts_present = 1;\n\t\t\topti.ts_val = ntohl(*(u_int32_t *)(optp + 4));\n\t\t\topti.ts_ecr = ntohl(*(u_int32_t *)(optp + 8));\n\t\t\toptp = NULL;\t/* we've parsed the options */\n\t\t}\n\t}\n\ttiflags = th->th_flags;\n\n\t/*\n\t * Convert TCP protocol specific fields to host format.\n\t */\n\tth->th_seq = ntohl(th->th_seq);\n\tth->th_ack = ntohl(th->th_ack);\n\tth->th_win = ntohs(th->th_win);\n\tth->th_urp = ntohs(th->th_urp);\n\n\t/*\n\t * Locate pcb for segment.\n\t */\n#if NPF > 0\n\tinp = pf_inp_lookup(m);\n#endif\nfindpcb:\n\tif (inp == NULL) {\n\t\tswitch (af) {\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tinp = in6_pcbhashlookup(&tcbtable, &ip6->ip6_src,\n\t\t\t    th->th_sport, &ip6->ip6_dst, th->th_dport,\n\t\t\t    m->m_pkthdr.ph_rtableid);\n\t\t\tbreak;\n#endif\n\t\tcase AF_INET:\n\t\t\tinp = in_pcbhashlookup(&tcbtable, ip->ip_src,\n\t\t\t    th->th_sport, ip->ip_dst, th->th_dport,\n\t\t\t    m->m_pkthdr.ph_rtableid);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (inp == NULL) {\n\t\ttcpstat_inc(tcps_pcbhashmiss);\n\t\tswitch (af) {\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tinp = in6_pcblookup_listen(&tcbtable, &ip6->ip6_dst,\n\t\t\t    th->th_dport, m, m->m_pkthdr.ph_rtableid);\n\t\t\tbreak;\n#endif /* INET6 */\n\t\tcase AF_INET:\n\t\t\tinp = in_pcblookup_listen(&tcbtable, ip->ip_dst,\n\t\t\t    th->th_dport, m, m->m_pkthdr.ph_rtableid);\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * If the state is CLOSED (i.e., TCB does not exist) then\n\t\t * all data in the incoming segment is discarded.\n\t\t * If the TCB exists but is in CLOSED state, it is embryonic,\n\t\t * but should either do a listen or a connect soon.\n\t\t */\n\t\tif (inp == NULL) {\n\t\t\ttcpstat_inc(tcps_noport);\n\t\t\tgoto dropwithreset_ratelim;\n\t\t}\n\t}\n\tKASSERT(sotoinpcb(inp->inp_socket) == inp);\n\tKASSERT(intotcpcb(inp) == NULL || intotcpcb(inp)->t_inpcb == inp);\n\tsoassertlocked(inp->inp_socket);\n\n\t/* Check the minimum TTL for socket. */\n\tswitch (af) {\n\tcase AF_INET:\n\t\tif (inp->inp_ip_minttl && inp->inp_ip_minttl > ip->ip_ttl)\n\t\t\tgoto drop;\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tif (inp->inp_ip6_minhlim &&\n\t\t    inp->inp_ip6_minhlim > ip6->ip6_hlim)\n\t\t\tgoto drop;\n\t\tbreak;\n#endif\n\t}\n\n\ttp = intotcpcb(inp);\n\tif (tp == NULL)\n\t\tgoto dropwithreset_ratelim;\n\tif (tp->t_state == TCPS_CLOSED)\n\t\tgoto drop;\n\n\t/* Unscale the window into a 32-bit value. */\n\tif ((tiflags & TH_SYN) == 0)\n\t\ttiwin = th->th_win << tp->snd_scale;\n\telse\n\t\ttiwin = th->th_win;\n\n\tso = inp->inp_socket;\n\tif (so->so_options & (SO_DEBUG|SO_ACCEPTCONN)) {\n\t\tunion syn_cache_sa src;\n\t\tunion syn_cache_sa dst;\n\n\t\tbzero(&src, sizeof(src));\n\t\tbzero(&dst, sizeof(dst));\n\t\tswitch (af) {\n\t\tcase AF_INET:\n\t\t\tsrc.sin.sin_len = sizeof(struct sockaddr_in);\n\t\t\tsrc.sin.sin_family = AF_INET;\n\t\t\tsrc.sin.sin_addr = ip->ip_src;\n\t\t\tsrc.sin.sin_port = th->th_sport;\n\n\t\t\tdst.sin.sin_len = sizeof(struct sockaddr_in);\n\t\t\tdst.sin.sin_family = AF_INET;\n\t\t\tdst.sin.sin_addr = ip->ip_dst;\n\t\t\tdst.sin.sin_port = th->th_dport;\n\t\t\tbreak;\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tsrc.sin6.sin6_len = sizeof(struct sockaddr_in6);\n\t\t\tsrc.sin6.sin6_family = AF_INET6;\n\t\t\tsrc.sin6.sin6_addr = ip6->ip6_src;\n\t\t\tsrc.sin6.sin6_port = th->th_sport;\n\n\t\t\tdst.sin6.sin6_len = sizeof(struct sockaddr_in6);\n\t\t\tdst.sin6.sin6_family = AF_INET6;\n\t\t\tdst.sin6.sin6_addr = ip6->ip6_dst;\n\t\t\tdst.sin6.sin6_port = th->th_dport;\n\t\t\tbreak;\n#endif /* INET6 */\n\t\t}\n\n\t\tif (so->so_options & SO_DEBUG) {\n\t\t\totp = tp;\n\t\t\tostate = tp->t_state;\n\t\t\tswitch (af) {\n#ifdef INET6\n\t\t\tcase AF_INET6:\n\t\t\t\tsaveti = (caddr_t) &tcp_saveti6;\n\t\t\t\tmemcpy(&tcp_saveti6.ti6_i, ip6, sizeof(*ip6));\n\t\t\t\tmemcpy(&tcp_saveti6.ti6_t, th, sizeof(*th));\n\t\t\t\tbreak;\n#endif\n\t\t\tcase AF_INET:\n\t\t\t\tsaveti = (caddr_t) &tcp_saveti;\n\t\t\t\tmemcpy(&tcp_saveti.ti_i, ip, sizeof(*ip));\n\t\t\t\tmemcpy(&tcp_saveti.ti_t, th, sizeof(*th));\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (so->so_options & SO_ACCEPTCONN) {\n\t\t\tswitch (tiflags & (TH_RST|TH_SYN|TH_ACK)) {\n\n\t\t\tcase TH_SYN|TH_ACK|TH_RST:\n\t\t\tcase TH_SYN|TH_RST:\n\t\t\tcase TH_ACK|TH_RST:\n\t\t\tcase TH_RST:\n\t\t\t\tsyn_cache_reset(&src.sa, &dst.sa, th,\n\t\t\t\t    inp->inp_rtableid);\n\t\t\t\tgoto drop;\n\n\t\t\tcase TH_SYN|TH_ACK:\n\t\t\t\t/*\n\t\t\t\t * Received a SYN,ACK.  This should\n\t\t\t\t * never happen while we are in\n\t\t\t\t * LISTEN.  Send an RST.\n\t\t\t\t */\n\t\t\t\tgoto badsyn;\n\n\t\t\tcase TH_ACK:\n\t\t\t\tso = syn_cache_get(&src.sa, &dst.sa,\n\t\t\t\t\tth, iphlen, tlen, so, m);\n\t\t\t\tif (so == NULL) {\n\t\t\t\t\t/*\n\t\t\t\t\t * We don't have a SYN for\n\t\t\t\t\t * this ACK; send an RST.\n\t\t\t\t\t */\n\t\t\t\t\tgoto badsyn;\n\t\t\t\t} else if (so == (struct socket *)(-1)) {\n\t\t\t\t\t/*\n\t\t\t\t\t * We were unable to create\n\t\t\t\t\t * the connection.  If the\n\t\t\t\t\t * 3-way handshake was\n\t\t\t\t\t * completed, and RST has\n\t\t\t\t\t * been sent to the peer.\n\t\t\t\t\t * Since the mbuf might be\n\t\t\t\t\t * in use for the reply,\n\t\t\t\t\t * do not free it.\n\t\t\t\t\t */\n\t\t\t\t\tm = *mp = NULL;\n\t\t\t\t\tgoto drop;\n\t\t\t\t} else {\n\t\t\t\t\t/*\n\t\t\t\t\t * We have created a\n\t\t\t\t\t * full-blown connection.\n\t\t\t\t\t */\n\t\t\t\t\ttp = NULL;\n\t\t\t\t\tinp = sotoinpcb(so);\n\t\t\t\t\ttp = intotcpcb(inp);\n\t\t\t\t\tif (tp == NULL)\n\t\t\t\t\t\tgoto badsyn;\t/*XXX*/\n\n\t\t\t\t}\n\t\t\t\tbreak;\n\n\t\t\tdefault:\n\t\t\t\t/*\n\t\t\t\t * None of RST, SYN or ACK was set.\n\t\t\t\t * This is an invalid packet for a\n\t\t\t\t * TCB in LISTEN state.  Send a RST.\n\t\t\t\t */\n\t\t\t\tgoto badsyn;\n\n\t\t\tcase TH_SYN:\n\t\t\t\t/*\n\t\t\t\t * Received a SYN.\n\t\t\t\t */\n#ifdef INET6\n\t\t\t\t/*\n\t\t\t\t * If deprecated address is forbidden, we do\n\t\t\t\t * not accept SYN to deprecated interface\n\t\t\t\t * address to prevent any new inbound\n\t\t\t\t * connection from getting established.\n\t\t\t\t * When we do not accept SYN, we send a TCP\n\t\t\t\t * RST, with deprecated source address (instead\n\t\t\t\t * of dropping it).  We compromise it as it is\n\t\t\t\t * much better for peer to send a RST, and\n\t\t\t\t * RST will be the final packet for the\n\t\t\t\t * exchange.\n\t\t\t\t *\n\t\t\t\t * If we do not forbid deprecated addresses, we\n\t\t\t\t * accept the SYN packet.  RFC2462 does not\n\t\t\t\t * suggest dropping SYN in this case.\n\t\t\t\t * If we decipher RFC2462 5.5.4, it says like\n\t\t\t\t * this:\n\t\t\t\t * 1. use of deprecated addr with existing\n\t\t\t\t *    communication is okay - \"SHOULD continue\n\t\t\t\t *    to be used\"\n\t\t\t\t * 2. use of it with new communication:\n\t\t\t\t *   (2a) \"SHOULD NOT be used if alternate\n\t\t\t\t *        address with sufficient scope is\n\t\t\t\t *        available\"\n\t\t\t\t *   (2b) nothing mentioned otherwise.\n\t\t\t\t * Here we fall into (2b) case as we have no\n\t\t\t\t * choice in our source address selection - we\n\t\t\t\t * must obey the peer.\n\t\t\t\t *\n\t\t\t\t * The wording in RFC2462 is confusing, and\n\t\t\t\t * there are multiple description text for\n\t\t\t\t * deprecated address handling - worse, they\n\t\t\t\t * are not exactly the same.  I believe 5.5.4\n\t\t\t\t * is the best one, so we follow 5.5.4.\n\t\t\t\t */\n\t\t\t\tif (ip6 && !ip6_use_deprecated) {\n\t\t\t\t\tstruct in6_ifaddr *ia6;\n\t\t\t\t\tstruct ifnet *ifp =\n\t\t\t\t\t    if_get(m->m_pkthdr.ph_ifidx);\n\n\t\t\t\t\tif (ifp &&\n\t\t\t\t\t    (ia6 = in6ifa_ifpwithaddr(ifp,\n\t\t\t\t\t    &ip6->ip6_dst)) &&\n\t\t\t\t\t    (ia6->ia6_flags &\n\t\t\t\t\t    IN6_IFF_DEPRECATED)) {\n\t\t\t\t\t\ttp = NULL;\n\t\t\t\t\t\tif_put(ifp);\n\t\t\t\t\t\tgoto dropwithreset;\n\t\t\t\t\t}\n\t\t\t\t\tif_put(ifp);\n\t\t\t\t}\n#endif\n\n\t\t\t\t/*\n\t\t\t\t * LISTEN socket received a SYN\n\t\t\t\t * from itself?  This can't possibly\n\t\t\t\t * be valid; drop the packet.\n\t\t\t\t */\n\t\t\t\tif (th->th_dport == th->th_sport) {\n\t\t\t\t\tswitch (af) {\n#ifdef INET6\n\t\t\t\t\tcase AF_INET6:\n\t\t\t\t\t\tif (IN6_ARE_ADDR_EQUAL(&ip6->ip6_src,\n\t\t\t\t\t\t    &ip6->ip6_dst)) {\n\t\t\t\t\t\t\ttcpstat_inc(tcps_badsyn);\n\t\t\t\t\t\t\tgoto drop;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n#endif /* INET6 */\n\t\t\t\t\tcase AF_INET:\n\t\t\t\t\t\tif (ip->ip_dst.s_addr == ip->ip_src.s_addr) {\n\t\t\t\t\t\t\ttcpstat_inc(tcps_badsyn);\n\t\t\t\t\t\t\tgoto drop;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * SYN looks ok; create compressed TCP\n\t\t\t\t * state for it.\n\t\t\t\t */\n\t\t\t\tif (so->so_qlen > so->so_qlimit ||\n\t\t\t\t    syn_cache_add(&src.sa, &dst.sa, th, iphlen,\n\t\t\t\t    so, m, optp, optlen, &opti, reuse) == -1) {\n\t\t\t\t\ttcpstat_inc(tcps_dropsyn);\n\t\t\t\t\tgoto drop;\n\t\t\t\t}\n\t\t\t\treturn IPPROTO_DONE;\n\t\t\t}\n\t\t}\n\t}\n\n#ifdef DIAGNOSTIC\n\t/*\n\t * Should not happen now that all embryonic connections\n\t * are handled with compressed state.\n\t */\n\tif (tp->t_state == TCPS_LISTEN)\n\t\tpanic(\"tcp_input: TCPS_LISTEN\");\n#endif\n\n#if NPF > 0\n\tpf_inp_link(m, inp);\n#endif\n\n#ifdef IPSEC\n\t/* Find most recent IPsec tag */\n\tmtag = m_tag_find(m, PACKET_TAG_IPSEC_IN_DONE, NULL);\n\tif (mtag != NULL) {\n\t\ttdbi = (struct tdb_ident *)(mtag + 1);\n\t        tdb = gettdb(tdbi->rdomain, tdbi->spi,\n\t\t    &tdbi->dst, tdbi->proto);\n\t} else\n\t\ttdb = NULL;\n\tipsp_spd_lookup(m, af, iphlen, &error, IPSP_DIRECTION_IN,\n\t    tdb, inp, 0);\n\tif (error) {\n\t\ttcpstat_inc(tcps_rcvnosec);\n\t\tgoto drop;\n\t}\n#endif /* IPSEC */\n\n\t/*\n\t * Segment received on connection.\n\t * Reset idle time and keep-alive timer.\n\t */\n\ttp->t_rcvtime = tcp_now;\n\tif (TCPS_HAVEESTABLISHED(tp->t_state))\n\t\tTCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);\n\n\tif (tp->sack_enable)\n\t\ttcp_del_sackholes(tp, th); /* Delete stale SACK holes */\n\n\t/*\n\t * Process options.\n\t */\n#ifdef TCP_SIGNATURE\n\tif (optp || (tp->t_flags & TF_SIGNATURE))\n#else\n\tif (optp)\n#endif\n\t\tif (tcp_dooptions(tp, optp, optlen, th, m, iphlen, &opti,\n\t\t    m->m_pkthdr.ph_rtableid))\n\t\t\tgoto drop;\n\n\tif (opti.ts_present && opti.ts_ecr) {\n\t\tint rtt_test;\n\n\t\t/* subtract out the tcp timestamp modulator */\n\t\topti.ts_ecr -= tp->ts_modulate;\n\n\t\t/* make sure ts_ecr is sensible */\n\t\trtt_test = tcp_now - opti.ts_ecr;\n\t\tif (rtt_test < 0 || rtt_test > TCP_RTT_MAX)\n\t\t\topti.ts_ecr = 0;\n\t}\n\n#ifdef TCP_ECN\n\t/* if congestion experienced, set ECE bit in subsequent packets. */\n\tif ((iptos & IPTOS_ECN_MASK) == IPTOS_ECN_CE) {\n\t\ttp->t_flags |= TF_RCVD_CE;\n\t\ttcpstat_inc(tcps_ecn_rcvce);\n\t}\n#endif\n\t/*\n\t * Header prediction: check for the two common cases\n\t * of a uni-directional data xfer.  If the packet has\n\t * no control flags, is in-sequence, the window didn't\n\t * change and we're not retransmitting, it's a\n\t * candidate.  If the length is zero and the ack moved\n\t * forward, we're the sender side of the xfer.  Just\n\t * free the data acked & wake any higher level process\n\t * that was blocked waiting for space.  If the length\n\t * is non-zero and the ack didn't move, we're the\n\t * receiver side.  If we're getting packets in-order\n\t * (the reassembly queue is empty), add the data to\n\t * the socket buffer and note that we need a delayed ack.\n\t */\n\tif (tp->t_state == TCPS_ESTABLISHED &&\n#ifdef TCP_ECN\n\t    (tiflags & (TH_SYN|TH_FIN|TH_RST|TH_URG|TH_ECE|TH_CWR|TH_ACK)) == TH_ACK &&\n#else\n\t    (tiflags & (TH_SYN|TH_FIN|TH_RST|TH_URG|TH_ACK)) == TH_ACK &&\n#endif\n\t    (!opti.ts_present || TSTMP_GEQ(opti.ts_val, tp->ts_recent)) &&\n\t    th->th_seq == tp->rcv_nxt &&\n\t    tiwin && tiwin == tp->snd_wnd &&\n\t    tp->snd_nxt == tp->snd_max) {\n\n\t\t/*\n\t\t * If last ACK falls within this segment's sequence numbers,\n\t\t *  record the timestamp.\n\t\t * Fix from Braden, see Stevens p. 870\n\t\t */\n\t\tif (opti.ts_present && SEQ_LEQ(th->th_seq, tp->last_ack_sent)) {\n\t\t\ttp->ts_recent_age = tcp_now;\n\t\t\ttp->ts_recent = opti.ts_val;\n\t\t}\n\n\t\tif (tlen == 0) {\n\t\t\tif (SEQ_GT(th->th_ack, tp->snd_una) &&\n\t\t\t    SEQ_LEQ(th->th_ack, tp->snd_max) &&\n\t\t\t    tp->snd_cwnd >= tp->snd_wnd &&\n\t\t\t    tp->t_dupacks == 0) {\n\t\t\t\t/*\n\t\t\t\t * this is a pure ack for outstanding data.\n\t\t\t\t */\n\t\t\t\ttcpstat_inc(tcps_predack);\n\t\t\t\tif (opti.ts_present && opti.ts_ecr)\n\t\t\t\t\ttcp_xmit_timer(tp, tcp_now - opti.ts_ecr);\n\t\t\t\telse if (tp->t_rtttime &&\n\t\t\t\t    SEQ_GT(th->th_ack, tp->t_rtseq))\n\t\t\t\t\ttcp_xmit_timer(tp,\n\t\t\t\t\t    tcp_now - tp->t_rtttime);\n\t\t\t\tacked = th->th_ack - tp->snd_una;\n\t\t\t\ttcpstat_pkt(tcps_rcvackpack, tcps_rcvackbyte,\n\t\t\t\t    acked);\n\t\t\t\tND6_HINT(tp);\n\t\t\t\tsbdrop(so, &so->so_snd, acked);\n\n\t\t\t\t/*\n\t\t\t\t * If we had a pending ICMP message that\n\t\t\t\t * refers to data that have just been\n\t\t\t\t * acknowledged, disregard the recorded ICMP\n\t\t\t\t * message.\n\t\t\t\t */\n\t\t\t\tif ((tp->t_flags & TF_PMTUD_PEND) &&\n\t\t\t\t    SEQ_GT(th->th_ack, tp->t_pmtud_th_seq))\n\t\t\t\t\ttp->t_flags &= ~TF_PMTUD_PEND;\n\n\t\t\t\t/*\n\t\t\t\t * Keep track of the largest chunk of data\n\t\t\t\t * acknowledged since last PMTU update\n\t\t\t\t */\n\t\t\t\tif (tp->t_pmtud_mss_acked < acked)\n\t\t\t\t\ttp->t_pmtud_mss_acked = acked;\n\n\t\t\t\ttp->snd_una = th->th_ack;\n\t\t\t\t/*\n\t\t\t\t * We want snd_last to track snd_una so\n\t\t\t\t * as to avoid sequence wraparound problems\n\t\t\t\t * for very large transfers.\n\t\t\t\t */\n#ifdef TCP_ECN\n\t\t\t\tif (SEQ_GT(tp->snd_una, tp->snd_last))\n#endif\n\t\t\t\ttp->snd_last = tp->snd_una;\n\t\t\t\tm_freem(m);\n\n\t\t\t\t/*\n\t\t\t\t * If all outstanding data are acked, stop\n\t\t\t\t * retransmit timer, otherwise restart timer\n\t\t\t\t * using current (possibly backed-off) value.\n\t\t\t\t * If process is waiting for space,\n\t\t\t\t * wakeup/selwakeup/signal.  If data\n\t\t\t\t * are ready to send, let tcp_output\n\t\t\t\t * decide between more output or persist.\n\t\t\t\t */\n\t\t\t\tif (tp->snd_una == tp->snd_max)\n\t\t\t\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\t\t\telse if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)\n\t\t\t\t\tTCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);\n\n\t\t\t\ttcp_update_sndspace(tp);\n\t\t\t\tif (sb_notify(so, &so->so_snd)) {\n\t\t\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\t\t\tsowwakeup(so);\n\t\t\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\t\t}\n\t\t\t\tif (so->so_snd.sb_cc ||\n\t\t\t\t    tp->t_flags & TF_NEEDOUTPUT)\n\t\t\t\t\t(void) tcp_output(tp);\n\t\t\t\treturn IPPROTO_DONE;\n\t\t\t}\n\t\t} else if (th->th_ack == tp->snd_una &&\n\t\t    TAILQ_EMPTY(&tp->t_segq) &&\n\t\t    tlen <= sbspace(so, &so->so_rcv)) {\n\t\t\t/*\n\t\t\t * This is a pure, in-sequence data packet\n\t\t\t * with nothing on the reassembly queue and\n\t\t\t * we have enough buffer space to take it.\n\t\t\t */\n\t\t\t/* Clean receiver SACK report if present */\n\t\t\tif (tp->sack_enable && tp->rcv_numsacks)\n\t\t\t\ttcp_clean_sackreport(tp);\n\t\t\ttcpstat_inc(tcps_preddat);\n\t\t\ttp->rcv_nxt += tlen;\n\t\t\ttcpstat_pkt(tcps_rcvpack, tcps_rcvbyte, tlen);\n\t\t\tND6_HINT(tp);\n\n\t\t\tTCP_SETUP_ACK(tp, tiflags, m);\n\t\t\t/*\n\t\t\t * Drop TCP, IP headers and TCP options then add data\n\t\t\t * to socket buffer.\n\t\t\t */\n\t\t\tif (so->so_state & SS_CANTRCVMORE)\n\t\t\t\tm_freem(m);\n\t\t\telse {\n\t\t\t\tif (opti.ts_present && opti.ts_ecr) {\n\t\t\t\t\tif (tp->rfbuf_ts < opti.ts_ecr &&\n\t\t\t\t\t    opti.ts_ecr - tp->rfbuf_ts < hz) {\n\t\t\t\t\t\ttcp_update_rcvspace(tp);\n\t\t\t\t\t\t/* Start over with next RTT. */\n\t\t\t\t\t\ttp->rfbuf_cnt = 0;\n\t\t\t\t\t\ttp->rfbuf_ts = 0;\n\t\t\t\t\t} else\n\t\t\t\t\t\ttp->rfbuf_cnt += tlen;\n\t\t\t\t}\n\t\t\t\tm_adj(m, iphlen + off);\n\t\t\t\tsbappendstream(so, &so->so_rcv, m);\n\t\t\t}\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsorwakeup(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\tif (tp->t_flags & (TF_ACKNOW|TF_NEEDOUTPUT))\n\t\t\t\t(void) tcp_output(tp);\n\t\t\treturn IPPROTO_DONE;\n\t\t}\n\t}\n\n\t/*\n\t * Compute mbuf offset to TCP data segment.\n\t */\n\thdroptlen = iphlen + off;\n\n\t/*\n\t * Calculate amount of space in receive window,\n\t * and then do TCP input processing.\n\t * Receive window is amount of space in rcv queue,\n\t * but not less than advertised window.\n\t */\n\t{ int win;\n\n\twin = sbspace(so, &so->so_rcv);\n\tif (win < 0)\n\t\twin = 0;\n\ttp->rcv_wnd = imax(win, (int)(tp->rcv_adv - tp->rcv_nxt));\n\t}\n\n\t/* Reset receive buffer auto scaling when not in bulk receive mode. */\n\ttp->rfbuf_cnt = 0;\n\ttp->rfbuf_ts = 0;\n\n\tswitch (tp->t_state) {\n\n\t/*\n\t * If the state is SYN_RECEIVED:\n\t * \tif seg contains SYN/ACK, send an RST.\n\t *\tif seg contains an ACK, but not for our SYN/ACK, send an RST\n\t */\n\n\tcase TCPS_SYN_RECEIVED:\n\t\tif (tiflags & TH_ACK) {\n\t\t\tif (tiflags & TH_SYN) {\n\t\t\t\ttcpstat_inc(tcps_badsyn);\n\t\t\t\tgoto dropwithreset;\n\t\t\t}\n\t\t\tif (SEQ_LEQ(th->th_ack, tp->snd_una) ||\n\t\t\t    SEQ_GT(th->th_ack, tp->snd_max))\n\t\t\t\tgoto dropwithreset;\n\t\t}\n\t\tbreak;\n\n\t/*\n\t * If the state is SYN_SENT:\n\t *\tif seg contains an ACK, but not for our SYN, drop the input.\n\t *\tif seg contains a RST, then drop the connection.\n\t *\tif seg does not contain SYN, then drop it.\n\t * Otherwise this is an acceptable SYN segment\n\t *\tinitialize tp->rcv_nxt and tp->irs\n\t *\tif seg contains ack then advance tp->snd_una\n\t *\tif SYN has been acked change to ESTABLISHED else SYN_RCVD state\n\t *\tarrange for segment to be acked (eventually)\n\t *\tcontinue processing rest of data/controls, beginning with URG\n\t */\n\tcase TCPS_SYN_SENT:\n\t\tif ((tiflags & TH_ACK) &&\n\t\t    (SEQ_LEQ(th->th_ack, tp->iss) ||\n\t\t     SEQ_GT(th->th_ack, tp->snd_max)))\n\t\t\tgoto dropwithreset;\n\t\tif (tiflags & TH_RST) {\n#ifdef TCP_ECN\n\t\t\t/* if ECN is enabled, fall back to non-ecn at rexmit */\n\t\t\tif (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))\n\t\t\t\tgoto drop;\n#endif\n\t\t\tif (tiflags & TH_ACK)\n\t\t\t\ttp = tcp_drop(tp, ECONNREFUSED);\n\t\t\tgoto drop;\n\t\t}\n\t\tif ((tiflags & TH_SYN) == 0)\n\t\t\tgoto drop;\n\t\tif (tiflags & TH_ACK) {\n\t\t\ttp->snd_una = th->th_ack;\n\t\t\tif (SEQ_LT(tp->snd_nxt, tp->snd_una))\n\t\t\t\ttp->snd_nxt = tp->snd_una;\n\t\t}\n\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\ttp->irs = th->th_seq;\n\t\ttcp_mss(tp, opti.maxseg);\n\t\t/* Reset initial window to 1 segment for retransmit */\n\t\tif (tp->t_rxtshift > 0)\n\t\t\ttp->snd_cwnd = tp->t_maxseg;\n\t\ttcp_rcvseqinit(tp);\n\t\ttp->t_flags |= TF_ACKNOW;\n                /*\n                 * If we've sent a SACK_PERMITTED option, and the peer\n                 * also replied with one, then TF_SACK_PERMIT should have\n                 * been set in tcp_dooptions().  If it was not, disable SACKs.\n                 */\n\t\tif (tp->sack_enable)\n\t\t\ttp->sack_enable = tp->t_flags & TF_SACK_PERMIT;\n#ifdef TCP_ECN\n\t\t/*\n\t\t * if ECE is set but CWR is not set for SYN-ACK, or\n\t\t * both ECE and CWR are set for simultaneous open,\n\t\t * peer is ECN capable.\n\t\t */\n\t\tif (tcp_do_ecn) {\n\t\t\tswitch (tiflags & (TH_ACK|TH_ECE|TH_CWR)) {\n\t\t\tcase TH_ACK|TH_ECE:\n\t\t\tcase TH_ECE|TH_CWR:\n\t\t\t\ttp->t_flags |= TF_ECN_PERMIT;\n\t\t\t\ttiflags &= ~(TH_ECE|TH_CWR);\n\t\t\t\ttcpstat_inc(tcps_ecn_accepts);\n\t\t\t}\n\t\t}\n#endif\n\n\t\tif (tiflags & TH_ACK && SEQ_GT(tp->snd_una, tp->iss)) {\n\t\t\ttcpstat_inc(tcps_connects);\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsoisconnected(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\ttp->t_state = TCPS_ESTABLISHED;\n\t\t\tTCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);\n\t\t\t/* Do window scaling on this connection? */\n\t\t\tif ((tp->t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==\n\t\t\t\t(TF_RCVD_SCALE|TF_REQ_SCALE)) {\n\t\t\t\ttp->snd_scale = tp->requested_s_scale;\n\t\t\t\ttp->rcv_scale = tp->request_r_scale;\n\t\t\t}\n\t\t\ttcp_flush_queue(tp);\n\n\t\t\t/*\n\t\t\t * if we didn't have to retransmit the SYN,\n\t\t\t * use its rtt as our initial srtt & rtt var.\n\t\t\t */\n\t\t\tif (tp->t_rtttime)\n\t\t\t\ttcp_xmit_timer(tp, tcp_now - tp->t_rtttime);\n\t\t\t/*\n\t\t\t * Since new data was acked (the SYN), open the\n\t\t\t * congestion window by one MSS.  We do this\n\t\t\t * here, because we won't go through the normal\n\t\t\t * ACK processing below.  And since this is the\n\t\t\t * start of the connection, we know we are in\n\t\t\t * the exponential phase of slow-start.\n\t\t\t */\n\t\t\ttp->snd_cwnd += tp->t_maxseg;\n\t\t} else\n\t\t\ttp->t_state = TCPS_SYN_RECEIVED;\n\n#if 0\ntrimthenstep6:\n#endif\n\t\t/*\n\t\t * Advance th->th_seq to correspond to first data byte.\n\t\t * If data, trim to stay within window,\n\t\t * dropping FIN if necessary.\n\t\t */\n\t\tth->th_seq++;\n\t\tif (tlen > tp->rcv_wnd) {\n\t\t\ttodrop = tlen - tp->rcv_wnd;\n\t\t\tm_adj(m, -todrop);\n\t\t\ttlen = tp->rcv_wnd;\n\t\t\ttiflags &= ~TH_FIN;\n\t\t\ttcpstat_pkt(tcps_rcvpackafterwin, tcps_rcvbyteafterwin,\n\t\t\t    todrop);\n\t\t}\n\t\ttp->snd_wl1 = th->th_seq - 1;\n\t\ttp->rcv_up = th->th_seq;\n\t\tgoto step6;\n\t/*\n\t * If a new connection request is received while in TIME_WAIT,\n\t * drop the old connection and start over if the if the\n\t * timestamp or the sequence numbers are above the previous\n\t * ones.\n\t */\n\tcase TCPS_TIME_WAIT:\n\t\tif (((tiflags & (TH_SYN|TH_ACK)) == TH_SYN) &&\n\t\t    ((opti.ts_present &&\n\t\t    TSTMP_LT(tp->ts_recent, opti.ts_val)) ||\n\t\t    SEQ_GT(th->th_seq, tp->rcv_nxt))) {\n#if NPF > 0\n\t\t\t/*\n\t\t\t * The socket will be recreated but the new state\n\t\t\t * has already been linked to the socket.  Remove the\n\t\t\t * link between old socket and new state.\n\t\t\t */\n\t\t\tpf_inp_unlink(inp);\n#endif\n\t\t\t/*\n\t\t\t* Advance the iss by at least 32768, but\n\t\t\t* clear the msb in order to make sure\n\t\t\t* that SEG_LT(snd_nxt, iss).\n\t\t\t*/\n\t\t\tiss = tp->snd_nxt +\n\t\t\t    ((arc4random() & 0x7fffffff) | 0x8000);\n\t\t\treuse = &iss;\n\t\t\ttp = tcp_close(tp);\n\t\t\tinp = NULL;\n\t\t\tgoto findpcb;\n\t\t}\n\t}\n\n\t/*\n\t * States other than LISTEN or SYN_SENT.\n\t * First check timestamp, if present.\n\t * Then check that at least some bytes of segment are within\n\t * receive window.  If segment begins before rcv_nxt,\n\t * drop leading data (and SYN); if nothing left, just ack.\n\t *\n\t * RFC 1323 PAWS: If we have a timestamp reply on this segment\n\t * and it's less than opti.ts_recent, drop it.\n\t */\n\tif (opti.ts_present && (tiflags & TH_RST) == 0 && tp->ts_recent &&\n\t    TSTMP_LT(opti.ts_val, tp->ts_recent)) {\n\n\t\t/* Check to see if ts_recent is over 24 days old.  */\n\t\tif ((int)(tcp_now - tp->ts_recent_age) > TCP_PAWS_IDLE) {\n\t\t\t/*\n\t\t\t * Invalidate ts_recent.  If this segment updates\n\t\t\t * ts_recent, the age will be reset later and ts_recent\n\t\t\t * will get a valid value.  If it does not, setting\n\t\t\t * ts_recent to zero will at least satisfy the\n\t\t\t * requirement that zero be placed in the timestamp\n\t\t\t * echo reply when ts_recent isn't valid.  The\n\t\t\t * age isn't reset until we get a valid ts_recent\n\t\t\t * because we don't want out-of-order segments to be\n\t\t\t * dropped when ts_recent is old.\n\t\t\t */\n\t\t\ttp->ts_recent = 0;\n\t\t} else {\n\t\t\ttcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte, tlen);\n\t\t\ttcpstat_inc(tcps_pawsdrop);\n\t\t\tif (tlen)\n\t\t\t\tgoto dropafterack;\n\t\t\tgoto drop;\n\t\t}\n\t}\n\n\ttodrop = tp->rcv_nxt - th->th_seq;\n\tif (todrop > 0) {\n\t\tif (tiflags & TH_SYN) {\n\t\t\ttiflags &= ~TH_SYN;\n\t\t\tth->th_seq++;\n\t\t\tif (th->th_urp > 1)\n\t\t\t\tth->th_urp--;\n\t\t\telse\n\t\t\t\ttiflags &= ~TH_URG;\n\t\t\ttodrop--;\n\t\t}\n\t\tif (todrop > tlen ||\n\t\t    (todrop == tlen && (tiflags & TH_FIN) == 0)) {\n\t\t\t/*\n\t\t\t * Any valid FIN must be to the left of the\n\t\t\t * window.  At this point, FIN must be a\n\t\t\t * duplicate or out-of-sequence, so drop it.\n\t\t\t */\n\t\t\ttiflags &= ~TH_FIN;\n\t\t\t/*\n\t\t\t * Send ACK to resynchronize, and drop any data,\n\t\t\t * but keep on processing for RST or ACK.\n\t\t\t */\n\t\t\ttp->t_flags |= TF_ACKNOW;\n\t\t\ttodrop = tlen;\n\t\t\ttcpstat_pkt(tcps_rcvduppack, tcps_rcvdupbyte, todrop);\n\t\t} else {\n\t\t\ttcpstat_pkt(tcps_rcvpartduppack, tcps_rcvpartdupbyte,\n\t\t\t    todrop);\n\t\t}\n\t\thdroptlen += todrop;\t/* drop from head afterwards */\n\t\tth->th_seq += todrop;\n\t\ttlen -= todrop;\n\t\tif (th->th_urp > todrop)\n\t\t\tth->th_urp -= todrop;\n\t\telse {\n\t\t\ttiflags &= ~TH_URG;\n\t\t\tth->th_urp = 0;\n\t\t}\n\t}\n\n\t/*\n\t * If new data are received on a connection after the\n\t * user processes are gone, then RST the other end.\n\t */\n\tif ((so->so_state & SS_NOFDREF) &&\n\t    tp->t_state > TCPS_CLOSE_WAIT && tlen) {\n\t\ttp = tcp_close(tp);\n\t\ttcpstat_inc(tcps_rcvafterclose);\n\t\tgoto dropwithreset;\n\t}\n\n\t/*\n\t * If segment ends after window, drop trailing data\n\t * (and PUSH and FIN); if nothing left, just ACK.\n\t */\n\ttodrop = (th->th_seq + tlen) - (tp->rcv_nxt+tp->rcv_wnd);\n\tif (todrop > 0) {\n\t\ttcpstat_inc(tcps_rcvpackafterwin);\n\t\tif (todrop >= tlen) {\n\t\t\ttcpstat_add(tcps_rcvbyteafterwin, tlen);\n\t\t\t/*\n\t\t\t * If window is closed can only take segments at\n\t\t\t * window edge, and have to drop data and PUSH from\n\t\t\t * incoming segments.  Continue processing, but\n\t\t\t * remember to ack.  Otherwise, drop segment\n\t\t\t * and ack.\n\t\t\t */\n\t\t\tif (tp->rcv_wnd == 0 && th->th_seq == tp->rcv_nxt) {\n\t\t\t\ttp->t_flags |= TF_ACKNOW;\n\t\t\t\ttcpstat_inc(tcps_rcvwinprobe);\n\t\t\t} else\n\t\t\t\tgoto dropafterack;\n\t\t} else\n\t\t\ttcpstat_add(tcps_rcvbyteafterwin, todrop);\n\t\tm_adj(m, -todrop);\n\t\ttlen -= todrop;\n\t\ttiflags &= ~(TH_PUSH|TH_FIN);\n\t}\n\n\t/*\n\t * If last ACK falls within this segment's sequence numbers,\n\t * record its timestamp if it's more recent.\n\t * NOTE that the test is modified according to the latest\n\t * proposal of the tcplw@cray.com list (Braden 1993/04/26).\n\t */\n\tif (opti.ts_present && TSTMP_GEQ(opti.ts_val, tp->ts_recent) &&\n\t    SEQ_LEQ(th->th_seq, tp->last_ack_sent)) {\n\t\ttp->ts_recent_age = tcp_now;\n\t\ttp->ts_recent = opti.ts_val;\n\t}\n\n\t/*\n\t * If the RST bit is set examine the state:\n\t *    SYN_RECEIVED STATE:\n\t *\tIf passive open, return to LISTEN state.\n\t *\tIf active open, inform user that connection was refused.\n\t *    ESTABLISHED, FIN_WAIT_1, FIN_WAIT2, CLOSE_WAIT STATES:\n\t *\tInform user that connection was reset, and close tcb.\n\t *    CLOSING, LAST_ACK, TIME_WAIT STATES\n\t *\tClose the tcb.\n\t */\n\tif (tiflags & TH_RST) {\n\t\tif (th->th_seq != tp->last_ack_sent &&\n\t\t    th->th_seq != tp->rcv_nxt &&\n\t\t    th->th_seq != (tp->rcv_nxt + 1))\n\t\t\tgoto drop;\n\n\t\tswitch (tp->t_state) {\n\t\tcase TCPS_SYN_RECEIVED:\n#ifdef TCP_ECN\n\t\t\t/* if ECN is enabled, fall back to non-ecn at rexmit */\n\t\t\tif (tcp_do_ecn && !(tp->t_flags & TF_DISABLE_ECN))\n\t\t\t\tgoto drop;\n#endif\n\t\t\tso->so_error = ECONNREFUSED;\n\t\t\tgoto close;\n\n\t\tcase TCPS_ESTABLISHED:\n\t\tcase TCPS_FIN_WAIT_1:\n\t\tcase TCPS_FIN_WAIT_2:\n\t\tcase TCPS_CLOSE_WAIT:\n\t\t\tso->so_error = ECONNRESET;\n\t\tclose:\n\t\t\ttp->t_state = TCPS_CLOSED;\n\t\t\ttcpstat_inc(tcps_drops);\n\t\t\ttp = tcp_close(tp);\n\t\t\tgoto drop;\n\t\tcase TCPS_CLOSING:\n\t\tcase TCPS_LAST_ACK:\n\t\tcase TCPS_TIME_WAIT:\n\t\t\ttp = tcp_close(tp);\n\t\t\tgoto drop;\n\t\t}\n\t}\n\n\t/*\n\t * If a SYN is in the window, then this is an\n\t * error and we ACK and drop the packet.\n\t */\n\tif (tiflags & TH_SYN)\n\t\tgoto dropafterack_ratelim;\n\n\t/*\n\t * If the ACK bit is off we drop the segment and return.\n\t */\n\tif ((tiflags & TH_ACK) == 0) {\n\t\tif (tp->t_flags & TF_ACKNOW)\n\t\t\tgoto dropafterack;\n\t\telse\n\t\t\tgoto drop;\n\t}\n\n\t/*\n\t * Ack processing.\n\t */\n\tswitch (tp->t_state) {\n\n\t/*\n\t * In SYN_RECEIVED state, the ack ACKs our SYN, so enter\n\t * ESTABLISHED state and continue processing.\n\t * The ACK was checked above.\n\t */\n\tcase TCPS_SYN_RECEIVED:\n\t\ttcpstat_inc(tcps_connects);\n\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\tsoisconnected(so);\n\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\ttp->t_state = TCPS_ESTABLISHED;\n\t\tTCP_TIMER_ARM(tp, TCPT_KEEP, tcp_keepidle);\n\t\t/* Do window scaling? */\n\t\tif ((tp->t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==\n\t\t\t(TF_RCVD_SCALE|TF_REQ_SCALE)) {\n\t\t\ttp->snd_scale = tp->requested_s_scale;\n\t\t\ttp->rcv_scale = tp->request_r_scale;\n\t\t\ttiwin = th->th_win << tp->snd_scale;\n\t\t}\n\t\ttcp_flush_queue(tp);\n\t\ttp->snd_wl1 = th->th_seq - 1;\n\t\t/* fall into ... */\n\n\t/*\n\t * In ESTABLISHED state: drop duplicate ACKs; ACK out of range\n\t * ACKs.  If the ack is in the range\n\t *\ttp->snd_una < th->th_ack <= tp->snd_max\n\t * then advance tp->snd_una to th->th_ack and drop\n\t * data from the retransmission queue.  If this ACK reflects\n\t * more up to date window information we update our window information.\n\t */\n\tcase TCPS_ESTABLISHED:\n\tcase TCPS_FIN_WAIT_1:\n\tcase TCPS_FIN_WAIT_2:\n\tcase TCPS_CLOSE_WAIT:\n\tcase TCPS_CLOSING:\n\tcase TCPS_LAST_ACK:\n\tcase TCPS_TIME_WAIT:\n#ifdef TCP_ECN\n\t\t/*\n\t\t * if we receive ECE and are not already in recovery phase,\n\t\t * reduce cwnd by half but don't slow-start.\n\t\t * advance snd_last to snd_max not to reduce cwnd again\n\t\t * until all outstanding packets are acked.\n\t\t */\n\t\tif (tcp_do_ecn && (tiflags & TH_ECE)) {\n\t\t\tif ((tp->t_flags & TF_ECN_PERMIT) &&\n\t\t\t    SEQ_GEQ(tp->snd_una, tp->snd_last)) {\n\t\t\t\tu_int win;\n\n\t\t\t\twin = min(tp->snd_wnd, tp->snd_cwnd) / tp->t_maxseg;\n\t\t\t\tif (win > 1) {\n\t\t\t\t\ttp->snd_ssthresh = win / 2 * tp->t_maxseg;\n\t\t\t\t\ttp->snd_cwnd = tp->snd_ssthresh;\n\t\t\t\t\ttp->snd_last = tp->snd_max;\n\t\t\t\t\ttp->t_flags |= TF_SEND_CWR;\n\t\t\t\t\ttcpstat_inc(tcps_cwr_ecn);\n\t\t\t\t}\n\t\t\t}\n\t\t\ttcpstat_inc(tcps_ecn_rcvece);\n\t\t}\n\t\t/*\n\t\t * if we receive CWR, we know that the peer has reduced\n\t\t * its congestion window.  stop sending ecn-echo.\n\t\t */\n\t\tif ((tiflags & TH_CWR)) {\n\t\t\ttp->t_flags &= ~TF_RCVD_CE;\n\t\t\ttcpstat_inc(tcps_ecn_rcvcwr);\n\t\t}\n#endif /* TCP_ECN */\n\n\t\tif (SEQ_LEQ(th->th_ack, tp->snd_una)) {\n\t\t\t/*\n\t\t\t * Duplicate/old ACK processing.\n\t\t\t * Increments t_dupacks:\n\t\t\t *\tPure duplicate (same seq/ack/window, no data)\n\t\t\t * Doesn't affect t_dupacks:\n\t\t\t *\tData packets.\n\t\t\t *\tNormal window updates (window opens)\n\t\t\t * Resets t_dupacks:\n\t\t\t *\tNew data ACKed.\n\t\t\t *\tWindow shrinks\n\t\t\t *\tOld ACK\n\t\t\t */\n\t\t\tif (tlen) {\n\t\t\t\t/* Drop very old ACKs unless th_seq matches */\n\t\t\t\tif (th->th_seq != tp->rcv_nxt &&\n\t\t\t\t   SEQ_LT(th->th_ack,\n\t\t\t\t   tp->snd_una - tp->max_sndwnd)) {\n\t\t\t\t\ttcpstat_inc(tcps_rcvacktooold);\n\t\t\t\t\tgoto drop;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/*\n\t\t\t * If we get an old ACK, there is probably packet\n\t\t\t * reordering going on.  Be conservative and reset\n\t\t\t * t_dupacks so that we are less aggressive in\n\t\t\t * doing a fast retransmit.\n\t\t\t */\n\t\t\tif (th->th_ack != tp->snd_una) {\n\t\t\t\ttp->t_dupacks = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif (tiwin == tp->snd_wnd) {\n\t\t\t\ttcpstat_inc(tcps_rcvdupack);\n\t\t\t\t/*\n\t\t\t\t * If we have outstanding data (other than\n\t\t\t\t * a window probe), this is a completely\n\t\t\t\t * duplicate ack (ie, window info didn't\n\t\t\t\t * change), the ack is the biggest we've\n\t\t\t\t * seen and we've seen exactly our rexmt\n\t\t\t\t * threshold of them, assume a packet\n\t\t\t\t * has been dropped and retransmit it.\n\t\t\t\t * Kludge snd_nxt & the congestion\n\t\t\t\t * window so we send only this one\n\t\t\t\t * packet.\n\t\t\t\t *\n\t\t\t\t * We know we're losing at the current\n\t\t\t\t * window size so do congestion avoidance\n\t\t\t\t * (set ssthresh to half the current window\n\t\t\t\t * and pull our congestion window back to\n\t\t\t\t * the new ssthresh).\n\t\t\t\t *\n\t\t\t\t * Dup acks mean that packets have left the\n\t\t\t\t * network (they're now cached at the receiver)\n\t\t\t\t * so bump cwnd by the amount in the receiver\n\t\t\t\t * to keep a constant cwnd packets in the\n\t\t\t\t * network.\n\t\t\t\t */\n\t\t\t\tif (TCP_TIMER_ISARMED(tp, TCPT_REXMT) == 0)\n\t\t\t\t\ttp->t_dupacks = 0;\n\t\t\t\telse if (++tp->t_dupacks == tcprexmtthresh) {\n\t\t\t\t\ttcp_seq onxt = tp->snd_nxt;\n\t\t\t\t\tu_long win =\n\t\t\t\t\t    ulmin(tp->snd_wnd, tp->snd_cwnd) /\n\t\t\t\t\t\t2 / tp->t_maxseg;\n\n\t\t\t\t\tif (SEQ_LT(th->th_ack, tp->snd_last)){\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * False fast retx after\n\t\t\t\t\t\t * timeout.  Do not cut window.\n\t\t\t\t\t\t */\n\t\t\t\t\t\ttp->t_dupacks = 0;\n\t\t\t\t\t\tgoto drop;\n\t\t\t\t\t}\n\t\t\t\t\tif (win < 2)\n\t\t\t\t\t\twin = 2;\n\t\t\t\t\ttp->snd_ssthresh = win * tp->t_maxseg;\n\t\t\t\t\ttp->snd_last = tp->snd_max;\n\t\t\t\t\tif (tp->sack_enable) {\n\t\t\t\t\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\t\t\t\t\ttp->t_rtttime = 0;\n#ifdef TCP_ECN\n\t\t\t\t\t\ttp->t_flags |= TF_SEND_CWR;\n#endif\n\t\t\t\t\t\ttcpstat_inc(tcps_cwr_frecovery);\n\t\t\t\t\t\ttcpstat_inc(tcps_sack_recovery_episode);\n\t\t\t\t\t\t/*\n\t\t\t\t\t\t * tcp_output() will send\n\t\t\t\t\t\t * oldest SACK-eligible rtx.\n\t\t\t\t\t\t */\n\t\t\t\t\t\t(void) tcp_output(tp);\n\t\t\t\t\t\ttp->snd_cwnd = tp->snd_ssthresh+\n\t\t\t\t\t           tp->t_maxseg * tp->t_dupacks;\n\t\t\t\t\t\tgoto drop;\n\t\t\t\t\t}\n\t\t\t\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\t\t\t\ttp->t_rtttime = 0;\n\t\t\t\t\ttp->snd_nxt = th->th_ack;\n\t\t\t\t\ttp->snd_cwnd = tp->t_maxseg;\n#ifdef TCP_ECN\n\t\t\t\t\ttp->t_flags |= TF_SEND_CWR;\n#endif\n\t\t\t\t\ttcpstat_inc(tcps_cwr_frecovery);\n\t\t\t\t\ttcpstat_inc(tcps_sndrexmitfast);\n\t\t\t\t\t(void) tcp_output(tp);\n\n\t\t\t\t\ttp->snd_cwnd = tp->snd_ssthresh +\n\t\t\t\t\t    tp->t_maxseg * tp->t_dupacks;\n\t\t\t\t\tif (SEQ_GT(onxt, tp->snd_nxt))\n\t\t\t\t\t\ttp->snd_nxt = onxt;\n\t\t\t\t\tgoto drop;\n\t\t\t\t} else if (tp->t_dupacks > tcprexmtthresh) {\n\t\t\t\t\ttp->snd_cwnd += tp->t_maxseg;\n\t\t\t\t\t(void) tcp_output(tp);\n\t\t\t\t\tgoto drop;\n\t\t\t\t}\n\t\t\t} else if (tiwin < tp->snd_wnd) {\n\t\t\t\t/*\n\t\t\t\t * The window was retracted!  Previous dup\n\t\t\t\t * ACKs may have been due to packets arriving\n\t\t\t\t * after the shrunken window, not a missing\n\t\t\t\t * packet, so play it safe and reset t_dupacks\n\t\t\t\t */\n\t\t\t\ttp->t_dupacks = 0;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t/*\n\t\t * If the congestion window was inflated to account\n\t\t * for the other side's cached packets, retract it.\n\t\t */\n\t\tif (tp->t_dupacks >= tcprexmtthresh) {\n\t\t\t/* Check for a partial ACK */\n\t\t\tif (SEQ_LT(th->th_ack, tp->snd_last)) {\n\t\t\t\tif (tp->sack_enable)\n\t\t\t\t\ttcp_sack_partialack(tp, th);\n\t\t\t\telse\n\t\t\t\t\ttcp_newreno_partialack(tp, th);\n\t\t\t} else {\n\t\t\t\t/* Out of fast recovery */\n\t\t\t\ttp->snd_cwnd = tp->snd_ssthresh;\n\t\t\t\tif (tcp_seq_subtract(tp->snd_max, th->th_ack) <\n\t\t\t\t    tp->snd_ssthresh)\n\t\t\t\t\ttp->snd_cwnd =\n\t\t\t\t\t    tcp_seq_subtract(tp->snd_max,\n\t\t\t\t\t    th->th_ack);\n\t\t\t\ttp->t_dupacks = 0;\n\t\t\t}\n\t\t} else {\n\t\t\t/*\n\t\t\t * Reset the duplicate ACK counter if we\n\t\t\t * were not in fast recovery.\n\t\t\t */\n\t\t\ttp->t_dupacks = 0;\n\t\t}\n\t\tif (SEQ_GT(th->th_ack, tp->snd_max)) {\n\t\t\ttcpstat_inc(tcps_rcvacktoomuch);\n\t\t\tgoto dropafterack_ratelim;\n\t\t}\n\t\tacked = th->th_ack - tp->snd_una;\n\t\ttcpstat_pkt(tcps_rcvackpack, tcps_rcvackbyte, acked);\n\n\t\t/*\n\t\t * If we have a timestamp reply, update smoothed\n\t\t * round trip time.  If no timestamp is present but\n\t\t * transmit timer is running and timed sequence\n\t\t * number was acked, update smoothed round trip time.\n\t\t * Since we now have an rtt measurement, cancel the\n\t\t * timer backoff (cf., Phil Karn's retransmit alg.).\n\t\t * Recompute the initial retransmit timer.\n\t\t */\n\t\tif (opti.ts_present && opti.ts_ecr)\n\t\t\ttcp_xmit_timer(tp, tcp_now - opti.ts_ecr);\n\t\telse if (tp->t_rtttime && SEQ_GT(th->th_ack, tp->t_rtseq))\n\t\t\ttcp_xmit_timer(tp, tcp_now - tp->t_rtttime);\n\n\t\t/*\n\t\t * If all outstanding data is acked, stop retransmit\n\t\t * timer and remember to restart (more output or persist).\n\t\t * If there is more data to be acked, restart retransmit\n\t\t * timer, using current (possibly backed-off) value.\n\t\t */\n\t\tif (th->th_ack == tp->snd_max) {\n\t\t\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\t\t\ttp->t_flags |= TF_NEEDOUTPUT;\n\t\t} else if (TCP_TIMER_ISARMED(tp, TCPT_PERSIST) == 0)\n\t\t\tTCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);\n\t\t/*\n\t\t * When new data is acked, open the congestion window.\n\t\t * If the window gives us less than ssthresh packets\n\t\t * in flight, open exponentially (maxseg per packet).\n\t\t * Otherwise open linearly: maxseg per window\n\t\t * (maxseg^2 / cwnd per packet).\n\t\t */\n\t\t{\n\t\tu_int cw = tp->snd_cwnd;\n\t\tu_int incr = tp->t_maxseg;\n\n\t\tif (cw > tp->snd_ssthresh)\n\t\t\tincr = incr * incr / cw;\n\t\tif (tp->t_dupacks < tcprexmtthresh)\n\t\t\ttp->snd_cwnd = ulmin(cw + incr,\n\t\t\t    TCP_MAXWIN << tp->snd_scale);\n\t\t}\n\t\tND6_HINT(tp);\n\t\tif (acked > so->so_snd.sb_cc) {\n\t\t\ttp->snd_wnd -= so->so_snd.sb_cc;\n\t\t\tsbdrop(so, &so->so_snd, (int)so->so_snd.sb_cc);\n\t\t\tourfinisacked = 1;\n\t\t} else {\n\t\t\tsbdrop(so, &so->so_snd, acked);\n\t\t\ttp->snd_wnd -= acked;\n\t\t\tourfinisacked = 0;\n\t\t}\n\n\t\ttcp_update_sndspace(tp);\n\t\tif (sb_notify(so, &so->so_snd)) {\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsowwakeup(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t}\n\n\t\t/*\n\t\t * If we had a pending ICMP message that referred to data\n\t\t * that have just been acknowledged, disregard the recorded\n\t\t * ICMP message.\n\t\t */\n\t\tif ((tp->t_flags & TF_PMTUD_PEND) &&\n\t\t    SEQ_GT(th->th_ack, tp->t_pmtud_th_seq))\n\t\t\ttp->t_flags &= ~TF_PMTUD_PEND;\n\n\t\t/*\n\t\t * Keep track of the largest chunk of data acknowledged\n\t\t * since last PMTU update\n\t\t */\n\t\tif (tp->t_pmtud_mss_acked < acked)\n\t\t\ttp->t_pmtud_mss_acked = acked;\n\n\t\ttp->snd_una = th->th_ack;\n#ifdef TCP_ECN\n\t\t/* sync snd_last with snd_una */\n\t\tif (SEQ_GT(tp->snd_una, tp->snd_last))\n\t\t\ttp->snd_last = tp->snd_una;\n#endif\n\t\tif (SEQ_LT(tp->snd_nxt, tp->snd_una))\n\t\t\ttp->snd_nxt = tp->snd_una;\n\n\t\tswitch (tp->t_state) {\n\n\t\t/*\n\t\t * In FIN_WAIT_1 STATE in addition to the processing\n\t\t * for the ESTABLISHED state if our FIN is now acknowledged\n\t\t * then enter FIN_WAIT_2.\n\t\t */\n\t\tcase TCPS_FIN_WAIT_1:\n\t\t\tif (ourfinisacked) {\n\t\t\t\t/*\n\t\t\t\t * If we can't receive any more\n\t\t\t\t * data, then closing user can proceed.\n\t\t\t\t * Starting the timer is contrary to the\n\t\t\t\t * specification, but if we don't get a FIN\n\t\t\t\t * we'll hang forever.\n\t\t\t\t */\n\t\t\t\tif (so->so_state & SS_CANTRCVMORE) {\n\t\t\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\t\t\tsoisdisconnected(so);\n\t\t\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, tcp_maxidle);\n\t\t\t\t}\n\t\t\t\ttp->t_state = TCPS_FIN_WAIT_2;\n\t\t\t}\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In CLOSING STATE in addition to the processing for\n\t\t * the ESTABLISHED state if the ACK acknowledges our FIN\n\t\t * then enter the TIME-WAIT state, otherwise ignore\n\t\t * the segment.\n\t\t */\n\t\tcase TCPS_CLOSING:\n\t\t\tif (ourfinisacked) {\n\t\t\t\ttp->t_state = TCPS_TIME_WAIT;\n\t\t\t\ttcp_canceltimers(tp);\n\t\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);\n\t\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\t\tsoisdisconnected(so);\n\t\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\t}\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In LAST_ACK, we may still be waiting for data to drain\n\t\t * and/or to be acked, as well as for the ack of our FIN.\n\t\t * If our FIN is now acknowledged, delete the TCB,\n\t\t * enter the closed state and return.\n\t\t */\n\t\tcase TCPS_LAST_ACK:\n\t\t\tif (ourfinisacked) {\n\t\t\t\ttp = tcp_close(tp);\n\t\t\t\tgoto drop;\n\t\t\t}\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In TIME_WAIT state the only thing that should arrive\n\t\t * is a retransmission of the remote FIN.  Acknowledge\n\t\t * it and restart the finack timer.\n\t\t */\n\t\tcase TCPS_TIME_WAIT:\n\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);\n\t\t\tgoto dropafterack;\n\t\t}\n\t}\n\nstep6:\n\t/*\n\t * Update window information.\n\t * Don't look at window if no ACK: TAC's send garbage on first SYN.\n\t */\n\tif ((tiflags & TH_ACK) &&\n\t    (SEQ_LT(tp->snd_wl1, th->th_seq) || (tp->snd_wl1 == th->th_seq &&\n\t    (SEQ_LT(tp->snd_wl2, th->th_ack) ||\n\t    (tp->snd_wl2 == th->th_ack && tiwin > tp->snd_wnd))))) {\n\t\t/* keep track of pure window updates */\n\t\tif (tlen == 0 &&\n\t\t    tp->snd_wl2 == th->th_ack && tiwin > tp->snd_wnd)\n\t\t\ttcpstat_inc(tcps_rcvwinupd);\n\t\ttp->snd_wnd = tiwin;\n\t\ttp->snd_wl1 = th->th_seq;\n\t\ttp->snd_wl2 = th->th_ack;\n\t\tif (tp->snd_wnd > tp->max_sndwnd)\n\t\t\ttp->max_sndwnd = tp->snd_wnd;\n\t\ttp->t_flags |= TF_NEEDOUTPUT;\n\t}\n\n\t/*\n\t * Process segments with URG.\n\t */\n\tif ((tiflags & TH_URG) && th->th_urp &&\n\t    TCPS_HAVERCVDFIN(tp->t_state) == 0) {\n\t\t/*\n\t\t * This is a kludge, but if we receive and accept\n\t\t * random urgent pointers, we'll crash in\n\t\t * soreceive.  It's hard to imagine someone\n\t\t * actually wanting to send this much urgent data.\n\t\t */\n\t\tif (th->th_urp + so->so_rcv.sb_cc > sb_max) {\n\t\t\tth->th_urp = 0;\t\t\t/* XXX */\n\t\t\ttiflags &= ~TH_URG;\t\t/* XXX */\n\t\t\tgoto dodata;\t\t\t/* XXX */\n\t\t}\n\t\t/*\n\t\t * If this segment advances the known urgent pointer,\n\t\t * then mark the data stream.  This should not happen\n\t\t * in CLOSE_WAIT, CLOSING, LAST_ACK or TIME_WAIT STATES since\n\t\t * a FIN has been received from the remote side.\n\t\t * In these states we ignore the URG.\n\t\t *\n\t\t * According to RFC961 (Assigned Protocols),\n\t\t * the urgent pointer points to the last octet\n\t\t * of urgent data.  We continue, however,\n\t\t * to consider it to indicate the first octet\n\t\t * of data past the urgent section as the original\n\t\t * spec states (in one of two places).\n\t\t */\n\t\tif (SEQ_GT(th->th_seq+th->th_urp, tp->rcv_up)) {\n\t\t\ttp->rcv_up = th->th_seq + th->th_urp;\n\t\t\tso->so_oobmark = so->so_rcv.sb_cc +\n\t\t\t    (tp->rcv_up - tp->rcv_nxt) - 1;\n\t\t\tif (so->so_oobmark == 0)\n\t\t\t\tso->so_state |= SS_RCVATMARK;\n\t\t\tsohasoutofband(so);\n\t\t\ttp->t_oobflags &= ~(TCPOOB_HAVEDATA | TCPOOB_HADDATA);\n\t\t}\n\t\t/*\n\t\t * Remove out of band data so doesn't get presented to user.\n\t\t * This can happen independent of advancing the URG pointer,\n\t\t * but if two URG's are pending at once, some out-of-band\n\t\t * data may creep in... ick.\n\t\t */\n\t\tif (th->th_urp <= (u_int16_t) tlen &&\n\t\t    (so->so_options & SO_OOBINLINE) == 0)\n\t\t        tcp_pulloutofband(so, th->th_urp, m, hdroptlen);\n\t} else\n\t\t/*\n\t\t * If no out of band data is expected,\n\t\t * pull receive urgent pointer along\n\t\t * with the receive window.\n\t\t */\n\t\tif (SEQ_GT(tp->rcv_nxt, tp->rcv_up))\n\t\t\ttp->rcv_up = tp->rcv_nxt;\ndodata:\t\t\t\t\t\t\t/* XXX */\n\n\t/*\n\t * Process the segment text, merging it into the TCP sequencing queue,\n\t * and arranging for acknowledgment of receipt if necessary.\n\t * This process logically involves adjusting tp->rcv_wnd as data\n\t * is presented to the user (this happens in tcp_usrreq.c,\n\t * case PRU_RCVD).  If a FIN has already been received on this\n\t * connection then we just ignore the text.\n\t */\n\tif ((tlen || (tiflags & TH_FIN)) &&\n\t    TCPS_HAVERCVDFIN(tp->t_state) == 0) {\n\t\ttcp_seq laststart = th->th_seq;\n\t\ttcp_seq lastend = th->th_seq + tlen;\n\n\t\tif (th->th_seq == tp->rcv_nxt && TAILQ_EMPTY(&tp->t_segq) &&\n\t\t    tp->t_state == TCPS_ESTABLISHED) {\n\t\t\tTCP_SETUP_ACK(tp, tiflags, m);\n\t\t\ttp->rcv_nxt += tlen;\n\t\t\ttiflags = th->th_flags & TH_FIN;\n\t\t\ttcpstat_pkt(tcps_rcvpack, tcps_rcvbyte, tlen);\n\t\t\tND6_HINT(tp);\n\t\t\tif (so->so_state & SS_CANTRCVMORE)\n\t\t\t\tm_freem(m);\n\t\t\telse {\n\t\t\t\tm_adj(m, hdroptlen);\n\t\t\t\tsbappendstream(so, &so->so_rcv, m);\n\t\t\t}\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsorwakeup(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t} else {\n\t\t\tm_adj(m, hdroptlen);\n\t\t\ttiflags = tcp_reass(tp, th, m, &tlen);\n\t\t\ttp->t_flags |= TF_ACKNOW;\n\t\t}\n\t\tif (tp->sack_enable)\n\t\t\ttcp_update_sack_list(tp, laststart, lastend);\n\n\t\t/*\n\t\t * variable len never referenced again in modern BSD,\n\t\t * so why bother computing it ??\n\t\t */\n#if 0\n\t\t/*\n\t\t * Note the amount of data that peer has sent into\n\t\t * our window, in order to estimate the sender's\n\t\t * buffer size.\n\t\t */\n\t\tlen = so->so_rcv.sb_hiwat - (tp->rcv_adv - tp->rcv_nxt);\n#endif /* 0 */\n\t} else {\n\t\tm_freem(m);\n\t\ttiflags &= ~TH_FIN;\n\t}\n\n\t/*\n\t * If FIN is received ACK the FIN and let the user know\n\t * that the connection is closing.  Ignore a FIN received before\n\t * the connection is fully established.\n\t */\n\tif ((tiflags & TH_FIN) && TCPS_HAVEESTABLISHED(tp->t_state)) {\n\t\tif (TCPS_HAVERCVDFIN(tp->t_state) == 0) {\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsocantrcvmore(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\ttp->t_flags |= TF_ACKNOW;\n\t\t\ttp->rcv_nxt++;\n\t\t}\n\t\tswitch (tp->t_state) {\n\n\t\t/*\n\t\t * In ESTABLISHED STATE enter the CLOSE_WAIT state.\n\t\t */\n\t\tcase TCPS_ESTABLISHED:\n\t\t\ttp->t_state = TCPS_CLOSE_WAIT;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * If still in FIN_WAIT_1 STATE FIN has not been acked so\n\t\t * enter the CLOSING state.\n\t\t */\n\t\tcase TCPS_FIN_WAIT_1:\n\t\t\ttp->t_state = TCPS_CLOSING;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In FIN_WAIT_2 state enter the TIME_WAIT state,\n\t\t * starting the time-wait timer, turning off the other\n\t\t * standard timers.\n\t\t */\n\t\tcase TCPS_FIN_WAIT_2:\n\t\t\ttp->t_state = TCPS_TIME_WAIT;\n\t\t\ttcp_canceltimers(tp);\n\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);\n\t\t\ttp->t_flags |= TF_BLOCKOUTPUT;\n\t\t\tsoisdisconnected(so);\n\t\t\ttp->t_flags &= ~TF_BLOCKOUTPUT;\n\t\t\tbreak;\n\n\t\t/*\n\t\t * In TIME_WAIT state restart the 2 MSL time_wait timer.\n\t\t */\n\t\tcase TCPS_TIME_WAIT:\n\t\t\tTCP_TIMER_ARM(tp, TCPT_2MSL, 2 * TCPTV_MSL);\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (otp)\n\t\ttcp_trace(TA_INPUT, ostate, tp, otp, saveti, 0, tlen);\n\n\t/*\n\t * Return any desired output.\n\t */\n\tif (tp->t_flags & (TF_ACKNOW|TF_NEEDOUTPUT))\n\t\t(void) tcp_output(tp);\n\treturn IPPROTO_DONE;\n\nbadsyn:\n\t/*\n\t * Received a bad SYN.  Increment counters and dropwithreset.\n\t */\n\ttcpstat_inc(tcps_badsyn);\n\ttp = NULL;\n\tgoto dropwithreset;\n\ndropafterack_ratelim:\n\tif (ppsratecheck(&tcp_ackdrop_ppslim_last, &tcp_ackdrop_ppslim_count,\n\t    tcp_ackdrop_ppslim) == 0) {\n\t\t/* XXX stat */\n\t\tgoto drop;\n\t}\n\t/* ...fall into dropafterack... */\n\ndropafterack:\n\t/*\n\t * Generate an ACK dropping incoming segment if it occupies\n\t * sequence space, where the ACK reflects our state.\n\t */\n\tif (tiflags & TH_RST)\n\t\tgoto drop;\n\tm_freem(m);\n\ttp->t_flags |= TF_ACKNOW;\n\t(void) tcp_output(tp);\n\treturn IPPROTO_DONE;\n\ndropwithreset_ratelim:\n\t/*\n\t * We may want to rate-limit RSTs in certain situations,\n\t * particularly if we are sending an RST in response to\n\t * an attempt to connect to or otherwise communicate with\n\t * a port for which we have no socket.\n\t */\n\tif (ppsratecheck(&tcp_rst_ppslim_last, &tcp_rst_ppslim_count,\n\t    tcp_rst_ppslim) == 0) {\n\t\t/* XXX stat */\n\t\tgoto drop;\n\t}\n\t/* ...fall into dropwithreset... */\n\ndropwithreset:\n\t/*\n\t * Generate a RST, dropping incoming segment.\n\t * Make ACK acceptable to originator of segment.\n\t * Don't bother to respond to RST.\n\t */\n\tif (tiflags & TH_RST)\n\t\tgoto drop;\n\tif (tiflags & TH_ACK) {\n\t\ttcp_respond(tp, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack,\n\t\t    TH_RST, m->m_pkthdr.ph_rtableid);\n\t} else {\n\t\tif (tiflags & TH_SYN)\n\t\t\ttlen++;\n\t\ttcp_respond(tp, mtod(m, caddr_t), th, th->th_seq + tlen,\n\t\t    (tcp_seq)0, TH_RST|TH_ACK, m->m_pkthdr.ph_rtableid);\n\t}\n\tm_freem(m);\n\treturn IPPROTO_DONE;\n\ndrop:\n\t/*\n\t * Drop space held by incoming segment and return.\n\t */\n\tif (otp)\n\t\ttcp_trace(TA_DROP, ostate, tp, otp, saveti, 0, tlen);\n\n\tm_freem(m);\n\treturn IPPROTO_DONE;\n}\n\nint\ntcp_dooptions(struct tcpcb *tp, u_char *cp, int cnt, struct tcphdr *th,\n    struct mbuf *m, int iphlen, struct tcp_opt_info *oi,\n    u_int rtableid)\n{\n\tu_int16_t mss = 0;\n\tint opt, optlen;\n#ifdef TCP_SIGNATURE\n\tcaddr_t sigp = NULL;\n\tstruct tdb *tdb = NULL;\n#endif /* TCP_SIGNATURE */\n\n\tfor (; cp && cnt > 0; cnt -= optlen, cp += optlen) {\n\t\topt = cp[0];\n\t\tif (opt == TCPOPT_EOL)\n\t\t\tbreak;\n\t\tif (opt == TCPOPT_NOP)\n\t\t\toptlen = 1;\n\t\telse {\n\t\t\tif (cnt < 2)\n\t\t\t\tbreak;\n\t\t\toptlen = cp[1];\n\t\t\tif (optlen < 2 || optlen > cnt)\n\t\t\t\tbreak;\n\t\t}\n\t\tswitch (opt) {\n\n\t\tdefault:\n\t\t\tcontinue;\n\n\t\tcase TCPOPT_MAXSEG:\n\t\t\tif (optlen != TCPOLEN_MAXSEG)\n\t\t\t\tcontinue;\n\t\t\tif (!(th->th_flags & TH_SYN))\n\t\t\t\tcontinue;\n\t\t\tif (TCPS_HAVERCVDSYN(tp->t_state))\n\t\t\t\tcontinue;\n\t\t\tmemcpy(&mss, cp + 2, sizeof(mss));\n\t\t\tmss = ntohs(mss);\n\t\t\toi->maxseg = mss;\n\t\t\tbreak;\n\n\t\tcase TCPOPT_WINDOW:\n\t\t\tif (optlen != TCPOLEN_WINDOW)\n\t\t\t\tcontinue;\n\t\t\tif (!(th->th_flags & TH_SYN))\n\t\t\t\tcontinue;\n\t\t\tif (TCPS_HAVERCVDSYN(tp->t_state))\n\t\t\t\tcontinue;\n\t\t\ttp->t_flags |= TF_RCVD_SCALE;\n\t\t\ttp->requested_s_scale = min(cp[2], TCP_MAX_WINSHIFT);\n\t\t\tbreak;\n\n\t\tcase TCPOPT_TIMESTAMP:\n\t\t\tif (optlen != TCPOLEN_TIMESTAMP)\n\t\t\t\tcontinue;\n\t\t\toi->ts_present = 1;\n\t\t\tmemcpy(&oi->ts_val, cp + 2, sizeof(oi->ts_val));\n\t\t\toi->ts_val = ntohl(oi->ts_val);\n\t\t\tmemcpy(&oi->ts_ecr, cp + 6, sizeof(oi->ts_ecr));\n\t\t\toi->ts_ecr = ntohl(oi->ts_ecr);\n\n\t\t\tif (!(th->th_flags & TH_SYN))\n\t\t\t\tcontinue;\n\t\t\tif (TCPS_HAVERCVDSYN(tp->t_state))\n\t\t\t\tcontinue;\n\t\t\t/*\n\t\t\t * A timestamp received in a SYN makes\n\t\t\t * it ok to send timestamp requests and replies.\n\t\t\t */\n\t\t\ttp->t_flags |= TF_RCVD_TSTMP;\n\t\t\ttp->ts_recent = oi->ts_val;\n\t\t\ttp->ts_recent_age = tcp_now;\n\t\t\tbreak;\n\n\t\tcase TCPOPT_SACK_PERMITTED:\n\t\t\tif (!tp->sack_enable || optlen!=TCPOLEN_SACK_PERMITTED)\n\t\t\t\tcontinue;\n\t\t\tif (!(th->th_flags & TH_SYN))\n\t\t\t\tcontinue;\n\t\t\tif (TCPS_HAVERCVDSYN(tp->t_state))\n\t\t\t\tcontinue;\n\t\t\t/* MUST only be set on SYN */\n\t\t\ttp->t_flags |= TF_SACK_PERMIT;\n\t\t\tbreak;\n\t\tcase TCPOPT_SACK:\n\t\t\ttcp_sack_option(tp, th, cp, optlen);\n\t\t\tbreak;\n#ifdef TCP_SIGNATURE\n\t\tcase TCPOPT_SIGNATURE:\n\t\t\tif (optlen != TCPOLEN_SIGNATURE)\n\t\t\t\tcontinue;\n\n\t\t\tif (sigp && timingsafe_bcmp(sigp, cp + 2, 16))\n\t\t\t\treturn (-1);\n\n\t\t\tsigp = cp + 2;\n\t\t\tbreak;\n#endif /* TCP_SIGNATURE */\n\t\t}\n\t}\n\n#ifdef TCP_SIGNATURE\n\tif (tp->t_flags & TF_SIGNATURE) {\n\t\tunion sockaddr_union src, dst;\n\n\t\tmemset(&src, 0, sizeof(union sockaddr_union));\n\t\tmemset(&dst, 0, sizeof(union sockaddr_union));\n\n\t\tswitch (tp->pf) {\n\t\tcase 0:\n\t\tcase AF_INET:\n\t\t\tsrc.sa.sa_len = sizeof(struct sockaddr_in);\n\t\t\tsrc.sa.sa_family = AF_INET;\n\t\t\tsrc.sin.sin_addr = mtod(m, struct ip *)->ip_src;\n\t\t\tdst.sa.sa_len = sizeof(struct sockaddr_in);\n\t\t\tdst.sa.sa_family = AF_INET;\n\t\t\tdst.sin.sin_addr = mtod(m, struct ip *)->ip_dst;\n\t\t\tbreak;\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tsrc.sa.sa_len = sizeof(struct sockaddr_in6);\n\t\t\tsrc.sa.sa_family = AF_INET6;\n\t\t\tsrc.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_src;\n\t\t\tdst.sa.sa_len = sizeof(struct sockaddr_in6);\n\t\t\tdst.sa.sa_family = AF_INET6;\n\t\t\tdst.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;\n\t\t\tbreak;\n#endif /* INET6 */\n\t\t}\n\n\t\ttdb = gettdbbysrcdst(rtable_l2(rtableid),\n\t\t    0, &src, &dst, IPPROTO_TCP);\n\n\t\t/*\n\t\t * We don't have an SA for this peer, so we turn off\n\t\t * TF_SIGNATURE on the listen socket\n\t\t */\n\t\tif (tdb == NULL && tp->t_state == TCPS_LISTEN)\n\t\t\ttp->t_flags &= ~TF_SIGNATURE;\n\n\t}\n\n\tif ((sigp ? TF_SIGNATURE : 0) ^ (tp->t_flags & TF_SIGNATURE)) {\n\t\ttcpstat_inc(tcps_rcvbadsig);\n\t\treturn (-1);\n\t}\n\n\tif (sigp) {\n\t\tchar sig[16];\n\n\t\tif (tdb == NULL) {\n\t\t\ttcpstat_inc(tcps_rcvbadsig);\n\t\t\treturn (-1);\n\t\t}\n\n\t\tif (tcp_signature(tdb, tp->pf, m, th, iphlen, 1, sig) < 0)\n\t\t\treturn (-1);\n\n\t\tif (timingsafe_bcmp(sig, sigp, 16)) {\n\t\t\ttcpstat_inc(tcps_rcvbadsig);\n\t\t\treturn (-1);\n\t\t}\n\n\t\ttcpstat_inc(tcps_rcvgoodsig);\n\t}\n#endif /* TCP_SIGNATURE */\n\n\treturn (0);\n}\n\nu_long\ntcp_seq_subtract(u_long a, u_long b)\n{\n\treturn ((long)(a - b));\n}\n\n/*\n * This function is called upon receipt of new valid data (while not in header\n * prediction mode), and it updates the ordered list of sacks.\n */\nvoid\ntcp_update_sack_list(struct tcpcb *tp, tcp_seq rcv_laststart,\n    tcp_seq rcv_lastend)\n{\n\t/*\n\t * First reported block MUST be the most recent one.  Subsequent\n\t * blocks SHOULD be in the order in which they arrived at the\n\t * receiver.  These two conditions make the implementation fully\n\t * compliant with RFC 2018.\n\t */\n\tint i, j = 0, count = 0, lastpos = -1;\n\tstruct sackblk sack, firstsack, temp[MAX_SACK_BLKS];\n\n\t/* First clean up current list of sacks */\n\tfor (i = 0; i < tp->rcv_numsacks; i++) {\n\t\tsack = tp->sackblks[i];\n\t\tif (sack.start == 0 && sack.end == 0) {\n\t\t\tcount++; /* count = number of blocks to be discarded */\n\t\t\tcontinue;\n\t\t}\n\t\tif (SEQ_LEQ(sack.end, tp->rcv_nxt)) {\n\t\t\ttp->sackblks[i].start = tp->sackblks[i].end = 0;\n\t\t\tcount++;\n\t\t} else {\n\t\t\ttemp[j].start = tp->sackblks[i].start;\n\t\t\ttemp[j++].end = tp->sackblks[i].end;\n\t\t}\n\t}\n\ttp->rcv_numsacks -= count;\n\tif (tp->rcv_numsacks == 0) { /* no sack blocks currently (fast path) */\n\t\ttcp_clean_sackreport(tp);\n\t\tif (SEQ_LT(tp->rcv_nxt, rcv_laststart)) {\n\t\t\t/* ==> need first sack block */\n\t\t\ttp->sackblks[0].start = rcv_laststart;\n\t\t\ttp->sackblks[0].end = rcv_lastend;\n\t\t\ttp->rcv_numsacks = 1;\n\t\t}\n\t\treturn;\n\t}\n\t/* Otherwise, sack blocks are already present. */\n\tfor (i = 0; i < tp->rcv_numsacks; i++)\n\t\ttp->sackblks[i] = temp[i]; /* first copy back sack list */\n\tif (SEQ_GEQ(tp->rcv_nxt, rcv_lastend))\n\t\treturn;     /* sack list remains unchanged */\n\t/*\n\t * From here, segment just received should be (part of) the 1st sack.\n\t * Go through list, possibly coalescing sack block entries.\n\t */\n\tfirstsack.start = rcv_laststart;\n\tfirstsack.end = rcv_lastend;\n\tfor (i = 0; i < tp->rcv_numsacks; i++) {\n\t\tsack = tp->sackblks[i];\n\t\tif (SEQ_LT(sack.end, firstsack.start) ||\n\t\t    SEQ_GT(sack.start, firstsack.end))\n\t\t\tcontinue; /* no overlap */\n\t\tif (sack.start == firstsack.start && sack.end == firstsack.end){\n\t\t\t/*\n\t\t\t * identical block; delete it here since we will\n\t\t\t * move it to the front of the list.\n\t\t\t */\n\t\t\ttp->sackblks[i].start = tp->sackblks[i].end = 0;\n\t\t\tlastpos = i;    /* last posn with a zero entry */\n\t\t\tcontinue;\n\t\t}\n\t\tif (SEQ_LEQ(sack.start, firstsack.start))\n\t\t\tfirstsack.start = sack.start; /* merge blocks */\n\t\tif (SEQ_GEQ(sack.end, firstsack.end))\n\t\t\tfirstsack.end = sack.end;     /* merge blocks */\n\t\ttp->sackblks[i].start = tp->sackblks[i].end = 0;\n\t\tlastpos = i;    /* last posn with a zero entry */\n\t}\n\tif (lastpos != -1) {    /* at least one merge */\n\t\tfor (i = 0, j = 1; i < tp->rcv_numsacks; i++) {\n\t\t\tsack = tp->sackblks[i];\n\t\t\tif (sack.start == 0 && sack.end == 0)\n\t\t\t\tcontinue;\n\t\t\ttemp[j++] = sack;\n\t\t}\n\t\ttp->rcv_numsacks = j; /* including first blk (added later) */\n\t\tfor (i = 1; i < tp->rcv_numsacks; i++) /* now copy back */\n\t\t\ttp->sackblks[i] = temp[i];\n\t} else {        /* no merges -- shift sacks by 1 */\n\t\tif (tp->rcv_numsacks < MAX_SACK_BLKS)\n\t\t\ttp->rcv_numsacks++;\n\t\tfor (i = tp->rcv_numsacks-1; i > 0; i--)\n\t\t\ttp->sackblks[i] = tp->sackblks[i-1];\n\t}\n\ttp->sackblks[0] = firstsack;\n\treturn;\n}\n\n/*\n * Process the TCP SACK option.  tp->snd_holes is an ordered list\n * of holes (oldest to newest, in terms of the sequence space).\n */\nvoid\ntcp_sack_option(struct tcpcb *tp, struct tcphdr *th, u_char *cp, int optlen)\n{\n\tint tmp_olen;\n\tu_char *tmp_cp;\n\tstruct sackhole *cur, *p, *temp;\n\n\tif (!tp->sack_enable)\n\t\treturn;\n\t/* SACK without ACK doesn't make sense. */\n\tif ((th->th_flags & TH_ACK) == 0)\n\t       return;\n\t/* Make sure the ACK on this segment is in [snd_una, snd_max]. */\n\tif (SEQ_LT(th->th_ack, tp->snd_una) ||\n\t    SEQ_GT(th->th_ack, tp->snd_max))\n\t\treturn;\n\t/* Note: TCPOLEN_SACK must be 2*sizeof(tcp_seq) */\n\tif (optlen <= 2 || (optlen - 2) % TCPOLEN_SACK != 0)\n\t\treturn;\n\t/* Note: TCPOLEN_SACK must be 2*sizeof(tcp_seq) */\n\ttmp_cp = cp + 2;\n\ttmp_olen = optlen - 2;\n\ttcpstat_inc(tcps_sack_rcv_opts);\n\tif (tp->snd_numholes < 0)\n\t\ttp->snd_numholes = 0;\n\tif (tp->t_maxseg == 0)\n\t\tpanic(\"tcp_sack_option\"); /* Should never happen */\n\twhile (tmp_olen > 0) {\n\t\tstruct sackblk sack;\n\n\t\tmemcpy(&sack.start, tmp_cp, sizeof(tcp_seq));\n\t\tsack.start = ntohl(sack.start);\n\t\tmemcpy(&sack.end, tmp_cp + sizeof(tcp_seq), sizeof(tcp_seq));\n\t\tsack.end = ntohl(sack.end);\n\t\ttmp_olen -= TCPOLEN_SACK;\n\t\ttmp_cp += TCPOLEN_SACK;\n\t\tif (SEQ_LEQ(sack.end, sack.start))\n\t\t\tcontinue; /* bad SACK fields */\n\t\tif (SEQ_LEQ(sack.end, tp->snd_una))\n\t\t\tcontinue; /* old block */\n\t\tif (SEQ_GT(th->th_ack, tp->snd_una)) {\n\t\t\tif (SEQ_LT(sack.start, th->th_ack))\n\t\t\t\tcontinue;\n\t\t}\n\t\tif (SEQ_GT(sack.end, tp->snd_max))\n\t\t\tcontinue;\n\t\tif (tp->snd_holes == NULL) { /* first hole */\n\t\t\ttp->snd_holes = (struct sackhole *)\n\t\t\t    pool_get(&sackhl_pool, PR_NOWAIT);\n\t\t\tif (tp->snd_holes == NULL) {\n\t\t\t\t/* ENOBUFS, so ignore SACKed block for now*/\n\t\t\t\tgoto done;\n\t\t\t}\n\t\t\tcur = tp->snd_holes;\n\t\t\tcur->start = th->th_ack;\n\t\t\tcur->end = sack.start;\n\t\t\tcur->rxmit = cur->start;\n\t\t\tcur->next = NULL;\n\t\t\ttp->snd_numholes = 1;\n\t\t\ttp->rcv_lastsack = sack.end;\n\t\t\t/*\n\t\t\t * dups is at least one.  If more data has been\n\t\t\t * SACKed, it can be greater than one.\n\t\t\t */\n\t\t\tcur->dups = min(tcprexmtthresh,\n\t\t\t    ((sack.end - cur->end)/tp->t_maxseg));\n\t\t\tif (cur->dups < 1)\n\t\t\t\tcur->dups = 1;\n\t\t\tcontinue; /* with next sack block */\n\t\t}\n\t\t/* Go thru list of holes:  p = previous,  cur = current */\n\t\tp = cur = tp->snd_holes;\n\t\twhile (cur) {\n\t\t\tif (SEQ_LEQ(sack.end, cur->start))\n\t\t\t\t/* SACKs data before the current hole */\n\t\t\t\tbreak; /* no use going through more holes */\n\t\t\tif (SEQ_GEQ(sack.start, cur->end)) {\n\t\t\t\t/* SACKs data beyond the current hole */\n\t\t\t\tcur->dups++;\n\t\t\t\tif (((sack.end - cur->end)/tp->t_maxseg) >=\n\t\t\t\t    tcprexmtthresh)\n\t\t\t\t\tcur->dups = tcprexmtthresh;\n\t\t\t\tp = cur;\n\t\t\t\tcur = cur->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (SEQ_LEQ(sack.start, cur->start)) {\n\t\t\t\t/* Data acks at least the beginning of hole */\n\t\t\t\tif (SEQ_GEQ(sack.end, cur->end)) {\n\t\t\t\t\t/* Acks entire hole, so delete hole */\n\t\t\t\t\tif (p != cur) {\n\t\t\t\t\t\tp->next = cur->next;\n\t\t\t\t\t\tpool_put(&sackhl_pool, cur);\n\t\t\t\t\t\tcur = p->next;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tcur = cur->next;\n\t\t\t\t\t\tpool_put(&sackhl_pool, p);\n\t\t\t\t\t\tp = cur;\n\t\t\t\t\t\ttp->snd_holes = p;\n\t\t\t\t\t}\n\t\t\t\t\ttp->snd_numholes--;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\t/* otherwise, move start of hole forward */\n\t\t\t\tcur->start = sack.end;\n\t\t\t\tcur->rxmit = SEQ_MAX(cur->rxmit, cur->start);\n\t\t\t\tp = cur;\n\t\t\t\tcur = cur->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\t/* move end of hole backward */\n\t\t\tif (SEQ_GEQ(sack.end, cur->end)) {\n\t\t\t\tcur->end = sack.start;\n\t\t\t\tcur->rxmit = SEQ_MIN(cur->rxmit, cur->end);\n\t\t\t\tcur->dups++;\n\t\t\t\tif (((sack.end - cur->end)/tp->t_maxseg) >=\n\t\t\t\t    tcprexmtthresh)\n\t\t\t\t\tcur->dups = tcprexmtthresh;\n\t\t\t\tp = cur;\n\t\t\t\tcur = cur->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (SEQ_LT(cur->start, sack.start) &&\n\t\t\t    SEQ_GT(cur->end, sack.end)) {\n\t\t\t\t/*\n\t\t\t\t * ACKs some data in middle of a hole; need to\n\t\t\t\t * split current hole\n\t\t\t\t */\n\t\t\t\tif (tp->snd_numholes >= TCP_SACKHOLE_LIMIT)\n\t\t\t\t\tgoto done;\n\t\t\t\ttemp = (struct sackhole *)\n\t\t\t\t    pool_get(&sackhl_pool, PR_NOWAIT);\n\t\t\t\tif (temp == NULL)\n\t\t\t\t\tgoto done; /* ENOBUFS */\n\t\t\t\ttemp->next = cur->next;\n\t\t\t\ttemp->start = sack.end;\n\t\t\t\ttemp->end = cur->end;\n\t\t\t\ttemp->dups = cur->dups;\n\t\t\t\ttemp->rxmit = SEQ_MAX(cur->rxmit, temp->start);\n\t\t\t\tcur->end = sack.start;\n\t\t\t\tcur->rxmit = SEQ_MIN(cur->rxmit, cur->end);\n\t\t\t\tcur->dups++;\n\t\t\t\tif (((sack.end - cur->end)/tp->t_maxseg) >=\n\t\t\t\t\ttcprexmtthresh)\n\t\t\t\t\tcur->dups = tcprexmtthresh;\n\t\t\t\tcur->next = temp;\n\t\t\t\tp = temp;\n\t\t\t\tcur = p->next;\n\t\t\t\ttp->snd_numholes++;\n\t\t\t}\n\t\t}\n\t\t/* At this point, p points to the last hole on the list */\n\t\tif (SEQ_LT(tp->rcv_lastsack, sack.start)) {\n\t\t\t/*\n\t\t\t * Need to append new hole at end.\n\t\t\t * Last hole is p (and it's not NULL).\n\t\t\t */\n\t\t\tif (tp->snd_numholes >= TCP_SACKHOLE_LIMIT)\n\t\t\t\tgoto done;\n\t\t\ttemp = (struct sackhole *)\n\t\t\t    pool_get(&sackhl_pool, PR_NOWAIT);\n\t\t\tif (temp == NULL)\n\t\t\t\tgoto done; /* ENOBUFS */\n\t\t\ttemp->start = tp->rcv_lastsack;\n\t\t\ttemp->end = sack.start;\n\t\t\ttemp->dups = min(tcprexmtthresh,\n\t\t\t    ((sack.end - sack.start)/tp->t_maxseg));\n\t\t\tif (temp->dups < 1)\n\t\t\t\ttemp->dups = 1;\n\t\t\ttemp->rxmit = temp->start;\n\t\t\ttemp->next = 0;\n\t\t\tp->next = temp;\n\t\t\ttp->rcv_lastsack = sack.end;\n\t\t\ttp->snd_numholes++;\n\t\t}\n\t}\ndone:\n\treturn;\n}\n\n/*\n * Delete stale (i.e, cumulatively ack'd) holes.  Hole is deleted only if\n * it is completely acked; otherwise, tcp_sack_option(), called from\n * tcp_dooptions(), will fix up the hole.\n */\nvoid\ntcp_del_sackholes(struct tcpcb *tp, struct tcphdr *th)\n{\n\tif (tp->sack_enable && tp->t_state != TCPS_LISTEN) {\n\t\t/* max because this could be an older ack just arrived */\n\t\ttcp_seq lastack = SEQ_GT(th->th_ack, tp->snd_una) ?\n\t\t\tth->th_ack : tp->snd_una;\n\t\tstruct sackhole *cur = tp->snd_holes;\n\t\tstruct sackhole *prev;\n\t\twhile (cur)\n\t\t\tif (SEQ_LEQ(cur->end, lastack)) {\n\t\t\t\tprev = cur;\n\t\t\t\tcur = cur->next;\n\t\t\t\tpool_put(&sackhl_pool, prev);\n\t\t\t\ttp->snd_numholes--;\n\t\t\t} else if (SEQ_LT(cur->start, lastack)) {\n\t\t\t\tcur->start = lastack;\n\t\t\t\tif (SEQ_LT(cur->rxmit, cur->start))\n\t\t\t\t\tcur->rxmit = cur->start;\n\t\t\t\tbreak;\n\t\t\t} else\n\t\t\t\tbreak;\n\t\ttp->snd_holes = cur;\n\t}\n}\n\n/*\n * Delete all receiver-side SACK information.\n */\nvoid\ntcp_clean_sackreport(struct tcpcb *tp)\n{\n\tint i;\n\n\ttp->rcv_numsacks = 0;\n\tfor (i = 0; i < MAX_SACK_BLKS; i++)\n\t\ttp->sackblks[i].start = tp->sackblks[i].end=0;\n\n}\n\n/*\n * Partial ack handling within a sack recovery episode.  When a partial ack\n * arrives, turn off retransmission timer, deflate the window, do not clear\n * tp->t_dupacks.\n */\nvoid\ntcp_sack_partialack(struct tcpcb *tp, struct tcphdr *th)\n{\n\t/* Turn off retx. timer (will start again next segment) */\n\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\ttp->t_rtttime = 0;\n\t/*\n\t * Partial window deflation.  This statement relies on the\n\t * fact that tp->snd_una has not been updated yet.\n\t */\n\tif (tp->snd_cwnd > (th->th_ack - tp->snd_una)) {\n\t\ttp->snd_cwnd -= th->th_ack - tp->snd_una;\n\t\ttp->snd_cwnd += tp->t_maxseg;\n\t} else\n\t\ttp->snd_cwnd = tp->t_maxseg;\n\ttp->snd_cwnd += tp->t_maxseg;\n\ttp->t_flags |= TF_NEEDOUTPUT;\n}\n\n/*\n * Pull out of band byte out of a segment so\n * it doesn't appear in the user's data queue.\n * It is still reflected in the segment length for\n * sequencing purposes.\n */\nvoid\ntcp_pulloutofband(struct socket *so, u_int urgent, struct mbuf *m, int off)\n{\n        int cnt = off + urgent - 1;\n\n\twhile (cnt >= 0) {\n\t\tif (m->m_len > cnt) {\n\t\t\tchar *cp = mtod(m, caddr_t) + cnt;\n\t\t\tstruct tcpcb *tp = sototcpcb(so);\n\n\t\t\ttp->t_iobc = *cp;\n\t\t\ttp->t_oobflags |= TCPOOB_HAVEDATA;\n\t\t\tmemmove(cp, cp + 1, m->m_len - cnt - 1);\n\t\t\tm->m_len--;\n\t\t\treturn;\n\t\t}\n\t\tcnt -= m->m_len;\n\t\tm = m->m_next;\n\t\tif (m == NULL)\n\t\t\tbreak;\n\t}\n\tpanic(\"tcp_pulloutofband\");\n}\n\n/*\n * Collect new round-trip time estimate\n * and update averages and current timeout.\n */\nvoid\ntcp_xmit_timer(struct tcpcb *tp, int rtt)\n{\n\tshort delta;\n\tshort rttmin;\n\n\tif (rtt < 0)\n\t\trtt = 0;\n\telse if (rtt > TCP_RTT_MAX)\n\t\trtt = TCP_RTT_MAX;\n\n\ttcpstat_inc(tcps_rttupdated);\n\tif (tp->t_srtt != 0) {\n\t\t/*\n\t\t * delta is fixed point with 2 (TCP_RTT_BASE_SHIFT) bits\n\t\t * after the binary point (scaled by 4), whereas\n\t\t * srtt is stored as fixed point with 5 bits after the\n\t\t * binary point (i.e., scaled by 32).  The following magic\n\t\t * is equivalent to the smoothing algorithm in rfc793 with\n\t\t * an alpha of .875 (srtt = rtt/8 + srtt*7/8 in fixed\n\t\t * point).\n\t\t */\n\t\tdelta = (rtt << TCP_RTT_BASE_SHIFT) -\n\t\t    (tp->t_srtt >> TCP_RTT_SHIFT);\n\t\tif ((tp->t_srtt += delta) <= 0)\n\t\t\ttp->t_srtt = 1 << TCP_RTT_BASE_SHIFT;\n\t\t/*\n\t\t * We accumulate a smoothed rtt variance (actually, a\n\t\t * smoothed mean difference), then set the retransmit\n\t\t * timer to smoothed rtt + 4 times the smoothed variance.\n\t\t * rttvar is stored as fixed point with 4 bits after the\n\t\t * binary point (scaled by 16).  The following is\n\t\t * equivalent to rfc793 smoothing with an alpha of .75\n\t\t * (rttvar = rttvar*3/4 + |delta| / 4).  This replaces\n\t\t * rfc793's wired-in beta.\n\t\t */\n\t\tif (delta < 0)\n\t\t\tdelta = -delta;\n\t\tdelta -= (tp->t_rttvar >> TCP_RTTVAR_SHIFT);\n\t\tif ((tp->t_rttvar += delta) <= 0)\n\t\t\ttp->t_rttvar = 1 << TCP_RTT_BASE_SHIFT;\n\t} else {\n\t\t/*\n\t\t * No rtt measurement yet - use the unsmoothed rtt.\n\t\t * Set the variance to half the rtt (so our first\n\t\t * retransmit happens at 3*rtt).\n\t\t */\n\t\ttp->t_srtt = (rtt + 1) << (TCP_RTT_SHIFT + TCP_RTT_BASE_SHIFT);\n\t\ttp->t_rttvar = (rtt + 1) <<\n\t\t    (TCP_RTTVAR_SHIFT + TCP_RTT_BASE_SHIFT - 1);\n\t}\n\ttp->t_rtttime = 0;\n\ttp->t_rxtshift = 0;\n\n\t/*\n\t * the retransmit should happen at rtt + 4 * rttvar.\n\t * Because of the way we do the smoothing, srtt and rttvar\n\t * will each average +1/2 tick of bias.  When we compute\n\t * the retransmit timer, we want 1/2 tick of rounding and\n\t * 1 extra tick because of +-1/2 tick uncertainty in the\n\t * firing of the timer.  The bias will give us exactly the\n\t * 1.5 tick we need.  But, because the bias is\n\t * statistical, we have to test that we don't drop below\n\t * the minimum feasible timer (which is 2 ticks).\n\t */\n\trttmin = min(max(rtt + 2, tp->t_rttmin), TCPTV_REXMTMAX);\n\tTCPT_RANGESET(tp->t_rxtcur, TCP_REXMTVAL(tp), rttmin, TCPTV_REXMTMAX);\n\n\t/*\n\t * We received an ack for a packet that wasn't retransmitted;\n\t * it is probably safe to discard any error indications we've\n\t * received recently.  This isn't quite right, but close enough\n\t * for now (a route might have failed after we sent a segment,\n\t * and the return path might not be symmetrical).\n\t */\n\ttp->t_softerror = 0;\n}\n\n/*\n * Determine a reasonable value for maxseg size.\n * If the route is known, check route for mtu.\n * If none, use an mss that can be handled on the outgoing\n * interface without forcing IP to fragment; if bigger than\n * an mbuf cluster (MCLBYTES), round down to nearest multiple of MCLBYTES\n * to utilize large mbufs.  If no route is found, route has no mtu,\n * or the destination isn't local, use a default, hopefully conservative\n * size (usually 512 or the default IP max size, but no more than the mtu\n * of the interface), as we can't discover anything about intervening\n * gateways or networks.  We also initialize the congestion/slow start\n * window to be a single segment if the destination isn't local.\n * While looking at the routing entry, we also initialize other path-dependent\n * parameters from pre-set or cached values in the routing entry.\n *\n * Also take into account the space needed for options that we\n * send regularly.  Make maxseg shorter by that amount to assure\n * that we can send maxseg amount of data even when the options\n * are present.  Store the upper limit of the length of options plus\n * data in maxopd.\n *\n * NOTE: offer == -1 indicates that the maxseg size changed due to\n * Path MTU discovery.\n */\nint\ntcp_mss(struct tcpcb *tp, int offer)\n{\n\tstruct rtentry *rt;\n\tstruct ifnet *ifp = NULL;\n\tint mss, mssopt;\n\tint iphlen;\n\tstruct inpcb *inp;\n\n\tinp = tp->t_inpcb;\n\n\tmssopt = mss = tcp_mssdflt;\n\n\trt = in_pcbrtentry(inp);\n\n\tif (rt == NULL)\n\t\tgoto out;\n\n\tifp = if_get(rt->rt_ifidx);\n\tif (ifp == NULL)\n\t\tgoto out;\n\n\tswitch (tp->pf) {\n#ifdef INET6\n\tcase AF_INET6:\n\t\tiphlen = sizeof(struct ip6_hdr);\n\t\tbreak;\n#endif\n\tcase AF_INET:\n\t\tiphlen = sizeof(struct ip);\n\t\tbreak;\n\tdefault:\n\t\t/* the family does not support path MTU discovery */\n\t\tgoto out;\n\t}\n\n\t/*\n\t * if there's an mtu associated with the route and we support\n\t * path MTU discovery for the underlying protocol family, use it.\n\t */\n\tif (rt->rt_mtu) {\n\t\t/*\n\t\t * One may wish to lower MSS to take into account options,\n\t\t * especially security-related options.\n\t\t */\n\t\tif (tp->pf == AF_INET6 && rt->rt_mtu < IPV6_MMTU) {\n\t\t\t/*\n\t\t\t * RFC2460 section 5, last paragraph: if path MTU is\n\t\t\t * smaller than 1280, use 1280 as packet size and\n\t\t\t * attach fragment header.\n\t\t\t */\n\t\t\tmss = IPV6_MMTU - iphlen - sizeof(struct ip6_frag) -\n\t\t\t    sizeof(struct tcphdr);\n\t\t} else {\n\t\t\tmss = rt->rt_mtu - iphlen -\n\t\t\t    sizeof(struct tcphdr);\n\t\t}\n\t} else if (ifp->if_flags & IFF_LOOPBACK) {\n\t\tmss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);\n\t} else if (tp->pf == AF_INET) {\n\t\tif (ip_mtudisc)\n\t\t\tmss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);\n\t}\n#ifdef INET6\n\telse if (tp->pf == AF_INET6) {\n\t\t/*\n\t\t * for IPv6, path MTU discovery is always turned on,\n\t\t * or the node must use packet size <= 1280.\n\t\t */\n\t\tmss = ifp->if_mtu - iphlen - sizeof(struct tcphdr);\n\t}\n#endif /* INET6 */\n\n\t/* Calculate the value that we offer in TCPOPT_MAXSEG */\n\tif (offer != -1) {\n\t\tmssopt = ifp->if_mtu - iphlen - sizeof(struct tcphdr);\n\t\tmssopt = max(tcp_mssdflt, mssopt);\n\t}\n out:\n\tif_put(ifp);\n\t/*\n\t * The current mss, t_maxseg, is initialized to the default value.\n\t * If we compute a smaller value, reduce the current mss.\n\t * If we compute a larger value, return it for use in sending\n\t * a max seg size option, but don't store it for use\n\t * unless we received an offer at least that large from peer.\n\t *\n\t * However, do not accept offers lower than the minimum of\n\t * the interface MTU and 216.\n\t */\n\tif (offer > 0)\n\t\ttp->t_peermss = offer;\n\tif (tp->t_peermss)\n\t\tmss = min(mss, max(tp->t_peermss, 216));\n\n\t/* sanity - at least max opt. space */\n\tmss = max(mss, 64);\n\n\t/*\n\t * maxopd stores the maximum length of data AND options\n\t * in a segment; maxseg is the amount of data in a normal\n\t * segment.  We need to store this value (maxopd) apart\n\t * from maxseg, because now every segment carries options\n\t * and thus we normally have somewhat less data in segments.\n\t */\n\ttp->t_maxopd = mss;\n\n\tif ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&\n\t    (tp->t_flags & TF_RCVD_TSTMP) == TF_RCVD_TSTMP)\n\t\tmss -= TCPOLEN_TSTAMP_APPA;\n#ifdef TCP_SIGNATURE\n\tif (tp->t_flags & TF_SIGNATURE)\n\t\tmss -= TCPOLEN_SIGLEN;\n#endif\n\n\tif (offer == -1) {\n\t\t/* mss changed due to Path MTU discovery */\n\t\ttp->t_flags &= ~TF_PMTUD_PEND;\n\t\ttp->t_pmtud_mtu_sent = 0;\n\t\ttp->t_pmtud_mss_acked = 0;\n\t\tif (mss < tp->t_maxseg) {\n\t\t\t/*\n\t\t\t * Follow suggestion in RFC 2414 to reduce the\n\t\t\t * congestion window by the ratio of the old\n\t\t\t * segment size to the new segment size.\n\t\t\t */\n\t\t\ttp->snd_cwnd = ulmax((tp->snd_cwnd / tp->t_maxseg) *\n\t\t\t\t\t     mss, mss);\n\t\t}\n\t} else if (tcp_do_rfc3390 == 2) {\n\t\t/* increase initial window  */\n\t\ttp->snd_cwnd = ulmin(10 * mss, ulmax(2 * mss, 14600));\n\t} else if (tcp_do_rfc3390) {\n\t\t/* increase initial window  */\n\t\ttp->snd_cwnd = ulmin(4 * mss, ulmax(2 * mss, 4380));\n\t} else\n\t\ttp->snd_cwnd = mss;\n\n\ttp->t_maxseg = mss;\n\n\treturn (offer != -1 ? mssopt : mss);\n}\n\nu_int\ntcp_hdrsz(struct tcpcb *tp)\n{\n\tu_int hlen;\n\n\tswitch (tp->pf) {\n#ifdef INET6\n\tcase AF_INET6:\n\t\thlen = sizeof(struct ip6_hdr);\n\t\tbreak;\n#endif\n\tcase AF_INET:\n\t\thlen = sizeof(struct ip);\n\t\tbreak;\n\tdefault:\n\t\thlen = 0;\n\t\tbreak;\n\t}\n\thlen += sizeof(struct tcphdr);\n\n\tif ((tp->t_flags & (TF_REQ_TSTMP|TF_NOOPT)) == TF_REQ_TSTMP &&\n\t    (tp->t_flags & TF_RCVD_TSTMP) == TF_RCVD_TSTMP)\n\t\thlen += TCPOLEN_TSTAMP_APPA;\n#ifdef TCP_SIGNATURE\n\tif (tp->t_flags & TF_SIGNATURE)\n\t\thlen += TCPOLEN_SIGLEN;\n#endif\n\treturn (hlen);\n}\n\n/*\n * Set connection variables based on the effective MSS.\n * We are passed the TCPCB for the actual connection.  If we\n * are the server, we are called by the compressed state engine\n * when the 3-way handshake is complete.  If we are the client,\n * we are called when we receive the SYN,ACK from the server.\n *\n * NOTE: The t_maxseg value must be initialized in the TCPCB\n * before this routine is called!\n */\nvoid\ntcp_mss_update(struct tcpcb *tp)\n{\n\tint mss;\n\tu_long bufsize;\n\tstruct rtentry *rt;\n\tstruct socket *so;\n\n\tso = tp->t_inpcb->inp_socket;\n\tmss = tp->t_maxseg;\n\n\trt = in_pcbrtentry(tp->t_inpcb);\n\n\tif (rt == NULL)\n\t\treturn;\n\n\tbufsize = so->so_snd.sb_hiwat;\n\tif (bufsize < mss) {\n\t\tmss = bufsize;\n\t\t/* Update t_maxseg and t_maxopd */\n\t\ttcp_mss(tp, mss);\n\t} else {\n\t\tbufsize = roundup(bufsize, mss);\n\t\tif (bufsize > sb_max)\n\t\t\tbufsize = sb_max;\n\t\t(void)sbreserve(so, &so->so_snd, bufsize);\n\t}\n\n\tbufsize = so->so_rcv.sb_hiwat;\n\tif (bufsize > mss) {\n\t\tbufsize = roundup(bufsize, mss);\n\t\tif (bufsize > sb_max)\n\t\t\tbufsize = sb_max;\n\t\t(void)sbreserve(so, &so->so_rcv, bufsize);\n\t}\n\n}\n\n/*\n * When a partial ack arrives, force the retransmission of the\n * next unacknowledged segment.  Do not clear tp->t_dupacks.\n * By setting snd_nxt to ti_ack, this forces retransmission timer\n * to be started again.\n */\nvoid\ntcp_newreno_partialack(struct tcpcb *tp, struct tcphdr *th)\n{\n\t/*\n\t * snd_una has not been updated and the socket send buffer\n\t * not yet drained of the acked data, so we have to leave\n\t * snd_una as it was to get the correct data offset in\n\t * tcp_output().\n\t */\n\ttcp_seq onxt = tp->snd_nxt;\n\tu_long  ocwnd = tp->snd_cwnd;\n\n\tTCP_TIMER_DISARM(tp, TCPT_REXMT);\n\ttp->t_rtttime = 0;\n\ttp->snd_nxt = th->th_ack;\n\t/*\n\t * Set snd_cwnd to one segment beyond acknowledged offset\n\t * (tp->snd_una not yet updated when this function is called)\n\t */\n\ttp->snd_cwnd = tp->t_maxseg + (th->th_ack - tp->snd_una);\n\t(void)tcp_output(tp);\n\ttp->snd_cwnd = ocwnd;\n\tif (SEQ_GT(onxt, tp->snd_nxt))\n\t\ttp->snd_nxt = onxt;\n\t/*\n\t * Partial window deflation.  Relies on fact that tp->snd_una\n\t * not updated yet.\n\t */\n\tif (tp->snd_cwnd > th->th_ack - tp->snd_una)\n\t\ttp->snd_cwnd -= th->th_ack - tp->snd_una;\n\telse\n\t\ttp->snd_cwnd = 0;\n\ttp->snd_cwnd += tp->t_maxseg;\n}\n\nint\ntcp_mss_adv(struct mbuf *m, int af)\n{\n\tint mss = 0;\n\tint iphlen;\n\tstruct ifnet *ifp = NULL;\n\n\tif (m && (m->m_flags & M_PKTHDR))\n\t\tifp = if_get(m->m_pkthdr.ph_ifidx);\n\n\tswitch (af) {\n\tcase AF_INET:\n\t\tif (ifp != NULL)\n\t\t\tmss = ifp->if_mtu;\n\t\tiphlen = sizeof(struct ip);\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tif (ifp != NULL)\n\t\t\tmss = ifp->if_mtu;\n\t\tiphlen = sizeof(struct ip6_hdr);\n\t\tbreak;\n#endif  \n\tdefault:\n\t\tunhandled_af(af);\n\t}\n\tif_put(ifp);\n\tmss = mss - iphlen - sizeof(struct tcphdr);\n\treturn (max(mss, tcp_mssdflt));\n}\n\n/*\n * TCP compressed state engine.  Currently used to hold compressed\n * state for SYN_RECEIVED.\n */\n\n/* syn hash parameters */\nint\ttcp_syn_hash_size = TCP_SYN_HASH_SIZE;\nint\ttcp_syn_cache_limit = TCP_SYN_HASH_SIZE*TCP_SYN_BUCKET_SIZE;\nint\ttcp_syn_bucket_limit = 3*TCP_SYN_BUCKET_SIZE;\nint\ttcp_syn_use_limit = 100000;\n\nstruct syn_cache_set tcp_syn_cache[2];\nint tcp_syn_cache_active;\n\n#define SYN_HASH(sa, sp, dp, rand) \\\n\t(((sa)->s_addr ^ (rand)[0]) *\t\t\t\t\\\n\t(((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp))) ^ (rand)[4]))\n#ifndef INET6\n#define\tSYN_HASHALL(hash, src, dst, rand) \\\ndo {\t\t\t\t\t\t\t\t\t\\\n\thash = SYN_HASH(&satosin(src)->sin_addr,\t\t\t\\\n\t\tsatosin(src)->sin_port,\t\t\t\t\t\\\n\t\tsatosin(dst)->sin_port, (rand));\t\t\t\\\n} while (/*CONSTCOND*/ 0)\n#else\n#define SYN_HASH6(sa, sp, dp, rand) \\\n\t(((sa)->s6_addr32[0] ^ (rand)[0]) *\t\t\t\\\n\t((sa)->s6_addr32[1] ^ (rand)[1]) *\t\t\t\\\n\t((sa)->s6_addr32[2] ^ (rand)[2]) *\t\t\t\\\n\t((sa)->s6_addr32[3] ^ (rand)[3]) *\t\t\t\\\n\t(((((u_int32_t)(dp))<<16) + ((u_int32_t)(sp))) ^ (rand)[4]))\n\n#define SYN_HASHALL(hash, src, dst, rand) \\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tswitch ((src)->sa_family) {\t\t\t\t\t\\\n\tcase AF_INET:\t\t\t\t\t\t\t\\\n\t\thash = SYN_HASH(&satosin(src)->sin_addr,\t\t\\\n\t\t\tsatosin(src)->sin_port,\t\t\t\t\\\n\t\t\tsatosin(dst)->sin_port, (rand));\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tcase AF_INET6:\t\t\t\t\t\t\t\\\n\t\thash = SYN_HASH6(&satosin6(src)->sin6_addr,\t\t\\\n\t\t\tsatosin6(src)->sin6_port,\t\t\t\\\n\t\t\tsatosin6(dst)->sin6_port, (rand));\t\t\\\n\t\tbreak;\t\t\t\t\t\t\t\\\n\tdefault:\t\t\t\t\t\t\t\\\n\t\thash = 0;\t\t\t\t\t\t\\\n\t}\t\t\t\t\t\t\t\t\\\n} while (/*CONSTCOND*/0)\n#endif /* INET6 */\n\nvoid\nsyn_cache_rm(struct syn_cache *sc)\n{\n\tsc->sc_flags |= SCF_DEAD;\n\tTAILQ_REMOVE(&sc->sc_buckethead->sch_bucket, sc, sc_bucketq);\n\tsc->sc_tp = NULL;\n\tLIST_REMOVE(sc, sc_tpq);\n\tsc->sc_buckethead->sch_length--;\n\ttimeout_del(&sc->sc_timer);\n\tsc->sc_set->scs_count--;\n}\n\nvoid\nsyn_cache_put(struct syn_cache *sc)\n{\n\tm_free(sc->sc_ipopts);\n\tif (sc->sc_route4.ro_rt != NULL) {\n\t\trtfree(sc->sc_route4.ro_rt);\n\t\tsc->sc_route4.ro_rt = NULL;\n\t}\n\ttimeout_set(&sc->sc_timer, syn_cache_reaper, sc);\n\ttimeout_add(&sc->sc_timer, 0);\n}\n\nstruct pool syn_cache_pool;\n\n/*\n * We don't estimate RTT with SYNs, so each packet starts with the default\n * RTT and each timer step has a fixed timeout value.\n */\n#define\tSYN_CACHE_TIMER_ARM(sc)\t\t\t\t\t\t\\\ndo {\t\t\t\t\t\t\t\t\t\\\n\tTCPT_RANGESET((sc)->sc_rxtcur,\t\t\t\t\t\\\n\t    TCPTV_SRTTDFLT * tcp_backoff[(sc)->sc_rxtshift], TCPTV_MIN,\t\\\n\t    TCPTV_REXMTMAX);\t\t\t\t\t\t\\\n\tif (!timeout_initialized(&(sc)->sc_timer))\t\t\t\\\n\t\ttimeout_set_proc(&(sc)->sc_timer, syn_cache_timer, (sc)); \\\n\ttimeout_add(&(sc)->sc_timer, (sc)->sc_rxtcur * (hz / PR_SLOWHZ)); \\\n} while (/*CONSTCOND*/0)\n\n#define\tSYN_CACHE_TIMESTAMP(sc)\ttcp_now + (sc)->sc_modulate\n\nvoid\nsyn_cache_init(void)\n{\n\tint i;\n\n\t/* Initialize the hash buckets. */\n\ttcp_syn_cache[0].scs_buckethead = mallocarray(tcp_syn_hash_size,\n\t    sizeof(struct syn_cache_head), M_SYNCACHE, M_WAITOK|M_ZERO);\n\ttcp_syn_cache[1].scs_buckethead = mallocarray(tcp_syn_hash_size,\n\t    sizeof(struct syn_cache_head), M_SYNCACHE, M_WAITOK|M_ZERO);\n\ttcp_syn_cache[0].scs_size = tcp_syn_hash_size;\n\ttcp_syn_cache[1].scs_size = tcp_syn_hash_size;\n\tfor (i = 0; i < tcp_syn_hash_size; i++) {\n\t\tTAILQ_INIT(&tcp_syn_cache[0].scs_buckethead[i].sch_bucket);\n\t\tTAILQ_INIT(&tcp_syn_cache[1].scs_buckethead[i].sch_bucket);\n\t}\n\n\t/* Initialize the syn cache pool. */\n\tpool_init(&syn_cache_pool, sizeof(struct syn_cache), 0, IPL_SOFTNET,\n\t    0, \"syncache\", NULL);\n}\n\nvoid\nsyn_cache_insert(struct syn_cache *sc, struct tcpcb *tp)\n{\n\tstruct syn_cache_set *set = &tcp_syn_cache[tcp_syn_cache_active];\n\tstruct syn_cache_head *scp;\n\tstruct syn_cache *sc2;\n\tint i;\n\n\tNET_ASSERT_LOCKED();\n\n\t/*\n\t * If there are no entries in the hash table, reinitialize\n\t * the hash secrets.  To avoid useless cache swaps and\n\t * reinitialization, use it until the limit is reached.\n\t * An emtpy cache is also the oportunity to resize the hash.\n\t */\n\tif (set->scs_count == 0 && set->scs_use <= 0) {\n\t\tset->scs_use = tcp_syn_use_limit;\n\t\tif (set->scs_size != tcp_syn_hash_size) {\n\t\t\tscp = mallocarray(tcp_syn_hash_size, sizeof(struct\n\t\t\t    syn_cache_head), M_SYNCACHE, M_NOWAIT|M_ZERO);\n\t\t\tif (scp == NULL) {\n\t\t\t\t/* Try again next time. */\n\t\t\t\tset->scs_use = 0;\n\t\t\t} else {\n\t\t\t\tfree(set->scs_buckethead, M_SYNCACHE,\n\t\t\t\t    set->scs_size *\n\t\t\t\t    sizeof(struct syn_cache_head));\n\t\t\t\tset->scs_buckethead = scp;\n\t\t\t\tset->scs_size = tcp_syn_hash_size;\n\t\t\t\tfor (i = 0; i < tcp_syn_hash_size; i++)\n\t\t\t\t\tTAILQ_INIT(&scp[i].sch_bucket);\n\t\t\t}\n\t\t}\n\t\tarc4random_buf(set->scs_random, sizeof(set->scs_random));\n\t\ttcpstat_inc(tcps_sc_seedrandom);\n\t}\n\n\tSYN_HASHALL(sc->sc_hash, &sc->sc_src.sa, &sc->sc_dst.sa,\n\t    set->scs_random);\n\tscp = &set->scs_buckethead[sc->sc_hash % set->scs_size];\n\tsc->sc_buckethead = scp;\n\n\t/*\n\t * Make sure that we don't overflow the per-bucket\n\t * limit or the total cache size limit.\n\t */\n\tif (scp->sch_length >= tcp_syn_bucket_limit) {\n\t\ttcpstat_inc(tcps_sc_bucketoverflow);\n\t\t/*\n\t\t * Someone might attack our bucket hash function.  Reseed\n\t\t * with random as soon as the passive syn cache gets empty.\n\t\t */\n\t\tset->scs_use = 0;\n\t\t/*\n\t\t * The bucket is full.  Toss the oldest element in the\n\t\t * bucket.  This will be the first entry in the bucket.\n\t\t */\n\t\tsc2 = TAILQ_FIRST(&scp->sch_bucket);\n#ifdef DIAGNOSTIC\n\t\t/*\n\t\t * This should never happen; we should always find an\n\t\t * entry in our bucket.\n\t\t */\n\t\tif (sc2 == NULL)\n\t\t\tpanic(\"%s: bucketoverflow: impossible\", __func__);\n#endif\n\t\tsyn_cache_rm(sc2);\n\t\tsyn_cache_put(sc2);\n\t} else if (set->scs_count >= tcp_syn_cache_limit) {\n\t\tstruct syn_cache_head *scp2, *sce;\n\n\t\ttcpstat_inc(tcps_sc_overflowed);\n\t\t/*\n\t\t * The cache is full.  Toss the oldest entry in the\n\t\t * first non-empty bucket we can find.\n\t\t *\n\t\t * XXX We would really like to toss the oldest\n\t\t * entry in the cache, but we hope that this\n\t\t * condition doesn't happen very often.\n\t\t */\n\t\tscp2 = scp;\n\t\tif (TAILQ_EMPTY(&scp2->sch_bucket)) {\n\t\t\tsce = &set->scs_buckethead[set->scs_size];\n\t\t\tfor (++scp2; scp2 != scp; scp2++) {\n\t\t\t\tif (scp2 >= sce)\n\t\t\t\t\tscp2 = &set->scs_buckethead[0];\n\t\t\t\tif (! TAILQ_EMPTY(&scp2->sch_bucket))\n\t\t\t\t\tbreak;\n\t\t\t}\n#ifdef DIAGNOSTIC\n\t\t\t/*\n\t\t\t * This should never happen; we should always find a\n\t\t\t * non-empty bucket.\n\t\t\t */\n\t\t\tif (scp2 == scp)\n\t\t\t\tpanic(\"%s: cacheoverflow: impossible\",\n\t\t\t\t    __func__);\n#endif\n\t\t}\n\t\tsc2 = TAILQ_FIRST(&scp2->sch_bucket);\n\t\tsyn_cache_rm(sc2);\n\t\tsyn_cache_put(sc2);\n\t}\n\n\t/*\n\t * Initialize the entry's timer.\n\t */\n\tsc->sc_rxttot = 0;\n\tsc->sc_rxtshift = 0;\n\tSYN_CACHE_TIMER_ARM(sc);\n\n\t/* Link it from tcpcb entry */\n\tLIST_INSERT_HEAD(&tp->t_sc, sc, sc_tpq);\n\n\t/* Put it into the bucket. */\n\tTAILQ_INSERT_TAIL(&scp->sch_bucket, sc, sc_bucketq);\n\tscp->sch_length++;\n\tsc->sc_set = set;\n\tset->scs_count++;\n\tset->scs_use--;\n\n\ttcpstat_inc(tcps_sc_added);\n\n\t/*\n\t * If the active cache has exceeded its use limit and\n\t * the passive syn cache is empty, exchange their roles.\n\t */\n\tif (set->scs_use <= 0 &&\n\t    tcp_syn_cache[!tcp_syn_cache_active].scs_count == 0)\n\t\ttcp_syn_cache_active = !tcp_syn_cache_active;\n}\n\n/*\n * Walk the timer queues, looking for SYN,ACKs that need to be retransmitted.\n * If we have retransmitted an entry the maximum number of times, expire\n * that entry.\n */\nvoid\nsyn_cache_timer(void *arg)\n{\n\tstruct syn_cache *sc = arg;\n\n\tNET_LOCK();\n\tif (sc->sc_flags & SCF_DEAD)\n\t\tgoto out;\n\n\tif (__predict_false(sc->sc_rxtshift == TCP_MAXRXTSHIFT)) {\n\t\t/* Drop it -- too many retransmissions. */\n\t\tgoto dropit;\n\t}\n\n\t/*\n\t * Compute the total amount of time this entry has\n\t * been on a queue.  If this entry has been on longer\n\t * than the keep alive timer would allow, expire it.\n\t */\n\tsc->sc_rxttot += sc->sc_rxtcur;\n\tif (sc->sc_rxttot >= tcptv_keep_init)\n\t\tgoto dropit;\n\n\ttcpstat_inc(tcps_sc_retransmitted);\n\t(void) syn_cache_respond(sc, NULL);\n\n\t/* Advance the timer back-off. */\n\tsc->sc_rxtshift++;\n\tSYN_CACHE_TIMER_ARM(sc);\n\n out:\n\tNET_UNLOCK();\n\treturn;\n\n dropit:\n\ttcpstat_inc(tcps_sc_timed_out);\n\tsyn_cache_rm(sc);\n\tsyn_cache_put(sc);\n\tNET_UNLOCK();\n}\n\nvoid\nsyn_cache_reaper(void *arg)\n{\n\tstruct syn_cache *sc = arg;\n\n\tpool_put(&syn_cache_pool, (sc));\n\treturn;\n}\n\n/*\n * Remove syn cache created by the specified tcb entry,\n * because this does not make sense to keep them\n * (if there's no tcb entry, syn cache entry will never be used)\n */\nvoid\nsyn_cache_cleanup(struct tcpcb *tp)\n{\n\tstruct syn_cache *sc, *nsc;\n\n\tNET_ASSERT_LOCKED();\n\n\tLIST_FOREACH_SAFE(sc, &tp->t_sc, sc_tpq, nsc) {\n#ifdef DIAGNOSTIC\n\t\tif (sc->sc_tp != tp)\n\t\t\tpanic(\"invalid sc_tp in syn_cache_cleanup\");\n#endif\n\t\tsyn_cache_rm(sc);\n\t\tsyn_cache_put(sc);\n\t}\n\t/* just for safety */\n\tLIST_INIT(&tp->t_sc);\n}\n\n/*\n * Find an entry in the syn cache.\n */\nstruct syn_cache *\nsyn_cache_lookup(struct sockaddr *src, struct sockaddr *dst,\n    struct syn_cache_head **headp, u_int rtableid)\n{\n\tstruct syn_cache_set *sets[2];\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\tu_int32_t hash;\n\tint i;\n\n\tNET_ASSERT_LOCKED();\n\n\t/* Check the active cache first, the passive cache is likely emtpy. */\n\tsets[0] = &tcp_syn_cache[tcp_syn_cache_active];\n\tsets[1] = &tcp_syn_cache[!tcp_syn_cache_active];\n\tfor (i = 0; i < 2; i++) {\n\t\tif (sets[i]->scs_count == 0)\n\t\t\tcontinue;\n\t\tSYN_HASHALL(hash, src, dst, sets[i]->scs_random);\n\t\tscp = &sets[i]->scs_buckethead[hash % sets[i]->scs_size];\n\t\t*headp = scp;\n\t\tTAILQ_FOREACH(sc, &scp->sch_bucket, sc_bucketq) {\n\t\t\tif (sc->sc_hash != hash)\n\t\t\t\tcontinue;\n\t\t\tif (!bcmp(&sc->sc_src, src, src->sa_len) &&\n\t\t\t    !bcmp(&sc->sc_dst, dst, dst->sa_len) &&\n\t\t\t    rtable_l2(rtableid) == rtable_l2(sc->sc_rtableid))\n\t\t\t\treturn (sc);\n\t\t}\n\t}\n\treturn (NULL);\n}\n\n/*\n * This function gets called when we receive an ACK for a\n * socket in the LISTEN state.  We look up the connection\n * in the syn cache, and if its there, we pull it out of\n * the cache and turn it into a full-blown connection in\n * the SYN-RECEIVED state.\n *\n * The return values may not be immediately obvious, and their effects\n * can be subtle, so here they are:\n *\n *\tNULL\tSYN was not found in cache; caller should drop the\n *\t\tpacket and send an RST.\n *\n *\t-1\tWe were unable to create the new connection, and are\n *\t\taborting it.  An ACK,RST is being sent to the peer\n *\t\t(unless we got screwey sequence numbners; see below),\n *\t\tbecause the 3-way handshake has been completed.  Caller\n *\t\tshould not free the mbuf, since we may be using it.  If\n *\t\twe are not, we will free it.\n *\n *\tOtherwise, the return value is a pointer to the new socket\n *\tassociated with the connection.\n */\nstruct socket *\nsyn_cache_get(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,\n    u_int hlen, u_int tlen, struct socket *so, struct mbuf *m)\n{\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\tstruct inpcb *inp, *oldinp;\n\tstruct tcpcb *tp = NULL;\n\tstruct mbuf *am;\n\tstruct socket *oso;\n\n\tNET_ASSERT_LOCKED();\n\n\tsc = syn_cache_lookup(src, dst, &scp, sotoinpcb(so)->inp_rtableid);\n\tif (sc == NULL)\n\t\treturn (NULL);\n\n\t/*\n\t * Verify the sequence and ack numbers.  Try getting the correct\n\t * response again.\n\t */\n\tif ((th->th_ack != sc->sc_iss + 1) ||\n\t    SEQ_LEQ(th->th_seq, sc->sc_irs) ||\n\t    SEQ_GT(th->th_seq, sc->sc_irs + 1 + sc->sc_win)) {\n\t\t(void) syn_cache_respond(sc, m);\n\t\treturn ((struct socket *)(-1));\n\t}\n\n\t/* Remove this cache entry */\n\tsyn_cache_rm(sc);\n\n\t/*\n\t * Ok, create the full blown connection, and set things up\n\t * as they would have been set up if we had created the\n\t * connection when the SYN arrived.  If we can't create\n\t * the connection, abort it.\n\t */\n\toso = so;\n\tso = sonewconn(so, SS_ISCONNECTED);\n\tif (so == NULL)\n\t\tgoto resetandabort;\n\n\toldinp = sotoinpcb(oso);\n\tinp = sotoinpcb(so);\n\n#ifdef IPSEC\n\t/*\n\t * We need to copy the required security levels\n\t * from the old pcb. Ditto for any other\n\t * IPsec-related information.\n\t */\n\tmemcpy(inp->inp_seclevel, oldinp->inp_seclevel,\n\t    sizeof(oldinp->inp_seclevel));\n#endif /* IPSEC */\n#ifdef INET6\n\t/*\n\t * inp still has the OLD in_pcb stuff, set the\n\t * v6-related flags on the new guy, too.\n\t */\n\tinp->inp_flags |= (oldinp->inp_flags & INP_IPV6);\n\tif (inp->inp_flags & INP_IPV6) {\n\t\tinp->inp_ipv6.ip6_hlim = oldinp->inp_ipv6.ip6_hlim;\n\t\tinp->inp_hops = oldinp->inp_hops;\n\t} else\n#endif /* INET6 */\n\t{\n\t\tinp->inp_ip.ip_ttl = oldinp->inp_ip.ip_ttl;\n\t}\n\n#if NPF > 0\n\tif (m->m_pkthdr.pf.flags & PF_TAG_DIVERTED) {\n\t\tstruct pf_divert *divert;\n\n\t\tdivert = pf_find_divert(m);\n\t\tKASSERT(divert != NULL);\n\t\tinp->inp_rtableid = divert->rdomain;\n\t} else\n#endif\n\t/* inherit rtable from listening socket */\n\tinp->inp_rtableid = sc->sc_rtableid;\n\n\tinp->inp_lport = th->th_dport;\n\tswitch (src->sa_family) {\n#ifdef INET6\n\tcase AF_INET6:\n\t\tinp->inp_laddr6 = satosin6(dst)->sin6_addr;\n\t\tbreak;\n#endif /* INET6 */\n\tcase AF_INET:\n\t\tinp->inp_laddr = satosin(dst)->sin_addr;\n\t\tinp->inp_options = ip_srcroute(m);\n\t\tif (inp->inp_options == NULL) {\n\t\t\tinp->inp_options = sc->sc_ipopts;\n\t\t\tsc->sc_ipopts = NULL;\n\t\t}\n\t\tbreak;\n\t}\n\tin_pcbrehash(inp);\n\n\t/*\n\t * Give the new socket our cached route reference.\n\t */\n\tif (src->sa_family == AF_INET)\n\t\tinp->inp_route = sc->sc_route4;         /* struct assignment */\n#ifdef INET6\n\telse\n\t\tinp->inp_route6 = sc->sc_route6;\n#endif\n\tsc->sc_route4.ro_rt = NULL;\n\n\tam = m_get(M_DONTWAIT, MT_SONAME);\t/* XXX */\n\tif (am == NULL)\n\t\tgoto resetandabort;\n\tam->m_len = src->sa_len;\n\tmemcpy(mtod(am, caddr_t), src, src->sa_len);\n\tif (in_pcbconnect(inp, am)) {\n\t\t(void) m_free(am);\n\t\tgoto resetandabort;\n\t}\n\t(void) m_free(am);\n\n\ttp = intotcpcb(inp);\n\ttp->t_flags = sototcpcb(oso)->t_flags & (TF_NOPUSH|TF_NODELAY);\n\tif (sc->sc_request_r_scale != 15) {\n\t\ttp->requested_s_scale = sc->sc_requested_s_scale;\n\t\ttp->request_r_scale = sc->sc_request_r_scale;\n\t\ttp->t_flags |= TF_REQ_SCALE|TF_RCVD_SCALE;\n\t}\n\tif (sc->sc_flags & SCF_TIMESTAMP)\n\t\ttp->t_flags |= TF_REQ_TSTMP|TF_RCVD_TSTMP;\n\n\ttp->t_template = tcp_template(tp);\n\tif (tp->t_template == 0) {\n\t\ttp = tcp_drop(tp, ENOBUFS);\t/* destroys socket */\n\t\tso = NULL;\n\t\tgoto abort;\n\t}\n\ttp->sack_enable = sc->sc_flags & SCF_SACK_PERMIT;\n\ttp->ts_modulate = sc->sc_modulate;\n\ttp->ts_recent = sc->sc_timestamp;\n\ttp->iss = sc->sc_iss;\n\ttp->irs = sc->sc_irs;\n\ttcp_sendseqinit(tp);\n\ttp->snd_last = tp->snd_una;\n#ifdef TCP_ECN\n\tif (sc->sc_flags & SCF_ECN_PERMIT) {\n\t\ttp->t_flags |= TF_ECN_PERMIT;\n\t\ttcpstat_inc(tcps_ecn_accepts);\n\t}\n#endif\n\tif (sc->sc_flags & SCF_SACK_PERMIT)\n\t\ttp->t_flags |= TF_SACK_PERMIT;\n#ifdef TCP_SIGNATURE\n\tif (sc->sc_flags & SCF_SIGNATURE)\n\t\ttp->t_flags |= TF_SIGNATURE;\n#endif\n\ttcp_rcvseqinit(tp);\n\ttp->t_state = TCPS_SYN_RECEIVED;\n\ttp->t_rcvtime = tcp_now;\n\tTCP_TIMER_ARM(tp, TCPT_KEEP, tcptv_keep_init);\n\ttcpstat_inc(tcps_accepts);\n\n\ttcp_mss(tp, sc->sc_peermaxseg);\t /* sets t_maxseg */\n\tif (sc->sc_peermaxseg)\n\t\ttcp_mss_update(tp);\n\t/* Reset initial window to 1 segment for retransmit */\n\tif (sc->sc_rxtshift > 0)\n\t\ttp->snd_cwnd = tp->t_maxseg;\n\ttp->snd_wl1 = sc->sc_irs;\n\ttp->rcv_up = sc->sc_irs + 1;\n\n\t/*\n\t * This is what whould have happened in tcp_output() when\n\t * the SYN,ACK was sent.\n\t */\n\ttp->snd_up = tp->snd_una;\n\ttp->snd_max = tp->snd_nxt = tp->iss+1;\n\tTCP_TIMER_ARM(tp, TCPT_REXMT, tp->t_rxtcur);\n\tif (sc->sc_win > 0 && SEQ_GT(tp->rcv_nxt + sc->sc_win, tp->rcv_adv))\n\t\ttp->rcv_adv = tp->rcv_nxt + sc->sc_win;\n\ttp->last_ack_sent = tp->rcv_nxt;\n\n\ttcpstat_inc(tcps_sc_completed);\n\tsyn_cache_put(sc);\n\treturn (so);\n\nresetandabort:\n\ttcp_respond(NULL, mtod(m, caddr_t), th, (tcp_seq)0, th->th_ack, TH_RST,\n\t    m->m_pkthdr.ph_rtableid);\nabort:\n\tm_freem(m);\n\tif (so != NULL)\n\t\t(void) soabort(so);\n\tsyn_cache_put(sc);\n\ttcpstat_inc(tcps_sc_aborted);\n\treturn ((struct socket *)(-1));\n}\n\n/*\n * This function is called when we get a RST for a\n * non-existent connection, so that we can see if the\n * connection is in the syn cache.  If it is, zap it.\n */\n\nvoid\nsyn_cache_reset(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,\n    u_int rtableid)\n{\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\n\tNET_ASSERT_LOCKED();\n\n\tif ((sc = syn_cache_lookup(src, dst, &scp, rtableid)) == NULL)\n\t\treturn;\n\tif (SEQ_LT(th->th_seq, sc->sc_irs) ||\n\t    SEQ_GT(th->th_seq, sc->sc_irs + 1))\n\t\treturn;\n\tsyn_cache_rm(sc);\n\ttcpstat_inc(tcps_sc_reset);\n\tsyn_cache_put(sc);\n}\n\nvoid\nsyn_cache_unreach(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,\n    u_int rtableid)\n{\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\n\tNET_ASSERT_LOCKED();\n\n\tif ((sc = syn_cache_lookup(src, dst, &scp, rtableid)) == NULL)\n\t\treturn;\n\t/* If the sequence number != sc_iss, then it's a bogus ICMP msg */\n\tif (ntohl (th->th_seq) != sc->sc_iss) {\n\t\treturn;\n\t}\n\n\t/*\n\t * If we've retransmitted 3 times and this is our second error,\n\t * we remove the entry.  Otherwise, we allow it to continue on.\n\t * This prevents us from incorrectly nuking an entry during a\n\t * spurious network outage.\n\t *\n\t * See tcp_notify().\n\t */\n\tif ((sc->sc_flags & SCF_UNREACH) == 0 || sc->sc_rxtshift < 3) {\n\t\tsc->sc_flags |= SCF_UNREACH;\n\t\treturn;\n\t}\n\n\tsyn_cache_rm(sc);\n\ttcpstat_inc(tcps_sc_unreach);\n\tsyn_cache_put(sc);\n}\n\n/*\n * Given a LISTEN socket and an inbound SYN request, add\n * this to the syn cache, and send back a segment:\n *\t<SEQ=ISS><ACK=RCV_NXT><CTL=SYN,ACK>\n * to the source.\n *\n * IMPORTANT NOTE: We do _NOT_ ACK data that might accompany the SYN.\n * Doing so would require that we hold onto the data and deliver it\n * to the application.  However, if we are the target of a SYN-flood\n * DoS attack, an attacker could send data which would eventually\n * consume all available buffer space if it were ACKed.  By not ACKing\n * the data, we avoid this DoS scenario.\n */\n\nint\nsyn_cache_add(struct sockaddr *src, struct sockaddr *dst, struct tcphdr *th,\n    u_int iphlen, struct socket *so, struct mbuf *m, u_char *optp, int optlen,\n    struct tcp_opt_info *oi, tcp_seq *issp)\n{\n\tstruct tcpcb tb, *tp;\n\tlong win;\n\tstruct syn_cache *sc;\n\tstruct syn_cache_head *scp;\n\tstruct mbuf *ipopts;\n\n\ttp = sototcpcb(so);\n\n\t/*\n\t * RFC1122 4.2.3.10, p. 104: discard bcast/mcast SYN\n\t *\n\t * Note this check is performed in tcp_input() very early on.\n\t */\n\n\t/*\n\t * Initialize some local state.\n\t */\n\twin = sbspace(so, &so->so_rcv);\n\tif (win > TCP_MAXWIN)\n\t\twin = TCP_MAXWIN;\n\n\tbzero(&tb, sizeof(tb));\n#ifdef TCP_SIGNATURE\n\tif (optp || (tp->t_flags & TF_SIGNATURE)) {\n#else\n\tif (optp) {\n#endif\n\t\ttb.pf = tp->pf;\n\t\ttb.sack_enable = tp->sack_enable;\n\t\ttb.t_flags = tcp_do_rfc1323 ? (TF_REQ_SCALE|TF_REQ_TSTMP) : 0;\n#ifdef TCP_SIGNATURE\n\t\tif (tp->t_flags & TF_SIGNATURE)\n\t\t\ttb.t_flags |= TF_SIGNATURE;\n#endif\n\t\ttb.t_state = TCPS_LISTEN;\n\t\tif (tcp_dooptions(&tb, optp, optlen, th, m, iphlen, oi,\n\t\t    sotoinpcb(so)->inp_rtableid))\n\t\t\treturn (-1);\n\t}\n\n\tswitch (src->sa_family) {\n\tcase AF_INET:\n\t\t/*\n\t\t * Remember the IP options, if any.\n\t\t */\n\t\tipopts = ip_srcroute(m);\n\t\tbreak;\n\tdefault:\n\t\tipopts = NULL;\n\t}\n\n\t/*\n\t * See if we already have an entry for this connection.\n\t * If we do, resend the SYN,ACK.  We do not count this\n\t * as a retransmission (XXX though maybe we should).\n\t */\n\tsc = syn_cache_lookup(src, dst, &scp, sotoinpcb(so)->inp_rtableid);\n\tif (sc != NULL) {\n\t\ttcpstat_inc(tcps_sc_dupesyn);\n\t\tif (ipopts) {\n\t\t\t/*\n\t\t\t * If we were remembering a previous source route,\n\t\t\t * forget it and use the new one we've been given.\n\t\t\t */\n\t\t\tm_free(sc->sc_ipopts);\n\t\t\tsc->sc_ipopts = ipopts;\n\t\t}\n\t\tsc->sc_timestamp = tb.ts_recent;\n\t\tif (syn_cache_respond(sc, m) == 0) {\n\t\t\ttcpstat_inc(tcps_sndacks);\n\t\t\ttcpstat_inc(tcps_sndtotal);\n\t\t}\n\t\treturn (0);\n\t}\n\n\tsc = pool_get(&syn_cache_pool, PR_NOWAIT|PR_ZERO);\n\tif (sc == NULL) {\n\t\tm_free(ipopts);\n\t\treturn (-1);\n\t}\n\n\t/*\n\t * Fill in the cache, and put the necessary IP and TCP\n\t * options into the reply.\n\t */\n\tmemcpy(&sc->sc_src, src, src->sa_len);\n\tmemcpy(&sc->sc_dst, dst, dst->sa_len);\n\tsc->sc_rtableid = sotoinpcb(so)->inp_rtableid;\n\tsc->sc_flags = 0;\n\tsc->sc_ipopts = ipopts;\n\tsc->sc_irs = th->th_seq;\n\n\tsc->sc_iss = issp ? *issp : arc4random();\n\tsc->sc_peermaxseg = oi->maxseg;\n\tsc->sc_ourmaxseg = tcp_mss_adv(m, sc->sc_src.sa.sa_family);\n\tsc->sc_win = win;\n\tsc->sc_timestamp = tb.ts_recent;\n\tif ((tb.t_flags & (TF_REQ_TSTMP|TF_RCVD_TSTMP)) ==\n\t    (TF_REQ_TSTMP|TF_RCVD_TSTMP)) {\n\t\tsc->sc_flags |= SCF_TIMESTAMP;\n\t\tsc->sc_modulate = arc4random();\n\t}\n\tif ((tb.t_flags & (TF_RCVD_SCALE|TF_REQ_SCALE)) ==\n\t    (TF_RCVD_SCALE|TF_REQ_SCALE)) {\n\t\tsc->sc_requested_s_scale = tb.requested_s_scale;\n\t\tsc->sc_request_r_scale = 0;\n\t\t/*\n\t\t * Pick the smallest possible scaling factor that\n\t\t * will still allow us to scale up to sb_max.\n\t\t *\n\t\t * We do this because there are broken firewalls that\n\t\t * will corrupt the window scale option, leading to\n\t\t * the other endpoint believing that our advertised\n\t\t * window is unscaled.  At scale factors larger than\n\t\t * 5 the unscaled window will drop below 1500 bytes,\n\t\t * leading to serious problems when traversing these\n\t\t * broken firewalls.\n\t\t *\n\t\t * With the default sbmax of 256K, a scale factor\n\t\t * of 3 will be chosen by this algorithm.  Those who\n\t\t * choose a larger sbmax should watch out\n\t\t * for the compatiblity problems mentioned above.\n\t\t *\n\t\t * RFC1323: The Window field in a SYN (i.e., a <SYN>\n\t\t * or <SYN,ACK>) segment itself is never scaled.\n\t\t */\n\t\twhile (sc->sc_request_r_scale < TCP_MAX_WINSHIFT &&\n\t\t    (TCP_MAXWIN << sc->sc_request_r_scale) < sb_max)\n\t\t\tsc->sc_request_r_scale++;\n\t} else {\n\t\tsc->sc_requested_s_scale = 15;\n\t\tsc->sc_request_r_scale = 15;\n\t}\n#ifdef TCP_ECN\n\t/*\n\t * if both ECE and CWR flag bits are set, peer is ECN capable.\n\t */\n\tif (tcp_do_ecn &&\n\t    (th->th_flags & (TH_ECE|TH_CWR)) == (TH_ECE|TH_CWR))\n\t\tsc->sc_flags |= SCF_ECN_PERMIT;\n#endif\n\t/*\n\t * Set SCF_SACK_PERMIT if peer did send a SACK_PERMITTED option\n\t * (i.e., if tcp_dooptions() did set TF_SACK_PERMIT).\n\t */\n\tif (tb.sack_enable && (tb.t_flags & TF_SACK_PERMIT))\n\t\tsc->sc_flags |= SCF_SACK_PERMIT;\n#ifdef TCP_SIGNATURE\n\tif (tb.t_flags & TF_SIGNATURE)\n\t\tsc->sc_flags |= SCF_SIGNATURE;\n#endif\n\tsc->sc_tp = tp;\n\tif (syn_cache_respond(sc, m) == 0) {\n\t\tsyn_cache_insert(sc, tp);\n\t\ttcpstat_inc(tcps_sndacks);\n\t\ttcpstat_inc(tcps_sndtotal);\n\t} else {\n\t\tsyn_cache_put(sc);\n\t\ttcpstat_inc(tcps_sc_dropped);\n\t}\n\n\treturn (0);\n}\n\nint\nsyn_cache_respond(struct syn_cache *sc, struct mbuf *m)\n{\n\tu_int8_t *optp;\n\tint optlen, error;\n\tu_int16_t tlen;\n\tstruct ip *ip = NULL;\n#ifdef INET6\n\tstruct ip6_hdr *ip6 = NULL;\n#endif\n\tstruct tcphdr *th;\n\tu_int hlen;\n\tstruct inpcb *inp;\n\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\thlen = sizeof(struct ip);\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\thlen = sizeof(struct ip6_hdr);\n\t\tbreak;\n#endif\n\tdefault:\n\t\tm_freem(m);\n\t\treturn (EAFNOSUPPORT);\n\t}\n\n\t/* Compute the size of the TCP options. */\n\toptlen = 4 + (sc->sc_request_r_scale != 15 ? 4 : 0) +\n\t    ((sc->sc_flags & SCF_SACK_PERMIT) ? 4 : 0) +\n#ifdef TCP_SIGNATURE\n\t    ((sc->sc_flags & SCF_SIGNATURE) ? TCPOLEN_SIGLEN : 0) +\n#endif\n\t    ((sc->sc_flags & SCF_TIMESTAMP) ? TCPOLEN_TSTAMP_APPA : 0);\n\n\ttlen = hlen + sizeof(struct tcphdr) + optlen;\n\n\t/*\n\t * Create the IP+TCP header from scratch.\n\t */\n\tm_freem(m);\n#ifdef DIAGNOSTIC\n\tif (max_linkhdr + tlen > MCLBYTES)\n\t\treturn (ENOBUFS);\n#endif\n\tMGETHDR(m, M_DONTWAIT, MT_DATA);\n\tif (m && max_linkhdr + tlen > MHLEN) {\n\t\tMCLGET(m, M_DONTWAIT);\n\t\tif ((m->m_flags & M_EXT) == 0) {\n\t\t\tm_freem(m);\n\t\t\tm = NULL;\n\t\t}\n\t}\n\tif (m == NULL)\n\t\treturn (ENOBUFS);\n\n\t/* Fixup the mbuf. */\n\tm->m_data += max_linkhdr;\n\tm->m_len = m->m_pkthdr.len = tlen;\n\tm->m_pkthdr.ph_ifidx = 0;\n\tm->m_pkthdr.ph_rtableid = sc->sc_rtableid;\n\tmemset(mtod(m, u_char *), 0, tlen);\n\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\tip = mtod(m, struct ip *);\n\t\tip->ip_dst = sc->sc_src.sin.sin_addr;\n\t\tip->ip_src = sc->sc_dst.sin.sin_addr;\n\t\tip->ip_p = IPPROTO_TCP;\n\t\tth = (struct tcphdr *)(ip + 1);\n\t\tth->th_dport = sc->sc_src.sin.sin_port;\n\t\tth->th_sport = sc->sc_dst.sin.sin_port;\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6 = mtod(m, struct ip6_hdr *);\n\t\tip6->ip6_dst = sc->sc_src.sin6.sin6_addr;\n\t\tip6->ip6_src = sc->sc_dst.sin6.sin6_addr;\n\t\tip6->ip6_nxt = IPPROTO_TCP;\n\t\t/* ip6_plen will be updated in ip6_output() */\n\t\tth = (struct tcphdr *)(ip6 + 1);\n\t\tth->th_dport = sc->sc_src.sin6.sin6_port;\n\t\tth->th_sport = sc->sc_dst.sin6.sin6_port;\n\t\tbreak;\n#endif\n\tdefault:\n\t\tunhandled_af(sc->sc_src.sa.sa_family);\n\t}\n\n\tth->th_seq = htonl(sc->sc_iss);\n\tth->th_ack = htonl(sc->sc_irs + 1);\n\tth->th_off = (sizeof(struct tcphdr) + optlen) >> 2;\n\tth->th_flags = TH_SYN|TH_ACK;\n#ifdef TCP_ECN\n\t/* Set ECE for SYN-ACK if peer supports ECN. */\n\tif (tcp_do_ecn && (sc->sc_flags & SCF_ECN_PERMIT))\n\t\tth->th_flags |= TH_ECE;\n#endif\n\tth->th_win = htons(sc->sc_win);\n\t/* th_sum already 0 */\n\t/* th_urp already 0 */\n\n\t/* Tack on the TCP options. */\n\toptp = (u_int8_t *)(th + 1);\n\t*optp++ = TCPOPT_MAXSEG;\n\t*optp++ = 4;\n\t*optp++ = (sc->sc_ourmaxseg >> 8) & 0xff;\n\t*optp++ = sc->sc_ourmaxseg & 0xff;\n\n\t/* Include SACK_PERMIT_HDR option if peer has already done so. */\n\tif (sc->sc_flags & SCF_SACK_PERMIT) {\n\t\t*((u_int32_t *)optp) = htonl(TCPOPT_SACK_PERMIT_HDR);\n\t\toptp += 4;\n\t}\n\n\tif (sc->sc_request_r_scale != 15) {\n\t\t*((u_int32_t *)optp) = htonl(TCPOPT_NOP << 24 |\n\t\t    TCPOPT_WINDOW << 16 | TCPOLEN_WINDOW << 8 |\n\t\t    sc->sc_request_r_scale);\n\t\toptp += 4;\n\t}\n\n\tif (sc->sc_flags & SCF_TIMESTAMP) {\n\t\tu_int32_t *lp = (u_int32_t *)(optp);\n\t\t/* Form timestamp option as shown in appendix A of RFC 1323. */\n\t\t*lp++ = htonl(TCPOPT_TSTAMP_HDR);\n\t\t*lp++ = htonl(SYN_CACHE_TIMESTAMP(sc));\n\t\t*lp   = htonl(sc->sc_timestamp);\n\t\toptp += TCPOLEN_TSTAMP_APPA;\n\t}\n\n#ifdef TCP_SIGNATURE\n\tif (sc->sc_flags & SCF_SIGNATURE) {\n\t\tunion sockaddr_union src, dst;\n\t\tstruct tdb *tdb;\n\n\t\tbzero(&src, sizeof(union sockaddr_union));\n\t\tbzero(&dst, sizeof(union sockaddr_union));\n\t\tsrc.sa.sa_len = sc->sc_src.sa.sa_len;\n\t\tsrc.sa.sa_family = sc->sc_src.sa.sa_family;\n\t\tdst.sa.sa_len = sc->sc_dst.sa.sa_len;\n\t\tdst.sa.sa_family = sc->sc_dst.sa.sa_family;\n\n\t\tswitch (sc->sc_src.sa.sa_family) {\n\t\tcase 0:\t/*default to PF_INET*/\n\t\tcase AF_INET:\n\t\t\tsrc.sin.sin_addr = mtod(m, struct ip *)->ip_src;\n\t\t\tdst.sin.sin_addr = mtod(m, struct ip *)->ip_dst;\n\t\t\tbreak;\n#ifdef INET6\n\t\tcase AF_INET6:\n\t\t\tsrc.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_src;\n\t\t\tdst.sin6.sin6_addr = mtod(m, struct ip6_hdr *)->ip6_dst;\n\t\t\tbreak;\n#endif /* INET6 */\n\t\t}\n\n\t\ttdb = gettdbbysrcdst(rtable_l2(sc->sc_rtableid),\n\t\t    0, &src, &dst, IPPROTO_TCP);\n\t\tif (tdb == NULL) {\n\t\t\tm_freem(m);\n\t\t\treturn (EPERM);\n\t\t}\n\n\t\t/* Send signature option */\n\t\t*(optp++) = TCPOPT_SIGNATURE;\n\t\t*(optp++) = TCPOLEN_SIGNATURE;\n\n\t\tif (tcp_signature(tdb, sc->sc_src.sa.sa_family, m, th,\n\t\t    hlen, 0, optp) < 0) {\n\t\t\tm_freem(m);\n\t\t\treturn (EINVAL);\n\t\t}\n\t\toptp += 16;\n\n\t\t/* Pad options list to the next 32 bit boundary and\n\t\t * terminate it.\n\t\t */\n\t\t*optp++ = TCPOPT_NOP;\n\t\t*optp++ = TCPOPT_EOL;\n\t}\n#endif /* TCP_SIGNATURE */\n\n\t/* Compute the packet's checksum. */\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\tip->ip_len = htons(tlen - hlen);\n\t\tth->th_sum = 0;\n\t\tth->th_sum = in_cksum(m, tlen);\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6->ip6_plen = htons(tlen - hlen);\n\t\tth->th_sum = 0;\n\t\tth->th_sum = in6_cksum(m, IPPROTO_TCP, hlen, tlen - hlen);\n\t\tbreak;\n#endif\n\t}\n\n\t/* use IPsec policy and ttl from listening socket, on SYN ACK */\n\tinp = sc->sc_tp ? sc->sc_tp->t_inpcb : NULL;\n\n\t/*\n\t * Fill in some straggling IP bits.  Note the stack expects\n\t * ip_len to be in host order, for convenience.\n\t */\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\tip->ip_len = htons(tlen);\n\t\tip->ip_ttl = inp ? inp->inp_ip.ip_ttl : ip_defttl;\n\t\tif (inp != NULL)\n\t\t\tip->ip_tos = inp->inp_ip.ip_tos;\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6->ip6_vfc &= ~IPV6_VERSION_MASK;\n\t\tip6->ip6_vfc |= IPV6_VERSION;\n\t\tip6->ip6_plen = htons(tlen - hlen);\n\t\t/* ip6_hlim will be initialized afterwards */\n\t\t/* leave flowlabel = 0, it is legal and require no state mgmt */\n\t\tbreak;\n#endif\n\t}\n\n\tswitch (sc->sc_src.sa.sa_family) {\n\tcase AF_INET:\n\t\terror = ip_output(m, sc->sc_ipopts, &sc->sc_route4,\n\t\t    (ip_mtudisc ? IP_MTUDISC : 0),  NULL, inp, 0);\n\t\tbreak;\n#ifdef INET6\n\tcase AF_INET6:\n\t\tip6->ip6_hlim = in6_selecthlim(inp);\n\n\t\terror = ip6_output(m, NULL /*XXX*/, &sc->sc_route6, 0,\n\t\t    NULL, NULL);\n\t\tbreak;\n#endif\n\tdefault:\n\t\terror = EAFNOSUPPORT;\n\t\tbreak;\n\t}\n\treturn (error);\n}\n"], "filenames": ["sys/netinet/tcp.h", "sys/netinet/tcp_input.c"], "buggy_code_start_loc": [1, 1], "buggy_code_end_loc": [106, 2521], "fixing_code_start_loc": [1, 1], "fixing_code_end_loc": [107, 2526], "type": "NVD-CWE-Other", "message": "OpenBSD kernel version <= 6.5 can be forced to create long chains of TCP SACK holes that causes very expensive calls to tcp_sack_option() for every incoming SACK packet which can lead to a denial of service.", "other": {"cve": {"id": "CVE-2019-8460", "sourceIdentifier": "cve@checkpoint.com", "published": "2019-08-26T20:15:10.030", "lastModified": "2021-08-02T17:15:12.697", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "OpenBSD kernel version <= 6.5 can be forced to create long chains of TCP SACK holes that causes very expensive calls to tcp_sack_option() for every incoming SACK packet which can lead to a denial of service."}, {"lang": "es", "value": "La versi\u00f3n del n\u00facleo de OpenBSD anterior o igual a la versi\u00f3n 6.5 se puede forzar a crear largas cadenas de agujeros TCP SACK que provocan llamadas muy costosas a tcp_sack_option () para cada paquete SACK entrante que puede conducir a una denegaci\u00f3n de servicio."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-Other"}]}, {"source": "cve@checkpoint.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-1049"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:openbsd:openbsd:*:*:*:*:*:*:*:*", "versionEndIncluding": "6.5", "matchCriteriaId": "2E0C4316-BB30-4BB0-B57D-61302AC4E93F"}]}]}], "references": [{"url": "https://ftp.openbsd.org/pub/OpenBSD/patches/6.5/common/006_tcpsack.patch.sig", "source": "cve@checkpoint.com", "tags": ["Exploit", "Vendor Advisory"]}, {"url": "https://github.com/openbsd/src/commit/ed8fdce754a5d8d14c09e989d8877707bd43906f", "source": "cve@checkpoint.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://research.checkpoint.com/tcp-sack-security-issue-in-openbsd-cve-2019-8460/", "source": "cve@checkpoint.com", "tags": ["Exploit", "Patch", "Press/Media Coverage", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20190905-0001/", "source": "cve@checkpoint.com", "tags": ["Third Party Advisory"]}, {"url": "https://us-cert.cisa.gov/ics/advisories/icsa-19-253-03", "source": "cve@checkpoint.com"}]}, "github_commit_url": "https://github.com/openbsd/src/commit/ed8fdce754a5d8d14c09e989d8877707bd43906f"}}
{"buggy_code": ["package daemon // import \"github.com/docker/docker/daemon\"\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\tcdcgroups \"github.com/containerd/cgroups\"\n\t\"github.com/containerd/containerd/containers\"\n\tcoci \"github.com/containerd/containerd/oci\"\n\t\"github.com/containerd/containerd/pkg/apparmor\"\n\t\"github.com/containerd/containerd/pkg/userns\"\n\tcontainertypes \"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/container\"\n\tdconfig \"github.com/docker/docker/daemon/config\"\n\t\"github.com/docker/docker/errdefs\"\n\t\"github.com/docker/docker/oci\"\n\t\"github.com/docker/docker/oci/caps\"\n\t\"github.com/docker/docker/pkg/idtools\"\n\t\"github.com/docker/docker/pkg/stringid\"\n\t\"github.com/docker/docker/rootless/specconv\"\n\tvolumemounts \"github.com/docker/docker/volume/mounts\"\n\t\"github.com/moby/sys/mount\"\n\t\"github.com/moby/sys/mountinfo\"\n\t\"github.com/opencontainers/runc/libcontainer/cgroups\"\n\t\"github.com/opencontainers/runc/libcontainer/user\"\n\tspecs \"github.com/opencontainers/runtime-spec/specs-go\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/sirupsen/logrus\"\n\t\"golang.org/x/sys/unix\"\n)\n\nconst inContainerInitPath = \"/sbin/\" + dconfig.DefaultInitBinary\n\n// WithRlimits sets the container's rlimits along with merging the daemon's rlimits\nfunc WithRlimits(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tvar rlimits []specs.POSIXRlimit\n\n\t\t// We want to leave the original HostConfig alone so make a copy here\n\t\thostConfig := *c.HostConfig\n\t\t// Merge with the daemon defaults\n\t\tdaemon.mergeUlimits(&hostConfig)\n\t\tfor _, ul := range hostConfig.Ulimits {\n\t\t\trlimits = append(rlimits, specs.POSIXRlimit{\n\t\t\t\tType: \"RLIMIT_\" + strings.ToUpper(ul.Name),\n\t\t\t\tSoft: uint64(ul.Soft),\n\t\t\t\tHard: uint64(ul.Hard),\n\t\t\t})\n\t\t}\n\n\t\ts.Process.Rlimits = rlimits\n\t\treturn nil\n\t}\n}\n\n// WithLibnetwork sets the libnetwork hook\nfunc WithLibnetwork(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tif s.Hooks == nil {\n\t\t\ts.Hooks = &specs.Hooks{}\n\t\t}\n\t\tfor _, ns := range s.Linux.Namespaces {\n\t\t\tif ns.Type == \"network\" && ns.Path == \"\" && !c.Config.NetworkDisabled {\n\t\t\t\ttarget := filepath.Join(\"/proc\", strconv.Itoa(os.Getpid()), \"exe\")\n\t\t\t\tshortNetCtlrID := stringid.TruncateID(daemon.netController.ID())\n\t\t\t\ts.Hooks.Prestart = append(s.Hooks.Prestart, specs.Hook{\n\t\t\t\t\tPath: target,\n\t\t\t\t\tArgs: []string{\n\t\t\t\t\t\t\"libnetwork-setkey\",\n\t\t\t\t\t\t\"-exec-root=\" + daemon.configStore.GetExecRoot(),\n\t\t\t\t\t\tc.ID,\n\t\t\t\t\t\tshortNetCtlrID,\n\t\t\t\t\t},\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithRootless sets the spec to the rootless configuration\nfunc WithRootless(daemon *Daemon) coci.SpecOpts {\n\treturn func(_ context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tvar v2Controllers []string\n\t\tif daemon.getCgroupDriver() == cgroupSystemdDriver {\n\t\t\tif cdcgroups.Mode() != cdcgroups.Unified {\n\t\t\t\treturn errors.New(\"rootless systemd driver doesn't support cgroup v1\")\n\t\t\t}\n\t\t\trootlesskitParentEUID := os.Getenv(\"ROOTLESSKIT_PARENT_EUID\")\n\t\t\tif rootlesskitParentEUID == \"\" {\n\t\t\t\treturn errors.New(\"$ROOTLESSKIT_PARENT_EUID is not set (requires RootlessKit v0.8.0)\")\n\t\t\t}\n\t\t\teuid, err := strconv.Atoi(rootlesskitParentEUID)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"invalid $ROOTLESSKIT_PARENT_EUID: must be a numeric value\")\n\t\t\t}\n\t\t\tcontrollersPath := fmt.Sprintf(\"/sys/fs/cgroup/user.slice/user-%d.slice/cgroup.controllers\", euid)\n\t\t\tcontrollersFile, err := os.ReadFile(controllersPath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tv2Controllers = strings.Fields(string(controllersFile))\n\t\t}\n\t\treturn specconv.ToRootless(s, v2Controllers)\n\t}\n}\n\n// WithOOMScore sets the oom score\nfunc WithOOMScore(score *int) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\ts.Process.OOMScoreAdj = score\n\t\treturn nil\n\t}\n}\n\n// WithSelinux sets the selinux labels\nfunc WithSelinux(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\ts.Process.SelinuxLabel = c.GetProcessLabel()\n\t\ts.Linux.MountLabel = c.MountLabel\n\t\treturn nil\n\t}\n}\n\n// WithApparmor sets the apparmor profile\nfunc WithApparmor(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tif apparmor.HostSupports() {\n\t\t\tvar appArmorProfile string\n\t\t\tif c.AppArmorProfile != \"\" {\n\t\t\t\tappArmorProfile = c.AppArmorProfile\n\t\t\t} else if c.HostConfig.Privileged {\n\t\t\t\tappArmorProfile = unconfinedAppArmorProfile\n\t\t\t} else {\n\t\t\t\tappArmorProfile = defaultAppArmorProfile\n\t\t\t}\n\n\t\t\tif appArmorProfile == defaultAppArmorProfile {\n\t\t\t\t// Unattended upgrades and other fun services can unload AppArmor\n\t\t\t\t// profiles inadvertently. Since we cannot store our profile in\n\t\t\t\t// /etc/apparmor.d, nor can we practically add other ways of\n\t\t\t\t// telling the system to keep our profile loaded, in order to make\n\t\t\t\t// sure that we keep the default profile enabled we dynamically\n\t\t\t\t// reload it if necessary.\n\t\t\t\tif err := ensureDefaultAppArmorProfile(); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\ts.Process.ApparmorProfile = appArmorProfile\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithCapabilities sets the container's capabilties\nfunc WithCapabilities(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tcapabilities, err := caps.TweakCapabilities(\n\t\t\tcaps.DefaultCapabilities(),\n\t\t\tc.HostConfig.CapAdd,\n\t\t\tc.HostConfig.CapDrop,\n\t\t\tc.HostConfig.Privileged,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn oci.SetCapabilities(s, capabilities)\n\t}\n}\n\nfunc resourcePath(c *container.Container, getPath func() (string, error)) (string, error) {\n\tp, err := getPath()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn c.GetResourcePath(p)\n}\n\nfunc getUser(c *container.Container, username string) (specs.User, error) {\n\tvar usr specs.User\n\tpasswdPath, err := resourcePath(c, user.GetPasswdPath)\n\tif err != nil {\n\t\treturn usr, err\n\t}\n\tgroupPath, err := resourcePath(c, user.GetGroupPath)\n\tif err != nil {\n\t\treturn usr, err\n\t}\n\texecUser, err := user.GetExecUserPath(username, nil, passwdPath, groupPath)\n\tif err != nil {\n\t\treturn usr, err\n\t}\n\tusr.UID = uint32(execUser.Uid)\n\tusr.GID = uint32(execUser.Gid)\n\n\tvar addGroups []int\n\tif len(c.HostConfig.GroupAdd) > 0 {\n\t\taddGroups, err = user.GetAdditionalGroupsPath(c.HostConfig.GroupAdd, groupPath)\n\t\tif err != nil {\n\t\t\treturn usr, err\n\t\t}\n\t}\n\tfor _, g := range append(execUser.Sgids, addGroups...) {\n\t\tusr.AdditionalGids = append(usr.AdditionalGids, uint32(g))\n\t}\n\treturn usr, nil\n}\n\nfunc setNamespace(s *specs.Spec, ns specs.LinuxNamespace) {\n\tfor i, n := range s.Linux.Namespaces {\n\t\tif n.Type == ns.Type {\n\t\t\ts.Linux.Namespaces[i] = ns\n\t\t\treturn\n\t\t}\n\t}\n\ts.Linux.Namespaces = append(s.Linux.Namespaces, ns)\n}\n\n// WithNamespaces sets the container's namespaces\nfunc WithNamespaces(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tuserNS := false\n\t\t// user\n\t\tif c.HostConfig.UsernsMode.IsPrivate() {\n\t\t\tuidMap := daemon.idMapping.UIDMaps\n\t\t\tif uidMap != nil {\n\t\t\t\tuserNS = true\n\t\t\t\tns := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\tsetNamespace(s, ns)\n\t\t\t\ts.Linux.UIDMappings = specMapping(uidMap)\n\t\t\t\ts.Linux.GIDMappings = specMapping(daemon.idMapping.GIDMaps)\n\t\t\t}\n\t\t}\n\t\t// network\n\t\tif !c.Config.NetworkDisabled {\n\t\t\tns := specs.LinuxNamespace{Type: \"network\"}\n\t\t\tparts := strings.SplitN(string(c.HostConfig.NetworkMode), \":\", 2)\n\t\t\tif parts[0] == \"container\" {\n\t\t\t\tnc, err := daemon.getNetworkedContainer(c.ID, c.HostConfig.NetworkMode.ConnectedContainer())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tns.Path = fmt.Sprintf(\"/proc/%d/ns/net\", nc.State.GetPID())\n\t\t\t\tif userNS {\n\t\t\t\t\t// to share a net namespace, they must also share a user namespace\n\t\t\t\t\tnsUser := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\t\tnsUser.Path = fmt.Sprintf(\"/proc/%d/ns/user\", nc.State.GetPID())\n\t\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t\t}\n\t\t\t} else if c.HostConfig.NetworkMode.IsHost() {\n\t\t\t\tns.Path = c.NetworkSettings.SandboxKey\n\t\t\t}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n\n\t\t// ipc\n\t\tipcMode := c.HostConfig.IpcMode\n\t\tif !ipcMode.Valid() {\n\t\t\treturn errdefs.InvalidParameter(errors.Errorf(\"invalid IPC mode: %v\", ipcMode))\n\t\t}\n\t\tswitch {\n\t\tcase ipcMode.IsContainer():\n\t\t\tns := specs.LinuxNamespace{Type: \"ipc\"}\n\t\t\tic, err := daemon.getIpcContainer(ipcMode.Container())\n\t\t\tif err != nil {\n\t\t\t\treturn errdefs.InvalidParameter(errors.Wrapf(err, \"invalid IPC mode: %v\", ipcMode))\n\t\t\t}\n\t\t\tns.Path = fmt.Sprintf(\"/proc/%d/ns/ipc\", ic.State.GetPID())\n\t\t\tsetNamespace(s, ns)\n\t\t\tif userNS {\n\t\t\t\t// to share an IPC namespace, they must also share a user namespace\n\t\t\t\tnsUser := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\tnsUser.Path = fmt.Sprintf(\"/proc/%d/ns/user\", ic.State.GetPID())\n\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t}\n\t\tcase ipcMode.IsHost():\n\t\t\toci.RemoveNamespace(s, \"ipc\")\n\t\tcase ipcMode.IsEmpty():\n\t\t\t// A container was created by an older version of the daemon.\n\t\t\t// The default behavior used to be what is now called \"shareable\".\n\t\t\tfallthrough\n\t\tcase ipcMode.IsPrivate(), ipcMode.IsShareable(), ipcMode.IsNone():\n\t\t\tns := specs.LinuxNamespace{Type: \"ipc\"}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n\n\t\t// pid\n\t\tif !c.HostConfig.PidMode.Valid() {\n\t\t\treturn errdefs.InvalidParameter(errors.Errorf(\"invalid PID mode: %v\", c.HostConfig.PidMode))\n\t\t}\n\t\tif c.HostConfig.PidMode.IsContainer() {\n\t\t\tpc, err := daemon.getPidContainer(c)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tns := specs.LinuxNamespace{\n\t\t\t\tType: \"pid\",\n\t\t\t\tPath: fmt.Sprintf(\"/proc/%d/ns/pid\", pc.State.GetPID()),\n\t\t\t}\n\t\t\tsetNamespace(s, ns)\n\t\t\tif userNS {\n\t\t\t\t// to share a PID namespace, they must also share a user namespace\n\t\t\t\tnsUser := specs.LinuxNamespace{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tPath: fmt.Sprintf(\"/proc/%d/ns/user\", pc.State.GetPID()),\n\t\t\t\t}\n\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t}\n\t\t} else if c.HostConfig.PidMode.IsHost() {\n\t\t\toci.RemoveNamespace(s, \"pid\")\n\t\t} else {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n\t\t// uts\n\t\tif !c.HostConfig.UTSMode.Valid() {\n\t\t\treturn errdefs.InvalidParameter(errors.Errorf(\"invalid UTS mode: %v\", c.HostConfig.UTSMode))\n\t\t}\n\t\tif c.HostConfig.UTSMode.IsHost() {\n\t\t\toci.RemoveNamespace(s, \"uts\")\n\t\t\ts.Hostname = \"\"\n\t\t}\n\n\t\t// cgroup\n\t\tif !c.HostConfig.CgroupnsMode.Valid() {\n\t\t\treturn errdefs.InvalidParameter(errors.Errorf(\"invalid cgroup namespace mode: %v\", c.HostConfig.CgroupnsMode))\n\t\t}\n\t\tif !c.HostConfig.CgroupnsMode.IsEmpty() {\n\t\t\tif c.HostConfig.CgroupnsMode.IsPrivate() {\n\t\t\t\tnsCgroup := specs.LinuxNamespace{Type: \"cgroup\"}\n\t\t\t\tsetNamespace(s, nsCgroup)\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\nfunc specMapping(s []idtools.IDMap) []specs.LinuxIDMapping {\n\tvar ids []specs.LinuxIDMapping\n\tfor _, item := range s {\n\t\tids = append(ids, specs.LinuxIDMapping{\n\t\t\tHostID:      uint32(item.HostID),\n\t\t\tContainerID: uint32(item.ContainerID),\n\t\t\tSize:        uint32(item.Size),\n\t\t})\n\t}\n\treturn ids\n}\n\n// Get the source mount point of directory passed in as argument. Also return\n// optional fields.\nfunc getSourceMount(source string) (string, string, error) {\n\t// Ensure any symlinks are resolved.\n\tsourcePath, err := filepath.EvalSymlinks(source)\n\tif err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\n\tmi, err := mountinfo.GetMounts(mountinfo.ParentsFilter(sourcePath))\n\tif err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\tif len(mi) < 1 {\n\t\treturn \"\", \"\", fmt.Errorf(\"Can't find mount point of %s\", source)\n\t}\n\n\t// find the longest mount point\n\tvar idx, maxlen int\n\tfor i := range mi {\n\t\tif len(mi[i].Mountpoint) > maxlen {\n\t\t\tmaxlen = len(mi[i].Mountpoint)\n\t\t\tidx = i\n\t\t}\n\t}\n\treturn mi[idx].Mountpoint, mi[idx].Optional, nil\n}\n\nconst (\n\tsharedPropagationOption = \"shared:\"\n\tslavePropagationOption  = \"master:\"\n)\n\n// hasMountInfoOption checks if any of the passed any of the given option values\n// are set in the passed in option string.\nfunc hasMountInfoOption(opts string, vals ...string) bool {\n\tfor _, opt := range strings.Split(opts, \" \") {\n\t\tfor _, val := range vals {\n\t\t\tif strings.HasPrefix(opt, val) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}\n\n// Ensure mount point on which path is mounted, is shared.\nfunc ensureShared(path string) error {\n\tsourceMount, optionalOpts, err := getSourceMount(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Make sure source mount point is shared.\n\tif !hasMountInfoOption(optionalOpts, sharedPropagationOption) {\n\t\treturn errors.Errorf(\"path %s is mounted on %s but it is not a shared mount\", path, sourceMount)\n\t}\n\treturn nil\n}\n\n// Ensure mount point on which path is mounted, is either shared or slave.\nfunc ensureSharedOrSlave(path string) error {\n\tsourceMount, optionalOpts, err := getSourceMount(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !hasMountInfoOption(optionalOpts, sharedPropagationOption, slavePropagationOption) {\n\t\treturn errors.Errorf(\"path %s is mounted on %s but it is not a shared or slave mount\", path, sourceMount)\n\t}\n\treturn nil\n}\n\n// Get the set of mount flags that are set on the mount that contains the given\n// path and are locked by CL_UNPRIVILEGED. This is necessary to ensure that\n// bind-mounting \"with options\" will not fail with user namespaces, due to\n// kernel restrictions that require user namespace mounts to preserve\n// CL_UNPRIVILEGED locked flags.\nfunc getUnprivilegedMountFlags(path string) ([]string, error) {\n\tvar statfs unix.Statfs_t\n\tif err := unix.Statfs(path, &statfs); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// The set of keys come from https://github.com/torvalds/linux/blob/v4.13/fs/namespace.c#L1034-L1048.\n\tunprivilegedFlags := map[uint64]string{\n\t\tunix.MS_RDONLY:     \"ro\",\n\t\tunix.MS_NODEV:      \"nodev\",\n\t\tunix.MS_NOEXEC:     \"noexec\",\n\t\tunix.MS_NOSUID:     \"nosuid\",\n\t\tunix.MS_NOATIME:    \"noatime\",\n\t\tunix.MS_RELATIME:   \"relatime\",\n\t\tunix.MS_NODIRATIME: \"nodiratime\",\n\t}\n\n\tvar flags []string\n\tfor mask, flag := range unprivilegedFlags {\n\t\tif uint64(statfs.Flags)&mask == mask {\n\t\t\tflags = append(flags, flag)\n\t\t}\n\t}\n\n\treturn flags, nil\n}\n\nvar (\n\tmountPropagationMap = map[string]int{\n\t\t\"private\":  mount.PRIVATE,\n\t\t\"rprivate\": mount.RPRIVATE,\n\t\t\"shared\":   mount.SHARED,\n\t\t\"rshared\":  mount.RSHARED,\n\t\t\"slave\":    mount.SLAVE,\n\t\t\"rslave\":   mount.RSLAVE,\n\t}\n\n\tmountPropagationReverseMap = map[int]string{\n\t\tmount.PRIVATE:  \"private\",\n\t\tmount.RPRIVATE: \"rprivate\",\n\t\tmount.SHARED:   \"shared\",\n\t\tmount.RSHARED:  \"rshared\",\n\t\tmount.SLAVE:    \"slave\",\n\t\tmount.RSLAVE:   \"rslave\",\n\t}\n)\n\n// inSlice tests whether a string is contained in a slice of strings or not.\n// Comparison is case sensitive\nfunc inSlice(slice []string, s string) bool {\n\tfor _, ss := range slice {\n\t\tif s == ss {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// WithMounts sets the container's mounts\nfunc WithMounts(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) (err error) {\n\t\tif err := daemon.setupContainerMountsRoot(c); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := daemon.setupIpcDirs(c); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdefer func() {\n\t\t\tif err != nil {\n\t\t\t\tdaemon.cleanupSecretDir(c)\n\t\t\t}\n\t\t}()\n\n\t\tif err := daemon.setupSecretDir(c); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tms, err := daemon.setupMounts(c)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !c.HostConfig.IpcMode.IsPrivate() && !c.HostConfig.IpcMode.IsEmpty() {\n\t\t\tms = append(ms, c.IpcMounts()...)\n\t\t}\n\n\t\ttmpfsMounts, err := c.TmpfsMounts()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tms = append(ms, tmpfsMounts...)\n\n\t\tsecretMounts, err := c.SecretMounts()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tms = append(ms, secretMounts...)\n\n\t\tsort.Sort(mounts(ms))\n\n\t\tmounts := ms\n\n\t\tuserMounts := make(map[string]struct{})\n\t\tfor _, m := range mounts {\n\t\t\tuserMounts[m.Destination] = struct{}{}\n\t\t}\n\n\t\t// Copy all mounts from spec to defaultMounts, except for\n\t\t//  - mounts overridden by a user supplied mount;\n\t\t//  - all mounts under /dev if a user supplied /dev is present;\n\t\t//  - /dev/shm, in case IpcMode is none.\n\t\t// While at it, also\n\t\t//  - set size for /dev/shm from shmsize.\n\t\tdefaultMounts := s.Mounts[:0]\n\t\t_, mountDev := userMounts[\"/dev\"]\n\t\tfor _, m := range s.Mounts {\n\t\t\tif _, ok := userMounts[m.Destination]; ok {\n\t\t\t\t// filter out mount overridden by a user supplied mount\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif mountDev && strings.HasPrefix(m.Destination, \"/dev/\") {\n\t\t\t\t// filter out everything under /dev if /dev is user-mounted\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif m.Destination == \"/dev/shm\" {\n\t\t\t\tif c.HostConfig.IpcMode.IsNone() {\n\t\t\t\t\t// filter out /dev/shm for \"none\" IpcMode\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\t// set size for /dev/shm mount from spec\n\t\t\t\tsizeOpt := \"size=\" + strconv.FormatInt(c.HostConfig.ShmSize, 10)\n\t\t\t\tm.Options = append(m.Options, sizeOpt)\n\t\t\t}\n\n\t\t\tdefaultMounts = append(defaultMounts, m)\n\t\t}\n\n\t\ts.Mounts = defaultMounts\n\t\tfor _, m := range mounts {\n\t\t\tif m.Source == \"tmpfs\" {\n\t\t\t\tdata := m.Data\n\t\t\t\tparser := volumemounts.NewParser()\n\t\t\t\toptions := []string{\"noexec\", \"nosuid\", \"nodev\", string(parser.DefaultPropagationMode())}\n\t\t\t\tif data != \"\" {\n\t\t\t\t\toptions = append(options, strings.Split(data, \",\")...)\n\t\t\t\t}\n\n\t\t\t\tmerged, err := mount.MergeTmpfsOptions(options)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\ts.Mounts = append(s.Mounts, specs.Mount{Destination: m.Destination, Source: m.Source, Type: \"tmpfs\", Options: merged})\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tmt := specs.Mount{Destination: m.Destination, Source: m.Source, Type: \"bind\"}\n\n\t\t\t// Determine property of RootPropagation based on volume\n\t\t\t// properties. If a volume is shared, then keep root propagation\n\t\t\t// shared. This should work for slave and private volumes too.\n\t\t\t//\n\t\t\t// For slave volumes, it can be either [r]shared/[r]slave.\n\t\t\t//\n\t\t\t// For private volumes any root propagation value should work.\n\t\t\tpFlag := mountPropagationMap[m.Propagation]\n\t\t\tswitch pFlag {\n\t\t\tcase mount.SHARED, mount.RSHARED:\n\t\t\t\tif err := ensureShared(m.Source); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\trootpg := mountPropagationMap[s.Linux.RootfsPropagation]\n\t\t\t\tif rootpg != mount.SHARED && rootpg != mount.RSHARED {\n\t\t\t\t\ts.Linux.RootfsPropagation = mountPropagationReverseMap[mount.SHARED]\n\t\t\t\t}\n\t\t\tcase mount.SLAVE, mount.RSLAVE:\n\t\t\t\tvar fallback bool\n\t\t\t\tif err := ensureSharedOrSlave(m.Source); err != nil {\n\t\t\t\t\t// For backwards compatibility purposes, treat mounts from the daemon root\n\t\t\t\t\t// as special since we automatically add rslave propagation to these mounts\n\t\t\t\t\t// when the user did not set anything, so we should fallback to the old\n\t\t\t\t\t// behavior which is to use private propagation which is normally the\n\t\t\t\t\t// default.\n\t\t\t\t\tif !strings.HasPrefix(m.Source, daemon.root) && !strings.HasPrefix(daemon.root, m.Source) {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\tcm, ok := c.MountPoints[m.Destination]\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif cm.Spec.BindOptions != nil && cm.Spec.BindOptions.Propagation != \"\" {\n\t\t\t\t\t\t// This means the user explicitly set a propagation, do not fallback in that case.\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tfallback = true\n\t\t\t\t\tlogrus.WithField(\"container\", c.ID).WithField(\"source\", m.Source).Warn(\"Falling back to default propagation for bind source in daemon root\")\n\t\t\t\t}\n\t\t\t\tif !fallback {\n\t\t\t\t\trootpg := mountPropagationMap[s.Linux.RootfsPropagation]\n\t\t\t\t\tif rootpg != mount.SHARED && rootpg != mount.RSHARED && rootpg != mount.SLAVE && rootpg != mount.RSLAVE {\n\t\t\t\t\t\ts.Linux.RootfsPropagation = mountPropagationReverseMap[mount.RSLAVE]\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbindMode := \"rbind\"\n\t\t\tif m.NonRecursive {\n\t\t\t\tbindMode = \"bind\"\n\t\t\t}\n\t\t\topts := []string{bindMode}\n\t\t\tif !m.Writable {\n\t\t\t\topts = append(opts, \"ro\")\n\t\t\t}\n\t\t\tif pFlag != 0 {\n\t\t\t\topts = append(opts, mountPropagationReverseMap[pFlag])\n\t\t\t}\n\n\t\t\t// If we are using user namespaces, then we must make sure that we\n\t\t\t// don't drop any of the CL_UNPRIVILEGED \"locked\" flags of the source\n\t\t\t// \"mount\" when we bind-mount. The reason for this is that at the point\n\t\t\t// when runc sets up the root filesystem, it is already inside a user\n\t\t\t// namespace, and thus cannot change any flags that are locked.\n\t\t\tif daemon.configStore.RemappedRoot != \"\" || userns.RunningInUserNS() {\n\t\t\t\tunprivOpts, err := getUnprivilegedMountFlags(m.Source)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\topts = append(opts, unprivOpts...)\n\t\t\t}\n\n\t\t\tmt.Options = opts\n\t\t\ts.Mounts = append(s.Mounts, mt)\n\t\t}\n\n\t\tif s.Root.Readonly {\n\t\t\tfor i, m := range s.Mounts {\n\t\t\t\tswitch m.Destination {\n\t\t\t\tcase \"/proc\", \"/dev/pts\", \"/dev/shm\", \"/dev/mqueue\", \"/dev\":\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif _, ok := userMounts[m.Destination]; !ok {\n\t\t\t\t\tif !inSlice(m.Options, \"ro\") {\n\t\t\t\t\t\ts.Mounts[i].Options = append(s.Mounts[i].Options, \"ro\")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif c.HostConfig.Privileged {\n\t\t\t// clear readonly for /sys\n\t\t\tfor i := range s.Mounts {\n\t\t\t\tif s.Mounts[i].Destination == \"/sys\" {\n\t\t\t\t\tclearReadOnly(&s.Mounts[i])\n\t\t\t\t}\n\t\t\t}\n\t\t\ts.Linux.ReadonlyPaths = nil\n\t\t\ts.Linux.MaskedPaths = nil\n\t\t}\n\n\t\t// TODO: until a kernel/mount solution exists for handling remount in a user namespace,\n\t\t// we must clear the readonly flag for the cgroups mount (@mrunalp concurs)\n\t\tif uidMap := daemon.idMapping.UIDMaps; uidMap != nil || c.HostConfig.Privileged {\n\t\t\tfor i, m := range s.Mounts {\n\t\t\t\tif m.Type == \"cgroup\" {\n\t\t\t\t\tclearReadOnly(&s.Mounts[i])\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\n\t}\n}\n\n// sysctlExists checks if a sysctl exists; runc will error if we add any that do not actually\n// exist, so do not add the default ones if running on an old kernel.\nfunc sysctlExists(s string) bool {\n\tf := filepath.Join(\"/proc\", \"sys\", strings.ReplaceAll(s, \".\", \"/\"))\n\t_, err := os.Stat(f)\n\treturn err == nil\n}\n\n// WithCommonOptions sets common docker options\nfunc WithCommonOptions(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tif c.BaseFS == nil && !daemon.UsesSnapshotter() {\n\t\t\treturn errors.New(\"populateCommonSpec: BaseFS of container \" + c.ID + \" is unexpectedly nil\")\n\t\t}\n\t\tlinkedEnv, err := daemon.setupLinkedContainers(c)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !daemon.UsesSnapshotter() {\n\t\t\ts.Root = &specs.Root{\n\t\t\t\tPath:     c.BaseFS.Path(),\n\t\t\t\tReadonly: c.HostConfig.ReadonlyRootfs,\n\t\t\t}\n\t\t}\n\t\tif err := c.SetupWorkingDirectory(daemon.idMapping.RootPair()); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcwd := c.Config.WorkingDir\n\t\tif len(cwd) == 0 {\n\t\t\tcwd = \"/\"\n\t\t}\n\t\ts.Process.Args = append([]string{c.Path}, c.Args...)\n\n\t\t// only add the custom init if it is specified and the container is running in its\n\t\t// own private pid namespace.  It does not make sense to add if it is running in the\n\t\t// host namespace or another container's pid namespace where we already have an init\n\t\tif c.HostConfig.PidMode.IsPrivate() {\n\t\t\tif (c.HostConfig.Init != nil && *c.HostConfig.Init) ||\n\t\t\t\t(c.HostConfig.Init == nil && daemon.configStore.Init) {\n\t\t\t\ts.Process.Args = append([]string{inContainerInitPath, \"--\", c.Path}, c.Args...)\n\t\t\t\tpath := daemon.configStore.InitPath\n\t\t\t\tif path == \"\" {\n\t\t\t\t\tpath, err = exec.LookPath(dconfig.DefaultInitBinary)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ts.Mounts = append(s.Mounts, specs.Mount{\n\t\t\t\t\tDestination: inContainerInitPath,\n\t\t\t\t\tType:        \"bind\",\n\t\t\t\t\tSource:      path,\n\t\t\t\t\tOptions:     []string{\"bind\", \"ro\"},\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t\ts.Process.Cwd = cwd\n\t\ts.Process.Env = c.CreateDaemonEnvironment(c.Config.Tty, linkedEnv)\n\t\ts.Process.Terminal = c.Config.Tty\n\n\t\ts.Hostname = c.Config.Hostname\n\t\tsetLinuxDomainname(c, s)\n\n\t\t// Add default sysctls that are generally safe and useful; currently we\n\t\t// grant the capabilities to allow these anyway. You can override if\n\t\t// you want to restore the original behaviour.\n\t\t// We do not set network sysctls if network namespace is host, or if we are\n\t\t// joining an existing namespace, only if we create a new net namespace.\n\t\tif c.HostConfig.NetworkMode.IsPrivate() {\n\t\t\t// We cannot set up ping socket support in a user namespace\n\t\t\tuserNS := daemon.configStore.RemappedRoot != \"\" && c.HostConfig.UsernsMode.IsPrivate()\n\t\t\tif !userNS && !userns.RunningInUserNS() && sysctlExists(\"net.ipv4.ping_group_range\") {\n\t\t\t\t// allow unprivileged ICMP echo sockets without CAP_NET_RAW\n\t\t\t\ts.Linux.Sysctl[\"net.ipv4.ping_group_range\"] = \"0 2147483647\"\n\t\t\t}\n\t\t\t// allow opening any port less than 1024 without CAP_NET_BIND_SERVICE\n\t\t\tif sysctlExists(\"net.ipv4.ip_unprivileged_port_start\") {\n\t\t\t\ts.Linux.Sysctl[\"net.ipv4.ip_unprivileged_port_start\"] = \"0\"\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\n// WithCgroups sets the container's cgroups\nfunc WithCgroups(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tvar cgroupsPath string\n\t\tscopePrefix := \"docker\"\n\t\tparent := \"/docker\"\n\t\tuseSystemd := UsingSystemd(daemon.configStore)\n\t\tif useSystemd {\n\t\t\tparent = \"system.slice\"\n\t\t\tif daemon.configStore.Rootless {\n\t\t\t\tparent = \"user.slice\"\n\t\t\t}\n\t\t}\n\n\t\tif c.HostConfig.CgroupParent != \"\" {\n\t\t\tparent = c.HostConfig.CgroupParent\n\t\t} else if daemon.configStore.CgroupParent != \"\" {\n\t\t\tparent = daemon.configStore.CgroupParent\n\t\t}\n\n\t\tif useSystemd {\n\t\t\tcgroupsPath = parent + \":\" + scopePrefix + \":\" + c.ID\n\t\t\tlogrus.Debugf(\"createSpec: cgroupsPath: %s\", cgroupsPath)\n\t\t} else {\n\t\t\tcgroupsPath = filepath.Join(parent, c.ID)\n\t\t}\n\t\ts.Linux.CgroupsPath = cgroupsPath\n\n\t\t// the rest is only needed for CPU RT controller\n\n\t\tif daemon.configStore.CPURealtimePeriod == 0 && daemon.configStore.CPURealtimeRuntime == 0 {\n\t\t\treturn nil\n\t\t}\n\n\t\tp := cgroupsPath\n\t\tif useSystemd {\n\t\t\tinitPath, err := cgroups.GetInitCgroup(\"cpu\")\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unable to init CPU RT controller\")\n\t\t\t}\n\t\t\t_, err = cgroups.GetOwnCgroup(\"cpu\")\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unable to init CPU RT controller\")\n\t\t\t}\n\t\t\tp = filepath.Join(initPath, s.Linux.CgroupsPath)\n\t\t}\n\n\t\t// Clean path to guard against things like ../../../BAD\n\t\tparentPath := filepath.Dir(p)\n\t\tif !filepath.IsAbs(parentPath) {\n\t\t\tparentPath = filepath.Clean(\"/\" + parentPath)\n\t\t}\n\n\t\tmnt, root, err := cgroups.FindCgroupMountpointAndRoot(\"\", \"cpu\")\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"unable to init CPU RT controller\")\n\t\t}\n\t\t// When docker is run inside docker, the root is based of the host cgroup.\n\t\t// Should this be handled in runc/libcontainer/cgroups ?\n\t\tif strings.HasPrefix(root, \"/docker/\") {\n\t\t\troot = \"/\"\n\t\t}\n\t\tmnt = filepath.Join(mnt, root)\n\n\t\tif err := daemon.initCPURtController(mnt, parentPath); err != nil {\n\t\t\treturn errors.Wrap(err, \"unable to init CPU RT controller\")\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithDevices sets the container's devices\nfunc WithDevices(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\t// Build lists of devices allowed and created within the container.\n\t\tvar devs []specs.LinuxDevice\n\t\tdevPermissions := s.Linux.Resources.Devices\n\n\t\tif c.HostConfig.Privileged {\n\t\t\thostDevices, err := coci.HostDevices()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdevs = append(devs, hostDevices...)\n\n\t\t\t// adding device mappings in privileged containers\n\t\t\tfor _, deviceMapping := range c.HostConfig.Devices {\n\t\t\t\t// issue a warning that custom cgroup permissions are ignored in privileged mode\n\t\t\t\tif deviceMapping.CgroupPermissions != \"rwm\" {\n\t\t\t\t\tlogrus.WithField(\"container\", c.ID).Warnf(\"custom %s permissions for device %s are ignored in privileged mode\", deviceMapping.CgroupPermissions, deviceMapping.PathOnHost)\n\t\t\t\t}\n\t\t\t\t// issue a warning that the device path already exists via /dev mounting in privileged mode\n\t\t\t\tif deviceMapping.PathOnHost == deviceMapping.PathInContainer {\n\t\t\t\t\tlogrus.WithField(\"container\", c.ID).Warnf(\"path in container %s already exists in privileged mode\", deviceMapping.PathInContainer)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\td, _, err := oci.DevicesFromPath(deviceMapping.PathOnHost, deviceMapping.PathInContainer, \"rwm\")\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tdevs = append(devs, d...)\n\t\t\t}\n\n\t\t\tdevPermissions = []specs.LinuxDeviceCgroup{\n\t\t\t\t{\n\t\t\t\t\tAllow:  true,\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t}\n\t\t} else {\n\t\t\tfor _, deviceMapping := range c.HostConfig.Devices {\n\t\t\t\td, dPermissions, err := oci.DevicesFromPath(deviceMapping.PathOnHost, deviceMapping.PathInContainer, deviceMapping.CgroupPermissions)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tdevs = append(devs, d...)\n\t\t\t\tdevPermissions = append(devPermissions, dPermissions...)\n\t\t\t}\n\n\t\t\tvar err error\n\t\t\tdevPermissions, err = oci.AppendDevicePermissionsFromCgroupRules(devPermissions, c.HostConfig.DeviceCgroupRules)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\ts.Linux.Devices = append(s.Linux.Devices, devs...)\n\t\ts.Linux.Resources.Devices = devPermissions\n\n\t\tfor _, req := range c.HostConfig.DeviceRequests {\n\t\t\tif err := daemon.handleDevice(req, s); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithResources applies the container resources\nfunc WithResources(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tr := c.HostConfig.Resources\n\t\tweightDevices, err := getBlkioWeightDevices(r)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treadBpsDevice, err := getBlkioThrottleDevices(r.BlkioDeviceReadBps)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\twriteBpsDevice, err := getBlkioThrottleDevices(r.BlkioDeviceWriteBps)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treadIOpsDevice, err := getBlkioThrottleDevices(r.BlkioDeviceReadIOps)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\twriteIOpsDevice, err := getBlkioThrottleDevices(r.BlkioDeviceWriteIOps)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tmemoryRes := getMemoryResources(r)\n\t\tcpuRes, err := getCPUResources(r)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tblkioWeight := r.BlkioWeight\n\n\t\tspecResources := &specs.LinuxResources{\n\t\t\tMemory: memoryRes,\n\t\t\tCPU:    cpuRes,\n\t\t\tBlockIO: &specs.LinuxBlockIO{\n\t\t\t\tWeight:                  &blkioWeight,\n\t\t\t\tWeightDevice:            weightDevices,\n\t\t\t\tThrottleReadBpsDevice:   readBpsDevice,\n\t\t\t\tThrottleWriteBpsDevice:  writeBpsDevice,\n\t\t\t\tThrottleReadIOPSDevice:  readIOpsDevice,\n\t\t\t\tThrottleWriteIOPSDevice: writeIOpsDevice,\n\t\t\t},\n\t\t\tPids: getPidsLimit(r),\n\t\t}\n\n\t\tif s.Linux.Resources != nil && len(s.Linux.Resources.Devices) > 0 {\n\t\t\tspecResources.Devices = s.Linux.Resources.Devices\n\t\t}\n\n\t\ts.Linux.Resources = specResources\n\t\treturn nil\n\t}\n}\n\n// WithSysctls sets the container's sysctls\nfunc WithSysctls(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\t// We merge the sysctls injected above with the HostConfig (latter takes\n\t\t// precedence for backwards-compatibility reasons).\n\t\tfor k, v := range c.HostConfig.Sysctls {\n\t\t\ts.Linux.Sysctl[k] = v\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithUser sets the container's user\nfunc WithUser(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tvar err error\n\t\ts.Process.User, err = getUser(c, c.Config.User)\n\t\treturn err\n\t}\n}\n\nfunc (daemon *Daemon) createSpec(c *container.Container) (retSpec *specs.Spec, err error) {\n\tvar (\n\t\topts []coci.SpecOpts\n\t\ts    = oci.DefaultSpec()\n\t)\n\topts = append(opts,\n\t\tWithCommonOptions(daemon, c),\n\t\tWithCgroups(daemon, c),\n\t\tWithResources(c),\n\t\tWithSysctls(c),\n\t\tWithDevices(daemon, c),\n\t\tWithUser(c),\n\t\tWithRlimits(daemon, c),\n\t\tWithNamespaces(daemon, c),\n\t\tWithCapabilities(c),\n\t\tWithSeccomp(daemon, c),\n\t\tWithMounts(daemon, c),\n\t\tWithLibnetwork(daemon, c),\n\t\tWithApparmor(c),\n\t\tWithSelinux(c),\n\t\tWithOOMScore(&c.HostConfig.OomScoreAdj),\n\t)\n\tif c.NoNewPrivileges {\n\t\topts = append(opts, coci.WithNoNewPrivileges)\n\t}\n\tif c.Config.Tty {\n\t\topts = append(opts, WithConsoleSize(c))\n\t}\n\t// Set the masked and readonly paths with regard to the host config options if they are set.\n\tif c.HostConfig.MaskedPaths != nil {\n\t\topts = append(opts, coci.WithMaskedPaths(c.HostConfig.MaskedPaths))\n\t}\n\tif c.HostConfig.ReadonlyPaths != nil {\n\t\topts = append(opts, coci.WithReadonlyPaths(c.HostConfig.ReadonlyPaths))\n\t}\n\tif daemon.configStore.Rootless {\n\t\topts = append(opts, WithRootless(daemon))\n\t}\n\n\tvar snapshotter, snapshotKey string\n\tif daemon.UsesSnapshotter() {\n\t\tsnapshotter = daemon.imageService.StorageDriver()\n\t\tsnapshotKey = c.ID\n\t}\n\n\treturn &s, coci.ApplyOpts(context.Background(), nil, &containers.Container{\n\t\tID:          c.ID,\n\t\tSnapshotter: snapshotter,\n\t\tSnapshotKey: snapshotKey,\n\t}, &s, opts...)\n}\n\nfunc clearReadOnly(m *specs.Mount) {\n\tvar opt []string\n\tfor _, o := range m.Options {\n\t\tif o != \"ro\" {\n\t\t\topt = append(opt, o)\n\t\t}\n\t}\n\tm.Options = opt\n}\n\n// mergeUlimits merge the Ulimits from HostConfig with daemon defaults, and update HostConfig\nfunc (daemon *Daemon) mergeUlimits(c *containertypes.HostConfig) {\n\tulimits := c.Ulimits\n\t// Merge ulimits with daemon defaults\n\tulIdx := make(map[string]struct{})\n\tfor _, ul := range ulimits {\n\t\tulIdx[ul.Name] = struct{}{}\n\t}\n\tfor name, ul := range daemon.configStore.Ulimits {\n\t\tif _, exists := ulIdx[name]; !exists {\n\t\t\tulimits = append(ulimits, ul)\n\t\t}\n\t}\n\tc.Ulimits = ulimits\n}\n"], "fixing_code": ["package daemon // import \"github.com/docker/docker/daemon\"\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\tcdcgroups \"github.com/containerd/cgroups\"\n\t\"github.com/containerd/containerd/containers\"\n\tcoci \"github.com/containerd/containerd/oci\"\n\t\"github.com/containerd/containerd/pkg/apparmor\"\n\t\"github.com/containerd/containerd/pkg/userns\"\n\tcontainertypes \"github.com/docker/docker/api/types/container\"\n\t\"github.com/docker/docker/container\"\n\tdconfig \"github.com/docker/docker/daemon/config\"\n\t\"github.com/docker/docker/errdefs\"\n\t\"github.com/docker/docker/oci\"\n\t\"github.com/docker/docker/oci/caps\"\n\t\"github.com/docker/docker/pkg/idtools\"\n\t\"github.com/docker/docker/pkg/stringid\"\n\t\"github.com/docker/docker/rootless/specconv\"\n\tvolumemounts \"github.com/docker/docker/volume/mounts\"\n\t\"github.com/moby/sys/mount\"\n\t\"github.com/moby/sys/mountinfo\"\n\t\"github.com/opencontainers/runc/libcontainer/cgroups\"\n\t\"github.com/opencontainers/runc/libcontainer/user\"\n\tspecs \"github.com/opencontainers/runtime-spec/specs-go\"\n\t\"github.com/pkg/errors\"\n\t\"github.com/sirupsen/logrus\"\n\t\"golang.org/x/sys/unix\"\n)\n\nconst inContainerInitPath = \"/sbin/\" + dconfig.DefaultInitBinary\n\n// WithRlimits sets the container's rlimits along with merging the daemon's rlimits\nfunc WithRlimits(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tvar rlimits []specs.POSIXRlimit\n\n\t\t// We want to leave the original HostConfig alone so make a copy here\n\t\thostConfig := *c.HostConfig\n\t\t// Merge with the daemon defaults\n\t\tdaemon.mergeUlimits(&hostConfig)\n\t\tfor _, ul := range hostConfig.Ulimits {\n\t\t\trlimits = append(rlimits, specs.POSIXRlimit{\n\t\t\t\tType: \"RLIMIT_\" + strings.ToUpper(ul.Name),\n\t\t\t\tSoft: uint64(ul.Soft),\n\t\t\t\tHard: uint64(ul.Hard),\n\t\t\t})\n\t\t}\n\n\t\ts.Process.Rlimits = rlimits\n\t\treturn nil\n\t}\n}\n\n// WithLibnetwork sets the libnetwork hook\nfunc WithLibnetwork(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tif s.Hooks == nil {\n\t\t\ts.Hooks = &specs.Hooks{}\n\t\t}\n\t\tfor _, ns := range s.Linux.Namespaces {\n\t\t\tif ns.Type == \"network\" && ns.Path == \"\" && !c.Config.NetworkDisabled {\n\t\t\t\ttarget := filepath.Join(\"/proc\", strconv.Itoa(os.Getpid()), \"exe\")\n\t\t\t\tshortNetCtlrID := stringid.TruncateID(daemon.netController.ID())\n\t\t\t\ts.Hooks.Prestart = append(s.Hooks.Prestart, specs.Hook{\n\t\t\t\t\tPath: target,\n\t\t\t\t\tArgs: []string{\n\t\t\t\t\t\t\"libnetwork-setkey\",\n\t\t\t\t\t\t\"-exec-root=\" + daemon.configStore.GetExecRoot(),\n\t\t\t\t\t\tc.ID,\n\t\t\t\t\t\tshortNetCtlrID,\n\t\t\t\t\t},\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithRootless sets the spec to the rootless configuration\nfunc WithRootless(daemon *Daemon) coci.SpecOpts {\n\treturn func(_ context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tvar v2Controllers []string\n\t\tif daemon.getCgroupDriver() == cgroupSystemdDriver {\n\t\t\tif cdcgroups.Mode() != cdcgroups.Unified {\n\t\t\t\treturn errors.New(\"rootless systemd driver doesn't support cgroup v1\")\n\t\t\t}\n\t\t\trootlesskitParentEUID := os.Getenv(\"ROOTLESSKIT_PARENT_EUID\")\n\t\t\tif rootlesskitParentEUID == \"\" {\n\t\t\t\treturn errors.New(\"$ROOTLESSKIT_PARENT_EUID is not set (requires RootlessKit v0.8.0)\")\n\t\t\t}\n\t\t\teuid, err := strconv.Atoi(rootlesskitParentEUID)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"invalid $ROOTLESSKIT_PARENT_EUID: must be a numeric value\")\n\t\t\t}\n\t\t\tcontrollersPath := fmt.Sprintf(\"/sys/fs/cgroup/user.slice/user-%d.slice/cgroup.controllers\", euid)\n\t\t\tcontrollersFile, err := os.ReadFile(controllersPath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tv2Controllers = strings.Fields(string(controllersFile))\n\t\t}\n\t\treturn specconv.ToRootless(s, v2Controllers)\n\t}\n}\n\n// WithOOMScore sets the oom score\nfunc WithOOMScore(score *int) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\ts.Process.OOMScoreAdj = score\n\t\treturn nil\n\t}\n}\n\n// WithSelinux sets the selinux labels\nfunc WithSelinux(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\ts.Process.SelinuxLabel = c.GetProcessLabel()\n\t\ts.Linux.MountLabel = c.MountLabel\n\t\treturn nil\n\t}\n}\n\n// WithApparmor sets the apparmor profile\nfunc WithApparmor(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tif apparmor.HostSupports() {\n\t\t\tvar appArmorProfile string\n\t\t\tif c.AppArmorProfile != \"\" {\n\t\t\t\tappArmorProfile = c.AppArmorProfile\n\t\t\t} else if c.HostConfig.Privileged {\n\t\t\t\tappArmorProfile = unconfinedAppArmorProfile\n\t\t\t} else {\n\t\t\t\tappArmorProfile = defaultAppArmorProfile\n\t\t\t}\n\n\t\t\tif appArmorProfile == defaultAppArmorProfile {\n\t\t\t\t// Unattended upgrades and other fun services can unload AppArmor\n\t\t\t\t// profiles inadvertently. Since we cannot store our profile in\n\t\t\t\t// /etc/apparmor.d, nor can we practically add other ways of\n\t\t\t\t// telling the system to keep our profile loaded, in order to make\n\t\t\t\t// sure that we keep the default profile enabled we dynamically\n\t\t\t\t// reload it if necessary.\n\t\t\t\tif err := ensureDefaultAppArmorProfile(); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\ts.Process.ApparmorProfile = appArmorProfile\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithCapabilities sets the container's capabilties\nfunc WithCapabilities(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tcapabilities, err := caps.TweakCapabilities(\n\t\t\tcaps.DefaultCapabilities(),\n\t\t\tc.HostConfig.CapAdd,\n\t\t\tc.HostConfig.CapDrop,\n\t\t\tc.HostConfig.Privileged,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treturn oci.SetCapabilities(s, capabilities)\n\t}\n}\n\nfunc resourcePath(c *container.Container, getPath func() (string, error)) (string, error) {\n\tp, err := getPath()\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn c.GetResourcePath(p)\n}\n\nfunc getUser(c *container.Container, username string) (specs.User, error) {\n\tvar usr specs.User\n\tpasswdPath, err := resourcePath(c, user.GetPasswdPath)\n\tif err != nil {\n\t\treturn usr, err\n\t}\n\tgroupPath, err := resourcePath(c, user.GetGroupPath)\n\tif err != nil {\n\t\treturn usr, err\n\t}\n\texecUser, err := user.GetExecUserPath(username, nil, passwdPath, groupPath)\n\tif err != nil {\n\t\treturn usr, err\n\t}\n\tusr.UID = uint32(execUser.Uid)\n\tusr.GID = uint32(execUser.Gid)\n\tusr.AdditionalGids = []uint32{usr.GID}\n\n\tvar addGroups []int\n\tif len(c.HostConfig.GroupAdd) > 0 {\n\t\taddGroups, err = user.GetAdditionalGroupsPath(c.HostConfig.GroupAdd, groupPath)\n\t\tif err != nil {\n\t\t\treturn usr, err\n\t\t}\n\t}\n\tfor _, g := range append(execUser.Sgids, addGroups...) {\n\t\tusr.AdditionalGids = append(usr.AdditionalGids, uint32(g))\n\t}\n\treturn usr, nil\n}\n\nfunc setNamespace(s *specs.Spec, ns specs.LinuxNamespace) {\n\tfor i, n := range s.Linux.Namespaces {\n\t\tif n.Type == ns.Type {\n\t\t\ts.Linux.Namespaces[i] = ns\n\t\t\treturn\n\t\t}\n\t}\n\ts.Linux.Namespaces = append(s.Linux.Namespaces, ns)\n}\n\n// WithNamespaces sets the container's namespaces\nfunc WithNamespaces(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tuserNS := false\n\t\t// user\n\t\tif c.HostConfig.UsernsMode.IsPrivate() {\n\t\t\tuidMap := daemon.idMapping.UIDMaps\n\t\t\tif uidMap != nil {\n\t\t\t\tuserNS = true\n\t\t\t\tns := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\tsetNamespace(s, ns)\n\t\t\t\ts.Linux.UIDMappings = specMapping(uidMap)\n\t\t\t\ts.Linux.GIDMappings = specMapping(daemon.idMapping.GIDMaps)\n\t\t\t}\n\t\t}\n\t\t// network\n\t\tif !c.Config.NetworkDisabled {\n\t\t\tns := specs.LinuxNamespace{Type: \"network\"}\n\t\t\tparts := strings.SplitN(string(c.HostConfig.NetworkMode), \":\", 2)\n\t\t\tif parts[0] == \"container\" {\n\t\t\t\tnc, err := daemon.getNetworkedContainer(c.ID, c.HostConfig.NetworkMode.ConnectedContainer())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tns.Path = fmt.Sprintf(\"/proc/%d/ns/net\", nc.State.GetPID())\n\t\t\t\tif userNS {\n\t\t\t\t\t// to share a net namespace, they must also share a user namespace\n\t\t\t\t\tnsUser := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\t\tnsUser.Path = fmt.Sprintf(\"/proc/%d/ns/user\", nc.State.GetPID())\n\t\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t\t}\n\t\t\t} else if c.HostConfig.NetworkMode.IsHost() {\n\t\t\t\tns.Path = c.NetworkSettings.SandboxKey\n\t\t\t}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n\n\t\t// ipc\n\t\tipcMode := c.HostConfig.IpcMode\n\t\tif !ipcMode.Valid() {\n\t\t\treturn errdefs.InvalidParameter(errors.Errorf(\"invalid IPC mode: %v\", ipcMode))\n\t\t}\n\t\tswitch {\n\t\tcase ipcMode.IsContainer():\n\t\t\tns := specs.LinuxNamespace{Type: \"ipc\"}\n\t\t\tic, err := daemon.getIpcContainer(ipcMode.Container())\n\t\t\tif err != nil {\n\t\t\t\treturn errdefs.InvalidParameter(errors.Wrapf(err, \"invalid IPC mode: %v\", ipcMode))\n\t\t\t}\n\t\t\tns.Path = fmt.Sprintf(\"/proc/%d/ns/ipc\", ic.State.GetPID())\n\t\t\tsetNamespace(s, ns)\n\t\t\tif userNS {\n\t\t\t\t// to share an IPC namespace, they must also share a user namespace\n\t\t\t\tnsUser := specs.LinuxNamespace{Type: \"user\"}\n\t\t\t\tnsUser.Path = fmt.Sprintf(\"/proc/%d/ns/user\", ic.State.GetPID())\n\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t}\n\t\tcase ipcMode.IsHost():\n\t\t\toci.RemoveNamespace(s, \"ipc\")\n\t\tcase ipcMode.IsEmpty():\n\t\t\t// A container was created by an older version of the daemon.\n\t\t\t// The default behavior used to be what is now called \"shareable\".\n\t\t\tfallthrough\n\t\tcase ipcMode.IsPrivate(), ipcMode.IsShareable(), ipcMode.IsNone():\n\t\t\tns := specs.LinuxNamespace{Type: \"ipc\"}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n\n\t\t// pid\n\t\tif !c.HostConfig.PidMode.Valid() {\n\t\t\treturn errdefs.InvalidParameter(errors.Errorf(\"invalid PID mode: %v\", c.HostConfig.PidMode))\n\t\t}\n\t\tif c.HostConfig.PidMode.IsContainer() {\n\t\t\tpc, err := daemon.getPidContainer(c)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tns := specs.LinuxNamespace{\n\t\t\t\tType: \"pid\",\n\t\t\t\tPath: fmt.Sprintf(\"/proc/%d/ns/pid\", pc.State.GetPID()),\n\t\t\t}\n\t\t\tsetNamespace(s, ns)\n\t\t\tif userNS {\n\t\t\t\t// to share a PID namespace, they must also share a user namespace\n\t\t\t\tnsUser := specs.LinuxNamespace{\n\t\t\t\t\tType: \"user\",\n\t\t\t\t\tPath: fmt.Sprintf(\"/proc/%d/ns/user\", pc.State.GetPID()),\n\t\t\t\t}\n\t\t\t\tsetNamespace(s, nsUser)\n\t\t\t}\n\t\t} else if c.HostConfig.PidMode.IsHost() {\n\t\t\toci.RemoveNamespace(s, \"pid\")\n\t\t} else {\n\t\t\tns := specs.LinuxNamespace{Type: \"pid\"}\n\t\t\tsetNamespace(s, ns)\n\t\t}\n\t\t// uts\n\t\tif !c.HostConfig.UTSMode.Valid() {\n\t\t\treturn errdefs.InvalidParameter(errors.Errorf(\"invalid UTS mode: %v\", c.HostConfig.UTSMode))\n\t\t}\n\t\tif c.HostConfig.UTSMode.IsHost() {\n\t\t\toci.RemoveNamespace(s, \"uts\")\n\t\t\ts.Hostname = \"\"\n\t\t}\n\n\t\t// cgroup\n\t\tif !c.HostConfig.CgroupnsMode.Valid() {\n\t\t\treturn errdefs.InvalidParameter(errors.Errorf(\"invalid cgroup namespace mode: %v\", c.HostConfig.CgroupnsMode))\n\t\t}\n\t\tif !c.HostConfig.CgroupnsMode.IsEmpty() {\n\t\t\tif c.HostConfig.CgroupnsMode.IsPrivate() {\n\t\t\t\tnsCgroup := specs.LinuxNamespace{Type: \"cgroup\"}\n\t\t\t\tsetNamespace(s, nsCgroup)\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\nfunc specMapping(s []idtools.IDMap) []specs.LinuxIDMapping {\n\tvar ids []specs.LinuxIDMapping\n\tfor _, item := range s {\n\t\tids = append(ids, specs.LinuxIDMapping{\n\t\t\tHostID:      uint32(item.HostID),\n\t\t\tContainerID: uint32(item.ContainerID),\n\t\t\tSize:        uint32(item.Size),\n\t\t})\n\t}\n\treturn ids\n}\n\n// Get the source mount point of directory passed in as argument. Also return\n// optional fields.\nfunc getSourceMount(source string) (string, string, error) {\n\t// Ensure any symlinks are resolved.\n\tsourcePath, err := filepath.EvalSymlinks(source)\n\tif err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\n\tmi, err := mountinfo.GetMounts(mountinfo.ParentsFilter(sourcePath))\n\tif err != nil {\n\t\treturn \"\", \"\", err\n\t}\n\tif len(mi) < 1 {\n\t\treturn \"\", \"\", fmt.Errorf(\"Can't find mount point of %s\", source)\n\t}\n\n\t// find the longest mount point\n\tvar idx, maxlen int\n\tfor i := range mi {\n\t\tif len(mi[i].Mountpoint) > maxlen {\n\t\t\tmaxlen = len(mi[i].Mountpoint)\n\t\t\tidx = i\n\t\t}\n\t}\n\treturn mi[idx].Mountpoint, mi[idx].Optional, nil\n}\n\nconst (\n\tsharedPropagationOption = \"shared:\"\n\tslavePropagationOption  = \"master:\"\n)\n\n// hasMountInfoOption checks if any of the passed any of the given option values\n// are set in the passed in option string.\nfunc hasMountInfoOption(opts string, vals ...string) bool {\n\tfor _, opt := range strings.Split(opts, \" \") {\n\t\tfor _, val := range vals {\n\t\t\tif strings.HasPrefix(opt, val) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}\n\n// Ensure mount point on which path is mounted, is shared.\nfunc ensureShared(path string) error {\n\tsourceMount, optionalOpts, err := getSourceMount(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// Make sure source mount point is shared.\n\tif !hasMountInfoOption(optionalOpts, sharedPropagationOption) {\n\t\treturn errors.Errorf(\"path %s is mounted on %s but it is not a shared mount\", path, sourceMount)\n\t}\n\treturn nil\n}\n\n// Ensure mount point on which path is mounted, is either shared or slave.\nfunc ensureSharedOrSlave(path string) error {\n\tsourceMount, optionalOpts, err := getSourceMount(path)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif !hasMountInfoOption(optionalOpts, sharedPropagationOption, slavePropagationOption) {\n\t\treturn errors.Errorf(\"path %s is mounted on %s but it is not a shared or slave mount\", path, sourceMount)\n\t}\n\treturn nil\n}\n\n// Get the set of mount flags that are set on the mount that contains the given\n// path and are locked by CL_UNPRIVILEGED. This is necessary to ensure that\n// bind-mounting \"with options\" will not fail with user namespaces, due to\n// kernel restrictions that require user namespace mounts to preserve\n// CL_UNPRIVILEGED locked flags.\nfunc getUnprivilegedMountFlags(path string) ([]string, error) {\n\tvar statfs unix.Statfs_t\n\tif err := unix.Statfs(path, &statfs); err != nil {\n\t\treturn nil, err\n\t}\n\n\t// The set of keys come from https://github.com/torvalds/linux/blob/v4.13/fs/namespace.c#L1034-L1048.\n\tunprivilegedFlags := map[uint64]string{\n\t\tunix.MS_RDONLY:     \"ro\",\n\t\tunix.MS_NODEV:      \"nodev\",\n\t\tunix.MS_NOEXEC:     \"noexec\",\n\t\tunix.MS_NOSUID:     \"nosuid\",\n\t\tunix.MS_NOATIME:    \"noatime\",\n\t\tunix.MS_RELATIME:   \"relatime\",\n\t\tunix.MS_NODIRATIME: \"nodiratime\",\n\t}\n\n\tvar flags []string\n\tfor mask, flag := range unprivilegedFlags {\n\t\tif uint64(statfs.Flags)&mask == mask {\n\t\t\tflags = append(flags, flag)\n\t\t}\n\t}\n\n\treturn flags, nil\n}\n\nvar (\n\tmountPropagationMap = map[string]int{\n\t\t\"private\":  mount.PRIVATE,\n\t\t\"rprivate\": mount.RPRIVATE,\n\t\t\"shared\":   mount.SHARED,\n\t\t\"rshared\":  mount.RSHARED,\n\t\t\"slave\":    mount.SLAVE,\n\t\t\"rslave\":   mount.RSLAVE,\n\t}\n\n\tmountPropagationReverseMap = map[int]string{\n\t\tmount.PRIVATE:  \"private\",\n\t\tmount.RPRIVATE: \"rprivate\",\n\t\tmount.SHARED:   \"shared\",\n\t\tmount.RSHARED:  \"rshared\",\n\t\tmount.SLAVE:    \"slave\",\n\t\tmount.RSLAVE:   \"rslave\",\n\t}\n)\n\n// inSlice tests whether a string is contained in a slice of strings or not.\n// Comparison is case sensitive\nfunc inSlice(slice []string, s string) bool {\n\tfor _, ss := range slice {\n\t\tif s == ss {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// WithMounts sets the container's mounts\nfunc WithMounts(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) (err error) {\n\t\tif err := daemon.setupContainerMountsRoot(c); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif err := daemon.setupIpcDirs(c); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tdefer func() {\n\t\t\tif err != nil {\n\t\t\t\tdaemon.cleanupSecretDir(c)\n\t\t\t}\n\t\t}()\n\n\t\tif err := daemon.setupSecretDir(c); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tms, err := daemon.setupMounts(c)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif !c.HostConfig.IpcMode.IsPrivate() && !c.HostConfig.IpcMode.IsEmpty() {\n\t\t\tms = append(ms, c.IpcMounts()...)\n\t\t}\n\n\t\ttmpfsMounts, err := c.TmpfsMounts()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tms = append(ms, tmpfsMounts...)\n\n\t\tsecretMounts, err := c.SecretMounts()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tms = append(ms, secretMounts...)\n\n\t\tsort.Sort(mounts(ms))\n\n\t\tmounts := ms\n\n\t\tuserMounts := make(map[string]struct{})\n\t\tfor _, m := range mounts {\n\t\t\tuserMounts[m.Destination] = struct{}{}\n\t\t}\n\n\t\t// Copy all mounts from spec to defaultMounts, except for\n\t\t//  - mounts overridden by a user supplied mount;\n\t\t//  - all mounts under /dev if a user supplied /dev is present;\n\t\t//  - /dev/shm, in case IpcMode is none.\n\t\t// While at it, also\n\t\t//  - set size for /dev/shm from shmsize.\n\t\tdefaultMounts := s.Mounts[:0]\n\t\t_, mountDev := userMounts[\"/dev\"]\n\t\tfor _, m := range s.Mounts {\n\t\t\tif _, ok := userMounts[m.Destination]; ok {\n\t\t\t\t// filter out mount overridden by a user supplied mount\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif mountDev && strings.HasPrefix(m.Destination, \"/dev/\") {\n\t\t\t\t// filter out everything under /dev if /dev is user-mounted\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif m.Destination == \"/dev/shm\" {\n\t\t\t\tif c.HostConfig.IpcMode.IsNone() {\n\t\t\t\t\t// filter out /dev/shm for \"none\" IpcMode\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\t// set size for /dev/shm mount from spec\n\t\t\t\tsizeOpt := \"size=\" + strconv.FormatInt(c.HostConfig.ShmSize, 10)\n\t\t\t\tm.Options = append(m.Options, sizeOpt)\n\t\t\t}\n\n\t\t\tdefaultMounts = append(defaultMounts, m)\n\t\t}\n\n\t\ts.Mounts = defaultMounts\n\t\tfor _, m := range mounts {\n\t\t\tif m.Source == \"tmpfs\" {\n\t\t\t\tdata := m.Data\n\t\t\t\tparser := volumemounts.NewParser()\n\t\t\t\toptions := []string{\"noexec\", \"nosuid\", \"nodev\", string(parser.DefaultPropagationMode())}\n\t\t\t\tif data != \"\" {\n\t\t\t\t\toptions = append(options, strings.Split(data, \",\")...)\n\t\t\t\t}\n\n\t\t\t\tmerged, err := mount.MergeTmpfsOptions(options)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\ts.Mounts = append(s.Mounts, specs.Mount{Destination: m.Destination, Source: m.Source, Type: \"tmpfs\", Options: merged})\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tmt := specs.Mount{Destination: m.Destination, Source: m.Source, Type: \"bind\"}\n\n\t\t\t// Determine property of RootPropagation based on volume\n\t\t\t// properties. If a volume is shared, then keep root propagation\n\t\t\t// shared. This should work for slave and private volumes too.\n\t\t\t//\n\t\t\t// For slave volumes, it can be either [r]shared/[r]slave.\n\t\t\t//\n\t\t\t// For private volumes any root propagation value should work.\n\t\t\tpFlag := mountPropagationMap[m.Propagation]\n\t\t\tswitch pFlag {\n\t\t\tcase mount.SHARED, mount.RSHARED:\n\t\t\t\tif err := ensureShared(m.Source); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\trootpg := mountPropagationMap[s.Linux.RootfsPropagation]\n\t\t\t\tif rootpg != mount.SHARED && rootpg != mount.RSHARED {\n\t\t\t\t\ts.Linux.RootfsPropagation = mountPropagationReverseMap[mount.SHARED]\n\t\t\t\t}\n\t\t\tcase mount.SLAVE, mount.RSLAVE:\n\t\t\t\tvar fallback bool\n\t\t\t\tif err := ensureSharedOrSlave(m.Source); err != nil {\n\t\t\t\t\t// For backwards compatibility purposes, treat mounts from the daemon root\n\t\t\t\t\t// as special since we automatically add rslave propagation to these mounts\n\t\t\t\t\t// when the user did not set anything, so we should fallback to the old\n\t\t\t\t\t// behavior which is to use private propagation which is normally the\n\t\t\t\t\t// default.\n\t\t\t\t\tif !strings.HasPrefix(m.Source, daemon.root) && !strings.HasPrefix(daemon.root, m.Source) {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\n\t\t\t\t\tcm, ok := c.MountPoints[m.Destination]\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tif cm.Spec.BindOptions != nil && cm.Spec.BindOptions.Propagation != \"\" {\n\t\t\t\t\t\t// This means the user explicitly set a propagation, do not fallback in that case.\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t\tfallback = true\n\t\t\t\t\tlogrus.WithField(\"container\", c.ID).WithField(\"source\", m.Source).Warn(\"Falling back to default propagation for bind source in daemon root\")\n\t\t\t\t}\n\t\t\t\tif !fallback {\n\t\t\t\t\trootpg := mountPropagationMap[s.Linux.RootfsPropagation]\n\t\t\t\t\tif rootpg != mount.SHARED && rootpg != mount.RSHARED && rootpg != mount.SLAVE && rootpg != mount.RSLAVE {\n\t\t\t\t\t\ts.Linux.RootfsPropagation = mountPropagationReverseMap[mount.RSLAVE]\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbindMode := \"rbind\"\n\t\t\tif m.NonRecursive {\n\t\t\t\tbindMode = \"bind\"\n\t\t\t}\n\t\t\topts := []string{bindMode}\n\t\t\tif !m.Writable {\n\t\t\t\topts = append(opts, \"ro\")\n\t\t\t}\n\t\t\tif pFlag != 0 {\n\t\t\t\topts = append(opts, mountPropagationReverseMap[pFlag])\n\t\t\t}\n\n\t\t\t// If we are using user namespaces, then we must make sure that we\n\t\t\t// don't drop any of the CL_UNPRIVILEGED \"locked\" flags of the source\n\t\t\t// \"mount\" when we bind-mount. The reason for this is that at the point\n\t\t\t// when runc sets up the root filesystem, it is already inside a user\n\t\t\t// namespace, and thus cannot change any flags that are locked.\n\t\t\tif daemon.configStore.RemappedRoot != \"\" || userns.RunningInUserNS() {\n\t\t\t\tunprivOpts, err := getUnprivilegedMountFlags(m.Source)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\topts = append(opts, unprivOpts...)\n\t\t\t}\n\n\t\t\tmt.Options = opts\n\t\t\ts.Mounts = append(s.Mounts, mt)\n\t\t}\n\n\t\tif s.Root.Readonly {\n\t\t\tfor i, m := range s.Mounts {\n\t\t\t\tswitch m.Destination {\n\t\t\t\tcase \"/proc\", \"/dev/pts\", \"/dev/shm\", \"/dev/mqueue\", \"/dev\":\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif _, ok := userMounts[m.Destination]; !ok {\n\t\t\t\t\tif !inSlice(m.Options, \"ro\") {\n\t\t\t\t\t\ts.Mounts[i].Options = append(s.Mounts[i].Options, \"ro\")\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif c.HostConfig.Privileged {\n\t\t\t// clear readonly for /sys\n\t\t\tfor i := range s.Mounts {\n\t\t\t\tif s.Mounts[i].Destination == \"/sys\" {\n\t\t\t\t\tclearReadOnly(&s.Mounts[i])\n\t\t\t\t}\n\t\t\t}\n\t\t\ts.Linux.ReadonlyPaths = nil\n\t\t\ts.Linux.MaskedPaths = nil\n\t\t}\n\n\t\t// TODO: until a kernel/mount solution exists for handling remount in a user namespace,\n\t\t// we must clear the readonly flag for the cgroups mount (@mrunalp concurs)\n\t\tif uidMap := daemon.idMapping.UIDMaps; uidMap != nil || c.HostConfig.Privileged {\n\t\t\tfor i, m := range s.Mounts {\n\t\t\t\tif m.Type == \"cgroup\" {\n\t\t\t\t\tclearReadOnly(&s.Mounts[i])\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\n\t}\n}\n\n// sysctlExists checks if a sysctl exists; runc will error if we add any that do not actually\n// exist, so do not add the default ones if running on an old kernel.\nfunc sysctlExists(s string) bool {\n\tf := filepath.Join(\"/proc\", \"sys\", strings.ReplaceAll(s, \".\", \"/\"))\n\t_, err := os.Stat(f)\n\treturn err == nil\n}\n\n// WithCommonOptions sets common docker options\nfunc WithCommonOptions(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tif c.BaseFS == nil && !daemon.UsesSnapshotter() {\n\t\t\treturn errors.New(\"populateCommonSpec: BaseFS of container \" + c.ID + \" is unexpectedly nil\")\n\t\t}\n\t\tlinkedEnv, err := daemon.setupLinkedContainers(c)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !daemon.UsesSnapshotter() {\n\t\t\ts.Root = &specs.Root{\n\t\t\t\tPath:     c.BaseFS.Path(),\n\t\t\t\tReadonly: c.HostConfig.ReadonlyRootfs,\n\t\t\t}\n\t\t}\n\t\tif err := c.SetupWorkingDirectory(daemon.idMapping.RootPair()); err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcwd := c.Config.WorkingDir\n\t\tif len(cwd) == 0 {\n\t\t\tcwd = \"/\"\n\t\t}\n\t\ts.Process.Args = append([]string{c.Path}, c.Args...)\n\n\t\t// only add the custom init if it is specified and the container is running in its\n\t\t// own private pid namespace.  It does not make sense to add if it is running in the\n\t\t// host namespace or another container's pid namespace where we already have an init\n\t\tif c.HostConfig.PidMode.IsPrivate() {\n\t\t\tif (c.HostConfig.Init != nil && *c.HostConfig.Init) ||\n\t\t\t\t(c.HostConfig.Init == nil && daemon.configStore.Init) {\n\t\t\t\ts.Process.Args = append([]string{inContainerInitPath, \"--\", c.Path}, c.Args...)\n\t\t\t\tpath := daemon.configStore.InitPath\n\t\t\t\tif path == \"\" {\n\t\t\t\t\tpath, err = exec.LookPath(dconfig.DefaultInitBinary)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn err\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ts.Mounts = append(s.Mounts, specs.Mount{\n\t\t\t\t\tDestination: inContainerInitPath,\n\t\t\t\t\tType:        \"bind\",\n\t\t\t\t\tSource:      path,\n\t\t\t\t\tOptions:     []string{\"bind\", \"ro\"},\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t\ts.Process.Cwd = cwd\n\t\ts.Process.Env = c.CreateDaemonEnvironment(c.Config.Tty, linkedEnv)\n\t\ts.Process.Terminal = c.Config.Tty\n\n\t\ts.Hostname = c.Config.Hostname\n\t\tsetLinuxDomainname(c, s)\n\n\t\t// Add default sysctls that are generally safe and useful; currently we\n\t\t// grant the capabilities to allow these anyway. You can override if\n\t\t// you want to restore the original behaviour.\n\t\t// We do not set network sysctls if network namespace is host, or if we are\n\t\t// joining an existing namespace, only if we create a new net namespace.\n\t\tif c.HostConfig.NetworkMode.IsPrivate() {\n\t\t\t// We cannot set up ping socket support in a user namespace\n\t\t\tuserNS := daemon.configStore.RemappedRoot != \"\" && c.HostConfig.UsernsMode.IsPrivate()\n\t\t\tif !userNS && !userns.RunningInUserNS() && sysctlExists(\"net.ipv4.ping_group_range\") {\n\t\t\t\t// allow unprivileged ICMP echo sockets without CAP_NET_RAW\n\t\t\t\ts.Linux.Sysctl[\"net.ipv4.ping_group_range\"] = \"0 2147483647\"\n\t\t\t}\n\t\t\t// allow opening any port less than 1024 without CAP_NET_BIND_SERVICE\n\t\t\tif sysctlExists(\"net.ipv4.ip_unprivileged_port_start\") {\n\t\t\t\ts.Linux.Sysctl[\"net.ipv4.ip_unprivileged_port_start\"] = \"0\"\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\n// WithCgroups sets the container's cgroups\nfunc WithCgroups(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tvar cgroupsPath string\n\t\tscopePrefix := \"docker\"\n\t\tparent := \"/docker\"\n\t\tuseSystemd := UsingSystemd(daemon.configStore)\n\t\tif useSystemd {\n\t\t\tparent = \"system.slice\"\n\t\t\tif daemon.configStore.Rootless {\n\t\t\t\tparent = \"user.slice\"\n\t\t\t}\n\t\t}\n\n\t\tif c.HostConfig.CgroupParent != \"\" {\n\t\t\tparent = c.HostConfig.CgroupParent\n\t\t} else if daemon.configStore.CgroupParent != \"\" {\n\t\t\tparent = daemon.configStore.CgroupParent\n\t\t}\n\n\t\tif useSystemd {\n\t\t\tcgroupsPath = parent + \":\" + scopePrefix + \":\" + c.ID\n\t\t\tlogrus.Debugf(\"createSpec: cgroupsPath: %s\", cgroupsPath)\n\t\t} else {\n\t\t\tcgroupsPath = filepath.Join(parent, c.ID)\n\t\t}\n\t\ts.Linux.CgroupsPath = cgroupsPath\n\n\t\t// the rest is only needed for CPU RT controller\n\n\t\tif daemon.configStore.CPURealtimePeriod == 0 && daemon.configStore.CPURealtimeRuntime == 0 {\n\t\t\treturn nil\n\t\t}\n\n\t\tp := cgroupsPath\n\t\tif useSystemd {\n\t\t\tinitPath, err := cgroups.GetInitCgroup(\"cpu\")\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unable to init CPU RT controller\")\n\t\t\t}\n\t\t\t_, err = cgroups.GetOwnCgroup(\"cpu\")\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"unable to init CPU RT controller\")\n\t\t\t}\n\t\t\tp = filepath.Join(initPath, s.Linux.CgroupsPath)\n\t\t}\n\n\t\t// Clean path to guard against things like ../../../BAD\n\t\tparentPath := filepath.Dir(p)\n\t\tif !filepath.IsAbs(parentPath) {\n\t\t\tparentPath = filepath.Clean(\"/\" + parentPath)\n\t\t}\n\n\t\tmnt, root, err := cgroups.FindCgroupMountpointAndRoot(\"\", \"cpu\")\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"unable to init CPU RT controller\")\n\t\t}\n\t\t// When docker is run inside docker, the root is based of the host cgroup.\n\t\t// Should this be handled in runc/libcontainer/cgroups ?\n\t\tif strings.HasPrefix(root, \"/docker/\") {\n\t\t\troot = \"/\"\n\t\t}\n\t\tmnt = filepath.Join(mnt, root)\n\n\t\tif err := daemon.initCPURtController(mnt, parentPath); err != nil {\n\t\t\treturn errors.Wrap(err, \"unable to init CPU RT controller\")\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithDevices sets the container's devices\nfunc WithDevices(daemon *Daemon, c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\t// Build lists of devices allowed and created within the container.\n\t\tvar devs []specs.LinuxDevice\n\t\tdevPermissions := s.Linux.Resources.Devices\n\n\t\tif c.HostConfig.Privileged {\n\t\t\thostDevices, err := coci.HostDevices()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tdevs = append(devs, hostDevices...)\n\n\t\t\t// adding device mappings in privileged containers\n\t\t\tfor _, deviceMapping := range c.HostConfig.Devices {\n\t\t\t\t// issue a warning that custom cgroup permissions are ignored in privileged mode\n\t\t\t\tif deviceMapping.CgroupPermissions != \"rwm\" {\n\t\t\t\t\tlogrus.WithField(\"container\", c.ID).Warnf(\"custom %s permissions for device %s are ignored in privileged mode\", deviceMapping.CgroupPermissions, deviceMapping.PathOnHost)\n\t\t\t\t}\n\t\t\t\t// issue a warning that the device path already exists via /dev mounting in privileged mode\n\t\t\t\tif deviceMapping.PathOnHost == deviceMapping.PathInContainer {\n\t\t\t\t\tlogrus.WithField(\"container\", c.ID).Warnf(\"path in container %s already exists in privileged mode\", deviceMapping.PathInContainer)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\td, _, err := oci.DevicesFromPath(deviceMapping.PathOnHost, deviceMapping.PathInContainer, \"rwm\")\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tdevs = append(devs, d...)\n\t\t\t}\n\n\t\t\tdevPermissions = []specs.LinuxDeviceCgroup{\n\t\t\t\t{\n\t\t\t\t\tAllow:  true,\n\t\t\t\t\tAccess: \"rwm\",\n\t\t\t\t},\n\t\t\t}\n\t\t} else {\n\t\t\tfor _, deviceMapping := range c.HostConfig.Devices {\n\t\t\t\td, dPermissions, err := oci.DevicesFromPath(deviceMapping.PathOnHost, deviceMapping.PathInContainer, deviceMapping.CgroupPermissions)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tdevs = append(devs, d...)\n\t\t\t\tdevPermissions = append(devPermissions, dPermissions...)\n\t\t\t}\n\n\t\t\tvar err error\n\t\t\tdevPermissions, err = oci.AppendDevicePermissionsFromCgroupRules(devPermissions, c.HostConfig.DeviceCgroupRules)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\ts.Linux.Devices = append(s.Linux.Devices, devs...)\n\t\ts.Linux.Resources.Devices = devPermissions\n\n\t\tfor _, req := range c.HostConfig.DeviceRequests {\n\t\t\tif err := daemon.handleDevice(req, s); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithResources applies the container resources\nfunc WithResources(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tr := c.HostConfig.Resources\n\t\tweightDevices, err := getBlkioWeightDevices(r)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treadBpsDevice, err := getBlkioThrottleDevices(r.BlkioDeviceReadBps)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\twriteBpsDevice, err := getBlkioThrottleDevices(r.BlkioDeviceWriteBps)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\treadIOpsDevice, err := getBlkioThrottleDevices(r.BlkioDeviceReadIOps)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\twriteIOpsDevice, err := getBlkioThrottleDevices(r.BlkioDeviceWriteIOps)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tmemoryRes := getMemoryResources(r)\n\t\tcpuRes, err := getCPUResources(r)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tblkioWeight := r.BlkioWeight\n\n\t\tspecResources := &specs.LinuxResources{\n\t\t\tMemory: memoryRes,\n\t\t\tCPU:    cpuRes,\n\t\t\tBlockIO: &specs.LinuxBlockIO{\n\t\t\t\tWeight:                  &blkioWeight,\n\t\t\t\tWeightDevice:            weightDevices,\n\t\t\t\tThrottleReadBpsDevice:   readBpsDevice,\n\t\t\t\tThrottleWriteBpsDevice:  writeBpsDevice,\n\t\t\t\tThrottleReadIOPSDevice:  readIOpsDevice,\n\t\t\t\tThrottleWriteIOPSDevice: writeIOpsDevice,\n\t\t\t},\n\t\t\tPids: getPidsLimit(r),\n\t\t}\n\n\t\tif s.Linux.Resources != nil && len(s.Linux.Resources.Devices) > 0 {\n\t\t\tspecResources.Devices = s.Linux.Resources.Devices\n\t\t}\n\n\t\ts.Linux.Resources = specResources\n\t\treturn nil\n\t}\n}\n\n// WithSysctls sets the container's sysctls\nfunc WithSysctls(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\t// We merge the sysctls injected above with the HostConfig (latter takes\n\t\t// precedence for backwards-compatibility reasons).\n\t\tfor k, v := range c.HostConfig.Sysctls {\n\t\t\ts.Linux.Sysctl[k] = v\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// WithUser sets the container's user\nfunc WithUser(c *container.Container) coci.SpecOpts {\n\treturn func(ctx context.Context, _ coci.Client, _ *containers.Container, s *coci.Spec) error {\n\t\tvar err error\n\t\ts.Process.User, err = getUser(c, c.Config.User)\n\t\treturn err\n\t}\n}\n\nfunc (daemon *Daemon) createSpec(c *container.Container) (retSpec *specs.Spec, err error) {\n\tvar (\n\t\topts []coci.SpecOpts\n\t\ts    = oci.DefaultSpec()\n\t)\n\topts = append(opts,\n\t\tWithCommonOptions(daemon, c),\n\t\tWithCgroups(daemon, c),\n\t\tWithResources(c),\n\t\tWithSysctls(c),\n\t\tWithDevices(daemon, c),\n\t\tWithUser(c),\n\t\tWithRlimits(daemon, c),\n\t\tWithNamespaces(daemon, c),\n\t\tWithCapabilities(c),\n\t\tWithSeccomp(daemon, c),\n\t\tWithMounts(daemon, c),\n\t\tWithLibnetwork(daemon, c),\n\t\tWithApparmor(c),\n\t\tWithSelinux(c),\n\t\tWithOOMScore(&c.HostConfig.OomScoreAdj),\n\t)\n\tif c.NoNewPrivileges {\n\t\topts = append(opts, coci.WithNoNewPrivileges)\n\t}\n\tif c.Config.Tty {\n\t\topts = append(opts, WithConsoleSize(c))\n\t}\n\t// Set the masked and readonly paths with regard to the host config options if they are set.\n\tif c.HostConfig.MaskedPaths != nil {\n\t\topts = append(opts, coci.WithMaskedPaths(c.HostConfig.MaskedPaths))\n\t}\n\tif c.HostConfig.ReadonlyPaths != nil {\n\t\topts = append(opts, coci.WithReadonlyPaths(c.HostConfig.ReadonlyPaths))\n\t}\n\tif daemon.configStore.Rootless {\n\t\topts = append(opts, WithRootless(daemon))\n\t}\n\n\tvar snapshotter, snapshotKey string\n\tif daemon.UsesSnapshotter() {\n\t\tsnapshotter = daemon.imageService.StorageDriver()\n\t\tsnapshotKey = c.ID\n\t}\n\n\treturn &s, coci.ApplyOpts(context.Background(), nil, &containers.Container{\n\t\tID:          c.ID,\n\t\tSnapshotter: snapshotter,\n\t\tSnapshotKey: snapshotKey,\n\t}, &s, opts...)\n}\n\nfunc clearReadOnly(m *specs.Mount) {\n\tvar opt []string\n\tfor _, o := range m.Options {\n\t\tif o != \"ro\" {\n\t\t\topt = append(opt, o)\n\t\t}\n\t}\n\tm.Options = opt\n}\n\n// mergeUlimits merge the Ulimits from HostConfig with daemon defaults, and update HostConfig\nfunc (daemon *Daemon) mergeUlimits(c *containertypes.HostConfig) {\n\tulimits := c.Ulimits\n\t// Merge ulimits with daemon defaults\n\tulIdx := make(map[string]struct{})\n\tfor _, ul := range ulimits {\n\t\tulIdx[ul.Name] = struct{}{}\n\t}\n\tfor name, ul := range daemon.configStore.Ulimits {\n\t\tif _, exists := ulIdx[name]; !exists {\n\t\t\tulimits = append(ulimits, ul)\n\t\t}\n\t}\n\tc.Ulimits = ulimits\n}\n"], "filenames": ["daemon/oci_linux.go"], "buggy_code_start_loc": [200], "buggy_code_end_loc": [200], "fixing_code_start_loc": [201], "fixing_code_end_loc": [202], "type": "CWE-863", "message": "Moby is an open-source project created by Docker to enable software containerization. A bug was found in Moby (Docker Engine) where supplementary groups are not set up properly. If an attacker has direct access to a container and manipulates their supplementary group access, they may be able to use supplementary group access to bypass primary group restrictions in some cases, potentially gaining access to sensitive information or gaining the ability to execute code in that container. This bug is fixed in Moby (Docker Engine) 20.10.18. Running containers should be stopped and restarted for the permissions to be fixed. For users unable to upgrade, this problem can be worked around by not using the `\"USER $USERNAME\"` Dockerfile instruction. Instead by calling `ENTRYPOINT [\"su\", \"-\", \"user\"]` the supplementary groups will be set up properly.", "other": {"cve": {"id": "CVE-2022-36109", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-09T18:15:10.540", "lastModified": "2022-10-01T02:15:52.683", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Moby is an open-source project created by Docker to enable software containerization. A bug was found in Moby (Docker Engine) where supplementary groups are not set up properly. If an attacker has direct access to a container and manipulates their supplementary group access, they may be able to use supplementary group access to bypass primary group restrictions in some cases, potentially gaining access to sensitive information or gaining the ability to execute code in that container. This bug is fixed in Moby (Docker Engine) 20.10.18. Running containers should be stopped and restarted for the permissions to be fixed. For users unable to upgrade, this problem can be worked around by not using the `\"USER $USERNAME\"` Dockerfile instruction. Instead by calling `ENTRYPOINT [\"su\", \"-\", \"user\"]` the supplementary groups will be set up properly."}, {"lang": "es", "value": "Moby es un proyecto de c\u00f3digo abierto creado por Docker para permitir una contenci\u00f3n de software. Ha sido encontrado un bug en Moby (Docker Engine) en el que los grupos complementarios no son configurados apropiadamente. Si un atacante presenta acceso directo a un contenedor y manipula su acceso a grupos suplementarios, puede ser capaz de usar el acceso a grupos suplementarios para omitir las restricciones de grupos primarios en algunos casos, obteniendo potencialmente acceso a informaci\u00f3n confidencial o ganando la capacidad de ejecutar c\u00f3digo en ese contenedor. Este error ha sido corregido en Moby (Docker Engine) versi\u00f3n 20.10.18. Los contenedores en ejecuci\u00f3n deben ser detenidos y reiniciados para que los permisos sean corregidos. Para usuarios que no puedan actualizar, este problema puede mitigarse al no usar la instrucci\u00f3n \"\"USER $USERNAME\"\" de Dockerfile. En su lugar, llamando a \"ENTRYPOINT [\"su\", \"-\", \"user\"]\" los grupos complementarios ser\u00e1n configurados apropiadamente"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 6.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.4}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 6.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.4}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-863"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:mobyproject:moby:*:*:*:*:*:*:*:*", "versionEndExcluding": "20.10.18", "matchCriteriaId": "6E6EEA64-3516-4248-BE60-F537623DA9E8"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:36:*:*:*:*:*:*:*", "matchCriteriaId": "5C675112-476C-4D7C-BCB9-A2FB2D0BC9FD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:37:*:*:*:*:*:*:*", "matchCriteriaId": "E30D0E6F-4AE8-4284-8716-991DFA48CC5D"}]}]}], "references": [{"url": "https://github.com/moby/moby/commit/de7af816e76a7fd3fbf06bffa6832959289fba32", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/moby/moby/releases/tag/v20.10.18", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/moby/moby/security/advisories/GHSA-rc4r-wh2q-q6c4", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/O7JL2QA3RB732MLJ3RMUXB3IB7AA22YU/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/RQQ4E3JBXVR3VK5FIZVJ3QS2TAOOXXTQ/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/moby/moby/commit/de7af816e76a7fd3fbf06bffa6832959289fba32"}}
{"buggy_code": ["/**************************************************************************\n *\n * Copyright \u00a9 2009-2015 VMware, Inc., Palo Alto, CA., USA\n * All Rights Reserved.\n *\n * Permission is hereby granted, free of charge, to any person obtaining a\n * copy of this software and associated documentation files (the\n * \"Software\"), to deal in the Software without restriction, including\n * without limitation the rights to use, copy, modify, merge, publish,\n * distribute, sub license, and/or sell copies of the Software, and to\n * permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice (including the\n * next paragraph) shall be included in all copies or substantial portions\n * of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL\n * THE COPYRIGHT HOLDERS, AUTHORS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM,\n * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n * USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n **************************************************************************/\n\n#include \"vmwgfx_drv.h\"\n#include \"vmwgfx_resource_priv.h\"\n#include \"vmwgfx_so.h\"\n#include \"vmwgfx_binding.h\"\n#include <ttm/ttm_placement.h>\n#include \"device_include/svga3d_surfacedefs.h\"\n\n\n/**\n * struct vmw_user_surface - User-space visible surface resource\n *\n * @base:           The TTM base object handling user-space visibility.\n * @srf:            The surface metadata.\n * @size:           TTM accounting size for the surface.\n * @master: master of the creating client. Used for security check.\n */\nstruct vmw_user_surface {\n\tstruct ttm_prime_object prime;\n\tstruct vmw_surface srf;\n\tuint32_t size;\n\tstruct drm_master *master;\n\tstruct ttm_base_object *backup_base;\n};\n\n/**\n * struct vmw_surface_offset - Backing store mip level offset info\n *\n * @face:           Surface face.\n * @mip:            Mip level.\n * @bo_offset:      Offset into backing store of this mip level.\n *\n */\nstruct vmw_surface_offset {\n\tuint32_t face;\n\tuint32_t mip;\n\tuint32_t bo_offset;\n};\n\nstatic void vmw_user_surface_free(struct vmw_resource *res);\nstatic struct vmw_resource *\nvmw_user_surface_base_to_res(struct ttm_base_object *base);\nstatic int vmw_legacy_srf_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf);\nstatic int vmw_legacy_srf_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf);\nstatic int vmw_legacy_srf_create(struct vmw_resource *res);\nstatic int vmw_legacy_srf_destroy(struct vmw_resource *res);\nstatic int vmw_gb_surface_create(struct vmw_resource *res);\nstatic int vmw_gb_surface_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf);\nstatic int vmw_gb_surface_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf);\nstatic int vmw_gb_surface_destroy(struct vmw_resource *res);\n\n\nstatic const struct vmw_user_resource_conv user_surface_conv = {\n\t.object_type = VMW_RES_SURFACE,\n\t.base_obj_to_res = vmw_user_surface_base_to_res,\n\t.res_free = vmw_user_surface_free\n};\n\nconst struct vmw_user_resource_conv *user_surface_converter =\n\t&user_surface_conv;\n\n\nstatic uint64_t vmw_user_surface_size;\n\nstatic const struct vmw_res_func vmw_legacy_surface_func = {\n\t.res_type = vmw_res_surface,\n\t.needs_backup = false,\n\t.may_evict = true,\n\t.type_name = \"legacy surfaces\",\n\t.backup_placement = &vmw_srf_placement,\n\t.create = &vmw_legacy_srf_create,\n\t.destroy = &vmw_legacy_srf_destroy,\n\t.bind = &vmw_legacy_srf_bind,\n\t.unbind = &vmw_legacy_srf_unbind\n};\n\nstatic const struct vmw_res_func vmw_gb_surface_func = {\n\t.res_type = vmw_res_surface,\n\t.needs_backup = true,\n\t.may_evict = true,\n\t.type_name = \"guest backed surfaces\",\n\t.backup_placement = &vmw_mob_placement,\n\t.create = vmw_gb_surface_create,\n\t.destroy = vmw_gb_surface_destroy,\n\t.bind = vmw_gb_surface_bind,\n\t.unbind = vmw_gb_surface_unbind\n};\n\n/**\n * struct vmw_surface_dma - SVGA3D DMA command\n */\nstruct vmw_surface_dma {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdSurfaceDMA body;\n\tSVGA3dCopyBox cb;\n\tSVGA3dCmdSurfaceDMASuffix suffix;\n};\n\n/**\n * struct vmw_surface_define - SVGA3D Surface Define command\n */\nstruct vmw_surface_define {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdDefineSurface body;\n};\n\n/**\n * struct vmw_surface_destroy - SVGA3D Surface Destroy command\n */\nstruct vmw_surface_destroy {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdDestroySurface body;\n};\n\n\n/**\n * vmw_surface_dma_size - Compute fifo size for a dma command.\n *\n * @srf: Pointer to a struct vmw_surface\n *\n * Computes the required size for a surface dma command for backup or\n * restoration of the surface represented by @srf.\n */\nstatic inline uint32_t vmw_surface_dma_size(const struct vmw_surface *srf)\n{\n\treturn srf->num_sizes * sizeof(struct vmw_surface_dma);\n}\n\n\n/**\n * vmw_surface_define_size - Compute fifo size for a surface define command.\n *\n * @srf: Pointer to a struct vmw_surface\n *\n * Computes the required size for a surface define command for the definition\n * of the surface represented by @srf.\n */\nstatic inline uint32_t vmw_surface_define_size(const struct vmw_surface *srf)\n{\n\treturn sizeof(struct vmw_surface_define) + srf->num_sizes *\n\t\tsizeof(SVGA3dSize);\n}\n\n\n/**\n * vmw_surface_destroy_size - Compute fifo size for a surface destroy command.\n *\n * Computes the required size for a surface destroy command for the destruction\n * of a hw surface.\n */\nstatic inline uint32_t vmw_surface_destroy_size(void)\n{\n\treturn sizeof(struct vmw_surface_destroy);\n}\n\n/**\n * vmw_surface_destroy_encode - Encode a surface_destroy command.\n *\n * @id: The surface id\n * @cmd_space: Pointer to memory area in which the commands should be encoded.\n */\nstatic void vmw_surface_destroy_encode(uint32_t id,\n\t\t\t\t       void *cmd_space)\n{\n\tstruct vmw_surface_destroy *cmd = (struct vmw_surface_destroy *)\n\t\tcmd_space;\n\n\tcmd->header.id = SVGA_3D_CMD_SURFACE_DESTROY;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.sid = id;\n}\n\n/**\n * vmw_surface_define_encode - Encode a surface_define command.\n *\n * @srf: Pointer to a struct vmw_surface object.\n * @cmd_space: Pointer to memory area in which the commands should be encoded.\n */\nstatic void vmw_surface_define_encode(const struct vmw_surface *srf,\n\t\t\t\t      void *cmd_space)\n{\n\tstruct vmw_surface_define *cmd = (struct vmw_surface_define *)\n\t\tcmd_space;\n\tstruct drm_vmw_size *src_size;\n\tSVGA3dSize *cmd_size;\n\tuint32_t cmd_len;\n\tint i;\n\n\tcmd_len = sizeof(cmd->body) + srf->num_sizes * sizeof(SVGA3dSize);\n\n\tcmd->header.id = SVGA_3D_CMD_SURFACE_DEFINE;\n\tcmd->header.size = cmd_len;\n\tcmd->body.sid = srf->res.id;\n\tcmd->body.surfaceFlags = srf->flags;\n\tcmd->body.format = srf->format;\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i)\n\t\tcmd->body.face[i].numMipLevels = srf->mip_levels[i];\n\n\tcmd += 1;\n\tcmd_size = (SVGA3dSize *) cmd;\n\tsrc_size = srf->sizes;\n\n\tfor (i = 0; i < srf->num_sizes; ++i, cmd_size++, src_size++) {\n\t\tcmd_size->width = src_size->width;\n\t\tcmd_size->height = src_size->height;\n\t\tcmd_size->depth = src_size->depth;\n\t}\n}\n\n/**\n * vmw_surface_dma_encode - Encode a surface_dma command.\n *\n * @srf: Pointer to a struct vmw_surface object.\n * @cmd_space: Pointer to memory area in which the commands should be encoded.\n * @ptr: Pointer to an SVGAGuestPtr indicating where the surface contents\n * should be placed or read from.\n * @to_surface: Boolean whether to DMA to the surface or from the surface.\n */\nstatic void vmw_surface_dma_encode(struct vmw_surface *srf,\n\t\t\t\t   void *cmd_space,\n\t\t\t\t   const SVGAGuestPtr *ptr,\n\t\t\t\t   bool to_surface)\n{\n\tuint32_t i;\n\tstruct vmw_surface_dma *cmd = (struct vmw_surface_dma *)cmd_space;\n\tconst struct svga3d_surface_desc *desc =\n\t\tsvga3dsurface_get_desc(srf->format);\n\n\tfor (i = 0; i < srf->num_sizes; ++i) {\n\t\tSVGA3dCmdHeader *header = &cmd->header;\n\t\tSVGA3dCmdSurfaceDMA *body = &cmd->body;\n\t\tSVGA3dCopyBox *cb = &cmd->cb;\n\t\tSVGA3dCmdSurfaceDMASuffix *suffix = &cmd->suffix;\n\t\tconst struct vmw_surface_offset *cur_offset = &srf->offsets[i];\n\t\tconst struct drm_vmw_size *cur_size = &srf->sizes[i];\n\n\t\theader->id = SVGA_3D_CMD_SURFACE_DMA;\n\t\theader->size = sizeof(*body) + sizeof(*cb) + sizeof(*suffix);\n\n\t\tbody->guest.ptr = *ptr;\n\t\tbody->guest.ptr.offset += cur_offset->bo_offset;\n\t\tbody->guest.pitch = svga3dsurface_calculate_pitch(desc,\n\t\t\t\t\t\t\t\t  cur_size);\n\t\tbody->host.sid = srf->res.id;\n\t\tbody->host.face = cur_offset->face;\n\t\tbody->host.mipmap = cur_offset->mip;\n\t\tbody->transfer = ((to_surface) ?  SVGA3D_WRITE_HOST_VRAM :\n\t\t\t\t  SVGA3D_READ_HOST_VRAM);\n\t\tcb->x = 0;\n\t\tcb->y = 0;\n\t\tcb->z = 0;\n\t\tcb->srcx = 0;\n\t\tcb->srcy = 0;\n\t\tcb->srcz = 0;\n\t\tcb->w = cur_size->width;\n\t\tcb->h = cur_size->height;\n\t\tcb->d = cur_size->depth;\n\n\t\tsuffix->suffixSize = sizeof(*suffix);\n\t\tsuffix->maximumOffset =\n\t\t\tsvga3dsurface_get_image_buffer_size(desc, cur_size,\n\t\t\t\t\t\t\t    body->guest.pitch);\n\t\tsuffix->flags.discard = 0;\n\t\tsuffix->flags.unsynchronized = 0;\n\t\tsuffix->flags.reserved = 0;\n\t\t++cmd;\n\t}\n};\n\n\n/**\n * vmw_hw_surface_destroy - destroy a Device surface\n *\n * @res:        Pointer to a struct vmw_resource embedded in a struct\n *              vmw_surface.\n *\n * Destroys a the device surface associated with a struct vmw_surface if\n * any, and adjusts accounting and resource count accordingly.\n */\nstatic void vmw_hw_surface_destroy(struct vmw_resource *res)\n{\n\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf;\n\tvoid *cmd;\n\n\tif (res->func->destroy == vmw_gb_surface_destroy) {\n\t\t(void) vmw_gb_surface_destroy(res);\n\t\treturn;\n\t}\n\n\tif (res->id != -1) {\n\n\t\tcmd = vmw_fifo_reserve(dev_priv, vmw_surface_destroy_size());\n\t\tif (unlikely(!cmd)) {\n\t\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t\t  \"destruction.\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\tvmw_surface_destroy_encode(res->id, cmd);\n\t\tvmw_fifo_commit(dev_priv, vmw_surface_destroy_size());\n\n\t\t/*\n\t\t * used_memory_size_atomic, or separate lock\n\t\t * to avoid taking dev_priv::cmdbuf_mutex in\n\t\t * the destroy path.\n\t\t */\n\n\t\tmutex_lock(&dev_priv->cmdbuf_mutex);\n\t\tsrf = vmw_res_to_srf(res);\n\t\tdev_priv->used_memory_size -= res->backup_size;\n\t\tmutex_unlock(&dev_priv->cmdbuf_mutex);\n\t}\n\tvmw_fifo_resource_dec(dev_priv);\n}\n\n/**\n * vmw_legacy_srf_create - Create a device surface as part of the\n * resource validation process.\n *\n * @res: Pointer to a struct vmw_surface.\n *\n * If the surface doesn't have a hw id.\n *\n * Returns -EBUSY if there wasn't sufficient device resources to\n * complete the validation. Retry after freeing up resources.\n *\n * May return other errors if the kernel is out of guest resources.\n */\nstatic int vmw_legacy_srf_create(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\tint ret;\n\n\tif (likely(res->id != -1))\n\t\treturn 0;\n\n\tsrf = vmw_res_to_srf(res);\n\tif (unlikely(dev_priv->used_memory_size + res->backup_size >=\n\t\t     dev_priv->memory_size))\n\t\treturn -EBUSY;\n\n\t/*\n\t * Alloc id for the resource.\n\t */\n\n\tret = vmw_resource_alloc_id(res);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Failed to allocate a surface id.\\n\");\n\t\tgoto out_no_id;\n\t}\n\n\tif (unlikely(res->id >= SVGA3D_MAX_SURFACE_IDS)) {\n\t\tret = -EBUSY;\n\t\tgoto out_no_fifo;\n\t}\n\n\t/*\n\t * Encode surface define- commands.\n\t */\n\n\tsubmit_size = vmw_surface_define_size(srf);\n\tcmd = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"creation.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_no_fifo;\n\t}\n\n\tvmw_surface_define_encode(srf, cmd);\n\tvmw_fifo_commit(dev_priv, submit_size);\n\t/*\n\t * Surface memory usage accounting.\n\t */\n\n\tdev_priv->used_memory_size += res->backup_size;\n\treturn 0;\n\nout_no_fifo:\n\tvmw_resource_release_id(res);\nout_no_id:\n\treturn ret;\n}\n\n/**\n * vmw_legacy_srf_dma - Copy backup data to or from a legacy surface.\n *\n * @res:            Pointer to a struct vmw_res embedded in a struct\n *                  vmw_surface.\n * @val_buf:        Pointer to a struct ttm_validate_buffer containing\n *                  information about the backup buffer.\n * @bind:           Boolean wether to DMA to the surface.\n *\n * Transfer backup data to or from a legacy surface as part of the\n * validation process.\n * May return other errors if the kernel is out of guest resources.\n * The backup buffer will be fenced or idle upon successful completion,\n * and if the surface needs persistent backup storage, the backup buffer\n * will also be returned reserved iff @bind is true.\n */\nstatic int vmw_legacy_srf_dma(struct vmw_resource *res,\n\t\t\t      struct ttm_validate_buffer *val_buf,\n\t\t\t      bool bind)\n{\n\tSVGAGuestPtr ptr;\n\tstruct vmw_fence_obj *fence;\n\tuint32_t submit_size;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tuint8_t *cmd;\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\n\tBUG_ON(!val_buf->bo);\n\tsubmit_size = vmw_surface_dma_size(srf);\n\tcmd = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"DMA.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tvmw_bo_get_guest_ptr(val_buf->bo, &ptr);\n\tvmw_surface_dma_encode(srf, cmd, &ptr, bind);\n\n\tvmw_fifo_commit(dev_priv, submit_size);\n\n\t/*\n\t * Create a fence object and fence the backup buffer.\n\t */\n\n\t(void) vmw_execbuf_fence_commands(NULL, dev_priv,\n\t\t\t\t\t  &fence, NULL);\n\n\tvmw_fence_single_bo(val_buf->bo, fence);\n\n\tif (likely(fence != NULL))\n\t\tvmw_fence_obj_unreference(&fence);\n\n\treturn 0;\n}\n\n/**\n * vmw_legacy_srf_bind - Perform a legacy surface bind as part of the\n *                       surface validation process.\n *\n * @res:            Pointer to a struct vmw_res embedded in a struct\n *                  vmw_surface.\n * @val_buf:        Pointer to a struct ttm_validate_buffer containing\n *                  information about the backup buffer.\n *\n * This function will copy backup data to the surface if the\n * backup buffer is dirty.\n */\nstatic int vmw_legacy_srf_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf)\n{\n\tif (!res->backup_dirty)\n\t\treturn 0;\n\n\treturn vmw_legacy_srf_dma(res, val_buf, true);\n}\n\n\n/**\n * vmw_legacy_srf_unbind - Perform a legacy surface unbind as part of the\n *                         surface eviction process.\n *\n * @res:            Pointer to a struct vmw_res embedded in a struct\n *                  vmw_surface.\n * @val_buf:        Pointer to a struct ttm_validate_buffer containing\n *                  information about the backup buffer.\n *\n * This function will copy backup data from the surface.\n */\nstatic int vmw_legacy_srf_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf)\n{\n\tif (unlikely(readback))\n\t\treturn vmw_legacy_srf_dma(res, val_buf, false);\n\treturn 0;\n}\n\n/**\n * vmw_legacy_srf_destroy - Destroy a device surface as part of a\n *                          resource eviction process.\n *\n * @res:            Pointer to a struct vmw_res embedded in a struct\n *                  vmw_surface.\n */\nstatic int vmw_legacy_srf_destroy(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\n\tBUG_ON(res->id == -1);\n\n\t/*\n\t * Encode the dma- and surface destroy commands.\n\t */\n\n\tsubmit_size = vmw_surface_destroy_size();\n\tcmd = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"eviction.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tvmw_surface_destroy_encode(res->id, cmd);\n\tvmw_fifo_commit(dev_priv, submit_size);\n\n\t/*\n\t * Surface memory usage accounting.\n\t */\n\n\tdev_priv->used_memory_size -= res->backup_size;\n\n\t/*\n\t * Release the surface ID.\n\t */\n\n\tvmw_resource_release_id(res);\n\n\treturn 0;\n}\n\n\n/**\n * vmw_surface_init - initialize a struct vmw_surface\n *\n * @dev_priv:       Pointer to a device private struct.\n * @srf:            Pointer to the struct vmw_surface to initialize.\n * @res_free:       Pointer to a resource destructor used to free\n *                  the object.\n */\nstatic int vmw_surface_init(struct vmw_private *dev_priv,\n\t\t\t    struct vmw_surface *srf,\n\t\t\t    void (*res_free) (struct vmw_resource *res))\n{\n\tint ret;\n\tstruct vmw_resource *res = &srf->res;\n\n\tBUG_ON(!res_free);\n\tif (!dev_priv->has_mob)\n\t\tvmw_fifo_resource_inc(dev_priv);\n\tret = vmw_resource_init(dev_priv, res, true, res_free,\n\t\t\t\t(dev_priv->has_mob) ? &vmw_gb_surface_func :\n\t\t\t\t&vmw_legacy_surface_func);\n\n\tif (unlikely(ret != 0)) {\n\t\tif (!dev_priv->has_mob)\n\t\t\tvmw_fifo_resource_dec(dev_priv);\n\t\tres_free(res);\n\t\treturn ret;\n\t}\n\n\t/*\n\t * The surface won't be visible to hardware until a\n\t * surface validate.\n\t */\n\n\tINIT_LIST_HEAD(&srf->view_list);\n\tvmw_resource_activate(res, vmw_hw_surface_destroy);\n\treturn ret;\n}\n\n/**\n * vmw_user_surface_base_to_res - TTM base object to resource converter for\n *                                user visible surfaces\n *\n * @base:           Pointer to a TTM base object\n *\n * Returns the struct vmw_resource embedded in a struct vmw_surface\n * for the user-visible object identified by the TTM base object @base.\n */\nstatic struct vmw_resource *\nvmw_user_surface_base_to_res(struct ttm_base_object *base)\n{\n\treturn &(container_of(base, struct vmw_user_surface,\n\t\t\t      prime.base)->srf.res);\n}\n\n/**\n * vmw_user_surface_free - User visible surface resource destructor\n *\n * @res:            A struct vmw_resource embedded in a struct vmw_surface.\n */\nstatic void vmw_user_surface_free(struct vmw_resource *res)\n{\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tstruct vmw_user_surface *user_srf =\n\t    container_of(srf, struct vmw_user_surface, srf);\n\tstruct vmw_private *dev_priv = srf->res.dev_priv;\n\tuint32_t size = user_srf->size;\n\n\tif (user_srf->master)\n\t\tdrm_master_put(&user_srf->master);\n\tkfree(srf->offsets);\n\tkfree(srf->sizes);\n\tkfree(srf->snooper.image);\n\tttm_prime_object_kfree(user_srf, prime);\n\tttm_mem_global_free(vmw_mem_glob(dev_priv), size);\n}\n\n/**\n * vmw_user_surface_free - User visible surface TTM base object destructor\n *\n * @p_base:         Pointer to a pointer to a TTM base object\n *                  embedded in a struct vmw_user_surface.\n *\n * Drops the base object's reference on its resource, and the\n * pointer pointed to by *p_base is set to NULL.\n */\nstatic void vmw_user_surface_base_release(struct ttm_base_object **p_base)\n{\n\tstruct ttm_base_object *base = *p_base;\n\tstruct vmw_user_surface *user_srf =\n\t    container_of(base, struct vmw_user_surface, prime.base);\n\tstruct vmw_resource *res = &user_srf->srf.res;\n\n\t*p_base = NULL;\n\tif (user_srf->backup_base)\n\t\tttm_base_object_unref(&user_srf->backup_base);\n\tvmw_resource_unreference(&res);\n}\n\n/**\n * vmw_user_surface_destroy_ioctl - Ioctl function implementing\n *                                  the user surface destroy functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_surface_destroy_ioctl(struct drm_device *dev, void *data,\n\t\t\t      struct drm_file *file_priv)\n{\n\tstruct drm_vmw_surface_arg *arg = (struct drm_vmw_surface_arg *)data;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\n\treturn ttm_ref_object_base_unref(tfile, arg->sid, TTM_REF_USAGE);\n}\n\n/**\n * vmw_user_surface_define_ioctl - Ioctl function implementing\n *                                  the user surface define functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_surface_define_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tstruct vmw_resource *res;\n\tstruct vmw_resource *tmp;\n\tunion drm_vmw_surface_create_arg *arg =\n\t    (union drm_vmw_surface_create_arg *)data;\n\tstruct drm_vmw_surface_create_req *req = &arg->req;\n\tstruct drm_vmw_surface_arg *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tint ret;\n\tint i, j;\n\tuint32_t cur_bo_offset;\n\tstruct drm_vmw_size *cur_size;\n\tstruct vmw_surface_offset *cur_offset;\n\tuint32_t num_sizes;\n\tuint32_t size;\n\tconst struct svga3d_surface_desc *desc;\n\n\tif (unlikely(vmw_user_surface_size == 0))\n\t\tvmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +\n\t\t\t128;\n\n\tnum_sizes = 0;\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tif (req->mip_levels[i] > DRM_VMW_MAX_MIP_LEVELS)\n\t\t\treturn -EINVAL;\n\t\tnum_sizes += req->mip_levels[i];\n\t}\n\n\tif (num_sizes > DRM_VMW_MAX_SURFACE_FACES * DRM_VMW_MAX_MIP_LEVELS ||\n\t    num_sizes == 0)\n\t\treturn -EINVAL;\n\n\tsize = vmw_user_surface_size + 128 +\n\t\tttm_round_pot(num_sizes * sizeof(struct drm_vmw_size)) +\n\t\tttm_round_pot(num_sizes * sizeof(struct vmw_surface_offset));\n\n\n\tdesc = svga3dsurface_get_desc(req->format);\n\tif (unlikely(desc->block_desc == SVGA3DBLOCKDESC_NONE)) {\n\t\tDRM_ERROR(\"Invalid surface format for surface creation.\\n\");\n\t\tDRM_ERROR(\"Format requested is: %d\\n\", req->format);\n\t\treturn -EINVAL;\n\t}\n\n\tret = ttm_read_lock(&dev_priv->reservation_sem, true);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tret = ttm_mem_global_alloc(vmw_mem_glob(dev_priv),\n\t\t\t\t   size, false, true);\n\tif (unlikely(ret != 0)) {\n\t\tif (ret != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Out of graphics memory for surface\"\n\t\t\t\t  \" creation.\\n\");\n\t\tgoto out_unlock;\n\t}\n\n\tuser_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);\n\tif (unlikely(!user_srf)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_user_srf;\n\t}\n\n\tsrf = &user_srf->srf;\n\tres = &srf->res;\n\n\tsrf->flags = req->flags;\n\tsrf->format = req->format;\n\tsrf->scanout = req->scanout;\n\n\tmemcpy(srf->mip_levels, req->mip_levels, sizeof(srf->mip_levels));\n\tsrf->num_sizes = num_sizes;\n\tuser_srf->size = size;\n\tsrf->sizes = memdup_user((struct drm_vmw_size __user *)(unsigned long)\n\t\t\t\t req->size_addr,\n\t\t\t\t sizeof(*srf->sizes) * srf->num_sizes);\n\tif (IS_ERR(srf->sizes)) {\n\t\tret = PTR_ERR(srf->sizes);\n\t\tgoto out_no_sizes;\n\t}\n\tsrf->offsets = kmalloc_array(srf->num_sizes,\n\t\t\t\t     sizeof(*srf->offsets),\n\t\t\t\t     GFP_KERNEL);\n\tif (unlikely(!srf->offsets)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_offsets;\n\t}\n\n\tsrf->base_size = *srf->sizes;\n\tsrf->autogen_filter = SVGA3D_TEX_FILTER_NONE;\n\tsrf->multisample_count = 0;\n\n\tcur_bo_offset = 0;\n\tcur_offset = srf->offsets;\n\tcur_size = srf->sizes;\n\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tfor (j = 0; j < srf->mip_levels[i]; ++j) {\n\t\t\tuint32_t stride = svga3dsurface_calculate_pitch\n\t\t\t\t(desc, cur_size);\n\n\t\t\tcur_offset->face = i;\n\t\t\tcur_offset->mip = j;\n\t\t\tcur_offset->bo_offset = cur_bo_offset;\n\t\t\tcur_bo_offset += svga3dsurface_get_image_buffer_size\n\t\t\t\t(desc, cur_size, stride);\n\t\t\t++cur_offset;\n\t\t\t++cur_size;\n\t\t}\n\t}\n\tres->backup_size = cur_bo_offset;\n\tif (srf->scanout &&\n\t    srf->num_sizes == 1 &&\n\t    srf->sizes[0].width == 64 &&\n\t    srf->sizes[0].height == 64 &&\n\t    srf->format == SVGA3D_A8R8G8B8) {\n\n\t\tsrf->snooper.image = kzalloc(64 * 64 * 4, GFP_KERNEL);\n\t\tif (!srf->snooper.image) {\n\t\t\tDRM_ERROR(\"Failed to allocate cursor_image\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_no_copy;\n\t\t}\n\t} else {\n\t\tsrf->snooper.image = NULL;\n\t}\n\n\tuser_srf->prime.base.shareable = false;\n\tuser_srf->prime.base.tfile = NULL;\n\tif (drm_is_primary_client(file_priv))\n\t\tuser_srf->master = drm_master_get(file_priv->master);\n\n\t/**\n\t * From this point, the generic resource management functions\n\t * destroy the object on failure.\n\t */\n\n\tret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);\n\tif (unlikely(ret != 0))\n\t\tgoto out_unlock;\n\n\t/*\n\t * A gb-aware client referencing a shared surface will\n\t * expect a backup buffer to be present.\n\t */\n\tif (dev_priv->has_mob && req->shareable) {\n\t\tuint32_t backup_handle;\n\n\t\tret = vmw_user_dmabuf_alloc(dev_priv, tfile,\n\t\t\t\t\t    res->backup_size,\n\t\t\t\t\t    true,\n\t\t\t\t\t    &backup_handle,\n\t\t\t\t\t    &res->backup,\n\t\t\t\t\t    &user_srf->backup_base);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tvmw_resource_unreference(&res);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\ttmp = vmw_resource_reference(&srf->res);\n\tret = ttm_prime_object_init(tfile, res->backup_size, &user_srf->prime,\n\t\t\t\t    req->shareable, VMW_RES_SURFACE,\n\t\t\t\t    &vmw_user_surface_base_release, NULL);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&tmp);\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\trep->sid = user_srf->prime.base.hash.key;\n\tvmw_resource_unreference(&res);\n\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn 0;\nout_no_copy:\n\tkfree(srf->offsets);\nout_no_offsets:\n\tkfree(srf->sizes);\nout_no_sizes:\n\tttm_prime_object_kfree(user_srf, prime);\nout_no_user_srf:\n\tttm_mem_global_free(vmw_mem_glob(dev_priv), size);\nout_unlock:\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n}\n\n\nstatic int\nvmw_surface_handle_reference(struct vmw_private *dev_priv,\n\t\t\t     struct drm_file *file_priv,\n\t\t\t     uint32_t u_handle,\n\t\t\t     enum drm_vmw_handle_type handle_type,\n\t\t\t     struct ttm_base_object **base_p)\n{\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_user_surface *user_srf;\n\tuint32_t handle;\n\tstruct ttm_base_object *base;\n\tint ret;\n\tbool require_exist = false;\n\n\tif (handle_type == DRM_VMW_HANDLE_PRIME) {\n\t\tret = ttm_prime_fd_to_handle(tfile, u_handle, &handle);\n\t\tif (unlikely(ret != 0))\n\t\t\treturn ret;\n\t} else {\n\t\tif (unlikely(drm_is_render_client(file_priv)))\n\t\t\trequire_exist = true;\n\n\t\tif (ACCESS_ONCE(vmw_fpriv(file_priv)->locked_master)) {\n\t\t\tDRM_ERROR(\"Locked master refused legacy \"\n\t\t\t\t  \"surface reference.\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\thandle = u_handle;\n\t}\n\n\tret = -EINVAL;\n\tbase = ttm_base_object_lookup_for_ref(dev_priv->tdev, handle);\n\tif (unlikely(!base)) {\n\t\tDRM_ERROR(\"Could not find surface to reference.\\n\");\n\t\tgoto out_no_lookup;\n\t}\n\n\tif (unlikely(ttm_base_object_type(base) != VMW_RES_SURFACE)) {\n\t\tDRM_ERROR(\"Referenced object is not a surface.\\n\");\n\t\tgoto out_bad_resource;\n\t}\n\n\tif (handle_type != DRM_VMW_HANDLE_PRIME) {\n\t\tuser_srf = container_of(base, struct vmw_user_surface,\n\t\t\t\t\tprime.base);\n\n\t\t/*\n\t\t * Make sure the surface creator has the same\n\t\t * authenticating master, or is already registered with us.\n\t\t */\n\t\tif (drm_is_primary_client(file_priv) &&\n\t\t    user_srf->master != file_priv->master)\n\t\t\trequire_exist = true;\n\n\t\tret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL,\n\t\t\t\t\t require_exist);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tDRM_ERROR(\"Could not add a reference to a surface.\\n\");\n\t\t\tgoto out_bad_resource;\n\t\t}\n\t}\n\n\t*base_p = base;\n\treturn 0;\n\nout_bad_resource:\n\tttm_base_object_unref(&base);\nout_no_lookup:\n\tif (handle_type == DRM_VMW_HANDLE_PRIME)\n\t\t(void) ttm_ref_object_base_unref(tfile, handle, TTM_REF_USAGE);\n\n\treturn ret;\n}\n\n/**\n * vmw_user_surface_define_ioctl - Ioctl function implementing\n *                                  the user surface reference functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_surface_reference_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tunion drm_vmw_surface_reference_arg *arg =\n\t    (union drm_vmw_surface_reference_arg *)data;\n\tstruct drm_vmw_surface_arg *req = &arg->req;\n\tstruct drm_vmw_surface_create_req *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_surface *srf;\n\tstruct vmw_user_surface *user_srf;\n\tstruct drm_vmw_size __user *user_sizes;\n\tstruct ttm_base_object *base;\n\tint ret;\n\n\tret = vmw_surface_handle_reference(dev_priv, file_priv, req->sid,\n\t\t\t\t\t   req->handle_type, &base);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tuser_srf = container_of(base, struct vmw_user_surface, prime.base);\n\tsrf = &user_srf->srf;\n\n\trep->flags = srf->flags;\n\trep->format = srf->format;\n\tmemcpy(rep->mip_levels, srf->mip_levels, sizeof(srf->mip_levels));\n\tuser_sizes = (struct drm_vmw_size __user *)(unsigned long)\n\t    rep->size_addr;\n\n\tif (user_sizes)\n\t\tret = copy_to_user(user_sizes, &srf->base_size,\n\t\t\t\t   sizeof(srf->base_size));\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"copy_to_user failed %p %u\\n\",\n\t\t\t  user_sizes, srf->num_sizes);\n\t\tttm_ref_object_base_unref(tfile, base->hash.key, TTM_REF_USAGE);\n\t\tret = -EFAULT;\n\t}\n\n\tttm_base_object_unref(&base);\n\n\treturn ret;\n}\n\n/**\n * vmw_surface_define_encode - Encode a surface_define command.\n *\n * @srf: Pointer to a struct vmw_surface object.\n * @cmd_space: Pointer to memory area in which the commands should be encoded.\n */\nstatic int vmw_gb_surface_create(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tuint32_t cmd_len, cmd_id, submit_len;\n\tint ret;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDefineGBSurface body;\n\t} *cmd;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDefineGBSurface_v2 body;\n\t} *cmd2;\n\n\tif (likely(res->id != -1))\n\t\treturn 0;\n\n\tvmw_fifo_resource_inc(dev_priv);\n\tret = vmw_resource_alloc_id(res);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Failed to allocate a surface id.\\n\");\n\t\tgoto out_no_id;\n\t}\n\n\tif (unlikely(res->id >= VMWGFX_NUM_GB_SURFACE)) {\n\t\tret = -EBUSY;\n\t\tgoto out_no_fifo;\n\t}\n\n\tif (srf->array_size > 0) {\n\t\t/* has_dx checked on creation time. */\n\t\tcmd_id = SVGA_3D_CMD_DEFINE_GB_SURFACE_V2;\n\t\tcmd_len = sizeof(cmd2->body);\n\t\tsubmit_len = sizeof(*cmd2);\n\t} else {\n\t\tcmd_id = SVGA_3D_CMD_DEFINE_GB_SURFACE;\n\t\tcmd_len = sizeof(cmd->body);\n\t\tsubmit_len = sizeof(*cmd);\n\t}\n\n\tcmd = vmw_fifo_reserve(dev_priv, submit_len);\n\tcmd2 = (typeof(cmd2))cmd;\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"creation.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_no_fifo;\n\t}\n\n\tif (srf->array_size > 0) {\n\t\tcmd2->header.id = cmd_id;\n\t\tcmd2->header.size = cmd_len;\n\t\tcmd2->body.sid = srf->res.id;\n\t\tcmd2->body.surfaceFlags = srf->flags;\n\t\tcmd2->body.format = cpu_to_le32(srf->format);\n\t\tcmd2->body.numMipLevels = srf->mip_levels[0];\n\t\tcmd2->body.multisampleCount = srf->multisample_count;\n\t\tcmd2->body.autogenFilter = srf->autogen_filter;\n\t\tcmd2->body.size.width = srf->base_size.width;\n\t\tcmd2->body.size.height = srf->base_size.height;\n\t\tcmd2->body.size.depth = srf->base_size.depth;\n\t\tcmd2->body.arraySize = srf->array_size;\n\t} else {\n\t\tcmd->header.id = cmd_id;\n\t\tcmd->header.size = cmd_len;\n\t\tcmd->body.sid = srf->res.id;\n\t\tcmd->body.surfaceFlags = srf->flags;\n\t\tcmd->body.format = cpu_to_le32(srf->format);\n\t\tcmd->body.numMipLevels = srf->mip_levels[0];\n\t\tcmd->body.multisampleCount = srf->multisample_count;\n\t\tcmd->body.autogenFilter = srf->autogen_filter;\n\t\tcmd->body.size.width = srf->base_size.width;\n\t\tcmd->body.size.height = srf->base_size.height;\n\t\tcmd->body.size.depth = srf->base_size.depth;\n\t}\n\n\tvmw_fifo_commit(dev_priv, submit_len);\n\n\treturn 0;\n\nout_no_fifo:\n\tvmw_resource_release_id(res);\nout_no_id:\n\tvmw_fifo_resource_dec(dev_priv);\n\treturn ret;\n}\n\n\nstatic int vmw_gb_surface_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdBindGBSurface body;\n\t} *cmd1;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdUpdateGBSurface body;\n\t} *cmd2;\n\tuint32_t submit_size;\n\tstruct ttm_buffer_object *bo = val_buf->bo;\n\n\tBUG_ON(bo->mem.mem_type != VMW_PL_MOB);\n\n\tsubmit_size = sizeof(*cmd1) + (res->backup_dirty ? sizeof(*cmd2) : 0);\n\n\tcmd1 = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd1)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"binding.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tcmd1->header.id = SVGA_3D_CMD_BIND_GB_SURFACE;\n\tcmd1->header.size = sizeof(cmd1->body);\n\tcmd1->body.sid = res->id;\n\tcmd1->body.mobid = bo->mem.start;\n\tif (res->backup_dirty) {\n\t\tcmd2 = (void *) &cmd1[1];\n\t\tcmd2->header.id = SVGA_3D_CMD_UPDATE_GB_SURFACE;\n\t\tcmd2->header.size = sizeof(cmd2->body);\n\t\tcmd2->body.sid = res->id;\n\t\tres->backup_dirty = false;\n\t}\n\tvmw_fifo_commit(dev_priv, submit_size);\n\n\treturn 0;\n}\n\nstatic int vmw_gb_surface_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct ttm_buffer_object *bo = val_buf->bo;\n\tstruct vmw_fence_obj *fence;\n\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdReadbackGBSurface body;\n\t} *cmd1;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdInvalidateGBSurface body;\n\t} *cmd2;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdBindGBSurface body;\n\t} *cmd3;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\n\n\tBUG_ON(bo->mem.mem_type != VMW_PL_MOB);\n\n\tsubmit_size = sizeof(*cmd3) + (readback ? sizeof(*cmd1) : sizeof(*cmd2));\n\tcmd = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"unbinding.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (readback) {\n\t\tcmd1 = (void *) cmd;\n\t\tcmd1->header.id = SVGA_3D_CMD_READBACK_GB_SURFACE;\n\t\tcmd1->header.size = sizeof(cmd1->body);\n\t\tcmd1->body.sid = res->id;\n\t\tcmd3 = (void *) &cmd1[1];\n\t} else {\n\t\tcmd2 = (void *) cmd;\n\t\tcmd2->header.id = SVGA_3D_CMD_INVALIDATE_GB_SURFACE;\n\t\tcmd2->header.size = sizeof(cmd2->body);\n\t\tcmd2->body.sid = res->id;\n\t\tcmd3 = (void *) &cmd2[1];\n\t}\n\n\tcmd3->header.id = SVGA_3D_CMD_BIND_GB_SURFACE;\n\tcmd3->header.size = sizeof(cmd3->body);\n\tcmd3->body.sid = res->id;\n\tcmd3->body.mobid = SVGA3D_INVALID_ID;\n\n\tvmw_fifo_commit(dev_priv, submit_size);\n\n\t/*\n\t * Create a fence object and fence the backup buffer.\n\t */\n\n\t(void) vmw_execbuf_fence_commands(NULL, dev_priv,\n\t\t\t\t\t  &fence, NULL);\n\n\tvmw_fence_single_bo(val_buf->bo, fence);\n\n\tif (likely(fence != NULL))\n\t\tvmw_fence_obj_unreference(&fence);\n\n\treturn 0;\n}\n\nstatic int vmw_gb_surface_destroy(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDestroyGBSurface body;\n\t} *cmd;\n\n\tif (likely(res->id == -1))\n\t\treturn 0;\n\n\tmutex_lock(&dev_priv->binding_mutex);\n\tvmw_view_surface_list_destroy(dev_priv, &srf->view_list);\n\tvmw_binding_res_list_scrub(&res->binding_head);\n\n\tcmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"destruction.\\n\");\n\t\tmutex_unlock(&dev_priv->binding_mutex);\n\t\treturn -ENOMEM;\n\t}\n\n\tcmd->header.id = SVGA_3D_CMD_DESTROY_GB_SURFACE;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.sid = res->id;\n\tvmw_fifo_commit(dev_priv, sizeof(*cmd));\n\tmutex_unlock(&dev_priv->binding_mutex);\n\tvmw_resource_release_id(res);\n\tvmw_fifo_resource_dec(dev_priv);\n\n\treturn 0;\n}\n\n\n/**\n * vmw_gb_surface_define_ioctl - Ioctl function implementing\n *                               the user surface define functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tstruct vmw_resource *res;\n\tstruct vmw_resource *tmp;\n\tunion drm_vmw_gb_surface_create_arg *arg =\n\t    (union drm_vmw_gb_surface_create_arg *)data;\n\tstruct drm_vmw_gb_surface_create_req *req = &arg->req;\n\tstruct drm_vmw_gb_surface_create_rep *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tint ret;\n\tuint32_t size;\n\tuint32_t backup_handle;\n\n\tif (req->multisample_count != 0)\n\t\treturn -EINVAL;\n\n\tif (req->mip_levels > DRM_VMW_MAX_MIP_LEVELS)\n\t\treturn -EINVAL;\n\n\tif (unlikely(vmw_user_surface_size == 0))\n\t\tvmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +\n\t\t\t128;\n\n\tsize = vmw_user_surface_size + 128;\n\n\t/* Define a surface based on the parameters. */\n\tret = vmw_surface_gb_priv_define(dev,\n\t\t\tsize,\n\t\t\treq->svga3d_flags,\n\t\t\treq->format,\n\t\t\treq->drm_surface_flags & drm_vmw_surface_flag_scanout,\n\t\t\treq->mip_levels,\n\t\t\treq->multisample_count,\n\t\t\treq->array_size,\n\t\t\treq->base_size,\n\t\t\t&srf);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tuser_srf = container_of(srf, struct vmw_user_surface, srf);\n\tif (drm_is_primary_client(file_priv))\n\t\tuser_srf->master = drm_master_get(file_priv->master);\n\n\tret = ttm_read_lock(&dev_priv->reservation_sem, true);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tres = &user_srf->srf.res;\n\n\n\tif (req->buffer_handle != SVGA3D_INVALID_ID) {\n\t\tret = vmw_user_dmabuf_lookup(tfile, req->buffer_handle,\n\t\t\t\t\t     &res->backup,\n\t\t\t\t\t     &user_srf->backup_base);\n\t\tif (ret == 0 && res->backup->base.num_pages * PAGE_SIZE <\n\t\t    res->backup_size) {\n\t\t\tDRM_ERROR(\"Surface backup buffer is too small.\\n\");\n\t\t\tvmw_dmabuf_unreference(&res->backup);\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_unlock;\n\t\t}\n\t} else if (req->drm_surface_flags & drm_vmw_surface_flag_create_buffer)\n\t\tret = vmw_user_dmabuf_alloc(dev_priv, tfile,\n\t\t\t\t\t    res->backup_size,\n\t\t\t\t\t    req->drm_surface_flags &\n\t\t\t\t\t    drm_vmw_surface_flag_shareable,\n\t\t\t\t\t    &backup_handle,\n\t\t\t\t\t    &res->backup,\n\t\t\t\t\t    &user_srf->backup_base);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\ttmp = vmw_resource_reference(res);\n\tret = ttm_prime_object_init(tfile, res->backup_size, &user_srf->prime,\n\t\t\t\t    req->drm_surface_flags &\n\t\t\t\t    drm_vmw_surface_flag_shareable,\n\t\t\t\t    VMW_RES_SURFACE,\n\t\t\t\t    &vmw_user_surface_base_release, NULL);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&tmp);\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\trep->handle      = user_srf->prime.base.hash.key;\n\trep->backup_size = res->backup_size;\n\tif (res->backup) {\n\t\trep->buffer_map_handle =\n\t\t\tdrm_vma_node_offset_addr(&res->backup->base.vma_node);\n\t\trep->buffer_size = res->backup->base.num_pages * PAGE_SIZE;\n\t\trep->buffer_handle = backup_handle;\n\t} else {\n\t\trep->buffer_map_handle = 0;\n\t\trep->buffer_size = 0;\n\t\trep->buffer_handle = SVGA3D_INVALID_ID;\n\t}\n\n\tvmw_resource_unreference(&res);\n\nout_unlock:\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n}\n\n/**\n * vmw_gb_surface_reference_ioctl - Ioctl function implementing\n *                                  the user surface reference functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_gb_surface_reference_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t   struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tunion drm_vmw_gb_surface_reference_arg *arg =\n\t    (union drm_vmw_gb_surface_reference_arg *)data;\n\tstruct drm_vmw_surface_arg *req = &arg->req;\n\tstruct drm_vmw_gb_surface_ref_rep *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_surface *srf;\n\tstruct vmw_user_surface *user_srf;\n\tstruct ttm_base_object *base;\n\tuint32_t backup_handle;\n\tint ret = -EINVAL;\n\n\tret = vmw_surface_handle_reference(dev_priv, file_priv, req->sid,\n\t\t\t\t\t   req->handle_type, &base);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tuser_srf = container_of(base, struct vmw_user_surface, prime.base);\n\tsrf = &user_srf->srf;\n\tif (!srf->res.backup) {\n\t\tDRM_ERROR(\"Shared GB surface is missing a backup buffer.\\n\");\n\t\tgoto out_bad_resource;\n\t}\n\n\tmutex_lock(&dev_priv->cmdbuf_mutex); /* Protect res->backup */\n\tret = vmw_user_dmabuf_reference(tfile, srf->res.backup,\n\t\t\t\t\t&backup_handle);\n\tmutex_unlock(&dev_priv->cmdbuf_mutex);\n\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Could not add a reference to a GB surface \"\n\t\t\t  \"backup buffer.\\n\");\n\t\t(void) ttm_ref_object_base_unref(tfile, base->hash.key,\n\t\t\t\t\t\t TTM_REF_USAGE);\n\t\tgoto out_bad_resource;\n\t}\n\n\trep->creq.svga3d_flags = srf->flags;\n\trep->creq.format = srf->format;\n\trep->creq.mip_levels = srf->mip_levels[0];\n\trep->creq.drm_surface_flags = 0;\n\trep->creq.multisample_count = srf->multisample_count;\n\trep->creq.autogen_filter = srf->autogen_filter;\n\trep->creq.array_size = srf->array_size;\n\trep->creq.buffer_handle = backup_handle;\n\trep->creq.base_size = srf->base_size;\n\trep->crep.handle = user_srf->prime.base.hash.key;\n\trep->crep.backup_size = srf->res.backup_size;\n\trep->crep.buffer_handle = backup_handle;\n\trep->crep.buffer_map_handle =\n\t\tdrm_vma_node_offset_addr(&srf->res.backup->base.vma_node);\n\trep->crep.buffer_size = srf->res.backup->base.num_pages * PAGE_SIZE;\n\nout_bad_resource:\n\tttm_base_object_unref(&base);\n\n\treturn ret;\n}\n\n/**\n * vmw_surface_gb_priv_define - Define a private GB surface\n *\n * @dev:  Pointer to a struct drm_device\n * @user_accounting_size:  Used to track user-space memory usage, set\n *                         to 0 for kernel mode only memory\n * @svga3d_flags: SVGA3d surface flags for the device\n * @format: requested surface format\n * @for_scanout: true if inteded to be used for scanout buffer\n * @num_mip_levels:  number of MIP levels\n * @multisample_count:\n * @array_size: Surface array size.\n * @size: width, heigh, depth of the surface requested\n * @user_srf_out: allocated user_srf.  Set to NULL on failure.\n *\n * GB surfaces allocated by this function will not have a user mode handle, and\n * thus will only be visible to vmwgfx.  For optimization reasons the\n * surface may later be given a user mode handle by another function to make\n * it available to user mode drivers.\n */\nint vmw_surface_gb_priv_define(struct drm_device *dev,\n\t\t\t       uint32_t user_accounting_size,\n\t\t\t       uint32_t svga3d_flags,\n\t\t\t       SVGA3dSurfaceFormat format,\n\t\t\t       bool for_scanout,\n\t\t\t       uint32_t num_mip_levels,\n\t\t\t       uint32_t multisample_count,\n\t\t\t       uint32_t array_size,\n\t\t\t       struct drm_vmw_size size,\n\t\t\t       struct vmw_surface **srf_out)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tint ret;\n\tu32 num_layers;\n\n\t*srf_out = NULL;\n\n\tif (for_scanout) {\n\t\tuint32_t max_width, max_height;\n\n\t\tif (!svga3dsurface_is_screen_target_format(format)) {\n\t\t\tDRM_ERROR(\"Invalid Screen Target surface format.\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tmax_width = min(dev_priv->texture_max_width,\n\t\t\t\tdev_priv->stdu_max_width);\n\t\tmax_height = min(dev_priv->texture_max_height,\n\t\t\t\t dev_priv->stdu_max_height);\n\n\t\tif (size.width > max_width || size.height > max_height) {\n\t\t\tDRM_ERROR(\"%ux%u\\n, exeeds max surface size %ux%u\",\n\t\t\t\t  size.width, size.height,\n\t\t\t\t  max_width, max_height);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tconst struct svga3d_surface_desc *desc;\n\n\t\tdesc = svga3dsurface_get_desc(format);\n\t\tif (unlikely(desc->block_desc == SVGA3DBLOCKDESC_NONE)) {\n\t\t\tDRM_ERROR(\"Invalid surface format.\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/* array_size must be null for non-GL3 host. */\n\tif (array_size > 0 && !dev_priv->has_dx) {\n\t\tDRM_ERROR(\"Tried to create DX surface on non-DX host.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tret = ttm_read_lock(&dev_priv->reservation_sem, true);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tret = ttm_mem_global_alloc(vmw_mem_glob(dev_priv),\n\t\t\t\t   user_accounting_size, false, true);\n\tif (unlikely(ret != 0)) {\n\t\tif (ret != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Out of graphics memory for surface\"\n\t\t\t\t  \" creation.\\n\");\n\t\tgoto out_unlock;\n\t}\n\n\tuser_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);\n\tif (unlikely(!user_srf)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_user_srf;\n\t}\n\n\t*srf_out  = &user_srf->srf;\n\tuser_srf->size = user_accounting_size;\n\tuser_srf->prime.base.shareable = false;\n\tuser_srf->prime.base.tfile     = NULL;\n\n\tsrf = &user_srf->srf;\n\tsrf->flags             = svga3d_flags;\n\tsrf->format            = format;\n\tsrf->scanout           = for_scanout;\n\tsrf->mip_levels[0]     = num_mip_levels;\n\tsrf->num_sizes         = 1;\n\tsrf->sizes             = NULL;\n\tsrf->offsets           = NULL;\n\tsrf->base_size         = size;\n\tsrf->autogen_filter    = SVGA3D_TEX_FILTER_NONE;\n\tsrf->array_size        = array_size;\n\tsrf->multisample_count = multisample_count;\n\n\tif (array_size)\n\t\tnum_layers = array_size;\n\telse if (svga3d_flags & SVGA3D_SURFACE_CUBEMAP)\n\t\tnum_layers = SVGA3D_MAX_SURFACE_FACES;\n\telse\n\t\tnum_layers = 1;\n\n\tsrf->res.backup_size   =\n\t\tsvga3dsurface_get_serialized_size(srf->format,\n\t\t\t\t\t\t  srf->base_size,\n\t\t\t\t\t\t  srf->mip_levels[0],\n\t\t\t\t\t\t  num_layers);\n\n\tif (srf->flags & SVGA3D_SURFACE_BIND_STREAM_OUTPUT)\n\t\tsrf->res.backup_size += sizeof(SVGA3dDXSOState);\n\n\tif (dev_priv->active_display_unit == vmw_du_screen_target &&\n\t    for_scanout)\n\t\tsrf->flags |= SVGA3D_SURFACE_SCREENTARGET;\n\n\t/*\n\t * From this point, the generic resource management functions\n\t * destroy the object on failure.\n\t */\n\tret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);\n\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n\nout_no_user_srf:\n\tttm_mem_global_free(vmw_mem_glob(dev_priv), user_accounting_size);\n\nout_unlock:\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n}\n"], "fixing_code": ["/**************************************************************************\n *\n * Copyright \u00a9 2009-2015 VMware, Inc., Palo Alto, CA., USA\n * All Rights Reserved.\n *\n * Permission is hereby granted, free of charge, to any person obtaining a\n * copy of this software and associated documentation files (the\n * \"Software\"), to deal in the Software without restriction, including\n * without limitation the rights to use, copy, modify, merge, publish,\n * distribute, sub license, and/or sell copies of the Software, and to\n * permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice (including the\n * next paragraph) shall be included in all copies or substantial portions\n * of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL\n * THE COPYRIGHT HOLDERS, AUTHORS AND/OR ITS SUPPLIERS BE LIABLE FOR ANY CLAIM,\n * DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n * OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n * USE OR OTHER DEALINGS IN THE SOFTWARE.\n *\n **************************************************************************/\n\n#include \"vmwgfx_drv.h\"\n#include \"vmwgfx_resource_priv.h\"\n#include \"vmwgfx_so.h\"\n#include \"vmwgfx_binding.h\"\n#include <ttm/ttm_placement.h>\n#include \"device_include/svga3d_surfacedefs.h\"\n\n\n/**\n * struct vmw_user_surface - User-space visible surface resource\n *\n * @base:           The TTM base object handling user-space visibility.\n * @srf:            The surface metadata.\n * @size:           TTM accounting size for the surface.\n * @master: master of the creating client. Used for security check.\n */\nstruct vmw_user_surface {\n\tstruct ttm_prime_object prime;\n\tstruct vmw_surface srf;\n\tuint32_t size;\n\tstruct drm_master *master;\n\tstruct ttm_base_object *backup_base;\n};\n\n/**\n * struct vmw_surface_offset - Backing store mip level offset info\n *\n * @face:           Surface face.\n * @mip:            Mip level.\n * @bo_offset:      Offset into backing store of this mip level.\n *\n */\nstruct vmw_surface_offset {\n\tuint32_t face;\n\tuint32_t mip;\n\tuint32_t bo_offset;\n};\n\nstatic void vmw_user_surface_free(struct vmw_resource *res);\nstatic struct vmw_resource *\nvmw_user_surface_base_to_res(struct ttm_base_object *base);\nstatic int vmw_legacy_srf_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf);\nstatic int vmw_legacy_srf_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf);\nstatic int vmw_legacy_srf_create(struct vmw_resource *res);\nstatic int vmw_legacy_srf_destroy(struct vmw_resource *res);\nstatic int vmw_gb_surface_create(struct vmw_resource *res);\nstatic int vmw_gb_surface_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf);\nstatic int vmw_gb_surface_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf);\nstatic int vmw_gb_surface_destroy(struct vmw_resource *res);\n\n\nstatic const struct vmw_user_resource_conv user_surface_conv = {\n\t.object_type = VMW_RES_SURFACE,\n\t.base_obj_to_res = vmw_user_surface_base_to_res,\n\t.res_free = vmw_user_surface_free\n};\n\nconst struct vmw_user_resource_conv *user_surface_converter =\n\t&user_surface_conv;\n\n\nstatic uint64_t vmw_user_surface_size;\n\nstatic const struct vmw_res_func vmw_legacy_surface_func = {\n\t.res_type = vmw_res_surface,\n\t.needs_backup = false,\n\t.may_evict = true,\n\t.type_name = \"legacy surfaces\",\n\t.backup_placement = &vmw_srf_placement,\n\t.create = &vmw_legacy_srf_create,\n\t.destroy = &vmw_legacy_srf_destroy,\n\t.bind = &vmw_legacy_srf_bind,\n\t.unbind = &vmw_legacy_srf_unbind\n};\n\nstatic const struct vmw_res_func vmw_gb_surface_func = {\n\t.res_type = vmw_res_surface,\n\t.needs_backup = true,\n\t.may_evict = true,\n\t.type_name = \"guest backed surfaces\",\n\t.backup_placement = &vmw_mob_placement,\n\t.create = vmw_gb_surface_create,\n\t.destroy = vmw_gb_surface_destroy,\n\t.bind = vmw_gb_surface_bind,\n\t.unbind = vmw_gb_surface_unbind\n};\n\n/**\n * struct vmw_surface_dma - SVGA3D DMA command\n */\nstruct vmw_surface_dma {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdSurfaceDMA body;\n\tSVGA3dCopyBox cb;\n\tSVGA3dCmdSurfaceDMASuffix suffix;\n};\n\n/**\n * struct vmw_surface_define - SVGA3D Surface Define command\n */\nstruct vmw_surface_define {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdDefineSurface body;\n};\n\n/**\n * struct vmw_surface_destroy - SVGA3D Surface Destroy command\n */\nstruct vmw_surface_destroy {\n\tSVGA3dCmdHeader header;\n\tSVGA3dCmdDestroySurface body;\n};\n\n\n/**\n * vmw_surface_dma_size - Compute fifo size for a dma command.\n *\n * @srf: Pointer to a struct vmw_surface\n *\n * Computes the required size for a surface dma command for backup or\n * restoration of the surface represented by @srf.\n */\nstatic inline uint32_t vmw_surface_dma_size(const struct vmw_surface *srf)\n{\n\treturn srf->num_sizes * sizeof(struct vmw_surface_dma);\n}\n\n\n/**\n * vmw_surface_define_size - Compute fifo size for a surface define command.\n *\n * @srf: Pointer to a struct vmw_surface\n *\n * Computes the required size for a surface define command for the definition\n * of the surface represented by @srf.\n */\nstatic inline uint32_t vmw_surface_define_size(const struct vmw_surface *srf)\n{\n\treturn sizeof(struct vmw_surface_define) + srf->num_sizes *\n\t\tsizeof(SVGA3dSize);\n}\n\n\n/**\n * vmw_surface_destroy_size - Compute fifo size for a surface destroy command.\n *\n * Computes the required size for a surface destroy command for the destruction\n * of a hw surface.\n */\nstatic inline uint32_t vmw_surface_destroy_size(void)\n{\n\treturn sizeof(struct vmw_surface_destroy);\n}\n\n/**\n * vmw_surface_destroy_encode - Encode a surface_destroy command.\n *\n * @id: The surface id\n * @cmd_space: Pointer to memory area in which the commands should be encoded.\n */\nstatic void vmw_surface_destroy_encode(uint32_t id,\n\t\t\t\t       void *cmd_space)\n{\n\tstruct vmw_surface_destroy *cmd = (struct vmw_surface_destroy *)\n\t\tcmd_space;\n\n\tcmd->header.id = SVGA_3D_CMD_SURFACE_DESTROY;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.sid = id;\n}\n\n/**\n * vmw_surface_define_encode - Encode a surface_define command.\n *\n * @srf: Pointer to a struct vmw_surface object.\n * @cmd_space: Pointer to memory area in which the commands should be encoded.\n */\nstatic void vmw_surface_define_encode(const struct vmw_surface *srf,\n\t\t\t\t      void *cmd_space)\n{\n\tstruct vmw_surface_define *cmd = (struct vmw_surface_define *)\n\t\tcmd_space;\n\tstruct drm_vmw_size *src_size;\n\tSVGA3dSize *cmd_size;\n\tuint32_t cmd_len;\n\tint i;\n\n\tcmd_len = sizeof(cmd->body) + srf->num_sizes * sizeof(SVGA3dSize);\n\n\tcmd->header.id = SVGA_3D_CMD_SURFACE_DEFINE;\n\tcmd->header.size = cmd_len;\n\tcmd->body.sid = srf->res.id;\n\tcmd->body.surfaceFlags = srf->flags;\n\tcmd->body.format = srf->format;\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i)\n\t\tcmd->body.face[i].numMipLevels = srf->mip_levels[i];\n\n\tcmd += 1;\n\tcmd_size = (SVGA3dSize *) cmd;\n\tsrc_size = srf->sizes;\n\n\tfor (i = 0; i < srf->num_sizes; ++i, cmd_size++, src_size++) {\n\t\tcmd_size->width = src_size->width;\n\t\tcmd_size->height = src_size->height;\n\t\tcmd_size->depth = src_size->depth;\n\t}\n}\n\n/**\n * vmw_surface_dma_encode - Encode a surface_dma command.\n *\n * @srf: Pointer to a struct vmw_surface object.\n * @cmd_space: Pointer to memory area in which the commands should be encoded.\n * @ptr: Pointer to an SVGAGuestPtr indicating where the surface contents\n * should be placed or read from.\n * @to_surface: Boolean whether to DMA to the surface or from the surface.\n */\nstatic void vmw_surface_dma_encode(struct vmw_surface *srf,\n\t\t\t\t   void *cmd_space,\n\t\t\t\t   const SVGAGuestPtr *ptr,\n\t\t\t\t   bool to_surface)\n{\n\tuint32_t i;\n\tstruct vmw_surface_dma *cmd = (struct vmw_surface_dma *)cmd_space;\n\tconst struct svga3d_surface_desc *desc =\n\t\tsvga3dsurface_get_desc(srf->format);\n\n\tfor (i = 0; i < srf->num_sizes; ++i) {\n\t\tSVGA3dCmdHeader *header = &cmd->header;\n\t\tSVGA3dCmdSurfaceDMA *body = &cmd->body;\n\t\tSVGA3dCopyBox *cb = &cmd->cb;\n\t\tSVGA3dCmdSurfaceDMASuffix *suffix = &cmd->suffix;\n\t\tconst struct vmw_surface_offset *cur_offset = &srf->offsets[i];\n\t\tconst struct drm_vmw_size *cur_size = &srf->sizes[i];\n\n\t\theader->id = SVGA_3D_CMD_SURFACE_DMA;\n\t\theader->size = sizeof(*body) + sizeof(*cb) + sizeof(*suffix);\n\n\t\tbody->guest.ptr = *ptr;\n\t\tbody->guest.ptr.offset += cur_offset->bo_offset;\n\t\tbody->guest.pitch = svga3dsurface_calculate_pitch(desc,\n\t\t\t\t\t\t\t\t  cur_size);\n\t\tbody->host.sid = srf->res.id;\n\t\tbody->host.face = cur_offset->face;\n\t\tbody->host.mipmap = cur_offset->mip;\n\t\tbody->transfer = ((to_surface) ?  SVGA3D_WRITE_HOST_VRAM :\n\t\t\t\t  SVGA3D_READ_HOST_VRAM);\n\t\tcb->x = 0;\n\t\tcb->y = 0;\n\t\tcb->z = 0;\n\t\tcb->srcx = 0;\n\t\tcb->srcy = 0;\n\t\tcb->srcz = 0;\n\t\tcb->w = cur_size->width;\n\t\tcb->h = cur_size->height;\n\t\tcb->d = cur_size->depth;\n\n\t\tsuffix->suffixSize = sizeof(*suffix);\n\t\tsuffix->maximumOffset =\n\t\t\tsvga3dsurface_get_image_buffer_size(desc, cur_size,\n\t\t\t\t\t\t\t    body->guest.pitch);\n\t\tsuffix->flags.discard = 0;\n\t\tsuffix->flags.unsynchronized = 0;\n\t\tsuffix->flags.reserved = 0;\n\t\t++cmd;\n\t}\n};\n\n\n/**\n * vmw_hw_surface_destroy - destroy a Device surface\n *\n * @res:        Pointer to a struct vmw_resource embedded in a struct\n *              vmw_surface.\n *\n * Destroys a the device surface associated with a struct vmw_surface if\n * any, and adjusts accounting and resource count accordingly.\n */\nstatic void vmw_hw_surface_destroy(struct vmw_resource *res)\n{\n\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf;\n\tvoid *cmd;\n\n\tif (res->func->destroy == vmw_gb_surface_destroy) {\n\t\t(void) vmw_gb_surface_destroy(res);\n\t\treturn;\n\t}\n\n\tif (res->id != -1) {\n\n\t\tcmd = vmw_fifo_reserve(dev_priv, vmw_surface_destroy_size());\n\t\tif (unlikely(!cmd)) {\n\t\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t\t  \"destruction.\\n\");\n\t\t\treturn;\n\t\t}\n\n\t\tvmw_surface_destroy_encode(res->id, cmd);\n\t\tvmw_fifo_commit(dev_priv, vmw_surface_destroy_size());\n\n\t\t/*\n\t\t * used_memory_size_atomic, or separate lock\n\t\t * to avoid taking dev_priv::cmdbuf_mutex in\n\t\t * the destroy path.\n\t\t */\n\n\t\tmutex_lock(&dev_priv->cmdbuf_mutex);\n\t\tsrf = vmw_res_to_srf(res);\n\t\tdev_priv->used_memory_size -= res->backup_size;\n\t\tmutex_unlock(&dev_priv->cmdbuf_mutex);\n\t}\n\tvmw_fifo_resource_dec(dev_priv);\n}\n\n/**\n * vmw_legacy_srf_create - Create a device surface as part of the\n * resource validation process.\n *\n * @res: Pointer to a struct vmw_surface.\n *\n * If the surface doesn't have a hw id.\n *\n * Returns -EBUSY if there wasn't sufficient device resources to\n * complete the validation. Retry after freeing up resources.\n *\n * May return other errors if the kernel is out of guest resources.\n */\nstatic int vmw_legacy_srf_create(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\tint ret;\n\n\tif (likely(res->id != -1))\n\t\treturn 0;\n\n\tsrf = vmw_res_to_srf(res);\n\tif (unlikely(dev_priv->used_memory_size + res->backup_size >=\n\t\t     dev_priv->memory_size))\n\t\treturn -EBUSY;\n\n\t/*\n\t * Alloc id for the resource.\n\t */\n\n\tret = vmw_resource_alloc_id(res);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Failed to allocate a surface id.\\n\");\n\t\tgoto out_no_id;\n\t}\n\n\tif (unlikely(res->id >= SVGA3D_MAX_SURFACE_IDS)) {\n\t\tret = -EBUSY;\n\t\tgoto out_no_fifo;\n\t}\n\n\t/*\n\t * Encode surface define- commands.\n\t */\n\n\tsubmit_size = vmw_surface_define_size(srf);\n\tcmd = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"creation.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_no_fifo;\n\t}\n\n\tvmw_surface_define_encode(srf, cmd);\n\tvmw_fifo_commit(dev_priv, submit_size);\n\t/*\n\t * Surface memory usage accounting.\n\t */\n\n\tdev_priv->used_memory_size += res->backup_size;\n\treturn 0;\n\nout_no_fifo:\n\tvmw_resource_release_id(res);\nout_no_id:\n\treturn ret;\n}\n\n/**\n * vmw_legacy_srf_dma - Copy backup data to or from a legacy surface.\n *\n * @res:            Pointer to a struct vmw_res embedded in a struct\n *                  vmw_surface.\n * @val_buf:        Pointer to a struct ttm_validate_buffer containing\n *                  information about the backup buffer.\n * @bind:           Boolean wether to DMA to the surface.\n *\n * Transfer backup data to or from a legacy surface as part of the\n * validation process.\n * May return other errors if the kernel is out of guest resources.\n * The backup buffer will be fenced or idle upon successful completion,\n * and if the surface needs persistent backup storage, the backup buffer\n * will also be returned reserved iff @bind is true.\n */\nstatic int vmw_legacy_srf_dma(struct vmw_resource *res,\n\t\t\t      struct ttm_validate_buffer *val_buf,\n\t\t\t      bool bind)\n{\n\tSVGAGuestPtr ptr;\n\tstruct vmw_fence_obj *fence;\n\tuint32_t submit_size;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tuint8_t *cmd;\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\n\tBUG_ON(!val_buf->bo);\n\tsubmit_size = vmw_surface_dma_size(srf);\n\tcmd = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"DMA.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\tvmw_bo_get_guest_ptr(val_buf->bo, &ptr);\n\tvmw_surface_dma_encode(srf, cmd, &ptr, bind);\n\n\tvmw_fifo_commit(dev_priv, submit_size);\n\n\t/*\n\t * Create a fence object and fence the backup buffer.\n\t */\n\n\t(void) vmw_execbuf_fence_commands(NULL, dev_priv,\n\t\t\t\t\t  &fence, NULL);\n\n\tvmw_fence_single_bo(val_buf->bo, fence);\n\n\tif (likely(fence != NULL))\n\t\tvmw_fence_obj_unreference(&fence);\n\n\treturn 0;\n}\n\n/**\n * vmw_legacy_srf_bind - Perform a legacy surface bind as part of the\n *                       surface validation process.\n *\n * @res:            Pointer to a struct vmw_res embedded in a struct\n *                  vmw_surface.\n * @val_buf:        Pointer to a struct ttm_validate_buffer containing\n *                  information about the backup buffer.\n *\n * This function will copy backup data to the surface if the\n * backup buffer is dirty.\n */\nstatic int vmw_legacy_srf_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf)\n{\n\tif (!res->backup_dirty)\n\t\treturn 0;\n\n\treturn vmw_legacy_srf_dma(res, val_buf, true);\n}\n\n\n/**\n * vmw_legacy_srf_unbind - Perform a legacy surface unbind as part of the\n *                         surface eviction process.\n *\n * @res:            Pointer to a struct vmw_res embedded in a struct\n *                  vmw_surface.\n * @val_buf:        Pointer to a struct ttm_validate_buffer containing\n *                  information about the backup buffer.\n *\n * This function will copy backup data from the surface.\n */\nstatic int vmw_legacy_srf_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf)\n{\n\tif (unlikely(readback))\n\t\treturn vmw_legacy_srf_dma(res, val_buf, false);\n\treturn 0;\n}\n\n/**\n * vmw_legacy_srf_destroy - Destroy a device surface as part of a\n *                          resource eviction process.\n *\n * @res:            Pointer to a struct vmw_res embedded in a struct\n *                  vmw_surface.\n */\nstatic int vmw_legacy_srf_destroy(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\n\tBUG_ON(res->id == -1);\n\n\t/*\n\t * Encode the dma- and surface destroy commands.\n\t */\n\n\tsubmit_size = vmw_surface_destroy_size();\n\tcmd = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"eviction.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tvmw_surface_destroy_encode(res->id, cmd);\n\tvmw_fifo_commit(dev_priv, submit_size);\n\n\t/*\n\t * Surface memory usage accounting.\n\t */\n\n\tdev_priv->used_memory_size -= res->backup_size;\n\n\t/*\n\t * Release the surface ID.\n\t */\n\n\tvmw_resource_release_id(res);\n\n\treturn 0;\n}\n\n\n/**\n * vmw_surface_init - initialize a struct vmw_surface\n *\n * @dev_priv:       Pointer to a device private struct.\n * @srf:            Pointer to the struct vmw_surface to initialize.\n * @res_free:       Pointer to a resource destructor used to free\n *                  the object.\n */\nstatic int vmw_surface_init(struct vmw_private *dev_priv,\n\t\t\t    struct vmw_surface *srf,\n\t\t\t    void (*res_free) (struct vmw_resource *res))\n{\n\tint ret;\n\tstruct vmw_resource *res = &srf->res;\n\n\tBUG_ON(!res_free);\n\tif (!dev_priv->has_mob)\n\t\tvmw_fifo_resource_inc(dev_priv);\n\tret = vmw_resource_init(dev_priv, res, true, res_free,\n\t\t\t\t(dev_priv->has_mob) ? &vmw_gb_surface_func :\n\t\t\t\t&vmw_legacy_surface_func);\n\n\tif (unlikely(ret != 0)) {\n\t\tif (!dev_priv->has_mob)\n\t\t\tvmw_fifo_resource_dec(dev_priv);\n\t\tres_free(res);\n\t\treturn ret;\n\t}\n\n\t/*\n\t * The surface won't be visible to hardware until a\n\t * surface validate.\n\t */\n\n\tINIT_LIST_HEAD(&srf->view_list);\n\tvmw_resource_activate(res, vmw_hw_surface_destroy);\n\treturn ret;\n}\n\n/**\n * vmw_user_surface_base_to_res - TTM base object to resource converter for\n *                                user visible surfaces\n *\n * @base:           Pointer to a TTM base object\n *\n * Returns the struct vmw_resource embedded in a struct vmw_surface\n * for the user-visible object identified by the TTM base object @base.\n */\nstatic struct vmw_resource *\nvmw_user_surface_base_to_res(struct ttm_base_object *base)\n{\n\treturn &(container_of(base, struct vmw_user_surface,\n\t\t\t      prime.base)->srf.res);\n}\n\n/**\n * vmw_user_surface_free - User visible surface resource destructor\n *\n * @res:            A struct vmw_resource embedded in a struct vmw_surface.\n */\nstatic void vmw_user_surface_free(struct vmw_resource *res)\n{\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tstruct vmw_user_surface *user_srf =\n\t    container_of(srf, struct vmw_user_surface, srf);\n\tstruct vmw_private *dev_priv = srf->res.dev_priv;\n\tuint32_t size = user_srf->size;\n\n\tif (user_srf->master)\n\t\tdrm_master_put(&user_srf->master);\n\tkfree(srf->offsets);\n\tkfree(srf->sizes);\n\tkfree(srf->snooper.image);\n\tttm_prime_object_kfree(user_srf, prime);\n\tttm_mem_global_free(vmw_mem_glob(dev_priv), size);\n}\n\n/**\n * vmw_user_surface_free - User visible surface TTM base object destructor\n *\n * @p_base:         Pointer to a pointer to a TTM base object\n *                  embedded in a struct vmw_user_surface.\n *\n * Drops the base object's reference on its resource, and the\n * pointer pointed to by *p_base is set to NULL.\n */\nstatic void vmw_user_surface_base_release(struct ttm_base_object **p_base)\n{\n\tstruct ttm_base_object *base = *p_base;\n\tstruct vmw_user_surface *user_srf =\n\t    container_of(base, struct vmw_user_surface, prime.base);\n\tstruct vmw_resource *res = &user_srf->srf.res;\n\n\t*p_base = NULL;\n\tif (user_srf->backup_base)\n\t\tttm_base_object_unref(&user_srf->backup_base);\n\tvmw_resource_unreference(&res);\n}\n\n/**\n * vmw_user_surface_destroy_ioctl - Ioctl function implementing\n *                                  the user surface destroy functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_surface_destroy_ioctl(struct drm_device *dev, void *data,\n\t\t\t      struct drm_file *file_priv)\n{\n\tstruct drm_vmw_surface_arg *arg = (struct drm_vmw_surface_arg *)data;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\n\treturn ttm_ref_object_base_unref(tfile, arg->sid, TTM_REF_USAGE);\n}\n\n/**\n * vmw_user_surface_define_ioctl - Ioctl function implementing\n *                                  the user surface define functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_surface_define_ioctl(struct drm_device *dev, void *data,\n\t\t\t     struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tstruct vmw_resource *res;\n\tstruct vmw_resource *tmp;\n\tunion drm_vmw_surface_create_arg *arg =\n\t    (union drm_vmw_surface_create_arg *)data;\n\tstruct drm_vmw_surface_create_req *req = &arg->req;\n\tstruct drm_vmw_surface_arg *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tint ret;\n\tint i, j;\n\tuint32_t cur_bo_offset;\n\tstruct drm_vmw_size *cur_size;\n\tstruct vmw_surface_offset *cur_offset;\n\tuint32_t num_sizes;\n\tuint32_t size;\n\tconst struct svga3d_surface_desc *desc;\n\n\tif (unlikely(vmw_user_surface_size == 0))\n\t\tvmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +\n\t\t\t128;\n\n\tnum_sizes = 0;\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tif (req->mip_levels[i] > DRM_VMW_MAX_MIP_LEVELS)\n\t\t\treturn -EINVAL;\n\t\tnum_sizes += req->mip_levels[i];\n\t}\n\n\tif (num_sizes > DRM_VMW_MAX_SURFACE_FACES * DRM_VMW_MAX_MIP_LEVELS ||\n\t    num_sizes == 0)\n\t\treturn -EINVAL;\n\n\tsize = vmw_user_surface_size + 128 +\n\t\tttm_round_pot(num_sizes * sizeof(struct drm_vmw_size)) +\n\t\tttm_round_pot(num_sizes * sizeof(struct vmw_surface_offset));\n\n\n\tdesc = svga3dsurface_get_desc(req->format);\n\tif (unlikely(desc->block_desc == SVGA3DBLOCKDESC_NONE)) {\n\t\tDRM_ERROR(\"Invalid surface format for surface creation.\\n\");\n\t\tDRM_ERROR(\"Format requested is: %d\\n\", req->format);\n\t\treturn -EINVAL;\n\t}\n\n\tret = ttm_read_lock(&dev_priv->reservation_sem, true);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tret = ttm_mem_global_alloc(vmw_mem_glob(dev_priv),\n\t\t\t\t   size, false, true);\n\tif (unlikely(ret != 0)) {\n\t\tif (ret != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Out of graphics memory for surface\"\n\t\t\t\t  \" creation.\\n\");\n\t\tgoto out_unlock;\n\t}\n\n\tuser_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);\n\tif (unlikely(!user_srf)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_user_srf;\n\t}\n\n\tsrf = &user_srf->srf;\n\tres = &srf->res;\n\n\tsrf->flags = req->flags;\n\tsrf->format = req->format;\n\tsrf->scanout = req->scanout;\n\n\tmemcpy(srf->mip_levels, req->mip_levels, sizeof(srf->mip_levels));\n\tsrf->num_sizes = num_sizes;\n\tuser_srf->size = size;\n\tsrf->sizes = memdup_user((struct drm_vmw_size __user *)(unsigned long)\n\t\t\t\t req->size_addr,\n\t\t\t\t sizeof(*srf->sizes) * srf->num_sizes);\n\tif (IS_ERR(srf->sizes)) {\n\t\tret = PTR_ERR(srf->sizes);\n\t\tgoto out_no_sizes;\n\t}\n\tsrf->offsets = kmalloc_array(srf->num_sizes,\n\t\t\t\t     sizeof(*srf->offsets),\n\t\t\t\t     GFP_KERNEL);\n\tif (unlikely(!srf->offsets)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_offsets;\n\t}\n\n\tsrf->base_size = *srf->sizes;\n\tsrf->autogen_filter = SVGA3D_TEX_FILTER_NONE;\n\tsrf->multisample_count = 0;\n\n\tcur_bo_offset = 0;\n\tcur_offset = srf->offsets;\n\tcur_size = srf->sizes;\n\n\tfor (i = 0; i < DRM_VMW_MAX_SURFACE_FACES; ++i) {\n\t\tfor (j = 0; j < srf->mip_levels[i]; ++j) {\n\t\t\tuint32_t stride = svga3dsurface_calculate_pitch\n\t\t\t\t(desc, cur_size);\n\n\t\t\tcur_offset->face = i;\n\t\t\tcur_offset->mip = j;\n\t\t\tcur_offset->bo_offset = cur_bo_offset;\n\t\t\tcur_bo_offset += svga3dsurface_get_image_buffer_size\n\t\t\t\t(desc, cur_size, stride);\n\t\t\t++cur_offset;\n\t\t\t++cur_size;\n\t\t}\n\t}\n\tres->backup_size = cur_bo_offset;\n\tif (srf->scanout &&\n\t    srf->num_sizes == 1 &&\n\t    srf->sizes[0].width == 64 &&\n\t    srf->sizes[0].height == 64 &&\n\t    srf->format == SVGA3D_A8R8G8B8) {\n\n\t\tsrf->snooper.image = kzalloc(64 * 64 * 4, GFP_KERNEL);\n\t\tif (!srf->snooper.image) {\n\t\t\tDRM_ERROR(\"Failed to allocate cursor_image\\n\");\n\t\t\tret = -ENOMEM;\n\t\t\tgoto out_no_copy;\n\t\t}\n\t} else {\n\t\tsrf->snooper.image = NULL;\n\t}\n\n\tuser_srf->prime.base.shareable = false;\n\tuser_srf->prime.base.tfile = NULL;\n\tif (drm_is_primary_client(file_priv))\n\t\tuser_srf->master = drm_master_get(file_priv->master);\n\n\t/**\n\t * From this point, the generic resource management functions\n\t * destroy the object on failure.\n\t */\n\n\tret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);\n\tif (unlikely(ret != 0))\n\t\tgoto out_unlock;\n\n\t/*\n\t * A gb-aware client referencing a shared surface will\n\t * expect a backup buffer to be present.\n\t */\n\tif (dev_priv->has_mob && req->shareable) {\n\t\tuint32_t backup_handle;\n\n\t\tret = vmw_user_dmabuf_alloc(dev_priv, tfile,\n\t\t\t\t\t    res->backup_size,\n\t\t\t\t\t    true,\n\t\t\t\t\t    &backup_handle,\n\t\t\t\t\t    &res->backup,\n\t\t\t\t\t    &user_srf->backup_base);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tvmw_resource_unreference(&res);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\ttmp = vmw_resource_reference(&srf->res);\n\tret = ttm_prime_object_init(tfile, res->backup_size, &user_srf->prime,\n\t\t\t\t    req->shareable, VMW_RES_SURFACE,\n\t\t\t\t    &vmw_user_surface_base_release, NULL);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&tmp);\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\trep->sid = user_srf->prime.base.hash.key;\n\tvmw_resource_unreference(&res);\n\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn 0;\nout_no_copy:\n\tkfree(srf->offsets);\nout_no_offsets:\n\tkfree(srf->sizes);\nout_no_sizes:\n\tttm_prime_object_kfree(user_srf, prime);\nout_no_user_srf:\n\tttm_mem_global_free(vmw_mem_glob(dev_priv), size);\nout_unlock:\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n}\n\n\nstatic int\nvmw_surface_handle_reference(struct vmw_private *dev_priv,\n\t\t\t     struct drm_file *file_priv,\n\t\t\t     uint32_t u_handle,\n\t\t\t     enum drm_vmw_handle_type handle_type,\n\t\t\t     struct ttm_base_object **base_p)\n{\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_user_surface *user_srf;\n\tuint32_t handle;\n\tstruct ttm_base_object *base;\n\tint ret;\n\tbool require_exist = false;\n\n\tif (handle_type == DRM_VMW_HANDLE_PRIME) {\n\t\tret = ttm_prime_fd_to_handle(tfile, u_handle, &handle);\n\t\tif (unlikely(ret != 0))\n\t\t\treturn ret;\n\t} else {\n\t\tif (unlikely(drm_is_render_client(file_priv)))\n\t\t\trequire_exist = true;\n\n\t\tif (ACCESS_ONCE(vmw_fpriv(file_priv)->locked_master)) {\n\t\t\tDRM_ERROR(\"Locked master refused legacy \"\n\t\t\t\t  \"surface reference.\\n\");\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\thandle = u_handle;\n\t}\n\n\tret = -EINVAL;\n\tbase = ttm_base_object_lookup_for_ref(dev_priv->tdev, handle);\n\tif (unlikely(!base)) {\n\t\tDRM_ERROR(\"Could not find surface to reference.\\n\");\n\t\tgoto out_no_lookup;\n\t}\n\n\tif (unlikely(ttm_base_object_type(base) != VMW_RES_SURFACE)) {\n\t\tDRM_ERROR(\"Referenced object is not a surface.\\n\");\n\t\tgoto out_bad_resource;\n\t}\n\n\tif (handle_type != DRM_VMW_HANDLE_PRIME) {\n\t\tuser_srf = container_of(base, struct vmw_user_surface,\n\t\t\t\t\tprime.base);\n\n\t\t/*\n\t\t * Make sure the surface creator has the same\n\t\t * authenticating master, or is already registered with us.\n\t\t */\n\t\tif (drm_is_primary_client(file_priv) &&\n\t\t    user_srf->master != file_priv->master)\n\t\t\trequire_exist = true;\n\n\t\tret = ttm_ref_object_add(tfile, base, TTM_REF_USAGE, NULL,\n\t\t\t\t\t require_exist);\n\t\tif (unlikely(ret != 0)) {\n\t\t\tDRM_ERROR(\"Could not add a reference to a surface.\\n\");\n\t\t\tgoto out_bad_resource;\n\t\t}\n\t}\n\n\t*base_p = base;\n\treturn 0;\n\nout_bad_resource:\n\tttm_base_object_unref(&base);\nout_no_lookup:\n\tif (handle_type == DRM_VMW_HANDLE_PRIME)\n\t\t(void) ttm_ref_object_base_unref(tfile, handle, TTM_REF_USAGE);\n\n\treturn ret;\n}\n\n/**\n * vmw_user_surface_define_ioctl - Ioctl function implementing\n *                                  the user surface reference functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_surface_reference_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tunion drm_vmw_surface_reference_arg *arg =\n\t    (union drm_vmw_surface_reference_arg *)data;\n\tstruct drm_vmw_surface_arg *req = &arg->req;\n\tstruct drm_vmw_surface_create_req *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_surface *srf;\n\tstruct vmw_user_surface *user_srf;\n\tstruct drm_vmw_size __user *user_sizes;\n\tstruct ttm_base_object *base;\n\tint ret;\n\n\tret = vmw_surface_handle_reference(dev_priv, file_priv, req->sid,\n\t\t\t\t\t   req->handle_type, &base);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tuser_srf = container_of(base, struct vmw_user_surface, prime.base);\n\tsrf = &user_srf->srf;\n\n\trep->flags = srf->flags;\n\trep->format = srf->format;\n\tmemcpy(rep->mip_levels, srf->mip_levels, sizeof(srf->mip_levels));\n\tuser_sizes = (struct drm_vmw_size __user *)(unsigned long)\n\t    rep->size_addr;\n\n\tif (user_sizes)\n\t\tret = copy_to_user(user_sizes, &srf->base_size,\n\t\t\t\t   sizeof(srf->base_size));\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"copy_to_user failed %p %u\\n\",\n\t\t\t  user_sizes, srf->num_sizes);\n\t\tttm_ref_object_base_unref(tfile, base->hash.key, TTM_REF_USAGE);\n\t\tret = -EFAULT;\n\t}\n\n\tttm_base_object_unref(&base);\n\n\treturn ret;\n}\n\n/**\n * vmw_surface_define_encode - Encode a surface_define command.\n *\n * @srf: Pointer to a struct vmw_surface object.\n * @cmd_space: Pointer to memory area in which the commands should be encoded.\n */\nstatic int vmw_gb_surface_create(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tuint32_t cmd_len, cmd_id, submit_len;\n\tint ret;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDefineGBSurface body;\n\t} *cmd;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDefineGBSurface_v2 body;\n\t} *cmd2;\n\n\tif (likely(res->id != -1))\n\t\treturn 0;\n\n\tvmw_fifo_resource_inc(dev_priv);\n\tret = vmw_resource_alloc_id(res);\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Failed to allocate a surface id.\\n\");\n\t\tgoto out_no_id;\n\t}\n\n\tif (unlikely(res->id >= VMWGFX_NUM_GB_SURFACE)) {\n\t\tret = -EBUSY;\n\t\tgoto out_no_fifo;\n\t}\n\n\tif (srf->array_size > 0) {\n\t\t/* has_dx checked on creation time. */\n\t\tcmd_id = SVGA_3D_CMD_DEFINE_GB_SURFACE_V2;\n\t\tcmd_len = sizeof(cmd2->body);\n\t\tsubmit_len = sizeof(*cmd2);\n\t} else {\n\t\tcmd_id = SVGA_3D_CMD_DEFINE_GB_SURFACE;\n\t\tcmd_len = sizeof(cmd->body);\n\t\tsubmit_len = sizeof(*cmd);\n\t}\n\n\tcmd = vmw_fifo_reserve(dev_priv, submit_len);\n\tcmd2 = (typeof(cmd2))cmd;\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"creation.\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out_no_fifo;\n\t}\n\n\tif (srf->array_size > 0) {\n\t\tcmd2->header.id = cmd_id;\n\t\tcmd2->header.size = cmd_len;\n\t\tcmd2->body.sid = srf->res.id;\n\t\tcmd2->body.surfaceFlags = srf->flags;\n\t\tcmd2->body.format = cpu_to_le32(srf->format);\n\t\tcmd2->body.numMipLevels = srf->mip_levels[0];\n\t\tcmd2->body.multisampleCount = srf->multisample_count;\n\t\tcmd2->body.autogenFilter = srf->autogen_filter;\n\t\tcmd2->body.size.width = srf->base_size.width;\n\t\tcmd2->body.size.height = srf->base_size.height;\n\t\tcmd2->body.size.depth = srf->base_size.depth;\n\t\tcmd2->body.arraySize = srf->array_size;\n\t} else {\n\t\tcmd->header.id = cmd_id;\n\t\tcmd->header.size = cmd_len;\n\t\tcmd->body.sid = srf->res.id;\n\t\tcmd->body.surfaceFlags = srf->flags;\n\t\tcmd->body.format = cpu_to_le32(srf->format);\n\t\tcmd->body.numMipLevels = srf->mip_levels[0];\n\t\tcmd->body.multisampleCount = srf->multisample_count;\n\t\tcmd->body.autogenFilter = srf->autogen_filter;\n\t\tcmd->body.size.width = srf->base_size.width;\n\t\tcmd->body.size.height = srf->base_size.height;\n\t\tcmd->body.size.depth = srf->base_size.depth;\n\t}\n\n\tvmw_fifo_commit(dev_priv, submit_len);\n\n\treturn 0;\n\nout_no_fifo:\n\tvmw_resource_release_id(res);\nout_no_id:\n\tvmw_fifo_resource_dec(dev_priv);\n\treturn ret;\n}\n\n\nstatic int vmw_gb_surface_bind(struct vmw_resource *res,\n\t\t\t       struct ttm_validate_buffer *val_buf)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdBindGBSurface body;\n\t} *cmd1;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdUpdateGBSurface body;\n\t} *cmd2;\n\tuint32_t submit_size;\n\tstruct ttm_buffer_object *bo = val_buf->bo;\n\n\tBUG_ON(bo->mem.mem_type != VMW_PL_MOB);\n\n\tsubmit_size = sizeof(*cmd1) + (res->backup_dirty ? sizeof(*cmd2) : 0);\n\n\tcmd1 = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd1)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"binding.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tcmd1->header.id = SVGA_3D_CMD_BIND_GB_SURFACE;\n\tcmd1->header.size = sizeof(cmd1->body);\n\tcmd1->body.sid = res->id;\n\tcmd1->body.mobid = bo->mem.start;\n\tif (res->backup_dirty) {\n\t\tcmd2 = (void *) &cmd1[1];\n\t\tcmd2->header.id = SVGA_3D_CMD_UPDATE_GB_SURFACE;\n\t\tcmd2->header.size = sizeof(cmd2->body);\n\t\tcmd2->body.sid = res->id;\n\t\tres->backup_dirty = false;\n\t}\n\tvmw_fifo_commit(dev_priv, submit_size);\n\n\treturn 0;\n}\n\nstatic int vmw_gb_surface_unbind(struct vmw_resource *res,\n\t\t\t\t bool readback,\n\t\t\t\t struct ttm_validate_buffer *val_buf)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct ttm_buffer_object *bo = val_buf->bo;\n\tstruct vmw_fence_obj *fence;\n\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdReadbackGBSurface body;\n\t} *cmd1;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdInvalidateGBSurface body;\n\t} *cmd2;\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdBindGBSurface body;\n\t} *cmd3;\n\tuint32_t submit_size;\n\tuint8_t *cmd;\n\n\n\tBUG_ON(bo->mem.mem_type != VMW_PL_MOB);\n\n\tsubmit_size = sizeof(*cmd3) + (readback ? sizeof(*cmd1) : sizeof(*cmd2));\n\tcmd = vmw_fifo_reserve(dev_priv, submit_size);\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"unbinding.\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tif (readback) {\n\t\tcmd1 = (void *) cmd;\n\t\tcmd1->header.id = SVGA_3D_CMD_READBACK_GB_SURFACE;\n\t\tcmd1->header.size = sizeof(cmd1->body);\n\t\tcmd1->body.sid = res->id;\n\t\tcmd3 = (void *) &cmd1[1];\n\t} else {\n\t\tcmd2 = (void *) cmd;\n\t\tcmd2->header.id = SVGA_3D_CMD_INVALIDATE_GB_SURFACE;\n\t\tcmd2->header.size = sizeof(cmd2->body);\n\t\tcmd2->body.sid = res->id;\n\t\tcmd3 = (void *) &cmd2[1];\n\t}\n\n\tcmd3->header.id = SVGA_3D_CMD_BIND_GB_SURFACE;\n\tcmd3->header.size = sizeof(cmd3->body);\n\tcmd3->body.sid = res->id;\n\tcmd3->body.mobid = SVGA3D_INVALID_ID;\n\n\tvmw_fifo_commit(dev_priv, submit_size);\n\n\t/*\n\t * Create a fence object and fence the backup buffer.\n\t */\n\n\t(void) vmw_execbuf_fence_commands(NULL, dev_priv,\n\t\t\t\t\t  &fence, NULL);\n\n\tvmw_fence_single_bo(val_buf->bo, fence);\n\n\tif (likely(fence != NULL))\n\t\tvmw_fence_obj_unreference(&fence);\n\n\treturn 0;\n}\n\nstatic int vmw_gb_surface_destroy(struct vmw_resource *res)\n{\n\tstruct vmw_private *dev_priv = res->dev_priv;\n\tstruct vmw_surface *srf = vmw_res_to_srf(res);\n\tstruct {\n\t\tSVGA3dCmdHeader header;\n\t\tSVGA3dCmdDestroyGBSurface body;\n\t} *cmd;\n\n\tif (likely(res->id == -1))\n\t\treturn 0;\n\n\tmutex_lock(&dev_priv->binding_mutex);\n\tvmw_view_surface_list_destroy(dev_priv, &srf->view_list);\n\tvmw_binding_res_list_scrub(&res->binding_head);\n\n\tcmd = vmw_fifo_reserve(dev_priv, sizeof(*cmd));\n\tif (unlikely(!cmd)) {\n\t\tDRM_ERROR(\"Failed reserving FIFO space for surface \"\n\t\t\t  \"destruction.\\n\");\n\t\tmutex_unlock(&dev_priv->binding_mutex);\n\t\treturn -ENOMEM;\n\t}\n\n\tcmd->header.id = SVGA_3D_CMD_DESTROY_GB_SURFACE;\n\tcmd->header.size = sizeof(cmd->body);\n\tcmd->body.sid = res->id;\n\tvmw_fifo_commit(dev_priv, sizeof(*cmd));\n\tmutex_unlock(&dev_priv->binding_mutex);\n\tvmw_resource_release_id(res);\n\tvmw_fifo_resource_dec(dev_priv);\n\n\treturn 0;\n}\n\n\n/**\n * vmw_gb_surface_define_ioctl - Ioctl function implementing\n *                               the user surface define functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_gb_surface_define_ioctl(struct drm_device *dev, void *data,\n\t\t\t\tstruct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tstruct vmw_resource *res;\n\tstruct vmw_resource *tmp;\n\tunion drm_vmw_gb_surface_create_arg *arg =\n\t    (union drm_vmw_gb_surface_create_arg *)data;\n\tstruct drm_vmw_gb_surface_create_req *req = &arg->req;\n\tstruct drm_vmw_gb_surface_create_rep *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tint ret;\n\tuint32_t size;\n\tuint32_t backup_handle = 0;\n\n\tif (req->multisample_count != 0)\n\t\treturn -EINVAL;\n\n\tif (req->mip_levels > DRM_VMW_MAX_MIP_LEVELS)\n\t\treturn -EINVAL;\n\n\tif (unlikely(vmw_user_surface_size == 0))\n\t\tvmw_user_surface_size = ttm_round_pot(sizeof(*user_srf)) +\n\t\t\t128;\n\n\tsize = vmw_user_surface_size + 128;\n\n\t/* Define a surface based on the parameters. */\n\tret = vmw_surface_gb_priv_define(dev,\n\t\t\tsize,\n\t\t\treq->svga3d_flags,\n\t\t\treq->format,\n\t\t\treq->drm_surface_flags & drm_vmw_surface_flag_scanout,\n\t\t\treq->mip_levels,\n\t\t\treq->multisample_count,\n\t\t\treq->array_size,\n\t\t\treq->base_size,\n\t\t\t&srf);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tuser_srf = container_of(srf, struct vmw_user_surface, srf);\n\tif (drm_is_primary_client(file_priv))\n\t\tuser_srf->master = drm_master_get(file_priv->master);\n\n\tret = ttm_read_lock(&dev_priv->reservation_sem, true);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tres = &user_srf->srf.res;\n\n\n\tif (req->buffer_handle != SVGA3D_INVALID_ID) {\n\t\tret = vmw_user_dmabuf_lookup(tfile, req->buffer_handle,\n\t\t\t\t\t     &res->backup,\n\t\t\t\t\t     &user_srf->backup_base);\n\t\tif (ret == 0) {\n\t\t\tif (res->backup->base.num_pages * PAGE_SIZE <\n\t\t\t    res->backup_size) {\n\t\t\t\tDRM_ERROR(\"Surface backup buffer is too small.\\n\");\n\t\t\t\tvmw_dmabuf_unreference(&res->backup);\n\t\t\t\tret = -EINVAL;\n\t\t\t\tgoto out_unlock;\n\t\t\t} else {\n\t\t\t\tbackup_handle = req->buffer_handle;\n\t\t\t}\n\t\t}\n\t} else if (req->drm_surface_flags & drm_vmw_surface_flag_create_buffer)\n\t\tret = vmw_user_dmabuf_alloc(dev_priv, tfile,\n\t\t\t\t\t    res->backup_size,\n\t\t\t\t\t    req->drm_surface_flags &\n\t\t\t\t\t    drm_vmw_surface_flag_shareable,\n\t\t\t\t\t    &backup_handle,\n\t\t\t\t\t    &res->backup,\n\t\t\t\t\t    &user_srf->backup_base);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\ttmp = vmw_resource_reference(res);\n\tret = ttm_prime_object_init(tfile, res->backup_size, &user_srf->prime,\n\t\t\t\t    req->drm_surface_flags &\n\t\t\t\t    drm_vmw_surface_flag_shareable,\n\t\t\t\t    VMW_RES_SURFACE,\n\t\t\t\t    &vmw_user_surface_base_release, NULL);\n\n\tif (unlikely(ret != 0)) {\n\t\tvmw_resource_unreference(&tmp);\n\t\tvmw_resource_unreference(&res);\n\t\tgoto out_unlock;\n\t}\n\n\trep->handle      = user_srf->prime.base.hash.key;\n\trep->backup_size = res->backup_size;\n\tif (res->backup) {\n\t\trep->buffer_map_handle =\n\t\t\tdrm_vma_node_offset_addr(&res->backup->base.vma_node);\n\t\trep->buffer_size = res->backup->base.num_pages * PAGE_SIZE;\n\t\trep->buffer_handle = backup_handle;\n\t} else {\n\t\trep->buffer_map_handle = 0;\n\t\trep->buffer_size = 0;\n\t\trep->buffer_handle = SVGA3D_INVALID_ID;\n\t}\n\n\tvmw_resource_unreference(&res);\n\nout_unlock:\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n}\n\n/**\n * vmw_gb_surface_reference_ioctl - Ioctl function implementing\n *                                  the user surface reference functionality.\n *\n * @dev:            Pointer to a struct drm_device.\n * @data:           Pointer to data copied from / to user-space.\n * @file_priv:      Pointer to a drm file private structure.\n */\nint vmw_gb_surface_reference_ioctl(struct drm_device *dev, void *data,\n\t\t\t\t   struct drm_file *file_priv)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tunion drm_vmw_gb_surface_reference_arg *arg =\n\t    (union drm_vmw_gb_surface_reference_arg *)data;\n\tstruct drm_vmw_surface_arg *req = &arg->req;\n\tstruct drm_vmw_gb_surface_ref_rep *rep = &arg->rep;\n\tstruct ttm_object_file *tfile = vmw_fpriv(file_priv)->tfile;\n\tstruct vmw_surface *srf;\n\tstruct vmw_user_surface *user_srf;\n\tstruct ttm_base_object *base;\n\tuint32_t backup_handle;\n\tint ret = -EINVAL;\n\n\tret = vmw_surface_handle_reference(dev_priv, file_priv, req->sid,\n\t\t\t\t\t   req->handle_type, &base);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tuser_srf = container_of(base, struct vmw_user_surface, prime.base);\n\tsrf = &user_srf->srf;\n\tif (!srf->res.backup) {\n\t\tDRM_ERROR(\"Shared GB surface is missing a backup buffer.\\n\");\n\t\tgoto out_bad_resource;\n\t}\n\n\tmutex_lock(&dev_priv->cmdbuf_mutex); /* Protect res->backup */\n\tret = vmw_user_dmabuf_reference(tfile, srf->res.backup,\n\t\t\t\t\t&backup_handle);\n\tmutex_unlock(&dev_priv->cmdbuf_mutex);\n\n\tif (unlikely(ret != 0)) {\n\t\tDRM_ERROR(\"Could not add a reference to a GB surface \"\n\t\t\t  \"backup buffer.\\n\");\n\t\t(void) ttm_ref_object_base_unref(tfile, base->hash.key,\n\t\t\t\t\t\t TTM_REF_USAGE);\n\t\tgoto out_bad_resource;\n\t}\n\n\trep->creq.svga3d_flags = srf->flags;\n\trep->creq.format = srf->format;\n\trep->creq.mip_levels = srf->mip_levels[0];\n\trep->creq.drm_surface_flags = 0;\n\trep->creq.multisample_count = srf->multisample_count;\n\trep->creq.autogen_filter = srf->autogen_filter;\n\trep->creq.array_size = srf->array_size;\n\trep->creq.buffer_handle = backup_handle;\n\trep->creq.base_size = srf->base_size;\n\trep->crep.handle = user_srf->prime.base.hash.key;\n\trep->crep.backup_size = srf->res.backup_size;\n\trep->crep.buffer_handle = backup_handle;\n\trep->crep.buffer_map_handle =\n\t\tdrm_vma_node_offset_addr(&srf->res.backup->base.vma_node);\n\trep->crep.buffer_size = srf->res.backup->base.num_pages * PAGE_SIZE;\n\nout_bad_resource:\n\tttm_base_object_unref(&base);\n\n\treturn ret;\n}\n\n/**\n * vmw_surface_gb_priv_define - Define a private GB surface\n *\n * @dev:  Pointer to a struct drm_device\n * @user_accounting_size:  Used to track user-space memory usage, set\n *                         to 0 for kernel mode only memory\n * @svga3d_flags: SVGA3d surface flags for the device\n * @format: requested surface format\n * @for_scanout: true if inteded to be used for scanout buffer\n * @num_mip_levels:  number of MIP levels\n * @multisample_count:\n * @array_size: Surface array size.\n * @size: width, heigh, depth of the surface requested\n * @user_srf_out: allocated user_srf.  Set to NULL on failure.\n *\n * GB surfaces allocated by this function will not have a user mode handle, and\n * thus will only be visible to vmwgfx.  For optimization reasons the\n * surface may later be given a user mode handle by another function to make\n * it available to user mode drivers.\n */\nint vmw_surface_gb_priv_define(struct drm_device *dev,\n\t\t\t       uint32_t user_accounting_size,\n\t\t\t       uint32_t svga3d_flags,\n\t\t\t       SVGA3dSurfaceFormat format,\n\t\t\t       bool for_scanout,\n\t\t\t       uint32_t num_mip_levels,\n\t\t\t       uint32_t multisample_count,\n\t\t\t       uint32_t array_size,\n\t\t\t       struct drm_vmw_size size,\n\t\t\t       struct vmw_surface **srf_out)\n{\n\tstruct vmw_private *dev_priv = vmw_priv(dev);\n\tstruct vmw_user_surface *user_srf;\n\tstruct vmw_surface *srf;\n\tint ret;\n\tu32 num_layers;\n\n\t*srf_out = NULL;\n\n\tif (for_scanout) {\n\t\tuint32_t max_width, max_height;\n\n\t\tif (!svga3dsurface_is_screen_target_format(format)) {\n\t\t\tDRM_ERROR(\"Invalid Screen Target surface format.\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tmax_width = min(dev_priv->texture_max_width,\n\t\t\t\tdev_priv->stdu_max_width);\n\t\tmax_height = min(dev_priv->texture_max_height,\n\t\t\t\t dev_priv->stdu_max_height);\n\n\t\tif (size.width > max_width || size.height > max_height) {\n\t\t\tDRM_ERROR(\"%ux%u\\n, exeeds max surface size %ux%u\",\n\t\t\t\t  size.width, size.height,\n\t\t\t\t  max_width, max_height);\n\t\t\treturn -EINVAL;\n\t\t}\n\t} else {\n\t\tconst struct svga3d_surface_desc *desc;\n\n\t\tdesc = svga3dsurface_get_desc(format);\n\t\tif (unlikely(desc->block_desc == SVGA3DBLOCKDESC_NONE)) {\n\t\t\tDRM_ERROR(\"Invalid surface format.\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\t/* array_size must be null for non-GL3 host. */\n\tif (array_size > 0 && !dev_priv->has_dx) {\n\t\tDRM_ERROR(\"Tried to create DX surface on non-DX host.\\n\");\n\t\treturn -EINVAL;\n\t}\n\n\tret = ttm_read_lock(&dev_priv->reservation_sem, true);\n\tif (unlikely(ret != 0))\n\t\treturn ret;\n\n\tret = ttm_mem_global_alloc(vmw_mem_glob(dev_priv),\n\t\t\t\t   user_accounting_size, false, true);\n\tif (unlikely(ret != 0)) {\n\t\tif (ret != -ERESTARTSYS)\n\t\t\tDRM_ERROR(\"Out of graphics memory for surface\"\n\t\t\t\t  \" creation.\\n\");\n\t\tgoto out_unlock;\n\t}\n\n\tuser_srf = kzalloc(sizeof(*user_srf), GFP_KERNEL);\n\tif (unlikely(!user_srf)) {\n\t\tret = -ENOMEM;\n\t\tgoto out_no_user_srf;\n\t}\n\n\t*srf_out  = &user_srf->srf;\n\tuser_srf->size = user_accounting_size;\n\tuser_srf->prime.base.shareable = false;\n\tuser_srf->prime.base.tfile     = NULL;\n\n\tsrf = &user_srf->srf;\n\tsrf->flags             = svga3d_flags;\n\tsrf->format            = format;\n\tsrf->scanout           = for_scanout;\n\tsrf->mip_levels[0]     = num_mip_levels;\n\tsrf->num_sizes         = 1;\n\tsrf->sizes             = NULL;\n\tsrf->offsets           = NULL;\n\tsrf->base_size         = size;\n\tsrf->autogen_filter    = SVGA3D_TEX_FILTER_NONE;\n\tsrf->array_size        = array_size;\n\tsrf->multisample_count = multisample_count;\n\n\tif (array_size)\n\t\tnum_layers = array_size;\n\telse if (svga3d_flags & SVGA3D_SURFACE_CUBEMAP)\n\t\tnum_layers = SVGA3D_MAX_SURFACE_FACES;\n\telse\n\t\tnum_layers = 1;\n\n\tsrf->res.backup_size   =\n\t\tsvga3dsurface_get_serialized_size(srf->format,\n\t\t\t\t\t\t  srf->base_size,\n\t\t\t\t\t\t  srf->mip_levels[0],\n\t\t\t\t\t\t  num_layers);\n\n\tif (srf->flags & SVGA3D_SURFACE_BIND_STREAM_OUTPUT)\n\t\tsrf->res.backup_size += sizeof(SVGA3dDXSOState);\n\n\tif (dev_priv->active_display_unit == vmw_du_screen_target &&\n\t    for_scanout)\n\t\tsrf->flags |= SVGA3D_SURFACE_SCREENTARGET;\n\n\t/*\n\t * From this point, the generic resource management functions\n\t * destroy the object on failure.\n\t */\n\tret = vmw_surface_init(dev_priv, srf, vmw_user_surface_free);\n\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n\nout_no_user_srf:\n\tttm_mem_global_free(vmw_mem_glob(dev_priv), user_accounting_size);\n\nout_unlock:\n\tttm_read_unlock(&dev_priv->reservation_sem);\n\treturn ret;\n}\n"], "filenames": ["drivers/gpu/drm/vmwgfx/vmwgfx_surface.c"], "buggy_code_start_loc": [1277], "buggy_code_end_loc": [1326], "fixing_code_start_loc": [1277], "fixing_code_end_loc": [1330], "type": "CWE-200", "message": "The vmw_gb_surface_define_ioctl function (accessible via DRM_IOCTL_VMW_GB_SURFACE_CREATE) in drivers/gpu/drm/vmwgfx/vmwgfx_surface.c in the Linux kernel through 4.11.4 defines a backup_handle variable but does not give it an initial value. If one attempts to create a GB surface, with a previously allocated DMA buffer to be used as a backup buffer, the backup_handle variable does not get written to and is then later returned to user space, allowing local users to obtain sensitive information from uninitialized kernel memory via a crafted ioctl call.", "other": {"cve": {"id": "CVE-2017-9605", "sourceIdentifier": "cve@mitre.org", "published": "2017-06-13T19:29:00.393", "lastModified": "2017-11-04T01:29:57.133", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The vmw_gb_surface_define_ioctl function (accessible via DRM_IOCTL_VMW_GB_SURFACE_CREATE) in drivers/gpu/drm/vmwgfx/vmwgfx_surface.c in the Linux kernel through 4.11.4 defines a backup_handle variable but does not give it an initial value. If one attempts to create a GB surface, with a previously allocated DMA buffer to be used as a backup buffer, the backup_handle variable does not get written to and is then later returned to user space, allowing local users to obtain sensitive information from uninitialized kernel memory via a crafted ioctl call."}, {"lang": "es", "value": "La funci\u00f3n vmw_gb_surface_define_ioctl (accesible mediante DRM_IOCTL_VMW_GB_SURFACE_CREATE) eb drivers/gpu/drm/vmwgfx/vmwgfx_surface.c en el Kernel de Linux hasta la 4.11.4 define una variable backup_handle pero no da un valor inicial. Si uno intenta crear una superficie GB, con una colocaci\u00f3n previa del buffer DMA va ser usado como un buffer backup, la variable backup_handle no consigue escritura, y despu\u00e9s es devuelto al espacio de usuario, permitiendo a los usuarios locales obtener informaci\u00f3n sensible de la memoria del kernel no inicializada mediante la manipulaci\u00f3n de la llamada ioctl."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:N/A:N", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-200"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.11.4", "matchCriteriaId": "CEAAE4E7-00CF-47FC-8331-A5B82622BB91"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=07678eca2cf9c9a18584e546c2b2a0d0c9a3150c", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://www.debian.org/security/2017/dsa-3927", "source": "cve@mitre.org"}, {"url": "http://www.debian.org/security/2017/dsa-3945", "source": "cve@mitre.org"}, {"url": "http://www.securityfocus.com/bid/99095", "source": "cve@mitre.org", "tags": ["VDB Entry", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/07678eca2cf9c9a18584e546c2b2a0d0c9a3150c", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/07678eca2cf9c9a18584e546c2b2a0d0c9a3150c"}}
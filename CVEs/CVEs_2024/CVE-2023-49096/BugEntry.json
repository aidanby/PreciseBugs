{"buggy_code": ["using System;\nusing System.Collections.Generic;\nusing System.ComponentModel.DataAnnotations;\nusing System.Threading.Tasks;\nusing Jellyfin.Api.Attributes;\nusing Jellyfin.Api.Helpers;\nusing Jellyfin.Api.Models.StreamingDtos;\nusing MediaBrowser.Controller.MediaEncoding;\nusing MediaBrowser.Model.Dlna;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\n\nnamespace Jellyfin.Api.Controllers\n{\n    /// <summary>\n    /// The audio controller.\n    /// </summary>\n    // TODO: In order to authenticate this in the future, Dlna playback will require updating\n    public class AudioController : BaseJellyfinApiController\n    {\n        private readonly AudioHelper _audioHelper;\n\n        private readonly TranscodingJobType _transcodingJobType = TranscodingJobType.Progressive;\n\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"AudioController\"/> class.\n        /// </summary>\n        /// <param name=\"audioHelper\">Instance of <see cref=\"AudioHelper\"/>.</param>\n        public AudioController(AudioHelper audioHelper)\n        {\n            _audioHelper = audioHelper;\n        }\n\n        /// <summary>\n        /// Gets an audio stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The audio container.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"{itemId}/stream\", Name = \"GetAudioStream\")]\n        [HttpHead(\"{itemId}/stream\", Name = \"HeadAudioStream\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesAudioFile]\n        public async Task<ActionResult> GetAudioStream(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] string? container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string>? streamOptions)\n        {\n            StreamingRequestDto streamingRequest = new StreamingRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Static,\n                StreamOptions = streamOptions\n            };\n\n            return await _audioHelper.GetAudioStream(_transcodingJobType, streamingRequest).ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets an audio stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The audio container.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment lenght.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamporphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"{itemId}/stream.{container}\", Name = \"GetAudioStreamByContainer\")]\n        [HttpHead(\"{itemId}/stream.{container}\", Name = \"HeadAudioStreamByContainer\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesAudioFile]\n        public async Task<ActionResult> GetAudioStreamByContainer(\n            [FromRoute, Required] Guid itemId,\n            [FromRoute, Required] string container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string>? streamOptions)\n        {\n            StreamingRequestDto streamingRequest = new StreamingRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Static,\n                StreamOptions = streamOptions\n            };\n\n            return await _audioHelper.GetAudioStream(_transcodingJobType, streamingRequest).ConfigureAwait(false);\n        }\n    }\n}\n", "using System;\nusing System.Collections.Generic;\nusing System.ComponentModel.DataAnnotations;\nusing System.Diagnostics.CodeAnalysis;\nusing System.Globalization;\nusing System.IO;\nusing System.Linq;\nusing System.Text;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing Jellyfin.Api.Attributes;\nusing Jellyfin.Api.Constants;\nusing Jellyfin.Api.Helpers;\nusing Jellyfin.Api.Models.PlaybackDtos;\nusing Jellyfin.Api.Models.StreamingDtos;\nusing Jellyfin.Extensions;\nusing Jellyfin.MediaEncoding.Hls.Playlist;\nusing MediaBrowser.Common.Configuration;\nusing MediaBrowser.Controller.Configuration;\nusing MediaBrowser.Controller.Devices;\nusing MediaBrowser.Controller.Dlna;\nusing MediaBrowser.Controller.Library;\nusing MediaBrowser.Controller.MediaEncoding;\nusing MediaBrowser.Controller.Net;\nusing MediaBrowser.MediaEncoding.Encoder;\nusing MediaBrowser.Model.Configuration;\nusing MediaBrowser.Model.Dlna;\nusing MediaBrowser.Model.IO;\nusing MediaBrowser.Model.Net;\nusing Microsoft.AspNetCore.Authorization;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Logging;\n\nnamespace Jellyfin.Api.Controllers\n{\n    /// <summary>\n    /// Dynamic hls controller.\n    /// </summary>\n    [Route(\"\")]\n    [Authorize(Policy = Policies.DefaultAuthorization)]\n    public class DynamicHlsController : BaseJellyfinApiController\n    {\n        private const string DefaultVodEncoderPreset = \"veryfast\";\n        private const string DefaultEventEncoderPreset = \"superfast\";\n        private const TranscodingJobType TranscodingJobType = MediaBrowser.Controller.MediaEncoding.TranscodingJobType.Hls;\n\n        private readonly ILibraryManager _libraryManager;\n        private readonly IUserManager _userManager;\n        private readonly IDlnaManager _dlnaManager;\n        private readonly IAuthorizationContext _authContext;\n        private readonly IMediaSourceManager _mediaSourceManager;\n        private readonly IServerConfigurationManager _serverConfigurationManager;\n        private readonly IMediaEncoder _mediaEncoder;\n        private readonly IFileSystem _fileSystem;\n        private readonly IDeviceManager _deviceManager;\n        private readonly TranscodingJobHelper _transcodingJobHelper;\n        private readonly ILogger<DynamicHlsController> _logger;\n        private readonly EncodingHelper _encodingHelper;\n        private readonly IDynamicHlsPlaylistGenerator _dynamicHlsPlaylistGenerator;\n        private readonly DynamicHlsHelper _dynamicHlsHelper;\n        private readonly EncodingOptions _encodingOptions;\n\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"DynamicHlsController\"/> class.\n        /// </summary>\n        /// <param name=\"libraryManager\">Instance of the <see cref=\"ILibraryManager\"/> interface.</param>\n        /// <param name=\"userManager\">Instance of the <see cref=\"IUserManager\"/> interface.</param>\n        /// <param name=\"dlnaManager\">Instance of the <see cref=\"IDlnaManager\"/> interface.</param>\n        /// <param name=\"authContext\">Instance of the <see cref=\"IAuthorizationContext\"/> interface.</param>\n        /// <param name=\"mediaSourceManager\">Instance of the <see cref=\"IMediaSourceManager\"/> interface.</param>\n        /// <param name=\"serverConfigurationManager\">Instance of the <see cref=\"IServerConfigurationManager\"/> interface.</param>\n        /// <param name=\"mediaEncoder\">Instance of the <see cref=\"IMediaEncoder\"/> interface.</param>\n        /// <param name=\"fileSystem\">Instance of the <see cref=\"IFileSystem\"/> interface.</param>\n        /// <param name=\"deviceManager\">Instance of the <see cref=\"IDeviceManager\"/> interface.</param>\n        /// <param name=\"transcodingJobHelper\">Instance of the <see cref=\"TranscodingJobHelper\"/> class.</param>\n        /// <param name=\"logger\">Instance of the <see cref=\"ILogger{DynamicHlsController}\"/> interface.</param>\n        /// <param name=\"dynamicHlsHelper\">Instance of <see cref=\"DynamicHlsHelper\"/>.</param>\n        /// <param name=\"encodingHelper\">Instance of <see cref=\"EncodingHelper\"/>.</param>\n        /// <param name=\"dynamicHlsPlaylistGenerator\">Instance of <see cref=\"IDynamicHlsPlaylistGenerator\"/>.</param>\n        public DynamicHlsController(\n            ILibraryManager libraryManager,\n            IUserManager userManager,\n            IDlnaManager dlnaManager,\n            IAuthorizationContext authContext,\n            IMediaSourceManager mediaSourceManager,\n            IServerConfigurationManager serverConfigurationManager,\n            IMediaEncoder mediaEncoder,\n            IFileSystem fileSystem,\n            IDeviceManager deviceManager,\n            TranscodingJobHelper transcodingJobHelper,\n            ILogger<DynamicHlsController> logger,\n            DynamicHlsHelper dynamicHlsHelper,\n            EncodingHelper encodingHelper,\n            IDynamicHlsPlaylistGenerator dynamicHlsPlaylistGenerator)\n        {\n            _libraryManager = libraryManager;\n            _userManager = userManager;\n            _dlnaManager = dlnaManager;\n            _authContext = authContext;\n            _mediaSourceManager = mediaSourceManager;\n            _serverConfigurationManager = serverConfigurationManager;\n            _mediaEncoder = mediaEncoder;\n            _fileSystem = fileSystem;\n            _deviceManager = deviceManager;\n            _transcodingJobHelper = transcodingJobHelper;\n            _logger = logger;\n            _dynamicHlsHelper = dynamicHlsHelper;\n            _encodingHelper = encodingHelper;\n            _dynamicHlsPlaylistGenerator = dynamicHlsPlaylistGenerator;\n\n            _encodingOptions = serverConfigurationManager.GetEncodingOptions();\n        }\n\n        /// <summary>\n        /// Gets a hls live stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The audio container.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment lenght.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <param name=\"maxWidth\">Optional. The max width.</param>\n        /// <param name=\"maxHeight\">Optional. The max height.</param>\n        /// <param name=\"enableSubtitlesInManifest\">Optional. Whether to enable subtitles in the manifest.</param>\n        /// <response code=\"200\">Hls live stream retrieved.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the hls file.</returns>\n        [HttpGet(\"Videos/{itemId}/live.m3u8\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetLiveHlsStream(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] string? container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] bool? enableSubtitlesInManifest)\n        {\n            VideoRequestDto streamingRequest = new VideoRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions,\n                MaxHeight = maxHeight,\n                MaxWidth = maxWidth,\n                EnableSubtitlesInManifest = enableSubtitlesInManifest ?? true\n            };\n\n            // CTS lifecycle is managed internally.\n            var cancellationTokenSource = new CancellationTokenSource();\n            // Due to CTS.Token calling ThrowIfDisposed (https://github.com/dotnet/runtime/issues/29970) we have to \"cache\" the token\n            // since it gets disposed when ffmpeg exits\n            var cancellationToken = cancellationTokenSource.Token;\n            var state = await StreamingHelpers.GetStreamingState(\n                    streamingRequest,\n                    Request,\n                    _authContext,\n                    _mediaSourceManager,\n                    _userManager,\n                    _libraryManager,\n                    _serverConfigurationManager,\n                    _mediaEncoder,\n                    _encodingHelper,\n                    _dlnaManager,\n                    _deviceManager,\n                    _transcodingJobHelper,\n                    TranscodingJobType,\n                    cancellationToken)\n                .ConfigureAwait(false);\n\n            TranscodingJobDto? job = null;\n            var playlistPath = Path.ChangeExtension(state.OutputFilePath, \".m3u8\");\n\n            if (!System.IO.File.Exists(playlistPath))\n            {\n                var transcodingLock = _transcodingJobHelper.GetTranscodingLock(playlistPath);\n                await transcodingLock.WaitAsync(cancellationToken).ConfigureAwait(false);\n                try\n                {\n                    if (!System.IO.File.Exists(playlistPath))\n                    {\n                        // If the playlist doesn't already exist, startup ffmpeg\n                        try\n                        {\n                            job = await _transcodingJobHelper.StartFfMpeg(\n                                    state,\n                                    playlistPath,\n                                    GetCommandLineArguments(playlistPath, state, true, 0),\n                                    Request,\n                                    TranscodingJobType,\n                                    cancellationTokenSource)\n                                .ConfigureAwait(false);\n                            job.IsLiveOutput = true;\n                        }\n                        catch\n                        {\n                            state.Dispose();\n                            throw;\n                        }\n\n                        minSegments = state.MinSegments;\n                        if (minSegments > 0)\n                        {\n                            await HlsHelpers.WaitForMinimumSegmentCount(playlistPath, minSegments, _logger, cancellationToken).ConfigureAwait(false);\n                        }\n                    }\n                }\n                finally\n                {\n                    transcodingLock.Release();\n                }\n            }\n\n            job ??= _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n\n            if (job != null)\n            {\n                _transcodingJobHelper.OnTranscodeEndRequest(job);\n            }\n\n            var playlistText = HlsHelpers.GetLivePlaylistText(playlistPath, state);\n\n            return Content(playlistText, MimeTypes.GetMimeType(\"playlist.m3u8\"));\n        }\n\n        /// <summary>\n        /// Gets a video hls playlist stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <param name=\"enableAdaptiveBitrateStreaming\">Enable adaptive bitrate streaming.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the playlist file.</returns>\n        [HttpGet(\"Videos/{itemId}/master.m3u8\")]\n        [HttpHead(\"Videos/{itemId}/master.m3u8\", Name = \"HeadMasterHlsVideoPlaylist\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetMasterHlsVideoPlaylist(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery, Required] string mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions,\n            [FromQuery] bool enableAdaptiveBitrateStreaming = true)\n        {\n            var streamingRequest = new HlsVideoRequestDto\n            {\n                Id = itemId,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                MaxWidth = maxWidth,\n                MaxHeight = maxHeight,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions,\n                EnableAdaptiveBitrateStreaming = enableAdaptiveBitrateStreaming\n            };\n\n            return await _dynamicHlsHelper.GetMasterHlsPlaylist(TranscodingJobType, streamingRequest, enableAdaptiveBitrateStreaming).ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets an audio hls playlist stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"maxStreamingBitrate\">Optional. The maximum streaming bitrate.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <param name=\"enableAdaptiveBitrateStreaming\">Enable adaptive bitrate streaming.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the playlist file.</returns>\n        [HttpGet(\"Audio/{itemId}/master.m3u8\")]\n        [HttpHead(\"Audio/{itemId}/master.m3u8\", Name = \"HeadMasterHlsAudioPlaylist\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetMasterHlsAudioPlaylist(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery, Required] string mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? maxStreamingBitrate,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions,\n            [FromQuery] bool enableAdaptiveBitrateStreaming = true)\n        {\n            var streamingRequest = new HlsAudioRequestDto\n            {\n                Id = itemId,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate ?? maxStreamingBitrate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions,\n                EnableAdaptiveBitrateStreaming = enableAdaptiveBitrateStreaming\n            };\n\n            return await _dynamicHlsHelper.GetMasterHlsPlaylist(TranscodingJobType, streamingRequest, enableAdaptiveBitrateStreaming).ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets a video stream using HTTP live streaming.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"Videos/{itemId}/main.m3u8\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetVariantHlsVideoPlaylist(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            using var cancellationTokenSource = new CancellationTokenSource();\n            var streamingRequest = new VideoRequestDto\n            {\n                Id = itemId,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                MaxWidth = maxWidth,\n                MaxHeight = maxHeight,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            return await GetVariantPlaylistInternal(streamingRequest, cancellationTokenSource)\n                .ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets an audio stream using HTTP live streaming.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"maxStreamingBitrate\">Optional. The maximum streaming bitrate.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vpx, wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"Audio/{itemId}/main.m3u8\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetVariantHlsAudioPlaylist(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? maxStreamingBitrate,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            using var cancellationTokenSource = new CancellationTokenSource();\n            var streamingRequest = new StreamingRequestDto\n            {\n                Id = itemId,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate ?? maxStreamingBitrate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            return await GetVariantPlaylistInternal(streamingRequest, cancellationTokenSource)\n                .ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets a video stream using HTTP live streaming.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"playlistId\">The playlist id.</param>\n        /// <param name=\"segmentId\">The segment id.</param>\n        /// <param name=\"container\">The video container. Possible values are: ts, webm, asf, wmv, ogv, mp4, m4v, mkv, mpeg, mpg, avi, 3gp, wmv, wtv, m2ts, mov, iso, flv. </param>\n        /// <param name=\"runtimeTicks\">The position of the requested segment in ticks.</param>\n        /// <param name=\"actualSegmentLengthTicks\">The length of the requested segment in ticks.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The desired segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"Videos/{itemId}/hls1/{playlistId}/{segmentId}.{container}\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesVideoFile]\n        [SuppressMessage(\"Microsoft.Performance\", \"CA1801:ReviewUnusedParameters\", MessageId = \"playlistId\", Justification = \"Imported from ServiceStack\")]\n        public async Task<ActionResult> GetHlsVideoSegment(\n            [FromRoute, Required] Guid itemId,\n            [FromRoute, Required] string playlistId,\n            [FromRoute, Required] int segmentId,\n            [FromRoute, Required] string container,\n            [FromQuery, Required] long runtimeTicks,\n            [FromQuery, Required] long actualSegmentLengthTicks,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            var streamingRequest = new VideoRequestDto\n            {\n                Id = itemId,\n                CurrentRuntimeTicks = runtimeTicks,\n                ActualSegmentLengthTicks = actualSegmentLengthTicks,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                MaxWidth = maxWidth,\n                MaxHeight = maxHeight,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            return await GetDynamicSegment(streamingRequest, segmentId)\n                .ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets a video stream using HTTP live streaming.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"playlistId\">The playlist id.</param>\n        /// <param name=\"segmentId\">The segment id.</param>\n        /// <param name=\"container\">The video container. Possible values are: ts, webm, asf, wmv, ogv, mp4, m4v, mkv, mpeg, mpg, avi, 3gp, wmv, wtv, m2ts, mov, iso, flv. </param>\n        /// <param name=\"runtimeTicks\">The position of the requested segment in ticks.</param>\n        /// <param name=\"actualSegmentLengthTicks\">The length of the requested segment in ticks.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"maxStreamingBitrate\">Optional. The maximum streaming bitrate.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vpx, wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"Audio/{itemId}/hls1/{playlistId}/{segmentId}.{container}\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesAudioFile]\n        [SuppressMessage(\"Microsoft.Performance\", \"CA1801:ReviewUnusedParameters\", MessageId = \"playlistId\", Justification = \"Imported from ServiceStack\")]\n        public async Task<ActionResult> GetHlsAudioSegment(\n            [FromRoute, Required] Guid itemId,\n            [FromRoute, Required] string playlistId,\n            [FromRoute, Required] int segmentId,\n            [FromRoute, Required] string container,\n            [FromQuery, Required] long runtimeTicks,\n            [FromQuery, Required] long actualSegmentLengthTicks,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? maxStreamingBitrate,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            var streamingRequest = new StreamingRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                CurrentRuntimeTicks = runtimeTicks,\n                ActualSegmentLengthTicks = actualSegmentLengthTicks,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate ?? maxStreamingBitrate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            return await GetDynamicSegment(streamingRequest, segmentId)\n                .ConfigureAwait(false);\n        }\n\n        private async Task<ActionResult> GetVariantPlaylistInternal(StreamingRequestDto streamingRequest, CancellationTokenSource cancellationTokenSource)\n        {\n            using var state = await StreamingHelpers.GetStreamingState(\n                    streamingRequest,\n                    Request,\n                    _authContext,\n                    _mediaSourceManager,\n                    _userManager,\n                    _libraryManager,\n                    _serverConfigurationManager,\n                    _mediaEncoder,\n                    _encodingHelper,\n                    _dlnaManager,\n                    _deviceManager,\n                    _transcodingJobHelper,\n                    TranscodingJobType,\n                    cancellationTokenSource.Token)\n                .ConfigureAwait(false);\n\n            var request = new CreateMainPlaylistRequest(\n                state.MediaPath,\n                state.SegmentLength * 1000,\n                state.RunTimeTicks ?? 0,\n                state.Request.SegmentContainer ?? string.Empty,\n                \"hls1/main/\",\n                Request.QueryString.ToString(),\n                EncodingHelper.IsCopyCodec(state.OutputVideoCodec));\n            var playlist = _dynamicHlsPlaylistGenerator.CreateMainPlaylist(request);\n\n            return new FileContentResult(Encoding.UTF8.GetBytes(playlist), MimeTypes.GetMimeType(\"playlist.m3u8\"));\n        }\n\n        private async Task<ActionResult> GetDynamicSegment(StreamingRequestDto streamingRequest, int segmentId)\n        {\n            if ((streamingRequest.StartTimeTicks ?? 0) > 0)\n            {\n                throw new ArgumentException(\"StartTimeTicks is not allowed.\");\n            }\n\n            // CTS lifecycle is managed internally.\n            var cancellationTokenSource = new CancellationTokenSource();\n            var cancellationToken = cancellationTokenSource.Token;\n\n            var state = await StreamingHelpers.GetStreamingState(\n                    streamingRequest,\n                    Request,\n                    _authContext,\n                    _mediaSourceManager,\n                    _userManager,\n                    _libraryManager,\n                    _serverConfigurationManager,\n                    _mediaEncoder,\n                    _encodingHelper,\n                    _dlnaManager,\n                    _deviceManager,\n                    _transcodingJobHelper,\n                    TranscodingJobType,\n                    cancellationToken)\n                .ConfigureAwait(false);\n\n            var playlistPath = Path.ChangeExtension(state.OutputFilePath, \".m3u8\");\n\n            var segmentPath = GetSegmentPath(state, playlistPath, segmentId);\n\n            var segmentExtension = EncodingHelper.GetSegmentFileExtension(state.Request.SegmentContainer);\n\n            TranscodingJobDto? job;\n\n            if (System.IO.File.Exists(segmentPath))\n            {\n                job = _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n                _logger.LogDebug(\"returning {0} [it exists, try 1]\", segmentPath);\n                return await GetSegmentResult(state, playlistPath, segmentPath, segmentExtension, segmentId, job, cancellationToken).ConfigureAwait(false);\n            }\n\n            var transcodingLock = _transcodingJobHelper.GetTranscodingLock(playlistPath);\n            await transcodingLock.WaitAsync(cancellationToken).ConfigureAwait(false);\n            var released = false;\n            var startTranscoding = false;\n\n            try\n            {\n                if (System.IO.File.Exists(segmentPath))\n                {\n                    job = _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n                    transcodingLock.Release();\n                    released = true;\n                    _logger.LogDebug(\"returning {0} [it exists, try 2]\", segmentPath);\n                    return await GetSegmentResult(state, playlistPath, segmentPath, segmentExtension, segmentId, job, cancellationToken).ConfigureAwait(false);\n                }\n                else\n                {\n                    var currentTranscodingIndex = GetCurrentTranscodingIndex(playlistPath, segmentExtension);\n                    var segmentGapRequiringTranscodingChange = 24 / state.SegmentLength;\n\n                    if (segmentId == -1)\n                    {\n                        _logger.LogDebug(\"Starting transcoding because fmp4 init file is being requested\");\n                        startTranscoding = true;\n                        segmentId = 0;\n                    }\n                    else if (currentTranscodingIndex == null)\n                    {\n                        _logger.LogDebug(\"Starting transcoding because currentTranscodingIndex=null\");\n                        startTranscoding = true;\n                    }\n                    else if (segmentId < currentTranscodingIndex.Value)\n                    {\n                        _logger.LogDebug(\"Starting transcoding because requestedIndex={0} and currentTranscodingIndex={1}\", segmentId, currentTranscodingIndex);\n                        startTranscoding = true;\n                    }\n                    else if (segmentId - currentTranscodingIndex.Value > segmentGapRequiringTranscodingChange)\n                    {\n                        _logger.LogDebug(\"Starting transcoding because segmentGap is {0} and max allowed gap is {1}. requestedIndex={2}\", segmentId - currentTranscodingIndex.Value, segmentGapRequiringTranscodingChange, segmentId);\n                        startTranscoding = true;\n                    }\n\n                    if (startTranscoding)\n                    {\n                        // If the playlist doesn't already exist, startup ffmpeg\n                        try\n                        {\n                            await _transcodingJobHelper.KillTranscodingJobs(streamingRequest.DeviceId, streamingRequest.PlaySessionId, p => false)\n                                .ConfigureAwait(false);\n\n                            if (currentTranscodingIndex.HasValue)\n                            {\n                                DeleteLastFile(playlistPath, segmentExtension, 0);\n                            }\n\n                            streamingRequest.StartTimeTicks = streamingRequest.CurrentRuntimeTicks;\n\n                            state.WaitForPath = segmentPath;\n                            job = await _transcodingJobHelper.StartFfMpeg(\n                                state,\n                                playlistPath,\n                                GetCommandLineArguments(playlistPath, state, false, segmentId),\n                                Request,\n                                TranscodingJobType,\n                                cancellationTokenSource).ConfigureAwait(false);\n                        }\n                        catch\n                        {\n                            state.Dispose();\n                            throw;\n                        }\n\n                        // await WaitForMinimumSegmentCount(playlistPath, 1, cancellationTokenSource.Token).ConfigureAwait(false);\n                    }\n                    else\n                    {\n                        job = _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n                        if (job?.TranscodingThrottler != null)\n                        {\n                            await job.TranscodingThrottler.UnpauseTranscoding().ConfigureAwait(false);\n                        }\n                    }\n                }\n            }\n            finally\n            {\n                if (!released)\n                {\n                    transcodingLock.Release();\n                }\n            }\n\n            _logger.LogDebug(\"returning {0} [general case]\", segmentPath);\n            job ??= _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n            return await GetSegmentResult(state, playlistPath, segmentPath, segmentExtension, segmentId, job, cancellationToken).ConfigureAwait(false);\n        }\n\n        private static double[] GetSegmentLengths(StreamState state)\n            => GetSegmentLengthsInternal(state.RunTimeTicks ?? 0, state.SegmentLength);\n\n        internal static double[] GetSegmentLengthsInternal(long runtimeTicks, int segmentlength)\n        {\n            var segmentLengthTicks = TimeSpan.FromSeconds(segmentlength).Ticks;\n            var wholeSegments = runtimeTicks / segmentLengthTicks;\n            var remainingTicks = runtimeTicks % segmentLengthTicks;\n\n            var segmentsLen = wholeSegments + (remainingTicks == 0 ? 0 : 1);\n            var segments = new double[segmentsLen];\n            for (int i = 0; i < wholeSegments; i++)\n            {\n                segments[i] = segmentlength;\n            }\n\n            if (remainingTicks != 0)\n            {\n                segments[^1] = TimeSpan.FromTicks(remainingTicks).TotalSeconds;\n            }\n\n            return segments;\n        }\n\n        private string GetCommandLineArguments(string outputPath, StreamState state, bool isEventPlaylist, int startNumber)\n        {\n            var videoCodec = _encodingHelper.GetVideoEncoder(state, _encodingOptions);\n            var threads = EncodingHelper.GetNumberOfThreads(state, _encodingOptions, videoCodec);\n\n            if (state.BaseRequest.BreakOnNonKeyFrames)\n            {\n                // FIXME: this is actually a workaround, as ideally it really should be the client which decides whether non-keyframe\n                //        breakpoints are supported; but current implementation always uses \"ffmpeg input seeking\" which is liable\n                //        to produce a missing part of video stream before first keyframe is encountered, which may lead to\n                //        awkward cases like a few starting HLS segments having no video whatsoever, which breaks hls.js\n                _logger.LogInformation(\"Current HLS implementation doesn't support non-keyframe breaks but one is requested, ignoring that request\");\n                state.BaseRequest.BreakOnNonKeyFrames = false;\n            }\n\n            var mapArgs = state.IsOutputVideo ? _encodingHelper.GetMapArgs(state) : string.Empty;\n\n            var directory = Path.GetDirectoryName(outputPath) ?? throw new ArgumentException($\"Provided path ({outputPath}) is not valid.\", nameof(outputPath));\n            var outputFileNameWithoutExtension = Path.GetFileNameWithoutExtension(outputPath);\n            var outputPrefix = Path.Combine(directory, outputFileNameWithoutExtension);\n            var outputExtension = EncodingHelper.GetSegmentFileExtension(state.Request.SegmentContainer);\n            var outputTsArg = outputPrefix + \"%d\" + outputExtension;\n\n            var segmentFormat = string.Empty;\n            var segmentContainer = outputExtension.TrimStart('.');\n            var inputModifier = _encodingHelper.GetInputModifier(state, _encodingOptions, segmentContainer);\n\n            if (string.Equals(segmentContainer, \"ts\", StringComparison.OrdinalIgnoreCase))\n            {\n                segmentFormat = \"mpegts\";\n            }\n            else if (string.Equals(segmentContainer, \"mp4\", StringComparison.OrdinalIgnoreCase))\n            {\n                var outputFmp4HeaderArg = OperatingSystem.IsWindows() switch\n                {\n                    // on Windows, the path of fmp4 header file needs to be configured\n                    true => \" -hls_fmp4_init_filename \\\"\" + outputPrefix + \"-1\" + outputExtension + \"\\\"\",\n                    // on Linux/Unix, ffmpeg generate fmp4 header file to m3u8 output folder\n                    false => \" -hls_fmp4_init_filename \\\"\" + outputFileNameWithoutExtension + \"-1\" + outputExtension + \"\\\"\"\n                };\n\n                segmentFormat = \"fmp4\" + outputFmp4HeaderArg;\n            }\n            else\n            {\n                _logger.LogError(\"Invalid HLS segment container: {SegmentContainer}, default to mpegts\", segmentContainer);\n                segmentFormat = \"mpegts\";\n            }\n\n            var maxMuxingQueueSize = _encodingOptions.MaxMuxingQueueSize > 128\n                ? _encodingOptions.MaxMuxingQueueSize.ToString(CultureInfo.InvariantCulture)\n                : \"128\";\n\n            var baseUrlParam = string.Empty;\n            if (isEventPlaylist)\n            {\n                baseUrlParam = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -hls_base_url \\\"hls/{0}/\\\"\",\n                    Path.GetFileNameWithoutExtension(outputPath));\n            }\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"{0} {1} -map_metadata -1 -map_chapters -1 -threads {2} {3} {4} {5} -copyts -avoid_negative_ts disabled -max_muxing_queue_size {6} -f hls -max_delay 5000000 -hls_time {7} -hls_segment_type {8} -start_number {9}{10} -hls_segment_filename \\\"{12}\\\" -hls_playlist_type {11} -hls_list_size 0 -y \\\"{13}\\\"\",\n                inputModifier,\n                _encodingHelper.GetInputArgument(state, _encodingOptions, segmentContainer),\n                threads,\n                mapArgs,\n                GetVideoArguments(state, startNumber, isEventPlaylist),\n                GetAudioArguments(state),\n                maxMuxingQueueSize,\n                state.SegmentLength.ToString(CultureInfo.InvariantCulture),\n                segmentFormat,\n                startNumber.ToString(CultureInfo.InvariantCulture),\n                baseUrlParam,\n                isEventPlaylist ? \"event\" : \"vod\",\n                EncodingUtils.NormalizePath(outputTsArg),\n                EncodingUtils.NormalizePath(outputPath)).Trim();\n        }\n\n        /// <summary>\n        /// Gets the audio arguments for transcoding.\n        /// </summary>\n        /// <param name=\"state\">The <see cref=\"StreamState\"/>.</param>\n        /// <returns>The command line arguments for audio transcoding.</returns>\n        private string GetAudioArguments(StreamState state)\n        {\n            if (state.AudioStream == null)\n            {\n                return string.Empty;\n            }\n\n            var audioCodec = _encodingHelper.GetAudioEncoder(state);\n\n            if (!state.IsOutputVideo)\n            {\n                if (EncodingHelper.IsCopyCodec(audioCodec))\n                {\n                    var bitStreamArgs = EncodingHelper.GetAudioBitStreamArguments(state, state.Request.SegmentContainer, state.MediaSource.Container);\n\n                    return \"-acodec copy -strict -2\" + bitStreamArgs;\n                }\n\n                var audioTranscodeParams = string.Empty;\n\n                audioTranscodeParams += \"-acodec \" + audioCodec;\n\n                if (state.OutputAudioBitrate.HasValue && !EncodingHelper.LosslessAudioCodecs.Contains(state.ActualOutputAudioCodec, StringComparison.OrdinalIgnoreCase))\n                {\n                    audioTranscodeParams += \" -ab \" + state.OutputAudioBitrate.Value.ToString(CultureInfo.InvariantCulture);\n                }\n\n                if (state.OutputAudioChannels.HasValue)\n                {\n                    audioTranscodeParams += \" -ac \" + state.OutputAudioChannels.Value.ToString(CultureInfo.InvariantCulture);\n                }\n\n                if (state.OutputAudioSampleRate.HasValue)\n                {\n                    audioTranscodeParams += \" -ar \" + state.OutputAudioSampleRate.Value.ToString(CultureInfo.InvariantCulture);\n                }\n\n                audioTranscodeParams += \" -vn\";\n                return audioTranscodeParams;\n            }\n\n            // dts, flac, opus and truehd are experimental in mp4 muxer\n            var strictArgs = string.Empty;\n            var actualOutputAudioCodec = state.ActualOutputAudioCodec;\n            if (string.Equals(actualOutputAudioCodec, \"flac\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(actualOutputAudioCodec, \"opus\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(actualOutputAudioCodec, \"dts\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(actualOutputAudioCodec, \"truehd\", StringComparison.OrdinalIgnoreCase))\n            {\n                strictArgs = \" -strict -2\";\n            }\n\n            if (EncodingHelper.IsCopyCodec(audioCodec))\n            {\n                var videoCodec = _encodingHelper.GetVideoEncoder(state, _encodingOptions);\n                var bitStreamArgs = EncodingHelper.GetAudioBitStreamArguments(state, state.Request.SegmentContainer, state.MediaSource.Container);\n                var copyArgs = \"-codec:a:0 copy\" + bitStreamArgs + strictArgs;\n\n                if (EncodingHelper.IsCopyCodec(videoCodec) && state.EnableBreakOnNonKeyFrames(videoCodec))\n                {\n                    return copyArgs + \" -copypriorss:a:0 0\";\n                }\n\n                return copyArgs;\n            }\n\n            var args = \"-codec:a:0 \" + audioCodec + strictArgs;\n\n            var channels = state.OutputAudioChannels;\n\n            if (channels.HasValue)\n            {\n                args += \" -ac \" + channels.Value;\n            }\n\n            var bitrate = state.OutputAudioBitrate;\n            if (bitrate.HasValue && !EncodingHelper.LosslessAudioCodecs.Contains(actualOutputAudioCodec, StringComparison.OrdinalIgnoreCase))\n            {\n                args += \" -ab \" + bitrate.Value.ToString(CultureInfo.InvariantCulture);\n            }\n\n            if (state.OutputAudioSampleRate.HasValue)\n            {\n                args += \" -ar \" + state.OutputAudioSampleRate.Value.ToString(CultureInfo.InvariantCulture);\n            }\n\n            args += _encodingHelper.GetAudioFilterParam(state, _encodingOptions);\n\n            return args;\n        }\n\n        /// <summary>\n        /// Gets the video arguments for transcoding.\n        /// </summary>\n        /// <param name=\"state\">The <see cref=\"StreamState\"/>.</param>\n        /// <param name=\"startNumber\">The first number in the hls sequence.</param>\n        /// <param name=\"isEventPlaylist\">Whether the playlist is EVENT or VOD.</param>\n        /// <returns>The command line arguments for video transcoding.</returns>\n        private string GetVideoArguments(StreamState state, int startNumber, bool isEventPlaylist)\n        {\n            if (state.VideoStream == null)\n            {\n                return string.Empty;\n            }\n\n            if (!state.IsOutputVideo)\n            {\n                return string.Empty;\n            }\n\n            var codec = _encodingHelper.GetVideoEncoder(state, _encodingOptions);\n\n            var args = \"-codec:v:0 \" + codec;\n\n            if (string.Equals(state.ActualOutputVideoCodec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(state.ActualOutputVideoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (EncodingHelper.IsCopyCodec(codec)\n                    && (string.Equals(state.VideoStream.VideoRangeType, \"DOVI\", StringComparison.OrdinalIgnoreCase)\n                        || string.Equals(state.VideoStream.CodecTag, \"dovi\", StringComparison.OrdinalIgnoreCase)\n                        || string.Equals(state.VideoStream.CodecTag, \"dvh1\", StringComparison.OrdinalIgnoreCase)\n                        || string.Equals(state.VideoStream.CodecTag, \"dvhe\", StringComparison.OrdinalIgnoreCase)))\n                {\n                    // Prefer dvh1 to dvhe\n                    args += \" -tag:v:0 dvh1 -strict -2\";\n                }\n                else\n                {\n                    // Prefer hvc1 to hev1\n                    args += \" -tag:v:0 hvc1\";\n                }\n            }\n\n            // if  (state.EnableMpegtsM2TsMode)\n            // {\n            //     args += \" -mpegts_m2ts_mode 1\";\n            // }\n\n            // See if we can save come cpu cycles by avoiding encoding.\n            if (EncodingHelper.IsCopyCodec(codec))\n            {\n                // If h264_mp4toannexb is ever added, do not use it for live tv.\n                if (state.VideoStream != null && !string.Equals(state.VideoStream.NalLengthSize, \"0\", StringComparison.OrdinalIgnoreCase))\n                {\n                    string bitStreamArgs = EncodingHelper.GetBitStreamArgs(state.VideoStream);\n                    if (!string.IsNullOrEmpty(bitStreamArgs))\n                    {\n                        args += \" \" + bitStreamArgs;\n                    }\n                }\n\n                args += \" -start_at_zero\";\n            }\n            else\n            {\n                args += _encodingHelper.GetVideoQualityParam(state, codec, _encodingOptions, isEventPlaylist ? DefaultEventEncoderPreset : DefaultVodEncoderPreset);\n\n                // Set the key frame params for video encoding to match the hls segment time.\n                args += _encodingHelper.GetHlsVideoKeyFrameArguments(state, codec, state.SegmentLength, isEventPlaylist, startNumber);\n\n                // Currenly b-frames in libx265 breaks the FMP4-HLS playback on iOS, disable it for now.\n                if (string.Equals(codec, \"libx265\", StringComparison.OrdinalIgnoreCase))\n                {\n                    args += \" -bf 0\";\n                }\n\n                // args += \" -mixed-refs 0 -refs 3 -x264opts b_pyramid=0:weightb=0:weightp=0\";\n\n                // video processing filters.\n                var videoProcessParam = _encodingHelper.GetVideoProcessingFilterParam(state, _encodingOptions, codec);\n\n                var negativeMapArgs = _encodingHelper.GetNegativeMapArgsByFilters(state, videoProcessParam);\n\n                args = negativeMapArgs + args + videoProcessParam;\n\n                // -start_at_zero is necessary to use with -ss when seeking,\n                // otherwise the target position cannot be determined.\n                if (state.SubtitleStream != null)\n                {\n                    // Disable start_at_zero for external graphical subs\n                    if (!(state.SubtitleStream.IsExternal && !state.SubtitleStream.IsTextSubtitleStream))\n                    {\n                        args += \" -start_at_zero\";\n                    }\n                }\n            }\n\n            // TODO why was this not enabled for VOD?\n            if (isEventPlaylist)\n            {\n                args += \" -flags -global_header\";\n            }\n\n            if (!string.IsNullOrEmpty(state.OutputVideoSync))\n            {\n                args += \" -vsync \" + state.OutputVideoSync;\n            }\n\n            args += _encodingHelper.GetOutputFFlags(state);\n\n            return args;\n        }\n\n        private string GetSegmentPath(StreamState state, string playlist, int index)\n        {\n            var folder = Path.GetDirectoryName(playlist) ?? throw new ArgumentException($\"Provided path ({playlist}) is not valid.\", nameof(playlist));\n            var filename = Path.GetFileNameWithoutExtension(playlist);\n\n            return Path.Combine(folder, filename + index.ToString(CultureInfo.InvariantCulture) + EncodingHelper.GetSegmentFileExtension(state.Request.SegmentContainer));\n        }\n\n        private async Task<ActionResult> GetSegmentResult(\n            StreamState state,\n            string playlistPath,\n            string segmentPath,\n            string segmentExtension,\n            int segmentIndex,\n            TranscodingJobDto? transcodingJob,\n            CancellationToken cancellationToken)\n        {\n            var segmentExists = System.IO.File.Exists(segmentPath);\n            if (segmentExists)\n            {\n                if (transcodingJob != null && transcodingJob.HasExited)\n                {\n                    // Transcoding job is over, so assume all existing files are ready\n                    _logger.LogDebug(\"serving up {0} as transcode is over\", segmentPath);\n                    return GetSegmentResult(state, segmentPath, transcodingJob);\n                }\n\n                var currentTranscodingIndex = GetCurrentTranscodingIndex(playlistPath, segmentExtension);\n\n                // If requested segment is less than transcoding position, we can't transcode backwards, so assume it's ready\n                if (segmentIndex < currentTranscodingIndex)\n                {\n                    _logger.LogDebug(\"serving up {0} as transcode index {1} is past requested point {2}\", segmentPath, currentTranscodingIndex, segmentIndex);\n                    return GetSegmentResult(state, segmentPath, transcodingJob);\n                }\n            }\n\n            var nextSegmentPath = GetSegmentPath(state, playlistPath, segmentIndex + 1);\n            if (transcodingJob != null)\n            {\n                while (!cancellationToken.IsCancellationRequested && !transcodingJob.HasExited)\n                {\n                    // To be considered ready, the segment file has to exist AND\n                    // either the transcoding job should be done or next segment should also exist\n                    if (segmentExists)\n                    {\n                        if (transcodingJob.HasExited || System.IO.File.Exists(nextSegmentPath))\n                        {\n                            _logger.LogDebug(\"Serving up {SegmentPath} as it deemed ready\", segmentPath);\n                            return GetSegmentResult(state, segmentPath, transcodingJob);\n                        }\n                    }\n                    else\n                    {\n                        segmentExists = System.IO.File.Exists(segmentPath);\n                        if (segmentExists)\n                        {\n                            continue; // avoid unnecessary waiting if segment just became available\n                        }\n                    }\n\n                    await Task.Delay(100, cancellationToken).ConfigureAwait(false);\n                }\n\n                if (!System.IO.File.Exists(segmentPath))\n                {\n                    _logger.LogWarning(\"cannot serve {0} as transcoding quit before we got there\", segmentPath);\n                }\n                else\n                {\n                    _logger.LogDebug(\"serving {0} as it's on disk and transcoding stopped\", segmentPath);\n                }\n\n                cancellationToken.ThrowIfCancellationRequested();\n            }\n            else\n            {\n                _logger.LogWarning(\"cannot serve {0} as it doesn't exist and no transcode is running\", segmentPath);\n            }\n\n            return GetSegmentResult(state, segmentPath, transcodingJob);\n        }\n\n        private ActionResult GetSegmentResult(StreamState state, string segmentPath, TranscodingJobDto? transcodingJob)\n        {\n            var segmentEndingPositionTicks = state.Request.CurrentRuntimeTicks + state.Request.ActualSegmentLengthTicks;\n\n            Response.OnCompleted(() =>\n            {\n                _logger.LogDebug(\"Finished serving {SegmentPath}\", segmentPath);\n                if (transcodingJob != null)\n                {\n                    transcodingJob.DownloadPositionTicks = Math.Max(transcodingJob.DownloadPositionTicks ?? segmentEndingPositionTicks, segmentEndingPositionTicks);\n                    _transcodingJobHelper.OnTranscodeEndRequest(transcodingJob);\n                }\n\n                return Task.CompletedTask;\n            });\n\n            return FileStreamResponseHelpers.GetStaticFileResult(segmentPath, MimeTypes.GetMimeType(segmentPath));\n        }\n\n        private int? GetCurrentTranscodingIndex(string playlist, string segmentExtension)\n        {\n            var job = _transcodingJobHelper.GetTranscodingJob(playlist, TranscodingJobType);\n\n            if (job == null || job.HasExited)\n            {\n                return null;\n            }\n\n            var file = GetLastTranscodingFile(playlist, segmentExtension, _fileSystem);\n\n            if (file == null)\n            {\n                return null;\n            }\n\n            var playlistFilename = Path.GetFileNameWithoutExtension(playlist);\n\n            var indexString = Path.GetFileNameWithoutExtension(file.Name).Substring(playlistFilename.Length);\n\n            return int.Parse(indexString, NumberStyles.Integer, CultureInfo.InvariantCulture);\n        }\n\n        private static FileSystemMetadata? GetLastTranscodingFile(string playlist, string segmentExtension, IFileSystem fileSystem)\n        {\n            var folder = Path.GetDirectoryName(playlist) ?? throw new ArgumentException(\"Path can't be a root directory.\", nameof(playlist));\n\n            var filePrefix = Path.GetFileNameWithoutExtension(playlist);\n\n            try\n            {\n                return fileSystem.GetFiles(folder, new[] { segmentExtension }, true, false)\n                    .Where(i => Path.GetFileNameWithoutExtension(i.Name).StartsWith(filePrefix, StringComparison.OrdinalIgnoreCase))\n                    .OrderByDescending(fileSystem.GetLastWriteTimeUtc)\n                    .FirstOrDefault();\n            }\n            catch (IOException)\n            {\n                return null;\n            }\n        }\n\n        private void DeleteLastFile(string playlistPath, string segmentExtension, int retryCount)\n        {\n            var file = GetLastTranscodingFile(playlistPath, segmentExtension, _fileSystem);\n\n            if (file != null)\n            {\n                DeleteFile(file.FullName, retryCount);\n            }\n        }\n\n        private void DeleteFile(string path, int retryCount)\n        {\n            if (retryCount >= 5)\n            {\n                return;\n            }\n\n            _logger.LogDebug(\"Deleting partial HLS file {Path}\", path);\n\n            try\n            {\n                _fileSystem.DeleteFile(path);\n            }\n            catch (IOException ex)\n            {\n                _logger.LogError(ex, \"Error deleting partial stream file(s) {Path}\", path);\n\n                var task = Task.Delay(100);\n                task.Wait();\n                DeleteFile(path, retryCount + 1);\n            }\n            catch (Exception ex)\n            {\n                _logger.LogError(ex, \"Error deleting partial stream file(s) {Path}\", path);\n            }\n        }\n    }\n}\n", "using System;\nusing System.Collections.Generic;\nusing System.ComponentModel.DataAnnotations;\nusing System.Globalization;\nusing System.Linq;\nusing System.Threading.Tasks;\nusing Jellyfin.Api.Attributes;\nusing Jellyfin.Api.Constants;\nusing Jellyfin.Api.Helpers;\nusing Jellyfin.Api.ModelBinders;\nusing Jellyfin.Api.Models.StreamingDtos;\nusing MediaBrowser.Common.Extensions;\nusing MediaBrowser.Controller.Devices;\nusing MediaBrowser.Controller.Library;\nusing MediaBrowser.Controller.MediaEncoding;\nusing MediaBrowser.Controller.Net;\nusing MediaBrowser.Model.Dlna;\nusing MediaBrowser.Model.MediaInfo;\nusing MediaBrowser.Model.Session;\nusing Microsoft.AspNetCore.Authorization;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Logging;\n\nnamespace Jellyfin.Api.Controllers\n{\n    /// <summary>\n    /// The universal audio controller.\n    /// </summary>\n    [Route(\"\")]\n    public class UniversalAudioController : BaseJellyfinApiController\n    {\n        private readonly IAuthorizationContext _authorizationContext;\n        private readonly IDeviceManager _deviceManager;\n        private readonly ILibraryManager _libraryManager;\n        private readonly ILogger<UniversalAudioController> _logger;\n        private readonly MediaInfoHelper _mediaInfoHelper;\n        private readonly AudioHelper _audioHelper;\n        private readonly DynamicHlsHelper _dynamicHlsHelper;\n\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"UniversalAudioController\"/> class.\n        /// </summary>\n        /// <param name=\"authorizationContext\">Instance of the <see cref=\"IAuthorizationContext\"/> interface.</param>\n        /// <param name=\"deviceManager\">Instance of the <see cref=\"IDeviceManager\"/> interface.</param>\n        /// <param name=\"libraryManager\">Instance of the <see cref=\"ILibraryManager\"/> interface.</param>\n        /// <param name=\"logger\">Instance of the <see cref=\"ILogger{UniversalAudioController}\"/> interface.</param>\n        /// <param name=\"mediaInfoHelper\">Instance of <see cref=\"MediaInfoHelper\"/>.</param>\n        /// <param name=\"audioHelper\">Instance of <see cref=\"AudioHelper\"/>.</param>\n        /// <param name=\"dynamicHlsHelper\">Instance of <see cref=\"DynamicHlsHelper\"/>.</param>\n        public UniversalAudioController(\n            IAuthorizationContext authorizationContext,\n            IDeviceManager deviceManager,\n            ILibraryManager libraryManager,\n            ILogger<UniversalAudioController> logger,\n            MediaInfoHelper mediaInfoHelper,\n            AudioHelper audioHelper,\n            DynamicHlsHelper dynamicHlsHelper)\n        {\n            _authorizationContext = authorizationContext;\n            _deviceManager = deviceManager;\n            _libraryManager = libraryManager;\n            _logger = logger;\n            _mediaInfoHelper = mediaInfoHelper;\n            _audioHelper = audioHelper;\n            _dynamicHlsHelper = dynamicHlsHelper;\n        }\n\n        /// <summary>\n        /// Gets an audio stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">Optional. The audio container.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"userId\">Optional. The user id.</param>\n        /// <param name=\"audioCodec\">Optional. The audio codec to transcode to.</param>\n        /// <param name=\"maxAudioChannels\">Optional. The maximum number of audio channels.</param>\n        /// <param name=\"transcodingAudioChannels\">Optional. The number of how many audio channels to transcode to.</param>\n        /// <param name=\"maxStreamingBitrate\">Optional. The maximum streaming bitrate.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"transcodingContainer\">Optional. The container to transcode to.</param>\n        /// <param name=\"transcodingProtocol\">Optional. The transcoding protocol.</param>\n        /// <param name=\"maxAudioSampleRate\">Optional. The maximum audio sample rate.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"enableRemoteMedia\">Optional. Whether to enable remote media.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"enableRedirection\">Whether to enable redirection. Defaults to true.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <response code=\"302\">Redirected to remote audio stream.</response>\n        /// <returns>A <see cref=\"Task\"/> containing the audio file.</returns>\n        [HttpGet(\"Audio/{itemId}/universal\")]\n        [HttpHead(\"Audio/{itemId}/universal\", Name = \"HeadUniversalAudioStream\")]\n        [Authorize(Policy = Policies.DefaultAuthorization)]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesResponseType(StatusCodes.Status302Found)]\n        [ProducesAudioFile]\n        public async Task<ActionResult> GetUniversalAudioStream(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery, ModelBinder(typeof(CommaDelimitedArrayModelBinder))] string[] container,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] Guid? userId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] int? transcodingAudioChannels,\n            [FromQuery] int? maxStreamingBitrate,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] string? transcodingContainer,\n            [FromQuery] string? transcodingProtocol,\n            [FromQuery] int? maxAudioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] bool? enableRemoteMedia,\n            [FromQuery] bool breakOnNonKeyFrames = false,\n            [FromQuery] bool enableRedirection = true)\n        {\n            var deviceProfile = GetDeviceProfile(container, transcodingContainer, audioCodec, transcodingProtocol, breakOnNonKeyFrames, transcodingAudioChannels, maxAudioSampleRate, maxAudioBitDepth, maxAudioChannels);\n            var authorizationInfo = await _authorizationContext.GetAuthorizationInfo(Request).ConfigureAwait(false);\n            authorizationInfo.DeviceId = deviceId;\n\n            if (!userId.HasValue || userId.Value.Equals(Guid.Empty))\n            {\n                userId = authorizationInfo.UserId;\n            }\n\n            var authInfo = await _authorizationContext.GetAuthorizationInfo(Request).ConfigureAwait(false);\n\n            _logger.LogInformation(\"GetPostedPlaybackInfo profile: {@Profile}\", deviceProfile);\n\n            if (deviceProfile == null)\n            {\n                var clientCapabilities = _deviceManager.GetCapabilities(authInfo.DeviceId);\n                if (clientCapabilities != null)\n                {\n                    deviceProfile = clientCapabilities.DeviceProfile;\n                }\n            }\n\n            var info = await _mediaInfoHelper.GetPlaybackInfo(\n                    itemId,\n                    userId,\n                    mediaSourceId)\n                .ConfigureAwait(false);\n\n            if (deviceProfile != null)\n            {\n                // set device specific data\n                var item = _libraryManager.GetItemById(itemId);\n\n                foreach (var sourceInfo in info.MediaSources)\n                {\n                    _mediaInfoHelper.SetDeviceSpecificData(\n                        item,\n                        sourceInfo,\n                        deviceProfile,\n                        authInfo,\n                        maxStreamingBitrate ?? deviceProfile.MaxStreamingBitrate,\n                        startTimeTicks ?? 0,\n                        mediaSourceId ?? string.Empty,\n                        null,\n                        null,\n                        maxAudioChannels,\n                        info.PlaySessionId!,\n                        userId ?? Guid.Empty,\n                        true,\n                        true,\n                        true,\n                        true,\n                        true,\n                        Request.HttpContext.GetNormalizedRemoteIp());\n                }\n\n                _mediaInfoHelper.SortMediaSources(info, maxStreamingBitrate);\n            }\n\n            if (info.MediaSources != null)\n            {\n                foreach (var source in info.MediaSources)\n                {\n                    _mediaInfoHelper.NormalizeMediaSourceContainer(source, deviceProfile!, DlnaProfileType.Video);\n                }\n            }\n\n            var mediaSource = info.MediaSources![0];\n            if (mediaSource.SupportsDirectPlay && mediaSource.Protocol == MediaProtocol.Http)\n            {\n                if (enableRedirection)\n                {\n                    if (mediaSource.IsRemote && enableRemoteMedia.HasValue && enableRemoteMedia.Value)\n                    {\n                        return Redirect(mediaSource.Path);\n                    }\n                }\n            }\n\n            var isStatic = mediaSource.SupportsDirectStream;\n            if (!isStatic && string.Equals(mediaSource.TranscodingSubProtocol, \"hls\", StringComparison.OrdinalIgnoreCase))\n            {\n                // hls segment container can only be mpegts or fmp4 per ffmpeg documentation\n                // ffmpeg option -> file extension\n                //        mpegts -> ts\n                //          fmp4 -> mp4\n                // TODO: remove this when we switch back to the segment muxer\n                var supportedHlsContainers = new[] { \"ts\", \"mp4\" };\n\n                var dynamicHlsRequestDto = new HlsAudioRequestDto\n                {\n                    Id = itemId,\n                    Container = \".m3u8\",\n                    Static = isStatic,\n                    PlaySessionId = info.PlaySessionId,\n                    // fallback to mpegts if device reports some weird value unsupported by hls\n                    SegmentContainer = Array.Exists(supportedHlsContainers, element => element == transcodingContainer) ? transcodingContainer : \"ts\",\n                    MediaSourceId = mediaSourceId,\n                    DeviceId = deviceId,\n                    AudioCodec = audioCodec,\n                    EnableAutoStreamCopy = true,\n                    AllowAudioStreamCopy = true,\n                    AllowVideoStreamCopy = true,\n                    BreakOnNonKeyFrames = breakOnNonKeyFrames,\n                    AudioSampleRate = maxAudioSampleRate,\n                    MaxAudioChannels = maxAudioChannels,\n                    MaxAudioBitDepth = maxAudioBitDepth,\n                    AudioBitRate = audioBitRate ?? maxStreamingBitrate,\n                    StartTimeTicks = startTimeTicks,\n                    SubtitleMethod = SubtitleDeliveryMethod.Hls,\n                    RequireAvc = false,\n                    DeInterlace = false,\n                    RequireNonAnamorphic = false,\n                    EnableMpegtsM2TsMode = false,\n                    TranscodeReasons = mediaSource.TranscodeReasons == 0 ? null : mediaSource.TranscodeReasons.ToString(),\n                    Context = EncodingContext.Static,\n                    StreamOptions = new Dictionary<string, string>(),\n                    EnableAdaptiveBitrateStreaming = true\n                };\n\n                return await _dynamicHlsHelper.GetMasterHlsPlaylist(TranscodingJobType.Hls, dynamicHlsRequestDto, true)\n                    .ConfigureAwait(false);\n            }\n\n            var audioStreamingDto = new StreamingRequestDto\n            {\n                Id = itemId,\n                Container = isStatic ? null : (\".\" + mediaSource.TranscodingContainer),\n                Static = isStatic,\n                PlaySessionId = info.PlaySessionId,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = true,\n                AllowAudioStreamCopy = true,\n                AllowVideoStreamCopy = true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames,\n                AudioSampleRate = maxAudioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = isStatic ? (int?)null : (audioBitRate ?? maxStreamingBitrate),\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = maxAudioChannels,\n                CopyTimestamps = true,\n                StartTimeTicks = startTimeTicks,\n                SubtitleMethod = SubtitleDeliveryMethod.Embed,\n                TranscodeReasons = mediaSource.TranscodeReasons == 0 ? null : mediaSource.TranscodeReasons.ToString(),\n                Context = EncodingContext.Static\n            };\n\n            return await _audioHelper.GetAudioStream(TranscodingJobType.Progressive, audioStreamingDto).ConfigureAwait(false);\n        }\n\n        private DeviceProfile GetDeviceProfile(\n            string[] containers,\n            string? transcodingContainer,\n            string? audioCodec,\n            string? transcodingProtocol,\n            bool? breakOnNonKeyFrames,\n            int? transcodingAudioChannels,\n            int? maxAudioSampleRate,\n            int? maxAudioBitDepth,\n            int? maxAudioChannels)\n        {\n            var deviceProfile = new DeviceProfile();\n\n            int len = containers.Length;\n            var directPlayProfiles = new DirectPlayProfile[len];\n            for (int i = 0; i < len; i++)\n            {\n                var parts = containers[i].Split('|', StringSplitOptions.RemoveEmptyEntries);\n\n                var audioCodecs = parts.Length == 1 ? null : string.Join(',', parts.Skip(1));\n\n                directPlayProfiles[i] = new DirectPlayProfile\n                {\n                    Type = DlnaProfileType.Audio,\n                    Container = parts[0],\n                    AudioCodec = audioCodecs\n                };\n            }\n\n            deviceProfile.DirectPlayProfiles = directPlayProfiles;\n\n            deviceProfile.TranscodingProfiles = new[]\n            {\n                new TranscodingProfile\n                {\n                    Type = DlnaProfileType.Audio,\n                    Context = EncodingContext.Streaming,\n                    Container = transcodingContainer ?? \"mp3\",\n                    AudioCodec = audioCodec ?? \"mp3\",\n                    Protocol = transcodingProtocol ?? \"http\",\n                    BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                    MaxAudioChannels = transcodingAudioChannels?.ToString(CultureInfo.InvariantCulture)\n                }\n            };\n\n            var codecProfiles = new List<CodecProfile>();\n            var conditions = new List<ProfileCondition>();\n\n            if (maxAudioSampleRate.HasValue)\n            {\n                // codec profile\n                conditions.Add(\n                    new ProfileCondition\n                    {\n                        Condition = ProfileConditionType.LessThanEqual,\n                        IsRequired = false,\n                        Property = ProfileConditionValue.AudioSampleRate,\n                        Value = maxAudioSampleRate.Value.ToString(CultureInfo.InvariantCulture)\n                    });\n            }\n\n            if (maxAudioBitDepth.HasValue)\n            {\n                // codec profile\n                conditions.Add(\n                    new ProfileCondition\n                    {\n                        Condition = ProfileConditionType.LessThanEqual,\n                        IsRequired = false,\n                        Property = ProfileConditionValue.AudioBitDepth,\n                        Value = maxAudioBitDepth.Value.ToString(CultureInfo.InvariantCulture)\n                    });\n            }\n\n            if (maxAudioChannels.HasValue)\n            {\n                // codec profile\n                conditions.Add(\n                    new ProfileCondition\n                    {\n                        Condition = ProfileConditionType.LessThanEqual,\n                        IsRequired = false,\n                        Property = ProfileConditionValue.AudioChannels,\n                        Value = maxAudioChannels.Value.ToString(CultureInfo.InvariantCulture)\n                    });\n            }\n\n            if (conditions.Count > 0)\n            {\n                // codec profile\n                codecProfiles.Add(\n                    new CodecProfile\n                    {\n                        Type = CodecType.Audio,\n                        Container = string.Join(',', containers),\n                        Conditions = conditions.ToArray()\n                    });\n            }\n\n            deviceProfile.CodecProfiles = codecProfiles.ToArray();\n\n            return deviceProfile;\n        }\n    }\n}\n", "using System;\nusing System.Collections.Generic;\nusing System.ComponentModel.DataAnnotations;\nusing System.Globalization;\nusing System.Linq;\nusing System.Net.Http;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing Jellyfin.Api.Attributes;\nusing Jellyfin.Api.Constants;\nusing Jellyfin.Api.Extensions;\nusing Jellyfin.Api.Helpers;\nusing Jellyfin.Api.ModelBinders;\nusing Jellyfin.Api.Models.StreamingDtos;\nusing MediaBrowser.Common.Configuration;\nusing MediaBrowser.Common.Net;\nusing MediaBrowser.Controller.Configuration;\nusing MediaBrowser.Controller.Devices;\nusing MediaBrowser.Controller.Dlna;\nusing MediaBrowser.Controller.Dto;\nusing MediaBrowser.Controller.Entities;\nusing MediaBrowser.Controller.Library;\nusing MediaBrowser.Controller.MediaEncoding;\nusing MediaBrowser.Controller.Net;\nusing MediaBrowser.Model.Dlna;\nusing MediaBrowser.Model.Dto;\nusing MediaBrowser.Model.Entities;\nusing MediaBrowser.Model.MediaInfo;\nusing MediaBrowser.Model.Net;\nusing MediaBrowser.Model.Querying;\nusing Microsoft.AspNetCore.Authorization;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\n\nnamespace Jellyfin.Api.Controllers\n{\n    /// <summary>\n    /// The videos controller.\n    /// </summary>\n    public class VideosController : BaseJellyfinApiController\n    {\n        private readonly ILibraryManager _libraryManager;\n        private readonly IUserManager _userManager;\n        private readonly IDtoService _dtoService;\n        private readonly IDlnaManager _dlnaManager;\n        private readonly IAuthorizationContext _authContext;\n        private readonly IMediaSourceManager _mediaSourceManager;\n        private readonly IServerConfigurationManager _serverConfigurationManager;\n        private readonly IMediaEncoder _mediaEncoder;\n        private readonly IDeviceManager _deviceManager;\n        private readonly TranscodingJobHelper _transcodingJobHelper;\n        private readonly IHttpClientFactory _httpClientFactory;\n        private readonly EncodingHelper _encodingHelper;\n\n        private readonly TranscodingJobType _transcodingJobType = TranscodingJobType.Progressive;\n\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"VideosController\"/> class.\n        /// </summary>\n        /// <param name=\"libraryManager\">Instance of the <see cref=\"ILibraryManager\"/> interface.</param>\n        /// <param name=\"userManager\">Instance of the <see cref=\"IUserManager\"/> interface.</param>\n        /// <param name=\"dtoService\">Instance of the <see cref=\"IDtoService\"/> interface.</param>\n        /// <param name=\"dlnaManager\">Instance of the <see cref=\"IDlnaManager\"/> interface.</param>\n        /// <param name=\"authContext\">Instance of the <see cref=\"IAuthorizationContext\"/> interface.</param>\n        /// <param name=\"mediaSourceManager\">Instance of the <see cref=\"IMediaSourceManager\"/> interface.</param>\n        /// <param name=\"serverConfigurationManager\">Instance of the <see cref=\"IServerConfigurationManager\"/> interface.</param>\n        /// <param name=\"mediaEncoder\">Instance of the <see cref=\"IMediaEncoder\"/> interface.</param>\n        /// <param name=\"deviceManager\">Instance of the <see cref=\"IDeviceManager\"/> interface.</param>\n        /// <param name=\"transcodingJobHelper\">Instance of the <see cref=\"TranscodingJobHelper\"/> class.</param>\n        /// <param name=\"httpClientFactory\">Instance of the <see cref=\"IHttpClientFactory\"/> interface.</param>\n        /// <param name=\"encodingHelper\">Instance of <see cref=\"EncodingHelper\"/>.</param>\n        public VideosController(\n            ILibraryManager libraryManager,\n            IUserManager userManager,\n            IDtoService dtoService,\n            IDlnaManager dlnaManager,\n            IAuthorizationContext authContext,\n            IMediaSourceManager mediaSourceManager,\n            IServerConfigurationManager serverConfigurationManager,\n            IMediaEncoder mediaEncoder,\n            IDeviceManager deviceManager,\n            TranscodingJobHelper transcodingJobHelper,\n            IHttpClientFactory httpClientFactory,\n            EncodingHelper encodingHelper)\n        {\n            _libraryManager = libraryManager;\n            _userManager = userManager;\n            _dtoService = dtoService;\n            _dlnaManager = dlnaManager;\n            _authContext = authContext;\n            _mediaSourceManager = mediaSourceManager;\n            _serverConfigurationManager = serverConfigurationManager;\n            _mediaEncoder = mediaEncoder;\n            _deviceManager = deviceManager;\n            _transcodingJobHelper = transcodingJobHelper;\n            _httpClientFactory = httpClientFactory;\n            _encodingHelper = encodingHelper;\n        }\n\n        /// <summary>\n        /// Gets additional parts for a video.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"userId\">Optional. Filter by user id, and attach user data.</param>\n        /// <response code=\"200\">Additional parts returned.</response>\n        /// <returns>A <see cref=\"QueryResult{BaseItemDto}\"/> with the parts.</returns>\n        [HttpGet(\"{itemId}/AdditionalParts\")]\n        [Authorize(Policy = Policies.DefaultAuthorization)]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        public ActionResult<QueryResult<BaseItemDto>> GetAdditionalPart([FromRoute, Required] Guid itemId, [FromQuery] Guid? userId)\n        {\n            var user = userId is null || userId.Value.Equals(default)\n                ? null\n                : _userManager.GetUserById(userId.Value);\n\n            var item = itemId.Equals(default)\n                ? (userId is null || userId.Value.Equals(default)\n                    ? _libraryManager.RootFolder\n                    : _libraryManager.GetUserRootFolder())\n                : _libraryManager.GetItemById(itemId);\n\n            var dtoOptions = new DtoOptions();\n            dtoOptions = dtoOptions.AddClientFields(Request);\n\n            BaseItemDto[] items;\n            if (item is Video video)\n            {\n                items = video.GetAdditionalParts()\n                    .Select(i => _dtoService.GetBaseItemDto(i, dtoOptions, user, video))\n                    .ToArray();\n            }\n            else\n            {\n                items = Array.Empty<BaseItemDto>();\n            }\n\n            var result = new QueryResult<BaseItemDto>(items);\n            return result;\n        }\n\n        /// <summary>\n        /// Removes alternate video sources.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <response code=\"204\">Alternate sources deleted.</response>\n        /// <response code=\"404\">Video not found.</response>\n        /// <returns>A <see cref=\"NoContentResult\"/> indicating success, or a <see cref=\"NotFoundResult\"/> if the video doesn't exist.</returns>\n        [HttpDelete(\"{itemId}/AlternateSources\")]\n        [Authorize(Policy = Policies.RequiresElevation)]\n        [ProducesResponseType(StatusCodes.Status204NoContent)]\n        [ProducesResponseType(StatusCodes.Status404NotFound)]\n        public async Task<ActionResult> DeleteAlternateSources([FromRoute, Required] Guid itemId)\n        {\n            var video = (Video)_libraryManager.GetItemById(itemId);\n\n            if (video == null)\n            {\n                return NotFound(\"The video either does not exist or the id does not belong to a video.\");\n            }\n\n            if (video.LinkedAlternateVersions.Length == 0)\n            {\n                video = (Video)_libraryManager.GetItemById(video.PrimaryVersionId);\n            }\n\n            foreach (var link in video.GetLinkedAlternateVersions())\n            {\n                link.SetPrimaryVersionId(null);\n                link.LinkedAlternateVersions = Array.Empty<LinkedChild>();\n\n                await link.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n            }\n\n            video.LinkedAlternateVersions = Array.Empty<LinkedChild>();\n            video.SetPrimaryVersionId(null);\n            await video.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n\n            return NoContent();\n        }\n\n        /// <summary>\n        /// Merges videos into a single record.\n        /// </summary>\n        /// <param name=\"ids\">Item id list. This allows multiple, comma delimited.</param>\n        /// <response code=\"204\">Videos merged.</response>\n        /// <response code=\"400\">Supply at least 2 video ids.</response>\n        /// <returns>A <see cref=\"NoContentResult\"/> indicating success, or a <see cref=\"BadRequestResult\"/> if less than two ids were supplied.</returns>\n        [HttpPost(\"MergeVersions\")]\n        [Authorize(Policy = Policies.RequiresElevation)]\n        [ProducesResponseType(StatusCodes.Status204NoContent)]\n        [ProducesResponseType(StatusCodes.Status400BadRequest)]\n        public async Task<ActionResult> MergeVersions([FromQuery, Required, ModelBinder(typeof(CommaDelimitedArrayModelBinder))] Guid[] ids)\n        {\n            var items = ids\n                .Select(i => _libraryManager.GetItemById(i))\n                .OfType<Video>()\n                .OrderBy(i => i.Id)\n                .ToList();\n\n            if (items.Count < 2)\n            {\n                return BadRequest(\"Please supply at least two videos to merge.\");\n            }\n\n            var primaryVersion = items.FirstOrDefault(i => i.MediaSourceCount > 1 && string.IsNullOrEmpty(i.PrimaryVersionId));\n            if (primaryVersion == null)\n            {\n                primaryVersion = items\n                    .OrderBy(i =>\n                    {\n                        if (i.Video3DFormat.HasValue || i.VideoType != VideoType.VideoFile)\n                        {\n                            return 1;\n                        }\n\n                        return 0;\n                    })\n                    .ThenByDescending(i => i.GetDefaultVideoStream()?.Width ?? 0)\n                    .First();\n            }\n\n            var alternateVersionsOfPrimary = primaryVersion.LinkedAlternateVersions.ToList();\n\n            foreach (var item in items.Where(i => !i.Id.Equals(primaryVersion.Id)))\n            {\n                item.SetPrimaryVersionId(primaryVersion.Id.ToString(\"N\", CultureInfo.InvariantCulture));\n\n                await item.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n\n                if (!alternateVersionsOfPrimary.Any(i => string.Equals(i.Path, item.Path, StringComparison.OrdinalIgnoreCase)))\n                {\n                    alternateVersionsOfPrimary.Add(new LinkedChild\n                    {\n                        Path = item.Path,\n                        ItemId = item.Id\n                    });\n                }\n\n                foreach (var linkedItem in item.LinkedAlternateVersions)\n                {\n                    if (!alternateVersionsOfPrimary.Any(i => string.Equals(i.Path, linkedItem.Path, StringComparison.OrdinalIgnoreCase)))\n                    {\n                        alternateVersionsOfPrimary.Add(linkedItem);\n                    }\n                }\n\n                if (item.LinkedAlternateVersions.Length > 0)\n                {\n                    item.LinkedAlternateVersions = Array.Empty<LinkedChild>();\n                    await item.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n                }\n            }\n\n            primaryVersion.LinkedAlternateVersions = alternateVersionsOfPrimary.ToArray();\n            await primaryVersion.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n            return NoContent();\n        }\n\n        /// <summary>\n        /// Gets a video stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The video container. Possible values are: ts, webm, asf, wmv, ogv, mp4, m4v, mkv, mpeg, mpg, avi, 3gp, wmv, wtv, m2ts, mov, iso, flv. </param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"{itemId}/stream\")]\n        [HttpHead(\"{itemId}/stream\", Name = \"HeadVideoStream\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesVideoFile]\n        public async Task<ActionResult> GetVideoStream(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] string? container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            var isHeadRequest = Request.Method == System.Net.WebRequestMethods.Http.Head;\n            // CTS lifecycle is managed internally.\n            var cancellationTokenSource = new CancellationTokenSource();\n            var streamingRequest = new VideoRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                MaxWidth = maxWidth,\n                MaxHeight = maxHeight,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            var state = await StreamingHelpers.GetStreamingState(\n                    streamingRequest,\n                    Request,\n                    _authContext,\n                    _mediaSourceManager,\n                    _userManager,\n                    _libraryManager,\n                    _serverConfigurationManager,\n                    _mediaEncoder,\n                    _encodingHelper,\n                    _dlnaManager,\n                    _deviceManager,\n                    _transcodingJobHelper,\n                    _transcodingJobType,\n                    cancellationTokenSource.Token)\n                .ConfigureAwait(false);\n\n            if (@static.HasValue && @static.Value && state.DirectStreamProvider != null)\n            {\n                StreamingHelpers.AddDlnaHeaders(state, Response.Headers, true, state.Request.StartTimeTicks, Request, _dlnaManager);\n\n                var liveStreamInfo = _mediaSourceManager.GetLiveStreamInfo(streamingRequest.LiveStreamId);\n                if (liveStreamInfo == null)\n                {\n                    return NotFound();\n                }\n\n                var liveStream = new ProgressiveFileStream(liveStreamInfo.GetStream());\n                // TODO (moved from MediaBrowser.Api): Don't hardcode contentType\n                return File(liveStream, MimeTypes.GetMimeType(\"file.ts\"));\n            }\n\n            // Static remote stream\n            if (@static.HasValue && @static.Value && state.InputProtocol == MediaProtocol.Http)\n            {\n                StreamingHelpers.AddDlnaHeaders(state, Response.Headers, true, state.Request.StartTimeTicks, Request, _dlnaManager);\n\n                var httpClient = _httpClientFactory.CreateClient(NamedClient.Default);\n                return await FileStreamResponseHelpers.GetStaticRemoteStreamResult(state, httpClient, HttpContext).ConfigureAwait(false);\n            }\n\n            if (@static.HasValue && @static.Value && state.InputProtocol != MediaProtocol.File)\n            {\n                return BadRequest($\"Input protocol {state.InputProtocol} cannot be streamed statically\");\n            }\n\n            var outputPath = state.OutputFilePath;\n            var outputPathExists = System.IO.File.Exists(outputPath);\n\n            var transcodingJob = _transcodingJobHelper.GetTranscodingJob(outputPath, TranscodingJobType.Progressive);\n            var isTranscodeCached = outputPathExists && transcodingJob != null;\n\n            StreamingHelpers.AddDlnaHeaders(state, Response.Headers, (@static.HasValue && @static.Value) || isTranscodeCached, state.Request.StartTimeTicks, Request, _dlnaManager);\n\n            // Static stream\n            if (@static.HasValue && @static.Value)\n            {\n                var contentType = state.GetMimeType(\".\" + state.OutputContainer, false) ?? state.GetMimeType(state.MediaPath);\n\n                if (state.MediaSource.IsInfiniteStream)\n                {\n                    var liveStream = new ProgressiveFileStream(state.MediaPath, null, _transcodingJobHelper);\n                    return File(liveStream, contentType);\n                }\n\n                return FileStreamResponseHelpers.GetStaticFileResult(\n                    state.MediaPath,\n                    contentType);\n            }\n\n            // Need to start ffmpeg (because media can't be returned directly)\n            var encodingOptions = _serverConfigurationManager.GetEncodingOptions();\n            var ffmpegCommandLineArguments = _encodingHelper.GetProgressiveVideoFullCommandLine(state, encodingOptions, outputPath, \"superfast\");\n            return await FileStreamResponseHelpers.GetTranscodedFile(\n                state,\n                isHeadRequest,\n                HttpContext,\n                _transcodingJobHelper,\n                ffmpegCommandLineArguments,\n                _transcodingJobType,\n                cancellationTokenSource).ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets a video stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The video container. Possible values are: ts, webm, asf, wmv, ogv, mp4, m4v, mkv, mpeg, mpg, avi, 3gp, wmv, wtv, m2ts, mov, iso, flv. </param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"{itemId}/stream.{container}\")]\n        [HttpHead(\"{itemId}/stream.{container}\", Name = \"HeadVideoStreamByContainer\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesVideoFile]\n        public Task<ActionResult> GetVideoStreamByContainer(\n            [FromRoute, Required] Guid itemId,\n            [FromRoute, Required] string container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery] string? videoCodec,\n            [FromQuery] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            return GetVideoStream(\n                itemId,\n                container,\n                @static,\n                @params,\n                tag,\n                deviceProfileId,\n                playSessionId,\n                segmentContainer,\n                segmentLength,\n                minSegments,\n                mediaSourceId,\n                deviceId,\n                audioCodec,\n                enableAutoStreamCopy,\n                allowVideoStreamCopy,\n                allowAudioStreamCopy,\n                breakOnNonKeyFrames,\n                audioSampleRate,\n                maxAudioBitDepth,\n                audioBitRate,\n                audioChannels,\n                maxAudioChannels,\n                profile,\n                level,\n                framerate,\n                maxFramerate,\n                copyTimestamps,\n                startTimeTicks,\n                width,\n                height,\n                maxWidth,\n                maxHeight,\n                videoBitRate,\n                subtitleStreamIndex,\n                subtitleMethod,\n                maxRefFrames,\n                maxVideoBitDepth,\n                requireAvc,\n                deInterlace,\n                requireNonAnamorphic,\n                transcodingMaxAudioChannels,\n                cpuCoreLimit,\n                liveStreamId,\n                enableMpegtsM2TsMode,\n                videoCodec,\n                subtitleCodec,\n                transcodeReasons,\n                audioStreamIndex,\n                videoStreamIndex,\n                context,\n                streamOptions);\n        }\n    }\n}\n", "#nullable disable\n\n#pragma warning disable CS1591\n\nusing System;\nusing System.Collections.Generic;\nusing System.Globalization;\nusing System.IO;\nusing System.Linq;\nusing System.Text;\nusing System.Text.RegularExpressions;\nusing System.Threading;\nusing Jellyfin.Data.Enums;\nusing Jellyfin.Extensions;\nusing MediaBrowser.Common.Configuration;\nusing MediaBrowser.Controller.Extensions;\nusing MediaBrowser.Model.Configuration;\nusing MediaBrowser.Model.Dlna;\nusing MediaBrowser.Model.Dto;\nusing MediaBrowser.Model.Entities;\nusing MediaBrowser.Model.MediaInfo;\nusing Microsoft.Extensions.Configuration;\n\nnamespace MediaBrowser.Controller.MediaEncoding\n{\n    public class EncodingHelper\n    {\n        private const string QsvAlias = \"qs\";\n        private const string VaapiAlias = \"va\";\n        private const string D3d11vaAlias = \"dx11\";\n        private const string VideotoolboxAlias = \"vt\";\n        private const string OpenclAlias = \"ocl\";\n        private const string CudaAlias = \"cu\";\n        private readonly IApplicationPaths _appPaths;\n        private readonly IMediaEncoder _mediaEncoder;\n        private readonly ISubtitleEncoder _subtitleEncoder;\n        private readonly IConfiguration _config;\n\n        // i915 hang was fixed by linux 6.2 (3f882f2)\n        private readonly Version _minKerneli915Hang = new Version(5, 18);\n        private readonly Version _maxKerneli915Hang = new Version(6, 1, 3);\n        private readonly Version _minFixedKernel60i915Hang = new Version(6, 0, 18);\n\n        private readonly Version _minFFmpegImplictHwaccel = new Version(6, 0);\n        private readonly Version _minFFmpegHwaUnsafeOutput = new Version(6, 0);\n        private readonly Version _minFFmpegOclCuTonemapMode = new Version(5, 1, 3);\n\n        private static readonly string[] _videoProfilesH264 = new[]\n        {\n            \"ConstrainedBaseline\",\n            \"Baseline\",\n            \"Extended\",\n            \"Main\",\n            \"High\",\n            \"ProgressiveHigh\",\n            \"ConstrainedHigh\",\n            \"High10\"\n        };\n\n        private static readonly string[] _videoProfilesH265 = new[]\n        {\n            \"Main\",\n            \"Main10\"\n        };\n\n        public static readonly string[] LosslessAudioCodecs = new string[]\n        {\n            \"alac\",\n            \"ape\",\n            \"flac\",\n            \"mlp\",\n            \"truehd\",\n            \"wavpack\"\n        };\n\n        public EncodingHelper(\n            IApplicationPaths appPaths,\n            IMediaEncoder mediaEncoder,\n            ISubtitleEncoder subtitleEncoder,\n            IConfiguration config)\n        {\n            _appPaths = appPaths;\n            _mediaEncoder = mediaEncoder;\n            _subtitleEncoder = subtitleEncoder;\n            _config = config;\n        }\n\n        public string GetH264Encoder(EncodingJobInfo state, EncodingOptions encodingOptions)\n            => GetH264OrH265Encoder(\"libx264\", \"h264\", state, encodingOptions);\n\n        public string GetH265Encoder(EncodingJobInfo state, EncodingOptions encodingOptions)\n            => GetH264OrH265Encoder(\"libx265\", \"hevc\", state, encodingOptions);\n\n        private string GetH264OrH265Encoder(string defaultEncoder, string hwEncoder, EncodingJobInfo state, EncodingOptions encodingOptions)\n        {\n            // Only use alternative encoders for video files.\n            // When using concat with folder rips, if the mfx session fails to initialize, ffmpeg will be stuck retrying and will not exit gracefully\n            // Since transcoding of folder rips is experimental anyway, it's not worth adding additional variables such as this.\n            if (state.VideoType == VideoType.VideoFile)\n            {\n                var hwType = encodingOptions.HardwareAccelerationType;\n\n                var codecMap = new Dictionary<string, string>(StringComparer.OrdinalIgnoreCase)\n                {\n                    { \"amf\",                  hwEncoder + \"_amf\" },\n                    { \"nvenc\",                hwEncoder + \"_nvenc\" },\n                    { \"qsv\",                  hwEncoder + \"_qsv\" },\n                    { \"vaapi\",                hwEncoder + \"_vaapi\" },\n                    { \"videotoolbox\",         hwEncoder + \"_videotoolbox\" },\n                    { \"v4l2m2m\",              hwEncoder + \"_v4l2m2m\" },\n                };\n\n                if (!string.IsNullOrEmpty(hwType)\n                    && encodingOptions.EnableHardwareEncoding\n                    && codecMap.ContainsKey(hwType))\n                {\n                    var preferredEncoder = codecMap[hwType];\n\n                    if (_mediaEncoder.SupportsEncoder(preferredEncoder))\n                    {\n                        return preferredEncoder;\n                    }\n                }\n            }\n\n            return defaultEncoder;\n        }\n\n        private bool IsVaapiSupported(EncodingJobInfo state)\n        {\n            // vaapi will throw an error with this input\n            // [vaapi @ 0x7faed8000960] No VAAPI support for codec mpeg4 profile -99.\n            if (string.Equals(state.VideoStream?.Codec, \"mpeg4\", StringComparison.OrdinalIgnoreCase))\n            {\n                return false;\n            }\n\n            return _mediaEncoder.SupportsHwaccel(\"vaapi\");\n        }\n\n        private bool IsVaapiFullSupported()\n        {\n            return _mediaEncoder.SupportsHwaccel(\"vaapi\")\n                   && _mediaEncoder.SupportsFilter(\"scale_vaapi\")\n                   && _mediaEncoder.SupportsFilter(\"deinterlace_vaapi\")\n                   && _mediaEncoder.SupportsFilter(\"tonemap_vaapi\")\n                   && _mediaEncoder.SupportsFilter(\"procamp_vaapi\")\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.OverlayVaapiFrameSync)\n                   && _mediaEncoder.SupportsFilter(\"hwupload_vaapi\");\n        }\n\n        private bool IsOpenclFullSupported()\n        {\n            return _mediaEncoder.SupportsHwaccel(\"opencl\")\n                   && _mediaEncoder.SupportsFilter(\"scale_opencl\")\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.TonemapOpenclBt2390)\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.OverlayOpenclFrameSync);\n        }\n\n        private bool IsCudaFullSupported()\n        {\n            return _mediaEncoder.SupportsHwaccel(\"cuda\")\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.ScaleCudaFormat)\n                   && _mediaEncoder.SupportsFilter(\"yadif_cuda\")\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.TonemapCudaName)\n                   && _mediaEncoder.SupportsFilter(\"overlay_cuda\")\n                   && _mediaEncoder.SupportsFilter(\"hwupload_cuda\");\n        }\n\n        private bool IsHwTonemapAvailable(EncodingJobInfo state, EncodingOptions options)\n        {\n            if (state.VideoStream == null\n                || !options.EnableTonemapping\n                || GetVideoColorBitDepth(state) != 10)\n            {\n                return false;\n            }\n\n            if (string.Equals(state.VideoStream.Codec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                && string.Equals(state.VideoStream.VideoRange, \"HDR\", StringComparison.OrdinalIgnoreCase)\n                && string.Equals(state.VideoStream.VideoRangeType, \"DOVI\", StringComparison.OrdinalIgnoreCase))\n            {\n                // Only native SW decoder and HW accelerator can parse dovi rpu.\n                var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n                var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n                var isNvdecDecoder = vidDecoder.Contains(\"cuda\", StringComparison.OrdinalIgnoreCase);\n                var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n                return isSwDecoder || isNvdecDecoder || isVaapiDecoder || isD3d11vaDecoder;\n            }\n\n            return string.Equals(state.VideoStream.VideoRange, \"HDR\", StringComparison.OrdinalIgnoreCase)\n                   && (string.Equals(state.VideoStream.VideoRangeType, \"HDR10\", StringComparison.OrdinalIgnoreCase)\n                       || string.Equals(state.VideoStream.VideoRangeType, \"HLG\", StringComparison.OrdinalIgnoreCase));\n        }\n\n        private bool IsVaapiVppTonemapAvailable(EncodingJobInfo state, EncodingOptions options)\n        {\n            if (state.VideoStream == null\n                || !options.EnableVppTonemapping\n                || GetVideoColorBitDepth(state) != 10)\n            {\n                return false;\n            }\n\n            // Native VPP tonemapping may come to QSV in the future.\n\n            return string.Equals(state.VideoStream.VideoRange, \"HDR\", StringComparison.OrdinalIgnoreCase)\n                   && string.Equals(state.VideoStream.VideoRangeType, \"HDR10\", StringComparison.OrdinalIgnoreCase);\n        }\n\n        /// <summary>\n        /// Gets the name of the output video codec.\n        /// </summary>\n        /// <param name=\"state\">Encording state.</param>\n        /// <param name=\"encodingOptions\">Encoding options.</param>\n        /// <returns>Encoder string.</returns>\n        public string GetVideoEncoder(EncodingJobInfo state, EncodingOptions encodingOptions)\n        {\n            var codec = state.OutputVideoCodec;\n\n            if (!string.IsNullOrEmpty(codec))\n            {\n                if (string.Equals(codec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(codec, \"hevc\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetH265Encoder(state, encodingOptions);\n                }\n\n                if (string.Equals(codec, \"h264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetH264Encoder(state, encodingOptions);\n                }\n\n                if (string.Equals(codec, \"vp8\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(codec, \"vpx\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return \"libvpx\";\n                }\n\n                if (string.Equals(codec, \"vp9\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return \"libvpx-vp9\";\n                }\n\n                if (string.Equals(codec, \"wmv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return \"wmv2\";\n                }\n\n                if (string.Equals(codec, \"theora\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return \"libtheora\";\n                }\n\n                return codec.ToLowerInvariant();\n            }\n\n            return \"copy\";\n        }\n\n        /// <summary>\n        /// Gets the user agent param.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <returns>System.String.</returns>\n        public string GetUserAgentParam(EncodingJobInfo state)\n        {\n            if (state.RemoteHttpHeaders.TryGetValue(\"User-Agent\", out string useragent))\n            {\n                return \"-user_agent \\\"\" + useragent + \"\\\"\";\n            }\n\n            return string.Empty;\n        }\n\n        public static string GetInputFormat(string container)\n        {\n            if (string.IsNullOrEmpty(container))\n            {\n                return null;\n            }\n\n            container = container.Replace(\"mkv\", \"matroska\", StringComparison.OrdinalIgnoreCase);\n\n            if (string.Equals(container, \"ts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"mpegts\";\n            }\n\n            // For these need to find out the ffmpeg names\n            if (string.Equals(container, \"m2ts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"wmv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"mts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"vob\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"mpg\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"mpeg\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"rec\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"dvr-ms\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"ogm\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"divx\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"tp\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"rmvb\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"rtp\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            // Seeing reported failures here, not sure yet if this is related to specifying input format\n            if (string.Equals(container, \"m4v\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            // obviously don't do this for strm files\n            if (string.Equals(container, \"strm\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            // ISO files don't have an ffmpeg format\n            if (string.Equals(container, \"iso\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            return container;\n        }\n\n        /// <summary>\n        /// Gets decoder from a codec.\n        /// </summary>\n        /// <param name=\"codec\">Codec to use.</param>\n        /// <returns>Decoder string.</returns>\n        public string GetDecoderFromCodec(string codec)\n        {\n            // For these need to find out the ffmpeg names\n            if (string.Equals(codec, \"mp2\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(codec, \"aac_latm\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(codec, \"eac3\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (_mediaEncoder.SupportsDecoder(codec))\n            {\n                return codec;\n            }\n\n            return null;\n        }\n\n        /// <summary>\n        /// Infers the audio codec based on the url.\n        /// </summary>\n        /// <param name=\"container\">Container to use.</param>\n        /// <returns>Codec string.</returns>\n        public string InferAudioCodec(string container)\n        {\n            var ext = \".\" + (container ?? string.Empty);\n\n            if (string.Equals(ext, \".mp3\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"mp3\";\n            }\n\n            if (string.Equals(ext, \".aac\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"aac\";\n            }\n\n            if (string.Equals(ext, \".wma\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"wma\";\n            }\n\n            if (string.Equals(ext, \".ogg\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            if (string.Equals(ext, \".oga\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            if (string.Equals(ext, \".ogv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            if (string.Equals(ext, \".webm\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            if (string.Equals(ext, \".webma\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            return \"copy\";\n        }\n\n        /// <summary>\n        /// Infers the video codec.\n        /// </summary>\n        /// <param name=\"url\">The URL.</param>\n        /// <returns>System.Nullable{VideoCodecs}.</returns>\n        public string InferVideoCodec(string url)\n        {\n            var ext = Path.GetExtension(url);\n\n            if (string.Equals(ext, \".asf\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"wmv\";\n            }\n\n            if (string.Equals(ext, \".webm\", StringComparison.OrdinalIgnoreCase))\n            {\n                // TODO: this may not always mean VP8, as the codec ages\n                return \"vp8\";\n            }\n\n            if (string.Equals(ext, \".ogg\", StringComparison.OrdinalIgnoreCase) || string.Equals(ext, \".ogv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"theora\";\n            }\n\n            if (string.Equals(ext, \".m3u8\", StringComparison.OrdinalIgnoreCase) || string.Equals(ext, \".ts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"h264\";\n            }\n\n            return \"copy\";\n        }\n\n        public int GetVideoProfileScore(string videoCodec, string videoProfile)\n        {\n            // strip spaces because they may be stripped out on the query string\n            string profile = videoProfile.Replace(\" \", string.Empty, StringComparison.Ordinal);\n            if (string.Equals(\"h264\", videoCodec, StringComparison.OrdinalIgnoreCase))\n            {\n                return Array.FindIndex(_videoProfilesH264, x => string.Equals(x, profile, StringComparison.OrdinalIgnoreCase));\n            }\n            else if (string.Equals(\"hevc\", videoCodec, StringComparison.OrdinalIgnoreCase))\n            {\n                return Array.FindIndex(_videoProfilesH265, x => string.Equals(x, profile, StringComparison.OrdinalIgnoreCase));\n            }\n\n            return -1;\n        }\n\n        public string GetInputPathArgument(EncodingJobInfo state)\n        {\n            var mediaPath = state.MediaPath ?? string.Empty;\n\n            return _mediaEncoder.GetInputArgument(mediaPath, state.MediaSource);\n        }\n\n        /// <summary>\n        /// Gets the audio encoder.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <returns>System.String.</returns>\n        public string GetAudioEncoder(EncodingJobInfo state)\n        {\n            var codec = state.OutputAudioCodec;\n\n            if (string.Equals(codec, \"aac\", StringComparison.OrdinalIgnoreCase))\n            {\n                // Use libfdk_aac for better audio quality if using custom build of FFmpeg which has fdk_aac support\n                if (_mediaEncoder.SupportsEncoder(\"libfdk_aac\"))\n                {\n                    return \"libfdk_aac\";\n                }\n\n                return \"aac\";\n            }\n\n            if (string.Equals(codec, \"mp3\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"libmp3lame\";\n            }\n\n            if (string.Equals(codec, \"vorbis\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"libvorbis\";\n            }\n\n            if (string.Equals(codec, \"wma\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"wmav2\";\n            }\n\n            if (string.Equals(codec, \"opus\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"libopus\";\n            }\n\n            if (string.Equals(codec, \"flac\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"flac\";\n            }\n\n            if (string.Equals(codec, \"dts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"dca\";\n            }\n\n            return codec.ToLowerInvariant();\n        }\n\n        private string GetVideoToolboxDeviceArgs(string alias)\n        {\n            alias ??= VideotoolboxAlias;\n\n            // device selection in vt is not supported.\n            return \" -init_hw_device videotoolbox=\" + alias;\n        }\n\n        private string GetCudaDeviceArgs(int deviceIndex, string alias)\n        {\n            alias ??= CudaAlias;\n            deviceIndex = deviceIndex >= 0\n                ? deviceIndex\n                : 0;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \" -init_hw_device cuda={0}:{1}\",\n                alias,\n                deviceIndex);\n        }\n\n        private string GetOpenclDeviceArgs(int deviceIndex, string deviceVendorName, string srcDeviceAlias, string alias)\n        {\n            alias ??= OpenclAlias;\n            deviceIndex = deviceIndex >= 0\n                ? deviceIndex\n                : 0;\n            var vendorOpts = string.IsNullOrEmpty(deviceVendorName)\n                ? \":0.0\"\n                : \":.\" + deviceIndex + \",device_vendor=\\\"\" + deviceVendorName + \"\\\"\";\n            var options = string.IsNullOrEmpty(srcDeviceAlias)\n                ? vendorOpts\n                : \"@\" + srcDeviceAlias;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \" -init_hw_device opencl={0}{1}\",\n                alias,\n                options);\n        }\n\n        private string GetD3d11vaDeviceArgs(int deviceIndex, string deviceVendorId, string alias)\n        {\n            alias ??= D3d11vaAlias;\n            deviceIndex = deviceIndex >= 0 ? deviceIndex : 0;\n            var options = string.IsNullOrEmpty(deviceVendorId)\n                ? deviceIndex.ToString(CultureInfo.InvariantCulture)\n                : \",vendor=\" + deviceVendorId;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \" -init_hw_device d3d11va={0}:{1}\",\n                alias,\n                options);\n        }\n\n        private string GetVaapiDeviceArgs(string renderNodePath, string driver, string kernelDriver, string alias)\n        {\n            alias ??= VaapiAlias;\n\n            // 'renderNodePath' has higher priority than 'kernelDriver'\n            var driverOpts = string.IsNullOrEmpty(renderNodePath)\n                ? (string.IsNullOrEmpty(kernelDriver) ? string.Empty : \",kernel_driver=\" + kernelDriver)\n                : renderNodePath;\n\n            // 'driver' behaves similarly to env LIBVA_DRIVER_NAME\n            driverOpts += string.IsNullOrEmpty(driver) ? string.Empty : \",driver=\" + driver;\n\n            var options = string.IsNullOrEmpty(driverOpts) ? string.Empty : \":\" + driverOpts;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \" -init_hw_device vaapi={0}{1}\",\n                alias,\n                options);\n        }\n\n        private string GetQsvDeviceArgs(string alias)\n        {\n            var arg = \" -init_hw_device qsv=\" + (alias ?? QsvAlias);\n            if (OperatingSystem.IsLinux())\n            {\n                // derive qsv from vaapi device\n                return GetVaapiDeviceArgs(null, \"iHD\", \"i915\", VaapiAlias) + arg + \"@\" + VaapiAlias;\n            }\n\n            if (OperatingSystem.IsWindows())\n            {\n                // derive qsv from d3d11va device\n                return GetD3d11vaDeviceArgs(0, \"0x8086\", D3d11vaAlias) + arg + \"@\" + D3d11vaAlias;\n            }\n\n            return null;\n        }\n\n        private string GetFilterHwDeviceArgs(string alias)\n        {\n            return string.IsNullOrEmpty(alias)\n                ? string.Empty\n                : \" -filter_hw_device \" + alias;\n        }\n\n        public string GetGraphicalSubCanvasSize(EncodingJobInfo state)\n        {\n            // DVBSUB and DVDSUB use the fixed canvas size 720x576\n            if (state.SubtitleStream != null\n                && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode\n                && !state.SubtitleStream.IsTextSubtitleStream\n                && !string.Equals(state.SubtitleStream.Codec, \"DVBSUB\", StringComparison.OrdinalIgnoreCase)\n                && !string.Equals(state.SubtitleStream.Codec, \"DVDSUB\", StringComparison.OrdinalIgnoreCase))\n            {\n                var inW = state.VideoStream?.Width;\n                var inH = state.VideoStream?.Height;\n                var reqW = state.BaseRequest.Width;\n                var reqH = state.BaseRequest.Height;\n                var reqMaxW = state.BaseRequest.MaxWidth;\n                var reqMaxH = state.BaseRequest.MaxHeight;\n\n                // setup a relative small canvas_size for overlay_qsv/vaapi to reduce transfer overhead\n                var (overlayW, overlayH) = GetFixedOutputSize(inW, inH, reqW, reqH, reqMaxW, 1080);\n\n                if (overlayW.HasValue && overlayH.HasValue)\n                {\n                    return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \" -canvas_size {0}x{1}\",\n                        overlayW.Value,\n                        overlayH.Value);\n                }\n            }\n\n            return string.Empty;\n        }\n\n        /// <summary>\n        /// Gets the input video hwaccel argument.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <returns>Input video hwaccel arguments.</returns>\n        public string GetInputVideoHwaccelArgs(EncodingJobInfo state, EncodingOptions options)\n        {\n            if (!state.IsVideoRequest)\n            {\n                return string.Empty;\n            }\n\n            var vidEncoder = GetVideoEncoder(state, options) ?? string.Empty;\n            if (IsCopyCodec(vidEncoder))\n            {\n                return string.Empty;\n            }\n\n            var args = new StringBuilder();\n            var isWindows = OperatingSystem.IsWindows();\n            var isLinux = OperatingSystem.IsLinux();\n            var isMacOS = OperatingSystem.IsMacOS();\n            var optHwaccelType = options.HardwareAccelerationType;\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isHwTonemapAvailable = IsHwTonemapAvailable(state, options);\n\n            if (string.Equals(optHwaccelType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (!isLinux || !_mediaEncoder.SupportsHwaccel(\"vaapi\"))\n                {\n                    return string.Empty;\n                }\n\n                var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                var isVaapiEncoder = vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                if (!isVaapiDecoder && !isVaapiEncoder)\n                {\n                    return string.Empty;\n                }\n\n                if (_mediaEncoder.IsVaapiDeviceInteliHD)\n                {\n                    args.Append(GetVaapiDeviceArgs(options.VaapiDevice, \"iHD\", null, VaapiAlias));\n                }\n                else if (_mediaEncoder.IsVaapiDeviceInteli965)\n                {\n                    // Only override i965 since it has lower priority than iHD in libva lookup.\n                    Environment.SetEnvironmentVariable(\"LIBVA_DRIVER_NAME\", \"i965\");\n                    Environment.SetEnvironmentVariable(\"LIBVA_DRIVER_NAME_JELLYFIN\", \"i965\");\n                    args.Append(GetVaapiDeviceArgs(options.VaapiDevice, \"i965\", null, VaapiAlias));\n                }\n                else\n                {\n                    args.Append(GetVaapiDeviceArgs(options.VaapiDevice, null, null, VaapiAlias));\n                }\n\n                var filterDevArgs = GetFilterHwDeviceArgs(VaapiAlias);\n\n                if (isHwTonemapAvailable && IsOpenclFullSupported())\n                {\n                    if (_mediaEncoder.IsVaapiDeviceInteliHD || _mediaEncoder.IsVaapiDeviceInteli965)\n                    {\n                        if (!isVaapiDecoder)\n                        {\n                            args.Append(GetOpenclDeviceArgs(0, null, VaapiAlias, OpenclAlias));\n                            filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                        }\n                    }\n                    else if (_mediaEncoder.IsVaapiDeviceAmd)\n                    {\n                        args.Append(GetOpenclDeviceArgs(0, \"Advanced Micro Devices\", null, OpenclAlias));\n                        filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                    }\n                    else\n                    {\n                        args.Append(GetOpenclDeviceArgs(0, null, null, OpenclAlias));\n                        filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                    }\n                }\n\n                args.Append(filterDevArgs);\n            }\n            else if (string.Equals(optHwaccelType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                if ((!isLinux && !isWindows) || !_mediaEncoder.SupportsHwaccel(\"qsv\"))\n                {\n                    return string.Empty;\n                }\n\n                var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n                var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                var isQsvDecoder = vidDecoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n                var isQsvEncoder = vidEncoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n                var isHwDecoder = isQsvDecoder || isVaapiDecoder || isD3d11vaDecoder;\n                if (!isHwDecoder && !isQsvEncoder)\n                {\n                    return string.Empty;\n                }\n\n                args.Append(GetQsvDeviceArgs(QsvAlias));\n                var filterDevArgs = GetFilterHwDeviceArgs(QsvAlias);\n                // child device used by qsv.\n                if (_mediaEncoder.SupportsHwaccel(\"vaapi\") || _mediaEncoder.SupportsHwaccel(\"d3d11va\"))\n                {\n                    if (isHwTonemapAvailable && IsOpenclFullSupported())\n                    {\n                        var srcAlias = isLinux ? VaapiAlias : D3d11vaAlias;\n                        args.Append(GetOpenclDeviceArgs(0, null, srcAlias, OpenclAlias));\n                        if (!isHwDecoder)\n                        {\n                            filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                        }\n                    }\n                }\n\n                args.Append(filterDevArgs);\n            }\n            else if (string.Equals(optHwaccelType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                if ((!isLinux && !isWindows) || !IsCudaFullSupported())\n                {\n                    return string.Empty;\n                }\n\n                var isCuvidDecoder = vidDecoder.Contains(\"cuvid\", StringComparison.OrdinalIgnoreCase);\n                var isNvdecDecoder = vidDecoder.Contains(\"cuda\", StringComparison.OrdinalIgnoreCase);\n                var isNvencEncoder = vidEncoder.Contains(\"nvenc\", StringComparison.OrdinalIgnoreCase);\n                var isHwDecoder = isNvdecDecoder || isCuvidDecoder;\n                if (!isHwDecoder && !isNvencEncoder)\n                {\n                    return string.Empty;\n                }\n\n                args.Append(GetCudaDeviceArgs(0, CudaAlias))\n                     .Append(GetFilterHwDeviceArgs(CudaAlias));\n            }\n            else if (string.Equals(optHwaccelType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (!isWindows || !_mediaEncoder.SupportsHwaccel(\"d3d11va\"))\n                {\n                    return string.Empty;\n                }\n\n                var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n                var isAmfEncoder = vidEncoder.Contains(\"amf\", StringComparison.OrdinalIgnoreCase);\n                if (!isD3d11vaDecoder && !isAmfEncoder)\n                {\n                    return string.Empty;\n                }\n\n                // no dxva video processor hw filter.\n                args.Append(GetD3d11vaDeviceArgs(0, \"0x1002\", D3d11vaAlias));\n                var filterDevArgs = string.Empty;\n                if (IsOpenclFullSupported())\n                {\n                    args.Append(GetOpenclDeviceArgs(0, null, D3d11vaAlias, OpenclAlias));\n                    filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                }\n\n                args.Append(filterDevArgs);\n            }\n            else if (string.Equals(optHwaccelType, \"videotoolbox\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (!isMacOS || !_mediaEncoder.SupportsHwaccel(\"videotoolbox\"))\n                {\n                    return string.Empty;\n                }\n\n                var isVideotoolboxDecoder = vidDecoder.Contains(\"videotoolbox\", StringComparison.OrdinalIgnoreCase);\n                var isVideotoolboxEncoder = vidEncoder.Contains(\"videotoolbox\", StringComparison.OrdinalIgnoreCase);\n                if (!isVideotoolboxDecoder && !isVideotoolboxEncoder)\n                {\n                    return string.Empty;\n                }\n\n                // no videotoolbox hw filter.\n                args.Append(GetVideoToolboxDeviceArgs(VideotoolboxAlias));\n            }\n\n            if (!string.IsNullOrEmpty(vidDecoder))\n            {\n                args.Append(vidDecoder);\n            }\n\n            // hw transpose filters should be added manually.\n            args.Append(\" -autorotate 0\");\n\n            return args.ToString().Trim();\n        }\n\n        /// <summary>\n        /// Gets the input argument.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"segmentContainer\">Segment Container.</param>\n        /// <returns>Input arguments.</returns>\n        public string GetInputArgument(EncodingJobInfo state, EncodingOptions options, string segmentContainer)\n        {\n            var arg = new StringBuilder();\n            var inputVidHwaccelArgs = GetInputVideoHwaccelArgs(state, options);\n\n            if (!string.IsNullOrEmpty(inputVidHwaccelArgs))\n            {\n                arg.Append(inputVidHwaccelArgs);\n            }\n\n            var canvasArgs = GetGraphicalSubCanvasSize(state);\n            if (!string.IsNullOrEmpty(canvasArgs))\n            {\n                arg.Append(canvasArgs);\n            }\n\n            arg.Append(\" -i \")\n                .Append(GetInputPathArgument(state));\n\n            // sub2video for external graphical subtitles\n            if (state.SubtitleStream != null\n                && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode\n                && !state.SubtitleStream.IsTextSubtitleStream\n                && state.SubtitleStream.IsExternal)\n            {\n                var subtitlePath = state.SubtitleStream.Path;\n\n                if (string.Equals(Path.GetExtension(subtitlePath), \".sub\", StringComparison.OrdinalIgnoreCase))\n                {\n                    var idxFile = Path.ChangeExtension(subtitlePath, \".idx\");\n                    if (File.Exists(idxFile))\n                    {\n                        subtitlePath = idxFile;\n                    }\n                }\n\n                // Also seek the external subtitles stream.\n                var seekSubParam = GetFastSeekCommandLineParameter(state, options, segmentContainer);\n                if (!string.IsNullOrEmpty(seekSubParam))\n                {\n                    arg.Append(' ').Append(seekSubParam);\n                }\n\n                if (!string.IsNullOrEmpty(canvasArgs))\n                {\n                    arg.Append(canvasArgs);\n                }\n\n                arg.Append(\" -i file:\\\"\").Append(subtitlePath).Append('\\\"');\n            }\n\n            if (state.AudioStream != null && state.AudioStream.IsExternal)\n            {\n                // Also seek the external audio stream.\n                var seekAudioParam = GetFastSeekCommandLineParameter(state, options, segmentContainer);\n                if (!string.IsNullOrEmpty(seekAudioParam))\n                {\n                    arg.Append(' ').Append(seekAudioParam);\n                }\n\n                arg.Append(\" -i \\\"\").Append(state.AudioStream.Path).Append('\"');\n            }\n\n            // Disable auto inserted SW scaler for HW decoders in case of changed resolution.\n            var isSwDecoder = string.IsNullOrEmpty(GetHardwareVideoDecoder(state, options));\n            if (!isSwDecoder)\n            {\n                arg.Append(\" -autoscale 0\");\n            }\n\n            return arg.ToString();\n        }\n\n        /// <summary>\n        /// Determines whether the specified stream is H264.\n        /// </summary>\n        /// <param name=\"stream\">The stream.</param>\n        /// <returns><c>true</c> if the specified stream is H264; otherwise, <c>false</c>.</returns>\n        public static bool IsH264(MediaStream stream)\n        {\n            var codec = stream.Codec ?? string.Empty;\n\n            return codec.IndexOf(\"264\", StringComparison.OrdinalIgnoreCase) != -1\n                    || codec.IndexOf(\"avc\", StringComparison.OrdinalIgnoreCase) != -1;\n        }\n\n        public static bool IsH265(MediaStream stream)\n        {\n            var codec = stream.Codec ?? string.Empty;\n\n            return codec.IndexOf(\"265\", StringComparison.OrdinalIgnoreCase) != -1\n                || codec.IndexOf(\"hevc\", StringComparison.OrdinalIgnoreCase) != -1;\n        }\n\n        public static bool IsAAC(MediaStream stream)\n        {\n            var codec = stream.Codec ?? string.Empty;\n\n            return codec.IndexOf(\"aac\", StringComparison.OrdinalIgnoreCase) != -1;\n        }\n\n        public static string GetBitStreamArgs(MediaStream stream)\n        {\n            // TODO This is auto inserted into the mpegts mux so it might not be needed.\n            // https://www.ffmpeg.org/ffmpeg-bitstream-filters.html#h264_005fmp4toannexb\n            if (IsH264(stream))\n            {\n                return \"-bsf:v h264_mp4toannexb\";\n            }\n            else if (IsH265(stream))\n            {\n                return \"-bsf:v hevc_mp4toannexb\";\n            }\n            else if (IsAAC(stream))\n            {\n                // Convert adts header(mpegts) to asc header(mp4).\n                return \"-bsf:a aac_adtstoasc\";\n            }\n            else\n            {\n                return null;\n            }\n        }\n\n        public static string GetAudioBitStreamArguments(EncodingJobInfo state, string segmentContainer, string mediaSourceContainer)\n        {\n            var bitStreamArgs = string.Empty;\n            var segmentFormat = GetSegmentFileExtension(segmentContainer).TrimStart('.');\n\n            // Apply aac_adtstoasc bitstream filter when media source is in mpegts.\n            if (string.Equals(segmentFormat, \"mp4\", StringComparison.OrdinalIgnoreCase)\n                && (string.Equals(mediaSourceContainer, \"mpegts\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(mediaSourceContainer, \"aac\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(mediaSourceContainer, \"hls\", StringComparison.OrdinalIgnoreCase)))\n            {\n                bitStreamArgs = GetBitStreamArgs(state.AudioStream);\n                bitStreamArgs = string.IsNullOrEmpty(bitStreamArgs) ? string.Empty : \" \" + bitStreamArgs;\n            }\n\n            return bitStreamArgs;\n        }\n\n        public static string GetSegmentFileExtension(string segmentContainer)\n        {\n            if (!string.IsNullOrWhiteSpace(segmentContainer))\n            {\n                return \".\" + segmentContainer;\n            }\n\n            return \".ts\";\n        }\n\n        public string GetVideoBitrateParam(EncodingJobInfo state, string videoCodec)\n        {\n            if (state.OutputVideoBitrate == null)\n            {\n                return string.Empty;\n            }\n\n            int bitrate = state.OutputVideoBitrate.Value;\n\n            // Currently use the same buffer size for all encoders\n            int bufsize = bitrate * 2;\n\n            if (string.Equals(videoCodec, \"libvpx\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(videoCodec, \"libvpx-vp9\", StringComparison.OrdinalIgnoreCase))\n            {\n                // When crf is used with vpx, b:v becomes a max rate\n                // https://trac.ffmpeg.org/wiki/Encode/VP8\n                // https://trac.ffmpeg.org/wiki/Encode/VP9\n                return FormattableString.Invariant($\" -maxrate:v {bitrate} -bufsize:v {bufsize} -b:v {bitrate}\");\n            }\n\n            if (string.Equals(videoCodec, \"msmpeg4\", StringComparison.OrdinalIgnoreCase))\n            {\n                return FormattableString.Invariant($\" -b:v {bitrate}\");\n            }\n\n            if (string.Equals(videoCodec, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(videoCodec, \"libx265\", StringComparison.OrdinalIgnoreCase))\n            {\n                return FormattableString.Invariant($\" -maxrate {bitrate} -bufsize {bufsize}\");\n            }\n\n            if (string.Equals(videoCodec, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(videoCodec, \"hevc_amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                // Override the too high default qmin 18 in transcoding preset\n                return FormattableString.Invariant($\" -rc cbr -qmin 0 -qmax 32 -b:v {bitrate} -maxrate {bitrate} -bufsize {bufsize}\");\n            }\n\n            if (string.Equals(videoCodec, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(videoCodec, \"hevc_vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                // VBR in i965 driver may result in pixelated output.\n                if (_mediaEncoder.IsVaapiDeviceInteli965)\n                {\n                    return FormattableString.Invariant($\" -rc_mode CBR -b:v {bitrate} -maxrate {bitrate} -bufsize {bufsize}\");\n                }\n                else\n                {\n                    return FormattableString.Invariant($\" -rc_mode VBR -b:v {bitrate} -maxrate {bitrate} -bufsize {bufsize}\");\n                }\n            }\n\n            return FormattableString.Invariant($\" -b:v {bitrate} -maxrate {bitrate} -bufsize {bufsize}\");\n        }\n\n        public static string NormalizeTranscodingLevel(EncodingJobInfo state, string level)\n        {\n            if (double.TryParse(level, NumberStyles.Any, CultureInfo.InvariantCulture, out double requestLevel))\n            {\n                if (string.Equals(state.ActualOutputVideoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.ActualOutputVideoCodec, \"h265\", StringComparison.OrdinalIgnoreCase))\n                {\n                    // Transcode to level 5.0 and lower for maximum compatibility.\n                    // Level 5.0 is suitable for up to 4k 30fps hevc encoding, otherwise let the encoder to handle it.\n                    // https://en.wikipedia.org/wiki/High_Efficiency_Video_Coding_tiers_and_levels\n                    // MaxLumaSampleRate = 3840*2160*30 = 248832000 < 267386880.\n                    if (requestLevel >= 150)\n                    {\n                        return \"150\";\n                    }\n                }\n                else if (string.Equals(state.ActualOutputVideoCodec, \"h264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    // Transcode to level 5.1 and lower for maximum compatibility.\n                    // h264 4k 30fps requires at least level 5.1 otherwise it will break on safari fmp4.\n                    // https://en.wikipedia.org/wiki/Advanced_Video_Coding#Levels\n                    if (requestLevel >= 51)\n                    {\n                        return \"51\";\n                    }\n                }\n            }\n\n            return level;\n        }\n\n        /// <summary>\n        /// Gets the text subtitle param.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <param name=\"enableAlpha\">Enable alpha processing.</param>\n        /// <param name=\"enableSub2video\">Enable sub2video mode.</param>\n        /// <returns>System.String.</returns>\n        public string GetTextSubtitlesFilter(EncodingJobInfo state, bool enableAlpha, bool enableSub2video)\n        {\n            var seconds = Math.Round(TimeSpan.FromTicks(state.StartTimeTicks ?? 0).TotalSeconds);\n\n            // hls always copies timestamps\n            var setPtsParam = state.CopyTimestamps || state.TranscodingType != TranscodingJobType.Progressive\n                ? string.Empty\n                : string.Format(CultureInfo.InvariantCulture, \",setpts=PTS -{0}/TB\", seconds);\n\n            var alphaParam = enableAlpha ? \":alpha=1\" : string.Empty;\n            var sub2videoParam = enableSub2video ? \":sub2video=1\" : string.Empty;\n\n            var fontPath = Path.Combine(_appPaths.CachePath, \"attachments\", state.MediaSource.Id);\n            var fontParam = string.Format(\n                CultureInfo.InvariantCulture,\n                \":fontsdir='{0}'\",\n                _mediaEncoder.EscapeSubtitleFilterPath(fontPath));\n\n            // TODO\n            // var fallbackFontPath = Path.Combine(_appPaths.ProgramDataPath, \"fonts\", \"DroidSansFallback.ttf\");\n            // string fallbackFontParam = string.Empty;\n\n            // if (!File.Exists(fallbackFontPath))\n            // {\n            //     _fileSystem.CreateDirectory(_fileSystem.GetDirectoryName(fallbackFontPath));\n            //     using (var stream = _assemblyInfo.GetManifestResourceStream(GetType(), GetType().Namespace + \".DroidSansFallback.ttf\"))\n            //     {\n            //         using (var fileStream = new FileStream(fallbackFontPath, FileMode.Create, FileAccess.Write, FileShare.Read))\n            //         {\n            //             stream.CopyTo(fileStream);\n            //         }\n            //     }\n            // }\n\n            // fallbackFontParam = string.Format(CultureInfo.InvariantCulture, \":force_style='FontName=Droid Sans Fallback':fontsdir='{0}'\", _mediaEncoder.EscapeSubtitleFilterPath(_fileSystem.GetDirectoryName(fallbackFontPath)));\n\n            if (state.SubtitleStream.IsExternal)\n            {\n                var charsetParam = string.Empty;\n\n                if (!string.IsNullOrEmpty(state.SubtitleStream.Language))\n                {\n                    var charenc = _subtitleEncoder.GetSubtitleFileCharacterSet(\n                            state.SubtitleStream,\n                            state.SubtitleStream.Language,\n                            state.MediaSource,\n                            CancellationToken.None).GetAwaiter().GetResult();\n\n                    if (!string.IsNullOrEmpty(charenc))\n                    {\n                        charsetParam = \":charenc=\" + charenc;\n                    }\n                }\n\n                // TODO: Perhaps also use original_size=1920x800 ??\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"subtitles=f='{0}'{1}{2}{3}{4}{5}\",\n                    _mediaEncoder.EscapeSubtitleFilterPath(state.SubtitleStream.Path),\n                    charsetParam,\n                    alphaParam,\n                    sub2videoParam,\n                    fontParam,\n                    // fallbackFontParam,\n                    setPtsParam);\n            }\n\n            var mediaPath = state.MediaPath ?? string.Empty;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"subtitles=f='{0}':si={1}{2}{3}{4}{5}\",\n                _mediaEncoder.EscapeSubtitleFilterPath(mediaPath),\n                state.InternalSubtitleStreamOffset.ToString(CultureInfo.InvariantCulture),\n                alphaParam,\n                sub2videoParam,\n                fontParam,\n                // fallbackFontParam,\n                setPtsParam);\n        }\n\n        public double? GetFramerateParam(EncodingJobInfo state)\n        {\n            var request = state.BaseRequest;\n\n            if (request.Framerate.HasValue)\n            {\n                return request.Framerate.Value;\n            }\n\n            var maxrate = request.MaxFramerate;\n\n            if (maxrate.HasValue && state.VideoStream != null)\n            {\n                var contentRate = state.VideoStream.AverageFrameRate ?? state.VideoStream.RealFrameRate;\n\n                if (contentRate.HasValue && contentRate.Value > maxrate.Value)\n                {\n                    return maxrate;\n                }\n            }\n\n            return null;\n        }\n\n        public string GetHlsVideoKeyFrameArguments(\n            EncodingJobInfo state,\n            string codec,\n            int segmentLength,\n            bool isEventPlaylist,\n            int? startNumber)\n        {\n            var args = string.Empty;\n            var gopArg = string.Empty;\n            var keyFrameArg = string.Empty;\n            if (isEventPlaylist)\n            {\n                keyFrameArg = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -force_key_frames:0 \\\"expr:gte(t,n_forced*{0})\\\"\",\n                    segmentLength);\n            }\n            else if (startNumber.HasValue)\n            {\n                keyFrameArg = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -force_key_frames:0 \\\"expr:gte(t,{0}+n_forced*{1})\\\"\",\n                    startNumber.Value * segmentLength,\n                    segmentLength);\n            }\n\n            var framerate = state.VideoStream?.RealFrameRate;\n            if (framerate.HasValue)\n            {\n                // This is to make sure keyframe interval is limited to our segment,\n                // as forcing keyframes is not enough.\n                // Example: we encoded half of desired length, then codec detected\n                // scene cut and inserted a keyframe; next forced keyframe would\n                // be created outside of segment, which breaks seeking.\n                gopArg = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -g:v:0 {0} -keyint_min:v:0 {0}\",\n                    Math.Ceiling(segmentLength * framerate.Value));\n            }\n\n            // Unable to force key frames using these encoders, set key frames by GOP.\n            if (string.Equals(codec, \"h264_qsv\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc_qsv\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc_nvenc\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc_amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                args += gopArg;\n            }\n            else if (string.Equals(codec, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                     || string.Equals(codec, \"libx265\", StringComparison.OrdinalIgnoreCase)\n                     || string.Equals(codec, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase)\n                     || string.Equals(codec, \"hevc_vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                args += keyFrameArg;\n\n                // prevent the libx264 from post processing to break the set keyframe.\n                if (string.Equals(codec, \"libx264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    args += \" -sc_threshold:v:0 0\";\n                }\n            }\n            else\n            {\n                args += keyFrameArg + gopArg;\n            }\n\n            // global_header produced by AMD VA-API encoder causes non-playable fMP4 on iOS\n            if (codec.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase)\n                && _mediaEncoder.IsVaapiDeviceAmd)\n            {\n                args += \" -flags:v -global_header\";\n            }\n\n            return args;\n        }\n\n        /// <summary>\n        /// Gets the video bitrate to specify on the command line.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"videoEncoder\">Video encoder to use.</param>\n        /// <param name=\"encodingOptions\">Encoding options.</param>\n        /// <param name=\"defaultPreset\">Default present to use for encoding.</param>\n        /// <returns>Video bitrate.</returns>\n        public string GetVideoQualityParam(EncodingJobInfo state, string videoEncoder, EncodingOptions encodingOptions, string defaultPreset)\n        {\n            var param = string.Empty;\n\n            // Tutorials: Enable Intel GuC / HuC firmware loading for Low Power Encoding.\n            // https://01.org/linuxgraphics/downloads/firmware\n            // https://wiki.archlinux.org/title/intel_graphics#Enable_GuC_/_HuC_firmware_loading\n            // Intel Low Power Encoding can save unnecessary CPU-GPU synchronization,\n            // which will reduce overhead in performance intensive tasks such as 4k transcoding and tonemapping.\n            var intelLowPowerHwEncoding = false;\n\n            // Workaround for linux 5.18 to 6.1.3 i915 hang at cost of performance.\n            // https://github.com/intel/media-driver/issues/1456\n            var enableWaFori915Hang = false;\n\n            if (string.Equals(encodingOptions.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                var isIntelVaapiDriver = _mediaEncoder.IsVaapiDeviceInteliHD || _mediaEncoder.IsVaapiDeviceInteli965;\n\n                if (string.Equals(videoEncoder, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase))\n                {\n                    intelLowPowerHwEncoding = encodingOptions.EnableIntelLowPowerH264HwEncoder && isIntelVaapiDriver;\n                }\n                else if (string.Equals(videoEncoder, \"hevc_vaapi\", StringComparison.OrdinalIgnoreCase))\n                {\n                    intelLowPowerHwEncoding = encodingOptions.EnableIntelLowPowerHevcHwEncoder && isIntelVaapiDriver;\n                }\n            }\n            else if (string.Equals(encodingOptions.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (OperatingSystem.IsLinux())\n                {\n                    var ver = Environment.OSVersion.Version;\n                    var isFixedKernel60 = ver.Major == 6 && ver.Minor == 0 && ver >= _minFixedKernel60i915Hang;\n                    var isUnaffectedKernel = ver < _minKerneli915Hang || ver > _maxKerneli915Hang;\n\n                    if (!(isUnaffectedKernel || isFixedKernel60))\n                    {\n                        var vidDecoder = GetHardwareVideoDecoder(state, encodingOptions) ?? string.Empty;\n                        var isIntelDecoder = vidDecoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase)\n                                             || vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                        var doOclTonemap = _mediaEncoder.SupportsHwaccel(\"qsv\")\n                            && IsVaapiSupported(state)\n                            && IsOpenclFullSupported()\n                            && !IsVaapiVppTonemapAvailable(state, encodingOptions)\n                            && IsHwTonemapAvailable(state, encodingOptions);\n\n                        enableWaFori915Hang = isIntelDecoder && doOclTonemap;\n                    }\n                }\n\n                if (string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    intelLowPowerHwEncoding = encodingOptions.EnableIntelLowPowerH264HwEncoder;\n                }\n                else if (string.Equals(videoEncoder, \"hevc_qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    intelLowPowerHwEncoding = encodingOptions.EnableIntelLowPowerHevcHwEncoder;\n                }\n                else\n                {\n                    enableWaFori915Hang = false;\n                }\n            }\n\n            if (intelLowPowerHwEncoding)\n            {\n                param += \" -low_power 1\";\n            }\n\n            if (enableWaFori915Hang)\n            {\n                param += \" -async_depth 1\";\n            }\n\n            var isVc1 = string.Equals(state.VideoStream?.Codec, \"vc1\", StringComparison.OrdinalIgnoreCase);\n            var isLibX265 = string.Equals(videoEncoder, \"libx265\", StringComparison.OrdinalIgnoreCase);\n\n            if (string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase) || isLibX265)\n            {\n                if (!string.IsNullOrEmpty(encodingOptions.EncoderPreset))\n                {\n                    param += \" -preset \" + encodingOptions.EncoderPreset;\n                }\n                else\n                {\n                    param += \" -preset \" + defaultPreset;\n                }\n\n                int encodeCrf = encodingOptions.H264Crf;\n                if (isLibX265)\n                {\n                    encodeCrf = encodingOptions.H265Crf;\n                }\n\n                if (encodeCrf >= 0 && encodeCrf <= 51)\n                {\n                    param += \" -crf \" + encodeCrf.ToString(CultureInfo.InvariantCulture);\n                }\n                else\n                {\n                    string defaultCrf = \"23\";\n                    if (isLibX265)\n                    {\n                        defaultCrf = \"28\";\n                    }\n\n                    param += \" -crf \" + defaultCrf;\n                }\n            }\n            else if (string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase) // h264 (h264_qsv)\n                     || string.Equals(videoEncoder, \"hevc_qsv\", StringComparison.OrdinalIgnoreCase)) // hevc (hevc_qsv)\n            {\n                string[] valid_h264_qsv = { \"veryslow\", \"slower\", \"slow\", \"medium\", \"fast\", \"faster\", \"veryfast\" };\n\n                if (valid_h264_qsv.Contains(encodingOptions.EncoderPreset, StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -preset \" + encodingOptions.EncoderPreset;\n                }\n                else\n                {\n                    param += \" -preset 7\";\n                }\n\n                // Only h264_qsv has look_ahead option\n                if (string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -look_ahead 0\";\n                }\n            }\n            else if (string.Equals(videoEncoder, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase) // h264 (h264_nvenc)\n                     || string.Equals(videoEncoder, \"hevc_nvenc\", StringComparison.OrdinalIgnoreCase)) // hevc (hevc_nvenc)\n            {\n                switch (encodingOptions.EncoderPreset)\n                {\n                    case \"veryslow\":\n                        param += \" -preset p7\";\n                        break;\n\n                    case \"slower\":\n                        param += \" -preset p6\";\n                        break;\n\n                    case \"slow\":\n                        param += \" -preset p5\";\n                        break;\n\n                    case \"medium\":\n                        param += \" -preset p4\";\n                        break;\n\n                    case \"fast\":\n                        param += \" -preset p3\";\n                        break;\n\n                    case \"faster\":\n                        param += \" -preset p2\";\n                        break;\n\n                    case \"veryfast\":\n                    case \"superfast\":\n                    case \"ultrafast\":\n                        param += \" -preset p1\";\n                        break;\n\n                    default:\n                        param += \" -preset p1\";\n                        break;\n                }\n            }\n            else if (string.Equals(videoEncoder, \"h264_amf\", StringComparison.OrdinalIgnoreCase) // h264 (h264_amf)\n                     || string.Equals(videoEncoder, \"hevc_amf\", StringComparison.OrdinalIgnoreCase)) // hevc (hevc_amf)\n            {\n                switch (encodingOptions.EncoderPreset)\n                {\n                    case \"veryslow\":\n                    case \"slower\":\n                    case \"slow\":\n                        param += \" -quality quality\";\n                        break;\n\n                    case \"medium\":\n                        param += \" -quality balanced\";\n                        break;\n\n                    case \"fast\":\n                    case \"faster\":\n                    case \"veryfast\":\n                    case \"superfast\":\n                    case \"ultrafast\":\n                        param += \" -quality speed\";\n                        break;\n\n                    default:\n                        param += \" -quality speed\";\n                        break;\n                }\n\n                if (string.Equals(videoEncoder, \"hevc_amf\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -header_insertion_mode gop -gops_per_idr 1\";\n                }\n            }\n            else if (string.Equals(videoEncoder, \"libvpx\", StringComparison.OrdinalIgnoreCase)) // vp8\n            {\n                // Values 0-3, 0 being highest quality but slower\n                var profileScore = 0;\n\n                string crf;\n                var qmin = \"0\";\n                var qmax = \"50\";\n\n                crf = \"10\";\n\n                if (isVc1)\n                {\n                    profileScore++;\n                }\n\n                // Max of 2\n                profileScore = Math.Min(profileScore, 2);\n\n                // http://www.webmproject.org/docs/encoder-parameters/\n                param += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -speed 16 -quality good -profile:v {0} -slices 8 -crf {1} -qmin {2} -qmax {3}\",\n                    profileScore.ToString(CultureInfo.InvariantCulture),\n                    crf,\n                    qmin,\n                    qmax);\n            }\n            else if (string.Equals(videoEncoder, \"libvpx-vp9\", StringComparison.OrdinalIgnoreCase)) // vp9\n            {\n                // When `-deadline` is set to `good` or `best`, `-cpu-used` ranges from 0-5.\n                // When `-deadline` is set to `realtime`, `-cpu-used` ranges from 0-15.\n                // Resources:\n                //   * https://trac.ffmpeg.org/wiki/Encode/VP9\n                //   * https://superuser.com/questions/1586934\n                //   * https://developers.google.com/media/vp9\n                param += encodingOptions.EncoderPreset switch\n                {\n                    \"veryslow\" => \" -deadline best -cpu-used 0\",\n                    \"slower\" => \" -deadline best -cpu-used 2\",\n                    \"slow\" => \" -deadline best -cpu-used 3\",\n                    \"medium\" => \" -deadline good -cpu-used 0\",\n                    \"fast\" => \" -deadline good -cpu-used 1\",\n                    \"faster\" => \" -deadline good -cpu-used 2\",\n                    \"veryfast\" => \" -deadline good -cpu-used 3\",\n                    \"superfast\" => \" -deadline good -cpu-used 4\",\n                    \"ultrafast\" => \" -deadline good -cpu-used 5\",\n                    _ => \" -deadline good -cpu-used 1\"\n                };\n\n                // TODO: until VP9 gets its own CRF setting, base CRF on H.265.\n                int h265Crf = encodingOptions.H265Crf;\n                int defaultVp9Crf = 31;\n                if (h265Crf >= 0 && h265Crf <= 51)\n                {\n                    // This conversion factor is chosen to match the default CRF for H.265 to the\n                    // recommended 1080p CRF from Google. The factor also maps the logarithmic CRF\n                    // scale of x265 [0, 51] to that of VP9 [0, 63] relatively well.\n\n                    // Resources:\n                    //   * https://developers.google.com/media/vp9/settings/vod\n                    const float H265ToVp9CrfConversionFactor = 1.12F;\n\n                    var vp9Crf = Convert.ToInt32(h265Crf * H265ToVp9CrfConversionFactor);\n\n                    // Encoder allows for CRF values in the range [0, 63].\n                    vp9Crf = Math.Clamp(vp9Crf, 0, 63);\n\n                    param += FormattableString.Invariant($\" -crf {vp9Crf}\");\n                }\n                else\n                {\n                    param += FormattableString.Invariant($\" -crf {defaultVp9Crf}\");\n                }\n\n                param += \" -row-mt 1 -profile 1\";\n            }\n            else if (string.Equals(videoEncoder, \"mpeg4\", StringComparison.OrdinalIgnoreCase))\n            {\n                param += \" -mbd rd -flags +mv4+aic -trellis 2 -cmp 2 -subcmp 2 -bf 2\";\n            }\n            else if (string.Equals(videoEncoder, \"wmv2\", StringComparison.OrdinalIgnoreCase)) // asf/wmv\n            {\n                param += \" -qmin 2\";\n            }\n            else if (string.Equals(videoEncoder, \"msmpeg4\", StringComparison.OrdinalIgnoreCase))\n            {\n                param += \" -mbd 2\";\n            }\n\n            param += GetVideoBitrateParam(state, videoEncoder);\n\n            var framerate = GetFramerateParam(state);\n            if (framerate.HasValue)\n            {\n                param += string.Format(CultureInfo.InvariantCulture, \" -r {0}\", framerate.Value.ToString(CultureInfo.InvariantCulture));\n            }\n\n            var targetVideoCodec = state.ActualOutputVideoCodec;\n            if (string.Equals(targetVideoCodec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(targetVideoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase))\n            {\n                targetVideoCodec = \"hevc\";\n            }\n\n            var profile = state.GetRequestedProfiles(targetVideoCodec).FirstOrDefault() ?? string.Empty;\n            profile = Regex.Replace(profile, @\"\\s+\", string.Empty);\n\n            // We only transcode to HEVC 8-bit for now, force Main Profile.\n            if (profile.Contains(\"main10\", StringComparison.OrdinalIgnoreCase)\n                || profile.Contains(\"mainstill\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"main\";\n            }\n\n            // Extended Profile is not supported by any known h264 encoders, force Main Profile.\n            if (profile.Contains(\"extended\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"main\";\n            }\n\n            // Only libx264 support encoding H264 High 10 Profile, otherwise force High Profile.\n            if (!string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                && profile.Contains(\"high10\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"high\";\n            }\n\n            // h264_vaapi does not support Baseline profile, force Constrained Baseline in this case,\n            // which is compatible (and ugly).\n            if (string.Equals(videoEncoder, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase)\n                && profile.Contains(\"baseline\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"constrained_baseline\";\n            }\n\n            // libx264, h264_qsv and h264_nvenc does not support Constrained Baseline profile, force Baseline in this case.\n            if ((string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase))\n                && profile.Contains(\"baseline\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"baseline\";\n            }\n\n            // libx264, h264_qsv, h264_nvenc and h264_vaapi does not support Constrained High profile, force High in this case.\n            if ((string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase))\n                && profile.Contains(\"high\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"high\";\n            }\n\n            if (string.Equals(videoEncoder, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                && profile.Contains(\"baseline\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"constrained_baseline\";\n            }\n\n            if (string.Equals(videoEncoder, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                && profile.Contains(\"constrainedhigh\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"constrained_high\";\n            }\n\n            if (!string.IsNullOrEmpty(profile))\n            {\n                if (!string.Equals(videoEncoder, \"h264_v4l2m2m\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -profile:v:0 \" + profile;\n                }\n            }\n\n            var level = state.GetRequestedLevel(targetVideoCodec);\n\n            if (!string.IsNullOrEmpty(level))\n            {\n                level = NormalizeTranscodingLevel(state, level);\n\n                // libx264, QSV, AMF can adjust the given level to match the output.\n                if (string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -level \" + level;\n                }\n                else if (string.Equals(videoEncoder, \"hevc_qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    // hevc_qsv use -level 51 instead of -level 153.\n                    if (double.TryParse(level, NumberStyles.Any, CultureInfo.InvariantCulture, out double hevcLevel))\n                    {\n                        param += \" -level \" + (hevcLevel / 3);\n                    }\n                }\n                else if (string.Equals(videoEncoder, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoEncoder, \"hevc_amf\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -level \" + level;\n                }\n                else if (string.Equals(videoEncoder, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoEncoder, \"hevc_nvenc\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoEncoder, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoEncoder, \"hevc_vaapi\", StringComparison.OrdinalIgnoreCase))\n                {\n                    // level option may cause NVENC to fail.\n                    // NVENC cannot adjust the given level, just throw an error.\n                    // level option may cause corrupted frames on AMD VAAPI.\n                }\n                else if (!string.Equals(videoEncoder, \"libx265\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -level \" + level;\n                }\n            }\n\n            if (string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase))\n            {\n                param += \" -x264opts:0 subme=0:me_range=4:rc_lookahead=10:me=dia:no_chroma_me:8x8dct=0:partitions=none\";\n            }\n\n            if (string.Equals(videoEncoder, \"libx265\", StringComparison.OrdinalIgnoreCase))\n            {\n                // libx265 only accept level option in -x265-params.\n                // level option may cause libx265 to fail.\n                // libx265 cannot adjust the given level, just throw an error.\n                // TODO: set fine tuned params.\n                param += \" -x265-params:0 no-info=1\";\n            }\n\n            return param;\n        }\n\n        public bool CanStreamCopyVideo(EncodingJobInfo state, MediaStream videoStream)\n        {\n            var request = state.BaseRequest;\n\n            if (!request.AllowVideoStreamCopy)\n            {\n                return false;\n            }\n\n            if (videoStream.IsInterlaced\n                && state.DeInterlace(videoStream.Codec, false))\n            {\n                return false;\n            }\n\n            if (videoStream.IsAnamorphic ?? false)\n            {\n                if (request.RequireNonAnamorphic)\n                {\n                    return false;\n                }\n            }\n\n            // Can't stream copy if we're burning in subtitles\n            if (request.SubtitleStreamIndex.HasValue\n                && request.SubtitleStreamIndex.Value >= 0\n                && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode)\n            {\n                return false;\n            }\n\n            if (string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                && videoStream.IsAVC.HasValue\n                && !videoStream.IsAVC.Value\n                && request.RequireAvc)\n            {\n                return false;\n            }\n\n            // Source and target codecs must match\n            if (string.IsNullOrEmpty(videoStream.Codec)\n                || (state.SupportedVideoCodecs.Length != 0\n                    && !state.SupportedVideoCodecs.Contains(videoStream.Codec, StringComparison.OrdinalIgnoreCase)))\n            {\n                return false;\n            }\n\n            var requestedProfiles = state.GetRequestedProfiles(videoStream.Codec);\n\n            // If client is requesting a specific video profile, it must match the source\n            if (requestedProfiles.Length > 0)\n            {\n                if (string.IsNullOrEmpty(videoStream.Profile))\n                {\n                    // return false;\n                }\n\n                var requestedProfile = requestedProfiles[0];\n                // strip spaces because they may be stripped out on the query string as well\n                if (!string.IsNullOrEmpty(videoStream.Profile)\n                    && !requestedProfiles.Contains(videoStream.Profile.Replace(\" \", string.Empty, StringComparison.Ordinal), StringComparison.OrdinalIgnoreCase))\n                {\n                    var currentScore = GetVideoProfileScore(videoStream.Codec, videoStream.Profile);\n                    var requestedScore = GetVideoProfileScore(videoStream.Codec, requestedProfile);\n\n                    if (currentScore == -1 || currentScore > requestedScore)\n                    {\n                        return false;\n                    }\n                }\n            }\n\n            var requestedRangeTypes = state.GetRequestedRangeTypes(videoStream.Codec);\n            if (requestedRangeTypes.Length > 0)\n            {\n                if (string.IsNullOrEmpty(videoStream.VideoRangeType))\n                {\n                    return false;\n                }\n\n                if (!requestedRangeTypes.Contains(videoStream.VideoRangeType, StringComparison.OrdinalIgnoreCase))\n                {\n                    return false;\n                }\n            }\n\n            // Video width must fall within requested value\n            if (request.MaxWidth.HasValue\n                && (!videoStream.Width.HasValue || videoStream.Width.Value > request.MaxWidth.Value))\n            {\n                return false;\n            }\n\n            // Video height must fall within requested value\n            if (request.MaxHeight.HasValue\n                && (!videoStream.Height.HasValue || videoStream.Height.Value > request.MaxHeight.Value))\n            {\n                return false;\n            }\n\n            // Video framerate must fall within requested value\n            var requestedFramerate = request.MaxFramerate ?? request.Framerate;\n            if (requestedFramerate.HasValue)\n            {\n                var videoFrameRate = videoStream.AverageFrameRate ?? videoStream.RealFrameRate;\n\n                if (!videoFrameRate.HasValue || videoFrameRate.Value > requestedFramerate.Value)\n                {\n                    return false;\n                }\n            }\n\n            // Video bitrate must fall within requested value\n            if (request.VideoBitRate.HasValue\n                && (!videoStream.BitRate.HasValue || videoStream.BitRate.Value > request.VideoBitRate.Value))\n            {\n                return false;\n            }\n\n            var maxBitDepth = state.GetRequestedVideoBitDepth(videoStream.Codec);\n            if (maxBitDepth.HasValue)\n            {\n                if (videoStream.BitDepth.HasValue && videoStream.BitDepth.Value > maxBitDepth.Value)\n                {\n                    return false;\n                }\n            }\n\n            var maxRefFrames = state.GetRequestedMaxRefFrames(videoStream.Codec);\n            if (maxRefFrames.HasValue\n                && videoStream.RefFrames.HasValue && videoStream.RefFrames.Value > maxRefFrames.Value)\n            {\n                return false;\n            }\n\n            // If a specific level was requested, the source must match or be less than\n            var level = state.GetRequestedLevel(videoStream.Codec);\n            if (!string.IsNullOrEmpty(level)\n                && double.TryParse(level, NumberStyles.Any, CultureInfo.InvariantCulture, out var requestLevel))\n            {\n                if (!videoStream.Level.HasValue)\n                {\n                    // return false;\n                }\n\n                if (videoStream.Level.HasValue && videoStream.Level.Value > requestLevel)\n                {\n                    return false;\n                }\n            }\n\n            if (string.Equals(state.InputContainer, \"avi\", StringComparison.OrdinalIgnoreCase)\n                && string.Equals(videoStream.Codec, \"h264\", StringComparison.OrdinalIgnoreCase)\n                && !(videoStream.IsAVC ?? false))\n            {\n                // see Coach S01E01 - Kelly and the Professor(0).avi\n                return false;\n            }\n\n            return true;\n        }\n\n        public bool CanStreamCopyAudio(EncodingJobInfo state, MediaStream audioStream, IEnumerable<string> supportedAudioCodecs)\n        {\n            var request = state.BaseRequest;\n\n            if (!request.AllowAudioStreamCopy)\n            {\n                return false;\n            }\n\n            var maxBitDepth = state.GetRequestedAudioBitDepth(audioStream.Codec);\n            if (maxBitDepth.HasValue\n                && audioStream.BitDepth.HasValue\n                && audioStream.BitDepth.Value > maxBitDepth.Value)\n            {\n                return false;\n            }\n\n            // Source and target codecs must match\n            if (string.IsNullOrEmpty(audioStream.Codec)\n                || !supportedAudioCodecs.Contains(audioStream.Codec, StringComparison.OrdinalIgnoreCase))\n            {\n                return false;\n            }\n\n            // Channels must fall within requested value\n            var channels = state.GetRequestedAudioChannels(audioStream.Codec);\n            if (channels.HasValue)\n            {\n                if (!audioStream.Channels.HasValue || audioStream.Channels.Value <= 0)\n                {\n                    return false;\n                }\n\n                if (audioStream.Channels.Value > channels.Value)\n                {\n                    return false;\n                }\n            }\n\n            // Sample rate must fall within requested value\n            if (request.AudioSampleRate.HasValue)\n            {\n                if (!audioStream.SampleRate.HasValue || audioStream.SampleRate.Value <= 0)\n                {\n                    return false;\n                }\n\n                if (audioStream.SampleRate.Value > request.AudioSampleRate.Value)\n                {\n                    return false;\n                }\n            }\n\n            // Audio bitrate must fall within requested value\n            if (request.AudioBitRate.HasValue\n                && audioStream.BitRate.HasValue\n                && audioStream.BitRate.Value > request.AudioBitRate.Value)\n            {\n                return false;\n            }\n\n            return request.EnableAutoStreamCopy;\n        }\n\n        public int GetVideoBitrateParamValue(BaseEncodingJobOptions request, MediaStream videoStream, string outputVideoCodec)\n        {\n            var bitrate = request.VideoBitRate;\n\n            if (videoStream != null)\n            {\n                var isUpscaling = request.Height.HasValue\n                    && videoStream.Height.HasValue\n                    && request.Height.Value > videoStream.Height.Value\n                    && request.Width.HasValue\n                    && videoStream.Width.HasValue\n                    && request.Width.Value > videoStream.Width.Value;\n\n                // Don't allow bitrate increases unless upscaling\n                if (!isUpscaling && bitrate.HasValue && videoStream.BitRate.HasValue)\n                {\n                    bitrate = GetMinBitrate(videoStream.BitRate.Value, bitrate.Value);\n                }\n\n                if (bitrate.HasValue)\n                {\n                    var inputVideoCodec = videoStream.Codec;\n                    bitrate = ScaleBitrate(bitrate.Value, inputVideoCodec, outputVideoCodec);\n\n                    // If a max bitrate was requested, don't let the scaled bitrate exceed it\n                    if (request.VideoBitRate.HasValue)\n                    {\n                        bitrate = Math.Min(bitrate.Value, request.VideoBitRate.Value);\n                    }\n                }\n            }\n\n            // Cap the max target bitrate to intMax/2 to satisify the bufsize=bitrate*2.\n            return Math.Min(bitrate ?? 0, int.MaxValue / 2);\n        }\n\n        private int GetMinBitrate(int sourceBitrate, int requestedBitrate)\n        {\n            // these values were chosen from testing to improve low bitrate streams\n            if (sourceBitrate <= 2000000)\n            {\n                sourceBitrate = Convert.ToInt32(sourceBitrate * 2.5);\n            }\n            else if (sourceBitrate <= 3000000)\n            {\n                sourceBitrate *= 2;\n            }\n\n            var bitrate = Math.Min(sourceBitrate, requestedBitrate);\n\n            return bitrate;\n        }\n\n        private static double GetVideoBitrateScaleFactor(string codec)\n        {\n            // hevc & vp9 - 40% more efficient than h.264\n            if (string.Equals(codec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"vp9\", StringComparison.OrdinalIgnoreCase))\n            {\n                return .6;\n            }\n\n            // av1 - 50% more efficient than h.264\n            if (string.Equals(codec, \"av1\", StringComparison.OrdinalIgnoreCase))\n            {\n                return .5;\n            }\n\n            return 1;\n        }\n\n        private static int ScaleBitrate(int bitrate, string inputVideoCodec, string outputVideoCodec)\n        {\n            var inputScaleFactor = GetVideoBitrateScaleFactor(inputVideoCodec);\n            var outputScaleFactor = GetVideoBitrateScaleFactor(outputVideoCodec);\n\n            // Don't scale the real bitrate lower than the requested bitrate\n            var scaleFactor = Math.Max(outputScaleFactor / inputScaleFactor, 1);\n\n            if (bitrate <= 500000)\n            {\n                scaleFactor = Math.Max(scaleFactor, 4);\n            }\n            else if (bitrate <= 1000000)\n            {\n                scaleFactor = Math.Max(scaleFactor, 3);\n            }\n            else if (bitrate <= 2000000)\n            {\n                scaleFactor = Math.Max(scaleFactor, 2.5);\n            }\n            else if (bitrate <= 3000000)\n            {\n                scaleFactor = Math.Max(scaleFactor, 2);\n            }\n\n            return Convert.ToInt32(scaleFactor * bitrate);\n        }\n\n        public int? GetAudioBitrateParam(BaseEncodingJobOptions request, MediaStream audioStream, int? outputAudioChannels)\n        {\n            return GetAudioBitrateParam(request.AudioBitRate, request.AudioCodec, audioStream, outputAudioChannels);\n        }\n\n        public int? GetAudioBitrateParam(int? audioBitRate, string audioCodec, MediaStream audioStream, int? outputAudioChannels)\n        {\n            if (audioStream == null)\n            {\n                return null;\n            }\n\n            var inputChannels = audioStream.Channels ?? 0;\n            var outputChannels = outputAudioChannels ?? 0;\n            var bitrate = audioBitRate ?? int.MaxValue;\n\n            if (string.IsNullOrEmpty(audioCodec)\n                || string.Equals(audioCodec, \"aac\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"mp3\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"opus\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"vorbis\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"ac3\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"eac3\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (inputChannels, outputChannels) switch\n                {\n                    (>= 6, >= 6 or 0) => Math.Min(640000, bitrate),\n                    (> 0, > 0) => Math.Min(outputChannels * 128000, bitrate),\n                    (> 0, _) => Math.Min(inputChannels * 128000, bitrate),\n                    (_, _) => Math.Min(384000, bitrate)\n                };\n            }\n\n            if (string.Equals(audioCodec, \"dts\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"dca\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (inputChannels, outputChannels) switch\n                {\n                    (>= 6, >= 6 or 0) => Math.Min(768000, bitrate),\n                    (> 0, > 0) => Math.Min(outputChannels * 136000, bitrate),\n                    (> 0, _) => Math.Min(inputChannels * 136000, bitrate),\n                    (_, _) => Math.Min(672000, bitrate)\n                };\n            }\n\n            // Empty bitrate area is not allow on iOS\n            // Default audio bitrate to 128K per channel if we don't have codec specific defaults\n            // https://ffmpeg.org/ffmpeg-codecs.html#toc-Codec-Options\n            return 128000 * (outputAudioChannels ?? audioStream.Channels ?? 2);\n        }\n\n        public string GetAudioFilterParam(EncodingJobInfo state, EncodingOptions encodingOptions)\n        {\n            var channels = state.OutputAudioChannels;\n\n            var filters = new List<string>();\n\n            // Boost volume to 200% when downsampling from 6ch to 2ch\n            if (channels.HasValue\n                && channels.Value <= 2\n                && state.AudioStream != null\n                && state.AudioStream.Channels.HasValue\n                && state.AudioStream.Channels.Value > 5\n                && !encodingOptions.DownMixAudioBoost.Equals(1))\n            {\n                filters.Add(\"volume=\" + encodingOptions.DownMixAudioBoost.ToString(CultureInfo.InvariantCulture));\n            }\n\n            var isCopyingTimestamps = state.CopyTimestamps || state.TranscodingType != TranscodingJobType.Progressive;\n            if (state.SubtitleStream != null && state.SubtitleStream.IsTextSubtitleStream && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode && !isCopyingTimestamps)\n            {\n                var seconds = TimeSpan.FromTicks(state.StartTimeTicks ?? 0).TotalSeconds;\n\n                filters.Add(\n                    string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"asetpts=PTS-{0}/TB\",\n                        Math.Round(seconds)));\n            }\n\n            if (filters.Count > 0)\n            {\n                return \" -af \\\"\" + string.Join(',', filters) + \"\\\"\";\n            }\n\n            return string.Empty;\n        }\n\n        /// <summary>\n        /// Gets the number of audio channels to specify on the command line.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <param name=\"audioStream\">The audio stream.</param>\n        /// <param name=\"outputAudioCodec\">The output audio codec.</param>\n        /// <returns>System.Nullable{System.Int32}.</returns>\n        public int? GetNumAudioChannelsParam(EncodingJobInfo state, MediaStream audioStream, string outputAudioCodec)\n        {\n            if (audioStream == null)\n            {\n                return null;\n            }\n\n            var request = state.BaseRequest;\n\n            var inputChannels = audioStream.Channels;\n\n            if (inputChannels <= 0)\n            {\n                inputChannels = null;\n            }\n\n            var codec = outputAudioCodec ?? string.Empty;\n\n            int? transcoderChannelLimit;\n            if (codec.IndexOf(\"wma\", StringComparison.OrdinalIgnoreCase) != -1)\n            {\n                // wmav2 currently only supports two channel output\n                transcoderChannelLimit = 2;\n            }\n            else if (codec.IndexOf(\"mp3\", StringComparison.OrdinalIgnoreCase) != -1)\n            {\n                // libmp3lame currently only supports two channel output\n                transcoderChannelLimit = 2;\n            }\n            else if (codec.IndexOf(\"aac\", StringComparison.OrdinalIgnoreCase) != -1)\n            {\n                // aac is able to handle 8ch(7.1 layout)\n                transcoderChannelLimit = 8;\n            }\n            else\n            {\n                // If we don't have any media info then limit it to 6 to prevent encoding errors due to asking for too many channels\n                transcoderChannelLimit = 6;\n            }\n\n            var isTranscodingAudio = !IsCopyCodec(codec);\n\n            int? resultChannels = state.GetRequestedAudioChannels(codec);\n            if (isTranscodingAudio)\n            {\n                resultChannels = GetMinValue(request.TranscodingMaxAudioChannels, resultChannels);\n            }\n\n            if (inputChannels.HasValue)\n            {\n                resultChannels = resultChannels.HasValue\n                    ? Math.Min(resultChannels.Value, inputChannels.Value)\n                    : inputChannels.Value;\n            }\n\n            if (isTranscodingAudio && transcoderChannelLimit.HasValue)\n            {\n                resultChannels = resultChannels.HasValue\n                    ? Math.Min(resultChannels.Value, transcoderChannelLimit.Value)\n                    : transcoderChannelLimit.Value;\n            }\n\n            // Avoid transcoding to audio channels other than 1ch, 2ch, 6ch (5.1 layout) and 8ch (7.1 layout).\n            // https://developer.apple.com/documentation/http_live_streaming/hls_authoring_specification_for_apple_devices\n            if (isTranscodingAudio\n                && state.TranscodingType != TranscodingJobType.Progressive\n                && resultChannels.HasValue\n                && ((resultChannels.Value > 2 && resultChannels.Value < 6) || resultChannels.Value == 7))\n            {\n                resultChannels = 2;\n            }\n\n            return resultChannels;\n        }\n\n        private int? GetMinValue(int? val1, int? val2)\n        {\n            if (!val1.HasValue)\n            {\n                return val2;\n            }\n\n            if (!val2.HasValue)\n            {\n                return val1;\n            }\n\n            return Math.Min(val1.Value, val2.Value);\n        }\n\n        /// <summary>\n        /// Enforces the resolution limit.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        public void EnforceResolutionLimit(EncodingJobInfo state)\n        {\n            var videoRequest = state.BaseRequest;\n\n            // Switch the incoming params to be ceilings rather than fixed values\n            videoRequest.MaxWidth = videoRequest.MaxWidth ?? videoRequest.Width;\n            videoRequest.MaxHeight = videoRequest.MaxHeight ?? videoRequest.Height;\n\n            videoRequest.Width = null;\n            videoRequest.Height = null;\n        }\n\n        /// <summary>\n        /// Gets the fast seek command line parameter.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <param name=\"options\">The options.</param>\n        /// <param name=\"segmentContainer\">Segment Container.</param>\n        /// <returns>System.String.</returns>\n        /// <value>The fast seek command line parameter.</value>\n        public string GetFastSeekCommandLineParameter(EncodingJobInfo state, EncodingOptions options, string segmentContainer)\n        {\n            var time = state.BaseRequest.StartTimeTicks ?? 0;\n            var seekParam = string.Empty;\n\n            if (time > 0)\n            {\n                seekParam += string.Format(CultureInfo.InvariantCulture, \"-ss {0}\", _mediaEncoder.GetTimeParameter(time));\n\n                if (state.IsVideoRequest)\n                {\n                    var outputVideoCodec = GetVideoEncoder(state, options);\n                    var segmentFormat = GetSegmentFileExtension(segmentContainer).TrimStart('.');\n\n                    // Important: If this is ever re-enabled, make sure not to use it with wtv because it breaks seeking\n                    // Disable -noaccurate_seek on mpegts container due to the timestamps issue on some clients,\n                    // but it's still required for fMP4 container otherwise the audio can't be synced to the video.\n                    if (!string.Equals(state.InputContainer, \"wtv\", StringComparison.OrdinalIgnoreCase)\n                        && !string.Equals(segmentFormat, \"ts\", StringComparison.OrdinalIgnoreCase)\n                        && state.TranscodingType != TranscodingJobType.Progressive\n                        && !state.EnableBreakOnNonKeyFrames(outputVideoCodec)\n                        && (state.BaseRequest.StartTimeTicks ?? 0) > 0)\n                    {\n                        seekParam += \" -noaccurate_seek\";\n                    }\n                }\n            }\n\n            return seekParam;\n        }\n\n        /// <summary>\n        /// Gets the map args.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <returns>System.String.</returns>\n        public string GetMapArgs(EncodingJobInfo state)\n        {\n            // If we don't have known media info\n            // If input is video, use -sn to drop subtitles\n            // Otherwise just return empty\n            if (state.VideoStream == null && state.AudioStream == null)\n            {\n                return state.IsInputVideo ? \"-sn\" : string.Empty;\n            }\n\n            // We have media info, but we don't know the stream index\n            if (state.VideoStream != null && state.VideoStream.Index == -1)\n            {\n                return \"-sn\";\n            }\n\n            // We have media info, but we don't know the stream index\n            if (state.AudioStream != null && state.AudioStream.Index == -1)\n            {\n                return state.IsInputVideo ? \"-sn\" : string.Empty;\n            }\n\n            var args = string.Empty;\n\n            if (state.VideoStream != null)\n            {\n                int videoStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.VideoStream);\n\n                args += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"-map 0:{0}\",\n                    videoStreamIndex);\n            }\n            else\n            {\n                // No known video stream\n                args += \"-vn\";\n            }\n\n            if (state.AudioStream != null)\n            {\n                int audioStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.AudioStream);\n                if (state.AudioStream.IsExternal)\n                {\n                    bool hasExternalGraphicsSubs = state.SubtitleStream != null\n                        && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode\n                        && state.SubtitleStream.IsExternal\n                        && !state.SubtitleStream.IsTextSubtitleStream;\n                    int externalAudioMapIndex = hasExternalGraphicsSubs ? 2 : 1;\n\n                    args += string.Format(\n                        CultureInfo.InvariantCulture,\n                        \" -map {0}:{1}\",\n                        externalAudioMapIndex,\n                        audioStreamIndex);\n                }\n                else\n                {\n                    args += string.Format(\n                        CultureInfo.InvariantCulture,\n                        \" -map 0:{0}\",\n                        audioStreamIndex);\n                }\n            }\n            else\n            {\n                args += \" -map -0:a\";\n            }\n\n            var subtitleMethod = state.SubtitleDeliveryMethod;\n            if (state.SubtitleStream == null || subtitleMethod == SubtitleDeliveryMethod.Hls)\n            {\n                args += \" -map -0:s\";\n            }\n            else if (subtitleMethod == SubtitleDeliveryMethod.Embed)\n            {\n                int subtitleStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.SubtitleStream);\n\n                args += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -map 0:{0}\",\n                    subtitleStreamIndex);\n            }\n            else if (state.SubtitleStream.IsExternal && !state.SubtitleStream.IsTextSubtitleStream)\n            {\n                int externalSubtitleStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.SubtitleStream);\n\n                args += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -map 1:{0} -sn\",\n                    externalSubtitleStreamIndex);\n            }\n\n            return args;\n        }\n\n        /// <summary>\n        /// Gets the negative map args by filters.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <param name=\"videoProcessFilters\">The videoProcessFilters.</param>\n        /// <returns>System.String.</returns>\n        public string GetNegativeMapArgsByFilters(EncodingJobInfo state, string videoProcessFilters)\n        {\n            string args = string.Empty;\n\n            // http://ffmpeg.org/ffmpeg-all.html#toc-Complex-filtergraphs-1\n            if (state.VideoStream != null && videoProcessFilters.Contains(\"-filter_complex\", StringComparison.Ordinal))\n            {\n                int videoStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.VideoStream);\n\n                args += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"-map -0:{0} \",\n                    videoStreamIndex);\n            }\n\n            return args;\n        }\n\n        /// <summary>\n        /// Determines which stream will be used for playback.\n        /// </summary>\n        /// <param name=\"allStream\">All stream.</param>\n        /// <param name=\"desiredIndex\">Index of the desired.</param>\n        /// <param name=\"type\">The type.</param>\n        /// <param name=\"returnFirstIfNoIndex\">if set to <c>true</c> [return first if no index].</param>\n        /// <returns>MediaStream.</returns>\n        public MediaStream GetMediaStream(IEnumerable<MediaStream> allStream, int? desiredIndex, MediaStreamType type, bool returnFirstIfNoIndex = true)\n        {\n            var streams = allStream.Where(s => s.Type == type).OrderBy(i => i.Index).ToList();\n\n            if (desiredIndex.HasValue)\n            {\n                var stream = streams.FirstOrDefault(s => s.Index == desiredIndex.Value);\n\n                if (stream != null)\n                {\n                    return stream;\n                }\n            }\n\n            if (returnFirstIfNoIndex && type == MediaStreamType.Audio)\n            {\n                return streams.FirstOrDefault(i => i.Channels.HasValue && i.Channels.Value > 0) ??\n                       streams.FirstOrDefault();\n            }\n\n            // Just return the first one\n            return returnFirstIfNoIndex ? streams.FirstOrDefault() : null;\n        }\n\n        public static (int? Width, int? Height) GetFixedOutputSize(\n            int? videoWidth,\n            int? videoHeight,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight)\n        {\n            if (!videoWidth.HasValue && !requestedWidth.HasValue)\n            {\n                return (null, null);\n            }\n\n            if (!videoHeight.HasValue && !requestedHeight.HasValue)\n            {\n                return (null, null);\n            }\n\n            int inputWidth = Convert.ToInt32(videoWidth ?? requestedWidth, CultureInfo.InvariantCulture);\n            int inputHeight = Convert.ToInt32(videoHeight ?? requestedHeight, CultureInfo.InvariantCulture);\n            int outputWidth = requestedWidth ?? inputWidth;\n            int outputHeight = requestedHeight ?? inputHeight;\n\n            // Don't transcode video to bigger than 4k when using HW.\n            int maximumWidth = Math.Min(requestedMaxWidth ?? outputWidth, 4096);\n            int maximumHeight = Math.Min(requestedMaxHeight ?? outputHeight, 4096);\n\n            if (outputWidth > maximumWidth || outputHeight > maximumHeight)\n            {\n                var scaleW = (double)maximumWidth / (double)outputWidth;\n                var scaleH = (double)maximumHeight / (double)outputHeight;\n                var scale = Math.Min(scaleW, scaleH);\n                outputWidth = Math.Min(maximumWidth, (int)(outputWidth * scale));\n                outputHeight = Math.Min(maximumHeight, (int)(outputHeight * scale));\n            }\n\n            outputWidth = 2 * (outputWidth / 2);\n            outputHeight = 2 * (outputHeight / 2);\n\n            return (outputWidth, outputHeight);\n        }\n\n        public static string GetHwScaleFilter(\n            string hwScaleSuffix,\n            string videoFormat,\n            int? videoWidth,\n            int? videoHeight,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight)\n        {\n            var (outWidth, outHeight) = GetFixedOutputSize(\n                videoWidth,\n                videoHeight,\n                requestedWidth,\n                requestedHeight,\n                requestedMaxWidth,\n                requestedMaxHeight);\n\n            var isFormatFixed = !string.IsNullOrEmpty(videoFormat);\n            var isSizeFixed = !videoWidth.HasValue\n                || outWidth.Value != videoWidth.Value\n                || !videoHeight.HasValue\n                || outHeight.Value != videoHeight.Value;\n\n            var arg1 = isSizeFixed ? (\"=w=\" + outWidth.Value + \":h=\" + outHeight.Value) : string.Empty;\n            var arg2 = isFormatFixed ? (\"format=\" + videoFormat) : string.Empty;\n            if (isFormatFixed)\n            {\n                arg2 = (isSizeFixed ? ':' : '=') + arg2;\n            }\n\n            if (!string.IsNullOrEmpty(hwScaleSuffix) && (isSizeFixed || isFormatFixed))\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"scale_{0}{1}{2}\",\n                    hwScaleSuffix,\n                    arg1,\n                    arg2);\n            }\n\n            return string.Empty;\n        }\n\n        public static string GetCustomSwScaleFilter(\n            int? videoWidth,\n            int? videoHeight,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight)\n        {\n            var (outWidth, outHeight) = GetFixedOutputSize(\n                videoWidth,\n                videoHeight,\n                requestedWidth,\n                requestedHeight,\n                requestedMaxWidth,\n                requestedMaxHeight);\n\n            if (outWidth.HasValue && outHeight.HasValue)\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"scale=s={0}x{1}:flags=fast_bilinear\",\n                    outWidth.Value,\n                    outHeight.Value);\n            }\n\n            return string.Empty;\n        }\n\n        public static string GetAlphaSrcFilter(\n            EncodingJobInfo state,\n            int? videoWidth,\n            int? videoHeight,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight,\n            int? framerate)\n        {\n            var reqTicks = state.BaseRequest.StartTimeTicks ?? 0;\n            var startTime = TimeSpan.FromTicks(reqTicks).ToString(@\"hh\\\\\\:mm\\\\\\:ss\\\\\\.fff\", CultureInfo.InvariantCulture);\n            var (outWidth, outHeight) = GetFixedOutputSize(\n                videoWidth,\n                videoHeight,\n                requestedWidth,\n                requestedHeight,\n                requestedMaxWidth,\n                requestedMaxHeight);\n\n            if (outWidth.HasValue && outHeight.HasValue)\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"alphasrc=s={0}x{1}:r={2}:start='{3}'\",\n                    outWidth.Value,\n                    outHeight.Value,\n                    framerate ?? 10,\n                    reqTicks > 0 ? startTime : 0);\n            }\n\n            return string.Empty;\n        }\n\n        public static string GetSwScaleFilter(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string videoEncoder,\n            int? videoWidth,\n            int? videoHeight,\n            Video3DFormat? threedFormat,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight)\n        {\n            var isV4l2 = string.Equals(videoEncoder, \"h264_v4l2m2m\", StringComparison.OrdinalIgnoreCase);\n            var scaleVal = isV4l2 ? 64 : 2;\n\n            // If fixed dimensions were supplied\n            if (requestedWidth.HasValue && requestedHeight.HasValue)\n            {\n                if (isV4l2)\n                {\n                    var widthParam = requestedWidth.Value.ToString(CultureInfo.InvariantCulture);\n                    var heightParam = requestedHeight.Value.ToString(CultureInfo.InvariantCulture);\n\n                    return string.Format(\n                            CultureInfo.InvariantCulture,\n                            \"scale=trunc({0}/64)*64:trunc({1}/2)*2\",\n                            widthParam,\n                            heightParam);\n                }\n                else\n                {\n                    return GetFixedSwScaleFilter(threedFormat, requestedWidth.Value, requestedHeight.Value);\n                }\n            }\n\n            // If Max dimensions were supplied, for width selects lowest even number between input width and width req size and selects lowest even number from in width*display aspect and requested size\n            else if (requestedMaxWidth.HasValue && requestedMaxHeight.HasValue)\n            {\n                var maxWidthParam = requestedMaxWidth.Value.ToString(CultureInfo.InvariantCulture);\n                var maxHeightParam = requestedMaxHeight.Value.ToString(CultureInfo.InvariantCulture);\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"scale=trunc(min(max(iw\\\\,ih*a)\\\\,min({0}\\\\,{1}*a))/{2})*{2}:trunc(min(max(iw/a\\\\,ih)\\\\,min({0}/a\\\\,{1}))/2)*2\",\n                        maxWidthParam,\n                        maxHeightParam,\n                        scaleVal);\n            }\n\n            // If a fixed width was requested\n            else if (requestedWidth.HasValue)\n            {\n                if (threedFormat.HasValue)\n                {\n                    // This method can handle 0 being passed in for the requested height\n                    return GetFixedSwScaleFilter(threedFormat, requestedWidth.Value, 0);\n                }\n                else\n                {\n                    var widthParam = requestedWidth.Value.ToString(CultureInfo.InvariantCulture);\n\n                    return string.Format(\n                            CultureInfo.InvariantCulture,\n                            \"scale={0}:trunc(ow/a/2)*2\",\n                            widthParam);\n                }\n            }\n\n            // If a fixed height was requested\n            else if (requestedHeight.HasValue)\n            {\n                var heightParam = requestedHeight.Value.ToString(CultureInfo.InvariantCulture);\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"scale=trunc(oh*a/{1})*{1}:{0}\",\n                        heightParam,\n                        scaleVal);\n            }\n\n            // If a max width was requested\n            else if (requestedMaxWidth.HasValue)\n            {\n                var maxWidthParam = requestedMaxWidth.Value.ToString(CultureInfo.InvariantCulture);\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"scale=trunc(min(max(iw\\\\,ih*a)\\\\,{0})/{1})*{1}:trunc(ow/a/2)*2\",\n                        maxWidthParam,\n                        scaleVal);\n            }\n\n            // If a max height was requested\n            else if (requestedMaxHeight.HasValue)\n            {\n                var maxHeightParam = requestedMaxHeight.Value.ToString(CultureInfo.InvariantCulture);\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"scale=trunc(oh*a/{1})*{1}:min(max(iw/a\\\\,ih)\\\\,{0})\",\n                        maxHeightParam,\n                        scaleVal);\n            }\n\n            return string.Empty;\n        }\n\n        private static string GetFixedSwScaleFilter(Video3DFormat? threedFormat, int requestedWidth, int requestedHeight)\n        {\n            var widthParam = requestedWidth.ToString(CultureInfo.InvariantCulture);\n            var heightParam = requestedHeight.ToString(CultureInfo.InvariantCulture);\n\n            string filter = null;\n\n            if (threedFormat.HasValue)\n            {\n                switch (threedFormat.Value)\n                {\n                    case Video3DFormat.HalfSideBySide:\n                        filter = \"crop=iw/2:ih:0:0,scale=(iw*2):ih,setdar=dar=a,crop=min(iw\\\\,ih*dar):min(ih\\\\,iw/dar):(iw-min(iw\\\\,iw*sar))/2:(ih - min (ih\\\\,ih/sar))/2,setsar=sar=1,scale={0}:trunc({0}/dar/2)*2\";\n                        // hsbs crop width in half,scale to correct size, set the display aspect,crop out any black bars we may have made the scale width to requestedWidth. Work out the correct height based on the display aspect it will maintain the aspect where -1 in this case (3d) may not.\n                        break;\n                    case Video3DFormat.FullSideBySide:\n                        filter = \"crop=iw/2:ih:0:0,setdar=dar=a,crop=min(iw\\\\,ih*dar):min(ih\\\\,iw/dar):(iw-min(iw\\\\,iw*sar))/2:(ih - min (ih\\\\,ih/sar))/2,setsar=sar=1,scale={0}:trunc({0}/dar/2)*2\";\n                        // fsbs crop width in half,set the display aspect,crop out any black bars we may have made the scale width to requestedWidth.\n                        break;\n                    case Video3DFormat.HalfTopAndBottom:\n                        filter = \"crop=iw:ih/2:0:0,scale=(iw*2):ih),setdar=dar=a,crop=min(iw\\\\,ih*dar):min(ih\\\\,iw/dar):(iw-min(iw\\\\,iw*sar))/2:(ih - min (ih\\\\,ih/sar))/2,setsar=sar=1,scale={0}:trunc({0}/dar/2)*2\";\n                        // htab crop height in half,scale to correct size, set the display aspect,crop out any black bars we may have made the scale width to requestedWidth\n                        break;\n                    case Video3DFormat.FullTopAndBottom:\n                        filter = \"crop=iw:ih/2:0:0,setdar=dar=a,crop=min(iw\\\\,ih*dar):min(ih\\\\,iw/dar):(iw-min(iw\\\\,iw*sar))/2:(ih - min (ih\\\\,ih/sar))/2,setsar=sar=1,scale={0}:trunc({0}/dar/2)*2\";\n                        // ftab crop height in half, set the display aspect,crop out any black bars we may have made the scale width to requestedWidth\n                        break;\n                    default:\n                        break;\n                }\n            }\n\n            // default\n            if (filter == null)\n            {\n                if (requestedHeight > 0)\n                {\n                    filter = \"scale=trunc({0}/2)*2:trunc({1}/2)*2\";\n                }\n                else\n                {\n                    filter = \"scale={0}:trunc({0}/a/2)*2\";\n                }\n            }\n\n            return string.Format(CultureInfo.InvariantCulture, filter, widthParam, heightParam);\n        }\n\n        public static string GetSwDeinterlaceFilter(EncodingJobInfo state, EncodingOptions options)\n        {\n            var doubleRateDeint = options.DeinterlaceDoubleRate && state.VideoStream?.AverageFrameRate <= 30;\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"{0}={1}:-1:0\",\n                string.Equals(options.DeinterlaceMethod, \"bwdif\", StringComparison.OrdinalIgnoreCase) ? \"bwdif\" : \"yadif\",\n                doubleRateDeint ? \"1\" : \"0\");\n        }\n\n        public static string GetHwDeinterlaceFilter(EncodingJobInfo state, EncodingOptions options, string hwDeintSuffix)\n        {\n            var doubleRateDeint = options.DeinterlaceDoubleRate && (state.VideoStream?.AverageFrameRate ?? 60) <= 30;\n            if (hwDeintSuffix.Contains(\"cuda\", StringComparison.OrdinalIgnoreCase))\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"yadif_cuda={0}:-1:0\",\n                    doubleRateDeint ? \"1\" : \"0\");\n            }\n            else if (hwDeintSuffix.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"deinterlace_vaapi=rate={0}\",\n                    doubleRateDeint ? \"field\" : \"frame\");\n            }\n            else if (hwDeintSuffix.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"deinterlace_qsv=mode=2\";\n            }\n\n            return string.Empty;\n        }\n\n        public string GetHwTonemapFilter(EncodingOptions options, string hwTonemapSuffix, string videoFormat)\n        {\n            if (string.IsNullOrEmpty(hwTonemapSuffix))\n            {\n                return string.Empty;\n            }\n\n            var args = \"tonemap_{0}=format={1}:p=bt709:t=bt709:m=bt709\";\n\n            if (hwTonemapSuffix.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                args = \"procamp_vaapi=b={2}:c={3},\" + args + \":extra_hw_frames=32\";\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        args,\n                        hwTonemapSuffix,\n                        videoFormat ?? \"nv12\",\n                        options.VppTonemappingBrightness,\n                        options.VppTonemappingContrast);\n            }\n            else\n            {\n                args += \":tonemap={2}:peak={3}:desat={4}\";\n\n                if (string.Equals(options.TonemappingMode, \"max\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(options.TonemappingMode, \"rgb\", StringComparison.OrdinalIgnoreCase))\n                {\n                    if (_mediaEncoder.EncoderVersion >= _minFFmpegOclCuTonemapMode)\n                    {\n                        args += \":tonemap_mode={5}\";\n                    }\n                }\n\n                if (options.TonemappingParam != 0)\n                {\n                    args += \":param={6}\";\n                }\n\n                if (string.Equals(options.TonemappingRange, \"tv\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(options.TonemappingRange, \"pc\", StringComparison.OrdinalIgnoreCase))\n                {\n                    args += \":range={7}\";\n                }\n            }\n\n            return string.Format(\n                    CultureInfo.InvariantCulture,\n                    args,\n                    hwTonemapSuffix,\n                    videoFormat ?? \"nv12\",\n                    options.TonemappingAlgorithm,\n                    options.TonemappingPeak,\n                    options.TonemappingDesat,\n                    options.TonemappingMode,\n                    options.TonemappingParam,\n                    options.TonemappingRange);\n        }\n\n        /// <summary>\n        /// Gets the parameter of software filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetSwVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isVaapiEncoder = vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isV4l2Encoder = vidEncoder.Contains(\"h264_v4l2m2m\", StringComparison.OrdinalIgnoreCase);\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, false));\n\n            // INPUT sw surface(memory/copy-back from vram)\n            // sw deint\n            if (doDeintH2645)\n            {\n                var deintFilter = GetSwDeinterlaceFilter(state, options);\n                mainFilters.Add(deintFilter);\n            }\n\n            var outFormat = isSwDecoder ? \"yuv420p\" : \"nv12\";\n            var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n            if (isVaapiEncoder)\n            {\n                outFormat = \"nv12\";\n            }\n            else if (isV4l2Encoder)\n            {\n                outFormat = \"yuv420p\";\n            }\n\n            // sw scale\n            mainFilters.Add(swScaleFilter);\n            mainFilters.Add(\"format=\" + outFormat);\n\n            // sw tonemap <= TODO: finsh the fast tonemap filter\n\n            // OUTPUT yuv420p/nv12 surface(memory)\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (hasTextSubs)\n            {\n                // subtitles=f='*.ass':alpha=0\n                var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                mainFilters.Add(textSubtitlesFilter);\n            }\n            else if (hasGraphicalSubs)\n            {\n                // [0:s]scale=s=1280x720\n                var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                subFilters.Add(subSwScaleFilter);\n                overlayFilters.Add(\"overlay=eof_action=endall:shortest=1:repeatlast=0\");\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of Nvidia NVENC filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetNvidiaVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            if (!string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (null, null, null);\n            }\n\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !vidEncoder.Contains(\"nvenc\", StringComparison.OrdinalIgnoreCase);\n\n            // legacy cuvid pipeline(copy-back)\n            if ((isSwDecoder && isSwEncoder)\n                || !IsCudaFullSupported()\n                || !_mediaEncoder.SupportsFilter(\"alphasrc\"))\n            {\n                return GetSwVidFilterChain(state, options, vidEncoder);\n            }\n\n            // prefered nvdec/cuvid + cuda filters + nvenc pipeline\n            return GetNvidiaVidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetNvidiaVidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isNvDecoder = vidDecoder.Contains(\"cuda\", StringComparison.OrdinalIgnoreCase);\n            var isNvencEncoder = vidEncoder.Contains(\"nvenc\", StringComparison.OrdinalIgnoreCase);\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isNvencEncoder;\n            var isCuInCuOut = isNvDecoder && isNvencEncoder;\n\n            var doubleRateDeint = options.DeinterlaceDoubleRate && (state.VideoStream?.AverageFrameRate ?? 60) <= 30;\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n            var doCuTonemap = IsHwTonemapAvailable(state, options);\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doCuTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doCuTonemap ? \"yuv420p10le\" : \"yuv420p\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // sw => hw\n                if (doCuTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=cuda\");\n                }\n            }\n\n            if (isNvDecoder)\n            {\n                // INPUT cuda surface(vram)\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, \"cuda\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                var outFormat = doCuTonemap ? string.Empty : \"yuv420p\";\n                var hwScaleFilter = GetHwScaleFilter(\"cuda\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            // hw tonemap\n            if (doCuTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"cuda\", \"yuv420p\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            var memoryOutput = false;\n            var isUploadForCuTonemap = isSwDecoder && doCuTonemap;\n            if ((isNvDecoder && isSwEncoder) || (isUploadForCuTonemap && hasSubs))\n            {\n                memoryOutput = true;\n\n                // OUTPUT yuv420p surface(memory)\n                mainFilters.Add(\"hwdownload\");\n                mainFilters.Add(\"format=yuv420p\");\n            }\n\n            // OUTPUT yuv420p surface(memory)\n            if (isSwDecoder && isNvencEncoder && !isUploadForCuTonemap)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            // OUTPUT cuda(yuv420p) surface(vram)\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isCuInCuOut)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        // scale=s=1280x720,format=yuva420p,hwupload\n                        var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                        subFilters.Add(subSwScaleFilter);\n                        subFilters.Add(\"format=yuva420p\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        // alphasrc=s=1280x720:r=10:start=0,format=yuva420p,subtitles,hwupload\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, reqMaxH, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=yuva420p\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    subFilters.Add(\"hwupload=derive_device=cuda\");\n                    overlayFilters.Add(\"overlay_cuda=eof_action=endall:shortest=1:repeatlast=0\");\n                }\n            }\n            else\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=endall:shortest=1:repeatlast=0\");\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of AMD AMF filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetAmdVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            if (!string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (null, null, null);\n            }\n\n            var isWindows = OperatingSystem.IsWindows();\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !vidEncoder.Contains(\"amf\", StringComparison.OrdinalIgnoreCase);\n            var isAmfDx11OclSupported = isWindows && _mediaEncoder.SupportsHwaccel(\"d3d11va\") && IsOpenclFullSupported();\n\n            // legacy d3d11va pipeline(copy-back)\n            if ((isSwDecoder && isSwEncoder)\n                || !isAmfDx11OclSupported\n                || !_mediaEncoder.SupportsFilter(\"alphasrc\"))\n            {\n                return GetSwVidFilterChain(state, options, vidEncoder);\n            }\n\n            // prefered d3d11va + opencl filters + amf pipeline\n            return GetAmdDx11VidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetAmdDx11VidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n            var isAmfEncoder = vidEncoder.Contains(\"amf\", StringComparison.OrdinalIgnoreCase);\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isAmfEncoder;\n            var isDxInDxOut = isD3d11vaDecoder && isAmfEncoder;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n            var doOclTonemap = IsHwTonemapAvailable(state, options);\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doOclTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doOclTonemap ? \"yuv420p10le\" : \"yuv420p\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=d3d11va:extra_hw_frames=16\");\n                    mainFilters.Add(\"format=d3d11\");\n                    mainFilters.Add(\"hwmap=derive_device=opencl\");\n                }\n            }\n\n            if (isD3d11vaDecoder)\n            {\n                // INPUT d3d11 surface(vram)\n                // map from d3d11va to opencl via d3d11-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=opencl\");\n\n                // hw deint <= TODO: finsh the 'yadif_opencl' filter\n\n                var outFormat = doOclTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(\"opencl\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            // hw tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = isSwDecoder && doOclTonemap;\n            if (isD3d11vaDecoder && isSwEncoder)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl.\n                var hwTransferFilter = hasGraphicalSubs ? \"hwdownload\" : \"hwmap=mode=read\";\n                mainFilters.Add(hwTransferFilter);\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT yuv420p surface\n            if (isSwDecoder && isAmfEncoder && !isUploadForOclTonemap)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if ((isDxInDxOut || isUploadForOclTonemap) && !hasSubs)\n            {\n                // OUTPUT d3d11(nv12) surface(vram)\n                // reverse-mapping via d3d11-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=d3d11va:reverse=1\");\n                mainFilters.Add(\"format=d3d11\");\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isDxInDxOut || isUploadForOclTonemap)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        // scale=s=1280x720,format=yuva420p,hwupload\n                        var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                        subFilters.Add(subSwScaleFilter);\n                        subFilters.Add(\"format=yuva420p\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        // alphasrc=s=1280x720:r=10:start=0,format=yuva420p,subtitles,hwupload\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, reqMaxH, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=yuva420p\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    subFilters.Add(\"hwupload=derive_device=opencl\");\n                    overlayFilters.Add(\"overlay_opencl=eof_action=endall:shortest=1:repeatlast=0\");\n                    overlayFilters.Add(\"hwmap=derive_device=d3d11va:reverse=1\");\n                    overlayFilters.Add(\"format=d3d11\");\n                }\n            }\n            else if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=endall:shortest=1:repeatlast=0\");\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of Intel QSV filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetIntelVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            if (!string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (null, null, null);\n            }\n\n            var isWindows = OperatingSystem.IsWindows();\n            var isLinux = OperatingSystem.IsLinux();\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !vidEncoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isQsvOclSupported = _mediaEncoder.SupportsHwaccel(\"qsv\") && IsOpenclFullSupported();\n            var isIntelDx11OclSupported = isWindows\n                && _mediaEncoder.SupportsHwaccel(\"d3d11va\")\n                && isQsvOclSupported;\n            var isIntelVaapiOclSupported = isLinux\n                && IsVaapiSupported(state)\n                && isQsvOclSupported;\n\n            // legacy qsv pipeline(copy-back)\n            if ((isSwDecoder && isSwEncoder)\n                || (!isIntelVaapiOclSupported && !isIntelDx11OclSupported)\n                || !_mediaEncoder.SupportsFilter(\"alphasrc\"))\n            {\n                return GetSwVidFilterChain(state, options, vidEncoder);\n            }\n\n            // prefered qsv(vaapi) + opencl filters pipeline\n            if (isIntelVaapiOclSupported)\n            {\n                return GetIntelQsvVaapiVidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n            }\n\n            // prefered qsv(d3d11) + opencl filters pipeline\n            if (isIntelDx11OclSupported)\n            {\n                return GetIntelQsvDx11VidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n            }\n\n            return (null, null, null);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetIntelQsvDx11VidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n            var isQsvDecoder = vidDecoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isQsvEncoder = vidEncoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isHwDecoder = isD3d11vaDecoder || isQsvDecoder;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isQsvEncoder;\n            var isQsvInQsvOut = isHwDecoder && isQsvEncoder;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n            var doOclTonemap = IsHwTonemapAvailable(state, options);\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doOclTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doOclTonemap ? \"yuv420p10le\" : \"yuv420p\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n            else if (isD3d11vaDecoder || isQsvDecoder)\n            {\n                var outFormat = doOclTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(\"qsv\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n\n                if (isD3d11vaDecoder)\n                {\n                    if (!string.IsNullOrEmpty(hwScaleFilter) || doDeintH2645)\n                    {\n                        // INPUT d3d11 surface(vram)\n                        // map from d3d11va to qsv.\n                        mainFilters.Add(\"hwmap=derive_device=qsv\");\n                    }\n                }\n\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, \"qsv\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            if (doOclTonemap && isHwDecoder)\n            {\n                // map from qsv to opencl via qsv(d3d11)-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=opencl\");\n            }\n\n            // hw tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = isSwDecoder && doOclTonemap;\n            var isHwmapUsable = isSwEncoder && doOclTonemap;\n            if ((isHwDecoder && isSwEncoder) || isUploadForOclTonemap)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl.\n                // qsv hwmap is not fully implemented for the time being.\n                mainFilters.Add(isHwmapUsable ? \"hwmap=mode=read\" : \"hwdownload\");\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT nv12 surface(memory)\n            if (isSwDecoder && isQsvEncoder)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if (isQsvInQsvOut && doOclTonemap)\n            {\n                // OUTPUT qsv(nv12) surface(vram)\n                // reverse-mapping via qsv(d3d11)-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=qsv:reverse=1\");\n                mainFilters.Add(\"format=qsv\");\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isQsvInQsvOut)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        // scale,format=bgra,hwupload\n                        // overlay_qsv can handle overlay scaling,\n                        // add a dummy scale filter to pair with -canvas_size.\n                        subFilters.Add(\"scale=flags=fast_bilinear\");\n                        subFilters.Add(\"format=bgra\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        // alphasrc=s=1280x720:r=10:start=0,format=bgra,subtitles,hwupload\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, 1080, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=bgra\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    // qsv requires a fixed pool size.\n                    // default to 64 otherwise it will fail on certain iGPU.\n                    subFilters.Add(\"hwupload=derive_device=qsv:extra_hw_frames=64\");\n\n                    var (overlayW, overlayH) = GetFixedOutputSize(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    var overlaySize = (overlayW.HasValue && overlayH.HasValue)\n                        ? (\":w=\" + overlayW.Value + \":h=\" + overlayH.Value)\n                        : string.Empty;\n                    var overlayQsvFilter = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"overlay_qsv=eof_action=endall:shortest=1:repeatlast=0{0}\",\n                        overlaySize);\n                    overlayFilters.Add(overlayQsvFilter);\n                }\n            }\n            else if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=endall:shortest=1:repeatlast=0\");\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetIntelQsvVaapiVidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isQsvDecoder = vidDecoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isQsvEncoder = vidEncoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isHwDecoder = isVaapiDecoder || isQsvDecoder;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isQsvEncoder;\n            var isQsvInQsvOut = isHwDecoder && isQsvEncoder;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doVaVppTonemap = IsVaapiVppTonemapAvailable(state, options);\n            var doOclTonemap = !doVaVppTonemap && IsHwTonemapAvailable(state, options);\n            var doTonemap = doVaVppTonemap || doOclTonemap;\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doOclTonemap ? \"yuv420p10le\" : \"yuv420p\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n            else if (isVaapiDecoder || isQsvDecoder)\n            {\n                // INPUT vaapi/qsv surface(vram)\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, isVaapiDecoder ? \"vaapi\" : \"qsv\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                var outFormat = doTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(isVaapiDecoder ? \"vaapi\" : \"qsv\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n\n                // allocate extra pool sizes for vaapi vpp\n                if (!string.IsNullOrEmpty(hwScaleFilter) && isVaapiDecoder)\n                {\n                    hwScaleFilter += \":extra_hw_frames=24\";\n                }\n\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            // vaapi vpp tonemap\n            if (doVaVppTonemap && isHwDecoder)\n            {\n                if (isQsvDecoder)\n                {\n                    // map from qsv to vaapi.\n                    mainFilters.Add(\"hwmap=derive_device=vaapi\");\n                }\n\n                var tonemapFilter = GetHwTonemapFilter(options, \"vaapi\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n\n                if (isQsvDecoder)\n                {\n                    // map from vaapi to qsv.\n                    mainFilters.Add(\"hwmap=derive_device=qsv\");\n                }\n            }\n\n            if (doOclTonemap && isHwDecoder)\n            {\n                // map from qsv to opencl via qsv(vaapi)-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=opencl\");\n            }\n\n            // ocl tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = isSwDecoder && doOclTonemap;\n            var isHwmapUsable = isSwEncoder && (doOclTonemap || isVaapiDecoder);\n            if ((isHwDecoder && isSwEncoder) || isUploadForOclTonemap)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl/vaapi.\n                // qsv hwmap is not fully implemented for the time being.\n                mainFilters.Add(isHwmapUsable ? \"hwmap=mode=read\" : \"hwdownload\");\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT nv12 surface(memory)\n            if (isSwDecoder && isQsvEncoder)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if (isQsvInQsvOut)\n            {\n                if (doOclTonemap)\n                {\n                    // OUTPUT qsv(nv12) surface(vram)\n                    // reverse-mapping via qsv(vaapi)-opencl interop.\n                    // add extra pool size to avoid the 'cannot allocate memory' error on hevc_qsv.\n                    mainFilters.Add(\"hwmap=derive_device=qsv:reverse=1:extra_hw_frames=16\");\n                    mainFilters.Add(\"format=qsv\");\n                }\n                else if (isVaapiDecoder)\n                {\n                    mainFilters.Add(\"hwmap=derive_device=qsv\");\n                    mainFilters.Add(\"format=qsv\");\n                }\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isQsvInQsvOut)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        subFilters.Add(\"scale=flags=fast_bilinear\");\n                        subFilters.Add(\"format=bgra\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, 1080, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=bgra\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    // qsv requires a fixed pool size.\n                    // default to 64 otherwise it will fail on certain iGPU.\n                    subFilters.Add(\"hwupload=derive_device=qsv:extra_hw_frames=64\");\n\n                    var (overlayW, overlayH) = GetFixedOutputSize(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    var overlaySize = (overlayW.HasValue && overlayH.HasValue)\n                        ? (\":w=\" + overlayW.Value + \":h=\" + overlayH.Value)\n                        : string.Empty;\n                    var overlayQsvFilter = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"overlay_qsv=eof_action=endall:shortest=1:repeatlast=0{0}\",\n                        overlaySize);\n                    overlayFilters.Add(overlayQsvFilter);\n                }\n            }\n            else if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=pass:shortest=1:repeatlast=0\");\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of Intel/AMD VAAPI filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetVaapiVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            if (!string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (null, null, null);\n            }\n\n            var isLinux = OperatingSystem.IsLinux();\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isVaapiOclSupported = isLinux && IsVaapiSupported(state) && IsVaapiFullSupported() && IsOpenclFullSupported();\n\n            // legacy vaapi pipeline(copy-back)\n            if ((isSwDecoder && isSwEncoder)\n                || !isVaapiOclSupported\n                || !_mediaEncoder.SupportsFilter(\"alphasrc\"))\n            {\n                var swFilterChain = GetSwVidFilterChain(state, options, vidEncoder);\n\n                if (!isSwEncoder)\n                {\n                    var newfilters = new List<string>();\n                    var noOverlay = swFilterChain.OverlayFilters.Count == 0;\n                    newfilters.AddRange(noOverlay ? swFilterChain.MainFilters : swFilterChain.OverlayFilters);\n                    newfilters.Add(\"hwupload=derive_device=vaapi\");\n\n                    var mainFilters = noOverlay ? newfilters : swFilterChain.MainFilters;\n                    var overlayFilters = noOverlay ? swFilterChain.OverlayFilters : newfilters;\n                    return (mainFilters, swFilterChain.SubFilters, overlayFilters);\n                }\n\n                return swFilterChain;\n            }\n\n            // prefered vaapi + opencl filters pipeline\n            if (_mediaEncoder.IsVaapiDeviceInteliHD)\n            {\n                // Intel iHD path, with extra vpp tonemap and overlay support.\n                return GetVaapiFullVidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n            }\n\n            // Intel i965 and Amd radeonsi/r600 path, only featuring scale and deinterlace support.\n            return GetVaapiLimitedVidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetVaapiFullVidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isVaapiEncoder = vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isVaapiEncoder;\n            var isVaInVaOut = isVaapiDecoder && isVaapiEncoder;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doVaVppTonemap = isVaapiDecoder && IsVaapiVppTonemapAvailable(state, options);\n            var doOclTonemap = !doVaVppTonemap && IsHwTonemapAvailable(state, options);\n            var doTonemap = doVaVppTonemap || doOclTonemap;\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doOclTonemap ? \"yuv420p10le\" : \"nv12\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n            else if (isVaapiDecoder)\n            {\n                // INPUT vaapi surface(vram)\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, \"vaapi\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                var outFormat = doTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(\"vaapi\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n\n                // allocate extra pool sizes for vaapi vpp\n                if (!string.IsNullOrEmpty(hwScaleFilter))\n                {\n                    hwScaleFilter += \":extra_hw_frames=24\";\n                }\n\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            // vaapi vpp tonemap\n            if (doVaVppTonemap && isVaapiDecoder)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"vaapi\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            if (doOclTonemap && isVaapiDecoder)\n            {\n                // map from vaapi to opencl via vaapi-opencl interop(Intel only).\n                mainFilters.Add(\"hwmap=derive_device=opencl\");\n            }\n\n            // ocl tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            if (doOclTonemap && isVaInVaOut)\n            {\n                // OUTPUT vaapi(nv12) surface(vram)\n                // reverse-mapping via vaapi-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=vaapi:reverse=1\");\n                mainFilters.Add(\"format=vaapi\");\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = isSwDecoder && doOclTonemap;\n            var isHwmapNotUsable = isUploadForOclTonemap && isVaapiEncoder;\n            if ((isVaapiDecoder && isSwEncoder) || isUploadForOclTonemap)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl/vaapi.\n                mainFilters.Add(isHwmapNotUsable ? \"hwdownload\" : \"hwmap=mode=read\");\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT nv12 surface(memory)\n            if (isSwDecoder && isVaapiEncoder)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if (memoryOutput && isVaapiEncoder)\n            {\n                if (!hasGraphicalSubs)\n                {\n                    mainFilters.Add(\"hwupload_vaapi\");\n                }\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isVaInVaOut)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        subFilters.Add(\"scale=flags=fast_bilinear\");\n                        subFilters.Add(\"format=bgra\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, 1080, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=bgra\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    subFilters.Add(\"hwupload=derive_device=vaapi\");\n\n                    var (overlayW, overlayH) = GetFixedOutputSize(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    var overlaySize = (overlayW.HasValue && overlayH.HasValue)\n                        ? (\":w=\" + overlayW.Value + \":h=\" + overlayH.Value)\n                        : string.Empty;\n                    var overlayVaapiFilter = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"overlay_vaapi=eof_action=endall:shortest=1:repeatlast=0{0}\",\n                        overlaySize);\n                    overlayFilters.Add(overlayVaapiFilter);\n                }\n            }\n            else if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=pass:shortest=1:repeatlast=0\");\n\n                    if (isVaapiEncoder)\n                    {\n                        overlayFilters.Add(\"hwupload_vaapi\");\n                    }\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetVaapiLimitedVidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isVaapiEncoder = vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isVaapiEncoder;\n            var isVaInVaOut = isVaapiDecoder && isVaapiEncoder;\n            var isi965Driver = _mediaEncoder.IsVaapiDeviceInteli965;\n            var isAmdDriver = _mediaEncoder.IsVaapiDeviceAmd;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n            var doOclTonemap = IsHwTonemapAvailable(state, options);\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doOclTonemap));\n\n            var outFormat = string.Empty;\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                outFormat = doOclTonemap ? \"yuv420p10le\" : \"nv12\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n            else if (isVaapiDecoder)\n            {\n                // INPUT vaapi surface(vram)\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, \"vaapi\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                outFormat = doOclTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(\"vaapi\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n\n                // allocate extra pool sizes for vaapi vpp\n                if (!string.IsNullOrEmpty(hwScaleFilter))\n                {\n                    hwScaleFilter += \":extra_hw_frames=24\";\n                }\n\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            if (doOclTonemap && isVaapiDecoder)\n            {\n                if (isi965Driver)\n                {\n                    // map from vaapi to opencl via vaapi-opencl interop(Intel only).\n                    mainFilters.Add(\"hwmap=derive_device=opencl\");\n                }\n                else\n                {\n                    mainFilters.Add(\"hwdownload\");\n                    mainFilters.Add(\"format=p010le\");\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n\n            // ocl tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            if (doOclTonemap && isVaInVaOut)\n            {\n                if (isi965Driver)\n                {\n                    // OUTPUT vaapi(nv12) surface(vram)\n                    // reverse-mapping via vaapi-opencl interop.\n                    mainFilters.Add(\"hwmap=derive_device=vaapi:reverse=1\");\n                    mainFilters.Add(\"format=vaapi\");\n                }\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = doOclTonemap && (isSwDecoder || (isVaapiDecoder && !isi965Driver));\n            var isHwmapNotUsable = hasGraphicalSubs || isUploadForOclTonemap;\n            var isHwmapForSubs = hasSubs && isVaapiDecoder;\n            var isHwUnmapForTextSubs = hasTextSubs && isVaInVaOut && !isUploadForOclTonemap;\n            if ((isVaapiDecoder && isSwEncoder) || isUploadForOclTonemap || isHwmapForSubs)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl/vaapi.\n                mainFilters.Add(isHwmapNotUsable ? \"hwdownload\" : \"hwmap\");\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT nv12 surface(memory)\n            if (isSwDecoder && isVaapiEncoder)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if (isHwUnmapForTextSubs)\n            {\n                mainFilters.Add(\"hwmap\");\n                mainFilters.Add(\"format=vaapi\");\n            }\n            else if (memoryOutput && isVaapiEncoder)\n            {\n                if (!hasGraphicalSubs)\n                {\n                    mainFilters.Add(\"hwupload_vaapi\");\n                }\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=pass:shortest=1:repeatlast=0\");\n\n                    if (isVaapiEncoder)\n                    {\n                        overlayFilters.Add(\"hwupload_vaapi\");\n                    }\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of video processing filters.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"outputVideoCodec\">Video codec to use.</param>\n        /// <returns>The video processing filters parameter.</returns>\n        public string GetVideoProcessingFilterParam(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string outputVideoCodec)\n        {\n            var videoStream = state.VideoStream;\n            if (videoStream == null)\n            {\n                return string.Empty;\n            }\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n\n            List<string> mainFilters;\n            List<string> subFilters;\n            List<string> overlayFilters;\n\n            if (string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                (mainFilters, subFilters, overlayFilters) = GetVaapiVidFilterChain(state, options, outputVideoCodec);\n            }\n            else if (string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                (mainFilters, subFilters, overlayFilters) = GetIntelVidFilterChain(state, options, outputVideoCodec);\n            }\n            else if (string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                (mainFilters, subFilters, overlayFilters) = GetNvidiaVidFilterChain(state, options, outputVideoCodec);\n            }\n            else if (string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                (mainFilters, subFilters, overlayFilters) = GetAmdVidFilterChain(state, options, outputVideoCodec);\n            }\n            else\n            {\n                (mainFilters, subFilters, overlayFilters) = GetSwVidFilterChain(state, options, outputVideoCodec);\n            }\n\n            mainFilters?.RemoveAll(filter => string.IsNullOrEmpty(filter));\n            subFilters?.RemoveAll(filter => string.IsNullOrEmpty(filter));\n            overlayFilters?.RemoveAll(filter => string.IsNullOrEmpty(filter));\n\n            var mainStr = string.Empty;\n            if (mainFilters?.Count > 0)\n            {\n                mainStr = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"{0}\",\n                    string.Join(',', mainFilters));\n            }\n\n            if (overlayFilters?.Count == 0)\n            {\n                // -vf \"scale...\"\n                return string.IsNullOrEmpty(mainStr) ? string.Empty : \" -vf \\\"\" + mainStr + \"\\\"\";\n            }\n\n            if (overlayFilters?.Count > 0\n                && subFilters?.Count > 0\n                && state.SubtitleStream != null)\n            {\n                // overlay graphical/text subtitles\n                var subStr = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"{0}\",\n                        string.Join(',', subFilters));\n\n                var overlayStr = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"{0}\",\n                        string.Join(',', overlayFilters));\n\n                var mapPrefix = Convert.ToInt32(state.SubtitleStream.IsExternal);\n                var subtitleStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.SubtitleStream);\n                var videoStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.VideoStream);\n\n                if (hasSubs)\n                {\n                    // -filter_complex \"[0:s]scale=s[sub]...\"\n                    var filterStr = string.IsNullOrEmpty(mainStr)\n                        ? \" -filter_complex \\\"[{0}:{1}]{4}[sub];[0:{2}][sub]{5}\\\"\"\n                        : \" -filter_complex \\\"[{0}:{1}]{4}[sub];[0:{2}]{3}[main];[main][sub]{5}\\\"\";\n\n                    if (hasTextSubs)\n                    {\n                        filterStr = string.IsNullOrEmpty(mainStr)\n                            ? \" -filter_complex \\\"{4}[sub];[0:{2}][sub]{5}\\\"\"\n                            : \" -filter_complex \\\"{4}[sub];[0:{2}]{3}[main];[main][sub]{5}\\\"\";\n                    }\n\n                    return string.Format(\n                        CultureInfo.InvariantCulture,\n                        filterStr,\n                        mapPrefix,\n                        subtitleStreamIndex,\n                        videoStreamIndex,\n                        mainStr,\n                        subStr,\n                        overlayStr);\n                }\n            }\n\n            return string.Empty;\n        }\n\n        public string GetOverwriteColorPropertiesParam(EncodingJobInfo state, bool isTonemapAvailable)\n        {\n            if (isTonemapAvailable)\n            {\n                return GetInputHdrParam(state.VideoStream?.ColorTransfer);\n            }\n\n            return GetOutputSdrParam(null);\n        }\n\n        public string GetInputHdrParam(string colorTransfer)\n        {\n            if (string.Equals(colorTransfer, \"arib-std-b67\", StringComparison.OrdinalIgnoreCase))\n            {\n                // HLG\n                return \"setparams=color_primaries=bt2020:color_trc=arib-std-b67:colorspace=bt2020nc\";\n            }\n\n            // HDR10\n            return \"setparams=color_primaries=bt2020:color_trc=smpte2084:colorspace=bt2020nc\";\n        }\n\n        public string GetOutputSdrParam(string tonemappingRange)\n        {\n            // SDR\n            if (string.Equals(tonemappingRange, \"tv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"setparams=color_primaries=bt709:color_trc=bt709:colorspace=bt709:range=tv\";\n            }\n\n            if (string.Equals(tonemappingRange, \"pc\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"setparams=color_primaries=bt709:color_trc=bt709:colorspace=bt709:range=pc\";\n            }\n\n            return \"setparams=color_primaries=bt709:color_trc=bt709:colorspace=bt709\";\n        }\n\n        public static int GetVideoColorBitDepth(EncodingJobInfo state)\n        {\n            var videoStream = state.VideoStream;\n            if (videoStream != null)\n            {\n                if (videoStream.BitDepth.HasValue)\n                {\n                    return videoStream.BitDepth.Value;\n                }\n                else if (string.Equals(videoStream.PixelFormat, \"yuv420p\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.PixelFormat, \"yuvj420p\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.PixelFormat, \"yuv444p\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return 8;\n                }\n                else if (string.Equals(videoStream.PixelFormat, \"yuv420p10le\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.PixelFormat, \"yuv444p10le\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return 10;\n                }\n                else if (string.Equals(videoStream.PixelFormat, \"yuv420p12le\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.PixelFormat, \"yuv444p12le\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return 12;\n                }\n                else\n                {\n                    return 8;\n                }\n            }\n\n            return 0;\n        }\n\n        /// <summary>\n        /// Gets the ffmpeg option string for the hardware accelerated video decoder.\n        /// </summary>\n        /// <param name=\"state\">The encoding job info.</param>\n        /// <param name=\"options\">The encoding options.</param>\n        /// <returns>The option string or null if none available.</returns>\n        protected string GetHardwareVideoDecoder(EncodingJobInfo state, EncodingOptions options)\n        {\n            var videoStream = state.VideoStream;\n            var mediaSource = state.MediaSource;\n            if (videoStream == null || mediaSource == null)\n            {\n                return null;\n            }\n\n            // HWA decoders can handle both video files and video folders.\n            var videoType = state.VideoType;\n            if (videoType != VideoType.VideoFile\n                && videoType != VideoType.Iso\n                && videoType != VideoType.Dvd\n                && videoType != VideoType.BluRay)\n            {\n                return null;\n            }\n\n            if (IsCopyCodec(state.OutputVideoCodec))\n            {\n                return null;\n            }\n\n            if (!string.IsNullOrEmpty(videoStream.Codec) && !string.IsNullOrEmpty(options.HardwareAccelerationType))\n            {\n                var bitDepth = GetVideoColorBitDepth(state);\n\n                // Only HEVC, VP9 and AV1 formats have 10-bit hardware decoder support now.\n                if (bitDepth == 10\n                    && !(string.Equals(videoStream.Codec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.Codec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.Codec, \"vp9\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.Codec, \"av1\", StringComparison.OrdinalIgnoreCase)))\n                {\n                    return null;\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetQsvHwVidDecoder(state, options, videoStream, bitDepth);\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetNvdecVidDecoder(state, options, videoStream, bitDepth);\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetAmfVidDecoder(state, options, videoStream, bitDepth);\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetVaapiVidDecoder(state, options, videoStream, bitDepth);\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"videotoolbox\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetVideotoolboxVidDecoder(state, options, videoStream, bitDepth);\n                }\n            }\n\n            var whichCodec = videoStream.Codec;\n            if (string.Equals(whichCodec, \"avc\", StringComparison.OrdinalIgnoreCase))\n            {\n                whichCodec = \"h264\";\n            }\n            else if (string.Equals(whichCodec, \"h265\", StringComparison.OrdinalIgnoreCase))\n            {\n                whichCodec = \"hevc\";\n            }\n\n            // Avoid a second attempt if no hardware acceleration is being used\n            options.HardwareDecodingCodecs = Array.FindAll(options.HardwareDecodingCodecs, val => !string.Equals(val, whichCodec, StringComparison.OrdinalIgnoreCase));\n\n            // leave blank so ffmpeg will decide\n            return null;\n        }\n\n        /// <summary>\n        /// Gets a hw decoder name.\n        /// </summary>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"decoderPrefix\">Decoder prefix.</param>\n        /// <param name=\"decoderSuffix\">Decoder suffix.</param>\n        /// <param name=\"videoCodec\">Video codec to use.</param>\n        /// <param name=\"bitDepth\">Video color bit depth.</param>\n        /// <returns>Hardware decoder name.</returns>\n        public string GetHwDecoderName(EncodingOptions options, string decoderPrefix, string decoderSuffix, string videoCodec, int bitDepth)\n        {\n            if (string.IsNullOrEmpty(decoderPrefix) || string.IsNullOrEmpty(decoderSuffix))\n            {\n                return null;\n            }\n\n            var decoderName = decoderPrefix + '_' + decoderSuffix;\n\n            var isCodecAvailable = _mediaEncoder.SupportsDecoder(decoderName) && options.HardwareDecodingCodecs.Contains(videoCodec, StringComparison.OrdinalIgnoreCase);\n            if (bitDepth == 10 && isCodecAvailable)\n            {\n                if (string.Equals(videoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                    && options.HardwareDecodingCodecs.Contains(\"hevc\", StringComparison.OrdinalIgnoreCase)\n                    && !options.EnableDecodingColorDepth10Hevc)\n                {\n                    return null;\n                }\n\n                if (string.Equals(videoCodec, \"vp9\", StringComparison.OrdinalIgnoreCase)\n                    && options.HardwareDecodingCodecs.Contains(\"vp9\", StringComparison.OrdinalIgnoreCase)\n                    && !options.EnableDecodingColorDepth10Vp9)\n                {\n                    return null;\n                }\n            }\n\n            if (string.Equals(decoderSuffix, \"cuvid\", StringComparison.OrdinalIgnoreCase) && options.EnableEnhancedNvdecDecoder)\n            {\n                return null;\n            }\n\n            if (string.Equals(decoderSuffix, \"qsv\", StringComparison.OrdinalIgnoreCase) && options.PreferSystemNativeHwDecoder)\n            {\n                return null;\n            }\n\n            return isCodecAvailable ? (\" -c:v \" + decoderName) : null;\n        }\n\n        /// <summary>\n        /// Gets a hwaccel type to use as a hardware decoder depending on the system.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"videoCodec\">Video codec to use.</param>\n        /// <param name=\"bitDepth\">Video color bit depth.</param>\n        /// <param name=\"outputHwSurface\">Specifies if output hw surface.</param>\n        /// <returns>Hardware accelerator type.</returns>\n        public string GetHwaccelType(EncodingJobInfo state, EncodingOptions options, string videoCodec, int bitDepth, bool outputHwSurface)\n        {\n            var isWindows = OperatingSystem.IsWindows();\n            var isLinux = OperatingSystem.IsLinux();\n            var isMacOS = OperatingSystem.IsMacOS();\n            var isD3d11Supported = isWindows && _mediaEncoder.SupportsHwaccel(\"d3d11va\");\n            var isVaapiSupported = isLinux && IsVaapiSupported(state);\n            var isCudaSupported = (isLinux || isWindows) && IsCudaFullSupported();\n            var isQsvSupported = (isLinux || isWindows) && _mediaEncoder.SupportsHwaccel(\"qsv\");\n            var isVideotoolboxSupported = isMacOS && _mediaEncoder.SupportsHwaccel(\"videotoolbox\");\n            var isCodecAvailable = options.HardwareDecodingCodecs.Contains(videoCodec, StringComparison.OrdinalIgnoreCase);\n\n            var ffmpegVersion = _mediaEncoder.EncoderVersion;\n\n            // Set the av1 codec explicitly to trigger hw accelerator, otherwise libdav1d will be used.\n            var isAv1 = ffmpegVersion < _minFFmpegImplictHwaccel\n                && string.Equals(videoCodec, \"av1\", StringComparison.OrdinalIgnoreCase);\n\n            // Allow profile mismatch if decoding H.264 baseline with d3d11va and vaapi hwaccels.\n            var profileMismatch = string.Equals(videoCodec, \"h264\", StringComparison.OrdinalIgnoreCase)\n                && string.Equals(state.VideoStream?.Profile, \"baseline\", StringComparison.OrdinalIgnoreCase);\n\n            // Disable the extra internal copy in nvdec. We already handle it in filter chain.\n            var nvdecNoInternalCopy = ffmpegVersion >= _minFFmpegHwaUnsafeOutput;\n\n            if (bitDepth == 10 && isCodecAvailable)\n            {\n                if (string.Equals(videoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                    && options.HardwareDecodingCodecs.Contains(\"hevc\", StringComparison.OrdinalIgnoreCase)\n                    && !options.EnableDecodingColorDepth10Hevc)\n                {\n                    return null;\n                }\n\n                if (string.Equals(videoCodec, \"vp9\", StringComparison.OrdinalIgnoreCase)\n                    && options.HardwareDecodingCodecs.Contains(\"vp9\", StringComparison.OrdinalIgnoreCase)\n                    && !options.EnableDecodingColorDepth10Vp9)\n                {\n                    return null;\n                }\n            }\n\n            // Intel qsv/d3d11va/vaapi\n            if (string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (options.PreferSystemNativeHwDecoder)\n                {\n                    if (isVaapiSupported && isCodecAvailable)\n                    {\n                        return \" -hwaccel vaapi\" + (outputHwSurface ? \" -hwaccel_output_format vaapi\" : string.Empty)\n                            + (profileMismatch ? \" -hwaccel_flags +allow_profile_mismatch\" : string.Empty) + (isAv1 ? \" -c:v av1\" : string.Empty);\n                    }\n\n                    if (isD3d11Supported && isCodecAvailable)\n                    {\n                        return \" -hwaccel d3d11va\" + (outputHwSurface ? \" -hwaccel_output_format d3d11\" : string.Empty)\n                            + (profileMismatch ? \" -hwaccel_flags +allow_profile_mismatch\" : string.Empty) + \" -threads 2\" + (isAv1 ? \" -c:v av1\" : string.Empty);\n                    }\n                }\n                else\n                {\n                    if (isQsvSupported && isCodecAvailable)\n                    {\n                        return \" -hwaccel qsv\" + (outputHwSurface ? \" -hwaccel_output_format qsv\" : string.Empty);\n                    }\n                }\n            }\n\n            // Nvidia cuda\n            if (string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (isCudaSupported && isCodecAvailable)\n                {\n                    if (options.EnableEnhancedNvdecDecoder)\n                    {\n                        // set -threads 1 to nvdec decoder explicitly since it doesn't implement threading support.\n                        return \" -hwaccel cuda\" + (outputHwSurface ? \" -hwaccel_output_format cuda\" : string.Empty)\n                            + (nvdecNoInternalCopy ? \" -hwaccel_flags +unsafe_output\" : string.Empty) + \" -threads 1\" + (isAv1 ? \" -c:v av1\" : string.Empty);\n                    }\n                    else\n                    {\n                        // cuvid decoder doesn't have threading issue.\n                        return \" -hwaccel cuda\" + (outputHwSurface ? \" -hwaccel_output_format cuda\" : string.Empty);\n                    }\n                }\n            }\n\n            // Amd d3d11va\n            if (string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (isD3d11Supported && isCodecAvailable)\n                {\n                    return \" -hwaccel d3d11va\" + (outputHwSurface ? \" -hwaccel_output_format d3d11\" : string.Empty)\n                        + (profileMismatch ? \" -hwaccel_flags +allow_profile_mismatch\" : string.Empty) + (isAv1 ? \" -c:v av1\" : string.Empty);\n                }\n            }\n\n            // Vaapi\n            if (string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase)\n                && isVaapiSupported\n                && isCodecAvailable)\n            {\n                return \" -hwaccel vaapi\" + (outputHwSurface ? \" -hwaccel_output_format vaapi\" : string.Empty)\n                    + (profileMismatch ? \" -hwaccel_flags +allow_profile_mismatch\" : string.Empty) + (isAv1 ? \" -c:v av1\" : string.Empty);\n            }\n\n            // Apple videotoolbox\n            if (string.Equals(options.HardwareAccelerationType, \"videotoolbox\", StringComparison.OrdinalIgnoreCase)\n                && isVideotoolboxSupported\n                && isCodecAvailable)\n            {\n                return \" -hwaccel videotoolbox\" + (outputHwSurface ? \" -hwaccel_output_format videotoolbox_vld\" : string.Empty);\n            }\n\n            return null;\n        }\n\n        public string GetQsvHwVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            var isWindows = OperatingSystem.IsWindows();\n            var isLinux = OperatingSystem.IsLinux();\n\n            if ((!isWindows && !isLinux)\n                || !string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var isQsvOclSupported = _mediaEncoder.SupportsHwaccel(\"qsv\") && IsOpenclFullSupported();\n            var isIntelDx11OclSupported = isWindows\n                && _mediaEncoder.SupportsHwaccel(\"d3d11va\")\n                && isQsvOclSupported;\n            var isIntelVaapiOclSupported = isLinux\n                && IsVaapiSupported(state)\n                && isQsvOclSupported;\n            var hwSurface = (isIntelDx11OclSupported || isIntelVaapiOclSupported)\n                && _mediaEncoder.SupportsFilter(\"alphasrc\");\n\n            var is8bitSwFormatsQsv = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                     || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsQsv = is8bitSwFormatsQsv || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            // TODO: add more 8/10bit and 4:4:4 formats for Qsv after finishing the ffcheck tool\n\n            if (is8bitSwFormatsQsv)\n            {\n                if (string.Equals(videoStream.Codec, \"avc\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(videoStream.Codec, \"h264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, hwSurface) + GetHwDecoderName(options, \"h264\", \"qsv\", \"h264\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"vc1\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vc1\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vc1\", \"qsv\", \"vc1\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"vp8\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp8\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vp8\", \"qsv\", \"vp8\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"mpeg2video\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, hwSurface) + GetHwDecoderName(options, \"mpeg2\", \"qsv\", \"mpeg2video\", bitDepth);\n                }\n            }\n\n            if (is8_10bitSwFormatsQsv)\n            {\n                if (string.Equals(videoStream.Codec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(videoStream.Codec, \"h265\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, hwSurface) + GetHwDecoderName(options, \"hevc\", \"qsv\", \"hevc\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"vp9\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vp9\", \"qsv\", \"vp9\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"av1\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"av1\", bitDepth, hwSurface) + GetHwDecoderName(options, \"av1\", \"qsv\", \"av1\", bitDepth);\n                }\n            }\n\n            return null;\n        }\n\n        public string GetNvdecVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            if ((!OperatingSystem.IsWindows() && !OperatingSystem.IsLinux())\n                || !string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var hwSurface = IsCudaFullSupported() && _mediaEncoder.SupportsFilter(\"alphasrc\");\n            var is8bitSwFormatsNvdec = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                       || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsNvdec = is8bitSwFormatsNvdec || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            // TODO: add more 8/10/12bit and 4:4:4 formats for Nvdec after finishing the ffcheck tool\n\n            if (is8bitSwFormatsNvdec)\n            {\n                if (string.Equals(\"avc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, hwSurface) + GetHwDecoderName(options, \"h264\", \"cuvid\", \"h264\", bitDepth);\n                }\n\n                if (string.Equals(\"mpeg2video\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, hwSurface) + GetHwDecoderName(options, \"mpeg2\", \"cuvid\", \"mpeg2video\", bitDepth);\n                }\n\n                if (string.Equals(\"vc1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vc1\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vc1\", \"cuvid\", \"vc1\", bitDepth);\n                }\n\n                if (string.Equals(\"mpeg4\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg4\", bitDepth, hwSurface) + GetHwDecoderName(options, \"mpeg4\", \"cuvid\", \"mpeg4\", bitDepth);\n                }\n\n                if (string.Equals(\"vp8\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp8\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vp8\", \"cuvid\", \"vp8\", bitDepth);\n                }\n            }\n\n            if (is8_10bitSwFormatsNvdec)\n            {\n                if (string.Equals(\"hevc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h265\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, hwSurface) + GetHwDecoderName(options, \"hevc\", \"cuvid\", \"hevc\", bitDepth);\n                }\n\n                if (string.Equals(\"vp9\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vp9\", \"cuvid\", \"vp9\", bitDepth);\n                }\n\n                if (string.Equals(\"av1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"av1\", bitDepth, hwSurface) + GetHwDecoderName(options, \"av1\", \"cuvid\", \"av1\", bitDepth);\n                }\n            }\n\n            return null;\n        }\n\n        public string GetAmfVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            if (!OperatingSystem.IsWindows()\n                || !string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var hwSurface = _mediaEncoder.SupportsHwaccel(\"d3d11va\")\n                && IsOpenclFullSupported()\n                && _mediaEncoder.SupportsFilter(\"alphasrc\");\n            var is8bitSwFormatsAmf = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                     || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsAmf = is8bitSwFormatsAmf || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n\n            if (is8bitSwFormatsAmf)\n            {\n                if (string.Equals(\"avc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"mpeg2video\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vc1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vc1\", bitDepth, hwSurface);\n                }\n            }\n\n            if (is8_10bitSwFormatsAmf)\n            {\n                if (string.Equals(\"hevc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h265\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vp9\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"av1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"av1\", bitDepth, hwSurface);\n                }\n            }\n\n            return null;\n        }\n\n        public string GetVaapiVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            if (!OperatingSystem.IsLinux()\n                || !string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var hwSurface = IsVaapiSupported(state)\n                && IsVaapiFullSupported()\n                && IsOpenclFullSupported()\n                && _mediaEncoder.SupportsFilter(\"alphasrc\");\n            var is8bitSwFormatsVaapi = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                       || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsVaapi = is8bitSwFormatsVaapi || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n\n            if (is8bitSwFormatsVaapi)\n            {\n                if (string.Equals(\"avc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"mpeg2video\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vc1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vc1\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vp8\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp8\", bitDepth, hwSurface);\n                }\n            }\n\n            if (is8_10bitSwFormatsVaapi)\n            {\n                if (string.Equals(\"hevc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h265\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vp9\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"av1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"av1\", bitDepth, hwSurface);\n                }\n            }\n\n            return null;\n        }\n\n        public string GetVideotoolboxVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            if (!OperatingSystem.IsMacOS()\n                || !string.Equals(options.HardwareAccelerationType, \"videotoolbox\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var is8bitSwFormatsVt = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                    || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsVt = is8bitSwFormatsVt || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n\n            if (is8bitSwFormatsVt)\n            {\n                if (string.Equals(\"avc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, false);\n                }\n\n                if (string.Equals(\"mpeg2video\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, false);\n                }\n\n                if (string.Equals(\"mpeg4\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg4\", bitDepth, false);\n                }\n            }\n\n            if (is8_10bitSwFormatsVt)\n            {\n                if (string.Equals(\"hevc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h265\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, false);\n                }\n\n                if (string.Equals(\"vp9\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, false);\n                }\n            }\n\n            return null;\n        }\n\n        /// <summary>\n        /// Gets the number of threads.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"encodingOptions\">Encoding options.</param>\n        /// <param name=\"outputVideoCodec\">Video codec to use.</param>\n        /// <returns>Number of threads.</returns>\n#nullable enable\n        public static int GetNumberOfThreads(EncodingJobInfo? state, EncodingOptions encodingOptions, string? outputVideoCodec)\n        {\n            // VP8 and VP9 encoders must have their thread counts set.\n            bool mustSetThreadCount = string.Equals(outputVideoCodec, \"libvpx\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(outputVideoCodec, \"libvpx-vp9\", StringComparison.OrdinalIgnoreCase);\n\n            var threads = state?.BaseRequest.CpuCoreLimit ?? encodingOptions.EncodingThreadCount;\n\n            if (threads <= 0)\n            {\n                // Automatically set thread count\n                return mustSetThreadCount ? Math.Max(Environment.ProcessorCount - 1, 1) : 0;\n            }\n            else if (threads >= Environment.ProcessorCount)\n            {\n                return Environment.ProcessorCount;\n            }\n\n            return threads;\n        }\n\n#nullable disable\n        public void TryStreamCopy(EncodingJobInfo state)\n        {\n            if (state.VideoStream != null && CanStreamCopyVideo(state, state.VideoStream))\n            {\n                state.OutputVideoCodec = \"copy\";\n            }\n            else\n            {\n                var user = state.User;\n\n                // If the user doesn't have access to transcoding, then force stream copy, regardless of whether it will be compatible or not\n                if (user != null && !user.HasPermission(PermissionKind.EnableVideoPlaybackTranscoding))\n                {\n                    state.OutputVideoCodec = \"copy\";\n                }\n            }\n\n            if (state.AudioStream != null\n                && CanStreamCopyAudio(state, state.AudioStream, state.SupportedAudioCodecs))\n            {\n                state.OutputAudioCodec = \"copy\";\n            }\n            else\n            {\n                var user = state.User;\n\n                // If the user doesn't have access to transcoding, then force stream copy, regardless of whether it will be compatible or not\n                if (user != null && !user.HasPermission(PermissionKind.EnableAudioPlaybackTranscoding))\n                {\n                    state.OutputAudioCodec = \"copy\";\n                }\n            }\n        }\n\n        public string GetInputModifier(EncodingJobInfo state, EncodingOptions encodingOptions, string segmentContainer)\n        {\n            var inputModifier = string.Empty;\n            var analyzeDurationArgument = string.Empty;\n\n            // Apply -analyzeduration as per the environment variable,\n            // otherwise ffmpeg will break on certain files due to default value is 0.\n            // The default value of -probesize is more than enough, so leave it as is.\n            var ffmpegAnalyzeDuration = _config.GetFFmpegAnalyzeDuration() ?? string.Empty;\n\n            if (state.MediaSource.AnalyzeDurationMs > 0)\n            {\n                analyzeDurationArgument = \"-analyzeduration \" + (state.MediaSource.AnalyzeDurationMs.Value * 1000).ToString(CultureInfo.InvariantCulture);\n            }\n            else if (!string.IsNullOrEmpty(ffmpegAnalyzeDuration))\n            {\n                analyzeDurationArgument = \"-analyzeduration \" + ffmpegAnalyzeDuration;\n            }\n\n            if (!string.IsNullOrEmpty(analyzeDurationArgument))\n            {\n                inputModifier += \" \" + analyzeDurationArgument;\n            }\n\n            inputModifier = inputModifier.Trim();\n\n            var userAgentParam = GetUserAgentParam(state);\n\n            if (!string.IsNullOrEmpty(userAgentParam))\n            {\n                inputModifier += \" \" + userAgentParam;\n            }\n\n            inputModifier = inputModifier.Trim();\n\n            inputModifier += \" \" + GetFastSeekCommandLineParameter(state, encodingOptions, segmentContainer);\n            inputModifier = inputModifier.Trim();\n\n            if (state.InputProtocol == MediaProtocol.Rtsp)\n            {\n                inputModifier += \" -rtsp_transport tcp+udp -rtsp_flags prefer_tcp\";\n            }\n\n            if (!string.IsNullOrEmpty(state.InputAudioSync))\n            {\n                inputModifier += \" -async \" + state.InputAudioSync;\n            }\n\n            if (!string.IsNullOrEmpty(state.InputVideoSync))\n            {\n                inputModifier += \" -vsync \" + state.InputVideoSync;\n            }\n\n            if (state.ReadInputAtNativeFramerate && state.InputProtocol != MediaProtocol.Rtsp)\n            {\n                inputModifier += \" -re\";\n            }\n\n            var flags = new List<string>();\n            if (state.IgnoreInputDts)\n            {\n                flags.Add(\"+igndts\");\n            }\n\n            if (state.IgnoreInputIndex)\n            {\n                flags.Add(\"+ignidx\");\n            }\n\n            if (state.GenPtsInput || IsCopyCodec(state.OutputVideoCodec))\n            {\n                flags.Add(\"+genpts\");\n            }\n\n            if (state.DiscardCorruptFramesInput)\n            {\n                flags.Add(\"+discardcorrupt\");\n            }\n\n            if (state.EnableFastSeekInput)\n            {\n                flags.Add(\"+fastseek\");\n            }\n\n            if (flags.Count > 0)\n            {\n                inputModifier += \" -fflags \" + string.Join(string.Empty, flags);\n            }\n\n            if (state.IsVideoRequest)\n            {\n                if (!string.IsNullOrEmpty(state.InputContainer) && state.VideoType == VideoType.VideoFile && string.IsNullOrEmpty(encodingOptions.HardwareAccelerationType))\n                {\n                    var inputFormat = GetInputFormat(state.InputContainer);\n                    if (!string.IsNullOrEmpty(inputFormat))\n                    {\n                        inputModifier += \" -f \" + inputFormat;\n                    }\n                }\n            }\n\n            if (state.MediaSource.RequiresLooping)\n            {\n                inputModifier += \" -stream_loop -1 -reconnect_at_eof 1 -reconnect_streamed 1 -reconnect_delay_max 2\";\n            }\n\n            return inputModifier;\n        }\n\n        public void AttachMediaSourceInfo(\n            EncodingJobInfo state,\n            EncodingOptions encodingOptions,\n            MediaSourceInfo mediaSource,\n            string requestedUrl)\n        {\n            if (state == null)\n            {\n                throw new ArgumentNullException(nameof(state));\n            }\n\n            if (mediaSource == null)\n            {\n                throw new ArgumentNullException(nameof(mediaSource));\n            }\n\n            var path = mediaSource.Path;\n            var protocol = mediaSource.Protocol;\n\n            if (!string.IsNullOrEmpty(mediaSource.EncoderPath) && mediaSource.EncoderProtocol.HasValue)\n            {\n                path = mediaSource.EncoderPath;\n                protocol = mediaSource.EncoderProtocol.Value;\n            }\n\n            state.MediaPath = path;\n            state.InputProtocol = protocol;\n            state.InputContainer = mediaSource.Container;\n            state.RunTimeTicks = mediaSource.RunTimeTicks;\n            state.RemoteHttpHeaders = mediaSource.RequiredHttpHeaders;\n\n            state.IsoType = mediaSource.IsoType;\n\n            if (mediaSource.Timestamp.HasValue)\n            {\n                state.InputTimestamp = mediaSource.Timestamp.Value;\n            }\n\n            state.RunTimeTicks = mediaSource.RunTimeTicks;\n            state.RemoteHttpHeaders = mediaSource.RequiredHttpHeaders;\n            state.ReadInputAtNativeFramerate = mediaSource.ReadAtNativeFramerate;\n\n            if (state.ReadInputAtNativeFramerate\n                || (mediaSource.Protocol == MediaProtocol.File\n                && string.Equals(mediaSource.Container, \"wtv\", StringComparison.OrdinalIgnoreCase)))\n            {\n                state.InputVideoSync = \"-1\";\n                state.InputAudioSync = \"1\";\n            }\n\n            if (string.Equals(mediaSource.Container, \"wma\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(mediaSource.Container, \"asf\", StringComparison.OrdinalIgnoreCase))\n            {\n                // Seeing some stuttering when transcoding wma to audio-only HLS\n                state.InputAudioSync = \"1\";\n            }\n\n            var mediaStreams = mediaSource.MediaStreams;\n\n            if (state.IsVideoRequest)\n            {\n                var videoRequest = state.BaseRequest;\n\n                if (string.IsNullOrEmpty(videoRequest.VideoCodec))\n                {\n                    if (string.IsNullOrEmpty(requestedUrl))\n                    {\n                        requestedUrl = \"test.\" + videoRequest.Container;\n                    }\n\n                    videoRequest.VideoCodec = InferVideoCodec(requestedUrl);\n                }\n\n                state.VideoStream = GetMediaStream(mediaStreams, videoRequest.VideoStreamIndex, MediaStreamType.Video);\n                state.SubtitleStream = GetMediaStream(mediaStreams, videoRequest.SubtitleStreamIndex, MediaStreamType.Subtitle, false);\n                state.SubtitleDeliveryMethod = videoRequest.SubtitleMethod;\n                state.AudioStream = GetMediaStream(mediaStreams, videoRequest.AudioStreamIndex, MediaStreamType.Audio);\n\n                if (state.SubtitleStream != null && !state.SubtitleStream.IsExternal)\n                {\n                    state.InternalSubtitleStreamOffset = mediaStreams.Where(i => i.Type == MediaStreamType.Subtitle && !i.IsExternal).ToList().IndexOf(state.SubtitleStream);\n                }\n\n                EnforceResolutionLimit(state);\n\n                NormalizeSubtitleEmbed(state);\n            }\n            else\n            {\n                state.AudioStream = GetMediaStream(mediaStreams, null, MediaStreamType.Audio, true);\n            }\n\n            state.MediaSource = mediaSource;\n\n            var request = state.BaseRequest;\n            var supportedAudioCodecs = state.SupportedAudioCodecs;\n            if (request != null && supportedAudioCodecs != null && supportedAudioCodecs.Length > 0)\n            {\n                var supportedAudioCodecsList = supportedAudioCodecs.ToList();\n\n                ShiftAudioCodecsIfNeeded(supportedAudioCodecsList, state.AudioStream);\n\n                state.SupportedAudioCodecs = supportedAudioCodecsList.ToArray();\n\n                request.AudioCodec = state.SupportedAudioCodecs.FirstOrDefault(i => _mediaEncoder.CanEncodeToAudioCodec(i))\n                    ?? state.SupportedAudioCodecs.FirstOrDefault();\n            }\n\n            var supportedVideoCodecs = state.SupportedVideoCodecs;\n            if (request != null && supportedVideoCodecs != null && supportedVideoCodecs.Length > 0)\n            {\n                var supportedVideoCodecsList = supportedVideoCodecs.ToList();\n\n                ShiftVideoCodecsIfNeeded(supportedVideoCodecsList, encodingOptions);\n\n                state.SupportedVideoCodecs = supportedVideoCodecsList.ToArray();\n\n                request.VideoCodec = state.SupportedVideoCodecs.FirstOrDefault();\n            }\n        }\n\n        private void ShiftAudioCodecsIfNeeded(List<string> audioCodecs, MediaStream audioStream)\n        {\n            // No need to shift if there is only one supported audio codec.\n            if (audioCodecs.Count < 2)\n            {\n                return;\n            }\n\n            var inputChannels = audioStream is null ? 6 : audioStream.Channels ?? 6;\n            var shiftAudioCodecs = new List<string>();\n            if (inputChannels >= 6)\n            {\n                // DTS and TrueHD are not supported by HLS\n                // Keep them in the supported codecs list, but shift them to the end of the list so that if transcoding happens, another codec is used\n                shiftAudioCodecs.Add(\"dca\");\n                shiftAudioCodecs.Add(\"truehd\");\n            }\n            else\n            {\n                // Transcoding to 2ch ac3 or eac3 almost always causes a playback failure\n                // Keep them in the supported codecs list, but shift them to the end of the list so that if transcoding happens, another codec is used\n                shiftAudioCodecs.Add(\"ac3\");\n                shiftAudioCodecs.Add(\"eac3\");\n            }\n\n            if (audioCodecs.All(i => shiftAudioCodecs.Contains(i, StringComparison.OrdinalIgnoreCase)))\n            {\n                return;\n            }\n\n            while (shiftAudioCodecs.Contains(audioCodecs[0], StringComparison.OrdinalIgnoreCase))\n            {\n                var removed = shiftAudioCodecs[0];\n                audioCodecs.RemoveAt(0);\n                audioCodecs.Add(removed);\n            }\n        }\n\n        private void ShiftVideoCodecsIfNeeded(List<string> videoCodecs, EncodingOptions encodingOptions)\n        {\n            // Shift hevc/h265 to the end of list if hevc encoding is not allowed.\n            if (encodingOptions.AllowHevcEncoding)\n            {\n                return;\n            }\n\n            // No need to shift if there is only one supported video codec.\n            if (videoCodecs.Count < 2)\n            {\n                return;\n            }\n\n            var shiftVideoCodecs = new[] { \"hevc\", \"h265\" };\n            if (videoCodecs.All(i => shiftVideoCodecs.Contains(i, StringComparison.OrdinalIgnoreCase)))\n            {\n                return;\n            }\n\n            while (shiftVideoCodecs.Contains(videoCodecs[0], StringComparison.OrdinalIgnoreCase))\n            {\n                var removed = shiftVideoCodecs[0];\n                videoCodecs.RemoveAt(0);\n                videoCodecs.Add(removed);\n            }\n        }\n\n        private void NormalizeSubtitleEmbed(EncodingJobInfo state)\n        {\n            if (state.SubtitleStream == null || state.SubtitleDeliveryMethod != SubtitleDeliveryMethod.Embed)\n            {\n                return;\n            }\n\n            // This is tricky to remux in, after converting to dvdsub it's not positioned correctly\n            // Therefore, let's just burn it in\n            if (string.Equals(state.SubtitleStream.Codec, \"DVBSUB\", StringComparison.OrdinalIgnoreCase))\n            {\n                state.SubtitleDeliveryMethod = SubtitleDeliveryMethod.Encode;\n            }\n        }\n\n        public string GetSubtitleEmbedArguments(EncodingJobInfo state)\n        {\n            if (state.SubtitleStream == null || state.SubtitleDeliveryMethod != SubtitleDeliveryMethod.Embed)\n            {\n                return string.Empty;\n            }\n\n            var format = state.SupportedSubtitleCodecs.FirstOrDefault();\n            string codec;\n\n            if (string.IsNullOrEmpty(format) || string.Equals(format, state.SubtitleStream.Codec, StringComparison.OrdinalIgnoreCase))\n            {\n                codec = \"copy\";\n            }\n            else\n            {\n                codec = format;\n            }\n\n            return \" -codec:s:0 \" + codec + \" -disposition:s:0 default\";\n        }\n\n        public string GetProgressiveVideoFullCommandLine(EncodingJobInfo state, EncodingOptions encodingOptions, string outputPath, string defaultPreset)\n        {\n            // Get the output codec name\n            var videoCodec = GetVideoEncoder(state, encodingOptions);\n\n            var format = string.Empty;\n            var keyFrame = string.Empty;\n\n            if (string.Equals(Path.GetExtension(outputPath), \".mp4\", StringComparison.OrdinalIgnoreCase)\n                && state.BaseRequest.Context == EncodingContext.Streaming)\n            {\n                // Comparison: https://github.com/jansmolders86/mediacenterjs/blob/master/lib/transcoding/desktop.js\n                format = \" -f mp4 -movflags frag_keyframe+empty_moov\";\n            }\n\n            var threads = GetNumberOfThreads(state, encodingOptions, videoCodec);\n\n            var inputModifier = GetInputModifier(state, encodingOptions, null);\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"{0} {1}{2} {3} {4} -map_metadata -1 -map_chapters -1 -threads {5} {6}{7}{8} -y \\\"{9}\\\"\",\n                inputModifier,\n                GetInputArgument(state, encodingOptions, null),\n                keyFrame,\n                GetMapArgs(state),\n                GetProgressiveVideoArguments(state, encodingOptions, videoCodec, defaultPreset),\n                threads,\n                GetProgressiveVideoAudioArguments(state, encodingOptions),\n                GetSubtitleEmbedArguments(state),\n                format,\n                outputPath).Trim();\n        }\n\n        public string GetOutputFFlags(EncodingJobInfo state)\n        {\n            var flags = new List<string>();\n            if (state.GenPtsOutput)\n            {\n                flags.Add(\"+genpts\");\n            }\n\n            if (flags.Count > 0)\n            {\n                return \" -fflags \" + string.Join(string.Empty, flags);\n            }\n\n            return string.Empty;\n        }\n\n        public string GetProgressiveVideoArguments(EncodingJobInfo state, EncodingOptions encodingOptions, string videoCodec, string defaultPreset)\n        {\n            var args = \"-codec:v:0 \" + videoCodec;\n\n            if (state.BaseRequest.EnableMpegtsM2TsMode)\n            {\n                args += \" -mpegts_m2ts_mode 1\";\n            }\n\n            if (IsCopyCodec(videoCodec))\n            {\n                if (state.VideoStream != null\n                    && string.Equals(state.OutputContainer, \"ts\", StringComparison.OrdinalIgnoreCase)\n                    && !string.Equals(state.VideoStream.NalLengthSize, \"0\", StringComparison.OrdinalIgnoreCase))\n                {\n                    string bitStreamArgs = GetBitStreamArgs(state.VideoStream);\n                    if (!string.IsNullOrEmpty(bitStreamArgs))\n                    {\n                        args += \" \" + bitStreamArgs;\n                    }\n                }\n\n                if (state.RunTimeTicks.HasValue && state.BaseRequest.CopyTimestamps)\n                {\n                    args += \" -copyts -avoid_negative_ts disabled -start_at_zero\";\n                }\n\n                if (!state.RunTimeTicks.HasValue)\n                {\n                    args += \" -fflags +genpts\";\n                }\n            }\n            else\n            {\n                var keyFrameArg = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -force_key_frames \\\"expr:gte(t,n_forced*{0})\\\"\",\n                    5);\n\n                args += keyFrameArg;\n\n                var hasGraphicalSubs = state.SubtitleStream != null && !state.SubtitleStream.IsTextSubtitleStream && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n\n                var hasCopyTs = false;\n\n                // video processing filters.\n                var videoProcessParam = GetVideoProcessingFilterParam(state, encodingOptions, videoCodec);\n\n                var negativeMapArgs = GetNegativeMapArgsByFilters(state, videoProcessParam);\n\n                args = negativeMapArgs + args + videoProcessParam;\n\n                hasCopyTs = videoProcessParam.Contains(\"copyts\", StringComparison.OrdinalIgnoreCase);\n\n                if (state.RunTimeTicks.HasValue && state.BaseRequest.CopyTimestamps)\n                {\n                    if (!hasCopyTs)\n                    {\n                        args += \" -copyts\";\n                    }\n\n                    args += \" -avoid_negative_ts disabled\";\n\n                    if (!(state.SubtitleStream != null && state.SubtitleStream.IsExternal && !state.SubtitleStream.IsTextSubtitleStream))\n                    {\n                        args += \" -start_at_zero\";\n                    }\n                }\n\n                var qualityParam = GetVideoQualityParam(state, videoCodec, encodingOptions, defaultPreset);\n\n                if (!string.IsNullOrEmpty(qualityParam))\n                {\n                    args += \" \" + qualityParam.Trim();\n                }\n            }\n\n            if (!string.IsNullOrEmpty(state.OutputVideoSync))\n            {\n                args += \" -vsync \" + state.OutputVideoSync;\n            }\n\n            args += GetOutputFFlags(state);\n\n            return args;\n        }\n\n        public string GetProgressiveVideoAudioArguments(EncodingJobInfo state, EncodingOptions encodingOptions)\n        {\n            // If the video doesn't have an audio stream, return a default.\n            if (state.AudioStream == null && state.VideoStream != null)\n            {\n                return string.Empty;\n            }\n\n            // Get the output codec name\n            var codec = GetAudioEncoder(state);\n\n            var args = \"-codec:a:0 \" + codec;\n\n            if (IsCopyCodec(codec))\n            {\n                return args;\n            }\n\n            // Add the number of audio channels\n            var channels = state.OutputAudioChannels;\n\n            if (channels.HasValue)\n            {\n                args += \" -ac \" + channels.Value;\n            }\n\n            var bitrate = state.OutputAudioBitrate;\n\n            if (bitrate.HasValue && !LosslessAudioCodecs.Contains(codec, StringComparison.OrdinalIgnoreCase))\n            {\n                args += \" -ab \" + bitrate.Value.ToString(CultureInfo.InvariantCulture);\n            }\n\n            if (state.OutputAudioSampleRate.HasValue)\n            {\n                args += \" -ar \" + state.OutputAudioSampleRate.Value.ToString(CultureInfo.InvariantCulture);\n            }\n\n            args += GetAudioFilterParam(state, encodingOptions);\n\n            return args;\n        }\n\n        public string GetProgressiveAudioFullCommandLine(EncodingJobInfo state, EncodingOptions encodingOptions, string outputPath)\n        {\n            var audioTranscodeParams = new List<string>();\n\n            var bitrate = state.OutputAudioBitrate;\n            var channels = state.OutputAudioChannels;\n            var outputCodec = state.OutputAudioCodec;\n\n            if (bitrate.HasValue && !LosslessAudioCodecs.Contains(outputCodec, StringComparison.OrdinalIgnoreCase))\n            {\n                audioTranscodeParams.Add(\"-ab \" + bitrate.Value.ToString(CultureInfo.InvariantCulture));\n            }\n\n            if (state.OutputAudioChannels.HasValue)\n            {\n                audioTranscodeParams.Add(\"-ac \" + state.OutputAudioChannels.Value.ToString(CultureInfo.InvariantCulture));\n            }\n\n            if (!string.IsNullOrEmpty(outputCodec))\n            {\n                audioTranscodeParams.Add(\"-acodec \" + GetAudioEncoder(state));\n            }\n\n            if (!string.Equals(outputCodec, \"opus\", StringComparison.OrdinalIgnoreCase))\n            {\n                // opus only supports specific sampling rates\n                var sampleRate = state.OutputAudioSampleRate;\n                if (sampleRate.HasValue)\n                {\n                    var sampleRateValue = sampleRate.Value switch\n                    {\n                        <= 8000 => 8000,\n                        <= 12000 => 12000,\n                        <= 16000 => 16000,\n                        <= 24000 => 24000,\n                        _ => 48000\n                    };\n\n                    audioTranscodeParams.Add(\"-ar \" + sampleRateValue.ToString(CultureInfo.InvariantCulture));\n                }\n            }\n\n            var threads = GetNumberOfThreads(state, encodingOptions, null);\n\n            var inputModifier = GetInputModifier(state, encodingOptions, null);\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"{0} {1}{7}{8} -threads {2}{3} {4} -id3v2_version 3 -write_id3v1 1{6} -y \\\"{5}\\\"\",\n                inputModifier,\n                GetInputArgument(state, encodingOptions, null),\n                threads,\n                \" -vn\",\n                string.Join(' ', audioTranscodeParams),\n                outputPath,\n                string.Empty,\n                string.Empty,\n                string.Empty).Trim();\n        }\n\n        public static int FindIndex(IReadOnlyList<MediaStream> mediaStreams, MediaStream streamToFind)\n        {\n            var index = 0;\n            var length = mediaStreams.Count;\n\n            for (var i = 0; i < length; i++)\n            {\n                var currentMediaStream = mediaStreams[i];\n                if (currentMediaStream == streamToFind)\n                {\n                    return index;\n                }\n\n                if (string.Equals(currentMediaStream.Path, streamToFind.Path, StringComparison.Ordinal))\n                {\n                    index++;\n                }\n            }\n\n            return -1;\n        }\n\n        public static bool IsCopyCodec(string codec)\n        {\n            return string.Equals(codec, \"copy\", StringComparison.OrdinalIgnoreCase);\n        }\n    }\n}\n"], "fixing_code": ["using System;\nusing System.Collections.Generic;\nusing System.ComponentModel.DataAnnotations;\nusing System.Threading.Tasks;\nusing Jellyfin.Api.Attributes;\nusing Jellyfin.Api.Helpers;\nusing Jellyfin.Api.Models.StreamingDtos;\nusing MediaBrowser.Controller.MediaEncoding;\nusing MediaBrowser.Model.Dlna;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\n\nnamespace Jellyfin.Api.Controllers\n{\n    /// <summary>\n    /// The audio controller.\n    /// </summary>\n    // TODO: In order to authenticate this in the future, Dlna playback will require updating\n    public class AudioController : BaseJellyfinApiController\n    {\n        private readonly AudioHelper _audioHelper;\n\n        private readonly TranscodingJobType _transcodingJobType = TranscodingJobType.Progressive;\n\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"AudioController\"/> class.\n        /// </summary>\n        /// <param name=\"audioHelper\">Instance of <see cref=\"AudioHelper\"/>.</param>\n        public AudioController(AudioHelper audioHelper)\n        {\n            _audioHelper = audioHelper;\n        }\n\n        /// <summary>\n        /// Gets an audio stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The audio container.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"{itemId}/stream\", Name = \"GetAudioStream\")]\n        [HttpHead(\"{itemId}/stream\", Name = \"HeadAudioStream\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesAudioFile]\n        public async Task<ActionResult> GetAudioStream(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string>? streamOptions)\n        {\n            StreamingRequestDto streamingRequest = new StreamingRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Static,\n                StreamOptions = streamOptions\n            };\n\n            return await _audioHelper.GetAudioStream(_transcodingJobType, streamingRequest).ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets an audio stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The audio container.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment lenght.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamporphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"{itemId}/stream.{container}\", Name = \"GetAudioStreamByContainer\")]\n        [HttpHead(\"{itemId}/stream.{container}\", Name = \"HeadAudioStreamByContainer\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesAudioFile]\n        public async Task<ActionResult> GetAudioStreamByContainer(\n            [FromRoute, Required] Guid itemId,\n            [FromRoute, Required] string container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string>? streamOptions)\n        {\n            StreamingRequestDto streamingRequest = new StreamingRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Static,\n                StreamOptions = streamOptions\n            };\n\n            return await _audioHelper.GetAudioStream(_transcodingJobType, streamingRequest).ConfigureAwait(false);\n        }\n    }\n}\n", "using System;\nusing System.Collections.Generic;\nusing System.ComponentModel.DataAnnotations;\nusing System.Diagnostics.CodeAnalysis;\nusing System.Globalization;\nusing System.IO;\nusing System.Linq;\nusing System.Text;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing Jellyfin.Api.Attributes;\nusing Jellyfin.Api.Constants;\nusing Jellyfin.Api.Helpers;\nusing Jellyfin.Api.Models.PlaybackDtos;\nusing Jellyfin.Api.Models.StreamingDtos;\nusing Jellyfin.Extensions;\nusing Jellyfin.MediaEncoding.Hls.Playlist;\nusing MediaBrowser.Common.Configuration;\nusing MediaBrowser.Controller.Configuration;\nusing MediaBrowser.Controller.Devices;\nusing MediaBrowser.Controller.Dlna;\nusing MediaBrowser.Controller.Library;\nusing MediaBrowser.Controller.MediaEncoding;\nusing MediaBrowser.Controller.Net;\nusing MediaBrowser.MediaEncoding.Encoder;\nusing MediaBrowser.Model.Configuration;\nusing MediaBrowser.Model.Dlna;\nusing MediaBrowser.Model.IO;\nusing MediaBrowser.Model.Net;\nusing Microsoft.AspNetCore.Authorization;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Logging;\n\nnamespace Jellyfin.Api.Controllers\n{\n    /// <summary>\n    /// Dynamic hls controller.\n    /// </summary>\n    [Route(\"\")]\n    [Authorize(Policy = Policies.DefaultAuthorization)]\n    public class DynamicHlsController : BaseJellyfinApiController\n    {\n        private const string DefaultVodEncoderPreset = \"veryfast\";\n        private const string DefaultEventEncoderPreset = \"superfast\";\n        private const TranscodingJobType TranscodingJobType = MediaBrowser.Controller.MediaEncoding.TranscodingJobType.Hls;\n\n        private readonly ILibraryManager _libraryManager;\n        private readonly IUserManager _userManager;\n        private readonly IDlnaManager _dlnaManager;\n        private readonly IAuthorizationContext _authContext;\n        private readonly IMediaSourceManager _mediaSourceManager;\n        private readonly IServerConfigurationManager _serverConfigurationManager;\n        private readonly IMediaEncoder _mediaEncoder;\n        private readonly IFileSystem _fileSystem;\n        private readonly IDeviceManager _deviceManager;\n        private readonly TranscodingJobHelper _transcodingJobHelper;\n        private readonly ILogger<DynamicHlsController> _logger;\n        private readonly EncodingHelper _encodingHelper;\n        private readonly IDynamicHlsPlaylistGenerator _dynamicHlsPlaylistGenerator;\n        private readonly DynamicHlsHelper _dynamicHlsHelper;\n        private readonly EncodingOptions _encodingOptions;\n\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"DynamicHlsController\"/> class.\n        /// </summary>\n        /// <param name=\"libraryManager\">Instance of the <see cref=\"ILibraryManager\"/> interface.</param>\n        /// <param name=\"userManager\">Instance of the <see cref=\"IUserManager\"/> interface.</param>\n        /// <param name=\"dlnaManager\">Instance of the <see cref=\"IDlnaManager\"/> interface.</param>\n        /// <param name=\"authContext\">Instance of the <see cref=\"IAuthorizationContext\"/> interface.</param>\n        /// <param name=\"mediaSourceManager\">Instance of the <see cref=\"IMediaSourceManager\"/> interface.</param>\n        /// <param name=\"serverConfigurationManager\">Instance of the <see cref=\"IServerConfigurationManager\"/> interface.</param>\n        /// <param name=\"mediaEncoder\">Instance of the <see cref=\"IMediaEncoder\"/> interface.</param>\n        /// <param name=\"fileSystem\">Instance of the <see cref=\"IFileSystem\"/> interface.</param>\n        /// <param name=\"deviceManager\">Instance of the <see cref=\"IDeviceManager\"/> interface.</param>\n        /// <param name=\"transcodingJobHelper\">Instance of the <see cref=\"TranscodingJobHelper\"/> class.</param>\n        /// <param name=\"logger\">Instance of the <see cref=\"ILogger{DynamicHlsController}\"/> interface.</param>\n        /// <param name=\"dynamicHlsHelper\">Instance of <see cref=\"DynamicHlsHelper\"/>.</param>\n        /// <param name=\"encodingHelper\">Instance of <see cref=\"EncodingHelper\"/>.</param>\n        /// <param name=\"dynamicHlsPlaylistGenerator\">Instance of <see cref=\"IDynamicHlsPlaylistGenerator\"/>.</param>\n        public DynamicHlsController(\n            ILibraryManager libraryManager,\n            IUserManager userManager,\n            IDlnaManager dlnaManager,\n            IAuthorizationContext authContext,\n            IMediaSourceManager mediaSourceManager,\n            IServerConfigurationManager serverConfigurationManager,\n            IMediaEncoder mediaEncoder,\n            IFileSystem fileSystem,\n            IDeviceManager deviceManager,\n            TranscodingJobHelper transcodingJobHelper,\n            ILogger<DynamicHlsController> logger,\n            DynamicHlsHelper dynamicHlsHelper,\n            EncodingHelper encodingHelper,\n            IDynamicHlsPlaylistGenerator dynamicHlsPlaylistGenerator)\n        {\n            _libraryManager = libraryManager;\n            _userManager = userManager;\n            _dlnaManager = dlnaManager;\n            _authContext = authContext;\n            _mediaSourceManager = mediaSourceManager;\n            _serverConfigurationManager = serverConfigurationManager;\n            _mediaEncoder = mediaEncoder;\n            _fileSystem = fileSystem;\n            _deviceManager = deviceManager;\n            _transcodingJobHelper = transcodingJobHelper;\n            _logger = logger;\n            _dynamicHlsHelper = dynamicHlsHelper;\n            _encodingHelper = encodingHelper;\n            _dynamicHlsPlaylistGenerator = dynamicHlsPlaylistGenerator;\n\n            _encodingOptions = serverConfigurationManager.GetEncodingOptions();\n        }\n\n        /// <summary>\n        /// Gets a hls live stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The audio container.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment lenght.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <param name=\"maxWidth\">Optional. The max width.</param>\n        /// <param name=\"maxHeight\">Optional. The max height.</param>\n        /// <param name=\"enableSubtitlesInManifest\">Optional. Whether to enable subtitles in the manifest.</param>\n        /// <response code=\"200\">Hls live stream retrieved.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the hls file.</returns>\n        [HttpGet(\"Videos/{itemId}/live.m3u8\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetLiveHlsStream(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] bool? enableSubtitlesInManifest)\n        {\n            VideoRequestDto streamingRequest = new VideoRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions,\n                MaxHeight = maxHeight,\n                MaxWidth = maxWidth,\n                EnableSubtitlesInManifest = enableSubtitlesInManifest ?? true\n            };\n\n            // CTS lifecycle is managed internally.\n            var cancellationTokenSource = new CancellationTokenSource();\n            // Due to CTS.Token calling ThrowIfDisposed (https://github.com/dotnet/runtime/issues/29970) we have to \"cache\" the token\n            // since it gets disposed when ffmpeg exits\n            var cancellationToken = cancellationTokenSource.Token;\n            var state = await StreamingHelpers.GetStreamingState(\n                    streamingRequest,\n                    Request,\n                    _authContext,\n                    _mediaSourceManager,\n                    _userManager,\n                    _libraryManager,\n                    _serverConfigurationManager,\n                    _mediaEncoder,\n                    _encodingHelper,\n                    _dlnaManager,\n                    _deviceManager,\n                    _transcodingJobHelper,\n                    TranscodingJobType,\n                    cancellationToken)\n                .ConfigureAwait(false);\n\n            TranscodingJobDto? job = null;\n            var playlistPath = Path.ChangeExtension(state.OutputFilePath, \".m3u8\");\n\n            if (!System.IO.File.Exists(playlistPath))\n            {\n                var transcodingLock = _transcodingJobHelper.GetTranscodingLock(playlistPath);\n                await transcodingLock.WaitAsync(cancellationToken).ConfigureAwait(false);\n                try\n                {\n                    if (!System.IO.File.Exists(playlistPath))\n                    {\n                        // If the playlist doesn't already exist, startup ffmpeg\n                        try\n                        {\n                            job = await _transcodingJobHelper.StartFfMpeg(\n                                    state,\n                                    playlistPath,\n                                    GetCommandLineArguments(playlistPath, state, true, 0),\n                                    Request,\n                                    TranscodingJobType,\n                                    cancellationTokenSource)\n                                .ConfigureAwait(false);\n                            job.IsLiveOutput = true;\n                        }\n                        catch\n                        {\n                            state.Dispose();\n                            throw;\n                        }\n\n                        minSegments = state.MinSegments;\n                        if (minSegments > 0)\n                        {\n                            await HlsHelpers.WaitForMinimumSegmentCount(playlistPath, minSegments, _logger, cancellationToken).ConfigureAwait(false);\n                        }\n                    }\n                }\n                finally\n                {\n                    transcodingLock.Release();\n                }\n            }\n\n            job ??= _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n\n            if (job != null)\n            {\n                _transcodingJobHelper.OnTranscodeEndRequest(job);\n            }\n\n            var playlistText = HlsHelpers.GetLivePlaylistText(playlistPath, state);\n\n            return Content(playlistText, MimeTypes.GetMimeType(\"playlist.m3u8\"));\n        }\n\n        /// <summary>\n        /// Gets a video hls playlist stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <param name=\"enableAdaptiveBitrateStreaming\">Enable adaptive bitrate streaming.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the playlist file.</returns>\n        [HttpGet(\"Videos/{itemId}/master.m3u8\")]\n        [HttpHead(\"Videos/{itemId}/master.m3u8\", Name = \"HeadMasterHlsVideoPlaylist\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetMasterHlsVideoPlaylist(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery, Required] string mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions,\n            [FromQuery] bool enableAdaptiveBitrateStreaming = true)\n        {\n            var streamingRequest = new HlsVideoRequestDto\n            {\n                Id = itemId,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                MaxWidth = maxWidth,\n                MaxHeight = maxHeight,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions,\n                EnableAdaptiveBitrateStreaming = enableAdaptiveBitrateStreaming\n            };\n\n            return await _dynamicHlsHelper.GetMasterHlsPlaylist(TranscodingJobType, streamingRequest, enableAdaptiveBitrateStreaming).ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets an audio hls playlist stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"maxStreamingBitrate\">Optional. The maximum streaming bitrate.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <param name=\"enableAdaptiveBitrateStreaming\">Enable adaptive bitrate streaming.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the playlist file.</returns>\n        [HttpGet(\"Audio/{itemId}/master.m3u8\")]\n        [HttpHead(\"Audio/{itemId}/master.m3u8\", Name = \"HeadMasterHlsAudioPlaylist\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetMasterHlsAudioPlaylist(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery, Required] string mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? maxStreamingBitrate,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions,\n            [FromQuery] bool enableAdaptiveBitrateStreaming = true)\n        {\n            var streamingRequest = new HlsAudioRequestDto\n            {\n                Id = itemId,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate ?? maxStreamingBitrate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions,\n                EnableAdaptiveBitrateStreaming = enableAdaptiveBitrateStreaming\n            };\n\n            return await _dynamicHlsHelper.GetMasterHlsPlaylist(TranscodingJobType, streamingRequest, enableAdaptiveBitrateStreaming).ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets a video stream using HTTP live streaming.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"Videos/{itemId}/main.m3u8\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetVariantHlsVideoPlaylist(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            using var cancellationTokenSource = new CancellationTokenSource();\n            var streamingRequest = new VideoRequestDto\n            {\n                Id = itemId,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                MaxWidth = maxWidth,\n                MaxHeight = maxHeight,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            return await GetVariantPlaylistInternal(streamingRequest, cancellationTokenSource)\n                .ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets an audio stream using HTTP live streaming.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"maxStreamingBitrate\">Optional. The maximum streaming bitrate.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vpx, wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"Audio/{itemId}/main.m3u8\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesPlaylistFile]\n        public async Task<ActionResult> GetVariantHlsAudioPlaylist(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? maxStreamingBitrate,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            using var cancellationTokenSource = new CancellationTokenSource();\n            var streamingRequest = new StreamingRequestDto\n            {\n                Id = itemId,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate ?? maxStreamingBitrate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            return await GetVariantPlaylistInternal(streamingRequest, cancellationTokenSource)\n                .ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets a video stream using HTTP live streaming.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"playlistId\">The playlist id.</param>\n        /// <param name=\"segmentId\">The segment id.</param>\n        /// <param name=\"container\">The video container. Possible values are: ts, webm, asf, wmv, ogv, mp4, m4v, mkv, mpeg, mpg, avi, 3gp, wmv, wtv, m2ts, mov, iso, flv. </param>\n        /// <param name=\"runtimeTicks\">The position of the requested segment in ticks.</param>\n        /// <param name=\"actualSegmentLengthTicks\">The length of the requested segment in ticks.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The desired segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"Videos/{itemId}/hls1/{playlistId}/{segmentId}.{container}\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesVideoFile]\n        [SuppressMessage(\"Microsoft.Performance\", \"CA1801:ReviewUnusedParameters\", MessageId = \"playlistId\", Justification = \"Imported from ServiceStack\")]\n        public async Task<ActionResult> GetHlsVideoSegment(\n            [FromRoute, Required] Guid itemId,\n            [FromRoute, Required] string playlistId,\n            [FromRoute, Required] int segmentId,\n            [FromRoute, Required] string container,\n            [FromQuery, Required] long runtimeTicks,\n            [FromQuery, Required] long actualSegmentLengthTicks,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            var streamingRequest = new VideoRequestDto\n            {\n                Id = itemId,\n                CurrentRuntimeTicks = runtimeTicks,\n                ActualSegmentLengthTicks = actualSegmentLengthTicks,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                MaxWidth = maxWidth,\n                MaxHeight = maxHeight,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            return await GetDynamicSegment(streamingRequest, segmentId)\n                .ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets a video stream using HTTP live streaming.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"playlistId\">The playlist id.</param>\n        /// <param name=\"segmentId\">The segment id.</param>\n        /// <param name=\"container\">The video container. Possible values are: ts, webm, asf, wmv, ogv, mp4, m4v, mkv, mpeg, mpg, avi, 3gp, wmv, wtv, m2ts, mov, iso, flv. </param>\n        /// <param name=\"runtimeTicks\">The position of the requested segment in ticks.</param>\n        /// <param name=\"actualSegmentLengthTicks\">The length of the requested segment in ticks.</param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"maxStreamingBitrate\">Optional. The maximum streaming bitrate.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vpx, wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"Audio/{itemId}/hls1/{playlistId}/{segmentId}.{container}\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesAudioFile]\n        [SuppressMessage(\"Microsoft.Performance\", \"CA1801:ReviewUnusedParameters\", MessageId = \"playlistId\", Justification = \"Imported from ServiceStack\")]\n        public async Task<ActionResult> GetHlsAudioSegment(\n            [FromRoute, Required] Guid itemId,\n            [FromRoute, Required] string playlistId,\n            [FromRoute, Required] int segmentId,\n            [FromRoute, Required] string container,\n            [FromQuery, Required] long runtimeTicks,\n            [FromQuery, Required] long actualSegmentLengthTicks,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? maxStreamingBitrate,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            var streamingRequest = new StreamingRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                CurrentRuntimeTicks = runtimeTicks,\n                ActualSegmentLengthTicks = actualSegmentLengthTicks,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate ?? maxStreamingBitrate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            return await GetDynamicSegment(streamingRequest, segmentId)\n                .ConfigureAwait(false);\n        }\n\n        private async Task<ActionResult> GetVariantPlaylistInternal(StreamingRequestDto streamingRequest, CancellationTokenSource cancellationTokenSource)\n        {\n            using var state = await StreamingHelpers.GetStreamingState(\n                    streamingRequest,\n                    Request,\n                    _authContext,\n                    _mediaSourceManager,\n                    _userManager,\n                    _libraryManager,\n                    _serverConfigurationManager,\n                    _mediaEncoder,\n                    _encodingHelper,\n                    _dlnaManager,\n                    _deviceManager,\n                    _transcodingJobHelper,\n                    TranscodingJobType,\n                    cancellationTokenSource.Token)\n                .ConfigureAwait(false);\n\n            var request = new CreateMainPlaylistRequest(\n                state.MediaPath,\n                state.SegmentLength * 1000,\n                state.RunTimeTicks ?? 0,\n                state.Request.SegmentContainer ?? string.Empty,\n                \"hls1/main/\",\n                Request.QueryString.ToString(),\n                EncodingHelper.IsCopyCodec(state.OutputVideoCodec));\n            var playlist = _dynamicHlsPlaylistGenerator.CreateMainPlaylist(request);\n\n            return new FileContentResult(Encoding.UTF8.GetBytes(playlist), MimeTypes.GetMimeType(\"playlist.m3u8\"));\n        }\n\n        private async Task<ActionResult> GetDynamicSegment(StreamingRequestDto streamingRequest, int segmentId)\n        {\n            if ((streamingRequest.StartTimeTicks ?? 0) > 0)\n            {\n                throw new ArgumentException(\"StartTimeTicks is not allowed.\");\n            }\n\n            // CTS lifecycle is managed internally.\n            var cancellationTokenSource = new CancellationTokenSource();\n            var cancellationToken = cancellationTokenSource.Token;\n\n            var state = await StreamingHelpers.GetStreamingState(\n                    streamingRequest,\n                    Request,\n                    _authContext,\n                    _mediaSourceManager,\n                    _userManager,\n                    _libraryManager,\n                    _serverConfigurationManager,\n                    _mediaEncoder,\n                    _encodingHelper,\n                    _dlnaManager,\n                    _deviceManager,\n                    _transcodingJobHelper,\n                    TranscodingJobType,\n                    cancellationToken)\n                .ConfigureAwait(false);\n\n            var playlistPath = Path.ChangeExtension(state.OutputFilePath, \".m3u8\");\n\n            var segmentPath = GetSegmentPath(state, playlistPath, segmentId);\n\n            var segmentExtension = EncodingHelper.GetSegmentFileExtension(state.Request.SegmentContainer);\n\n            TranscodingJobDto? job;\n\n            if (System.IO.File.Exists(segmentPath))\n            {\n                job = _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n                _logger.LogDebug(\"returning {0} [it exists, try 1]\", segmentPath);\n                return await GetSegmentResult(state, playlistPath, segmentPath, segmentExtension, segmentId, job, cancellationToken).ConfigureAwait(false);\n            }\n\n            var transcodingLock = _transcodingJobHelper.GetTranscodingLock(playlistPath);\n            await transcodingLock.WaitAsync(cancellationToken).ConfigureAwait(false);\n            var released = false;\n            var startTranscoding = false;\n\n            try\n            {\n                if (System.IO.File.Exists(segmentPath))\n                {\n                    job = _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n                    transcodingLock.Release();\n                    released = true;\n                    _logger.LogDebug(\"returning {0} [it exists, try 2]\", segmentPath);\n                    return await GetSegmentResult(state, playlistPath, segmentPath, segmentExtension, segmentId, job, cancellationToken).ConfigureAwait(false);\n                }\n                else\n                {\n                    var currentTranscodingIndex = GetCurrentTranscodingIndex(playlistPath, segmentExtension);\n                    var segmentGapRequiringTranscodingChange = 24 / state.SegmentLength;\n\n                    if (segmentId == -1)\n                    {\n                        _logger.LogDebug(\"Starting transcoding because fmp4 init file is being requested\");\n                        startTranscoding = true;\n                        segmentId = 0;\n                    }\n                    else if (currentTranscodingIndex == null)\n                    {\n                        _logger.LogDebug(\"Starting transcoding because currentTranscodingIndex=null\");\n                        startTranscoding = true;\n                    }\n                    else if (segmentId < currentTranscodingIndex.Value)\n                    {\n                        _logger.LogDebug(\"Starting transcoding because requestedIndex={0} and currentTranscodingIndex={1}\", segmentId, currentTranscodingIndex);\n                        startTranscoding = true;\n                    }\n                    else if (segmentId - currentTranscodingIndex.Value > segmentGapRequiringTranscodingChange)\n                    {\n                        _logger.LogDebug(\"Starting transcoding because segmentGap is {0} and max allowed gap is {1}. requestedIndex={2}\", segmentId - currentTranscodingIndex.Value, segmentGapRequiringTranscodingChange, segmentId);\n                        startTranscoding = true;\n                    }\n\n                    if (startTranscoding)\n                    {\n                        // If the playlist doesn't already exist, startup ffmpeg\n                        try\n                        {\n                            await _transcodingJobHelper.KillTranscodingJobs(streamingRequest.DeviceId, streamingRequest.PlaySessionId, p => false)\n                                .ConfigureAwait(false);\n\n                            if (currentTranscodingIndex.HasValue)\n                            {\n                                DeleteLastFile(playlistPath, segmentExtension, 0);\n                            }\n\n                            streamingRequest.StartTimeTicks = streamingRequest.CurrentRuntimeTicks;\n\n                            state.WaitForPath = segmentPath;\n                            job = await _transcodingJobHelper.StartFfMpeg(\n                                state,\n                                playlistPath,\n                                GetCommandLineArguments(playlistPath, state, false, segmentId),\n                                Request,\n                                TranscodingJobType,\n                                cancellationTokenSource).ConfigureAwait(false);\n                        }\n                        catch\n                        {\n                            state.Dispose();\n                            throw;\n                        }\n\n                        // await WaitForMinimumSegmentCount(playlistPath, 1, cancellationTokenSource.Token).ConfigureAwait(false);\n                    }\n                    else\n                    {\n                        job = _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n                        if (job?.TranscodingThrottler != null)\n                        {\n                            await job.TranscodingThrottler.UnpauseTranscoding().ConfigureAwait(false);\n                        }\n                    }\n                }\n            }\n            finally\n            {\n                if (!released)\n                {\n                    transcodingLock.Release();\n                }\n            }\n\n            _logger.LogDebug(\"returning {0} [general case]\", segmentPath);\n            job ??= _transcodingJobHelper.OnTranscodeBeginRequest(playlistPath, TranscodingJobType);\n            return await GetSegmentResult(state, playlistPath, segmentPath, segmentExtension, segmentId, job, cancellationToken).ConfigureAwait(false);\n        }\n\n        private static double[] GetSegmentLengths(StreamState state)\n            => GetSegmentLengthsInternal(state.RunTimeTicks ?? 0, state.SegmentLength);\n\n        internal static double[] GetSegmentLengthsInternal(long runtimeTicks, int segmentlength)\n        {\n            var segmentLengthTicks = TimeSpan.FromSeconds(segmentlength).Ticks;\n            var wholeSegments = runtimeTicks / segmentLengthTicks;\n            var remainingTicks = runtimeTicks % segmentLengthTicks;\n\n            var segmentsLen = wholeSegments + (remainingTicks == 0 ? 0 : 1);\n            var segments = new double[segmentsLen];\n            for (int i = 0; i < wholeSegments; i++)\n            {\n                segments[i] = segmentlength;\n            }\n\n            if (remainingTicks != 0)\n            {\n                segments[^1] = TimeSpan.FromTicks(remainingTicks).TotalSeconds;\n            }\n\n            return segments;\n        }\n\n        private string GetCommandLineArguments(string outputPath, StreamState state, bool isEventPlaylist, int startNumber)\n        {\n            var videoCodec = _encodingHelper.GetVideoEncoder(state, _encodingOptions);\n            var threads = EncodingHelper.GetNumberOfThreads(state, _encodingOptions, videoCodec);\n\n            if (state.BaseRequest.BreakOnNonKeyFrames)\n            {\n                // FIXME: this is actually a workaround, as ideally it really should be the client which decides whether non-keyframe\n                //        breakpoints are supported; but current implementation always uses \"ffmpeg input seeking\" which is liable\n                //        to produce a missing part of video stream before first keyframe is encountered, which may lead to\n                //        awkward cases like a few starting HLS segments having no video whatsoever, which breaks hls.js\n                _logger.LogInformation(\"Current HLS implementation doesn't support non-keyframe breaks but one is requested, ignoring that request\");\n                state.BaseRequest.BreakOnNonKeyFrames = false;\n            }\n\n            var mapArgs = state.IsOutputVideo ? _encodingHelper.GetMapArgs(state) : string.Empty;\n\n            var directory = Path.GetDirectoryName(outputPath) ?? throw new ArgumentException($\"Provided path ({outputPath}) is not valid.\", nameof(outputPath));\n            var outputFileNameWithoutExtension = Path.GetFileNameWithoutExtension(outputPath);\n            var outputPrefix = Path.Combine(directory, outputFileNameWithoutExtension);\n            var outputExtension = EncodingHelper.GetSegmentFileExtension(state.Request.SegmentContainer);\n            var outputTsArg = outputPrefix + \"%d\" + outputExtension;\n\n            var segmentFormat = string.Empty;\n            var segmentContainer = outputExtension.TrimStart('.');\n            var inputModifier = _encodingHelper.GetInputModifier(state, _encodingOptions, segmentContainer);\n\n            if (string.Equals(segmentContainer, \"ts\", StringComparison.OrdinalIgnoreCase))\n            {\n                segmentFormat = \"mpegts\";\n            }\n            else if (string.Equals(segmentContainer, \"mp4\", StringComparison.OrdinalIgnoreCase))\n            {\n                var outputFmp4HeaderArg = OperatingSystem.IsWindows() switch\n                {\n                    // on Windows, the path of fmp4 header file needs to be configured\n                    true => \" -hls_fmp4_init_filename \\\"\" + outputPrefix + \"-1\" + outputExtension + \"\\\"\",\n                    // on Linux/Unix, ffmpeg generate fmp4 header file to m3u8 output folder\n                    false => \" -hls_fmp4_init_filename \\\"\" + outputFileNameWithoutExtension + \"-1\" + outputExtension + \"\\\"\"\n                };\n\n                segmentFormat = \"fmp4\" + outputFmp4HeaderArg;\n            }\n            else\n            {\n                _logger.LogError(\"Invalid HLS segment container: {SegmentContainer}, default to mpegts\", segmentContainer);\n                segmentFormat = \"mpegts\";\n            }\n\n            var maxMuxingQueueSize = _encodingOptions.MaxMuxingQueueSize > 128\n                ? _encodingOptions.MaxMuxingQueueSize.ToString(CultureInfo.InvariantCulture)\n                : \"128\";\n\n            var baseUrlParam = string.Empty;\n            if (isEventPlaylist)\n            {\n                baseUrlParam = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -hls_base_url \\\"hls/{0}/\\\"\",\n                    Path.GetFileNameWithoutExtension(outputPath));\n            }\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"{0} {1} -map_metadata -1 -map_chapters -1 -threads {2} {3} {4} {5} -copyts -avoid_negative_ts disabled -max_muxing_queue_size {6} -f hls -max_delay 5000000 -hls_time {7} -hls_segment_type {8} -start_number {9}{10} -hls_segment_filename \\\"{12}\\\" -hls_playlist_type {11} -hls_list_size 0 -y \\\"{13}\\\"\",\n                inputModifier,\n                _encodingHelper.GetInputArgument(state, _encodingOptions, segmentContainer),\n                threads,\n                mapArgs,\n                GetVideoArguments(state, startNumber, isEventPlaylist),\n                GetAudioArguments(state),\n                maxMuxingQueueSize,\n                state.SegmentLength.ToString(CultureInfo.InvariantCulture),\n                segmentFormat,\n                startNumber.ToString(CultureInfo.InvariantCulture),\n                baseUrlParam,\n                isEventPlaylist ? \"event\" : \"vod\",\n                EncodingUtils.NormalizePath(outputTsArg),\n                EncodingUtils.NormalizePath(outputPath)).Trim();\n        }\n\n        /// <summary>\n        /// Gets the audio arguments for transcoding.\n        /// </summary>\n        /// <param name=\"state\">The <see cref=\"StreamState\"/>.</param>\n        /// <returns>The command line arguments for audio transcoding.</returns>\n        private string GetAudioArguments(StreamState state)\n        {\n            if (state.AudioStream == null)\n            {\n                return string.Empty;\n            }\n\n            var audioCodec = _encodingHelper.GetAudioEncoder(state);\n\n            if (!state.IsOutputVideo)\n            {\n                if (EncodingHelper.IsCopyCodec(audioCodec))\n                {\n                    var bitStreamArgs = EncodingHelper.GetAudioBitStreamArguments(state, state.Request.SegmentContainer, state.MediaSource.Container);\n\n                    return \"-acodec copy -strict -2\" + bitStreamArgs;\n                }\n\n                var audioTranscodeParams = string.Empty;\n\n                audioTranscodeParams += \"-acodec \" + audioCodec;\n\n                if (state.OutputAudioBitrate.HasValue && !EncodingHelper.LosslessAudioCodecs.Contains(state.ActualOutputAudioCodec, StringComparison.OrdinalIgnoreCase))\n                {\n                    audioTranscodeParams += \" -ab \" + state.OutputAudioBitrate.Value.ToString(CultureInfo.InvariantCulture);\n                }\n\n                if (state.OutputAudioChannels.HasValue)\n                {\n                    audioTranscodeParams += \" -ac \" + state.OutputAudioChannels.Value.ToString(CultureInfo.InvariantCulture);\n                }\n\n                if (state.OutputAudioSampleRate.HasValue)\n                {\n                    audioTranscodeParams += \" -ar \" + state.OutputAudioSampleRate.Value.ToString(CultureInfo.InvariantCulture);\n                }\n\n                audioTranscodeParams += \" -vn\";\n                return audioTranscodeParams;\n            }\n\n            // dts, flac, opus and truehd are experimental in mp4 muxer\n            var strictArgs = string.Empty;\n            var actualOutputAudioCodec = state.ActualOutputAudioCodec;\n            if (string.Equals(actualOutputAudioCodec, \"flac\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(actualOutputAudioCodec, \"opus\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(actualOutputAudioCodec, \"dts\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(actualOutputAudioCodec, \"truehd\", StringComparison.OrdinalIgnoreCase))\n            {\n                strictArgs = \" -strict -2\";\n            }\n\n            if (EncodingHelper.IsCopyCodec(audioCodec))\n            {\n                var videoCodec = _encodingHelper.GetVideoEncoder(state, _encodingOptions);\n                var bitStreamArgs = EncodingHelper.GetAudioBitStreamArguments(state, state.Request.SegmentContainer, state.MediaSource.Container);\n                var copyArgs = \"-codec:a:0 copy\" + bitStreamArgs + strictArgs;\n\n                if (EncodingHelper.IsCopyCodec(videoCodec) && state.EnableBreakOnNonKeyFrames(videoCodec))\n                {\n                    return copyArgs + \" -copypriorss:a:0 0\";\n                }\n\n                return copyArgs;\n            }\n\n            var args = \"-codec:a:0 \" + audioCodec + strictArgs;\n\n            var channels = state.OutputAudioChannels;\n\n            if (channels.HasValue)\n            {\n                args += \" -ac \" + channels.Value;\n            }\n\n            var bitrate = state.OutputAudioBitrate;\n            if (bitrate.HasValue && !EncodingHelper.LosslessAudioCodecs.Contains(actualOutputAudioCodec, StringComparison.OrdinalIgnoreCase))\n            {\n                args += \" -ab \" + bitrate.Value.ToString(CultureInfo.InvariantCulture);\n            }\n\n            if (state.OutputAudioSampleRate.HasValue)\n            {\n                args += \" -ar \" + state.OutputAudioSampleRate.Value.ToString(CultureInfo.InvariantCulture);\n            }\n\n            args += _encodingHelper.GetAudioFilterParam(state, _encodingOptions);\n\n            return args;\n        }\n\n        /// <summary>\n        /// Gets the video arguments for transcoding.\n        /// </summary>\n        /// <param name=\"state\">The <see cref=\"StreamState\"/>.</param>\n        /// <param name=\"startNumber\">The first number in the hls sequence.</param>\n        /// <param name=\"isEventPlaylist\">Whether the playlist is EVENT or VOD.</param>\n        /// <returns>The command line arguments for video transcoding.</returns>\n        private string GetVideoArguments(StreamState state, int startNumber, bool isEventPlaylist)\n        {\n            if (state.VideoStream == null)\n            {\n                return string.Empty;\n            }\n\n            if (!state.IsOutputVideo)\n            {\n                return string.Empty;\n            }\n\n            var codec = _encodingHelper.GetVideoEncoder(state, _encodingOptions);\n\n            var args = \"-codec:v:0 \" + codec;\n\n            if (string.Equals(state.ActualOutputVideoCodec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(state.ActualOutputVideoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (EncodingHelper.IsCopyCodec(codec)\n                    && (string.Equals(state.VideoStream.VideoRangeType, \"DOVI\", StringComparison.OrdinalIgnoreCase)\n                        || string.Equals(state.VideoStream.CodecTag, \"dovi\", StringComparison.OrdinalIgnoreCase)\n                        || string.Equals(state.VideoStream.CodecTag, \"dvh1\", StringComparison.OrdinalIgnoreCase)\n                        || string.Equals(state.VideoStream.CodecTag, \"dvhe\", StringComparison.OrdinalIgnoreCase)))\n                {\n                    // Prefer dvh1 to dvhe\n                    args += \" -tag:v:0 dvh1 -strict -2\";\n                }\n                else\n                {\n                    // Prefer hvc1 to hev1\n                    args += \" -tag:v:0 hvc1\";\n                }\n            }\n\n            // if  (state.EnableMpegtsM2TsMode)\n            // {\n            //     args += \" -mpegts_m2ts_mode 1\";\n            // }\n\n            // See if we can save come cpu cycles by avoiding encoding.\n            if (EncodingHelper.IsCopyCodec(codec))\n            {\n                // If h264_mp4toannexb is ever added, do not use it for live tv.\n                if (state.VideoStream != null && !string.Equals(state.VideoStream.NalLengthSize, \"0\", StringComparison.OrdinalIgnoreCase))\n                {\n                    string bitStreamArgs = EncodingHelper.GetBitStreamArgs(state.VideoStream);\n                    if (!string.IsNullOrEmpty(bitStreamArgs))\n                    {\n                        args += \" \" + bitStreamArgs;\n                    }\n                }\n\n                args += \" -start_at_zero\";\n            }\n            else\n            {\n                args += _encodingHelper.GetVideoQualityParam(state, codec, _encodingOptions, isEventPlaylist ? DefaultEventEncoderPreset : DefaultVodEncoderPreset);\n\n                // Set the key frame params for video encoding to match the hls segment time.\n                args += _encodingHelper.GetHlsVideoKeyFrameArguments(state, codec, state.SegmentLength, isEventPlaylist, startNumber);\n\n                // Currenly b-frames in libx265 breaks the FMP4-HLS playback on iOS, disable it for now.\n                if (string.Equals(codec, \"libx265\", StringComparison.OrdinalIgnoreCase))\n                {\n                    args += \" -bf 0\";\n                }\n\n                // args += \" -mixed-refs 0 -refs 3 -x264opts b_pyramid=0:weightb=0:weightp=0\";\n\n                // video processing filters.\n                var videoProcessParam = _encodingHelper.GetVideoProcessingFilterParam(state, _encodingOptions, codec);\n\n                var negativeMapArgs = _encodingHelper.GetNegativeMapArgsByFilters(state, videoProcessParam);\n\n                args = negativeMapArgs + args + videoProcessParam;\n\n                // -start_at_zero is necessary to use with -ss when seeking,\n                // otherwise the target position cannot be determined.\n                if (state.SubtitleStream != null)\n                {\n                    // Disable start_at_zero for external graphical subs\n                    if (!(state.SubtitleStream.IsExternal && !state.SubtitleStream.IsTextSubtitleStream))\n                    {\n                        args += \" -start_at_zero\";\n                    }\n                }\n            }\n\n            // TODO why was this not enabled for VOD?\n            if (isEventPlaylist)\n            {\n                args += \" -flags -global_header\";\n            }\n\n            if (!string.IsNullOrEmpty(state.OutputVideoSync))\n            {\n                args += \" -vsync \" + state.OutputVideoSync;\n            }\n\n            args += _encodingHelper.GetOutputFFlags(state);\n\n            return args;\n        }\n\n        private string GetSegmentPath(StreamState state, string playlist, int index)\n        {\n            var folder = Path.GetDirectoryName(playlist) ?? throw new ArgumentException($\"Provided path ({playlist}) is not valid.\", nameof(playlist));\n            var filename = Path.GetFileNameWithoutExtension(playlist);\n\n            return Path.Combine(folder, filename + index.ToString(CultureInfo.InvariantCulture) + EncodingHelper.GetSegmentFileExtension(state.Request.SegmentContainer));\n        }\n\n        private async Task<ActionResult> GetSegmentResult(\n            StreamState state,\n            string playlistPath,\n            string segmentPath,\n            string segmentExtension,\n            int segmentIndex,\n            TranscodingJobDto? transcodingJob,\n            CancellationToken cancellationToken)\n        {\n            var segmentExists = System.IO.File.Exists(segmentPath);\n            if (segmentExists)\n            {\n                if (transcodingJob != null && transcodingJob.HasExited)\n                {\n                    // Transcoding job is over, so assume all existing files are ready\n                    _logger.LogDebug(\"serving up {0} as transcode is over\", segmentPath);\n                    return GetSegmentResult(state, segmentPath, transcodingJob);\n                }\n\n                var currentTranscodingIndex = GetCurrentTranscodingIndex(playlistPath, segmentExtension);\n\n                // If requested segment is less than transcoding position, we can't transcode backwards, so assume it's ready\n                if (segmentIndex < currentTranscodingIndex)\n                {\n                    _logger.LogDebug(\"serving up {0} as transcode index {1} is past requested point {2}\", segmentPath, currentTranscodingIndex, segmentIndex);\n                    return GetSegmentResult(state, segmentPath, transcodingJob);\n                }\n            }\n\n            var nextSegmentPath = GetSegmentPath(state, playlistPath, segmentIndex + 1);\n            if (transcodingJob != null)\n            {\n                while (!cancellationToken.IsCancellationRequested && !transcodingJob.HasExited)\n                {\n                    // To be considered ready, the segment file has to exist AND\n                    // either the transcoding job should be done or next segment should also exist\n                    if (segmentExists)\n                    {\n                        if (transcodingJob.HasExited || System.IO.File.Exists(nextSegmentPath))\n                        {\n                            _logger.LogDebug(\"Serving up {SegmentPath} as it deemed ready\", segmentPath);\n                            return GetSegmentResult(state, segmentPath, transcodingJob);\n                        }\n                    }\n                    else\n                    {\n                        segmentExists = System.IO.File.Exists(segmentPath);\n                        if (segmentExists)\n                        {\n                            continue; // avoid unnecessary waiting if segment just became available\n                        }\n                    }\n\n                    await Task.Delay(100, cancellationToken).ConfigureAwait(false);\n                }\n\n                if (!System.IO.File.Exists(segmentPath))\n                {\n                    _logger.LogWarning(\"cannot serve {0} as transcoding quit before we got there\", segmentPath);\n                }\n                else\n                {\n                    _logger.LogDebug(\"serving {0} as it's on disk and transcoding stopped\", segmentPath);\n                }\n\n                cancellationToken.ThrowIfCancellationRequested();\n            }\n            else\n            {\n                _logger.LogWarning(\"cannot serve {0} as it doesn't exist and no transcode is running\", segmentPath);\n            }\n\n            return GetSegmentResult(state, segmentPath, transcodingJob);\n        }\n\n        private ActionResult GetSegmentResult(StreamState state, string segmentPath, TranscodingJobDto? transcodingJob)\n        {\n            var segmentEndingPositionTicks = state.Request.CurrentRuntimeTicks + state.Request.ActualSegmentLengthTicks;\n\n            Response.OnCompleted(() =>\n            {\n                _logger.LogDebug(\"Finished serving {SegmentPath}\", segmentPath);\n                if (transcodingJob != null)\n                {\n                    transcodingJob.DownloadPositionTicks = Math.Max(transcodingJob.DownloadPositionTicks ?? segmentEndingPositionTicks, segmentEndingPositionTicks);\n                    _transcodingJobHelper.OnTranscodeEndRequest(transcodingJob);\n                }\n\n                return Task.CompletedTask;\n            });\n\n            return FileStreamResponseHelpers.GetStaticFileResult(segmentPath, MimeTypes.GetMimeType(segmentPath));\n        }\n\n        private int? GetCurrentTranscodingIndex(string playlist, string segmentExtension)\n        {\n            var job = _transcodingJobHelper.GetTranscodingJob(playlist, TranscodingJobType);\n\n            if (job == null || job.HasExited)\n            {\n                return null;\n            }\n\n            var file = GetLastTranscodingFile(playlist, segmentExtension, _fileSystem);\n\n            if (file == null)\n            {\n                return null;\n            }\n\n            var playlistFilename = Path.GetFileNameWithoutExtension(playlist);\n\n            var indexString = Path.GetFileNameWithoutExtension(file.Name).Substring(playlistFilename.Length);\n\n            return int.Parse(indexString, NumberStyles.Integer, CultureInfo.InvariantCulture);\n        }\n\n        private static FileSystemMetadata? GetLastTranscodingFile(string playlist, string segmentExtension, IFileSystem fileSystem)\n        {\n            var folder = Path.GetDirectoryName(playlist) ?? throw new ArgumentException(\"Path can't be a root directory.\", nameof(playlist));\n\n            var filePrefix = Path.GetFileNameWithoutExtension(playlist);\n\n            try\n            {\n                return fileSystem.GetFiles(folder, new[] { segmentExtension }, true, false)\n                    .Where(i => Path.GetFileNameWithoutExtension(i.Name).StartsWith(filePrefix, StringComparison.OrdinalIgnoreCase))\n                    .OrderByDescending(fileSystem.GetLastWriteTimeUtc)\n                    .FirstOrDefault();\n            }\n            catch (IOException)\n            {\n                return null;\n            }\n        }\n\n        private void DeleteLastFile(string playlistPath, string segmentExtension, int retryCount)\n        {\n            var file = GetLastTranscodingFile(playlistPath, segmentExtension, _fileSystem);\n\n            if (file != null)\n            {\n                DeleteFile(file.FullName, retryCount);\n            }\n        }\n\n        private void DeleteFile(string path, int retryCount)\n        {\n            if (retryCount >= 5)\n            {\n                return;\n            }\n\n            _logger.LogDebug(\"Deleting partial HLS file {Path}\", path);\n\n            try\n            {\n                _fileSystem.DeleteFile(path);\n            }\n            catch (IOException ex)\n            {\n                _logger.LogError(ex, \"Error deleting partial stream file(s) {Path}\", path);\n\n                var task = Task.Delay(100);\n                task.Wait();\n                DeleteFile(path, retryCount + 1);\n            }\n            catch (Exception ex)\n            {\n                _logger.LogError(ex, \"Error deleting partial stream file(s) {Path}\", path);\n            }\n        }\n    }\n}\n", "using System;\nusing System.Collections.Generic;\nusing System.ComponentModel.DataAnnotations;\nusing System.Globalization;\nusing System.Linq;\nusing System.Threading.Tasks;\nusing Jellyfin.Api.Attributes;\nusing Jellyfin.Api.Constants;\nusing Jellyfin.Api.Helpers;\nusing Jellyfin.Api.ModelBinders;\nusing Jellyfin.Api.Models.StreamingDtos;\nusing MediaBrowser.Common.Extensions;\nusing MediaBrowser.Controller.Devices;\nusing MediaBrowser.Controller.Library;\nusing MediaBrowser.Controller.MediaEncoding;\nusing MediaBrowser.Controller.Net;\nusing MediaBrowser.Model.Dlna;\nusing MediaBrowser.Model.MediaInfo;\nusing MediaBrowser.Model.Session;\nusing Microsoft.AspNetCore.Authorization;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\nusing Microsoft.Extensions.Logging;\n\nnamespace Jellyfin.Api.Controllers\n{\n    /// <summary>\n    /// The universal audio controller.\n    /// </summary>\n    [Route(\"\")]\n    public class UniversalAudioController : BaseJellyfinApiController\n    {\n        private readonly IAuthorizationContext _authorizationContext;\n        private readonly IDeviceManager _deviceManager;\n        private readonly ILibraryManager _libraryManager;\n        private readonly ILogger<UniversalAudioController> _logger;\n        private readonly MediaInfoHelper _mediaInfoHelper;\n        private readonly AudioHelper _audioHelper;\n        private readonly DynamicHlsHelper _dynamicHlsHelper;\n\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"UniversalAudioController\"/> class.\n        /// </summary>\n        /// <param name=\"authorizationContext\">Instance of the <see cref=\"IAuthorizationContext\"/> interface.</param>\n        /// <param name=\"deviceManager\">Instance of the <see cref=\"IDeviceManager\"/> interface.</param>\n        /// <param name=\"libraryManager\">Instance of the <see cref=\"ILibraryManager\"/> interface.</param>\n        /// <param name=\"logger\">Instance of the <see cref=\"ILogger{UniversalAudioController}\"/> interface.</param>\n        /// <param name=\"mediaInfoHelper\">Instance of <see cref=\"MediaInfoHelper\"/>.</param>\n        /// <param name=\"audioHelper\">Instance of <see cref=\"AudioHelper\"/>.</param>\n        /// <param name=\"dynamicHlsHelper\">Instance of <see cref=\"DynamicHlsHelper\"/>.</param>\n        public UniversalAudioController(\n            IAuthorizationContext authorizationContext,\n            IDeviceManager deviceManager,\n            ILibraryManager libraryManager,\n            ILogger<UniversalAudioController> logger,\n            MediaInfoHelper mediaInfoHelper,\n            AudioHelper audioHelper,\n            DynamicHlsHelper dynamicHlsHelper)\n        {\n            _authorizationContext = authorizationContext;\n            _deviceManager = deviceManager;\n            _libraryManager = libraryManager;\n            _logger = logger;\n            _mediaInfoHelper = mediaInfoHelper;\n            _audioHelper = audioHelper;\n            _dynamicHlsHelper = dynamicHlsHelper;\n        }\n\n        /// <summary>\n        /// Gets an audio stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">Optional. The audio container.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"userId\">Optional. The user id.</param>\n        /// <param name=\"audioCodec\">Optional. The audio codec to transcode to.</param>\n        /// <param name=\"maxAudioChannels\">Optional. The maximum number of audio channels.</param>\n        /// <param name=\"transcodingAudioChannels\">Optional. The number of how many audio channels to transcode to.</param>\n        /// <param name=\"maxStreamingBitrate\">Optional. The maximum streaming bitrate.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"transcodingContainer\">Optional. The container to transcode to.</param>\n        /// <param name=\"transcodingProtocol\">Optional. The transcoding protocol.</param>\n        /// <param name=\"maxAudioSampleRate\">Optional. The maximum audio sample rate.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"enableRemoteMedia\">Optional. Whether to enable remote media.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"enableRedirection\">Whether to enable redirection. Defaults to true.</param>\n        /// <response code=\"200\">Audio stream returned.</response>\n        /// <response code=\"302\">Redirected to remote audio stream.</response>\n        /// <returns>A <see cref=\"Task\"/> containing the audio file.</returns>\n        [HttpGet(\"Audio/{itemId}/universal\")]\n        [HttpHead(\"Audio/{itemId}/universal\", Name = \"HeadUniversalAudioStream\")]\n        [Authorize(Policy = Policies.DefaultAuthorization)]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesResponseType(StatusCodes.Status302Found)]\n        [ProducesAudioFile]\n        public async Task<ActionResult> GetUniversalAudioStream(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery, ModelBinder(typeof(CommaDelimitedArrayModelBinder))] string[] container,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery] Guid? userId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] int? transcodingAudioChannels,\n            [FromQuery] int? maxStreamingBitrate,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? transcodingContainer,\n            [FromQuery] string? transcodingProtocol,\n            [FromQuery] int? maxAudioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] bool? enableRemoteMedia,\n            [FromQuery] bool breakOnNonKeyFrames = false,\n            [FromQuery] bool enableRedirection = true)\n        {\n            var deviceProfile = GetDeviceProfile(container, transcodingContainer, audioCodec, transcodingProtocol, breakOnNonKeyFrames, transcodingAudioChannels, maxAudioSampleRate, maxAudioBitDepth, maxAudioChannels);\n            var authorizationInfo = await _authorizationContext.GetAuthorizationInfo(Request).ConfigureAwait(false);\n            authorizationInfo.DeviceId = deviceId;\n\n            if (!userId.HasValue || userId.Value.Equals(Guid.Empty))\n            {\n                userId = authorizationInfo.UserId;\n            }\n\n            var authInfo = await _authorizationContext.GetAuthorizationInfo(Request).ConfigureAwait(false);\n\n            _logger.LogInformation(\"GetPostedPlaybackInfo profile: {@Profile}\", deviceProfile);\n\n            if (deviceProfile == null)\n            {\n                var clientCapabilities = _deviceManager.GetCapabilities(authInfo.DeviceId);\n                if (clientCapabilities != null)\n                {\n                    deviceProfile = clientCapabilities.DeviceProfile;\n                }\n            }\n\n            var info = await _mediaInfoHelper.GetPlaybackInfo(\n                    itemId,\n                    userId,\n                    mediaSourceId)\n                .ConfigureAwait(false);\n\n            if (deviceProfile != null)\n            {\n                // set device specific data\n                var item = _libraryManager.GetItemById(itemId);\n\n                foreach (var sourceInfo in info.MediaSources)\n                {\n                    _mediaInfoHelper.SetDeviceSpecificData(\n                        item,\n                        sourceInfo,\n                        deviceProfile,\n                        authInfo,\n                        maxStreamingBitrate ?? deviceProfile.MaxStreamingBitrate,\n                        startTimeTicks ?? 0,\n                        mediaSourceId ?? string.Empty,\n                        null,\n                        null,\n                        maxAudioChannels,\n                        info.PlaySessionId!,\n                        userId ?? Guid.Empty,\n                        true,\n                        true,\n                        true,\n                        true,\n                        true,\n                        Request.HttpContext.GetNormalizedRemoteIp());\n                }\n\n                _mediaInfoHelper.SortMediaSources(info, maxStreamingBitrate);\n            }\n\n            if (info.MediaSources != null)\n            {\n                foreach (var source in info.MediaSources)\n                {\n                    _mediaInfoHelper.NormalizeMediaSourceContainer(source, deviceProfile!, DlnaProfileType.Video);\n                }\n            }\n\n            var mediaSource = info.MediaSources![0];\n            if (mediaSource.SupportsDirectPlay && mediaSource.Protocol == MediaProtocol.Http)\n            {\n                if (enableRedirection)\n                {\n                    if (mediaSource.IsRemote && enableRemoteMedia.HasValue && enableRemoteMedia.Value)\n                    {\n                        return Redirect(mediaSource.Path);\n                    }\n                }\n            }\n\n            var isStatic = mediaSource.SupportsDirectStream;\n            if (!isStatic && string.Equals(mediaSource.TranscodingSubProtocol, \"hls\", StringComparison.OrdinalIgnoreCase))\n            {\n                // hls segment container can only be mpegts or fmp4 per ffmpeg documentation\n                // ffmpeg option -> file extension\n                //        mpegts -> ts\n                //          fmp4 -> mp4\n                // TODO: remove this when we switch back to the segment muxer\n                var supportedHlsContainers = new[] { \"ts\", \"mp4\" };\n\n                var dynamicHlsRequestDto = new HlsAudioRequestDto\n                {\n                    Id = itemId,\n                    Container = \".m3u8\",\n                    Static = isStatic,\n                    PlaySessionId = info.PlaySessionId,\n                    // fallback to mpegts if device reports some weird value unsupported by hls\n                    SegmentContainer = Array.Exists(supportedHlsContainers, element => element == transcodingContainer) ? transcodingContainer : \"ts\",\n                    MediaSourceId = mediaSourceId,\n                    DeviceId = deviceId,\n                    AudioCodec = audioCodec,\n                    EnableAutoStreamCopy = true,\n                    AllowAudioStreamCopy = true,\n                    AllowVideoStreamCopy = true,\n                    BreakOnNonKeyFrames = breakOnNonKeyFrames,\n                    AudioSampleRate = maxAudioSampleRate,\n                    MaxAudioChannels = maxAudioChannels,\n                    MaxAudioBitDepth = maxAudioBitDepth,\n                    AudioBitRate = audioBitRate ?? maxStreamingBitrate,\n                    StartTimeTicks = startTimeTicks,\n                    SubtitleMethod = SubtitleDeliveryMethod.Hls,\n                    RequireAvc = false,\n                    DeInterlace = false,\n                    RequireNonAnamorphic = false,\n                    EnableMpegtsM2TsMode = false,\n                    TranscodeReasons = mediaSource.TranscodeReasons == 0 ? null : mediaSource.TranscodeReasons.ToString(),\n                    Context = EncodingContext.Static,\n                    StreamOptions = new Dictionary<string, string>(),\n                    EnableAdaptiveBitrateStreaming = true\n                };\n\n                return await _dynamicHlsHelper.GetMasterHlsPlaylist(TranscodingJobType.Hls, dynamicHlsRequestDto, true)\n                    .ConfigureAwait(false);\n            }\n\n            var audioStreamingDto = new StreamingRequestDto\n            {\n                Id = itemId,\n                Container = isStatic ? null : (\".\" + mediaSource.TranscodingContainer),\n                Static = isStatic,\n                PlaySessionId = info.PlaySessionId,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = true,\n                AllowAudioStreamCopy = true,\n                AllowVideoStreamCopy = true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames,\n                AudioSampleRate = maxAudioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = isStatic ? (int?)null : (audioBitRate ?? maxStreamingBitrate),\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = maxAudioChannels,\n                CopyTimestamps = true,\n                StartTimeTicks = startTimeTicks,\n                SubtitleMethod = SubtitleDeliveryMethod.Embed,\n                TranscodeReasons = mediaSource.TranscodeReasons == 0 ? null : mediaSource.TranscodeReasons.ToString(),\n                Context = EncodingContext.Static\n            };\n\n            return await _audioHelper.GetAudioStream(TranscodingJobType.Progressive, audioStreamingDto).ConfigureAwait(false);\n        }\n\n        private DeviceProfile GetDeviceProfile(\n            string[] containers,\n            string? transcodingContainer,\n            string? audioCodec,\n            string? transcodingProtocol,\n            bool? breakOnNonKeyFrames,\n            int? transcodingAudioChannels,\n            int? maxAudioSampleRate,\n            int? maxAudioBitDepth,\n            int? maxAudioChannels)\n        {\n            var deviceProfile = new DeviceProfile();\n\n            int len = containers.Length;\n            var directPlayProfiles = new DirectPlayProfile[len];\n            for (int i = 0; i < len; i++)\n            {\n                var parts = containers[i].Split('|', StringSplitOptions.RemoveEmptyEntries);\n\n                var audioCodecs = parts.Length == 1 ? null : string.Join(',', parts.Skip(1));\n\n                directPlayProfiles[i] = new DirectPlayProfile\n                {\n                    Type = DlnaProfileType.Audio,\n                    Container = parts[0],\n                    AudioCodec = audioCodecs\n                };\n            }\n\n            deviceProfile.DirectPlayProfiles = directPlayProfiles;\n\n            deviceProfile.TranscodingProfiles = new[]\n            {\n                new TranscodingProfile\n                {\n                    Type = DlnaProfileType.Audio,\n                    Context = EncodingContext.Streaming,\n                    Container = transcodingContainer ?? \"mp3\",\n                    AudioCodec = audioCodec ?? \"mp3\",\n                    Protocol = transcodingProtocol ?? \"http\",\n                    BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                    MaxAudioChannels = transcodingAudioChannels?.ToString(CultureInfo.InvariantCulture)\n                }\n            };\n\n            var codecProfiles = new List<CodecProfile>();\n            var conditions = new List<ProfileCondition>();\n\n            if (maxAudioSampleRate.HasValue)\n            {\n                // codec profile\n                conditions.Add(\n                    new ProfileCondition\n                    {\n                        Condition = ProfileConditionType.LessThanEqual,\n                        IsRequired = false,\n                        Property = ProfileConditionValue.AudioSampleRate,\n                        Value = maxAudioSampleRate.Value.ToString(CultureInfo.InvariantCulture)\n                    });\n            }\n\n            if (maxAudioBitDepth.HasValue)\n            {\n                // codec profile\n                conditions.Add(\n                    new ProfileCondition\n                    {\n                        Condition = ProfileConditionType.LessThanEqual,\n                        IsRequired = false,\n                        Property = ProfileConditionValue.AudioBitDepth,\n                        Value = maxAudioBitDepth.Value.ToString(CultureInfo.InvariantCulture)\n                    });\n            }\n\n            if (maxAudioChannels.HasValue)\n            {\n                // codec profile\n                conditions.Add(\n                    new ProfileCondition\n                    {\n                        Condition = ProfileConditionType.LessThanEqual,\n                        IsRequired = false,\n                        Property = ProfileConditionValue.AudioChannels,\n                        Value = maxAudioChannels.Value.ToString(CultureInfo.InvariantCulture)\n                    });\n            }\n\n            if (conditions.Count > 0)\n            {\n                // codec profile\n                codecProfiles.Add(\n                    new CodecProfile\n                    {\n                        Type = CodecType.Audio,\n                        Container = string.Join(',', containers),\n                        Conditions = conditions.ToArray()\n                    });\n            }\n\n            deviceProfile.CodecProfiles = codecProfiles.ToArray();\n\n            return deviceProfile;\n        }\n    }\n}\n", "using System;\nusing System.Collections.Generic;\nusing System.ComponentModel.DataAnnotations;\nusing System.Globalization;\nusing System.Linq;\nusing System.Net.Http;\nusing System.Threading;\nusing System.Threading.Tasks;\nusing Jellyfin.Api.Attributes;\nusing Jellyfin.Api.Constants;\nusing Jellyfin.Api.Extensions;\nusing Jellyfin.Api.Helpers;\nusing Jellyfin.Api.ModelBinders;\nusing Jellyfin.Api.Models.StreamingDtos;\nusing MediaBrowser.Common.Configuration;\nusing MediaBrowser.Common.Net;\nusing MediaBrowser.Controller.Configuration;\nusing MediaBrowser.Controller.Devices;\nusing MediaBrowser.Controller.Dlna;\nusing MediaBrowser.Controller.Dto;\nusing MediaBrowser.Controller.Entities;\nusing MediaBrowser.Controller.Library;\nusing MediaBrowser.Controller.MediaEncoding;\nusing MediaBrowser.Controller.Net;\nusing MediaBrowser.Model.Dlna;\nusing MediaBrowser.Model.Dto;\nusing MediaBrowser.Model.Entities;\nusing MediaBrowser.Model.MediaInfo;\nusing MediaBrowser.Model.Net;\nusing MediaBrowser.Model.Querying;\nusing Microsoft.AspNetCore.Authorization;\nusing Microsoft.AspNetCore.Http;\nusing Microsoft.AspNetCore.Mvc;\n\nnamespace Jellyfin.Api.Controllers\n{\n    /// <summary>\n    /// The videos controller.\n    /// </summary>\n    public class VideosController : BaseJellyfinApiController\n    {\n        private readonly ILibraryManager _libraryManager;\n        private readonly IUserManager _userManager;\n        private readonly IDtoService _dtoService;\n        private readonly IDlnaManager _dlnaManager;\n        private readonly IAuthorizationContext _authContext;\n        private readonly IMediaSourceManager _mediaSourceManager;\n        private readonly IServerConfigurationManager _serverConfigurationManager;\n        private readonly IMediaEncoder _mediaEncoder;\n        private readonly IDeviceManager _deviceManager;\n        private readonly TranscodingJobHelper _transcodingJobHelper;\n        private readonly IHttpClientFactory _httpClientFactory;\n        private readonly EncodingHelper _encodingHelper;\n\n        private readonly TranscodingJobType _transcodingJobType = TranscodingJobType.Progressive;\n\n        /// <summary>\n        /// Initializes a new instance of the <see cref=\"VideosController\"/> class.\n        /// </summary>\n        /// <param name=\"libraryManager\">Instance of the <see cref=\"ILibraryManager\"/> interface.</param>\n        /// <param name=\"userManager\">Instance of the <see cref=\"IUserManager\"/> interface.</param>\n        /// <param name=\"dtoService\">Instance of the <see cref=\"IDtoService\"/> interface.</param>\n        /// <param name=\"dlnaManager\">Instance of the <see cref=\"IDlnaManager\"/> interface.</param>\n        /// <param name=\"authContext\">Instance of the <see cref=\"IAuthorizationContext\"/> interface.</param>\n        /// <param name=\"mediaSourceManager\">Instance of the <see cref=\"IMediaSourceManager\"/> interface.</param>\n        /// <param name=\"serverConfigurationManager\">Instance of the <see cref=\"IServerConfigurationManager\"/> interface.</param>\n        /// <param name=\"mediaEncoder\">Instance of the <see cref=\"IMediaEncoder\"/> interface.</param>\n        /// <param name=\"deviceManager\">Instance of the <see cref=\"IDeviceManager\"/> interface.</param>\n        /// <param name=\"transcodingJobHelper\">Instance of the <see cref=\"TranscodingJobHelper\"/> class.</param>\n        /// <param name=\"httpClientFactory\">Instance of the <see cref=\"IHttpClientFactory\"/> interface.</param>\n        /// <param name=\"encodingHelper\">Instance of <see cref=\"EncodingHelper\"/>.</param>\n        public VideosController(\n            ILibraryManager libraryManager,\n            IUserManager userManager,\n            IDtoService dtoService,\n            IDlnaManager dlnaManager,\n            IAuthorizationContext authContext,\n            IMediaSourceManager mediaSourceManager,\n            IServerConfigurationManager serverConfigurationManager,\n            IMediaEncoder mediaEncoder,\n            IDeviceManager deviceManager,\n            TranscodingJobHelper transcodingJobHelper,\n            IHttpClientFactory httpClientFactory,\n            EncodingHelper encodingHelper)\n        {\n            _libraryManager = libraryManager;\n            _userManager = userManager;\n            _dtoService = dtoService;\n            _dlnaManager = dlnaManager;\n            _authContext = authContext;\n            _mediaSourceManager = mediaSourceManager;\n            _serverConfigurationManager = serverConfigurationManager;\n            _mediaEncoder = mediaEncoder;\n            _deviceManager = deviceManager;\n            _transcodingJobHelper = transcodingJobHelper;\n            _httpClientFactory = httpClientFactory;\n            _encodingHelper = encodingHelper;\n        }\n\n        /// <summary>\n        /// Gets additional parts for a video.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"userId\">Optional. Filter by user id, and attach user data.</param>\n        /// <response code=\"200\">Additional parts returned.</response>\n        /// <returns>A <see cref=\"QueryResult{BaseItemDto}\"/> with the parts.</returns>\n        [HttpGet(\"{itemId}/AdditionalParts\")]\n        [Authorize(Policy = Policies.DefaultAuthorization)]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        public ActionResult<QueryResult<BaseItemDto>> GetAdditionalPart([FromRoute, Required] Guid itemId, [FromQuery] Guid? userId)\n        {\n            var user = userId is null || userId.Value.Equals(default)\n                ? null\n                : _userManager.GetUserById(userId.Value);\n\n            var item = itemId.Equals(default)\n                ? (userId is null || userId.Value.Equals(default)\n                    ? _libraryManager.RootFolder\n                    : _libraryManager.GetUserRootFolder())\n                : _libraryManager.GetItemById(itemId);\n\n            var dtoOptions = new DtoOptions();\n            dtoOptions = dtoOptions.AddClientFields(Request);\n\n            BaseItemDto[] items;\n            if (item is Video video)\n            {\n                items = video.GetAdditionalParts()\n                    .Select(i => _dtoService.GetBaseItemDto(i, dtoOptions, user, video))\n                    .ToArray();\n            }\n            else\n            {\n                items = Array.Empty<BaseItemDto>();\n            }\n\n            var result = new QueryResult<BaseItemDto>(items);\n            return result;\n        }\n\n        /// <summary>\n        /// Removes alternate video sources.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <response code=\"204\">Alternate sources deleted.</response>\n        /// <response code=\"404\">Video not found.</response>\n        /// <returns>A <see cref=\"NoContentResult\"/> indicating success, or a <see cref=\"NotFoundResult\"/> if the video doesn't exist.</returns>\n        [HttpDelete(\"{itemId}/AlternateSources\")]\n        [Authorize(Policy = Policies.RequiresElevation)]\n        [ProducesResponseType(StatusCodes.Status204NoContent)]\n        [ProducesResponseType(StatusCodes.Status404NotFound)]\n        public async Task<ActionResult> DeleteAlternateSources([FromRoute, Required] Guid itemId)\n        {\n            var video = (Video)_libraryManager.GetItemById(itemId);\n\n            if (video == null)\n            {\n                return NotFound(\"The video either does not exist or the id does not belong to a video.\");\n            }\n\n            if (video.LinkedAlternateVersions.Length == 0)\n            {\n                video = (Video)_libraryManager.GetItemById(video.PrimaryVersionId);\n            }\n\n            foreach (var link in video.GetLinkedAlternateVersions())\n            {\n                link.SetPrimaryVersionId(null);\n                link.LinkedAlternateVersions = Array.Empty<LinkedChild>();\n\n                await link.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n            }\n\n            video.LinkedAlternateVersions = Array.Empty<LinkedChild>();\n            video.SetPrimaryVersionId(null);\n            await video.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n\n            return NoContent();\n        }\n\n        /// <summary>\n        /// Merges videos into a single record.\n        /// </summary>\n        /// <param name=\"ids\">Item id list. This allows multiple, comma delimited.</param>\n        /// <response code=\"204\">Videos merged.</response>\n        /// <response code=\"400\">Supply at least 2 video ids.</response>\n        /// <returns>A <see cref=\"NoContentResult\"/> indicating success, or a <see cref=\"BadRequestResult\"/> if less than two ids were supplied.</returns>\n        [HttpPost(\"MergeVersions\")]\n        [Authorize(Policy = Policies.RequiresElevation)]\n        [ProducesResponseType(StatusCodes.Status204NoContent)]\n        [ProducesResponseType(StatusCodes.Status400BadRequest)]\n        public async Task<ActionResult> MergeVersions([FromQuery, Required, ModelBinder(typeof(CommaDelimitedArrayModelBinder))] Guid[] ids)\n        {\n            var items = ids\n                .Select(i => _libraryManager.GetItemById(i))\n                .OfType<Video>()\n                .OrderBy(i => i.Id)\n                .ToList();\n\n            if (items.Count < 2)\n            {\n                return BadRequest(\"Please supply at least two videos to merge.\");\n            }\n\n            var primaryVersion = items.FirstOrDefault(i => i.MediaSourceCount > 1 && string.IsNullOrEmpty(i.PrimaryVersionId));\n            if (primaryVersion == null)\n            {\n                primaryVersion = items\n                    .OrderBy(i =>\n                    {\n                        if (i.Video3DFormat.HasValue || i.VideoType != VideoType.VideoFile)\n                        {\n                            return 1;\n                        }\n\n                        return 0;\n                    })\n                    .ThenByDescending(i => i.GetDefaultVideoStream()?.Width ?? 0)\n                    .First();\n            }\n\n            var alternateVersionsOfPrimary = primaryVersion.LinkedAlternateVersions.ToList();\n\n            foreach (var item in items.Where(i => !i.Id.Equals(primaryVersion.Id)))\n            {\n                item.SetPrimaryVersionId(primaryVersion.Id.ToString(\"N\", CultureInfo.InvariantCulture));\n\n                await item.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n\n                if (!alternateVersionsOfPrimary.Any(i => string.Equals(i.Path, item.Path, StringComparison.OrdinalIgnoreCase)))\n                {\n                    alternateVersionsOfPrimary.Add(new LinkedChild\n                    {\n                        Path = item.Path,\n                        ItemId = item.Id\n                    });\n                }\n\n                foreach (var linkedItem in item.LinkedAlternateVersions)\n                {\n                    if (!alternateVersionsOfPrimary.Any(i => string.Equals(i.Path, linkedItem.Path, StringComparison.OrdinalIgnoreCase)))\n                    {\n                        alternateVersionsOfPrimary.Add(linkedItem);\n                    }\n                }\n\n                if (item.LinkedAlternateVersions.Length > 0)\n                {\n                    item.LinkedAlternateVersions = Array.Empty<LinkedChild>();\n                    await item.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n                }\n            }\n\n            primaryVersion.LinkedAlternateVersions = alternateVersionsOfPrimary.ToArray();\n            await primaryVersion.UpdateToRepositoryAsync(ItemUpdateType.MetadataEdit, CancellationToken.None).ConfigureAwait(false);\n            return NoContent();\n        }\n\n        /// <summary>\n        /// Gets a video stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The video container. Possible values are: ts, webm, asf, wmv, ogv, mp4, m4v, mkv, mpeg, mpg, avi, 3gp, wmv, wtv, m2ts, mov, iso, flv. </param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"{itemId}/stream\")]\n        [HttpHead(\"{itemId}/stream\", Name = \"HeadVideoStream\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesVideoFile]\n        public async Task<ActionResult> GetVideoStream(\n            [FromRoute, Required] Guid itemId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            var isHeadRequest = Request.Method == System.Net.WebRequestMethods.Http.Head;\n            // CTS lifecycle is managed internally.\n            var cancellationTokenSource = new CancellationTokenSource();\n            var streamingRequest = new VideoRequestDto\n            {\n                Id = itemId,\n                Container = container,\n                Static = @static ?? false,\n                Params = @params,\n                Tag = tag,\n                DeviceProfileId = deviceProfileId,\n                PlaySessionId = playSessionId,\n                SegmentContainer = segmentContainer,\n                SegmentLength = segmentLength,\n                MinSegments = minSegments,\n                MediaSourceId = mediaSourceId,\n                DeviceId = deviceId,\n                AudioCodec = audioCodec,\n                EnableAutoStreamCopy = enableAutoStreamCopy ?? true,\n                AllowAudioStreamCopy = allowAudioStreamCopy ?? true,\n                AllowVideoStreamCopy = allowVideoStreamCopy ?? true,\n                BreakOnNonKeyFrames = breakOnNonKeyFrames ?? false,\n                AudioSampleRate = audioSampleRate,\n                MaxAudioChannels = maxAudioChannels,\n                AudioBitRate = audioBitRate,\n                MaxAudioBitDepth = maxAudioBitDepth,\n                AudioChannels = audioChannels,\n                Profile = profile,\n                Level = level,\n                Framerate = framerate,\n                MaxFramerate = maxFramerate,\n                CopyTimestamps = copyTimestamps ?? false,\n                StartTimeTicks = startTimeTicks,\n                Width = width,\n                Height = height,\n                MaxWidth = maxWidth,\n                MaxHeight = maxHeight,\n                VideoBitRate = videoBitRate,\n                SubtitleStreamIndex = subtitleStreamIndex,\n                SubtitleMethod = subtitleMethod ?? SubtitleDeliveryMethod.Encode,\n                MaxRefFrames = maxRefFrames,\n                MaxVideoBitDepth = maxVideoBitDepth,\n                RequireAvc = requireAvc ?? false,\n                DeInterlace = deInterlace ?? false,\n                RequireNonAnamorphic = requireNonAnamorphic ?? false,\n                TranscodingMaxAudioChannels = transcodingMaxAudioChannels,\n                CpuCoreLimit = cpuCoreLimit,\n                LiveStreamId = liveStreamId,\n                EnableMpegtsM2TsMode = enableMpegtsM2TsMode ?? false,\n                VideoCodec = videoCodec,\n                SubtitleCodec = subtitleCodec,\n                TranscodeReasons = transcodeReasons,\n                AudioStreamIndex = audioStreamIndex,\n                VideoStreamIndex = videoStreamIndex,\n                Context = context ?? EncodingContext.Streaming,\n                StreamOptions = streamOptions\n            };\n\n            var state = await StreamingHelpers.GetStreamingState(\n                    streamingRequest,\n                    Request,\n                    _authContext,\n                    _mediaSourceManager,\n                    _userManager,\n                    _libraryManager,\n                    _serverConfigurationManager,\n                    _mediaEncoder,\n                    _encodingHelper,\n                    _dlnaManager,\n                    _deviceManager,\n                    _transcodingJobHelper,\n                    _transcodingJobType,\n                    cancellationTokenSource.Token)\n                .ConfigureAwait(false);\n\n            if (@static.HasValue && @static.Value && state.DirectStreamProvider != null)\n            {\n                StreamingHelpers.AddDlnaHeaders(state, Response.Headers, true, state.Request.StartTimeTicks, Request, _dlnaManager);\n\n                var liveStreamInfo = _mediaSourceManager.GetLiveStreamInfo(streamingRequest.LiveStreamId);\n                if (liveStreamInfo == null)\n                {\n                    return NotFound();\n                }\n\n                var liveStream = new ProgressiveFileStream(liveStreamInfo.GetStream());\n                // TODO (moved from MediaBrowser.Api): Don't hardcode contentType\n                return File(liveStream, MimeTypes.GetMimeType(\"file.ts\"));\n            }\n\n            // Static remote stream\n            if (@static.HasValue && @static.Value && state.InputProtocol == MediaProtocol.Http)\n            {\n                StreamingHelpers.AddDlnaHeaders(state, Response.Headers, true, state.Request.StartTimeTicks, Request, _dlnaManager);\n\n                var httpClient = _httpClientFactory.CreateClient(NamedClient.Default);\n                return await FileStreamResponseHelpers.GetStaticRemoteStreamResult(state, httpClient, HttpContext).ConfigureAwait(false);\n            }\n\n            if (@static.HasValue && @static.Value && state.InputProtocol != MediaProtocol.File)\n            {\n                return BadRequest($\"Input protocol {state.InputProtocol} cannot be streamed statically\");\n            }\n\n            var outputPath = state.OutputFilePath;\n            var outputPathExists = System.IO.File.Exists(outputPath);\n\n            var transcodingJob = _transcodingJobHelper.GetTranscodingJob(outputPath, TranscodingJobType.Progressive);\n            var isTranscodeCached = outputPathExists && transcodingJob != null;\n\n            StreamingHelpers.AddDlnaHeaders(state, Response.Headers, (@static.HasValue && @static.Value) || isTranscodeCached, state.Request.StartTimeTicks, Request, _dlnaManager);\n\n            // Static stream\n            if (@static.HasValue && @static.Value)\n            {\n                var contentType = state.GetMimeType(\".\" + state.OutputContainer, false) ?? state.GetMimeType(state.MediaPath);\n\n                if (state.MediaSource.IsInfiniteStream)\n                {\n                    var liveStream = new ProgressiveFileStream(state.MediaPath, null, _transcodingJobHelper);\n                    return File(liveStream, contentType);\n                }\n\n                return FileStreamResponseHelpers.GetStaticFileResult(\n                    state.MediaPath,\n                    contentType);\n            }\n\n            // Need to start ffmpeg (because media can't be returned directly)\n            var encodingOptions = _serverConfigurationManager.GetEncodingOptions();\n            var ffmpegCommandLineArguments = _encodingHelper.GetProgressiveVideoFullCommandLine(state, encodingOptions, outputPath, \"superfast\");\n            return await FileStreamResponseHelpers.GetTranscodedFile(\n                state,\n                isHeadRequest,\n                HttpContext,\n                _transcodingJobHelper,\n                ffmpegCommandLineArguments,\n                _transcodingJobType,\n                cancellationTokenSource).ConfigureAwait(false);\n        }\n\n        /// <summary>\n        /// Gets a video stream.\n        /// </summary>\n        /// <param name=\"itemId\">The item id.</param>\n        /// <param name=\"container\">The video container. Possible values are: ts, webm, asf, wmv, ogv, mp4, m4v, mkv, mpeg, mpg, avi, 3gp, wmv, wtv, m2ts, mov, iso, flv. </param>\n        /// <param name=\"static\">Optional. If true, the original file will be streamed statically without any encoding. Use either no url extension or the original file extension. true/false.</param>\n        /// <param name=\"params\">The streaming parameters.</param>\n        /// <param name=\"tag\">The tag.</param>\n        /// <param name=\"deviceProfileId\">Optional. The dlna device profile id to utilize.</param>\n        /// <param name=\"playSessionId\">The play session id.</param>\n        /// <param name=\"segmentContainer\">The segment container.</param>\n        /// <param name=\"segmentLength\">The segment length.</param>\n        /// <param name=\"minSegments\">The minimum number of segments.</param>\n        /// <param name=\"mediaSourceId\">The media version id, if playing an alternate version.</param>\n        /// <param name=\"deviceId\">The device id of the client requesting. Used to stop encoding processes when needed.</param>\n        /// <param name=\"audioCodec\">Optional. Specify a audio codec to encode to, e.g. mp3. If omitted the server will auto-select using the url's extension. Options: aac, mp3, vorbis, wma.</param>\n        /// <param name=\"enableAutoStreamCopy\">Whether or not to allow automatic stream copy if requested values match the original source. Defaults to true.</param>\n        /// <param name=\"allowVideoStreamCopy\">Whether or not to allow copying of the video stream url.</param>\n        /// <param name=\"allowAudioStreamCopy\">Whether or not to allow copying of the audio stream url.</param>\n        /// <param name=\"breakOnNonKeyFrames\">Optional. Whether to break on non key frames.</param>\n        /// <param name=\"audioSampleRate\">Optional. Specify a specific audio sample rate, e.g. 44100.</param>\n        /// <param name=\"maxAudioBitDepth\">Optional. The maximum audio bit depth.</param>\n        /// <param name=\"audioBitRate\">Optional. Specify an audio bitrate to encode to, e.g. 128000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"audioChannels\">Optional. Specify a specific number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"maxAudioChannels\">Optional. Specify a maximum number of audio channels to encode to, e.g. 2.</param>\n        /// <param name=\"profile\">Optional. Specify a specific an encoder profile (varies by encoder), e.g. main, baseline, high.</param>\n        /// <param name=\"level\">Optional. Specify a level for the encoder profile (varies by encoder), e.g. 3, 3.1.</param>\n        /// <param name=\"framerate\">Optional. A specific video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"maxFramerate\">Optional. A specific maximum video framerate to encode to, e.g. 23.976. Generally this should be omitted unless the device has specific requirements.</param>\n        /// <param name=\"copyTimestamps\">Whether or not to copy timestamps when transcoding with an offset. Defaults to false.</param>\n        /// <param name=\"startTimeTicks\">Optional. Specify a starting offset, in ticks. 1 tick = 10000 ms.</param>\n        /// <param name=\"width\">Optional. The fixed horizontal resolution of the encoded video.</param>\n        /// <param name=\"height\">Optional. The fixed vertical resolution of the encoded video.</param>\n        /// <param name=\"maxWidth\">Optional. The maximum horizontal resolution of the encoded video.</param>\n        /// <param name=\"maxHeight\">Optional. The maximum vertical resolution of the encoded video.</param>\n        /// <param name=\"videoBitRate\">Optional. Specify a video bitrate to encode to, e.g. 500000. If omitted this will be left to encoder defaults.</param>\n        /// <param name=\"subtitleStreamIndex\">Optional. The index of the subtitle stream to use. If omitted no subtitles will be used.</param>\n        /// <param name=\"subtitleMethod\">Optional. Specify the subtitle delivery method.</param>\n        /// <param name=\"maxRefFrames\">Optional.</param>\n        /// <param name=\"maxVideoBitDepth\">Optional. The maximum video bit depth.</param>\n        /// <param name=\"requireAvc\">Optional. Whether to require avc.</param>\n        /// <param name=\"deInterlace\">Optional. Whether to deinterlace the video.</param>\n        /// <param name=\"requireNonAnamorphic\">Optional. Whether to require a non anamorphic stream.</param>\n        /// <param name=\"transcodingMaxAudioChannels\">Optional. The maximum number of audio channels to transcode.</param>\n        /// <param name=\"cpuCoreLimit\">Optional. The limit of how many cpu cores to use.</param>\n        /// <param name=\"liveStreamId\">The live stream id.</param>\n        /// <param name=\"enableMpegtsM2TsMode\">Optional. Whether to enable the MpegtsM2Ts mode.</param>\n        /// <param name=\"videoCodec\">Optional. Specify a video codec to encode to, e.g. h264. If omitted the server will auto-select using the url's extension. Options: h265, h264, mpeg4, theora, vp8, vp9, vpx (deprecated), wmv.</param>\n        /// <param name=\"subtitleCodec\">Optional. Specify a subtitle codec to encode to.</param>\n        /// <param name=\"transcodeReasons\">Optional. The transcoding reason.</param>\n        /// <param name=\"audioStreamIndex\">Optional. The index of the audio stream to use. If omitted the first audio stream will be used.</param>\n        /// <param name=\"videoStreamIndex\">Optional. The index of the video stream to use. If omitted the first video stream will be used.</param>\n        /// <param name=\"context\">Optional. The <see cref=\"EncodingContext\"/>.</param>\n        /// <param name=\"streamOptions\">Optional. The streaming options.</param>\n        /// <response code=\"200\">Video stream returned.</response>\n        /// <returns>A <see cref=\"FileResult\"/> containing the audio file.</returns>\n        [HttpGet(\"{itemId}/stream.{container}\")]\n        [HttpHead(\"{itemId}/stream.{container}\", Name = \"HeadVideoStreamByContainer\")]\n        [ProducesResponseType(StatusCodes.Status200OK)]\n        [ProducesVideoFile]\n        public Task<ActionResult> GetVideoStreamByContainer(\n            [FromRoute, Required] Guid itemId,\n            [FromRoute, Required] string container,\n            [FromQuery] bool? @static,\n            [FromQuery] string? @params,\n            [FromQuery] string? tag,\n            [FromQuery] string? deviceProfileId,\n            [FromQuery] string? playSessionId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? segmentContainer,\n            [FromQuery] int? segmentLength,\n            [FromQuery] int? minSegments,\n            [FromQuery] string? mediaSourceId,\n            [FromQuery] string? deviceId,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? audioCodec,\n            [FromQuery] bool? enableAutoStreamCopy,\n            [FromQuery] bool? allowVideoStreamCopy,\n            [FromQuery] bool? allowAudioStreamCopy,\n            [FromQuery] bool? breakOnNonKeyFrames,\n            [FromQuery] int? audioSampleRate,\n            [FromQuery] int? maxAudioBitDepth,\n            [FromQuery] int? audioBitRate,\n            [FromQuery] int? audioChannels,\n            [FromQuery] int? maxAudioChannels,\n            [FromQuery] string? profile,\n            [FromQuery] string? level,\n            [FromQuery] float? framerate,\n            [FromQuery] float? maxFramerate,\n            [FromQuery] bool? copyTimestamps,\n            [FromQuery] long? startTimeTicks,\n            [FromQuery] int? width,\n            [FromQuery] int? height,\n            [FromQuery] int? maxWidth,\n            [FromQuery] int? maxHeight,\n            [FromQuery] int? videoBitRate,\n            [FromQuery] int? subtitleStreamIndex,\n            [FromQuery] SubtitleDeliveryMethod? subtitleMethod,\n            [FromQuery] int? maxRefFrames,\n            [FromQuery] int? maxVideoBitDepth,\n            [FromQuery] bool? requireAvc,\n            [FromQuery] bool? deInterlace,\n            [FromQuery] bool? requireNonAnamorphic,\n            [FromQuery] int? transcodingMaxAudioChannels,\n            [FromQuery] int? cpuCoreLimit,\n            [FromQuery] string? liveStreamId,\n            [FromQuery] bool? enableMpegtsM2TsMode,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? videoCodec,\n            [FromQuery][RegularExpression(EncodingHelper.ValidationRegex)] string? subtitleCodec,\n            [FromQuery] string? transcodeReasons,\n            [FromQuery] int? audioStreamIndex,\n            [FromQuery] int? videoStreamIndex,\n            [FromQuery] EncodingContext? context,\n            [FromQuery] Dictionary<string, string> streamOptions)\n        {\n            return GetVideoStream(\n                itemId,\n                container,\n                @static,\n                @params,\n                tag,\n                deviceProfileId,\n                playSessionId,\n                segmentContainer,\n                segmentLength,\n                minSegments,\n                mediaSourceId,\n                deviceId,\n                audioCodec,\n                enableAutoStreamCopy,\n                allowVideoStreamCopy,\n                allowAudioStreamCopy,\n                breakOnNonKeyFrames,\n                audioSampleRate,\n                maxAudioBitDepth,\n                audioBitRate,\n                audioChannels,\n                maxAudioChannels,\n                profile,\n                level,\n                framerate,\n                maxFramerate,\n                copyTimestamps,\n                startTimeTicks,\n                width,\n                height,\n                maxWidth,\n                maxHeight,\n                videoBitRate,\n                subtitleStreamIndex,\n                subtitleMethod,\n                maxRefFrames,\n                maxVideoBitDepth,\n                requireAvc,\n                deInterlace,\n                requireNonAnamorphic,\n                transcodingMaxAudioChannels,\n                cpuCoreLimit,\n                liveStreamId,\n                enableMpegtsM2TsMode,\n                videoCodec,\n                subtitleCodec,\n                transcodeReasons,\n                audioStreamIndex,\n                videoStreamIndex,\n                context,\n                streamOptions);\n        }\n    }\n}\n", "#nullable disable\n\n#pragma warning disable CS1591\n\nusing System;\nusing System.Collections.Generic;\nusing System.Globalization;\nusing System.IO;\nusing System.Linq;\nusing System.Text;\nusing System.Text.RegularExpressions;\nusing System.Threading;\nusing Jellyfin.Data.Enums;\nusing Jellyfin.Extensions;\nusing MediaBrowser.Common.Configuration;\nusing MediaBrowser.Controller.Extensions;\nusing MediaBrowser.Model.Configuration;\nusing MediaBrowser.Model.Dlna;\nusing MediaBrowser.Model.Dto;\nusing MediaBrowser.Model.Entities;\nusing MediaBrowser.Model.MediaInfo;\nusing Microsoft.Extensions.Configuration;\n\nnamespace MediaBrowser.Controller.MediaEncoding\n{\n    public class EncodingHelper\n    {\n        /// <summary>\n        /// The codec validation regex.\n        /// </summary>\n        public const string ValidationRegex = @\"^[a-zA-Z0-9\\-\\._,|]{0,40}$\";\n\n        private const string QsvAlias = \"qs\";\n        private const string VaapiAlias = \"va\";\n        private const string D3d11vaAlias = \"dx11\";\n        private const string VideotoolboxAlias = \"vt\";\n        private const string OpenclAlias = \"ocl\";\n        private const string CudaAlias = \"cu\";\n        private readonly IApplicationPaths _appPaths;\n        private readonly IMediaEncoder _mediaEncoder;\n        private readonly ISubtitleEncoder _subtitleEncoder;\n        private readonly IConfiguration _config;\n\n        private static readonly Regex _validationRegex = new(ValidationRegex, RegexOptions.Compiled);\n\n        // i915 hang was fixed by linux 6.2 (3f882f2)\n        private readonly Version _minKerneli915Hang = new Version(5, 18);\n        private readonly Version _maxKerneli915Hang = new Version(6, 1, 3);\n        private readonly Version _minFixedKernel60i915Hang = new Version(6, 0, 18);\n\n        private readonly Version _minFFmpegImplictHwaccel = new Version(6, 0);\n        private readonly Version _minFFmpegHwaUnsafeOutput = new Version(6, 0);\n        private readonly Version _minFFmpegOclCuTonemapMode = new Version(5, 1, 3);\n\n        private static readonly string[] _videoProfilesH264 = new[]\n        {\n            \"ConstrainedBaseline\",\n            \"Baseline\",\n            \"Extended\",\n            \"Main\",\n            \"High\",\n            \"ProgressiveHigh\",\n            \"ConstrainedHigh\",\n            \"High10\"\n        };\n\n        private static readonly string[] _videoProfilesH265 = new[]\n        {\n            \"Main\",\n            \"Main10\"\n        };\n\n        public static readonly string[] LosslessAudioCodecs = new string[]\n        {\n            \"alac\",\n            \"ape\",\n            \"flac\",\n            \"mlp\",\n            \"truehd\",\n            \"wavpack\"\n        };\n\n        public EncodingHelper(\n            IApplicationPaths appPaths,\n            IMediaEncoder mediaEncoder,\n            ISubtitleEncoder subtitleEncoder,\n            IConfiguration config)\n        {\n            _appPaths = appPaths;\n            _mediaEncoder = mediaEncoder;\n            _subtitleEncoder = subtitleEncoder;\n            _config = config;\n        }\n\n        public string GetH264Encoder(EncodingJobInfo state, EncodingOptions encodingOptions)\n            => GetH264OrH265Encoder(\"libx264\", \"h264\", state, encodingOptions);\n\n        public string GetH265Encoder(EncodingJobInfo state, EncodingOptions encodingOptions)\n            => GetH264OrH265Encoder(\"libx265\", \"hevc\", state, encodingOptions);\n\n        private string GetH264OrH265Encoder(string defaultEncoder, string hwEncoder, EncodingJobInfo state, EncodingOptions encodingOptions)\n        {\n            // Only use alternative encoders for video files.\n            // When using concat with folder rips, if the mfx session fails to initialize, ffmpeg will be stuck retrying and will not exit gracefully\n            // Since transcoding of folder rips is experimental anyway, it's not worth adding additional variables such as this.\n            if (state.VideoType == VideoType.VideoFile)\n            {\n                var hwType = encodingOptions.HardwareAccelerationType;\n\n                var codecMap = new Dictionary<string, string>(StringComparer.OrdinalIgnoreCase)\n                {\n                    { \"amf\",                  hwEncoder + \"_amf\" },\n                    { \"nvenc\",                hwEncoder + \"_nvenc\" },\n                    { \"qsv\",                  hwEncoder + \"_qsv\" },\n                    { \"vaapi\",                hwEncoder + \"_vaapi\" },\n                    { \"videotoolbox\",         hwEncoder + \"_videotoolbox\" },\n                    { \"v4l2m2m\",              hwEncoder + \"_v4l2m2m\" },\n                };\n\n                if (!string.IsNullOrEmpty(hwType)\n                    && encodingOptions.EnableHardwareEncoding\n                    && codecMap.ContainsKey(hwType))\n                {\n                    var preferredEncoder = codecMap[hwType];\n\n                    if (_mediaEncoder.SupportsEncoder(preferredEncoder))\n                    {\n                        return preferredEncoder;\n                    }\n                }\n            }\n\n            return defaultEncoder;\n        }\n\n        private bool IsVaapiSupported(EncodingJobInfo state)\n        {\n            // vaapi will throw an error with this input\n            // [vaapi @ 0x7faed8000960] No VAAPI support for codec mpeg4 profile -99.\n            if (string.Equals(state.VideoStream?.Codec, \"mpeg4\", StringComparison.OrdinalIgnoreCase))\n            {\n                return false;\n            }\n\n            return _mediaEncoder.SupportsHwaccel(\"vaapi\");\n        }\n\n        private bool IsVaapiFullSupported()\n        {\n            return _mediaEncoder.SupportsHwaccel(\"vaapi\")\n                   && _mediaEncoder.SupportsFilter(\"scale_vaapi\")\n                   && _mediaEncoder.SupportsFilter(\"deinterlace_vaapi\")\n                   && _mediaEncoder.SupportsFilter(\"tonemap_vaapi\")\n                   && _mediaEncoder.SupportsFilter(\"procamp_vaapi\")\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.OverlayVaapiFrameSync)\n                   && _mediaEncoder.SupportsFilter(\"hwupload_vaapi\");\n        }\n\n        private bool IsOpenclFullSupported()\n        {\n            return _mediaEncoder.SupportsHwaccel(\"opencl\")\n                   && _mediaEncoder.SupportsFilter(\"scale_opencl\")\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.TonemapOpenclBt2390)\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.OverlayOpenclFrameSync);\n        }\n\n        private bool IsCudaFullSupported()\n        {\n            return _mediaEncoder.SupportsHwaccel(\"cuda\")\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.ScaleCudaFormat)\n                   && _mediaEncoder.SupportsFilter(\"yadif_cuda\")\n                   && _mediaEncoder.SupportsFilterWithOption(FilterOptionType.TonemapCudaName)\n                   && _mediaEncoder.SupportsFilter(\"overlay_cuda\")\n                   && _mediaEncoder.SupportsFilter(\"hwupload_cuda\");\n        }\n\n        private bool IsHwTonemapAvailable(EncodingJobInfo state, EncodingOptions options)\n        {\n            if (state.VideoStream == null\n                || !options.EnableTonemapping\n                || GetVideoColorBitDepth(state) != 10)\n            {\n                return false;\n            }\n\n            if (string.Equals(state.VideoStream.Codec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                && string.Equals(state.VideoStream.VideoRange, \"HDR\", StringComparison.OrdinalIgnoreCase)\n                && string.Equals(state.VideoStream.VideoRangeType, \"DOVI\", StringComparison.OrdinalIgnoreCase))\n            {\n                // Only native SW decoder and HW accelerator can parse dovi rpu.\n                var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n                var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n                var isNvdecDecoder = vidDecoder.Contains(\"cuda\", StringComparison.OrdinalIgnoreCase);\n                var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n                return isSwDecoder || isNvdecDecoder || isVaapiDecoder || isD3d11vaDecoder;\n            }\n\n            return string.Equals(state.VideoStream.VideoRange, \"HDR\", StringComparison.OrdinalIgnoreCase)\n                   && (string.Equals(state.VideoStream.VideoRangeType, \"HDR10\", StringComparison.OrdinalIgnoreCase)\n                       || string.Equals(state.VideoStream.VideoRangeType, \"HLG\", StringComparison.OrdinalIgnoreCase));\n        }\n\n        private bool IsVaapiVppTonemapAvailable(EncodingJobInfo state, EncodingOptions options)\n        {\n            if (state.VideoStream == null\n                || !options.EnableVppTonemapping\n                || GetVideoColorBitDepth(state) != 10)\n            {\n                return false;\n            }\n\n            // Native VPP tonemapping may come to QSV in the future.\n\n            return string.Equals(state.VideoStream.VideoRange, \"HDR\", StringComparison.OrdinalIgnoreCase)\n                   && string.Equals(state.VideoStream.VideoRangeType, \"HDR10\", StringComparison.OrdinalIgnoreCase);\n        }\n\n        /// <summary>\n        /// Gets the name of the output video codec.\n        /// </summary>\n        /// <param name=\"state\">Encording state.</param>\n        /// <param name=\"encodingOptions\">Encoding options.</param>\n        /// <returns>Encoder string.</returns>\n        public string GetVideoEncoder(EncodingJobInfo state, EncodingOptions encodingOptions)\n        {\n            var codec = state.OutputVideoCodec;\n\n            if (!string.IsNullOrEmpty(codec))\n            {\n                if (string.Equals(codec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(codec, \"hevc\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetH265Encoder(state, encodingOptions);\n                }\n\n                if (string.Equals(codec, \"h264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetH264Encoder(state, encodingOptions);\n                }\n\n                if (string.Equals(codec, \"vp8\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(codec, \"vpx\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return \"libvpx\";\n                }\n\n                if (string.Equals(codec, \"vp9\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return \"libvpx-vp9\";\n                }\n\n                if (string.Equals(codec, \"wmv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return \"wmv2\";\n                }\n\n                if (string.Equals(codec, \"theora\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return \"libtheora\";\n                }\n\n                if (_validationRegex.IsMatch(codec))\n                {\n                    return codec.ToLowerInvariant();\n                }\n            }\n\n            return \"copy\";\n        }\n\n        /// <summary>\n        /// Gets the user agent param.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <returns>System.String.</returns>\n        public string GetUserAgentParam(EncodingJobInfo state)\n        {\n            if (state.RemoteHttpHeaders.TryGetValue(\"User-Agent\", out string useragent))\n            {\n                return \"-user_agent \\\"\" + useragent + \"\\\"\";\n            }\n\n            return string.Empty;\n        }\n\n        public static string GetInputFormat(string container)\n        {\n            if (string.IsNullOrEmpty(container) || !_validationRegex.IsMatch(container))\n            {\n                return null;\n            }\n\n            container = container.Replace(\"mkv\", \"matroska\", StringComparison.OrdinalIgnoreCase);\n\n            if (string.Equals(container, \"ts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"mpegts\";\n            }\n\n            // For these need to find out the ffmpeg names\n            if (string.Equals(container, \"m2ts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"wmv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"mts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"vob\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"mpg\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"mpeg\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"rec\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"dvr-ms\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"ogm\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"divx\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"tp\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"rmvb\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(container, \"rtp\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            // Seeing reported failures here, not sure yet if this is related to specifying input format\n            if (string.Equals(container, \"m4v\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            // obviously don't do this for strm files\n            if (string.Equals(container, \"strm\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            // ISO files don't have an ffmpeg format\n            if (string.Equals(container, \"iso\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            return container;\n        }\n\n        /// <summary>\n        /// Gets decoder from a codec.\n        /// </summary>\n        /// <param name=\"codec\">Codec to use.</param>\n        /// <returns>Decoder string.</returns>\n        public string GetDecoderFromCodec(string codec)\n        {\n            // For these need to find out the ffmpeg names\n            if (string.Equals(codec, \"mp2\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(codec, \"aac_latm\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (string.Equals(codec, \"eac3\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            if (_mediaEncoder.SupportsDecoder(codec))\n            {\n                return codec;\n            }\n\n            return null;\n        }\n\n        /// <summary>\n        /// Infers the audio codec based on the url.\n        /// </summary>\n        /// <param name=\"container\">Container to use.</param>\n        /// <returns>Codec string.</returns>\n        public string InferAudioCodec(string container)\n        {\n            var ext = \".\" + (container ?? string.Empty);\n\n            if (string.Equals(ext, \".mp3\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"mp3\";\n            }\n\n            if (string.Equals(ext, \".aac\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"aac\";\n            }\n\n            if (string.Equals(ext, \".wma\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"wma\";\n            }\n\n            if (string.Equals(ext, \".ogg\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            if (string.Equals(ext, \".oga\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            if (string.Equals(ext, \".ogv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            if (string.Equals(ext, \".webm\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            if (string.Equals(ext, \".webma\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"vorbis\";\n            }\n\n            return \"copy\";\n        }\n\n        /// <summary>\n        /// Infers the video codec.\n        /// </summary>\n        /// <param name=\"url\">The URL.</param>\n        /// <returns>System.Nullable{VideoCodecs}.</returns>\n        public string InferVideoCodec(string url)\n        {\n            var ext = Path.GetExtension(url);\n\n            if (string.Equals(ext, \".asf\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"wmv\";\n            }\n\n            if (string.Equals(ext, \".webm\", StringComparison.OrdinalIgnoreCase))\n            {\n                // TODO: this may not always mean VP8, as the codec ages\n                return \"vp8\";\n            }\n\n            if (string.Equals(ext, \".ogg\", StringComparison.OrdinalIgnoreCase) || string.Equals(ext, \".ogv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"theora\";\n            }\n\n            if (string.Equals(ext, \".m3u8\", StringComparison.OrdinalIgnoreCase) || string.Equals(ext, \".ts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"h264\";\n            }\n\n            return \"copy\";\n        }\n\n        public int GetVideoProfileScore(string videoCodec, string videoProfile)\n        {\n            // strip spaces because they may be stripped out on the query string\n            string profile = videoProfile.Replace(\" \", string.Empty, StringComparison.Ordinal);\n            if (string.Equals(\"h264\", videoCodec, StringComparison.OrdinalIgnoreCase))\n            {\n                return Array.FindIndex(_videoProfilesH264, x => string.Equals(x, profile, StringComparison.OrdinalIgnoreCase));\n            }\n            else if (string.Equals(\"hevc\", videoCodec, StringComparison.OrdinalIgnoreCase))\n            {\n                return Array.FindIndex(_videoProfilesH265, x => string.Equals(x, profile, StringComparison.OrdinalIgnoreCase));\n            }\n\n            return -1;\n        }\n\n        public string GetInputPathArgument(EncodingJobInfo state)\n        {\n            var mediaPath = state.MediaPath ?? string.Empty;\n\n            return _mediaEncoder.GetInputArgument(mediaPath, state.MediaSource);\n        }\n\n        /// <summary>\n        /// Gets the audio encoder.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <returns>System.String.</returns>\n        public string GetAudioEncoder(EncodingJobInfo state)\n        {\n            var codec = state.OutputAudioCodec;\n\n            if (!_validationRegex.IsMatch(codec))\n            {\n                codec = \"aac\";\n            }\n\n            if (string.Equals(codec, \"aac\", StringComparison.OrdinalIgnoreCase))\n            {\n                // Use libfdk_aac for better audio quality if using custom build of FFmpeg which has fdk_aac support\n                if (_mediaEncoder.SupportsEncoder(\"libfdk_aac\"))\n                {\n                    return \"libfdk_aac\";\n                }\n\n                return \"aac\";\n            }\n\n            if (string.Equals(codec, \"mp3\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"libmp3lame\";\n            }\n\n            if (string.Equals(codec, \"vorbis\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"libvorbis\";\n            }\n\n            if (string.Equals(codec, \"wma\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"wmav2\";\n            }\n\n            if (string.Equals(codec, \"opus\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"libopus\";\n            }\n\n            if (string.Equals(codec, \"flac\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"flac\";\n            }\n\n            if (string.Equals(codec, \"dts\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"dca\";\n            }\n\n            return codec.ToLowerInvariant();\n        }\n\n        private string GetVideoToolboxDeviceArgs(string alias)\n        {\n            alias ??= VideotoolboxAlias;\n\n            // device selection in vt is not supported.\n            return \" -init_hw_device videotoolbox=\" + alias;\n        }\n\n        private string GetCudaDeviceArgs(int deviceIndex, string alias)\n        {\n            alias ??= CudaAlias;\n            deviceIndex = deviceIndex >= 0\n                ? deviceIndex\n                : 0;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \" -init_hw_device cuda={0}:{1}\",\n                alias,\n                deviceIndex);\n        }\n\n        private string GetOpenclDeviceArgs(int deviceIndex, string deviceVendorName, string srcDeviceAlias, string alias)\n        {\n            alias ??= OpenclAlias;\n            deviceIndex = deviceIndex >= 0\n                ? deviceIndex\n                : 0;\n            var vendorOpts = string.IsNullOrEmpty(deviceVendorName)\n                ? \":0.0\"\n                : \":.\" + deviceIndex + \",device_vendor=\\\"\" + deviceVendorName + \"\\\"\";\n            var options = string.IsNullOrEmpty(srcDeviceAlias)\n                ? vendorOpts\n                : \"@\" + srcDeviceAlias;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \" -init_hw_device opencl={0}{1}\",\n                alias,\n                options);\n        }\n\n        private string GetD3d11vaDeviceArgs(int deviceIndex, string deviceVendorId, string alias)\n        {\n            alias ??= D3d11vaAlias;\n            deviceIndex = deviceIndex >= 0 ? deviceIndex : 0;\n            var options = string.IsNullOrEmpty(deviceVendorId)\n                ? deviceIndex.ToString(CultureInfo.InvariantCulture)\n                : \",vendor=\" + deviceVendorId;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \" -init_hw_device d3d11va={0}:{1}\",\n                alias,\n                options);\n        }\n\n        private string GetVaapiDeviceArgs(string renderNodePath, string driver, string kernelDriver, string alias)\n        {\n            alias ??= VaapiAlias;\n\n            // 'renderNodePath' has higher priority than 'kernelDriver'\n            var driverOpts = string.IsNullOrEmpty(renderNodePath)\n                ? (string.IsNullOrEmpty(kernelDriver) ? string.Empty : \",kernel_driver=\" + kernelDriver)\n                : renderNodePath;\n\n            // 'driver' behaves similarly to env LIBVA_DRIVER_NAME\n            driverOpts += string.IsNullOrEmpty(driver) ? string.Empty : \",driver=\" + driver;\n\n            var options = string.IsNullOrEmpty(driverOpts) ? string.Empty : \":\" + driverOpts;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \" -init_hw_device vaapi={0}{1}\",\n                alias,\n                options);\n        }\n\n        private string GetQsvDeviceArgs(string alias)\n        {\n            var arg = \" -init_hw_device qsv=\" + (alias ?? QsvAlias);\n            if (OperatingSystem.IsLinux())\n            {\n                // derive qsv from vaapi device\n                return GetVaapiDeviceArgs(null, \"iHD\", \"i915\", VaapiAlias) + arg + \"@\" + VaapiAlias;\n            }\n\n            if (OperatingSystem.IsWindows())\n            {\n                // derive qsv from d3d11va device\n                return GetD3d11vaDeviceArgs(0, \"0x8086\", D3d11vaAlias) + arg + \"@\" + D3d11vaAlias;\n            }\n\n            return null;\n        }\n\n        private string GetFilterHwDeviceArgs(string alias)\n        {\n            return string.IsNullOrEmpty(alias)\n                ? string.Empty\n                : \" -filter_hw_device \" + alias;\n        }\n\n        public string GetGraphicalSubCanvasSize(EncodingJobInfo state)\n        {\n            // DVBSUB and DVDSUB use the fixed canvas size 720x576\n            if (state.SubtitleStream != null\n                && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode\n                && !state.SubtitleStream.IsTextSubtitleStream\n                && !string.Equals(state.SubtitleStream.Codec, \"DVBSUB\", StringComparison.OrdinalIgnoreCase)\n                && !string.Equals(state.SubtitleStream.Codec, \"DVDSUB\", StringComparison.OrdinalIgnoreCase))\n            {\n                var inW = state.VideoStream?.Width;\n                var inH = state.VideoStream?.Height;\n                var reqW = state.BaseRequest.Width;\n                var reqH = state.BaseRequest.Height;\n                var reqMaxW = state.BaseRequest.MaxWidth;\n                var reqMaxH = state.BaseRequest.MaxHeight;\n\n                // setup a relative small canvas_size for overlay_qsv/vaapi to reduce transfer overhead\n                var (overlayW, overlayH) = GetFixedOutputSize(inW, inH, reqW, reqH, reqMaxW, 1080);\n\n                if (overlayW.HasValue && overlayH.HasValue)\n                {\n                    return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \" -canvas_size {0}x{1}\",\n                        overlayW.Value,\n                        overlayH.Value);\n                }\n            }\n\n            return string.Empty;\n        }\n\n        /// <summary>\n        /// Gets the input video hwaccel argument.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <returns>Input video hwaccel arguments.</returns>\n        public string GetInputVideoHwaccelArgs(EncodingJobInfo state, EncodingOptions options)\n        {\n            if (!state.IsVideoRequest)\n            {\n                return string.Empty;\n            }\n\n            var vidEncoder = GetVideoEncoder(state, options) ?? string.Empty;\n            if (IsCopyCodec(vidEncoder))\n            {\n                return string.Empty;\n            }\n\n            var args = new StringBuilder();\n            var isWindows = OperatingSystem.IsWindows();\n            var isLinux = OperatingSystem.IsLinux();\n            var isMacOS = OperatingSystem.IsMacOS();\n            var optHwaccelType = options.HardwareAccelerationType;\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isHwTonemapAvailable = IsHwTonemapAvailable(state, options);\n\n            if (string.Equals(optHwaccelType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (!isLinux || !_mediaEncoder.SupportsHwaccel(\"vaapi\"))\n                {\n                    return string.Empty;\n                }\n\n                var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                var isVaapiEncoder = vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                if (!isVaapiDecoder && !isVaapiEncoder)\n                {\n                    return string.Empty;\n                }\n\n                if (_mediaEncoder.IsVaapiDeviceInteliHD)\n                {\n                    args.Append(GetVaapiDeviceArgs(options.VaapiDevice, \"iHD\", null, VaapiAlias));\n                }\n                else if (_mediaEncoder.IsVaapiDeviceInteli965)\n                {\n                    // Only override i965 since it has lower priority than iHD in libva lookup.\n                    Environment.SetEnvironmentVariable(\"LIBVA_DRIVER_NAME\", \"i965\");\n                    Environment.SetEnvironmentVariable(\"LIBVA_DRIVER_NAME_JELLYFIN\", \"i965\");\n                    args.Append(GetVaapiDeviceArgs(options.VaapiDevice, \"i965\", null, VaapiAlias));\n                }\n                else\n                {\n                    args.Append(GetVaapiDeviceArgs(options.VaapiDevice, null, null, VaapiAlias));\n                }\n\n                var filterDevArgs = GetFilterHwDeviceArgs(VaapiAlias);\n\n                if (isHwTonemapAvailable && IsOpenclFullSupported())\n                {\n                    if (_mediaEncoder.IsVaapiDeviceInteliHD || _mediaEncoder.IsVaapiDeviceInteli965)\n                    {\n                        if (!isVaapiDecoder)\n                        {\n                            args.Append(GetOpenclDeviceArgs(0, null, VaapiAlias, OpenclAlias));\n                            filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                        }\n                    }\n                    else if (_mediaEncoder.IsVaapiDeviceAmd)\n                    {\n                        args.Append(GetOpenclDeviceArgs(0, \"Advanced Micro Devices\", null, OpenclAlias));\n                        filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                    }\n                    else\n                    {\n                        args.Append(GetOpenclDeviceArgs(0, null, null, OpenclAlias));\n                        filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                    }\n                }\n\n                args.Append(filterDevArgs);\n            }\n            else if (string.Equals(optHwaccelType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                if ((!isLinux && !isWindows) || !_mediaEncoder.SupportsHwaccel(\"qsv\"))\n                {\n                    return string.Empty;\n                }\n\n                var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n                var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                var isQsvDecoder = vidDecoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n                var isQsvEncoder = vidEncoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n                var isHwDecoder = isQsvDecoder || isVaapiDecoder || isD3d11vaDecoder;\n                if (!isHwDecoder && !isQsvEncoder)\n                {\n                    return string.Empty;\n                }\n\n                args.Append(GetQsvDeviceArgs(QsvAlias));\n                var filterDevArgs = GetFilterHwDeviceArgs(QsvAlias);\n                // child device used by qsv.\n                if (_mediaEncoder.SupportsHwaccel(\"vaapi\") || _mediaEncoder.SupportsHwaccel(\"d3d11va\"))\n                {\n                    if (isHwTonemapAvailable && IsOpenclFullSupported())\n                    {\n                        var srcAlias = isLinux ? VaapiAlias : D3d11vaAlias;\n                        args.Append(GetOpenclDeviceArgs(0, null, srcAlias, OpenclAlias));\n                        if (!isHwDecoder)\n                        {\n                            filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                        }\n                    }\n                }\n\n                args.Append(filterDevArgs);\n            }\n            else if (string.Equals(optHwaccelType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                if ((!isLinux && !isWindows) || !IsCudaFullSupported())\n                {\n                    return string.Empty;\n                }\n\n                var isCuvidDecoder = vidDecoder.Contains(\"cuvid\", StringComparison.OrdinalIgnoreCase);\n                var isNvdecDecoder = vidDecoder.Contains(\"cuda\", StringComparison.OrdinalIgnoreCase);\n                var isNvencEncoder = vidEncoder.Contains(\"nvenc\", StringComparison.OrdinalIgnoreCase);\n                var isHwDecoder = isNvdecDecoder || isCuvidDecoder;\n                if (!isHwDecoder && !isNvencEncoder)\n                {\n                    return string.Empty;\n                }\n\n                args.Append(GetCudaDeviceArgs(0, CudaAlias))\n                     .Append(GetFilterHwDeviceArgs(CudaAlias));\n            }\n            else if (string.Equals(optHwaccelType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (!isWindows || !_mediaEncoder.SupportsHwaccel(\"d3d11va\"))\n                {\n                    return string.Empty;\n                }\n\n                var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n                var isAmfEncoder = vidEncoder.Contains(\"amf\", StringComparison.OrdinalIgnoreCase);\n                if (!isD3d11vaDecoder && !isAmfEncoder)\n                {\n                    return string.Empty;\n                }\n\n                // no dxva video processor hw filter.\n                args.Append(GetD3d11vaDeviceArgs(0, \"0x1002\", D3d11vaAlias));\n                var filterDevArgs = string.Empty;\n                if (IsOpenclFullSupported())\n                {\n                    args.Append(GetOpenclDeviceArgs(0, null, D3d11vaAlias, OpenclAlias));\n                    filterDevArgs = GetFilterHwDeviceArgs(OpenclAlias);\n                }\n\n                args.Append(filterDevArgs);\n            }\n            else if (string.Equals(optHwaccelType, \"videotoolbox\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (!isMacOS || !_mediaEncoder.SupportsHwaccel(\"videotoolbox\"))\n                {\n                    return string.Empty;\n                }\n\n                var isVideotoolboxDecoder = vidDecoder.Contains(\"videotoolbox\", StringComparison.OrdinalIgnoreCase);\n                var isVideotoolboxEncoder = vidEncoder.Contains(\"videotoolbox\", StringComparison.OrdinalIgnoreCase);\n                if (!isVideotoolboxDecoder && !isVideotoolboxEncoder)\n                {\n                    return string.Empty;\n                }\n\n                // no videotoolbox hw filter.\n                args.Append(GetVideoToolboxDeviceArgs(VideotoolboxAlias));\n            }\n\n            if (!string.IsNullOrEmpty(vidDecoder))\n            {\n                args.Append(vidDecoder);\n            }\n\n            // hw transpose filters should be added manually.\n            args.Append(\" -autorotate 0\");\n\n            return args.ToString().Trim();\n        }\n\n        /// <summary>\n        /// Gets the input argument.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"segmentContainer\">Segment Container.</param>\n        /// <returns>Input arguments.</returns>\n        public string GetInputArgument(EncodingJobInfo state, EncodingOptions options, string segmentContainer)\n        {\n            var arg = new StringBuilder();\n            var inputVidHwaccelArgs = GetInputVideoHwaccelArgs(state, options);\n\n            if (!string.IsNullOrEmpty(inputVidHwaccelArgs))\n            {\n                arg.Append(inputVidHwaccelArgs);\n            }\n\n            var canvasArgs = GetGraphicalSubCanvasSize(state);\n            if (!string.IsNullOrEmpty(canvasArgs))\n            {\n                arg.Append(canvasArgs);\n            }\n\n            arg.Append(\" -i \")\n                .Append(GetInputPathArgument(state));\n\n            // sub2video for external graphical subtitles\n            if (state.SubtitleStream != null\n                && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode\n                && !state.SubtitleStream.IsTextSubtitleStream\n                && state.SubtitleStream.IsExternal)\n            {\n                var subtitlePath = state.SubtitleStream.Path;\n\n                if (string.Equals(Path.GetExtension(subtitlePath), \".sub\", StringComparison.OrdinalIgnoreCase))\n                {\n                    var idxFile = Path.ChangeExtension(subtitlePath, \".idx\");\n                    if (File.Exists(idxFile))\n                    {\n                        subtitlePath = idxFile;\n                    }\n                }\n\n                // Also seek the external subtitles stream.\n                var seekSubParam = GetFastSeekCommandLineParameter(state, options, segmentContainer);\n                if (!string.IsNullOrEmpty(seekSubParam))\n                {\n                    arg.Append(' ').Append(seekSubParam);\n                }\n\n                if (!string.IsNullOrEmpty(canvasArgs))\n                {\n                    arg.Append(canvasArgs);\n                }\n\n                arg.Append(\" -i file:\\\"\").Append(subtitlePath).Append('\\\"');\n            }\n\n            if (state.AudioStream != null && state.AudioStream.IsExternal)\n            {\n                // Also seek the external audio stream.\n                var seekAudioParam = GetFastSeekCommandLineParameter(state, options, segmentContainer);\n                if (!string.IsNullOrEmpty(seekAudioParam))\n                {\n                    arg.Append(' ').Append(seekAudioParam);\n                }\n\n                arg.Append(\" -i \\\"\").Append(state.AudioStream.Path).Append('\"');\n            }\n\n            // Disable auto inserted SW scaler for HW decoders in case of changed resolution.\n            var isSwDecoder = string.IsNullOrEmpty(GetHardwareVideoDecoder(state, options));\n            if (!isSwDecoder)\n            {\n                arg.Append(\" -autoscale 0\");\n            }\n\n            return arg.ToString();\n        }\n\n        /// <summary>\n        /// Determines whether the specified stream is H264.\n        /// </summary>\n        /// <param name=\"stream\">The stream.</param>\n        /// <returns><c>true</c> if the specified stream is H264; otherwise, <c>false</c>.</returns>\n        public static bool IsH264(MediaStream stream)\n        {\n            var codec = stream.Codec ?? string.Empty;\n\n            return codec.IndexOf(\"264\", StringComparison.OrdinalIgnoreCase) != -1\n                    || codec.IndexOf(\"avc\", StringComparison.OrdinalIgnoreCase) != -1;\n        }\n\n        public static bool IsH265(MediaStream stream)\n        {\n            var codec = stream.Codec ?? string.Empty;\n\n            return codec.IndexOf(\"265\", StringComparison.OrdinalIgnoreCase) != -1\n                || codec.IndexOf(\"hevc\", StringComparison.OrdinalIgnoreCase) != -1;\n        }\n\n        public static bool IsAAC(MediaStream stream)\n        {\n            var codec = stream.Codec ?? string.Empty;\n\n            return codec.IndexOf(\"aac\", StringComparison.OrdinalIgnoreCase) != -1;\n        }\n\n        public static string GetBitStreamArgs(MediaStream stream)\n        {\n            // TODO This is auto inserted into the mpegts mux so it might not be needed.\n            // https://www.ffmpeg.org/ffmpeg-bitstream-filters.html#h264_005fmp4toannexb\n            if (IsH264(stream))\n            {\n                return \"-bsf:v h264_mp4toannexb\";\n            }\n            else if (IsH265(stream))\n            {\n                return \"-bsf:v hevc_mp4toannexb\";\n            }\n            else if (IsAAC(stream))\n            {\n                // Convert adts header(mpegts) to asc header(mp4).\n                return \"-bsf:a aac_adtstoasc\";\n            }\n            else\n            {\n                return null;\n            }\n        }\n\n        public static string GetAudioBitStreamArguments(EncodingJobInfo state, string segmentContainer, string mediaSourceContainer)\n        {\n            var bitStreamArgs = string.Empty;\n            var segmentFormat = GetSegmentFileExtension(segmentContainer).TrimStart('.');\n\n            // Apply aac_adtstoasc bitstream filter when media source is in mpegts.\n            if (string.Equals(segmentFormat, \"mp4\", StringComparison.OrdinalIgnoreCase)\n                && (string.Equals(mediaSourceContainer, \"mpegts\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(mediaSourceContainer, \"aac\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(mediaSourceContainer, \"hls\", StringComparison.OrdinalIgnoreCase)))\n            {\n                bitStreamArgs = GetBitStreamArgs(state.AudioStream);\n                bitStreamArgs = string.IsNullOrEmpty(bitStreamArgs) ? string.Empty : \" \" + bitStreamArgs;\n            }\n\n            return bitStreamArgs;\n        }\n\n        public static string GetSegmentFileExtension(string segmentContainer)\n        {\n            if (!string.IsNullOrWhiteSpace(segmentContainer))\n            {\n                return \".\" + segmentContainer;\n            }\n\n            return \".ts\";\n        }\n\n        public string GetVideoBitrateParam(EncodingJobInfo state, string videoCodec)\n        {\n            if (state.OutputVideoBitrate == null)\n            {\n                return string.Empty;\n            }\n\n            int bitrate = state.OutputVideoBitrate.Value;\n\n            // Currently use the same buffer size for all encoders\n            int bufsize = bitrate * 2;\n\n            if (string.Equals(videoCodec, \"libvpx\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(videoCodec, \"libvpx-vp9\", StringComparison.OrdinalIgnoreCase))\n            {\n                // When crf is used with vpx, b:v becomes a max rate\n                // https://trac.ffmpeg.org/wiki/Encode/VP8\n                // https://trac.ffmpeg.org/wiki/Encode/VP9\n                return FormattableString.Invariant($\" -maxrate:v {bitrate} -bufsize:v {bufsize} -b:v {bitrate}\");\n            }\n\n            if (string.Equals(videoCodec, \"msmpeg4\", StringComparison.OrdinalIgnoreCase))\n            {\n                return FormattableString.Invariant($\" -b:v {bitrate}\");\n            }\n\n            if (string.Equals(videoCodec, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(videoCodec, \"libx265\", StringComparison.OrdinalIgnoreCase))\n            {\n                return FormattableString.Invariant($\" -maxrate {bitrate} -bufsize {bufsize}\");\n            }\n\n            if (string.Equals(videoCodec, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(videoCodec, \"hevc_amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                // Override the too high default qmin 18 in transcoding preset\n                return FormattableString.Invariant($\" -rc cbr -qmin 0 -qmax 32 -b:v {bitrate} -maxrate {bitrate} -bufsize {bufsize}\");\n            }\n\n            if (string.Equals(videoCodec, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(videoCodec, \"hevc_vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                // VBR in i965 driver may result in pixelated output.\n                if (_mediaEncoder.IsVaapiDeviceInteli965)\n                {\n                    return FormattableString.Invariant($\" -rc_mode CBR -b:v {bitrate} -maxrate {bitrate} -bufsize {bufsize}\");\n                }\n                else\n                {\n                    return FormattableString.Invariant($\" -rc_mode VBR -b:v {bitrate} -maxrate {bitrate} -bufsize {bufsize}\");\n                }\n            }\n\n            return FormattableString.Invariant($\" -b:v {bitrate} -maxrate {bitrate} -bufsize {bufsize}\");\n        }\n\n        public static string NormalizeTranscodingLevel(EncodingJobInfo state, string level)\n        {\n            if (double.TryParse(level, NumberStyles.Any, CultureInfo.InvariantCulture, out double requestLevel))\n            {\n                if (string.Equals(state.ActualOutputVideoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.ActualOutputVideoCodec, \"h265\", StringComparison.OrdinalIgnoreCase))\n                {\n                    // Transcode to level 5.0 and lower for maximum compatibility.\n                    // Level 5.0 is suitable for up to 4k 30fps hevc encoding, otherwise let the encoder to handle it.\n                    // https://en.wikipedia.org/wiki/High_Efficiency_Video_Coding_tiers_and_levels\n                    // MaxLumaSampleRate = 3840*2160*30 = 248832000 < 267386880.\n                    if (requestLevel >= 150)\n                    {\n                        return \"150\";\n                    }\n                }\n                else if (string.Equals(state.ActualOutputVideoCodec, \"h264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    // Transcode to level 5.1 and lower for maximum compatibility.\n                    // h264 4k 30fps requires at least level 5.1 otherwise it will break on safari fmp4.\n                    // https://en.wikipedia.org/wiki/Advanced_Video_Coding#Levels\n                    if (requestLevel >= 51)\n                    {\n                        return \"51\";\n                    }\n                }\n            }\n\n            return level;\n        }\n\n        /// <summary>\n        /// Gets the text subtitle param.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <param name=\"enableAlpha\">Enable alpha processing.</param>\n        /// <param name=\"enableSub2video\">Enable sub2video mode.</param>\n        /// <returns>System.String.</returns>\n        public string GetTextSubtitlesFilter(EncodingJobInfo state, bool enableAlpha, bool enableSub2video)\n        {\n            var seconds = Math.Round(TimeSpan.FromTicks(state.StartTimeTicks ?? 0).TotalSeconds);\n\n            // hls always copies timestamps\n            var setPtsParam = state.CopyTimestamps || state.TranscodingType != TranscodingJobType.Progressive\n                ? string.Empty\n                : string.Format(CultureInfo.InvariantCulture, \",setpts=PTS -{0}/TB\", seconds);\n\n            var alphaParam = enableAlpha ? \":alpha=1\" : string.Empty;\n            var sub2videoParam = enableSub2video ? \":sub2video=1\" : string.Empty;\n\n            var fontPath = Path.Combine(_appPaths.CachePath, \"attachments\", state.MediaSource.Id);\n            var fontParam = string.Format(\n                CultureInfo.InvariantCulture,\n                \":fontsdir='{0}'\",\n                _mediaEncoder.EscapeSubtitleFilterPath(fontPath));\n\n            // TODO\n            // var fallbackFontPath = Path.Combine(_appPaths.ProgramDataPath, \"fonts\", \"DroidSansFallback.ttf\");\n            // string fallbackFontParam = string.Empty;\n\n            // if (!File.Exists(fallbackFontPath))\n            // {\n            //     _fileSystem.CreateDirectory(_fileSystem.GetDirectoryName(fallbackFontPath));\n            //     using (var stream = _assemblyInfo.GetManifestResourceStream(GetType(), GetType().Namespace + \".DroidSansFallback.ttf\"))\n            //     {\n            //         using (var fileStream = new FileStream(fallbackFontPath, FileMode.Create, FileAccess.Write, FileShare.Read))\n            //         {\n            //             stream.CopyTo(fileStream);\n            //         }\n            //     }\n            // }\n\n            // fallbackFontParam = string.Format(CultureInfo.InvariantCulture, \":force_style='FontName=Droid Sans Fallback':fontsdir='{0}'\", _mediaEncoder.EscapeSubtitleFilterPath(_fileSystem.GetDirectoryName(fallbackFontPath)));\n\n            if (state.SubtitleStream.IsExternal)\n            {\n                var charsetParam = string.Empty;\n\n                if (!string.IsNullOrEmpty(state.SubtitleStream.Language))\n                {\n                    var charenc = _subtitleEncoder.GetSubtitleFileCharacterSet(\n                            state.SubtitleStream,\n                            state.SubtitleStream.Language,\n                            state.MediaSource,\n                            CancellationToken.None).GetAwaiter().GetResult();\n\n                    if (!string.IsNullOrEmpty(charenc))\n                    {\n                        charsetParam = \":charenc=\" + charenc;\n                    }\n                }\n\n                // TODO: Perhaps also use original_size=1920x800 ??\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"subtitles=f='{0}'{1}{2}{3}{4}{5}\",\n                    _mediaEncoder.EscapeSubtitleFilterPath(state.SubtitleStream.Path),\n                    charsetParam,\n                    alphaParam,\n                    sub2videoParam,\n                    fontParam,\n                    // fallbackFontParam,\n                    setPtsParam);\n            }\n\n            var mediaPath = state.MediaPath ?? string.Empty;\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"subtitles=f='{0}':si={1}{2}{3}{4}{5}\",\n                _mediaEncoder.EscapeSubtitleFilterPath(mediaPath),\n                state.InternalSubtitleStreamOffset.ToString(CultureInfo.InvariantCulture),\n                alphaParam,\n                sub2videoParam,\n                fontParam,\n                // fallbackFontParam,\n                setPtsParam);\n        }\n\n        public double? GetFramerateParam(EncodingJobInfo state)\n        {\n            var request = state.BaseRequest;\n\n            if (request.Framerate.HasValue)\n            {\n                return request.Framerate.Value;\n            }\n\n            var maxrate = request.MaxFramerate;\n\n            if (maxrate.HasValue && state.VideoStream != null)\n            {\n                var contentRate = state.VideoStream.AverageFrameRate ?? state.VideoStream.RealFrameRate;\n\n                if (contentRate.HasValue && contentRate.Value > maxrate.Value)\n                {\n                    return maxrate;\n                }\n            }\n\n            return null;\n        }\n\n        public string GetHlsVideoKeyFrameArguments(\n            EncodingJobInfo state,\n            string codec,\n            int segmentLength,\n            bool isEventPlaylist,\n            int? startNumber)\n        {\n            var args = string.Empty;\n            var gopArg = string.Empty;\n            var keyFrameArg = string.Empty;\n            if (isEventPlaylist)\n            {\n                keyFrameArg = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -force_key_frames:0 \\\"expr:gte(t,n_forced*{0})\\\"\",\n                    segmentLength);\n            }\n            else if (startNumber.HasValue)\n            {\n                keyFrameArg = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -force_key_frames:0 \\\"expr:gte(t,{0}+n_forced*{1})\\\"\",\n                    startNumber.Value * segmentLength,\n                    segmentLength);\n            }\n\n            var framerate = state.VideoStream?.RealFrameRate;\n            if (framerate.HasValue)\n            {\n                // This is to make sure keyframe interval is limited to our segment,\n                // as forcing keyframes is not enough.\n                // Example: we encoded half of desired length, then codec detected\n                // scene cut and inserted a keyframe; next forced keyframe would\n                // be created outside of segment, which breaks seeking.\n                gopArg = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -g:v:0 {0} -keyint_min:v:0 {0}\",\n                    Math.Ceiling(segmentLength * framerate.Value));\n            }\n\n            // Unable to force key frames using these encoders, set key frames by GOP.\n            if (string.Equals(codec, \"h264_qsv\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc_qsv\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc_nvenc\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc_amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                args += gopArg;\n            }\n            else if (string.Equals(codec, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                     || string.Equals(codec, \"libx265\", StringComparison.OrdinalIgnoreCase)\n                     || string.Equals(codec, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase)\n                     || string.Equals(codec, \"hevc_vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                args += keyFrameArg;\n\n                // prevent the libx264 from post processing to break the set keyframe.\n                if (string.Equals(codec, \"libx264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    args += \" -sc_threshold:v:0 0\";\n                }\n            }\n            else\n            {\n                args += keyFrameArg + gopArg;\n            }\n\n            // global_header produced by AMD VA-API encoder causes non-playable fMP4 on iOS\n            if (codec.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase)\n                && _mediaEncoder.IsVaapiDeviceAmd)\n            {\n                args += \" -flags:v -global_header\";\n            }\n\n            return args;\n        }\n\n        /// <summary>\n        /// Gets the video bitrate to specify on the command line.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"videoEncoder\">Video encoder to use.</param>\n        /// <param name=\"encodingOptions\">Encoding options.</param>\n        /// <param name=\"defaultPreset\">Default present to use for encoding.</param>\n        /// <returns>Video bitrate.</returns>\n        public string GetVideoQualityParam(EncodingJobInfo state, string videoEncoder, EncodingOptions encodingOptions, string defaultPreset)\n        {\n            var param = string.Empty;\n\n            // Tutorials: Enable Intel GuC / HuC firmware loading for Low Power Encoding.\n            // https://01.org/linuxgraphics/downloads/firmware\n            // https://wiki.archlinux.org/title/intel_graphics#Enable_GuC_/_HuC_firmware_loading\n            // Intel Low Power Encoding can save unnecessary CPU-GPU synchronization,\n            // which will reduce overhead in performance intensive tasks such as 4k transcoding and tonemapping.\n            var intelLowPowerHwEncoding = false;\n\n            // Workaround for linux 5.18 to 6.1.3 i915 hang at cost of performance.\n            // https://github.com/intel/media-driver/issues/1456\n            var enableWaFori915Hang = false;\n\n            if (string.Equals(encodingOptions.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                var isIntelVaapiDriver = _mediaEncoder.IsVaapiDeviceInteliHD || _mediaEncoder.IsVaapiDeviceInteli965;\n\n                if (string.Equals(videoEncoder, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase))\n                {\n                    intelLowPowerHwEncoding = encodingOptions.EnableIntelLowPowerH264HwEncoder && isIntelVaapiDriver;\n                }\n                else if (string.Equals(videoEncoder, \"hevc_vaapi\", StringComparison.OrdinalIgnoreCase))\n                {\n                    intelLowPowerHwEncoding = encodingOptions.EnableIntelLowPowerHevcHwEncoder && isIntelVaapiDriver;\n                }\n            }\n            else if (string.Equals(encodingOptions.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (OperatingSystem.IsLinux())\n                {\n                    var ver = Environment.OSVersion.Version;\n                    var isFixedKernel60 = ver.Major == 6 && ver.Minor == 0 && ver >= _minFixedKernel60i915Hang;\n                    var isUnaffectedKernel = ver < _minKerneli915Hang || ver > _maxKerneli915Hang;\n\n                    if (!(isUnaffectedKernel || isFixedKernel60))\n                    {\n                        var vidDecoder = GetHardwareVideoDecoder(state, encodingOptions) ?? string.Empty;\n                        var isIntelDecoder = vidDecoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase)\n                                             || vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n                        var doOclTonemap = _mediaEncoder.SupportsHwaccel(\"qsv\")\n                            && IsVaapiSupported(state)\n                            && IsOpenclFullSupported()\n                            && !IsVaapiVppTonemapAvailable(state, encodingOptions)\n                            && IsHwTonemapAvailable(state, encodingOptions);\n\n                        enableWaFori915Hang = isIntelDecoder && doOclTonemap;\n                    }\n                }\n\n                if (string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    intelLowPowerHwEncoding = encodingOptions.EnableIntelLowPowerH264HwEncoder;\n                }\n                else if (string.Equals(videoEncoder, \"hevc_qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    intelLowPowerHwEncoding = encodingOptions.EnableIntelLowPowerHevcHwEncoder;\n                }\n                else\n                {\n                    enableWaFori915Hang = false;\n                }\n            }\n\n            if (intelLowPowerHwEncoding)\n            {\n                param += \" -low_power 1\";\n            }\n\n            if (enableWaFori915Hang)\n            {\n                param += \" -async_depth 1\";\n            }\n\n            var isVc1 = string.Equals(state.VideoStream?.Codec, \"vc1\", StringComparison.OrdinalIgnoreCase);\n            var isLibX265 = string.Equals(videoEncoder, \"libx265\", StringComparison.OrdinalIgnoreCase);\n\n            if (string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase) || isLibX265)\n            {\n                if (!string.IsNullOrEmpty(encodingOptions.EncoderPreset))\n                {\n                    param += \" -preset \" + encodingOptions.EncoderPreset;\n                }\n                else\n                {\n                    param += \" -preset \" + defaultPreset;\n                }\n\n                int encodeCrf = encodingOptions.H264Crf;\n                if (isLibX265)\n                {\n                    encodeCrf = encodingOptions.H265Crf;\n                }\n\n                if (encodeCrf >= 0 && encodeCrf <= 51)\n                {\n                    param += \" -crf \" + encodeCrf.ToString(CultureInfo.InvariantCulture);\n                }\n                else\n                {\n                    string defaultCrf = \"23\";\n                    if (isLibX265)\n                    {\n                        defaultCrf = \"28\";\n                    }\n\n                    param += \" -crf \" + defaultCrf;\n                }\n            }\n            else if (string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase) // h264 (h264_qsv)\n                     || string.Equals(videoEncoder, \"hevc_qsv\", StringComparison.OrdinalIgnoreCase)) // hevc (hevc_qsv)\n            {\n                string[] valid_h264_qsv = { \"veryslow\", \"slower\", \"slow\", \"medium\", \"fast\", \"faster\", \"veryfast\" };\n\n                if (valid_h264_qsv.Contains(encodingOptions.EncoderPreset, StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -preset \" + encodingOptions.EncoderPreset;\n                }\n                else\n                {\n                    param += \" -preset 7\";\n                }\n\n                // Only h264_qsv has look_ahead option\n                if (string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -look_ahead 0\";\n                }\n            }\n            else if (string.Equals(videoEncoder, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase) // h264 (h264_nvenc)\n                     || string.Equals(videoEncoder, \"hevc_nvenc\", StringComparison.OrdinalIgnoreCase)) // hevc (hevc_nvenc)\n            {\n                switch (encodingOptions.EncoderPreset)\n                {\n                    case \"veryslow\":\n                        param += \" -preset p7\";\n                        break;\n\n                    case \"slower\":\n                        param += \" -preset p6\";\n                        break;\n\n                    case \"slow\":\n                        param += \" -preset p5\";\n                        break;\n\n                    case \"medium\":\n                        param += \" -preset p4\";\n                        break;\n\n                    case \"fast\":\n                        param += \" -preset p3\";\n                        break;\n\n                    case \"faster\":\n                        param += \" -preset p2\";\n                        break;\n\n                    case \"veryfast\":\n                    case \"superfast\":\n                    case \"ultrafast\":\n                        param += \" -preset p1\";\n                        break;\n\n                    default:\n                        param += \" -preset p1\";\n                        break;\n                }\n            }\n            else if (string.Equals(videoEncoder, \"h264_amf\", StringComparison.OrdinalIgnoreCase) // h264 (h264_amf)\n                     || string.Equals(videoEncoder, \"hevc_amf\", StringComparison.OrdinalIgnoreCase)) // hevc (hevc_amf)\n            {\n                switch (encodingOptions.EncoderPreset)\n                {\n                    case \"veryslow\":\n                    case \"slower\":\n                    case \"slow\":\n                        param += \" -quality quality\";\n                        break;\n\n                    case \"medium\":\n                        param += \" -quality balanced\";\n                        break;\n\n                    case \"fast\":\n                    case \"faster\":\n                    case \"veryfast\":\n                    case \"superfast\":\n                    case \"ultrafast\":\n                        param += \" -quality speed\";\n                        break;\n\n                    default:\n                        param += \" -quality speed\";\n                        break;\n                }\n\n                if (string.Equals(videoEncoder, \"hevc_amf\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -header_insertion_mode gop -gops_per_idr 1\";\n                }\n            }\n            else if (string.Equals(videoEncoder, \"libvpx\", StringComparison.OrdinalIgnoreCase)) // vp8\n            {\n                // Values 0-3, 0 being highest quality but slower\n                var profileScore = 0;\n\n                string crf;\n                var qmin = \"0\";\n                var qmax = \"50\";\n\n                crf = \"10\";\n\n                if (isVc1)\n                {\n                    profileScore++;\n                }\n\n                // Max of 2\n                profileScore = Math.Min(profileScore, 2);\n\n                // http://www.webmproject.org/docs/encoder-parameters/\n                param += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -speed 16 -quality good -profile:v {0} -slices 8 -crf {1} -qmin {2} -qmax {3}\",\n                    profileScore.ToString(CultureInfo.InvariantCulture),\n                    crf,\n                    qmin,\n                    qmax);\n            }\n            else if (string.Equals(videoEncoder, \"libvpx-vp9\", StringComparison.OrdinalIgnoreCase)) // vp9\n            {\n                // When `-deadline` is set to `good` or `best`, `-cpu-used` ranges from 0-5.\n                // When `-deadline` is set to `realtime`, `-cpu-used` ranges from 0-15.\n                // Resources:\n                //   * https://trac.ffmpeg.org/wiki/Encode/VP9\n                //   * https://superuser.com/questions/1586934\n                //   * https://developers.google.com/media/vp9\n                param += encodingOptions.EncoderPreset switch\n                {\n                    \"veryslow\" => \" -deadline best -cpu-used 0\",\n                    \"slower\" => \" -deadline best -cpu-used 2\",\n                    \"slow\" => \" -deadline best -cpu-used 3\",\n                    \"medium\" => \" -deadline good -cpu-used 0\",\n                    \"fast\" => \" -deadline good -cpu-used 1\",\n                    \"faster\" => \" -deadline good -cpu-used 2\",\n                    \"veryfast\" => \" -deadline good -cpu-used 3\",\n                    \"superfast\" => \" -deadline good -cpu-used 4\",\n                    \"ultrafast\" => \" -deadline good -cpu-used 5\",\n                    _ => \" -deadline good -cpu-used 1\"\n                };\n\n                // TODO: until VP9 gets its own CRF setting, base CRF on H.265.\n                int h265Crf = encodingOptions.H265Crf;\n                int defaultVp9Crf = 31;\n                if (h265Crf >= 0 && h265Crf <= 51)\n                {\n                    // This conversion factor is chosen to match the default CRF for H.265 to the\n                    // recommended 1080p CRF from Google. The factor also maps the logarithmic CRF\n                    // scale of x265 [0, 51] to that of VP9 [0, 63] relatively well.\n\n                    // Resources:\n                    //   * https://developers.google.com/media/vp9/settings/vod\n                    const float H265ToVp9CrfConversionFactor = 1.12F;\n\n                    var vp9Crf = Convert.ToInt32(h265Crf * H265ToVp9CrfConversionFactor);\n\n                    // Encoder allows for CRF values in the range [0, 63].\n                    vp9Crf = Math.Clamp(vp9Crf, 0, 63);\n\n                    param += FormattableString.Invariant($\" -crf {vp9Crf}\");\n                }\n                else\n                {\n                    param += FormattableString.Invariant($\" -crf {defaultVp9Crf}\");\n                }\n\n                param += \" -row-mt 1 -profile 1\";\n            }\n            else if (string.Equals(videoEncoder, \"mpeg4\", StringComparison.OrdinalIgnoreCase))\n            {\n                param += \" -mbd rd -flags +mv4+aic -trellis 2 -cmp 2 -subcmp 2 -bf 2\";\n            }\n            else if (string.Equals(videoEncoder, \"wmv2\", StringComparison.OrdinalIgnoreCase)) // asf/wmv\n            {\n                param += \" -qmin 2\";\n            }\n            else if (string.Equals(videoEncoder, \"msmpeg4\", StringComparison.OrdinalIgnoreCase))\n            {\n                param += \" -mbd 2\";\n            }\n\n            param += GetVideoBitrateParam(state, videoEncoder);\n\n            var framerate = GetFramerateParam(state);\n            if (framerate.HasValue)\n            {\n                param += string.Format(CultureInfo.InvariantCulture, \" -r {0}\", framerate.Value.ToString(CultureInfo.InvariantCulture));\n            }\n\n            var targetVideoCodec = state.ActualOutputVideoCodec;\n            if (string.Equals(targetVideoCodec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(targetVideoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase))\n            {\n                targetVideoCodec = \"hevc\";\n            }\n\n            var profile = state.GetRequestedProfiles(targetVideoCodec).FirstOrDefault() ?? string.Empty;\n            profile = Regex.Replace(profile, @\"\\s+\", string.Empty);\n\n            // We only transcode to HEVC 8-bit for now, force Main Profile.\n            if (profile.Contains(\"main10\", StringComparison.OrdinalIgnoreCase)\n                || profile.Contains(\"mainstill\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"main\";\n            }\n\n            // Extended Profile is not supported by any known h264 encoders, force Main Profile.\n            if (profile.Contains(\"extended\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"main\";\n            }\n\n            // Only libx264 support encoding H264 High 10 Profile, otherwise force High Profile.\n            if (!string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                && profile.Contains(\"high10\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"high\";\n            }\n\n            // h264_vaapi does not support Baseline profile, force Constrained Baseline in this case,\n            // which is compatible (and ugly).\n            if (string.Equals(videoEncoder, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase)\n                && profile.Contains(\"baseline\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"constrained_baseline\";\n            }\n\n            // libx264, h264_qsv and h264_nvenc does not support Constrained Baseline profile, force Baseline in this case.\n            if ((string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase))\n                && profile.Contains(\"baseline\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"baseline\";\n            }\n\n            // libx264, h264_qsv, h264_nvenc and h264_vaapi does not support Constrained High profile, force High in this case.\n            if ((string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase)\n                 || string.Equals(videoEncoder, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase))\n                && profile.Contains(\"high\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"high\";\n            }\n\n            if (string.Equals(videoEncoder, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                && profile.Contains(\"baseline\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"constrained_baseline\";\n            }\n\n            if (string.Equals(videoEncoder, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                && profile.Contains(\"constrainedhigh\", StringComparison.OrdinalIgnoreCase))\n            {\n                profile = \"constrained_high\";\n            }\n\n            if (!string.IsNullOrEmpty(profile))\n            {\n                if (!string.Equals(videoEncoder, \"h264_v4l2m2m\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -profile:v:0 \" + profile;\n                }\n            }\n\n            var level = state.GetRequestedLevel(targetVideoCodec);\n\n            if (!string.IsNullOrEmpty(level))\n            {\n                level = NormalizeTranscodingLevel(state, level);\n\n                // libx264, QSV, AMF can adjust the given level to match the output.\n                if (string.Equals(videoEncoder, \"h264_qsv\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -level \" + level;\n                }\n                else if (string.Equals(videoEncoder, \"hevc_qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    // hevc_qsv use -level 51 instead of -level 153.\n                    if (double.TryParse(level, NumberStyles.Any, CultureInfo.InvariantCulture, out double hevcLevel))\n                    {\n                        param += \" -level \" + (hevcLevel / 3);\n                    }\n                }\n                else if (string.Equals(videoEncoder, \"h264_amf\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoEncoder, \"hevc_amf\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -level \" + level;\n                }\n                else if (string.Equals(videoEncoder, \"h264_nvenc\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoEncoder, \"hevc_nvenc\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoEncoder, \"h264_vaapi\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoEncoder, \"hevc_vaapi\", StringComparison.OrdinalIgnoreCase))\n                {\n                    // level option may cause NVENC to fail.\n                    // NVENC cannot adjust the given level, just throw an error.\n                    // level option may cause corrupted frames on AMD VAAPI.\n                }\n                else if (!string.Equals(videoEncoder, \"libx265\", StringComparison.OrdinalIgnoreCase))\n                {\n                    param += \" -level \" + level;\n                }\n            }\n\n            if (string.Equals(videoEncoder, \"libx264\", StringComparison.OrdinalIgnoreCase))\n            {\n                param += \" -x264opts:0 subme=0:me_range=4:rc_lookahead=10:me=dia:no_chroma_me:8x8dct=0:partitions=none\";\n            }\n\n            if (string.Equals(videoEncoder, \"libx265\", StringComparison.OrdinalIgnoreCase))\n            {\n                // libx265 only accept level option in -x265-params.\n                // level option may cause libx265 to fail.\n                // libx265 cannot adjust the given level, just throw an error.\n                // TODO: set fine tuned params.\n                param += \" -x265-params:0 no-info=1\";\n            }\n\n            return param;\n        }\n\n        public bool CanStreamCopyVideo(EncodingJobInfo state, MediaStream videoStream)\n        {\n            var request = state.BaseRequest;\n\n            if (!request.AllowVideoStreamCopy)\n            {\n                return false;\n            }\n\n            if (videoStream.IsInterlaced\n                && state.DeInterlace(videoStream.Codec, false))\n            {\n                return false;\n            }\n\n            if (videoStream.IsAnamorphic ?? false)\n            {\n                if (request.RequireNonAnamorphic)\n                {\n                    return false;\n                }\n            }\n\n            // Can't stream copy if we're burning in subtitles\n            if (request.SubtitleStreamIndex.HasValue\n                && request.SubtitleStreamIndex.Value >= 0\n                && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode)\n            {\n                return false;\n            }\n\n            if (string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                && videoStream.IsAVC.HasValue\n                && !videoStream.IsAVC.Value\n                && request.RequireAvc)\n            {\n                return false;\n            }\n\n            // Source and target codecs must match\n            if (string.IsNullOrEmpty(videoStream.Codec)\n                || (state.SupportedVideoCodecs.Length != 0\n                    && !state.SupportedVideoCodecs.Contains(videoStream.Codec, StringComparison.OrdinalIgnoreCase)))\n            {\n                return false;\n            }\n\n            var requestedProfiles = state.GetRequestedProfiles(videoStream.Codec);\n\n            // If client is requesting a specific video profile, it must match the source\n            if (requestedProfiles.Length > 0)\n            {\n                if (string.IsNullOrEmpty(videoStream.Profile))\n                {\n                    // return false;\n                }\n\n                var requestedProfile = requestedProfiles[0];\n                // strip spaces because they may be stripped out on the query string as well\n                if (!string.IsNullOrEmpty(videoStream.Profile)\n                    && !requestedProfiles.Contains(videoStream.Profile.Replace(\" \", string.Empty, StringComparison.Ordinal), StringComparison.OrdinalIgnoreCase))\n                {\n                    var currentScore = GetVideoProfileScore(videoStream.Codec, videoStream.Profile);\n                    var requestedScore = GetVideoProfileScore(videoStream.Codec, requestedProfile);\n\n                    if (currentScore == -1 || currentScore > requestedScore)\n                    {\n                        return false;\n                    }\n                }\n            }\n\n            var requestedRangeTypes = state.GetRequestedRangeTypes(videoStream.Codec);\n            if (requestedRangeTypes.Length > 0)\n            {\n                if (string.IsNullOrEmpty(videoStream.VideoRangeType))\n                {\n                    return false;\n                }\n\n                if (!requestedRangeTypes.Contains(videoStream.VideoRangeType, StringComparison.OrdinalIgnoreCase))\n                {\n                    return false;\n                }\n            }\n\n            // Video width must fall within requested value\n            if (request.MaxWidth.HasValue\n                && (!videoStream.Width.HasValue || videoStream.Width.Value > request.MaxWidth.Value))\n            {\n                return false;\n            }\n\n            // Video height must fall within requested value\n            if (request.MaxHeight.HasValue\n                && (!videoStream.Height.HasValue || videoStream.Height.Value > request.MaxHeight.Value))\n            {\n                return false;\n            }\n\n            // Video framerate must fall within requested value\n            var requestedFramerate = request.MaxFramerate ?? request.Framerate;\n            if (requestedFramerate.HasValue)\n            {\n                var videoFrameRate = videoStream.AverageFrameRate ?? videoStream.RealFrameRate;\n\n                if (!videoFrameRate.HasValue || videoFrameRate.Value > requestedFramerate.Value)\n                {\n                    return false;\n                }\n            }\n\n            // Video bitrate must fall within requested value\n            if (request.VideoBitRate.HasValue\n                && (!videoStream.BitRate.HasValue || videoStream.BitRate.Value > request.VideoBitRate.Value))\n            {\n                return false;\n            }\n\n            var maxBitDepth = state.GetRequestedVideoBitDepth(videoStream.Codec);\n            if (maxBitDepth.HasValue)\n            {\n                if (videoStream.BitDepth.HasValue && videoStream.BitDepth.Value > maxBitDepth.Value)\n                {\n                    return false;\n                }\n            }\n\n            var maxRefFrames = state.GetRequestedMaxRefFrames(videoStream.Codec);\n            if (maxRefFrames.HasValue\n                && videoStream.RefFrames.HasValue && videoStream.RefFrames.Value > maxRefFrames.Value)\n            {\n                return false;\n            }\n\n            // If a specific level was requested, the source must match or be less than\n            var level = state.GetRequestedLevel(videoStream.Codec);\n            if (!string.IsNullOrEmpty(level)\n                && double.TryParse(level, NumberStyles.Any, CultureInfo.InvariantCulture, out var requestLevel))\n            {\n                if (!videoStream.Level.HasValue)\n                {\n                    // return false;\n                }\n\n                if (videoStream.Level.HasValue && videoStream.Level.Value > requestLevel)\n                {\n                    return false;\n                }\n            }\n\n            if (string.Equals(state.InputContainer, \"avi\", StringComparison.OrdinalIgnoreCase)\n                && string.Equals(videoStream.Codec, \"h264\", StringComparison.OrdinalIgnoreCase)\n                && !(videoStream.IsAVC ?? false))\n            {\n                // see Coach S01E01 - Kelly and the Professor(0).avi\n                return false;\n            }\n\n            return true;\n        }\n\n        public bool CanStreamCopyAudio(EncodingJobInfo state, MediaStream audioStream, IEnumerable<string> supportedAudioCodecs)\n        {\n            var request = state.BaseRequest;\n\n            if (!request.AllowAudioStreamCopy)\n            {\n                return false;\n            }\n\n            var maxBitDepth = state.GetRequestedAudioBitDepth(audioStream.Codec);\n            if (maxBitDepth.HasValue\n                && audioStream.BitDepth.HasValue\n                && audioStream.BitDepth.Value > maxBitDepth.Value)\n            {\n                return false;\n            }\n\n            // Source and target codecs must match\n            if (string.IsNullOrEmpty(audioStream.Codec)\n                || !supportedAudioCodecs.Contains(audioStream.Codec, StringComparison.OrdinalIgnoreCase))\n            {\n                return false;\n            }\n\n            // Channels must fall within requested value\n            var channels = state.GetRequestedAudioChannels(audioStream.Codec);\n            if (channels.HasValue)\n            {\n                if (!audioStream.Channels.HasValue || audioStream.Channels.Value <= 0)\n                {\n                    return false;\n                }\n\n                if (audioStream.Channels.Value > channels.Value)\n                {\n                    return false;\n                }\n            }\n\n            // Sample rate must fall within requested value\n            if (request.AudioSampleRate.HasValue)\n            {\n                if (!audioStream.SampleRate.HasValue || audioStream.SampleRate.Value <= 0)\n                {\n                    return false;\n                }\n\n                if (audioStream.SampleRate.Value > request.AudioSampleRate.Value)\n                {\n                    return false;\n                }\n            }\n\n            // Audio bitrate must fall within requested value\n            if (request.AudioBitRate.HasValue\n                && audioStream.BitRate.HasValue\n                && audioStream.BitRate.Value > request.AudioBitRate.Value)\n            {\n                return false;\n            }\n\n            return request.EnableAutoStreamCopy;\n        }\n\n        public int GetVideoBitrateParamValue(BaseEncodingJobOptions request, MediaStream videoStream, string outputVideoCodec)\n        {\n            var bitrate = request.VideoBitRate;\n\n            if (videoStream != null)\n            {\n                var isUpscaling = request.Height.HasValue\n                    && videoStream.Height.HasValue\n                    && request.Height.Value > videoStream.Height.Value\n                    && request.Width.HasValue\n                    && videoStream.Width.HasValue\n                    && request.Width.Value > videoStream.Width.Value;\n\n                // Don't allow bitrate increases unless upscaling\n                if (!isUpscaling && bitrate.HasValue && videoStream.BitRate.HasValue)\n                {\n                    bitrate = GetMinBitrate(videoStream.BitRate.Value, bitrate.Value);\n                }\n\n                if (bitrate.HasValue)\n                {\n                    var inputVideoCodec = videoStream.Codec;\n                    bitrate = ScaleBitrate(bitrate.Value, inputVideoCodec, outputVideoCodec);\n\n                    // If a max bitrate was requested, don't let the scaled bitrate exceed it\n                    if (request.VideoBitRate.HasValue)\n                    {\n                        bitrate = Math.Min(bitrate.Value, request.VideoBitRate.Value);\n                    }\n                }\n            }\n\n            // Cap the max target bitrate to intMax/2 to satisify the bufsize=bitrate*2.\n            return Math.Min(bitrate ?? 0, int.MaxValue / 2);\n        }\n\n        private int GetMinBitrate(int sourceBitrate, int requestedBitrate)\n        {\n            // these values were chosen from testing to improve low bitrate streams\n            if (sourceBitrate <= 2000000)\n            {\n                sourceBitrate = Convert.ToInt32(sourceBitrate * 2.5);\n            }\n            else if (sourceBitrate <= 3000000)\n            {\n                sourceBitrate *= 2;\n            }\n\n            var bitrate = Math.Min(sourceBitrate, requestedBitrate);\n\n            return bitrate;\n        }\n\n        private static double GetVideoBitrateScaleFactor(string codec)\n        {\n            // hevc & vp9 - 40% more efficient than h.264\n            if (string.Equals(codec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(codec, \"vp9\", StringComparison.OrdinalIgnoreCase))\n            {\n                return .6;\n            }\n\n            // av1 - 50% more efficient than h.264\n            if (string.Equals(codec, \"av1\", StringComparison.OrdinalIgnoreCase))\n            {\n                return .5;\n            }\n\n            return 1;\n        }\n\n        private static int ScaleBitrate(int bitrate, string inputVideoCodec, string outputVideoCodec)\n        {\n            var inputScaleFactor = GetVideoBitrateScaleFactor(inputVideoCodec);\n            var outputScaleFactor = GetVideoBitrateScaleFactor(outputVideoCodec);\n\n            // Don't scale the real bitrate lower than the requested bitrate\n            var scaleFactor = Math.Max(outputScaleFactor / inputScaleFactor, 1);\n\n            if (bitrate <= 500000)\n            {\n                scaleFactor = Math.Max(scaleFactor, 4);\n            }\n            else if (bitrate <= 1000000)\n            {\n                scaleFactor = Math.Max(scaleFactor, 3);\n            }\n            else if (bitrate <= 2000000)\n            {\n                scaleFactor = Math.Max(scaleFactor, 2.5);\n            }\n            else if (bitrate <= 3000000)\n            {\n                scaleFactor = Math.Max(scaleFactor, 2);\n            }\n\n            return Convert.ToInt32(scaleFactor * bitrate);\n        }\n\n        public int? GetAudioBitrateParam(BaseEncodingJobOptions request, MediaStream audioStream, int? outputAudioChannels)\n        {\n            return GetAudioBitrateParam(request.AudioBitRate, request.AudioCodec, audioStream, outputAudioChannels);\n        }\n\n        public int? GetAudioBitrateParam(int? audioBitRate, string audioCodec, MediaStream audioStream, int? outputAudioChannels)\n        {\n            if (audioStream == null)\n            {\n                return null;\n            }\n\n            var inputChannels = audioStream.Channels ?? 0;\n            var outputChannels = outputAudioChannels ?? 0;\n            var bitrate = audioBitRate ?? int.MaxValue;\n\n            if (string.IsNullOrEmpty(audioCodec)\n                || string.Equals(audioCodec, \"aac\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"mp3\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"opus\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"vorbis\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"ac3\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"eac3\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (inputChannels, outputChannels) switch\n                {\n                    (>= 6, >= 6 or 0) => Math.Min(640000, bitrate),\n                    (> 0, > 0) => Math.Min(outputChannels * 128000, bitrate),\n                    (> 0, _) => Math.Min(inputChannels * 128000, bitrate),\n                    (_, _) => Math.Min(384000, bitrate)\n                };\n            }\n\n            if (string.Equals(audioCodec, \"dts\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(audioCodec, \"dca\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (inputChannels, outputChannels) switch\n                {\n                    (>= 6, >= 6 or 0) => Math.Min(768000, bitrate),\n                    (> 0, > 0) => Math.Min(outputChannels * 136000, bitrate),\n                    (> 0, _) => Math.Min(inputChannels * 136000, bitrate),\n                    (_, _) => Math.Min(672000, bitrate)\n                };\n            }\n\n            // Empty bitrate area is not allow on iOS\n            // Default audio bitrate to 128K per channel if we don't have codec specific defaults\n            // https://ffmpeg.org/ffmpeg-codecs.html#toc-Codec-Options\n            return 128000 * (outputAudioChannels ?? audioStream.Channels ?? 2);\n        }\n\n        public string GetAudioFilterParam(EncodingJobInfo state, EncodingOptions encodingOptions)\n        {\n            var channels = state.OutputAudioChannels;\n\n            var filters = new List<string>();\n\n            // Boost volume to 200% when downsampling from 6ch to 2ch\n            if (channels.HasValue\n                && channels.Value <= 2\n                && state.AudioStream != null\n                && state.AudioStream.Channels.HasValue\n                && state.AudioStream.Channels.Value > 5\n                && !encodingOptions.DownMixAudioBoost.Equals(1))\n            {\n                filters.Add(\"volume=\" + encodingOptions.DownMixAudioBoost.ToString(CultureInfo.InvariantCulture));\n            }\n\n            var isCopyingTimestamps = state.CopyTimestamps || state.TranscodingType != TranscodingJobType.Progressive;\n            if (state.SubtitleStream != null && state.SubtitleStream.IsTextSubtitleStream && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode && !isCopyingTimestamps)\n            {\n                var seconds = TimeSpan.FromTicks(state.StartTimeTicks ?? 0).TotalSeconds;\n\n                filters.Add(\n                    string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"asetpts=PTS-{0}/TB\",\n                        Math.Round(seconds)));\n            }\n\n            if (filters.Count > 0)\n            {\n                return \" -af \\\"\" + string.Join(',', filters) + \"\\\"\";\n            }\n\n            return string.Empty;\n        }\n\n        /// <summary>\n        /// Gets the number of audio channels to specify on the command line.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <param name=\"audioStream\">The audio stream.</param>\n        /// <param name=\"outputAudioCodec\">The output audio codec.</param>\n        /// <returns>System.Nullable{System.Int32}.</returns>\n        public int? GetNumAudioChannelsParam(EncodingJobInfo state, MediaStream audioStream, string outputAudioCodec)\n        {\n            if (audioStream == null)\n            {\n                return null;\n            }\n\n            var request = state.BaseRequest;\n\n            var inputChannels = audioStream.Channels;\n\n            if (inputChannels <= 0)\n            {\n                inputChannels = null;\n            }\n\n            var codec = outputAudioCodec ?? string.Empty;\n\n            int? transcoderChannelLimit;\n            if (codec.IndexOf(\"wma\", StringComparison.OrdinalIgnoreCase) != -1)\n            {\n                // wmav2 currently only supports two channel output\n                transcoderChannelLimit = 2;\n            }\n            else if (codec.IndexOf(\"mp3\", StringComparison.OrdinalIgnoreCase) != -1)\n            {\n                // libmp3lame currently only supports two channel output\n                transcoderChannelLimit = 2;\n            }\n            else if (codec.IndexOf(\"aac\", StringComparison.OrdinalIgnoreCase) != -1)\n            {\n                // aac is able to handle 8ch(7.1 layout)\n                transcoderChannelLimit = 8;\n            }\n            else\n            {\n                // If we don't have any media info then limit it to 6 to prevent encoding errors due to asking for too many channels\n                transcoderChannelLimit = 6;\n            }\n\n            var isTranscodingAudio = !IsCopyCodec(codec);\n\n            int? resultChannels = state.GetRequestedAudioChannels(codec);\n            if (isTranscodingAudio)\n            {\n                resultChannels = GetMinValue(request.TranscodingMaxAudioChannels, resultChannels);\n            }\n\n            if (inputChannels.HasValue)\n            {\n                resultChannels = resultChannels.HasValue\n                    ? Math.Min(resultChannels.Value, inputChannels.Value)\n                    : inputChannels.Value;\n            }\n\n            if (isTranscodingAudio && transcoderChannelLimit.HasValue)\n            {\n                resultChannels = resultChannels.HasValue\n                    ? Math.Min(resultChannels.Value, transcoderChannelLimit.Value)\n                    : transcoderChannelLimit.Value;\n            }\n\n            // Avoid transcoding to audio channels other than 1ch, 2ch, 6ch (5.1 layout) and 8ch (7.1 layout).\n            // https://developer.apple.com/documentation/http_live_streaming/hls_authoring_specification_for_apple_devices\n            if (isTranscodingAudio\n                && state.TranscodingType != TranscodingJobType.Progressive\n                && resultChannels.HasValue\n                && ((resultChannels.Value > 2 && resultChannels.Value < 6) || resultChannels.Value == 7))\n            {\n                resultChannels = 2;\n            }\n\n            return resultChannels;\n        }\n\n        private int? GetMinValue(int? val1, int? val2)\n        {\n            if (!val1.HasValue)\n            {\n                return val2;\n            }\n\n            if (!val2.HasValue)\n            {\n                return val1;\n            }\n\n            return Math.Min(val1.Value, val2.Value);\n        }\n\n        /// <summary>\n        /// Enforces the resolution limit.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        public void EnforceResolutionLimit(EncodingJobInfo state)\n        {\n            var videoRequest = state.BaseRequest;\n\n            // Switch the incoming params to be ceilings rather than fixed values\n            videoRequest.MaxWidth = videoRequest.MaxWidth ?? videoRequest.Width;\n            videoRequest.MaxHeight = videoRequest.MaxHeight ?? videoRequest.Height;\n\n            videoRequest.Width = null;\n            videoRequest.Height = null;\n        }\n\n        /// <summary>\n        /// Gets the fast seek command line parameter.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <param name=\"options\">The options.</param>\n        /// <param name=\"segmentContainer\">Segment Container.</param>\n        /// <returns>System.String.</returns>\n        /// <value>The fast seek command line parameter.</value>\n        public string GetFastSeekCommandLineParameter(EncodingJobInfo state, EncodingOptions options, string segmentContainer)\n        {\n            var time = state.BaseRequest.StartTimeTicks ?? 0;\n            var seekParam = string.Empty;\n\n            if (time > 0)\n            {\n                seekParam += string.Format(CultureInfo.InvariantCulture, \"-ss {0}\", _mediaEncoder.GetTimeParameter(time));\n\n                if (state.IsVideoRequest)\n                {\n                    var outputVideoCodec = GetVideoEncoder(state, options);\n                    var segmentFormat = GetSegmentFileExtension(segmentContainer).TrimStart('.');\n\n                    // Important: If this is ever re-enabled, make sure not to use it with wtv because it breaks seeking\n                    // Disable -noaccurate_seek on mpegts container due to the timestamps issue on some clients,\n                    // but it's still required for fMP4 container otherwise the audio can't be synced to the video.\n                    if (!string.Equals(state.InputContainer, \"wtv\", StringComparison.OrdinalIgnoreCase)\n                        && !string.Equals(segmentFormat, \"ts\", StringComparison.OrdinalIgnoreCase)\n                        && state.TranscodingType != TranscodingJobType.Progressive\n                        && !state.EnableBreakOnNonKeyFrames(outputVideoCodec)\n                        && (state.BaseRequest.StartTimeTicks ?? 0) > 0)\n                    {\n                        seekParam += \" -noaccurate_seek\";\n                    }\n                }\n            }\n\n            return seekParam;\n        }\n\n        /// <summary>\n        /// Gets the map args.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <returns>System.String.</returns>\n        public string GetMapArgs(EncodingJobInfo state)\n        {\n            // If we don't have known media info\n            // If input is video, use -sn to drop subtitles\n            // Otherwise just return empty\n            if (state.VideoStream == null && state.AudioStream == null)\n            {\n                return state.IsInputVideo ? \"-sn\" : string.Empty;\n            }\n\n            // We have media info, but we don't know the stream index\n            if (state.VideoStream != null && state.VideoStream.Index == -1)\n            {\n                return \"-sn\";\n            }\n\n            // We have media info, but we don't know the stream index\n            if (state.AudioStream != null && state.AudioStream.Index == -1)\n            {\n                return state.IsInputVideo ? \"-sn\" : string.Empty;\n            }\n\n            var args = string.Empty;\n\n            if (state.VideoStream != null)\n            {\n                int videoStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.VideoStream);\n\n                args += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"-map 0:{0}\",\n                    videoStreamIndex);\n            }\n            else\n            {\n                // No known video stream\n                args += \"-vn\";\n            }\n\n            if (state.AudioStream != null)\n            {\n                int audioStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.AudioStream);\n                if (state.AudioStream.IsExternal)\n                {\n                    bool hasExternalGraphicsSubs = state.SubtitleStream != null\n                        && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode\n                        && state.SubtitleStream.IsExternal\n                        && !state.SubtitleStream.IsTextSubtitleStream;\n                    int externalAudioMapIndex = hasExternalGraphicsSubs ? 2 : 1;\n\n                    args += string.Format(\n                        CultureInfo.InvariantCulture,\n                        \" -map {0}:{1}\",\n                        externalAudioMapIndex,\n                        audioStreamIndex);\n                }\n                else\n                {\n                    args += string.Format(\n                        CultureInfo.InvariantCulture,\n                        \" -map 0:{0}\",\n                        audioStreamIndex);\n                }\n            }\n            else\n            {\n                args += \" -map -0:a\";\n            }\n\n            var subtitleMethod = state.SubtitleDeliveryMethod;\n            if (state.SubtitleStream == null || subtitleMethod == SubtitleDeliveryMethod.Hls)\n            {\n                args += \" -map -0:s\";\n            }\n            else if (subtitleMethod == SubtitleDeliveryMethod.Embed)\n            {\n                int subtitleStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.SubtitleStream);\n\n                args += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -map 0:{0}\",\n                    subtitleStreamIndex);\n            }\n            else if (state.SubtitleStream.IsExternal && !state.SubtitleStream.IsTextSubtitleStream)\n            {\n                int externalSubtitleStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.SubtitleStream);\n\n                args += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -map 1:{0} -sn\",\n                    externalSubtitleStreamIndex);\n            }\n\n            return args;\n        }\n\n        /// <summary>\n        /// Gets the negative map args by filters.\n        /// </summary>\n        /// <param name=\"state\">The state.</param>\n        /// <param name=\"videoProcessFilters\">The videoProcessFilters.</param>\n        /// <returns>System.String.</returns>\n        public string GetNegativeMapArgsByFilters(EncodingJobInfo state, string videoProcessFilters)\n        {\n            string args = string.Empty;\n\n            // http://ffmpeg.org/ffmpeg-all.html#toc-Complex-filtergraphs-1\n            if (state.VideoStream != null && videoProcessFilters.Contains(\"-filter_complex\", StringComparison.Ordinal))\n            {\n                int videoStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.VideoStream);\n\n                args += string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"-map -0:{0} \",\n                    videoStreamIndex);\n            }\n\n            return args;\n        }\n\n        /// <summary>\n        /// Determines which stream will be used for playback.\n        /// </summary>\n        /// <param name=\"allStream\">All stream.</param>\n        /// <param name=\"desiredIndex\">Index of the desired.</param>\n        /// <param name=\"type\">The type.</param>\n        /// <param name=\"returnFirstIfNoIndex\">if set to <c>true</c> [return first if no index].</param>\n        /// <returns>MediaStream.</returns>\n        public MediaStream GetMediaStream(IEnumerable<MediaStream> allStream, int? desiredIndex, MediaStreamType type, bool returnFirstIfNoIndex = true)\n        {\n            var streams = allStream.Where(s => s.Type == type).OrderBy(i => i.Index).ToList();\n\n            if (desiredIndex.HasValue)\n            {\n                var stream = streams.FirstOrDefault(s => s.Index == desiredIndex.Value);\n\n                if (stream != null)\n                {\n                    return stream;\n                }\n            }\n\n            if (returnFirstIfNoIndex && type == MediaStreamType.Audio)\n            {\n                return streams.FirstOrDefault(i => i.Channels.HasValue && i.Channels.Value > 0) ??\n                       streams.FirstOrDefault();\n            }\n\n            // Just return the first one\n            return returnFirstIfNoIndex ? streams.FirstOrDefault() : null;\n        }\n\n        public static (int? Width, int? Height) GetFixedOutputSize(\n            int? videoWidth,\n            int? videoHeight,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight)\n        {\n            if (!videoWidth.HasValue && !requestedWidth.HasValue)\n            {\n                return (null, null);\n            }\n\n            if (!videoHeight.HasValue && !requestedHeight.HasValue)\n            {\n                return (null, null);\n            }\n\n            int inputWidth = Convert.ToInt32(videoWidth ?? requestedWidth, CultureInfo.InvariantCulture);\n            int inputHeight = Convert.ToInt32(videoHeight ?? requestedHeight, CultureInfo.InvariantCulture);\n            int outputWidth = requestedWidth ?? inputWidth;\n            int outputHeight = requestedHeight ?? inputHeight;\n\n            // Don't transcode video to bigger than 4k when using HW.\n            int maximumWidth = Math.Min(requestedMaxWidth ?? outputWidth, 4096);\n            int maximumHeight = Math.Min(requestedMaxHeight ?? outputHeight, 4096);\n\n            if (outputWidth > maximumWidth || outputHeight > maximumHeight)\n            {\n                var scaleW = (double)maximumWidth / (double)outputWidth;\n                var scaleH = (double)maximumHeight / (double)outputHeight;\n                var scale = Math.Min(scaleW, scaleH);\n                outputWidth = Math.Min(maximumWidth, (int)(outputWidth * scale));\n                outputHeight = Math.Min(maximumHeight, (int)(outputHeight * scale));\n            }\n\n            outputWidth = 2 * (outputWidth / 2);\n            outputHeight = 2 * (outputHeight / 2);\n\n            return (outputWidth, outputHeight);\n        }\n\n        public static string GetHwScaleFilter(\n            string hwScaleSuffix,\n            string videoFormat,\n            int? videoWidth,\n            int? videoHeight,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight)\n        {\n            var (outWidth, outHeight) = GetFixedOutputSize(\n                videoWidth,\n                videoHeight,\n                requestedWidth,\n                requestedHeight,\n                requestedMaxWidth,\n                requestedMaxHeight);\n\n            var isFormatFixed = !string.IsNullOrEmpty(videoFormat);\n            var isSizeFixed = !videoWidth.HasValue\n                || outWidth.Value != videoWidth.Value\n                || !videoHeight.HasValue\n                || outHeight.Value != videoHeight.Value;\n\n            var arg1 = isSizeFixed ? (\"=w=\" + outWidth.Value + \":h=\" + outHeight.Value) : string.Empty;\n            var arg2 = isFormatFixed ? (\"format=\" + videoFormat) : string.Empty;\n            if (isFormatFixed)\n            {\n                arg2 = (isSizeFixed ? ':' : '=') + arg2;\n            }\n\n            if (!string.IsNullOrEmpty(hwScaleSuffix) && (isSizeFixed || isFormatFixed))\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"scale_{0}{1}{2}\",\n                    hwScaleSuffix,\n                    arg1,\n                    arg2);\n            }\n\n            return string.Empty;\n        }\n\n        public static string GetCustomSwScaleFilter(\n            int? videoWidth,\n            int? videoHeight,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight)\n        {\n            var (outWidth, outHeight) = GetFixedOutputSize(\n                videoWidth,\n                videoHeight,\n                requestedWidth,\n                requestedHeight,\n                requestedMaxWidth,\n                requestedMaxHeight);\n\n            if (outWidth.HasValue && outHeight.HasValue)\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"scale=s={0}x{1}:flags=fast_bilinear\",\n                    outWidth.Value,\n                    outHeight.Value);\n            }\n\n            return string.Empty;\n        }\n\n        public static string GetAlphaSrcFilter(\n            EncodingJobInfo state,\n            int? videoWidth,\n            int? videoHeight,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight,\n            int? framerate)\n        {\n            var reqTicks = state.BaseRequest.StartTimeTicks ?? 0;\n            var startTime = TimeSpan.FromTicks(reqTicks).ToString(@\"hh\\\\\\:mm\\\\\\:ss\\\\\\.fff\", CultureInfo.InvariantCulture);\n            var (outWidth, outHeight) = GetFixedOutputSize(\n                videoWidth,\n                videoHeight,\n                requestedWidth,\n                requestedHeight,\n                requestedMaxWidth,\n                requestedMaxHeight);\n\n            if (outWidth.HasValue && outHeight.HasValue)\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"alphasrc=s={0}x{1}:r={2}:start='{3}'\",\n                    outWidth.Value,\n                    outHeight.Value,\n                    framerate ?? 10,\n                    reqTicks > 0 ? startTime : 0);\n            }\n\n            return string.Empty;\n        }\n\n        public static string GetSwScaleFilter(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string videoEncoder,\n            int? videoWidth,\n            int? videoHeight,\n            Video3DFormat? threedFormat,\n            int? requestedWidth,\n            int? requestedHeight,\n            int? requestedMaxWidth,\n            int? requestedMaxHeight)\n        {\n            var isV4l2 = string.Equals(videoEncoder, \"h264_v4l2m2m\", StringComparison.OrdinalIgnoreCase);\n            var scaleVal = isV4l2 ? 64 : 2;\n\n            // If fixed dimensions were supplied\n            if (requestedWidth.HasValue && requestedHeight.HasValue)\n            {\n                if (isV4l2)\n                {\n                    var widthParam = requestedWidth.Value.ToString(CultureInfo.InvariantCulture);\n                    var heightParam = requestedHeight.Value.ToString(CultureInfo.InvariantCulture);\n\n                    return string.Format(\n                            CultureInfo.InvariantCulture,\n                            \"scale=trunc({0}/64)*64:trunc({1}/2)*2\",\n                            widthParam,\n                            heightParam);\n                }\n                else\n                {\n                    return GetFixedSwScaleFilter(threedFormat, requestedWidth.Value, requestedHeight.Value);\n                }\n            }\n\n            // If Max dimensions were supplied, for width selects lowest even number between input width and width req size and selects lowest even number from in width*display aspect and requested size\n            else if (requestedMaxWidth.HasValue && requestedMaxHeight.HasValue)\n            {\n                var maxWidthParam = requestedMaxWidth.Value.ToString(CultureInfo.InvariantCulture);\n                var maxHeightParam = requestedMaxHeight.Value.ToString(CultureInfo.InvariantCulture);\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"scale=trunc(min(max(iw\\\\,ih*a)\\\\,min({0}\\\\,{1}*a))/{2})*{2}:trunc(min(max(iw/a\\\\,ih)\\\\,min({0}/a\\\\,{1}))/2)*2\",\n                        maxWidthParam,\n                        maxHeightParam,\n                        scaleVal);\n            }\n\n            // If a fixed width was requested\n            else if (requestedWidth.HasValue)\n            {\n                if (threedFormat.HasValue)\n                {\n                    // This method can handle 0 being passed in for the requested height\n                    return GetFixedSwScaleFilter(threedFormat, requestedWidth.Value, 0);\n                }\n                else\n                {\n                    var widthParam = requestedWidth.Value.ToString(CultureInfo.InvariantCulture);\n\n                    return string.Format(\n                            CultureInfo.InvariantCulture,\n                            \"scale={0}:trunc(ow/a/2)*2\",\n                            widthParam);\n                }\n            }\n\n            // If a fixed height was requested\n            else if (requestedHeight.HasValue)\n            {\n                var heightParam = requestedHeight.Value.ToString(CultureInfo.InvariantCulture);\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"scale=trunc(oh*a/{1})*{1}:{0}\",\n                        heightParam,\n                        scaleVal);\n            }\n\n            // If a max width was requested\n            else if (requestedMaxWidth.HasValue)\n            {\n                var maxWidthParam = requestedMaxWidth.Value.ToString(CultureInfo.InvariantCulture);\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"scale=trunc(min(max(iw\\\\,ih*a)\\\\,{0})/{1})*{1}:trunc(ow/a/2)*2\",\n                        maxWidthParam,\n                        scaleVal);\n            }\n\n            // If a max height was requested\n            else if (requestedMaxHeight.HasValue)\n            {\n                var maxHeightParam = requestedMaxHeight.Value.ToString(CultureInfo.InvariantCulture);\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"scale=trunc(oh*a/{1})*{1}:min(max(iw/a\\\\,ih)\\\\,{0})\",\n                        maxHeightParam,\n                        scaleVal);\n            }\n\n            return string.Empty;\n        }\n\n        private static string GetFixedSwScaleFilter(Video3DFormat? threedFormat, int requestedWidth, int requestedHeight)\n        {\n            var widthParam = requestedWidth.ToString(CultureInfo.InvariantCulture);\n            var heightParam = requestedHeight.ToString(CultureInfo.InvariantCulture);\n\n            string filter = null;\n\n            if (threedFormat.HasValue)\n            {\n                switch (threedFormat.Value)\n                {\n                    case Video3DFormat.HalfSideBySide:\n                        filter = \"crop=iw/2:ih:0:0,scale=(iw*2):ih,setdar=dar=a,crop=min(iw\\\\,ih*dar):min(ih\\\\,iw/dar):(iw-min(iw\\\\,iw*sar))/2:(ih - min (ih\\\\,ih/sar))/2,setsar=sar=1,scale={0}:trunc({0}/dar/2)*2\";\n                        // hsbs crop width in half,scale to correct size, set the display aspect,crop out any black bars we may have made the scale width to requestedWidth. Work out the correct height based on the display aspect it will maintain the aspect where -1 in this case (3d) may not.\n                        break;\n                    case Video3DFormat.FullSideBySide:\n                        filter = \"crop=iw/2:ih:0:0,setdar=dar=a,crop=min(iw\\\\,ih*dar):min(ih\\\\,iw/dar):(iw-min(iw\\\\,iw*sar))/2:(ih - min (ih\\\\,ih/sar))/2,setsar=sar=1,scale={0}:trunc({0}/dar/2)*2\";\n                        // fsbs crop width in half,set the display aspect,crop out any black bars we may have made the scale width to requestedWidth.\n                        break;\n                    case Video3DFormat.HalfTopAndBottom:\n                        filter = \"crop=iw:ih/2:0:0,scale=(iw*2):ih),setdar=dar=a,crop=min(iw\\\\,ih*dar):min(ih\\\\,iw/dar):(iw-min(iw\\\\,iw*sar))/2:(ih - min (ih\\\\,ih/sar))/2,setsar=sar=1,scale={0}:trunc({0}/dar/2)*2\";\n                        // htab crop height in half,scale to correct size, set the display aspect,crop out any black bars we may have made the scale width to requestedWidth\n                        break;\n                    case Video3DFormat.FullTopAndBottom:\n                        filter = \"crop=iw:ih/2:0:0,setdar=dar=a,crop=min(iw\\\\,ih*dar):min(ih\\\\,iw/dar):(iw-min(iw\\\\,iw*sar))/2:(ih - min (ih\\\\,ih/sar))/2,setsar=sar=1,scale={0}:trunc({0}/dar/2)*2\";\n                        // ftab crop height in half, set the display aspect,crop out any black bars we may have made the scale width to requestedWidth\n                        break;\n                    default:\n                        break;\n                }\n            }\n\n            // default\n            if (filter == null)\n            {\n                if (requestedHeight > 0)\n                {\n                    filter = \"scale=trunc({0}/2)*2:trunc({1}/2)*2\";\n                }\n                else\n                {\n                    filter = \"scale={0}:trunc({0}/a/2)*2\";\n                }\n            }\n\n            return string.Format(CultureInfo.InvariantCulture, filter, widthParam, heightParam);\n        }\n\n        public static string GetSwDeinterlaceFilter(EncodingJobInfo state, EncodingOptions options)\n        {\n            var doubleRateDeint = options.DeinterlaceDoubleRate && state.VideoStream?.AverageFrameRate <= 30;\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"{0}={1}:-1:0\",\n                string.Equals(options.DeinterlaceMethod, \"bwdif\", StringComparison.OrdinalIgnoreCase) ? \"bwdif\" : \"yadif\",\n                doubleRateDeint ? \"1\" : \"0\");\n        }\n\n        public static string GetHwDeinterlaceFilter(EncodingJobInfo state, EncodingOptions options, string hwDeintSuffix)\n        {\n            var doubleRateDeint = options.DeinterlaceDoubleRate && (state.VideoStream?.AverageFrameRate ?? 60) <= 30;\n            if (hwDeintSuffix.Contains(\"cuda\", StringComparison.OrdinalIgnoreCase))\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"yadif_cuda={0}:-1:0\",\n                    doubleRateDeint ? \"1\" : \"0\");\n            }\n            else if (hwDeintSuffix.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                return string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"deinterlace_vaapi=rate={0}\",\n                    doubleRateDeint ? \"field\" : \"frame\");\n            }\n            else if (hwDeintSuffix.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"deinterlace_qsv=mode=2\";\n            }\n\n            return string.Empty;\n        }\n\n        public string GetHwTonemapFilter(EncodingOptions options, string hwTonemapSuffix, string videoFormat)\n        {\n            if (string.IsNullOrEmpty(hwTonemapSuffix))\n            {\n                return string.Empty;\n            }\n\n            var args = \"tonemap_{0}=format={1}:p=bt709:t=bt709:m=bt709\";\n\n            if (hwTonemapSuffix.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                args = \"procamp_vaapi=b={2}:c={3},\" + args + \":extra_hw_frames=32\";\n\n                return string.Format(\n                        CultureInfo.InvariantCulture,\n                        args,\n                        hwTonemapSuffix,\n                        videoFormat ?? \"nv12\",\n                        options.VppTonemappingBrightness,\n                        options.VppTonemappingContrast);\n            }\n            else\n            {\n                args += \":tonemap={2}:peak={3}:desat={4}\";\n\n                if (string.Equals(options.TonemappingMode, \"max\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(options.TonemappingMode, \"rgb\", StringComparison.OrdinalIgnoreCase))\n                {\n                    if (_mediaEncoder.EncoderVersion >= _minFFmpegOclCuTonemapMode)\n                    {\n                        args += \":tonemap_mode={5}\";\n                    }\n                }\n\n                if (options.TonemappingParam != 0)\n                {\n                    args += \":param={6}\";\n                }\n\n                if (string.Equals(options.TonemappingRange, \"tv\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(options.TonemappingRange, \"pc\", StringComparison.OrdinalIgnoreCase))\n                {\n                    args += \":range={7}\";\n                }\n            }\n\n            return string.Format(\n                    CultureInfo.InvariantCulture,\n                    args,\n                    hwTonemapSuffix,\n                    videoFormat ?? \"nv12\",\n                    options.TonemappingAlgorithm,\n                    options.TonemappingPeak,\n                    options.TonemappingDesat,\n                    options.TonemappingMode,\n                    options.TonemappingParam,\n                    options.TonemappingRange);\n        }\n\n        /// <summary>\n        /// Gets the parameter of software filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetSwVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isVaapiEncoder = vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isV4l2Encoder = vidEncoder.Contains(\"h264_v4l2m2m\", StringComparison.OrdinalIgnoreCase);\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, false));\n\n            // INPUT sw surface(memory/copy-back from vram)\n            // sw deint\n            if (doDeintH2645)\n            {\n                var deintFilter = GetSwDeinterlaceFilter(state, options);\n                mainFilters.Add(deintFilter);\n            }\n\n            var outFormat = isSwDecoder ? \"yuv420p\" : \"nv12\";\n            var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n            if (isVaapiEncoder)\n            {\n                outFormat = \"nv12\";\n            }\n            else if (isV4l2Encoder)\n            {\n                outFormat = \"yuv420p\";\n            }\n\n            // sw scale\n            mainFilters.Add(swScaleFilter);\n            mainFilters.Add(\"format=\" + outFormat);\n\n            // sw tonemap <= TODO: finsh the fast tonemap filter\n\n            // OUTPUT yuv420p/nv12 surface(memory)\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (hasTextSubs)\n            {\n                // subtitles=f='*.ass':alpha=0\n                var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                mainFilters.Add(textSubtitlesFilter);\n            }\n            else if (hasGraphicalSubs)\n            {\n                // [0:s]scale=s=1280x720\n                var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                subFilters.Add(subSwScaleFilter);\n                overlayFilters.Add(\"overlay=eof_action=endall:shortest=1:repeatlast=0\");\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of Nvidia NVENC filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetNvidiaVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            if (!string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (null, null, null);\n            }\n\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !vidEncoder.Contains(\"nvenc\", StringComparison.OrdinalIgnoreCase);\n\n            // legacy cuvid pipeline(copy-back)\n            if ((isSwDecoder && isSwEncoder)\n                || !IsCudaFullSupported()\n                || !_mediaEncoder.SupportsFilter(\"alphasrc\"))\n            {\n                return GetSwVidFilterChain(state, options, vidEncoder);\n            }\n\n            // prefered nvdec/cuvid + cuda filters + nvenc pipeline\n            return GetNvidiaVidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetNvidiaVidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isNvDecoder = vidDecoder.Contains(\"cuda\", StringComparison.OrdinalIgnoreCase);\n            var isNvencEncoder = vidEncoder.Contains(\"nvenc\", StringComparison.OrdinalIgnoreCase);\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isNvencEncoder;\n            var isCuInCuOut = isNvDecoder && isNvencEncoder;\n\n            var doubleRateDeint = options.DeinterlaceDoubleRate && (state.VideoStream?.AverageFrameRate ?? 60) <= 30;\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n            var doCuTonemap = IsHwTonemapAvailable(state, options);\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doCuTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doCuTonemap ? \"yuv420p10le\" : \"yuv420p\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // sw => hw\n                if (doCuTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=cuda\");\n                }\n            }\n\n            if (isNvDecoder)\n            {\n                // INPUT cuda surface(vram)\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, \"cuda\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                var outFormat = doCuTonemap ? string.Empty : \"yuv420p\";\n                var hwScaleFilter = GetHwScaleFilter(\"cuda\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            // hw tonemap\n            if (doCuTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"cuda\", \"yuv420p\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            var memoryOutput = false;\n            var isUploadForCuTonemap = isSwDecoder && doCuTonemap;\n            if ((isNvDecoder && isSwEncoder) || (isUploadForCuTonemap && hasSubs))\n            {\n                memoryOutput = true;\n\n                // OUTPUT yuv420p surface(memory)\n                mainFilters.Add(\"hwdownload\");\n                mainFilters.Add(\"format=yuv420p\");\n            }\n\n            // OUTPUT yuv420p surface(memory)\n            if (isSwDecoder && isNvencEncoder && !isUploadForCuTonemap)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            // OUTPUT cuda(yuv420p) surface(vram)\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isCuInCuOut)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        // scale=s=1280x720,format=yuva420p,hwupload\n                        var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                        subFilters.Add(subSwScaleFilter);\n                        subFilters.Add(\"format=yuva420p\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        // alphasrc=s=1280x720:r=10:start=0,format=yuva420p,subtitles,hwupload\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, reqMaxH, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=yuva420p\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    subFilters.Add(\"hwupload=derive_device=cuda\");\n                    overlayFilters.Add(\"overlay_cuda=eof_action=endall:shortest=1:repeatlast=0\");\n                }\n            }\n            else\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=endall:shortest=1:repeatlast=0\");\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of AMD AMF filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetAmdVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            if (!string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (null, null, null);\n            }\n\n            var isWindows = OperatingSystem.IsWindows();\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !vidEncoder.Contains(\"amf\", StringComparison.OrdinalIgnoreCase);\n            var isAmfDx11OclSupported = isWindows && _mediaEncoder.SupportsHwaccel(\"d3d11va\") && IsOpenclFullSupported();\n\n            // legacy d3d11va pipeline(copy-back)\n            if ((isSwDecoder && isSwEncoder)\n                || !isAmfDx11OclSupported\n                || !_mediaEncoder.SupportsFilter(\"alphasrc\"))\n            {\n                return GetSwVidFilterChain(state, options, vidEncoder);\n            }\n\n            // prefered d3d11va + opencl filters + amf pipeline\n            return GetAmdDx11VidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetAmdDx11VidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n            var isAmfEncoder = vidEncoder.Contains(\"amf\", StringComparison.OrdinalIgnoreCase);\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isAmfEncoder;\n            var isDxInDxOut = isD3d11vaDecoder && isAmfEncoder;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n            var doOclTonemap = IsHwTonemapAvailable(state, options);\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doOclTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doOclTonemap ? \"yuv420p10le\" : \"yuv420p\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=d3d11va:extra_hw_frames=16\");\n                    mainFilters.Add(\"format=d3d11\");\n                    mainFilters.Add(\"hwmap=derive_device=opencl\");\n                }\n            }\n\n            if (isD3d11vaDecoder)\n            {\n                // INPUT d3d11 surface(vram)\n                // map from d3d11va to opencl via d3d11-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=opencl\");\n\n                // hw deint <= TODO: finsh the 'yadif_opencl' filter\n\n                var outFormat = doOclTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(\"opencl\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            // hw tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = isSwDecoder && doOclTonemap;\n            if (isD3d11vaDecoder && isSwEncoder)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl.\n                var hwTransferFilter = hasGraphicalSubs ? \"hwdownload\" : \"hwmap=mode=read\";\n                mainFilters.Add(hwTransferFilter);\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT yuv420p surface\n            if (isSwDecoder && isAmfEncoder && !isUploadForOclTonemap)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if ((isDxInDxOut || isUploadForOclTonemap) && !hasSubs)\n            {\n                // OUTPUT d3d11(nv12) surface(vram)\n                // reverse-mapping via d3d11-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=d3d11va:reverse=1\");\n                mainFilters.Add(\"format=d3d11\");\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isDxInDxOut || isUploadForOclTonemap)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        // scale=s=1280x720,format=yuva420p,hwupload\n                        var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                        subFilters.Add(subSwScaleFilter);\n                        subFilters.Add(\"format=yuva420p\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        // alphasrc=s=1280x720:r=10:start=0,format=yuva420p,subtitles,hwupload\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, reqMaxH, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=yuva420p\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    subFilters.Add(\"hwupload=derive_device=opencl\");\n                    overlayFilters.Add(\"overlay_opencl=eof_action=endall:shortest=1:repeatlast=0\");\n                    overlayFilters.Add(\"hwmap=derive_device=d3d11va:reverse=1\");\n                    overlayFilters.Add(\"format=d3d11\");\n                }\n            }\n            else if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=endall:shortest=1:repeatlast=0\");\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of Intel QSV filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetIntelVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            if (!string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (null, null, null);\n            }\n\n            var isWindows = OperatingSystem.IsWindows();\n            var isLinux = OperatingSystem.IsLinux();\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !vidEncoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isQsvOclSupported = _mediaEncoder.SupportsHwaccel(\"qsv\") && IsOpenclFullSupported();\n            var isIntelDx11OclSupported = isWindows\n                && _mediaEncoder.SupportsHwaccel(\"d3d11va\")\n                && isQsvOclSupported;\n            var isIntelVaapiOclSupported = isLinux\n                && IsVaapiSupported(state)\n                && isQsvOclSupported;\n\n            // legacy qsv pipeline(copy-back)\n            if ((isSwDecoder && isSwEncoder)\n                || (!isIntelVaapiOclSupported && !isIntelDx11OclSupported)\n                || !_mediaEncoder.SupportsFilter(\"alphasrc\"))\n            {\n                return GetSwVidFilterChain(state, options, vidEncoder);\n            }\n\n            // prefered qsv(vaapi) + opencl filters pipeline\n            if (isIntelVaapiOclSupported)\n            {\n                return GetIntelQsvVaapiVidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n            }\n\n            // prefered qsv(d3d11) + opencl filters pipeline\n            if (isIntelDx11OclSupported)\n            {\n                return GetIntelQsvDx11VidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n            }\n\n            return (null, null, null);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetIntelQsvDx11VidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isD3d11vaDecoder = vidDecoder.Contains(\"d3d11va\", StringComparison.OrdinalIgnoreCase);\n            var isQsvDecoder = vidDecoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isQsvEncoder = vidEncoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isHwDecoder = isD3d11vaDecoder || isQsvDecoder;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isQsvEncoder;\n            var isQsvInQsvOut = isHwDecoder && isQsvEncoder;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n            var doOclTonemap = IsHwTonemapAvailable(state, options);\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doOclTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doOclTonemap ? \"yuv420p10le\" : \"yuv420p\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n            else if (isD3d11vaDecoder || isQsvDecoder)\n            {\n                var outFormat = doOclTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(\"qsv\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n\n                if (isD3d11vaDecoder)\n                {\n                    if (!string.IsNullOrEmpty(hwScaleFilter) || doDeintH2645)\n                    {\n                        // INPUT d3d11 surface(vram)\n                        // map from d3d11va to qsv.\n                        mainFilters.Add(\"hwmap=derive_device=qsv\");\n                    }\n                }\n\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, \"qsv\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            if (doOclTonemap && isHwDecoder)\n            {\n                // map from qsv to opencl via qsv(d3d11)-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=opencl\");\n            }\n\n            // hw tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = isSwDecoder && doOclTonemap;\n            var isHwmapUsable = isSwEncoder && doOclTonemap;\n            if ((isHwDecoder && isSwEncoder) || isUploadForOclTonemap)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl.\n                // qsv hwmap is not fully implemented for the time being.\n                mainFilters.Add(isHwmapUsable ? \"hwmap=mode=read\" : \"hwdownload\");\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT nv12 surface(memory)\n            if (isSwDecoder && isQsvEncoder)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if (isQsvInQsvOut && doOclTonemap)\n            {\n                // OUTPUT qsv(nv12) surface(vram)\n                // reverse-mapping via qsv(d3d11)-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=qsv:reverse=1\");\n                mainFilters.Add(\"format=qsv\");\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isQsvInQsvOut)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        // scale,format=bgra,hwupload\n                        // overlay_qsv can handle overlay scaling,\n                        // add a dummy scale filter to pair with -canvas_size.\n                        subFilters.Add(\"scale=flags=fast_bilinear\");\n                        subFilters.Add(\"format=bgra\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        // alphasrc=s=1280x720:r=10:start=0,format=bgra,subtitles,hwupload\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, 1080, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=bgra\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    // qsv requires a fixed pool size.\n                    // default to 64 otherwise it will fail on certain iGPU.\n                    subFilters.Add(\"hwupload=derive_device=qsv:extra_hw_frames=64\");\n\n                    var (overlayW, overlayH) = GetFixedOutputSize(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    var overlaySize = (overlayW.HasValue && overlayH.HasValue)\n                        ? (\":w=\" + overlayW.Value + \":h=\" + overlayH.Value)\n                        : string.Empty;\n                    var overlayQsvFilter = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"overlay_qsv=eof_action=endall:shortest=1:repeatlast=0{0}\",\n                        overlaySize);\n                    overlayFilters.Add(overlayQsvFilter);\n                }\n            }\n            else if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=endall:shortest=1:repeatlast=0\");\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetIntelQsvVaapiVidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isQsvDecoder = vidDecoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isQsvEncoder = vidEncoder.Contains(\"qsv\", StringComparison.OrdinalIgnoreCase);\n            var isHwDecoder = isVaapiDecoder || isQsvDecoder;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isQsvEncoder;\n            var isQsvInQsvOut = isHwDecoder && isQsvEncoder;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doVaVppTonemap = IsVaapiVppTonemapAvailable(state, options);\n            var doOclTonemap = !doVaVppTonemap && IsHwTonemapAvailable(state, options);\n            var doTonemap = doVaVppTonemap || doOclTonemap;\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doOclTonemap ? \"yuv420p10le\" : \"yuv420p\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n            else if (isVaapiDecoder || isQsvDecoder)\n            {\n                // INPUT vaapi/qsv surface(vram)\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, isVaapiDecoder ? \"vaapi\" : \"qsv\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                var outFormat = doTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(isVaapiDecoder ? \"vaapi\" : \"qsv\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n\n                // allocate extra pool sizes for vaapi vpp\n                if (!string.IsNullOrEmpty(hwScaleFilter) && isVaapiDecoder)\n                {\n                    hwScaleFilter += \":extra_hw_frames=24\";\n                }\n\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            // vaapi vpp tonemap\n            if (doVaVppTonemap && isHwDecoder)\n            {\n                if (isQsvDecoder)\n                {\n                    // map from qsv to vaapi.\n                    mainFilters.Add(\"hwmap=derive_device=vaapi\");\n                }\n\n                var tonemapFilter = GetHwTonemapFilter(options, \"vaapi\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n\n                if (isQsvDecoder)\n                {\n                    // map from vaapi to qsv.\n                    mainFilters.Add(\"hwmap=derive_device=qsv\");\n                }\n            }\n\n            if (doOclTonemap && isHwDecoder)\n            {\n                // map from qsv to opencl via qsv(vaapi)-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=opencl\");\n            }\n\n            // ocl tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = isSwDecoder && doOclTonemap;\n            var isHwmapUsable = isSwEncoder && (doOclTonemap || isVaapiDecoder);\n            if ((isHwDecoder && isSwEncoder) || isUploadForOclTonemap)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl/vaapi.\n                // qsv hwmap is not fully implemented for the time being.\n                mainFilters.Add(isHwmapUsable ? \"hwmap=mode=read\" : \"hwdownload\");\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT nv12 surface(memory)\n            if (isSwDecoder && isQsvEncoder)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if (isQsvInQsvOut)\n            {\n                if (doOclTonemap)\n                {\n                    // OUTPUT qsv(nv12) surface(vram)\n                    // reverse-mapping via qsv(vaapi)-opencl interop.\n                    // add extra pool size to avoid the 'cannot allocate memory' error on hevc_qsv.\n                    mainFilters.Add(\"hwmap=derive_device=qsv:reverse=1:extra_hw_frames=16\");\n                    mainFilters.Add(\"format=qsv\");\n                }\n                else if (isVaapiDecoder)\n                {\n                    mainFilters.Add(\"hwmap=derive_device=qsv\");\n                    mainFilters.Add(\"format=qsv\");\n                }\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isQsvInQsvOut)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        subFilters.Add(\"scale=flags=fast_bilinear\");\n                        subFilters.Add(\"format=bgra\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, 1080, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=bgra\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    // qsv requires a fixed pool size.\n                    // default to 64 otherwise it will fail on certain iGPU.\n                    subFilters.Add(\"hwupload=derive_device=qsv:extra_hw_frames=64\");\n\n                    var (overlayW, overlayH) = GetFixedOutputSize(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    var overlaySize = (overlayW.HasValue && overlayH.HasValue)\n                        ? (\":w=\" + overlayW.Value + \":h=\" + overlayH.Value)\n                        : string.Empty;\n                    var overlayQsvFilter = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"overlay_qsv=eof_action=endall:shortest=1:repeatlast=0{0}\",\n                        overlaySize);\n                    overlayFilters.Add(overlayQsvFilter);\n                }\n            }\n            else if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=pass:shortest=1:repeatlast=0\");\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of Intel/AMD VAAPI filter chain.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"vidEncoder\">Video encoder to use.</param>\n        /// <returns>The tuple contains three lists: main, sub and overlay filters.</returns>\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetVaapiVidFilterChain(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidEncoder)\n        {\n            if (!string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                return (null, null, null);\n            }\n\n            var isLinux = OperatingSystem.IsLinux();\n            var vidDecoder = GetHardwareVideoDecoder(state, options) ?? string.Empty;\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isVaapiOclSupported = isLinux && IsVaapiSupported(state) && IsVaapiFullSupported() && IsOpenclFullSupported();\n\n            // legacy vaapi pipeline(copy-back)\n            if ((isSwDecoder && isSwEncoder)\n                || !isVaapiOclSupported\n                || !_mediaEncoder.SupportsFilter(\"alphasrc\"))\n            {\n                var swFilterChain = GetSwVidFilterChain(state, options, vidEncoder);\n\n                if (!isSwEncoder)\n                {\n                    var newfilters = new List<string>();\n                    var noOverlay = swFilterChain.OverlayFilters.Count == 0;\n                    newfilters.AddRange(noOverlay ? swFilterChain.MainFilters : swFilterChain.OverlayFilters);\n                    newfilters.Add(\"hwupload=derive_device=vaapi\");\n\n                    var mainFilters = noOverlay ? newfilters : swFilterChain.MainFilters;\n                    var overlayFilters = noOverlay ? swFilterChain.OverlayFilters : newfilters;\n                    return (mainFilters, swFilterChain.SubFilters, overlayFilters);\n                }\n\n                return swFilterChain;\n            }\n\n            // prefered vaapi + opencl filters pipeline\n            if (_mediaEncoder.IsVaapiDeviceInteliHD)\n            {\n                // Intel iHD path, with extra vpp tonemap and overlay support.\n                return GetVaapiFullVidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n            }\n\n            // Intel i965 and Amd radeonsi/r600 path, only featuring scale and deinterlace support.\n            return GetVaapiLimitedVidFiltersPrefered(state, options, vidDecoder, vidEncoder);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetVaapiFullVidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isVaapiEncoder = vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isVaapiEncoder;\n            var isVaInVaOut = isVaapiDecoder && isVaapiEncoder;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doVaVppTonemap = isVaapiDecoder && IsVaapiVppTonemapAvailable(state, options);\n            var doOclTonemap = !doVaVppTonemap && IsHwTonemapAvailable(state, options);\n            var doTonemap = doVaVppTonemap || doOclTonemap;\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n            var hasAssSubs = hasSubs\n                && (string.Equals(state.SubtitleStream.Codec, \"ass\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(state.SubtitleStream.Codec, \"ssa\", StringComparison.OrdinalIgnoreCase));\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doTonemap));\n\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                var outFormat = doOclTonemap ? \"yuv420p10le\" : \"nv12\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n            else if (isVaapiDecoder)\n            {\n                // INPUT vaapi surface(vram)\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, \"vaapi\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                var outFormat = doTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(\"vaapi\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n\n                // allocate extra pool sizes for vaapi vpp\n                if (!string.IsNullOrEmpty(hwScaleFilter))\n                {\n                    hwScaleFilter += \":extra_hw_frames=24\";\n                }\n\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            // vaapi vpp tonemap\n            if (doVaVppTonemap && isVaapiDecoder)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"vaapi\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            if (doOclTonemap && isVaapiDecoder)\n            {\n                // map from vaapi to opencl via vaapi-opencl interop(Intel only).\n                mainFilters.Add(\"hwmap=derive_device=opencl\");\n            }\n\n            // ocl tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            if (doOclTonemap && isVaInVaOut)\n            {\n                // OUTPUT vaapi(nv12) surface(vram)\n                // reverse-mapping via vaapi-opencl interop.\n                mainFilters.Add(\"hwmap=derive_device=vaapi:reverse=1\");\n                mainFilters.Add(\"format=vaapi\");\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = isSwDecoder && doOclTonemap;\n            var isHwmapNotUsable = isUploadForOclTonemap && isVaapiEncoder;\n            if ((isVaapiDecoder && isSwEncoder) || isUploadForOclTonemap)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl/vaapi.\n                mainFilters.Add(isHwmapNotUsable ? \"hwdownload\" : \"hwmap=mode=read\");\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT nv12 surface(memory)\n            if (isSwDecoder && isVaapiEncoder)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if (memoryOutput && isVaapiEncoder)\n            {\n                if (!hasGraphicalSubs)\n                {\n                    mainFilters.Add(\"hwupload_vaapi\");\n                }\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (isVaInVaOut)\n            {\n                if (hasSubs)\n                {\n                    if (hasGraphicalSubs)\n                    {\n                        subFilters.Add(\"scale=flags=fast_bilinear\");\n                        subFilters.Add(\"format=bgra\");\n                    }\n                    else if (hasTextSubs)\n                    {\n                        var alphaSrcFilter = GetAlphaSrcFilter(state, inW, inH, reqW, reqH, reqMaxW, 1080, hasAssSubs ? 10 : 5);\n                        var subTextSubtitlesFilter = GetTextSubtitlesFilter(state, true, true);\n                        subFilters.Add(alphaSrcFilter);\n                        subFilters.Add(\"format=bgra\");\n                        subFilters.Add(subTextSubtitlesFilter);\n                    }\n\n                    subFilters.Add(\"hwupload=derive_device=vaapi\");\n\n                    var (overlayW, overlayH) = GetFixedOutputSize(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    var overlaySize = (overlayW.HasValue && overlayH.HasValue)\n                        ? (\":w=\" + overlayW.Value + \":h=\" + overlayH.Value)\n                        : string.Empty;\n                    var overlayVaapiFilter = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"overlay_vaapi=eof_action=endall:shortest=1:repeatlast=0{0}\",\n                        overlaySize);\n                    overlayFilters.Add(overlayVaapiFilter);\n                }\n            }\n            else if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=pass:shortest=1:repeatlast=0\");\n\n                    if (isVaapiEncoder)\n                    {\n                        overlayFilters.Add(\"hwupload_vaapi\");\n                    }\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        public (List<string> MainFilters, List<string> SubFilters, List<string> OverlayFilters) GetVaapiLimitedVidFiltersPrefered(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string vidDecoder,\n            string vidEncoder)\n        {\n            var inW = state.VideoStream?.Width;\n            var inH = state.VideoStream?.Height;\n            var reqW = state.BaseRequest.Width;\n            var reqH = state.BaseRequest.Height;\n            var reqMaxW = state.BaseRequest.MaxWidth;\n            var reqMaxH = state.BaseRequest.MaxHeight;\n            var threeDFormat = state.MediaSource.Video3DFormat;\n\n            var isVaapiDecoder = vidDecoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isVaapiEncoder = vidEncoder.Contains(\"vaapi\", StringComparison.OrdinalIgnoreCase);\n            var isSwDecoder = string.IsNullOrEmpty(vidDecoder);\n            var isSwEncoder = !isVaapiEncoder;\n            var isVaInVaOut = isVaapiDecoder && isVaapiEncoder;\n            var isi965Driver = _mediaEncoder.IsVaapiDeviceInteli965;\n            var isAmdDriver = _mediaEncoder.IsVaapiDeviceAmd;\n\n            var doDeintH264 = state.DeInterlace(\"h264\", true) || state.DeInterlace(\"avc\", true);\n            var doDeintHevc = state.DeInterlace(\"h265\", true) || state.DeInterlace(\"hevc\", true);\n            var doDeintH2645 = doDeintH264 || doDeintHevc;\n            var doOclTonemap = IsHwTonemapAvailable(state, options);\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n\n            /* Make main filters for video stream */\n            var mainFilters = new List<string>();\n\n            mainFilters.Add(GetOverwriteColorPropertiesParam(state, doOclTonemap));\n\n            var outFormat = string.Empty;\n            if (isSwDecoder)\n            {\n                // INPUT sw surface(memory)\n                // sw deint\n                if (doDeintH2645)\n                {\n                    var swDeintFilter = GetSwDeinterlaceFilter(state, options);\n                    mainFilters.Add(swDeintFilter);\n                }\n\n                outFormat = doOclTonemap ? \"yuv420p10le\" : \"nv12\";\n                var swScaleFilter = GetSwScaleFilter(state, options, vidEncoder, inW, inH, threeDFormat, reqW, reqH, reqMaxW, reqMaxH);\n                // sw scale\n                mainFilters.Add(swScaleFilter);\n                mainFilters.Add(\"format=\" + outFormat);\n\n                // keep video at memory except ocl tonemap,\n                // since the overhead caused by hwupload >>> using sw filter.\n                // sw => hw\n                if (doOclTonemap)\n                {\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n            else if (isVaapiDecoder)\n            {\n                // INPUT vaapi surface(vram)\n                // hw deint\n                if (doDeintH2645)\n                {\n                    var deintFilter = GetHwDeinterlaceFilter(state, options, \"vaapi\");\n                    mainFilters.Add(deintFilter);\n                }\n\n                outFormat = doOclTonemap ? string.Empty : \"nv12\";\n                var hwScaleFilter = GetHwScaleFilter(\"vaapi\", outFormat, inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n\n                // allocate extra pool sizes for vaapi vpp\n                if (!string.IsNullOrEmpty(hwScaleFilter))\n                {\n                    hwScaleFilter += \":extra_hw_frames=24\";\n                }\n\n                // hw scale\n                mainFilters.Add(hwScaleFilter);\n            }\n\n            if (doOclTonemap && isVaapiDecoder)\n            {\n                if (isi965Driver)\n                {\n                    // map from vaapi to opencl via vaapi-opencl interop(Intel only).\n                    mainFilters.Add(\"hwmap=derive_device=opencl\");\n                }\n                else\n                {\n                    mainFilters.Add(\"hwdownload\");\n                    mainFilters.Add(\"format=p010le\");\n                    mainFilters.Add(\"hwupload=derive_device=opencl\");\n                }\n            }\n\n            // ocl tonemap\n            if (doOclTonemap)\n            {\n                var tonemapFilter = GetHwTonemapFilter(options, \"opencl\", \"nv12\");\n                mainFilters.Add(tonemapFilter);\n            }\n\n            if (doOclTonemap && isVaInVaOut)\n            {\n                if (isi965Driver)\n                {\n                    // OUTPUT vaapi(nv12) surface(vram)\n                    // reverse-mapping via vaapi-opencl interop.\n                    mainFilters.Add(\"hwmap=derive_device=vaapi:reverse=1\");\n                    mainFilters.Add(\"format=vaapi\");\n                }\n            }\n\n            var memoryOutput = false;\n            var isUploadForOclTonemap = doOclTonemap && (isSwDecoder || (isVaapiDecoder && !isi965Driver));\n            var isHwmapNotUsable = hasGraphicalSubs || isUploadForOclTonemap;\n            var isHwmapForSubs = hasSubs && isVaapiDecoder;\n            var isHwUnmapForTextSubs = hasTextSubs && isVaInVaOut && !isUploadForOclTonemap;\n            if ((isVaapiDecoder && isSwEncoder) || isUploadForOclTonemap || isHwmapForSubs)\n            {\n                memoryOutput = true;\n\n                // OUTPUT nv12 surface(memory)\n                // prefer hwmap to hwdownload on opencl/vaapi.\n                mainFilters.Add(isHwmapNotUsable ? \"hwdownload\" : \"hwmap\");\n                mainFilters.Add(\"format=nv12\");\n            }\n\n            // OUTPUT nv12 surface(memory)\n            if (isSwDecoder && isVaapiEncoder)\n            {\n                memoryOutput = true;\n            }\n\n            if (memoryOutput)\n            {\n                // text subtitles\n                if (hasTextSubs)\n                {\n                    var textSubtitlesFilter = GetTextSubtitlesFilter(state, false, false);\n                    mainFilters.Add(textSubtitlesFilter);\n                }\n            }\n\n            if (isHwUnmapForTextSubs)\n            {\n                mainFilters.Add(\"hwmap\");\n                mainFilters.Add(\"format=vaapi\");\n            }\n            else if (memoryOutput && isVaapiEncoder)\n            {\n                if (!hasGraphicalSubs)\n                {\n                    mainFilters.Add(\"hwupload_vaapi\");\n                }\n            }\n\n            /* Make sub and overlay filters for subtitle stream */\n            var subFilters = new List<string>();\n            var overlayFilters = new List<string>();\n            if (memoryOutput)\n            {\n                if (hasGraphicalSubs)\n                {\n                    var subSwScaleFilter = GetCustomSwScaleFilter(inW, inH, reqW, reqH, reqMaxW, reqMaxH);\n                    subFilters.Add(subSwScaleFilter);\n                    overlayFilters.Add(\"overlay=eof_action=pass:shortest=1:repeatlast=0\");\n\n                    if (isVaapiEncoder)\n                    {\n                        overlayFilters.Add(\"hwupload_vaapi\");\n                    }\n                }\n            }\n\n            return (mainFilters, subFilters, overlayFilters);\n        }\n\n        /// <summary>\n        /// Gets the parameter of video processing filters.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"outputVideoCodec\">Video codec to use.</param>\n        /// <returns>The video processing filters parameter.</returns>\n        public string GetVideoProcessingFilterParam(\n            EncodingJobInfo state,\n            EncodingOptions options,\n            string outputVideoCodec)\n        {\n            var videoStream = state.VideoStream;\n            if (videoStream == null)\n            {\n                return string.Empty;\n            }\n\n            var hasSubs = state.SubtitleStream != null && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n            var hasTextSubs = hasSubs && state.SubtitleStream.IsTextSubtitleStream;\n            var hasGraphicalSubs = hasSubs && !state.SubtitleStream.IsTextSubtitleStream;\n\n            List<string> mainFilters;\n            List<string> subFilters;\n            List<string> overlayFilters;\n\n            if (string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                (mainFilters, subFilters, overlayFilters) = GetVaapiVidFilterChain(state, options, outputVideoCodec);\n            }\n            else if (string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                (mainFilters, subFilters, overlayFilters) = GetIntelVidFilterChain(state, options, outputVideoCodec);\n            }\n            else if (string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                (mainFilters, subFilters, overlayFilters) = GetNvidiaVidFilterChain(state, options, outputVideoCodec);\n            }\n            else if (string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                (mainFilters, subFilters, overlayFilters) = GetAmdVidFilterChain(state, options, outputVideoCodec);\n            }\n            else\n            {\n                (mainFilters, subFilters, overlayFilters) = GetSwVidFilterChain(state, options, outputVideoCodec);\n            }\n\n            mainFilters?.RemoveAll(filter => string.IsNullOrEmpty(filter));\n            subFilters?.RemoveAll(filter => string.IsNullOrEmpty(filter));\n            overlayFilters?.RemoveAll(filter => string.IsNullOrEmpty(filter));\n\n            var mainStr = string.Empty;\n            if (mainFilters?.Count > 0)\n            {\n                mainStr = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \"{0}\",\n                    string.Join(',', mainFilters));\n            }\n\n            if (overlayFilters?.Count == 0)\n            {\n                // -vf \"scale...\"\n                return string.IsNullOrEmpty(mainStr) ? string.Empty : \" -vf \\\"\" + mainStr + \"\\\"\";\n            }\n\n            if (overlayFilters?.Count > 0\n                && subFilters?.Count > 0\n                && state.SubtitleStream != null)\n            {\n                // overlay graphical/text subtitles\n                var subStr = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"{0}\",\n                        string.Join(',', subFilters));\n\n                var overlayStr = string.Format(\n                        CultureInfo.InvariantCulture,\n                        \"{0}\",\n                        string.Join(',', overlayFilters));\n\n                var mapPrefix = Convert.ToInt32(state.SubtitleStream.IsExternal);\n                var subtitleStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.SubtitleStream);\n                var videoStreamIndex = FindIndex(state.MediaSource.MediaStreams, state.VideoStream);\n\n                if (hasSubs)\n                {\n                    // -filter_complex \"[0:s]scale=s[sub]...\"\n                    var filterStr = string.IsNullOrEmpty(mainStr)\n                        ? \" -filter_complex \\\"[{0}:{1}]{4}[sub];[0:{2}][sub]{5}\\\"\"\n                        : \" -filter_complex \\\"[{0}:{1}]{4}[sub];[0:{2}]{3}[main];[main][sub]{5}\\\"\";\n\n                    if (hasTextSubs)\n                    {\n                        filterStr = string.IsNullOrEmpty(mainStr)\n                            ? \" -filter_complex \\\"{4}[sub];[0:{2}][sub]{5}\\\"\"\n                            : \" -filter_complex \\\"{4}[sub];[0:{2}]{3}[main];[main][sub]{5}\\\"\";\n                    }\n\n                    return string.Format(\n                        CultureInfo.InvariantCulture,\n                        filterStr,\n                        mapPrefix,\n                        subtitleStreamIndex,\n                        videoStreamIndex,\n                        mainStr,\n                        subStr,\n                        overlayStr);\n                }\n            }\n\n            return string.Empty;\n        }\n\n        public string GetOverwriteColorPropertiesParam(EncodingJobInfo state, bool isTonemapAvailable)\n        {\n            if (isTonemapAvailable)\n            {\n                return GetInputHdrParam(state.VideoStream?.ColorTransfer);\n            }\n\n            return GetOutputSdrParam(null);\n        }\n\n        public string GetInputHdrParam(string colorTransfer)\n        {\n            if (string.Equals(colorTransfer, \"arib-std-b67\", StringComparison.OrdinalIgnoreCase))\n            {\n                // HLG\n                return \"setparams=color_primaries=bt2020:color_trc=arib-std-b67:colorspace=bt2020nc\";\n            }\n\n            // HDR10\n            return \"setparams=color_primaries=bt2020:color_trc=smpte2084:colorspace=bt2020nc\";\n        }\n\n        public string GetOutputSdrParam(string tonemappingRange)\n        {\n            // SDR\n            if (string.Equals(tonemappingRange, \"tv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"setparams=color_primaries=bt709:color_trc=bt709:colorspace=bt709:range=tv\";\n            }\n\n            if (string.Equals(tonemappingRange, \"pc\", StringComparison.OrdinalIgnoreCase))\n            {\n                return \"setparams=color_primaries=bt709:color_trc=bt709:colorspace=bt709:range=pc\";\n            }\n\n            return \"setparams=color_primaries=bt709:color_trc=bt709:colorspace=bt709\";\n        }\n\n        public static int GetVideoColorBitDepth(EncodingJobInfo state)\n        {\n            var videoStream = state.VideoStream;\n            if (videoStream != null)\n            {\n                if (videoStream.BitDepth.HasValue)\n                {\n                    return videoStream.BitDepth.Value;\n                }\n                else if (string.Equals(videoStream.PixelFormat, \"yuv420p\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.PixelFormat, \"yuvj420p\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.PixelFormat, \"yuv444p\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return 8;\n                }\n                else if (string.Equals(videoStream.PixelFormat, \"yuv420p10le\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.PixelFormat, \"yuv444p10le\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return 10;\n                }\n                else if (string.Equals(videoStream.PixelFormat, \"yuv420p12le\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.PixelFormat, \"yuv444p12le\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return 12;\n                }\n                else\n                {\n                    return 8;\n                }\n            }\n\n            return 0;\n        }\n\n        /// <summary>\n        /// Gets the ffmpeg option string for the hardware accelerated video decoder.\n        /// </summary>\n        /// <param name=\"state\">The encoding job info.</param>\n        /// <param name=\"options\">The encoding options.</param>\n        /// <returns>The option string or null if none available.</returns>\n        protected string GetHardwareVideoDecoder(EncodingJobInfo state, EncodingOptions options)\n        {\n            var videoStream = state.VideoStream;\n            var mediaSource = state.MediaSource;\n            if (videoStream == null || mediaSource == null)\n            {\n                return null;\n            }\n\n            // HWA decoders can handle both video files and video folders.\n            var videoType = state.VideoType;\n            if (videoType != VideoType.VideoFile\n                && videoType != VideoType.Iso\n                && videoType != VideoType.Dvd\n                && videoType != VideoType.BluRay)\n            {\n                return null;\n            }\n\n            if (IsCopyCodec(state.OutputVideoCodec))\n            {\n                return null;\n            }\n\n            if (!string.IsNullOrEmpty(videoStream.Codec) && !string.IsNullOrEmpty(options.HardwareAccelerationType))\n            {\n                var bitDepth = GetVideoColorBitDepth(state);\n\n                // Only HEVC, VP9 and AV1 formats have 10-bit hardware decoder support now.\n                if (bitDepth == 10\n                    && !(string.Equals(videoStream.Codec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.Codec, \"h265\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.Codec, \"vp9\", StringComparison.OrdinalIgnoreCase)\n                         || string.Equals(videoStream.Codec, \"av1\", StringComparison.OrdinalIgnoreCase)))\n                {\n                    return null;\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetQsvHwVidDecoder(state, options, videoStream, bitDepth);\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetNvdecVidDecoder(state, options, videoStream, bitDepth);\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetAmfVidDecoder(state, options, videoStream, bitDepth);\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetVaapiVidDecoder(state, options, videoStream, bitDepth);\n                }\n\n                if (string.Equals(options.HardwareAccelerationType, \"videotoolbox\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetVideotoolboxVidDecoder(state, options, videoStream, bitDepth);\n                }\n            }\n\n            var whichCodec = videoStream.Codec;\n            if (string.Equals(whichCodec, \"avc\", StringComparison.OrdinalIgnoreCase))\n            {\n                whichCodec = \"h264\";\n            }\n            else if (string.Equals(whichCodec, \"h265\", StringComparison.OrdinalIgnoreCase))\n            {\n                whichCodec = \"hevc\";\n            }\n\n            // Avoid a second attempt if no hardware acceleration is being used\n            options.HardwareDecodingCodecs = Array.FindAll(options.HardwareDecodingCodecs, val => !string.Equals(val, whichCodec, StringComparison.OrdinalIgnoreCase));\n\n            // leave blank so ffmpeg will decide\n            return null;\n        }\n\n        /// <summary>\n        /// Gets a hw decoder name.\n        /// </summary>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"decoderPrefix\">Decoder prefix.</param>\n        /// <param name=\"decoderSuffix\">Decoder suffix.</param>\n        /// <param name=\"videoCodec\">Video codec to use.</param>\n        /// <param name=\"bitDepth\">Video color bit depth.</param>\n        /// <returns>Hardware decoder name.</returns>\n        public string GetHwDecoderName(EncodingOptions options, string decoderPrefix, string decoderSuffix, string videoCodec, int bitDepth)\n        {\n            if (string.IsNullOrEmpty(decoderPrefix) || string.IsNullOrEmpty(decoderSuffix))\n            {\n                return null;\n            }\n\n            var decoderName = decoderPrefix + '_' + decoderSuffix;\n\n            var isCodecAvailable = _mediaEncoder.SupportsDecoder(decoderName) && options.HardwareDecodingCodecs.Contains(videoCodec, StringComparison.OrdinalIgnoreCase);\n            if (bitDepth == 10 && isCodecAvailable)\n            {\n                if (string.Equals(videoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                    && options.HardwareDecodingCodecs.Contains(\"hevc\", StringComparison.OrdinalIgnoreCase)\n                    && !options.EnableDecodingColorDepth10Hevc)\n                {\n                    return null;\n                }\n\n                if (string.Equals(videoCodec, \"vp9\", StringComparison.OrdinalIgnoreCase)\n                    && options.HardwareDecodingCodecs.Contains(\"vp9\", StringComparison.OrdinalIgnoreCase)\n                    && !options.EnableDecodingColorDepth10Vp9)\n                {\n                    return null;\n                }\n            }\n\n            if (string.Equals(decoderSuffix, \"cuvid\", StringComparison.OrdinalIgnoreCase) && options.EnableEnhancedNvdecDecoder)\n            {\n                return null;\n            }\n\n            if (string.Equals(decoderSuffix, \"qsv\", StringComparison.OrdinalIgnoreCase) && options.PreferSystemNativeHwDecoder)\n            {\n                return null;\n            }\n\n            return isCodecAvailable ? (\" -c:v \" + decoderName) : null;\n        }\n\n        /// <summary>\n        /// Gets a hwaccel type to use as a hardware decoder depending on the system.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"options\">Encoding options.</param>\n        /// <param name=\"videoCodec\">Video codec to use.</param>\n        /// <param name=\"bitDepth\">Video color bit depth.</param>\n        /// <param name=\"outputHwSurface\">Specifies if output hw surface.</param>\n        /// <returns>Hardware accelerator type.</returns>\n        public string GetHwaccelType(EncodingJobInfo state, EncodingOptions options, string videoCodec, int bitDepth, bool outputHwSurface)\n        {\n            var isWindows = OperatingSystem.IsWindows();\n            var isLinux = OperatingSystem.IsLinux();\n            var isMacOS = OperatingSystem.IsMacOS();\n            var isD3d11Supported = isWindows && _mediaEncoder.SupportsHwaccel(\"d3d11va\");\n            var isVaapiSupported = isLinux && IsVaapiSupported(state);\n            var isCudaSupported = (isLinux || isWindows) && IsCudaFullSupported();\n            var isQsvSupported = (isLinux || isWindows) && _mediaEncoder.SupportsHwaccel(\"qsv\");\n            var isVideotoolboxSupported = isMacOS && _mediaEncoder.SupportsHwaccel(\"videotoolbox\");\n            var isCodecAvailable = options.HardwareDecodingCodecs.Contains(videoCodec, StringComparison.OrdinalIgnoreCase);\n\n            var ffmpegVersion = _mediaEncoder.EncoderVersion;\n\n            // Set the av1 codec explicitly to trigger hw accelerator, otherwise libdav1d will be used.\n            var isAv1 = ffmpegVersion < _minFFmpegImplictHwaccel\n                && string.Equals(videoCodec, \"av1\", StringComparison.OrdinalIgnoreCase);\n\n            // Allow profile mismatch if decoding H.264 baseline with d3d11va and vaapi hwaccels.\n            var profileMismatch = string.Equals(videoCodec, \"h264\", StringComparison.OrdinalIgnoreCase)\n                && string.Equals(state.VideoStream?.Profile, \"baseline\", StringComparison.OrdinalIgnoreCase);\n\n            // Disable the extra internal copy in nvdec. We already handle it in filter chain.\n            var nvdecNoInternalCopy = ffmpegVersion >= _minFFmpegHwaUnsafeOutput;\n\n            if (bitDepth == 10 && isCodecAvailable)\n            {\n                if (string.Equals(videoCodec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                    && options.HardwareDecodingCodecs.Contains(\"hevc\", StringComparison.OrdinalIgnoreCase)\n                    && !options.EnableDecodingColorDepth10Hevc)\n                {\n                    return null;\n                }\n\n                if (string.Equals(videoCodec, \"vp9\", StringComparison.OrdinalIgnoreCase)\n                    && options.HardwareDecodingCodecs.Contains(\"vp9\", StringComparison.OrdinalIgnoreCase)\n                    && !options.EnableDecodingColorDepth10Vp9)\n                {\n                    return null;\n                }\n            }\n\n            // Intel qsv/d3d11va/vaapi\n            if (string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (options.PreferSystemNativeHwDecoder)\n                {\n                    if (isVaapiSupported && isCodecAvailable)\n                    {\n                        return \" -hwaccel vaapi\" + (outputHwSurface ? \" -hwaccel_output_format vaapi\" : string.Empty)\n                            + (profileMismatch ? \" -hwaccel_flags +allow_profile_mismatch\" : string.Empty) + (isAv1 ? \" -c:v av1\" : string.Empty);\n                    }\n\n                    if (isD3d11Supported && isCodecAvailable)\n                    {\n                        return \" -hwaccel d3d11va\" + (outputHwSurface ? \" -hwaccel_output_format d3d11\" : string.Empty)\n                            + (profileMismatch ? \" -hwaccel_flags +allow_profile_mismatch\" : string.Empty) + \" -threads 2\" + (isAv1 ? \" -c:v av1\" : string.Empty);\n                    }\n                }\n                else\n                {\n                    if (isQsvSupported && isCodecAvailable)\n                    {\n                        return \" -hwaccel qsv\" + (outputHwSurface ? \" -hwaccel_output_format qsv\" : string.Empty);\n                    }\n                }\n            }\n\n            // Nvidia cuda\n            if (string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (isCudaSupported && isCodecAvailable)\n                {\n                    if (options.EnableEnhancedNvdecDecoder)\n                    {\n                        // set -threads 1 to nvdec decoder explicitly since it doesn't implement threading support.\n                        return \" -hwaccel cuda\" + (outputHwSurface ? \" -hwaccel_output_format cuda\" : string.Empty)\n                            + (nvdecNoInternalCopy ? \" -hwaccel_flags +unsafe_output\" : string.Empty) + \" -threads 1\" + (isAv1 ? \" -c:v av1\" : string.Empty);\n                    }\n                    else\n                    {\n                        // cuvid decoder doesn't have threading issue.\n                        return \" -hwaccel cuda\" + (outputHwSurface ? \" -hwaccel_output_format cuda\" : string.Empty);\n                    }\n                }\n            }\n\n            // Amd d3d11va\n            if (string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                if (isD3d11Supported && isCodecAvailable)\n                {\n                    return \" -hwaccel d3d11va\" + (outputHwSurface ? \" -hwaccel_output_format d3d11\" : string.Empty)\n                        + (profileMismatch ? \" -hwaccel_flags +allow_profile_mismatch\" : string.Empty) + (isAv1 ? \" -c:v av1\" : string.Empty);\n                }\n            }\n\n            // Vaapi\n            if (string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase)\n                && isVaapiSupported\n                && isCodecAvailable)\n            {\n                return \" -hwaccel vaapi\" + (outputHwSurface ? \" -hwaccel_output_format vaapi\" : string.Empty)\n                    + (profileMismatch ? \" -hwaccel_flags +allow_profile_mismatch\" : string.Empty) + (isAv1 ? \" -c:v av1\" : string.Empty);\n            }\n\n            // Apple videotoolbox\n            if (string.Equals(options.HardwareAccelerationType, \"videotoolbox\", StringComparison.OrdinalIgnoreCase)\n                && isVideotoolboxSupported\n                && isCodecAvailable)\n            {\n                return \" -hwaccel videotoolbox\" + (outputHwSurface ? \" -hwaccel_output_format videotoolbox_vld\" : string.Empty);\n            }\n\n            return null;\n        }\n\n        public string GetQsvHwVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            var isWindows = OperatingSystem.IsWindows();\n            var isLinux = OperatingSystem.IsLinux();\n\n            if ((!isWindows && !isLinux)\n                || !string.Equals(options.HardwareAccelerationType, \"qsv\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var isQsvOclSupported = _mediaEncoder.SupportsHwaccel(\"qsv\") && IsOpenclFullSupported();\n            var isIntelDx11OclSupported = isWindows\n                && _mediaEncoder.SupportsHwaccel(\"d3d11va\")\n                && isQsvOclSupported;\n            var isIntelVaapiOclSupported = isLinux\n                && IsVaapiSupported(state)\n                && isQsvOclSupported;\n            var hwSurface = (isIntelDx11OclSupported || isIntelVaapiOclSupported)\n                && _mediaEncoder.SupportsFilter(\"alphasrc\");\n\n            var is8bitSwFormatsQsv = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                     || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsQsv = is8bitSwFormatsQsv || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            // TODO: add more 8/10bit and 4:4:4 formats for Qsv after finishing the ffcheck tool\n\n            if (is8bitSwFormatsQsv)\n            {\n                if (string.Equals(videoStream.Codec, \"avc\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(videoStream.Codec, \"h264\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, hwSurface) + GetHwDecoderName(options, \"h264\", \"qsv\", \"h264\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"vc1\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vc1\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vc1\", \"qsv\", \"vc1\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"vp8\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp8\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vp8\", \"qsv\", \"vp8\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"mpeg2video\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, hwSurface) + GetHwDecoderName(options, \"mpeg2\", \"qsv\", \"mpeg2video\", bitDepth);\n                }\n            }\n\n            if (is8_10bitSwFormatsQsv)\n            {\n                if (string.Equals(videoStream.Codec, \"hevc\", StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(videoStream.Codec, \"h265\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, hwSurface) + GetHwDecoderName(options, \"hevc\", \"qsv\", \"hevc\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"vp9\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vp9\", \"qsv\", \"vp9\", bitDepth);\n                }\n\n                if (string.Equals(videoStream.Codec, \"av1\", StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"av1\", bitDepth, hwSurface) + GetHwDecoderName(options, \"av1\", \"qsv\", \"av1\", bitDepth);\n                }\n            }\n\n            return null;\n        }\n\n        public string GetNvdecVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            if ((!OperatingSystem.IsWindows() && !OperatingSystem.IsLinux())\n                || !string.Equals(options.HardwareAccelerationType, \"nvenc\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var hwSurface = IsCudaFullSupported() && _mediaEncoder.SupportsFilter(\"alphasrc\");\n            var is8bitSwFormatsNvdec = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                       || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsNvdec = is8bitSwFormatsNvdec || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            // TODO: add more 8/10/12bit and 4:4:4 formats for Nvdec after finishing the ffcheck tool\n\n            if (is8bitSwFormatsNvdec)\n            {\n                if (string.Equals(\"avc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, hwSurface) + GetHwDecoderName(options, \"h264\", \"cuvid\", \"h264\", bitDepth);\n                }\n\n                if (string.Equals(\"mpeg2video\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, hwSurface) + GetHwDecoderName(options, \"mpeg2\", \"cuvid\", \"mpeg2video\", bitDepth);\n                }\n\n                if (string.Equals(\"vc1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vc1\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vc1\", \"cuvid\", \"vc1\", bitDepth);\n                }\n\n                if (string.Equals(\"mpeg4\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg4\", bitDepth, hwSurface) + GetHwDecoderName(options, \"mpeg4\", \"cuvid\", \"mpeg4\", bitDepth);\n                }\n\n                if (string.Equals(\"vp8\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp8\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vp8\", \"cuvid\", \"vp8\", bitDepth);\n                }\n            }\n\n            if (is8_10bitSwFormatsNvdec)\n            {\n                if (string.Equals(\"hevc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h265\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, hwSurface) + GetHwDecoderName(options, \"hevc\", \"cuvid\", \"hevc\", bitDepth);\n                }\n\n                if (string.Equals(\"vp9\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, hwSurface) + GetHwDecoderName(options, \"vp9\", \"cuvid\", \"vp9\", bitDepth);\n                }\n\n                if (string.Equals(\"av1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"av1\", bitDepth, hwSurface) + GetHwDecoderName(options, \"av1\", \"cuvid\", \"av1\", bitDepth);\n                }\n            }\n\n            return null;\n        }\n\n        public string GetAmfVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            if (!OperatingSystem.IsWindows()\n                || !string.Equals(options.HardwareAccelerationType, \"amf\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var hwSurface = _mediaEncoder.SupportsHwaccel(\"d3d11va\")\n                && IsOpenclFullSupported()\n                && _mediaEncoder.SupportsFilter(\"alphasrc\");\n            var is8bitSwFormatsAmf = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                     || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsAmf = is8bitSwFormatsAmf || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n\n            if (is8bitSwFormatsAmf)\n            {\n                if (string.Equals(\"avc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"mpeg2video\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vc1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vc1\", bitDepth, hwSurface);\n                }\n            }\n\n            if (is8_10bitSwFormatsAmf)\n            {\n                if (string.Equals(\"hevc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h265\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vp9\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"av1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"av1\", bitDepth, hwSurface);\n                }\n            }\n\n            return null;\n        }\n\n        public string GetVaapiVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            if (!OperatingSystem.IsLinux()\n                || !string.Equals(options.HardwareAccelerationType, \"vaapi\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var hwSurface = IsVaapiSupported(state)\n                && IsVaapiFullSupported()\n                && IsOpenclFullSupported()\n                && _mediaEncoder.SupportsFilter(\"alphasrc\");\n            var is8bitSwFormatsVaapi = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                       || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsVaapi = is8bitSwFormatsVaapi || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n\n            if (is8bitSwFormatsVaapi)\n            {\n                if (string.Equals(\"avc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"mpeg2video\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vc1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vc1\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vp8\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp8\", bitDepth, hwSurface);\n                }\n            }\n\n            if (is8_10bitSwFormatsVaapi)\n            {\n                if (string.Equals(\"hevc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h265\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"vp9\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, hwSurface);\n                }\n\n                if (string.Equals(\"av1\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"av1\", bitDepth, hwSurface);\n                }\n            }\n\n            return null;\n        }\n\n        public string GetVideotoolboxVidDecoder(EncodingJobInfo state, EncodingOptions options, MediaStream videoStream, int bitDepth)\n        {\n            if (!OperatingSystem.IsMacOS()\n                || !string.Equals(options.HardwareAccelerationType, \"videotoolbox\", StringComparison.OrdinalIgnoreCase))\n            {\n                return null;\n            }\n\n            var is8bitSwFormatsVt = string.Equals(\"yuv420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase)\n                                    || string.Equals(\"yuvj420p\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n            var is8_10bitSwFormatsVt = is8bitSwFormatsVt || string.Equals(\"yuv420p10le\", videoStream.PixelFormat, StringComparison.OrdinalIgnoreCase);\n\n            if (is8bitSwFormatsVt)\n            {\n                if (string.Equals(\"avc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h264\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"h264\", bitDepth, false);\n                }\n\n                if (string.Equals(\"mpeg2video\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg2video\", bitDepth, false);\n                }\n\n                if (string.Equals(\"mpeg4\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"mpeg4\", bitDepth, false);\n                }\n            }\n\n            if (is8_10bitSwFormatsVt)\n            {\n                if (string.Equals(\"hevc\", videoStream.Codec, StringComparison.OrdinalIgnoreCase)\n                    || string.Equals(\"h265\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"hevc\", bitDepth, false);\n                }\n\n                if (string.Equals(\"vp9\", videoStream.Codec, StringComparison.OrdinalIgnoreCase))\n                {\n                    return GetHwaccelType(state, options, \"vp9\", bitDepth, false);\n                }\n            }\n\n            return null;\n        }\n\n        /// <summary>\n        /// Gets the number of threads.\n        /// </summary>\n        /// <param name=\"state\">Encoding state.</param>\n        /// <param name=\"encodingOptions\">Encoding options.</param>\n        /// <param name=\"outputVideoCodec\">Video codec to use.</param>\n        /// <returns>Number of threads.</returns>\n#nullable enable\n        public static int GetNumberOfThreads(EncodingJobInfo? state, EncodingOptions encodingOptions, string? outputVideoCodec)\n        {\n            // VP8 and VP9 encoders must have their thread counts set.\n            bool mustSetThreadCount = string.Equals(outputVideoCodec, \"libvpx\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(outputVideoCodec, \"libvpx-vp9\", StringComparison.OrdinalIgnoreCase);\n\n            var threads = state?.BaseRequest.CpuCoreLimit ?? encodingOptions.EncodingThreadCount;\n\n            if (threads <= 0)\n            {\n                // Automatically set thread count\n                return mustSetThreadCount ? Math.Max(Environment.ProcessorCount - 1, 1) : 0;\n            }\n            else if (threads >= Environment.ProcessorCount)\n            {\n                return Environment.ProcessorCount;\n            }\n\n            return threads;\n        }\n\n#nullable disable\n        public void TryStreamCopy(EncodingJobInfo state)\n        {\n            if (state.VideoStream != null && CanStreamCopyVideo(state, state.VideoStream))\n            {\n                state.OutputVideoCodec = \"copy\";\n            }\n            else\n            {\n                var user = state.User;\n\n                // If the user doesn't have access to transcoding, then force stream copy, regardless of whether it will be compatible or not\n                if (user != null && !user.HasPermission(PermissionKind.EnableVideoPlaybackTranscoding))\n                {\n                    state.OutputVideoCodec = \"copy\";\n                }\n            }\n\n            if (state.AudioStream != null\n                && CanStreamCopyAudio(state, state.AudioStream, state.SupportedAudioCodecs))\n            {\n                state.OutputAudioCodec = \"copy\";\n            }\n            else\n            {\n                var user = state.User;\n\n                // If the user doesn't have access to transcoding, then force stream copy, regardless of whether it will be compatible or not\n                if (user != null && !user.HasPermission(PermissionKind.EnableAudioPlaybackTranscoding))\n                {\n                    state.OutputAudioCodec = \"copy\";\n                }\n            }\n        }\n\n        public string GetInputModifier(EncodingJobInfo state, EncodingOptions encodingOptions, string segmentContainer)\n        {\n            var inputModifier = string.Empty;\n            var analyzeDurationArgument = string.Empty;\n\n            // Apply -analyzeduration as per the environment variable,\n            // otherwise ffmpeg will break on certain files due to default value is 0.\n            // The default value of -probesize is more than enough, so leave it as is.\n            var ffmpegAnalyzeDuration = _config.GetFFmpegAnalyzeDuration() ?? string.Empty;\n\n            if (state.MediaSource.AnalyzeDurationMs > 0)\n            {\n                analyzeDurationArgument = \"-analyzeduration \" + (state.MediaSource.AnalyzeDurationMs.Value * 1000).ToString(CultureInfo.InvariantCulture);\n            }\n            else if (!string.IsNullOrEmpty(ffmpegAnalyzeDuration))\n            {\n                analyzeDurationArgument = \"-analyzeduration \" + ffmpegAnalyzeDuration;\n            }\n\n            if (!string.IsNullOrEmpty(analyzeDurationArgument))\n            {\n                inputModifier += \" \" + analyzeDurationArgument;\n            }\n\n            inputModifier = inputModifier.Trim();\n\n            var userAgentParam = GetUserAgentParam(state);\n\n            if (!string.IsNullOrEmpty(userAgentParam))\n            {\n                inputModifier += \" \" + userAgentParam;\n            }\n\n            inputModifier = inputModifier.Trim();\n\n            inputModifier += \" \" + GetFastSeekCommandLineParameter(state, encodingOptions, segmentContainer);\n            inputModifier = inputModifier.Trim();\n\n            if (state.InputProtocol == MediaProtocol.Rtsp)\n            {\n                inputModifier += \" -rtsp_transport tcp+udp -rtsp_flags prefer_tcp\";\n            }\n\n            if (!string.IsNullOrEmpty(state.InputAudioSync))\n            {\n                inputModifier += \" -async \" + state.InputAudioSync;\n            }\n\n            if (!string.IsNullOrEmpty(state.InputVideoSync))\n            {\n                inputModifier += \" -vsync \" + state.InputVideoSync;\n            }\n\n            if (state.ReadInputAtNativeFramerate && state.InputProtocol != MediaProtocol.Rtsp)\n            {\n                inputModifier += \" -re\";\n            }\n\n            var flags = new List<string>();\n            if (state.IgnoreInputDts)\n            {\n                flags.Add(\"+igndts\");\n            }\n\n            if (state.IgnoreInputIndex)\n            {\n                flags.Add(\"+ignidx\");\n            }\n\n            if (state.GenPtsInput || IsCopyCodec(state.OutputVideoCodec))\n            {\n                flags.Add(\"+genpts\");\n            }\n\n            if (state.DiscardCorruptFramesInput)\n            {\n                flags.Add(\"+discardcorrupt\");\n            }\n\n            if (state.EnableFastSeekInput)\n            {\n                flags.Add(\"+fastseek\");\n            }\n\n            if (flags.Count > 0)\n            {\n                inputModifier += \" -fflags \" + string.Join(string.Empty, flags);\n            }\n\n            if (state.IsVideoRequest)\n            {\n                if (!string.IsNullOrEmpty(state.InputContainer) && state.VideoType == VideoType.VideoFile && string.IsNullOrEmpty(encodingOptions.HardwareAccelerationType))\n                {\n                    var inputFormat = GetInputFormat(state.InputContainer);\n                    if (!string.IsNullOrEmpty(inputFormat))\n                    {\n                        inputModifier += \" -f \" + inputFormat;\n                    }\n                }\n            }\n\n            if (state.MediaSource.RequiresLooping)\n            {\n                inputModifier += \" -stream_loop -1 -reconnect_at_eof 1 -reconnect_streamed 1 -reconnect_delay_max 2\";\n            }\n\n            return inputModifier;\n        }\n\n        public void AttachMediaSourceInfo(\n            EncodingJobInfo state,\n            EncodingOptions encodingOptions,\n            MediaSourceInfo mediaSource,\n            string requestedUrl)\n        {\n            if (state == null)\n            {\n                throw new ArgumentNullException(nameof(state));\n            }\n\n            if (mediaSource == null)\n            {\n                throw new ArgumentNullException(nameof(mediaSource));\n            }\n\n            var path = mediaSource.Path;\n            var protocol = mediaSource.Protocol;\n\n            if (!string.IsNullOrEmpty(mediaSource.EncoderPath) && mediaSource.EncoderProtocol.HasValue)\n            {\n                path = mediaSource.EncoderPath;\n                protocol = mediaSource.EncoderProtocol.Value;\n            }\n\n            state.MediaPath = path;\n            state.InputProtocol = protocol;\n            state.InputContainer = mediaSource.Container;\n            state.RunTimeTicks = mediaSource.RunTimeTicks;\n            state.RemoteHttpHeaders = mediaSource.RequiredHttpHeaders;\n\n            state.IsoType = mediaSource.IsoType;\n\n            if (mediaSource.Timestamp.HasValue)\n            {\n                state.InputTimestamp = mediaSource.Timestamp.Value;\n            }\n\n            state.RunTimeTicks = mediaSource.RunTimeTicks;\n            state.RemoteHttpHeaders = mediaSource.RequiredHttpHeaders;\n            state.ReadInputAtNativeFramerate = mediaSource.ReadAtNativeFramerate;\n\n            if (state.ReadInputAtNativeFramerate\n                || (mediaSource.Protocol == MediaProtocol.File\n                && string.Equals(mediaSource.Container, \"wtv\", StringComparison.OrdinalIgnoreCase)))\n            {\n                state.InputVideoSync = \"-1\";\n                state.InputAudioSync = \"1\";\n            }\n\n            if (string.Equals(mediaSource.Container, \"wma\", StringComparison.OrdinalIgnoreCase)\n                || string.Equals(mediaSource.Container, \"asf\", StringComparison.OrdinalIgnoreCase))\n            {\n                // Seeing some stuttering when transcoding wma to audio-only HLS\n                state.InputAudioSync = \"1\";\n            }\n\n            var mediaStreams = mediaSource.MediaStreams;\n\n            if (state.IsVideoRequest)\n            {\n                var videoRequest = state.BaseRequest;\n\n                if (string.IsNullOrEmpty(videoRequest.VideoCodec))\n                {\n                    if (string.IsNullOrEmpty(requestedUrl))\n                    {\n                        requestedUrl = \"test.\" + videoRequest.Container;\n                    }\n\n                    videoRequest.VideoCodec = InferVideoCodec(requestedUrl);\n                }\n\n                state.VideoStream = GetMediaStream(mediaStreams, videoRequest.VideoStreamIndex, MediaStreamType.Video);\n                state.SubtitleStream = GetMediaStream(mediaStreams, videoRequest.SubtitleStreamIndex, MediaStreamType.Subtitle, false);\n                state.SubtitleDeliveryMethod = videoRequest.SubtitleMethod;\n                state.AudioStream = GetMediaStream(mediaStreams, videoRequest.AudioStreamIndex, MediaStreamType.Audio);\n\n                if (state.SubtitleStream != null && !state.SubtitleStream.IsExternal)\n                {\n                    state.InternalSubtitleStreamOffset = mediaStreams.Where(i => i.Type == MediaStreamType.Subtitle && !i.IsExternal).ToList().IndexOf(state.SubtitleStream);\n                }\n\n                EnforceResolutionLimit(state);\n\n                NormalizeSubtitleEmbed(state);\n            }\n            else\n            {\n                state.AudioStream = GetMediaStream(mediaStreams, null, MediaStreamType.Audio, true);\n            }\n\n            state.MediaSource = mediaSource;\n\n            var request = state.BaseRequest;\n            var supportedAudioCodecs = state.SupportedAudioCodecs;\n            if (request != null && supportedAudioCodecs != null && supportedAudioCodecs.Length > 0)\n            {\n                var supportedAudioCodecsList = supportedAudioCodecs.ToList();\n\n                ShiftAudioCodecsIfNeeded(supportedAudioCodecsList, state.AudioStream);\n\n                state.SupportedAudioCodecs = supportedAudioCodecsList.ToArray();\n\n                request.AudioCodec = state.SupportedAudioCodecs.FirstOrDefault(i => _mediaEncoder.CanEncodeToAudioCodec(i))\n                    ?? state.SupportedAudioCodecs.FirstOrDefault();\n            }\n\n            var supportedVideoCodecs = state.SupportedVideoCodecs;\n            if (request != null && supportedVideoCodecs != null && supportedVideoCodecs.Length > 0)\n            {\n                var supportedVideoCodecsList = supportedVideoCodecs.ToList();\n\n                ShiftVideoCodecsIfNeeded(supportedVideoCodecsList, encodingOptions);\n\n                state.SupportedVideoCodecs = supportedVideoCodecsList.ToArray();\n\n                request.VideoCodec = state.SupportedVideoCodecs.FirstOrDefault();\n            }\n        }\n\n        private void ShiftAudioCodecsIfNeeded(List<string> audioCodecs, MediaStream audioStream)\n        {\n            // No need to shift if there is only one supported audio codec.\n            if (audioCodecs.Count < 2)\n            {\n                return;\n            }\n\n            var inputChannels = audioStream is null ? 6 : audioStream.Channels ?? 6;\n            var shiftAudioCodecs = new List<string>();\n            if (inputChannels >= 6)\n            {\n                // DTS and TrueHD are not supported by HLS\n                // Keep them in the supported codecs list, but shift them to the end of the list so that if transcoding happens, another codec is used\n                shiftAudioCodecs.Add(\"dca\");\n                shiftAudioCodecs.Add(\"truehd\");\n            }\n            else\n            {\n                // Transcoding to 2ch ac3 or eac3 almost always causes a playback failure\n                // Keep them in the supported codecs list, but shift them to the end of the list so that if transcoding happens, another codec is used\n                shiftAudioCodecs.Add(\"ac3\");\n                shiftAudioCodecs.Add(\"eac3\");\n            }\n\n            if (audioCodecs.All(i => shiftAudioCodecs.Contains(i, StringComparison.OrdinalIgnoreCase)))\n            {\n                return;\n            }\n\n            while (shiftAudioCodecs.Contains(audioCodecs[0], StringComparison.OrdinalIgnoreCase))\n            {\n                var removed = shiftAudioCodecs[0];\n                audioCodecs.RemoveAt(0);\n                audioCodecs.Add(removed);\n            }\n        }\n\n        private void ShiftVideoCodecsIfNeeded(List<string> videoCodecs, EncodingOptions encodingOptions)\n        {\n            // Shift hevc/h265 to the end of list if hevc encoding is not allowed.\n            if (encodingOptions.AllowHevcEncoding)\n            {\n                return;\n            }\n\n            // No need to shift if there is only one supported video codec.\n            if (videoCodecs.Count < 2)\n            {\n                return;\n            }\n\n            var shiftVideoCodecs = new[] { \"hevc\", \"h265\" };\n            if (videoCodecs.All(i => shiftVideoCodecs.Contains(i, StringComparison.OrdinalIgnoreCase)))\n            {\n                return;\n            }\n\n            while (shiftVideoCodecs.Contains(videoCodecs[0], StringComparison.OrdinalIgnoreCase))\n            {\n                var removed = shiftVideoCodecs[0];\n                videoCodecs.RemoveAt(0);\n                videoCodecs.Add(removed);\n            }\n        }\n\n        private void NormalizeSubtitleEmbed(EncodingJobInfo state)\n        {\n            if (state.SubtitleStream == null || state.SubtitleDeliveryMethod != SubtitleDeliveryMethod.Embed)\n            {\n                return;\n            }\n\n            // This is tricky to remux in, after converting to dvdsub it's not positioned correctly\n            // Therefore, let's just burn it in\n            if (string.Equals(state.SubtitleStream.Codec, \"DVBSUB\", StringComparison.OrdinalIgnoreCase))\n            {\n                state.SubtitleDeliveryMethod = SubtitleDeliveryMethod.Encode;\n            }\n        }\n\n        public string GetSubtitleEmbedArguments(EncodingJobInfo state)\n        {\n            if (state.SubtitleStream == null || state.SubtitleDeliveryMethod != SubtitleDeliveryMethod.Embed)\n            {\n                return string.Empty;\n            }\n\n            var format = state.SupportedSubtitleCodecs.FirstOrDefault();\n            string codec;\n\n            if (string.IsNullOrEmpty(format) || string.Equals(format, state.SubtitleStream.Codec, StringComparison.OrdinalIgnoreCase))\n            {\n                codec = \"copy\";\n            }\n            else\n            {\n                codec = format;\n            }\n\n            return \" -codec:s:0 \" + codec + \" -disposition:s:0 default\";\n        }\n\n        public string GetProgressiveVideoFullCommandLine(EncodingJobInfo state, EncodingOptions encodingOptions, string outputPath, string defaultPreset)\n        {\n            // Get the output codec name\n            var videoCodec = GetVideoEncoder(state, encodingOptions);\n\n            var format = string.Empty;\n            var keyFrame = string.Empty;\n\n            if (string.Equals(Path.GetExtension(outputPath), \".mp4\", StringComparison.OrdinalIgnoreCase)\n                && state.BaseRequest.Context == EncodingContext.Streaming)\n            {\n                // Comparison: https://github.com/jansmolders86/mediacenterjs/blob/master/lib/transcoding/desktop.js\n                format = \" -f mp4 -movflags frag_keyframe+empty_moov\";\n            }\n\n            var threads = GetNumberOfThreads(state, encodingOptions, videoCodec);\n\n            var inputModifier = GetInputModifier(state, encodingOptions, null);\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"{0} {1}{2} {3} {4} -map_metadata -1 -map_chapters -1 -threads {5} {6}{7}{8} -y \\\"{9}\\\"\",\n                inputModifier,\n                GetInputArgument(state, encodingOptions, null),\n                keyFrame,\n                GetMapArgs(state),\n                GetProgressiveVideoArguments(state, encodingOptions, videoCodec, defaultPreset),\n                threads,\n                GetProgressiveVideoAudioArguments(state, encodingOptions),\n                GetSubtitleEmbedArguments(state),\n                format,\n                outputPath).Trim();\n        }\n\n        public string GetOutputFFlags(EncodingJobInfo state)\n        {\n            var flags = new List<string>();\n            if (state.GenPtsOutput)\n            {\n                flags.Add(\"+genpts\");\n            }\n\n            if (flags.Count > 0)\n            {\n                return \" -fflags \" + string.Join(string.Empty, flags);\n            }\n\n            return string.Empty;\n        }\n\n        public string GetProgressiveVideoArguments(EncodingJobInfo state, EncodingOptions encodingOptions, string videoCodec, string defaultPreset)\n        {\n            var args = \"-codec:v:0 \" + videoCodec;\n\n            if (state.BaseRequest.EnableMpegtsM2TsMode)\n            {\n                args += \" -mpegts_m2ts_mode 1\";\n            }\n\n            if (IsCopyCodec(videoCodec))\n            {\n                if (state.VideoStream != null\n                    && string.Equals(state.OutputContainer, \"ts\", StringComparison.OrdinalIgnoreCase)\n                    && !string.Equals(state.VideoStream.NalLengthSize, \"0\", StringComparison.OrdinalIgnoreCase))\n                {\n                    string bitStreamArgs = GetBitStreamArgs(state.VideoStream);\n                    if (!string.IsNullOrEmpty(bitStreamArgs))\n                    {\n                        args += \" \" + bitStreamArgs;\n                    }\n                }\n\n                if (state.RunTimeTicks.HasValue && state.BaseRequest.CopyTimestamps)\n                {\n                    args += \" -copyts -avoid_negative_ts disabled -start_at_zero\";\n                }\n\n                if (!state.RunTimeTicks.HasValue)\n                {\n                    args += \" -fflags +genpts\";\n                }\n            }\n            else\n            {\n                var keyFrameArg = string.Format(\n                    CultureInfo.InvariantCulture,\n                    \" -force_key_frames \\\"expr:gte(t,n_forced*{0})\\\"\",\n                    5);\n\n                args += keyFrameArg;\n\n                var hasGraphicalSubs = state.SubtitleStream != null && !state.SubtitleStream.IsTextSubtitleStream && state.SubtitleDeliveryMethod == SubtitleDeliveryMethod.Encode;\n\n                var hasCopyTs = false;\n\n                // video processing filters.\n                var videoProcessParam = GetVideoProcessingFilterParam(state, encodingOptions, videoCodec);\n\n                var negativeMapArgs = GetNegativeMapArgsByFilters(state, videoProcessParam);\n\n                args = negativeMapArgs + args + videoProcessParam;\n\n                hasCopyTs = videoProcessParam.Contains(\"copyts\", StringComparison.OrdinalIgnoreCase);\n\n                if (state.RunTimeTicks.HasValue && state.BaseRequest.CopyTimestamps)\n                {\n                    if (!hasCopyTs)\n                    {\n                        args += \" -copyts\";\n                    }\n\n                    args += \" -avoid_negative_ts disabled\";\n\n                    if (!(state.SubtitleStream != null && state.SubtitleStream.IsExternal && !state.SubtitleStream.IsTextSubtitleStream))\n                    {\n                        args += \" -start_at_zero\";\n                    }\n                }\n\n                var qualityParam = GetVideoQualityParam(state, videoCodec, encodingOptions, defaultPreset);\n\n                if (!string.IsNullOrEmpty(qualityParam))\n                {\n                    args += \" \" + qualityParam.Trim();\n                }\n            }\n\n            if (!string.IsNullOrEmpty(state.OutputVideoSync))\n            {\n                args += \" -vsync \" + state.OutputVideoSync;\n            }\n\n            args += GetOutputFFlags(state);\n\n            return args;\n        }\n\n        public string GetProgressiveVideoAudioArguments(EncodingJobInfo state, EncodingOptions encodingOptions)\n        {\n            // If the video doesn't have an audio stream, return a default.\n            if (state.AudioStream == null && state.VideoStream != null)\n            {\n                return string.Empty;\n            }\n\n            // Get the output codec name\n            var codec = GetAudioEncoder(state);\n\n            var args = \"-codec:a:0 \" + codec;\n\n            if (IsCopyCodec(codec))\n            {\n                return args;\n            }\n\n            // Add the number of audio channels\n            var channels = state.OutputAudioChannels;\n\n            if (channels.HasValue)\n            {\n                args += \" -ac \" + channels.Value;\n            }\n\n            var bitrate = state.OutputAudioBitrate;\n\n            if (bitrate.HasValue && !LosslessAudioCodecs.Contains(codec, StringComparison.OrdinalIgnoreCase))\n            {\n                args += \" -ab \" + bitrate.Value.ToString(CultureInfo.InvariantCulture);\n            }\n\n            if (state.OutputAudioSampleRate.HasValue)\n            {\n                args += \" -ar \" + state.OutputAudioSampleRate.Value.ToString(CultureInfo.InvariantCulture);\n            }\n\n            args += GetAudioFilterParam(state, encodingOptions);\n\n            return args;\n        }\n\n        public string GetProgressiveAudioFullCommandLine(EncodingJobInfo state, EncodingOptions encodingOptions, string outputPath)\n        {\n            var audioTranscodeParams = new List<string>();\n\n            var bitrate = state.OutputAudioBitrate;\n            var channels = state.OutputAudioChannels;\n            var outputCodec = state.OutputAudioCodec;\n\n            if (bitrate.HasValue && !LosslessAudioCodecs.Contains(outputCodec, StringComparison.OrdinalIgnoreCase))\n            {\n                audioTranscodeParams.Add(\"-ab \" + bitrate.Value.ToString(CultureInfo.InvariantCulture));\n            }\n\n            if (state.OutputAudioChannels.HasValue)\n            {\n                audioTranscodeParams.Add(\"-ac \" + state.OutputAudioChannels.Value.ToString(CultureInfo.InvariantCulture));\n            }\n\n            if (!string.IsNullOrEmpty(outputCodec))\n            {\n                audioTranscodeParams.Add(\"-acodec \" + GetAudioEncoder(state));\n            }\n\n            if (!string.Equals(outputCodec, \"opus\", StringComparison.OrdinalIgnoreCase))\n            {\n                // opus only supports specific sampling rates\n                var sampleRate = state.OutputAudioSampleRate;\n                if (sampleRate.HasValue)\n                {\n                    var sampleRateValue = sampleRate.Value switch\n                    {\n                        <= 8000 => 8000,\n                        <= 12000 => 12000,\n                        <= 16000 => 16000,\n                        <= 24000 => 24000,\n                        _ => 48000\n                    };\n\n                    audioTranscodeParams.Add(\"-ar \" + sampleRateValue.ToString(CultureInfo.InvariantCulture));\n                }\n            }\n\n            var threads = GetNumberOfThreads(state, encodingOptions, null);\n\n            var inputModifier = GetInputModifier(state, encodingOptions, null);\n\n            return string.Format(\n                CultureInfo.InvariantCulture,\n                \"{0} {1}{7}{8} -threads {2}{3} {4} -id3v2_version 3 -write_id3v1 1{6} -y \\\"{5}\\\"\",\n                inputModifier,\n                GetInputArgument(state, encodingOptions, null),\n                threads,\n                \" -vn\",\n                string.Join(' ', audioTranscodeParams),\n                outputPath,\n                string.Empty,\n                string.Empty,\n                string.Empty).Trim();\n        }\n\n        public static int FindIndex(IReadOnlyList<MediaStream> mediaStreams, MediaStream streamToFind)\n        {\n            var index = 0;\n            var length = mediaStreams.Count;\n\n            for (var i = 0; i < length; i++)\n            {\n                var currentMediaStream = mediaStreams[i];\n                if (currentMediaStream == streamToFind)\n                {\n                    return index;\n                }\n\n                if (string.Equals(currentMediaStream.Path, streamToFind.Path, StringComparison.Ordinal))\n                {\n                    index++;\n                }\n            }\n\n            return -1;\n        }\n\n        public static bool IsCopyCodec(string codec)\n        {\n            return string.Equals(codec, \"copy\", StringComparison.OrdinalIgnoreCase);\n        }\n    }\n}\n"], "filenames": ["Jellyfin.Api/Controllers/AudioController.cs", "Jellyfin.Api/Controllers/DynamicHlsController.cs", "Jellyfin.Api/Controllers/UniversalAudioController.cs", "Jellyfin.Api/Controllers/VideosController.cs", "MediaBrowser.Controller/MediaEncoding/EncodingHelper.cs"], "buggy_code_start_loc": [94, 177, 105, 321, 27], "buggy_code_end_loc": [302, 1329, 112, 620, 524], "fixing_code_start_loc": [94, 177, 105, 321, 28], "fixing_code_end_loc": [302, 1329, 112, 620, 540], "type": "CWE-88", "message": "Jellyfin is a Free Software Media System for managing and streaming media. In affected versions there is an argument injection in the VideosController, specifically the `/Videos/<itemId>/stream` and `/Videos/<itemId>/stream.<container>` endpoints which are present in the current Jellyfin version. Additional endpoints in the AudioController might also be vulnerable, as they differ only slightly in execution. Those endpoints are reachable by an unauthenticated user. In order to exploit this vulnerability an unauthenticated attacker has to guess an itemId, which is a completely random GUID. It\u2019s a very unlikely case even for a large media database with lots of items. Without an additional information leak, this vulnerability shouldn\u2019t be directly exploitable, even if the instance is reachable from the Internet. There are a lot of query parameters that get accepted by the method. At least two of those, videoCodec and audioCodec are vulnerable to the argument injection. The values can be traced through a lot of code and might be changed in the process. However, the fallback is to always use them as-is, which means we can inject our own arguments. Those arguments land in the command line of FFmpeg. Because UseShellExecute is always set to false, we can\u2019t simply terminate the FFmpeg command and execute our own. It should only be possible to add additional arguments to FFmpeg, which is powerful enough as it stands. There is probably a way of overwriting an arbitrary file with malicious content. This vulnerability has been addressed in version 10.8.13. Users are advised to upgrade. There are no known workarounds for this vulnerability.", "other": {"cve": {"id": "CVE-2023-49096", "sourceIdentifier": "security-advisories@github.com", "published": "2023-12-06T20:15:07.287", "lastModified": "2023-12-12T16:09:48.753", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Jellyfin is a Free Software Media System for managing and streaming media. In affected versions there is an argument injection in the VideosController, specifically the `/Videos/<itemId>/stream` and `/Videos/<itemId>/stream.<container>` endpoints which are present in the current Jellyfin version. Additional endpoints in the AudioController might also be vulnerable, as they differ only slightly in execution. Those endpoints are reachable by an unauthenticated user. In order to exploit this vulnerability an unauthenticated attacker has to guess an itemId, which is a completely random GUID. It\u2019s a very unlikely case even for a large media database with lots of items. Without an additional information leak, this vulnerability shouldn\u2019t be directly exploitable, even if the instance is reachable from the Internet. There are a lot of query parameters that get accepted by the method. At least two of those, videoCodec and audioCodec are vulnerable to the argument injection. The values can be traced through a lot of code and might be changed in the process. However, the fallback is to always use them as-is, which means we can inject our own arguments. Those arguments land in the command line of FFmpeg. Because UseShellExecute is always set to false, we can\u2019t simply terminate the FFmpeg command and execute our own. It should only be possible to add additional arguments to FFmpeg, which is powerful enough as it stands. There is probably a way of overwriting an arbitrary file with malicious content. This vulnerability has been addressed in version 10.8.13. Users are advised to upgrade. There are no known workarounds for this vulnerability."}, {"lang": "es", "value": "Jellyfin es un sistema multimedia de software libre para gestionar y transmitir medios. En las versiones afectadas hay una inyecci\u00f3n de argumentos en VideosController, espec\u00edficamente los endpoints `/Videos//stream` y `/Videos//stream.` que est\u00e1n presentes en la versi\u00f3n actual de Jellyfin. Los endpoints adicionales en AudioController tambi\u00e9n pueden ser vulnerables, ya que difieren s\u00f3lo ligeramente en la ejecuci\u00f3n. Un usuario no autenticado puede acceder a esos endpoints. Para aprovechar esta vulnerabilidad, un atacante no autenticado debe adivinar un itemId, que es un GUID completamente aleatorio. Es un caso muy improbable incluso para una gran base de datos de medios con muchos elementos. Sin una filtraci\u00f3n de informaci\u00f3n adicional, esta vulnerabilidad no deber\u00eda ser explotable directamente, incluso si se puede acceder a la instancia desde Internet. Hay muchos par\u00e1metros de consulta que el m\u00e9todo acepta. Al menos dos de ellos, videoCodec y audioCodec, son vulnerables a la inyecci\u00f3n de argumentos. Los valores se pueden rastrear a trav\u00e9s de una gran cantidad de c\u00f3digo y pueden cambiarse en el proceso. Sin embargo, la alternativa es usarlos siempre tal como est\u00e1n, lo que significa que podemos inyectar nuestros propios argumentos. Esos argumentos llegan a la l\u00ednea de comando de FFmpeg. Debido a que UseShellExecute siempre est\u00e1 configurado en falso, no podemos simplemente terminar el comando FFmpeg y ejecutar el nuestro. S\u00f3lo deber\u00eda ser posible agregar argumentos adicionales a FFmpeg, que es lo suficientemente poderoso tal como est\u00e1. Probablemente exista una forma de sobrescribir un archivo arbitrario con contenido malicioso. Esta vulnerabilidad se ha solucionado en la versi\u00f3n 10.8.13. Se recomienda a los usuarios que actualicen. No se conocen workarounds para esta vulnerabilidad."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:L", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "LOW", "baseScore": 7.7, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.5}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-88"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:jellyfin:jellyfin:*:*:*:*:*:*:*:*", "versionEndExcluding": "10.8.13", "matchCriteriaId": "93D6F598-55D9-4041-BED8-4448226B5EFF"}]}]}], "references": [{"url": "https://cwe.mitre.org/data/definitions/88.html", "source": "security-advisories@github.com", "tags": ["Not Applicable"]}, {"url": "https://en.wikipedia.org/wiki/Pass_the_hash", "source": "security-advisories@github.com", "tags": ["Not Applicable"]}, {"url": "https://ffmpeg.org/ffmpeg-filters.html#drawtext-1", "source": "security-advisories@github.com", "tags": ["Not Applicable"]}, {"url": "https://github.com/jellyfin/jellyfin/commit/a656799dc879d16d21bf2ce7ad412ebd5d45394a", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/jellyfin/jellyfin/issues/5415", "source": "security-advisories@github.com", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/jellyfin/jellyfin/security/advisories/GHSA-866x-wj5j-2vf4", "source": "security-advisories@github.com", "tags": ["Exploit", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/jellyfin/jellyfin/commit/a656799dc879d16d21bf2ce7ad412ebd5d45394a"}}
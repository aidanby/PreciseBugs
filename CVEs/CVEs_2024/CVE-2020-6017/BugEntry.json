{"buggy_code": ["//====== Copyright Valve Corporation, All rights reserved. ====================\n\n#include \"steamnetworkingsockets_snp.h\"\n#include \"steamnetworkingsockets_connections.h\"\n#include \"crypto.h\"\n\n// memdbgon must be the last include file in a .cpp file!!!\n#include \"tier0/memdbgon.h\"\n\nnamespace SteamNetworkingSocketsLib {\n\nstruct SNPAckSerializerHelper\n{\n\tstruct Block\n\t{\n\t\t// Acks and nacks count to serialize\n\t\tuint32 m_nAck;\n\t\tuint32 m_nNack;\n\n\t\t// What to put in the header if we use this as the\n\t\t// highest numbered block\n\t\tuint32 m_nLatestPktNum; // Lower 32-bits.  We might send even fewer bits\n\t\tuint16 m_nEncodedTimeSinceLatestPktNum;\n\n\t\t// Total size of ack data up to this point:\n\t\t// header, all previous blocks, and this block\n\t\tint16 m_cbTotalEncodedSize;\n\t};\n\n\tenum { k_cbHeaderSize = 5 };\n\tenum { k_nMaxBlocks = 64 };\n\tint m_nBlocks;\n\tint m_nBlocksNeedToAck; // Number of blocks we really need to send now.\n\tBlock m_arBlocks[ k_nMaxBlocks ];\n\n\tstatic uint16 EncodeTimeSince( SteamNetworkingMicroseconds usecNow, SteamNetworkingMicroseconds usecWhenSentLast )\n\t{\n\n\t\t// Encode time since last\n\t\tSteamNetworkingMicroseconds usecElapsedSinceLast = usecNow - usecWhenSentLast;\n\t\tAssert( usecElapsedSinceLast >= 0 );\n\t\tAssert( usecNow > 0x20000*k_usecAckDelayPrecision ); // We should never have small timestamp values.  A timestamp of zero should always be \"a long time ago\"\n\t\tif ( usecElapsedSinceLast > 0xfffell<<k_nAckDelayPrecisionShift )\n\t\t\treturn 0xffff;\n\t\treturn uint16( usecElapsedSinceLast >> k_nAckDelayPrecisionShift );\n\t}\n\n};\n\n// Fetch ping, and handle two edge cases:\n// - if we don't have an estimate, just be relatively conservative\n// - clamp to minimum\ninline SteamNetworkingMicroseconds GetUsecPingWithFallback( CSteamNetworkConnectionBase *pConnection )\n{\n\tint nPingMS = pConnection->m_statsEndToEnd.m_ping.m_nSmoothedPing;\n\tif ( nPingMS < 0 )\n\t\treturn 200*1000; // no estimate, just be conservative\n\tif ( nPingMS < 1 )\n\t\treturn 500; // less than 1ms.  Make sure we don't blow up, though, since they are asking for microsecond resolution.  We should just keep our pings with microsecond resolution!\n\treturn nPingMS*1000;\n}\n\n\nvoid SSNPSenderState::Shutdown()\n{\n\tm_unackedReliableMessages.PurgeMessages();\n\tm_messagesQueued.PurgeMessages();\n\tm_mapInFlightPacketsByPktNum.clear();\n\tm_listInFlightReliableRange.clear();\n\tm_cbPendingUnreliable = 0;\n\tm_cbPendingReliable = 0;\n\tm_cbSentUnackedReliable = 0;\n}\n\n//-----------------------------------------------------------------------------\nvoid SSNPSenderState::RemoveAckedReliableMessageFromUnackedList()\n{\n\n\t// Trim messages from the head that have been acked.\n\t// Note that in theory we could have a message in the middle that\n\t// has been acked.  But it's not worth the time to go looking for them,\n\t// just to free up a bit of memory early.  We'll get to it once the earlier\n\t// messages have been acked.\n\twhile ( !m_unackedReliableMessages.empty() )\n\t{\n\t\tCSteamNetworkingMessage *pMsg = m_unackedReliableMessages.m_pFirst;\n\t\tAssert( pMsg->SNPSend_ReliableStreamPos() > 0 );\n\t\tint64 nReliableEnd = pMsg->SNPSend_ReliableStreamPos() + pMsg->m_cbSize;\n\n\t\t// Are we backing a range that is in flight (and thus we might need\n\t\t// to resend?)\n\t\tif ( !m_listInFlightReliableRange.empty() )\n\t\t{\n\t\t\tauto head = m_listInFlightReliableRange.begin();\n\t\t\tAssert( head->first.m_nBegin >= pMsg->SNPSend_ReliableStreamPos() );\n\t\t\tif ( head->second == pMsg )\n\t\t\t{\n\t\t\t\tAssert( head->first.m_nBegin < nReliableEnd );\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tAssert( head->first.m_nBegin >= nReliableEnd );\n\t\t}\n\n\t\t// Are we backing the next range that is ready for resend now?\n\t\tif ( !m_listReadyRetryReliableRange.empty() )\n\t\t{\n\t\t\tauto head = m_listReadyRetryReliableRange.begin();\n\t\t\tAssert( head->first.m_nBegin >= pMsg->SNPSend_ReliableStreamPos() );\n\t\t\tif ( head->second == pMsg )\n\t\t\t{\n\t\t\t\tAssert( head->first.m_nBegin < nReliableEnd );\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tAssert( head->first.m_nBegin >= nReliableEnd );\n\t\t}\n\n\t\t// We're all done!\n\t\tDbgVerify( m_unackedReliableMessages.pop_front() == pMsg );\n\t\tpMsg->Release();\n\t}\n}\n\n//-----------------------------------------------------------------------------\nSSNPSenderState::SSNPSenderState()\n{\n\t// Setup the table of inflight packets with a sentinel.\n\tm_mapInFlightPacketsByPktNum.clear();\n\tSNPInFlightPacket_t &sentinel = m_mapInFlightPacketsByPktNum[INT64_MIN];\n\tsentinel.m_bNack = false;\n\tsentinel.m_pTransport = nullptr;\n\tsentinel.m_usecWhenSent = 0;\n\tm_itNextInFlightPacketToTimeout = m_mapInFlightPacketsByPktNum.end();\n\tDebugCheckInFlightPacketMap();\n}\n\n#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 0\nvoid SSNPSenderState::DebugCheckInFlightPacketMap() const\n{\n\tAssert( !m_mapInFlightPacketsByPktNum.empty() );\n\tbool bFoundNextToTimeout = false;\n\tauto it = m_mapInFlightPacketsByPktNum.begin();\n\tAssert( it->first == INT64_MIN );\n\tAssert( m_itNextInFlightPacketToTimeout != it );\n\tint64 prevPktNum = it->first;\n\tSteamNetworkingMicroseconds prevWhenSent = it->second.m_usecWhenSent;\n\twhile ( ++it != m_mapInFlightPacketsByPktNum.end() )\n\t{\n\t\tAssert( prevPktNum < it->first );\n\t\tAssert( prevWhenSent <= it->second.m_usecWhenSent );\n\t\tif ( it == m_itNextInFlightPacketToTimeout )\n\t\t{\n\t\t\tAssert( !bFoundNextToTimeout );\n\t\t\tbFoundNextToTimeout = true;\n\t\t}\n\t\tprevPktNum = it->first;\n\t\tprevWhenSent = it->second.m_usecWhenSent;\n\t}\n\tif ( !bFoundNextToTimeout )\n\t{\n\t\tAssert( m_itNextInFlightPacketToTimeout == m_mapInFlightPacketsByPktNum.end() );\n\t}\n}\n#endif\n\n//-----------------------------------------------------------------------------\nSSNPReceiverState::SSNPReceiverState()\n{\n\t// Init packet gaps with a sentinel\n\tSSNPPacketGap &sentinel = m_mapPacketGaps[INT64_MAX];\n\tsentinel.m_nEnd = INT64_MAX; // Fixed value\n\tsentinel.m_usecWhenOKToNack = INT64_MAX; // Fixed value, for when there is nothing left to nack\n\tsentinel.m_usecWhenAckPrior = INT64_MAX; // Time when we need to flush a report on all lower-numbered packets\n\n\t// Point at the sentinel\n\tm_itPendingAck = m_mapPacketGaps.end();\n\t--m_itPendingAck;\n\tm_itPendingNack = m_itPendingAck;\n}\n\n//-----------------------------------------------------------------------------\nvoid SSNPReceiverState::Shutdown()\n{\n\tm_mapUnreliableSegments.clear();\n\tm_bufReliableStream.clear();\n\tm_mapReliableStreamGaps.clear();\n\tm_mapPacketGaps.clear();\n}\n\n//-----------------------------------------------------------------------------\nvoid CSteamNetworkConnectionBase::SNP_InitializeConnection( SteamNetworkingMicroseconds usecNow )\n{\n\tm_senderState.TokenBucket_Init( usecNow );\n\n\tSteamNetworkingMicroseconds usecPing = GetUsecPingWithFallback( this );\n\n\t/*\n\t* Compute the initial sending rate X_init in the manner of RFC 3390:\n\t*\n\t*\tX_init  =  min(4 * s, max(2 * s, 4380 bytes)) / RTT\n\t*\n\t* Note that RFC 3390 uses MSS, RFC 4342 refers to RFC 3390, and rfc3448bis\n\t* (rev-02) clarifies the use of RFC 3390 with regard to the above formula.\n\t*/\n\tAssert( usecPing > 0 );\n\tint64 w_init = Clamp( 4380, 2 * k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend, 4 * k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend );\n\tm_senderState.m_n_x = int( k_nMillion * w_init / usecPing );\n\n\t// Go ahead and clamp it now\n\tSNP_ClampSendRate();\n}\n\n//-----------------------------------------------------------------------------\nvoid CSteamNetworkConnectionBase::SNP_ShutdownConnection()\n{\n\tm_senderState.Shutdown();\n\tm_receiverState.Shutdown();\n}\n\n//-----------------------------------------------------------------------------\nint64 CSteamNetworkConnectionBase::SNP_SendMessage( CSteamNetworkingMessage *pSendMessage, SteamNetworkingMicroseconds usecNow, bool *pbThinkImmediately )\n{\n\tint cbData = (int)pSendMessage->m_cbSize;\n\n\t// Assume we won't want to wake up immediately\n\tif ( pbThinkImmediately )\n\t\t*pbThinkImmediately = false;\n\n\t// Check if we're full\n\tif ( m_senderState.PendingBytesTotal() + cbData > m_connectionConfig.m_SendBufferSize.Get() )\n\t{\n\t\tSpewWarningRateLimited( usecNow, \"Connection already has %u bytes pending, cannot queue any more messages\\n\", m_senderState.PendingBytesTotal() );\n\t\tpSendMessage->Release();\n\t\treturn -k_EResultLimitExceeded; \n\t}\n\n\t// Check if they try to send a really large message\n\tif ( cbData > k_cbMaxUnreliableMsgSize && !( pSendMessage->m_nFlags & k_nSteamNetworkingSend_Reliable )  )\n\t{\n\t\tSpewWarningRateLimited( usecNow, \"Trying to send a very large (%d bytes) unreliable message.  Sending as reliable instead.\\n\", cbData );\n\t\tpSendMessage->m_nFlags |= k_nSteamNetworkingSend_Reliable;\n\t}\n\n\tif ( pSendMessage->m_nFlags & k_nSteamNetworkingSend_NoDelay )\n\t{\n\t\t// FIXME - need to check how much data is currently pending, and return\n\t\t// k_EResultIgnored if we think it's going to be a while before this\n\t\t// packet goes on the wire.\n\t}\n\n\t// First, accumulate tokens, and also limit to reasonable burst\n\t// if we weren't already waiting to send\n\tSNP_ClampSendRate();\n\tSNP_TokenBucket_Accumulate( usecNow );\n\n\t// Assign a message number\n\tpSendMessage->m_nMessageNumber = ++m_senderState.m_nLastSentMsgNum;\n\n\t// Reliable, or unreliable?\n\tif ( pSendMessage->m_nFlags & k_nSteamNetworkingSend_Reliable )\n\t{\n\t\tpSendMessage->SNPSend_SetReliableStreamPos( m_senderState.m_nReliableStreamPos );\n\n\t\t// Generate the header\n\t\tbyte *hdr = pSendMessage->SNPSend_ReliableHeader();\n\t\thdr[0] = 0;\n\t\tbyte *hdrEnd = hdr+1;\n\t\tint64 nMsgNumGap = pSendMessage->m_nMessageNumber - m_senderState.m_nLastSendMsgNumReliable;\n\t\tAssert( nMsgNumGap >= 1 );\n\t\tif ( nMsgNumGap > 1 )\n\t\t{\n\t\t\thdrEnd = SerializeVarInt( hdrEnd, (uint64)nMsgNumGap );\n\t\t\thdr[0] |= 0x40;\n\t\t}\n\t\tif ( cbData < 0x20 )\n\t\t{\n\t\t\thdr[0] |= (byte)cbData;\n\t\t}\n\t\telse\n\t\t{\n\t\t\thdr[0] |= (byte)( 0x20 | ( cbData & 0x1f ) );\n\t\t\thdrEnd = SerializeVarInt( hdrEnd, cbData>>5U );\n\t\t}\n\t\tpSendMessage->m_cbSNPSendReliableHeader = hdrEnd - hdr;\n\n\t\t// Grow the total size of the message by the header\n\t\tpSendMessage->m_cbSize += pSendMessage->m_cbSNPSendReliableHeader;\n\n\t\t// Advance stream pointer\n\t\tm_senderState.m_nReliableStreamPos += pSendMessage->m_cbSize;\n\n\t\t// Update stats\n\t\t++m_senderState.m_nMessagesSentReliable;\n\t\tm_senderState.m_cbPendingReliable += pSendMessage->m_cbSize;\n\n\t\t// Remember last sent reliable message number, so we can know how to\n\t\t// encode the next one\n\t\tm_senderState.m_nLastSendMsgNumReliable = pSendMessage->m_nMessageNumber;\n\n\t\tAssert( pSendMessage->SNPSend_IsReliable() );\n\t}\n\telse\n\t{\n\t\tpSendMessage->SNPSend_SetReliableStreamPos( 0 );\n\t\tpSendMessage->m_cbSNPSendReliableHeader = 0;\n\n\t\t++m_senderState.m_nMessagesSentUnreliable;\n\t\tm_senderState.m_cbPendingUnreliable += pSendMessage->m_cbSize;\n\n\t\tAssert( !pSendMessage->SNPSend_IsReliable() );\n\t}\n\n\t// Add to pending list\n\tm_senderState.m_messagesQueued.push_back( pSendMessage );\n\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_Message.Get(), \"[%s] SendMessage %s: MsgNum=%lld sz=%d\\n\",\n\t\t\t\t GetDescription(),\n\t\t\t\t pSendMessage->SNPSend_IsReliable() ? \"RELIABLE\" : \"UNRELIABLE\",\n\t\t\t\t (long long)pSendMessage->m_nMessageNumber,\n\t\t\t\t pSendMessage->m_cbSize );\n\n\t// Use Nagle?\n\t// We always set the Nagle timer, even if we immediately clear it.  This makes our clearing code simpler,\n\t// since we can always safely assume that once we find a message with the nagle timer cleared, all messages\n\t// queued earlier than this also have it cleared.\n\t// FIXME - Don't think this works if the configuration value is changing.  Since changing the\n\t// config value could violate the assumption that nagle times are increasing.  Probably not worth\n\t// fixing.\n\tpSendMessage->SNPSend_SetUsecNagle( usecNow + m_connectionConfig.m_NagleTime.Get() );\n\tif ( pSendMessage->m_nFlags & k_nSteamNetworkingSend_NoNagle )\n\t\tm_senderState.ClearNagleTimers();\n\n\t// Save the message number.  The code below might end up deleting the message we just queued\n\tint64 result = pSendMessage->m_nMessageNumber;\n\n\t// Schedule wakeup at the appropriate time.  (E.g. right now, if we're ready to send, \n\t// or at the Nagle time, if Nagle is active.)\n\t//\n\t// NOTE: Right now we might not actually be capable of sending end to end data.\n\t// But that case is relatievly rare, and nothing will break if we try to right now.\n\t// On the other hand, just asking the question involved a virtual function call,\n\t// and it will return success most of the time, so let's not make the check here.\n\tif ( GetState() == k_ESteamNetworkingConnectionState_Connected )\n\t{\n\t\tSteamNetworkingMicroseconds usecNextThink = SNP_GetNextThinkTime( usecNow );\n\n\t\t// Ready to send now?\n\t\tif ( usecNextThink > usecNow )\n\t\t{\n\n\t\t\t// We are rate limiting.  Spew about it?\n\t\t\tif ( m_senderState.m_messagesQueued.m_pFirst->SNPSend_UsecNagle() == 0 )\n\t\t\t{\n\t\t\t\tSpewVerbose( \"[%s] RATELIM QueueTime is %.1fms, SendRate=%.1fk, BytesQueued=%d\\n\", \n\t\t\t\t\tGetDescription(),\n\t\t\t\t\tm_senderState.CalcTimeUntilNextSend() * 1e-3,\n\t\t\t\t\tm_senderState.m_n_x * ( 1.0/1024.0),\n\t\t\t\t\tm_senderState.PendingBytesTotal()\n\t\t\t\t);\n\t\t\t}\n\n\t\t\t// Set a wakeup call.\n\t\t\tEnsureMinThinkTime( usecNextThink );\n\t\t}\n\t\telse\n\t\t{\n\n\t\t\t// We're ready to send right now.  Check if we should!\n\t\t\tif ( pSendMessage->m_nFlags & k_nSteamNetworkingSend_UseCurrentThread )\n\t\t\t{\n\n\t\t\t\t// We should send in this thread, before the API entry point\n\t\t\t\t// that the app used returns.  Is the caller gonna handle this?\n\t\t\t\tif ( pbThinkImmediately )\n\t\t\t\t{\n\t\t\t\t\t// Caller says they will handle it\n\t\t\t\t\t*pbThinkImmediately = true;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t// Caller wants us to just do it here.\n\t\t\t\t\tCheckConnectionStateAndSetNextThinkTime( usecNow );\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Wake up the service thread ASAP to send this in the background thread\n\t\t\t\tSetNextThinkTimeASAP();\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}\n\nEResult CSteamNetworkConnectionBase::SNP_FlushMessage( SteamNetworkingMicroseconds usecNow )\n{\n\t// If we're not connected, then go ahead and mark the messages ready to send\n\t// once we connect, but otherwise don't take any action\n\tif ( GetState() != k_ESteamNetworkingConnectionState_Connected )\n\t{\n\t\tm_senderState.ClearNagleTimers();\n\t\treturn k_EResultIgnored;\n\t}\n\n\tif ( m_senderState.m_messagesQueued.empty() )\n\t\treturn k_EResultOK;\n\n\t// If no Nagle timer was set, then there's nothing to do, we should already\n\t// be properly scheduled.  Don't do work to re-discover that fact.\n\tif ( m_senderState.m_messagesQueued.m_pLast->SNPSend_UsecNagle() == 0 )\n\t\treturn k_EResultOK;\n\n\t// Accumulate tokens, and also limit to reasonable burst\n\t// if we weren't already waiting to send before this.\n\t// (Clearing the Nagle timers might very well make us want to\n\t// send so we want to do this first.)\n\tSNP_ClampSendRate();\n\tSNP_TokenBucket_Accumulate( usecNow );\n\n\t// Clear all Nagle timers\n\tm_senderState.ClearNagleTimers();\n\n\t// Schedule wakeup at the appropriate time.  (E.g. right now, if we're ready to send.)\n\tSteamNetworkingMicroseconds usecNextThink = SNP_GetNextThinkTime( usecNow );\n\tEnsureMinThinkTime( usecNextThink );\n\treturn k_EResultOK;\n}\n\nbool CSteamNetworkConnectionBase::ProcessPlainTextDataChunk( int usecTimeSinceLast, RecvPacketContext_t &ctx )\n{\n\t#define DECODE_ERROR( ... ) do { \\\n\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError, __VA_ARGS__ ); \\\n\t\treturn false; } while(false)\n\n\t#define EXPECT_BYTES(n,pszWhatFor) \\\n\t\tdo { \\\n\t\t\tif ( pDecode + (n) > pEnd ) \\\n\t\t\t\tDECODE_ERROR( \"SNP decode overrun, %d bytes for %s\", (n), pszWhatFor ); \\\n\t\t} while (false)\n\n\t#define READ_8BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(1,pszWhatFor); var = *(uint8 *)pDecode; pDecode += 1; } while(false)\n\n\t#define READ_16BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(2,pszWhatFor); var = LittleWord(*(uint16 *)pDecode); pDecode += 2; } while(false)\n\n\t#define READ_24BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(3,pszWhatFor); \\\n\t\t\tvar = *(uint8 *)pDecode; pDecode += 1; \\\n\t\t\tvar |= uint32( LittleWord(*(uint16 *)pDecode) ) << 8U; pDecode += 2; \\\n\t\t} while(false)\n\n\t#define READ_32BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(4,pszWhatFor); var = LittleDWord(*(uint32 *)pDecode); pDecode += 4; } while(false)\n\n\t#define READ_48BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(6,pszWhatFor); \\\n\t\t\tvar = LittleWord( *(uint16 *)pDecode ); pDecode += 2; \\\n\t\t\tvar |= uint64( LittleDWord(*(uint32 *)pDecode) ) << 16U; pDecode += 4; \\\n\t\t} while(false)\n\n\t#define READ_64BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(8,pszWhatFor); var = LittleQWord(*(uint64 *)pDecode); pDecode += 8; } while(false)\n\n\t#define READ_VARINT( var, pszWhatFor ) \\\n\t\tdo { pDecode = DeserializeVarInt( pDecode, pEnd, var ); if ( !pDecode ) { DECODE_ERROR( \"SNP data chunk decode overflow, varint for %s\", pszWhatFor ); } } while(false)\n\n\t#define READ_SEGMENT_DATA_SIZE( is_reliable ) \\\n\t\tint cbSegmentSize; \\\n\t\t{ \\\n\t\t\tint sizeFlags = nFrameType & 7; \\\n\t\t\tif ( sizeFlags <= 4 ) \\\n\t\t\t{ \\\n\t\t\t\tuint8 lowerSizeBits; \\\n\t\t\t\tREAD_8BITU( lowerSizeBits, #is_reliable \" size lower bits\" ); \\\n\t\t\t\tcbSegmentSize = (sizeFlags<<8) + lowerSizeBits; \\\n\t\t\t\tif ( pDecode + cbSegmentSize > pEnd ) \\\n\t\t\t\t{ \\\n\t\t\t\t\tDECODE_ERROR( \"SNP decode overrun %d bytes for %s segment data.\", cbSegmentSize, #is_reliable ); \\\n\t\t\t\t} \\\n\t\t\t} \\\n\t\t\telse if ( sizeFlags == 7 ) \\\n\t\t\t{ \\\n\t\t\t\tcbSegmentSize = pEnd - pDecode; \\\n\t\t\t} \\\n\t\t\telse \\\n\t\t\t{ \\\n\t\t\t\tDECODE_ERROR( \"Invalid SNP frame lead byte 0x%02x. (size bits)\", nFrameType ); \\\n\t\t\t} \\\n\t\t} \\\n\t\tconst uint8 *pSegmentData = pDecode; \\\n\t\tpDecode += cbSegmentSize;\n\n\t// Make sure we have initialized the connection\n\tAssert( BStateIsActive() );\n\n\tconst SteamNetworkingMicroseconds usecNow = ctx.m_usecNow;\n\tconst int64 nPktNum = ctx.m_nPktNum;\n\tbool bInhibitMarkReceived = false;\n\n\tconst int nLogLevelPacketDecode = m_connectionConfig.m_LogLevel_PacketDecode.Get();\n\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s] decode pkt %lld\\n\", GetDescription(), (long long)nPktNum );\n\n\t// Decode frames until we get to the end of the payload\n\tconst byte *pDecode = (const byte *)ctx.m_pPlainText;\n\tconst byte *pEnd = pDecode + ctx.m_cbPlainText;\n\tint64 nCurMsgNum = 0;\n\tint64 nDecodeReliablePos = 0;\n\twhile ( pDecode < pEnd )\n\t{\n\n\t\tuint8 nFrameType = *pDecode;\n\t\t++pDecode;\n\t\tif ( ( nFrameType & 0xc0 ) == 0x00 )\n\t\t{\n\n\t\t\t//\n\t\t\t// Unreliable segment\n\t\t\t//\n\n\t\t\t// Decode message number\n\t\t\tif ( nCurMsgNum == 0 )\n\t\t\t{\n\t\t\t\t// First unreliable frame.  Message number is absolute, but only bottom N bits are sent\n\t\t\t\tstatic const char szUnreliableMsgNumOffset[] = \"unreliable msgnum\";\n\t\t\t\tint64 nLowerBits, nMask;\n\t\t\t\tif ( nFrameType & 0x10 )\n\t\t\t\t{\n\t\t\t\t\tREAD_32BITU( nLowerBits, szUnreliableMsgNumOffset );\n\t\t\t\t\tnMask = 0xffffffff;\n\t\t\t\t\tnCurMsgNum = NearestWithSameLowerBits( (int32)nLowerBits, m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tREAD_16BITU( nLowerBits, szUnreliableMsgNumOffset );\n\t\t\t\t\tnMask = 0xffff;\n\t\t\t\t\tnCurMsgNum = NearestWithSameLowerBits( (int16)nLowerBits, m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\t}\n\t\t\t\tAssert( ( nCurMsgNum & nMask ) == nLowerBits );\n\n\t\t\t\tif ( nCurMsgNum <= 0 )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP decode unreliable msgnum underflow.  %llx mod %llx, highest seen %llx\",\n\t\t\t\t\t\t(unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ), (unsigned long long)m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\t}\n\t\t\t\tif ( std::abs( nCurMsgNum - m_receiverState.m_nHighestSeenMsgNum ) > (nMask>>2) )\n\t\t\t\t{\n\t\t\t\t\t// We really should never get close to this boundary.\n\t\t\t\t\tSpewWarningRateLimited( usecNow, \"Sender sent abs unreliable message number using %llx mod %llx, highest seen %llx\\n\",\n\t\t\t\t\t\t(unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ), (unsigned long long)m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\t}\n\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif ( nFrameType & 0x10 )\n\t\t\t\t{\n\t\t\t\t\tuint64 nMsgNumOffset;\n\t\t\t\t\tREAD_VARINT( nMsgNumOffset, \"unreliable msgnum offset\" );\n\t\t\t\t\tnCurMsgNum += nMsgNumOffset;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t++nCurMsgNum;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( nCurMsgNum > m_receiverState.m_nHighestSeenMsgNum )\n\t\t\t\tm_receiverState.m_nHighestSeenMsgNum = nCurMsgNum;\n\n\t\t\t//\n\t\t\t// Decode segment offset in message\n\t\t\t//\n\t\t\tuint32 nOffset = 0;\n\t\t\tif ( nFrameType & 0x08 )\n\t\t\t\tREAD_VARINT( nOffset, \"unreliable data offset\" );\n\n\t\t\t//\n\t\t\t// Decode size, locate segment data\n\t\t\t//\n\t\t\tREAD_SEGMENT_DATA_SIZE( unreliable )\n\t\t\tAssert( cbSegmentSize > 0 ); // !TEST! Bogus assert, zero byte messages are OK.  Remove after testing\n\n\t\t\t// Receive the segment\n\t\t\tbool bLastSegmentInMessage = ( nFrameType & 0x20 ) != 0;\n\t\t\tSNP_ReceiveUnreliableSegment( nCurMsgNum, nOffset, pSegmentData, cbSegmentSize, bLastSegmentInMessage, usecNow );\n\t\t}\n\t\telse if ( ( nFrameType & 0xe0 ) == 0x40 )\n\t\t{\n\n\t\t\t//\n\t\t\t// Reliable segment\n\t\t\t//\n\n\t\t\t// First reliable segment?\n\t\t\tif ( nDecodeReliablePos == 0 )\n\t\t\t{\n\n\t\t\t\t// Stream position is absolute.  How many bits?\n\t\t\t\tstatic const char szFirstReliableStreamPos[] = \"first reliable streampos\";\n\t\t\t\tint64 nOffset, nMask;\n\t\t\t\tswitch ( nFrameType & (3<<3) )\n\t\t\t\t{\n\t\t\t\t\tcase 0<<3: READ_24BITU( nOffset, szFirstReliableStreamPos ); nMask = (1ll<<24)-1; break;\n\t\t\t\t\tcase 1<<3: READ_32BITU( nOffset, szFirstReliableStreamPos ); nMask = (1ll<<32)-1; break;\n\t\t\t\t\tcase 2<<3: READ_48BITU( nOffset, szFirstReliableStreamPos ); nMask = (1ll<<48)-1; break;\n\t\t\t\t\tdefault: DECODE_ERROR( \"Reserved reliable stream pos size\" );\n\t\t\t\t}\n\n\t\t\t\t// What do we expect to receive next?\n\t\t\t\tint64 nExpectNextStreamPos = m_receiverState.m_nReliableStreamPos + len( m_receiverState.m_bufReliableStream );\n\n\t\t\t\t// Find the stream offset closest to that\n\t\t\t\tnDecodeReliablePos = ( nExpectNextStreamPos & ~nMask ) + nOffset;\n\t\t\t\tif ( nDecodeReliablePos + (nMask>>1) < nExpectNextStreamPos )\n\t\t\t\t{\n\t\t\t\t\tnDecodeReliablePos += nMask+1;\n\t\t\t\t\tAssert( ( nDecodeReliablePos & nMask ) == nOffset );\n\t\t\t\t\tAssert( nExpectNextStreamPos < nDecodeReliablePos );\n\t\t\t\t\tAssert( nExpectNextStreamPos + (nMask>>1) >= nDecodeReliablePos );\n\t\t\t\t}\n\t\t\t\tif ( nDecodeReliablePos <= 0 )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP decode first reliable stream pos underflow.  %llx mod %llx, expected next %llx\",\n\t\t\t\t\t\t(unsigned long long)nOffset, (unsigned long long)( nMask+1 ), (unsigned long long)nExpectNextStreamPos );\n\t\t\t\t}\n\t\t\t\tif ( std::abs( nDecodeReliablePos - nExpectNextStreamPos ) > (nMask>>2) )\n\t\t\t\t{\n\t\t\t\t\t// We really should never get close to this boundary.\n\t\t\t\t\tSpewWarningRateLimited( usecNow, \"Sender sent reliable stream pos using %llx mod %llx, expected next %llx\\n\",\n\t\t\t\t\t\t(unsigned long long)nOffset, (unsigned long long)( nMask+1 ), (unsigned long long)nExpectNextStreamPos );\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Subsequent reliable message encode the position as an offset from previous.\n\t\t\t\tstatic const char szOtherReliableStreamPos[] = \"reliable streampos offset\";\n\t\t\t\tint64 nOffset;\n\t\t\t\tswitch ( nFrameType & (3<<3) )\n\t\t\t\t{\n\t\t\t\t\tcase 0<<3: nOffset = 0; break;\n\t\t\t\t\tcase 1<<3: READ_8BITU( nOffset, szOtherReliableStreamPos ); break;\n\t\t\t\t\tcase 2<<3: READ_16BITU( nOffset, szOtherReliableStreamPos ); break;\n\t\t\t\t\tdefault: READ_32BITU( nOffset, szOtherReliableStreamPos ); break;\n\t\t\t\t}\n\t\t\t\tnDecodeReliablePos += nOffset;\n\t\t\t}\n\n\t\t\t//\n\t\t\t// Decode size, locate segment data\n\t\t\t//\n\t\t\tREAD_SEGMENT_DATA_SIZE( reliable )\n\n\t\t\t// Ingest the segment.\n\t\t\tif ( !SNP_ReceiveReliableSegment( nPktNum, nDecodeReliablePos, pSegmentData, cbSegmentSize, usecNow ) )\n\t\t\t{\n\t\t\t\tif ( !BStateIsActive() )\n\t\t\t\t\treturn false; // we decided to nuke the connection - abort packet processing\n\n\t\t\t\t// We're not able to ingest this reliable segment at the moment,\n\t\t\t\t// but we didn't terminate the connection.  So do not ack this packet\n\t\t\t\t// to the peer.  We need them to retransmit\n\t\t\t\tbInhibitMarkReceived = true;\n\t\t\t}\n\n\t\t\t// Advance pointer for the next reliable segment, if any.\n\t\t\tnDecodeReliablePos += cbSegmentSize;\n\n\t\t\t// Decoding rules state that if we have established a message number,\n\t\t\t// (from an earlier unreliable message), then we advance it.\n\t\t\tif ( nCurMsgNum > 0 ) \n\t\t\t\t++nCurMsgNum;\n\t\t}\n\t\telse if ( ( nFrameType & 0xfc ) == 0x80 )\n\t\t{\n\t\t\t//\n\t\t\t// Stop waiting\n\t\t\t//\n\n\t\t\tint64 nOffset = 0;\n\t\t\tstatic const char szStopWaitingOffset[] = \"stop_waiting offset\";\n\t\t\tswitch ( nFrameType & 3 )\n\t\t\t{\n\t\t\t\tcase 0: READ_8BITU( nOffset, szStopWaitingOffset ); break;\n\t\t\t\tcase 1: READ_16BITU( nOffset, szStopWaitingOffset ); break;\n\t\t\t\tcase 2: READ_24BITU( nOffset, szStopWaitingOffset ); break;\n\t\t\t\tcase 3: READ_64BITU( nOffset, szStopWaitingOffset ); break;\n\t\t\t}\n\t\t\tif ( nOffset >= nPktNum )\n\t\t\t{\n\t\t\t\tDECODE_ERROR( \"stop_waiting pktNum %llu offset %llu\", nPktNum, nOffset );\n\t\t\t}\n\t\t\t++nOffset;\n\t\t\tint64 nMinPktNumToSendAcks = nPktNum-nOffset;\n\t\t\tif ( nMinPktNumToSendAcks == m_receiverState.m_nMinPktNumToSendAcks )\n\t\t\t\tcontinue;\n\t\t\tif ( nMinPktNumToSendAcks < m_receiverState.m_nMinPktNumToSendAcks )\n\t\t\t{\n\t\t\t\t// Sender must never reduce this number!  Check for bugs or bogus sender\n\t\t\t\tif ( nPktNum >= m_receiverState.m_nPktNumUpdatedMinPktNumToSendAcks )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP stop waiting reduced %lld (pkt %lld) -> %lld (pkt %lld)\",\n\t\t\t\t\t\t(long long)m_receiverState.m_nMinPktNumToSendAcks,\n\t\t\t\t\t\t(long long)m_receiverState.m_nPktNumUpdatedMinPktNumToSendAcks,\n\t\t\t\t\t\t(long long)nMinPktNumToSendAcks,\n\t\t\t\t\t\t(long long)nPktNum\n\t\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld stop waiting: %lld (was %lld)\",\n\t\t\t\tGetDescription(),\n\t\t\t\t(long long)nPktNum,\n\t\t\t\t(long long)nMinPktNumToSendAcks, (long long)m_receiverState.m_nMinPktNumToSendAcks );\n\t\t\tm_receiverState.m_nMinPktNumToSendAcks = nMinPktNumToSendAcks;\n\t\t\tm_receiverState.m_nPktNumUpdatedMinPktNumToSendAcks = nPktNum;\n\n\t\t\t// Trim from the front of the packet gap list,\n\t\t\t// we can stop reporting these losses to the sender\n\t\t\tauto h = m_receiverState.m_mapPacketGaps.begin();\n\t\t\twhile ( h->first <= m_receiverState.m_nMinPktNumToSendAcks )\n\t\t\t{\n\t\t\t\tif ( h->second.m_nEnd > m_receiverState.m_nMinPktNumToSendAcks )\n\t\t\t\t{\n\t\t\t\t\t// Ug.  You're not supposed to modify the key in a map.\n\t\t\t\t\t// I suppose that's legit, since you could violate the ordering.\n\t\t\t\t\t// but in this case I know that this change is OK.\n\t\t\t\t\tconst_cast<int64 &>( h->first ) = m_receiverState.m_nMinPktNumToSendAcks;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t// Were we pending an ack on this?\n\t\t\t\tif ( m_receiverState.m_itPendingAck == h )\n\t\t\t\t\t++m_receiverState.m_itPendingAck;\n\n\t\t\t\t// Were we pending a nack on this?\n\t\t\t\tif ( m_receiverState.m_itPendingNack == h )\n\t\t\t\t{\n\t\t\t\t\t// I am not sure this is even possible.\n\t\t\t\t\tAssertMsg( false, \"Expiring packet gap, which had pending NACK\" );\n\n\t\t\t\t\t// But just in case, this would be the proper action\n\t\t\t\t\t++m_receiverState.m_itPendingNack;\n\t\t\t\t}\n\n\t\t\t\t// Packet loss is in the past.  Forget about it and move on\n\t\t\t\th = m_receiverState.m_mapPacketGaps.erase(h);\n\t\t\t}\n\t\t}\n\t\telse if ( ( nFrameType & 0xf0 ) == 0x90 )\n\t\t{\n\n\t\t\t//\n\t\t\t// Ack\n\t\t\t//\n\n\t\t\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 0\n\t\t\t\tm_senderState.DebugCheckInFlightPacketMap();\n\t\t\t\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA == 1\n\t\t\t\tif ( ( nPktNum & 255 ) == 0 ) // only do it periodically\n\t\t\t\t#endif\n\t\t\t\t{\n\t\t\t\t\tm_senderState.DebugCheckInFlightPacketMap();\n\t\t\t\t}\n\t\t\t#endif\n\n\t\t\t// Parse latest received sequence number\n\t\t\tint64 nLatestRecvSeqNum;\n\t\t\t{\n\t\t\t\tstatic const char szAckLatestPktNum[] = \"ack latest pktnum\";\n\t\t\t\tint64 nLowerBits, nMask;\n\t\t\t\tif ( nFrameType & 0x40 )\n\t\t\t\t{\n\t\t\t\t\tREAD_32BITU( nLowerBits, szAckLatestPktNum );\n\t\t\t\t\tnMask = 0xffffffff;\n\t\t\t\t\tnLatestRecvSeqNum = NearestWithSameLowerBits( (int32)nLowerBits, m_statsEndToEnd.m_nNextSendSequenceNumber );\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tREAD_16BITU( nLowerBits, szAckLatestPktNum );\n\t\t\t\t\tnMask = 0xffff;\n\t\t\t\t\tnLatestRecvSeqNum = NearestWithSameLowerBits( (int16)nLowerBits, m_statsEndToEnd.m_nNextSendSequenceNumber );\n\t\t\t\t}\n\t\t\t\tAssert( ( nLatestRecvSeqNum & nMask ) == nLowerBits );\n\n\t\t\t\t// Find the message number that is closes to \n\t\t\t\tif ( nLatestRecvSeqNum < 0 )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP decode ack latest pktnum underflow.  %llx mod %llx, next send %llx\",\n\t\t\t\t\t\t(unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ), (unsigned long long)m_statsEndToEnd.m_nNextSendSequenceNumber );\n\t\t\t\t}\n\t\t\t\tif ( std::abs( nLatestRecvSeqNum - m_statsEndToEnd.m_nNextSendSequenceNumber ) > (nMask>>2) )\n\t\t\t\t{\n\t\t\t\t\t// We really should never get close to this boundary.\n\t\t\t\t\tSpewWarningRateLimited( usecNow, \"Sender sent abs latest recv pkt number using %llx mod %llx, next send %llx\\n\",\n\t\t\t\t\t\t(unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ), (unsigned long long)m_statsEndToEnd.m_nNextSendSequenceNumber );\n\t\t\t\t}\n\t\t\t\tif ( nLatestRecvSeqNum >= m_statsEndToEnd.m_nNextSendSequenceNumber )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP decode ack latest pktnum %lld (%llx mod %llx), but next outoing packet is %lld (%llx).\",\n\t\t\t\t\t\t(long long)nLatestRecvSeqNum, (unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ),\n\t\t\t\t\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (unsigned long long)m_statsEndToEnd.m_nNextSendSequenceNumber\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld latest recv %lld\\n\",\n\t\t\t\tGetDescription(),\n\t\t\t\t(long long)nPktNum, (long long)nLatestRecvSeqNum\n\t\t\t);\n\n\t\t\t// Locate our bookkeeping for this packet, or the latest one before it\n\t\t\t// Remember, we have a sentinel with a low, invalid packet number\n\t\t\tAssert( !m_senderState.m_mapInFlightPacketsByPktNum.empty() );\n\t\t\tauto inFlightPkt = m_senderState.m_mapInFlightPacketsByPktNum.upper_bound( nLatestRecvSeqNum );\n\t\t\t--inFlightPkt;\n\t\t\tAssert( inFlightPkt->first <= nLatestRecvSeqNum );\n\n\t\t\t// Parse out delay, and process the ping\n\t\t\t{\n\t\t\t\tuint16 nPackedDelay;\n\t\t\t\tREAD_16BITU( nPackedDelay, \"ack delay\" );\n\t\t\t\tif ( nPackedDelay != 0xffff && inFlightPkt->first == nLatestRecvSeqNum && inFlightPkt->second.m_pTransport == ctx.m_pTransport )\n\t\t\t\t{\n\t\t\t\t\tSteamNetworkingMicroseconds usecDelay = SteamNetworkingMicroseconds( nPackedDelay ) << k_nAckDelayPrecisionShift;\n\t\t\t\t\tSteamNetworkingMicroseconds usecElapsed = usecNow - inFlightPkt->second.m_usecWhenSent;\n\t\t\t\t\tAssert( usecElapsed >= 0 );\n\n\t\t\t\t\t// Account for their reported delay, and calculate ping, in MS\n\t\t\t\t\tint msPing = ( usecElapsed - usecDelay ) / 1000;\n\n\t\t\t\t\t// Does this seem bogus?  (We allow a small amount of slop.)\n\t\t\t\t\t// NOTE: A malicious sender could lie about this delay, tricking us\n\t\t\t\t\t// into thinking that the real network latency is low, they are just\n\t\t\t\t\t// delaying their replies.  This actually matters, since the ping time\n\t\t\t\t\t// is an input into the rate calculation.  So we might need to\n\t\t\t\t\t// occasionally send pings that require an immediately reply, and\n\t\t\t\t\t// if those ping times seem way out of whack with the ones where they are\n\t\t\t\t\t// allowed to send a delay, take action against them.\n\t\t\t\t\tif ( msPing < -1 || msPing > 2000 )\n\t\t\t\t\t{\n\t\t\t\t\t\t// Either they are lying or some weird timer stuff is happening.\n\t\t\t\t\t\t// Either way, discard it.\n\n\t\t\t\t\t\tSpewMsgGroup( m_connectionConfig.m_LogLevel_AckRTT.Get(), \"[%s] decode pkt %lld latest recv %lld delay %lluusec INVALID ping %lldusec\\n\",\n\t\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t\t(long long)nPktNum, (long long)nLatestRecvSeqNum,\n\t\t\t\t\t\t\t(unsigned long long)usecDelay,\n\t\t\t\t\t\t\t(long long)usecElapsed\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t// Clamp, if we have slop\n\t\t\t\t\t\tif ( msPing < 0 )\n\t\t\t\t\t\t\tmsPing = 0;\n\t\t\t\t\t\tProcessSNPPing( msPing, ctx );\n\n\t\t\t\t\t\t// Spew\n\t\t\t\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_AckRTT.Get(), \"[%s] decode pkt %lld latest recv %lld delay %.1fms elapsed %.1fms ping %dms\\n\",\n\t\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t\t(long long)nPktNum, (long long)nLatestRecvSeqNum,\n\t\t\t\t\t\t\t(float)(usecDelay * 1e-3 ),\n\t\t\t\t\t\t\t(float)(usecElapsed * 1e-3 ),\n\t\t\t\t\t\t\tmsPing\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Parse number of blocks\n\t\t\tint nBlocks = nFrameType&7;\n\t\t\tif ( nBlocks == 7 )\n\t\t\t\tREAD_8BITU( nBlocks, \"ack num blocks\" );\n\n\t\t\t// If they actually sent us any blocks, that means they are fragmented.\n\t\t\t// We should make sure and tell them to stop sending us these nacks\n\t\t\t// and move forward.\n\t\t\tif ( nBlocks > 0 )\n\t\t\t{\n\t\t\t\t// Decrease flush delay the more blocks they send us.\n\t\t\t\t// FIXME - This is not an optimal way to do this.  Forcing us to\n\t\t\t\t// ack everything is not what we want to do.  Instead, we should\n\t\t\t\t// use a separate timer for when we need to flush out a stop_waiting\n\t\t\t\t// packet!\n\t\t\t\tSteamNetworkingMicroseconds usecDelay = 250*1000 / nBlocks;\n\t\t\t\tQueueFlushAllAcks( usecNow + usecDelay );\n\t\t\t}\n\n\t\t\t// Process ack blocks, working backwards from the latest received sequence number.\n\t\t\t// Note that we have to parse all this stuff out, even if it's old news (packets older\n\t\t\t// than the stop_aiting value we sent), because we need to do that to get to the rest\n\t\t\t// of the packet.\n\t\t\tbool bAckedReliableRange = false;\n\t\t\tint64 nPktNumAckEnd = nLatestRecvSeqNum+1;\n\t\t\twhile ( nBlocks >= 0 )\n\t\t\t{\n\n\t\t\t\t// Parse out number of acks/nacks.\n\t\t\t\t// Have we parsed all the real blocks?\n\t\t\t\tint64 nPktNumAckBegin, nPktNumNackBegin;\n\t\t\t\tif ( nBlocks == 0 )\n\t\t\t\t{\n\t\t\t\t\t// Implicit block.  Everything earlier between the last\n\t\t\t\t\t// NACK and the stop_waiting value is implicitly acked!\n\t\t\t\t\tif ( nPktNumAckEnd <= m_senderState.m_nMinPktWaitingOnAck )\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tnPktNumAckBegin = m_senderState.m_nMinPktWaitingOnAck;\n\t\t\t\t\tnPktNumNackBegin = nPktNumAckBegin;\n\t\t\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld ack last block ack begin %lld\\n\",\n\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t(long long)nPktNum, (long long)nPktNumAckBegin );\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tuint8 nBlockHeader;\n\t\t\t\t\tREAD_8BITU( nBlockHeader, \"ack block header\" );\n\n\t\t\t\t\t// Ack count?\n\t\t\t\t\tint64 numAcks = ( nBlockHeader>> 4 ) & 7;\n\t\t\t\t\tif ( nBlockHeader & 0x80 )\n\t\t\t\t\t{\n\t\t\t\t\t\tuint64 nUpperBits;\n\t\t\t\t\t\tREAD_VARINT( nUpperBits, \"ack count upper bits\" );\n\t\t\t\t\t\tif ( nUpperBits > 100000 )\n\t\t\t\t\t\t\tDECODE_ERROR( \"Ack count of %llu<<3 is crazy\", (unsigned long long)nUpperBits );\n\t\t\t\t\t\tnumAcks |= nUpperBits<<3;\n\t\t\t\t\t}\n\t\t\t\t\tnPktNumAckBegin = nPktNumAckEnd - numAcks;\n\t\t\t\t\tif ( nPktNumAckBegin < 0 )\n\t\t\t\t\t\tDECODE_ERROR( \"Ack range underflow, end=%lld, num=%lld\", (long long)nPktNumAckEnd, (long long)numAcks );\n\n\t\t\t\t\t// Extended nack count?\n\t\t\t\t\tint64 numNacks = nBlockHeader & 7;\n\t\t\t\t\tif ( nBlockHeader & 0x08)\n\t\t\t\t\t{\n\t\t\t\t\t\tuint64 nUpperBits;\n\t\t\t\t\t\tREAD_VARINT( nUpperBits, \"nack count upper bits\" );\n\t\t\t\t\t\tif ( nUpperBits > 100000 )\n\t\t\t\t\t\t\tDECODE_ERROR( \"Nack count of %llu<<3 is crazy\", nUpperBits );\n\t\t\t\t\t\tnumNacks |= nUpperBits<<3;\n\t\t\t\t\t}\n\t\t\t\t\tnPktNumNackBegin = nPktNumAckBegin - numNacks;\n\t\t\t\t\tif ( nPktNumNackBegin < 0 )\n\t\t\t\t\t\tDECODE_ERROR( \"Nack range underflow, end=%lld, num=%lld\", (long long)nPktNumAckBegin, (long long)numAcks );\n\n\t\t\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld nack [%lld,%lld) ack [%lld,%lld)\\n\",\n\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t(long long)nPktNum,\n\t\t\t\t\t\t(long long)nPktNumNackBegin, (long long)( nPktNumNackBegin + numNacks ),\n\t\t\t\t\t\t(long long)nPktNumAckBegin, (long long)( nPktNumAckBegin + numAcks )\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\t// Process acks first.\n\t\t\t\tAssert( nPktNumAckBegin >= 0 );\n\t\t\t\twhile ( inFlightPkt->first >= nPktNumAckBegin )\n\t\t\t\t{\n\t\t\t\t\tAssert( inFlightPkt->first < nPktNumAckEnd );\n\n\t\t\t\t\t// Scan reliable segments, and see if any are marked for retry or are in flight\n\t\t\t\t\tfor ( const SNPRange_t &relRange: inFlightPkt->second.m_vecReliableSegments )\n\t\t\t\t\t{\n\n\t\t\t\t\t\t// If range is present, it should be in only one of these two tables.\n\t\t\t\t\t\tif ( m_senderState.m_listInFlightReliableRange.erase( relRange ) == 0 )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif ( m_senderState.m_listReadyRetryReliableRange.erase( relRange ) > 0 )\n\t\t\t\t\t\t\t{\n\n\t\t\t\t\t\t\t\t// When we put stuff into the reliable retry list, we mark it as pending again.\n\t\t\t\t\t\t\t\t// But now it's acked, so it's no longer pending, even though we didn't send it.\n\t\t\t\t\t\t\t\tm_senderState.m_cbPendingReliable -= int( relRange.length() );\n\t\t\t\t\t\t\t\tAssert( m_senderState.m_cbPendingReliable >= 0 );\n\n\t\t\t\t\t\t\t\tbAckedReliableRange = true;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tbAckedReliableRange = true;\n\t\t\t\t\t\t\tAssert( m_senderState.m_listReadyRetryReliableRange.count( relRange ) == 0 );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Check if this was the next packet we were going to timeout, then advance\n\t\t\t\t\t// pointer.  This guy didn't timeout.\n\t\t\t\t\tif ( inFlightPkt == m_senderState.m_itNextInFlightPacketToTimeout )\n\t\t\t\t\t\t++m_senderState.m_itNextInFlightPacketToTimeout;\n\n\t\t\t\t\t// No need to track this anymore, remove from our table\n\t\t\t\t\tinFlightPkt = m_senderState.m_mapInFlightPacketsByPktNum.erase( inFlightPkt );\n\t\t\t\t\t--inFlightPkt;\n\t\t\t\t\tm_senderState.MaybeCheckInFlightPacketMap();\n\t\t\t\t}\n\n\t\t\t\t// Ack of in-flight end-to-end stats?\n\t\t\t\tif ( nPktNumAckBegin <= m_statsEndToEnd.m_pktNumInFlight && m_statsEndToEnd.m_pktNumInFlight < nPktNumAckEnd )\n\t\t\t\t\tm_statsEndToEnd.InFlightPktAck( usecNow );\n\n\t\t\t\t// Process nacks.\n\t\t\t\tAssert( nPktNumNackBegin >= 0 );\n\t\t\t\twhile ( inFlightPkt->first >= nPktNumNackBegin )\n\t\t\t\t{\n\t\t\t\t\tAssert( inFlightPkt->first < nPktNumAckEnd );\n\t\t\t\t\tSNP_SenderProcessPacketNack( inFlightPkt->first, inFlightPkt->second, \"NACK\" );\n\n\t\t\t\t\t// We'll keep the record on hand, though, in case an ACK comes in\n\t\t\t\t\t--inFlightPkt;\n\t\t\t\t}\n\n\t\t\t\t// Continue on to the the next older block\n\t\t\t\tnPktNumAckEnd = nPktNumNackBegin;\n\t\t\t\t--nBlocks;\n\t\t\t}\n\n\t\t\t// Should we check for discarding reliable messages we are keeping around in case\n\t\t\t// of retransmission, since we know now that they were delivered?\n\t\t\tif ( bAckedReliableRange )\n\t\t\t{\n\t\t\t\tm_senderState.RemoveAckedReliableMessageFromUnackedList();\n\n\t\t\t\t// Spew where we think the peer is decoding the reliable stream\n\t\t\t\tif ( nLogLevelPacketDecode >= k_ESteamNetworkingSocketsDebugOutputType_Debug )\n\t\t\t\t{\n\n\t\t\t\t\tint64 nPeerReliablePos = m_senderState.m_nReliableStreamPos;\n\t\t\t\t\tif ( !m_senderState.m_listInFlightReliableRange.empty() )\n\t\t\t\t\t\tnPeerReliablePos = std::min( nPeerReliablePos, m_senderState.m_listInFlightReliableRange.begin()->first.m_nBegin );\n\t\t\t\t\tif ( !m_senderState.m_listReadyRetryReliableRange.empty() )\n\t\t\t\t\t\tnPeerReliablePos = std::min( nPeerReliablePos, m_senderState.m_listReadyRetryReliableRange.begin()->first.m_nBegin );\n\n\t\t\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld peer reliable pos = %lld\\n\",\n\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t(long long)nPktNum, (long long)nPeerReliablePos );\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if any of this was new info, then advance our stop_waiting value.\n\t\t\tif ( nLatestRecvSeqNum > m_senderState.m_nMinPktWaitingOnAck )\n\t\t\t{\n\t\t\t\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s]   updating min_waiting_on_ack %lld -> %lld\\n\",\n\t\t\t\t\tGetDescription(),\n\t\t\t\t\t(long long)m_senderState.m_nMinPktWaitingOnAck, (long long)nLatestRecvSeqNum );\n\t\t\t\tm_senderState.m_nMinPktWaitingOnAck = nLatestRecvSeqNum;\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tDECODE_ERROR( \"Invalid SNP frame lead byte 0x%02x\", nFrameType );\n\t\t}\n\t}\n\n\t// Should we record that we received it?\n\tif ( bInhibitMarkReceived )\n\t{\n\t\t// Something really odd.  High packet loss / fragmentation.\n\t\t// Potentially the peer is being abusive and we need\n\t\t// to protect ourselves.\n\t\t//\n\t\t// Act as if the packet was dropped.  This will cause the\n\t\t// peer's sender logic to interpret this as additional packet\n\t\t// loss and back off.  That's a feature, not a bug.\n\t}\n\telse\n\t{\n\n\t\t// Update structures needed to populate our ACKs.\n\t\t// If we received reliable data now, then schedule an ack\n\t\tbool bScheduleAck = nDecodeReliablePos > 0;\n\t\tSNP_RecordReceivedPktNum( nPktNum, usecNow, bScheduleAck );\n\t}\n\n\t// Track end-to-end flow.  Even if we decided to tell our peer that\n\t// we did not receive this, we want our own stats to reflect\n\t// that we did.  (And we want to be able to quickly reject a\n\t// packet with this same number.)\n\t//\n\t// Also, note that order of operations is important.  This call must\n\t// happen after the SNP_RecordReceivedPktNum call above\n\tm_statsEndToEnd.TrackProcessSequencedPacket( nPktNum, usecNow, usecTimeSinceLast );\n\n\t// Packet can be processed further\n\treturn true;\n\n\t// Make sure these don't get used beyond where we intended them to get used\n\t#undef DECODE_ERROR\n\t#undef EXPECT_BYTES\n\t#undef READ_8BITU\n\t#undef READ_16BITU\n\t#undef READ_24BITU\n\t#undef READ_32BITU\n\t#undef READ_64BITU\n\t#undef READ_VARINT\n\t#undef READ_SEGMENT_DATA_SIZE\n}\n\nvoid CSteamNetworkConnectionBase::SNP_SenderProcessPacketNack( int64 nPktNum, SNPInFlightPacket_t &pkt, const char *pszDebug )\n{\n\n\t// Did we already treat the packet as dropped (implicitly or explicitly)?\n\tif ( pkt.m_bNack )\n\t\treturn;\n\n\t// Mark as dropped\n\tpkt.m_bNack = true;\n\n\t// Is this in-flight stats we were expecting an ack for?\n\tif ( m_statsEndToEnd.m_pktNumInFlight == nPktNum )\n\t\tm_statsEndToEnd.InFlightPktTimeout();\n\n\t// Scan reliable segments\n\tfor ( const SNPRange_t &relRange: pkt.m_vecReliableSegments )\n\t{\n\n\t\t// Marked as in-flight?\n\t\tauto inFlightRange = m_senderState.m_listInFlightReliableRange.find( relRange );\n\t\tif ( inFlightRange == m_senderState.m_listInFlightReliableRange.end() )\n\t\t\tcontinue;\n\n\t\tSpewMsgGroup( m_connectionConfig.m_LogLevel_PacketDecode.Get(), \"[%s] pkt %lld %s, queueing retry of reliable range [%lld,%lld)\\n\", \n\t\t\tGetDescription(),\n\t\t\tnPktNum,\n\t\t\tpszDebug,\n\t\t\trelRange.m_nBegin, relRange.m_nEnd );\n\n\t\t// The ready-to-retry list counts towards the \"pending\" stat\n\t\tm_senderState.m_cbPendingReliable += int( relRange.length() );\n\n\t\t// Move it to the ready for retry list!\n\t\t// if shouldn't already be there!\n\t\tAssert( m_senderState.m_listReadyRetryReliableRange.count( relRange ) == 0 );\n\t\tm_senderState.m_listReadyRetryReliableRange[ inFlightRange->first ] = inFlightRange->second;\n\t\tm_senderState.m_listInFlightReliableRange.erase( inFlightRange );\n\t}\n}\n\nSteamNetworkingMicroseconds CSteamNetworkConnectionBase::SNP_SenderCheckInFlightPackets( SteamNetworkingMicroseconds usecNow )\n{\n\t// Fast path for nothing in flight.\n\tm_senderState.MaybeCheckInFlightPacketMap();\n\tif ( m_senderState.m_mapInFlightPacketsByPktNum.size() <= 1 )\n\t{\n\t\tAssert( m_senderState.m_itNextInFlightPacketToTimeout == m_senderState.m_mapInFlightPacketsByPktNum.end() );\n\t\treturn k_nThinkTime_Never;\n\t}\n\tAssert( m_senderState.m_mapInFlightPacketsByPktNum.begin()->first < 0 );\n\n\tSteamNetworkingMicroseconds usecNextRetry = k_nThinkTime_Never;\n\n\t// Process retry timeout.  Here we use a shorter timeout to trigger retry\n\t// than we do to totally forgot about the packet, in case an ack comes in late,\n\t// we can take advantage of it.\n\tSteamNetworkingMicroseconds usecRTO = m_statsEndToEnd.CalcSenderRetryTimeout();\n\twhile ( m_senderState.m_itNextInFlightPacketToTimeout != m_senderState.m_mapInFlightPacketsByPktNum.end() )\n\t{\n\t\tAssert( m_senderState.m_itNextInFlightPacketToTimeout->first > 0 );\n\n\t\t// If already nacked, then no use waiting on it, just skip it\n\t\tif ( !m_senderState.m_itNextInFlightPacketToTimeout->second.m_bNack )\n\t\t{\n\n\t\t\t// Not yet time to give up?\n\t\t\tSteamNetworkingMicroseconds usecRetryPkt = m_senderState.m_itNextInFlightPacketToTimeout->second.m_usecWhenSent + usecRTO;\n\t\t\tif ( usecRetryPkt > usecNow )\n\t\t\t{\n\t\t\t\tusecNextRetry = usecRetryPkt;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// Mark as dropped, and move any reliable contents into the\n\t\t\t// retry list.\n\t\t\tSNP_SenderProcessPacketNack( m_senderState.m_itNextInFlightPacketToTimeout->first, m_senderState.m_itNextInFlightPacketToTimeout->second, \"AckTimeout\" );\n\t\t}\n\n\t\t// Advance to next packet waiting to timeout\n\t\t++m_senderState.m_itNextInFlightPacketToTimeout;\n\t}\n\n\t// Skip the sentinel\n\tauto inFlightPkt = m_senderState.m_mapInFlightPacketsByPktNum.begin();\n\tAssert( inFlightPkt->first < 0 );\n\t++inFlightPkt;\n\n\t// Expire old packets (all of these should have been marked as nacked)\n\tSteamNetworkingMicroseconds usecWhenExpiry = usecNow - usecRTO*2;\n\tfor (;;)\n\t{\n\t\tif ( inFlightPkt->second.m_usecWhenSent > usecWhenExpiry )\n\t\t\tbreak;\n\n\t\t// Should have already been timed out by the code above\n\t\tAssert( inFlightPkt->second.m_bNack );\n\t\tAssert( inFlightPkt != m_senderState.m_itNextInFlightPacketToTimeout );\n\n\t\t// Expire it, advance to the next one\n\t\tinFlightPkt = m_senderState.m_mapInFlightPacketsByPktNum.erase( inFlightPkt );\n\t\tAssert( !m_senderState.m_mapInFlightPacketsByPktNum.empty() );\n\n\t\t// Bail if we've hit the end of the nacks\n\t\tif ( inFlightPkt == m_senderState.m_mapInFlightPacketsByPktNum.end() )\n\t\t\tbreak;\n\t}\n\n\t// Make sure we didn't hose data structures\n\tm_senderState.MaybeCheckInFlightPacketMap();\n\n\t// Return time when we really need to check back in again.\n\t// We don't wake up early just to expire old nacked packets,\n\t// there is no urgency or value in doing that, we can clean\n\t// those up whenever.  We only make sure and wake up when we\n\t// need to retry.  (And we need to make sure we don't let\n\t// our list of old packets grow unnecessarily long.)\n\treturn usecNextRetry;\n}\n\nstruct EncodedSegment\n{\n\tstatic constexpr int k_cbMaxHdr = 16; \n\tuint8 m_hdr[ k_cbMaxHdr ];\n\tint m_cbHdr; // Doesn't include any size byte\n\tCSteamNetworkingMessage *m_pMsg;\n\tint m_cbSegSize;\n\tint m_nOffset;\n\n\tinline void SetupReliable( CSteamNetworkingMessage *pMsg, int64 nBegin, int64 nEnd, int64 nLastReliableStreamPosEnd )\n\t{\n\t\tAssert( nBegin < nEnd );\n\t\t//Assert( nBegin + k_cbSteamNetworkingSocketsMaxReliableMessageSegment >= nEnd ); // Max sure we don't exceed max segment size\n\t\tAssert( pMsg->SNPSend_IsReliable() );\n\n\t\t// Start filling out the header with the top three bits = 010,\n\t\t// identifying this as a reliable segment\n\t\tuint8 *pHdr = m_hdr;\n\t\t*(pHdr++) = 0x40;\n\n\t\t// First reliable segment in the message?\n\t\tif ( nLastReliableStreamPosEnd == 0 )\n\t\t{\n\t\t\t// Always use 48-byte offsets, to make sure we are exercising the worst case.\n\t\t\t// Later we should optimize this\n\t\t\tm_hdr[0] |= 0x10;\n\t\t\t*(uint16*)pHdr = LittleWord( uint16( nBegin ) ); pHdr += 2;\n\t\t\t*(uint32*)pHdr = LittleDWord( uint32( nBegin>>16 ) ); pHdr += 4;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Offset from end of previous reliable segment in the same packet\n\t\t\tAssert( nBegin >= nLastReliableStreamPosEnd );\n\t\t\tint64 nOffset = nBegin - nLastReliableStreamPosEnd;\n\t\t\tif ( nOffset == 0)\n\t\t\t{\n\t\t\t\t// Nothing to encode\n\t\t\t}\n\t\t\telse if ( nOffset < 0x100 )\n\t\t\t{\n\t\t\t\tm_hdr[0] |= (1<<3);\n\t\t\t\t*pHdr = uint8( nOffset ); pHdr += 1;\n\t\t\t}\n\t\t\telse if ( nOffset < 0x10000 )\n\t\t\t{\n\t\t\t\tm_hdr[0] |= (2<<3);\n\t\t\t\t*(uint16*)pHdr = LittleWord( uint16( nOffset ) ); pHdr += 2;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tm_hdr[0] |= (3<<3);\n\t\t\t\t*(uint32*)pHdr = LittleDWord( uint32( nOffset ) ); pHdr += 4;\n\t\t\t}\n\t\t}\n\n\t\tm_cbHdr = pHdr-m_hdr;\n\n\t\t// Size of the segment.  We assume that the whole things fits for now,\n\t\t// even though it might need to get truncated\n\t\tint cbSegData = nEnd - nBegin;\n\t\tAssert( cbSegData > 0 );\n\t\tAssert( nBegin >= pMsg->SNPSend_ReliableStreamPos() );\n\t\tAssert( nEnd <= pMsg->SNPSend_ReliableStreamPos() + pMsg->m_cbSize );\n\n\t\tm_pMsg = pMsg;\n\t\tm_nOffset = nBegin - pMsg->SNPSend_ReliableStreamPos();\n\t\tm_cbSegSize = cbSegData;\n\t}\n\n\tinline void SetupUnreliable( CSteamNetworkingMessage *pMsg, int nOffset, int64 nLastMsgNum )\n\t{\n\n\t\t// Start filling out the header with the top two bits = 00,\n\t\t// identifying this as an unreliable segment\n\t\tuint8 *pHdr = m_hdr;\n\t\t*(pHdr++) = 0x00;\n\n\t\t// Encode message number.  First unreliable message?\n\t\tif ( nLastMsgNum == 0 )\n\t\t{\n\n\t\t\t// Just always encode message number with 32 bits for now,\n\t\t\t// to make sure we are hitting the worst case.  We can optimize this later\n\t\t\t*(uint32*)pHdr = LittleDWord( (uint32)pMsg->m_nMessageNumber ); pHdr += 4;\n\t\t\tm_hdr[0] |= 0x10;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Subsequent unreliable message\n\t\t\tAssert( pMsg->m_nMessageNumber > nLastMsgNum );\n\t\t\tuint64 nDelta = pMsg->m_nMessageNumber - nLastMsgNum;\n\t\t\tif ( nDelta == 1 )\n\t\t\t{\n\t\t\t\t// Common case of sequential messages.  Don't encode any offset\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tpHdr = SerializeVarInt( pHdr, nDelta, m_hdr+k_cbMaxHdr );\n\t\t\t\tAssert( pHdr ); // Overflow shouldn't be possible\n\t\t\t\tm_hdr[0] |= 0x10;\n\t\t\t}\n\t\t}\n\n\t\t// Encode segment offset within message, except in the special common case of the first segment\n\t\tif ( nOffset > 0 )\n\t\t{\n\t\t\tpHdr = SerializeVarInt( pHdr, (uint32)( nOffset ), m_hdr+k_cbMaxHdr );\n\t\t\tAssert( pHdr ); // Overflow shouldn't be possible\n\t\t\tm_hdr[0] |= 0x08;\n\t\t}\n\n\t\tm_cbHdr = pHdr-m_hdr;\n\n\t\t// Size of the segment.  We assume that the whole things fits for now, event hough it might ned to get truncated\n\t\tint cbSegData = pMsg->m_cbSize - nOffset;\n\t\tAssert( cbSegData > 0 || ( cbSegData == 0 && pMsg->m_cbSize == 0 ) ); // We should only send zero-byte segments if the message itself is zero bytes.  (Which is legitimate!)\n\n\t\tm_pMsg = pMsg;\n\t\tm_cbSegSize = cbSegData;\n\t\tm_nOffset = nOffset;\n\t}\n\n};\n\ntemplate <typename T, typename L>\ninline bool HasOverlappingRange( const SNPRange_t &range, const std::map<SNPRange_t,T,L> &map )\n{\n\tauto l = map.lower_bound( range );\n\tif ( l != map.end() )\n\t{\n\t\tAssert( l->first.m_nBegin >= range.m_nBegin );\n\t\tif ( l->first.m_nBegin < range.m_nEnd )\n\t\t\treturn true;\n\t}\n\tauto u = map.upper_bound( range );\n\tif ( u != map.end() )\n\t{\n\t\tAssert( range.m_nBegin < u->first.m_nBegin );\n\t\tif ( range.m_nEnd > l->first.m_nBegin )\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nbool CSteamNetworkConnectionBase::SNP_SendPacket( CConnectionTransport *pTransport, SendPacketContext_t &ctx )\n{\n\t// Check calling conditions, and don't crash\n\tif ( !BStateIsActive() || m_senderState.m_mapInFlightPacketsByPktNum.empty() || !pTransport )\n\t{\n\t\tAssert( BStateIsActive() );\n\t\tAssert( !m_senderState.m_mapInFlightPacketsByPktNum.empty() );\n\t\tAssert( pTransport );\n\t\treturn false;\n\t}\n\n\tSteamNetworkingMicroseconds usecNow = ctx.m_usecNow;\n\n\t// Get max size of plaintext we could send.\n\t// AES-GCM has a fixed size overhead, for the tag.\n\t// FIXME - but what we if we aren't using AES-GCM!\n\tint cbMaxPlaintextPayload = std::max( 0, ctx.m_cbMaxEncryptedPayload-k_cbSteamNetwokingSocketsEncrytionTagSize );\n\tcbMaxPlaintextPayload = std::min( cbMaxPlaintextPayload, m_cbMaxPlaintextPayloadSend );\n\n\tuint8 payload[ k_cbSteamNetworkingSocketsMaxPlaintextPayloadSend ];\n\tuint8 *pPayloadEnd = payload + cbMaxPlaintextPayload;\n\tuint8 *pPayloadPtr = payload;\n\n\tint nLogLevelPacketDecode = m_connectionConfig.m_LogLevel_PacketDecode.Get();\n\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s] encode pkt %lld\",\n\t\tGetDescription(),\n\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber );\n\n\t// Stop waiting frame\n\tpPayloadPtr = SNP_SerializeStopWaitingFrame( pPayloadPtr, pPayloadEnd, usecNow );\n\tif ( pPayloadPtr == nullptr )\n\t\treturn false;\n\n\t// Get list of ack blocks we might want to serialize, and which\n\t// of those acks we really want to flush out right now.\n\tSNPAckSerializerHelper ackHelper;\n\tSNP_GatherAckBlocks( ackHelper, usecNow );\n\n\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\tPacketSendLog *pLog = push_back_get_ptr( m_vecSendLog );\n\t\tpLog->m_usecTime = usecNow;\n\t\tpLog->m_cbPendingReliable = m_senderState.m_cbPendingReliable;\n\t\tpLog->m_cbPendingUnreliable = m_senderState.m_cbPendingUnreliable;\n\t\tpLog->m_nPacketGaps = len( m_receiverState.m_mapPacketGaps )-1;\n\t\tpLog->m_nAckBlocksNeeded = ackHelper.m_nBlocksNeedToAck;\n\t\tpLog->m_nPktNumNextPendingAck = m_receiverState.m_itPendingAck->first;\n\t\tpLog->m_usecNextPendingAckTime = m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior;\n\t\tpLog->m_fltokens = m_senderState.m_flTokenBucket;\n\t\tpLog->m_nMaxPktRecv = m_statsEndToEnd.m_nMaxRecvPktNum;\n\t\tpLog->m_nMinPktNumToSendAcks = m_receiverState.m_nMinPktNumToSendAcks;\n\t\tpLog->m_nReliableSegmentsRetry = 0;\n\t\tpLog->m_nSegmentsSent = 0;\n\t#endif\n\n\t// How much space do we need to reserve for acks?\n\tint cbReserveForAcks = 0;\n\tif ( m_statsEndToEnd.m_nMaxRecvPktNum > 0 )\n\t{\n\t\tint cbPayloadRemainingForAcks = pPayloadEnd - pPayloadPtr;\n\t\tif ( cbPayloadRemainingForAcks >= SNPAckSerializerHelper::k_cbHeaderSize )\n\t\t{\n\t\t\tcbReserveForAcks = SNPAckSerializerHelper::k_cbHeaderSize;\n\t\t\tint n = 3; // Assume we want to send a handful\n\t\t\tn = std::max( n, ackHelper.m_nBlocksNeedToAck ); // But if we have blocks that need to be flushed now, try to fit all of them\n\t\t\tn = std::min( n, ackHelper.m_nBlocks ); // Cannot send more than we actually have\n\t\t\twhile ( n > 0 )\n\t\t\t{\n\t\t\t\t--n;\n\t\t\t\tif ( ackHelper.m_arBlocks[n].m_cbTotalEncodedSize <= cbPayloadRemainingForAcks )\n\t\t\t\t{\n\t\t\t\t\tcbReserveForAcks = ackHelper.m_arBlocks[n].m_cbTotalEncodedSize;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check if we are actually going to send data in this packet\n\tif (\n\t\tm_senderState.m_flTokenBucket < 0.0 // No bandwidth available.  (Presumably this is a relatively rare out-of-band connectivity check, etc)  FIXME should we use a different token bucket per transport?\n\t\t|| !BStateIsConnectedForWirePurposes() // not actually in a connection stats where we should be sending real data yet\n\t\t|| pTransport != m_pTransport // transport is not the selected transport\n\t) {\n\n\t\t// Serialize some acks, if we want to\n\t\tif ( cbReserveForAcks > 0 )\n\t\t{\n\t\t\t// But if we're going to send any acks, then try to send as many\n\t\t\t// as possible, not just the bare minimum.\n\t\t\tpPayloadPtr = SNP_SerializeAckBlocks( ackHelper, pPayloadPtr, pPayloadEnd, usecNow );\n\t\t\tif ( pPayloadPtr == nullptr )\n\t\t\t\treturn false; // bug!  Abort\n\n\t\t\t// We don't need to serialize any more acks\n\t\t\tcbReserveForAcks = 0;\n\t\t}\n\n\t\t// Truncate the buffer, don't try to fit any data\n\t\t// !SPEED! - instead of doing this, we could just put all of the segment code below\n\t\t// in an else() block.\n\t\tpPayloadEnd = pPayloadPtr;\n\t}\n\n\tint64 nLastReliableStreamPosEnd = 0;\n\tint cbBytesRemainingForSegments = pPayloadEnd - pPayloadPtr - cbReserveForAcks;\n\tvstd::small_vector<EncodedSegment,8> vecSegments;\n\n\t// If we need to retry any reliable data, then try to put that in first.\n\t// Bail if we only have a tiny sliver of data left\n\twhile ( !m_senderState.m_listReadyRetryReliableRange.empty() && cbBytesRemainingForSegments > 2 )\n\t{\n\t\tauto h = m_senderState.m_listReadyRetryReliableRange.begin();\n\n\t\t// Start a reliable segment\n\t\tEncodedSegment &seg = *push_back_get_ptr( vecSegments );\n\t\tseg.SetupReliable( h->second, h->first.m_nBegin, h->first.m_nEnd, nLastReliableStreamPosEnd );\n\t\tint cbSegTotalWithoutSizeField = seg.m_cbHdr + seg.m_cbSegSize;\n\t\tif ( cbSegTotalWithoutSizeField > cbBytesRemainingForSegments )\n\t\t{\n\t\t\t// This one won't fit.\n\t\t\tvecSegments.pop_back();\n\n\t\t\t// FIXME If there's a decent amount of space left in this packet, it might\n\t\t\t// be worthwhile to send what we can.  Right now, once we send a reliable range,\n\t\t\t// we always retry exactly that range.  The only complication would be when we\n\t\t\t// receive an ack, we would need to be aware that the acked ranges might not\n\t\t\t// exactly match up with the ranges that we sent.  Actually this shouldn't\n\t\t\t// be that big of a deal.  But for now let's always retry the exact ranges that\n\t\t\t// things got chopped up during the initial send.\n\n\t\t\t// This should only happen if we have already fit some data in, or\n\t\t\t// the caller asked us to see what we could squeeze into a smaller\n\t\t\t// packet, or we need to serialized a bunch of acks.  If this is an\n\t\t\t// opportunity to fill a normal packet and we fail on the first segment,\n\t\t\t// we will never make progress and we are hosed!\n\t\t\tAssertMsg2(\n\t\t\t\tnLastReliableStreamPosEnd > 0\n\t\t\t\t|| cbMaxPlaintextPayload < m_cbMaxPlaintextPayloadSend\n\t\t\t\t|| ( cbReserveForAcks > 15 && ackHelper.m_nBlocksNeedToAck > 8 ),\n\t\t\t\t\"We cannot fit reliable segment, need %d bytes, only %d remaining\", cbSegTotalWithoutSizeField, cbBytesRemainingForSegments\n\t\t\t);\n\n\t\t\t// Don't try to put more stuff in the packet, even if we have room.  We're\n\t\t\t// already having to retry, so this data is already delayed.  If we skip ahead\n\t\t\t// and put more into this packet, that's just extending the time until we can send\n\t\t\t// the next packet.\n\t\t\tbreak;\n\t\t}\n\n\t\t// If we only have a sliver left, then don't try to fit any more.\n\t\tcbBytesRemainingForSegments -= cbSegTotalWithoutSizeField;\n\t\tnLastReliableStreamPosEnd = h->first.m_nEnd;\n\n\t\t// Assume for now this won't be the last segment, in which case we will also need\n\t\t// the byte for the size field.\n\t\t// NOTE: This might cause cbPayloadBytesRemaining to go negative by one!  I know\n\t\t// that seems weird, but it actually keeps the logic below simpler.\n\t\tcbBytesRemainingForSegments -= 1;\n\n\t\t// Remove from retry list.  (We'll add to the in-flight list later)\n\t\tm_senderState.m_listReadyRetryReliableRange.erase( h );\n\n\t\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\t\t++pLog->m_nReliableSegmentsRetry;\n\t\t#endif\n\t}\n\n\t// Did we retry everything we needed to?  If not, then don't try to send new stuff,\n\t// before we send those retries.\n\tif ( m_senderState.m_listReadyRetryReliableRange.empty() )\n\t{\n\n\t\t// OK, check the outgoing messages, and send as much stuff as we can cram in there\n\t\tint64 nLastMsgNum = 0;\n\t\twhile ( cbBytesRemainingForSegments > 4 )\n\t\t{\n\t\t\tif ( m_senderState.m_messagesQueued.empty() )\n\t\t\t{\n\t\t\t\tm_senderState.m_cbCurrentSendMessageSent = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tCSteamNetworkingMessage *pSendMsg = m_senderState.m_messagesQueued.m_pFirst;\n\t\t\tAssert( m_senderState.m_cbCurrentSendMessageSent < pSendMsg->m_cbSize );\n\n\t\t\t// Start a new segment\n\t\t\tEncodedSegment &seg = *push_back_get_ptr( vecSegments );\n\n\t\t\t// Reliable?\n\t\t\tbool bLastSegment = false;\n\t\t\tif ( pSendMsg->SNPSend_IsReliable() )\n\t\t\t{\n\n\t\t\t\t// FIXME - Coalesce adjacent reliable messages ranges\n\n\t\t\t\tint64 nBegin = pSendMsg->SNPSend_ReliableStreamPos() + m_senderState.m_cbCurrentSendMessageSent;\n\n\t\t\t\t// How large would we like this segment to be,\n\t\t\t\t// ignoring how much space is left in the packet.\n\t\t\t\t// We limit the size of reliable segments, to make\n\t\t\t\t// sure that we don't make an excessively large\n\t\t\t\t// one and then have a hard time retrying it later.\n\t\t\t\tint cbDesiredSegSize = pSendMsg->m_cbSize - m_senderState.m_cbCurrentSendMessageSent;\n\t\t\t\tif ( cbDesiredSegSize > m_cbMaxReliableMessageSegment )\n\t\t\t\t{\n\t\t\t\t\tcbDesiredSegSize = m_cbMaxReliableMessageSegment;\n\t\t\t\t\tbLastSegment = true;\n\t\t\t\t}\n\n\t\t\t\tint64 nEnd = nBegin + cbDesiredSegSize;\n\t\t\t\tseg.SetupReliable( pSendMsg, nBegin, nEnd, nLastReliableStreamPosEnd );\n\n\t\t\t\t// If we encode subsequent \n\t\t\t\tnLastReliableStreamPosEnd = nEnd;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tseg.SetupUnreliable( pSendMsg, m_senderState.m_cbCurrentSendMessageSent, nLastMsgNum );\n\t\t\t}\n\n\t\t\t// Can't fit the whole thing?\n\t\t\tif ( bLastSegment || seg.m_cbHdr + seg.m_cbSegSize > cbBytesRemainingForSegments )\n\t\t\t{\n\n\t\t\t\t// Check if we have enough room to send anything worthwhile.\n\t\t\t\t// Don't send really tiny silver segments at the very end of a packet.  That sort of fragmentation\n\t\t\t\t// just makes it more likely for something to drop.  Our goal is to reduce the number of packets\n\t\t\t\t// just as much as the total number of bytes, so if we're going to have to send another packet\n\t\t\t\t// anyway, don't send a little sliver of a message at the beginning of a packet\n\t\t\t\t// We need to finish the header by this point if we're going to send anything\n\t\t\t\tint cbMinSegDataSizeToSend = std::min( 16, seg.m_cbSegSize );\n\t\t\t\tif ( seg.m_cbHdr + cbMinSegDataSizeToSend > cbBytesRemainingForSegments )\n\t\t\t\t{\n\t\t\t\t\t// Don't send this segment now.\n\t\t\t\t\tvecSegments.pop_back();\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\t\t\t\t++pLog->m_nSegmentsSent;\n\t\t\t\t#endif\n\n\t\t\t\t// Truncate, and leave the message in the queue\n\t\t\t\tseg.m_cbSegSize = std::min( seg.m_cbSegSize, cbBytesRemainingForSegments - seg.m_cbHdr );\n\t\t\t\tm_senderState.m_cbCurrentSendMessageSent += seg.m_cbSegSize;\n\t\t\t\tAssert( m_senderState.m_cbCurrentSendMessageSent < pSendMsg->m_cbSize );\n\t\t\t\tcbBytesRemainingForSegments -= seg.m_cbHdr + seg.m_cbSegSize;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// The whole message fit (perhaps exactly, without the size byte)\n\t\t\t// Reset send pointer for the next message\n\t\t\tAssert( m_senderState.m_cbCurrentSendMessageSent + seg.m_cbSegSize == pSendMsg->m_cbSize );\n\t\t\tm_senderState.m_cbCurrentSendMessageSent = 0;\n\n\t\t\t// Remove message from queue,w e have transfered ownership to the segment and will\n\t\t\t// dispose of the message when we serialize the segments\n\t\t\tm_senderState.m_messagesQueued.pop_front();\n\n\t\t\t// Consume payload bytes\n\t\t\tcbBytesRemainingForSegments -= seg.m_cbHdr + seg.m_cbSegSize;\n\n\t\t\t// Assume for now this won't be the last segment, in which case we will also need the byte for the size field.\n\t\t\t// NOTE: This might cause cbPayloadBytesRemaining to go negative by one!  I know that seems weird, but it actually\n\t\t\t// keeps the logic below simpler.\n\t\t\tcbBytesRemainingForSegments -= 1;\n\n\t\t\t// Update various accounting, depending on reliable or unreliable\n\t\t\tif ( pSendMsg->SNPSend_IsReliable() )\n\t\t\t{\n\t\t\t\t// Reliable segments advance the current message number.\n\t\t\t\t// NOTE: If we coalesce adjacent reliable segments, this will probably need to be adjusted\n\t\t\t\tif ( nLastMsgNum > 0 )\n\t\t\t\t\t++nLastMsgNum;\n\n\t\t\t\t// Go ahead and add us to the end of the list of unacked messages\n\t\t\t\tm_senderState.m_unackedReliableMessages.push_back( seg.m_pMsg );\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tnLastMsgNum = pSendMsg->m_nMessageNumber;\n\n\t\t\t\t// Set the \"This is the last segment in this message\" header bit\n\t\t\t\tseg.m_hdr[0] |= 0x20;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Now we know how much space we need for the segments.  If we asked to reserve\n\t// space for acks, we should have at least that much.  But we might have more.\n\t// Serialize acks, as much as will fit.  If we are badly fragmented and we have\n\t// the space, it's better to keep sending acks over and over to try to clear\n\t// it out as fast as possible.\n\tif ( cbReserveForAcks > 0 )\n\t{\n\n\t\t// If we didn't use all the space for data, that's more we could use for acks\n\t\tint cbAvailForAcks = cbReserveForAcks;\n\t\tif ( cbBytesRemainingForSegments > 0 )\n\t\t\tcbAvailForAcks += cbBytesRemainingForSegments;\n\t\tuint8 *pAckEnd = pPayloadPtr + cbAvailForAcks;\n\t\tAssert( pAckEnd <= pPayloadEnd );\n\n\t\tuint8 *pAfterAcks = SNP_SerializeAckBlocks( ackHelper, pPayloadPtr, pAckEnd, usecNow );\n\t\tif ( pAfterAcks == nullptr )\n\t\t\treturn false; // bug!  Abort\n\n\t\tint cbAckBytesWritten = pAfterAcks - pPayloadPtr;\n\t\tif ( cbAckBytesWritten > cbReserveForAcks )\n\t\t{\n\t\t\t// We used more space for acks than was strictly reserved.\n\t\t\t// Update space remaining for data segments.  We should have the room!\n\t\t\tcbBytesRemainingForSegments -= ( cbAckBytesWritten - cbReserveForAcks );\n\t\t\tAssert( cbBytesRemainingForSegments >= -1 ); // remember we might go over by one byte\n\t\t}\n\t\telse\n\t\t{\n\t\t\tAssert( cbAckBytesWritten == cbReserveForAcks ); // The code above reserves space very carefuly.  So if we reserve it, we should fill it!\n\t\t}\n\n\t\tpPayloadPtr = pAfterAcks;\n\t}\n\n\t// We are gonna send a packet.  Start filling out an entry so that when it's acked (or nacked)\n\t// we can know what to do.\n\tAssert( m_senderState.m_mapInFlightPacketsByPktNum.lower_bound( m_statsEndToEnd.m_nNextSendSequenceNumber ) == m_senderState.m_mapInFlightPacketsByPktNum.end() );\n\tstd::pair<int64,SNPInFlightPacket_t> pairInsert( m_statsEndToEnd.m_nNextSendSequenceNumber, SNPInFlightPacket_t{ usecNow, false, pTransport, {} } );\n\tSNPInFlightPacket_t &inFlightPkt = pairInsert.second;\n\n\t// We might have gone over exactly one byte, because we counted the size byte of the last\n\t// segment, which doesn't actually need to be sent\n\tAssert( cbBytesRemainingForSegments >= 0 || ( cbBytesRemainingForSegments == -1 && vecSegments.size() > 0 ) );\n\n\t// OK, now go through and actually serialize the segments\n\tint nSegments = len( vecSegments );\n\tfor ( int idx = 0 ; idx < nSegments ; ++idx )\n\t{\n\t\tEncodedSegment &seg = vecSegments[ idx ];\n\n\t\t// Check if this message is still sitting in the queue.  (If so, it has to be the first one!)\n\t\tbool bStillInQueue = ( seg.m_pMsg == m_senderState.m_messagesQueued.m_pFirst );\n\n\t\t// Finish the segment size byte\n\t\tif ( idx < nSegments-1 )\n\t\t{\n\t\t\t// Stash upper 3 bits into the header\n\t\t\tint nUpper3Bits = ( seg.m_cbSegSize>>8 );\n\t\t\tAssert( nUpper3Bits <= 4 ); // The values 5 and 6 are reserved and shouldn't be needed due to the MTU we support\n\t\t\tseg.m_hdr[0] |= nUpper3Bits;\n\n\t\t\t// And the lower 8 bits follow the other fields\n\t\t\tseg.m_hdr[ seg.m_cbHdr++ ] = uint8( seg.m_cbSegSize );\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Set \"no explicit size field included, segment extends to end of packet\"\n\t\t\tseg.m_hdr[0] |= 7;\n\t\t}\n\n\t\t// Double-check that we didn't overflow\n\t\tAssert( seg.m_cbHdr <= seg.k_cbMaxHdr );\n\n\t\t// Copy the header\n\t\tmemcpy( pPayloadPtr, seg.m_hdr, seg.m_cbHdr ); pPayloadPtr += seg.m_cbHdr;\n\t\tAssert( pPayloadPtr+seg.m_cbSegSize <= pPayloadEnd );\n\n\t\t// Reliable?\n\t\tif ( seg.m_pMsg->SNPSend_IsReliable() )\n\t\t{\n\t\t\t// We should never encode an empty range of the stream, that is worthless.\n\t\t\t// (Even an empty reliable message requires some framing in the stream.)\n\t\t\tAssert( seg.m_cbSegSize > 0 );\n\n\t\t\t// Copy the unreliable segment into the packet.  Does the portion we are serializing\n\t\t\t// begin in the header?\n\t\t\tif ( seg.m_nOffset < seg.m_pMsg->m_cbSNPSendReliableHeader )\n\t\t\t{\n\t\t\t\tint cbCopyHdr = std::min( seg.m_cbSegSize, seg.m_pMsg->m_cbSNPSendReliableHeader - seg.m_nOffset );\n\n\t\t\t\tmemcpy( pPayloadPtr, seg.m_pMsg->SNPSend_ReliableHeader() + seg.m_nOffset, cbCopyHdr );\n\t\t\t\tpPayloadPtr += cbCopyHdr;\n\n\t\t\t\tint cbCopyBody = seg.m_cbSegSize - cbCopyHdr;\n\t\t\t\tif ( cbCopyBody > 0 )\n\t\t\t\t{\n\t\t\t\t\tmemcpy( pPayloadPtr, seg.m_pMsg->m_pData, cbCopyBody );\n\t\t\t\t\tpPayloadPtr += cbCopyBody;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// This segment is entirely from the message body\n\t\t\t\tmemcpy( pPayloadPtr, (char*)seg.m_pMsg->m_pData + seg.m_nOffset - seg.m_pMsg->m_cbSNPSendReliableHeader, seg.m_cbSegSize );\n\t\t\t\tpPayloadPtr += seg.m_cbSegSize;\n\t\t\t}\n\n\n\t\t\t// Remember that this range is in-flight\n\t\t\tSNPRange_t range;\n\t\t\trange.m_nBegin = seg.m_pMsg->SNPSend_ReliableStreamPos() + seg.m_nOffset;\n\t\t\trange.m_nEnd = range.m_nBegin + seg.m_cbSegSize;\n\n\t\t\t// Ranges of the reliable stream that have not been acked should either be\n\t\t\t// in flight, or queued for retry.  Make sure this range is not already in\n\t\t\t// either state.\n\t\t\tAssert( !HasOverlappingRange( range, m_senderState.m_listInFlightReliableRange ) );\n\t\t\tAssert( !HasOverlappingRange( range, m_senderState.m_listReadyRetryReliableRange ) );\n\n\t\t\t// Spew\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld reliable msg %lld offset %d+%d=%d range [%lld,%lld)\\n\",\n\t\t\t\tGetDescription(), (long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)seg.m_pMsg->m_nMessageNumber,\n\t\t\t\tseg.m_nOffset, seg.m_cbSegSize, seg.m_nOffset+seg.m_cbSegSize,\n\t\t\t\t(long long)range.m_nBegin, (long long)range.m_nEnd );\n\n\t\t\t// Add to table of in-flight reliable ranges\n\t\t\tm_senderState.m_listInFlightReliableRange[ range ] = seg.m_pMsg;\n\n\t\t\t// Remember that this packet contained that range\n\t\t\tinFlightPkt.m_vecReliableSegments.push_back( range );\n\n\t\t\t// Less reliable data pending\n\t\t\tm_senderState.m_cbPendingReliable -= seg.m_cbSegSize;\n\t\t\tAssert( m_senderState.m_cbPendingReliable >= 0 );\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// We should only encode an empty segment if the message itself is empty\n\t\t\tAssert( seg.m_cbSegSize > 0 || ( seg.m_cbSegSize == 0 && seg.m_pMsg->m_cbSize == 0 ) );\n\n\t\t\t// Check some stuff\n\t\t\tAssert( bStillInQueue == ( seg.m_nOffset + seg.m_cbSegSize < seg.m_pMsg->m_cbSize ) ); // If we ended the message, we should have removed it from the queue\n\t\t\tAssert( bStillInQueue == ( ( seg.m_hdr[0] & 0x20 ) == 0 ) );\n\t\t\tAssert( bStillInQueue || seg.m_pMsg->m_links.m_pNext == nullptr ); // If not in the queue, we should be detached\n\t\t\tAssert( seg.m_pMsg->m_links.m_pPrev == nullptr ); // We should either be at the head of the queue, or detached\n\n\t\t\t// Copy the unreliable segment into the packet\n\t\t\tmemcpy( pPayloadPtr, (char*)seg.m_pMsg->m_pData + seg.m_nOffset, seg.m_cbSegSize );\n\t\t\tpPayloadPtr += seg.m_cbSegSize;\n\n\t\t\t// Spew\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld unreliable msg %lld offset %d+%d=%d\\n\",\n\t\t\t\tGetDescription(), (long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)seg.m_pMsg->m_nMessageNumber,\n\t\t\t\tseg.m_nOffset, seg.m_cbSegSize, seg.m_nOffset+seg.m_cbSegSize );\n\n\t\t\t// Less unreliable data pending\n\t\t\tm_senderState.m_cbPendingUnreliable -= seg.m_cbSegSize;\n\t\t\tAssert( m_senderState.m_cbPendingUnreliable >= 0 );\n\n\t\t\t// Done with this message?  Clean up\n\t\t\tif ( !bStillInQueue )\n\t\t\t\tseg.m_pMsg->Release();\n\t\t}\n\t}\n\n\t// One last check for overflow\n\tAssert( pPayloadPtr <= pPayloadEnd );\n\tint cbPlainText = pPayloadPtr - payload;\n\tif ( cbPlainText > cbMaxPlaintextPayload )\n\t{\n\t\tAssertMsg1( false, \"Payload exceeded max size of %d\\n\", cbMaxPlaintextPayload );\n\t\treturn 0;\n\t}\n\n\t// OK, we have a plaintext payload.  Encrypt and send it.\n\t// What cipher are we using?\n\tint nBytesSent = 0;\n\tswitch ( m_eNegotiatedCipher )\n\t{\n\t\tdefault:\n\t\t\tAssertMsg1( false, \"Bogus cipher %d\", m_eNegotiatedCipher );\n\t\t\tbreak;\n\n\t\tcase k_ESteamNetworkingSocketsCipher_NULL:\n\t\t{\n\n\t\t\t// No encryption!\n\t\t\t// Ask current transport to deliver it\n\t\t\tnBytesSent = pTransport->SendEncryptedDataChunk( payload, cbPlainText, ctx );\n\t\t}\n\t\tbreak;\n\n\t\tcase k_ESteamNetworkingSocketsCipher_AES_256_GCM:\n\t\t{\n\n\t\t\tAssert( m_bCryptKeysValid );\n\n\t\t\t// Adjust the IV by the packet number\n\t\t\t*(uint64 *)&m_cryptIVSend.m_buf += LittleQWord( m_statsEndToEnd.m_nNextSendSequenceNumber );\n\n\t\t\t// Encrypt the chunk\n\t\t\tuint8 arEncryptedChunk[ k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend + 64 ]; // Should not need pad\n\t\t\tuint32 cbEncrypted = sizeof(arEncryptedChunk);\n\t\t\tDbgVerify( m_cryptContextSend.Encrypt(\n\t\t\t\tpayload, cbPlainText, // plaintext\n\t\t\t\tm_cryptIVSend.m_buf, // IV\n\t\t\t\tarEncryptedChunk, &cbEncrypted, // output\n\t\t\t\tnullptr, 0 // no AAD\n\t\t\t) );\n\n\t\t\t//SpewMsg( \"Send encrypt IV %llu + %02x%02x%02x%02x  encrypted %d %02x%02x%02x%02x\\n\",\n\t\t\t//\t*(uint64 *)&m_cryptIVSend.m_buf,\n\t\t\t//\tm_cryptIVSend.m_buf[8], m_cryptIVSend.m_buf[9], m_cryptIVSend.m_buf[10], m_cryptIVSend.m_buf[11],\n\t\t\t//\tcbEncrypted,\n\t\t\t//\tarEncryptedChunk[0], arEncryptedChunk[1], arEncryptedChunk[2],arEncryptedChunk[3]\n\t\t\t//);\n\n\t\t\t// Restore the IV to the base value\n\t\t\t*(uint64 *)&m_cryptIVSend.m_buf -= LittleQWord( m_statsEndToEnd.m_nNextSendSequenceNumber );\n\n\t\t\tAssert( (int)cbEncrypted >= cbPlainText );\n\t\t\tAssert( (int)cbEncrypted <= k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend ); // confirm that pad above was not necessary and we never exceed k_nMaxSteamDatagramTransportPayload, even after encrypting\n\n\t\t\t// Ask current transport to deliver it\n\t\t\tnBytesSent = pTransport->SendEncryptedDataChunk( arEncryptedChunk, cbEncrypted, ctx );\n\t\t}\n\t}\n\tif ( nBytesSent <= 0 )\n\t\treturn false;\n\n\t// We sent a packet.  Track it\n\tauto pairInsertResult = m_senderState.m_mapInFlightPacketsByPktNum.insert( pairInsert );\n\tAssert( pairInsertResult.second ); // We should have inserted a new element, not updated an existing element\n\n\t// If we sent any reliable data, we should expect a reply\n\tif ( !inFlightPkt.m_vecReliableSegments.empty() )\n\t{\n\t\tm_statsEndToEnd.TrackSentMessageExpectingSeqNumAck( usecNow, true );\n\t\t// FIXME - should let transport know\n\t}\n\n\t// If we aren't already tracking anything to timeout, then this is the next one.\n\tif ( m_senderState.m_itNextInFlightPacketToTimeout == m_senderState.m_mapInFlightPacketsByPktNum.end() )\n\t\tm_senderState.m_itNextInFlightPacketToTimeout = pairInsertResult.first;\n\n\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\tpLog->m_cbSent = nBytesSent;\n\t#endif\n\n\t// We spent some tokens\n\tm_senderState.m_flTokenBucket -= (float)nBytesSent;\n\treturn true;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_SentNonDataPacket( CConnectionTransport *pTransport, SteamNetworkingMicroseconds usecNow )\n{\n\tstd::pair<int64,SNPInFlightPacket_t> pairInsert( m_statsEndToEnd.m_nNextSendSequenceNumber-1, SNPInFlightPacket_t{ usecNow, false, pTransport, {} } );\n\tauto pairInsertResult = m_senderState.m_mapInFlightPacketsByPktNum.insert( pairInsert );\n\tAssert( pairInsertResult.second ); // We should have inserted a new element, not updated an existing element.  Probably an order ofoperations bug with m_nNextSendSequenceNumber\n}\n\nvoid CSteamNetworkConnectionBase::SNP_GatherAckBlocks( SNPAckSerializerHelper &helper, SteamNetworkingMicroseconds usecNow )\n{\n\thelper.m_nBlocks = 0;\n\thelper.m_nBlocksNeedToAck = 0;\n\n\t// Fast case for no packet loss we need to ack, which will (hopefully!) be a common case\n\tint n = len( m_receiverState.m_mapPacketGaps ) - 1;\n\tif ( n <= 0 )\n\t\treturn;\n\n\t// Let's not just flush the acks that are due right now.  Let's flush all of them\n\t// that will be due any time before we have the bandwidth to send the next packet.\n\t// (Assuming that we send the max packet size here.)\n\tSteamNetworkingMicroseconds usecSendAcksDueBefore = usecNow;\n\tSteamNetworkingMicroseconds usecTimeUntilNextPacket = SteamNetworkingMicroseconds( ( m_senderState.m_flTokenBucket - (float)m_cbMTUPacketSize ) / (float)m_senderState.m_n_x * -1e6 );\n\tif ( usecTimeUntilNextPacket > 0 )\n\t\tusecSendAcksDueBefore += usecTimeUntilNextPacket;\n\n\tm_receiverState.DebugCheckPackGapMap();\n\n\tn = std::min( (int)helper.k_nMaxBlocks, n );\n\tauto itNext = m_receiverState.m_mapPacketGaps.begin();\n\n\tint cbEncodedSize = helper.k_cbHeaderSize;\n\twhile ( n > 0 )\n\t{\n\t\t--n;\n\t\tauto itCur = itNext;\n\t\t++itNext;\n\n\t\tAssert( itCur->first < itCur->second.m_nEnd );\n\n\t\t// Do we need to report on this block now?\n\t\tbool bNeedToReport = ( itNext->second.m_usecWhenAckPrior <= usecSendAcksDueBefore );\n\n\t\t// Should we wait to NACK this?\n\t\tif ( itCur == m_receiverState.m_itPendingNack )\n\t\t{\n\n\t\t\t// Wait to NACK this?\n\t\t\tif ( !bNeedToReport )\n\t\t\t{\n\t\t\t\tif ( usecNow < itCur->second.m_usecWhenOKToNack )\n\t\t\t\t\tbreak;\n\t\t\t\tbNeedToReport = true;\n\t\t\t}\n\n\t\t\t// Go ahead and NACK it.  If the packet arrives, we will use it.\n\t\t\t// But our NACK may cause the sender to retransmit.\n\t\t\t++m_receiverState.m_itPendingNack;\n\t\t}\n\n\t\tSNPAckSerializerHelper::Block &block = helper.m_arBlocks[ helper.m_nBlocks ];\n\t\tblock.m_nNack = uint32( itCur->second.m_nEnd - itCur->first );\n\n\t\tint64 nAckEnd;\n\t\tSteamNetworkingMicroseconds usecWhenSentLast;\n\t\tif ( n == 0 )\n\t\t{\n\t\t\t// itNext should be the sentinel\n\t\t\tAssert( itNext->first == INT64_MAX );\n\t\t\tnAckEnd = m_statsEndToEnd.m_nMaxRecvPktNum+1;\n\t\t\tusecWhenSentLast = m_statsEndToEnd.m_usecTimeLastRecvSeq;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tnAckEnd = itNext->first;\n\t\t\tusecWhenSentLast = itNext->second.m_usecWhenReceivedPktBefore;\n\t\t}\n\t\tAssert( itCur->second.m_nEnd < nAckEnd );\n\t\tblock.m_nAck = uint32( nAckEnd - itCur->second.m_nEnd );\n\n\t\tblock.m_nLatestPktNum = uint32( nAckEnd-1 );\n\t\tblock.m_nEncodedTimeSinceLatestPktNum = SNPAckSerializerHelper::EncodeTimeSince( usecNow, usecWhenSentLast );\n\n\t\t// When we encode 7+ blocks, the header grows by one byte\n\t\t// to store an explicit count\n\t\tif ( helper.m_nBlocks == 6 )\n\t\t\t++cbEncodedSize;\n\n\t\t// This block\n\t\t++cbEncodedSize;\n\t\tif ( block.m_nAck > 7 )\n\t\t\tcbEncodedSize += VarIntSerializedSize( block.m_nAck>>3 );\n\t\tif ( block.m_nNack > 7 )\n\t\t\tcbEncodedSize += VarIntSerializedSize( block.m_nNack>>3 );\n\t\tblock.m_cbTotalEncodedSize = cbEncodedSize;\n\n\t\t// FIXME Here if the caller knows they are working with limited space,\n\t\t// they could tell us how much space they have and we could bail\n\t\t// if we already know we're over\n\n\t\t++helper.m_nBlocks;\n\n\t\t// Do we really need to try to flush the ack/nack for that block out now?\n\t\tif ( bNeedToReport )\n\t\t\thelper.m_nBlocksNeedToAck = helper.m_nBlocks;\n\t}\n}\n\nuint8 *CSteamNetworkConnectionBase::SNP_SerializeAckBlocks( const SNPAckSerializerHelper &helper, uint8 *pOut, const uint8 *pOutEnd, SteamNetworkingMicroseconds usecNow )\n{\n\n\t// We shouldn't be called if we never received anything\n\tAssert( m_statsEndToEnd.m_nMaxRecvPktNum > 0 );\n\n\t// No room even for the header?\n\tif ( pOut + SNPAckSerializerHelper::k_cbHeaderSize > pOutEnd )\n\t\treturn pOut;\n\n\t// !KLUDGE! For now limit number of blocks, and always use 16-bit ID.\n\t//          Later we might want to make this code smarter.\n\tCOMPILE_TIME_ASSERT( SNPAckSerializerHelper::k_cbHeaderSize == 5 );\n\tuint8 *pAckHeaderByte = pOut;\n\t++pOut;\n\tuint16 *pLatestPktNum = (uint16 *)pOut;\n\tpOut += 2;\n\tuint16 *pTimeSinceLatestPktNum = (uint16 *)pOut;\n\tpOut += 2;\n\n\t// 10011000 - ack frame designator, with 16-bit last-received sequence number, and no ack blocks\n\t*pAckHeaderByte = 0x98;\n\n\tint nLogLevelPacketDecode = m_connectionConfig.m_LogLevel_PacketDecode.Get();\n\n\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\tPacketSendLog *pLog = &m_vecSendLog[ m_vecSendLog.size()-1 ];\n\t#endif\n\n\t// Fast case for no packet loss we need to ack, which will (hopefully!) be a common case\n\tif ( m_receiverState.m_mapPacketGaps.size() == 1 )\n\t{\n\t\tint64 nLastRecvPktNum = m_statsEndToEnd.m_nMaxRecvPktNum;\n\t\t*pLatestPktNum = LittleWord( (uint16)nLastRecvPktNum );\n\t\t*pTimeSinceLatestPktNum = LittleWord( (uint16)SNPAckSerializerHelper::EncodeTimeSince( usecNow, m_statsEndToEnd.m_usecTimeLastRecvSeq ) );\n\n\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld last recv %lld (no loss)\\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)nLastRecvPktNum\n\t\t);\n\t\tm_receiverState.m_mapPacketGaps.rbegin()->second.m_usecWhenAckPrior = INT64_MAX; // Clear timer, we wrote everything we needed to\n\n\t\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\t\tpLog->m_nAckBlocksSent = 0;\n\t\t\tpLog->m_nAckEnd = nLastRecvPktNum;\n\t\t#endif\n\n\t\treturn pOut;\n\t}\n\n\t// Fit as many blocks as possible.\n\t// (Unless we are badly fragmented and are trying to squeeze in what\n\t// we can at the end of a packet, this won't ever iterate\n\tint nBlocks = helper.m_nBlocks;\n\tuint8 *pExpectedOutEnd;\n\tfor (;;)\n\t{\n\n\t\t// Not sending any blocks at all?  (Either they don't fit, or we are waiting because we don't\n\t\t// want to nack yet.)  Just fill in the header with the oldest ack\n\t\tif ( nBlocks == 0 )\n\t\t{\n\t\t\tauto itOldestGap = m_receiverState.m_mapPacketGaps.begin();\n\t\t\tint64 nLastRecvPktNum = itOldestGap->first-1;\n\t\t\t*pLatestPktNum = LittleWord( uint16( nLastRecvPktNum ) );\n\t\t\t*pTimeSinceLatestPktNum = LittleWord( (uint16)SNPAckSerializerHelper::EncodeTimeSince( usecNow, itOldestGap->second.m_usecWhenReceivedPktBefore ) );\n\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld last recv %lld (no blocks, actual last recv=%lld)\\n\",\n\t\t\t\tGetDescription(),\n\t\t\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)nLastRecvPktNum, (long long)m_statsEndToEnd.m_nMaxRecvPktNum\n\t\t\t);\n\n\t\t\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\t\t\tpLog->m_nAckBlocksSent = 0;\n\t\t\t\tpLog->m_nAckEnd = nLastRecvPktNum;\n\t\t\t#endif\n\n\t\t\t// Acked packets before this gap.  Were we waiting to flush them?\n\t\t\tif ( itOldestGap == m_receiverState.m_itPendingAck )\n\t\t\t{\n\t\t\t\t// Mark it as sent\n\t\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\t\t++m_receiverState.m_itPendingAck;\n\t\t\t}\n\n\t\t\t// NOTE: We did NOT nack anything just now\n\t\t\treturn pOut;\n\t\t}\n\n\t\tint cbTotalEncoded = helper.m_arBlocks[nBlocks-1].m_cbTotalEncodedSize;\n\t\tpExpectedOutEnd = pAckHeaderByte + cbTotalEncoded; // Save for debugging below\n\t\tif ( pExpectedOutEnd <= pOutEnd )\n\t\t\tbreak;\n\n\t\t// Won't fit, peel off the newest one, see if the earlier ones will fit\n\t\t--nBlocks;\n\t}\n\n\t// OK, we know how many blocks we are going to write.  Finish the header byte\n\tAssert( nBlocks == uint8(nBlocks) );\n\tif ( nBlocks > 6 )\n\t{\n\t\t*pAckHeaderByte |= 7;\n\t\t*(pOut++) = uint8( nBlocks );\n\t}\n\telse\n\t{\n\t\t*pAckHeaderByte |= uint8( nBlocks );\n\t}\n\n\t// Locate the first one we will serialize.\n\t// (It's the newest one, which is the last one in the list).\n\tconst SNPAckSerializerHelper::Block *pBlock = &helper.m_arBlocks[nBlocks-1];\n\n\t// Latest packet number and time\n\t*pLatestPktNum = LittleWord( uint16( pBlock->m_nLatestPktNum ) );\n\t*pTimeSinceLatestPktNum = LittleWord( pBlock->m_nEncodedTimeSinceLatestPktNum );\n\n\t// Full packet number, for spew\n\tint64 nAckEnd = ( m_statsEndToEnd.m_nMaxRecvPktNum & ~(int64)(~(uint32)0) ) | pBlock->m_nLatestPktNum;\n\t++nAckEnd;\n\n\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\tpLog->m_nAckBlocksSent = nBlocks;\n\t\tpLog->m_nAckEnd = nAckEnd;\n\t#endif\n\n\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld last recv %lld (%d blocks, actual last recv=%lld)\\n\",\n\t\tGetDescription(),\n\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)(nAckEnd-1), nBlocks, (long long)m_statsEndToEnd.m_nMaxRecvPktNum\n\t);\n\n\t// Check for a common case where we report on everything\n\tif ( nAckEnd > m_statsEndToEnd.m_nMaxRecvPktNum )\n\t{\n\t\tAssert( nAckEnd == m_statsEndToEnd.m_nMaxRecvPktNum+1 );\n\t\tfor (;;)\n\t\t{\n\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\tif ( m_receiverState.m_itPendingAck->first == INT64_MAX )\n\t\t\t\tbreak;\n\t\t\t++m_receiverState.m_itPendingAck;\n\t\t}\n\t\tm_receiverState.m_itPendingNack = m_receiverState.m_itPendingAck;\n\t}\n\telse\n\t{\n\n\t\t// Advance pointer to next block that needs to be acked,\n\t\t// past the ones we are about to ack.\n\t\tif ( m_receiverState.m_itPendingAck->first <= nAckEnd )\n\t\t{\n\t\t\tdo\n\t\t\t{\n\t\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\t\t++m_receiverState.m_itPendingAck;\n\t\t\t} while ( m_receiverState.m_itPendingAck->first <= nAckEnd );\n\t\t}\n\n\t\t// Advance pointer to next block that needs to be nacked, past the ones\n\t\t// we are about to nack.\n\t\twhile ( m_receiverState.m_itPendingNack->first < nAckEnd )\n\t\t\t++m_receiverState.m_itPendingNack;\n\t}\n\n\t// Serialize the blocks into the packet, from newest to oldest\n\twhile ( pBlock >= helper.m_arBlocks )\n\t{\n\t\tuint8 *pAckBlockHeaderByte = pOut;\n\t\t++pOut;\n\n\t\t// Encode ACK (number of packets successfully received)\n\t\t{\n\t\t\tif ( pBlock->m_nAck < 8 )\n\t\t\t{\n\t\t\t\t// Small block of packets.  Encode directly in the header.\n\t\t\t\t*pAckBlockHeaderByte = uint8(pBlock->m_nAck << 4);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Larger block of received packets.  Put lowest bits in the header,\n\t\t\t\t// and overflow using varint.  This is probably going to be pretty\n\t\t\t\t// common.\n\t\t\t\t*pAckBlockHeaderByte = 0x80 | ( uint8(pBlock->m_nAck & 7) << 4 );\n\t\t\t\tpOut = SerializeVarInt( pOut, pBlock->m_nAck>>3, pOutEnd );\n\t\t\t\tif ( pOut == nullptr )\n\t\t\t\t{\n\t\t\t\t\tAssertMsg( false, \"Overflow serializing packet ack varint count\" );\n\t\t\t\t\treturn nullptr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Encode NACK (number of packets dropped)\n\t\t{\n\t\t\tif ( pBlock->m_nNack < 8 )\n\t\t\t{\n\t\t\t\t// Small block of packets.  Encode directly in the header.\n\t\t\t\t*pAckBlockHeaderByte |= uint8(pBlock->m_nNack);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Larger block of dropped packets.  Put lowest bits in the header,\n\t\t\t\t// and overflow using varint.  This is probably going to be less common than\n\t\t\t\t// large ACK runs, but not totally uncommon.  Losing one or two packets is\n\t\t\t\t// really common, but loss events often involve a lost of many packets in a run.\n\t\t\t\t*pAckBlockHeaderByte |= 0x08 | uint8(pBlock->m_nNack & 7);\n\t\t\t\tpOut = SerializeVarInt( pOut, pBlock->m_nNack >> 3, pOutEnd );\n\t\t\t\tif ( pOut == nullptr )\n\t\t\t\t{\n\t\t\t\t\tAssertMsg( false, \"Overflow serializing packet nack varint count\" );\n\t\t\t\t\treturn nullptr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Debug\n\t\tint64 nAckBegin = nAckEnd - pBlock->m_nAck;\n\t\tint64 nNackBegin = nAckBegin - pBlock->m_nNack;\n\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld nack [%lld,%lld) ack [%lld,%lld) \\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber,\n\t\t\t(long long)nNackBegin, (long long)nAckBegin,\n\t\t\t(long long)nAckBegin, (long long)nAckEnd\n\t\t);\n\t\tnAckEnd = nNackBegin;\n\t\tAssert( nAckEnd > 0 ); // Make sure we don't try to ack packet 0 or below\n\n\t\t// Move backwards in time\n\t\t--pBlock;\n\t}\n\n\t// Make sure when we were checking what would fit, we correctly calculated serialized size\n\tAssert( pOut == pExpectedOutEnd );\n\n\treturn pOut;\n}\n\nuint8 *CSteamNetworkConnectionBase::SNP_SerializeStopWaitingFrame( uint8 *pOut, const uint8 *pOutEnd, SteamNetworkingMicroseconds usecNow )\n{\n\t// For now, we will always write this.  We should optimize this and try to be\n\t// smart about when to send it (probably maybe once per RTT, or when N packets\n\t// have been received or N blocks accumulate?)\n\n\t// Calculate offset from the current sequence number\n\tint64 nOffset = m_statsEndToEnd.m_nNextSendSequenceNumber - m_senderState.m_nMinPktWaitingOnAck;\n\tAssertMsg2( nOffset > 0, \"Told peer to stop acking up to %lld, but latest packet we have sent is %lld\", (long long)m_senderState.m_nMinPktWaitingOnAck, (long long)m_statsEndToEnd.m_nNextSendSequenceNumber );\n\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketDecode.Get(), \"[%s]   encode pkt %lld stop_waiting offset %lld = %lld\",\n\t\tGetDescription(),\n\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)nOffset, (long long)m_senderState.m_nMinPktWaitingOnAck );\n\n\t// Subtract one, as a *tiny* optimization, since they cannot possible have\n\t// acknowledged this packet we are serializing already\n\t--nOffset;\n\n\t// Now encode based on number of bits needed\n\tif ( nOffset < 0x100 )\n\t{\n\t\tif ( pOut + 2 > pOutEnd )\n\t\t\treturn pOut;\n\t\t*pOut = 0x80;\n\t\t++pOut;\n\t\t*pOut = uint8( nOffset );\n\t\t++pOut;\n\t}\n\telse if ( nOffset < 0x10000 )\n\t{\n\t\tif ( pOut + 3 > pOutEnd )\n\t\t\treturn pOut;\n\t\t*pOut = 0x81;\n\t\t++pOut;\n\t\t*(uint16*)pOut = LittleWord( uint16( nOffset ) );\n\t\tpOut += 2;\n\t}\n\telse if ( nOffset < 0x1000000 )\n\t{\n\t\tif ( pOut + 4 > pOutEnd )\n\t\t\treturn pOut;\n\t\t*pOut = 0x82;\n\t\t++pOut;\n\t\t*pOut = uint8( nOffset ); // Wire format is little endian, so lowest 8 bits first\n\t\t++pOut;\n\t\t*(uint16*)pOut = LittleWord( uint16( nOffset>>8 ) );\n\t\tpOut += 2;\n\t}\n\telse\n\t{\n\t\tif ( pOut + 9 > pOutEnd )\n\t\t\treturn pOut;\n\t\t*pOut = 0x83;\n\t\t++pOut;\n\t\t*(uint64*)pOut = LittleQWord( nOffset );\n\t\tpOut += 8;\n\t}\n\n\tAssert( pOut <= pOutEnd );\n\treturn pOut;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_ReceiveUnreliableSegment( int64 nMsgNum, int nOffset, const void *pSegmentData, int cbSegmentSize, bool bLastSegmentInMessage, SteamNetworkingMicroseconds usecNow )\n{\n\tSpewDebugGroup( m_connectionConfig.m_LogLevel_PacketDecode.Get(), \"[%s] RX msg %lld offset %d+%d=%d %02x ... %02x\\n\", GetDescription(), nMsgNum, nOffset, cbSegmentSize, nOffset+cbSegmentSize, ((byte*)pSegmentData)[0], ((byte*)pSegmentData)[cbSegmentSize-1] );\n\n\t// Ignore data segments when we are not going to process them (e.g. linger)\n\tif ( GetState() != k_ESteamNetworkingConnectionState_Connected )\n\t{\n\t\tSpewDebugGroup( m_connectionConfig.m_LogLevel_PacketDecode.Get(), \"[%s] discarding msg %lld [%d,%d) as connection is in state %d\\n\",\n\t\t\tGetDescription(),\n\t\t\tnMsgNum,\n\t\t\tnOffset, nOffset+cbSegmentSize,\n\t\t\t(int)GetState() );\n\t\treturn;\n\t}\n\n\t// Check for a common special case: non-fragmented message.\n\tif ( nOffset == 0 && bLastSegmentInMessage )\n\t{\n\n\t\t// Deliver it immediately, don't go through the fragmentation assembly process below.\n\t\t// (Although that would work.)\n\t\tReceivedMessage( pSegmentData, cbSegmentSize, nMsgNum, k_nSteamNetworkingSend_Unreliable, usecNow );\n\t\treturn;\n\t}\n\n\t// Limit number of unreliable segments we store.  We just use a fixed\n\t// limit, rather than trying to be smart by expiring based on time or whatever.\n\tif ( len( m_receiverState.m_mapUnreliableSegments ) > k_nMaxBufferedUnreliableSegments )\n\t{\n\t\tauto itDelete = m_receiverState.m_mapUnreliableSegments.begin();\n\n\t\t// If we're going to delete some, go ahead and delete all of them for this\n\t\t// message.\n\t\tint64 nDeleteMsgNum = itDelete->first.m_nMsgNum;\n\t\tdo {\n\t\t\titDelete = m_receiverState.m_mapUnreliableSegments.erase( itDelete );\n\t\t} while ( itDelete != m_receiverState.m_mapUnreliableSegments.end() && itDelete->first.m_nMsgNum == nDeleteMsgNum );\n\n\t\t// Warn if the message we are receiving is older (or the same) than the one\n\t\t// we are deleting.  If sender is legit, then it probably means that we have\n\t\t// something tuned badly.\n\t\tif ( nDeleteMsgNum >= nMsgNum )\n\t\t{\n\t\t\t// Spew, but rate limit in case of malicious sender\n\t\t\tSpewWarningRateLimited( usecNow, \"[%s] SNP expiring unreliable segments for msg %lld, while receiving unreliable segments for msg %lld\\n\",\n\t\t\t\tGetDescription(), (long long)nDeleteMsgNum, (long long)nMsgNum );\n\t\t}\n\t}\n\n\t// Message fragment.  Find/insert the entry in our reassembly queue\n\t// I really hate this syntax and interface.\n\tSSNPRecvUnreliableSegmentKey key;\n\tkey.m_nMsgNum = nMsgNum;\n\tkey.m_nOffset = nOffset;\n\tSSNPRecvUnreliableSegmentData &data = m_receiverState.m_mapUnreliableSegments[ key ];\n\tif ( data.m_cbSegSize >= 0 )\n\t{\n\t\t// We got another segment starting at the same offset.  This is weird, since they shouldn't\n\t\t// be doing.  But remember that we're working on top of UDP, which could deliver packets\n\t\t// multiple times.  We'll spew about it, just in case it indicates a bug in this code or the sender.\n\t\tSpewWarningRateLimited( usecNow, \"[%s] Received unreliable msg %lld segment offset %d twice.  Sizes %d,%d, last=%d,%d\\n\",\n\t\t\tGetDescription(), nMsgNum, nOffset, data.m_cbSegSize, cbSegmentSize, (int)data.m_bLast, (int)bLastSegmentInMessage );\n\n\t\t// Just drop the segment.  Note that the sender might have sent a longer segment from the previous\n\t\t// one, in which case this segment contains new data, and is not therefore redundant.  That seems\n\t\t// \"legal\", but very weird, and not worth handling.  If senders do retransmit unreliable segments\n\t\t// (perhaps FEC?) then they need to retransmit the exact same segments.\n\t\treturn;\n\t}\n\n\t// Segment in the map either just got inserted, or is a subset of the segment\n\t// we just received.  Replace it.\n\tdata.m_cbSegSize = cbSegmentSize;\n\tAssert( !data.m_bLast );\n\tdata.m_bLast = bLastSegmentInMessage;\n\tmemcpy( data.m_buf, pSegmentData, cbSegmentSize );\n\n\t// Now check if that completed the message\n\tkey.m_nOffset = 0;\n\tauto itMsgStart = m_receiverState.m_mapUnreliableSegments.lower_bound( key );\n\tauto end = m_receiverState.m_mapUnreliableSegments.end();\n\tAssert( itMsgStart != end );\n\tauto itMsgLast = itMsgStart;\n\tint cbMessageSize = 0;\n\tfor (;;)\n\t{\n\t\t// Is this the thing we expected?\n\t\tif ( itMsgLast->first.m_nMsgNum != nMsgNum || itMsgLast->first.m_nOffset > cbMessageSize )\n\t\t\treturn; // We've got a gap.\n\n\t\t// Update.  This code looks more complicated than strictly necessary, but it works\n\t\t// if we have overlapping segments.\n\t\tcbMessageSize = std::max( cbMessageSize, itMsgLast->first.m_nOffset + itMsgLast->second.m_cbSegSize );\n\n\t\t// Is that the end?\n\t\tif ( itMsgLast->second.m_bLast )\n\t\t\tbreak;\n\n\t\t// Still looking for the end\n\t\t++itMsgLast;\n\t\tif ( itMsgLast == end )\n\t\t\treturn;\n\t}\n\n\tCSteamNetworkingMessage *pMsg = CSteamNetworkingMessage::New( this, cbMessageSize, nMsgNum, k_nSteamNetworkingSend_Unreliable, usecNow );\n\tif ( !pMsg )\n\t\treturn;\n\n\t// OK, we have the complete message!  Gather the\n\t// segments into a contiguous buffer\n\tfor (;;)\n\t{\n\t\tAssert( itMsgStart->first.m_nMsgNum == nMsgNum );\n\t\tmemcpy( (char *)pMsg->m_pData + itMsgStart->first.m_nOffset, itMsgStart->second.m_buf, itMsgStart->second.m_cbSegSize );\n\n\t\t// Done?\n\t\tif ( itMsgStart->second.m_bLast )\n\t\t\tbreak;\n\n\t\t// Remove entry from list, and move onto the next entry\n\t\titMsgStart = m_receiverState.m_mapUnreliableSegments.erase( itMsgStart );\n\t}\n\n\t// Erase the last segment, and anything else we might have hanging around\n\t// for this message (???)\n\tdo {\n\t\titMsgStart = m_receiverState.m_mapUnreliableSegments.erase( itMsgStart );\n\t} while ( itMsgStart != end && itMsgStart->first.m_nMsgNum == nMsgNum );\n\n\t// Deliver the message.\n\tReceivedMessage( pMsg );\n}\n\nbool CSteamNetworkConnectionBase::SNP_ReceiveReliableSegment( int64 nPktNum, int64 nSegBegin, const uint8 *pSegmentData, int cbSegmentSize, SteamNetworkingMicroseconds usecNow )\n{\n\tint nLogLevelPacketDecode = m_connectionConfig.m_LogLevel_PacketDecode.Get();\n\n\t// Calculate segment end stream position\n\tint64 nSegEnd = nSegBegin + cbSegmentSize;\n\n\t// Spew\n\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld reliable range [%lld,%lld)\\n\",\n\t\tGetDescription(),\n\t\t(long long)nPktNum,\n\t\t(long long)nSegBegin, (long long)nSegEnd );\n\n\t// No segment data?  Seems fishy, but if it happens, just skip it.\n\tAssert( cbSegmentSize >= 0 );\n\tif ( cbSegmentSize <= 0 )\n\t{\n\t\t// Spew but rate limit in case of malicious sender\n\t\tSpewWarningRateLimited( usecNow, \"[%s] decode pkt %lld empty reliable segment?\\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)nPktNum );\n\t\treturn true;\n\t}\n\n\t// Ignore data segments when we are not going to process them (e.g. linger)\n\tif ( GetState() != k_ESteamNetworkingConnectionState_Connected )\n\t{\n\t\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s]   discarding pkt %lld [%lld,%lld) as connection is in state %d\\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)nPktNum,\n\t\t\t(long long)nSegBegin, (long long)nSegEnd,\n\t\t\t(int)GetState() );\n\t\treturn true;\n\t}\n\n\t// Check if the entire thing is stuff we have already received, then\n\t// we can discard it\n\tif ( nSegEnd <= m_receiverState.m_nReliableStreamPos )\n\t\treturn true;\n\n\t// !SPEED! Should we have a fast path here for small messages\n\t// where we have nothing buffered, and avoid all the copying into the \n\t// stream buffer and decode directly.\n\n\t// What do we expect to receive next?\n\tconst int64 nExpectNextStreamPos = m_receiverState.m_nReliableStreamPos + len( m_receiverState.m_bufReliableStream );\n\n\t// Check if we need to grow the reliable buffer to hold the data\n\tif ( nSegEnd > nExpectNextStreamPos )\n\t{\n\t\tint64 cbNewSize = nSegEnd - m_receiverState.m_nReliableStreamPos;\n\t\tAssert( cbNewSize > len( m_receiverState.m_bufReliableStream ) );\n\n\t\t// Check if we have too much data buffered, just stop processing\n\t\t// this packet, and forget we ever received it.  We need to protect\n\t\t// against a malicious sender trying to create big gaps.  If they\n\t\t// are legit, they will notice that we go back and fill in the gaps\n\t\t// and we will get caught up.\n\t\tif ( cbNewSize > k_cbMaxBufferedReceiveReliableData )\n\t\t{\n\t\t\t// Stop processing the packet, and don't ack it.\n\t\t\t// This indicates the connection is in pretty bad shape,\n\t\t\t// so spew about it.  But rate limit in case of malicious sender\n\t\t\tSpewWarningRateLimited( usecNow, \"[%s] decode pkt %lld abort.  %lld bytes reliable data buffered [%lld-%lld), new size would be %lld to %lld\\n\",\n\t\t\t\tGetDescription(),\n\t\t\t\t(long long)nPktNum,\n\t\t\t\t(long long)m_receiverState.m_bufReliableStream.size(),\n\t\t\t\t(long long)m_receiverState.m_nReliableStreamPos,\n\t\t\t\t(long long)( m_receiverState.m_nReliableStreamPos + m_receiverState.m_bufReliableStream.size() ),\n\t\t\t\t(long long)cbNewSize, (long long)nSegEnd\n\t\t\t);\n\t\t\treturn false;  // DO NOT ACK THIS PACKET\n\t\t}\n\n\t\t// Check if this is going to make a new gap\n\t\tif ( nSegBegin > nExpectNextStreamPos )\n\t\t{\n\t\t\tif ( !m_receiverState.m_mapReliableStreamGaps.empty() )\n\t\t\t{\n\n\t\t\t\t// We should never have a gap at the very end of the buffer.\n\t\t\t\t// (Why would we extend the buffer, unless we needed to to\n\t\t\t\t// store some data?)\n\t\t\t\tAssert( m_receiverState.m_mapReliableStreamGaps.rbegin()->second < nExpectNextStreamPos );\n\n\t\t\t\t// We need to add a new gap.  See if we're already too fragmented.\n\t\t\t\tif ( len( m_receiverState.m_mapReliableStreamGaps ) >= k_nMaxReliableStreamGaps_Extend )\n\t\t\t\t{\n\t\t\t\t\t// Stop processing the packet, and don't ack it\n\t\t\t\t\t// This indicates the connection is in pretty bad shape,\n\t\t\t\t\t// so spew about it.  But rate limit in case of malicious sender\n\t\t\t\t\tSpewWarningRateLimited( usecNow, \"[%s] decode pkt %lld abort.  Reliable stream already has %d fragments, first is [%lld,%lld), last is [%lld,%lld), new segment is [%lld,%lld)\\n\",\n\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t(long long)nPktNum,\n\t\t\t\t\t\tlen( m_receiverState.m_mapReliableStreamGaps ),\n\t\t\t\t\t\t(long long)m_receiverState.m_mapReliableStreamGaps.begin()->first, (long long)m_receiverState.m_mapReliableStreamGaps.begin()->second,\n\t\t\t\t\t\t(long long)m_receiverState.m_mapReliableStreamGaps.rbegin()->first, (long long)m_receiverState.m_mapReliableStreamGaps.rbegin()->second,\n\t\t\t\t\t\t(long long)nSegBegin, (long long)nSegEnd\n\t\t\t\t\t);\n\t\t\t\t\treturn false;  // DO NOT ACK THIS PACKET\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Add a gap\n\t\t\tm_receiverState.m_mapReliableStreamGaps[ nExpectNextStreamPos ] = nSegBegin;\n\t\t}\n\t\tm_receiverState.m_bufReliableStream.resize( size_t( cbNewSize ) );\n\t}\n\n\t// If segment overlapped the existing buffer, we might need to discard the front\n\t// bit or discard a gap that was filled\n\tif ( nSegBegin < nExpectNextStreamPos )\n\t{\n\n\t\t// Check if the front bit has already been processed, then skip it\n\t\tif ( nSegBegin < m_receiverState.m_nReliableStreamPos )\n\t\t{\n\t\t\tint nSkip = m_receiverState.m_nReliableStreamPos - nSegBegin;\n\t\t\tcbSegmentSize -= nSkip;\n\t\t\tpSegmentData += nSkip;\n\t\t\tnSegBegin += nSkip;\n\t\t}\n\t\tAssert( nSegBegin < nSegEnd );\n\n\t\t// Check if this filled in one or more gaps (or made a hole in the middle!)\n\t\tif ( !m_receiverState.m_mapReliableStreamGaps.empty() )\n\t\t{\n\t\t\tauto gapFilled = m_receiverState.m_mapReliableStreamGaps.upper_bound( nSegBegin );\n\t\t\tif ( gapFilled != m_receiverState.m_mapReliableStreamGaps.begin() )\n\t\t\t{\n\t\t\t\t--gapFilled;\n\t\t\t\tAssert( gapFilled->first < gapFilled->second ); // Make sure we don't have degenerate/invalid gaps in our table\n\t\t\t\tAssert( gapFilled->first <= nSegBegin ); // Make sure we located the gap we think we located\n\t\t\t\tif ( gapFilled->second > nSegBegin ) // gap is not entirely before this segment\n\t\t\t\t{\n\t\t\t\t\tdo {\n\n\t\t\t\t\t\t// Common case where we fill exactly at the start\n\t\t\t\t\t\tif ( nSegBegin == gapFilled->first )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif ( nSegEnd < gapFilled->second )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t// We filled the first bit of the gap.  Chop off the front bit that we filled.\n\t\t\t\t\t\t\t\t// We cast away const here because we know that we aren't violating the ordering constraints\n\t\t\t\t\t\t\t\tconst_cast<int64&>( gapFilled->first ) = nSegEnd;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// Filled the whole gap.\n\t\t\t\t\t\t\t// Erase, and move forward in case this also fills more gaps\n\t\t\t\t\t\t\t// !SPEED! Since exactly filing the gap should be common, we might\n\t\t\t\t\t\t\t// check specifically for that case and early out here.\n\t\t\t\t\t\t\tgapFilled = m_receiverState.m_mapReliableStreamGaps.erase( gapFilled );\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if ( nSegEnd >= gapFilled->second )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Chop off the end of the gap\n\t\t\t\t\t\t\tAssert( nSegBegin < gapFilled->second );\n\t\t\t\t\t\t\tgapFilled->second = nSegBegin;\n\n\t\t\t\t\t\t\t// And maybe subsequent gaps!\n\t\t\t\t\t\t\t++gapFilled;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// We are fragmenting.\n\t\t\t\t\t\t\tAssert( nSegBegin > gapFilled->first );\n\t\t\t\t\t\t\tAssert( nSegEnd < gapFilled->second );\n\n\t\t\t\t\t\t\t// Protect against malicious sender.  A good sender will\n\t\t\t\t\t\t\t// fill the gaps in stream position order and not fragment\n\t\t\t\t\t\t\t// like this\n\t\t\t\t\t\t\tif ( len( m_receiverState.m_mapReliableStreamGaps ) >= k_nMaxReliableStreamGaps_Fragment )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t// Stop processing the packet, and don't ack it\n\t\t\t\t\t\t\t\tSpewWarningRateLimited( usecNow, \"[%s] decode pkt %lld abort.  Reliable stream already has %d fragments, first is [%lld,%lld), last is [%lld,%lld).  We don't want to fragment [%lld,%lld) with new segment [%lld,%lld)\\n\",\n\t\t\t\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t\t\t\t(long long)nPktNum,\n\t\t\t\t\t\t\t\t\tlen( m_receiverState.m_mapReliableStreamGaps ),\n\t\t\t\t\t\t\t\t\t(long long)m_receiverState.m_mapReliableStreamGaps.begin()->first, (long long)m_receiverState.m_mapReliableStreamGaps.begin()->second,\n\t\t\t\t\t\t\t\t\t(long long)m_receiverState.m_mapReliableStreamGaps.rbegin()->first, (long long)m_receiverState.m_mapReliableStreamGaps.rbegin()->second,\n\t\t\t\t\t\t\t\t\t(long long)gapFilled->first, (long long)gapFilled->second,\n\t\t\t\t\t\t\t\t\t(long long)nSegBegin, (long long)nSegEnd\n\t\t\t\t\t\t\t\t);\n\t\t\t\t\t\t\t\treturn false;  // DO NOT ACK THIS PACKET\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// Save bounds of the right side\n\t\t\t\t\t\t\tint64 nRightHandBegin = nSegEnd;\n\t\t\t\t\t\t\tint64 nRightHandEnd = gapFilled->second;\n\n\t\t\t\t\t\t\t// Truncate the left side\n\t\t\t\t\t\t\tgapFilled->second = nSegBegin;\n\n\t\t\t\t\t\t\t// Add the right hand gap\n\t\t\t\t\t\t\tm_receiverState.m_mapReliableStreamGaps[ nRightHandBegin ] = nRightHandEnd;\n\n\t\t\t\t\t\t\t// And we know that we cannot possible have covered any more gaps\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// In some rare cases we might fill more than one gap with a single segment.\n\t\t\t\t\t\t// So keep searching forward.\n\t\t\t\t\t} while ( gapFilled != m_receiverState.m_mapReliableStreamGaps.end() && gapFilled->first < nSegEnd );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Copy the data into the buffer.\n\t// It might be redundant, but if so, we aren't going to take the\n\t// time to figure that out.\n\tint nBufOffset = nSegBegin - m_receiverState.m_nReliableStreamPos;\n\tAssert( nBufOffset >= 0 );\n\tAssert( nBufOffset+cbSegmentSize <= len( m_receiverState.m_bufReliableStream ) );\n\tmemcpy( &m_receiverState.m_bufReliableStream[nBufOffset], pSegmentData, cbSegmentSize );\n\n\t// Figure out how many valid bytes are at the head of the buffer\n\tint nNumReliableBytes;\n\tif ( m_receiverState.m_mapReliableStreamGaps.empty() )\n\t{\n\t\tnNumReliableBytes = len( m_receiverState.m_bufReliableStream );\n\t}\n\telse\n\t{\n\t\tauto firstGap = m_receiverState.m_mapReliableStreamGaps.begin();\n\t\tAssert( firstGap->first >= m_receiverState.m_nReliableStreamPos );\n\t\tif ( firstGap->first < nSegBegin )\n\t\t{\n\t\t\t// There's gap in front of us, and therefore if we didn't have\n\t\t\t// a complete reliable message before, we don't have one now.\n\t\t\tAssert( firstGap->second <= nSegBegin );\n\t\t\treturn true;\n\t\t}\n\n\t\t// We do have a gap, but it's somewhere after this segment.\n\t\tAssert( firstGap->first >= nSegEnd );\n\t\tnNumReliableBytes = firstGap->first - m_receiverState.m_nReliableStreamPos;\n\t\tAssert( nNumReliableBytes > 0 );\n\t\tAssert( nNumReliableBytes < len( m_receiverState.m_bufReliableStream ) ); // The last byte in the buffer should always be valid!\n\t}\n\tAssert( nNumReliableBytes > 0 );\n\n\t// OK, now dispatch as many reliable messages as are now available\n\tdo\n\t{\n\n\t\t// OK, if we get here, we have some data.  Attempt to decode a reliable message.\n\t\t// NOTE: If the message is really big, we will end up doing this parsing work\n\t\t// each time we get a new packet.  We could cache off the result if we find out\n\t\t// that it's worth while.  It should be pretty fast, though, so let's keep the\n\t\t// code simple until we know that it's worthwhile.\n\t\tuint8 *pReliableStart = &m_receiverState.m_bufReliableStream[0];\n\t\tuint8 *pReliableDecode = pReliableStart;\n\t\tuint8 *pReliableEnd = pReliableDecode + nNumReliableBytes;\n\n\t\t// Spew\n\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld valid reliable bytes = %d [%lld,%lld)\\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)nPktNum, nNumReliableBytes,\n\t\t\t(long long)m_receiverState.m_nReliableStreamPos,\n\t\t\t(long long)( m_receiverState.m_nReliableStreamPos + nNumReliableBytes ) );\n\n\t\t// Sanity check that we have a valid header byte.\n\t\tuint8 nHeaderByte = *(pReliableDecode++);\n\t\tif ( nHeaderByte & 0x80 )\n\t\t{\n\t\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError, \"Invalid reliable message header byte 0x%02x\", nHeaderByte );\n\t\t\treturn false;\n\t\t}\n\n\t\t// Parse the message number\n\t\tint64 nMsgNum = m_receiverState.m_nLastRecvReliableMsgNum;\n\t\tif ( nHeaderByte & 0x40 )\n\t\t{\n\t\t\tuint64 nOffset;\n\t\t\tpReliableDecode = DeserializeVarInt( pReliableDecode, pReliableEnd, nOffset );\n\t\t\tif ( pReliableDecode == nullptr )\n\t\t\t{\n\t\t\t\t// We haven't received all of the message\n\t\t\t\treturn true; // Packet OK and can be acked.\n\t\t\t}\n\n\t\t\tnMsgNum += nOffset;\n\n\t\t\t// Sanity check against a HUGE jump in the message number.\n\t\t\t// This is almost certainly bogus.  (OKOK, yes it is theoretically\n\t\t\t// possible.  But for now while this thing is still under development,\n\t\t\t// most likely it's a bug.  Eventually we can lessen these to handle\n\t\t\t// the case where the app decides to send literally a million unreliable\n\t\t\t// messages in between reliable messages.  The second condition is probably\n\t\t\t// legit, though.)\n\t\t\tif ( nOffset > 1000000 || nMsgNum > m_receiverState.m_nHighestSeenMsgNum+10000 )\n\t\t\t{\n\t\t\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError,\n\t\t\t\t\t\"Reliable message number lurch.  Last reliable %lld, offset %llu, highest seen %lld\",\n\t\t\t\t\t(long long)m_receiverState.m_nLastRecvReliableMsgNum, (unsigned long long)nOffset,\n\t\t\t\t\t(long long)m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\t++nMsgNum;\n\t\t}\n\n\t\t// Check for updating highest message number seen, so we know how to interpret\n\t\t// message numbers from the sender with only the lowest N bits present.\n\t\t// And yes, we want to do this even if we end up not processing the entire message\n\t\tif ( nMsgNum > m_receiverState.m_nHighestSeenMsgNum )\n\t\t\tm_receiverState.m_nHighestSeenMsgNum = nMsgNum;\n\n\t\t// Parse message size.\n\t\tint cbMsgSize = nHeaderByte&0x1f;\n\t\tif ( nHeaderByte & 0x20 )\n\t\t{\n\t\t\tuint64 nMsgSizeUpperBits;\n\t\t\tpReliableDecode = DeserializeVarInt( pReliableDecode, pReliableEnd, nMsgSizeUpperBits );\n\t\t\tif ( pReliableDecode == nullptr )\n\t\t\t{\n\t\t\t\t// We haven't received all of the message\n\t\t\t\treturn true; // Packet OK and can be acked.\n\t\t\t}\n\n\t\t\t// Sanity check size.  Note that we do this check before we shift,\n\t\t\t// to protect against overflow.\n\t\t\t// (Although DeserializeVarInt doesn't detect overflow...)\n\t\t\tif ( nMsgSizeUpperBits > (uint64)k_cbMaxMessageSizeRecv<<5 )\n\t\t\t{\n\t\t\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError,\n\t\t\t\t\t\"Reliable message size too large.  (%llu<<5 + %d)\",\n\t\t\t\t\t(unsigned long long)nMsgSizeUpperBits, cbMsgSize );\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\t// Compute total size, and check it again\n\t\t\tcbMsgSize += int( nMsgSizeUpperBits<<5 );\n\t\t\tif ( cbMsgSize > k_cbMaxMessageSizeRecv )\n\t\t\t{\n\t\t\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError,\n\t\t\t\t\t\"Reliable message size %d too large.\", cbMsgSize );\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\t// Do we have the full thing?\n\t\tif ( pReliableDecode+cbMsgSize > pReliableEnd )\n\t\t{\n\t\t\t// Ouch, we did all that work and still don't have the whole message.\n\t\t\treturn true; // packet is OK, can be acked, and continue processing it\n\t\t}\n\n\t\t// We have a full message!  Queue it\n\t\tif ( !ReceivedMessage( pReliableDecode, cbMsgSize, nMsgNum, k_nSteamNetworkingSend_Reliable, usecNow ) )\n\t\t\treturn false; // Weird failure.  Most graceful response is to not ack this packet, and maybe we will work next on retry.\n\t\tpReliableDecode += cbMsgSize;\n\t\tint cbStreamConsumed = pReliableDecode-pReliableStart;\n\n\t\t// Advance bookkeeping\n\t\tm_receiverState.m_nLastRecvReliableMsgNum = nMsgNum;\n\t\tm_receiverState.m_nReliableStreamPos += cbStreamConsumed;\n\n\t\t// Remove the data from the from the front of the buffer\n\t\tpop_from_front( m_receiverState.m_bufReliableStream, cbStreamConsumed );\n\n\t\t// We might have more in the stream that is ready to dispatch right now.\n\t\tnNumReliableBytes -= cbStreamConsumed;\n\t} while ( nNumReliableBytes > 0 );\n\n\treturn true; // packet is OK, can be acked, and continue processing it\n}\n\nvoid CSteamNetworkConnectionBase::SNP_RecordReceivedPktNum( int64 nPktNum, SteamNetworkingMicroseconds usecNow, bool bScheduleAck )\n{\n\n\t// Check if sender has already told us they don't need us to\n\t// account for packets this old anymore\n\tif ( unlikely( nPktNum < m_receiverState.m_nMinPktNumToSendAcks ) )\n\t\treturn;\n\n\t// Fast path for the (hopefully) most common case of packets arriving in order\n\tif ( likely( nPktNum == m_statsEndToEnd.m_nMaxRecvPktNum+1 ) )\n\t{\n\t\tif ( bScheduleAck ) // fast path for all unreliable data (common when we are just being used for transport)\n\t\t{\n\t\t\t// Schedule ack of this packet (since we are the highest numbered\n\t\t\t// packet, that means reporting on everything)\n\t\t\tQueueFlushAllAcks( usecNow + k_usecMaxDataAckDelay );\n\t\t}\n\t\treturn;\n\t}\n\n\t// At this point, ack invariants should be met\n\tm_receiverState.DebugCheckPackGapMap();\n\n\t// Latest time that this packet should be acked.\n\t// (We might already be scheduled to send and ack that would include this packet.)\n\tSteamNetworkingMicroseconds usecScheduleAck = bScheduleAck ? usecNow + k_usecMaxDataAckDelay : INT64_MAX;\n\n\t// Check if this introduced a gap since the last sequence packet we have received\n\tif ( nPktNum > m_statsEndToEnd.m_nMaxRecvPktNum )\n\t{\n\n\t\t// Protect against malicious sender!\n\t\tif ( len( m_receiverState.m_mapPacketGaps ) >= k_nMaxPacketGaps )\n\t\t\treturn; // Nope, we will *not* actually mark the packet as received\n\n\t\t// Add a gap for the skipped packet(s).\n\t\tint64 nBegin = m_statsEndToEnd.m_nMaxRecvPktNum+1;\n\t\tstd::pair<int64,SSNPPacketGap> x;\n\t\tx.first = nBegin;\n\t\tx.second.m_nEnd = nPktNum;\n\t\tx.second.m_usecWhenReceivedPktBefore = m_statsEndToEnd.m_usecTimeLastRecvSeq;\n\t\tx.second.m_usecWhenAckPrior = m_receiverState.m_mapPacketGaps.rbegin()->second.m_usecWhenAckPrior;\n\n\t\t// When should we nack this?\n\t\tx.second.m_usecWhenOKToNack = usecNow;\n\t\tif ( nPktNum < m_statsEndToEnd.m_nMaxRecvPktNum + 3 )\n\t\t\tx.second.m_usecWhenOKToNack += k_usecNackFlush;\n\n\t\tauto iter = m_receiverState.m_mapPacketGaps.insert( x ).first;\n\n\t\tSpewMsgGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] drop %d pkts [%lld-%lld)\",\n\t\t\tGetDescription(),\n\t\t\t(int)( nPktNum - nBegin ),\n\t\t\t(long long)nBegin, (long long)nPktNum );\n\n\t\t// Remember that we need to send a NACK\n\t\tif ( m_receiverState.m_itPendingNack->first == INT64_MAX )\n\t\t{\n\t\t\tm_receiverState.m_itPendingNack = iter;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Pending nacks should be for older packet, not newer\n\t\t\tAssert( m_receiverState.m_itPendingNack->first < nBegin );\n\t\t}\n\n\t\t// Back up if we we had a flush of everything scheduled\n\t\tif ( m_receiverState.m_itPendingAck->first == INT64_MAX && m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior < INT64_MAX )\n\t\t{\n\t\t\tAssert( iter->second.m_usecWhenAckPrior == m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior );\n\t\t\tm_receiverState.m_itPendingAck = iter;\n\t\t}\n\n\t\t// At this point, ack invariants should be met\n\t\tm_receiverState.DebugCheckPackGapMap();\n\n\t\t// Schedule ack of this packet (since we are the highest numbered\n\t\t// packet, that means reporting on everything) by the requested\n\t\t// time\n\t\tQueueFlushAllAcks( usecScheduleAck );\n\t}\n\telse\n\t{\n\n\t\t// Check if this filed a gap\n\t\tauto itGap = m_receiverState.m_mapPacketGaps.upper_bound( nPktNum );\n\t\tif ( itGap == m_receiverState.m_mapPacketGaps.end() )\n\t\t{\n\t\t\tAssertMsg( false, \"[%s] Cannot locate gap, or processing packet %lld multiple times. %s | %s\",\n\t\t\t\tGetDescription(), (long long)nPktNum,\n\t\t\t\tm_statsEndToEnd.RecvPktNumStateDebugString().c_str(), m_statsEndToEnd.HistoryRecvSeqNumDebugString(8).c_str() );\n\t\t\treturn;\n\t\t}\n\t\tif ( itGap == m_receiverState.m_mapPacketGaps.begin() )\n\t\t{\n\t\t\tAssertMsg( false, \"[%s] Cannot locate gap, or processing packet %lld multiple times. [%lld,%lld) %s | %s\",\n\t\t\t\tGetDescription(), (long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd,\n\t\t\t\tm_statsEndToEnd.RecvPktNumStateDebugString().c_str(), m_statsEndToEnd.HistoryRecvSeqNumDebugString(8).c_str() );\n\t\t\treturn;\n\t\t}\n\t\t--itGap;\n\t\tif ( itGap->first > nPktNum || itGap->second.m_nEnd <= nPktNum )\n\t\t{\n\t\t\t// We already received this packet.  But this should be impossible now,\n\t\t\t// we should be rejecting duplicate packet numbers earlier\n\t\t\tAssertMsg( false, \"[%s] Packet gap bug.  %lld [%lld,%lld) %s | %s\",\n\t\t\t\tGetDescription(), (long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd,\n\t\t\t\tm_statsEndToEnd.RecvPktNumStateDebugString().c_str(), m_statsEndToEnd.HistoryRecvSeqNumDebugString(8).c_str() );\n\t\t\treturn;\n\t\t}\n\n\t\t// Packet is in a gap where we previously thought packets were lost.\n\t\t// (Packets arriving out of order.)\n\n\t\t// Last packet in gap?\n\t\tif ( itGap->second.m_nEnd-1 == nPktNum )\n\t\t{\n\t\t\t// Single-packet gap?\n\t\t\tif ( itGap->first == nPktNum )\n\t\t\t{\n\t\t\t\t// Were we waiting to ack/nack this?  Then move forward to the next gap, if any\n\t\t\t\tusecScheduleAck = std::min( usecScheduleAck, itGap->second.m_usecWhenAckPrior );\n\t\t\t\tif ( m_receiverState.m_itPendingAck == itGap )\n\t\t\t\t\t++m_receiverState.m_itPendingAck;\n\t\t\t\tif ( m_receiverState.m_itPendingNack == itGap )\n\t\t\t\t\t++m_receiverState.m_itPendingNack;\n\n\t\t\t\t// Save time when we needed to ack the packets before this gap\n\t\t\t\tSteamNetworkingMicroseconds usecWhenAckPrior = itGap->second.m_usecWhenAckPrior;\n\n\t\t\t\t// Gap is totally filled.  Erase, and move to the next one,\n\t\t\t\t// if any, so we can schedule ack below\n\t\t\t\titGap = m_receiverState.m_mapPacketGaps.erase( itGap );\n\n\t\t\t\t// Were we scheduled to ack the packets before this?  If so, then\n\t\t\t\t// we still need to do that, only now when we send that ack, we will\n\t\t\t\t// ack the packets after this gap as well, since they will be included\n\t\t\t\t// in the same ack block.\n\t\t\t\t//\n\t\t\t\t// NOTE: This is based on what was scheduled to be acked before we got\n\t\t\t\t// this packet.  If we need to update the schedule to ack the current\n\t\t\t\t// packet, we will do that below.  However, usually if previous\n\t\t\t\t// packets were already scheduled to be acked, then that deadline time\n\t\t\t\t// will be sooner usecScheduleAck, so the code below will not actually\n\t\t\t\t// do anything.\n\t\t\t\tif ( usecWhenAckPrior < itGap->second.m_usecWhenAckPrior )\n\t\t\t\t{\n\t\t\t\t\titGap->second.m_usecWhenAckPrior = usecWhenAckPrior;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t// Otherwise, we might not have any acks scheduled.  In that\n\t\t\t\t\t// case, the invariant is that m_itPendingAck should point at the sentinel\n\t\t\t\t\tif ( m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior == INT64_MAX )\n\t\t\t\t\t{\n\t\t\t\t\t\tm_receiverState.m_itPendingAck = m_receiverState.m_mapPacketGaps.end();\n\t\t\t\t\t\t--m_receiverState.m_itPendingAck;\n\t\t\t\t\t\tAssert( m_receiverState.m_itPendingAck->first == INT64_MAX );\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] decode pkt %lld, single pkt gap filled\", GetDescription(), (long long)nPktNum );\n\n\t\t\t\t// At this point, ack invariants should be met\n\t\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Shrink gap by one from the end\n\t\t\t\t--itGap->second.m_nEnd;\n\t\t\t\tAssert( itGap->first < itGap->second.m_nEnd );\n\n\t\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] decode pkt %lld, last packet in gap, reduced to [%lld,%lld)\", GetDescription(),\n\t\t\t\t\t(long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd );\n\n\t\t\t\t// Move to the next gap so we can schedule ack below\n\t\t\t\t++itGap;\n\n\t\t\t\t// At this point, ack invariants should be met\n\t\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t\t}\n\t\t}\n\t\telse if ( itGap->first == nPktNum )\n\t\t{\n\t\t\t// First packet in multi-packet gap.\n\t\t\t// Shrink packet from the front\n\t\t\t// Cast away const to allow us to modify the key.\n\t\t\t// We know this won't break the map ordering\n\t\t\t++const_cast<int64&>( itGap->first );\n\t\t\tAssert( itGap->first < itGap->second.m_nEnd );\n\t\t\titGap->second.m_usecWhenReceivedPktBefore = usecNow;\n\n\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] decode pkt %lld, first packet in gap, reduced to [%lld,%lld)\", GetDescription(),\n\t\t\t\t(long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd );\n\n\t\t\t// At this point, ack invariants should be met\n\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Packet is in the middle of the gap.  We'll need to fragment this gap\n\t\t\t// Protect against malicious sender!\n\t\t\tif ( len( m_receiverState.m_mapPacketGaps ) >= k_nMaxPacketGaps )\n\t\t\t\treturn; // Nope, we will *not* actually mark the packet as received\n\n\t\t\t// Locate the next block so we can set the schedule time\n\t\t\tauto itNext = itGap;\n\t\t\t++itNext;\n\n\t\t\t// Start making a new gap to account for the upper end\n\t\t\tstd::pair<int64,SSNPPacketGap> upper;\n\t\t\tupper.first = nPktNum+1;\n\t\t\tupper.second.m_nEnd = itGap->second.m_nEnd;\n\t\t\tupper.second.m_usecWhenReceivedPktBefore = usecNow;\n\t\t\tif ( itNext == m_receiverState.m_itPendingAck )\n\t\t\t\tupper.second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\telse\n\t\t\t\tupper.second.m_usecWhenAckPrior = itNext->second.m_usecWhenAckPrior;\n\t\t\tupper.second.m_usecWhenOKToNack = itGap->second.m_usecWhenOKToNack;\n\n\t\t\t// Truncate the current gap\n\t\t\titGap->second.m_nEnd = nPktNum;\n\t\t\tAssert( itGap->first < itGap->second.m_nEnd );\n\n\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] decode pkt %lld, gap split [%lld,%lld) and [%lld,%lld)\", GetDescription(),\n\t\t\t\t(long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd, upper.first, upper.second.m_nEnd );\n\n\t\t\t// Insert a new gap to account for the upper end, and\n\t\t\t// advance iterator to it, so that we can schedule ack below\n\t\t\titGap = m_receiverState.m_mapPacketGaps.insert( upper ).first;\n\n\t\t\t// At this point, ack invariants should be met\n\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t}\n\n\t\tAssert( itGap != m_receiverState.m_mapPacketGaps.end() );\n\n\t\t// Need to schedule ack (earlier than it is already scheduled)?\n\t\tif ( usecScheduleAck < itGap->second.m_usecWhenAckPrior )\n\t\t{\n\n\t\t\t// Earlier than the current thing being scheduled?\n\t\t\tif ( usecScheduleAck <= m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior )\n\t\t\t{\n\n\t\t\t\t// We're next, set the time\n\t\t\t\titGap->second.m_usecWhenAckPrior = usecScheduleAck;\n\n\t\t\t\t// Any schedules for lower-numbered packets are superseded\n\t\t\t\t// by this one.\n\t\t\t\tif ( m_receiverState.m_itPendingAck->first <= itGap->first )\n\t\t\t\t{\n\t\t\t\t\twhile ( m_receiverState.m_itPendingAck != itGap )\n\t\t\t\t\t{\n\t\t\t\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\t\t\t\t++m_receiverState.m_itPendingAck;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t// If our number is lower than the thing that was scheduled next,\n\t\t\t\t\t// then back up and re-schedule any blocks in between to be effectively\n\t\t\t\t\t// the same time as they would have been flushed before.\n\t\t\t\t\tSteamNetworkingMicroseconds usecOldSched = m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior;\n\t\t\t\t\twhile ( --m_receiverState.m_itPendingAck != itGap )\n\t\t\t\t\t{\n\t\t\t\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = usecOldSched;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// We're not the next thing that needs to be acked.\n\t\t\t\t\n\t\t\t\tif ( itGap->first < m_receiverState.m_itPendingAck->first )\n\t\t\t\t{\n\t\t\t\t\t// We're a lowered numbered packet,\tso this request is subsumed by the\n\t\t\t\t\t// request to flush more packets at an earlier time,\n\t\t\t\t\t// and we don't need to do anything.\n\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\n\t\t\t\t\t// We need to ack a bit earlier\n\t\t\t\t\titGap->second.m_usecWhenAckPrior = usecScheduleAck;\n\n\t\t\t\t\t// Now the only way for our invariants to be violated is for lower\n\t\t\t\t\t// numbered blocks to have later scheduled times.\n\t\t\t\t\tAssert( itGap != m_receiverState.m_mapPacketGaps.begin() );\n\t\t\t\t\twhile ( (--itGap)->second.m_usecWhenAckPrior > usecScheduleAck )\n\t\t\t\t\t{\n\t\t\t\t\t\tAssert( itGap != m_receiverState.m_mapPacketGaps.begin() );\n\t\t\t\t\t\titGap->second.m_usecWhenAckPrior = usecScheduleAck;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Make sure we didn't screw things up\n\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t}\n\n\t\t// Make sure are scheduled to wake up\n\t\tif ( bScheduleAck )\n\t\t\tEnsureMinThinkTime( m_receiverState.TimeWhenFlushAcks() );\n\t}\n}\n\nint CSteamNetworkConnectionBase::SNP_ClampSendRate()\n{\n\t// Get effective clamp limits.  We clamp the limits themselves to be safe\n\t// and make sure they are sane\n\tint nMin = Clamp( m_connectionConfig.m_SendRateMin.Get(), 1024, 100*1024*1024 );\n\tint nMax = Clamp( m_connectionConfig.m_SendRateMax.Get(), nMin, 100*1024*1024 );\n\n\t// Clamp it, adjusting the value if it's out of range\n\tm_senderState.m_n_x = Clamp( m_senderState.m_n_x, nMin, nMax );\n\n\t// Return value\n\treturn m_senderState.m_n_x;\n}\n\n// Returns next think time\nSteamNetworkingMicroseconds CSteamNetworkConnectionBase::SNP_ThinkSendState( SteamNetworkingMicroseconds usecNow )\n{\n\t// Accumulate tokens based on how long it's been since last time\n\tSNP_ClampSendRate();\n\tSNP_TokenBucket_Accumulate( usecNow );\n\n\t// Calculate next time we want to take action.  If it isn't right now, then we're either idle or throttled.\n\t// Importantly, this will also check for retry timeout\n\tSteamNetworkingMicroseconds usecNextThink = SNP_GetNextThinkTime( usecNow );\n\tif ( usecNextThink > usecNow )\n\t\treturn usecNextThink;\n\n\t// Keep sending packets until we run out of tokens\n\tint nPacketsSent = 0;\n\twhile ( m_pTransport )\n\t{\n\n\t\tif ( nPacketsSent > k_nMaxPacketsPerThink )\n\t\t{\n\t\t\t// We're sending too much at one time.  Nuke token bucket so that\n\t\t\t// we'll be ready to send again very soon, but not immediately.\n\t\t\t// We don't want the outer code to complain that we are requesting\n\t\t\t// a wakeup call in the past\n\t\t\tm_senderState.m_flTokenBucket = m_senderState.m_n_x * -0.0005f;\n\t\t\treturn usecNow + 1000;\n\t\t}\n\n\t\t// Check if we have anything to send.\n\t\tif ( usecNow < m_receiverState.TimeWhenFlushAcks() && usecNow < SNP_TimeWhenWantToSendNextPacket() )\n\t\t{\n\n\t\t\t// We've sent everything we want to send.  Limit our reserve to a\n\t\t\t// small burst overage, in case we had built up an excess reserve\n\t\t\t// before due to the scheduler waking us up late.\n\t\t\tm_senderState.TokenBucket_Limit();\n\t\t\tbreak;\n\t\t}\n\n\t\t// Send the next data packet.\n\t\tif ( !m_pTransport->SendDataPacket( usecNow ) )\n\t\t{\n\t\t\t// Problem sending packet.  Nuke token bucket, but request\n\t\t\t// a wakeup relatively quick to check on our state again\n\t\t\tm_senderState.m_flTokenBucket = m_senderState.m_n_x * -0.001f;\n\t\t\treturn usecNow + 2000;\n\t\t}\n\n\t\t// We spent some tokens, do we have any left?\n\t\tif ( m_senderState.m_flTokenBucket < 0.0f )\n\t\t\tbreak;\n\n\t\t// Limit number of packets sent at a time, even if the scheduler is really bad\n\t\t// or somebody holds the lock for along time, or we wake up late for whatever reason\n\t\t++nPacketsSent;\n\t}\n\n\t// Return time when we need to check in again.\n\tSteamNetworkingMicroseconds usecNextAction = SNP_GetNextThinkTime( usecNow );\n\tAssert( usecNextAction > usecNow );\n\treturn usecNextAction;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_TokenBucket_Accumulate( SteamNetworkingMicroseconds usecNow )\n{\n\t// If we're not connected, just keep our bucket full\n\tif ( !BStateIsConnectedForWirePurposes() )\n\t{\n\t\tm_senderState.m_flTokenBucket = k_flSendRateBurstOverageAllowance;\n\t\tm_senderState.m_usecTokenBucketTime = usecNow;\n\t\treturn;\n\t}\n\n\tfloat flElapsed = ( usecNow - m_senderState.m_usecTokenBucketTime ) * 1e-6;\n\tm_senderState.m_flTokenBucket += (float)m_senderState.m_n_x * flElapsed;\n\tm_senderState.m_usecTokenBucketTime = usecNow;\n\n\t// If we don't currently have any packets ready to send right now,\n\t// then go ahead and limit the tokens.  If we do have packets ready\n\t// to send right now, then we must assume that we would be trying to\n\t// wakeup as soon as we are ready to send the next packet, and thus\n\t// any excess tokens we accumulate are because the scheduler woke\n\t// us up late, and we are not actually bursting\n\tif ( SNP_TimeWhenWantToSendNextPacket() > usecNow )\n\t\tm_senderState.TokenBucket_Limit();\n}\n\nvoid SSNPReceiverState::QueueFlushAllAcks( SteamNetworkingMicroseconds usecWhen )\n{\n\tDebugCheckPackGapMap();\n\n\tAssert( usecWhen > 0 ); // zero is reserved and should never be used as a requested wake time\n\n\t// if we're already scheduled for earlier, then there cannot be any work to do\n\tauto it = m_mapPacketGaps.end();\n\t--it;\n\tif ( it->second.m_usecWhenAckPrior <= usecWhen )\n\t\treturn;\n\tit->second.m_usecWhenAckPrior = usecWhen;\n\n\t// Nothing partial scheduled?\n\tif ( m_itPendingAck == it )\n\t\treturn;\n\n\tif ( m_itPendingAck->second.m_usecWhenAckPrior >= usecWhen )\n\t{\n\t\tdo\n\t\t{\n\t\t\tm_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\t++m_itPendingAck;\n\t\t} while ( m_itPendingAck != it );\n\t\tDebugCheckPackGapMap();\n\t}\n\telse\n\t{\n\t\t// Maintain invariant\n\t\twhile ( (--it)->second.m_usecWhenAckPrior >= usecWhen )\n\t\t\tit->second.m_usecWhenAckPrior = usecWhen;\n\t\tDebugCheckPackGapMap();\n\t}\n}\n\n#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 1\nvoid SSNPReceiverState::DebugCheckPackGapMap() const\n{\n\tint64 nPrevEnd = 0;\n\tSteamNetworkingMicroseconds usecPrevAck = 0;\n\tbool bFoundPendingAck = false;\n\tfor ( auto it: m_mapPacketGaps )\n\t{\n\t\tAssert( it.first > nPrevEnd );\n\t\tif ( it.first == m_itPendingAck->first )\n\t\t{\n\t\t\tAssert( !bFoundPendingAck );\n\t\t\tbFoundPendingAck = true;\n\t\t\tif ( it.first < INT64_MAX )\n\t\t\t\tAssert( it.second.m_usecWhenAckPrior < INT64_MAX );\n\t\t}\n\t\telse if ( !bFoundPendingAck )\n\t\t{\n\t\t\tAssert( it.second.m_usecWhenAckPrior == INT64_MAX );\n\t\t}\n\t\telse\n\t\t{\n\t\t\tAssert( it.second.m_usecWhenAckPrior >= usecPrevAck );\n\t\t}\n\t\tusecPrevAck = it.second.m_usecWhenAckPrior;\n\t\tif ( it.first == INT64_MAX )\n\t\t{\n\t\t\tAssert( it.second.m_nEnd == INT64_MAX );\n\t\t}\n\t\telse\n\t\t{\n\t\t\tAssert( it.first < it.second.m_nEnd );\n\t\t}\n\t\tnPrevEnd = it.second.m_nEnd;\n\t}\n\tAssert( nPrevEnd == INT64_MAX );\n}\n#endif\n\nSteamNetworkingMicroseconds CSteamNetworkConnectionBase::SNP_TimeWhenWantToSendNextPacket() const\n{\n\t// We really shouldn't be trying to do this when not connected\n\tif ( !BStateIsConnectedForWirePurposes() )\n\t{\n\t\tAssertMsg( false, \"We shouldn't be asking about sending packets when not fully connected\" );\n\t\treturn k_nThinkTime_Never;\n\t}\n\n\t// Reliable triggered?  Then send it right now\n\tif ( !m_senderState.m_listReadyRetryReliableRange.empty() )\n\t\treturn 0;\n\n\t// Anything queued?\n\tSteamNetworkingMicroseconds usecNextSend;\n\tif ( m_senderState.m_messagesQueued.empty() )\n\t{\n\n\t\t// Queue is empty, nothing to send except perhaps nacks (below)\n\t\tAssert( m_senderState.PendingBytesTotal() == 0 );\n\t\tusecNextSend = INT64_MAX;\n\t}\n\telse\n\t{\n\n\t\t// FIXME acks, stop_waiting?\n\n\t\t// Have we got at least a full packet ready to go?\n\t\tif ( m_senderState.PendingBytesTotal() >= m_cbMaxPlaintextPayloadSend )\n\t\t\t// Send it ASAP\n\t\t\treturn 0;\n\n\t\t// We have less than a full packet's worth of data.  Wait until\n\t\t// the Nagle time, if we have one\n\t\tusecNextSend = m_senderState.m_messagesQueued.m_pFirst->SNPSend_UsecNagle();\n\t}\n\n\t// Check if the receiver wants to send a NACK.\n\tusecNextSend = std::min( usecNextSend, m_receiverState.m_itPendingNack->second.m_usecWhenOKToNack );\n\n\t// Return the earlier of the two\n\treturn usecNextSend;\n}\n\nSteamNetworkingMicroseconds CSteamNetworkConnectionBase::SNP_GetNextThinkTime( SteamNetworkingMicroseconds usecNow )\n{\n\t// We really shouldn't be trying to do this when not connected\n\tif ( !BStateIsConnectedForWirePurposes() )\n\t{\n\t\tAssertMsg( false, \"We shouldn't be trying to think SNP when not fully connected\" );\n\t\treturn k_nThinkTime_Never;\n\t}\n\n\t// We cannot send any packets if we don't have transport\n\tif ( !m_pTransport )\n\t\treturn k_nThinkTime_Never;\n\n\t// Start with the time when the receiver needs to flush out ack.\n\tSteamNetworkingMicroseconds usecNextThink = m_receiverState.TimeWhenFlushAcks();\n\n\t// Check retransmit timers.  If they have expired, this will move reliable\n\t// segments into the \"ready to retry\" list, which will cause\n\t// TimeWhenWantToSendNextPacket to think we want to send data.  If nothing has timed out,\n\t// it will return the time when we need to check back in.  Or, if everything is idle it will\n\t// return \"never\" (very large number).\n\tSteamNetworkingMicroseconds usecNextRetry = SNP_SenderCheckInFlightPackets( usecNow );\n\n\t// If we want to send packets, then we might need to wake up and take action\n\tSteamNetworkingMicroseconds usecTimeWantToSend = SNP_TimeWhenWantToSendNextPacket();\n\tusecTimeWantToSend = std::min( usecNextRetry, usecTimeWantToSend );\n\tif ( usecTimeWantToSend < usecNextThink )\n\t{\n\n\t\t// Time when we *could* send the next packet, ignoring Nagle\n\t\tSteamNetworkingMicroseconds usecNextSend = usecNow;\n\t\tSteamNetworkingMicroseconds usecQueueTime = m_senderState.CalcTimeUntilNextSend();\n\t\tif ( usecQueueTime > 0 )\n\t\t{\n\t\t\tusecNextSend += usecQueueTime;\n\n\t\t\t// Add a small amount of fudge here, so that we don't wake up too early and think\n\t\t\t// we're not ready yet, causing us to spin our wheels.  Our token bucket system\n\t\t\t// should keep us sending at the correct overall rate.  Remember that the\n\t\t\t// underlying kernel timer/wake resolution might be 1 or 2ms, (E.g. Windows.)\n\t\t\tusecNextSend += 25;\n\t\t}\n\n\t\t// Time when we will next send is the greater of when we want to and when we can\n\t\tusecNextSend = std::max( usecNextSend, usecTimeWantToSend );\n\n\t\t// Earlier than any other reason to wake up?\n\t\tusecNextThink = std::min( usecNextThink, usecNextSend );\n\t}\n\n\treturn usecNextThink;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_PopulateDetailedStats( SteamDatagramLinkStats &info )\n{\n\tinfo.m_latest.m_nSendRate = SNP_ClampSendRate();\n\tinfo.m_latest.m_nPendingBytes = m_senderState.m_cbPendingUnreliable + m_senderState.m_cbPendingReliable;\n\tinfo.m_lifetime.m_nMessagesSentReliable    = m_senderState.m_nMessagesSentReliable;\n\tinfo.m_lifetime.m_nMessagesSentUnreliable  = m_senderState.m_nMessagesSentUnreliable;\n\tinfo.m_lifetime.m_nMessagesRecvReliable    = m_receiverState.m_nMessagesRecvReliable;\n\tinfo.m_lifetime.m_nMessagesRecvUnreliable  = m_receiverState.m_nMessagesRecvUnreliable;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_PopulateQuickStats( SteamNetworkingQuickConnectionStatus &info, SteamNetworkingMicroseconds usecNow )\n{\n\tinfo.m_nSendRateBytesPerSecond = SNP_ClampSendRate();\n\tinfo.m_cbPendingUnreliable = m_senderState.m_cbPendingUnreliable;\n\tinfo.m_cbPendingReliable = m_senderState.m_cbPendingReliable;\n\tinfo.m_cbSentUnackedReliable = m_senderState.m_cbSentUnackedReliable;\n\tif ( GetState() == k_ESteamNetworkingConnectionState_Connected )\n\t{\n\n\t\t// Accumulate tokens so that we can properly predict when the next time we'll be able to send something is\n\t\tSNP_TokenBucket_Accumulate( usecNow );\n\n\t\t//\n\t\t// Time until we can send the next packet\n\t\t// If anything is already queued, then that will have to go out first.  Round it down\n\t\t// to the nearest packet.\n\t\t//\n\t\t// NOTE: This ignores the precise details of SNP framing.  If there are tons of\n\t\t// small packets, it'll actually be worse.  We might be able to approximate that\n\t\t// the framing overhead better by also counting up the number of *messages* pending.\n\t\t// Probably not worth it here, but if we had that number available, we'd use it.\n\t\tint cbPendingTotal = m_senderState.PendingBytesTotal() / m_cbMaxMessageNoFragment * m_cbMaxMessageNoFragment;\n\n\t\t// Adjust based on how many tokens we have to spend now (or if we are already\n\t\t// over-budget and have to wait until we could spend another)\n\t\tcbPendingTotal -= (int)m_senderState.m_flTokenBucket;\n\t\tif ( cbPendingTotal <= 0 )\n\t\t{\n\t\t\t// We could send it right now.\n\t\t\tinfo.m_usecQueueTime = 0;\n\t\t}\n\t\telse\n\t\t{\n\n\t\t\tinfo.m_usecQueueTime = (int64)cbPendingTotal * k_nMillion / SNP_ClampSendRate();\n\t\t}\n\t}\n\telse\n\t{\n\t\t// We'll never be able to send it.  (Or, we don't know when that will be.)\n\t\tinfo.m_usecQueueTime = INT64_MAX;\n\t}\n}\n\n} // namespace SteamNetworkingSocketsLib\n", "//====== Copyright Valve Corporation, All rights reserved. ====================\n\n#pragma once\n\n#include \"../steamnetworkingsockets_internal.h\"\n#include <vector>\n#include <map>\n#include <set>\n\n// Set paranoia level, if not already set:\n// 0 = disabled\n// 1 = sometimes\n// 2 = max\n#ifndef STEAMNETWORKINGSOCKETS_SNP_PARANOIA\n\t#ifdef _DEBUG\n\t\t#define STEAMNETWORKINGSOCKETS_SNP_PARANOIA 2\n\t#else\n\t\t#define STEAMNETWORKINGSOCKETS_SNP_PARANOIA 0\n\t#endif\n#endif\n\n#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 0\n\t#if defined(__GNUC__ ) && defined( __linux__ ) && !defined( __ANDROID__ )\n\t\t#include <debug/map>\n\t\t// FIXME use debug versions\n\t\ttemplate< typename K, typename V, typename L = std::less<K> >\n\t\tusing std_map = __gnu_debug::map<K,V,L>;\n\n\t\ttemplate <typename K, typename V, typename L>\n\t\tinline int len( const std_map<K,V,L> &map )\n\t\t{\n\t\t\treturn (int)map.size();\n\t\t}\n\n\t#else\n\t\ttemplate< typename K, typename V, typename L = std::less<K> >\n\t\tusing std_map = std::map<K,V,L>;\n\t#endif\n#else\n\ttemplate< typename K, typename V, typename L = std::less<K> >\n\tusing std_map = std::map<K,V,L>;\n#endif\n\nstruct P2PSessionState_t;\n\nnamespace SteamNetworkingSocketsLib {\n\n// Acks may be delayed.  This controls the precision used on the wire to encode the delay time.\nconstexpr int k_nAckDelayPrecisionShift = 5;\nconstexpr SteamNetworkingMicroseconds k_usecAckDelayPrecision = (1 << k_nAckDelayPrecisionShift );\n\n// When a receiver detects a dropped packet, wait a bit before NACKing it, to give it time\n// to arrive out of order.  This is really important for many different types of connections\n// that send on different channels, e.g. DSL, Wifi.\n// Here we really could be smarter, by tracking how often dropped\n// packets really do arrive out of order.  If the rate is low, then it's\n// probably best to go ahead and send a NACK now, rather than waiting.\n// But if dropped packets do often arrive out of order, then waiting\n// to NACK will probably save some retransmits.  In fact, instead\n// of learning the rate, we should probably try to learn the delay.\n// E.g. a probability distribution P(t), which describes the odds\n// that a dropped packet will have arrived at time t.  Then you\n// adjust the NACK delay such that P(nack_delay) gives the best\n// balance between false positive and false negative rates.\nconstexpr SteamNetworkingMicroseconds k_usecNackFlush = 3*1000;\n\n// Max size of a message that we are wiling to *receive*.\nconstexpr int k_cbMaxMessageSizeRecv = k_cbMaxSteamNetworkingSocketsMessageSizeSend*2;\n\n// The max we will look ahead and allocate data, ahead of the reliable\n// messages we have been able to decode.  We limit this to make sure that\n// a malicious sender cannot exploit us.\nconstexpr int k_cbMaxBufferedReceiveReliableData = k_cbMaxMessageSizeRecv + 64*1024;\nconstexpr int k_nMaxReliableStreamGaps_Extend = 30; // Discard reliable data past the end of the stream, if it would cause us to get too many gaps\nconstexpr int k_nMaxReliableStreamGaps_Fragment = 20; // Discard reliable data that is filling in the middle of a hole, if it would cause the number of gaps to exceed this number\nconstexpr int k_nMaxPacketGaps = 62; // Don't bother tracking more than N gaps.  Instead, we will end up NACKing some packets that we actually did receive.  This should not break the protocol, but it protects us from malicious sender\n\n// Hang on to at most N unreliable segments.  When packets are dropping\n// and unreliable messages being fragmented, we will accumulate old pieces\n// of unreliable messages that we retain in hopes that we will get the\n// missing piece and reassemble the whole message.  At a certain point we\n// must give up and discard them.  We use a simple strategy of just limiting\n// the max total number.  In reality large unreliable messages are just a very bad\n// idea, since the odds of the message dropping increase exponentially with the\n// number of packets.  With 20 packets, even 1% packet loss becomes ~80% message\n// loss.  (Assuming naive fragmentation and reassembly and no forward\n// error correction.)\nconstexpr int k_nMaxBufferedUnreliableSegments = 20;\n\n// If app tries to send a message larger than N bytes unreliably,\n// complain about it, and automatically convert to reliable.\n// About 15 segments.\nconstexpr int k_cbMaxUnreliableMsgSize = 15*1100;\n\nclass CSteamNetworkConnectionBase;\nclass CConnectionTransport;\nstruct SteamNetworkingMessageQueue;\n\n/// Actual implementation of SteamNetworkingMessage_t, which is the API\n/// visible type.  Has extra fields needed to put the message into intrusive\n/// linked lists.\nclass CSteamNetworkingMessage : public SteamNetworkingMessage_t\n{\npublic:\n\tstatic CSteamNetworkingMessage *New( CSteamNetworkConnectionBase *pParent, uint32 cbSize, int64 nMsgNum, int nFlags, SteamNetworkingMicroseconds usecNow );\n\tstatic CSteamNetworkingMessage *New( uint32 cbSize );\n\tstatic void DefaultFreeData( SteamNetworkingMessage_t *pMsg );\n\n\t/// OK to delay sending this message until this time.  Set to zero to explicitly force\n\t/// Nagle timer to expire and send now (but this should behave the same as if the\n\t/// timer < usecNow).  If the timer is cleared, then all messages with lower message numbers\n\t/// are also cleared.\n\tinline SteamNetworkingMicroseconds SNPSend_UsecNagle() const { return m_usecTimeReceived; }\n\tinline void SNPSend_SetUsecNagle( SteamNetworkingMicroseconds x ) { m_usecTimeReceived = x; }\n\n\t/// Offset in reliable stream of the header byte.  0 if we're not reliable.\n\tinline int64 SNPSend_ReliableStreamPos() const { return m_nConnUserData; }\n\tinline void SNPSend_SetReliableStreamPos( int64 x ) { m_nConnUserData = x; }\n\tinline int SNPSend_ReliableStreamSize() const\n\t{\n\t\tDbgAssert( m_nFlags & k_nSteamNetworkingSend_Reliable && m_nConnUserData > 0 && m_cbSNPSendReliableHeader > 0 && m_cbSize >= m_cbSNPSendReliableHeader );\n\t\treturn m_cbSize;\n\t}\n\n\tinline bool SNPSend_IsReliable() const\n\t{\n\t\tif ( m_nFlags & k_nSteamNetworkingSend_Reliable )\n\t\t{\n\t\t\tDbgAssert( m_nConnUserData > 0 && m_cbSNPSendReliableHeader > 0 && m_cbSize >= m_cbSNPSendReliableHeader );\n\t\t\treturn true;\n\t\t}\n\t\tDbgAssert( m_nConnUserData == 0 && m_cbSNPSendReliableHeader == 0 );\n\t\treturn false;\n\t}\n\n\t// Reliable stream header\n\tint m_cbSNPSendReliableHeader;\n\tbyte *SNPSend_ReliableHeader()\n\t{\n\t\t// !KLUDGE! Reuse the peer identity to hold the reliable header\n\t\treturn (byte*)&m_identityPeer;\n\t}\n\n\t/// Remove it from queues\n\tvoid Unlink();\n\n\tstruct Links\n\t{\n\t\tSteamNetworkingMessageQueue *m_pQueue;\n\t\tCSteamNetworkingMessage *m_pPrev;\n\t\tCSteamNetworkingMessage *m_pNext;\n\n\t\tinline void Clear() { m_pQueue = nullptr; m_pPrev = nullptr; m_pNext = nullptr; }\n\t};\n\n\t/// Intrusive links for the \"primary\" list we are in\n\tLinks m_links;\n\n\t/// Intrusive links for any secondary list we may be in.  (Same listen socket or\n\t/// P2P channel, depending on message type)\n\tLinks m_linksSecondaryQueue;\n\n\tvoid LinkBefore( CSteamNetworkingMessage *pSuccessor, Links CSteamNetworkingMessage::*pMbrLinks, SteamNetworkingMessageQueue *pQueue );\n\tvoid LinkToQueueTail( Links CSteamNetworkingMessage::*pMbrLinks, SteamNetworkingMessageQueue *pQueue );\n\tvoid UnlinkFromQueue( Links CSteamNetworkingMessage::*pMbrLinks );\n\nprivate:\n\t// Use New and Release()!!\n\tinline CSteamNetworkingMessage() {}\n\tinline ~CSteamNetworkingMessage() {}\n\tstatic void ReleaseFunc( SteamNetworkingMessage_t *pIMsg );\n};\n\n/// A doubly-linked list of CSteamNetworkingMessage\nstruct SteamNetworkingMessageQueue\n{\n\tCSteamNetworkingMessage *m_pFirst = nullptr;\n\tCSteamNetworkingMessage *m_pLast = nullptr;\n\n\tinline bool empty() const\n\t{\n\t\tif ( m_pFirst )\n\t\t{\n\t\t\tAssert( m_pLast );\n\t\t\treturn false;\n\t\t}\n\t\tAssert( !m_pLast );\n\t\treturn true;\n\t}\n\n\t/// Remove the first messages out of the queue (up to nMaxMessages).  Returns the number returned\n\tint RemoveMessages( SteamNetworkingMessage_t **ppOutMessages, int nMaxMessages );\n\n\t/// Delete all queued messages\n\tvoid PurgeMessages();\n};\n\n/// Maximum number of packets we will send in one Think() call.\nconst int k_nMaxPacketsPerThink = 16;\n\n/// Max number of tokens we are allowed to store up in reserve, for a burst.\nconst float k_flSendRateBurstOverageAllowance = k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend;\n\nstruct SNPRange_t\n{\n\t/// Byte or sequence number range\n\tint64 m_nBegin;\n\tint64 m_nEnd; // STL-style.  It's one past the end\n\n\tinline int64 length() const\n\t{\n\t\t// In general, allow zero-length ranges, but not negative ones\n\t\tAssert( m_nEnd >= m_nBegin );\n\t\treturn m_nEnd - m_nBegin;\n\t}\n\n\t/// Strict comparison function.  This is used in situations where\n\t/// ranges must not overlap, AND we also never search for\n\t/// a range that might overlap.\n\tstruct NonOverlappingLess\n\t{\n\t\tinline bool operator ()(const SNPRange_t &l, const SNPRange_t &r ) const\n\t\t{\n\t\t\tif ( l.m_nBegin < r.m_nBegin ) return true;\n\t\t\tAssertMsg( l.m_nBegin > r.m_nBegin || l.m_nEnd == r.m_nEnd, \"Ranges should not overlap in this map!\" );\n\t\t\treturn false;\n\t\t}\n\t};\n};\n\n/// A packet that has been sent but we don't yet know if was received\n/// or dropped.  These are kept in an ordered map keyed by packet number.\n/// (Hence the packet number not being a member)  When we receive an ACK,\n/// we remove packets from this list.\nstruct SNPInFlightPacket_t\n{\n\t//\n\t// FIXME - Could definitely pack this structure better.  And maybe\n\t//         worth it to optimize cache\n\t//\n\n\t/// Local timestamp when we sent it\n\tSteamNetworkingMicroseconds m_usecWhenSent;\n\n\t/// Did we get an ack block from peer that explicitly marked this\n\t/// packet as being skipped?  Note that we might subsequently get an\n\t/// an ack for this same packet, that's OK!\n\tbool m_bNack;\n\n\t/// Transport used to send\n\tCConnectionTransport *m_pTransport;\n\n\t/// List of reliable segments.  Ignoring retransmission,\n\t/// there really is no reason why we we would need to have\n\t/// more than 1 in a packet, even if there are multiple\n\t/// reliable messages.  If we need to retry, we might\n\t/// be fragmented.  But usually it will only be a few.\n\tvstd::small_vector<SNPRange_t,1> m_vecReliableSegments;\n};\n\nstruct SSNPSendMessageList : public SteamNetworkingMessageQueue\n{\n\n\t/// Unlink the message at the head, if any and return it.\n\t/// Unlike STL pop_front, this will return nullptr if the\n\t/// list is empty\n\tCSteamNetworkingMessage *pop_front()\n\t{\n\t\tCSteamNetworkingMessage *pResult = m_pFirst;\n\t\tif ( pResult )\n\t\t{\n\t\t\tAssert( m_pLast );\n\t\t\tAssert( pResult->m_links.m_pQueue == this );\n\t\t\tAssert( pResult->m_links.m_pPrev == nullptr );\n\t\t\tm_pFirst = pResult->m_links.m_pNext;\n\t\t\tif ( m_pFirst )\n\t\t\t{\n\t\t\t\tAssert( m_pFirst->m_links.m_pPrev == pResult );\n\t\t\t\tAssert( m_pFirst->m_nMessageNumber > pResult->m_nMessageNumber );\n\t\t\t\tm_pFirst->m_links.m_pPrev = nullptr;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tAssert( m_pLast == pResult );\n\t\t\t\tm_pLast = nullptr;\n\t\t\t}\n\t\t\tpResult->m_links.m_pQueue = nullptr;\n\t\t\tpResult->m_links.m_pNext = nullptr;\n\t\t}\n\t\treturn pResult;\n\t}\n\n\t/// Optimized insertion when we know it goes at the end\n\tvoid push_back( CSteamNetworkingMessage *pMsg )\n\t{\n\t\tif ( m_pFirst == nullptr )\n\t\t{\n\t\t\tAssert( m_pLast == nullptr );\n\t\t\tm_pFirst = pMsg;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Messages are always kept in message number order\n\t\t\tAssert( pMsg->m_nMessageNumber > m_pLast->m_nMessageNumber );\n\t\t\tAssert( m_pLast->m_links.m_pNext == nullptr );\n\t\t\tm_pLast->m_links.m_pNext = pMsg;\n\t\t}\n\t\tpMsg->m_links.m_pQueue = this;\n\t\tpMsg->m_links.m_pNext = nullptr;\n\t\tpMsg->m_links.m_pPrev = m_pLast;\n\t\tm_pLast = pMsg;\n\t}\n\n};\n\nstruct SSNPSenderState\n{\n\tSSNPSenderState();\n\t~SSNPSenderState() {\n\t\tShutdown();\n\t}\n\tvoid Shutdown();\n\n\t/// Current sending rate in bytes per second, RFC 3448 4.2 states default\n\t/// is one packet per second, but that is insane and we're not doing that.\n\t/// In most cases we will set a default based on initial ping, so this is\n\t/// only rarely used.\n\tint m_n_x = 32*1024;\n\n\t/// If >=0, then we can send a full packet right now.  We allow ourselves to \"store up\"\n\t/// about 1 packet worth of \"reserve\".  In other words, if we have not sent any packets\n\t/// for a while, basically we allow ourselves to send two packets in rapid succession,\n\t/// thus \"bursting\" over the limit by 1 packet.  That long term rate will be clamped by\n\t/// the send rate.\n\t///\n\t/// If <0, then we are currently \"over\" our rate limit and need to wait before we can\n\t/// send a packet.\n\t///\n\t/// Provision for accumulating \"credits\" and burst allowance, to account for lossy\n\t/// kernel scheduler, etc is mentioned in RFC 5348, section 4.6.\n\tfloat m_flTokenBucket = 0;\n\n\t/// Last time that we added tokens to m_flTokenBucket\n\tSteamNetworkingMicroseconds m_usecTokenBucketTime = 0;\n\n\tvoid TokenBucket_Init( SteamNetworkingMicroseconds usecNow )\n\t{\n\t\tm_usecTokenBucketTime = usecNow;\n\t\tm_flTokenBucket = k_flSendRateBurstOverageAllowance;\n\t}\n\n\t/// Limit our token bucket to the max reserve amount\n\tvoid TokenBucket_Limit()\n\t{\n\t\tif ( m_flTokenBucket > k_flSendRateBurstOverageAllowance )\n\t\t\tm_flTokenBucket = k_flSendRateBurstOverageAllowance;\n\t}\n\n\t/// Calculate time until we could send our next packet, checking our token\n\t/// bucket and the current send rate\n\tSteamNetworkingMicroseconds CalcTimeUntilNextSend() const\n\t{\n\t\t// Do we have tokens to burn right now?\n\t\tif ( m_flTokenBucket >= 0.0f )\n\t\t\treturn 0;\n\n\t\treturn SteamNetworkingMicroseconds( m_flTokenBucket * -1e6f / (float)m_n_x ) + 1; // +1 to make sure that if we don't have any tokens, we never return 0, since zero means \"ready right now\"\n\t}\n\n\t/// Nagle timer on all pending messages\n\tvoid ClearNagleTimers()\n\t{\n\t\tCSteamNetworkingMessage *pMsg = m_messagesQueued.m_pLast;\n\t\twhile ( pMsg && pMsg->SNPSend_UsecNagle() )\n\t\t{\n\t\t\tpMsg->SNPSend_SetUsecNagle( 0 );\n\t\t\tpMsg = pMsg->m_links.m_pPrev;\n\t\t}\n\t}\n\n\t// Current message number, we ++ when adding a message\n\tint64 m_nReliableStreamPos = 1;\n\tint64 m_nLastSentMsgNum = 0; // Will increment to 1 with first message\n\tint64 m_nLastSendMsgNumReliable = 0;\n\n\t/// List of messages that we have not yet finished putting on the wire the first time.\n\t/// The Nagle timer may be active on one or more, but if so, it is only on messages\n\t/// at the END of the list.  The first message may be partially sent.\n\tSSNPSendMessageList m_messagesQueued;\n\n\t/// How many bytes into the first message in the queue have we put on the wire?\n\tint m_cbCurrentSendMessageSent = 0;\n\n\t/// List of reliable messages that have been fully placed on the wire at least once,\n\t/// but we're hanging onto because of the potential need to retry.  (Note that if we get\n\t/// packet loss, it's possible that we hang onto a message even after it's been fully\n\t/// acked, because a prior message is still needed.  We always operate on this list\n\t/// like a queue, rather than seeking into the middle of the list and removing messages\n\t/// as soon as they are no longer needed.)\n\tSSNPSendMessageList m_unackedReliableMessages;\n\n\t// Buffered data counters.  See SteamNetworkingQuickConnectionStatus for more info\n\tint m_cbPendingUnreliable = 0;\n\tint m_cbPendingReliable = 0;\n\tint m_cbSentUnackedReliable = 0;\n\tinline int PendingBytesTotal() const { return m_cbPendingUnreliable + m_cbPendingReliable; }\n\n\t// Stats.  FIXME - move to LinkStatsEndToEnd and track rate counters\n\tint64 m_nMessagesSentReliable = 0;\n\tint64 m_nMessagesSentUnreliable = 0;\n\n\t/// List of packets that we have sent but don't know whether they were received or not.\n\t/// We keep a dummy sentinel at the head of the list, with a negative packet number.\n\t/// This vastly simplifies the processing.\n\tstd_map<int64,SNPInFlightPacket_t> m_mapInFlightPacketsByPktNum;\n\n\t/// The next unacked packet that should be timed out and implicitly NACKed,\n\t/// if we don't receive an ACK in time.  Will be m_mapInFlightPacketsByPktNum.end()\n\t/// if we don't have any in flight packets that we are waiting on.\n\tstd_map<int64,SNPInFlightPacket_t>::iterator m_itNextInFlightPacketToTimeout;\n\n\t/// Ordered list of reliable ranges that we have recently sent\n\t/// in a packet.  These should be non-overlapping, and furthermore\n\t/// should not overlap with with any range in m_listReadyReliableRange\n\t///\n\t/// The \"value\" portion of the map is the message that has the first bit of\n\t/// reliable data we need for this message\n\tstd_map<SNPRange_t,CSteamNetworkingMessage*,SNPRange_t::NonOverlappingLess> m_listInFlightReliableRange;\n\n\t/// Ordered list of ranges that have been put on the wire,\n\t/// but have been detected as dropped, and now need to be retried.\n\tstd_map<SNPRange_t,CSteamNetworkingMessage*,SNPRange_t::NonOverlappingLess> m_listReadyRetryReliableRange;\n\n\t/// Oldest packet sequence number that we are still asking peer\n\t/// to send acks for.\n\tint64 m_nMinPktWaitingOnAck = 0;\n\n\t// Remove messages from m_unackedReliableMessages that have been fully acked.\n\tvoid RemoveAckedReliableMessageFromUnackedList();\n\n\t/// Check invariants in debug.\n\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA == 0 \n\t\tinline void DebugCheckInFlightPacketMap() const {}\n\t#else\n\t\tvoid DebugCheckInFlightPacketMap() const;\n\t#endif\n\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 1\n\t\tinline void MaybeCheckInFlightPacketMap() const { DebugCheckInFlightPacketMap(); }\n\t#else\n\t\tinline void MaybeCheckInFlightPacketMap() const {}\n\t#endif\n};\n\nstruct SSNPRecvUnreliableSegmentKey\n{\n\tint64 m_nMsgNum;\n\tint m_nOffset;\n\n\tinline bool operator<(const SSNPRecvUnreliableSegmentKey &x) const\n\t{\n\t\tif ( m_nMsgNum < x.m_nMsgNum ) return true;\n\t\tif ( m_nMsgNum > x.m_nMsgNum ) return false;\n\t\treturn m_nOffset < x.m_nOffset;\n\t}\n};\n\nstruct SSNPRecvUnreliableSegmentData\n{\n\tint m_cbSegSize = -1;\n\tbool m_bLast = false;\n\tchar m_buf[ k_cbSteamNetworkingSocketsMaxPlaintextPayloadRecv ];\n};\n\nstruct SSNPPacketGap\n{\n\tint64 m_nEnd; // just after the last packet received\n\tSteamNetworkingMicroseconds m_usecWhenReceivedPktBefore; // So we can send RTT data in our acks\n\tSteamNetworkingMicroseconds m_usecWhenAckPrior; // We need to send an ack for everything with lower packet numbers than this gap by this time.  (Earlier is OK.)\n\tSteamNetworkingMicroseconds m_usecWhenOKToNack; // Don't give up on the gap being filed before this time\n};\n\nstruct SSNPReceiverState\n{\n\tSSNPReceiverState();\n\t~SSNPReceiverState() {\n\t\tShutdown();\n\t}\n\tvoid Shutdown();\n\n\t/// Unreliable message segments that we have received.  When an unreliable message\n\t/// needs to be fragmented, we store the pieces here.  NOTE: it might be more efficient\n\t/// to use a simpler container, with worse O(), since this should ordinarily be\n\t/// a pretty small list.\n\tstd_map<SSNPRecvUnreliableSegmentKey,SSNPRecvUnreliableSegmentData> m_mapUnreliableSegments;\n\n\t/// Stream position of the first byte in m_bufReliableData.  Remember that the first byte\n\t/// in the reliable stream is actually at position 1, not 0\n\tint64 m_nReliableStreamPos = 1;\n\n\t/// The highest message number we have seen so far.\n\tint64 m_nHighestSeenMsgNum = 0;\n\n\t/// The message number of the most recently received reliable message\n\tint64 m_nLastRecvReliableMsgNum = 0;\n\n\t/// Reliable data stream that we have received.  This might have gaps in it!\n\tstd::vector<byte> m_bufReliableStream;\n\n\t/// Gaps in the reliable data.  These are created when we receive reliable data that\n\t/// is beyond what we expect next.  Since these must never overlap, we store them\n\t/// using begin as the key and end as the value.\n\t///\n\t/// !SPEED! We should probably use a small fixed-sized, sorted vector here,\n\t/// since in most cases the list will be small, and the cost of dynamic memory\n\t/// allocation will be way worse than O(n) insertion/removal.\n\tstd_map<int64,int64> m_mapReliableStreamGaps;\n\n\t/// List of gaps in the packet sequence numbers we have received.\n\t/// Since these must never overlap, we store them using begin as the\n\t/// key and the end in the value.\n\t///\n\t/// The last item in the list is a sentinel with\n\t/// begin and end set to INT64_MAX, and m_usecWhenAckPrior is\n\t/// the time when we need to flush acks/backs for all packets,\n\t/// including those received after the last gap (if any --\n\t/// INT64_MAX means nothing scheduled).  Remember, our wire\n\t/// protocol cannot report on packet N without also reporting\n\t/// on all packets numbered < N.\n\t///\n\t/// !SPEED! We should probably use a small fixed-sized, sorted vector here,\n\t/// since in most cases the list will be small, and the cost of dynamic memory\n\t/// allocation will be way worse than O(n) insertion/removal.\n\tstd_map<int64,SSNPPacketGap> m_mapPacketGaps;\n\n\t/// Oldest packet sequence number we need to ack to our peer\n\tint64 m_nMinPktNumToSendAcks = 0;\n\n\t/// Packet number when we received the value of m_nMinPktNumToSendAcks\n\tint64 m_nPktNumUpdatedMinPktNumToSendAcks = 0;\n\n\t/// The next ack that needs to be sent.  The invariant\n\t/// for the times are:\n\t///\n\t/// * Blocks with lower packet numbers: m_usecWhenAckPrior = INT64_MAX\n\t/// * This block: m_usecWhenAckPrior < INT64_MAX, or we are the sentinel\n\t/// * Blocks with higher packet numbers (if we are not the sentinel): m_usecWhenAckPrior >= previous m_usecWhenAckPrior\n\t///\n\t/// We might send acks before they are due, rather than\n\t/// waiting until the last moment!  If we are going to\n\t/// send a packet at all, we usually try to send at least\n\t/// a few acks, and if there is room in the packet, as\n\t/// many as will fit.  The one exception is that if\n\t/// sending an ack would imply a NACK that we don't want to\n\t/// send yet.  (Remember the restrictions on what we are able\n\t/// to communicate due to the tight RLE encoding of the wire\n\t/// format.)  These delays are usually very short lived, and\n\t/// only happen when there is packet loss, so they don't delay\n\t/// acks very much.  The whole purpose of this rather involved\n\t/// bookkeeping is to figure out which acks we *need* to send,\n\t/// and which acks we cannot send yet, so we can make optimal\n\t/// decisions.\n\tstd_map<int64,SSNPPacketGap>::iterator m_itPendingAck;\n\n\t/// Iterator into m_mapPacketGaps.  If != the sentinel,\n\t/// we will avoid reporting on the dropped packets in this\n\t/// gap (and all higher numbered packets), because we are\n\t/// waiting in the hopes that they will arrive out of order.\n\tstd_map<int64,SSNPPacketGap>::iterator m_itPendingNack;\n\n\t/// Queue a flush of ALL acks (and NACKs!) by the given time.\n\t/// If anything is scheduled to happen earlier, that schedule\n\t/// will still be honered.  We will ack up to that packet number,\n\t/// and then we we may report higher numbered blocks, or we may\n\t/// stop and wait to report more acks until later.\n\tvoid QueueFlushAllAcks( SteamNetworkingMicroseconds usecWhen );\n\n\t/// Return the time when we need to flush out acks, or INT64_MAX\n\t/// if we don't have any acks pending right now.\n\tinline SteamNetworkingMicroseconds TimeWhenFlushAcks() const\n\t{\n\t\t// Paranoia\n\t\tif ( m_mapPacketGaps.empty() )\n\t\t{\n\t\t\tAssertMsg( false, \"TimeWhenFlushAcks - we're shut down!\" );\n\t\t\treturn INT64_MAX;\n\t\t}\n\t\treturn m_itPendingAck->second.m_usecWhenAckPrior;\n\t}\n\n\t/// Check invariants in debug.\n\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 1\n\t\tvoid DebugCheckPackGapMap() const;\n\t#else\n\t\tinline void DebugCheckPackGapMap() const {}\n\t#endif\n\n\t// Stats.  FIXME - move to LinkStatsEndToEnd and track rate counters\n\tint64 m_nMessagesRecvReliable = 0;\n\tint64 m_nMessagesRecvUnreliable = 0;\n};\n\n} // SteamNetworkingSocketsLib\n"], "fixing_code": ["//====== Copyright Valve Corporation, All rights reserved. ====================\n\n#include \"steamnetworkingsockets_snp.h\"\n#include \"steamnetworkingsockets_connections.h\"\n#include \"crypto.h\"\n\n// memdbgon must be the last include file in a .cpp file!!!\n#include \"tier0/memdbgon.h\"\n\nnamespace SteamNetworkingSocketsLib {\n\nstruct SNPAckSerializerHelper\n{\n\tstruct Block\n\t{\n\t\t// Acks and nacks count to serialize\n\t\tuint32 m_nAck;\n\t\tuint32 m_nNack;\n\n\t\t// What to put in the header if we use this as the\n\t\t// highest numbered block\n\t\tuint32 m_nLatestPktNum; // Lower 32-bits.  We might send even fewer bits\n\t\tuint16 m_nEncodedTimeSinceLatestPktNum;\n\n\t\t// Total size of ack data up to this point:\n\t\t// header, all previous blocks, and this block\n\t\tint16 m_cbTotalEncodedSize;\n\t};\n\n\tenum { k_cbHeaderSize = 5 };\n\tenum { k_nMaxBlocks = 64 };\n\tint m_nBlocks;\n\tint m_nBlocksNeedToAck; // Number of blocks we really need to send now.\n\tBlock m_arBlocks[ k_nMaxBlocks ];\n\n\tstatic uint16 EncodeTimeSince( SteamNetworkingMicroseconds usecNow, SteamNetworkingMicroseconds usecWhenSentLast )\n\t{\n\n\t\t// Encode time since last\n\t\tSteamNetworkingMicroseconds usecElapsedSinceLast = usecNow - usecWhenSentLast;\n\t\tAssert( usecElapsedSinceLast >= 0 );\n\t\tAssert( usecNow > 0x20000*k_usecAckDelayPrecision ); // We should never have small timestamp values.  A timestamp of zero should always be \"a long time ago\"\n\t\tif ( usecElapsedSinceLast > 0xfffell<<k_nAckDelayPrecisionShift )\n\t\t\treturn 0xffff;\n\t\treturn uint16( usecElapsedSinceLast >> k_nAckDelayPrecisionShift );\n\t}\n\n};\n\n// Fetch ping, and handle two edge cases:\n// - if we don't have an estimate, just be relatively conservative\n// - clamp to minimum\ninline SteamNetworkingMicroseconds GetUsecPingWithFallback( CSteamNetworkConnectionBase *pConnection )\n{\n\tint nPingMS = pConnection->m_statsEndToEnd.m_ping.m_nSmoothedPing;\n\tif ( nPingMS < 0 )\n\t\treturn 200*1000; // no estimate, just be conservative\n\tif ( nPingMS < 1 )\n\t\treturn 500; // less than 1ms.  Make sure we don't blow up, though, since they are asking for microsecond resolution.  We should just keep our pings with microsecond resolution!\n\treturn nPingMS*1000;\n}\n\n\nvoid SSNPSenderState::Shutdown()\n{\n\tm_unackedReliableMessages.PurgeMessages();\n\tm_messagesQueued.PurgeMessages();\n\tm_mapInFlightPacketsByPktNum.clear();\n\tm_listInFlightReliableRange.clear();\n\tm_cbPendingUnreliable = 0;\n\tm_cbPendingReliable = 0;\n\tm_cbSentUnackedReliable = 0;\n}\n\n//-----------------------------------------------------------------------------\nvoid SSNPSenderState::RemoveAckedReliableMessageFromUnackedList()\n{\n\n\t// Trim messages from the head that have been acked.\n\t// Note that in theory we could have a message in the middle that\n\t// has been acked.  But it's not worth the time to go looking for them,\n\t// just to free up a bit of memory early.  We'll get to it once the earlier\n\t// messages have been acked.\n\twhile ( !m_unackedReliableMessages.empty() )\n\t{\n\t\tCSteamNetworkingMessage *pMsg = m_unackedReliableMessages.m_pFirst;\n\t\tAssert( pMsg->SNPSend_ReliableStreamPos() > 0 );\n\t\tint64 nReliableEnd = pMsg->SNPSend_ReliableStreamPos() + pMsg->m_cbSize;\n\n\t\t// Are we backing a range that is in flight (and thus we might need\n\t\t// to resend?)\n\t\tif ( !m_listInFlightReliableRange.empty() )\n\t\t{\n\t\t\tauto head = m_listInFlightReliableRange.begin();\n\t\t\tAssert( head->first.m_nBegin >= pMsg->SNPSend_ReliableStreamPos() );\n\t\t\tif ( head->second == pMsg )\n\t\t\t{\n\t\t\t\tAssert( head->first.m_nBegin < nReliableEnd );\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tAssert( head->first.m_nBegin >= nReliableEnd );\n\t\t}\n\n\t\t// Are we backing the next range that is ready for resend now?\n\t\tif ( !m_listReadyRetryReliableRange.empty() )\n\t\t{\n\t\t\tauto head = m_listReadyRetryReliableRange.begin();\n\t\t\tAssert( head->first.m_nBegin >= pMsg->SNPSend_ReliableStreamPos() );\n\t\t\tif ( head->second == pMsg )\n\t\t\t{\n\t\t\t\tAssert( head->first.m_nBegin < nReliableEnd );\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tAssert( head->first.m_nBegin >= nReliableEnd );\n\t\t}\n\n\t\t// We're all done!\n\t\tDbgVerify( m_unackedReliableMessages.pop_front() == pMsg );\n\t\tpMsg->Release();\n\t}\n}\n\n//-----------------------------------------------------------------------------\nSSNPSenderState::SSNPSenderState()\n{\n\t// Setup the table of inflight packets with a sentinel.\n\tm_mapInFlightPacketsByPktNum.clear();\n\tSNPInFlightPacket_t &sentinel = m_mapInFlightPacketsByPktNum[INT64_MIN];\n\tsentinel.m_bNack = false;\n\tsentinel.m_pTransport = nullptr;\n\tsentinel.m_usecWhenSent = 0;\n\tm_itNextInFlightPacketToTimeout = m_mapInFlightPacketsByPktNum.end();\n\tDebugCheckInFlightPacketMap();\n}\n\n#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 0\nvoid SSNPSenderState::DebugCheckInFlightPacketMap() const\n{\n\tAssert( !m_mapInFlightPacketsByPktNum.empty() );\n\tbool bFoundNextToTimeout = false;\n\tauto it = m_mapInFlightPacketsByPktNum.begin();\n\tAssert( it->first == INT64_MIN );\n\tAssert( m_itNextInFlightPacketToTimeout != it );\n\tint64 prevPktNum = it->first;\n\tSteamNetworkingMicroseconds prevWhenSent = it->second.m_usecWhenSent;\n\twhile ( ++it != m_mapInFlightPacketsByPktNum.end() )\n\t{\n\t\tAssert( prevPktNum < it->first );\n\t\tAssert( prevWhenSent <= it->second.m_usecWhenSent );\n\t\tif ( it == m_itNextInFlightPacketToTimeout )\n\t\t{\n\t\t\tAssert( !bFoundNextToTimeout );\n\t\t\tbFoundNextToTimeout = true;\n\t\t}\n\t\tprevPktNum = it->first;\n\t\tprevWhenSent = it->second.m_usecWhenSent;\n\t}\n\tif ( !bFoundNextToTimeout )\n\t{\n\t\tAssert( m_itNextInFlightPacketToTimeout == m_mapInFlightPacketsByPktNum.end() );\n\t}\n}\n#endif\n\n//-----------------------------------------------------------------------------\nSSNPReceiverState::SSNPReceiverState()\n{\n\t// Init packet gaps with a sentinel\n\tSSNPPacketGap &sentinel = m_mapPacketGaps[INT64_MAX];\n\tsentinel.m_nEnd = INT64_MAX; // Fixed value\n\tsentinel.m_usecWhenOKToNack = INT64_MAX; // Fixed value, for when there is nothing left to nack\n\tsentinel.m_usecWhenAckPrior = INT64_MAX; // Time when we need to flush a report on all lower-numbered packets\n\n\t// Point at the sentinel\n\tm_itPendingAck = m_mapPacketGaps.end();\n\t--m_itPendingAck;\n\tm_itPendingNack = m_itPendingAck;\n}\n\n//-----------------------------------------------------------------------------\nvoid SSNPReceiverState::Shutdown()\n{\n\tm_mapUnreliableSegments.clear();\n\tm_bufReliableStream.clear();\n\tm_mapReliableStreamGaps.clear();\n\tm_mapPacketGaps.clear();\n}\n\n//-----------------------------------------------------------------------------\nvoid CSteamNetworkConnectionBase::SNP_InitializeConnection( SteamNetworkingMicroseconds usecNow )\n{\n\tm_senderState.TokenBucket_Init( usecNow );\n\n\tSteamNetworkingMicroseconds usecPing = GetUsecPingWithFallback( this );\n\n\t/*\n\t* Compute the initial sending rate X_init in the manner of RFC 3390:\n\t*\n\t*\tX_init  =  min(4 * s, max(2 * s, 4380 bytes)) / RTT\n\t*\n\t* Note that RFC 3390 uses MSS, RFC 4342 refers to RFC 3390, and rfc3448bis\n\t* (rev-02) clarifies the use of RFC 3390 with regard to the above formula.\n\t*/\n\tAssert( usecPing > 0 );\n\tint64 w_init = Clamp( 4380, 2 * k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend, 4 * k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend );\n\tm_senderState.m_n_x = int( k_nMillion * w_init / usecPing );\n\n\t// Go ahead and clamp it now\n\tSNP_ClampSendRate();\n}\n\n//-----------------------------------------------------------------------------\nvoid CSteamNetworkConnectionBase::SNP_ShutdownConnection()\n{\n\tm_senderState.Shutdown();\n\tm_receiverState.Shutdown();\n}\n\n//-----------------------------------------------------------------------------\nint64 CSteamNetworkConnectionBase::SNP_SendMessage( CSteamNetworkingMessage *pSendMessage, SteamNetworkingMicroseconds usecNow, bool *pbThinkImmediately )\n{\n\tint cbData = (int)pSendMessage->m_cbSize;\n\n\t// Assume we won't want to wake up immediately\n\tif ( pbThinkImmediately )\n\t\t*pbThinkImmediately = false;\n\n\t// Check if we're full\n\tif ( m_senderState.PendingBytesTotal() + cbData > m_connectionConfig.m_SendBufferSize.Get() )\n\t{\n\t\tSpewWarningRateLimited( usecNow, \"Connection already has %u bytes pending, cannot queue any more messages\\n\", m_senderState.PendingBytesTotal() );\n\t\tpSendMessage->Release();\n\t\treturn -k_EResultLimitExceeded; \n\t}\n\n\t// Check if they try to send a really large message\n\tif ( cbData > k_cbMaxUnreliableMsgSizeSend && !( pSendMessage->m_nFlags & k_nSteamNetworkingSend_Reliable )  )\n\t{\n\t\tSpewWarningRateLimited( usecNow, \"Trying to send a very large (%d bytes) unreliable message.  Sending as reliable instead.\\n\", cbData );\n\t\tpSendMessage->m_nFlags |= k_nSteamNetworkingSend_Reliable;\n\t}\n\n\tif ( pSendMessage->m_nFlags & k_nSteamNetworkingSend_NoDelay )\n\t{\n\t\t// FIXME - need to check how much data is currently pending, and return\n\t\t// k_EResultIgnored if we think it's going to be a while before this\n\t\t// packet goes on the wire.\n\t}\n\n\t// First, accumulate tokens, and also limit to reasonable burst\n\t// if we weren't already waiting to send\n\tSNP_ClampSendRate();\n\tSNP_TokenBucket_Accumulate( usecNow );\n\n\t// Assign a message number\n\tpSendMessage->m_nMessageNumber = ++m_senderState.m_nLastSentMsgNum;\n\n\t// Reliable, or unreliable?\n\tif ( pSendMessage->m_nFlags & k_nSteamNetworkingSend_Reliable )\n\t{\n\t\tpSendMessage->SNPSend_SetReliableStreamPos( m_senderState.m_nReliableStreamPos );\n\n\t\t// Generate the header\n\t\tbyte *hdr = pSendMessage->SNPSend_ReliableHeader();\n\t\thdr[0] = 0;\n\t\tbyte *hdrEnd = hdr+1;\n\t\tint64 nMsgNumGap = pSendMessage->m_nMessageNumber - m_senderState.m_nLastSendMsgNumReliable;\n\t\tAssert( nMsgNumGap >= 1 );\n\t\tif ( nMsgNumGap > 1 )\n\t\t{\n\t\t\thdrEnd = SerializeVarInt( hdrEnd, (uint64)nMsgNumGap );\n\t\t\thdr[0] |= 0x40;\n\t\t}\n\t\tif ( cbData < 0x20 )\n\t\t{\n\t\t\thdr[0] |= (byte)cbData;\n\t\t}\n\t\telse\n\t\t{\n\t\t\thdr[0] |= (byte)( 0x20 | ( cbData & 0x1f ) );\n\t\t\thdrEnd = SerializeVarInt( hdrEnd, cbData>>5U );\n\t\t}\n\t\tpSendMessage->m_cbSNPSendReliableHeader = hdrEnd - hdr;\n\n\t\t// Grow the total size of the message by the header\n\t\tpSendMessage->m_cbSize += pSendMessage->m_cbSNPSendReliableHeader;\n\n\t\t// Advance stream pointer\n\t\tm_senderState.m_nReliableStreamPos += pSendMessage->m_cbSize;\n\n\t\t// Update stats\n\t\t++m_senderState.m_nMessagesSentReliable;\n\t\tm_senderState.m_cbPendingReliable += pSendMessage->m_cbSize;\n\n\t\t// Remember last sent reliable message number, so we can know how to\n\t\t// encode the next one\n\t\tm_senderState.m_nLastSendMsgNumReliable = pSendMessage->m_nMessageNumber;\n\n\t\tAssert( pSendMessage->SNPSend_IsReliable() );\n\t}\n\telse\n\t{\n\t\tpSendMessage->SNPSend_SetReliableStreamPos( 0 );\n\t\tpSendMessage->m_cbSNPSendReliableHeader = 0;\n\n\t\t++m_senderState.m_nMessagesSentUnreliable;\n\t\tm_senderState.m_cbPendingUnreliable += pSendMessage->m_cbSize;\n\n\t\tAssert( !pSendMessage->SNPSend_IsReliable() );\n\t}\n\n\t// Add to pending list\n\tm_senderState.m_messagesQueued.push_back( pSendMessage );\n\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_Message.Get(), \"[%s] SendMessage %s: MsgNum=%lld sz=%d\\n\",\n\t\t\t\t GetDescription(),\n\t\t\t\t pSendMessage->SNPSend_IsReliable() ? \"RELIABLE\" : \"UNRELIABLE\",\n\t\t\t\t (long long)pSendMessage->m_nMessageNumber,\n\t\t\t\t pSendMessage->m_cbSize );\n\n\t// Use Nagle?\n\t// We always set the Nagle timer, even if we immediately clear it.  This makes our clearing code simpler,\n\t// since we can always safely assume that once we find a message with the nagle timer cleared, all messages\n\t// queued earlier than this also have it cleared.\n\t// FIXME - Don't think this works if the configuration value is changing.  Since changing the\n\t// config value could violate the assumption that nagle times are increasing.  Probably not worth\n\t// fixing.\n\tpSendMessage->SNPSend_SetUsecNagle( usecNow + m_connectionConfig.m_NagleTime.Get() );\n\tif ( pSendMessage->m_nFlags & k_nSteamNetworkingSend_NoNagle )\n\t\tm_senderState.ClearNagleTimers();\n\n\t// Save the message number.  The code below might end up deleting the message we just queued\n\tint64 result = pSendMessage->m_nMessageNumber;\n\n\t// Schedule wakeup at the appropriate time.  (E.g. right now, if we're ready to send, \n\t// or at the Nagle time, if Nagle is active.)\n\t//\n\t// NOTE: Right now we might not actually be capable of sending end to end data.\n\t// But that case is relatievly rare, and nothing will break if we try to right now.\n\t// On the other hand, just asking the question involved a virtual function call,\n\t// and it will return success most of the time, so let's not make the check here.\n\tif ( GetState() == k_ESteamNetworkingConnectionState_Connected )\n\t{\n\t\tSteamNetworkingMicroseconds usecNextThink = SNP_GetNextThinkTime( usecNow );\n\n\t\t// Ready to send now?\n\t\tif ( usecNextThink > usecNow )\n\t\t{\n\n\t\t\t// We are rate limiting.  Spew about it?\n\t\t\tif ( m_senderState.m_messagesQueued.m_pFirst->SNPSend_UsecNagle() == 0 )\n\t\t\t{\n\t\t\t\tSpewVerbose( \"[%s] RATELIM QueueTime is %.1fms, SendRate=%.1fk, BytesQueued=%d\\n\", \n\t\t\t\t\tGetDescription(),\n\t\t\t\t\tm_senderState.CalcTimeUntilNextSend() * 1e-3,\n\t\t\t\t\tm_senderState.m_n_x * ( 1.0/1024.0),\n\t\t\t\t\tm_senderState.PendingBytesTotal()\n\t\t\t\t);\n\t\t\t}\n\n\t\t\t// Set a wakeup call.\n\t\t\tEnsureMinThinkTime( usecNextThink );\n\t\t}\n\t\telse\n\t\t{\n\n\t\t\t// We're ready to send right now.  Check if we should!\n\t\t\tif ( pSendMessage->m_nFlags & k_nSteamNetworkingSend_UseCurrentThread )\n\t\t\t{\n\n\t\t\t\t// We should send in this thread, before the API entry point\n\t\t\t\t// that the app used returns.  Is the caller gonna handle this?\n\t\t\t\tif ( pbThinkImmediately )\n\t\t\t\t{\n\t\t\t\t\t// Caller says they will handle it\n\t\t\t\t\t*pbThinkImmediately = true;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t// Caller wants us to just do it here.\n\t\t\t\t\tCheckConnectionStateAndSetNextThinkTime( usecNow );\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Wake up the service thread ASAP to send this in the background thread\n\t\t\t\tSetNextThinkTimeASAP();\n\t\t\t}\n\t\t}\n\t}\n\n\treturn result;\n}\n\nEResult CSteamNetworkConnectionBase::SNP_FlushMessage( SteamNetworkingMicroseconds usecNow )\n{\n\t// If we're not connected, then go ahead and mark the messages ready to send\n\t// once we connect, but otherwise don't take any action\n\tif ( GetState() != k_ESteamNetworkingConnectionState_Connected )\n\t{\n\t\tm_senderState.ClearNagleTimers();\n\t\treturn k_EResultIgnored;\n\t}\n\n\tif ( m_senderState.m_messagesQueued.empty() )\n\t\treturn k_EResultOK;\n\n\t// If no Nagle timer was set, then there's nothing to do, we should already\n\t// be properly scheduled.  Don't do work to re-discover that fact.\n\tif ( m_senderState.m_messagesQueued.m_pLast->SNPSend_UsecNagle() == 0 )\n\t\treturn k_EResultOK;\n\n\t// Accumulate tokens, and also limit to reasonable burst\n\t// if we weren't already waiting to send before this.\n\t// (Clearing the Nagle timers might very well make us want to\n\t// send so we want to do this first.)\n\tSNP_ClampSendRate();\n\tSNP_TokenBucket_Accumulate( usecNow );\n\n\t// Clear all Nagle timers\n\tm_senderState.ClearNagleTimers();\n\n\t// Schedule wakeup at the appropriate time.  (E.g. right now, if we're ready to send.)\n\tSteamNetworkingMicroseconds usecNextThink = SNP_GetNextThinkTime( usecNow );\n\tEnsureMinThinkTime( usecNextThink );\n\treturn k_EResultOK;\n}\n\nbool CSteamNetworkConnectionBase::ProcessPlainTextDataChunk( int usecTimeSinceLast, RecvPacketContext_t &ctx )\n{\n\t#define DECODE_ERROR( ... ) do { \\\n\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError, __VA_ARGS__ ); \\\n\t\treturn false; } while(false)\n\n\t#define EXPECT_BYTES(n,pszWhatFor) \\\n\t\tdo { \\\n\t\t\tif ( pDecode + (n) > pEnd ) \\\n\t\t\t\tDECODE_ERROR( \"SNP decode overrun, %d bytes for %s\", (n), pszWhatFor ); \\\n\t\t} while (false)\n\n\t#define READ_8BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(1,pszWhatFor); var = *(uint8 *)pDecode; pDecode += 1; } while(false)\n\n\t#define READ_16BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(2,pszWhatFor); var = LittleWord(*(uint16 *)pDecode); pDecode += 2; } while(false)\n\n\t#define READ_24BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(3,pszWhatFor); \\\n\t\t\tvar = *(uint8 *)pDecode; pDecode += 1; \\\n\t\t\tvar |= uint32( LittleWord(*(uint16 *)pDecode) ) << 8U; pDecode += 2; \\\n\t\t} while(false)\n\n\t#define READ_32BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(4,pszWhatFor); var = LittleDWord(*(uint32 *)pDecode); pDecode += 4; } while(false)\n\n\t#define READ_48BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(6,pszWhatFor); \\\n\t\t\tvar = LittleWord( *(uint16 *)pDecode ); pDecode += 2; \\\n\t\t\tvar |= uint64( LittleDWord(*(uint32 *)pDecode) ) << 16U; pDecode += 4; \\\n\t\t} while(false)\n\n\t#define READ_64BITU( var, pszWhatFor ) \\\n\t\tdo { EXPECT_BYTES(8,pszWhatFor); var = LittleQWord(*(uint64 *)pDecode); pDecode += 8; } while(false)\n\n\t#define READ_VARINT( var, pszWhatFor ) \\\n\t\tdo { pDecode = DeserializeVarInt( pDecode, pEnd, var ); if ( !pDecode ) { DECODE_ERROR( \"SNP data chunk decode overflow, varint for %s\", pszWhatFor ); } } while(false)\n\n\t#define READ_SEGMENT_DATA_SIZE( is_reliable ) \\\n\t\tint cbSegmentSize; \\\n\t\t{ \\\n\t\t\tint sizeFlags = nFrameType & 7; \\\n\t\t\tif ( sizeFlags <= 4 ) \\\n\t\t\t{ \\\n\t\t\t\tuint8 lowerSizeBits; \\\n\t\t\t\tREAD_8BITU( lowerSizeBits, #is_reliable \" size lower bits\" ); \\\n\t\t\t\tcbSegmentSize = (sizeFlags<<8) + lowerSizeBits; \\\n\t\t\t\tif ( pDecode + cbSegmentSize > pEnd ) \\\n\t\t\t\t{ \\\n\t\t\t\t\tDECODE_ERROR( \"SNP decode overrun %d bytes for %s segment data.\", cbSegmentSize, #is_reliable ); \\\n\t\t\t\t} \\\n\t\t\t} \\\n\t\t\telse if ( sizeFlags == 7 ) \\\n\t\t\t{ \\\n\t\t\t\tcbSegmentSize = pEnd - pDecode; \\\n\t\t\t} \\\n\t\t\telse \\\n\t\t\t{ \\\n\t\t\t\tDECODE_ERROR( \"Invalid SNP frame lead byte 0x%02x. (size bits)\", nFrameType ); \\\n\t\t\t} \\\n\t\t} \\\n\t\tconst uint8 *pSegmentData = pDecode; \\\n\t\tpDecode += cbSegmentSize;\n\n\t// Make sure we have initialized the connection\n\tAssert( BStateIsActive() );\n\n\tconst SteamNetworkingMicroseconds usecNow = ctx.m_usecNow;\n\tconst int64 nPktNum = ctx.m_nPktNum;\n\tbool bInhibitMarkReceived = false;\n\n\tconst int nLogLevelPacketDecode = m_connectionConfig.m_LogLevel_PacketDecode.Get();\n\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s] decode pkt %lld\\n\", GetDescription(), (long long)nPktNum );\n\n\t// Decode frames until we get to the end of the payload\n\tconst byte *pDecode = (const byte *)ctx.m_pPlainText;\n\tconst byte *pEnd = pDecode + ctx.m_cbPlainText;\n\tint64 nCurMsgNum = 0;\n\tint64 nDecodeReliablePos = 0;\n\twhile ( pDecode < pEnd )\n\t{\n\n\t\tuint8 nFrameType = *pDecode;\n\t\t++pDecode;\n\t\tif ( ( nFrameType & 0xc0 ) == 0x00 )\n\t\t{\n\n\t\t\t//\n\t\t\t// Unreliable segment\n\t\t\t//\n\n\t\t\t// Decode message number\n\t\t\tif ( nCurMsgNum == 0 )\n\t\t\t{\n\t\t\t\t// First unreliable frame.  Message number is absolute, but only bottom N bits are sent\n\t\t\t\tstatic const char szUnreliableMsgNumOffset[] = \"unreliable msgnum\";\n\t\t\t\tint64 nLowerBits, nMask;\n\t\t\t\tif ( nFrameType & 0x10 )\n\t\t\t\t{\n\t\t\t\t\tREAD_32BITU( nLowerBits, szUnreliableMsgNumOffset );\n\t\t\t\t\tnMask = 0xffffffff;\n\t\t\t\t\tnCurMsgNum = NearestWithSameLowerBits( (int32)nLowerBits, m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tREAD_16BITU( nLowerBits, szUnreliableMsgNumOffset );\n\t\t\t\t\tnMask = 0xffff;\n\t\t\t\t\tnCurMsgNum = NearestWithSameLowerBits( (int16)nLowerBits, m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\t}\n\t\t\t\tAssert( ( nCurMsgNum & nMask ) == nLowerBits );\n\n\t\t\t\tif ( nCurMsgNum <= 0 )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP decode unreliable msgnum underflow.  %llx mod %llx, highest seen %llx\",\n\t\t\t\t\t\t(unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ), (unsigned long long)m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\t}\n\t\t\t\tif ( std::abs( nCurMsgNum - m_receiverState.m_nHighestSeenMsgNum ) > (nMask>>2) )\n\t\t\t\t{\n\t\t\t\t\t// We really should never get close to this boundary.\n\t\t\t\t\tSpewWarningRateLimited( usecNow, \"Sender sent abs unreliable message number using %llx mod %llx, highest seen %llx\\n\",\n\t\t\t\t\t\t(unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ), (unsigned long long)m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\t}\n\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tif ( nFrameType & 0x10 )\n\t\t\t\t{\n\t\t\t\t\tuint64 nMsgNumOffset;\n\t\t\t\t\tREAD_VARINT( nMsgNumOffset, \"unreliable msgnum offset\" );\n\t\t\t\t\tnCurMsgNum += nMsgNumOffset;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t++nCurMsgNum;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif ( nCurMsgNum > m_receiverState.m_nHighestSeenMsgNum )\n\t\t\t\tm_receiverState.m_nHighestSeenMsgNum = nCurMsgNum;\n\n\t\t\t//\n\t\t\t// Decode segment offset in message\n\t\t\t//\n\t\t\tuint32 nOffset = 0;\n\t\t\tif ( nFrameType & 0x08 )\n\t\t\t\tREAD_VARINT( nOffset, \"unreliable data offset\" );\n\n\t\t\t//\n\t\t\t// Decode size, locate segment data\n\t\t\t//\n\t\t\tREAD_SEGMENT_DATA_SIZE( unreliable )\n\n\t\t\t// Check if offset+size indicates a message larger than what we support.  (Also,\n\t\t\t// protect against malicious sender sending *extremely* large offset causing overflow.)\n\t\t\tif ( (int64)nOffset + cbSegmentSize > k_cbMaxUnreliableMsgSizeRecv || cbSegmentSize > k_cbMaxUnreliableSegmentSizeRecv )\n\t\t\t{\n\n\t\t\t\t// Since this is unreliable data, we can just ignore the segment.\n\t\t\t\tSpewWarningRateLimited( usecNow, \"[%s] Ignoring unreliable segment with invalid offset %u size %d\\n\",\n\t\t\t\t\tGetDescription(), nOffset, cbSegmentSize );\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\n\t\t\t\t// Receive the segment\n\t\t\t\tbool bLastSegmentInMessage = ( nFrameType & 0x20 ) != 0;\n\t\t\t\tSNP_ReceiveUnreliableSegment( nCurMsgNum, nOffset, pSegmentData, cbSegmentSize, bLastSegmentInMessage, usecNow );\n\t\t\t}\n\t\t}\n\t\telse if ( ( nFrameType & 0xe0 ) == 0x40 )\n\t\t{\n\n\t\t\t//\n\t\t\t// Reliable segment\n\t\t\t//\n\n\t\t\t// First reliable segment?\n\t\t\tif ( nDecodeReliablePos == 0 )\n\t\t\t{\n\n\t\t\t\t// Stream position is absolute.  How many bits?\n\t\t\t\tstatic const char szFirstReliableStreamPos[] = \"first reliable streampos\";\n\t\t\t\tint64 nOffset, nMask;\n\t\t\t\tswitch ( nFrameType & (3<<3) )\n\t\t\t\t{\n\t\t\t\t\tcase 0<<3: READ_24BITU( nOffset, szFirstReliableStreamPos ); nMask = (1ll<<24)-1; break;\n\t\t\t\t\tcase 1<<3: READ_32BITU( nOffset, szFirstReliableStreamPos ); nMask = (1ll<<32)-1; break;\n\t\t\t\t\tcase 2<<3: READ_48BITU( nOffset, szFirstReliableStreamPos ); nMask = (1ll<<48)-1; break;\n\t\t\t\t\tdefault: DECODE_ERROR( \"Reserved reliable stream pos size\" );\n\t\t\t\t}\n\n\t\t\t\t// What do we expect to receive next?\n\t\t\t\tint64 nExpectNextStreamPos = m_receiverState.m_nReliableStreamPos + len( m_receiverState.m_bufReliableStream );\n\n\t\t\t\t// Find the stream offset closest to that\n\t\t\t\tnDecodeReliablePos = ( nExpectNextStreamPos & ~nMask ) + nOffset;\n\t\t\t\tif ( nDecodeReliablePos + (nMask>>1) < nExpectNextStreamPos )\n\t\t\t\t{\n\t\t\t\t\tnDecodeReliablePos += nMask+1;\n\t\t\t\t\tAssert( ( nDecodeReliablePos & nMask ) == nOffset );\n\t\t\t\t\tAssert( nExpectNextStreamPos < nDecodeReliablePos );\n\t\t\t\t\tAssert( nExpectNextStreamPos + (nMask>>1) >= nDecodeReliablePos );\n\t\t\t\t}\n\t\t\t\tif ( nDecodeReliablePos <= 0 )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP decode first reliable stream pos underflow.  %llx mod %llx, expected next %llx\",\n\t\t\t\t\t\t(unsigned long long)nOffset, (unsigned long long)( nMask+1 ), (unsigned long long)nExpectNextStreamPos );\n\t\t\t\t}\n\t\t\t\tif ( std::abs( nDecodeReliablePos - nExpectNextStreamPos ) > (nMask>>2) )\n\t\t\t\t{\n\t\t\t\t\t// We really should never get close to this boundary.\n\t\t\t\t\tSpewWarningRateLimited( usecNow, \"Sender sent reliable stream pos using %llx mod %llx, expected next %llx\\n\",\n\t\t\t\t\t\t(unsigned long long)nOffset, (unsigned long long)( nMask+1 ), (unsigned long long)nExpectNextStreamPos );\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Subsequent reliable message encode the position as an offset from previous.\n\t\t\t\tstatic const char szOtherReliableStreamPos[] = \"reliable streampos offset\";\n\t\t\t\tint64 nOffset;\n\t\t\t\tswitch ( nFrameType & (3<<3) )\n\t\t\t\t{\n\t\t\t\t\tcase 0<<3: nOffset = 0; break;\n\t\t\t\t\tcase 1<<3: READ_8BITU( nOffset, szOtherReliableStreamPos ); break;\n\t\t\t\t\tcase 2<<3: READ_16BITU( nOffset, szOtherReliableStreamPos ); break;\n\t\t\t\t\tdefault: READ_32BITU( nOffset, szOtherReliableStreamPos ); break;\n\t\t\t\t}\n\t\t\t\tnDecodeReliablePos += nOffset;\n\t\t\t}\n\n\t\t\t//\n\t\t\t// Decode size, locate segment data\n\t\t\t//\n\t\t\tREAD_SEGMENT_DATA_SIZE( reliable )\n\n\t\t\t// Ingest the segment.\n\t\t\tif ( !SNP_ReceiveReliableSegment( nPktNum, nDecodeReliablePos, pSegmentData, cbSegmentSize, usecNow ) )\n\t\t\t{\n\t\t\t\tif ( !BStateIsActive() )\n\t\t\t\t\treturn false; // we decided to nuke the connection - abort packet processing\n\n\t\t\t\t// We're not able to ingest this reliable segment at the moment,\n\t\t\t\t// but we didn't terminate the connection.  So do not ack this packet\n\t\t\t\t// to the peer.  We need them to retransmit\n\t\t\t\tbInhibitMarkReceived = true;\n\t\t\t}\n\n\t\t\t// Advance pointer for the next reliable segment, if any.\n\t\t\tnDecodeReliablePos += cbSegmentSize;\n\n\t\t\t// Decoding rules state that if we have established a message number,\n\t\t\t// (from an earlier unreliable message), then we advance it.\n\t\t\tif ( nCurMsgNum > 0 ) \n\t\t\t\t++nCurMsgNum;\n\t\t}\n\t\telse if ( ( nFrameType & 0xfc ) == 0x80 )\n\t\t{\n\t\t\t//\n\t\t\t// Stop waiting\n\t\t\t//\n\n\t\t\tint64 nOffset = 0;\n\t\t\tstatic const char szStopWaitingOffset[] = \"stop_waiting offset\";\n\t\t\tswitch ( nFrameType & 3 )\n\t\t\t{\n\t\t\t\tcase 0: READ_8BITU( nOffset, szStopWaitingOffset ); break;\n\t\t\t\tcase 1: READ_16BITU( nOffset, szStopWaitingOffset ); break;\n\t\t\t\tcase 2: READ_24BITU( nOffset, szStopWaitingOffset ); break;\n\t\t\t\tcase 3: READ_64BITU( nOffset, szStopWaitingOffset ); break;\n\t\t\t}\n\t\t\tif ( nOffset >= nPktNum )\n\t\t\t{\n\t\t\t\tDECODE_ERROR( \"stop_waiting pktNum %llu offset %llu\", nPktNum, nOffset );\n\t\t\t}\n\t\t\t++nOffset;\n\t\t\tint64 nMinPktNumToSendAcks = nPktNum-nOffset;\n\t\t\tif ( nMinPktNumToSendAcks == m_receiverState.m_nMinPktNumToSendAcks )\n\t\t\t\tcontinue;\n\t\t\tif ( nMinPktNumToSendAcks < m_receiverState.m_nMinPktNumToSendAcks )\n\t\t\t{\n\t\t\t\t// Sender must never reduce this number!  Check for bugs or bogus sender\n\t\t\t\tif ( nPktNum >= m_receiverState.m_nPktNumUpdatedMinPktNumToSendAcks )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP stop waiting reduced %lld (pkt %lld) -> %lld (pkt %lld)\",\n\t\t\t\t\t\t(long long)m_receiverState.m_nMinPktNumToSendAcks,\n\t\t\t\t\t\t(long long)m_receiverState.m_nPktNumUpdatedMinPktNumToSendAcks,\n\t\t\t\t\t\t(long long)nMinPktNumToSendAcks,\n\t\t\t\t\t\t(long long)nPktNum\n\t\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld stop waiting: %lld (was %lld)\",\n\t\t\t\tGetDescription(),\n\t\t\t\t(long long)nPktNum,\n\t\t\t\t(long long)nMinPktNumToSendAcks, (long long)m_receiverState.m_nMinPktNumToSendAcks );\n\t\t\tm_receiverState.m_nMinPktNumToSendAcks = nMinPktNumToSendAcks;\n\t\t\tm_receiverState.m_nPktNumUpdatedMinPktNumToSendAcks = nPktNum;\n\n\t\t\t// Trim from the front of the packet gap list,\n\t\t\t// we can stop reporting these losses to the sender\n\t\t\tauto h = m_receiverState.m_mapPacketGaps.begin();\n\t\t\twhile ( h->first <= m_receiverState.m_nMinPktNumToSendAcks )\n\t\t\t{\n\t\t\t\tif ( h->second.m_nEnd > m_receiverState.m_nMinPktNumToSendAcks )\n\t\t\t\t{\n\t\t\t\t\t// Ug.  You're not supposed to modify the key in a map.\n\t\t\t\t\t// I suppose that's legit, since you could violate the ordering.\n\t\t\t\t\t// but in this case I know that this change is OK.\n\t\t\t\t\tconst_cast<int64 &>( h->first ) = m_receiverState.m_nMinPktNumToSendAcks;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t// Were we pending an ack on this?\n\t\t\t\tif ( m_receiverState.m_itPendingAck == h )\n\t\t\t\t\t++m_receiverState.m_itPendingAck;\n\n\t\t\t\t// Were we pending a nack on this?\n\t\t\t\tif ( m_receiverState.m_itPendingNack == h )\n\t\t\t\t{\n\t\t\t\t\t// I am not sure this is even possible.\n\t\t\t\t\tAssertMsg( false, \"Expiring packet gap, which had pending NACK\" );\n\n\t\t\t\t\t// But just in case, this would be the proper action\n\t\t\t\t\t++m_receiverState.m_itPendingNack;\n\t\t\t\t}\n\n\t\t\t\t// Packet loss is in the past.  Forget about it and move on\n\t\t\t\th = m_receiverState.m_mapPacketGaps.erase(h);\n\t\t\t}\n\t\t}\n\t\telse if ( ( nFrameType & 0xf0 ) == 0x90 )\n\t\t{\n\n\t\t\t//\n\t\t\t// Ack\n\t\t\t//\n\n\t\t\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 0\n\t\t\t\tm_senderState.DebugCheckInFlightPacketMap();\n\t\t\t\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA == 1\n\t\t\t\tif ( ( nPktNum & 255 ) == 0 ) // only do it periodically\n\t\t\t\t#endif\n\t\t\t\t{\n\t\t\t\t\tm_senderState.DebugCheckInFlightPacketMap();\n\t\t\t\t}\n\t\t\t#endif\n\n\t\t\t// Parse latest received sequence number\n\t\t\tint64 nLatestRecvSeqNum;\n\t\t\t{\n\t\t\t\tstatic const char szAckLatestPktNum[] = \"ack latest pktnum\";\n\t\t\t\tint64 nLowerBits, nMask;\n\t\t\t\tif ( nFrameType & 0x40 )\n\t\t\t\t{\n\t\t\t\t\tREAD_32BITU( nLowerBits, szAckLatestPktNum );\n\t\t\t\t\tnMask = 0xffffffff;\n\t\t\t\t\tnLatestRecvSeqNum = NearestWithSameLowerBits( (int32)nLowerBits, m_statsEndToEnd.m_nNextSendSequenceNumber );\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tREAD_16BITU( nLowerBits, szAckLatestPktNum );\n\t\t\t\t\tnMask = 0xffff;\n\t\t\t\t\tnLatestRecvSeqNum = NearestWithSameLowerBits( (int16)nLowerBits, m_statsEndToEnd.m_nNextSendSequenceNumber );\n\t\t\t\t}\n\t\t\t\tAssert( ( nLatestRecvSeqNum & nMask ) == nLowerBits );\n\n\t\t\t\t// Find the message number that is closes to \n\t\t\t\tif ( nLatestRecvSeqNum < 0 )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP decode ack latest pktnum underflow.  %llx mod %llx, next send %llx\",\n\t\t\t\t\t\t(unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ), (unsigned long long)m_statsEndToEnd.m_nNextSendSequenceNumber );\n\t\t\t\t}\n\t\t\t\tif ( std::abs( nLatestRecvSeqNum - m_statsEndToEnd.m_nNextSendSequenceNumber ) > (nMask>>2) )\n\t\t\t\t{\n\t\t\t\t\t// We really should never get close to this boundary.\n\t\t\t\t\tSpewWarningRateLimited( usecNow, \"Sender sent abs latest recv pkt number using %llx mod %llx, next send %llx\\n\",\n\t\t\t\t\t\t(unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ), (unsigned long long)m_statsEndToEnd.m_nNextSendSequenceNumber );\n\t\t\t\t}\n\t\t\t\tif ( nLatestRecvSeqNum >= m_statsEndToEnd.m_nNextSendSequenceNumber )\n\t\t\t\t{\n\t\t\t\t\tDECODE_ERROR( \"SNP decode ack latest pktnum %lld (%llx mod %llx), but next outoing packet is %lld (%llx).\",\n\t\t\t\t\t\t(long long)nLatestRecvSeqNum, (unsigned long long)nLowerBits, (unsigned long long)( nMask+1 ),\n\t\t\t\t\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (unsigned long long)m_statsEndToEnd.m_nNextSendSequenceNumber\n\t\t\t\t\t);\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld latest recv %lld\\n\",\n\t\t\t\tGetDescription(),\n\t\t\t\t(long long)nPktNum, (long long)nLatestRecvSeqNum\n\t\t\t);\n\n\t\t\t// Locate our bookkeeping for this packet, or the latest one before it\n\t\t\t// Remember, we have a sentinel with a low, invalid packet number\n\t\t\tAssert( !m_senderState.m_mapInFlightPacketsByPktNum.empty() );\n\t\t\tauto inFlightPkt = m_senderState.m_mapInFlightPacketsByPktNum.upper_bound( nLatestRecvSeqNum );\n\t\t\t--inFlightPkt;\n\t\t\tAssert( inFlightPkt->first <= nLatestRecvSeqNum );\n\n\t\t\t// Parse out delay, and process the ping\n\t\t\t{\n\t\t\t\tuint16 nPackedDelay;\n\t\t\t\tREAD_16BITU( nPackedDelay, \"ack delay\" );\n\t\t\t\tif ( nPackedDelay != 0xffff && inFlightPkt->first == nLatestRecvSeqNum && inFlightPkt->second.m_pTransport == ctx.m_pTransport )\n\t\t\t\t{\n\t\t\t\t\tSteamNetworkingMicroseconds usecDelay = SteamNetworkingMicroseconds( nPackedDelay ) << k_nAckDelayPrecisionShift;\n\t\t\t\t\tSteamNetworkingMicroseconds usecElapsed = usecNow - inFlightPkt->second.m_usecWhenSent;\n\t\t\t\t\tAssert( usecElapsed >= 0 );\n\n\t\t\t\t\t// Account for their reported delay, and calculate ping, in MS\n\t\t\t\t\tint msPing = ( usecElapsed - usecDelay ) / 1000;\n\n\t\t\t\t\t// Does this seem bogus?  (We allow a small amount of slop.)\n\t\t\t\t\t// NOTE: A malicious sender could lie about this delay, tricking us\n\t\t\t\t\t// into thinking that the real network latency is low, they are just\n\t\t\t\t\t// delaying their replies.  This actually matters, since the ping time\n\t\t\t\t\t// is an input into the rate calculation.  So we might need to\n\t\t\t\t\t// occasionally send pings that require an immediately reply, and\n\t\t\t\t\t// if those ping times seem way out of whack with the ones where they are\n\t\t\t\t\t// allowed to send a delay, take action against them.\n\t\t\t\t\tif ( msPing < -1 || msPing > 2000 )\n\t\t\t\t\t{\n\t\t\t\t\t\t// Either they are lying or some weird timer stuff is happening.\n\t\t\t\t\t\t// Either way, discard it.\n\n\t\t\t\t\t\tSpewMsgGroup( m_connectionConfig.m_LogLevel_AckRTT.Get(), \"[%s] decode pkt %lld latest recv %lld delay %lluusec INVALID ping %lldusec\\n\",\n\t\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t\t(long long)nPktNum, (long long)nLatestRecvSeqNum,\n\t\t\t\t\t\t\t(unsigned long long)usecDelay,\n\t\t\t\t\t\t\t(long long)usecElapsed\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\t\t// Clamp, if we have slop\n\t\t\t\t\t\tif ( msPing < 0 )\n\t\t\t\t\t\t\tmsPing = 0;\n\t\t\t\t\t\tProcessSNPPing( msPing, ctx );\n\n\t\t\t\t\t\t// Spew\n\t\t\t\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_AckRTT.Get(), \"[%s] decode pkt %lld latest recv %lld delay %.1fms elapsed %.1fms ping %dms\\n\",\n\t\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t\t(long long)nPktNum, (long long)nLatestRecvSeqNum,\n\t\t\t\t\t\t\t(float)(usecDelay * 1e-3 ),\n\t\t\t\t\t\t\t(float)(usecElapsed * 1e-3 ),\n\t\t\t\t\t\t\tmsPing\n\t\t\t\t\t\t);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Parse number of blocks\n\t\t\tint nBlocks = nFrameType&7;\n\t\t\tif ( nBlocks == 7 )\n\t\t\t\tREAD_8BITU( nBlocks, \"ack num blocks\" );\n\n\t\t\t// If they actually sent us any blocks, that means they are fragmented.\n\t\t\t// We should make sure and tell them to stop sending us these nacks\n\t\t\t// and move forward.\n\t\t\tif ( nBlocks > 0 )\n\t\t\t{\n\t\t\t\t// Decrease flush delay the more blocks they send us.\n\t\t\t\t// FIXME - This is not an optimal way to do this.  Forcing us to\n\t\t\t\t// ack everything is not what we want to do.  Instead, we should\n\t\t\t\t// use a separate timer for when we need to flush out a stop_waiting\n\t\t\t\t// packet!\n\t\t\t\tSteamNetworkingMicroseconds usecDelay = 250*1000 / nBlocks;\n\t\t\t\tQueueFlushAllAcks( usecNow + usecDelay );\n\t\t\t}\n\n\t\t\t// Process ack blocks, working backwards from the latest received sequence number.\n\t\t\t// Note that we have to parse all this stuff out, even if it's old news (packets older\n\t\t\t// than the stop_aiting value we sent), because we need to do that to get to the rest\n\t\t\t// of the packet.\n\t\t\tbool bAckedReliableRange = false;\n\t\t\tint64 nPktNumAckEnd = nLatestRecvSeqNum+1;\n\t\t\twhile ( nBlocks >= 0 )\n\t\t\t{\n\n\t\t\t\t// Parse out number of acks/nacks.\n\t\t\t\t// Have we parsed all the real blocks?\n\t\t\t\tint64 nPktNumAckBegin, nPktNumNackBegin;\n\t\t\t\tif ( nBlocks == 0 )\n\t\t\t\t{\n\t\t\t\t\t// Implicit block.  Everything earlier between the last\n\t\t\t\t\t// NACK and the stop_waiting value is implicitly acked!\n\t\t\t\t\tif ( nPktNumAckEnd <= m_senderState.m_nMinPktWaitingOnAck )\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\tnPktNumAckBegin = m_senderState.m_nMinPktWaitingOnAck;\n\t\t\t\t\tnPktNumNackBegin = nPktNumAckBegin;\n\t\t\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld ack last block ack begin %lld\\n\",\n\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t(long long)nPktNum, (long long)nPktNumAckBegin );\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\tuint8 nBlockHeader;\n\t\t\t\t\tREAD_8BITU( nBlockHeader, \"ack block header\" );\n\n\t\t\t\t\t// Ack count?\n\t\t\t\t\tint64 numAcks = ( nBlockHeader>> 4 ) & 7;\n\t\t\t\t\tif ( nBlockHeader & 0x80 )\n\t\t\t\t\t{\n\t\t\t\t\t\tuint64 nUpperBits;\n\t\t\t\t\t\tREAD_VARINT( nUpperBits, \"ack count upper bits\" );\n\t\t\t\t\t\tif ( nUpperBits > 100000 )\n\t\t\t\t\t\t\tDECODE_ERROR( \"Ack count of %llu<<3 is crazy\", (unsigned long long)nUpperBits );\n\t\t\t\t\t\tnumAcks |= nUpperBits<<3;\n\t\t\t\t\t}\n\t\t\t\t\tnPktNumAckBegin = nPktNumAckEnd - numAcks;\n\t\t\t\t\tif ( nPktNumAckBegin < 0 )\n\t\t\t\t\t\tDECODE_ERROR( \"Ack range underflow, end=%lld, num=%lld\", (long long)nPktNumAckEnd, (long long)numAcks );\n\n\t\t\t\t\t// Extended nack count?\n\t\t\t\t\tint64 numNacks = nBlockHeader & 7;\n\t\t\t\t\tif ( nBlockHeader & 0x08)\n\t\t\t\t\t{\n\t\t\t\t\t\tuint64 nUpperBits;\n\t\t\t\t\t\tREAD_VARINT( nUpperBits, \"nack count upper bits\" );\n\t\t\t\t\t\tif ( nUpperBits > 100000 )\n\t\t\t\t\t\t\tDECODE_ERROR( \"Nack count of %llu<<3 is crazy\", nUpperBits );\n\t\t\t\t\t\tnumNacks |= nUpperBits<<3;\n\t\t\t\t\t}\n\t\t\t\t\tnPktNumNackBegin = nPktNumAckBegin - numNacks;\n\t\t\t\t\tif ( nPktNumNackBegin < 0 )\n\t\t\t\t\t\tDECODE_ERROR( \"Nack range underflow, end=%lld, num=%lld\", (long long)nPktNumAckBegin, (long long)numAcks );\n\n\t\t\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld nack [%lld,%lld) ack [%lld,%lld)\\n\",\n\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t(long long)nPktNum,\n\t\t\t\t\t\t(long long)nPktNumNackBegin, (long long)( nPktNumNackBegin + numNacks ),\n\t\t\t\t\t\t(long long)nPktNumAckBegin, (long long)( nPktNumAckBegin + numAcks )\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\t// Process acks first.\n\t\t\t\tAssert( nPktNumAckBegin >= 0 );\n\t\t\t\twhile ( inFlightPkt->first >= nPktNumAckBegin )\n\t\t\t\t{\n\t\t\t\t\tAssert( inFlightPkt->first < nPktNumAckEnd );\n\n\t\t\t\t\t// Scan reliable segments, and see if any are marked for retry or are in flight\n\t\t\t\t\tfor ( const SNPRange_t &relRange: inFlightPkt->second.m_vecReliableSegments )\n\t\t\t\t\t{\n\n\t\t\t\t\t\t// If range is present, it should be in only one of these two tables.\n\t\t\t\t\t\tif ( m_senderState.m_listInFlightReliableRange.erase( relRange ) == 0 )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif ( m_senderState.m_listReadyRetryReliableRange.erase( relRange ) > 0 )\n\t\t\t\t\t\t\t{\n\n\t\t\t\t\t\t\t\t// When we put stuff into the reliable retry list, we mark it as pending again.\n\t\t\t\t\t\t\t\t// But now it's acked, so it's no longer pending, even though we didn't send it.\n\t\t\t\t\t\t\t\tm_senderState.m_cbPendingReliable -= int( relRange.length() );\n\t\t\t\t\t\t\t\tAssert( m_senderState.m_cbPendingReliable >= 0 );\n\n\t\t\t\t\t\t\t\tbAckedReliableRange = true;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tbAckedReliableRange = true;\n\t\t\t\t\t\t\tAssert( m_senderState.m_listReadyRetryReliableRange.count( relRange ) == 0 );\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Check if this was the next packet we were going to timeout, then advance\n\t\t\t\t\t// pointer.  This guy didn't timeout.\n\t\t\t\t\tif ( inFlightPkt == m_senderState.m_itNextInFlightPacketToTimeout )\n\t\t\t\t\t\t++m_senderState.m_itNextInFlightPacketToTimeout;\n\n\t\t\t\t\t// No need to track this anymore, remove from our table\n\t\t\t\t\tinFlightPkt = m_senderState.m_mapInFlightPacketsByPktNum.erase( inFlightPkt );\n\t\t\t\t\t--inFlightPkt;\n\t\t\t\t\tm_senderState.MaybeCheckInFlightPacketMap();\n\t\t\t\t}\n\n\t\t\t\t// Ack of in-flight end-to-end stats?\n\t\t\t\tif ( nPktNumAckBegin <= m_statsEndToEnd.m_pktNumInFlight && m_statsEndToEnd.m_pktNumInFlight < nPktNumAckEnd )\n\t\t\t\t\tm_statsEndToEnd.InFlightPktAck( usecNow );\n\n\t\t\t\t// Process nacks.\n\t\t\t\tAssert( nPktNumNackBegin >= 0 );\n\t\t\t\twhile ( inFlightPkt->first >= nPktNumNackBegin )\n\t\t\t\t{\n\t\t\t\t\tAssert( inFlightPkt->first < nPktNumAckEnd );\n\t\t\t\t\tSNP_SenderProcessPacketNack( inFlightPkt->first, inFlightPkt->second, \"NACK\" );\n\n\t\t\t\t\t// We'll keep the record on hand, though, in case an ACK comes in\n\t\t\t\t\t--inFlightPkt;\n\t\t\t\t}\n\n\t\t\t\t// Continue on to the the next older block\n\t\t\t\tnPktNumAckEnd = nPktNumNackBegin;\n\t\t\t\t--nBlocks;\n\t\t\t}\n\n\t\t\t// Should we check for discarding reliable messages we are keeping around in case\n\t\t\t// of retransmission, since we know now that they were delivered?\n\t\t\tif ( bAckedReliableRange )\n\t\t\t{\n\t\t\t\tm_senderState.RemoveAckedReliableMessageFromUnackedList();\n\n\t\t\t\t// Spew where we think the peer is decoding the reliable stream\n\t\t\t\tif ( nLogLevelPacketDecode >= k_ESteamNetworkingSocketsDebugOutputType_Debug )\n\t\t\t\t{\n\n\t\t\t\t\tint64 nPeerReliablePos = m_senderState.m_nReliableStreamPos;\n\t\t\t\t\tif ( !m_senderState.m_listInFlightReliableRange.empty() )\n\t\t\t\t\t\tnPeerReliablePos = std::min( nPeerReliablePos, m_senderState.m_listInFlightReliableRange.begin()->first.m_nBegin );\n\t\t\t\t\tif ( !m_senderState.m_listReadyRetryReliableRange.empty() )\n\t\t\t\t\t\tnPeerReliablePos = std::min( nPeerReliablePos, m_senderState.m_listReadyRetryReliableRange.begin()->first.m_nBegin );\n\n\t\t\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld peer reliable pos = %lld\\n\",\n\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t(long long)nPktNum, (long long)nPeerReliablePos );\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check if any of this was new info, then advance our stop_waiting value.\n\t\t\tif ( nLatestRecvSeqNum > m_senderState.m_nMinPktWaitingOnAck )\n\t\t\t{\n\t\t\t\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s]   updating min_waiting_on_ack %lld -> %lld\\n\",\n\t\t\t\t\tGetDescription(),\n\t\t\t\t\t(long long)m_senderState.m_nMinPktWaitingOnAck, (long long)nLatestRecvSeqNum );\n\t\t\t\tm_senderState.m_nMinPktWaitingOnAck = nLatestRecvSeqNum;\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\tDECODE_ERROR( \"Invalid SNP frame lead byte 0x%02x\", nFrameType );\n\t\t}\n\t}\n\n\t// Should we record that we received it?\n\tif ( bInhibitMarkReceived )\n\t{\n\t\t// Something really odd.  High packet loss / fragmentation.\n\t\t// Potentially the peer is being abusive and we need\n\t\t// to protect ourselves.\n\t\t//\n\t\t// Act as if the packet was dropped.  This will cause the\n\t\t// peer's sender logic to interpret this as additional packet\n\t\t// loss and back off.  That's a feature, not a bug.\n\t}\n\telse\n\t{\n\n\t\t// Update structures needed to populate our ACKs.\n\t\t// If we received reliable data now, then schedule an ack\n\t\tbool bScheduleAck = nDecodeReliablePos > 0;\n\t\tSNP_RecordReceivedPktNum( nPktNum, usecNow, bScheduleAck );\n\t}\n\n\t// Track end-to-end flow.  Even if we decided to tell our peer that\n\t// we did not receive this, we want our own stats to reflect\n\t// that we did.  (And we want to be able to quickly reject a\n\t// packet with this same number.)\n\t//\n\t// Also, note that order of operations is important.  This call must\n\t// happen after the SNP_RecordReceivedPktNum call above\n\tm_statsEndToEnd.TrackProcessSequencedPacket( nPktNum, usecNow, usecTimeSinceLast );\n\n\t// Packet can be processed further\n\treturn true;\n\n\t// Make sure these don't get used beyond where we intended them to get used\n\t#undef DECODE_ERROR\n\t#undef EXPECT_BYTES\n\t#undef READ_8BITU\n\t#undef READ_16BITU\n\t#undef READ_24BITU\n\t#undef READ_32BITU\n\t#undef READ_64BITU\n\t#undef READ_VARINT\n\t#undef READ_SEGMENT_DATA_SIZE\n}\n\nvoid CSteamNetworkConnectionBase::SNP_SenderProcessPacketNack( int64 nPktNum, SNPInFlightPacket_t &pkt, const char *pszDebug )\n{\n\n\t// Did we already treat the packet as dropped (implicitly or explicitly)?\n\tif ( pkt.m_bNack )\n\t\treturn;\n\n\t// Mark as dropped\n\tpkt.m_bNack = true;\n\n\t// Is this in-flight stats we were expecting an ack for?\n\tif ( m_statsEndToEnd.m_pktNumInFlight == nPktNum )\n\t\tm_statsEndToEnd.InFlightPktTimeout();\n\n\t// Scan reliable segments\n\tfor ( const SNPRange_t &relRange: pkt.m_vecReliableSegments )\n\t{\n\n\t\t// Marked as in-flight?\n\t\tauto inFlightRange = m_senderState.m_listInFlightReliableRange.find( relRange );\n\t\tif ( inFlightRange == m_senderState.m_listInFlightReliableRange.end() )\n\t\t\tcontinue;\n\n\t\tSpewMsgGroup( m_connectionConfig.m_LogLevel_PacketDecode.Get(), \"[%s] pkt %lld %s, queueing retry of reliable range [%lld,%lld)\\n\", \n\t\t\tGetDescription(),\n\t\t\tnPktNum,\n\t\t\tpszDebug,\n\t\t\trelRange.m_nBegin, relRange.m_nEnd );\n\n\t\t// The ready-to-retry list counts towards the \"pending\" stat\n\t\tm_senderState.m_cbPendingReliable += int( relRange.length() );\n\n\t\t// Move it to the ready for retry list!\n\t\t// if shouldn't already be there!\n\t\tAssert( m_senderState.m_listReadyRetryReliableRange.count( relRange ) == 0 );\n\t\tm_senderState.m_listReadyRetryReliableRange[ inFlightRange->first ] = inFlightRange->second;\n\t\tm_senderState.m_listInFlightReliableRange.erase( inFlightRange );\n\t}\n}\n\nSteamNetworkingMicroseconds CSteamNetworkConnectionBase::SNP_SenderCheckInFlightPackets( SteamNetworkingMicroseconds usecNow )\n{\n\t// Fast path for nothing in flight.\n\tm_senderState.MaybeCheckInFlightPacketMap();\n\tif ( m_senderState.m_mapInFlightPacketsByPktNum.size() <= 1 )\n\t{\n\t\tAssert( m_senderState.m_itNextInFlightPacketToTimeout == m_senderState.m_mapInFlightPacketsByPktNum.end() );\n\t\treturn k_nThinkTime_Never;\n\t}\n\tAssert( m_senderState.m_mapInFlightPacketsByPktNum.begin()->first < 0 );\n\n\tSteamNetworkingMicroseconds usecNextRetry = k_nThinkTime_Never;\n\n\t// Process retry timeout.  Here we use a shorter timeout to trigger retry\n\t// than we do to totally forgot about the packet, in case an ack comes in late,\n\t// we can take advantage of it.\n\tSteamNetworkingMicroseconds usecRTO = m_statsEndToEnd.CalcSenderRetryTimeout();\n\twhile ( m_senderState.m_itNextInFlightPacketToTimeout != m_senderState.m_mapInFlightPacketsByPktNum.end() )\n\t{\n\t\tAssert( m_senderState.m_itNextInFlightPacketToTimeout->first > 0 );\n\n\t\t// If already nacked, then no use waiting on it, just skip it\n\t\tif ( !m_senderState.m_itNextInFlightPacketToTimeout->second.m_bNack )\n\t\t{\n\n\t\t\t// Not yet time to give up?\n\t\t\tSteamNetworkingMicroseconds usecRetryPkt = m_senderState.m_itNextInFlightPacketToTimeout->second.m_usecWhenSent + usecRTO;\n\t\t\tif ( usecRetryPkt > usecNow )\n\t\t\t{\n\t\t\t\tusecNextRetry = usecRetryPkt;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// Mark as dropped, and move any reliable contents into the\n\t\t\t// retry list.\n\t\t\tSNP_SenderProcessPacketNack( m_senderState.m_itNextInFlightPacketToTimeout->first, m_senderState.m_itNextInFlightPacketToTimeout->second, \"AckTimeout\" );\n\t\t}\n\n\t\t// Advance to next packet waiting to timeout\n\t\t++m_senderState.m_itNextInFlightPacketToTimeout;\n\t}\n\n\t// Skip the sentinel\n\tauto inFlightPkt = m_senderState.m_mapInFlightPacketsByPktNum.begin();\n\tAssert( inFlightPkt->first < 0 );\n\t++inFlightPkt;\n\n\t// Expire old packets (all of these should have been marked as nacked)\n\tSteamNetworkingMicroseconds usecWhenExpiry = usecNow - usecRTO*2;\n\tfor (;;)\n\t{\n\t\tif ( inFlightPkt->second.m_usecWhenSent > usecWhenExpiry )\n\t\t\tbreak;\n\n\t\t// Should have already been timed out by the code above\n\t\tAssert( inFlightPkt->second.m_bNack );\n\t\tAssert( inFlightPkt != m_senderState.m_itNextInFlightPacketToTimeout );\n\n\t\t// Expire it, advance to the next one\n\t\tinFlightPkt = m_senderState.m_mapInFlightPacketsByPktNum.erase( inFlightPkt );\n\t\tAssert( !m_senderState.m_mapInFlightPacketsByPktNum.empty() );\n\n\t\t// Bail if we've hit the end of the nacks\n\t\tif ( inFlightPkt == m_senderState.m_mapInFlightPacketsByPktNum.end() )\n\t\t\tbreak;\n\t}\n\n\t// Make sure we didn't hose data structures\n\tm_senderState.MaybeCheckInFlightPacketMap();\n\n\t// Return time when we really need to check back in again.\n\t// We don't wake up early just to expire old nacked packets,\n\t// there is no urgency or value in doing that, we can clean\n\t// those up whenever.  We only make sure and wake up when we\n\t// need to retry.  (And we need to make sure we don't let\n\t// our list of old packets grow unnecessarily long.)\n\treturn usecNextRetry;\n}\n\nstruct EncodedSegment\n{\n\tstatic constexpr int k_cbMaxHdr = 16; \n\tuint8 m_hdr[ k_cbMaxHdr ];\n\tint m_cbHdr; // Doesn't include any size byte\n\tCSteamNetworkingMessage *m_pMsg;\n\tint m_cbSegSize;\n\tint m_nOffset;\n\n\tinline void SetupReliable( CSteamNetworkingMessage *pMsg, int64 nBegin, int64 nEnd, int64 nLastReliableStreamPosEnd )\n\t{\n\t\tAssert( nBegin < nEnd );\n\t\t//Assert( nBegin + k_cbSteamNetworkingSocketsMaxReliableMessageSegment >= nEnd ); // Max sure we don't exceed max segment size\n\t\tAssert( pMsg->SNPSend_IsReliable() );\n\n\t\t// Start filling out the header with the top three bits = 010,\n\t\t// identifying this as a reliable segment\n\t\tuint8 *pHdr = m_hdr;\n\t\t*(pHdr++) = 0x40;\n\n\t\t// First reliable segment in the message?\n\t\tif ( nLastReliableStreamPosEnd == 0 )\n\t\t{\n\t\t\t// Always use 48-byte offsets, to make sure we are exercising the worst case.\n\t\t\t// Later we should optimize this\n\t\t\tm_hdr[0] |= 0x10;\n\t\t\t*(uint16*)pHdr = LittleWord( uint16( nBegin ) ); pHdr += 2;\n\t\t\t*(uint32*)pHdr = LittleDWord( uint32( nBegin>>16 ) ); pHdr += 4;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Offset from end of previous reliable segment in the same packet\n\t\t\tAssert( nBegin >= nLastReliableStreamPosEnd );\n\t\t\tint64 nOffset = nBegin - nLastReliableStreamPosEnd;\n\t\t\tif ( nOffset == 0)\n\t\t\t{\n\t\t\t\t// Nothing to encode\n\t\t\t}\n\t\t\telse if ( nOffset < 0x100 )\n\t\t\t{\n\t\t\t\tm_hdr[0] |= (1<<3);\n\t\t\t\t*pHdr = uint8( nOffset ); pHdr += 1;\n\t\t\t}\n\t\t\telse if ( nOffset < 0x10000 )\n\t\t\t{\n\t\t\t\tm_hdr[0] |= (2<<3);\n\t\t\t\t*(uint16*)pHdr = LittleWord( uint16( nOffset ) ); pHdr += 2;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tm_hdr[0] |= (3<<3);\n\t\t\t\t*(uint32*)pHdr = LittleDWord( uint32( nOffset ) ); pHdr += 4;\n\t\t\t}\n\t\t}\n\n\t\tm_cbHdr = pHdr-m_hdr;\n\n\t\t// Size of the segment.  We assume that the whole things fits for now,\n\t\t// even though it might need to get truncated\n\t\tint cbSegData = nEnd - nBegin;\n\t\tAssert( cbSegData > 0 );\n\t\tAssert( nBegin >= pMsg->SNPSend_ReliableStreamPos() );\n\t\tAssert( nEnd <= pMsg->SNPSend_ReliableStreamPos() + pMsg->m_cbSize );\n\n\t\tm_pMsg = pMsg;\n\t\tm_nOffset = nBegin - pMsg->SNPSend_ReliableStreamPos();\n\t\tm_cbSegSize = cbSegData;\n\t}\n\n\tinline void SetupUnreliable( CSteamNetworkingMessage *pMsg, int nOffset, int64 nLastMsgNum )\n\t{\n\n\t\t// Start filling out the header with the top two bits = 00,\n\t\t// identifying this as an unreliable segment\n\t\tuint8 *pHdr = m_hdr;\n\t\t*(pHdr++) = 0x00;\n\n\t\t// Encode message number.  First unreliable message?\n\t\tif ( nLastMsgNum == 0 )\n\t\t{\n\n\t\t\t// Just always encode message number with 32 bits for now,\n\t\t\t// to make sure we are hitting the worst case.  We can optimize this later\n\t\t\t*(uint32*)pHdr = LittleDWord( (uint32)pMsg->m_nMessageNumber ); pHdr += 4;\n\t\t\tm_hdr[0] |= 0x10;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Subsequent unreliable message\n\t\t\tAssert( pMsg->m_nMessageNumber > nLastMsgNum );\n\t\t\tuint64 nDelta = pMsg->m_nMessageNumber - nLastMsgNum;\n\t\t\tif ( nDelta == 1 )\n\t\t\t{\n\t\t\t\t// Common case of sequential messages.  Don't encode any offset\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tpHdr = SerializeVarInt( pHdr, nDelta, m_hdr+k_cbMaxHdr );\n\t\t\t\tAssert( pHdr ); // Overflow shouldn't be possible\n\t\t\t\tm_hdr[0] |= 0x10;\n\t\t\t}\n\t\t}\n\n\t\t// Encode segment offset within message, except in the special common case of the first segment\n\t\tif ( nOffset > 0 )\n\t\t{\n\t\t\tpHdr = SerializeVarInt( pHdr, (uint32)( nOffset ), m_hdr+k_cbMaxHdr );\n\t\t\tAssert( pHdr ); // Overflow shouldn't be possible\n\t\t\tm_hdr[0] |= 0x08;\n\t\t}\n\n\t\tm_cbHdr = pHdr-m_hdr;\n\n\t\t// Size of the segment.  We assume that the whole things fits for now, event hough it might ned to get truncated\n\t\tint cbSegData = pMsg->m_cbSize - nOffset;\n\t\tAssert( cbSegData > 0 || ( cbSegData == 0 && pMsg->m_cbSize == 0 ) ); // We should only send zero-byte segments if the message itself is zero bytes.  (Which is legitimate!)\n\n\t\tm_pMsg = pMsg;\n\t\tm_cbSegSize = cbSegData;\n\t\tm_nOffset = nOffset;\n\t}\n\n};\n\ntemplate <typename T, typename L>\ninline bool HasOverlappingRange( const SNPRange_t &range, const std::map<SNPRange_t,T,L> &map )\n{\n\tauto l = map.lower_bound( range );\n\tif ( l != map.end() )\n\t{\n\t\tAssert( l->first.m_nBegin >= range.m_nBegin );\n\t\tif ( l->first.m_nBegin < range.m_nEnd )\n\t\t\treturn true;\n\t}\n\tauto u = map.upper_bound( range );\n\tif ( u != map.end() )\n\t{\n\t\tAssert( range.m_nBegin < u->first.m_nBegin );\n\t\tif ( range.m_nEnd > l->first.m_nBegin )\n\t\t\treturn true;\n\t}\n\n\treturn false;\n}\n\nbool CSteamNetworkConnectionBase::SNP_SendPacket( CConnectionTransport *pTransport, SendPacketContext_t &ctx )\n{\n\t// Check calling conditions, and don't crash\n\tif ( !BStateIsActive() || m_senderState.m_mapInFlightPacketsByPktNum.empty() || !pTransport )\n\t{\n\t\tAssert( BStateIsActive() );\n\t\tAssert( !m_senderState.m_mapInFlightPacketsByPktNum.empty() );\n\t\tAssert( pTransport );\n\t\treturn false;\n\t}\n\n\tSteamNetworkingMicroseconds usecNow = ctx.m_usecNow;\n\n\t// Get max size of plaintext we could send.\n\t// AES-GCM has a fixed size overhead, for the tag.\n\t// FIXME - but what we if we aren't using AES-GCM!\n\tint cbMaxPlaintextPayload = std::max( 0, ctx.m_cbMaxEncryptedPayload-k_cbSteamNetwokingSocketsEncrytionTagSize );\n\tcbMaxPlaintextPayload = std::min( cbMaxPlaintextPayload, m_cbMaxPlaintextPayloadSend );\n\n\tuint8 payload[ k_cbSteamNetworkingSocketsMaxPlaintextPayloadSend ];\n\tuint8 *pPayloadEnd = payload + cbMaxPlaintextPayload;\n\tuint8 *pPayloadPtr = payload;\n\n\tint nLogLevelPacketDecode = m_connectionConfig.m_LogLevel_PacketDecode.Get();\n\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s] encode pkt %lld\",\n\t\tGetDescription(),\n\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber );\n\n\t// Stop waiting frame\n\tpPayloadPtr = SNP_SerializeStopWaitingFrame( pPayloadPtr, pPayloadEnd, usecNow );\n\tif ( pPayloadPtr == nullptr )\n\t\treturn false;\n\n\t// Get list of ack blocks we might want to serialize, and which\n\t// of those acks we really want to flush out right now.\n\tSNPAckSerializerHelper ackHelper;\n\tSNP_GatherAckBlocks( ackHelper, usecNow );\n\n\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\tPacketSendLog *pLog = push_back_get_ptr( m_vecSendLog );\n\t\tpLog->m_usecTime = usecNow;\n\t\tpLog->m_cbPendingReliable = m_senderState.m_cbPendingReliable;\n\t\tpLog->m_cbPendingUnreliable = m_senderState.m_cbPendingUnreliable;\n\t\tpLog->m_nPacketGaps = len( m_receiverState.m_mapPacketGaps )-1;\n\t\tpLog->m_nAckBlocksNeeded = ackHelper.m_nBlocksNeedToAck;\n\t\tpLog->m_nPktNumNextPendingAck = m_receiverState.m_itPendingAck->first;\n\t\tpLog->m_usecNextPendingAckTime = m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior;\n\t\tpLog->m_fltokens = m_senderState.m_flTokenBucket;\n\t\tpLog->m_nMaxPktRecv = m_statsEndToEnd.m_nMaxRecvPktNum;\n\t\tpLog->m_nMinPktNumToSendAcks = m_receiverState.m_nMinPktNumToSendAcks;\n\t\tpLog->m_nReliableSegmentsRetry = 0;\n\t\tpLog->m_nSegmentsSent = 0;\n\t#endif\n\n\t// How much space do we need to reserve for acks?\n\tint cbReserveForAcks = 0;\n\tif ( m_statsEndToEnd.m_nMaxRecvPktNum > 0 )\n\t{\n\t\tint cbPayloadRemainingForAcks = pPayloadEnd - pPayloadPtr;\n\t\tif ( cbPayloadRemainingForAcks >= SNPAckSerializerHelper::k_cbHeaderSize )\n\t\t{\n\t\t\tcbReserveForAcks = SNPAckSerializerHelper::k_cbHeaderSize;\n\t\t\tint n = 3; // Assume we want to send a handful\n\t\t\tn = std::max( n, ackHelper.m_nBlocksNeedToAck ); // But if we have blocks that need to be flushed now, try to fit all of them\n\t\t\tn = std::min( n, ackHelper.m_nBlocks ); // Cannot send more than we actually have\n\t\t\twhile ( n > 0 )\n\t\t\t{\n\t\t\t\t--n;\n\t\t\t\tif ( ackHelper.m_arBlocks[n].m_cbTotalEncodedSize <= cbPayloadRemainingForAcks )\n\t\t\t\t{\n\t\t\t\t\tcbReserveForAcks = ackHelper.m_arBlocks[n].m_cbTotalEncodedSize;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check if we are actually going to send data in this packet\n\tif (\n\t\tm_senderState.m_flTokenBucket < 0.0 // No bandwidth available.  (Presumably this is a relatively rare out-of-band connectivity check, etc)  FIXME should we use a different token bucket per transport?\n\t\t|| !BStateIsConnectedForWirePurposes() // not actually in a connection stats where we should be sending real data yet\n\t\t|| pTransport != m_pTransport // transport is not the selected transport\n\t) {\n\n\t\t// Serialize some acks, if we want to\n\t\tif ( cbReserveForAcks > 0 )\n\t\t{\n\t\t\t// But if we're going to send any acks, then try to send as many\n\t\t\t// as possible, not just the bare minimum.\n\t\t\tpPayloadPtr = SNP_SerializeAckBlocks( ackHelper, pPayloadPtr, pPayloadEnd, usecNow );\n\t\t\tif ( pPayloadPtr == nullptr )\n\t\t\t\treturn false; // bug!  Abort\n\n\t\t\t// We don't need to serialize any more acks\n\t\t\tcbReserveForAcks = 0;\n\t\t}\n\n\t\t// Truncate the buffer, don't try to fit any data\n\t\t// !SPEED! - instead of doing this, we could just put all of the segment code below\n\t\t// in an else() block.\n\t\tpPayloadEnd = pPayloadPtr;\n\t}\n\n\tint64 nLastReliableStreamPosEnd = 0;\n\tint cbBytesRemainingForSegments = pPayloadEnd - pPayloadPtr - cbReserveForAcks;\n\tvstd::small_vector<EncodedSegment,8> vecSegments;\n\n\t// If we need to retry any reliable data, then try to put that in first.\n\t// Bail if we only have a tiny sliver of data left\n\twhile ( !m_senderState.m_listReadyRetryReliableRange.empty() && cbBytesRemainingForSegments > 2 )\n\t{\n\t\tauto h = m_senderState.m_listReadyRetryReliableRange.begin();\n\n\t\t// Start a reliable segment\n\t\tEncodedSegment &seg = *push_back_get_ptr( vecSegments );\n\t\tseg.SetupReliable( h->second, h->first.m_nBegin, h->first.m_nEnd, nLastReliableStreamPosEnd );\n\t\tint cbSegTotalWithoutSizeField = seg.m_cbHdr + seg.m_cbSegSize;\n\t\tif ( cbSegTotalWithoutSizeField > cbBytesRemainingForSegments )\n\t\t{\n\t\t\t// This one won't fit.\n\t\t\tvecSegments.pop_back();\n\n\t\t\t// FIXME If there's a decent amount of space left in this packet, it might\n\t\t\t// be worthwhile to send what we can.  Right now, once we send a reliable range,\n\t\t\t// we always retry exactly that range.  The only complication would be when we\n\t\t\t// receive an ack, we would need to be aware that the acked ranges might not\n\t\t\t// exactly match up with the ranges that we sent.  Actually this shouldn't\n\t\t\t// be that big of a deal.  But for now let's always retry the exact ranges that\n\t\t\t// things got chopped up during the initial send.\n\n\t\t\t// This should only happen if we have already fit some data in, or\n\t\t\t// the caller asked us to see what we could squeeze into a smaller\n\t\t\t// packet, or we need to serialized a bunch of acks.  If this is an\n\t\t\t// opportunity to fill a normal packet and we fail on the first segment,\n\t\t\t// we will never make progress and we are hosed!\n\t\t\tAssertMsg2(\n\t\t\t\tnLastReliableStreamPosEnd > 0\n\t\t\t\t|| cbMaxPlaintextPayload < m_cbMaxPlaintextPayloadSend\n\t\t\t\t|| ( cbReserveForAcks > 15 && ackHelper.m_nBlocksNeedToAck > 8 ),\n\t\t\t\t\"We cannot fit reliable segment, need %d bytes, only %d remaining\", cbSegTotalWithoutSizeField, cbBytesRemainingForSegments\n\t\t\t);\n\n\t\t\t// Don't try to put more stuff in the packet, even if we have room.  We're\n\t\t\t// already having to retry, so this data is already delayed.  If we skip ahead\n\t\t\t// and put more into this packet, that's just extending the time until we can send\n\t\t\t// the next packet.\n\t\t\tbreak;\n\t\t}\n\n\t\t// If we only have a sliver left, then don't try to fit any more.\n\t\tcbBytesRemainingForSegments -= cbSegTotalWithoutSizeField;\n\t\tnLastReliableStreamPosEnd = h->first.m_nEnd;\n\n\t\t// Assume for now this won't be the last segment, in which case we will also need\n\t\t// the byte for the size field.\n\t\t// NOTE: This might cause cbPayloadBytesRemaining to go negative by one!  I know\n\t\t// that seems weird, but it actually keeps the logic below simpler.\n\t\tcbBytesRemainingForSegments -= 1;\n\n\t\t// Remove from retry list.  (We'll add to the in-flight list later)\n\t\tm_senderState.m_listReadyRetryReliableRange.erase( h );\n\n\t\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\t\t++pLog->m_nReliableSegmentsRetry;\n\t\t#endif\n\t}\n\n\t// Did we retry everything we needed to?  If not, then don't try to send new stuff,\n\t// before we send those retries.\n\tif ( m_senderState.m_listReadyRetryReliableRange.empty() )\n\t{\n\n\t\t// OK, check the outgoing messages, and send as much stuff as we can cram in there\n\t\tint64 nLastMsgNum = 0;\n\t\twhile ( cbBytesRemainingForSegments > 4 )\n\t\t{\n\t\t\tif ( m_senderState.m_messagesQueued.empty() )\n\t\t\t{\n\t\t\t\tm_senderState.m_cbCurrentSendMessageSent = 0;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tCSteamNetworkingMessage *pSendMsg = m_senderState.m_messagesQueued.m_pFirst;\n\t\t\tAssert( m_senderState.m_cbCurrentSendMessageSent < pSendMsg->m_cbSize );\n\n\t\t\t// Start a new segment\n\t\t\tEncodedSegment &seg = *push_back_get_ptr( vecSegments );\n\n\t\t\t// Reliable?\n\t\t\tbool bLastSegment = false;\n\t\t\tif ( pSendMsg->SNPSend_IsReliable() )\n\t\t\t{\n\n\t\t\t\t// FIXME - Coalesce adjacent reliable messages ranges\n\n\t\t\t\tint64 nBegin = pSendMsg->SNPSend_ReliableStreamPos() + m_senderState.m_cbCurrentSendMessageSent;\n\n\t\t\t\t// How large would we like this segment to be,\n\t\t\t\t// ignoring how much space is left in the packet.\n\t\t\t\t// We limit the size of reliable segments, to make\n\t\t\t\t// sure that we don't make an excessively large\n\t\t\t\t// one and then have a hard time retrying it later.\n\t\t\t\tint cbDesiredSegSize = pSendMsg->m_cbSize - m_senderState.m_cbCurrentSendMessageSent;\n\t\t\t\tif ( cbDesiredSegSize > m_cbMaxReliableMessageSegment )\n\t\t\t\t{\n\t\t\t\t\tcbDesiredSegSize = m_cbMaxReliableMessageSegment;\n\t\t\t\t\tbLastSegment = true;\n\t\t\t\t}\n\n\t\t\t\tint64 nEnd = nBegin + cbDesiredSegSize;\n\t\t\t\tseg.SetupReliable( pSendMsg, nBegin, nEnd, nLastReliableStreamPosEnd );\n\n\t\t\t\t// If we encode subsequent \n\t\t\t\tnLastReliableStreamPosEnd = nEnd;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tseg.SetupUnreliable( pSendMsg, m_senderState.m_cbCurrentSendMessageSent, nLastMsgNum );\n\t\t\t}\n\n\t\t\t// Can't fit the whole thing?\n\t\t\tif ( bLastSegment || seg.m_cbHdr + seg.m_cbSegSize > cbBytesRemainingForSegments )\n\t\t\t{\n\n\t\t\t\t// Check if we have enough room to send anything worthwhile.\n\t\t\t\t// Don't send really tiny silver segments at the very end of a packet.  That sort of fragmentation\n\t\t\t\t// just makes it more likely for something to drop.  Our goal is to reduce the number of packets\n\t\t\t\t// just as much as the total number of bytes, so if we're going to have to send another packet\n\t\t\t\t// anyway, don't send a little sliver of a message at the beginning of a packet\n\t\t\t\t// We need to finish the header by this point if we're going to send anything\n\t\t\t\tint cbMinSegDataSizeToSend = std::min( 16, seg.m_cbSegSize );\n\t\t\t\tif ( seg.m_cbHdr + cbMinSegDataSizeToSend > cbBytesRemainingForSegments )\n\t\t\t\t{\n\t\t\t\t\t// Don't send this segment now.\n\t\t\t\t\tvecSegments.pop_back();\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\t\t\t\t++pLog->m_nSegmentsSent;\n\t\t\t\t#endif\n\n\t\t\t\t// Truncate, and leave the message in the queue\n\t\t\t\tseg.m_cbSegSize = std::min( seg.m_cbSegSize, cbBytesRemainingForSegments - seg.m_cbHdr );\n\t\t\t\tm_senderState.m_cbCurrentSendMessageSent += seg.m_cbSegSize;\n\t\t\t\tAssert( m_senderState.m_cbCurrentSendMessageSent < pSendMsg->m_cbSize );\n\t\t\t\tcbBytesRemainingForSegments -= seg.m_cbHdr + seg.m_cbSegSize;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// The whole message fit (perhaps exactly, without the size byte)\n\t\t\t// Reset send pointer for the next message\n\t\t\tAssert( m_senderState.m_cbCurrentSendMessageSent + seg.m_cbSegSize == pSendMsg->m_cbSize );\n\t\t\tm_senderState.m_cbCurrentSendMessageSent = 0;\n\n\t\t\t// Remove message from queue,w e have transfered ownership to the segment and will\n\t\t\t// dispose of the message when we serialize the segments\n\t\t\tm_senderState.m_messagesQueued.pop_front();\n\n\t\t\t// Consume payload bytes\n\t\t\tcbBytesRemainingForSegments -= seg.m_cbHdr + seg.m_cbSegSize;\n\n\t\t\t// Assume for now this won't be the last segment, in which case we will also need the byte for the size field.\n\t\t\t// NOTE: This might cause cbPayloadBytesRemaining to go negative by one!  I know that seems weird, but it actually\n\t\t\t// keeps the logic below simpler.\n\t\t\tcbBytesRemainingForSegments -= 1;\n\n\t\t\t// Update various accounting, depending on reliable or unreliable\n\t\t\tif ( pSendMsg->SNPSend_IsReliable() )\n\t\t\t{\n\t\t\t\t// Reliable segments advance the current message number.\n\t\t\t\t// NOTE: If we coalesce adjacent reliable segments, this will probably need to be adjusted\n\t\t\t\tif ( nLastMsgNum > 0 )\n\t\t\t\t\t++nLastMsgNum;\n\n\t\t\t\t// Go ahead and add us to the end of the list of unacked messages\n\t\t\t\tm_senderState.m_unackedReliableMessages.push_back( seg.m_pMsg );\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tnLastMsgNum = pSendMsg->m_nMessageNumber;\n\n\t\t\t\t// Set the \"This is the last segment in this message\" header bit\n\t\t\t\tseg.m_hdr[0] |= 0x20;\n\t\t\t}\n\t\t}\n\t}\n\n\t// Now we know how much space we need for the segments.  If we asked to reserve\n\t// space for acks, we should have at least that much.  But we might have more.\n\t// Serialize acks, as much as will fit.  If we are badly fragmented and we have\n\t// the space, it's better to keep sending acks over and over to try to clear\n\t// it out as fast as possible.\n\tif ( cbReserveForAcks > 0 )\n\t{\n\n\t\t// If we didn't use all the space for data, that's more we could use for acks\n\t\tint cbAvailForAcks = cbReserveForAcks;\n\t\tif ( cbBytesRemainingForSegments > 0 )\n\t\t\tcbAvailForAcks += cbBytesRemainingForSegments;\n\t\tuint8 *pAckEnd = pPayloadPtr + cbAvailForAcks;\n\t\tAssert( pAckEnd <= pPayloadEnd );\n\n\t\tuint8 *pAfterAcks = SNP_SerializeAckBlocks( ackHelper, pPayloadPtr, pAckEnd, usecNow );\n\t\tif ( pAfterAcks == nullptr )\n\t\t\treturn false; // bug!  Abort\n\n\t\tint cbAckBytesWritten = pAfterAcks - pPayloadPtr;\n\t\tif ( cbAckBytesWritten > cbReserveForAcks )\n\t\t{\n\t\t\t// We used more space for acks than was strictly reserved.\n\t\t\t// Update space remaining for data segments.  We should have the room!\n\t\t\tcbBytesRemainingForSegments -= ( cbAckBytesWritten - cbReserveForAcks );\n\t\t\tAssert( cbBytesRemainingForSegments >= -1 ); // remember we might go over by one byte\n\t\t}\n\t\telse\n\t\t{\n\t\t\tAssert( cbAckBytesWritten == cbReserveForAcks ); // The code above reserves space very carefuly.  So if we reserve it, we should fill it!\n\t\t}\n\n\t\tpPayloadPtr = pAfterAcks;\n\t}\n\n\t// We are gonna send a packet.  Start filling out an entry so that when it's acked (or nacked)\n\t// we can know what to do.\n\tAssert( m_senderState.m_mapInFlightPacketsByPktNum.lower_bound( m_statsEndToEnd.m_nNextSendSequenceNumber ) == m_senderState.m_mapInFlightPacketsByPktNum.end() );\n\tstd::pair<int64,SNPInFlightPacket_t> pairInsert( m_statsEndToEnd.m_nNextSendSequenceNumber, SNPInFlightPacket_t{ usecNow, false, pTransport, {} } );\n\tSNPInFlightPacket_t &inFlightPkt = pairInsert.second;\n\n\t// We might have gone over exactly one byte, because we counted the size byte of the last\n\t// segment, which doesn't actually need to be sent\n\tAssert( cbBytesRemainingForSegments >= 0 || ( cbBytesRemainingForSegments == -1 && vecSegments.size() > 0 ) );\n\n\t// OK, now go through and actually serialize the segments\n\tint nSegments = len( vecSegments );\n\tfor ( int idx = 0 ; idx < nSegments ; ++idx )\n\t{\n\t\tEncodedSegment &seg = vecSegments[ idx ];\n\n\t\t// Check if this message is still sitting in the queue.  (If so, it has to be the first one!)\n\t\tbool bStillInQueue = ( seg.m_pMsg == m_senderState.m_messagesQueued.m_pFirst );\n\n\t\t// Finish the segment size byte\n\t\tif ( idx < nSegments-1 )\n\t\t{\n\t\t\t// Stash upper 3 bits into the header\n\t\t\tint nUpper3Bits = ( seg.m_cbSegSize>>8 );\n\t\t\tAssert( nUpper3Bits <= 4 ); // The values 5 and 6 are reserved and shouldn't be needed due to the MTU we support\n\t\t\tseg.m_hdr[0] |= nUpper3Bits;\n\n\t\t\t// And the lower 8 bits follow the other fields\n\t\t\tseg.m_hdr[ seg.m_cbHdr++ ] = uint8( seg.m_cbSegSize );\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Set \"no explicit size field included, segment extends to end of packet\"\n\t\t\tseg.m_hdr[0] |= 7;\n\t\t}\n\n\t\t// Double-check that we didn't overflow\n\t\tAssert( seg.m_cbHdr <= seg.k_cbMaxHdr );\n\n\t\t// Copy the header\n\t\tmemcpy( pPayloadPtr, seg.m_hdr, seg.m_cbHdr ); pPayloadPtr += seg.m_cbHdr;\n\t\tAssert( pPayloadPtr+seg.m_cbSegSize <= pPayloadEnd );\n\n\t\t// Reliable?\n\t\tif ( seg.m_pMsg->SNPSend_IsReliable() )\n\t\t{\n\t\t\t// We should never encode an empty range of the stream, that is worthless.\n\t\t\t// (Even an empty reliable message requires some framing in the stream.)\n\t\t\tAssert( seg.m_cbSegSize > 0 );\n\n\t\t\t// Copy the unreliable segment into the packet.  Does the portion we are serializing\n\t\t\t// begin in the header?\n\t\t\tif ( seg.m_nOffset < seg.m_pMsg->m_cbSNPSendReliableHeader )\n\t\t\t{\n\t\t\t\tint cbCopyHdr = std::min( seg.m_cbSegSize, seg.m_pMsg->m_cbSNPSendReliableHeader - seg.m_nOffset );\n\n\t\t\t\tmemcpy( pPayloadPtr, seg.m_pMsg->SNPSend_ReliableHeader() + seg.m_nOffset, cbCopyHdr );\n\t\t\t\tpPayloadPtr += cbCopyHdr;\n\n\t\t\t\tint cbCopyBody = seg.m_cbSegSize - cbCopyHdr;\n\t\t\t\tif ( cbCopyBody > 0 )\n\t\t\t\t{\n\t\t\t\t\tmemcpy( pPayloadPtr, seg.m_pMsg->m_pData, cbCopyBody );\n\t\t\t\t\tpPayloadPtr += cbCopyBody;\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// This segment is entirely from the message body\n\t\t\t\tmemcpy( pPayloadPtr, (char*)seg.m_pMsg->m_pData + seg.m_nOffset - seg.m_pMsg->m_cbSNPSendReliableHeader, seg.m_cbSegSize );\n\t\t\t\tpPayloadPtr += seg.m_cbSegSize;\n\t\t\t}\n\n\n\t\t\t// Remember that this range is in-flight\n\t\t\tSNPRange_t range;\n\t\t\trange.m_nBegin = seg.m_pMsg->SNPSend_ReliableStreamPos() + seg.m_nOffset;\n\t\t\trange.m_nEnd = range.m_nBegin + seg.m_cbSegSize;\n\n\t\t\t// Ranges of the reliable stream that have not been acked should either be\n\t\t\t// in flight, or queued for retry.  Make sure this range is not already in\n\t\t\t// either state.\n\t\t\tAssert( !HasOverlappingRange( range, m_senderState.m_listInFlightReliableRange ) );\n\t\t\tAssert( !HasOverlappingRange( range, m_senderState.m_listReadyRetryReliableRange ) );\n\n\t\t\t// Spew\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld reliable msg %lld offset %d+%d=%d range [%lld,%lld)\\n\",\n\t\t\t\tGetDescription(), (long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)seg.m_pMsg->m_nMessageNumber,\n\t\t\t\tseg.m_nOffset, seg.m_cbSegSize, seg.m_nOffset+seg.m_cbSegSize,\n\t\t\t\t(long long)range.m_nBegin, (long long)range.m_nEnd );\n\n\t\t\t// Add to table of in-flight reliable ranges\n\t\t\tm_senderState.m_listInFlightReliableRange[ range ] = seg.m_pMsg;\n\n\t\t\t// Remember that this packet contained that range\n\t\t\tinFlightPkt.m_vecReliableSegments.push_back( range );\n\n\t\t\t// Less reliable data pending\n\t\t\tm_senderState.m_cbPendingReliable -= seg.m_cbSegSize;\n\t\t\tAssert( m_senderState.m_cbPendingReliable >= 0 );\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// We should only encode an empty segment if the message itself is empty\n\t\t\tAssert( seg.m_cbSegSize > 0 || ( seg.m_cbSegSize == 0 && seg.m_pMsg->m_cbSize == 0 ) );\n\n\t\t\t// Check some stuff\n\t\t\tAssert( bStillInQueue == ( seg.m_nOffset + seg.m_cbSegSize < seg.m_pMsg->m_cbSize ) ); // If we ended the message, we should have removed it from the queue\n\t\t\tAssert( bStillInQueue == ( ( seg.m_hdr[0] & 0x20 ) == 0 ) );\n\t\t\tAssert( bStillInQueue || seg.m_pMsg->m_links.m_pNext == nullptr ); // If not in the queue, we should be detached\n\t\t\tAssert( seg.m_pMsg->m_links.m_pPrev == nullptr ); // We should either be at the head of the queue, or detached\n\n\t\t\t// Copy the unreliable segment into the packet\n\t\t\tmemcpy( pPayloadPtr, (char*)seg.m_pMsg->m_pData + seg.m_nOffset, seg.m_cbSegSize );\n\t\t\tpPayloadPtr += seg.m_cbSegSize;\n\n\t\t\t// Spew\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld unreliable msg %lld offset %d+%d=%d\\n\",\n\t\t\t\tGetDescription(), (long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)seg.m_pMsg->m_nMessageNumber,\n\t\t\t\tseg.m_nOffset, seg.m_cbSegSize, seg.m_nOffset+seg.m_cbSegSize );\n\n\t\t\t// Less unreliable data pending\n\t\t\tm_senderState.m_cbPendingUnreliable -= seg.m_cbSegSize;\n\t\t\tAssert( m_senderState.m_cbPendingUnreliable >= 0 );\n\n\t\t\t// Done with this message?  Clean up\n\t\t\tif ( !bStillInQueue )\n\t\t\t\tseg.m_pMsg->Release();\n\t\t}\n\t}\n\n\t// One last check for overflow\n\tAssert( pPayloadPtr <= pPayloadEnd );\n\tint cbPlainText = pPayloadPtr - payload;\n\tif ( cbPlainText > cbMaxPlaintextPayload )\n\t{\n\t\tAssertMsg1( false, \"Payload exceeded max size of %d\\n\", cbMaxPlaintextPayload );\n\t\treturn 0;\n\t}\n\n\t// OK, we have a plaintext payload.  Encrypt and send it.\n\t// What cipher are we using?\n\tint nBytesSent = 0;\n\tswitch ( m_eNegotiatedCipher )\n\t{\n\t\tdefault:\n\t\t\tAssertMsg1( false, \"Bogus cipher %d\", m_eNegotiatedCipher );\n\t\t\tbreak;\n\n\t\tcase k_ESteamNetworkingSocketsCipher_NULL:\n\t\t{\n\n\t\t\t// No encryption!\n\t\t\t// Ask current transport to deliver it\n\t\t\tnBytesSent = pTransport->SendEncryptedDataChunk( payload, cbPlainText, ctx );\n\t\t}\n\t\tbreak;\n\n\t\tcase k_ESteamNetworkingSocketsCipher_AES_256_GCM:\n\t\t{\n\n\t\t\tAssert( m_bCryptKeysValid );\n\n\t\t\t// Adjust the IV by the packet number\n\t\t\t*(uint64 *)&m_cryptIVSend.m_buf += LittleQWord( m_statsEndToEnd.m_nNextSendSequenceNumber );\n\n\t\t\t// Encrypt the chunk\n\t\t\tuint8 arEncryptedChunk[ k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend + 64 ]; // Should not need pad\n\t\t\tuint32 cbEncrypted = sizeof(arEncryptedChunk);\n\t\t\tDbgVerify( m_cryptContextSend.Encrypt(\n\t\t\t\tpayload, cbPlainText, // plaintext\n\t\t\t\tm_cryptIVSend.m_buf, // IV\n\t\t\t\tarEncryptedChunk, &cbEncrypted, // output\n\t\t\t\tnullptr, 0 // no AAD\n\t\t\t) );\n\n\t\t\t//SpewMsg( \"Send encrypt IV %llu + %02x%02x%02x%02x  encrypted %d %02x%02x%02x%02x\\n\",\n\t\t\t//\t*(uint64 *)&m_cryptIVSend.m_buf,\n\t\t\t//\tm_cryptIVSend.m_buf[8], m_cryptIVSend.m_buf[9], m_cryptIVSend.m_buf[10], m_cryptIVSend.m_buf[11],\n\t\t\t//\tcbEncrypted,\n\t\t\t//\tarEncryptedChunk[0], arEncryptedChunk[1], arEncryptedChunk[2],arEncryptedChunk[3]\n\t\t\t//);\n\n\t\t\t// Restore the IV to the base value\n\t\t\t*(uint64 *)&m_cryptIVSend.m_buf -= LittleQWord( m_statsEndToEnd.m_nNextSendSequenceNumber );\n\n\t\t\tAssert( (int)cbEncrypted >= cbPlainText );\n\t\t\tAssert( (int)cbEncrypted <= k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend ); // confirm that pad above was not necessary and we never exceed k_nMaxSteamDatagramTransportPayload, even after encrypting\n\n\t\t\t// Ask current transport to deliver it\n\t\t\tnBytesSent = pTransport->SendEncryptedDataChunk( arEncryptedChunk, cbEncrypted, ctx );\n\t\t}\n\t}\n\tif ( nBytesSent <= 0 )\n\t\treturn false;\n\n\t// We sent a packet.  Track it\n\tauto pairInsertResult = m_senderState.m_mapInFlightPacketsByPktNum.insert( pairInsert );\n\tAssert( pairInsertResult.second ); // We should have inserted a new element, not updated an existing element\n\n\t// If we sent any reliable data, we should expect a reply\n\tif ( !inFlightPkt.m_vecReliableSegments.empty() )\n\t{\n\t\tm_statsEndToEnd.TrackSentMessageExpectingSeqNumAck( usecNow, true );\n\t\t// FIXME - should let transport know\n\t}\n\n\t// If we aren't already tracking anything to timeout, then this is the next one.\n\tif ( m_senderState.m_itNextInFlightPacketToTimeout == m_senderState.m_mapInFlightPacketsByPktNum.end() )\n\t\tm_senderState.m_itNextInFlightPacketToTimeout = pairInsertResult.first;\n\n\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\tpLog->m_cbSent = nBytesSent;\n\t#endif\n\n\t// We spent some tokens\n\tm_senderState.m_flTokenBucket -= (float)nBytesSent;\n\treturn true;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_SentNonDataPacket( CConnectionTransport *pTransport, SteamNetworkingMicroseconds usecNow )\n{\n\tstd::pair<int64,SNPInFlightPacket_t> pairInsert( m_statsEndToEnd.m_nNextSendSequenceNumber-1, SNPInFlightPacket_t{ usecNow, false, pTransport, {} } );\n\tauto pairInsertResult = m_senderState.m_mapInFlightPacketsByPktNum.insert( pairInsert );\n\tAssert( pairInsertResult.second ); // We should have inserted a new element, not updated an existing element.  Probably an order ofoperations bug with m_nNextSendSequenceNumber\n}\n\nvoid CSteamNetworkConnectionBase::SNP_GatherAckBlocks( SNPAckSerializerHelper &helper, SteamNetworkingMicroseconds usecNow )\n{\n\thelper.m_nBlocks = 0;\n\thelper.m_nBlocksNeedToAck = 0;\n\n\t// Fast case for no packet loss we need to ack, which will (hopefully!) be a common case\n\tint n = len( m_receiverState.m_mapPacketGaps ) - 1;\n\tif ( n <= 0 )\n\t\treturn;\n\n\t// Let's not just flush the acks that are due right now.  Let's flush all of them\n\t// that will be due any time before we have the bandwidth to send the next packet.\n\t// (Assuming that we send the max packet size here.)\n\tSteamNetworkingMicroseconds usecSendAcksDueBefore = usecNow;\n\tSteamNetworkingMicroseconds usecTimeUntilNextPacket = SteamNetworkingMicroseconds( ( m_senderState.m_flTokenBucket - (float)m_cbMTUPacketSize ) / (float)m_senderState.m_n_x * -1e6 );\n\tif ( usecTimeUntilNextPacket > 0 )\n\t\tusecSendAcksDueBefore += usecTimeUntilNextPacket;\n\n\tm_receiverState.DebugCheckPackGapMap();\n\n\tn = std::min( (int)helper.k_nMaxBlocks, n );\n\tauto itNext = m_receiverState.m_mapPacketGaps.begin();\n\n\tint cbEncodedSize = helper.k_cbHeaderSize;\n\twhile ( n > 0 )\n\t{\n\t\t--n;\n\t\tauto itCur = itNext;\n\t\t++itNext;\n\n\t\tAssert( itCur->first < itCur->second.m_nEnd );\n\n\t\t// Do we need to report on this block now?\n\t\tbool bNeedToReport = ( itNext->second.m_usecWhenAckPrior <= usecSendAcksDueBefore );\n\n\t\t// Should we wait to NACK this?\n\t\tif ( itCur == m_receiverState.m_itPendingNack )\n\t\t{\n\n\t\t\t// Wait to NACK this?\n\t\t\tif ( !bNeedToReport )\n\t\t\t{\n\t\t\t\tif ( usecNow < itCur->second.m_usecWhenOKToNack )\n\t\t\t\t\tbreak;\n\t\t\t\tbNeedToReport = true;\n\t\t\t}\n\n\t\t\t// Go ahead and NACK it.  If the packet arrives, we will use it.\n\t\t\t// But our NACK may cause the sender to retransmit.\n\t\t\t++m_receiverState.m_itPendingNack;\n\t\t}\n\n\t\tSNPAckSerializerHelper::Block &block = helper.m_arBlocks[ helper.m_nBlocks ];\n\t\tblock.m_nNack = uint32( itCur->second.m_nEnd - itCur->first );\n\n\t\tint64 nAckEnd;\n\t\tSteamNetworkingMicroseconds usecWhenSentLast;\n\t\tif ( n == 0 )\n\t\t{\n\t\t\t// itNext should be the sentinel\n\t\t\tAssert( itNext->first == INT64_MAX );\n\t\t\tnAckEnd = m_statsEndToEnd.m_nMaxRecvPktNum+1;\n\t\t\tusecWhenSentLast = m_statsEndToEnd.m_usecTimeLastRecvSeq;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tnAckEnd = itNext->first;\n\t\t\tusecWhenSentLast = itNext->second.m_usecWhenReceivedPktBefore;\n\t\t}\n\t\tAssert( itCur->second.m_nEnd < nAckEnd );\n\t\tblock.m_nAck = uint32( nAckEnd - itCur->second.m_nEnd );\n\n\t\tblock.m_nLatestPktNum = uint32( nAckEnd-1 );\n\t\tblock.m_nEncodedTimeSinceLatestPktNum = SNPAckSerializerHelper::EncodeTimeSince( usecNow, usecWhenSentLast );\n\n\t\t// When we encode 7+ blocks, the header grows by one byte\n\t\t// to store an explicit count\n\t\tif ( helper.m_nBlocks == 6 )\n\t\t\t++cbEncodedSize;\n\n\t\t// This block\n\t\t++cbEncodedSize;\n\t\tif ( block.m_nAck > 7 )\n\t\t\tcbEncodedSize += VarIntSerializedSize( block.m_nAck>>3 );\n\t\tif ( block.m_nNack > 7 )\n\t\t\tcbEncodedSize += VarIntSerializedSize( block.m_nNack>>3 );\n\t\tblock.m_cbTotalEncodedSize = cbEncodedSize;\n\n\t\t// FIXME Here if the caller knows they are working with limited space,\n\t\t// they could tell us how much space they have and we could bail\n\t\t// if we already know we're over\n\n\t\t++helper.m_nBlocks;\n\n\t\t// Do we really need to try to flush the ack/nack for that block out now?\n\t\tif ( bNeedToReport )\n\t\t\thelper.m_nBlocksNeedToAck = helper.m_nBlocks;\n\t}\n}\n\nuint8 *CSteamNetworkConnectionBase::SNP_SerializeAckBlocks( const SNPAckSerializerHelper &helper, uint8 *pOut, const uint8 *pOutEnd, SteamNetworkingMicroseconds usecNow )\n{\n\n\t// We shouldn't be called if we never received anything\n\tAssert( m_statsEndToEnd.m_nMaxRecvPktNum > 0 );\n\n\t// No room even for the header?\n\tif ( pOut + SNPAckSerializerHelper::k_cbHeaderSize > pOutEnd )\n\t\treturn pOut;\n\n\t// !KLUDGE! For now limit number of blocks, and always use 16-bit ID.\n\t//          Later we might want to make this code smarter.\n\tCOMPILE_TIME_ASSERT( SNPAckSerializerHelper::k_cbHeaderSize == 5 );\n\tuint8 *pAckHeaderByte = pOut;\n\t++pOut;\n\tuint16 *pLatestPktNum = (uint16 *)pOut;\n\tpOut += 2;\n\tuint16 *pTimeSinceLatestPktNum = (uint16 *)pOut;\n\tpOut += 2;\n\n\t// 10011000 - ack frame designator, with 16-bit last-received sequence number, and no ack blocks\n\t*pAckHeaderByte = 0x98;\n\n\tint nLogLevelPacketDecode = m_connectionConfig.m_LogLevel_PacketDecode.Get();\n\n\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\tPacketSendLog *pLog = &m_vecSendLog[ m_vecSendLog.size()-1 ];\n\t#endif\n\n\t// Fast case for no packet loss we need to ack, which will (hopefully!) be a common case\n\tif ( m_receiverState.m_mapPacketGaps.size() == 1 )\n\t{\n\t\tint64 nLastRecvPktNum = m_statsEndToEnd.m_nMaxRecvPktNum;\n\t\t*pLatestPktNum = LittleWord( (uint16)nLastRecvPktNum );\n\t\t*pTimeSinceLatestPktNum = LittleWord( (uint16)SNPAckSerializerHelper::EncodeTimeSince( usecNow, m_statsEndToEnd.m_usecTimeLastRecvSeq ) );\n\n\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld last recv %lld (no loss)\\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)nLastRecvPktNum\n\t\t);\n\t\tm_receiverState.m_mapPacketGaps.rbegin()->second.m_usecWhenAckPrior = INT64_MAX; // Clear timer, we wrote everything we needed to\n\n\t\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\t\tpLog->m_nAckBlocksSent = 0;\n\t\t\tpLog->m_nAckEnd = nLastRecvPktNum;\n\t\t#endif\n\n\t\treturn pOut;\n\t}\n\n\t// Fit as many blocks as possible.\n\t// (Unless we are badly fragmented and are trying to squeeze in what\n\t// we can at the end of a packet, this won't ever iterate\n\tint nBlocks = helper.m_nBlocks;\n\tuint8 *pExpectedOutEnd;\n\tfor (;;)\n\t{\n\n\t\t// Not sending any blocks at all?  (Either they don't fit, or we are waiting because we don't\n\t\t// want to nack yet.)  Just fill in the header with the oldest ack\n\t\tif ( nBlocks == 0 )\n\t\t{\n\t\t\tauto itOldestGap = m_receiverState.m_mapPacketGaps.begin();\n\t\t\tint64 nLastRecvPktNum = itOldestGap->first-1;\n\t\t\t*pLatestPktNum = LittleWord( uint16( nLastRecvPktNum ) );\n\t\t\t*pTimeSinceLatestPktNum = LittleWord( (uint16)SNPAckSerializerHelper::EncodeTimeSince( usecNow, itOldestGap->second.m_usecWhenReceivedPktBefore ) );\n\n\t\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld last recv %lld (no blocks, actual last recv=%lld)\\n\",\n\t\t\t\tGetDescription(),\n\t\t\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)nLastRecvPktNum, (long long)m_statsEndToEnd.m_nMaxRecvPktNum\n\t\t\t);\n\n\t\t\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\t\t\tpLog->m_nAckBlocksSent = 0;\n\t\t\t\tpLog->m_nAckEnd = nLastRecvPktNum;\n\t\t\t#endif\n\n\t\t\t// Acked packets before this gap.  Were we waiting to flush them?\n\t\t\tif ( itOldestGap == m_receiverState.m_itPendingAck )\n\t\t\t{\n\t\t\t\t// Mark it as sent\n\t\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\t\t++m_receiverState.m_itPendingAck;\n\t\t\t}\n\n\t\t\t// NOTE: We did NOT nack anything just now\n\t\t\treturn pOut;\n\t\t}\n\n\t\tint cbTotalEncoded = helper.m_arBlocks[nBlocks-1].m_cbTotalEncodedSize;\n\t\tpExpectedOutEnd = pAckHeaderByte + cbTotalEncoded; // Save for debugging below\n\t\tif ( pExpectedOutEnd <= pOutEnd )\n\t\t\tbreak;\n\n\t\t// Won't fit, peel off the newest one, see if the earlier ones will fit\n\t\t--nBlocks;\n\t}\n\n\t// OK, we know how many blocks we are going to write.  Finish the header byte\n\tAssert( nBlocks == uint8(nBlocks) );\n\tif ( nBlocks > 6 )\n\t{\n\t\t*pAckHeaderByte |= 7;\n\t\t*(pOut++) = uint8( nBlocks );\n\t}\n\telse\n\t{\n\t\t*pAckHeaderByte |= uint8( nBlocks );\n\t}\n\n\t// Locate the first one we will serialize.\n\t// (It's the newest one, which is the last one in the list).\n\tconst SNPAckSerializerHelper::Block *pBlock = &helper.m_arBlocks[nBlocks-1];\n\n\t// Latest packet number and time\n\t*pLatestPktNum = LittleWord( uint16( pBlock->m_nLatestPktNum ) );\n\t*pTimeSinceLatestPktNum = LittleWord( pBlock->m_nEncodedTimeSinceLatestPktNum );\n\n\t// Full packet number, for spew\n\tint64 nAckEnd = ( m_statsEndToEnd.m_nMaxRecvPktNum & ~(int64)(~(uint32)0) ) | pBlock->m_nLatestPktNum;\n\t++nAckEnd;\n\n\t#ifdef SNP_ENABLE_PACKETSENDLOG\n\t\tpLog->m_nAckBlocksSent = nBlocks;\n\t\tpLog->m_nAckEnd = nAckEnd;\n\t#endif\n\n\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld last recv %lld (%d blocks, actual last recv=%lld)\\n\",\n\t\tGetDescription(),\n\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)(nAckEnd-1), nBlocks, (long long)m_statsEndToEnd.m_nMaxRecvPktNum\n\t);\n\n\t// Check for a common case where we report on everything\n\tif ( nAckEnd > m_statsEndToEnd.m_nMaxRecvPktNum )\n\t{\n\t\tAssert( nAckEnd == m_statsEndToEnd.m_nMaxRecvPktNum+1 );\n\t\tfor (;;)\n\t\t{\n\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\tif ( m_receiverState.m_itPendingAck->first == INT64_MAX )\n\t\t\t\tbreak;\n\t\t\t++m_receiverState.m_itPendingAck;\n\t\t}\n\t\tm_receiverState.m_itPendingNack = m_receiverState.m_itPendingAck;\n\t}\n\telse\n\t{\n\n\t\t// Advance pointer to next block that needs to be acked,\n\t\t// past the ones we are about to ack.\n\t\tif ( m_receiverState.m_itPendingAck->first <= nAckEnd )\n\t\t{\n\t\t\tdo\n\t\t\t{\n\t\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\t\t++m_receiverState.m_itPendingAck;\n\t\t\t} while ( m_receiverState.m_itPendingAck->first <= nAckEnd );\n\t\t}\n\n\t\t// Advance pointer to next block that needs to be nacked, past the ones\n\t\t// we are about to nack.\n\t\twhile ( m_receiverState.m_itPendingNack->first < nAckEnd )\n\t\t\t++m_receiverState.m_itPendingNack;\n\t}\n\n\t// Serialize the blocks into the packet, from newest to oldest\n\twhile ( pBlock >= helper.m_arBlocks )\n\t{\n\t\tuint8 *pAckBlockHeaderByte = pOut;\n\t\t++pOut;\n\n\t\t// Encode ACK (number of packets successfully received)\n\t\t{\n\t\t\tif ( pBlock->m_nAck < 8 )\n\t\t\t{\n\t\t\t\t// Small block of packets.  Encode directly in the header.\n\t\t\t\t*pAckBlockHeaderByte = uint8(pBlock->m_nAck << 4);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Larger block of received packets.  Put lowest bits in the header,\n\t\t\t\t// and overflow using varint.  This is probably going to be pretty\n\t\t\t\t// common.\n\t\t\t\t*pAckBlockHeaderByte = 0x80 | ( uint8(pBlock->m_nAck & 7) << 4 );\n\t\t\t\tpOut = SerializeVarInt( pOut, pBlock->m_nAck>>3, pOutEnd );\n\t\t\t\tif ( pOut == nullptr )\n\t\t\t\t{\n\t\t\t\t\tAssertMsg( false, \"Overflow serializing packet ack varint count\" );\n\t\t\t\t\treturn nullptr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Encode NACK (number of packets dropped)\n\t\t{\n\t\t\tif ( pBlock->m_nNack < 8 )\n\t\t\t{\n\t\t\t\t// Small block of packets.  Encode directly in the header.\n\t\t\t\t*pAckBlockHeaderByte |= uint8(pBlock->m_nNack);\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Larger block of dropped packets.  Put lowest bits in the header,\n\t\t\t\t// and overflow using varint.  This is probably going to be less common than\n\t\t\t\t// large ACK runs, but not totally uncommon.  Losing one or two packets is\n\t\t\t\t// really common, but loss events often involve a lost of many packets in a run.\n\t\t\t\t*pAckBlockHeaderByte |= 0x08 | uint8(pBlock->m_nNack & 7);\n\t\t\t\tpOut = SerializeVarInt( pOut, pBlock->m_nNack >> 3, pOutEnd );\n\t\t\t\tif ( pOut == nullptr )\n\t\t\t\t{\n\t\t\t\t\tAssertMsg( false, \"Overflow serializing packet nack varint count\" );\n\t\t\t\t\treturn nullptr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Debug\n\t\tint64 nAckBegin = nAckEnd - pBlock->m_nAck;\n\t\tint64 nNackBegin = nAckBegin - pBlock->m_nNack;\n\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   encode pkt %lld nack [%lld,%lld) ack [%lld,%lld) \\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber,\n\t\t\t(long long)nNackBegin, (long long)nAckBegin,\n\t\t\t(long long)nAckBegin, (long long)nAckEnd\n\t\t);\n\t\tnAckEnd = nNackBegin;\n\t\tAssert( nAckEnd > 0 ); // Make sure we don't try to ack packet 0 or below\n\n\t\t// Move backwards in time\n\t\t--pBlock;\n\t}\n\n\t// Make sure when we were checking what would fit, we correctly calculated serialized size\n\tAssert( pOut == pExpectedOutEnd );\n\n\treturn pOut;\n}\n\nuint8 *CSteamNetworkConnectionBase::SNP_SerializeStopWaitingFrame( uint8 *pOut, const uint8 *pOutEnd, SteamNetworkingMicroseconds usecNow )\n{\n\t// For now, we will always write this.  We should optimize this and try to be\n\t// smart about when to send it (probably maybe once per RTT, or when N packets\n\t// have been received or N blocks accumulate?)\n\n\t// Calculate offset from the current sequence number\n\tint64 nOffset = m_statsEndToEnd.m_nNextSendSequenceNumber - m_senderState.m_nMinPktWaitingOnAck;\n\tAssertMsg2( nOffset > 0, \"Told peer to stop acking up to %lld, but latest packet we have sent is %lld\", (long long)m_senderState.m_nMinPktWaitingOnAck, (long long)m_statsEndToEnd.m_nNextSendSequenceNumber );\n\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketDecode.Get(), \"[%s]   encode pkt %lld stop_waiting offset %lld = %lld\",\n\t\tGetDescription(),\n\t\t(long long)m_statsEndToEnd.m_nNextSendSequenceNumber, (long long)nOffset, (long long)m_senderState.m_nMinPktWaitingOnAck );\n\n\t// Subtract one, as a *tiny* optimization, since they cannot possible have\n\t// acknowledged this packet we are serializing already\n\t--nOffset;\n\n\t// Now encode based on number of bits needed\n\tif ( nOffset < 0x100 )\n\t{\n\t\tif ( pOut + 2 > pOutEnd )\n\t\t\treturn pOut;\n\t\t*pOut = 0x80;\n\t\t++pOut;\n\t\t*pOut = uint8( nOffset );\n\t\t++pOut;\n\t}\n\telse if ( nOffset < 0x10000 )\n\t{\n\t\tif ( pOut + 3 > pOutEnd )\n\t\t\treturn pOut;\n\t\t*pOut = 0x81;\n\t\t++pOut;\n\t\t*(uint16*)pOut = LittleWord( uint16( nOffset ) );\n\t\tpOut += 2;\n\t}\n\telse if ( nOffset < 0x1000000 )\n\t{\n\t\tif ( pOut + 4 > pOutEnd )\n\t\t\treturn pOut;\n\t\t*pOut = 0x82;\n\t\t++pOut;\n\t\t*pOut = uint8( nOffset ); // Wire format is little endian, so lowest 8 bits first\n\t\t++pOut;\n\t\t*(uint16*)pOut = LittleWord( uint16( nOffset>>8 ) );\n\t\tpOut += 2;\n\t}\n\telse\n\t{\n\t\tif ( pOut + 9 > pOutEnd )\n\t\t\treturn pOut;\n\t\t*pOut = 0x83;\n\t\t++pOut;\n\t\t*(uint64*)pOut = LittleQWord( nOffset );\n\t\tpOut += 8;\n\t}\n\n\tAssert( pOut <= pOutEnd );\n\treturn pOut;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_ReceiveUnreliableSegment( int64 nMsgNum, int nOffset, const void *pSegmentData, int cbSegmentSize, bool bLastSegmentInMessage, SteamNetworkingMicroseconds usecNow )\n{\n\tSpewDebugGroup( m_connectionConfig.m_LogLevel_PacketDecode.Get(), \"[%s] RX msg %lld offset %d+%d=%d %02x ... %02x\\n\", GetDescription(), nMsgNum, nOffset, cbSegmentSize, nOffset+cbSegmentSize, ((byte*)pSegmentData)[0], ((byte*)pSegmentData)[cbSegmentSize-1] );\n\n\t// Ignore data segments when we are not going to process them (e.g. linger)\n\tif ( GetState() != k_ESteamNetworkingConnectionState_Connected )\n\t{\n\t\tSpewDebugGroup( m_connectionConfig.m_LogLevel_PacketDecode.Get(), \"[%s] discarding msg %lld [%d,%d) as connection is in state %d\\n\",\n\t\t\tGetDescription(),\n\t\t\tnMsgNum,\n\t\t\tnOffset, nOffset+cbSegmentSize,\n\t\t\t(int)GetState() );\n\t\treturn;\n\t}\n\n\t// Check for a common special case: non-fragmented message.\n\tif ( nOffset == 0 && bLastSegmentInMessage )\n\t{\n\n\t\t// Deliver it immediately, don't go through the fragmentation assembly process below.\n\t\t// (Although that would work.)\n\t\tReceivedMessage( pSegmentData, cbSegmentSize, nMsgNum, k_nSteamNetworkingSend_Unreliable, usecNow );\n\t\treturn;\n\t}\n\n\t// Limit number of unreliable segments we store.  We just use a fixed\n\t// limit, rather than trying to be smart by expiring based on time or whatever.\n\tif ( len( m_receiverState.m_mapUnreliableSegments ) > k_nMaxBufferedUnreliableSegments )\n\t{\n\t\tauto itDelete = m_receiverState.m_mapUnreliableSegments.begin();\n\n\t\t// If we're going to delete some, go ahead and delete all of them for this\n\t\t// message.\n\t\tint64 nDeleteMsgNum = itDelete->first.m_nMsgNum;\n\t\tdo {\n\t\t\titDelete = m_receiverState.m_mapUnreliableSegments.erase( itDelete );\n\t\t} while ( itDelete != m_receiverState.m_mapUnreliableSegments.end() && itDelete->first.m_nMsgNum == nDeleteMsgNum );\n\n\t\t// Warn if the message we are receiving is older (or the same) than the one\n\t\t// we are deleting.  If sender is legit, then it probably means that we have\n\t\t// something tuned badly.\n\t\tif ( nDeleteMsgNum >= nMsgNum )\n\t\t{\n\t\t\t// Spew, but rate limit in case of malicious sender\n\t\t\tSpewWarningRateLimited( usecNow, \"[%s] SNP expiring unreliable segments for msg %lld, while receiving unreliable segments for msg %lld\\n\",\n\t\t\t\tGetDescription(), (long long)nDeleteMsgNum, (long long)nMsgNum );\n\t\t}\n\t}\n\n\t// Message fragment.  Find/insert the entry in our reassembly queue\n\t// I really hate this syntax and interface.\n\tSSNPRecvUnreliableSegmentKey key;\n\tkey.m_nMsgNum = nMsgNum;\n\tkey.m_nOffset = nOffset;\n\tSSNPRecvUnreliableSegmentData &data = m_receiverState.m_mapUnreliableSegments[ key ];\n\tif ( data.m_cbSegSize >= 0 )\n\t{\n\t\t// We got another segment starting at the same offset.  This is weird, since they shouldn't\n\t\t// be doing.  But remember that we're working on top of UDP, which could deliver packets\n\t\t// multiple times.  We'll spew about it, just in case it indicates a bug in this code or the sender.\n\t\tSpewWarningRateLimited( usecNow, \"[%s] Received unreliable msg %lld segment offset %d twice.  Sizes %d,%d, last=%d,%d\\n\",\n\t\t\tGetDescription(), nMsgNum, nOffset, data.m_cbSegSize, cbSegmentSize, (int)data.m_bLast, (int)bLastSegmentInMessage );\n\n\t\t// Just drop the segment.  Note that the sender might have sent a longer segment from the previous\n\t\t// one, in which case this segment contains new data, and is not therefore redundant.  That seems\n\t\t// \"legal\", but very weird, and not worth handling.  If senders do retransmit unreliable segments\n\t\t// (perhaps FEC?) then they need to retransmit the exact same segments.\n\t\treturn;\n\t}\n\n\t// Segment in the map either just got inserted, or is a subset of the segment\n\t// we just received.  Replace it.\n\tdata.m_cbSegSize = cbSegmentSize;\n\tAssert( !data.m_bLast );\n\tdata.m_bLast = bLastSegmentInMessage;\n\tmemcpy( data.m_buf, pSegmentData, cbSegmentSize );\n\n\t// Now check if that completed the message\n\tkey.m_nOffset = 0;\n\tauto itMsgStart = m_receiverState.m_mapUnreliableSegments.lower_bound( key );\n\tauto end = m_receiverState.m_mapUnreliableSegments.end();\n\tAssert( itMsgStart != end );\n\tauto itMsgLast = itMsgStart;\n\tint cbMessageSize = 0;\n\tfor (;;)\n\t{\n\t\t// Is this the thing we expected?\n\t\tif ( itMsgLast->first.m_nMsgNum != nMsgNum || itMsgLast->first.m_nOffset > cbMessageSize )\n\t\t\treturn; // We've got a gap.\n\n\t\t// Update.  This code looks more complicated than strictly necessary, but it works\n\t\t// if we have overlapping segments.\n\t\tcbMessageSize = std::max( cbMessageSize, itMsgLast->first.m_nOffset + itMsgLast->second.m_cbSegSize );\n\n\t\t// Is that the end?\n\t\tif ( itMsgLast->second.m_bLast )\n\t\t\tbreak;\n\n\t\t// Still looking for the end\n\t\t++itMsgLast;\n\t\tif ( itMsgLast == end )\n\t\t\treturn;\n\t}\n\n\tCSteamNetworkingMessage *pMsg = CSteamNetworkingMessage::New( this, cbMessageSize, nMsgNum, k_nSteamNetworkingSend_Unreliable, usecNow );\n\tif ( !pMsg )\n\t\treturn;\n\n\t// OK, we have the complete message!  Gather the\n\t// segments into a contiguous buffer\n\tfor (;;)\n\t{\n\t\tAssert( itMsgStart->first.m_nMsgNum == nMsgNum );\n\t\tmemcpy( (char *)pMsg->m_pData + itMsgStart->first.m_nOffset, itMsgStart->second.m_buf, itMsgStart->second.m_cbSegSize );\n\n\t\t// Done?\n\t\tif ( itMsgStart->second.m_bLast )\n\t\t\tbreak;\n\n\t\t// Remove entry from list, and move onto the next entry\n\t\titMsgStart = m_receiverState.m_mapUnreliableSegments.erase( itMsgStart );\n\t}\n\n\t// Erase the last segment, and anything else we might have hanging around\n\t// for this message (???)\n\tdo {\n\t\titMsgStart = m_receiverState.m_mapUnreliableSegments.erase( itMsgStart );\n\t} while ( itMsgStart != end && itMsgStart->first.m_nMsgNum == nMsgNum );\n\n\t// Deliver the message.\n\tReceivedMessage( pMsg );\n}\n\nbool CSteamNetworkConnectionBase::SNP_ReceiveReliableSegment( int64 nPktNum, int64 nSegBegin, const uint8 *pSegmentData, int cbSegmentSize, SteamNetworkingMicroseconds usecNow )\n{\n\tint nLogLevelPacketDecode = m_connectionConfig.m_LogLevel_PacketDecode.Get();\n\n\t// Calculate segment end stream position\n\tint64 nSegEnd = nSegBegin + cbSegmentSize;\n\n\t// Spew\n\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld reliable range [%lld,%lld)\\n\",\n\t\tGetDescription(),\n\t\t(long long)nPktNum,\n\t\t(long long)nSegBegin, (long long)nSegEnd );\n\n\t// No segment data?  Seems fishy, but if it happens, just skip it.\n\tAssert( cbSegmentSize >= 0 );\n\tif ( cbSegmentSize <= 0 )\n\t{\n\t\t// Spew but rate limit in case of malicious sender\n\t\tSpewWarningRateLimited( usecNow, \"[%s] decode pkt %lld empty reliable segment?\\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)nPktNum );\n\t\treturn true;\n\t}\n\n\t// Ignore data segments when we are not going to process them (e.g. linger)\n\tif ( GetState() != k_ESteamNetworkingConnectionState_Connected )\n\t{\n\t\tSpewVerboseGroup( nLogLevelPacketDecode, \"[%s]   discarding pkt %lld [%lld,%lld) as connection is in state %d\\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)nPktNum,\n\t\t\t(long long)nSegBegin, (long long)nSegEnd,\n\t\t\t(int)GetState() );\n\t\treturn true;\n\t}\n\n\t// Check if the entire thing is stuff we have already received, then\n\t// we can discard it\n\tif ( nSegEnd <= m_receiverState.m_nReliableStreamPos )\n\t\treturn true;\n\n\t// !SPEED! Should we have a fast path here for small messages\n\t// where we have nothing buffered, and avoid all the copying into the \n\t// stream buffer and decode directly.\n\n\t// What do we expect to receive next?\n\tconst int64 nExpectNextStreamPos = m_receiverState.m_nReliableStreamPos + len( m_receiverState.m_bufReliableStream );\n\n\t// Check if we need to grow the reliable buffer to hold the data\n\tif ( nSegEnd > nExpectNextStreamPos )\n\t{\n\t\tint64 cbNewSize = nSegEnd - m_receiverState.m_nReliableStreamPos;\n\t\tAssert( cbNewSize > len( m_receiverState.m_bufReliableStream ) );\n\n\t\t// Check if we have too much data buffered, just stop processing\n\t\t// this packet, and forget we ever received it.  We need to protect\n\t\t// against a malicious sender trying to create big gaps.  If they\n\t\t// are legit, they will notice that we go back and fill in the gaps\n\t\t// and we will get caught up.\n\t\tif ( cbNewSize > k_cbMaxBufferedReceiveReliableData )\n\t\t{\n\t\t\t// Stop processing the packet, and don't ack it.\n\t\t\t// This indicates the connection is in pretty bad shape,\n\t\t\t// so spew about it.  But rate limit in case of malicious sender\n\t\t\tSpewWarningRateLimited( usecNow, \"[%s] decode pkt %lld abort.  %lld bytes reliable data buffered [%lld-%lld), new size would be %lld to %lld\\n\",\n\t\t\t\tGetDescription(),\n\t\t\t\t(long long)nPktNum,\n\t\t\t\t(long long)m_receiverState.m_bufReliableStream.size(),\n\t\t\t\t(long long)m_receiverState.m_nReliableStreamPos,\n\t\t\t\t(long long)( m_receiverState.m_nReliableStreamPos + m_receiverState.m_bufReliableStream.size() ),\n\t\t\t\t(long long)cbNewSize, (long long)nSegEnd\n\t\t\t);\n\t\t\treturn false;  // DO NOT ACK THIS PACKET\n\t\t}\n\n\t\t// Check if this is going to make a new gap\n\t\tif ( nSegBegin > nExpectNextStreamPos )\n\t\t{\n\t\t\tif ( !m_receiverState.m_mapReliableStreamGaps.empty() )\n\t\t\t{\n\n\t\t\t\t// We should never have a gap at the very end of the buffer.\n\t\t\t\t// (Why would we extend the buffer, unless we needed to to\n\t\t\t\t// store some data?)\n\t\t\t\tAssert( m_receiverState.m_mapReliableStreamGaps.rbegin()->second < nExpectNextStreamPos );\n\n\t\t\t\t// We need to add a new gap.  See if we're already too fragmented.\n\t\t\t\tif ( len( m_receiverState.m_mapReliableStreamGaps ) >= k_nMaxReliableStreamGaps_Extend )\n\t\t\t\t{\n\t\t\t\t\t// Stop processing the packet, and don't ack it\n\t\t\t\t\t// This indicates the connection is in pretty bad shape,\n\t\t\t\t\t// so spew about it.  But rate limit in case of malicious sender\n\t\t\t\t\tSpewWarningRateLimited( usecNow, \"[%s] decode pkt %lld abort.  Reliable stream already has %d fragments, first is [%lld,%lld), last is [%lld,%lld), new segment is [%lld,%lld)\\n\",\n\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t(long long)nPktNum,\n\t\t\t\t\t\tlen( m_receiverState.m_mapReliableStreamGaps ),\n\t\t\t\t\t\t(long long)m_receiverState.m_mapReliableStreamGaps.begin()->first, (long long)m_receiverState.m_mapReliableStreamGaps.begin()->second,\n\t\t\t\t\t\t(long long)m_receiverState.m_mapReliableStreamGaps.rbegin()->first, (long long)m_receiverState.m_mapReliableStreamGaps.rbegin()->second,\n\t\t\t\t\t\t(long long)nSegBegin, (long long)nSegEnd\n\t\t\t\t\t);\n\t\t\t\t\treturn false;  // DO NOT ACK THIS PACKET\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Add a gap\n\t\t\tm_receiverState.m_mapReliableStreamGaps[ nExpectNextStreamPos ] = nSegBegin;\n\t\t}\n\t\tm_receiverState.m_bufReliableStream.resize( size_t( cbNewSize ) );\n\t}\n\n\t// If segment overlapped the existing buffer, we might need to discard the front\n\t// bit or discard a gap that was filled\n\tif ( nSegBegin < nExpectNextStreamPos )\n\t{\n\n\t\t// Check if the front bit has already been processed, then skip it\n\t\tif ( nSegBegin < m_receiverState.m_nReliableStreamPos )\n\t\t{\n\t\t\tint nSkip = m_receiverState.m_nReliableStreamPos - nSegBegin;\n\t\t\tcbSegmentSize -= nSkip;\n\t\t\tpSegmentData += nSkip;\n\t\t\tnSegBegin += nSkip;\n\t\t}\n\t\tAssert( nSegBegin < nSegEnd );\n\n\t\t// Check if this filled in one or more gaps (or made a hole in the middle!)\n\t\tif ( !m_receiverState.m_mapReliableStreamGaps.empty() )\n\t\t{\n\t\t\tauto gapFilled = m_receiverState.m_mapReliableStreamGaps.upper_bound( nSegBegin );\n\t\t\tif ( gapFilled != m_receiverState.m_mapReliableStreamGaps.begin() )\n\t\t\t{\n\t\t\t\t--gapFilled;\n\t\t\t\tAssert( gapFilled->first < gapFilled->second ); // Make sure we don't have degenerate/invalid gaps in our table\n\t\t\t\tAssert( gapFilled->first <= nSegBegin ); // Make sure we located the gap we think we located\n\t\t\t\tif ( gapFilled->second > nSegBegin ) // gap is not entirely before this segment\n\t\t\t\t{\n\t\t\t\t\tdo {\n\n\t\t\t\t\t\t// Common case where we fill exactly at the start\n\t\t\t\t\t\tif ( nSegBegin == gapFilled->first )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\tif ( nSegEnd < gapFilled->second )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t// We filled the first bit of the gap.  Chop off the front bit that we filled.\n\t\t\t\t\t\t\t\t// We cast away const here because we know that we aren't violating the ordering constraints\n\t\t\t\t\t\t\t\tconst_cast<int64&>( gapFilled->first ) = nSegEnd;\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// Filled the whole gap.\n\t\t\t\t\t\t\t// Erase, and move forward in case this also fills more gaps\n\t\t\t\t\t\t\t// !SPEED! Since exactly filing the gap should be common, we might\n\t\t\t\t\t\t\t// check specifically for that case and early out here.\n\t\t\t\t\t\t\tgapFilled = m_receiverState.m_mapReliableStreamGaps.erase( gapFilled );\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse if ( nSegEnd >= gapFilled->second )\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// Chop off the end of the gap\n\t\t\t\t\t\t\tAssert( nSegBegin < gapFilled->second );\n\t\t\t\t\t\t\tgapFilled->second = nSegBegin;\n\n\t\t\t\t\t\t\t// And maybe subsequent gaps!\n\t\t\t\t\t\t\t++gapFilled;\n\t\t\t\t\t\t}\n\t\t\t\t\t\telse\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t// We are fragmenting.\n\t\t\t\t\t\t\tAssert( nSegBegin > gapFilled->first );\n\t\t\t\t\t\t\tAssert( nSegEnd < gapFilled->second );\n\n\t\t\t\t\t\t\t// Protect against malicious sender.  A good sender will\n\t\t\t\t\t\t\t// fill the gaps in stream position order and not fragment\n\t\t\t\t\t\t\t// like this\n\t\t\t\t\t\t\tif ( len( m_receiverState.m_mapReliableStreamGaps ) >= k_nMaxReliableStreamGaps_Fragment )\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\t// Stop processing the packet, and don't ack it\n\t\t\t\t\t\t\t\tSpewWarningRateLimited( usecNow, \"[%s] decode pkt %lld abort.  Reliable stream already has %d fragments, first is [%lld,%lld), last is [%lld,%lld).  We don't want to fragment [%lld,%lld) with new segment [%lld,%lld)\\n\",\n\t\t\t\t\t\t\t\t\tGetDescription(),\n\t\t\t\t\t\t\t\t\t(long long)nPktNum,\n\t\t\t\t\t\t\t\t\tlen( m_receiverState.m_mapReliableStreamGaps ),\n\t\t\t\t\t\t\t\t\t(long long)m_receiverState.m_mapReliableStreamGaps.begin()->first, (long long)m_receiverState.m_mapReliableStreamGaps.begin()->second,\n\t\t\t\t\t\t\t\t\t(long long)m_receiverState.m_mapReliableStreamGaps.rbegin()->first, (long long)m_receiverState.m_mapReliableStreamGaps.rbegin()->second,\n\t\t\t\t\t\t\t\t\t(long long)gapFilled->first, (long long)gapFilled->second,\n\t\t\t\t\t\t\t\t\t(long long)nSegBegin, (long long)nSegEnd\n\t\t\t\t\t\t\t\t);\n\t\t\t\t\t\t\t\treturn false;  // DO NOT ACK THIS PACKET\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t// Save bounds of the right side\n\t\t\t\t\t\t\tint64 nRightHandBegin = nSegEnd;\n\t\t\t\t\t\t\tint64 nRightHandEnd = gapFilled->second;\n\n\t\t\t\t\t\t\t// Truncate the left side\n\t\t\t\t\t\t\tgapFilled->second = nSegBegin;\n\n\t\t\t\t\t\t\t// Add the right hand gap\n\t\t\t\t\t\t\tm_receiverState.m_mapReliableStreamGaps[ nRightHandBegin ] = nRightHandEnd;\n\n\t\t\t\t\t\t\t// And we know that we cannot possible have covered any more gaps\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// In some rare cases we might fill more than one gap with a single segment.\n\t\t\t\t\t\t// So keep searching forward.\n\t\t\t\t\t} while ( gapFilled != m_receiverState.m_mapReliableStreamGaps.end() && gapFilled->first < nSegEnd );\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Copy the data into the buffer.\n\t// It might be redundant, but if so, we aren't going to take the\n\t// time to figure that out.\n\tint nBufOffset = nSegBegin - m_receiverState.m_nReliableStreamPos;\n\tAssert( nBufOffset >= 0 );\n\tAssert( nBufOffset+cbSegmentSize <= len( m_receiverState.m_bufReliableStream ) );\n\tmemcpy( &m_receiverState.m_bufReliableStream[nBufOffset], pSegmentData, cbSegmentSize );\n\n\t// Figure out how many valid bytes are at the head of the buffer\n\tint nNumReliableBytes;\n\tif ( m_receiverState.m_mapReliableStreamGaps.empty() )\n\t{\n\t\tnNumReliableBytes = len( m_receiverState.m_bufReliableStream );\n\t}\n\telse\n\t{\n\t\tauto firstGap = m_receiverState.m_mapReliableStreamGaps.begin();\n\t\tAssert( firstGap->first >= m_receiverState.m_nReliableStreamPos );\n\t\tif ( firstGap->first < nSegBegin )\n\t\t{\n\t\t\t// There's gap in front of us, and therefore if we didn't have\n\t\t\t// a complete reliable message before, we don't have one now.\n\t\t\tAssert( firstGap->second <= nSegBegin );\n\t\t\treturn true;\n\t\t}\n\n\t\t// We do have a gap, but it's somewhere after this segment.\n\t\tAssert( firstGap->first >= nSegEnd );\n\t\tnNumReliableBytes = firstGap->first - m_receiverState.m_nReliableStreamPos;\n\t\tAssert( nNumReliableBytes > 0 );\n\t\tAssert( nNumReliableBytes < len( m_receiverState.m_bufReliableStream ) ); // The last byte in the buffer should always be valid!\n\t}\n\tAssert( nNumReliableBytes > 0 );\n\n\t// OK, now dispatch as many reliable messages as are now available\n\tdo\n\t{\n\n\t\t// OK, if we get here, we have some data.  Attempt to decode a reliable message.\n\t\t// NOTE: If the message is really big, we will end up doing this parsing work\n\t\t// each time we get a new packet.  We could cache off the result if we find out\n\t\t// that it's worth while.  It should be pretty fast, though, so let's keep the\n\t\t// code simple until we know that it's worthwhile.\n\t\tuint8 *pReliableStart = &m_receiverState.m_bufReliableStream[0];\n\t\tuint8 *pReliableDecode = pReliableStart;\n\t\tuint8 *pReliableEnd = pReliableDecode + nNumReliableBytes;\n\n\t\t// Spew\n\t\tSpewDebugGroup( nLogLevelPacketDecode, \"[%s]   decode pkt %lld valid reliable bytes = %d [%lld,%lld)\\n\",\n\t\t\tGetDescription(),\n\t\t\t(long long)nPktNum, nNumReliableBytes,\n\t\t\t(long long)m_receiverState.m_nReliableStreamPos,\n\t\t\t(long long)( m_receiverState.m_nReliableStreamPos + nNumReliableBytes ) );\n\n\t\t// Sanity check that we have a valid header byte.\n\t\tuint8 nHeaderByte = *(pReliableDecode++);\n\t\tif ( nHeaderByte & 0x80 )\n\t\t{\n\t\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError, \"Invalid reliable message header byte 0x%02x\", nHeaderByte );\n\t\t\treturn false;\n\t\t}\n\n\t\t// Parse the message number\n\t\tint64 nMsgNum = m_receiverState.m_nLastRecvReliableMsgNum;\n\t\tif ( nHeaderByte & 0x40 )\n\t\t{\n\t\t\tuint64 nOffset;\n\t\t\tpReliableDecode = DeserializeVarInt( pReliableDecode, pReliableEnd, nOffset );\n\t\t\tif ( pReliableDecode == nullptr )\n\t\t\t{\n\t\t\t\t// We haven't received all of the message\n\t\t\t\treturn true; // Packet OK and can be acked.\n\t\t\t}\n\n\t\t\tnMsgNum += nOffset;\n\n\t\t\t// Sanity check against a HUGE jump in the message number.\n\t\t\t// This is almost certainly bogus.  (OKOK, yes it is theoretically\n\t\t\t// possible.  But for now while this thing is still under development,\n\t\t\t// most likely it's a bug.  Eventually we can lessen these to handle\n\t\t\t// the case where the app decides to send literally a million unreliable\n\t\t\t// messages in between reliable messages.  The second condition is probably\n\t\t\t// legit, though.)\n\t\t\tif ( nOffset > 1000000 || nMsgNum > m_receiverState.m_nHighestSeenMsgNum+10000 )\n\t\t\t{\n\t\t\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError,\n\t\t\t\t\t\"Reliable message number lurch.  Last reliable %lld, offset %llu, highest seen %lld\",\n\t\t\t\t\t(long long)m_receiverState.m_nLastRecvReliableMsgNum, (unsigned long long)nOffset,\n\t\t\t\t\t(long long)m_receiverState.m_nHighestSeenMsgNum );\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\telse\n\t\t{\n\t\t\t++nMsgNum;\n\t\t}\n\n\t\t// Check for updating highest message number seen, so we know how to interpret\n\t\t// message numbers from the sender with only the lowest N bits present.\n\t\t// And yes, we want to do this even if we end up not processing the entire message\n\t\tif ( nMsgNum > m_receiverState.m_nHighestSeenMsgNum )\n\t\t\tm_receiverState.m_nHighestSeenMsgNum = nMsgNum;\n\n\t\t// Parse message size.\n\t\tint cbMsgSize = nHeaderByte&0x1f;\n\t\tif ( nHeaderByte & 0x20 )\n\t\t{\n\t\t\tuint64 nMsgSizeUpperBits;\n\t\t\tpReliableDecode = DeserializeVarInt( pReliableDecode, pReliableEnd, nMsgSizeUpperBits );\n\t\t\tif ( pReliableDecode == nullptr )\n\t\t\t{\n\t\t\t\t// We haven't received all of the message\n\t\t\t\treturn true; // Packet OK and can be acked.\n\t\t\t}\n\n\t\t\t// Sanity check size.  Note that we do this check before we shift,\n\t\t\t// to protect against overflow.\n\t\t\t// (Although DeserializeVarInt doesn't detect overflow...)\n\t\t\tif ( nMsgSizeUpperBits > (uint64)k_cbMaxMessageSizeRecv<<5 )\n\t\t\t{\n\t\t\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError,\n\t\t\t\t\t\"Reliable message size too large.  (%llu<<5 + %d)\",\n\t\t\t\t\t(unsigned long long)nMsgSizeUpperBits, cbMsgSize );\n\t\t\t\treturn false;\n\t\t\t}\n\n\t\t\t// Compute total size, and check it again\n\t\t\tcbMsgSize += int( nMsgSizeUpperBits<<5 );\n\t\t\tif ( cbMsgSize > k_cbMaxMessageSizeRecv )\n\t\t\t{\n\t\t\t\tConnectionState_ProblemDetectedLocally( k_ESteamNetConnectionEnd_Misc_InternalError,\n\t\t\t\t\t\"Reliable message size %d too large.\", cbMsgSize );\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\t// Do we have the full thing?\n\t\tif ( pReliableDecode+cbMsgSize > pReliableEnd )\n\t\t{\n\t\t\t// Ouch, we did all that work and still don't have the whole message.\n\t\t\treturn true; // packet is OK, can be acked, and continue processing it\n\t\t}\n\n\t\t// We have a full message!  Queue it\n\t\tif ( !ReceivedMessage( pReliableDecode, cbMsgSize, nMsgNum, k_nSteamNetworkingSend_Reliable, usecNow ) )\n\t\t\treturn false; // Weird failure.  Most graceful response is to not ack this packet, and maybe we will work next on retry.\n\t\tpReliableDecode += cbMsgSize;\n\t\tint cbStreamConsumed = pReliableDecode-pReliableStart;\n\n\t\t// Advance bookkeeping\n\t\tm_receiverState.m_nLastRecvReliableMsgNum = nMsgNum;\n\t\tm_receiverState.m_nReliableStreamPos += cbStreamConsumed;\n\n\t\t// Remove the data from the from the front of the buffer\n\t\tpop_from_front( m_receiverState.m_bufReliableStream, cbStreamConsumed );\n\n\t\t// We might have more in the stream that is ready to dispatch right now.\n\t\tnNumReliableBytes -= cbStreamConsumed;\n\t} while ( nNumReliableBytes > 0 );\n\n\treturn true; // packet is OK, can be acked, and continue processing it\n}\n\nvoid CSteamNetworkConnectionBase::SNP_RecordReceivedPktNum( int64 nPktNum, SteamNetworkingMicroseconds usecNow, bool bScheduleAck )\n{\n\n\t// Check if sender has already told us they don't need us to\n\t// account for packets this old anymore\n\tif ( unlikely( nPktNum < m_receiverState.m_nMinPktNumToSendAcks ) )\n\t\treturn;\n\n\t// Fast path for the (hopefully) most common case of packets arriving in order\n\tif ( likely( nPktNum == m_statsEndToEnd.m_nMaxRecvPktNum+1 ) )\n\t{\n\t\tif ( bScheduleAck ) // fast path for all unreliable data (common when we are just being used for transport)\n\t\t{\n\t\t\t// Schedule ack of this packet (since we are the highest numbered\n\t\t\t// packet, that means reporting on everything)\n\t\t\tQueueFlushAllAcks( usecNow + k_usecMaxDataAckDelay );\n\t\t}\n\t\treturn;\n\t}\n\n\t// At this point, ack invariants should be met\n\tm_receiverState.DebugCheckPackGapMap();\n\n\t// Latest time that this packet should be acked.\n\t// (We might already be scheduled to send and ack that would include this packet.)\n\tSteamNetworkingMicroseconds usecScheduleAck = bScheduleAck ? usecNow + k_usecMaxDataAckDelay : INT64_MAX;\n\n\t// Check if this introduced a gap since the last sequence packet we have received\n\tif ( nPktNum > m_statsEndToEnd.m_nMaxRecvPktNum )\n\t{\n\n\t\t// Protect against malicious sender!\n\t\tif ( len( m_receiverState.m_mapPacketGaps ) >= k_nMaxPacketGaps )\n\t\t\treturn; // Nope, we will *not* actually mark the packet as received\n\n\t\t// Add a gap for the skipped packet(s).\n\t\tint64 nBegin = m_statsEndToEnd.m_nMaxRecvPktNum+1;\n\t\tstd::pair<int64,SSNPPacketGap> x;\n\t\tx.first = nBegin;\n\t\tx.second.m_nEnd = nPktNum;\n\t\tx.second.m_usecWhenReceivedPktBefore = m_statsEndToEnd.m_usecTimeLastRecvSeq;\n\t\tx.second.m_usecWhenAckPrior = m_receiverState.m_mapPacketGaps.rbegin()->second.m_usecWhenAckPrior;\n\n\t\t// When should we nack this?\n\t\tx.second.m_usecWhenOKToNack = usecNow;\n\t\tif ( nPktNum < m_statsEndToEnd.m_nMaxRecvPktNum + 3 )\n\t\t\tx.second.m_usecWhenOKToNack += k_usecNackFlush;\n\n\t\tauto iter = m_receiverState.m_mapPacketGaps.insert( x ).first;\n\n\t\tSpewMsgGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] drop %d pkts [%lld-%lld)\",\n\t\t\tGetDescription(),\n\t\t\t(int)( nPktNum - nBegin ),\n\t\t\t(long long)nBegin, (long long)nPktNum );\n\n\t\t// Remember that we need to send a NACK\n\t\tif ( m_receiverState.m_itPendingNack->first == INT64_MAX )\n\t\t{\n\t\t\tm_receiverState.m_itPendingNack = iter;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Pending nacks should be for older packet, not newer\n\t\t\tAssert( m_receiverState.m_itPendingNack->first < nBegin );\n\t\t}\n\n\t\t// Back up if we we had a flush of everything scheduled\n\t\tif ( m_receiverState.m_itPendingAck->first == INT64_MAX && m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior < INT64_MAX )\n\t\t{\n\t\t\tAssert( iter->second.m_usecWhenAckPrior == m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior );\n\t\t\tm_receiverState.m_itPendingAck = iter;\n\t\t}\n\n\t\t// At this point, ack invariants should be met\n\t\tm_receiverState.DebugCheckPackGapMap();\n\n\t\t// Schedule ack of this packet (since we are the highest numbered\n\t\t// packet, that means reporting on everything) by the requested\n\t\t// time\n\t\tQueueFlushAllAcks( usecScheduleAck );\n\t}\n\telse\n\t{\n\n\t\t// Check if this filed a gap\n\t\tauto itGap = m_receiverState.m_mapPacketGaps.upper_bound( nPktNum );\n\t\tif ( itGap == m_receiverState.m_mapPacketGaps.end() )\n\t\t{\n\t\t\tAssertMsg( false, \"[%s] Cannot locate gap, or processing packet %lld multiple times. %s | %s\",\n\t\t\t\tGetDescription(), (long long)nPktNum,\n\t\t\t\tm_statsEndToEnd.RecvPktNumStateDebugString().c_str(), m_statsEndToEnd.HistoryRecvSeqNumDebugString(8).c_str() );\n\t\t\treturn;\n\t\t}\n\t\tif ( itGap == m_receiverState.m_mapPacketGaps.begin() )\n\t\t{\n\t\t\tAssertMsg( false, \"[%s] Cannot locate gap, or processing packet %lld multiple times. [%lld,%lld) %s | %s\",\n\t\t\t\tGetDescription(), (long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd,\n\t\t\t\tm_statsEndToEnd.RecvPktNumStateDebugString().c_str(), m_statsEndToEnd.HistoryRecvSeqNumDebugString(8).c_str() );\n\t\t\treturn;\n\t\t}\n\t\t--itGap;\n\t\tif ( itGap->first > nPktNum || itGap->second.m_nEnd <= nPktNum )\n\t\t{\n\t\t\t// We already received this packet.  But this should be impossible now,\n\t\t\t// we should be rejecting duplicate packet numbers earlier\n\t\t\tAssertMsg( false, \"[%s] Packet gap bug.  %lld [%lld,%lld) %s | %s\",\n\t\t\t\tGetDescription(), (long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd,\n\t\t\t\tm_statsEndToEnd.RecvPktNumStateDebugString().c_str(), m_statsEndToEnd.HistoryRecvSeqNumDebugString(8).c_str() );\n\t\t\treturn;\n\t\t}\n\n\t\t// Packet is in a gap where we previously thought packets were lost.\n\t\t// (Packets arriving out of order.)\n\n\t\t// Last packet in gap?\n\t\tif ( itGap->second.m_nEnd-1 == nPktNum )\n\t\t{\n\t\t\t// Single-packet gap?\n\t\t\tif ( itGap->first == nPktNum )\n\t\t\t{\n\t\t\t\t// Were we waiting to ack/nack this?  Then move forward to the next gap, if any\n\t\t\t\tusecScheduleAck = std::min( usecScheduleAck, itGap->second.m_usecWhenAckPrior );\n\t\t\t\tif ( m_receiverState.m_itPendingAck == itGap )\n\t\t\t\t\t++m_receiverState.m_itPendingAck;\n\t\t\t\tif ( m_receiverState.m_itPendingNack == itGap )\n\t\t\t\t\t++m_receiverState.m_itPendingNack;\n\n\t\t\t\t// Save time when we needed to ack the packets before this gap\n\t\t\t\tSteamNetworkingMicroseconds usecWhenAckPrior = itGap->second.m_usecWhenAckPrior;\n\n\t\t\t\t// Gap is totally filled.  Erase, and move to the next one,\n\t\t\t\t// if any, so we can schedule ack below\n\t\t\t\titGap = m_receiverState.m_mapPacketGaps.erase( itGap );\n\n\t\t\t\t// Were we scheduled to ack the packets before this?  If so, then\n\t\t\t\t// we still need to do that, only now when we send that ack, we will\n\t\t\t\t// ack the packets after this gap as well, since they will be included\n\t\t\t\t// in the same ack block.\n\t\t\t\t//\n\t\t\t\t// NOTE: This is based on what was scheduled to be acked before we got\n\t\t\t\t// this packet.  If we need to update the schedule to ack the current\n\t\t\t\t// packet, we will do that below.  However, usually if previous\n\t\t\t\t// packets were already scheduled to be acked, then that deadline time\n\t\t\t\t// will be sooner usecScheduleAck, so the code below will not actually\n\t\t\t\t// do anything.\n\t\t\t\tif ( usecWhenAckPrior < itGap->second.m_usecWhenAckPrior )\n\t\t\t\t{\n\t\t\t\t\titGap->second.m_usecWhenAckPrior = usecWhenAckPrior;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t// Otherwise, we might not have any acks scheduled.  In that\n\t\t\t\t\t// case, the invariant is that m_itPendingAck should point at the sentinel\n\t\t\t\t\tif ( m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior == INT64_MAX )\n\t\t\t\t\t{\n\t\t\t\t\t\tm_receiverState.m_itPendingAck = m_receiverState.m_mapPacketGaps.end();\n\t\t\t\t\t\t--m_receiverState.m_itPendingAck;\n\t\t\t\t\t\tAssert( m_receiverState.m_itPendingAck->first == INT64_MAX );\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] decode pkt %lld, single pkt gap filled\", GetDescription(), (long long)nPktNum );\n\n\t\t\t\t// At this point, ack invariants should be met\n\t\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// Shrink gap by one from the end\n\t\t\t\t--itGap->second.m_nEnd;\n\t\t\t\tAssert( itGap->first < itGap->second.m_nEnd );\n\n\t\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] decode pkt %lld, last packet in gap, reduced to [%lld,%lld)\", GetDescription(),\n\t\t\t\t\t(long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd );\n\n\t\t\t\t// Move to the next gap so we can schedule ack below\n\t\t\t\t++itGap;\n\n\t\t\t\t// At this point, ack invariants should be met\n\t\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t\t}\n\t\t}\n\t\telse if ( itGap->first == nPktNum )\n\t\t{\n\t\t\t// First packet in multi-packet gap.\n\t\t\t// Shrink packet from the front\n\t\t\t// Cast away const to allow us to modify the key.\n\t\t\t// We know this won't break the map ordering\n\t\t\t++const_cast<int64&>( itGap->first );\n\t\t\tAssert( itGap->first < itGap->second.m_nEnd );\n\t\t\titGap->second.m_usecWhenReceivedPktBefore = usecNow;\n\n\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] decode pkt %lld, first packet in gap, reduced to [%lld,%lld)\", GetDescription(),\n\t\t\t\t(long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd );\n\n\t\t\t// At this point, ack invariants should be met\n\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Packet is in the middle of the gap.  We'll need to fragment this gap\n\t\t\t// Protect against malicious sender!\n\t\t\tif ( len( m_receiverState.m_mapPacketGaps ) >= k_nMaxPacketGaps )\n\t\t\t\treturn; // Nope, we will *not* actually mark the packet as received\n\n\t\t\t// Locate the next block so we can set the schedule time\n\t\t\tauto itNext = itGap;\n\t\t\t++itNext;\n\n\t\t\t// Start making a new gap to account for the upper end\n\t\t\tstd::pair<int64,SSNPPacketGap> upper;\n\t\t\tupper.first = nPktNum+1;\n\t\t\tupper.second.m_nEnd = itGap->second.m_nEnd;\n\t\t\tupper.second.m_usecWhenReceivedPktBefore = usecNow;\n\t\t\tif ( itNext == m_receiverState.m_itPendingAck )\n\t\t\t\tupper.second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\telse\n\t\t\t\tupper.second.m_usecWhenAckPrior = itNext->second.m_usecWhenAckPrior;\n\t\t\tupper.second.m_usecWhenOKToNack = itGap->second.m_usecWhenOKToNack;\n\n\t\t\t// Truncate the current gap\n\t\t\titGap->second.m_nEnd = nPktNum;\n\t\t\tAssert( itGap->first < itGap->second.m_nEnd );\n\n\t\t\tSpewVerboseGroup( m_connectionConfig.m_LogLevel_PacketGaps.Get(), \"[%s] decode pkt %lld, gap split [%lld,%lld) and [%lld,%lld)\", GetDescription(),\n\t\t\t\t(long long)nPktNum, (long long)itGap->first, (long long)itGap->second.m_nEnd, upper.first, upper.second.m_nEnd );\n\n\t\t\t// Insert a new gap to account for the upper end, and\n\t\t\t// advance iterator to it, so that we can schedule ack below\n\t\t\titGap = m_receiverState.m_mapPacketGaps.insert( upper ).first;\n\n\t\t\t// At this point, ack invariants should be met\n\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t}\n\n\t\tAssert( itGap != m_receiverState.m_mapPacketGaps.end() );\n\n\t\t// Need to schedule ack (earlier than it is already scheduled)?\n\t\tif ( usecScheduleAck < itGap->second.m_usecWhenAckPrior )\n\t\t{\n\n\t\t\t// Earlier than the current thing being scheduled?\n\t\t\tif ( usecScheduleAck <= m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior )\n\t\t\t{\n\n\t\t\t\t// We're next, set the time\n\t\t\t\titGap->second.m_usecWhenAckPrior = usecScheduleAck;\n\n\t\t\t\t// Any schedules for lower-numbered packets are superseded\n\t\t\t\t// by this one.\n\t\t\t\tif ( m_receiverState.m_itPendingAck->first <= itGap->first )\n\t\t\t\t{\n\t\t\t\t\twhile ( m_receiverState.m_itPendingAck != itGap )\n\t\t\t\t\t{\n\t\t\t\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\t\t\t\t++m_receiverState.m_itPendingAck;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\t\t\t\t\t// If our number is lower than the thing that was scheduled next,\n\t\t\t\t\t// then back up and re-schedule any blocks in between to be effectively\n\t\t\t\t\t// the same time as they would have been flushed before.\n\t\t\t\t\tSteamNetworkingMicroseconds usecOldSched = m_receiverState.m_itPendingAck->second.m_usecWhenAckPrior;\n\t\t\t\t\twhile ( --m_receiverState.m_itPendingAck != itGap )\n\t\t\t\t\t{\n\t\t\t\t\t\tm_receiverState.m_itPendingAck->second.m_usecWhenAckPrior = usecOldSched;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\t// We're not the next thing that needs to be acked.\n\t\t\t\t\n\t\t\t\tif ( itGap->first < m_receiverState.m_itPendingAck->first )\n\t\t\t\t{\n\t\t\t\t\t// We're a lowered numbered packet,\tso this request is subsumed by the\n\t\t\t\t\t// request to flush more packets at an earlier time,\n\t\t\t\t\t// and we don't need to do anything.\n\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t{\n\n\t\t\t\t\t// We need to ack a bit earlier\n\t\t\t\t\titGap->second.m_usecWhenAckPrior = usecScheduleAck;\n\n\t\t\t\t\t// Now the only way for our invariants to be violated is for lower\n\t\t\t\t\t// numbered blocks to have later scheduled times.\n\t\t\t\t\tAssert( itGap != m_receiverState.m_mapPacketGaps.begin() );\n\t\t\t\t\twhile ( (--itGap)->second.m_usecWhenAckPrior > usecScheduleAck )\n\t\t\t\t\t{\n\t\t\t\t\t\tAssert( itGap != m_receiverState.m_mapPacketGaps.begin() );\n\t\t\t\t\t\titGap->second.m_usecWhenAckPrior = usecScheduleAck;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Make sure we didn't screw things up\n\t\t\tm_receiverState.DebugCheckPackGapMap();\n\t\t}\n\n\t\t// Make sure are scheduled to wake up\n\t\tif ( bScheduleAck )\n\t\t\tEnsureMinThinkTime( m_receiverState.TimeWhenFlushAcks() );\n\t}\n}\n\nint CSteamNetworkConnectionBase::SNP_ClampSendRate()\n{\n\t// Get effective clamp limits.  We clamp the limits themselves to be safe\n\t// and make sure they are sane\n\tint nMin = Clamp( m_connectionConfig.m_SendRateMin.Get(), 1024, 100*1024*1024 );\n\tint nMax = Clamp( m_connectionConfig.m_SendRateMax.Get(), nMin, 100*1024*1024 );\n\n\t// Clamp it, adjusting the value if it's out of range\n\tm_senderState.m_n_x = Clamp( m_senderState.m_n_x, nMin, nMax );\n\n\t// Return value\n\treturn m_senderState.m_n_x;\n}\n\n// Returns next think time\nSteamNetworkingMicroseconds CSteamNetworkConnectionBase::SNP_ThinkSendState( SteamNetworkingMicroseconds usecNow )\n{\n\t// Accumulate tokens based on how long it's been since last time\n\tSNP_ClampSendRate();\n\tSNP_TokenBucket_Accumulate( usecNow );\n\n\t// Calculate next time we want to take action.  If it isn't right now, then we're either idle or throttled.\n\t// Importantly, this will also check for retry timeout\n\tSteamNetworkingMicroseconds usecNextThink = SNP_GetNextThinkTime( usecNow );\n\tif ( usecNextThink > usecNow )\n\t\treturn usecNextThink;\n\n\t// Keep sending packets until we run out of tokens\n\tint nPacketsSent = 0;\n\twhile ( m_pTransport )\n\t{\n\n\t\tif ( nPacketsSent > k_nMaxPacketsPerThink )\n\t\t{\n\t\t\t// We're sending too much at one time.  Nuke token bucket so that\n\t\t\t// we'll be ready to send again very soon, but not immediately.\n\t\t\t// We don't want the outer code to complain that we are requesting\n\t\t\t// a wakeup call in the past\n\t\t\tm_senderState.m_flTokenBucket = m_senderState.m_n_x * -0.0005f;\n\t\t\treturn usecNow + 1000;\n\t\t}\n\n\t\t// Check if we have anything to send.\n\t\tif ( usecNow < m_receiverState.TimeWhenFlushAcks() && usecNow < SNP_TimeWhenWantToSendNextPacket() )\n\t\t{\n\n\t\t\t// We've sent everything we want to send.  Limit our reserve to a\n\t\t\t// small burst overage, in case we had built up an excess reserve\n\t\t\t// before due to the scheduler waking us up late.\n\t\t\tm_senderState.TokenBucket_Limit();\n\t\t\tbreak;\n\t\t}\n\n\t\t// Send the next data packet.\n\t\tif ( !m_pTransport->SendDataPacket( usecNow ) )\n\t\t{\n\t\t\t// Problem sending packet.  Nuke token bucket, but request\n\t\t\t// a wakeup relatively quick to check on our state again\n\t\t\tm_senderState.m_flTokenBucket = m_senderState.m_n_x * -0.001f;\n\t\t\treturn usecNow + 2000;\n\t\t}\n\n\t\t// We spent some tokens, do we have any left?\n\t\tif ( m_senderState.m_flTokenBucket < 0.0f )\n\t\t\tbreak;\n\n\t\t// Limit number of packets sent at a time, even if the scheduler is really bad\n\t\t// or somebody holds the lock for along time, or we wake up late for whatever reason\n\t\t++nPacketsSent;\n\t}\n\n\t// Return time when we need to check in again.\n\tSteamNetworkingMicroseconds usecNextAction = SNP_GetNextThinkTime( usecNow );\n\tAssert( usecNextAction > usecNow );\n\treturn usecNextAction;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_TokenBucket_Accumulate( SteamNetworkingMicroseconds usecNow )\n{\n\t// If we're not connected, just keep our bucket full\n\tif ( !BStateIsConnectedForWirePurposes() )\n\t{\n\t\tm_senderState.m_flTokenBucket = k_flSendRateBurstOverageAllowance;\n\t\tm_senderState.m_usecTokenBucketTime = usecNow;\n\t\treturn;\n\t}\n\n\tfloat flElapsed = ( usecNow - m_senderState.m_usecTokenBucketTime ) * 1e-6;\n\tm_senderState.m_flTokenBucket += (float)m_senderState.m_n_x * flElapsed;\n\tm_senderState.m_usecTokenBucketTime = usecNow;\n\n\t// If we don't currently have any packets ready to send right now,\n\t// then go ahead and limit the tokens.  If we do have packets ready\n\t// to send right now, then we must assume that we would be trying to\n\t// wakeup as soon as we are ready to send the next packet, and thus\n\t// any excess tokens we accumulate are because the scheduler woke\n\t// us up late, and we are not actually bursting\n\tif ( SNP_TimeWhenWantToSendNextPacket() > usecNow )\n\t\tm_senderState.TokenBucket_Limit();\n}\n\nvoid SSNPReceiverState::QueueFlushAllAcks( SteamNetworkingMicroseconds usecWhen )\n{\n\tDebugCheckPackGapMap();\n\n\tAssert( usecWhen > 0 ); // zero is reserved and should never be used as a requested wake time\n\n\t// if we're already scheduled for earlier, then there cannot be any work to do\n\tauto it = m_mapPacketGaps.end();\n\t--it;\n\tif ( it->second.m_usecWhenAckPrior <= usecWhen )\n\t\treturn;\n\tit->second.m_usecWhenAckPrior = usecWhen;\n\n\t// Nothing partial scheduled?\n\tif ( m_itPendingAck == it )\n\t\treturn;\n\n\tif ( m_itPendingAck->second.m_usecWhenAckPrior >= usecWhen )\n\t{\n\t\tdo\n\t\t{\n\t\t\tm_itPendingAck->second.m_usecWhenAckPrior = INT64_MAX;\n\t\t\t++m_itPendingAck;\n\t\t} while ( m_itPendingAck != it );\n\t\tDebugCheckPackGapMap();\n\t}\n\telse\n\t{\n\t\t// Maintain invariant\n\t\twhile ( (--it)->second.m_usecWhenAckPrior >= usecWhen )\n\t\t\tit->second.m_usecWhenAckPrior = usecWhen;\n\t\tDebugCheckPackGapMap();\n\t}\n}\n\n#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 1\nvoid SSNPReceiverState::DebugCheckPackGapMap() const\n{\n\tint64 nPrevEnd = 0;\n\tSteamNetworkingMicroseconds usecPrevAck = 0;\n\tbool bFoundPendingAck = false;\n\tfor ( auto it: m_mapPacketGaps )\n\t{\n\t\tAssert( it.first > nPrevEnd );\n\t\tif ( it.first == m_itPendingAck->first )\n\t\t{\n\t\t\tAssert( !bFoundPendingAck );\n\t\t\tbFoundPendingAck = true;\n\t\t\tif ( it.first < INT64_MAX )\n\t\t\t\tAssert( it.second.m_usecWhenAckPrior < INT64_MAX );\n\t\t}\n\t\telse if ( !bFoundPendingAck )\n\t\t{\n\t\t\tAssert( it.second.m_usecWhenAckPrior == INT64_MAX );\n\t\t}\n\t\telse\n\t\t{\n\t\t\tAssert( it.second.m_usecWhenAckPrior >= usecPrevAck );\n\t\t}\n\t\tusecPrevAck = it.second.m_usecWhenAckPrior;\n\t\tif ( it.first == INT64_MAX )\n\t\t{\n\t\t\tAssert( it.second.m_nEnd == INT64_MAX );\n\t\t}\n\t\telse\n\t\t{\n\t\t\tAssert( it.first < it.second.m_nEnd );\n\t\t}\n\t\tnPrevEnd = it.second.m_nEnd;\n\t}\n\tAssert( nPrevEnd == INT64_MAX );\n}\n#endif\n\nSteamNetworkingMicroseconds CSteamNetworkConnectionBase::SNP_TimeWhenWantToSendNextPacket() const\n{\n\t// We really shouldn't be trying to do this when not connected\n\tif ( !BStateIsConnectedForWirePurposes() )\n\t{\n\t\tAssertMsg( false, \"We shouldn't be asking about sending packets when not fully connected\" );\n\t\treturn k_nThinkTime_Never;\n\t}\n\n\t// Reliable triggered?  Then send it right now\n\tif ( !m_senderState.m_listReadyRetryReliableRange.empty() )\n\t\treturn 0;\n\n\t// Anything queued?\n\tSteamNetworkingMicroseconds usecNextSend;\n\tif ( m_senderState.m_messagesQueued.empty() )\n\t{\n\n\t\t// Queue is empty, nothing to send except perhaps nacks (below)\n\t\tAssert( m_senderState.PendingBytesTotal() == 0 );\n\t\tusecNextSend = INT64_MAX;\n\t}\n\telse\n\t{\n\n\t\t// FIXME acks, stop_waiting?\n\n\t\t// Have we got at least a full packet ready to go?\n\t\tif ( m_senderState.PendingBytesTotal() >= m_cbMaxPlaintextPayloadSend )\n\t\t\t// Send it ASAP\n\t\t\treturn 0;\n\n\t\t// We have less than a full packet's worth of data.  Wait until\n\t\t// the Nagle time, if we have one\n\t\tusecNextSend = m_senderState.m_messagesQueued.m_pFirst->SNPSend_UsecNagle();\n\t}\n\n\t// Check if the receiver wants to send a NACK.\n\tusecNextSend = std::min( usecNextSend, m_receiverState.m_itPendingNack->second.m_usecWhenOKToNack );\n\n\t// Return the earlier of the two\n\treturn usecNextSend;\n}\n\nSteamNetworkingMicroseconds CSteamNetworkConnectionBase::SNP_GetNextThinkTime( SteamNetworkingMicroseconds usecNow )\n{\n\t// We really shouldn't be trying to do this when not connected\n\tif ( !BStateIsConnectedForWirePurposes() )\n\t{\n\t\tAssertMsg( false, \"We shouldn't be trying to think SNP when not fully connected\" );\n\t\treturn k_nThinkTime_Never;\n\t}\n\n\t// We cannot send any packets if we don't have transport\n\tif ( !m_pTransport )\n\t\treturn k_nThinkTime_Never;\n\n\t// Start with the time when the receiver needs to flush out ack.\n\tSteamNetworkingMicroseconds usecNextThink = m_receiverState.TimeWhenFlushAcks();\n\n\t// Check retransmit timers.  If they have expired, this will move reliable\n\t// segments into the \"ready to retry\" list, which will cause\n\t// TimeWhenWantToSendNextPacket to think we want to send data.  If nothing has timed out,\n\t// it will return the time when we need to check back in.  Or, if everything is idle it will\n\t// return \"never\" (very large number).\n\tSteamNetworkingMicroseconds usecNextRetry = SNP_SenderCheckInFlightPackets( usecNow );\n\n\t// If we want to send packets, then we might need to wake up and take action\n\tSteamNetworkingMicroseconds usecTimeWantToSend = SNP_TimeWhenWantToSendNextPacket();\n\tusecTimeWantToSend = std::min( usecNextRetry, usecTimeWantToSend );\n\tif ( usecTimeWantToSend < usecNextThink )\n\t{\n\n\t\t// Time when we *could* send the next packet, ignoring Nagle\n\t\tSteamNetworkingMicroseconds usecNextSend = usecNow;\n\t\tSteamNetworkingMicroseconds usecQueueTime = m_senderState.CalcTimeUntilNextSend();\n\t\tif ( usecQueueTime > 0 )\n\t\t{\n\t\t\tusecNextSend += usecQueueTime;\n\n\t\t\t// Add a small amount of fudge here, so that we don't wake up too early and think\n\t\t\t// we're not ready yet, causing us to spin our wheels.  Our token bucket system\n\t\t\t// should keep us sending at the correct overall rate.  Remember that the\n\t\t\t// underlying kernel timer/wake resolution might be 1 or 2ms, (E.g. Windows.)\n\t\t\tusecNextSend += 25;\n\t\t}\n\n\t\t// Time when we will next send is the greater of when we want to and when we can\n\t\tusecNextSend = std::max( usecNextSend, usecTimeWantToSend );\n\n\t\t// Earlier than any other reason to wake up?\n\t\tusecNextThink = std::min( usecNextThink, usecNextSend );\n\t}\n\n\treturn usecNextThink;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_PopulateDetailedStats( SteamDatagramLinkStats &info )\n{\n\tinfo.m_latest.m_nSendRate = SNP_ClampSendRate();\n\tinfo.m_latest.m_nPendingBytes = m_senderState.m_cbPendingUnreliable + m_senderState.m_cbPendingReliable;\n\tinfo.m_lifetime.m_nMessagesSentReliable    = m_senderState.m_nMessagesSentReliable;\n\tinfo.m_lifetime.m_nMessagesSentUnreliable  = m_senderState.m_nMessagesSentUnreliable;\n\tinfo.m_lifetime.m_nMessagesRecvReliable    = m_receiverState.m_nMessagesRecvReliable;\n\tinfo.m_lifetime.m_nMessagesRecvUnreliable  = m_receiverState.m_nMessagesRecvUnreliable;\n}\n\nvoid CSteamNetworkConnectionBase::SNP_PopulateQuickStats( SteamNetworkingQuickConnectionStatus &info, SteamNetworkingMicroseconds usecNow )\n{\n\tinfo.m_nSendRateBytesPerSecond = SNP_ClampSendRate();\n\tinfo.m_cbPendingUnreliable = m_senderState.m_cbPendingUnreliable;\n\tinfo.m_cbPendingReliable = m_senderState.m_cbPendingReliable;\n\tinfo.m_cbSentUnackedReliable = m_senderState.m_cbSentUnackedReliable;\n\tif ( GetState() == k_ESteamNetworkingConnectionState_Connected )\n\t{\n\n\t\t// Accumulate tokens so that we can properly predict when the next time we'll be able to send something is\n\t\tSNP_TokenBucket_Accumulate( usecNow );\n\n\t\t//\n\t\t// Time until we can send the next packet\n\t\t// If anything is already queued, then that will have to go out first.  Round it down\n\t\t// to the nearest packet.\n\t\t//\n\t\t// NOTE: This ignores the precise details of SNP framing.  If there are tons of\n\t\t// small packets, it'll actually be worse.  We might be able to approximate that\n\t\t// the framing overhead better by also counting up the number of *messages* pending.\n\t\t// Probably not worth it here, but if we had that number available, we'd use it.\n\t\tint cbPendingTotal = m_senderState.PendingBytesTotal() / m_cbMaxMessageNoFragment * m_cbMaxMessageNoFragment;\n\n\t\t// Adjust based on how many tokens we have to spend now (or if we are already\n\t\t// over-budget and have to wait until we could spend another)\n\t\tcbPendingTotal -= (int)m_senderState.m_flTokenBucket;\n\t\tif ( cbPendingTotal <= 0 )\n\t\t{\n\t\t\t// We could send it right now.\n\t\t\tinfo.m_usecQueueTime = 0;\n\t\t}\n\t\telse\n\t\t{\n\n\t\t\tinfo.m_usecQueueTime = (int64)cbPendingTotal * k_nMillion / SNP_ClampSendRate();\n\t\t}\n\t}\n\telse\n\t{\n\t\t// We'll never be able to send it.  (Or, we don't know when that will be.)\n\t\tinfo.m_usecQueueTime = INT64_MAX;\n\t}\n}\n\n} // namespace SteamNetworkingSocketsLib\n", "//====== Copyright Valve Corporation, All rights reserved. ====================\n\n#pragma once\n\n#include \"../steamnetworkingsockets_internal.h\"\n#include <vector>\n#include <map>\n#include <set>\n\n// Set paranoia level, if not already set:\n// 0 = disabled\n// 1 = sometimes\n// 2 = max\n#ifndef STEAMNETWORKINGSOCKETS_SNP_PARANOIA\n\t#ifdef _DEBUG\n\t\t#define STEAMNETWORKINGSOCKETS_SNP_PARANOIA 2\n\t#else\n\t\t#define STEAMNETWORKINGSOCKETS_SNP_PARANOIA 0\n\t#endif\n#endif\n\n#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 0\n\t#if defined(__GNUC__ ) && defined( __linux__ ) && !defined( __ANDROID__ )\n\t\t#include <debug/map>\n\t\t// FIXME use debug versions\n\t\ttemplate< typename K, typename V, typename L = std::less<K> >\n\t\tusing std_map = __gnu_debug::map<K,V,L>;\n\n\t\ttemplate <typename K, typename V, typename L>\n\t\tinline int len( const std_map<K,V,L> &map )\n\t\t{\n\t\t\treturn (int)map.size();\n\t\t}\n\n\t#else\n\t\ttemplate< typename K, typename V, typename L = std::less<K> >\n\t\tusing std_map = std::map<K,V,L>;\n\t#endif\n#else\n\ttemplate< typename K, typename V, typename L = std::less<K> >\n\tusing std_map = std::map<K,V,L>;\n#endif\n\nstruct P2PSessionState_t;\n\nnamespace SteamNetworkingSocketsLib {\n\n// Acks may be delayed.  This controls the precision used on the wire to encode the delay time.\nconstexpr int k_nAckDelayPrecisionShift = 5;\nconstexpr SteamNetworkingMicroseconds k_usecAckDelayPrecision = (1 << k_nAckDelayPrecisionShift );\n\n// When a receiver detects a dropped packet, wait a bit before NACKing it, to give it time\n// to arrive out of order.  This is really important for many different types of connections\n// that send on different channels, e.g. DSL, Wifi.\n// Here we really could be smarter, by tracking how often dropped\n// packets really do arrive out of order.  If the rate is low, then it's\n// probably best to go ahead and send a NACK now, rather than waiting.\n// But if dropped packets do often arrive out of order, then waiting\n// to NACK will probably save some retransmits.  In fact, instead\n// of learning the rate, we should probably try to learn the delay.\n// E.g. a probability distribution P(t), which describes the odds\n// that a dropped packet will have arrived at time t.  Then you\n// adjust the NACK delay such that P(nack_delay) gives the best\n// balance between false positive and false negative rates.\nconstexpr SteamNetworkingMicroseconds k_usecNackFlush = 3*1000;\n\n// Max size of a message that we are wiling to *receive*.\nconstexpr int k_cbMaxMessageSizeRecv = k_cbMaxSteamNetworkingSocketsMessageSizeSend*2;\n\n// The max we will look ahead and allocate data, ahead of the reliable\n// messages we have been able to decode.  We limit this to make sure that\n// a malicious sender cannot exploit us.\nconstexpr int k_cbMaxBufferedReceiveReliableData = k_cbMaxMessageSizeRecv + 64*1024;\nconstexpr int k_nMaxReliableStreamGaps_Extend = 30; // Discard reliable data past the end of the stream, if it would cause us to get too many gaps\nconstexpr int k_nMaxReliableStreamGaps_Fragment = 20; // Discard reliable data that is filling in the middle of a hole, if it would cause the number of gaps to exceed this number\nconstexpr int k_nMaxPacketGaps = 62; // Don't bother tracking more than N gaps.  Instead, we will end up NACKing some packets that we actually did receive.  This should not break the protocol, but it protects us from malicious sender\n\n// Hang on to at most N unreliable segments.  When packets are dropping\n// and unreliable messages being fragmented, we will accumulate old pieces\n// of unreliable messages that we retain in hopes that we will get the\n// missing piece and reassemble the whole message.  At a certain point we\n// must give up and discard them.  We use a simple strategy of just limiting\n// the max total number.  In reality large unreliable messages are just a very bad\n// idea, since the odds of the message dropping increase exponentially with the\n// number of packets.  With 20 packets, even 1% packet loss becomes ~80% message\n// loss.  (Assuming naive fragmentation and reassembly and no forward\n// error correction.)\nconstexpr int k_nMaxBufferedUnreliableSegments = 20;\n\n// If app tries to send a message larger than N bytes unreliably,\n// complain about it, and automatically convert to reliable.\n// About 15 segments.\nconstexpr int k_cbMaxUnreliableMsgSizeSend = 15*1100;\n\n// Max possible size of an unreliable segment we could receive.\nconstexpr int k_cbMaxUnreliableSegmentSizeRecv = k_cbSteamNetworkingSocketsMaxPlaintextPayloadRecv;\n\n// Largest possible total unreliable message we can receive, based on the constraints above\nconstexpr int k_cbMaxUnreliableMsgSizeRecv = k_nMaxBufferedUnreliableSegments*k_cbMaxUnreliableSegmentSizeRecv;\nCOMPILE_TIME_ASSERT( k_cbMaxUnreliableMsgSizeRecv > k_cbMaxUnreliableMsgSizeSend + 4096 ); // Postel's law; confirm how much slack we have here\n\nclass CSteamNetworkConnectionBase;\nclass CConnectionTransport;\nstruct SteamNetworkingMessageQueue;\n\n/// Actual implementation of SteamNetworkingMessage_t, which is the API\n/// visible type.  Has extra fields needed to put the message into intrusive\n/// linked lists.\nclass CSteamNetworkingMessage : public SteamNetworkingMessage_t\n{\npublic:\n\tstatic CSteamNetworkingMessage *New( CSteamNetworkConnectionBase *pParent, uint32 cbSize, int64 nMsgNum, int nFlags, SteamNetworkingMicroseconds usecNow );\n\tstatic CSteamNetworkingMessage *New( uint32 cbSize );\n\tstatic void DefaultFreeData( SteamNetworkingMessage_t *pMsg );\n\n\t/// OK to delay sending this message until this time.  Set to zero to explicitly force\n\t/// Nagle timer to expire and send now (but this should behave the same as if the\n\t/// timer < usecNow).  If the timer is cleared, then all messages with lower message numbers\n\t/// are also cleared.\n\tinline SteamNetworkingMicroseconds SNPSend_UsecNagle() const { return m_usecTimeReceived; }\n\tinline void SNPSend_SetUsecNagle( SteamNetworkingMicroseconds x ) { m_usecTimeReceived = x; }\n\n\t/// Offset in reliable stream of the header byte.  0 if we're not reliable.\n\tinline int64 SNPSend_ReliableStreamPos() const { return m_nConnUserData; }\n\tinline void SNPSend_SetReliableStreamPos( int64 x ) { m_nConnUserData = x; }\n\tinline int SNPSend_ReliableStreamSize() const\n\t{\n\t\tDbgAssert( m_nFlags & k_nSteamNetworkingSend_Reliable && m_nConnUserData > 0 && m_cbSNPSendReliableHeader > 0 && m_cbSize >= m_cbSNPSendReliableHeader );\n\t\treturn m_cbSize;\n\t}\n\n\tinline bool SNPSend_IsReliable() const\n\t{\n\t\tif ( m_nFlags & k_nSteamNetworkingSend_Reliable )\n\t\t{\n\t\t\tDbgAssert( m_nConnUserData > 0 && m_cbSNPSendReliableHeader > 0 && m_cbSize >= m_cbSNPSendReliableHeader );\n\t\t\treturn true;\n\t\t}\n\t\tDbgAssert( m_nConnUserData == 0 && m_cbSNPSendReliableHeader == 0 );\n\t\treturn false;\n\t}\n\n\t// Reliable stream header\n\tint m_cbSNPSendReliableHeader;\n\tbyte *SNPSend_ReliableHeader()\n\t{\n\t\t// !KLUDGE! Reuse the peer identity to hold the reliable header\n\t\treturn (byte*)&m_identityPeer;\n\t}\n\n\t/// Remove it from queues\n\tvoid Unlink();\n\n\tstruct Links\n\t{\n\t\tSteamNetworkingMessageQueue *m_pQueue;\n\t\tCSteamNetworkingMessage *m_pPrev;\n\t\tCSteamNetworkingMessage *m_pNext;\n\n\t\tinline void Clear() { m_pQueue = nullptr; m_pPrev = nullptr; m_pNext = nullptr; }\n\t};\n\n\t/// Intrusive links for the \"primary\" list we are in\n\tLinks m_links;\n\n\t/// Intrusive links for any secondary list we may be in.  (Same listen socket or\n\t/// P2P channel, depending on message type)\n\tLinks m_linksSecondaryQueue;\n\n\tvoid LinkBefore( CSteamNetworkingMessage *pSuccessor, Links CSteamNetworkingMessage::*pMbrLinks, SteamNetworkingMessageQueue *pQueue );\n\tvoid LinkToQueueTail( Links CSteamNetworkingMessage::*pMbrLinks, SteamNetworkingMessageQueue *pQueue );\n\tvoid UnlinkFromQueue( Links CSteamNetworkingMessage::*pMbrLinks );\n\nprivate:\n\t// Use New and Release()!!\n\tinline CSteamNetworkingMessage() {}\n\tinline ~CSteamNetworkingMessage() {}\n\tstatic void ReleaseFunc( SteamNetworkingMessage_t *pIMsg );\n};\n\n/// A doubly-linked list of CSteamNetworkingMessage\nstruct SteamNetworkingMessageQueue\n{\n\tCSteamNetworkingMessage *m_pFirst = nullptr;\n\tCSteamNetworkingMessage *m_pLast = nullptr;\n\n\tinline bool empty() const\n\t{\n\t\tif ( m_pFirst )\n\t\t{\n\t\t\tAssert( m_pLast );\n\t\t\treturn false;\n\t\t}\n\t\tAssert( !m_pLast );\n\t\treturn true;\n\t}\n\n\t/// Remove the first messages out of the queue (up to nMaxMessages).  Returns the number returned\n\tint RemoveMessages( SteamNetworkingMessage_t **ppOutMessages, int nMaxMessages );\n\n\t/// Delete all queued messages\n\tvoid PurgeMessages();\n};\n\n/// Maximum number of packets we will send in one Think() call.\nconst int k_nMaxPacketsPerThink = 16;\n\n/// Max number of tokens we are allowed to store up in reserve, for a burst.\nconst float k_flSendRateBurstOverageAllowance = k_cbSteamNetworkingSocketsMaxEncryptedPayloadSend;\n\nstruct SNPRange_t\n{\n\t/// Byte or sequence number range\n\tint64 m_nBegin;\n\tint64 m_nEnd; // STL-style.  It's one past the end\n\n\tinline int64 length() const\n\t{\n\t\t// In general, allow zero-length ranges, but not negative ones\n\t\tAssert( m_nEnd >= m_nBegin );\n\t\treturn m_nEnd - m_nBegin;\n\t}\n\n\t/// Strict comparison function.  This is used in situations where\n\t/// ranges must not overlap, AND we also never search for\n\t/// a range that might overlap.\n\tstruct NonOverlappingLess\n\t{\n\t\tinline bool operator ()(const SNPRange_t &l, const SNPRange_t &r ) const\n\t\t{\n\t\t\tif ( l.m_nBegin < r.m_nBegin ) return true;\n\t\t\tAssertMsg( l.m_nBegin > r.m_nBegin || l.m_nEnd == r.m_nEnd, \"Ranges should not overlap in this map!\" );\n\t\t\treturn false;\n\t\t}\n\t};\n};\n\n/// A packet that has been sent but we don't yet know if was received\n/// or dropped.  These are kept in an ordered map keyed by packet number.\n/// (Hence the packet number not being a member)  When we receive an ACK,\n/// we remove packets from this list.\nstruct SNPInFlightPacket_t\n{\n\t//\n\t// FIXME - Could definitely pack this structure better.  And maybe\n\t//         worth it to optimize cache\n\t//\n\n\t/// Local timestamp when we sent it\n\tSteamNetworkingMicroseconds m_usecWhenSent;\n\n\t/// Did we get an ack block from peer that explicitly marked this\n\t/// packet as being skipped?  Note that we might subsequently get an\n\t/// an ack for this same packet, that's OK!\n\tbool m_bNack;\n\n\t/// Transport used to send\n\tCConnectionTransport *m_pTransport;\n\n\t/// List of reliable segments.  Ignoring retransmission,\n\t/// there really is no reason why we we would need to have\n\t/// more than 1 in a packet, even if there are multiple\n\t/// reliable messages.  If we need to retry, we might\n\t/// be fragmented.  But usually it will only be a few.\n\tvstd::small_vector<SNPRange_t,1> m_vecReliableSegments;\n};\n\nstruct SSNPSendMessageList : public SteamNetworkingMessageQueue\n{\n\n\t/// Unlink the message at the head, if any and return it.\n\t/// Unlike STL pop_front, this will return nullptr if the\n\t/// list is empty\n\tCSteamNetworkingMessage *pop_front()\n\t{\n\t\tCSteamNetworkingMessage *pResult = m_pFirst;\n\t\tif ( pResult )\n\t\t{\n\t\t\tAssert( m_pLast );\n\t\t\tAssert( pResult->m_links.m_pQueue == this );\n\t\t\tAssert( pResult->m_links.m_pPrev == nullptr );\n\t\t\tm_pFirst = pResult->m_links.m_pNext;\n\t\t\tif ( m_pFirst )\n\t\t\t{\n\t\t\t\tAssert( m_pFirst->m_links.m_pPrev == pResult );\n\t\t\t\tAssert( m_pFirst->m_nMessageNumber > pResult->m_nMessageNumber );\n\t\t\t\tm_pFirst->m_links.m_pPrev = nullptr;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tAssert( m_pLast == pResult );\n\t\t\t\tm_pLast = nullptr;\n\t\t\t}\n\t\t\tpResult->m_links.m_pQueue = nullptr;\n\t\t\tpResult->m_links.m_pNext = nullptr;\n\t\t}\n\t\treturn pResult;\n\t}\n\n\t/// Optimized insertion when we know it goes at the end\n\tvoid push_back( CSteamNetworkingMessage *pMsg )\n\t{\n\t\tif ( m_pFirst == nullptr )\n\t\t{\n\t\t\tAssert( m_pLast == nullptr );\n\t\t\tm_pFirst = pMsg;\n\t\t}\n\t\telse\n\t\t{\n\t\t\t// Messages are always kept in message number order\n\t\t\tAssert( pMsg->m_nMessageNumber > m_pLast->m_nMessageNumber );\n\t\t\tAssert( m_pLast->m_links.m_pNext == nullptr );\n\t\t\tm_pLast->m_links.m_pNext = pMsg;\n\t\t}\n\t\tpMsg->m_links.m_pQueue = this;\n\t\tpMsg->m_links.m_pNext = nullptr;\n\t\tpMsg->m_links.m_pPrev = m_pLast;\n\t\tm_pLast = pMsg;\n\t}\n\n};\n\nstruct SSNPSenderState\n{\n\tSSNPSenderState();\n\t~SSNPSenderState() {\n\t\tShutdown();\n\t}\n\tvoid Shutdown();\n\n\t/// Current sending rate in bytes per second, RFC 3448 4.2 states default\n\t/// is one packet per second, but that is insane and we're not doing that.\n\t/// In most cases we will set a default based on initial ping, so this is\n\t/// only rarely used.\n\tint m_n_x = 32*1024;\n\n\t/// If >=0, then we can send a full packet right now.  We allow ourselves to \"store up\"\n\t/// about 1 packet worth of \"reserve\".  In other words, if we have not sent any packets\n\t/// for a while, basically we allow ourselves to send two packets in rapid succession,\n\t/// thus \"bursting\" over the limit by 1 packet.  That long term rate will be clamped by\n\t/// the send rate.\n\t///\n\t/// If <0, then we are currently \"over\" our rate limit and need to wait before we can\n\t/// send a packet.\n\t///\n\t/// Provision for accumulating \"credits\" and burst allowance, to account for lossy\n\t/// kernel scheduler, etc is mentioned in RFC 5348, section 4.6.\n\tfloat m_flTokenBucket = 0;\n\n\t/// Last time that we added tokens to m_flTokenBucket\n\tSteamNetworkingMicroseconds m_usecTokenBucketTime = 0;\n\n\tvoid TokenBucket_Init( SteamNetworkingMicroseconds usecNow )\n\t{\n\t\tm_usecTokenBucketTime = usecNow;\n\t\tm_flTokenBucket = k_flSendRateBurstOverageAllowance;\n\t}\n\n\t/// Limit our token bucket to the max reserve amount\n\tvoid TokenBucket_Limit()\n\t{\n\t\tif ( m_flTokenBucket > k_flSendRateBurstOverageAllowance )\n\t\t\tm_flTokenBucket = k_flSendRateBurstOverageAllowance;\n\t}\n\n\t/// Calculate time until we could send our next packet, checking our token\n\t/// bucket and the current send rate\n\tSteamNetworkingMicroseconds CalcTimeUntilNextSend() const\n\t{\n\t\t// Do we have tokens to burn right now?\n\t\tif ( m_flTokenBucket >= 0.0f )\n\t\t\treturn 0;\n\n\t\treturn SteamNetworkingMicroseconds( m_flTokenBucket * -1e6f / (float)m_n_x ) + 1; // +1 to make sure that if we don't have any tokens, we never return 0, since zero means \"ready right now\"\n\t}\n\n\t/// Nagle timer on all pending messages\n\tvoid ClearNagleTimers()\n\t{\n\t\tCSteamNetworkingMessage *pMsg = m_messagesQueued.m_pLast;\n\t\twhile ( pMsg && pMsg->SNPSend_UsecNagle() )\n\t\t{\n\t\t\tpMsg->SNPSend_SetUsecNagle( 0 );\n\t\t\tpMsg = pMsg->m_links.m_pPrev;\n\t\t}\n\t}\n\n\t// Current message number, we ++ when adding a message\n\tint64 m_nReliableStreamPos = 1;\n\tint64 m_nLastSentMsgNum = 0; // Will increment to 1 with first message\n\tint64 m_nLastSendMsgNumReliable = 0;\n\n\t/// List of messages that we have not yet finished putting on the wire the first time.\n\t/// The Nagle timer may be active on one or more, but if so, it is only on messages\n\t/// at the END of the list.  The first message may be partially sent.\n\tSSNPSendMessageList m_messagesQueued;\n\n\t/// How many bytes into the first message in the queue have we put on the wire?\n\tint m_cbCurrentSendMessageSent = 0;\n\n\t/// List of reliable messages that have been fully placed on the wire at least once,\n\t/// but we're hanging onto because of the potential need to retry.  (Note that if we get\n\t/// packet loss, it's possible that we hang onto a message even after it's been fully\n\t/// acked, because a prior message is still needed.  We always operate on this list\n\t/// like a queue, rather than seeking into the middle of the list and removing messages\n\t/// as soon as they are no longer needed.)\n\tSSNPSendMessageList m_unackedReliableMessages;\n\n\t// Buffered data counters.  See SteamNetworkingQuickConnectionStatus for more info\n\tint m_cbPendingUnreliable = 0;\n\tint m_cbPendingReliable = 0;\n\tint m_cbSentUnackedReliable = 0;\n\tinline int PendingBytesTotal() const { return m_cbPendingUnreliable + m_cbPendingReliable; }\n\n\t// Stats.  FIXME - move to LinkStatsEndToEnd and track rate counters\n\tint64 m_nMessagesSentReliable = 0;\n\tint64 m_nMessagesSentUnreliable = 0;\n\n\t/// List of packets that we have sent but don't know whether they were received or not.\n\t/// We keep a dummy sentinel at the head of the list, with a negative packet number.\n\t/// This vastly simplifies the processing.\n\tstd_map<int64,SNPInFlightPacket_t> m_mapInFlightPacketsByPktNum;\n\n\t/// The next unacked packet that should be timed out and implicitly NACKed,\n\t/// if we don't receive an ACK in time.  Will be m_mapInFlightPacketsByPktNum.end()\n\t/// if we don't have any in flight packets that we are waiting on.\n\tstd_map<int64,SNPInFlightPacket_t>::iterator m_itNextInFlightPacketToTimeout;\n\n\t/// Ordered list of reliable ranges that we have recently sent\n\t/// in a packet.  These should be non-overlapping, and furthermore\n\t/// should not overlap with with any range in m_listReadyReliableRange\n\t///\n\t/// The \"value\" portion of the map is the message that has the first bit of\n\t/// reliable data we need for this message\n\tstd_map<SNPRange_t,CSteamNetworkingMessage*,SNPRange_t::NonOverlappingLess> m_listInFlightReliableRange;\n\n\t/// Ordered list of ranges that have been put on the wire,\n\t/// but have been detected as dropped, and now need to be retried.\n\tstd_map<SNPRange_t,CSteamNetworkingMessage*,SNPRange_t::NonOverlappingLess> m_listReadyRetryReliableRange;\n\n\t/// Oldest packet sequence number that we are still asking peer\n\t/// to send acks for.\n\tint64 m_nMinPktWaitingOnAck = 0;\n\n\t// Remove messages from m_unackedReliableMessages that have been fully acked.\n\tvoid RemoveAckedReliableMessageFromUnackedList();\n\n\t/// Check invariants in debug.\n\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA == 0 \n\t\tinline void DebugCheckInFlightPacketMap() const {}\n\t#else\n\t\tvoid DebugCheckInFlightPacketMap() const;\n\t#endif\n\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 1\n\t\tinline void MaybeCheckInFlightPacketMap() const { DebugCheckInFlightPacketMap(); }\n\t#else\n\t\tinline void MaybeCheckInFlightPacketMap() const {}\n\t#endif\n};\n\nstruct SSNPRecvUnreliableSegmentKey\n{\n\tint64 m_nMsgNum;\n\tint m_nOffset;\n\n\tinline bool operator<(const SSNPRecvUnreliableSegmentKey &x) const\n\t{\n\t\tif ( m_nMsgNum < x.m_nMsgNum ) return true;\n\t\tif ( m_nMsgNum > x.m_nMsgNum ) return false;\n\t\treturn m_nOffset < x.m_nOffset;\n\t}\n};\n\nstruct SSNPRecvUnreliableSegmentData\n{\n\tint m_cbSegSize = -1;\n\tbool m_bLast = false;\n\tchar m_buf[ k_cbMaxUnreliableSegmentSizeRecv ];\n};\n\nstruct SSNPPacketGap\n{\n\tint64 m_nEnd; // just after the last packet received\n\tSteamNetworkingMicroseconds m_usecWhenReceivedPktBefore; // So we can send RTT data in our acks\n\tSteamNetworkingMicroseconds m_usecWhenAckPrior; // We need to send an ack for everything with lower packet numbers than this gap by this time.  (Earlier is OK.)\n\tSteamNetworkingMicroseconds m_usecWhenOKToNack; // Don't give up on the gap being filed before this time\n};\n\nstruct SSNPReceiverState\n{\n\tSSNPReceiverState();\n\t~SSNPReceiverState() {\n\t\tShutdown();\n\t}\n\tvoid Shutdown();\n\n\t/// Unreliable message segments that we have received.  When an unreliable message\n\t/// needs to be fragmented, we store the pieces here.  NOTE: it might be more efficient\n\t/// to use a simpler container, with worse O(), since this should ordinarily be\n\t/// a pretty small list.\n\tstd_map<SSNPRecvUnreliableSegmentKey,SSNPRecvUnreliableSegmentData> m_mapUnreliableSegments;\n\n\t/// Stream position of the first byte in m_bufReliableData.  Remember that the first byte\n\t/// in the reliable stream is actually at position 1, not 0\n\tint64 m_nReliableStreamPos = 1;\n\n\t/// The highest message number we have seen so far.\n\tint64 m_nHighestSeenMsgNum = 0;\n\n\t/// The message number of the most recently received reliable message\n\tint64 m_nLastRecvReliableMsgNum = 0;\n\n\t/// Reliable data stream that we have received.  This might have gaps in it!\n\tstd::vector<byte> m_bufReliableStream;\n\n\t/// Gaps in the reliable data.  These are created when we receive reliable data that\n\t/// is beyond what we expect next.  Since these must never overlap, we store them\n\t/// using begin as the key and end as the value.\n\t///\n\t/// !SPEED! We should probably use a small fixed-sized, sorted vector here,\n\t/// since in most cases the list will be small, and the cost of dynamic memory\n\t/// allocation will be way worse than O(n) insertion/removal.\n\tstd_map<int64,int64> m_mapReliableStreamGaps;\n\n\t/// List of gaps in the packet sequence numbers we have received.\n\t/// Since these must never overlap, we store them using begin as the\n\t/// key and the end in the value.\n\t///\n\t/// The last item in the list is a sentinel with\n\t/// begin and end set to INT64_MAX, and m_usecWhenAckPrior is\n\t/// the time when we need to flush acks/backs for all packets,\n\t/// including those received after the last gap (if any --\n\t/// INT64_MAX means nothing scheduled).  Remember, our wire\n\t/// protocol cannot report on packet N without also reporting\n\t/// on all packets numbered < N.\n\t///\n\t/// !SPEED! We should probably use a small fixed-sized, sorted vector here,\n\t/// since in most cases the list will be small, and the cost of dynamic memory\n\t/// allocation will be way worse than O(n) insertion/removal.\n\tstd_map<int64,SSNPPacketGap> m_mapPacketGaps;\n\n\t/// Oldest packet sequence number we need to ack to our peer\n\tint64 m_nMinPktNumToSendAcks = 0;\n\n\t/// Packet number when we received the value of m_nMinPktNumToSendAcks\n\tint64 m_nPktNumUpdatedMinPktNumToSendAcks = 0;\n\n\t/// The next ack that needs to be sent.  The invariant\n\t/// for the times are:\n\t///\n\t/// * Blocks with lower packet numbers: m_usecWhenAckPrior = INT64_MAX\n\t/// * This block: m_usecWhenAckPrior < INT64_MAX, or we are the sentinel\n\t/// * Blocks with higher packet numbers (if we are not the sentinel): m_usecWhenAckPrior >= previous m_usecWhenAckPrior\n\t///\n\t/// We might send acks before they are due, rather than\n\t/// waiting until the last moment!  If we are going to\n\t/// send a packet at all, we usually try to send at least\n\t/// a few acks, and if there is room in the packet, as\n\t/// many as will fit.  The one exception is that if\n\t/// sending an ack would imply a NACK that we don't want to\n\t/// send yet.  (Remember the restrictions on what we are able\n\t/// to communicate due to the tight RLE encoding of the wire\n\t/// format.)  These delays are usually very short lived, and\n\t/// only happen when there is packet loss, so they don't delay\n\t/// acks very much.  The whole purpose of this rather involved\n\t/// bookkeeping is to figure out which acks we *need* to send,\n\t/// and which acks we cannot send yet, so we can make optimal\n\t/// decisions.\n\tstd_map<int64,SSNPPacketGap>::iterator m_itPendingAck;\n\n\t/// Iterator into m_mapPacketGaps.  If != the sentinel,\n\t/// we will avoid reporting on the dropped packets in this\n\t/// gap (and all higher numbered packets), because we are\n\t/// waiting in the hopes that they will arrive out of order.\n\tstd_map<int64,SSNPPacketGap>::iterator m_itPendingNack;\n\n\t/// Queue a flush of ALL acks (and NACKs!) by the given time.\n\t/// If anything is scheduled to happen earlier, that schedule\n\t/// will still be honered.  We will ack up to that packet number,\n\t/// and then we we may report higher numbered blocks, or we may\n\t/// stop and wait to report more acks until later.\n\tvoid QueueFlushAllAcks( SteamNetworkingMicroseconds usecWhen );\n\n\t/// Return the time when we need to flush out acks, or INT64_MAX\n\t/// if we don't have any acks pending right now.\n\tinline SteamNetworkingMicroseconds TimeWhenFlushAcks() const\n\t{\n\t\t// Paranoia\n\t\tif ( m_mapPacketGaps.empty() )\n\t\t{\n\t\t\tAssertMsg( false, \"TimeWhenFlushAcks - we're shut down!\" );\n\t\t\treturn INT64_MAX;\n\t\t}\n\t\treturn m_itPendingAck->second.m_usecWhenAckPrior;\n\t}\n\n\t/// Check invariants in debug.\n\t#if STEAMNETWORKINGSOCKETS_SNP_PARANOIA > 1\n\t\tvoid DebugCheckPackGapMap() const;\n\t#else\n\t\tinline void DebugCheckPackGapMap() const {}\n\t#endif\n\n\t// Stats.  FIXME - move to LinkStatsEndToEnd and track rate counters\n\tint64 m_nMessagesRecvReliable = 0;\n\tint64 m_nMessagesRecvUnreliable = 0;\n};\n\n} // SteamNetworkingSocketsLib\n"], "filenames": ["src/steamnetworkingsockets/clientlib/steamnetworkingsockets_snp.cpp", "src/steamnetworkingsockets/clientlib/steamnetworkingsockets_snp.h"], "buggy_code_start_loc": [237, 93], "buggy_code_end_loc": [585, 472], "fixing_code_start_loc": [237, 93], "fixing_code_end_loc": [597, 479], "type": "CWE-787", "message": "Valve's Game Networking Sockets prior to version v1.2.0 improperly handles long unreliable segments in function SNP_ReceiveUnreliableSegment() when configured to support plain-text messages, leading to a Heap-Based Buffer Overflow and resulting in a memory corruption and possibly even a remote code execution.", "other": {"cve": {"id": "CVE-2020-6017", "sourceIdentifier": "cve@checkpoint.com", "published": "2020-12-03T14:15:11.020", "lastModified": "2022-04-12T16:19:16.723", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Valve's Game Networking Sockets prior to version v1.2.0 improperly handles long unreliable segments in function SNP_ReceiveUnreliableSegment() when configured to support plain-text messages, leading to a Heap-Based Buffer Overflow and resulting in a memory corruption and possibly even a remote code execution."}, {"lang": "es", "value": "Game Networking Sockets de Valve versiones anteriores a v1.2.0, manejan de manera inapropiada segmentos largos y no confiables en la funci\u00f3n SNP_ReceiveUnreliableSegment() cuando est\u00e1n configurados para admitir mensajes de texto plano, conllevando a un desbordamiento del b\u00fafer en la regi\u00f3n heap de la memoria y resultando en una corrupci\u00f3n de la memoria y posiblemente incluso en una ejecuci\u00f3n de c\u00f3digo remota"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}, {"source": "cve@checkpoint.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-120"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:valvesoftware:game_networking_sockets:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.2.0", "matchCriteriaId": "8CB71176-D705-4517-81B9-97A557278890"}]}]}], "references": [{"url": "https://github.com/ValveSoftware/GameNetworkingSockets/commit/e0c86dcb9139771db3db0cfdb1fb8bef0af19c43", "source": "cve@checkpoint.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://research.checkpoint.com/2020/game-on-finding-vulnerabilities-in-valves-steam-sockets/", "source": "cve@checkpoint.com", "tags": ["Exploit", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/ValveSoftware/GameNetworkingSockets/commit/e0c86dcb9139771db3db0cfdb1fb8bef0af19c43"}}
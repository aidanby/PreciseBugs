{"buggy_code": ["#ifndef _X_TABLES_H\n#define _X_TABLES_H\n\n\n#include <linux/netdevice.h>\n#include <linux/static_key.h>\n#include <uapi/linux/netfilter/x_tables.h>\n\n/**\n * struct xt_action_param - parameters for matches/targets\n *\n * @match:\tthe match extension\n * @target:\tthe target extension\n * @matchinfo:\tper-match data\n * @targetinfo:\tper-target data\n * @net\t\tnetwork namespace through which the action was invoked\n * @in:\t\tinput netdevice\n * @out:\toutput netdevice\n * @fragoff:\tpacket is a fragment, this is the data offset\n * @thoff:\tposition of transport header relative to skb->data\n * @hook:\thook number given packet came from\n * @family:\tActual NFPROTO_* through which the function is invoked\n * \t\t(helpful when match->family == NFPROTO_UNSPEC)\n *\n * Fields written to by extensions:\n *\n * @hotdrop:\tdrop packet if we had inspection problems\n */\nstruct xt_action_param {\n\tunion {\n\t\tconst struct xt_match *match;\n\t\tconst struct xt_target *target;\n\t};\n\tunion {\n\t\tconst void *matchinfo, *targinfo;\n\t};\n\tstruct net *net;\n\tconst struct net_device *in, *out;\n\tint fragoff;\n\tunsigned int thoff;\n\tunsigned int hooknum;\n\tu_int8_t family;\n\tbool hotdrop;\n};\n\n/**\n * struct xt_mtchk_param - parameters for match extensions'\n * checkentry functions\n *\n * @net:\tnetwork namespace through which the check was invoked\n * @table:\ttable the rule is tried to be inserted into\n * @entryinfo:\tthe family-specific rule data\n * \t\t(struct ipt_ip, ip6t_ip, arpt_arp or (note) ebt_entry)\n * @match:\tstruct xt_match through which this function was invoked\n * @matchinfo:\tper-match data\n * @hook_mask:\tvia which hooks the new rule is reachable\n * Other fields as above.\n */\nstruct xt_mtchk_param {\n\tstruct net *net;\n\tconst char *table;\n\tconst void *entryinfo;\n\tconst struct xt_match *match;\n\tvoid *matchinfo;\n\tunsigned int hook_mask;\n\tu_int8_t family;\n\tbool nft_compat;\n};\n\n/**\n * struct xt_mdtor_param - match destructor parameters\n * Fields as above.\n */\nstruct xt_mtdtor_param {\n\tstruct net *net;\n\tconst struct xt_match *match;\n\tvoid *matchinfo;\n\tu_int8_t family;\n};\n\n/**\n * struct xt_tgchk_param - parameters for target extensions'\n * checkentry functions\n *\n * @entryinfo:\tthe family-specific rule data\n * \t\t(struct ipt_entry, ip6t_entry, arpt_entry, ebt_entry)\n *\n * Other fields see above.\n */\nstruct xt_tgchk_param {\n\tstruct net *net;\n\tconst char *table;\n\tconst void *entryinfo;\n\tconst struct xt_target *target;\n\tvoid *targinfo;\n\tunsigned int hook_mask;\n\tu_int8_t family;\n\tbool nft_compat;\n};\n\n/* Target destructor parameters */\nstruct xt_tgdtor_param {\n\tstruct net *net;\n\tconst struct xt_target *target;\n\tvoid *targinfo;\n\tu_int8_t family;\n};\n\nstruct xt_match {\n\tstruct list_head list;\n\n\tconst char name[XT_EXTENSION_MAXNAMELEN];\n\tu_int8_t revision;\n\n\t/* Return true or false: return FALSE and set *hotdrop = 1 to\n           force immediate packet drop. */\n\t/* Arguments changed since 2.6.9, as this must now handle\n\t   non-linear skb, using skb_header_pointer and\n\t   skb_ip_make_writable. */\n\tbool (*match)(const struct sk_buff *skb,\n\t\t      struct xt_action_param *);\n\n\t/* Called when user tries to insert an entry of this type. */\n\tint (*checkentry)(const struct xt_mtchk_param *);\n\n\t/* Called when entry of this type deleted. */\n\tvoid (*destroy)(const struct xt_mtdtor_param *);\n#ifdef CONFIG_COMPAT\n\t/* Called when userspace align differs from kernel space one */\n\tvoid (*compat_from_user)(void *dst, const void *src);\n\tint (*compat_to_user)(void __user *dst, const void *src);\n#endif\n\t/* Set this to THIS_MODULE if you are a module, otherwise NULL */\n\tstruct module *me;\n\n\tconst char *table;\n\tunsigned int matchsize;\n#ifdef CONFIG_COMPAT\n\tunsigned int compatsize;\n#endif\n\tunsigned int hooks;\n\tunsigned short proto;\n\n\tunsigned short family;\n};\n\n/* Registration hooks for targets. */\nstruct xt_target {\n\tstruct list_head list;\n\n\tconst char name[XT_EXTENSION_MAXNAMELEN];\n\tu_int8_t revision;\n\n\t/* Returns verdict. Argument order changed since 2.6.9, as this\n\t   must now handle non-linear skbs, using skb_copy_bits and\n\t   skb_ip_make_writable. */\n\tunsigned int (*target)(struct sk_buff *skb,\n\t\t\t       const struct xt_action_param *);\n\n\t/* Called when user tries to insert an entry of this type:\n           hook_mask is a bitmask of hooks from which it can be\n           called. */\n\t/* Should return 0 on success or an error code otherwise (-Exxxx). */\n\tint (*checkentry)(const struct xt_tgchk_param *);\n\n\t/* Called when entry of this type deleted. */\n\tvoid (*destroy)(const struct xt_tgdtor_param *);\n#ifdef CONFIG_COMPAT\n\t/* Called when userspace align differs from kernel space one */\n\tvoid (*compat_from_user)(void *dst, const void *src);\n\tint (*compat_to_user)(void __user *dst, const void *src);\n#endif\n\t/* Set this to THIS_MODULE if you are a module, otherwise NULL */\n\tstruct module *me;\n\n\tconst char *table;\n\tunsigned int targetsize;\n#ifdef CONFIG_COMPAT\n\tunsigned int compatsize;\n#endif\n\tunsigned int hooks;\n\tunsigned short proto;\n\n\tunsigned short family;\n};\n\n/* Furniture shopping... */\nstruct xt_table {\n\tstruct list_head list;\n\n\t/* What hooks you will enter on */\n\tunsigned int valid_hooks;\n\n\t/* Man behind the curtain... */\n\tstruct xt_table_info *private;\n\n\t/* Set this to THIS_MODULE if you are a module, otherwise NULL */\n\tstruct module *me;\n\n\tu_int8_t af;\t\t/* address/protocol family */\n\tint priority;\t\t/* hook order */\n\n\t/* called when table is needed in the given netns */\n\tint (*table_init)(struct net *net);\n\n\t/* A unique name... */\n\tconst char name[XT_TABLE_MAXNAMELEN];\n};\n\n#include <linux/netfilter_ipv4.h>\n\n/* The table itself */\nstruct xt_table_info {\n\t/* Size per table */\n\tunsigned int size;\n\t/* Number of entries: FIXME. --RR */\n\tunsigned int number;\n\t/* Initial number of entries. Needed for module usage count */\n\tunsigned int initial_entries;\n\n\t/* Entry points and underflows */\n\tunsigned int hook_entry[NF_INET_NUMHOOKS];\n\tunsigned int underflow[NF_INET_NUMHOOKS];\n\n\t/*\n\t * Number of user chains. Since tables cannot have loops, at most\n\t * @stacksize jumps (number of user chains) can possibly be made.\n\t */\n\tunsigned int stacksize;\n\tvoid ***jumpstack;\n\n\tunsigned char entries[0] __aligned(8);\n};\n\nint xt_register_target(struct xt_target *target);\nvoid xt_unregister_target(struct xt_target *target);\nint xt_register_targets(struct xt_target *target, unsigned int n);\nvoid xt_unregister_targets(struct xt_target *target, unsigned int n);\n\nint xt_register_match(struct xt_match *target);\nvoid xt_unregister_match(struct xt_match *target);\nint xt_register_matches(struct xt_match *match, unsigned int n);\nvoid xt_unregister_matches(struct xt_match *match, unsigned int n);\n\nint xt_check_entry_offsets(const void *base,\n\t\t\t   unsigned int target_offset,\n\t\t\t   unsigned int next_offset);\n\nint xt_check_match(struct xt_mtchk_param *, unsigned int size, u_int8_t proto,\n\t\t   bool inv_proto);\nint xt_check_target(struct xt_tgchk_param *, unsigned int size, u_int8_t proto,\n\t\t    bool inv_proto);\n\nstruct xt_table *xt_register_table(struct net *net,\n\t\t\t\t   const struct xt_table *table,\n\t\t\t\t   struct xt_table_info *bootstrap,\n\t\t\t\t   struct xt_table_info *newinfo);\nvoid *xt_unregister_table(struct xt_table *table);\n\nstruct xt_table_info *xt_replace_table(struct xt_table *table,\n\t\t\t\t       unsigned int num_counters,\n\t\t\t\t       struct xt_table_info *newinfo,\n\t\t\t\t       int *error);\n\nstruct xt_match *xt_find_match(u8 af, const char *name, u8 revision);\nstruct xt_target *xt_find_target(u8 af, const char *name, u8 revision);\nstruct xt_match *xt_request_find_match(u8 af, const char *name, u8 revision);\nstruct xt_target *xt_request_find_target(u8 af, const char *name, u8 revision);\nint xt_find_revision(u8 af, const char *name, u8 revision, int target,\n\t\t     int *err);\n\nstruct xt_table *xt_find_table_lock(struct net *net, u_int8_t af,\n\t\t\t\t    const char *name);\nvoid xt_table_unlock(struct xt_table *t);\n\nint xt_proto_init(struct net *net, u_int8_t af);\nvoid xt_proto_fini(struct net *net, u_int8_t af);\n\nstruct xt_table_info *xt_alloc_table_info(unsigned int size);\nvoid xt_free_table_info(struct xt_table_info *info);\n\n/**\n * xt_recseq - recursive seqcount for netfilter use\n * \n * Packet processing changes the seqcount only if no recursion happened\n * get_counters() can use read_seqcount_begin()/read_seqcount_retry(),\n * because we use the normal seqcount convention :\n * Low order bit set to 1 if a writer is active.\n */\nDECLARE_PER_CPU(seqcount_t, xt_recseq);\n\n/* xt_tee_enabled - true if x_tables needs to handle reentrancy\n *\n * Enabled if current ip(6)tables ruleset has at least one -j TEE rule.\n */\nextern struct static_key xt_tee_enabled;\n\n/**\n * xt_write_recseq_begin - start of a write section\n *\n * Begin packet processing : all readers must wait the end\n * 1) Must be called with preemption disabled\n * 2) softirqs must be disabled too (or we should use this_cpu_add())\n * Returns :\n *  1 if no recursion on this cpu\n *  0 if recursion detected\n */\nstatic inline unsigned int xt_write_recseq_begin(void)\n{\n\tunsigned int addend;\n\n\t/*\n\t * Low order bit of sequence is set if we already\n\t * called xt_write_recseq_begin().\n\t */\n\taddend = (__this_cpu_read(xt_recseq.sequence) + 1) & 1;\n\n\t/*\n\t * This is kind of a write_seqcount_begin(), but addend is 0 or 1\n\t * We dont check addend value to avoid a test and conditional jump,\n\t * since addend is most likely 1\n\t */\n\t__this_cpu_add(xt_recseq.sequence, addend);\n\tsmp_wmb();\n\n\treturn addend;\n}\n\n/**\n * xt_write_recseq_end - end of a write section\n * @addend: return value from previous xt_write_recseq_begin()\n *\n * End packet processing : all readers can proceed\n * 1) Must be called with preemption disabled\n * 2) softirqs must be disabled too (or we should use this_cpu_add())\n */\nstatic inline void xt_write_recseq_end(unsigned int addend)\n{\n\t/* this is kind of a write_seqcount_end(), but addend is 0 or 1 */\n\tsmp_wmb();\n\t__this_cpu_add(xt_recseq.sequence, addend);\n}\n\n/*\n * This helper is performance critical and must be inlined\n */\nstatic inline unsigned long ifname_compare_aligned(const char *_a,\n\t\t\t\t\t\t   const char *_b,\n\t\t\t\t\t\t   const char *_mask)\n{\n\tconst unsigned long *a = (const unsigned long *)_a;\n\tconst unsigned long *b = (const unsigned long *)_b;\n\tconst unsigned long *mask = (const unsigned long *)_mask;\n\tunsigned long ret;\n\n\tret = (a[0] ^ b[0]) & mask[0];\n\tif (IFNAMSIZ > sizeof(unsigned long))\n\t\tret |= (a[1] ^ b[1]) & mask[1];\n\tif (IFNAMSIZ > 2 * sizeof(unsigned long))\n\t\tret |= (a[2] ^ b[2]) & mask[2];\n\tif (IFNAMSIZ > 3 * sizeof(unsigned long))\n\t\tret |= (a[3] ^ b[3]) & mask[3];\n\tBUILD_BUG_ON(IFNAMSIZ > 4 * sizeof(unsigned long));\n\treturn ret;\n}\n\n\n/* On SMP, ip(6)t_entry->counters.pcnt holds address of the\n * real (percpu) counter.  On !SMP, its just the packet count,\n * so nothing needs to be done there.\n *\n * xt_percpu_counter_alloc returns the address of the percpu\n * counter, or 0 on !SMP. We force an alignment of 16 bytes\n * so that bytes/packets share a common cache line.\n *\n * Hence caller must use IS_ERR_VALUE to check for error, this\n * allows us to return 0 for single core systems without forcing\n * callers to deal with SMP vs. NONSMP issues.\n */\nstatic inline u64 xt_percpu_counter_alloc(void)\n{\n\tif (nr_cpu_ids > 1) {\n\t\tvoid __percpu *res = __alloc_percpu(sizeof(struct xt_counters),\n\t\t\t\t\t\t    sizeof(struct xt_counters));\n\n\t\tif (res == NULL)\n\t\t\treturn (u64) -ENOMEM;\n\n\t\treturn (u64) (__force unsigned long) res;\n\t}\n\n\treturn 0;\n}\nstatic inline void xt_percpu_counter_free(u64 pcnt)\n{\n\tif (nr_cpu_ids > 1)\n\t\tfree_percpu((void __percpu *) (unsigned long) pcnt);\n}\n\nstatic inline struct xt_counters *\nxt_get_this_cpu_counter(struct xt_counters *cnt)\n{\n\tif (nr_cpu_ids > 1)\n\t\treturn this_cpu_ptr((void __percpu *) (unsigned long) cnt->pcnt);\n\n\treturn cnt;\n}\n\nstatic inline struct xt_counters *\nxt_get_per_cpu_counter(struct xt_counters *cnt, unsigned int cpu)\n{\n\tif (nr_cpu_ids > 1)\n\t\treturn per_cpu_ptr((void __percpu *) (unsigned long) cnt->pcnt, cpu);\n\n\treturn cnt;\n}\n\nstruct nf_hook_ops *xt_hook_ops_alloc(const struct xt_table *, nf_hookfn *);\n\n#ifdef CONFIG_COMPAT\n#include <net/compat.h>\n\nstruct compat_xt_entry_match {\n\tunion {\n\t\tstruct {\n\t\t\tu_int16_t match_size;\n\t\t\tchar name[XT_FUNCTION_MAXNAMELEN - 1];\n\t\t\tu_int8_t revision;\n\t\t} user;\n\t\tstruct {\n\t\t\tu_int16_t match_size;\n\t\t\tcompat_uptr_t match;\n\t\t} kernel;\n\t\tu_int16_t match_size;\n\t} u;\n\tunsigned char data[0];\n};\n\nstruct compat_xt_entry_target {\n\tunion {\n\t\tstruct {\n\t\t\tu_int16_t target_size;\n\t\t\tchar name[XT_FUNCTION_MAXNAMELEN - 1];\n\t\t\tu_int8_t revision;\n\t\t} user;\n\t\tstruct {\n\t\t\tu_int16_t target_size;\n\t\t\tcompat_uptr_t target;\n\t\t} kernel;\n\t\tu_int16_t target_size;\n\t} u;\n\tunsigned char data[0];\n};\n\n/* FIXME: this works only on 32 bit tasks\n * need to change whole approach in order to calculate align as function of\n * current task alignment */\n\nstruct compat_xt_counters {\n\tcompat_u64 pcnt, bcnt;\t\t\t/* Packet and byte counters */\n};\n\nstruct compat_xt_counters_info {\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tcompat_uint_t num_counters;\n\tstruct compat_xt_counters counters[0];\n};\n\nstruct _compat_xt_align {\n\t__u8 u8;\n\t__u16 u16;\n\t__u32 u32;\n\tcompat_u64 u64;\n};\n\n#define COMPAT_XT_ALIGN(s) __ALIGN_KERNEL((s), __alignof__(struct _compat_xt_align))\n\nvoid xt_compat_lock(u_int8_t af);\nvoid xt_compat_unlock(u_int8_t af);\n\nint xt_compat_add_offset(u_int8_t af, unsigned int offset, int delta);\nvoid xt_compat_flush_offsets(u_int8_t af);\nvoid xt_compat_init_offsets(u_int8_t af, unsigned int number);\nint xt_compat_calc_jump(u_int8_t af, unsigned int offset);\n\nint xt_compat_match_offset(const struct xt_match *match);\nint xt_compat_match_from_user(struct xt_entry_match *m, void **dstptr,\n\t\t\t      unsigned int *size);\nint xt_compat_match_to_user(const struct xt_entry_match *m,\n\t\t\t    void __user **dstptr, unsigned int *size);\n\nint xt_compat_target_offset(const struct xt_target *target);\nvoid xt_compat_target_from_user(struct xt_entry_target *t, void **dstptr,\n\t\t\t\tunsigned int *size);\nint xt_compat_target_to_user(const struct xt_entry_target *t,\n\t\t\t     void __user **dstptr, unsigned int *size);\nint xt_compat_check_entry_offsets(const void *base,\n\t\t\t\t  unsigned int target_offset,\n\t\t\t\t  unsigned int next_offset);\n\n#endif /* CONFIG_COMPAT */\n#endif /* _X_TABLES_H */\n", "/*\n * Packet matching code for ARP packets.\n *\n * Based heavily, if not almost entirely, upon ip_tables.c framework.\n *\n * Some ARP specific bits are:\n *\n * Copyright (C) 2002 David S. Miller (davem@redhat.com)\n * Copyright (C) 2006-2009 Patrick McHardy <kaber@trash.net>\n *\n */\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/kernel.h>\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include <linux/capability.h>\n#include <linux/if_arp.h>\n#include <linux/kmod.h>\n#include <linux/vmalloc.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/mutex.h>\n#include <linux/err.h>\n#include <net/compat.h>\n#include <net/sock.h>\n#include <asm/uaccess.h>\n\n#include <linux/netfilter/x_tables.h>\n#include <linux/netfilter_arp/arp_tables.h>\n#include \"../../netfilter/xt_repldata.h\"\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"David S. Miller <davem@redhat.com>\");\nMODULE_DESCRIPTION(\"arptables core\");\n\n/*#define DEBUG_ARP_TABLES*/\n/*#define DEBUG_ARP_TABLES_USER*/\n\n#ifdef DEBUG_ARP_TABLES\n#define dprintf(format, args...)  pr_debug(format, ## args)\n#else\n#define dprintf(format, args...)\n#endif\n\n#ifdef DEBUG_ARP_TABLES_USER\n#define duprintf(format, args...) pr_debug(format, ## args)\n#else\n#define duprintf(format, args...)\n#endif\n\n#ifdef CONFIG_NETFILTER_DEBUG\n#define ARP_NF_ASSERT(x)\tWARN_ON(!(x))\n#else\n#define ARP_NF_ASSERT(x)\n#endif\n\nvoid *arpt_alloc_initial_table(const struct xt_table *info)\n{\n\treturn xt_alloc_initial_table(arpt, ARPT);\n}\nEXPORT_SYMBOL_GPL(arpt_alloc_initial_table);\n\nstatic inline int arp_devaddr_compare(const struct arpt_devaddr_info *ap,\n\t\t\t\t      const char *hdr_addr, int len)\n{\n\tint i, ret;\n\n\tif (len > ARPT_DEV_ADDR_LEN_MAX)\n\t\tlen = ARPT_DEV_ADDR_LEN_MAX;\n\n\tret = 0;\n\tfor (i = 0; i < len; i++)\n\t\tret |= (hdr_addr[i] ^ ap->addr[i]) & ap->mask[i];\n\n\treturn ret != 0;\n}\n\n/*\n * Unfortunately, _b and _mask are not aligned to an int (or long int)\n * Some arches dont care, unrolling the loop is a win on them.\n * For other arches, we only have a 16bit alignement.\n */\nstatic unsigned long ifname_compare(const char *_a, const char *_b, const char *_mask)\n{\n#ifdef CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS\n\tunsigned long ret = ifname_compare_aligned(_a, _b, _mask);\n#else\n\tunsigned long ret = 0;\n\tconst u16 *a = (const u16 *)_a;\n\tconst u16 *b = (const u16 *)_b;\n\tconst u16 *mask = (const u16 *)_mask;\n\tint i;\n\n\tfor (i = 0; i < IFNAMSIZ/sizeof(u16); i++)\n\t\tret |= (a[i] ^ b[i]) & mask[i];\n#endif\n\treturn ret;\n}\n\n/* Returns whether packet matches rule or not. */\nstatic inline int arp_packet_match(const struct arphdr *arphdr,\n\t\t\t\t   struct net_device *dev,\n\t\t\t\t   const char *indev,\n\t\t\t\t   const char *outdev,\n\t\t\t\t   const struct arpt_arp *arpinfo)\n{\n\tconst char *arpptr = (char *)(arphdr + 1);\n\tconst char *src_devaddr, *tgt_devaddr;\n\t__be32 src_ipaddr, tgt_ipaddr;\n\tlong ret;\n\n#define FWINV(bool, invflg) ((bool) ^ !!(arpinfo->invflags & (invflg)))\n\n\tif (FWINV((arphdr->ar_op & arpinfo->arpop_mask) != arpinfo->arpop,\n\t\t  ARPT_INV_ARPOP)) {\n\t\tdprintf(\"ARP operation field mismatch.\\n\");\n\t\tdprintf(\"ar_op: %04x info->arpop: %04x info->arpop_mask: %04x\\n\",\n\t\t\tarphdr->ar_op, arpinfo->arpop, arpinfo->arpop_mask);\n\t\treturn 0;\n\t}\n\n\tif (FWINV((arphdr->ar_hrd & arpinfo->arhrd_mask) != arpinfo->arhrd,\n\t\t  ARPT_INV_ARPHRD)) {\n\t\tdprintf(\"ARP hardware address format mismatch.\\n\");\n\t\tdprintf(\"ar_hrd: %04x info->arhrd: %04x info->arhrd_mask: %04x\\n\",\n\t\t\tarphdr->ar_hrd, arpinfo->arhrd, arpinfo->arhrd_mask);\n\t\treturn 0;\n\t}\n\n\tif (FWINV((arphdr->ar_pro & arpinfo->arpro_mask) != arpinfo->arpro,\n\t\t  ARPT_INV_ARPPRO)) {\n\t\tdprintf(\"ARP protocol address format mismatch.\\n\");\n\t\tdprintf(\"ar_pro: %04x info->arpro: %04x info->arpro_mask: %04x\\n\",\n\t\t\tarphdr->ar_pro, arpinfo->arpro, arpinfo->arpro_mask);\n\t\treturn 0;\n\t}\n\n\tif (FWINV((arphdr->ar_hln & arpinfo->arhln_mask) != arpinfo->arhln,\n\t\t  ARPT_INV_ARPHLN)) {\n\t\tdprintf(\"ARP hardware address length mismatch.\\n\");\n\t\tdprintf(\"ar_hln: %02x info->arhln: %02x info->arhln_mask: %02x\\n\",\n\t\t\tarphdr->ar_hln, arpinfo->arhln, arpinfo->arhln_mask);\n\t\treturn 0;\n\t}\n\n\tsrc_devaddr = arpptr;\n\tarpptr += dev->addr_len;\n\tmemcpy(&src_ipaddr, arpptr, sizeof(u32));\n\tarpptr += sizeof(u32);\n\ttgt_devaddr = arpptr;\n\tarpptr += dev->addr_len;\n\tmemcpy(&tgt_ipaddr, arpptr, sizeof(u32));\n\n\tif (FWINV(arp_devaddr_compare(&arpinfo->src_devaddr, src_devaddr, dev->addr_len),\n\t\t  ARPT_INV_SRCDEVADDR) ||\n\t    FWINV(arp_devaddr_compare(&arpinfo->tgt_devaddr, tgt_devaddr, dev->addr_len),\n\t\t  ARPT_INV_TGTDEVADDR)) {\n\t\tdprintf(\"Source or target device address mismatch.\\n\");\n\n\t\treturn 0;\n\t}\n\n\tif (FWINV((src_ipaddr & arpinfo->smsk.s_addr) != arpinfo->src.s_addr,\n\t\t  ARPT_INV_SRCIP) ||\n\t    FWINV(((tgt_ipaddr & arpinfo->tmsk.s_addr) != arpinfo->tgt.s_addr),\n\t\t  ARPT_INV_TGTIP)) {\n\t\tdprintf(\"Source or target IP address mismatch.\\n\");\n\n\t\tdprintf(\"SRC: %pI4. Mask: %pI4. Target: %pI4.%s\\n\",\n\t\t\t&src_ipaddr,\n\t\t\t&arpinfo->smsk.s_addr,\n\t\t\t&arpinfo->src.s_addr,\n\t\t\tarpinfo->invflags & ARPT_INV_SRCIP ? \" (INV)\" : \"\");\n\t\tdprintf(\"TGT: %pI4 Mask: %pI4 Target: %pI4.%s\\n\",\n\t\t\t&tgt_ipaddr,\n\t\t\t&arpinfo->tmsk.s_addr,\n\t\t\t&arpinfo->tgt.s_addr,\n\t\t\tarpinfo->invflags & ARPT_INV_TGTIP ? \" (INV)\" : \"\");\n\t\treturn 0;\n\t}\n\n\t/* Look for ifname matches.  */\n\tret = ifname_compare(indev, arpinfo->iniface, arpinfo->iniface_mask);\n\n\tif (FWINV(ret != 0, ARPT_INV_VIA_IN)) {\n\t\tdprintf(\"VIA in mismatch (%s vs %s).%s\\n\",\n\t\t\tindev, arpinfo->iniface,\n\t\t\tarpinfo->invflags & ARPT_INV_VIA_IN ? \" (INV)\" : \"\");\n\t\treturn 0;\n\t}\n\n\tret = ifname_compare(outdev, arpinfo->outiface, arpinfo->outiface_mask);\n\n\tif (FWINV(ret != 0, ARPT_INV_VIA_OUT)) {\n\t\tdprintf(\"VIA out mismatch (%s vs %s).%s\\n\",\n\t\t\toutdev, arpinfo->outiface,\n\t\t\tarpinfo->invflags & ARPT_INV_VIA_OUT ? \" (INV)\" : \"\");\n\t\treturn 0;\n\t}\n\n\treturn 1;\n#undef FWINV\n}\n\nstatic inline int arp_checkentry(const struct arpt_arp *arp)\n{\n\tif (arp->flags & ~ARPT_F_MASK) {\n\t\tduprintf(\"Unknown flag bits set: %08X\\n\",\n\t\t\t arp->flags & ~ARPT_F_MASK);\n\t\treturn 0;\n\t}\n\tif (arp->invflags & ~ARPT_INV_MASK) {\n\t\tduprintf(\"Unknown invflag bits set: %08X\\n\",\n\t\t\t arp->invflags & ~ARPT_INV_MASK);\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic unsigned int\narpt_error(struct sk_buff *skb, const struct xt_action_param *par)\n{\n\tnet_err_ratelimited(\"arp_tables: error: '%s'\\n\",\n\t\t\t    (const char *)par->targinfo);\n\n\treturn NF_DROP;\n}\n\nstatic inline const struct xt_entry_target *\narpt_get_target_c(const struct arpt_entry *e)\n{\n\treturn arpt_get_target((struct arpt_entry *)e);\n}\n\nstatic inline struct arpt_entry *\nget_entry(const void *base, unsigned int offset)\n{\n\treturn (struct arpt_entry *)(base + offset);\n}\n\nstatic inline\nstruct arpt_entry *arpt_next_entry(const struct arpt_entry *entry)\n{\n\treturn (void *)entry + entry->next_offset;\n}\n\nunsigned int arpt_do_table(struct sk_buff *skb,\n\t\t\t   const struct nf_hook_state *state,\n\t\t\t   struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\tunsigned int verdict = NF_DROP;\n\tconst struct arphdr *arp;\n\tstruct arpt_entry *e, **jumpstack;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tunsigned int cpu, stackidx = 0;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\tif (!pskb_may_pull(skb, arp_hdr_len(skb->dev)))\n\t\treturn NF_DROP;\n\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = table->private;\n\tcpu     = smp_processor_id();\n\t/*\n\t * Ensure we load private-> members after we've fetched the base\n\t * pointer.\n\t */\n\tsmp_read_barrier_depends();\n\ttable_base = private->entries;\n\tjumpstack  = (struct arpt_entry **)private->jumpstack[cpu];\n\n\t/* No TEE support for arptables, so no need to switch to alternate\n\t * stack.  All targets that reenter must return absolute verdicts.\n\t */\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tacpar.net     = state->net;\n\tacpar.in      = state->in;\n\tacpar.out     = state->out;\n\tacpar.hooknum = hook;\n\tacpar.family  = NFPROTO_ARP;\n\tacpar.hotdrop = false;\n\n\tarp = arp_hdr(skb);\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tstruct xt_counters *counter;\n\n\t\tif (!arp_packet_match(arp, skb->dev, indev, outdev, &e->arp)) {\n\t\t\te = arpt_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, arp_hdr_len(skb->dev), 1);\n\n\t\tt = arpt_get_target_c(e);\n\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0) {\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t\t      private->underflow[hook]);\n\t\t\t\t} else {\n\t\t\t\t\te = jumpstack[--stackidx];\n\t\t\t\t\te = arpt_next_entry(e);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v\n\t\t\t    != arpt_next_entry(e)) {\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\n\t\t/* Target might have changed stuff. */\n\t\tarp = arp_hdr(skb);\n\n\t\tif (verdict == XT_CONTINUE)\n\t\t\te = arpt_next_entry(e);\n\t\telse\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t} while (!acpar.hotdrop);\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse\n\t\treturn verdict;\n}\n\n/* All zeroes == unconditional rule. */\nstatic inline bool unconditional(const struct arpt_entry *e)\n{\n\tstatic const struct arpt_arp uncond;\n\n\treturn e->target_offset == sizeof(struct arpt_entry) &&\n\t       memcmp(&e->arp, &uncond, sizeof(uncond)) == 0;\n}\n\nstatic bool find_jump_target(const struct xt_table_info *t,\n\t\t\t     const struct arpt_entry *target)\n{\n\tstruct arpt_entry *iter;\n\n\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t if (iter == target)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n/* Figures out from what hook each rule can be called: returns 0 if\n * there are loops.  Puts hook bitmask in comefrom.\n */\nstatic int mark_source_chains(const struct xt_table_info *newinfo,\n\t\t\t      unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t * to 0 as we leave), and comefrom to save source hook bitmask.\n\t */\n\tfor (hook = 0; hook < NF_ARP_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct arpt_entry *e\n\t\t\t= (struct arpt_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)arpt_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_ARP_NUMHOOKS)) {\n\t\t\t\tpr_notice(\"arptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom\n\t\t\t\t|= ((1 << hook) | (1 << NF_ARP_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t * big jump.\n\t\t\t\t */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_ARP_NUMHOOKS);\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\tif (pos + size >= newinfo->size)\n\t\t\t\t\treturn 0;\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct arpt_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t\t(entry0 + newpos);\n\t\t\t\t\tif (!find_jump_target(newinfo, e))\n\t\t\t\t\t\treturn 0;\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t\tif (newpos >= newinfo->size)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}\n\nstatic inline int check_target(struct arpt_entry *e, const char *name)\n{\n\tstruct xt_entry_target *t = arpt_get_target(e);\n\tint ret;\n\tstruct xt_tgchk_param par = {\n\t\t.table     = name,\n\t\t.entryinfo = e,\n\t\t.target    = t->u.kernel.target,\n\t\t.targinfo  = t->data,\n\t\t.hook_mask = e->comefrom,\n\t\t.family    = NFPROTO_ARP,\n\t};\n\n\tret = xt_check_target(&par, t->u.target_size - sizeof(*t), 0, false);\n\tif (ret < 0) {\n\t\tduprintf(\"arp_tables: check failed for `%s'.\\n\",\n\t\t\t t->u.kernel.target->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic inline int\nfind_check_entry(struct arpt_entry *e, const char *name, unsigned int size)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tint ret;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\n\tt = arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"find_check_entry: `%s' not found\\n\", t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\tret = check_target(e, name);\n\tif (ret)\n\t\tgoto err;\n\treturn 0;\nerr:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic bool check_underflow(const struct arpt_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = arpt_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n\nstatic inline int check_entry_size_and_hooks(struct arpt_entry *e,\n\t\t\t\t\t     struct xt_table_info *newinfo,\n\t\t\t\t\t     const unsigned char *base,\n\t\t\t\t\t     const unsigned char *limit,\n\t\t\t\t\t     const unsigned int *hook_entries,\n\t\t\t\t\t     const unsigned int *underflows,\n\t\t\t\t\t     unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}\n\nstatic inline void cleanup_entry(struct arpt_entry *e)\n{\n\tstruct xt_tgdtor_param par;\n\tstruct xt_entry_target *t;\n\n\tt = arpt_get_target(e);\n\tpar.target   = t->u.kernel.target;\n\tpar.targinfo = t->data;\n\tpar.family   = NFPROTO_ARP;\n\tif (par.target->destroy != NULL)\n\t\tpar.target->destroy(&par);\n\tmodule_put(par.target->me);\n\txt_percpu_counter_free(e->counters.pcnt);\n}\n\n/* Checks and translates the user-supplied table segment (held in\n * newinfo).\n */\nstatic int translate_table(struct xt_table_info *newinfo, void *entry0,\n\t\t\t   const struct arpt_replace *repl)\n{\n\tstruct arpt_entry *iter;\n\tunsigned int i;\n\tint ret = 0;\n\n\tnewinfo->size = repl->size;\n\tnewinfo->number = repl->num_entries;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tnewinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_table: size %u\\n\", newinfo->size);\n\ti = 0;\n\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = check_entry_size_and_hooks(iter, newinfo, entry0,\n\t\t\t\t\t\t entry0 + repl->size,\n\t\t\t\t\t\t repl->hook_entry,\n\t\t\t\t\t\t repl->underflow,\n\t\t\t\t\t\t repl->valid_hooks);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t\tif (strcmp(arpt_get_target(iter)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\tduprintf(\"translate_table: ARPT_ENTRY_ITERATE gives %d\\n\", ret);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tif (i != repl->num_entries) {\n\t\tduprintf(\"translate_table: %u not %u entries\\n\",\n\t\t\t i, repl->num_entries);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(repl->valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (newinfo->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, repl->hook_entry[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (newinfo->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, repl->underflow[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!mark_source_chains(newinfo, repl->valid_hooks, entry0))\n\t\treturn -ELOOP;\n\n\t/* Finally, each sanity check must pass */\n\ti = 0;\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = find_check_entry(iter, repl->name, repl->size);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t}\n\n\tif (ret != 0) {\n\t\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter);\n\t\t}\n\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic void get_counters(const struct xt_table_info *t,\n\t\t\t struct xt_counters counters[])\n{\n\tstruct arpt_entry *iter;\n\tunsigned int cpu;\n\tunsigned int i;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tseqcount_t *s = &per_cpu(xt_recseq, cpu);\n\n\t\ti = 0;\n\t\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t\tstruct xt_counters *tmp;\n\t\t\tu64 bcnt, pcnt;\n\t\t\tunsigned int start;\n\n\t\t\ttmp = xt_get_per_cpu_counter(&iter->counters, cpu);\n\t\t\tdo {\n\t\t\t\tstart = read_seqcount_begin(s);\n\t\t\t\tbcnt = tmp->bcnt;\n\t\t\t\tpcnt = tmp->pcnt;\n\t\t\t} while (read_seqcount_retry(s, start));\n\n\t\t\tADD_COUNTER(counters[i], bcnt, pcnt);\n\t\t\t++i;\n\t\t}\n\t}\n}\n\nstatic struct xt_counters *alloc_counters(const struct xt_table *table)\n{\n\tunsigned int countersize;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\n\t/* We need atomic snapshot of counters: rest doesn't change\n\t * (other than comefrom, which userspace doesn't care\n\t * about).\n\t */\n\tcountersize = sizeof(struct xt_counters) * private->number;\n\tcounters = vzalloc(countersize);\n\n\tif (counters == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tget_counters(private, counters);\n\n\treturn counters;\n}\n\nstatic int copy_entries_to_user(unsigned int total_size,\n\t\t\t\tconst struct xt_table *table,\n\t\t\t\tvoid __user *userptr)\n{\n\tunsigned int off, num;\n\tconst struct arpt_entry *e;\n\tstruct xt_counters *counters;\n\tstruct xt_table_info *private = table->private;\n\tint ret = 0;\n\tvoid *loc_cpu_entry;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tloc_cpu_entry = private->entries;\n\t/* ... then copy entire thing ... */\n\tif (copy_to_user(userptr, loc_cpu_entry, total_size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_counters;\n\t}\n\n\t/* FIXME: use iterator macros --RR */\n\t/* ... then go back and fix counters and names */\n\tfor (off = 0, num = 0; off < total_size; off += e->next_offset, num++){\n\t\tconst struct xt_entry_target *t;\n\n\t\te = (struct arpt_entry *)(loc_cpu_entry + off);\n\t\tif (copy_to_user(userptr + off\n\t\t\t\t + offsetof(struct arpt_entry, counters),\n\t\t\t\t &counters[num],\n\t\t\t\t sizeof(counters[num])) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\n\t\tt = arpt_get_target_c(e);\n\t\tif (copy_to_user(userptr + off + e->target_offset\n\t\t\t\t + offsetof(struct xt_entry_target,\n\t\t\t\t\t    u.user.name),\n\t\t\t\t t->u.kernel.target->name,\n\t\t\t\t strlen(t->u.kernel.target->name)+1) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\t}\n\n free_counters:\n\tvfree(counters);\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic void compat_standard_from_user(void *dst, const void *src)\n{\n\tint v = *(compat_int_t *)src;\n\n\tif (v > 0)\n\t\tv += xt_compat_calc_jump(NFPROTO_ARP, v);\n\tmemcpy(dst, &v, sizeof(v));\n}\n\nstatic int compat_standard_to_user(void __user *dst, const void *src)\n{\n\tcompat_int_t cv = *(int *)src;\n\n\tif (cv > 0)\n\t\tcv -= xt_compat_calc_jump(NFPROTO_ARP, cv);\n\treturn copy_to_user(dst, &cv, sizeof(cv)) ? -EFAULT : 0;\n}\n\nstatic int compat_calc_entry(const struct arpt_entry *e,\n\t\t\t     const struct xt_table_info *info,\n\t\t\t     const void *base, struct xt_table_info *newinfo)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int entry_offset;\n\tint off, i, ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - base;\n\n\tt = arpt_get_target_c(e);\n\toff += xt_compat_target_offset(t->u.kernel.target);\n\tnewinfo->size -= off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tif (info->hook_entry[i] &&\n\t\t    (e < (struct arpt_entry *)(base + info->hook_entry[i])))\n\t\t\tnewinfo->hook_entry[i] -= off;\n\t\tif (info->underflow[i] &&\n\t\t    (e < (struct arpt_entry *)(base + info->underflow[i])))\n\t\t\tnewinfo->underflow[i] -= off;\n\t}\n\treturn 0;\n}\n\nstatic int compat_table_info(const struct xt_table_info *info,\n\t\t\t     struct xt_table_info *newinfo)\n{\n\tstruct arpt_entry *iter;\n\tconst void *loc_cpu_entry;\n\tint ret;\n\n\tif (!newinfo || !info)\n\t\treturn -EINVAL;\n\n\t/* we dont care about newinfo->entries */\n\tmemcpy(newinfo, info, offsetof(struct xt_table_info, entries));\n\tnewinfo->initial_entries = 0;\n\tloc_cpu_entry = info->entries;\n\txt_compat_init_offsets(NFPROTO_ARP, info->number);\n\txt_entry_foreach(iter, loc_cpu_entry, info->size) {\n\t\tret = compat_calc_entry(iter, info, loc_cpu_entry, newinfo);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n#endif\n\nstatic int get_info(struct net *net, void __user *user,\n\t\t    const int *len, int compat)\n{\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tstruct xt_table *t;\n\tint ret;\n\n\tif (*len != sizeof(struct arpt_getinfo)) {\n\t\tduprintf(\"length %u != %Zu\\n\", *len,\n\t\t\t sizeof(struct arpt_getinfo));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(name, user, sizeof(name)) != 0)\n\t\treturn -EFAULT;\n\n\tname[XT_TABLE_MAXNAMELEN-1] = '\\0';\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_lock(NFPROTO_ARP);\n#endif\n\tt = try_then_request_module(xt_find_table_lock(net, NFPROTO_ARP, name),\n\t\t\t\t    \"arptable_%s\", name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tstruct arpt_getinfo info;\n\t\tconst struct xt_table_info *private = t->private;\n#ifdef CONFIG_COMPAT\n\t\tstruct xt_table_info tmp;\n\n\t\tif (compat) {\n\t\t\tret = compat_table_info(private, &tmp);\n\t\t\txt_compat_flush_offsets(NFPROTO_ARP);\n\t\t\tprivate = &tmp;\n\t\t}\n#endif\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.valid_hooks = t->valid_hooks;\n\t\tmemcpy(info.hook_entry, private->hook_entry,\n\t\t       sizeof(info.hook_entry));\n\t\tmemcpy(info.underflow, private->underflow,\n\t\t       sizeof(info.underflow));\n\t\tinfo.num_entries = private->number;\n\t\tinfo.size = private->size;\n\t\tstrcpy(info.name, name);\n\n\t\tif (copy_to_user(user, &info, *len) != 0)\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = 0;\n\t\txt_table_unlock(t);\n\t\tmodule_put(t->me);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_unlock(NFPROTO_ARP);\n#endif\n\treturn ret;\n}\n\nstatic int get_entries(struct net *net, struct arpt_get_entries __user *uptr,\n\t\t       const int *len)\n{\n\tint ret;\n\tstruct arpt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"get_entries: %u < %Zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct arpt_get_entries) + get.size) {\n\t\tduprintf(\"get_entries: %u != %Zu\\n\", *len,\n\t\t\t sizeof(struct arpt_get_entries) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, NFPROTO_ARP, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\n\t\tduprintf(\"t->private->number = %u\\n\",\n\t\t\t private->number);\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse {\n\t\t\tduprintf(\"get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\treturn ret;\n}\n\nstatic int __do_replace(struct net *net, const char *name,\n\t\t\tunsigned int valid_hooks,\n\t\t\tstruct xt_table_info *newinfo,\n\t\t\tunsigned int num_counters,\n\t\t\tvoid __user *counters_ptr)\n{\n\tint ret;\n\tstruct xt_table *t;\n\tstruct xt_table_info *oldinfo;\n\tstruct xt_counters *counters;\n\tvoid *loc_cpu_old_entry;\n\tstruct arpt_entry *iter;\n\n\tret = 0;\n\tcounters = vzalloc(num_counters * sizeof(struct xt_counters));\n\tif (!counters) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tt = try_then_request_module(xt_find_table_lock(net, NFPROTO_ARP, name),\n\t\t\t\t    \"arptable_%s\", name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free_newinfo_counters_untrans;\n\t}\n\n\t/* You lied! */\n\tif (valid_hooks != t->valid_hooks) {\n\t\tduprintf(\"Valid hook crap: %08X vs %08X\\n\",\n\t\t\t valid_hooks, t->valid_hooks);\n\t\tret = -EINVAL;\n\t\tgoto put_module;\n\t}\n\n\toldinfo = xt_replace_table(t, num_counters, newinfo, &ret);\n\tif (!oldinfo)\n\t\tgoto put_module;\n\n\t/* Update module usage count based on number of rules */\n\tduprintf(\"do_replace: oldnum=%u, initnum=%u, newnum=%u\\n\",\n\t\toldinfo->number, oldinfo->initial_entries, newinfo->number);\n\tif ((oldinfo->number > oldinfo->initial_entries) ||\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\tif ((oldinfo->number > oldinfo->initial_entries) &&\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\n\t/* Get the old counters, and synchronize with replace */\n\tget_counters(oldinfo, counters);\n\n\t/* Decrease module usage counts and free resource */\n\tloc_cpu_old_entry = oldinfo->entries;\n\txt_entry_foreach(iter, loc_cpu_old_entry, oldinfo->size)\n\t\tcleanup_entry(iter);\n\n\txt_free_table_info(oldinfo);\n\tif (copy_to_user(counters_ptr, counters,\n\t\t\t sizeof(struct xt_counters) * num_counters) != 0) {\n\t\t/* Silent error, can't fail, new table is already in place */\n\t\tnet_warn_ratelimited(\"arptables: counters copy to user failed while replacing table\\n\");\n\t}\n\tvfree(counters);\n\txt_table_unlock(t);\n\treturn ret;\n\n put_module:\n\tmodule_put(t->me);\n\txt_table_unlock(t);\n free_newinfo_counters_untrans:\n\tvfree(counters);\n out:\n\treturn ret;\n}\n\nstatic int do_replace(struct net *net, const void __user *user,\n\t\t      unsigned int len)\n{\n\tint ret;\n\tstruct arpt_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct arpt_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_table(newinfo, loc_cpu_entry, &tmp);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"arp_tables: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, tmp.counters);\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int do_add_counters(struct net *net, const void __user *user,\n\t\t\t   unsigned int len, int compat)\n{\n\tunsigned int i;\n\tstruct xt_counters_info tmp;\n\tstruct xt_counters *paddc;\n\tunsigned int num_counters;\n\tconst char *name;\n\tint size;\n\tvoid *ptmp;\n\tstruct xt_table *t;\n\tconst struct xt_table_info *private;\n\tint ret = 0;\n\tstruct arpt_entry *iter;\n\tunsigned int addend;\n#ifdef CONFIG_COMPAT\n\tstruct compat_xt_counters_info compat_tmp;\n\n\tif (compat) {\n\t\tptmp = &compat_tmp;\n\t\tsize = sizeof(struct compat_xt_counters_info);\n\t} else\n#endif\n\t{\n\t\tptmp = &tmp;\n\t\tsize = sizeof(struct xt_counters_info);\n\t}\n\n\tif (copy_from_user(ptmp, user, size) != 0)\n\t\treturn -EFAULT;\n\n#ifdef CONFIG_COMPAT\n\tif (compat) {\n\t\tnum_counters = compat_tmp.num_counters;\n\t\tname = compat_tmp.name;\n\t} else\n#endif\n\t{\n\t\tnum_counters = tmp.num_counters;\n\t\tname = tmp.name;\n\t}\n\n\tif (len != size + num_counters * sizeof(struct xt_counters))\n\t\treturn -EINVAL;\n\n\tpaddc = vmalloc(len - size);\n\tif (!paddc)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(paddc, user + size, len - size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free;\n\t}\n\n\tt = xt_find_table_lock(net, NFPROTO_ARP, name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free;\n\t}\n\n\tlocal_bh_disable();\n\tprivate = t->private;\n\tif (private->number != num_counters) {\n\t\tret = -EINVAL;\n\t\tgoto unlock_up_free;\n\t}\n\n\ti = 0;\n\n\taddend = xt_write_recseq_begin();\n\txt_entry_foreach(iter,  private->entries, private->size) {\n\t\tstruct xt_counters *tmp;\n\n\t\ttmp = xt_get_this_cpu_counter(&iter->counters);\n\t\tADD_COUNTER(*tmp, paddc[i].bcnt, paddc[i].pcnt);\n\t\t++i;\n\t}\n\txt_write_recseq_end(addend);\n unlock_up_free:\n\tlocal_bh_enable();\n\txt_table_unlock(t);\n\tmodule_put(t->me);\n free:\n\tvfree(paddc);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic inline void compat_release_entry(struct compat_arpt_entry *e)\n{\n\tstruct xt_entry_target *t;\n\n\tt = compat_arpt_get_target(e);\n\tmodule_put(t->u.kernel.target->me);\n}\n\nstatic inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}\n\nstatic int\ncompat_copy_entry_from_user(struct compat_arpt_entry *e, void **dstptr,\n\t\t\t    unsigned int *size, const char *name,\n\t\t\t    struct xt_table_info *newinfo, unsigned char *base)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tstruct arpt_entry *de;\n\tunsigned int origsize;\n\tint ret, h;\n\n\tret = 0;\n\torigsize = *size;\n\tde = (struct arpt_entry *)*dstptr;\n\tmemcpy(de, e, sizeof(struct arpt_entry));\n\tmemcpy(&de->counters, &e->counters, sizeof(e->counters));\n\n\t*dstptr += sizeof(struct arpt_entry);\n\t*size += sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\n\tde->target_offset = e->target_offset - (origsize - *size);\n\tt = compat_arpt_get_target(e);\n\ttarget = t->u.kernel.target;\n\txt_compat_target_from_user(t, dstptr, size);\n\n\tde->next_offset = e->next_offset - (origsize - *size);\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)de - base < newinfo->hook_entry[h])\n\t\t\tnewinfo->hook_entry[h] -= origsize - *size;\n\t\tif ((unsigned char *)de - base < newinfo->underflow[h])\n\t\t\tnewinfo->underflow[h] -= origsize - *size;\n\t}\n\treturn ret;\n}\n\nstatic int translate_compat_table(const char *name,\n\t\t\t\t  unsigned int valid_hooks,\n\t\t\t\t  struct xt_table_info **pinfo,\n\t\t\t\t  void **pentry0,\n\t\t\t\t  unsigned int total_size,\n\t\t\t\t  unsigned int number,\n\t\t\t\t  unsigned int *hook_entries,\n\t\t\t\t  unsigned int *underflows)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_arpt_entry *iter0;\n\tstruct arpt_entry *iter1;\n\tunsigned int size;\n\tint ret = 0;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = total_size;\n\tinfo->number = number;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_compat_table: size %u\\n\", info->size);\n\tj = 0;\n\txt_compat_lock(NFPROTO_ARP);\n\txt_compat_init_offsets(NFPROTO_ARP, number);\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + total_size,\n\t\t\t\t\t\t\thook_entries,\n\t\t\t\t\t\t\tunderflows,\n\t\t\t\t\t\t\tname);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != number) {\n\t\tduprintf(\"translate_compat_table: %u not %u entries\\n\",\n\t\t\t j, number);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (info->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, hook_entries[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tif (info->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, underflows[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = number;\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = info->hook_entry[i];\n\t\tnewinfo->underflow[i] = info->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = total_size;\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = compat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t\t  name, newinfo, entry1);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\txt_compat_flush_offsets(NFPROTO_ARP);\n\txt_compat_unlock(NFPROTO_ARP);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\tret = -ELOOP;\n\tif (!mark_source_chains(newinfo, valid_hooks, entry1))\n\t\tgoto free_newinfo;\n\n\ti = 0;\n\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\titer1->counters.pcnt = xt_percpu_counter_alloc();\n\t\tif (IS_ERR_VALUE(iter1->counters.pcnt)) {\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = check_target(iter1, name);\n\t\tif (ret != 0) {\n\t\t\txt_percpu_counter_free(iter1->counters.pcnt);\n\t\t\tbreak;\n\t\t}\n\t\t++i;\n\t\tif (strcmp(arpt_get_target(iter1)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\tif (ret) {\n\t\t/*\n\t\t * The first i matches need cleanup_entry (calls ->destroy)\n\t\t * because they had called ->check already. The other j-i\n\t\t * entries need only release.\n\t\t */\n\t\tint skip = i;\n\t\tj -= i;\n\t\txt_entry_foreach(iter0, entry0, newinfo->size) {\n\t\t\tif (skip-- > 0)\n\t\t\t\tcontinue;\n\t\t\tif (j-- == 0)\n\t\t\t\tbreak;\n\t\t\tcompat_release_entry(iter0);\n\t\t}\n\t\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter1);\n\t\t}\n\t\txt_free_table_info(newinfo);\n\t\treturn ret;\n\t}\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\nout:\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(NFPROTO_ARP);\n\txt_compat_unlock(NFPROTO_ARP);\n\tgoto out;\n}\n\nstruct compat_arpt_replace {\n\tchar\t\t\t\tname[XT_TABLE_MAXNAMELEN];\n\tu32\t\t\t\tvalid_hooks;\n\tu32\t\t\t\tnum_entries;\n\tu32\t\t\t\tsize;\n\tu32\t\t\t\thook_entry[NF_ARP_NUMHOOKS];\n\tu32\t\t\t\tunderflow[NF_ARP_NUMHOOKS];\n\tu32\t\t\t\tnum_counters;\n\tcompat_uptr_t\t\t\tcounters;\n\tstruct compat_arpt_entry\tentries[0];\n};\n\nstatic int compat_do_replace(struct net *net, void __user *user,\n\t\t\t     unsigned int len)\n{\n\tint ret;\n\tstruct compat_arpt_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct arpt_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.size >= INT_MAX / num_possible_cpus())\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp), tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_compat_table(tmp.name, tmp.valid_hooks,\n\t\t\t\t     &newinfo, &loc_cpu_entry, tmp.size,\n\t\t\t\t     tmp.num_entries, tmp.hook_entry,\n\t\t\t\t     tmp.underflow);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"compat_do_replace: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, compat_ptr(tmp.counters));\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int compat_do_arpt_set_ctl(struct sock *sk, int cmd, void __user *user,\n\t\t\t\t  unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase ARPT_SO_SET_REPLACE:\n\t\tret = compat_do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase ARPT_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 1);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_arpt_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int compat_copy_entry_to_user(struct arpt_entry *e, void __user **dstptr,\n\t\t\t\t     compat_uint_t *size,\n\t\t\t\t     struct xt_counters *counters,\n\t\t\t\t     unsigned int i)\n{\n\tstruct xt_entry_target *t;\n\tstruct compat_arpt_entry __user *ce;\n\tu_int16_t target_offset, next_offset;\n\tcompat_uint_t origsize;\n\tint ret;\n\n\torigsize = *size;\n\tce = (struct compat_arpt_entry __user *)*dstptr;\n\tif (copy_to_user(ce, e, sizeof(struct arpt_entry)) != 0 ||\n\t    copy_to_user(&ce->counters, &counters[i],\n\t    sizeof(counters[i])) != 0)\n\t\treturn -EFAULT;\n\n\t*dstptr += sizeof(struct compat_arpt_entry);\n\t*size -= sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\n\ttarget_offset = e->target_offset - (origsize - *size);\n\n\tt = arpt_get_target(e);\n\tret = xt_compat_target_to_user(t, dstptr, size);\n\tif (ret)\n\t\treturn ret;\n\tnext_offset = e->next_offset - (origsize - *size);\n\tif (put_user(target_offset, &ce->target_offset) != 0 ||\n\t    put_user(next_offset, &ce->next_offset) != 0)\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int compat_copy_entries_to_user(unsigned int total_size,\n\t\t\t\t       struct xt_table *table,\n\t\t\t\t       void __user *userptr)\n{\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tvoid __user *pos;\n\tunsigned int size;\n\tint ret = 0;\n\tunsigned int i = 0;\n\tstruct arpt_entry *iter;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tpos = userptr;\n\tsize = total_size;\n\txt_entry_foreach(iter, private->entries, total_size) {\n\t\tret = compat_copy_entry_to_user(iter, &pos,\n\t\t\t\t\t\t&size, counters, i++);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\tvfree(counters);\n\treturn ret;\n}\n\nstruct compat_arpt_get_entries {\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tcompat_uint_t size;\n\tstruct compat_arpt_entry entrytable[0];\n};\n\nstatic int compat_get_entries(struct net *net,\n\t\t\t      struct compat_arpt_get_entries __user *uptr,\n\t\t\t      int *len)\n{\n\tint ret;\n\tstruct compat_arpt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"compat_get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct compat_arpt_get_entries) + get.size) {\n\t\tduprintf(\"compat_get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\txt_compat_lock(NFPROTO_ARP);\n\tt = xt_find_table_lock(net, NFPROTO_ARP, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tstruct xt_table_info info;\n\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tret = compat_table_info(private, &info);\n\t\tif (!ret && get.size == info.size) {\n\t\t\tret = compat_copy_entries_to_user(private->size,\n\t\t\t\t\t\t\t  t, uptr->entrytable);\n\t\t} else if (!ret) {\n\t\t\tduprintf(\"compat_get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\txt_compat_flush_offsets(NFPROTO_ARP);\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\txt_compat_unlock(NFPROTO_ARP);\n\treturn ret;\n}\n\nstatic int do_arpt_get_ctl(struct sock *, int, void __user *, int *);\n\nstatic int compat_do_arpt_get_ctl(struct sock *sk, int cmd, void __user *user,\n\t\t\t\t  int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase ARPT_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 1);\n\t\tbreak;\n\tcase ARPT_SO_GET_ENTRIES:\n\t\tret = compat_get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\tdefault:\n\t\tret = do_arpt_get_ctl(sk, cmd, user, len);\n\t}\n\treturn ret;\n}\n#endif\n\nstatic int do_arpt_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase ARPT_SO_SET_REPLACE:\n\t\tret = do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase ARPT_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_arpt_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int do_arpt_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase ARPT_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tcase ARPT_SO_GET_ENTRIES:\n\t\tret = get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase ARPT_SO_GET_REVISION_TARGET: {\n\t\tstruct xt_get_revision rev;\n\n\t\tif (*len != sizeof(rev)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&rev, user, sizeof(rev)) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\trev.name[sizeof(rev.name)-1] = 0;\n\n\t\ttry_then_request_module(xt_find_revision(NFPROTO_ARP, rev.name,\n\t\t\t\t\t\t\t rev.revision, 1, &ret),\n\t\t\t\t\t\"arpt_%s\", rev.name);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tduprintf(\"do_arpt_get_ctl: unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic void __arpt_unregister_table(struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\tvoid *loc_cpu_entry;\n\tstruct module *table_owner = table->me;\n\tstruct arpt_entry *iter;\n\n\tprivate = xt_unregister_table(table);\n\n\t/* Decrease module usage counts and free resources */\n\tloc_cpu_entry = private->entries;\n\txt_entry_foreach(iter, loc_cpu_entry, private->size)\n\t\tcleanup_entry(iter);\n\tif (private->number > private->initial_entries)\n\t\tmodule_put(table_owner);\n\txt_free_table_info(private);\n}\n\nint arpt_register_table(struct net *net,\n\t\t\tconst struct xt_table *table,\n\t\t\tconst struct arpt_replace *repl,\n\t\t\tconst struct nf_hook_ops *ops,\n\t\t\tstruct xt_table **res)\n{\n\tint ret;\n\tstruct xt_table_info *newinfo;\n\tstruct xt_table_info bootstrap = {0};\n\tvoid *loc_cpu_entry;\n\tstruct xt_table *new_table;\n\n\tnewinfo = xt_alloc_table_info(repl->size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tmemcpy(loc_cpu_entry, repl->entries, repl->size);\n\n\tret = translate_table(newinfo, loc_cpu_entry, repl);\n\tduprintf(\"arpt_register_table: translate table gives %d\\n\", ret);\n\tif (ret != 0)\n\t\tgoto out_free;\n\n\tnew_table = xt_register_table(net, table, &bootstrap, newinfo);\n\tif (IS_ERR(new_table)) {\n\t\tret = PTR_ERR(new_table);\n\t\tgoto out_free;\n\t}\n\n\t/* set res now, will see skbs right after nf_register_net_hooks */\n\tWRITE_ONCE(*res, new_table);\n\n\tret = nf_register_net_hooks(net, ops, hweight32(table->valid_hooks));\n\tif (ret != 0) {\n\t\t__arpt_unregister_table(new_table);\n\t\t*res = NULL;\n\t}\n\n\treturn ret;\n\nout_free:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nvoid arpt_unregister_table(struct net *net, struct xt_table *table,\n\t\t\t   const struct nf_hook_ops *ops)\n{\n\tnf_unregister_net_hooks(net, ops, hweight32(table->valid_hooks));\n\t__arpt_unregister_table(table);\n}\n\n/* The built-in targets: standard (NULL) and error. */\nstatic struct xt_target arpt_builtin_tg[] __read_mostly = {\n\t{\n\t\t.name             = XT_STANDARD_TARGET,\n\t\t.targetsize       = sizeof(int),\n\t\t.family           = NFPROTO_ARP,\n#ifdef CONFIG_COMPAT\n\t\t.compatsize       = sizeof(compat_int_t),\n\t\t.compat_from_user = compat_standard_from_user,\n\t\t.compat_to_user   = compat_standard_to_user,\n#endif\n\t},\n\t{\n\t\t.name             = XT_ERROR_TARGET,\n\t\t.target           = arpt_error,\n\t\t.targetsize       = XT_FUNCTION_MAXNAMELEN,\n\t\t.family           = NFPROTO_ARP,\n\t},\n};\n\nstatic struct nf_sockopt_ops arpt_sockopts = {\n\t.pf\t\t= PF_INET,\n\t.set_optmin\t= ARPT_BASE_CTL,\n\t.set_optmax\t= ARPT_SO_SET_MAX+1,\n\t.set\t\t= do_arpt_set_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_set\t= compat_do_arpt_set_ctl,\n#endif\n\t.get_optmin\t= ARPT_BASE_CTL,\n\t.get_optmax\t= ARPT_SO_GET_MAX+1,\n\t.get\t\t= do_arpt_get_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_get\t= compat_do_arpt_get_ctl,\n#endif\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic int __net_init arp_tables_net_init(struct net *net)\n{\n\treturn xt_proto_init(net, NFPROTO_ARP);\n}\n\nstatic void __net_exit arp_tables_net_exit(struct net *net)\n{\n\txt_proto_fini(net, NFPROTO_ARP);\n}\n\nstatic struct pernet_operations arp_tables_net_ops = {\n\t.init = arp_tables_net_init,\n\t.exit = arp_tables_net_exit,\n};\n\nstatic int __init arp_tables_init(void)\n{\n\tint ret;\n\n\tret = register_pernet_subsys(&arp_tables_net_ops);\n\tif (ret < 0)\n\t\tgoto err1;\n\n\t/* No one else will be downing sem now, so we won't sleep */\n\tret = xt_register_targets(arpt_builtin_tg, ARRAY_SIZE(arpt_builtin_tg));\n\tif (ret < 0)\n\t\tgoto err2;\n\n\t/* Register setsockopt */\n\tret = nf_register_sockopt(&arpt_sockopts);\n\tif (ret < 0)\n\t\tgoto err4;\n\n\tpr_info(\"arp_tables: (C) 2002 David S. Miller\\n\");\n\treturn 0;\n\nerr4:\n\txt_unregister_targets(arpt_builtin_tg, ARRAY_SIZE(arpt_builtin_tg));\nerr2:\n\tunregister_pernet_subsys(&arp_tables_net_ops);\nerr1:\n\treturn ret;\n}\n\nstatic void __exit arp_tables_fini(void)\n{\n\tnf_unregister_sockopt(&arpt_sockopts);\n\txt_unregister_targets(arpt_builtin_tg, ARRAY_SIZE(arpt_builtin_tg));\n\tunregister_pernet_subsys(&arp_tables_net_ops);\n}\n\nEXPORT_SYMBOL(arpt_register_table);\nEXPORT_SYMBOL(arpt_unregister_table);\nEXPORT_SYMBOL(arpt_do_table);\n\nmodule_init(arp_tables_init);\nmodule_exit(arp_tables_fini);\n", "/*\n * Packet matching code.\n *\n * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling\n * Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>\n * Copyright (C) 2006-2010 Patrick McHardy <kaber@trash.net>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/cache.h>\n#include <linux/capability.h>\n#include <linux/skbuff.h>\n#include <linux/kmod.h>\n#include <linux/vmalloc.h>\n#include <linux/netdevice.h>\n#include <linux/module.h>\n#include <linux/icmp.h>\n#include <net/ip.h>\n#include <net/compat.h>\n#include <asm/uaccess.h>\n#include <linux/mutex.h>\n#include <linux/proc_fs.h>\n#include <linux/err.h>\n#include <linux/cpumask.h>\n\n#include <linux/netfilter/x_tables.h>\n#include <linux/netfilter_ipv4/ip_tables.h>\n#include <net/netfilter/nf_log.h>\n#include \"../../netfilter/xt_repldata.h\"\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Netfilter Core Team <coreteam@netfilter.org>\");\nMODULE_DESCRIPTION(\"IPv4 packet filter\");\n\n/*#define DEBUG_IP_FIREWALL*/\n/*#define DEBUG_ALLOW_ALL*/ /* Useful for remote debugging */\n/*#define DEBUG_IP_FIREWALL_USER*/\n\n#ifdef DEBUG_IP_FIREWALL\n#define dprintf(format, args...) pr_info(format , ## args)\n#else\n#define dprintf(format, args...)\n#endif\n\n#ifdef DEBUG_IP_FIREWALL_USER\n#define duprintf(format, args...) pr_info(format , ## args)\n#else\n#define duprintf(format, args...)\n#endif\n\n#ifdef CONFIG_NETFILTER_DEBUG\n#define IP_NF_ASSERT(x)\t\tWARN_ON(!(x))\n#else\n#define IP_NF_ASSERT(x)\n#endif\n\n#if 0\n/* All the better to debug you with... */\n#define static\n#define inline\n#endif\n\nvoid *ipt_alloc_initial_table(const struct xt_table *info)\n{\n\treturn xt_alloc_initial_table(ipt, IPT);\n}\nEXPORT_SYMBOL_GPL(ipt_alloc_initial_table);\n\n/* Returns whether matches rule or not. */\n/* Performance critical - called for every packet */\nstatic inline bool\nip_packet_match(const struct iphdr *ip,\n\t\tconst char *indev,\n\t\tconst char *outdev,\n\t\tconst struct ipt_ip *ipinfo,\n\t\tint isfrag)\n{\n\tunsigned long ret;\n\n#define FWINV(bool, invflg) ((bool) ^ !!(ipinfo->invflags & (invflg)))\n\n\tif (FWINV((ip->saddr&ipinfo->smsk.s_addr) != ipinfo->src.s_addr,\n\t\t  IPT_INV_SRCIP) ||\n\t    FWINV((ip->daddr&ipinfo->dmsk.s_addr) != ipinfo->dst.s_addr,\n\t\t  IPT_INV_DSTIP)) {\n\t\tdprintf(\"Source or dest mismatch.\\n\");\n\n\t\tdprintf(\"SRC: %pI4. Mask: %pI4. Target: %pI4.%s\\n\",\n\t\t\t&ip->saddr, &ipinfo->smsk.s_addr, &ipinfo->src.s_addr,\n\t\t\tipinfo->invflags & IPT_INV_SRCIP ? \" (INV)\" : \"\");\n\t\tdprintf(\"DST: %pI4 Mask: %pI4 Target: %pI4.%s\\n\",\n\t\t\t&ip->daddr, &ipinfo->dmsk.s_addr, &ipinfo->dst.s_addr,\n\t\t\tipinfo->invflags & IPT_INV_DSTIP ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\tret = ifname_compare_aligned(indev, ipinfo->iniface, ipinfo->iniface_mask);\n\n\tif (FWINV(ret != 0, IPT_INV_VIA_IN)) {\n\t\tdprintf(\"VIA in mismatch (%s vs %s).%s\\n\",\n\t\t\tindev, ipinfo->iniface,\n\t\t\tipinfo->invflags & IPT_INV_VIA_IN ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\tret = ifname_compare_aligned(outdev, ipinfo->outiface, ipinfo->outiface_mask);\n\n\tif (FWINV(ret != 0, IPT_INV_VIA_OUT)) {\n\t\tdprintf(\"VIA out mismatch (%s vs %s).%s\\n\",\n\t\t\toutdev, ipinfo->outiface,\n\t\t\tipinfo->invflags & IPT_INV_VIA_OUT ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\t/* Check specific protocol */\n\tif (ipinfo->proto &&\n\t    FWINV(ip->protocol != ipinfo->proto, IPT_INV_PROTO)) {\n\t\tdprintf(\"Packet protocol %hi does not match %hi.%s\\n\",\n\t\t\tip->protocol, ipinfo->proto,\n\t\t\tipinfo->invflags & IPT_INV_PROTO ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\t/* If we have a fragment rule but the packet is not a fragment\n\t * then we return zero */\n\tif (FWINV((ipinfo->flags&IPT_F_FRAG) && !isfrag, IPT_INV_FRAG)) {\n\t\tdprintf(\"Fragment rule but not fragment.%s\\n\",\n\t\t\tipinfo->invflags & IPT_INV_FRAG ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool\nip_checkentry(const struct ipt_ip *ip)\n{\n\tif (ip->flags & ~IPT_F_MASK) {\n\t\tduprintf(\"Unknown flag bits set: %08X\\n\",\n\t\t\t ip->flags & ~IPT_F_MASK);\n\t\treturn false;\n\t}\n\tif (ip->invflags & ~IPT_INV_MASK) {\n\t\tduprintf(\"Unknown invflag bits set: %08X\\n\",\n\t\t\t ip->invflags & ~IPT_INV_MASK);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic unsigned int\nipt_error(struct sk_buff *skb, const struct xt_action_param *par)\n{\n\tnet_info_ratelimited(\"error: `%s'\\n\", (const char *)par->targinfo);\n\n\treturn NF_DROP;\n}\n\n/* Performance critical */\nstatic inline struct ipt_entry *\nget_entry(const void *base, unsigned int offset)\n{\n\treturn (struct ipt_entry *)(base + offset);\n}\n\n/* All zeroes == unconditional rule. */\n/* Mildly perf critical (only if packet tracing is on) */\nstatic inline bool unconditional(const struct ipt_entry *e)\n{\n\tstatic const struct ipt_ip uncond;\n\n\treturn e->target_offset == sizeof(struct ipt_entry) &&\n\t       memcmp(&e->ip, &uncond, sizeof(uncond)) == 0;\n#undef FWINV\n}\n\n/* for const-correctness */\nstatic inline const struct xt_entry_target *\nipt_get_target_c(const struct ipt_entry *e)\n{\n\treturn ipt_get_target((struct ipt_entry *)e);\n}\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\nstatic const char *const hooknames[] = {\n\t[NF_INET_PRE_ROUTING]\t\t= \"PREROUTING\",\n\t[NF_INET_LOCAL_IN]\t\t= \"INPUT\",\n\t[NF_INET_FORWARD]\t\t= \"FORWARD\",\n\t[NF_INET_LOCAL_OUT]\t\t= \"OUTPUT\",\n\t[NF_INET_POST_ROUTING]\t\t= \"POSTROUTING\",\n};\n\nenum nf_ip_trace_comments {\n\tNF_IP_TRACE_COMMENT_RULE,\n\tNF_IP_TRACE_COMMENT_RETURN,\n\tNF_IP_TRACE_COMMENT_POLICY,\n};\n\nstatic const char *const comments[] = {\n\t[NF_IP_TRACE_COMMENT_RULE]\t= \"rule\",\n\t[NF_IP_TRACE_COMMENT_RETURN]\t= \"return\",\n\t[NF_IP_TRACE_COMMENT_POLICY]\t= \"policy\",\n};\n\nstatic struct nf_loginfo trace_loginfo = {\n\t.type = NF_LOG_TYPE_LOG,\n\t.u = {\n\t\t.log = {\n\t\t\t.level = 4,\n\t\t\t.logflags = NF_LOG_MASK,\n\t\t},\n\t},\n};\n\n/* Mildly perf critical (only if packet tracing is on) */\nstatic inline int\nget_chainname_rulenum(const struct ipt_entry *s, const struct ipt_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ipt_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (unconditional(s) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t   t->verdict < 0) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}\n\nstatic void trace_packet(struct net *net,\n\t\t\t const struct sk_buff *skb,\n\t\t\t unsigned int hook,\n\t\t\t const struct net_device *in,\n\t\t\t const struct net_device *out,\n\t\t\t const char *tablename,\n\t\t\t const struct xt_table_info *private,\n\t\t\t const struct ipt_entry *e)\n{\n\tconst struct ipt_entry *root;\n\tconst char *hookname, *chainname, *comment;\n\tconst struct ipt_entry *iter;\n\tunsigned int rulenum = 0;\n\n\troot = get_entry(private->entries, private->hook_entry[hook]);\n\n\thookname = chainname = hooknames[hook];\n\tcomment = comments[NF_IP_TRACE_COMMENT_RULE];\n\n\txt_entry_foreach(iter, root, private->size - private->hook_entry[hook])\n\t\tif (get_chainname_rulenum(iter, e, hookname,\n\t\t    &chainname, &comment, &rulenum) != 0)\n\t\t\tbreak;\n\n\tnf_log_trace(net, AF_INET, hook, skb, in, out, &trace_loginfo,\n\t\t     \"TRACE: %s:%s:%s:%u \",\n\t\t     tablename, chainname, comment, rulenum);\n}\n#endif\n\nstatic inline\nstruct ipt_entry *ipt_next_entry(const struct ipt_entry *entry)\n{\n\treturn (void *)entry + entry->next_offset;\n}\n\n/* Returns one of the generic firewall policies, like NF_ACCEPT. */\nunsigned int\nipt_do_table(struct sk_buff *skb,\n\t     const struct nf_hook_state *state,\n\t     struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\tconst struct iphdr *ip;\n\t/* Initializing verdict to NF_DROP keeps gcc happy. */\n\tunsigned int verdict = NF_DROP;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tstruct ipt_entry *e, **jumpstack;\n\tunsigned int stackidx, cpu;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\t/* Initialization */\n\tstackidx = 0;\n\tip = ip_hdr(skb);\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\t/* We handle fragments by dealing with the first fragment as\n\t * if it was a normal packet.  All other fragments are treated\n\t * normally, except that they will NEVER match rules that ask\n\t * things we don't know, ie. tcp syn flag or ports).  If the\n\t * rule is also a fragment-specific rule, non-fragments won't\n\t * match it. */\n\tacpar.fragoff = ntohs(ip->frag_off) & IP_OFFSET;\n\tacpar.thoff   = ip_hdrlen(skb);\n\tacpar.hotdrop = false;\n\tacpar.net     = state->net;\n\tacpar.in      = state->in;\n\tacpar.out     = state->out;\n\tacpar.family  = NFPROTO_IPV4;\n\tacpar.hooknum = hook;\n\n\tIP_NF_ASSERT(table->valid_hooks & (1 << hook));\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = table->private;\n\tcpu        = smp_processor_id();\n\t/*\n\t * Ensure we load private-> members after we've fetched the base\n\t * pointer.\n\t */\n\tsmp_read_barrier_depends();\n\ttable_base = private->entries;\n\tjumpstack  = (struct ipt_entry **)private->jumpstack[cpu];\n\n\t/* Switch to alternate jumpstack if we're being invoked via TEE.\n\t * TEE issues XT_CONTINUE verdict on original skb so we must not\n\t * clobber the jumpstack.\n\t *\n\t * For recursion via REJECT or SYNPROXY the stack will be clobbered\n\t * but it is no problem since absolute verdict is issued by these.\n\t */\n\tif (static_key_false(&xt_tee_enabled))\n\t\tjumpstack += private->stacksize * __this_cpu_read(nf_skb_duplicated);\n\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tpr_debug(\"Entering %s(hook %u), UF %p\\n\",\n\t\t table->name, hook,\n\t\t get_entry(table_base, private->underflow[hook]));\n\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tconst struct xt_entry_match *ematch;\n\t\tstruct xt_counters *counter;\n\n\t\tIP_NF_ASSERT(e);\n\t\tif (!ip_packet_match(ip, indev, outdev,\n\t\t    &e->ip, acpar.fragoff)) {\n no_match:\n\t\t\te = ipt_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\txt_ematch_foreach(ematch, e) {\n\t\t\tacpar.match     = ematch->u.kernel.match;\n\t\t\tacpar.matchinfo = ematch->data;\n\t\t\tif (!acpar.match->match(skb, &acpar))\n\t\t\t\tgoto no_match;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, skb->len, 1);\n\n\t\tt = ipt_get_target(e);\n\t\tIP_NF_ASSERT(t->u.kernel.target);\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n\t\t/* The packet is traced: log it */\n\t\tif (unlikely(skb->nf_trace))\n\t\t\ttrace_packet(state->net, skb, hook, state->in,\n\t\t\t\t     state->out, table->name, private, e);\n#endif\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0) {\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t    private->underflow[hook]);\n\t\t\t\t\tpr_debug(\"Underflow (this is normal) \"\n\t\t\t\t\t\t \"to %p\\n\", e);\n\t\t\t\t} else {\n\t\t\t\t\te = jumpstack[--stackidx];\n\t\t\t\t\tpr_debug(\"Pulled %p out from pos %u\\n\",\n\t\t\t\t\t\t e, stackidx);\n\t\t\t\t\te = ipt_next_entry(e);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v != ipt_next_entry(e) &&\n\t\t\t    !(e->ip.flags & IPT_F_GOTO)) {\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t\tpr_debug(\"Pushed %p into pos %u\\n\",\n\t\t\t\t\t e, stackidx - 1);\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\t\t/* Target might have changed stuff. */\n\t\tip = ip_hdr(skb);\n\t\tif (verdict == XT_CONTINUE)\n\t\t\te = ipt_next_entry(e);\n\t\telse\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t} while (!acpar.hotdrop);\n\tpr_debug(\"Exiting %s; sp at %u\\n\", __func__, stackidx);\n\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n#ifdef DEBUG_ALLOW_ALL\n\treturn NF_ACCEPT;\n#else\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse return verdict;\n#endif\n}\n\nstatic bool find_jump_target(const struct xt_table_info *t,\n\t\t\t     const struct ipt_entry *target)\n{\n\tstruct ipt_entry *iter;\n\n\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t if (iter == target)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n/* Figures out from what hook each rule can be called: returns 0 if\n   there are loops.  Puts hook bitmask in comefrom. */\nstatic int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ipt_entry *e = (struct ipt_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ipt_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\tif (pos + size >= newinfo->size)\n\t\t\t\t\treturn 0;\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ipt_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t\t(entry0 + newpos);\n\t\t\t\t\tif (!find_jump_target(newinfo, e))\n\t\t\t\t\t\treturn 0;\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t\tif (newpos >= newinfo->size)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}\n\nstatic void cleanup_match(struct xt_entry_match *m, struct net *net)\n{\n\tstruct xt_mtdtor_param par;\n\n\tpar.net       = net;\n\tpar.match     = m->u.kernel.match;\n\tpar.matchinfo = m->data;\n\tpar.family    = NFPROTO_IPV4;\n\tif (par.match->destroy != NULL)\n\t\tpar.match->destroy(&par);\n\tmodule_put(par.match->me);\n}\n\nstatic int\ncheck_match(struct xt_entry_match *m, struct xt_mtchk_param *par)\n{\n\tconst struct ipt_ip *ip = par->entryinfo;\n\tint ret;\n\n\tpar->match     = m->u.kernel.match;\n\tpar->matchinfo = m->data;\n\n\tret = xt_check_match(par, m->u.match_size - sizeof(*m),\n\t      ip->proto, ip->invflags & IPT_INV_PROTO);\n\tif (ret < 0) {\n\t\tduprintf(\"check failed for `%s'.\\n\", par->match->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int\nfind_check_match(struct xt_entry_match *m, struct xt_mtchk_param *par)\n{\n\tstruct xt_match *match;\n\tint ret;\n\n\tmatch = xt_request_find_match(NFPROTO_IPV4, m->u.user.name,\n\t\t\t\t      m->u.user.revision);\n\tif (IS_ERR(match)) {\n\t\tduprintf(\"find_check_match: `%s' not found\\n\", m->u.user.name);\n\t\treturn PTR_ERR(match);\n\t}\n\tm->u.kernel.match = match;\n\n\tret = check_match(m, par);\n\tif (ret)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tmodule_put(m->u.kernel.match->me);\n\treturn ret;\n}\n\nstatic int check_target(struct ipt_entry *e, struct net *net, const char *name)\n{\n\tstruct xt_entry_target *t = ipt_get_target(e);\n\tstruct xt_tgchk_param par = {\n\t\t.net       = net,\n\t\t.table     = name,\n\t\t.entryinfo = e,\n\t\t.target    = t->u.kernel.target,\n\t\t.targinfo  = t->data,\n\t\t.hook_mask = e->comefrom,\n\t\t.family    = NFPROTO_IPV4,\n\t};\n\tint ret;\n\n\tret = xt_check_target(&par, t->u.target_size - sizeof(*t),\n\t      e->ip.proto, e->ip.invflags & IPT_INV_PROTO);\n\tif (ret < 0) {\n\t\tduprintf(\"check failed for `%s'.\\n\",\n\t\t\t t->u.kernel.target->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int\nfind_check_entry(struct ipt_entry *e, struct net *net, const char *name,\n\t\t unsigned int size)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tint ret;\n\tunsigned int j;\n\tstruct xt_mtchk_param mtpar;\n\tstruct xt_entry_match *ematch;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\n\tj = 0;\n\tmtpar.net\t= net;\n\tmtpar.table     = name;\n\tmtpar.entryinfo = &e->ip;\n\tmtpar.hook_mask = e->comefrom;\n\tmtpar.family    = NFPROTO_IPV4;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = find_check_match(ematch, &mtpar);\n\t\tif (ret != 0)\n\t\t\tgoto cleanup_matches;\n\t\t++j;\n\t}\n\n\tt = ipt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"find_check_entry: `%s' not found\\n\", t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto cleanup_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\tret = check_target(e, net, name);\n\tif (ret)\n\t\tgoto err;\n\n\treturn 0;\n err:\n\tmodule_put(t->u.kernel.target->me);\n cleanup_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcleanup_match(ematch, net);\n\t}\n\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic bool check_underflow(const struct ipt_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = ipt_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n\nstatic int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}\n\nstatic void\ncleanup_entry(struct ipt_entry *e, struct net *net)\n{\n\tstruct xt_tgdtor_param par;\n\tstruct xt_entry_target *t;\n\tstruct xt_entry_match *ematch;\n\n\t/* Cleanup all matches */\n\txt_ematch_foreach(ematch, e)\n\t\tcleanup_match(ematch, net);\n\tt = ipt_get_target(e);\n\n\tpar.net      = net;\n\tpar.target   = t->u.kernel.target;\n\tpar.targinfo = t->data;\n\tpar.family   = NFPROTO_IPV4;\n\tif (par.target->destroy != NULL)\n\t\tpar.target->destroy(&par);\n\tmodule_put(par.target->me);\n\txt_percpu_counter_free(e->counters.pcnt);\n}\n\n/* Checks and translates the user-supplied table segment (held in\n   newinfo) */\nstatic int\ntranslate_table(struct net *net, struct xt_table_info *newinfo, void *entry0,\n\t\tconst struct ipt_replace *repl)\n{\n\tstruct ipt_entry *iter;\n\tunsigned int i;\n\tint ret = 0;\n\n\tnewinfo->size = repl->size;\n\tnewinfo->number = repl->num_entries;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tnewinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_table: size %u\\n\", newinfo->size);\n\ti = 0;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = check_entry_size_and_hooks(iter, newinfo, entry0,\n\t\t\t\t\t\t entry0 + repl->size,\n\t\t\t\t\t\t repl->hook_entry,\n\t\t\t\t\t\t repl->underflow,\n\t\t\t\t\t\t repl->valid_hooks);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t\t++i;\n\t\tif (strcmp(ipt_get_target(iter)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\n\tif (i != repl->num_entries) {\n\t\tduprintf(\"translate_table: %u not %u entries\\n\",\n\t\t\t i, repl->num_entries);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(repl->valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (newinfo->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, repl->hook_entry[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (newinfo->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, repl->underflow[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!mark_source_chains(newinfo, repl->valid_hooks, entry0))\n\t\treturn -ELOOP;\n\n\t/* Finally, each sanity check must pass */\n\ti = 0;\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = find_check_entry(iter, net, repl->name, repl->size);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t}\n\n\tif (ret != 0) {\n\t\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter, net);\n\t\t}\n\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic void\nget_counters(const struct xt_table_info *t,\n\t     struct xt_counters counters[])\n{\n\tstruct ipt_entry *iter;\n\tunsigned int cpu;\n\tunsigned int i;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tseqcount_t *s = &per_cpu(xt_recseq, cpu);\n\n\t\ti = 0;\n\t\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t\tstruct xt_counters *tmp;\n\t\t\tu64 bcnt, pcnt;\n\t\t\tunsigned int start;\n\n\t\t\ttmp = xt_get_per_cpu_counter(&iter->counters, cpu);\n\t\t\tdo {\n\t\t\t\tstart = read_seqcount_begin(s);\n\t\t\t\tbcnt = tmp->bcnt;\n\t\t\t\tpcnt = tmp->pcnt;\n\t\t\t} while (read_seqcount_retry(s, start));\n\n\t\t\tADD_COUNTER(counters[i], bcnt, pcnt);\n\t\t\t++i; /* macro does multi eval of i */\n\t\t}\n\t}\n}\n\nstatic struct xt_counters *alloc_counters(const struct xt_table *table)\n{\n\tunsigned int countersize;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\n\t/* We need atomic snapshot of counters: rest doesn't change\n\t   (other than comefrom, which userspace doesn't care\n\t   about). */\n\tcountersize = sizeof(struct xt_counters) * private->number;\n\tcounters = vzalloc(countersize);\n\n\tif (counters == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tget_counters(private, counters);\n\n\treturn counters;\n}\n\nstatic int\ncopy_entries_to_user(unsigned int total_size,\n\t\t     const struct xt_table *table,\n\t\t     void __user *userptr)\n{\n\tunsigned int off, num;\n\tconst struct ipt_entry *e;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tint ret = 0;\n\tconst void *loc_cpu_entry;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tloc_cpu_entry = private->entries;\n\tif (copy_to_user(userptr, loc_cpu_entry, total_size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_counters;\n\t}\n\n\t/* FIXME: use iterator macros --RR */\n\t/* ... then go back and fix counters and names */\n\tfor (off = 0, num = 0; off < total_size; off += e->next_offset, num++){\n\t\tunsigned int i;\n\t\tconst struct xt_entry_match *m;\n\t\tconst struct xt_entry_target *t;\n\n\t\te = (struct ipt_entry *)(loc_cpu_entry + off);\n\t\tif (copy_to_user(userptr + off\n\t\t\t\t + offsetof(struct ipt_entry, counters),\n\t\t\t\t &counters[num],\n\t\t\t\t sizeof(counters[num])) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\n\t\tfor (i = sizeof(struct ipt_entry);\n\t\t     i < e->target_offset;\n\t\t     i += m->u.match_size) {\n\t\t\tm = (void *)e + i;\n\n\t\t\tif (copy_to_user(userptr + off + i\n\t\t\t\t\t + offsetof(struct xt_entry_match,\n\t\t\t\t\t\t    u.user.name),\n\t\t\t\t\t m->u.kernel.match->name,\n\t\t\t\t\t strlen(m->u.kernel.match->name)+1)\n\t\t\t    != 0) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto free_counters;\n\t\t\t}\n\t\t}\n\n\t\tt = ipt_get_target_c(e);\n\t\tif (copy_to_user(userptr + off + e->target_offset\n\t\t\t\t + offsetof(struct xt_entry_target,\n\t\t\t\t\t    u.user.name),\n\t\t\t\t t->u.kernel.target->name,\n\t\t\t\t strlen(t->u.kernel.target->name)+1) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\t}\n\n free_counters:\n\tvfree(counters);\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic void compat_standard_from_user(void *dst, const void *src)\n{\n\tint v = *(compat_int_t *)src;\n\n\tif (v > 0)\n\t\tv += xt_compat_calc_jump(AF_INET, v);\n\tmemcpy(dst, &v, sizeof(v));\n}\n\nstatic int compat_standard_to_user(void __user *dst, const void *src)\n{\n\tcompat_int_t cv = *(int *)src;\n\n\tif (cv > 0)\n\t\tcv -= xt_compat_calc_jump(AF_INET, cv);\n\treturn copy_to_user(dst, &cv, sizeof(cv)) ? -EFAULT : 0;\n}\n\nstatic int compat_calc_entry(const struct ipt_entry *e,\n\t\t\t     const struct xt_table_info *info,\n\t\t\t     const void *base, struct xt_table_info *newinfo)\n{\n\tconst struct xt_entry_match *ematch;\n\tconst struct xt_entry_target *t;\n\tunsigned int entry_offset;\n\tint off, i, ret;\n\n\toff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\tentry_offset = (void *)e - base;\n\txt_ematch_foreach(ematch, e)\n\t\toff += xt_compat_match_offset(ematch->u.kernel.match);\n\tt = ipt_get_target_c(e);\n\toff += xt_compat_target_offset(t->u.kernel.target);\n\tnewinfo->size -= off;\n\tret = xt_compat_add_offset(AF_INET, entry_offset, off);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tif (info->hook_entry[i] &&\n\t\t    (e < (struct ipt_entry *)(base + info->hook_entry[i])))\n\t\t\tnewinfo->hook_entry[i] -= off;\n\t\tif (info->underflow[i] &&\n\t\t    (e < (struct ipt_entry *)(base + info->underflow[i])))\n\t\t\tnewinfo->underflow[i] -= off;\n\t}\n\treturn 0;\n}\n\nstatic int compat_table_info(const struct xt_table_info *info,\n\t\t\t     struct xt_table_info *newinfo)\n{\n\tstruct ipt_entry *iter;\n\tconst void *loc_cpu_entry;\n\tint ret;\n\n\tif (!newinfo || !info)\n\t\treturn -EINVAL;\n\n\t/* we dont care about newinfo->entries */\n\tmemcpy(newinfo, info, offsetof(struct xt_table_info, entries));\n\tnewinfo->initial_entries = 0;\n\tloc_cpu_entry = info->entries;\n\txt_compat_init_offsets(AF_INET, info->number);\n\txt_entry_foreach(iter, loc_cpu_entry, info->size) {\n\t\tret = compat_calc_entry(iter, info, loc_cpu_entry, newinfo);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n#endif\n\nstatic int get_info(struct net *net, void __user *user,\n\t\t    const int *len, int compat)\n{\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tstruct xt_table *t;\n\tint ret;\n\n\tif (*len != sizeof(struct ipt_getinfo)) {\n\t\tduprintf(\"length %u != %zu\\n\", *len,\n\t\t\t sizeof(struct ipt_getinfo));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(name, user, sizeof(name)) != 0)\n\t\treturn -EFAULT;\n\n\tname[XT_TABLE_MAXNAMELEN-1] = '\\0';\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_lock(AF_INET);\n#endif\n\tt = try_then_request_module(xt_find_table_lock(net, AF_INET, name),\n\t\t\t\t    \"iptable_%s\", name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tstruct ipt_getinfo info;\n\t\tconst struct xt_table_info *private = t->private;\n#ifdef CONFIG_COMPAT\n\t\tstruct xt_table_info tmp;\n\n\t\tif (compat) {\n\t\t\tret = compat_table_info(private, &tmp);\n\t\t\txt_compat_flush_offsets(AF_INET);\n\t\t\tprivate = &tmp;\n\t\t}\n#endif\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.valid_hooks = t->valid_hooks;\n\t\tmemcpy(info.hook_entry, private->hook_entry,\n\t\t       sizeof(info.hook_entry));\n\t\tmemcpy(info.underflow, private->underflow,\n\t\t       sizeof(info.underflow));\n\t\tinfo.num_entries = private->number;\n\t\tinfo.size = private->size;\n\t\tstrcpy(info.name, name);\n\n\t\tif (copy_to_user(user, &info, *len) != 0)\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = 0;\n\n\t\txt_table_unlock(t);\n\t\tmodule_put(t->me);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_unlock(AF_INET);\n#endif\n\treturn ret;\n}\n\nstatic int\nget_entries(struct net *net, struct ipt_get_entries __user *uptr,\n\t    const int *len)\n{\n\tint ret;\n\tstruct ipt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct ipt_get_entries) + get.size) {\n\t\tduprintf(\"get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, AF_INET, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse {\n\t\t\tduprintf(\"get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\treturn ret;\n}\n\nstatic int\n__do_replace(struct net *net, const char *name, unsigned int valid_hooks,\n\t     struct xt_table_info *newinfo, unsigned int num_counters,\n\t     void __user *counters_ptr)\n{\n\tint ret;\n\tstruct xt_table *t;\n\tstruct xt_table_info *oldinfo;\n\tstruct xt_counters *counters;\n\tstruct ipt_entry *iter;\n\n\tret = 0;\n\tcounters = vzalloc(num_counters * sizeof(struct xt_counters));\n\tif (!counters) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tt = try_then_request_module(xt_find_table_lock(net, AF_INET, name),\n\t\t\t\t    \"iptable_%s\", name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free_newinfo_counters_untrans;\n\t}\n\n\t/* You lied! */\n\tif (valid_hooks != t->valid_hooks) {\n\t\tduprintf(\"Valid hook crap: %08X vs %08X\\n\",\n\t\t\t valid_hooks, t->valid_hooks);\n\t\tret = -EINVAL;\n\t\tgoto put_module;\n\t}\n\n\toldinfo = xt_replace_table(t, num_counters, newinfo, &ret);\n\tif (!oldinfo)\n\t\tgoto put_module;\n\n\t/* Update module usage count based on number of rules */\n\tduprintf(\"do_replace: oldnum=%u, initnum=%u, newnum=%u\\n\",\n\t\toldinfo->number, oldinfo->initial_entries, newinfo->number);\n\tif ((oldinfo->number > oldinfo->initial_entries) ||\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\tif ((oldinfo->number > oldinfo->initial_entries) &&\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\n\t/* Get the old counters, and synchronize with replace */\n\tget_counters(oldinfo, counters);\n\n\t/* Decrease module usage counts and free resource */\n\txt_entry_foreach(iter, oldinfo->entries, oldinfo->size)\n\t\tcleanup_entry(iter, net);\n\n\txt_free_table_info(oldinfo);\n\tif (copy_to_user(counters_ptr, counters,\n\t\t\t sizeof(struct xt_counters) * num_counters) != 0) {\n\t\t/* Silent error, can't fail, new table is already in place */\n\t\tnet_warn_ratelimited(\"iptables: counters copy to user failed while replacing table\\n\");\n\t}\n\tvfree(counters);\n\txt_table_unlock(t);\n\treturn ret;\n\n put_module:\n\tmodule_put(t->me);\n\txt_table_unlock(t);\n free_newinfo_counters_untrans:\n\tvfree(counters);\n out:\n\treturn ret;\n}\n\nstatic int\ndo_replace(struct net *net, const void __user *user, unsigned int len)\n{\n\tint ret;\n\tstruct ipt_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct ipt_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_table(net, newinfo, loc_cpu_entry, &tmp);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, tmp.counters);\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter, net);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int\ndo_add_counters(struct net *net, const void __user *user,\n\t\tunsigned int len, int compat)\n{\n\tunsigned int i;\n\tstruct xt_counters_info tmp;\n\tstruct xt_counters *paddc;\n\tunsigned int num_counters;\n\tconst char *name;\n\tint size;\n\tvoid *ptmp;\n\tstruct xt_table *t;\n\tconst struct xt_table_info *private;\n\tint ret = 0;\n\tstruct ipt_entry *iter;\n\tunsigned int addend;\n#ifdef CONFIG_COMPAT\n\tstruct compat_xt_counters_info compat_tmp;\n\n\tif (compat) {\n\t\tptmp = &compat_tmp;\n\t\tsize = sizeof(struct compat_xt_counters_info);\n\t} else\n#endif\n\t{\n\t\tptmp = &tmp;\n\t\tsize = sizeof(struct xt_counters_info);\n\t}\n\n\tif (copy_from_user(ptmp, user, size) != 0)\n\t\treturn -EFAULT;\n\n#ifdef CONFIG_COMPAT\n\tif (compat) {\n\t\tnum_counters = compat_tmp.num_counters;\n\t\tname = compat_tmp.name;\n\t} else\n#endif\n\t{\n\t\tnum_counters = tmp.num_counters;\n\t\tname = tmp.name;\n\t}\n\n\tif (len != size + num_counters * sizeof(struct xt_counters))\n\t\treturn -EINVAL;\n\n\tpaddc = vmalloc(len - size);\n\tif (!paddc)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(paddc, user + size, len - size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free;\n\t}\n\n\tt = xt_find_table_lock(net, AF_INET, name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free;\n\t}\n\n\tlocal_bh_disable();\n\tprivate = t->private;\n\tif (private->number != num_counters) {\n\t\tret = -EINVAL;\n\t\tgoto unlock_up_free;\n\t}\n\n\ti = 0;\n\taddend = xt_write_recseq_begin();\n\txt_entry_foreach(iter, private->entries, private->size) {\n\t\tstruct xt_counters *tmp;\n\n\t\ttmp = xt_get_this_cpu_counter(&iter->counters);\n\t\tADD_COUNTER(*tmp, paddc[i].bcnt, paddc[i].pcnt);\n\t\t++i;\n\t}\n\txt_write_recseq_end(addend);\n unlock_up_free:\n\tlocal_bh_enable();\n\txt_table_unlock(t);\n\tmodule_put(t->me);\n free:\n\tvfree(paddc);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_ipt_replace {\n\tchar\t\t\tname[XT_TABLE_MAXNAMELEN];\n\tu32\t\t\tvalid_hooks;\n\tu32\t\t\tnum_entries;\n\tu32\t\t\tsize;\n\tu32\t\t\thook_entry[NF_INET_NUMHOOKS];\n\tu32\t\t\tunderflow[NF_INET_NUMHOOKS];\n\tu32\t\t\tnum_counters;\n\tcompat_uptr_t\t\tcounters;\t/* struct xt_counters * */\n\tstruct compat_ipt_entry\tentries[0];\n};\n\nstatic int\ncompat_copy_entry_to_user(struct ipt_entry *e, void __user **dstptr,\n\t\t\t  unsigned int *size, struct xt_counters *counters,\n\t\t\t  unsigned int i)\n{\n\tstruct xt_entry_target *t;\n\tstruct compat_ipt_entry __user *ce;\n\tu_int16_t target_offset, next_offset;\n\tcompat_uint_t origsize;\n\tconst struct xt_entry_match *ematch;\n\tint ret = 0;\n\n\torigsize = *size;\n\tce = (struct compat_ipt_entry __user *)*dstptr;\n\tif (copy_to_user(ce, e, sizeof(struct ipt_entry)) != 0 ||\n\t    copy_to_user(&ce->counters, &counters[i],\n\t    sizeof(counters[i])) != 0)\n\t\treturn -EFAULT;\n\n\t*dstptr += sizeof(struct compat_ipt_entry);\n\t*size -= sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\n\txt_ematch_foreach(ematch, e) {\n\t\tret = xt_compat_match_to_user(ematch, dstptr, size);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\ttarget_offset = e->target_offset - (origsize - *size);\n\tt = ipt_get_target(e);\n\tret = xt_compat_target_to_user(t, dstptr, size);\n\tif (ret)\n\t\treturn ret;\n\tnext_offset = e->next_offset - (origsize - *size);\n\tif (put_user(target_offset, &ce->target_offset) != 0 ||\n\t    put_user(next_offset, &ce->next_offset) != 0)\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int\ncompat_find_calc_match(struct xt_entry_match *m,\n\t\t       const char *name,\n\t\t       const struct ipt_ip *ip,\n\t\t       int *size)\n{\n\tstruct xt_match *match;\n\n\tmatch = xt_request_find_match(NFPROTO_IPV4, m->u.user.name,\n\t\t\t\t      m->u.user.revision);\n\tif (IS_ERR(match)) {\n\t\tduprintf(\"compat_check_calc_match: `%s' not found\\n\",\n\t\t\t m->u.user.name);\n\t\treturn PTR_ERR(match);\n\t}\n\tm->u.kernel.match = match;\n\t*size += xt_compat_match_offset(match);\n\treturn 0;\n}\n\nstatic void compat_release_entry(struct compat_ipt_entry *e)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_entry_match *ematch;\n\n\t/* Cleanup all matches */\n\txt_ematch_foreach(ematch, e)\n\t\tmodule_put(ematch->u.kernel.match->me);\n\tt = compat_ipt_get_target(e);\n\tmodule_put(t->u.kernel.target->me);\n}\n\nstatic int\ncheck_compat_entry_size_and_hooks(struct compat_ipt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ipt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ip, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ipt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}\n\nstatic int\ncompat_copy_entry_from_user(struct compat_ipt_entry *e, void **dstptr,\n\t\t\t    unsigned int *size, const char *name,\n\t\t\t    struct xt_table_info *newinfo, unsigned char *base)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tstruct ipt_entry *de;\n\tunsigned int origsize;\n\tint ret, h;\n\tstruct xt_entry_match *ematch;\n\n\tret = 0;\n\torigsize = *size;\n\tde = (struct ipt_entry *)*dstptr;\n\tmemcpy(de, e, sizeof(struct ipt_entry));\n\tmemcpy(&de->counters, &e->counters, sizeof(e->counters));\n\n\t*dstptr += sizeof(struct ipt_entry);\n\t*size += sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\n\txt_ematch_foreach(ematch, e) {\n\t\tret = xt_compat_match_from_user(ematch, dstptr, size);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\tde->target_offset = e->target_offset - (origsize - *size);\n\tt = compat_ipt_get_target(e);\n\ttarget = t->u.kernel.target;\n\txt_compat_target_from_user(t, dstptr, size);\n\n\tde->next_offset = e->next_offset - (origsize - *size);\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)de - base < newinfo->hook_entry[h])\n\t\t\tnewinfo->hook_entry[h] -= origsize - *size;\n\t\tif ((unsigned char *)de - base < newinfo->underflow[h])\n\t\t\tnewinfo->underflow[h] -= origsize - *size;\n\t}\n\treturn ret;\n}\n\nstatic int\ncompat_check_entry(struct ipt_entry *e, struct net *net, const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_mtchk_param mtpar;\n\tunsigned int j;\n\tint ret = 0;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\n\tj = 0;\n\tmtpar.net\t= net;\n\tmtpar.table     = name;\n\tmtpar.entryinfo = &e->ip;\n\tmtpar.hook_mask = e->comefrom;\n\tmtpar.family    = NFPROTO_IPV4;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = check_match(ematch, &mtpar);\n\t\tif (ret != 0)\n\t\t\tgoto cleanup_matches;\n\t\t++j;\n\t}\n\n\tret = check_target(e, net, name);\n\tif (ret)\n\t\tgoto cleanup_matches;\n\treturn 0;\n\n cleanup_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcleanup_match(ematch, net);\n\t}\n\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic int\ntranslate_compat_table(struct net *net,\n\t\t       const char *name,\n\t\t       unsigned int valid_hooks,\n\t\t       struct xt_table_info **pinfo,\n\t\t       void **pentry0,\n\t\t       unsigned int total_size,\n\t\t       unsigned int number,\n\t\t       unsigned int *hook_entries,\n\t\t       unsigned int *underflows)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_ipt_entry *iter0;\n\tstruct ipt_entry *iter1;\n\tunsigned int size;\n\tint ret;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = total_size;\n\tinfo->number = number;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_compat_table: size %u\\n\", info->size);\n\tj = 0;\n\txt_compat_lock(AF_INET);\n\txt_compat_init_offsets(AF_INET, number);\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + total_size,\n\t\t\t\t\t\t\thook_entries,\n\t\t\t\t\t\t\tunderflows,\n\t\t\t\t\t\t\tname);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != number) {\n\t\tduprintf(\"translate_compat_table: %u not %u entries\\n\",\n\t\t\t j, number);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (info->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, hook_entries[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tif (info->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, underflows[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = number;\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = info->hook_entry[i];\n\t\tnewinfo->underflow[i] = info->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = total_size;\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = compat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t\t  name, newinfo, entry1);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\txt_compat_flush_offsets(AF_INET);\n\txt_compat_unlock(AF_INET);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\tret = -ELOOP;\n\tif (!mark_source_chains(newinfo, valid_hooks, entry1))\n\t\tgoto free_newinfo;\n\n\ti = 0;\n\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\tret = compat_check_entry(iter1, net, name);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t\tif (strcmp(ipt_get_target(iter1)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\tif (ret) {\n\t\t/*\n\t\t * The first i matches need cleanup_entry (calls ->destroy)\n\t\t * because they had called ->check already. The other j-i\n\t\t * entries need only release.\n\t\t */\n\t\tint skip = i;\n\t\tj -= i;\n\t\txt_entry_foreach(iter0, entry0, newinfo->size) {\n\t\t\tif (skip-- > 0)\n\t\t\t\tcontinue;\n\t\t\tif (j-- == 0)\n\t\t\t\tbreak;\n\t\t\tcompat_release_entry(iter0);\n\t\t}\n\t\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter1, net);\n\t\t}\n\t\txt_free_table_info(newinfo);\n\t\treturn ret;\n\t}\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\nout:\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(AF_INET);\n\txt_compat_unlock(AF_INET);\n\tgoto out;\n}\n\nstatic int\ncompat_do_replace(struct net *net, void __user *user, unsigned int len)\n{\n\tint ret;\n\tstruct compat_ipt_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct ipt_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.size >= INT_MAX / num_possible_cpus())\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_compat_table(net, tmp.name, tmp.valid_hooks,\n\t\t\t\t     &newinfo, &loc_cpu_entry, tmp.size,\n\t\t\t\t     tmp.num_entries, tmp.hook_entry,\n\t\t\t\t     tmp.underflow);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"compat_do_replace: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, compat_ptr(tmp.counters));\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter, net);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int\ncompat_do_ipt_set_ctl(struct sock *sk,\tint cmd, void __user *user,\n\t\t      unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IPT_SO_SET_REPLACE:\n\t\tret = compat_do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IPT_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 1);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_ipt_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstruct compat_ipt_get_entries {\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tcompat_uint_t size;\n\tstruct compat_ipt_entry entrytable[0];\n};\n\nstatic int\ncompat_copy_entries_to_user(unsigned int total_size, struct xt_table *table,\n\t\t\t    void __user *userptr)\n{\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tvoid __user *pos;\n\tunsigned int size;\n\tint ret = 0;\n\tunsigned int i = 0;\n\tstruct ipt_entry *iter;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tpos = userptr;\n\tsize = total_size;\n\txt_entry_foreach(iter, private->entries, total_size) {\n\t\tret = compat_copy_entry_to_user(iter, &pos,\n\t\t\t\t\t\t&size, counters, i++);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\n\tvfree(counters);\n\treturn ret;\n}\n\nstatic int\ncompat_get_entries(struct net *net, struct compat_ipt_get_entries __user *uptr,\n\t\t   int *len)\n{\n\tint ret;\n\tstruct compat_ipt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"compat_get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\n\tif (*len != sizeof(struct compat_ipt_get_entries) + get.size) {\n\t\tduprintf(\"compat_get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\txt_compat_lock(AF_INET);\n\tt = xt_find_table_lock(net, AF_INET, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tstruct xt_table_info info;\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tret = compat_table_info(private, &info);\n\t\tif (!ret && get.size == info.size) {\n\t\t\tret = compat_copy_entries_to_user(private->size,\n\t\t\t\t\t\t\t  t, uptr->entrytable);\n\t\t} else if (!ret) {\n\t\t\tduprintf(\"compat_get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\txt_compat_flush_offsets(AF_INET);\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\txt_compat_unlock(AF_INET);\n\treturn ret;\n}\n\nstatic int do_ipt_get_ctl(struct sock *, int, void __user *, int *);\n\nstatic int\ncompat_do_ipt_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IPT_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 1);\n\t\tbreak;\n\tcase IPT_SO_GET_ENTRIES:\n\t\tret = compat_get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\tdefault:\n\t\tret = do_ipt_get_ctl(sk, cmd, user, len);\n\t}\n\treturn ret;\n}\n#endif\n\nstatic int\ndo_ipt_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IPT_SO_SET_REPLACE:\n\t\tret = do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IPT_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_ipt_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int\ndo_ipt_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IPT_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tcase IPT_SO_GET_ENTRIES:\n\t\tret = get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IPT_SO_GET_REVISION_MATCH:\n\tcase IPT_SO_GET_REVISION_TARGET: {\n\t\tstruct xt_get_revision rev;\n\t\tint target;\n\n\t\tif (*len != sizeof(rev)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&rev, user, sizeof(rev)) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\trev.name[sizeof(rev.name)-1] = 0;\n\n\t\tif (cmd == IPT_SO_GET_REVISION_TARGET)\n\t\t\ttarget = 1;\n\t\telse\n\t\t\ttarget = 0;\n\n\t\ttry_then_request_module(xt_find_revision(AF_INET, rev.name,\n\t\t\t\t\t\t\t rev.revision,\n\t\t\t\t\t\t\t target, &ret),\n\t\t\t\t\t\"ipt_%s\", rev.name);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tduprintf(\"do_ipt_get_ctl: unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic void __ipt_unregister_table(struct net *net, struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\tvoid *loc_cpu_entry;\n\tstruct module *table_owner = table->me;\n\tstruct ipt_entry *iter;\n\n\tprivate = xt_unregister_table(table);\n\n\t/* Decrease module usage counts and free resources */\n\tloc_cpu_entry = private->entries;\n\txt_entry_foreach(iter, loc_cpu_entry, private->size)\n\t\tcleanup_entry(iter, net);\n\tif (private->number > private->initial_entries)\n\t\tmodule_put(table_owner);\n\txt_free_table_info(private);\n}\n\nint ipt_register_table(struct net *net, const struct xt_table *table,\n\t\t       const struct ipt_replace *repl,\n\t\t       const struct nf_hook_ops *ops, struct xt_table **res)\n{\n\tint ret;\n\tstruct xt_table_info *newinfo;\n\tstruct xt_table_info bootstrap = {0};\n\tvoid *loc_cpu_entry;\n\tstruct xt_table *new_table;\n\n\tnewinfo = xt_alloc_table_info(repl->size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tmemcpy(loc_cpu_entry, repl->entries, repl->size);\n\n\tret = translate_table(net, newinfo, loc_cpu_entry, repl);\n\tif (ret != 0)\n\t\tgoto out_free;\n\n\tnew_table = xt_register_table(net, table, &bootstrap, newinfo);\n\tif (IS_ERR(new_table)) {\n\t\tret = PTR_ERR(new_table);\n\t\tgoto out_free;\n\t}\n\n\t/* set res now, will see skbs right after nf_register_net_hooks */\n\tWRITE_ONCE(*res, new_table);\n\n\tret = nf_register_net_hooks(net, ops, hweight32(table->valid_hooks));\n\tif (ret != 0) {\n\t\t__ipt_unregister_table(net, new_table);\n\t\t*res = NULL;\n\t}\n\n\treturn ret;\n\nout_free:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nvoid ipt_unregister_table(struct net *net, struct xt_table *table,\n\t\t\t  const struct nf_hook_ops *ops)\n{\n\tnf_unregister_net_hooks(net, ops, hweight32(table->valid_hooks));\n\t__ipt_unregister_table(net, table);\n}\n\n/* Returns 1 if the type and code is matched by the range, 0 otherwise */\nstatic inline bool\nicmp_type_code_match(u_int8_t test_type, u_int8_t min_code, u_int8_t max_code,\n\t\t     u_int8_t type, u_int8_t code,\n\t\t     bool invert)\n{\n\treturn ((test_type == 0xFF) ||\n\t\t(type == test_type && code >= min_code && code <= max_code))\n\t\t^ invert;\n}\n\nstatic bool\nicmp_match(const struct sk_buff *skb, struct xt_action_param *par)\n{\n\tconst struct icmphdr *ic;\n\tstruct icmphdr _icmph;\n\tconst struct ipt_icmp *icmpinfo = par->matchinfo;\n\n\t/* Must not be a fragment. */\n\tif (par->fragoff != 0)\n\t\treturn false;\n\n\tic = skb_header_pointer(skb, par->thoff, sizeof(_icmph), &_icmph);\n\tif (ic == NULL) {\n\t\t/* We've been asked to examine this packet, and we\n\t\t * can't.  Hence, no choice but to drop.\n\t\t */\n\t\tduprintf(\"Dropping evil ICMP tinygram.\\n\");\n\t\tpar->hotdrop = true;\n\t\treturn false;\n\t}\n\n\treturn icmp_type_code_match(icmpinfo->type,\n\t\t\t\t    icmpinfo->code[0],\n\t\t\t\t    icmpinfo->code[1],\n\t\t\t\t    ic->type, ic->code,\n\t\t\t\t    !!(icmpinfo->invflags&IPT_ICMP_INV));\n}\n\nstatic int icmp_checkentry(const struct xt_mtchk_param *par)\n{\n\tconst struct ipt_icmp *icmpinfo = par->matchinfo;\n\n\t/* Must specify no unknown invflags */\n\treturn (icmpinfo->invflags & ~IPT_ICMP_INV) ? -EINVAL : 0;\n}\n\nstatic struct xt_target ipt_builtin_tg[] __read_mostly = {\n\t{\n\t\t.name             = XT_STANDARD_TARGET,\n\t\t.targetsize       = sizeof(int),\n\t\t.family           = NFPROTO_IPV4,\n#ifdef CONFIG_COMPAT\n\t\t.compatsize       = sizeof(compat_int_t),\n\t\t.compat_from_user = compat_standard_from_user,\n\t\t.compat_to_user   = compat_standard_to_user,\n#endif\n\t},\n\t{\n\t\t.name             = XT_ERROR_TARGET,\n\t\t.target           = ipt_error,\n\t\t.targetsize       = XT_FUNCTION_MAXNAMELEN,\n\t\t.family           = NFPROTO_IPV4,\n\t},\n};\n\nstatic struct nf_sockopt_ops ipt_sockopts = {\n\t.pf\t\t= PF_INET,\n\t.set_optmin\t= IPT_BASE_CTL,\n\t.set_optmax\t= IPT_SO_SET_MAX+1,\n\t.set\t\t= do_ipt_set_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_set\t= compat_do_ipt_set_ctl,\n#endif\n\t.get_optmin\t= IPT_BASE_CTL,\n\t.get_optmax\t= IPT_SO_GET_MAX+1,\n\t.get\t\t= do_ipt_get_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_get\t= compat_do_ipt_get_ctl,\n#endif\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic struct xt_match ipt_builtin_mt[] __read_mostly = {\n\t{\n\t\t.name       = \"icmp\",\n\t\t.match      = icmp_match,\n\t\t.matchsize  = sizeof(struct ipt_icmp),\n\t\t.checkentry = icmp_checkentry,\n\t\t.proto      = IPPROTO_ICMP,\n\t\t.family     = NFPROTO_IPV4,\n\t},\n};\n\nstatic int __net_init ip_tables_net_init(struct net *net)\n{\n\treturn xt_proto_init(net, NFPROTO_IPV4);\n}\n\nstatic void __net_exit ip_tables_net_exit(struct net *net)\n{\n\txt_proto_fini(net, NFPROTO_IPV4);\n}\n\nstatic struct pernet_operations ip_tables_net_ops = {\n\t.init = ip_tables_net_init,\n\t.exit = ip_tables_net_exit,\n};\n\nstatic int __init ip_tables_init(void)\n{\n\tint ret;\n\n\tret = register_pernet_subsys(&ip_tables_net_ops);\n\tif (ret < 0)\n\t\tgoto err1;\n\n\t/* No one else will be downing sem now, so we won't sleep */\n\tret = xt_register_targets(ipt_builtin_tg, ARRAY_SIZE(ipt_builtin_tg));\n\tif (ret < 0)\n\t\tgoto err2;\n\tret = xt_register_matches(ipt_builtin_mt, ARRAY_SIZE(ipt_builtin_mt));\n\tif (ret < 0)\n\t\tgoto err4;\n\n\t/* Register setsockopt */\n\tret = nf_register_sockopt(&ipt_sockopts);\n\tif (ret < 0)\n\t\tgoto err5;\n\n\tpr_info(\"(C) 2000-2006 Netfilter Core Team\\n\");\n\treturn 0;\n\nerr5:\n\txt_unregister_matches(ipt_builtin_mt, ARRAY_SIZE(ipt_builtin_mt));\nerr4:\n\txt_unregister_targets(ipt_builtin_tg, ARRAY_SIZE(ipt_builtin_tg));\nerr2:\n\tunregister_pernet_subsys(&ip_tables_net_ops);\nerr1:\n\treturn ret;\n}\n\nstatic void __exit ip_tables_fini(void)\n{\n\tnf_unregister_sockopt(&ipt_sockopts);\n\n\txt_unregister_matches(ipt_builtin_mt, ARRAY_SIZE(ipt_builtin_mt));\n\txt_unregister_targets(ipt_builtin_tg, ARRAY_SIZE(ipt_builtin_tg));\n\tunregister_pernet_subsys(&ip_tables_net_ops);\n}\n\nEXPORT_SYMBOL(ipt_register_table);\nEXPORT_SYMBOL(ipt_unregister_table);\nEXPORT_SYMBOL(ipt_do_table);\nmodule_init(ip_tables_init);\nmodule_exit(ip_tables_fini);\n", "/*\n * Packet matching code.\n *\n * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling\n * Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>\n * Copyright (c) 2006-2010 Patrick McHardy <kaber@trash.net>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kernel.h>\n#include <linux/capability.h>\n#include <linux/in.h>\n#include <linux/skbuff.h>\n#include <linux/kmod.h>\n#include <linux/vmalloc.h>\n#include <linux/netdevice.h>\n#include <linux/module.h>\n#include <linux/poison.h>\n#include <linux/icmpv6.h>\n#include <net/ipv6.h>\n#include <net/compat.h>\n#include <asm/uaccess.h>\n#include <linux/mutex.h>\n#include <linux/proc_fs.h>\n#include <linux/err.h>\n#include <linux/cpumask.h>\n\n#include <linux/netfilter_ipv6/ip6_tables.h>\n#include <linux/netfilter/x_tables.h>\n#include <net/netfilter/nf_log.h>\n#include \"../../netfilter/xt_repldata.h\"\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Netfilter Core Team <coreteam@netfilter.org>\");\nMODULE_DESCRIPTION(\"IPv6 packet filter\");\n\n/*#define DEBUG_IP_FIREWALL*/\n/*#define DEBUG_ALLOW_ALL*/ /* Useful for remote debugging */\n/*#define DEBUG_IP_FIREWALL_USER*/\n\n#ifdef DEBUG_IP_FIREWALL\n#define dprintf(format, args...) pr_info(format , ## args)\n#else\n#define dprintf(format, args...)\n#endif\n\n#ifdef DEBUG_IP_FIREWALL_USER\n#define duprintf(format, args...) pr_info(format , ## args)\n#else\n#define duprintf(format, args...)\n#endif\n\n#ifdef CONFIG_NETFILTER_DEBUG\n#define IP_NF_ASSERT(x)\tWARN_ON(!(x))\n#else\n#define IP_NF_ASSERT(x)\n#endif\n\n#if 0\n/* All the better to debug you with... */\n#define static\n#define inline\n#endif\n\nvoid *ip6t_alloc_initial_table(const struct xt_table *info)\n{\n\treturn xt_alloc_initial_table(ip6t, IP6T);\n}\nEXPORT_SYMBOL_GPL(ip6t_alloc_initial_table);\n\n/*\n   We keep a set of rules for each CPU, so we can avoid write-locking\n   them in the softirq when updating the counters and therefore\n   only need to read-lock in the softirq; doing a write_lock_bh() in user\n   context stops packets coming through and allows user context to read\n   the counters or update the rules.\n\n   Hence the start of any table is given by get_table() below.  */\n\n/* Returns whether matches rule or not. */\n/* Performance critical - called for every packet */\nstatic inline bool\nip6_packet_match(const struct sk_buff *skb,\n\t\t const char *indev,\n\t\t const char *outdev,\n\t\t const struct ip6t_ip6 *ip6info,\n\t\t unsigned int *protoff,\n\t\t int *fragoff, bool *hotdrop)\n{\n\tunsigned long ret;\n\tconst struct ipv6hdr *ipv6 = ipv6_hdr(skb);\n\n#define FWINV(bool, invflg) ((bool) ^ !!(ip6info->invflags & (invflg)))\n\n\tif (FWINV(ipv6_masked_addr_cmp(&ipv6->saddr, &ip6info->smsk,\n\t\t\t\t       &ip6info->src), IP6T_INV_SRCIP) ||\n\t    FWINV(ipv6_masked_addr_cmp(&ipv6->daddr, &ip6info->dmsk,\n\t\t\t\t       &ip6info->dst), IP6T_INV_DSTIP)) {\n\t\tdprintf(\"Source or dest mismatch.\\n\");\n/*\n\t\tdprintf(\"SRC: %u. Mask: %u. Target: %u.%s\\n\", ip->saddr,\n\t\t\tipinfo->smsk.s_addr, ipinfo->src.s_addr,\n\t\t\tipinfo->invflags & IP6T_INV_SRCIP ? \" (INV)\" : \"\");\n\t\tdprintf(\"DST: %u. Mask: %u. Target: %u.%s\\n\", ip->daddr,\n\t\t\tipinfo->dmsk.s_addr, ipinfo->dst.s_addr,\n\t\t\tipinfo->invflags & IP6T_INV_DSTIP ? \" (INV)\" : \"\");*/\n\t\treturn false;\n\t}\n\n\tret = ifname_compare_aligned(indev, ip6info->iniface, ip6info->iniface_mask);\n\n\tif (FWINV(ret != 0, IP6T_INV_VIA_IN)) {\n\t\tdprintf(\"VIA in mismatch (%s vs %s).%s\\n\",\n\t\t\tindev, ip6info->iniface,\n\t\t\tip6info->invflags & IP6T_INV_VIA_IN ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\tret = ifname_compare_aligned(outdev, ip6info->outiface, ip6info->outiface_mask);\n\n\tif (FWINV(ret != 0, IP6T_INV_VIA_OUT)) {\n\t\tdprintf(\"VIA out mismatch (%s vs %s).%s\\n\",\n\t\t\toutdev, ip6info->outiface,\n\t\t\tip6info->invflags & IP6T_INV_VIA_OUT ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n/* ... might want to do something with class and flowlabel here ... */\n\n\t/* look for the desired protocol header */\n\tif (ip6info->flags & IP6T_F_PROTO) {\n\t\tint protohdr;\n\t\tunsigned short _frag_off;\n\n\t\tprotohdr = ipv6_find_hdr(skb, protoff, -1, &_frag_off, NULL);\n\t\tif (protohdr < 0) {\n\t\t\tif (_frag_off == 0)\n\t\t\t\t*hotdrop = true;\n\t\t\treturn false;\n\t\t}\n\t\t*fragoff = _frag_off;\n\n\t\tdprintf(\"Packet protocol %hi ?= %s%hi.\\n\",\n\t\t\t\tprotohdr,\n\t\t\t\tip6info->invflags & IP6T_INV_PROTO ? \"!\":\"\",\n\t\t\t\tip6info->proto);\n\n\t\tif (ip6info->proto == protohdr) {\n\t\t\tif (ip6info->invflags & IP6T_INV_PROTO)\n\t\t\t\treturn false;\n\n\t\t\treturn true;\n\t\t}\n\n\t\t/* We need match for the '-p all', too! */\n\t\tif ((ip6info->proto != 0) &&\n\t\t\t!(ip6info->invflags & IP6T_INV_PROTO))\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\n/* should be ip6 safe */\nstatic bool\nip6_checkentry(const struct ip6t_ip6 *ipv6)\n{\n\tif (ipv6->flags & ~IP6T_F_MASK) {\n\t\tduprintf(\"Unknown flag bits set: %08X\\n\",\n\t\t\t ipv6->flags & ~IP6T_F_MASK);\n\t\treturn false;\n\t}\n\tif (ipv6->invflags & ~IP6T_INV_MASK) {\n\t\tduprintf(\"Unknown invflag bits set: %08X\\n\",\n\t\t\t ipv6->invflags & ~IP6T_INV_MASK);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic unsigned int\nip6t_error(struct sk_buff *skb, const struct xt_action_param *par)\n{\n\tnet_info_ratelimited(\"error: `%s'\\n\", (const char *)par->targinfo);\n\n\treturn NF_DROP;\n}\n\nstatic inline struct ip6t_entry *\nget_entry(const void *base, unsigned int offset)\n{\n\treturn (struct ip6t_entry *)(base + offset);\n}\n\n/* All zeroes == unconditional rule. */\n/* Mildly perf critical (only if packet tracing is on) */\nstatic inline bool unconditional(const struct ip6t_entry *e)\n{\n\tstatic const struct ip6t_ip6 uncond;\n\n\treturn e->target_offset == sizeof(struct ip6t_entry) &&\n\t       memcmp(&e->ipv6, &uncond, sizeof(uncond)) == 0;\n}\n\nstatic inline const struct xt_entry_target *\nip6t_get_target_c(const struct ip6t_entry *e)\n{\n\treturn ip6t_get_target((struct ip6t_entry *)e);\n}\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n/* This cries for unification! */\nstatic const char *const hooknames[] = {\n\t[NF_INET_PRE_ROUTING]\t\t= \"PREROUTING\",\n\t[NF_INET_LOCAL_IN]\t\t= \"INPUT\",\n\t[NF_INET_FORWARD]\t\t= \"FORWARD\",\n\t[NF_INET_LOCAL_OUT]\t\t= \"OUTPUT\",\n\t[NF_INET_POST_ROUTING]\t\t= \"POSTROUTING\",\n};\n\nenum nf_ip_trace_comments {\n\tNF_IP6_TRACE_COMMENT_RULE,\n\tNF_IP6_TRACE_COMMENT_RETURN,\n\tNF_IP6_TRACE_COMMENT_POLICY,\n};\n\nstatic const char *const comments[] = {\n\t[NF_IP6_TRACE_COMMENT_RULE]\t= \"rule\",\n\t[NF_IP6_TRACE_COMMENT_RETURN]\t= \"return\",\n\t[NF_IP6_TRACE_COMMENT_POLICY]\t= \"policy\",\n};\n\nstatic struct nf_loginfo trace_loginfo = {\n\t.type = NF_LOG_TYPE_LOG,\n\t.u = {\n\t\t.log = {\n\t\t\t.level = LOGLEVEL_WARNING,\n\t\t\t.logflags = NF_LOG_MASK,\n\t\t},\n\t},\n};\n\n/* Mildly perf critical (only if packet tracing is on) */\nstatic inline int\nget_chainname_rulenum(const struct ip6t_entry *s, const struct ip6t_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ip6t_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (unconditional(s) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t    t->verdict < 0) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP6_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP6_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}\n\nstatic void trace_packet(struct net *net,\n\t\t\t const struct sk_buff *skb,\n\t\t\t unsigned int hook,\n\t\t\t const struct net_device *in,\n\t\t\t const struct net_device *out,\n\t\t\t const char *tablename,\n\t\t\t const struct xt_table_info *private,\n\t\t\t const struct ip6t_entry *e)\n{\n\tconst struct ip6t_entry *root;\n\tconst char *hookname, *chainname, *comment;\n\tconst struct ip6t_entry *iter;\n\tunsigned int rulenum = 0;\n\n\troot = get_entry(private->entries, private->hook_entry[hook]);\n\n\thookname = chainname = hooknames[hook];\n\tcomment = comments[NF_IP6_TRACE_COMMENT_RULE];\n\n\txt_entry_foreach(iter, root, private->size - private->hook_entry[hook])\n\t\tif (get_chainname_rulenum(iter, e, hookname,\n\t\t    &chainname, &comment, &rulenum) != 0)\n\t\t\tbreak;\n\n\tnf_log_trace(net, AF_INET6, hook, skb, in, out, &trace_loginfo,\n\t\t     \"TRACE: %s:%s:%s:%u \",\n\t\t     tablename, chainname, comment, rulenum);\n}\n#endif\n\nstatic inline struct ip6t_entry *\nip6t_next_entry(const struct ip6t_entry *entry)\n{\n\treturn (void *)entry + entry->next_offset;\n}\n\n/* Returns one of the generic firewall policies, like NF_ACCEPT. */\nunsigned int\nip6t_do_table(struct sk_buff *skb,\n\t      const struct nf_hook_state *state,\n\t      struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\t/* Initializing verdict to NF_DROP keeps gcc happy. */\n\tunsigned int verdict = NF_DROP;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tstruct ip6t_entry *e, **jumpstack;\n\tunsigned int stackidx, cpu;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\t/* Initialization */\n\tstackidx = 0;\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\t/* We handle fragments by dealing with the first fragment as\n\t * if it was a normal packet.  All other fragments are treated\n\t * normally, except that they will NEVER match rules that ask\n\t * things we don't know, ie. tcp syn flag or ports).  If the\n\t * rule is also a fragment-specific rule, non-fragments won't\n\t * match it. */\n\tacpar.hotdrop = false;\n\tacpar.net     = state->net;\n\tacpar.in      = state->in;\n\tacpar.out     = state->out;\n\tacpar.family  = NFPROTO_IPV6;\n\tacpar.hooknum = hook;\n\n\tIP_NF_ASSERT(table->valid_hooks & (1 << hook));\n\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = table->private;\n\t/*\n\t * Ensure we load private-> members after we've fetched the base\n\t * pointer.\n\t */\n\tsmp_read_barrier_depends();\n\tcpu        = smp_processor_id();\n\ttable_base = private->entries;\n\tjumpstack  = (struct ip6t_entry **)private->jumpstack[cpu];\n\n\t/* Switch to alternate jumpstack if we're being invoked via TEE.\n\t * TEE issues XT_CONTINUE verdict on original skb so we must not\n\t * clobber the jumpstack.\n\t *\n\t * For recursion via REJECT or SYNPROXY the stack will be clobbered\n\t * but it is no problem since absolute verdict is issued by these.\n\t */\n\tif (static_key_false(&xt_tee_enabled))\n\t\tjumpstack += private->stacksize * __this_cpu_read(nf_skb_duplicated);\n\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tconst struct xt_entry_match *ematch;\n\t\tstruct xt_counters *counter;\n\n\t\tIP_NF_ASSERT(e);\n\t\tacpar.thoff = 0;\n\t\tif (!ip6_packet_match(skb, indev, outdev, &e->ipv6,\n\t\t    &acpar.thoff, &acpar.fragoff, &acpar.hotdrop)) {\n no_match:\n\t\t\te = ip6t_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\txt_ematch_foreach(ematch, e) {\n\t\t\tacpar.match     = ematch->u.kernel.match;\n\t\t\tacpar.matchinfo = ematch->data;\n\t\t\tif (!acpar.match->match(skb, &acpar))\n\t\t\t\tgoto no_match;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, skb->len, 1);\n\n\t\tt = ip6t_get_target_c(e);\n\t\tIP_NF_ASSERT(t->u.kernel.target);\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n\t\t/* The packet is traced: log it */\n\t\tif (unlikely(skb->nf_trace))\n\t\t\ttrace_packet(state->net, skb, hook, state->in,\n\t\t\t\t     state->out, table->name, private, e);\n#endif\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0)\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t    private->underflow[hook]);\n\t\t\t\telse\n\t\t\t\t\te = ip6t_next_entry(jumpstack[--stackidx]);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v != ip6t_next_entry(e) &&\n\t\t\t    !(e->ipv6.flags & IP6T_F_GOTO)) {\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\t\tif (verdict == XT_CONTINUE)\n\t\t\te = ip6t_next_entry(e);\n\t\telse\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t} while (!acpar.hotdrop);\n\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n#ifdef DEBUG_ALLOW_ALL\n\treturn NF_ACCEPT;\n#else\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse return verdict;\n#endif\n}\n\nstatic bool find_jump_target(const struct xt_table_info *t,\n\t\t\t     const struct ip6t_entry *target)\n{\n\tstruct ip6t_entry *iter;\n\n\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t if (iter == target)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n/* Figures out from what hook each rule can be called: returns 0 if\n   there are loops.  Puts hook bitmask in comefrom. */\nstatic int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ip6t_entry *e = (struct ip6t_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ip6t_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\tif (pos + size >= newinfo->size)\n\t\t\t\t\treturn 0;\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ip6t_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t\t(entry0 + newpos);\n\t\t\t\t\tif (!find_jump_target(newinfo, e))\n\t\t\t\t\t\treturn 0;\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t\tif (newpos >= newinfo->size)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}\n\nstatic void cleanup_match(struct xt_entry_match *m, struct net *net)\n{\n\tstruct xt_mtdtor_param par;\n\n\tpar.net       = net;\n\tpar.match     = m->u.kernel.match;\n\tpar.matchinfo = m->data;\n\tpar.family    = NFPROTO_IPV6;\n\tif (par.match->destroy != NULL)\n\t\tpar.match->destroy(&par);\n\tmodule_put(par.match->me);\n}\n\nstatic int check_match(struct xt_entry_match *m, struct xt_mtchk_param *par)\n{\n\tconst struct ip6t_ip6 *ipv6 = par->entryinfo;\n\tint ret;\n\n\tpar->match     = m->u.kernel.match;\n\tpar->matchinfo = m->data;\n\n\tret = xt_check_match(par, m->u.match_size - sizeof(*m),\n\t\t\t     ipv6->proto, ipv6->invflags & IP6T_INV_PROTO);\n\tif (ret < 0) {\n\t\tduprintf(\"ip_tables: check failed for `%s'.\\n\",\n\t\t\t par.match->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int\nfind_check_match(struct xt_entry_match *m, struct xt_mtchk_param *par)\n{\n\tstruct xt_match *match;\n\tint ret;\n\n\tmatch = xt_request_find_match(NFPROTO_IPV6, m->u.user.name,\n\t\t\t\t      m->u.user.revision);\n\tif (IS_ERR(match)) {\n\t\tduprintf(\"find_check_match: `%s' not found\\n\", m->u.user.name);\n\t\treturn PTR_ERR(match);\n\t}\n\tm->u.kernel.match = match;\n\n\tret = check_match(m, par);\n\tif (ret)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tmodule_put(m->u.kernel.match->me);\n\treturn ret;\n}\n\nstatic int check_target(struct ip6t_entry *e, struct net *net, const char *name)\n{\n\tstruct xt_entry_target *t = ip6t_get_target(e);\n\tstruct xt_tgchk_param par = {\n\t\t.net       = net,\n\t\t.table     = name,\n\t\t.entryinfo = e,\n\t\t.target    = t->u.kernel.target,\n\t\t.targinfo  = t->data,\n\t\t.hook_mask = e->comefrom,\n\t\t.family    = NFPROTO_IPV6,\n\t};\n\tint ret;\n\n\tt = ip6t_get_target(e);\n\tret = xt_check_target(&par, t->u.target_size - sizeof(*t),\n\t      e->ipv6.proto, e->ipv6.invflags & IP6T_INV_PROTO);\n\tif (ret < 0) {\n\t\tduprintf(\"ip_tables: check failed for `%s'.\\n\",\n\t\t\t t->u.kernel.target->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int\nfind_check_entry(struct ip6t_entry *e, struct net *net, const char *name,\n\t\t unsigned int size)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tint ret;\n\tunsigned int j;\n\tstruct xt_mtchk_param mtpar;\n\tstruct xt_entry_match *ematch;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\n\tj = 0;\n\tmtpar.net\t= net;\n\tmtpar.table     = name;\n\tmtpar.entryinfo = &e->ipv6;\n\tmtpar.hook_mask = e->comefrom;\n\tmtpar.family    = NFPROTO_IPV6;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = find_check_match(ematch, &mtpar);\n\t\tif (ret != 0)\n\t\t\tgoto cleanup_matches;\n\t\t++j;\n\t}\n\n\tt = ip6t_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"find_check_entry: `%s' not found\\n\", t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto cleanup_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\tret = check_target(e, net, name);\n\tif (ret)\n\t\tgoto err;\n\treturn 0;\n err:\n\tmodule_put(t->u.kernel.target->me);\n cleanup_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcleanup_match(ematch, net);\n\t}\n\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic bool check_underflow(const struct ip6t_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = ip6t_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n\nstatic int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->target_offset, e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}\n\nstatic void cleanup_entry(struct ip6t_entry *e, struct net *net)\n{\n\tstruct xt_tgdtor_param par;\n\tstruct xt_entry_target *t;\n\tstruct xt_entry_match *ematch;\n\n\t/* Cleanup all matches */\n\txt_ematch_foreach(ematch, e)\n\t\tcleanup_match(ematch, net);\n\tt = ip6t_get_target(e);\n\n\tpar.net      = net;\n\tpar.target   = t->u.kernel.target;\n\tpar.targinfo = t->data;\n\tpar.family   = NFPROTO_IPV6;\n\tif (par.target->destroy != NULL)\n\t\tpar.target->destroy(&par);\n\tmodule_put(par.target->me);\n\n\txt_percpu_counter_free(e->counters.pcnt);\n}\n\n/* Checks and translates the user-supplied table segment (held in\n   newinfo) */\nstatic int\ntranslate_table(struct net *net, struct xt_table_info *newinfo, void *entry0,\n\t\tconst struct ip6t_replace *repl)\n{\n\tstruct ip6t_entry *iter;\n\tunsigned int i;\n\tint ret = 0;\n\n\tnewinfo->size = repl->size;\n\tnewinfo->number = repl->num_entries;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tnewinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_table: size %u\\n\", newinfo->size);\n\ti = 0;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = check_entry_size_and_hooks(iter, newinfo, entry0,\n\t\t\t\t\t\t entry0 + repl->size,\n\t\t\t\t\t\t repl->hook_entry,\n\t\t\t\t\t\t repl->underflow,\n\t\t\t\t\t\t repl->valid_hooks);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t\t++i;\n\t\tif (strcmp(ip6t_get_target(iter)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\n\tif (i != repl->num_entries) {\n\t\tduprintf(\"translate_table: %u not %u entries\\n\",\n\t\t\t i, repl->num_entries);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(repl->valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (newinfo->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, repl->hook_entry[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (newinfo->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, repl->underflow[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!mark_source_chains(newinfo, repl->valid_hooks, entry0))\n\t\treturn -ELOOP;\n\n\t/* Finally, each sanity check must pass */\n\ti = 0;\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = find_check_entry(iter, net, repl->name, repl->size);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t}\n\n\tif (ret != 0) {\n\t\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter, net);\n\t\t}\n\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic void\nget_counters(const struct xt_table_info *t,\n\t     struct xt_counters counters[])\n{\n\tstruct ip6t_entry *iter;\n\tunsigned int cpu;\n\tunsigned int i;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tseqcount_t *s = &per_cpu(xt_recseq, cpu);\n\n\t\ti = 0;\n\t\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t\tstruct xt_counters *tmp;\n\t\t\tu64 bcnt, pcnt;\n\t\t\tunsigned int start;\n\n\t\t\ttmp = xt_get_per_cpu_counter(&iter->counters, cpu);\n\t\t\tdo {\n\t\t\t\tstart = read_seqcount_begin(s);\n\t\t\t\tbcnt = tmp->bcnt;\n\t\t\t\tpcnt = tmp->pcnt;\n\t\t\t} while (read_seqcount_retry(s, start));\n\n\t\t\tADD_COUNTER(counters[i], bcnt, pcnt);\n\t\t\t++i;\n\t\t}\n\t}\n}\n\nstatic struct xt_counters *alloc_counters(const struct xt_table *table)\n{\n\tunsigned int countersize;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\n\t/* We need atomic snapshot of counters: rest doesn't change\n\t   (other than comefrom, which userspace doesn't care\n\t   about). */\n\tcountersize = sizeof(struct xt_counters) * private->number;\n\tcounters = vzalloc(countersize);\n\n\tif (counters == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tget_counters(private, counters);\n\n\treturn counters;\n}\n\nstatic int\ncopy_entries_to_user(unsigned int total_size,\n\t\t     const struct xt_table *table,\n\t\t     void __user *userptr)\n{\n\tunsigned int off, num;\n\tconst struct ip6t_entry *e;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tint ret = 0;\n\tconst void *loc_cpu_entry;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tloc_cpu_entry = private->entries;\n\tif (copy_to_user(userptr, loc_cpu_entry, total_size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_counters;\n\t}\n\n\t/* FIXME: use iterator macros --RR */\n\t/* ... then go back and fix counters and names */\n\tfor (off = 0, num = 0; off < total_size; off += e->next_offset, num++){\n\t\tunsigned int i;\n\t\tconst struct xt_entry_match *m;\n\t\tconst struct xt_entry_target *t;\n\n\t\te = (struct ip6t_entry *)(loc_cpu_entry + off);\n\t\tif (copy_to_user(userptr + off\n\t\t\t\t + offsetof(struct ip6t_entry, counters),\n\t\t\t\t &counters[num],\n\t\t\t\t sizeof(counters[num])) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\n\t\tfor (i = sizeof(struct ip6t_entry);\n\t\t     i < e->target_offset;\n\t\t     i += m->u.match_size) {\n\t\t\tm = (void *)e + i;\n\n\t\t\tif (copy_to_user(userptr + off + i\n\t\t\t\t\t + offsetof(struct xt_entry_match,\n\t\t\t\t\t\t    u.user.name),\n\t\t\t\t\t m->u.kernel.match->name,\n\t\t\t\t\t strlen(m->u.kernel.match->name)+1)\n\t\t\t    != 0) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto free_counters;\n\t\t\t}\n\t\t}\n\n\t\tt = ip6t_get_target_c(e);\n\t\tif (copy_to_user(userptr + off + e->target_offset\n\t\t\t\t + offsetof(struct xt_entry_target,\n\t\t\t\t\t    u.user.name),\n\t\t\t\t t->u.kernel.target->name,\n\t\t\t\t strlen(t->u.kernel.target->name)+1) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\t}\n\n free_counters:\n\tvfree(counters);\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic void compat_standard_from_user(void *dst, const void *src)\n{\n\tint v = *(compat_int_t *)src;\n\n\tif (v > 0)\n\t\tv += xt_compat_calc_jump(AF_INET6, v);\n\tmemcpy(dst, &v, sizeof(v));\n}\n\nstatic int compat_standard_to_user(void __user *dst, const void *src)\n{\n\tcompat_int_t cv = *(int *)src;\n\n\tif (cv > 0)\n\t\tcv -= xt_compat_calc_jump(AF_INET6, cv);\n\treturn copy_to_user(dst, &cv, sizeof(cv)) ? -EFAULT : 0;\n}\n\nstatic int compat_calc_entry(const struct ip6t_entry *e,\n\t\t\t     const struct xt_table_info *info,\n\t\t\t     const void *base, struct xt_table_info *newinfo)\n{\n\tconst struct xt_entry_match *ematch;\n\tconst struct xt_entry_target *t;\n\tunsigned int entry_offset;\n\tint off, i, ret;\n\n\toff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\tentry_offset = (void *)e - base;\n\txt_ematch_foreach(ematch, e)\n\t\toff += xt_compat_match_offset(ematch->u.kernel.match);\n\tt = ip6t_get_target_c(e);\n\toff += xt_compat_target_offset(t->u.kernel.target);\n\tnewinfo->size -= off;\n\tret = xt_compat_add_offset(AF_INET6, entry_offset, off);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tif (info->hook_entry[i] &&\n\t\t    (e < (struct ip6t_entry *)(base + info->hook_entry[i])))\n\t\t\tnewinfo->hook_entry[i] -= off;\n\t\tif (info->underflow[i] &&\n\t\t    (e < (struct ip6t_entry *)(base + info->underflow[i])))\n\t\t\tnewinfo->underflow[i] -= off;\n\t}\n\treturn 0;\n}\n\nstatic int compat_table_info(const struct xt_table_info *info,\n\t\t\t     struct xt_table_info *newinfo)\n{\n\tstruct ip6t_entry *iter;\n\tconst void *loc_cpu_entry;\n\tint ret;\n\n\tif (!newinfo || !info)\n\t\treturn -EINVAL;\n\n\t/* we dont care about newinfo->entries */\n\tmemcpy(newinfo, info, offsetof(struct xt_table_info, entries));\n\tnewinfo->initial_entries = 0;\n\tloc_cpu_entry = info->entries;\n\txt_compat_init_offsets(AF_INET6, info->number);\n\txt_entry_foreach(iter, loc_cpu_entry, info->size) {\n\t\tret = compat_calc_entry(iter, info, loc_cpu_entry, newinfo);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n#endif\n\nstatic int get_info(struct net *net, void __user *user,\n\t\t    const int *len, int compat)\n{\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tstruct xt_table *t;\n\tint ret;\n\n\tif (*len != sizeof(struct ip6t_getinfo)) {\n\t\tduprintf(\"length %u != %zu\\n\", *len,\n\t\t\t sizeof(struct ip6t_getinfo));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(name, user, sizeof(name)) != 0)\n\t\treturn -EFAULT;\n\n\tname[XT_TABLE_MAXNAMELEN-1] = '\\0';\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_lock(AF_INET6);\n#endif\n\tt = try_then_request_module(xt_find_table_lock(net, AF_INET6, name),\n\t\t\t\t    \"ip6table_%s\", name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tstruct ip6t_getinfo info;\n\t\tconst struct xt_table_info *private = t->private;\n#ifdef CONFIG_COMPAT\n\t\tstruct xt_table_info tmp;\n\n\t\tif (compat) {\n\t\t\tret = compat_table_info(private, &tmp);\n\t\t\txt_compat_flush_offsets(AF_INET6);\n\t\t\tprivate = &tmp;\n\t\t}\n#endif\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.valid_hooks = t->valid_hooks;\n\t\tmemcpy(info.hook_entry, private->hook_entry,\n\t\t       sizeof(info.hook_entry));\n\t\tmemcpy(info.underflow, private->underflow,\n\t\t       sizeof(info.underflow));\n\t\tinfo.num_entries = private->number;\n\t\tinfo.size = private->size;\n\t\tstrcpy(info.name, name);\n\n\t\tif (copy_to_user(user, &info, *len) != 0)\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = 0;\n\n\t\txt_table_unlock(t);\n\t\tmodule_put(t->me);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_unlock(AF_INET6);\n#endif\n\treturn ret;\n}\n\nstatic int\nget_entries(struct net *net, struct ip6t_get_entries __user *uptr,\n\t    const int *len)\n{\n\tint ret;\n\tstruct ip6t_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct ip6t_get_entries) + get.size) {\n\t\tduprintf(\"get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, AF_INET6, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tstruct xt_table_info *private = t->private;\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse {\n\t\t\tduprintf(\"get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\treturn ret;\n}\n\nstatic int\n__do_replace(struct net *net, const char *name, unsigned int valid_hooks,\n\t     struct xt_table_info *newinfo, unsigned int num_counters,\n\t     void __user *counters_ptr)\n{\n\tint ret;\n\tstruct xt_table *t;\n\tstruct xt_table_info *oldinfo;\n\tstruct xt_counters *counters;\n\tstruct ip6t_entry *iter;\n\n\tret = 0;\n\tcounters = vzalloc(num_counters * sizeof(struct xt_counters));\n\tif (!counters) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tt = try_then_request_module(xt_find_table_lock(net, AF_INET6, name),\n\t\t\t\t    \"ip6table_%s\", name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free_newinfo_counters_untrans;\n\t}\n\n\t/* You lied! */\n\tif (valid_hooks != t->valid_hooks) {\n\t\tduprintf(\"Valid hook crap: %08X vs %08X\\n\",\n\t\t\t valid_hooks, t->valid_hooks);\n\t\tret = -EINVAL;\n\t\tgoto put_module;\n\t}\n\n\toldinfo = xt_replace_table(t, num_counters, newinfo, &ret);\n\tif (!oldinfo)\n\t\tgoto put_module;\n\n\t/* Update module usage count based on number of rules */\n\tduprintf(\"do_replace: oldnum=%u, initnum=%u, newnum=%u\\n\",\n\t\toldinfo->number, oldinfo->initial_entries, newinfo->number);\n\tif ((oldinfo->number > oldinfo->initial_entries) ||\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\tif ((oldinfo->number > oldinfo->initial_entries) &&\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\n\t/* Get the old counters, and synchronize with replace */\n\tget_counters(oldinfo, counters);\n\n\t/* Decrease module usage counts and free resource */\n\txt_entry_foreach(iter, oldinfo->entries, oldinfo->size)\n\t\tcleanup_entry(iter, net);\n\n\txt_free_table_info(oldinfo);\n\tif (copy_to_user(counters_ptr, counters,\n\t\t\t sizeof(struct xt_counters) * num_counters) != 0) {\n\t\t/* Silent error, can't fail, new table is already in place */\n\t\tnet_warn_ratelimited(\"ip6tables: counters copy to user failed while replacing table\\n\");\n\t}\n\tvfree(counters);\n\txt_table_unlock(t);\n\treturn ret;\n\n put_module:\n\tmodule_put(t->me);\n\txt_table_unlock(t);\n free_newinfo_counters_untrans:\n\tvfree(counters);\n out:\n\treturn ret;\n}\n\nstatic int\ndo_replace(struct net *net, const void __user *user, unsigned int len)\n{\n\tint ret;\n\tstruct ip6t_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct ip6t_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_table(net, newinfo, loc_cpu_entry, &tmp);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"ip_tables: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, tmp.counters);\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter, net);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int\ndo_add_counters(struct net *net, const void __user *user, unsigned int len,\n\t\tint compat)\n{\n\tunsigned int i;\n\tstruct xt_counters_info tmp;\n\tstruct xt_counters *paddc;\n\tunsigned int num_counters;\n\tchar *name;\n\tint size;\n\tvoid *ptmp;\n\tstruct xt_table *t;\n\tconst struct xt_table_info *private;\n\tint ret = 0;\n\tstruct ip6t_entry *iter;\n\tunsigned int addend;\n#ifdef CONFIG_COMPAT\n\tstruct compat_xt_counters_info compat_tmp;\n\n\tif (compat) {\n\t\tptmp = &compat_tmp;\n\t\tsize = sizeof(struct compat_xt_counters_info);\n\t} else\n#endif\n\t{\n\t\tptmp = &tmp;\n\t\tsize = sizeof(struct xt_counters_info);\n\t}\n\n\tif (copy_from_user(ptmp, user, size) != 0)\n\t\treturn -EFAULT;\n\n#ifdef CONFIG_COMPAT\n\tif (compat) {\n\t\tnum_counters = compat_tmp.num_counters;\n\t\tname = compat_tmp.name;\n\t} else\n#endif\n\t{\n\t\tnum_counters = tmp.num_counters;\n\t\tname = tmp.name;\n\t}\n\n\tif (len != size + num_counters * sizeof(struct xt_counters))\n\t\treturn -EINVAL;\n\n\tpaddc = vmalloc(len - size);\n\tif (!paddc)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(paddc, user + size, len - size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free;\n\t}\n\n\tt = xt_find_table_lock(net, AF_INET6, name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free;\n\t}\n\n\tlocal_bh_disable();\n\tprivate = t->private;\n\tif (private->number != num_counters) {\n\t\tret = -EINVAL;\n\t\tgoto unlock_up_free;\n\t}\n\n\ti = 0;\n\taddend = xt_write_recseq_begin();\n\txt_entry_foreach(iter, private->entries, private->size) {\n\t\tstruct xt_counters *tmp;\n\n\t\ttmp = xt_get_this_cpu_counter(&iter->counters);\n\t\tADD_COUNTER(*tmp, paddc[i].bcnt, paddc[i].pcnt);\n\t\t++i;\n\t}\n\txt_write_recseq_end(addend);\n unlock_up_free:\n\tlocal_bh_enable();\n\txt_table_unlock(t);\n\tmodule_put(t->me);\n free:\n\tvfree(paddc);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_ip6t_replace {\n\tchar\t\t\tname[XT_TABLE_MAXNAMELEN];\n\tu32\t\t\tvalid_hooks;\n\tu32\t\t\tnum_entries;\n\tu32\t\t\tsize;\n\tu32\t\t\thook_entry[NF_INET_NUMHOOKS];\n\tu32\t\t\tunderflow[NF_INET_NUMHOOKS];\n\tu32\t\t\tnum_counters;\n\tcompat_uptr_t\t\tcounters;\t/* struct xt_counters * */\n\tstruct compat_ip6t_entry entries[0];\n};\n\nstatic int\ncompat_copy_entry_to_user(struct ip6t_entry *e, void __user **dstptr,\n\t\t\t  unsigned int *size, struct xt_counters *counters,\n\t\t\t  unsigned int i)\n{\n\tstruct xt_entry_target *t;\n\tstruct compat_ip6t_entry __user *ce;\n\tu_int16_t target_offset, next_offset;\n\tcompat_uint_t origsize;\n\tconst struct xt_entry_match *ematch;\n\tint ret = 0;\n\n\torigsize = *size;\n\tce = (struct compat_ip6t_entry __user *)*dstptr;\n\tif (copy_to_user(ce, e, sizeof(struct ip6t_entry)) != 0 ||\n\t    copy_to_user(&ce->counters, &counters[i],\n\t    sizeof(counters[i])) != 0)\n\t\treturn -EFAULT;\n\n\t*dstptr += sizeof(struct compat_ip6t_entry);\n\t*size -= sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\n\txt_ematch_foreach(ematch, e) {\n\t\tret = xt_compat_match_to_user(ematch, dstptr, size);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\ttarget_offset = e->target_offset - (origsize - *size);\n\tt = ip6t_get_target(e);\n\tret = xt_compat_target_to_user(t, dstptr, size);\n\tif (ret)\n\t\treturn ret;\n\tnext_offset = e->next_offset - (origsize - *size);\n\tif (put_user(target_offset, &ce->target_offset) != 0 ||\n\t    put_user(next_offset, &ce->next_offset) != 0)\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int\ncompat_find_calc_match(struct xt_entry_match *m,\n\t\t       const char *name,\n\t\t       const struct ip6t_ip6 *ipv6,\n\t\t       int *size)\n{\n\tstruct xt_match *match;\n\n\tmatch = xt_request_find_match(NFPROTO_IPV6, m->u.user.name,\n\t\t\t\t      m->u.user.revision);\n\tif (IS_ERR(match)) {\n\t\tduprintf(\"compat_check_calc_match: `%s' not found\\n\",\n\t\t\t m->u.user.name);\n\t\treturn PTR_ERR(match);\n\t}\n\tm->u.kernel.match = match;\n\t*size += xt_compat_match_offset(match);\n\treturn 0;\n}\n\nstatic void compat_release_entry(struct compat_ip6t_entry *e)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_entry_match *ematch;\n\n\t/* Cleanup all matches */\n\txt_ematch_foreach(ematch, e)\n\t\tmodule_put(ematch->u.kernel.match->me);\n\tt = compat_ip6t_get_target(e);\n\tmodule_put(t->u.kernel.target->me);\n}\n\nstatic int\ncheck_compat_entry_size_and_hooks(struct compat_ip6t_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ip6t_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ipv6, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ip6t_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET6, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}\n\nstatic int\ncompat_copy_entry_from_user(struct compat_ip6t_entry *e, void **dstptr,\n\t\t\t    unsigned int *size, const char *name,\n\t\t\t    struct xt_table_info *newinfo, unsigned char *base)\n{\n\tstruct xt_entry_target *t;\n\tstruct ip6t_entry *de;\n\tunsigned int origsize;\n\tint ret, h;\n\tstruct xt_entry_match *ematch;\n\n\tret = 0;\n\torigsize = *size;\n\tde = (struct ip6t_entry *)*dstptr;\n\tmemcpy(de, e, sizeof(struct ip6t_entry));\n\tmemcpy(&de->counters, &e->counters, sizeof(e->counters));\n\n\t*dstptr += sizeof(struct ip6t_entry);\n\t*size += sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\n\txt_ematch_foreach(ematch, e) {\n\t\tret = xt_compat_match_from_user(ematch, dstptr, size);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\tde->target_offset = e->target_offset - (origsize - *size);\n\tt = compat_ip6t_get_target(e);\n\txt_compat_target_from_user(t, dstptr, size);\n\n\tde->next_offset = e->next_offset - (origsize - *size);\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)de - base < newinfo->hook_entry[h])\n\t\t\tnewinfo->hook_entry[h] -= origsize - *size;\n\t\tif ((unsigned char *)de - base < newinfo->underflow[h])\n\t\t\tnewinfo->underflow[h] -= origsize - *size;\n\t}\n\treturn ret;\n}\n\nstatic int compat_check_entry(struct ip6t_entry *e, struct net *net,\n\t\t\t      const char *name)\n{\n\tunsigned int j;\n\tint ret = 0;\n\tstruct xt_mtchk_param mtpar;\n\tstruct xt_entry_match *ematch;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\tj = 0;\n\tmtpar.net\t= net;\n\tmtpar.table     = name;\n\tmtpar.entryinfo = &e->ipv6;\n\tmtpar.hook_mask = e->comefrom;\n\tmtpar.family    = NFPROTO_IPV6;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = check_match(ematch, &mtpar);\n\t\tif (ret != 0)\n\t\t\tgoto cleanup_matches;\n\t\t++j;\n\t}\n\n\tret = check_target(e, net, name);\n\tif (ret)\n\t\tgoto cleanup_matches;\n\treturn 0;\n\n cleanup_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcleanup_match(ematch, net);\n\t}\n\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic int\ntranslate_compat_table(struct net *net,\n\t\t       const char *name,\n\t\t       unsigned int valid_hooks,\n\t\t       struct xt_table_info **pinfo,\n\t\t       void **pentry0,\n\t\t       unsigned int total_size,\n\t\t       unsigned int number,\n\t\t       unsigned int *hook_entries,\n\t\t       unsigned int *underflows)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_ip6t_entry *iter0;\n\tstruct ip6t_entry *iter1;\n\tunsigned int size;\n\tint ret = 0;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = total_size;\n\tinfo->number = number;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_compat_table: size %u\\n\", info->size);\n\tj = 0;\n\txt_compat_lock(AF_INET6);\n\txt_compat_init_offsets(AF_INET6, number);\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + total_size,\n\t\t\t\t\t\t\thook_entries,\n\t\t\t\t\t\t\tunderflows,\n\t\t\t\t\t\t\tname);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != number) {\n\t\tduprintf(\"translate_compat_table: %u not %u entries\\n\",\n\t\t\t j, number);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (info->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, hook_entries[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tif (info->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, underflows[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = number;\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = info->hook_entry[i];\n\t\tnewinfo->underflow[i] = info->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = total_size;\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = compat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t\t  name, newinfo, entry1);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\txt_compat_flush_offsets(AF_INET6);\n\txt_compat_unlock(AF_INET6);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\tret = -ELOOP;\n\tif (!mark_source_chains(newinfo, valid_hooks, entry1))\n\t\tgoto free_newinfo;\n\n\ti = 0;\n\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\tret = compat_check_entry(iter1, net, name);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t\tif (strcmp(ip6t_get_target(iter1)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\tif (ret) {\n\t\t/*\n\t\t * The first i matches need cleanup_entry (calls ->destroy)\n\t\t * because they had called ->check already. The other j-i\n\t\t * entries need only release.\n\t\t */\n\t\tint skip = i;\n\t\tj -= i;\n\t\txt_entry_foreach(iter0, entry0, newinfo->size) {\n\t\t\tif (skip-- > 0)\n\t\t\t\tcontinue;\n\t\t\tif (j-- == 0)\n\t\t\t\tbreak;\n\t\t\tcompat_release_entry(iter0);\n\t\t}\n\t\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter1, net);\n\t\t}\n\t\txt_free_table_info(newinfo);\n\t\treturn ret;\n\t}\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\nout:\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(AF_INET6);\n\txt_compat_unlock(AF_INET6);\n\tgoto out;\n}\n\nstatic int\ncompat_do_replace(struct net *net, void __user *user, unsigned int len)\n{\n\tint ret;\n\tstruct compat_ip6t_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct ip6t_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.size >= INT_MAX / num_possible_cpus())\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_compat_table(net, tmp.name, tmp.valid_hooks,\n\t\t\t\t     &newinfo, &loc_cpu_entry, tmp.size,\n\t\t\t\t     tmp.num_entries, tmp.hook_entry,\n\t\t\t\t     tmp.underflow);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"compat_do_replace: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, compat_ptr(tmp.counters));\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter, net);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int\ncompat_do_ip6t_set_ctl(struct sock *sk, int cmd, void __user *user,\n\t\t       unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IP6T_SO_SET_REPLACE:\n\t\tret = compat_do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IP6T_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 1);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_ip6t_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstruct compat_ip6t_get_entries {\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tcompat_uint_t size;\n\tstruct compat_ip6t_entry entrytable[0];\n};\n\nstatic int\ncompat_copy_entries_to_user(unsigned int total_size, struct xt_table *table,\n\t\t\t    void __user *userptr)\n{\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tvoid __user *pos;\n\tunsigned int size;\n\tint ret = 0;\n\tunsigned int i = 0;\n\tstruct ip6t_entry *iter;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tpos = userptr;\n\tsize = total_size;\n\txt_entry_foreach(iter, private->entries, total_size) {\n\t\tret = compat_copy_entry_to_user(iter, &pos,\n\t\t\t\t\t\t&size, counters, i++);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\n\tvfree(counters);\n\treturn ret;\n}\n\nstatic int\ncompat_get_entries(struct net *net, struct compat_ip6t_get_entries __user *uptr,\n\t\t   int *len)\n{\n\tint ret;\n\tstruct compat_ip6t_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"compat_get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\n\tif (*len != sizeof(struct compat_ip6t_get_entries) + get.size) {\n\t\tduprintf(\"compat_get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\txt_compat_lock(AF_INET6);\n\tt = xt_find_table_lock(net, AF_INET6, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tstruct xt_table_info info;\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tret = compat_table_info(private, &info);\n\t\tif (!ret && get.size == info.size) {\n\t\t\tret = compat_copy_entries_to_user(private->size,\n\t\t\t\t\t\t\t  t, uptr->entrytable);\n\t\t} else if (!ret) {\n\t\t\tduprintf(\"compat_get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\txt_compat_flush_offsets(AF_INET6);\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\txt_compat_unlock(AF_INET6);\n\treturn ret;\n}\n\nstatic int do_ip6t_get_ctl(struct sock *, int, void __user *, int *);\n\nstatic int\ncompat_do_ip6t_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IP6T_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 1);\n\t\tbreak;\n\tcase IP6T_SO_GET_ENTRIES:\n\t\tret = compat_get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\tdefault:\n\t\tret = do_ip6t_get_ctl(sk, cmd, user, len);\n\t}\n\treturn ret;\n}\n#endif\n\nstatic int\ndo_ip6t_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IP6T_SO_SET_REPLACE:\n\t\tret = do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IP6T_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_ip6t_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int\ndo_ip6t_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IP6T_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tcase IP6T_SO_GET_ENTRIES:\n\t\tret = get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IP6T_SO_GET_REVISION_MATCH:\n\tcase IP6T_SO_GET_REVISION_TARGET: {\n\t\tstruct xt_get_revision rev;\n\t\tint target;\n\n\t\tif (*len != sizeof(rev)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&rev, user, sizeof(rev)) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\trev.name[sizeof(rev.name)-1] = 0;\n\n\t\tif (cmd == IP6T_SO_GET_REVISION_TARGET)\n\t\t\ttarget = 1;\n\t\telse\n\t\t\ttarget = 0;\n\n\t\ttry_then_request_module(xt_find_revision(AF_INET6, rev.name,\n\t\t\t\t\t\t\t rev.revision,\n\t\t\t\t\t\t\t target, &ret),\n\t\t\t\t\t\"ip6t_%s\", rev.name);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tduprintf(\"do_ip6t_get_ctl: unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic void __ip6t_unregister_table(struct net *net, struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\tvoid *loc_cpu_entry;\n\tstruct module *table_owner = table->me;\n\tstruct ip6t_entry *iter;\n\n\tprivate = xt_unregister_table(table);\n\n\t/* Decrease module usage counts and free resources */\n\tloc_cpu_entry = private->entries;\n\txt_entry_foreach(iter, loc_cpu_entry, private->size)\n\t\tcleanup_entry(iter, net);\n\tif (private->number > private->initial_entries)\n\t\tmodule_put(table_owner);\n\txt_free_table_info(private);\n}\n\nint ip6t_register_table(struct net *net, const struct xt_table *table,\n\t\t\tconst struct ip6t_replace *repl,\n\t\t\tconst struct nf_hook_ops *ops,\n\t\t\tstruct xt_table **res)\n{\n\tint ret;\n\tstruct xt_table_info *newinfo;\n\tstruct xt_table_info bootstrap = {0};\n\tvoid *loc_cpu_entry;\n\tstruct xt_table *new_table;\n\n\tnewinfo = xt_alloc_table_info(repl->size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tmemcpy(loc_cpu_entry, repl->entries, repl->size);\n\n\tret = translate_table(net, newinfo, loc_cpu_entry, repl);\n\tif (ret != 0)\n\t\tgoto out_free;\n\n\tnew_table = xt_register_table(net, table, &bootstrap, newinfo);\n\tif (IS_ERR(new_table)) {\n\t\tret = PTR_ERR(new_table);\n\t\tgoto out_free;\n\t}\n\n\t/* set res now, will see skbs right after nf_register_net_hooks */\n\tWRITE_ONCE(*res, new_table);\n\n\tret = nf_register_net_hooks(net, ops, hweight32(table->valid_hooks));\n\tif (ret != 0) {\n\t\t__ip6t_unregister_table(net, new_table);\n\t\t*res = NULL;\n\t}\n\n\treturn ret;\n\nout_free:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nvoid ip6t_unregister_table(struct net *net, struct xt_table *table,\n\t\t\t   const struct nf_hook_ops *ops)\n{\n\tnf_unregister_net_hooks(net, ops, hweight32(table->valid_hooks));\n\t__ip6t_unregister_table(net, table);\n}\n\n/* Returns 1 if the type and code is matched by the range, 0 otherwise */\nstatic inline bool\nicmp6_type_code_match(u_int8_t test_type, u_int8_t min_code, u_int8_t max_code,\n\t\t     u_int8_t type, u_int8_t code,\n\t\t     bool invert)\n{\n\treturn (type == test_type && code >= min_code && code <= max_code)\n\t\t^ invert;\n}\n\nstatic bool\nicmp6_match(const struct sk_buff *skb, struct xt_action_param *par)\n{\n\tconst struct icmp6hdr *ic;\n\tstruct icmp6hdr _icmph;\n\tconst struct ip6t_icmp *icmpinfo = par->matchinfo;\n\n\t/* Must not be a fragment. */\n\tif (par->fragoff != 0)\n\t\treturn false;\n\n\tic = skb_header_pointer(skb, par->thoff, sizeof(_icmph), &_icmph);\n\tif (ic == NULL) {\n\t\t/* We've been asked to examine this packet, and we\n\t\t * can't.  Hence, no choice but to drop.\n\t\t */\n\t\tduprintf(\"Dropping evil ICMP tinygram.\\n\");\n\t\tpar->hotdrop = true;\n\t\treturn false;\n\t}\n\n\treturn icmp6_type_code_match(icmpinfo->type,\n\t\t\t\t     icmpinfo->code[0],\n\t\t\t\t     icmpinfo->code[1],\n\t\t\t\t     ic->icmp6_type, ic->icmp6_code,\n\t\t\t\t     !!(icmpinfo->invflags&IP6T_ICMP_INV));\n}\n\n/* Called when user tries to insert an entry of this type. */\nstatic int icmp6_checkentry(const struct xt_mtchk_param *par)\n{\n\tconst struct ip6t_icmp *icmpinfo = par->matchinfo;\n\n\t/* Must specify no unknown invflags */\n\treturn (icmpinfo->invflags & ~IP6T_ICMP_INV) ? -EINVAL : 0;\n}\n\n/* The built-in targets: standard (NULL) and error. */\nstatic struct xt_target ip6t_builtin_tg[] __read_mostly = {\n\t{\n\t\t.name             = XT_STANDARD_TARGET,\n\t\t.targetsize       = sizeof(int),\n\t\t.family           = NFPROTO_IPV6,\n#ifdef CONFIG_COMPAT\n\t\t.compatsize       = sizeof(compat_int_t),\n\t\t.compat_from_user = compat_standard_from_user,\n\t\t.compat_to_user   = compat_standard_to_user,\n#endif\n\t},\n\t{\n\t\t.name             = XT_ERROR_TARGET,\n\t\t.target           = ip6t_error,\n\t\t.targetsize       = XT_FUNCTION_MAXNAMELEN,\n\t\t.family           = NFPROTO_IPV6,\n\t},\n};\n\nstatic struct nf_sockopt_ops ip6t_sockopts = {\n\t.pf\t\t= PF_INET6,\n\t.set_optmin\t= IP6T_BASE_CTL,\n\t.set_optmax\t= IP6T_SO_SET_MAX+1,\n\t.set\t\t= do_ip6t_set_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_set\t= compat_do_ip6t_set_ctl,\n#endif\n\t.get_optmin\t= IP6T_BASE_CTL,\n\t.get_optmax\t= IP6T_SO_GET_MAX+1,\n\t.get\t\t= do_ip6t_get_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_get\t= compat_do_ip6t_get_ctl,\n#endif\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic struct xt_match ip6t_builtin_mt[] __read_mostly = {\n\t{\n\t\t.name       = \"icmp6\",\n\t\t.match      = icmp6_match,\n\t\t.matchsize  = sizeof(struct ip6t_icmp),\n\t\t.checkentry = icmp6_checkentry,\n\t\t.proto      = IPPROTO_ICMPV6,\n\t\t.family     = NFPROTO_IPV6,\n\t},\n};\n\nstatic int __net_init ip6_tables_net_init(struct net *net)\n{\n\treturn xt_proto_init(net, NFPROTO_IPV6);\n}\n\nstatic void __net_exit ip6_tables_net_exit(struct net *net)\n{\n\txt_proto_fini(net, NFPROTO_IPV6);\n}\n\nstatic struct pernet_operations ip6_tables_net_ops = {\n\t.init = ip6_tables_net_init,\n\t.exit = ip6_tables_net_exit,\n};\n\nstatic int __init ip6_tables_init(void)\n{\n\tint ret;\n\n\tret = register_pernet_subsys(&ip6_tables_net_ops);\n\tif (ret < 0)\n\t\tgoto err1;\n\n\t/* No one else will be downing sem now, so we won't sleep */\n\tret = xt_register_targets(ip6t_builtin_tg, ARRAY_SIZE(ip6t_builtin_tg));\n\tif (ret < 0)\n\t\tgoto err2;\n\tret = xt_register_matches(ip6t_builtin_mt, ARRAY_SIZE(ip6t_builtin_mt));\n\tif (ret < 0)\n\t\tgoto err4;\n\n\t/* Register setsockopt */\n\tret = nf_register_sockopt(&ip6t_sockopts);\n\tif (ret < 0)\n\t\tgoto err5;\n\n\tpr_info(\"(C) 2000-2006 Netfilter Core Team\\n\");\n\treturn 0;\n\nerr5:\n\txt_unregister_matches(ip6t_builtin_mt, ARRAY_SIZE(ip6t_builtin_mt));\nerr4:\n\txt_unregister_targets(ip6t_builtin_tg, ARRAY_SIZE(ip6t_builtin_tg));\nerr2:\n\tunregister_pernet_subsys(&ip6_tables_net_ops);\nerr1:\n\treturn ret;\n}\n\nstatic void __exit ip6_tables_fini(void)\n{\n\tnf_unregister_sockopt(&ip6t_sockopts);\n\n\txt_unregister_matches(ip6t_builtin_mt, ARRAY_SIZE(ip6t_builtin_mt));\n\txt_unregister_targets(ip6t_builtin_tg, ARRAY_SIZE(ip6t_builtin_tg));\n\tunregister_pernet_subsys(&ip6_tables_net_ops);\n}\n\nEXPORT_SYMBOL(ip6t_register_table);\nEXPORT_SYMBOL(ip6t_unregister_table);\nEXPORT_SYMBOL(ip6t_do_table);\n\nmodule_init(ip6_tables_init);\nmodule_exit(ip6_tables_fini);\n", "/*\n * x_tables core - Backend for {ip,ip6,arp}_tables\n *\n * Copyright (C) 2006-2006 Harald Welte <laforge@netfilter.org>\n * Copyright (C) 2006-2012 Patrick McHardy <kaber@trash.net>\n *\n * Based on existing ip_tables code which is\n *   Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling\n *   Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n *\n */\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/socket.h>\n#include <linux/net.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/string.h>\n#include <linux/vmalloc.h>\n#include <linux/mutex.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/audit.h>\n#include <linux/user_namespace.h>\n#include <net/net_namespace.h>\n\n#include <linux/netfilter/x_tables.h>\n#include <linux/netfilter_arp.h>\n#include <linux/netfilter_ipv4/ip_tables.h>\n#include <linux/netfilter_ipv6/ip6_tables.h>\n#include <linux/netfilter_arp/arp_tables.h>\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Harald Welte <laforge@netfilter.org>\");\nMODULE_DESCRIPTION(\"{ip,ip6,arp,eb}_tables backend module\");\n\n#define SMP_ALIGN(x) (((x) + SMP_CACHE_BYTES-1) & ~(SMP_CACHE_BYTES-1))\n\nstruct compat_delta {\n\tunsigned int offset; /* offset in kernel */\n\tint delta; /* delta in 32bit user land */\n};\n\nstruct xt_af {\n\tstruct mutex mutex;\n\tstruct list_head match;\n\tstruct list_head target;\n#ifdef CONFIG_COMPAT\n\tstruct mutex compat_mutex;\n\tstruct compat_delta *compat_tab;\n\tunsigned int number; /* number of slots in compat_tab[] */\n\tunsigned int cur; /* number of used slots in compat_tab[] */\n#endif\n};\n\nstatic struct xt_af *xt;\n\nstatic const char *const xt_prefix[NFPROTO_NUMPROTO] = {\n\t[NFPROTO_UNSPEC] = \"x\",\n\t[NFPROTO_IPV4]   = \"ip\",\n\t[NFPROTO_ARP]    = \"arp\",\n\t[NFPROTO_BRIDGE] = \"eb\",\n\t[NFPROTO_IPV6]   = \"ip6\",\n};\n\n/* Registration hooks for targets. */\nint xt_register_target(struct xt_target *target)\n{\n\tu_int8_t af = target->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_add(&target->list, &xt[af].target);\n\tmutex_unlock(&xt[af].mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_register_target);\n\nvoid\nxt_unregister_target(struct xt_target *target)\n{\n\tu_int8_t af = target->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_del(&target->list);\n\tmutex_unlock(&xt[af].mutex);\n}\nEXPORT_SYMBOL(xt_unregister_target);\n\nint\nxt_register_targets(struct xt_target *target, unsigned int n)\n{\n\tunsigned int i;\n\tint err = 0;\n\n\tfor (i = 0; i < n; i++) {\n\t\terr = xt_register_target(&target[i]);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\treturn err;\n\nerr:\n\tif (i > 0)\n\t\txt_unregister_targets(target, i);\n\treturn err;\n}\nEXPORT_SYMBOL(xt_register_targets);\n\nvoid\nxt_unregister_targets(struct xt_target *target, unsigned int n)\n{\n\twhile (n-- > 0)\n\t\txt_unregister_target(&target[n]);\n}\nEXPORT_SYMBOL(xt_unregister_targets);\n\nint xt_register_match(struct xt_match *match)\n{\n\tu_int8_t af = match->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_add(&match->list, &xt[af].match);\n\tmutex_unlock(&xt[af].mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_register_match);\n\nvoid\nxt_unregister_match(struct xt_match *match)\n{\n\tu_int8_t af = match->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_del(&match->list);\n\tmutex_unlock(&xt[af].mutex);\n}\nEXPORT_SYMBOL(xt_unregister_match);\n\nint\nxt_register_matches(struct xt_match *match, unsigned int n)\n{\n\tunsigned int i;\n\tint err = 0;\n\n\tfor (i = 0; i < n; i++) {\n\t\terr = xt_register_match(&match[i]);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\treturn err;\n\nerr:\n\tif (i > 0)\n\t\txt_unregister_matches(match, i);\n\treturn err;\n}\nEXPORT_SYMBOL(xt_register_matches);\n\nvoid\nxt_unregister_matches(struct xt_match *match, unsigned int n)\n{\n\twhile (n-- > 0)\n\t\txt_unregister_match(&match[n]);\n}\nEXPORT_SYMBOL(xt_unregister_matches);\n\n\n/*\n * These are weird, but module loading must not be done with mutex\n * held (since they will register), and we have to have a single\n * function to use.\n */\n\n/* Find match, grabs ref.  Returns ERR_PTR() on error. */\nstruct xt_match *xt_find_match(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_match *m;\n\tint err = -ENOENT;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(m, &xt[af].match, list) {\n\t\tif (strcmp(m->name, name) == 0) {\n\t\t\tif (m->revision == revision) {\n\t\t\t\tif (try_module_get(m->me)) {\n\t\t\t\t\tmutex_unlock(&xt[af].mutex);\n\t\t\t\t\treturn m;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\terr = -EPROTOTYPE; /* Found something. */\n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\n\tif (af != NFPROTO_UNSPEC)\n\t\t/* Try searching again in the family-independent list */\n\t\treturn xt_find_match(NFPROTO_UNSPEC, name, revision);\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xt_find_match);\n\nstruct xt_match *\nxt_request_find_match(uint8_t nfproto, const char *name, uint8_t revision)\n{\n\tstruct xt_match *match;\n\n\tmatch = xt_find_match(nfproto, name, revision);\n\tif (IS_ERR(match)) {\n\t\trequest_module(\"%st_%s\", xt_prefix[nfproto], name);\n\t\tmatch = xt_find_match(nfproto, name, revision);\n\t}\n\n\treturn match;\n}\nEXPORT_SYMBOL_GPL(xt_request_find_match);\n\n/* Find target, grabs ref.  Returns ERR_PTR() on error. */\nstruct xt_target *xt_find_target(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_target *t;\n\tint err = -ENOENT;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &xt[af].target, list) {\n\t\tif (strcmp(t->name, name) == 0) {\n\t\t\tif (t->revision == revision) {\n\t\t\t\tif (try_module_get(t->me)) {\n\t\t\t\t\tmutex_unlock(&xt[af].mutex);\n\t\t\t\t\treturn t;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\terr = -EPROTOTYPE; /* Found something. */\n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\n\tif (af != NFPROTO_UNSPEC)\n\t\t/* Try searching again in the family-independent list */\n\t\treturn xt_find_target(NFPROTO_UNSPEC, name, revision);\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xt_find_target);\n\nstruct xt_target *xt_request_find_target(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_target *target;\n\n\ttarget = xt_find_target(af, name, revision);\n\tif (IS_ERR(target)) {\n\t\trequest_module(\"%st_%s\", xt_prefix[af], name);\n\t\ttarget = xt_find_target(af, name, revision);\n\t}\n\n\treturn target;\n}\nEXPORT_SYMBOL_GPL(xt_request_find_target);\n\nstatic int match_revfn(u8 af, const char *name, u8 revision, int *bestp)\n{\n\tconst struct xt_match *m;\n\tint have_rev = 0;\n\n\tlist_for_each_entry(m, &xt[af].match, list) {\n\t\tif (strcmp(m->name, name) == 0) {\n\t\t\tif (m->revision > *bestp)\n\t\t\t\t*bestp = m->revision;\n\t\t\tif (m->revision == revision)\n\t\t\t\thave_rev = 1;\n\t\t}\n\t}\n\n\tif (af != NFPROTO_UNSPEC && !have_rev)\n\t\treturn match_revfn(NFPROTO_UNSPEC, name, revision, bestp);\n\n\treturn have_rev;\n}\n\nstatic int target_revfn(u8 af, const char *name, u8 revision, int *bestp)\n{\n\tconst struct xt_target *t;\n\tint have_rev = 0;\n\n\tlist_for_each_entry(t, &xt[af].target, list) {\n\t\tif (strcmp(t->name, name) == 0) {\n\t\t\tif (t->revision > *bestp)\n\t\t\t\t*bestp = t->revision;\n\t\t\tif (t->revision == revision)\n\t\t\t\thave_rev = 1;\n\t\t}\n\t}\n\n\tif (af != NFPROTO_UNSPEC && !have_rev)\n\t\treturn target_revfn(NFPROTO_UNSPEC, name, revision, bestp);\n\n\treturn have_rev;\n}\n\n/* Returns true or false (if no such extension at all) */\nint xt_find_revision(u8 af, const char *name, u8 revision, int target,\n\t\t     int *err)\n{\n\tint have_rev, best = -1;\n\n\tmutex_lock(&xt[af].mutex);\n\tif (target == 1)\n\t\thave_rev = target_revfn(af, name, revision, &best);\n\telse\n\t\thave_rev = match_revfn(af, name, revision, &best);\n\tmutex_unlock(&xt[af].mutex);\n\n\t/* Nothing at all?  Return 0 to try loading module. */\n\tif (best == -1) {\n\t\t*err = -ENOENT;\n\t\treturn 0;\n\t}\n\n\t*err = best;\n\tif (!have_rev)\n\t\t*err = -EPROTONOSUPPORT;\n\treturn 1;\n}\nEXPORT_SYMBOL_GPL(xt_find_revision);\n\nstatic char *\ntextify_hooks(char *buf, size_t size, unsigned int mask, uint8_t nfproto)\n{\n\tstatic const char *const inetbr_names[] = {\n\t\t\"PREROUTING\", \"INPUT\", \"FORWARD\",\n\t\t\"OUTPUT\", \"POSTROUTING\", \"BROUTING\",\n\t};\n\tstatic const char *const arp_names[] = {\n\t\t\"INPUT\", \"FORWARD\", \"OUTPUT\",\n\t};\n\tconst char *const *names;\n\tunsigned int i, max;\n\tchar *p = buf;\n\tbool np = false;\n\tint res;\n\n\tnames = (nfproto == NFPROTO_ARP) ? arp_names : inetbr_names;\n\tmax   = (nfproto == NFPROTO_ARP) ? ARRAY_SIZE(arp_names) :\n\t                                   ARRAY_SIZE(inetbr_names);\n\t*p = '\\0';\n\tfor (i = 0; i < max; ++i) {\n\t\tif (!(mask & (1 << i)))\n\t\t\tcontinue;\n\t\tres = snprintf(p, size, \"%s%s\", np ? \"/\" : \"\", names[i]);\n\t\tif (res > 0) {\n\t\t\tsize -= res;\n\t\t\tp += res;\n\t\t}\n\t\tnp = true;\n\t}\n\n\treturn buf;\n}\n\nint xt_check_match(struct xt_mtchk_param *par,\n\t\t   unsigned int size, u_int8_t proto, bool inv_proto)\n{\n\tint ret;\n\n\tif (XT_ALIGN(par->match->matchsize) != size &&\n\t    par->match->matchsize != -1) {\n\t\t/*\n\t\t * ebt_among is exempt from centralized matchsize checking\n\t\t * because it uses a dynamic-size data set.\n\t\t */\n\t\tpr_err(\"%s_tables: %s.%u match: invalid size \"\n\t\t       \"%u (kernel) != (user) %u\\n\",\n\t\t       xt_prefix[par->family], par->match->name,\n\t\t       par->match->revision,\n\t\t       XT_ALIGN(par->match->matchsize), size);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->table != NULL &&\n\t    strcmp(par->match->table, par->table) != 0) {\n\t\tpr_err(\"%s_tables: %s match: only valid in %s table, not %s\\n\",\n\t\t       xt_prefix[par->family], par->match->name,\n\t\t       par->match->table, par->table);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->hooks && (par->hook_mask & ~par->match->hooks) != 0) {\n\t\tchar used[64], allow[64];\n\n\t\tpr_err(\"%s_tables: %s match: used from hooks %s, but only \"\n\t\t       \"valid from %s\\n\",\n\t\t       xt_prefix[par->family], par->match->name,\n\t\t       textify_hooks(used, sizeof(used), par->hook_mask,\n\t\t                     par->family),\n\t\t       textify_hooks(allow, sizeof(allow), par->match->hooks,\n\t\t                     par->family));\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->proto && (par->match->proto != proto || inv_proto)) {\n\t\tpr_err(\"%s_tables: %s match: only valid for protocol %u\\n\",\n\t\t       xt_prefix[par->family], par->match->name,\n\t\t       par->match->proto);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->checkentry != NULL) {\n\t\tret = par->match->checkentry(par);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\telse if (ret > 0)\n\t\t\t/* Flag up potential errors. */\n\t\t\treturn -EIO;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_check_match);\n\n#ifdef CONFIG_COMPAT\nint xt_compat_add_offset(u_int8_t af, unsigned int offset, int delta)\n{\n\tstruct xt_af *xp = &xt[af];\n\n\tif (!xp->compat_tab) {\n\t\tif (!xp->number)\n\t\t\treturn -EINVAL;\n\t\txp->compat_tab = vmalloc(sizeof(struct compat_delta) * xp->number);\n\t\tif (!xp->compat_tab)\n\t\t\treturn -ENOMEM;\n\t\txp->cur = 0;\n\t}\n\n\tif (xp->cur >= xp->number)\n\t\treturn -EINVAL;\n\n\tif (xp->cur)\n\t\tdelta += xp->compat_tab[xp->cur - 1].delta;\n\txp->compat_tab[xp->cur].offset = offset;\n\txp->compat_tab[xp->cur].delta = delta;\n\txp->cur++;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_add_offset);\n\nvoid xt_compat_flush_offsets(u_int8_t af)\n{\n\tif (xt[af].compat_tab) {\n\t\tvfree(xt[af].compat_tab);\n\t\txt[af].compat_tab = NULL;\n\t\txt[af].number = 0;\n\t\txt[af].cur = 0;\n\t}\n}\nEXPORT_SYMBOL_GPL(xt_compat_flush_offsets);\n\nint xt_compat_calc_jump(u_int8_t af, unsigned int offset)\n{\n\tstruct compat_delta *tmp = xt[af].compat_tab;\n\tint mid, left = 0, right = xt[af].cur - 1;\n\n\twhile (left <= right) {\n\t\tmid = (left + right) >> 1;\n\t\tif (offset > tmp[mid].offset)\n\t\t\tleft = mid + 1;\n\t\telse if (offset < tmp[mid].offset)\n\t\t\tright = mid - 1;\n\t\telse\n\t\t\treturn mid ? tmp[mid - 1].delta : 0;\n\t}\n\treturn left ? tmp[left - 1].delta : 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_calc_jump);\n\nvoid xt_compat_init_offsets(u_int8_t af, unsigned int number)\n{\n\txt[af].number = number;\n\txt[af].cur = 0;\n}\nEXPORT_SYMBOL(xt_compat_init_offsets);\n\nint xt_compat_match_offset(const struct xt_match *match)\n{\n\tu_int16_t csize = match->compatsize ? : match->matchsize;\n\treturn XT_ALIGN(match->matchsize) - COMPAT_XT_ALIGN(csize);\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_offset);\n\nint xt_compat_match_from_user(struct xt_entry_match *m, void **dstptr,\n\t\t\t      unsigned int *size)\n{\n\tconst struct xt_match *match = m->u.kernel.match;\n\tstruct compat_xt_entry_match *cm = (struct compat_xt_entry_match *)m;\n\tint pad, off = xt_compat_match_offset(match);\n\tu_int16_t msize = cm->u.user.match_size;\n\n\tm = *dstptr;\n\tmemcpy(m, cm, sizeof(*cm));\n\tif (match->compat_from_user)\n\t\tmatch->compat_from_user(m->data, cm->data);\n\telse\n\t\tmemcpy(m->data, cm->data, msize - sizeof(*cm));\n\tpad = XT_ALIGN(match->matchsize) - match->matchsize;\n\tif (pad > 0)\n\t\tmemset(m->data + match->matchsize, 0, pad);\n\n\tmsize += off;\n\tm->u.user.match_size = msize;\n\n\t*size += off;\n\t*dstptr += msize;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_from_user);\n\nint xt_compat_match_to_user(const struct xt_entry_match *m,\n\t\t\t    void __user **dstptr, unsigned int *size)\n{\n\tconst struct xt_match *match = m->u.kernel.match;\n\tstruct compat_xt_entry_match __user *cm = *dstptr;\n\tint off = xt_compat_match_offset(match);\n\tu_int16_t msize = m->u.user.match_size - off;\n\n\tif (copy_to_user(cm, m, sizeof(*cm)) ||\n\t    put_user(msize, &cm->u.user.match_size) ||\n\t    copy_to_user(cm->u.user.name, m->u.kernel.match->name,\n\t\t\t strlen(m->u.kernel.match->name) + 1))\n\t\treturn -EFAULT;\n\n\tif (match->compat_to_user) {\n\t\tif (match->compat_to_user((void __user *)cm->data, m->data))\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tif (copy_to_user(cm->data, m->data, msize - sizeof(*cm)))\n\t\t\treturn -EFAULT;\n\t}\n\n\t*size -= off;\n\t*dstptr += msize;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_to_user);\n\n/* non-compat version may have padding after verdict */\nstruct compat_xt_standard_target {\n\tstruct compat_xt_entry_target t;\n\tcompat_uint_t verdict;\n};\n\n/* see xt_check_entry_offsets */\nint xt_compat_check_entry_offsets(const void *base,\n\t\t\t\t  unsigned int target_offset,\n\t\t\t\t  unsigned int next_offset)\n{\n\tconst struct compat_xt_entry_target *t;\n\tconst char *e = base;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0 &&\n\t    target_offset + sizeof(struct compat_xt_standard_target) != next_offset)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_compat_check_entry_offsets);\n#endif /* CONFIG_COMPAT */\n\n/**\n * xt_check_entry_offsets - validate arp/ip/ip6t_entry\n *\n * @base: pointer to arp/ip/ip6t_entry\n * @target_offset: the arp/ip/ip6_t->target_offset\n * @next_offset: the arp/ip/ip6_t->next_offset\n *\n * validates that target_offset and next_offset are sane.\n * Also see xt_compat_check_entry_offsets for CONFIG_COMPAT version.\n *\n * The arp/ip/ip6t_entry structure @base must have passed following tests:\n * - it must point to a valid memory location\n * - base to base + next_offset must be accessible, i.e. not exceed allocated\n *   length.\n *\n * Return: 0 on success, negative errno on failure.\n */\nint xt_check_entry_offsets(const void *base,\n\t\t\t   unsigned int target_offset,\n\t\t\t   unsigned int next_offset)\n{\n\tconst struct xt_entry_target *t;\n\tconst char *e = base;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0 &&\n\t    target_offset + sizeof(struct xt_standard_target) != next_offset)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_check_entry_offsets);\n\nint xt_check_target(struct xt_tgchk_param *par,\n\t\t    unsigned int size, u_int8_t proto, bool inv_proto)\n{\n\tint ret;\n\n\tif (XT_ALIGN(par->target->targetsize) != size) {\n\t\tpr_err(\"%s_tables: %s.%u target: invalid size \"\n\t\t       \"%u (kernel) != (user) %u\\n\",\n\t\t       xt_prefix[par->family], par->target->name,\n\t\t       par->target->revision,\n\t\t       XT_ALIGN(par->target->targetsize), size);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->table != NULL &&\n\t    strcmp(par->target->table, par->table) != 0) {\n\t\tpr_err(\"%s_tables: %s target: only valid in %s table, not %s\\n\",\n\t\t       xt_prefix[par->family], par->target->name,\n\t\t       par->target->table, par->table);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->hooks && (par->hook_mask & ~par->target->hooks) != 0) {\n\t\tchar used[64], allow[64];\n\n\t\tpr_err(\"%s_tables: %s target: used from hooks %s, but only \"\n\t\t       \"usable from %s\\n\",\n\t\t       xt_prefix[par->family], par->target->name,\n\t\t       textify_hooks(used, sizeof(used), par->hook_mask,\n\t\t                     par->family),\n\t\t       textify_hooks(allow, sizeof(allow), par->target->hooks,\n\t\t                     par->family));\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->proto && (par->target->proto != proto || inv_proto)) {\n\t\tpr_err(\"%s_tables: %s target: only valid for protocol %u\\n\",\n\t\t       xt_prefix[par->family], par->target->name,\n\t\t       par->target->proto);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->checkentry != NULL) {\n\t\tret = par->target->checkentry(par);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\telse if (ret > 0)\n\t\t\t/* Flag up potential errors. */\n\t\t\treturn -EIO;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_check_target);\n\n#ifdef CONFIG_COMPAT\nint xt_compat_target_offset(const struct xt_target *target)\n{\n\tu_int16_t csize = target->compatsize ? : target->targetsize;\n\treturn XT_ALIGN(target->targetsize) - COMPAT_XT_ALIGN(csize);\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_offset);\n\nvoid xt_compat_target_from_user(struct xt_entry_target *t, void **dstptr,\n\t\t\t\tunsigned int *size)\n{\n\tconst struct xt_target *target = t->u.kernel.target;\n\tstruct compat_xt_entry_target *ct = (struct compat_xt_entry_target *)t;\n\tint pad, off = xt_compat_target_offset(target);\n\tu_int16_t tsize = ct->u.user.target_size;\n\n\tt = *dstptr;\n\tmemcpy(t, ct, sizeof(*ct));\n\tif (target->compat_from_user)\n\t\ttarget->compat_from_user(t->data, ct->data);\n\telse\n\t\tmemcpy(t->data, ct->data, tsize - sizeof(*ct));\n\tpad = XT_ALIGN(target->targetsize) - target->targetsize;\n\tif (pad > 0)\n\t\tmemset(t->data + target->targetsize, 0, pad);\n\n\ttsize += off;\n\tt->u.user.target_size = tsize;\n\n\t*size += off;\n\t*dstptr += tsize;\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_from_user);\n\nint xt_compat_target_to_user(const struct xt_entry_target *t,\n\t\t\t     void __user **dstptr, unsigned int *size)\n{\n\tconst struct xt_target *target = t->u.kernel.target;\n\tstruct compat_xt_entry_target __user *ct = *dstptr;\n\tint off = xt_compat_target_offset(target);\n\tu_int16_t tsize = t->u.user.target_size - off;\n\n\tif (copy_to_user(ct, t, sizeof(*ct)) ||\n\t    put_user(tsize, &ct->u.user.target_size) ||\n\t    copy_to_user(ct->u.user.name, t->u.kernel.target->name,\n\t\t\t strlen(t->u.kernel.target->name) + 1))\n\t\treturn -EFAULT;\n\n\tif (target->compat_to_user) {\n\t\tif (target->compat_to_user((void __user *)ct->data, t->data))\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tif (copy_to_user(ct->data, t->data, tsize - sizeof(*ct)))\n\t\t\treturn -EFAULT;\n\t}\n\n\t*size -= off;\n\t*dstptr += tsize;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_to_user);\n#endif\n\nstruct xt_table_info *xt_alloc_table_info(unsigned int size)\n{\n\tstruct xt_table_info *info = NULL;\n\tsize_t sz = sizeof(*info) + size;\n\n\tif (sz < sizeof(*info))\n\t\treturn NULL;\n\n\t/* Pedantry: prevent them from hitting BUG() in vmalloc.c --RR */\n\tif ((SMP_ALIGN(size) >> PAGE_SHIFT) + 2 > totalram_pages)\n\t\treturn NULL;\n\n\tif (sz <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER))\n\t\tinfo = kmalloc(sz, GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (!info) {\n\t\tinfo = vmalloc(sz);\n\t\tif (!info)\n\t\t\treturn NULL;\n\t}\n\tmemset(info, 0, sizeof(*info));\n\tinfo->size = size;\n\treturn info;\n}\nEXPORT_SYMBOL(xt_alloc_table_info);\n\nvoid xt_free_table_info(struct xt_table_info *info)\n{\n\tint cpu;\n\n\tif (info->jumpstack != NULL) {\n\t\tfor_each_possible_cpu(cpu)\n\t\t\tkvfree(info->jumpstack[cpu]);\n\t\tkvfree(info->jumpstack);\n\t}\n\n\tkvfree(info);\n}\nEXPORT_SYMBOL(xt_free_table_info);\n\n/* Find table by name, grabs mutex & ref.  Returns ERR_PTR() on error. */\nstruct xt_table *xt_find_table_lock(struct net *net, u_int8_t af,\n\t\t\t\t    const char *name)\n{\n\tstruct xt_table *t, *found = NULL;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &net->xt.tables[af], list)\n\t\tif (strcmp(t->name, name) == 0 && try_module_get(t->me))\n\t\t\treturn t;\n\n\tif (net == &init_net)\n\t\tgoto out;\n\n\t/* Table doesn't exist in this netns, re-try init */\n\tlist_for_each_entry(t, &init_net.xt.tables[af], list) {\n\t\tif (strcmp(t->name, name))\n\t\t\tcontinue;\n\t\tif (!try_module_get(t->me))\n\t\t\treturn NULL;\n\n\t\tmutex_unlock(&xt[af].mutex);\n\t\tif (t->table_init(net) != 0) {\n\t\t\tmodule_put(t->me);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tfound = t;\n\n\t\tmutex_lock(&xt[af].mutex);\n\t\tbreak;\n\t}\n\n\tif (!found)\n\t\tgoto out;\n\n\t/* and once again: */\n\tlist_for_each_entry(t, &net->xt.tables[af], list)\n\t\tif (strcmp(t->name, name) == 0)\n\t\t\treturn t;\n\n\tmodule_put(found->me);\n out:\n\tmutex_unlock(&xt[af].mutex);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(xt_find_table_lock);\n\nvoid xt_table_unlock(struct xt_table *table)\n{\n\tmutex_unlock(&xt[table->af].mutex);\n}\nEXPORT_SYMBOL_GPL(xt_table_unlock);\n\n#ifdef CONFIG_COMPAT\nvoid xt_compat_lock(u_int8_t af)\n{\n\tmutex_lock(&xt[af].compat_mutex);\n}\nEXPORT_SYMBOL_GPL(xt_compat_lock);\n\nvoid xt_compat_unlock(u_int8_t af)\n{\n\tmutex_unlock(&xt[af].compat_mutex);\n}\nEXPORT_SYMBOL_GPL(xt_compat_unlock);\n#endif\n\nDEFINE_PER_CPU(seqcount_t, xt_recseq);\nEXPORT_PER_CPU_SYMBOL_GPL(xt_recseq);\n\nstruct static_key xt_tee_enabled __read_mostly;\nEXPORT_SYMBOL_GPL(xt_tee_enabled);\n\nstatic int xt_jumpstack_alloc(struct xt_table_info *i)\n{\n\tunsigned int size;\n\tint cpu;\n\n\tsize = sizeof(void **) * nr_cpu_ids;\n\tif (size > PAGE_SIZE)\n\t\ti->jumpstack = vzalloc(size);\n\telse\n\t\ti->jumpstack = kzalloc(size, GFP_KERNEL);\n\tif (i->jumpstack == NULL)\n\t\treturn -ENOMEM;\n\n\t/* ruleset without jumps -- no stack needed */\n\tif (i->stacksize == 0)\n\t\treturn 0;\n\n\t/* Jumpstack needs to be able to record two full callchains, one\n\t * from the first rule set traversal, plus one table reentrancy\n\t * via -j TEE without clobbering the callchain that brought us to\n\t * TEE target.\n\t *\n\t * This is done by allocating two jumpstacks per cpu, on reentry\n\t * the upper half of the stack is used.\n\t *\n\t * see the jumpstack setup in ipt_do_table() for more details.\n\t */\n\tsize = sizeof(void *) * i->stacksize * 2u;\n\tfor_each_possible_cpu(cpu) {\n\t\tif (size > PAGE_SIZE)\n\t\t\ti->jumpstack[cpu] = vmalloc_node(size,\n\t\t\t\tcpu_to_node(cpu));\n\t\telse\n\t\t\ti->jumpstack[cpu] = kmalloc_node(size,\n\t\t\t\tGFP_KERNEL, cpu_to_node(cpu));\n\t\tif (i->jumpstack[cpu] == NULL)\n\t\t\t/*\n\t\t\t * Freeing will be done later on by the callers. The\n\t\t\t * chain is: xt_replace_table -> __do_replace ->\n\t\t\t * do_replace -> xt_free_table_info.\n\t\t\t */\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstruct xt_table_info *\nxt_replace_table(struct xt_table *table,\n\t      unsigned int num_counters,\n\t      struct xt_table_info *newinfo,\n\t      int *error)\n{\n\tstruct xt_table_info *private;\n\tint ret;\n\n\tret = xt_jumpstack_alloc(newinfo);\n\tif (ret < 0) {\n\t\t*error = ret;\n\t\treturn NULL;\n\t}\n\n\t/* Do the substitution. */\n\tlocal_bh_disable();\n\tprivate = table->private;\n\n\t/* Check inside lock: is the old number correct? */\n\tif (num_counters != private->number) {\n\t\tpr_debug(\"num_counters != table->private->number (%u/%u)\\n\",\n\t\t\t num_counters, private->number);\n\t\tlocal_bh_enable();\n\t\t*error = -EAGAIN;\n\t\treturn NULL;\n\t}\n\n\tnewinfo->initial_entries = private->initial_entries;\n\t/*\n\t * Ensure contents of newinfo are visible before assigning to\n\t * private.\n\t */\n\tsmp_wmb();\n\ttable->private = newinfo;\n\n\t/*\n\t * Even though table entries have now been swapped, other CPU's\n\t * may still be using the old entries. This is okay, because\n\t * resynchronization happens because of the locking done\n\t * during the get_counters() routine.\n\t */\n\tlocal_bh_enable();\n\n#ifdef CONFIG_AUDIT\n\tif (audit_enabled) {\n\t\tstruct audit_buffer *ab;\n\n\t\tab = audit_log_start(current->audit_context, GFP_KERNEL,\n\t\t\t\t     AUDIT_NETFILTER_CFG);\n\t\tif (ab) {\n\t\t\taudit_log_format(ab, \"table=%s family=%u entries=%u\",\n\t\t\t\t\t table->name, table->af,\n\t\t\t\t\t private->number);\n\t\t\taudit_log_end(ab);\n\t\t}\n\t}\n#endif\n\n\treturn private;\n}\nEXPORT_SYMBOL_GPL(xt_replace_table);\n\nstruct xt_table *xt_register_table(struct net *net,\n\t\t\t\t   const struct xt_table *input_table,\n\t\t\t\t   struct xt_table_info *bootstrap,\n\t\t\t\t   struct xt_table_info *newinfo)\n{\n\tint ret;\n\tstruct xt_table_info *private;\n\tstruct xt_table *t, *table;\n\n\t/* Don't add one object to multiple lists. */\n\ttable = kmemdup(input_table, sizeof(struct xt_table), GFP_KERNEL);\n\tif (!table) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmutex_lock(&xt[table->af].mutex);\n\t/* Don't autoload: we'd eat our tail... */\n\tlist_for_each_entry(t, &net->xt.tables[table->af], list) {\n\t\tif (strcmp(t->name, table->name) == 0) {\n\t\t\tret = -EEXIST;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\t/* Simplifies replace_table code. */\n\ttable->private = bootstrap;\n\n\tif (!xt_replace_table(table, 0, newinfo, &ret))\n\t\tgoto unlock;\n\n\tprivate = table->private;\n\tpr_debug(\"table->private->number = %u\\n\", private->number);\n\n\t/* save number of initial entries */\n\tprivate->initial_entries = private->number;\n\n\tlist_add(&table->list, &net->xt.tables[table->af]);\n\tmutex_unlock(&xt[table->af].mutex);\n\treturn table;\n\nunlock:\n\tmutex_unlock(&xt[table->af].mutex);\n\tkfree(table);\nout:\n\treturn ERR_PTR(ret);\n}\nEXPORT_SYMBOL_GPL(xt_register_table);\n\nvoid *xt_unregister_table(struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\n\tmutex_lock(&xt[table->af].mutex);\n\tprivate = table->private;\n\tlist_del(&table->list);\n\tmutex_unlock(&xt[table->af].mutex);\n\tkfree(table);\n\n\treturn private;\n}\nEXPORT_SYMBOL_GPL(xt_unregister_table);\n\n#ifdef CONFIG_PROC_FS\nstruct xt_names_priv {\n\tstruct seq_net_private p;\n\tu_int8_t af;\n};\nstatic void *xt_table_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tstruct xt_names_priv *priv = seq->private;\n\tstruct net *net = seq_file_net(seq);\n\tu_int8_t af = priv->af;\n\n\tmutex_lock(&xt[af].mutex);\n\treturn seq_list_start(&net->xt.tables[af], *pos);\n}\n\nstatic void *xt_table_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tstruct xt_names_priv *priv = seq->private;\n\tstruct net *net = seq_file_net(seq);\n\tu_int8_t af = priv->af;\n\n\treturn seq_list_next(v, &net->xt.tables[af], pos);\n}\n\nstatic void xt_table_seq_stop(struct seq_file *seq, void *v)\n{\n\tstruct xt_names_priv *priv = seq->private;\n\tu_int8_t af = priv->af;\n\n\tmutex_unlock(&xt[af].mutex);\n}\n\nstatic int xt_table_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct xt_table *table = list_entry(v, struct xt_table, list);\n\n\tif (*table->name)\n\t\tseq_printf(seq, \"%s\\n\", table->name);\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_table_seq_ops = {\n\t.start\t= xt_table_seq_start,\n\t.next\t= xt_table_seq_next,\n\t.stop\t= xt_table_seq_stop,\n\t.show\t= xt_table_seq_show,\n};\n\nstatic int xt_table_open(struct inode *inode, struct file *file)\n{\n\tint ret;\n\tstruct xt_names_priv *priv;\n\n\tret = seq_open_net(inode, file, &xt_table_seq_ops,\n\t\t\t   sizeof(struct xt_names_priv));\n\tif (!ret) {\n\t\tpriv = ((struct seq_file *)file->private_data)->private;\n\t\tpriv->af = (unsigned long)PDE_DATA(inode);\n\t}\n\treturn ret;\n}\n\nstatic const struct file_operations xt_table_ops = {\n\t.owner\t = THIS_MODULE,\n\t.open\t = xt_table_open,\n\t.read\t = seq_read,\n\t.llseek\t = seq_lseek,\n\t.release = seq_release_net,\n};\n\n/*\n * Traverse state for ip{,6}_{tables,matches} for helping crossing\n * the multi-AF mutexes.\n */\nstruct nf_mttg_trav {\n\tstruct list_head *head, *curr;\n\tuint8_t class, nfproto;\n};\n\nenum {\n\tMTTG_TRAV_INIT,\n\tMTTG_TRAV_NFP_UNSPEC,\n\tMTTG_TRAV_NFP_SPEC,\n\tMTTG_TRAV_DONE,\n};\n\nstatic void *xt_mttg_seq_next(struct seq_file *seq, void *v, loff_t *ppos,\n    bool is_target)\n{\n\tstatic const uint8_t next_class[] = {\n\t\t[MTTG_TRAV_NFP_UNSPEC] = MTTG_TRAV_NFP_SPEC,\n\t\t[MTTG_TRAV_NFP_SPEC]   = MTTG_TRAV_DONE,\n\t};\n\tstruct nf_mttg_trav *trav = seq->private;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_INIT:\n\t\ttrav->class = MTTG_TRAV_NFP_UNSPEC;\n\t\tmutex_lock(&xt[NFPROTO_UNSPEC].mutex);\n\t\ttrav->head = trav->curr = is_target ?\n\t\t\t&xt[NFPROTO_UNSPEC].target : &xt[NFPROTO_UNSPEC].match;\n \t\tbreak;\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\t\ttrav->curr = trav->curr->next;\n\t\tif (trav->curr != trav->head)\n\t\t\tbreak;\n\t\tmutex_unlock(&xt[NFPROTO_UNSPEC].mutex);\n\t\tmutex_lock(&xt[trav->nfproto].mutex);\n\t\ttrav->head = trav->curr = is_target ?\n\t\t\t&xt[trav->nfproto].target : &xt[trav->nfproto].match;\n\t\ttrav->class = next_class[trav->class];\n\t\tbreak;\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\ttrav->curr = trav->curr->next;\n\t\tif (trav->curr != trav->head)\n\t\t\tbreak;\n\t\t/* fallthru, _stop will unlock */\n\tdefault:\n\t\treturn NULL;\n\t}\n\n\tif (ppos != NULL)\n\t\t++*ppos;\n\treturn trav;\n}\n\nstatic void *xt_mttg_seq_start(struct seq_file *seq, loff_t *pos,\n    bool is_target)\n{\n\tstruct nf_mttg_trav *trav = seq->private;\n\tunsigned int j;\n\n\ttrav->class = MTTG_TRAV_INIT;\n\tfor (j = 0; j < *pos; ++j)\n\t\tif (xt_mttg_seq_next(seq, NULL, NULL, is_target) == NULL)\n\t\t\treturn NULL;\n\treturn trav;\n}\n\nstatic void xt_mttg_seq_stop(struct seq_file *seq, void *v)\n{\n\tstruct nf_mttg_trav *trav = seq->private;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\t\tmutex_unlock(&xt[NFPROTO_UNSPEC].mutex);\n\t\tbreak;\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tmutex_unlock(&xt[trav->nfproto].mutex);\n\t\tbreak;\n\t}\n}\n\nstatic void *xt_match_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\treturn xt_mttg_seq_start(seq, pos, false);\n}\n\nstatic void *xt_match_seq_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn xt_mttg_seq_next(seq, v, ppos, false);\n}\n\nstatic int xt_match_seq_show(struct seq_file *seq, void *v)\n{\n\tconst struct nf_mttg_trav *trav = seq->private;\n\tconst struct xt_match *match;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tif (trav->curr == trav->head)\n\t\t\treturn 0;\n\t\tmatch = list_entry(trav->curr, struct xt_match, list);\n\t\tif (*match->name)\n\t\t\tseq_printf(seq, \"%s\\n\", match->name);\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_match_seq_ops = {\n\t.start\t= xt_match_seq_start,\n\t.next\t= xt_match_seq_next,\n\t.stop\t= xt_mttg_seq_stop,\n\t.show\t= xt_match_seq_show,\n};\n\nstatic int xt_match_open(struct inode *inode, struct file *file)\n{\n\tstruct nf_mttg_trav *trav;\n\ttrav = __seq_open_private(file, &xt_match_seq_ops, sizeof(*trav));\n\tif (!trav)\n\t\treturn -ENOMEM;\n\n\ttrav->nfproto = (unsigned long)PDE_DATA(inode);\n\treturn 0;\n}\n\nstatic const struct file_operations xt_match_ops = {\n\t.owner\t = THIS_MODULE,\n\t.open\t = xt_match_open,\n\t.read\t = seq_read,\n\t.llseek\t = seq_lseek,\n\t.release = seq_release_private,\n};\n\nstatic void *xt_target_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\treturn xt_mttg_seq_start(seq, pos, true);\n}\n\nstatic void *xt_target_seq_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn xt_mttg_seq_next(seq, v, ppos, true);\n}\n\nstatic int xt_target_seq_show(struct seq_file *seq, void *v)\n{\n\tconst struct nf_mttg_trav *trav = seq->private;\n\tconst struct xt_target *target;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tif (trav->curr == trav->head)\n\t\t\treturn 0;\n\t\ttarget = list_entry(trav->curr, struct xt_target, list);\n\t\tif (*target->name)\n\t\t\tseq_printf(seq, \"%s\\n\", target->name);\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_target_seq_ops = {\n\t.start\t= xt_target_seq_start,\n\t.next\t= xt_target_seq_next,\n\t.stop\t= xt_mttg_seq_stop,\n\t.show\t= xt_target_seq_show,\n};\n\nstatic int xt_target_open(struct inode *inode, struct file *file)\n{\n\tstruct nf_mttg_trav *trav;\n\ttrav = __seq_open_private(file, &xt_target_seq_ops, sizeof(*trav));\n\tif (!trav)\n\t\treturn -ENOMEM;\n\n\ttrav->nfproto = (unsigned long)PDE_DATA(inode);\n\treturn 0;\n}\n\nstatic const struct file_operations xt_target_ops = {\n\t.owner\t = THIS_MODULE,\n\t.open\t = xt_target_open,\n\t.read\t = seq_read,\n\t.llseek\t = seq_lseek,\n\t.release = seq_release_private,\n};\n\n#define FORMAT_TABLES\t\"_tables_names\"\n#define\tFORMAT_MATCHES\t\"_tables_matches\"\n#define FORMAT_TARGETS \t\"_tables_targets\"\n\n#endif /* CONFIG_PROC_FS */\n\n/**\n * xt_hook_ops_alloc - set up hooks for a new table\n * @table:\ttable with metadata needed to set up hooks\n * @fn:\t\tHook function\n *\n * This function will create the nf_hook_ops that the x_table needs\n * to hand to xt_hook_link_net().\n */\nstruct nf_hook_ops *\nxt_hook_ops_alloc(const struct xt_table *table, nf_hookfn *fn)\n{\n\tunsigned int hook_mask = table->valid_hooks;\n\tuint8_t i, num_hooks = hweight32(hook_mask);\n\tuint8_t hooknum;\n\tstruct nf_hook_ops *ops;\n\n\tops = kmalloc(sizeof(*ops) * num_hooks, GFP_KERNEL);\n\tif (ops == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfor (i = 0, hooknum = 0; i < num_hooks && hook_mask != 0;\n\t     hook_mask >>= 1, ++hooknum) {\n\t\tif (!(hook_mask & 1))\n\t\t\tcontinue;\n\t\tops[i].hook     = fn;\n\t\tops[i].pf       = table->af;\n\t\tops[i].hooknum  = hooknum;\n\t\tops[i].priority = table->priority;\n\t\t++i;\n\t}\n\n\treturn ops;\n}\nEXPORT_SYMBOL_GPL(xt_hook_ops_alloc);\n\nint xt_proto_init(struct net *net, u_int8_t af)\n{\n#ifdef CONFIG_PROC_FS\n\tchar buf[XT_FUNCTION_MAXNAMELEN];\n\tstruct proc_dir_entry *proc;\n\tkuid_t root_uid;\n\tkgid_t root_gid;\n#endif\n\n\tif (af >= ARRAY_SIZE(xt_prefix))\n\t\treturn -EINVAL;\n\n\n#ifdef CONFIG_PROC_FS\n\troot_uid = make_kuid(net->user_ns, 0);\n\troot_gid = make_kgid(net->user_ns, 0);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tproc = proc_create_data(buf, 0440, net->proc_net, &xt_table_ops,\n\t\t\t\t(void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tproc = proc_create_data(buf, 0440, net->proc_net, &xt_match_ops,\n\t\t\t\t(void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out_remove_tables;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TARGETS, sizeof(buf));\n\tproc = proc_create_data(buf, 0440, net->proc_net, &xt_target_ops,\n\t\t\t\t(void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out_remove_matches;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n#endif\n\n\treturn 0;\n\n#ifdef CONFIG_PROC_FS\nout_remove_matches:\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\nout_remove_tables:\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\nout:\n\treturn -1;\n#endif\n}\nEXPORT_SYMBOL_GPL(xt_proto_init);\n\nvoid xt_proto_fini(struct net *net, u_int8_t af)\n{\n#ifdef CONFIG_PROC_FS\n\tchar buf[XT_FUNCTION_MAXNAMELEN];\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TARGETS, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n#endif /*CONFIG_PROC_FS*/\n}\nEXPORT_SYMBOL_GPL(xt_proto_fini);\n\nstatic int __net_init xt_net_init(struct net *net)\n{\n\tint i;\n\n\tfor (i = 0; i < NFPROTO_NUMPROTO; i++)\n\t\tINIT_LIST_HEAD(&net->xt.tables[i]);\n\treturn 0;\n}\n\nstatic struct pernet_operations xt_net_ops = {\n\t.init = xt_net_init,\n};\n\nstatic int __init xt_init(void)\n{\n\tunsigned int i;\n\tint rv;\n\n\tfor_each_possible_cpu(i) {\n\t\tseqcount_init(&per_cpu(xt_recseq, i));\n\t}\n\n\txt = kmalloc(sizeof(struct xt_af) * NFPROTO_NUMPROTO, GFP_KERNEL);\n\tif (!xt)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < NFPROTO_NUMPROTO; i++) {\n\t\tmutex_init(&xt[i].mutex);\n#ifdef CONFIG_COMPAT\n\t\tmutex_init(&xt[i].compat_mutex);\n\t\txt[i].compat_tab = NULL;\n#endif\n\t\tINIT_LIST_HEAD(&xt[i].target);\n\t\tINIT_LIST_HEAD(&xt[i].match);\n\t}\n\trv = register_pernet_subsys(&xt_net_ops);\n\tif (rv < 0)\n\t\tkfree(xt);\n\treturn rv;\n}\n\nstatic void __exit xt_fini(void)\n{\n\tunregister_pernet_subsys(&xt_net_ops);\n\tkfree(xt);\n}\n\nmodule_init(xt_init);\nmodule_exit(xt_fini);\n\n"], "fixing_code": ["#ifndef _X_TABLES_H\n#define _X_TABLES_H\n\n\n#include <linux/netdevice.h>\n#include <linux/static_key.h>\n#include <uapi/linux/netfilter/x_tables.h>\n\n/**\n * struct xt_action_param - parameters for matches/targets\n *\n * @match:\tthe match extension\n * @target:\tthe target extension\n * @matchinfo:\tper-match data\n * @targetinfo:\tper-target data\n * @net\t\tnetwork namespace through which the action was invoked\n * @in:\t\tinput netdevice\n * @out:\toutput netdevice\n * @fragoff:\tpacket is a fragment, this is the data offset\n * @thoff:\tposition of transport header relative to skb->data\n * @hook:\thook number given packet came from\n * @family:\tActual NFPROTO_* through which the function is invoked\n * \t\t(helpful when match->family == NFPROTO_UNSPEC)\n *\n * Fields written to by extensions:\n *\n * @hotdrop:\tdrop packet if we had inspection problems\n */\nstruct xt_action_param {\n\tunion {\n\t\tconst struct xt_match *match;\n\t\tconst struct xt_target *target;\n\t};\n\tunion {\n\t\tconst void *matchinfo, *targinfo;\n\t};\n\tstruct net *net;\n\tconst struct net_device *in, *out;\n\tint fragoff;\n\tunsigned int thoff;\n\tunsigned int hooknum;\n\tu_int8_t family;\n\tbool hotdrop;\n};\n\n/**\n * struct xt_mtchk_param - parameters for match extensions'\n * checkentry functions\n *\n * @net:\tnetwork namespace through which the check was invoked\n * @table:\ttable the rule is tried to be inserted into\n * @entryinfo:\tthe family-specific rule data\n * \t\t(struct ipt_ip, ip6t_ip, arpt_arp or (note) ebt_entry)\n * @match:\tstruct xt_match through which this function was invoked\n * @matchinfo:\tper-match data\n * @hook_mask:\tvia which hooks the new rule is reachable\n * Other fields as above.\n */\nstruct xt_mtchk_param {\n\tstruct net *net;\n\tconst char *table;\n\tconst void *entryinfo;\n\tconst struct xt_match *match;\n\tvoid *matchinfo;\n\tunsigned int hook_mask;\n\tu_int8_t family;\n\tbool nft_compat;\n};\n\n/**\n * struct xt_mdtor_param - match destructor parameters\n * Fields as above.\n */\nstruct xt_mtdtor_param {\n\tstruct net *net;\n\tconst struct xt_match *match;\n\tvoid *matchinfo;\n\tu_int8_t family;\n};\n\n/**\n * struct xt_tgchk_param - parameters for target extensions'\n * checkentry functions\n *\n * @entryinfo:\tthe family-specific rule data\n * \t\t(struct ipt_entry, ip6t_entry, arpt_entry, ebt_entry)\n *\n * Other fields see above.\n */\nstruct xt_tgchk_param {\n\tstruct net *net;\n\tconst char *table;\n\tconst void *entryinfo;\n\tconst struct xt_target *target;\n\tvoid *targinfo;\n\tunsigned int hook_mask;\n\tu_int8_t family;\n\tbool nft_compat;\n};\n\n/* Target destructor parameters */\nstruct xt_tgdtor_param {\n\tstruct net *net;\n\tconst struct xt_target *target;\n\tvoid *targinfo;\n\tu_int8_t family;\n};\n\nstruct xt_match {\n\tstruct list_head list;\n\n\tconst char name[XT_EXTENSION_MAXNAMELEN];\n\tu_int8_t revision;\n\n\t/* Return true or false: return FALSE and set *hotdrop = 1 to\n           force immediate packet drop. */\n\t/* Arguments changed since 2.6.9, as this must now handle\n\t   non-linear skb, using skb_header_pointer and\n\t   skb_ip_make_writable. */\n\tbool (*match)(const struct sk_buff *skb,\n\t\t      struct xt_action_param *);\n\n\t/* Called when user tries to insert an entry of this type. */\n\tint (*checkentry)(const struct xt_mtchk_param *);\n\n\t/* Called when entry of this type deleted. */\n\tvoid (*destroy)(const struct xt_mtdtor_param *);\n#ifdef CONFIG_COMPAT\n\t/* Called when userspace align differs from kernel space one */\n\tvoid (*compat_from_user)(void *dst, const void *src);\n\tint (*compat_to_user)(void __user *dst, const void *src);\n#endif\n\t/* Set this to THIS_MODULE if you are a module, otherwise NULL */\n\tstruct module *me;\n\n\tconst char *table;\n\tunsigned int matchsize;\n#ifdef CONFIG_COMPAT\n\tunsigned int compatsize;\n#endif\n\tunsigned int hooks;\n\tunsigned short proto;\n\n\tunsigned short family;\n};\n\n/* Registration hooks for targets. */\nstruct xt_target {\n\tstruct list_head list;\n\n\tconst char name[XT_EXTENSION_MAXNAMELEN];\n\tu_int8_t revision;\n\n\t/* Returns verdict. Argument order changed since 2.6.9, as this\n\t   must now handle non-linear skbs, using skb_copy_bits and\n\t   skb_ip_make_writable. */\n\tunsigned int (*target)(struct sk_buff *skb,\n\t\t\t       const struct xt_action_param *);\n\n\t/* Called when user tries to insert an entry of this type:\n           hook_mask is a bitmask of hooks from which it can be\n           called. */\n\t/* Should return 0 on success or an error code otherwise (-Exxxx). */\n\tint (*checkentry)(const struct xt_tgchk_param *);\n\n\t/* Called when entry of this type deleted. */\n\tvoid (*destroy)(const struct xt_tgdtor_param *);\n#ifdef CONFIG_COMPAT\n\t/* Called when userspace align differs from kernel space one */\n\tvoid (*compat_from_user)(void *dst, const void *src);\n\tint (*compat_to_user)(void __user *dst, const void *src);\n#endif\n\t/* Set this to THIS_MODULE if you are a module, otherwise NULL */\n\tstruct module *me;\n\n\tconst char *table;\n\tunsigned int targetsize;\n#ifdef CONFIG_COMPAT\n\tunsigned int compatsize;\n#endif\n\tunsigned int hooks;\n\tunsigned short proto;\n\n\tunsigned short family;\n};\n\n/* Furniture shopping... */\nstruct xt_table {\n\tstruct list_head list;\n\n\t/* What hooks you will enter on */\n\tunsigned int valid_hooks;\n\n\t/* Man behind the curtain... */\n\tstruct xt_table_info *private;\n\n\t/* Set this to THIS_MODULE if you are a module, otherwise NULL */\n\tstruct module *me;\n\n\tu_int8_t af;\t\t/* address/protocol family */\n\tint priority;\t\t/* hook order */\n\n\t/* called when table is needed in the given netns */\n\tint (*table_init)(struct net *net);\n\n\t/* A unique name... */\n\tconst char name[XT_TABLE_MAXNAMELEN];\n};\n\n#include <linux/netfilter_ipv4.h>\n\n/* The table itself */\nstruct xt_table_info {\n\t/* Size per table */\n\tunsigned int size;\n\t/* Number of entries: FIXME. --RR */\n\tunsigned int number;\n\t/* Initial number of entries. Needed for module usage count */\n\tunsigned int initial_entries;\n\n\t/* Entry points and underflows */\n\tunsigned int hook_entry[NF_INET_NUMHOOKS];\n\tunsigned int underflow[NF_INET_NUMHOOKS];\n\n\t/*\n\t * Number of user chains. Since tables cannot have loops, at most\n\t * @stacksize jumps (number of user chains) can possibly be made.\n\t */\n\tunsigned int stacksize;\n\tvoid ***jumpstack;\n\n\tunsigned char entries[0] __aligned(8);\n};\n\nint xt_register_target(struct xt_target *target);\nvoid xt_unregister_target(struct xt_target *target);\nint xt_register_targets(struct xt_target *target, unsigned int n);\nvoid xt_unregister_targets(struct xt_target *target, unsigned int n);\n\nint xt_register_match(struct xt_match *target);\nvoid xt_unregister_match(struct xt_match *target);\nint xt_register_matches(struct xt_match *match, unsigned int n);\nvoid xt_unregister_matches(struct xt_match *match, unsigned int n);\n\nint xt_check_entry_offsets(const void *base, const char *elems,\n\t\t\t   unsigned int target_offset,\n\t\t\t   unsigned int next_offset);\n\nint xt_check_match(struct xt_mtchk_param *, unsigned int size, u_int8_t proto,\n\t\t   bool inv_proto);\nint xt_check_target(struct xt_tgchk_param *, unsigned int size, u_int8_t proto,\n\t\t    bool inv_proto);\n\nstruct xt_table *xt_register_table(struct net *net,\n\t\t\t\t   const struct xt_table *table,\n\t\t\t\t   struct xt_table_info *bootstrap,\n\t\t\t\t   struct xt_table_info *newinfo);\nvoid *xt_unregister_table(struct xt_table *table);\n\nstruct xt_table_info *xt_replace_table(struct xt_table *table,\n\t\t\t\t       unsigned int num_counters,\n\t\t\t\t       struct xt_table_info *newinfo,\n\t\t\t\t       int *error);\n\nstruct xt_match *xt_find_match(u8 af, const char *name, u8 revision);\nstruct xt_target *xt_find_target(u8 af, const char *name, u8 revision);\nstruct xt_match *xt_request_find_match(u8 af, const char *name, u8 revision);\nstruct xt_target *xt_request_find_target(u8 af, const char *name, u8 revision);\nint xt_find_revision(u8 af, const char *name, u8 revision, int target,\n\t\t     int *err);\n\nstruct xt_table *xt_find_table_lock(struct net *net, u_int8_t af,\n\t\t\t\t    const char *name);\nvoid xt_table_unlock(struct xt_table *t);\n\nint xt_proto_init(struct net *net, u_int8_t af);\nvoid xt_proto_fini(struct net *net, u_int8_t af);\n\nstruct xt_table_info *xt_alloc_table_info(unsigned int size);\nvoid xt_free_table_info(struct xt_table_info *info);\n\n/**\n * xt_recseq - recursive seqcount for netfilter use\n * \n * Packet processing changes the seqcount only if no recursion happened\n * get_counters() can use read_seqcount_begin()/read_seqcount_retry(),\n * because we use the normal seqcount convention :\n * Low order bit set to 1 if a writer is active.\n */\nDECLARE_PER_CPU(seqcount_t, xt_recseq);\n\n/* xt_tee_enabled - true if x_tables needs to handle reentrancy\n *\n * Enabled if current ip(6)tables ruleset has at least one -j TEE rule.\n */\nextern struct static_key xt_tee_enabled;\n\n/**\n * xt_write_recseq_begin - start of a write section\n *\n * Begin packet processing : all readers must wait the end\n * 1) Must be called with preemption disabled\n * 2) softirqs must be disabled too (or we should use this_cpu_add())\n * Returns :\n *  1 if no recursion on this cpu\n *  0 if recursion detected\n */\nstatic inline unsigned int xt_write_recseq_begin(void)\n{\n\tunsigned int addend;\n\n\t/*\n\t * Low order bit of sequence is set if we already\n\t * called xt_write_recseq_begin().\n\t */\n\taddend = (__this_cpu_read(xt_recseq.sequence) + 1) & 1;\n\n\t/*\n\t * This is kind of a write_seqcount_begin(), but addend is 0 or 1\n\t * We dont check addend value to avoid a test and conditional jump,\n\t * since addend is most likely 1\n\t */\n\t__this_cpu_add(xt_recseq.sequence, addend);\n\tsmp_wmb();\n\n\treturn addend;\n}\n\n/**\n * xt_write_recseq_end - end of a write section\n * @addend: return value from previous xt_write_recseq_begin()\n *\n * End packet processing : all readers can proceed\n * 1) Must be called with preemption disabled\n * 2) softirqs must be disabled too (or we should use this_cpu_add())\n */\nstatic inline void xt_write_recseq_end(unsigned int addend)\n{\n\t/* this is kind of a write_seqcount_end(), but addend is 0 or 1 */\n\tsmp_wmb();\n\t__this_cpu_add(xt_recseq.sequence, addend);\n}\n\n/*\n * This helper is performance critical and must be inlined\n */\nstatic inline unsigned long ifname_compare_aligned(const char *_a,\n\t\t\t\t\t\t   const char *_b,\n\t\t\t\t\t\t   const char *_mask)\n{\n\tconst unsigned long *a = (const unsigned long *)_a;\n\tconst unsigned long *b = (const unsigned long *)_b;\n\tconst unsigned long *mask = (const unsigned long *)_mask;\n\tunsigned long ret;\n\n\tret = (a[0] ^ b[0]) & mask[0];\n\tif (IFNAMSIZ > sizeof(unsigned long))\n\t\tret |= (a[1] ^ b[1]) & mask[1];\n\tif (IFNAMSIZ > 2 * sizeof(unsigned long))\n\t\tret |= (a[2] ^ b[2]) & mask[2];\n\tif (IFNAMSIZ > 3 * sizeof(unsigned long))\n\t\tret |= (a[3] ^ b[3]) & mask[3];\n\tBUILD_BUG_ON(IFNAMSIZ > 4 * sizeof(unsigned long));\n\treturn ret;\n}\n\n\n/* On SMP, ip(6)t_entry->counters.pcnt holds address of the\n * real (percpu) counter.  On !SMP, its just the packet count,\n * so nothing needs to be done there.\n *\n * xt_percpu_counter_alloc returns the address of the percpu\n * counter, or 0 on !SMP. We force an alignment of 16 bytes\n * so that bytes/packets share a common cache line.\n *\n * Hence caller must use IS_ERR_VALUE to check for error, this\n * allows us to return 0 for single core systems without forcing\n * callers to deal with SMP vs. NONSMP issues.\n */\nstatic inline u64 xt_percpu_counter_alloc(void)\n{\n\tif (nr_cpu_ids > 1) {\n\t\tvoid __percpu *res = __alloc_percpu(sizeof(struct xt_counters),\n\t\t\t\t\t\t    sizeof(struct xt_counters));\n\n\t\tif (res == NULL)\n\t\t\treturn (u64) -ENOMEM;\n\n\t\treturn (u64) (__force unsigned long) res;\n\t}\n\n\treturn 0;\n}\nstatic inline void xt_percpu_counter_free(u64 pcnt)\n{\n\tif (nr_cpu_ids > 1)\n\t\tfree_percpu((void __percpu *) (unsigned long) pcnt);\n}\n\nstatic inline struct xt_counters *\nxt_get_this_cpu_counter(struct xt_counters *cnt)\n{\n\tif (nr_cpu_ids > 1)\n\t\treturn this_cpu_ptr((void __percpu *) (unsigned long) cnt->pcnt);\n\n\treturn cnt;\n}\n\nstatic inline struct xt_counters *\nxt_get_per_cpu_counter(struct xt_counters *cnt, unsigned int cpu)\n{\n\tif (nr_cpu_ids > 1)\n\t\treturn per_cpu_ptr((void __percpu *) (unsigned long) cnt->pcnt, cpu);\n\n\treturn cnt;\n}\n\nstruct nf_hook_ops *xt_hook_ops_alloc(const struct xt_table *, nf_hookfn *);\n\n#ifdef CONFIG_COMPAT\n#include <net/compat.h>\n\nstruct compat_xt_entry_match {\n\tunion {\n\t\tstruct {\n\t\t\tu_int16_t match_size;\n\t\t\tchar name[XT_FUNCTION_MAXNAMELEN - 1];\n\t\t\tu_int8_t revision;\n\t\t} user;\n\t\tstruct {\n\t\t\tu_int16_t match_size;\n\t\t\tcompat_uptr_t match;\n\t\t} kernel;\n\t\tu_int16_t match_size;\n\t} u;\n\tunsigned char data[0];\n};\n\nstruct compat_xt_entry_target {\n\tunion {\n\t\tstruct {\n\t\t\tu_int16_t target_size;\n\t\t\tchar name[XT_FUNCTION_MAXNAMELEN - 1];\n\t\t\tu_int8_t revision;\n\t\t} user;\n\t\tstruct {\n\t\t\tu_int16_t target_size;\n\t\t\tcompat_uptr_t target;\n\t\t} kernel;\n\t\tu_int16_t target_size;\n\t} u;\n\tunsigned char data[0];\n};\n\n/* FIXME: this works only on 32 bit tasks\n * need to change whole approach in order to calculate align as function of\n * current task alignment */\n\nstruct compat_xt_counters {\n\tcompat_u64 pcnt, bcnt;\t\t\t/* Packet and byte counters */\n};\n\nstruct compat_xt_counters_info {\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tcompat_uint_t num_counters;\n\tstruct compat_xt_counters counters[0];\n};\n\nstruct _compat_xt_align {\n\t__u8 u8;\n\t__u16 u16;\n\t__u32 u32;\n\tcompat_u64 u64;\n};\n\n#define COMPAT_XT_ALIGN(s) __ALIGN_KERNEL((s), __alignof__(struct _compat_xt_align))\n\nvoid xt_compat_lock(u_int8_t af);\nvoid xt_compat_unlock(u_int8_t af);\n\nint xt_compat_add_offset(u_int8_t af, unsigned int offset, int delta);\nvoid xt_compat_flush_offsets(u_int8_t af);\nvoid xt_compat_init_offsets(u_int8_t af, unsigned int number);\nint xt_compat_calc_jump(u_int8_t af, unsigned int offset);\n\nint xt_compat_match_offset(const struct xt_match *match);\nint xt_compat_match_from_user(struct xt_entry_match *m, void **dstptr,\n\t\t\t      unsigned int *size);\nint xt_compat_match_to_user(const struct xt_entry_match *m,\n\t\t\t    void __user **dstptr, unsigned int *size);\n\nint xt_compat_target_offset(const struct xt_target *target);\nvoid xt_compat_target_from_user(struct xt_entry_target *t, void **dstptr,\n\t\t\t\tunsigned int *size);\nint xt_compat_target_to_user(const struct xt_entry_target *t,\n\t\t\t     void __user **dstptr, unsigned int *size);\nint xt_compat_check_entry_offsets(const void *base, const char *elems,\n\t\t\t\t  unsigned int target_offset,\n\t\t\t\t  unsigned int next_offset);\n\n#endif /* CONFIG_COMPAT */\n#endif /* _X_TABLES_H */\n", "/*\n * Packet matching code for ARP packets.\n *\n * Based heavily, if not almost entirely, upon ip_tables.c framework.\n *\n * Some ARP specific bits are:\n *\n * Copyright (C) 2002 David S. Miller (davem@redhat.com)\n * Copyright (C) 2006-2009 Patrick McHardy <kaber@trash.net>\n *\n */\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/kernel.h>\n#include <linux/skbuff.h>\n#include <linux/netdevice.h>\n#include <linux/capability.h>\n#include <linux/if_arp.h>\n#include <linux/kmod.h>\n#include <linux/vmalloc.h>\n#include <linux/proc_fs.h>\n#include <linux/module.h>\n#include <linux/init.h>\n#include <linux/mutex.h>\n#include <linux/err.h>\n#include <net/compat.h>\n#include <net/sock.h>\n#include <asm/uaccess.h>\n\n#include <linux/netfilter/x_tables.h>\n#include <linux/netfilter_arp/arp_tables.h>\n#include \"../../netfilter/xt_repldata.h\"\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"David S. Miller <davem@redhat.com>\");\nMODULE_DESCRIPTION(\"arptables core\");\n\n/*#define DEBUG_ARP_TABLES*/\n/*#define DEBUG_ARP_TABLES_USER*/\n\n#ifdef DEBUG_ARP_TABLES\n#define dprintf(format, args...)  pr_debug(format, ## args)\n#else\n#define dprintf(format, args...)\n#endif\n\n#ifdef DEBUG_ARP_TABLES_USER\n#define duprintf(format, args...) pr_debug(format, ## args)\n#else\n#define duprintf(format, args...)\n#endif\n\n#ifdef CONFIG_NETFILTER_DEBUG\n#define ARP_NF_ASSERT(x)\tWARN_ON(!(x))\n#else\n#define ARP_NF_ASSERT(x)\n#endif\n\nvoid *arpt_alloc_initial_table(const struct xt_table *info)\n{\n\treturn xt_alloc_initial_table(arpt, ARPT);\n}\nEXPORT_SYMBOL_GPL(arpt_alloc_initial_table);\n\nstatic inline int arp_devaddr_compare(const struct arpt_devaddr_info *ap,\n\t\t\t\t      const char *hdr_addr, int len)\n{\n\tint i, ret;\n\n\tif (len > ARPT_DEV_ADDR_LEN_MAX)\n\t\tlen = ARPT_DEV_ADDR_LEN_MAX;\n\n\tret = 0;\n\tfor (i = 0; i < len; i++)\n\t\tret |= (hdr_addr[i] ^ ap->addr[i]) & ap->mask[i];\n\n\treturn ret != 0;\n}\n\n/*\n * Unfortunately, _b and _mask are not aligned to an int (or long int)\n * Some arches dont care, unrolling the loop is a win on them.\n * For other arches, we only have a 16bit alignement.\n */\nstatic unsigned long ifname_compare(const char *_a, const char *_b, const char *_mask)\n{\n#ifdef CONFIG_HAVE_EFFICIENT_UNALIGNED_ACCESS\n\tunsigned long ret = ifname_compare_aligned(_a, _b, _mask);\n#else\n\tunsigned long ret = 0;\n\tconst u16 *a = (const u16 *)_a;\n\tconst u16 *b = (const u16 *)_b;\n\tconst u16 *mask = (const u16 *)_mask;\n\tint i;\n\n\tfor (i = 0; i < IFNAMSIZ/sizeof(u16); i++)\n\t\tret |= (a[i] ^ b[i]) & mask[i];\n#endif\n\treturn ret;\n}\n\n/* Returns whether packet matches rule or not. */\nstatic inline int arp_packet_match(const struct arphdr *arphdr,\n\t\t\t\t   struct net_device *dev,\n\t\t\t\t   const char *indev,\n\t\t\t\t   const char *outdev,\n\t\t\t\t   const struct arpt_arp *arpinfo)\n{\n\tconst char *arpptr = (char *)(arphdr + 1);\n\tconst char *src_devaddr, *tgt_devaddr;\n\t__be32 src_ipaddr, tgt_ipaddr;\n\tlong ret;\n\n#define FWINV(bool, invflg) ((bool) ^ !!(arpinfo->invflags & (invflg)))\n\n\tif (FWINV((arphdr->ar_op & arpinfo->arpop_mask) != arpinfo->arpop,\n\t\t  ARPT_INV_ARPOP)) {\n\t\tdprintf(\"ARP operation field mismatch.\\n\");\n\t\tdprintf(\"ar_op: %04x info->arpop: %04x info->arpop_mask: %04x\\n\",\n\t\t\tarphdr->ar_op, arpinfo->arpop, arpinfo->arpop_mask);\n\t\treturn 0;\n\t}\n\n\tif (FWINV((arphdr->ar_hrd & arpinfo->arhrd_mask) != arpinfo->arhrd,\n\t\t  ARPT_INV_ARPHRD)) {\n\t\tdprintf(\"ARP hardware address format mismatch.\\n\");\n\t\tdprintf(\"ar_hrd: %04x info->arhrd: %04x info->arhrd_mask: %04x\\n\",\n\t\t\tarphdr->ar_hrd, arpinfo->arhrd, arpinfo->arhrd_mask);\n\t\treturn 0;\n\t}\n\n\tif (FWINV((arphdr->ar_pro & arpinfo->arpro_mask) != arpinfo->arpro,\n\t\t  ARPT_INV_ARPPRO)) {\n\t\tdprintf(\"ARP protocol address format mismatch.\\n\");\n\t\tdprintf(\"ar_pro: %04x info->arpro: %04x info->arpro_mask: %04x\\n\",\n\t\t\tarphdr->ar_pro, arpinfo->arpro, arpinfo->arpro_mask);\n\t\treturn 0;\n\t}\n\n\tif (FWINV((arphdr->ar_hln & arpinfo->arhln_mask) != arpinfo->arhln,\n\t\t  ARPT_INV_ARPHLN)) {\n\t\tdprintf(\"ARP hardware address length mismatch.\\n\");\n\t\tdprintf(\"ar_hln: %02x info->arhln: %02x info->arhln_mask: %02x\\n\",\n\t\t\tarphdr->ar_hln, arpinfo->arhln, arpinfo->arhln_mask);\n\t\treturn 0;\n\t}\n\n\tsrc_devaddr = arpptr;\n\tarpptr += dev->addr_len;\n\tmemcpy(&src_ipaddr, arpptr, sizeof(u32));\n\tarpptr += sizeof(u32);\n\ttgt_devaddr = arpptr;\n\tarpptr += dev->addr_len;\n\tmemcpy(&tgt_ipaddr, arpptr, sizeof(u32));\n\n\tif (FWINV(arp_devaddr_compare(&arpinfo->src_devaddr, src_devaddr, dev->addr_len),\n\t\t  ARPT_INV_SRCDEVADDR) ||\n\t    FWINV(arp_devaddr_compare(&arpinfo->tgt_devaddr, tgt_devaddr, dev->addr_len),\n\t\t  ARPT_INV_TGTDEVADDR)) {\n\t\tdprintf(\"Source or target device address mismatch.\\n\");\n\n\t\treturn 0;\n\t}\n\n\tif (FWINV((src_ipaddr & arpinfo->smsk.s_addr) != arpinfo->src.s_addr,\n\t\t  ARPT_INV_SRCIP) ||\n\t    FWINV(((tgt_ipaddr & arpinfo->tmsk.s_addr) != arpinfo->tgt.s_addr),\n\t\t  ARPT_INV_TGTIP)) {\n\t\tdprintf(\"Source or target IP address mismatch.\\n\");\n\n\t\tdprintf(\"SRC: %pI4. Mask: %pI4. Target: %pI4.%s\\n\",\n\t\t\t&src_ipaddr,\n\t\t\t&arpinfo->smsk.s_addr,\n\t\t\t&arpinfo->src.s_addr,\n\t\t\tarpinfo->invflags & ARPT_INV_SRCIP ? \" (INV)\" : \"\");\n\t\tdprintf(\"TGT: %pI4 Mask: %pI4 Target: %pI4.%s\\n\",\n\t\t\t&tgt_ipaddr,\n\t\t\t&arpinfo->tmsk.s_addr,\n\t\t\t&arpinfo->tgt.s_addr,\n\t\t\tarpinfo->invflags & ARPT_INV_TGTIP ? \" (INV)\" : \"\");\n\t\treturn 0;\n\t}\n\n\t/* Look for ifname matches.  */\n\tret = ifname_compare(indev, arpinfo->iniface, arpinfo->iniface_mask);\n\n\tif (FWINV(ret != 0, ARPT_INV_VIA_IN)) {\n\t\tdprintf(\"VIA in mismatch (%s vs %s).%s\\n\",\n\t\t\tindev, arpinfo->iniface,\n\t\t\tarpinfo->invflags & ARPT_INV_VIA_IN ? \" (INV)\" : \"\");\n\t\treturn 0;\n\t}\n\n\tret = ifname_compare(outdev, arpinfo->outiface, arpinfo->outiface_mask);\n\n\tif (FWINV(ret != 0, ARPT_INV_VIA_OUT)) {\n\t\tdprintf(\"VIA out mismatch (%s vs %s).%s\\n\",\n\t\t\toutdev, arpinfo->outiface,\n\t\t\tarpinfo->invflags & ARPT_INV_VIA_OUT ? \" (INV)\" : \"\");\n\t\treturn 0;\n\t}\n\n\treturn 1;\n#undef FWINV\n}\n\nstatic inline int arp_checkentry(const struct arpt_arp *arp)\n{\n\tif (arp->flags & ~ARPT_F_MASK) {\n\t\tduprintf(\"Unknown flag bits set: %08X\\n\",\n\t\t\t arp->flags & ~ARPT_F_MASK);\n\t\treturn 0;\n\t}\n\tif (arp->invflags & ~ARPT_INV_MASK) {\n\t\tduprintf(\"Unknown invflag bits set: %08X\\n\",\n\t\t\t arp->invflags & ~ARPT_INV_MASK);\n\t\treturn 0;\n\t}\n\n\treturn 1;\n}\n\nstatic unsigned int\narpt_error(struct sk_buff *skb, const struct xt_action_param *par)\n{\n\tnet_err_ratelimited(\"arp_tables: error: '%s'\\n\",\n\t\t\t    (const char *)par->targinfo);\n\n\treturn NF_DROP;\n}\n\nstatic inline const struct xt_entry_target *\narpt_get_target_c(const struct arpt_entry *e)\n{\n\treturn arpt_get_target((struct arpt_entry *)e);\n}\n\nstatic inline struct arpt_entry *\nget_entry(const void *base, unsigned int offset)\n{\n\treturn (struct arpt_entry *)(base + offset);\n}\n\nstatic inline\nstruct arpt_entry *arpt_next_entry(const struct arpt_entry *entry)\n{\n\treturn (void *)entry + entry->next_offset;\n}\n\nunsigned int arpt_do_table(struct sk_buff *skb,\n\t\t\t   const struct nf_hook_state *state,\n\t\t\t   struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\tunsigned int verdict = NF_DROP;\n\tconst struct arphdr *arp;\n\tstruct arpt_entry *e, **jumpstack;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tunsigned int cpu, stackidx = 0;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\tif (!pskb_may_pull(skb, arp_hdr_len(skb->dev)))\n\t\treturn NF_DROP;\n\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = table->private;\n\tcpu     = smp_processor_id();\n\t/*\n\t * Ensure we load private-> members after we've fetched the base\n\t * pointer.\n\t */\n\tsmp_read_barrier_depends();\n\ttable_base = private->entries;\n\tjumpstack  = (struct arpt_entry **)private->jumpstack[cpu];\n\n\t/* No TEE support for arptables, so no need to switch to alternate\n\t * stack.  All targets that reenter must return absolute verdicts.\n\t */\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tacpar.net     = state->net;\n\tacpar.in      = state->in;\n\tacpar.out     = state->out;\n\tacpar.hooknum = hook;\n\tacpar.family  = NFPROTO_ARP;\n\tacpar.hotdrop = false;\n\n\tarp = arp_hdr(skb);\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tstruct xt_counters *counter;\n\n\t\tif (!arp_packet_match(arp, skb->dev, indev, outdev, &e->arp)) {\n\t\t\te = arpt_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, arp_hdr_len(skb->dev), 1);\n\n\t\tt = arpt_get_target_c(e);\n\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0) {\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t\t      private->underflow[hook]);\n\t\t\t\t} else {\n\t\t\t\t\te = jumpstack[--stackidx];\n\t\t\t\t\te = arpt_next_entry(e);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v\n\t\t\t    != arpt_next_entry(e)) {\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\n\t\t/* Target might have changed stuff. */\n\t\tarp = arp_hdr(skb);\n\n\t\tif (verdict == XT_CONTINUE)\n\t\t\te = arpt_next_entry(e);\n\t\telse\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t} while (!acpar.hotdrop);\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse\n\t\treturn verdict;\n}\n\n/* All zeroes == unconditional rule. */\nstatic inline bool unconditional(const struct arpt_entry *e)\n{\n\tstatic const struct arpt_arp uncond;\n\n\treturn e->target_offset == sizeof(struct arpt_entry) &&\n\t       memcmp(&e->arp, &uncond, sizeof(uncond)) == 0;\n}\n\nstatic bool find_jump_target(const struct xt_table_info *t,\n\t\t\t     const struct arpt_entry *target)\n{\n\tstruct arpt_entry *iter;\n\n\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t if (iter == target)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n/* Figures out from what hook each rule can be called: returns 0 if\n * there are loops.  Puts hook bitmask in comefrom.\n */\nstatic int mark_source_chains(const struct xt_table_info *newinfo,\n\t\t\t      unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t * to 0 as we leave), and comefrom to save source hook bitmask.\n\t */\n\tfor (hook = 0; hook < NF_ARP_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct arpt_entry *e\n\t\t\t= (struct arpt_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)arpt_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_ARP_NUMHOOKS)) {\n\t\t\t\tpr_notice(\"arptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom\n\t\t\t\t|= ((1 << hook) | (1 << NF_ARP_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t * big jump.\n\t\t\t\t */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_ARP_NUMHOOKS);\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\tif (pos + size >= newinfo->size)\n\t\t\t\t\treturn 0;\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct arpt_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t\t(entry0 + newpos);\n\t\t\t\t\tif (!find_jump_target(newinfo, e))\n\t\t\t\t\t\treturn 0;\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t\tif (newpos >= newinfo->size)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\te = (struct arpt_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}\n\nstatic inline int check_target(struct arpt_entry *e, const char *name)\n{\n\tstruct xt_entry_target *t = arpt_get_target(e);\n\tint ret;\n\tstruct xt_tgchk_param par = {\n\t\t.table     = name,\n\t\t.entryinfo = e,\n\t\t.target    = t->u.kernel.target,\n\t\t.targinfo  = t->data,\n\t\t.hook_mask = e->comefrom,\n\t\t.family    = NFPROTO_ARP,\n\t};\n\n\tret = xt_check_target(&par, t->u.target_size - sizeof(*t), 0, false);\n\tif (ret < 0) {\n\t\tduprintf(\"arp_tables: check failed for `%s'.\\n\",\n\t\t\t t->u.kernel.target->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic inline int\nfind_check_entry(struct arpt_entry *e, const char *name, unsigned int size)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tint ret;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\n\tt = arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"find_check_entry: `%s' not found\\n\", t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\tret = check_target(e, name);\n\tif (ret)\n\t\tgoto err;\n\treturn 0;\nerr:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic bool check_underflow(const struct arpt_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = arpt_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n\nstatic inline int check_entry_size_and_hooks(struct arpt_entry *e,\n\t\t\t\t\t     struct xt_table_info *newinfo,\n\t\t\t\t\t     const unsigned char *base,\n\t\t\t\t\t     const unsigned char *limit,\n\t\t\t\t\t     const unsigned int *hook_entries,\n\t\t\t\t\t     const unsigned int *underflows,\n\t\t\t\t\t     unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct arpt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}\n\nstatic inline void cleanup_entry(struct arpt_entry *e)\n{\n\tstruct xt_tgdtor_param par;\n\tstruct xt_entry_target *t;\n\n\tt = arpt_get_target(e);\n\tpar.target   = t->u.kernel.target;\n\tpar.targinfo = t->data;\n\tpar.family   = NFPROTO_ARP;\n\tif (par.target->destroy != NULL)\n\t\tpar.target->destroy(&par);\n\tmodule_put(par.target->me);\n\txt_percpu_counter_free(e->counters.pcnt);\n}\n\n/* Checks and translates the user-supplied table segment (held in\n * newinfo).\n */\nstatic int translate_table(struct xt_table_info *newinfo, void *entry0,\n\t\t\t   const struct arpt_replace *repl)\n{\n\tstruct arpt_entry *iter;\n\tunsigned int i;\n\tint ret = 0;\n\n\tnewinfo->size = repl->size;\n\tnewinfo->number = repl->num_entries;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tnewinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_table: size %u\\n\", newinfo->size);\n\ti = 0;\n\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = check_entry_size_and_hooks(iter, newinfo, entry0,\n\t\t\t\t\t\t entry0 + repl->size,\n\t\t\t\t\t\t repl->hook_entry,\n\t\t\t\t\t\t repl->underflow,\n\t\t\t\t\t\t repl->valid_hooks);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t\tif (strcmp(arpt_get_target(iter)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\tduprintf(\"translate_table: ARPT_ENTRY_ITERATE gives %d\\n\", ret);\n\tif (ret != 0)\n\t\treturn ret;\n\n\tif (i != repl->num_entries) {\n\t\tduprintf(\"translate_table: %u not %u entries\\n\",\n\t\t\t i, repl->num_entries);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(repl->valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (newinfo->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, repl->hook_entry[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (newinfo->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, repl->underflow[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!mark_source_chains(newinfo, repl->valid_hooks, entry0))\n\t\treturn -ELOOP;\n\n\t/* Finally, each sanity check must pass */\n\ti = 0;\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = find_check_entry(iter, repl->name, repl->size);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t}\n\n\tif (ret != 0) {\n\t\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter);\n\t\t}\n\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic void get_counters(const struct xt_table_info *t,\n\t\t\t struct xt_counters counters[])\n{\n\tstruct arpt_entry *iter;\n\tunsigned int cpu;\n\tunsigned int i;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tseqcount_t *s = &per_cpu(xt_recseq, cpu);\n\n\t\ti = 0;\n\t\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t\tstruct xt_counters *tmp;\n\t\t\tu64 bcnt, pcnt;\n\t\t\tunsigned int start;\n\n\t\t\ttmp = xt_get_per_cpu_counter(&iter->counters, cpu);\n\t\t\tdo {\n\t\t\t\tstart = read_seqcount_begin(s);\n\t\t\t\tbcnt = tmp->bcnt;\n\t\t\t\tpcnt = tmp->pcnt;\n\t\t\t} while (read_seqcount_retry(s, start));\n\n\t\t\tADD_COUNTER(counters[i], bcnt, pcnt);\n\t\t\t++i;\n\t\t}\n\t}\n}\n\nstatic struct xt_counters *alloc_counters(const struct xt_table *table)\n{\n\tunsigned int countersize;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\n\t/* We need atomic snapshot of counters: rest doesn't change\n\t * (other than comefrom, which userspace doesn't care\n\t * about).\n\t */\n\tcountersize = sizeof(struct xt_counters) * private->number;\n\tcounters = vzalloc(countersize);\n\n\tif (counters == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tget_counters(private, counters);\n\n\treturn counters;\n}\n\nstatic int copy_entries_to_user(unsigned int total_size,\n\t\t\t\tconst struct xt_table *table,\n\t\t\t\tvoid __user *userptr)\n{\n\tunsigned int off, num;\n\tconst struct arpt_entry *e;\n\tstruct xt_counters *counters;\n\tstruct xt_table_info *private = table->private;\n\tint ret = 0;\n\tvoid *loc_cpu_entry;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tloc_cpu_entry = private->entries;\n\t/* ... then copy entire thing ... */\n\tif (copy_to_user(userptr, loc_cpu_entry, total_size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_counters;\n\t}\n\n\t/* FIXME: use iterator macros --RR */\n\t/* ... then go back and fix counters and names */\n\tfor (off = 0, num = 0; off < total_size; off += e->next_offset, num++){\n\t\tconst struct xt_entry_target *t;\n\n\t\te = (struct arpt_entry *)(loc_cpu_entry + off);\n\t\tif (copy_to_user(userptr + off\n\t\t\t\t + offsetof(struct arpt_entry, counters),\n\t\t\t\t &counters[num],\n\t\t\t\t sizeof(counters[num])) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\n\t\tt = arpt_get_target_c(e);\n\t\tif (copy_to_user(userptr + off + e->target_offset\n\t\t\t\t + offsetof(struct xt_entry_target,\n\t\t\t\t\t    u.user.name),\n\t\t\t\t t->u.kernel.target->name,\n\t\t\t\t strlen(t->u.kernel.target->name)+1) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\t}\n\n free_counters:\n\tvfree(counters);\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic void compat_standard_from_user(void *dst, const void *src)\n{\n\tint v = *(compat_int_t *)src;\n\n\tif (v > 0)\n\t\tv += xt_compat_calc_jump(NFPROTO_ARP, v);\n\tmemcpy(dst, &v, sizeof(v));\n}\n\nstatic int compat_standard_to_user(void __user *dst, const void *src)\n{\n\tcompat_int_t cv = *(int *)src;\n\n\tif (cv > 0)\n\t\tcv -= xt_compat_calc_jump(NFPROTO_ARP, cv);\n\treturn copy_to_user(dst, &cv, sizeof(cv)) ? -EFAULT : 0;\n}\n\nstatic int compat_calc_entry(const struct arpt_entry *e,\n\t\t\t     const struct xt_table_info *info,\n\t\t\t     const void *base, struct xt_table_info *newinfo)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int entry_offset;\n\tint off, i, ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - base;\n\n\tt = arpt_get_target_c(e);\n\toff += xt_compat_target_offset(t->u.kernel.target);\n\tnewinfo->size -= off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tif (info->hook_entry[i] &&\n\t\t    (e < (struct arpt_entry *)(base + info->hook_entry[i])))\n\t\t\tnewinfo->hook_entry[i] -= off;\n\t\tif (info->underflow[i] &&\n\t\t    (e < (struct arpt_entry *)(base + info->underflow[i])))\n\t\t\tnewinfo->underflow[i] -= off;\n\t}\n\treturn 0;\n}\n\nstatic int compat_table_info(const struct xt_table_info *info,\n\t\t\t     struct xt_table_info *newinfo)\n{\n\tstruct arpt_entry *iter;\n\tconst void *loc_cpu_entry;\n\tint ret;\n\n\tif (!newinfo || !info)\n\t\treturn -EINVAL;\n\n\t/* we dont care about newinfo->entries */\n\tmemcpy(newinfo, info, offsetof(struct xt_table_info, entries));\n\tnewinfo->initial_entries = 0;\n\tloc_cpu_entry = info->entries;\n\txt_compat_init_offsets(NFPROTO_ARP, info->number);\n\txt_entry_foreach(iter, loc_cpu_entry, info->size) {\n\t\tret = compat_calc_entry(iter, info, loc_cpu_entry, newinfo);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n#endif\n\nstatic int get_info(struct net *net, void __user *user,\n\t\t    const int *len, int compat)\n{\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tstruct xt_table *t;\n\tint ret;\n\n\tif (*len != sizeof(struct arpt_getinfo)) {\n\t\tduprintf(\"length %u != %Zu\\n\", *len,\n\t\t\t sizeof(struct arpt_getinfo));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(name, user, sizeof(name)) != 0)\n\t\treturn -EFAULT;\n\n\tname[XT_TABLE_MAXNAMELEN-1] = '\\0';\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_lock(NFPROTO_ARP);\n#endif\n\tt = try_then_request_module(xt_find_table_lock(net, NFPROTO_ARP, name),\n\t\t\t\t    \"arptable_%s\", name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tstruct arpt_getinfo info;\n\t\tconst struct xt_table_info *private = t->private;\n#ifdef CONFIG_COMPAT\n\t\tstruct xt_table_info tmp;\n\n\t\tif (compat) {\n\t\t\tret = compat_table_info(private, &tmp);\n\t\t\txt_compat_flush_offsets(NFPROTO_ARP);\n\t\t\tprivate = &tmp;\n\t\t}\n#endif\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.valid_hooks = t->valid_hooks;\n\t\tmemcpy(info.hook_entry, private->hook_entry,\n\t\t       sizeof(info.hook_entry));\n\t\tmemcpy(info.underflow, private->underflow,\n\t\t       sizeof(info.underflow));\n\t\tinfo.num_entries = private->number;\n\t\tinfo.size = private->size;\n\t\tstrcpy(info.name, name);\n\n\t\tif (copy_to_user(user, &info, *len) != 0)\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = 0;\n\t\txt_table_unlock(t);\n\t\tmodule_put(t->me);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_unlock(NFPROTO_ARP);\n#endif\n\treturn ret;\n}\n\nstatic int get_entries(struct net *net, struct arpt_get_entries __user *uptr,\n\t\t       const int *len)\n{\n\tint ret;\n\tstruct arpt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"get_entries: %u < %Zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct arpt_get_entries) + get.size) {\n\t\tduprintf(\"get_entries: %u != %Zu\\n\", *len,\n\t\t\t sizeof(struct arpt_get_entries) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, NFPROTO_ARP, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\n\t\tduprintf(\"t->private->number = %u\\n\",\n\t\t\t private->number);\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse {\n\t\t\tduprintf(\"get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\treturn ret;\n}\n\nstatic int __do_replace(struct net *net, const char *name,\n\t\t\tunsigned int valid_hooks,\n\t\t\tstruct xt_table_info *newinfo,\n\t\t\tunsigned int num_counters,\n\t\t\tvoid __user *counters_ptr)\n{\n\tint ret;\n\tstruct xt_table *t;\n\tstruct xt_table_info *oldinfo;\n\tstruct xt_counters *counters;\n\tvoid *loc_cpu_old_entry;\n\tstruct arpt_entry *iter;\n\n\tret = 0;\n\tcounters = vzalloc(num_counters * sizeof(struct xt_counters));\n\tif (!counters) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tt = try_then_request_module(xt_find_table_lock(net, NFPROTO_ARP, name),\n\t\t\t\t    \"arptable_%s\", name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free_newinfo_counters_untrans;\n\t}\n\n\t/* You lied! */\n\tif (valid_hooks != t->valid_hooks) {\n\t\tduprintf(\"Valid hook crap: %08X vs %08X\\n\",\n\t\t\t valid_hooks, t->valid_hooks);\n\t\tret = -EINVAL;\n\t\tgoto put_module;\n\t}\n\n\toldinfo = xt_replace_table(t, num_counters, newinfo, &ret);\n\tif (!oldinfo)\n\t\tgoto put_module;\n\n\t/* Update module usage count based on number of rules */\n\tduprintf(\"do_replace: oldnum=%u, initnum=%u, newnum=%u\\n\",\n\t\toldinfo->number, oldinfo->initial_entries, newinfo->number);\n\tif ((oldinfo->number > oldinfo->initial_entries) ||\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\tif ((oldinfo->number > oldinfo->initial_entries) &&\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\n\t/* Get the old counters, and synchronize with replace */\n\tget_counters(oldinfo, counters);\n\n\t/* Decrease module usage counts and free resource */\n\tloc_cpu_old_entry = oldinfo->entries;\n\txt_entry_foreach(iter, loc_cpu_old_entry, oldinfo->size)\n\t\tcleanup_entry(iter);\n\n\txt_free_table_info(oldinfo);\n\tif (copy_to_user(counters_ptr, counters,\n\t\t\t sizeof(struct xt_counters) * num_counters) != 0) {\n\t\t/* Silent error, can't fail, new table is already in place */\n\t\tnet_warn_ratelimited(\"arptables: counters copy to user failed while replacing table\\n\");\n\t}\n\tvfree(counters);\n\txt_table_unlock(t);\n\treturn ret;\n\n put_module:\n\tmodule_put(t->me);\n\txt_table_unlock(t);\n free_newinfo_counters_untrans:\n\tvfree(counters);\n out:\n\treturn ret;\n}\n\nstatic int do_replace(struct net *net, const void __user *user,\n\t\t      unsigned int len)\n{\n\tint ret;\n\tstruct arpt_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct arpt_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_table(newinfo, loc_cpu_entry, &tmp);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"arp_tables: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, tmp.counters);\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int do_add_counters(struct net *net, const void __user *user,\n\t\t\t   unsigned int len, int compat)\n{\n\tunsigned int i;\n\tstruct xt_counters_info tmp;\n\tstruct xt_counters *paddc;\n\tunsigned int num_counters;\n\tconst char *name;\n\tint size;\n\tvoid *ptmp;\n\tstruct xt_table *t;\n\tconst struct xt_table_info *private;\n\tint ret = 0;\n\tstruct arpt_entry *iter;\n\tunsigned int addend;\n#ifdef CONFIG_COMPAT\n\tstruct compat_xt_counters_info compat_tmp;\n\n\tif (compat) {\n\t\tptmp = &compat_tmp;\n\t\tsize = sizeof(struct compat_xt_counters_info);\n\t} else\n#endif\n\t{\n\t\tptmp = &tmp;\n\t\tsize = sizeof(struct xt_counters_info);\n\t}\n\n\tif (copy_from_user(ptmp, user, size) != 0)\n\t\treturn -EFAULT;\n\n#ifdef CONFIG_COMPAT\n\tif (compat) {\n\t\tnum_counters = compat_tmp.num_counters;\n\t\tname = compat_tmp.name;\n\t} else\n#endif\n\t{\n\t\tnum_counters = tmp.num_counters;\n\t\tname = tmp.name;\n\t}\n\n\tif (len != size + num_counters * sizeof(struct xt_counters))\n\t\treturn -EINVAL;\n\n\tpaddc = vmalloc(len - size);\n\tif (!paddc)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(paddc, user + size, len - size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free;\n\t}\n\n\tt = xt_find_table_lock(net, NFPROTO_ARP, name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free;\n\t}\n\n\tlocal_bh_disable();\n\tprivate = t->private;\n\tif (private->number != num_counters) {\n\t\tret = -EINVAL;\n\t\tgoto unlock_up_free;\n\t}\n\n\ti = 0;\n\n\taddend = xt_write_recseq_begin();\n\txt_entry_foreach(iter,  private->entries, private->size) {\n\t\tstruct xt_counters *tmp;\n\n\t\ttmp = xt_get_this_cpu_counter(&iter->counters);\n\t\tADD_COUNTER(*tmp, paddc[i].bcnt, paddc[i].pcnt);\n\t\t++i;\n\t}\n\txt_write_recseq_end(addend);\n unlock_up_free:\n\tlocal_bh_enable();\n\txt_table_unlock(t);\n\tmodule_put(t->me);\n free:\n\tvfree(paddc);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic inline void compat_release_entry(struct compat_arpt_entry *e)\n{\n\tstruct xt_entry_target *t;\n\n\tt = compat_arpt_get_target(e);\n\tmodule_put(t->u.kernel.target->me);\n}\n\nstatic inline int\ncheck_compat_entry_size_and_hooks(struct compat_arpt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_arpt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_arpt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_arpt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!arp_checkentry(&e->arp))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t\t    e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\n\tt = compat_arpt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_ARP, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto out;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(NFPROTO_ARP, entry_offset, off);\n\tif (ret)\n\t\tgoto release_target;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nrelease_target:\n\tmodule_put(t->u.kernel.target->me);\nout:\n\treturn ret;\n}\n\nstatic int\ncompat_copy_entry_from_user(struct compat_arpt_entry *e, void **dstptr,\n\t\t\t    unsigned int *size, const char *name,\n\t\t\t    struct xt_table_info *newinfo, unsigned char *base)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tstruct arpt_entry *de;\n\tunsigned int origsize;\n\tint ret, h;\n\n\tret = 0;\n\torigsize = *size;\n\tde = (struct arpt_entry *)*dstptr;\n\tmemcpy(de, e, sizeof(struct arpt_entry));\n\tmemcpy(&de->counters, &e->counters, sizeof(e->counters));\n\n\t*dstptr += sizeof(struct arpt_entry);\n\t*size += sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\n\tde->target_offset = e->target_offset - (origsize - *size);\n\tt = compat_arpt_get_target(e);\n\ttarget = t->u.kernel.target;\n\txt_compat_target_from_user(t, dstptr, size);\n\n\tde->next_offset = e->next_offset - (origsize - *size);\n\tfor (h = 0; h < NF_ARP_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)de - base < newinfo->hook_entry[h])\n\t\t\tnewinfo->hook_entry[h] -= origsize - *size;\n\t\tif ((unsigned char *)de - base < newinfo->underflow[h])\n\t\t\tnewinfo->underflow[h] -= origsize - *size;\n\t}\n\treturn ret;\n}\n\nstatic int translate_compat_table(const char *name,\n\t\t\t\t  unsigned int valid_hooks,\n\t\t\t\t  struct xt_table_info **pinfo,\n\t\t\t\t  void **pentry0,\n\t\t\t\t  unsigned int total_size,\n\t\t\t\t  unsigned int number,\n\t\t\t\t  unsigned int *hook_entries,\n\t\t\t\t  unsigned int *underflows)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_arpt_entry *iter0;\n\tstruct arpt_entry *iter1;\n\tunsigned int size;\n\tint ret = 0;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = total_size;\n\tinfo->number = number;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_compat_table: size %u\\n\", info->size);\n\tj = 0;\n\txt_compat_lock(NFPROTO_ARP);\n\txt_compat_init_offsets(NFPROTO_ARP, number);\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + total_size,\n\t\t\t\t\t\t\thook_entries,\n\t\t\t\t\t\t\tunderflows,\n\t\t\t\t\t\t\tname);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != number) {\n\t\tduprintf(\"translate_compat_table: %u not %u entries\\n\",\n\t\t\t j, number);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (info->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, hook_entries[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tif (info->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, underflows[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = number;\n\tfor (i = 0; i < NF_ARP_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = info->hook_entry[i];\n\t\tnewinfo->underflow[i] = info->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = total_size;\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = compat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t\t  name, newinfo, entry1);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\txt_compat_flush_offsets(NFPROTO_ARP);\n\txt_compat_unlock(NFPROTO_ARP);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\tret = -ELOOP;\n\tif (!mark_source_chains(newinfo, valid_hooks, entry1))\n\t\tgoto free_newinfo;\n\n\ti = 0;\n\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\titer1->counters.pcnt = xt_percpu_counter_alloc();\n\t\tif (IS_ERR_VALUE(iter1->counters.pcnt)) {\n\t\t\tret = -ENOMEM;\n\t\t\tbreak;\n\t\t}\n\n\t\tret = check_target(iter1, name);\n\t\tif (ret != 0) {\n\t\t\txt_percpu_counter_free(iter1->counters.pcnt);\n\t\t\tbreak;\n\t\t}\n\t\t++i;\n\t\tif (strcmp(arpt_get_target(iter1)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\tif (ret) {\n\t\t/*\n\t\t * The first i matches need cleanup_entry (calls ->destroy)\n\t\t * because they had called ->check already. The other j-i\n\t\t * entries need only release.\n\t\t */\n\t\tint skip = i;\n\t\tj -= i;\n\t\txt_entry_foreach(iter0, entry0, newinfo->size) {\n\t\t\tif (skip-- > 0)\n\t\t\t\tcontinue;\n\t\t\tif (j-- == 0)\n\t\t\t\tbreak;\n\t\t\tcompat_release_entry(iter0);\n\t\t}\n\t\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter1);\n\t\t}\n\t\txt_free_table_info(newinfo);\n\t\treturn ret;\n\t}\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\nout:\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(NFPROTO_ARP);\n\txt_compat_unlock(NFPROTO_ARP);\n\tgoto out;\n}\n\nstruct compat_arpt_replace {\n\tchar\t\t\t\tname[XT_TABLE_MAXNAMELEN];\n\tu32\t\t\t\tvalid_hooks;\n\tu32\t\t\t\tnum_entries;\n\tu32\t\t\t\tsize;\n\tu32\t\t\t\thook_entry[NF_ARP_NUMHOOKS];\n\tu32\t\t\t\tunderflow[NF_ARP_NUMHOOKS];\n\tu32\t\t\t\tnum_counters;\n\tcompat_uptr_t\t\t\tcounters;\n\tstruct compat_arpt_entry\tentries[0];\n};\n\nstatic int compat_do_replace(struct net *net, void __user *user,\n\t\t\t     unsigned int len)\n{\n\tint ret;\n\tstruct compat_arpt_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct arpt_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.size >= INT_MAX / num_possible_cpus())\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp), tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_compat_table(tmp.name, tmp.valid_hooks,\n\t\t\t\t     &newinfo, &loc_cpu_entry, tmp.size,\n\t\t\t\t     tmp.num_entries, tmp.hook_entry,\n\t\t\t\t     tmp.underflow);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"compat_do_replace: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, compat_ptr(tmp.counters));\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int compat_do_arpt_set_ctl(struct sock *sk, int cmd, void __user *user,\n\t\t\t\t  unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase ARPT_SO_SET_REPLACE:\n\t\tret = compat_do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase ARPT_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 1);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_arpt_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int compat_copy_entry_to_user(struct arpt_entry *e, void __user **dstptr,\n\t\t\t\t     compat_uint_t *size,\n\t\t\t\t     struct xt_counters *counters,\n\t\t\t\t     unsigned int i)\n{\n\tstruct xt_entry_target *t;\n\tstruct compat_arpt_entry __user *ce;\n\tu_int16_t target_offset, next_offset;\n\tcompat_uint_t origsize;\n\tint ret;\n\n\torigsize = *size;\n\tce = (struct compat_arpt_entry __user *)*dstptr;\n\tif (copy_to_user(ce, e, sizeof(struct arpt_entry)) != 0 ||\n\t    copy_to_user(&ce->counters, &counters[i],\n\t    sizeof(counters[i])) != 0)\n\t\treturn -EFAULT;\n\n\t*dstptr += sizeof(struct compat_arpt_entry);\n\t*size -= sizeof(struct arpt_entry) - sizeof(struct compat_arpt_entry);\n\n\ttarget_offset = e->target_offset - (origsize - *size);\n\n\tt = arpt_get_target(e);\n\tret = xt_compat_target_to_user(t, dstptr, size);\n\tif (ret)\n\t\treturn ret;\n\tnext_offset = e->next_offset - (origsize - *size);\n\tif (put_user(target_offset, &ce->target_offset) != 0 ||\n\t    put_user(next_offset, &ce->next_offset) != 0)\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int compat_copy_entries_to_user(unsigned int total_size,\n\t\t\t\t       struct xt_table *table,\n\t\t\t\t       void __user *userptr)\n{\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tvoid __user *pos;\n\tunsigned int size;\n\tint ret = 0;\n\tunsigned int i = 0;\n\tstruct arpt_entry *iter;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tpos = userptr;\n\tsize = total_size;\n\txt_entry_foreach(iter, private->entries, total_size) {\n\t\tret = compat_copy_entry_to_user(iter, &pos,\n\t\t\t\t\t\t&size, counters, i++);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\tvfree(counters);\n\treturn ret;\n}\n\nstruct compat_arpt_get_entries {\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tcompat_uint_t size;\n\tstruct compat_arpt_entry entrytable[0];\n};\n\nstatic int compat_get_entries(struct net *net,\n\t\t\t      struct compat_arpt_get_entries __user *uptr,\n\t\t\t      int *len)\n{\n\tint ret;\n\tstruct compat_arpt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"compat_get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct compat_arpt_get_entries) + get.size) {\n\t\tduprintf(\"compat_get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\txt_compat_lock(NFPROTO_ARP);\n\tt = xt_find_table_lock(net, NFPROTO_ARP, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tstruct xt_table_info info;\n\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tret = compat_table_info(private, &info);\n\t\tif (!ret && get.size == info.size) {\n\t\t\tret = compat_copy_entries_to_user(private->size,\n\t\t\t\t\t\t\t  t, uptr->entrytable);\n\t\t} else if (!ret) {\n\t\t\tduprintf(\"compat_get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\txt_compat_flush_offsets(NFPROTO_ARP);\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\txt_compat_unlock(NFPROTO_ARP);\n\treturn ret;\n}\n\nstatic int do_arpt_get_ctl(struct sock *, int, void __user *, int *);\n\nstatic int compat_do_arpt_get_ctl(struct sock *sk, int cmd, void __user *user,\n\t\t\t\t  int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase ARPT_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 1);\n\t\tbreak;\n\tcase ARPT_SO_GET_ENTRIES:\n\t\tret = compat_get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\tdefault:\n\t\tret = do_arpt_get_ctl(sk, cmd, user, len);\n\t}\n\treturn ret;\n}\n#endif\n\nstatic int do_arpt_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase ARPT_SO_SET_REPLACE:\n\t\tret = do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase ARPT_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_arpt_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int do_arpt_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase ARPT_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tcase ARPT_SO_GET_ENTRIES:\n\t\tret = get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase ARPT_SO_GET_REVISION_TARGET: {\n\t\tstruct xt_get_revision rev;\n\n\t\tif (*len != sizeof(rev)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&rev, user, sizeof(rev)) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\trev.name[sizeof(rev.name)-1] = 0;\n\n\t\ttry_then_request_module(xt_find_revision(NFPROTO_ARP, rev.name,\n\t\t\t\t\t\t\t rev.revision, 1, &ret),\n\t\t\t\t\t\"arpt_%s\", rev.name);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tduprintf(\"do_arpt_get_ctl: unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic void __arpt_unregister_table(struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\tvoid *loc_cpu_entry;\n\tstruct module *table_owner = table->me;\n\tstruct arpt_entry *iter;\n\n\tprivate = xt_unregister_table(table);\n\n\t/* Decrease module usage counts and free resources */\n\tloc_cpu_entry = private->entries;\n\txt_entry_foreach(iter, loc_cpu_entry, private->size)\n\t\tcleanup_entry(iter);\n\tif (private->number > private->initial_entries)\n\t\tmodule_put(table_owner);\n\txt_free_table_info(private);\n}\n\nint arpt_register_table(struct net *net,\n\t\t\tconst struct xt_table *table,\n\t\t\tconst struct arpt_replace *repl,\n\t\t\tconst struct nf_hook_ops *ops,\n\t\t\tstruct xt_table **res)\n{\n\tint ret;\n\tstruct xt_table_info *newinfo;\n\tstruct xt_table_info bootstrap = {0};\n\tvoid *loc_cpu_entry;\n\tstruct xt_table *new_table;\n\n\tnewinfo = xt_alloc_table_info(repl->size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tmemcpy(loc_cpu_entry, repl->entries, repl->size);\n\n\tret = translate_table(newinfo, loc_cpu_entry, repl);\n\tduprintf(\"arpt_register_table: translate table gives %d\\n\", ret);\n\tif (ret != 0)\n\t\tgoto out_free;\n\n\tnew_table = xt_register_table(net, table, &bootstrap, newinfo);\n\tif (IS_ERR(new_table)) {\n\t\tret = PTR_ERR(new_table);\n\t\tgoto out_free;\n\t}\n\n\t/* set res now, will see skbs right after nf_register_net_hooks */\n\tWRITE_ONCE(*res, new_table);\n\n\tret = nf_register_net_hooks(net, ops, hweight32(table->valid_hooks));\n\tif (ret != 0) {\n\t\t__arpt_unregister_table(new_table);\n\t\t*res = NULL;\n\t}\n\n\treturn ret;\n\nout_free:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nvoid arpt_unregister_table(struct net *net, struct xt_table *table,\n\t\t\t   const struct nf_hook_ops *ops)\n{\n\tnf_unregister_net_hooks(net, ops, hweight32(table->valid_hooks));\n\t__arpt_unregister_table(table);\n}\n\n/* The built-in targets: standard (NULL) and error. */\nstatic struct xt_target arpt_builtin_tg[] __read_mostly = {\n\t{\n\t\t.name             = XT_STANDARD_TARGET,\n\t\t.targetsize       = sizeof(int),\n\t\t.family           = NFPROTO_ARP,\n#ifdef CONFIG_COMPAT\n\t\t.compatsize       = sizeof(compat_int_t),\n\t\t.compat_from_user = compat_standard_from_user,\n\t\t.compat_to_user   = compat_standard_to_user,\n#endif\n\t},\n\t{\n\t\t.name             = XT_ERROR_TARGET,\n\t\t.target           = arpt_error,\n\t\t.targetsize       = XT_FUNCTION_MAXNAMELEN,\n\t\t.family           = NFPROTO_ARP,\n\t},\n};\n\nstatic struct nf_sockopt_ops arpt_sockopts = {\n\t.pf\t\t= PF_INET,\n\t.set_optmin\t= ARPT_BASE_CTL,\n\t.set_optmax\t= ARPT_SO_SET_MAX+1,\n\t.set\t\t= do_arpt_set_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_set\t= compat_do_arpt_set_ctl,\n#endif\n\t.get_optmin\t= ARPT_BASE_CTL,\n\t.get_optmax\t= ARPT_SO_GET_MAX+1,\n\t.get\t\t= do_arpt_get_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_get\t= compat_do_arpt_get_ctl,\n#endif\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic int __net_init arp_tables_net_init(struct net *net)\n{\n\treturn xt_proto_init(net, NFPROTO_ARP);\n}\n\nstatic void __net_exit arp_tables_net_exit(struct net *net)\n{\n\txt_proto_fini(net, NFPROTO_ARP);\n}\n\nstatic struct pernet_operations arp_tables_net_ops = {\n\t.init = arp_tables_net_init,\n\t.exit = arp_tables_net_exit,\n};\n\nstatic int __init arp_tables_init(void)\n{\n\tint ret;\n\n\tret = register_pernet_subsys(&arp_tables_net_ops);\n\tif (ret < 0)\n\t\tgoto err1;\n\n\t/* No one else will be downing sem now, so we won't sleep */\n\tret = xt_register_targets(arpt_builtin_tg, ARRAY_SIZE(arpt_builtin_tg));\n\tif (ret < 0)\n\t\tgoto err2;\n\n\t/* Register setsockopt */\n\tret = nf_register_sockopt(&arpt_sockopts);\n\tif (ret < 0)\n\t\tgoto err4;\n\n\tpr_info(\"arp_tables: (C) 2002 David S. Miller\\n\");\n\treturn 0;\n\nerr4:\n\txt_unregister_targets(arpt_builtin_tg, ARRAY_SIZE(arpt_builtin_tg));\nerr2:\n\tunregister_pernet_subsys(&arp_tables_net_ops);\nerr1:\n\treturn ret;\n}\n\nstatic void __exit arp_tables_fini(void)\n{\n\tnf_unregister_sockopt(&arpt_sockopts);\n\txt_unregister_targets(arpt_builtin_tg, ARRAY_SIZE(arpt_builtin_tg));\n\tunregister_pernet_subsys(&arp_tables_net_ops);\n}\n\nEXPORT_SYMBOL(arpt_register_table);\nEXPORT_SYMBOL(arpt_unregister_table);\nEXPORT_SYMBOL(arpt_do_table);\n\nmodule_init(arp_tables_init);\nmodule_exit(arp_tables_fini);\n", "/*\n * Packet matching code.\n *\n * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling\n * Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>\n * Copyright (C) 2006-2010 Patrick McHardy <kaber@trash.net>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/cache.h>\n#include <linux/capability.h>\n#include <linux/skbuff.h>\n#include <linux/kmod.h>\n#include <linux/vmalloc.h>\n#include <linux/netdevice.h>\n#include <linux/module.h>\n#include <linux/icmp.h>\n#include <net/ip.h>\n#include <net/compat.h>\n#include <asm/uaccess.h>\n#include <linux/mutex.h>\n#include <linux/proc_fs.h>\n#include <linux/err.h>\n#include <linux/cpumask.h>\n\n#include <linux/netfilter/x_tables.h>\n#include <linux/netfilter_ipv4/ip_tables.h>\n#include <net/netfilter/nf_log.h>\n#include \"../../netfilter/xt_repldata.h\"\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Netfilter Core Team <coreteam@netfilter.org>\");\nMODULE_DESCRIPTION(\"IPv4 packet filter\");\n\n/*#define DEBUG_IP_FIREWALL*/\n/*#define DEBUG_ALLOW_ALL*/ /* Useful for remote debugging */\n/*#define DEBUG_IP_FIREWALL_USER*/\n\n#ifdef DEBUG_IP_FIREWALL\n#define dprintf(format, args...) pr_info(format , ## args)\n#else\n#define dprintf(format, args...)\n#endif\n\n#ifdef DEBUG_IP_FIREWALL_USER\n#define duprintf(format, args...) pr_info(format , ## args)\n#else\n#define duprintf(format, args...)\n#endif\n\n#ifdef CONFIG_NETFILTER_DEBUG\n#define IP_NF_ASSERT(x)\t\tWARN_ON(!(x))\n#else\n#define IP_NF_ASSERT(x)\n#endif\n\n#if 0\n/* All the better to debug you with... */\n#define static\n#define inline\n#endif\n\nvoid *ipt_alloc_initial_table(const struct xt_table *info)\n{\n\treturn xt_alloc_initial_table(ipt, IPT);\n}\nEXPORT_SYMBOL_GPL(ipt_alloc_initial_table);\n\n/* Returns whether matches rule or not. */\n/* Performance critical - called for every packet */\nstatic inline bool\nip_packet_match(const struct iphdr *ip,\n\t\tconst char *indev,\n\t\tconst char *outdev,\n\t\tconst struct ipt_ip *ipinfo,\n\t\tint isfrag)\n{\n\tunsigned long ret;\n\n#define FWINV(bool, invflg) ((bool) ^ !!(ipinfo->invflags & (invflg)))\n\n\tif (FWINV((ip->saddr&ipinfo->smsk.s_addr) != ipinfo->src.s_addr,\n\t\t  IPT_INV_SRCIP) ||\n\t    FWINV((ip->daddr&ipinfo->dmsk.s_addr) != ipinfo->dst.s_addr,\n\t\t  IPT_INV_DSTIP)) {\n\t\tdprintf(\"Source or dest mismatch.\\n\");\n\n\t\tdprintf(\"SRC: %pI4. Mask: %pI4. Target: %pI4.%s\\n\",\n\t\t\t&ip->saddr, &ipinfo->smsk.s_addr, &ipinfo->src.s_addr,\n\t\t\tipinfo->invflags & IPT_INV_SRCIP ? \" (INV)\" : \"\");\n\t\tdprintf(\"DST: %pI4 Mask: %pI4 Target: %pI4.%s\\n\",\n\t\t\t&ip->daddr, &ipinfo->dmsk.s_addr, &ipinfo->dst.s_addr,\n\t\t\tipinfo->invflags & IPT_INV_DSTIP ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\tret = ifname_compare_aligned(indev, ipinfo->iniface, ipinfo->iniface_mask);\n\n\tif (FWINV(ret != 0, IPT_INV_VIA_IN)) {\n\t\tdprintf(\"VIA in mismatch (%s vs %s).%s\\n\",\n\t\t\tindev, ipinfo->iniface,\n\t\t\tipinfo->invflags & IPT_INV_VIA_IN ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\tret = ifname_compare_aligned(outdev, ipinfo->outiface, ipinfo->outiface_mask);\n\n\tif (FWINV(ret != 0, IPT_INV_VIA_OUT)) {\n\t\tdprintf(\"VIA out mismatch (%s vs %s).%s\\n\",\n\t\t\toutdev, ipinfo->outiface,\n\t\t\tipinfo->invflags & IPT_INV_VIA_OUT ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\t/* Check specific protocol */\n\tif (ipinfo->proto &&\n\t    FWINV(ip->protocol != ipinfo->proto, IPT_INV_PROTO)) {\n\t\tdprintf(\"Packet protocol %hi does not match %hi.%s\\n\",\n\t\t\tip->protocol, ipinfo->proto,\n\t\t\tipinfo->invflags & IPT_INV_PROTO ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\t/* If we have a fragment rule but the packet is not a fragment\n\t * then we return zero */\n\tif (FWINV((ipinfo->flags&IPT_F_FRAG) && !isfrag, IPT_INV_FRAG)) {\n\t\tdprintf(\"Fragment rule but not fragment.%s\\n\",\n\t\t\tipinfo->invflags & IPT_INV_FRAG ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\treturn true;\n}\n\nstatic bool\nip_checkentry(const struct ipt_ip *ip)\n{\n\tif (ip->flags & ~IPT_F_MASK) {\n\t\tduprintf(\"Unknown flag bits set: %08X\\n\",\n\t\t\t ip->flags & ~IPT_F_MASK);\n\t\treturn false;\n\t}\n\tif (ip->invflags & ~IPT_INV_MASK) {\n\t\tduprintf(\"Unknown invflag bits set: %08X\\n\",\n\t\t\t ip->invflags & ~IPT_INV_MASK);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic unsigned int\nipt_error(struct sk_buff *skb, const struct xt_action_param *par)\n{\n\tnet_info_ratelimited(\"error: `%s'\\n\", (const char *)par->targinfo);\n\n\treturn NF_DROP;\n}\n\n/* Performance critical */\nstatic inline struct ipt_entry *\nget_entry(const void *base, unsigned int offset)\n{\n\treturn (struct ipt_entry *)(base + offset);\n}\n\n/* All zeroes == unconditional rule. */\n/* Mildly perf critical (only if packet tracing is on) */\nstatic inline bool unconditional(const struct ipt_entry *e)\n{\n\tstatic const struct ipt_ip uncond;\n\n\treturn e->target_offset == sizeof(struct ipt_entry) &&\n\t       memcmp(&e->ip, &uncond, sizeof(uncond)) == 0;\n#undef FWINV\n}\n\n/* for const-correctness */\nstatic inline const struct xt_entry_target *\nipt_get_target_c(const struct ipt_entry *e)\n{\n\treturn ipt_get_target((struct ipt_entry *)e);\n}\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\nstatic const char *const hooknames[] = {\n\t[NF_INET_PRE_ROUTING]\t\t= \"PREROUTING\",\n\t[NF_INET_LOCAL_IN]\t\t= \"INPUT\",\n\t[NF_INET_FORWARD]\t\t= \"FORWARD\",\n\t[NF_INET_LOCAL_OUT]\t\t= \"OUTPUT\",\n\t[NF_INET_POST_ROUTING]\t\t= \"POSTROUTING\",\n};\n\nenum nf_ip_trace_comments {\n\tNF_IP_TRACE_COMMENT_RULE,\n\tNF_IP_TRACE_COMMENT_RETURN,\n\tNF_IP_TRACE_COMMENT_POLICY,\n};\n\nstatic const char *const comments[] = {\n\t[NF_IP_TRACE_COMMENT_RULE]\t= \"rule\",\n\t[NF_IP_TRACE_COMMENT_RETURN]\t= \"return\",\n\t[NF_IP_TRACE_COMMENT_POLICY]\t= \"policy\",\n};\n\nstatic struct nf_loginfo trace_loginfo = {\n\t.type = NF_LOG_TYPE_LOG,\n\t.u = {\n\t\t.log = {\n\t\t\t.level = 4,\n\t\t\t.logflags = NF_LOG_MASK,\n\t\t},\n\t},\n};\n\n/* Mildly perf critical (only if packet tracing is on) */\nstatic inline int\nget_chainname_rulenum(const struct ipt_entry *s, const struct ipt_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ipt_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (unconditional(s) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t   t->verdict < 0) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}\n\nstatic void trace_packet(struct net *net,\n\t\t\t const struct sk_buff *skb,\n\t\t\t unsigned int hook,\n\t\t\t const struct net_device *in,\n\t\t\t const struct net_device *out,\n\t\t\t const char *tablename,\n\t\t\t const struct xt_table_info *private,\n\t\t\t const struct ipt_entry *e)\n{\n\tconst struct ipt_entry *root;\n\tconst char *hookname, *chainname, *comment;\n\tconst struct ipt_entry *iter;\n\tunsigned int rulenum = 0;\n\n\troot = get_entry(private->entries, private->hook_entry[hook]);\n\n\thookname = chainname = hooknames[hook];\n\tcomment = comments[NF_IP_TRACE_COMMENT_RULE];\n\n\txt_entry_foreach(iter, root, private->size - private->hook_entry[hook])\n\t\tif (get_chainname_rulenum(iter, e, hookname,\n\t\t    &chainname, &comment, &rulenum) != 0)\n\t\t\tbreak;\n\n\tnf_log_trace(net, AF_INET, hook, skb, in, out, &trace_loginfo,\n\t\t     \"TRACE: %s:%s:%s:%u \",\n\t\t     tablename, chainname, comment, rulenum);\n}\n#endif\n\nstatic inline\nstruct ipt_entry *ipt_next_entry(const struct ipt_entry *entry)\n{\n\treturn (void *)entry + entry->next_offset;\n}\n\n/* Returns one of the generic firewall policies, like NF_ACCEPT. */\nunsigned int\nipt_do_table(struct sk_buff *skb,\n\t     const struct nf_hook_state *state,\n\t     struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\tconst struct iphdr *ip;\n\t/* Initializing verdict to NF_DROP keeps gcc happy. */\n\tunsigned int verdict = NF_DROP;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tstruct ipt_entry *e, **jumpstack;\n\tunsigned int stackidx, cpu;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\t/* Initialization */\n\tstackidx = 0;\n\tip = ip_hdr(skb);\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\t/* We handle fragments by dealing with the first fragment as\n\t * if it was a normal packet.  All other fragments are treated\n\t * normally, except that they will NEVER match rules that ask\n\t * things we don't know, ie. tcp syn flag or ports).  If the\n\t * rule is also a fragment-specific rule, non-fragments won't\n\t * match it. */\n\tacpar.fragoff = ntohs(ip->frag_off) & IP_OFFSET;\n\tacpar.thoff   = ip_hdrlen(skb);\n\tacpar.hotdrop = false;\n\tacpar.net     = state->net;\n\tacpar.in      = state->in;\n\tacpar.out     = state->out;\n\tacpar.family  = NFPROTO_IPV4;\n\tacpar.hooknum = hook;\n\n\tIP_NF_ASSERT(table->valid_hooks & (1 << hook));\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = table->private;\n\tcpu        = smp_processor_id();\n\t/*\n\t * Ensure we load private-> members after we've fetched the base\n\t * pointer.\n\t */\n\tsmp_read_barrier_depends();\n\ttable_base = private->entries;\n\tjumpstack  = (struct ipt_entry **)private->jumpstack[cpu];\n\n\t/* Switch to alternate jumpstack if we're being invoked via TEE.\n\t * TEE issues XT_CONTINUE verdict on original skb so we must not\n\t * clobber the jumpstack.\n\t *\n\t * For recursion via REJECT or SYNPROXY the stack will be clobbered\n\t * but it is no problem since absolute verdict is issued by these.\n\t */\n\tif (static_key_false(&xt_tee_enabled))\n\t\tjumpstack += private->stacksize * __this_cpu_read(nf_skb_duplicated);\n\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tpr_debug(\"Entering %s(hook %u), UF %p\\n\",\n\t\t table->name, hook,\n\t\t get_entry(table_base, private->underflow[hook]));\n\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tconst struct xt_entry_match *ematch;\n\t\tstruct xt_counters *counter;\n\n\t\tIP_NF_ASSERT(e);\n\t\tif (!ip_packet_match(ip, indev, outdev,\n\t\t    &e->ip, acpar.fragoff)) {\n no_match:\n\t\t\te = ipt_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\txt_ematch_foreach(ematch, e) {\n\t\t\tacpar.match     = ematch->u.kernel.match;\n\t\t\tacpar.matchinfo = ematch->data;\n\t\t\tif (!acpar.match->match(skb, &acpar))\n\t\t\t\tgoto no_match;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, skb->len, 1);\n\n\t\tt = ipt_get_target(e);\n\t\tIP_NF_ASSERT(t->u.kernel.target);\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n\t\t/* The packet is traced: log it */\n\t\tif (unlikely(skb->nf_trace))\n\t\t\ttrace_packet(state->net, skb, hook, state->in,\n\t\t\t\t     state->out, table->name, private, e);\n#endif\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0) {\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t    private->underflow[hook]);\n\t\t\t\t\tpr_debug(\"Underflow (this is normal) \"\n\t\t\t\t\t\t \"to %p\\n\", e);\n\t\t\t\t} else {\n\t\t\t\t\te = jumpstack[--stackidx];\n\t\t\t\t\tpr_debug(\"Pulled %p out from pos %u\\n\",\n\t\t\t\t\t\t e, stackidx);\n\t\t\t\t\te = ipt_next_entry(e);\n\t\t\t\t}\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v != ipt_next_entry(e) &&\n\t\t\t    !(e->ip.flags & IPT_F_GOTO)) {\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t\tpr_debug(\"Pushed %p into pos %u\\n\",\n\t\t\t\t\t e, stackidx - 1);\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\t\t/* Target might have changed stuff. */\n\t\tip = ip_hdr(skb);\n\t\tif (verdict == XT_CONTINUE)\n\t\t\te = ipt_next_entry(e);\n\t\telse\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t} while (!acpar.hotdrop);\n\tpr_debug(\"Exiting %s; sp at %u\\n\", __func__, stackidx);\n\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n#ifdef DEBUG_ALLOW_ALL\n\treturn NF_ACCEPT;\n#else\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse return verdict;\n#endif\n}\n\nstatic bool find_jump_target(const struct xt_table_info *t,\n\t\t\t     const struct ipt_entry *target)\n{\n\tstruct ipt_entry *iter;\n\n\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t if (iter == target)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n/* Figures out from what hook each rule can be called: returns 0 if\n   there are loops.  Puts hook bitmask in comefrom. */\nstatic int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ipt_entry *e = (struct ipt_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ipt_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\tif (pos + size >= newinfo->size)\n\t\t\t\t\treturn 0;\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ipt_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t\t(entry0 + newpos);\n\t\t\t\t\tif (!find_jump_target(newinfo, e))\n\t\t\t\t\t\treturn 0;\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t\tif (newpos >= newinfo->size)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\te = (struct ipt_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}\n\nstatic void cleanup_match(struct xt_entry_match *m, struct net *net)\n{\n\tstruct xt_mtdtor_param par;\n\n\tpar.net       = net;\n\tpar.match     = m->u.kernel.match;\n\tpar.matchinfo = m->data;\n\tpar.family    = NFPROTO_IPV4;\n\tif (par.match->destroy != NULL)\n\t\tpar.match->destroy(&par);\n\tmodule_put(par.match->me);\n}\n\nstatic int\ncheck_match(struct xt_entry_match *m, struct xt_mtchk_param *par)\n{\n\tconst struct ipt_ip *ip = par->entryinfo;\n\tint ret;\n\n\tpar->match     = m->u.kernel.match;\n\tpar->matchinfo = m->data;\n\n\tret = xt_check_match(par, m->u.match_size - sizeof(*m),\n\t      ip->proto, ip->invflags & IPT_INV_PROTO);\n\tif (ret < 0) {\n\t\tduprintf(\"check failed for `%s'.\\n\", par->match->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int\nfind_check_match(struct xt_entry_match *m, struct xt_mtchk_param *par)\n{\n\tstruct xt_match *match;\n\tint ret;\n\n\tmatch = xt_request_find_match(NFPROTO_IPV4, m->u.user.name,\n\t\t\t\t      m->u.user.revision);\n\tif (IS_ERR(match)) {\n\t\tduprintf(\"find_check_match: `%s' not found\\n\", m->u.user.name);\n\t\treturn PTR_ERR(match);\n\t}\n\tm->u.kernel.match = match;\n\n\tret = check_match(m, par);\n\tif (ret)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tmodule_put(m->u.kernel.match->me);\n\treturn ret;\n}\n\nstatic int check_target(struct ipt_entry *e, struct net *net, const char *name)\n{\n\tstruct xt_entry_target *t = ipt_get_target(e);\n\tstruct xt_tgchk_param par = {\n\t\t.net       = net,\n\t\t.table     = name,\n\t\t.entryinfo = e,\n\t\t.target    = t->u.kernel.target,\n\t\t.targinfo  = t->data,\n\t\t.hook_mask = e->comefrom,\n\t\t.family    = NFPROTO_IPV4,\n\t};\n\tint ret;\n\n\tret = xt_check_target(&par, t->u.target_size - sizeof(*t),\n\t      e->ip.proto, e->ip.invflags & IPT_INV_PROTO);\n\tif (ret < 0) {\n\t\tduprintf(\"check failed for `%s'.\\n\",\n\t\t\t t->u.kernel.target->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int\nfind_check_entry(struct ipt_entry *e, struct net *net, const char *name,\n\t\t unsigned int size)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tint ret;\n\tunsigned int j;\n\tstruct xt_mtchk_param mtpar;\n\tstruct xt_entry_match *ematch;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\n\tj = 0;\n\tmtpar.net\t= net;\n\tmtpar.table     = name;\n\tmtpar.entryinfo = &e->ip;\n\tmtpar.hook_mask = e->comefrom;\n\tmtpar.family    = NFPROTO_IPV4;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = find_check_match(ematch, &mtpar);\n\t\tif (ret != 0)\n\t\t\tgoto cleanup_matches;\n\t\t++j;\n\t}\n\n\tt = ipt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"find_check_entry: `%s' not found\\n\", t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto cleanup_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\tret = check_target(e, net, name);\n\tif (ret)\n\t\tgoto err;\n\n\treturn 0;\n err:\n\tmodule_put(t->u.kernel.target->me);\n cleanup_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcleanup_match(ematch, net);\n\t}\n\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic bool check_underflow(const struct ipt_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = ipt_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n\nstatic int\ncheck_entry_size_and_hooks(struct ipt_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ipt_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}\n\nstatic void\ncleanup_entry(struct ipt_entry *e, struct net *net)\n{\n\tstruct xt_tgdtor_param par;\n\tstruct xt_entry_target *t;\n\tstruct xt_entry_match *ematch;\n\n\t/* Cleanup all matches */\n\txt_ematch_foreach(ematch, e)\n\t\tcleanup_match(ematch, net);\n\tt = ipt_get_target(e);\n\n\tpar.net      = net;\n\tpar.target   = t->u.kernel.target;\n\tpar.targinfo = t->data;\n\tpar.family   = NFPROTO_IPV4;\n\tif (par.target->destroy != NULL)\n\t\tpar.target->destroy(&par);\n\tmodule_put(par.target->me);\n\txt_percpu_counter_free(e->counters.pcnt);\n}\n\n/* Checks and translates the user-supplied table segment (held in\n   newinfo) */\nstatic int\ntranslate_table(struct net *net, struct xt_table_info *newinfo, void *entry0,\n\t\tconst struct ipt_replace *repl)\n{\n\tstruct ipt_entry *iter;\n\tunsigned int i;\n\tint ret = 0;\n\n\tnewinfo->size = repl->size;\n\tnewinfo->number = repl->num_entries;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tnewinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_table: size %u\\n\", newinfo->size);\n\ti = 0;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = check_entry_size_and_hooks(iter, newinfo, entry0,\n\t\t\t\t\t\t entry0 + repl->size,\n\t\t\t\t\t\t repl->hook_entry,\n\t\t\t\t\t\t repl->underflow,\n\t\t\t\t\t\t repl->valid_hooks);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t\t++i;\n\t\tif (strcmp(ipt_get_target(iter)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\n\tif (i != repl->num_entries) {\n\t\tduprintf(\"translate_table: %u not %u entries\\n\",\n\t\t\t i, repl->num_entries);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(repl->valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (newinfo->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, repl->hook_entry[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (newinfo->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, repl->underflow[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!mark_source_chains(newinfo, repl->valid_hooks, entry0))\n\t\treturn -ELOOP;\n\n\t/* Finally, each sanity check must pass */\n\ti = 0;\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = find_check_entry(iter, net, repl->name, repl->size);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t}\n\n\tif (ret != 0) {\n\t\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter, net);\n\t\t}\n\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic void\nget_counters(const struct xt_table_info *t,\n\t     struct xt_counters counters[])\n{\n\tstruct ipt_entry *iter;\n\tunsigned int cpu;\n\tunsigned int i;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tseqcount_t *s = &per_cpu(xt_recseq, cpu);\n\n\t\ti = 0;\n\t\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t\tstruct xt_counters *tmp;\n\t\t\tu64 bcnt, pcnt;\n\t\t\tunsigned int start;\n\n\t\t\ttmp = xt_get_per_cpu_counter(&iter->counters, cpu);\n\t\t\tdo {\n\t\t\t\tstart = read_seqcount_begin(s);\n\t\t\t\tbcnt = tmp->bcnt;\n\t\t\t\tpcnt = tmp->pcnt;\n\t\t\t} while (read_seqcount_retry(s, start));\n\n\t\t\tADD_COUNTER(counters[i], bcnt, pcnt);\n\t\t\t++i; /* macro does multi eval of i */\n\t\t}\n\t}\n}\n\nstatic struct xt_counters *alloc_counters(const struct xt_table *table)\n{\n\tunsigned int countersize;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\n\t/* We need atomic snapshot of counters: rest doesn't change\n\t   (other than comefrom, which userspace doesn't care\n\t   about). */\n\tcountersize = sizeof(struct xt_counters) * private->number;\n\tcounters = vzalloc(countersize);\n\n\tif (counters == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tget_counters(private, counters);\n\n\treturn counters;\n}\n\nstatic int\ncopy_entries_to_user(unsigned int total_size,\n\t\t     const struct xt_table *table,\n\t\t     void __user *userptr)\n{\n\tunsigned int off, num;\n\tconst struct ipt_entry *e;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tint ret = 0;\n\tconst void *loc_cpu_entry;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tloc_cpu_entry = private->entries;\n\tif (copy_to_user(userptr, loc_cpu_entry, total_size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_counters;\n\t}\n\n\t/* FIXME: use iterator macros --RR */\n\t/* ... then go back and fix counters and names */\n\tfor (off = 0, num = 0; off < total_size; off += e->next_offset, num++){\n\t\tunsigned int i;\n\t\tconst struct xt_entry_match *m;\n\t\tconst struct xt_entry_target *t;\n\n\t\te = (struct ipt_entry *)(loc_cpu_entry + off);\n\t\tif (copy_to_user(userptr + off\n\t\t\t\t + offsetof(struct ipt_entry, counters),\n\t\t\t\t &counters[num],\n\t\t\t\t sizeof(counters[num])) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\n\t\tfor (i = sizeof(struct ipt_entry);\n\t\t     i < e->target_offset;\n\t\t     i += m->u.match_size) {\n\t\t\tm = (void *)e + i;\n\n\t\t\tif (copy_to_user(userptr + off + i\n\t\t\t\t\t + offsetof(struct xt_entry_match,\n\t\t\t\t\t\t    u.user.name),\n\t\t\t\t\t m->u.kernel.match->name,\n\t\t\t\t\t strlen(m->u.kernel.match->name)+1)\n\t\t\t    != 0) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto free_counters;\n\t\t\t}\n\t\t}\n\n\t\tt = ipt_get_target_c(e);\n\t\tif (copy_to_user(userptr + off + e->target_offset\n\t\t\t\t + offsetof(struct xt_entry_target,\n\t\t\t\t\t    u.user.name),\n\t\t\t\t t->u.kernel.target->name,\n\t\t\t\t strlen(t->u.kernel.target->name)+1) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\t}\n\n free_counters:\n\tvfree(counters);\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic void compat_standard_from_user(void *dst, const void *src)\n{\n\tint v = *(compat_int_t *)src;\n\n\tif (v > 0)\n\t\tv += xt_compat_calc_jump(AF_INET, v);\n\tmemcpy(dst, &v, sizeof(v));\n}\n\nstatic int compat_standard_to_user(void __user *dst, const void *src)\n{\n\tcompat_int_t cv = *(int *)src;\n\n\tif (cv > 0)\n\t\tcv -= xt_compat_calc_jump(AF_INET, cv);\n\treturn copy_to_user(dst, &cv, sizeof(cv)) ? -EFAULT : 0;\n}\n\nstatic int compat_calc_entry(const struct ipt_entry *e,\n\t\t\t     const struct xt_table_info *info,\n\t\t\t     const void *base, struct xt_table_info *newinfo)\n{\n\tconst struct xt_entry_match *ematch;\n\tconst struct xt_entry_target *t;\n\tunsigned int entry_offset;\n\tint off, i, ret;\n\n\toff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\tentry_offset = (void *)e - base;\n\txt_ematch_foreach(ematch, e)\n\t\toff += xt_compat_match_offset(ematch->u.kernel.match);\n\tt = ipt_get_target_c(e);\n\toff += xt_compat_target_offset(t->u.kernel.target);\n\tnewinfo->size -= off;\n\tret = xt_compat_add_offset(AF_INET, entry_offset, off);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tif (info->hook_entry[i] &&\n\t\t    (e < (struct ipt_entry *)(base + info->hook_entry[i])))\n\t\t\tnewinfo->hook_entry[i] -= off;\n\t\tif (info->underflow[i] &&\n\t\t    (e < (struct ipt_entry *)(base + info->underflow[i])))\n\t\t\tnewinfo->underflow[i] -= off;\n\t}\n\treturn 0;\n}\n\nstatic int compat_table_info(const struct xt_table_info *info,\n\t\t\t     struct xt_table_info *newinfo)\n{\n\tstruct ipt_entry *iter;\n\tconst void *loc_cpu_entry;\n\tint ret;\n\n\tif (!newinfo || !info)\n\t\treturn -EINVAL;\n\n\t/* we dont care about newinfo->entries */\n\tmemcpy(newinfo, info, offsetof(struct xt_table_info, entries));\n\tnewinfo->initial_entries = 0;\n\tloc_cpu_entry = info->entries;\n\txt_compat_init_offsets(AF_INET, info->number);\n\txt_entry_foreach(iter, loc_cpu_entry, info->size) {\n\t\tret = compat_calc_entry(iter, info, loc_cpu_entry, newinfo);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n#endif\n\nstatic int get_info(struct net *net, void __user *user,\n\t\t    const int *len, int compat)\n{\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tstruct xt_table *t;\n\tint ret;\n\n\tif (*len != sizeof(struct ipt_getinfo)) {\n\t\tduprintf(\"length %u != %zu\\n\", *len,\n\t\t\t sizeof(struct ipt_getinfo));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(name, user, sizeof(name)) != 0)\n\t\treturn -EFAULT;\n\n\tname[XT_TABLE_MAXNAMELEN-1] = '\\0';\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_lock(AF_INET);\n#endif\n\tt = try_then_request_module(xt_find_table_lock(net, AF_INET, name),\n\t\t\t\t    \"iptable_%s\", name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tstruct ipt_getinfo info;\n\t\tconst struct xt_table_info *private = t->private;\n#ifdef CONFIG_COMPAT\n\t\tstruct xt_table_info tmp;\n\n\t\tif (compat) {\n\t\t\tret = compat_table_info(private, &tmp);\n\t\t\txt_compat_flush_offsets(AF_INET);\n\t\t\tprivate = &tmp;\n\t\t}\n#endif\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.valid_hooks = t->valid_hooks;\n\t\tmemcpy(info.hook_entry, private->hook_entry,\n\t\t       sizeof(info.hook_entry));\n\t\tmemcpy(info.underflow, private->underflow,\n\t\t       sizeof(info.underflow));\n\t\tinfo.num_entries = private->number;\n\t\tinfo.size = private->size;\n\t\tstrcpy(info.name, name);\n\n\t\tif (copy_to_user(user, &info, *len) != 0)\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = 0;\n\n\t\txt_table_unlock(t);\n\t\tmodule_put(t->me);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_unlock(AF_INET);\n#endif\n\treturn ret;\n}\n\nstatic int\nget_entries(struct net *net, struct ipt_get_entries __user *uptr,\n\t    const int *len)\n{\n\tint ret;\n\tstruct ipt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct ipt_get_entries) + get.size) {\n\t\tduprintf(\"get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, AF_INET, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse {\n\t\t\tduprintf(\"get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\treturn ret;\n}\n\nstatic int\n__do_replace(struct net *net, const char *name, unsigned int valid_hooks,\n\t     struct xt_table_info *newinfo, unsigned int num_counters,\n\t     void __user *counters_ptr)\n{\n\tint ret;\n\tstruct xt_table *t;\n\tstruct xt_table_info *oldinfo;\n\tstruct xt_counters *counters;\n\tstruct ipt_entry *iter;\n\n\tret = 0;\n\tcounters = vzalloc(num_counters * sizeof(struct xt_counters));\n\tif (!counters) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tt = try_then_request_module(xt_find_table_lock(net, AF_INET, name),\n\t\t\t\t    \"iptable_%s\", name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free_newinfo_counters_untrans;\n\t}\n\n\t/* You lied! */\n\tif (valid_hooks != t->valid_hooks) {\n\t\tduprintf(\"Valid hook crap: %08X vs %08X\\n\",\n\t\t\t valid_hooks, t->valid_hooks);\n\t\tret = -EINVAL;\n\t\tgoto put_module;\n\t}\n\n\toldinfo = xt_replace_table(t, num_counters, newinfo, &ret);\n\tif (!oldinfo)\n\t\tgoto put_module;\n\n\t/* Update module usage count based on number of rules */\n\tduprintf(\"do_replace: oldnum=%u, initnum=%u, newnum=%u\\n\",\n\t\toldinfo->number, oldinfo->initial_entries, newinfo->number);\n\tif ((oldinfo->number > oldinfo->initial_entries) ||\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\tif ((oldinfo->number > oldinfo->initial_entries) &&\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\n\t/* Get the old counters, and synchronize with replace */\n\tget_counters(oldinfo, counters);\n\n\t/* Decrease module usage counts and free resource */\n\txt_entry_foreach(iter, oldinfo->entries, oldinfo->size)\n\t\tcleanup_entry(iter, net);\n\n\txt_free_table_info(oldinfo);\n\tif (copy_to_user(counters_ptr, counters,\n\t\t\t sizeof(struct xt_counters) * num_counters) != 0) {\n\t\t/* Silent error, can't fail, new table is already in place */\n\t\tnet_warn_ratelimited(\"iptables: counters copy to user failed while replacing table\\n\");\n\t}\n\tvfree(counters);\n\txt_table_unlock(t);\n\treturn ret;\n\n put_module:\n\tmodule_put(t->me);\n\txt_table_unlock(t);\n free_newinfo_counters_untrans:\n\tvfree(counters);\n out:\n\treturn ret;\n}\n\nstatic int\ndo_replace(struct net *net, const void __user *user, unsigned int len)\n{\n\tint ret;\n\tstruct ipt_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct ipt_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_table(net, newinfo, loc_cpu_entry, &tmp);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, tmp.counters);\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter, net);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int\ndo_add_counters(struct net *net, const void __user *user,\n\t\tunsigned int len, int compat)\n{\n\tunsigned int i;\n\tstruct xt_counters_info tmp;\n\tstruct xt_counters *paddc;\n\tunsigned int num_counters;\n\tconst char *name;\n\tint size;\n\tvoid *ptmp;\n\tstruct xt_table *t;\n\tconst struct xt_table_info *private;\n\tint ret = 0;\n\tstruct ipt_entry *iter;\n\tunsigned int addend;\n#ifdef CONFIG_COMPAT\n\tstruct compat_xt_counters_info compat_tmp;\n\n\tif (compat) {\n\t\tptmp = &compat_tmp;\n\t\tsize = sizeof(struct compat_xt_counters_info);\n\t} else\n#endif\n\t{\n\t\tptmp = &tmp;\n\t\tsize = sizeof(struct xt_counters_info);\n\t}\n\n\tif (copy_from_user(ptmp, user, size) != 0)\n\t\treturn -EFAULT;\n\n#ifdef CONFIG_COMPAT\n\tif (compat) {\n\t\tnum_counters = compat_tmp.num_counters;\n\t\tname = compat_tmp.name;\n\t} else\n#endif\n\t{\n\t\tnum_counters = tmp.num_counters;\n\t\tname = tmp.name;\n\t}\n\n\tif (len != size + num_counters * sizeof(struct xt_counters))\n\t\treturn -EINVAL;\n\n\tpaddc = vmalloc(len - size);\n\tif (!paddc)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(paddc, user + size, len - size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free;\n\t}\n\n\tt = xt_find_table_lock(net, AF_INET, name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free;\n\t}\n\n\tlocal_bh_disable();\n\tprivate = t->private;\n\tif (private->number != num_counters) {\n\t\tret = -EINVAL;\n\t\tgoto unlock_up_free;\n\t}\n\n\ti = 0;\n\taddend = xt_write_recseq_begin();\n\txt_entry_foreach(iter, private->entries, private->size) {\n\t\tstruct xt_counters *tmp;\n\n\t\ttmp = xt_get_this_cpu_counter(&iter->counters);\n\t\tADD_COUNTER(*tmp, paddc[i].bcnt, paddc[i].pcnt);\n\t\t++i;\n\t}\n\txt_write_recseq_end(addend);\n unlock_up_free:\n\tlocal_bh_enable();\n\txt_table_unlock(t);\n\tmodule_put(t->me);\n free:\n\tvfree(paddc);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_ipt_replace {\n\tchar\t\t\tname[XT_TABLE_MAXNAMELEN];\n\tu32\t\t\tvalid_hooks;\n\tu32\t\t\tnum_entries;\n\tu32\t\t\tsize;\n\tu32\t\t\thook_entry[NF_INET_NUMHOOKS];\n\tu32\t\t\tunderflow[NF_INET_NUMHOOKS];\n\tu32\t\t\tnum_counters;\n\tcompat_uptr_t\t\tcounters;\t/* struct xt_counters * */\n\tstruct compat_ipt_entry\tentries[0];\n};\n\nstatic int\ncompat_copy_entry_to_user(struct ipt_entry *e, void __user **dstptr,\n\t\t\t  unsigned int *size, struct xt_counters *counters,\n\t\t\t  unsigned int i)\n{\n\tstruct xt_entry_target *t;\n\tstruct compat_ipt_entry __user *ce;\n\tu_int16_t target_offset, next_offset;\n\tcompat_uint_t origsize;\n\tconst struct xt_entry_match *ematch;\n\tint ret = 0;\n\n\torigsize = *size;\n\tce = (struct compat_ipt_entry __user *)*dstptr;\n\tif (copy_to_user(ce, e, sizeof(struct ipt_entry)) != 0 ||\n\t    copy_to_user(&ce->counters, &counters[i],\n\t    sizeof(counters[i])) != 0)\n\t\treturn -EFAULT;\n\n\t*dstptr += sizeof(struct compat_ipt_entry);\n\t*size -= sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\n\txt_ematch_foreach(ematch, e) {\n\t\tret = xt_compat_match_to_user(ematch, dstptr, size);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\ttarget_offset = e->target_offset - (origsize - *size);\n\tt = ipt_get_target(e);\n\tret = xt_compat_target_to_user(t, dstptr, size);\n\tif (ret)\n\t\treturn ret;\n\tnext_offset = e->next_offset - (origsize - *size);\n\tif (put_user(target_offset, &ce->target_offset) != 0 ||\n\t    put_user(next_offset, &ce->next_offset) != 0)\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int\ncompat_find_calc_match(struct xt_entry_match *m,\n\t\t       const char *name,\n\t\t       const struct ipt_ip *ip,\n\t\t       int *size)\n{\n\tstruct xt_match *match;\n\n\tmatch = xt_request_find_match(NFPROTO_IPV4, m->u.user.name,\n\t\t\t\t      m->u.user.revision);\n\tif (IS_ERR(match)) {\n\t\tduprintf(\"compat_check_calc_match: `%s' not found\\n\",\n\t\t\t m->u.user.name);\n\t\treturn PTR_ERR(match);\n\t}\n\tm->u.kernel.match = match;\n\t*size += xt_compat_match_offset(match);\n\treturn 0;\n}\n\nstatic void compat_release_entry(struct compat_ipt_entry *e)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_entry_match *ematch;\n\n\t/* Cleanup all matches */\n\txt_ematch_foreach(ematch, e)\n\t\tmodule_put(ematch->u.kernel.match->me);\n\tt = compat_ipt_get_target(e);\n\tmodule_put(t->u.kernel.target->me);\n}\n\nstatic int\ncheck_compat_entry_size_and_hooks(struct compat_ipt_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ipt_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ipt_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ipt_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip_checkentry(&e->ip))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ip, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ipt_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV4, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}\n\nstatic int\ncompat_copy_entry_from_user(struct compat_ipt_entry *e, void **dstptr,\n\t\t\t    unsigned int *size, const char *name,\n\t\t\t    struct xt_table_info *newinfo, unsigned char *base)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tstruct ipt_entry *de;\n\tunsigned int origsize;\n\tint ret, h;\n\tstruct xt_entry_match *ematch;\n\n\tret = 0;\n\torigsize = *size;\n\tde = (struct ipt_entry *)*dstptr;\n\tmemcpy(de, e, sizeof(struct ipt_entry));\n\tmemcpy(&de->counters, &e->counters, sizeof(e->counters));\n\n\t*dstptr += sizeof(struct ipt_entry);\n\t*size += sizeof(struct ipt_entry) - sizeof(struct compat_ipt_entry);\n\n\txt_ematch_foreach(ematch, e) {\n\t\tret = xt_compat_match_from_user(ematch, dstptr, size);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\tde->target_offset = e->target_offset - (origsize - *size);\n\tt = compat_ipt_get_target(e);\n\ttarget = t->u.kernel.target;\n\txt_compat_target_from_user(t, dstptr, size);\n\n\tde->next_offset = e->next_offset - (origsize - *size);\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)de - base < newinfo->hook_entry[h])\n\t\t\tnewinfo->hook_entry[h] -= origsize - *size;\n\t\tif ((unsigned char *)de - base < newinfo->underflow[h])\n\t\t\tnewinfo->underflow[h] -= origsize - *size;\n\t}\n\treturn ret;\n}\n\nstatic int\ncompat_check_entry(struct ipt_entry *e, struct net *net, const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_mtchk_param mtpar;\n\tunsigned int j;\n\tint ret = 0;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\n\tj = 0;\n\tmtpar.net\t= net;\n\tmtpar.table     = name;\n\tmtpar.entryinfo = &e->ip;\n\tmtpar.hook_mask = e->comefrom;\n\tmtpar.family    = NFPROTO_IPV4;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = check_match(ematch, &mtpar);\n\t\tif (ret != 0)\n\t\t\tgoto cleanup_matches;\n\t\t++j;\n\t}\n\n\tret = check_target(e, net, name);\n\tif (ret)\n\t\tgoto cleanup_matches;\n\treturn 0;\n\n cleanup_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcleanup_match(ematch, net);\n\t}\n\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic int\ntranslate_compat_table(struct net *net,\n\t\t       const char *name,\n\t\t       unsigned int valid_hooks,\n\t\t       struct xt_table_info **pinfo,\n\t\t       void **pentry0,\n\t\t       unsigned int total_size,\n\t\t       unsigned int number,\n\t\t       unsigned int *hook_entries,\n\t\t       unsigned int *underflows)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_ipt_entry *iter0;\n\tstruct ipt_entry *iter1;\n\tunsigned int size;\n\tint ret;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = total_size;\n\tinfo->number = number;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_compat_table: size %u\\n\", info->size);\n\tj = 0;\n\txt_compat_lock(AF_INET);\n\txt_compat_init_offsets(AF_INET, number);\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + total_size,\n\t\t\t\t\t\t\thook_entries,\n\t\t\t\t\t\t\tunderflows,\n\t\t\t\t\t\t\tname);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != number) {\n\t\tduprintf(\"translate_compat_table: %u not %u entries\\n\",\n\t\t\t j, number);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (info->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, hook_entries[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tif (info->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, underflows[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = number;\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = info->hook_entry[i];\n\t\tnewinfo->underflow[i] = info->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = total_size;\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = compat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t\t  name, newinfo, entry1);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\txt_compat_flush_offsets(AF_INET);\n\txt_compat_unlock(AF_INET);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\tret = -ELOOP;\n\tif (!mark_source_chains(newinfo, valid_hooks, entry1))\n\t\tgoto free_newinfo;\n\n\ti = 0;\n\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\tret = compat_check_entry(iter1, net, name);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t\tif (strcmp(ipt_get_target(iter1)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\tif (ret) {\n\t\t/*\n\t\t * The first i matches need cleanup_entry (calls ->destroy)\n\t\t * because they had called ->check already. The other j-i\n\t\t * entries need only release.\n\t\t */\n\t\tint skip = i;\n\t\tj -= i;\n\t\txt_entry_foreach(iter0, entry0, newinfo->size) {\n\t\t\tif (skip-- > 0)\n\t\t\t\tcontinue;\n\t\t\tif (j-- == 0)\n\t\t\t\tbreak;\n\t\t\tcompat_release_entry(iter0);\n\t\t}\n\t\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter1, net);\n\t\t}\n\t\txt_free_table_info(newinfo);\n\t\treturn ret;\n\t}\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\nout:\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(AF_INET);\n\txt_compat_unlock(AF_INET);\n\tgoto out;\n}\n\nstatic int\ncompat_do_replace(struct net *net, void __user *user, unsigned int len)\n{\n\tint ret;\n\tstruct compat_ipt_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct ipt_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.size >= INT_MAX / num_possible_cpus())\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_compat_table(net, tmp.name, tmp.valid_hooks,\n\t\t\t\t     &newinfo, &loc_cpu_entry, tmp.size,\n\t\t\t\t     tmp.num_entries, tmp.hook_entry,\n\t\t\t\t     tmp.underflow);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"compat_do_replace: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, compat_ptr(tmp.counters));\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter, net);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int\ncompat_do_ipt_set_ctl(struct sock *sk,\tint cmd, void __user *user,\n\t\t      unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IPT_SO_SET_REPLACE:\n\t\tret = compat_do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IPT_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 1);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_ipt_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstruct compat_ipt_get_entries {\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tcompat_uint_t size;\n\tstruct compat_ipt_entry entrytable[0];\n};\n\nstatic int\ncompat_copy_entries_to_user(unsigned int total_size, struct xt_table *table,\n\t\t\t    void __user *userptr)\n{\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tvoid __user *pos;\n\tunsigned int size;\n\tint ret = 0;\n\tunsigned int i = 0;\n\tstruct ipt_entry *iter;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tpos = userptr;\n\tsize = total_size;\n\txt_entry_foreach(iter, private->entries, total_size) {\n\t\tret = compat_copy_entry_to_user(iter, &pos,\n\t\t\t\t\t\t&size, counters, i++);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\n\tvfree(counters);\n\treturn ret;\n}\n\nstatic int\ncompat_get_entries(struct net *net, struct compat_ipt_get_entries __user *uptr,\n\t\t   int *len)\n{\n\tint ret;\n\tstruct compat_ipt_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"compat_get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\n\tif (*len != sizeof(struct compat_ipt_get_entries) + get.size) {\n\t\tduprintf(\"compat_get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\txt_compat_lock(AF_INET);\n\tt = xt_find_table_lock(net, AF_INET, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tstruct xt_table_info info;\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tret = compat_table_info(private, &info);\n\t\tif (!ret && get.size == info.size) {\n\t\t\tret = compat_copy_entries_to_user(private->size,\n\t\t\t\t\t\t\t  t, uptr->entrytable);\n\t\t} else if (!ret) {\n\t\t\tduprintf(\"compat_get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\txt_compat_flush_offsets(AF_INET);\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\txt_compat_unlock(AF_INET);\n\treturn ret;\n}\n\nstatic int do_ipt_get_ctl(struct sock *, int, void __user *, int *);\n\nstatic int\ncompat_do_ipt_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IPT_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 1);\n\t\tbreak;\n\tcase IPT_SO_GET_ENTRIES:\n\t\tret = compat_get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\tdefault:\n\t\tret = do_ipt_get_ctl(sk, cmd, user, len);\n\t}\n\treturn ret;\n}\n#endif\n\nstatic int\ndo_ipt_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IPT_SO_SET_REPLACE:\n\t\tret = do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IPT_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_ipt_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int\ndo_ipt_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IPT_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tcase IPT_SO_GET_ENTRIES:\n\t\tret = get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IPT_SO_GET_REVISION_MATCH:\n\tcase IPT_SO_GET_REVISION_TARGET: {\n\t\tstruct xt_get_revision rev;\n\t\tint target;\n\n\t\tif (*len != sizeof(rev)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&rev, user, sizeof(rev)) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\trev.name[sizeof(rev.name)-1] = 0;\n\n\t\tif (cmd == IPT_SO_GET_REVISION_TARGET)\n\t\t\ttarget = 1;\n\t\telse\n\t\t\ttarget = 0;\n\n\t\ttry_then_request_module(xt_find_revision(AF_INET, rev.name,\n\t\t\t\t\t\t\t rev.revision,\n\t\t\t\t\t\t\t target, &ret),\n\t\t\t\t\t\"ipt_%s\", rev.name);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tduprintf(\"do_ipt_get_ctl: unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic void __ipt_unregister_table(struct net *net, struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\tvoid *loc_cpu_entry;\n\tstruct module *table_owner = table->me;\n\tstruct ipt_entry *iter;\n\n\tprivate = xt_unregister_table(table);\n\n\t/* Decrease module usage counts and free resources */\n\tloc_cpu_entry = private->entries;\n\txt_entry_foreach(iter, loc_cpu_entry, private->size)\n\t\tcleanup_entry(iter, net);\n\tif (private->number > private->initial_entries)\n\t\tmodule_put(table_owner);\n\txt_free_table_info(private);\n}\n\nint ipt_register_table(struct net *net, const struct xt_table *table,\n\t\t       const struct ipt_replace *repl,\n\t\t       const struct nf_hook_ops *ops, struct xt_table **res)\n{\n\tint ret;\n\tstruct xt_table_info *newinfo;\n\tstruct xt_table_info bootstrap = {0};\n\tvoid *loc_cpu_entry;\n\tstruct xt_table *new_table;\n\n\tnewinfo = xt_alloc_table_info(repl->size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tmemcpy(loc_cpu_entry, repl->entries, repl->size);\n\n\tret = translate_table(net, newinfo, loc_cpu_entry, repl);\n\tif (ret != 0)\n\t\tgoto out_free;\n\n\tnew_table = xt_register_table(net, table, &bootstrap, newinfo);\n\tif (IS_ERR(new_table)) {\n\t\tret = PTR_ERR(new_table);\n\t\tgoto out_free;\n\t}\n\n\t/* set res now, will see skbs right after nf_register_net_hooks */\n\tWRITE_ONCE(*res, new_table);\n\n\tret = nf_register_net_hooks(net, ops, hweight32(table->valid_hooks));\n\tif (ret != 0) {\n\t\t__ipt_unregister_table(net, new_table);\n\t\t*res = NULL;\n\t}\n\n\treturn ret;\n\nout_free:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nvoid ipt_unregister_table(struct net *net, struct xt_table *table,\n\t\t\t  const struct nf_hook_ops *ops)\n{\n\tnf_unregister_net_hooks(net, ops, hweight32(table->valid_hooks));\n\t__ipt_unregister_table(net, table);\n}\n\n/* Returns 1 if the type and code is matched by the range, 0 otherwise */\nstatic inline bool\nicmp_type_code_match(u_int8_t test_type, u_int8_t min_code, u_int8_t max_code,\n\t\t     u_int8_t type, u_int8_t code,\n\t\t     bool invert)\n{\n\treturn ((test_type == 0xFF) ||\n\t\t(type == test_type && code >= min_code && code <= max_code))\n\t\t^ invert;\n}\n\nstatic bool\nicmp_match(const struct sk_buff *skb, struct xt_action_param *par)\n{\n\tconst struct icmphdr *ic;\n\tstruct icmphdr _icmph;\n\tconst struct ipt_icmp *icmpinfo = par->matchinfo;\n\n\t/* Must not be a fragment. */\n\tif (par->fragoff != 0)\n\t\treturn false;\n\n\tic = skb_header_pointer(skb, par->thoff, sizeof(_icmph), &_icmph);\n\tif (ic == NULL) {\n\t\t/* We've been asked to examine this packet, and we\n\t\t * can't.  Hence, no choice but to drop.\n\t\t */\n\t\tduprintf(\"Dropping evil ICMP tinygram.\\n\");\n\t\tpar->hotdrop = true;\n\t\treturn false;\n\t}\n\n\treturn icmp_type_code_match(icmpinfo->type,\n\t\t\t\t    icmpinfo->code[0],\n\t\t\t\t    icmpinfo->code[1],\n\t\t\t\t    ic->type, ic->code,\n\t\t\t\t    !!(icmpinfo->invflags&IPT_ICMP_INV));\n}\n\nstatic int icmp_checkentry(const struct xt_mtchk_param *par)\n{\n\tconst struct ipt_icmp *icmpinfo = par->matchinfo;\n\n\t/* Must specify no unknown invflags */\n\treturn (icmpinfo->invflags & ~IPT_ICMP_INV) ? -EINVAL : 0;\n}\n\nstatic struct xt_target ipt_builtin_tg[] __read_mostly = {\n\t{\n\t\t.name             = XT_STANDARD_TARGET,\n\t\t.targetsize       = sizeof(int),\n\t\t.family           = NFPROTO_IPV4,\n#ifdef CONFIG_COMPAT\n\t\t.compatsize       = sizeof(compat_int_t),\n\t\t.compat_from_user = compat_standard_from_user,\n\t\t.compat_to_user   = compat_standard_to_user,\n#endif\n\t},\n\t{\n\t\t.name             = XT_ERROR_TARGET,\n\t\t.target           = ipt_error,\n\t\t.targetsize       = XT_FUNCTION_MAXNAMELEN,\n\t\t.family           = NFPROTO_IPV4,\n\t},\n};\n\nstatic struct nf_sockopt_ops ipt_sockopts = {\n\t.pf\t\t= PF_INET,\n\t.set_optmin\t= IPT_BASE_CTL,\n\t.set_optmax\t= IPT_SO_SET_MAX+1,\n\t.set\t\t= do_ipt_set_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_set\t= compat_do_ipt_set_ctl,\n#endif\n\t.get_optmin\t= IPT_BASE_CTL,\n\t.get_optmax\t= IPT_SO_GET_MAX+1,\n\t.get\t\t= do_ipt_get_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_get\t= compat_do_ipt_get_ctl,\n#endif\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic struct xt_match ipt_builtin_mt[] __read_mostly = {\n\t{\n\t\t.name       = \"icmp\",\n\t\t.match      = icmp_match,\n\t\t.matchsize  = sizeof(struct ipt_icmp),\n\t\t.checkentry = icmp_checkentry,\n\t\t.proto      = IPPROTO_ICMP,\n\t\t.family     = NFPROTO_IPV4,\n\t},\n};\n\nstatic int __net_init ip_tables_net_init(struct net *net)\n{\n\treturn xt_proto_init(net, NFPROTO_IPV4);\n}\n\nstatic void __net_exit ip_tables_net_exit(struct net *net)\n{\n\txt_proto_fini(net, NFPROTO_IPV4);\n}\n\nstatic struct pernet_operations ip_tables_net_ops = {\n\t.init = ip_tables_net_init,\n\t.exit = ip_tables_net_exit,\n};\n\nstatic int __init ip_tables_init(void)\n{\n\tint ret;\n\n\tret = register_pernet_subsys(&ip_tables_net_ops);\n\tif (ret < 0)\n\t\tgoto err1;\n\n\t/* No one else will be downing sem now, so we won't sleep */\n\tret = xt_register_targets(ipt_builtin_tg, ARRAY_SIZE(ipt_builtin_tg));\n\tif (ret < 0)\n\t\tgoto err2;\n\tret = xt_register_matches(ipt_builtin_mt, ARRAY_SIZE(ipt_builtin_mt));\n\tif (ret < 0)\n\t\tgoto err4;\n\n\t/* Register setsockopt */\n\tret = nf_register_sockopt(&ipt_sockopts);\n\tif (ret < 0)\n\t\tgoto err5;\n\n\tpr_info(\"(C) 2000-2006 Netfilter Core Team\\n\");\n\treturn 0;\n\nerr5:\n\txt_unregister_matches(ipt_builtin_mt, ARRAY_SIZE(ipt_builtin_mt));\nerr4:\n\txt_unregister_targets(ipt_builtin_tg, ARRAY_SIZE(ipt_builtin_tg));\nerr2:\n\tunregister_pernet_subsys(&ip_tables_net_ops);\nerr1:\n\treturn ret;\n}\n\nstatic void __exit ip_tables_fini(void)\n{\n\tnf_unregister_sockopt(&ipt_sockopts);\n\n\txt_unregister_matches(ipt_builtin_mt, ARRAY_SIZE(ipt_builtin_mt));\n\txt_unregister_targets(ipt_builtin_tg, ARRAY_SIZE(ipt_builtin_tg));\n\tunregister_pernet_subsys(&ip_tables_net_ops);\n}\n\nEXPORT_SYMBOL(ipt_register_table);\nEXPORT_SYMBOL(ipt_unregister_table);\nEXPORT_SYMBOL(ipt_do_table);\nmodule_init(ip_tables_init);\nmodule_exit(ip_tables_fini);\n", "/*\n * Packet matching code.\n *\n * Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling\n * Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>\n * Copyright (c) 2006-2010 Patrick McHardy <kaber@trash.net>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n */\n\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n\n#include <linux/kernel.h>\n#include <linux/capability.h>\n#include <linux/in.h>\n#include <linux/skbuff.h>\n#include <linux/kmod.h>\n#include <linux/vmalloc.h>\n#include <linux/netdevice.h>\n#include <linux/module.h>\n#include <linux/poison.h>\n#include <linux/icmpv6.h>\n#include <net/ipv6.h>\n#include <net/compat.h>\n#include <asm/uaccess.h>\n#include <linux/mutex.h>\n#include <linux/proc_fs.h>\n#include <linux/err.h>\n#include <linux/cpumask.h>\n\n#include <linux/netfilter_ipv6/ip6_tables.h>\n#include <linux/netfilter/x_tables.h>\n#include <net/netfilter/nf_log.h>\n#include \"../../netfilter/xt_repldata.h\"\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Netfilter Core Team <coreteam@netfilter.org>\");\nMODULE_DESCRIPTION(\"IPv6 packet filter\");\n\n/*#define DEBUG_IP_FIREWALL*/\n/*#define DEBUG_ALLOW_ALL*/ /* Useful for remote debugging */\n/*#define DEBUG_IP_FIREWALL_USER*/\n\n#ifdef DEBUG_IP_FIREWALL\n#define dprintf(format, args...) pr_info(format , ## args)\n#else\n#define dprintf(format, args...)\n#endif\n\n#ifdef DEBUG_IP_FIREWALL_USER\n#define duprintf(format, args...) pr_info(format , ## args)\n#else\n#define duprintf(format, args...)\n#endif\n\n#ifdef CONFIG_NETFILTER_DEBUG\n#define IP_NF_ASSERT(x)\tWARN_ON(!(x))\n#else\n#define IP_NF_ASSERT(x)\n#endif\n\n#if 0\n/* All the better to debug you with... */\n#define static\n#define inline\n#endif\n\nvoid *ip6t_alloc_initial_table(const struct xt_table *info)\n{\n\treturn xt_alloc_initial_table(ip6t, IP6T);\n}\nEXPORT_SYMBOL_GPL(ip6t_alloc_initial_table);\n\n/*\n   We keep a set of rules for each CPU, so we can avoid write-locking\n   them in the softirq when updating the counters and therefore\n   only need to read-lock in the softirq; doing a write_lock_bh() in user\n   context stops packets coming through and allows user context to read\n   the counters or update the rules.\n\n   Hence the start of any table is given by get_table() below.  */\n\n/* Returns whether matches rule or not. */\n/* Performance critical - called for every packet */\nstatic inline bool\nip6_packet_match(const struct sk_buff *skb,\n\t\t const char *indev,\n\t\t const char *outdev,\n\t\t const struct ip6t_ip6 *ip6info,\n\t\t unsigned int *protoff,\n\t\t int *fragoff, bool *hotdrop)\n{\n\tunsigned long ret;\n\tconst struct ipv6hdr *ipv6 = ipv6_hdr(skb);\n\n#define FWINV(bool, invflg) ((bool) ^ !!(ip6info->invflags & (invflg)))\n\n\tif (FWINV(ipv6_masked_addr_cmp(&ipv6->saddr, &ip6info->smsk,\n\t\t\t\t       &ip6info->src), IP6T_INV_SRCIP) ||\n\t    FWINV(ipv6_masked_addr_cmp(&ipv6->daddr, &ip6info->dmsk,\n\t\t\t\t       &ip6info->dst), IP6T_INV_DSTIP)) {\n\t\tdprintf(\"Source or dest mismatch.\\n\");\n/*\n\t\tdprintf(\"SRC: %u. Mask: %u. Target: %u.%s\\n\", ip->saddr,\n\t\t\tipinfo->smsk.s_addr, ipinfo->src.s_addr,\n\t\t\tipinfo->invflags & IP6T_INV_SRCIP ? \" (INV)\" : \"\");\n\t\tdprintf(\"DST: %u. Mask: %u. Target: %u.%s\\n\", ip->daddr,\n\t\t\tipinfo->dmsk.s_addr, ipinfo->dst.s_addr,\n\t\t\tipinfo->invflags & IP6T_INV_DSTIP ? \" (INV)\" : \"\");*/\n\t\treturn false;\n\t}\n\n\tret = ifname_compare_aligned(indev, ip6info->iniface, ip6info->iniface_mask);\n\n\tif (FWINV(ret != 0, IP6T_INV_VIA_IN)) {\n\t\tdprintf(\"VIA in mismatch (%s vs %s).%s\\n\",\n\t\t\tindev, ip6info->iniface,\n\t\t\tip6info->invflags & IP6T_INV_VIA_IN ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n\tret = ifname_compare_aligned(outdev, ip6info->outiface, ip6info->outiface_mask);\n\n\tif (FWINV(ret != 0, IP6T_INV_VIA_OUT)) {\n\t\tdprintf(\"VIA out mismatch (%s vs %s).%s\\n\",\n\t\t\toutdev, ip6info->outiface,\n\t\t\tip6info->invflags & IP6T_INV_VIA_OUT ? \" (INV)\" : \"\");\n\t\treturn false;\n\t}\n\n/* ... might want to do something with class and flowlabel here ... */\n\n\t/* look for the desired protocol header */\n\tif (ip6info->flags & IP6T_F_PROTO) {\n\t\tint protohdr;\n\t\tunsigned short _frag_off;\n\n\t\tprotohdr = ipv6_find_hdr(skb, protoff, -1, &_frag_off, NULL);\n\t\tif (protohdr < 0) {\n\t\t\tif (_frag_off == 0)\n\t\t\t\t*hotdrop = true;\n\t\t\treturn false;\n\t\t}\n\t\t*fragoff = _frag_off;\n\n\t\tdprintf(\"Packet protocol %hi ?= %s%hi.\\n\",\n\t\t\t\tprotohdr,\n\t\t\t\tip6info->invflags & IP6T_INV_PROTO ? \"!\":\"\",\n\t\t\t\tip6info->proto);\n\n\t\tif (ip6info->proto == protohdr) {\n\t\t\tif (ip6info->invflags & IP6T_INV_PROTO)\n\t\t\t\treturn false;\n\n\t\t\treturn true;\n\t\t}\n\n\t\t/* We need match for the '-p all', too! */\n\t\tif ((ip6info->proto != 0) &&\n\t\t\t!(ip6info->invflags & IP6T_INV_PROTO))\n\t\t\treturn false;\n\t}\n\treturn true;\n}\n\n/* should be ip6 safe */\nstatic bool\nip6_checkentry(const struct ip6t_ip6 *ipv6)\n{\n\tif (ipv6->flags & ~IP6T_F_MASK) {\n\t\tduprintf(\"Unknown flag bits set: %08X\\n\",\n\t\t\t ipv6->flags & ~IP6T_F_MASK);\n\t\treturn false;\n\t}\n\tif (ipv6->invflags & ~IP6T_INV_MASK) {\n\t\tduprintf(\"Unknown invflag bits set: %08X\\n\",\n\t\t\t ipv6->invflags & ~IP6T_INV_MASK);\n\t\treturn false;\n\t}\n\treturn true;\n}\n\nstatic unsigned int\nip6t_error(struct sk_buff *skb, const struct xt_action_param *par)\n{\n\tnet_info_ratelimited(\"error: `%s'\\n\", (const char *)par->targinfo);\n\n\treturn NF_DROP;\n}\n\nstatic inline struct ip6t_entry *\nget_entry(const void *base, unsigned int offset)\n{\n\treturn (struct ip6t_entry *)(base + offset);\n}\n\n/* All zeroes == unconditional rule. */\n/* Mildly perf critical (only if packet tracing is on) */\nstatic inline bool unconditional(const struct ip6t_entry *e)\n{\n\tstatic const struct ip6t_ip6 uncond;\n\n\treturn e->target_offset == sizeof(struct ip6t_entry) &&\n\t       memcmp(&e->ipv6, &uncond, sizeof(uncond)) == 0;\n}\n\nstatic inline const struct xt_entry_target *\nip6t_get_target_c(const struct ip6t_entry *e)\n{\n\treturn ip6t_get_target((struct ip6t_entry *)e);\n}\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n/* This cries for unification! */\nstatic const char *const hooknames[] = {\n\t[NF_INET_PRE_ROUTING]\t\t= \"PREROUTING\",\n\t[NF_INET_LOCAL_IN]\t\t= \"INPUT\",\n\t[NF_INET_FORWARD]\t\t= \"FORWARD\",\n\t[NF_INET_LOCAL_OUT]\t\t= \"OUTPUT\",\n\t[NF_INET_POST_ROUTING]\t\t= \"POSTROUTING\",\n};\n\nenum nf_ip_trace_comments {\n\tNF_IP6_TRACE_COMMENT_RULE,\n\tNF_IP6_TRACE_COMMENT_RETURN,\n\tNF_IP6_TRACE_COMMENT_POLICY,\n};\n\nstatic const char *const comments[] = {\n\t[NF_IP6_TRACE_COMMENT_RULE]\t= \"rule\",\n\t[NF_IP6_TRACE_COMMENT_RETURN]\t= \"return\",\n\t[NF_IP6_TRACE_COMMENT_POLICY]\t= \"policy\",\n};\n\nstatic struct nf_loginfo trace_loginfo = {\n\t.type = NF_LOG_TYPE_LOG,\n\t.u = {\n\t\t.log = {\n\t\t\t.level = LOGLEVEL_WARNING,\n\t\t\t.logflags = NF_LOG_MASK,\n\t\t},\n\t},\n};\n\n/* Mildly perf critical (only if packet tracing is on) */\nstatic inline int\nget_chainname_rulenum(const struct ip6t_entry *s, const struct ip6t_entry *e,\n\t\t      const char *hookname, const char **chainname,\n\t\t      const char **comment, unsigned int *rulenum)\n{\n\tconst struct xt_standard_target *t = (void *)ip6t_get_target_c(s);\n\n\tif (strcmp(t->target.u.kernel.target->name, XT_ERROR_TARGET) == 0) {\n\t\t/* Head of user chain: ERROR target with chainname */\n\t\t*chainname = t->target.data;\n\t\t(*rulenum) = 0;\n\t} else if (s == e) {\n\t\t(*rulenum)++;\n\n\t\tif (unconditional(s) &&\n\t\t    strcmp(t->target.u.kernel.target->name,\n\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t    t->verdict < 0) {\n\t\t\t/* Tail of chains: STANDARD target (return/policy) */\n\t\t\t*comment = *chainname == hookname\n\t\t\t\t? comments[NF_IP6_TRACE_COMMENT_POLICY]\n\t\t\t\t: comments[NF_IP6_TRACE_COMMENT_RETURN];\n\t\t}\n\t\treturn 1;\n\t} else\n\t\t(*rulenum)++;\n\n\treturn 0;\n}\n\nstatic void trace_packet(struct net *net,\n\t\t\t const struct sk_buff *skb,\n\t\t\t unsigned int hook,\n\t\t\t const struct net_device *in,\n\t\t\t const struct net_device *out,\n\t\t\t const char *tablename,\n\t\t\t const struct xt_table_info *private,\n\t\t\t const struct ip6t_entry *e)\n{\n\tconst struct ip6t_entry *root;\n\tconst char *hookname, *chainname, *comment;\n\tconst struct ip6t_entry *iter;\n\tunsigned int rulenum = 0;\n\n\troot = get_entry(private->entries, private->hook_entry[hook]);\n\n\thookname = chainname = hooknames[hook];\n\tcomment = comments[NF_IP6_TRACE_COMMENT_RULE];\n\n\txt_entry_foreach(iter, root, private->size - private->hook_entry[hook])\n\t\tif (get_chainname_rulenum(iter, e, hookname,\n\t\t    &chainname, &comment, &rulenum) != 0)\n\t\t\tbreak;\n\n\tnf_log_trace(net, AF_INET6, hook, skb, in, out, &trace_loginfo,\n\t\t     \"TRACE: %s:%s:%s:%u \",\n\t\t     tablename, chainname, comment, rulenum);\n}\n#endif\n\nstatic inline struct ip6t_entry *\nip6t_next_entry(const struct ip6t_entry *entry)\n{\n\treturn (void *)entry + entry->next_offset;\n}\n\n/* Returns one of the generic firewall policies, like NF_ACCEPT. */\nunsigned int\nip6t_do_table(struct sk_buff *skb,\n\t      const struct nf_hook_state *state,\n\t      struct xt_table *table)\n{\n\tunsigned int hook = state->hook;\n\tstatic const char nulldevname[IFNAMSIZ] __attribute__((aligned(sizeof(long))));\n\t/* Initializing verdict to NF_DROP keeps gcc happy. */\n\tunsigned int verdict = NF_DROP;\n\tconst char *indev, *outdev;\n\tconst void *table_base;\n\tstruct ip6t_entry *e, **jumpstack;\n\tunsigned int stackidx, cpu;\n\tconst struct xt_table_info *private;\n\tstruct xt_action_param acpar;\n\tunsigned int addend;\n\n\t/* Initialization */\n\tstackidx = 0;\n\tindev = state->in ? state->in->name : nulldevname;\n\toutdev = state->out ? state->out->name : nulldevname;\n\t/* We handle fragments by dealing with the first fragment as\n\t * if it was a normal packet.  All other fragments are treated\n\t * normally, except that they will NEVER match rules that ask\n\t * things we don't know, ie. tcp syn flag or ports).  If the\n\t * rule is also a fragment-specific rule, non-fragments won't\n\t * match it. */\n\tacpar.hotdrop = false;\n\tacpar.net     = state->net;\n\tacpar.in      = state->in;\n\tacpar.out     = state->out;\n\tacpar.family  = NFPROTO_IPV6;\n\tacpar.hooknum = hook;\n\n\tIP_NF_ASSERT(table->valid_hooks & (1 << hook));\n\n\tlocal_bh_disable();\n\taddend = xt_write_recseq_begin();\n\tprivate = table->private;\n\t/*\n\t * Ensure we load private-> members after we've fetched the base\n\t * pointer.\n\t */\n\tsmp_read_barrier_depends();\n\tcpu        = smp_processor_id();\n\ttable_base = private->entries;\n\tjumpstack  = (struct ip6t_entry **)private->jumpstack[cpu];\n\n\t/* Switch to alternate jumpstack if we're being invoked via TEE.\n\t * TEE issues XT_CONTINUE verdict on original skb so we must not\n\t * clobber the jumpstack.\n\t *\n\t * For recursion via REJECT or SYNPROXY the stack will be clobbered\n\t * but it is no problem since absolute verdict is issued by these.\n\t */\n\tif (static_key_false(&xt_tee_enabled))\n\t\tjumpstack += private->stacksize * __this_cpu_read(nf_skb_duplicated);\n\n\te = get_entry(table_base, private->hook_entry[hook]);\n\n\tdo {\n\t\tconst struct xt_entry_target *t;\n\t\tconst struct xt_entry_match *ematch;\n\t\tstruct xt_counters *counter;\n\n\t\tIP_NF_ASSERT(e);\n\t\tacpar.thoff = 0;\n\t\tif (!ip6_packet_match(skb, indev, outdev, &e->ipv6,\n\t\t    &acpar.thoff, &acpar.fragoff, &acpar.hotdrop)) {\n no_match:\n\t\t\te = ip6t_next_entry(e);\n\t\t\tcontinue;\n\t\t}\n\n\t\txt_ematch_foreach(ematch, e) {\n\t\t\tacpar.match     = ematch->u.kernel.match;\n\t\t\tacpar.matchinfo = ematch->data;\n\t\t\tif (!acpar.match->match(skb, &acpar))\n\t\t\t\tgoto no_match;\n\t\t}\n\n\t\tcounter = xt_get_this_cpu_counter(&e->counters);\n\t\tADD_COUNTER(*counter, skb->len, 1);\n\n\t\tt = ip6t_get_target_c(e);\n\t\tIP_NF_ASSERT(t->u.kernel.target);\n\n#if IS_ENABLED(CONFIG_NETFILTER_XT_TARGET_TRACE)\n\t\t/* The packet is traced: log it */\n\t\tif (unlikely(skb->nf_trace))\n\t\t\ttrace_packet(state->net, skb, hook, state->in,\n\t\t\t\t     state->out, table->name, private, e);\n#endif\n\t\t/* Standard target? */\n\t\tif (!t->u.kernel.target->target) {\n\t\t\tint v;\n\n\t\t\tv = ((struct xt_standard_target *)t)->verdict;\n\t\t\tif (v < 0) {\n\t\t\t\t/* Pop from stack? */\n\t\t\t\tif (v != XT_RETURN) {\n\t\t\t\t\tverdict = (unsigned int)(-v) - 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (stackidx == 0)\n\t\t\t\t\te = get_entry(table_base,\n\t\t\t\t\t    private->underflow[hook]);\n\t\t\t\telse\n\t\t\t\t\te = ip6t_next_entry(jumpstack[--stackidx]);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (table_base + v != ip6t_next_entry(e) &&\n\t\t\t    !(e->ipv6.flags & IP6T_F_GOTO)) {\n\t\t\t\tjumpstack[stackidx++] = e;\n\t\t\t}\n\n\t\t\te = get_entry(table_base, v);\n\t\t\tcontinue;\n\t\t}\n\n\t\tacpar.target   = t->u.kernel.target;\n\t\tacpar.targinfo = t->data;\n\n\t\tverdict = t->u.kernel.target->target(skb, &acpar);\n\t\tif (verdict == XT_CONTINUE)\n\t\t\te = ip6t_next_entry(e);\n\t\telse\n\t\t\t/* Verdict */\n\t\t\tbreak;\n\t} while (!acpar.hotdrop);\n\n\txt_write_recseq_end(addend);\n\tlocal_bh_enable();\n\n#ifdef DEBUG_ALLOW_ALL\n\treturn NF_ACCEPT;\n#else\n\tif (acpar.hotdrop)\n\t\treturn NF_DROP;\n\telse return verdict;\n#endif\n}\n\nstatic bool find_jump_target(const struct xt_table_info *t,\n\t\t\t     const struct ip6t_entry *target)\n{\n\tstruct ip6t_entry *iter;\n\n\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t if (iter == target)\n\t\t\treturn true;\n\t}\n\treturn false;\n}\n\n/* Figures out from what hook each rule can be called: returns 0 if\n   there are loops.  Puts hook bitmask in comefrom. */\nstatic int\nmark_source_chains(const struct xt_table_info *newinfo,\n\t\t   unsigned int valid_hooks, void *entry0)\n{\n\tunsigned int hook;\n\n\t/* No recursion; use packet counter to save back ptrs (reset\n\t   to 0 as we leave), and comefrom to save source hook bitmask */\n\tfor (hook = 0; hook < NF_INET_NUMHOOKS; hook++) {\n\t\tunsigned int pos = newinfo->hook_entry[hook];\n\t\tstruct ip6t_entry *e = (struct ip6t_entry *)(entry0 + pos);\n\n\t\tif (!(valid_hooks & (1 << hook)))\n\t\t\tcontinue;\n\n\t\t/* Set initial back pointer. */\n\t\te->counters.pcnt = pos;\n\n\t\tfor (;;) {\n\t\t\tconst struct xt_standard_target *t\n\t\t\t\t= (void *)ip6t_get_target_c(e);\n\t\t\tint visited = e->comefrom & (1 << hook);\n\n\t\t\tif (e->comefrom & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\tpr_err(\"iptables: loop hook %u pos %u %08X.\\n\",\n\t\t\t\t       hook, pos, e->comefrom);\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\te->comefrom |= ((1 << hook) | (1 << NF_INET_NUMHOOKS));\n\n\t\t\t/* Unconditional return/END. */\n\t\t\tif ((unconditional(e) &&\n\t\t\t     (strcmp(t->target.u.user.name,\n\t\t\t\t     XT_STANDARD_TARGET) == 0) &&\n\t\t\t     t->verdict < 0) || visited) {\n\t\t\t\tunsigned int oldpos, size;\n\n\t\t\t\tif ((strcmp(t->target.u.user.name,\n\t\t\t\t\t    XT_STANDARD_TARGET) == 0) &&\n\t\t\t\t    t->verdict < -NF_MAX_VERDICT - 1) {\n\t\t\t\t\tduprintf(\"mark_source_chains: bad \"\n\t\t\t\t\t\t\"negative verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tt->verdict);\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\n\t\t\t\t/* Return: backtrack through the last\n\t\t\t\t   big jump. */\n\t\t\t\tdo {\n\t\t\t\t\te->comefrom ^= (1<<NF_INET_NUMHOOKS);\n#ifdef DEBUG_IP_FIREWALL_USER\n\t\t\t\t\tif (e->comefrom\n\t\t\t\t\t    & (1 << NF_INET_NUMHOOKS)) {\n\t\t\t\t\t\tduprintf(\"Back unset \"\n\t\t\t\t\t\t\t \"on hook %u \"\n\t\t\t\t\t\t\t \"rule %u\\n\",\n\t\t\t\t\t\t\t hook, pos);\n\t\t\t\t\t}\n#endif\n\t\t\t\t\toldpos = pos;\n\t\t\t\t\tpos = e->counters.pcnt;\n\t\t\t\t\te->counters.pcnt = 0;\n\n\t\t\t\t\t/* We're at the start. */\n\t\t\t\t\tif (pos == oldpos)\n\t\t\t\t\t\tgoto next;\n\n\t\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t\t(entry0 + pos);\n\t\t\t\t} while (oldpos == pos + e->next_offset);\n\n\t\t\t\t/* Move along one */\n\t\t\t\tsize = e->next_offset;\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + pos + size);\n\t\t\t\tif (pos + size >= newinfo->size)\n\t\t\t\t\treturn 0;\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos += size;\n\t\t\t} else {\n\t\t\t\tint newpos = t->verdict;\n\n\t\t\t\tif (strcmp(t->target.u.user.name,\n\t\t\t\t\t   XT_STANDARD_TARGET) == 0 &&\n\t\t\t\t    newpos >= 0) {\n\t\t\t\t\tif (newpos > newinfo->size -\n\t\t\t\t\t\tsizeof(struct ip6t_entry)) {\n\t\t\t\t\t\tduprintf(\"mark_source_chains: \"\n\t\t\t\t\t\t\t\"bad verdict (%i)\\n\",\n\t\t\t\t\t\t\t\tnewpos);\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t}\n\t\t\t\t\t/* This a jump; chase it. */\n\t\t\t\t\tduprintf(\"Jump rule %u -> %u\\n\",\n\t\t\t\t\t\t pos, newpos);\n\t\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t\t(entry0 + newpos);\n\t\t\t\t\tif (!find_jump_target(newinfo, e))\n\t\t\t\t\t\treturn 0;\n\t\t\t\t} else {\n\t\t\t\t\t/* ... this is a fallthru */\n\t\t\t\t\tnewpos = pos + e->next_offset;\n\t\t\t\t\tif (newpos >= newinfo->size)\n\t\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\te = (struct ip6t_entry *)\n\t\t\t\t\t(entry0 + newpos);\n\t\t\t\te->counters.pcnt = pos;\n\t\t\t\tpos = newpos;\n\t\t\t}\n\t\t}\nnext:\n\t\tduprintf(\"Finished chain %u\\n\", hook);\n\t}\n\treturn 1;\n}\n\nstatic void cleanup_match(struct xt_entry_match *m, struct net *net)\n{\n\tstruct xt_mtdtor_param par;\n\n\tpar.net       = net;\n\tpar.match     = m->u.kernel.match;\n\tpar.matchinfo = m->data;\n\tpar.family    = NFPROTO_IPV6;\n\tif (par.match->destroy != NULL)\n\t\tpar.match->destroy(&par);\n\tmodule_put(par.match->me);\n}\n\nstatic int check_match(struct xt_entry_match *m, struct xt_mtchk_param *par)\n{\n\tconst struct ip6t_ip6 *ipv6 = par->entryinfo;\n\tint ret;\n\n\tpar->match     = m->u.kernel.match;\n\tpar->matchinfo = m->data;\n\n\tret = xt_check_match(par, m->u.match_size - sizeof(*m),\n\t\t\t     ipv6->proto, ipv6->invflags & IP6T_INV_PROTO);\n\tif (ret < 0) {\n\t\tduprintf(\"ip_tables: check failed for `%s'.\\n\",\n\t\t\t par.match->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int\nfind_check_match(struct xt_entry_match *m, struct xt_mtchk_param *par)\n{\n\tstruct xt_match *match;\n\tint ret;\n\n\tmatch = xt_request_find_match(NFPROTO_IPV6, m->u.user.name,\n\t\t\t\t      m->u.user.revision);\n\tif (IS_ERR(match)) {\n\t\tduprintf(\"find_check_match: `%s' not found\\n\", m->u.user.name);\n\t\treturn PTR_ERR(match);\n\t}\n\tm->u.kernel.match = match;\n\n\tret = check_match(m, par);\n\tif (ret)\n\t\tgoto err;\n\n\treturn 0;\nerr:\n\tmodule_put(m->u.kernel.match->me);\n\treturn ret;\n}\n\nstatic int check_target(struct ip6t_entry *e, struct net *net, const char *name)\n{\n\tstruct xt_entry_target *t = ip6t_get_target(e);\n\tstruct xt_tgchk_param par = {\n\t\t.net       = net,\n\t\t.table     = name,\n\t\t.entryinfo = e,\n\t\t.target    = t->u.kernel.target,\n\t\t.targinfo  = t->data,\n\t\t.hook_mask = e->comefrom,\n\t\t.family    = NFPROTO_IPV6,\n\t};\n\tint ret;\n\n\tt = ip6t_get_target(e);\n\tret = xt_check_target(&par, t->u.target_size - sizeof(*t),\n\t      e->ipv6.proto, e->ipv6.invflags & IP6T_INV_PROTO);\n\tif (ret < 0) {\n\t\tduprintf(\"ip_tables: check failed for `%s'.\\n\",\n\t\t\t t->u.kernel.target->name);\n\t\treturn ret;\n\t}\n\treturn 0;\n}\n\nstatic int\nfind_check_entry(struct ip6t_entry *e, struct net *net, const char *name,\n\t\t unsigned int size)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tint ret;\n\tunsigned int j;\n\tstruct xt_mtchk_param mtpar;\n\tstruct xt_entry_match *ematch;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\n\tj = 0;\n\tmtpar.net\t= net;\n\tmtpar.table     = name;\n\tmtpar.entryinfo = &e->ipv6;\n\tmtpar.hook_mask = e->comefrom;\n\tmtpar.family    = NFPROTO_IPV6;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = find_check_match(ematch, &mtpar);\n\t\tif (ret != 0)\n\t\t\tgoto cleanup_matches;\n\t\t++j;\n\t}\n\n\tt = ip6t_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"find_check_entry: `%s' not found\\n\", t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto cleanup_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\tret = check_target(e, net, name);\n\tif (ret)\n\t\tgoto err;\n\treturn 0;\n err:\n\tmodule_put(t->u.kernel.target->me);\n cleanup_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcleanup_match(ematch, net);\n\t}\n\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic bool check_underflow(const struct ip6t_entry *e)\n{\n\tconst struct xt_entry_target *t;\n\tunsigned int verdict;\n\n\tif (!unconditional(e))\n\t\treturn false;\n\tt = ip6t_get_target_c(e);\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) != 0)\n\t\treturn false;\n\tverdict = ((struct xt_standard_target *)t)->verdict;\n\tverdict = -verdict - 1;\n\treturn verdict == NF_DROP || verdict == NF_ACCEPT;\n}\n\nstatic int\ncheck_entry_size_and_hooks(struct ip6t_entry *e,\n\t\t\t   struct xt_table_info *newinfo,\n\t\t\t   const unsigned char *base,\n\t\t\t   const unsigned char *limit,\n\t\t\t   const unsigned int *hook_entries,\n\t\t\t   const unsigned int *underflows,\n\t\t\t   unsigned int valid_hooks)\n{\n\tunsigned int h;\n\tint err;\n\n\tif ((unsigned long)e % __alignof__(struct ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p\\n\", e);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset\n\t    < sizeof(struct ip6t_entry) + sizeof(struct xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\terr = xt_check_entry_offsets(e, e->elems, e->target_offset,\n\t\t\t\t     e->next_offset);\n\tif (err)\n\t\treturn err;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif (!(valid_hooks & (1 << h)))\n\t\t\tcontinue;\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h]) {\n\t\t\tif (!check_underflow(e)) {\n\t\t\t\tpr_debug(\"Underflows must be unconditional and \"\n\t\t\t\t\t \"use the STANDARD target with \"\n\t\t\t\t\t \"ACCEPT/DROP\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t\t}\n\t}\n\n\t/* Clear counters and comefrom */\n\te->counters = ((struct xt_counters) { 0, 0 });\n\te->comefrom = 0;\n\treturn 0;\n}\n\nstatic void cleanup_entry(struct ip6t_entry *e, struct net *net)\n{\n\tstruct xt_tgdtor_param par;\n\tstruct xt_entry_target *t;\n\tstruct xt_entry_match *ematch;\n\n\t/* Cleanup all matches */\n\txt_ematch_foreach(ematch, e)\n\t\tcleanup_match(ematch, net);\n\tt = ip6t_get_target(e);\n\n\tpar.net      = net;\n\tpar.target   = t->u.kernel.target;\n\tpar.targinfo = t->data;\n\tpar.family   = NFPROTO_IPV6;\n\tif (par.target->destroy != NULL)\n\t\tpar.target->destroy(&par);\n\tmodule_put(par.target->me);\n\n\txt_percpu_counter_free(e->counters.pcnt);\n}\n\n/* Checks and translates the user-supplied table segment (held in\n   newinfo) */\nstatic int\ntranslate_table(struct net *net, struct xt_table_info *newinfo, void *entry0,\n\t\tconst struct ip6t_replace *repl)\n{\n\tstruct ip6t_entry *iter;\n\tunsigned int i;\n\tint ret = 0;\n\n\tnewinfo->size = repl->size;\n\tnewinfo->number = repl->num_entries;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tnewinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_table: size %u\\n\", newinfo->size);\n\ti = 0;\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = check_entry_size_and_hooks(iter, newinfo, entry0,\n\t\t\t\t\t\t entry0 + repl->size,\n\t\t\t\t\t\t repl->hook_entry,\n\t\t\t\t\t\t repl->underflow,\n\t\t\t\t\t\t repl->valid_hooks);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t\t++i;\n\t\tif (strcmp(ip6t_get_target(iter)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\n\tif (i != repl->num_entries) {\n\t\tduprintf(\"translate_table: %u not %u entries\\n\",\n\t\t\t i, repl->num_entries);\n\t\treturn -EINVAL;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(repl->valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (newinfo->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, repl->hook_entry[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t\tif (newinfo->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, repl->underflow[i]);\n\t\t\treturn -EINVAL;\n\t\t}\n\t}\n\n\tif (!mark_source_chains(newinfo, repl->valid_hooks, entry0))\n\t\treturn -ELOOP;\n\n\t/* Finally, each sanity check must pass */\n\ti = 0;\n\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\tret = find_check_entry(iter, net, repl->name, repl->size);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t}\n\n\tif (ret != 0) {\n\t\txt_entry_foreach(iter, entry0, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter, net);\n\t\t}\n\t\treturn ret;\n\t}\n\n\treturn ret;\n}\n\nstatic void\nget_counters(const struct xt_table_info *t,\n\t     struct xt_counters counters[])\n{\n\tstruct ip6t_entry *iter;\n\tunsigned int cpu;\n\tunsigned int i;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tseqcount_t *s = &per_cpu(xt_recseq, cpu);\n\n\t\ti = 0;\n\t\txt_entry_foreach(iter, t->entries, t->size) {\n\t\t\tstruct xt_counters *tmp;\n\t\t\tu64 bcnt, pcnt;\n\t\t\tunsigned int start;\n\n\t\t\ttmp = xt_get_per_cpu_counter(&iter->counters, cpu);\n\t\t\tdo {\n\t\t\t\tstart = read_seqcount_begin(s);\n\t\t\t\tbcnt = tmp->bcnt;\n\t\t\t\tpcnt = tmp->pcnt;\n\t\t\t} while (read_seqcount_retry(s, start));\n\n\t\t\tADD_COUNTER(counters[i], bcnt, pcnt);\n\t\t\t++i;\n\t\t}\n\t}\n}\n\nstatic struct xt_counters *alloc_counters(const struct xt_table *table)\n{\n\tunsigned int countersize;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\n\t/* We need atomic snapshot of counters: rest doesn't change\n\t   (other than comefrom, which userspace doesn't care\n\t   about). */\n\tcountersize = sizeof(struct xt_counters) * private->number;\n\tcounters = vzalloc(countersize);\n\n\tif (counters == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tget_counters(private, counters);\n\n\treturn counters;\n}\n\nstatic int\ncopy_entries_to_user(unsigned int total_size,\n\t\t     const struct xt_table *table,\n\t\t     void __user *userptr)\n{\n\tunsigned int off, num;\n\tconst struct ip6t_entry *e;\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tint ret = 0;\n\tconst void *loc_cpu_entry;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tloc_cpu_entry = private->entries;\n\tif (copy_to_user(userptr, loc_cpu_entry, total_size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_counters;\n\t}\n\n\t/* FIXME: use iterator macros --RR */\n\t/* ... then go back and fix counters and names */\n\tfor (off = 0, num = 0; off < total_size; off += e->next_offset, num++){\n\t\tunsigned int i;\n\t\tconst struct xt_entry_match *m;\n\t\tconst struct xt_entry_target *t;\n\n\t\te = (struct ip6t_entry *)(loc_cpu_entry + off);\n\t\tif (copy_to_user(userptr + off\n\t\t\t\t + offsetof(struct ip6t_entry, counters),\n\t\t\t\t &counters[num],\n\t\t\t\t sizeof(counters[num])) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\n\t\tfor (i = sizeof(struct ip6t_entry);\n\t\t     i < e->target_offset;\n\t\t     i += m->u.match_size) {\n\t\t\tm = (void *)e + i;\n\n\t\t\tif (copy_to_user(userptr + off + i\n\t\t\t\t\t + offsetof(struct xt_entry_match,\n\t\t\t\t\t\t    u.user.name),\n\t\t\t\t\t m->u.kernel.match->name,\n\t\t\t\t\t strlen(m->u.kernel.match->name)+1)\n\t\t\t    != 0) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tgoto free_counters;\n\t\t\t}\n\t\t}\n\n\t\tt = ip6t_get_target_c(e);\n\t\tif (copy_to_user(userptr + off + e->target_offset\n\t\t\t\t + offsetof(struct xt_entry_target,\n\t\t\t\t\t    u.user.name),\n\t\t\t\t t->u.kernel.target->name,\n\t\t\t\t strlen(t->u.kernel.target->name)+1) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto free_counters;\n\t\t}\n\t}\n\n free_counters:\n\tvfree(counters);\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstatic void compat_standard_from_user(void *dst, const void *src)\n{\n\tint v = *(compat_int_t *)src;\n\n\tif (v > 0)\n\t\tv += xt_compat_calc_jump(AF_INET6, v);\n\tmemcpy(dst, &v, sizeof(v));\n}\n\nstatic int compat_standard_to_user(void __user *dst, const void *src)\n{\n\tcompat_int_t cv = *(int *)src;\n\n\tif (cv > 0)\n\t\tcv -= xt_compat_calc_jump(AF_INET6, cv);\n\treturn copy_to_user(dst, &cv, sizeof(cv)) ? -EFAULT : 0;\n}\n\nstatic int compat_calc_entry(const struct ip6t_entry *e,\n\t\t\t     const struct xt_table_info *info,\n\t\t\t     const void *base, struct xt_table_info *newinfo)\n{\n\tconst struct xt_entry_match *ematch;\n\tconst struct xt_entry_target *t;\n\tunsigned int entry_offset;\n\tint off, i, ret;\n\n\toff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\tentry_offset = (void *)e - base;\n\txt_ematch_foreach(ematch, e)\n\t\toff += xt_compat_match_offset(ematch->u.kernel.match);\n\tt = ip6t_get_target_c(e);\n\toff += xt_compat_target_offset(t->u.kernel.target);\n\tnewinfo->size -= off;\n\tret = xt_compat_add_offset(AF_INET6, entry_offset, off);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tif (info->hook_entry[i] &&\n\t\t    (e < (struct ip6t_entry *)(base + info->hook_entry[i])))\n\t\t\tnewinfo->hook_entry[i] -= off;\n\t\tif (info->underflow[i] &&\n\t\t    (e < (struct ip6t_entry *)(base + info->underflow[i])))\n\t\t\tnewinfo->underflow[i] -= off;\n\t}\n\treturn 0;\n}\n\nstatic int compat_table_info(const struct xt_table_info *info,\n\t\t\t     struct xt_table_info *newinfo)\n{\n\tstruct ip6t_entry *iter;\n\tconst void *loc_cpu_entry;\n\tint ret;\n\n\tif (!newinfo || !info)\n\t\treturn -EINVAL;\n\n\t/* we dont care about newinfo->entries */\n\tmemcpy(newinfo, info, offsetof(struct xt_table_info, entries));\n\tnewinfo->initial_entries = 0;\n\tloc_cpu_entry = info->entries;\n\txt_compat_init_offsets(AF_INET6, info->number);\n\txt_entry_foreach(iter, loc_cpu_entry, info->size) {\n\t\tret = compat_calc_entry(iter, info, loc_cpu_entry, newinfo);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\treturn 0;\n}\n#endif\n\nstatic int get_info(struct net *net, void __user *user,\n\t\t    const int *len, int compat)\n{\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tstruct xt_table *t;\n\tint ret;\n\n\tif (*len != sizeof(struct ip6t_getinfo)) {\n\t\tduprintf(\"length %u != %zu\\n\", *len,\n\t\t\t sizeof(struct ip6t_getinfo));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(name, user, sizeof(name)) != 0)\n\t\treturn -EFAULT;\n\n\tname[XT_TABLE_MAXNAMELEN-1] = '\\0';\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_lock(AF_INET6);\n#endif\n\tt = try_then_request_module(xt_find_table_lock(net, AF_INET6, name),\n\t\t\t\t    \"ip6table_%s\", name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tstruct ip6t_getinfo info;\n\t\tconst struct xt_table_info *private = t->private;\n#ifdef CONFIG_COMPAT\n\t\tstruct xt_table_info tmp;\n\n\t\tif (compat) {\n\t\t\tret = compat_table_info(private, &tmp);\n\t\t\txt_compat_flush_offsets(AF_INET6);\n\t\t\tprivate = &tmp;\n\t\t}\n#endif\n\t\tmemset(&info, 0, sizeof(info));\n\t\tinfo.valid_hooks = t->valid_hooks;\n\t\tmemcpy(info.hook_entry, private->hook_entry,\n\t\t       sizeof(info.hook_entry));\n\t\tmemcpy(info.underflow, private->underflow,\n\t\t       sizeof(info.underflow));\n\t\tinfo.num_entries = private->number;\n\t\tinfo.size = private->size;\n\t\tstrcpy(info.name, name);\n\n\t\tif (copy_to_user(user, &info, *len) != 0)\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = 0;\n\n\t\txt_table_unlock(t);\n\t\tmodule_put(t->me);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n#ifdef CONFIG_COMPAT\n\tif (compat)\n\t\txt_compat_unlock(AF_INET6);\n#endif\n\treturn ret;\n}\n\nstatic int\nget_entries(struct net *net, struct ip6t_get_entries __user *uptr,\n\t    const int *len)\n{\n\tint ret;\n\tstruct ip6t_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\tif (*len != sizeof(struct ip6t_get_entries) + get.size) {\n\t\tduprintf(\"get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\tt = xt_find_table_lock(net, AF_INET6, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tstruct xt_table_info *private = t->private;\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tif (get.size == private->size)\n\t\t\tret = copy_entries_to_user(private->size,\n\t\t\t\t\t\t   t, uptr->entrytable);\n\t\telse {\n\t\t\tduprintf(\"get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\treturn ret;\n}\n\nstatic int\n__do_replace(struct net *net, const char *name, unsigned int valid_hooks,\n\t     struct xt_table_info *newinfo, unsigned int num_counters,\n\t     void __user *counters_ptr)\n{\n\tint ret;\n\tstruct xt_table *t;\n\tstruct xt_table_info *oldinfo;\n\tstruct xt_counters *counters;\n\tstruct ip6t_entry *iter;\n\n\tret = 0;\n\tcounters = vzalloc(num_counters * sizeof(struct xt_counters));\n\tif (!counters) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tt = try_then_request_module(xt_find_table_lock(net, AF_INET6, name),\n\t\t\t\t    \"ip6table_%s\", name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free_newinfo_counters_untrans;\n\t}\n\n\t/* You lied! */\n\tif (valid_hooks != t->valid_hooks) {\n\t\tduprintf(\"Valid hook crap: %08X vs %08X\\n\",\n\t\t\t valid_hooks, t->valid_hooks);\n\t\tret = -EINVAL;\n\t\tgoto put_module;\n\t}\n\n\toldinfo = xt_replace_table(t, num_counters, newinfo, &ret);\n\tif (!oldinfo)\n\t\tgoto put_module;\n\n\t/* Update module usage count based on number of rules */\n\tduprintf(\"do_replace: oldnum=%u, initnum=%u, newnum=%u\\n\",\n\t\toldinfo->number, oldinfo->initial_entries, newinfo->number);\n\tif ((oldinfo->number > oldinfo->initial_entries) ||\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\tif ((oldinfo->number > oldinfo->initial_entries) &&\n\t    (newinfo->number <= oldinfo->initial_entries))\n\t\tmodule_put(t->me);\n\n\t/* Get the old counters, and synchronize with replace */\n\tget_counters(oldinfo, counters);\n\n\t/* Decrease module usage counts and free resource */\n\txt_entry_foreach(iter, oldinfo->entries, oldinfo->size)\n\t\tcleanup_entry(iter, net);\n\n\txt_free_table_info(oldinfo);\n\tif (copy_to_user(counters_ptr, counters,\n\t\t\t sizeof(struct xt_counters) * num_counters) != 0) {\n\t\t/* Silent error, can't fail, new table is already in place */\n\t\tnet_warn_ratelimited(\"ip6tables: counters copy to user failed while replacing table\\n\");\n\t}\n\tvfree(counters);\n\txt_table_unlock(t);\n\treturn ret;\n\n put_module:\n\tmodule_put(t->me);\n\txt_table_unlock(t);\n free_newinfo_counters_untrans:\n\tvfree(counters);\n out:\n\treturn ret;\n}\n\nstatic int\ndo_replace(struct net *net, const void __user *user, unsigned int len)\n{\n\tint ret;\n\tstruct ip6t_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct ip6t_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_table(net, newinfo, loc_cpu_entry, &tmp);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"ip_tables: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, tmp.counters);\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter, net);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int\ndo_add_counters(struct net *net, const void __user *user, unsigned int len,\n\t\tint compat)\n{\n\tunsigned int i;\n\tstruct xt_counters_info tmp;\n\tstruct xt_counters *paddc;\n\tunsigned int num_counters;\n\tchar *name;\n\tint size;\n\tvoid *ptmp;\n\tstruct xt_table *t;\n\tconst struct xt_table_info *private;\n\tint ret = 0;\n\tstruct ip6t_entry *iter;\n\tunsigned int addend;\n#ifdef CONFIG_COMPAT\n\tstruct compat_xt_counters_info compat_tmp;\n\n\tif (compat) {\n\t\tptmp = &compat_tmp;\n\t\tsize = sizeof(struct compat_xt_counters_info);\n\t} else\n#endif\n\t{\n\t\tptmp = &tmp;\n\t\tsize = sizeof(struct xt_counters_info);\n\t}\n\n\tif (copy_from_user(ptmp, user, size) != 0)\n\t\treturn -EFAULT;\n\n#ifdef CONFIG_COMPAT\n\tif (compat) {\n\t\tnum_counters = compat_tmp.num_counters;\n\t\tname = compat_tmp.name;\n\t} else\n#endif\n\t{\n\t\tnum_counters = tmp.num_counters;\n\t\tname = tmp.name;\n\t}\n\n\tif (len != size + num_counters * sizeof(struct xt_counters))\n\t\treturn -EINVAL;\n\n\tpaddc = vmalloc(len - size);\n\tif (!paddc)\n\t\treturn -ENOMEM;\n\n\tif (copy_from_user(paddc, user + size, len - size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free;\n\t}\n\n\tt = xt_find_table_lock(net, AF_INET6, name);\n\tif (IS_ERR_OR_NULL(t)) {\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\t\tgoto free;\n\t}\n\n\tlocal_bh_disable();\n\tprivate = t->private;\n\tif (private->number != num_counters) {\n\t\tret = -EINVAL;\n\t\tgoto unlock_up_free;\n\t}\n\n\ti = 0;\n\taddend = xt_write_recseq_begin();\n\txt_entry_foreach(iter, private->entries, private->size) {\n\t\tstruct xt_counters *tmp;\n\n\t\ttmp = xt_get_this_cpu_counter(&iter->counters);\n\t\tADD_COUNTER(*tmp, paddc[i].bcnt, paddc[i].pcnt);\n\t\t++i;\n\t}\n\txt_write_recseq_end(addend);\n unlock_up_free:\n\tlocal_bh_enable();\n\txt_table_unlock(t);\n\tmodule_put(t->me);\n free:\n\tvfree(paddc);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_COMPAT\nstruct compat_ip6t_replace {\n\tchar\t\t\tname[XT_TABLE_MAXNAMELEN];\n\tu32\t\t\tvalid_hooks;\n\tu32\t\t\tnum_entries;\n\tu32\t\t\tsize;\n\tu32\t\t\thook_entry[NF_INET_NUMHOOKS];\n\tu32\t\t\tunderflow[NF_INET_NUMHOOKS];\n\tu32\t\t\tnum_counters;\n\tcompat_uptr_t\t\tcounters;\t/* struct xt_counters * */\n\tstruct compat_ip6t_entry entries[0];\n};\n\nstatic int\ncompat_copy_entry_to_user(struct ip6t_entry *e, void __user **dstptr,\n\t\t\t  unsigned int *size, struct xt_counters *counters,\n\t\t\t  unsigned int i)\n{\n\tstruct xt_entry_target *t;\n\tstruct compat_ip6t_entry __user *ce;\n\tu_int16_t target_offset, next_offset;\n\tcompat_uint_t origsize;\n\tconst struct xt_entry_match *ematch;\n\tint ret = 0;\n\n\torigsize = *size;\n\tce = (struct compat_ip6t_entry __user *)*dstptr;\n\tif (copy_to_user(ce, e, sizeof(struct ip6t_entry)) != 0 ||\n\t    copy_to_user(&ce->counters, &counters[i],\n\t    sizeof(counters[i])) != 0)\n\t\treturn -EFAULT;\n\n\t*dstptr += sizeof(struct compat_ip6t_entry);\n\t*size -= sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\n\txt_ematch_foreach(ematch, e) {\n\t\tret = xt_compat_match_to_user(ematch, dstptr, size);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\ttarget_offset = e->target_offset - (origsize - *size);\n\tt = ip6t_get_target(e);\n\tret = xt_compat_target_to_user(t, dstptr, size);\n\tif (ret)\n\t\treturn ret;\n\tnext_offset = e->next_offset - (origsize - *size);\n\tif (put_user(target_offset, &ce->target_offset) != 0 ||\n\t    put_user(next_offset, &ce->next_offset) != 0)\n\t\treturn -EFAULT;\n\treturn 0;\n}\n\nstatic int\ncompat_find_calc_match(struct xt_entry_match *m,\n\t\t       const char *name,\n\t\t       const struct ip6t_ip6 *ipv6,\n\t\t       int *size)\n{\n\tstruct xt_match *match;\n\n\tmatch = xt_request_find_match(NFPROTO_IPV6, m->u.user.name,\n\t\t\t\t      m->u.user.revision);\n\tif (IS_ERR(match)) {\n\t\tduprintf(\"compat_check_calc_match: `%s' not found\\n\",\n\t\t\t m->u.user.name);\n\t\treturn PTR_ERR(match);\n\t}\n\tm->u.kernel.match = match;\n\t*size += xt_compat_match_offset(match);\n\treturn 0;\n}\n\nstatic void compat_release_entry(struct compat_ip6t_entry *e)\n{\n\tstruct xt_entry_target *t;\n\tstruct xt_entry_match *ematch;\n\n\t/* Cleanup all matches */\n\txt_ematch_foreach(ematch, e)\n\t\tmodule_put(ematch->u.kernel.match->me);\n\tt = compat_ip6t_get_target(e);\n\tmodule_put(t->u.kernel.target->me);\n}\n\nstatic int\ncheck_compat_entry_size_and_hooks(struct compat_ip6t_entry *e,\n\t\t\t\t  struct xt_table_info *newinfo,\n\t\t\t\t  unsigned int *size,\n\t\t\t\t  const unsigned char *base,\n\t\t\t\t  const unsigned char *limit,\n\t\t\t\t  const unsigned int *hook_entries,\n\t\t\t\t  const unsigned int *underflows,\n\t\t\t\t  const char *name)\n{\n\tstruct xt_entry_match *ematch;\n\tstruct xt_entry_target *t;\n\tstruct xt_target *target;\n\tunsigned int entry_offset;\n\tunsigned int j;\n\tint ret, off, h;\n\n\tduprintf(\"check_compat_entry_size_and_hooks %p\\n\", e);\n\tif ((unsigned long)e % __alignof__(struct compat_ip6t_entry) != 0 ||\n\t    (unsigned char *)e + sizeof(struct compat_ip6t_entry) >= limit ||\n\t    (unsigned char *)e + e->next_offset > limit) {\n\t\tduprintf(\"Bad offset %p, limit = %p\\n\", e, limit);\n\t\treturn -EINVAL;\n\t}\n\n\tif (e->next_offset < sizeof(struct compat_ip6t_entry) +\n\t\t\t     sizeof(struct compat_xt_entry_target)) {\n\t\tduprintf(\"checking: element %p size %u\\n\",\n\t\t\t e, e->next_offset);\n\t\treturn -EINVAL;\n\t}\n\n\tif (!ip6_checkentry(&e->ipv6))\n\t\treturn -EINVAL;\n\n\tret = xt_compat_check_entry_offsets(e, e->elems,\n\t\t\t\t\t    e->target_offset, e->next_offset);\n\tif (ret)\n\t\treturn ret;\n\n\toff = sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\tentry_offset = (void *)e - (void *)base;\n\tj = 0;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = compat_find_calc_match(ematch, name, &e->ipv6, &off);\n\t\tif (ret != 0)\n\t\t\tgoto release_matches;\n\t\t++j;\n\t}\n\n\tt = compat_ip6t_get_target(e);\n\ttarget = xt_request_find_target(NFPROTO_IPV6, t->u.user.name,\n\t\t\t\t\tt->u.user.revision);\n\tif (IS_ERR(target)) {\n\t\tduprintf(\"check_compat_entry_size_and_hooks: `%s' not found\\n\",\n\t\t\t t->u.user.name);\n\t\tret = PTR_ERR(target);\n\t\tgoto release_matches;\n\t}\n\tt->u.kernel.target = target;\n\n\toff += xt_compat_target_offset(target);\n\t*size += off;\n\tret = xt_compat_add_offset(AF_INET6, entry_offset, off);\n\tif (ret)\n\t\tgoto out;\n\n\t/* Check hooks & underflows */\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)e - base == hook_entries[h])\n\t\t\tnewinfo->hook_entry[h] = hook_entries[h];\n\t\tif ((unsigned char *)e - base == underflows[h])\n\t\t\tnewinfo->underflow[h] = underflows[h];\n\t}\n\n\t/* Clear counters and comefrom */\n\tmemset(&e->counters, 0, sizeof(e->counters));\n\te->comefrom = 0;\n\treturn 0;\n\nout:\n\tmodule_put(t->u.kernel.target->me);\nrelease_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tmodule_put(ematch->u.kernel.match->me);\n\t}\n\treturn ret;\n}\n\nstatic int\ncompat_copy_entry_from_user(struct compat_ip6t_entry *e, void **dstptr,\n\t\t\t    unsigned int *size, const char *name,\n\t\t\t    struct xt_table_info *newinfo, unsigned char *base)\n{\n\tstruct xt_entry_target *t;\n\tstruct ip6t_entry *de;\n\tunsigned int origsize;\n\tint ret, h;\n\tstruct xt_entry_match *ematch;\n\n\tret = 0;\n\torigsize = *size;\n\tde = (struct ip6t_entry *)*dstptr;\n\tmemcpy(de, e, sizeof(struct ip6t_entry));\n\tmemcpy(&de->counters, &e->counters, sizeof(e->counters));\n\n\t*dstptr += sizeof(struct ip6t_entry);\n\t*size += sizeof(struct ip6t_entry) - sizeof(struct compat_ip6t_entry);\n\n\txt_ematch_foreach(ematch, e) {\n\t\tret = xt_compat_match_from_user(ematch, dstptr, size);\n\t\tif (ret != 0)\n\t\t\treturn ret;\n\t}\n\tde->target_offset = e->target_offset - (origsize - *size);\n\tt = compat_ip6t_get_target(e);\n\txt_compat_target_from_user(t, dstptr, size);\n\n\tde->next_offset = e->next_offset - (origsize - *size);\n\tfor (h = 0; h < NF_INET_NUMHOOKS; h++) {\n\t\tif ((unsigned char *)de - base < newinfo->hook_entry[h])\n\t\t\tnewinfo->hook_entry[h] -= origsize - *size;\n\t\tif ((unsigned char *)de - base < newinfo->underflow[h])\n\t\t\tnewinfo->underflow[h] -= origsize - *size;\n\t}\n\treturn ret;\n}\n\nstatic int compat_check_entry(struct ip6t_entry *e, struct net *net,\n\t\t\t      const char *name)\n{\n\tunsigned int j;\n\tint ret = 0;\n\tstruct xt_mtchk_param mtpar;\n\tstruct xt_entry_match *ematch;\n\n\te->counters.pcnt = xt_percpu_counter_alloc();\n\tif (IS_ERR_VALUE(e->counters.pcnt))\n\t\treturn -ENOMEM;\n\tj = 0;\n\tmtpar.net\t= net;\n\tmtpar.table     = name;\n\tmtpar.entryinfo = &e->ipv6;\n\tmtpar.hook_mask = e->comefrom;\n\tmtpar.family    = NFPROTO_IPV6;\n\txt_ematch_foreach(ematch, e) {\n\t\tret = check_match(ematch, &mtpar);\n\t\tif (ret != 0)\n\t\t\tgoto cleanup_matches;\n\t\t++j;\n\t}\n\n\tret = check_target(e, net, name);\n\tif (ret)\n\t\tgoto cleanup_matches;\n\treturn 0;\n\n cleanup_matches:\n\txt_ematch_foreach(ematch, e) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcleanup_match(ematch, net);\n\t}\n\n\txt_percpu_counter_free(e->counters.pcnt);\n\n\treturn ret;\n}\n\nstatic int\ntranslate_compat_table(struct net *net,\n\t\t       const char *name,\n\t\t       unsigned int valid_hooks,\n\t\t       struct xt_table_info **pinfo,\n\t\t       void **pentry0,\n\t\t       unsigned int total_size,\n\t\t       unsigned int number,\n\t\t       unsigned int *hook_entries,\n\t\t       unsigned int *underflows)\n{\n\tunsigned int i, j;\n\tstruct xt_table_info *newinfo, *info;\n\tvoid *pos, *entry0, *entry1;\n\tstruct compat_ip6t_entry *iter0;\n\tstruct ip6t_entry *iter1;\n\tunsigned int size;\n\tint ret = 0;\n\n\tinfo = *pinfo;\n\tentry0 = *pentry0;\n\tsize = total_size;\n\tinfo->number = number;\n\n\t/* Init all hooks to impossible value. */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tinfo->hook_entry[i] = 0xFFFFFFFF;\n\t\tinfo->underflow[i] = 0xFFFFFFFF;\n\t}\n\n\tduprintf(\"translate_compat_table: size %u\\n\", info->size);\n\tj = 0;\n\txt_compat_lock(AF_INET6);\n\txt_compat_init_offsets(AF_INET6, number);\n\t/* Walk through entries, checking offsets. */\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = check_compat_entry_size_and_hooks(iter0, info, &size,\n\t\t\t\t\t\t\tentry0,\n\t\t\t\t\t\t\tentry0 + total_size,\n\t\t\t\t\t\t\thook_entries,\n\t\t\t\t\t\t\tunderflows,\n\t\t\t\t\t\t\tname);\n\t\tif (ret != 0)\n\t\t\tgoto out_unlock;\n\t\t++j;\n\t}\n\n\tret = -EINVAL;\n\tif (j != number) {\n\t\tduprintf(\"translate_compat_table: %u not %u entries\\n\",\n\t\t\t j, number);\n\t\tgoto out_unlock;\n\t}\n\n\t/* Check hooks all assigned */\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\t/* Only hooks which are valid */\n\t\tif (!(valid_hooks & (1 << i)))\n\t\t\tcontinue;\n\t\tif (info->hook_entry[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid hook entry %u %u\\n\",\n\t\t\t\t i, hook_entries[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t\tif (info->underflow[i] == 0xFFFFFFFF) {\n\t\t\tduprintf(\"Invalid underflow %u %u\\n\",\n\t\t\t\t i, underflows[i]);\n\t\t\tgoto out_unlock;\n\t\t}\n\t}\n\n\tret = -ENOMEM;\n\tnewinfo = xt_alloc_table_info(size);\n\tif (!newinfo)\n\t\tgoto out_unlock;\n\n\tnewinfo->number = number;\n\tfor (i = 0; i < NF_INET_NUMHOOKS; i++) {\n\t\tnewinfo->hook_entry[i] = info->hook_entry[i];\n\t\tnewinfo->underflow[i] = info->underflow[i];\n\t}\n\tentry1 = newinfo->entries;\n\tpos = entry1;\n\tsize = total_size;\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tret = compat_copy_entry_from_user(iter0, &pos, &size,\n\t\t\t\t\t\t  name, newinfo, entry1);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\txt_compat_flush_offsets(AF_INET6);\n\txt_compat_unlock(AF_INET6);\n\tif (ret)\n\t\tgoto free_newinfo;\n\n\tret = -ELOOP;\n\tif (!mark_source_chains(newinfo, valid_hooks, entry1))\n\t\tgoto free_newinfo;\n\n\ti = 0;\n\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\tret = compat_check_entry(iter1, net, name);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t\t++i;\n\t\tif (strcmp(ip6t_get_target(iter1)->u.user.name,\n\t\t    XT_ERROR_TARGET) == 0)\n\t\t\t++newinfo->stacksize;\n\t}\n\tif (ret) {\n\t\t/*\n\t\t * The first i matches need cleanup_entry (calls ->destroy)\n\t\t * because they had called ->check already. The other j-i\n\t\t * entries need only release.\n\t\t */\n\t\tint skip = i;\n\t\tj -= i;\n\t\txt_entry_foreach(iter0, entry0, newinfo->size) {\n\t\t\tif (skip-- > 0)\n\t\t\t\tcontinue;\n\t\t\tif (j-- == 0)\n\t\t\t\tbreak;\n\t\t\tcompat_release_entry(iter0);\n\t\t}\n\t\txt_entry_foreach(iter1, entry1, newinfo->size) {\n\t\t\tif (i-- == 0)\n\t\t\t\tbreak;\n\t\t\tcleanup_entry(iter1, net);\n\t\t}\n\t\txt_free_table_info(newinfo);\n\t\treturn ret;\n\t}\n\n\t*pinfo = newinfo;\n\t*pentry0 = entry1;\n\txt_free_table_info(info);\n\treturn 0;\n\nfree_newinfo:\n\txt_free_table_info(newinfo);\nout:\n\txt_entry_foreach(iter0, entry0, total_size) {\n\t\tif (j-- == 0)\n\t\t\tbreak;\n\t\tcompat_release_entry(iter0);\n\t}\n\treturn ret;\nout_unlock:\n\txt_compat_flush_offsets(AF_INET6);\n\txt_compat_unlock(AF_INET6);\n\tgoto out;\n}\n\nstatic int\ncompat_do_replace(struct net *net, void __user *user, unsigned int len)\n{\n\tint ret;\n\tstruct compat_ip6t_replace tmp;\n\tstruct xt_table_info *newinfo;\n\tvoid *loc_cpu_entry;\n\tstruct ip6t_entry *iter;\n\n\tif (copy_from_user(&tmp, user, sizeof(tmp)) != 0)\n\t\treturn -EFAULT;\n\n\t/* overflow check */\n\tif (tmp.size >= INT_MAX / num_possible_cpus())\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters >= INT_MAX / sizeof(struct xt_counters))\n\t\treturn -ENOMEM;\n\tif (tmp.num_counters == 0)\n\t\treturn -EINVAL;\n\n\ttmp.name[sizeof(tmp.name)-1] = 0;\n\n\tnewinfo = xt_alloc_table_info(tmp.size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tif (copy_from_user(loc_cpu_entry, user + sizeof(tmp),\n\t\t\t   tmp.size) != 0) {\n\t\tret = -EFAULT;\n\t\tgoto free_newinfo;\n\t}\n\n\tret = translate_compat_table(net, tmp.name, tmp.valid_hooks,\n\t\t\t\t     &newinfo, &loc_cpu_entry, tmp.size,\n\t\t\t\t     tmp.num_entries, tmp.hook_entry,\n\t\t\t\t     tmp.underflow);\n\tif (ret != 0)\n\t\tgoto free_newinfo;\n\n\tduprintf(\"compat_do_replace: Translated table\\n\");\n\n\tret = __do_replace(net, tmp.name, tmp.valid_hooks, newinfo,\n\t\t\t   tmp.num_counters, compat_ptr(tmp.counters));\n\tif (ret)\n\t\tgoto free_newinfo_untrans;\n\treturn 0;\n\n free_newinfo_untrans:\n\txt_entry_foreach(iter, loc_cpu_entry, newinfo->size)\n\t\tcleanup_entry(iter, net);\n free_newinfo:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nstatic int\ncompat_do_ip6t_set_ctl(struct sock *sk, int cmd, void __user *user,\n\t\t       unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IP6T_SO_SET_REPLACE:\n\t\tret = compat_do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IP6T_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 1);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_ip6t_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstruct compat_ip6t_get_entries {\n\tchar name[XT_TABLE_MAXNAMELEN];\n\tcompat_uint_t size;\n\tstruct compat_ip6t_entry entrytable[0];\n};\n\nstatic int\ncompat_copy_entries_to_user(unsigned int total_size, struct xt_table *table,\n\t\t\t    void __user *userptr)\n{\n\tstruct xt_counters *counters;\n\tconst struct xt_table_info *private = table->private;\n\tvoid __user *pos;\n\tunsigned int size;\n\tint ret = 0;\n\tunsigned int i = 0;\n\tstruct ip6t_entry *iter;\n\n\tcounters = alloc_counters(table);\n\tif (IS_ERR(counters))\n\t\treturn PTR_ERR(counters);\n\n\tpos = userptr;\n\tsize = total_size;\n\txt_entry_foreach(iter, private->entries, total_size) {\n\t\tret = compat_copy_entry_to_user(iter, &pos,\n\t\t\t\t\t\t&size, counters, i++);\n\t\tif (ret != 0)\n\t\t\tbreak;\n\t}\n\n\tvfree(counters);\n\treturn ret;\n}\n\nstatic int\ncompat_get_entries(struct net *net, struct compat_ip6t_get_entries __user *uptr,\n\t\t   int *len)\n{\n\tint ret;\n\tstruct compat_ip6t_get_entries get;\n\tstruct xt_table *t;\n\n\tif (*len < sizeof(get)) {\n\t\tduprintf(\"compat_get_entries: %u < %zu\\n\", *len, sizeof(get));\n\t\treturn -EINVAL;\n\t}\n\n\tif (copy_from_user(&get, uptr, sizeof(get)) != 0)\n\t\treturn -EFAULT;\n\n\tif (*len != sizeof(struct compat_ip6t_get_entries) + get.size) {\n\t\tduprintf(\"compat_get_entries: %u != %zu\\n\",\n\t\t\t *len, sizeof(get) + get.size);\n\t\treturn -EINVAL;\n\t}\n\tget.name[sizeof(get.name) - 1] = '\\0';\n\n\txt_compat_lock(AF_INET6);\n\tt = xt_find_table_lock(net, AF_INET6, get.name);\n\tif (!IS_ERR_OR_NULL(t)) {\n\t\tconst struct xt_table_info *private = t->private;\n\t\tstruct xt_table_info info;\n\t\tduprintf(\"t->private->number = %u\\n\", private->number);\n\t\tret = compat_table_info(private, &info);\n\t\tif (!ret && get.size == info.size) {\n\t\t\tret = compat_copy_entries_to_user(private->size,\n\t\t\t\t\t\t\t  t, uptr->entrytable);\n\t\t} else if (!ret) {\n\t\t\tduprintf(\"compat_get_entries: I've got %u not %u!\\n\",\n\t\t\t\t private->size, get.size);\n\t\t\tret = -EAGAIN;\n\t\t}\n\t\txt_compat_flush_offsets(AF_INET6);\n\t\tmodule_put(t->me);\n\t\txt_table_unlock(t);\n\t} else\n\t\tret = t ? PTR_ERR(t) : -ENOENT;\n\n\txt_compat_unlock(AF_INET6);\n\treturn ret;\n}\n\nstatic int do_ip6t_get_ctl(struct sock *, int, void __user *, int *);\n\nstatic int\ncompat_do_ip6t_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IP6T_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 1);\n\t\tbreak;\n\tcase IP6T_SO_GET_ENTRIES:\n\t\tret = compat_get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\tdefault:\n\t\tret = do_ip6t_get_ctl(sk, cmd, user, len);\n\t}\n\treturn ret;\n}\n#endif\n\nstatic int\ndo_ip6t_set_ctl(struct sock *sk, int cmd, void __user *user, unsigned int len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IP6T_SO_SET_REPLACE:\n\t\tret = do_replace(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IP6T_SO_SET_ADD_COUNTERS:\n\t\tret = do_add_counters(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tdefault:\n\t\tduprintf(\"do_ip6t_set_ctl:  unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic int\ndo_ip6t_get_ctl(struct sock *sk, int cmd, void __user *user, int *len)\n{\n\tint ret;\n\n\tif (!ns_capable(sock_net(sk)->user_ns, CAP_NET_ADMIN))\n\t\treturn -EPERM;\n\n\tswitch (cmd) {\n\tcase IP6T_SO_GET_INFO:\n\t\tret = get_info(sock_net(sk), user, len, 0);\n\t\tbreak;\n\n\tcase IP6T_SO_GET_ENTRIES:\n\t\tret = get_entries(sock_net(sk), user, len);\n\t\tbreak;\n\n\tcase IP6T_SO_GET_REVISION_MATCH:\n\tcase IP6T_SO_GET_REVISION_TARGET: {\n\t\tstruct xt_get_revision rev;\n\t\tint target;\n\n\t\tif (*len != sizeof(rev)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\t\tif (copy_from_user(&rev, user, sizeof(rev)) != 0) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\trev.name[sizeof(rev.name)-1] = 0;\n\n\t\tif (cmd == IP6T_SO_GET_REVISION_TARGET)\n\t\t\ttarget = 1;\n\t\telse\n\t\t\ttarget = 0;\n\n\t\ttry_then_request_module(xt_find_revision(AF_INET6, rev.name,\n\t\t\t\t\t\t\t rev.revision,\n\t\t\t\t\t\t\t target, &ret),\n\t\t\t\t\t\"ip6t_%s\", rev.name);\n\t\tbreak;\n\t}\n\n\tdefault:\n\t\tduprintf(\"do_ip6t_get_ctl: unknown request %i\\n\", cmd);\n\t\tret = -EINVAL;\n\t}\n\n\treturn ret;\n}\n\nstatic void __ip6t_unregister_table(struct net *net, struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\tvoid *loc_cpu_entry;\n\tstruct module *table_owner = table->me;\n\tstruct ip6t_entry *iter;\n\n\tprivate = xt_unregister_table(table);\n\n\t/* Decrease module usage counts and free resources */\n\tloc_cpu_entry = private->entries;\n\txt_entry_foreach(iter, loc_cpu_entry, private->size)\n\t\tcleanup_entry(iter, net);\n\tif (private->number > private->initial_entries)\n\t\tmodule_put(table_owner);\n\txt_free_table_info(private);\n}\n\nint ip6t_register_table(struct net *net, const struct xt_table *table,\n\t\t\tconst struct ip6t_replace *repl,\n\t\t\tconst struct nf_hook_ops *ops,\n\t\t\tstruct xt_table **res)\n{\n\tint ret;\n\tstruct xt_table_info *newinfo;\n\tstruct xt_table_info bootstrap = {0};\n\tvoid *loc_cpu_entry;\n\tstruct xt_table *new_table;\n\n\tnewinfo = xt_alloc_table_info(repl->size);\n\tif (!newinfo)\n\t\treturn -ENOMEM;\n\n\tloc_cpu_entry = newinfo->entries;\n\tmemcpy(loc_cpu_entry, repl->entries, repl->size);\n\n\tret = translate_table(net, newinfo, loc_cpu_entry, repl);\n\tif (ret != 0)\n\t\tgoto out_free;\n\n\tnew_table = xt_register_table(net, table, &bootstrap, newinfo);\n\tif (IS_ERR(new_table)) {\n\t\tret = PTR_ERR(new_table);\n\t\tgoto out_free;\n\t}\n\n\t/* set res now, will see skbs right after nf_register_net_hooks */\n\tWRITE_ONCE(*res, new_table);\n\n\tret = nf_register_net_hooks(net, ops, hweight32(table->valid_hooks));\n\tif (ret != 0) {\n\t\t__ip6t_unregister_table(net, new_table);\n\t\t*res = NULL;\n\t}\n\n\treturn ret;\n\nout_free:\n\txt_free_table_info(newinfo);\n\treturn ret;\n}\n\nvoid ip6t_unregister_table(struct net *net, struct xt_table *table,\n\t\t\t   const struct nf_hook_ops *ops)\n{\n\tnf_unregister_net_hooks(net, ops, hweight32(table->valid_hooks));\n\t__ip6t_unregister_table(net, table);\n}\n\n/* Returns 1 if the type and code is matched by the range, 0 otherwise */\nstatic inline bool\nicmp6_type_code_match(u_int8_t test_type, u_int8_t min_code, u_int8_t max_code,\n\t\t     u_int8_t type, u_int8_t code,\n\t\t     bool invert)\n{\n\treturn (type == test_type && code >= min_code && code <= max_code)\n\t\t^ invert;\n}\n\nstatic bool\nicmp6_match(const struct sk_buff *skb, struct xt_action_param *par)\n{\n\tconst struct icmp6hdr *ic;\n\tstruct icmp6hdr _icmph;\n\tconst struct ip6t_icmp *icmpinfo = par->matchinfo;\n\n\t/* Must not be a fragment. */\n\tif (par->fragoff != 0)\n\t\treturn false;\n\n\tic = skb_header_pointer(skb, par->thoff, sizeof(_icmph), &_icmph);\n\tif (ic == NULL) {\n\t\t/* We've been asked to examine this packet, and we\n\t\t * can't.  Hence, no choice but to drop.\n\t\t */\n\t\tduprintf(\"Dropping evil ICMP tinygram.\\n\");\n\t\tpar->hotdrop = true;\n\t\treturn false;\n\t}\n\n\treturn icmp6_type_code_match(icmpinfo->type,\n\t\t\t\t     icmpinfo->code[0],\n\t\t\t\t     icmpinfo->code[1],\n\t\t\t\t     ic->icmp6_type, ic->icmp6_code,\n\t\t\t\t     !!(icmpinfo->invflags&IP6T_ICMP_INV));\n}\n\n/* Called when user tries to insert an entry of this type. */\nstatic int icmp6_checkentry(const struct xt_mtchk_param *par)\n{\n\tconst struct ip6t_icmp *icmpinfo = par->matchinfo;\n\n\t/* Must specify no unknown invflags */\n\treturn (icmpinfo->invflags & ~IP6T_ICMP_INV) ? -EINVAL : 0;\n}\n\n/* The built-in targets: standard (NULL) and error. */\nstatic struct xt_target ip6t_builtin_tg[] __read_mostly = {\n\t{\n\t\t.name             = XT_STANDARD_TARGET,\n\t\t.targetsize       = sizeof(int),\n\t\t.family           = NFPROTO_IPV6,\n#ifdef CONFIG_COMPAT\n\t\t.compatsize       = sizeof(compat_int_t),\n\t\t.compat_from_user = compat_standard_from_user,\n\t\t.compat_to_user   = compat_standard_to_user,\n#endif\n\t},\n\t{\n\t\t.name             = XT_ERROR_TARGET,\n\t\t.target           = ip6t_error,\n\t\t.targetsize       = XT_FUNCTION_MAXNAMELEN,\n\t\t.family           = NFPROTO_IPV6,\n\t},\n};\n\nstatic struct nf_sockopt_ops ip6t_sockopts = {\n\t.pf\t\t= PF_INET6,\n\t.set_optmin\t= IP6T_BASE_CTL,\n\t.set_optmax\t= IP6T_SO_SET_MAX+1,\n\t.set\t\t= do_ip6t_set_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_set\t= compat_do_ip6t_set_ctl,\n#endif\n\t.get_optmin\t= IP6T_BASE_CTL,\n\t.get_optmax\t= IP6T_SO_GET_MAX+1,\n\t.get\t\t= do_ip6t_get_ctl,\n#ifdef CONFIG_COMPAT\n\t.compat_get\t= compat_do_ip6t_get_ctl,\n#endif\n\t.owner\t\t= THIS_MODULE,\n};\n\nstatic struct xt_match ip6t_builtin_mt[] __read_mostly = {\n\t{\n\t\t.name       = \"icmp6\",\n\t\t.match      = icmp6_match,\n\t\t.matchsize  = sizeof(struct ip6t_icmp),\n\t\t.checkentry = icmp6_checkentry,\n\t\t.proto      = IPPROTO_ICMPV6,\n\t\t.family     = NFPROTO_IPV6,\n\t},\n};\n\nstatic int __net_init ip6_tables_net_init(struct net *net)\n{\n\treturn xt_proto_init(net, NFPROTO_IPV6);\n}\n\nstatic void __net_exit ip6_tables_net_exit(struct net *net)\n{\n\txt_proto_fini(net, NFPROTO_IPV6);\n}\n\nstatic struct pernet_operations ip6_tables_net_ops = {\n\t.init = ip6_tables_net_init,\n\t.exit = ip6_tables_net_exit,\n};\n\nstatic int __init ip6_tables_init(void)\n{\n\tint ret;\n\n\tret = register_pernet_subsys(&ip6_tables_net_ops);\n\tif (ret < 0)\n\t\tgoto err1;\n\n\t/* No one else will be downing sem now, so we won't sleep */\n\tret = xt_register_targets(ip6t_builtin_tg, ARRAY_SIZE(ip6t_builtin_tg));\n\tif (ret < 0)\n\t\tgoto err2;\n\tret = xt_register_matches(ip6t_builtin_mt, ARRAY_SIZE(ip6t_builtin_mt));\n\tif (ret < 0)\n\t\tgoto err4;\n\n\t/* Register setsockopt */\n\tret = nf_register_sockopt(&ip6t_sockopts);\n\tif (ret < 0)\n\t\tgoto err5;\n\n\tpr_info(\"(C) 2000-2006 Netfilter Core Team\\n\");\n\treturn 0;\n\nerr5:\n\txt_unregister_matches(ip6t_builtin_mt, ARRAY_SIZE(ip6t_builtin_mt));\nerr4:\n\txt_unregister_targets(ip6t_builtin_tg, ARRAY_SIZE(ip6t_builtin_tg));\nerr2:\n\tunregister_pernet_subsys(&ip6_tables_net_ops);\nerr1:\n\treturn ret;\n}\n\nstatic void __exit ip6_tables_fini(void)\n{\n\tnf_unregister_sockopt(&ip6t_sockopts);\n\n\txt_unregister_matches(ip6t_builtin_mt, ARRAY_SIZE(ip6t_builtin_mt));\n\txt_unregister_targets(ip6t_builtin_tg, ARRAY_SIZE(ip6t_builtin_tg));\n\tunregister_pernet_subsys(&ip6_tables_net_ops);\n}\n\nEXPORT_SYMBOL(ip6t_register_table);\nEXPORT_SYMBOL(ip6t_unregister_table);\nEXPORT_SYMBOL(ip6t_do_table);\n\nmodule_init(ip6_tables_init);\nmodule_exit(ip6_tables_fini);\n", "/*\n * x_tables core - Backend for {ip,ip6,arp}_tables\n *\n * Copyright (C) 2006-2006 Harald Welte <laforge@netfilter.org>\n * Copyright (C) 2006-2012 Patrick McHardy <kaber@trash.net>\n *\n * Based on existing ip_tables code which is\n *   Copyright (C) 1999 Paul `Rusty' Russell & Michael J. Neuling\n *   Copyright (C) 2000-2005 Netfilter Core Team <coreteam@netfilter.org>\n *\n * This program is free software; you can redistribute it and/or modify\n * it under the terms of the GNU General Public License version 2 as\n * published by the Free Software Foundation.\n *\n */\n#define pr_fmt(fmt) KBUILD_MODNAME \": \" fmt\n#include <linux/kernel.h>\n#include <linux/module.h>\n#include <linux/socket.h>\n#include <linux/net.h>\n#include <linux/proc_fs.h>\n#include <linux/seq_file.h>\n#include <linux/string.h>\n#include <linux/vmalloc.h>\n#include <linux/mutex.h>\n#include <linux/mm.h>\n#include <linux/slab.h>\n#include <linux/audit.h>\n#include <linux/user_namespace.h>\n#include <net/net_namespace.h>\n\n#include <linux/netfilter/x_tables.h>\n#include <linux/netfilter_arp.h>\n#include <linux/netfilter_ipv4/ip_tables.h>\n#include <linux/netfilter_ipv6/ip6_tables.h>\n#include <linux/netfilter_arp/arp_tables.h>\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Harald Welte <laforge@netfilter.org>\");\nMODULE_DESCRIPTION(\"{ip,ip6,arp,eb}_tables backend module\");\n\n#define SMP_ALIGN(x) (((x) + SMP_CACHE_BYTES-1) & ~(SMP_CACHE_BYTES-1))\n\nstruct compat_delta {\n\tunsigned int offset; /* offset in kernel */\n\tint delta; /* delta in 32bit user land */\n};\n\nstruct xt_af {\n\tstruct mutex mutex;\n\tstruct list_head match;\n\tstruct list_head target;\n#ifdef CONFIG_COMPAT\n\tstruct mutex compat_mutex;\n\tstruct compat_delta *compat_tab;\n\tunsigned int number; /* number of slots in compat_tab[] */\n\tunsigned int cur; /* number of used slots in compat_tab[] */\n#endif\n};\n\nstatic struct xt_af *xt;\n\nstatic const char *const xt_prefix[NFPROTO_NUMPROTO] = {\n\t[NFPROTO_UNSPEC] = \"x\",\n\t[NFPROTO_IPV4]   = \"ip\",\n\t[NFPROTO_ARP]    = \"arp\",\n\t[NFPROTO_BRIDGE] = \"eb\",\n\t[NFPROTO_IPV6]   = \"ip6\",\n};\n\n/* Registration hooks for targets. */\nint xt_register_target(struct xt_target *target)\n{\n\tu_int8_t af = target->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_add(&target->list, &xt[af].target);\n\tmutex_unlock(&xt[af].mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_register_target);\n\nvoid\nxt_unregister_target(struct xt_target *target)\n{\n\tu_int8_t af = target->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_del(&target->list);\n\tmutex_unlock(&xt[af].mutex);\n}\nEXPORT_SYMBOL(xt_unregister_target);\n\nint\nxt_register_targets(struct xt_target *target, unsigned int n)\n{\n\tunsigned int i;\n\tint err = 0;\n\n\tfor (i = 0; i < n; i++) {\n\t\terr = xt_register_target(&target[i]);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\treturn err;\n\nerr:\n\tif (i > 0)\n\t\txt_unregister_targets(target, i);\n\treturn err;\n}\nEXPORT_SYMBOL(xt_register_targets);\n\nvoid\nxt_unregister_targets(struct xt_target *target, unsigned int n)\n{\n\twhile (n-- > 0)\n\t\txt_unregister_target(&target[n]);\n}\nEXPORT_SYMBOL(xt_unregister_targets);\n\nint xt_register_match(struct xt_match *match)\n{\n\tu_int8_t af = match->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_add(&match->list, &xt[af].match);\n\tmutex_unlock(&xt[af].mutex);\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_register_match);\n\nvoid\nxt_unregister_match(struct xt_match *match)\n{\n\tu_int8_t af = match->family;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_del(&match->list);\n\tmutex_unlock(&xt[af].mutex);\n}\nEXPORT_SYMBOL(xt_unregister_match);\n\nint\nxt_register_matches(struct xt_match *match, unsigned int n)\n{\n\tunsigned int i;\n\tint err = 0;\n\n\tfor (i = 0; i < n; i++) {\n\t\terr = xt_register_match(&match[i]);\n\t\tif (err)\n\t\t\tgoto err;\n\t}\n\treturn err;\n\nerr:\n\tif (i > 0)\n\t\txt_unregister_matches(match, i);\n\treturn err;\n}\nEXPORT_SYMBOL(xt_register_matches);\n\nvoid\nxt_unregister_matches(struct xt_match *match, unsigned int n)\n{\n\twhile (n-- > 0)\n\t\txt_unregister_match(&match[n]);\n}\nEXPORT_SYMBOL(xt_unregister_matches);\n\n\n/*\n * These are weird, but module loading must not be done with mutex\n * held (since they will register), and we have to have a single\n * function to use.\n */\n\n/* Find match, grabs ref.  Returns ERR_PTR() on error. */\nstruct xt_match *xt_find_match(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_match *m;\n\tint err = -ENOENT;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(m, &xt[af].match, list) {\n\t\tif (strcmp(m->name, name) == 0) {\n\t\t\tif (m->revision == revision) {\n\t\t\t\tif (try_module_get(m->me)) {\n\t\t\t\t\tmutex_unlock(&xt[af].mutex);\n\t\t\t\t\treturn m;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\terr = -EPROTOTYPE; /* Found something. */\n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\n\tif (af != NFPROTO_UNSPEC)\n\t\t/* Try searching again in the family-independent list */\n\t\treturn xt_find_match(NFPROTO_UNSPEC, name, revision);\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xt_find_match);\n\nstruct xt_match *\nxt_request_find_match(uint8_t nfproto, const char *name, uint8_t revision)\n{\n\tstruct xt_match *match;\n\n\tmatch = xt_find_match(nfproto, name, revision);\n\tif (IS_ERR(match)) {\n\t\trequest_module(\"%st_%s\", xt_prefix[nfproto], name);\n\t\tmatch = xt_find_match(nfproto, name, revision);\n\t}\n\n\treturn match;\n}\nEXPORT_SYMBOL_GPL(xt_request_find_match);\n\n/* Find target, grabs ref.  Returns ERR_PTR() on error. */\nstruct xt_target *xt_find_target(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_target *t;\n\tint err = -ENOENT;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &xt[af].target, list) {\n\t\tif (strcmp(t->name, name) == 0) {\n\t\t\tif (t->revision == revision) {\n\t\t\t\tif (try_module_get(t->me)) {\n\t\t\t\t\tmutex_unlock(&xt[af].mutex);\n\t\t\t\t\treturn t;\n\t\t\t\t}\n\t\t\t} else\n\t\t\t\terr = -EPROTOTYPE; /* Found something. */\n\t\t}\n\t}\n\tmutex_unlock(&xt[af].mutex);\n\n\tif (af != NFPROTO_UNSPEC)\n\t\t/* Try searching again in the family-independent list */\n\t\treturn xt_find_target(NFPROTO_UNSPEC, name, revision);\n\n\treturn ERR_PTR(err);\n}\nEXPORT_SYMBOL(xt_find_target);\n\nstruct xt_target *xt_request_find_target(u8 af, const char *name, u8 revision)\n{\n\tstruct xt_target *target;\n\n\ttarget = xt_find_target(af, name, revision);\n\tif (IS_ERR(target)) {\n\t\trequest_module(\"%st_%s\", xt_prefix[af], name);\n\t\ttarget = xt_find_target(af, name, revision);\n\t}\n\n\treturn target;\n}\nEXPORT_SYMBOL_GPL(xt_request_find_target);\n\nstatic int match_revfn(u8 af, const char *name, u8 revision, int *bestp)\n{\n\tconst struct xt_match *m;\n\tint have_rev = 0;\n\n\tlist_for_each_entry(m, &xt[af].match, list) {\n\t\tif (strcmp(m->name, name) == 0) {\n\t\t\tif (m->revision > *bestp)\n\t\t\t\t*bestp = m->revision;\n\t\t\tif (m->revision == revision)\n\t\t\t\thave_rev = 1;\n\t\t}\n\t}\n\n\tif (af != NFPROTO_UNSPEC && !have_rev)\n\t\treturn match_revfn(NFPROTO_UNSPEC, name, revision, bestp);\n\n\treturn have_rev;\n}\n\nstatic int target_revfn(u8 af, const char *name, u8 revision, int *bestp)\n{\n\tconst struct xt_target *t;\n\tint have_rev = 0;\n\n\tlist_for_each_entry(t, &xt[af].target, list) {\n\t\tif (strcmp(t->name, name) == 0) {\n\t\t\tif (t->revision > *bestp)\n\t\t\t\t*bestp = t->revision;\n\t\t\tif (t->revision == revision)\n\t\t\t\thave_rev = 1;\n\t\t}\n\t}\n\n\tif (af != NFPROTO_UNSPEC && !have_rev)\n\t\treturn target_revfn(NFPROTO_UNSPEC, name, revision, bestp);\n\n\treturn have_rev;\n}\n\n/* Returns true or false (if no such extension at all) */\nint xt_find_revision(u8 af, const char *name, u8 revision, int target,\n\t\t     int *err)\n{\n\tint have_rev, best = -1;\n\n\tmutex_lock(&xt[af].mutex);\n\tif (target == 1)\n\t\thave_rev = target_revfn(af, name, revision, &best);\n\telse\n\t\thave_rev = match_revfn(af, name, revision, &best);\n\tmutex_unlock(&xt[af].mutex);\n\n\t/* Nothing at all?  Return 0 to try loading module. */\n\tif (best == -1) {\n\t\t*err = -ENOENT;\n\t\treturn 0;\n\t}\n\n\t*err = best;\n\tif (!have_rev)\n\t\t*err = -EPROTONOSUPPORT;\n\treturn 1;\n}\nEXPORT_SYMBOL_GPL(xt_find_revision);\n\nstatic char *\ntextify_hooks(char *buf, size_t size, unsigned int mask, uint8_t nfproto)\n{\n\tstatic const char *const inetbr_names[] = {\n\t\t\"PREROUTING\", \"INPUT\", \"FORWARD\",\n\t\t\"OUTPUT\", \"POSTROUTING\", \"BROUTING\",\n\t};\n\tstatic const char *const arp_names[] = {\n\t\t\"INPUT\", \"FORWARD\", \"OUTPUT\",\n\t};\n\tconst char *const *names;\n\tunsigned int i, max;\n\tchar *p = buf;\n\tbool np = false;\n\tint res;\n\n\tnames = (nfproto == NFPROTO_ARP) ? arp_names : inetbr_names;\n\tmax   = (nfproto == NFPROTO_ARP) ? ARRAY_SIZE(arp_names) :\n\t                                   ARRAY_SIZE(inetbr_names);\n\t*p = '\\0';\n\tfor (i = 0; i < max; ++i) {\n\t\tif (!(mask & (1 << i)))\n\t\t\tcontinue;\n\t\tres = snprintf(p, size, \"%s%s\", np ? \"/\" : \"\", names[i]);\n\t\tif (res > 0) {\n\t\t\tsize -= res;\n\t\t\tp += res;\n\t\t}\n\t\tnp = true;\n\t}\n\n\treturn buf;\n}\n\nint xt_check_match(struct xt_mtchk_param *par,\n\t\t   unsigned int size, u_int8_t proto, bool inv_proto)\n{\n\tint ret;\n\n\tif (XT_ALIGN(par->match->matchsize) != size &&\n\t    par->match->matchsize != -1) {\n\t\t/*\n\t\t * ebt_among is exempt from centralized matchsize checking\n\t\t * because it uses a dynamic-size data set.\n\t\t */\n\t\tpr_err(\"%s_tables: %s.%u match: invalid size \"\n\t\t       \"%u (kernel) != (user) %u\\n\",\n\t\t       xt_prefix[par->family], par->match->name,\n\t\t       par->match->revision,\n\t\t       XT_ALIGN(par->match->matchsize), size);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->table != NULL &&\n\t    strcmp(par->match->table, par->table) != 0) {\n\t\tpr_err(\"%s_tables: %s match: only valid in %s table, not %s\\n\",\n\t\t       xt_prefix[par->family], par->match->name,\n\t\t       par->match->table, par->table);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->hooks && (par->hook_mask & ~par->match->hooks) != 0) {\n\t\tchar used[64], allow[64];\n\n\t\tpr_err(\"%s_tables: %s match: used from hooks %s, but only \"\n\t\t       \"valid from %s\\n\",\n\t\t       xt_prefix[par->family], par->match->name,\n\t\t       textify_hooks(used, sizeof(used), par->hook_mask,\n\t\t                     par->family),\n\t\t       textify_hooks(allow, sizeof(allow), par->match->hooks,\n\t\t                     par->family));\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->proto && (par->match->proto != proto || inv_proto)) {\n\t\tpr_err(\"%s_tables: %s match: only valid for protocol %u\\n\",\n\t\t       xt_prefix[par->family], par->match->name,\n\t\t       par->match->proto);\n\t\treturn -EINVAL;\n\t}\n\tif (par->match->checkentry != NULL) {\n\t\tret = par->match->checkentry(par);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\telse if (ret > 0)\n\t\t\t/* Flag up potential errors. */\n\t\t\treturn -EIO;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_check_match);\n\n#ifdef CONFIG_COMPAT\nint xt_compat_add_offset(u_int8_t af, unsigned int offset, int delta)\n{\n\tstruct xt_af *xp = &xt[af];\n\n\tif (!xp->compat_tab) {\n\t\tif (!xp->number)\n\t\t\treturn -EINVAL;\n\t\txp->compat_tab = vmalloc(sizeof(struct compat_delta) * xp->number);\n\t\tif (!xp->compat_tab)\n\t\t\treturn -ENOMEM;\n\t\txp->cur = 0;\n\t}\n\n\tif (xp->cur >= xp->number)\n\t\treturn -EINVAL;\n\n\tif (xp->cur)\n\t\tdelta += xp->compat_tab[xp->cur - 1].delta;\n\txp->compat_tab[xp->cur].offset = offset;\n\txp->compat_tab[xp->cur].delta = delta;\n\txp->cur++;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_add_offset);\n\nvoid xt_compat_flush_offsets(u_int8_t af)\n{\n\tif (xt[af].compat_tab) {\n\t\tvfree(xt[af].compat_tab);\n\t\txt[af].compat_tab = NULL;\n\t\txt[af].number = 0;\n\t\txt[af].cur = 0;\n\t}\n}\nEXPORT_SYMBOL_GPL(xt_compat_flush_offsets);\n\nint xt_compat_calc_jump(u_int8_t af, unsigned int offset)\n{\n\tstruct compat_delta *tmp = xt[af].compat_tab;\n\tint mid, left = 0, right = xt[af].cur - 1;\n\n\twhile (left <= right) {\n\t\tmid = (left + right) >> 1;\n\t\tif (offset > tmp[mid].offset)\n\t\t\tleft = mid + 1;\n\t\telse if (offset < tmp[mid].offset)\n\t\t\tright = mid - 1;\n\t\telse\n\t\t\treturn mid ? tmp[mid - 1].delta : 0;\n\t}\n\treturn left ? tmp[left - 1].delta : 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_calc_jump);\n\nvoid xt_compat_init_offsets(u_int8_t af, unsigned int number)\n{\n\txt[af].number = number;\n\txt[af].cur = 0;\n}\nEXPORT_SYMBOL(xt_compat_init_offsets);\n\nint xt_compat_match_offset(const struct xt_match *match)\n{\n\tu_int16_t csize = match->compatsize ? : match->matchsize;\n\treturn XT_ALIGN(match->matchsize) - COMPAT_XT_ALIGN(csize);\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_offset);\n\nint xt_compat_match_from_user(struct xt_entry_match *m, void **dstptr,\n\t\t\t      unsigned int *size)\n{\n\tconst struct xt_match *match = m->u.kernel.match;\n\tstruct compat_xt_entry_match *cm = (struct compat_xt_entry_match *)m;\n\tint pad, off = xt_compat_match_offset(match);\n\tu_int16_t msize = cm->u.user.match_size;\n\n\tm = *dstptr;\n\tmemcpy(m, cm, sizeof(*cm));\n\tif (match->compat_from_user)\n\t\tmatch->compat_from_user(m->data, cm->data);\n\telse\n\t\tmemcpy(m->data, cm->data, msize - sizeof(*cm));\n\tpad = XT_ALIGN(match->matchsize) - match->matchsize;\n\tif (pad > 0)\n\t\tmemset(m->data + match->matchsize, 0, pad);\n\n\tmsize += off;\n\tm->u.user.match_size = msize;\n\n\t*size += off;\n\t*dstptr += msize;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_from_user);\n\nint xt_compat_match_to_user(const struct xt_entry_match *m,\n\t\t\t    void __user **dstptr, unsigned int *size)\n{\n\tconst struct xt_match *match = m->u.kernel.match;\n\tstruct compat_xt_entry_match __user *cm = *dstptr;\n\tint off = xt_compat_match_offset(match);\n\tu_int16_t msize = m->u.user.match_size - off;\n\n\tif (copy_to_user(cm, m, sizeof(*cm)) ||\n\t    put_user(msize, &cm->u.user.match_size) ||\n\t    copy_to_user(cm->u.user.name, m->u.kernel.match->name,\n\t\t\t strlen(m->u.kernel.match->name) + 1))\n\t\treturn -EFAULT;\n\n\tif (match->compat_to_user) {\n\t\tif (match->compat_to_user((void __user *)cm->data, m->data))\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tif (copy_to_user(cm->data, m->data, msize - sizeof(*cm)))\n\t\t\treturn -EFAULT;\n\t}\n\n\t*size -= off;\n\t*dstptr += msize;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_match_to_user);\n\n/* non-compat version may have padding after verdict */\nstruct compat_xt_standard_target {\n\tstruct compat_xt_entry_target t;\n\tcompat_uint_t verdict;\n};\n\nint xt_compat_check_entry_offsets(const void *base, const char *elems,\n\t\t\t\t  unsigned int target_offset,\n\t\t\t\t  unsigned int next_offset)\n{\n\tlong size_of_base_struct = elems - (const char *)base;\n\tconst struct compat_xt_entry_target *t;\n\tconst char *e = base;\n\n\tif (target_offset < size_of_base_struct)\n\t\treturn -EINVAL;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0 &&\n\t    target_offset + sizeof(struct compat_xt_standard_target) != next_offset)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_compat_check_entry_offsets);\n#endif /* CONFIG_COMPAT */\n\n/**\n * xt_check_entry_offsets - validate arp/ip/ip6t_entry\n *\n * @base: pointer to arp/ip/ip6t_entry\n * @elems: pointer to first xt_entry_match, i.e. ip(6)t_entry->elems\n * @target_offset: the arp/ip/ip6_t->target_offset\n * @next_offset: the arp/ip/ip6_t->next_offset\n *\n * validates that target_offset and next_offset are sane.\n * Also see xt_compat_check_entry_offsets for CONFIG_COMPAT version.\n *\n * This function does not validate the targets or matches themselves, it\n * only tests that all the offsets and sizes are correct.\n *\n * The arp/ip/ip6t_entry structure @base must have passed following tests:\n * - it must point to a valid memory location\n * - base to base + next_offset must be accessible, i.e. not exceed allocated\n *   length.\n *\n * Return: 0 on success, negative errno on failure.\n */\nint xt_check_entry_offsets(const void *base,\n\t\t\t   const char *elems,\n\t\t\t   unsigned int target_offset,\n\t\t\t   unsigned int next_offset)\n{\n\tlong size_of_base_struct = elems - (const char *)base;\n\tconst struct xt_entry_target *t;\n\tconst char *e = base;\n\n\t/* target start is within the ip/ip6/arpt_entry struct */\n\tif (target_offset < size_of_base_struct)\n\t\treturn -EINVAL;\n\n\tif (target_offset + sizeof(*t) > next_offset)\n\t\treturn -EINVAL;\n\n\tt = (void *)(e + target_offset);\n\tif (t->u.target_size < sizeof(*t))\n\t\treturn -EINVAL;\n\n\tif (target_offset + t->u.target_size > next_offset)\n\t\treturn -EINVAL;\n\n\tif (strcmp(t->u.user.name, XT_STANDARD_TARGET) == 0 &&\n\t    target_offset + sizeof(struct xt_standard_target) != next_offset)\n\t\treturn -EINVAL;\n\n\treturn 0;\n}\nEXPORT_SYMBOL(xt_check_entry_offsets);\n\nint xt_check_target(struct xt_tgchk_param *par,\n\t\t    unsigned int size, u_int8_t proto, bool inv_proto)\n{\n\tint ret;\n\n\tif (XT_ALIGN(par->target->targetsize) != size) {\n\t\tpr_err(\"%s_tables: %s.%u target: invalid size \"\n\t\t       \"%u (kernel) != (user) %u\\n\",\n\t\t       xt_prefix[par->family], par->target->name,\n\t\t       par->target->revision,\n\t\t       XT_ALIGN(par->target->targetsize), size);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->table != NULL &&\n\t    strcmp(par->target->table, par->table) != 0) {\n\t\tpr_err(\"%s_tables: %s target: only valid in %s table, not %s\\n\",\n\t\t       xt_prefix[par->family], par->target->name,\n\t\t       par->target->table, par->table);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->hooks && (par->hook_mask & ~par->target->hooks) != 0) {\n\t\tchar used[64], allow[64];\n\n\t\tpr_err(\"%s_tables: %s target: used from hooks %s, but only \"\n\t\t       \"usable from %s\\n\",\n\t\t       xt_prefix[par->family], par->target->name,\n\t\t       textify_hooks(used, sizeof(used), par->hook_mask,\n\t\t                     par->family),\n\t\t       textify_hooks(allow, sizeof(allow), par->target->hooks,\n\t\t                     par->family));\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->proto && (par->target->proto != proto || inv_proto)) {\n\t\tpr_err(\"%s_tables: %s target: only valid for protocol %u\\n\",\n\t\t       xt_prefix[par->family], par->target->name,\n\t\t       par->target->proto);\n\t\treturn -EINVAL;\n\t}\n\tif (par->target->checkentry != NULL) {\n\t\tret = par->target->checkentry(par);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\telse if (ret > 0)\n\t\t\t/* Flag up potential errors. */\n\t\t\treturn -EIO;\n\t}\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_check_target);\n\n#ifdef CONFIG_COMPAT\nint xt_compat_target_offset(const struct xt_target *target)\n{\n\tu_int16_t csize = target->compatsize ? : target->targetsize;\n\treturn XT_ALIGN(target->targetsize) - COMPAT_XT_ALIGN(csize);\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_offset);\n\nvoid xt_compat_target_from_user(struct xt_entry_target *t, void **dstptr,\n\t\t\t\tunsigned int *size)\n{\n\tconst struct xt_target *target = t->u.kernel.target;\n\tstruct compat_xt_entry_target *ct = (struct compat_xt_entry_target *)t;\n\tint pad, off = xt_compat_target_offset(target);\n\tu_int16_t tsize = ct->u.user.target_size;\n\n\tt = *dstptr;\n\tmemcpy(t, ct, sizeof(*ct));\n\tif (target->compat_from_user)\n\t\ttarget->compat_from_user(t->data, ct->data);\n\telse\n\t\tmemcpy(t->data, ct->data, tsize - sizeof(*ct));\n\tpad = XT_ALIGN(target->targetsize) - target->targetsize;\n\tif (pad > 0)\n\t\tmemset(t->data + target->targetsize, 0, pad);\n\n\ttsize += off;\n\tt->u.user.target_size = tsize;\n\n\t*size += off;\n\t*dstptr += tsize;\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_from_user);\n\nint xt_compat_target_to_user(const struct xt_entry_target *t,\n\t\t\t     void __user **dstptr, unsigned int *size)\n{\n\tconst struct xt_target *target = t->u.kernel.target;\n\tstruct compat_xt_entry_target __user *ct = *dstptr;\n\tint off = xt_compat_target_offset(target);\n\tu_int16_t tsize = t->u.user.target_size - off;\n\n\tif (copy_to_user(ct, t, sizeof(*ct)) ||\n\t    put_user(tsize, &ct->u.user.target_size) ||\n\t    copy_to_user(ct->u.user.name, t->u.kernel.target->name,\n\t\t\t strlen(t->u.kernel.target->name) + 1))\n\t\treturn -EFAULT;\n\n\tif (target->compat_to_user) {\n\t\tif (target->compat_to_user((void __user *)ct->data, t->data))\n\t\t\treturn -EFAULT;\n\t} else {\n\t\tif (copy_to_user(ct->data, t->data, tsize - sizeof(*ct)))\n\t\t\treturn -EFAULT;\n\t}\n\n\t*size -= off;\n\t*dstptr += tsize;\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(xt_compat_target_to_user);\n#endif\n\nstruct xt_table_info *xt_alloc_table_info(unsigned int size)\n{\n\tstruct xt_table_info *info = NULL;\n\tsize_t sz = sizeof(*info) + size;\n\n\tif (sz < sizeof(*info))\n\t\treturn NULL;\n\n\t/* Pedantry: prevent them from hitting BUG() in vmalloc.c --RR */\n\tif ((SMP_ALIGN(size) >> PAGE_SHIFT) + 2 > totalram_pages)\n\t\treturn NULL;\n\n\tif (sz <= (PAGE_SIZE << PAGE_ALLOC_COSTLY_ORDER))\n\t\tinfo = kmalloc(sz, GFP_KERNEL | __GFP_NOWARN | __GFP_NORETRY);\n\tif (!info) {\n\t\tinfo = vmalloc(sz);\n\t\tif (!info)\n\t\t\treturn NULL;\n\t}\n\tmemset(info, 0, sizeof(*info));\n\tinfo->size = size;\n\treturn info;\n}\nEXPORT_SYMBOL(xt_alloc_table_info);\n\nvoid xt_free_table_info(struct xt_table_info *info)\n{\n\tint cpu;\n\n\tif (info->jumpstack != NULL) {\n\t\tfor_each_possible_cpu(cpu)\n\t\t\tkvfree(info->jumpstack[cpu]);\n\t\tkvfree(info->jumpstack);\n\t}\n\n\tkvfree(info);\n}\nEXPORT_SYMBOL(xt_free_table_info);\n\n/* Find table by name, grabs mutex & ref.  Returns ERR_PTR() on error. */\nstruct xt_table *xt_find_table_lock(struct net *net, u_int8_t af,\n\t\t\t\t    const char *name)\n{\n\tstruct xt_table *t, *found = NULL;\n\n\tmutex_lock(&xt[af].mutex);\n\tlist_for_each_entry(t, &net->xt.tables[af], list)\n\t\tif (strcmp(t->name, name) == 0 && try_module_get(t->me))\n\t\t\treturn t;\n\n\tif (net == &init_net)\n\t\tgoto out;\n\n\t/* Table doesn't exist in this netns, re-try init */\n\tlist_for_each_entry(t, &init_net.xt.tables[af], list) {\n\t\tif (strcmp(t->name, name))\n\t\t\tcontinue;\n\t\tif (!try_module_get(t->me))\n\t\t\treturn NULL;\n\n\t\tmutex_unlock(&xt[af].mutex);\n\t\tif (t->table_init(net) != 0) {\n\t\t\tmodule_put(t->me);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tfound = t;\n\n\t\tmutex_lock(&xt[af].mutex);\n\t\tbreak;\n\t}\n\n\tif (!found)\n\t\tgoto out;\n\n\t/* and once again: */\n\tlist_for_each_entry(t, &net->xt.tables[af], list)\n\t\tif (strcmp(t->name, name) == 0)\n\t\t\treturn t;\n\n\tmodule_put(found->me);\n out:\n\tmutex_unlock(&xt[af].mutex);\n\treturn NULL;\n}\nEXPORT_SYMBOL_GPL(xt_find_table_lock);\n\nvoid xt_table_unlock(struct xt_table *table)\n{\n\tmutex_unlock(&xt[table->af].mutex);\n}\nEXPORT_SYMBOL_GPL(xt_table_unlock);\n\n#ifdef CONFIG_COMPAT\nvoid xt_compat_lock(u_int8_t af)\n{\n\tmutex_lock(&xt[af].compat_mutex);\n}\nEXPORT_SYMBOL_GPL(xt_compat_lock);\n\nvoid xt_compat_unlock(u_int8_t af)\n{\n\tmutex_unlock(&xt[af].compat_mutex);\n}\nEXPORT_SYMBOL_GPL(xt_compat_unlock);\n#endif\n\nDEFINE_PER_CPU(seqcount_t, xt_recseq);\nEXPORT_PER_CPU_SYMBOL_GPL(xt_recseq);\n\nstruct static_key xt_tee_enabled __read_mostly;\nEXPORT_SYMBOL_GPL(xt_tee_enabled);\n\nstatic int xt_jumpstack_alloc(struct xt_table_info *i)\n{\n\tunsigned int size;\n\tint cpu;\n\n\tsize = sizeof(void **) * nr_cpu_ids;\n\tif (size > PAGE_SIZE)\n\t\ti->jumpstack = vzalloc(size);\n\telse\n\t\ti->jumpstack = kzalloc(size, GFP_KERNEL);\n\tif (i->jumpstack == NULL)\n\t\treturn -ENOMEM;\n\n\t/* ruleset without jumps -- no stack needed */\n\tif (i->stacksize == 0)\n\t\treturn 0;\n\n\t/* Jumpstack needs to be able to record two full callchains, one\n\t * from the first rule set traversal, plus one table reentrancy\n\t * via -j TEE without clobbering the callchain that brought us to\n\t * TEE target.\n\t *\n\t * This is done by allocating two jumpstacks per cpu, on reentry\n\t * the upper half of the stack is used.\n\t *\n\t * see the jumpstack setup in ipt_do_table() for more details.\n\t */\n\tsize = sizeof(void *) * i->stacksize * 2u;\n\tfor_each_possible_cpu(cpu) {\n\t\tif (size > PAGE_SIZE)\n\t\t\ti->jumpstack[cpu] = vmalloc_node(size,\n\t\t\t\tcpu_to_node(cpu));\n\t\telse\n\t\t\ti->jumpstack[cpu] = kmalloc_node(size,\n\t\t\t\tGFP_KERNEL, cpu_to_node(cpu));\n\t\tif (i->jumpstack[cpu] == NULL)\n\t\t\t/*\n\t\t\t * Freeing will be done later on by the callers. The\n\t\t\t * chain is: xt_replace_table -> __do_replace ->\n\t\t\t * do_replace -> xt_free_table_info.\n\t\t\t */\n\t\t\treturn -ENOMEM;\n\t}\n\n\treturn 0;\n}\n\nstruct xt_table_info *\nxt_replace_table(struct xt_table *table,\n\t      unsigned int num_counters,\n\t      struct xt_table_info *newinfo,\n\t      int *error)\n{\n\tstruct xt_table_info *private;\n\tint ret;\n\n\tret = xt_jumpstack_alloc(newinfo);\n\tif (ret < 0) {\n\t\t*error = ret;\n\t\treturn NULL;\n\t}\n\n\t/* Do the substitution. */\n\tlocal_bh_disable();\n\tprivate = table->private;\n\n\t/* Check inside lock: is the old number correct? */\n\tif (num_counters != private->number) {\n\t\tpr_debug(\"num_counters != table->private->number (%u/%u)\\n\",\n\t\t\t num_counters, private->number);\n\t\tlocal_bh_enable();\n\t\t*error = -EAGAIN;\n\t\treturn NULL;\n\t}\n\n\tnewinfo->initial_entries = private->initial_entries;\n\t/*\n\t * Ensure contents of newinfo are visible before assigning to\n\t * private.\n\t */\n\tsmp_wmb();\n\ttable->private = newinfo;\n\n\t/*\n\t * Even though table entries have now been swapped, other CPU's\n\t * may still be using the old entries. This is okay, because\n\t * resynchronization happens because of the locking done\n\t * during the get_counters() routine.\n\t */\n\tlocal_bh_enable();\n\n#ifdef CONFIG_AUDIT\n\tif (audit_enabled) {\n\t\tstruct audit_buffer *ab;\n\n\t\tab = audit_log_start(current->audit_context, GFP_KERNEL,\n\t\t\t\t     AUDIT_NETFILTER_CFG);\n\t\tif (ab) {\n\t\t\taudit_log_format(ab, \"table=%s family=%u entries=%u\",\n\t\t\t\t\t table->name, table->af,\n\t\t\t\t\t private->number);\n\t\t\taudit_log_end(ab);\n\t\t}\n\t}\n#endif\n\n\treturn private;\n}\nEXPORT_SYMBOL_GPL(xt_replace_table);\n\nstruct xt_table *xt_register_table(struct net *net,\n\t\t\t\t   const struct xt_table *input_table,\n\t\t\t\t   struct xt_table_info *bootstrap,\n\t\t\t\t   struct xt_table_info *newinfo)\n{\n\tint ret;\n\tstruct xt_table_info *private;\n\tstruct xt_table *t, *table;\n\n\t/* Don't add one object to multiple lists. */\n\ttable = kmemdup(input_table, sizeof(struct xt_table), GFP_KERNEL);\n\tif (!table) {\n\t\tret = -ENOMEM;\n\t\tgoto out;\n\t}\n\n\tmutex_lock(&xt[table->af].mutex);\n\t/* Don't autoload: we'd eat our tail... */\n\tlist_for_each_entry(t, &net->xt.tables[table->af], list) {\n\t\tif (strcmp(t->name, table->name) == 0) {\n\t\t\tret = -EEXIST;\n\t\t\tgoto unlock;\n\t\t}\n\t}\n\n\t/* Simplifies replace_table code. */\n\ttable->private = bootstrap;\n\n\tif (!xt_replace_table(table, 0, newinfo, &ret))\n\t\tgoto unlock;\n\n\tprivate = table->private;\n\tpr_debug(\"table->private->number = %u\\n\", private->number);\n\n\t/* save number of initial entries */\n\tprivate->initial_entries = private->number;\n\n\tlist_add(&table->list, &net->xt.tables[table->af]);\n\tmutex_unlock(&xt[table->af].mutex);\n\treturn table;\n\nunlock:\n\tmutex_unlock(&xt[table->af].mutex);\n\tkfree(table);\nout:\n\treturn ERR_PTR(ret);\n}\nEXPORT_SYMBOL_GPL(xt_register_table);\n\nvoid *xt_unregister_table(struct xt_table *table)\n{\n\tstruct xt_table_info *private;\n\n\tmutex_lock(&xt[table->af].mutex);\n\tprivate = table->private;\n\tlist_del(&table->list);\n\tmutex_unlock(&xt[table->af].mutex);\n\tkfree(table);\n\n\treturn private;\n}\nEXPORT_SYMBOL_GPL(xt_unregister_table);\n\n#ifdef CONFIG_PROC_FS\nstruct xt_names_priv {\n\tstruct seq_net_private p;\n\tu_int8_t af;\n};\nstatic void *xt_table_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\tstruct xt_names_priv *priv = seq->private;\n\tstruct net *net = seq_file_net(seq);\n\tu_int8_t af = priv->af;\n\n\tmutex_lock(&xt[af].mutex);\n\treturn seq_list_start(&net->xt.tables[af], *pos);\n}\n\nstatic void *xt_table_seq_next(struct seq_file *seq, void *v, loff_t *pos)\n{\n\tstruct xt_names_priv *priv = seq->private;\n\tstruct net *net = seq_file_net(seq);\n\tu_int8_t af = priv->af;\n\n\treturn seq_list_next(v, &net->xt.tables[af], pos);\n}\n\nstatic void xt_table_seq_stop(struct seq_file *seq, void *v)\n{\n\tstruct xt_names_priv *priv = seq->private;\n\tu_int8_t af = priv->af;\n\n\tmutex_unlock(&xt[af].mutex);\n}\n\nstatic int xt_table_seq_show(struct seq_file *seq, void *v)\n{\n\tstruct xt_table *table = list_entry(v, struct xt_table, list);\n\n\tif (*table->name)\n\t\tseq_printf(seq, \"%s\\n\", table->name);\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_table_seq_ops = {\n\t.start\t= xt_table_seq_start,\n\t.next\t= xt_table_seq_next,\n\t.stop\t= xt_table_seq_stop,\n\t.show\t= xt_table_seq_show,\n};\n\nstatic int xt_table_open(struct inode *inode, struct file *file)\n{\n\tint ret;\n\tstruct xt_names_priv *priv;\n\n\tret = seq_open_net(inode, file, &xt_table_seq_ops,\n\t\t\t   sizeof(struct xt_names_priv));\n\tif (!ret) {\n\t\tpriv = ((struct seq_file *)file->private_data)->private;\n\t\tpriv->af = (unsigned long)PDE_DATA(inode);\n\t}\n\treturn ret;\n}\n\nstatic const struct file_operations xt_table_ops = {\n\t.owner\t = THIS_MODULE,\n\t.open\t = xt_table_open,\n\t.read\t = seq_read,\n\t.llseek\t = seq_lseek,\n\t.release = seq_release_net,\n};\n\n/*\n * Traverse state for ip{,6}_{tables,matches} for helping crossing\n * the multi-AF mutexes.\n */\nstruct nf_mttg_trav {\n\tstruct list_head *head, *curr;\n\tuint8_t class, nfproto;\n};\n\nenum {\n\tMTTG_TRAV_INIT,\n\tMTTG_TRAV_NFP_UNSPEC,\n\tMTTG_TRAV_NFP_SPEC,\n\tMTTG_TRAV_DONE,\n};\n\nstatic void *xt_mttg_seq_next(struct seq_file *seq, void *v, loff_t *ppos,\n    bool is_target)\n{\n\tstatic const uint8_t next_class[] = {\n\t\t[MTTG_TRAV_NFP_UNSPEC] = MTTG_TRAV_NFP_SPEC,\n\t\t[MTTG_TRAV_NFP_SPEC]   = MTTG_TRAV_DONE,\n\t};\n\tstruct nf_mttg_trav *trav = seq->private;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_INIT:\n\t\ttrav->class = MTTG_TRAV_NFP_UNSPEC;\n\t\tmutex_lock(&xt[NFPROTO_UNSPEC].mutex);\n\t\ttrav->head = trav->curr = is_target ?\n\t\t\t&xt[NFPROTO_UNSPEC].target : &xt[NFPROTO_UNSPEC].match;\n \t\tbreak;\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\t\ttrav->curr = trav->curr->next;\n\t\tif (trav->curr != trav->head)\n\t\t\tbreak;\n\t\tmutex_unlock(&xt[NFPROTO_UNSPEC].mutex);\n\t\tmutex_lock(&xt[trav->nfproto].mutex);\n\t\ttrav->head = trav->curr = is_target ?\n\t\t\t&xt[trav->nfproto].target : &xt[trav->nfproto].match;\n\t\ttrav->class = next_class[trav->class];\n\t\tbreak;\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\ttrav->curr = trav->curr->next;\n\t\tif (trav->curr != trav->head)\n\t\t\tbreak;\n\t\t/* fallthru, _stop will unlock */\n\tdefault:\n\t\treturn NULL;\n\t}\n\n\tif (ppos != NULL)\n\t\t++*ppos;\n\treturn trav;\n}\n\nstatic void *xt_mttg_seq_start(struct seq_file *seq, loff_t *pos,\n    bool is_target)\n{\n\tstruct nf_mttg_trav *trav = seq->private;\n\tunsigned int j;\n\n\ttrav->class = MTTG_TRAV_INIT;\n\tfor (j = 0; j < *pos; ++j)\n\t\tif (xt_mttg_seq_next(seq, NULL, NULL, is_target) == NULL)\n\t\t\treturn NULL;\n\treturn trav;\n}\n\nstatic void xt_mttg_seq_stop(struct seq_file *seq, void *v)\n{\n\tstruct nf_mttg_trav *trav = seq->private;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\t\tmutex_unlock(&xt[NFPROTO_UNSPEC].mutex);\n\t\tbreak;\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tmutex_unlock(&xt[trav->nfproto].mutex);\n\t\tbreak;\n\t}\n}\n\nstatic void *xt_match_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\treturn xt_mttg_seq_start(seq, pos, false);\n}\n\nstatic void *xt_match_seq_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn xt_mttg_seq_next(seq, v, ppos, false);\n}\n\nstatic int xt_match_seq_show(struct seq_file *seq, void *v)\n{\n\tconst struct nf_mttg_trav *trav = seq->private;\n\tconst struct xt_match *match;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tif (trav->curr == trav->head)\n\t\t\treturn 0;\n\t\tmatch = list_entry(trav->curr, struct xt_match, list);\n\t\tif (*match->name)\n\t\t\tseq_printf(seq, \"%s\\n\", match->name);\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_match_seq_ops = {\n\t.start\t= xt_match_seq_start,\n\t.next\t= xt_match_seq_next,\n\t.stop\t= xt_mttg_seq_stop,\n\t.show\t= xt_match_seq_show,\n};\n\nstatic int xt_match_open(struct inode *inode, struct file *file)\n{\n\tstruct nf_mttg_trav *trav;\n\ttrav = __seq_open_private(file, &xt_match_seq_ops, sizeof(*trav));\n\tif (!trav)\n\t\treturn -ENOMEM;\n\n\ttrav->nfproto = (unsigned long)PDE_DATA(inode);\n\treturn 0;\n}\n\nstatic const struct file_operations xt_match_ops = {\n\t.owner\t = THIS_MODULE,\n\t.open\t = xt_match_open,\n\t.read\t = seq_read,\n\t.llseek\t = seq_lseek,\n\t.release = seq_release_private,\n};\n\nstatic void *xt_target_seq_start(struct seq_file *seq, loff_t *pos)\n{\n\treturn xt_mttg_seq_start(seq, pos, true);\n}\n\nstatic void *xt_target_seq_next(struct seq_file *seq, void *v, loff_t *ppos)\n{\n\treturn xt_mttg_seq_next(seq, v, ppos, true);\n}\n\nstatic int xt_target_seq_show(struct seq_file *seq, void *v)\n{\n\tconst struct nf_mttg_trav *trav = seq->private;\n\tconst struct xt_target *target;\n\n\tswitch (trav->class) {\n\tcase MTTG_TRAV_NFP_UNSPEC:\n\tcase MTTG_TRAV_NFP_SPEC:\n\t\tif (trav->curr == trav->head)\n\t\t\treturn 0;\n\t\ttarget = list_entry(trav->curr, struct xt_target, list);\n\t\tif (*target->name)\n\t\t\tseq_printf(seq, \"%s\\n\", target->name);\n\t}\n\treturn 0;\n}\n\nstatic const struct seq_operations xt_target_seq_ops = {\n\t.start\t= xt_target_seq_start,\n\t.next\t= xt_target_seq_next,\n\t.stop\t= xt_mttg_seq_stop,\n\t.show\t= xt_target_seq_show,\n};\n\nstatic int xt_target_open(struct inode *inode, struct file *file)\n{\n\tstruct nf_mttg_trav *trav;\n\ttrav = __seq_open_private(file, &xt_target_seq_ops, sizeof(*trav));\n\tif (!trav)\n\t\treturn -ENOMEM;\n\n\ttrav->nfproto = (unsigned long)PDE_DATA(inode);\n\treturn 0;\n}\n\nstatic const struct file_operations xt_target_ops = {\n\t.owner\t = THIS_MODULE,\n\t.open\t = xt_target_open,\n\t.read\t = seq_read,\n\t.llseek\t = seq_lseek,\n\t.release = seq_release_private,\n};\n\n#define FORMAT_TABLES\t\"_tables_names\"\n#define\tFORMAT_MATCHES\t\"_tables_matches\"\n#define FORMAT_TARGETS \t\"_tables_targets\"\n\n#endif /* CONFIG_PROC_FS */\n\n/**\n * xt_hook_ops_alloc - set up hooks for a new table\n * @table:\ttable with metadata needed to set up hooks\n * @fn:\t\tHook function\n *\n * This function will create the nf_hook_ops that the x_table needs\n * to hand to xt_hook_link_net().\n */\nstruct nf_hook_ops *\nxt_hook_ops_alloc(const struct xt_table *table, nf_hookfn *fn)\n{\n\tunsigned int hook_mask = table->valid_hooks;\n\tuint8_t i, num_hooks = hweight32(hook_mask);\n\tuint8_t hooknum;\n\tstruct nf_hook_ops *ops;\n\n\tops = kmalloc(sizeof(*ops) * num_hooks, GFP_KERNEL);\n\tif (ops == NULL)\n\t\treturn ERR_PTR(-ENOMEM);\n\n\tfor (i = 0, hooknum = 0; i < num_hooks && hook_mask != 0;\n\t     hook_mask >>= 1, ++hooknum) {\n\t\tif (!(hook_mask & 1))\n\t\t\tcontinue;\n\t\tops[i].hook     = fn;\n\t\tops[i].pf       = table->af;\n\t\tops[i].hooknum  = hooknum;\n\t\tops[i].priority = table->priority;\n\t\t++i;\n\t}\n\n\treturn ops;\n}\nEXPORT_SYMBOL_GPL(xt_hook_ops_alloc);\n\nint xt_proto_init(struct net *net, u_int8_t af)\n{\n#ifdef CONFIG_PROC_FS\n\tchar buf[XT_FUNCTION_MAXNAMELEN];\n\tstruct proc_dir_entry *proc;\n\tkuid_t root_uid;\n\tkgid_t root_gid;\n#endif\n\n\tif (af >= ARRAY_SIZE(xt_prefix))\n\t\treturn -EINVAL;\n\n\n#ifdef CONFIG_PROC_FS\n\troot_uid = make_kuid(net->user_ns, 0);\n\troot_gid = make_kgid(net->user_ns, 0);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tproc = proc_create_data(buf, 0440, net->proc_net, &xt_table_ops,\n\t\t\t\t(void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tproc = proc_create_data(buf, 0440, net->proc_net, &xt_match_ops,\n\t\t\t\t(void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out_remove_tables;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TARGETS, sizeof(buf));\n\tproc = proc_create_data(buf, 0440, net->proc_net, &xt_target_ops,\n\t\t\t\t(void *)(unsigned long)af);\n\tif (!proc)\n\t\tgoto out_remove_matches;\n\tif (uid_valid(root_uid) && gid_valid(root_gid))\n\t\tproc_set_user(proc, root_uid, root_gid);\n#endif\n\n\treturn 0;\n\n#ifdef CONFIG_PROC_FS\nout_remove_matches:\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\nout_remove_tables:\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\nout:\n\treturn -1;\n#endif\n}\nEXPORT_SYMBOL_GPL(xt_proto_init);\n\nvoid xt_proto_fini(struct net *net, u_int8_t af)\n{\n#ifdef CONFIG_PROC_FS\n\tchar buf[XT_FUNCTION_MAXNAMELEN];\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TABLES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_TARGETS, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n\n\tstrlcpy(buf, xt_prefix[af], sizeof(buf));\n\tstrlcat(buf, FORMAT_MATCHES, sizeof(buf));\n\tremove_proc_entry(buf, net->proc_net);\n#endif /*CONFIG_PROC_FS*/\n}\nEXPORT_SYMBOL_GPL(xt_proto_fini);\n\nstatic int __net_init xt_net_init(struct net *net)\n{\n\tint i;\n\n\tfor (i = 0; i < NFPROTO_NUMPROTO; i++)\n\t\tINIT_LIST_HEAD(&net->xt.tables[i]);\n\treturn 0;\n}\n\nstatic struct pernet_operations xt_net_ops = {\n\t.init = xt_net_init,\n};\n\nstatic int __init xt_init(void)\n{\n\tunsigned int i;\n\tint rv;\n\n\tfor_each_possible_cpu(i) {\n\t\tseqcount_init(&per_cpu(xt_recseq, i));\n\t}\n\n\txt = kmalloc(sizeof(struct xt_af) * NFPROTO_NUMPROTO, GFP_KERNEL);\n\tif (!xt)\n\t\treturn -ENOMEM;\n\n\tfor (i = 0; i < NFPROTO_NUMPROTO; i++) {\n\t\tmutex_init(&xt[i].mutex);\n#ifdef CONFIG_COMPAT\n\t\tmutex_init(&xt[i].compat_mutex);\n\t\txt[i].compat_tab = NULL;\n#endif\n\t\tINIT_LIST_HEAD(&xt[i].target);\n\t\tINIT_LIST_HEAD(&xt[i].match);\n\t}\n\trv = register_pernet_subsys(&xt_net_ops);\n\tif (rv < 0)\n\t\tkfree(xt);\n\treturn rv;\n}\n\nstatic void __exit xt_fini(void)\n{\n\tunregister_pernet_subsys(&xt_net_ops);\n\tkfree(xt);\n}\n\nmodule_init(xt_init);\nmodule_exit(xt_fini);\n\n"], "filenames": ["include/linux/netfilter/x_tables.h", "net/ipv4/netfilter/arp_tables.c", "net/ipv4/netfilter/ip_tables.c", "net/ipv6/netfilter/ip6_tables.c", "net/netfilter/x_tables.c"], "buggy_code_start_loc": [245, 595, 757, 769, 549], "buggy_code_end_loc": [498, 1258, 1517, 1529, 598], "fixing_code_start_loc": [245, 595, 757, 769, 549], "fixing_code_end_loc": [498, 1259, 1518, 1530, 612], "type": "CWE-264", "message": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement.", "other": {"cve": {"id": "CVE-2016-4997", "sourceIdentifier": "secalert@redhat.com", "published": "2016-07-03T21:59:16.057", "lastModified": "2023-02-12T23:22:40.897", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The compat IPT_SO_SET_REPLACE and IP6T_SO_SET_REPLACE setsockopt implementations in the netfilter subsystem in the Linux kernel before 4.6.3 allow local users to gain privileges or cause a denial of service (memory corruption) by leveraging in-container root access to provide a crafted offset value that triggers an unintended decrement."}, {"lang": "es", "value": "Las implementaciones de setsockopt del compat IPT_SO_SET_REPLACE y IP6T_SO_SET_REPLACE en el subsistema de netfilter en el kernel de Linux en versiones anteriores a 4.6.3 permiten a usuarios locales obtener privilegios o provocar una denegaci\u00f3n de servicio (corrupci\u00f3n de memoria) aprovechando el acceso root en contenedor para proveer un valor de desplazamiento manipulado que desencadena un decremento involuntario."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 7.2}, "baseSeverity": "HIGH", "exploitabilityScore": 3.9, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-264"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.17", "versionEndExcluding": "3.2.80", "matchCriteriaId": "14022F90-39CA-4DE4-B584-6380B9F657B7"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.3", "versionEndExcluding": "3.10.103", "matchCriteriaId": "0DC9AE03-9DF2-4168-8542-1171CB42C604"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.11", "versionEndExcluding": "3.12.62", "matchCriteriaId": "CB3CF40A-6C26-4C0B-B6F1-41BE884182DA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.13", "versionEndExcluding": "3.14.73", "matchCriteriaId": "1346A01D-227D-4D11-8C7A-ADBAE630C87D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.15", "versionEndExcluding": "3.16.37", "matchCriteriaId": "7DEF7E2D-A1AA-4733-A573-11EE52A2B419"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.17", "versionEndExcluding": "3.18.37", "matchCriteriaId": "B55F09A2-F470-41BA-9585-40E8C1960ABA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.19", "versionEndExcluding": "4.1.28", "matchCriteriaId": "2BACB680-D42D-4EFF-9B8B-121AA348DB7A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.2", "versionEndExcluding": "4.4.14", "matchCriteriaId": "06B86F5B-ACB3-42F5-B15C-0EEB47DF8809"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.5", "versionEndExcluding": "4.6.3", "matchCriteriaId": "0911A351-61CB-4070-A172-8AD9BC1871AE"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:12.04:*:*:*:lts:*:*:*", "matchCriteriaId": "B6B7CAD7-9D4E-4FDB-88E3-1E583210A01F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:lts:*:*:*", "matchCriteriaId": "B5A6F2F3-4894-4392-8296-3B8DD2679084"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:15.10:*:*:*:*:*:*:*", "matchCriteriaId": "E88A537F-F4D0-46B9-9E37-965233C2A355"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:16.04:*:*:*:lts:*:*:*", "matchCriteriaId": "F7016A2A-8365-4F1A-89A2-7A19F2BCAE5B"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_desktop:12.0:*:*:*:*:*:*:*", "matchCriteriaId": "EA04C9F1-6257-4D82-BA0B-37DE66D94736"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_desktop:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "6359EF76-9371-4418-8694-B604CF02CF63"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_live_patching:12.0:*:*:*:*:*:*:*", "matchCriteriaId": "CCAAE4A1-D542-43F3-B7FC-685BCDB248D5"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_module_for_public_cloud:12.0:*:*:*:*:*:*:*", "matchCriteriaId": "A961CBC6-3CA1-4A0F-BBE0-8F6315781B7C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_real_time_extension:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "B2905A9C-3E00-4188-8341-E5C2F62EF405"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_server:12.0:*:*:*:*:*:*:*", "matchCriteriaId": "C384D0B6-8A5C-45CA-8CD9-7F4E967FE4F0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_server:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "81D94366-47D6-445A-A811-39327B150FCD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_software_development_kit:12.0:*:*:*:*:*:*:*", "matchCriteriaId": "E85AFCCA-8B55-4F7C-A282-691CCA624D79"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_software_development_kit:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "F5A10CB2-3AB0-4ADB-A072-A2E18B1DC642"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_workstation_extension:12.0:*:*:*:*:*:*:*", "matchCriteriaId": "DF461FB4-8BA5-4065-9A69-DC017D3611C3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:novell:suse_linux_enterprise_workstation_extension:12.0:sp1:*:*:*:*:*:*", "matchCriteriaId": "1F003591-0639-476C-A014-03F06A274880"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:oracle:linux:7:*:*:*:*:*:*:*", "matchCriteriaId": "104DA87B-DEE4-4262-AE50-8E6BC43B228B"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=ce683e5f9d045e5d67d1312a42b359cb2ab2a13c", "source": "secalert@redhat.com", "tags": ["Vendor Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-06/msg00060.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-06/msg00061.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00000.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00007.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00027.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00044.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00048.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00050.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00051.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00052.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00053.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00054.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2016-08/msg00055.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2016-1847.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2016-1875.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2016-1883.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.debian.org/security/2016/dsa-3607", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.6.3", "source": "secalert@redhat.com", "tags": ["Vendor Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2016/06/24/5", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2016/09/29/10", "source": "secalert@redhat.com", "tags": ["Exploit", "Mailing List", "Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/topics/security/linuxbulletinjul2016-3090544.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/topics/security/linuxbulletinoct2016-3090545.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.oracle.com/technetwork/topics/security/ovmbulletinoct2016-3090547.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/91451", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.securitytracker.com/id/1036171", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://www.ubuntu.com/usn/USN-3016-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3016-2", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3016-3", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3016-4", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3017-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3017-2", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3017-3", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3018-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3018-2", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3019-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-3020-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1349722", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/nccgroup/TriforceLinuxSyscallFuzzer/tree/master/crash_reports/report_compatIpt", "source": "secalert@redhat.com", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://h20566.www2.hpe.com/portal/site/hpsc/public/kb/docDisplay?docId=emr_na-c05347541", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://www.exploit-db.com/exploits/40435/", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://www.exploit-db.com/exploits/40489/", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/ce683e5f9d045e5d67d1312a42b359cb2ab2a13c"}}
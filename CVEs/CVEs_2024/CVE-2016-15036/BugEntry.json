{"buggy_code": ["package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/deis/workflow-manager/config\"\n\t\"github.com/deis/workflow-manager/data\"\n\t\"github.com/deis/workflow-manager/handlers\"\n\t\"github.com/deis/workflow-manager/jobs\"\n\t\"github.com/deis/workflow-manager/k8s\"\n\t\"github.com/gorilla/mux\"\n\tkcl \"k8s.io/kubernetes/pkg/client/unversioned\"\n)\n\nfunc main() {\n\tkubeClient, err := kcl.NewInCluster()\n\tif err != nil {\n\t\tlog.Fatalf(\"Error creating new Kubernetes client (%s)\", err)\n\t}\n\tapiClient, err := config.GetSwaggerClient(config.Spec.VersionsAPIURL)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error creating new swagger api client (%s)\", err)\n\t}\n\tdeisK8sResources := k8s.NewResourceInterfaceNamespaced(kubeClient, config.Spec.DeisNamespace)\n\tclusterID := data.NewClusterIDFromPersistentStorage(deisK8sResources.Secrets())\n\tinstalledDeisData := data.NewInstalledDeisData(deisK8sResources)\n\tavailableVersion := data.NewAvailableVersionsFromAPI(\n\t\tapiClient,\n\t\tconfig.Spec.VersionsAPIURL,\n\t)\n\tavailableComponentVersion := data.NewLatestReleasedComponent(deisK8sResources, availableVersion)\n\n\tpollDur := time.Duration(config.Spec.Polling) * time.Second\n\t// we want to do the following jobs according to our remote API interval:\n\t// 1. get latest stable deis component versions\n\t// 2. send diagnostic data, if appropriate\n\tglvdPeriodic := jobs.NewGetLatestVersionDataPeriodic(\n\t\tinstalledDeisData,\n\t\tclusterID,\n\t\tavailableVersion,\n\t\tavailableComponentVersion,\n\t\tpollDur,\n\t)\n\n\tsvPeriodic := jobs.NewSendVersionsPeriodic(\n\t\tapiClient,\n\t\tdeisK8sResources,\n\t\tavailableVersion,\n\t\tpollDur,\n\t)\n\ttoDo := []jobs.Periodic{glvdPeriodic, svPeriodic}\n\tlog.Printf(\"Starting periodic jobs at interval %s\", pollDur)\n\tch := jobs.DoPeriodic(toDo)\n\tdefer close(ch)\n\n\t// Get a new router, with handler functions\n\tr := handlers.RegisterRoutes(mux.NewRouter(), availableVersion, deisK8sResources)\n\t// Bind to a port and pass our router in\n\thostStr := fmt.Sprintf(\":%s\", config.Spec.Port)\n\tlog.Printf(\"Serving on %s\", hostStr)\n\tif err := http.ListenAndServe(hostStr, r); err != nil {\n\t\tclose(ch)\n\t\tlog.Println(\"Unable to open up TLS listener\")\n\t\tlog.Fatal(\"ListenAndServe: \", err)\n\t}\n}\n", "package data\n\nimport (\n\t\"sync\"\n\n\t\"github.com/deis/workflow-manager/k8s\"\n\t\"github.com/satori/go.uuid\"\n\t\"k8s.io/kubernetes/pkg/api\"\n\tapierrors \"k8s.io/kubernetes/pkg/api/errors\"\n)\n\n// ClusterID is an interface for managing cluster ID data\ntype ClusterID interface {\n\t// will have a Get method to retrieve the cluster ID\n\tGet() (string, error)\n\t// Cached returns the internal cache of the cluster ID. returns the empty string on a miss\n\tCached() string\n\t// StoreInCache stores the given string in the internal cluster ID cache\n\tStoreInCache(string)\n}\n\n// GetID gets the cluster ID from the cache. on a cache miss, uses the k8s API to get it\nfunc GetID(id ClusterID) (string, error) {\n\t// First, check to see if we have an in-memory copy\n\tdata := id.Cached()\n\t// If we haven't yet cached the ID in memory, invoke the passed-in getter\n\tif data == \"\" {\n\t\td, err := id.Get()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tdata = d\n\t}\n\treturn data, nil\n}\n\ntype clusterIDFromPersistentStorage struct {\n\trwm                 *sync.RWMutex\n\tcache               string\n\tsecretGetterCreator k8s.KubeSecretGetterCreator\n}\n\n// NewClusterIDFromPersistentStorage returns a new ClusterID implementation that uses the kubernetes API to get its cluster information\nfunc NewClusterIDFromPersistentStorage(sgc k8s.KubeSecretGetterCreator) ClusterID {\n\treturn &clusterIDFromPersistentStorage{\n\t\trwm:                 new(sync.RWMutex),\n\t\tcache:               \"\",\n\t\tsecretGetterCreator: sgc,\n\t}\n}\n\n// Get is the ClusterID interface implementation\nfunc (c clusterIDFromPersistentStorage) Get() (string, error) {\n\tsecret, err := c.secretGetterCreator.Get(wfmSecretName)\n\t//If we don't have the secret we shouldn't be returning error and instead a create a new one\n\tif err != nil && !apierrors.IsNotFound(err) {\n\t\treturn \"\", err\n\t}\n\t// if we don't have secret data for the cluster ID we assume a new cluster\n\t// and create a new secret\n\tif secret.Data[clusterIDSecretKey] == nil {\n\t\tnewSecret := new(api.Secret)\n\t\tnewSecret.Name = wfmSecretName\n\t\tnewSecret.Data = make(map[string][]byte)\n\t\tnewSecret.Data[clusterIDSecretKey] = []byte(uuid.NewV4().String())\n\t\tfromAPI, err := c.secretGetterCreator.Create(newSecret)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tsecret = fromAPI\n\t}\n\treturn string(secret.Data[clusterIDSecretKey]), nil\n}\n\n// StoreInCache is the ClusterID interface implementation\nfunc (c *clusterIDFromPersistentStorage) StoreInCache(cid string) {\n\tc.rwm.Lock()\n\tdefer c.rwm.Unlock()\n\tc.cache = cid\n}\n\n// Cached is the ClusterID interface implementation\nfunc (c clusterIDFromPersistentStorage) Cached() string {\n\tc.rwm.RLock()\n\tdefer c.rwm.RUnlock()\n\treturn c.cache\n}\n", "package jobs\n\nimport (\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/deis/workflow-manager/config\"\n\t\"github.com/deis/workflow-manager/data\"\n\t\"github.com/deis/workflow-manager/k8s\"\n\tapiclient \"github.com/deis/workflow-manager/pkg/swagger/client\"\n\t\"github.com/deis/workflow-manager/pkg/swagger/client/operations\"\n)\n\n// Periodic is an interface for managing periodic job invocation\ntype Periodic interface {\n\t// Do begins the periodic job. It starts the first execution of the job, and then is\n\t// repsonsible for executing it every Frequency() thereafter\n\tDo() error\n\tFrequency() time.Duration\n}\n\n// SendVersions fulfills the Periodic interface\ntype sendVersions struct {\n\tk8sResources      *k8s.ResourceInterfaceNamespaced\n\tapiClient         *apiclient.WorkflowManager\n\tavailableVersions data.AvailableVersions\n\tfrequency         time.Duration\n}\n\n// NewSendVersionsPeriodic creates a new SendVersions using sgc and rcl as the the secret getter / creator and replication controller lister implementations (respectively)\nfunc NewSendVersionsPeriodic(\n\tapiClient *apiclient.WorkflowManager,\n\tri *k8s.ResourceInterfaceNamespaced,\n\tavailableVersions data.AvailableVersions,\n\tfrequency time.Duration,\n) Periodic {\n\treturn &sendVersions{\n\t\tk8sResources:      ri,\n\t\tapiClient:         apiClient,\n\t\tavailableVersions: availableVersions,\n\t\tfrequency:         frequency,\n\t}\n}\n\n// Do is the Periodic interface implementation\nfunc (s sendVersions) Do() error {\n\tif config.Spec.CheckVersions {\n\t\terr := sendVersionsImpl(s.apiClient, s.k8sResources, s.availableVersions)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Frequency is the Periodic interface implementation\nfunc (s sendVersions) Frequency() time.Duration {\n\treturn s.frequency\n}\n\ntype getLatestVersionData struct {\n\tvsns                  data.AvailableVersions\n\tinstalledData         data.InstalledData\n\tclusterID             data.ClusterID\n\tavailableComponentVsn data.AvailableComponentVersion\n\tk8sResources          k8s.ResourceInterfaceNamespaced\n\tfrequency             time.Duration\n}\n\n// NewGetLatestVersionDataPeriodic creates a new periodic implementation that gets latest version data. It uses sgc and rcl as the secret getter/creator and replication controller lister implementations (respectively)\nfunc NewGetLatestVersionDataPeriodic(\n\tinstalledData data.InstalledData,\n\tclusterID data.ClusterID,\n\tavailVsn data.AvailableVersions,\n\tavailCompVsn data.AvailableComponentVersion,\n\tfrequency time.Duration,\n) Periodic {\n\n\treturn &getLatestVersionData{\n\t\tvsns:                  availVsn,\n\t\tinstalledData:         installedData,\n\t\tclusterID:             clusterID,\n\t\tavailableComponentVsn: availCompVsn,\n\t\tfrequency:             frequency,\n\t}\n}\n\n// Do is the Periodic interface implementation\nfunc (u *getLatestVersionData) Do() error {\n\tcluster, err := data.GetCluster(u.installedData, u.clusterID, u.availableComponentVsn)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif _, err := u.vsns.Refresh(cluster); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// Frequency is the Periodic interface implementation\nfunc (u getLatestVersionData) Frequency() time.Duration {\n\treturn u.frequency\n}\n\n// DoPeriodic calls p.Do() once, and then again every p.Frequency() on each element p in pSlice.\n// For each p in pSlice, a new goroutine is started, and the returned channel can be closed\n// to stop all of the goroutines.\nfunc DoPeriodic(pSlice []Periodic) chan<- struct{} {\n\tdoneCh := make(chan struct{})\n\tfor _, p := range pSlice {\n\t\tgo func(p Periodic) {\n\t\t\t// execute once at the beginning\n\t\t\terr := p.Do()\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"periodic job ran and returned error (%s)\", err)\n\t\t\t}\n\t\t\tticker := time.NewTicker(p.Frequency())\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ticker.C:\n\t\t\t\t\terr := p.Do()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Printf(\"periodic job ran and returned error (%s)\", err)\n\t\t\t\t\t}\n\t\t\t\tcase <-doneCh:\n\t\t\t\t\tticker.Stop()\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}(p)\n\t}\n\treturn doneCh\n}\n\n//  sendVersions sends cluster version data\nfunc sendVersionsImpl(\n\tapiClient *apiclient.WorkflowManager,\n\tk8sResources *k8s.ResourceInterfaceNamespaced,\n\tavailableVersions data.AvailableVersions,\n) error {\n\tcluster, err := data.GetCluster(\n\t\tdata.NewInstalledDeisData(k8sResources),\n\t\tdata.NewClusterIDFromPersistentStorage(k8sResources.Secrets()),\n\t\tdata.NewLatestReleasedComponent(k8sResources, availableVersions),\n\t)\n\tif err != nil {\n\t\tlog.Println(\"error getting installed components data\")\n\t\treturn err\n\t}\n\n\t_, err = apiClient.Operations.CreateClusterDetails(&operations.CreateClusterDetailsParams{Body: &cluster})\n\tif err != nil {\n\t\tlog.Println(\"error sending diagnostic data\")\n\t\treturn err\n\t}\n\treturn nil\n}\n"], "fixing_code": ["package main\n\nimport (\n\t\"fmt\"\n\t\"log\"\n\t\"net/http\"\n\t\"time\"\n\n\t\"github.com/deis/workflow-manager/config\"\n\t\"github.com/deis/workflow-manager/data\"\n\t\"github.com/deis/workflow-manager/handlers\"\n\t\"github.com/deis/workflow-manager/jobs\"\n\t\"github.com/deis/workflow-manager/k8s\"\n\t\"github.com/gorilla/mux\"\n\tkcl \"k8s.io/kubernetes/pkg/client/unversioned\"\n)\n\nfunc main() {\n\tkubeClient, err := kcl.NewInCluster()\n\tif err != nil {\n\t\tlog.Fatalf(\"Error creating new Kubernetes client (%s)\", err)\n\t}\n\tapiClient, err := config.GetSwaggerClient(config.Spec.VersionsAPIURL)\n\tif err != nil {\n\t\tlog.Fatalf(\"Error creating new swagger api client (%s)\", err)\n\t}\n\tdeisK8sResources := k8s.NewResourceInterfaceNamespaced(kubeClient, config.Spec.DeisNamespace)\n\tclusterID := data.NewClusterIDFromPersistentStorage(deisK8sResources.Secrets())\n\tinstalledDeisData := data.NewInstalledDeisData(deisK8sResources)\n\tavailableVersion := data.NewAvailableVersionsFromAPI(\n\t\tapiClient,\n\t\tconfig.Spec.VersionsAPIURL,\n\t)\n\tavailableComponentVersion := data.NewLatestReleasedComponent(deisK8sResources, availableVersion)\n\n\tpollDur := time.Duration(config.Spec.Polling) * time.Second\n\t// we want to do the following jobs according to our remote API interval:\n\t// 1. get latest stable deis component versions\n\t// 2. send diagnostic data, if appropriate\n\tglvdPeriodic := jobs.NewGetLatestVersionDataPeriodic(\n\t\tinstalledDeisData,\n\t\tclusterID,\n\t\tavailableVersion,\n\t\tavailableComponentVersion,\n\t\tpollDur,\n\t)\n\n\tsvPeriodic := jobs.NewSendVersionsPeriodic(\n\t\tapiClient,\n\t\tclusterID,\n\t\tdeisK8sResources,\n\t\tavailableVersion,\n\t\tpollDur,\n\t)\n\ttoDo := []jobs.Periodic{glvdPeriodic, svPeriodic}\n\tlog.Printf(\"Starting periodic jobs at interval %s\", pollDur)\n\tch := jobs.DoPeriodic(toDo)\n\tdefer close(ch)\n\n\t// Get a new router, with handler functions\n\tr := handlers.RegisterRoutes(mux.NewRouter(), availableVersion, deisK8sResources)\n\t// Bind to a port and pass our router in\n\thostStr := fmt.Sprintf(\":%s\", config.Spec.Port)\n\tlog.Printf(\"Serving on %s\", hostStr)\n\tif err := http.ListenAndServe(hostStr, r); err != nil {\n\t\tclose(ch)\n\t\tlog.Println(\"Unable to open up TLS listener\")\n\t\tlog.Fatal(\"ListenAndServe: \", err)\n\t}\n}\n", "package data\n\nimport (\n\t\"sync\"\n\n\t\"github.com/deis/workflow-manager/k8s\"\n\t\"github.com/satori/go.uuid\"\n\t\"k8s.io/kubernetes/pkg/api\"\n\tapierrors \"k8s.io/kubernetes/pkg/api/errors\"\n)\n\n// ClusterID is an interface for managing cluster ID data\ntype ClusterID interface {\n\t// will have a Get method to retrieve the cluster ID\n\tGet() (string, error)\n\t// Cached returns the internal cache of the cluster ID. returns the empty string on a miss\n\tCached() string\n\t// StoreInCache stores the given string in the internal cluster ID cache\n\tStoreInCache(string)\n}\n\n// GetID gets the cluster ID from the cache. on a cache miss, uses the k8s API to get it\nfunc GetID(id ClusterID) (string, error) {\n\t// First, check to see if we have an in-memory copy\n\tdata := id.Cached()\n\t// If we haven't yet cached the ID in memory, invoke the passed-in getter\n\tif data == \"\" {\n\t\td, err := id.Get()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tdata = d\n\t}\n\treturn data, nil\n}\n\ntype clusterIDFromPersistentStorage struct {\n\trwm                 *sync.RWMutex\n\tcache               string\n\tsecretGetterCreator k8s.KubeSecretGetterCreator\n}\n\n// NewClusterIDFromPersistentStorage returns a new ClusterID implementation that uses the kubernetes API to get its cluster information\nfunc NewClusterIDFromPersistentStorage(sgc k8s.KubeSecretGetterCreator) ClusterID {\n\treturn &clusterIDFromPersistentStorage{\n\t\trwm:                 new(sync.RWMutex),\n\t\tcache:               \"\",\n\t\tsecretGetterCreator: sgc,\n\t}\n}\n\n// Get is the ClusterID interface implementation\nfunc (c clusterIDFromPersistentStorage) Get() (string, error) {\n\tc.rwm.Lock()\n\tdefer c.rwm.Unlock()\n\tsecret, err := c.secretGetterCreator.Get(wfmSecretName)\n\t//If we don't have the secret we shouldn't be returning error and instead a create a new one\n\tif err != nil && !apierrors.IsNotFound(err) {\n\t\treturn \"\", err\n\t}\n\t// if we don't have secret data for the cluster ID we assume a new cluster\n\t// and create a new secret\n\tif secret.Data[clusterIDSecretKey] == nil {\n\t\tnewSecret := new(api.Secret)\n\t\tnewSecret.Name = wfmSecretName\n\t\tnewSecret.Data = make(map[string][]byte)\n\t\tnewSecret.Data[clusterIDSecretKey] = []byte(uuid.NewV4().String())\n\t\tfromAPI, err := c.secretGetterCreator.Create(newSecret)\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tsecret = fromAPI\n\t}\n\treturn string(secret.Data[clusterIDSecretKey]), nil\n}\n\n// StoreInCache is the ClusterID interface implementation\nfunc (c *clusterIDFromPersistentStorage) StoreInCache(cid string) {\n\tc.rwm.Lock()\n\tdefer c.rwm.Unlock()\n\tc.cache = cid\n}\n\n// Cached is the ClusterID interface implementation\nfunc (c clusterIDFromPersistentStorage) Cached() string {\n\tc.rwm.RLock()\n\tdefer c.rwm.RUnlock()\n\treturn c.cache\n}\n", "package jobs\n\nimport (\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/deis/workflow-manager/config\"\n\t\"github.com/deis/workflow-manager/data\"\n\t\"github.com/deis/workflow-manager/k8s\"\n\tapiclient \"github.com/deis/workflow-manager/pkg/swagger/client\"\n\t\"github.com/deis/workflow-manager/pkg/swagger/client/operations\"\n)\n\n// Periodic is an interface for managing periodic job invocation\ntype Periodic interface {\n\t// Do begins the periodic job. It starts the first execution of the job, and then is\n\t// repsonsible for executing it every Frequency() thereafter\n\tDo() error\n\tFrequency() time.Duration\n}\n\n// SendVersions fulfills the Periodic interface\ntype sendVersions struct {\n\tk8sResources      *k8s.ResourceInterfaceNamespaced\n\tclusterID         data.ClusterID\n\tapiClient         *apiclient.WorkflowManager\n\tavailableVersions data.AvailableVersions\n\tfrequency         time.Duration\n}\n\n// NewSendVersionsPeriodic creates a new SendVersions using sgc and rcl as the the secret getter / creator and replication controller lister implementations (respectively)\nfunc NewSendVersionsPeriodic(\n\tapiClient *apiclient.WorkflowManager,\n\tclusterID data.ClusterID,\n\tri *k8s.ResourceInterfaceNamespaced,\n\tavailableVersions data.AvailableVersions,\n\tfrequency time.Duration,\n) Periodic {\n\treturn &sendVersions{\n\t\tk8sResources:      ri,\n\t\tclusterID:         clusterID,\n\t\tapiClient:         apiClient,\n\t\tavailableVersions: availableVersions,\n\t\tfrequency:         frequency,\n\t}\n}\n\n// Do is the Periodic interface implementation\nfunc (s sendVersions) Do() error {\n\tif config.Spec.CheckVersions {\n\t\terr := sendVersionsImpl(s.apiClient, s.clusterID, s.k8sResources, s.availableVersions)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Frequency is the Periodic interface implementation\nfunc (s sendVersions) Frequency() time.Duration {\n\treturn s.frequency\n}\n\ntype getLatestVersionData struct {\n\tvsns                  data.AvailableVersions\n\tinstalledData         data.InstalledData\n\tclusterID             data.ClusterID\n\tavailableComponentVsn data.AvailableComponentVersion\n\tk8sResources          k8s.ResourceInterfaceNamespaced\n\tfrequency             time.Duration\n}\n\n// NewGetLatestVersionDataPeriodic creates a new periodic implementation that gets latest version data. It uses sgc and rcl as the secret getter/creator and replication controller lister implementations (respectively)\nfunc NewGetLatestVersionDataPeriodic(\n\tinstalledData data.InstalledData,\n\tclusterID data.ClusterID,\n\tavailVsn data.AvailableVersions,\n\tavailCompVsn data.AvailableComponentVersion,\n\tfrequency time.Duration,\n) Periodic {\n\n\treturn &getLatestVersionData{\n\t\tvsns:                  availVsn,\n\t\tinstalledData:         installedData,\n\t\tclusterID:             clusterID,\n\t\tavailableComponentVsn: availCompVsn,\n\t\tfrequency:             frequency,\n\t}\n}\n\n// Do is the Periodic interface implementation\nfunc (u *getLatestVersionData) Do() error {\n\tcluster, err := data.GetCluster(u.installedData, u.clusterID, u.availableComponentVsn)\n\tif err != nil {\n\t\treturn err\n\t}\n\tif _, err := u.vsns.Refresh(cluster); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// Frequency is the Periodic interface implementation\nfunc (u getLatestVersionData) Frequency() time.Duration {\n\treturn u.frequency\n}\n\n// DoPeriodic calls p.Do() once, and then again every p.Frequency() on each element p in pSlice.\n// For each p in pSlice, a new goroutine is started, and the returned channel can be closed\n// to stop all of the goroutines.\nfunc DoPeriodic(pSlice []Periodic) chan<- struct{} {\n\tdoneCh := make(chan struct{})\n\tfor _, p := range pSlice {\n\t\tgo func(p Periodic) {\n\t\t\t// execute once at the beginning\n\t\t\terr := p.Do()\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"periodic job ran and returned error (%s)\", err)\n\t\t\t}\n\t\t\tticker := time.NewTicker(p.Frequency())\n\t\t\tfor {\n\t\t\t\tselect {\n\t\t\t\tcase <-ticker.C:\n\t\t\t\t\terr := p.Do()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Printf(\"periodic job ran and returned error (%s)\", err)\n\t\t\t\t\t}\n\t\t\t\tcase <-doneCh:\n\t\t\t\t\tticker.Stop()\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}(p)\n\t}\n\treturn doneCh\n}\n\n//  sendVersions sends cluster version data\nfunc sendVersionsImpl(\n\tapiClient *apiclient.WorkflowManager,\n\tclusterID data.ClusterID,\n\tk8sResources *k8s.ResourceInterfaceNamespaced,\n\tavailableVersions data.AvailableVersions,\n) error {\n\tcluster, err := data.GetCluster(\n\t\tdata.NewInstalledDeisData(k8sResources),\n\t\tclusterID,\n\t\tdata.NewLatestReleasedComponent(k8sResources, availableVersions),\n\t)\n\tif err != nil {\n\t\tlog.Println(\"error getting installed components data\")\n\t\treturn err\n\t}\n\n\t_, err = apiClient.Operations.CreateClusterDetails(&operations.CreateClusterDetailsParams{Body: &cluster})\n\tif err != nil {\n\t\tlog.Println(\"error sending diagnostic data\")\n\t\treturn err\n\t}\n\treturn nil\n}\n"], "filenames": ["boot.go", "data/cluster_id.go", "jobs/jobs.go"], "buggy_code_start_loc": [49, 53, 24], "buggy_code_end_loc": [49, 53, 144], "fixing_code_start_loc": [50, 54, 25], "fixing_code_end_loc": [51, 56, 148], "type": "CWE-362", "message": "** UNSUPPORTED WHEN ASSIGNED ** A vulnerability was found in Deis Workflow Manager up to 2.3.2. It has been classified as problematic. This affects an unknown part. The manipulation leads to race condition. The complexity of an attack is rather high. The exploitability is told to be difficult. Upgrading to version 2.3.3 is able to address this issue. The patch is named 31fe3bccbdde134a185752e53380330d16053f7f. It is recommended to upgrade the affected component. The associated identifier of this vulnerability is VDB-248847. NOTE: This vulnerability only affects products that are no longer supported by the maintainer.", "other": {"cve": {"id": "CVE-2016-15036", "sourceIdentifier": "cna@vuldb.com", "published": "2023-12-23T20:15:37.930", "lastModified": "2024-02-29T01:17:45.273", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "** UNSUPPORTED WHEN ASSIGNED ** A vulnerability was found in Deis Workflow Manager up to 2.3.2. It has been classified as problematic. This affects an unknown part. The manipulation leads to race condition. The complexity of an attack is rather high. The exploitability is told to be difficult. Upgrading to version 2.3.3 is able to address this issue. The patch is named 31fe3bccbdde134a185752e53380330d16053f7f. It is recommended to upgrade the affected component. The associated identifier of this vulnerability is VDB-248847. NOTE: This vulnerability only affects products that are no longer supported by the maintainer."}, {"lang": "es", "value": "** NO SOPORTADO CUANDO SE ASIGN\u00d3 ** Se encontr\u00f3 una vulnerabilidad en Deis Workflow Manager hasta 2.3.2. Ha sido clasificada como problem\u00e1tica. Esto afecta a una parte desconocida. La manipulaci\u00f3n conduce a la condici\u00f3n de ejecuci\u00f3n. La complejidad del ataque es bastante alta. Se dice que la explotabilidad es dif\u00edcil. La actualizaci\u00f3n a la versi\u00f3n 2.3.3 puede solucionar este problema. El parche se llama 31fe3bccbdde134a185752e53380330d16053f7f. Se recomienda actualizar el componente afectado. El identificador asociado de esta vulnerabilidad es VDB-248847. NOTA: Esta vulnerabilidad solo afecta a productos que ya no son compatibles con el fabricante."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:A/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "ADJACENT_NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.6, "impactScore": 5.9}, {"source": "cna@vuldb.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:A/AC:H/PR:L/UI:N/S:U/C:L/I:L/A:L", "attackVector": "ADJACENT_NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 4.6, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.2, "impactScore": 3.4}], "cvssMetricV2": [{"source": "cna@vuldb.com", "type": "Secondary", "cvssData": {"version": "2.0", "vectorString": "AV:A/AC:H/Au:S/C:P/I:P/A:P", "accessVector": "ADJACENT_NETWORK", "accessComplexity": "HIGH", "authentication": "SINGLE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 2.5, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "cna@vuldb.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-362"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:deis:workflow_manager:*:*:*:*:*:go:*:*", "versionEndIncluding": "2.3.2", "matchCriteriaId": "A82C2086-3CC8-4669-B3E1-8453CD63A459"}]}]}], "references": [{"url": "https://github.com/deis/workflow-manager/commit/31fe3bccbdde134a185752e53380330d16053f7f", "source": "cna@vuldb.com", "tags": ["Patch"]}, {"url": "https://github.com/deis/workflow-manager/pull/94", "source": "cna@vuldb.com", "tags": ["Patch"]}, {"url": "https://github.com/deis/workflow-manager/releases/tag/v2.3.3", "source": "cna@vuldb.com", "tags": ["Release Notes"]}, {"url": "https://vuldb.com/?ctiid.248847", "source": "cna@vuldb.com", "tags": ["Third Party Advisory"]}, {"url": "https://vuldb.com/?id.248847", "source": "cna@vuldb.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/deis/workflow-manager/commit/31fe3bccbdde134a185752e53380330d16053f7f"}}
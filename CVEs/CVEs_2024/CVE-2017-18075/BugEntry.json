{"buggy_code": ["/*\n * pcrypt - Parallel crypto wrapper.\n *\n * Copyright (C) 2009 secunet Security Networks AG\n * Copyright (C) 2009 Steffen Klassert <steffen.klassert@secunet.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms and conditions of the GNU General Public License,\n * version 2, as published by the Free Software Foundation.\n *\n * This program is distributed in the hope it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc.,\n * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.\n */\n\n#include <crypto/algapi.h>\n#include <crypto/internal/aead.h>\n#include <linux/atomic.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/notifier.h>\n#include <linux/kobject.h>\n#include <linux/cpu.h>\n#include <crypto/pcrypt.h>\n\nstruct padata_pcrypt {\n\tstruct padata_instance *pinst;\n\tstruct workqueue_struct *wq;\n\n\t/*\n\t * Cpumask for callback CPUs. It should be\n\t * equal to serial cpumask of corresponding padata instance,\n\t * so it is updated when padata notifies us about serial\n\t * cpumask change.\n\t *\n\t * cb_cpumask is protected by RCU. This fact prevents us from\n\t * using cpumask_var_t directly because the actual type of\n\t * cpumsak_var_t depends on kernel configuration(particularly on\n\t * CONFIG_CPUMASK_OFFSTACK macro). Depending on the configuration\n\t * cpumask_var_t may be either a pointer to the struct cpumask\n\t * or a variable allocated on the stack. Thus we can not safely use\n\t * cpumask_var_t with RCU operations such as rcu_assign_pointer or\n\t * rcu_dereference. So cpumask_var_t is wrapped with struct\n\t * pcrypt_cpumask which makes possible to use it with RCU.\n\t */\n\tstruct pcrypt_cpumask {\n\t\tcpumask_var_t mask;\n\t} *cb_cpumask;\n\tstruct notifier_block nblock;\n};\n\nstatic struct padata_pcrypt pencrypt;\nstatic struct padata_pcrypt pdecrypt;\nstatic struct kset           *pcrypt_kset;\n\nstruct pcrypt_instance_ctx {\n\tstruct crypto_aead_spawn spawn;\n\tatomic_t tfm_count;\n};\n\nstruct pcrypt_aead_ctx {\n\tstruct crypto_aead *child;\n\tunsigned int cb_cpu;\n};\n\nstatic int pcrypt_do_parallel(struct padata_priv *padata, unsigned int *cb_cpu,\n\t\t\t      struct padata_pcrypt *pcrypt)\n{\n\tunsigned int cpu_index, cpu, i;\n\tstruct pcrypt_cpumask *cpumask;\n\n\tcpu = *cb_cpu;\n\n\trcu_read_lock_bh();\n\tcpumask = rcu_dereference_bh(pcrypt->cb_cpumask);\n\tif (cpumask_test_cpu(cpu, cpumask->mask))\n\t\t\tgoto out;\n\n\tif (!cpumask_weight(cpumask->mask))\n\t\t\tgoto out;\n\n\tcpu_index = cpu % cpumask_weight(cpumask->mask);\n\n\tcpu = cpumask_first(cpumask->mask);\n\tfor (i = 0; i < cpu_index; i++)\n\t\tcpu = cpumask_next(cpu, cpumask->mask);\n\n\t*cb_cpu = cpu;\n\nout:\n\trcu_read_unlock_bh();\n\treturn padata_do_parallel(pcrypt->pinst, padata, cpu);\n}\n\nstatic int pcrypt_aead_setkey(struct crypto_aead *parent,\n\t\t\t      const u8 *key, unsigned int keylen)\n{\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(parent);\n\n\treturn crypto_aead_setkey(ctx->child, key, keylen);\n}\n\nstatic int pcrypt_aead_setauthsize(struct crypto_aead *parent,\n\t\t\t\t   unsigned int authsize)\n{\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(parent);\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic void pcrypt_aead_serial(struct padata_priv *padata)\n{\n\tstruct pcrypt_request *preq = pcrypt_padata_request(padata);\n\tstruct aead_request *req = pcrypt_request_ctx(preq);\n\n\taead_request_complete(req->base.data, padata->info);\n}\n\nstatic void pcrypt_aead_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct pcrypt_request *preq = aead_request_ctx(req);\n\tstruct padata_priv *padata = pcrypt_request_padata(preq);\n\n\tpadata->info = err;\n\treq->base.flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tpadata_do_serial(padata);\n}\n\nstatic void pcrypt_aead_enc(struct padata_priv *padata)\n{\n\tstruct pcrypt_request *preq = pcrypt_padata_request(padata);\n\tstruct aead_request *req = pcrypt_request_ctx(preq);\n\n\tpadata->info = crypto_aead_encrypt(req);\n\n\tif (padata->info == -EINPROGRESS)\n\t\treturn;\n\n\tpadata_do_serial(padata);\n}\n\nstatic int pcrypt_aead_encrypt(struct aead_request *req)\n{\n\tint err;\n\tstruct pcrypt_request *preq = aead_request_ctx(req);\n\tstruct aead_request *creq = pcrypt_request_ctx(preq);\n\tstruct padata_priv *padata = pcrypt_request_padata(preq);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(aead);\n\tu32 flags = aead_request_flags(req);\n\n\tmemset(padata, 0, sizeof(struct padata_priv));\n\n\tpadata->parallel = pcrypt_aead_enc;\n\tpadata->serial = pcrypt_aead_serial;\n\n\taead_request_set_tfm(creq, ctx->child);\n\taead_request_set_callback(creq, flags & ~CRYPTO_TFM_REQ_MAY_SLEEP,\n\t\t\t\t  pcrypt_aead_done, req);\n\taead_request_set_crypt(creq, req->src, req->dst,\n\t\t\t       req->cryptlen, req->iv);\n\taead_request_set_ad(creq, req->assoclen);\n\n\terr = pcrypt_do_parallel(padata, &ctx->cb_cpu, &pencrypt);\n\tif (!err)\n\t\treturn -EINPROGRESS;\n\n\treturn err;\n}\n\nstatic void pcrypt_aead_dec(struct padata_priv *padata)\n{\n\tstruct pcrypt_request *preq = pcrypt_padata_request(padata);\n\tstruct aead_request *req = pcrypt_request_ctx(preq);\n\n\tpadata->info = crypto_aead_decrypt(req);\n\n\tif (padata->info == -EINPROGRESS)\n\t\treturn;\n\n\tpadata_do_serial(padata);\n}\n\nstatic int pcrypt_aead_decrypt(struct aead_request *req)\n{\n\tint err;\n\tstruct pcrypt_request *preq = aead_request_ctx(req);\n\tstruct aead_request *creq = pcrypt_request_ctx(preq);\n\tstruct padata_priv *padata = pcrypt_request_padata(preq);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(aead);\n\tu32 flags = aead_request_flags(req);\n\n\tmemset(padata, 0, sizeof(struct padata_priv));\n\n\tpadata->parallel = pcrypt_aead_dec;\n\tpadata->serial = pcrypt_aead_serial;\n\n\taead_request_set_tfm(creq, ctx->child);\n\taead_request_set_callback(creq, flags & ~CRYPTO_TFM_REQ_MAY_SLEEP,\n\t\t\t\t  pcrypt_aead_done, req);\n\taead_request_set_crypt(creq, req->src, req->dst,\n\t\t\t       req->cryptlen, req->iv);\n\taead_request_set_ad(creq, req->assoclen);\n\n\terr = pcrypt_do_parallel(padata, &ctx->cb_cpu, &pdecrypt);\n\tif (!err)\n\t\treturn -EINPROGRESS;\n\n\treturn err;\n}\n\nstatic int pcrypt_aead_init_tfm(struct crypto_aead *tfm)\n{\n\tint cpu, cpu_index;\n\tstruct aead_instance *inst = aead_alg_instance(tfm);\n\tstruct pcrypt_instance_ctx *ictx = aead_instance_ctx(inst);\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\tstruct crypto_aead *cipher;\n\n\tcpu_index = (unsigned int)atomic_inc_return(&ictx->tfm_count) %\n\t\t    cpumask_weight(cpu_online_mask);\n\n\tctx->cb_cpu = cpumask_first(cpu_online_mask);\n\tfor (cpu = 0; cpu < cpu_index; cpu++)\n\t\tctx->cb_cpu = cpumask_next(ctx->cb_cpu, cpu_online_mask);\n\n\tcipher = crypto_spawn_aead(&ictx->spawn);\n\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctx->child = cipher;\n\tcrypto_aead_set_reqsize(tfm, sizeof(struct pcrypt_request) +\n\t\t\t\t     sizeof(struct aead_request) +\n\t\t\t\t     crypto_aead_reqsize(cipher));\n\n\treturn 0;\n}\n\nstatic void pcrypt_aead_exit_tfm(struct crypto_aead *tfm)\n{\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n}\n\nstatic int pcrypt_init_instance(struct crypto_instance *inst,\n\t\t\t\tstruct crypto_alg *alg)\n{\n\tif (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"pcrypt(%s)\", alg->cra_driver_name) >= CRYPTO_MAX_ALG_NAME)\n\t\treturn -ENAMETOOLONG;\n\n\tmemcpy(inst->alg.cra_name, alg->cra_name, CRYPTO_MAX_ALG_NAME);\n\n\tinst->alg.cra_priority = alg->cra_priority + 100;\n\tinst->alg.cra_blocksize = alg->cra_blocksize;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\n\treturn 0;\n}\n\nstatic int pcrypt_create_aead(struct crypto_template *tmpl, struct rtattr **tb,\n\t\t\t      u32 type, u32 mask)\n{\n\tstruct pcrypt_instance_ctx *ctx;\n\tstruct crypto_attr_type *algt;\n\tstruct aead_instance *inst;\n\tstruct aead_alg *alg;\n\tconst char *name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn PTR_ERR(algt);\n\n\tname = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);\n\tif (!inst)\n\t\treturn -ENOMEM;\n\n\tctx = aead_instance_ctx(inst);\n\tcrypto_set_aead_spawn(&ctx->spawn, aead_crypto_instance(inst));\n\n\terr = crypto_grab_aead(&ctx->spawn, name, 0, 0);\n\tif (err)\n\t\tgoto out_free_inst;\n\n\talg = crypto_spawn_aead_alg(&ctx->spawn);\n\terr = pcrypt_init_instance(aead_crypto_instance(inst), &alg->base);\n\tif (err)\n\t\tgoto out_drop_aead;\n\n\tinst->alg.base.cra_flags = CRYPTO_ALG_ASYNC;\n\n\tinst->alg.ivsize = crypto_aead_alg_ivsize(alg);\n\tinst->alg.maxauthsize = crypto_aead_alg_maxauthsize(alg);\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct pcrypt_aead_ctx);\n\n\tinst->alg.init = pcrypt_aead_init_tfm;\n\tinst->alg.exit = pcrypt_aead_exit_tfm;\n\n\tinst->alg.setkey = pcrypt_aead_setkey;\n\tinst->alg.setauthsize = pcrypt_aead_setauthsize;\n\tinst->alg.encrypt = pcrypt_aead_encrypt;\n\tinst->alg.decrypt = pcrypt_aead_decrypt;\n\n\terr = aead_register_instance(tmpl, inst);\n\tif (err)\n\t\tgoto out_drop_aead;\n\nout:\n\treturn err;\n\nout_drop_aead:\n\tcrypto_drop_aead(&ctx->spawn);\nout_free_inst:\n\tkfree(inst);\n\tgoto out;\n}\n\nstatic int pcrypt_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn PTR_ERR(algt);\n\n\tswitch (algt->type & algt->mask & CRYPTO_ALG_TYPE_MASK) {\n\tcase CRYPTO_ALG_TYPE_AEAD:\n\t\treturn pcrypt_create_aead(tmpl, tb, algt->type, algt->mask);\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic void pcrypt_free(struct crypto_instance *inst)\n{\n\tstruct pcrypt_instance_ctx *ctx = crypto_instance_ctx(inst);\n\n\tcrypto_drop_aead(&ctx->spawn);\n\tkfree(inst);\n}\n\nstatic int pcrypt_cpumask_change_notify(struct notifier_block *self,\n\t\t\t\t\tunsigned long val, void *data)\n{\n\tstruct padata_pcrypt *pcrypt;\n\tstruct pcrypt_cpumask *new_mask, *old_mask;\n\tstruct padata_cpumask *cpumask = (struct padata_cpumask *)data;\n\n\tif (!(val & PADATA_CPU_SERIAL))\n\t\treturn 0;\n\n\tpcrypt = container_of(self, struct padata_pcrypt, nblock);\n\tnew_mask = kmalloc(sizeof(*new_mask), GFP_KERNEL);\n\tif (!new_mask)\n\t\treturn -ENOMEM;\n\tif (!alloc_cpumask_var(&new_mask->mask, GFP_KERNEL)) {\n\t\tkfree(new_mask);\n\t\treturn -ENOMEM;\n\t}\n\n\told_mask = pcrypt->cb_cpumask;\n\n\tcpumask_copy(new_mask->mask, cpumask->cbcpu);\n\trcu_assign_pointer(pcrypt->cb_cpumask, new_mask);\n\tsynchronize_rcu_bh();\n\n\tfree_cpumask_var(old_mask->mask);\n\tkfree(old_mask);\n\treturn 0;\n}\n\nstatic int pcrypt_sysfs_add(struct padata_instance *pinst, const char *name)\n{\n\tint ret;\n\n\tpinst->kobj.kset = pcrypt_kset;\n\tret = kobject_add(&pinst->kobj, NULL, name);\n\tif (!ret)\n\t\tkobject_uevent(&pinst->kobj, KOBJ_ADD);\n\n\treturn ret;\n}\n\nstatic int pcrypt_init_padata(struct padata_pcrypt *pcrypt,\n\t\t\t      const char *name)\n{\n\tint ret = -ENOMEM;\n\tstruct pcrypt_cpumask *mask;\n\n\tget_online_cpus();\n\n\tpcrypt->wq = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM | WQ_CPU_INTENSIVE,\n\t\t\t\t     1, name);\n\tif (!pcrypt->wq)\n\t\tgoto err;\n\n\tpcrypt->pinst = padata_alloc_possible(pcrypt->wq);\n\tif (!pcrypt->pinst)\n\t\tgoto err_destroy_workqueue;\n\n\tmask = kmalloc(sizeof(*mask), GFP_KERNEL);\n\tif (!mask)\n\t\tgoto err_free_padata;\n\tif (!alloc_cpumask_var(&mask->mask, GFP_KERNEL)) {\n\t\tkfree(mask);\n\t\tgoto err_free_padata;\n\t}\n\n\tcpumask_and(mask->mask, cpu_possible_mask, cpu_online_mask);\n\trcu_assign_pointer(pcrypt->cb_cpumask, mask);\n\n\tpcrypt->nblock.notifier_call = pcrypt_cpumask_change_notify;\n\tret = padata_register_cpumask_notifier(pcrypt->pinst, &pcrypt->nblock);\n\tif (ret)\n\t\tgoto err_free_cpumask;\n\n\tret = pcrypt_sysfs_add(pcrypt->pinst, name);\n\tif (ret)\n\t\tgoto err_unregister_notifier;\n\n\tput_online_cpus();\n\n\treturn ret;\n\nerr_unregister_notifier:\n\tpadata_unregister_cpumask_notifier(pcrypt->pinst, &pcrypt->nblock);\nerr_free_cpumask:\n\tfree_cpumask_var(mask->mask);\n\tkfree(mask);\nerr_free_padata:\n\tpadata_free(pcrypt->pinst);\nerr_destroy_workqueue:\n\tdestroy_workqueue(pcrypt->wq);\nerr:\n\tput_online_cpus();\n\n\treturn ret;\n}\n\nstatic void pcrypt_fini_padata(struct padata_pcrypt *pcrypt)\n{\n\tfree_cpumask_var(pcrypt->cb_cpumask->mask);\n\tkfree(pcrypt->cb_cpumask);\n\n\tpadata_stop(pcrypt->pinst);\n\tpadata_unregister_cpumask_notifier(pcrypt->pinst, &pcrypt->nblock);\n\tdestroy_workqueue(pcrypt->wq);\n\tpadata_free(pcrypt->pinst);\n}\n\nstatic struct crypto_template pcrypt_tmpl = {\n\t.name = \"pcrypt\",\n\t.create = pcrypt_create,\n\t.free = pcrypt_free,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init pcrypt_init(void)\n{\n\tint err = -ENOMEM;\n\n\tpcrypt_kset = kset_create_and_add(\"pcrypt\", NULL, kernel_kobj);\n\tif (!pcrypt_kset)\n\t\tgoto err;\n\n\terr = pcrypt_init_padata(&pencrypt, \"pencrypt\");\n\tif (err)\n\t\tgoto err_unreg_kset;\n\n\terr = pcrypt_init_padata(&pdecrypt, \"pdecrypt\");\n\tif (err)\n\t\tgoto err_deinit_pencrypt;\n\n\tpadata_start(pencrypt.pinst);\n\tpadata_start(pdecrypt.pinst);\n\n\treturn crypto_register_template(&pcrypt_tmpl);\n\nerr_deinit_pencrypt:\n\tpcrypt_fini_padata(&pencrypt);\nerr_unreg_kset:\n\tkset_unregister(pcrypt_kset);\nerr:\n\treturn err;\n}\n\nstatic void __exit pcrypt_exit(void)\n{\n\tpcrypt_fini_padata(&pencrypt);\n\tpcrypt_fini_padata(&pdecrypt);\n\n\tkset_unregister(pcrypt_kset);\n\tcrypto_unregister_template(&pcrypt_tmpl);\n}\n\nmodule_init(pcrypt_init);\nmodule_exit(pcrypt_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Steffen Klassert <steffen.klassert@secunet.com>\");\nMODULE_DESCRIPTION(\"Parallel crypto wrapper\");\nMODULE_ALIAS_CRYPTO(\"pcrypt\");\n"], "fixing_code": ["/*\n * pcrypt - Parallel crypto wrapper.\n *\n * Copyright (C) 2009 secunet Security Networks AG\n * Copyright (C) 2009 Steffen Klassert <steffen.klassert@secunet.com>\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms and conditions of the GNU General Public License,\n * version 2, as published by the Free Software Foundation.\n *\n * This program is distributed in the hope it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc.,\n * 51 Franklin St - Fifth Floor, Boston, MA 02110-1301 USA.\n */\n\n#include <crypto/algapi.h>\n#include <crypto/internal/aead.h>\n#include <linux/atomic.h>\n#include <linux/err.h>\n#include <linux/init.h>\n#include <linux/module.h>\n#include <linux/slab.h>\n#include <linux/notifier.h>\n#include <linux/kobject.h>\n#include <linux/cpu.h>\n#include <crypto/pcrypt.h>\n\nstruct padata_pcrypt {\n\tstruct padata_instance *pinst;\n\tstruct workqueue_struct *wq;\n\n\t/*\n\t * Cpumask for callback CPUs. It should be\n\t * equal to serial cpumask of corresponding padata instance,\n\t * so it is updated when padata notifies us about serial\n\t * cpumask change.\n\t *\n\t * cb_cpumask is protected by RCU. This fact prevents us from\n\t * using cpumask_var_t directly because the actual type of\n\t * cpumsak_var_t depends on kernel configuration(particularly on\n\t * CONFIG_CPUMASK_OFFSTACK macro). Depending on the configuration\n\t * cpumask_var_t may be either a pointer to the struct cpumask\n\t * or a variable allocated on the stack. Thus we can not safely use\n\t * cpumask_var_t with RCU operations such as rcu_assign_pointer or\n\t * rcu_dereference. So cpumask_var_t is wrapped with struct\n\t * pcrypt_cpumask which makes possible to use it with RCU.\n\t */\n\tstruct pcrypt_cpumask {\n\t\tcpumask_var_t mask;\n\t} *cb_cpumask;\n\tstruct notifier_block nblock;\n};\n\nstatic struct padata_pcrypt pencrypt;\nstatic struct padata_pcrypt pdecrypt;\nstatic struct kset           *pcrypt_kset;\n\nstruct pcrypt_instance_ctx {\n\tstruct crypto_aead_spawn spawn;\n\tatomic_t tfm_count;\n};\n\nstruct pcrypt_aead_ctx {\n\tstruct crypto_aead *child;\n\tunsigned int cb_cpu;\n};\n\nstatic int pcrypt_do_parallel(struct padata_priv *padata, unsigned int *cb_cpu,\n\t\t\t      struct padata_pcrypt *pcrypt)\n{\n\tunsigned int cpu_index, cpu, i;\n\tstruct pcrypt_cpumask *cpumask;\n\n\tcpu = *cb_cpu;\n\n\trcu_read_lock_bh();\n\tcpumask = rcu_dereference_bh(pcrypt->cb_cpumask);\n\tif (cpumask_test_cpu(cpu, cpumask->mask))\n\t\t\tgoto out;\n\n\tif (!cpumask_weight(cpumask->mask))\n\t\t\tgoto out;\n\n\tcpu_index = cpu % cpumask_weight(cpumask->mask);\n\n\tcpu = cpumask_first(cpumask->mask);\n\tfor (i = 0; i < cpu_index; i++)\n\t\tcpu = cpumask_next(cpu, cpumask->mask);\n\n\t*cb_cpu = cpu;\n\nout:\n\trcu_read_unlock_bh();\n\treturn padata_do_parallel(pcrypt->pinst, padata, cpu);\n}\n\nstatic int pcrypt_aead_setkey(struct crypto_aead *parent,\n\t\t\t      const u8 *key, unsigned int keylen)\n{\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(parent);\n\n\treturn crypto_aead_setkey(ctx->child, key, keylen);\n}\n\nstatic int pcrypt_aead_setauthsize(struct crypto_aead *parent,\n\t\t\t\t   unsigned int authsize)\n{\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(parent);\n\n\treturn crypto_aead_setauthsize(ctx->child, authsize);\n}\n\nstatic void pcrypt_aead_serial(struct padata_priv *padata)\n{\n\tstruct pcrypt_request *preq = pcrypt_padata_request(padata);\n\tstruct aead_request *req = pcrypt_request_ctx(preq);\n\n\taead_request_complete(req->base.data, padata->info);\n}\n\nstatic void pcrypt_aead_done(struct crypto_async_request *areq, int err)\n{\n\tstruct aead_request *req = areq->data;\n\tstruct pcrypt_request *preq = aead_request_ctx(req);\n\tstruct padata_priv *padata = pcrypt_request_padata(preq);\n\n\tpadata->info = err;\n\treq->base.flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;\n\n\tpadata_do_serial(padata);\n}\n\nstatic void pcrypt_aead_enc(struct padata_priv *padata)\n{\n\tstruct pcrypt_request *preq = pcrypt_padata_request(padata);\n\tstruct aead_request *req = pcrypt_request_ctx(preq);\n\n\tpadata->info = crypto_aead_encrypt(req);\n\n\tif (padata->info == -EINPROGRESS)\n\t\treturn;\n\n\tpadata_do_serial(padata);\n}\n\nstatic int pcrypt_aead_encrypt(struct aead_request *req)\n{\n\tint err;\n\tstruct pcrypt_request *preq = aead_request_ctx(req);\n\tstruct aead_request *creq = pcrypt_request_ctx(preq);\n\tstruct padata_priv *padata = pcrypt_request_padata(preq);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(aead);\n\tu32 flags = aead_request_flags(req);\n\n\tmemset(padata, 0, sizeof(struct padata_priv));\n\n\tpadata->parallel = pcrypt_aead_enc;\n\tpadata->serial = pcrypt_aead_serial;\n\n\taead_request_set_tfm(creq, ctx->child);\n\taead_request_set_callback(creq, flags & ~CRYPTO_TFM_REQ_MAY_SLEEP,\n\t\t\t\t  pcrypt_aead_done, req);\n\taead_request_set_crypt(creq, req->src, req->dst,\n\t\t\t       req->cryptlen, req->iv);\n\taead_request_set_ad(creq, req->assoclen);\n\n\terr = pcrypt_do_parallel(padata, &ctx->cb_cpu, &pencrypt);\n\tif (!err)\n\t\treturn -EINPROGRESS;\n\n\treturn err;\n}\n\nstatic void pcrypt_aead_dec(struct padata_priv *padata)\n{\n\tstruct pcrypt_request *preq = pcrypt_padata_request(padata);\n\tstruct aead_request *req = pcrypt_request_ctx(preq);\n\n\tpadata->info = crypto_aead_decrypt(req);\n\n\tif (padata->info == -EINPROGRESS)\n\t\treturn;\n\n\tpadata_do_serial(padata);\n}\n\nstatic int pcrypt_aead_decrypt(struct aead_request *req)\n{\n\tint err;\n\tstruct pcrypt_request *preq = aead_request_ctx(req);\n\tstruct aead_request *creq = pcrypt_request_ctx(preq);\n\tstruct padata_priv *padata = pcrypt_request_padata(preq);\n\tstruct crypto_aead *aead = crypto_aead_reqtfm(req);\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(aead);\n\tu32 flags = aead_request_flags(req);\n\n\tmemset(padata, 0, sizeof(struct padata_priv));\n\n\tpadata->parallel = pcrypt_aead_dec;\n\tpadata->serial = pcrypt_aead_serial;\n\n\taead_request_set_tfm(creq, ctx->child);\n\taead_request_set_callback(creq, flags & ~CRYPTO_TFM_REQ_MAY_SLEEP,\n\t\t\t\t  pcrypt_aead_done, req);\n\taead_request_set_crypt(creq, req->src, req->dst,\n\t\t\t       req->cryptlen, req->iv);\n\taead_request_set_ad(creq, req->assoclen);\n\n\terr = pcrypt_do_parallel(padata, &ctx->cb_cpu, &pdecrypt);\n\tif (!err)\n\t\treturn -EINPROGRESS;\n\n\treturn err;\n}\n\nstatic int pcrypt_aead_init_tfm(struct crypto_aead *tfm)\n{\n\tint cpu, cpu_index;\n\tstruct aead_instance *inst = aead_alg_instance(tfm);\n\tstruct pcrypt_instance_ctx *ictx = aead_instance_ctx(inst);\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\tstruct crypto_aead *cipher;\n\n\tcpu_index = (unsigned int)atomic_inc_return(&ictx->tfm_count) %\n\t\t    cpumask_weight(cpu_online_mask);\n\n\tctx->cb_cpu = cpumask_first(cpu_online_mask);\n\tfor (cpu = 0; cpu < cpu_index; cpu++)\n\t\tctx->cb_cpu = cpumask_next(ctx->cb_cpu, cpu_online_mask);\n\n\tcipher = crypto_spawn_aead(&ictx->spawn);\n\n\tif (IS_ERR(cipher))\n\t\treturn PTR_ERR(cipher);\n\n\tctx->child = cipher;\n\tcrypto_aead_set_reqsize(tfm, sizeof(struct pcrypt_request) +\n\t\t\t\t     sizeof(struct aead_request) +\n\t\t\t\t     crypto_aead_reqsize(cipher));\n\n\treturn 0;\n}\n\nstatic void pcrypt_aead_exit_tfm(struct crypto_aead *tfm)\n{\n\tstruct pcrypt_aead_ctx *ctx = crypto_aead_ctx(tfm);\n\n\tcrypto_free_aead(ctx->child);\n}\n\nstatic void pcrypt_free(struct aead_instance *inst)\n{\n\tstruct pcrypt_instance_ctx *ctx = aead_instance_ctx(inst);\n\n\tcrypto_drop_aead(&ctx->spawn);\n\tkfree(inst);\n}\n\nstatic int pcrypt_init_instance(struct crypto_instance *inst,\n\t\t\t\tstruct crypto_alg *alg)\n{\n\tif (snprintf(inst->alg.cra_driver_name, CRYPTO_MAX_ALG_NAME,\n\t\t     \"pcrypt(%s)\", alg->cra_driver_name) >= CRYPTO_MAX_ALG_NAME)\n\t\treturn -ENAMETOOLONG;\n\n\tmemcpy(inst->alg.cra_name, alg->cra_name, CRYPTO_MAX_ALG_NAME);\n\n\tinst->alg.cra_priority = alg->cra_priority + 100;\n\tinst->alg.cra_blocksize = alg->cra_blocksize;\n\tinst->alg.cra_alignmask = alg->cra_alignmask;\n\n\treturn 0;\n}\n\nstatic int pcrypt_create_aead(struct crypto_template *tmpl, struct rtattr **tb,\n\t\t\t      u32 type, u32 mask)\n{\n\tstruct pcrypt_instance_ctx *ctx;\n\tstruct crypto_attr_type *algt;\n\tstruct aead_instance *inst;\n\tstruct aead_alg *alg;\n\tconst char *name;\n\tint err;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn PTR_ERR(algt);\n\n\tname = crypto_attr_alg_name(tb[1]);\n\tif (IS_ERR(name))\n\t\treturn PTR_ERR(name);\n\n\tinst = kzalloc(sizeof(*inst) + sizeof(*ctx), GFP_KERNEL);\n\tif (!inst)\n\t\treturn -ENOMEM;\n\n\tctx = aead_instance_ctx(inst);\n\tcrypto_set_aead_spawn(&ctx->spawn, aead_crypto_instance(inst));\n\n\terr = crypto_grab_aead(&ctx->spawn, name, 0, 0);\n\tif (err)\n\t\tgoto out_free_inst;\n\n\talg = crypto_spawn_aead_alg(&ctx->spawn);\n\terr = pcrypt_init_instance(aead_crypto_instance(inst), &alg->base);\n\tif (err)\n\t\tgoto out_drop_aead;\n\n\tinst->alg.base.cra_flags = CRYPTO_ALG_ASYNC;\n\n\tinst->alg.ivsize = crypto_aead_alg_ivsize(alg);\n\tinst->alg.maxauthsize = crypto_aead_alg_maxauthsize(alg);\n\n\tinst->alg.base.cra_ctxsize = sizeof(struct pcrypt_aead_ctx);\n\n\tinst->alg.init = pcrypt_aead_init_tfm;\n\tinst->alg.exit = pcrypt_aead_exit_tfm;\n\n\tinst->alg.setkey = pcrypt_aead_setkey;\n\tinst->alg.setauthsize = pcrypt_aead_setauthsize;\n\tinst->alg.encrypt = pcrypt_aead_encrypt;\n\tinst->alg.decrypt = pcrypt_aead_decrypt;\n\n\tinst->free = pcrypt_free;\n\n\terr = aead_register_instance(tmpl, inst);\n\tif (err)\n\t\tgoto out_drop_aead;\n\nout:\n\treturn err;\n\nout_drop_aead:\n\tcrypto_drop_aead(&ctx->spawn);\nout_free_inst:\n\tkfree(inst);\n\tgoto out;\n}\n\nstatic int pcrypt_create(struct crypto_template *tmpl, struct rtattr **tb)\n{\n\tstruct crypto_attr_type *algt;\n\n\talgt = crypto_get_attr_type(tb);\n\tif (IS_ERR(algt))\n\t\treturn PTR_ERR(algt);\n\n\tswitch (algt->type & algt->mask & CRYPTO_ALG_TYPE_MASK) {\n\tcase CRYPTO_ALG_TYPE_AEAD:\n\t\treturn pcrypt_create_aead(tmpl, tb, algt->type, algt->mask);\n\t}\n\n\treturn -EINVAL;\n}\n\nstatic int pcrypt_cpumask_change_notify(struct notifier_block *self,\n\t\t\t\t\tunsigned long val, void *data)\n{\n\tstruct padata_pcrypt *pcrypt;\n\tstruct pcrypt_cpumask *new_mask, *old_mask;\n\tstruct padata_cpumask *cpumask = (struct padata_cpumask *)data;\n\n\tif (!(val & PADATA_CPU_SERIAL))\n\t\treturn 0;\n\n\tpcrypt = container_of(self, struct padata_pcrypt, nblock);\n\tnew_mask = kmalloc(sizeof(*new_mask), GFP_KERNEL);\n\tif (!new_mask)\n\t\treturn -ENOMEM;\n\tif (!alloc_cpumask_var(&new_mask->mask, GFP_KERNEL)) {\n\t\tkfree(new_mask);\n\t\treturn -ENOMEM;\n\t}\n\n\told_mask = pcrypt->cb_cpumask;\n\n\tcpumask_copy(new_mask->mask, cpumask->cbcpu);\n\trcu_assign_pointer(pcrypt->cb_cpumask, new_mask);\n\tsynchronize_rcu_bh();\n\n\tfree_cpumask_var(old_mask->mask);\n\tkfree(old_mask);\n\treturn 0;\n}\n\nstatic int pcrypt_sysfs_add(struct padata_instance *pinst, const char *name)\n{\n\tint ret;\n\n\tpinst->kobj.kset = pcrypt_kset;\n\tret = kobject_add(&pinst->kobj, NULL, name);\n\tif (!ret)\n\t\tkobject_uevent(&pinst->kobj, KOBJ_ADD);\n\n\treturn ret;\n}\n\nstatic int pcrypt_init_padata(struct padata_pcrypt *pcrypt,\n\t\t\t      const char *name)\n{\n\tint ret = -ENOMEM;\n\tstruct pcrypt_cpumask *mask;\n\n\tget_online_cpus();\n\n\tpcrypt->wq = alloc_workqueue(\"%s\", WQ_MEM_RECLAIM | WQ_CPU_INTENSIVE,\n\t\t\t\t     1, name);\n\tif (!pcrypt->wq)\n\t\tgoto err;\n\n\tpcrypt->pinst = padata_alloc_possible(pcrypt->wq);\n\tif (!pcrypt->pinst)\n\t\tgoto err_destroy_workqueue;\n\n\tmask = kmalloc(sizeof(*mask), GFP_KERNEL);\n\tif (!mask)\n\t\tgoto err_free_padata;\n\tif (!alloc_cpumask_var(&mask->mask, GFP_KERNEL)) {\n\t\tkfree(mask);\n\t\tgoto err_free_padata;\n\t}\n\n\tcpumask_and(mask->mask, cpu_possible_mask, cpu_online_mask);\n\trcu_assign_pointer(pcrypt->cb_cpumask, mask);\n\n\tpcrypt->nblock.notifier_call = pcrypt_cpumask_change_notify;\n\tret = padata_register_cpumask_notifier(pcrypt->pinst, &pcrypt->nblock);\n\tif (ret)\n\t\tgoto err_free_cpumask;\n\n\tret = pcrypt_sysfs_add(pcrypt->pinst, name);\n\tif (ret)\n\t\tgoto err_unregister_notifier;\n\n\tput_online_cpus();\n\n\treturn ret;\n\nerr_unregister_notifier:\n\tpadata_unregister_cpumask_notifier(pcrypt->pinst, &pcrypt->nblock);\nerr_free_cpumask:\n\tfree_cpumask_var(mask->mask);\n\tkfree(mask);\nerr_free_padata:\n\tpadata_free(pcrypt->pinst);\nerr_destroy_workqueue:\n\tdestroy_workqueue(pcrypt->wq);\nerr:\n\tput_online_cpus();\n\n\treturn ret;\n}\n\nstatic void pcrypt_fini_padata(struct padata_pcrypt *pcrypt)\n{\n\tfree_cpumask_var(pcrypt->cb_cpumask->mask);\n\tkfree(pcrypt->cb_cpumask);\n\n\tpadata_stop(pcrypt->pinst);\n\tpadata_unregister_cpumask_notifier(pcrypt->pinst, &pcrypt->nblock);\n\tdestroy_workqueue(pcrypt->wq);\n\tpadata_free(pcrypt->pinst);\n}\n\nstatic struct crypto_template pcrypt_tmpl = {\n\t.name = \"pcrypt\",\n\t.create = pcrypt_create,\n\t.module = THIS_MODULE,\n};\n\nstatic int __init pcrypt_init(void)\n{\n\tint err = -ENOMEM;\n\n\tpcrypt_kset = kset_create_and_add(\"pcrypt\", NULL, kernel_kobj);\n\tif (!pcrypt_kset)\n\t\tgoto err;\n\n\terr = pcrypt_init_padata(&pencrypt, \"pencrypt\");\n\tif (err)\n\t\tgoto err_unreg_kset;\n\n\terr = pcrypt_init_padata(&pdecrypt, \"pdecrypt\");\n\tif (err)\n\t\tgoto err_deinit_pencrypt;\n\n\tpadata_start(pencrypt.pinst);\n\tpadata_start(pdecrypt.pinst);\n\n\treturn crypto_register_template(&pcrypt_tmpl);\n\nerr_deinit_pencrypt:\n\tpcrypt_fini_padata(&pencrypt);\nerr_unreg_kset:\n\tkset_unregister(pcrypt_kset);\nerr:\n\treturn err;\n}\n\nstatic void __exit pcrypt_exit(void)\n{\n\tpcrypt_fini_padata(&pencrypt);\n\tpcrypt_fini_padata(&pdecrypt);\n\n\tkset_unregister(pcrypt_kset);\n\tcrypto_unregister_template(&pcrypt_tmpl);\n}\n\nmodule_init(pcrypt_init);\nmodule_exit(pcrypt_exit);\n\nMODULE_LICENSE(\"GPL\");\nMODULE_AUTHOR(\"Steffen Klassert <steffen.klassert@secunet.com>\");\nMODULE_DESCRIPTION(\"Parallel crypto wrapper\");\nMODULE_ALIAS_CRYPTO(\"pcrypt\");\n"], "filenames": ["crypto/pcrypt.c"], "buggy_code_start_loc": [256], "buggy_code_end_loc": [473], "fixing_code_start_loc": [257], "fixing_code_end_loc": [473], "type": "CWE-763", "message": "crypto/pcrypt.c in the Linux kernel before 4.14.13 mishandles freeing instances, allowing a local user able to access the AF_ALG-based AEAD interface (CONFIG_CRYPTO_USER_API_AEAD) and pcrypt (CONFIG_CRYPTO_PCRYPT) to cause a denial of service (kfree of an incorrect pointer) or possibly have unspecified other impact by executing a crafted sequence of system calls.", "other": {"cve": {"id": "CVE-2017-18075", "sourceIdentifier": "cve@mitre.org", "published": "2018-01-24T10:29:00.223", "lastModified": "2023-02-07T22:17:25.573", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "crypto/pcrypt.c in the Linux kernel before 4.14.13 mishandles freeing instances, allowing a local user able to access the AF_ALG-based AEAD interface (CONFIG_CRYPTO_USER_API_AEAD) and pcrypt (CONFIG_CRYPTO_PCRYPT) to cause a denial of service (kfree of an incorrect pointer) or possibly have unspecified other impact by executing a crafted sequence of system calls."}, {"lang": "es", "value": "crypto/pcrypt.c en el kernel de Linux en versiones anteriores a la 4.14.13 gestiona de manera incorrecta la liberaci\u00f3n de instancias, lo que permite que un usuario local acceda a la interfaz AEAD basada en AF_ALG (CONFIG_CRYPTO_USER_API_AEAD) y pcrypt (CONFIG_CRYPTO_PCRYPT) para provocar una denegaci\u00f3n de servicio (kfree de un puntero incorrecto) o, posiblemente, causar otro tipo de impacto sin especificar mediante la ejecuci\u00f3n de una secuencia manipulada de llamadas del sistema."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 7.2}, "baseSeverity": "HIGH", "exploitabilityScore": 3.9, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-763"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.2", "versionEndExcluding": "4.4.111", "matchCriteriaId": "59A1E494-3731-439A-9E74-5A560A7363B5"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.5", "versionEndExcluding": "4.9.76", "matchCriteriaId": "C2A2A513-DC1C-45F4-B9E2-237203C2C3CD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.10", "versionEndExcluding": "4.14.13", "matchCriteriaId": "063D10E5-185A-4A85-9867-844FC6FE2761"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:esm:*:*:*", "matchCriteriaId": "815D70A8-47D3-459C-A32C-9FEACA0659D1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:16.04:*:*:*:esm:*:*:*", "matchCriteriaId": "7A5301BF-1402-4BE0-A0F8-69FBE79BC6D6"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=d76c68109f37cb85b243a1cf0f40313afd2bae68", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/102813", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://access.redhat.com/errata/RHSA-2018:2948", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/d76c68109f37cb85b243a1cf0f40313afd2bae68", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://usn.ubuntu.com/3619-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3619-2/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.14.13", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Release Notes", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/d76c68109f37cb85b243a1cf0f40313afd2bae68"}}
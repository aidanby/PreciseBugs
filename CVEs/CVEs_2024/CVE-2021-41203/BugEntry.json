{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Utilities for saving/restoring tensor slice checkpoints.\n\n#ifndef TENSORFLOW_CORE_UTIL_SAVED_TENSOR_SLICE_UTIL_H_\n#define TENSORFLOW_CORE_UTIL_SAVED_TENSOR_SLICE_UTIL_H_\n\n#include <string>  // for string\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/tensor_slice.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/status.h\"  // for Status\n#include \"tensorflow/core/platform/protobuf.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\n// The key for the metadata in the tensor slice checkpoint files. It is \"\" so\n// that the metadata is always at the beginning of a checkpoint file.\nextern const char kSavedTensorSlicesKey[];\n\n// Encode a tensor name + a tensor slice into an ordered code and outputs it as\n// a string.\n// The format is\n//  <0>\n//  <tensor_name>\n//  <rank>\n//  <dim-0-start><dim-0-length>\n//  <dim-1-start><dim-1-length>\n//  ...\n\nstring EncodeTensorNameSlice(const string& name,\n                             const tensorflow::TensorSlice& slice);\n\n// Parse out the name and the slice from string encoded as an ordered code.\nStatus DecodeTensorNameSlice(const string& code, string* name,\n                             tensorflow::TensorSlice* slice);\n\n// Extracts the full shape, slice spec, and shape of the slice from\n// \"shape_and_slice\".  On non-OK return, caller must clear the out-arguments\n// before reusing.\nStatus ParseShapeAndSlice(const string& shape_and_slice, TensorShape* shape,\n                          TensorSlice* slice, TensorShape* shape_slice);\n\ntemplate <typename T>\nstruct SaveTypeTraits;\n\ntemplate <typename T>\nconst typename SaveTypeTraits<T>::SavedType* TensorProtoData(\n    const TensorProto& t);\n\ntemplate <typename T>\ntypename SaveTypeTraits<T>::RepeatedField* MutableTensorProtoData(\n    TensorProto* t);\n\ntemplate <typename T>\nvoid Fill(T* data, size_t n, TensorProto* t);\n\n#define TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, STYPE)      \\\n  template <>                                                            \\\n  struct SaveTypeTraits<TYPE> {                                          \\\n    static constexpr bool supported = true;                              \\\n    typedef STYPE SavedType;                                             \\\n    typedef protobuf::RepeatedField<FTYPE> RepeatedField;                \\\n  };                                                                     \\\n  template <>                                                            \\\n  inline const STYPE* TensorProtoData<TYPE>(const TensorProto& t) {      \\\n    static_assert(SaveTypeTraits<TYPE>::supported,                       \\\n                  \"Specified type \" #TYPE \" not supported for Restore\"); \\\n    return reinterpret_cast<const STYPE*>(t.FIELD##_val().data());       \\\n  }                                                                      \\\n  template <>                                                            \\\n  inline protobuf::RepeatedField<FTYPE>* MutableTensorProtoData<TYPE>(   \\\n      TensorProto * t) {                                                 \\\n    static_assert(SaveTypeTraits<TYPE>::supported,                       \\\n                  \"Specified type \" #TYPE \" not supported for Save\");    \\\n    return reinterpret_cast<protobuf::RepeatedField<FTYPE>*>(            \\\n        t->mutable_##FIELD##_val());                                     \\\n  }\n\n#define TENSOR_PROTO_EXTRACT_TYPE(TYPE, FIELD, FTYPE)             \\\n  TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, FTYPE)     \\\n  template <>                                                     \\\n  inline void Fill(const TYPE* data, size_t n, TensorProto* t) {  \\\n    typename protobuf::RepeatedField<FTYPE> copy(data, data + n); \\\n    t->mutable_##FIELD##_val()->Swap(&copy);                      \\\n  }\n\n// Complex needs special treatment since proto doesn't have native complex\n#define TENSOR_PROTO_EXTRACT_TYPE_COMPLEX(TYPE, FIELD, FTYPE)       \\\n  TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, TYPE)        \\\n  template <>                                                       \\\n  inline void Fill(const TYPE* data, size_t n, TensorProto* t) {    \\\n    const FTYPE* sub = reinterpret_cast<const FTYPE*>(data);        \\\n    typename protobuf::RepeatedField<FTYPE> copy(sub, sub + 2 * n); \\\n    t->mutable_##FIELD##_val()->Swap(&copy);                        \\\n  }\n\nTENSOR_PROTO_EXTRACT_TYPE(bool, bool, bool);\nTENSOR_PROTO_EXTRACT_TYPE(float, float, float);\nTENSOR_PROTO_EXTRACT_TYPE(double, double, double);\nTENSOR_PROTO_EXTRACT_TYPE_COMPLEX(complex64, scomplex, float);\nTENSOR_PROTO_EXTRACT_TYPE_COMPLEX(complex128, dcomplex, double);\nTENSOR_PROTO_EXTRACT_TYPE(int32, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(uint32, uint32, uint32);\nTENSOR_PROTO_EXTRACT_TYPE(int64_t, int64, protobuf_int64);\nTENSOR_PROTO_EXTRACT_TYPE(uint64, uint64, protobuf_uint64);\nTENSOR_PROTO_EXTRACT_TYPE(uint16, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(uint8, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(int8, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(int16, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(qint8, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(quint8, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(quint16, int, int32);\n\n#undef TENSOR_PROTO_EXTRACT_TYPE_COMPLEX\n#undef TENSOR_PROTO_EXTRACT_TYPE_HELPER\n#undef TENSOR_PROTO_EXTRACT_TYPE\n\n// Custom implementation for qint32, based on the one for int32.\n\ntemplate <>\nstruct SaveTypeTraits<qint32> : SaveTypeTraits<int32> {};\n\ntemplate <>\ninline const int32* TensorProtoData<qint32>(const TensorProto& t) {\n  static_assert(SaveTypeTraits<qint32>::supported,\n                \"Specified type qint32 not supported for Restore\");\n  return reinterpret_cast<const int32*>(t.int_val().data());\n}\n\ninline void Fill(const qint32* data, size_t n, TensorProto* t) {\n  const int32* p = reinterpret_cast<const int32*>(data);\n  typename protobuf::RepeatedField<int32> copy(p, p + n);\n  t->mutable_int_val()->Swap(&copy);\n}\n\n// Custom implementation for Eigen::half.\n\ntemplate <>\nstruct SaveTypeTraits<Eigen::half> {\n  static constexpr bool supported = true;\n  typedef int SavedType;\n  typedef protobuf::RepeatedField<int32> RepeatedField;\n};\n\ntemplate <>\ninline const int* TensorProtoData<Eigen::half>(const TensorProto& t) {\n  return t.half_val().data();\n}\n\ntemplate <>\ninline protobuf::RepeatedField<int32>* MutableTensorProtoData<Eigen::half>(\n    TensorProto* t) {\n  return t->mutable_half_val();\n}\n\ntemplate <>\ninline void Fill(const Eigen::half* data, size_t n, TensorProto* t) {\n  typename protobuf::RepeatedField<int32>* val = t->mutable_half_val();\n  val->Resize(n, 0);\n  for (size_t i = 0; i < n; ++i) {\n    val->Set(i, Eigen::numext::bit_cast<uint16>(data[i]));\n  }\n}\n\n// Custom implementation for string.\n\ntemplate <>\nstruct SaveTypeTraits<tstring> {\n  static constexpr bool supported = true;\n  typedef const string* SavedType;\n  typedef protobuf::RepeatedPtrField<string> RepeatedField;\n};\n\ntemplate <>\ninline const string* const* TensorProtoData<tstring>(const TensorProto& t) {\n  static_assert(SaveTypeTraits<tstring>::supported,\n                \"Specified type tstring not supported for Restore\");\n  return t.string_val().data();\n}\n\ntemplate <>\ninline protobuf::RepeatedPtrField<string>* MutableTensorProtoData<tstring>(\n    TensorProto* t) {\n  static_assert(SaveTypeTraits<tstring>::supported,\n                \"Specified type tstring not supported for Save\");\n  return t->mutable_string_val();\n}\n\ntemplate <>\ninline void Fill(const tstring* data, size_t n, TensorProto* t) {\n  typename protobuf::RepeatedPtrField<string> copy(data, data + n);\n  t->mutable_string_val()->Swap(&copy);\n}\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_UTIL_SAVED_TENSOR_SLICE_UTIL_H_\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// The utility to read checkpoints for google brain tensor ops and v3\n// checkpoints for dist_belief.\n\n#ifndef TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_\n#define TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_\n\n#include <unordered_map>\n\n#include <vector>\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_slice.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/gtl/map_util.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/macros.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/saved_tensor_slice.pb.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n#include \"tensorflow/core/util/tensor_slice_set.h\"\n#include \"tensorflow/core/util/tensor_slice_util.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\n// The reader reads in all the meta data about all the tensor slices. Then it\n// will try to read the relevant data on-demand to produce the data for the\n// slices needed.\n// NOTE(yangke): another way to do this is to first load a list of the tensor\n// slices needed and then just selectively read some of the meta data. That\n// might optimize the loading but makes the logic a bit more complicated. We\n// might want to revisit that.\n// TODO(yangke): consider moving to TensorProto.\nclass TensorSliceReader {\n public:\n  // Abstract interface for reading data out of a tensor slice checkpoint file\n  class Table {\n   public:\n    virtual ~Table();\n    virtual bool Get(const string& key, string* value) = 0;\n  };\n  typedef std::function<Status(const string&, Table**)> OpenTableFunction;\n\n  static constexpr int kLoadAllShards = -1;\n  TensorSliceReader(const string& filepattern);\n  TensorSliceReader(const string& filepattern, OpenTableFunction open_function);\n  TensorSliceReader(const string& filepattern, OpenTableFunction open_function,\n                    int preferred_shard);\n  virtual ~TensorSliceReader();\n\n  // Get the filename this reader is attached to.\n  const string& filepattern() const { return filepattern_; }\n\n  // Get the number of files matched.\n  int num_files() const { return sss_.size(); }\n\n  // Get the status of the reader.\n  const Status status() const { return status_; }\n\n  // Checks if the reader contains any slice of a tensor. In case the reader\n  // does contain the tensor, if \"shape\" is not nullptr, fill \"shape\" with the\n  // shape of the tensor; if \"type\" is not nullptr, fill \"type\" with the type\n  // of the tensor.\n  bool HasTensor(const string& name, TensorShape* shape, DataType* type) const;\n\n  // Checks if the reader contains all the data about a tensor slice, and if\n  // yes, copies the data of the slice to \"data\". The caller needs to make sure\n  // that \"data\" points to a buffer that holds enough data.\n  // This is a slow function since it needs to read sstables.\n  template <typename T>\n  bool CopySliceData(const string& name, const TensorSlice& slice,\n                     T* data) const;\n\n  // Get the tensors.\n  const std::unordered_map<string, TensorSliceSet*>& Tensors() const {\n    return tensors_;\n  }\n\n  // Returns value for one tensor. Only single slice checkpoints are supported\n  // at the moment.\n  Status GetTensor(const string& name,\n                   std::unique_ptr<tensorflow::Tensor>* out_tensor) const;\n\n  typedef std::unordered_map<string, TensorShape> VarToShapeMap;\n  typedef std::unordered_map<string, DataType> VarToDataTypeMap;\n\n  // Returns a map from tensor name to shape.\n  VarToShapeMap GetVariableToShapeMap() const;\n\n  // Returns a map from tensor name to data type.\n  VarToDataTypeMap GetVariableToDataTypeMap() const;\n\n  // Returns a string containing names and shapes of all the tensors.\n  const string DebugString() const;\n\n private:\n  friend class TensorSliceWriteTestHelper;\n\n  void LoadShard(int shard) const;\n  void LoadAllShards() const;\n\n  const TensorSliceSet* FindTensorSlice(\n      const string& name, const TensorSlice& slice,\n      std::vector<std::pair<TensorSlice, string>>* details) const;\n\n  const string filepattern_;\n  const OpenTableFunction open_function_;\n  std::vector<string> fnames_;\n  std::unordered_map<string, int> fname_to_index_;\n\n  // Guards the attributes below.\n  mutable mutex mu_;\n  mutable bool all_shards_loaded_ = false;\n  mutable std::vector<std::unique_ptr<Table>> sss_;\n  mutable std::unordered_map<string, TensorSliceSet*> tensors_;\n  mutable Status status_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorSliceReader);\n};\n\nStatus OpenTableTensorSliceReader(const string& fname,\n                                  TensorSliceReader::Table** table);\n\ntemplate <typename T>\nbool TensorSliceReader::CopySliceData(const string& name,\n                                      const TensorSlice& slice, T* data) const {\n  std::vector<std::pair<TensorSlice, string>> details;\n  const TensorSliceSet* tss;\n  {\n    mutex_lock l(mu_);\n    tss = FindTensorSlice(name, slice, &details);\n    if (!tss && !all_shards_loaded_) {\n      VLOG(1) << \"Did not find slice in preferred shard, loading all shards.\"\n              << name << \": \" << slice.DebugString();\n      LoadAllShards();\n      tss = FindTensorSlice(name, slice, &details);\n    }\n    if (!tss) {\n      // No such tensor\n      return false;\n    }\n  }\n  // We have the data -- copy it over.\n  string value;\n  for (const auto& x : details) {\n    const TensorSlice& slice_s = x.first;\n    const string& fname = x.second;\n    int idx = gtl::FindWithDefault(fname_to_index_, fname, -1);\n    CHECK_GE(idx, 0) << \"Failed to find the index for filename \" << fname;\n    // We read a record in the corresponding sstable\n    const string key = EncodeTensorNameSlice(name, slice_s);\n    if (!sss_[idx]->Get(key, &value)) {\n      VLOG(1) << \"Failed to seek to the record for tensor \" << name\n              << \", slice \" << slice_s.DebugString()\n              << \": computed key = \" << key;\n      return false;\n    }\n    SavedTensorSlices sts;\n    if (!ParseProtoUnlimited(&sts, value)) {\n      VLOG(1) << \"Failed to parse the record for tensor \" << name << \", slice \"\n              << slice_s.DebugString() << \": computed key = \" << key;\n      return false;\n    }\n    CopyDataFromTensorSliceToTensorSlice(\n        tss->shape(), slice_s, slice,\n        checkpoint::TensorProtoData<T>(sts.data().data()), data);\n  }\n  return true;\n}\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/util/tensor_slice_reader.h\"\n\n#include <utility>\n#include <vector>\n\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/versions.pb.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/io/iterator.h\"\n#include \"tensorflow/core/lib/io/path.h\"\n#include \"tensorflow/core/lib/io/table.h\"\n#include \"tensorflow/core/lib/io/table_builder.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/lib/strings/strcat.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n#include \"tensorflow/core/platform/test.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/public/version.h\"\n#include \"tensorflow/core/util/saved_tensor_slice.pb.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n#include \"tensorflow/core/util/tensor_slice_reader_cache.h\"\n#include \"tensorflow/core/util/tensor_slice_writer.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\nnamespace {\n\n// A simple test where we write a few tensor slices with a number of tensor\n// slice writers and then read them back from a tensor slice reader.\n//\n// We have a 2-d tensor of shape 4 X 5 that looks like this:\n//\n//   0   1   2   3   4\n//   5   6   7   8   9\n//  10  11  12  13  14\n//  15  16  17  18  19\n//\n// We assume this is a row-major matrix.\n\nvoid SimpleFloatHelper(\n    const TensorSliceWriter::CreateBuilderFunction& create_function,\n    TensorSliceReader::OpenTableFunction open_function) {\n  const string fname_base = io::JoinPath(testing::TmpDir(), \"float_checkpoint\");\n\n  TensorShape shape({4, 5});\n\n  // File #0 contains a slice that is the top two rows:\n  //\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    const string fname = strings::StrCat(fname_base, \"_0\");\n    TensorSliceWriter writer(fname, create_function);\n    const float data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // File #1 contains two slices:\n  //\n  // slice #0 is the bottom left corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //  10  11  12   .   .\n  //  15  16  17   .   .\n  //\n  // slice #1 is the bottom right corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .  18  19\n  {\n    const string fname = strings::StrCat(fname_base, \"_1\");\n    TensorSliceWriter writer(fname, create_function);\n    // slice #0\n    {\n      const float data[] = {10, 11, 12, 15, 16, 17};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"2,2:0,3\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    // slice #1\n    {\n      const float data[] = {18, 19};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"3,1:3,2\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // Notice that we leave a hole in the tensor\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   . (13) (14)\n  //   .   .   .   .   .\n\n  // Now we need to read the tensor slices\n  const string filepattern = strings::StrCat(fname_base, \"_*\");\n  TensorSliceReader reader(filepattern, std::move(open_function));\n  TF_EXPECT_OK(reader.status());\n  EXPECT_EQ(2, reader.num_files());\n\n  // We query some of the tensors\n  {\n    TensorShape shape;\n    DataType type;\n    EXPECT_TRUE(reader.HasTensor(\"test\", &shape, &type));\n    EXPECT_EQ(\"[4,5]\", shape.DebugString());\n    EXPECT_EQ(DT_FLOAT, type);\n    EXPECT_FALSE(reader.HasTensor(\"don't exist\", nullptr, nullptr));\n  }\n\n  // Now we query some slices\n  //\n  // Slice #1 is an exact match\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"0,2:-\");\n    float expected[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    float results[10];\n    EXPECT_TRUE(reader.CopySliceData(\"test\", s, results));\n    for (int i = 0; i < 10; ++i) {\n      EXPECT_EQ(expected[i], results[i]);\n    }\n  }\n\n  // Slice #2 is a subset match\n  //   .   .   .   .   .\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"1,1:-\");\n    float expected[] = {5, 6, 7, 8, 9};\n    float results[5];\n    EXPECT_TRUE(reader.CopySliceData(\"test\", s, results));\n    for (int i = 0; i < 5; ++i) {\n      EXPECT_EQ(expected[i], results[i]);\n    }\n  }\n\n  // Slice #4 includes the hole and so there is no match\n  //   .   .   .   .   .\n  //   .   .   7   8   9\n  //   .   .  12  13  14\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"1,2:2,3\");\n    float results[6];\n    EXPECT_FALSE(reader.CopySliceData(\"test\", s, results));\n  }\n}\n\nTEST(TensorSliceReaderTest, SimpleFloat) {\n  SimpleFloatHelper(CreateTableTensorSliceBuilder, OpenTableTensorSliceReader);\n}\n\ntemplate <typename T, typename U>\nvoid SimpleIntXHelper(\n    const TensorSliceWriter::CreateBuilderFunction& create_function,\n    TensorSliceReader::OpenTableFunction open_function,\n    const string& checkpoint_file) {\n  const string fname_base = io::JoinPath(testing::TmpDir(), checkpoint_file);\n\n  TensorShape shape({4, 5});\n\n  // File #0 contains a slice that is the top two rows:\n  //\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    const string fname = strings::StrCat(fname_base, \"_0\");\n    TensorSliceWriter writer(fname, create_function);\n    const T data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // File #1 contains two slices:\n  //\n  // slice #0 is the bottom left corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //  10  11  12   .   .\n  //  15  16  17   .   .\n  //\n  // slice #1 is the bottom right corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .  18  19\n  {\n    const string fname = strings::StrCat(fname_base, \"_1\");\n    TensorSliceWriter writer(fname, create_function);\n    // slice #0\n    {\n      const T data[] = {10, 11, 12, 15, 16, 17};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"2,2:0,3\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    // slice #1\n    {\n      const T data[] = {18, 19};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"3,1:3,2\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // Notice that we leave a hole in the tensor\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   . (13) (14)\n  //   .   .   .   .   .\n\n  // Now we need to read the tensor slices\n  const string filepattern = strings::StrCat(fname_base, \"_*\");\n  TensorSliceReader reader(filepattern, std::move(open_function));\n  TF_EXPECT_OK(reader.status());\n  EXPECT_EQ(2, reader.num_files());\n\n  // We query some of the tensors\n  {\n    TensorShape shape;\n    DataType type;\n    EXPECT_TRUE(reader.HasTensor(\"test\", &shape, &type));\n    EXPECT_EQ(\"[4,5]\", shape.DebugString());\n    EXPECT_EQ(DataTypeToEnum<T>::v(), type);\n    EXPECT_FALSE(reader.HasTensor(\"don't exist\", nullptr, nullptr));\n  }\n\n  // Now we query some slices\n  //\n  // Slice #1 is an exact match\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"0,2:-\");\n    T expected[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    U results[10];\n    EXPECT_TRUE(reader.CopySliceData(\"test\", s, results));\n    for (int i = 0; i < 10; ++i) {\n      EXPECT_EQ(expected[i], results[i]);\n    }\n  }\n\n  // Slice #2 is a subset match\n  //   .   .   .   .   .\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"1,1:-\");\n    T expected[] = {5, 6, 7, 8, 9};\n    U results[5];\n    EXPECT_TRUE(reader.CopySliceData(\"test\", s, results));\n    for (int i = 0; i < 5; ++i) {\n      EXPECT_EQ(expected[i], results[i]);\n    }\n  }\n\n  // Slice #4 includes the hole and so there is no match\n  //   .   .   .   .   .\n  //   .   .   7   8   9\n  //   .   .  12  13  14\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"1,2:2,3\");\n    U results[6];\n    EXPECT_FALSE(reader.CopySliceData(\"test\", s, results));\n  }\n}\n\n#define TEST_SIMPLE_INT(TYPE, SAVED_TYPE)                             \\\n  TEST(TensorSliceReaderTest, Simple##TYPE) {                         \\\n    SimpleIntXHelper<TYPE, SAVED_TYPE>(CreateTableTensorSliceBuilder, \\\n                                       OpenTableTensorSliceReader,    \\\n                                       #TYPE \"_checkpoint\");          \\\n  }\n\nTEST_SIMPLE_INT(int32, int32)\nTEST_SIMPLE_INT(int64_t, int64_t)\nTEST_SIMPLE_INT(int16, int32)\nTEST_SIMPLE_INT(int8, int32)\nTEST_SIMPLE_INT(uint8, int32)\n\n// Modifies the SavedTensorSlices messages in a checkpoint to allow creating\n// malformed or unsupported checkpoints.\nvoid MutateSavedTensorSlices(\n    const std::string& fname,\n    const std::function<std::string(SavedTensorSlices)>& mutator) {\n  table::Options options;\n  options.compression = table::kNoCompression;\n\n  // Read all entres from the table.\n  std::vector<std::pair<std::string, std::string>> entries;\n  {\n    std::unique_ptr<RandomAccessFile> file;\n    TF_CHECK_OK(Env::Default()->NewRandomAccessFile(fname, &file));\n    uint64 file_size;\n    TF_CHECK_OK(Env::Default()->GetFileSize(fname, &file_size));\n    table::Table* t;\n    TF_CHECK_OK(table::Table::Open(options, file.get(), file_size, &t));\n    std::unique_ptr<table::Table> table(t);\n    std::unique_ptr<table::Iterator> it(table->NewIterator());\n    for (it->Seek(\"\"); it->Valid(); it->Next()) {\n      entries.emplace_back(it->key(), it->value());\n    }\n    TF_CHECK_OK(it->status());\n  }\n\n  // Rewrite the table, mutating each value.\n  {\n    std::unique_ptr<WritableFile> file;\n    TF_CHECK_OK(Env::Default()->NewWritableFile(fname, &file));\n    table::TableBuilder builder(options, file.get());\n    for (const auto& entry : entries) {\n      SavedTensorSlices sts;\n      CHECK(sts.ParseFromString(entry.second));\n      builder.Add(entry.first, mutator(std::move(sts)));\n    }\n    TF_CHECK_OK(builder.Finish());\n    TF_CHECK_OK(file->Close());\n  }\n}\n\nTEST(TensorSliceReaderTest, MissingTensorType) {\n  const string fname = io::JoinPath(testing::TmpDir(), \"invalid_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TensorShape shape({4, 5});\n  TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n  TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n  TF_CHECK_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n    if (sts.has_meta()) {\n      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n        tensor.clear_type();\n      }\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  TF_CHECK_OK(reader.status());\n\n  // The tensor should be present, but loading it should fail due to the\n  // unset (invalid) type.\n  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n  std::unique_ptr<Tensor> tensor;\n  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n}\n\nTEST(TensorSliceReaderTest, UnsupportedTensorType) {\n  const string fname = io::JoinPath(testing::TmpDir(), \"int32_ref_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TensorShape shape({4, 5});\n  TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n  TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n  TF_CHECK_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n    if (sts.has_meta()) {\n      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n        tensor.set_type(DT_INT32_REF);\n      }\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  TF_CHECK_OK(reader.status());\n\n  // The tensor should be present, but loading it should fail due to the\n  // unsupported type.\n  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n  std::unique_ptr<Tensor> tensor;\n  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n}\n\nTEST(TensorSliceReaderTest, NegativeTensorShapeDimension) {\n  const string fname =\n      io::JoinPath(testing::TmpDir(), \"negative_dim_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TF_CHECK_OK(writer.Add(\"test\", TensorShape({4, 5}),\n                         TensorSlice::ParseOrDie(\"0,2:-\"), data));\n  TF_CHECK_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n    if (sts.has_meta()) {\n      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n        for (auto& dim : *tensor.mutable_shape()->mutable_dim()) {\n          dim.set_size(-dim.size());\n        }\n      }\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  // The negative dimension should cause loading to fail.\n  EXPECT_FALSE(reader.status().ok());\n}\n\nTEST(TensorSliceReaderTest, InvalidTensorSlice) {\n  const string fname =\n      io::JoinPath(testing::TmpDir(), \"invalid_slice_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TF_CHECK_OK(writer.Add(\"test\", TensorShape({4, 5}),\n                         TensorSlice::ParseOrDie(\"0,2:-\"), data));\n  TF_CHECK_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n    if (sts.has_meta()) {\n      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n        tensor.mutable_slice(0)->mutable_extent(0)->set_length(-10);\n      }\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  // The negative exent length should cause loading to fail.\n  EXPECT_FALSE(reader.status().ok());\n}\n\nvoid CachedTensorSliceReaderTesterHelper(\n    const TensorSliceWriter::CreateBuilderFunction& create_function,\n    const TensorSliceReader::OpenTableFunction& open_function) {\n  const string fname_base = io::JoinPath(testing::TmpDir(), \"float_checkpoint\");\n\n  TensorShape shape({4, 5});\n\n  // File #0 contains a slice that is the top two rows:\n  //\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    const string fname = strings::StrCat(fname_base, \"_0\");\n    TensorSliceWriter writer(fname, create_function);\n    const float data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // File #1 contains two slices:\n  //\n  // slice #0 is the bottom left corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //  10  11  12   .   .\n  //  15  16  17   .   .\n  //\n  // slice #1 is the bottom right corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .  18  19\n  {\n    const string fname = strings::StrCat(fname_base, \"_1\");\n    TensorSliceWriter writer(fname, create_function);\n    // slice #0\n    {\n      const float data[] = {10, 11, 12, 15, 16, 17};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"2,2:0,3\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    // slice #1\n    {\n      const float data[] = {18, 19};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"3,1:3,2\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // Notice that we leave a hole in the tensor\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   . (13) (14)\n  //   .   .   .   .   .\n\n  // Now we need to read the tensor slices\n  TensorSliceReaderCache cache;\n  const string filepattern = strings::StrCat(fname_base, \"_*\");\n  const TensorSliceReader* reader = cache.GetReader(\n      filepattern, open_function, TensorSliceReader::kLoadAllShards);\n  EXPECT_TRUE(reader != nullptr);\n  EXPECT_EQ(2, reader->num_files());\n\n  // We query some of the tensors\n  {\n    TensorShape shape;\n    DataType type;\n    EXPECT_TRUE(reader->HasTensor(\"test\", &shape, &type));\n    EXPECT_EQ(\"[4,5]\", shape.DebugString());\n    EXPECT_EQ(DT_FLOAT, type);\n    EXPECT_FALSE(reader->HasTensor(\"don't exist\", nullptr, nullptr));\n  }\n\n  // Make sure the reader is cached.\n  const TensorSliceReader* reader2 = cache.GetReader(\n      filepattern, open_function, TensorSliceReader::kLoadAllShards);\n  EXPECT_EQ(reader, reader2);\n\n  reader = cache.GetReader(\"file_does_not_exist\", open_function,\n                           TensorSliceReader::kLoadAllShards);\n  EXPECT_TRUE(reader == nullptr);\n}\n\nTEST(CachedTensorSliceReaderTest, SimpleFloat) {\n  CachedTensorSliceReaderTesterHelper(CreateTableTensorSliceBuilder,\n                                      OpenTableTensorSliceReader);\n}\n\nstatic void VersionTest(const VersionDef& versions, const string& error) {\n  const string path = io::JoinPath(testing::TmpDir(), \"checkpoint\");\n\n  {\n    // Prepare an empty checkpoint with some version information\n    SavedTensorSlices sts;\n    *sts.mutable_meta()->mutable_versions() = versions;\n    string contents;\n    EXPECT_TRUE(sts.SerializeToString(&contents));\n\n    // Write it to disk\n    TensorSliceWriter::Builder* builder;\n    TF_ASSERT_OK(CreateTableTensorSliceBuilder(path, &builder));\n    builder->Add(kSavedTensorSlicesKey, contents);\n    int64_t file_size;\n    TF_EXPECT_OK(builder->Finish(&file_size));\n    delete builder;\n  }\n\n  // Read it back in and verify that we get the expected error\n  TensorSliceReader reader(path, OpenTableTensorSliceReader);\n  EXPECT_TRUE(reader.status().code() == error::INVALID_ARGUMENT &&\n              absl::StartsWith(reader.status().error_message(), error))\n      << \"Expected error starting with '\" << errors::InvalidArgument(error)\n      << \"', got '\" << reader.status() << \"'\";\n}\n\nTEST(CheckpointVersionTest, MinConsumer) {\n  VersionDef versions;\n  versions.set_producer(TF_CHECKPOINT_VERSION + 1);\n  versions.set_min_consumer(TF_CHECKPOINT_VERSION + 1);\n  VersionTest(\n      versions,\n      strings::StrCat(\"Checkpoint min consumer version \",\n                      TF_CHECKPOINT_VERSION + 1, \" above current version \",\n                      TF_CHECKPOINT_VERSION, \" for TensorFlow\"));\n}\n\nTEST(CheckpointVersionTest, MinProducer) {\n  VersionDef versions;\n  versions.set_producer(TF_CHECKPOINT_VERSION_MIN_PRODUCER - 1);\n  VersionTest(versions, strings::StrCat(\"Checkpoint producer version \",\n                                        TF_CHECKPOINT_VERSION_MIN_PRODUCER - 1,\n                                        \" below min producer \",\n                                        TF_CHECKPOINT_VERSION_MIN_PRODUCER,\n                                        \" supported by TensorFlow\"));\n}\n\nTEST(CheckpointVersionTest, BadConsumer) {\n  VersionDef versions;\n  versions.set_producer(TF_CHECKPOINT_VERSION + 1);\n  versions.add_bad_consumers(TF_CHECKPOINT_VERSION);\n  VersionTest(\n      versions,\n      strings::StrCat(\n          \"Checkpoint disallows consumer version \", TF_CHECKPOINT_VERSION,\n          \".  Please upgrade TensorFlow: this version is likely buggy.\"));\n}\n\n}  // namespace\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// Utilities for saving/restoring tensor slice checkpoints.\n\n#ifndef TENSORFLOW_CORE_UTIL_SAVED_TENSOR_SLICE_UTIL_H_\n#define TENSORFLOW_CORE_UTIL_SAVED_TENSOR_SLICE_UTIL_H_\n\n#include <string>  // for string\n#include \"tensorflow/core/framework/tensor.pb.h\"\n#include \"tensorflow/core/framework/tensor_slice.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/lib/core/status.h\"  // for Status\n#include \"tensorflow/core/platform/protobuf.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\n// The key for the metadata in the tensor slice checkpoint files. It is \"\" so\n// that the metadata is always at the beginning of a checkpoint file.\nextern const char kSavedTensorSlicesKey[];\n\n// Encode a tensor name + a tensor slice into an ordered code and outputs it as\n// a string.\n// The format is\n//  <0>\n//  <tensor_name>\n//  <rank>\n//  <dim-0-start><dim-0-length>\n//  <dim-1-start><dim-1-length>\n//  ...\n\nstring EncodeTensorNameSlice(const string& name,\n                             const tensorflow::TensorSlice& slice);\n\n// Parse out the name and the slice from string encoded as an ordered code.\nStatus DecodeTensorNameSlice(const string& code, string* name,\n                             tensorflow::TensorSlice* slice);\n\n// Extracts the full shape, slice spec, and shape of the slice from\n// \"shape_and_slice\".  On non-OK return, caller must clear the out-arguments\n// before reusing.\nStatus ParseShapeAndSlice(const string& shape_and_slice, TensorShape* shape,\n                          TensorSlice* slice, TensorShape* shape_slice);\n\ntemplate <typename T>\nstruct SaveTypeTraits;\n\ntemplate <typename T>\nint TensorProtoDataSize(const TensorProto& t);\n\ntemplate <typename T>\nconst typename SaveTypeTraits<T>::SavedType* TensorProtoData(\n    const TensorProto& t);\n\ntemplate <typename T>\ntypename SaveTypeTraits<T>::RepeatedField* MutableTensorProtoData(\n    TensorProto* t);\n\ntemplate <typename T>\nvoid Fill(T* data, size_t n, TensorProto* t);\n\n#define TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, STYPE)      \\\n  template <>                                                            \\\n  struct SaveTypeTraits<TYPE> {                                          \\\n    static constexpr bool supported = true;                              \\\n    typedef STYPE SavedType;                                             \\\n    typedef protobuf::RepeatedField<FTYPE> RepeatedField;                \\\n  };                                                                     \\\n  template <>                                                            \\\n  inline const STYPE* TensorProtoData<TYPE>(const TensorProto& t) {      \\\n    static_assert(SaveTypeTraits<TYPE>::supported,                       \\\n                  \"Specified type \" #TYPE \" not supported for Restore\"); \\\n    return reinterpret_cast<const STYPE*>(t.FIELD##_val().data());       \\\n  }                                                                      \\\n  template <>                                                            \\\n  inline protobuf::RepeatedField<FTYPE>* MutableTensorProtoData<TYPE>(   \\\n      TensorProto * t) {                                                 \\\n    static_assert(SaveTypeTraits<TYPE>::supported,                       \\\n                  \"Specified type \" #TYPE \" not supported for Save\");    \\\n    return reinterpret_cast<protobuf::RepeatedField<FTYPE>*>(            \\\n        t->mutable_##FIELD##_val());                                     \\\n  }\n\n#define TENSOR_PROTO_EXTRACT_TYPE(TYPE, FIELD, FTYPE)             \\\n  TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, FTYPE)     \\\n  template <>                                                     \\\n  inline int TensorProtoDataSize<TYPE>(const TensorProto& t) {    \\\n    return t.FIELD##_val_size();                                  \\\n  }                                                               \\\n  template <>                                                     \\\n  inline void Fill(const TYPE* data, size_t n, TensorProto* t) {  \\\n    typename protobuf::RepeatedField<FTYPE> copy(data, data + n); \\\n    t->mutable_##FIELD##_val()->Swap(&copy);                      \\\n  }\n\n// Complex needs special treatment since proto doesn't have native complex\n#define TENSOR_PROTO_EXTRACT_TYPE_COMPLEX(TYPE, FIELD, FTYPE)       \\\n  TENSOR_PROTO_EXTRACT_TYPE_HELPER(TYPE, FIELD, FTYPE, TYPE)        \\\n  template <>                                                       \\\n  inline int TensorProtoDataSize<TYPE>(const TensorProto& t) {      \\\n    return t.FIELD##_val_size() / 2;                                \\\n  }                                                                 \\\n  template <>                                                       \\\n  inline void Fill(const TYPE* data, size_t n, TensorProto* t) {    \\\n    const FTYPE* sub = reinterpret_cast<const FTYPE*>(data);        \\\n    typename protobuf::RepeatedField<FTYPE> copy(sub, sub + 2 * n); \\\n    t->mutable_##FIELD##_val()->Swap(&copy);                        \\\n  }\n\nTENSOR_PROTO_EXTRACT_TYPE(bool, bool, bool);\nTENSOR_PROTO_EXTRACT_TYPE(float, float, float);\nTENSOR_PROTO_EXTRACT_TYPE(double, double, double);\nTENSOR_PROTO_EXTRACT_TYPE_COMPLEX(complex64, scomplex, float);\nTENSOR_PROTO_EXTRACT_TYPE_COMPLEX(complex128, dcomplex, double);\nTENSOR_PROTO_EXTRACT_TYPE(int32, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(uint32, uint32, uint32);\nTENSOR_PROTO_EXTRACT_TYPE(int64_t, int64, protobuf_int64);\nTENSOR_PROTO_EXTRACT_TYPE(uint64, uint64, protobuf_uint64);\nTENSOR_PROTO_EXTRACT_TYPE(uint16, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(uint8, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(int8, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(int16, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(qint8, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(quint8, int, int32);\nTENSOR_PROTO_EXTRACT_TYPE(quint16, int, int32);\n\n#undef TENSOR_PROTO_EXTRACT_TYPE_COMPLEX\n#undef TENSOR_PROTO_EXTRACT_TYPE_HELPER\n#undef TENSOR_PROTO_EXTRACT_TYPE\n\n// Custom implementation for qint32, based on the one for int32.\n\ntemplate <>\nstruct SaveTypeTraits<qint32> : SaveTypeTraits<int32> {};\n\ntemplate <>\ninline int TensorProtoDataSize<qint32>(const TensorProto& t) {\n  return t.int_val_size();\n}\n\ntemplate <>\ninline const int32* TensorProtoData<qint32>(const TensorProto& t) {\n  static_assert(SaveTypeTraits<qint32>::supported,\n                \"Specified type qint32 not supported for Restore\");\n  return reinterpret_cast<const int32*>(t.int_val().data());\n}\n\ninline void Fill(const qint32* data, size_t n, TensorProto* t) {\n  const int32* p = reinterpret_cast<const int32*>(data);\n  typename protobuf::RepeatedField<int32> copy(p, p + n);\n  t->mutable_int_val()->Swap(&copy);\n}\n\n// Custom implementation for Eigen::half.\n\ntemplate <>\nstruct SaveTypeTraits<Eigen::half> {\n  static constexpr bool supported = true;\n  typedef int SavedType;\n  typedef protobuf::RepeatedField<int32> RepeatedField;\n};\n\ntemplate <>\ninline int TensorProtoDataSize<Eigen::half>(const TensorProto& t) {\n  return t.half_val_size();\n}\n\ntemplate <>\ninline const int* TensorProtoData<Eigen::half>(const TensorProto& t) {\n  return t.half_val().data();\n}\n\ntemplate <>\ninline protobuf::RepeatedField<int32>* MutableTensorProtoData<Eigen::half>(\n    TensorProto* t) {\n  return t->mutable_half_val();\n}\n\ntemplate <>\ninline void Fill(const Eigen::half* data, size_t n, TensorProto* t) {\n  typename protobuf::RepeatedField<int32>* val = t->mutable_half_val();\n  val->Resize(n, 0);\n  for (size_t i = 0; i < n; ++i) {\n    val->Set(i, Eigen::numext::bit_cast<uint16>(data[i]));\n  }\n}\n\n// Custom implementation for string.\n\ntemplate <>\nstruct SaveTypeTraits<tstring> {\n  static constexpr bool supported = true;\n  typedef const string* SavedType;\n  typedef protobuf::RepeatedPtrField<string> RepeatedField;\n};\n\ntemplate <>\ninline int TensorProtoDataSize<tstring>(const TensorProto& t) {\n  return t.string_val_size();\n}\n\ntemplate <>\ninline const string* const* TensorProtoData<tstring>(const TensorProto& t) {\n  static_assert(SaveTypeTraits<tstring>::supported,\n                \"Specified type tstring not supported for Restore\");\n  return t.string_val().data();\n}\n\ntemplate <>\ninline protobuf::RepeatedPtrField<string>* MutableTensorProtoData<tstring>(\n    TensorProto* t) {\n  static_assert(SaveTypeTraits<tstring>::supported,\n                \"Specified type tstring not supported for Save\");\n  return t->mutable_string_val();\n}\n\ntemplate <>\ninline void Fill(const tstring* data, size_t n, TensorProto* t) {\n  typename protobuf::RepeatedPtrField<string> copy(data, data + n);\n  t->mutable_string_val()->Swap(&copy);\n}\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_UTIL_SAVED_TENSOR_SLICE_UTIL_H_\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// The utility to read checkpoints for google brain tensor ops and v3\n// checkpoints for dist_belief.\n\n#ifndef TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_\n#define TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_\n\n#include <unordered_map>\n\n#include <vector>\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_slice.h\"\n#include \"tensorflow/core/framework/types.pb.h\"\n#include \"tensorflow/core/lib/core/status.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/gtl/map_util.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/macros.h\"\n#include \"tensorflow/core/platform/mutex.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/util/saved_tensor_slice.pb.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n#include \"tensorflow/core/util/tensor_slice_set.h\"\n#include \"tensorflow/core/util/tensor_slice_util.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\n// The reader reads in all the meta data about all the tensor slices. Then it\n// will try to read the relevant data on-demand to produce the data for the\n// slices needed.\n// NOTE(yangke): another way to do this is to first load a list of the tensor\n// slices needed and then just selectively read some of the meta data. That\n// might optimize the loading but makes the logic a bit more complicated. We\n// might want to revisit that.\n// TODO(yangke): consider moving to TensorProto.\nclass TensorSliceReader {\n public:\n  // Abstract interface for reading data out of a tensor slice checkpoint file\n  class Table {\n   public:\n    virtual ~Table();\n    virtual bool Get(const string& key, string* value) = 0;\n  };\n  typedef std::function<Status(const string&, Table**)> OpenTableFunction;\n\n  static constexpr int kLoadAllShards = -1;\n  TensorSliceReader(const string& filepattern);\n  TensorSliceReader(const string& filepattern, OpenTableFunction open_function);\n  TensorSliceReader(const string& filepattern, OpenTableFunction open_function,\n                    int preferred_shard);\n  virtual ~TensorSliceReader();\n\n  // Get the filename this reader is attached to.\n  const string& filepattern() const { return filepattern_; }\n\n  // Get the number of files matched.\n  int num_files() const { return sss_.size(); }\n\n  // Get the status of the reader.\n  const Status status() const { return status_; }\n\n  // Checks if the reader contains any slice of a tensor. In case the reader\n  // does contain the tensor, if \"shape\" is not nullptr, fill \"shape\" with the\n  // shape of the tensor; if \"type\" is not nullptr, fill \"type\" with the type\n  // of the tensor.\n  bool HasTensor(const string& name, TensorShape* shape, DataType* type) const;\n\n  // Checks if the reader contains all the data about a tensor slice, and if\n  // yes, copies the data of the slice to \"data\". The caller needs to make sure\n  // that \"data\" points to a buffer that holds enough data.\n  // This is a slow function since it needs to read sstables.\n  template <typename T>\n  bool CopySliceData(const string& name, const TensorSlice& slice,\n                     T* data) const;\n\n  // Get the tensors.\n  const std::unordered_map<string, TensorSliceSet*>& Tensors() const {\n    return tensors_;\n  }\n\n  // Returns value for one tensor. Only single slice checkpoints are supported\n  // at the moment.\n  Status GetTensor(const string& name,\n                   std::unique_ptr<tensorflow::Tensor>* out_tensor) const;\n\n  typedef std::unordered_map<string, TensorShape> VarToShapeMap;\n  typedef std::unordered_map<string, DataType> VarToDataTypeMap;\n\n  // Returns a map from tensor name to shape.\n  VarToShapeMap GetVariableToShapeMap() const;\n\n  // Returns a map from tensor name to data type.\n  VarToDataTypeMap GetVariableToDataTypeMap() const;\n\n  // Returns a string containing names and shapes of all the tensors.\n  const string DebugString() const;\n\n private:\n  friend class TensorSliceWriteTestHelper;\n\n  void LoadShard(int shard) const;\n  void LoadAllShards() const;\n\n  const TensorSliceSet* FindTensorSlice(\n      const string& name, const TensorSlice& slice,\n      std::vector<std::pair<TensorSlice, string>>* details) const;\n\n  const string filepattern_;\n  const OpenTableFunction open_function_;\n  std::vector<string> fnames_;\n  std::unordered_map<string, int> fname_to_index_;\n\n  // Guards the attributes below.\n  mutable mutex mu_;\n  mutable bool all_shards_loaded_ = false;\n  mutable std::vector<std::unique_ptr<Table>> sss_;\n  mutable std::unordered_map<string, TensorSliceSet*> tensors_;\n  mutable Status status_;\n\n  TF_DISALLOW_COPY_AND_ASSIGN(TensorSliceReader);\n};\n\nStatus OpenTableTensorSliceReader(const string& fname,\n                                  TensorSliceReader::Table** table);\n\ntemplate <typename T>\nbool TensorSliceReader::CopySliceData(const string& name,\n                                      const TensorSlice& slice, T* data) const {\n  std::vector<std::pair<TensorSlice, string>> details;\n  const TensorSliceSet* tss;\n  {\n    mutex_lock l(mu_);\n    tss = FindTensorSlice(name, slice, &details);\n    if (!tss && !all_shards_loaded_) {\n      VLOG(1) << \"Did not find slice in preferred shard, loading all shards.\"\n              << name << \": \" << slice.DebugString();\n      LoadAllShards();\n      tss = FindTensorSlice(name, slice, &details);\n    }\n    if (!tss) {\n      // No such tensor\n      return false;\n    }\n  }\n  // We have the data -- copy it over.\n  string value;\n  for (const auto& x : details) {\n    const TensorSlice& slice_s = x.first;\n    const string& fname = x.second;\n    int idx = gtl::FindWithDefault(fname_to_index_, fname, -1);\n    CHECK_GE(idx, 0) << \"Failed to find the index for filename \" << fname;\n    // We read a record in the corresponding sstable\n    const string key = EncodeTensorNameSlice(name, slice_s);\n    if (!sss_[idx]->Get(key, &value)) {\n      VLOG(1) << \"Failed to seek to the record for tensor \" << name\n              << \", slice \" << slice_s.DebugString()\n              << \": computed key = \" << key;\n      return false;\n    }\n    SavedTensorSlices sts;\n    if (!ParseProtoUnlimited(&sts, value)) {\n      VLOG(1) << \"Failed to parse the record for tensor \" << name << \", slice \"\n              << slice_s.DebugString() << \": computed key = \" << key;\n      return false;\n    }\n    // Ensure the TensorSlice contains the expected amount of data.\n    TensorShape shp_s;\n    Status s = slice_s.SliceTensorShape(tss->shape(), &shp_s);\n    if (!s.ok()) {\n      VLOG(1) << \"Failed to slice tensor \" << name << \", slice \"\n              << slice_s.DebugString() << \": \" << s;\n      return false;\n    }\n    if (checkpoint::TensorProtoDataSize<T>(sts.data().data()) !=\n        shp_s.num_elements()) {\n      VLOG(1) << \"Tensor \" << name << \", slice \" << slice_s.DebugString()\n              << \" had an unexpected amount of data: expected = \"\n              << shp_s.num_elements() << \", got = \"\n              << checkpoint::TensorProtoDataSize<T>(sts.data().data());\n      return false;\n    }\n    CopyDataFromTensorSliceToTensorSlice(\n        tss->shape(), slice_s, slice,\n        checkpoint::TensorProtoData<T>(sts.data().data()), data);\n  }\n  return true;\n}\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n\n#endif  // TENSORFLOW_CORE_UTIL_TENSOR_SLICE_READER_H_\n", "/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/core/util/tensor_slice_reader.h\"\n\n#include <utility>\n#include <vector>\n\n#include \"tensorflow/core/framework/tensor_shape.pb.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/framework/versions.pb.h\"\n#include \"tensorflow/core/lib/core/status_test_util.h\"\n#include \"tensorflow/core/lib/core/stringpiece.h\"\n#include \"tensorflow/core/lib/io/iterator.h\"\n#include \"tensorflow/core/lib/io/path.h\"\n#include \"tensorflow/core/lib/io/table.h\"\n#include \"tensorflow/core/lib/io/table_builder.h\"\n#include \"tensorflow/core/lib/strings/str_util.h\"\n#include \"tensorflow/core/lib/strings/strcat.h\"\n#include \"tensorflow/core/platform/env.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/protobuf.h\"\n#include \"tensorflow/core/platform/test.h\"\n#include \"tensorflow/core/platform/types.h\"\n#include \"tensorflow/core/public/version.h\"\n#include \"tensorflow/core/util/saved_tensor_slice.pb.h\"\n#include \"tensorflow/core/util/saved_tensor_slice_util.h\"\n#include \"tensorflow/core/util/tensor_slice_reader_cache.h\"\n#include \"tensorflow/core/util/tensor_slice_writer.h\"\n\nnamespace tensorflow {\n\nnamespace checkpoint {\n\nnamespace {\n\n// A simple test where we write a few tensor slices with a number of tensor\n// slice writers and then read them back from a tensor slice reader.\n//\n// We have a 2-d tensor of shape 4 X 5 that looks like this:\n//\n//   0   1   2   3   4\n//   5   6   7   8   9\n//  10  11  12  13  14\n//  15  16  17  18  19\n//\n// We assume this is a row-major matrix.\n\nvoid SimpleFloatHelper(\n    const TensorSliceWriter::CreateBuilderFunction& create_function,\n    TensorSliceReader::OpenTableFunction open_function) {\n  const string fname_base = io::JoinPath(testing::TmpDir(), \"float_checkpoint\");\n\n  TensorShape shape({4, 5});\n\n  // File #0 contains a slice that is the top two rows:\n  //\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    const string fname = strings::StrCat(fname_base, \"_0\");\n    TensorSliceWriter writer(fname, create_function);\n    const float data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // File #1 contains two slices:\n  //\n  // slice #0 is the bottom left corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //  10  11  12   .   .\n  //  15  16  17   .   .\n  //\n  // slice #1 is the bottom right corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .  18  19\n  {\n    const string fname = strings::StrCat(fname_base, \"_1\");\n    TensorSliceWriter writer(fname, create_function);\n    // slice #0\n    {\n      const float data[] = {10, 11, 12, 15, 16, 17};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"2,2:0,3\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    // slice #1\n    {\n      const float data[] = {18, 19};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"3,1:3,2\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // Notice that we leave a hole in the tensor\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   . (13) (14)\n  //   .   .   .   .   .\n\n  // Now we need to read the tensor slices\n  const string filepattern = strings::StrCat(fname_base, \"_*\");\n  TensorSliceReader reader(filepattern, std::move(open_function));\n  TF_EXPECT_OK(reader.status());\n  EXPECT_EQ(2, reader.num_files());\n\n  // We query some of the tensors\n  {\n    TensorShape shape;\n    DataType type;\n    EXPECT_TRUE(reader.HasTensor(\"test\", &shape, &type));\n    EXPECT_EQ(\"[4,5]\", shape.DebugString());\n    EXPECT_EQ(DT_FLOAT, type);\n    EXPECT_FALSE(reader.HasTensor(\"don't exist\", nullptr, nullptr));\n  }\n\n  // Now we query some slices\n  //\n  // Slice #1 is an exact match\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"0,2:-\");\n    float expected[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    float results[10];\n    EXPECT_TRUE(reader.CopySliceData(\"test\", s, results));\n    for (int i = 0; i < 10; ++i) {\n      EXPECT_EQ(expected[i], results[i]);\n    }\n  }\n\n  // Slice #2 is a subset match\n  //   .   .   .   .   .\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"1,1:-\");\n    float expected[] = {5, 6, 7, 8, 9};\n    float results[5];\n    EXPECT_TRUE(reader.CopySliceData(\"test\", s, results));\n    for (int i = 0; i < 5; ++i) {\n      EXPECT_EQ(expected[i], results[i]);\n    }\n  }\n\n  // Slice #4 includes the hole and so there is no match\n  //   .   .   .   .   .\n  //   .   .   7   8   9\n  //   .   .  12  13  14\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"1,2:2,3\");\n    float results[6];\n    EXPECT_FALSE(reader.CopySliceData(\"test\", s, results));\n  }\n}\n\nTEST(TensorSliceReaderTest, SimpleFloat) {\n  SimpleFloatHelper(CreateTableTensorSliceBuilder, OpenTableTensorSliceReader);\n}\n\ntemplate <typename T, typename U>\nvoid SimpleIntXHelper(\n    const TensorSliceWriter::CreateBuilderFunction& create_function,\n    TensorSliceReader::OpenTableFunction open_function,\n    const string& checkpoint_file) {\n  const string fname_base = io::JoinPath(testing::TmpDir(), checkpoint_file);\n\n  TensorShape shape({4, 5});\n\n  // File #0 contains a slice that is the top two rows:\n  //\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    const string fname = strings::StrCat(fname_base, \"_0\");\n    TensorSliceWriter writer(fname, create_function);\n    const T data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // File #1 contains two slices:\n  //\n  // slice #0 is the bottom left corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //  10  11  12   .   .\n  //  15  16  17   .   .\n  //\n  // slice #1 is the bottom right corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .  18  19\n  {\n    const string fname = strings::StrCat(fname_base, \"_1\");\n    TensorSliceWriter writer(fname, create_function);\n    // slice #0\n    {\n      const T data[] = {10, 11, 12, 15, 16, 17};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"2,2:0,3\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    // slice #1\n    {\n      const T data[] = {18, 19};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"3,1:3,2\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // Notice that we leave a hole in the tensor\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   . (13) (14)\n  //   .   .   .   .   .\n\n  // Now we need to read the tensor slices\n  const string filepattern = strings::StrCat(fname_base, \"_*\");\n  TensorSliceReader reader(filepattern, std::move(open_function));\n  TF_EXPECT_OK(reader.status());\n  EXPECT_EQ(2, reader.num_files());\n\n  // We query some of the tensors\n  {\n    TensorShape shape;\n    DataType type;\n    EXPECT_TRUE(reader.HasTensor(\"test\", &shape, &type));\n    EXPECT_EQ(\"[4,5]\", shape.DebugString());\n    EXPECT_EQ(DataTypeToEnum<T>::v(), type);\n    EXPECT_FALSE(reader.HasTensor(\"don't exist\", nullptr, nullptr));\n  }\n\n  // Now we query some slices\n  //\n  // Slice #1 is an exact match\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"0,2:-\");\n    T expected[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    U results[10];\n    EXPECT_TRUE(reader.CopySliceData(\"test\", s, results));\n    for (int i = 0; i < 10; ++i) {\n      EXPECT_EQ(expected[i], results[i]);\n    }\n  }\n\n  // Slice #2 is a subset match\n  //   .   .   .   .   .\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"1,1:-\");\n    T expected[] = {5, 6, 7, 8, 9};\n    U results[5];\n    EXPECT_TRUE(reader.CopySliceData(\"test\", s, results));\n    for (int i = 0; i < 5; ++i) {\n      EXPECT_EQ(expected[i], results[i]);\n    }\n  }\n\n  // Slice #4 includes the hole and so there is no match\n  //   .   .   .   .   .\n  //   .   .   7   8   9\n  //   .   .  12  13  14\n  //   .   .   .   .   .\n  {\n    TensorSlice s = TensorSlice::ParseOrDie(\"1,2:2,3\");\n    U results[6];\n    EXPECT_FALSE(reader.CopySliceData(\"test\", s, results));\n  }\n}\n\n#define TEST_SIMPLE_INT(TYPE, SAVED_TYPE)                             \\\n  TEST(TensorSliceReaderTest, Simple##TYPE) {                         \\\n    SimpleIntXHelper<TYPE, SAVED_TYPE>(CreateTableTensorSliceBuilder, \\\n                                       OpenTableTensorSliceReader,    \\\n                                       #TYPE \"_checkpoint\");          \\\n  }\n\nTEST_SIMPLE_INT(int32, int32)\nTEST_SIMPLE_INT(int64_t, int64_t)\nTEST_SIMPLE_INT(int16, int32)\nTEST_SIMPLE_INT(int8, int32)\nTEST_SIMPLE_INT(uint8, int32)\n\n// Modifies the SavedTensorSlices messages in a checkpoint to allow creating\n// malformed or unsupported checkpoints.\nvoid MutateSavedTensorSlices(\n    const std::string& fname,\n    const std::function<std::string(SavedTensorSlices)>& mutator) {\n  table::Options options;\n  options.compression = table::kNoCompression;\n\n  // Read all entres from the table.\n  std::vector<std::pair<std::string, std::string>> entries;\n  {\n    std::unique_ptr<RandomAccessFile> file;\n    TF_CHECK_OK(Env::Default()->NewRandomAccessFile(fname, &file));\n    uint64 file_size;\n    TF_CHECK_OK(Env::Default()->GetFileSize(fname, &file_size));\n    table::Table* t;\n    TF_CHECK_OK(table::Table::Open(options, file.get(), file_size, &t));\n    std::unique_ptr<table::Table> table(t);\n    std::unique_ptr<table::Iterator> it(table->NewIterator());\n    for (it->Seek(\"\"); it->Valid(); it->Next()) {\n      entries.emplace_back(it->key(), it->value());\n    }\n    TF_CHECK_OK(it->status());\n  }\n\n  // Rewrite the table, mutating each value.\n  {\n    std::unique_ptr<WritableFile> file;\n    TF_CHECK_OK(Env::Default()->NewWritableFile(fname, &file));\n    table::TableBuilder builder(options, file.get());\n    for (const auto& entry : entries) {\n      SavedTensorSlices sts;\n      CHECK(sts.ParseFromString(entry.second));\n      builder.Add(entry.first, mutator(std::move(sts)));\n    }\n    TF_CHECK_OK(builder.Finish());\n    TF_CHECK_OK(file->Close());\n  }\n}\n\nTEST(TensorSliceReaderTest, MissingTensorType) {\n  const string fname = io::JoinPath(testing::TmpDir(), \"invalid_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TensorShape shape({4, 5});\n  TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n  TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n  TF_CHECK_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n    if (sts.has_meta()) {\n      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n        tensor.clear_type();\n      }\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  TF_CHECK_OK(reader.status());\n\n  // The tensor should be present, but loading it should fail due to the\n  // unset (invalid) type.\n  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n  std::unique_ptr<Tensor> tensor;\n  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n}\n\nTEST(TensorSliceReaderTest, UnsupportedTensorType) {\n  const string fname = io::JoinPath(testing::TmpDir(), \"int32_ref_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TensorShape shape({4, 5});\n  TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n  TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n  TF_CHECK_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n    if (sts.has_meta()) {\n      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n        tensor.set_type(DT_INT32_REF);\n      }\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  TF_CHECK_OK(reader.status());\n\n  // The tensor should be present, but loading it should fail due to the\n  // unsupported type.\n  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n  std::unique_ptr<Tensor> tensor;\n  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n}\n\nTEST(TensorSliceReaderTest, NegativeTensorShapeDimension) {\n  const string fname =\n      io::JoinPath(testing::TmpDir(), \"negative_dim_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TF_CHECK_OK(writer.Add(\"test\", TensorShape({4, 5}),\n                         TensorSlice::ParseOrDie(\"0,2:-\"), data));\n  TF_CHECK_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n    if (sts.has_meta()) {\n      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n        for (auto& dim : *tensor.mutable_shape()->mutable_dim()) {\n          dim.set_size(-dim.size());\n        }\n      }\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  // The negative dimension should cause loading to fail.\n  EXPECT_FALSE(reader.status().ok());\n}\n\nTEST(TensorSliceReaderTest, InvalidTensorSlice) {\n  const string fname =\n      io::JoinPath(testing::TmpDir(), \"invalid_slice_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TF_CHECK_OK(writer.Add(\"test\", TensorShape({4, 5}),\n                         TensorSlice::ParseOrDie(\"0,2:-\"), data));\n  TF_CHECK_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [](SavedTensorSlices sts) {\n    if (sts.has_meta()) {\n      for (auto& tensor : *sts.mutable_meta()->mutable_tensor()) {\n        tensor.mutable_slice(0)->mutable_extent(0)->set_length(-10);\n      }\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  // The negative exent length should cause loading to fail.\n  EXPECT_FALSE(reader.status().ok());\n}\n\nTEST(TensorSliceReaderTest, MissingTensorData) {\n  const string fname =\n      io::JoinPath(testing::TmpDir(), \"missing_data_checkpoint\");\n  TensorSliceWriter writer(fname, CreateTableTensorSliceBuilder);\n  const int32 data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n  TF_ASSERT_OK(writer.Add(\"test\", TensorShape({4, 5}),\n                          TensorSlice::ParseOrDie(\"0,2:-\"), data));\n  TF_ASSERT_OK(writer.Finish());\n\n  MutateSavedTensorSlices(fname, [&](SavedTensorSlices sts) {\n    if (sts.has_data()) {\n      // Replace the data with only 4 elements.\n      Fill(data, 4, sts.mutable_data()->mutable_data());\n    }\n    return sts.SerializeAsString();\n  });\n\n  TensorSliceReader reader(fname, OpenTableTensorSliceReader);\n  TF_ASSERT_OK(reader.status());\n\n  // The tensor should be present, but loading it should fail due to the missing\n  // data.\n  EXPECT_TRUE(reader.HasTensor(\"test\", nullptr, nullptr));\n  std::unique_ptr<Tensor> tensor;\n  EXPECT_FALSE(reader.GetTensor(\"test\", &tensor).ok());\n}\n\nvoid CachedTensorSliceReaderTesterHelper(\n    const TensorSliceWriter::CreateBuilderFunction& create_function,\n    const TensorSliceReader::OpenTableFunction& open_function) {\n  const string fname_base = io::JoinPath(testing::TmpDir(), \"float_checkpoint\");\n\n  TensorShape shape({4, 5});\n\n  // File #0 contains a slice that is the top two rows:\n  //\n  //   0   1   2   3   4\n  //   5   6   7   8   9\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  {\n    const string fname = strings::StrCat(fname_base, \"_0\");\n    TensorSliceWriter writer(fname, create_function);\n    const float data[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9};\n    TensorSlice slice = TensorSlice::ParseOrDie(\"0,2:-\");\n    TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // File #1 contains two slices:\n  //\n  // slice #0 is the bottom left corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //  10  11  12   .   .\n  //  15  16  17   .   .\n  //\n  // slice #1 is the bottom right corner\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   .  18  19\n  {\n    const string fname = strings::StrCat(fname_base, \"_1\");\n    TensorSliceWriter writer(fname, create_function);\n    // slice #0\n    {\n      const float data[] = {10, 11, 12, 15, 16, 17};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"2,2:0,3\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    // slice #1\n    {\n      const float data[] = {18, 19};\n      TensorSlice slice = TensorSlice::ParseOrDie(\"3,1:3,2\");\n      TF_CHECK_OK(writer.Add(\"test\", shape, slice, data));\n    }\n    TF_CHECK_OK(writer.Finish());\n  }\n\n  // Notice that we leave a hole in the tensor\n  //   .   .   .   .   .\n  //   .   .   .   .   .\n  //   .   .   . (13) (14)\n  //   .   .   .   .   .\n\n  // Now we need to read the tensor slices\n  TensorSliceReaderCache cache;\n  const string filepattern = strings::StrCat(fname_base, \"_*\");\n  const TensorSliceReader* reader = cache.GetReader(\n      filepattern, open_function, TensorSliceReader::kLoadAllShards);\n  EXPECT_TRUE(reader != nullptr);\n  EXPECT_EQ(2, reader->num_files());\n\n  // We query some of the tensors\n  {\n    TensorShape shape;\n    DataType type;\n    EXPECT_TRUE(reader->HasTensor(\"test\", &shape, &type));\n    EXPECT_EQ(\"[4,5]\", shape.DebugString());\n    EXPECT_EQ(DT_FLOAT, type);\n    EXPECT_FALSE(reader->HasTensor(\"don't exist\", nullptr, nullptr));\n  }\n\n  // Make sure the reader is cached.\n  const TensorSliceReader* reader2 = cache.GetReader(\n      filepattern, open_function, TensorSliceReader::kLoadAllShards);\n  EXPECT_EQ(reader, reader2);\n\n  reader = cache.GetReader(\"file_does_not_exist\", open_function,\n                           TensorSliceReader::kLoadAllShards);\n  EXPECT_TRUE(reader == nullptr);\n}\n\nTEST(CachedTensorSliceReaderTest, SimpleFloat) {\n  CachedTensorSliceReaderTesterHelper(CreateTableTensorSliceBuilder,\n                                      OpenTableTensorSliceReader);\n}\n\nstatic void VersionTest(const VersionDef& versions, const string& error) {\n  const string path = io::JoinPath(testing::TmpDir(), \"checkpoint\");\n\n  {\n    // Prepare an empty checkpoint with some version information\n    SavedTensorSlices sts;\n    *sts.mutable_meta()->mutable_versions() = versions;\n    string contents;\n    EXPECT_TRUE(sts.SerializeToString(&contents));\n\n    // Write it to disk\n    TensorSliceWriter::Builder* builder;\n    TF_ASSERT_OK(CreateTableTensorSliceBuilder(path, &builder));\n    builder->Add(kSavedTensorSlicesKey, contents);\n    int64_t file_size;\n    TF_EXPECT_OK(builder->Finish(&file_size));\n    delete builder;\n  }\n\n  // Read it back in and verify that we get the expected error\n  TensorSliceReader reader(path, OpenTableTensorSliceReader);\n  EXPECT_TRUE(reader.status().code() == error::INVALID_ARGUMENT &&\n              absl::StartsWith(reader.status().error_message(), error))\n      << \"Expected error starting with '\" << errors::InvalidArgument(error)\n      << \"', got '\" << reader.status() << \"'\";\n}\n\nTEST(CheckpointVersionTest, MinConsumer) {\n  VersionDef versions;\n  versions.set_producer(TF_CHECKPOINT_VERSION + 1);\n  versions.set_min_consumer(TF_CHECKPOINT_VERSION + 1);\n  VersionTest(\n      versions,\n      strings::StrCat(\"Checkpoint min consumer version \",\n                      TF_CHECKPOINT_VERSION + 1, \" above current version \",\n                      TF_CHECKPOINT_VERSION, \" for TensorFlow\"));\n}\n\nTEST(CheckpointVersionTest, MinProducer) {\n  VersionDef versions;\n  versions.set_producer(TF_CHECKPOINT_VERSION_MIN_PRODUCER - 1);\n  VersionTest(versions, strings::StrCat(\"Checkpoint producer version \",\n                                        TF_CHECKPOINT_VERSION_MIN_PRODUCER - 1,\n                                        \" below min producer \",\n                                        TF_CHECKPOINT_VERSION_MIN_PRODUCER,\n                                        \" supported by TensorFlow\"));\n}\n\nTEST(CheckpointVersionTest, BadConsumer) {\n  VersionDef versions;\n  versions.set_producer(TF_CHECKPOINT_VERSION + 1);\n  versions.add_bad_consumers(TF_CHECKPOINT_VERSION);\n  VersionTest(\n      versions,\n      strings::StrCat(\n          \"Checkpoint disallows consumer version \", TF_CHECKPOINT_VERSION,\n          \".  Please upgrade TensorFlow: this version is likely buggy.\"));\n}\n\n}  // namespace\n\n}  // namespace checkpoint\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/util/saved_tensor_slice_util.h", "tensorflow/core/util/tensor_slice_reader.h", "tensorflow/core/util/tensor_slice_reader_test.cc"], "buggy_code_start_loc": [60, 183, 461], "buggy_code_end_loc": [190, 183, 461], "fixing_code_start_loc": [61, 184, 462], "fixing_code_end_loc": [217, 200, 489], "type": "CWE-190", "message": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-41203", "sourceIdentifier": "security-advisories@github.com", "published": "2021-11-05T21:15:08.613", "lastModified": "2022-10-20T21:36:57.557", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. En las versiones afectadas un atacante puede desencadenar un comportamiento indefinido, desbordamientos de enteros, segfaults y fallos de \"CHECK\" si puede cambiar los puntos de control guardados desde fuera de TensorFlow. Esto es debido a que la infraestructura de carga de los puntos de control carece de la comprobaci\u00f3n de los formatos de archivo no v\u00e1lidos. Las correcciones ser\u00e1n incluidas en TensorFlow versi\u00f3n 2.7.0. Tambi\u00e9n vamos a recoger estos commits en TensorFlow versi\u00f3n 2.6.1, TensorFlow versi\u00f3n 2.5.2, y TensorFlow versi\u00f3n 2.4.4, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda en el rango admitido"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.6}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-190"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-345"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.4.4", "matchCriteriaId": "455FB550-4C9C-4BD6-9F76-A627B62AB332"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.5.0", "versionEndExcluding": "2.5.2", "matchCriteriaId": "035CDF63-1548-4FB4-B8A9-B8D328FAF910"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.0", "versionEndExcluding": "2.6.1", "matchCriteriaId": "5D68D8D1-DB27-4395-9D3D-2BED901B852C"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/368af875869a204b4ac552b9ddda59f6a46a56ec", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/abcced051cb1bd8fb05046ac3b6023a7ebcc4578", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/b619c6f865715ca3b15ef1842b5b95edbaa710ad", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/commit/e8dc63704c88007ee4713076605c90188d66f3d2", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-7pxj-m4jf-r6h2", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/368af875869a204b4ac552b9ddda59f6a46a56ec"}}
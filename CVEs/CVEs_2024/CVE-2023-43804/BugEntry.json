{"buggy_code": ["Changes\n=======\n\n1.26.16 (2023-05-23)\n--------------------\n\n* Fixed thread-safety issue where accessing a ``PoolManager`` with many distinct origins\n  would cause connection pools to be closed while requests are in progress (`#2954 <https://github.com/urllib3/urllib3/pull/2954>`_)\n\n\n1.26.15 (2023-03-10)\n--------------------\n\n* Fix socket timeout value when ``HTTPConnection`` is reused (`#2645 <https://github.com/urllib3/urllib3/issues/2645>`__)\n* Remove \"!\" character from the unreserved characters in IPv6 Zone ID parsing\n  (`#2899 <https://github.com/urllib3/urllib3/issues/2899>`__)\n* Fix IDNA handling of '\\x80' byte (`#2901 <https://github.com/urllib3/urllib3/issues/2901>`__)\n\n1.26.14 (2023-01-11)\n--------------------\n\n* Fixed parsing of port 0 (zero) returning None, instead of 0. (`#2850 <https://github.com/urllib3/urllib3/issues/2850>`__)\n* Removed deprecated getheaders() calls in contrib module.\n\n1.26.13 (2022-11-23)\n--------------------\n\n* Deprecated the ``HTTPResponse.getheaders()`` and ``HTTPResponse.getheader()`` methods.\n* Fixed an issue where parsing a URL with leading zeroes in the port would be rejected\n  even when the port number after removing the zeroes was valid.\n* Fixed a deprecation warning when using cryptography v39.0.0.\n* Removed the ``<4`` in the ``Requires-Python`` packaging metadata field.\n\n\n1.26.12 (2022-08-22)\n--------------------\n\n* Deprecated the `urllib3[secure]` extra and the `urllib3.contrib.pyopenssl` module.\n  Both will be removed in v2.x. See this `GitHub issue <https://github.com/urllib3/urllib3/issues/2680>`_\n  for justification and info on how to migrate.\n\n\n1.26.11 (2022-07-25)\n--------------------\n\n* Fixed an issue where reading more than 2 GiB in a call to ``HTTPResponse.read`` would\n  raise an ``OverflowError`` on Python 3.9 and earlier.\n\n\n1.26.10 (2022-07-07)\n--------------------\n\n* Removed support for Python 3.5\n* Fixed an issue where a ``ProxyError`` recommending configuring the proxy as HTTP\n  instead of HTTPS could appear even when an HTTPS proxy wasn't configured.\n\n\n1.26.9 (2022-03-16)\n-------------------\n\n* Changed ``urllib3[brotli]`` extra to favor installing Brotli libraries that are still\n  receiving updates like ``brotli`` and ``brotlicffi`` instead of ``brotlipy``.\n  This change does not impact behavior of urllib3, only which dependencies are installed.\n* Fixed a socket leaking when ``HTTPSConnection.connect()`` raises an exception.\n* Fixed ``server_hostname`` being forwarded from ``PoolManager`` to ``HTTPConnectionPool``\n  when requesting an HTTP URL. Should only be forwarded when requesting an HTTPS URL.\n\n\n1.26.8 (2022-01-07)\n-------------------\n\n* Added extra message to ``urllib3.exceptions.ProxyError`` when urllib3 detects that\n  a proxy is configured to use HTTPS but the proxy itself appears to only use HTTP.\n* Added a mention of the size of the connection pool when discarding a connection due to the pool being full.\n* Added explicit support for Python 3.11.\n* Deprecated the ``Retry.MAX_BACKOFF`` class property in favor of ``Retry.DEFAULT_MAX_BACKOFF``\n  to better match the rest of the default parameter names. ``Retry.MAX_BACKOFF`` is removed in v2.0.\n* Changed location of the vendored ``ssl.match_hostname`` function from ``urllib3.packages.ssl_match_hostname``\n  to ``urllib3.util.ssl_match_hostname`` to ensure Python 3.10+ compatibility after being repackaged\n  by downstream distributors.\n* Fixed absolute imports, all imports are now relative.\n\n\n1.26.7 (2021-09-22)\n-------------------\n\n* Fixed a bug with HTTPS hostname verification involving IP addresses and lack\n  of SNI. (Issue #2400)\n* Fixed a bug where IPv6 braces weren't stripped during certificate hostname\n  matching. (Issue #2240)\n\n\n1.26.6 (2021-06-25)\n-------------------\n\n* Deprecated the ``urllib3.contrib.ntlmpool`` module. urllib3 is not able to support\n  it properly due to `reasons listed in this issue <https://github.com/urllib3/urllib3/issues/2282>`_.\n  If you are a user of this module please leave a comment.\n* Changed ``HTTPConnection.request_chunked()`` to not erroneously emit multiple\n  ``Transfer-Encoding`` headers in the case that one is already specified.\n* Fixed typo in deprecation message to recommend ``Retry.DEFAULT_ALLOWED_METHODS``.\n\n\n1.26.5 (2021-05-26)\n-------------------\n\n* Fixed deprecation warnings emitted in Python 3.10.\n* Updated vendored ``six`` library to 1.16.0.\n* Improved performance of URL parser when splitting\n  the authority component.\n\n\n1.26.4 (2021-03-15)\n-------------------\n\n* Changed behavior of the default ``SSLContext`` when connecting to HTTPS proxy\n  during HTTPS requests. The default ``SSLContext`` now sets ``check_hostname=True``.\n\n\n1.26.3 (2021-01-26)\n-------------------\n\n* Fixed bytes and string comparison issue with headers (Pull #2141)\n\n* Changed ``ProxySchemeUnknown`` error message to be\n  more actionable if the user supplies a proxy URL without\n  a scheme. (Pull #2107)\n\n\n1.26.2 (2020-11-12)\n-------------------\n\n* Fixed an issue where ``wrap_socket`` and ``CERT_REQUIRED`` wouldn't\n  be imported properly on Python 2.7.8 and earlier (Pull #2052)\n\n\n1.26.1 (2020-11-11)\n-------------------\n\n* Fixed an issue where two ``User-Agent`` headers would be sent if a\n  ``User-Agent`` header key is passed as ``bytes`` (Pull #2047)\n\n\n1.26.0 (2020-11-10)\n-------------------\n\n* **NOTE: urllib3 v2.0 will drop support for Python 2**.\n  `Read more in the v2.0 Roadmap <https://urllib3.readthedocs.io/en/latest/v2-roadmap.html>`_.\n\n* Added support for HTTPS proxies contacting HTTPS servers (Pull #1923, Pull #1806)\n\n* Deprecated negotiating TLSv1 and TLSv1.1 by default. Users that\n  still wish to use TLS earlier than 1.2 without a deprecation warning\n  should opt-in explicitly by setting ``ssl_version=ssl.PROTOCOL_TLSv1_1`` (Pull #2002)\n  **Starting in urllib3 v2.0: Connections that receive a ``DeprecationWarning`` will fail**\n\n* Deprecated ``Retry`` options ``Retry.DEFAULT_METHOD_WHITELIST``, ``Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST``\n  and ``Retry(method_whitelist=...)`` in favor of ``Retry.DEFAULT_ALLOWED_METHODS``,\n  ``Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT``, and ``Retry(allowed_methods=...)``\n  (Pull #2000) **Starting in urllib3 v2.0: Deprecated options will be removed**\n\n* Added default ``User-Agent`` header to every request (Pull #1750)\n\n* Added ``urllib3.util.SKIP_HEADER`` for skipping ``User-Agent``, ``Accept-Encoding``, \n  and ``Host`` headers from being automatically emitted with requests (Pull #2018)\n\n* Collapse ``transfer-encoding: chunked`` request data and framing into\n  the same ``socket.send()`` call (Pull #1906)\n\n* Send ``http/1.1`` ALPN identifier with every TLS handshake by default (Pull #1894)\n\n* Properly terminate SecureTransport connections when CA verification fails (Pull #1977)\n\n* Don't emit an ``SNIMissingWarning`` when passing ``server_hostname=None``\n  to SecureTransport (Pull #1903)\n\n* Disabled requesting TLSv1.2 session tickets as they weren't being used by urllib3 (Pull #1970)\n\n* Suppress ``BrokenPipeError`` when writing request body after the server\n  has closed the socket (Pull #1524)\n\n* Wrap ``ssl.SSLError`` that can be raised from reading a socket (e.g. \"bad MAC\")\n  into an ``urllib3.exceptions.SSLError`` (Pull #1939)\n\n\n1.25.11 (2020-10-19)\n--------------------\n\n* Fix retry backoff time parsed from ``Retry-After`` header when given\n  in the HTTP date format. The HTTP date was parsed as the local timezone\n  rather than accounting for the timezone in the HTTP date (typically\n  UTC) (Pull #1932, Pull #1935, Pull #1938, Pull #1949)\n\n* Fix issue where an error would be raised when the ``SSLKEYLOGFILE``\n  environment variable was set to the empty string. Now ``SSLContext.keylog_file``\n  is not set in this situation (Pull #2016)\n\n\n1.25.10 (2020-07-22)\n--------------------\n\n* Added support for ``SSLKEYLOGFILE`` environment variable for\n  logging TLS session keys with use with programs like\n  Wireshark for decrypting captured web traffic (Pull #1867)\n\n* Fixed loading of SecureTransport libraries on macOS Big Sur\n  due to the new dynamic linker cache (Pull #1905)\n\n* Collapse chunked request bodies data and framing into one\n  call to ``send()`` to reduce the number of TCP packets by 2-4x (Pull #1906)\n\n* Don't insert ``None`` into ``ConnectionPool`` if the pool\n  was empty when requesting a connection (Pull #1866)\n\n* Avoid ``hasattr`` call in ``BrotliDecoder.decompress()`` (Pull #1858)\n\n\n1.25.9 (2020-04-16)\n-------------------\n\n* Added ``InvalidProxyConfigurationWarning`` which is raised when\n  erroneously specifying an HTTPS proxy URL. urllib3 doesn't currently\n  support connecting to HTTPS proxies but will soon be able to\n  and we would like users to migrate properly without much breakage.\n\n  See `this GitHub issue <https://github.com/urllib3/urllib3/issues/1850>`_\n  for more information on how to fix your proxy config. (Pull #1851)\n\n* Drain connection after ``PoolManager`` redirect (Pull #1817)\n\n* Ensure ``load_verify_locations`` raises ``SSLError`` for all backends (Pull #1812)\n\n* Rename ``VerifiedHTTPSConnection`` to ``HTTPSConnection`` (Pull #1805)\n\n* Allow the CA certificate data to be passed as a string (Pull #1804)\n\n* Raise ``ValueError`` if method contains control characters (Pull #1800)\n\n* Add ``__repr__`` to ``Timeout`` (Pull #1795)\n\n\n1.25.8 (2020-01-20)\n-------------------\n\n* Drop support for EOL Python 3.4 (Pull #1774)\n\n* Optimize _encode_invalid_chars (Pull #1787)\n\n\n1.25.7 (2019-11-11)\n-------------------\n\n* Preserve ``chunked`` parameter on retries (Pull #1715, Pull #1734)\n\n* Allow unset ``SERVER_SOFTWARE`` in App Engine (Pull #1704, Issue #1470)\n\n* Fix issue where URL fragment was sent within the request target. (Pull #1732)\n\n* Fix issue where an empty query section in a URL would fail to parse. (Pull #1732)\n\n* Remove TLS 1.3 support in SecureTransport due to Apple removing support (Pull #1703)\n\n\n1.25.6 (2019-09-24)\n-------------------\n\n* Fix issue where tilde (``~``) characters were incorrectly\n  percent-encoded in the path. (Pull #1692)\n\n\n1.25.5 (2019-09-19)\n-------------------\n\n* Add mitigation for BPO-37428 affecting Python <3.7.4 and OpenSSL 1.1.1+ which\n  caused certificate verification to be enabled when using ``cert_reqs=CERT_NONE``.\n  (Issue #1682)\n\n\n1.25.4 (2019-09-19)\n-------------------\n\n* Propagate Retry-After header settings to subsequent retries. (Pull #1607)\n\n* Fix edge case where Retry-After header was still respected even when\n  explicitly opted out of. (Pull #1607)\n\n* Remove dependency on ``rfc3986`` for URL parsing.\n\n* Fix issue where URLs containing invalid characters within ``Url.auth`` would\n  raise an exception instead of percent-encoding those characters.\n\n* Add support for ``HTTPResponse.auto_close = False`` which makes HTTP responses\n  work well with BufferedReaders and other ``io`` module features. (Pull #1652)\n\n* Percent-encode invalid characters in URL for ``HTTPConnectionPool.request()`` (Pull #1673)\n\n\n1.25.3 (2019-05-23)\n-------------------\n\n* Change ``HTTPSConnection`` to load system CA certificates\n  when ``ca_certs``, ``ca_cert_dir``, and ``ssl_context`` are\n  unspecified. (Pull #1608, Issue #1603)\n\n* Upgrade bundled rfc3986 to v1.3.2. (Pull #1609, Issue #1605)\n\n\n1.25.2 (2019-04-28)\n-------------------\n\n* Change ``is_ipaddress`` to not detect IPvFuture addresses. (Pull #1583)\n\n* Change ``parse_url`` to percent-encode invalid characters within the\n  path, query, and target components. (Pull #1586)\n\n\n1.25.1 (2019-04-24)\n-------------------\n\n* Add support for Google's ``Brotli`` package. (Pull #1572, Pull #1579)\n\n* Upgrade bundled rfc3986 to v1.3.1 (Pull #1578)\n\n\n1.25 (2019-04-22)\n-----------------\n\n* Require and validate certificates by default when using HTTPS (Pull #1507)\n\n* Upgraded ``urllib3.utils.parse_url()`` to be RFC 3986 compliant. (Pull #1487)\n\n* Added support for ``key_password`` for ``HTTPSConnectionPool`` to use\n  encrypted ``key_file`` without creating your own ``SSLContext`` object. (Pull #1489)\n\n* Add TLSv1.3 support to CPython, pyOpenSSL, and SecureTransport ``SSLContext``\n  implementations. (Pull #1496)\n\n* Switched the default multipart header encoder from RFC 2231 to HTML 5 working draft. (Issue #303, Pull #1492)\n\n* Fixed issue where OpenSSL would block if an encrypted client private key was\n  given and no password was given. Instead an ``SSLError`` is raised. (Pull #1489)\n\n* Added support for Brotli content encoding. It is enabled automatically if\n  ``brotlipy`` package is installed which can be requested with\n  ``urllib3[brotli]`` extra. (Pull #1532)\n\n* Drop ciphers using DSS key exchange from default TLS cipher suites.\n  Improve default ciphers when using SecureTransport. (Pull #1496)\n\n* Implemented a more efficient ``HTTPResponse.__iter__()`` method. (Issue #1483)\n\n1.24.3 (2019-05-01)\n-------------------\n\n* Apply fix for CVE-2019-9740. (Pull #1591)\n\n1.24.2 (2019-04-17)\n-------------------\n\n* Don't load system certificates by default when any other ``ca_certs``, ``ca_certs_dir`` or\n  ``ssl_context`` parameters are specified.\n\n* Remove Authorization header regardless of case when redirecting to cross-site. (Issue #1510)\n\n* Add support for IPv6 addresses in subjectAltName section of certificates. (Issue #1269)\n\n\n1.24.1 (2018-11-02)\n-------------------\n\n* Remove quadratic behavior within ``GzipDecoder.decompress()`` (Issue #1467)\n\n* Restored functionality of ``ciphers`` parameter for ``create_urllib3_context()``. (Issue #1462)\n\n\n1.24 (2018-10-16)\n-----------------\n\n* Allow key_server_hostname to be specified when initializing a PoolManager to allow custom SNI to be overridden. (Pull #1449)\n\n* Test against Python 3.7 on AppVeyor. (Pull #1453)\n\n* Early-out ipv6 checks when running on App Engine. (Pull #1450)\n\n* Change ambiguous description of backoff_factor (Pull #1436)\n\n* Add ability to handle multiple Content-Encodings (Issue #1441 and Pull #1442)\n\n* Skip DNS names that can't be idna-decoded when using pyOpenSSL (Issue #1405).\n\n* Add a server_hostname parameter to HTTPSConnection which allows for\n  overriding the SNI hostname sent in the handshake. (Pull #1397)\n\n* Drop support for EOL Python 2.6 (Pull #1429 and Pull #1430)\n\n* Fixed bug where responses with header Content-Type: message/* erroneously\n  raised HeaderParsingError, resulting in a warning being logged. (Pull #1439)\n\n* Move urllib3 to src/urllib3 (Pull #1409)\n\n\n1.23 (2018-06-04)\n-----------------\n\n* Allow providing a list of headers to strip from requests when redirecting\n  to a different host. Defaults to the ``Authorization`` header. Different\n  headers can be set via ``Retry.remove_headers_on_redirect``. (Issue #1316)\n\n* Fix ``util.selectors._fileobj_to_fd`` to accept ``long`` (Issue #1247).\n\n* Dropped Python 3.3 support. (Pull #1242)\n\n* Put the connection back in the pool when calling stream() or read_chunked() on\n  a chunked HEAD response. (Issue #1234)\n\n* Fixed pyOpenSSL-specific ssl client authentication issue when clients\n  attempted to auth via certificate + chain (Issue #1060)\n\n* Add the port to the connectionpool connect print (Pull #1251)\n\n* Don't use the ``uuid`` module to create multipart data boundaries. (Pull #1380)\n\n* ``read_chunked()`` on a closed response returns no chunks. (Issue #1088)\n\n* Add Python 2.6 support to ``contrib.securetransport`` (Pull #1359)\n\n* Added support for auth info in url for SOCKS proxy (Pull #1363)\n\n\n1.22 (2017-07-20)\n-----------------\n\n* Fixed missing brackets in ``HTTP CONNECT`` when connecting to IPv6 address via\n  IPv6 proxy. (Issue #1222)\n\n* Made the connection pool retry on ``SSLError``.  The original ``SSLError``\n  is available on ``MaxRetryError.reason``. (Issue #1112)\n\n* Drain and release connection before recursing on retry/redirect.  Fixes\n  deadlocks with a blocking connectionpool. (Issue #1167)\n\n* Fixed compatibility for cookiejar. (Issue #1229)\n\n* pyopenssl: Use vendored version of ``six``. (Issue #1231)\n\n\n1.21.1 (2017-05-02)\n-------------------\n\n* Fixed SecureTransport issue that would cause long delays in response body\n  delivery. (Pull #1154)\n\n* Fixed regression in 1.21 that threw exceptions when users passed the\n  ``socket_options`` flag to the ``PoolManager``.  (Issue #1165)\n\n* Fixed regression in 1.21 that threw exceptions when users passed the\n  ``assert_hostname`` or ``assert_fingerprint`` flag to the ``PoolManager``.\n  (Pull #1157)\n\n\n1.21 (2017-04-25)\n-----------------\n\n* Improved performance of certain selector system calls on Python 3.5 and\n  later. (Pull #1095)\n\n* Resolved issue where the PyOpenSSL backend would not wrap SysCallError\n  exceptions appropriately when sending data. (Pull #1125)\n\n* Selectors now detects a monkey-patched select module after import for modules\n  that patch the select module like eventlet, greenlet. (Pull #1128)\n\n* Reduced memory consumption when streaming zlib-compressed responses\n  (as opposed to raw deflate streams). (Pull #1129)\n\n* Connection pools now use the entire request context when constructing the\n  pool key. (Pull #1016)\n\n* ``PoolManager.connection_from_*`` methods now accept a new keyword argument,\n  ``pool_kwargs``, which are merged with the existing ``connection_pool_kw``.\n  (Pull #1016)\n\n* Add retry counter for ``status_forcelist``. (Issue #1147)\n\n* Added ``contrib`` module for using SecureTransport on macOS:\n  ``urllib3.contrib.securetransport``.  (Pull #1122)\n\n* urllib3 now only normalizes the case of ``http://`` and ``https://`` schemes:\n  for schemes it does not recognise, it assumes they are case-sensitive and\n  leaves them unchanged.\n  (Issue #1080)\n\n\n1.20 (2017-01-19)\n-----------------\n\n* Added support for waiting for I/O using selectors other than select,\n  improving urllib3's behaviour with large numbers of concurrent connections.\n  (Pull #1001)\n\n* Updated the date for the system clock check. (Issue #1005)\n\n* ConnectionPools now correctly consider hostnames to be case-insensitive.\n  (Issue #1032)\n\n* Outdated versions of PyOpenSSL now cause the PyOpenSSL contrib module\n  to fail when it is injected, rather than at first use. (Pull #1063)\n\n* Outdated versions of cryptography now cause the PyOpenSSL contrib module\n  to fail when it is injected, rather than at first use. (Issue #1044)\n\n* Automatically attempt to rewind a file-like body object when a request is\n  retried or redirected. (Pull #1039)\n\n* Fix some bugs that occur when modules incautiously patch the queue module.\n  (Pull #1061)\n\n* Prevent retries from occurring on read timeouts for which the request method\n  was not in the method whitelist. (Issue #1059)\n\n* Changed the PyOpenSSL contrib module to lazily load idna to avoid\n  unnecessarily bloating the memory of programs that don't need it. (Pull\n  #1076)\n\n* Add support for IPv6 literals with zone identifiers. (Pull #1013)\n\n* Added support for socks5h:// and socks4a:// schemes when working with SOCKS\n  proxies, and controlled remote DNS appropriately. (Issue #1035)\n\n\n1.19.1 (2016-11-16)\n-------------------\n\n* Fixed AppEngine import that didn't function on Python 3.5. (Pull #1025)\n\n\n1.19 (2016-11-03)\n-----------------\n\n* urllib3 now respects Retry-After headers on 413, 429, and 503 responses when\n  using the default retry logic. (Pull #955)\n\n* Remove markers from setup.py to assist ancient setuptools versions. (Issue\n  #986)\n\n* Disallow superscripts and other integerish things in URL ports. (Issue #989)\n\n* Allow urllib3's HTTPResponse.stream() method to continue to work with\n  non-httplib underlying FPs. (Pull #990)\n\n* Empty filenames in multipart headers are now emitted as such, rather than\n  being suppressed. (Issue #1015)\n\n* Prefer user-supplied Host headers on chunked uploads. (Issue #1009)\n\n\n1.18.1 (2016-10-27)\n-------------------\n\n* CVE-2016-9015. Users who are using urllib3 version 1.17 or 1.18 along with\n  PyOpenSSL injection and OpenSSL 1.1.0 *must* upgrade to this version. This\n  release fixes a vulnerability whereby urllib3 in the above configuration\n  would silently fail to validate TLS certificates due to erroneously setting\n  invalid flags in OpenSSL's ``SSL_CTX_set_verify`` function. These erroneous\n  flags do not cause a problem in OpenSSL versions before 1.1.0, which\n  interprets the presence of any flag as requesting certificate validation.\n\n  There is no PR for this patch, as it was prepared for simultaneous disclosure\n  and release. The master branch received the same fix in Pull #1010.\n\n\n1.18 (2016-09-26)\n-----------------\n\n* Fixed incorrect message for IncompleteRead exception. (Pull #973)\n\n* Accept ``iPAddress`` subject alternative name fields in TLS certificates.\n  (Issue #258)\n\n* Fixed consistency of ``HTTPResponse.closed`` between Python 2 and 3.\n  (Issue #977)\n\n* Fixed handling of wildcard certificates when using PyOpenSSL. (Issue #979)\n\n\n1.17 (2016-09-06)\n-----------------\n\n* Accept ``SSLContext`` objects for use in SSL/TLS negotiation. (Issue #835)\n\n* ConnectionPool debug log now includes scheme, host, and port. (Issue #897)\n\n* Substantially refactored documentation. (Issue #887)\n\n* Used URLFetch default timeout on AppEngine, rather than hardcoding our own.\n  (Issue #858)\n\n* Normalize the scheme and host in the URL parser (Issue #833)\n\n* ``HTTPResponse`` contains the last ``Retry`` object, which now also\n  contains retries history. (Issue #848)\n\n* Timeout can no longer be set as boolean, and must be greater than zero.\n  (Pull #924)\n\n* Removed pyasn1 and ndg-httpsclient from dependencies used for PyOpenSSL. We\n  now use cryptography and idna, both of which are already dependencies of\n  PyOpenSSL. (Pull #930)\n\n* Fixed infinite loop in ``stream`` when amt=None. (Issue #928)\n\n* Try to use the operating system's certificates when we are using an\n  ``SSLContext``. (Pull #941)\n\n* Updated cipher suite list to allow ChaCha20+Poly1305. AES-GCM is preferred to\n  ChaCha20, but ChaCha20 is then preferred to everything else. (Pull #947)\n\n* Updated cipher suite list to remove 3DES-based cipher suites. (Pull #958)\n\n* Removed the cipher suite fallback to allow HIGH ciphers. (Pull #958)\n\n* Implemented ``length_remaining`` to determine remaining content\n  to be read. (Pull #949)\n\n* Implemented ``enforce_content_length`` to enable exceptions when\n  incomplete data chunks are received. (Pull #949)\n\n* Dropped connection start, dropped connection reset, redirect, forced retry,\n  and new HTTPS connection log levels to DEBUG, from INFO. (Pull #967)\n\n\n1.16 (2016-06-11)\n-----------------\n\n* Disable IPv6 DNS when IPv6 connections are not possible. (Issue #840)\n\n* Provide ``key_fn_by_scheme`` pool keying mechanism that can be\n  overridden. (Issue #830)\n\n* Normalize scheme and host to lowercase for pool keys, and include\n  ``source_address``. (Issue #830)\n\n* Cleaner exception chain in Python 3 for ``_make_request``.\n  (Issue #861)\n\n* Fixed installing ``urllib3[socks]`` extra. (Issue #864)\n\n* Fixed signature of ``ConnectionPool.close`` so it can actually safely be\n  called by subclasses. (Issue #873)\n\n* Retain ``release_conn`` state across retries. (Issues #651, #866)\n\n* Add customizable ``HTTPConnectionPool.ResponseCls``, which defaults to\n  ``HTTPResponse`` but can be replaced with a subclass. (Issue #879)\n\n\n1.15.1 (2016-04-11)\n-------------------\n\n* Fix packaging to include backports module. (Issue #841)\n\n\n1.15 (2016-04-06)\n-----------------\n\n* Added Retry(raise_on_status=False). (Issue #720)\n\n* Always use setuptools, no more distutils fallback. (Issue #785)\n\n* Dropped support for Python 3.2. (Issue #786)\n\n* Chunked transfer encoding when requesting with ``chunked=True``.\n  (Issue #790)\n\n* Fixed regression with IPv6 port parsing. (Issue #801)\n\n* Append SNIMissingWarning messages to allow users to specify it in\n  the PYTHONWARNINGS environment variable. (Issue #816)\n\n* Handle unicode headers in Py2. (Issue #818)\n\n* Log certificate when there is a hostname mismatch. (Issue #820)\n\n* Preserve order of request/response headers. (Issue #821)\n\n\n1.14 (2015-12-29)\n-----------------\n\n* contrib: SOCKS proxy support! (Issue #762)\n\n* Fixed AppEngine handling of transfer-encoding header and bug\n  in Timeout defaults checking. (Issue #763)\n\n\n1.13.1 (2015-12-18)\n-------------------\n\n* Fixed regression in IPv6 + SSL for match_hostname. (Issue #761)\n\n\n1.13 (2015-12-14)\n-----------------\n\n* Fixed ``pip install urllib3[secure]`` on modern pip. (Issue #706)\n\n* pyopenssl: Fixed SSL3_WRITE_PENDING error. (Issue #717)\n\n* pyopenssl: Support for TLSv1.1 and TLSv1.2. (Issue #696)\n\n* Close connections more defensively on exception. (Issue #734)\n\n* Adjusted ``read_chunked`` to handle gzipped, chunk-encoded bodies without\n  repeatedly flushing the decoder, to function better on Jython. (Issue #743)\n\n* Accept ``ca_cert_dir`` for SSL-related PoolManager configuration. (Issue #758)\n\n\n1.12 (2015-09-03)\n-----------------\n\n* Rely on ``six`` for importing ``httplib`` to work around\n  conflicts with other Python 3 shims. (Issue #688)\n\n* Add support for directories of certificate authorities, as supported by\n  OpenSSL. (Issue #701)\n\n* New exception: ``NewConnectionError``, raised when we fail to establish\n  a new connection, usually ``ECONNREFUSED`` socket error.\n\n\n1.11 (2015-07-21)\n-----------------\n\n* When ``ca_certs`` is given, ``cert_reqs`` defaults to\n  ``'CERT_REQUIRED'``. (Issue #650)\n\n* ``pip install urllib3[secure]`` will install Certifi and\n  PyOpenSSL as dependencies. (Issue #678)\n\n* Made ``HTTPHeaderDict`` usable as a ``headers`` input value\n  (Issues #632, #679)\n\n* Added `urllib3.contrib.appengine <https://urllib3.readthedocs.io/en/latest/contrib.html#google-app-engine>`_\n  which has an ``AppEngineManager`` for using ``URLFetch`` in a\n  Google AppEngine environment. (Issue #664)\n\n* Dev: Added test suite for AppEngine. (Issue #631)\n\n* Fix performance regression when using PyOpenSSL. (Issue #626)\n\n* Passing incorrect scheme (e.g. ``foo://``) will raise\n  ``ValueError`` instead of ``AssertionError`` (backwards\n  compatible for now, but please migrate). (Issue #640)\n\n* Fix pools not getting replenished when an error occurs during a\n  request using ``release_conn=False``. (Issue #644)\n\n* Fix pool-default headers not applying for url-encoded requests\n  like GET. (Issue #657)\n\n* log.warning in Python 3 when headers are skipped due to parsing\n  errors. (Issue #642)\n\n* Close and discard connections if an error occurs during read.\n  (Issue #660)\n\n* Fix host parsing for IPv6 proxies. (Issue #668)\n\n* Separate warning type SubjectAltNameWarning, now issued once\n  per host. (Issue #671)\n\n* Fix ``httplib.IncompleteRead`` not getting converted to\n  ``ProtocolError`` when using ``HTTPResponse.stream()``\n  (Issue #674)\n\n1.10.4 (2015-05-03)\n-------------------\n\n* Migrate tests to Tornado 4. (Issue #594)\n\n* Append default warning configuration rather than overwrite.\n  (Issue #603)\n\n* Fix streaming decoding regression. (Issue #595)\n\n* Fix chunked requests losing state across keep-alive connections.\n  (Issue #599)\n\n* Fix hanging when chunked HEAD response has no body. (Issue #605)\n\n\n1.10.3 (2015-04-21)\n-------------------\n\n* Emit ``InsecurePlatformWarning`` when SSLContext object is missing.\n  (Issue #558)\n\n* Fix regression of duplicate header keys being discarded.\n  (Issue #563)\n\n* ``Response.stream()`` returns a generator for chunked responses.\n  (Issue #560)\n\n* Set upper-bound timeout when waiting for a socket in PyOpenSSL.\n  (Issue #585)\n\n* Work on platforms without `ssl` module for plain HTTP requests.\n  (Issue #587)\n\n* Stop relying on the stdlib's default cipher list. (Issue #588)\n\n\n1.10.2 (2015-02-25)\n-------------------\n\n* Fix file descriptor leakage on retries. (Issue #548)\n\n* Removed RC4 from default cipher list. (Issue #551)\n\n* Header performance improvements. (Issue #544)\n\n* Fix PoolManager not obeying redirect retry settings. (Issue #553)\n\n\n1.10.1 (2015-02-10)\n-------------------\n\n* Pools can be used as context managers. (Issue #545)\n\n* Don't re-use connections which experienced an SSLError. (Issue #529)\n\n* Don't fail when gzip decoding an empty stream. (Issue #535)\n\n* Add sha256 support for fingerprint verification. (Issue #540)\n\n* Fixed handling of header values containing commas. (Issue #533)\n\n\n1.10 (2014-12-14)\n-----------------\n\n* Disabled SSLv3. (Issue #473)\n\n* Add ``Url.url`` property to return the composed url string. (Issue #394)\n\n* Fixed PyOpenSSL + gevent ``WantWriteError``. (Issue #412)\n\n* ``MaxRetryError.reason`` will always be an exception, not string.\n  (Issue #481)\n\n* Fixed SSL-related timeouts not being detected as timeouts. (Issue #492)\n\n* Py3: Use ``ssl.create_default_context()`` when available. (Issue #473)\n\n* Emit ``InsecureRequestWarning`` for *every* insecure HTTPS request.\n  (Issue #496)\n\n* Emit ``SecurityWarning`` when certificate has no ``subjectAltName``.\n  (Issue #499)\n\n* Close and discard sockets which experienced SSL-related errors.\n  (Issue #501)\n\n* Handle ``body`` param in ``.request(...)``. (Issue #513)\n\n* Respect timeout with HTTPS proxy. (Issue #505)\n\n* PyOpenSSL: Handle ZeroReturnError exception. (Issue #520)\n\n\n1.9.1 (2014-09-13)\n------------------\n\n* Apply socket arguments before binding. (Issue #427)\n\n* More careful checks if fp-like object is closed. (Issue #435)\n\n* Fixed packaging issues of some development-related files not\n  getting included. (Issue #440)\n\n* Allow performing *only* fingerprint verification. (Issue #444)\n\n* Emit ``SecurityWarning`` if system clock is waaay off. (Issue #445)\n\n* Fixed PyOpenSSL compatibility with PyPy. (Issue #450)\n\n* Fixed ``BrokenPipeError`` and ``ConnectionError`` handling in Py3.\n  (Issue #443)\n\n\n\n1.9 (2014-07-04)\n----------------\n\n* Shuffled around development-related files. If you're maintaining a distro\n  package of urllib3, you may need to tweak things. (Issue #415)\n\n* Unverified HTTPS requests will trigger a warning on the first request. See\n  our new `security documentation\n  <https://urllib3.readthedocs.io/en/latest/security.html>`_ for details.\n  (Issue #426)\n\n* New retry logic and ``urllib3.util.retry.Retry`` configuration object.\n  (Issue #326)\n\n* All raised exceptions should now wrapped in a\n  ``urllib3.exceptions.HTTPException``-extending exception. (Issue #326)\n\n* All errors during a retry-enabled request should be wrapped in\n  ``urllib3.exceptions.MaxRetryError``, including timeout-related exceptions\n  which were previously exempt. Underlying error is accessible from the\n  ``.reason`` property. (Issue #326)\n\n* ``urllib3.exceptions.ConnectionError`` renamed to\n  ``urllib3.exceptions.ProtocolError``. (Issue #326)\n\n* Errors during response read (such as IncompleteRead) are now wrapped in\n  ``urllib3.exceptions.ProtocolError``. (Issue #418)\n\n* Requesting an empty host will raise ``urllib3.exceptions.LocationValueError``.\n  (Issue #417)\n\n* Catch read timeouts over SSL connections as\n  ``urllib3.exceptions.ReadTimeoutError``. (Issue #419)\n\n* Apply socket arguments before connecting. (Issue #427)\n\n\n1.8.3 (2014-06-23)\n------------------\n\n* Fix TLS verification when using a proxy in Python 3.4.1. (Issue #385)\n\n* Add ``disable_cache`` option to ``urllib3.util.make_headers``. (Issue #393)\n\n* Wrap ``socket.timeout`` exception with\n  ``urllib3.exceptions.ReadTimeoutError``. (Issue #399)\n\n* Fixed proxy-related bug where connections were being reused incorrectly.\n  (Issues #366, #369)\n\n* Added ``socket_options`` keyword parameter which allows to define\n  ``setsockopt`` configuration of new sockets. (Issue #397)\n\n* Removed ``HTTPConnection.tcp_nodelay`` in favor of\n  ``HTTPConnection.default_socket_options``. (Issue #397)\n\n* Fixed ``TypeError`` bug in Python 2.6.4. (Issue #411)\n\n\n1.8.2 (2014-04-17)\n------------------\n\n* Fix ``urllib3.util`` not being included in the package.\n\n\n1.8.1 (2014-04-17)\n------------------\n\n* Fix AppEngine bug of HTTPS requests going out as HTTP. (Issue #356)\n\n* Don't install ``dummyserver`` into ``site-packages`` as it's only needed\n  for the test suite. (Issue #362)\n\n* Added support for specifying ``source_address``. (Issue #352)\n\n\n1.8 (2014-03-04)\n----------------\n\n* Improved url parsing in ``urllib3.util.parse_url`` (properly parse '@' in\n  username, and blank ports like 'hostname:').\n\n* New ``urllib3.connection`` module which contains all the HTTPConnection\n  objects.\n\n* Several ``urllib3.util.Timeout``-related fixes. Also changed constructor\n  signature to a more sensible order. [Backwards incompatible]\n  (Issues #252, #262, #263)\n\n* Use ``backports.ssl_match_hostname`` if it's installed. (Issue #274)\n\n* Added ``.tell()`` method to ``urllib3.response.HTTPResponse`` which\n  returns the number of bytes read so far. (Issue #277)\n\n* Support for platforms without threading. (Issue #289)\n\n* Expand default-port comparison in ``HTTPConnectionPool.is_same_host``\n  to allow a pool with no specified port to be considered equal to to an\n  HTTP/HTTPS url with port 80/443 explicitly provided. (Issue #305)\n\n* Improved default SSL/TLS settings to avoid vulnerabilities.\n  (Issue #309)\n\n* Fixed ``urllib3.poolmanager.ProxyManager`` not retrying on connect errors.\n  (Issue #310)\n\n* Disable Nagle's Algorithm on the socket for non-proxies. A subset of requests\n  will send the entire HTTP request ~200 milliseconds faster; however, some of\n  the resulting TCP packets will be smaller. (Issue #254)\n\n* Increased maximum number of SubjectAltNames in ``urllib3.contrib.pyopenssl``\n  from the default 64 to 1024 in a single certificate. (Issue #318)\n\n* Headers are now passed and stored as a custom\n  ``urllib3.collections_.HTTPHeaderDict`` object rather than a plain ``dict``.\n  (Issue #329, #333)\n\n* Headers no longer lose their case on Python 3. (Issue #236)\n\n* ``urllib3.contrib.pyopenssl`` now uses the operating system's default CA\n  certificates on inject. (Issue #332)\n\n* Requests with ``retries=False`` will immediately raise any exceptions without\n  wrapping them in ``MaxRetryError``. (Issue #348)\n\n* Fixed open socket leak with SSL-related failures. (Issue #344, #348)\n\n\n1.7.1 (2013-09-25)\n------------------\n\n* Added granular timeout support with new ``urllib3.util.Timeout`` class.\n  (Issue #231)\n\n* Fixed Python 3.4 support. (Issue #238)\n\n\n1.7 (2013-08-14)\n----------------\n\n* More exceptions are now pickle-able, with tests. (Issue #174)\n\n* Fixed redirecting with relative URLs in Location header. (Issue #178)\n\n* Support for relative urls in ``Location: ...`` header. (Issue #179)\n\n* ``urllib3.response.HTTPResponse`` now inherits from ``io.IOBase`` for bonus\n  file-like functionality. (Issue #187)\n\n* Passing ``assert_hostname=False`` when creating a HTTPSConnectionPool will\n  skip hostname verification for SSL connections. (Issue #194)\n\n* New method ``urllib3.response.HTTPResponse.stream(...)`` which acts as a\n  generator wrapped around ``.read(...)``. (Issue #198)\n\n* IPv6 url parsing enforces brackets around the hostname. (Issue #199)\n\n* Fixed thread race condition in\n  ``urllib3.poolmanager.PoolManager.connection_from_host(...)`` (Issue #204)\n\n* ``ProxyManager`` requests now include non-default port in ``Host: ...``\n  header. (Issue #217)\n\n* Added HTTPS proxy support in ``ProxyManager``. (Issue #170 #139)\n\n* New ``RequestField`` object can be passed to the ``fields=...`` param which\n  can specify headers. (Issue #220)\n\n* Raise ``urllib3.exceptions.ProxyError`` when connecting to proxy fails.\n  (Issue #221)\n\n* Use international headers when posting file names. (Issue #119)\n\n* Improved IPv6 support. (Issue #203)\n\n\n1.6 (2013-04-25)\n----------------\n\n* Contrib: Optional SNI support for Py2 using PyOpenSSL. (Issue #156)\n\n* ``ProxyManager`` automatically adds ``Host: ...`` header if not given.\n\n* Improved SSL-related code. ``cert_req`` now optionally takes a string like\n  \"REQUIRED\" or \"NONE\". Same with ``ssl_version`` takes strings like \"SSLv23\"\n  The string values reflect the suffix of the respective constant variable.\n  (Issue #130)\n\n* Vendored ``socksipy`` now based on Anorov's fork which handles unexpectedly\n  closed proxy connections and larger read buffers. (Issue #135)\n\n* Ensure the connection is closed if no data is received, fixes connection leak\n  on some platforms. (Issue #133)\n\n* Added SNI support for SSL/TLS connections on Py32+. (Issue #89)\n\n* Tests fixed to be compatible with Py26 again. (Issue #125)\n\n* Added ability to choose SSL version by passing an ``ssl.PROTOCOL_*`` constant\n  to the ``ssl_version`` parameter of ``HTTPSConnectionPool``. (Issue #109)\n\n* Allow an explicit content type to be specified when encoding file fields.\n  (Issue #126)\n\n* Exceptions are now pickleable, with tests. (Issue #101)\n\n* Fixed default headers not getting passed in some cases. (Issue #99)\n\n* Treat \"content-encoding\" header value as case-insensitive, per RFC 2616\n  Section 3.5. (Issue #110)\n\n* \"Connection Refused\" SocketErrors will get retried rather than raised.\n  (Issue #92)\n\n* Updated vendored ``six``, no longer overrides the global ``six`` module\n  namespace. (Issue #113)\n\n* ``urllib3.exceptions.MaxRetryError`` contains a ``reason`` property holding\n  the exception that prompted the final retry. If ``reason is None`` then it\n  was due to a redirect. (Issue #92, #114)\n\n* Fixed ``PoolManager.urlopen()`` from not redirecting more than once.\n  (Issue #149)\n\n* Don't assume ``Content-Type: text/plain`` for multi-part encoding parameters\n  that are not files. (Issue #111)\n\n* Pass `strict` param down to ``httplib.HTTPConnection``. (Issue #122)\n\n* Added mechanism to verify SSL certificates by fingerprint (md5, sha1) or\n  against an arbitrary hostname (when connecting by IP or for misconfigured\n  servers). (Issue #140)\n\n* Streaming decompression support. (Issue #159)\n\n\n1.5 (2012-08-02)\n----------------\n\n* Added ``urllib3.add_stderr_logger()`` for quickly enabling STDERR debug\n  logging in urllib3.\n\n* Native full URL parsing (including auth, path, query, fragment) available in\n  ``urllib3.util.parse_url(url)``.\n\n* Built-in redirect will switch method to 'GET' if status code is 303.\n  (Issue #11)\n\n* ``urllib3.PoolManager`` strips the scheme and host before sending the request\n  uri. (Issue #8)\n\n* New ``urllib3.exceptions.DecodeError`` exception for when automatic decoding,\n  based on the Content-Type header, fails.\n\n* Fixed bug with pool depletion and leaking connections (Issue #76). Added\n  explicit connection closing on pool eviction. Added\n  ``urllib3.PoolManager.clear()``.\n\n* 99% -> 100% unit test coverage.\n\n\n1.4 (2012-06-16)\n----------------\n\n* Minor AppEngine-related fixes.\n\n* Switched from ``mimetools.choose_boundary`` to ``uuid.uuid4()``.\n\n* Improved url parsing. (Issue #73)\n\n* IPv6 url support. (Issue #72)\n\n\n1.3 (2012-03-25)\n----------------\n\n* Removed pre-1.0 deprecated API.\n\n* Refactored helpers into a ``urllib3.util`` submodule.\n\n* Fixed multipart encoding to support list-of-tuples for keys with multiple\n  values. (Issue #48)\n\n* Fixed multiple Set-Cookie headers in response not getting merged properly in\n  Python 3. (Issue #53)\n\n* AppEngine support with Py27. (Issue #61)\n\n* Minor ``encode_multipart_formdata`` fixes related to Python 3 strings vs\n  bytes.\n\n\n1.2.2 (2012-02-06)\n------------------\n\n* Fixed packaging bug of not shipping ``test-requirements.txt``. (Issue #47)\n\n\n1.2.1 (2012-02-05)\n------------------\n\n* Fixed another bug related to when ``ssl`` module is not available. (Issue #41)\n\n* Location parsing errors now raise ``urllib3.exceptions.LocationParseError``\n  which inherits from ``ValueError``.\n\n\n1.2 (2012-01-29)\n----------------\n\n* Added Python 3 support (tested on 3.2.2)\n\n* Dropped Python 2.5 support (tested on 2.6.7, 2.7.2)\n\n* Use ``select.poll`` instead of ``select.select`` for platforms that support\n  it.\n\n* Use ``Queue.LifoQueue`` instead of ``Queue.Queue`` for more aggressive\n  connection reusing. Configurable by overriding ``ConnectionPool.QueueCls``.\n\n* Fixed ``ImportError`` during install when ``ssl`` module is not available.\n  (Issue #41)\n\n* Fixed ``PoolManager`` redirects between schemes (such as HTTP -> HTTPS) not\n  completing properly. (Issue #28, uncovered by Issue #10 in v1.1)\n\n* Ported ``dummyserver`` to use ``tornado`` instead of ``webob`` +\n  ``eventlet``. Removed extraneous unsupported dummyserver testing backends.\n  Added socket-level tests.\n\n* More tests. Achievement Unlocked: 99% Coverage.\n\n\n1.1 (2012-01-07)\n----------------\n\n* Refactored ``dummyserver`` to its own root namespace module (used for\n  testing).\n\n* Added hostname verification for ``VerifiedHTTPSConnection`` by vendoring in\n  Py32's ``ssl_match_hostname``. (Issue #25)\n\n* Fixed cross-host HTTP redirects when using ``PoolManager``. (Issue #10)\n\n* Fixed ``decode_content`` being ignored when set through ``urlopen``. (Issue\n  #27)\n\n* Fixed timeout-related bugs. (Issues #17, #23)\n\n\n1.0.2 (2011-11-04)\n------------------\n\n* Fixed typo in ``VerifiedHTTPSConnection`` which would only present as a bug if\n  you're using the object manually. (Thanks pyos)\n\n* Made RecentlyUsedContainer (and consequently PoolManager) more thread-safe by\n  wrapping the access log in a mutex. (Thanks @christer)\n\n* Made RecentlyUsedContainer more dict-like (corrected ``__delitem__`` and\n  ``__getitem__`` behaviour), with tests. Shouldn't affect core urllib3 code.\n\n\n1.0.1 (2011-10-10)\n------------------\n\n* Fixed a bug where the same connection would get returned into the pool twice,\n  causing extraneous \"HttpConnectionPool is full\" log warnings.\n\n\n1.0 (2011-10-08)\n----------------\n\n* Added ``PoolManager`` with LRU expiration of connections (tested and\n  documented).\n* Added ``ProxyManager`` (needs tests, docs, and confirmation that it works\n  with HTTPS proxies).\n* Added optional partial-read support for responses when\n  ``preload_content=False``. You can now make requests and just read the headers\n  without loading the content.\n* Made response decoding optional (default on, same as before).\n* Added optional explicit boundary string for ``encode_multipart_formdata``.\n* Convenience request methods are now inherited from ``RequestMethods``. Old\n  helpers like ``get_url`` and ``post_url`` should be abandoned in favour of\n  the new ``request(method, url, ...)``.\n* Refactored code to be even more decoupled, reusable, and extendable.\n* License header added to ``.py`` files.\n* Embiggened the documentation: Lots of Sphinx-friendly docstrings in the code\n  and docs in ``docs/`` and on https://urllib3.readthedocs.io/.\n* Embettered all the things!\n* Started writing this file.\n\n\n0.4.1 (2011-07-17)\n------------------\n\n* Minor bug fixes, code cleanup.\n\n\n0.4 (2011-03-01)\n----------------\n\n* Better unicode support.\n* Added ``VerifiedHTTPSConnection``.\n* Added ``NTLMConnectionPool`` in contrib.\n* Minor improvements.\n\n\n0.3.1 (2010-07-13)\n------------------\n\n* Added ``assert_host_name`` optional parameter. Now compatible with proxies.\n\n\n0.3 (2009-12-10)\n----------------\n\n* Added HTTPS support.\n* Minor bug fixes.\n* Refactored, broken backwards compatibility with 0.2.\n* API to be treated as stable from this version forward.\n\n\n0.2 (2008-11-17)\n----------------\n\n* Added unit tests.\n* Bug fixes.\n\n\n0.1 (2008-11-16)\n----------------\n\n* First release.\n", "from __future__ import absolute_import\n\nimport email\nimport logging\nimport re\nimport time\nimport warnings\nfrom collections import namedtuple\nfrom itertools import takewhile\n\nfrom ..exceptions import (\n    ConnectTimeoutError,\n    InvalidHeader,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    ResponseError,\n)\nfrom ..packages import six\n\nlog = logging.getLogger(__name__)\n\n\n# Data structure for representing the metadata of requests that result in a retry.\nRequestHistory = namedtuple(\n    \"RequestHistory\", [\"method\", \"url\", \"error\", \"status\", \"redirect_location\"]\n)\n\n\n# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.\n_Default = object()\n\n\nclass _RetryMeta(type):\n    @property\n    def DEFAULT_METHOD_WHITELIST(cls):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_ALLOWED_METHODS\n\n    @DEFAULT_METHOD_WHITELIST.setter\n    def DEFAULT_METHOD_WHITELIST(cls, value):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_ALLOWED_METHODS = value\n\n    @property\n    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT\n\n    @DEFAULT_REDIRECT_HEADERS_BLACKLIST.setter\n    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls, value):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT = value\n\n    @property\n    def BACKOFF_MAX(cls):\n        warnings.warn(\n            \"Using 'Retry.BACKOFF_MAX' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_BACKOFF_MAX\n\n    @BACKOFF_MAX.setter\n    def BACKOFF_MAX(cls, value):\n        warnings.warn(\n            \"Using 'Retry.BACKOFF_MAX' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_BACKOFF_MAX = value\n\n\n@six.add_metaclass(_RetryMeta)\nclass Retry(object):\n    \"\"\"Retry configuration.\n\n    Each retry attempt will create a new Retry object with updated values, so\n    they can be safely reused.\n\n    Retries can be defined as a default for a pool::\n\n        retries = Retry(connect=5, read=2, redirect=5)\n        http = PoolManager(retries=retries)\n        response = http.request('GET', 'http://example.com/')\n\n    Or per-request (which overrides the default for the pool)::\n\n        response = http.request('GET', 'http://example.com/', retries=Retry(10))\n\n    Retries can be disabled by passing ``False``::\n\n        response = http.request('GET', 'http://example.com/', retries=False)\n\n    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless\n    retries are disabled, in which case the causing exception will be raised.\n\n    :param int total:\n        Total number of retries to allow. Takes precedence over other counts.\n\n        Set to ``None`` to remove this constraint and fall back on other\n        counts.\n\n        Set to ``0`` to fail on the first retry.\n\n        Set to ``False`` to disable and imply ``raise_on_redirect=False``.\n\n    :param int connect:\n        How many connection-related errors to retry on.\n\n        These are errors raised before the request is sent to the remote server,\n        which we assume has not triggered the server to process the request.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n    :param int read:\n        How many times to retry on read errors.\n\n        These errors are raised after the request was sent to the server, so the\n        request may have side-effects.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n    :param int redirect:\n        How many redirects to perform. Limit this to avoid infinite redirect\n        loops.\n\n        A redirect is a HTTP response with a status code 301, 302, 303, 307 or\n        308.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n        Set to ``False`` to disable and imply ``raise_on_redirect=False``.\n\n    :param int status:\n        How many times to retry on bad status codes.\n\n        These are retries made on responses, where status code matches\n        ``status_forcelist``.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n    :param int other:\n        How many times to retry on other errors.\n\n        Other errors are errors that are not connect, read, redirect or status errors.\n        These errors might be raised after the request was sent to the server, so the\n        request might have side-effects.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n        If ``total`` is not set, it's a good idea to set this to 0 to account\n        for unexpected edge cases and avoid infinite retry loops.\n\n    :param iterable allowed_methods:\n        Set of uppercased HTTP method verbs that we should retry on.\n\n        By default, we only retry on methods which are considered to be\n        idempotent (multiple requests with the same parameters end with the\n        same state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.\n\n        Set to a ``False`` value to retry on any verb.\n\n        .. warning::\n\n            Previously this parameter was named ``method_whitelist``, that\n            usage is deprecated in v1.26.0 and will be removed in v2.0.\n\n    :param iterable status_forcelist:\n        A set of integer HTTP status codes that we should force a retry on.\n        A retry is initiated if the request method is in ``allowed_methods``\n        and the response status code is in ``status_forcelist``.\n\n        By default, this is disabled with ``None``.\n\n    :param float backoff_factor:\n        A backoff factor to apply between attempts after the second try\n        (most errors are resolved immediately by a second try without a\n        delay). urllib3 will sleep for::\n\n            {backoff factor} * (2 ** ({number of total retries} - 1))\n\n        seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep\n        for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer\n        than :attr:`Retry.DEFAULT_BACKOFF_MAX`.\n\n        By default, backoff is disabled (set to 0).\n\n    :param bool raise_on_redirect: Whether, if the number of redirects is\n        exhausted, to raise a MaxRetryError, or to return a response with a\n        response code in the 3xx range.\n\n    :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:\n        whether we should raise an exception, or return a response,\n        if status falls in ``status_forcelist`` range and retries have\n        been exhausted.\n\n    :param tuple history: The history of the request encountered during\n        each call to :meth:`~Retry.increment`. The list is in the order\n        the requests occurred. Each list item is of class :class:`RequestHistory`.\n\n    :param bool respect_retry_after_header:\n        Whether to respect Retry-After header on status codes defined as\n        :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.\n\n    :param iterable remove_headers_on_redirect:\n        Sequence of headers to remove from the request when a response\n        indicating a redirect is returned before firing off the redirected\n        request.\n    \"\"\"\n\n    #: Default methods to be used for ``allowed_methods``\n    DEFAULT_ALLOWED_METHODS = frozenset(\n        [\"HEAD\", \"GET\", \"PUT\", \"DELETE\", \"OPTIONS\", \"TRACE\"]\n    )\n\n    #: Default status codes to be used for ``status_forcelist``\n    RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])\n\n    #: Default headers to be used for ``remove_headers_on_redirect``\n    DEFAULT_REMOVE_HEADERS_ON_REDIRECT = frozenset([\"Authorization\"])\n\n    #: Maximum backoff time.\n    DEFAULT_BACKOFF_MAX = 120\n\n    def __init__(\n        self,\n        total=10,\n        connect=None,\n        read=None,\n        redirect=None,\n        status=None,\n        other=None,\n        allowed_methods=_Default,\n        status_forcelist=None,\n        backoff_factor=0,\n        raise_on_redirect=True,\n        raise_on_status=True,\n        history=None,\n        respect_retry_after_header=True,\n        remove_headers_on_redirect=_Default,\n        # TODO: Deprecated, remove in v2.0\n        method_whitelist=_Default,\n    ):\n\n        if method_whitelist is not _Default:\n            if allowed_methods is not _Default:\n                raise ValueError(\n                    \"Using both 'allowed_methods' and \"\n                    \"'method_whitelist' together is not allowed. \"\n                    \"Instead only use 'allowed_methods'\"\n                )\n            warnings.warn(\n                \"Using 'method_whitelist' with Retry is deprecated and \"\n                \"will be removed in v2.0. Use 'allowed_methods' instead\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            allowed_methods = method_whitelist\n        if allowed_methods is _Default:\n            allowed_methods = self.DEFAULT_ALLOWED_METHODS\n        if remove_headers_on_redirect is _Default:\n            remove_headers_on_redirect = self.DEFAULT_REMOVE_HEADERS_ON_REDIRECT\n\n        self.total = total\n        self.connect = connect\n        self.read = read\n        self.status = status\n        self.other = other\n\n        if redirect is False or total is False:\n            redirect = 0\n            raise_on_redirect = False\n\n        self.redirect = redirect\n        self.status_forcelist = status_forcelist or set()\n        self.allowed_methods = allowed_methods\n        self.backoff_factor = backoff_factor\n        self.raise_on_redirect = raise_on_redirect\n        self.raise_on_status = raise_on_status\n        self.history = history or tuple()\n        self.respect_retry_after_header = respect_retry_after_header\n        self.remove_headers_on_redirect = frozenset(\n            [h.lower() for h in remove_headers_on_redirect]\n        )\n\n    def new(self, **kw):\n        params = dict(\n            total=self.total,\n            connect=self.connect,\n            read=self.read,\n            redirect=self.redirect,\n            status=self.status,\n            other=self.other,\n            status_forcelist=self.status_forcelist,\n            backoff_factor=self.backoff_factor,\n            raise_on_redirect=self.raise_on_redirect,\n            raise_on_status=self.raise_on_status,\n            history=self.history,\n            remove_headers_on_redirect=self.remove_headers_on_redirect,\n            respect_retry_after_header=self.respect_retry_after_header,\n        )\n\n        # TODO: If already given in **kw we use what's given to us\n        # If not given we need to figure out what to pass. We decide\n        # based on whether our class has the 'method_whitelist' property\n        # and if so we pass the deprecated 'method_whitelist' otherwise\n        # we use 'allowed_methods'. Remove in v2.0\n        if \"method_whitelist\" not in kw and \"allowed_methods\" not in kw:\n            if \"method_whitelist\" in self.__dict__:\n                warnings.warn(\n                    \"Using 'method_whitelist' with Retry is deprecated and \"\n                    \"will be removed in v2.0. Use 'allowed_methods' instead\",\n                    DeprecationWarning,\n                )\n                params[\"method_whitelist\"] = self.allowed_methods\n            else:\n                params[\"allowed_methods\"] = self.allowed_methods\n\n        params.update(kw)\n        return type(self)(**params)\n\n    @classmethod\n    def from_int(cls, retries, redirect=True, default=None):\n        \"\"\"Backwards-compatibility for the old retries format.\"\"\"\n        if retries is None:\n            retries = default if default is not None else cls.DEFAULT\n\n        if isinstance(retries, Retry):\n            return retries\n\n        redirect = bool(redirect) and None\n        new_retries = cls(retries, redirect=redirect)\n        log.debug(\"Converted retries value: %r -> %r\", retries, new_retries)\n        return new_retries\n\n    def get_backoff_time(self):\n        \"\"\"Formula for computing the current backoff\n\n        :rtype: float\n        \"\"\"\n        # We want to consider only the last consecutive errors sequence (Ignore redirects).\n        consecutive_errors_len = len(\n            list(\n                takewhile(lambda x: x.redirect_location is None, reversed(self.history))\n            )\n        )\n        if consecutive_errors_len <= 1:\n            return 0\n\n        backoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))\n        return min(self.DEFAULT_BACKOFF_MAX, backoff_value)\n\n    def parse_retry_after(self, retry_after):\n        # Whitespace: https://tools.ietf.org/html/rfc7230#section-3.2.4\n        if re.match(r\"^\\s*[0-9]+\\s*$\", retry_after):\n            seconds = int(retry_after)\n        else:\n            retry_date_tuple = email.utils.parsedate_tz(retry_after)\n            if retry_date_tuple is None:\n                raise InvalidHeader(\"Invalid Retry-After header: %s\" % retry_after)\n            if retry_date_tuple[9] is None:  # Python 2\n                # Assume UTC if no timezone was specified\n                # On Python2.7, parsedate_tz returns None for a timezone offset\n                # instead of 0 if no timezone is given, where mktime_tz treats\n                # a None timezone offset as local time.\n                retry_date_tuple = retry_date_tuple[:9] + (0,) + retry_date_tuple[10:]\n\n            retry_date = email.utils.mktime_tz(retry_date_tuple)\n            seconds = retry_date - time.time()\n\n        if seconds < 0:\n            seconds = 0\n\n        return seconds\n\n    def get_retry_after(self, response):\n        \"\"\"Get the value of Retry-After in seconds.\"\"\"\n\n        retry_after = response.headers.get(\"Retry-After\")\n\n        if retry_after is None:\n            return None\n\n        return self.parse_retry_after(retry_after)\n\n    def sleep_for_retry(self, response=None):\n        retry_after = self.get_retry_after(response)\n        if retry_after:\n            time.sleep(retry_after)\n            return True\n\n        return False\n\n    def _sleep_backoff(self):\n        backoff = self.get_backoff_time()\n        if backoff <= 0:\n            return\n        time.sleep(backoff)\n\n    def sleep(self, response=None):\n        \"\"\"Sleep between retry attempts.\n\n        This method will respect a server's ``Retry-After`` response header\n        and sleep the duration of the time requested. If that is not present, it\n        will use an exponential backoff. By default, the backoff factor is 0 and\n        this method will return immediately.\n        \"\"\"\n\n        if self.respect_retry_after_header and response:\n            slept = self.sleep_for_retry(response)\n            if slept:\n                return\n\n        self._sleep_backoff()\n\n    def _is_connection_error(self, err):\n        \"\"\"Errors when we're fairly sure that the server did not receive the\n        request, so it should be safe to retry.\n        \"\"\"\n        if isinstance(err, ProxyError):\n            err = err.original_error\n        return isinstance(err, ConnectTimeoutError)\n\n    def _is_read_error(self, err):\n        \"\"\"Errors that occur after the request has been started, so we should\n        assume that the server began processing it.\n        \"\"\"\n        return isinstance(err, (ReadTimeoutError, ProtocolError))\n\n    def _is_method_retryable(self, method):\n        \"\"\"Checks if a given HTTP method should be retried upon, depending if\n        it is included in the allowed_methods\n        \"\"\"\n        # TODO: For now favor if the Retry implementation sets its own method_whitelist\n        # property outside of our constructor to avoid breaking custom implementations.\n        if \"method_whitelist\" in self.__dict__:\n            warnings.warn(\n                \"Using 'method_whitelist' with Retry is deprecated and \"\n                \"will be removed in v2.0. Use 'allowed_methods' instead\",\n                DeprecationWarning,\n            )\n            allowed_methods = self.method_whitelist\n        else:\n            allowed_methods = self.allowed_methods\n\n        if allowed_methods and method.upper() not in allowed_methods:\n            return False\n        return True\n\n    def is_retry(self, method, status_code, has_retry_after=False):\n        \"\"\"Is this method/status code retryable? (Based on allowlists and control\n        variables such as the number of total retries to allow, whether to\n        respect the Retry-After header, whether this header is present, and\n        whether the returned status code is on the list of status codes to\n        be retried upon on the presence of the aforementioned header)\n        \"\"\"\n        if not self._is_method_retryable(method):\n            return False\n\n        if self.status_forcelist and status_code in self.status_forcelist:\n            return True\n\n        return (\n            self.total\n            and self.respect_retry_after_header\n            and has_retry_after\n            and (status_code in self.RETRY_AFTER_STATUS_CODES)\n        )\n\n    def is_exhausted(self):\n        \"\"\"Are we out of retries?\"\"\"\n        retry_counts = (\n            self.total,\n            self.connect,\n            self.read,\n            self.redirect,\n            self.status,\n            self.other,\n        )\n        retry_counts = list(filter(None, retry_counts))\n        if not retry_counts:\n            return False\n\n        return min(retry_counts) < 0\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \"\"\"Return a new Retry object with incremented retry counters.\n\n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n\n        :return: A new ``Retry`` object.\n        \"\"\"\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n\n        total = self.total\n        if total is not None:\n            total -= 1\n\n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \"unknown\"\n        status = None\n        redirect_location = None\n\n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n\n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n\n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n\n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \"too many redirects\"\n            redirect_location = response.get_redirect_location()\n            status = response.status\n\n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n\n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n\n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n\n        if new_retry.is_exhausted():\n            raise MaxRetryError(_pool, url, error or ResponseError(cause))\n\n        log.debug(\"Incremented Retry for (url='%s'): %r\", url, new_retry)\n\n        return new_retry\n\n    def __repr__(self):\n        return (\n            \"{cls.__name__}(total={self.total}, connect={self.connect}, \"\n            \"read={self.read}, redirect={self.redirect}, status={self.status})\"\n        ).format(cls=type(self), self=self)\n\n    def __getattr__(self, item):\n        if item == \"method_whitelist\":\n            # TODO: Remove this deprecated alias in v2.0\n            warnings.warn(\n                \"Using 'method_whitelist' with Retry is deprecated and \"\n                \"will be removed in v2.0. Use 'allowed_methods' instead\",\n                DeprecationWarning,\n            )\n            return self.allowed_methods\n        try:\n            return getattr(super(Retry, self), item)\n        except AttributeError:\n            return getattr(Retry, item)\n\n\n# For backwards compatibility (equivalent to pre-v1.9):\nRetry.DEFAULT = Retry(3)\n", "import warnings\n\nimport mock\nimport pytest\n\nfrom urllib3.exceptions import (\n    ConnectTimeoutError,\n    InvalidHeader,\n    MaxRetryError,\n    ReadTimeoutError,\n    ResponseError,\n    SSLError,\n)\nfrom urllib3.packages import six\nfrom urllib3.packages.six.moves import xrange\nfrom urllib3.response import HTTPResponse\nfrom urllib3.util.retry import RequestHistory, Retry\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef no_retry_deprecations():\n    with warnings.catch_warnings(record=True) as w:\n        yield\n    assert len([str(x.message) for x in w if \"Retry\" in str(x.message)]) == 0\n\n\nclass TestRetry(object):\n    def test_string(self):\n        \"\"\"Retry string representation looks the way we expect\"\"\"\n        retry = Retry()\n        assert (\n            str(retry)\n            == \"Retry(total=10, connect=None, read=None, redirect=None, status=None)\"\n        )\n        for _ in range(3):\n            retry = retry.increment(method=\"GET\")\n        assert (\n            str(retry)\n            == \"Retry(total=7, connect=None, read=None, redirect=None, status=None)\"\n        )\n\n    def test_retry_both_specified(self):\n        \"\"\"Total can win if it's lower than the connect value\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=3, total=2)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=error)\n        assert e.value.reason == error\n\n    def test_retry_higher_total_loses(self):\n        \"\"\"A lower connect timeout than the total is honored\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=2, total=3)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(error=error)\n\n    def test_retry_higher_total_loses_vs_read(self):\n        \"\"\"A lower read timeout than the total is honored\"\"\"\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(read=2, total=3)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(method=\"GET\", error=error)\n\n    def test_retry_total_none(self):\n        \"\"\"if Total is none, connect error should take precedence\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=2, total=None)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=error)\n        assert e.value.reason == error\n\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(connect=2, total=None)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        assert not retry.is_exhausted()\n\n    def test_retry_default(self):\n        \"\"\"If no value is specified, should retry connects 3 times\"\"\"\n        retry = Retry()\n        assert retry.total == 10\n        assert retry.connect is None\n        assert retry.read is None\n        assert retry.redirect is None\n        assert retry.other is None\n\n        error = ConnectTimeoutError()\n        retry = Retry(connect=1)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(error=error)\n\n        retry = Retry(connect=1)\n        retry = retry.increment(error=error)\n        assert not retry.is_exhausted()\n\n        assert Retry(0).raise_on_redirect\n        assert not Retry(False).raise_on_redirect\n\n    def test_retry_other(self):\n        \"\"\"If an unexpected error is raised, should retry other times\"\"\"\n        other_error = SSLError()\n        retry = Retry(connect=1)\n        retry = retry.increment(error=other_error)\n        retry = retry.increment(error=other_error)\n        assert not retry.is_exhausted()\n\n        retry = Retry(other=1)\n        retry = retry.increment(error=other_error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=other_error)\n        assert e.value.reason == other_error\n\n    def test_retry_read_zero(self):\n        \"\"\"No second chances on read timeouts, by default\"\"\"\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(read=0)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(method=\"GET\", error=error)\n        assert e.value.reason == error\n\n    def test_status_counter(self):\n        resp = HTTPResponse(status=400)\n        retry = Retry(status=2)\n        retry = retry.increment(response=resp)\n        retry = retry.increment(response=resp)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(response=resp)\n        assert str(e.value.reason) == ResponseError.SPECIFIC_ERROR.format(\n            status_code=400\n        )\n\n    def test_backoff(self):\n        \"\"\"Backoff is computed correctly\"\"\"\n        max_backoff = Retry.DEFAULT_BACKOFF_MAX\n\n        retry = Retry(total=100, backoff_factor=0.2)\n        assert retry.get_backoff_time() == 0  # First request\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0  # First retry\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.backoff_factor == 0.2\n        assert retry.total == 98\n        assert retry.get_backoff_time() == 0.4  # Start backoff\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.8\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 1.6\n\n        for _ in xrange(10):\n            retry = retry.increment(method=\"GET\")\n\n        assert retry.get_backoff_time() == max_backoff\n\n    def test_zero_backoff(self):\n        retry = Retry()\n        assert retry.get_backoff_time() == 0\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0\n\n    def test_backoff_reset_after_redirect(self):\n        retry = Retry(total=100, redirect=5, backoff_factor=0.2)\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.4\n        redirect_response = HTTPResponse(status=302, headers={\"location\": \"test\"})\n        retry = retry.increment(method=\"GET\", response=redirect_response)\n        assert retry.get_backoff_time() == 0\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.4\n\n    def test_sleep(self):\n        # sleep a very small amount of time so our code coverage is happy\n        retry = Retry(backoff_factor=0.0001)\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        retry.sleep()\n\n    def test_status_forcelist(self):\n        retry = Retry(status_forcelist=xrange(500, 600))\n        assert not retry.is_retry(\"GET\", status_code=200)\n        assert not retry.is_retry(\"GET\", status_code=400)\n        assert retry.is_retry(\"GET\", status_code=500)\n\n        retry = Retry(total=1, status_forcelist=[418])\n        assert not retry.is_retry(\"GET\", status_code=400)\n        assert retry.is_retry(\"GET\", status_code=418)\n\n        # String status codes are not matched.\n        retry = Retry(total=1, status_forcelist=[\"418\"])\n        assert not retry.is_retry(\"GET\", status_code=418)\n\n    def test_allowed_methods_with_status_forcelist(self):\n        # Falsey allowed_methods means to retry on any method.\n        retry = Retry(status_forcelist=[500], allowed_methods=None)\n        assert retry.is_retry(\"GET\", status_code=500)\n        assert retry.is_retry(\"POST\", status_code=500)\n\n        # Criteria of allowed_methods and status_forcelist are ANDed.\n        retry = Retry(status_forcelist=[500], allowed_methods=[\"POST\"])\n        assert not retry.is_retry(\"GET\", status_code=500)\n        assert retry.is_retry(\"POST\", status_code=500)\n\n    def test_exhausted(self):\n        assert not Retry(0).is_exhausted()\n        assert Retry(-1).is_exhausted()\n        assert Retry(1).increment(method=\"GET\").total == 0\n\n    @pytest.mark.parametrize(\"total\", [-1, 0])\n    def test_disabled(self, total):\n        with pytest.raises(MaxRetryError):\n            Retry(total).increment(method=\"GET\")\n\n    def test_error_message(self):\n        retry = Retry(total=0)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\n                method=\"GET\", error=ReadTimeoutError(None, \"/\", \"read timed out\")\n            )\n        assert \"Caused by redirect\" not in str(e.value)\n        assert str(e.value.reason) == \"None: read timed out\"\n\n        retry = Retry(total=1)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\"POST\", \"/\")\n            retry = retry.increment(\"POST\", \"/\")\n        assert \"Caused by redirect\" not in str(e.value)\n        assert isinstance(e.value.reason, ResponseError)\n        assert str(e.value.reason) == ResponseError.GENERIC_ERROR\n\n        retry = Retry(total=1)\n        response = HTTPResponse(status=500)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\"POST\", \"/\", response=response)\n            retry = retry.increment(\"POST\", \"/\", response=response)\n        assert \"Caused by redirect\" not in str(e.value)\n        msg = ResponseError.SPECIFIC_ERROR.format(status_code=500)\n        assert str(e.value.reason) == msg\n\n        retry = Retry(connect=1)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(error=ConnectTimeoutError(\"conntimeout\"))\n            retry = retry.increment(error=ConnectTimeoutError(\"conntimeout\"))\n        assert \"Caused by redirect\" not in str(e.value)\n        assert str(e.value.reason) == \"conntimeout\"\n\n    def test_history(self):\n        retry = Retry(total=10, allowed_methods=frozenset([\"GET\", \"POST\"]))\n        assert retry.history == tuple()\n        connection_error = ConnectTimeoutError(\"conntimeout\")\n        retry = retry.increment(\"GET\", \"/test1\", None, connection_error)\n        history = (RequestHistory(\"GET\", \"/test1\", connection_error, None, None),)\n        assert retry.history == history\n\n        read_error = ReadTimeoutError(None, \"/test2\", \"read timed out\")\n        retry = retry.increment(\"POST\", \"/test2\", None, read_error)\n        history = (\n            RequestHistory(\"GET\", \"/test1\", connection_error, None, None),\n            RequestHistory(\"POST\", \"/test2\", read_error, None, None),\n        )\n        assert retry.history == history\n\n        response = HTTPResponse(status=500)\n        retry = retry.increment(\"GET\", \"/test3\", response, None)\n        history = (\n            RequestHistory(\"GET\", \"/test1\", connection_error, None, None),\n            RequestHistory(\"POST\", \"/test2\", read_error, None, None),\n            RequestHistory(\"GET\", \"/test3\", None, 500, None),\n        )\n        assert retry.history == history\n\n    def test_retry_method_not_in_whitelist(self):\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry()\n        with pytest.raises(ReadTimeoutError):\n            retry.increment(method=\"POST\", error=error)\n\n    def test_retry_default_remove_headers_on_redirect(self):\n        retry = Retry()\n\n        assert list(retry.remove_headers_on_redirect) == [\"authorization\"]\n\n    def test_retry_set_remove_headers_on_redirect(self):\n        retry = Retry(remove_headers_on_redirect=[\"X-API-Secret\"])\n\n        assert list(retry.remove_headers_on_redirect) == [\"x-api-secret\"]\n\n    @pytest.mark.parametrize(\"value\", [\"-1\", \"+1\", \"1.0\", six.u(\"\\xb2\")])  # \\xb2 = ^2\n    def test_parse_retry_after_invalid(self, value):\n        retry = Retry()\n        with pytest.raises(InvalidHeader):\n            retry.parse_retry_after(value)\n\n    @pytest.mark.parametrize(\n        \"value, expected\", [(\"0\", 0), (\"1000\", 1000), (\"\\t42 \", 42)]\n    )\n    def test_parse_retry_after(self, value, expected):\n        retry = Retry()\n        assert retry.parse_retry_after(value) == expected\n\n    @pytest.mark.parametrize(\"respect_retry_after_header\", [True, False])\n    def test_respect_retry_after_header_propagated(self, respect_retry_after_header):\n\n        retry = Retry(respect_retry_after_header=respect_retry_after_header)\n        new_retry = retry.new()\n        assert new_retry.respect_retry_after_header == respect_retry_after_header\n\n    @pytest.mark.freeze_time(\"2019-06-03 11:00:00\", tz_offset=0)\n    @pytest.mark.parametrize(\n        \"retry_after_header,respect_retry_after_header,sleep_duration\",\n        [\n            (\"3600\", True, 3600),\n            (\"3600\", False, None),\n            # Will sleep due to header is 1 hour in future\n            (\"Mon, 3 Jun 2019 12:00:00 UTC\", True, 3600),\n            # Won't sleep due to not respecting header\n            (\"Mon, 3 Jun 2019 12:00:00 UTC\", False, None),\n            # Won't sleep due to current time reached\n            (\"Mon, 3 Jun 2019 11:00:00 UTC\", True, None),\n            # Won't sleep due to current time reached + not respecting header\n            (\"Mon, 3 Jun 2019 11:00:00 UTC\", False, None),\n            # Handle all the formats in RFC 7231 Section 7.1.1.1\n            (\"Mon, 03 Jun 2019 11:30:12 GMT\", True, 1812),\n            (\"Monday, 03-Jun-19 11:30:12 GMT\", True, 1812),\n            # Assume that datetimes without a timezone are in UTC per RFC 7231\n            (\"Mon Jun  3 11:30:12 2019\", True, 1812),\n        ],\n    )\n    @pytest.mark.parametrize(\n        \"stub_timezone\",\n        [\n            \"UTC\",\n            \"Asia/Jerusalem\",\n            None,\n        ],\n        indirect=True,\n    )\n    @pytest.mark.usefixtures(\"stub_timezone\")\n    def test_respect_retry_after_header_sleep(\n        self, retry_after_header, respect_retry_after_header, sleep_duration\n    ):\n        retry = Retry(respect_retry_after_header=respect_retry_after_header)\n\n        with mock.patch(\"time.sleep\") as sleep_mock:\n            # for the default behavior, it must be in RETRY_AFTER_STATUS_CODES\n            response = HTTPResponse(\n                status=503, headers={\"Retry-After\": retry_after_header}\n            )\n\n            retry.sleep(response)\n\n            # The expected behavior is that we'll only sleep if respecting\n            # this header (since we won't have any backoff sleep attempts)\n            if respect_retry_after_header and sleep_duration is not None:\n                sleep_mock.assert_called_with(sleep_duration)\n            else:\n                sleep_mock.assert_not_called()\n", "# This is a copy-paste of test_retry.py with extra asserts about deprecated options. It will be removed for v2.\nimport warnings\n\nimport mock\nimport pytest\n\nfrom urllib3.exceptions import (\n    ConnectTimeoutError,\n    InvalidHeader,\n    MaxRetryError,\n    ReadTimeoutError,\n    ResponseError,\n    SSLError,\n)\nfrom urllib3.packages import six\nfrom urllib3.packages.six.moves import xrange\nfrom urllib3.response import HTTPResponse\nfrom urllib3.util.retry import RequestHistory, Retry\n\n\n# TODO: Remove this entire file once deprecated Retry options are removed in v2.\n@pytest.fixture(scope=\"function\")\ndef expect_retry_deprecation():\n    with warnings.catch_warnings(record=True) as w:\n        yield\n    assert len([str(x.message) for x in w if \"Retry\" in str(x.message)]) > 0\n\n\nclass TestRetry(object):\n    def test_string(self):\n        \"\"\"Retry string representation looks the way we expect\"\"\"\n        retry = Retry()\n        assert (\n            str(retry)\n            == \"Retry(total=10, connect=None, read=None, redirect=None, status=None)\"\n        )\n        for _ in range(3):\n            retry = retry.increment(method=\"GET\")\n        assert (\n            str(retry)\n            == \"Retry(total=7, connect=None, read=None, redirect=None, status=None)\"\n        )\n\n    def test_retry_both_specified(self):\n        \"\"\"Total can win if it's lower than the connect value\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=3, total=2)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=error)\n        assert e.value.reason == error\n\n    def test_retry_higher_total_loses(self):\n        \"\"\"A lower connect timeout than the total is honored\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=2, total=3)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(error=error)\n\n    def test_retry_higher_total_loses_vs_read(self):\n        \"\"\"A lower read timeout than the total is honored\"\"\"\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(read=2, total=3)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(method=\"GET\", error=error)\n\n    def test_retry_total_none(self):\n        \"\"\"if Total is none, connect error should take precedence\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=2, total=None)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=error)\n        assert e.value.reason == error\n\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(connect=2, total=None)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        assert not retry.is_exhausted()\n\n    def test_retry_default(self):\n        \"\"\"If no value is specified, should retry connects 3 times\"\"\"\n        retry = Retry()\n        assert retry.total == 10\n        assert retry.connect is None\n        assert retry.read is None\n        assert retry.redirect is None\n        assert retry.other is None\n\n        error = ConnectTimeoutError()\n        retry = Retry(connect=1)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(error=error)\n\n        retry = Retry(connect=1)\n        retry = retry.increment(error=error)\n        assert not retry.is_exhausted()\n\n        assert Retry(0).raise_on_redirect\n        assert not Retry(False).raise_on_redirect\n\n    def test_retry_other(self):\n        \"\"\"If an unexpected error is raised, should retry other times\"\"\"\n        other_error = SSLError()\n        retry = Retry(connect=1)\n        retry = retry.increment(error=other_error)\n        retry = retry.increment(error=other_error)\n        assert not retry.is_exhausted()\n\n        retry = Retry(other=1)\n        retry = retry.increment(error=other_error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=other_error)\n        assert e.value.reason == other_error\n\n    def test_retry_read_zero(self):\n        \"\"\"No second chances on read timeouts, by default\"\"\"\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(read=0)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(method=\"GET\", error=error)\n        assert e.value.reason == error\n\n    def test_status_counter(self):\n        resp = HTTPResponse(status=400)\n        retry = Retry(status=2)\n        retry = retry.increment(response=resp)\n        retry = retry.increment(response=resp)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(response=resp)\n        assert str(e.value.reason) == ResponseError.SPECIFIC_ERROR.format(\n            status_code=400\n        )\n\n    def test_backoff(self):\n        \"\"\"Backoff is computed correctly\"\"\"\n        max_backoff = Retry.DEFAULT_BACKOFF_MAX\n\n        retry = Retry(total=100, backoff_factor=0.2)\n        assert retry.get_backoff_time() == 0  # First request\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0  # First retry\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.backoff_factor == 0.2\n        assert retry.total == 98\n        assert retry.get_backoff_time() == 0.4  # Start backoff\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.8\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 1.6\n\n        for _ in xrange(10):\n            retry = retry.increment(method=\"GET\")\n\n        assert retry.get_backoff_time() == max_backoff\n\n    def test_zero_backoff(self):\n        retry = Retry()\n        assert retry.get_backoff_time() == 0\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0\n\n    def test_backoff_reset_after_redirect(self):\n        retry = Retry(total=100, redirect=5, backoff_factor=0.2)\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.4\n        redirect_response = HTTPResponse(status=302, headers={\"location\": \"test\"})\n        retry = retry.increment(method=\"GET\", response=redirect_response)\n        assert retry.get_backoff_time() == 0\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.4\n\n    def test_sleep(self):\n        # sleep a very small amount of time so our code coverage is happy\n        retry = Retry(backoff_factor=0.0001)\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        retry.sleep()\n\n    def test_status_forcelist(self):\n        retry = Retry(status_forcelist=xrange(500, 600))\n        assert not retry.is_retry(\"GET\", status_code=200)\n        assert not retry.is_retry(\"GET\", status_code=400)\n        assert retry.is_retry(\"GET\", status_code=500)\n\n        retry = Retry(total=1, status_forcelist=[418])\n        assert not retry.is_retry(\"GET\", status_code=400)\n        assert retry.is_retry(\"GET\", status_code=418)\n\n        # String status codes are not matched.\n        retry = Retry(total=1, status_forcelist=[\"418\"])\n        assert not retry.is_retry(\"GET\", status_code=418)\n\n    def test_method_whitelist_with_status_forcelist(self, expect_retry_deprecation):\n        # Falsey method_whitelist means to retry on any method.\n        retry = Retry(status_forcelist=[500], method_whitelist=None)\n        assert retry.is_retry(\"GET\", status_code=500)\n        assert retry.is_retry(\"POST\", status_code=500)\n\n        # Criteria of method_whitelist and status_forcelist are ANDed.\n        retry = Retry(status_forcelist=[500], method_whitelist=[\"POST\"])\n        assert not retry.is_retry(\"GET\", status_code=500)\n        assert retry.is_retry(\"POST\", status_code=500)\n\n    def test_exhausted(self):\n        assert not Retry(0).is_exhausted()\n        assert Retry(-1).is_exhausted()\n        assert Retry(1).increment(method=\"GET\").total == 0\n\n    @pytest.mark.parametrize(\"total\", [-1, 0])\n    def test_disabled(self, total):\n        with pytest.raises(MaxRetryError):\n            Retry(total).increment(method=\"GET\")\n\n    def test_error_message(self):\n        retry = Retry(total=0)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\n                method=\"GET\", error=ReadTimeoutError(None, \"/\", \"read timed out\")\n            )\n        assert \"Caused by redirect\" not in str(e.value)\n        assert str(e.value.reason) == \"None: read timed out\"\n\n        retry = Retry(total=1)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\"POST\", \"/\")\n            retry = retry.increment(\"POST\", \"/\")\n        assert \"Caused by redirect\" not in str(e.value)\n        assert isinstance(e.value.reason, ResponseError)\n        assert str(e.value.reason) == ResponseError.GENERIC_ERROR\n\n        retry = Retry(total=1)\n        response = HTTPResponse(status=500)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\"POST\", \"/\", response=response)\n            retry = retry.increment(\"POST\", \"/\", response=response)\n        assert \"Caused by redirect\" not in str(e.value)\n        msg = ResponseError.SPECIFIC_ERROR.format(status_code=500)\n        assert str(e.value.reason) == msg\n\n        retry = Retry(connect=1)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(error=ConnectTimeoutError(\"conntimeout\"))\n            retry = retry.increment(error=ConnectTimeoutError(\"conntimeout\"))\n        assert \"Caused by redirect\" not in str(e.value)\n        assert str(e.value.reason) == \"conntimeout\"\n\n    def test_history(self, expect_retry_deprecation):\n        retry = Retry(total=10, method_whitelist=frozenset([\"GET\", \"POST\"]))\n        assert retry.history == tuple()\n        connection_error = ConnectTimeoutError(\"conntimeout\")\n        retry = retry.increment(\"GET\", \"/test1\", None, connection_error)\n        history = (RequestHistory(\"GET\", \"/test1\", connection_error, None, None),)\n        assert retry.history == history\n\n        read_error = ReadTimeoutError(None, \"/test2\", \"read timed out\")\n        retry = retry.increment(\"POST\", \"/test2\", None, read_error)\n        history = (\n            RequestHistory(\"GET\", \"/test1\", connection_error, None, None),\n            RequestHistory(\"POST\", \"/test2\", read_error, None, None),\n        )\n        assert retry.history == history\n\n        response = HTTPResponse(status=500)\n        retry = retry.increment(\"GET\", \"/test3\", response, None)\n        history = (\n            RequestHistory(\"GET\", \"/test1\", connection_error, None, None),\n            RequestHistory(\"POST\", \"/test2\", read_error, None, None),\n            RequestHistory(\"GET\", \"/test3\", None, 500, None),\n        )\n        assert retry.history == history\n\n    def test_retry_method_not_in_whitelist(self):\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry()\n        with pytest.raises(ReadTimeoutError):\n            retry.increment(method=\"POST\", error=error)\n\n    def test_retry_default_remove_headers_on_redirect(self):\n        retry = Retry()\n\n        assert list(retry.remove_headers_on_redirect) == [\"authorization\"]\n\n    def test_retry_set_remove_headers_on_redirect(self):\n        retry = Retry(remove_headers_on_redirect=[\"X-API-Secret\"])\n\n        assert list(retry.remove_headers_on_redirect) == [\"x-api-secret\"]\n\n    @pytest.mark.parametrize(\"value\", [\"-1\", \"+1\", \"1.0\", six.u(\"\\xb2\")])  # \\xb2 = ^2\n    def test_parse_retry_after_invalid(self, value):\n        retry = Retry()\n        with pytest.raises(InvalidHeader):\n            retry.parse_retry_after(value)\n\n    @pytest.mark.parametrize(\n        \"value, expected\", [(\"0\", 0), (\"1000\", 1000), (\"\\t42 \", 42)]\n    )\n    def test_parse_retry_after(self, value, expected):\n        retry = Retry()\n        assert retry.parse_retry_after(value) == expected\n\n    @pytest.mark.parametrize(\"respect_retry_after_header\", [True, False])\n    def test_respect_retry_after_header_propagated(self, respect_retry_after_header):\n\n        retry = Retry(respect_retry_after_header=respect_retry_after_header)\n        new_retry = retry.new()\n        assert new_retry.respect_retry_after_header == respect_retry_after_header\n\n    @pytest.mark.freeze_time(\"2019-06-03 11:00:00\", tz_offset=0)\n    @pytest.mark.parametrize(\n        \"retry_after_header,respect_retry_after_header,sleep_duration\",\n        [\n            (\"3600\", True, 3600),\n            (\"3600\", False, None),\n            # Will sleep due to header is 1 hour in future\n            (\"Mon, 3 Jun 2019 12:00:00 UTC\", True, 3600),\n            # Won't sleep due to not respecting header\n            (\"Mon, 3 Jun 2019 12:00:00 UTC\", False, None),\n            # Won't sleep due to current time reached\n            (\"Mon, 3 Jun 2019 11:00:00 UTC\", True, None),\n            # Won't sleep due to current time reached + not respecting header\n            (\"Mon, 3 Jun 2019 11:00:00 UTC\", False, None),\n            # Handle all the formats in RFC 7231 Section 7.1.1.1\n            (\"Mon, 03 Jun 2019 11:30:12 GMT\", True, 1812),\n            (\"Monday, 03-Jun-19 11:30:12 GMT\", True, 1812),\n            # Assume that datetimes without a timezone are in UTC per RFC 7231\n            (\"Mon Jun  3 11:30:12 2019\", True, 1812),\n        ],\n    )\n    @pytest.mark.parametrize(\n        \"stub_timezone\",\n        [\n            \"UTC\",\n            \"Asia/Jerusalem\",\n            None,\n        ],\n        indirect=True,\n    )\n    @pytest.mark.usefixtures(\"stub_timezone\")\n    def test_respect_retry_after_header_sleep(\n        self, retry_after_header, respect_retry_after_header, sleep_duration\n    ):\n        retry = Retry(respect_retry_after_header=respect_retry_after_header)\n\n        with mock.patch(\"time.sleep\") as sleep_mock:\n            # for the default behavior, it must be in RETRY_AFTER_STATUS_CODES\n            response = HTTPResponse(\n                status=503, headers={\"Retry-After\": retry_after_header}\n            )\n\n            retry.sleep(response)\n\n            # The expected behavior is that we'll only sleep if respecting\n            # this header (since we won't have any backoff sleep attempts)\n            if respect_retry_after_header and sleep_duration is not None:\n                sleep_mock.assert_called_with(sleep_duration)\n            else:\n                sleep_mock.assert_not_called()\n\n\nclass TestRetryDeprecations(object):\n    def test_cls_get_default_method_whitelist(self, expect_retry_deprecation):\n        assert Retry.DEFAULT_ALLOWED_METHODS == Retry.DEFAULT_METHOD_WHITELIST\n\n    def test_cls_get_default_redirect_headers_blacklist(self, expect_retry_deprecation):\n        assert (\n            Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT\n            == Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST\n        )\n\n    def test_cls_get_default_backoff_max(self, expect_retry_deprecation):\n        assert Retry.DEFAULT_BACKOFF_MAX == Retry.BACKOFF_MAX\n\n    def test_cls_set_default_method_whitelist(self, expect_retry_deprecation):\n        old_setting = Retry.DEFAULT_METHOD_WHITELIST\n        try:\n            Retry.DEFAULT_METHOD_WHITELIST = {\"GET\"}\n            retry = Retry()\n            assert retry.DEFAULT_ALLOWED_METHODS == {\"GET\"}\n            assert retry.DEFAULT_METHOD_WHITELIST == {\"GET\"}\n            assert retry.allowed_methods == {\"GET\"}\n            assert retry.method_whitelist == {\"GET\"}\n\n            # Test that the default can be overridden both ways\n            retry = Retry(allowed_methods={\"GET\", \"POST\"})\n            assert retry.DEFAULT_ALLOWED_METHODS == {\"GET\"}\n            assert retry.DEFAULT_METHOD_WHITELIST == {\"GET\"}\n            assert retry.allowed_methods == {\"GET\", \"POST\"}\n            assert retry.method_whitelist == {\"GET\", \"POST\"}\n\n            retry = Retry(method_whitelist={\"POST\"})\n            assert retry.DEFAULT_ALLOWED_METHODS == {\"GET\"}\n            assert retry.DEFAULT_METHOD_WHITELIST == {\"GET\"}\n            assert retry.allowed_methods == {\"POST\"}\n            assert retry.method_whitelist == {\"POST\"}\n        finally:\n            Retry.DEFAULT_METHOD_WHITELIST = old_setting\n            assert Retry.DEFAULT_ALLOWED_METHODS == old_setting\n\n    def test_cls_set_default_redirect_headers_blacklist(self, expect_retry_deprecation):\n        old_setting = Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST\n        try:\n            Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST = {\"test\"}\n            retry = Retry()\n            assert retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT == {\"test\"}\n            assert retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST == {\"test\"}\n            assert retry.remove_headers_on_redirect == {\"test\"}\n            assert retry.remove_headers_on_redirect == {\"test\"}\n\n            retry = Retry(remove_headers_on_redirect={\"test2\"})\n            assert retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT == {\"test\"}\n            assert retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST == {\"test\"}\n            assert retry.remove_headers_on_redirect == {\"test2\"}\n            assert retry.remove_headers_on_redirect == {\"test2\"}\n        finally:\n            Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST = old_setting\n            assert Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST == old_setting\n\n    def test_cls_set_default_backoff_max(self, expect_retry_deprecation):\n        old_setting = Retry.BACKOFF_MAX\n        try:\n            Retry.BACKOFF_MAX = 99\n            retry = Retry()\n            assert retry.DEFAULT_BACKOFF_MAX == 99\n            assert retry.BACKOFF_MAX == 99\n        finally:\n            Retry.BACKOFF_MAX = old_setting\n            assert Retry.BACKOFF_MAX == old_setting\n\n    @pytest.mark.parametrize(\n        \"options\", [(None, None), ({\"GET\"}, None), (None, {\"GET\"}), ({\"GET\"}, {\"GET\"})]\n    )\n    def test_retry_allowed_methods_and_method_whitelist_error(self, options):\n        with pytest.raises(ValueError) as e:\n            Retry(allowed_methods=options[0], method_whitelist=options[1])\n        assert str(e.value) == (\n            \"Using both 'allowed_methods' and 'method_whitelist' together \"\n            \"is not allowed. Instead only use 'allowed_methods'\"\n        )\n\n    def test_retry_subclass_that_sets_method_whitelist(self, expect_retry_deprecation):\n        class SubclassRetry(Retry):\n            def __init__(self, **kwargs):\n                if \"allowed_methods\" in kwargs:\n                    raise AssertionError(\n                        \"This subclass likely doesn't use 'allowed_methods'\"\n                    )\n\n                super(SubclassRetry, self).__init__(**kwargs)\n\n                # Since we're setting 'method_whiteist' we get fallbacks\n                # within Retry.new() and Retry._is_method_retryable()\n                # to use 'method_whitelist' instead of 'allowed_methods'\n                self.method_whitelist = self.method_whitelist | {\"POST\"}\n\n        retry = SubclassRetry()\n        assert retry.method_whitelist == Retry.DEFAULT_ALLOWED_METHODS | {\"POST\"}\n        assert retry.new(read=0).method_whitelist == retry.method_whitelist\n        assert retry._is_method_retryable(\"POST\")\n        assert not retry._is_method_retryable(\"CONNECT\")\n\n        assert retry.new(method_whitelist={\"GET\"}).method_whitelist == {\"GET\", \"POST\"}\n\n        # urllib3 doesn't do this during normal operation\n        # so we don't want users passing in 'allowed_methods'\n        # when their subclass doesn't support the option yet.\n        with pytest.raises(AssertionError) as e:\n            retry.new(allowed_methods={\"GET\"})\n        assert str(e.value) == \"This subclass likely doesn't use 'allowed_methods'\"\n", "import json\nfrom test import LONG_TIMEOUT\n\nimport pytest\n\nfrom dummyserver.server import HAS_IPV6\nfrom dummyserver.testcase import HTTPDummyServerTestCase, IPv6HTTPDummyServerTestCase\nfrom urllib3.connectionpool import port_by_scheme\nfrom urllib3.exceptions import MaxRetryError, URLSchemeUnknown\nfrom urllib3.poolmanager import PoolManager\nfrom urllib3.util.retry import Retry\n\n# Retry failed tests\npytestmark = pytest.mark.flaky\n\n\nclass TestPoolManager(HTTPDummyServerTestCase):\n    @classmethod\n    def setup_class(cls):\n        super(TestPoolManager, cls).setup_class()\n        cls.base_url = \"http://%s:%d\" % (cls.host, cls.port)\n        cls.base_url_alt = \"http://%s:%d\" % (cls.host_alt, cls.port)\n\n    def test_redirect(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/\" % self.base_url},\n                redirect=False,\n            )\n\n            assert r.status == 303\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/\" % self.base_url},\n            )\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_redirect_twice(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/redirect\" % self.base_url},\n                redirect=False,\n            )\n\n            assert r.status == 303\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\n                    \"target\": \"%s/redirect?target=%s/\" % (self.base_url, self.base_url)\n                },\n            )\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_redirect_to_relative_url(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"/redirect\"},\n                redirect=False,\n            )\n\n            assert r.status == 303\n\n            r = http.request(\n                \"GET\", \"%s/redirect\" % self.base_url, fields={\"target\": \"/redirect\"}\n            )\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_cross_host_redirect(self):\n        with PoolManager() as http:\n            cross_host_location = \"%s/echo?a=b\" % self.base_url_alt\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.base_url,\n                    fields={\"target\": cross_host_location},\n                    timeout=LONG_TIMEOUT,\n                    retries=0,\n                )\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/echo?a=b\" % self.base_url_alt},\n                timeout=LONG_TIMEOUT,\n                retries=1,\n            )\n\n            assert r._pool.host == self.host_alt\n\n    def test_too_many_redirects(self):\n        with PoolManager() as http:\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.base_url,\n                    fields={\n                        \"target\": \"%s/redirect?target=%s/\"\n                        % (self.base_url, self.base_url)\n                    },\n                    retries=1,\n                    preload_content=False,\n                )\n\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.base_url,\n                    fields={\n                        \"target\": \"%s/redirect?target=%s/\"\n                        % (self.base_url, self.base_url)\n                    },\n                    retries=Retry(total=None, redirect=1),\n                    preload_content=False,\n                )\n\n            # Even with preload_content=False and raise on redirects, we reused the same\n            # connection\n            assert len(http.pools) == 1\n            pool = http.connection_from_host(self.host, self.port)\n            assert pool.num_connections == 1\n\n    def test_redirect_cross_host_remove_headers(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\"Authorization\": \"foo\"},\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert \"Authorization\" not in data\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\"authorization\": \"foo\"},\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert \"authorization\" not in data\n            assert \"Authorization\" not in data\n\n    def test_redirect_cross_host_no_remove_headers(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\"Authorization\": \"foo\"},\n                retries=Retry(remove_headers_on_redirect=[]),\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert data[\"Authorization\"] == \"foo\"\n\n    def test_redirect_cross_host_set_removed_headers(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\"X-API-Secret\": \"foo\", \"Authorization\": \"bar\"},\n                retries=Retry(remove_headers_on_redirect=[\"X-API-Secret\"]),\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert \"X-API-Secret\" not in data\n            assert data[\"Authorization\"] == \"bar\"\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\"x-api-secret\": \"foo\", \"authorization\": \"bar\"},\n                retries=Retry(remove_headers_on_redirect=[\"X-API-Secret\"]),\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert \"x-api-secret\" not in data\n            assert \"X-API-Secret\" not in data\n            assert data[\"Authorization\"] == \"bar\"\n\n    def test_redirect_without_preload_releases_connection(self):\n        with PoolManager(block=True, maxsize=2) as http:\n            r = http.request(\n                \"GET\", \"%s/redirect\" % self.base_url, preload_content=False\n            )\n            assert r._pool.num_requests == 2\n            assert r._pool.num_connections == 1\n            assert len(http.pools) == 1\n\n    def test_unknown_scheme(self):\n        with PoolManager() as http:\n            unknown_scheme = \"unknown\"\n            unknown_scheme_url = \"%s://host\" % unknown_scheme\n            with pytest.raises(URLSchemeUnknown) as e:\n                r = http.request(\"GET\", unknown_scheme_url)\n            assert e.value.scheme == unknown_scheme\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": unknown_scheme_url},\n                redirect=False,\n            )\n            assert r.status == 303\n            assert r.headers.get(\"Location\") == unknown_scheme_url\n            with pytest.raises(URLSchemeUnknown) as e:\n                r = http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.base_url,\n                    fields={\"target\": unknown_scheme_url},\n                )\n            assert e.value.scheme == unknown_scheme\n\n    def test_raise_on_redirect(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\n                    \"target\": \"%s/redirect?target=%s/\" % (self.base_url, self.base_url)\n                },\n                retries=Retry(total=None, redirect=1, raise_on_redirect=False),\n            )\n\n            assert r.status == 303\n\n    def test_raise_on_status(self):\n        with PoolManager() as http:\n            with pytest.raises(MaxRetryError):\n                # the default is to raise\n                r = http.request(\n                    \"GET\",\n                    \"%s/status\" % self.base_url,\n                    fields={\"status\": \"500 Internal Server Error\"},\n                    retries=Retry(total=1, status_forcelist=range(500, 600)),\n                )\n\n            with pytest.raises(MaxRetryError):\n                # raise explicitly\n                r = http.request(\n                    \"GET\",\n                    \"%s/status\" % self.base_url,\n                    fields={\"status\": \"500 Internal Server Error\"},\n                    retries=Retry(\n                        total=1, status_forcelist=range(500, 600), raise_on_status=True\n                    ),\n                )\n\n            # don't raise\n            r = http.request(\n                \"GET\",\n                \"%s/status\" % self.base_url,\n                fields={\"status\": \"500 Internal Server Error\"},\n                retries=Retry(\n                    total=1, status_forcelist=range(500, 600), raise_on_status=False\n                ),\n            )\n\n            assert r.status == 500\n\n    def test_missing_port(self):\n        # Can a URL that lacks an explicit port like ':80' succeed, or\n        # will all such URLs fail with an error?\n\n        with PoolManager() as http:\n            # By globally adjusting `port_by_scheme` we pretend for a moment\n            # that HTTP's default port is not 80, but is the port at which\n            # our test server happens to be listening.\n            port_by_scheme[\"http\"] = self.port\n            try:\n                r = http.request(\"GET\", \"http://%s/\" % self.host, retries=0)\n            finally:\n                port_by_scheme[\"http\"] = 80\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_headers(self):\n        with PoolManager(headers={\"Foo\": \"bar\"}) as http:\n            r = http.request(\"GET\", \"%s/headers\" % self.base_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n\n            r = http.request(\"POST\", \"%s/headers\" % self.base_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.base_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n\n            r = http.request_encode_body(\"POST\", \"%s/headers\" % self.base_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n\n            r = http.request_encode_url(\n                \"GET\", \"%s/headers\" % self.base_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n\n            r = http.request_encode_body(\n                \"GET\", \"%s/headers\" % self.base_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n\n    def test_http_with_ssl_keywords(self):\n        with PoolManager(ca_certs=\"REQUIRED\") as http:\n            r = http.request(\"GET\", \"http://%s:%s/\" % (self.host, self.port))\n            assert r.status == 200\n\n    def test_http_with_server_hostname(self):\n        with PoolManager(server_hostname=\"example.com\") as http:\n            r = http.request(\"GET\", \"http://%s:%s/\" % (self.host, self.port))\n            assert r.status == 200\n\n    def test_http_with_ca_cert_dir(self):\n        with PoolManager(ca_certs=\"REQUIRED\", ca_cert_dir=\"/nosuchdir\") as http:\n            r = http.request(\"GET\", \"http://%s:%s/\" % (self.host, self.port))\n            assert r.status == 200\n\n    @pytest.mark.parametrize(\n        [\"target\", \"expected_target\"],\n        [\n            (\"/echo_uri?q=1#fragment\", b\"/echo_uri?q=1\"),\n            (\"/echo_uri?#\", b\"/echo_uri?\"),\n            (\"/echo_uri#?\", b\"/echo_uri\"),\n            (\"/echo_uri#?#\", b\"/echo_uri\"),\n            (\"/echo_uri??#\", b\"/echo_uri??\"),\n            (\"/echo_uri?%3f#\", b\"/echo_uri?%3F\"),\n            (\"/echo_uri?%3F#\", b\"/echo_uri?%3F\"),\n            (\"/echo_uri?[]\", b\"/echo_uri?%5B%5D\"),\n        ],\n    )\n    def test_encode_http_target(self, target, expected_target):\n        with PoolManager() as http:\n            url = \"http://%s:%d%s\" % (self.host, self.port, target)\n            r = http.request(\"GET\", url)\n            assert r.data == expected_target\n\n\n@pytest.mark.skipif(not HAS_IPV6, reason=\"IPv6 is not supported on this system\")\nclass TestIPv6PoolManager(IPv6HTTPDummyServerTestCase):\n    @classmethod\n    def setup_class(cls):\n        super(TestIPv6PoolManager, cls).setup_class()\n        cls.base_url = \"http://[%s]:%d\" % (cls.host, cls.port)\n\n    def test_ipv6(self):\n        with PoolManager() as http:\n            http.request(\"GET\", self.base_url)\n"], "fixing_code": ["Changes\n=======\n\n1.26.17 (2023-10-02)\n--------------------\n\n* Added the ``Cookie`` header to the list of headers to strip from requests when redirecting to a different host. As before, different headers can be set via ``Retry.remove_headers_on_redirect``.\n\n\n1.26.16 (2023-05-23)\n--------------------\n\n* Fixed thread-safety issue where accessing a ``PoolManager`` with many distinct origins\n  would cause connection pools to be closed while requests are in progress (`#2954 <https://github.com/urllib3/urllib3/pull/2954>`_)\n\n\n1.26.15 (2023-03-10)\n--------------------\n\n* Fix socket timeout value when ``HTTPConnection`` is reused (`#2645 <https://github.com/urllib3/urllib3/issues/2645>`__)\n* Remove \"!\" character from the unreserved characters in IPv6 Zone ID parsing\n  (`#2899 <https://github.com/urllib3/urllib3/issues/2899>`__)\n* Fix IDNA handling of '\\x80' byte (`#2901 <https://github.com/urllib3/urllib3/issues/2901>`__)\n\n1.26.14 (2023-01-11)\n--------------------\n\n* Fixed parsing of port 0 (zero) returning None, instead of 0. (`#2850 <https://github.com/urllib3/urllib3/issues/2850>`__)\n* Removed deprecated getheaders() calls in contrib module.\n\n1.26.13 (2022-11-23)\n--------------------\n\n* Deprecated the ``HTTPResponse.getheaders()`` and ``HTTPResponse.getheader()`` methods.\n* Fixed an issue where parsing a URL with leading zeroes in the port would be rejected\n  even when the port number after removing the zeroes was valid.\n* Fixed a deprecation warning when using cryptography v39.0.0.\n* Removed the ``<4`` in the ``Requires-Python`` packaging metadata field.\n\n\n1.26.12 (2022-08-22)\n--------------------\n\n* Deprecated the `urllib3[secure]` extra and the `urllib3.contrib.pyopenssl` module.\n  Both will be removed in v2.x. See this `GitHub issue <https://github.com/urllib3/urllib3/issues/2680>`_\n  for justification and info on how to migrate.\n\n\n1.26.11 (2022-07-25)\n--------------------\n\n* Fixed an issue where reading more than 2 GiB in a call to ``HTTPResponse.read`` would\n  raise an ``OverflowError`` on Python 3.9 and earlier.\n\n\n1.26.10 (2022-07-07)\n--------------------\n\n* Removed support for Python 3.5\n* Fixed an issue where a ``ProxyError`` recommending configuring the proxy as HTTP\n  instead of HTTPS could appear even when an HTTPS proxy wasn't configured.\n\n\n1.26.9 (2022-03-16)\n-------------------\n\n* Changed ``urllib3[brotli]`` extra to favor installing Brotli libraries that are still\n  receiving updates like ``brotli`` and ``brotlicffi`` instead of ``brotlipy``.\n  This change does not impact behavior of urllib3, only which dependencies are installed.\n* Fixed a socket leaking when ``HTTPSConnection.connect()`` raises an exception.\n* Fixed ``server_hostname`` being forwarded from ``PoolManager`` to ``HTTPConnectionPool``\n  when requesting an HTTP URL. Should only be forwarded when requesting an HTTPS URL.\n\n\n1.26.8 (2022-01-07)\n-------------------\n\n* Added extra message to ``urllib3.exceptions.ProxyError`` when urllib3 detects that\n  a proxy is configured to use HTTPS but the proxy itself appears to only use HTTP.\n* Added a mention of the size of the connection pool when discarding a connection due to the pool being full.\n* Added explicit support for Python 3.11.\n* Deprecated the ``Retry.MAX_BACKOFF`` class property in favor of ``Retry.DEFAULT_MAX_BACKOFF``\n  to better match the rest of the default parameter names. ``Retry.MAX_BACKOFF`` is removed in v2.0.\n* Changed location of the vendored ``ssl.match_hostname`` function from ``urllib3.packages.ssl_match_hostname``\n  to ``urllib3.util.ssl_match_hostname`` to ensure Python 3.10+ compatibility after being repackaged\n  by downstream distributors.\n* Fixed absolute imports, all imports are now relative.\n\n\n1.26.7 (2021-09-22)\n-------------------\n\n* Fixed a bug with HTTPS hostname verification involving IP addresses and lack\n  of SNI. (Issue #2400)\n* Fixed a bug where IPv6 braces weren't stripped during certificate hostname\n  matching. (Issue #2240)\n\n\n1.26.6 (2021-06-25)\n-------------------\n\n* Deprecated the ``urllib3.contrib.ntlmpool`` module. urllib3 is not able to support\n  it properly due to `reasons listed in this issue <https://github.com/urllib3/urllib3/issues/2282>`_.\n  If you are a user of this module please leave a comment.\n* Changed ``HTTPConnection.request_chunked()`` to not erroneously emit multiple\n  ``Transfer-Encoding`` headers in the case that one is already specified.\n* Fixed typo in deprecation message to recommend ``Retry.DEFAULT_ALLOWED_METHODS``.\n\n\n1.26.5 (2021-05-26)\n-------------------\n\n* Fixed deprecation warnings emitted in Python 3.10.\n* Updated vendored ``six`` library to 1.16.0.\n* Improved performance of URL parser when splitting\n  the authority component.\n\n\n1.26.4 (2021-03-15)\n-------------------\n\n* Changed behavior of the default ``SSLContext`` when connecting to HTTPS proxy\n  during HTTPS requests. The default ``SSLContext`` now sets ``check_hostname=True``.\n\n\n1.26.3 (2021-01-26)\n-------------------\n\n* Fixed bytes and string comparison issue with headers (Pull #2141)\n\n* Changed ``ProxySchemeUnknown`` error message to be\n  more actionable if the user supplies a proxy URL without\n  a scheme. (Pull #2107)\n\n\n1.26.2 (2020-11-12)\n-------------------\n\n* Fixed an issue where ``wrap_socket`` and ``CERT_REQUIRED`` wouldn't\n  be imported properly on Python 2.7.8 and earlier (Pull #2052)\n\n\n1.26.1 (2020-11-11)\n-------------------\n\n* Fixed an issue where two ``User-Agent`` headers would be sent if a\n  ``User-Agent`` header key is passed as ``bytes`` (Pull #2047)\n\n\n1.26.0 (2020-11-10)\n-------------------\n\n* **NOTE: urllib3 v2.0 will drop support for Python 2**.\n  `Read more in the v2.0 Roadmap <https://urllib3.readthedocs.io/en/latest/v2-roadmap.html>`_.\n\n* Added support for HTTPS proxies contacting HTTPS servers (Pull #1923, Pull #1806)\n\n* Deprecated negotiating TLSv1 and TLSv1.1 by default. Users that\n  still wish to use TLS earlier than 1.2 without a deprecation warning\n  should opt-in explicitly by setting ``ssl_version=ssl.PROTOCOL_TLSv1_1`` (Pull #2002)\n  **Starting in urllib3 v2.0: Connections that receive a ``DeprecationWarning`` will fail**\n\n* Deprecated ``Retry`` options ``Retry.DEFAULT_METHOD_WHITELIST``, ``Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST``\n  and ``Retry(method_whitelist=...)`` in favor of ``Retry.DEFAULT_ALLOWED_METHODS``,\n  ``Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT``, and ``Retry(allowed_methods=...)``\n  (Pull #2000) **Starting in urllib3 v2.0: Deprecated options will be removed**\n\n* Added default ``User-Agent`` header to every request (Pull #1750)\n\n* Added ``urllib3.util.SKIP_HEADER`` for skipping ``User-Agent``, ``Accept-Encoding``, \n  and ``Host`` headers from being automatically emitted with requests (Pull #2018)\n\n* Collapse ``transfer-encoding: chunked`` request data and framing into\n  the same ``socket.send()`` call (Pull #1906)\n\n* Send ``http/1.1`` ALPN identifier with every TLS handshake by default (Pull #1894)\n\n* Properly terminate SecureTransport connections when CA verification fails (Pull #1977)\n\n* Don't emit an ``SNIMissingWarning`` when passing ``server_hostname=None``\n  to SecureTransport (Pull #1903)\n\n* Disabled requesting TLSv1.2 session tickets as they weren't being used by urllib3 (Pull #1970)\n\n* Suppress ``BrokenPipeError`` when writing request body after the server\n  has closed the socket (Pull #1524)\n\n* Wrap ``ssl.SSLError`` that can be raised from reading a socket (e.g. \"bad MAC\")\n  into an ``urllib3.exceptions.SSLError`` (Pull #1939)\n\n\n1.25.11 (2020-10-19)\n--------------------\n\n* Fix retry backoff time parsed from ``Retry-After`` header when given\n  in the HTTP date format. The HTTP date was parsed as the local timezone\n  rather than accounting for the timezone in the HTTP date (typically\n  UTC) (Pull #1932, Pull #1935, Pull #1938, Pull #1949)\n\n* Fix issue where an error would be raised when the ``SSLKEYLOGFILE``\n  environment variable was set to the empty string. Now ``SSLContext.keylog_file``\n  is not set in this situation (Pull #2016)\n\n\n1.25.10 (2020-07-22)\n--------------------\n\n* Added support for ``SSLKEYLOGFILE`` environment variable for\n  logging TLS session keys with use with programs like\n  Wireshark for decrypting captured web traffic (Pull #1867)\n\n* Fixed loading of SecureTransport libraries on macOS Big Sur\n  due to the new dynamic linker cache (Pull #1905)\n\n* Collapse chunked request bodies data and framing into one\n  call to ``send()`` to reduce the number of TCP packets by 2-4x (Pull #1906)\n\n* Don't insert ``None`` into ``ConnectionPool`` if the pool\n  was empty when requesting a connection (Pull #1866)\n\n* Avoid ``hasattr`` call in ``BrotliDecoder.decompress()`` (Pull #1858)\n\n\n1.25.9 (2020-04-16)\n-------------------\n\n* Added ``InvalidProxyConfigurationWarning`` which is raised when\n  erroneously specifying an HTTPS proxy URL. urllib3 doesn't currently\n  support connecting to HTTPS proxies but will soon be able to\n  and we would like users to migrate properly without much breakage.\n\n  See `this GitHub issue <https://github.com/urllib3/urllib3/issues/1850>`_\n  for more information on how to fix your proxy config. (Pull #1851)\n\n* Drain connection after ``PoolManager`` redirect (Pull #1817)\n\n* Ensure ``load_verify_locations`` raises ``SSLError`` for all backends (Pull #1812)\n\n* Rename ``VerifiedHTTPSConnection`` to ``HTTPSConnection`` (Pull #1805)\n\n* Allow the CA certificate data to be passed as a string (Pull #1804)\n\n* Raise ``ValueError`` if method contains control characters (Pull #1800)\n\n* Add ``__repr__`` to ``Timeout`` (Pull #1795)\n\n\n1.25.8 (2020-01-20)\n-------------------\n\n* Drop support for EOL Python 3.4 (Pull #1774)\n\n* Optimize _encode_invalid_chars (Pull #1787)\n\n\n1.25.7 (2019-11-11)\n-------------------\n\n* Preserve ``chunked`` parameter on retries (Pull #1715, Pull #1734)\n\n* Allow unset ``SERVER_SOFTWARE`` in App Engine (Pull #1704, Issue #1470)\n\n* Fix issue where URL fragment was sent within the request target. (Pull #1732)\n\n* Fix issue where an empty query section in a URL would fail to parse. (Pull #1732)\n\n* Remove TLS 1.3 support in SecureTransport due to Apple removing support (Pull #1703)\n\n\n1.25.6 (2019-09-24)\n-------------------\n\n* Fix issue where tilde (``~``) characters were incorrectly\n  percent-encoded in the path. (Pull #1692)\n\n\n1.25.5 (2019-09-19)\n-------------------\n\n* Add mitigation for BPO-37428 affecting Python <3.7.4 and OpenSSL 1.1.1+ which\n  caused certificate verification to be enabled when using ``cert_reqs=CERT_NONE``.\n  (Issue #1682)\n\n\n1.25.4 (2019-09-19)\n-------------------\n\n* Propagate Retry-After header settings to subsequent retries. (Pull #1607)\n\n* Fix edge case where Retry-After header was still respected even when\n  explicitly opted out of. (Pull #1607)\n\n* Remove dependency on ``rfc3986`` for URL parsing.\n\n* Fix issue where URLs containing invalid characters within ``Url.auth`` would\n  raise an exception instead of percent-encoding those characters.\n\n* Add support for ``HTTPResponse.auto_close = False`` which makes HTTP responses\n  work well with BufferedReaders and other ``io`` module features. (Pull #1652)\n\n* Percent-encode invalid characters in URL for ``HTTPConnectionPool.request()`` (Pull #1673)\n\n\n1.25.3 (2019-05-23)\n-------------------\n\n* Change ``HTTPSConnection`` to load system CA certificates\n  when ``ca_certs``, ``ca_cert_dir``, and ``ssl_context`` are\n  unspecified. (Pull #1608, Issue #1603)\n\n* Upgrade bundled rfc3986 to v1.3.2. (Pull #1609, Issue #1605)\n\n\n1.25.2 (2019-04-28)\n-------------------\n\n* Change ``is_ipaddress`` to not detect IPvFuture addresses. (Pull #1583)\n\n* Change ``parse_url`` to percent-encode invalid characters within the\n  path, query, and target components. (Pull #1586)\n\n\n1.25.1 (2019-04-24)\n-------------------\n\n* Add support for Google's ``Brotli`` package. (Pull #1572, Pull #1579)\n\n* Upgrade bundled rfc3986 to v1.3.1 (Pull #1578)\n\n\n1.25 (2019-04-22)\n-----------------\n\n* Require and validate certificates by default when using HTTPS (Pull #1507)\n\n* Upgraded ``urllib3.utils.parse_url()`` to be RFC 3986 compliant. (Pull #1487)\n\n* Added support for ``key_password`` for ``HTTPSConnectionPool`` to use\n  encrypted ``key_file`` without creating your own ``SSLContext`` object. (Pull #1489)\n\n* Add TLSv1.3 support to CPython, pyOpenSSL, and SecureTransport ``SSLContext``\n  implementations. (Pull #1496)\n\n* Switched the default multipart header encoder from RFC 2231 to HTML 5 working draft. (Issue #303, Pull #1492)\n\n* Fixed issue where OpenSSL would block if an encrypted client private key was\n  given and no password was given. Instead an ``SSLError`` is raised. (Pull #1489)\n\n* Added support for Brotli content encoding. It is enabled automatically if\n  ``brotlipy`` package is installed which can be requested with\n  ``urllib3[brotli]`` extra. (Pull #1532)\n\n* Drop ciphers using DSS key exchange from default TLS cipher suites.\n  Improve default ciphers when using SecureTransport. (Pull #1496)\n\n* Implemented a more efficient ``HTTPResponse.__iter__()`` method. (Issue #1483)\n\n1.24.3 (2019-05-01)\n-------------------\n\n* Apply fix for CVE-2019-9740. (Pull #1591)\n\n1.24.2 (2019-04-17)\n-------------------\n\n* Don't load system certificates by default when any other ``ca_certs``, ``ca_certs_dir`` or\n  ``ssl_context`` parameters are specified.\n\n* Remove Authorization header regardless of case when redirecting to cross-site. (Issue #1510)\n\n* Add support for IPv6 addresses in subjectAltName section of certificates. (Issue #1269)\n\n\n1.24.1 (2018-11-02)\n-------------------\n\n* Remove quadratic behavior within ``GzipDecoder.decompress()`` (Issue #1467)\n\n* Restored functionality of ``ciphers`` parameter for ``create_urllib3_context()``. (Issue #1462)\n\n\n1.24 (2018-10-16)\n-----------------\n\n* Allow key_server_hostname to be specified when initializing a PoolManager to allow custom SNI to be overridden. (Pull #1449)\n\n* Test against Python 3.7 on AppVeyor. (Pull #1453)\n\n* Early-out ipv6 checks when running on App Engine. (Pull #1450)\n\n* Change ambiguous description of backoff_factor (Pull #1436)\n\n* Add ability to handle multiple Content-Encodings (Issue #1441 and Pull #1442)\n\n* Skip DNS names that can't be idna-decoded when using pyOpenSSL (Issue #1405).\n\n* Add a server_hostname parameter to HTTPSConnection which allows for\n  overriding the SNI hostname sent in the handshake. (Pull #1397)\n\n* Drop support for EOL Python 2.6 (Pull #1429 and Pull #1430)\n\n* Fixed bug where responses with header Content-Type: message/* erroneously\n  raised HeaderParsingError, resulting in a warning being logged. (Pull #1439)\n\n* Move urllib3 to src/urllib3 (Pull #1409)\n\n\n1.23 (2018-06-04)\n-----------------\n\n* Allow providing a list of headers to strip from requests when redirecting\n  to a different host. Defaults to the ``Authorization`` header. Different\n  headers can be set via ``Retry.remove_headers_on_redirect``. (Issue #1316)\n\n* Fix ``util.selectors._fileobj_to_fd`` to accept ``long`` (Issue #1247).\n\n* Dropped Python 3.3 support. (Pull #1242)\n\n* Put the connection back in the pool when calling stream() or read_chunked() on\n  a chunked HEAD response. (Issue #1234)\n\n* Fixed pyOpenSSL-specific ssl client authentication issue when clients\n  attempted to auth via certificate + chain (Issue #1060)\n\n* Add the port to the connectionpool connect print (Pull #1251)\n\n* Don't use the ``uuid`` module to create multipart data boundaries. (Pull #1380)\n\n* ``read_chunked()`` on a closed response returns no chunks. (Issue #1088)\n\n* Add Python 2.6 support to ``contrib.securetransport`` (Pull #1359)\n\n* Added support for auth info in url for SOCKS proxy (Pull #1363)\n\n\n1.22 (2017-07-20)\n-----------------\n\n* Fixed missing brackets in ``HTTP CONNECT`` when connecting to IPv6 address via\n  IPv6 proxy. (Issue #1222)\n\n* Made the connection pool retry on ``SSLError``.  The original ``SSLError``\n  is available on ``MaxRetryError.reason``. (Issue #1112)\n\n* Drain and release connection before recursing on retry/redirect.  Fixes\n  deadlocks with a blocking connectionpool. (Issue #1167)\n\n* Fixed compatibility for cookiejar. (Issue #1229)\n\n* pyopenssl: Use vendored version of ``six``. (Issue #1231)\n\n\n1.21.1 (2017-05-02)\n-------------------\n\n* Fixed SecureTransport issue that would cause long delays in response body\n  delivery. (Pull #1154)\n\n* Fixed regression in 1.21 that threw exceptions when users passed the\n  ``socket_options`` flag to the ``PoolManager``.  (Issue #1165)\n\n* Fixed regression in 1.21 that threw exceptions when users passed the\n  ``assert_hostname`` or ``assert_fingerprint`` flag to the ``PoolManager``.\n  (Pull #1157)\n\n\n1.21 (2017-04-25)\n-----------------\n\n* Improved performance of certain selector system calls on Python 3.5 and\n  later. (Pull #1095)\n\n* Resolved issue where the PyOpenSSL backend would not wrap SysCallError\n  exceptions appropriately when sending data. (Pull #1125)\n\n* Selectors now detects a monkey-patched select module after import for modules\n  that patch the select module like eventlet, greenlet. (Pull #1128)\n\n* Reduced memory consumption when streaming zlib-compressed responses\n  (as opposed to raw deflate streams). (Pull #1129)\n\n* Connection pools now use the entire request context when constructing the\n  pool key. (Pull #1016)\n\n* ``PoolManager.connection_from_*`` methods now accept a new keyword argument,\n  ``pool_kwargs``, which are merged with the existing ``connection_pool_kw``.\n  (Pull #1016)\n\n* Add retry counter for ``status_forcelist``. (Issue #1147)\n\n* Added ``contrib`` module for using SecureTransport on macOS:\n  ``urllib3.contrib.securetransport``.  (Pull #1122)\n\n* urllib3 now only normalizes the case of ``http://`` and ``https://`` schemes:\n  for schemes it does not recognise, it assumes they are case-sensitive and\n  leaves them unchanged.\n  (Issue #1080)\n\n\n1.20 (2017-01-19)\n-----------------\n\n* Added support for waiting for I/O using selectors other than select,\n  improving urllib3's behaviour with large numbers of concurrent connections.\n  (Pull #1001)\n\n* Updated the date for the system clock check. (Issue #1005)\n\n* ConnectionPools now correctly consider hostnames to be case-insensitive.\n  (Issue #1032)\n\n* Outdated versions of PyOpenSSL now cause the PyOpenSSL contrib module\n  to fail when it is injected, rather than at first use. (Pull #1063)\n\n* Outdated versions of cryptography now cause the PyOpenSSL contrib module\n  to fail when it is injected, rather than at first use. (Issue #1044)\n\n* Automatically attempt to rewind a file-like body object when a request is\n  retried or redirected. (Pull #1039)\n\n* Fix some bugs that occur when modules incautiously patch the queue module.\n  (Pull #1061)\n\n* Prevent retries from occurring on read timeouts for which the request method\n  was not in the method whitelist. (Issue #1059)\n\n* Changed the PyOpenSSL contrib module to lazily load idna to avoid\n  unnecessarily bloating the memory of programs that don't need it. (Pull\n  #1076)\n\n* Add support for IPv6 literals with zone identifiers. (Pull #1013)\n\n* Added support for socks5h:// and socks4a:// schemes when working with SOCKS\n  proxies, and controlled remote DNS appropriately. (Issue #1035)\n\n\n1.19.1 (2016-11-16)\n-------------------\n\n* Fixed AppEngine import that didn't function on Python 3.5. (Pull #1025)\n\n\n1.19 (2016-11-03)\n-----------------\n\n* urllib3 now respects Retry-After headers on 413, 429, and 503 responses when\n  using the default retry logic. (Pull #955)\n\n* Remove markers from setup.py to assist ancient setuptools versions. (Issue\n  #986)\n\n* Disallow superscripts and other integerish things in URL ports. (Issue #989)\n\n* Allow urllib3's HTTPResponse.stream() method to continue to work with\n  non-httplib underlying FPs. (Pull #990)\n\n* Empty filenames in multipart headers are now emitted as such, rather than\n  being suppressed. (Issue #1015)\n\n* Prefer user-supplied Host headers on chunked uploads. (Issue #1009)\n\n\n1.18.1 (2016-10-27)\n-------------------\n\n* CVE-2016-9015. Users who are using urllib3 version 1.17 or 1.18 along with\n  PyOpenSSL injection and OpenSSL 1.1.0 *must* upgrade to this version. This\n  release fixes a vulnerability whereby urllib3 in the above configuration\n  would silently fail to validate TLS certificates due to erroneously setting\n  invalid flags in OpenSSL's ``SSL_CTX_set_verify`` function. These erroneous\n  flags do not cause a problem in OpenSSL versions before 1.1.0, which\n  interprets the presence of any flag as requesting certificate validation.\n\n  There is no PR for this patch, as it was prepared for simultaneous disclosure\n  and release. The master branch received the same fix in Pull #1010.\n\n\n1.18 (2016-09-26)\n-----------------\n\n* Fixed incorrect message for IncompleteRead exception. (Pull #973)\n\n* Accept ``iPAddress`` subject alternative name fields in TLS certificates.\n  (Issue #258)\n\n* Fixed consistency of ``HTTPResponse.closed`` between Python 2 and 3.\n  (Issue #977)\n\n* Fixed handling of wildcard certificates when using PyOpenSSL. (Issue #979)\n\n\n1.17 (2016-09-06)\n-----------------\n\n* Accept ``SSLContext`` objects for use in SSL/TLS negotiation. (Issue #835)\n\n* ConnectionPool debug log now includes scheme, host, and port. (Issue #897)\n\n* Substantially refactored documentation. (Issue #887)\n\n* Used URLFetch default timeout on AppEngine, rather than hardcoding our own.\n  (Issue #858)\n\n* Normalize the scheme and host in the URL parser (Issue #833)\n\n* ``HTTPResponse`` contains the last ``Retry`` object, which now also\n  contains retries history. (Issue #848)\n\n* Timeout can no longer be set as boolean, and must be greater than zero.\n  (Pull #924)\n\n* Removed pyasn1 and ndg-httpsclient from dependencies used for PyOpenSSL. We\n  now use cryptography and idna, both of which are already dependencies of\n  PyOpenSSL. (Pull #930)\n\n* Fixed infinite loop in ``stream`` when amt=None. (Issue #928)\n\n* Try to use the operating system's certificates when we are using an\n  ``SSLContext``. (Pull #941)\n\n* Updated cipher suite list to allow ChaCha20+Poly1305. AES-GCM is preferred to\n  ChaCha20, but ChaCha20 is then preferred to everything else. (Pull #947)\n\n* Updated cipher suite list to remove 3DES-based cipher suites. (Pull #958)\n\n* Removed the cipher suite fallback to allow HIGH ciphers. (Pull #958)\n\n* Implemented ``length_remaining`` to determine remaining content\n  to be read. (Pull #949)\n\n* Implemented ``enforce_content_length`` to enable exceptions when\n  incomplete data chunks are received. (Pull #949)\n\n* Dropped connection start, dropped connection reset, redirect, forced retry,\n  and new HTTPS connection log levels to DEBUG, from INFO. (Pull #967)\n\n\n1.16 (2016-06-11)\n-----------------\n\n* Disable IPv6 DNS when IPv6 connections are not possible. (Issue #840)\n\n* Provide ``key_fn_by_scheme`` pool keying mechanism that can be\n  overridden. (Issue #830)\n\n* Normalize scheme and host to lowercase for pool keys, and include\n  ``source_address``. (Issue #830)\n\n* Cleaner exception chain in Python 3 for ``_make_request``.\n  (Issue #861)\n\n* Fixed installing ``urllib3[socks]`` extra. (Issue #864)\n\n* Fixed signature of ``ConnectionPool.close`` so it can actually safely be\n  called by subclasses. (Issue #873)\n\n* Retain ``release_conn`` state across retries. (Issues #651, #866)\n\n* Add customizable ``HTTPConnectionPool.ResponseCls``, which defaults to\n  ``HTTPResponse`` but can be replaced with a subclass. (Issue #879)\n\n\n1.15.1 (2016-04-11)\n-------------------\n\n* Fix packaging to include backports module. (Issue #841)\n\n\n1.15 (2016-04-06)\n-----------------\n\n* Added Retry(raise_on_status=False). (Issue #720)\n\n* Always use setuptools, no more distutils fallback. (Issue #785)\n\n* Dropped support for Python 3.2. (Issue #786)\n\n* Chunked transfer encoding when requesting with ``chunked=True``.\n  (Issue #790)\n\n* Fixed regression with IPv6 port parsing. (Issue #801)\n\n* Append SNIMissingWarning messages to allow users to specify it in\n  the PYTHONWARNINGS environment variable. (Issue #816)\n\n* Handle unicode headers in Py2. (Issue #818)\n\n* Log certificate when there is a hostname mismatch. (Issue #820)\n\n* Preserve order of request/response headers. (Issue #821)\n\n\n1.14 (2015-12-29)\n-----------------\n\n* contrib: SOCKS proxy support! (Issue #762)\n\n* Fixed AppEngine handling of transfer-encoding header and bug\n  in Timeout defaults checking. (Issue #763)\n\n\n1.13.1 (2015-12-18)\n-------------------\n\n* Fixed regression in IPv6 + SSL for match_hostname. (Issue #761)\n\n\n1.13 (2015-12-14)\n-----------------\n\n* Fixed ``pip install urllib3[secure]`` on modern pip. (Issue #706)\n\n* pyopenssl: Fixed SSL3_WRITE_PENDING error. (Issue #717)\n\n* pyopenssl: Support for TLSv1.1 and TLSv1.2. (Issue #696)\n\n* Close connections more defensively on exception. (Issue #734)\n\n* Adjusted ``read_chunked`` to handle gzipped, chunk-encoded bodies without\n  repeatedly flushing the decoder, to function better on Jython. (Issue #743)\n\n* Accept ``ca_cert_dir`` for SSL-related PoolManager configuration. (Issue #758)\n\n\n1.12 (2015-09-03)\n-----------------\n\n* Rely on ``six`` for importing ``httplib`` to work around\n  conflicts with other Python 3 shims. (Issue #688)\n\n* Add support for directories of certificate authorities, as supported by\n  OpenSSL. (Issue #701)\n\n* New exception: ``NewConnectionError``, raised when we fail to establish\n  a new connection, usually ``ECONNREFUSED`` socket error.\n\n\n1.11 (2015-07-21)\n-----------------\n\n* When ``ca_certs`` is given, ``cert_reqs`` defaults to\n  ``'CERT_REQUIRED'``. (Issue #650)\n\n* ``pip install urllib3[secure]`` will install Certifi and\n  PyOpenSSL as dependencies. (Issue #678)\n\n* Made ``HTTPHeaderDict`` usable as a ``headers`` input value\n  (Issues #632, #679)\n\n* Added `urllib3.contrib.appengine <https://urllib3.readthedocs.io/en/latest/contrib.html#google-app-engine>`_\n  which has an ``AppEngineManager`` for using ``URLFetch`` in a\n  Google AppEngine environment. (Issue #664)\n\n* Dev: Added test suite for AppEngine. (Issue #631)\n\n* Fix performance regression when using PyOpenSSL. (Issue #626)\n\n* Passing incorrect scheme (e.g. ``foo://``) will raise\n  ``ValueError`` instead of ``AssertionError`` (backwards\n  compatible for now, but please migrate). (Issue #640)\n\n* Fix pools not getting replenished when an error occurs during a\n  request using ``release_conn=False``. (Issue #644)\n\n* Fix pool-default headers not applying for url-encoded requests\n  like GET. (Issue #657)\n\n* log.warning in Python 3 when headers are skipped due to parsing\n  errors. (Issue #642)\n\n* Close and discard connections if an error occurs during read.\n  (Issue #660)\n\n* Fix host parsing for IPv6 proxies. (Issue #668)\n\n* Separate warning type SubjectAltNameWarning, now issued once\n  per host. (Issue #671)\n\n* Fix ``httplib.IncompleteRead`` not getting converted to\n  ``ProtocolError`` when using ``HTTPResponse.stream()``\n  (Issue #674)\n\n1.10.4 (2015-05-03)\n-------------------\n\n* Migrate tests to Tornado 4. (Issue #594)\n\n* Append default warning configuration rather than overwrite.\n  (Issue #603)\n\n* Fix streaming decoding regression. (Issue #595)\n\n* Fix chunked requests losing state across keep-alive connections.\n  (Issue #599)\n\n* Fix hanging when chunked HEAD response has no body. (Issue #605)\n\n\n1.10.3 (2015-04-21)\n-------------------\n\n* Emit ``InsecurePlatformWarning`` when SSLContext object is missing.\n  (Issue #558)\n\n* Fix regression of duplicate header keys being discarded.\n  (Issue #563)\n\n* ``Response.stream()`` returns a generator for chunked responses.\n  (Issue #560)\n\n* Set upper-bound timeout when waiting for a socket in PyOpenSSL.\n  (Issue #585)\n\n* Work on platforms without `ssl` module for plain HTTP requests.\n  (Issue #587)\n\n* Stop relying on the stdlib's default cipher list. (Issue #588)\n\n\n1.10.2 (2015-02-25)\n-------------------\n\n* Fix file descriptor leakage on retries. (Issue #548)\n\n* Removed RC4 from default cipher list. (Issue #551)\n\n* Header performance improvements. (Issue #544)\n\n* Fix PoolManager not obeying redirect retry settings. (Issue #553)\n\n\n1.10.1 (2015-02-10)\n-------------------\n\n* Pools can be used as context managers. (Issue #545)\n\n* Don't re-use connections which experienced an SSLError. (Issue #529)\n\n* Don't fail when gzip decoding an empty stream. (Issue #535)\n\n* Add sha256 support for fingerprint verification. (Issue #540)\n\n* Fixed handling of header values containing commas. (Issue #533)\n\n\n1.10 (2014-12-14)\n-----------------\n\n* Disabled SSLv3. (Issue #473)\n\n* Add ``Url.url`` property to return the composed url string. (Issue #394)\n\n* Fixed PyOpenSSL + gevent ``WantWriteError``. (Issue #412)\n\n* ``MaxRetryError.reason`` will always be an exception, not string.\n  (Issue #481)\n\n* Fixed SSL-related timeouts not being detected as timeouts. (Issue #492)\n\n* Py3: Use ``ssl.create_default_context()`` when available. (Issue #473)\n\n* Emit ``InsecureRequestWarning`` for *every* insecure HTTPS request.\n  (Issue #496)\n\n* Emit ``SecurityWarning`` when certificate has no ``subjectAltName``.\n  (Issue #499)\n\n* Close and discard sockets which experienced SSL-related errors.\n  (Issue #501)\n\n* Handle ``body`` param in ``.request(...)``. (Issue #513)\n\n* Respect timeout with HTTPS proxy. (Issue #505)\n\n* PyOpenSSL: Handle ZeroReturnError exception. (Issue #520)\n\n\n1.9.1 (2014-09-13)\n------------------\n\n* Apply socket arguments before binding. (Issue #427)\n\n* More careful checks if fp-like object is closed. (Issue #435)\n\n* Fixed packaging issues of some development-related files not\n  getting included. (Issue #440)\n\n* Allow performing *only* fingerprint verification. (Issue #444)\n\n* Emit ``SecurityWarning`` if system clock is waaay off. (Issue #445)\n\n* Fixed PyOpenSSL compatibility with PyPy. (Issue #450)\n\n* Fixed ``BrokenPipeError`` and ``ConnectionError`` handling in Py3.\n  (Issue #443)\n\n\n\n1.9 (2014-07-04)\n----------------\n\n* Shuffled around development-related files. If you're maintaining a distro\n  package of urllib3, you may need to tweak things. (Issue #415)\n\n* Unverified HTTPS requests will trigger a warning on the first request. See\n  our new `security documentation\n  <https://urllib3.readthedocs.io/en/latest/security.html>`_ for details.\n  (Issue #426)\n\n* New retry logic and ``urllib3.util.retry.Retry`` configuration object.\n  (Issue #326)\n\n* All raised exceptions should now wrapped in a\n  ``urllib3.exceptions.HTTPException``-extending exception. (Issue #326)\n\n* All errors during a retry-enabled request should be wrapped in\n  ``urllib3.exceptions.MaxRetryError``, including timeout-related exceptions\n  which were previously exempt. Underlying error is accessible from the\n  ``.reason`` property. (Issue #326)\n\n* ``urllib3.exceptions.ConnectionError`` renamed to\n  ``urllib3.exceptions.ProtocolError``. (Issue #326)\n\n* Errors during response read (such as IncompleteRead) are now wrapped in\n  ``urllib3.exceptions.ProtocolError``. (Issue #418)\n\n* Requesting an empty host will raise ``urllib3.exceptions.LocationValueError``.\n  (Issue #417)\n\n* Catch read timeouts over SSL connections as\n  ``urllib3.exceptions.ReadTimeoutError``. (Issue #419)\n\n* Apply socket arguments before connecting. (Issue #427)\n\n\n1.8.3 (2014-06-23)\n------------------\n\n* Fix TLS verification when using a proxy in Python 3.4.1. (Issue #385)\n\n* Add ``disable_cache`` option to ``urllib3.util.make_headers``. (Issue #393)\n\n* Wrap ``socket.timeout`` exception with\n  ``urllib3.exceptions.ReadTimeoutError``. (Issue #399)\n\n* Fixed proxy-related bug where connections were being reused incorrectly.\n  (Issues #366, #369)\n\n* Added ``socket_options`` keyword parameter which allows to define\n  ``setsockopt`` configuration of new sockets. (Issue #397)\n\n* Removed ``HTTPConnection.tcp_nodelay`` in favor of\n  ``HTTPConnection.default_socket_options``. (Issue #397)\n\n* Fixed ``TypeError`` bug in Python 2.6.4. (Issue #411)\n\n\n1.8.2 (2014-04-17)\n------------------\n\n* Fix ``urllib3.util`` not being included in the package.\n\n\n1.8.1 (2014-04-17)\n------------------\n\n* Fix AppEngine bug of HTTPS requests going out as HTTP. (Issue #356)\n\n* Don't install ``dummyserver`` into ``site-packages`` as it's only needed\n  for the test suite. (Issue #362)\n\n* Added support for specifying ``source_address``. (Issue #352)\n\n\n1.8 (2014-03-04)\n----------------\n\n* Improved url parsing in ``urllib3.util.parse_url`` (properly parse '@' in\n  username, and blank ports like 'hostname:').\n\n* New ``urllib3.connection`` module which contains all the HTTPConnection\n  objects.\n\n* Several ``urllib3.util.Timeout``-related fixes. Also changed constructor\n  signature to a more sensible order. [Backwards incompatible]\n  (Issues #252, #262, #263)\n\n* Use ``backports.ssl_match_hostname`` if it's installed. (Issue #274)\n\n* Added ``.tell()`` method to ``urllib3.response.HTTPResponse`` which\n  returns the number of bytes read so far. (Issue #277)\n\n* Support for platforms without threading. (Issue #289)\n\n* Expand default-port comparison in ``HTTPConnectionPool.is_same_host``\n  to allow a pool with no specified port to be considered equal to to an\n  HTTP/HTTPS url with port 80/443 explicitly provided. (Issue #305)\n\n* Improved default SSL/TLS settings to avoid vulnerabilities.\n  (Issue #309)\n\n* Fixed ``urllib3.poolmanager.ProxyManager`` not retrying on connect errors.\n  (Issue #310)\n\n* Disable Nagle's Algorithm on the socket for non-proxies. A subset of requests\n  will send the entire HTTP request ~200 milliseconds faster; however, some of\n  the resulting TCP packets will be smaller. (Issue #254)\n\n* Increased maximum number of SubjectAltNames in ``urllib3.contrib.pyopenssl``\n  from the default 64 to 1024 in a single certificate. (Issue #318)\n\n* Headers are now passed and stored as a custom\n  ``urllib3.collections_.HTTPHeaderDict`` object rather than a plain ``dict``.\n  (Issue #329, #333)\n\n* Headers no longer lose their case on Python 3. (Issue #236)\n\n* ``urllib3.contrib.pyopenssl`` now uses the operating system's default CA\n  certificates on inject. (Issue #332)\n\n* Requests with ``retries=False`` will immediately raise any exceptions without\n  wrapping them in ``MaxRetryError``. (Issue #348)\n\n* Fixed open socket leak with SSL-related failures. (Issue #344, #348)\n\n\n1.7.1 (2013-09-25)\n------------------\n\n* Added granular timeout support with new ``urllib3.util.Timeout`` class.\n  (Issue #231)\n\n* Fixed Python 3.4 support. (Issue #238)\n\n\n1.7 (2013-08-14)\n----------------\n\n* More exceptions are now pickle-able, with tests. (Issue #174)\n\n* Fixed redirecting with relative URLs in Location header. (Issue #178)\n\n* Support for relative urls in ``Location: ...`` header. (Issue #179)\n\n* ``urllib3.response.HTTPResponse`` now inherits from ``io.IOBase`` for bonus\n  file-like functionality. (Issue #187)\n\n* Passing ``assert_hostname=False`` when creating a HTTPSConnectionPool will\n  skip hostname verification for SSL connections. (Issue #194)\n\n* New method ``urllib3.response.HTTPResponse.stream(...)`` which acts as a\n  generator wrapped around ``.read(...)``. (Issue #198)\n\n* IPv6 url parsing enforces brackets around the hostname. (Issue #199)\n\n* Fixed thread race condition in\n  ``urllib3.poolmanager.PoolManager.connection_from_host(...)`` (Issue #204)\n\n* ``ProxyManager`` requests now include non-default port in ``Host: ...``\n  header. (Issue #217)\n\n* Added HTTPS proxy support in ``ProxyManager``. (Issue #170 #139)\n\n* New ``RequestField`` object can be passed to the ``fields=...`` param which\n  can specify headers. (Issue #220)\n\n* Raise ``urllib3.exceptions.ProxyError`` when connecting to proxy fails.\n  (Issue #221)\n\n* Use international headers when posting file names. (Issue #119)\n\n* Improved IPv6 support. (Issue #203)\n\n\n1.6 (2013-04-25)\n----------------\n\n* Contrib: Optional SNI support for Py2 using PyOpenSSL. (Issue #156)\n\n* ``ProxyManager`` automatically adds ``Host: ...`` header if not given.\n\n* Improved SSL-related code. ``cert_req`` now optionally takes a string like\n  \"REQUIRED\" or \"NONE\". Same with ``ssl_version`` takes strings like \"SSLv23\"\n  The string values reflect the suffix of the respective constant variable.\n  (Issue #130)\n\n* Vendored ``socksipy`` now based on Anorov's fork which handles unexpectedly\n  closed proxy connections and larger read buffers. (Issue #135)\n\n* Ensure the connection is closed if no data is received, fixes connection leak\n  on some platforms. (Issue #133)\n\n* Added SNI support for SSL/TLS connections on Py32+. (Issue #89)\n\n* Tests fixed to be compatible with Py26 again. (Issue #125)\n\n* Added ability to choose SSL version by passing an ``ssl.PROTOCOL_*`` constant\n  to the ``ssl_version`` parameter of ``HTTPSConnectionPool``. (Issue #109)\n\n* Allow an explicit content type to be specified when encoding file fields.\n  (Issue #126)\n\n* Exceptions are now pickleable, with tests. (Issue #101)\n\n* Fixed default headers not getting passed in some cases. (Issue #99)\n\n* Treat \"content-encoding\" header value as case-insensitive, per RFC 2616\n  Section 3.5. (Issue #110)\n\n* \"Connection Refused\" SocketErrors will get retried rather than raised.\n  (Issue #92)\n\n* Updated vendored ``six``, no longer overrides the global ``six`` module\n  namespace. (Issue #113)\n\n* ``urllib3.exceptions.MaxRetryError`` contains a ``reason`` property holding\n  the exception that prompted the final retry. If ``reason is None`` then it\n  was due to a redirect. (Issue #92, #114)\n\n* Fixed ``PoolManager.urlopen()`` from not redirecting more than once.\n  (Issue #149)\n\n* Don't assume ``Content-Type: text/plain`` for multi-part encoding parameters\n  that are not files. (Issue #111)\n\n* Pass `strict` param down to ``httplib.HTTPConnection``. (Issue #122)\n\n* Added mechanism to verify SSL certificates by fingerprint (md5, sha1) or\n  against an arbitrary hostname (when connecting by IP or for misconfigured\n  servers). (Issue #140)\n\n* Streaming decompression support. (Issue #159)\n\n\n1.5 (2012-08-02)\n----------------\n\n* Added ``urllib3.add_stderr_logger()`` for quickly enabling STDERR debug\n  logging in urllib3.\n\n* Native full URL parsing (including auth, path, query, fragment) available in\n  ``urllib3.util.parse_url(url)``.\n\n* Built-in redirect will switch method to 'GET' if status code is 303.\n  (Issue #11)\n\n* ``urllib3.PoolManager`` strips the scheme and host before sending the request\n  uri. (Issue #8)\n\n* New ``urllib3.exceptions.DecodeError`` exception for when automatic decoding,\n  based on the Content-Type header, fails.\n\n* Fixed bug with pool depletion and leaking connections (Issue #76). Added\n  explicit connection closing on pool eviction. Added\n  ``urllib3.PoolManager.clear()``.\n\n* 99% -> 100% unit test coverage.\n\n\n1.4 (2012-06-16)\n----------------\n\n* Minor AppEngine-related fixes.\n\n* Switched from ``mimetools.choose_boundary`` to ``uuid.uuid4()``.\n\n* Improved url parsing. (Issue #73)\n\n* IPv6 url support. (Issue #72)\n\n\n1.3 (2012-03-25)\n----------------\n\n* Removed pre-1.0 deprecated API.\n\n* Refactored helpers into a ``urllib3.util`` submodule.\n\n* Fixed multipart encoding to support list-of-tuples for keys with multiple\n  values. (Issue #48)\n\n* Fixed multiple Set-Cookie headers in response not getting merged properly in\n  Python 3. (Issue #53)\n\n* AppEngine support with Py27. (Issue #61)\n\n* Minor ``encode_multipart_formdata`` fixes related to Python 3 strings vs\n  bytes.\n\n\n1.2.2 (2012-02-06)\n------------------\n\n* Fixed packaging bug of not shipping ``test-requirements.txt``. (Issue #47)\n\n\n1.2.1 (2012-02-05)\n------------------\n\n* Fixed another bug related to when ``ssl`` module is not available. (Issue #41)\n\n* Location parsing errors now raise ``urllib3.exceptions.LocationParseError``\n  which inherits from ``ValueError``.\n\n\n1.2 (2012-01-29)\n----------------\n\n* Added Python 3 support (tested on 3.2.2)\n\n* Dropped Python 2.5 support (tested on 2.6.7, 2.7.2)\n\n* Use ``select.poll`` instead of ``select.select`` for platforms that support\n  it.\n\n* Use ``Queue.LifoQueue`` instead of ``Queue.Queue`` for more aggressive\n  connection reusing. Configurable by overriding ``ConnectionPool.QueueCls``.\n\n* Fixed ``ImportError`` during install when ``ssl`` module is not available.\n  (Issue #41)\n\n* Fixed ``PoolManager`` redirects between schemes (such as HTTP -> HTTPS) not\n  completing properly. (Issue #28, uncovered by Issue #10 in v1.1)\n\n* Ported ``dummyserver`` to use ``tornado`` instead of ``webob`` +\n  ``eventlet``. Removed extraneous unsupported dummyserver testing backends.\n  Added socket-level tests.\n\n* More tests. Achievement Unlocked: 99% Coverage.\n\n\n1.1 (2012-01-07)\n----------------\n\n* Refactored ``dummyserver`` to its own root namespace module (used for\n  testing).\n\n* Added hostname verification for ``VerifiedHTTPSConnection`` by vendoring in\n  Py32's ``ssl_match_hostname``. (Issue #25)\n\n* Fixed cross-host HTTP redirects when using ``PoolManager``. (Issue #10)\n\n* Fixed ``decode_content`` being ignored when set through ``urlopen``. (Issue\n  #27)\n\n* Fixed timeout-related bugs. (Issues #17, #23)\n\n\n1.0.2 (2011-11-04)\n------------------\n\n* Fixed typo in ``VerifiedHTTPSConnection`` which would only present as a bug if\n  you're using the object manually. (Thanks pyos)\n\n* Made RecentlyUsedContainer (and consequently PoolManager) more thread-safe by\n  wrapping the access log in a mutex. (Thanks @christer)\n\n* Made RecentlyUsedContainer more dict-like (corrected ``__delitem__`` and\n  ``__getitem__`` behaviour), with tests. Shouldn't affect core urllib3 code.\n\n\n1.0.1 (2011-10-10)\n------------------\n\n* Fixed a bug where the same connection would get returned into the pool twice,\n  causing extraneous \"HttpConnectionPool is full\" log warnings.\n\n\n1.0 (2011-10-08)\n----------------\n\n* Added ``PoolManager`` with LRU expiration of connections (tested and\n  documented).\n* Added ``ProxyManager`` (needs tests, docs, and confirmation that it works\n  with HTTPS proxies).\n* Added optional partial-read support for responses when\n  ``preload_content=False``. You can now make requests and just read the headers\n  without loading the content.\n* Made response decoding optional (default on, same as before).\n* Added optional explicit boundary string for ``encode_multipart_formdata``.\n* Convenience request methods are now inherited from ``RequestMethods``. Old\n  helpers like ``get_url`` and ``post_url`` should be abandoned in favour of\n  the new ``request(method, url, ...)``.\n* Refactored code to be even more decoupled, reusable, and extendable.\n* License header added to ``.py`` files.\n* Embiggened the documentation: Lots of Sphinx-friendly docstrings in the code\n  and docs in ``docs/`` and on https://urllib3.readthedocs.io/.\n* Embettered all the things!\n* Started writing this file.\n\n\n0.4.1 (2011-07-17)\n------------------\n\n* Minor bug fixes, code cleanup.\n\n\n0.4 (2011-03-01)\n----------------\n\n* Better unicode support.\n* Added ``VerifiedHTTPSConnection``.\n* Added ``NTLMConnectionPool`` in contrib.\n* Minor improvements.\n\n\n0.3.1 (2010-07-13)\n------------------\n\n* Added ``assert_host_name`` optional parameter. Now compatible with proxies.\n\n\n0.3 (2009-12-10)\n----------------\n\n* Added HTTPS support.\n* Minor bug fixes.\n* Refactored, broken backwards compatibility with 0.2.\n* API to be treated as stable from this version forward.\n\n\n0.2 (2008-11-17)\n----------------\n\n* Added unit tests.\n* Bug fixes.\n\n\n0.1 (2008-11-16)\n----------------\n\n* First release.\n", "from __future__ import absolute_import\n\nimport email\nimport logging\nimport re\nimport time\nimport warnings\nfrom collections import namedtuple\nfrom itertools import takewhile\n\nfrom ..exceptions import (\n    ConnectTimeoutError,\n    InvalidHeader,\n    MaxRetryError,\n    ProtocolError,\n    ProxyError,\n    ReadTimeoutError,\n    ResponseError,\n)\nfrom ..packages import six\n\nlog = logging.getLogger(__name__)\n\n\n# Data structure for representing the metadata of requests that result in a retry.\nRequestHistory = namedtuple(\n    \"RequestHistory\", [\"method\", \"url\", \"error\", \"status\", \"redirect_location\"]\n)\n\n\n# TODO: In v2 we can remove this sentinel and metaclass with deprecated options.\n_Default = object()\n\n\nclass _RetryMeta(type):\n    @property\n    def DEFAULT_METHOD_WHITELIST(cls):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_ALLOWED_METHODS\n\n    @DEFAULT_METHOD_WHITELIST.setter\n    def DEFAULT_METHOD_WHITELIST(cls, value):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_METHOD_WHITELIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_ALLOWED_METHODS' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_ALLOWED_METHODS = value\n\n    @property\n    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT\n\n    @DEFAULT_REDIRECT_HEADERS_BLACKLIST.setter\n    def DEFAULT_REDIRECT_HEADERS_BLACKLIST(cls, value):\n        warnings.warn(\n            \"Using 'Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_REMOVE_HEADERS_ON_REDIRECT = value\n\n    @property\n    def BACKOFF_MAX(cls):\n        warnings.warn(\n            \"Using 'Retry.BACKOFF_MAX' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead\",\n            DeprecationWarning,\n        )\n        return cls.DEFAULT_BACKOFF_MAX\n\n    @BACKOFF_MAX.setter\n    def BACKOFF_MAX(cls, value):\n        warnings.warn(\n            \"Using 'Retry.BACKOFF_MAX' is deprecated and \"\n            \"will be removed in v2.0. Use 'Retry.DEFAULT_BACKOFF_MAX' instead\",\n            DeprecationWarning,\n        )\n        cls.DEFAULT_BACKOFF_MAX = value\n\n\n@six.add_metaclass(_RetryMeta)\nclass Retry(object):\n    \"\"\"Retry configuration.\n\n    Each retry attempt will create a new Retry object with updated values, so\n    they can be safely reused.\n\n    Retries can be defined as a default for a pool::\n\n        retries = Retry(connect=5, read=2, redirect=5)\n        http = PoolManager(retries=retries)\n        response = http.request('GET', 'http://example.com/')\n\n    Or per-request (which overrides the default for the pool)::\n\n        response = http.request('GET', 'http://example.com/', retries=Retry(10))\n\n    Retries can be disabled by passing ``False``::\n\n        response = http.request('GET', 'http://example.com/', retries=False)\n\n    Errors will be wrapped in :class:`~urllib3.exceptions.MaxRetryError` unless\n    retries are disabled, in which case the causing exception will be raised.\n\n    :param int total:\n        Total number of retries to allow. Takes precedence over other counts.\n\n        Set to ``None`` to remove this constraint and fall back on other\n        counts.\n\n        Set to ``0`` to fail on the first retry.\n\n        Set to ``False`` to disable and imply ``raise_on_redirect=False``.\n\n    :param int connect:\n        How many connection-related errors to retry on.\n\n        These are errors raised before the request is sent to the remote server,\n        which we assume has not triggered the server to process the request.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n    :param int read:\n        How many times to retry on read errors.\n\n        These errors are raised after the request was sent to the server, so the\n        request may have side-effects.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n    :param int redirect:\n        How many redirects to perform. Limit this to avoid infinite redirect\n        loops.\n\n        A redirect is a HTTP response with a status code 301, 302, 303, 307 or\n        308.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n        Set to ``False`` to disable and imply ``raise_on_redirect=False``.\n\n    :param int status:\n        How many times to retry on bad status codes.\n\n        These are retries made on responses, where status code matches\n        ``status_forcelist``.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n    :param int other:\n        How many times to retry on other errors.\n\n        Other errors are errors that are not connect, read, redirect or status errors.\n        These errors might be raised after the request was sent to the server, so the\n        request might have side-effects.\n\n        Set to ``0`` to fail on the first retry of this type.\n\n        If ``total`` is not set, it's a good idea to set this to 0 to account\n        for unexpected edge cases and avoid infinite retry loops.\n\n    :param iterable allowed_methods:\n        Set of uppercased HTTP method verbs that we should retry on.\n\n        By default, we only retry on methods which are considered to be\n        idempotent (multiple requests with the same parameters end with the\n        same state). See :attr:`Retry.DEFAULT_ALLOWED_METHODS`.\n\n        Set to a ``False`` value to retry on any verb.\n\n        .. warning::\n\n            Previously this parameter was named ``method_whitelist``, that\n            usage is deprecated in v1.26.0 and will be removed in v2.0.\n\n    :param iterable status_forcelist:\n        A set of integer HTTP status codes that we should force a retry on.\n        A retry is initiated if the request method is in ``allowed_methods``\n        and the response status code is in ``status_forcelist``.\n\n        By default, this is disabled with ``None``.\n\n    :param float backoff_factor:\n        A backoff factor to apply between attempts after the second try\n        (most errors are resolved immediately by a second try without a\n        delay). urllib3 will sleep for::\n\n            {backoff factor} * (2 ** ({number of total retries} - 1))\n\n        seconds. If the backoff_factor is 0.1, then :func:`.sleep` will sleep\n        for [0.0s, 0.2s, 0.4s, ...] between retries. It will never be longer\n        than :attr:`Retry.DEFAULT_BACKOFF_MAX`.\n\n        By default, backoff is disabled (set to 0).\n\n    :param bool raise_on_redirect: Whether, if the number of redirects is\n        exhausted, to raise a MaxRetryError, or to return a response with a\n        response code in the 3xx range.\n\n    :param bool raise_on_status: Similar meaning to ``raise_on_redirect``:\n        whether we should raise an exception, or return a response,\n        if status falls in ``status_forcelist`` range and retries have\n        been exhausted.\n\n    :param tuple history: The history of the request encountered during\n        each call to :meth:`~Retry.increment`. The list is in the order\n        the requests occurred. Each list item is of class :class:`RequestHistory`.\n\n    :param bool respect_retry_after_header:\n        Whether to respect Retry-After header on status codes defined as\n        :attr:`Retry.RETRY_AFTER_STATUS_CODES` or not.\n\n    :param iterable remove_headers_on_redirect:\n        Sequence of headers to remove from the request when a response\n        indicating a redirect is returned before firing off the redirected\n        request.\n    \"\"\"\n\n    #: Default methods to be used for ``allowed_methods``\n    DEFAULT_ALLOWED_METHODS = frozenset(\n        [\"HEAD\", \"GET\", \"PUT\", \"DELETE\", \"OPTIONS\", \"TRACE\"]\n    )\n\n    #: Default status codes to be used for ``status_forcelist``\n    RETRY_AFTER_STATUS_CODES = frozenset([413, 429, 503])\n\n    #: Default headers to be used for ``remove_headers_on_redirect``\n    DEFAULT_REMOVE_HEADERS_ON_REDIRECT = frozenset([\"Cookie\", \"Authorization\"])\n\n    #: Maximum backoff time.\n    DEFAULT_BACKOFF_MAX = 120\n\n    def __init__(\n        self,\n        total=10,\n        connect=None,\n        read=None,\n        redirect=None,\n        status=None,\n        other=None,\n        allowed_methods=_Default,\n        status_forcelist=None,\n        backoff_factor=0,\n        raise_on_redirect=True,\n        raise_on_status=True,\n        history=None,\n        respect_retry_after_header=True,\n        remove_headers_on_redirect=_Default,\n        # TODO: Deprecated, remove in v2.0\n        method_whitelist=_Default,\n    ):\n\n        if method_whitelist is not _Default:\n            if allowed_methods is not _Default:\n                raise ValueError(\n                    \"Using both 'allowed_methods' and \"\n                    \"'method_whitelist' together is not allowed. \"\n                    \"Instead only use 'allowed_methods'\"\n                )\n            warnings.warn(\n                \"Using 'method_whitelist' with Retry is deprecated and \"\n                \"will be removed in v2.0. Use 'allowed_methods' instead\",\n                DeprecationWarning,\n                stacklevel=2,\n            )\n            allowed_methods = method_whitelist\n        if allowed_methods is _Default:\n            allowed_methods = self.DEFAULT_ALLOWED_METHODS\n        if remove_headers_on_redirect is _Default:\n            remove_headers_on_redirect = self.DEFAULT_REMOVE_HEADERS_ON_REDIRECT\n\n        self.total = total\n        self.connect = connect\n        self.read = read\n        self.status = status\n        self.other = other\n\n        if redirect is False or total is False:\n            redirect = 0\n            raise_on_redirect = False\n\n        self.redirect = redirect\n        self.status_forcelist = status_forcelist or set()\n        self.allowed_methods = allowed_methods\n        self.backoff_factor = backoff_factor\n        self.raise_on_redirect = raise_on_redirect\n        self.raise_on_status = raise_on_status\n        self.history = history or tuple()\n        self.respect_retry_after_header = respect_retry_after_header\n        self.remove_headers_on_redirect = frozenset(\n            [h.lower() for h in remove_headers_on_redirect]\n        )\n\n    def new(self, **kw):\n        params = dict(\n            total=self.total,\n            connect=self.connect,\n            read=self.read,\n            redirect=self.redirect,\n            status=self.status,\n            other=self.other,\n            status_forcelist=self.status_forcelist,\n            backoff_factor=self.backoff_factor,\n            raise_on_redirect=self.raise_on_redirect,\n            raise_on_status=self.raise_on_status,\n            history=self.history,\n            remove_headers_on_redirect=self.remove_headers_on_redirect,\n            respect_retry_after_header=self.respect_retry_after_header,\n        )\n\n        # TODO: If already given in **kw we use what's given to us\n        # If not given we need to figure out what to pass. We decide\n        # based on whether our class has the 'method_whitelist' property\n        # and if so we pass the deprecated 'method_whitelist' otherwise\n        # we use 'allowed_methods'. Remove in v2.0\n        if \"method_whitelist\" not in kw and \"allowed_methods\" not in kw:\n            if \"method_whitelist\" in self.__dict__:\n                warnings.warn(\n                    \"Using 'method_whitelist' with Retry is deprecated and \"\n                    \"will be removed in v2.0. Use 'allowed_methods' instead\",\n                    DeprecationWarning,\n                )\n                params[\"method_whitelist\"] = self.allowed_methods\n            else:\n                params[\"allowed_methods\"] = self.allowed_methods\n\n        params.update(kw)\n        return type(self)(**params)\n\n    @classmethod\n    def from_int(cls, retries, redirect=True, default=None):\n        \"\"\"Backwards-compatibility for the old retries format.\"\"\"\n        if retries is None:\n            retries = default if default is not None else cls.DEFAULT\n\n        if isinstance(retries, Retry):\n            return retries\n\n        redirect = bool(redirect) and None\n        new_retries = cls(retries, redirect=redirect)\n        log.debug(\"Converted retries value: %r -> %r\", retries, new_retries)\n        return new_retries\n\n    def get_backoff_time(self):\n        \"\"\"Formula for computing the current backoff\n\n        :rtype: float\n        \"\"\"\n        # We want to consider only the last consecutive errors sequence (Ignore redirects).\n        consecutive_errors_len = len(\n            list(\n                takewhile(lambda x: x.redirect_location is None, reversed(self.history))\n            )\n        )\n        if consecutive_errors_len <= 1:\n            return 0\n\n        backoff_value = self.backoff_factor * (2 ** (consecutive_errors_len - 1))\n        return min(self.DEFAULT_BACKOFF_MAX, backoff_value)\n\n    def parse_retry_after(self, retry_after):\n        # Whitespace: https://tools.ietf.org/html/rfc7230#section-3.2.4\n        if re.match(r\"^\\s*[0-9]+\\s*$\", retry_after):\n            seconds = int(retry_after)\n        else:\n            retry_date_tuple = email.utils.parsedate_tz(retry_after)\n            if retry_date_tuple is None:\n                raise InvalidHeader(\"Invalid Retry-After header: %s\" % retry_after)\n            if retry_date_tuple[9] is None:  # Python 2\n                # Assume UTC if no timezone was specified\n                # On Python2.7, parsedate_tz returns None for a timezone offset\n                # instead of 0 if no timezone is given, where mktime_tz treats\n                # a None timezone offset as local time.\n                retry_date_tuple = retry_date_tuple[:9] + (0,) + retry_date_tuple[10:]\n\n            retry_date = email.utils.mktime_tz(retry_date_tuple)\n            seconds = retry_date - time.time()\n\n        if seconds < 0:\n            seconds = 0\n\n        return seconds\n\n    def get_retry_after(self, response):\n        \"\"\"Get the value of Retry-After in seconds.\"\"\"\n\n        retry_after = response.headers.get(\"Retry-After\")\n\n        if retry_after is None:\n            return None\n\n        return self.parse_retry_after(retry_after)\n\n    def sleep_for_retry(self, response=None):\n        retry_after = self.get_retry_after(response)\n        if retry_after:\n            time.sleep(retry_after)\n            return True\n\n        return False\n\n    def _sleep_backoff(self):\n        backoff = self.get_backoff_time()\n        if backoff <= 0:\n            return\n        time.sleep(backoff)\n\n    def sleep(self, response=None):\n        \"\"\"Sleep between retry attempts.\n\n        This method will respect a server's ``Retry-After`` response header\n        and sleep the duration of the time requested. If that is not present, it\n        will use an exponential backoff. By default, the backoff factor is 0 and\n        this method will return immediately.\n        \"\"\"\n\n        if self.respect_retry_after_header and response:\n            slept = self.sleep_for_retry(response)\n            if slept:\n                return\n\n        self._sleep_backoff()\n\n    def _is_connection_error(self, err):\n        \"\"\"Errors when we're fairly sure that the server did not receive the\n        request, so it should be safe to retry.\n        \"\"\"\n        if isinstance(err, ProxyError):\n            err = err.original_error\n        return isinstance(err, ConnectTimeoutError)\n\n    def _is_read_error(self, err):\n        \"\"\"Errors that occur after the request has been started, so we should\n        assume that the server began processing it.\n        \"\"\"\n        return isinstance(err, (ReadTimeoutError, ProtocolError))\n\n    def _is_method_retryable(self, method):\n        \"\"\"Checks if a given HTTP method should be retried upon, depending if\n        it is included in the allowed_methods\n        \"\"\"\n        # TODO: For now favor if the Retry implementation sets its own method_whitelist\n        # property outside of our constructor to avoid breaking custom implementations.\n        if \"method_whitelist\" in self.__dict__:\n            warnings.warn(\n                \"Using 'method_whitelist' with Retry is deprecated and \"\n                \"will be removed in v2.0. Use 'allowed_methods' instead\",\n                DeprecationWarning,\n            )\n            allowed_methods = self.method_whitelist\n        else:\n            allowed_methods = self.allowed_methods\n\n        if allowed_methods and method.upper() not in allowed_methods:\n            return False\n        return True\n\n    def is_retry(self, method, status_code, has_retry_after=False):\n        \"\"\"Is this method/status code retryable? (Based on allowlists and control\n        variables such as the number of total retries to allow, whether to\n        respect the Retry-After header, whether this header is present, and\n        whether the returned status code is on the list of status codes to\n        be retried upon on the presence of the aforementioned header)\n        \"\"\"\n        if not self._is_method_retryable(method):\n            return False\n\n        if self.status_forcelist and status_code in self.status_forcelist:\n            return True\n\n        return (\n            self.total\n            and self.respect_retry_after_header\n            and has_retry_after\n            and (status_code in self.RETRY_AFTER_STATUS_CODES)\n        )\n\n    def is_exhausted(self):\n        \"\"\"Are we out of retries?\"\"\"\n        retry_counts = (\n            self.total,\n            self.connect,\n            self.read,\n            self.redirect,\n            self.status,\n            self.other,\n        )\n        retry_counts = list(filter(None, retry_counts))\n        if not retry_counts:\n            return False\n\n        return min(retry_counts) < 0\n\n    def increment(\n        self,\n        method=None,\n        url=None,\n        response=None,\n        error=None,\n        _pool=None,\n        _stacktrace=None,\n    ):\n        \"\"\"Return a new Retry object with incremented retry counters.\n\n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.HTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n\n        :return: A new ``Retry`` object.\n        \"\"\"\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n            raise six.reraise(type(error), error, _stacktrace)\n\n        total = self.total\n        if total is not None:\n            total -= 1\n\n        connect = self.connect\n        read = self.read\n        redirect = self.redirect\n        status_count = self.status\n        other = self.other\n        cause = \"unknown\"\n        status = None\n        redirect_location = None\n\n        if error and self._is_connection_error(error):\n            # Connect retry?\n            if connect is False:\n                raise six.reraise(type(error), error, _stacktrace)\n            elif connect is not None:\n                connect -= 1\n\n        elif error and self._is_read_error(error):\n            # Read retry?\n            if read is False or not self._is_method_retryable(method):\n                raise six.reraise(type(error), error, _stacktrace)\n            elif read is not None:\n                read -= 1\n\n        elif error:\n            # Other retry?\n            if other is not None:\n                other -= 1\n\n        elif response and response.get_redirect_location():\n            # Redirect retry?\n            if redirect is not None:\n                redirect -= 1\n            cause = \"too many redirects\"\n            redirect_location = response.get_redirect_location()\n            status = response.status\n\n        else:\n            # Incrementing because of a server error like a 500 in\n            # status_forcelist and the given method is in the allowed_methods\n            cause = ResponseError.GENERIC_ERROR\n            if response and response.status:\n                if status_count is not None:\n                    status_count -= 1\n                cause = ResponseError.SPECIFIC_ERROR.format(status_code=response.status)\n                status = response.status\n\n        history = self.history + (\n            RequestHistory(method, url, error, status, redirect_location),\n        )\n\n        new_retry = self.new(\n            total=total,\n            connect=connect,\n            read=read,\n            redirect=redirect,\n            status=status_count,\n            other=other,\n            history=history,\n        )\n\n        if new_retry.is_exhausted():\n            raise MaxRetryError(_pool, url, error or ResponseError(cause))\n\n        log.debug(\"Incremented Retry for (url='%s'): %r\", url, new_retry)\n\n        return new_retry\n\n    def __repr__(self):\n        return (\n            \"{cls.__name__}(total={self.total}, connect={self.connect}, \"\n            \"read={self.read}, redirect={self.redirect}, status={self.status})\"\n        ).format(cls=type(self), self=self)\n\n    def __getattr__(self, item):\n        if item == \"method_whitelist\":\n            # TODO: Remove this deprecated alias in v2.0\n            warnings.warn(\n                \"Using 'method_whitelist' with Retry is deprecated and \"\n                \"will be removed in v2.0. Use 'allowed_methods' instead\",\n                DeprecationWarning,\n            )\n            return self.allowed_methods\n        try:\n            return getattr(super(Retry, self), item)\n        except AttributeError:\n            return getattr(Retry, item)\n\n\n# For backwards compatibility (equivalent to pre-v1.9):\nRetry.DEFAULT = Retry(3)\n", "import warnings\n\nimport mock\nimport pytest\n\nfrom urllib3.exceptions import (\n    ConnectTimeoutError,\n    InvalidHeader,\n    MaxRetryError,\n    ReadTimeoutError,\n    ResponseError,\n    SSLError,\n)\nfrom urllib3.packages import six\nfrom urllib3.packages.six.moves import xrange\nfrom urllib3.response import HTTPResponse\nfrom urllib3.util.retry import RequestHistory, Retry\n\n\n@pytest.fixture(scope=\"function\", autouse=True)\ndef no_retry_deprecations():\n    with warnings.catch_warnings(record=True) as w:\n        yield\n    assert len([str(x.message) for x in w if \"Retry\" in str(x.message)]) == 0\n\n\nclass TestRetry(object):\n    def test_string(self):\n        \"\"\"Retry string representation looks the way we expect\"\"\"\n        retry = Retry()\n        assert (\n            str(retry)\n            == \"Retry(total=10, connect=None, read=None, redirect=None, status=None)\"\n        )\n        for _ in range(3):\n            retry = retry.increment(method=\"GET\")\n        assert (\n            str(retry)\n            == \"Retry(total=7, connect=None, read=None, redirect=None, status=None)\"\n        )\n\n    def test_retry_both_specified(self):\n        \"\"\"Total can win if it's lower than the connect value\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=3, total=2)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=error)\n        assert e.value.reason == error\n\n    def test_retry_higher_total_loses(self):\n        \"\"\"A lower connect timeout than the total is honored\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=2, total=3)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(error=error)\n\n    def test_retry_higher_total_loses_vs_read(self):\n        \"\"\"A lower read timeout than the total is honored\"\"\"\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(read=2, total=3)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(method=\"GET\", error=error)\n\n    def test_retry_total_none(self):\n        \"\"\"if Total is none, connect error should take precedence\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=2, total=None)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=error)\n        assert e.value.reason == error\n\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(connect=2, total=None)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        assert not retry.is_exhausted()\n\n    def test_retry_default(self):\n        \"\"\"If no value is specified, should retry connects 3 times\"\"\"\n        retry = Retry()\n        assert retry.total == 10\n        assert retry.connect is None\n        assert retry.read is None\n        assert retry.redirect is None\n        assert retry.other is None\n\n        error = ConnectTimeoutError()\n        retry = Retry(connect=1)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(error=error)\n\n        retry = Retry(connect=1)\n        retry = retry.increment(error=error)\n        assert not retry.is_exhausted()\n\n        assert Retry(0).raise_on_redirect\n        assert not Retry(False).raise_on_redirect\n\n    def test_retry_other(self):\n        \"\"\"If an unexpected error is raised, should retry other times\"\"\"\n        other_error = SSLError()\n        retry = Retry(connect=1)\n        retry = retry.increment(error=other_error)\n        retry = retry.increment(error=other_error)\n        assert not retry.is_exhausted()\n\n        retry = Retry(other=1)\n        retry = retry.increment(error=other_error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=other_error)\n        assert e.value.reason == other_error\n\n    def test_retry_read_zero(self):\n        \"\"\"No second chances on read timeouts, by default\"\"\"\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(read=0)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(method=\"GET\", error=error)\n        assert e.value.reason == error\n\n    def test_status_counter(self):\n        resp = HTTPResponse(status=400)\n        retry = Retry(status=2)\n        retry = retry.increment(response=resp)\n        retry = retry.increment(response=resp)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(response=resp)\n        assert str(e.value.reason) == ResponseError.SPECIFIC_ERROR.format(\n            status_code=400\n        )\n\n    def test_backoff(self):\n        \"\"\"Backoff is computed correctly\"\"\"\n        max_backoff = Retry.DEFAULT_BACKOFF_MAX\n\n        retry = Retry(total=100, backoff_factor=0.2)\n        assert retry.get_backoff_time() == 0  # First request\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0  # First retry\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.backoff_factor == 0.2\n        assert retry.total == 98\n        assert retry.get_backoff_time() == 0.4  # Start backoff\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.8\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 1.6\n\n        for _ in xrange(10):\n            retry = retry.increment(method=\"GET\")\n\n        assert retry.get_backoff_time() == max_backoff\n\n    def test_zero_backoff(self):\n        retry = Retry()\n        assert retry.get_backoff_time() == 0\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0\n\n    def test_backoff_reset_after_redirect(self):\n        retry = Retry(total=100, redirect=5, backoff_factor=0.2)\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.4\n        redirect_response = HTTPResponse(status=302, headers={\"location\": \"test\"})\n        retry = retry.increment(method=\"GET\", response=redirect_response)\n        assert retry.get_backoff_time() == 0\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.4\n\n    def test_sleep(self):\n        # sleep a very small amount of time so our code coverage is happy\n        retry = Retry(backoff_factor=0.0001)\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        retry.sleep()\n\n    def test_status_forcelist(self):\n        retry = Retry(status_forcelist=xrange(500, 600))\n        assert not retry.is_retry(\"GET\", status_code=200)\n        assert not retry.is_retry(\"GET\", status_code=400)\n        assert retry.is_retry(\"GET\", status_code=500)\n\n        retry = Retry(total=1, status_forcelist=[418])\n        assert not retry.is_retry(\"GET\", status_code=400)\n        assert retry.is_retry(\"GET\", status_code=418)\n\n        # String status codes are not matched.\n        retry = Retry(total=1, status_forcelist=[\"418\"])\n        assert not retry.is_retry(\"GET\", status_code=418)\n\n    def test_allowed_methods_with_status_forcelist(self):\n        # Falsey allowed_methods means to retry on any method.\n        retry = Retry(status_forcelist=[500], allowed_methods=None)\n        assert retry.is_retry(\"GET\", status_code=500)\n        assert retry.is_retry(\"POST\", status_code=500)\n\n        # Criteria of allowed_methods and status_forcelist are ANDed.\n        retry = Retry(status_forcelist=[500], allowed_methods=[\"POST\"])\n        assert not retry.is_retry(\"GET\", status_code=500)\n        assert retry.is_retry(\"POST\", status_code=500)\n\n    def test_exhausted(self):\n        assert not Retry(0).is_exhausted()\n        assert Retry(-1).is_exhausted()\n        assert Retry(1).increment(method=\"GET\").total == 0\n\n    @pytest.mark.parametrize(\"total\", [-1, 0])\n    def test_disabled(self, total):\n        with pytest.raises(MaxRetryError):\n            Retry(total).increment(method=\"GET\")\n\n    def test_error_message(self):\n        retry = Retry(total=0)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\n                method=\"GET\", error=ReadTimeoutError(None, \"/\", \"read timed out\")\n            )\n        assert \"Caused by redirect\" not in str(e.value)\n        assert str(e.value.reason) == \"None: read timed out\"\n\n        retry = Retry(total=1)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\"POST\", \"/\")\n            retry = retry.increment(\"POST\", \"/\")\n        assert \"Caused by redirect\" not in str(e.value)\n        assert isinstance(e.value.reason, ResponseError)\n        assert str(e.value.reason) == ResponseError.GENERIC_ERROR\n\n        retry = Retry(total=1)\n        response = HTTPResponse(status=500)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\"POST\", \"/\", response=response)\n            retry = retry.increment(\"POST\", \"/\", response=response)\n        assert \"Caused by redirect\" not in str(e.value)\n        msg = ResponseError.SPECIFIC_ERROR.format(status_code=500)\n        assert str(e.value.reason) == msg\n\n        retry = Retry(connect=1)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(error=ConnectTimeoutError(\"conntimeout\"))\n            retry = retry.increment(error=ConnectTimeoutError(\"conntimeout\"))\n        assert \"Caused by redirect\" not in str(e.value)\n        assert str(e.value.reason) == \"conntimeout\"\n\n    def test_history(self):\n        retry = Retry(total=10, allowed_methods=frozenset([\"GET\", \"POST\"]))\n        assert retry.history == tuple()\n        connection_error = ConnectTimeoutError(\"conntimeout\")\n        retry = retry.increment(\"GET\", \"/test1\", None, connection_error)\n        history = (RequestHistory(\"GET\", \"/test1\", connection_error, None, None),)\n        assert retry.history == history\n\n        read_error = ReadTimeoutError(None, \"/test2\", \"read timed out\")\n        retry = retry.increment(\"POST\", \"/test2\", None, read_error)\n        history = (\n            RequestHistory(\"GET\", \"/test1\", connection_error, None, None),\n            RequestHistory(\"POST\", \"/test2\", read_error, None, None),\n        )\n        assert retry.history == history\n\n        response = HTTPResponse(status=500)\n        retry = retry.increment(\"GET\", \"/test3\", response, None)\n        history = (\n            RequestHistory(\"GET\", \"/test1\", connection_error, None, None),\n            RequestHistory(\"POST\", \"/test2\", read_error, None, None),\n            RequestHistory(\"GET\", \"/test3\", None, 500, None),\n        )\n        assert retry.history == history\n\n    def test_retry_method_not_in_whitelist(self):\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry()\n        with pytest.raises(ReadTimeoutError):\n            retry.increment(method=\"POST\", error=error)\n\n    def test_retry_default_remove_headers_on_redirect(self):\n        retry = Retry()\n\n        assert retry.remove_headers_on_redirect == {\"authorization\", \"cookie\"}\n\n    def test_retry_set_remove_headers_on_redirect(self):\n        retry = Retry(remove_headers_on_redirect=[\"X-API-Secret\"])\n\n        assert retry.remove_headers_on_redirect == {\"x-api-secret\"}\n\n    @pytest.mark.parametrize(\"value\", [\"-1\", \"+1\", \"1.0\", six.u(\"\\xb2\")])  # \\xb2 = ^2\n    def test_parse_retry_after_invalid(self, value):\n        retry = Retry()\n        with pytest.raises(InvalidHeader):\n            retry.parse_retry_after(value)\n\n    @pytest.mark.parametrize(\n        \"value, expected\", [(\"0\", 0), (\"1000\", 1000), (\"\\t42 \", 42)]\n    )\n    def test_parse_retry_after(self, value, expected):\n        retry = Retry()\n        assert retry.parse_retry_after(value) == expected\n\n    @pytest.mark.parametrize(\"respect_retry_after_header\", [True, False])\n    def test_respect_retry_after_header_propagated(self, respect_retry_after_header):\n\n        retry = Retry(respect_retry_after_header=respect_retry_after_header)\n        new_retry = retry.new()\n        assert new_retry.respect_retry_after_header == respect_retry_after_header\n\n    @pytest.mark.freeze_time(\"2019-06-03 11:00:00\", tz_offset=0)\n    @pytest.mark.parametrize(\n        \"retry_after_header,respect_retry_after_header,sleep_duration\",\n        [\n            (\"3600\", True, 3600),\n            (\"3600\", False, None),\n            # Will sleep due to header is 1 hour in future\n            (\"Mon, 3 Jun 2019 12:00:00 UTC\", True, 3600),\n            # Won't sleep due to not respecting header\n            (\"Mon, 3 Jun 2019 12:00:00 UTC\", False, None),\n            # Won't sleep due to current time reached\n            (\"Mon, 3 Jun 2019 11:00:00 UTC\", True, None),\n            # Won't sleep due to current time reached + not respecting header\n            (\"Mon, 3 Jun 2019 11:00:00 UTC\", False, None),\n            # Handle all the formats in RFC 7231 Section 7.1.1.1\n            (\"Mon, 03 Jun 2019 11:30:12 GMT\", True, 1812),\n            (\"Monday, 03-Jun-19 11:30:12 GMT\", True, 1812),\n            # Assume that datetimes without a timezone are in UTC per RFC 7231\n            (\"Mon Jun  3 11:30:12 2019\", True, 1812),\n        ],\n    )\n    @pytest.mark.parametrize(\n        \"stub_timezone\",\n        [\n            \"UTC\",\n            \"Asia/Jerusalem\",\n            None,\n        ],\n        indirect=True,\n    )\n    @pytest.mark.usefixtures(\"stub_timezone\")\n    def test_respect_retry_after_header_sleep(\n        self, retry_after_header, respect_retry_after_header, sleep_duration\n    ):\n        retry = Retry(respect_retry_after_header=respect_retry_after_header)\n\n        with mock.patch(\"time.sleep\") as sleep_mock:\n            # for the default behavior, it must be in RETRY_AFTER_STATUS_CODES\n            response = HTTPResponse(\n                status=503, headers={\"Retry-After\": retry_after_header}\n            )\n\n            retry.sleep(response)\n\n            # The expected behavior is that we'll only sleep if respecting\n            # this header (since we won't have any backoff sleep attempts)\n            if respect_retry_after_header and sleep_duration is not None:\n                sleep_mock.assert_called_with(sleep_duration)\n            else:\n                sleep_mock.assert_not_called()\n", "# This is a copy-paste of test_retry.py with extra asserts about deprecated options. It will be removed for v2.\nimport warnings\n\nimport mock\nimport pytest\n\nfrom urllib3.exceptions import (\n    ConnectTimeoutError,\n    InvalidHeader,\n    MaxRetryError,\n    ReadTimeoutError,\n    ResponseError,\n    SSLError,\n)\nfrom urllib3.packages import six\nfrom urllib3.packages.six.moves import xrange\nfrom urllib3.response import HTTPResponse\nfrom urllib3.util.retry import RequestHistory, Retry\n\n\n# TODO: Remove this entire file once deprecated Retry options are removed in v2.\n@pytest.fixture(scope=\"function\")\ndef expect_retry_deprecation():\n    with warnings.catch_warnings(record=True) as w:\n        yield\n    assert len([str(x.message) for x in w if \"Retry\" in str(x.message)]) > 0\n\n\nclass TestRetry(object):\n    def test_string(self):\n        \"\"\"Retry string representation looks the way we expect\"\"\"\n        retry = Retry()\n        assert (\n            str(retry)\n            == \"Retry(total=10, connect=None, read=None, redirect=None, status=None)\"\n        )\n        for _ in range(3):\n            retry = retry.increment(method=\"GET\")\n        assert (\n            str(retry)\n            == \"Retry(total=7, connect=None, read=None, redirect=None, status=None)\"\n        )\n\n    def test_retry_both_specified(self):\n        \"\"\"Total can win if it's lower than the connect value\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=3, total=2)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=error)\n        assert e.value.reason == error\n\n    def test_retry_higher_total_loses(self):\n        \"\"\"A lower connect timeout than the total is honored\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=2, total=3)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(error=error)\n\n    def test_retry_higher_total_loses_vs_read(self):\n        \"\"\"A lower read timeout than the total is honored\"\"\"\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(read=2, total=3)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(method=\"GET\", error=error)\n\n    def test_retry_total_none(self):\n        \"\"\"if Total is none, connect error should take precedence\"\"\"\n        error = ConnectTimeoutError()\n        retry = Retry(connect=2, total=None)\n        retry = retry.increment(error=error)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=error)\n        assert e.value.reason == error\n\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(connect=2, total=None)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        retry = retry.increment(method=\"GET\", error=error)\n        assert not retry.is_exhausted()\n\n    def test_retry_default(self):\n        \"\"\"If no value is specified, should retry connects 3 times\"\"\"\n        retry = Retry()\n        assert retry.total == 10\n        assert retry.connect is None\n        assert retry.read is None\n        assert retry.redirect is None\n        assert retry.other is None\n\n        error = ConnectTimeoutError()\n        retry = Retry(connect=1)\n        retry = retry.increment(error=error)\n        with pytest.raises(MaxRetryError):\n            retry.increment(error=error)\n\n        retry = Retry(connect=1)\n        retry = retry.increment(error=error)\n        assert not retry.is_exhausted()\n\n        assert Retry(0).raise_on_redirect\n        assert not Retry(False).raise_on_redirect\n\n    def test_retry_other(self):\n        \"\"\"If an unexpected error is raised, should retry other times\"\"\"\n        other_error = SSLError()\n        retry = Retry(connect=1)\n        retry = retry.increment(error=other_error)\n        retry = retry.increment(error=other_error)\n        assert not retry.is_exhausted()\n\n        retry = Retry(other=1)\n        retry = retry.increment(error=other_error)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(error=other_error)\n        assert e.value.reason == other_error\n\n    def test_retry_read_zero(self):\n        \"\"\"No second chances on read timeouts, by default\"\"\"\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry(read=0)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(method=\"GET\", error=error)\n        assert e.value.reason == error\n\n    def test_status_counter(self):\n        resp = HTTPResponse(status=400)\n        retry = Retry(status=2)\n        retry = retry.increment(response=resp)\n        retry = retry.increment(response=resp)\n        with pytest.raises(MaxRetryError) as e:\n            retry.increment(response=resp)\n        assert str(e.value.reason) == ResponseError.SPECIFIC_ERROR.format(\n            status_code=400\n        )\n\n    def test_backoff(self):\n        \"\"\"Backoff is computed correctly\"\"\"\n        max_backoff = Retry.DEFAULT_BACKOFF_MAX\n\n        retry = Retry(total=100, backoff_factor=0.2)\n        assert retry.get_backoff_time() == 0  # First request\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0  # First retry\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.backoff_factor == 0.2\n        assert retry.total == 98\n        assert retry.get_backoff_time() == 0.4  # Start backoff\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.8\n\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 1.6\n\n        for _ in xrange(10):\n            retry = retry.increment(method=\"GET\")\n\n        assert retry.get_backoff_time() == max_backoff\n\n    def test_zero_backoff(self):\n        retry = Retry()\n        assert retry.get_backoff_time() == 0\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0\n\n    def test_backoff_reset_after_redirect(self):\n        retry = Retry(total=100, redirect=5, backoff_factor=0.2)\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.4\n        redirect_response = HTTPResponse(status=302, headers={\"location\": \"test\"})\n        retry = retry.increment(method=\"GET\", response=redirect_response)\n        assert retry.get_backoff_time() == 0\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        assert retry.get_backoff_time() == 0.4\n\n    def test_sleep(self):\n        # sleep a very small amount of time so our code coverage is happy\n        retry = Retry(backoff_factor=0.0001)\n        retry = retry.increment(method=\"GET\")\n        retry = retry.increment(method=\"GET\")\n        retry.sleep()\n\n    def test_status_forcelist(self):\n        retry = Retry(status_forcelist=xrange(500, 600))\n        assert not retry.is_retry(\"GET\", status_code=200)\n        assert not retry.is_retry(\"GET\", status_code=400)\n        assert retry.is_retry(\"GET\", status_code=500)\n\n        retry = Retry(total=1, status_forcelist=[418])\n        assert not retry.is_retry(\"GET\", status_code=400)\n        assert retry.is_retry(\"GET\", status_code=418)\n\n        # String status codes are not matched.\n        retry = Retry(total=1, status_forcelist=[\"418\"])\n        assert not retry.is_retry(\"GET\", status_code=418)\n\n    def test_method_whitelist_with_status_forcelist(self, expect_retry_deprecation):\n        # Falsey method_whitelist means to retry on any method.\n        retry = Retry(status_forcelist=[500], method_whitelist=None)\n        assert retry.is_retry(\"GET\", status_code=500)\n        assert retry.is_retry(\"POST\", status_code=500)\n\n        # Criteria of method_whitelist and status_forcelist are ANDed.\n        retry = Retry(status_forcelist=[500], method_whitelist=[\"POST\"])\n        assert not retry.is_retry(\"GET\", status_code=500)\n        assert retry.is_retry(\"POST\", status_code=500)\n\n    def test_exhausted(self):\n        assert not Retry(0).is_exhausted()\n        assert Retry(-1).is_exhausted()\n        assert Retry(1).increment(method=\"GET\").total == 0\n\n    @pytest.mark.parametrize(\"total\", [-1, 0])\n    def test_disabled(self, total):\n        with pytest.raises(MaxRetryError):\n            Retry(total).increment(method=\"GET\")\n\n    def test_error_message(self):\n        retry = Retry(total=0)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\n                method=\"GET\", error=ReadTimeoutError(None, \"/\", \"read timed out\")\n            )\n        assert \"Caused by redirect\" not in str(e.value)\n        assert str(e.value.reason) == \"None: read timed out\"\n\n        retry = Retry(total=1)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\"POST\", \"/\")\n            retry = retry.increment(\"POST\", \"/\")\n        assert \"Caused by redirect\" not in str(e.value)\n        assert isinstance(e.value.reason, ResponseError)\n        assert str(e.value.reason) == ResponseError.GENERIC_ERROR\n\n        retry = Retry(total=1)\n        response = HTTPResponse(status=500)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(\"POST\", \"/\", response=response)\n            retry = retry.increment(\"POST\", \"/\", response=response)\n        assert \"Caused by redirect\" not in str(e.value)\n        msg = ResponseError.SPECIFIC_ERROR.format(status_code=500)\n        assert str(e.value.reason) == msg\n\n        retry = Retry(connect=1)\n        with pytest.raises(MaxRetryError) as e:\n            retry = retry.increment(error=ConnectTimeoutError(\"conntimeout\"))\n            retry = retry.increment(error=ConnectTimeoutError(\"conntimeout\"))\n        assert \"Caused by redirect\" not in str(e.value)\n        assert str(e.value.reason) == \"conntimeout\"\n\n    def test_history(self, expect_retry_deprecation):\n        retry = Retry(total=10, method_whitelist=frozenset([\"GET\", \"POST\"]))\n        assert retry.history == tuple()\n        connection_error = ConnectTimeoutError(\"conntimeout\")\n        retry = retry.increment(\"GET\", \"/test1\", None, connection_error)\n        history = (RequestHistory(\"GET\", \"/test1\", connection_error, None, None),)\n        assert retry.history == history\n\n        read_error = ReadTimeoutError(None, \"/test2\", \"read timed out\")\n        retry = retry.increment(\"POST\", \"/test2\", None, read_error)\n        history = (\n            RequestHistory(\"GET\", \"/test1\", connection_error, None, None),\n            RequestHistory(\"POST\", \"/test2\", read_error, None, None),\n        )\n        assert retry.history == history\n\n        response = HTTPResponse(status=500)\n        retry = retry.increment(\"GET\", \"/test3\", response, None)\n        history = (\n            RequestHistory(\"GET\", \"/test1\", connection_error, None, None),\n            RequestHistory(\"POST\", \"/test2\", read_error, None, None),\n            RequestHistory(\"GET\", \"/test3\", None, 500, None),\n        )\n        assert retry.history == history\n\n    def test_retry_method_not_in_whitelist(self):\n        error = ReadTimeoutError(None, \"/\", \"read timed out\")\n        retry = Retry()\n        with pytest.raises(ReadTimeoutError):\n            retry.increment(method=\"POST\", error=error)\n\n    def test_retry_default_remove_headers_on_redirect(self):\n        retry = Retry()\n\n        assert retry.remove_headers_on_redirect == {\"authorization\", \"cookie\"}\n\n    def test_retry_set_remove_headers_on_redirect(self):\n        retry = Retry(remove_headers_on_redirect=[\"X-API-Secret\"])\n\n        assert list(retry.remove_headers_on_redirect) == [\"x-api-secret\"]\n\n    @pytest.mark.parametrize(\"value\", [\"-1\", \"+1\", \"1.0\", six.u(\"\\xb2\")])  # \\xb2 = ^2\n    def test_parse_retry_after_invalid(self, value):\n        retry = Retry()\n        with pytest.raises(InvalidHeader):\n            retry.parse_retry_after(value)\n\n    @pytest.mark.parametrize(\n        \"value, expected\", [(\"0\", 0), (\"1000\", 1000), (\"\\t42 \", 42)]\n    )\n    def test_parse_retry_after(self, value, expected):\n        retry = Retry()\n        assert retry.parse_retry_after(value) == expected\n\n    @pytest.mark.parametrize(\"respect_retry_after_header\", [True, False])\n    def test_respect_retry_after_header_propagated(self, respect_retry_after_header):\n\n        retry = Retry(respect_retry_after_header=respect_retry_after_header)\n        new_retry = retry.new()\n        assert new_retry.respect_retry_after_header == respect_retry_after_header\n\n    @pytest.mark.freeze_time(\"2019-06-03 11:00:00\", tz_offset=0)\n    @pytest.mark.parametrize(\n        \"retry_after_header,respect_retry_after_header,sleep_duration\",\n        [\n            (\"3600\", True, 3600),\n            (\"3600\", False, None),\n            # Will sleep due to header is 1 hour in future\n            (\"Mon, 3 Jun 2019 12:00:00 UTC\", True, 3600),\n            # Won't sleep due to not respecting header\n            (\"Mon, 3 Jun 2019 12:00:00 UTC\", False, None),\n            # Won't sleep due to current time reached\n            (\"Mon, 3 Jun 2019 11:00:00 UTC\", True, None),\n            # Won't sleep due to current time reached + not respecting header\n            (\"Mon, 3 Jun 2019 11:00:00 UTC\", False, None),\n            # Handle all the formats in RFC 7231 Section 7.1.1.1\n            (\"Mon, 03 Jun 2019 11:30:12 GMT\", True, 1812),\n            (\"Monday, 03-Jun-19 11:30:12 GMT\", True, 1812),\n            # Assume that datetimes without a timezone are in UTC per RFC 7231\n            (\"Mon Jun  3 11:30:12 2019\", True, 1812),\n        ],\n    )\n    @pytest.mark.parametrize(\n        \"stub_timezone\",\n        [\n            \"UTC\",\n            \"Asia/Jerusalem\",\n            None,\n        ],\n        indirect=True,\n    )\n    @pytest.mark.usefixtures(\"stub_timezone\")\n    def test_respect_retry_after_header_sleep(\n        self, retry_after_header, respect_retry_after_header, sleep_duration\n    ):\n        retry = Retry(respect_retry_after_header=respect_retry_after_header)\n\n        with mock.patch(\"time.sleep\") as sleep_mock:\n            # for the default behavior, it must be in RETRY_AFTER_STATUS_CODES\n            response = HTTPResponse(\n                status=503, headers={\"Retry-After\": retry_after_header}\n            )\n\n            retry.sleep(response)\n\n            # The expected behavior is that we'll only sleep if respecting\n            # this header (since we won't have any backoff sleep attempts)\n            if respect_retry_after_header and sleep_duration is not None:\n                sleep_mock.assert_called_with(sleep_duration)\n            else:\n                sleep_mock.assert_not_called()\n\n\nclass TestRetryDeprecations(object):\n    def test_cls_get_default_method_whitelist(self, expect_retry_deprecation):\n        assert Retry.DEFAULT_ALLOWED_METHODS == Retry.DEFAULT_METHOD_WHITELIST\n\n    def test_cls_get_default_redirect_headers_blacklist(self, expect_retry_deprecation):\n        assert (\n            Retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT\n            == Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST\n        )\n\n    def test_cls_get_default_backoff_max(self, expect_retry_deprecation):\n        assert Retry.DEFAULT_BACKOFF_MAX == Retry.BACKOFF_MAX\n\n    def test_cls_set_default_method_whitelist(self, expect_retry_deprecation):\n        old_setting = Retry.DEFAULT_METHOD_WHITELIST\n        try:\n            Retry.DEFAULT_METHOD_WHITELIST = {\"GET\"}\n            retry = Retry()\n            assert retry.DEFAULT_ALLOWED_METHODS == {\"GET\"}\n            assert retry.DEFAULT_METHOD_WHITELIST == {\"GET\"}\n            assert retry.allowed_methods == {\"GET\"}\n            assert retry.method_whitelist == {\"GET\"}\n\n            # Test that the default can be overridden both ways\n            retry = Retry(allowed_methods={\"GET\", \"POST\"})\n            assert retry.DEFAULT_ALLOWED_METHODS == {\"GET\"}\n            assert retry.DEFAULT_METHOD_WHITELIST == {\"GET\"}\n            assert retry.allowed_methods == {\"GET\", \"POST\"}\n            assert retry.method_whitelist == {\"GET\", \"POST\"}\n\n            retry = Retry(method_whitelist={\"POST\"})\n            assert retry.DEFAULT_ALLOWED_METHODS == {\"GET\"}\n            assert retry.DEFAULT_METHOD_WHITELIST == {\"GET\"}\n            assert retry.allowed_methods == {\"POST\"}\n            assert retry.method_whitelist == {\"POST\"}\n        finally:\n            Retry.DEFAULT_METHOD_WHITELIST = old_setting\n            assert Retry.DEFAULT_ALLOWED_METHODS == old_setting\n\n    def test_cls_set_default_redirect_headers_blacklist(self, expect_retry_deprecation):\n        old_setting = Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST\n        try:\n            Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST = {\"test\"}\n            retry = Retry()\n            assert retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT == {\"test\"}\n            assert retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST == {\"test\"}\n            assert retry.remove_headers_on_redirect == {\"test\"}\n            assert retry.remove_headers_on_redirect == {\"test\"}\n\n            retry = Retry(remove_headers_on_redirect={\"test2\"})\n            assert retry.DEFAULT_REMOVE_HEADERS_ON_REDIRECT == {\"test\"}\n            assert retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST == {\"test\"}\n            assert retry.remove_headers_on_redirect == {\"test2\"}\n            assert retry.remove_headers_on_redirect == {\"test2\"}\n        finally:\n            Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST = old_setting\n            assert Retry.DEFAULT_REDIRECT_HEADERS_BLACKLIST == old_setting\n\n    def test_cls_set_default_backoff_max(self, expect_retry_deprecation):\n        old_setting = Retry.BACKOFF_MAX\n        try:\n            Retry.BACKOFF_MAX = 99\n            retry = Retry()\n            assert retry.DEFAULT_BACKOFF_MAX == 99\n            assert retry.BACKOFF_MAX == 99\n        finally:\n            Retry.BACKOFF_MAX = old_setting\n            assert Retry.BACKOFF_MAX == old_setting\n\n    @pytest.mark.parametrize(\n        \"options\", [(None, None), ({\"GET\"}, None), (None, {\"GET\"}), ({\"GET\"}, {\"GET\"})]\n    )\n    def test_retry_allowed_methods_and_method_whitelist_error(self, options):\n        with pytest.raises(ValueError) as e:\n            Retry(allowed_methods=options[0], method_whitelist=options[1])\n        assert str(e.value) == (\n            \"Using both 'allowed_methods' and 'method_whitelist' together \"\n            \"is not allowed. Instead only use 'allowed_methods'\"\n        )\n\n    def test_retry_subclass_that_sets_method_whitelist(self, expect_retry_deprecation):\n        class SubclassRetry(Retry):\n            def __init__(self, **kwargs):\n                if \"allowed_methods\" in kwargs:\n                    raise AssertionError(\n                        \"This subclass likely doesn't use 'allowed_methods'\"\n                    )\n\n                super(SubclassRetry, self).__init__(**kwargs)\n\n                # Since we're setting 'method_whiteist' we get fallbacks\n                # within Retry.new() and Retry._is_method_retryable()\n                # to use 'method_whitelist' instead of 'allowed_methods'\n                self.method_whitelist = self.method_whitelist | {\"POST\"}\n\n        retry = SubclassRetry()\n        assert retry.method_whitelist == Retry.DEFAULT_ALLOWED_METHODS | {\"POST\"}\n        assert retry.new(read=0).method_whitelist == retry.method_whitelist\n        assert retry._is_method_retryable(\"POST\")\n        assert not retry._is_method_retryable(\"CONNECT\")\n\n        assert retry.new(method_whitelist={\"GET\"}).method_whitelist == {\"GET\", \"POST\"}\n\n        # urllib3 doesn't do this during normal operation\n        # so we don't want users passing in 'allowed_methods'\n        # when their subclass doesn't support the option yet.\n        with pytest.raises(AssertionError) as e:\n            retry.new(allowed_methods={\"GET\"})\n        assert str(e.value) == \"This subclass likely doesn't use 'allowed_methods'\"\n", "import json\nfrom test import LONG_TIMEOUT\n\nimport pytest\n\nfrom dummyserver.server import HAS_IPV6\nfrom dummyserver.testcase import HTTPDummyServerTestCase, IPv6HTTPDummyServerTestCase\nfrom urllib3.connectionpool import port_by_scheme\nfrom urllib3.exceptions import MaxRetryError, URLSchemeUnknown\nfrom urllib3.poolmanager import PoolManager\nfrom urllib3.util.retry import Retry\n\n# Retry failed tests\npytestmark = pytest.mark.flaky\n\n\nclass TestPoolManager(HTTPDummyServerTestCase):\n    @classmethod\n    def setup_class(cls):\n        super(TestPoolManager, cls).setup_class()\n        cls.base_url = \"http://%s:%d\" % (cls.host, cls.port)\n        cls.base_url_alt = \"http://%s:%d\" % (cls.host_alt, cls.port)\n\n    def test_redirect(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/\" % self.base_url},\n                redirect=False,\n            )\n\n            assert r.status == 303\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/\" % self.base_url},\n            )\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_redirect_twice(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/redirect\" % self.base_url},\n                redirect=False,\n            )\n\n            assert r.status == 303\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\n                    \"target\": \"%s/redirect?target=%s/\" % (self.base_url, self.base_url)\n                },\n            )\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_redirect_to_relative_url(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"/redirect\"},\n                redirect=False,\n            )\n\n            assert r.status == 303\n\n            r = http.request(\n                \"GET\", \"%s/redirect\" % self.base_url, fields={\"target\": \"/redirect\"}\n            )\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_cross_host_redirect(self):\n        with PoolManager() as http:\n            cross_host_location = \"%s/echo?a=b\" % self.base_url_alt\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.base_url,\n                    fields={\"target\": cross_host_location},\n                    timeout=LONG_TIMEOUT,\n                    retries=0,\n                )\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/echo?a=b\" % self.base_url_alt},\n                timeout=LONG_TIMEOUT,\n                retries=1,\n            )\n\n            assert r._pool.host == self.host_alt\n\n    def test_too_many_redirects(self):\n        with PoolManager() as http:\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.base_url,\n                    fields={\n                        \"target\": \"%s/redirect?target=%s/\"\n                        % (self.base_url, self.base_url)\n                    },\n                    retries=1,\n                    preload_content=False,\n                )\n\n            with pytest.raises(MaxRetryError):\n                http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.base_url,\n                    fields={\n                        \"target\": \"%s/redirect?target=%s/\"\n                        % (self.base_url, self.base_url)\n                    },\n                    retries=Retry(total=None, redirect=1),\n                    preload_content=False,\n                )\n\n            # Even with preload_content=False and raise on redirects, we reused the same\n            # connection\n            assert len(http.pools) == 1\n            pool = http.connection_from_host(self.host, self.port)\n            assert pool.num_connections == 1\n\n    def test_redirect_cross_host_remove_headers(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\"Authorization\": \"foo\", \"Cookie\": \"foo=bar\"},\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert \"Authorization\" not in data\n            assert \"Cookie\" not in data\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\"authorization\": \"foo\", \"cookie\": \"foo=bar\"},\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert \"authorization\" not in data\n            assert \"Authorization\" not in data\n            assert \"cookie\" not in data\n            assert \"Cookie\" not in data\n\n    def test_redirect_cross_host_no_remove_headers(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\"Authorization\": \"foo\", \"Cookie\": \"foo=bar\"},\n                retries=Retry(remove_headers_on_redirect=[]),\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert data[\"Authorization\"] == \"foo\"\n            assert data[\"Cookie\"] == \"foo=bar\"\n\n    def test_redirect_cross_host_set_removed_headers(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\n                    \"X-API-Secret\": \"foo\",\n                    \"Authorization\": \"bar\",\n                    \"Cookie\": \"foo=bar\",\n                },\n                retries=Retry(remove_headers_on_redirect=[\"X-API-Secret\"]),\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert \"X-API-Secret\" not in data\n            assert data[\"Authorization\"] == \"bar\"\n            assert data[\"Cookie\"] == \"foo=bar\"\n\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": \"%s/headers\" % self.base_url_alt},\n                headers={\n                    \"x-api-secret\": \"foo\",\n                    \"authorization\": \"bar\",\n                    \"cookie\": \"foo=bar\",\n                },\n                retries=Retry(remove_headers_on_redirect=[\"X-API-Secret\"]),\n            )\n\n            assert r.status == 200\n\n            data = json.loads(r.data.decode(\"utf-8\"))\n\n            assert \"x-api-secret\" not in data\n            assert \"X-API-Secret\" not in data\n            assert data[\"Authorization\"] == \"bar\"\n            assert data[\"Cookie\"] == \"foo=bar\"\n\n    def test_redirect_without_preload_releases_connection(self):\n        with PoolManager(block=True, maxsize=2) as http:\n            r = http.request(\n                \"GET\", \"%s/redirect\" % self.base_url, preload_content=False\n            )\n            assert r._pool.num_requests == 2\n            assert r._pool.num_connections == 1\n            assert len(http.pools) == 1\n\n    def test_unknown_scheme(self):\n        with PoolManager() as http:\n            unknown_scheme = \"unknown\"\n            unknown_scheme_url = \"%s://host\" % unknown_scheme\n            with pytest.raises(URLSchemeUnknown) as e:\n                r = http.request(\"GET\", unknown_scheme_url)\n            assert e.value.scheme == unknown_scheme\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\"target\": unknown_scheme_url},\n                redirect=False,\n            )\n            assert r.status == 303\n            assert r.headers.get(\"Location\") == unknown_scheme_url\n            with pytest.raises(URLSchemeUnknown) as e:\n                r = http.request(\n                    \"GET\",\n                    \"%s/redirect\" % self.base_url,\n                    fields={\"target\": unknown_scheme_url},\n                )\n            assert e.value.scheme == unknown_scheme\n\n    def test_raise_on_redirect(self):\n        with PoolManager() as http:\n            r = http.request(\n                \"GET\",\n                \"%s/redirect\" % self.base_url,\n                fields={\n                    \"target\": \"%s/redirect?target=%s/\" % (self.base_url, self.base_url)\n                },\n                retries=Retry(total=None, redirect=1, raise_on_redirect=False),\n            )\n\n            assert r.status == 303\n\n    def test_raise_on_status(self):\n        with PoolManager() as http:\n            with pytest.raises(MaxRetryError):\n                # the default is to raise\n                r = http.request(\n                    \"GET\",\n                    \"%s/status\" % self.base_url,\n                    fields={\"status\": \"500 Internal Server Error\"},\n                    retries=Retry(total=1, status_forcelist=range(500, 600)),\n                )\n\n            with pytest.raises(MaxRetryError):\n                # raise explicitly\n                r = http.request(\n                    \"GET\",\n                    \"%s/status\" % self.base_url,\n                    fields={\"status\": \"500 Internal Server Error\"},\n                    retries=Retry(\n                        total=1, status_forcelist=range(500, 600), raise_on_status=True\n                    ),\n                )\n\n            # don't raise\n            r = http.request(\n                \"GET\",\n                \"%s/status\" % self.base_url,\n                fields={\"status\": \"500 Internal Server Error\"},\n                retries=Retry(\n                    total=1, status_forcelist=range(500, 600), raise_on_status=False\n                ),\n            )\n\n            assert r.status == 500\n\n    def test_missing_port(self):\n        # Can a URL that lacks an explicit port like ':80' succeed, or\n        # will all such URLs fail with an error?\n\n        with PoolManager() as http:\n            # By globally adjusting `port_by_scheme` we pretend for a moment\n            # that HTTP's default port is not 80, but is the port at which\n            # our test server happens to be listening.\n            port_by_scheme[\"http\"] = self.port\n            try:\n                r = http.request(\"GET\", \"http://%s/\" % self.host, retries=0)\n            finally:\n                port_by_scheme[\"http\"] = 80\n\n            assert r.status == 200\n            assert r.data == b\"Dummy server!\"\n\n    def test_headers(self):\n        with PoolManager(headers={\"Foo\": \"bar\"}) as http:\n            r = http.request(\"GET\", \"%s/headers\" % self.base_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n\n            r = http.request(\"POST\", \"%s/headers\" % self.base_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n\n            r = http.request_encode_url(\"GET\", \"%s/headers\" % self.base_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n\n            r = http.request_encode_body(\"POST\", \"%s/headers\" % self.base_url)\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") == \"bar\"\n\n            r = http.request_encode_url(\n                \"GET\", \"%s/headers\" % self.base_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n\n            r = http.request_encode_body(\n                \"GET\", \"%s/headers\" % self.base_url, headers={\"Baz\": \"quux\"}\n            )\n            returned_headers = json.loads(r.data.decode())\n            assert returned_headers.get(\"Foo\") is None\n            assert returned_headers.get(\"Baz\") == \"quux\"\n\n    def test_http_with_ssl_keywords(self):\n        with PoolManager(ca_certs=\"REQUIRED\") as http:\n            r = http.request(\"GET\", \"http://%s:%s/\" % (self.host, self.port))\n            assert r.status == 200\n\n    def test_http_with_server_hostname(self):\n        with PoolManager(server_hostname=\"example.com\") as http:\n            r = http.request(\"GET\", \"http://%s:%s/\" % (self.host, self.port))\n            assert r.status == 200\n\n    def test_http_with_ca_cert_dir(self):\n        with PoolManager(ca_certs=\"REQUIRED\", ca_cert_dir=\"/nosuchdir\") as http:\n            r = http.request(\"GET\", \"http://%s:%s/\" % (self.host, self.port))\n            assert r.status == 200\n\n    @pytest.mark.parametrize(\n        [\"target\", \"expected_target\"],\n        [\n            (\"/echo_uri?q=1#fragment\", b\"/echo_uri?q=1\"),\n            (\"/echo_uri?#\", b\"/echo_uri?\"),\n            (\"/echo_uri#?\", b\"/echo_uri\"),\n            (\"/echo_uri#?#\", b\"/echo_uri\"),\n            (\"/echo_uri??#\", b\"/echo_uri??\"),\n            (\"/echo_uri?%3f#\", b\"/echo_uri?%3F\"),\n            (\"/echo_uri?%3F#\", b\"/echo_uri?%3F\"),\n            (\"/echo_uri?[]\", b\"/echo_uri?%5B%5D\"),\n        ],\n    )\n    def test_encode_http_target(self, target, expected_target):\n        with PoolManager() as http:\n            url = \"http://%s:%d%s\" % (self.host, self.port, target)\n            r = http.request(\"GET\", url)\n            assert r.data == expected_target\n\n\n@pytest.mark.skipif(not HAS_IPV6, reason=\"IPv6 is not supported on this system\")\nclass TestIPv6PoolManager(IPv6HTTPDummyServerTestCase):\n    @classmethod\n    def setup_class(cls):\n        super(TestIPv6PoolManager, cls).setup_class()\n        cls.base_url = \"http://[%s]:%d\" % (cls.host, cls.port)\n\n    def test_ipv6(self):\n        with PoolManager() as http:\n            http.request(\"GET\", self.base_url)\n"], "filenames": ["CHANGES.rst", "src/urllib3/util/retry.py", "test/test_retry.py", "test/test_retry_deprecated.py", "test/with_dummyserver/test_poolmanager.py"], "buggy_code_start_loc": [2, 238, 296, 298, 144], "buggy_code_end_loc": [2, 239, 302, 299, 214], "fixing_code_start_loc": [3, 238, 296, 298, 144], "fixing_code_end_loc": [9, 239, 302, 299, 229], "type": "CWE-200", "message": "urllib3 is a user-friendly HTTP client library for Python. urllib3 doesn't treat the `Cookie` HTTP header special or provide any helpers for managing cookies over HTTP, that is the responsibility of the user. However, it is possible for a user to specify a `Cookie` header and unknowingly leak information via HTTP redirects to a different origin if that user doesn't disable redirects explicitly. This issue has been patched in urllib3 version 1.26.17 or 2.0.5.", "other": {"cve": {"id": "CVE-2023-43804", "sourceIdentifier": "security-advisories@github.com", "published": "2023-10-04T17:15:10.163", "lastModified": "2024-02-01T00:55:23.317", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "urllib3 is a user-friendly HTTP client library for Python. urllib3 doesn't treat the `Cookie` HTTP header special or provide any helpers for managing cookies over HTTP, that is the responsibility of the user. However, it is possible for a user to specify a `Cookie` header and unknowingly leak information via HTTP redirects to a different origin if that user doesn't disable redirects explicitly. This issue has been patched in urllib3 version 1.26.17 or 2.0.5."}, {"lang": "es", "value": "urllib3 es una librer\u00eda cliente HTTP f\u00e1cil de usar para Python. urllib3 no trata el encabezado HTTP \"Cookie\" de manera especial ni proporciona ayuda para administrar las cookies a trav\u00e9s de HTTP, eso es responsabilidad del usuario. Sin embargo, es posible que un usuario especifique un encabezado \"Cookie\" y, sin saberlo, filtre informaci\u00f3n a trav\u00e9s de redireccionamientos HTTP a un origen diferente si ese usuario no deshabilita los redireccionamientos expl\u00edcitamente. Este problema se solucion\u00f3 en urllib3 versi\u00f3n 1.26.17 o 2.0.5."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:H/UI:N/S:U/C:H/I:H/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "HIGH", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 5.9, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 0.7, "impactScore": 5.2}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-200"}]}, {"source": "nvd@nist.gov", "type": "Secondary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:python:urllib3:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.26.17", "matchCriteriaId": "97C54576-30ED-41C6-817B-E40030A06A69"}, {"vulnerable": true, "criteria": "cpe:2.3:a:python:urllib3:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.0.0", "versionEndExcluding": "2.0.6", "matchCriteriaId": "59C45894-31CB-46E5-B085-986EC7223245"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B237A9-69A3-4A9C-9DA0-4E06BD37AE73"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:37:*:*:*:*:*:*:*", "matchCriteriaId": "E30D0E6F-4AE8-4284-8716-991DFA48CC5D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:38:*:*:*:*:*:*:*", "matchCriteriaId": "CC559B26-5DFC-4B7A-A27C-B77DE755DFF9"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:39:*:*:*:*:*:*:*", "matchCriteriaId": "B8EDB836-4E6A-4B71-B9B2-AA3E03E0F646"}]}]}], "references": [{"url": "https://github.com/urllib3/urllib3/commit/01220354d389cd05474713f8c982d05c9b17aafb", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/urllib3/urllib3/commit/644124ecd0b6e417c527191f866daa05a5a2056d", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/urllib3/urllib3/security/advisories/GHSA-v845-jxx5-vc9f", "source": "security-advisories@github.com", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2023/10/msg00012.html", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/5F5CUBAN5XMEBVBZPHFITBLMJV5FIJJ5/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/I3PR7C6RJ6JUBQKIJ644DMIJSUP36VDY/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/NDAGZXYJ7H2G3SB47M453VQVNAWKAEJJ/", "source": "security-advisories@github.com", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/urllib3/urllib3/commit/01220354d389cd05474713f8c982d05c9b17aafb"}}
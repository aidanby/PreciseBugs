{"buggy_code": ["# -*-python-*-\n#\n# Copyright (C) 1999-2020 The ViewCVS Group. All Rights Reserved.\n#\n# By using this file, you agree to the terms and conditions set forth in\n# the LICENSE.html file which can be found at the top level of the ViewVC\n# distribution or at http://viewvc.org/license-1.html.\n#\n# For more information, visit http://viewvc.org/\n#\n# -----------------------------------------------------------------------\n#\n# viewvc: View CVS/SVN repositories via a web browser\n#\n# -----------------------------------------------------------------------\n\n__version__ = '1.2.1-dev'\n\n# this comes from our library; measure the startup time\nimport debug\ndebug.t_start('startup')\ndebug.t_start('imports')\n\n# standard modules that we know are in the path or builtin\nimport sys\nimport os\nimport calendar\nimport copy\nimport fnmatch\nimport gzip\nimport mimetypes\nimport re\nimport rfc822\nimport stat\nimport struct\nimport tempfile\nimport time\nimport types\nimport urllib\n\n# These modules come from our library (the stub has set up the path)\nfrom common import _item, _RCSDIFF_NO_CHANGES, _RCSDIFF_IS_BINARY, _RCSDIFF_ERROR, TemplateData\nimport accept\nimport config\nimport ezt\nimport popen\nimport sapi\nimport vcauth\nimport vclib\nimport vclib.ccvs\nimport vclib.svn\n\ntry:\n  import idiff\nexcept (SyntaxError, ImportError):\n  idiff = None\n\ndebug.t_end('imports')\n\n# Initialize the system tracebacklimit value to 0, meaning stack\n# traces will carry only the top-level exception string.  This can be\n# overridden via configuration.\nsys.tracebacklimit = 0\n\n#########################################################################\n\ncheckout_magic_path = '*checkout*'\n# According to RFC 1738 the '~' character is unsafe in URLs.\n# But for compatibility with URLs bookmarked with old releases of ViewCVS:\noldstyle_checkout_magic_path = '~checkout~'\ndocroot_magic_path = '*docroot*'\nviewcvs_mime_type = 'text/vnd.viewcvs-markup'\nalt_mime_type = 'text/x-cvsweb-markup'\nview_roots_magic = '*viewroots*'\n\n# Put here the variables we need in order to hold our state - they\n# will be added (with their current value) to (almost) any link/query\n# string you construct.\n_sticky_vars = [\n  'hideattic',\n  'sortby',\n  'sortdir',\n  'logsort',\n  'diff_format',\n  'search',\n  'limit_changes',\n  ]\n\n# for reading/writing between a couple descriptors\nCHUNK_SIZE = 8192\n\n# special characters that don't need to be URL encoded\n_URL_SAFE_CHARS = \"/*~\"\n\n\nclass Request:\n  def __init__(self, server, cfg):\n    self.server = server\n    self.cfg = cfg\n\n    self.script_name = _normalize_path(server.getenv('SCRIPT_NAME', ''))\n    self.browser = server.getenv('HTTP_USER_AGENT', 'unknown')\n\n    # process the Accept-Language: header, and load the key/value\n    # files, given the selected language\n    hal = server.getenv('HTTP_ACCEPT_LANGUAGE','')\n    try:\n      self.lang_selector = accept.language(hal)\n    except accept.AcceptLanguageParseError:\n      self.lang_selector = accept.language('en')\n    self.language = self.lang_selector.select_from(cfg.general.languages)\n    self.kv = cfg.load_kv_files(self.language)\n\n    # check for an authenticated username\n    self.username = server.getenv('REMOTE_USER')\n\n    # if we allow compressed output, see if the client does too\n    self.gzip_compress_level = 0\n    if cfg.options.allow_compress:\n      http_accept_encoding = os.environ.get(\"HTTP_ACCEPT_ENCODING\", \"\")\n      if \"gzip\" in filter(None,\n                          map(lambda x: x.strip(),\n                              http_accept_encoding.split(','))):\n        self.gzip_compress_level = 9  # make this configurable?\n\n  def run_viewvc(self):\n\n    cfg = self.cfg\n\n    # This function first parses the query string and sets the following\n    # variables. Then it executes the request.\n    self.view_func = None  # function to call to process the request\n    self.repos = None      # object representing current repository\n    self.rootname = None   # name of current root (as used in viewvc.conf)\n    self.roottype = None   # current root type ('svn' or 'cvs')\n    self.rootpath = None   # physical path to current root\n    self.pathtype = None   # type of path, either vclib.FILE or vclib.DIR\n    self.where = None      # path to file or directory in current root\n    self.query_dict = {}   # validated and cleaned up query options\n    self.path_parts = None # for convenience, equals where.split('/')\n    self.pathrev = None    # current path revision or tag\n    self.auth = None       # authorizer module in use\n\n    # redirect if we're loading from a valid but irregular URL\n    # These redirects aren't neccessary to make ViewVC work, it functions\n    # just fine without them, but they make it easier for server admins to\n    # implement access restrictions based on URL\n    needs_redirect = 0\n\n    # Process the query params\n    for name, values in self.server.params().items():\n      # we only care about the first value\n      value = values[0]\n      \n      # patch up old queries that use 'cvsroot' to look like they used 'root'\n      if name == 'cvsroot':\n        name = 'root'\n        needs_redirect = 1\n\n      # same for 'only_with_tag' and 'pathrev'\n      if name == 'only_with_tag':\n        name = 'pathrev'\n        needs_redirect = 1\n\n      # redirect view=rev to view=revision, too\n      if name == 'view' and value == 'rev':\n        value = 'revision'\n        needs_redirect = 1\n\n      # validate the parameter\n      _validate_param(name, value)\n      \n      # if we're here, then the parameter is okay\n      self.query_dict[name] = value\n\n    # Resolve the view parameter into a handler function.\n    self.view_func = _views.get(self.query_dict.get('view', None), \n                                self.view_func)\n\n    # Process PATH_INFO component of query string\n    path_info = self.server.getenv('PATH_INFO', '')\n\n    # clean it up. this removes duplicate '/' characters and any that may\n    # exist at the front or end of the path.\n    ### we might want to redirect to the cleaned up URL\n    path_parts = _path_parts(path_info)\n\n    if path_parts:\n      # handle magic path prefixes\n      if path_parts[0] == docroot_magic_path:\n        # if this is just a simple hunk of doc, then serve it up\n        self.where = _path_join(path_parts[1:])\n        return view_doc(self)\n      elif path_parts[0] in (checkout_magic_path,\n                             oldstyle_checkout_magic_path):\n        path_parts.pop(0)\n        self.view_func = view_checkout\n        if not cfg.options.checkout_magic:\n          needs_redirect = 1\n\n      # handle tarball magic suffixes\n      if self.view_func is download_tarball:\n        if (self.query_dict.get('parent')):\n          del path_parts[-1]\n        elif path_parts[-1][-7:] == \".tar.gz\":\n          path_parts[-1] = path_parts[-1][:-7]\n\n    # Figure out root name\n    self.rootname = self.query_dict.get('root')\n    if self.rootname == view_roots_magic:\n      del self.query_dict['root']\n      self.rootname = \"\"\n      needs_redirect = 1\n    elif self.rootname is None:\n      if cfg.options.root_as_url_component:\n        if path_parts:\n          roottype, rootpath, self.rootname, new_path_parts = \\\n                  locate_root_from_path(cfg, path_parts)\n          if roottype is None:\n            # Perhaps the root name is candidate for renaming...\n            # Take care of old-new roots mapping\n            for old_root, new_root in cfg.general.renamed_roots.iteritems():\n              pp = _path_parts(old_root)\n              if _path_starts_with(path_parts, pp):\n                path_parts = path_parts[len(pp):]\n                self.rootname = new_root\n                needs_redirect = 1\n            if self.rootname is None:\n              # Not found; interpret whole path as root, to show as error\n              self.rootname = _path_join(path_parts)\n              path_parts = []\n          else:\n            path_parts = new_path_parts\n        else:\n          self.rootname = \"\"\n      elif self.view_func != view_roots:\n        self.rootname = cfg.general.default_root\n    elif cfg.options.root_as_url_component:\n      needs_redirect = 1\n\n    # Take care of old-new roots mapping\n    for old_root, new_root in cfg.general.renamed_roots.iteritems():\n      if self.rootname == old_root:\n        self.rootname = new_root\n        needs_redirect = 1\n\n    self.where = _path_join(path_parts)\n    self.path_parts = path_parts\n\n    if self.rootname:\n      roottype, rootpath = locate_root(cfg, self.rootname)\n      if roottype:\n        # Overlay root-specific options.\n        cfg.overlay_root_options(self.rootname)\n        \n        # Setup an Authorizer for this rootname and username\n        debug.t_start('setup-authorizer')\n        self.auth = setup_authorizer(cfg, self.username)\n        debug.t_end('setup-authorizer')\n\n        # Create the repository object\n        debug.t_start('select-repos')\n        try:\n          if roottype == 'cvs':\n            self.rootpath = vclib.ccvs.canonicalize_rootpath(rootpath)\n            self.repos = vclib.ccvs.CVSRepository(self.rootname,\n                                                  self.rootpath,\n                                                  self.auth,\n                                                  cfg.utilities,\n                                                  cfg.options.use_rcsparse)\n            # required so that spawned rcs programs correctly expand\n            # $CVSHeader$\n            os.environ['CVSROOT'] = self.rootpath\n          elif roottype == 'svn':\n            self.rootpath = vclib.svn.canonicalize_rootpath(rootpath)\n            self.repos = vclib.svn.SubversionRepository(self.rootname,\n                                                        self.rootpath,\n                                                        self.auth,\n                                                        cfg.utilities,\n                                                        cfg.options.svn_config_dir)\n          else:\n            raise vclib.ReposNotFound()\n        except vclib.ReposNotFound:\n          pass\n        debug.t_end('select-repos')\n      if self.repos is None:\n        raise debug.ViewVCException(\n          'The root \"%s\" is unknown. If you believe the value is '\n          'correct, then please double-check your configuration.'\n          % self.rootname, \"404 Not Found\")\n\n    if self.repos:\n      debug.t_start('select-repos')\n      self.repos.open()\n      debug.t_end('select-repos')\n      type = self.repos.roottype()\n      if type == vclib.SVN:\n        self.roottype = 'svn'\n      elif type == vclib.CVS:\n        self.roottype = 'cvs'\n      else:\n        raise debug.ViewVCException(\n          'The root \"%s\" has an unknown type (\"%s\").  Expected \"cvs\" or \"svn\".'\n          % (self.rootname, type),\n          \"500 Internal Server Error\")\n      \n    # If this is using an old-style 'rev' parameter, redirect to new hotness.\n    # Subversion URLs will now use 'pathrev'; CVS ones use 'revision'.\n    if self.repos and self.query_dict.has_key('rev'):\n      if self.roottype == 'svn' \\\n             and not self.query_dict.has_key('pathrev') \\\n             and not self.view_func == view_revision:\n        self.query_dict['pathrev'] = self.query_dict['rev']\n        del self.query_dict['rev']\n      else: # elif not self.query_dict.has_key('revision'): ?\n        self.query_dict['revision'] = self.query_dict['rev']\n        del self.query_dict['rev']\n      needs_redirect = 1\n\n    if self.repos and self.view_func is not redirect_pathrev:\n      # If this is an intended-to-be-hidden CVSROOT path, complain.\n      if cfg.options.hide_cvsroot \\\n         and is_cvsroot_path(self.roottype, path_parts):\n        raise debug.ViewVCException(\"Unknown location: /%s\" % self.where,\n                                    \"404 Not Found\")\n\n      # Make sure path exists\n      self.pathrev = pathrev = self.query_dict.get('pathrev')\n      self.pathtype = _repos_pathtype(self.repos, path_parts, pathrev)\n\n      if self.pathtype is None:\n        # Path doesn't exist, see if it could be an old-style ViewVC URL\n        # with a fake suffix.\n        result = _strip_suffix('.diff', path_parts, pathrev, vclib.FILE,     \\\n                               self.repos, view_diff) or                     \\\n                 _strip_suffix('.tar.gz', path_parts, pathrev, vclib.DIR,    \\\n                               self.repos, download_tarball) or              \\\n                 _strip_suffix('root.tar.gz', path_parts, pathrev, vclib.DIR,\\\n                               self.repos, download_tarball) or              \\\n                 _strip_suffix(self.rootname + '-root.tar.gz',               \\\n                               path_parts, pathrev, vclib.DIR,               \\\n                               self.repos, download_tarball) or              \\\n                 _strip_suffix('root',                                       \\\n                               path_parts, pathrev, vclib.DIR,               \\\n                               self.repos, download_tarball) or              \\\n                 _strip_suffix(self.rootname + '-root',                      \\\n                               path_parts, pathrev, vclib.DIR,               \\\n                               self.repos, download_tarball)\n        if result:\n          self.path_parts, self.pathtype, self.view_func = result\n          self.where = _path_join(self.path_parts)\n          needs_redirect = 1\n        else:\n          raise debug.ViewVCException(\"Unknown location: /%s\" % self.where,\n                                      \"404 Not Found\")\n\n      # If we have an old ViewCVS Attic URL which is still valid, redirect\n      if self.roottype == 'cvs':\n        attic_parts = None\n        if (self.pathtype == vclib.FILE and len(self.path_parts) > 1\n            and self.path_parts[-2] == 'Attic'):\n          attic_parts = self.path_parts[:-2] + self.path_parts[-1:]\n        elif (self.pathtype == vclib.DIR and len(self.path_parts) > 0\n              and self.path_parts[-1] == 'Attic'):\n          attic_parts = self.path_parts[:-1]\n        if attic_parts:\n          self.path_parts = attic_parts\n          self.where = _path_join(attic_parts)\n          needs_redirect = 1\n\n    if self.view_func is None:\n      # view parameter is not set, try looking at pathtype and the \n      # other parameters\n      if not self.rootname:\n        self.view_func = view_roots\n      elif self.pathtype == vclib.DIR:\n        # ViewCVS 0.9.2 used to put ?tarball=1 at the end of tarball urls\n        if self.query_dict.has_key('tarball'):\n          self.view_func = download_tarball\n        elif self.query_dict.has_key('r1') and self.query_dict.has_key('r2'):\n          self.view_func = view_diff\n        else:\n          self.view_func = view_directory\n      elif self.pathtype == vclib.FILE:\n        if self.query_dict.has_key('r1') and self.query_dict.has_key('r2'):\n          self.view_func = view_diff\n        elif self.query_dict.has_key('annotate'):\n          self.view_func = view_annotate\n        elif self.query_dict.has_key('graph'):\n          if not self.query_dict.has_key('makeimage'):\n            self.view_func = view_cvsgraph\n          else: \n            self.view_func = view_cvsgraph_image\n        elif self.query_dict.has_key('revision') \\\n                 or cfg.options.default_file_view != \"log\":\n          if cfg.options.default_file_view == \"markup\" \\\n             or self.query_dict.get('content-type', None) \\\n                 in (viewcvs_mime_type, alt_mime_type):\n            self.view_func = view_markup\n          else:\n            self.view_func = view_checkout\n        else:\n          self.view_func = view_log\n\n    # If we've chosen the roots or revision view, our effective\n    # location is not really \"inside\" the repository, so we have no\n    # path and therefore no path parts or type, either.\n    if self.view_func is view_revision or self.view_func is view_roots:\n      self.where = ''\n      self.path_parts = []\n      self.pathtype = None\n      \n    # if we have a directory and the request didn't end in \"/\", then redirect\n    # so that it does.\n    if (self.pathtype == vclib.DIR and path_info[-1:] != '/'\n        and self.view_func is not download_tarball\n        and self.view_func is not redirect_pathrev):\n      needs_redirect = 1\n\n    # startup is done now.\n    debug.t_end('startup')\n\n    # If we need to redirect, do so.  Otherwise, handle our requested view.\n    if needs_redirect:\n      self.server.redirect(self.get_url())\n    else:\n      debug.t_start('view-func')\n      self.view_func(self)\n      debug.t_end('view-func')\n\n  def get_url(self, escape=0, partial=0, prefix=0, **args):\n    \"\"\"Constructs a link to another ViewVC page just like the get_link\n    function except that it returns a single URL instead of a URL\n    split into components.  If PREFIX is set, include the protocol and\n    server name portions of the URL.\"\"\"\n\n    url, params = apply(self.get_link, (), args)\n    qs = urllib.urlencode(params)\n    if qs:\n      result = urllib.quote(url, _URL_SAFE_CHARS) + '?' + qs\n    else:\n      result = urllib.quote(url, _URL_SAFE_CHARS)\n\n    if partial:\n      result = result + (qs and '&' or '?')\n    if escape:\n      result = self.server.escape(result)\n    if prefix:\n      result = '%s://%s%s' % \\\n               (self.server.getenv(\"HTTPS\") == \"on\" and \"https\" or \"http\",\n                self.server.getenv(\"HTTP_HOST\"),\n                result)\n    return result\n\n  def get_form(self, **args):\n    \"\"\"Constructs a link to another ViewVC page just like the get_link\n    function except that it returns a base URL suitable for use as an\n    HTML form action, and an iterable object with .name and .value\n    attributes representing stuff that should be in <input\n    type=hidden> tags with the link parameters.\"\"\"\n\n    url, params = apply(self.get_link, (), args)\n    action = self.server.escape(urllib.quote(url, _URL_SAFE_CHARS))\n    hidden_values = []\n    for name, value in params.items():\n      hidden_values.append(_item(name=self.server.escape(name),\n                                 value=self.server.escape(value)))\n    return action, hidden_values\n\n  def get_link(self, view_func=None, where=None, pathtype=None, params=None):\n    \"\"\"Constructs a link pointing to another ViewVC page. All arguments\n    correspond to members of the Request object. If they are set to \n    None they take values from the current page. Return value is a base\n    URL and a dictionary of parameters\"\"\"\n\n    cfg = self.cfg\n\n    if view_func is None:\n      view_func = self.view_func\n\n    if params is None:\n      params = self.query_dict.copy()\n    else:\n      params = params.copy()\n      \n    # must specify both where and pathtype or neither\n    assert (where is None) == (pathtype is None)\n\n    # if we are asking for the revision info view, we don't need any\n    # path information\n    if (view_func is view_revision or view_func is view_roots\n        or view_func is redirect_pathrev):\n      where = pathtype = None\n    elif where is None:\n      where = self.where\n      pathtype = self.pathtype\n\n    # no need to add sticky variables for views with no links\n    sticky_vars = not (view_func is view_checkout \n                       or view_func is download_tarball)\n\n    # The logic used to construct the URL is an inverse of the\n    # logic used to interpret URLs in Request.run_viewvc\n\n    url = self.script_name\n\n    # add checkout magic if neccessary\n    if view_func is view_checkout and cfg.options.checkout_magic:\n      url = url + '/' + checkout_magic_path\n\n    # add root to url\n    rootname = None\n    if view_func is not view_roots:\n      if cfg.options.root_as_url_component:\n        # remove root from parameter list if present\n        try:\n          rootname = params['root']\n        except KeyError:\n          rootname = self.rootname\n        else:\n          del params['root']\n\n        # add root path component\n        if rootname is not None:\n          url = url + '/' + rootname\n\n      else:\n        # add root to parameter list\n        try:\n          rootname = params['root']\n        except KeyError:\n          rootname = params['root'] = self.rootname\n\n        # no need to specify default root\n        if rootname == cfg.general.default_root:\n          del params['root']   \n\n    # add 'pathrev' value to parameter list\n    if (self.pathrev is not None\n        and not params.has_key('pathrev')\n        and view_func is not view_revision\n        and rootname == self.rootname):\n      params['pathrev'] = self.pathrev\n\n    # add path\n    if where:\n      url = url + '/' + where\n\n    # add trailing slash for a directory\n    if pathtype == vclib.DIR:\n      url = url + '/'\n\n    # normalize top level URLs for use in Location headers and A tags\n    elif not url:\n      url = '/'\n\n    # no need to explicitly specify directory view for a directory\n    if view_func is view_directory and pathtype == vclib.DIR:\n      view_func = None\n\n    # no need to explicitly specify roots view when in root_as_url\n    # mode or there's no default root\n    if view_func is view_roots and (cfg.options.root_as_url_component\n                                    or not cfg.general.default_root):\n      view_func = None\n\n    # no need to explicitly specify annotate view when\n    # there's an annotate parameter\n    if view_func is view_annotate and params.get('annotate') is not None:\n      view_func = None\n\n    # no need to explicitly specify diff view when\n    # there's r1 and r2 parameters\n    if (view_func is view_diff and params.get('r1') is not None\n        and params.get('r2') is not None):\n      view_func = None\n\n    # no need to explicitly specify checkout view when it's the default\n    # view or when checkout_magic is enabled\n    if view_func is view_checkout:\n      if ((cfg.options.default_file_view == \"co\" and pathtype == vclib.FILE)\n          or cfg.options.checkout_magic):\n        view_func = None\n\n    # no need to explicitly specify markup view when it's the default view\n    if view_func is view_markup:\n      if (cfg.options.default_file_view == \"markup\" \\\n          and pathtype == vclib.FILE):\n        view_func = None\n\n    # set the view parameter\n    view_code = _view_codes.get(view_func)\n    if view_code and not (params.has_key('view') and params['view'] is None):\n      params['view'] = view_code\n\n    # add sticky values to parameter list\n    if sticky_vars:\n      for name in _sticky_vars:\n        value = self.query_dict.get(name)\n        if value is not None and not params.has_key(name):\n          params[name] = value\n\n    # remove null values from parameter list\n    for name, value in params.items():\n      if value is None:\n        del params[name]\n\n    return url, params\n\ndef _path_parts(path):\n  \"\"\"Split up a repository path into a list of path components\"\"\"\n  # clean it up. this removes duplicate '/' characters and any that may\n  # exist at the front or end of the path.\n  return filter(None, path.split('/'))\n\ndef _normalize_path(path):\n  \"\"\"Collapse leading slashes in the script name\n\n  You only get multiple slashes in the script name when users accidentally\n  type urls like http://abc.com//viewvc.cgi/, but we correct for it\n  because we output the script name in links and web browsers\n  interpret //viewvc.cgi/ as http://viewvc.cgi/\n  \"\"\"\n  \n  i = 0\n  for c in path:\n    if c != '/':\n      break\n    i = i + 1\n\n  if i:\n    return path[i-1:]\n\n  return path\n\ndef _validate_param(name, value):\n  \"\"\"Validate whether the given value is acceptable for the param name.\n\n  If the value is not allowed, then an error response is generated, and\n  this function throws an exception. Otherwise, it simply returns None.\n  \"\"\"\n\n  # First things first -- check that we have a legal parameter name.\n  try:\n    validator = _legal_params[name]\n  except KeyError:\n    raise debug.ViewVCException(\n      'An illegal parameter name was provided.',\n      '400 Bad Request')\n\n  # Is there a validator?  Is it a regex or a function?  Validate if\n  # we can, returning without incident on valid input.\n  if validator is None:\n    return\n  elif hasattr(validator, 'match'):\n    if validator.match(value):\n      return\n  else:\n    if validator(value):\n      return\n\n  # If we get here, the input value isn't valid.\n  raise debug.ViewVCException(\n    'An illegal value was provided for the \"%s\" parameter.' % (name),\n    '400 Bad Request')\n\ndef _validate_regex(value):\n  ### we need to watch the flow of these parameters through the system\n  ### to ensure they don't hit the page unescaped. otherwise, these\n  ### parameters could constitute a CSS attack.\n  try:\n    re.compile(value)\n    return True\n  except:\n    return None\n\ndef _validate_view(value):\n  # Return true iff VALUE is one of our allowed views.\n  return _views.has_key(value)\n\ndef _validate_mimetype(value):\n  # For security purposes, we only allow mimetypes from a predefined set\n  # thereof.\n  return value in (viewcvs_mime_type, alt_mime_type, 'text/plain')\n\n# obvious things here. note that we don't need uppercase for alpha.\n_re_validate_alpha = re.compile('^[a-z]+$')\n_re_validate_number = re.compile('^[0-9]+$')\n_re_validate_boolint = re.compile('^[01]$')\n\n# when comparing two revs, we sometimes construct REV:SYMBOL, so ':' is needed\n_re_validate_revnum = re.compile('^[-_.a-zA-Z0-9:~\\\\[\\\\]/]*$')\n\n# date time values\n_re_validate_datetime = re.compile(r'^(\\d\\d\\d\\d-\\d\\d-\\d\\d(\\s+\\d\\d:\\d\\d'\n                                   '(:\\d\\d)?)?)?$')\n\n# the legal query parameters and their validation functions\n_legal_params = {\n  'root'          : None,\n  'view'          : _validate_view,\n  'search'        : _validate_regex,\n  'p1'            : None,\n  'p2'            : None,\n  \n  'hideattic'     : _re_validate_boolint,\n  'limit_changes' : _re_validate_number,\n  'sortby'        : _re_validate_alpha,\n  'sortdir'       : _re_validate_alpha,\n  'logsort'       : _re_validate_alpha,\n  'diff_format'   : _re_validate_alpha,\n  'pathrev'       : _re_validate_revnum,\n  'dir_pagestart' : _re_validate_number,\n  'log_pagestart' : _re_validate_number,\n  'annotate'      : _re_validate_revnum,\n  'graph'         : _re_validate_revnum,\n  'makeimage'     : _re_validate_boolint,\n  'r1'            : _re_validate_revnum,\n  'tr1'           : _re_validate_revnum,\n  'r2'            : _re_validate_revnum,\n  'tr2'           : _re_validate_revnum,\n  'revision'      : _re_validate_revnum,\n  'content-type'  : _validate_mimetype,\n\n  # for cvsgraph\n  'gflip'         : _re_validate_boolint,\n  'gbbox'         : _re_validate_boolint,\n  'gshow'         : _re_validate_alpha,\n  'gleft'         : _re_validate_boolint,\n  'gmaxtag'       : _re_validate_number,\n\n  # for query\n  'file_match'    : _re_validate_alpha,\n  'branch_match'  : _re_validate_alpha,\n  'who_match'     : _re_validate_alpha,\n  'comment_match' : _re_validate_alpha,\n  'dir'           : None,\n  'file'          : None,\n  'branch'        : None,\n  'who'           : None,\n  'comment'       : None,\n  'querysort'     : _re_validate_alpha,\n  'date'          : _re_validate_alpha,\n  'hours'         : _re_validate_number,\n  'mindate'       : _re_validate_datetime,\n  'maxdate'       : _re_validate_datetime,\n  'format'        : _re_validate_alpha,\n\n  # for redirect_pathrev\n  'orig_path'     : None,\n  'orig_pathtype' : None,\n  'orig_pathrev'  : None,\n  'orig_view'     : None,\n\n  # deprecated - these are no longer used, but kept around so that\n  # bookmarked URLs still \"work\" (for some definition thereof) after a\n  # ViewVC upgrade.\n  'parent'        : _re_validate_boolint,\n  'rev'           : _re_validate_revnum,\n  'tarball'       : _re_validate_boolint,\n  'hidecvsroot'   : _re_validate_boolint,\n  'limit'         : _re_validate_number,\n  }\n\ndef _path_join(path_parts):\n  return '/'.join(path_parts)\n\ndef _path_starts_with(path_parts, first_path_parts):\n  if not path_parts:\n    return False\n  if len(path_parts) < len(first_path_parts):\n    return False\n  return path_parts[0:len(first_path_parts)] == first_path_parts\n\ndef _strip_suffix(suffix, path_parts, rev, pathtype, repos, view_func):\n  \"\"\"strip the suffix from a repository path if the resulting path\n  is of the specified type, otherwise return None\"\"\"\n  if not path_parts:\n    return None\n  l = len(suffix)\n  if path_parts[-1][-l:] == suffix:\n    path_parts = path_parts[:]\n    if len(path_parts[-1]) == l:\n      del path_parts[-1]\n    else:\n      path_parts[-1] = path_parts[-1][:-l]\n    t = _repos_pathtype(repos, path_parts, rev)\n    if pathtype == t:\n      return path_parts, t, view_func\n  return None\n\ndef _repos_pathtype(repos, path_parts, rev):\n  \"\"\"Return the type of a repository path, or None if the path doesn't\n  exist\"\"\"\n  try:\n    return repos.itemtype(path_parts, rev)\n  except vclib.ItemNotFound:\n    return None\n\ndef _orig_path(request, rev_param='revision', path_param=None):\n  \"Get original path of requested file at old revision before copies or moves\"\n\n  # The 'pathrev' variable is interpreted by nearly all ViewVC views to\n  # provide a browsable snapshot of a repository at some point in its history.\n  # 'pathrev' is a tag name for CVS repositories and a revision number for\n  # Subversion repositories. It's automatically propagated between pages by\n  # logic in the Request.get_link() function which adds it to links like a\n  # sticky variable. When 'pathrev' is set, directory listings only include\n  # entries that exist in the specified revision or tag. Similarly, log pages\n  # will only show revisions preceding the point in history specified by\n  # 'pathrev.' Markup, checkout, and annotate pages show the 'pathrev'\n  # revision of files by default when no other revision is specified.\n  #\n  # In Subversion repositories, paths are always considered to refer to the\n  # pathrev revision. For example, if there is a \"circle.jpg\" in revision 3,\n  # which is renamed and modified as \"square.jpg\" in revision 4, the original\n  # circle image is visible at the following URLs:\n  #\n  #     *checkout*/circle.jpg?pathrev=3\n  #     *checkout*/square.jpg?revision=3\n  #     *checkout*/square.jpg?revision=3&pathrev=4\n  # \n  # Note that the following:\n  #\n  #     *checkout*/circle.jpg?rev=3\n  #\n  # now gets redirected to one of the following URLs:\n  #\n  #     *checkout*/circle.jpg?pathrev=3  (for Subversion)\n  #     *checkout*/circle.jpg?revision=3  (for CVS)\n  #\n  rev = request.query_dict.get(rev_param, request.pathrev)\n  path = request.query_dict.get(path_param, request.where)\n  \n  if rev is not None and hasattr(request.repos, '_getrev'):\n    try:\n      pathrev = request.repos._getrev(request.pathrev)\n      rev = request.repos._getrev(rev)\n    except vclib.InvalidRevision:\n      raise debug.ViewVCException('Invalid revision', '404 Not Found')\n    return _path_parts(request.repos.get_location(path, pathrev, rev)), rev\n  return _path_parts(path), rev\n\ndef setup_authorizer(cfg, username, rootname=None):\n  \"\"\"Setup the authorizer.  If ROOTNAME is provided, assume that\n  per-root options have not been overlayed.  Otherwise, assume they\n  have (and fetch the authorizer for the configured root).\"\"\"\n  \n  if rootname is None:\n    authorizer = cfg.options.authorizer\n    params = cfg.get_authorizer_params()\n  else:\n    authorizer, params = cfg.get_authorizer_and_params_hack(rootname)\n\n  # No configured authorizer?  No problem.\n  if not authorizer:\n    return None\n\n  # First, try to load a module with the configured name.\n  import imp\n  fp = None\n  try:\n    try:\n      fp, path, desc = imp.find_module(\"%s\" % (authorizer), vcauth.__path__)\n      my_auth = imp.load_module('viewvc', fp, path, desc)\n    except ImportError:\n      raise debug.ViewVCException(\n        'Invalid authorizer (%s) specified for root \"%s\"' \\\n        % (authorizer, rootname),\n        '500 Internal Server Error')\n  finally:\n    if fp:\n      fp.close()\n\n  # Add a rootname mapping callback function to the parameters.\n  def _root_lookup_func(cb_rootname):\n    return locate_root(cfg, cb_rootname)\n\n  # Finally, instantiate our Authorizer.\n  return my_auth.ViewVCAuthorizer(_root_lookup_func, username, params)\n\ndef check_freshness(request, mtime=None, etag=None, weak=0):\n  cfg = request.cfg\n\n  # See if we are supposed to disable etags (for debugging, usually)\n  if not cfg.options.generate_etags:\n    return 0\n  \n  request_etag = request_mtime = None\n  if etag is not None:\n    if weak:\n      etag = 'W/\"%s\"' % etag\n    else:\n      etag = '\"%s\"' % etag\n    request_etag = request.server.getenv('HTTP_IF_NONE_MATCH')\n  if mtime is not None:\n    try:\n      request_mtime = request.server.getenv('HTTP_IF_MODIFIED_SINCE')\n      request_mtime = rfc822.mktime_tz(rfc822.parsedate_tz(request_mtime))\n    except:\n      request_mtime = None\n\n  # if we have an etag, use that for freshness checking.\n  # if not available, then we use the last-modified time.\n  # if not available, then the document isn't fresh.\n  if etag is not None:\n    isfresh = (request_etag == etag)\n  elif mtime is not None:\n    isfresh = (request_mtime >= mtime)\n  else:\n    isfresh = 0\n\n  # require revalidation after the configured amount of time\n  if cfg and cfg.options.http_expiration_time >= 0:\n    expiration = rfc822.formatdate(time.time() +\n                                   cfg.options.http_expiration_time)\n    request.server.addheader('Expires', expiration)\n    request.server.addheader('Cache-Control',\n                             'max-age=%d' % cfg.options.http_expiration_time)\n\n  if isfresh:\n    request.server.header(status='304 Not Modified')\n  else:\n    if etag is not None:\n      request.server.addheader('ETag', etag)\n    if mtime is not None:\n      request.server.addheader('Last-Modified', rfc822.formatdate(mtime))\n  return isfresh\n\ndef get_view_template(cfg, view_name, language=\"en\"):\n  # See if the configuration specifies a template for this view.  If\n  # not, use the default template path for this view.\n  tname = vars(cfg.templates).get(view_name) or view_name + \".ezt\"\n\n  # Template paths are relative to the configurated template_dir (if\n  # any, \"templates\" otherwise), so build the template path as such.\n  tname = os.path.join(cfg.options.template_dir or \"templates\", tname)\n\n  # Allow per-language template selection.\n  tname = tname.replace('%lang%', language)\n\n  # Finally, construct the whole template path.\n  tname = cfg.path(tname)\n\n  debug.t_start('ezt-parse')\n  template = ezt.Template(tname)\n  debug.t_end('ezt-parse')\n\n  return template\n\ndef get_writeready_server_file(request, content_type=None, encoding=None,\n                               content_length=None, allow_compress=True):\n  \"\"\"Return a file handle to a response body stream, after outputting\n  any queued special headers (on REQUEST.server) and (optionally) a\n  'Content-Type' header whose value is CONTENT_TYPE and character set\n  is ENCODING.\n\n  If CONTENT_LENGTH is provided and compression is not in use, also\n  generate a 'Content-Length' header for this response.\n\n  Callers my use ALLOW_COMPRESS to disable compression where it would\n  otherwise be allowed.  (Such as when transmitting an\n  already-compressed response.)\n\n  After this function is called, it is too late to add new headers to\n  the response.\"\"\"\n\n  if allow_compress and request.gzip_compress_level:\n    request.server.addheader('Content-Encoding', 'gzip')\n  elif content_length is not None:\n    request.server.addheader('Content-Length', content_length)\n  \n  if content_type and encoding:\n    request.server.header(\"%s; charset=%s\" % (content_type, encoding))\n  elif content_type:\n    request.server.header(content_type)\n  else:\n    request.server.header()\n\n  if allow_compress and request.gzip_compress_level:\n    fp = gzip.GzipFile('', 'wb', request.gzip_compress_level,\n                       request.server.file())\n  else:\n    fp = request.server.file()\n  \n  return fp\n  \ndef generate_page(request, view_name, data, content_type=None):\n  server_fp = get_writeready_server_file(request, content_type)\n  template = get_view_template(request.cfg, view_name, request.language)\n  template.generate(server_fp, data)\n\ndef nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=request.server.escape(part), href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items\n\ndef prep_tags(request, tags):\n  url, params = request.get_link(params={'pathrev': None})\n  params = urllib.urlencode(params)\n  if params:\n    url = urllib.quote(url, _URL_SAFE_CHARS) + '?' + params + '&pathrev='\n  else:\n    url = urllib.quote(url, _URL_SAFE_CHARS) + '?pathrev='\n  url = request.server.escape(url)\n\n  links = [ ]\n  for tag in tags:\n    links.append(_item(name=tag.name, href=url+tag.name))\n  links.sort(lambda a, b: cmp(a.name, b.name))\n  return links\n\ndef guess_mime(filename):\n  return mimetypes.guess_type(filename)[0]\n\ndef is_viewable_image(mime_type):\n  return mime_type and mime_type in ('image/gif', 'image/jpeg', 'image/png')\n\ndef is_text(mime_type):\n  return not mime_type or mime_type[:5] == 'text/'\n\ndef is_cvsroot_path(roottype, path_parts):\n  return roottype == 'cvs' and path_parts and path_parts[0] == 'CVSROOT'\n\ndef is_plain_text(mime_type):\n  return not mime_type or mime_type == 'text/plain'\n\ndef default_view(mime_type, cfg):\n  \"Determine whether file should be viewed through markup page or sent raw\"\n  # If the mime type is text/anything or a supported image format we view\n  # through the markup page. If the mime type is something else, we send\n  # it directly to the browser. That way users can see things like flash\n  # animations, pdfs, word documents, multimedia, etc, which wouldn't be\n  # very useful marked up. If the mime type is totally unknown (happens when\n  # we encounter an unrecognized file extension) we also view it through\n  # the markup page since that's better than sending it text/plain.\n  if ('markup' in cfg.options.allowed_views and \n      (is_viewable_image(mime_type) or is_text(mime_type))):\n    return view_markup\n  return view_checkout\n\ndef is_binary_file_mime_type(mime_type, cfg):\n  \"\"\"Return True iff MIME_TYPE is set and matches one of the binary\n  file mime type patterns in CFG.\"\"\"\n  if mime_type:\n    for pattern in cfg.options.binary_mime_types:\n      if fnmatch.fnmatch(mime_type, pattern):\n        return True\n  return False\n  \ndef is_dir_ignored_file(file_name, cfg):\n  \"\"\"Return True if FILE_NAME is set and matches one of the file names\n  or extensions to be ignored in directory listing per CFG.\"\"\"\n  if file_name:\n    for pattern in cfg.options.dir_ignored_files:\n      if fnmatch.fnmatch(file_name, pattern):\n        return True\n  return False\n\ndef get_file_view_info(request, where, rev=None, mime_type=None, pathrev=-1):\n  \"\"\"Return an object holding common hrefs and a viewability flag used\n  for various views of FILENAME at revision REV whose MIME type is\n  MIME_TYPE.\n\n  The object's members include:\n     view_href\n     download_href\n     download_text_href\n     annotate_href\n     revision_href\n     prefer_markup\n     is_viewable_image\n     is_binary\n     \n  \"\"\"\n  \n  rev = rev and str(rev) or None\n  mime_type = mime_type or guess_mime(where)\n  if pathrev == -1: # cheesy default value, since we need to preserve None\n    pathrev = request.pathrev\n\n  view_href = None\n  download_href = None\n  download_text_href = None\n  annotate_href = None\n  revision_href = None\n\n  if 'markup' in request.cfg.options.allowed_views:\n    view_href = request.get_url(view_func=view_markup,\n                                where=where,\n                                pathtype=vclib.FILE,\n                                params={'revision': rev,\n                                        'pathrev': pathrev},\n                                escape=1)\n  if 'co' in request.cfg.options.allowed_views:\n    download_href = request.get_url(view_func=view_checkout,\n                                    where=where,\n                                    pathtype=vclib.FILE,\n                                    params={'revision': rev,\n                                            'pathrev': pathrev},\n                                    escape=1)\n    if not is_plain_text(mime_type):\n      download_text_href = request.get_url(view_func=view_checkout,\n                                           where=where,\n                                           pathtype=vclib.FILE,\n                                           params={'content-type': 'text/plain',\n                                                   'revision': rev,\n                                                   'pathrev': pathrev},\n                                           escape=1)\n  if 'annotate' in request.cfg.options.allowed_views:\n    annotate_href = request.get_url(view_func=view_annotate,\n                                    where=where,\n                                    pathtype=vclib.FILE,\n                                    params={'annotate': rev,\n                                            'pathrev': pathrev},\n                                    escape=1)\n  if request.roottype == 'svn':\n    revision_href = request.get_url(view_func=view_revision,\n                                    params={'revision': rev},\n                                    escape=1)\n\n  is_binary_file = is_binary_file_mime_type(mime_type, request.cfg)\n  if is_binary_file:\n    download_text_href = annotate_href = view_href = None\n    prefer_markup = False\n  else:\n    prefer_markup = default_view(mime_type, request.cfg) == view_markup\n\n  return _item(view_href=view_href,\n               download_href=download_href,\n               download_text_href=download_text_href,\n               annotate_href=annotate_href,\n               revision_href=revision_href,\n               prefer_markup=ezt.boolean(prefer_markup),\n               is_viewable_image=ezt.boolean(is_viewable_image(mime_type)),\n               is_binary=ezt.boolean(is_binary_file))\n\n\n# Matches URLs\n_re_rewrite_url = re.compile('((http|https|ftp|file|svn|svn\\+ssh)'\n                             '(://[-a-zA-Z0-9%.~:_/]+)((\\?|\\&)'\n                             '([-a-zA-Z0-9%.~:_]+)=([-a-zA-Z0-9%.~:_])+)*'\n                             '(#([-a-zA-Z0-9%.~:_]+)?)?)')\n# Matches email addresses\n_re_rewrite_email = re.compile('([-a-zA-Z0-9_.\\+]+)@'\n                               '(([-a-zA-Z0-9]+\\.)+[A-Za-z]{2,4})')\n\n# Matches revision references\n_re_rewrite_svnrevref = re.compile(r'\\b(r|rev #?|revision #?)([0-9]+)\\b')\n\nclass ViewVCHtmlFormatterTokens:\n  def __init__(self, tokens):\n    self.tokens = tokens\n\n  def get_result(self, maxlen=0):\n    \"\"\"Format the tokens per the registered set of formatters, and\n    limited to MAXLEN visible characters (or unlimited if MAXLEN is\n    0).  Return a 3-tuple containing the formatted result string, the\n    number of visible characters in the result string, and a boolean\n    flag indicating whether or not S was truncated.\"\"\"\n    out = ''\n    out_len = 0\n    for token in self.tokens:\n      chunk, chunk_len = token.converter(token.match, token.userdata, maxlen)\n      out = out + chunk\n      out_len = out_len + chunk_len\n      if maxlen:\n        maxlen = maxlen - chunk_len\n        if maxlen <= 0:\n          return out, out_len, 1\n    return out, out_len, 0\n\n    \nclass ViewVCHtmlFormatter:\n  \"\"\"Format a string as HTML-encoded output with customizable markup\n  rules, for example turning strings that look like URLs into anchor links.\n\n  NOTE:  While there might appear to be some unused portions of this\n  interface, there is a good chance that there are consumers outside\n  of ViewVC itself that make use of these things.\n  \"\"\"\n  \n  def __init__(self):\n    self._formatters = []\n\n  def format_url(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as\n           linkified URL, with no more than MAXLEN characters in the\n           non-HTML-tag bits.  If MAXLEN is 0, there is no maximum.\n         - the number of non-HTML-tag characters returned.\n    \"\"\"\n    s = mobj.group(0)\n    trunc_s = maxlen and s[:maxlen] or s\n    return '<a href=\"%s\">%s</a>' % (sapi.escape(s),\n                                    sapi.escape(trunc_s)), \\\n           len(trunc_s)\n\n  def format_email(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as\n           linkified email address, with no more than MAXLEN characters\n           in the non-HTML-tag bits.  If MAXLEN is 0, there is no maximum.\n         - the number of non-HTML-tag characters returned.\n    \"\"\"\n    s = mobj.group(0)\n    trunc_s = maxlen and s[:maxlen] or s\n    return '<a href=\"mailto:%s\">%s</a>' % (urllib.quote(s),\n                                           self._entity_encode(trunc_s)), \\\n           len(trunc_s)\n\n  def format_email_obfuscated(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as an\n           entity-encoded email address, with no more than MAXLEN characters\n           in the non-HTML-tag bits.  If MAXLEN is 0, there is no maximum.\n         - the number of non-HTML-tag characters returned.\n    \"\"\"    \n    s = mobj.group(0)\n    trunc_s = maxlen and s[:maxlen] or s\n    return self._entity_encode(trunc_s), len(trunc_s)\n\n  def format_email_truncated(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as an\n           HTML-escaped truncated email address of no more than MAXLEN\n           characters.  If MAXLEN is 0, there is no maximum.\n         - the number of characters returned.\n    \"\"\"\n    s = mobj.group(1)\n    s_len = len(s)\n    if (maxlen == 0) or (s_len < (maxlen - 1)):\n      return self._entity_encode(s) + '&#64;&hellip;', s_len + 2\n    elif s_len < maxlen:\n      return self._entity_encode(s) + '&#64;', s_len + 1\n    else:\n      trunc_s = mobj.group(1)[:maxlen]\n      return self._entity_encode(trunc_s), len(trunc_s)\n\n  def format_svnrevref(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as an\n           linkified URL to a ViewVC Subversion revision view, with no\n           more than MAXLEN characters in the non-HTML-tag portions.\n           If MAXLEN is 0, there is no maximum.\n         - the number of characters returned.\n\n       USERDATA is a function that accepts a revision reference\n       and returns a URL to that revision.\n    \"\"\"\n    s = mobj.group(0)\n    revref = mobj.group(2)\n    trunc_s = maxlen and s[:maxlen] or s\n    revref_url = userdata(revref)\n    return '<a href=\"%s\">%s</a>' % (sapi.escape(revref_url),\n                                    sapi.escape(trunc_s)), \\\n           len(trunc_s)\n\n  def format_custom_url(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as an\n           linkified URL created by substituting match groups 0-9 into\n           USERDATA (which is a format string that uses \\N to\n           represent the substitution locations) and with no more than\n           MAXLEN characters in the non-HTML-tag portions.  If MAXLEN\n           is 0, there is no maximum.\n         - the number of characters returned.\n    \"\"\"\n    format = userdata\n    text = mobj.group(0)\n    url = format\n    for i in range(9):\n      try:\n        repl = mobj.group(i)\n      except:\n        repl = ''\n      url = url.replace('\\%d' % (i), repl)\n    trunc_s = maxlen and text[:maxlen] or text\n    return '<a href=\"%s\">%s</a>' % (sapi.escape(url),\n                                    sapi.escape(trunc_s)), \\\n           len(trunc_s)\n\n  def format_text(self, s, unused, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text S, HTML-escaped, containing no more than MAXLEN\n           characters.  If MAXLEN is 0, there is no maximum.\n         - the number of characters returned.\n    \"\"\"   \n    trunc_s = maxlen and s[:maxlen] or s\n    return sapi.escape(trunc_s), len(trunc_s)\n  \n  def add_formatter(self, regexp, conv, userdata=None):\n    \"\"\"Register a formatter which finds instances of strings matching\n    REGEXP, and using the function CONV and USERDATA to format them.\n\n    CONV is a function which accepts three parameters:\n      - the MatchObject which holds the string portion to be formatted,\n      - the USERDATA object,\n      - the maximum number of characters from that string to use for\n        human-readable output (or 0 to indicate no maximum).\n    \"\"\"\n    if type(regexp) == type(''):\n      regexp = re.compile(regexp)\n    self._formatters.append([regexp, conv, userdata])\n\n  def get_result(self, s, maxlen=0):\n    \"\"\"Format S per the set of formatters registered with this object,\n    and limited to MAXLEN visible characters (or unlimited if MAXLEN\n    is 0).  Return a 3-tuple containing the formatted result string,\n    the number of visible characters in the result string, and a\n    boolean flag indicating whether or not S was truncated.\n    \"\"\"\n    return self.tokenize_text(s).get_result(maxlen)\n\n  def tokenize_text(self, s):\n    \"\"\"Return a ViewVCHtmlFormatterTokens object containing the tokens\n    created when parsing the string S.  Callers can use that object's\n    get_result() function to retrieve HTML-formatted text.\n    \"\"\"\n    tokens = []\n    # We could just have a \"while s:\" here instead of \"for line: while\n    # line:\", but for really large log messages with heavy\n    # tokenization, the cost in both performance and memory\n    # consumption of the approach taken was atrocious.\n    for line in s.replace('\\r\\n', '\\n').split('\\n'):\n      line = line + '\\n'\n      while line:\n        best_match = best_conv = best_userdata = None\n        for test in self._formatters:\n          match = test[0].search(line)\n          # If we find and match and (a) its our first one, or (b) it\n          # matches text earlier than our previous best match, or (c) it\n          # matches text at the same location as our previous best match\n          # but extends to cover more text than that match, then this is\n          # our new best match.\n          #\n          # Implied here is that when multiple formatters match exactly\n          # the same text, the first formatter in the registration list wins.\n          if match \\\n             and ((best_match is None) \\\n                  or (match.start() < best_match.start())\n                  or ((match.start() == best_match.start()) \\\n                      and (match.end() > best_match.end()))):\n            best_match = match\n            best_conv = test[1]\n            best_userdata = test[2]\n        # If we found a match...\n        if best_match:\n          # ... add any non-matching stuff first, then the matching bit.\n          start = best_match.start()\n          end = best_match.end()\n          if start > 0:\n            tokens.append(_item(match=line[:start],\n                                converter=self.format_text,\n                                userdata=None))\n          tokens.append(_item(match=best_match,\n                              converter=best_conv,\n                              userdata=best_userdata))\n          line = line[end:]\n        else:\n          # Otherwise, just add the rest of the string.\n          tokens.append(_item(match=line,\n                              converter=self.format_text,\n                              userdata=None))\n          line = ''\n    return ViewVCHtmlFormatterTokens(tokens)\n\n  def _entity_encode(self, s):\n    return ''.join(map(lambda x: '&#%d;' % (ord(x)), s))\n\n\nclass LogFormatter:\n  def __init__(self, request, log):\n    self.request = request\n    self.log = log or ''\n    self.tokens = None\n    self.cache = {}  # (maxlen, htmlize) => resulting_log\n\n  def get(self, maxlen=0, htmlize=1):\n    cfg = self.request.cfg\n    \n    # Prefer the cache.\n    if self.cache.has_key((maxlen, htmlize)):\n      return self.cache[(maxlen, htmlize)]\n    \n    # If we are HTML-izing...\n    if htmlize:\n      # ...and we don't yet have ViewVCHtmlFormatter() object tokens...\n      if not self.tokens:\n        # ... then get them.\n        lf = ViewVCHtmlFormatter()\n\n        # Rewrite URLs.\n        lf.add_formatter(_re_rewrite_url, lf.format_url)\n\n        # Rewrite Subversion revision references.\n        if self.request.roottype == 'svn':\n          def revision_to_url(rev):\n            return self.request.get_url(view_func=view_revision,\n                                        params={'revision': rev},\n                                        escape=0)\n          lf.add_formatter(_re_rewrite_svnrevref, lf.format_svnrevref,\n                           revision_to_url)\n\n        # Rewrite email addresses.\n        if cfg.options.mangle_email_addresses == 2:\n          lf.add_formatter(_re_rewrite_email, lf.format_email_truncated)\n        elif cfg.options.mangle_email_addresses == 1:\n          lf.add_formatter(_re_rewrite_email, lf.format_email_obfuscated)\n        else:\n          lf.add_formatter(_re_rewrite_email, lf.format_email)\n\n        # Add custom rewrite handling per configuration.\n        for rule in cfg.options.custom_log_formatting:\n          rule = rule.replace('\\\\:', '\\x01')          \n          regexp, format = map(lambda x: x.strip(), rule.split(':', 1))\n          regexp = regexp.replace('\\x01', ':')\n          format = format.replace('\\x01', ':')\n          lf.add_formatter(re.compile(regexp), lf.format_custom_url, format)\n\n        # Tokenize the log message.\n        self.tokens = lf.tokenize_text(self.log)\n\n      # Use our formatter to ... you know ... format.\n      log, log_len, truncated = self.tokens.get_result(maxlen)\n      result_log = log + (truncated and '&hellip;' or '')\n\n    # But if we're not HTML-izing...\n    else:\n      # ...then do much more simplistic transformations as necessary.\n      log = self.log\n      if cfg.options.mangle_email_addresses == 2:\n        log = re.sub(_re_rewrite_email, r'\\1@...', log)\n      result_log = maxlen and log[:maxlen] or log\n\n    # In either case, populate the cache and return the results.\n    self.cache[(maxlen, htmlize)] = result_log\n    return result_log\n\n\n_time_desc = {\n         1 : 'second',\n        60 : 'minute',\n      3600 : 'hour',\n     86400 : 'day',\n    604800 : 'week',\n   2628000 : 'month',\n  31536000 : 'year',\n  }\n\ndef get_time_text(request, interval, num):\n  \"Get some time text, possibly internationalized.\"\n  ### some languages have even harder pluralization rules. we'll have to\n  ### deal with those on demand\n  if num == 0:\n    return ''\n  text = _time_desc[interval]\n  if num == 1:\n    attr = text + '_singular'\n    fmt = '%d ' + text\n  else:\n    attr = text + '_plural'\n    fmt = '%d ' + text + 's'\n  try:\n    fmt = getattr(request.kv.i18n.time, attr)\n  except AttributeError:\n    pass\n  return fmt % num\n\ndef little_time(request):\n  try:\n    return request.kv.i18n.time.little_time\n  except AttributeError:\n    return 'very little time'\n\ndef html_time(request, secs, extended=0):\n  secs = long(time.time()) - secs\n  if secs < 2:\n    return little_time(request)\n  breaks = _time_desc.keys()\n  breaks.sort()\n  i = 0\n  while i < len(breaks):\n    if secs < 2 * breaks[i]:\n      break\n    i = i + 1\n  value = breaks[i - 1]\n  s = get_time_text(request, value, secs / value)\n\n  if extended and i > 1:\n    secs = secs % value\n    value = breaks[i - 2]\n    ext = get_time_text(request, value, secs / value)\n    if ext:\n      ### this is not i18n compatible. pass on it for now\n      s = s + ', ' + ext\n  return s\n\ndef common_template_data(request, revision=None, mime_type=None):\n  \"\"\"Return a TemplateData instance with data dictionary items\n  common to most ViewVC views.\"\"\"\n  \n  cfg = request.cfg\n\n  # Initialize data dictionary members (sorted alphanumerically)\n  data = TemplateData({\n    'annotate_href' : None,\n    'cfg' : cfg,\n    'docroot' : cfg.options.docroot is None \\\n                and request.script_name + '/' + docroot_magic_path \\\n                or cfg.options.docroot,\n    'download_href' : None,\n    'download_text_href' : None,\n    'graph_href': None,\n    'home_href': request.script_name or '/',\n    'kv'  : request.kv,\n    'lockinfo' : None,\n    'log_href' : None,\n    'nav_path' : nav_path(request),\n    'pathtype' : None,\n    'prefer_markup' : ezt.boolean(0),\n    'queryform_href' : None,\n    'rev'      : None,\n    'revision_href' : None,\n    'rootname' : request.rootname \\\n                 and request.server.escape(request.rootname) or None,\n    'rootpath' : request.rootpath,\n    'roots_href' : None,\n    'roottype' : request.roottype,\n    'rss_href' : None,\n    'tarball_href' : None,\n    'up_href'  : None,\n    'username' : request.username,\n    'view'     : _view_codes[request.view_func],\n    'view_href' : None,\n    'vsn' : __version__,\n    'where' : request.server.escape(request.where),\n  })\n\n  rev = revision\n  if not rev:\n    rev = request.query_dict.get('annotate')\n  if not rev:\n    rev = request.query_dict.get('revision')\n  if not rev and request.roottype == 'svn':\n    rev = request.query_dict.get('pathrev')\n  try:\n    data['rev'] = hasattr(request.repos, '_getrev') \\\n                  and request.repos._getrev(rev) or rev\n  except vclib.InvalidRevision:\n    raise debug.ViewVCException('Invalid revision', '404 Not Found')\n\n  if request.pathtype == vclib.DIR:\n    data['pathtype'] = 'dir'\n  elif request.pathtype == vclib.FILE:\n    data['pathtype'] = 'file'\n\n  if request.path_parts:\n    dir = _path_join(request.path_parts[:-1])\n    data['up_href'] = request.get_url(view_func=view_directory,\n                                      where=dir, pathtype=vclib.DIR,\n                                      params={}, escape=1)\n\n  if 'roots' in cfg.options.allowed_views:\n    data['roots_href'] = request.get_url(view_func=view_roots,\n                                         escape=1, params={})\n\n  if request.pathtype == vclib.FILE:\n    fvi = get_file_view_info(request, request.where, data['rev'], mime_type)\n    data['view_href'] = fvi.view_href\n    data['download_href'] = fvi.download_href\n    data['download_text_href'] = fvi.download_text_href\n    data['annotate_href'] = fvi.annotate_href\n    data['revision_href'] = fvi.revision_href\n    data['prefer_markup'] = fvi.prefer_markup\n    data['log_href'] = request.get_url(view_func=view_log, params={}, escape=1)\n    if request.roottype == 'cvs' and cfg.options.use_cvsgraph:\n      data['graph_href'] = request.get_url(view_func=view_cvsgraph,\n                                           params={}, escape=1)\n    file_data = request.repos.listdir(request.path_parts[:-1],\n                                      request.pathrev, {})\n    def _only_this_file(item):\n      return item.name == request.path_parts[-1]\n    entries = filter(_only_this_file, file_data)\n    if len(entries) == 1:\n      request.repos.dirlogs(request.path_parts[:-1], request.pathrev,\n                            entries, {})\n      data['lockinfo'] = entries[0].lockinfo\n  elif request.pathtype == vclib.DIR:\n    data['view_href'] = request.get_url(view_func=view_directory,\n                                       params={}, escape=1)\n    if 'tar' in cfg.options.allowed_views:\n      data['tarball_href'] = request.get_url(view_func=download_tarball, \n                                             params={},\n                                             escape=1)\n    if request.roottype == 'svn':\n      data['revision_href'] = request.get_url(view_func=view_revision,\n                                              params={'revision': data['rev']},\n                                              escape=1)\n\n      data['log_href'] = request.get_url(view_func=view_log,\n                                         params={}, escape=1)\n\n  if is_querydb_nonempty_for_root(request):\n    if request.pathtype == vclib.DIR:\n      params = {}\n      if request.roottype == 'cvs' and request.pathrev:\n        params['branch'] = request.pathrev\n      data['queryform_href'] = request.get_url(view_func=view_queryform,\n                                               params=params,\n                                               escape=1)\n      data['rss_href'] = request.get_url(view_func=view_query,\n                                         params={'date': 'month',\n                                                 'format': 'rss'},\n                                         escape=1)\n    elif request.pathtype == vclib.FILE:\n      parts = _path_parts(request.where)\n      where = _path_join(parts[:-1])\n      data['rss_href'] = request.get_url(view_func=view_query,\n                                         where=where,\n                                         pathtype=request.pathtype,\n                                         params={'date': 'month',\n                                                 'format': 'rss',\n                                                 'file': parts[-1],\n                                                 'file_match': 'exact'},\n                                         escape=1)\n  return data\n\ndef retry_read(src, reqlen=CHUNK_SIZE):\n  while 1:\n    chunk = src.read(CHUNK_SIZE)\n    if not chunk:\n      # need to check for eof methods because the cStringIO file objects\n      # returned by ccvs don't provide them\n      if hasattr(src, 'eof') and src.eof() is None:\n        time.sleep(1)\n        continue\n    return chunk\n  \ndef copy_stream(src, dst, htmlize=0):\n  while 1:\n    chunk = retry_read(src)\n    if not chunk:\n      break\n    if htmlize:\n      chunk = sapi.escape(chunk)\n    dst.write(chunk)\n\nclass MarkupPipeWrapper:\n  \"\"\"An EZT callback that outputs a filepointer, plus some optional\n  pre- and post- text.\"\"\"\n\n  def __init__(self, fp, pretext=None, posttext=None, htmlize=0):\n    self.fp = fp\n    self.pretext = pretext\n    self.posttext = posttext\n    self.htmlize = htmlize\n\n  def __call__(self, ctx):\n    if self.pretext:\n      ctx.fp.write(self.pretext)\n    copy_stream(self.fp, ctx.fp, self.htmlize)\n    self.fp.close()\n    if self.posttext:\n      ctx.fp.write(self.posttext)\n\n_re_rewrite_escaped_url = re.compile('((http|https|ftp|file|svn|svn\\+ssh)'\n                                     '(://[-a-zA-Z0-9%.~:_/]+)'\n                                     '((\\?|\\&amp;amp;|\\&amp;|\\&)'\n                                     '([-a-zA-Z0-9%.~:_]+)=([-a-zA-Z0-9%.~:_])+)*'\n                                     '(#([-a-zA-Z0-9%.~:_]+)?)?)')\n\ndef markup_escaped_urls(s):\n  # Return a copy of S with all URL references -- which are expected\n  # to be already HTML-escaped -- wrapped in <a href=\"\"></a>.\n  def _url_repl(match_obj):\n    url = match_obj.group(0)\n    unescaped_url = url.replace(\"&amp;amp;\", \"&amp;\")\n    return \"<a href=\\\"%s\\\">%s</a>\" % (unescaped_url, url)\n  return re.sub(_re_rewrite_escaped_url, _url_repl, s)\n\n\ndef detect_encoding(text_block):\n  \"\"\"Return the encoding used by TEXT_BLOCK as detected by the chardet\n  Python module.  (Currently, this is used only when syntax\n  highlighting is not enabled/available; otherwise, Pygments does this\n  work for us.)\"\"\"\n  \n  # Does the TEXT_BLOCK start with a BOM?\n  for bom, encoding in [('\\xef\\xbb\\xbf', 'utf-8'),\n                        ('\\xff\\xfe', 'utf-16'),\n                        ('\\xfe\\xff', 'utf-16be'),\n                        ('\\xff\\xfe\\0\\0', 'utf-32'),\n                        ('\\0\\0\\xfe\\xff', 'utf-32be'),\n                        ]:\n    if text_block.startswith(bom):\n      return encoding\n\n  # If no recognized BOM, see if chardet can help us.\n  try:\n    import chardet\n\n    # If chardet can confidently claimed a match, we'll use its\n    # findings.  (And if that match is 'ascii' -- which is a subset of\n    # utf-8 -- we'll just call it 'utf-8' and score a zero transform.)\n    resp = chardet.detect(text_block)\n    if resp.get('confidence') == 1.0:\n      encoding = resp.get('encoding')\n      if encoding is \"ascii\":\n        encoding = \"utf-8\"\n      return encoding\n  except:\n    pass\n\n  # By default ... we have no idea.\n  return None\n  \ndef transcode_text(text, encoding=None):\n  \"\"\"If ENCODING is provided and not 'utf-8', transcode TEXT from\n  ENCODING to UTF-8.\"\"\"\n\n  if not encoding or encoding == 'utf-8':\n    return text\n  try:\n    return unicode(text, encoding, 'replace').encode('utf-8', 'replace')\n  except:\n    pass\n  return text\n\ndef markup_file_contents(request, cfg, file_lines, filename,\n                         mime_type, encoding, colorize):\n  # Nothing to mark up?  So be it.\n  if not file_lines:\n    return []\n\n  # Determine if we should (and can) use Pygments to highlight our\n  # output.  Reasons not to include a) being told not to by the\n  # configuration, b) not being able to import the Pygments modules,\n  # and c) Pygments not having a lexer for our file's format.\n  pygments_lexer = None\n  if colorize:\n    from pygments import highlight\n    from pygments.formatters import HtmlFormatter\n    from pygments.lexers import ClassNotFound, \\\n                                get_lexer_by_name, \\\n                                get_lexer_for_mimetype, \\\n                                get_lexer_for_filename, \\\n                                guess_lexer\n    if not encoding:\n      encoding = 'guess'\n      if cfg.options.detect_encoding:\n        try:\n          import chardet\n          encoding = 'chardet'\n        except (SyntaxError, ImportError):\n          pass\n\n    # First, see if there's a Pygments lexer associated with MIME_TYPE.\n    if mime_type:\n      try:\n        pygments_lexer = get_lexer_for_mimetype(mime_type,\n                                                encoding=encoding,\n                                                tabsize=cfg.options.tabsize,\n                                                stripnl=False)\n      except ClassNotFound:\n        pygments_lexer = None\n\n    # If we've no lexer thus far, try to find one based on the FILENAME.\n    if not pygments_lexer:\n      try:\n        pygments_lexer = get_lexer_for_filename(filename,\n                                                encoding=encoding,\n                                                tabsize=cfg.options.tabsize,\n                                                stripnl=False)\n      except ClassNotFound:\n        pygments_lexer = None\n\n    # Still no lexer?  If we've reason to believe this is a text\n    # file, try to guess the lexer based on the file's content.\n    if not pygments_lexer and is_text(mime_type) and file_lines:\n      try:\n        pygments_lexer = guess_lexer(file_lines[0],\n                                     encoding=encoding,\n                                     tabsize=cfg.options.tabsize,\n                                     stripnl=False)\n      except ClassNotFound:\n        pygments_lexer = None\n        \n  # If we aren't highlighting, just return FILE_LINES, corrected for\n  # encoding (if possible).\n  if not pygments_lexer:\n\n    # If allowed by configuration, try to detect the source encoding\n    # for this file.  We'll assemble a block of data from the file\n    # contents to do so... 1024 bytes should be enough.\n    if not encoding and cfg.options.detect_encoding:\n      block_size = 0\n      text_block = ''\n      for i in range(len(file_lines)):\n        text_block = text_block + file_lines[i]\n        if len(text_block) >= 1024:\n          break\n      encoding = detect_encoding(text_block)\n\n    # Built output data comprised of marked-up and possibly-transcoded\n    # source text lines wrapped in (possibly dummy) vclib.Annotation\n    # objects.\n    file_lines = transcode_text(''.join(file_lines), encoding)\n    if file_lines[-1] == '\\n':\n      file_lines = file_lines[:-1]\n    file_lines = file_lines.split('\\n')\n    for i in range(len(file_lines)):\n      line = file_lines[i]\n      if cfg.options.tabsize > 0:\n        line = line.expandtabs(cfg.options.tabsize)\n      file_lines[i] = markup_escaped_urls(sapi.escape(line))\n    return file_lines\n  \n  # If we get here, we're highlighting something.\n  class PygmentsSink:\n    def __init__(self):\n      self.colorized_file_lines = []\n    \n    def write(self, buf):\n      ### FIXME:  Don't bank on write() being called once per line\n      self.colorized_file_lines.append(markup_escaped_urls(buf.rstrip('\\n\\r')))\n\n  ps = PygmentsSink()\n  highlight(''.join(file_lines), pygments_lexer,\n            HtmlFormatter(nowrap=True,\n                          classprefix=\"pygments-\",\n                          encoding='utf-8'), ps)\n  return ps.colorized_file_lines\n\ndef empty_blame_item(line, line_no):\n  blame_item = vclib.Annotation(line, line_no, None, None, None, None)\n  blame_item.diff_href = None\n  return blame_item\n  \ndef merge_blame_data(file_lines, blame_data):\n  errorful = 0\n  if blame_data and (len(file_lines) != len(blame_data)):\n    errorful = 1\n    blame_data = None\n  if not blame_data:\n    new_blame_data = []\n  for i in range(len(file_lines)):\n    line = file_lines[i]\n    if blame_data:\n      blame_data[i].text = line\n    else:\n      new_blame_data.append(empty_blame_item(line, i + 1))\n  return blame_data or new_blame_data, errorful\n  \ndef make_time_string(date, cfg):\n  \"\"\"Returns formatted date string in either local time or UTC.\n\n  The passed in 'date' variable is seconds since epoch.\n\n  \"\"\"\n  if date is None:\n    return None\n  if cfg.options.use_localtime:\n    tm = time.localtime(date)\n  else:\n    tm = time.gmtime(date)\n  if cfg.options.iso8601_timestamps:\n    if cfg.options.use_localtime:\n      if tm[8] and time.daylight:\n        tz = -time.altzone\n      else:\n        tz = -time.timezone\n      if tz < 0:\n        tz = '-%02d:%02d' % (-tz // 3600, (-tz % 3600) // 60)\n      else:\n        tz = '+%02d:%02d' % (tz // 3600, (tz % 3600) // 60)\n    else:\n      tz = 'Z'\n    return time.strftime('%Y-%m-%dT%H:%M:%S', tm) + tz\n  else:\n    return time.asctime(tm) + ' ' + \\\n           (cfg.options.use_localtime and time.tzname[tm[8]] or 'UTC')\n\ndef make_rss_time_string(date, cfg):\n  \"\"\"Returns formatted date string in UTC, formatted for RSS.\n\n  The passed in 'date' variable is seconds since epoch.\n\n  \"\"\"\n  if date is None:\n    return None\n  return time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.gmtime(date)) + ' UTC'\n\ndef make_comma_sep_list_string(items):\n  return ', '.join(map(lambda x: x.name, items))\n\ndef is_undisplayable(val):\n  try:\n    unicode(val)\n    return 0\n  except:\n    return 1\n\ndef get_itemprops(request, path_parts, rev):\n  itemprops = request.repos.itemprops(path_parts, rev)\n  propnames = itemprops.keys()\n  propnames.sort()\n  props = []\n  for name in propnames:\n    # skip non-utf8 property names\n    if is_undisplayable(name):\n      continue\n    lf = LogFormatter(request, itemprops[name])\n    value = lf.get(maxlen=0, htmlize=1)\n    undisplayable = is_undisplayable(value)\n    if undisplayable:\n      value = None\n    props.append(_item(name=name, value=value,\n                       undisplayable=ezt.boolean(undisplayable)))\n  return props\n\ndef parse_mime_type(mime_type):\n  mime_parts = map(lambda x: x.strip(), mime_type.split(';'))\n  type_subtype = mime_parts[0].lower()\n  parameters = {}\n  for part in mime_parts[1:]:\n    name, value = part.split('=', 1)\n    parameters[name] = value\n  return type_subtype, parameters\n  \ndef calculate_mime_type(request, path_parts, rev):\n  \"\"\"Return a 2-tuple carrying the MIME content type and character\n  encoding for the file represented by PATH_PARTS in REV.  Use REQUEST\n  for repository access as necessary.\"\"\"\n  if not path_parts:\n    return None, None\n  mime_type = encoding = None\n  if request.roottype == 'svn' \\\n     and (not request.cfg.options.svn_ignore_mimetype):\n    try:\n      itemprops = request.repos.itemprops(path_parts, rev)\n      mime_type = itemprops.get('svn:mime-type')\n      if mime_type:\n        mime_type, parameters = parse_mime_type(mime_type)\n        return mime_type, parameters.get('charset')\n    except:\n      pass\n  return guess_mime(path_parts[-1]), None\n\ndef assert_viewable_filesize(cfg, filesize):\n  if cfg.options.max_filesize_kbytes \\\n     and filesize != -1 \\\n     and filesize > (1024 * cfg.options.max_filesize_kbytes):\n    raise debug.ViewVCException('Display of files larger than %d KB '\n                                'disallowed by configuration'\n                                % (cfg.options.max_filesize_kbytes),\n                                '403 Forbidden')\n  \ndef markup_or_annotate(request, is_annotate):\n  cfg = request.cfg\n  path, rev = _orig_path(request, is_annotate and 'annotate' or 'revision')\n  lines = fp = image_src_href = None\n  annotation = 'none'\n  revision = None\n  mime_type, encoding = calculate_mime_type(request, path, rev)\n\n  # Is this display blocked by 'binary_mime_types' configuration?\n  if is_binary_file_mime_type(mime_type, cfg):\n    raise debug.ViewVCException('Display of binary file content disabled '\n                                'by configuration', '403 Forbidden')\n    \n  # Is this a viewable image type?\n  if is_viewable_image(mime_type) \\\n     and 'co' in cfg.options.allowed_views:\n    fp, revision = request.repos.openfile(path, rev, {})\n    fp.close()\n    if check_freshness(request, None, revision, weak=1):\n      return\n    if is_annotate:\n      annotation = 'binary'\n    image_src_href = request.get_url(view_func=view_checkout,\n                                     params={'revision': rev}, escape=1)\n\n  # Not a viewable image.\n  else:\n    filesize = request.repos.filesize(path, rev)\n\n    # If configuration disallows display of large files, try to honor\n    # that request.\n    assert_viewable_filesize(cfg, filesize)\n\n    # If this was an annotation request, try to annotate this file.\n    # If something goes wrong, that's okay -- we'll gracefully revert\n    # to a plain markup display.\n    blame_data = None\n    if is_annotate:\n      try:\n        blame_source, revision = request.repos.annotate(path, rev, False)\n        if check_freshness(request, None, revision, weak=1):\n          return\n        # Create BLAME_DATA list from BLAME_SOURCE, adding diff_href\n        # items to each relevant \"line\".\n        blame_data = []\n        for item in blame_source:\n          item.diff_href = None\n          if item.prev_rev:\n            item.diff_href = request.get_url(view_func=view_diff,\n                                             params={'r1': item.prev_rev,\n                                                     'r2': item.rev},\n                                             escape=1, partial=1)\n          blame_data.append(item)\n        annotation = 'annotated'\n      except vclib.NonTextualFileContents:\n        annotation = 'binary'\n      except:\n        annotation = 'error'\n\n    # Grab the file contents.\n    fp, revision = request.repos.openfile(path, rev, {'cvs_oldkeywords' : 1})\n    if check_freshness(request, None, revision, weak=1):\n      fp.close()\n      return\n\n    # If we're limiting by filesize but couldn't pull off the cheap\n    # check above, we'll try to do so line by line here (while\n    # building our file_lines array).\n    if cfg.options.max_filesize_kbytes and filesize == -1:\n      file_lines = []\n      filesize = 0\n      while 1:\n        line = fp.readline()\n        if not line:\n          break\n        filesize = filesize + len(line)\n        assert_viewable_filesize(cfg, filesize)\n        file_lines.append(line)\n    else:\n      file_lines = fp.readlines()\n    fp.close()\n\n    # Try to colorize the file contents.\n    colorize = cfg.options.enable_syntax_coloration\n    try:\n      lines = markup_file_contents(request, cfg, file_lines, path[-1],\n                                   mime_type, encoding, colorize)\n    except:\n      if colorize:\n        lines = markup_file_contents(request, cfg, file_lines, path[-1],\n                                     mime_type, encoding, False)\n      else:\n        raise debug.ViewVCException('Error displaying file contents',\n                                    '500 Internal Server Error')\n\n    # Now, try to match up the annotation data (if any) with the file\n    # lines.\n    lines, errorful = merge_blame_data(lines, blame_data)\n    if errorful:\n      annotation = 'error'\n        \n  data = common_template_data(request, revision, mime_type)\n  data.merge(TemplateData({\n    'mime_type' : mime_type,\n    'log' : None,\n    'date' : None,\n    'ago' : None,\n    'author' : None,\n    'branches' : None,\n    'tags' : None,\n    'branch_points' : None,\n    'changed' : None,\n    'size' : None,\n    'state' : None,\n    'vendor_branch' : None,\n    'prev' : None,\n    'orig_path' : None,\n    'orig_href' : None,\n    'image_src_href' : image_src_href,\n    'lines' : lines,\n    'properties' : get_itemprops(request, path, rev),\n    'annotation' : annotation,\n    }))\n\n  if cfg.options.show_log_in_markup:\n    options = {\n      'svn_latest_log': 1, ### FIXME: Use of this magical value is uncool.\n      'svn_cross_copies': 1,\n      }\n    revs = request.repos.itemlog(path, revision, vclib.SORTBY_REV,\n                                 0, 1, options)\n    entry = revs[-1]\n    lf = LogFormatter(request, entry.log)\n\n    data['date'] = make_time_string(entry.date, cfg)\n    data['author'] = entry.author\n    data['changed'] = entry.changed\n    data['log'] = lf.get(maxlen=0, htmlize=1)\n    data['size'] = entry.size\n\n    if entry.date is not None:\n      data['ago'] = html_time(request, entry.date, 1)\n\n    if request.roottype == 'cvs':\n      branch = entry.branch_number\n      prev = entry.prev or entry.parent\n      data['state'] = entry.dead and 'dead'\n      data['prev'] = prev and prev.string\n      data['vendor_branch'] = ezt.boolean(branch and branch[2] % 2 == 1)\n\n      ### TODO:  Should this be using prep_tags() instead?\n      data['branches'] = make_comma_sep_list_string(entry.branches)\n      data['tags'] = make_comma_sep_list_string(entry.tags)\n      data['branch_points']= make_comma_sep_list_string(entry.branch_points)\n\n  if path != request.path_parts:\n    orig_path = _path_join(path)\n    data['orig_path'] = orig_path\n    data['orig_href'] = request.get_url(view_func=view_log,\n                                        where=orig_path,\n                                        pathtype=vclib.FILE,\n                                        params={'pathrev': revision},\n                                        escape=1)\n    \n  generate_page(request, \"file\", data)\n  \ndef view_markup(request):\n  if 'markup' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Markup view is disabled',\n                                '403 Forbidden')\n  if request.pathtype != vclib.FILE:\n    raise debug.ViewVCException('Unsupported feature: markup view on '\n                                'directory', '400 Bad Request')\n  markup_or_annotate(request, 0)\n\ndef view_annotate(request):\n  if 'annotate' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Annotation view is disabled',\n                                 '403 Forbidden')\n  if request.pathtype != vclib.FILE:\n    raise debug.ViewVCException('Unsupported feature: annotate view on '\n                                'directory', '400 Bad Request')\n  markup_or_annotate(request, 1)\n\ndef revcmp(rev1, rev2):\n  rev1 = map(int, rev1.split('.'))\n  rev2 = map(int, rev2.split('.'))\n  return cmp(rev1, rev2)\n\ndef sort_file_data(file_data, roottype, sortdir, sortby, group_dirs):\n  # convert sortdir into a sign bit\n  s = sortdir == \"down\" and -1 or 1\n\n  # in cvs, revision numbers can't be compared meaningfully between\n  # files, so try to do the right thing and compare dates instead\n  if roottype == \"cvs\" and sortby == \"rev\":\n    sortby = \"date\"\n\n  def file_sort_sortby(file1, file2, sortby):\n    # sort according to sortby\n    if sortby == 'rev':\n      return s * revcmp(file1.rev, file2.rev)\n    elif sortby == 'date':\n      return s * cmp(file2.date, file1.date)        # latest date is first\n    elif sortby == 'log':\n      return s * cmp(file1.log, file2.log)\n    elif sortby == 'author':\n      return s * cmp(file1.author, file2.author)\n    return s * cmp(file1.name, file2.name)\n\n  def file_sort_cmp(file1, file2, sortby=sortby, group_dirs=group_dirs, s=s):\n    # if we're grouping directories together, sorting is pretty\n    # simple.  a directory sorts \"higher\" than a non-directory, and\n    # two directories are sorted as normal.\n    if group_dirs:\n      if file1.kind == vclib.DIR:\n        if file2.kind == vclib.DIR:\n          # two directories, no special handling.\n          return file_sort_sortby(file1, file2, sortby)\n        else:\n          # file1 is a directory, it sorts first.\n          return -1\n      elif file2.kind == vclib.DIR:\n        # file2 is a directory, it sorts first.\n        return 1\n\n    # we should have data on these. if not, then it is because we requested\n    # a specific tag and that tag is not present on the file.\n    if file1.rev is not None and file2.rev is not None:\n      return file_sort_sortby(file1, file2, sortby)\n    elif file1.rev is not None:\n      return -1\n    elif file2.rev is not None:\n      return 1\n\n    # sort by file name\n    return s * cmp(file1.name, file2.name)\n\n  file_data.sort(file_sort_cmp)\n\ndef icmp(x, y):\n  \"\"\"case insensitive comparison\"\"\"\n  return cmp(x.lower(), y.lower())\n\ndef view_roots(request):\n  if 'roots' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Root listing view is disabled',\n                                '403 Forbidden')\n  \n  # add in the roots for the selection\n  roots = []\n  expand_root_parents(request.cfg)\n  allroots = list_roots(request)\n  if len(allroots):\n    rootnames = allroots.keys()\n    rootnames.sort(icmp)\n    for rootname in rootnames:\n      root_path, root_type, lastmod = allroots[rootname]\n      href = request.get_url(view_func=view_directory,\n                             where='', pathtype=vclib.DIR,\n                             params={'root': rootname}, escape=1)\n      if root_type == vclib.SVN:\n        log_href = request.get_url(view_func=view_log,\n                                   where='', pathtype=vclib.DIR,\n                                   params={'root': rootname}, escape=1)\n      else:\n        log_href = None\n      roots.append(_item(name=request.server.escape(rootname),\n                         type=root_type,\n                         path=root_path,\n                         author=lastmod and lastmod.author or None,\n                         ago=lastmod and lastmod.ago or None,\n                         date=lastmod and lastmod.date or None,\n                         log=lastmod and lastmod.log or None,\n                         short_log=lastmod and lastmod.short_log or None,\n                         rev=lastmod and lastmod.rev or None,\n                         href=href,\n                         log_href=log_href))\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'roots' : roots,\n    'roots_shown' : len(roots), \n    }))\n  generate_page(request, \"roots\", data)\n\ndef view_directory(request):\n  cfg = request.cfg\n\n  # For Subversion repositories, the revision acts as a weak validator for\n  # the directory listing (to take into account template changes or\n  # revision property changes).\n  if request.roottype == 'svn':\n    try:\n      rev = request.repos._getrev(request.pathrev)\n    except vclib.InvalidRevision:\n      raise debug.ViewVCException('Invalid revision', '404 Not Found')\n    tree_rev = request.repos.created_rev(request.where, rev)\n    if check_freshness(request, None, str(tree_rev), weak=1):\n      return\n\n  # List current directory\n  options = {}\n  if request.roottype == 'cvs':\n    hideattic = int(request.query_dict.get('hideattic', \n                                           cfg.options.hide_attic))\n    options[\"cvs_subdirs\"] = (cfg.options.show_subdir_lastmod and\n                              cfg.options.show_logs)\n  debug.t_start(\"listdir\")\n  file_data = request.repos.listdir(request.path_parts, request.pathrev,\n                                    options)\n  debug.t_end(\"listdir\")\n\n  # sort with directories first, and using the \"sortby\" criteria\n  sortby = request.query_dict.get('sortby', cfg.options.sort_by) or 'file'\n  sortdir = request.query_dict.get('sortdir', 'up')\n\n  # when paging and sorting by filename, we can greatly improve\n  # performance by \"cheating\" -- first, we sort (we already have the\n  # names), then we just fetch dirlogs for the needed entries.\n  # however, when sorting by other properties or not paging, we've no\n  # choice but to fetch dirlogs for everything.\n  debug.t_start(\"dirlogs\")\n  if cfg.options.dir_pagesize and sortby == 'file':\n    dirlogs_first = int(request.query_dict.get('dir_pagestart', 0))\n    if dirlogs_first > len(file_data):\n      dirlogs_first = 0\n    dirlogs_last = dirlogs_first + cfg.options.dir_pagesize\n    for file in file_data:\n      file.rev = None\n      file.date = None\n      file.log = None\n      file.author = None\n      file.size = None\n      file.lockinfo = None\n      file.dead = None\n    sort_file_data(file_data, request.roottype, sortdir, sortby,\n                   cfg.options.sort_group_dirs)\n    # request dirlogs only for the slice of files in \"this page\"\n    request.repos.dirlogs(request.path_parts, request.pathrev,\n                          file_data[dirlogs_first:dirlogs_last], options)\n  else:\n    request.repos.dirlogs(request.path_parts, request.pathrev,\n                          file_data, options)\n    sort_file_data(file_data, request.roottype, sortdir, sortby,\n                   cfg.options.sort_group_dirs)\n  debug.t_end(\"dirlogs\")\n\n  # If a regex is specified, build a compiled form thereof for filtering\n  searchstr = None\n  search_re = request.query_dict.get('search', '')\n  if cfg.options.use_re_search and search_re:\n    searchstr = re.compile(search_re)\n\n  # loop through entries creating rows and changing these values\n  rows = [ ]\n  dirs_displayed = files_displayed = 0\n  num_dead = 0\n  \n  # set some values to be used inside loop\n  where = request.where\n  where_prefix = where and where + '/'\n\n  debug.t_start(\"row-building\")\n  for file in file_data:\n    if is_dir_ignored_file(file.name, cfg):\n      continue\n    row = _item(author=None, log=None, short_log=None, state=None, size=None,\n                log_file=None, log_rev=None, graph_href=None, mime_type=None,\n                date=None, ago=None, view_href=None, log_href=None,\n                revision_href=None, annotate_href=None, download_href=None,\n                download_text_href=None, prefer_markup=ezt.boolean(0),\n                is_viewable_image=ezt.boolean(0), is_binary=ezt.boolean(0))\n    if request.roottype == 'cvs' and file.absent:\n      continue\n    if cfg.options.hide_errorful_entries and file.errors:\n      continue\n    row.rev = file.rev\n    row.author = file.author\n    row.state = (request.roottype == 'cvs' and file.dead) and 'dead' or ''\n    if file.date is not None:\n      row.date = make_time_string(file.date, cfg)\n      row.ago = html_time(request, file.date)\n    if cfg.options.show_logs:\n      debug.t_start(\"dirview_logformat\")\n      lf = LogFormatter(request, file.log)\n      row.log = lf.get(maxlen=0, htmlize=1)\n      row.short_log = lf.get(maxlen=cfg.options.short_log_len, htmlize=1)\n      debug.t_end(\"dirview_logformat\")\n    row.lockinfo = file.lockinfo\n    row.anchor = request.server.escape(file.name)\n    row.name = request.server.escape(file.name)\n    row.pathtype = (file.kind == vclib.FILE and 'file') or \\\n                   (file.kind == vclib.DIR and 'dir')\n    row.errors = file.errors\n\n    if file.kind == vclib.DIR:\n      if cfg.options.hide_cvsroot \\\n         and is_cvsroot_path(request.roottype,\n                             request.path_parts + [file.name]):\n        continue\n    \n      dirs_displayed += 1\n\n      row.view_href = request.get_url(view_func=view_directory,\n                                      where=where_prefix+file.name,\n                                      pathtype=vclib.DIR,\n                                      params={},\n                                      escape=1)\n\n      if request.roottype == 'svn':\n        row.revision_href = request.get_url(view_func=view_revision,\n                                            params={'revision': file.rev},\n                                            escape=1)\n\n      if request.roottype == 'cvs' and file.rev is not None:\n        row.rev = None\n        if cfg.options.show_logs:\n          row.log_file = file.newest_file\n          row.log_rev = file.rev\n\n      if request.roottype == 'svn':\n        row.log_href = request.get_url(view_func=view_log,\n                                       where=where_prefix + file.name,\n                                       pathtype=vclib.DIR,\n                                       params={},\n                                       escape=1)\n      \n    elif file.kind == vclib.FILE:\n      if searchstr is not None:\n        if request.roottype == 'cvs' and (file.errors or file.dead):\n          continue\n        if not search_file(request.repos, request.path_parts + [file.name],\n                           request.pathrev, searchstr):\n          continue\n      if request.roottype == 'cvs' and file.dead:\n        num_dead = num_dead + 1\n        if hideattic:\n          continue\n        \n      files_displayed += 1\n\n      file_where = where_prefix + file.name\n      if request.roottype == 'svn': \n        row.size = file.size\n\n      row.mime_type, encoding = calculate_mime_type(request,\n                                                    _path_parts(file_where),\n                                                    file.rev)\n      fvi = get_file_view_info(request, file_where, file.rev, row.mime_type)\n      row.view_href = fvi.view_href\n      row.download_href = fvi.download_href\n      row.download_text_href = fvi.download_text_href\n      row.annotate_href = fvi.annotate_href\n      row.revision_href = fvi.revision_href\n      row.prefer_markup = fvi.prefer_markup\n      row.is_viewable_image = fvi.is_viewable_image\n      row.is_binary = fvi.is_binary\n      row.log_href = request.get_url(view_func=view_log,\n                                     where=file_where,\n                                     pathtype=vclib.FILE,\n                                     params={},\n                                     escape=1)\n      if cfg.options.use_cvsgraph and request.roottype == 'cvs':\n         row.graph_href = request.get_url(view_func=view_cvsgraph,\n                                          where=file_where,\n                                          pathtype=vclib.FILE,\n                                          params={},\n                                          escape=1)\n\n    rows.append(row)\n  debug.t_end(\"row-building\")\n\n  # Prepare the data that will be passed to the template, based on the\n  # common template data.\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'entries' : rows,\n    'sortby' : sortby,\n    'sortdir' : sortdir,\n    'search_re' : request.server.escape(search_re),\n    'dir_pagestart' : None,\n    'sortby_file_href' :   request.get_url(params={'sortby': 'file',\n                                                   'sortdir': None},\n                                           escape=1),\n    'sortby_rev_href' :    request.get_url(params={'sortby': 'rev',\n                                                   'sortdir': None},\n                                           escape=1),\n    'sortby_date_href' :   request.get_url(params={'sortby': 'date',\n                                                   'sortdir': None},\n                                           escape=1),\n    'sortby_author_href' : request.get_url(params={'sortby': 'author',\n                                                   'sortdir': None},\n                                           escape=1),\n    'sortby_log_href' :    request.get_url(params={'sortby': 'log',\n                                                   'sortdir': None},\n                                           escape=1),\n    'files_shown' : files_displayed,\n    'dirs_shown' : dirs_displayed,\n    'num_dead' : num_dead,\n    'youngest_rev' : None,\n    'youngest_rev_href' : None,\n    'selection_form' : None,\n    'attic_showing' : None,\n    'show_attic_href' : None,\n    'hide_attic_href' : None,\n    'branch_tags': None,\n    'plain_tags': None,\n    'properties': get_itemprops(request, request.path_parts, request.pathrev),\n    'tree_rev' : None,\n    'tree_rev_href' : None,\n    'dir_paging_action' : None,\n    'dir_paging_hidden_values' : [],\n    'search_re_action' : None,\n    'search_re_hidden_values' : [],\n\n    # Populated by paging()/paging_sws()\n    'picklist' : [],\n    'picklist_len' : 0,\n\n    # Populated by pathrev_form()\n    'pathrev_action' : None,\n    'pathrev_hidden_values' : [],\n    'pathrev_clear_action' : None,\n    'pathrev_clear_hidden_values' : [],\n    'pathrev' : None,\n    'lastrev' : None,\n  }))\n\n  # clicking on sort column reverses sort order\n  if sortdir == 'down':\n    revsortdir = None # 'up'\n  else:\n    revsortdir = 'down'\n  if sortby in ['file', 'rev', 'date', 'log', 'author']:\n    data['sortby_%s_href' % sortby] = request.get_url(params={'sortdir':\n                                                              revsortdir},\n                                                      escape=1)\n  # CVS doesn't support sorting by rev\n  if request.roottype == \"cvs\":\n    data['sortby_rev_href'] = None\n\n  # set cvs-specific fields\n  if request.roottype == 'cvs':\n    plain_tags = options['cvs_tags']\n    plain_tags.sort(icmp)\n    plain_tags.reverse()\n    data['plain_tags'] = []\n    for plain_tag in plain_tags:\n      data['plain_tags'].append(_item(name=plain_tag, revision=None))\n\n    branch_tags = options['cvs_branches']\n    branch_tags.sort(icmp)\n    branch_tags.reverse()\n    data['branch_tags'] = []\n    for branch_tag in branch_tags:\n      data['branch_tags'].append(_item(name=branch_tag, revision=None))\n    \n    data['attic_showing'] = ezt.boolean(not hideattic)\n    data['show_attic_href'] = request.get_url(params={'hideattic': 0},\n                                              escape=1)\n    data['hide_attic_href'] = request.get_url(params={'hideattic': 1},\n                                              escape=1)\n\n  # set svn-specific fields\n  elif request.roottype == 'svn':\n    data['tree_rev'] = tree_rev\n    data['tree_rev_href'] = request.get_url(view_func=view_revision,\n                                            params={'revision': tree_rev},\n                                            escape=1)\n    data['youngest_rev'] = request.repos.get_youngest_revision()\n    data['youngest_rev_href'] = request.get_url(view_func=view_revision,\n                                                params={},\n                                                escape=1)\n\n  if cfg.options.dir_pagesize:\n    data['dir_paging_action'], data['dir_paging_hidden_values'] = \\\n      request.get_form(params={'dir_pagestart': None})\n\n  pathrev_form(request, data)\n\n  if cfg.options.use_re_search:\n    data['search_re_action'], data['search_re_hidden_values'] = \\\n      request.get_form(params={'search': None})\n\n  if cfg.options.dir_pagesize:\n    data['dir_pagestart'] = int(request.query_dict.get('dir_pagestart',0))\n    data['entries'] = paging(data, 'entries', data['dir_pagestart'], 'name',\n                             cfg.options.dir_pagesize)\n\n  generate_page(request, \"directory\", data)\n\ndef paging(data, key, pagestart, local_name, pagesize):\n  # Implement paging\n  # Create the picklist\n  picklist = data['picklist'] = []\n  for i in range(0, len(data[key]), pagesize):\n    pick = _item(start=None, end=None, count=None, more=ezt.boolean(0))\n    pick.start = getattr(data[key][i], local_name)\n    pick.count = i\n    pick.page = (i / pagesize) + 1\n    try:\n      pick.end = getattr(data[key][i+pagesize-1], local_name)\n    except IndexError:\n      pick.end = getattr(data[key][-1], local_name)\n    picklist.append(pick)\n  data['picklist_len'] = len(picklist)\n  # Need to fix\n  # pagestart can be greater than the length of data[key] if you\n  # select a tag or search while on a page other than the first.\n  # Should reset to the first page, this test won't do that every\n  # time that it is needed.\n  # Problem might go away if we don't hide non-matching files when\n  # selecting for tags or searching.\n  if pagestart > len(data[key]):\n    pagestart = 0\n  pageend = pagestart + pagesize\n  # Slice\n  return data[key][pagestart:pageend]\n\ndef paging_sws(data, key, pagestart, local_name, pagesize,\n               extra_pages, offset):\n  \"\"\"Implement sliding window-style paging.\"\"\"\n  # Create the picklist\n  last_requested = pagestart + (extra_pages * pagesize)\n  picklist = data['picklist'] = []\n  has_more = ezt.boolean(0)\n  for i in range(0, len(data[key]), pagesize):\n    pick = _item(start=None, end=None, count=None, more=ezt.boolean(0))\n    pick.start = getattr(data[key][i], local_name)\n    pick.count = offset + i\n    pick.page = (pick.count / pagesize) + 1\n    try:\n      pick.end = getattr(data[key][i+pagesize-1], local_name)\n    except IndexError:\n      pick.end = getattr(data[key][-1], local_name)   \n    picklist.append(pick)\n    if pick.count >= last_requested:\n      pick.more = ezt.boolean(1)\n      break\n  data['picklist_len'] = len(picklist)\n  first = pagestart - offset\n  # FIXME: first can be greater than the length of data[key] if\n  # you select a tag or search while on a page other than the first.\n  # Should reset to the first page, but this test won't do that every\n  # time that it is needed.  Problem might go away if we don't hide\n  # non-matching files when selecting for tags or searching.\n  if first > len(data[key]):\n    pagestart = 0\n  pageend = first + pagesize\n  # Slice\n  return data[key][first:pageend]\n\ndef pathrev_form(request, data):\n  lastrev = None\n\n  if request.roottype == 'svn':\n    data['pathrev_action'], data['pathrev_hidden_values'] = \\\n      request.get_form(view_func=redirect_pathrev,\n                       params={'pathrev': None,\n                               'orig_path': request.where,\n                               'orig_pathtype': request.pathtype,\n                               'orig_pathrev': request.pathrev,\n                               'orig_view': _view_codes.get(request.view_func)})\n\n    if request.pathrev:\n      youngest = request.repos.get_youngest_revision()\n      lastrev = request.repos.last_rev(request.where, request.pathrev,\n                                       youngest)[0]\n\n      if lastrev == youngest:\n        lastrev = None\n\n  data['pathrev'] = request.pathrev\n  data['lastrev'] = lastrev\n\n  action, hidden_values = request.get_form(params={'pathrev': lastrev})\n  if request.roottype != 'svn':\n    data['pathrev_action'] = action\n    data['pathrev_hidden_values'] = hidden_values\n  data['pathrev_clear_action'] = action\n  data['pathrev_clear_hidden_values'] = hidden_values\n\n  return lastrev\n\ndef redirect_pathrev(request):\n  assert request.roottype == 'svn'\n  new_pathrev = request.query_dict.get('pathrev') or None\n  path = request.query_dict.get('orig_path', '')\n  pathtype = request.query_dict.get('orig_pathtype')\n  pathrev = request.query_dict.get('orig_pathrev') \n  view = _views.get(request.query_dict.get('orig_view'))\n  \n  youngest = request.repos.get_youngest_revision()\n\n  # go out of the way to allow revision numbers higher than youngest\n  try:\n    new_pathrev = int(new_pathrev)\n  except ValueError:\n    new_pathrev = youngest\n  except TypeError:\n    pass\n  else:\n    if new_pathrev > youngest:\n      new_pathrev = youngest\n\n  if _repos_pathtype(request.repos, _path_parts(path), new_pathrev):\n    pathrev = new_pathrev\n  else:\n    pathrev, path = request.repos.last_rev(path, pathrev, new_pathrev)\n    # allow clearing sticky revision by submitting empty string\n    if new_pathrev is None and pathrev == youngest:\n      pathrev = None\n\n  request.server.redirect(request.get_url(view_func=view, \n                                          where=path,\n                                          pathtype=pathtype,\n                                          params={'pathrev': pathrev}))\n\ndef view_log(request):\n  cfg = request.cfg\n  diff_format = request.query_dict.get('diff_format', cfg.options.diff_format)\n  pathtype = request.pathtype\n\n  if pathtype is vclib.DIR:\n    if request.roottype == 'cvs':\n      raise debug.ViewVCException('Unsupported feature: log view on CVS '\n                                  'directory', '400 Bad Request')\n    mime_type = encoding = None\n  else:\n    mime_type, encoding = calculate_mime_type(request,\n                                              request.path_parts,\n                                              request.pathrev)\n\n  options = {}\n  options['svn_show_all_dir_logs'] = 1 ### someday make this optional?\n  options['svn_cross_copies'] = cfg.options.cross_copies\n\n  logsort = request.query_dict.get('logsort', cfg.options.log_sort)\n  if request.roottype == \"svn\":\n    sortby = vclib.SORTBY_DEFAULT\n    logsort = None\n  else:\n    if logsort == 'date':\n      sortby = vclib.SORTBY_DATE\n    elif logsort == 'rev':\n      sortby = vclib.SORTBY_REV\n    else:\n      sortby = vclib.SORTBY_DEFAULT\n\n  first = last = 0\n  log_pagestart = None\n  if cfg.options.log_pagesize:\n    log_pagestart = int(request.query_dict.get('log_pagestart', 0))\n    total = cfg.options.log_pagesextra * cfg.options.log_pagesize\n    first = log_pagestart - min(log_pagestart, total)\n    last = log_pagestart + (total + cfg.options.log_pagesize) + 1\n  show_revs = request.repos.itemlog(request.path_parts, request.pathrev,\n                                    sortby, first, last - first, options)\n\n  # selected revision\n  selected_rev = request.query_dict.get('r1')\n\n  entries = [ ]\n  name_printed = { }\n  cvs = request.roottype == 'cvs'\n  for rev in show_revs:\n    entry = _item()\n    entry.rev = rev.string\n    entry.state = (cvs and rev.dead and 'dead')\n    entry.author = rev.author\n    entry.changed = rev.changed\n    entry.date = make_time_string(rev.date, cfg)\n    entry.ago = None\n    if rev.date is not None:\n      entry.ago = html_time(request, rev.date, 1)\n    entry.size = rev.size\n    entry.lockinfo = rev.lockinfo\n    entry.branch_point = None\n    entry.next_main = None\n    entry.orig_path = None\n    entry.copy_path = None\n\n    lf = LogFormatter(request, rev.log or '')\n    entry.log = lf.get(maxlen=0, htmlize=1)\n\n    entry.view_href = None\n    entry.download_href = None\n    entry.download_text_href = None\n    entry.annotate_href = None\n    entry.revision_href = None\n    entry.sel_for_diff_href = None\n    entry.diff_to_sel_href = None\n    entry.diff_to_prev_href = None\n    entry.diff_to_branch_href = None\n    entry.diff_to_main_href = None\n        \n    if request.roottype == 'cvs':\n      prev = rev.prev or rev.parent\n      entry.prev = prev and prev.string\n\n      branch = rev.branch_number\n      entry.vendor_branch = ezt.boolean(branch and branch[2] % 2 == 1)\n\n      entry.branches = prep_tags(request, rev.branches)\n      entry.tags = prep_tags(request, rev.tags)\n      entry.branch_points = prep_tags(request, rev.branch_points)\n\n      entry.tag_names = map(lambda x: x.name, rev.tags)\n      if branch and not name_printed.has_key(branch):\n        entry.branch_names = map(lambda x: x.name, rev.branches)\n        name_printed[branch] = 1\n      else:\n        entry.branch_names = [ ]\n\n      if rev.parent and rev.parent is not prev and not entry.vendor_branch:\n        entry.branch_point = rev.parent.string\n\n      # if it's the last revision on a branch then diff against the\n      # last revision on the higher branch (e.g. change is committed and\n      # brought over to -stable)\n      if not rev.next and rev.parent and rev.parent.next:\n        r = rev.parent.next\n        while r.next:\n          r = r.next\n        entry.next_main = r.string\n\n    elif request.roottype == 'svn':\n      entry.prev = rev.prev and rev.prev.string\n      entry.branches = entry.tags = entry.branch_points = [ ]\n      entry.tag_names = entry.branch_names = [ ]\n      entry.vendor_branch = None\n      if rev.filename != request.where:\n        entry.orig_path = rev.filename\n      entry.copy_path = rev.copy_path\n      entry.copy_rev = rev.copy_rev\n\n      if entry.orig_path:\n        entry.orig_href = request.get_url(view_func=view_log,\n                                          where=entry.orig_path,\n                                          pathtype=vclib.FILE,\n                                          params={'pathrev': rev.string},\n                                          escape=1)\n\n      if rev.copy_path:\n        entry.copy_href = request.get_url(view_func=view_log,\n                                          where=rev.copy_path,\n                                          pathtype=vclib.FILE,\n                                          params={'pathrev': rev.copy_rev},\n                                          escape=1)\n\n\n    # view/download links\n    if pathtype is vclib.FILE:\n      fvi = get_file_view_info(request, request.where, rev.string, mime_type)\n      entry.view_href = fvi.view_href\n      entry.download_href = fvi.download_href\n      entry.download_text_href = fvi.download_text_href\n      entry.annotate_href = fvi.annotate_href\n      entry.revision_href = fvi.revision_href\n      entry.prefer_markup = fvi.prefer_markup\n    else:\n      entry.revision_href = request.get_url(view_func=view_revision,\n                                            params={'revision': rev.string},\n                                            escape=1)\n      entry.view_href = request.get_url(view_func=view_directory,\n                                        where=rev.filename,\n                                        pathtype=vclib.DIR,\n                                        params={'pathrev': rev.string},\n                                        escape=1)\n\n    # calculate diff links\n    if selected_rev != entry.rev:\n      entry.sel_for_diff_href = \\\n        request.get_url(view_func=view_log,\n                        params={'r1': entry.rev,\n                                'log_pagestart': log_pagestart},\n                        escape=1)\n    if entry.prev is not None:\n      entry.diff_to_prev_href = \\\n        request.get_url(view_func=view_diff,\n                        params={'r1': entry.prev,\n                                'r2': entry.rev,\n                                'diff_format': None},\n                        escape=1)\n    if selected_rev and \\\n           selected_rev != str(entry.rev) and \\\n           selected_rev != str(entry.prev) and \\\n           selected_rev != str(entry.branch_point) and \\\n           selected_rev != str(entry.next_main):\n      entry.diff_to_sel_href = \\\n        request.get_url(view_func=view_diff,\n                        params={'r1': selected_rev,\n                                'r2': entry.rev,\n                                'diff_format': None},\n                        escape=1)\n\n    if entry.next_main:\n      entry.diff_to_main_href = \\\n        request.get_url(view_func=view_diff,\n                        params={'r1': entry.next_main,\n                                'r2': entry.rev,\n                                'diff_format': None},\n                        escape=1)\n    if entry.branch_point:\n      entry.diff_to_branch_href = \\\n        request.get_url(view_func=view_diff,\n                        params={'r1': entry.branch_point,\n                                'r2': entry.rev,\n                                'diff_format': None},\n                        escape=1)\n\n    # Save our escaping until the end so stuff above works\n    if entry.orig_path:\n      entry.orig_path = request.server.escape(entry.orig_path)\n    if entry.copy_path:\n      entry.copy_path = request.server.escape(entry.copy_path)\n    entries.append(entry)\n\n  diff_select_action, diff_select_hidden_values = \\\n    request.get_form(view_func=view_diff,\n                     params={'r1': None, 'r2': None, 'tr1': None,\n                             'tr2': None, 'diff_format': None})\n  logsort_action, logsort_hidden_values = \\\n    request.get_form(params={'logsort': None})\n\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'default_branch' : None,\n    'mime_type' : mime_type,\n    'rev_selected' : selected_rev,\n    'diff_format' : diff_format,\n    'logsort' : logsort,\n    'human_readable' : ezt.boolean(diff_format in ('f', 'h', 'l')),\n    'log_pagestart' : None,\n    'log_paging_action' : None,\n    'log_paging_hidden_values' : [],\n    'entries': entries,\n    'head_prefer_markup' : ezt.boolean(0),\n    'head_view_href' : None,\n    'head_download_href': None,\n    'head_download_text_href': None,\n    'head_annotate_href': None,\n    'tag_prefer_markup' : ezt.boolean(0),\n    'tag_view_href' : None,\n    'tag_download_href': None,\n    'tag_download_text_href': None,\n    'tag_annotate_href': None,\n    'diff_select_action' : diff_select_action,\n    'diff_select_hidden_values' : diff_select_hidden_values,\n    'logsort_action' : logsort_action,\n    'logsort_hidden_values' : logsort_hidden_values,\n    'tags' : [],\n    'branch_tags' : [],\n    'plain_tags' : [],\n\n    # Populated by paging()/paging_sws()\n    'picklist' : [],\n    'picklist_len' : 0,\n\n    # Populated by pathrev_form()\n    'pathrev_action' : None,\n    'pathrev_hidden_values' : [],\n    'pathrev_clear_action' : None,\n    'pathrev_clear_hidden_values' : [],\n    'pathrev' : None,\n    'lastrev' : None,\n  }))\n\n  lastrev = pathrev_form(request, data)\n\n  if pathtype is vclib.FILE:\n    if not request.pathrev or lastrev is None:\n      fvi = get_file_view_info(request, request.where, None, mime_type, None)\n      data['head_view_href']= fvi.view_href\n      data['head_download_href']= fvi.download_href\n      data['head_download_text_href']= fvi.download_text_href\n      data['head_annotate_href']= fvi.annotate_href\n      data['head_prefer_markup']= fvi.prefer_markup\n\n    if request.pathrev and request.roottype == 'cvs':\n      fvi = get_file_view_info(request, request.where, None, mime_type)\n      data['tag_view_href']= fvi.view_href\n      data['tag_download_href']= fvi.download_href\n      data['tag_download_text_href']= fvi.download_text_href\n      data['tag_annotate_href']= fvi.annotate_href\n      data['tag_prefer_markup']= fvi.prefer_markup\n  else:\n    data['head_view_href'] = request.get_url(view_func=view_directory, \n                                             params={}, escape=1)\n\n  taginfo = options.get('cvs_tags', {})\n  tagitems = taginfo.items()\n  tagitems.sort()\n  tagitems.reverse()\n\n  main = taginfo.get('MAIN')\n  if main:\n    # Default branch may have multiple names so we list them\n    branches = []\n    for branch in main.aliases:\n      # Don't list MAIN\n      if branch is not main:\n        branches.append(branch)\n    data['default_branch'] = prep_tags(request, branches)\n\n  for tag, rev in tagitems:\n    rev_str = None\n    if rev.number:\n      rev_str = '.'.join(map(str, rev.number))\n\n    if rev.co_rev:\n      data['tags'].append(_item(rev=rev.co_rev.string, name=tag))\n    if rev.is_branch:\n      data['branch_tags'].append(_item(name=tag, revision=rev_str))\n    else:\n      data['plain_tags'].append(_item(name=tag, revision=rev_str))\n\n  if cfg.options.log_pagesize:\n    data['log_paging_action'], data['log_paging_hidden_values'] = \\\n      request.get_form(params={'log_pagestart': None,\n                               'r1': selected_rev,\n                               })\n    data['log_pagestart'] = int(request.query_dict.get('log_pagestart',0))\n    data['entries'] = paging_sws(data, 'entries', data['log_pagestart'],\n                                 'rev', cfg.options.log_pagesize,\n                                 cfg.options.log_pagesextra, first)\n\n  generate_page(request, \"log\", data)\n\ndef view_checkout(request):\n\n  cfg = request.cfg\n  \n  if 'co' not in cfg.options.allowed_views:\n    raise debug.ViewVCException('Checkout view is disabled',\n                                 '403 Forbidden')\n  if request.pathtype != vclib.FILE:\n    raise debug.ViewVCException('Unsupported feature: checkout view on '\n                                'directory', '400 Bad Request')\n\n  path, rev = _orig_path(request)\n  fp, revision = request.repos.openfile(path, rev, {})\n\n  # The revision number acts as a strong validator.\n  if not check_freshness(request, None, revision):\n    mime_type, encoding = calculate_mime_type(request, path, rev)\n    mime_type = request.query_dict.get('content-type') \\\n                or mime_type \\\n                or 'text/plain'\n    server_fp = get_writeready_server_file(request, mime_type, encoding)\n    copy_stream(fp, server_fp)\n  fp.close()\n\ndef cvsgraph_make_reqopt(request, cfgname, queryparam, optvalue):\n  # Return a cvsgraph custom option substring bit OPTVALUE based on\n  # CFGNAME's presence in the allowed list of user-configurable\n  # options and QUERYPARAM's presence and boolean interpretation in\n  # the actual request; otherwise, return the empty string for options\n  # that either aren't overridden or aren't allowed to be overridden.\n  \n  if (cfgname in request.cfg.options.allowed_cvsgraph_useropts) \\\n     and (int(request.query_dict.get(queryparam, 0))):\n    return optvalue\n  return ''\n\ndef cvsgraph_normalize_gshow(request):\n  # Return the effective value of the 'gshow' query parameter, noting\n  # that a missing parameter is the same as gshow=all, and treating a\n  # bogus parameter value as the same as gshow=all, too.\n  gshow = request.query_dict.get('gshow', 'all')\n  if gshow not in ('all', 'inittagged', 'tagged'):\n    gshow = 'all'\n  return gshow\n  \ndef cvsgraph_extraopts(request):\n  # Build a set of -O options for controlling cvsgraph's behavior,\n  # based on what the user has requested and filtered against what the\n  # user is allowed to request.\n  \n  cfg = request.cfg\n\n  ep = '-O'\n\n  # Simple mappings of boolean flags\n  ep = ep + cvsgraph_make_reqopt(request, 'invert', 'gflip',\n                                 ';upside_down=true')\n  ep = ep + cvsgraph_make_reqopt(request, 'branchbox', 'gbbox',\n                                 ';branch_dupbox=true')\n  ep = ep + cvsgraph_make_reqopt(request, 'rotate', 'gleft',\n                                 ';left_right=true')\n\n  # Stripping is a little more complex.\n  if ('show' in request.cfg.options.allowed_cvsgraph_useropts):\n    gshow = cvsgraph_normalize_gshow(request)\n    if gshow == 'inittagged':\n      ep = ep + ';strip_untagged=true'\n    elif gshow == 'tagged':\n      ep = ep + ';strip_untagged=true;strip_first_rev=true'\n\n  # And tag limitation has a user-supplied value to mess with.\n  if ('limittags' in request.cfg.options.allowed_cvsgraph_useropts) \\\n     and request.query_dict.has_key('gmaxtag'):\n    ep = ep + ';rev_maxtags=' + request.query_dict['gmaxtag']\n\n  return ep + ';'\n  \ndef view_cvsgraph_image(request):\n  \"output the image rendered by cvsgraph\"\n  # this function is derived from cgi/cvsgraphmkimg.cgi\n\n  cfg = request.cfg\n\n  if not cfg.options.use_cvsgraph:\n    raise debug.ViewVCException('Graph view is disabled', '403 Forbidden')\n\n  # If cvsgraph can't find its supporting libraries, uncomment and set\n  # accordingly.  Do the same in view_cvsgraph().\n  #os.environ['LD_LIBRARY_PATH'] = '/usr/lib:/usr/local/lib:/path/to/cvsgraph'\n\n  rcsfile = request.repos.rcsfile(request.path_parts)\n  fp = popen.popen(cfg.utilities.cvsgraph or 'cvsgraph',\n                   (\"-c\", cfg.path(cfg.options.cvsgraph_conf),\n                    \"-r\", request.repos.rootpath,\n                    cvsgraph_extraopts(request),\n                    rcsfile), 'rb', 0)\n  \n  copy_stream(fp, get_writeready_server_file(request, 'image/png'))\n  fp.close()\n\ndef view_cvsgraph(request):\n  \"output a page containing an image rendered by cvsgraph\"\n\n  cfg = request.cfg\n\n  if not cfg.options.use_cvsgraph:\n    raise debug.ViewVCException('Graph view is disabled', '403 Forbidden')\n\n  # If cvsgraph can't find its supporting libraries, uncomment and set\n  # accordingly.  Do the same in view_cvsgraph_image().\n  #os.environ['LD_LIBRARY_PATH'] = '/usr/lib:/usr/local/lib:/path/to/cvsgraph'\n\n  imagesrc = request.get_url(view_func=view_cvsgraph_image, escape=1)\n  mime_type = guess_mime(request.where)\n  view = default_view(mime_type, cfg)\n  up_where = _path_join(request.path_parts[:-1])\n\n  # Create an image map\n  rcsfile = request.repos.rcsfile(request.path_parts)\n  fp = popen.popen(cfg.utilities.cvsgraph or 'cvsgraph',\n                   (\"-i\",\n                    \"-c\", cfg.path(cfg.options.cvsgraph_conf),\n                    \"-r\", request.repos.rootpath,\n                    \"-x\", \"x\",\n                    \"-3\", request.get_url(view_func=view_log, params={},\n                                          escape=1),\n                    \"-4\", request.get_url(view_func=view, \n                                          params={'revision': None},\n                                          escape=1, partial=1),\n                    \"-5\", request.get_url(view_func=view_diff,\n                                          params={'r1': None, 'r2': None},\n                                          escape=1, partial=1),\n                    \"-6\", request.get_url(view_func=view_directory,\n                                          where=up_where,\n                                          pathtype=vclib.DIR,\n                                          params={'pathrev': None},\n                                          escape=1, partial=1),\n                    cvsgraph_extraopts(request),\n                    rcsfile), 'rb', 0)\n\n  graph_action, graph_hidden_values = \\\n    request.get_form(view_func=view_cvsgraph, params={})\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'imagemap' : fp,\n    'imagesrc' : imagesrc,\n    'graph_action' : graph_action,\n    'graph_hidden_values' : graph_hidden_values,\n    'opt_gflip' : ezt.boolean('invert' in cfg.options.allowed_cvsgraph_useropts),\n    'opt_gbbox' : ezt.boolean('branchbox' in cfg.options.allowed_cvsgraph_useropts),\n    'opt_gshow' : ezt.boolean('show' in cfg.options.allowed_cvsgraph_useropts),\n    'opt_gleft' : ezt.boolean('rotate' in cfg.options.allowed_cvsgraph_useropts),\n    'opt_gmaxtag' : ezt.boolean('limittags' in cfg.options.allowed_cvsgraph_useropts),\n    'gflip' : ezt.boolean(int(request.query_dict.get('gflip', 0))),\n    'gbbox' : ezt.boolean(int(request.query_dict.get('gbbox', 0))),\n    'gleft' : ezt.boolean(int(request.query_dict.get('gleft', 0))),\n    'gmaxtag' : request.query_dict.get('gmaxtag', 0),\n    'gshow' : cvsgraph_normalize_gshow(request),\n    }))\n  generate_page(request, \"graph\", data)\n\ndef search_file(repos, path_parts, rev, search_re):\n  \"\"\"Return 1 iff the contents of the file at PATH_PARTS in REPOS as\n  of revision REV matches regular expression SEARCH_RE.\"\"\"\n\n  # Read in each line of a checked-out file, and then use re.search to\n  # search line.\n  fp = repos.openfile(path_parts, rev, {})[0]\n  matches = 0\n  while 1:\n    line = fp.readline()\n    if not line:\n      break\n    if search_re.search(line):\n      matches = 1\n      fp.close()\n      break\n  return matches\n\ndef view_doc(request):\n  \"\"\"Serve ViewVC static content locally.\n\n  Using this avoids the need for modifying the setup of the web server.\n  \"\"\"\n  cfg = request.cfg\n  document = request.where\n  filename = cfg.path(os.path.join(cfg.options.template_dir,\n                                   \"docroot\", document))\n\n  # Stat the file to get content length and last-modified date.\n  try:\n    info = os.stat(filename)\n  except OSError, v:\n    raise debug.ViewVCException('Static file \"%s\" not available (%s)'\n                                 % (document, str(v)), '404 Not Found')\n  content_length = str(info[stat.ST_SIZE])\n  last_modified = info[stat.ST_MTIME]\n\n  # content_length + mtime makes a pretty good etag.\n  if check_freshness(request, last_modified,\n                     \"%s-%s\" % (content_length, last_modified)):\n    return\n\n  try:\n    fp = open(filename, \"rb\")\n  except IOError, v:\n    raise debug.ViewVCException('Static file \"%s\" not available (%s)'\n                                 % (document, str(v)), '404 Not Found')\n\n  if document[-3:] == 'png':\n    mime_type = 'image/png'\n  elif document[-3:] == 'jpg':\n    mime_type = 'image/jpeg'\n  elif document[-3:] == 'gif':\n    mime_type = 'image/gif'\n  elif document[-3:] == 'css':\n    mime_type = 'text/css'\n  else: # assume HTML:\n    mime_type = None\n  copy_stream(fp, get_writeready_server_file(request, mime_type,\n                                             content_length=content_length))\n  fp.close()\n\ndef rcsdiff_date_reformat(date_str, cfg):\n  if date_str is None:\n    return None\n  try:\n    date = vclib.ccvs.cvs_strptime(date_str)\n  except ValueError:\n    return date_str\n  return make_time_string(calendar.timegm(date), cfg)\n\n_re_extract_rev = re.compile(r'^[-+*]{3} [^\\t]+\\t([^\\t]+)\\t((\\d+\\.)*\\d+)$')\n_re_extract_info = re.compile(r'@@ \\-([0-9]+).*\\+([0-9]+).*@@(.*)')\n\nclass DiffSource:\n  def __init__(self, fp, cfg):\n    self.fp = fp\n    self.cfg = cfg\n    self.save_line = None\n    self.line_number = None\n    self.prev_line_number = None\n    \n    # keep track of where we are during an iteration\n    self.idx = -1\n    self.last = None\n\n    # these will be set once we start reading\n    self.state = 'no-changes'\n    self.left_col = [ ]\n    self.right_col = [ ]\n\n  def __getitem__(self, idx):\n    if idx == self.idx:\n      return self.last\n    if idx != self.idx + 1:\n      raise DiffSequencingError()\n\n    # keep calling _get_row until it gives us something. sometimes, it\n    # doesn't return a row immediately because it is accumulating changes.\n    # when it is out of data, _get_row will raise IndexError.\n    while 1:\n      item = self._get_row()\n      if item:\n        self.idx = idx\n        self.last = item\n        return item\n\n  def _format_text(self, text):\n    text = text.rstrip('\\r\\n')\n    if self.cfg.options.tabsize > 0:\n      text = text.expandtabs(self.cfg.options.tabsize)\n    hr_breakable = self.cfg.options.hr_breakable\n    \n    # in the code below, \"\\x01\" will be our stand-in for \"&\". We don't want\n    # to insert \"&\" because it would get escaped by sapi.escape().  Similarly,\n    # we use \"\\x02\" as a stand-in for \"<br>\"\n  \n    if hr_breakable > 1 and len(text) > hr_breakable:\n      text = re.sub('(' + ('.' * hr_breakable) + ')', '\\\\1\\x02', text)\n    if hr_breakable:\n      # make every other space \"breakable\"\n      text = text.replace('  ', ' \\x01nbsp;')\n    else:\n      text = text.replace(' ', '\\x01nbsp;')\n    text = sapi.escape(text)\n    text = text.replace('\\x01', '&')\n    text = text.replace('\\x02', '<span style=\"color:red\">\\</span><br />')\n    return text\n    \n  def _get_row(self):\n    if self.state[:5] == 'flush':\n      item = self._flush_row()\n      if item:\n        return item\n      self.state = 'dump'\n\n    if self.save_line:\n      line = self.save_line\n      self.save_line = None\n    else:\n      line = self.fp.readline()\n\n    if not line:\n      if self.state == 'no-changes':\n        self.state = 'done'\n        return _item(type=_RCSDIFF_NO_CHANGES)\n\n      # see if there are lines to flush\n      if self.left_col or self.right_col:\n        # move into the flushing state\n        self.state = 'flush-' + self.state\n        return None\n\n      # nothing more to return\n      raise IndexError\n\n    if line[:2] == '@@':\n      self.state = 'dump'\n      self.left_col = [ ]\n      self.right_col = [ ]\n\n      match = _re_extract_info.match(line)\n      self.line_number = int(match.group(2)) - 1\n      self.prev_line_number = int(match.group(1)) - 1\n      return _item(type='header',\n                   line_info_left=match.group(1),\n                   line_info_right=match.group(2),\n                   line_info_extra=self._format_text(match.group(3)))\n    \n    if line[0] == '\\\\':\n      # \\ No newline at end of file\n      # Just skip. This code used to move to flush state, but that resulted in\n      # changes being displayed as removals-and-readditions.\n      return None\n\n    diff_code = line[0]\n    output = self._format_text(line[1:])\n    \n    if diff_code == '+':\n      if self.state == 'dump':\n        self.line_number = self.line_number + 1\n        return _item(type='add', right=output, line_number=self.line_number)\n\n      self.state = 'pre-change-add'\n      self.right_col.append(output)\n      return None\n\n    if diff_code == '-':\n      self.state = 'pre-change-remove'\n      self.left_col.append(output)\n      return None  # early exit to avoid line in\n\n    if self.left_col or self.right_col:\n      # save the line for processing again later, and move into the\n      # flushing state\n      self.save_line = line\n      self.state = 'flush-' + self.state\n      return None\n\n    self.line_number = self.line_number + 1\n    self.prev_line_number = self.prev_line_number + 1\n    return _item(type='context', left=output, right=output,\n                 line_number=self.line_number)\n\n  def _flush_row(self):\n    if not self.left_col and not self.right_col:\n      # nothing more to flush\n      return None\n\n    if self.state == 'flush-pre-change-remove':\n      self.prev_line_number = self.prev_line_number + 1\n      return _item(type='remove', left=self.left_col.pop(0),\n                   line_number=self.prev_line_number)\n\n    # state == flush-pre-change-add\n    item = _item(type='change',\n                 have_left=ezt.boolean(0),\n                 have_right=ezt.boolean(0))\n    if self.left_col:\n      self.prev_line_number = self.prev_line_number + 1\n      item.have_left = ezt.boolean(1)\n      item.left = self.left_col.pop(0)\n      item.line_number = self.prev_line_number\n    if self.right_col:\n      self.line_number = self.line_number + 1\n      item.have_right = ezt.boolean(1)\n      item.right = self.right_col.pop(0)\n      item.line_number = self.line_number\n    return item\n\nclass DiffSequencingError(Exception):\n  pass\n\ndef diff_parse_headers(fp, diff_type, path1, path2, rev1, rev2,\n                       sym1=None, sym2=None):\n  date1 = date2 = log_rev1 = log_rev2 = flag = None\n  header_lines = []\n\n  if diff_type == vclib.UNIFIED:\n    f1 = '--- '\n    f2 = '+++ '\n  elif diff_type == vclib.CONTEXT:\n    f1 = '*** '\n    f2 = '--- '\n  else:\n    f1 = f2 = None\n\n  # If we're parsing headers, then parse and tweak the diff headers,\n  # collecting them in an array until we've read and handled them all.\n  if f1 and f2:\n    parsing = 1\n    flag = _RCSDIFF_NO_CHANGES\n    len_f1 = len(f1)\n    len_f2 = len(f2)\n    while parsing:\n      line = fp.readline()\n      if not line:\n        break\n\n      # Saw at least one line in the stream\n      flag = None\n\n      if line[:len(f1)] == f1:\n        match = _re_extract_rev.match(line)\n        if match:\n          date1 = match.group(1)\n          log_rev1 = match.group(2)\n          line = '%s%s\\t%s\\t%s%s\\n' % (f1, path1, date1, log_rev1,\n                                       sym1 and ' ' + sym1 or '')\n      elif line[:len(f2)] == f2:\n        match = _re_extract_rev.match(line)\n        if match:\n          date2 = match.group(1)\n          log_rev2 = match.group(2)\n          line = '%s%s\\t%s\\t%s%s\\n' % (f2, path2, date2, log_rev2,\n                                       sym2 and ' ' + sym2 or '')\n        parsing = 0\n      elif line[:3] == 'Bin':\n        flag = _RCSDIFF_IS_BINARY\n        parsing = 0\n      elif (line.find('not found') != -1 or \n            line.find('illegal option') != -1):\n        flag = _RCSDIFF_ERROR\n        parsing = 0\n      header_lines.append(line)\n\n  if (log_rev1 and log_rev1 != rev1):\n    raise debug.ViewVCException('rcsdiff found revision %s, but expected '\n                                 'revision %s' % (log_rev1, rev1),\n                                 '500 Internal Server Error')\n  if (log_rev2 and log_rev2 != rev2):\n    raise debug.ViewVCException('rcsdiff found revision %s, but expected '\n                                 'revision %s' % (log_rev2, rev2),\n                                 '500 Internal Server Error')\n\n  return date1, date2, flag, ''.join(header_lines)\n\n\ndef _get_diff_path_parts(request, query_key, rev, base_rev):\n  repos = request.repos\n  if request.query_dict.has_key(query_key):\n    parts = _path_parts(request.query_dict[query_key])\n  elif request.roottype == 'svn':\n    try:\n      parts = _path_parts(repos.get_location(request.where,\n                                             repos._getrev(base_rev),\n                                             repos._getrev(rev)))\n    except vclib.InvalidRevision:\n      raise debug.ViewVCException('Invalid path(s) or revision(s) passed '\n                                   'to diff', '400 Bad Request')\n    except vclib.ItemNotFound:\n      raise debug.ViewVCException('Invalid path(s) or revision(s) passed '\n                                   'to diff', '400 Bad Request')\n  else:\n    parts = request.path_parts\n  return parts\n\n\ndef setup_diff(request):\n  query_dict = request.query_dict\n\n  rev1 = r1 = query_dict['r1']\n  rev2 = r2 = query_dict['r2']\n  sym1 = sym2 = None\n\n  # hack on the diff revisions\n  if r1 == 'text':\n    rev1 = query_dict.get('tr1', None)\n    if not rev1:\n      raise debug.ViewVCException('Missing revision from the diff '\n                                   'form text field', '400 Bad Request')\n  else:\n    idx = r1.find(':')\n    if idx == -1:\n      rev1 = r1\n    else:\n      rev1 = r1[:idx]\n      sym1 = r1[idx+1:]\n      \n  if r2 == 'text':\n    rev2 = query_dict.get('tr2', None)\n    if not rev2:\n      raise debug.ViewVCException('Missing revision from the diff '\n                                   'form text field', '400 Bad Request')\n    sym2 = ''\n  else:\n    idx = r2.find(':')\n    if idx == -1:\n      rev2 = r2\n    else:\n      rev2 = r2[:idx]\n      sym2 = r2[idx+1:]\n\n  if request.roottype == 'svn':\n    try:\n      rev1 = str(request.repos._getrev(rev1))\n      rev2 = str(request.repos._getrev(rev2))\n    except vclib.InvalidRevision:\n      raise debug.ViewVCException('Invalid revision(s) passed to diff',\n                                  '400 Bad Request')\n    \n  p1 = _get_diff_path_parts(request, 'p1', rev1, request.pathrev)\n  p2 = _get_diff_path_parts(request, 'p2', rev2, request.pathrev)\n\n  try:\n    if revcmp(rev1, rev2) > 0:\n      rev1, rev2 = rev2, rev1\n      sym1, sym2 = sym2, sym1\n      p1, p2 = p2, p1\n  except ValueError:\n    raise debug.ViewVCException('Invalid revision(s) passed to diff',\n                                 '400 Bad Request')\n  return p1, p2, rev1, rev2, sym1, sym2\n\n\ndef view_patch(request):\n  if 'diff' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Diff generation is disabled',\n                                 '403 Forbidden')\n\n  cfg = request.cfg\n  query_dict = request.query_dict\n  p1, p2, rev1, rev2, sym1, sym2 = setup_diff(request)\n\n  mime_type1, encoding1 = calculate_mime_type(request, p1, rev1)\n  mime_type2, encoding2 = calculate_mime_type(request, p2, rev2)\n  if is_binary_file_mime_type(mime_type1, cfg) or \\\n     is_binary_file_mime_type(mime_type2, cfg):\n    raise debug.ViewVCException('Display of binary file content disabled '\n                                'by configuration', '403 Forbidden')\n\n  # In the absence of a format dictation in the CGI params, we'll let\n  # use the configured diff format, allowing 'c' to mean 'c' and\n  # anything else to mean 'u'.\n  format = query_dict.get('diff_format',\n                          cfg.options.diff_format == 'c' and 'c' or 'u')\n  if format == 'c':\n    diff_type = vclib.CONTEXT\n  elif format == 'u':\n    diff_type = vclib.UNIFIED\n  else:\n    raise debug.ViewVCException('Diff format %s not understood'\n                                 % format, '400 Bad Request')\n\n  # Set some diff options.  (Are there other options folks might want?\n  # Maybe not.  For a patch, perhaps the precise change is ideal.)\n  diff_options = {}\n  diff_options['funout'] = cfg.options.hr_funout\n  \n  try:\n    fp = request.repos.rawdiff(p1, rev1, p2, rev2, diff_type, diff_options)\n  except vclib.InvalidRevision:\n    raise debug.ViewVCException('Invalid path(s) or revision(s) passed '\n                                 'to diff', '400 Bad Request')\n\n  path_left = _path_join(p1)\n  path_right = _path_join(p2)\n  date1, date2, flag, headers = diff_parse_headers(fp, diff_type,\n                                                   path_left, path_right,\n                                                   rev1, rev2, sym1, sym2)\n\n  server_fp = get_writeready_server_file(request, 'text/plain')\n  server_fp.write(headers)\n  copy_stream(fp, server_fp)\n  fp.close()\n\n\ndef diff_side_item(request, path_comp, rev, sym):\n  '''Prepare information about left/right side of the diff. Prepare two flavors,\n  for content and for property diffs.'''\n\n  # TODO: Is the slice necessary, or is limit enough?\n  options = {'svn_show_all_dir_logs': 1}\n  log_entry = request.repos.itemlog(path_comp, rev, vclib.SORTBY_REV,\n                                    0, 1, options)[-1]\n  ago = log_entry.date is not None \\\n         and html_time(request, log_entry.date, 1) or None\n  path_joined = _path_join(path_comp)\n\n  lf = LogFormatter(request, log_entry.log)\n  \n  # Item for property diff: no hrefs, there's no view\n  # to download/annotate property\n  i_prop = _item(log_entry=log_entry,\n                 date=make_time_string(log_entry.date, request.cfg),\n                 author=log_entry.author,\n                 log = lf.get(maxlen=0, htmlize=1),\n                 size=log_entry.size,\n                 ago=ago,\n                 path=path_joined,\n                 path_comp=path_comp,\n                 rev=rev,\n                 tag=sym,\n                 view_href=None,\n                 download_href=None,\n                 download_text_href=None,\n                 annotate_href=None,\n                 revision_href=None,\n                 prefer_markup=ezt.boolean(0))\n\n  # Content diff item is based on property diff, with URIs added\n  fvi = get_file_view_info(request, path_joined, rev)\n  i_content = copy.copy(i_prop)\n  i_content.view_href = fvi.view_href\n  i_content.download_href = fvi.download_href\n  i_content.download_text_href = fvi.download_text_href\n  i_content.annotate_href = fvi.annotate_href\n  i_content.revision_href = fvi.revision_href\n  i_content.prefer_markup = fvi.prefer_markup\n\n  # Property diff item has properties hash, naturally. Content item doesn't.\n  i_content.properties = None\n  i_prop.properties = request.repos.itemprops(path_comp, rev)\n  return i_content, i_prop\n\n\nclass DiffDescription:\n  def __init__(self, request):\n    cfg = request.cfg\n    query_dict = request.query_dict\n\n    self.diff_format = query_dict.get('diff_format', cfg.options.diff_format)\n    self.human_readable = 0\n    self.hide_legend = 0\n    self.line_differ = None\n    self.fp_differ = None\n    self.request = request\n    self.context = -1\n    self.changes = []\n\n    if self.diff_format == 'c':\n      self.diff_type = vclib.CONTEXT\n      self.hide_legend = 1\n    elif self.diff_format == 's':\n      self.diff_type = vclib.SIDE_BY_SIDE\n      self.hide_legend = 1\n    elif self.diff_format == 'l':\n      self.diff_type = vclib.UNIFIED\n      self.context = 15\n      self.human_readable = 1\n    elif self.diff_format == 'f':\n      self.diff_type = vclib.UNIFIED\n      self.context = None\n      self.human_readable = 1\n    elif self.diff_format == 'h':\n      self.diff_type = vclib.UNIFIED\n      self.human_readable = 1\n    elif self.diff_format == 'u':\n      self.diff_type = vclib.UNIFIED\n      self.hide_legend = 1\n    else:\n      raise debug.ViewVCException('Diff format %s not understood'\n                                   % self.diff_format, '400 Bad Request')\n\n    # Determine whether idiff is avaialble and whether it could be used.\n    # idiff only supports side-by-side (conditionally) and unified formats,\n    # and is only used if intra-line diffs are requested.\n    if (cfg.options.hr_intraline and idiff\n        and ((self.human_readable and idiff.sidebyside)\n             or (not self.human_readable and self.diff_type == vclib.UNIFIED))):\n      # Override hiding legend for unified format. It is not marked 'human\n      # readable', and it is displayed differently depending on whether\n      # hr_intraline is disabled (displayed as raw diff) or enabled\n      # (displayed as colored). What a royal mess... Issue #301 should\n      # at some time address it; at that time, human_readable and hide_legend\n      # controls should both be merged into one, 'is_colored' or something.\n      self.hide_legend = 0\n      if self.human_readable:\n        self.line_differ = self._line_idiff_sidebyside\n        self.diff_block_format = 'sidebyside-2'\n      else:\n        self.line_differ = self._line_idiff_unified\n        self.diff_block_format = 'unified'\n    else:\n      if self.human_readable:\n        self.diff_block_format = 'sidebyside-1'\n        self.fp_differ = self._fp_vclib_hr\n      else:\n        self.diff_block_format = 'raw'\n        self.fp_differ = self._fp_vclib_raw\n\n  def anchor(self, anchor_name):\n    self.changes.append(_item(diff_block_format='anchor', anchor=anchor_name))\n\n  def get_content_diff(self, left, right):\n    cfg = self.request.cfg\n    diff_options = {}\n    if self.context != -1:\n      diff_options['context'] = self.context\n    if self.human_readable or self.diff_format == 'u':\n      diff_options['funout'] = cfg.options.hr_funout      \n    if self.human_readable:\n      diff_options['ignore_white'] = cfg.options.hr_ignore_white\n      diff_options['ignore_keyword_subst'] = \\\n                      cfg.options.hr_ignore_keyword_subst\n    self._get_diff(left, right, self._content_lines, self._content_fp,\n                   diff_options, None)\n\n  def get_prop_diff(self, left, right):\n    diff_options = {}\n    if self.context != -1:\n      diff_options['context'] = self.context\n    if self.human_readable:\n      cfg = self.request.cfg\n      diff_options['ignore_white'] = cfg.options.hr_ignore_white\n    for name in self._uniq(left.properties.keys() + right.properties.keys()):\n      # Skip non-utf8 property names\n      if is_undisplayable(name):\n        continue\n      val_left = left.properties.get(name, '')\n      val_right = right.properties.get(name, '')\n      # Skip non-changed properties\n      if val_left == val_right:\n        continue\n      # Check for binary properties\n      if is_undisplayable(val_left) or is_undisplayable(val_right):\n        self.changes.append(_item(left=left,\n                                  right=right,\n                                  diff_block_format=self.diff_block_format,\n                                  changes=[ _item(type=_RCSDIFF_IS_BINARY) ],\n                                  propname=name))\n        continue\n      self._get_diff(left, right, self._prop_lines, self._prop_fp,\n                     diff_options, name)\n\n  def _get_diff(self, left, right, get_lines, get_fp, diff_options, propname):\n    if self.fp_differ is not None:\n      fp = get_fp(left, right, propname, diff_options)\n      changes = self.fp_differ(left, right, fp, propname)\n    else:\n      lines_left = get_lines(left, propname)\n      lines_right = get_lines(right, propname)\n      changes = self.line_differ(lines_left, lines_right, diff_options)\n    self.changes.append(_item(left=left,\n                              right=right,\n                              changes=changes,\n                              diff_block_format=self.diff_block_format,\n                              propname=propname))\n\n  def _line_idiff_sidebyside(self, lines_left, lines_right, diff_options):\n    return idiff.sidebyside(lines_left, lines_right,\n                            diff_options.get(\"context\", 5))\n\n  def _line_idiff_unified(self, lines_left, lines_right, diff_options):\n    return idiff.unified(lines_left, lines_right,\n                         diff_options.get(\"context\", 2))\n\n  def _fp_vclib_hr(self, left, right, fp, propname):\n    date1, date2, flag, headers = \\\n                    diff_parse_headers(fp, self.diff_type,\n                                       self._property_path(left, propname),\n                                       self._property_path(right, propname),\n                                       left.rev, right.rev, left.tag, right.tag)\n    if flag is not None:\n      return [ _item(type=flag) ]\n    else:\n      return DiffSource(fp, self.request.cfg)\n\n  def _fp_vclib_raw(self, left, right, fp, propname):\n    date1, date2, flag, headers = \\\n                    diff_parse_headers(fp, self.diff_type,\n                                       self._property_path(left, propname),\n                                       self._property_path(right, propname),\n                                       left.rev, right.rev, left.tag, right.tag)\n    if flag is not None:\n      return _item(type=flag)\n    else:\n      return _item(type='raw', raw=MarkupPipeWrapper(fp,\n              self.request.server.escape(headers), None, 1))\n\n  def _content_lines(self, side, propname):\n    f = self.request.repos.openfile(side.path_comp, side.rev, {})[0]\n    try:\n      lines = f.readlines()\n    finally:\n      f.close()\n    return lines\n\n  def _content_fp(self, left, right, propname, diff_options):\n    return self.request.repos.rawdiff(left.path_comp, left.rev,\n                                      right.path_comp, right.rev,\n                                      self.diff_type, diff_options)\n\n  def _prop_lines(self, side, propname):\n    val = side.properties.get(propname, '')\n    return val.splitlines()\n\n  def _prop_fp(self, left, right, propname, diff_options):\n    fn_left = self._temp_file(left.properties.get(propname))\n    fn_right = self._temp_file(right.properties.get(propname))\n    diff_args = vclib._diff_args(self.diff_type, diff_options)\n    info_left = self._property_path(left, propname), \\\n                left.log_entry.date, left.rev\n    info_right = self._property_path(right, propname), \\\n                 right.log_entry.date, right.rev\n    return vclib._diff_fp(fn_left, fn_right, info_left, info_right,\n                          self.request.cfg.utilities.diff or 'diff', diff_args)\n\n  def _temp_file(self, val):\n    '''Create a temporary file with content from val'''\n    fd, fn = tempfile.mkstemp()\n    fp = os.fdopen(fd, \"wb\")\n    if val:\n      fp.write(val)\n    fp.close()\n    return fn\n\n  def _uniq(self, lst):\n    '''Determine unique set of list elements'''\n    h = {}\n    for e in lst:\n      h[e] = 1\n    return sorted(h.keys())\n\n  def _property_path(self, side, propname):\n    '''Return path to be displayed in raw diff - possibly augmented with\n    property name'''\n    if propname is None:\n      return side.path\n    else:\n      return \"%s:property(%s)\" % (side.path, propname)\n\n\ndef view_diff(request):\n  if 'diff' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Diff generation is disabled',\n                                 '403 Forbidden')\n\n  cfg = request.cfg\n  p1, p2, rev1, rev2, sym1, sym2 = setup_diff(request)\n  \n  mime_type1, encoding1 = calculate_mime_type(request, p1, rev1)\n  mime_type2, encoding2 = calculate_mime_type(request, p2, rev2)\n  if is_binary_file_mime_type(mime_type1, cfg) or \\\n     is_binary_file_mime_type(mime_type2, cfg):\n    raise debug.ViewVCException('Display of binary file content disabled '\n                                'by configuration', '403 Forbidden')\n\n  # since templates are in use and subversion allows changes to the dates,\n  # we can't provide a strong etag\n  if check_freshness(request, None, '%s-%s' % (rev1, rev2), weak=1):\n    return\n\n  left_side_content, left_side_prop = diff_side_item(request, p1, rev1, sym1)\n  right_side_content, right_side_prop = diff_side_item(request, p2, rev2, sym2)\n\n  desc = DiffDescription(request)\n\n  try:\n    if request.pathtype == vclib.FILE:\n      # Get file content diff\n      desc.anchor(\"content\")\n      desc.get_content_diff(left_side_content, right_side_content)\n\n    # Get property list and diff each property\n    desc.anchor(\"properties\")\n    desc.get_prop_diff(left_side_prop, right_side_prop)\n\n  except vclib.InvalidRevision:\n    raise debug.ViewVCException('Invalid path(s) or revision(s) passed '\n        'to diff', '400 Bad Request')\n\n  no_format_params = request.query_dict.copy()\n  no_format_params['diff_format'] = None\n  diff_format_action, diff_format_hidden_values = \\\n    request.get_form(params=no_format_params)\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'diffs' : desc.changes,\n    'diff_format' : desc.diff_format,\n    'hide_legend' : ezt.boolean(desc.hide_legend),\n    'patch_href' : request.get_url(view_func=view_patch,\n                                   params=no_format_params,\n                                   escape=1),\n    'diff_format_action' : diff_format_action,\n    'diff_format_hidden_values' : diff_format_hidden_values,\n    }))\n  generate_page(request, \"diff\", data)\n\n\ndef generate_tarball_header(out, name, size=0, mode=None, mtime=0,\n                            uid=0, gid=0, typeflag=None, linkname='',\n                            uname='viewvc', gname='viewvc',\n                            devmajor=1, devminor=0, prefix=None,\n                            magic='ustar', version='00', chksum=None):\n  if not mode:\n    if name[-1:] == '/':\n      mode = 0755\n    else:\n      mode = 0644\n\n  if not typeflag:\n    if linkname:\n      typeflag = '2' # symbolic link\n    elif name[-1:] == '/':\n      typeflag = '5' # directory\n    else:\n      typeflag = '0' # regular file\n\n  if not prefix:\n    prefix = ''\n\n  # generate a GNU tar extension header for a long name.\n  if len(name) >= 100:\n    generate_tarball_header(out, '././@LongLink', len(name),\n                            0, 0, 0, 0, 'L')\n    out.write(name)\n    out.write('\\0' * (511 - ((len(name) + 511) % 512)))\n\n  # generate a GNU tar extension header for a long symlink name.\n  if len(linkname) >= 100:\n    generate_tarball_header(out, '././@LongLink', len(linkname),\n                            0, 0, 0, 0, 'K')\n    out.write(linkname)\n    out.write('\\0' * (511 - ((len(linkname) + 511) % 512)))\n\n  block1 = struct.pack('100s 8s 8s 8s 12s 12s',\n                       name,\n                       '%07o' % mode,\n                       '%07o' % uid,\n                       '%07o' % gid,\n                       '%011o' % size,\n                       '%011o' % mtime)\n\n  block2 = struct.pack('c 100s 6s 2s 32s 32s 8s 8s 155s',\n                       typeflag,\n                       linkname,\n                       magic,\n                       version,\n                       uname,\n                       gname,\n                       '%07o' % devmajor,\n                       '%07o' % devminor,\n                       prefix)\n\n  if not chksum:\n    dummy_chksum = '        '\n    block = block1 + dummy_chksum + block2\n    chksum = 0\n    for i in range(len(block)):\n      chksum = chksum + ord(block[i])\n\n  block = block1 + struct.pack('8s', '%07o' % chksum) + block2\n  block = block + '\\0' * (512 - len(block))\n\n  out.write(block)\n\ndef generate_tarball(out, request, reldir, stack, dir_mtime=None):\n  # get directory info from repository\n  rep_path = request.path_parts + reldir\n  entries = request.repos.listdir(rep_path, request.pathrev, {})\n  request.repos.dirlogs(rep_path, request.pathrev, entries, {})\n  entries.sort(lambda a, b: cmp(a.name, b.name))\n\n  # figure out corresponding path in tar file. everything gets put underneath\n  # a single top level directory named after the repository directory being\n  # tarred\n  if request.path_parts:\n    tar_dir = request.path_parts[-1] + '/'\n  else:\n    # Don't handle context as a directory in the tar ball.\n    root_path_parts = _path_parts(request.rootname)\n    tar_dir = root_path_parts[-1] + '/'\n  if reldir:\n    tar_dir = tar_dir + _path_join(reldir) + '/'\n\n  cvs = request.roottype == 'cvs'\n  \n  # If our caller doesn't dictate a datestamp to use for the current\n  # directory, its datestamps will be the youngest of the datestamps\n  # of versioned items in that subdirectory.  We'll be ignoring dead\n  # or busted items and, in CVS, subdirs.\n  if dir_mtime is None:\n    dir_mtime = 0\n    for file in entries:\n      if cvs and (file.kind != vclib.FILE or file.rev is None or file.dead):\n        continue\n      if (file.date is not None) and (file.date > dir_mtime):\n        dir_mtime = file.date\n\n  # Push current directory onto the stack.\n  stack.append(tar_dir)\n\n  # If this is Subversion, we generate a header for this directory\n  # regardless of its contents.  For CVS it will only get into the\n  # tarball if it has files underneath it, which we determine later.\n  if not cvs:\n    generate_tarball_header(out, tar_dir, mtime=dir_mtime)\n\n  # Run through the files in this directory, skipping busted and\n  # unauthorized ones.\n  for file in entries:\n    if file.kind != vclib.FILE:\n      continue\n    if cvs and (file.rev is None or file.dead):\n      continue\n\n    # If we get here, we've seen at least one valid file in the\n    # current directory.  For CVS, we need to make sure there are\n    # directory parents to contain it, so we flush the stack.\n    if cvs:\n      for dir in stack:\n        generate_tarball_header(out, dir, mtime=dir_mtime)\n      del stack[:]\n\n    # Calculate the mode for the file.  Sure, we could look directly\n    # at the ,v file in CVS, but that's a layering violation we'd like\n    # to avoid as much as possible.\n    if request.repos.isexecutable(rep_path + [file.name], request.pathrev):\n      mode = 0755\n    else:\n      mode = 0644\n\n    # Is this thing a symlink?\n    #\n    ### FIXME: A better solution would be to have vclib returning\n    ### symlinks with a new vclib.SYMLINK path type.\n    symlink_target = None\n    if hasattr(request.repos, 'get_symlink_target'):\n      symlink_target = request.repos.get_symlink_target(rep_path + [file.name],\n                                                        request.pathrev)\n\n    # If the object is a symlink, generate the appropriate header.\n    # Otherwise, we're dealing with a regular file.\n    if symlink_target:\n      generate_tarball_header(out, tar_dir + file.name, 0, mode,\n                              file.date is not None and file.date or 0,\n                              typeflag='2', linkname=symlink_target)\n    else:\n      filesize = request.repos.filesize(rep_path + [file.name], request.pathrev)\n\n      if filesize == -1:\n        # Bummer.  We have to calculate the filesize manually.\n        fp = request.repos.openfile(rep_path + [file.name], request.pathrev, {})[0]\n        filesize = 0\n        while 1:\n          chunk = retry_read(fp)\n          if not chunk:\n            break\n          filesize = filesize + len(chunk)\n        fp.close()\n\n      # Write the tarball header...\n      generate_tarball_header(out, tar_dir + file.name, filesize, mode,\n                              file.date is not None and file.date or 0)\n      \n      # ...the file's contents ...\n      fp = request.repos.openfile(rep_path + [file.name], request.pathrev, {})[0]\n      while 1:\n        chunk = retry_read(fp)\n        if not chunk:\n          break\n        out.write(chunk)\n      fp.close()\n\n      # ... and then add the block padding.\n      out.write('\\0' * (511 - (filesize + 511) % 512))\n\n  # Recurse into subdirectories, skipping busted and unauthorized (or\n  # configured-to-be-hidden) ones.\n  for file in entries:\n    if file.errors or file.kind != vclib.DIR:\n      continue\n    if request.cfg.options.hide_cvsroot \\\n       and is_cvsroot_path(request.roottype, rep_path + [file.name]):\n      continue\n\n    mtime = request.roottype == 'svn' and file.date or None\n    generate_tarball(out, request, reldir + [file.name], stack, mtime)\n\n  # Pop the current directory from the stack.\n  del stack[-1:]\n\ndef download_tarball(request):\n  cfg = request.cfg\n  \n  if 'tar' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Tarball generation is disabled',\n                                 '403 Forbidden')\n\n  # If debugging, we just need to open up the specified tar path for\n  # writing.  Otherwise, we get a writeable server output stream --\n  # disabling any default compression thereupon -- and wrap that in\n  # our own gzip stream wrapper.\n  if debug.TARFILE_PATH:\n    fp = open(debug.TARFILE_PATH, 'w')\n  else:    \n    tarfile = request.rootname\n    if request.path_parts:\n      tarfile = \"%s-%s\" % (tarfile, request.path_parts[-1])\n    request.server.addheader('Content-Disposition',\n                             'attachment; filename=\"%s.tar.gz\"' % (tarfile))\n    server_fp = get_writeready_server_file(request, 'application/x-gzip',\n                                           allow_compress=False)\n    request.server.flush()\n    fp = gzip.GzipFile('', 'wb', 9, server_fp)\n\n  ### FIXME: For Subversion repositories, we can get the real mtime of the\n  ### top-level directory here.\n  generate_tarball(fp, request, [], [])\n\n  fp.write('\\0' * 1024)\n  fp.close()\n\n  if debug.TARFILE_PATH:\n    request.server.header('')\n    print \"\"\"\n<html>\n<body>\n<p>Tarball '%s' successfully generated!</p>\n</body>\n</html>\"\"\" % (debug.TARFILE_PATH)\n\n\ndef view_revision(request):\n  if request.roottype != \"svn\":\n    raise debug.ViewVCException(\"Revision view not supported for CVS \"\n                                \"repositories at this time.\",\n                                \"400 Bad Request\")\n\n  cfg = request.cfg\n  query_dict = request.query_dict\n  try:\n    rev = request.repos._getrev(query_dict.get('revision'))\n  except vclib.InvalidRevision:\n    raise debug.ViewVCException('Invalid revision', '404 Not Found')\n  youngest_rev = request.repos.get_youngest_revision()\n  \n  # The revision number acts as a weak validator (but we tell browsers\n  # not to cache the youngest revision).\n  if rev != youngest_rev and check_freshness(request, None, str(rev), weak=1):\n    return\n\n  # Fetch the revision information.\n  date, author, msg, revprops, changes = request.repos.revinfo(rev)\n  date_str = make_time_string(date, cfg)\n\n  # Fix up the revprops list (rather like get_itemprops()).\n  propnames = revprops.keys()\n  propnames.sort()\n  props = []\n  for name in propnames:\n    # skip non-utf8 property names\n    if is_undisplayable(name):\n      continue\n    lf = LogFormatter(request, revprops[name])\n    value = lf.get(maxlen=0, htmlize=1)\n    # note non-utf8 property values\n    undisplayable = is_undisplayable(value)\n    if undisplayable:\n      value = None\n    props.append(_item(name=name, value=value,\n                       undisplayable=ezt.boolean(undisplayable)))\n  \n  # Sort the changes list by path.\n  def changes_sort_by_path(a, b):\n    return cmp(a.path_parts, b.path_parts)\n  changes.sort(changes_sort_by_path)\n\n  # Handle limit_changes parameter\n  cfg_limit_changes = cfg.options.limit_changes\n  limit_changes = int(query_dict.get('limit_changes', cfg_limit_changes))\n  more_changes = None\n  more_changes_href = None\n  first_changes = None\n  first_changes_href = None\n  num_changes = len(changes)\n  if limit_changes and len(changes) > limit_changes:\n    more_changes = len(changes) - limit_changes\n    params = query_dict.copy()\n    params['limit_changes'] = 0\n    more_changes_href = request.get_url(params=params, escape=1)\n    changes = changes[:limit_changes]\n  elif cfg_limit_changes and len(changes) > cfg_limit_changes:\n    first_changes = cfg_limit_changes\n    params = query_dict.copy()\n    params['limit_changes'] = None\n    first_changes_href = request.get_url(params=params, escape=1)\n\n  # Add the hrefs, types, and prev info\n  for change in changes:\n    change.view_href = change.diff_href = change.type = change.log_href = None\n\n    # If the path is newly added, don't claim text or property\n    # modifications.\n    if (change.action == vclib.ADDED or change.action == vclib.REPLACED) \\\n       and not change.copied:\n      change.text_changed = 0\n      change.props_changed = 0\n\n    # Calculate the view link URLs (for which we must have a pathtype).\n    if change.pathtype:\n      view_func = None\n      if change.pathtype is vclib.FILE \\\n         and 'markup' in cfg.options.allowed_views:\n        view_func = view_markup\n      elif change.pathtype is vclib.DIR:\n        view_func = view_directory\n\n      path = _path_join(change.path_parts)\n      base_path = _path_join(change.base_path_parts)\n      if change.action == vclib.DELETED:\n        link_rev = str(change.base_rev)\n        link_where = base_path\n      else:\n        link_rev = str(rev)\n        link_where = path\n\n      change.view_href = request.get_url(view_func=view_func,\n                                         where=link_where,\n                                         pathtype=change.pathtype,\n                                         params={'pathrev' : link_rev},\n                                         escape=1)\n      change.log_href = request.get_url(view_func=view_log,\n                                        where=link_where,\n                                        pathtype=change.pathtype,\n                                        params={'pathrev' : link_rev},\n                                        escape=1)\n\n      if (change.pathtype is vclib.FILE and change.text_changed) \\\n          or change.props_changed:\n        change.diff_href = request.get_url(view_func=view_diff,\n                                           where=path, \n                                           pathtype=change.pathtype,\n                                           params={'pathrev' : str(rev),\n                                                   'r1' : str(rev),\n                                                   'r2' : str(change.base_rev),\n                                                   },\n                                           escape=1)\n    \n\n    # use same variable names as the log template\n    change.path = _path_join(change.path_parts)\n    change.copy_path = _path_join(change.base_path_parts)\n    change.copy_rev = change.base_rev\n    change.text_mods = ezt.boolean(change.text_changed)\n    change.prop_mods = ezt.boolean(change.props_changed)\n    change.is_copy = ezt.boolean(change.copied)\n    change.pathtype = (change.pathtype == vclib.FILE and 'file') \\\n                      or (change.pathtype == vclib.DIR and 'dir') \\\n                      or None\n    del change.path_parts\n    del change.base_path_parts\n    del change.base_rev\n    del change.text_changed\n    del change.props_changed\n    del change.copied\n\n  prev_rev_href = next_rev_href = None\n  if rev > 0:\n    prev_rev_href = request.get_url(view_func=view_revision,\n                                    where=None,\n                                    pathtype=None,\n                                    params={'revision': str(rev - 1)},\n                                    escape=1)\n  if rev < request.repos.get_youngest_revision():\n    next_rev_href = request.get_url(view_func=view_revision,\n                                    where=None,\n                                    pathtype=None,\n                                    params={'revision': str(rev + 1)},\n                                    escape=1)\n  jump_rev_action, jump_rev_hidden_values = \\\n    request.get_form(params={'revision': None})\n\n  lf = LogFormatter(request, msg)\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'rev' : str(rev),\n    'author' : author,\n    'date' : date_str,\n    'log' : lf.get(maxlen=0, htmlize=1),\n    'properties' : props,\n    'ago' : date is not None and html_time(request, date, 1) or None,\n    'changes' : changes,\n    'prev_href' : prev_rev_href,\n    'next_href' : next_rev_href,\n    'num_changes' : num_changes,\n    'limit_changes': limit_changes,\n    'more_changes': more_changes,\n    'more_changes_href': more_changes_href,\n    'first_changes': first_changes,\n    'first_changes_href': first_changes_href,\n    'jump_rev_action' : jump_rev_action,\n    'jump_rev_hidden_values' : jump_rev_hidden_values,\n    'revision_href' : request.get_url(view_func=view_revision,\n                                      where=None,\n                                      pathtype=None,\n                                      params={'revision': str(rev)},\n                                      escape=1),\n  }))\n  if rev == youngest_rev:\n    request.server.addheader(\"Cache-control\", \"no-store\")\n  generate_page(request, \"revision\", data)\n\ndef is_query_supported(request):\n  \"\"\"Returns true if querying is supported for the given path.\"\"\"\n  return request.cfg.cvsdb.enabled \\\n         and request.pathtype == vclib.DIR \\\n         and request.roottype in ['cvs', 'svn']\n\ndef is_querydb_nonempty_for_root(request):\n  \"\"\"Return 1 iff commits database integration is supported *and* the\n  current root is found in that database.  Only does this check if\n  check_database is set to 1.\"\"\"\n  if request.cfg.cvsdb.enabled and request.roottype in ['cvs', 'svn']:\n    if request.cfg.cvsdb.check_database_for_root:\n      global cvsdb\n      import cvsdb\n      db = cvsdb.ConnectDatabaseReadOnly(request.cfg)\n      repos_root, repos_dir = cvsdb.FindRepository(db, request.rootpath)\n      if repos_root:\n        return 1\n    else:\n      return 1\n  return 0\n\ndef validate_query_args(request):\n  # Do some additional input validation of query form arguments beyond\n  # what is offered by the CGI param validation loop in Request.run_viewvc().\n  \n  for arg_base in ['branch', 'file', 'comment', 'who']:\n    # First, make sure the the XXX_match args have valid values:\n    arg_match = arg_base + '_match'\n    arg_match_value = request.query_dict.get(arg_match, 'exact')\n    if not arg_match_value in ('exact', 'like', 'glob', 'regex', 'notregex'):\n      raise debug.ViewVCException(\n        'An illegal value was provided for the \"%s\" parameter.'\n        % (arg_match),\n        '400 Bad Request')\n\n    # Now, for those args which are supposed to be regular expressions (per\n    # their corresponding XXX_match values), make sure they are.\n    if arg_match_value == 'regex' or arg_match_value == 'notregex':\n      arg_base_value = request.query_dict.get(arg_base)\n      if arg_base_value:\n        try:\n          re.compile(arg_base_value)\n        except:\n          raise debug.ViewVCException(\n            'An illegal value was provided for the \"%s\" parameter.'\n            % (arg_base),\n            '400 Bad Request')\n  \ndef view_queryform(request):\n  if not is_query_supported(request):\n    raise debug.ViewVCException('Can not query project root \"%s\" at \"%s\".'\n                                 % (request.rootname, request.where),\n                                 '403 Forbidden')\n\n  # Do some more precise input validation.\n  validate_query_args(request)\n  \n  query_action, query_hidden_values = \\\n    request.get_form(view_func=view_query, params={'limit_changes': None})\n  limit_changes = \\\n    int(request.query_dict.get('limit_changes',\n                               request.cfg.options.limit_changes))\n\n  def escaped_query_dict_get(itemname, itemdefault=''):\n    return request.server.escape(request.query_dict.get(itemname, itemdefault))\n    \n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'branch' : escaped_query_dict_get('branch', ''),\n    'branch_match' : escaped_query_dict_get('branch_match', 'exact'),\n    'dir' : escaped_query_dict_get('dir', ''),\n    'file' : escaped_query_dict_get('file', ''),\n    'file_match' : escaped_query_dict_get('file_match', 'exact'),\n    'who' : escaped_query_dict_get('who', ''),\n    'who_match' : escaped_query_dict_get('who_match', 'exact'),\n    'comment' : escaped_query_dict_get('comment', ''),\n    'comment_match' : escaped_query_dict_get('comment_match', 'exact'),\n    'querysort' : escaped_query_dict_get('querysort', 'date'),\n    'date' : escaped_query_dict_get('date', 'hours'),\n    'hours' : escaped_query_dict_get('hours', '2'),\n    'mindate' : escaped_query_dict_get('mindate', ''),\n    'maxdate' : escaped_query_dict_get('maxdate', ''),\n    'query_action' : query_action,\n    'query_hidden_values' : query_hidden_values,\n    'limit_changes' : limit_changes,\n    'dir_href' : request.get_url(view_func=view_directory, params={},\n                                 escape=1),\n    }))\n  generate_page(request, \"query_form\", data)\n\ndef parse_date(datestr):\n  \"\"\"Parse a date string from the query form.\"\"\"\n  \n  match = re.match(r'^(\\d\\d\\d\\d)-(\\d\\d)-(\\d\\d)(?:\\ +'\n                   '(\\d\\d):(\\d\\d)(?::(\\d\\d))?)?$', datestr)\n  if match:\n    year = int(match.group(1))\n    month = int(match.group(2))\n    day = int(match.group(3))\n    hour = match.group(4)\n    if hour is not None:\n      hour = int(hour)\n    else:\n      hour = 0\n    minute = match.group(5)\n    if minute is not None:\n      minute = int(minute)\n    else:\n      minute = 0\n    second = match.group(6)\n    if second is not None:\n      second = int(second)\n    else:\n      second = 0\n    # return a \"seconds since epoch\" value assuming date given in UTC\n    tm = (year, month, day, hour, minute, second, 0, 0, 0)\n    return calendar.timegm(tm)\n  else:\n    return None\n\ndef english_query(request):\n  \"\"\"Generate a sentance describing the query.\"\"\"\n  cfg = request.cfg\n  ret = [ 'Checkins ' ]\n  dir = request.query_dict.get('dir', '')\n  if dir:\n    ret.append('to ')\n    if ',' in dir:\n      ret.append('subdirectories')\n    else:\n      ret.append('subdirectory')\n    ret.append(' <em>%s</em> ' % request.server.escape(dir))\n  file = request.query_dict.get('file', '')\n  if file:\n    if len(ret) != 1:\n      ret.append('and ')\n    ret.append('to file <em>%s</em> ' % request.server.escape(file))\n  who = request.query_dict.get('who', '')\n  branch = request.query_dict.get('branch', '')\n  if branch:\n    ret.append('on branch <em>%s</em> ' % request.server.escape(branch))\n  else:\n    ret.append('on all branches ')\n  comment = request.query_dict.get('comment', '')\n  if comment:\n    ret.append('with comment <i>%s</i> ' % request.server.escape(comment))\n  if who:\n    ret.append('by <em>%s</em> ' % request.server.escape(who))\n  date = request.query_dict.get('date', 'hours')\n  if date == 'hours':\n    ret.append('in the last %s hours' \\\n               % request.server.escape(request.query_dict.get('hours', '2')))\n  elif date == 'day':\n    ret.append('in the last day')\n  elif date == 'week':\n    ret.append('in the last week')\n  elif date == 'month':\n    ret.append('in the last month')\n  elif date == 'all':\n    ret.append('since the beginning of time')\n  elif date == 'explicit':\n    mindate = request.query_dict.get('mindate', '')\n    maxdate = request.query_dict.get('maxdate', '')\n    if mindate and maxdate:\n      w1, w2 = 'between', 'and'\n    else:\n      w1, w2 = 'since', 'before'\n    if mindate:\n      mindate = make_time_string(parse_date(mindate), cfg)\n      ret.append('%s <em>%s</em> ' % (w1, mindate))\n    if maxdate:\n      maxdate = make_time_string(parse_date(maxdate), cfg)\n      ret.append('%s <em>%s</em> ' % (w2, maxdate))\n  return ''.join(ret)\n\ndef prev_rev(rev):\n  \"\"\"Returns a string representing the previous revision of the argument.\"\"\"\n  r = rev.split('.')\n  # decrement final revision component\n  r[-1] = str(int(r[-1]) - 1)\n  # prune if we pass the beginning of the branch\n  if len(r) > 2 and r[-1] == '0':\n    r = r[:-2]\n  return '.'.join(r)\n\ndef build_commit(request, files, max_files, dir_strip, format):\n  \"\"\"Return a commit object build from the information in FILES, or\n  None if no allowed files are present in the set.  DIR_STRIP is the\n  path prefix to remove from the commit object's set of files.  If\n  MAX_FILES is non-zero, it is used to limit the number of files\n  returned in the commit object.  FORMAT is the requested output\n  format of the query request.\"\"\"\n\n  cfg = request.cfg\n  author = files[0].GetAuthor()\n  date = files[0].GetTime()\n  desc = files[0].GetDescription()\n  commit_rev = files[0].GetRevision()\n  len_strip = len(dir_strip)\n  commit_files = []\n  num_allowed = 0\n  plus_count = 0\n  minus_count = 0\n  found_unreadable = 0\n  \n  for f in files:\n    dirname = f.GetDirectory()\n    filename = f.GetFile()\n    if dir_strip:\n      assert dirname[:len_strip] == dir_strip\n      assert len(dirname) == len_strip or dirname[len(dir_strip)] == '/'\n      dirname = dirname[len_strip+1:]\n    where = dirname and (\"%s/%s\" % (dirname, filename)) or filename\n    rev = f.GetRevision()\n    rev_prev = prev_rev(rev)\n    commit_time = f.GetTime()\n    if commit_time:\n      commit_time = make_time_string(commit_time, cfg)\n    change_type = f.GetTypeString()\n\n    # In CVS, we can actually look at deleted revisions; in Subversion\n    # we can't -- we'll look at the previous revision instead.\n    exam_rev = rev\n    if request.roottype == 'svn' and change_type == 'Remove':\n      exam_rev = rev_prev\n\n    # Check path access (since the commits database logic bypasses the\n    # vclib layer and, thus, the vcauth stuff that layer uses).\n    path_parts = _path_parts(where)\n    if path_parts:\n      # Skip files in CVSROOT if asked to hide such.\n      if cfg.options.hide_cvsroot \\\n         and is_cvsroot_path(request.roottype, path_parts):\n        found_unreadable = 1\n        continue\n      \n      # We have to do a rare authz check here because this data comes\n      # from the CVSdb, not from the vclib providers.\n      #\n      # WARNING: The Subversion CVSdb integration logic is weak, weak,\n      # weak.  It has no ability to track copies, so complex\n      # situations like a copied directory with a deleted subfile (all\n      # in the same revision) are very ... difficult.  We've no choice\n      # but to omit as unauthorized paths the authorization logic\n      # can't find.\n      try:\n        readable = vclib.check_path_access(request.repos, path_parts,\n                                           None, exam_rev)\n      except vclib.ItemNotFound:\n        readable = 0\n      if not readable:\n        found_unreadable = 1\n        continue\n         \n    if request.roottype == 'svn':\n      params = { 'pathrev': exam_rev }\n    else:\n      params = { 'revision': exam_rev, 'pathrev': f.GetBranch() or None }  \n    \n    dir_href = request.get_url(view_func=view_directory,\n                               where=dirname, pathtype=vclib.DIR,\n                               params=params, escape=1)\n    log_href = request.get_url(view_func=view_log,\n                               where=where, pathtype=vclib.FILE,\n                               params=params, escape=1)\n    diff_href = view_href = download_href = None\n    if 'markup' in cfg.options.allowed_views:\n      view_href = request.get_url(view_func=view_markup,\n                                  where=where, pathtype=vclib.FILE,\n                                  params=params, escape=1)\n    if 'co' in cfg.options.allowed_views:\n      download_href = request.get_url(view_func=view_checkout,\n                                      where=where, pathtype=vclib.FILE,\n                                      params=params, escape=1)\n    if change_type == 'Change':\n      diff_href_params = params.copy()\n      diff_href_params.update({\n        'r1': rev_prev,\n        'r2': rev,\n        'diff_format': None\n        })\n      diff_href = request.get_url(view_func=view_diff,\n                                  where=where, pathtype=vclib.FILE,\n                                  params=diff_href_params, escape=1)\n    mime_type, encoding = calculate_mime_type(request, path_parts, exam_rev)\n    prefer_markup = ezt.boolean(default_view(mime_type, cfg) == view_markup)\n\n    # Update plus/minus line change count.\n    plus = int(f.GetPlusCount())\n    minus = int(f.GetMinusCount())\n    plus_count = plus_count + plus\n    minus_count = minus_count + minus\n    \n    num_allowed = num_allowed + 1\n    if max_files and num_allowed > max_files:\n      continue\n\n    commit_files.append(_item(date=commit_time,\n                              dir=request.server.escape(dirname),\n                              file=request.server.escape(filename),\n                              author=request.server.escape(f.GetAuthor()),\n                              rev=rev,\n                              branch=f.GetBranch(),\n                              plus=plus,\n                              minus=minus,\n                              type=change_type,\n                              dir_href=dir_href,\n                              log_href=log_href,\n                              view_href=view_href,\n                              download_href=download_href,\n                              prefer_markup=prefer_markup,\n                              diff_href=diff_href))\n\n  # No files survived authz checks?  Let's just pretend this\n  # little commit didn't happen, shall we?\n  if not len(commit_files):\n    return None\n\n  commit = _item(num_files=len(commit_files), files=commit_files,\n                 plus=plus_count, minus=minus_count)\n  commit.limited_files = ezt.boolean(num_allowed > len(commit_files))\n\n  # We'll mask log messages in commits which contain unreadable paths,\n  # but even that is kinda iffy.  If a person searches for\n  # '/some/hidden/path' across log messages, then gets a response set\n  # that shows commits lacking log message, said person can reasonably\n  # assume that the log messages contained the hidden path, and that\n  # this is likely because they are referencing a real path in the\n  # repository -- a path the user isn't supposed to even know about.\n  if found_unreadable:\n    commit.log = None\n    commit.short_log = None\n  else:\n    lf = LogFormatter(request, desc)\n    htmlize = (format != 'rss')\n    commit.log = lf.get(maxlen=0, htmlize=htmlize)\n    commit.short_log = lf.get(maxlen=cfg.options.short_log_len, htmlize=htmlize)\n  commit.author = request.server.escape(author)\n  commit.rss_date = make_rss_time_string(date, request.cfg)\n  if request.roottype == 'svn':\n    commit.rev = commit_rev\n    commit.rss_url = '%s://%s%s' % \\\n      (request.server.getenv(\"HTTPS\") == \"on\" and \"https\" or \"http\",\n       request.server.getenv(\"HTTP_HOST\"),\n       request.get_url(view_func=view_revision,\n                       params={'revision': commit.rev},\n                       escape=1))\n  else:\n    commit.rev = None\n    commit.rss_url = None\n  return commit\n\ndef query_backout(request, commits):\n  server_fp = get_writeready_server_file(request, 'text/plain')\n  if not commits:\n    server_fp.write(\"\"\"\\\n# No changes were selected by the query.\n# There is nothing to back out.\n\"\"\")\n    return\n  server_fp.write(\"\"\"\\\n# This page can be saved as a shell script and executed.\n# It should be run at the top of your work area.  It will update\n# your working copy to back out the changes selected by the\n# query.\n\"\"\")\n  for commit in commits:\n    for fileinfo in commit.files:\n      if request.roottype == 'cvs':\n        server_fp.write('cvs update -j %s -j %s %s/%s\\n'\n                        % (fileinfo.rev, prev_rev(fileinfo.rev),\n                           fileinfo.dir, fileinfo.file))\n      elif request.roottype == 'svn':\n        server_fp.write('svn merge -r %s:%s %s/%s\\n'\n                        % (fileinfo.rev, prev_rev(fileinfo.rev),\n                           fileinfo.dir, fileinfo.file))\n\ndef view_query(request):\n  if not is_query_supported(request):\n    raise debug.ViewVCException('Can not query project root \"%s\" at \"%s\".'\n                                 % (request.rootname, request.where),\n                                 '403 Forbidden')\n\n  cfg = request.cfg\n\n  # Do some more precise input validation.\n  validate_query_args(request)\n\n  # get form data\n  branch = request.query_dict.get('branch', '')\n  branch_match = request.query_dict.get('branch_match', 'exact')\n  dir = request.query_dict.get('dir', '')\n  file = request.query_dict.get('file', '')\n  file_match = request.query_dict.get('file_match', 'exact')\n  who = request.query_dict.get('who', '')\n  who_match = request.query_dict.get('who_match', 'exact')\n  comment = request.query_dict.get('comment', '')\n  comment_match = request.query_dict.get('comment_match', 'exact')\n  querysort = request.query_dict.get('querysort', 'date')\n  date = request.query_dict.get('date', 'hours')\n  hours = request.query_dict.get('hours', '2')\n  mindate = request.query_dict.get('mindate', '')\n  maxdate = request.query_dict.get('maxdate', '')\n  format = request.query_dict.get('format')\n  limit_changes = int(request.query_dict.get('limit_changes',\n                                             cfg.options.limit_changes))\n\n  match_types = { 'exact':1, 'like':1, 'glob':1, 'regex':1, 'notregex':1 }\n  sort_types = { 'date':1, 'author':1, 'file':1 }\n  date_types = { 'hours':1, 'day':1, 'week':1, 'month':1,\n                 'all':1, 'explicit':1 }\n\n  # parse various fields, validating or converting them\n  if not match_types.has_key(branch_match): branch_match = 'exact'\n  if not match_types.has_key(file_match): file_match = 'exact'\n  if not match_types.has_key(who_match): who_match = 'exact'\n  if not match_types.has_key(comment_match): comment_match = 'exact'\n  if not sort_types.has_key(querysort): querysort = 'date'\n  if not date_types.has_key(date): date = 'hours'\n  mindate = parse_date(mindate)\n  maxdate = parse_date(maxdate)\n\n  global cvsdb\n  import cvsdb\n\n  db = cvsdb.ConnectDatabaseReadOnly(cfg)\n  repos_root, repos_dir = cvsdb.FindRepository(db, request.rootpath)\n  if not repos_root:\n    raise debug.ViewVCException(\n      \"The root '%s' was not found in the commit database \"\n      % request.rootname)\n\n  # create the database query from the form data\n  query = cvsdb.CreateCheckinQuery()\n  query.SetRepository(repos_root)\n  # treat \"HEAD\" specially ...\n  if branch_match == 'exact' and branch == 'HEAD':\n    query.SetBranch('')\n  elif branch:\n    query.SetBranch(branch, branch_match)\n  if dir:\n    for subdir in dir.split(','):\n      path = (_path_join(repos_dir + request.path_parts\n                         + _path_parts(subdir.strip())))\n      query.SetDirectory(path, 'exact')\n      query.SetDirectory('%s/%%' % cvsdb.EscapeLike(path), 'like')\n  else:\n    where = _path_join(repos_dir + request.path_parts)\n    if where: # if we are in a subdirectory ...\n      query.SetDirectory(where, 'exact')\n      query.SetDirectory('%s/%%' % cvsdb.EscapeLike(where), 'like')\n  if file:\n    query.SetFile(file, file_match)\n  if who:\n    query.SetAuthor(who, who_match)\n  if comment:\n    query.SetComment(comment, comment_match)\n  query.SetSortMethod(querysort)\n  if date == 'hours':\n    query.SetFromDateHoursAgo(int(hours))\n  elif date == 'day':\n    query.SetFromDateDaysAgo(1)\n  elif date == 'week':\n    query.SetFromDateDaysAgo(7)\n  elif date == 'month':\n    query.SetFromDateDaysAgo(31)\n  elif date == 'all':\n    pass\n  elif date == 'explicit':\n    if mindate is not None:\n      query.SetFromDateObject(mindate)\n    if maxdate is not None:\n      query.SetToDateObject(maxdate)\n\n  # Set the admin-defined (via configuration) row limits.  This is to avoid\n  # slamming the database server with a monster query.\n  if format == 'rss':\n    query.SetLimit(cfg.cvsdb.rss_row_limit)\n  else:\n    query.SetLimit(cfg.cvsdb.row_limit)\n\n  # run the query\n  db.RunQuery(query)\n  commit_list = query.GetCommitList()\n  row_limit_reached = query.GetLimitReached()\n  \n  # gather commits\n  commits = []\n  plus_count = 0\n  minus_count = 0\n  mod_time = -1\n  if commit_list:\n    files = []\n    limited_files = 0\n    current_desc = commit_list[0].GetDescriptionID()\n    current_rev = commit_list[0].GetRevision()\n    dir_strip = _path_join(repos_dir)\n\n    for commit in commit_list:\n      commit_desc = commit.GetDescriptionID()\n      commit_rev = commit.GetRevision()\n\n      # base modification time on the newest commit\n      if commit.GetTime() > mod_time:\n        mod_time = commit.GetTime()\n        \n      # For CVS, group commits with the same commit message.\n      # For Subversion, group them only if they have the same revision number\n      if request.roottype == 'cvs':\n        if current_desc == commit_desc:\n          files.append(commit)\n          continue\n      else:\n        if current_rev == commit_rev:\n          files.append(commit)\n          continue\n\n      # append this grouping\n      commit_item = build_commit(request, files, limit_changes,\n                                 dir_strip, format)\n      if commit_item:\n        # update running plus/minus totals\n        plus_count = plus_count + commit_item.plus\n        minus_count = minus_count + commit_item.minus\n        commits.append(commit_item)\n\n      files = [ commit ]\n      limited_files = 0\n      current_desc = commit_desc\n      current_rev = commit_rev\n      \n    # we need to tack on our last commit grouping, if any\n    commit_item = build_commit(request, files, limit_changes,\n                               dir_strip, format)\n    if commit_item:\n      # update running plus/minus totals\n      plus_count = plus_count + commit_item.plus\n      minus_count = minus_count + commit_item.minus\n      commits.append(commit_item)\n  \n  # only show the branch column if we are querying all branches\n  # or doing a non-exact branch match on a CVS repository.\n  show_branch = ezt.boolean(request.roottype == 'cvs' and\n                            (branch == '' or branch_match != 'exact'))\n\n  # backout link\n  params = request.query_dict.copy()\n  params['format'] = 'backout'\n  backout_href = request.get_url(params=params,\n                                 escape=1)\n\n  # link to zero limit_changes value\n  params = request.query_dict.copy()\n  params['limit_changes'] = 0\n  limit_changes_href = request.get_url(params=params, escape=1)\n\n  # if we got any results, use the newest commit as the modification time\n  if mod_time >= 0:\n    if check_freshness(request, mod_time):\n      return\n\n  if format == 'backout':\n    query_backout(request, commits)\n    return\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'sql': request.server.escape(db.CreateSQLQueryString(query)),\n    'english_query': english_query(request),\n    'queryform_href': request.get_url(view_func=view_queryform, escape=1),\n    'backout_href': backout_href,\n    'plus_count': plus_count,\n    'minus_count': minus_count,\n    'show_branch': show_branch,\n    'querysort': querysort,\n    'commits': commits,\n    'row_limit_reached' : ezt.boolean(row_limit_reached),\n    'limit_changes': limit_changes,\n    'limit_changes_href': limit_changes_href,\n    'rss_link_href': request.get_url(view_func=view_query,\n                                     params={'date': 'month'},\n                                     escape=1,\n                                     prefix=1),\n    }))\n  if format == 'rss':\n    generate_page(request, \"rss\", data, \"application/rss+xml\")\n  else:\n    generate_page(request, \"query_results\", data)\n\n_views = {\n  'annotate':  view_annotate,\n  'co':        view_checkout,\n  'diff':      view_diff,\n  'dir':       view_directory,\n  'graph':     view_cvsgraph,\n  'graphimg':  view_cvsgraph_image,\n  'log':       view_log,\n  'markup':    view_markup,\n  'patch':     view_patch,\n  'query':     view_query,\n  'queryform': view_queryform,\n  'revision':  view_revision,\n  'roots':     view_roots,\n  'tar':       download_tarball,\n  'redirect_pathrev': redirect_pathrev,\n}\n\n_view_codes = {}\nfor code, view in _views.items():\n  _view_codes[view] = code\n\ndef list_roots(request):\n  cfg = request.cfg\n  allroots = { }\n  \n  # Add the viewable Subversion roots\n  for root in cfg.general.svn_roots.keys():\n    auth = setup_authorizer(cfg, request.username, root)\n    try:\n      repos = vclib.svn.SubversionRepository(root, cfg.general.svn_roots[root],\n                                             auth, cfg.utilities,\n                                             cfg.options.svn_config_dir)\n      lastmod = None\n      if cfg.options.show_roots_lastmod:\n        try:\n          repos.open()\n          youngest_rev = repos.youngest\n          date, author, msg, revprops, changes = repos.revinfo(youngest_rev)\n          date_str = make_time_string(date, cfg)\n          ago = html_time(request, date)\n          lf = LogFormatter(request, msg)\n          log = lf.get(maxlen=0, htmlize=1)\n          short_log = lf.get(maxlen=cfg.options.short_log_len, htmlize=1)\n          lastmod = _item(ago=ago, author=author, date=date_str, log=log,\n                          short_log=short_log, rev=str(youngest_rev))\n        except:\n          lastmod = None\n    except vclib.ReposNotFound:\n      continue\n    allroots[root] = [cfg.general.svn_roots[root], 'svn', lastmod]\n\n  # Add the viewable CVS roots\n  for root in cfg.general.cvs_roots.keys():\n    auth = setup_authorizer(cfg, request.username, root)\n    try:\n      vclib.ccvs.CVSRepository(root, cfg.general.cvs_roots[root], auth,\n                               cfg.utilities, cfg.options.use_rcsparse)\n    except vclib.ReposNotFound:\n      continue\n    allroots[root] = [cfg.general.cvs_roots[root], 'cvs', None]\n    \n  return allroots\n\ndef _parse_root_parent(pp):\n  \"\"\"Parse a single root parent \"directory [= context] : repo_type\" string\n  and return as tuple.\"\"\"\n\n  pos = pp.rfind(':')\n  if pos > 0:\n    repo_type = pp[pos+1:].strip()\n    pp = pp[:pos].strip()\n  else:\n    repo_type = None\n\n  pos = pp.rfind('=')\n  if pos > 0:\n    context = _path_parts(pp[pos+1:].strip())\n    pp = pp[:pos].strip()\n  else:\n    context = None\n\n  path = os.path.normpath(pp)\n  return path,context,repo_type\n\ndef expand_root_parents(cfg):\n  \"\"\"Expand the configured root parents into individual roots.\"\"\"\n  \n  # Each item in root_parents is a \"directory [= context ] : repo_type\" string.\n  for pp in cfg.general.root_parents:\n    path,context,repo_type = _parse_root_parent(pp)\n\n    if repo_type == 'cvs':\n      roots = vclib.ccvs.expand_root_parent(path)\n      if cfg.options.hide_cvsroot and roots.has_key('CVSROOT'):\n        del roots['CVSROOT']\n      if context:\n        fullroots = {}\n        for root, rootpath in roots.iteritems():\n          fullroots[_path_join(context + [root])] = rootpath\n        cfg.general.cvs_roots.update(fullroots)\n      else:\n        cfg.general.cvs_roots.update(roots)\n    elif repo_type == 'svn':\n      roots = vclib.svn.expand_root_parent(path)\n      if context:\n        fullroots = {}\n        for root, rootpath in roots.iteritems():\n          fullroots[_path_join(context + [root])] = rootpath\n        cfg.general.svn_roots.update(fullroots)\n      else:\n        cfg.general.svn_roots.update(roots)\n    elif repo_type == None:\n      raise debug.ViewVCException(\n        'The path \"%s\" in \"root_parents\" does not include a '\n        'repository type.  Expected \"cvs\" or \"svn\".' % (pp))\n    else:\n      raise debug.ViewVCException(\n        'The path \"%s\" in \"root_parents\" has an unrecognized '\n        'repository type (\"%s\").  Expected \"cvs\" or \"svn\".'\n        % (pp, repo_type))\n\ndef find_root_in_parents(cfg, path_parts, roottype):\n  \"\"\"Return the rootpath for configured ROOTNAME of ROOTTYPE.\"\"\"\n\n  # Easy out:  caller wants rootname \"CVSROOT\", and we're hiding those.\n  if path_parts[-1] == 'CVSROOT' and cfg.options.hide_cvsroot:\n    return None\n\n  for pp in cfg.general.root_parents:\n    path,context,repo_type = _parse_root_parent(pp)\n\n    if repo_type != roottype:\n      continue\n    if context != None:\n      if not _path_starts_with(path_parts, context):\n        continue\n      rootidx = len(context)\n    else:\n      rootidx = 0\n\n    if len(path_parts) <= rootidx:\n      continue\n\n    rootname = path_parts[rootidx]\n    fullroot = _path_join(path_parts[0:rootidx+1])\n    remain = path_parts[rootidx+1:]\n\n    rootpath = None\n    if roottype == 'cvs':\n      rootpath = vclib.ccvs.find_root_in_parent(path, rootname)\n    elif roottype == 'svn':\n      rootpath = vclib.svn.find_root_in_parent(path, rootname)\n\n    if rootpath is not None:\n      return fullroot, rootpath, remain\n  return None, None, None\n\ndef locate_root_from_path(cfg, path_parts):\n  \"\"\"Return a 4-tuple ROOTTYPE, ROOTPATH, ROOTNAME, REMAIN for path_parts.\"\"\"\n  for rootname, rootpath in cfg.general.cvs_roots.iteritems():\n    pp = _path_parts(rootname)\n    if _path_starts_with(path_parts, pp):\n      return 'cvs', rootpath, rootname, path_parts[len(pp):]\n  for rootname, rootpath in cfg.general.svn_roots.iteritems():\n    pp = _path_parts(rootname)\n    if _path_starts_with(path_parts, pp):\n      return 'svn', rootpath, rootname, path_parts[len(pp):]\n  rootname, path_in_parent, remain = \\\n          find_root_in_parents(cfg, path_parts, 'cvs')\n  if path_in_parent:\n    cfg.general.cvs_roots[rootname] = path_in_parent\n    return 'cvs', path_in_parent, rootname, remain\n  rootname, path_in_parent, remain = \\\n          find_root_in_parents(cfg, path_parts, 'svn')\n  if path_in_parent:\n    cfg.general.svn_roots[rootname] = path_in_parent\n    return 'svn', path_in_parent, rootname, remain\n  return None, None, None, None\n\ndef locate_root(cfg, rootname):\n  \"\"\"Return a 2-tuple ROOTTYPE, ROOTPATH for configured ROOTNAME.\"\"\"\n  # First try a direct match\n  if cfg.general.cvs_roots.has_key(rootname):\n    return 'cvs', cfg.general.cvs_roots[rootname]\n  if cfg.general.svn_roots.has_key(rootname):\n    return 'svn', cfg.general.svn_roots[rootname]\n\n  path_parts = _path_parts(rootname)\n  roottype, rootpath, rootname_dupl, remain = \\\n          locate_root_from_path(cfg, path_parts)\n  if roottype != None:\n    if rootname_dupl != rootname:\n      raise debug.ViewVCException(\n        'Found root name \"%s\" doesn\\'t match \"%s\"' \\\n        % (rootname_dupl, rootname),\n        '500 Internal Server Error')\n    if len(remain) > 0:\n      raise debug.ViewVCException(\n        'Have remaining path \"%s\"' \\\n        % (remain),\n        '500 Internal Server Error')\n  return roottype, rootpath\n\ndef load_config(pathname=None, server=None):\n  \"\"\"Load the ViewVC configuration file.  SERVER is the server object\n  that will be using this configuration.  Consult the environment for\n  the variable VIEWVC_CONF_PATHNAME and VIEWCVS_CONF_PATHNAME (its\n  legacy name) and, if set, use its value as the path of the\n  configuration file; otherwise, use PATHNAME (if provided).  Failing\n  all else, use a hardcoded default configuration path.\"\"\"\n  \n  debug.t_start('load-config')\n\n  # See if the environment contains overrides to the configuration\n  # path.  If we have a SERVER object, consult its environment; use\n  # the OS environment otherwise.\n  env_get = server and server.getenv or os.environ.get\n  env_pathname = (env_get(\"VIEWVC_CONF_PATHNAME\")\n                  or env_get(\"VIEWCVS_CONF_PATHNAME\"))\n\n  # Try to find the configuration pathname by searching these ordered\n  # locations: the environment, the passed-in PATHNAME, the hard-coded\n  # default.\n  pathname = (env_pathname\n              or pathname\n              or os.path.join(os.path.dirname(os.path.dirname(__file__)),\n                              \"viewvc.conf\"))\n\n  # Load the configuration!\n  cfg = config.Config()\n  cfg.set_defaults()\n  cfg.load_config(pathname, env_get(\"HTTP_HOST\"))\n\n  # Apply the stacktrace configuration immediately.\n  sys.tracebacklimit = cfg.options.stacktraces and 1000 or 0\n\n  # Load mime types file(s), but reverse the order -- our\n  # configuration uses a most-to-least preferred approach, but the\n  # 'mimetypes' package wants things the other way around.\n  if cfg.general.mime_types_files:\n    files = cfg.general.mime_types_files[:]\n    files.reverse()\n    files = map(lambda x, y=pathname: os.path.join(os.path.dirname(y), x), files)\n    mimetypes.init(files)\n\n  debug.t_end('load-config')\n  return cfg\n\n\ndef view_error(server, cfg):\n  exc_dict = debug.GetExceptionData()\n  status = exc_dict['status']\n  if exc_dict['msg']:\n    exc_dict['msg'] = server.escape(exc_dict['msg'])\n  if exc_dict['stacktrace']:\n    exc_dict['stacktrace'] = server.escape(exc_dict['stacktrace'])\n\n  # Use the configured error template if possible.\n  try:\n    if cfg and not server.headerSent:\n      server.header(status=status)\n      template = get_view_template(cfg, \"error\")\n      template.generate(server.file(), exc_dict)\n      return\n  except:\n    pass\n\n  # Fallback to the old exception printer if no configuration is\n  # available, or if something went wrong.\n  debug.PrintException(server, exc_dict)\n\ndef main(server, cfg):\n  try:\n    debug.t_start('main')\n    try:\n      # build a Request object, which contains info about the HTTP request\n      request = Request(server, cfg)\n      request.run_viewvc()\n    except SystemExit, e:\n      return\n    except:\n      view_error(server, cfg)\n\n  finally:\n    debug.t_end('main')\n    debug.t_dump(server.file())\n    debug.DumpChildren(server)\n"], "fixing_code": ["# -*-python-*-\n#\n# Copyright (C) 1999-2020 The ViewCVS Group. All Rights Reserved.\n#\n# By using this file, you agree to the terms and conditions set forth in\n# the LICENSE.html file which can be found at the top level of the ViewVC\n# distribution or at http://viewvc.org/license-1.html.\n#\n# For more information, visit http://viewvc.org/\n#\n# -----------------------------------------------------------------------\n#\n# viewvc: View CVS/SVN repositories via a web browser\n#\n# -----------------------------------------------------------------------\n\n__version__ = '1.2.1-dev'\n\n# this comes from our library; measure the startup time\nimport debug\ndebug.t_start('startup')\ndebug.t_start('imports')\n\n# standard modules that we know are in the path or builtin\nimport sys\nimport os\nimport calendar\nimport copy\nimport fnmatch\nimport gzip\nimport mimetypes\nimport re\nimport rfc822\nimport stat\nimport struct\nimport tempfile\nimport time\nimport types\nimport urllib\n\n# These modules come from our library (the stub has set up the path)\nfrom common import _item, _RCSDIFF_NO_CHANGES, _RCSDIFF_IS_BINARY, _RCSDIFF_ERROR, TemplateData\nimport accept\nimport config\nimport ezt\nimport popen\nimport sapi\nimport vcauth\nimport vclib\nimport vclib.ccvs\nimport vclib.svn\n\ntry:\n  import idiff\nexcept (SyntaxError, ImportError):\n  idiff = None\n\ndebug.t_end('imports')\n\n# Initialize the system tracebacklimit value to 0, meaning stack\n# traces will carry only the top-level exception string.  This can be\n# overridden via configuration.\nsys.tracebacklimit = 0\n\n#########################################################################\n\ncheckout_magic_path = '*checkout*'\n# According to RFC 1738 the '~' character is unsafe in URLs.\n# But for compatibility with URLs bookmarked with old releases of ViewCVS:\noldstyle_checkout_magic_path = '~checkout~'\ndocroot_magic_path = '*docroot*'\nviewcvs_mime_type = 'text/vnd.viewcvs-markup'\nalt_mime_type = 'text/x-cvsweb-markup'\nview_roots_magic = '*viewroots*'\n\n# Put here the variables we need in order to hold our state - they\n# will be added (with their current value) to (almost) any link/query\n# string you construct.\n_sticky_vars = [\n  'hideattic',\n  'sortby',\n  'sortdir',\n  'logsort',\n  'diff_format',\n  'search',\n  'limit_changes',\n  ]\n\n# for reading/writing between a couple descriptors\nCHUNK_SIZE = 8192\n\n# special characters that don't need to be URL encoded\n_URL_SAFE_CHARS = \"/*~\"\n\n\nclass Request:\n  def __init__(self, server, cfg):\n    self.server = server\n    self.cfg = cfg\n\n    self.script_name = _normalize_path(server.getenv('SCRIPT_NAME', ''))\n    self.browser = server.getenv('HTTP_USER_AGENT', 'unknown')\n\n    # process the Accept-Language: header, and load the key/value\n    # files, given the selected language\n    hal = server.getenv('HTTP_ACCEPT_LANGUAGE','')\n    try:\n      self.lang_selector = accept.language(hal)\n    except accept.AcceptLanguageParseError:\n      self.lang_selector = accept.language('en')\n    self.language = self.lang_selector.select_from(cfg.general.languages)\n    self.kv = cfg.load_kv_files(self.language)\n\n    # check for an authenticated username\n    self.username = server.getenv('REMOTE_USER')\n\n    # if we allow compressed output, see if the client does too\n    self.gzip_compress_level = 0\n    if cfg.options.allow_compress:\n      http_accept_encoding = os.environ.get(\"HTTP_ACCEPT_ENCODING\", \"\")\n      if \"gzip\" in filter(None,\n                          map(lambda x: x.strip(),\n                              http_accept_encoding.split(','))):\n        self.gzip_compress_level = 9  # make this configurable?\n\n  def run_viewvc(self):\n\n    cfg = self.cfg\n\n    # This function first parses the query string and sets the following\n    # variables. Then it executes the request.\n    self.view_func = None  # function to call to process the request\n    self.repos = None      # object representing current repository\n    self.rootname = None   # name of current root (as used in viewvc.conf)\n    self.roottype = None   # current root type ('svn' or 'cvs')\n    self.rootpath = None   # physical path to current root\n    self.pathtype = None   # type of path, either vclib.FILE or vclib.DIR\n    self.where = None      # path to file or directory in current root\n    self.query_dict = {}   # validated and cleaned up query options\n    self.path_parts = None # for convenience, equals where.split('/')\n    self.pathrev = None    # current path revision or tag\n    self.auth = None       # authorizer module in use\n\n    # redirect if we're loading from a valid but irregular URL\n    # These redirects aren't neccessary to make ViewVC work, it functions\n    # just fine without them, but they make it easier for server admins to\n    # implement access restrictions based on URL\n    needs_redirect = 0\n\n    # Process the query params\n    for name, values in self.server.params().items():\n      # we only care about the first value\n      value = values[0]\n      \n      # patch up old queries that use 'cvsroot' to look like they used 'root'\n      if name == 'cvsroot':\n        name = 'root'\n        needs_redirect = 1\n\n      # same for 'only_with_tag' and 'pathrev'\n      if name == 'only_with_tag':\n        name = 'pathrev'\n        needs_redirect = 1\n\n      # redirect view=rev to view=revision, too\n      if name == 'view' and value == 'rev':\n        value = 'revision'\n        needs_redirect = 1\n\n      # validate the parameter\n      _validate_param(name, value)\n      \n      # if we're here, then the parameter is okay\n      self.query_dict[name] = value\n\n    # Resolve the view parameter into a handler function.\n    self.view_func = _views.get(self.query_dict.get('view', None), \n                                self.view_func)\n\n    # Process PATH_INFO component of query string\n    path_info = self.server.getenv('PATH_INFO', '')\n\n    # clean it up. this removes duplicate '/' characters and any that may\n    # exist at the front or end of the path.\n    ### we might want to redirect to the cleaned up URL\n    path_parts = _path_parts(path_info)\n\n    if path_parts:\n      # handle magic path prefixes\n      if path_parts[0] == docroot_magic_path:\n        # if this is just a simple hunk of doc, then serve it up\n        self.where = _path_join(path_parts[1:])\n        return view_doc(self)\n      elif path_parts[0] in (checkout_magic_path,\n                             oldstyle_checkout_magic_path):\n        path_parts.pop(0)\n        self.view_func = view_checkout\n        if not cfg.options.checkout_magic:\n          needs_redirect = 1\n\n      # handle tarball magic suffixes\n      if self.view_func is download_tarball:\n        if (self.query_dict.get('parent')):\n          del path_parts[-1]\n        elif path_parts[-1][-7:] == \".tar.gz\":\n          path_parts[-1] = path_parts[-1][:-7]\n\n    # Figure out root name\n    self.rootname = self.query_dict.get('root')\n    if self.rootname == view_roots_magic:\n      del self.query_dict['root']\n      self.rootname = \"\"\n      needs_redirect = 1\n    elif self.rootname is None:\n      if cfg.options.root_as_url_component:\n        if path_parts:\n          roottype, rootpath, self.rootname, new_path_parts = \\\n                  locate_root_from_path(cfg, path_parts)\n          if roottype is None:\n            # Perhaps the root name is candidate for renaming...\n            # Take care of old-new roots mapping\n            for old_root, new_root in cfg.general.renamed_roots.iteritems():\n              pp = _path_parts(old_root)\n              if _path_starts_with(path_parts, pp):\n                path_parts = path_parts[len(pp):]\n                self.rootname = new_root\n                needs_redirect = 1\n            if self.rootname is None:\n              # Not found; interpret whole path as root, to show as error\n              self.rootname = _path_join(path_parts)\n              path_parts = []\n          else:\n            path_parts = new_path_parts\n        else:\n          self.rootname = \"\"\n      elif self.view_func != view_roots:\n        self.rootname = cfg.general.default_root\n    elif cfg.options.root_as_url_component:\n      needs_redirect = 1\n\n    # Take care of old-new roots mapping\n    for old_root, new_root in cfg.general.renamed_roots.iteritems():\n      if self.rootname == old_root:\n        self.rootname = new_root\n        needs_redirect = 1\n\n    self.where = _path_join(path_parts)\n    self.path_parts = path_parts\n\n    if self.rootname:\n      roottype, rootpath = locate_root(cfg, self.rootname)\n      if roottype:\n        # Overlay root-specific options.\n        cfg.overlay_root_options(self.rootname)\n        \n        # Setup an Authorizer for this rootname and username\n        debug.t_start('setup-authorizer')\n        self.auth = setup_authorizer(cfg, self.username)\n        debug.t_end('setup-authorizer')\n\n        # Create the repository object\n        debug.t_start('select-repos')\n        try:\n          if roottype == 'cvs':\n            self.rootpath = vclib.ccvs.canonicalize_rootpath(rootpath)\n            self.repos = vclib.ccvs.CVSRepository(self.rootname,\n                                                  self.rootpath,\n                                                  self.auth,\n                                                  cfg.utilities,\n                                                  cfg.options.use_rcsparse)\n            # required so that spawned rcs programs correctly expand\n            # $CVSHeader$\n            os.environ['CVSROOT'] = self.rootpath\n          elif roottype == 'svn':\n            self.rootpath = vclib.svn.canonicalize_rootpath(rootpath)\n            self.repos = vclib.svn.SubversionRepository(self.rootname,\n                                                        self.rootpath,\n                                                        self.auth,\n                                                        cfg.utilities,\n                                                        cfg.options.svn_config_dir)\n          else:\n            raise vclib.ReposNotFound()\n        except vclib.ReposNotFound:\n          pass\n        debug.t_end('select-repos')\n      if self.repos is None:\n        raise debug.ViewVCException(\n          'The root \"%s\" is unknown. If you believe the value is '\n          'correct, then please double-check your configuration.'\n          % self.rootname, \"404 Not Found\")\n\n    if self.repos:\n      debug.t_start('select-repos')\n      self.repos.open()\n      debug.t_end('select-repos')\n      type = self.repos.roottype()\n      if type == vclib.SVN:\n        self.roottype = 'svn'\n      elif type == vclib.CVS:\n        self.roottype = 'cvs'\n      else:\n        raise debug.ViewVCException(\n          'The root \"%s\" has an unknown type (\"%s\").  Expected \"cvs\" or \"svn\".'\n          % (self.rootname, type),\n          \"500 Internal Server Error\")\n      \n    # If this is using an old-style 'rev' parameter, redirect to new hotness.\n    # Subversion URLs will now use 'pathrev'; CVS ones use 'revision'.\n    if self.repos and self.query_dict.has_key('rev'):\n      if self.roottype == 'svn' \\\n             and not self.query_dict.has_key('pathrev') \\\n             and not self.view_func == view_revision:\n        self.query_dict['pathrev'] = self.query_dict['rev']\n        del self.query_dict['rev']\n      else: # elif not self.query_dict.has_key('revision'): ?\n        self.query_dict['revision'] = self.query_dict['rev']\n        del self.query_dict['rev']\n      needs_redirect = 1\n\n    if self.repos and self.view_func is not redirect_pathrev:\n      # If this is an intended-to-be-hidden CVSROOT path, complain.\n      if cfg.options.hide_cvsroot \\\n         and is_cvsroot_path(self.roottype, path_parts):\n        raise debug.ViewVCException(\"Unknown location: /%s\" % self.where,\n                                    \"404 Not Found\")\n\n      # Make sure path exists\n      self.pathrev = pathrev = self.query_dict.get('pathrev')\n      self.pathtype = _repos_pathtype(self.repos, path_parts, pathrev)\n\n      if self.pathtype is None:\n        # Path doesn't exist, see if it could be an old-style ViewVC URL\n        # with a fake suffix.\n        result = _strip_suffix('.diff', path_parts, pathrev, vclib.FILE,     \\\n                               self.repos, view_diff) or                     \\\n                 _strip_suffix('.tar.gz', path_parts, pathrev, vclib.DIR,    \\\n                               self.repos, download_tarball) or              \\\n                 _strip_suffix('root.tar.gz', path_parts, pathrev, vclib.DIR,\\\n                               self.repos, download_tarball) or              \\\n                 _strip_suffix(self.rootname + '-root.tar.gz',               \\\n                               path_parts, pathrev, vclib.DIR,               \\\n                               self.repos, download_tarball) or              \\\n                 _strip_suffix('root',                                       \\\n                               path_parts, pathrev, vclib.DIR,               \\\n                               self.repos, download_tarball) or              \\\n                 _strip_suffix(self.rootname + '-root',                      \\\n                               path_parts, pathrev, vclib.DIR,               \\\n                               self.repos, download_tarball)\n        if result:\n          self.path_parts, self.pathtype, self.view_func = result\n          self.where = _path_join(self.path_parts)\n          needs_redirect = 1\n        else:\n          raise debug.ViewVCException(\"Unknown location: /%s\" % self.where,\n                                      \"404 Not Found\")\n\n      # If we have an old ViewCVS Attic URL which is still valid, redirect\n      if self.roottype == 'cvs':\n        attic_parts = None\n        if (self.pathtype == vclib.FILE and len(self.path_parts) > 1\n            and self.path_parts[-2] == 'Attic'):\n          attic_parts = self.path_parts[:-2] + self.path_parts[-1:]\n        elif (self.pathtype == vclib.DIR and len(self.path_parts) > 0\n              and self.path_parts[-1] == 'Attic'):\n          attic_parts = self.path_parts[:-1]\n        if attic_parts:\n          self.path_parts = attic_parts\n          self.where = _path_join(attic_parts)\n          needs_redirect = 1\n\n    if self.view_func is None:\n      # view parameter is not set, try looking at pathtype and the \n      # other parameters\n      if not self.rootname:\n        self.view_func = view_roots\n      elif self.pathtype == vclib.DIR:\n        # ViewCVS 0.9.2 used to put ?tarball=1 at the end of tarball urls\n        if self.query_dict.has_key('tarball'):\n          self.view_func = download_tarball\n        elif self.query_dict.has_key('r1') and self.query_dict.has_key('r2'):\n          self.view_func = view_diff\n        else:\n          self.view_func = view_directory\n      elif self.pathtype == vclib.FILE:\n        if self.query_dict.has_key('r1') and self.query_dict.has_key('r2'):\n          self.view_func = view_diff\n        elif self.query_dict.has_key('annotate'):\n          self.view_func = view_annotate\n        elif self.query_dict.has_key('graph'):\n          if not self.query_dict.has_key('makeimage'):\n            self.view_func = view_cvsgraph\n          else: \n            self.view_func = view_cvsgraph_image\n        elif self.query_dict.has_key('revision') \\\n                 or cfg.options.default_file_view != \"log\":\n          if cfg.options.default_file_view == \"markup\" \\\n             or self.query_dict.get('content-type', None) \\\n                 in (viewcvs_mime_type, alt_mime_type):\n            self.view_func = view_markup\n          else:\n            self.view_func = view_checkout\n        else:\n          self.view_func = view_log\n\n    # If we've chosen the roots or revision view, our effective\n    # location is not really \"inside\" the repository, so we have no\n    # path and therefore no path parts or type, either.\n    if self.view_func is view_revision or self.view_func is view_roots:\n      self.where = ''\n      self.path_parts = []\n      self.pathtype = None\n      \n    # if we have a directory and the request didn't end in \"/\", then redirect\n    # so that it does.\n    if (self.pathtype == vclib.DIR and path_info[-1:] != '/'\n        and self.view_func is not download_tarball\n        and self.view_func is not redirect_pathrev):\n      needs_redirect = 1\n\n    # startup is done now.\n    debug.t_end('startup')\n\n    # If we need to redirect, do so.  Otherwise, handle our requested view.\n    if needs_redirect:\n      self.server.redirect(self.get_url())\n    else:\n      debug.t_start('view-func')\n      self.view_func(self)\n      debug.t_end('view-func')\n\n  def get_url(self, escape=0, partial=0, prefix=0, **args):\n    \"\"\"Constructs a link to another ViewVC page just like the get_link\n    function except that it returns a single URL instead of a URL\n    split into components.  If PREFIX is set, include the protocol and\n    server name portions of the URL.\"\"\"\n\n    url, params = apply(self.get_link, (), args)\n    qs = urllib.urlencode(params)\n    if qs:\n      result = urllib.quote(url, _URL_SAFE_CHARS) + '?' + qs\n    else:\n      result = urllib.quote(url, _URL_SAFE_CHARS)\n\n    if partial:\n      result = result + (qs and '&' or '?')\n    if escape:\n      result = self.server.escape(result)\n    if prefix:\n      result = '%s://%s%s' % \\\n               (self.server.getenv(\"HTTPS\") == \"on\" and \"https\" or \"http\",\n                self.server.getenv(\"HTTP_HOST\"),\n                result)\n    return result\n\n  def get_form(self, **args):\n    \"\"\"Constructs a link to another ViewVC page just like the get_link\n    function except that it returns a base URL suitable for use as an\n    HTML form action, and an iterable object with .name and .value\n    attributes representing stuff that should be in <input\n    type=hidden> tags with the link parameters.\"\"\"\n\n    url, params = apply(self.get_link, (), args)\n    action = self.server.escape(urllib.quote(url, _URL_SAFE_CHARS))\n    hidden_values = []\n    for name, value in params.items():\n      hidden_values.append(_item(name=self.server.escape(name),\n                                 value=self.server.escape(value)))\n    return action, hidden_values\n\n  def get_link(self, view_func=None, where=None, pathtype=None, params=None):\n    \"\"\"Constructs a link pointing to another ViewVC page. All arguments\n    correspond to members of the Request object. If they are set to \n    None they take values from the current page. Return value is a base\n    URL and a dictionary of parameters\"\"\"\n\n    cfg = self.cfg\n\n    if view_func is None:\n      view_func = self.view_func\n\n    if params is None:\n      params = self.query_dict.copy()\n    else:\n      params = params.copy()\n      \n    # must specify both where and pathtype or neither\n    assert (where is None) == (pathtype is None)\n\n    # if we are asking for the revision info view, we don't need any\n    # path information\n    if (view_func is view_revision or view_func is view_roots\n        or view_func is redirect_pathrev):\n      where = pathtype = None\n    elif where is None:\n      where = self.where\n      pathtype = self.pathtype\n\n    # no need to add sticky variables for views with no links\n    sticky_vars = not (view_func is view_checkout \n                       or view_func is download_tarball)\n\n    # The logic used to construct the URL is an inverse of the\n    # logic used to interpret URLs in Request.run_viewvc\n\n    url = self.script_name\n\n    # add checkout magic if neccessary\n    if view_func is view_checkout and cfg.options.checkout_magic:\n      url = url + '/' + checkout_magic_path\n\n    # add root to url\n    rootname = None\n    if view_func is not view_roots:\n      if cfg.options.root_as_url_component:\n        # remove root from parameter list if present\n        try:\n          rootname = params['root']\n        except KeyError:\n          rootname = self.rootname\n        else:\n          del params['root']\n\n        # add root path component\n        if rootname is not None:\n          url = url + '/' + rootname\n\n      else:\n        # add root to parameter list\n        try:\n          rootname = params['root']\n        except KeyError:\n          rootname = params['root'] = self.rootname\n\n        # no need to specify default root\n        if rootname == cfg.general.default_root:\n          del params['root']   \n\n    # add 'pathrev' value to parameter list\n    if (self.pathrev is not None\n        and not params.has_key('pathrev')\n        and view_func is not view_revision\n        and rootname == self.rootname):\n      params['pathrev'] = self.pathrev\n\n    # add path\n    if where:\n      url = url + '/' + where\n\n    # add trailing slash for a directory\n    if pathtype == vclib.DIR:\n      url = url + '/'\n\n    # normalize top level URLs for use in Location headers and A tags\n    elif not url:\n      url = '/'\n\n    # no need to explicitly specify directory view for a directory\n    if view_func is view_directory and pathtype == vclib.DIR:\n      view_func = None\n\n    # no need to explicitly specify roots view when in root_as_url\n    # mode or there's no default root\n    if view_func is view_roots and (cfg.options.root_as_url_component\n                                    or not cfg.general.default_root):\n      view_func = None\n\n    # no need to explicitly specify annotate view when\n    # there's an annotate parameter\n    if view_func is view_annotate and params.get('annotate') is not None:\n      view_func = None\n\n    # no need to explicitly specify diff view when\n    # there's r1 and r2 parameters\n    if (view_func is view_diff and params.get('r1') is not None\n        and params.get('r2') is not None):\n      view_func = None\n\n    # no need to explicitly specify checkout view when it's the default\n    # view or when checkout_magic is enabled\n    if view_func is view_checkout:\n      if ((cfg.options.default_file_view == \"co\" and pathtype == vclib.FILE)\n          or cfg.options.checkout_magic):\n        view_func = None\n\n    # no need to explicitly specify markup view when it's the default view\n    if view_func is view_markup:\n      if (cfg.options.default_file_view == \"markup\" \\\n          and pathtype == vclib.FILE):\n        view_func = None\n\n    # set the view parameter\n    view_code = _view_codes.get(view_func)\n    if view_code and not (params.has_key('view') and params['view'] is None):\n      params['view'] = view_code\n\n    # add sticky values to parameter list\n    if sticky_vars:\n      for name in _sticky_vars:\n        value = self.query_dict.get(name)\n        if value is not None and not params.has_key(name):\n          params[name] = value\n\n    # remove null values from parameter list\n    for name, value in params.items():\n      if value is None:\n        del params[name]\n\n    return url, params\n\ndef _path_parts(path):\n  \"\"\"Split up a repository path into a list of path components\"\"\"\n  # clean it up. this removes duplicate '/' characters and any that may\n  # exist at the front or end of the path.\n  return filter(None, path.split('/'))\n\ndef _normalize_path(path):\n  \"\"\"Collapse leading slashes in the script name\n\n  You only get multiple slashes in the script name when users accidentally\n  type urls like http://abc.com//viewvc.cgi/, but we correct for it\n  because we output the script name in links and web browsers\n  interpret //viewvc.cgi/ as http://viewvc.cgi/\n  \"\"\"\n  \n  i = 0\n  for c in path:\n    if c != '/':\n      break\n    i = i + 1\n\n  if i:\n    return path[i-1:]\n\n  return path\n\ndef _validate_param(name, value):\n  \"\"\"Validate whether the given value is acceptable for the param name.\n\n  If the value is not allowed, then an error response is generated, and\n  this function throws an exception. Otherwise, it simply returns None.\n  \"\"\"\n\n  # First things first -- check that we have a legal parameter name.\n  try:\n    validator = _legal_params[name]\n  except KeyError:\n    raise debug.ViewVCException(\n      'An illegal parameter name was provided.',\n      '400 Bad Request')\n\n  # Is there a validator?  Is it a regex or a function?  Validate if\n  # we can, returning without incident on valid input.\n  if validator is None:\n    return\n  elif hasattr(validator, 'match'):\n    if validator.match(value):\n      return\n  else:\n    if validator(value):\n      return\n\n  # If we get here, the input value isn't valid.\n  raise debug.ViewVCException(\n    'An illegal value was provided for the \"%s\" parameter.' % (name),\n    '400 Bad Request')\n\ndef _validate_regex(value):\n  ### we need to watch the flow of these parameters through the system\n  ### to ensure they don't hit the page unescaped. otherwise, these\n  ### parameters could constitute a CSS attack.\n  try:\n    re.compile(value)\n    return True\n  except:\n    return None\n\ndef _validate_view(value):\n  # Return true iff VALUE is one of our allowed views.\n  return _views.has_key(value)\n\ndef _validate_mimetype(value):\n  # For security purposes, we only allow mimetypes from a predefined set\n  # thereof.\n  return value in (viewcvs_mime_type, alt_mime_type, 'text/plain')\n\n# obvious things here. note that we don't need uppercase for alpha.\n_re_validate_alpha = re.compile('^[a-z]+$')\n_re_validate_number = re.compile('^[0-9]+$')\n_re_validate_boolint = re.compile('^[01]$')\n\n# when comparing two revs, we sometimes construct REV:SYMBOL, so ':' is needed\n_re_validate_revnum = re.compile('^[-_.a-zA-Z0-9:~\\\\[\\\\]/]*$')\n\n# date time values\n_re_validate_datetime = re.compile(r'^(\\d\\d\\d\\d-\\d\\d-\\d\\d(\\s+\\d\\d:\\d\\d'\n                                   '(:\\d\\d)?)?)?$')\n\n# the legal query parameters and their validation functions\n_legal_params = {\n  'root'          : None,\n  'view'          : _validate_view,\n  'search'        : _validate_regex,\n  'p1'            : None,\n  'p2'            : None,\n  \n  'hideattic'     : _re_validate_boolint,\n  'limit_changes' : _re_validate_number,\n  'sortby'        : _re_validate_alpha,\n  'sortdir'       : _re_validate_alpha,\n  'logsort'       : _re_validate_alpha,\n  'diff_format'   : _re_validate_alpha,\n  'pathrev'       : _re_validate_revnum,\n  'dir_pagestart' : _re_validate_number,\n  'log_pagestart' : _re_validate_number,\n  'annotate'      : _re_validate_revnum,\n  'graph'         : _re_validate_revnum,\n  'makeimage'     : _re_validate_boolint,\n  'r1'            : _re_validate_revnum,\n  'tr1'           : _re_validate_revnum,\n  'r2'            : _re_validate_revnum,\n  'tr2'           : _re_validate_revnum,\n  'revision'      : _re_validate_revnum,\n  'content-type'  : _validate_mimetype,\n\n  # for cvsgraph\n  'gflip'         : _re_validate_boolint,\n  'gbbox'         : _re_validate_boolint,\n  'gshow'         : _re_validate_alpha,\n  'gleft'         : _re_validate_boolint,\n  'gmaxtag'       : _re_validate_number,\n\n  # for query\n  'file_match'    : _re_validate_alpha,\n  'branch_match'  : _re_validate_alpha,\n  'who_match'     : _re_validate_alpha,\n  'comment_match' : _re_validate_alpha,\n  'dir'           : None,\n  'file'          : None,\n  'branch'        : None,\n  'who'           : None,\n  'comment'       : None,\n  'querysort'     : _re_validate_alpha,\n  'date'          : _re_validate_alpha,\n  'hours'         : _re_validate_number,\n  'mindate'       : _re_validate_datetime,\n  'maxdate'       : _re_validate_datetime,\n  'format'        : _re_validate_alpha,\n\n  # for redirect_pathrev\n  'orig_path'     : None,\n  'orig_pathtype' : None,\n  'orig_pathrev'  : None,\n  'orig_view'     : None,\n\n  # deprecated - these are no longer used, but kept around so that\n  # bookmarked URLs still \"work\" (for some definition thereof) after a\n  # ViewVC upgrade.\n  'parent'        : _re_validate_boolint,\n  'rev'           : _re_validate_revnum,\n  'tarball'       : _re_validate_boolint,\n  'hidecvsroot'   : _re_validate_boolint,\n  'limit'         : _re_validate_number,\n  }\n\ndef _path_join(path_parts):\n  return '/'.join(path_parts)\n\ndef _path_starts_with(path_parts, first_path_parts):\n  if not path_parts:\n    return False\n  if len(path_parts) < len(first_path_parts):\n    return False\n  return path_parts[0:len(first_path_parts)] == first_path_parts\n\ndef _strip_suffix(suffix, path_parts, rev, pathtype, repos, view_func):\n  \"\"\"strip the suffix from a repository path if the resulting path\n  is of the specified type, otherwise return None\"\"\"\n  if not path_parts:\n    return None\n  l = len(suffix)\n  if path_parts[-1][-l:] == suffix:\n    path_parts = path_parts[:]\n    if len(path_parts[-1]) == l:\n      del path_parts[-1]\n    else:\n      path_parts[-1] = path_parts[-1][:-l]\n    t = _repos_pathtype(repos, path_parts, rev)\n    if pathtype == t:\n      return path_parts, t, view_func\n  return None\n\ndef _repos_pathtype(repos, path_parts, rev):\n  \"\"\"Return the type of a repository path, or None if the path doesn't\n  exist\"\"\"\n  try:\n    return repos.itemtype(path_parts, rev)\n  except vclib.ItemNotFound:\n    return None\n\ndef _orig_path(request, rev_param='revision', path_param=None):\n  \"Get original path of requested file at old revision before copies or moves\"\n\n  # The 'pathrev' variable is interpreted by nearly all ViewVC views to\n  # provide a browsable snapshot of a repository at some point in its history.\n  # 'pathrev' is a tag name for CVS repositories and a revision number for\n  # Subversion repositories. It's automatically propagated between pages by\n  # logic in the Request.get_link() function which adds it to links like a\n  # sticky variable. When 'pathrev' is set, directory listings only include\n  # entries that exist in the specified revision or tag. Similarly, log pages\n  # will only show revisions preceding the point in history specified by\n  # 'pathrev.' Markup, checkout, and annotate pages show the 'pathrev'\n  # revision of files by default when no other revision is specified.\n  #\n  # In Subversion repositories, paths are always considered to refer to the\n  # pathrev revision. For example, if there is a \"circle.jpg\" in revision 3,\n  # which is renamed and modified as \"square.jpg\" in revision 4, the original\n  # circle image is visible at the following URLs:\n  #\n  #     *checkout*/circle.jpg?pathrev=3\n  #     *checkout*/square.jpg?revision=3\n  #     *checkout*/square.jpg?revision=3&pathrev=4\n  # \n  # Note that the following:\n  #\n  #     *checkout*/circle.jpg?rev=3\n  #\n  # now gets redirected to one of the following URLs:\n  #\n  #     *checkout*/circle.jpg?pathrev=3  (for Subversion)\n  #     *checkout*/circle.jpg?revision=3  (for CVS)\n  #\n  rev = request.query_dict.get(rev_param, request.pathrev)\n  path = request.query_dict.get(path_param, request.where)\n  \n  if rev is not None and hasattr(request.repos, '_getrev'):\n    try:\n      pathrev = request.repos._getrev(request.pathrev)\n      rev = request.repos._getrev(rev)\n    except vclib.InvalidRevision:\n      raise debug.ViewVCException('Invalid revision', '404 Not Found')\n    return _path_parts(request.repos.get_location(path, pathrev, rev)), rev\n  return _path_parts(path), rev\n\ndef setup_authorizer(cfg, username, rootname=None):\n  \"\"\"Setup the authorizer.  If ROOTNAME is provided, assume that\n  per-root options have not been overlayed.  Otherwise, assume they\n  have (and fetch the authorizer for the configured root).\"\"\"\n  \n  if rootname is None:\n    authorizer = cfg.options.authorizer\n    params = cfg.get_authorizer_params()\n  else:\n    authorizer, params = cfg.get_authorizer_and_params_hack(rootname)\n\n  # No configured authorizer?  No problem.\n  if not authorizer:\n    return None\n\n  # First, try to load a module with the configured name.\n  import imp\n  fp = None\n  try:\n    try:\n      fp, path, desc = imp.find_module(\"%s\" % (authorizer), vcauth.__path__)\n      my_auth = imp.load_module('viewvc', fp, path, desc)\n    except ImportError:\n      raise debug.ViewVCException(\n        'Invalid authorizer (%s) specified for root \"%s\"' \\\n        % (authorizer, rootname),\n        '500 Internal Server Error')\n  finally:\n    if fp:\n      fp.close()\n\n  # Add a rootname mapping callback function to the parameters.\n  def _root_lookup_func(cb_rootname):\n    return locate_root(cfg, cb_rootname)\n\n  # Finally, instantiate our Authorizer.\n  return my_auth.ViewVCAuthorizer(_root_lookup_func, username, params)\n\ndef check_freshness(request, mtime=None, etag=None, weak=0):\n  cfg = request.cfg\n\n  # See if we are supposed to disable etags (for debugging, usually)\n  if not cfg.options.generate_etags:\n    return 0\n  \n  request_etag = request_mtime = None\n  if etag is not None:\n    if weak:\n      etag = 'W/\"%s\"' % etag\n    else:\n      etag = '\"%s\"' % etag\n    request_etag = request.server.getenv('HTTP_IF_NONE_MATCH')\n  if mtime is not None:\n    try:\n      request_mtime = request.server.getenv('HTTP_IF_MODIFIED_SINCE')\n      request_mtime = rfc822.mktime_tz(rfc822.parsedate_tz(request_mtime))\n    except:\n      request_mtime = None\n\n  # if we have an etag, use that for freshness checking.\n  # if not available, then we use the last-modified time.\n  # if not available, then the document isn't fresh.\n  if etag is not None:\n    isfresh = (request_etag == etag)\n  elif mtime is not None:\n    isfresh = (request_mtime >= mtime)\n  else:\n    isfresh = 0\n\n  # require revalidation after the configured amount of time\n  if cfg and cfg.options.http_expiration_time >= 0:\n    expiration = rfc822.formatdate(time.time() +\n                                   cfg.options.http_expiration_time)\n    request.server.addheader('Expires', expiration)\n    request.server.addheader('Cache-Control',\n                             'max-age=%d' % cfg.options.http_expiration_time)\n\n  if isfresh:\n    request.server.header(status='304 Not Modified')\n  else:\n    if etag is not None:\n      request.server.addheader('ETag', etag)\n    if mtime is not None:\n      request.server.addheader('Last-Modified', rfc822.formatdate(mtime))\n  return isfresh\n\ndef get_view_template(cfg, view_name, language=\"en\"):\n  # See if the configuration specifies a template for this view.  If\n  # not, use the default template path for this view.\n  tname = vars(cfg.templates).get(view_name) or view_name + \".ezt\"\n\n  # Template paths are relative to the configurated template_dir (if\n  # any, \"templates\" otherwise), so build the template path as such.\n  tname = os.path.join(cfg.options.template_dir or \"templates\", tname)\n\n  # Allow per-language template selection.\n  tname = tname.replace('%lang%', language)\n\n  # Finally, construct the whole template path.\n  tname = cfg.path(tname)\n\n  debug.t_start('ezt-parse')\n  template = ezt.Template(tname)\n  debug.t_end('ezt-parse')\n\n  return template\n\ndef get_writeready_server_file(request, content_type=None, encoding=None,\n                               content_length=None, allow_compress=True):\n  \"\"\"Return a file handle to a response body stream, after outputting\n  any queued special headers (on REQUEST.server) and (optionally) a\n  'Content-Type' header whose value is CONTENT_TYPE and character set\n  is ENCODING.\n\n  If CONTENT_LENGTH is provided and compression is not in use, also\n  generate a 'Content-Length' header for this response.\n\n  Callers my use ALLOW_COMPRESS to disable compression where it would\n  otherwise be allowed.  (Such as when transmitting an\n  already-compressed response.)\n\n  After this function is called, it is too late to add new headers to\n  the response.\"\"\"\n\n  if allow_compress and request.gzip_compress_level:\n    request.server.addheader('Content-Encoding', 'gzip')\n  elif content_length is not None:\n    request.server.addheader('Content-Length', content_length)\n  \n  if content_type and encoding:\n    request.server.header(\"%s; charset=%s\" % (content_type, encoding))\n  elif content_type:\n    request.server.header(content_type)\n  else:\n    request.server.header()\n\n  if allow_compress and request.gzip_compress_level:\n    fp = gzip.GzipFile('', 'wb', request.gzip_compress_level,\n                       request.server.file())\n  else:\n    fp = request.server.file()\n  \n  return fp\n  \ndef generate_page(request, view_name, data, content_type=None):\n  server_fp = get_writeready_server_file(request, content_type)\n  template = get_view_template(request.cfg, view_name, request.language)\n  template.generate(server_fp, data)\n\ndef nav_path(request):\n  \"\"\"Return current path as list of items with \"name\" and \"href\" members\n\n  The href members are view_directory links for directories and view_log\n  links for files, but are set to None when the link would point to\n  the current view\"\"\"\n\n  if not request.repos:\n    return []\n\n  is_dir = request.pathtype == vclib.DIR\n\n  # add root item\n  items = []\n  root_item = _item(name=request.server.escape(request.repos.name), href=None)\n  if request.path_parts or request.view_func is not view_directory:\n    root_item.href = request.get_url(view_func=view_directory,\n                                     where='', pathtype=vclib.DIR,\n                                     params={}, escape=1)\n  items.append(root_item)\n\n  # add path part items\n  path_parts = []\n  for part in request.path_parts:\n    path_parts.append(part)\n    is_last = len(path_parts) == len(request.path_parts)\n\n    item = _item(name=request.server.escape(part), href=None)\n\n    if not is_last or (is_dir and request.view_func is not view_directory):\n      item.href = request.get_url(view_func=view_directory,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.DIR,\n                                  params={}, escape=1)\n    elif not is_dir and request.view_func is not view_log:\n      item.href = request.get_url(view_func=view_log,\n                                  where=_path_join(path_parts),\n                                  pathtype=vclib.FILE,\n                                  params={}, escape=1)\n    items.append(item)\n\n  return items\n\ndef prep_tags(request, tags):\n  url, params = request.get_link(params={'pathrev': None})\n  params = urllib.urlencode(params)\n  if params:\n    url = urllib.quote(url, _URL_SAFE_CHARS) + '?' + params + '&pathrev='\n  else:\n    url = urllib.quote(url, _URL_SAFE_CHARS) + '?pathrev='\n  url = request.server.escape(url)\n\n  links = [ ]\n  for tag in tags:\n    links.append(_item(name=tag.name, href=url+tag.name))\n  links.sort(lambda a, b: cmp(a.name, b.name))\n  return links\n\ndef guess_mime(filename):\n  return mimetypes.guess_type(filename)[0]\n\ndef is_viewable_image(mime_type):\n  return mime_type and mime_type in ('image/gif', 'image/jpeg', 'image/png')\n\ndef is_text(mime_type):\n  return not mime_type or mime_type[:5] == 'text/'\n\ndef is_cvsroot_path(roottype, path_parts):\n  return roottype == 'cvs' and path_parts and path_parts[0] == 'CVSROOT'\n\ndef is_plain_text(mime_type):\n  return not mime_type or mime_type == 'text/plain'\n\ndef default_view(mime_type, cfg):\n  \"Determine whether file should be viewed through markup page or sent raw\"\n  # If the mime type is text/anything or a supported image format we view\n  # through the markup page. If the mime type is something else, we send\n  # it directly to the browser. That way users can see things like flash\n  # animations, pdfs, word documents, multimedia, etc, which wouldn't be\n  # very useful marked up. If the mime type is totally unknown (happens when\n  # we encounter an unrecognized file extension) we also view it through\n  # the markup page since that's better than sending it text/plain.\n  if ('markup' in cfg.options.allowed_views and \n      (is_viewable_image(mime_type) or is_text(mime_type))):\n    return view_markup\n  return view_checkout\n\ndef is_binary_file_mime_type(mime_type, cfg):\n  \"\"\"Return True iff MIME_TYPE is set and matches one of the binary\n  file mime type patterns in CFG.\"\"\"\n  if mime_type:\n    for pattern in cfg.options.binary_mime_types:\n      if fnmatch.fnmatch(mime_type, pattern):\n        return True\n  return False\n  \ndef is_dir_ignored_file(file_name, cfg):\n  \"\"\"Return True if FILE_NAME is set and matches one of the file names\n  or extensions to be ignored in directory listing per CFG.\"\"\"\n  if file_name:\n    for pattern in cfg.options.dir_ignored_files:\n      if fnmatch.fnmatch(file_name, pattern):\n        return True\n  return False\n\ndef get_file_view_info(request, where, rev=None, mime_type=None, pathrev=-1):\n  \"\"\"Return an object holding common hrefs and a viewability flag used\n  for various views of FILENAME at revision REV whose MIME type is\n  MIME_TYPE.\n\n  The object's members include:\n     view_href\n     download_href\n     download_text_href\n     annotate_href\n     revision_href\n     prefer_markup\n     is_viewable_image\n     is_binary\n     \n  \"\"\"\n  \n  rev = rev and str(rev) or None\n  mime_type = mime_type or guess_mime(where)\n  if pathrev == -1: # cheesy default value, since we need to preserve None\n    pathrev = request.pathrev\n\n  view_href = None\n  download_href = None\n  download_text_href = None\n  annotate_href = None\n  revision_href = None\n\n  if 'markup' in request.cfg.options.allowed_views:\n    view_href = request.get_url(view_func=view_markup,\n                                where=where,\n                                pathtype=vclib.FILE,\n                                params={'revision': rev,\n                                        'pathrev': pathrev},\n                                escape=1)\n  if 'co' in request.cfg.options.allowed_views:\n    download_href = request.get_url(view_func=view_checkout,\n                                    where=where,\n                                    pathtype=vclib.FILE,\n                                    params={'revision': rev,\n                                            'pathrev': pathrev},\n                                    escape=1)\n    if not is_plain_text(mime_type):\n      download_text_href = request.get_url(view_func=view_checkout,\n                                           where=where,\n                                           pathtype=vclib.FILE,\n                                           params={'content-type': 'text/plain',\n                                                   'revision': rev,\n                                                   'pathrev': pathrev},\n                                           escape=1)\n  if 'annotate' in request.cfg.options.allowed_views:\n    annotate_href = request.get_url(view_func=view_annotate,\n                                    where=where,\n                                    pathtype=vclib.FILE,\n                                    params={'annotate': rev,\n                                            'pathrev': pathrev},\n                                    escape=1)\n  if request.roottype == 'svn':\n    revision_href = request.get_url(view_func=view_revision,\n                                    params={'revision': rev},\n                                    escape=1)\n\n  is_binary_file = is_binary_file_mime_type(mime_type, request.cfg)\n  if is_binary_file:\n    download_text_href = annotate_href = view_href = None\n    prefer_markup = False\n  else:\n    prefer_markup = default_view(mime_type, request.cfg) == view_markup\n\n  return _item(view_href=view_href,\n               download_href=download_href,\n               download_text_href=download_text_href,\n               annotate_href=annotate_href,\n               revision_href=revision_href,\n               prefer_markup=ezt.boolean(prefer_markup),\n               is_viewable_image=ezt.boolean(is_viewable_image(mime_type)),\n               is_binary=ezt.boolean(is_binary_file))\n\n\n# Matches URLs\n_re_rewrite_url = re.compile('((http|https|ftp|file|svn|svn\\+ssh)'\n                             '(://[-a-zA-Z0-9%.~:_/]+)((\\?|\\&)'\n                             '([-a-zA-Z0-9%.~:_]+)=([-a-zA-Z0-9%.~:_])+)*'\n                             '(#([-a-zA-Z0-9%.~:_]+)?)?)')\n# Matches email addresses\n_re_rewrite_email = re.compile('([-a-zA-Z0-9_.\\+]+)@'\n                               '(([-a-zA-Z0-9]+\\.)+[A-Za-z]{2,4})')\n\n# Matches revision references\n_re_rewrite_svnrevref = re.compile(r'\\b(r|rev #?|revision #?)([0-9]+)\\b')\n\nclass ViewVCHtmlFormatterTokens:\n  def __init__(self, tokens):\n    self.tokens = tokens\n\n  def get_result(self, maxlen=0):\n    \"\"\"Format the tokens per the registered set of formatters, and\n    limited to MAXLEN visible characters (or unlimited if MAXLEN is\n    0).  Return a 3-tuple containing the formatted result string, the\n    number of visible characters in the result string, and a boolean\n    flag indicating whether or not S was truncated.\"\"\"\n    out = ''\n    out_len = 0\n    for token in self.tokens:\n      chunk, chunk_len = token.converter(token.match, token.userdata, maxlen)\n      out = out + chunk\n      out_len = out_len + chunk_len\n      if maxlen:\n        maxlen = maxlen - chunk_len\n        if maxlen <= 0:\n          return out, out_len, 1\n    return out, out_len, 0\n\n    \nclass ViewVCHtmlFormatter:\n  \"\"\"Format a string as HTML-encoded output with customizable markup\n  rules, for example turning strings that look like URLs into anchor links.\n\n  NOTE:  While there might appear to be some unused portions of this\n  interface, there is a good chance that there are consumers outside\n  of ViewVC itself that make use of these things.\n  \"\"\"\n  \n  def __init__(self):\n    self._formatters = []\n\n  def format_url(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as\n           linkified URL, with no more than MAXLEN characters in the\n           non-HTML-tag bits.  If MAXLEN is 0, there is no maximum.\n         - the number of non-HTML-tag characters returned.\n    \"\"\"\n    s = mobj.group(0)\n    trunc_s = maxlen and s[:maxlen] or s\n    return '<a href=\"%s\">%s</a>' % (sapi.escape(s),\n                                    sapi.escape(trunc_s)), \\\n           len(trunc_s)\n\n  def format_email(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as\n           linkified email address, with no more than MAXLEN characters\n           in the non-HTML-tag bits.  If MAXLEN is 0, there is no maximum.\n         - the number of non-HTML-tag characters returned.\n    \"\"\"\n    s = mobj.group(0)\n    trunc_s = maxlen and s[:maxlen] or s\n    return '<a href=\"mailto:%s\">%s</a>' % (urllib.quote(s),\n                                           self._entity_encode(trunc_s)), \\\n           len(trunc_s)\n\n  def format_email_obfuscated(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as an\n           entity-encoded email address, with no more than MAXLEN characters\n           in the non-HTML-tag bits.  If MAXLEN is 0, there is no maximum.\n         - the number of non-HTML-tag characters returned.\n    \"\"\"    \n    s = mobj.group(0)\n    trunc_s = maxlen and s[:maxlen] or s\n    return self._entity_encode(trunc_s), len(trunc_s)\n\n  def format_email_truncated(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as an\n           HTML-escaped truncated email address of no more than MAXLEN\n           characters.  If MAXLEN is 0, there is no maximum.\n         - the number of characters returned.\n    \"\"\"\n    s = mobj.group(1)\n    s_len = len(s)\n    if (maxlen == 0) or (s_len < (maxlen - 1)):\n      return self._entity_encode(s) + '&#64;&hellip;', s_len + 2\n    elif s_len < maxlen:\n      return self._entity_encode(s) + '&#64;', s_len + 1\n    else:\n      trunc_s = mobj.group(1)[:maxlen]\n      return self._entity_encode(trunc_s), len(trunc_s)\n\n  def format_svnrevref(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as an\n           linkified URL to a ViewVC Subversion revision view, with no\n           more than MAXLEN characters in the non-HTML-tag portions.\n           If MAXLEN is 0, there is no maximum.\n         - the number of characters returned.\n\n       USERDATA is a function that accepts a revision reference\n       and returns a URL to that revision.\n    \"\"\"\n    s = mobj.group(0)\n    revref = mobj.group(2)\n    trunc_s = maxlen and s[:maxlen] or s\n    revref_url = userdata(revref)\n    return '<a href=\"%s\">%s</a>' % (sapi.escape(revref_url),\n                                    sapi.escape(trunc_s)), \\\n           len(trunc_s)\n\n  def format_custom_url(self, mobj, userdata, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text represented by MatchObject MOBJ, formatted as an\n           linkified URL created by substituting match groups 0-9 into\n           USERDATA (which is a format string that uses \\N to\n           represent the substitution locations) and with no more than\n           MAXLEN characters in the non-HTML-tag portions.  If MAXLEN\n           is 0, there is no maximum.\n         - the number of characters returned.\n    \"\"\"\n    format = userdata\n    text = mobj.group(0)\n    url = format\n    for i in range(9):\n      try:\n        repl = mobj.group(i)\n      except:\n        repl = ''\n      url = url.replace('\\%d' % (i), repl)\n    trunc_s = maxlen and text[:maxlen] or text\n    return '<a href=\"%s\">%s</a>' % (sapi.escape(url),\n                                    sapi.escape(trunc_s)), \\\n           len(trunc_s)\n\n  def format_text(self, s, unused, maxlen=0):\n    \"\"\"Return a 2-tuple containing:\n         - the text S, HTML-escaped, containing no more than MAXLEN\n           characters.  If MAXLEN is 0, there is no maximum.\n         - the number of characters returned.\n    \"\"\"   \n    trunc_s = maxlen and s[:maxlen] or s\n    return sapi.escape(trunc_s), len(trunc_s)\n  \n  def add_formatter(self, regexp, conv, userdata=None):\n    \"\"\"Register a formatter which finds instances of strings matching\n    REGEXP, and using the function CONV and USERDATA to format them.\n\n    CONV is a function which accepts three parameters:\n      - the MatchObject which holds the string portion to be formatted,\n      - the USERDATA object,\n      - the maximum number of characters from that string to use for\n        human-readable output (or 0 to indicate no maximum).\n    \"\"\"\n    if type(regexp) == type(''):\n      regexp = re.compile(regexp)\n    self._formatters.append([regexp, conv, userdata])\n\n  def get_result(self, s, maxlen=0):\n    \"\"\"Format S per the set of formatters registered with this object,\n    and limited to MAXLEN visible characters (or unlimited if MAXLEN\n    is 0).  Return a 3-tuple containing the formatted result string,\n    the number of visible characters in the result string, and a\n    boolean flag indicating whether or not S was truncated.\n    \"\"\"\n    return self.tokenize_text(s).get_result(maxlen)\n\n  def tokenize_text(self, s):\n    \"\"\"Return a ViewVCHtmlFormatterTokens object containing the tokens\n    created when parsing the string S.  Callers can use that object's\n    get_result() function to retrieve HTML-formatted text.\n    \"\"\"\n    tokens = []\n    # We could just have a \"while s:\" here instead of \"for line: while\n    # line:\", but for really large log messages with heavy\n    # tokenization, the cost in both performance and memory\n    # consumption of the approach taken was atrocious.\n    for line in s.replace('\\r\\n', '\\n').split('\\n'):\n      line = line + '\\n'\n      while line:\n        best_match = best_conv = best_userdata = None\n        for test in self._formatters:\n          match = test[0].search(line)\n          # If we find and match and (a) its our first one, or (b) it\n          # matches text earlier than our previous best match, or (c) it\n          # matches text at the same location as our previous best match\n          # but extends to cover more text than that match, then this is\n          # our new best match.\n          #\n          # Implied here is that when multiple formatters match exactly\n          # the same text, the first formatter in the registration list wins.\n          if match \\\n             and ((best_match is None) \\\n                  or (match.start() < best_match.start())\n                  or ((match.start() == best_match.start()) \\\n                      and (match.end() > best_match.end()))):\n            best_match = match\n            best_conv = test[1]\n            best_userdata = test[2]\n        # If we found a match...\n        if best_match:\n          # ... add any non-matching stuff first, then the matching bit.\n          start = best_match.start()\n          end = best_match.end()\n          if start > 0:\n            tokens.append(_item(match=line[:start],\n                                converter=self.format_text,\n                                userdata=None))\n          tokens.append(_item(match=best_match,\n                              converter=best_conv,\n                              userdata=best_userdata))\n          line = line[end:]\n        else:\n          # Otherwise, just add the rest of the string.\n          tokens.append(_item(match=line,\n                              converter=self.format_text,\n                              userdata=None))\n          line = ''\n    return ViewVCHtmlFormatterTokens(tokens)\n\n  def _entity_encode(self, s):\n    return ''.join(map(lambda x: '&#%d;' % (ord(x)), s))\n\n\nclass LogFormatter:\n  def __init__(self, request, log):\n    self.request = request\n    self.log = log or ''\n    self.tokens = None\n    self.cache = {}  # (maxlen, htmlize) => resulting_log\n\n  def get(self, maxlen=0, htmlize=1):\n    cfg = self.request.cfg\n    \n    # Prefer the cache.\n    if self.cache.has_key((maxlen, htmlize)):\n      return self.cache[(maxlen, htmlize)]\n    \n    # If we are HTML-izing...\n    if htmlize:\n      # ...and we don't yet have ViewVCHtmlFormatter() object tokens...\n      if not self.tokens:\n        # ... then get them.\n        lf = ViewVCHtmlFormatter()\n\n        # Rewrite URLs.\n        lf.add_formatter(_re_rewrite_url, lf.format_url)\n\n        # Rewrite Subversion revision references.\n        if self.request.roottype == 'svn':\n          def revision_to_url(rev):\n            return self.request.get_url(view_func=view_revision,\n                                        params={'revision': rev},\n                                        escape=0)\n          lf.add_formatter(_re_rewrite_svnrevref, lf.format_svnrevref,\n                           revision_to_url)\n\n        # Rewrite email addresses.\n        if cfg.options.mangle_email_addresses == 2:\n          lf.add_formatter(_re_rewrite_email, lf.format_email_truncated)\n        elif cfg.options.mangle_email_addresses == 1:\n          lf.add_formatter(_re_rewrite_email, lf.format_email_obfuscated)\n        else:\n          lf.add_formatter(_re_rewrite_email, lf.format_email)\n\n        # Add custom rewrite handling per configuration.\n        for rule in cfg.options.custom_log_formatting:\n          rule = rule.replace('\\\\:', '\\x01')          \n          regexp, format = map(lambda x: x.strip(), rule.split(':', 1))\n          regexp = regexp.replace('\\x01', ':')\n          format = format.replace('\\x01', ':')\n          lf.add_formatter(re.compile(regexp), lf.format_custom_url, format)\n\n        # Tokenize the log message.\n        self.tokens = lf.tokenize_text(self.log)\n\n      # Use our formatter to ... you know ... format.\n      log, log_len, truncated = self.tokens.get_result(maxlen)\n      result_log = log + (truncated and '&hellip;' or '')\n\n    # But if we're not HTML-izing...\n    else:\n      # ...then do much more simplistic transformations as necessary.\n      log = self.log\n      if cfg.options.mangle_email_addresses == 2:\n        log = re.sub(_re_rewrite_email, r'\\1@...', log)\n      result_log = maxlen and log[:maxlen] or log\n\n    # In either case, populate the cache and return the results.\n    self.cache[(maxlen, htmlize)] = result_log\n    return result_log\n\n\n_time_desc = {\n         1 : 'second',\n        60 : 'minute',\n      3600 : 'hour',\n     86400 : 'day',\n    604800 : 'week',\n   2628000 : 'month',\n  31536000 : 'year',\n  }\n\ndef get_time_text(request, interval, num):\n  \"Get some time text, possibly internationalized.\"\n  ### some languages have even harder pluralization rules. we'll have to\n  ### deal with those on demand\n  if num == 0:\n    return ''\n  text = _time_desc[interval]\n  if num == 1:\n    attr = text + '_singular'\n    fmt = '%d ' + text\n  else:\n    attr = text + '_plural'\n    fmt = '%d ' + text + 's'\n  try:\n    fmt = getattr(request.kv.i18n.time, attr)\n  except AttributeError:\n    pass\n  return fmt % num\n\ndef little_time(request):\n  try:\n    return request.kv.i18n.time.little_time\n  except AttributeError:\n    return 'very little time'\n\ndef html_time(request, secs, extended=0):\n  secs = long(time.time()) - secs\n  if secs < 2:\n    return little_time(request)\n  breaks = _time_desc.keys()\n  breaks.sort()\n  i = 0\n  while i < len(breaks):\n    if secs < 2 * breaks[i]:\n      break\n    i = i + 1\n  value = breaks[i - 1]\n  s = get_time_text(request, value, secs / value)\n\n  if extended and i > 1:\n    secs = secs % value\n    value = breaks[i - 2]\n    ext = get_time_text(request, value, secs / value)\n    if ext:\n      ### this is not i18n compatible. pass on it for now\n      s = s + ', ' + ext\n  return s\n\ndef common_template_data(request, revision=None, mime_type=None):\n  \"\"\"Return a TemplateData instance with data dictionary items\n  common to most ViewVC views.\"\"\"\n  \n  cfg = request.cfg\n\n  # Initialize data dictionary members (sorted alphanumerically)\n  data = TemplateData({\n    'annotate_href' : None,\n    'cfg' : cfg,\n    'docroot' : cfg.options.docroot is None \\\n                and request.script_name + '/' + docroot_magic_path \\\n                or cfg.options.docroot,\n    'download_href' : None,\n    'download_text_href' : None,\n    'graph_href': None,\n    'home_href': request.script_name or '/',\n    'kv'  : request.kv,\n    'lockinfo' : None,\n    'log_href' : None,\n    'nav_path' : nav_path(request),\n    'pathtype' : None,\n    'prefer_markup' : ezt.boolean(0),\n    'queryform_href' : None,\n    'rev'      : None,\n    'revision_href' : None,\n    'rootname' : request.rootname \\\n                 and request.server.escape(request.rootname) or None,\n    'rootpath' : request.rootpath,\n    'roots_href' : None,\n    'roottype' : request.roottype,\n    'rss_href' : None,\n    'tarball_href' : None,\n    'up_href'  : None,\n    'username' : request.username,\n    'view'     : _view_codes[request.view_func],\n    'view_href' : None,\n    'vsn' : __version__,\n    'where' : request.server.escape(request.where),\n  })\n\n  rev = revision\n  if not rev:\n    rev = request.query_dict.get('annotate')\n  if not rev:\n    rev = request.query_dict.get('revision')\n  if not rev and request.roottype == 'svn':\n    rev = request.query_dict.get('pathrev')\n  try:\n    data['rev'] = hasattr(request.repos, '_getrev') \\\n                  and request.repos._getrev(rev) or rev\n  except vclib.InvalidRevision:\n    raise debug.ViewVCException('Invalid revision', '404 Not Found')\n\n  if request.pathtype == vclib.DIR:\n    data['pathtype'] = 'dir'\n  elif request.pathtype == vclib.FILE:\n    data['pathtype'] = 'file'\n\n  if request.path_parts:\n    dir = _path_join(request.path_parts[:-1])\n    data['up_href'] = request.get_url(view_func=view_directory,\n                                      where=dir, pathtype=vclib.DIR,\n                                      params={}, escape=1)\n\n  if 'roots' in cfg.options.allowed_views:\n    data['roots_href'] = request.get_url(view_func=view_roots,\n                                         escape=1, params={})\n\n  if request.pathtype == vclib.FILE:\n    fvi = get_file_view_info(request, request.where, data['rev'], mime_type)\n    data['view_href'] = fvi.view_href\n    data['download_href'] = fvi.download_href\n    data['download_text_href'] = fvi.download_text_href\n    data['annotate_href'] = fvi.annotate_href\n    data['revision_href'] = fvi.revision_href\n    data['prefer_markup'] = fvi.prefer_markup\n    data['log_href'] = request.get_url(view_func=view_log, params={}, escape=1)\n    if request.roottype == 'cvs' and cfg.options.use_cvsgraph:\n      data['graph_href'] = request.get_url(view_func=view_cvsgraph,\n                                           params={}, escape=1)\n    file_data = request.repos.listdir(request.path_parts[:-1],\n                                      request.pathrev, {})\n    def _only_this_file(item):\n      return item.name == request.path_parts[-1]\n    entries = filter(_only_this_file, file_data)\n    if len(entries) == 1:\n      request.repos.dirlogs(request.path_parts[:-1], request.pathrev,\n                            entries, {})\n      data['lockinfo'] = entries[0].lockinfo\n  elif request.pathtype == vclib.DIR:\n    data['view_href'] = request.get_url(view_func=view_directory,\n                                       params={}, escape=1)\n    if 'tar' in cfg.options.allowed_views:\n      data['tarball_href'] = request.get_url(view_func=download_tarball, \n                                             params={},\n                                             escape=1)\n    if request.roottype == 'svn':\n      data['revision_href'] = request.get_url(view_func=view_revision,\n                                              params={'revision': data['rev']},\n                                              escape=1)\n\n      data['log_href'] = request.get_url(view_func=view_log,\n                                         params={}, escape=1)\n\n  if is_querydb_nonempty_for_root(request):\n    if request.pathtype == vclib.DIR:\n      params = {}\n      if request.roottype == 'cvs' and request.pathrev:\n        params['branch'] = request.pathrev\n      data['queryform_href'] = request.get_url(view_func=view_queryform,\n                                               params=params,\n                                               escape=1)\n      data['rss_href'] = request.get_url(view_func=view_query,\n                                         params={'date': 'month',\n                                                 'format': 'rss'},\n                                         escape=1)\n    elif request.pathtype == vclib.FILE:\n      parts = _path_parts(request.where)\n      where = _path_join(parts[:-1])\n      data['rss_href'] = request.get_url(view_func=view_query,\n                                         where=where,\n                                         pathtype=request.pathtype,\n                                         params={'date': 'month',\n                                                 'format': 'rss',\n                                                 'file': parts[-1],\n                                                 'file_match': 'exact'},\n                                         escape=1)\n  return data\n\ndef retry_read(src, reqlen=CHUNK_SIZE):\n  while 1:\n    chunk = src.read(CHUNK_SIZE)\n    if not chunk:\n      # need to check for eof methods because the cStringIO file objects\n      # returned by ccvs don't provide them\n      if hasattr(src, 'eof') and src.eof() is None:\n        time.sleep(1)\n        continue\n    return chunk\n  \ndef copy_stream(src, dst, htmlize=0):\n  while 1:\n    chunk = retry_read(src)\n    if not chunk:\n      break\n    if htmlize:\n      chunk = sapi.escape(chunk)\n    dst.write(chunk)\n\nclass MarkupPipeWrapper:\n  \"\"\"An EZT callback that outputs a filepointer, plus some optional\n  pre- and post- text.\"\"\"\n\n  def __init__(self, fp, pretext=None, posttext=None, htmlize=0):\n    self.fp = fp\n    self.pretext = pretext\n    self.posttext = posttext\n    self.htmlize = htmlize\n\n  def __call__(self, ctx):\n    if self.pretext:\n      ctx.fp.write(self.pretext)\n    copy_stream(self.fp, ctx.fp, self.htmlize)\n    self.fp.close()\n    if self.posttext:\n      ctx.fp.write(self.posttext)\n\n_re_rewrite_escaped_url = re.compile('((http|https|ftp|file|svn|svn\\+ssh)'\n                                     '(://[-a-zA-Z0-9%.~:_/]+)'\n                                     '((\\?|\\&amp;amp;|\\&amp;|\\&)'\n                                     '([-a-zA-Z0-9%.~:_]+)=([-a-zA-Z0-9%.~:_])+)*'\n                                     '(#([-a-zA-Z0-9%.~:_]+)?)?)')\n\ndef markup_escaped_urls(s):\n  # Return a copy of S with all URL references -- which are expected\n  # to be already HTML-escaped -- wrapped in <a href=\"\"></a>.\n  def _url_repl(match_obj):\n    url = match_obj.group(0)\n    unescaped_url = url.replace(\"&amp;amp;\", \"&amp;\")\n    return \"<a href=\\\"%s\\\">%s</a>\" % (unescaped_url, url)\n  return re.sub(_re_rewrite_escaped_url, _url_repl, s)\n\n\ndef detect_encoding(text_block):\n  \"\"\"Return the encoding used by TEXT_BLOCK as detected by the chardet\n  Python module.  (Currently, this is used only when syntax\n  highlighting is not enabled/available; otherwise, Pygments does this\n  work for us.)\"\"\"\n  \n  # Does the TEXT_BLOCK start with a BOM?\n  for bom, encoding in [('\\xef\\xbb\\xbf', 'utf-8'),\n                        ('\\xff\\xfe', 'utf-16'),\n                        ('\\xfe\\xff', 'utf-16be'),\n                        ('\\xff\\xfe\\0\\0', 'utf-32'),\n                        ('\\0\\0\\xfe\\xff', 'utf-32be'),\n                        ]:\n    if text_block.startswith(bom):\n      return encoding\n\n  # If no recognized BOM, see if chardet can help us.\n  try:\n    import chardet\n\n    # If chardet can confidently claimed a match, we'll use its\n    # findings.  (And if that match is 'ascii' -- which is a subset of\n    # utf-8 -- we'll just call it 'utf-8' and score a zero transform.)\n    resp = chardet.detect(text_block)\n    if resp.get('confidence') == 1.0:\n      encoding = resp.get('encoding')\n      if encoding is \"ascii\":\n        encoding = \"utf-8\"\n      return encoding\n  except:\n    pass\n\n  # By default ... we have no idea.\n  return None\n  \ndef transcode_text(text, encoding=None):\n  \"\"\"If ENCODING is provided and not 'utf-8', transcode TEXT from\n  ENCODING to UTF-8.\"\"\"\n\n  if not encoding or encoding == 'utf-8':\n    return text\n  try:\n    return unicode(text, encoding, 'replace').encode('utf-8', 'replace')\n  except:\n    pass\n  return text\n\ndef markup_file_contents(request, cfg, file_lines, filename,\n                         mime_type, encoding, colorize):\n  # Nothing to mark up?  So be it.\n  if not file_lines:\n    return []\n\n  # Determine if we should (and can) use Pygments to highlight our\n  # output.  Reasons not to include a) being told not to by the\n  # configuration, b) not being able to import the Pygments modules,\n  # and c) Pygments not having a lexer for our file's format.\n  pygments_lexer = None\n  if colorize:\n    from pygments import highlight\n    from pygments.formatters import HtmlFormatter\n    from pygments.lexers import ClassNotFound, \\\n                                get_lexer_by_name, \\\n                                get_lexer_for_mimetype, \\\n                                get_lexer_for_filename, \\\n                                guess_lexer\n    if not encoding:\n      encoding = 'guess'\n      if cfg.options.detect_encoding:\n        try:\n          import chardet\n          encoding = 'chardet'\n        except (SyntaxError, ImportError):\n          pass\n\n    # First, see if there's a Pygments lexer associated with MIME_TYPE.\n    if mime_type:\n      try:\n        pygments_lexer = get_lexer_for_mimetype(mime_type,\n                                                encoding=encoding,\n                                                tabsize=cfg.options.tabsize,\n                                                stripnl=False)\n      except ClassNotFound:\n        pygments_lexer = None\n\n    # If we've no lexer thus far, try to find one based on the FILENAME.\n    if not pygments_lexer:\n      try:\n        pygments_lexer = get_lexer_for_filename(filename,\n                                                encoding=encoding,\n                                                tabsize=cfg.options.tabsize,\n                                                stripnl=False)\n      except ClassNotFound:\n        pygments_lexer = None\n\n    # Still no lexer?  If we've reason to believe this is a text\n    # file, try to guess the lexer based on the file's content.\n    if not pygments_lexer and is_text(mime_type) and file_lines:\n      try:\n        pygments_lexer = guess_lexer(file_lines[0],\n                                     encoding=encoding,\n                                     tabsize=cfg.options.tabsize,\n                                     stripnl=False)\n      except ClassNotFound:\n        pygments_lexer = None\n        \n  # If we aren't highlighting, just return FILE_LINES, corrected for\n  # encoding (if possible).\n  if not pygments_lexer:\n\n    # If allowed by configuration, try to detect the source encoding\n    # for this file.  We'll assemble a block of data from the file\n    # contents to do so... 1024 bytes should be enough.\n    if not encoding and cfg.options.detect_encoding:\n      block_size = 0\n      text_block = ''\n      for i in range(len(file_lines)):\n        text_block = text_block + file_lines[i]\n        if len(text_block) >= 1024:\n          break\n      encoding = detect_encoding(text_block)\n\n    # Built output data comprised of marked-up and possibly-transcoded\n    # source text lines wrapped in (possibly dummy) vclib.Annotation\n    # objects.\n    file_lines = transcode_text(''.join(file_lines), encoding)\n    if file_lines[-1] == '\\n':\n      file_lines = file_lines[:-1]\n    file_lines = file_lines.split('\\n')\n    for i in range(len(file_lines)):\n      line = file_lines[i]\n      if cfg.options.tabsize > 0:\n        line = line.expandtabs(cfg.options.tabsize)\n      file_lines[i] = markup_escaped_urls(sapi.escape(line))\n    return file_lines\n  \n  # If we get here, we're highlighting something.\n  class PygmentsSink:\n    def __init__(self):\n      self.colorized_file_lines = []\n    \n    def write(self, buf):\n      ### FIXME:  Don't bank on write() being called once per line\n      self.colorized_file_lines.append(markup_escaped_urls(buf.rstrip('\\n\\r')))\n\n  ps = PygmentsSink()\n  highlight(''.join(file_lines), pygments_lexer,\n            HtmlFormatter(nowrap=True,\n                          classprefix=\"pygments-\",\n                          encoding='utf-8'), ps)\n  return ps.colorized_file_lines\n\ndef empty_blame_item(line, line_no):\n  blame_item = vclib.Annotation(line, line_no, None, None, None, None)\n  blame_item.diff_href = None\n  return blame_item\n  \ndef merge_blame_data(file_lines, blame_data):\n  errorful = 0\n  if blame_data and (len(file_lines) != len(blame_data)):\n    errorful = 1\n    blame_data = None\n  if not blame_data:\n    new_blame_data = []\n  for i in range(len(file_lines)):\n    line = file_lines[i]\n    if blame_data:\n      blame_data[i].text = line\n    else:\n      new_blame_data.append(empty_blame_item(line, i + 1))\n  return blame_data or new_blame_data, errorful\n  \ndef make_time_string(date, cfg):\n  \"\"\"Returns formatted date string in either local time or UTC.\n\n  The passed in 'date' variable is seconds since epoch.\n\n  \"\"\"\n  if date is None:\n    return None\n  if cfg.options.use_localtime:\n    tm = time.localtime(date)\n  else:\n    tm = time.gmtime(date)\n  if cfg.options.iso8601_timestamps:\n    if cfg.options.use_localtime:\n      if tm[8] and time.daylight:\n        tz = -time.altzone\n      else:\n        tz = -time.timezone\n      if tz < 0:\n        tz = '-%02d:%02d' % (-tz // 3600, (-tz % 3600) // 60)\n      else:\n        tz = '+%02d:%02d' % (tz // 3600, (tz % 3600) // 60)\n    else:\n      tz = 'Z'\n    return time.strftime('%Y-%m-%dT%H:%M:%S', tm) + tz\n  else:\n    return time.asctime(tm) + ' ' + \\\n           (cfg.options.use_localtime and time.tzname[tm[8]] or 'UTC')\n\ndef make_rss_time_string(date, cfg):\n  \"\"\"Returns formatted date string in UTC, formatted for RSS.\n\n  The passed in 'date' variable is seconds since epoch.\n\n  \"\"\"\n  if date is None:\n    return None\n  return time.strftime(\"%a, %d %b %Y %H:%M:%S\", time.gmtime(date)) + ' UTC'\n\ndef make_comma_sep_list_string(items):\n  return ', '.join(map(lambda x: x.name, items))\n\ndef is_undisplayable(val):\n  try:\n    unicode(val)\n    return 0\n  except:\n    return 1\n\ndef get_itemprops(request, path_parts, rev):\n  itemprops = request.repos.itemprops(path_parts, rev)\n  propnames = itemprops.keys()\n  propnames.sort()\n  props = []\n  for name in propnames:\n    # skip non-utf8 property names\n    if is_undisplayable(name):\n      continue\n    lf = LogFormatter(request, itemprops[name])\n    value = lf.get(maxlen=0, htmlize=1)\n    undisplayable = is_undisplayable(value)\n    if undisplayable:\n      value = None\n    props.append(_item(name=name, value=value,\n                       undisplayable=ezt.boolean(undisplayable)))\n  return props\n\ndef parse_mime_type(mime_type):\n  mime_parts = map(lambda x: x.strip(), mime_type.split(';'))\n  type_subtype = mime_parts[0].lower()\n  parameters = {}\n  for part in mime_parts[1:]:\n    name, value = part.split('=', 1)\n    parameters[name] = value\n  return type_subtype, parameters\n  \ndef calculate_mime_type(request, path_parts, rev):\n  \"\"\"Return a 2-tuple carrying the MIME content type and character\n  encoding for the file represented by PATH_PARTS in REV.  Use REQUEST\n  for repository access as necessary.\"\"\"\n  if not path_parts:\n    return None, None\n  mime_type = encoding = None\n  if request.roottype == 'svn' \\\n     and (not request.cfg.options.svn_ignore_mimetype):\n    try:\n      itemprops = request.repos.itemprops(path_parts, rev)\n      mime_type = itemprops.get('svn:mime-type')\n      if mime_type:\n        mime_type, parameters = parse_mime_type(mime_type)\n        return mime_type, parameters.get('charset')\n    except:\n      pass\n  return guess_mime(path_parts[-1]), None\n\ndef assert_viewable_filesize(cfg, filesize):\n  if cfg.options.max_filesize_kbytes \\\n     and filesize != -1 \\\n     and filesize > (1024 * cfg.options.max_filesize_kbytes):\n    raise debug.ViewVCException('Display of files larger than %d KB '\n                                'disallowed by configuration'\n                                % (cfg.options.max_filesize_kbytes),\n                                '403 Forbidden')\n  \ndef markup_or_annotate(request, is_annotate):\n  cfg = request.cfg\n  path, rev = _orig_path(request, is_annotate and 'annotate' or 'revision')\n  lines = fp = image_src_href = None\n  annotation = 'none'\n  revision = None\n  mime_type, encoding = calculate_mime_type(request, path, rev)\n\n  # Is this display blocked by 'binary_mime_types' configuration?\n  if is_binary_file_mime_type(mime_type, cfg):\n    raise debug.ViewVCException('Display of binary file content disabled '\n                                'by configuration', '403 Forbidden')\n    \n  # Is this a viewable image type?\n  if is_viewable_image(mime_type) \\\n     and 'co' in cfg.options.allowed_views:\n    fp, revision = request.repos.openfile(path, rev, {})\n    fp.close()\n    if check_freshness(request, None, revision, weak=1):\n      return\n    if is_annotate:\n      annotation = 'binary'\n    image_src_href = request.get_url(view_func=view_checkout,\n                                     params={'revision': rev}, escape=1)\n\n  # Not a viewable image.\n  else:\n    filesize = request.repos.filesize(path, rev)\n\n    # If configuration disallows display of large files, try to honor\n    # that request.\n    assert_viewable_filesize(cfg, filesize)\n\n    # If this was an annotation request, try to annotate this file.\n    # If something goes wrong, that's okay -- we'll gracefully revert\n    # to a plain markup display.\n    blame_data = None\n    if is_annotate:\n      try:\n        blame_source, revision = request.repos.annotate(path, rev, False)\n        if check_freshness(request, None, revision, weak=1):\n          return\n        # Create BLAME_DATA list from BLAME_SOURCE, adding diff_href\n        # items to each relevant \"line\".\n        blame_data = []\n        for item in blame_source:\n          item.diff_href = None\n          if item.prev_rev:\n            item.diff_href = request.get_url(view_func=view_diff,\n                                             params={'r1': item.prev_rev,\n                                                     'r2': item.rev},\n                                             escape=1, partial=1)\n          blame_data.append(item)\n        annotation = 'annotated'\n      except vclib.NonTextualFileContents:\n        annotation = 'binary'\n      except:\n        annotation = 'error'\n\n    # Grab the file contents.\n    fp, revision = request.repos.openfile(path, rev, {'cvs_oldkeywords' : 1})\n    if check_freshness(request, None, revision, weak=1):\n      fp.close()\n      return\n\n    # If we're limiting by filesize but couldn't pull off the cheap\n    # check above, we'll try to do so line by line here (while\n    # building our file_lines array).\n    if cfg.options.max_filesize_kbytes and filesize == -1:\n      file_lines = []\n      filesize = 0\n      while 1:\n        line = fp.readline()\n        if not line:\n          break\n        filesize = filesize + len(line)\n        assert_viewable_filesize(cfg, filesize)\n        file_lines.append(line)\n    else:\n      file_lines = fp.readlines()\n    fp.close()\n\n    # Try to colorize the file contents.\n    colorize = cfg.options.enable_syntax_coloration\n    try:\n      lines = markup_file_contents(request, cfg, file_lines, path[-1],\n                                   mime_type, encoding, colorize)\n    except:\n      if colorize:\n        lines = markup_file_contents(request, cfg, file_lines, path[-1],\n                                     mime_type, encoding, False)\n      else:\n        raise debug.ViewVCException('Error displaying file contents',\n                                    '500 Internal Server Error')\n\n    # Now, try to match up the annotation data (if any) with the file\n    # lines.\n    lines, errorful = merge_blame_data(lines, blame_data)\n    if errorful:\n      annotation = 'error'\n        \n  data = common_template_data(request, revision, mime_type)\n  data.merge(TemplateData({\n    'mime_type' : mime_type,\n    'log' : None,\n    'date' : None,\n    'ago' : None,\n    'author' : None,\n    'branches' : None,\n    'tags' : None,\n    'branch_points' : None,\n    'changed' : None,\n    'size' : None,\n    'state' : None,\n    'vendor_branch' : None,\n    'prev' : None,\n    'orig_path' : None,\n    'orig_href' : None,\n    'image_src_href' : image_src_href,\n    'lines' : lines,\n    'properties' : get_itemprops(request, path, rev),\n    'annotation' : annotation,\n    }))\n\n  if cfg.options.show_log_in_markup:\n    options = {\n      'svn_latest_log': 1, ### FIXME: Use of this magical value is uncool.\n      'svn_cross_copies': 1,\n      }\n    revs = request.repos.itemlog(path, revision, vclib.SORTBY_REV,\n                                 0, 1, options)\n    entry = revs[-1]\n    lf = LogFormatter(request, entry.log)\n\n    data['date'] = make_time_string(entry.date, cfg)\n    data['author'] = entry.author\n    data['changed'] = entry.changed\n    data['log'] = lf.get(maxlen=0, htmlize=1)\n    data['size'] = entry.size\n\n    if entry.date is not None:\n      data['ago'] = html_time(request, entry.date, 1)\n\n    if request.roottype == 'cvs':\n      branch = entry.branch_number\n      prev = entry.prev or entry.parent\n      data['state'] = entry.dead and 'dead'\n      data['prev'] = prev and prev.string\n      data['vendor_branch'] = ezt.boolean(branch and branch[2] % 2 == 1)\n\n      ### TODO:  Should this be using prep_tags() instead?\n      data['branches'] = make_comma_sep_list_string(entry.branches)\n      data['tags'] = make_comma_sep_list_string(entry.tags)\n      data['branch_points']= make_comma_sep_list_string(entry.branch_points)\n\n  if path != request.path_parts:\n    orig_path = _path_join(path)\n    data['orig_path'] = orig_path\n    data['orig_href'] = request.get_url(view_func=view_log,\n                                        where=orig_path,\n                                        pathtype=vclib.FILE,\n                                        params={'pathrev': revision},\n                                        escape=1)\n    \n  generate_page(request, \"file\", data)\n  \ndef view_markup(request):\n  if 'markup' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Markup view is disabled',\n                                '403 Forbidden')\n  if request.pathtype != vclib.FILE:\n    raise debug.ViewVCException('Unsupported feature: markup view on '\n                                'directory', '400 Bad Request')\n  markup_or_annotate(request, 0)\n\ndef view_annotate(request):\n  if 'annotate' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Annotation view is disabled',\n                                 '403 Forbidden')\n  if request.pathtype != vclib.FILE:\n    raise debug.ViewVCException('Unsupported feature: annotate view on '\n                                'directory', '400 Bad Request')\n  markup_or_annotate(request, 1)\n\ndef revcmp(rev1, rev2):\n  rev1 = map(int, rev1.split('.'))\n  rev2 = map(int, rev2.split('.'))\n  return cmp(rev1, rev2)\n\ndef sort_file_data(file_data, roottype, sortdir, sortby, group_dirs):\n  # convert sortdir into a sign bit\n  s = sortdir == \"down\" and -1 or 1\n\n  # in cvs, revision numbers can't be compared meaningfully between\n  # files, so try to do the right thing and compare dates instead\n  if roottype == \"cvs\" and sortby == \"rev\":\n    sortby = \"date\"\n\n  def file_sort_sortby(file1, file2, sortby):\n    # sort according to sortby\n    if sortby == 'rev':\n      return s * revcmp(file1.rev, file2.rev)\n    elif sortby == 'date':\n      return s * cmp(file2.date, file1.date)        # latest date is first\n    elif sortby == 'log':\n      return s * cmp(file1.log, file2.log)\n    elif sortby == 'author':\n      return s * cmp(file1.author, file2.author)\n    return s * cmp(file1.name, file2.name)\n\n  def file_sort_cmp(file1, file2, sortby=sortby, group_dirs=group_dirs, s=s):\n    # if we're grouping directories together, sorting is pretty\n    # simple.  a directory sorts \"higher\" than a non-directory, and\n    # two directories are sorted as normal.\n    if group_dirs:\n      if file1.kind == vclib.DIR:\n        if file2.kind == vclib.DIR:\n          # two directories, no special handling.\n          return file_sort_sortby(file1, file2, sortby)\n        else:\n          # file1 is a directory, it sorts first.\n          return -1\n      elif file2.kind == vclib.DIR:\n        # file2 is a directory, it sorts first.\n        return 1\n\n    # we should have data on these. if not, then it is because we requested\n    # a specific tag and that tag is not present on the file.\n    if file1.rev is not None and file2.rev is not None:\n      return file_sort_sortby(file1, file2, sortby)\n    elif file1.rev is not None:\n      return -1\n    elif file2.rev is not None:\n      return 1\n\n    # sort by file name\n    return s * cmp(file1.name, file2.name)\n\n  file_data.sort(file_sort_cmp)\n\ndef icmp(x, y):\n  \"\"\"case insensitive comparison\"\"\"\n  return cmp(x.lower(), y.lower())\n\ndef view_roots(request):\n  if 'roots' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Root listing view is disabled',\n                                '403 Forbidden')\n  \n  # add in the roots for the selection\n  roots = []\n  expand_root_parents(request.cfg)\n  allroots = list_roots(request)\n  if len(allroots):\n    rootnames = allroots.keys()\n    rootnames.sort(icmp)\n    for rootname in rootnames:\n      root_path, root_type, lastmod = allroots[rootname]\n      href = request.get_url(view_func=view_directory,\n                             where='', pathtype=vclib.DIR,\n                             params={'root': rootname}, escape=1)\n      if root_type == vclib.SVN:\n        log_href = request.get_url(view_func=view_log,\n                                   where='', pathtype=vclib.DIR,\n                                   params={'root': rootname}, escape=1)\n      else:\n        log_href = None\n      roots.append(_item(name=request.server.escape(rootname),\n                         type=root_type,\n                         path=root_path,\n                         author=lastmod and lastmod.author or None,\n                         ago=lastmod and lastmod.ago or None,\n                         date=lastmod and lastmod.date or None,\n                         log=lastmod and lastmod.log or None,\n                         short_log=lastmod and lastmod.short_log or None,\n                         rev=lastmod and lastmod.rev or None,\n                         href=href,\n                         log_href=log_href))\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'roots' : roots,\n    'roots_shown' : len(roots), \n    }))\n  generate_page(request, \"roots\", data)\n\ndef view_directory(request):\n  cfg = request.cfg\n\n  # For Subversion repositories, the revision acts as a weak validator for\n  # the directory listing (to take into account template changes or\n  # revision property changes).\n  if request.roottype == 'svn':\n    try:\n      rev = request.repos._getrev(request.pathrev)\n    except vclib.InvalidRevision:\n      raise debug.ViewVCException('Invalid revision', '404 Not Found')\n    tree_rev = request.repos.created_rev(request.where, rev)\n    if check_freshness(request, None, str(tree_rev), weak=1):\n      return\n\n  # List current directory\n  options = {}\n  if request.roottype == 'cvs':\n    hideattic = int(request.query_dict.get('hideattic', \n                                           cfg.options.hide_attic))\n    options[\"cvs_subdirs\"] = (cfg.options.show_subdir_lastmod and\n                              cfg.options.show_logs)\n  debug.t_start(\"listdir\")\n  file_data = request.repos.listdir(request.path_parts, request.pathrev,\n                                    options)\n  debug.t_end(\"listdir\")\n\n  # sort with directories first, and using the \"sortby\" criteria\n  sortby = request.query_dict.get('sortby', cfg.options.sort_by) or 'file'\n  sortdir = request.query_dict.get('sortdir', 'up')\n\n  # when paging and sorting by filename, we can greatly improve\n  # performance by \"cheating\" -- first, we sort (we already have the\n  # names), then we just fetch dirlogs for the needed entries.\n  # however, when sorting by other properties or not paging, we've no\n  # choice but to fetch dirlogs for everything.\n  debug.t_start(\"dirlogs\")\n  if cfg.options.dir_pagesize and sortby == 'file':\n    dirlogs_first = int(request.query_dict.get('dir_pagestart', 0))\n    if dirlogs_first > len(file_data):\n      dirlogs_first = 0\n    dirlogs_last = dirlogs_first + cfg.options.dir_pagesize\n    for file in file_data:\n      file.rev = None\n      file.date = None\n      file.log = None\n      file.author = None\n      file.size = None\n      file.lockinfo = None\n      file.dead = None\n    sort_file_data(file_data, request.roottype, sortdir, sortby,\n                   cfg.options.sort_group_dirs)\n    # request dirlogs only for the slice of files in \"this page\"\n    request.repos.dirlogs(request.path_parts, request.pathrev,\n                          file_data[dirlogs_first:dirlogs_last], options)\n  else:\n    request.repos.dirlogs(request.path_parts, request.pathrev,\n                          file_data, options)\n    sort_file_data(file_data, request.roottype, sortdir, sortby,\n                   cfg.options.sort_group_dirs)\n  debug.t_end(\"dirlogs\")\n\n  # If a regex is specified, build a compiled form thereof for filtering\n  searchstr = None\n  search_re = request.query_dict.get('search', '')\n  if cfg.options.use_re_search and search_re:\n    searchstr = re.compile(search_re)\n\n  # loop through entries creating rows and changing these values\n  rows = [ ]\n  dirs_displayed = files_displayed = 0\n  num_dead = 0\n  \n  # set some values to be used inside loop\n  where = request.where\n  where_prefix = where and where + '/'\n\n  debug.t_start(\"row-building\")\n  for file in file_data:\n    if is_dir_ignored_file(file.name, cfg):\n      continue\n    row = _item(author=None, log=None, short_log=None, state=None, size=None,\n                log_file=None, log_rev=None, graph_href=None, mime_type=None,\n                date=None, ago=None, view_href=None, log_href=None,\n                revision_href=None, annotate_href=None, download_href=None,\n                download_text_href=None, prefer_markup=ezt.boolean(0),\n                is_viewable_image=ezt.boolean(0), is_binary=ezt.boolean(0))\n    if request.roottype == 'cvs' and file.absent:\n      continue\n    if cfg.options.hide_errorful_entries and file.errors:\n      continue\n    row.rev = file.rev\n    row.author = file.author\n    row.state = (request.roottype == 'cvs' and file.dead) and 'dead' or ''\n    if file.date is not None:\n      row.date = make_time_string(file.date, cfg)\n      row.ago = html_time(request, file.date)\n    if cfg.options.show_logs:\n      debug.t_start(\"dirview_logformat\")\n      lf = LogFormatter(request, file.log)\n      row.log = lf.get(maxlen=0, htmlize=1)\n      row.short_log = lf.get(maxlen=cfg.options.short_log_len, htmlize=1)\n      debug.t_end(\"dirview_logformat\")\n    row.lockinfo = file.lockinfo\n    row.anchor = request.server.escape(file.name)\n    row.name = request.server.escape(file.name)\n    row.pathtype = (file.kind == vclib.FILE and 'file') or \\\n                   (file.kind == vclib.DIR and 'dir')\n    row.errors = file.errors\n\n    if file.kind == vclib.DIR:\n      if cfg.options.hide_cvsroot \\\n         and is_cvsroot_path(request.roottype,\n                             request.path_parts + [file.name]):\n        continue\n    \n      dirs_displayed += 1\n\n      row.view_href = request.get_url(view_func=view_directory,\n                                      where=where_prefix+file.name,\n                                      pathtype=vclib.DIR,\n                                      params={},\n                                      escape=1)\n\n      if request.roottype == 'svn':\n        row.revision_href = request.get_url(view_func=view_revision,\n                                            params={'revision': file.rev},\n                                            escape=1)\n\n      if request.roottype == 'cvs' and file.rev is not None:\n        row.rev = None\n        if cfg.options.show_logs:\n          row.log_file = request.server.escape(file.newest_file)\n          row.log_rev = file.rev\n\n      if request.roottype == 'svn':\n        row.log_href = request.get_url(view_func=view_log,\n                                       where=where_prefix + file.name,\n                                       pathtype=vclib.DIR,\n                                       params={},\n                                       escape=1)\n      \n    elif file.kind == vclib.FILE:\n      if searchstr is not None:\n        if request.roottype == 'cvs' and (file.errors or file.dead):\n          continue\n        if not search_file(request.repos, request.path_parts + [file.name],\n                           request.pathrev, searchstr):\n          continue\n      if request.roottype == 'cvs' and file.dead:\n        num_dead = num_dead + 1\n        if hideattic:\n          continue\n        \n      files_displayed += 1\n\n      file_where = where_prefix + file.name\n      if request.roottype == 'svn': \n        row.size = file.size\n\n      row.mime_type, encoding = calculate_mime_type(request,\n                                                    _path_parts(file_where),\n                                                    file.rev)\n      fvi = get_file_view_info(request, file_where, file.rev, row.mime_type)\n      row.view_href = fvi.view_href\n      row.download_href = fvi.download_href\n      row.download_text_href = fvi.download_text_href\n      row.annotate_href = fvi.annotate_href\n      row.revision_href = fvi.revision_href\n      row.prefer_markup = fvi.prefer_markup\n      row.is_viewable_image = fvi.is_viewable_image\n      row.is_binary = fvi.is_binary\n      row.log_href = request.get_url(view_func=view_log,\n                                     where=file_where,\n                                     pathtype=vclib.FILE,\n                                     params={},\n                                     escape=1)\n      if cfg.options.use_cvsgraph and request.roottype == 'cvs':\n         row.graph_href = request.get_url(view_func=view_cvsgraph,\n                                          where=file_where,\n                                          pathtype=vclib.FILE,\n                                          params={},\n                                          escape=1)\n\n    rows.append(row)\n  debug.t_end(\"row-building\")\n\n  # Prepare the data that will be passed to the template, based on the\n  # common template data.\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'entries' : rows,\n    'sortby' : sortby,\n    'sortdir' : sortdir,\n    'search_re' : request.server.escape(search_re),\n    'dir_pagestart' : None,\n    'sortby_file_href' :   request.get_url(params={'sortby': 'file',\n                                                   'sortdir': None},\n                                           escape=1),\n    'sortby_rev_href' :    request.get_url(params={'sortby': 'rev',\n                                                   'sortdir': None},\n                                           escape=1),\n    'sortby_date_href' :   request.get_url(params={'sortby': 'date',\n                                                   'sortdir': None},\n                                           escape=1),\n    'sortby_author_href' : request.get_url(params={'sortby': 'author',\n                                                   'sortdir': None},\n                                           escape=1),\n    'sortby_log_href' :    request.get_url(params={'sortby': 'log',\n                                                   'sortdir': None},\n                                           escape=1),\n    'files_shown' : files_displayed,\n    'dirs_shown' : dirs_displayed,\n    'num_dead' : num_dead,\n    'youngest_rev' : None,\n    'youngest_rev_href' : None,\n    'selection_form' : None,\n    'attic_showing' : None,\n    'show_attic_href' : None,\n    'hide_attic_href' : None,\n    'branch_tags': None,\n    'plain_tags': None,\n    'properties': get_itemprops(request, request.path_parts, request.pathrev),\n    'tree_rev' : None,\n    'tree_rev_href' : None,\n    'dir_paging_action' : None,\n    'dir_paging_hidden_values' : [],\n    'search_re_action' : None,\n    'search_re_hidden_values' : [],\n\n    # Populated by paging()/paging_sws()\n    'picklist' : [],\n    'picklist_len' : 0,\n\n    # Populated by pathrev_form()\n    'pathrev_action' : None,\n    'pathrev_hidden_values' : [],\n    'pathrev_clear_action' : None,\n    'pathrev_clear_hidden_values' : [],\n    'pathrev' : None,\n    'lastrev' : None,\n  }))\n\n  # clicking on sort column reverses sort order\n  if sortdir == 'down':\n    revsortdir = None # 'up'\n  else:\n    revsortdir = 'down'\n  if sortby in ['file', 'rev', 'date', 'log', 'author']:\n    data['sortby_%s_href' % sortby] = request.get_url(params={'sortdir':\n                                                              revsortdir},\n                                                      escape=1)\n  # CVS doesn't support sorting by rev\n  if request.roottype == \"cvs\":\n    data['sortby_rev_href'] = None\n\n  # set cvs-specific fields\n  if request.roottype == 'cvs':\n    plain_tags = options['cvs_tags']\n    plain_tags.sort(icmp)\n    plain_tags.reverse()\n    data['plain_tags'] = []\n    for plain_tag in plain_tags:\n      data['plain_tags'].append(_item(name=plain_tag, revision=None))\n\n    branch_tags = options['cvs_branches']\n    branch_tags.sort(icmp)\n    branch_tags.reverse()\n    data['branch_tags'] = []\n    for branch_tag in branch_tags:\n      data['branch_tags'].append(_item(name=branch_tag, revision=None))\n    \n    data['attic_showing'] = ezt.boolean(not hideattic)\n    data['show_attic_href'] = request.get_url(params={'hideattic': 0},\n                                              escape=1)\n    data['hide_attic_href'] = request.get_url(params={'hideattic': 1},\n                                              escape=1)\n\n  # set svn-specific fields\n  elif request.roottype == 'svn':\n    data['tree_rev'] = tree_rev\n    data['tree_rev_href'] = request.get_url(view_func=view_revision,\n                                            params={'revision': tree_rev},\n                                            escape=1)\n    data['youngest_rev'] = request.repos.get_youngest_revision()\n    data['youngest_rev_href'] = request.get_url(view_func=view_revision,\n                                                params={},\n                                                escape=1)\n\n  if cfg.options.dir_pagesize:\n    data['dir_paging_action'], data['dir_paging_hidden_values'] = \\\n      request.get_form(params={'dir_pagestart': None})\n\n  pathrev_form(request, data)\n\n  if cfg.options.use_re_search:\n    data['search_re_action'], data['search_re_hidden_values'] = \\\n      request.get_form(params={'search': None})\n\n  if cfg.options.dir_pagesize:\n    data['dir_pagestart'] = int(request.query_dict.get('dir_pagestart',0))\n    data['entries'] = paging(data, 'entries', data['dir_pagestart'], 'name',\n                             cfg.options.dir_pagesize)\n\n  generate_page(request, \"directory\", data)\n\ndef paging(data, key, pagestart, local_name, pagesize):\n  # Implement paging\n  # Create the picklist\n  picklist = data['picklist'] = []\n  for i in range(0, len(data[key]), pagesize):\n    pick = _item(start=None, end=None, count=None, more=ezt.boolean(0))\n    pick.start = getattr(data[key][i], local_name)\n    pick.count = i\n    pick.page = (i / pagesize) + 1\n    try:\n      pick.end = getattr(data[key][i+pagesize-1], local_name)\n    except IndexError:\n      pick.end = getattr(data[key][-1], local_name)\n    picklist.append(pick)\n  data['picklist_len'] = len(picklist)\n  # Need to fix\n  # pagestart can be greater than the length of data[key] if you\n  # select a tag or search while on a page other than the first.\n  # Should reset to the first page, this test won't do that every\n  # time that it is needed.\n  # Problem might go away if we don't hide non-matching files when\n  # selecting for tags or searching.\n  if pagestart > len(data[key]):\n    pagestart = 0\n  pageend = pagestart + pagesize\n  # Slice\n  return data[key][pagestart:pageend]\n\ndef paging_sws(data, key, pagestart, local_name, pagesize,\n               extra_pages, offset):\n  \"\"\"Implement sliding window-style paging.\"\"\"\n  # Create the picklist\n  last_requested = pagestart + (extra_pages * pagesize)\n  picklist = data['picklist'] = []\n  has_more = ezt.boolean(0)\n  for i in range(0, len(data[key]), pagesize):\n    pick = _item(start=None, end=None, count=None, more=ezt.boolean(0))\n    pick.start = getattr(data[key][i], local_name)\n    pick.count = offset + i\n    pick.page = (pick.count / pagesize) + 1\n    try:\n      pick.end = getattr(data[key][i+pagesize-1], local_name)\n    except IndexError:\n      pick.end = getattr(data[key][-1], local_name)   \n    picklist.append(pick)\n    if pick.count >= last_requested:\n      pick.more = ezt.boolean(1)\n      break\n  data['picklist_len'] = len(picklist)\n  first = pagestart - offset\n  # FIXME: first can be greater than the length of data[key] if\n  # you select a tag or search while on a page other than the first.\n  # Should reset to the first page, but this test won't do that every\n  # time that it is needed.  Problem might go away if we don't hide\n  # non-matching files when selecting for tags or searching.\n  if first > len(data[key]):\n    pagestart = 0\n  pageend = first + pagesize\n  # Slice\n  return data[key][first:pageend]\n\ndef pathrev_form(request, data):\n  lastrev = None\n\n  if request.roottype == 'svn':\n    data['pathrev_action'], data['pathrev_hidden_values'] = \\\n      request.get_form(view_func=redirect_pathrev,\n                       params={'pathrev': None,\n                               'orig_path': request.where,\n                               'orig_pathtype': request.pathtype,\n                               'orig_pathrev': request.pathrev,\n                               'orig_view': _view_codes.get(request.view_func)})\n\n    if request.pathrev:\n      youngest = request.repos.get_youngest_revision()\n      lastrev = request.repos.last_rev(request.where, request.pathrev,\n                                       youngest)[0]\n\n      if lastrev == youngest:\n        lastrev = None\n\n  data['pathrev'] = request.pathrev\n  data['lastrev'] = lastrev\n\n  action, hidden_values = request.get_form(params={'pathrev': lastrev})\n  if request.roottype != 'svn':\n    data['pathrev_action'] = action\n    data['pathrev_hidden_values'] = hidden_values\n  data['pathrev_clear_action'] = action\n  data['pathrev_clear_hidden_values'] = hidden_values\n\n  return lastrev\n\ndef redirect_pathrev(request):\n  assert request.roottype == 'svn'\n  new_pathrev = request.query_dict.get('pathrev') or None\n  path = request.query_dict.get('orig_path', '')\n  pathtype = request.query_dict.get('orig_pathtype')\n  pathrev = request.query_dict.get('orig_pathrev') \n  view = _views.get(request.query_dict.get('orig_view'))\n  \n  youngest = request.repos.get_youngest_revision()\n\n  # go out of the way to allow revision numbers higher than youngest\n  try:\n    new_pathrev = int(new_pathrev)\n  except ValueError:\n    new_pathrev = youngest\n  except TypeError:\n    pass\n  else:\n    if new_pathrev > youngest:\n      new_pathrev = youngest\n\n  if _repos_pathtype(request.repos, _path_parts(path), new_pathrev):\n    pathrev = new_pathrev\n  else:\n    pathrev, path = request.repos.last_rev(path, pathrev, new_pathrev)\n    # allow clearing sticky revision by submitting empty string\n    if new_pathrev is None and pathrev == youngest:\n      pathrev = None\n\n  request.server.redirect(request.get_url(view_func=view, \n                                          where=path,\n                                          pathtype=pathtype,\n                                          params={'pathrev': pathrev}))\n\ndef view_log(request):\n  cfg = request.cfg\n  diff_format = request.query_dict.get('diff_format', cfg.options.diff_format)\n  pathtype = request.pathtype\n\n  if pathtype is vclib.DIR:\n    if request.roottype == 'cvs':\n      raise debug.ViewVCException('Unsupported feature: log view on CVS '\n                                  'directory', '400 Bad Request')\n    mime_type = encoding = None\n  else:\n    mime_type, encoding = calculate_mime_type(request,\n                                              request.path_parts,\n                                              request.pathrev)\n\n  options = {}\n  options['svn_show_all_dir_logs'] = 1 ### someday make this optional?\n  options['svn_cross_copies'] = cfg.options.cross_copies\n\n  logsort = request.query_dict.get('logsort', cfg.options.log_sort)\n  if request.roottype == \"svn\":\n    sortby = vclib.SORTBY_DEFAULT\n    logsort = None\n  else:\n    if logsort == 'date':\n      sortby = vclib.SORTBY_DATE\n    elif logsort == 'rev':\n      sortby = vclib.SORTBY_REV\n    else:\n      sortby = vclib.SORTBY_DEFAULT\n\n  first = last = 0\n  log_pagestart = None\n  if cfg.options.log_pagesize:\n    log_pagestart = int(request.query_dict.get('log_pagestart', 0))\n    total = cfg.options.log_pagesextra * cfg.options.log_pagesize\n    first = log_pagestart - min(log_pagestart, total)\n    last = log_pagestart + (total + cfg.options.log_pagesize) + 1\n  show_revs = request.repos.itemlog(request.path_parts, request.pathrev,\n                                    sortby, first, last - first, options)\n\n  # selected revision\n  selected_rev = request.query_dict.get('r1')\n\n  entries = [ ]\n  name_printed = { }\n  cvs = request.roottype == 'cvs'\n  for rev in show_revs:\n    entry = _item()\n    entry.rev = rev.string\n    entry.state = (cvs and rev.dead and 'dead')\n    entry.author = rev.author\n    entry.changed = rev.changed\n    entry.date = make_time_string(rev.date, cfg)\n    entry.ago = None\n    if rev.date is not None:\n      entry.ago = html_time(request, rev.date, 1)\n    entry.size = rev.size\n    entry.lockinfo = rev.lockinfo\n    entry.branch_point = None\n    entry.next_main = None\n    entry.orig_path = None\n    entry.copy_path = None\n\n    lf = LogFormatter(request, rev.log or '')\n    entry.log = lf.get(maxlen=0, htmlize=1)\n\n    entry.view_href = None\n    entry.download_href = None\n    entry.download_text_href = None\n    entry.annotate_href = None\n    entry.revision_href = None\n    entry.sel_for_diff_href = None\n    entry.diff_to_sel_href = None\n    entry.diff_to_prev_href = None\n    entry.diff_to_branch_href = None\n    entry.diff_to_main_href = None\n        \n    if request.roottype == 'cvs':\n      prev = rev.prev or rev.parent\n      entry.prev = prev and prev.string\n\n      branch = rev.branch_number\n      entry.vendor_branch = ezt.boolean(branch and branch[2] % 2 == 1)\n\n      entry.branches = prep_tags(request, rev.branches)\n      entry.tags = prep_tags(request, rev.tags)\n      entry.branch_points = prep_tags(request, rev.branch_points)\n\n      entry.tag_names = map(lambda x: x.name, rev.tags)\n      if branch and not name_printed.has_key(branch):\n        entry.branch_names = map(lambda x: x.name, rev.branches)\n        name_printed[branch] = 1\n      else:\n        entry.branch_names = [ ]\n\n      if rev.parent and rev.parent is not prev and not entry.vendor_branch:\n        entry.branch_point = rev.parent.string\n\n      # if it's the last revision on a branch then diff against the\n      # last revision on the higher branch (e.g. change is committed and\n      # brought over to -stable)\n      if not rev.next and rev.parent and rev.parent.next:\n        r = rev.parent.next\n        while r.next:\n          r = r.next\n        entry.next_main = r.string\n\n    elif request.roottype == 'svn':\n      entry.prev = rev.prev and rev.prev.string\n      entry.branches = entry.tags = entry.branch_points = [ ]\n      entry.tag_names = entry.branch_names = [ ]\n      entry.vendor_branch = None\n      if rev.filename != request.where:\n        entry.orig_path = rev.filename\n      entry.copy_path = rev.copy_path\n      entry.copy_rev = rev.copy_rev\n\n      if entry.orig_path:\n        entry.orig_href = request.get_url(view_func=view_log,\n                                          where=entry.orig_path,\n                                          pathtype=vclib.FILE,\n                                          params={'pathrev': rev.string},\n                                          escape=1)\n\n      if rev.copy_path:\n        entry.copy_href = request.get_url(view_func=view_log,\n                                          where=rev.copy_path,\n                                          pathtype=vclib.FILE,\n                                          params={'pathrev': rev.copy_rev},\n                                          escape=1)\n\n\n    # view/download links\n    if pathtype is vclib.FILE:\n      fvi = get_file_view_info(request, request.where, rev.string, mime_type)\n      entry.view_href = fvi.view_href\n      entry.download_href = fvi.download_href\n      entry.download_text_href = fvi.download_text_href\n      entry.annotate_href = fvi.annotate_href\n      entry.revision_href = fvi.revision_href\n      entry.prefer_markup = fvi.prefer_markup\n    else:\n      entry.revision_href = request.get_url(view_func=view_revision,\n                                            params={'revision': rev.string},\n                                            escape=1)\n      entry.view_href = request.get_url(view_func=view_directory,\n                                        where=rev.filename,\n                                        pathtype=vclib.DIR,\n                                        params={'pathrev': rev.string},\n                                        escape=1)\n\n    # calculate diff links\n    if selected_rev != entry.rev:\n      entry.sel_for_diff_href = \\\n        request.get_url(view_func=view_log,\n                        params={'r1': entry.rev,\n                                'log_pagestart': log_pagestart},\n                        escape=1)\n    if entry.prev is not None:\n      entry.diff_to_prev_href = \\\n        request.get_url(view_func=view_diff,\n                        params={'r1': entry.prev,\n                                'r2': entry.rev,\n                                'diff_format': None},\n                        escape=1)\n    if selected_rev and \\\n           selected_rev != str(entry.rev) and \\\n           selected_rev != str(entry.prev) and \\\n           selected_rev != str(entry.branch_point) and \\\n           selected_rev != str(entry.next_main):\n      entry.diff_to_sel_href = \\\n        request.get_url(view_func=view_diff,\n                        params={'r1': selected_rev,\n                                'r2': entry.rev,\n                                'diff_format': None},\n                        escape=1)\n\n    if entry.next_main:\n      entry.diff_to_main_href = \\\n        request.get_url(view_func=view_diff,\n                        params={'r1': entry.next_main,\n                                'r2': entry.rev,\n                                'diff_format': None},\n                        escape=1)\n    if entry.branch_point:\n      entry.diff_to_branch_href = \\\n        request.get_url(view_func=view_diff,\n                        params={'r1': entry.branch_point,\n                                'r2': entry.rev,\n                                'diff_format': None},\n                        escape=1)\n\n    # Save our escaping until the end so stuff above works\n    if entry.orig_path:\n      entry.orig_path = request.server.escape(entry.orig_path)\n    if entry.copy_path:\n      entry.copy_path = request.server.escape(entry.copy_path)\n    entries.append(entry)\n\n  diff_select_action, diff_select_hidden_values = \\\n    request.get_form(view_func=view_diff,\n                     params={'r1': None, 'r2': None, 'tr1': None,\n                             'tr2': None, 'diff_format': None})\n  logsort_action, logsort_hidden_values = \\\n    request.get_form(params={'logsort': None})\n\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'default_branch' : None,\n    'mime_type' : mime_type,\n    'rev_selected' : selected_rev,\n    'diff_format' : diff_format,\n    'logsort' : logsort,\n    'human_readable' : ezt.boolean(diff_format in ('f', 'h', 'l')),\n    'log_pagestart' : None,\n    'log_paging_action' : None,\n    'log_paging_hidden_values' : [],\n    'entries': entries,\n    'head_prefer_markup' : ezt.boolean(0),\n    'head_view_href' : None,\n    'head_download_href': None,\n    'head_download_text_href': None,\n    'head_annotate_href': None,\n    'tag_prefer_markup' : ezt.boolean(0),\n    'tag_view_href' : None,\n    'tag_download_href': None,\n    'tag_download_text_href': None,\n    'tag_annotate_href': None,\n    'diff_select_action' : diff_select_action,\n    'diff_select_hidden_values' : diff_select_hidden_values,\n    'logsort_action' : logsort_action,\n    'logsort_hidden_values' : logsort_hidden_values,\n    'tags' : [],\n    'branch_tags' : [],\n    'plain_tags' : [],\n\n    # Populated by paging()/paging_sws()\n    'picklist' : [],\n    'picklist_len' : 0,\n\n    # Populated by pathrev_form()\n    'pathrev_action' : None,\n    'pathrev_hidden_values' : [],\n    'pathrev_clear_action' : None,\n    'pathrev_clear_hidden_values' : [],\n    'pathrev' : None,\n    'lastrev' : None,\n  }))\n\n  lastrev = pathrev_form(request, data)\n\n  if pathtype is vclib.FILE:\n    if not request.pathrev or lastrev is None:\n      fvi = get_file_view_info(request, request.where, None, mime_type, None)\n      data['head_view_href']= fvi.view_href\n      data['head_download_href']= fvi.download_href\n      data['head_download_text_href']= fvi.download_text_href\n      data['head_annotate_href']= fvi.annotate_href\n      data['head_prefer_markup']= fvi.prefer_markup\n\n    if request.pathrev and request.roottype == 'cvs':\n      fvi = get_file_view_info(request, request.where, None, mime_type)\n      data['tag_view_href']= fvi.view_href\n      data['tag_download_href']= fvi.download_href\n      data['tag_download_text_href']= fvi.download_text_href\n      data['tag_annotate_href']= fvi.annotate_href\n      data['tag_prefer_markup']= fvi.prefer_markup\n  else:\n    data['head_view_href'] = request.get_url(view_func=view_directory, \n                                             params={}, escape=1)\n\n  taginfo = options.get('cvs_tags', {})\n  tagitems = taginfo.items()\n  tagitems.sort()\n  tagitems.reverse()\n\n  main = taginfo.get('MAIN')\n  if main:\n    # Default branch may have multiple names so we list them\n    branches = []\n    for branch in main.aliases:\n      # Don't list MAIN\n      if branch is not main:\n        branches.append(branch)\n    data['default_branch'] = prep_tags(request, branches)\n\n  for tag, rev in tagitems:\n    rev_str = None\n    if rev.number:\n      rev_str = '.'.join(map(str, rev.number))\n\n    if rev.co_rev:\n      data['tags'].append(_item(rev=rev.co_rev.string, name=tag))\n    if rev.is_branch:\n      data['branch_tags'].append(_item(name=tag, revision=rev_str))\n    else:\n      data['plain_tags'].append(_item(name=tag, revision=rev_str))\n\n  if cfg.options.log_pagesize:\n    data['log_paging_action'], data['log_paging_hidden_values'] = \\\n      request.get_form(params={'log_pagestart': None,\n                               'r1': selected_rev,\n                               })\n    data['log_pagestart'] = int(request.query_dict.get('log_pagestart',0))\n    data['entries'] = paging_sws(data, 'entries', data['log_pagestart'],\n                                 'rev', cfg.options.log_pagesize,\n                                 cfg.options.log_pagesextra, first)\n\n  generate_page(request, \"log\", data)\n\ndef view_checkout(request):\n\n  cfg = request.cfg\n  \n  if 'co' not in cfg.options.allowed_views:\n    raise debug.ViewVCException('Checkout view is disabled',\n                                 '403 Forbidden')\n  if request.pathtype != vclib.FILE:\n    raise debug.ViewVCException('Unsupported feature: checkout view on '\n                                'directory', '400 Bad Request')\n\n  path, rev = _orig_path(request)\n  fp, revision = request.repos.openfile(path, rev, {})\n\n  # The revision number acts as a strong validator.\n  if not check_freshness(request, None, revision):\n    mime_type, encoding = calculate_mime_type(request, path, rev)\n    mime_type = request.query_dict.get('content-type') \\\n                or mime_type \\\n                or 'text/plain'\n    server_fp = get_writeready_server_file(request, mime_type, encoding)\n    copy_stream(fp, server_fp)\n  fp.close()\n\ndef cvsgraph_make_reqopt(request, cfgname, queryparam, optvalue):\n  # Return a cvsgraph custom option substring bit OPTVALUE based on\n  # CFGNAME's presence in the allowed list of user-configurable\n  # options and QUERYPARAM's presence and boolean interpretation in\n  # the actual request; otherwise, return the empty string for options\n  # that either aren't overridden or aren't allowed to be overridden.\n  \n  if (cfgname in request.cfg.options.allowed_cvsgraph_useropts) \\\n     and (int(request.query_dict.get(queryparam, 0))):\n    return optvalue\n  return ''\n\ndef cvsgraph_normalize_gshow(request):\n  # Return the effective value of the 'gshow' query parameter, noting\n  # that a missing parameter is the same as gshow=all, and treating a\n  # bogus parameter value as the same as gshow=all, too.\n  gshow = request.query_dict.get('gshow', 'all')\n  if gshow not in ('all', 'inittagged', 'tagged'):\n    gshow = 'all'\n  return gshow\n  \ndef cvsgraph_extraopts(request):\n  # Build a set of -O options for controlling cvsgraph's behavior,\n  # based on what the user has requested and filtered against what the\n  # user is allowed to request.\n  \n  cfg = request.cfg\n\n  ep = '-O'\n\n  # Simple mappings of boolean flags\n  ep = ep + cvsgraph_make_reqopt(request, 'invert', 'gflip',\n                                 ';upside_down=true')\n  ep = ep + cvsgraph_make_reqopt(request, 'branchbox', 'gbbox',\n                                 ';branch_dupbox=true')\n  ep = ep + cvsgraph_make_reqopt(request, 'rotate', 'gleft',\n                                 ';left_right=true')\n\n  # Stripping is a little more complex.\n  if ('show' in request.cfg.options.allowed_cvsgraph_useropts):\n    gshow = cvsgraph_normalize_gshow(request)\n    if gshow == 'inittagged':\n      ep = ep + ';strip_untagged=true'\n    elif gshow == 'tagged':\n      ep = ep + ';strip_untagged=true;strip_first_rev=true'\n\n  # And tag limitation has a user-supplied value to mess with.\n  if ('limittags' in request.cfg.options.allowed_cvsgraph_useropts) \\\n     and request.query_dict.has_key('gmaxtag'):\n    ep = ep + ';rev_maxtags=' + request.query_dict['gmaxtag']\n\n  return ep + ';'\n  \ndef view_cvsgraph_image(request):\n  \"output the image rendered by cvsgraph\"\n  # this function is derived from cgi/cvsgraphmkimg.cgi\n\n  cfg = request.cfg\n\n  if not cfg.options.use_cvsgraph:\n    raise debug.ViewVCException('Graph view is disabled', '403 Forbidden')\n\n  # If cvsgraph can't find its supporting libraries, uncomment and set\n  # accordingly.  Do the same in view_cvsgraph().\n  #os.environ['LD_LIBRARY_PATH'] = '/usr/lib:/usr/local/lib:/path/to/cvsgraph'\n\n  rcsfile = request.repos.rcsfile(request.path_parts)\n  fp = popen.popen(cfg.utilities.cvsgraph or 'cvsgraph',\n                   (\"-c\", cfg.path(cfg.options.cvsgraph_conf),\n                    \"-r\", request.repos.rootpath,\n                    cvsgraph_extraopts(request),\n                    rcsfile), 'rb', 0)\n  \n  copy_stream(fp, get_writeready_server_file(request, 'image/png'))\n  fp.close()\n\ndef view_cvsgraph(request):\n  \"output a page containing an image rendered by cvsgraph\"\n\n  cfg = request.cfg\n\n  if not cfg.options.use_cvsgraph:\n    raise debug.ViewVCException('Graph view is disabled', '403 Forbidden')\n\n  # If cvsgraph can't find its supporting libraries, uncomment and set\n  # accordingly.  Do the same in view_cvsgraph_image().\n  #os.environ['LD_LIBRARY_PATH'] = '/usr/lib:/usr/local/lib:/path/to/cvsgraph'\n\n  imagesrc = request.get_url(view_func=view_cvsgraph_image, escape=1)\n  mime_type = guess_mime(request.where)\n  view = default_view(mime_type, cfg)\n  up_where = _path_join(request.path_parts[:-1])\n\n  # Create an image map\n  rcsfile = request.repos.rcsfile(request.path_parts)\n  fp = popen.popen(cfg.utilities.cvsgraph or 'cvsgraph',\n                   (\"-i\",\n                    \"-c\", cfg.path(cfg.options.cvsgraph_conf),\n                    \"-r\", request.repos.rootpath,\n                    \"-x\", \"x\",\n                    \"-3\", request.get_url(view_func=view_log, params={},\n                                          escape=1),\n                    \"-4\", request.get_url(view_func=view, \n                                          params={'revision': None},\n                                          escape=1, partial=1),\n                    \"-5\", request.get_url(view_func=view_diff,\n                                          params={'r1': None, 'r2': None},\n                                          escape=1, partial=1),\n                    \"-6\", request.get_url(view_func=view_directory,\n                                          where=up_where,\n                                          pathtype=vclib.DIR,\n                                          params={'pathrev': None},\n                                          escape=1, partial=1),\n                    cvsgraph_extraopts(request),\n                    rcsfile), 'rb', 0)\n\n  graph_action, graph_hidden_values = \\\n    request.get_form(view_func=view_cvsgraph, params={})\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'imagemap' : fp,\n    'imagesrc' : imagesrc,\n    'graph_action' : graph_action,\n    'graph_hidden_values' : graph_hidden_values,\n    'opt_gflip' : ezt.boolean('invert' in cfg.options.allowed_cvsgraph_useropts),\n    'opt_gbbox' : ezt.boolean('branchbox' in cfg.options.allowed_cvsgraph_useropts),\n    'opt_gshow' : ezt.boolean('show' in cfg.options.allowed_cvsgraph_useropts),\n    'opt_gleft' : ezt.boolean('rotate' in cfg.options.allowed_cvsgraph_useropts),\n    'opt_gmaxtag' : ezt.boolean('limittags' in cfg.options.allowed_cvsgraph_useropts),\n    'gflip' : ezt.boolean(int(request.query_dict.get('gflip', 0))),\n    'gbbox' : ezt.boolean(int(request.query_dict.get('gbbox', 0))),\n    'gleft' : ezt.boolean(int(request.query_dict.get('gleft', 0))),\n    'gmaxtag' : request.query_dict.get('gmaxtag', 0),\n    'gshow' : cvsgraph_normalize_gshow(request),\n    }))\n  generate_page(request, \"graph\", data)\n\ndef search_file(repos, path_parts, rev, search_re):\n  \"\"\"Return 1 iff the contents of the file at PATH_PARTS in REPOS as\n  of revision REV matches regular expression SEARCH_RE.\"\"\"\n\n  # Read in each line of a checked-out file, and then use re.search to\n  # search line.\n  fp = repos.openfile(path_parts, rev, {})[0]\n  matches = 0\n  while 1:\n    line = fp.readline()\n    if not line:\n      break\n    if search_re.search(line):\n      matches = 1\n      fp.close()\n      break\n  return matches\n\ndef view_doc(request):\n  \"\"\"Serve ViewVC static content locally.\n\n  Using this avoids the need for modifying the setup of the web server.\n  \"\"\"\n  cfg = request.cfg\n  document = request.where\n  filename = cfg.path(os.path.join(cfg.options.template_dir,\n                                   \"docroot\", document))\n\n  # Stat the file to get content length and last-modified date.\n  try:\n    info = os.stat(filename)\n  except OSError, v:\n    raise debug.ViewVCException('Static file \"%s\" not available (%s)'\n                                 % (document, str(v)), '404 Not Found')\n  content_length = str(info[stat.ST_SIZE])\n  last_modified = info[stat.ST_MTIME]\n\n  # content_length + mtime makes a pretty good etag.\n  if check_freshness(request, last_modified,\n                     \"%s-%s\" % (content_length, last_modified)):\n    return\n\n  try:\n    fp = open(filename, \"rb\")\n  except IOError, v:\n    raise debug.ViewVCException('Static file \"%s\" not available (%s)'\n                                 % (document, str(v)), '404 Not Found')\n\n  if document[-3:] == 'png':\n    mime_type = 'image/png'\n  elif document[-3:] == 'jpg':\n    mime_type = 'image/jpeg'\n  elif document[-3:] == 'gif':\n    mime_type = 'image/gif'\n  elif document[-3:] == 'css':\n    mime_type = 'text/css'\n  else: # assume HTML:\n    mime_type = None\n  copy_stream(fp, get_writeready_server_file(request, mime_type,\n                                             content_length=content_length))\n  fp.close()\n\ndef rcsdiff_date_reformat(date_str, cfg):\n  if date_str is None:\n    return None\n  try:\n    date = vclib.ccvs.cvs_strptime(date_str)\n  except ValueError:\n    return date_str\n  return make_time_string(calendar.timegm(date), cfg)\n\n_re_extract_rev = re.compile(r'^[-+*]{3} [^\\t]+\\t([^\\t]+)\\t((\\d+\\.)*\\d+)$')\n_re_extract_info = re.compile(r'@@ \\-([0-9]+).*\\+([0-9]+).*@@(.*)')\n\nclass DiffSource:\n  def __init__(self, fp, cfg):\n    self.fp = fp\n    self.cfg = cfg\n    self.save_line = None\n    self.line_number = None\n    self.prev_line_number = None\n    \n    # keep track of where we are during an iteration\n    self.idx = -1\n    self.last = None\n\n    # these will be set once we start reading\n    self.state = 'no-changes'\n    self.left_col = [ ]\n    self.right_col = [ ]\n\n  def __getitem__(self, idx):\n    if idx == self.idx:\n      return self.last\n    if idx != self.idx + 1:\n      raise DiffSequencingError()\n\n    # keep calling _get_row until it gives us something. sometimes, it\n    # doesn't return a row immediately because it is accumulating changes.\n    # when it is out of data, _get_row will raise IndexError.\n    while 1:\n      item = self._get_row()\n      if item:\n        self.idx = idx\n        self.last = item\n        return item\n\n  def _format_text(self, text):\n    text = text.rstrip('\\r\\n')\n    if self.cfg.options.tabsize > 0:\n      text = text.expandtabs(self.cfg.options.tabsize)\n    hr_breakable = self.cfg.options.hr_breakable\n    \n    # in the code below, \"\\x01\" will be our stand-in for \"&\". We don't want\n    # to insert \"&\" because it would get escaped by sapi.escape().  Similarly,\n    # we use \"\\x02\" as a stand-in for \"<br>\"\n  \n    if hr_breakable > 1 and len(text) > hr_breakable:\n      text = re.sub('(' + ('.' * hr_breakable) + ')', '\\\\1\\x02', text)\n    if hr_breakable:\n      # make every other space \"breakable\"\n      text = text.replace('  ', ' \\x01nbsp;')\n    else:\n      text = text.replace(' ', '\\x01nbsp;')\n    text = sapi.escape(text)\n    text = text.replace('\\x01', '&')\n    text = text.replace('\\x02', '<span style=\"color:red\">\\</span><br />')\n    return text\n    \n  def _get_row(self):\n    if self.state[:5] == 'flush':\n      item = self._flush_row()\n      if item:\n        return item\n      self.state = 'dump'\n\n    if self.save_line:\n      line = self.save_line\n      self.save_line = None\n    else:\n      line = self.fp.readline()\n\n    if not line:\n      if self.state == 'no-changes':\n        self.state = 'done'\n        return _item(type=_RCSDIFF_NO_CHANGES)\n\n      # see if there are lines to flush\n      if self.left_col or self.right_col:\n        # move into the flushing state\n        self.state = 'flush-' + self.state\n        return None\n\n      # nothing more to return\n      raise IndexError\n\n    if line[:2] == '@@':\n      self.state = 'dump'\n      self.left_col = [ ]\n      self.right_col = [ ]\n\n      match = _re_extract_info.match(line)\n      self.line_number = int(match.group(2)) - 1\n      self.prev_line_number = int(match.group(1)) - 1\n      return _item(type='header',\n                   line_info_left=match.group(1),\n                   line_info_right=match.group(2),\n                   line_info_extra=self._format_text(match.group(3)))\n    \n    if line[0] == '\\\\':\n      # \\ No newline at end of file\n      # Just skip. This code used to move to flush state, but that resulted in\n      # changes being displayed as removals-and-readditions.\n      return None\n\n    diff_code = line[0]\n    output = self._format_text(line[1:])\n    \n    if diff_code == '+':\n      if self.state == 'dump':\n        self.line_number = self.line_number + 1\n        return _item(type='add', right=output, line_number=self.line_number)\n\n      self.state = 'pre-change-add'\n      self.right_col.append(output)\n      return None\n\n    if diff_code == '-':\n      self.state = 'pre-change-remove'\n      self.left_col.append(output)\n      return None  # early exit to avoid line in\n\n    if self.left_col or self.right_col:\n      # save the line for processing again later, and move into the\n      # flushing state\n      self.save_line = line\n      self.state = 'flush-' + self.state\n      return None\n\n    self.line_number = self.line_number + 1\n    self.prev_line_number = self.prev_line_number + 1\n    return _item(type='context', left=output, right=output,\n                 line_number=self.line_number)\n\n  def _flush_row(self):\n    if not self.left_col and not self.right_col:\n      # nothing more to flush\n      return None\n\n    if self.state == 'flush-pre-change-remove':\n      self.prev_line_number = self.prev_line_number + 1\n      return _item(type='remove', left=self.left_col.pop(0),\n                   line_number=self.prev_line_number)\n\n    # state == flush-pre-change-add\n    item = _item(type='change',\n                 have_left=ezt.boolean(0),\n                 have_right=ezt.boolean(0))\n    if self.left_col:\n      self.prev_line_number = self.prev_line_number + 1\n      item.have_left = ezt.boolean(1)\n      item.left = self.left_col.pop(0)\n      item.line_number = self.prev_line_number\n    if self.right_col:\n      self.line_number = self.line_number + 1\n      item.have_right = ezt.boolean(1)\n      item.right = self.right_col.pop(0)\n      item.line_number = self.line_number\n    return item\n\nclass DiffSequencingError(Exception):\n  pass\n\ndef diff_parse_headers(fp, diff_type, path1, path2, rev1, rev2,\n                       sym1=None, sym2=None):\n  date1 = date2 = log_rev1 = log_rev2 = flag = None\n  header_lines = []\n\n  if diff_type == vclib.UNIFIED:\n    f1 = '--- '\n    f2 = '+++ '\n  elif diff_type == vclib.CONTEXT:\n    f1 = '*** '\n    f2 = '--- '\n  else:\n    f1 = f2 = None\n\n  # If we're parsing headers, then parse and tweak the diff headers,\n  # collecting them in an array until we've read and handled them all.\n  if f1 and f2:\n    parsing = 1\n    flag = _RCSDIFF_NO_CHANGES\n    len_f1 = len(f1)\n    len_f2 = len(f2)\n    while parsing:\n      line = fp.readline()\n      if not line:\n        break\n\n      # Saw at least one line in the stream\n      flag = None\n\n      if line[:len(f1)] == f1:\n        match = _re_extract_rev.match(line)\n        if match:\n          date1 = match.group(1)\n          log_rev1 = match.group(2)\n          line = '%s%s\\t%s\\t%s%s\\n' % (f1, path1, date1, log_rev1,\n                                       sym1 and ' ' + sym1 or '')\n      elif line[:len(f2)] == f2:\n        match = _re_extract_rev.match(line)\n        if match:\n          date2 = match.group(1)\n          log_rev2 = match.group(2)\n          line = '%s%s\\t%s\\t%s%s\\n' % (f2, path2, date2, log_rev2,\n                                       sym2 and ' ' + sym2 or '')\n        parsing = 0\n      elif line[:3] == 'Bin':\n        flag = _RCSDIFF_IS_BINARY\n        parsing = 0\n      elif (line.find('not found') != -1 or \n            line.find('illegal option') != -1):\n        flag = _RCSDIFF_ERROR\n        parsing = 0\n      header_lines.append(line)\n\n  if (log_rev1 and log_rev1 != rev1):\n    raise debug.ViewVCException('rcsdiff found revision %s, but expected '\n                                 'revision %s' % (log_rev1, rev1),\n                                 '500 Internal Server Error')\n  if (log_rev2 and log_rev2 != rev2):\n    raise debug.ViewVCException('rcsdiff found revision %s, but expected '\n                                 'revision %s' % (log_rev2, rev2),\n                                 '500 Internal Server Error')\n\n  return date1, date2, flag, ''.join(header_lines)\n\n\ndef _get_diff_path_parts(request, query_key, rev, base_rev):\n  repos = request.repos\n  if request.query_dict.has_key(query_key):\n    parts = _path_parts(request.query_dict[query_key])\n  elif request.roottype == 'svn':\n    try:\n      parts = _path_parts(repos.get_location(request.where,\n                                             repos._getrev(base_rev),\n                                             repos._getrev(rev)))\n    except vclib.InvalidRevision:\n      raise debug.ViewVCException('Invalid path(s) or revision(s) passed '\n                                   'to diff', '400 Bad Request')\n    except vclib.ItemNotFound:\n      raise debug.ViewVCException('Invalid path(s) or revision(s) passed '\n                                   'to diff', '400 Bad Request')\n  else:\n    parts = request.path_parts\n  return parts\n\n\ndef setup_diff(request):\n  query_dict = request.query_dict\n\n  rev1 = r1 = query_dict['r1']\n  rev2 = r2 = query_dict['r2']\n  sym1 = sym2 = None\n\n  # hack on the diff revisions\n  if r1 == 'text':\n    rev1 = query_dict.get('tr1', None)\n    if not rev1:\n      raise debug.ViewVCException('Missing revision from the diff '\n                                   'form text field', '400 Bad Request')\n  else:\n    idx = r1.find(':')\n    if idx == -1:\n      rev1 = r1\n    else:\n      rev1 = r1[:idx]\n      sym1 = r1[idx+1:]\n      \n  if r2 == 'text':\n    rev2 = query_dict.get('tr2', None)\n    if not rev2:\n      raise debug.ViewVCException('Missing revision from the diff '\n                                   'form text field', '400 Bad Request')\n    sym2 = ''\n  else:\n    idx = r2.find(':')\n    if idx == -1:\n      rev2 = r2\n    else:\n      rev2 = r2[:idx]\n      sym2 = r2[idx+1:]\n\n  if request.roottype == 'svn':\n    try:\n      rev1 = str(request.repos._getrev(rev1))\n      rev2 = str(request.repos._getrev(rev2))\n    except vclib.InvalidRevision:\n      raise debug.ViewVCException('Invalid revision(s) passed to diff',\n                                  '400 Bad Request')\n    \n  p1 = _get_diff_path_parts(request, 'p1', rev1, request.pathrev)\n  p2 = _get_diff_path_parts(request, 'p2', rev2, request.pathrev)\n\n  try:\n    if revcmp(rev1, rev2) > 0:\n      rev1, rev2 = rev2, rev1\n      sym1, sym2 = sym2, sym1\n      p1, p2 = p2, p1\n  except ValueError:\n    raise debug.ViewVCException('Invalid revision(s) passed to diff',\n                                 '400 Bad Request')\n  return p1, p2, rev1, rev2, sym1, sym2\n\n\ndef view_patch(request):\n  if 'diff' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Diff generation is disabled',\n                                 '403 Forbidden')\n\n  cfg = request.cfg\n  query_dict = request.query_dict\n  p1, p2, rev1, rev2, sym1, sym2 = setup_diff(request)\n\n  mime_type1, encoding1 = calculate_mime_type(request, p1, rev1)\n  mime_type2, encoding2 = calculate_mime_type(request, p2, rev2)\n  if is_binary_file_mime_type(mime_type1, cfg) or \\\n     is_binary_file_mime_type(mime_type2, cfg):\n    raise debug.ViewVCException('Display of binary file content disabled '\n                                'by configuration', '403 Forbidden')\n\n  # In the absence of a format dictation in the CGI params, we'll let\n  # use the configured diff format, allowing 'c' to mean 'c' and\n  # anything else to mean 'u'.\n  format = query_dict.get('diff_format',\n                          cfg.options.diff_format == 'c' and 'c' or 'u')\n  if format == 'c':\n    diff_type = vclib.CONTEXT\n  elif format == 'u':\n    diff_type = vclib.UNIFIED\n  else:\n    raise debug.ViewVCException('Diff format %s not understood'\n                                 % format, '400 Bad Request')\n\n  # Set some diff options.  (Are there other options folks might want?\n  # Maybe not.  For a patch, perhaps the precise change is ideal.)\n  diff_options = {}\n  diff_options['funout'] = cfg.options.hr_funout\n  \n  try:\n    fp = request.repos.rawdiff(p1, rev1, p2, rev2, diff_type, diff_options)\n  except vclib.InvalidRevision:\n    raise debug.ViewVCException('Invalid path(s) or revision(s) passed '\n                                 'to diff', '400 Bad Request')\n\n  path_left = _path_join(p1)\n  path_right = _path_join(p2)\n  date1, date2, flag, headers = diff_parse_headers(fp, diff_type,\n                                                   path_left, path_right,\n                                                   rev1, rev2, sym1, sym2)\n\n  server_fp = get_writeready_server_file(request, 'text/plain')\n  server_fp.write(headers)\n  copy_stream(fp, server_fp)\n  fp.close()\n\n\ndef diff_side_item(request, path_comp, rev, sym):\n  '''Prepare information about left/right side of the diff. Prepare two flavors,\n  for content and for property diffs.'''\n\n  # TODO: Is the slice necessary, or is limit enough?\n  options = {'svn_show_all_dir_logs': 1}\n  log_entry = request.repos.itemlog(path_comp, rev, vclib.SORTBY_REV,\n                                    0, 1, options)[-1]\n  ago = log_entry.date is not None \\\n         and html_time(request, log_entry.date, 1) or None\n  path_joined = _path_join(path_comp)\n\n  lf = LogFormatter(request, log_entry.log)\n  \n  # Item for property diff: no hrefs, there's no view\n  # to download/annotate property\n  i_prop = _item(log_entry=log_entry,\n                 date=make_time_string(log_entry.date, request.cfg),\n                 author=log_entry.author,\n                 log = lf.get(maxlen=0, htmlize=1),\n                 size=log_entry.size,\n                 ago=ago,\n                 path=path_joined,\n                 path_comp=path_comp,\n                 rev=rev,\n                 tag=sym,\n                 view_href=None,\n                 download_href=None,\n                 download_text_href=None,\n                 annotate_href=None,\n                 revision_href=None,\n                 prefer_markup=ezt.boolean(0))\n\n  # Content diff item is based on property diff, with URIs added\n  fvi = get_file_view_info(request, path_joined, rev)\n  i_content = copy.copy(i_prop)\n  i_content.view_href = fvi.view_href\n  i_content.download_href = fvi.download_href\n  i_content.download_text_href = fvi.download_text_href\n  i_content.annotate_href = fvi.annotate_href\n  i_content.revision_href = fvi.revision_href\n  i_content.prefer_markup = fvi.prefer_markup\n\n  # Property diff item has properties hash, naturally. Content item doesn't.\n  i_content.properties = None\n  i_prop.properties = request.repos.itemprops(path_comp, rev)\n  return i_content, i_prop\n\n\nclass DiffDescription:\n  def __init__(self, request):\n    cfg = request.cfg\n    query_dict = request.query_dict\n\n    self.diff_format = query_dict.get('diff_format', cfg.options.diff_format)\n    self.human_readable = 0\n    self.hide_legend = 0\n    self.line_differ = None\n    self.fp_differ = None\n    self.request = request\n    self.context = -1\n    self.changes = []\n\n    if self.diff_format == 'c':\n      self.diff_type = vclib.CONTEXT\n      self.hide_legend = 1\n    elif self.diff_format == 's':\n      self.diff_type = vclib.SIDE_BY_SIDE\n      self.hide_legend = 1\n    elif self.diff_format == 'l':\n      self.diff_type = vclib.UNIFIED\n      self.context = 15\n      self.human_readable = 1\n    elif self.diff_format == 'f':\n      self.diff_type = vclib.UNIFIED\n      self.context = None\n      self.human_readable = 1\n    elif self.diff_format == 'h':\n      self.diff_type = vclib.UNIFIED\n      self.human_readable = 1\n    elif self.diff_format == 'u':\n      self.diff_type = vclib.UNIFIED\n      self.hide_legend = 1\n    else:\n      raise debug.ViewVCException('Diff format %s not understood'\n                                   % self.diff_format, '400 Bad Request')\n\n    # Determine whether idiff is avaialble and whether it could be used.\n    # idiff only supports side-by-side (conditionally) and unified formats,\n    # and is only used if intra-line diffs are requested.\n    if (cfg.options.hr_intraline and idiff\n        and ((self.human_readable and idiff.sidebyside)\n             or (not self.human_readable and self.diff_type == vclib.UNIFIED))):\n      # Override hiding legend for unified format. It is not marked 'human\n      # readable', and it is displayed differently depending on whether\n      # hr_intraline is disabled (displayed as raw diff) or enabled\n      # (displayed as colored). What a royal mess... Issue #301 should\n      # at some time address it; at that time, human_readable and hide_legend\n      # controls should both be merged into one, 'is_colored' or something.\n      self.hide_legend = 0\n      if self.human_readable:\n        self.line_differ = self._line_idiff_sidebyside\n        self.diff_block_format = 'sidebyside-2'\n      else:\n        self.line_differ = self._line_idiff_unified\n        self.diff_block_format = 'unified'\n    else:\n      if self.human_readable:\n        self.diff_block_format = 'sidebyside-1'\n        self.fp_differ = self._fp_vclib_hr\n      else:\n        self.diff_block_format = 'raw'\n        self.fp_differ = self._fp_vclib_raw\n\n  def anchor(self, anchor_name):\n    self.changes.append(_item(diff_block_format='anchor', anchor=anchor_name))\n\n  def get_content_diff(self, left, right):\n    cfg = self.request.cfg\n    diff_options = {}\n    if self.context != -1:\n      diff_options['context'] = self.context\n    if self.human_readable or self.diff_format == 'u':\n      diff_options['funout'] = cfg.options.hr_funout      \n    if self.human_readable:\n      diff_options['ignore_white'] = cfg.options.hr_ignore_white\n      diff_options['ignore_keyword_subst'] = \\\n                      cfg.options.hr_ignore_keyword_subst\n    self._get_diff(left, right, self._content_lines, self._content_fp,\n                   diff_options, None)\n\n  def get_prop_diff(self, left, right):\n    diff_options = {}\n    if self.context != -1:\n      diff_options['context'] = self.context\n    if self.human_readable:\n      cfg = self.request.cfg\n      diff_options['ignore_white'] = cfg.options.hr_ignore_white\n    for name in self._uniq(left.properties.keys() + right.properties.keys()):\n      # Skip non-utf8 property names\n      if is_undisplayable(name):\n        continue\n      val_left = left.properties.get(name, '')\n      val_right = right.properties.get(name, '')\n      # Skip non-changed properties\n      if val_left == val_right:\n        continue\n      # Check for binary properties\n      if is_undisplayable(val_left) or is_undisplayable(val_right):\n        self.changes.append(_item(left=left,\n                                  right=right,\n                                  diff_block_format=self.diff_block_format,\n                                  changes=[ _item(type=_RCSDIFF_IS_BINARY) ],\n                                  propname=name))\n        continue\n      self._get_diff(left, right, self._prop_lines, self._prop_fp,\n                     diff_options, name)\n\n  def _get_diff(self, left, right, get_lines, get_fp, diff_options, propname):\n    if self.fp_differ is not None:\n      fp = get_fp(left, right, propname, diff_options)\n      changes = self.fp_differ(left, right, fp, propname)\n    else:\n      lines_left = get_lines(left, propname)\n      lines_right = get_lines(right, propname)\n      changes = self.line_differ(lines_left, lines_right, diff_options)\n    self.changes.append(_item(left=left,\n                              right=right,\n                              changes=changes,\n                              diff_block_format=self.diff_block_format,\n                              propname=propname))\n\n  def _line_idiff_sidebyside(self, lines_left, lines_right, diff_options):\n    return idiff.sidebyside(lines_left, lines_right,\n                            diff_options.get(\"context\", 5))\n\n  def _line_idiff_unified(self, lines_left, lines_right, diff_options):\n    return idiff.unified(lines_left, lines_right,\n                         diff_options.get(\"context\", 2))\n\n  def _fp_vclib_hr(self, left, right, fp, propname):\n    date1, date2, flag, headers = \\\n                    diff_parse_headers(fp, self.diff_type,\n                                       self._property_path(left, propname),\n                                       self._property_path(right, propname),\n                                       left.rev, right.rev, left.tag, right.tag)\n    if flag is not None:\n      return [ _item(type=flag) ]\n    else:\n      return DiffSource(fp, self.request.cfg)\n\n  def _fp_vclib_raw(self, left, right, fp, propname):\n    date1, date2, flag, headers = \\\n                    diff_parse_headers(fp, self.diff_type,\n                                       self._property_path(left, propname),\n                                       self._property_path(right, propname),\n                                       left.rev, right.rev, left.tag, right.tag)\n    if flag is not None:\n      return _item(type=flag)\n    else:\n      return _item(type='raw', raw=MarkupPipeWrapper(fp,\n              self.request.server.escape(headers), None, 1))\n\n  def _content_lines(self, side, propname):\n    f = self.request.repos.openfile(side.path_comp, side.rev, {})[0]\n    try:\n      lines = f.readlines()\n    finally:\n      f.close()\n    return lines\n\n  def _content_fp(self, left, right, propname, diff_options):\n    return self.request.repos.rawdiff(left.path_comp, left.rev,\n                                      right.path_comp, right.rev,\n                                      self.diff_type, diff_options)\n\n  def _prop_lines(self, side, propname):\n    val = side.properties.get(propname, '')\n    return val.splitlines()\n\n  def _prop_fp(self, left, right, propname, diff_options):\n    fn_left = self._temp_file(left.properties.get(propname))\n    fn_right = self._temp_file(right.properties.get(propname))\n    diff_args = vclib._diff_args(self.diff_type, diff_options)\n    info_left = self._property_path(left, propname), \\\n                left.log_entry.date, left.rev\n    info_right = self._property_path(right, propname), \\\n                 right.log_entry.date, right.rev\n    return vclib._diff_fp(fn_left, fn_right, info_left, info_right,\n                          self.request.cfg.utilities.diff or 'diff', diff_args)\n\n  def _temp_file(self, val):\n    '''Create a temporary file with content from val'''\n    fd, fn = tempfile.mkstemp()\n    fp = os.fdopen(fd, \"wb\")\n    if val:\n      fp.write(val)\n    fp.close()\n    return fn\n\n  def _uniq(self, lst):\n    '''Determine unique set of list elements'''\n    h = {}\n    for e in lst:\n      h[e] = 1\n    return sorted(h.keys())\n\n  def _property_path(self, side, propname):\n    '''Return path to be displayed in raw diff - possibly augmented with\n    property name'''\n    if propname is None:\n      return side.path\n    else:\n      return \"%s:property(%s)\" % (side.path, propname)\n\n\ndef view_diff(request):\n  if 'diff' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Diff generation is disabled',\n                                 '403 Forbidden')\n\n  cfg = request.cfg\n  p1, p2, rev1, rev2, sym1, sym2 = setup_diff(request)\n  \n  mime_type1, encoding1 = calculate_mime_type(request, p1, rev1)\n  mime_type2, encoding2 = calculate_mime_type(request, p2, rev2)\n  if is_binary_file_mime_type(mime_type1, cfg) or \\\n     is_binary_file_mime_type(mime_type2, cfg):\n    raise debug.ViewVCException('Display of binary file content disabled '\n                                'by configuration', '403 Forbidden')\n\n  # since templates are in use and subversion allows changes to the dates,\n  # we can't provide a strong etag\n  if check_freshness(request, None, '%s-%s' % (rev1, rev2), weak=1):\n    return\n\n  left_side_content, left_side_prop = diff_side_item(request, p1, rev1, sym1)\n  right_side_content, right_side_prop = diff_side_item(request, p2, rev2, sym2)\n\n  desc = DiffDescription(request)\n\n  try:\n    if request.pathtype == vclib.FILE:\n      # Get file content diff\n      desc.anchor(\"content\")\n      desc.get_content_diff(left_side_content, right_side_content)\n\n    # Get property list and diff each property\n    desc.anchor(\"properties\")\n    desc.get_prop_diff(left_side_prop, right_side_prop)\n\n  except vclib.InvalidRevision:\n    raise debug.ViewVCException('Invalid path(s) or revision(s) passed '\n        'to diff', '400 Bad Request')\n\n  no_format_params = request.query_dict.copy()\n  no_format_params['diff_format'] = None\n  diff_format_action, diff_format_hidden_values = \\\n    request.get_form(params=no_format_params)\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'diffs' : desc.changes,\n    'diff_format' : desc.diff_format,\n    'hide_legend' : ezt.boolean(desc.hide_legend),\n    'patch_href' : request.get_url(view_func=view_patch,\n                                   params=no_format_params,\n                                   escape=1),\n    'diff_format_action' : diff_format_action,\n    'diff_format_hidden_values' : diff_format_hidden_values,\n    }))\n  generate_page(request, \"diff\", data)\n\n\ndef generate_tarball_header(out, name, size=0, mode=None, mtime=0,\n                            uid=0, gid=0, typeflag=None, linkname='',\n                            uname='viewvc', gname='viewvc',\n                            devmajor=1, devminor=0, prefix=None,\n                            magic='ustar', version='00', chksum=None):\n  if not mode:\n    if name[-1:] == '/':\n      mode = 0755\n    else:\n      mode = 0644\n\n  if not typeflag:\n    if linkname:\n      typeflag = '2' # symbolic link\n    elif name[-1:] == '/':\n      typeflag = '5' # directory\n    else:\n      typeflag = '0' # regular file\n\n  if not prefix:\n    prefix = ''\n\n  # generate a GNU tar extension header for a long name.\n  if len(name) >= 100:\n    generate_tarball_header(out, '././@LongLink', len(name),\n                            0, 0, 0, 0, 'L')\n    out.write(name)\n    out.write('\\0' * (511 - ((len(name) + 511) % 512)))\n\n  # generate a GNU tar extension header for a long symlink name.\n  if len(linkname) >= 100:\n    generate_tarball_header(out, '././@LongLink', len(linkname),\n                            0, 0, 0, 0, 'K')\n    out.write(linkname)\n    out.write('\\0' * (511 - ((len(linkname) + 511) % 512)))\n\n  block1 = struct.pack('100s 8s 8s 8s 12s 12s',\n                       name,\n                       '%07o' % mode,\n                       '%07o' % uid,\n                       '%07o' % gid,\n                       '%011o' % size,\n                       '%011o' % mtime)\n\n  block2 = struct.pack('c 100s 6s 2s 32s 32s 8s 8s 155s',\n                       typeflag,\n                       linkname,\n                       magic,\n                       version,\n                       uname,\n                       gname,\n                       '%07o' % devmajor,\n                       '%07o' % devminor,\n                       prefix)\n\n  if not chksum:\n    dummy_chksum = '        '\n    block = block1 + dummy_chksum + block2\n    chksum = 0\n    for i in range(len(block)):\n      chksum = chksum + ord(block[i])\n\n  block = block1 + struct.pack('8s', '%07o' % chksum) + block2\n  block = block + '\\0' * (512 - len(block))\n\n  out.write(block)\n\ndef generate_tarball(out, request, reldir, stack, dir_mtime=None):\n  # get directory info from repository\n  rep_path = request.path_parts + reldir\n  entries = request.repos.listdir(rep_path, request.pathrev, {})\n  request.repos.dirlogs(rep_path, request.pathrev, entries, {})\n  entries.sort(lambda a, b: cmp(a.name, b.name))\n\n  # figure out corresponding path in tar file. everything gets put underneath\n  # a single top level directory named after the repository directory being\n  # tarred\n  if request.path_parts:\n    tar_dir = request.path_parts[-1] + '/'\n  else:\n    # Don't handle context as a directory in the tar ball.\n    root_path_parts = _path_parts(request.rootname)\n    tar_dir = root_path_parts[-1] + '/'\n  if reldir:\n    tar_dir = tar_dir + _path_join(reldir) + '/'\n\n  cvs = request.roottype == 'cvs'\n  \n  # If our caller doesn't dictate a datestamp to use for the current\n  # directory, its datestamps will be the youngest of the datestamps\n  # of versioned items in that subdirectory.  We'll be ignoring dead\n  # or busted items and, in CVS, subdirs.\n  if dir_mtime is None:\n    dir_mtime = 0\n    for file in entries:\n      if cvs and (file.kind != vclib.FILE or file.rev is None or file.dead):\n        continue\n      if (file.date is not None) and (file.date > dir_mtime):\n        dir_mtime = file.date\n\n  # Push current directory onto the stack.\n  stack.append(tar_dir)\n\n  # If this is Subversion, we generate a header for this directory\n  # regardless of its contents.  For CVS it will only get into the\n  # tarball if it has files underneath it, which we determine later.\n  if not cvs:\n    generate_tarball_header(out, tar_dir, mtime=dir_mtime)\n\n  # Run through the files in this directory, skipping busted and\n  # unauthorized ones.\n  for file in entries:\n    if file.kind != vclib.FILE:\n      continue\n    if cvs and (file.rev is None or file.dead):\n      continue\n\n    # If we get here, we've seen at least one valid file in the\n    # current directory.  For CVS, we need to make sure there are\n    # directory parents to contain it, so we flush the stack.\n    if cvs:\n      for dir in stack:\n        generate_tarball_header(out, dir, mtime=dir_mtime)\n      del stack[:]\n\n    # Calculate the mode for the file.  Sure, we could look directly\n    # at the ,v file in CVS, but that's a layering violation we'd like\n    # to avoid as much as possible.\n    if request.repos.isexecutable(rep_path + [file.name], request.pathrev):\n      mode = 0755\n    else:\n      mode = 0644\n\n    # Is this thing a symlink?\n    #\n    ### FIXME: A better solution would be to have vclib returning\n    ### symlinks with a new vclib.SYMLINK path type.\n    symlink_target = None\n    if hasattr(request.repos, 'get_symlink_target'):\n      symlink_target = request.repos.get_symlink_target(rep_path + [file.name],\n                                                        request.pathrev)\n\n    # If the object is a symlink, generate the appropriate header.\n    # Otherwise, we're dealing with a regular file.\n    if symlink_target:\n      generate_tarball_header(out, tar_dir + file.name, 0, mode,\n                              file.date is not None and file.date or 0,\n                              typeflag='2', linkname=symlink_target)\n    else:\n      filesize = request.repos.filesize(rep_path + [file.name], request.pathrev)\n\n      if filesize == -1:\n        # Bummer.  We have to calculate the filesize manually.\n        fp = request.repos.openfile(rep_path + [file.name], request.pathrev, {})[0]\n        filesize = 0\n        while 1:\n          chunk = retry_read(fp)\n          if not chunk:\n            break\n          filesize = filesize + len(chunk)\n        fp.close()\n\n      # Write the tarball header...\n      generate_tarball_header(out, tar_dir + file.name, filesize, mode,\n                              file.date is not None and file.date or 0)\n      \n      # ...the file's contents ...\n      fp = request.repos.openfile(rep_path + [file.name], request.pathrev, {})[0]\n      while 1:\n        chunk = retry_read(fp)\n        if not chunk:\n          break\n        out.write(chunk)\n      fp.close()\n\n      # ... and then add the block padding.\n      out.write('\\0' * (511 - (filesize + 511) % 512))\n\n  # Recurse into subdirectories, skipping busted and unauthorized (or\n  # configured-to-be-hidden) ones.\n  for file in entries:\n    if file.errors or file.kind != vclib.DIR:\n      continue\n    if request.cfg.options.hide_cvsroot \\\n       and is_cvsroot_path(request.roottype, rep_path + [file.name]):\n      continue\n\n    mtime = request.roottype == 'svn' and file.date or None\n    generate_tarball(out, request, reldir + [file.name], stack, mtime)\n\n  # Pop the current directory from the stack.\n  del stack[-1:]\n\ndef download_tarball(request):\n  cfg = request.cfg\n  \n  if 'tar' not in request.cfg.options.allowed_views:\n    raise debug.ViewVCException('Tarball generation is disabled',\n                                 '403 Forbidden')\n\n  # If debugging, we just need to open up the specified tar path for\n  # writing.  Otherwise, we get a writeable server output stream --\n  # disabling any default compression thereupon -- and wrap that in\n  # our own gzip stream wrapper.\n  if debug.TARFILE_PATH:\n    fp = open(debug.TARFILE_PATH, 'w')\n  else:    \n    tarfile = request.rootname\n    if request.path_parts:\n      tarfile = \"%s-%s\" % (tarfile, request.path_parts[-1])\n    request.server.addheader('Content-Disposition',\n                             'attachment; filename=\"%s.tar.gz\"' % (tarfile))\n    server_fp = get_writeready_server_file(request, 'application/x-gzip',\n                                           allow_compress=False)\n    request.server.flush()\n    fp = gzip.GzipFile('', 'wb', 9, server_fp)\n\n  ### FIXME: For Subversion repositories, we can get the real mtime of the\n  ### top-level directory here.\n  generate_tarball(fp, request, [], [])\n\n  fp.write('\\0' * 1024)\n  fp.close()\n\n  if debug.TARFILE_PATH:\n    request.server.header('')\n    print \"\"\"\n<html>\n<body>\n<p>Tarball '%s' successfully generated!</p>\n</body>\n</html>\"\"\" % (debug.TARFILE_PATH)\n\n\ndef view_revision(request):\n  if request.roottype != \"svn\":\n    raise debug.ViewVCException(\"Revision view not supported for CVS \"\n                                \"repositories at this time.\",\n                                \"400 Bad Request\")\n\n  cfg = request.cfg\n  query_dict = request.query_dict\n  try:\n    rev = request.repos._getrev(query_dict.get('revision'))\n  except vclib.InvalidRevision:\n    raise debug.ViewVCException('Invalid revision', '404 Not Found')\n  youngest_rev = request.repos.get_youngest_revision()\n  \n  # The revision number acts as a weak validator (but we tell browsers\n  # not to cache the youngest revision).\n  if rev != youngest_rev and check_freshness(request, None, str(rev), weak=1):\n    return\n\n  # Fetch the revision information.\n  date, author, msg, revprops, changes = request.repos.revinfo(rev)\n  date_str = make_time_string(date, cfg)\n\n  # Fix up the revprops list (rather like get_itemprops()).\n  propnames = revprops.keys()\n  propnames.sort()\n  props = []\n  for name in propnames:\n    # skip non-utf8 property names\n    if is_undisplayable(name):\n      continue\n    lf = LogFormatter(request, revprops[name])\n    value = lf.get(maxlen=0, htmlize=1)\n    # note non-utf8 property values\n    undisplayable = is_undisplayable(value)\n    if undisplayable:\n      value = None\n    props.append(_item(name=name, value=value,\n                       undisplayable=ezt.boolean(undisplayable)))\n  \n  # Sort the changes list by path.\n  def changes_sort_by_path(a, b):\n    return cmp(a.path_parts, b.path_parts)\n  changes.sort(changes_sort_by_path)\n\n  # Handle limit_changes parameter\n  cfg_limit_changes = cfg.options.limit_changes\n  limit_changes = int(query_dict.get('limit_changes', cfg_limit_changes))\n  more_changes = None\n  more_changes_href = None\n  first_changes = None\n  first_changes_href = None\n  num_changes = len(changes)\n  if limit_changes and len(changes) > limit_changes:\n    more_changes = len(changes) - limit_changes\n    params = query_dict.copy()\n    params['limit_changes'] = 0\n    more_changes_href = request.get_url(params=params, escape=1)\n    changes = changes[:limit_changes]\n  elif cfg_limit_changes and len(changes) > cfg_limit_changes:\n    first_changes = cfg_limit_changes\n    params = query_dict.copy()\n    params['limit_changes'] = None\n    first_changes_href = request.get_url(params=params, escape=1)\n\n  # Add the hrefs, types, and prev info\n  for change in changes:\n    change.view_href = change.diff_href = change.type = change.log_href = None\n\n    # If the path is newly added, don't claim text or property\n    # modifications.\n    if (change.action == vclib.ADDED or change.action == vclib.REPLACED) \\\n       and not change.copied:\n      change.text_changed = 0\n      change.props_changed = 0\n\n    # Calculate the view link URLs (for which we must have a pathtype).\n    if change.pathtype:\n      view_func = None\n      if change.pathtype is vclib.FILE \\\n         and 'markup' in cfg.options.allowed_views:\n        view_func = view_markup\n      elif change.pathtype is vclib.DIR:\n        view_func = view_directory\n\n      path = _path_join(change.path_parts)\n      base_path = _path_join(change.base_path_parts)\n      if change.action == vclib.DELETED:\n        link_rev = str(change.base_rev)\n        link_where = base_path\n      else:\n        link_rev = str(rev)\n        link_where = path\n\n      change.view_href = request.get_url(view_func=view_func,\n                                         where=link_where,\n                                         pathtype=change.pathtype,\n                                         params={'pathrev' : link_rev},\n                                         escape=1)\n      change.log_href = request.get_url(view_func=view_log,\n                                        where=link_where,\n                                        pathtype=change.pathtype,\n                                        params={'pathrev' : link_rev},\n                                        escape=1)\n\n      if (change.pathtype is vclib.FILE and change.text_changed) \\\n          or change.props_changed:\n        change.diff_href = request.get_url(view_func=view_diff,\n                                           where=path, \n                                           pathtype=change.pathtype,\n                                           params={'pathrev' : str(rev),\n                                                   'r1' : str(rev),\n                                                   'r2' : str(change.base_rev),\n                                                   },\n                                           escape=1)\n    \n\n    # use same variable names as the log template\n    change.path = _path_join(change.path_parts)\n    change.copy_path = _path_join(change.base_path_parts)\n    change.copy_rev = change.base_rev\n    change.text_mods = ezt.boolean(change.text_changed)\n    change.prop_mods = ezt.boolean(change.props_changed)\n    change.is_copy = ezt.boolean(change.copied)\n    change.pathtype = (change.pathtype == vclib.FILE and 'file') \\\n                      or (change.pathtype == vclib.DIR and 'dir') \\\n                      or None\n    del change.path_parts\n    del change.base_path_parts\n    del change.base_rev\n    del change.text_changed\n    del change.props_changed\n    del change.copied\n\n  prev_rev_href = next_rev_href = None\n  if rev > 0:\n    prev_rev_href = request.get_url(view_func=view_revision,\n                                    where=None,\n                                    pathtype=None,\n                                    params={'revision': str(rev - 1)},\n                                    escape=1)\n  if rev < request.repos.get_youngest_revision():\n    next_rev_href = request.get_url(view_func=view_revision,\n                                    where=None,\n                                    pathtype=None,\n                                    params={'revision': str(rev + 1)},\n                                    escape=1)\n  jump_rev_action, jump_rev_hidden_values = \\\n    request.get_form(params={'revision': None})\n\n  lf = LogFormatter(request, msg)\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'rev' : str(rev),\n    'author' : author,\n    'date' : date_str,\n    'log' : lf.get(maxlen=0, htmlize=1),\n    'properties' : props,\n    'ago' : date is not None and html_time(request, date, 1) or None,\n    'changes' : changes,\n    'prev_href' : prev_rev_href,\n    'next_href' : next_rev_href,\n    'num_changes' : num_changes,\n    'limit_changes': limit_changes,\n    'more_changes': more_changes,\n    'more_changes_href': more_changes_href,\n    'first_changes': first_changes,\n    'first_changes_href': first_changes_href,\n    'jump_rev_action' : jump_rev_action,\n    'jump_rev_hidden_values' : jump_rev_hidden_values,\n    'revision_href' : request.get_url(view_func=view_revision,\n                                      where=None,\n                                      pathtype=None,\n                                      params={'revision': str(rev)},\n                                      escape=1),\n  }))\n  if rev == youngest_rev:\n    request.server.addheader(\"Cache-control\", \"no-store\")\n  generate_page(request, \"revision\", data)\n\ndef is_query_supported(request):\n  \"\"\"Returns true if querying is supported for the given path.\"\"\"\n  return request.cfg.cvsdb.enabled \\\n         and request.pathtype == vclib.DIR \\\n         and request.roottype in ['cvs', 'svn']\n\ndef is_querydb_nonempty_for_root(request):\n  \"\"\"Return 1 iff commits database integration is supported *and* the\n  current root is found in that database.  Only does this check if\n  check_database is set to 1.\"\"\"\n  if request.cfg.cvsdb.enabled and request.roottype in ['cvs', 'svn']:\n    if request.cfg.cvsdb.check_database_for_root:\n      global cvsdb\n      import cvsdb\n      db = cvsdb.ConnectDatabaseReadOnly(request.cfg)\n      repos_root, repos_dir = cvsdb.FindRepository(db, request.rootpath)\n      if repos_root:\n        return 1\n    else:\n      return 1\n  return 0\n\ndef validate_query_args(request):\n  # Do some additional input validation of query form arguments beyond\n  # what is offered by the CGI param validation loop in Request.run_viewvc().\n  \n  for arg_base in ['branch', 'file', 'comment', 'who']:\n    # First, make sure the the XXX_match args have valid values:\n    arg_match = arg_base + '_match'\n    arg_match_value = request.query_dict.get(arg_match, 'exact')\n    if not arg_match_value in ('exact', 'like', 'glob', 'regex', 'notregex'):\n      raise debug.ViewVCException(\n        'An illegal value was provided for the \"%s\" parameter.'\n        % (arg_match),\n        '400 Bad Request')\n\n    # Now, for those args which are supposed to be regular expressions (per\n    # their corresponding XXX_match values), make sure they are.\n    if arg_match_value == 'regex' or arg_match_value == 'notregex':\n      arg_base_value = request.query_dict.get(arg_base)\n      if arg_base_value:\n        try:\n          re.compile(arg_base_value)\n        except:\n          raise debug.ViewVCException(\n            'An illegal value was provided for the \"%s\" parameter.'\n            % (arg_base),\n            '400 Bad Request')\n  \ndef view_queryform(request):\n  if not is_query_supported(request):\n    raise debug.ViewVCException('Can not query project root \"%s\" at \"%s\".'\n                                 % (request.rootname, request.where),\n                                 '403 Forbidden')\n\n  # Do some more precise input validation.\n  validate_query_args(request)\n  \n  query_action, query_hidden_values = \\\n    request.get_form(view_func=view_query, params={'limit_changes': None})\n  limit_changes = \\\n    int(request.query_dict.get('limit_changes',\n                               request.cfg.options.limit_changes))\n\n  def escaped_query_dict_get(itemname, itemdefault=''):\n    return request.server.escape(request.query_dict.get(itemname, itemdefault))\n    \n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'branch' : escaped_query_dict_get('branch', ''),\n    'branch_match' : escaped_query_dict_get('branch_match', 'exact'),\n    'dir' : escaped_query_dict_get('dir', ''),\n    'file' : escaped_query_dict_get('file', ''),\n    'file_match' : escaped_query_dict_get('file_match', 'exact'),\n    'who' : escaped_query_dict_get('who', ''),\n    'who_match' : escaped_query_dict_get('who_match', 'exact'),\n    'comment' : escaped_query_dict_get('comment', ''),\n    'comment_match' : escaped_query_dict_get('comment_match', 'exact'),\n    'querysort' : escaped_query_dict_get('querysort', 'date'),\n    'date' : escaped_query_dict_get('date', 'hours'),\n    'hours' : escaped_query_dict_get('hours', '2'),\n    'mindate' : escaped_query_dict_get('mindate', ''),\n    'maxdate' : escaped_query_dict_get('maxdate', ''),\n    'query_action' : query_action,\n    'query_hidden_values' : query_hidden_values,\n    'limit_changes' : limit_changes,\n    'dir_href' : request.get_url(view_func=view_directory, params={},\n                                 escape=1),\n    }))\n  generate_page(request, \"query_form\", data)\n\ndef parse_date(datestr):\n  \"\"\"Parse a date string from the query form.\"\"\"\n  \n  match = re.match(r'^(\\d\\d\\d\\d)-(\\d\\d)-(\\d\\d)(?:\\ +'\n                   '(\\d\\d):(\\d\\d)(?::(\\d\\d))?)?$', datestr)\n  if match:\n    year = int(match.group(1))\n    month = int(match.group(2))\n    day = int(match.group(3))\n    hour = match.group(4)\n    if hour is not None:\n      hour = int(hour)\n    else:\n      hour = 0\n    minute = match.group(5)\n    if minute is not None:\n      minute = int(minute)\n    else:\n      minute = 0\n    second = match.group(6)\n    if second is not None:\n      second = int(second)\n    else:\n      second = 0\n    # return a \"seconds since epoch\" value assuming date given in UTC\n    tm = (year, month, day, hour, minute, second, 0, 0, 0)\n    return calendar.timegm(tm)\n  else:\n    return None\n\ndef english_query(request):\n  \"\"\"Generate a sentance describing the query.\"\"\"\n  cfg = request.cfg\n  ret = [ 'Checkins ' ]\n  dir = request.query_dict.get('dir', '')\n  if dir:\n    ret.append('to ')\n    if ',' in dir:\n      ret.append('subdirectories')\n    else:\n      ret.append('subdirectory')\n    ret.append(' <em>%s</em> ' % request.server.escape(dir))\n  file = request.query_dict.get('file', '')\n  if file:\n    if len(ret) != 1:\n      ret.append('and ')\n    ret.append('to file <em>%s</em> ' % request.server.escape(file))\n  who = request.query_dict.get('who', '')\n  branch = request.query_dict.get('branch', '')\n  if branch:\n    ret.append('on branch <em>%s</em> ' % request.server.escape(branch))\n  else:\n    ret.append('on all branches ')\n  comment = request.query_dict.get('comment', '')\n  if comment:\n    ret.append('with comment <i>%s</i> ' % request.server.escape(comment))\n  if who:\n    ret.append('by <em>%s</em> ' % request.server.escape(who))\n  date = request.query_dict.get('date', 'hours')\n  if date == 'hours':\n    ret.append('in the last %s hours' \\\n               % request.server.escape(request.query_dict.get('hours', '2')))\n  elif date == 'day':\n    ret.append('in the last day')\n  elif date == 'week':\n    ret.append('in the last week')\n  elif date == 'month':\n    ret.append('in the last month')\n  elif date == 'all':\n    ret.append('since the beginning of time')\n  elif date == 'explicit':\n    mindate = request.query_dict.get('mindate', '')\n    maxdate = request.query_dict.get('maxdate', '')\n    if mindate and maxdate:\n      w1, w2 = 'between', 'and'\n    else:\n      w1, w2 = 'since', 'before'\n    if mindate:\n      mindate = make_time_string(parse_date(mindate), cfg)\n      ret.append('%s <em>%s</em> ' % (w1, mindate))\n    if maxdate:\n      maxdate = make_time_string(parse_date(maxdate), cfg)\n      ret.append('%s <em>%s</em> ' % (w2, maxdate))\n  return ''.join(ret)\n\ndef prev_rev(rev):\n  \"\"\"Returns a string representing the previous revision of the argument.\"\"\"\n  r = rev.split('.')\n  # decrement final revision component\n  r[-1] = str(int(r[-1]) - 1)\n  # prune if we pass the beginning of the branch\n  if len(r) > 2 and r[-1] == '0':\n    r = r[:-2]\n  return '.'.join(r)\n\ndef build_commit(request, files, max_files, dir_strip, format):\n  \"\"\"Return a commit object build from the information in FILES, or\n  None if no allowed files are present in the set.  DIR_STRIP is the\n  path prefix to remove from the commit object's set of files.  If\n  MAX_FILES is non-zero, it is used to limit the number of files\n  returned in the commit object.  FORMAT is the requested output\n  format of the query request.\"\"\"\n\n  cfg = request.cfg\n  author = files[0].GetAuthor()\n  date = files[0].GetTime()\n  desc = files[0].GetDescription()\n  commit_rev = files[0].GetRevision()\n  len_strip = len(dir_strip)\n  commit_files = []\n  num_allowed = 0\n  plus_count = 0\n  minus_count = 0\n  found_unreadable = 0\n  \n  for f in files:\n    dirname = f.GetDirectory()\n    filename = f.GetFile()\n    if dir_strip:\n      assert dirname[:len_strip] == dir_strip\n      assert len(dirname) == len_strip or dirname[len(dir_strip)] == '/'\n      dirname = dirname[len_strip+1:]\n    where = dirname and (\"%s/%s\" % (dirname, filename)) or filename\n    rev = f.GetRevision()\n    rev_prev = prev_rev(rev)\n    commit_time = f.GetTime()\n    if commit_time:\n      commit_time = make_time_string(commit_time, cfg)\n    change_type = f.GetTypeString()\n\n    # In CVS, we can actually look at deleted revisions; in Subversion\n    # we can't -- we'll look at the previous revision instead.\n    exam_rev = rev\n    if request.roottype == 'svn' and change_type == 'Remove':\n      exam_rev = rev_prev\n\n    # Check path access (since the commits database logic bypasses the\n    # vclib layer and, thus, the vcauth stuff that layer uses).\n    path_parts = _path_parts(where)\n    if path_parts:\n      # Skip files in CVSROOT if asked to hide such.\n      if cfg.options.hide_cvsroot \\\n         and is_cvsroot_path(request.roottype, path_parts):\n        found_unreadable = 1\n        continue\n      \n      # We have to do a rare authz check here because this data comes\n      # from the CVSdb, not from the vclib providers.\n      #\n      # WARNING: The Subversion CVSdb integration logic is weak, weak,\n      # weak.  It has no ability to track copies, so complex\n      # situations like a copied directory with a deleted subfile (all\n      # in the same revision) are very ... difficult.  We've no choice\n      # but to omit as unauthorized paths the authorization logic\n      # can't find.\n      try:\n        readable = vclib.check_path_access(request.repos, path_parts,\n                                           None, exam_rev)\n      except vclib.ItemNotFound:\n        readable = 0\n      if not readable:\n        found_unreadable = 1\n        continue\n         \n    if request.roottype == 'svn':\n      params = { 'pathrev': exam_rev }\n    else:\n      params = { 'revision': exam_rev, 'pathrev': f.GetBranch() or None }  \n    \n    dir_href = request.get_url(view_func=view_directory,\n                               where=dirname, pathtype=vclib.DIR,\n                               params=params, escape=1)\n    log_href = request.get_url(view_func=view_log,\n                               where=where, pathtype=vclib.FILE,\n                               params=params, escape=1)\n    diff_href = view_href = download_href = None\n    if 'markup' in cfg.options.allowed_views:\n      view_href = request.get_url(view_func=view_markup,\n                                  where=where, pathtype=vclib.FILE,\n                                  params=params, escape=1)\n    if 'co' in cfg.options.allowed_views:\n      download_href = request.get_url(view_func=view_checkout,\n                                      where=where, pathtype=vclib.FILE,\n                                      params=params, escape=1)\n    if change_type == 'Change':\n      diff_href_params = params.copy()\n      diff_href_params.update({\n        'r1': rev_prev,\n        'r2': rev,\n        'diff_format': None\n        })\n      diff_href = request.get_url(view_func=view_diff,\n                                  where=where, pathtype=vclib.FILE,\n                                  params=diff_href_params, escape=1)\n    mime_type, encoding = calculate_mime_type(request, path_parts, exam_rev)\n    prefer_markup = ezt.boolean(default_view(mime_type, cfg) == view_markup)\n\n    # Update plus/minus line change count.\n    plus = int(f.GetPlusCount())\n    minus = int(f.GetMinusCount())\n    plus_count = plus_count + plus\n    minus_count = minus_count + minus\n    \n    num_allowed = num_allowed + 1\n    if max_files and num_allowed > max_files:\n      continue\n\n    commit_files.append(_item(date=commit_time,\n                              dir=request.server.escape(dirname),\n                              file=request.server.escape(filename),\n                              author=request.server.escape(f.GetAuthor()),\n                              rev=rev,\n                              branch=f.GetBranch(),\n                              plus=plus,\n                              minus=minus,\n                              type=change_type,\n                              dir_href=dir_href,\n                              log_href=log_href,\n                              view_href=view_href,\n                              download_href=download_href,\n                              prefer_markup=prefer_markup,\n                              diff_href=diff_href))\n\n  # No files survived authz checks?  Let's just pretend this\n  # little commit didn't happen, shall we?\n  if not len(commit_files):\n    return None\n\n  commit = _item(num_files=len(commit_files), files=commit_files,\n                 plus=plus_count, minus=minus_count)\n  commit.limited_files = ezt.boolean(num_allowed > len(commit_files))\n\n  # We'll mask log messages in commits which contain unreadable paths,\n  # but even that is kinda iffy.  If a person searches for\n  # '/some/hidden/path' across log messages, then gets a response set\n  # that shows commits lacking log message, said person can reasonably\n  # assume that the log messages contained the hidden path, and that\n  # this is likely because they are referencing a real path in the\n  # repository -- a path the user isn't supposed to even know about.\n  if found_unreadable:\n    commit.log = None\n    commit.short_log = None\n  else:\n    lf = LogFormatter(request, desc)\n    htmlize = (format != 'rss')\n    commit.log = lf.get(maxlen=0, htmlize=htmlize)\n    commit.short_log = lf.get(maxlen=cfg.options.short_log_len, htmlize=htmlize)\n  commit.author = request.server.escape(author)\n  commit.rss_date = make_rss_time_string(date, request.cfg)\n  if request.roottype == 'svn':\n    commit.rev = commit_rev\n    commit.rss_url = '%s://%s%s' % \\\n      (request.server.getenv(\"HTTPS\") == \"on\" and \"https\" or \"http\",\n       request.server.getenv(\"HTTP_HOST\"),\n       request.get_url(view_func=view_revision,\n                       params={'revision': commit.rev},\n                       escape=1))\n  else:\n    commit.rev = None\n    commit.rss_url = None\n  return commit\n\ndef query_backout(request, commits):\n  server_fp = get_writeready_server_file(request, 'text/plain')\n  if not commits:\n    server_fp.write(\"\"\"\\\n# No changes were selected by the query.\n# There is nothing to back out.\n\"\"\")\n    return\n  server_fp.write(\"\"\"\\\n# This page can be saved as a shell script and executed.\n# It should be run at the top of your work area.  It will update\n# your working copy to back out the changes selected by the\n# query.\n\"\"\")\n  for commit in commits:\n    for fileinfo in commit.files:\n      if request.roottype == 'cvs':\n        server_fp.write('cvs update -j %s -j %s %s/%s\\n'\n                        % (fileinfo.rev, prev_rev(fileinfo.rev),\n                           fileinfo.dir, fileinfo.file))\n      elif request.roottype == 'svn':\n        server_fp.write('svn merge -r %s:%s %s/%s\\n'\n                        % (fileinfo.rev, prev_rev(fileinfo.rev),\n                           fileinfo.dir, fileinfo.file))\n\ndef view_query(request):\n  if not is_query_supported(request):\n    raise debug.ViewVCException('Can not query project root \"%s\" at \"%s\".'\n                                 % (request.rootname, request.where),\n                                 '403 Forbidden')\n\n  cfg = request.cfg\n\n  # Do some more precise input validation.\n  validate_query_args(request)\n\n  # get form data\n  branch = request.query_dict.get('branch', '')\n  branch_match = request.query_dict.get('branch_match', 'exact')\n  dir = request.query_dict.get('dir', '')\n  file = request.query_dict.get('file', '')\n  file_match = request.query_dict.get('file_match', 'exact')\n  who = request.query_dict.get('who', '')\n  who_match = request.query_dict.get('who_match', 'exact')\n  comment = request.query_dict.get('comment', '')\n  comment_match = request.query_dict.get('comment_match', 'exact')\n  querysort = request.query_dict.get('querysort', 'date')\n  date = request.query_dict.get('date', 'hours')\n  hours = request.query_dict.get('hours', '2')\n  mindate = request.query_dict.get('mindate', '')\n  maxdate = request.query_dict.get('maxdate', '')\n  format = request.query_dict.get('format')\n  limit_changes = int(request.query_dict.get('limit_changes',\n                                             cfg.options.limit_changes))\n\n  match_types = { 'exact':1, 'like':1, 'glob':1, 'regex':1, 'notregex':1 }\n  sort_types = { 'date':1, 'author':1, 'file':1 }\n  date_types = { 'hours':1, 'day':1, 'week':1, 'month':1,\n                 'all':1, 'explicit':1 }\n\n  # parse various fields, validating or converting them\n  if not match_types.has_key(branch_match): branch_match = 'exact'\n  if not match_types.has_key(file_match): file_match = 'exact'\n  if not match_types.has_key(who_match): who_match = 'exact'\n  if not match_types.has_key(comment_match): comment_match = 'exact'\n  if not sort_types.has_key(querysort): querysort = 'date'\n  if not date_types.has_key(date): date = 'hours'\n  mindate = parse_date(mindate)\n  maxdate = parse_date(maxdate)\n\n  global cvsdb\n  import cvsdb\n\n  db = cvsdb.ConnectDatabaseReadOnly(cfg)\n  repos_root, repos_dir = cvsdb.FindRepository(db, request.rootpath)\n  if not repos_root:\n    raise debug.ViewVCException(\n      \"The root '%s' was not found in the commit database \"\n      % request.rootname)\n\n  # create the database query from the form data\n  query = cvsdb.CreateCheckinQuery()\n  query.SetRepository(repos_root)\n  # treat \"HEAD\" specially ...\n  if branch_match == 'exact' and branch == 'HEAD':\n    query.SetBranch('')\n  elif branch:\n    query.SetBranch(branch, branch_match)\n  if dir:\n    for subdir in dir.split(','):\n      path = (_path_join(repos_dir + request.path_parts\n                         + _path_parts(subdir.strip())))\n      query.SetDirectory(path, 'exact')\n      query.SetDirectory('%s/%%' % cvsdb.EscapeLike(path), 'like')\n  else:\n    where = _path_join(repos_dir + request.path_parts)\n    if where: # if we are in a subdirectory ...\n      query.SetDirectory(where, 'exact')\n      query.SetDirectory('%s/%%' % cvsdb.EscapeLike(where), 'like')\n  if file:\n    query.SetFile(file, file_match)\n  if who:\n    query.SetAuthor(who, who_match)\n  if comment:\n    query.SetComment(comment, comment_match)\n  query.SetSortMethod(querysort)\n  if date == 'hours':\n    query.SetFromDateHoursAgo(int(hours))\n  elif date == 'day':\n    query.SetFromDateDaysAgo(1)\n  elif date == 'week':\n    query.SetFromDateDaysAgo(7)\n  elif date == 'month':\n    query.SetFromDateDaysAgo(31)\n  elif date == 'all':\n    pass\n  elif date == 'explicit':\n    if mindate is not None:\n      query.SetFromDateObject(mindate)\n    if maxdate is not None:\n      query.SetToDateObject(maxdate)\n\n  # Set the admin-defined (via configuration) row limits.  This is to avoid\n  # slamming the database server with a monster query.\n  if format == 'rss':\n    query.SetLimit(cfg.cvsdb.rss_row_limit)\n  else:\n    query.SetLimit(cfg.cvsdb.row_limit)\n\n  # run the query\n  db.RunQuery(query)\n  commit_list = query.GetCommitList()\n  row_limit_reached = query.GetLimitReached()\n  \n  # gather commits\n  commits = []\n  plus_count = 0\n  minus_count = 0\n  mod_time = -1\n  if commit_list:\n    files = []\n    limited_files = 0\n    current_desc = commit_list[0].GetDescriptionID()\n    current_rev = commit_list[0].GetRevision()\n    dir_strip = _path_join(repos_dir)\n\n    for commit in commit_list:\n      commit_desc = commit.GetDescriptionID()\n      commit_rev = commit.GetRevision()\n\n      # base modification time on the newest commit\n      if commit.GetTime() > mod_time:\n        mod_time = commit.GetTime()\n        \n      # For CVS, group commits with the same commit message.\n      # For Subversion, group them only if they have the same revision number\n      if request.roottype == 'cvs':\n        if current_desc == commit_desc:\n          files.append(commit)\n          continue\n      else:\n        if current_rev == commit_rev:\n          files.append(commit)\n          continue\n\n      # append this grouping\n      commit_item = build_commit(request, files, limit_changes,\n                                 dir_strip, format)\n      if commit_item:\n        # update running plus/minus totals\n        plus_count = plus_count + commit_item.plus\n        minus_count = minus_count + commit_item.minus\n        commits.append(commit_item)\n\n      files = [ commit ]\n      limited_files = 0\n      current_desc = commit_desc\n      current_rev = commit_rev\n      \n    # we need to tack on our last commit grouping, if any\n    commit_item = build_commit(request, files, limit_changes,\n                               dir_strip, format)\n    if commit_item:\n      # update running plus/minus totals\n      plus_count = plus_count + commit_item.plus\n      minus_count = minus_count + commit_item.minus\n      commits.append(commit_item)\n  \n  # only show the branch column if we are querying all branches\n  # or doing a non-exact branch match on a CVS repository.\n  show_branch = ezt.boolean(request.roottype == 'cvs' and\n                            (branch == '' or branch_match != 'exact'))\n\n  # backout link\n  params = request.query_dict.copy()\n  params['format'] = 'backout'\n  backout_href = request.get_url(params=params,\n                                 escape=1)\n\n  # link to zero limit_changes value\n  params = request.query_dict.copy()\n  params['limit_changes'] = 0\n  limit_changes_href = request.get_url(params=params, escape=1)\n\n  # if we got any results, use the newest commit as the modification time\n  if mod_time >= 0:\n    if check_freshness(request, mod_time):\n      return\n\n  if format == 'backout':\n    query_backout(request, commits)\n    return\n\n  data = common_template_data(request)\n  data.merge(TemplateData({\n    'sql': request.server.escape(db.CreateSQLQueryString(query)),\n    'english_query': english_query(request),\n    'queryform_href': request.get_url(view_func=view_queryform, escape=1),\n    'backout_href': backout_href,\n    'plus_count': plus_count,\n    'minus_count': minus_count,\n    'show_branch': show_branch,\n    'querysort': querysort,\n    'commits': commits,\n    'row_limit_reached' : ezt.boolean(row_limit_reached),\n    'limit_changes': limit_changes,\n    'limit_changes_href': limit_changes_href,\n    'rss_link_href': request.get_url(view_func=view_query,\n                                     params={'date': 'month'},\n                                     escape=1,\n                                     prefix=1),\n    }))\n  if format == 'rss':\n    generate_page(request, \"rss\", data, \"application/rss+xml\")\n  else:\n    generate_page(request, \"query_results\", data)\n\n_views = {\n  'annotate':  view_annotate,\n  'co':        view_checkout,\n  'diff':      view_diff,\n  'dir':       view_directory,\n  'graph':     view_cvsgraph,\n  'graphimg':  view_cvsgraph_image,\n  'log':       view_log,\n  'markup':    view_markup,\n  'patch':     view_patch,\n  'query':     view_query,\n  'queryform': view_queryform,\n  'revision':  view_revision,\n  'roots':     view_roots,\n  'tar':       download_tarball,\n  'redirect_pathrev': redirect_pathrev,\n}\n\n_view_codes = {}\nfor code, view in _views.items():\n  _view_codes[view] = code\n\ndef list_roots(request):\n  cfg = request.cfg\n  allroots = { }\n  \n  # Add the viewable Subversion roots\n  for root in cfg.general.svn_roots.keys():\n    auth = setup_authorizer(cfg, request.username, root)\n    try:\n      repos = vclib.svn.SubversionRepository(root, cfg.general.svn_roots[root],\n                                             auth, cfg.utilities,\n                                             cfg.options.svn_config_dir)\n      lastmod = None\n      if cfg.options.show_roots_lastmod:\n        try:\n          repos.open()\n          youngest_rev = repos.youngest\n          date, author, msg, revprops, changes = repos.revinfo(youngest_rev)\n          date_str = make_time_string(date, cfg)\n          ago = html_time(request, date)\n          lf = LogFormatter(request, msg)\n          log = lf.get(maxlen=0, htmlize=1)\n          short_log = lf.get(maxlen=cfg.options.short_log_len, htmlize=1)\n          lastmod = _item(ago=ago, author=author, date=date_str, log=log,\n                          short_log=short_log, rev=str(youngest_rev))\n        except:\n          lastmod = None\n    except vclib.ReposNotFound:\n      continue\n    allroots[root] = [cfg.general.svn_roots[root], 'svn', lastmod]\n\n  # Add the viewable CVS roots\n  for root in cfg.general.cvs_roots.keys():\n    auth = setup_authorizer(cfg, request.username, root)\n    try:\n      vclib.ccvs.CVSRepository(root, cfg.general.cvs_roots[root], auth,\n                               cfg.utilities, cfg.options.use_rcsparse)\n    except vclib.ReposNotFound:\n      continue\n    allroots[root] = [cfg.general.cvs_roots[root], 'cvs', None]\n    \n  return allroots\n\ndef _parse_root_parent(pp):\n  \"\"\"Parse a single root parent \"directory [= context] : repo_type\" string\n  and return as tuple.\"\"\"\n\n  pos = pp.rfind(':')\n  if pos > 0:\n    repo_type = pp[pos+1:].strip()\n    pp = pp[:pos].strip()\n  else:\n    repo_type = None\n\n  pos = pp.rfind('=')\n  if pos > 0:\n    context = _path_parts(pp[pos+1:].strip())\n    pp = pp[:pos].strip()\n  else:\n    context = None\n\n  path = os.path.normpath(pp)\n  return path,context,repo_type\n\ndef expand_root_parents(cfg):\n  \"\"\"Expand the configured root parents into individual roots.\"\"\"\n  \n  # Each item in root_parents is a \"directory [= context ] : repo_type\" string.\n  for pp in cfg.general.root_parents:\n    path,context,repo_type = _parse_root_parent(pp)\n\n    if repo_type == 'cvs':\n      roots = vclib.ccvs.expand_root_parent(path)\n      if cfg.options.hide_cvsroot and roots.has_key('CVSROOT'):\n        del roots['CVSROOT']\n      if context:\n        fullroots = {}\n        for root, rootpath in roots.iteritems():\n          fullroots[_path_join(context + [root])] = rootpath\n        cfg.general.cvs_roots.update(fullroots)\n      else:\n        cfg.general.cvs_roots.update(roots)\n    elif repo_type == 'svn':\n      roots = vclib.svn.expand_root_parent(path)\n      if context:\n        fullroots = {}\n        for root, rootpath in roots.iteritems():\n          fullroots[_path_join(context + [root])] = rootpath\n        cfg.general.svn_roots.update(fullroots)\n      else:\n        cfg.general.svn_roots.update(roots)\n    elif repo_type == None:\n      raise debug.ViewVCException(\n        'The path \"%s\" in \"root_parents\" does not include a '\n        'repository type.  Expected \"cvs\" or \"svn\".' % (pp))\n    else:\n      raise debug.ViewVCException(\n        'The path \"%s\" in \"root_parents\" has an unrecognized '\n        'repository type (\"%s\").  Expected \"cvs\" or \"svn\".'\n        % (pp, repo_type))\n\ndef find_root_in_parents(cfg, path_parts, roottype):\n  \"\"\"Return the rootpath for configured ROOTNAME of ROOTTYPE.\"\"\"\n\n  # Easy out:  caller wants rootname \"CVSROOT\", and we're hiding those.\n  if path_parts[-1] == 'CVSROOT' and cfg.options.hide_cvsroot:\n    return None\n\n  for pp in cfg.general.root_parents:\n    path,context,repo_type = _parse_root_parent(pp)\n\n    if repo_type != roottype:\n      continue\n    if context != None:\n      if not _path_starts_with(path_parts, context):\n        continue\n      rootidx = len(context)\n    else:\n      rootidx = 0\n\n    if len(path_parts) <= rootidx:\n      continue\n\n    rootname = path_parts[rootidx]\n    fullroot = _path_join(path_parts[0:rootidx+1])\n    remain = path_parts[rootidx+1:]\n\n    rootpath = None\n    if roottype == 'cvs':\n      rootpath = vclib.ccvs.find_root_in_parent(path, rootname)\n    elif roottype == 'svn':\n      rootpath = vclib.svn.find_root_in_parent(path, rootname)\n\n    if rootpath is not None:\n      return fullroot, rootpath, remain\n  return None, None, None\n\ndef locate_root_from_path(cfg, path_parts):\n  \"\"\"Return a 4-tuple ROOTTYPE, ROOTPATH, ROOTNAME, REMAIN for path_parts.\"\"\"\n  for rootname, rootpath in cfg.general.cvs_roots.iteritems():\n    pp = _path_parts(rootname)\n    if _path_starts_with(path_parts, pp):\n      return 'cvs', rootpath, rootname, path_parts[len(pp):]\n  for rootname, rootpath in cfg.general.svn_roots.iteritems():\n    pp = _path_parts(rootname)\n    if _path_starts_with(path_parts, pp):\n      return 'svn', rootpath, rootname, path_parts[len(pp):]\n  rootname, path_in_parent, remain = \\\n          find_root_in_parents(cfg, path_parts, 'cvs')\n  if path_in_parent:\n    cfg.general.cvs_roots[rootname] = path_in_parent\n    return 'cvs', path_in_parent, rootname, remain\n  rootname, path_in_parent, remain = \\\n          find_root_in_parents(cfg, path_parts, 'svn')\n  if path_in_parent:\n    cfg.general.svn_roots[rootname] = path_in_parent\n    return 'svn', path_in_parent, rootname, remain\n  return None, None, None, None\n\ndef locate_root(cfg, rootname):\n  \"\"\"Return a 2-tuple ROOTTYPE, ROOTPATH for configured ROOTNAME.\"\"\"\n  # First try a direct match\n  if cfg.general.cvs_roots.has_key(rootname):\n    return 'cvs', cfg.general.cvs_roots[rootname]\n  if cfg.general.svn_roots.has_key(rootname):\n    return 'svn', cfg.general.svn_roots[rootname]\n\n  path_parts = _path_parts(rootname)\n  roottype, rootpath, rootname_dupl, remain = \\\n          locate_root_from_path(cfg, path_parts)\n  if roottype != None:\n    if rootname_dupl != rootname:\n      raise debug.ViewVCException(\n        'Found root name \"%s\" doesn\\'t match \"%s\"' \\\n        % (rootname_dupl, rootname),\n        '500 Internal Server Error')\n    if len(remain) > 0:\n      raise debug.ViewVCException(\n        'Have remaining path \"%s\"' \\\n        % (remain),\n        '500 Internal Server Error')\n  return roottype, rootpath\n\ndef load_config(pathname=None, server=None):\n  \"\"\"Load the ViewVC configuration file.  SERVER is the server object\n  that will be using this configuration.  Consult the environment for\n  the variable VIEWVC_CONF_PATHNAME and VIEWCVS_CONF_PATHNAME (its\n  legacy name) and, if set, use its value as the path of the\n  configuration file; otherwise, use PATHNAME (if provided).  Failing\n  all else, use a hardcoded default configuration path.\"\"\"\n  \n  debug.t_start('load-config')\n\n  # See if the environment contains overrides to the configuration\n  # path.  If we have a SERVER object, consult its environment; use\n  # the OS environment otherwise.\n  env_get = server and server.getenv or os.environ.get\n  env_pathname = (env_get(\"VIEWVC_CONF_PATHNAME\")\n                  or env_get(\"VIEWCVS_CONF_PATHNAME\"))\n\n  # Try to find the configuration pathname by searching these ordered\n  # locations: the environment, the passed-in PATHNAME, the hard-coded\n  # default.\n  pathname = (env_pathname\n              or pathname\n              or os.path.join(os.path.dirname(os.path.dirname(__file__)),\n                              \"viewvc.conf\"))\n\n  # Load the configuration!\n  cfg = config.Config()\n  cfg.set_defaults()\n  cfg.load_config(pathname, env_get(\"HTTP_HOST\"))\n\n  # Apply the stacktrace configuration immediately.\n  sys.tracebacklimit = cfg.options.stacktraces and 1000 or 0\n\n  # Load mime types file(s), but reverse the order -- our\n  # configuration uses a most-to-least preferred approach, but the\n  # 'mimetypes' package wants things the other way around.\n  if cfg.general.mime_types_files:\n    files = cfg.general.mime_types_files[:]\n    files.reverse()\n    files = map(lambda x, y=pathname: os.path.join(os.path.dirname(y), x), files)\n    mimetypes.init(files)\n\n  debug.t_end('load-config')\n  return cfg\n\n\ndef view_error(server, cfg):\n  exc_dict = debug.GetExceptionData()\n  status = exc_dict['status']\n  if exc_dict['msg']:\n    exc_dict['msg'] = server.escape(exc_dict['msg'])\n  if exc_dict['stacktrace']:\n    exc_dict['stacktrace'] = server.escape(exc_dict['stacktrace'])\n\n  # Use the configured error template if possible.\n  try:\n    if cfg and not server.headerSent:\n      server.header(status=status)\n      template = get_view_template(cfg, \"error\")\n      template.generate(server.file(), exc_dict)\n      return\n  except:\n    pass\n\n  # Fallback to the old exception printer if no configuration is\n  # available, or if something went wrong.\n  debug.PrintException(server, exc_dict)\n\ndef main(server, cfg):\n  try:\n    debug.t_start('main')\n    try:\n      # build a Request object, which contains info about the HTTP request\n      request = Request(server, cfg)\n      request.run_viewvc()\n    except SystemExit, e:\n      return\n    except:\n      view_error(server, cfg)\n\n  finally:\n    debug.t_end('main')\n    debug.t_dump(server.file())\n    debug.DumpChildren(server)\n"], "filenames": ["lib/viewvc.py"], "buggy_code_start_loc": [2415], "buggy_code_end_loc": [2416], "fixing_code_start_loc": [2415], "fixing_code_end_loc": [2416], "type": "CWE-79", "message": "ViewVC before versions 1.1.28 and 1.2.1 has a XSS vulnerability in CVS show_subdir_lastmod support. The impact of this vulnerability is mitigated by the need for an attacker to have commit privileges to a CVS repository exposed by an otherwise trusted ViewVC instance that also has the `show_subdir_lastmod` feature enabled. The attack vector involves files with unsafe names (names that, when embedded into an HTML stream, would cause the browser to run unwanted code), which themselves can be challenging to create. This vulnerability is patched in versions 1.2.1 and 1.1.28.", "other": {"cve": {"id": "CVE-2020-5283", "sourceIdentifier": "security-advisories@github.com", "published": "2020-04-03T00:15:11.943", "lastModified": "2020-05-15T06:15:11.460", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "ViewVC before versions 1.1.28 and 1.2.1 has a XSS vulnerability in CVS show_subdir_lastmod support. The impact of this vulnerability is mitigated by the need for an attacker to have commit privileges to a CVS repository exposed by an otherwise trusted ViewVC instance that also has the `show_subdir_lastmod` feature enabled. The attack vector involves files with unsafe names (names that, when embedded into an HTML stream, would cause the browser to run unwanted code), which themselves can be challenging to create. This vulnerability is patched in versions 1.2.1 and 1.1.28."}, {"lang": "es", "value": "ViewVC versiones anteriores a 1.1.28 y 1.2.1, presenta una vulnerabilidad de tipo XSS en el soporte show_subdir_lastmod de CVS. El impacto de esta vulnerabilidad est\u00e1 mitigado mediante la necesidad de que un atacante tenga privilegios de commit en un repositorio CVS expuesto por una instancia de ViewVC confiable que tambi\u00e9n tenga la funcionalidad \"show_subdir_lastmod\" habilitada. El vector de ataque involucra archivos con nombres no seguros (nombres que, cuando se insertan en una secuencia de datos HTML, causar\u00edan que el navegador ejecute un c\u00f3digo no deseado), que pueden ser en si mismos dif\u00edciles de crear. Esta vulnerabilidad est\u00e1 parcheada en las versiones 1.2.1 y 1.1.28."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:H/UI:R/S:U/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "HIGH", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 3.5, "baseSeverity": "LOW"}, "exploitabilityScore": 0.9, "impactScore": 2.5}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:H/UI:R/S:U/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "HIGH", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 3.1, "baseSeverity": "LOW"}, "exploitabilityScore": 0.5, "impactScore": 2.5}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:H/Au:S/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "HIGH", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-79"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-80"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:viewvc:viewvc:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.1.28", "matchCriteriaId": "317FCBFB-4761-4735-8367-4AE5D03AB998"}, {"vulnerable": true, "criteria": "cpe:2.3:a:viewvc:viewvc:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.2.0", "versionEndExcluding": "1.2.1", "matchCriteriaId": "0C4C4AE3-6765-4AD4-991F-EF3F0B3EF39E"}]}]}], "references": [{"url": "https://github.com/viewvc/viewvc/commit/ad0f966e9a997b17d853a6972ea283d4dcd70fa8", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/viewvc/viewvc/issues/211", "source": "security-advisories@github.com", "tags": ["Exploit", "Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/viewvc/viewvc/security/advisories/GHSA-xpxf-fvqv-7mfg", "source": "security-advisories@github.com", "tags": ["Mitigation", "Patch", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/2Q2STF2MKT24HXZ3YZIU7CN6F6QM67I5/", "source": "security-advisories@github.com"}]}, "github_commit_url": "https://github.com/viewvc/viewvc/commit/ad0f966e9a997b17d853a6972ea283d4dcd70fa8"}}
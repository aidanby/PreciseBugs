{"buggy_code": ["#include <trace/syscall.h>\n#include <trace/events/syscalls.h>\n#include <linux/syscalls.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\t/* for MODULE_NAME_LEN via KSYM_SYMBOL_LEN */\n#include <linux/ftrace.h>\n#include <linux/perf_event.h>\n#include <asm/syscall.h>\n\n#include \"trace_output.h\"\n#include \"trace.h\"\n\nstatic DEFINE_MUTEX(syscall_trace_lock);\n\nstatic int syscall_enter_register(struct ftrace_event_call *event,\n\t\t\t\t enum trace_reg type, void *data);\nstatic int syscall_exit_register(struct ftrace_event_call *event,\n\t\t\t\t enum trace_reg type, void *data);\n\nstatic struct list_head *\nsyscall_get_enter_fields(struct ftrace_event_call *call)\n{\n\tstruct syscall_metadata *entry = call->data;\n\n\treturn &entry->enter_fields;\n}\n\nextern struct syscall_metadata *__start_syscalls_metadata[];\nextern struct syscall_metadata *__stop_syscalls_metadata[];\n\nstatic struct syscall_metadata **syscalls_metadata;\n\n#ifndef ARCH_HAS_SYSCALL_MATCH_SYM_NAME\nstatic inline bool arch_syscall_match_sym_name(const char *sym, const char *name)\n{\n\t/*\n\t * Only compare after the \"sys\" prefix. Archs that use\n\t * syscall wrappers may have syscalls symbols aliases prefixed\n\t * with \".SyS\" or \".sys\" instead of \"sys\", leading to an unwanted\n\t * mismatch.\n\t */\n\treturn !strcmp(sym + 3, name + 3);\n}\n#endif\n\n#ifdef ARCH_TRACE_IGNORE_COMPAT_SYSCALLS\n/*\n * Some architectures that allow for 32bit applications\n * to run on a 64bit kernel, do not map the syscalls for\n * the 32bit tasks the same as they do for 64bit tasks.\n *\n *     *cough*x86*cough*\n *\n * In such a case, instead of reporting the wrong syscalls,\n * simply ignore them.\n *\n * For an arch to ignore the compat syscalls it needs to\n * define ARCH_TRACE_IGNORE_COMPAT_SYSCALLS as well as\n * define the function arch_trace_is_compat_syscall() to let\n * the tracing system know that it should ignore it.\n */\nstatic int\ntrace_get_syscall_nr(struct task_struct *task, struct pt_regs *regs)\n{\n\tif (unlikely(arch_trace_is_compat_syscall(regs)))\n\t\treturn -1;\n\n\treturn syscall_get_nr(task, regs);\n}\n#else\nstatic inline int\ntrace_get_syscall_nr(struct task_struct *task, struct pt_regs *regs)\n{\n\treturn syscall_get_nr(task, regs);\n}\n#endif /* ARCH_TRACE_IGNORE_COMPAT_SYSCALLS */\n\nstatic __init struct syscall_metadata *\nfind_syscall_meta(unsigned long syscall)\n{\n\tstruct syscall_metadata **start;\n\tstruct syscall_metadata **stop;\n\tchar str[KSYM_SYMBOL_LEN];\n\n\n\tstart = __start_syscalls_metadata;\n\tstop = __stop_syscalls_metadata;\n\tkallsyms_lookup(syscall, NULL, NULL, NULL, str);\n\n\tif (arch_syscall_match_sym_name(str, \"sys_ni_syscall\"))\n\t\treturn NULL;\n\n\tfor ( ; start < stop; start++) {\n\t\tif ((*start)->name && arch_syscall_match_sym_name(str, (*start)->name))\n\t\t\treturn *start;\n\t}\n\treturn NULL;\n}\n\nstatic struct syscall_metadata *syscall_nr_to_meta(int nr)\n{\n\tif (!syscalls_metadata || nr >= NR_syscalls || nr < 0)\n\t\treturn NULL;\n\n\treturn syscalls_metadata[nr];\n}\n\nstatic enum print_line_t\nprint_syscall_enter(struct trace_iterator *iter, int flags,\n\t\t    struct trace_event *event)\n{\n\tstruct trace_seq *s = &iter->seq;\n\tstruct trace_entry *ent = iter->ent;\n\tstruct syscall_trace_enter *trace;\n\tstruct syscall_metadata *entry;\n\tint i, ret, syscall;\n\n\ttrace = (typeof(trace))ent;\n\tsyscall = trace->nr;\n\tentry = syscall_nr_to_meta(syscall);\n\n\tif (!entry)\n\t\tgoto end;\n\n\tif (entry->enter_event->event.type != ent->type) {\n\t\tWARN_ON_ONCE(1);\n\t\tgoto end;\n\t}\n\n\tret = trace_seq_printf(s, \"%s(\", entry->name);\n\tif (!ret)\n\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\n\tfor (i = 0; i < entry->nb_args; i++) {\n\t\t/* parameter types */\n\t\tif (trace_flags & TRACE_ITER_VERBOSE) {\n\t\t\tret = trace_seq_printf(s, \"%s \", entry->types[i]);\n\t\t\tif (!ret)\n\t\t\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\t\t}\n\t\t/* parameter values */\n\t\tret = trace_seq_printf(s, \"%s: %lx%s\", entry->args[i],\n\t\t\t\t       trace->args[i],\n\t\t\t\t       i == entry->nb_args - 1 ? \"\" : \", \");\n\t\tif (!ret)\n\t\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\t}\n\n\tret = trace_seq_putc(s, ')');\n\tif (!ret)\n\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\nend:\n\tret =  trace_seq_putc(s, '\\n');\n\tif (!ret)\n\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\n\treturn TRACE_TYPE_HANDLED;\n}\n\nstatic enum print_line_t\nprint_syscall_exit(struct trace_iterator *iter, int flags,\n\t\t   struct trace_event *event)\n{\n\tstruct trace_seq *s = &iter->seq;\n\tstruct trace_entry *ent = iter->ent;\n\tstruct syscall_trace_exit *trace;\n\tint syscall;\n\tstruct syscall_metadata *entry;\n\tint ret;\n\n\ttrace = (typeof(trace))ent;\n\tsyscall = trace->nr;\n\tentry = syscall_nr_to_meta(syscall);\n\n\tif (!entry) {\n\t\ttrace_seq_putc(s, '\\n');\n\t\treturn TRACE_TYPE_HANDLED;\n\t}\n\n\tif (entry->exit_event->event.type != ent->type) {\n\t\tWARN_ON_ONCE(1);\n\t\treturn TRACE_TYPE_UNHANDLED;\n\t}\n\n\tret = trace_seq_printf(s, \"%s -> 0x%lx\\n\", entry->name,\n\t\t\t\ttrace->ret);\n\tif (!ret)\n\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\n\treturn TRACE_TYPE_HANDLED;\n}\n\nextern char *__bad_type_size(void);\n\n#define SYSCALL_FIELD(type, name)\t\t\t\t\t\\\n\tsizeof(type) != sizeof(trace.name) ?\t\t\t\t\\\n\t\t__bad_type_size() :\t\t\t\t\t\\\n\t\t#type, #name, offsetof(typeof(trace), name),\t\t\\\n\t\tsizeof(trace.name), is_signed_type(type)\n\nstatic int __init\n__set_enter_print_fmt(struct syscall_metadata *entry, char *buf, int len)\n{\n\tint i;\n\tint pos = 0;\n\n\t/* When len=0, we just calculate the needed length */\n#define LEN_OR_ZERO (len ? len - pos : 0)\n\n\tpos += snprintf(buf + pos, LEN_OR_ZERO, \"\\\"\");\n\tfor (i = 0; i < entry->nb_args; i++) {\n\t\tpos += snprintf(buf + pos, LEN_OR_ZERO, \"%s: 0x%%0%zulx%s\",\n\t\t\t\tentry->args[i], sizeof(unsigned long),\n\t\t\t\ti == entry->nb_args - 1 ? \"\" : \", \");\n\t}\n\tpos += snprintf(buf + pos, LEN_OR_ZERO, \"\\\"\");\n\n\tfor (i = 0; i < entry->nb_args; i++) {\n\t\tpos += snprintf(buf + pos, LEN_OR_ZERO,\n\t\t\t\t\", ((unsigned long)(REC->%s))\", entry->args[i]);\n\t}\n\n#undef LEN_OR_ZERO\n\n\t/* return the length of print_fmt */\n\treturn pos;\n}\n\nstatic int __init set_syscall_print_fmt(struct ftrace_event_call *call)\n{\n\tchar *print_fmt;\n\tint len;\n\tstruct syscall_metadata *entry = call->data;\n\n\tif (entry->enter_event != call) {\n\t\tcall->print_fmt = \"\\\"0x%lx\\\", REC->ret\";\n\t\treturn 0;\n\t}\n\n\t/* First: called with 0 length to calculate the needed length */\n\tlen = __set_enter_print_fmt(entry, NULL, 0);\n\n\tprint_fmt = kmalloc(len + 1, GFP_KERNEL);\n\tif (!print_fmt)\n\t\treturn -ENOMEM;\n\n\t/* Second: actually write the @print_fmt */\n\t__set_enter_print_fmt(entry, print_fmt, len + 1);\n\tcall->print_fmt = print_fmt;\n\n\treturn 0;\n}\n\nstatic void __init free_syscall_print_fmt(struct ftrace_event_call *call)\n{\n\tstruct syscall_metadata *entry = call->data;\n\n\tif (entry->enter_event == call)\n\t\tkfree(call->print_fmt);\n}\n\nstatic int __init syscall_enter_define_fields(struct ftrace_event_call *call)\n{\n\tstruct syscall_trace_enter trace;\n\tstruct syscall_metadata *meta = call->data;\n\tint ret;\n\tint i;\n\tint offset = offsetof(typeof(trace), args);\n\n\tret = trace_define_field(call, SYSCALL_FIELD(int, nr), FILTER_OTHER);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < meta->nb_args; i++) {\n\t\tret = trace_define_field(call, meta->types[i],\n\t\t\t\t\t meta->args[i], offset,\n\t\t\t\t\t sizeof(unsigned long), 0,\n\t\t\t\t\t FILTER_OTHER);\n\t\toffset += sizeof(unsigned long);\n\t}\n\n\treturn ret;\n}\n\nstatic int __init syscall_exit_define_fields(struct ftrace_event_call *call)\n{\n\tstruct syscall_trace_exit trace;\n\tint ret;\n\n\tret = trace_define_field(call, SYSCALL_FIELD(int, nr), FILTER_OTHER);\n\tif (ret)\n\t\treturn ret;\n\n\tret = trace_define_field(call, SYSCALL_FIELD(long, ret),\n\t\t\t\t FILTER_OTHER);\n\n\treturn ret;\n}\n\nstatic void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id)\n{\n\tstruct trace_array *tr = data;\n\tstruct ftrace_event_file *ftrace_file;\n\tstruct syscall_trace_enter *entry;\n\tstruct syscall_metadata *sys_data;\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer *buffer;\n\tunsigned long irq_flags;\n\tint pc;\n\tint syscall_nr;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\n\t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE) */\n\tftrace_file = rcu_dereference_sched(tr->enter_syscall_files[syscall_nr]);\n\tif (!ftrace_file)\n\t\treturn;\n\n\tif (ftrace_trigger_soft_disabled(ftrace_file))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\tsize = sizeof(*entry) + sizeof(unsigned long) * sys_data->nb_args;\n\n\tlocal_save_flags(irq_flags);\n\tpc = preempt_count();\n\n\tbuffer = tr->trace_buffer.buffer;\n\tevent = trace_buffer_lock_reserve(buffer,\n\t\t\tsys_data->enter_event->event.type, size, irq_flags, pc);\n\tif (!event)\n\t\treturn;\n\n\tentry = ring_buffer_event_data(event);\n\tentry->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args, entry->args);\n\n\tevent_trigger_unlock_commit(ftrace_file, buffer, event, entry,\n\t\t\t\t    irq_flags, pc);\n}\n\nstatic void ftrace_syscall_exit(void *data, struct pt_regs *regs, long ret)\n{\n\tstruct trace_array *tr = data;\n\tstruct ftrace_event_file *ftrace_file;\n\tstruct syscall_trace_exit *entry;\n\tstruct syscall_metadata *sys_data;\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer *buffer;\n\tunsigned long irq_flags;\n\tint pc;\n\tint syscall_nr;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\n\t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE()) */\n\tftrace_file = rcu_dereference_sched(tr->exit_syscall_files[syscall_nr]);\n\tif (!ftrace_file)\n\t\treturn;\n\n\tif (ftrace_trigger_soft_disabled(ftrace_file))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\tlocal_save_flags(irq_flags);\n\tpc = preempt_count();\n\n\tbuffer = tr->trace_buffer.buffer;\n\tevent = trace_buffer_lock_reserve(buffer,\n\t\t\tsys_data->exit_event->event.type, sizeof(*entry),\n\t\t\tirq_flags, pc);\n\tif (!event)\n\t\treturn;\n\n\tentry = ring_buffer_event_data(event);\n\tentry->nr = syscall_nr;\n\tentry->ret = syscall_get_return_value(current, regs);\n\n\tevent_trigger_unlock_commit(ftrace_file, buffer, event, entry,\n\t\t\t\t    irq_flags, pc);\n}\n\nstatic int reg_event_syscall_enter(struct ftrace_event_file *file,\n\t\t\t\t   struct ftrace_event_call *call)\n{\n\tstruct trace_array *tr = file->tr;\n\tint ret = 0;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\n\t\treturn -ENOSYS;\n\tmutex_lock(&syscall_trace_lock);\n\tif (!tr->sys_refcount_enter)\n\t\tret = register_trace_sys_enter(ftrace_syscall_enter, tr);\n\tif (!ret) {\n\t\trcu_assign_pointer(tr->enter_syscall_files[num], file);\n\t\ttr->sys_refcount_enter++;\n\t}\n\tmutex_unlock(&syscall_trace_lock);\n\treturn ret;\n}\n\nstatic void unreg_event_syscall_enter(struct ftrace_event_file *file,\n\t\t\t\t      struct ftrace_event_call *call)\n{\n\tstruct trace_array *tr = file->tr;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\n\t\treturn;\n\tmutex_lock(&syscall_trace_lock);\n\ttr->sys_refcount_enter--;\n\tRCU_INIT_POINTER(tr->enter_syscall_files[num], NULL);\n\tif (!tr->sys_refcount_enter)\n\t\tunregister_trace_sys_enter(ftrace_syscall_enter, tr);\n\tmutex_unlock(&syscall_trace_lock);\n}\n\nstatic int reg_event_syscall_exit(struct ftrace_event_file *file,\n\t\t\t\t  struct ftrace_event_call *call)\n{\n\tstruct trace_array *tr = file->tr;\n\tint ret = 0;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\n\t\treturn -ENOSYS;\n\tmutex_lock(&syscall_trace_lock);\n\tif (!tr->sys_refcount_exit)\n\t\tret = register_trace_sys_exit(ftrace_syscall_exit, tr);\n\tif (!ret) {\n\t\trcu_assign_pointer(tr->exit_syscall_files[num], file);\n\t\ttr->sys_refcount_exit++;\n\t}\n\tmutex_unlock(&syscall_trace_lock);\n\treturn ret;\n}\n\nstatic void unreg_event_syscall_exit(struct ftrace_event_file *file,\n\t\t\t\t     struct ftrace_event_call *call)\n{\n\tstruct trace_array *tr = file->tr;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\n\t\treturn;\n\tmutex_lock(&syscall_trace_lock);\n\ttr->sys_refcount_exit--;\n\tRCU_INIT_POINTER(tr->exit_syscall_files[num], NULL);\n\tif (!tr->sys_refcount_exit)\n\t\tunregister_trace_sys_exit(ftrace_syscall_exit, tr);\n\tmutex_unlock(&syscall_trace_lock);\n}\n\nstatic int __init init_syscall_trace(struct ftrace_event_call *call)\n{\n\tint id;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (num < 0 || num >= NR_syscalls) {\n\t\tpr_debug(\"syscall %s metadata not mapped, disabling ftrace event\\n\",\n\t\t\t\t((struct syscall_metadata *)call->data)->name);\n\t\treturn -ENOSYS;\n\t}\n\n\tif (set_syscall_print_fmt(call) < 0)\n\t\treturn -ENOMEM;\n\n\tid = trace_event_raw_init(call);\n\n\tif (id < 0) {\n\t\tfree_syscall_print_fmt(call);\n\t\treturn id;\n\t}\n\n\treturn id;\n}\n\nstruct trace_event_functions enter_syscall_print_funcs = {\n\t.trace\t\t= print_syscall_enter,\n};\n\nstruct trace_event_functions exit_syscall_print_funcs = {\n\t.trace\t\t= print_syscall_exit,\n};\n\nstruct ftrace_event_class __refdata event_class_syscall_enter = {\n\t.system\t\t= \"syscalls\",\n\t.reg\t\t= syscall_enter_register,\n\t.define_fields\t= syscall_enter_define_fields,\n\t.get_fields\t= syscall_get_enter_fields,\n\t.raw_init\t= init_syscall_trace,\n};\n\nstruct ftrace_event_class __refdata event_class_syscall_exit = {\n\t.system\t\t= \"syscalls\",\n\t.reg\t\t= syscall_exit_register,\n\t.define_fields\t= syscall_exit_define_fields,\n\t.fields\t\t= LIST_HEAD_INIT(event_class_syscall_exit.fields),\n\t.raw_init\t= init_syscall_trace,\n};\n\nunsigned long __init __weak arch_syscall_addr(int nr)\n{\n\treturn (unsigned long)sys_call_table[nr];\n}\n\nstatic int __init init_ftrace_syscalls(void)\n{\n\tstruct syscall_metadata *meta;\n\tunsigned long addr;\n\tint i;\n\n\tsyscalls_metadata = kcalloc(NR_syscalls, sizeof(*syscalls_metadata),\n\t\t\t\t    GFP_KERNEL);\n\tif (!syscalls_metadata) {\n\t\tWARN_ON(1);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < NR_syscalls; i++) {\n\t\taddr = arch_syscall_addr(i);\n\t\tmeta = find_syscall_meta(addr);\n\t\tif (!meta)\n\t\t\tcontinue;\n\n\t\tmeta->syscall_nr = i;\n\t\tsyscalls_metadata[i] = meta;\n\t}\n\n\treturn 0;\n}\nearly_initcall(init_ftrace_syscalls);\n\n#ifdef CONFIG_PERF_EVENTS\n\nstatic DECLARE_BITMAP(enabled_perf_enter_syscalls, NR_syscalls);\nstatic DECLARE_BITMAP(enabled_perf_exit_syscalls, NR_syscalls);\nstatic int sys_perf_refcount_enter;\nstatic int sys_perf_refcount_exit;\n\nstatic void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_enter *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->enter_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* get the size after alignment with the u32 buffer size field */\n\tsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\n\tsize = ALIGN(size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->enter_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\n\t\t\t       (unsigned long *)&rec->args);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}\n\nstatic int perf_sysenter_enable(struct ftrace_event_call *call)\n{\n\tint ret = 0;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\n\tmutex_lock(&syscall_trace_lock);\n\tif (!sys_perf_refcount_enter)\n\t\tret = register_trace_sys_enter(perf_syscall_enter, NULL);\n\tif (ret) {\n\t\tpr_info(\"event trace: Could not activate\"\n\t\t\t\t\"syscall entry trace point\");\n\t} else {\n\t\tset_bit(num, enabled_perf_enter_syscalls);\n\t\tsys_perf_refcount_enter++;\n\t}\n\tmutex_unlock(&syscall_trace_lock);\n\treturn ret;\n}\n\nstatic void perf_sysenter_disable(struct ftrace_event_call *call)\n{\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\n\tmutex_lock(&syscall_trace_lock);\n\tsys_perf_refcount_enter--;\n\tclear_bit(num, enabled_perf_enter_syscalls);\n\tif (!sys_perf_refcount_enter)\n\t\tunregister_trace_sys_enter(perf_syscall_enter, NULL);\n\tmutex_unlock(&syscall_trace_lock);\n}\n\nstatic void perf_syscall_exit(void *ignore, struct pt_regs *regs, long ret)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_exit *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->exit_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* We can probably do that at build time */\n\tsize = ALIGN(sizeof(*rec) + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_exit *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->exit_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\trec->ret = syscall_get_return_value(current, regs);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}\n\nstatic int perf_sysexit_enable(struct ftrace_event_call *call)\n{\n\tint ret = 0;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\n\tmutex_lock(&syscall_trace_lock);\n\tif (!sys_perf_refcount_exit)\n\t\tret = register_trace_sys_exit(perf_syscall_exit, NULL);\n\tif (ret) {\n\t\tpr_info(\"event trace: Could not activate\"\n\t\t\t\t\"syscall exit trace point\");\n\t} else {\n\t\tset_bit(num, enabled_perf_exit_syscalls);\n\t\tsys_perf_refcount_exit++;\n\t}\n\tmutex_unlock(&syscall_trace_lock);\n\treturn ret;\n}\n\nstatic void perf_sysexit_disable(struct ftrace_event_call *call)\n{\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\n\tmutex_lock(&syscall_trace_lock);\n\tsys_perf_refcount_exit--;\n\tclear_bit(num, enabled_perf_exit_syscalls);\n\tif (!sys_perf_refcount_exit)\n\t\tunregister_trace_sys_exit(perf_syscall_exit, NULL);\n\tmutex_unlock(&syscall_trace_lock);\n}\n\n#endif /* CONFIG_PERF_EVENTS */\n\nstatic int syscall_enter_register(struct ftrace_event_call *event,\n\t\t\t\t enum trace_reg type, void *data)\n{\n\tstruct ftrace_event_file *file = data;\n\n\tswitch (type) {\n\tcase TRACE_REG_REGISTER:\n\t\treturn reg_event_syscall_enter(file, event);\n\tcase TRACE_REG_UNREGISTER:\n\t\tunreg_event_syscall_enter(file, event);\n\t\treturn 0;\n\n#ifdef CONFIG_PERF_EVENTS\n\tcase TRACE_REG_PERF_REGISTER:\n\t\treturn perf_sysenter_enable(event);\n\tcase TRACE_REG_PERF_UNREGISTER:\n\t\tperf_sysenter_disable(event);\n\t\treturn 0;\n\tcase TRACE_REG_PERF_OPEN:\n\tcase TRACE_REG_PERF_CLOSE:\n\tcase TRACE_REG_PERF_ADD:\n\tcase TRACE_REG_PERF_DEL:\n\t\treturn 0;\n#endif\n\t}\n\treturn 0;\n}\n\nstatic int syscall_exit_register(struct ftrace_event_call *event,\n\t\t\t\t enum trace_reg type, void *data)\n{\n\tstruct ftrace_event_file *file = data;\n\n\tswitch (type) {\n\tcase TRACE_REG_REGISTER:\n\t\treturn reg_event_syscall_exit(file, event);\n\tcase TRACE_REG_UNREGISTER:\n\t\tunreg_event_syscall_exit(file, event);\n\t\treturn 0;\n\n#ifdef CONFIG_PERF_EVENTS\n\tcase TRACE_REG_PERF_REGISTER:\n\t\treturn perf_sysexit_enable(event);\n\tcase TRACE_REG_PERF_UNREGISTER:\n\t\tperf_sysexit_disable(event);\n\t\treturn 0;\n\tcase TRACE_REG_PERF_OPEN:\n\tcase TRACE_REG_PERF_CLOSE:\n\tcase TRACE_REG_PERF_ADD:\n\tcase TRACE_REG_PERF_DEL:\n\t\treturn 0;\n#endif\n\t}\n\treturn 0;\n}\n"], "fixing_code": ["#include <trace/syscall.h>\n#include <trace/events/syscalls.h>\n#include <linux/syscalls.h>\n#include <linux/slab.h>\n#include <linux/kernel.h>\n#include <linux/module.h>\t/* for MODULE_NAME_LEN via KSYM_SYMBOL_LEN */\n#include <linux/ftrace.h>\n#include <linux/perf_event.h>\n#include <asm/syscall.h>\n\n#include \"trace_output.h\"\n#include \"trace.h\"\n\nstatic DEFINE_MUTEX(syscall_trace_lock);\n\nstatic int syscall_enter_register(struct ftrace_event_call *event,\n\t\t\t\t enum trace_reg type, void *data);\nstatic int syscall_exit_register(struct ftrace_event_call *event,\n\t\t\t\t enum trace_reg type, void *data);\n\nstatic struct list_head *\nsyscall_get_enter_fields(struct ftrace_event_call *call)\n{\n\tstruct syscall_metadata *entry = call->data;\n\n\treturn &entry->enter_fields;\n}\n\nextern struct syscall_metadata *__start_syscalls_metadata[];\nextern struct syscall_metadata *__stop_syscalls_metadata[];\n\nstatic struct syscall_metadata **syscalls_metadata;\n\n#ifndef ARCH_HAS_SYSCALL_MATCH_SYM_NAME\nstatic inline bool arch_syscall_match_sym_name(const char *sym, const char *name)\n{\n\t/*\n\t * Only compare after the \"sys\" prefix. Archs that use\n\t * syscall wrappers may have syscalls symbols aliases prefixed\n\t * with \".SyS\" or \".sys\" instead of \"sys\", leading to an unwanted\n\t * mismatch.\n\t */\n\treturn !strcmp(sym + 3, name + 3);\n}\n#endif\n\n#ifdef ARCH_TRACE_IGNORE_COMPAT_SYSCALLS\n/*\n * Some architectures that allow for 32bit applications\n * to run on a 64bit kernel, do not map the syscalls for\n * the 32bit tasks the same as they do for 64bit tasks.\n *\n *     *cough*x86*cough*\n *\n * In such a case, instead of reporting the wrong syscalls,\n * simply ignore them.\n *\n * For an arch to ignore the compat syscalls it needs to\n * define ARCH_TRACE_IGNORE_COMPAT_SYSCALLS as well as\n * define the function arch_trace_is_compat_syscall() to let\n * the tracing system know that it should ignore it.\n */\nstatic int\ntrace_get_syscall_nr(struct task_struct *task, struct pt_regs *regs)\n{\n\tif (unlikely(arch_trace_is_compat_syscall(regs)))\n\t\treturn -1;\n\n\treturn syscall_get_nr(task, regs);\n}\n#else\nstatic inline int\ntrace_get_syscall_nr(struct task_struct *task, struct pt_regs *regs)\n{\n\treturn syscall_get_nr(task, regs);\n}\n#endif /* ARCH_TRACE_IGNORE_COMPAT_SYSCALLS */\n\nstatic __init struct syscall_metadata *\nfind_syscall_meta(unsigned long syscall)\n{\n\tstruct syscall_metadata **start;\n\tstruct syscall_metadata **stop;\n\tchar str[KSYM_SYMBOL_LEN];\n\n\n\tstart = __start_syscalls_metadata;\n\tstop = __stop_syscalls_metadata;\n\tkallsyms_lookup(syscall, NULL, NULL, NULL, str);\n\n\tif (arch_syscall_match_sym_name(str, \"sys_ni_syscall\"))\n\t\treturn NULL;\n\n\tfor ( ; start < stop; start++) {\n\t\tif ((*start)->name && arch_syscall_match_sym_name(str, (*start)->name))\n\t\t\treturn *start;\n\t}\n\treturn NULL;\n}\n\nstatic struct syscall_metadata *syscall_nr_to_meta(int nr)\n{\n\tif (!syscalls_metadata || nr >= NR_syscalls || nr < 0)\n\t\treturn NULL;\n\n\treturn syscalls_metadata[nr];\n}\n\nstatic enum print_line_t\nprint_syscall_enter(struct trace_iterator *iter, int flags,\n\t\t    struct trace_event *event)\n{\n\tstruct trace_seq *s = &iter->seq;\n\tstruct trace_entry *ent = iter->ent;\n\tstruct syscall_trace_enter *trace;\n\tstruct syscall_metadata *entry;\n\tint i, ret, syscall;\n\n\ttrace = (typeof(trace))ent;\n\tsyscall = trace->nr;\n\tentry = syscall_nr_to_meta(syscall);\n\n\tif (!entry)\n\t\tgoto end;\n\n\tif (entry->enter_event->event.type != ent->type) {\n\t\tWARN_ON_ONCE(1);\n\t\tgoto end;\n\t}\n\n\tret = trace_seq_printf(s, \"%s(\", entry->name);\n\tif (!ret)\n\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\n\tfor (i = 0; i < entry->nb_args; i++) {\n\t\t/* parameter types */\n\t\tif (trace_flags & TRACE_ITER_VERBOSE) {\n\t\t\tret = trace_seq_printf(s, \"%s \", entry->types[i]);\n\t\t\tif (!ret)\n\t\t\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\t\t}\n\t\t/* parameter values */\n\t\tret = trace_seq_printf(s, \"%s: %lx%s\", entry->args[i],\n\t\t\t\t       trace->args[i],\n\t\t\t\t       i == entry->nb_args - 1 ? \"\" : \", \");\n\t\tif (!ret)\n\t\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\t}\n\n\tret = trace_seq_putc(s, ')');\n\tif (!ret)\n\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\nend:\n\tret =  trace_seq_putc(s, '\\n');\n\tif (!ret)\n\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\n\treturn TRACE_TYPE_HANDLED;\n}\n\nstatic enum print_line_t\nprint_syscall_exit(struct trace_iterator *iter, int flags,\n\t\t   struct trace_event *event)\n{\n\tstruct trace_seq *s = &iter->seq;\n\tstruct trace_entry *ent = iter->ent;\n\tstruct syscall_trace_exit *trace;\n\tint syscall;\n\tstruct syscall_metadata *entry;\n\tint ret;\n\n\ttrace = (typeof(trace))ent;\n\tsyscall = trace->nr;\n\tentry = syscall_nr_to_meta(syscall);\n\n\tif (!entry) {\n\t\ttrace_seq_putc(s, '\\n');\n\t\treturn TRACE_TYPE_HANDLED;\n\t}\n\n\tif (entry->exit_event->event.type != ent->type) {\n\t\tWARN_ON_ONCE(1);\n\t\treturn TRACE_TYPE_UNHANDLED;\n\t}\n\n\tret = trace_seq_printf(s, \"%s -> 0x%lx\\n\", entry->name,\n\t\t\t\ttrace->ret);\n\tif (!ret)\n\t\treturn TRACE_TYPE_PARTIAL_LINE;\n\n\treturn TRACE_TYPE_HANDLED;\n}\n\nextern char *__bad_type_size(void);\n\n#define SYSCALL_FIELD(type, name)\t\t\t\t\t\\\n\tsizeof(type) != sizeof(trace.name) ?\t\t\t\t\\\n\t\t__bad_type_size() :\t\t\t\t\t\\\n\t\t#type, #name, offsetof(typeof(trace), name),\t\t\\\n\t\tsizeof(trace.name), is_signed_type(type)\n\nstatic int __init\n__set_enter_print_fmt(struct syscall_metadata *entry, char *buf, int len)\n{\n\tint i;\n\tint pos = 0;\n\n\t/* When len=0, we just calculate the needed length */\n#define LEN_OR_ZERO (len ? len - pos : 0)\n\n\tpos += snprintf(buf + pos, LEN_OR_ZERO, \"\\\"\");\n\tfor (i = 0; i < entry->nb_args; i++) {\n\t\tpos += snprintf(buf + pos, LEN_OR_ZERO, \"%s: 0x%%0%zulx%s\",\n\t\t\t\tentry->args[i], sizeof(unsigned long),\n\t\t\t\ti == entry->nb_args - 1 ? \"\" : \", \");\n\t}\n\tpos += snprintf(buf + pos, LEN_OR_ZERO, \"\\\"\");\n\n\tfor (i = 0; i < entry->nb_args; i++) {\n\t\tpos += snprintf(buf + pos, LEN_OR_ZERO,\n\t\t\t\t\", ((unsigned long)(REC->%s))\", entry->args[i]);\n\t}\n\n#undef LEN_OR_ZERO\n\n\t/* return the length of print_fmt */\n\treturn pos;\n}\n\nstatic int __init set_syscall_print_fmt(struct ftrace_event_call *call)\n{\n\tchar *print_fmt;\n\tint len;\n\tstruct syscall_metadata *entry = call->data;\n\n\tif (entry->enter_event != call) {\n\t\tcall->print_fmt = \"\\\"0x%lx\\\", REC->ret\";\n\t\treturn 0;\n\t}\n\n\t/* First: called with 0 length to calculate the needed length */\n\tlen = __set_enter_print_fmt(entry, NULL, 0);\n\n\tprint_fmt = kmalloc(len + 1, GFP_KERNEL);\n\tif (!print_fmt)\n\t\treturn -ENOMEM;\n\n\t/* Second: actually write the @print_fmt */\n\t__set_enter_print_fmt(entry, print_fmt, len + 1);\n\tcall->print_fmt = print_fmt;\n\n\treturn 0;\n}\n\nstatic void __init free_syscall_print_fmt(struct ftrace_event_call *call)\n{\n\tstruct syscall_metadata *entry = call->data;\n\n\tif (entry->enter_event == call)\n\t\tkfree(call->print_fmt);\n}\n\nstatic int __init syscall_enter_define_fields(struct ftrace_event_call *call)\n{\n\tstruct syscall_trace_enter trace;\n\tstruct syscall_metadata *meta = call->data;\n\tint ret;\n\tint i;\n\tint offset = offsetof(typeof(trace), args);\n\n\tret = trace_define_field(call, SYSCALL_FIELD(int, nr), FILTER_OTHER);\n\tif (ret)\n\t\treturn ret;\n\n\tfor (i = 0; i < meta->nb_args; i++) {\n\t\tret = trace_define_field(call, meta->types[i],\n\t\t\t\t\t meta->args[i], offset,\n\t\t\t\t\t sizeof(unsigned long), 0,\n\t\t\t\t\t FILTER_OTHER);\n\t\toffset += sizeof(unsigned long);\n\t}\n\n\treturn ret;\n}\n\nstatic int __init syscall_exit_define_fields(struct ftrace_event_call *call)\n{\n\tstruct syscall_trace_exit trace;\n\tint ret;\n\n\tret = trace_define_field(call, SYSCALL_FIELD(int, nr), FILTER_OTHER);\n\tif (ret)\n\t\treturn ret;\n\n\tret = trace_define_field(call, SYSCALL_FIELD(long, ret),\n\t\t\t\t FILTER_OTHER);\n\n\treturn ret;\n}\n\nstatic void ftrace_syscall_enter(void *data, struct pt_regs *regs, long id)\n{\n\tstruct trace_array *tr = data;\n\tstruct ftrace_event_file *ftrace_file;\n\tstruct syscall_trace_enter *entry;\n\tstruct syscall_metadata *sys_data;\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer *buffer;\n\tunsigned long irq_flags;\n\tint pc;\n\tint syscall_nr;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\n\t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE) */\n\tftrace_file = rcu_dereference_sched(tr->enter_syscall_files[syscall_nr]);\n\tif (!ftrace_file)\n\t\treturn;\n\n\tif (ftrace_trigger_soft_disabled(ftrace_file))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\tsize = sizeof(*entry) + sizeof(unsigned long) * sys_data->nb_args;\n\n\tlocal_save_flags(irq_flags);\n\tpc = preempt_count();\n\n\tbuffer = tr->trace_buffer.buffer;\n\tevent = trace_buffer_lock_reserve(buffer,\n\t\t\tsys_data->enter_event->event.type, size, irq_flags, pc);\n\tif (!event)\n\t\treturn;\n\n\tentry = ring_buffer_event_data(event);\n\tentry->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args, entry->args);\n\n\tevent_trigger_unlock_commit(ftrace_file, buffer, event, entry,\n\t\t\t\t    irq_flags, pc);\n}\n\nstatic void ftrace_syscall_exit(void *data, struct pt_regs *regs, long ret)\n{\n\tstruct trace_array *tr = data;\n\tstruct ftrace_event_file *ftrace_file;\n\tstruct syscall_trace_exit *entry;\n\tstruct syscall_metadata *sys_data;\n\tstruct ring_buffer_event *event;\n\tstruct ring_buffer *buffer;\n\tunsigned long irq_flags;\n\tint pc;\n\tint syscall_nr;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\n\t/* Here we're inside tp handler's rcu_read_lock_sched (__DO_TRACE()) */\n\tftrace_file = rcu_dereference_sched(tr->exit_syscall_files[syscall_nr]);\n\tif (!ftrace_file)\n\t\treturn;\n\n\tif (ftrace_trigger_soft_disabled(ftrace_file))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\tlocal_save_flags(irq_flags);\n\tpc = preempt_count();\n\n\tbuffer = tr->trace_buffer.buffer;\n\tevent = trace_buffer_lock_reserve(buffer,\n\t\t\tsys_data->exit_event->event.type, sizeof(*entry),\n\t\t\tirq_flags, pc);\n\tif (!event)\n\t\treturn;\n\n\tentry = ring_buffer_event_data(event);\n\tentry->nr = syscall_nr;\n\tentry->ret = syscall_get_return_value(current, regs);\n\n\tevent_trigger_unlock_commit(ftrace_file, buffer, event, entry,\n\t\t\t\t    irq_flags, pc);\n}\n\nstatic int reg_event_syscall_enter(struct ftrace_event_file *file,\n\t\t\t\t   struct ftrace_event_call *call)\n{\n\tstruct trace_array *tr = file->tr;\n\tint ret = 0;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\n\t\treturn -ENOSYS;\n\tmutex_lock(&syscall_trace_lock);\n\tif (!tr->sys_refcount_enter)\n\t\tret = register_trace_sys_enter(ftrace_syscall_enter, tr);\n\tif (!ret) {\n\t\trcu_assign_pointer(tr->enter_syscall_files[num], file);\n\t\ttr->sys_refcount_enter++;\n\t}\n\tmutex_unlock(&syscall_trace_lock);\n\treturn ret;\n}\n\nstatic void unreg_event_syscall_enter(struct ftrace_event_file *file,\n\t\t\t\t      struct ftrace_event_call *call)\n{\n\tstruct trace_array *tr = file->tr;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\n\t\treturn;\n\tmutex_lock(&syscall_trace_lock);\n\ttr->sys_refcount_enter--;\n\tRCU_INIT_POINTER(tr->enter_syscall_files[num], NULL);\n\tif (!tr->sys_refcount_enter)\n\t\tunregister_trace_sys_enter(ftrace_syscall_enter, tr);\n\tmutex_unlock(&syscall_trace_lock);\n}\n\nstatic int reg_event_syscall_exit(struct ftrace_event_file *file,\n\t\t\t\t  struct ftrace_event_call *call)\n{\n\tstruct trace_array *tr = file->tr;\n\tint ret = 0;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\n\t\treturn -ENOSYS;\n\tmutex_lock(&syscall_trace_lock);\n\tif (!tr->sys_refcount_exit)\n\t\tret = register_trace_sys_exit(ftrace_syscall_exit, tr);\n\tif (!ret) {\n\t\trcu_assign_pointer(tr->exit_syscall_files[num], file);\n\t\ttr->sys_refcount_exit++;\n\t}\n\tmutex_unlock(&syscall_trace_lock);\n\treturn ret;\n}\n\nstatic void unreg_event_syscall_exit(struct ftrace_event_file *file,\n\t\t\t\t     struct ftrace_event_call *call)\n{\n\tstruct trace_array *tr = file->tr;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (WARN_ON_ONCE(num < 0 || num >= NR_syscalls))\n\t\treturn;\n\tmutex_lock(&syscall_trace_lock);\n\ttr->sys_refcount_exit--;\n\tRCU_INIT_POINTER(tr->exit_syscall_files[num], NULL);\n\tif (!tr->sys_refcount_exit)\n\t\tunregister_trace_sys_exit(ftrace_syscall_exit, tr);\n\tmutex_unlock(&syscall_trace_lock);\n}\n\nstatic int __init init_syscall_trace(struct ftrace_event_call *call)\n{\n\tint id;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\tif (num < 0 || num >= NR_syscalls) {\n\t\tpr_debug(\"syscall %s metadata not mapped, disabling ftrace event\\n\",\n\t\t\t\t((struct syscall_metadata *)call->data)->name);\n\t\treturn -ENOSYS;\n\t}\n\n\tif (set_syscall_print_fmt(call) < 0)\n\t\treturn -ENOMEM;\n\n\tid = trace_event_raw_init(call);\n\n\tif (id < 0) {\n\t\tfree_syscall_print_fmt(call);\n\t\treturn id;\n\t}\n\n\treturn id;\n}\n\nstruct trace_event_functions enter_syscall_print_funcs = {\n\t.trace\t\t= print_syscall_enter,\n};\n\nstruct trace_event_functions exit_syscall_print_funcs = {\n\t.trace\t\t= print_syscall_exit,\n};\n\nstruct ftrace_event_class __refdata event_class_syscall_enter = {\n\t.system\t\t= \"syscalls\",\n\t.reg\t\t= syscall_enter_register,\n\t.define_fields\t= syscall_enter_define_fields,\n\t.get_fields\t= syscall_get_enter_fields,\n\t.raw_init\t= init_syscall_trace,\n};\n\nstruct ftrace_event_class __refdata event_class_syscall_exit = {\n\t.system\t\t= \"syscalls\",\n\t.reg\t\t= syscall_exit_register,\n\t.define_fields\t= syscall_exit_define_fields,\n\t.fields\t\t= LIST_HEAD_INIT(event_class_syscall_exit.fields),\n\t.raw_init\t= init_syscall_trace,\n};\n\nunsigned long __init __weak arch_syscall_addr(int nr)\n{\n\treturn (unsigned long)sys_call_table[nr];\n}\n\nstatic int __init init_ftrace_syscalls(void)\n{\n\tstruct syscall_metadata *meta;\n\tunsigned long addr;\n\tint i;\n\n\tsyscalls_metadata = kcalloc(NR_syscalls, sizeof(*syscalls_metadata),\n\t\t\t\t    GFP_KERNEL);\n\tif (!syscalls_metadata) {\n\t\tWARN_ON(1);\n\t\treturn -ENOMEM;\n\t}\n\n\tfor (i = 0; i < NR_syscalls; i++) {\n\t\taddr = arch_syscall_addr(i);\n\t\tmeta = find_syscall_meta(addr);\n\t\tif (!meta)\n\t\t\tcontinue;\n\n\t\tmeta->syscall_nr = i;\n\t\tsyscalls_metadata[i] = meta;\n\t}\n\n\treturn 0;\n}\nearly_initcall(init_ftrace_syscalls);\n\n#ifdef CONFIG_PERF_EVENTS\n\nstatic DECLARE_BITMAP(enabled_perf_enter_syscalls, NR_syscalls);\nstatic DECLARE_BITMAP(enabled_perf_exit_syscalls, NR_syscalls);\nstatic int sys_perf_refcount_enter;\nstatic int sys_perf_refcount_exit;\n\nstatic void perf_syscall_enter(void *ignore, struct pt_regs *regs, long id)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_enter *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_enter_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->enter_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* get the size after alignment with the u32 buffer size field */\n\tsize = sizeof(unsigned long) * sys_data->nb_args + sizeof(*rec);\n\tsize = ALIGN(size + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_enter *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->enter_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\tsyscall_get_arguments(current, regs, 0, sys_data->nb_args,\n\t\t\t       (unsigned long *)&rec->args);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}\n\nstatic int perf_sysenter_enable(struct ftrace_event_call *call)\n{\n\tint ret = 0;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\n\tmutex_lock(&syscall_trace_lock);\n\tif (!sys_perf_refcount_enter)\n\t\tret = register_trace_sys_enter(perf_syscall_enter, NULL);\n\tif (ret) {\n\t\tpr_info(\"event trace: Could not activate\"\n\t\t\t\t\"syscall entry trace point\");\n\t} else {\n\t\tset_bit(num, enabled_perf_enter_syscalls);\n\t\tsys_perf_refcount_enter++;\n\t}\n\tmutex_unlock(&syscall_trace_lock);\n\treturn ret;\n}\n\nstatic void perf_sysenter_disable(struct ftrace_event_call *call)\n{\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\n\tmutex_lock(&syscall_trace_lock);\n\tsys_perf_refcount_enter--;\n\tclear_bit(num, enabled_perf_enter_syscalls);\n\tif (!sys_perf_refcount_enter)\n\t\tunregister_trace_sys_enter(perf_syscall_enter, NULL);\n\tmutex_unlock(&syscall_trace_lock);\n}\n\nstatic void perf_syscall_exit(void *ignore, struct pt_regs *regs, long ret)\n{\n\tstruct syscall_metadata *sys_data;\n\tstruct syscall_trace_exit *rec;\n\tstruct hlist_head *head;\n\tint syscall_nr;\n\tint rctx;\n\tint size;\n\n\tsyscall_nr = trace_get_syscall_nr(current, regs);\n\tif (syscall_nr < 0 || syscall_nr >= NR_syscalls)\n\t\treturn;\n\tif (!test_bit(syscall_nr, enabled_perf_exit_syscalls))\n\t\treturn;\n\n\tsys_data = syscall_nr_to_meta(syscall_nr);\n\tif (!sys_data)\n\t\treturn;\n\n\thead = this_cpu_ptr(sys_data->exit_event->perf_events);\n\tif (hlist_empty(head))\n\t\treturn;\n\n\t/* We can probably do that at build time */\n\tsize = ALIGN(sizeof(*rec) + sizeof(u32), sizeof(u64));\n\tsize -= sizeof(u32);\n\n\trec = (struct syscall_trace_exit *)perf_trace_buf_prepare(size,\n\t\t\t\tsys_data->exit_event->event.type, regs, &rctx);\n\tif (!rec)\n\t\treturn;\n\n\trec->nr = syscall_nr;\n\trec->ret = syscall_get_return_value(current, regs);\n\tperf_trace_buf_submit(rec, size, rctx, 0, 1, regs, head, NULL);\n}\n\nstatic int perf_sysexit_enable(struct ftrace_event_call *call)\n{\n\tint ret = 0;\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\n\tmutex_lock(&syscall_trace_lock);\n\tif (!sys_perf_refcount_exit)\n\t\tret = register_trace_sys_exit(perf_syscall_exit, NULL);\n\tif (ret) {\n\t\tpr_info(\"event trace: Could not activate\"\n\t\t\t\t\"syscall exit trace point\");\n\t} else {\n\t\tset_bit(num, enabled_perf_exit_syscalls);\n\t\tsys_perf_refcount_exit++;\n\t}\n\tmutex_unlock(&syscall_trace_lock);\n\treturn ret;\n}\n\nstatic void perf_sysexit_disable(struct ftrace_event_call *call)\n{\n\tint num;\n\n\tnum = ((struct syscall_metadata *)call->data)->syscall_nr;\n\n\tmutex_lock(&syscall_trace_lock);\n\tsys_perf_refcount_exit--;\n\tclear_bit(num, enabled_perf_exit_syscalls);\n\tif (!sys_perf_refcount_exit)\n\t\tunregister_trace_sys_exit(perf_syscall_exit, NULL);\n\tmutex_unlock(&syscall_trace_lock);\n}\n\n#endif /* CONFIG_PERF_EVENTS */\n\nstatic int syscall_enter_register(struct ftrace_event_call *event,\n\t\t\t\t enum trace_reg type, void *data)\n{\n\tstruct ftrace_event_file *file = data;\n\n\tswitch (type) {\n\tcase TRACE_REG_REGISTER:\n\t\treturn reg_event_syscall_enter(file, event);\n\tcase TRACE_REG_UNREGISTER:\n\t\tunreg_event_syscall_enter(file, event);\n\t\treturn 0;\n\n#ifdef CONFIG_PERF_EVENTS\n\tcase TRACE_REG_PERF_REGISTER:\n\t\treturn perf_sysenter_enable(event);\n\tcase TRACE_REG_PERF_UNREGISTER:\n\t\tperf_sysenter_disable(event);\n\t\treturn 0;\n\tcase TRACE_REG_PERF_OPEN:\n\tcase TRACE_REG_PERF_CLOSE:\n\tcase TRACE_REG_PERF_ADD:\n\tcase TRACE_REG_PERF_DEL:\n\t\treturn 0;\n#endif\n\t}\n\treturn 0;\n}\n\nstatic int syscall_exit_register(struct ftrace_event_call *event,\n\t\t\t\t enum trace_reg type, void *data)\n{\n\tstruct ftrace_event_file *file = data;\n\n\tswitch (type) {\n\tcase TRACE_REG_REGISTER:\n\t\treturn reg_event_syscall_exit(file, event);\n\tcase TRACE_REG_UNREGISTER:\n\t\tunreg_event_syscall_exit(file, event);\n\t\treturn 0;\n\n#ifdef CONFIG_PERF_EVENTS\n\tcase TRACE_REG_PERF_REGISTER:\n\t\treturn perf_sysexit_enable(event);\n\tcase TRACE_REG_PERF_UNREGISTER:\n\t\tperf_sysexit_disable(event);\n\t\treturn 0;\n\tcase TRACE_REG_PERF_OPEN:\n\tcase TRACE_REG_PERF_CLOSE:\n\tcase TRACE_REG_PERF_ADD:\n\tcase TRACE_REG_PERF_DEL:\n\t\treturn 0;\n#endif\n\t}\n\treturn 0;\n}\n"], "filenames": ["kernel/trace/trace_syscalls.c"], "buggy_code_start_loc": [316], "buggy_code_end_loc": [645], "fixing_code_start_loc": [316], "fixing_code_end_loc": [645], "type": "CWE-476", "message": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the ftrace subsystem, which allows local users to gain privileges or cause a denial of service (invalid pointer dereference) via a crafted application.", "other": {"cve": {"id": "CVE-2014-7826", "sourceIdentifier": "secalert@redhat.com", "published": "2014-11-10T11:55:08.173", "lastModified": "2023-02-13T00:42:33.107", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "kernel/trace/trace_syscalls.c in the Linux kernel through 3.17.2 does not properly handle private syscall numbers during use of the ftrace subsystem, which allows local users to gain privileges or cause a denial of service (invalid pointer dereference) via a crafted application."}, {"lang": "es", "value": "kernel/trace/trace_syscalls.c en el kernel de Linux hasta 3.17.2 no maneja debidamente los n\u00fameros privados de las llamadas al sistema durante el uso del subsistema ftrace, lo que permite a usuarios locales ganar privilegios o causar una denegaci\u00f3n de servicio (referencia a puntero inv\u00e1lido) a trav\u00e9s de una aplicaci\u00f3n manipulada."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 7.2}, "baseSeverity": "HIGH", "exploitabilityScore": 3.9, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-476"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.6.32", "versionEndExcluding": "3.2.65", "matchCriteriaId": "ECB1B089-6042-4651-8C4D-8A382721AF45"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.3", "versionEndExcluding": "3.4.106", "matchCriteriaId": "79C4C5AF-4667-4F85-9043-D834576687A8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.5", "versionEndExcluding": "3.10.60", "matchCriteriaId": "C0983E8C-42C1-4F9A-AB7E-AD6B3BFF72E3"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.11", "versionEndExcluding": "3.12.33", "matchCriteriaId": "70B1E419-B203-4A29-987D-BB2903962927"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.13", "versionEndExcluding": "3.14.24", "matchCriteriaId": "64E12F95-09DF-40D7-ABAF-D2EDCE99457A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.15", "versionEndExcluding": "3.16.35", "matchCriteriaId": "7DC4BA70-B111-4D2E-BC78-6601CED68F08"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.17", "versionEndExcluding": "3.17.3", "matchCriteriaId": "BBED3234-92E5-49B0-8EE2-17F3B74D5196"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:evergreen:11.4:*:*:*:*:*:*:*", "matchCriteriaId": "CCE4D64E-8C4B-4F21-A9B0-90637C85C1D0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:suse_linux_enterprise_server:11:sp2:*:*:ltss:*:*:*", "matchCriteriaId": "C202F75B-221A-40BB-8A0D-451335B39937"}]}]}], "references": [{"url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git%3Ba=commit%3Bh=086ba77a6db00ed858ff07451bedee197df868c9", "source": "secalert@redhat.com"}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2015-03/msg00010.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2015-03/msg00025.html", "source": "secalert@redhat.com", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2014-1943.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2015-0290.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://rhn.redhat.com/errata/RHSA-2015-0864.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2014/11/06/11", "source": "secalert@redhat.com", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "http://www.securityfocus.com/bid/70971", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1161565", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://exchange.xforce.ibmcloud.com/vulnerabilities/98556", "source": "secalert@redhat.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://github.com/torvalds/linux/commit/086ba77a6db00ed858ff07451bedee197df868c9", "source": "secalert@redhat.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/086ba77a6db00ed858ff07451bedee197df868c9"}}
{"buggy_code": ["/* -*- mode: c; c-basic-offset: 8; -*-\n * vim: noexpandtab sw=8 ts=8 sts=0:\n *\n * file.c\n *\n * File open, close, extend, truncate\n *\n * Copyright (C) 2002, 2004 Oracle.  All rights reserved.\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public\n * License as published by the Free Software Foundation; either\n * version 2 of the License, or (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * General Public License for more details.\n *\n * You should have received a copy of the GNU General Public\n * License along with this program; if not, write to the\n * Free Software Foundation, Inc., 59 Temple Place - Suite 330,\n * Boston, MA 021110-1307, USA.\n */\n\n#include <linux/capability.h>\n#include <linux/fs.h>\n#include <linux/types.h>\n#include <linux/slab.h>\n#include <linux/highmem.h>\n#include <linux/pagemap.h>\n#include <linux/uio.h>\n#include <linux/sched.h>\n#include <linux/splice.h>\n#include <linux/mount.h>\n#include <linux/writeback.h>\n#include <linux/falloc.h>\n#include <linux/quotaops.h>\n#include <linux/blkdev.h>\n#include <linux/backing-dev.h>\n\n#include <cluster/masklog.h>\n\n#include \"ocfs2.h\"\n\n#include \"alloc.h\"\n#include \"aops.h\"\n#include \"dir.h\"\n#include \"dlmglue.h\"\n#include \"extent_map.h\"\n#include \"file.h\"\n#include \"sysfile.h\"\n#include \"inode.h\"\n#include \"ioctl.h\"\n#include \"journal.h\"\n#include \"locks.h\"\n#include \"mmap.h\"\n#include \"suballoc.h\"\n#include \"super.h\"\n#include \"xattr.h\"\n#include \"acl.h\"\n#include \"quota.h\"\n#include \"refcounttree.h\"\n#include \"ocfs2_trace.h\"\n\n#include \"buffer_head_io.h\"\n\nstatic int ocfs2_init_file_private(struct inode *inode, struct file *file)\n{\n\tstruct ocfs2_file_private *fp;\n\n\tfp = kzalloc(sizeof(struct ocfs2_file_private), GFP_KERNEL);\n\tif (!fp)\n\t\treturn -ENOMEM;\n\n\tfp->fp_file = file;\n\tmutex_init(&fp->fp_mutex);\n\tocfs2_file_lock_res_init(&fp->fp_flock, fp);\n\tfile->private_data = fp;\n\n\treturn 0;\n}\n\nstatic void ocfs2_free_file_private(struct inode *inode, struct file *file)\n{\n\tstruct ocfs2_file_private *fp = file->private_data;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\n\tif (fp) {\n\t\tocfs2_simple_drop_lockres(osb, &fp->fp_flock);\n\t\tocfs2_lock_res_free(&fp->fp_flock);\n\t\tkfree(fp);\n\t\tfile->private_data = NULL;\n\t}\n}\n\nstatic int ocfs2_file_open(struct inode *inode, struct file *file)\n{\n\tint status;\n\tint mode = file->f_flags;\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\n\ttrace_ocfs2_file_open(inode, file, file->f_path.dentry,\n\t\t\t      (unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t      file->f_path.dentry->d_name.len,\n\t\t\t      file->f_path.dentry->d_name.name, mode);\n\n\tif (file->f_mode & FMODE_WRITE) {\n\t\tstatus = dquot_initialize(inode);\n\t\tif (status)\n\t\t\tgoto leave;\n\t}\n\n\tspin_lock(&oi->ip_lock);\n\n\t/* Check that the inode hasn't been wiped from disk by another\n\t * node. If it hasn't then we're safe as long as we hold the\n\t * spin lock until our increment of open count. */\n\tif (OCFS2_I(inode)->ip_flags & OCFS2_INODE_DELETED) {\n\t\tspin_unlock(&oi->ip_lock);\n\n\t\tstatus = -ENOENT;\n\t\tgoto leave;\n\t}\n\n\tif (mode & O_DIRECT)\n\t\toi->ip_flags |= OCFS2_INODE_OPEN_DIRECT;\n\n\toi->ip_open_count++;\n\tspin_unlock(&oi->ip_lock);\n\n\tstatus = ocfs2_init_file_private(inode, file);\n\tif (status) {\n\t\t/*\n\t\t * We want to set open count back if we're failing the\n\t\t * open.\n\t\t */\n\t\tspin_lock(&oi->ip_lock);\n\t\toi->ip_open_count--;\n\t\tspin_unlock(&oi->ip_lock);\n\t}\n\nleave:\n\treturn status;\n}\n\nstatic int ocfs2_file_release(struct inode *inode, struct file *file)\n{\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\n\tspin_lock(&oi->ip_lock);\n\tif (!--oi->ip_open_count)\n\t\toi->ip_flags &= ~OCFS2_INODE_OPEN_DIRECT;\n\n\ttrace_ocfs2_file_release(inode, file, file->f_path.dentry,\n\t\t\t\t oi->ip_blkno,\n\t\t\t\t file->f_path.dentry->d_name.len,\n\t\t\t\t file->f_path.dentry->d_name.name,\n\t\t\t\t oi->ip_open_count);\n\tspin_unlock(&oi->ip_lock);\n\n\tocfs2_free_file_private(inode, file);\n\n\treturn 0;\n}\n\nstatic int ocfs2_dir_open(struct inode *inode, struct file *file)\n{\n\treturn ocfs2_init_file_private(inode, file);\n}\n\nstatic int ocfs2_dir_release(struct inode *inode, struct file *file)\n{\n\tocfs2_free_file_private(inode, file);\n\treturn 0;\n}\n\nstatic int ocfs2_sync_file(struct file *file, loff_t start, loff_t end,\n\t\t\t   int datasync)\n{\n\tint err = 0;\n\tstruct inode *inode = file->f_mapping->host;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\tjournal_t *journal = osb->journal->j_journal;\n\tint ret;\n\ttid_t commit_tid;\n\tbool needs_barrier = false;\n\n\ttrace_ocfs2_sync_file(inode, file, file->f_path.dentry,\n\t\t\t      OCFS2_I(inode)->ip_blkno,\n\t\t\t      file->f_path.dentry->d_name.len,\n\t\t\t      file->f_path.dentry->d_name.name,\n\t\t\t      (unsigned long long)datasync);\n\n\tif (ocfs2_is_hard_readonly(osb) || ocfs2_is_soft_readonly(osb))\n\t\treturn -EROFS;\n\n\terr = file_write_and_wait_range(file, start, end);\n\tif (err)\n\t\treturn err;\n\n\tcommit_tid = datasync ? oi->i_datasync_tid : oi->i_sync_tid;\n\tif (journal->j_flags & JBD2_BARRIER &&\n\t    !jbd2_trans_will_send_data_barrier(journal, commit_tid))\n\t\tneeds_barrier = true;\n\terr = jbd2_complete_transaction(journal, commit_tid);\n\tif (needs_barrier) {\n\t\tret = blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);\n\t\tif (!err)\n\t\t\terr = ret;\n\t}\n\n\tif (err)\n\t\tmlog_errno(err);\n\n\treturn (err < 0) ? -EIO : 0;\n}\n\nint ocfs2_should_update_atime(struct inode *inode,\n\t\t\t      struct vfsmount *vfsmnt)\n{\n\tstruct timespec now;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\n\tif (ocfs2_is_hard_readonly(osb) || ocfs2_is_soft_readonly(osb))\n\t\treturn 0;\n\n\tif ((inode->i_flags & S_NOATIME) ||\n\t    ((inode->i_sb->s_flags & MS_NODIRATIME) && S_ISDIR(inode->i_mode)))\n\t\treturn 0;\n\n\t/*\n\t * We can be called with no vfsmnt structure - NFSD will\n\t * sometimes do this.\n\t *\n\t * Note that our action here is different than touch_atime() -\n\t * if we can't tell whether this is a noatime mount, then we\n\t * don't know whether to trust the value of s_atime_quantum.\n\t */\n\tif (vfsmnt == NULL)\n\t\treturn 0;\n\n\tif ((vfsmnt->mnt_flags & MNT_NOATIME) ||\n\t    ((vfsmnt->mnt_flags & MNT_NODIRATIME) && S_ISDIR(inode->i_mode)))\n\t\treturn 0;\n\n\tif (vfsmnt->mnt_flags & MNT_RELATIME) {\n\t\tif ((timespec_compare(&inode->i_atime, &inode->i_mtime) <= 0) ||\n\t\t    (timespec_compare(&inode->i_atime, &inode->i_ctime) <= 0))\n\t\t\treturn 1;\n\n\t\treturn 0;\n\t}\n\n\tnow = current_time(inode);\n\tif ((now.tv_sec - inode->i_atime.tv_sec <= osb->s_atime_quantum))\n\t\treturn 0;\n\telse\n\t\treturn 1;\n}\n\nint ocfs2_update_inode_atime(struct inode *inode,\n\t\t\t     struct buffer_head *bh)\n{\n\tint ret;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\thandle_t *handle;\n\tstruct ocfs2_dinode *di = (struct ocfs2_dinode *) bh->b_data;\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_journal_access_di(handle, INODE_CACHE(inode), bh,\n\t\t\t\t      OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out_commit;\n\t}\n\n\t/*\n\t * Don't use ocfs2_mark_inode_dirty() here as we don't always\n\t * have i_mutex to guard against concurrent changes to other\n\t * inode fields.\n\t */\n\tinode->i_atime = current_time(inode);\n\tdi->i_atime = cpu_to_le64(inode->i_atime.tv_sec);\n\tdi->i_atime_nsec = cpu_to_le32(inode->i_atime.tv_nsec);\n\tocfs2_update_inode_fsync_trans(handle, inode, 0);\n\tocfs2_journal_dirty(handle, bh);\n\nout_commit:\n\tocfs2_commit_trans(OCFS2_SB(inode->i_sb), handle);\nout:\n\treturn ret;\n}\n\nint ocfs2_set_inode_size(handle_t *handle,\n\t\t\t\tstruct inode *inode,\n\t\t\t\tstruct buffer_head *fe_bh,\n\t\t\t\tu64 new_i_size)\n{\n\tint status;\n\n\ti_size_write(inode, new_i_size);\n\tinode->i_blocks = ocfs2_inode_sector_count(inode);\n\tinode->i_ctime = inode->i_mtime = current_time(inode);\n\n\tstatus = ocfs2_mark_inode_dirty(handle, inode, fe_bh);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto bail;\n\t}\n\nbail:\n\treturn status;\n}\n\nint ocfs2_simple_size_update(struct inode *inode,\n\t\t\t     struct buffer_head *di_bh,\n\t\t\t     u64 new_i_size)\n{\n\tint ret;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\thandle_t *handle = NULL;\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_set_inode_size(handle, inode, di_bh,\n\t\t\t\t   new_i_size);\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\n\tocfs2_update_inode_fsync_trans(handle, inode, 0);\n\tocfs2_commit_trans(osb, handle);\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_cow_file_pos(struct inode *inode,\n\t\t\t      struct buffer_head *fe_bh,\n\t\t\t      u64 offset)\n{\n\tint status;\n\tu32 phys, cpos = offset >> OCFS2_SB(inode->i_sb)->s_clustersize_bits;\n\tunsigned int num_clusters = 0;\n\tunsigned int ext_flags = 0;\n\n\t/*\n\t * If the new offset is aligned to the range of the cluster, there is\n\t * no space for ocfs2_zero_range_for_truncate to fill, so no need to\n\t * CoW either.\n\t */\n\tif ((offset & (OCFS2_SB(inode->i_sb)->s_clustersize - 1)) == 0)\n\t\treturn 0;\n\n\tstatus = ocfs2_get_clusters(inode, cpos, &phys,\n\t\t\t\t    &num_clusters, &ext_flags);\n\tif (status) {\n\t\tmlog_errno(status);\n\t\tgoto out;\n\t}\n\n\tif (!(ext_flags & OCFS2_EXT_REFCOUNTED))\n\t\tgoto out;\n\n\treturn ocfs2_refcount_cow(inode, fe_bh, cpos, 1, cpos+1);\n\nout:\n\treturn status;\n}\n\nstatic int ocfs2_orphan_for_truncate(struct ocfs2_super *osb,\n\t\t\t\t     struct inode *inode,\n\t\t\t\t     struct buffer_head *fe_bh,\n\t\t\t\t     u64 new_i_size)\n{\n\tint status;\n\thandle_t *handle;\n\tstruct ocfs2_dinode *di;\n\tu64 cluster_bytes;\n\n\t/*\n\t * We need to CoW the cluster contains the offset if it is reflinked\n\t * since we will call ocfs2_zero_range_for_truncate later which will\n\t * write \"0\" from offset to the end of the cluster.\n\t */\n\tstatus = ocfs2_cow_file_pos(inode, fe_bh, new_i_size);\n\tif (status) {\n\t\tmlog_errno(status);\n\t\treturn status;\n\t}\n\n\t/* TODO: This needs to actually orphan the inode in this\n\t * transaction. */\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tstatus = PTR_ERR(handle);\n\t\tmlog_errno(status);\n\t\tgoto out;\n\t}\n\n\tstatus = ocfs2_journal_access_di(handle, INODE_CACHE(inode), fe_bh,\n\t\t\t\t\t OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto out_commit;\n\t}\n\n\t/*\n\t * Do this before setting i_size.\n\t */\n\tcluster_bytes = ocfs2_align_bytes_to_clusters(inode->i_sb, new_i_size);\n\tstatus = ocfs2_zero_range_for_truncate(inode, handle, new_i_size,\n\t\t\t\t\t       cluster_bytes);\n\tif (status) {\n\t\tmlog_errno(status);\n\t\tgoto out_commit;\n\t}\n\n\ti_size_write(inode, new_i_size);\n\tinode->i_ctime = inode->i_mtime = current_time(inode);\n\n\tdi = (struct ocfs2_dinode *) fe_bh->b_data;\n\tdi->i_size = cpu_to_le64(new_i_size);\n\tdi->i_ctime = di->i_mtime = cpu_to_le64(inode->i_ctime.tv_sec);\n\tdi->i_ctime_nsec = di->i_mtime_nsec = cpu_to_le32(inode->i_ctime.tv_nsec);\n\tocfs2_update_inode_fsync_trans(handle, inode, 0);\n\n\tocfs2_journal_dirty(handle, fe_bh);\n\nout_commit:\n\tocfs2_commit_trans(osb, handle);\nout:\n\treturn status;\n}\n\nint ocfs2_truncate_file(struct inode *inode,\n\t\t\t       struct buffer_head *di_bh,\n\t\t\t       u64 new_i_size)\n{\n\tint status = 0;\n\tstruct ocfs2_dinode *fe = NULL;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\n\t/* We trust di_bh because it comes from ocfs2_inode_lock(), which\n\t * already validated it */\n\tfe = (struct ocfs2_dinode *) di_bh->b_data;\n\n\ttrace_ocfs2_truncate_file((unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t\t  (unsigned long long)le64_to_cpu(fe->i_size),\n\t\t\t\t  (unsigned long long)new_i_size);\n\n\tmlog_bug_on_msg(le64_to_cpu(fe->i_size) != i_size_read(inode),\n\t\t\t\"Inode %llu, inode i_size = %lld != di \"\n\t\t\t\"i_size = %llu, i_flags = 0x%x\\n\",\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\ti_size_read(inode),\n\t\t\t(unsigned long long)le64_to_cpu(fe->i_size),\n\t\t\tle32_to_cpu(fe->i_flags));\n\n\tif (new_i_size > le64_to_cpu(fe->i_size)) {\n\t\ttrace_ocfs2_truncate_file_error(\n\t\t\t(unsigned long long)le64_to_cpu(fe->i_size),\n\t\t\t(unsigned long long)new_i_size);\n\t\tstatus = -EINVAL;\n\t\tmlog_errno(status);\n\t\tgoto bail;\n\t}\n\n\tdown_write(&OCFS2_I(inode)->ip_alloc_sem);\n\n\tocfs2_resv_discard(&osb->osb_la_resmap,\n\t\t\t   &OCFS2_I(inode)->ip_la_data_resv);\n\n\t/*\n\t * The inode lock forced other nodes to sync and drop their\n\t * pages, which (correctly) happens even if we have a truncate\n\t * without allocation change - ocfs2 cluster sizes can be much\n\t * greater than page size, so we have to truncate them\n\t * anyway.\n\t */\n\tunmap_mapping_range(inode->i_mapping, new_i_size + PAGE_SIZE - 1, 0, 1);\n\ttruncate_inode_pages(inode->i_mapping, new_i_size);\n\n\tif (OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL) {\n\t\tstatus = ocfs2_truncate_inline(inode, di_bh, new_i_size,\n\t\t\t\t\t       i_size_read(inode), 1);\n\t\tif (status)\n\t\t\tmlog_errno(status);\n\n\t\tgoto bail_unlock_sem;\n\t}\n\n\t/* alright, we're going to need to do a full blown alloc size\n\t * change. Orphan the inode so that recovery can complete the\n\t * truncate if necessary. This does the task of marking\n\t * i_size. */\n\tstatus = ocfs2_orphan_for_truncate(osb, inode, di_bh, new_i_size);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto bail_unlock_sem;\n\t}\n\n\tstatus = ocfs2_commit_truncate(osb, inode, di_bh);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto bail_unlock_sem;\n\t}\n\n\t/* TODO: orphan dir cleanup here. */\nbail_unlock_sem:\n\tup_write(&OCFS2_I(inode)->ip_alloc_sem);\n\nbail:\n\tif (!status && OCFS2_I(inode)->ip_clusters == 0)\n\t\tstatus = ocfs2_try_remove_refcount_tree(inode, di_bh);\n\n\treturn status;\n}\n\n/*\n * extend file allocation only here.\n * we'll update all the disk stuff, and oip->alloc_size\n *\n * expect stuff to be locked, a transaction started and enough data /\n * metadata reservations in the contexts.\n *\n * Will return -EAGAIN, and a reason if a restart is needed.\n * If passed in, *reason will always be set, even in error.\n */\nint ocfs2_add_inode_data(struct ocfs2_super *osb,\n\t\t\t struct inode *inode,\n\t\t\t u32 *logical_offset,\n\t\t\t u32 clusters_to_add,\n\t\t\t int mark_unwritten,\n\t\t\t struct buffer_head *fe_bh,\n\t\t\t handle_t *handle,\n\t\t\t struct ocfs2_alloc_context *data_ac,\n\t\t\t struct ocfs2_alloc_context *meta_ac,\n\t\t\t enum ocfs2_alloc_restarted *reason_ret)\n{\n\tint ret;\n\tstruct ocfs2_extent_tree et;\n\n\tocfs2_init_dinode_extent_tree(&et, INODE_CACHE(inode), fe_bh);\n\tret = ocfs2_add_clusters_in_btree(handle, &et, logical_offset,\n\t\t\t\t\t  clusters_to_add, mark_unwritten,\n\t\t\t\t\t  data_ac, meta_ac, reason_ret);\n\n\treturn ret;\n}\n\nstatic int __ocfs2_extend_allocation(struct inode *inode, u32 logical_start,\n\t\t\t\t     u32 clusters_to_add, int mark_unwritten)\n{\n\tint status = 0;\n\tint restart_func = 0;\n\tint credits;\n\tu32 prev_clusters;\n\tstruct buffer_head *bh = NULL;\n\tstruct ocfs2_dinode *fe = NULL;\n\thandle_t *handle = NULL;\n\tstruct ocfs2_alloc_context *data_ac = NULL;\n\tstruct ocfs2_alloc_context *meta_ac = NULL;\n\tenum ocfs2_alloc_restarted why = RESTART_NONE;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_extent_tree et;\n\tint did_quota = 0;\n\n\t/*\n\t * Unwritten extent only exists for file systems which\n\t * support holes.\n\t */\n\tBUG_ON(mark_unwritten && !ocfs2_sparse_alloc(osb));\n\n\tstatus = ocfs2_read_inode_block(inode, &bh);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\tfe = (struct ocfs2_dinode *) bh->b_data;\n\nrestart_all:\n\tBUG_ON(le32_to_cpu(fe->i_clusters) != OCFS2_I(inode)->ip_clusters);\n\n\tocfs2_init_dinode_extent_tree(&et, INODE_CACHE(inode), bh);\n\tstatus = ocfs2_lock_allocators(inode, &et, clusters_to_add, 0,\n\t\t\t\t       &data_ac, &meta_ac);\n\tif (status) {\n\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\n\tcredits = ocfs2_calc_extend_credits(osb->sb, &fe->id2.i_list);\n\thandle = ocfs2_start_trans(osb, credits);\n\tif (IS_ERR(handle)) {\n\t\tstatus = PTR_ERR(handle);\n\t\thandle = NULL;\n\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\nrestarted_transaction:\n\ttrace_ocfs2_extend_allocation(\n\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t(unsigned long long)i_size_read(inode),\n\t\tle32_to_cpu(fe->i_clusters), clusters_to_add,\n\t\twhy, restart_func);\n\n\tstatus = dquot_alloc_space_nodirty(inode,\n\t\t\tocfs2_clusters_to_bytes(osb->sb, clusters_to_add));\n\tif (status)\n\t\tgoto leave;\n\tdid_quota = 1;\n\n\t/* reserve a write to the file entry early on - that we if we\n\t * run out of credits in the allocation path, we can still\n\t * update i_size. */\n\tstatus = ocfs2_journal_access_di(handle, INODE_CACHE(inode), bh,\n\t\t\t\t\t OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\n\tprev_clusters = OCFS2_I(inode)->ip_clusters;\n\n\tstatus = ocfs2_add_inode_data(osb,\n\t\t\t\t      inode,\n\t\t\t\t      &logical_start,\n\t\t\t\t      clusters_to_add,\n\t\t\t\t      mark_unwritten,\n\t\t\t\t      bh,\n\t\t\t\t      handle,\n\t\t\t\t      data_ac,\n\t\t\t\t      meta_ac,\n\t\t\t\t      &why);\n\tif ((status < 0) && (status != -EAGAIN)) {\n\t\tif (status != -ENOSPC)\n\t\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\tocfs2_update_inode_fsync_trans(handle, inode, 1);\n\tocfs2_journal_dirty(handle, bh);\n\n\tspin_lock(&OCFS2_I(inode)->ip_lock);\n\tclusters_to_add -= (OCFS2_I(inode)->ip_clusters - prev_clusters);\n\tspin_unlock(&OCFS2_I(inode)->ip_lock);\n\t/* Release unused quota reservation */\n\tdquot_free_space(inode,\n\t\t\tocfs2_clusters_to_bytes(osb->sb, clusters_to_add));\n\tdid_quota = 0;\n\n\tif (why != RESTART_NONE && clusters_to_add) {\n\t\tif (why == RESTART_META) {\n\t\t\trestart_func = 1;\n\t\t\tstatus = 0;\n\t\t} else {\n\t\t\tBUG_ON(why != RESTART_TRANS);\n\n\t\t\tstatus = ocfs2_allocate_extend_trans(handle, 1);\n\t\t\tif (status < 0) {\n\t\t\t\t/* handle still has to be committed at\n\t\t\t\t * this point. */\n\t\t\t\tstatus = -ENOMEM;\n\t\t\t\tmlog_errno(status);\n\t\t\t\tgoto leave;\n\t\t\t}\n\t\t\tgoto restarted_transaction;\n\t\t}\n\t}\n\n\ttrace_ocfs2_extend_allocation_end(OCFS2_I(inode)->ip_blkno,\n\t     le32_to_cpu(fe->i_clusters),\n\t     (unsigned long long)le64_to_cpu(fe->i_size),\n\t     OCFS2_I(inode)->ip_clusters,\n\t     (unsigned long long)i_size_read(inode));\n\nleave:\n\tif (status < 0 && did_quota)\n\t\tdquot_free_space(inode,\n\t\t\tocfs2_clusters_to_bytes(osb->sb, clusters_to_add));\n\tif (handle) {\n\t\tocfs2_commit_trans(osb, handle);\n\t\thandle = NULL;\n\t}\n\tif (data_ac) {\n\t\tocfs2_free_alloc_context(data_ac);\n\t\tdata_ac = NULL;\n\t}\n\tif (meta_ac) {\n\t\tocfs2_free_alloc_context(meta_ac);\n\t\tmeta_ac = NULL;\n\t}\n\tif ((!status) && restart_func) {\n\t\trestart_func = 0;\n\t\tgoto restart_all;\n\t}\n\tbrelse(bh);\n\tbh = NULL;\n\n\treturn status;\n}\n\n/*\n * While a write will already be ordering the data, a truncate will not.\n * Thus, we need to explicitly order the zeroed pages.\n */\nstatic handle_t *ocfs2_zero_start_ordered_transaction(struct inode *inode,\n\t\t\t\t\t\tstruct buffer_head *di_bh)\n{\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\thandle_t *handle = NULL;\n\tint ret = 0;\n\n\tif (!ocfs2_should_order_data(inode))\n\t\tgoto out;\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = -ENOMEM;\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_jbd2_file_inode(handle, inode);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_journal_access_di(handle, INODE_CACHE(inode), di_bh,\n\t\t\t\t      OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (ret)\n\t\tmlog_errno(ret);\n\tocfs2_update_inode_fsync_trans(handle, inode, 1);\n\nout:\n\tif (ret) {\n\t\tif (!IS_ERR(handle))\n\t\t\tocfs2_commit_trans(osb, handle);\n\t\thandle = ERR_PTR(ret);\n\t}\n\treturn handle;\n}\n\n/* Some parts of this taken from generic_cont_expand, which turned out\n * to be too fragile to do exactly what we need without us having to\n * worry about recursive locking in ->write_begin() and ->write_end(). */\nstatic int ocfs2_write_zero_page(struct inode *inode, u64 abs_from,\n\t\t\t\t u64 abs_to, struct buffer_head *di_bh)\n{\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct page *page;\n\tunsigned long index = abs_from >> PAGE_SHIFT;\n\thandle_t *handle;\n\tint ret = 0;\n\tunsigned zero_from, zero_to, block_start, block_end;\n\tstruct ocfs2_dinode *di = (struct ocfs2_dinode *)di_bh->b_data;\n\n\tBUG_ON(abs_from >= abs_to);\n\tBUG_ON(abs_to > (((u64)index + 1) << PAGE_SHIFT));\n\tBUG_ON(abs_from & (inode->i_blkbits - 1));\n\n\thandle = ocfs2_zero_start_ordered_transaction(inode, di_bh);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tgoto out;\n\t}\n\n\tpage = find_or_create_page(mapping, index, GFP_NOFS);\n\tif (!page) {\n\t\tret = -ENOMEM;\n\t\tmlog_errno(ret);\n\t\tgoto out_commit_trans;\n\t}\n\n\t/* Get the offsets within the page that we want to zero */\n\tzero_from = abs_from & (PAGE_SIZE - 1);\n\tzero_to = abs_to & (PAGE_SIZE - 1);\n\tif (!zero_to)\n\t\tzero_to = PAGE_SIZE;\n\n\ttrace_ocfs2_write_zero_page(\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t(unsigned long long)abs_from,\n\t\t\t(unsigned long long)abs_to,\n\t\t\tindex, zero_from, zero_to);\n\n\t/* We know that zero_from is block aligned */\n\tfor (block_start = zero_from; block_start < zero_to;\n\t     block_start = block_end) {\n\t\tblock_end = block_start + i_blocksize(inode);\n\n\t\t/*\n\t\t * block_start is block-aligned.  Bump it by one to force\n\t\t * __block_write_begin and block_commit_write to zero the\n\t\t * whole block.\n\t\t */\n\t\tret = __block_write_begin(page, block_start + 1, 0,\n\t\t\t\t\t  ocfs2_get_block);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\n\t\t/* must not update i_size! */\n\t\tret = block_commit_write(page, block_start + 1,\n\t\t\t\t\t block_start + 1);\n\t\tif (ret < 0)\n\t\t\tmlog_errno(ret);\n\t\telse\n\t\t\tret = 0;\n\t}\n\n\t/*\n\t * fs-writeback will release the dirty pages without page lock\n\t * whose offset are over inode size, the release happens at\n\t * block_write_full_page().\n\t */\n\ti_size_write(inode, abs_to);\n\tinode->i_blocks = ocfs2_inode_sector_count(inode);\n\tdi->i_size = cpu_to_le64((u64)i_size_read(inode));\n\tinode->i_mtime = inode->i_ctime = current_time(inode);\n\tdi->i_mtime = di->i_ctime = cpu_to_le64(inode->i_mtime.tv_sec);\n\tdi->i_ctime_nsec = cpu_to_le32(inode->i_mtime.tv_nsec);\n\tdi->i_mtime_nsec = di->i_ctime_nsec;\n\tif (handle) {\n\t\tocfs2_journal_dirty(handle, di_bh);\n\t\tocfs2_update_inode_fsync_trans(handle, inode, 1);\n\t}\n\nout_unlock:\n\tunlock_page(page);\n\tput_page(page);\nout_commit_trans:\n\tif (handle)\n\t\tocfs2_commit_trans(OCFS2_SB(inode->i_sb), handle);\nout:\n\treturn ret;\n}\n\n/*\n * Find the next range to zero.  We do this in terms of bytes because\n * that's what ocfs2_zero_extend() wants, and it is dealing with the\n * pagecache.  We may return multiple extents.\n *\n * zero_start and zero_end are ocfs2_zero_extend()s current idea of what\n * needs to be zeroed.  range_start and range_end return the next zeroing\n * range.  A subsequent call should pass the previous range_end as its\n * zero_start.  If range_end is 0, there's nothing to do.\n *\n * Unwritten extents are skipped over.  Refcounted extents are CoWd.\n */\nstatic int ocfs2_zero_extend_get_range(struct inode *inode,\n\t\t\t\t       struct buffer_head *di_bh,\n\t\t\t\t       u64 zero_start, u64 zero_end,\n\t\t\t\t       u64 *range_start, u64 *range_end)\n{\n\tint rc = 0, needs_cow = 0;\n\tu32 p_cpos, zero_clusters = 0;\n\tu32 zero_cpos =\n\t\tzero_start >> OCFS2_SB(inode->i_sb)->s_clustersize_bits;\n\tu32 last_cpos = ocfs2_clusters_for_bytes(inode->i_sb, zero_end);\n\tunsigned int num_clusters = 0;\n\tunsigned int ext_flags = 0;\n\n\twhile (zero_cpos < last_cpos) {\n\t\trc = ocfs2_get_clusters(inode, zero_cpos, &p_cpos,\n\t\t\t\t\t&num_clusters, &ext_flags);\n\t\tif (rc) {\n\t\t\tmlog_errno(rc);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (p_cpos && !(ext_flags & OCFS2_EXT_UNWRITTEN)) {\n\t\t\tzero_clusters = num_clusters;\n\t\t\tif (ext_flags & OCFS2_EXT_REFCOUNTED)\n\t\t\t\tneeds_cow = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tzero_cpos += num_clusters;\n\t}\n\tif (!zero_clusters) {\n\t\t*range_end = 0;\n\t\tgoto out;\n\t}\n\n\twhile ((zero_cpos + zero_clusters) < last_cpos) {\n\t\trc = ocfs2_get_clusters(inode, zero_cpos + zero_clusters,\n\t\t\t\t\t&p_cpos, &num_clusters,\n\t\t\t\t\t&ext_flags);\n\t\tif (rc) {\n\t\t\tmlog_errno(rc);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!p_cpos || (ext_flags & OCFS2_EXT_UNWRITTEN))\n\t\t\tbreak;\n\t\tif (ext_flags & OCFS2_EXT_REFCOUNTED)\n\t\t\tneeds_cow = 1;\n\t\tzero_clusters += num_clusters;\n\t}\n\tif ((zero_cpos + zero_clusters) > last_cpos)\n\t\tzero_clusters = last_cpos - zero_cpos;\n\n\tif (needs_cow) {\n\t\trc = ocfs2_refcount_cow(inode, di_bh, zero_cpos,\n\t\t\t\t\tzero_clusters, UINT_MAX);\n\t\tif (rc) {\n\t\t\tmlog_errno(rc);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t*range_start = ocfs2_clusters_to_bytes(inode->i_sb, zero_cpos);\n\t*range_end = ocfs2_clusters_to_bytes(inode->i_sb,\n\t\t\t\t\t     zero_cpos + zero_clusters);\n\nout:\n\treturn rc;\n}\n\n/*\n * Zero one range returned from ocfs2_zero_extend_get_range().  The caller\n * has made sure that the entire range needs zeroing.\n */\nstatic int ocfs2_zero_extend_range(struct inode *inode, u64 range_start,\n\t\t\t\t   u64 range_end, struct buffer_head *di_bh)\n{\n\tint rc = 0;\n\tu64 next_pos;\n\tu64 zero_pos = range_start;\n\n\ttrace_ocfs2_zero_extend_range(\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t(unsigned long long)range_start,\n\t\t\t(unsigned long long)range_end);\n\tBUG_ON(range_start >= range_end);\n\n\twhile (zero_pos < range_end) {\n\t\tnext_pos = (zero_pos & PAGE_MASK) + PAGE_SIZE;\n\t\tif (next_pos > range_end)\n\t\t\tnext_pos = range_end;\n\t\trc = ocfs2_write_zero_page(inode, zero_pos, next_pos, di_bh);\n\t\tif (rc < 0) {\n\t\t\tmlog_errno(rc);\n\t\t\tbreak;\n\t\t}\n\t\tzero_pos = next_pos;\n\n\t\t/*\n\t\t * Very large extends have the potential to lock up\n\t\t * the cpu for extended periods of time.\n\t\t */\n\t\tcond_resched();\n\t}\n\n\treturn rc;\n}\n\nint ocfs2_zero_extend(struct inode *inode, struct buffer_head *di_bh,\n\t\t      loff_t zero_to_size)\n{\n\tint ret = 0;\n\tu64 zero_start, range_start = 0, range_end = 0;\n\tstruct super_block *sb = inode->i_sb;\n\n\tzero_start = ocfs2_align_bytes_to_blocks(sb, i_size_read(inode));\n\ttrace_ocfs2_zero_extend((unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t\t(unsigned long long)zero_start,\n\t\t\t\t(unsigned long long)i_size_read(inode));\n\twhile (zero_start < zero_to_size) {\n\t\tret = ocfs2_zero_extend_get_range(inode, di_bh, zero_start,\n\t\t\t\t\t\t  zero_to_size,\n\t\t\t\t\t\t  &range_start,\n\t\t\t\t\t\t  &range_end);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tbreak;\n\t\t}\n\t\tif (!range_end)\n\t\t\tbreak;\n\t\t/* Trim the ends */\n\t\tif (range_start < zero_start)\n\t\t\trange_start = zero_start;\n\t\tif (range_end > zero_to_size)\n\t\t\trange_end = zero_to_size;\n\n\t\tret = ocfs2_zero_extend_range(inode, range_start,\n\t\t\t\t\t      range_end, di_bh);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tbreak;\n\t\t}\n\t\tzero_start = range_end;\n\t}\n\n\treturn ret;\n}\n\nint ocfs2_extend_no_holes(struct inode *inode, struct buffer_head *di_bh,\n\t\t\t  u64 new_i_size, u64 zero_to)\n{\n\tint ret;\n\tu32 clusters_to_add;\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\n\t/*\n\t * Only quota files call this without a bh, and they can't be\n\t * refcounted.\n\t */\n\tBUG_ON(!di_bh && ocfs2_is_refcount_inode(inode));\n\tBUG_ON(!di_bh && !(oi->ip_flags & OCFS2_INODE_SYSTEM_FILE));\n\n\tclusters_to_add = ocfs2_clusters_for_bytes(inode->i_sb, new_i_size);\n\tif (clusters_to_add < oi->ip_clusters)\n\t\tclusters_to_add = 0;\n\telse\n\t\tclusters_to_add -= oi->ip_clusters;\n\n\tif (clusters_to_add) {\n\t\tret = __ocfs2_extend_allocation(inode, oi->ip_clusters,\n\t\t\t\t\t\tclusters_to_add, 0);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * Call this even if we don't add any clusters to the tree. We\n\t * still need to zero the area between the old i_size and the\n\t * new i_size.\n\t */\n\tret = ocfs2_zero_extend(inode, di_bh, zero_to);\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_extend_file(struct inode *inode,\n\t\t\t     struct buffer_head *di_bh,\n\t\t\t     u64 new_i_size)\n{\n\tint ret = 0;\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\n\tBUG_ON(!di_bh);\n\n\t/* setattr sometimes calls us like this. */\n\tif (new_i_size == 0)\n\t\tgoto out;\n\n\tif (i_size_read(inode) == new_i_size)\n\t\tgoto out;\n\tBUG_ON(new_i_size < i_size_read(inode));\n\n\t/*\n\t * The alloc sem blocks people in read/write from reading our\n\t * allocation until we're done changing it. We depend on\n\t * i_mutex to block other extend/truncate calls while we're\n\t * here.  We even have to hold it for sparse files because there\n\t * might be some tail zeroing.\n\t */\n\tdown_write(&oi->ip_alloc_sem);\n\n\tif (oi->ip_dyn_features & OCFS2_INLINE_DATA_FL) {\n\t\t/*\n\t\t * We can optimize small extends by keeping the inodes\n\t\t * inline data.\n\t\t */\n\t\tif (ocfs2_size_fits_inline_data(di_bh, new_i_size)) {\n\t\t\tup_write(&oi->ip_alloc_sem);\n\t\t\tgoto out_update_size;\n\t\t}\n\n\t\tret = ocfs2_convert_inline_data_to_extents(inode, di_bh);\n\t\tif (ret) {\n\t\t\tup_write(&oi->ip_alloc_sem);\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (ocfs2_sparse_alloc(OCFS2_SB(inode->i_sb)))\n\t\tret = ocfs2_zero_extend(inode, di_bh, new_i_size);\n\telse\n\t\tret = ocfs2_extend_no_holes(inode, di_bh, new_i_size,\n\t\t\t\t\t    new_i_size);\n\n\tup_write(&oi->ip_alloc_sem);\n\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\nout_update_size:\n\tret = ocfs2_simple_size_update(inode, di_bh, new_i_size);\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\nout:\n\treturn ret;\n}\n\nint ocfs2_setattr(struct dentry *dentry, struct iattr *attr)\n{\n\tint status = 0, size_change;\n\tint inode_locked = 0;\n\tstruct inode *inode = d_inode(dentry);\n\tstruct super_block *sb = inode->i_sb;\n\tstruct ocfs2_super *osb = OCFS2_SB(sb);\n\tstruct buffer_head *bh = NULL;\n\thandle_t *handle = NULL;\n\tstruct dquot *transfer_to[MAXQUOTAS] = { };\n\tint qtype;\n\tint had_lock;\n\tstruct ocfs2_lock_holder oh;\n\n\ttrace_ocfs2_setattr(inode, dentry,\n\t\t\t    (unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t    dentry->d_name.len, dentry->d_name.name,\n\t\t\t    attr->ia_valid, attr->ia_mode,\n\t\t\t    from_kuid(&init_user_ns, attr->ia_uid),\n\t\t\t    from_kgid(&init_user_ns, attr->ia_gid));\n\n\t/* ensuring we don't even attempt to truncate a symlink */\n\tif (S_ISLNK(inode->i_mode))\n\t\tattr->ia_valid &= ~ATTR_SIZE;\n\n#define OCFS2_VALID_ATTRS (ATTR_ATIME | ATTR_MTIME | ATTR_CTIME | ATTR_SIZE \\\n\t\t\t   | ATTR_GID | ATTR_UID | ATTR_MODE)\n\tif (!(attr->ia_valid & OCFS2_VALID_ATTRS))\n\t\treturn 0;\n\n\tstatus = setattr_prepare(dentry, attr);\n\tif (status)\n\t\treturn status;\n\n\tif (is_quota_modification(inode, attr)) {\n\t\tstatus = dquot_initialize(inode);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tsize_change = S_ISREG(inode->i_mode) && attr->ia_valid & ATTR_SIZE;\n\tif (size_change) {\n\t\tstatus = ocfs2_rw_lock(inode, 1);\n\t\tif (status < 0) {\n\t\t\tmlog_errno(status);\n\t\t\tgoto bail;\n\t\t}\n\t}\n\n\thad_lock = ocfs2_inode_lock_tracker(inode, &bh, 1, &oh);\n\tif (had_lock < 0) {\n\t\tstatus = had_lock;\n\t\tgoto bail_unlock_rw;\n\t} else if (had_lock) {\n\t\t/*\n\t\t * As far as we know, ocfs2_setattr() could only be the first\n\t\t * VFS entry point in the call chain of recursive cluster\n\t\t * locking issue.\n\t\t *\n\t\t * For instance:\n\t\t * chmod_common()\n\t\t *  notify_change()\n\t\t *   ocfs2_setattr()\n\t\t *    posix_acl_chmod()\n\t\t *     ocfs2_iop_get_acl()\n\t\t *\n\t\t * But, we're not 100% sure if it's always true, because the\n\t\t * ordering of the VFS entry points in the call chain is out\n\t\t * of our control. So, we'd better dump the stack here to\n\t\t * catch the other cases of recursive locking.\n\t\t */\n\t\tmlog(ML_ERROR, \"Another case of recursive locking:\\n\");\n\t\tdump_stack();\n\t}\n\tinode_locked = 1;\n\n\tif (size_change) {\n\t\tstatus = inode_newsize_ok(inode, attr->ia_size);\n\t\tif (status)\n\t\t\tgoto bail_unlock;\n\n\t\tinode_dio_wait(inode);\n\n\t\tif (i_size_read(inode) >= attr->ia_size) {\n\t\t\tif (ocfs2_should_order_data(inode)) {\n\t\t\t\tstatus = ocfs2_begin_ordered_truncate(inode,\n\t\t\t\t\t\t\t\t      attr->ia_size);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto bail_unlock;\n\t\t\t}\n\t\t\tstatus = ocfs2_truncate_file(inode, bh, attr->ia_size);\n\t\t} else\n\t\t\tstatus = ocfs2_extend_file(inode, bh, attr->ia_size);\n\t\tif (status < 0) {\n\t\t\tif (status != -ENOSPC)\n\t\t\t\tmlog_errno(status);\n\t\t\tstatus = -ENOSPC;\n\t\t\tgoto bail_unlock;\n\t\t}\n\t}\n\n\tif ((attr->ia_valid & ATTR_UID && !uid_eq(attr->ia_uid, inode->i_uid)) ||\n\t    (attr->ia_valid & ATTR_GID && !gid_eq(attr->ia_gid, inode->i_gid))) {\n\t\t/*\n\t\t * Gather pointers to quota structures so that allocation /\n\t\t * freeing of quota structures happens here and not inside\n\t\t * dquot_transfer() where we have problems with lock ordering\n\t\t */\n\t\tif (attr->ia_valid & ATTR_UID && !uid_eq(attr->ia_uid, inode->i_uid)\n\t\t    && OCFS2_HAS_RO_COMPAT_FEATURE(sb,\n\t\t    OCFS2_FEATURE_RO_COMPAT_USRQUOTA)) {\n\t\t\ttransfer_to[USRQUOTA] = dqget(sb, make_kqid_uid(attr->ia_uid));\n\t\t\tif (IS_ERR(transfer_to[USRQUOTA])) {\n\t\t\t\tstatus = PTR_ERR(transfer_to[USRQUOTA]);\n\t\t\t\tgoto bail_unlock;\n\t\t\t}\n\t\t}\n\t\tif (attr->ia_valid & ATTR_GID && !gid_eq(attr->ia_gid, inode->i_gid)\n\t\t    && OCFS2_HAS_RO_COMPAT_FEATURE(sb,\n\t\t    OCFS2_FEATURE_RO_COMPAT_GRPQUOTA)) {\n\t\t\ttransfer_to[GRPQUOTA] = dqget(sb, make_kqid_gid(attr->ia_gid));\n\t\t\tif (IS_ERR(transfer_to[GRPQUOTA])) {\n\t\t\t\tstatus = PTR_ERR(transfer_to[GRPQUOTA]);\n\t\t\t\tgoto bail_unlock;\n\t\t\t}\n\t\t}\n\t\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS +\n\t\t\t\t\t   2 * ocfs2_quota_trans_credits(sb));\n\t\tif (IS_ERR(handle)) {\n\t\t\tstatus = PTR_ERR(handle);\n\t\t\tmlog_errno(status);\n\t\t\tgoto bail_unlock;\n\t\t}\n\t\tstatus = __dquot_transfer(inode, transfer_to);\n\t\tif (status < 0)\n\t\t\tgoto bail_commit;\n\t} else {\n\t\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\t\tif (IS_ERR(handle)) {\n\t\t\tstatus = PTR_ERR(handle);\n\t\t\tmlog_errno(status);\n\t\t\tgoto bail_unlock;\n\t\t}\n\t}\n\n\tsetattr_copy(inode, attr);\n\tmark_inode_dirty(inode);\n\n\tstatus = ocfs2_mark_inode_dirty(handle, inode, bh);\n\tif (status < 0)\n\t\tmlog_errno(status);\n\nbail_commit:\n\tocfs2_commit_trans(osb, handle);\nbail_unlock:\n\tif (status && inode_locked) {\n\t\tocfs2_inode_unlock_tracker(inode, 1, &oh, had_lock);\n\t\tinode_locked = 0;\n\t}\nbail_unlock_rw:\n\tif (size_change)\n\t\tocfs2_rw_unlock(inode, 1);\nbail:\n\n\t/* Release quota pointers in case we acquired them */\n\tfor (qtype = 0; qtype < OCFS2_MAXQUOTAS; qtype++)\n\t\tdqput(transfer_to[qtype]);\n\n\tif (!status && attr->ia_valid & ATTR_MODE) {\n\t\tstatus = ocfs2_acl_chmod(inode, bh);\n\t\tif (status < 0)\n\t\t\tmlog_errno(status);\n\t}\n\tif (inode_locked)\n\t\tocfs2_inode_unlock_tracker(inode, 1, &oh, had_lock);\n\n\tbrelse(bh);\n\treturn status;\n}\n\nint ocfs2_getattr(const struct path *path, struct kstat *stat,\n\t\t  u32 request_mask, unsigned int flags)\n{\n\tstruct inode *inode = d_inode(path->dentry);\n\tstruct super_block *sb = path->dentry->d_sb;\n\tstruct ocfs2_super *osb = sb->s_fs_info;\n\tint err;\n\n\terr = ocfs2_inode_revalidate(path->dentry);\n\tif (err) {\n\t\tif (err != -ENOENT)\n\t\t\tmlog_errno(err);\n\t\tgoto bail;\n\t}\n\n\tgeneric_fillattr(inode, stat);\n\t/*\n\t * If there is inline data in the inode, the inode will normally not\n\t * have data blocks allocated (it may have an external xattr block).\n\t * Report at least one sector for such files, so tools like tar, rsync,\n\t * others don't incorrectly think the file is completely sparse.\n\t */\n\tif (unlikely(OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL))\n\t\tstat->blocks += (stat->size + 511)>>9;\n\n\t/* We set the blksize from the cluster size for performance */\n\tstat->blksize = osb->s_clustersize;\n\nbail:\n\treturn err;\n}\n\nint ocfs2_permission(struct inode *inode, int mask)\n{\n\tint ret, had_lock;\n\tstruct ocfs2_lock_holder oh;\n\n\tif (mask & MAY_NOT_BLOCK)\n\t\treturn -ECHILD;\n\n\thad_lock = ocfs2_inode_lock_tracker(inode, NULL, 0, &oh);\n\tif (had_lock < 0) {\n\t\tret = had_lock;\n\t\tgoto out;\n\t} else if (had_lock) {\n\t\t/* See comments in ocfs2_setattr() for details.\n\t\t * The call chain of this case could be:\n\t\t * do_sys_open()\n\t\t *  may_open()\n\t\t *   inode_permission()\n\t\t *    ocfs2_permission()\n\t\t *     ocfs2_iop_get_acl()\n\t\t */\n\t\tmlog(ML_ERROR, \"Another case of recursive locking:\\n\");\n\t\tdump_stack();\n\t}\n\n\tret = generic_permission(inode, mask);\n\n\tocfs2_inode_unlock_tracker(inode, 0, &oh, had_lock);\nout:\n\treturn ret;\n}\n\nstatic int __ocfs2_write_remove_suid(struct inode *inode,\n\t\t\t\t     struct buffer_head *bh)\n{\n\tint ret;\n\thandle_t *handle;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_dinode *di;\n\n\ttrace_ocfs2_write_remove_suid(\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\tinode->i_mode);\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_journal_access_di(handle, INODE_CACHE(inode), bh,\n\t\t\t\t      OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out_trans;\n\t}\n\n\tinode->i_mode &= ~S_ISUID;\n\tif ((inode->i_mode & S_ISGID) && (inode->i_mode & S_IXGRP))\n\t\tinode->i_mode &= ~S_ISGID;\n\n\tdi = (struct ocfs2_dinode *) bh->b_data;\n\tdi->i_mode = cpu_to_le16(inode->i_mode);\n\tocfs2_update_inode_fsync_trans(handle, inode, 0);\n\n\tocfs2_journal_dirty(handle, bh);\n\nout_trans:\n\tocfs2_commit_trans(osb, handle);\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_write_remove_suid(struct inode *inode)\n{\n\tint ret;\n\tstruct buffer_head *bh = NULL;\n\n\tret = ocfs2_read_inode_block(inode, &bh);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret =  __ocfs2_write_remove_suid(inode, bh);\nout:\n\tbrelse(bh);\n\treturn ret;\n}\n\n/*\n * Allocate enough extents to cover the region starting at byte offset\n * start for len bytes. Existing extents are skipped, any extents\n * added are marked as \"unwritten\".\n */\nstatic int ocfs2_allocate_unwritten_extents(struct inode *inode,\n\t\t\t\t\t    u64 start, u64 len)\n{\n\tint ret;\n\tu32 cpos, phys_cpos, clusters, alloc_size;\n\tu64 end = start + len;\n\tstruct buffer_head *di_bh = NULL;\n\n\tif (OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL) {\n\t\tret = ocfs2_read_inode_block(inode, &di_bh);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\t/*\n\t\t * Nothing to do if the requested reservation range\n\t\t * fits within the inode.\n\t\t */\n\t\tif (ocfs2_size_fits_inline_data(di_bh, end))\n\t\t\tgoto out;\n\n\t\tret = ocfs2_convert_inline_data_to_extents(inode, di_bh);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * We consider both start and len to be inclusive.\n\t */\n\tcpos = start >> OCFS2_SB(inode->i_sb)->s_clustersize_bits;\n\tclusters = ocfs2_clusters_for_bytes(inode->i_sb, start + len);\n\tclusters -= cpos;\n\n\twhile (clusters) {\n\t\tret = ocfs2_get_clusters(inode, cpos, &phys_cpos,\n\t\t\t\t\t &alloc_size, NULL);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\t/*\n\t\t * Hole or existing extent len can be arbitrary, so\n\t\t * cap it to our own allocation request.\n\t\t */\n\t\tif (alloc_size > clusters)\n\t\t\talloc_size = clusters;\n\n\t\tif (phys_cpos) {\n\t\t\t/*\n\t\t\t * We already have an allocation at this\n\t\t\t * region so we can safely skip it.\n\t\t\t */\n\t\t\tgoto next;\n\t\t}\n\n\t\tret = __ocfs2_extend_allocation(inode, cpos, alloc_size, 1);\n\t\tif (ret) {\n\t\t\tif (ret != -ENOSPC)\n\t\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\nnext:\n\t\tcpos += alloc_size;\n\t\tclusters -= alloc_size;\n\t}\n\n\tret = 0;\nout:\n\n\tbrelse(di_bh);\n\treturn ret;\n}\n\n/*\n * Truncate a byte range, avoiding pages within partial clusters. This\n * preserves those pages for the zeroing code to write to.\n */\nstatic void ocfs2_truncate_cluster_pages(struct inode *inode, u64 byte_start,\n\t\t\t\t\t u64 byte_len)\n{\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tloff_t start, end;\n\tstruct address_space *mapping = inode->i_mapping;\n\n\tstart = (loff_t)ocfs2_align_bytes_to_clusters(inode->i_sb, byte_start);\n\tend = byte_start + byte_len;\n\tend = end & ~(osb->s_clustersize - 1);\n\n\tif (start < end) {\n\t\tunmap_mapping_range(mapping, start, end - start, 0);\n\t\ttruncate_inode_pages_range(mapping, start, end - 1);\n\t}\n}\n\nstatic int ocfs2_zero_partial_clusters(struct inode *inode,\n\t\t\t\t       u64 start, u64 len)\n{\n\tint ret = 0;\n\tu64 tmpend = 0;\n\tu64 end = start + len;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tunsigned int csize = osb->s_clustersize;\n\thandle_t *handle;\n\n\t/*\n\t * The \"start\" and \"end\" values are NOT necessarily part of\n\t * the range whose allocation is being deleted. Rather, this\n\t * is what the user passed in with the request. We must zero\n\t * partial clusters here. There's no need to worry about\n\t * physical allocation - the zeroing code knows to skip holes.\n\t */\n\ttrace_ocfs2_zero_partial_clusters(\n\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t(unsigned long long)start, (unsigned long long)end);\n\n\t/*\n\t * If both edges are on a cluster boundary then there's no\n\t * zeroing required as the region is part of the allocation to\n\t * be truncated.\n\t */\n\tif ((start & (csize - 1)) == 0 && (end & (csize - 1)) == 0)\n\t\tgoto out;\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If start is on a cluster boundary and end is somewhere in another\n\t * cluster, we have not COWed the cluster starting at start, unless\n\t * end is also within the same cluster. So, in this case, we skip this\n\t * first call to ocfs2_zero_range_for_truncate() truncate and move on\n\t * to the next one.\n\t */\n\tif ((start & (csize - 1)) != 0) {\n\t\t/*\n\t\t * We want to get the byte offset of the end of the 1st\n\t\t * cluster.\n\t\t */\n\t\ttmpend = (u64)osb->s_clustersize +\n\t\t\t(start & ~(osb->s_clustersize - 1));\n\t\tif (tmpend > end)\n\t\t\ttmpend = end;\n\n\t\ttrace_ocfs2_zero_partial_clusters_range1(\n\t\t\t(unsigned long long)start,\n\t\t\t(unsigned long long)tmpend);\n\n\t\tret = ocfs2_zero_range_for_truncate(inode, handle, start,\n\t\t\t\t\t\t    tmpend);\n\t\tif (ret)\n\t\t\tmlog_errno(ret);\n\t}\n\n\tif (tmpend < end) {\n\t\t/*\n\t\t * This may make start and end equal, but the zeroing\n\t\t * code will skip any work in that case so there's no\n\t\t * need to catch it up here.\n\t\t */\n\t\tstart = end & ~(osb->s_clustersize - 1);\n\n\t\ttrace_ocfs2_zero_partial_clusters_range2(\n\t\t\t(unsigned long long)start, (unsigned long long)end);\n\n\t\tret = ocfs2_zero_range_for_truncate(inode, handle, start, end);\n\t\tif (ret)\n\t\t\tmlog_errno(ret);\n\t}\n\tocfs2_update_inode_fsync_trans(handle, inode, 1);\n\n\tocfs2_commit_trans(osb, handle);\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_find_rec(struct ocfs2_extent_list *el, u32 pos)\n{\n\tint i;\n\tstruct ocfs2_extent_rec *rec = NULL;\n\n\tfor (i = le16_to_cpu(el->l_next_free_rec) - 1; i >= 0; i--) {\n\n\t\trec = &el->l_recs[i];\n\n\t\tif (le32_to_cpu(rec->e_cpos) < pos)\n\t\t\tbreak;\n\t}\n\n\treturn i;\n}\n\n/*\n * Helper to calculate the punching pos and length in one run, we handle the\n * following three cases in order:\n *\n * - remove the entire record\n * - remove a partial record\n * - no record needs to be removed (hole-punching completed)\n*/\nstatic void ocfs2_calc_trunc_pos(struct inode *inode,\n\t\t\t\t struct ocfs2_extent_list *el,\n\t\t\t\t struct ocfs2_extent_rec *rec,\n\t\t\t\t u32 trunc_start, u32 *trunc_cpos,\n\t\t\t\t u32 *trunc_len, u32 *trunc_end,\n\t\t\t\t u64 *blkno, int *done)\n{\n\tint ret = 0;\n\tu32 coff, range;\n\n\trange = le32_to_cpu(rec->e_cpos) + ocfs2_rec_clusters(el, rec);\n\n\tif (le32_to_cpu(rec->e_cpos) >= trunc_start) {\n\t\t/*\n\t\t * remove an entire extent record.\n\t\t */\n\t\t*trunc_cpos = le32_to_cpu(rec->e_cpos);\n\t\t/*\n\t\t * Skip holes if any.\n\t\t */\n\t\tif (range < *trunc_end)\n\t\t\t*trunc_end = range;\n\t\t*trunc_len = *trunc_end - le32_to_cpu(rec->e_cpos);\n\t\t*blkno = le64_to_cpu(rec->e_blkno);\n\t\t*trunc_end = le32_to_cpu(rec->e_cpos);\n\t} else if (range > trunc_start) {\n\t\t/*\n\t\t * remove a partial extent record, which means we're\n\t\t * removing the last extent record.\n\t\t */\n\t\t*trunc_cpos = trunc_start;\n\t\t/*\n\t\t * skip hole if any.\n\t\t */\n\t\tif (range < *trunc_end)\n\t\t\t*trunc_end = range;\n\t\t*trunc_len = *trunc_end - trunc_start;\n\t\tcoff = trunc_start - le32_to_cpu(rec->e_cpos);\n\t\t*blkno = le64_to_cpu(rec->e_blkno) +\n\t\t\t\tocfs2_clusters_to_blocks(inode->i_sb, coff);\n\t\t*trunc_end = trunc_start;\n\t} else {\n\t\t/*\n\t\t * It may have two following possibilities:\n\t\t *\n\t\t * - last record has been removed\n\t\t * - trunc_start was within a hole\n\t\t *\n\t\t * both two cases mean the completion of hole punching.\n\t\t */\n\t\tret = 1;\n\t}\n\n\t*done = ret;\n}\n\nint ocfs2_remove_inode_range(struct inode *inode,\n\t\t\t     struct buffer_head *di_bh, u64 byte_start,\n\t\t\t     u64 byte_len)\n{\n\tint ret = 0, flags = 0, done = 0, i;\n\tu32 trunc_start, trunc_len, trunc_end, trunc_cpos, phys_cpos;\n\tu32 cluster_in_el;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_cached_dealloc_ctxt dealloc;\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct ocfs2_extent_tree et;\n\tstruct ocfs2_path *path = NULL;\n\tstruct ocfs2_extent_list *el = NULL;\n\tstruct ocfs2_extent_rec *rec = NULL;\n\tstruct ocfs2_dinode *di = (struct ocfs2_dinode *)di_bh->b_data;\n\tu64 blkno, refcount_loc = le64_to_cpu(di->i_refcount_loc);\n\n\tocfs2_init_dinode_extent_tree(&et, INODE_CACHE(inode), di_bh);\n\tocfs2_init_dealloc_ctxt(&dealloc);\n\n\ttrace_ocfs2_remove_inode_range(\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t(unsigned long long)byte_start,\n\t\t\t(unsigned long long)byte_len);\n\n\tif (byte_len == 0)\n\t\treturn 0;\n\n\tif (OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL) {\n\t\tret = ocfs2_truncate_inline(inode, di_bh, byte_start,\n\t\t\t\t\t    byte_start + byte_len, 0);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t\t/*\n\t\t * There's no need to get fancy with the page cache\n\t\t * truncate of an inline-data inode. We're talking\n\t\t * about less than a page here, which will be cached\n\t\t * in the dinode buffer anyway.\n\t\t */\n\t\tunmap_mapping_range(mapping, 0, 0, 0);\n\t\ttruncate_inode_pages(mapping, 0);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * For reflinks, we may need to CoW 2 clusters which might be\n\t * partially zero'd later, if hole's start and end offset were\n\t * within one cluster(means is not exactly aligned to clustersize).\n\t */\n\n\tif (ocfs2_is_refcount_inode(inode)) {\n\t\tret = ocfs2_cow_file_pos(inode, di_bh, byte_start);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = ocfs2_cow_file_pos(inode, di_bh, byte_start + byte_len);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\ttrunc_start = ocfs2_clusters_for_bytes(osb->sb, byte_start);\n\ttrunc_end = (byte_start + byte_len) >> osb->s_clustersize_bits;\n\tcluster_in_el = trunc_end;\n\n\tret = ocfs2_zero_partial_clusters(inode, byte_start, byte_len);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tpath = ocfs2_new_path_from_et(&et);\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\twhile (trunc_end > trunc_start) {\n\n\t\tret = ocfs2_find_path(INODE_CACHE(inode), path,\n\t\t\t\t      cluster_in_el);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tel = path_leaf_el(path);\n\n\t\ti = ocfs2_find_rec(el, trunc_end);\n\t\t/*\n\t\t * Need to go to previous extent block.\n\t\t */\n\t\tif (i < 0) {\n\t\t\tif (path->p_tree_depth == 0)\n\t\t\t\tbreak;\n\n\t\t\tret = ocfs2_find_cpos_for_left_leaf(inode->i_sb,\n\t\t\t\t\t\t\t    path,\n\t\t\t\t\t\t\t    &cluster_in_el);\n\t\t\tif (ret) {\n\t\t\t\tmlog_errno(ret);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * We've reached the leftmost extent block,\n\t\t\t * it's safe to leave.\n\t\t\t */\n\t\t\tif (cluster_in_el == 0)\n\t\t\t\tbreak;\n\n\t\t\t/*\n\t\t\t * The 'pos' searched for previous extent block is\n\t\t\t * always one cluster less than actual trunc_end.\n\t\t\t */\n\t\t\ttrunc_end = cluster_in_el + 1;\n\n\t\t\tocfs2_reinit_path(path, 1);\n\n\t\t\tcontinue;\n\n\t\t} else\n\t\t\trec = &el->l_recs[i];\n\n\t\tocfs2_calc_trunc_pos(inode, el, rec, trunc_start, &trunc_cpos,\n\t\t\t\t     &trunc_len, &trunc_end, &blkno, &done);\n\t\tif (done)\n\t\t\tbreak;\n\n\t\tflags = rec->e_flags;\n\t\tphys_cpos = ocfs2_blocks_to_clusters(inode->i_sb, blkno);\n\n\t\tret = ocfs2_remove_btree_range(inode, &et, trunc_cpos,\n\t\t\t\t\t       phys_cpos, trunc_len, flags,\n\t\t\t\t\t       &dealloc, refcount_loc, false);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tcluster_in_el = trunc_end;\n\n\t\tocfs2_reinit_path(path, 1);\n\t}\n\n\tocfs2_truncate_cluster_pages(inode, byte_start, byte_len);\n\nout:\n\tocfs2_free_path(path);\n\tocfs2_schedule_truncate_log_flush(osb, 1);\n\tocfs2_run_deallocs(osb, &dealloc);\n\n\treturn ret;\n}\n\n/*\n * Parts of this function taken from xfs_change_file_space()\n */\nstatic int __ocfs2_change_file_space(struct file *file, struct inode *inode,\n\t\t\t\t     loff_t f_pos, unsigned int cmd,\n\t\t\t\t     struct ocfs2_space_resv *sr,\n\t\t\t\t     int change_size)\n{\n\tint ret;\n\ts64 llen;\n\tloff_t size;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct buffer_head *di_bh = NULL;\n\thandle_t *handle;\n\tunsigned long long max_off = inode->i_sb->s_maxbytes;\n\n\tif (ocfs2_is_hard_readonly(osb) || ocfs2_is_soft_readonly(osb))\n\t\treturn -EROFS;\n\n\tinode_lock(inode);\n\n\t/*\n\t * This prevents concurrent writes on other nodes\n\t */\n\tret = ocfs2_rw_lock(inode, 1);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_inode_lock(inode, &di_bh, 1);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out_rw_unlock;\n\t}\n\n\tif (inode->i_flags & (S_IMMUTABLE|S_APPEND)) {\n\t\tret = -EPERM;\n\t\tgoto out_inode_unlock;\n\t}\n\n\tswitch (sr->l_whence) {\n\tcase 0: /*SEEK_SET*/\n\t\tbreak;\n\tcase 1: /*SEEK_CUR*/\n\t\tsr->l_start += f_pos;\n\t\tbreak;\n\tcase 2: /*SEEK_END*/\n\t\tsr->l_start += i_size_read(inode);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto out_inode_unlock;\n\t}\n\tsr->l_whence = 0;\n\n\tllen = sr->l_len > 0 ? sr->l_len - 1 : sr->l_len;\n\n\tif (sr->l_start < 0\n\t    || sr->l_start > max_off\n\t    || (sr->l_start + llen) < 0\n\t    || (sr->l_start + llen) > max_off) {\n\t\tret = -EINVAL;\n\t\tgoto out_inode_unlock;\n\t}\n\tsize = sr->l_start + sr->l_len;\n\n\tif (cmd == OCFS2_IOC_RESVSP || cmd == OCFS2_IOC_RESVSP64 ||\n\t    cmd == OCFS2_IOC_UNRESVSP || cmd == OCFS2_IOC_UNRESVSP64) {\n\t\tif (sr->l_len <= 0) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_inode_unlock;\n\t\t}\n\t}\n\n\tif (file && should_remove_suid(file->f_path.dentry)) {\n\t\tret = __ocfs2_write_remove_suid(inode, di_bh);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out_inode_unlock;\n\t\t}\n\t}\n\n\tdown_write(&OCFS2_I(inode)->ip_alloc_sem);\n\tswitch (cmd) {\n\tcase OCFS2_IOC_RESVSP:\n\tcase OCFS2_IOC_RESVSP64:\n\t\t/*\n\t\t * This takes unsigned offsets, but the signed ones we\n\t\t * pass have been checked against overflow above.\n\t\t */\n\t\tret = ocfs2_allocate_unwritten_extents(inode, sr->l_start,\n\t\t\t\t\t\t       sr->l_len);\n\t\tbreak;\n\tcase OCFS2_IOC_UNRESVSP:\n\tcase OCFS2_IOC_UNRESVSP64:\n\t\tret = ocfs2_remove_inode_range(inode, di_bh, sr->l_start,\n\t\t\t\t\t       sr->l_len);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\tup_write(&OCFS2_I(inode)->ip_alloc_sem);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out_inode_unlock;\n\t}\n\n\t/*\n\t * We update c/mtime for these changes\n\t */\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out_inode_unlock;\n\t}\n\n\tif (change_size && i_size_read(inode) < size)\n\t\ti_size_write(inode, size);\n\n\tinode->i_ctime = inode->i_mtime = current_time(inode);\n\tret = ocfs2_mark_inode_dirty(handle, inode, di_bh);\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\n\tif (file && (file->f_flags & O_SYNC))\n\t\thandle->h_sync = 1;\n\n\tocfs2_commit_trans(osb, handle);\n\nout_inode_unlock:\n\tbrelse(di_bh);\n\tocfs2_inode_unlock(inode, 1);\nout_rw_unlock:\n\tocfs2_rw_unlock(inode, 1);\n\nout:\n\tinode_unlock(inode);\n\treturn ret;\n}\n\nint ocfs2_change_file_space(struct file *file, unsigned int cmd,\n\t\t\t    struct ocfs2_space_resv *sr)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tint ret;\n\n\tif ((cmd == OCFS2_IOC_RESVSP || cmd == OCFS2_IOC_RESVSP64) &&\n\t    !ocfs2_writes_unwritten_extents(osb))\n\t\treturn -ENOTTY;\n\telse if ((cmd == OCFS2_IOC_UNRESVSP || cmd == OCFS2_IOC_UNRESVSP64) &&\n\t\t !ocfs2_sparse_alloc(osb))\n\t\treturn -ENOTTY;\n\n\tif (!S_ISREG(inode->i_mode))\n\t\treturn -EINVAL;\n\n\tif (!(file->f_mode & FMODE_WRITE))\n\t\treturn -EBADF;\n\n\tret = mnt_want_write_file(file);\n\tif (ret)\n\t\treturn ret;\n\tret = __ocfs2_change_file_space(file, inode, file->f_pos, cmd, sr, 0);\n\tmnt_drop_write_file(file);\n\treturn ret;\n}\n\nstatic long ocfs2_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t    loff_t len)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_space_resv sr;\n\tint change_size = 1;\n\tint cmd = OCFS2_IOC_RESVSP64;\n\n\tif (mode & ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))\n\t\treturn -EOPNOTSUPP;\n\tif (!ocfs2_writes_unwritten_extents(osb))\n\t\treturn -EOPNOTSUPP;\n\n\tif (mode & FALLOC_FL_KEEP_SIZE)\n\t\tchange_size = 0;\n\n\tif (mode & FALLOC_FL_PUNCH_HOLE)\n\t\tcmd = OCFS2_IOC_UNRESVSP64;\n\n\tsr.l_whence = 0;\n\tsr.l_start = (s64)offset;\n\tsr.l_len = (s64)len;\n\n\treturn __ocfs2_change_file_space(NULL, inode, offset, cmd, &sr,\n\t\t\t\t\t change_size);\n}\n\nint ocfs2_check_range_for_refcount(struct inode *inode, loff_t pos,\n\t\t\t\t   size_t count)\n{\n\tint ret = 0;\n\tunsigned int extent_flags;\n\tu32 cpos, clusters, extent_len, phys_cpos;\n\tstruct super_block *sb = inode->i_sb;\n\n\tif (!ocfs2_refcount_tree(OCFS2_SB(inode->i_sb)) ||\n\t    !ocfs2_is_refcount_inode(inode) ||\n\t    OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL)\n\t\treturn 0;\n\n\tcpos = pos >> OCFS2_SB(sb)->s_clustersize_bits;\n\tclusters = ocfs2_clusters_for_bytes(sb, pos + count) - cpos;\n\n\twhile (clusters) {\n\t\tret = ocfs2_get_clusters(inode, cpos, &phys_cpos, &extent_len,\n\t\t\t\t\t &extent_flags);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (phys_cpos && (extent_flags & OCFS2_EXT_REFCOUNTED)) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (extent_len > clusters)\n\t\t\textent_len = clusters;\n\n\t\tclusters -= extent_len;\n\t\tcpos += extent_len;\n\t}\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_is_io_unaligned(struct inode *inode, size_t count, loff_t pos)\n{\n\tint blockmask = inode->i_sb->s_blocksize - 1;\n\tloff_t final_size = pos + count;\n\n\tif ((pos & blockmask) || (final_size & blockmask))\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic int ocfs2_prepare_inode_for_refcount(struct inode *inode,\n\t\t\t\t\t    struct file *file,\n\t\t\t\t\t    loff_t pos, size_t count,\n\t\t\t\t\t    int *meta_level)\n{\n\tint ret;\n\tstruct buffer_head *di_bh = NULL;\n\tu32 cpos = pos >> OCFS2_SB(inode->i_sb)->s_clustersize_bits;\n\tu32 clusters =\n\t\tocfs2_clusters_for_bytes(inode->i_sb, pos + count) - cpos;\n\n\tret = ocfs2_inode_lock(inode, &di_bh, 1);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\t*meta_level = 1;\n\n\tret = ocfs2_refcount_cow(inode, di_bh, cpos, clusters, UINT_MAX);\n\tif (ret)\n\t\tmlog_errno(ret);\nout:\n\tbrelse(di_bh);\n\treturn ret;\n}\n\nstatic int ocfs2_prepare_inode_for_write(struct file *file,\n\t\t\t\t\t loff_t pos,\n\t\t\t\t\t size_t count)\n{\n\tint ret = 0, meta_level = 0;\n\tstruct dentry *dentry = file->f_path.dentry;\n\tstruct inode *inode = d_inode(dentry);\n\tloff_t end;\n\n\t/*\n\t * We start with a read level meta lock and only jump to an ex\n\t * if we need to make modifications here.\n\t */\n\tfor(;;) {\n\t\tret = ocfs2_inode_lock(inode, NULL, meta_level);\n\t\tif (ret < 0) {\n\t\t\tmeta_level = -1;\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* Clear suid / sgid if necessary. We do this here\n\t\t * instead of later in the write path because\n\t\t * remove_suid() calls ->setattr without any hint that\n\t\t * we may have already done our cluster locking. Since\n\t\t * ocfs2_setattr() *must* take cluster locks to\n\t\t * proceed, this will lead us to recursively lock the\n\t\t * inode. There's also the dinode i_size state which\n\t\t * can be lost via setattr during extending writes (we\n\t\t * set inode->i_size at the end of a write. */\n\t\tif (should_remove_suid(dentry)) {\n\t\t\tif (meta_level == 0) {\n\t\t\t\tocfs2_inode_unlock(inode, meta_level);\n\t\t\t\tmeta_level = 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = ocfs2_write_remove_suid(inode);\n\t\t\tif (ret < 0) {\n\t\t\t\tmlog_errno(ret);\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t}\n\n\t\tend = pos + count;\n\n\t\tret = ocfs2_check_range_for_refcount(inode, pos, count);\n\t\tif (ret == 1) {\n\t\t\tocfs2_inode_unlock(inode, meta_level);\n\t\t\tmeta_level = -1;\n\n\t\t\tret = ocfs2_prepare_inode_for_refcount(inode,\n\t\t\t\t\t\t\t       file,\n\t\t\t\t\t\t\t       pos,\n\t\t\t\t\t\t\t       count,\n\t\t\t\t\t\t\t       &meta_level);\n\t\t}\n\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tbreak;\n\t}\n\nout_unlock:\n\ttrace_ocfs2_prepare_inode_for_write(OCFS2_I(inode)->ip_blkno,\n\t\t\t\t\t    pos, count);\n\n\tif (meta_level >= 0)\n\t\tocfs2_inode_unlock(inode, meta_level);\n\nout:\n\treturn ret;\n}\n\nstatic ssize_t ocfs2_file_write_iter(struct kiocb *iocb,\n\t\t\t\t    struct iov_iter *from)\n{\n\tint direct_io, rw_level;\n\tssize_t written = 0;\n\tssize_t ret;\n\tsize_t count = iov_iter_count(from);\n\tstruct file *file = iocb->ki_filp;\n\tstruct inode *inode = file_inode(file);\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tint full_coherency = !(osb->s_mount_opt &\n\t\t\t       OCFS2_MOUNT_COHERENCY_BUFFERED);\n\tvoid *saved_ki_complete = NULL;\n\tint append_write = ((iocb->ki_pos + count) >=\n\t\t\ti_size_read(inode) ? 1 : 0);\n\n\ttrace_ocfs2_file_aio_write(inode, file, file->f_path.dentry,\n\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\tfile->f_path.dentry->d_name.len,\n\t\tfile->f_path.dentry->d_name.name,\n\t\t(unsigned int)from->nr_segs);\t/* GRRRRR */\n\n\tif (count == 0)\n\t\treturn 0;\n\n\tdirect_io = iocb->ki_flags & IOCB_DIRECT ? 1 : 0;\n\n\tinode_lock(inode);\n\n\t/*\n\t * Concurrent O_DIRECT writes are allowed with\n\t * mount_option \"coherency=buffered\".\n\t * For append write, we must take rw EX.\n\t */\n\trw_level = (!direct_io || full_coherency || append_write);\n\n\tret = ocfs2_rw_lock(inode, rw_level);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out_mutex;\n\t}\n\n\t/*\n\t * O_DIRECT writes with \"coherency=full\" need to take EX cluster\n\t * inode_lock to guarantee coherency.\n\t */\n\tif (direct_io && full_coherency) {\n\t\t/*\n\t\t * We need to take and drop the inode lock to force\n\t\t * other nodes to drop their caches.  Buffered I/O\n\t\t * already does this in write_begin().\n\t\t */\n\t\tret = ocfs2_inode_lock(inode, NULL, 1);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tocfs2_inode_unlock(inode, 1);\n\t}\n\n\tret = generic_write_checks(iocb, from);\n\tif (ret <= 0) {\n\t\tif (ret)\n\t\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\tcount = ret;\n\n\tret = ocfs2_prepare_inode_for_write(file, iocb->ki_pos, count);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tif (direct_io && !is_sync_kiocb(iocb) &&\n\t    ocfs2_is_io_unaligned(inode, count, iocb->ki_pos)) {\n\t\t/*\n\t\t * Make it a sync io if it's an unaligned aio.\n\t\t */\n\t\tsaved_ki_complete = xchg(&iocb->ki_complete, NULL);\n\t}\n\n\t/* communicate with ocfs2_dio_end_io */\n\tocfs2_iocb_set_rw_locked(iocb, rw_level);\n\n\twritten = __generic_file_write_iter(iocb, from);\n\t/* buffered aio wouldn't have proper lock coverage today */\n\tBUG_ON(written == -EIOCBQUEUED && !(iocb->ki_flags & IOCB_DIRECT));\n\n\t/*\n\t * deep in g_f_a_w_n()->ocfs2_direct_IO we pass in a ocfs2_dio_end_io\n\t * function pointer which is called when o_direct io completes so that\n\t * it can unlock our rw lock.\n\t * Unfortunately there are error cases which call end_io and others\n\t * that don't.  so we don't have to unlock the rw_lock if either an\n\t * async dio is going to do it in the future or an end_io after an\n\t * error has already done it.\n\t */\n\tif ((written == -EIOCBQUEUED) || (!ocfs2_iocb_is_rw_locked(iocb))) {\n\t\trw_level = -1;\n\t}\n\n\tif (unlikely(written <= 0))\n\t\tgoto out;\n\n\tif (((file->f_flags & O_DSYNC) && !direct_io) ||\n\t    IS_SYNC(inode)) {\n\t\tret = filemap_fdatawrite_range(file->f_mapping,\n\t\t\t\t\t       iocb->ki_pos - written,\n\t\t\t\t\t       iocb->ki_pos - 1);\n\t\tif (ret < 0)\n\t\t\twritten = ret;\n\n\t\tif (!ret) {\n\t\t\tret = jbd2_journal_force_commit(osb->journal->j_journal);\n\t\t\tif (ret < 0)\n\t\t\t\twritten = ret;\n\t\t}\n\n\t\tif (!ret)\n\t\t\tret = filemap_fdatawait_range(file->f_mapping,\n\t\t\t\t\t\t      iocb->ki_pos - written,\n\t\t\t\t\t\t      iocb->ki_pos - 1);\n\t}\n\nout:\n\tif (saved_ki_complete)\n\t\txchg(&iocb->ki_complete, saved_ki_complete);\n\n\tif (rw_level != -1)\n\t\tocfs2_rw_unlock(inode, rw_level);\n\nout_mutex:\n\tinode_unlock(inode);\n\n\tif (written)\n\t\tret = written;\n\treturn ret;\n}\n\nstatic ssize_t ocfs2_file_read_iter(struct kiocb *iocb,\n\t\t\t\t   struct iov_iter *to)\n{\n\tint ret = 0, rw_level = -1, lock_level = 0;\n\tstruct file *filp = iocb->ki_filp;\n\tstruct inode *inode = file_inode(filp);\n\n\ttrace_ocfs2_file_aio_read(inode, filp, filp->f_path.dentry,\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\tfilp->f_path.dentry->d_name.len,\n\t\t\tfilp->f_path.dentry->d_name.name,\n\t\t\tto->nr_segs);\t/* GRRRRR */\n\n\n\tif (!inode) {\n\t\tret = -EINVAL;\n\t\tmlog_errno(ret);\n\t\tgoto bail;\n\t}\n\n\t/*\n\t * buffered reads protect themselves in ->readpage().  O_DIRECT reads\n\t * need locks to protect pending reads from racing with truncate.\n\t */\n\tif (iocb->ki_flags & IOCB_DIRECT) {\n\t\tret = ocfs2_rw_lock(inode, 0);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto bail;\n\t\t}\n\t\trw_level = 0;\n\t\t/* communicate with ocfs2_dio_end_io */\n\t\tocfs2_iocb_set_rw_locked(iocb, rw_level);\n\t}\n\n\t/*\n\t * We're fine letting folks race truncates and extending\n\t * writes with read across the cluster, just like they can\n\t * locally. Hence no rw_lock during read.\n\t *\n\t * Take and drop the meta data lock to update inode fields\n\t * like i_size. This allows the checks down below\n\t * generic_file_aio_read() a chance of actually working.\n\t */\n\tret = ocfs2_inode_lock_atime(inode, filp->f_path.mnt, &lock_level);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto bail;\n\t}\n\tocfs2_inode_unlock(inode, lock_level);\n\n\tret = generic_file_read_iter(iocb, to);\n\ttrace_generic_file_aio_read_ret(ret);\n\n\t/* buffered aio wouldn't have proper lock coverage today */\n\tBUG_ON(ret == -EIOCBQUEUED && !(iocb->ki_flags & IOCB_DIRECT));\n\n\t/* see ocfs2_file_write_iter */\n\tif (ret == -EIOCBQUEUED || !ocfs2_iocb_is_rw_locked(iocb)) {\n\t\trw_level = -1;\n\t}\n\nbail:\n\tif (rw_level != -1)\n\t\tocfs2_rw_unlock(inode, rw_level);\n\n\treturn ret;\n}\n\n/* Refer generic_file_llseek_unlocked() */\nstatic loff_t ocfs2_file_llseek(struct file *file, loff_t offset, int whence)\n{\n\tstruct inode *inode = file->f_mapping->host;\n\tint ret = 0;\n\n\tinode_lock(inode);\n\n\tswitch (whence) {\n\tcase SEEK_SET:\n\t\tbreak;\n\tcase SEEK_END:\n\t\t/* SEEK_END requires the OCFS2 inode lock for the file\n\t\t * because it references the file's size.\n\t\t */\n\t\tret = ocfs2_inode_lock(inode, NULL, 0);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t\toffset += i_size_read(inode);\n\t\tocfs2_inode_unlock(inode, 0);\n\t\tbreak;\n\tcase SEEK_CUR:\n\t\tif (offset == 0) {\n\t\t\toffset = file->f_pos;\n\t\t\tgoto out;\n\t\t}\n\t\toffset += file->f_pos;\n\t\tbreak;\n\tcase SEEK_DATA:\n\tcase SEEK_HOLE:\n\t\tret = ocfs2_seek_data_hole_offset(file, &offset, whence);\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\toffset = vfs_setpos(file, offset, inode->i_sb->s_maxbytes);\n\nout:\n\tinode_unlock(inode);\n\tif (ret)\n\t\treturn ret;\n\treturn offset;\n}\n\nstatic int ocfs2_file_clone_range(struct file *file_in,\n\t\t\t\t  loff_t pos_in,\n\t\t\t\t  struct file *file_out,\n\t\t\t\t  loff_t pos_out,\n\t\t\t\t  u64 len)\n{\n\treturn ocfs2_reflink_remap_range(file_in, pos_in, file_out, pos_out,\n\t\t\t\t\t len, false);\n}\n\nstatic ssize_t ocfs2_file_dedupe_range(struct file *src_file,\n\t\t\t\t       u64 loff,\n\t\t\t\t       u64 len,\n\t\t\t\t       struct file *dst_file,\n\t\t\t\t       u64 dst_loff)\n{\n\tint error;\n\n\terror = ocfs2_reflink_remap_range(src_file, loff, dst_file, dst_loff,\n\t\t\t\t\t  len, true);\n\tif (error)\n\t\treturn error;\n\treturn len;\n}\n\nconst struct inode_operations ocfs2_file_iops = {\n\t.setattr\t= ocfs2_setattr,\n\t.getattr\t= ocfs2_getattr,\n\t.permission\t= ocfs2_permission,\n\t.listxattr\t= ocfs2_listxattr,\n\t.fiemap\t\t= ocfs2_fiemap,\n\t.get_acl\t= ocfs2_iop_get_acl,\n\t.set_acl\t= ocfs2_iop_set_acl,\n};\n\nconst struct inode_operations ocfs2_special_file_iops = {\n\t.setattr\t= ocfs2_setattr,\n\t.getattr\t= ocfs2_getattr,\n\t.permission\t= ocfs2_permission,\n\t.get_acl\t= ocfs2_iop_get_acl,\n\t.set_acl\t= ocfs2_iop_set_acl,\n};\n\n/*\n * Other than ->lock, keep ocfs2_fops and ocfs2_dops in sync with\n * ocfs2_fops_no_plocks and ocfs2_dops_no_plocks!\n */\nconst struct file_operations ocfs2_fops = {\n\t.llseek\t\t= ocfs2_file_llseek,\n\t.mmap\t\t= ocfs2_mmap,\n\t.fsync\t\t= ocfs2_sync_file,\n\t.release\t= ocfs2_file_release,\n\t.open\t\t= ocfs2_file_open,\n\t.read_iter\t= ocfs2_file_read_iter,\n\t.write_iter\t= ocfs2_file_write_iter,\n\t.unlocked_ioctl\t= ocfs2_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl   = ocfs2_compat_ioctl,\n#endif\n\t.lock\t\t= ocfs2_lock,\n\t.flock\t\t= ocfs2_flock,\n\t.splice_read\t= generic_file_splice_read,\n\t.splice_write\t= iter_file_splice_write,\n\t.fallocate\t= ocfs2_fallocate,\n\t.clone_file_range = ocfs2_file_clone_range,\n\t.dedupe_file_range = ocfs2_file_dedupe_range,\n};\n\nconst struct file_operations ocfs2_dops = {\n\t.llseek\t\t= generic_file_llseek,\n\t.read\t\t= generic_read_dir,\n\t.iterate\t= ocfs2_readdir,\n\t.fsync\t\t= ocfs2_sync_file,\n\t.release\t= ocfs2_dir_release,\n\t.open\t\t= ocfs2_dir_open,\n\t.unlocked_ioctl\t= ocfs2_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl   = ocfs2_compat_ioctl,\n#endif\n\t.lock\t\t= ocfs2_lock,\n\t.flock\t\t= ocfs2_flock,\n};\n\n/*\n * POSIX-lockless variants of our file_operations.\n *\n * These will be used if the underlying cluster stack does not support\n * posix file locking, if the user passes the \"localflocks\" mount\n * option, or if we have a local-only fs.\n *\n * ocfs2_flock is in here because all stacks handle UNIX file locks,\n * so we still want it in the case of no stack support for\n * plocks. Internally, it will do the right thing when asked to ignore\n * the cluster.\n */\nconst struct file_operations ocfs2_fops_no_plocks = {\n\t.llseek\t\t= ocfs2_file_llseek,\n\t.mmap\t\t= ocfs2_mmap,\n\t.fsync\t\t= ocfs2_sync_file,\n\t.release\t= ocfs2_file_release,\n\t.open\t\t= ocfs2_file_open,\n\t.read_iter\t= ocfs2_file_read_iter,\n\t.write_iter\t= ocfs2_file_write_iter,\n\t.unlocked_ioctl\t= ocfs2_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl   = ocfs2_compat_ioctl,\n#endif\n\t.flock\t\t= ocfs2_flock,\n\t.splice_read\t= generic_file_splice_read,\n\t.splice_write\t= iter_file_splice_write,\n\t.fallocate\t= ocfs2_fallocate,\n\t.clone_file_range = ocfs2_file_clone_range,\n\t.dedupe_file_range = ocfs2_file_dedupe_range,\n};\n\nconst struct file_operations ocfs2_dops_no_plocks = {\n\t.llseek\t\t= generic_file_llseek,\n\t.read\t\t= generic_read_dir,\n\t.iterate\t= ocfs2_readdir,\n\t.fsync\t\t= ocfs2_sync_file,\n\t.release\t= ocfs2_dir_release,\n\t.open\t\t= ocfs2_dir_open,\n\t.unlocked_ioctl\t= ocfs2_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl   = ocfs2_compat_ioctl,\n#endif\n\t.flock\t\t= ocfs2_flock,\n};\n"], "fixing_code": ["/* -*- mode: c; c-basic-offset: 8; -*-\n * vim: noexpandtab sw=8 ts=8 sts=0:\n *\n * file.c\n *\n * File open, close, extend, truncate\n *\n * Copyright (C) 2002, 2004 Oracle.  All rights reserved.\n *\n * This program is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public\n * License as published by the Free Software Foundation; either\n * version 2 of the License, or (at your option) any later version.\n *\n * This program is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * General Public License for more details.\n *\n * You should have received a copy of the GNU General Public\n * License along with this program; if not, write to the\n * Free Software Foundation, Inc., 59 Temple Place - Suite 330,\n * Boston, MA 021110-1307, USA.\n */\n\n#include <linux/capability.h>\n#include <linux/fs.h>\n#include <linux/types.h>\n#include <linux/slab.h>\n#include <linux/highmem.h>\n#include <linux/pagemap.h>\n#include <linux/uio.h>\n#include <linux/sched.h>\n#include <linux/splice.h>\n#include <linux/mount.h>\n#include <linux/writeback.h>\n#include <linux/falloc.h>\n#include <linux/quotaops.h>\n#include <linux/blkdev.h>\n#include <linux/backing-dev.h>\n\n#include <cluster/masklog.h>\n\n#include \"ocfs2.h\"\n\n#include \"alloc.h\"\n#include \"aops.h\"\n#include \"dir.h\"\n#include \"dlmglue.h\"\n#include \"extent_map.h\"\n#include \"file.h\"\n#include \"sysfile.h\"\n#include \"inode.h\"\n#include \"ioctl.h\"\n#include \"journal.h\"\n#include \"locks.h\"\n#include \"mmap.h\"\n#include \"suballoc.h\"\n#include \"super.h\"\n#include \"xattr.h\"\n#include \"acl.h\"\n#include \"quota.h\"\n#include \"refcounttree.h\"\n#include \"ocfs2_trace.h\"\n\n#include \"buffer_head_io.h\"\n\nstatic int ocfs2_init_file_private(struct inode *inode, struct file *file)\n{\n\tstruct ocfs2_file_private *fp;\n\n\tfp = kzalloc(sizeof(struct ocfs2_file_private), GFP_KERNEL);\n\tif (!fp)\n\t\treturn -ENOMEM;\n\n\tfp->fp_file = file;\n\tmutex_init(&fp->fp_mutex);\n\tocfs2_file_lock_res_init(&fp->fp_flock, fp);\n\tfile->private_data = fp;\n\n\treturn 0;\n}\n\nstatic void ocfs2_free_file_private(struct inode *inode, struct file *file)\n{\n\tstruct ocfs2_file_private *fp = file->private_data;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\n\tif (fp) {\n\t\tocfs2_simple_drop_lockres(osb, &fp->fp_flock);\n\t\tocfs2_lock_res_free(&fp->fp_flock);\n\t\tkfree(fp);\n\t\tfile->private_data = NULL;\n\t}\n}\n\nstatic int ocfs2_file_open(struct inode *inode, struct file *file)\n{\n\tint status;\n\tint mode = file->f_flags;\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\n\ttrace_ocfs2_file_open(inode, file, file->f_path.dentry,\n\t\t\t      (unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t      file->f_path.dentry->d_name.len,\n\t\t\t      file->f_path.dentry->d_name.name, mode);\n\n\tif (file->f_mode & FMODE_WRITE) {\n\t\tstatus = dquot_initialize(inode);\n\t\tif (status)\n\t\t\tgoto leave;\n\t}\n\n\tspin_lock(&oi->ip_lock);\n\n\t/* Check that the inode hasn't been wiped from disk by another\n\t * node. If it hasn't then we're safe as long as we hold the\n\t * spin lock until our increment of open count. */\n\tif (OCFS2_I(inode)->ip_flags & OCFS2_INODE_DELETED) {\n\t\tspin_unlock(&oi->ip_lock);\n\n\t\tstatus = -ENOENT;\n\t\tgoto leave;\n\t}\n\n\tif (mode & O_DIRECT)\n\t\toi->ip_flags |= OCFS2_INODE_OPEN_DIRECT;\n\n\toi->ip_open_count++;\n\tspin_unlock(&oi->ip_lock);\n\n\tstatus = ocfs2_init_file_private(inode, file);\n\tif (status) {\n\t\t/*\n\t\t * We want to set open count back if we're failing the\n\t\t * open.\n\t\t */\n\t\tspin_lock(&oi->ip_lock);\n\t\toi->ip_open_count--;\n\t\tspin_unlock(&oi->ip_lock);\n\t}\n\nleave:\n\treturn status;\n}\n\nstatic int ocfs2_file_release(struct inode *inode, struct file *file)\n{\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\n\tspin_lock(&oi->ip_lock);\n\tif (!--oi->ip_open_count)\n\t\toi->ip_flags &= ~OCFS2_INODE_OPEN_DIRECT;\n\n\ttrace_ocfs2_file_release(inode, file, file->f_path.dentry,\n\t\t\t\t oi->ip_blkno,\n\t\t\t\t file->f_path.dentry->d_name.len,\n\t\t\t\t file->f_path.dentry->d_name.name,\n\t\t\t\t oi->ip_open_count);\n\tspin_unlock(&oi->ip_lock);\n\n\tocfs2_free_file_private(inode, file);\n\n\treturn 0;\n}\n\nstatic int ocfs2_dir_open(struct inode *inode, struct file *file)\n{\n\treturn ocfs2_init_file_private(inode, file);\n}\n\nstatic int ocfs2_dir_release(struct inode *inode, struct file *file)\n{\n\tocfs2_free_file_private(inode, file);\n\treturn 0;\n}\n\nstatic int ocfs2_sync_file(struct file *file, loff_t start, loff_t end,\n\t\t\t   int datasync)\n{\n\tint err = 0;\n\tstruct inode *inode = file->f_mapping->host;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\tjournal_t *journal = osb->journal->j_journal;\n\tint ret;\n\ttid_t commit_tid;\n\tbool needs_barrier = false;\n\n\ttrace_ocfs2_sync_file(inode, file, file->f_path.dentry,\n\t\t\t      OCFS2_I(inode)->ip_blkno,\n\t\t\t      file->f_path.dentry->d_name.len,\n\t\t\t      file->f_path.dentry->d_name.name,\n\t\t\t      (unsigned long long)datasync);\n\n\tif (ocfs2_is_hard_readonly(osb) || ocfs2_is_soft_readonly(osb))\n\t\treturn -EROFS;\n\n\terr = file_write_and_wait_range(file, start, end);\n\tif (err)\n\t\treturn err;\n\n\tcommit_tid = datasync ? oi->i_datasync_tid : oi->i_sync_tid;\n\tif (journal->j_flags & JBD2_BARRIER &&\n\t    !jbd2_trans_will_send_data_barrier(journal, commit_tid))\n\t\tneeds_barrier = true;\n\terr = jbd2_complete_transaction(journal, commit_tid);\n\tif (needs_barrier) {\n\t\tret = blkdev_issue_flush(inode->i_sb->s_bdev, GFP_KERNEL, NULL);\n\t\tif (!err)\n\t\t\terr = ret;\n\t}\n\n\tif (err)\n\t\tmlog_errno(err);\n\n\treturn (err < 0) ? -EIO : 0;\n}\n\nint ocfs2_should_update_atime(struct inode *inode,\n\t\t\t      struct vfsmount *vfsmnt)\n{\n\tstruct timespec now;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\n\tif (ocfs2_is_hard_readonly(osb) || ocfs2_is_soft_readonly(osb))\n\t\treturn 0;\n\n\tif ((inode->i_flags & S_NOATIME) ||\n\t    ((inode->i_sb->s_flags & MS_NODIRATIME) && S_ISDIR(inode->i_mode)))\n\t\treturn 0;\n\n\t/*\n\t * We can be called with no vfsmnt structure - NFSD will\n\t * sometimes do this.\n\t *\n\t * Note that our action here is different than touch_atime() -\n\t * if we can't tell whether this is a noatime mount, then we\n\t * don't know whether to trust the value of s_atime_quantum.\n\t */\n\tif (vfsmnt == NULL)\n\t\treturn 0;\n\n\tif ((vfsmnt->mnt_flags & MNT_NOATIME) ||\n\t    ((vfsmnt->mnt_flags & MNT_NODIRATIME) && S_ISDIR(inode->i_mode)))\n\t\treturn 0;\n\n\tif (vfsmnt->mnt_flags & MNT_RELATIME) {\n\t\tif ((timespec_compare(&inode->i_atime, &inode->i_mtime) <= 0) ||\n\t\t    (timespec_compare(&inode->i_atime, &inode->i_ctime) <= 0))\n\t\t\treturn 1;\n\n\t\treturn 0;\n\t}\n\n\tnow = current_time(inode);\n\tif ((now.tv_sec - inode->i_atime.tv_sec <= osb->s_atime_quantum))\n\t\treturn 0;\n\telse\n\t\treturn 1;\n}\n\nint ocfs2_update_inode_atime(struct inode *inode,\n\t\t\t     struct buffer_head *bh)\n{\n\tint ret;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\thandle_t *handle;\n\tstruct ocfs2_dinode *di = (struct ocfs2_dinode *) bh->b_data;\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_journal_access_di(handle, INODE_CACHE(inode), bh,\n\t\t\t\t      OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out_commit;\n\t}\n\n\t/*\n\t * Don't use ocfs2_mark_inode_dirty() here as we don't always\n\t * have i_mutex to guard against concurrent changes to other\n\t * inode fields.\n\t */\n\tinode->i_atime = current_time(inode);\n\tdi->i_atime = cpu_to_le64(inode->i_atime.tv_sec);\n\tdi->i_atime_nsec = cpu_to_le32(inode->i_atime.tv_nsec);\n\tocfs2_update_inode_fsync_trans(handle, inode, 0);\n\tocfs2_journal_dirty(handle, bh);\n\nout_commit:\n\tocfs2_commit_trans(OCFS2_SB(inode->i_sb), handle);\nout:\n\treturn ret;\n}\n\nint ocfs2_set_inode_size(handle_t *handle,\n\t\t\t\tstruct inode *inode,\n\t\t\t\tstruct buffer_head *fe_bh,\n\t\t\t\tu64 new_i_size)\n{\n\tint status;\n\n\ti_size_write(inode, new_i_size);\n\tinode->i_blocks = ocfs2_inode_sector_count(inode);\n\tinode->i_ctime = inode->i_mtime = current_time(inode);\n\n\tstatus = ocfs2_mark_inode_dirty(handle, inode, fe_bh);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto bail;\n\t}\n\nbail:\n\treturn status;\n}\n\nint ocfs2_simple_size_update(struct inode *inode,\n\t\t\t     struct buffer_head *di_bh,\n\t\t\t     u64 new_i_size)\n{\n\tint ret;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\thandle_t *handle = NULL;\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_set_inode_size(handle, inode, di_bh,\n\t\t\t\t   new_i_size);\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\n\tocfs2_update_inode_fsync_trans(handle, inode, 0);\n\tocfs2_commit_trans(osb, handle);\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_cow_file_pos(struct inode *inode,\n\t\t\t      struct buffer_head *fe_bh,\n\t\t\t      u64 offset)\n{\n\tint status;\n\tu32 phys, cpos = offset >> OCFS2_SB(inode->i_sb)->s_clustersize_bits;\n\tunsigned int num_clusters = 0;\n\tunsigned int ext_flags = 0;\n\n\t/*\n\t * If the new offset is aligned to the range of the cluster, there is\n\t * no space for ocfs2_zero_range_for_truncate to fill, so no need to\n\t * CoW either.\n\t */\n\tif ((offset & (OCFS2_SB(inode->i_sb)->s_clustersize - 1)) == 0)\n\t\treturn 0;\n\n\tstatus = ocfs2_get_clusters(inode, cpos, &phys,\n\t\t\t\t    &num_clusters, &ext_flags);\n\tif (status) {\n\t\tmlog_errno(status);\n\t\tgoto out;\n\t}\n\n\tif (!(ext_flags & OCFS2_EXT_REFCOUNTED))\n\t\tgoto out;\n\n\treturn ocfs2_refcount_cow(inode, fe_bh, cpos, 1, cpos+1);\n\nout:\n\treturn status;\n}\n\nstatic int ocfs2_orphan_for_truncate(struct ocfs2_super *osb,\n\t\t\t\t     struct inode *inode,\n\t\t\t\t     struct buffer_head *fe_bh,\n\t\t\t\t     u64 new_i_size)\n{\n\tint status;\n\thandle_t *handle;\n\tstruct ocfs2_dinode *di;\n\tu64 cluster_bytes;\n\n\t/*\n\t * We need to CoW the cluster contains the offset if it is reflinked\n\t * since we will call ocfs2_zero_range_for_truncate later which will\n\t * write \"0\" from offset to the end of the cluster.\n\t */\n\tstatus = ocfs2_cow_file_pos(inode, fe_bh, new_i_size);\n\tif (status) {\n\t\tmlog_errno(status);\n\t\treturn status;\n\t}\n\n\t/* TODO: This needs to actually orphan the inode in this\n\t * transaction. */\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tstatus = PTR_ERR(handle);\n\t\tmlog_errno(status);\n\t\tgoto out;\n\t}\n\n\tstatus = ocfs2_journal_access_di(handle, INODE_CACHE(inode), fe_bh,\n\t\t\t\t\t OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto out_commit;\n\t}\n\n\t/*\n\t * Do this before setting i_size.\n\t */\n\tcluster_bytes = ocfs2_align_bytes_to_clusters(inode->i_sb, new_i_size);\n\tstatus = ocfs2_zero_range_for_truncate(inode, handle, new_i_size,\n\t\t\t\t\t       cluster_bytes);\n\tif (status) {\n\t\tmlog_errno(status);\n\t\tgoto out_commit;\n\t}\n\n\ti_size_write(inode, new_i_size);\n\tinode->i_ctime = inode->i_mtime = current_time(inode);\n\n\tdi = (struct ocfs2_dinode *) fe_bh->b_data;\n\tdi->i_size = cpu_to_le64(new_i_size);\n\tdi->i_ctime = di->i_mtime = cpu_to_le64(inode->i_ctime.tv_sec);\n\tdi->i_ctime_nsec = di->i_mtime_nsec = cpu_to_le32(inode->i_ctime.tv_nsec);\n\tocfs2_update_inode_fsync_trans(handle, inode, 0);\n\n\tocfs2_journal_dirty(handle, fe_bh);\n\nout_commit:\n\tocfs2_commit_trans(osb, handle);\nout:\n\treturn status;\n}\n\nint ocfs2_truncate_file(struct inode *inode,\n\t\t\t       struct buffer_head *di_bh,\n\t\t\t       u64 new_i_size)\n{\n\tint status = 0;\n\tstruct ocfs2_dinode *fe = NULL;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\n\t/* We trust di_bh because it comes from ocfs2_inode_lock(), which\n\t * already validated it */\n\tfe = (struct ocfs2_dinode *) di_bh->b_data;\n\n\ttrace_ocfs2_truncate_file((unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t\t  (unsigned long long)le64_to_cpu(fe->i_size),\n\t\t\t\t  (unsigned long long)new_i_size);\n\n\tmlog_bug_on_msg(le64_to_cpu(fe->i_size) != i_size_read(inode),\n\t\t\t\"Inode %llu, inode i_size = %lld != di \"\n\t\t\t\"i_size = %llu, i_flags = 0x%x\\n\",\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\ti_size_read(inode),\n\t\t\t(unsigned long long)le64_to_cpu(fe->i_size),\n\t\t\tle32_to_cpu(fe->i_flags));\n\n\tif (new_i_size > le64_to_cpu(fe->i_size)) {\n\t\ttrace_ocfs2_truncate_file_error(\n\t\t\t(unsigned long long)le64_to_cpu(fe->i_size),\n\t\t\t(unsigned long long)new_i_size);\n\t\tstatus = -EINVAL;\n\t\tmlog_errno(status);\n\t\tgoto bail;\n\t}\n\n\tdown_write(&OCFS2_I(inode)->ip_alloc_sem);\n\n\tocfs2_resv_discard(&osb->osb_la_resmap,\n\t\t\t   &OCFS2_I(inode)->ip_la_data_resv);\n\n\t/*\n\t * The inode lock forced other nodes to sync and drop their\n\t * pages, which (correctly) happens even if we have a truncate\n\t * without allocation change - ocfs2 cluster sizes can be much\n\t * greater than page size, so we have to truncate them\n\t * anyway.\n\t */\n\tunmap_mapping_range(inode->i_mapping, new_i_size + PAGE_SIZE - 1, 0, 1);\n\ttruncate_inode_pages(inode->i_mapping, new_i_size);\n\n\tif (OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL) {\n\t\tstatus = ocfs2_truncate_inline(inode, di_bh, new_i_size,\n\t\t\t\t\t       i_size_read(inode), 1);\n\t\tif (status)\n\t\t\tmlog_errno(status);\n\n\t\tgoto bail_unlock_sem;\n\t}\n\n\t/* alright, we're going to need to do a full blown alloc size\n\t * change. Orphan the inode so that recovery can complete the\n\t * truncate if necessary. This does the task of marking\n\t * i_size. */\n\tstatus = ocfs2_orphan_for_truncate(osb, inode, di_bh, new_i_size);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto bail_unlock_sem;\n\t}\n\n\tstatus = ocfs2_commit_truncate(osb, inode, di_bh);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto bail_unlock_sem;\n\t}\n\n\t/* TODO: orphan dir cleanup here. */\nbail_unlock_sem:\n\tup_write(&OCFS2_I(inode)->ip_alloc_sem);\n\nbail:\n\tif (!status && OCFS2_I(inode)->ip_clusters == 0)\n\t\tstatus = ocfs2_try_remove_refcount_tree(inode, di_bh);\n\n\treturn status;\n}\n\n/*\n * extend file allocation only here.\n * we'll update all the disk stuff, and oip->alloc_size\n *\n * expect stuff to be locked, a transaction started and enough data /\n * metadata reservations in the contexts.\n *\n * Will return -EAGAIN, and a reason if a restart is needed.\n * If passed in, *reason will always be set, even in error.\n */\nint ocfs2_add_inode_data(struct ocfs2_super *osb,\n\t\t\t struct inode *inode,\n\t\t\t u32 *logical_offset,\n\t\t\t u32 clusters_to_add,\n\t\t\t int mark_unwritten,\n\t\t\t struct buffer_head *fe_bh,\n\t\t\t handle_t *handle,\n\t\t\t struct ocfs2_alloc_context *data_ac,\n\t\t\t struct ocfs2_alloc_context *meta_ac,\n\t\t\t enum ocfs2_alloc_restarted *reason_ret)\n{\n\tint ret;\n\tstruct ocfs2_extent_tree et;\n\n\tocfs2_init_dinode_extent_tree(&et, INODE_CACHE(inode), fe_bh);\n\tret = ocfs2_add_clusters_in_btree(handle, &et, logical_offset,\n\t\t\t\t\t  clusters_to_add, mark_unwritten,\n\t\t\t\t\t  data_ac, meta_ac, reason_ret);\n\n\treturn ret;\n}\n\nstatic int __ocfs2_extend_allocation(struct inode *inode, u32 logical_start,\n\t\t\t\t     u32 clusters_to_add, int mark_unwritten)\n{\n\tint status = 0;\n\tint restart_func = 0;\n\tint credits;\n\tu32 prev_clusters;\n\tstruct buffer_head *bh = NULL;\n\tstruct ocfs2_dinode *fe = NULL;\n\thandle_t *handle = NULL;\n\tstruct ocfs2_alloc_context *data_ac = NULL;\n\tstruct ocfs2_alloc_context *meta_ac = NULL;\n\tenum ocfs2_alloc_restarted why = RESTART_NONE;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_extent_tree et;\n\tint did_quota = 0;\n\n\t/*\n\t * Unwritten extent only exists for file systems which\n\t * support holes.\n\t */\n\tBUG_ON(mark_unwritten && !ocfs2_sparse_alloc(osb));\n\n\tstatus = ocfs2_read_inode_block(inode, &bh);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\tfe = (struct ocfs2_dinode *) bh->b_data;\n\nrestart_all:\n\tBUG_ON(le32_to_cpu(fe->i_clusters) != OCFS2_I(inode)->ip_clusters);\n\n\tocfs2_init_dinode_extent_tree(&et, INODE_CACHE(inode), bh);\n\tstatus = ocfs2_lock_allocators(inode, &et, clusters_to_add, 0,\n\t\t\t\t       &data_ac, &meta_ac);\n\tif (status) {\n\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\n\tcredits = ocfs2_calc_extend_credits(osb->sb, &fe->id2.i_list);\n\thandle = ocfs2_start_trans(osb, credits);\n\tif (IS_ERR(handle)) {\n\t\tstatus = PTR_ERR(handle);\n\t\thandle = NULL;\n\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\nrestarted_transaction:\n\ttrace_ocfs2_extend_allocation(\n\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t(unsigned long long)i_size_read(inode),\n\t\tle32_to_cpu(fe->i_clusters), clusters_to_add,\n\t\twhy, restart_func);\n\n\tstatus = dquot_alloc_space_nodirty(inode,\n\t\t\tocfs2_clusters_to_bytes(osb->sb, clusters_to_add));\n\tif (status)\n\t\tgoto leave;\n\tdid_quota = 1;\n\n\t/* reserve a write to the file entry early on - that we if we\n\t * run out of credits in the allocation path, we can still\n\t * update i_size. */\n\tstatus = ocfs2_journal_access_di(handle, INODE_CACHE(inode), bh,\n\t\t\t\t\t OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (status < 0) {\n\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\n\tprev_clusters = OCFS2_I(inode)->ip_clusters;\n\n\tstatus = ocfs2_add_inode_data(osb,\n\t\t\t\t      inode,\n\t\t\t\t      &logical_start,\n\t\t\t\t      clusters_to_add,\n\t\t\t\t      mark_unwritten,\n\t\t\t\t      bh,\n\t\t\t\t      handle,\n\t\t\t\t      data_ac,\n\t\t\t\t      meta_ac,\n\t\t\t\t      &why);\n\tif ((status < 0) && (status != -EAGAIN)) {\n\t\tif (status != -ENOSPC)\n\t\t\tmlog_errno(status);\n\t\tgoto leave;\n\t}\n\tocfs2_update_inode_fsync_trans(handle, inode, 1);\n\tocfs2_journal_dirty(handle, bh);\n\n\tspin_lock(&OCFS2_I(inode)->ip_lock);\n\tclusters_to_add -= (OCFS2_I(inode)->ip_clusters - prev_clusters);\n\tspin_unlock(&OCFS2_I(inode)->ip_lock);\n\t/* Release unused quota reservation */\n\tdquot_free_space(inode,\n\t\t\tocfs2_clusters_to_bytes(osb->sb, clusters_to_add));\n\tdid_quota = 0;\n\n\tif (why != RESTART_NONE && clusters_to_add) {\n\t\tif (why == RESTART_META) {\n\t\t\trestart_func = 1;\n\t\t\tstatus = 0;\n\t\t} else {\n\t\t\tBUG_ON(why != RESTART_TRANS);\n\n\t\t\tstatus = ocfs2_allocate_extend_trans(handle, 1);\n\t\t\tif (status < 0) {\n\t\t\t\t/* handle still has to be committed at\n\t\t\t\t * this point. */\n\t\t\t\tstatus = -ENOMEM;\n\t\t\t\tmlog_errno(status);\n\t\t\t\tgoto leave;\n\t\t\t}\n\t\t\tgoto restarted_transaction;\n\t\t}\n\t}\n\n\ttrace_ocfs2_extend_allocation_end(OCFS2_I(inode)->ip_blkno,\n\t     le32_to_cpu(fe->i_clusters),\n\t     (unsigned long long)le64_to_cpu(fe->i_size),\n\t     OCFS2_I(inode)->ip_clusters,\n\t     (unsigned long long)i_size_read(inode));\n\nleave:\n\tif (status < 0 && did_quota)\n\t\tdquot_free_space(inode,\n\t\t\tocfs2_clusters_to_bytes(osb->sb, clusters_to_add));\n\tif (handle) {\n\t\tocfs2_commit_trans(osb, handle);\n\t\thandle = NULL;\n\t}\n\tif (data_ac) {\n\t\tocfs2_free_alloc_context(data_ac);\n\t\tdata_ac = NULL;\n\t}\n\tif (meta_ac) {\n\t\tocfs2_free_alloc_context(meta_ac);\n\t\tmeta_ac = NULL;\n\t}\n\tif ((!status) && restart_func) {\n\t\trestart_func = 0;\n\t\tgoto restart_all;\n\t}\n\tbrelse(bh);\n\tbh = NULL;\n\n\treturn status;\n}\n\n/*\n * While a write will already be ordering the data, a truncate will not.\n * Thus, we need to explicitly order the zeroed pages.\n */\nstatic handle_t *ocfs2_zero_start_ordered_transaction(struct inode *inode,\n\t\t\t\t\t\tstruct buffer_head *di_bh)\n{\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\thandle_t *handle = NULL;\n\tint ret = 0;\n\n\tif (!ocfs2_should_order_data(inode))\n\t\tgoto out;\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = -ENOMEM;\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_jbd2_file_inode(handle, inode);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_journal_access_di(handle, INODE_CACHE(inode), di_bh,\n\t\t\t\t      OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (ret)\n\t\tmlog_errno(ret);\n\tocfs2_update_inode_fsync_trans(handle, inode, 1);\n\nout:\n\tif (ret) {\n\t\tif (!IS_ERR(handle))\n\t\t\tocfs2_commit_trans(osb, handle);\n\t\thandle = ERR_PTR(ret);\n\t}\n\treturn handle;\n}\n\n/* Some parts of this taken from generic_cont_expand, which turned out\n * to be too fragile to do exactly what we need without us having to\n * worry about recursive locking in ->write_begin() and ->write_end(). */\nstatic int ocfs2_write_zero_page(struct inode *inode, u64 abs_from,\n\t\t\t\t u64 abs_to, struct buffer_head *di_bh)\n{\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct page *page;\n\tunsigned long index = abs_from >> PAGE_SHIFT;\n\thandle_t *handle;\n\tint ret = 0;\n\tunsigned zero_from, zero_to, block_start, block_end;\n\tstruct ocfs2_dinode *di = (struct ocfs2_dinode *)di_bh->b_data;\n\n\tBUG_ON(abs_from >= abs_to);\n\tBUG_ON(abs_to > (((u64)index + 1) << PAGE_SHIFT));\n\tBUG_ON(abs_from & (inode->i_blkbits - 1));\n\n\thandle = ocfs2_zero_start_ordered_transaction(inode, di_bh);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tgoto out;\n\t}\n\n\tpage = find_or_create_page(mapping, index, GFP_NOFS);\n\tif (!page) {\n\t\tret = -ENOMEM;\n\t\tmlog_errno(ret);\n\t\tgoto out_commit_trans;\n\t}\n\n\t/* Get the offsets within the page that we want to zero */\n\tzero_from = abs_from & (PAGE_SIZE - 1);\n\tzero_to = abs_to & (PAGE_SIZE - 1);\n\tif (!zero_to)\n\t\tzero_to = PAGE_SIZE;\n\n\ttrace_ocfs2_write_zero_page(\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t(unsigned long long)abs_from,\n\t\t\t(unsigned long long)abs_to,\n\t\t\tindex, zero_from, zero_to);\n\n\t/* We know that zero_from is block aligned */\n\tfor (block_start = zero_from; block_start < zero_to;\n\t     block_start = block_end) {\n\t\tblock_end = block_start + i_blocksize(inode);\n\n\t\t/*\n\t\t * block_start is block-aligned.  Bump it by one to force\n\t\t * __block_write_begin and block_commit_write to zero the\n\t\t * whole block.\n\t\t */\n\t\tret = __block_write_begin(page, block_start + 1, 0,\n\t\t\t\t\t  ocfs2_get_block);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\n\t\t/* must not update i_size! */\n\t\tret = block_commit_write(page, block_start + 1,\n\t\t\t\t\t block_start + 1);\n\t\tif (ret < 0)\n\t\t\tmlog_errno(ret);\n\t\telse\n\t\t\tret = 0;\n\t}\n\n\t/*\n\t * fs-writeback will release the dirty pages without page lock\n\t * whose offset are over inode size, the release happens at\n\t * block_write_full_page().\n\t */\n\ti_size_write(inode, abs_to);\n\tinode->i_blocks = ocfs2_inode_sector_count(inode);\n\tdi->i_size = cpu_to_le64((u64)i_size_read(inode));\n\tinode->i_mtime = inode->i_ctime = current_time(inode);\n\tdi->i_mtime = di->i_ctime = cpu_to_le64(inode->i_mtime.tv_sec);\n\tdi->i_ctime_nsec = cpu_to_le32(inode->i_mtime.tv_nsec);\n\tdi->i_mtime_nsec = di->i_ctime_nsec;\n\tif (handle) {\n\t\tocfs2_journal_dirty(handle, di_bh);\n\t\tocfs2_update_inode_fsync_trans(handle, inode, 1);\n\t}\n\nout_unlock:\n\tunlock_page(page);\n\tput_page(page);\nout_commit_trans:\n\tif (handle)\n\t\tocfs2_commit_trans(OCFS2_SB(inode->i_sb), handle);\nout:\n\treturn ret;\n}\n\n/*\n * Find the next range to zero.  We do this in terms of bytes because\n * that's what ocfs2_zero_extend() wants, and it is dealing with the\n * pagecache.  We may return multiple extents.\n *\n * zero_start and zero_end are ocfs2_zero_extend()s current idea of what\n * needs to be zeroed.  range_start and range_end return the next zeroing\n * range.  A subsequent call should pass the previous range_end as its\n * zero_start.  If range_end is 0, there's nothing to do.\n *\n * Unwritten extents are skipped over.  Refcounted extents are CoWd.\n */\nstatic int ocfs2_zero_extend_get_range(struct inode *inode,\n\t\t\t\t       struct buffer_head *di_bh,\n\t\t\t\t       u64 zero_start, u64 zero_end,\n\t\t\t\t       u64 *range_start, u64 *range_end)\n{\n\tint rc = 0, needs_cow = 0;\n\tu32 p_cpos, zero_clusters = 0;\n\tu32 zero_cpos =\n\t\tzero_start >> OCFS2_SB(inode->i_sb)->s_clustersize_bits;\n\tu32 last_cpos = ocfs2_clusters_for_bytes(inode->i_sb, zero_end);\n\tunsigned int num_clusters = 0;\n\tunsigned int ext_flags = 0;\n\n\twhile (zero_cpos < last_cpos) {\n\t\trc = ocfs2_get_clusters(inode, zero_cpos, &p_cpos,\n\t\t\t\t\t&num_clusters, &ext_flags);\n\t\tif (rc) {\n\t\t\tmlog_errno(rc);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (p_cpos && !(ext_flags & OCFS2_EXT_UNWRITTEN)) {\n\t\t\tzero_clusters = num_clusters;\n\t\t\tif (ext_flags & OCFS2_EXT_REFCOUNTED)\n\t\t\t\tneeds_cow = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tzero_cpos += num_clusters;\n\t}\n\tif (!zero_clusters) {\n\t\t*range_end = 0;\n\t\tgoto out;\n\t}\n\n\twhile ((zero_cpos + zero_clusters) < last_cpos) {\n\t\trc = ocfs2_get_clusters(inode, zero_cpos + zero_clusters,\n\t\t\t\t\t&p_cpos, &num_clusters,\n\t\t\t\t\t&ext_flags);\n\t\tif (rc) {\n\t\t\tmlog_errno(rc);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (!p_cpos || (ext_flags & OCFS2_EXT_UNWRITTEN))\n\t\t\tbreak;\n\t\tif (ext_flags & OCFS2_EXT_REFCOUNTED)\n\t\t\tneeds_cow = 1;\n\t\tzero_clusters += num_clusters;\n\t}\n\tif ((zero_cpos + zero_clusters) > last_cpos)\n\t\tzero_clusters = last_cpos - zero_cpos;\n\n\tif (needs_cow) {\n\t\trc = ocfs2_refcount_cow(inode, di_bh, zero_cpos,\n\t\t\t\t\tzero_clusters, UINT_MAX);\n\t\tif (rc) {\n\t\t\tmlog_errno(rc);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t*range_start = ocfs2_clusters_to_bytes(inode->i_sb, zero_cpos);\n\t*range_end = ocfs2_clusters_to_bytes(inode->i_sb,\n\t\t\t\t\t     zero_cpos + zero_clusters);\n\nout:\n\treturn rc;\n}\n\n/*\n * Zero one range returned from ocfs2_zero_extend_get_range().  The caller\n * has made sure that the entire range needs zeroing.\n */\nstatic int ocfs2_zero_extend_range(struct inode *inode, u64 range_start,\n\t\t\t\t   u64 range_end, struct buffer_head *di_bh)\n{\n\tint rc = 0;\n\tu64 next_pos;\n\tu64 zero_pos = range_start;\n\n\ttrace_ocfs2_zero_extend_range(\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t(unsigned long long)range_start,\n\t\t\t(unsigned long long)range_end);\n\tBUG_ON(range_start >= range_end);\n\n\twhile (zero_pos < range_end) {\n\t\tnext_pos = (zero_pos & PAGE_MASK) + PAGE_SIZE;\n\t\tif (next_pos > range_end)\n\t\t\tnext_pos = range_end;\n\t\trc = ocfs2_write_zero_page(inode, zero_pos, next_pos, di_bh);\n\t\tif (rc < 0) {\n\t\t\tmlog_errno(rc);\n\t\t\tbreak;\n\t\t}\n\t\tzero_pos = next_pos;\n\n\t\t/*\n\t\t * Very large extends have the potential to lock up\n\t\t * the cpu for extended periods of time.\n\t\t */\n\t\tcond_resched();\n\t}\n\n\treturn rc;\n}\n\nint ocfs2_zero_extend(struct inode *inode, struct buffer_head *di_bh,\n\t\t      loff_t zero_to_size)\n{\n\tint ret = 0;\n\tu64 zero_start, range_start = 0, range_end = 0;\n\tstruct super_block *sb = inode->i_sb;\n\n\tzero_start = ocfs2_align_bytes_to_blocks(sb, i_size_read(inode));\n\ttrace_ocfs2_zero_extend((unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t\t(unsigned long long)zero_start,\n\t\t\t\t(unsigned long long)i_size_read(inode));\n\twhile (zero_start < zero_to_size) {\n\t\tret = ocfs2_zero_extend_get_range(inode, di_bh, zero_start,\n\t\t\t\t\t\t  zero_to_size,\n\t\t\t\t\t\t  &range_start,\n\t\t\t\t\t\t  &range_end);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tbreak;\n\t\t}\n\t\tif (!range_end)\n\t\t\tbreak;\n\t\t/* Trim the ends */\n\t\tif (range_start < zero_start)\n\t\t\trange_start = zero_start;\n\t\tif (range_end > zero_to_size)\n\t\t\trange_end = zero_to_size;\n\n\t\tret = ocfs2_zero_extend_range(inode, range_start,\n\t\t\t\t\t      range_end, di_bh);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tbreak;\n\t\t}\n\t\tzero_start = range_end;\n\t}\n\n\treturn ret;\n}\n\nint ocfs2_extend_no_holes(struct inode *inode, struct buffer_head *di_bh,\n\t\t\t  u64 new_i_size, u64 zero_to)\n{\n\tint ret;\n\tu32 clusters_to_add;\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\n\t/*\n\t * Only quota files call this without a bh, and they can't be\n\t * refcounted.\n\t */\n\tBUG_ON(!di_bh && ocfs2_is_refcount_inode(inode));\n\tBUG_ON(!di_bh && !(oi->ip_flags & OCFS2_INODE_SYSTEM_FILE));\n\n\tclusters_to_add = ocfs2_clusters_for_bytes(inode->i_sb, new_i_size);\n\tif (clusters_to_add < oi->ip_clusters)\n\t\tclusters_to_add = 0;\n\telse\n\t\tclusters_to_add -= oi->ip_clusters;\n\n\tif (clusters_to_add) {\n\t\tret = __ocfs2_extend_allocation(inode, oi->ip_clusters,\n\t\t\t\t\t\tclusters_to_add, 0);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * Call this even if we don't add any clusters to the tree. We\n\t * still need to zero the area between the old i_size and the\n\t * new i_size.\n\t */\n\tret = ocfs2_zero_extend(inode, di_bh, zero_to);\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_extend_file(struct inode *inode,\n\t\t\t     struct buffer_head *di_bh,\n\t\t\t     u64 new_i_size)\n{\n\tint ret = 0;\n\tstruct ocfs2_inode_info *oi = OCFS2_I(inode);\n\n\tBUG_ON(!di_bh);\n\n\t/* setattr sometimes calls us like this. */\n\tif (new_i_size == 0)\n\t\tgoto out;\n\n\tif (i_size_read(inode) == new_i_size)\n\t\tgoto out;\n\tBUG_ON(new_i_size < i_size_read(inode));\n\n\t/*\n\t * The alloc sem blocks people in read/write from reading our\n\t * allocation until we're done changing it. We depend on\n\t * i_mutex to block other extend/truncate calls while we're\n\t * here.  We even have to hold it for sparse files because there\n\t * might be some tail zeroing.\n\t */\n\tdown_write(&oi->ip_alloc_sem);\n\n\tif (oi->ip_dyn_features & OCFS2_INLINE_DATA_FL) {\n\t\t/*\n\t\t * We can optimize small extends by keeping the inodes\n\t\t * inline data.\n\t\t */\n\t\tif (ocfs2_size_fits_inline_data(di_bh, new_i_size)) {\n\t\t\tup_write(&oi->ip_alloc_sem);\n\t\t\tgoto out_update_size;\n\t\t}\n\n\t\tret = ocfs2_convert_inline_data_to_extents(inode, di_bh);\n\t\tif (ret) {\n\t\t\tup_write(&oi->ip_alloc_sem);\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\tif (ocfs2_sparse_alloc(OCFS2_SB(inode->i_sb)))\n\t\tret = ocfs2_zero_extend(inode, di_bh, new_i_size);\n\telse\n\t\tret = ocfs2_extend_no_holes(inode, di_bh, new_i_size,\n\t\t\t\t\t    new_i_size);\n\n\tup_write(&oi->ip_alloc_sem);\n\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\nout_update_size:\n\tret = ocfs2_simple_size_update(inode, di_bh, new_i_size);\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\nout:\n\treturn ret;\n}\n\nint ocfs2_setattr(struct dentry *dentry, struct iattr *attr)\n{\n\tint status = 0, size_change;\n\tint inode_locked = 0;\n\tstruct inode *inode = d_inode(dentry);\n\tstruct super_block *sb = inode->i_sb;\n\tstruct ocfs2_super *osb = OCFS2_SB(sb);\n\tstruct buffer_head *bh = NULL;\n\thandle_t *handle = NULL;\n\tstruct dquot *transfer_to[MAXQUOTAS] = { };\n\tint qtype;\n\tint had_lock;\n\tstruct ocfs2_lock_holder oh;\n\n\ttrace_ocfs2_setattr(inode, dentry,\n\t\t\t    (unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t    dentry->d_name.len, dentry->d_name.name,\n\t\t\t    attr->ia_valid, attr->ia_mode,\n\t\t\t    from_kuid(&init_user_ns, attr->ia_uid),\n\t\t\t    from_kgid(&init_user_ns, attr->ia_gid));\n\n\t/* ensuring we don't even attempt to truncate a symlink */\n\tif (S_ISLNK(inode->i_mode))\n\t\tattr->ia_valid &= ~ATTR_SIZE;\n\n#define OCFS2_VALID_ATTRS (ATTR_ATIME | ATTR_MTIME | ATTR_CTIME | ATTR_SIZE \\\n\t\t\t   | ATTR_GID | ATTR_UID | ATTR_MODE)\n\tif (!(attr->ia_valid & OCFS2_VALID_ATTRS))\n\t\treturn 0;\n\n\tstatus = setattr_prepare(dentry, attr);\n\tif (status)\n\t\treturn status;\n\n\tif (is_quota_modification(inode, attr)) {\n\t\tstatus = dquot_initialize(inode);\n\t\tif (status)\n\t\t\treturn status;\n\t}\n\tsize_change = S_ISREG(inode->i_mode) && attr->ia_valid & ATTR_SIZE;\n\tif (size_change) {\n\t\t/*\n\t\t * Here we should wait dio to finish before inode lock\n\t\t * to avoid a deadlock between ocfs2_setattr() and\n\t\t * ocfs2_dio_end_io_write()\n\t\t */\n\t\tinode_dio_wait(inode);\n\n\t\tstatus = ocfs2_rw_lock(inode, 1);\n\t\tif (status < 0) {\n\t\t\tmlog_errno(status);\n\t\t\tgoto bail;\n\t\t}\n\t}\n\n\thad_lock = ocfs2_inode_lock_tracker(inode, &bh, 1, &oh);\n\tif (had_lock < 0) {\n\t\tstatus = had_lock;\n\t\tgoto bail_unlock_rw;\n\t} else if (had_lock) {\n\t\t/*\n\t\t * As far as we know, ocfs2_setattr() could only be the first\n\t\t * VFS entry point in the call chain of recursive cluster\n\t\t * locking issue.\n\t\t *\n\t\t * For instance:\n\t\t * chmod_common()\n\t\t *  notify_change()\n\t\t *   ocfs2_setattr()\n\t\t *    posix_acl_chmod()\n\t\t *     ocfs2_iop_get_acl()\n\t\t *\n\t\t * But, we're not 100% sure if it's always true, because the\n\t\t * ordering of the VFS entry points in the call chain is out\n\t\t * of our control. So, we'd better dump the stack here to\n\t\t * catch the other cases of recursive locking.\n\t\t */\n\t\tmlog(ML_ERROR, \"Another case of recursive locking:\\n\");\n\t\tdump_stack();\n\t}\n\tinode_locked = 1;\n\n\tif (size_change) {\n\t\tstatus = inode_newsize_ok(inode, attr->ia_size);\n\t\tif (status)\n\t\t\tgoto bail_unlock;\n\n\t\tif (i_size_read(inode) >= attr->ia_size) {\n\t\t\tif (ocfs2_should_order_data(inode)) {\n\t\t\t\tstatus = ocfs2_begin_ordered_truncate(inode,\n\t\t\t\t\t\t\t\t      attr->ia_size);\n\t\t\t\tif (status)\n\t\t\t\t\tgoto bail_unlock;\n\t\t\t}\n\t\t\tstatus = ocfs2_truncate_file(inode, bh, attr->ia_size);\n\t\t} else\n\t\t\tstatus = ocfs2_extend_file(inode, bh, attr->ia_size);\n\t\tif (status < 0) {\n\t\t\tif (status != -ENOSPC)\n\t\t\t\tmlog_errno(status);\n\t\t\tstatus = -ENOSPC;\n\t\t\tgoto bail_unlock;\n\t\t}\n\t}\n\n\tif ((attr->ia_valid & ATTR_UID && !uid_eq(attr->ia_uid, inode->i_uid)) ||\n\t    (attr->ia_valid & ATTR_GID && !gid_eq(attr->ia_gid, inode->i_gid))) {\n\t\t/*\n\t\t * Gather pointers to quota structures so that allocation /\n\t\t * freeing of quota structures happens here and not inside\n\t\t * dquot_transfer() where we have problems with lock ordering\n\t\t */\n\t\tif (attr->ia_valid & ATTR_UID && !uid_eq(attr->ia_uid, inode->i_uid)\n\t\t    && OCFS2_HAS_RO_COMPAT_FEATURE(sb,\n\t\t    OCFS2_FEATURE_RO_COMPAT_USRQUOTA)) {\n\t\t\ttransfer_to[USRQUOTA] = dqget(sb, make_kqid_uid(attr->ia_uid));\n\t\t\tif (IS_ERR(transfer_to[USRQUOTA])) {\n\t\t\t\tstatus = PTR_ERR(transfer_to[USRQUOTA]);\n\t\t\t\tgoto bail_unlock;\n\t\t\t}\n\t\t}\n\t\tif (attr->ia_valid & ATTR_GID && !gid_eq(attr->ia_gid, inode->i_gid)\n\t\t    && OCFS2_HAS_RO_COMPAT_FEATURE(sb,\n\t\t    OCFS2_FEATURE_RO_COMPAT_GRPQUOTA)) {\n\t\t\ttransfer_to[GRPQUOTA] = dqget(sb, make_kqid_gid(attr->ia_gid));\n\t\t\tif (IS_ERR(transfer_to[GRPQUOTA])) {\n\t\t\t\tstatus = PTR_ERR(transfer_to[GRPQUOTA]);\n\t\t\t\tgoto bail_unlock;\n\t\t\t}\n\t\t}\n\t\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS +\n\t\t\t\t\t   2 * ocfs2_quota_trans_credits(sb));\n\t\tif (IS_ERR(handle)) {\n\t\t\tstatus = PTR_ERR(handle);\n\t\t\tmlog_errno(status);\n\t\t\tgoto bail_unlock;\n\t\t}\n\t\tstatus = __dquot_transfer(inode, transfer_to);\n\t\tif (status < 0)\n\t\t\tgoto bail_commit;\n\t} else {\n\t\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\t\tif (IS_ERR(handle)) {\n\t\t\tstatus = PTR_ERR(handle);\n\t\t\tmlog_errno(status);\n\t\t\tgoto bail_unlock;\n\t\t}\n\t}\n\n\tsetattr_copy(inode, attr);\n\tmark_inode_dirty(inode);\n\n\tstatus = ocfs2_mark_inode_dirty(handle, inode, bh);\n\tif (status < 0)\n\t\tmlog_errno(status);\n\nbail_commit:\n\tocfs2_commit_trans(osb, handle);\nbail_unlock:\n\tif (status && inode_locked) {\n\t\tocfs2_inode_unlock_tracker(inode, 1, &oh, had_lock);\n\t\tinode_locked = 0;\n\t}\nbail_unlock_rw:\n\tif (size_change)\n\t\tocfs2_rw_unlock(inode, 1);\nbail:\n\n\t/* Release quota pointers in case we acquired them */\n\tfor (qtype = 0; qtype < OCFS2_MAXQUOTAS; qtype++)\n\t\tdqput(transfer_to[qtype]);\n\n\tif (!status && attr->ia_valid & ATTR_MODE) {\n\t\tstatus = ocfs2_acl_chmod(inode, bh);\n\t\tif (status < 0)\n\t\t\tmlog_errno(status);\n\t}\n\tif (inode_locked)\n\t\tocfs2_inode_unlock_tracker(inode, 1, &oh, had_lock);\n\n\tbrelse(bh);\n\treturn status;\n}\n\nint ocfs2_getattr(const struct path *path, struct kstat *stat,\n\t\t  u32 request_mask, unsigned int flags)\n{\n\tstruct inode *inode = d_inode(path->dentry);\n\tstruct super_block *sb = path->dentry->d_sb;\n\tstruct ocfs2_super *osb = sb->s_fs_info;\n\tint err;\n\n\terr = ocfs2_inode_revalidate(path->dentry);\n\tif (err) {\n\t\tif (err != -ENOENT)\n\t\t\tmlog_errno(err);\n\t\tgoto bail;\n\t}\n\n\tgeneric_fillattr(inode, stat);\n\t/*\n\t * If there is inline data in the inode, the inode will normally not\n\t * have data blocks allocated (it may have an external xattr block).\n\t * Report at least one sector for such files, so tools like tar, rsync,\n\t * others don't incorrectly think the file is completely sparse.\n\t */\n\tif (unlikely(OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL))\n\t\tstat->blocks += (stat->size + 511)>>9;\n\n\t/* We set the blksize from the cluster size for performance */\n\tstat->blksize = osb->s_clustersize;\n\nbail:\n\treturn err;\n}\n\nint ocfs2_permission(struct inode *inode, int mask)\n{\n\tint ret, had_lock;\n\tstruct ocfs2_lock_holder oh;\n\n\tif (mask & MAY_NOT_BLOCK)\n\t\treturn -ECHILD;\n\n\thad_lock = ocfs2_inode_lock_tracker(inode, NULL, 0, &oh);\n\tif (had_lock < 0) {\n\t\tret = had_lock;\n\t\tgoto out;\n\t} else if (had_lock) {\n\t\t/* See comments in ocfs2_setattr() for details.\n\t\t * The call chain of this case could be:\n\t\t * do_sys_open()\n\t\t *  may_open()\n\t\t *   inode_permission()\n\t\t *    ocfs2_permission()\n\t\t *     ocfs2_iop_get_acl()\n\t\t */\n\t\tmlog(ML_ERROR, \"Another case of recursive locking:\\n\");\n\t\tdump_stack();\n\t}\n\n\tret = generic_permission(inode, mask);\n\n\tocfs2_inode_unlock_tracker(inode, 0, &oh, had_lock);\nout:\n\treturn ret;\n}\n\nstatic int __ocfs2_write_remove_suid(struct inode *inode,\n\t\t\t\t     struct buffer_head *bh)\n{\n\tint ret;\n\thandle_t *handle;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_dinode *di;\n\n\ttrace_ocfs2_write_remove_suid(\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\tinode->i_mode);\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_journal_access_di(handle, INODE_CACHE(inode), bh,\n\t\t\t\t      OCFS2_JOURNAL_ACCESS_WRITE);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out_trans;\n\t}\n\n\tinode->i_mode &= ~S_ISUID;\n\tif ((inode->i_mode & S_ISGID) && (inode->i_mode & S_IXGRP))\n\t\tinode->i_mode &= ~S_ISGID;\n\n\tdi = (struct ocfs2_dinode *) bh->b_data;\n\tdi->i_mode = cpu_to_le16(inode->i_mode);\n\tocfs2_update_inode_fsync_trans(handle, inode, 0);\n\n\tocfs2_journal_dirty(handle, bh);\n\nout_trans:\n\tocfs2_commit_trans(osb, handle);\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_write_remove_suid(struct inode *inode)\n{\n\tint ret;\n\tstruct buffer_head *bh = NULL;\n\n\tret = ocfs2_read_inode_block(inode, &bh);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret =  __ocfs2_write_remove_suid(inode, bh);\nout:\n\tbrelse(bh);\n\treturn ret;\n}\n\n/*\n * Allocate enough extents to cover the region starting at byte offset\n * start for len bytes. Existing extents are skipped, any extents\n * added are marked as \"unwritten\".\n */\nstatic int ocfs2_allocate_unwritten_extents(struct inode *inode,\n\t\t\t\t\t    u64 start, u64 len)\n{\n\tint ret;\n\tu32 cpos, phys_cpos, clusters, alloc_size;\n\tu64 end = start + len;\n\tstruct buffer_head *di_bh = NULL;\n\n\tif (OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL) {\n\t\tret = ocfs2_read_inode_block(inode, &di_bh);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\t/*\n\t\t * Nothing to do if the requested reservation range\n\t\t * fits within the inode.\n\t\t */\n\t\tif (ocfs2_size_fits_inline_data(di_bh, end))\n\t\t\tgoto out;\n\n\t\tret = ocfs2_convert_inline_data_to_extents(inode, di_bh);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\t/*\n\t * We consider both start and len to be inclusive.\n\t */\n\tcpos = start >> OCFS2_SB(inode->i_sb)->s_clustersize_bits;\n\tclusters = ocfs2_clusters_for_bytes(inode->i_sb, start + len);\n\tclusters -= cpos;\n\n\twhile (clusters) {\n\t\tret = ocfs2_get_clusters(inode, cpos, &phys_cpos,\n\t\t\t\t\t &alloc_size, NULL);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\t/*\n\t\t * Hole or existing extent len can be arbitrary, so\n\t\t * cap it to our own allocation request.\n\t\t */\n\t\tif (alloc_size > clusters)\n\t\t\talloc_size = clusters;\n\n\t\tif (phys_cpos) {\n\t\t\t/*\n\t\t\t * We already have an allocation at this\n\t\t\t * region so we can safely skip it.\n\t\t\t */\n\t\t\tgoto next;\n\t\t}\n\n\t\tret = __ocfs2_extend_allocation(inode, cpos, alloc_size, 1);\n\t\tif (ret) {\n\t\t\tif (ret != -ENOSPC)\n\t\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\nnext:\n\t\tcpos += alloc_size;\n\t\tclusters -= alloc_size;\n\t}\n\n\tret = 0;\nout:\n\n\tbrelse(di_bh);\n\treturn ret;\n}\n\n/*\n * Truncate a byte range, avoiding pages within partial clusters. This\n * preserves those pages for the zeroing code to write to.\n */\nstatic void ocfs2_truncate_cluster_pages(struct inode *inode, u64 byte_start,\n\t\t\t\t\t u64 byte_len)\n{\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tloff_t start, end;\n\tstruct address_space *mapping = inode->i_mapping;\n\n\tstart = (loff_t)ocfs2_align_bytes_to_clusters(inode->i_sb, byte_start);\n\tend = byte_start + byte_len;\n\tend = end & ~(osb->s_clustersize - 1);\n\n\tif (start < end) {\n\t\tunmap_mapping_range(mapping, start, end - start, 0);\n\t\ttruncate_inode_pages_range(mapping, start, end - 1);\n\t}\n}\n\nstatic int ocfs2_zero_partial_clusters(struct inode *inode,\n\t\t\t\t       u64 start, u64 len)\n{\n\tint ret = 0;\n\tu64 tmpend = 0;\n\tu64 end = start + len;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tunsigned int csize = osb->s_clustersize;\n\thandle_t *handle;\n\n\t/*\n\t * The \"start\" and \"end\" values are NOT necessarily part of\n\t * the range whose allocation is being deleted. Rather, this\n\t * is what the user passed in with the request. We must zero\n\t * partial clusters here. There's no need to worry about\n\t * physical allocation - the zeroing code knows to skip holes.\n\t */\n\ttrace_ocfs2_zero_partial_clusters(\n\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t(unsigned long long)start, (unsigned long long)end);\n\n\t/*\n\t * If both edges are on a cluster boundary then there's no\n\t * zeroing required as the region is part of the allocation to\n\t * be truncated.\n\t */\n\tif ((start & (csize - 1)) == 0 && (end & (csize - 1)) == 0)\n\t\tgoto out;\n\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * If start is on a cluster boundary and end is somewhere in another\n\t * cluster, we have not COWed the cluster starting at start, unless\n\t * end is also within the same cluster. So, in this case, we skip this\n\t * first call to ocfs2_zero_range_for_truncate() truncate and move on\n\t * to the next one.\n\t */\n\tif ((start & (csize - 1)) != 0) {\n\t\t/*\n\t\t * We want to get the byte offset of the end of the 1st\n\t\t * cluster.\n\t\t */\n\t\ttmpend = (u64)osb->s_clustersize +\n\t\t\t(start & ~(osb->s_clustersize - 1));\n\t\tif (tmpend > end)\n\t\t\ttmpend = end;\n\n\t\ttrace_ocfs2_zero_partial_clusters_range1(\n\t\t\t(unsigned long long)start,\n\t\t\t(unsigned long long)tmpend);\n\n\t\tret = ocfs2_zero_range_for_truncate(inode, handle, start,\n\t\t\t\t\t\t    tmpend);\n\t\tif (ret)\n\t\t\tmlog_errno(ret);\n\t}\n\n\tif (tmpend < end) {\n\t\t/*\n\t\t * This may make start and end equal, but the zeroing\n\t\t * code will skip any work in that case so there's no\n\t\t * need to catch it up here.\n\t\t */\n\t\tstart = end & ~(osb->s_clustersize - 1);\n\n\t\ttrace_ocfs2_zero_partial_clusters_range2(\n\t\t\t(unsigned long long)start, (unsigned long long)end);\n\n\t\tret = ocfs2_zero_range_for_truncate(inode, handle, start, end);\n\t\tif (ret)\n\t\t\tmlog_errno(ret);\n\t}\n\tocfs2_update_inode_fsync_trans(handle, inode, 1);\n\n\tocfs2_commit_trans(osb, handle);\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_find_rec(struct ocfs2_extent_list *el, u32 pos)\n{\n\tint i;\n\tstruct ocfs2_extent_rec *rec = NULL;\n\n\tfor (i = le16_to_cpu(el->l_next_free_rec) - 1; i >= 0; i--) {\n\n\t\trec = &el->l_recs[i];\n\n\t\tif (le32_to_cpu(rec->e_cpos) < pos)\n\t\t\tbreak;\n\t}\n\n\treturn i;\n}\n\n/*\n * Helper to calculate the punching pos and length in one run, we handle the\n * following three cases in order:\n *\n * - remove the entire record\n * - remove a partial record\n * - no record needs to be removed (hole-punching completed)\n*/\nstatic void ocfs2_calc_trunc_pos(struct inode *inode,\n\t\t\t\t struct ocfs2_extent_list *el,\n\t\t\t\t struct ocfs2_extent_rec *rec,\n\t\t\t\t u32 trunc_start, u32 *trunc_cpos,\n\t\t\t\t u32 *trunc_len, u32 *trunc_end,\n\t\t\t\t u64 *blkno, int *done)\n{\n\tint ret = 0;\n\tu32 coff, range;\n\n\trange = le32_to_cpu(rec->e_cpos) + ocfs2_rec_clusters(el, rec);\n\n\tif (le32_to_cpu(rec->e_cpos) >= trunc_start) {\n\t\t/*\n\t\t * remove an entire extent record.\n\t\t */\n\t\t*trunc_cpos = le32_to_cpu(rec->e_cpos);\n\t\t/*\n\t\t * Skip holes if any.\n\t\t */\n\t\tif (range < *trunc_end)\n\t\t\t*trunc_end = range;\n\t\t*trunc_len = *trunc_end - le32_to_cpu(rec->e_cpos);\n\t\t*blkno = le64_to_cpu(rec->e_blkno);\n\t\t*trunc_end = le32_to_cpu(rec->e_cpos);\n\t} else if (range > trunc_start) {\n\t\t/*\n\t\t * remove a partial extent record, which means we're\n\t\t * removing the last extent record.\n\t\t */\n\t\t*trunc_cpos = trunc_start;\n\t\t/*\n\t\t * skip hole if any.\n\t\t */\n\t\tif (range < *trunc_end)\n\t\t\t*trunc_end = range;\n\t\t*trunc_len = *trunc_end - trunc_start;\n\t\tcoff = trunc_start - le32_to_cpu(rec->e_cpos);\n\t\t*blkno = le64_to_cpu(rec->e_blkno) +\n\t\t\t\tocfs2_clusters_to_blocks(inode->i_sb, coff);\n\t\t*trunc_end = trunc_start;\n\t} else {\n\t\t/*\n\t\t * It may have two following possibilities:\n\t\t *\n\t\t * - last record has been removed\n\t\t * - trunc_start was within a hole\n\t\t *\n\t\t * both two cases mean the completion of hole punching.\n\t\t */\n\t\tret = 1;\n\t}\n\n\t*done = ret;\n}\n\nint ocfs2_remove_inode_range(struct inode *inode,\n\t\t\t     struct buffer_head *di_bh, u64 byte_start,\n\t\t\t     u64 byte_len)\n{\n\tint ret = 0, flags = 0, done = 0, i;\n\tu32 trunc_start, trunc_len, trunc_end, trunc_cpos, phys_cpos;\n\tu32 cluster_in_el;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_cached_dealloc_ctxt dealloc;\n\tstruct address_space *mapping = inode->i_mapping;\n\tstruct ocfs2_extent_tree et;\n\tstruct ocfs2_path *path = NULL;\n\tstruct ocfs2_extent_list *el = NULL;\n\tstruct ocfs2_extent_rec *rec = NULL;\n\tstruct ocfs2_dinode *di = (struct ocfs2_dinode *)di_bh->b_data;\n\tu64 blkno, refcount_loc = le64_to_cpu(di->i_refcount_loc);\n\n\tocfs2_init_dinode_extent_tree(&et, INODE_CACHE(inode), di_bh);\n\tocfs2_init_dealloc_ctxt(&dealloc);\n\n\ttrace_ocfs2_remove_inode_range(\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\t(unsigned long long)byte_start,\n\t\t\t(unsigned long long)byte_len);\n\n\tif (byte_len == 0)\n\t\treturn 0;\n\n\tif (OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL) {\n\t\tret = ocfs2_truncate_inline(inode, di_bh, byte_start,\n\t\t\t\t\t    byte_start + byte_len, 0);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t\t/*\n\t\t * There's no need to get fancy with the page cache\n\t\t * truncate of an inline-data inode. We're talking\n\t\t * about less than a page here, which will be cached\n\t\t * in the dinode buffer anyway.\n\t\t */\n\t\tunmap_mapping_range(mapping, 0, 0, 0);\n\t\ttruncate_inode_pages(mapping, 0);\n\t\tgoto out;\n\t}\n\n\t/*\n\t * For reflinks, we may need to CoW 2 clusters which might be\n\t * partially zero'd later, if hole's start and end offset were\n\t * within one cluster(means is not exactly aligned to clustersize).\n\t */\n\n\tif (ocfs2_is_refcount_inode(inode)) {\n\t\tret = ocfs2_cow_file_pos(inode, di_bh, byte_start);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tret = ocfs2_cow_file_pos(inode, di_bh, byte_start + byte_len);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\ttrunc_start = ocfs2_clusters_for_bytes(osb->sb, byte_start);\n\ttrunc_end = (byte_start + byte_len) >> osb->s_clustersize_bits;\n\tcluster_in_el = trunc_end;\n\n\tret = ocfs2_zero_partial_clusters(inode, byte_start, byte_len);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tpath = ocfs2_new_path_from_et(&et);\n\tif (!path) {\n\t\tret = -ENOMEM;\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\twhile (trunc_end > trunc_start) {\n\n\t\tret = ocfs2_find_path(INODE_CACHE(inode), path,\n\t\t\t\t      cluster_in_el);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tel = path_leaf_el(path);\n\n\t\ti = ocfs2_find_rec(el, trunc_end);\n\t\t/*\n\t\t * Need to go to previous extent block.\n\t\t */\n\t\tif (i < 0) {\n\t\t\tif (path->p_tree_depth == 0)\n\t\t\t\tbreak;\n\n\t\t\tret = ocfs2_find_cpos_for_left_leaf(inode->i_sb,\n\t\t\t\t\t\t\t    path,\n\t\t\t\t\t\t\t    &cluster_in_el);\n\t\t\tif (ret) {\n\t\t\t\tmlog_errno(ret);\n\t\t\t\tgoto out;\n\t\t\t}\n\n\t\t\t/*\n\t\t\t * We've reached the leftmost extent block,\n\t\t\t * it's safe to leave.\n\t\t\t */\n\t\t\tif (cluster_in_el == 0)\n\t\t\t\tbreak;\n\n\t\t\t/*\n\t\t\t * The 'pos' searched for previous extent block is\n\t\t\t * always one cluster less than actual trunc_end.\n\t\t\t */\n\t\t\ttrunc_end = cluster_in_el + 1;\n\n\t\t\tocfs2_reinit_path(path, 1);\n\n\t\t\tcontinue;\n\n\t\t} else\n\t\t\trec = &el->l_recs[i];\n\n\t\tocfs2_calc_trunc_pos(inode, el, rec, trunc_start, &trunc_cpos,\n\t\t\t\t     &trunc_len, &trunc_end, &blkno, &done);\n\t\tif (done)\n\t\t\tbreak;\n\n\t\tflags = rec->e_flags;\n\t\tphys_cpos = ocfs2_blocks_to_clusters(inode->i_sb, blkno);\n\n\t\tret = ocfs2_remove_btree_range(inode, &et, trunc_cpos,\n\t\t\t\t\t       phys_cpos, trunc_len, flags,\n\t\t\t\t\t       &dealloc, refcount_loc, false);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tcluster_in_el = trunc_end;\n\n\t\tocfs2_reinit_path(path, 1);\n\t}\n\n\tocfs2_truncate_cluster_pages(inode, byte_start, byte_len);\n\nout:\n\tocfs2_free_path(path);\n\tocfs2_schedule_truncate_log_flush(osb, 1);\n\tocfs2_run_deallocs(osb, &dealloc);\n\n\treturn ret;\n}\n\n/*\n * Parts of this function taken from xfs_change_file_space()\n */\nstatic int __ocfs2_change_file_space(struct file *file, struct inode *inode,\n\t\t\t\t     loff_t f_pos, unsigned int cmd,\n\t\t\t\t     struct ocfs2_space_resv *sr,\n\t\t\t\t     int change_size)\n{\n\tint ret;\n\ts64 llen;\n\tloff_t size;\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct buffer_head *di_bh = NULL;\n\thandle_t *handle;\n\tunsigned long long max_off = inode->i_sb->s_maxbytes;\n\n\tif (ocfs2_is_hard_readonly(osb) || ocfs2_is_soft_readonly(osb))\n\t\treturn -EROFS;\n\n\tinode_lock(inode);\n\n\t/*\n\t * This prevents concurrent writes on other nodes\n\t */\n\tret = ocfs2_rw_lock(inode, 1);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tret = ocfs2_inode_lock(inode, &di_bh, 1);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out_rw_unlock;\n\t}\n\n\tif (inode->i_flags & (S_IMMUTABLE|S_APPEND)) {\n\t\tret = -EPERM;\n\t\tgoto out_inode_unlock;\n\t}\n\n\tswitch (sr->l_whence) {\n\tcase 0: /*SEEK_SET*/\n\t\tbreak;\n\tcase 1: /*SEEK_CUR*/\n\t\tsr->l_start += f_pos;\n\t\tbreak;\n\tcase 2: /*SEEK_END*/\n\t\tsr->l_start += i_size_read(inode);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto out_inode_unlock;\n\t}\n\tsr->l_whence = 0;\n\n\tllen = sr->l_len > 0 ? sr->l_len - 1 : sr->l_len;\n\n\tif (sr->l_start < 0\n\t    || sr->l_start > max_off\n\t    || (sr->l_start + llen) < 0\n\t    || (sr->l_start + llen) > max_off) {\n\t\tret = -EINVAL;\n\t\tgoto out_inode_unlock;\n\t}\n\tsize = sr->l_start + sr->l_len;\n\n\tif (cmd == OCFS2_IOC_RESVSP || cmd == OCFS2_IOC_RESVSP64 ||\n\t    cmd == OCFS2_IOC_UNRESVSP || cmd == OCFS2_IOC_UNRESVSP64) {\n\t\tif (sr->l_len <= 0) {\n\t\t\tret = -EINVAL;\n\t\t\tgoto out_inode_unlock;\n\t\t}\n\t}\n\n\tif (file && should_remove_suid(file->f_path.dentry)) {\n\t\tret = __ocfs2_write_remove_suid(inode, di_bh);\n\t\tif (ret) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out_inode_unlock;\n\t\t}\n\t}\n\n\tdown_write(&OCFS2_I(inode)->ip_alloc_sem);\n\tswitch (cmd) {\n\tcase OCFS2_IOC_RESVSP:\n\tcase OCFS2_IOC_RESVSP64:\n\t\t/*\n\t\t * This takes unsigned offsets, but the signed ones we\n\t\t * pass have been checked against overflow above.\n\t\t */\n\t\tret = ocfs2_allocate_unwritten_extents(inode, sr->l_start,\n\t\t\t\t\t\t       sr->l_len);\n\t\tbreak;\n\tcase OCFS2_IOC_UNRESVSP:\n\tcase OCFS2_IOC_UNRESVSP64:\n\t\tret = ocfs2_remove_inode_range(inode, di_bh, sr->l_start,\n\t\t\t\t\t       sr->l_len);\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t}\n\tup_write(&OCFS2_I(inode)->ip_alloc_sem);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out_inode_unlock;\n\t}\n\n\t/*\n\t * We update c/mtime for these changes\n\t */\n\thandle = ocfs2_start_trans(osb, OCFS2_INODE_UPDATE_CREDITS);\n\tif (IS_ERR(handle)) {\n\t\tret = PTR_ERR(handle);\n\t\tmlog_errno(ret);\n\t\tgoto out_inode_unlock;\n\t}\n\n\tif (change_size && i_size_read(inode) < size)\n\t\ti_size_write(inode, size);\n\n\tinode->i_ctime = inode->i_mtime = current_time(inode);\n\tret = ocfs2_mark_inode_dirty(handle, inode, di_bh);\n\tif (ret < 0)\n\t\tmlog_errno(ret);\n\n\tif (file && (file->f_flags & O_SYNC))\n\t\thandle->h_sync = 1;\n\n\tocfs2_commit_trans(osb, handle);\n\nout_inode_unlock:\n\tbrelse(di_bh);\n\tocfs2_inode_unlock(inode, 1);\nout_rw_unlock:\n\tocfs2_rw_unlock(inode, 1);\n\nout:\n\tinode_unlock(inode);\n\treturn ret;\n}\n\nint ocfs2_change_file_space(struct file *file, unsigned int cmd,\n\t\t\t    struct ocfs2_space_resv *sr)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tint ret;\n\n\tif ((cmd == OCFS2_IOC_RESVSP || cmd == OCFS2_IOC_RESVSP64) &&\n\t    !ocfs2_writes_unwritten_extents(osb))\n\t\treturn -ENOTTY;\n\telse if ((cmd == OCFS2_IOC_UNRESVSP || cmd == OCFS2_IOC_UNRESVSP64) &&\n\t\t !ocfs2_sparse_alloc(osb))\n\t\treturn -ENOTTY;\n\n\tif (!S_ISREG(inode->i_mode))\n\t\treturn -EINVAL;\n\n\tif (!(file->f_mode & FMODE_WRITE))\n\t\treturn -EBADF;\n\n\tret = mnt_want_write_file(file);\n\tif (ret)\n\t\treturn ret;\n\tret = __ocfs2_change_file_space(file, inode, file->f_pos, cmd, sr, 0);\n\tmnt_drop_write_file(file);\n\treturn ret;\n}\n\nstatic long ocfs2_fallocate(struct file *file, int mode, loff_t offset,\n\t\t\t    loff_t len)\n{\n\tstruct inode *inode = file_inode(file);\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tstruct ocfs2_space_resv sr;\n\tint change_size = 1;\n\tint cmd = OCFS2_IOC_RESVSP64;\n\n\tif (mode & ~(FALLOC_FL_KEEP_SIZE | FALLOC_FL_PUNCH_HOLE))\n\t\treturn -EOPNOTSUPP;\n\tif (!ocfs2_writes_unwritten_extents(osb))\n\t\treturn -EOPNOTSUPP;\n\n\tif (mode & FALLOC_FL_KEEP_SIZE)\n\t\tchange_size = 0;\n\n\tif (mode & FALLOC_FL_PUNCH_HOLE)\n\t\tcmd = OCFS2_IOC_UNRESVSP64;\n\n\tsr.l_whence = 0;\n\tsr.l_start = (s64)offset;\n\tsr.l_len = (s64)len;\n\n\treturn __ocfs2_change_file_space(NULL, inode, offset, cmd, &sr,\n\t\t\t\t\t change_size);\n}\n\nint ocfs2_check_range_for_refcount(struct inode *inode, loff_t pos,\n\t\t\t\t   size_t count)\n{\n\tint ret = 0;\n\tunsigned int extent_flags;\n\tu32 cpos, clusters, extent_len, phys_cpos;\n\tstruct super_block *sb = inode->i_sb;\n\n\tif (!ocfs2_refcount_tree(OCFS2_SB(inode->i_sb)) ||\n\t    !ocfs2_is_refcount_inode(inode) ||\n\t    OCFS2_I(inode)->ip_dyn_features & OCFS2_INLINE_DATA_FL)\n\t\treturn 0;\n\n\tcpos = pos >> OCFS2_SB(sb)->s_clustersize_bits;\n\tclusters = ocfs2_clusters_for_bytes(sb, pos + count) - cpos;\n\n\twhile (clusters) {\n\t\tret = ocfs2_get_clusters(inode, cpos, &phys_cpos, &extent_len,\n\t\t\t\t\t &extent_flags);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tif (phys_cpos && (extent_flags & OCFS2_EXT_REFCOUNTED)) {\n\t\t\tret = 1;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (extent_len > clusters)\n\t\t\textent_len = clusters;\n\n\t\tclusters -= extent_len;\n\t\tcpos += extent_len;\n\t}\nout:\n\treturn ret;\n}\n\nstatic int ocfs2_is_io_unaligned(struct inode *inode, size_t count, loff_t pos)\n{\n\tint blockmask = inode->i_sb->s_blocksize - 1;\n\tloff_t final_size = pos + count;\n\n\tif ((pos & blockmask) || (final_size & blockmask))\n\t\treturn 1;\n\treturn 0;\n}\n\nstatic int ocfs2_prepare_inode_for_refcount(struct inode *inode,\n\t\t\t\t\t    struct file *file,\n\t\t\t\t\t    loff_t pos, size_t count,\n\t\t\t\t\t    int *meta_level)\n{\n\tint ret;\n\tstruct buffer_head *di_bh = NULL;\n\tu32 cpos = pos >> OCFS2_SB(inode->i_sb)->s_clustersize_bits;\n\tu32 clusters =\n\t\tocfs2_clusters_for_bytes(inode->i_sb, pos + count) - cpos;\n\n\tret = ocfs2_inode_lock(inode, &di_bh, 1);\n\tif (ret) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\t*meta_level = 1;\n\n\tret = ocfs2_refcount_cow(inode, di_bh, cpos, clusters, UINT_MAX);\n\tif (ret)\n\t\tmlog_errno(ret);\nout:\n\tbrelse(di_bh);\n\treturn ret;\n}\n\nstatic int ocfs2_prepare_inode_for_write(struct file *file,\n\t\t\t\t\t loff_t pos,\n\t\t\t\t\t size_t count)\n{\n\tint ret = 0, meta_level = 0;\n\tstruct dentry *dentry = file->f_path.dentry;\n\tstruct inode *inode = d_inode(dentry);\n\tloff_t end;\n\n\t/*\n\t * We start with a read level meta lock and only jump to an ex\n\t * if we need to make modifications here.\n\t */\n\tfor(;;) {\n\t\tret = ocfs2_inode_lock(inode, NULL, meta_level);\n\t\tif (ret < 0) {\n\t\t\tmeta_level = -1;\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\t/* Clear suid / sgid if necessary. We do this here\n\t\t * instead of later in the write path because\n\t\t * remove_suid() calls ->setattr without any hint that\n\t\t * we may have already done our cluster locking. Since\n\t\t * ocfs2_setattr() *must* take cluster locks to\n\t\t * proceed, this will lead us to recursively lock the\n\t\t * inode. There's also the dinode i_size state which\n\t\t * can be lost via setattr during extending writes (we\n\t\t * set inode->i_size at the end of a write. */\n\t\tif (should_remove_suid(dentry)) {\n\t\t\tif (meta_level == 0) {\n\t\t\t\tocfs2_inode_unlock(inode, meta_level);\n\t\t\t\tmeta_level = 1;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tret = ocfs2_write_remove_suid(inode);\n\t\t\tif (ret < 0) {\n\t\t\t\tmlog_errno(ret);\n\t\t\t\tgoto out_unlock;\n\t\t\t}\n\t\t}\n\n\t\tend = pos + count;\n\n\t\tret = ocfs2_check_range_for_refcount(inode, pos, count);\n\t\tif (ret == 1) {\n\t\t\tocfs2_inode_unlock(inode, meta_level);\n\t\t\tmeta_level = -1;\n\n\t\t\tret = ocfs2_prepare_inode_for_refcount(inode,\n\t\t\t\t\t\t\t       file,\n\t\t\t\t\t\t\t       pos,\n\t\t\t\t\t\t\t       count,\n\t\t\t\t\t\t\t       &meta_level);\n\t\t}\n\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out_unlock;\n\t\t}\n\n\t\tbreak;\n\t}\n\nout_unlock:\n\ttrace_ocfs2_prepare_inode_for_write(OCFS2_I(inode)->ip_blkno,\n\t\t\t\t\t    pos, count);\n\n\tif (meta_level >= 0)\n\t\tocfs2_inode_unlock(inode, meta_level);\n\nout:\n\treturn ret;\n}\n\nstatic ssize_t ocfs2_file_write_iter(struct kiocb *iocb,\n\t\t\t\t    struct iov_iter *from)\n{\n\tint direct_io, rw_level;\n\tssize_t written = 0;\n\tssize_t ret;\n\tsize_t count = iov_iter_count(from);\n\tstruct file *file = iocb->ki_filp;\n\tstruct inode *inode = file_inode(file);\n\tstruct ocfs2_super *osb = OCFS2_SB(inode->i_sb);\n\tint full_coherency = !(osb->s_mount_opt &\n\t\t\t       OCFS2_MOUNT_COHERENCY_BUFFERED);\n\tvoid *saved_ki_complete = NULL;\n\tint append_write = ((iocb->ki_pos + count) >=\n\t\t\ti_size_read(inode) ? 1 : 0);\n\n\ttrace_ocfs2_file_aio_write(inode, file, file->f_path.dentry,\n\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\tfile->f_path.dentry->d_name.len,\n\t\tfile->f_path.dentry->d_name.name,\n\t\t(unsigned int)from->nr_segs);\t/* GRRRRR */\n\n\tif (count == 0)\n\t\treturn 0;\n\n\tdirect_io = iocb->ki_flags & IOCB_DIRECT ? 1 : 0;\n\n\tinode_lock(inode);\n\n\t/*\n\t * Concurrent O_DIRECT writes are allowed with\n\t * mount_option \"coherency=buffered\".\n\t * For append write, we must take rw EX.\n\t */\n\trw_level = (!direct_io || full_coherency || append_write);\n\n\tret = ocfs2_rw_lock(inode, rw_level);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out_mutex;\n\t}\n\n\t/*\n\t * O_DIRECT writes with \"coherency=full\" need to take EX cluster\n\t * inode_lock to guarantee coherency.\n\t */\n\tif (direct_io && full_coherency) {\n\t\t/*\n\t\t * We need to take and drop the inode lock to force\n\t\t * other nodes to drop their caches.  Buffered I/O\n\t\t * already does this in write_begin().\n\t\t */\n\t\tret = ocfs2_inode_lock(inode, NULL, 1);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\n\t\tocfs2_inode_unlock(inode, 1);\n\t}\n\n\tret = generic_write_checks(iocb, from);\n\tif (ret <= 0) {\n\t\tif (ret)\n\t\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\tcount = ret;\n\n\tret = ocfs2_prepare_inode_for_write(file, iocb->ki_pos, count);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto out;\n\t}\n\n\tif (direct_io && !is_sync_kiocb(iocb) &&\n\t    ocfs2_is_io_unaligned(inode, count, iocb->ki_pos)) {\n\t\t/*\n\t\t * Make it a sync io if it's an unaligned aio.\n\t\t */\n\t\tsaved_ki_complete = xchg(&iocb->ki_complete, NULL);\n\t}\n\n\t/* communicate with ocfs2_dio_end_io */\n\tocfs2_iocb_set_rw_locked(iocb, rw_level);\n\n\twritten = __generic_file_write_iter(iocb, from);\n\t/* buffered aio wouldn't have proper lock coverage today */\n\tBUG_ON(written == -EIOCBQUEUED && !(iocb->ki_flags & IOCB_DIRECT));\n\n\t/*\n\t * deep in g_f_a_w_n()->ocfs2_direct_IO we pass in a ocfs2_dio_end_io\n\t * function pointer which is called when o_direct io completes so that\n\t * it can unlock our rw lock.\n\t * Unfortunately there are error cases which call end_io and others\n\t * that don't.  so we don't have to unlock the rw_lock if either an\n\t * async dio is going to do it in the future or an end_io after an\n\t * error has already done it.\n\t */\n\tif ((written == -EIOCBQUEUED) || (!ocfs2_iocb_is_rw_locked(iocb))) {\n\t\trw_level = -1;\n\t}\n\n\tif (unlikely(written <= 0))\n\t\tgoto out;\n\n\tif (((file->f_flags & O_DSYNC) && !direct_io) ||\n\t    IS_SYNC(inode)) {\n\t\tret = filemap_fdatawrite_range(file->f_mapping,\n\t\t\t\t\t       iocb->ki_pos - written,\n\t\t\t\t\t       iocb->ki_pos - 1);\n\t\tif (ret < 0)\n\t\t\twritten = ret;\n\n\t\tif (!ret) {\n\t\t\tret = jbd2_journal_force_commit(osb->journal->j_journal);\n\t\t\tif (ret < 0)\n\t\t\t\twritten = ret;\n\t\t}\n\n\t\tif (!ret)\n\t\t\tret = filemap_fdatawait_range(file->f_mapping,\n\t\t\t\t\t\t      iocb->ki_pos - written,\n\t\t\t\t\t\t      iocb->ki_pos - 1);\n\t}\n\nout:\n\tif (saved_ki_complete)\n\t\txchg(&iocb->ki_complete, saved_ki_complete);\n\n\tif (rw_level != -1)\n\t\tocfs2_rw_unlock(inode, rw_level);\n\nout_mutex:\n\tinode_unlock(inode);\n\n\tif (written)\n\t\tret = written;\n\treturn ret;\n}\n\nstatic ssize_t ocfs2_file_read_iter(struct kiocb *iocb,\n\t\t\t\t   struct iov_iter *to)\n{\n\tint ret = 0, rw_level = -1, lock_level = 0;\n\tstruct file *filp = iocb->ki_filp;\n\tstruct inode *inode = file_inode(filp);\n\n\ttrace_ocfs2_file_aio_read(inode, filp, filp->f_path.dentry,\n\t\t\t(unsigned long long)OCFS2_I(inode)->ip_blkno,\n\t\t\tfilp->f_path.dentry->d_name.len,\n\t\t\tfilp->f_path.dentry->d_name.name,\n\t\t\tto->nr_segs);\t/* GRRRRR */\n\n\n\tif (!inode) {\n\t\tret = -EINVAL;\n\t\tmlog_errno(ret);\n\t\tgoto bail;\n\t}\n\n\t/*\n\t * buffered reads protect themselves in ->readpage().  O_DIRECT reads\n\t * need locks to protect pending reads from racing with truncate.\n\t */\n\tif (iocb->ki_flags & IOCB_DIRECT) {\n\t\tret = ocfs2_rw_lock(inode, 0);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto bail;\n\t\t}\n\t\trw_level = 0;\n\t\t/* communicate with ocfs2_dio_end_io */\n\t\tocfs2_iocb_set_rw_locked(iocb, rw_level);\n\t}\n\n\t/*\n\t * We're fine letting folks race truncates and extending\n\t * writes with read across the cluster, just like they can\n\t * locally. Hence no rw_lock during read.\n\t *\n\t * Take and drop the meta data lock to update inode fields\n\t * like i_size. This allows the checks down below\n\t * generic_file_aio_read() a chance of actually working.\n\t */\n\tret = ocfs2_inode_lock_atime(inode, filp->f_path.mnt, &lock_level);\n\tif (ret < 0) {\n\t\tmlog_errno(ret);\n\t\tgoto bail;\n\t}\n\tocfs2_inode_unlock(inode, lock_level);\n\n\tret = generic_file_read_iter(iocb, to);\n\ttrace_generic_file_aio_read_ret(ret);\n\n\t/* buffered aio wouldn't have proper lock coverage today */\n\tBUG_ON(ret == -EIOCBQUEUED && !(iocb->ki_flags & IOCB_DIRECT));\n\n\t/* see ocfs2_file_write_iter */\n\tif (ret == -EIOCBQUEUED || !ocfs2_iocb_is_rw_locked(iocb)) {\n\t\trw_level = -1;\n\t}\n\nbail:\n\tif (rw_level != -1)\n\t\tocfs2_rw_unlock(inode, rw_level);\n\n\treturn ret;\n}\n\n/* Refer generic_file_llseek_unlocked() */\nstatic loff_t ocfs2_file_llseek(struct file *file, loff_t offset, int whence)\n{\n\tstruct inode *inode = file->f_mapping->host;\n\tint ret = 0;\n\n\tinode_lock(inode);\n\n\tswitch (whence) {\n\tcase SEEK_SET:\n\t\tbreak;\n\tcase SEEK_END:\n\t\t/* SEEK_END requires the OCFS2 inode lock for the file\n\t\t * because it references the file's size.\n\t\t */\n\t\tret = ocfs2_inode_lock(inode, NULL, 0);\n\t\tif (ret < 0) {\n\t\t\tmlog_errno(ret);\n\t\t\tgoto out;\n\t\t}\n\t\toffset += i_size_read(inode);\n\t\tocfs2_inode_unlock(inode, 0);\n\t\tbreak;\n\tcase SEEK_CUR:\n\t\tif (offset == 0) {\n\t\t\toffset = file->f_pos;\n\t\t\tgoto out;\n\t\t}\n\t\toffset += file->f_pos;\n\t\tbreak;\n\tcase SEEK_DATA:\n\tcase SEEK_HOLE:\n\t\tret = ocfs2_seek_data_hole_offset(file, &offset, whence);\n\t\tif (ret)\n\t\t\tgoto out;\n\t\tbreak;\n\tdefault:\n\t\tret = -EINVAL;\n\t\tgoto out;\n\t}\n\n\toffset = vfs_setpos(file, offset, inode->i_sb->s_maxbytes);\n\nout:\n\tinode_unlock(inode);\n\tif (ret)\n\t\treturn ret;\n\treturn offset;\n}\n\nstatic int ocfs2_file_clone_range(struct file *file_in,\n\t\t\t\t  loff_t pos_in,\n\t\t\t\t  struct file *file_out,\n\t\t\t\t  loff_t pos_out,\n\t\t\t\t  u64 len)\n{\n\treturn ocfs2_reflink_remap_range(file_in, pos_in, file_out, pos_out,\n\t\t\t\t\t len, false);\n}\n\nstatic ssize_t ocfs2_file_dedupe_range(struct file *src_file,\n\t\t\t\t       u64 loff,\n\t\t\t\t       u64 len,\n\t\t\t\t       struct file *dst_file,\n\t\t\t\t       u64 dst_loff)\n{\n\tint error;\n\n\terror = ocfs2_reflink_remap_range(src_file, loff, dst_file, dst_loff,\n\t\t\t\t\t  len, true);\n\tif (error)\n\t\treturn error;\n\treturn len;\n}\n\nconst struct inode_operations ocfs2_file_iops = {\n\t.setattr\t= ocfs2_setattr,\n\t.getattr\t= ocfs2_getattr,\n\t.permission\t= ocfs2_permission,\n\t.listxattr\t= ocfs2_listxattr,\n\t.fiemap\t\t= ocfs2_fiemap,\n\t.get_acl\t= ocfs2_iop_get_acl,\n\t.set_acl\t= ocfs2_iop_set_acl,\n};\n\nconst struct inode_operations ocfs2_special_file_iops = {\n\t.setattr\t= ocfs2_setattr,\n\t.getattr\t= ocfs2_getattr,\n\t.permission\t= ocfs2_permission,\n\t.get_acl\t= ocfs2_iop_get_acl,\n\t.set_acl\t= ocfs2_iop_set_acl,\n};\n\n/*\n * Other than ->lock, keep ocfs2_fops and ocfs2_dops in sync with\n * ocfs2_fops_no_plocks and ocfs2_dops_no_plocks!\n */\nconst struct file_operations ocfs2_fops = {\n\t.llseek\t\t= ocfs2_file_llseek,\n\t.mmap\t\t= ocfs2_mmap,\n\t.fsync\t\t= ocfs2_sync_file,\n\t.release\t= ocfs2_file_release,\n\t.open\t\t= ocfs2_file_open,\n\t.read_iter\t= ocfs2_file_read_iter,\n\t.write_iter\t= ocfs2_file_write_iter,\n\t.unlocked_ioctl\t= ocfs2_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl   = ocfs2_compat_ioctl,\n#endif\n\t.lock\t\t= ocfs2_lock,\n\t.flock\t\t= ocfs2_flock,\n\t.splice_read\t= generic_file_splice_read,\n\t.splice_write\t= iter_file_splice_write,\n\t.fallocate\t= ocfs2_fallocate,\n\t.clone_file_range = ocfs2_file_clone_range,\n\t.dedupe_file_range = ocfs2_file_dedupe_range,\n};\n\nconst struct file_operations ocfs2_dops = {\n\t.llseek\t\t= generic_file_llseek,\n\t.read\t\t= generic_read_dir,\n\t.iterate\t= ocfs2_readdir,\n\t.fsync\t\t= ocfs2_sync_file,\n\t.release\t= ocfs2_dir_release,\n\t.open\t\t= ocfs2_dir_open,\n\t.unlocked_ioctl\t= ocfs2_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl   = ocfs2_compat_ioctl,\n#endif\n\t.lock\t\t= ocfs2_lock,\n\t.flock\t\t= ocfs2_flock,\n};\n\n/*\n * POSIX-lockless variants of our file_operations.\n *\n * These will be used if the underlying cluster stack does not support\n * posix file locking, if the user passes the \"localflocks\" mount\n * option, or if we have a local-only fs.\n *\n * ocfs2_flock is in here because all stacks handle UNIX file locks,\n * so we still want it in the case of no stack support for\n * plocks. Internally, it will do the right thing when asked to ignore\n * the cluster.\n */\nconst struct file_operations ocfs2_fops_no_plocks = {\n\t.llseek\t\t= ocfs2_file_llseek,\n\t.mmap\t\t= ocfs2_mmap,\n\t.fsync\t\t= ocfs2_sync_file,\n\t.release\t= ocfs2_file_release,\n\t.open\t\t= ocfs2_file_open,\n\t.read_iter\t= ocfs2_file_read_iter,\n\t.write_iter\t= ocfs2_file_write_iter,\n\t.unlocked_ioctl\t= ocfs2_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl   = ocfs2_compat_ioctl,\n#endif\n\t.flock\t\t= ocfs2_flock,\n\t.splice_read\t= generic_file_splice_read,\n\t.splice_write\t= iter_file_splice_write,\n\t.fallocate\t= ocfs2_fallocate,\n\t.clone_file_range = ocfs2_file_clone_range,\n\t.dedupe_file_range = ocfs2_file_dedupe_range,\n};\n\nconst struct file_operations ocfs2_dops_no_plocks = {\n\t.llseek\t\t= generic_file_llseek,\n\t.read\t\t= generic_read_dir,\n\t.iterate\t= ocfs2_readdir,\n\t.fsync\t\t= ocfs2_sync_file,\n\t.release\t= ocfs2_dir_release,\n\t.open\t\t= ocfs2_dir_open,\n\t.unlocked_ioctl\t= ocfs2_ioctl,\n#ifdef CONFIG_COMPAT\n\t.compat_ioctl   = ocfs2_compat_ioctl,\n#endif\n\t.flock\t\t= ocfs2_flock,\n};\n"], "filenames": ["fs/ocfs2/file.c"], "buggy_code_start_loc": [1163], "buggy_code_end_loc": [1204], "fixing_code_start_loc": [1164], "fixing_code_end_loc": [1208], "type": "NVD-CWE-noinfo", "message": "The ocfs2_setattr function in fs/ocfs2/file.c in the Linux kernel before 4.14.2 allows local users to cause a denial of service (deadlock) via DIO requests.", "other": {"cve": {"id": "CVE-2017-18204", "sourceIdentifier": "cve@mitre.org", "published": "2018-02-27T20:29:00.340", "lastModified": "2019-10-03T00:03:26.223", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The ocfs2_setattr function in fs/ocfs2/file.c in the Linux kernel before 4.14.2 allows local users to cause a denial of service (deadlock) via DIO requests."}, {"lang": "es", "value": "La funci\u00f3n ocfs2_setattr en fs/ocfs2/file.c en el kernel de Linux, en versiones anteriores a la 4.14.2, permite que usuarios locales provoquen una denegaci\u00f3n de servicio (deadlock) mediante peticiones DIO."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "4.14.2", "matchCriteriaId": "8BFBFB82-9C5E-45C1-AD36-05E379DAE87F"}]}]}], "references": [{"url": "http://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=28f5a8a7c033cbf3e32277f4cc9c6afd74f05300", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "http://www.securityfocus.com/bid/103183", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://github.com/torvalds/linux/commit/28f5a8a7c033cbf3e32277f4cc9c6afd74f05300", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/3617-1/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/3617-2/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/3617-3/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/3619-1/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/3619-2/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/3655-1/", "source": "cve@mitre.org"}, {"url": "https://usn.ubuntu.com/3655-2/", "source": "cve@mitre.org"}, {"url": "https://www.kernel.org/pub/linux/kernel/v4.x/ChangeLog-4.14.2", "source": "cve@mitre.org", "tags": ["Release Notes", "Vendor Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/28f5a8a7c033cbf3e32277f4cc9c6afd74f05300"}}
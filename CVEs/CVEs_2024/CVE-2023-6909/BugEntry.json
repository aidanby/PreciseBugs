{"buggy_code": ["import os\nimport pathlib\nimport posixpath\nimport re\nimport urllib.parse\nimport uuid\nfrom typing import Any, Tuple\n\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE\nfrom mlflow.store.db.db_types import DATABASE_ENGINES\nfrom mlflow.utils.os import is_windows\nfrom mlflow.utils.validation import _validate_db_type_string\n\n_INVALID_DB_URI_MSG = (\n    \"Please refer to https://mlflow.org/docs/latest/tracking.html#storage for \"\n    \"format specifications.\"\n)\n\n_DBFS_FUSE_PREFIX = \"/dbfs/\"\n_DBFS_HDFS_URI_PREFIX = \"dbfs:/\"\n_UC_VOLUMES_URI_PREFIX = \"/Volumes/\"\n_UC_DBFS_SYMLINK_PREFIX = \"/.fuse-mounts/\"\n_DATABRICKS_UNITY_CATALOG_SCHEME = \"databricks-uc\"\n\n\ndef is_local_uri(uri, is_tracking_or_registry_uri=True):\n    \"\"\"\n    Returns true if the specified URI is a local file path (/foo or file:/foo).\n\n    :param uri: The URI.\n    :param is_tracking_uri: Whether or not the specified URI is an MLflow Tracking or MLflow\n                            Model Registry URI. Examples of other URIs are MLflow artifact URIs,\n                            filesystem paths, etc.\n    \"\"\"\n    if uri == \"databricks\" and is_tracking_or_registry_uri:\n        return False\n\n    if is_windows() and uri.startswith(\"\\\\\\\\\"):\n        # windows network drive path looks like: \"\\\\<server name>\\path\\...\"\n        return False\n\n    parsed_uri = urllib.parse.urlparse(uri)\n    scheme = parsed_uri.scheme\n    if scheme == \"\":\n        return True\n\n    if parsed_uri.hostname and not (\n        parsed_uri.hostname == \".\"\n        or parsed_uri.hostname.startswith(\"localhost\")\n        or parsed_uri.hostname.startswith(\"127.0.0.1\")\n    ):\n        return False\n\n    if scheme == \"file\":\n        return True\n\n    if is_windows() and len(scheme) == 1 and scheme.lower() == pathlib.Path(uri).drive.lower()[0]:\n        return True\n\n    return False\n\n\ndef is_file_uri(uri):\n    return urllib.parse.urlparse(uri).scheme == \"file\"\n\n\ndef is_http_uri(uri):\n    scheme = urllib.parse.urlparse(uri).scheme\n    return scheme == \"http\" or scheme == \"https\"\n\n\ndef is_databricks_uri(uri):\n    \"\"\"\n    Databricks URIs look like 'databricks' (default profile) or 'databricks://profile'\n    or 'databricks://secret_scope:secret_key_prefix'.\n    \"\"\"\n    scheme = urllib.parse.urlparse(uri).scheme\n    return scheme == \"databricks\" or uri == \"databricks\"\n\n\ndef is_fuse_or_uc_volumes_uri(uri):\n    \"\"\"\n    Validates whether a provided URI is directed to a FUSE mount point or a UC volumes mount point.\n    Multiple directory paths are collapsed into a single designator for root path validation.\n    example:\n    \"////Volumes/\" will resolve to \"/Volumes/\" for validation purposes.\n    \"\"\"\n    resolved_uri = re.sub(\"/+\", \"/\", uri)\n    return any(\n        resolved_uri.startswith(x)\n        for x in [\n            _DBFS_FUSE_PREFIX,\n            _DBFS_HDFS_URI_PREFIX,\n            _UC_VOLUMES_URI_PREFIX,\n            _UC_DBFS_SYMLINK_PREFIX,\n        ]\n    )\n\n\ndef is_databricks_unity_catalog_uri(uri):\n    scheme = urllib.parse.urlparse(uri).scheme\n    return scheme == _DATABRICKS_UNITY_CATALOG_SCHEME or uri == _DATABRICKS_UNITY_CATALOG_SCHEME\n\n\ndef construct_db_uri_from_profile(profile):\n    if profile:\n        return \"databricks://\" + profile\n\n\n# Both scope and key_prefix should not contain special chars for URIs, like '/'\n# and ':'.\ndef validate_db_scope_prefix_info(scope, prefix):\n    for c in [\"/\", \":\", \" \"]:\n        if c in scope:\n            raise MlflowException(\n                f\"Unsupported Databricks profile name: {scope}.\"\n                f\" Profile names cannot contain '{c}'.\"\n            )\n        if prefix and c in prefix:\n            raise MlflowException(\n                f\"Unsupported Databricks profile key prefix: {prefix}.\"\n                f\" Key prefixes cannot contain '{c}'.\"\n            )\n    if prefix is not None and prefix.strip() == \"\":\n        raise MlflowException(\n            f\"Unsupported Databricks profile key prefix: '{prefix}'.\"\n            \" Key prefixes cannot be empty.\"\n        )\n\n\ndef get_db_info_from_uri(uri):\n    \"\"\"\n    Get the Databricks profile specified by the tracking URI (if any), otherwise\n    returns None.\n    \"\"\"\n    parsed_uri = urllib.parse.urlparse(uri)\n    if parsed_uri.scheme == \"databricks\" or parsed_uri.scheme == _DATABRICKS_UNITY_CATALOG_SCHEME:\n        # netloc should not be an empty string unless URI is formatted incorrectly.\n        if parsed_uri.netloc == \"\":\n            raise MlflowException(\n                f\"URI is formatted incorrectly: no netloc in URI '{uri}'.\"\n                \" This may be the case if there is only one slash in the URI.\"\n            )\n        profile_tokens = parsed_uri.netloc.split(\":\")\n        parsed_scope = profile_tokens[0]\n        if len(profile_tokens) == 1:\n            parsed_key_prefix = None\n        elif len(profile_tokens) == 2:\n            parsed_key_prefix = profile_tokens[1]\n        else:\n            # parse the content before the first colon as the profile.\n            parsed_key_prefix = \":\".join(profile_tokens[1:])\n        validate_db_scope_prefix_info(parsed_scope, parsed_key_prefix)\n        return parsed_scope, parsed_key_prefix\n    return None, None\n\n\ndef get_databricks_profile_uri_from_artifact_uri(uri, result_scheme=\"databricks\"):\n    \"\"\"\n    Retrieves the netloc portion of the URI as a ``databricks://`` or `databricks-uc://` URI,\n    if it is a proper Databricks profile specification, e.g.\n    ``profile@databricks`` or ``secret_scope:key_prefix@databricks``.\n    \"\"\"\n    parsed = urllib.parse.urlparse(uri)\n    if not parsed.netloc or parsed.hostname != result_scheme:\n        return None\n    if not parsed.username:  # no profile or scope:key\n        return result_scheme  # the default tracking/registry URI\n    validate_db_scope_prefix_info(parsed.username, parsed.password)\n    key_prefix = \":\" + parsed.password if parsed.password else \"\"\n    return f\"{result_scheme}://\" + parsed.username + key_prefix\n\n\ndef remove_databricks_profile_info_from_artifact_uri(artifact_uri):\n    \"\"\"\n    Only removes the netloc portion of the URI if it is a Databricks\n    profile specification, e.g.\n    ``profile@databricks`` or ``secret_scope:key_prefix@databricks``.\n    \"\"\"\n    parsed = urllib.parse.urlparse(artifact_uri)\n    if not parsed.netloc or parsed.hostname != \"databricks\":\n        return artifact_uri\n    return urllib.parse.urlunparse(parsed._replace(netloc=\"\"))\n\n\ndef add_databricks_profile_info_to_artifact_uri(artifact_uri, databricks_profile_uri):\n    \"\"\"\n    Throws an exception if ``databricks_profile_uri`` is not valid.\n    \"\"\"\n    if not databricks_profile_uri or not is_databricks_uri(databricks_profile_uri):\n        return artifact_uri\n    artifact_uri_parsed = urllib.parse.urlparse(artifact_uri)\n    # Do not overwrite the authority section if there is already one\n    if artifact_uri_parsed.netloc:\n        return artifact_uri\n\n    scheme = artifact_uri_parsed.scheme\n    if scheme == \"dbfs\" or scheme == \"runs\" or scheme == \"models\":\n        if databricks_profile_uri == \"databricks\":\n            netloc = \"databricks\"\n        else:\n            (profile, key_prefix) = get_db_info_from_uri(databricks_profile_uri)\n            prefix = \":\" + key_prefix if key_prefix else \"\"\n            netloc = profile + prefix + \"@databricks\"\n        new_parsed = artifact_uri_parsed._replace(netloc=netloc)\n        return urllib.parse.urlunparse(new_parsed)\n    else:\n        return artifact_uri\n\n\ndef extract_db_type_from_uri(db_uri):\n    \"\"\"\n    Parse the specified DB URI to extract the database type. Confirm the database type is\n    supported. If a driver is specified, confirm it passes a plausible regex.\n    \"\"\"\n    scheme = urllib.parse.urlparse(db_uri).scheme\n    scheme_plus_count = scheme.count(\"+\")\n\n    if scheme_plus_count == 0:\n        db_type = scheme\n    elif scheme_plus_count == 1:\n        db_type, _ = scheme.split(\"+\")\n    else:\n        error_msg = f\"Invalid database URI: '{db_uri}'. {_INVALID_DB_URI_MSG}\"\n        raise MlflowException(error_msg, INVALID_PARAMETER_VALUE)\n\n    _validate_db_type_string(db_type)\n\n    return db_type\n\n\ndef get_uri_scheme(uri_or_path):\n    scheme = urllib.parse.urlparse(uri_or_path).scheme\n    if any(scheme.lower().startswith(db) for db in DATABASE_ENGINES):\n        return extract_db_type_from_uri(uri_or_path)\n    return scheme\n\n\ndef extract_and_normalize_path(uri):\n    parsed_uri_path = urllib.parse.urlparse(uri).path\n    normalized_path = posixpath.normpath(parsed_uri_path)\n    return normalized_path.lstrip(\"/\")\n\n\ndef append_to_uri_path(uri, *paths):\n    \"\"\"\n    Appends the specified POSIX `paths` to the path component of the specified `uri`.\n\n    :param uri: The input URI, represented as a string.\n    :param paths: The POSIX paths to append to the specified `uri`'s path component.\n    :return: A new URI with a path component consisting of the specified `paths` appended to\n             the path component of the specified `uri`.\n\n    >>> uri1 = \"s3://root/base/path?param=value\"\n    >>> uri1 = append_to_uri_path(uri1, \"some/subpath\", \"/anotherpath\")\n    >>> assert uri1 == \"s3://root/base/path/some/subpath/anotherpath?param=value\"\n    >>> uri2 = \"a/posix/path\"\n    >>> uri2 = append_to_uri_path(uri2, \"/some\", \"subpath\")\n    >>> assert uri2 == \"a/posixpath/some/subpath\"\n    \"\"\"\n    path = \"\"\n    for subpath in paths:\n        path = _join_posixpaths_and_append_absolute_suffixes(path, subpath)\n\n    parsed_uri = urllib.parse.urlparse(uri)\n    if len(parsed_uri.scheme) == 0:\n        # If the input URI does not define a scheme, we assume that it is a POSIX path\n        # and join it with the specified input paths\n        return _join_posixpaths_and_append_absolute_suffixes(uri, path)\n\n    prefix = \"\"\n    if not parsed_uri.path.startswith(\"/\"):\n        # For certain URI schemes (e.g., \"file:\"), urllib's unparse routine does\n        # not preserve the relative URI path component properly. In certain cases,\n        # urlunparse converts relative paths to absolute paths. We introduce this logic\n        # to circumvent urlunparse's erroneous conversion\n        prefix = parsed_uri.scheme + \":\"\n        parsed_uri = parsed_uri._replace(scheme=\"\")\n\n    new_uri_path = _join_posixpaths_and_append_absolute_suffixes(parsed_uri.path, path)\n    new_parsed_uri = parsed_uri._replace(path=new_uri_path)\n    return prefix + urllib.parse.urlunparse(new_parsed_uri)\n\n\ndef append_to_uri_query_params(uri, *query_params: Tuple[str, Any]) -> str:\n    \"\"\"\n    Appends the specified query parameters to an existing URI.\n\n    :param uri: The URI to which to append query parameters.\n    :param query_params: Query parameters to append. Each parameter should\n                         be a 2-element tuple. For example, ``(\"key\", \"value\")``.\n    \"\"\"\n    parsed_uri = urllib.parse.urlparse(uri)\n    parsed_query = urllib.parse.parse_qsl(parsed_uri.query)\n    new_parsed_query = parsed_query + list(query_params)\n    new_query = urllib.parse.urlencode(new_parsed_query)\n    new_parsed_uri = parsed_uri._replace(query=new_query)\n    return urllib.parse.urlunparse(new_parsed_uri)\n\n\ndef _join_posixpaths_and_append_absolute_suffixes(prefix_path, suffix_path):\n    \"\"\"\n    Joins the POSIX path `prefix_path` with the POSIX path `suffix_path`. Unlike posixpath.join(),\n    if `suffix_path` is an absolute path, it is appended to prefix_path.\n\n    >>> result1 = _join_posixpaths_and_append_absolute_suffixes(\"relpath1\", \"relpath2\")\n    >>> assert result1 == \"relpath1/relpath2\"\n    >>> result2 = _join_posixpaths_and_append_absolute_suffixes(\"relpath\", \"/absolutepath\")\n    >>> assert result2 == \"relpath/absolutepath\"\n    >>> result3 = _join_posixpaths_and_append_absolute_suffixes(\"/absolutepath\", \"relpath\")\n    >>> assert result3 == \"/absolutepath/relpath\"\n    >>> result4 = _join_posixpaths_and_append_absolute_suffixes(\"/absolutepath1\", \"/absolutepath2\")\n    >>> assert result4 == \"/absolutepath1/absolutepath2\"\n    \"\"\"\n    if len(prefix_path) == 0:\n        return suffix_path\n\n    # If the specified prefix path is non-empty, we must relativize the suffix path by removing\n    # the leading slash, if present. Otherwise, posixpath.join() would omit the prefix from the\n    # joined path\n    suffix_path = suffix_path.lstrip(posixpath.sep)\n    return posixpath.join(prefix_path, suffix_path)\n\n\ndef is_databricks_acled_artifacts_uri(artifact_uri):\n    _ACLED_ARTIFACT_URI = \"databricks/mlflow-tracking/\"\n    artifact_uri_path = extract_and_normalize_path(artifact_uri)\n    return artifact_uri_path.startswith(_ACLED_ARTIFACT_URI)\n\n\ndef is_databricks_model_registry_artifacts_uri(artifact_uri):\n    _MODEL_REGISTRY_ARTIFACT_URI = \"databricks/mlflow-registry/\"\n    artifact_uri_path = extract_and_normalize_path(artifact_uri)\n    return artifact_uri_path.startswith(_MODEL_REGISTRY_ARTIFACT_URI)\n\n\ndef is_valid_dbfs_uri(uri):\n    parsed = urllib.parse.urlparse(uri)\n    if parsed.scheme != \"dbfs\":\n        return False\n    try:\n        db_profile_uri = get_databricks_profile_uri_from_artifact_uri(uri)\n    except MlflowException:\n        db_profile_uri = None\n    return not parsed.netloc or db_profile_uri is not None\n\n\ndef dbfs_hdfs_uri_to_fuse_path(dbfs_uri):\n    \"\"\"\n    Converts the provided DBFS URI into a DBFS FUSE path\n    :param dbfs_uri: A DBFS URI like \"dbfs:/my-directory\". Can also be a scheme-less URI like\n                     \"/my-directory\" if running in an environment where the default HDFS filesystem\n                     is \"dbfs:/\" (e.g. Databricks)\n    :return A DBFS FUSE-style path, e.g. \"/dbfs/my-directory\"\n    \"\"\"\n    if not is_valid_dbfs_uri(dbfs_uri) and dbfs_uri == posixpath.abspath(dbfs_uri):\n        # Convert posixpaths (e.g. \"/tmp/mlflow\") to DBFS URIs by adding \"dbfs:/\" as a prefix\n        dbfs_uri = \"dbfs:\" + dbfs_uri\n    if not dbfs_uri.startswith(_DBFS_HDFS_URI_PREFIX):\n        raise MlflowException(\n            f\"Path '{dbfs_uri}' did not start with expected DBFS URI \"\n            f\"prefix '{_DBFS_HDFS_URI_PREFIX}'\",\n        )\n\n    return _DBFS_FUSE_PREFIX + dbfs_uri[len(_DBFS_HDFS_URI_PREFIX) :]\n\n\ndef resolve_uri_if_local(local_uri):\n    \"\"\"\n    if `local_uri` is passed in as a relative local path, this function\n    resolves it to absolute path relative to current working directory.\n\n    :param local_uri: Relative or absolute path or local file uri\n\n    :return: a fully-formed absolute uri path or an absolute filesystem path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    if local_uri is not None and is_local_uri(local_uri):\n        scheme = get_uri_scheme(local_uri)\n        cwd = pathlib.Path.cwd()\n        local_path = local_file_uri_to_path(local_uri)\n        if not pathlib.Path(local_path).is_absolute():\n            if scheme == \"\":\n                if is_windows():\n                    return urllib.parse.urlunsplit(\n                        (\n                            \"file\",\n                            None,\n                            cwd.joinpath(local_path).as_posix(),\n                            None,\n                            None,\n                        )\n                    )\n                return cwd.joinpath(local_path).as_posix()\n            local_uri_split = urllib.parse.urlsplit(local_uri)\n            return urllib.parse.urlunsplit(\n                (\n                    local_uri_split.scheme,\n                    None,\n                    cwd.joinpath(local_path).as_posix(),\n                    local_uri_split.query,\n                    local_uri_split.fragment,\n                )\n            )\n    return local_uri\n\n\ndef generate_tmp_dfs_path(dfs_tmp):\n    return posixpath.join(dfs_tmp, str(uuid.uuid4()))\n\n\ndef join_paths(*paths: str) -> str:\n    stripped = (p.strip(\"/\") for p in paths)\n    return \"/\" + posixpath.normpath(posixpath.join(*stripped))\n\n\n_OS_ALT_SEPS = [sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"]\n\n\ndef validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    exc = MlflowException(f\"Invalid path: {path}\", error_code=INVALID_PARAMETER_VALUE)\n    if any((s in path) for s in (\"#\", \"%23\")):\n        raise exc\n\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise exc\n", "import json\nimport uuid\nfrom unittest import mock\n\nimport pytest\n\nimport mlflow\nfrom mlflow.entities import ViewType\nfrom mlflow.entities.model_registry import (\n    ModelVersion,\n    ModelVersionTag,\n    RegisteredModel,\n    RegisteredModelTag,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import INTERNAL_ERROR, INVALID_PARAMETER_VALUE, ErrorCode\nfrom mlflow.protos.model_registry_pb2 import (\n    CreateModelVersion,\n    CreateRegisteredModel,\n    DeleteModelVersion,\n    DeleteModelVersionTag,\n    DeleteRegisteredModel,\n    DeleteRegisteredModelAlias,\n    DeleteRegisteredModelTag,\n    GetLatestVersions,\n    GetModelVersion,\n    GetModelVersionByAlias,\n    GetModelVersionDownloadUri,\n    GetRegisteredModel,\n    RenameRegisteredModel,\n    SearchModelVersions,\n    SearchRegisteredModels,\n    SetModelVersionTag,\n    SetRegisteredModelAlias,\n    SetRegisteredModelTag,\n    TransitionModelVersionStage,\n    UpdateModelVersion,\n    UpdateRegisteredModel,\n)\nfrom mlflow.protos.service_pb2 import CreateExperiment, SearchRuns\nfrom mlflow.server import BACKEND_STORE_URI_ENV_VAR, app\nfrom mlflow.server.handlers import (\n    _create_experiment,\n    _create_model_version,\n    _create_registered_model,\n    _delete_model_version,\n    _delete_model_version_tag,\n    _delete_registered_model,\n    _delete_registered_model_alias,\n    _delete_registered_model_tag,\n    _get_latest_versions,\n    _get_model_version,\n    _get_model_version_by_alias,\n    _get_model_version_download_uri,\n    _get_registered_model,\n    _get_request_message,\n    _log_batch,\n    _rename_registered_model,\n    _search_model_versions,\n    _search_registered_models,\n    _search_runs,\n    _set_model_version_tag,\n    _set_registered_model_alias,\n    _set_registered_model_tag,\n    _transition_stage,\n    _update_model_version,\n    _update_registered_model,\n    catch_mlflow_exception,\n    get_endpoints,\n)\nfrom mlflow.store.entities.paged_list import PagedList\nfrom mlflow.store.model_registry import (\n    SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,\n    SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,\n)\nfrom mlflow.utils.proto_json_utils import message_to_json\nfrom mlflow.utils.validation import MAX_BATCH_LOG_REQUEST_SIZE\n\n\n@pytest.fixture\ndef mock_get_request_message():\n    with mock.patch(\"mlflow.server.handlers._get_request_message\") as m:\n        yield m\n\n\n@pytest.fixture\ndef mock_get_request_json():\n    with mock.patch(\"mlflow.server.handlers._get_request_json\") as m:\n        yield m\n\n\n@pytest.fixture\ndef mock_tracking_store():\n    with mock.patch(\"mlflow.server.handlers._get_tracking_store\") as m:\n        mock_store = mock.MagicMock()\n        m.return_value = mock_store\n        yield mock_store\n\n\n@pytest.fixture\ndef mock_model_registry_store():\n    with mock.patch(\"mlflow.server.handlers._get_model_registry_store\") as m:\n        mock_store = mock.MagicMock()\n        m.return_value = mock_store\n        yield mock_store\n\n\ndef test_health():\n    with app.test_client() as c:\n        response = c.get(\"/health\")\n        assert response.status_code == 200\n        assert response.get_data().decode() == \"OK\"\n\n\ndef test_version():\n    with app.test_client() as c:\n        response = c.get(\"/version\")\n        assert response.status_code == 200\n        assert response.get_data().decode() == mlflow.__version__\n\n\ndef test_get_endpoints():\n    endpoints = get_endpoints()\n    create_experiment_endpoint = [e for e in endpoints if e[1] == _create_experiment]\n    assert len(create_experiment_endpoint) == 2\n\n\ndef test_all_model_registry_endpoints_available():\n    endpoints = {handler: method for (path, handler, method) in get_endpoints()}\n\n    # Test that each of the handler is enabled as an endpoint with appropriate method.\n    expected_endpoints = {\n        \"POST\": [\n            _create_registered_model,\n            _create_model_version,\n            _rename_registered_model,\n            _transition_stage,\n        ],\n        \"PATCH\": [_update_registered_model, _update_model_version],\n        \"DELETE\": [_delete_registered_model, _delete_registered_model],\n        \"GET\": [\n            _search_model_versions,\n            _get_latest_versions,\n            _get_registered_model,\n            _get_model_version,\n            _get_model_version_download_uri,\n        ],\n    }\n    # TODO: efficient mechanism to test endpoint path\n    for method, handlers in expected_endpoints.items():\n        for handler in handlers:\n            assert handler in endpoints\n            assert endpoints[handler] == [method]\n\n\ndef test_can_parse_json():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"application/json\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\"}\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello\"\n\n\ndef test_can_parse_post_json_with_unknown_fields():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"application/json\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\", \"WHAT IS THIS FIELD EVEN\": \"DOING\"}\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello\"\n\n\ndef test_can_parse_post_json_with_content_type_params():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"application/json; charset=utf-8\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\"}\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello\"\n\n\ndef test_can_parse_get_json_with_unknown_fields():\n    request = mock.MagicMock()\n    request.method = \"GET\"\n    request.query_string = b\"name=hello&superDuperUnknown=field\"\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello\"\n\n\n# Previous versions of the client sent a doubly string encoded JSON blob,\n# so this test ensures continued compliance with such clients.\ndef test_can_parse_json_string():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"application/json\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = '{\"name\": \"hello2\"}'\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello2\"\n\n\ndef test_can_block_post_request_with_invalid_content_type():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"text/plain\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\"}\n    with pytest.raises(MlflowException, match=r\"Bad Request. Content-Type\"):\n        _get_request_message(CreateExperiment(), flask_request=request)\n\n\ndef test_can_block_post_request_with_missing_content_type():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = None\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\"}\n    with pytest.raises(MlflowException, match=r\"Bad Request. Content-Type\"):\n        _get_request_message(CreateExperiment(), flask_request=request)\n\n\ndef test_search_runs_default_view_type(mock_get_request_message, mock_tracking_store):\n    \"\"\"\n    Search Runs default view type is filled in as ViewType.ACTIVE_ONLY\n    \"\"\"\n    mock_get_request_message.return_value = SearchRuns(experiment_ids=[\"0\"])\n    mock_tracking_store.search_runs.return_value = PagedList([], None)\n    _search_runs()\n    args, _ = mock_tracking_store.search_runs.call_args\n    assert args[2] == ViewType.ACTIVE_ONLY\n\n\ndef test_log_batch_api_req(mock_get_request_json):\n    mock_get_request_json.return_value = \"a\" * (MAX_BATCH_LOG_REQUEST_SIZE + 1)\n    response = _log_batch()\n    assert response.status_code == 400\n    json_response = json.loads(response.get_data())\n    assert json_response[\"error_code\"] == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    assert (\n        f\"Batched logging API requests must be at most {MAX_BATCH_LOG_REQUEST_SIZE} bytes\"\n        in json_response[\"message\"]\n    )\n\n\ndef test_catch_mlflow_exception():\n    @catch_mlflow_exception\n    def test_handler():\n        raise MlflowException(\"test error\", error_code=INTERNAL_ERROR)\n\n    # pylint: disable=assignment-from-no-return\n    response = test_handler()\n    json_response = json.loads(response.get_data())\n    assert response.status_code == 500\n    assert json_response[\"error_code\"] == ErrorCode.Name(INTERNAL_ERROR)\n    assert json_response[\"message\"] == \"test error\"\n\n\ndef test_mlflow_server_with_installed_plugin(tmp_path, monkeypatch):\n    \"\"\"This test requires the package in tests/resources/mlflow-test-plugin to be installed\"\"\"\n    from mlflow_test_plugin.file_store import PluginFileStore\n\n    monkeypatch.setenv(BACKEND_STORE_URI_ENV_VAR, f\"file-plugin:{tmp_path}\")\n    monkeypatch.setattr(mlflow.server.handlers, \"_tracking_store\", None)\n    plugin_file_store = mlflow.server.handlers._get_tracking_store()\n    assert isinstance(plugin_file_store, PluginFileStore)\n    assert plugin_file_store.is_plugin\n\n\ndef jsonify(obj):\n    def _jsonify(obj):\n        return json.loads(message_to_json(obj.to_proto()))\n\n    if isinstance(obj, list):\n        return [_jsonify(o) for o in obj]\n    else:\n        return _jsonify(obj)\n\n\n# Tests for Model Registry handlers\ndef test_create_registered_model(mock_get_request_message, mock_model_registry_store):\n    tags = [\n        RegisteredModelTag(key=\"key\", value=\"value\"),\n        RegisteredModelTag(key=\"anotherKey\", value=\"some other value\"),\n    ]\n    mock_get_request_message.return_value = CreateRegisteredModel(\n        name=\"model_1\", tags=[tag.to_proto() for tag in tags]\n    )\n    rm = RegisteredModel(\"model_1\", tags=tags)\n    mock_model_registry_store.create_registered_model.return_value = rm\n    resp = _create_registered_model()\n    _, args = mock_model_registry_store.create_registered_model.call_args\n    assert args[\"name\"] == \"model_1\"\n    assert {tag.key: tag.value for tag in args[\"tags\"]} == {tag.key: tag.value for tag in tags}\n    assert json.loads(resp.get_data()) == {\"registered_model\": jsonify(rm)}\n\n\ndef test_get_registered_model(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    mock_get_request_message.return_value = GetRegisteredModel(name=name)\n    rmd = RegisteredModel(\n        name=name,\n        creation_timestamp=111,\n        last_updated_timestamp=222,\n        description=\"Test model\",\n        latest_versions=[],\n    )\n    mock_model_registry_store.get_registered_model.return_value = rmd\n    resp = _get_registered_model()\n    _, args = mock_model_registry_store.get_registered_model.call_args\n    assert args == {\"name\": name}\n    assert json.loads(resp.get_data()) == {\"registered_model\": jsonify(rmd)}\n\n\ndef test_update_registered_model(mock_get_request_message, mock_model_registry_store):\n    name = \"model_1\"\n    description = \"Test model\"\n    mock_get_request_message.return_value = UpdateRegisteredModel(\n        name=name, description=description\n    )\n    rm2 = RegisteredModel(name, description=description)\n    mock_model_registry_store.update_registered_model.return_value = rm2\n    resp = _update_registered_model()\n    _, args = mock_model_registry_store.update_registered_model.call_args\n    assert args == {\"name\": name, \"description\": \"Test model\"}\n    assert json.loads(resp.get_data()) == {\"registered_model\": jsonify(rm2)}\n\n\ndef test_rename_registered_model(mock_get_request_message, mock_model_registry_store):\n    name = \"model_1\"\n    new_name = \"model_2\"\n    mock_get_request_message.return_value = RenameRegisteredModel(name=name, new_name=new_name)\n    rm2 = RegisteredModel(new_name)\n    mock_model_registry_store.rename_registered_model.return_value = rm2\n    resp = _rename_registered_model()\n    _, args = mock_model_registry_store.rename_registered_model.call_args\n    assert args == {\"name\": name, \"new_name\": new_name}\n    assert json.loads(resp.get_data()) == {\"registered_model\": jsonify(rm2)}\n\n\ndef test_delete_registered_model(mock_get_request_message, mock_model_registry_store):\n    name = \"model_1\"\n    mock_get_request_message.return_value = DeleteRegisteredModel(name=name)\n    _delete_registered_model()\n    _, args = mock_model_registry_store.delete_registered_model.call_args\n    assert args == {\"name\": name}\n\n\ndef test_search_registered_models(mock_get_request_message, mock_model_registry_store):\n    rmds = [\n        RegisteredModel(\n            name=\"model_1\",\n            creation_timestamp=111,\n            last_updated_timestamp=222,\n            description=\"Test model\",\n            latest_versions=[],\n        ),\n        RegisteredModel(\n            name=\"model_2\",\n            creation_timestamp=111,\n            last_updated_timestamp=333,\n            description=\"Another model\",\n            latest_versions=[],\n        ),\n    ]\n    mock_get_request_message.return_value = SearchRegisteredModels()\n    mock_model_registry_store.search_registered_models.return_value = PagedList(rmds, None)\n    resp = _search_registered_models()\n    _, args = mock_model_registry_store.search_registered_models.call_args\n    assert args == {\n        \"filter_string\": \"\",\n        \"max_results\": SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,\n        \"order_by\": [],\n        \"page_token\": \"\",\n    }\n    assert json.loads(resp.get_data()) == {\"registered_models\": jsonify(rmds)}\n\n    mock_get_request_message.return_value = SearchRegisteredModels(filter=\"hello\")\n    mock_model_registry_store.search_registered_models.return_value = PagedList(rmds[:1], \"tok\")\n    resp = _search_registered_models()\n    _, args = mock_model_registry_store.search_registered_models.call_args\n    assert args == {\n        \"filter_string\": \"hello\",\n        \"max_results\": SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,\n        \"order_by\": [],\n        \"page_token\": \"\",\n    }\n    assert json.loads(resp.get_data()) == {\n        \"registered_models\": jsonify(rmds[:1]),\n        \"next_page_token\": \"tok\",\n    }\n\n    mock_get_request_message.return_value = SearchRegisteredModels(filter=\"hi\", max_results=5)\n    mock_model_registry_store.search_registered_models.return_value = PagedList([rmds[0]], \"tik\")\n    resp = _search_registered_models()\n    _, args = mock_model_registry_store.search_registered_models.call_args\n    assert args == {\"filter_string\": \"hi\", \"max_results\": 5, \"order_by\": [], \"page_token\": \"\"}\n    assert json.loads(resp.get_data()) == {\n        \"registered_models\": jsonify([rmds[0]]),\n        \"next_page_token\": \"tik\",\n    }\n\n    mock_get_request_message.return_value = SearchRegisteredModels(\n        filter=\"hey\", max_results=500, order_by=[\"a\", \"B desc\"], page_token=\"prev\"\n    )\n    mock_model_registry_store.search_registered_models.return_value = PagedList(rmds, \"DONE\")\n    resp = _search_registered_models()\n    _, args = mock_model_registry_store.search_registered_models.call_args\n    assert args == {\n        \"filter_string\": \"hey\",\n        \"max_results\": 500,\n        \"order_by\": [\"a\", \"B desc\"],\n        \"page_token\": \"prev\",\n    }\n    assert json.loads(resp.get_data()) == {\n        \"registered_models\": jsonify(rmds),\n        \"next_page_token\": \"DONE\",\n    }\n\n\ndef test_get_latest_versions(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    mock_get_request_message.return_value = GetLatestVersions(name=name)\n    mvds = [\n        ModelVersion(\n            name=name,\n            version=\"5\",\n            creation_timestamp=1,\n            last_updated_timestamp=12,\n            description=\"v 5\",\n            user_id=\"u1\",\n            current_stage=\"Production\",\n            source=\"A/B\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=name,\n            version=\"1\",\n            creation_timestamp=1,\n            last_updated_timestamp=1200,\n            description=\"v 1\",\n            user_id=\"u1\",\n            current_stage=\"Archived\",\n            source=\"A/B2\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=name,\n            version=\"12\",\n            creation_timestamp=100,\n            last_updated_timestamp=None,\n            description=\"v 12\",\n            user_id=\"u2\",\n            current_stage=\"Staging\",\n            source=\"A/B3\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n    ]\n    mock_model_registry_store.get_latest_versions.return_value = mvds\n    resp = _get_latest_versions()\n    _, args = mock_model_registry_store.get_latest_versions.call_args\n    assert args == {\"name\": name, \"stages\": []}\n    assert json.loads(resp.get_data()) == {\"model_versions\": jsonify(mvds)}\n\n    for stages in [[], [\"None\"], [\"Staging\"], [\"Staging\", \"Production\"]]:\n        mock_get_request_message.return_value = GetLatestVersions(name=name, stages=stages)\n        _get_latest_versions()\n        _, args = mock_model_registry_store.get_latest_versions.call_args\n        assert args == {\"name\": name, \"stages\": stages}\n\n\ndef test_create_model_version(mock_get_request_message, mock_model_registry_store):\n    run_id = uuid.uuid4().hex\n    tags = [\n        ModelVersionTag(key=\"key\", value=\"value\"),\n        ModelVersionTag(key=\"anotherKey\", value=\"some other value\"),\n    ]\n    run_link = \"localhost:5000/path/to/run\"\n    mock_get_request_message.return_value = CreateModelVersion(\n        name=\"model_1\",\n        source=f\"runs:/{run_id}\",\n        run_id=run_id,\n        run_link=run_link,\n        tags=[tag.to_proto() for tag in tags],\n    )\n    mv = ModelVersion(\n        name=\"model_1\", version=\"12\", creation_timestamp=123, tags=tags, run_link=run_link\n    )\n    mock_model_registry_store.create_model_version.return_value = mv\n    resp = _create_model_version()\n    _, args = mock_model_registry_store.create_model_version.call_args\n    assert args[\"name\"] == \"model_1\"\n    assert args[\"source\"] == f\"runs:/{run_id}\"\n    assert args[\"run_id\"] == run_id\n    assert {tag.key: tag.value for tag in args[\"tags\"]} == {tag.key: tag.value for tag in tags}\n    assert args[\"run_link\"] == run_link\n    assert json.loads(resp.get_data()) == {\"model_version\": jsonify(mv)}\n\n\ndef test_set_registered_model_tag(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    tag = RegisteredModelTag(key=\"some weird key\", value=\"some value\")\n    mock_get_request_message.return_value = SetRegisteredModelTag(\n        name=name, key=tag.key, value=tag.value\n    )\n    _set_registered_model_tag()\n    _, args = mock_model_registry_store.set_registered_model_tag.call_args\n    assert args == {\"name\": name, \"tag\": tag}\n\n\ndef test_delete_registered_model_tag(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    key = \"some weird key\"\n    mock_get_request_message.return_value = DeleteRegisteredModelTag(name=name, key=key)\n    _delete_registered_model_tag()\n    _, args = mock_model_registry_store.delete_registered_model_tag.call_args\n    assert args == {\"name\": name, \"key\": key}\n\n\ndef test_get_model_version_details(mock_get_request_message, mock_model_registry_store):\n    mock_get_request_message.return_value = GetModelVersion(name=\"model1\", version=\"32\")\n    mvd = ModelVersion(\n        name=\"model1\",\n        version=\"5\",\n        creation_timestamp=1,\n        last_updated_timestamp=12,\n        description=\"v 5\",\n        user_id=\"u1\",\n        current_stage=\"Production\",\n        source=\"A/B\",\n        run_id=uuid.uuid4().hex,\n        status=\"READY\",\n        status_message=None,\n    )\n    mock_model_registry_store.get_model_version.return_value = mvd\n    resp = _get_model_version()\n    _, args = mock_model_registry_store.get_model_version.call_args\n    assert args == {\"name\": \"model1\", \"version\": \"32\"}\n    assert json.loads(resp.get_data()) == {\"model_version\": jsonify(mvd)}\n\n\ndef test_update_model_version(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"32\"\n    description = \"Great model!\"\n    mock_get_request_message.return_value = UpdateModelVersion(\n        name=name, version=version, description=description\n    )\n\n    mv = ModelVersion(name=name, version=version, creation_timestamp=123, description=description)\n    mock_model_registry_store.update_model_version.return_value = mv\n    _update_model_version()\n    _, args = mock_model_registry_store.update_model_version.call_args\n    assert args == {\"name\": name, \"version\": version, \"description\": description}\n\n\ndef test_transition_model_version_stage(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"32\"\n    stage = \"Production\"\n    mock_get_request_message.return_value = TransitionModelVersionStage(\n        name=name, version=version, stage=stage\n    )\n    mv = ModelVersion(name=name, version=version, creation_timestamp=123, current_stage=stage)\n    mock_model_registry_store.transition_model_version_stage.return_value = mv\n    _transition_stage()\n    _, args = mock_model_registry_store.transition_model_version_stage.call_args\n    assert args == {\n        \"name\": name,\n        \"version\": version,\n        \"stage\": stage,\n        \"archive_existing_versions\": False,\n    }\n\n\ndef test_delete_model_version(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"32\"\n    mock_get_request_message.return_value = DeleteModelVersion(name=name, version=version)\n    _delete_model_version()\n    _, args = mock_model_registry_store.delete_model_version.call_args\n    assert args == {\"name\": name, \"version\": version}\n\n\ndef test_get_model_version_download_uri(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"32\"\n    mock_get_request_message.return_value = GetModelVersionDownloadUri(name=name, version=version)\n    mock_model_registry_store.get_model_version_download_uri.return_value = \"some/download/path\"\n    resp = _get_model_version_download_uri()\n    _, args = mock_model_registry_store.get_model_version_download_uri.call_args\n    assert args == {\"name\": name, \"version\": version}\n    assert json.loads(resp.get_data()) == {\"artifact_uri\": \"some/download/path\"}\n\n\ndef test_search_model_versions(mock_get_request_message, mock_model_registry_store):\n    mvds = [\n        ModelVersion(\n            name=\"model_1\",\n            version=\"5\",\n            creation_timestamp=100,\n            last_updated_timestamp=3200,\n            description=\"v 5\",\n            user_id=\"u1\",\n            current_stage=\"Production\",\n            source=\"A/B/CD\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=\"model_1\",\n            version=\"12\",\n            creation_timestamp=110,\n            last_updated_timestamp=2000,\n            description=\"v 12\",\n            user_id=\"u2\",\n            current_stage=\"Production\",\n            source=\"A/B/CD\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=\"ads_model\",\n            version=\"8\",\n            creation_timestamp=200,\n            last_updated_timestamp=1000,\n            description=\"v 8\",\n            user_id=\"u1\",\n            current_stage=\"Staging\",\n            source=\"A/B/CD\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=\"fraud_detection_model\",\n            version=\"345\",\n            creation_timestamp=1000,\n            last_updated_timestamp=999,\n            description=\"newest version\",\n            user_id=\"u12\",\n            current_stage=\"None\",\n            source=\"A/B/CD\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n    ]\n    mock_get_request_message.return_value = SearchModelVersions(filter=\"source_path = 'A/B/CD'\")\n    mock_model_registry_store.search_model_versions.return_value = PagedList(mvds, None)\n    resp = _search_model_versions()\n    mock_model_registry_store.search_model_versions.assert_called_with(\n        filter_string=\"source_path = 'A/B/CD'\",\n        max_results=SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,\n        order_by=[],\n        page_token=\"\",\n    )\n    assert json.loads(resp.get_data()) == {\"model_versions\": jsonify(mvds)}\n\n    mock_get_request_message.return_value = SearchModelVersions(filter=\"name='model_1'\")\n    mock_model_registry_store.search_model_versions.return_value = PagedList(mvds[:1], \"tok\")\n    resp = _search_model_versions()\n    mock_model_registry_store.search_model_versions.assert_called_with(\n        filter_string=\"name='model_1'\",\n        max_results=SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,\n        order_by=[],\n        page_token=\"\",\n    )\n    assert json.loads(resp.get_data()) == {\n        \"model_versions\": jsonify(mvds[:1]),\n        \"next_page_token\": \"tok\",\n    }\n\n    mock_get_request_message.return_value = SearchModelVersions(filter=\"version<=12\", max_results=2)\n    mock_model_registry_store.search_model_versions.return_value = PagedList(\n        [mvds[0], mvds[2]], \"next\"\n    )\n    resp = _search_model_versions()\n    mock_model_registry_store.search_model_versions.assert_called_with(\n        filter_string=\"version<=12\", max_results=2, order_by=[], page_token=\"\"\n    )\n    assert json.loads(resp.get_data()) == {\n        \"model_versions\": jsonify([mvds[0], mvds[2]]),\n        \"next_page_token\": \"next\",\n    }\n\n    mock_get_request_message.return_value = SearchModelVersions(\n        filter=\"version<=12\", max_results=2, order_by=[\"version DESC\"], page_token=\"prev\"\n    )\n    mock_model_registry_store.search_model_versions.return_value = PagedList(mvds[1:3], \"next\")\n    resp = _search_model_versions()\n    mock_model_registry_store.search_model_versions.assert_called_with(\n        filter_string=\"version<=12\", max_results=2, order_by=[\"version DESC\"], page_token=\"prev\"\n    )\n    assert json.loads(resp.get_data()) == {\n        \"model_versions\": jsonify(mvds[1:3]),\n        \"next_page_token\": \"next\",\n    }\n\n\ndef test_set_model_version_tag(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"1\"\n    tag = ModelVersionTag(key=\"some weird key\", value=\"some value\")\n    mock_get_request_message.return_value = SetModelVersionTag(\n        name=name, version=version, key=tag.key, value=tag.value\n    )\n    _set_model_version_tag()\n    _, args = mock_model_registry_store.set_model_version_tag.call_args\n    assert args == {\"name\": name, \"version\": version, \"tag\": tag}\n\n\ndef test_delete_model_version_tag(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"1\"\n    key = \"some weird key\"\n    mock_get_request_message.return_value = DeleteModelVersionTag(\n        name=name, version=version, key=key\n    )\n    _delete_model_version_tag()\n    _, args = mock_model_registry_store.delete_model_version_tag.call_args\n    assert args == {\"name\": name, \"version\": version, \"key\": key}\n\n\ndef test_set_registered_model_alias(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    alias = \"test_alias\"\n    version = \"1\"\n    mock_get_request_message.return_value = SetRegisteredModelAlias(\n        name=name, alias=alias, version=version\n    )\n    _set_registered_model_alias()\n    _, args = mock_model_registry_store.set_registered_model_alias.call_args\n    assert args == {\"name\": name, \"alias\": alias, \"version\": version}\n\n\ndef test_delete_registered_model_alias(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    alias = \"test_alias\"\n    mock_get_request_message.return_value = DeleteRegisteredModelAlias(name=name, alias=alias)\n    _delete_registered_model_alias()\n    _, args = mock_model_registry_store.delete_registered_model_alias.call_args\n    assert args == {\"name\": name, \"alias\": alias}\n\n\ndef test_get_model_version_by_alias(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    alias = \"test_alias\"\n    mock_get_request_message.return_value = GetModelVersionByAlias(name=name, alias=alias)\n    mvd = ModelVersion(\n        name=\"model1\",\n        version=\"5\",\n        creation_timestamp=1,\n        last_updated_timestamp=12,\n        description=\"v 5\",\n        user_id=\"u1\",\n        current_stage=\"Production\",\n        source=\"A/B\",\n        run_id=uuid.uuid4().hex,\n        status=\"READY\",\n        status_message=None,\n        aliases=[\"test_alias\"],\n    )\n    mock_model_registry_store.get_model_version_by_alias.return_value = mvd\n    resp = _get_model_version_by_alias()\n    _, args = mock_model_registry_store.get_model_version_by_alias.call_args\n    assert args == {\"name\": name, \"alias\": alias}\n    assert json.loads(resp.get_data()) == {\"model_version\": jsonify(mvd)}\n", "import os\nimport posixpath\nfrom unittest import mock\n\nimport pytest\nfrom requests import HTTPError\n\nfrom mlflow.entities.multipart_upload import (\n    CreateMultipartUploadResponse,\n    MultipartUploadCredential,\n    MultipartUploadPart,\n)\nfrom mlflow.environment_variables import (\n    MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE,\n    MLFLOW_TRACKING_CLIENT_CERT_PATH,\n    MLFLOW_TRACKING_INSECURE_TLS,\n    MLFLOW_TRACKING_PASSWORD,\n    MLFLOW_TRACKING_SERVER_CERT_PATH,\n    MLFLOW_TRACKING_TOKEN,\n    MLFLOW_TRACKING_USERNAME,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.store.artifact.artifact_repository_registry import get_artifact_repository\nfrom mlflow.store.artifact.http_artifact_repo import HttpArtifactRepository\nfrom mlflow.tracking._tracking_service.utils import _get_default_host_creds\nfrom mlflow.utils.rest_utils import MlflowHostCreds\n\n\n@pytest.mark.parametrize(\"scheme\", [\"http\", \"https\"])\ndef test_artifact_uri_factory(scheme):\n    repo = get_artifact_repository(f\"{scheme}://test.com\")\n    assert isinstance(repo, HttpArtifactRepository)\n\n\nclass MockResponse:\n    def __init__(self, data, status_code):\n        self.data = data\n        self.status_code = status_code\n\n    def json(self):\n        return self.data\n\n    def raise_for_status(self):\n        if self.status_code >= 400:\n            raise Exception(\"request failed\")\n\n\nclass MockStreamResponse(MockResponse):\n    def iter_content(self, chunk_size):  # pylint: disable=unused-argument\n        yield self.data.encode(\"utf-8\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc):\n        pass\n\n\nclass FileObjectMatcher:\n    def __init__(self, name, mode):\n        self.name = name\n        self.mode = mode\n\n    def __eq__(self, other):\n        return self.name == other.name and self.mode == other.mode\n\n\n@pytest.fixture\ndef http_artifact_repo():\n    artifact_uri = \"http://test.com/api/2.0/mlflow-artifacts/artifacts\"\n    return HttpArtifactRepository(artifact_uri)\n\n\n@pytest.mark.parametrize(\n    (\"filename\", \"expected_mime_type\"),\n    [\n        (\"c.txt\", \"text/plain\"),\n        (\"c.pkl\", \"application/octet-stream\"),\n        (\"MLmodel\", \"text/plain\"),\n    ],\n)\n@pytest.mark.parametrize(\"artifact_path\", [None, \"dir\"])\ndef test_log_artifact(\n    http_artifact_repo,\n    tmp_path,\n    artifact_path,\n    filename,\n    expected_mime_type,\n    monkeypatch,\n):\n    file_path = tmp_path.joinpath(filename)\n    file_path.write_text(\"0\")\n\n    def assert_called_log_artifact(mock_http_request):\n        paths = (artifact_path, file_path.name) if artifact_path else (file_path.name,)\n        mock_http_request.assert_called_once_with(\n            http_artifact_repo._host_creds,\n            posixpath.join(\"/\", *paths),\n            \"PUT\",\n            data=FileObjectMatcher(str(file_path), \"rb\"),\n            extra_headers={\"Content-Type\": expected_mime_type},\n        )\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_put:\n        http_artifact_repo.log_artifact(file_path, artifact_path)\n        assert_called_log_artifact(mock_put)\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 400),\n    ):\n        with pytest.raises(Exception, match=\"request failed\"):\n            http_artifact_repo.log_artifact(file_path, artifact_path)\n\n    monkeypatch.setenv(\"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", \"true\")\n    # assert mpu is triggered when file size is larger than minimum file size\n    file_path.write_text(\"0\" * MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE.get())\n    with mock.patch.object(\n        http_artifact_repo, \"_try_multipart_upload\", return_value=200\n    ) as mock_mpu:\n        http_artifact_repo.log_artifact(file_path, artifact_path)\n        mock_mpu.assert_called_once()\n\n    # assert reverted to normal upload when mpu is not supported\n    # mock that create_multipart_upload will returns a 400 error with appropriate message\n    with mock.patch.object(\n        http_artifact_repo,\n        \"create_multipart_upload\",\n        side_effect=HTTPError(\n            response=MockResponse(\n                data={\n                    \"message\": \"Multipart upload is not supported for the current \"\n                    \"artifact repository\"\n                },\n                status_code=501,\n            )\n        ),\n    ), mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_put:\n        http_artifact_repo.log_artifact(file_path, artifact_path)\n        assert_called_log_artifact(mock_put)\n\n    # assert if mpu is triggered but the uploads failed, mpu is aborted and exception is raised\n    with mock.patch(\"requests.put\", side_effect=Exception(\"MPU_UPLOAD_FAILS\")), mock.patch.object(\n        http_artifact_repo,\n        \"create_multipart_upload\",\n        return_value=CreateMultipartUploadResponse(\n            upload_id=\"upload_id\",\n            credentials=[MultipartUploadCredential(url=\"url\", part_number=1, headers={})],\n        ),\n    ), mock.patch.object(\n        http_artifact_repo,\n        \"abort_multipart_upload\",\n        return_value=None,\n    ) as mock_abort:\n        with pytest.raises(Exception, match=\"MPU_UPLOAD_FAILS\"):\n            http_artifact_repo.log_artifact(file_path, artifact_path)\n        mock_abort.assert_called_once()\n\n\n@pytest.mark.parametrize(\"artifact_path\", [None, \"dir\"])\ndef test_log_artifacts(http_artifact_repo, tmp_path, artifact_path):\n    tmp_path_a = tmp_path.joinpath(\"a.txt\")\n    d = tmp_path.joinpath(\"dir\")\n    d.mkdir()\n    tmp_path_b = d.joinpath(\"b.txt\")\n    tmp_path_a.write_text(\"0\")\n    tmp_path_b.write_text(\"1\")\n\n    with mock.patch.object(http_artifact_repo, \"log_artifact\") as mock_log_artifact:\n        http_artifact_repo.log_artifacts(tmp_path, artifact_path)\n        mock_log_artifact.assert_has_calls(\n            [\n                mock.call(str(tmp_path_a), artifact_path),\n                mock.call(\n                    str(tmp_path_b),\n                    posixpath.join(artifact_path, \"dir\") if artifact_path else \"dir\",\n                ),\n            ],\n        )\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 400),\n    ):\n        with pytest.raises(Exception, match=\"request failed\"):\n            http_artifact_repo.log_artifacts(tmp_path, artifact_path)\n\n\ndef test_list_artifacts(http_artifact_repo):\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_get:\n        assert http_artifact_repo.list_artifacts() == []\n        endpoint = \"/mlflow-artifacts/artifacts\"\n        url, _ = http_artifact_repo.artifact_uri.split(endpoint, maxsplit=1)\n        mock_get.assert_called_once_with(\n            _get_default_host_creds(url),\n            endpoint,\n            \"GET\",\n            params={\"path\": \"\"},\n        )\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse(\n            {\n                \"files\": [\n                    {\"path\": \"1.txt\", \"is_dir\": False, \"file_size\": 1},\n                    {\"path\": \"dir\", \"is_dir\": True},\n                ]\n            },\n            200,\n        ),\n    ):\n        assert [a.path for a in http_artifact_repo.list_artifacts()] == [\"1.txt\", \"dir\"]\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse(\n            {\n                \"files\": [\n                    {\"path\": \"1.txt\", \"is_dir\": False, \"file_size\": 1},\n                    {\"path\": \"dir\", \"is_dir\": True},\n                ]\n            },\n            200,\n        ),\n    ):\n        assert [a.path for a in http_artifact_repo.list_artifacts(path=\"path\")] == [\n            \"path/1.txt\",\n            \"path/dir\",\n        ]\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 400),\n    ):\n        with pytest.raises(Exception, match=\"request failed\"):\n            http_artifact_repo.list_artifacts()\n\n\n@pytest.mark.parametrize(\"path\", [\"/tmp/path\", \"../../path\"])\ndef test_list_artifacts_malicious_path(http_artifact_repo, path):\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse(\n            {\n                \"files\": [\n                    {\"path\": path, \"is_dir\": False, \"file_size\": 1},\n                ]\n            },\n            200,\n        ),\n    ):\n        with pytest.raises(MlflowException, match=f\"Invalid path: {path}\"):\n            http_artifact_repo.list_artifacts()\n\n\ndef read_file(path):\n    with open(path) as f:\n        return f.read()\n\n\n@pytest.mark.parametrize(\"remote_file_path\", [\"a.txt\", \"dir/b.xtx\"])\ndef test_download_file(http_artifact_repo, tmp_path, remote_file_path):\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockStreamResponse(\"data\", 200),\n    ) as mock_get:\n        file_path = tmp_path.joinpath(posixpath.basename(remote_file_path))\n        http_artifact_repo._download_file(remote_file_path, file_path)\n        mock_get.assert_called_once_with(\n            http_artifact_repo._host_creds,\n            posixpath.join(\"/\", remote_file_path),\n            \"GET\",\n            stream=True,\n        )\n        assert file_path.read_text() == \"data\"\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockStreamResponse(\"data\", 400),\n    ):\n        with pytest.raises(Exception, match=\"request failed\"):\n            http_artifact_repo._download_file(remote_file_path, tmp_path)\n\n\ndef test_download_artifacts(http_artifact_repo, tmp_path):\n    # This test simulates downloading artifacts in the following structure:\n    # ---------\n    # - a.txt\n    # - dir\n    #   - b.txt\n    # ---------\n    def http_request(_host_creds, endpoint, _method, **kwargs):\n        # Responses for list_artifacts\n        params = kwargs.get(\"params\")\n        if params:\n            if params.get(\"path\") == \"\":\n                return MockResponse(\n                    {\n                        \"files\": [\n                            {\"path\": \"a.txt\", \"is_dir\": False, \"file_size\": 1},\n                            {\"path\": \"dir\", \"is_dir\": True},\n                        ]\n                    },\n                    200,\n                )\n            elif params.get(\"path\") == \"dir\":\n                return MockResponse(\n                    {\n                        \"files\": [\n                            {\"path\": \"b.txt\", \"is_dir\": False, \"file_size\": 1},\n                        ]\n                    },\n                    200,\n                )\n            else:\n                Exception(\"Unreachable\")\n\n        # Responses for _download_file\n        if endpoint == \"/a.txt\":\n            return MockStreamResponse(\"data_a\", 200)\n        elif endpoint == \"/dir/b.txt\":\n            return MockStreamResponse(\"data_b\", 200)\n        else:\n            raise Exception(\"Unreachable\")\n\n    with mock.patch(\"mlflow.store.artifact.http_artifact_repo.http_request\", http_request):\n        http_artifact_repo.download_artifacts(\"\", tmp_path)\n        paths = [os.path.join(root, f) for root, _, files in os.walk(tmp_path) for f in files]\n        assert [os.path.relpath(p, tmp_path) for p in paths] == [\n            \"a.txt\",\n            os.path.join(\"dir\", \"b.txt\"),\n        ]\n        assert read_file(paths[0]) == \"data_a\"\n        assert read_file(paths[1]) == \"data_b\"\n\n\ndef test_default_host_creds(monkeypatch):\n    artifact_uri = \"https://test.com\"\n    username = \"user\"\n    password = \"pass\"\n    token = \"token\"\n    ignore_tls_verification = False\n    client_cert_path = \"client_cert_path\"\n    server_cert_path = \"server_cert_path\"\n\n    expected_host_creds = MlflowHostCreds(\n        host=artifact_uri,\n        username=username,\n        password=password,\n        token=token,\n        ignore_tls_verification=ignore_tls_verification,\n        client_cert_path=client_cert_path,\n        server_cert_path=server_cert_path,\n    )\n\n    repo = HttpArtifactRepository(artifact_uri)\n\n    monkeypatch.setenvs(\n        {\n            MLFLOW_TRACKING_USERNAME.name: username,\n            MLFLOW_TRACKING_PASSWORD.name: password,\n            MLFLOW_TRACKING_TOKEN.name: token,\n            MLFLOW_TRACKING_INSECURE_TLS.name: str(ignore_tls_verification),\n            MLFLOW_TRACKING_CLIENT_CERT_PATH.name: client_cert_path,\n            MLFLOW_TRACKING_SERVER_CERT_PATH.name: server_cert_path,\n        }\n    )\n    assert repo._host_creds == expected_host_creds\n\n\n@pytest.mark.parametrize(\"remote_file_path\", [\"a.txt\", \"dir/b.txt\", None])\ndef test_delete_artifacts(http_artifact_repo, remote_file_path):\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockStreamResponse(\"data\", 200),\n    ) as mock_get:\n        http_artifact_repo.delete_artifacts(remote_file_path)\n        mock_get.assert_called_once_with(\n            http_artifact_repo._host_creds,\n            posixpath.join(\"/\", remote_file_path if remote_file_path else \"\"),\n            \"DELETE\",\n            stream=True,\n        )\n\n\ndef test_create_multipart_upload(http_artifact_repo, monkeypatch):\n    monkeypatch.setenv(\"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", \"true\")\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse(\n            {\n                \"upload_id\": \"upload_id\",\n                \"credentials\": [\n                    {\n                        \"url\": \"/some/url\",\n                        \"part_number\": 1,\n                        \"headers\": {},\n                    }\n                ],\n            },\n            200,\n        ),\n    ):\n        response = http_artifact_repo.create_multipart_upload(\"\", 1)\n        assert response.upload_id == \"upload_id\"\n        assert len(response.credentials) == 1\n        assert response.credentials[0].url == \"/some/url\"\n\n\ndef test_complete_multipart_upload(http_artifact_repo, monkeypatch):\n    monkeypatch.setenv(\"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", \"true\")\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_post:\n        http_artifact_repo.complete_multipart_upload(\n            local_file=\"local_file\",\n            upload_id=\"upload_id\",\n            parts=[\n                MultipartUploadPart(part_number=1, etag=\"etag1\"),\n                MultipartUploadPart(part_number=2, etag=\"etag2\"),\n            ],\n            artifact_path=\"artifact/path\",\n        )\n        endpoint = \"/mlflow-artifacts\"\n        url, _ = http_artifact_repo.artifact_uri.split(endpoint, maxsplit=1)\n        mock_post.assert_called_once_with(\n            _get_default_host_creds(url),\n            \"/mlflow-artifacts/mpu/complete/artifact/path\",\n            \"POST\",\n            json={\n                \"path\": \"local_file\",\n                \"upload_id\": \"upload_id\",\n                \"parts\": [\n                    {\"part_number\": 1, \"etag\": \"etag1\"},\n                    {\"part_number\": 2, \"etag\": \"etag2\"},\n                ],\n            },\n        )\n\n\ndef test_abort_multipart_upload(http_artifact_repo, monkeypatch):\n    monkeypatch.setenv(\"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", \"true\")\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_post:\n        http_artifact_repo.abort_multipart_upload(\n            local_file=\"local_file\",\n            upload_id=\"upload_id\",\n            artifact_path=\"artifact/path\",\n        )\n        endpoint = \"/mlflow-artifacts\"\n        url, _ = http_artifact_repo.artifact_uri.split(endpoint, maxsplit=1)\n        mock_post.assert_called_once_with(\n            _get_default_host_creds(url),\n            \"/mlflow-artifacts/mpu/abort/artifact/path\",\n            \"POST\",\n            json={\n                \"path\": \"local_file\",\n                \"upload_id\": \"upload_id\",\n            },\n        )\n", "\"\"\"\nIntegration test which starts a local Tracking Server on an ephemeral port,\nand ensures we can use the tracking API to communicate with it.\n\"\"\"\nimport json\nimport logging\nimport math\nimport os\nimport pathlib\nimport posixpath\nimport sys\nimport time\nimport urllib.parse\nfrom unittest import mock\n\nimport flask\nimport pandas as pd\nimport pytest\nimport requests\n\nimport mlflow.experiments\nimport mlflow.pyfunc\nfrom mlflow import MlflowClient\nfrom mlflow.artifacts import download_artifacts\nfrom mlflow.data.pandas_dataset import from_pandas\nfrom mlflow.entities import (\n    Dataset,\n    DatasetInput,\n    InputTag,\n    Metric,\n    Param,\n    RunInputs,\n    RunTag,\n    ViewType,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.models import Model\nfrom mlflow.server.handlers import validate_path_is_safe\nfrom mlflow.store.tracking.sqlalchemy_store import SqlAlchemyStore\nfrom mlflow.utils import mlflow_tags\nfrom mlflow.utils.file_utils import TempDir, path_to_local_file_uri\nfrom mlflow.utils.mlflow_tags import (\n    MLFLOW_DATASET_CONTEXT,\n    MLFLOW_GIT_COMMIT,\n    MLFLOW_PARENT_RUN_ID,\n    MLFLOW_PROJECT_ENTRY_POINT,\n    MLFLOW_SOURCE_NAME,\n    MLFLOW_SOURCE_TYPE,\n    MLFLOW_USER,\n)\nfrom mlflow.utils.os import is_windows\nfrom mlflow.utils.proto_json_utils import message_to_json\nfrom mlflow.utils.time import get_current_time_millis\n\nfrom tests.integration.utils import invoke_cli_runner\nfrom tests.tracking.integration_test_utils import (\n    _init_server,\n    _send_rest_tracking_post_request,\n)\n\n_logger = logging.getLogger(__name__)\n\n\n@pytest.fixture(params=[\"file\", \"sqlalchemy\"])\ndef mlflow_client(request, tmp_path):\n    \"\"\"Provides an MLflow Tracking API client pointed at the local tracking server.\"\"\"\n    if request.param == \"file\":\n        backend_uri = tmp_path.joinpath(\"file\").as_uri()\n    elif request.param == \"sqlalchemy\":\n        path = tmp_path.joinpath(\"sqlalchemy.db\").as_uri()\n        backend_uri = (\"sqlite://\" if sys.platform == \"win32\" else \"sqlite:////\") + path[\n            len(\"file://\") :\n        ]\n\n    with _init_server(backend_uri, root_artifact_uri=tmp_path.as_uri()) as url:\n        yield MlflowClient(url)\n\n\n@pytest.fixture\ndef cli_env(mlflow_client):\n    \"\"\"Provides an environment for the MLflow CLI pointed at the local tracking server.\"\"\"\n    return {\n        \"LC_ALL\": \"en_US.UTF-8\",\n        \"LANG\": \"en_US.UTF-8\",\n        \"MLFLOW_TRACKING_URI\": mlflow_client.tracking_uri,\n    }\n\n\ndef create_experiments(client, names):\n    return [client.create_experiment(n) for n in names]\n\n\ndef test_create_get_search_experiment(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        \"My Experiment\", artifact_location=\"my_location\", tags={\"key1\": \"val1\", \"key2\": \"val2\"}\n    )\n    exp = mlflow_client.get_experiment(experiment_id)\n    assert exp.name == \"My Experiment\"\n    if is_windows():\n        assert exp.artifact_location == pathlib.Path.cwd().joinpath(\"my_location\").as_uri()\n    else:\n        assert exp.artifact_location == str(pathlib.Path.cwd().joinpath(\"my_location\"))\n    assert len(exp.tags) == 2\n    assert exp.tags[\"key1\"] == \"val1\"\n    assert exp.tags[\"key2\"] == \"val2\"\n\n    experiments = mlflow_client.search_experiments()\n    assert {e.name for e in experiments} == {\"My Experiment\", \"Default\"}\n    mlflow_client.delete_experiment(experiment_id)\n    assert {e.name for e in mlflow_client.search_experiments()} == {\"Default\"}\n    assert {e.name for e in mlflow_client.search_experiments(view_type=ViewType.ACTIVE_ONLY)} == {\n        \"Default\"\n    }\n    assert {e.name for e in mlflow_client.search_experiments(view_type=ViewType.DELETED_ONLY)} == {\n        \"My Experiment\"\n    }\n    assert {e.name for e in mlflow_client.search_experiments(view_type=ViewType.ALL)} == {\n        \"My Experiment\",\n        \"Default\",\n    }\n    active_exps_paginated = mlflow_client.search_experiments(max_results=1)\n    assert {e.name for e in active_exps_paginated} == {\"Default\"}\n    assert active_exps_paginated.token is None\n\n    all_exps_paginated = mlflow_client.search_experiments(max_results=1, view_type=ViewType.ALL)\n    first_page_names = {e.name for e in all_exps_paginated}\n    all_exps_second_page = mlflow_client.search_experiments(\n        max_results=1, view_type=ViewType.ALL, page_token=all_exps_paginated.token\n    )\n    second_page_names = {e.name for e in all_exps_second_page}\n    assert len(first_page_names) == 1\n    assert len(second_page_names) == 1\n    assert first_page_names.union(second_page_names) == {\"Default\", \"My Experiment\"}\n\n\ndef test_create_experiment_validation(mlflow_client):\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/experiments/create\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    assert_bad_request(\n        {\n            \"name\": 123,\n        },\n        \"Invalid value 123 for parameter 'name'\",\n    )\n    assert_bad_request({}, \"Missing value for required parameter 'name'\")\n    assert_bad_request(\n        {\n            \"name\": \"experiment name\",\n            \"artifact_location\": 9.0,\n            \"tags\": [{\"key\": \"key\", \"value\": \"value\"}],\n        },\n        \"Invalid value 9.0 for parameter 'artifact_location'\",\n    )\n    assert_bad_request(\n        {\n            \"name\": \"experiment name\",\n            \"artifact_location\": \"my_location\",\n            \"tags\": \"5\",\n        },\n        \"Invalid value 5 for parameter 'tags'\",\n    )\n\n\ndef test_delete_restore_experiment(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Deleterious\")\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"active\"\n    mlflow_client.delete_experiment(experiment_id)\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"deleted\"\n    mlflow_client.restore_experiment(experiment_id)\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"active\"\n\n\ndef test_delete_restore_experiment_cli(mlflow_client, cli_env):\n    experiment_name = \"DeleteriousCLI\"\n    invoke_cli_runner(\n        mlflow.experiments.commands, [\"create\", \"--experiment-name\", experiment_name], env=cli_env\n    )\n    experiment_id = mlflow_client.get_experiment_by_name(experiment_name).experiment_id\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"active\"\n    invoke_cli_runner(\n        mlflow.experiments.commands, [\"delete\", \"-x\", str(experiment_id)], env=cli_env\n    )\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"deleted\"\n    invoke_cli_runner(\n        mlflow.experiments.commands, [\"restore\", \"-x\", str(experiment_id)], env=cli_env\n    )\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"active\"\n\n\ndef test_rename_experiment(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"BadName\")\n    assert mlflow_client.get_experiment(experiment_id).name == \"BadName\"\n    mlflow_client.rename_experiment(experiment_id, \"GoodName\")\n    assert mlflow_client.get_experiment(experiment_id).name == \"GoodName\"\n\n\ndef test_rename_experiment_cli(mlflow_client, cli_env):\n    bad_experiment_name = \"CLIBadName\"\n    good_experiment_name = \"CLIGoodName\"\n\n    invoke_cli_runner(\n        mlflow.experiments.commands, [\"create\", \"-n\", bad_experiment_name], env=cli_env\n    )\n    experiment_id = mlflow_client.get_experiment_by_name(bad_experiment_name).experiment_id\n    assert mlflow_client.get_experiment(experiment_id).name == bad_experiment_name\n    invoke_cli_runner(\n        mlflow.experiments.commands,\n        [\"rename\", \"--experiment-id\", str(experiment_id), \"--new-name\", good_experiment_name],\n        env=cli_env,\n    )\n    assert mlflow_client.get_experiment(experiment_id).name == good_experiment_name\n\n\n@pytest.mark.parametrize(\"parent_run_id_kwarg\", [None, \"my-parent-id\"])\ndef test_create_run_all_args(mlflow_client, parent_run_id_kwarg):\n    user = \"username\"\n    source_name = \"Hello\"\n    entry_point = \"entry\"\n    source_version = \"abc\"\n    create_run_kwargs = {\n        \"start_time\": 456,\n        \"run_name\": \"my name\",\n        \"tags\": {\n            MLFLOW_USER: user,\n            MLFLOW_SOURCE_TYPE: \"LOCAL\",\n            MLFLOW_SOURCE_NAME: source_name,\n            MLFLOW_PROJECT_ENTRY_POINT: entry_point,\n            MLFLOW_GIT_COMMIT: source_version,\n            MLFLOW_PARENT_RUN_ID: \"7\",\n            \"my\": \"tag\",\n            \"other\": \"tag\",\n        },\n    }\n    experiment_id = mlflow_client.create_experiment(\n        f\"Run A Lot (parent_run_id={parent_run_id_kwarg})\"\n    )\n    created_run = mlflow_client.create_run(experiment_id, **create_run_kwargs)\n    run_id = created_run.info.run_id\n    _logger.info(f\"Run id={run_id}\")\n    fetched_run = mlflow_client.get_run(run_id)\n    for run in [created_run, fetched_run]:\n        assert run.info.run_id == run_id\n        assert run.info.run_uuid == run_id\n        assert run.info.experiment_id == experiment_id\n        assert run.info.user_id == user\n        assert run.info.start_time == create_run_kwargs[\"start_time\"]\n        assert run.info.run_name == \"my name\"\n        for tag in create_run_kwargs[\"tags\"]:\n            assert tag in run.data.tags\n        assert run.data.tags.get(MLFLOW_USER) == user\n        assert run.data.tags.get(MLFLOW_PARENT_RUN_ID) == parent_run_id_kwarg or \"7\"\n        assert [run.info for run in mlflow_client.search_runs([experiment_id])] == [run.info]\n\n\ndef test_create_run_defaults(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Run A Little\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    run = mlflow_client.get_run(run_id)\n    assert run.info.run_id == run_id\n    assert run.info.experiment_id == experiment_id\n    assert run.info.user_id == \"unknown\"\n\n\ndef test_log_metrics_params_tags(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Oh My\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    mlflow_client.log_metric(run_id, key=\"metric\", value=123.456, timestamp=789, step=2)\n    mlflow_client.log_metric(run_id, key=\"nan_metric\", value=float(\"nan\"))\n    mlflow_client.log_metric(run_id, key=\"inf_metric\", value=float(\"inf\"))\n    mlflow_client.log_metric(run_id, key=\"-inf_metric\", value=-float(\"inf\"))\n    mlflow_client.log_metric(run_id, key=\"stepless-metric\", value=987.654, timestamp=321)\n    mlflow_client.log_param(run_id, \"param\", \"value\")\n    mlflow_client.set_tag(run_id, \"taggity\", \"do-dah\")\n    run = mlflow_client.get_run(run_id)\n    assert run.data.metrics.get(\"metric\") == 123.456\n    assert math.isnan(run.data.metrics.get(\"nan_metric\"))\n    assert run.data.metrics.get(\"inf_metric\") >= 1.7976931348623157e308\n    assert run.data.metrics.get(\"-inf_metric\") <= -1.7976931348623157e308\n    assert run.data.metrics.get(\"stepless-metric\") == 987.654\n    assert run.data.params.get(\"param\") == \"value\"\n    assert run.data.tags.get(\"taggity\") == \"do-dah\"\n    metric_history0 = mlflow_client.get_metric_history(run_id, \"metric\")\n    assert len(metric_history0) == 1\n    metric0 = metric_history0[0]\n    assert metric0.key == \"metric\"\n    assert metric0.value == 123.456\n    assert metric0.timestamp == 789\n    assert metric0.step == 2\n    metric_history1 = mlflow_client.get_metric_history(run_id, \"stepless-metric\")\n    assert len(metric_history1) == 1\n    metric1 = metric_history1[0]\n    assert metric1.key == \"stepless-metric\"\n    assert metric1.value == 987.654\n    assert metric1.timestamp == 321\n    assert metric1.step == 0\n\n    metric_history = mlflow_client.get_metric_history(run_id, \"a_test_accuracy\")\n    assert metric_history == []\n\n\ndef test_log_metric_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"metrics validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/log-metric\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    assert_bad_request(\n        {\n            \"run_id\": 31,\n            \"key\": \"metric\",\n            \"value\": 41,\n            \"timestamp\": 59,\n            \"step\": 26,\n        },\n        \"Invalid value 31 for parameter 'run_id' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": 31,\n            \"value\": 41,\n            \"timestamp\": 59,\n            \"step\": 26,\n        },\n        \"Invalid value 31 for parameter 'key' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": \"foo\",\n            \"value\": 31,\n            \"timestamp\": 59,\n            \"step\": \"foo\",\n        },\n        \"Invalid value foo for parameter 'step' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": \"foo\",\n            \"value\": 31,\n            \"timestamp\": \"foo\",\n            \"step\": 41,\n        },\n        \"Invalid value foo for parameter 'timestamp' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": None,\n            \"key\": \"foo\",\n            \"value\": 31,\n            \"timestamp\": 59,\n            \"step\": 41,\n        },\n        \"Missing value for required parameter 'run_id'\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            # Missing key\n            \"value\": 31,\n            \"timestamp\": 59,\n            \"step\": 41,\n        },\n        \"Missing value for required parameter 'key'\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": None,\n            \"value\": 31,\n            \"timestamp\": 59,\n            \"step\": 41,\n        },\n        \"Missing value for required parameter 'key'\",\n    )\n\n\ndef test_log_param_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"params validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/log-parameter\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    assert_bad_request(\n        {\n            \"run_id\": 31,\n            \"key\": \"param\",\n            \"value\": 41,\n        },\n        \"Invalid value 31 for parameter 'run_id' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": 31,\n            \"value\": 41,\n        },\n        \"Invalid value 31 for parameter 'key' supplied\",\n    )\n\n\ndef test_log_param_with_empty_string_as_value(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        test_log_param_with_empty_string_as_value.__name__\n    )\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    mlflow_client.log_param(run_id, \"param_key\", \"\")\n    assert {\"param_key\": \"\"}.items() <= mlflow_client.get_run(run_id).data.params.items()\n\n\ndef test_set_tag_with_empty_string_as_value(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        test_set_tag_with_empty_string_as_value.__name__\n    )\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    mlflow_client.set_tag(run_id, \"tag_key\", \"\")\n    assert {\"tag_key\": \"\"}.items() <= mlflow_client.get_run(run_id).data.tags.items()\n\n\ndef test_log_batch_containing_params_and_tags_with_empty_string_values(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        test_log_batch_containing_params_and_tags_with_empty_string_values.__name__\n    )\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    mlflow_client.log_batch(\n        run_id=run_id,\n        params=[Param(\"param_key\", \"\")],\n        tags=[RunTag(\"tag_key\", \"\")],\n    )\n    assert {\"param_key\": \"\"}.items() <= mlflow_client.get_run(run_id).data.params.items()\n    assert {\"tag_key\": \"\"}.items() <= mlflow_client.get_run(run_id).data.tags.items()\n\n\ndef test_set_tag_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"tags validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/set-tag\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    assert_bad_request(\n        {\n            \"run_id\": 31,\n            \"key\": \"tag\",\n            \"value\": 41,\n        },\n        \"Invalid value 31 for parameter 'run_id' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": \"param\",\n            \"value\": 41,\n        },\n        \"Invalid value 41 for parameter 'value' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            # Missing key\n            \"value\": \"value\",\n        },\n        \"Missing value for required parameter 'key'\",\n    )\n\n    response = _send_rest_tracking_post_request(\n        mlflow_client.tracking_uri,\n        \"/api/2.0/mlflow/runs/set-tag\",\n        {\n            \"run_uuid\": run_id,\n            \"key\": \"key\",\n            \"value\": \"value\",\n        },\n    )\n    assert response.status_code == 200\n\n\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        \"path\",\n        \"path/\",\n        \"path/to/file\",\n    ],\n)\ndef test_validate_path_is_safe_good(path):\n    validate_path_is_safe(path)\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"This test only passes on Windows\")\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        # relative path from current directory of C: drive\n        \".../...//\",\n    ],\n)\ndef test_validate_path_is_safe_windows_good(path):\n    validate_path_is_safe(path)\n\n\n@pytest.mark.skipif(is_windows(), reason=\"This test does not pass on Windows\")\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        \"/path\",\n        \"../path\",\n        \"../../path\",\n        \"./../path\",\n        \"path/../to/file\",\n        \"path/../../to/file\",\n        \"file://a#/..//tmp\",\n        \"file://a%23/..//tmp/\",\n        \"/etc/passwd\",\n        \"/etc/passwd%00.jpg\",\n        \"/etc/passwd%00.html\",\n        \"/etc/passwd%00.txt\",\n        \"/etc/passwd%00.php\",\n        \"/etc/passwd%00.asp\",\n        \"/file://etc/passwd\",\n    ],\n)\ndef test_validate_path_is_safe_bad(path):\n    with pytest.raises(MlflowException, match=\"Invalid path\"):\n        validate_path_is_safe(path)\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"This test only passes on Windows\")\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        r\"../path\",\n        r\"../../path\",\n        r\"./../path\",\n        r\"path/../to/file\",\n        r\"path/../../to/file\",\n        r\"..\\path\",\n        r\"..\\..\\path\",\n        r\".\\..\\path\",\n        r\"path\\..\\to\\file\",\n        r\"path\\..\\..\\to\\file\",\n        # Drive-relative paths\n        r\"C:path\",\n        r\"C:path/\",\n        r\"C:path/to/file\",\n        r\"C:../path/to/file\",\n        r\"C:\\path\",\n        r\"C:/path\",\n        r\"C:\\path\\to\\file\",\n        r\"C:\\path/to/file\",\n        r\"C:\\path\\..\\to\\file\",\n        r\"C:/path/../to/file\",\n        # UNC(Universal Naming Convention) paths\n        r\"\\\\path\\to\\file\",\n        r\"\\\\path/to/file\",\n        r\"\\\\.\\\\C:\\path\\to\\file\",\n        r\"\\\\?\\C:\\path\\to\\file\",\n        r\"\\\\?\\UNC/path/to/file\",\n        # Other potential attackable paths\n        r\"/etc/password\",\n        r\"/path\",\n        r\"/etc/passwd%00.jpg\",\n        r\"/etc/passwd%00.html\",\n        r\"/etc/passwd%00.txt\",\n        r\"/etc/passwd%00.php\",\n        r\"/etc/passwd%00.asp\",\n        r\"/Windows/no/such/path\",\n        r\"/file://etc/passwd\",\n        r\"/file:c:/passwd\",\n        r\"/file://d:/windows/win.ini\",\n        r\"/file://./windows/win.ini\",\n        r\"file://c:/boot.ini\",\n        r\"file://C:path\",\n        r\"file://C:path/\",\n        r\"file://C:path/to/file\",\n        r\"file:///C:/Windows/System32/\",\n        r\"file:///etc/passwd\",\n        r\"file:///d:/windows/repair/sam\",\n        r\"file:///proc/version\",\n        r\"file:///inetpub/wwwroot/global.asa\",\n        r\"/file://../windows/win.ini\",\n        r\"../etc/passwd\",\n        r\"..\\Windows\\System32\\\\\",\n        r\"C:\\Windows\\System32\\\\\",\n        r\"/etc/passwd\",\n        r\"::Windows\\System32\",\n        r\"..\\..\\..\\..\\Windows\\System32\\\\\",\n        r\"../Windows/System32\",\n        r\"....\\\\\",\n        r\"\\\\?\\C:\\Windows\\System32\\\\\",\n        r\"\\\\.\\C:\\Windows\\System32\\\\\",\n        r\"\\\\UNC\\Server\\Share\\\\\",\n        r\"\\\\Server\\Share\\folder\\\\\",\n        r\"\\\\127.0.0.1\\c$\\Windows\\\\\",\n        r\"\\\\localhost\\c$\\Windows\\\\\",\n        r\"\\\\smbserver\\share\\path\\\\\",\n        r\"..\\\\?\\C:\\Windows\\System32\\\\\",\n        r\"C:/Windows/../Windows/System32/\",\n        r\"C:\\Windows\\..\\Windows\\System32\\\\\",\n        r\"../../../../../../../../../../../../Windows/System32\",\n        r\"../../../../../../../../../../../../etc/passwd\",\n        r\"../../../../../../../../../../../../var/www/html/index.html\",\n        r\"../../../../../../../../../../../../usr/local/etc/openvpn/server.conf\",\n        r\"../../../../../../../../../../../../Program Files (x86)\",\n        r\"/../../../../../../../../../../../../Windows/System32\",\n        r\"/Windows\\../etc/passwd\",\n        r\"/Windows\\..\\Windows\\System32\\\\\",\n        r\"/Windows\\..\\Windows\\System32\\cmd.exe\",\n        r\"/Windows\\..\\Windows\\System32\\msconfig.exe\",\n        r\"/Windows\\..\\Windows\\System32\\regedit.exe\",\n        r\"/Windows\\..\\Windows\\System32\\taskmgr.exe\",\n        r\"/Windows\\..\\Windows\\System32\\control.exe\",\n        r\"/Windows\\..\\Windows\\System32\\services.msc\",\n        r\"/Windows\\..\\Windows\\System32\\diskmgmt.msc\",\n        r\"/Windows\\..\\Windows\\System32\\eventvwr.msc\",\n        r\"/Windows/System32/drivers/etc/hosts\",\n    ],\n)\ndef test_validate_path_is_safe_windows_bad(path):\n    with pytest.raises(MlflowException, match=\"Invalid path\"):\n        validate_path_is_safe(path)\n\n\ndef test_path_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"tags validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    invalid_path = \"../path\"\n\n    def assert_response(resp):\n        assert resp.status_code == 400\n        assert response.json() == {\n            \"error_code\": \"INVALID_PARAMETER_VALUE\",\n            \"message\": f\"Invalid path: {invalid_path}\",\n        }\n\n    response = requests.get(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/artifacts/list\",\n        params={\"run_id\": run_id, \"path\": invalid_path},\n    )\n    assert_response(response)\n\n    response = requests.get(\n        f\"{mlflow_client.tracking_uri}/get-artifact\",\n        params={\"run_id\": run_id, \"path\": invalid_path},\n    )\n    assert_response(response)\n\n    response = requests.get(\n        f\"{mlflow_client.tracking_uri}//model-versions/get-artifact\",\n        params={\"name\": \"model\", \"version\": 1, \"path\": invalid_path},\n    )\n    assert_response(response)\n\n\ndef test_set_experiment_tag(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"SetExperimentTagTest\")\n    mlflow_client.set_experiment_tag(experiment_id, \"dataset\", \"imagenet1K\")\n    experiment = mlflow_client.get_experiment(experiment_id)\n    assert \"dataset\" in experiment.tags\n    assert experiment.tags[\"dataset\"] == \"imagenet1K\"\n    # test that updating a tag works\n    mlflow_client.set_experiment_tag(experiment_id, \"dataset\", \"birdbike\")\n    experiment = mlflow_client.get_experiment(experiment_id)\n    assert \"dataset\" in experiment.tags\n    assert experiment.tags[\"dataset\"] == \"birdbike\"\n    # test that setting a tag on 1 experiment does not impact another experiment.\n    experiment_id_2 = mlflow_client.create_experiment(\"SetExperimentTagTest2\")\n    experiment2 = mlflow_client.get_experiment(experiment_id_2)\n    assert len(experiment2.tags) == 0\n    # test that setting a tag on different experiments maintain different values across experiments\n    mlflow_client.set_experiment_tag(experiment_id_2, \"dataset\", \"birds200\")\n    experiment = mlflow_client.get_experiment(experiment_id)\n    experiment2 = mlflow_client.get_experiment(experiment_id_2)\n    assert \"dataset\" in experiment.tags\n    assert experiment.tags[\"dataset\"] == \"birdbike\"\n    assert \"dataset\" in experiment2.tags\n    assert experiment2.tags[\"dataset\"] == \"birds200\"\n    # test can set multi-line tags\n    mlflow_client.set_experiment_tag(experiment_id, \"multiline tag\", \"value2\\nvalue2\\nvalue2\")\n    experiment = mlflow_client.get_experiment(experiment_id)\n    assert \"multiline tag\" in experiment.tags\n    assert experiment.tags[\"multiline tag\"] == \"value2\\nvalue2\\nvalue2\"\n\n\ndef test_set_experiment_tag_with_empty_string_as_value(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        test_set_experiment_tag_with_empty_string_as_value.__name__\n    )\n    mlflow_client.set_experiment_tag(experiment_id, \"tag_key\", \"\")\n    assert {\"tag_key\": \"\"}.items() <= mlflow_client.get_experiment(experiment_id).tags.items()\n\n\ndef test_delete_tag(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"DeleteTagExperiment\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    mlflow_client.log_metric(run_id, key=\"metric\", value=123.456, timestamp=789, step=2)\n    mlflow_client.log_metric(run_id, key=\"stepless-metric\", value=987.654, timestamp=321)\n    mlflow_client.log_param(run_id, \"param\", \"value\")\n    mlflow_client.set_tag(run_id, \"taggity\", \"do-dah\")\n    run = mlflow_client.get_run(run_id)\n    assert \"taggity\" in run.data.tags\n    assert run.data.tags[\"taggity\"] == \"do-dah\"\n    mlflow_client.delete_tag(run_id, \"taggity\")\n    run = mlflow_client.get_run(run_id)\n    assert \"taggity\" not in run.data.tags\n    with pytest.raises(MlflowException, match=r\"Run .+ not found\"):\n        mlflow_client.delete_tag(\"fake_run_id\", \"taggity\")\n    with pytest.raises(MlflowException, match=\"No tag with name: fakeTag\"):\n        mlflow_client.delete_tag(run_id, \"fakeTag\")\n    mlflow_client.delete_run(run_id)\n    with pytest.raises(MlflowException, match=f\"The run {run_id} must be in\"):\n        mlflow_client.delete_tag(run_id, \"taggity\")\n\n\ndef test_log_batch(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Batch em up\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    mlflow_client.log_batch(\n        run_id=run_id,\n        metrics=[Metric(\"metric\", 123.456, 789, 3)],\n        params=[Param(\"param\", \"value\")],\n        tags=[RunTag(\"taggity\", \"do-dah\")],\n    )\n    run = mlflow_client.get_run(run_id)\n    assert run.data.metrics.get(\"metric\") == 123.456\n    assert run.data.params.get(\"param\") == \"value\"\n    assert run.data.tags.get(\"taggity\") == \"do-dah\"\n    metric_history = mlflow_client.get_metric_history(run_id, \"metric\")\n    assert len(metric_history) == 1\n    metric = metric_history[0]\n    assert metric.key == \"metric\"\n    assert metric.value == 123.456\n    assert metric.timestamp == 789\n    assert metric.step == 3\n\n\ndef test_log_batch_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log_batch validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/log-batch\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    for request_parameter in [\"metrics\", \"params\", \"tags\"]:\n        assert_bad_request(\n            {\n                \"run_id\": run_id,\n                request_parameter: \"foo\",\n            },\n            f\"Invalid value foo for parameter '{request_parameter}' supplied\",\n        )\n\n    ## Should 400 if missing timestamp\n    assert_bad_request(\n        {\"run_id\": run_id, \"metrics\": [{\"key\": \"mae\", \"value\": 2.5}]},\n        \"Invalid value [{'key': 'mae', 'value': 2.5}] for parameter 'metrics' supplied\",\n    )\n\n    ## Should 200 if timestamp provided but step is not\n    response = _send_rest_tracking_post_request(\n        mlflow_client.tracking_uri,\n        \"/api/2.0/mlflow/runs/log-batch\",\n        {\"run_id\": run_id, \"metrics\": [{\"key\": \"mae\", \"value\": 2.5, \"timestamp\": 123456789}]},\n    )\n\n    assert response.status_code == 200\n\n\n@pytest.mark.allow_infer_pip_requirements_fallback\ndef test_log_model(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Log models\")\n    with TempDir(chdr=True):\n        model_paths = [f\"model/path/{i}\" for i in range(3)]\n        mlflow.set_tracking_uri(mlflow_client.tracking_uri)\n        with mlflow.start_run(experiment_id=experiment_id) as run:\n            for i, m in enumerate(model_paths):\n                mlflow.pyfunc.log_model(m, loader_module=\"mlflow.pyfunc\")\n                mlflow.pyfunc.save_model(\n                    m,\n                    mlflow_model=Model(artifact_path=m, run_id=run.info.run_id),\n                    loader_module=\"mlflow.pyfunc\",\n                )\n                model = Model.load(os.path.join(m, \"MLmodel\"))\n                run = mlflow.get_run(run.info.run_id)\n                tag = run.data.tags[\"mlflow.log-model.history\"]\n                models = json.loads(tag)\n                model.utc_time_created = models[i][\"utc_time_created\"]\n\n                history_model_meta = models[i].copy()\n                original_model_uuid = history_model_meta.pop(\"model_uuid\")\n                model_meta = model.to_dict().copy()\n                new_model_uuid = model_meta.pop(\"model_uuid\")\n                assert history_model_meta == model_meta\n                assert original_model_uuid != new_model_uuid\n                assert len(models) == i + 1\n                for j in range(0, i + 1):\n                    assert models[j][\"artifact_path\"] == model_paths[j]\n\n\ndef test_set_terminated_defaults(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Terminator 1\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    assert mlflow_client.get_run(run_id).info.status == \"RUNNING\"\n    assert mlflow_client.get_run(run_id).info.end_time is None\n    mlflow_client.set_terminated(run_id)\n    assert mlflow_client.get_run(run_id).info.status == \"FINISHED\"\n    assert mlflow_client.get_run(run_id).info.end_time <= get_current_time_millis()\n\n\ndef test_set_terminated_status(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Terminator 2\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    assert mlflow_client.get_run(run_id).info.status == \"RUNNING\"\n    assert mlflow_client.get_run(run_id).info.end_time is None\n    mlflow_client.set_terminated(run_id, \"FAILED\")\n    assert mlflow_client.get_run(run_id).info.status == \"FAILED\"\n    assert mlflow_client.get_run(run_id).info.end_time <= get_current_time_millis()\n\n\ndef test_artifacts(mlflow_client, tmp_path):\n    experiment_id = mlflow_client.create_experiment(\"Art In Fact\")\n    experiment_info = mlflow_client.get_experiment(experiment_id)\n    assert experiment_info.artifact_location.startswith(path_to_local_file_uri(str(tmp_path)))\n    artifact_path = urllib.parse.urlparse(experiment_info.artifact_location).path\n    assert posixpath.split(artifact_path)[-1] == experiment_id\n\n    created_run = mlflow_client.create_run(experiment_id)\n    assert created_run.info.artifact_uri.startswith(experiment_info.artifact_location)\n    run_id = created_run.info.run_id\n    src_dir = tmp_path.joinpath(\"test_artifacts_src\")\n    src_dir.mkdir()\n    src_file = os.path.join(src_dir, \"my.file\")\n    with open(src_file, \"w\") as f:\n        f.write(\"Hello, World!\")\n    mlflow_client.log_artifact(run_id, src_file, None)\n    mlflow_client.log_artifacts(run_id, src_dir, \"dir\")\n\n    root_artifacts_list = mlflow_client.list_artifacts(run_id)\n    assert {a.path for a in root_artifacts_list} == {\"my.file\", \"dir\"}\n\n    dir_artifacts_list = mlflow_client.list_artifacts(run_id, \"dir\")\n    assert {a.path for a in dir_artifacts_list} == {\"dir/my.file\"}\n\n    all_artifacts = download_artifacts(\n        run_id=run_id, artifact_path=\".\", tracking_uri=mlflow_client.tracking_uri\n    )\n    with open(f\"{all_artifacts}/my.file\") as f:\n        assert f.read() == \"Hello, World!\"\n    with open(f\"{all_artifacts}/dir/my.file\") as f:\n        assert f.read() == \"Hello, World!\"\n\n    dir_artifacts = download_artifacts(\n        run_id=run_id, artifact_path=\"dir\", tracking_uri=mlflow_client.tracking_uri\n    )\n    with open(f\"{dir_artifacts}/my.file\") as f:\n        assert f.read() == \"Hello, World!\"\n\n\ndef test_search_pagination(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"search_pagination\")\n    runs = [mlflow_client.create_run(experiment_id, start_time=1).info.run_id for _ in range(0, 10)]\n    runs = sorted(runs)\n    result = mlflow_client.search_runs([experiment_id], max_results=4, page_token=None)\n    assert [r.info.run_id for r in result] == runs[0:4]\n    assert result.token is not None\n    result = mlflow_client.search_runs([experiment_id], max_results=4, page_token=result.token)\n    assert [r.info.run_id for r in result] == runs[4:8]\n    assert result.token is not None\n    result = mlflow_client.search_runs([experiment_id], max_results=4, page_token=result.token)\n    assert [r.info.run_id for r in result] == runs[8:]\n    assert result.token is None\n\n\ndef test_search_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"search_validation\")\n    with pytest.raises(\n        MlflowException, match=r\"Invalid value 123456789 for parameter 'max_results' supplied\"\n    ):\n        mlflow_client.search_runs([experiment_id], max_results=123456789)\n\n\ndef test_get_experiment_by_name(mlflow_client):\n    name = \"test_get_experiment_by_name\"\n    experiment_id = mlflow_client.create_experiment(name)\n    res = mlflow_client.get_experiment_by_name(name)\n    assert res.experiment_id == experiment_id\n    assert res.name == name\n    assert mlflow_client.get_experiment_by_name(\"idontexist\") is None\n\n\ndef test_get_experiment(mlflow_client):\n    name = \"test_get_experiment\"\n    experiment_id = mlflow_client.create_experiment(name)\n    res = mlflow_client.get_experiment(experiment_id)\n    assert res.experiment_id == experiment_id\n    assert res.name == name\n\n\ndef test_search_experiments(mlflow_client):\n    # To ensure the default experiment and non-default experiments have different creation_time\n    # for deterministic search results, send a request to the server and initialize the tracking\n    # store.\n    assert mlflow_client.search_experiments()[0].name == \"Default\"\n\n    experiments = [\n        (\"a\", {\"key\": \"value\"}),\n        (\"ab\", {\"key\": \"vaLue\"}),\n        (\"Abc\", None),\n    ]\n    experiment_ids = []\n    for name, tags in experiments:\n        # sleep for windows file system current_time precision in Python to enforce\n        # deterministic ordering based on last_update_time (creation_time due to no\n        # mutation of experiment state)\n        time.sleep(0.001)\n        experiment_ids.append(mlflow_client.create_experiment(name, tags=tags))\n\n    # filter_string\n    experiments = mlflow_client.search_experiments(filter_string=\"attribute.name = 'a'\")\n    assert [e.name for e in experiments] == [\"a\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"attribute.name != 'a'\")\n    assert [e.name for e in experiments] == [\"Abc\", \"ab\", \"Default\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"name LIKE 'a%'\")\n    assert [e.name for e in experiments] == [\"ab\", \"a\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"tag.key = 'value'\")\n    assert [e.name for e in experiments] == [\"a\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"tag.key != 'value'\")\n    assert [e.name for e in experiments] == [\"ab\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"tag.key ILIKE '%alu%'\")\n    assert [e.name for e in experiments] == [\"ab\", \"a\"]\n\n    # order_by\n    experiments = mlflow_client.search_experiments(order_by=[\"name DESC\"])\n    assert [e.name for e in experiments] == [\"ab\", \"a\", \"Default\", \"Abc\"]\n\n    # max_results\n    experiments = mlflow_client.search_experiments(max_results=2)\n    assert [e.name for e in experiments] == [\"Abc\", \"ab\"]\n    # page_token\n    experiments = mlflow_client.search_experiments(page_token=experiments.token)\n    assert [e.name for e in experiments] == [\"a\", \"Default\"]\n\n    # view_type\n    time.sleep(0.001)\n    mlflow_client.delete_experiment(experiment_ids[1])\n    experiments = mlflow_client.search_experiments(view_type=ViewType.ACTIVE_ONLY)\n    assert [e.name for e in experiments] == [\"Abc\", \"a\", \"Default\"]\n    experiments = mlflow_client.search_experiments(view_type=ViewType.DELETED_ONLY)\n    assert [e.name for e in experiments] == [\"ab\"]\n    experiments = mlflow_client.search_experiments(view_type=ViewType.ALL)\n    assert [e.name for e in experiments] == [\"Abc\", \"ab\", \"a\", \"Default\"]\n\n\ndef test_get_metric_history_bulk_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    response_no_run_ids_field = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"metric_key\": \"key\"},\n    )\n    assert_response(\n        response_no_run_ids_field,\n        \"GetMetricHistoryBulk request must specify at least one run_id\",\n    )\n\n    response_empty_run_ids = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [], \"metric_key\": \"key\"},\n    )\n    assert_response(\n        response_empty_run_ids,\n        \"GetMetricHistoryBulk request must specify at least one run_id\",\n    )\n\n    response_too_many_run_ids = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [f\"id_{i}\" for i in range(1000)], \"metric_key\": \"key\"},\n    )\n    assert_response(\n        response_too_many_run_ids,\n        \"GetMetricHistoryBulk request cannot specify more than\",\n    )\n\n    response_no_metric_key_field = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [\"123\"]},\n    )\n    assert_response(\n        response_no_metric_key_field,\n        \"GetMetricHistoryBulk request must specify a metric_key\",\n    )\n\n\ndef test_get_metric_history_bulk_returns_expected_metrics_in_expected_order(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"get metric history bulk\")\n    created_run1 = mlflow_client.create_run(experiment_id)\n    run_id1 = created_run1.info.run_id\n    created_run2 = mlflow_client.create_run(experiment_id)\n    run_id2 = created_run2.info.run_id\n    created_run3 = mlflow_client.create_run(experiment_id)\n    run_id3 = created_run3.info.run_id\n\n    metricA_history = [\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 2, \"value\": 10.0},\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 3, \"value\": 11.0},\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 3, \"value\": 12.0},\n        {\"key\": \"metricA\", \"timestamp\": 2, \"step\": 3, \"value\": 12.0},\n    ]\n    for metric in metricA_history:\n        mlflow_client.log_metric(run_id1, **metric)\n        metric_for_run2 = dict(metric)\n        metric_for_run2[\"value\"] += 1.0\n        mlflow_client.log_metric(run_id2, **metric_for_run2)\n\n    metricB_history = [\n        {\"key\": \"metricB\", \"timestamp\": 7, \"step\": -2, \"value\": -100.0},\n        {\"key\": \"metricB\", \"timestamp\": 8, \"step\": 0, \"value\": 0.0},\n        {\"key\": \"metricB\", \"timestamp\": 8, \"step\": 0, \"value\": 1.0},\n        {\"key\": \"metricB\", \"timestamp\": 9, \"step\": 1, \"value\": 12.0},\n    ]\n    for metric in metricB_history:\n        mlflow_client.log_metric(run_id1, **metric)\n        metric_for_run2 = dict(metric)\n        metric_for_run2[\"value\"] += 1.0\n        mlflow_client.log_metric(run_id2, **metric_for_run2)\n\n    response_run1_metricA = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id1], \"metric_key\": \"metricA\"},\n    )\n    assert response_run1_metricA.status_code == 200\n    assert response_run1_metricA.json().get(\"metrics\") == [\n        {**metric, \"run_id\": run_id1} for metric in metricA_history\n    ]\n\n    response_run2_metricB = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id2], \"metric_key\": \"metricB\"},\n    )\n    assert response_run2_metricB.status_code == 200\n    assert response_run2_metricB.json().get(\"metrics\") == [\n        {**metric, \"run_id\": run_id2, \"value\": metric[\"value\"] + 1.0} for metric in metricB_history\n    ]\n\n    response_run1_run2_metricA = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id1, run_id2], \"metric_key\": \"metricA\"},\n    )\n    assert response_run1_run2_metricA.status_code == 200\n    assert response_run1_run2_metricA.json().get(\"metrics\") == sorted(\n        [{**metric, \"run_id\": run_id1} for metric in metricA_history]\n        + [\n            {**metric, \"run_id\": run_id2, \"value\": metric[\"value\"] + 1.0}\n            for metric in metricA_history\n        ],\n        key=lambda metric: metric[\"run_id\"],\n    )\n\n    response_run1_run2_run_3_metricB = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id1, run_id2, run_id3], \"metric_key\": \"metricB\"},\n    )\n    assert response_run1_run2_run_3_metricB.status_code == 200\n    assert response_run1_run2_run_3_metricB.json().get(\"metrics\") == sorted(\n        [{**metric, \"run_id\": run_id1} for metric in metricB_history]\n        + [\n            {**metric, \"run_id\": run_id2, \"value\": metric[\"value\"] + 1.0}\n            for metric in metricB_history\n        ],\n        key=lambda metric: metric[\"run_id\"],\n    )\n\n\ndef test_get_metric_history_bulk_respects_max_results(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"get metric history bulk\")\n    run_id = mlflow_client.create_run(experiment_id).info.run_id\n    max_results = 2\n\n    metricA_history = [\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 2, \"value\": 10.0},\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 3, \"value\": 11.0},\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 3, \"value\": 12.0},\n        {\"key\": \"metricA\", \"timestamp\": 2, \"step\": 3, \"value\": 12.0},\n    ]\n    for metric in metricA_history:\n        mlflow_client.log_metric(run_id, **metric)\n\n    response_limited = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id], \"metric_key\": \"metricA\", \"max_results\": max_results},\n    )\n    assert response_limited.status_code == 200\n    assert response_limited.json().get(\"metrics\") == [\n        {**metric, \"run_id\": run_id} for metric in metricA_history[:max_results]\n    ]\n\n\ndef test_get_metric_history_bulk_calls_optimized_impl_when_expected(tmp_path):\n    from mlflow.server.handlers import get_metric_history_bulk_handler\n\n    path = path_to_local_file_uri(str(tmp_path.joinpath(\"sqlalchemy.db\")))\n    uri = (\"sqlite://\" if sys.platform == \"win32\" else \"sqlite:////\") + path[len(\"file://\") :]\n    mock_store = mock.Mock(wraps=SqlAlchemyStore(uri, str(tmp_path)))\n\n    flask_app = flask.Flask(\"test_flask_app\")\n\n    class MockRequestArgs:\n        def __init__(self, args_dict):\n            self.args_dict = args_dict\n\n        def to_dict(\n            self,\n            flat,  # pylint: disable=unused-argument\n        ):\n            return self.args_dict\n\n        def get(self, key, default=None):\n            return self.args_dict.get(key, default)\n\n    with mock.patch(\n        \"mlflow.server.handlers._get_tracking_store\", return_value=mock_store\n    ), flask_app.test_request_context() as mock_context:\n        run_ids = [str(i) for i in range(10)]\n        mock_context.request.args = MockRequestArgs(\n            {\n                \"run_id\": run_ids,\n                \"metric_key\": \"mock_key\",\n            }\n        )\n\n        get_metric_history_bulk_handler()\n\n        mock_store.get_metric_history_bulk.assert_called_once_with(\n            run_ids=run_ids,\n            metric_key=\"mock_key\",\n            max_results=25000,\n        )\n\n\ndef test_search_dataset_handler_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    response_no_experiment_id_field = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/experiments/search-datasets\",\n        json={},\n    )\n    assert_response(\n        response_no_experiment_id_field,\n        \"SearchDatasets request must specify at least one experiment_id.\",\n    )\n\n    response_empty_experiment_id_field = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/experiments/search-datasets\",\n        json={\"experiment_ids\": []},\n    )\n    assert_response(\n        response_empty_experiment_id_field,\n        \"SearchDatasets request must specify at least one experiment_id.\",\n    )\n\n    response_too_many_experiment_ids = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/experiments/search-datasets\",\n        json={\"experiment_ids\": [f\"id_{i}\" for i in range(1000)]},\n    )\n    assert_response(\n        response_too_many_experiment_ids,\n        \"SearchDatasets request cannot specify more than\",\n    )\n\n\ndef test_search_dataset_handler_returns_expected_results(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log inputs test\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    dataset1 = Dataset(\n        name=\"name1\",\n        digest=\"digest1\",\n        source_type=\"source_type1\",\n        source=\"source1\",\n    )\n    dataset_inputs1 = [\n        DatasetInput(\n            dataset=dataset1, tags=[InputTag(key=MLFLOW_DATASET_CONTEXT, value=\"training\")]\n        )\n    ]\n    mlflow_client.log_inputs(run_id, dataset_inputs1)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/experiments/search-datasets\",\n        json={\"experiment_ids\": [experiment_id]},\n    )\n    expected = {\n        \"experiment_id\": experiment_id,\n        \"name\": \"name1\",\n        \"digest\": \"digest1\",\n        \"context\": \"training\",\n    }\n\n    assert response.status_code == 200\n    assert response.json().get(\"dataset_summaries\") == [expected]\n\n\ndef test_create_model_version_with_path_source(mlflow_client):\n    name = \"model\"\n    mlflow_client.create_registered_model(name)\n    exp_id = mlflow_client.create_experiment(\"test\")\n    run = mlflow_client.create_run(experiment_id=exp_id)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri[len(\"file://\") :],\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # run_id is not specified\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri[len(\"file://\") :],\n        },\n    )\n    assert response.status_code == 400\n    assert \"To use a local path as a model version\" in response.json()[\"message\"]\n\n    # run_id is specified but source is not in the run's artifact directory\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"/tmp\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"To use a local path as a model version\" in response.json()[\"message\"]\n\n\ndef test_create_model_version_with_non_local_source(mlflow_client):\n    name = \"model\"\n    mlflow_client.create_registered_model(name)\n    exp_id = mlflow_client.create_experiment(\"test\")\n    run = mlflow_client.create_run(experiment_id=exp_id)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri[len(\"file://\") :],\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Test that remote uri's supplied as a source with absolute paths work fine\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts:/models\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # A single trailing slash\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts:/models/\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Multiple trailing slashes\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts:/models///\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Multiple slashes\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts:/models/foo///bar\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Multiple dots\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models/artifact/..../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Test that invalid remote uri's cannot be created\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"http://host:9000/models/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"https://host/api/2.0/mlflow-artifacts/artifacts/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"s3a://my_bucket/api/2.0/mlflow-artifacts/artifacts/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"ftp://host:8888/api/2.0/mlflow-artifacts/artifacts/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models/..%2f..%2fartifacts\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models/artifact%00\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n\ndef test_create_model_version_with_file_uri(mlflow_client):\n    name = \"test\"\n    mlflow_client.create_registered_model(name)\n    exp_id = mlflow_client.create_experiment(\"test\")\n    run = mlflow_client.create_run(experiment_id=exp_id)\n    assert run.info.artifact_uri.startswith(\"file://\")\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri,\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": f\"{run.info.artifact_uri}/model\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": f\"{run.info.artifact_uri}/.\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": f\"{run.info.artifact_uri}/model/..\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # run_id is not specified\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri,\n        },\n    )\n    assert response.status_code == 400\n    assert \"To use a local path as a model version\" in response.json()[\"message\"]\n\n    # run_id is specified but source is not in the run's artifact directory\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"file:///tmp\",\n        },\n    )\n    assert response.status_code == 400\n    assert \"To use a local path as a model version\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"file://123.456.789.123/path/to/source\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"MLflow tracking server doesn't allow\" in response.json()[\"message\"]\n\n\ndef test_create_model_version_with_file_uri_env_var(tmp_path):\n    backend_uri = tmp_path.joinpath(\"file\").as_uri()\n    with _init_server(\n        backend_uri,\n        root_artifact_uri=tmp_path.as_uri(),\n        extra_env={\"MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE\": \"true\"},\n    ) as url:\n        mlflow_client = MlflowClient(url)\n\n        name = \"test\"\n        mlflow_client.create_registered_model(name)\n        exp_id = mlflow_client.create_experiment(\"test\")\n        run = mlflow_client.create_run(experiment_id=exp_id)\n        response = requests.post(\n            f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n            json={\n                \"name\": name,\n                \"source\": \"file://123.456.789.123/path/to/source\",\n                \"run_id\": run.info.run_id,\n            },\n        )\n        assert response.status_code == 200\n\n\ndef test_logging_model_with_local_artifact_uri(mlflow_client):\n    from sklearn.linear_model import LogisticRegression\n\n    mlflow.set_tracking_uri(mlflow_client.tracking_uri)\n    with mlflow.start_run() as run:\n        assert run.info.artifact_uri.startswith(\"file://\")\n        mlflow.sklearn.log_model(LogisticRegression(), \"model\", registered_model_name=\"rmn\")\n        mlflow.pyfunc.load_model(\"models:/rmn/1\")\n\n\ndef test_log_input(mlflow_client, tmp_path):\n    df = pd.DataFrame([[1, 2, 3], [1, 2, 3]], columns=[\"a\", \"b\", \"c\"])\n    path = tmp_path / \"temp.csv\"\n    df.to_csv(path)\n    dataset = from_pandas(df, source=path)\n\n    mlflow.set_tracking_uri(mlflow_client.tracking_uri)\n\n    with mlflow.start_run() as run:\n        mlflow.log_input(dataset, \"train\", {\"foo\": \"baz\"})\n\n    dataset_inputs = mlflow_client.get_run(run.info.run_id).inputs.dataset_inputs\n\n    assert len(dataset_inputs) == 1\n    assert dataset_inputs[0].dataset.name == \"dataset\"\n    assert dataset_inputs[0].dataset.digest == \"f0f3e026\"\n    assert dataset_inputs[0].dataset.source_type == \"local\"\n    assert json.loads(dataset_inputs[0].dataset.source) == {\"uri\": str(path)}\n    assert json.loads(dataset_inputs[0].dataset.schema) == {\n        \"mlflow_colspec\": [\n            {\"name\": \"a\", \"type\": \"long\"},\n            {\"name\": \"b\", \"type\": \"long\"},\n            {\"name\": \"c\", \"type\": \"long\"},\n        ]\n    }\n    assert json.loads(dataset_inputs[0].dataset.profile) == {\"num_rows\": 2, \"num_elements\": 6}\n\n    assert len(dataset_inputs[0].tags) == 2\n    assert dataset_inputs[0].tags[0].key == \"foo\"\n    assert dataset_inputs[0].tags[0].value == \"baz\"\n    assert dataset_inputs[0].tags[1].key == mlflow_tags.MLFLOW_DATASET_CONTEXT\n    assert dataset_inputs[0].tags[1].value == \"train\"\n\n\ndef test_log_inputs(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log inputs test\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    dataset1 = Dataset(\n        name=\"name1\",\n        digest=\"digest1\",\n        source_type=\"source_type1\",\n        source=\"source1\",\n    )\n    dataset_inputs1 = [DatasetInput(dataset=dataset1, tags=[InputTag(key=\"tag1\", value=\"value1\")])]\n\n    mlflow_client.log_inputs(run_id, dataset_inputs1)\n    run = mlflow_client.get_run(run_id)\n    assert len(run.inputs.dataset_inputs) == 1\n\n    assert isinstance(run.inputs, RunInputs)\n    assert isinstance(run.inputs.dataset_inputs[0], DatasetInput)\n    assert isinstance(run.inputs.dataset_inputs[0].dataset, Dataset)\n    assert run.inputs.dataset_inputs[0].dataset.name == \"name1\"\n    assert run.inputs.dataset_inputs[0].dataset.digest == \"digest1\"\n    assert run.inputs.dataset_inputs[0].dataset.source_type == \"source_type1\"\n    assert run.inputs.dataset_inputs[0].dataset.source == \"source1\"\n    assert len(run.inputs.dataset_inputs[0].tags) == 1\n    assert run.inputs.dataset_inputs[0].tags[0].key == \"tag1\"\n    assert run.inputs.dataset_inputs[0].tags[0].value == \"value1\"\n\n\ndef test_log_inputs_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log inputs validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/log-inputs\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    dataset = Dataset(\n        name=\"name1\",\n        digest=\"digest1\",\n        source_type=\"source_type1\",\n        source=\"source1\",\n    )\n    tags = [InputTag(key=\"tag1\", value=\"value1\")]\n    dataset_inputs = [message_to_json(DatasetInput(dataset=dataset, tags=tags).to_proto())]\n    assert_bad_request(\n        {\n            \"datasets\": dataset_inputs,\n        },\n        \"Missing value for required parameter 'run_id'\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n        },\n        \"Missing value for required parameter 'datasets'\",\n    )\n\n\ndef test_update_run_name_without_changing_status(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"update run name\")\n    created_run = mlflow_client.create_run(experiment_id)\n    mlflow_client.set_terminated(created_run.info.run_id, \"FINISHED\")\n\n    mlflow_client.update_run(created_run.info.run_id, name=\"name_abc\")\n    updated_run_info = mlflow_client.get_run(created_run.info.run_id).info\n    assert updated_run_info.run_name == \"name_abc\"\n    assert updated_run_info.status == \"FINISHED\"\n\n\ndef test_create_promptlab_run_handler_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={},\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify experiment_id.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\"experiment_id\": \"123\"},\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify prompt_template.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\"experiment_id\": \"123\", \"prompt_template\": \"my_prompt_template\"},\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify prompt_parameters.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": \"123\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n        },\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify model_route.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": \"123\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n            \"model_route\": \"my_route\",\n        },\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify model_input.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": \"123\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n            \"model_route\": \"my_route\",\n            \"model_input\": \"my_input\",\n        },\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify mlflow_version.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": \"123\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n            \"model_route\": \"my_route\",\n            \"model_input\": \"my_input\",\n            \"mlflow_version\": \"1.0.0\",\n        },\n    )\n\n\ndef test_create_promptlab_run_handler_returns_expected_results(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log inputs test\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": experiment_id,\n            \"run_name\": \"my_run_name\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n            \"model_route\": \"my_route\",\n            \"model_parameters\": [{\"key\": \"temperature\", \"value\": \"0.1\"}],\n            \"model_input\": \"my_input\",\n            \"model_output\": \"my_output\",\n            \"model_output_parameters\": [{\"key\": \"latency\", \"value\": \"100\"}],\n            \"mlflow_version\": \"1.0.0\",\n            \"user_id\": \"username\",\n            \"start_time\": 456,\n        },\n    )\n    assert response.status_code == 200\n    run_json = response.json()\n    assert run_json[\"run\"][\"info\"][\"run_name\"] == \"my_run_name\"\n    assert run_json[\"run\"][\"info\"][\"experiment_id\"] == experiment_id\n    assert run_json[\"run\"][\"info\"][\"user_id\"] == \"username\"\n    assert run_json[\"run\"][\"info\"][\"status\"] == \"FINISHED\"\n    assert run_json[\"run\"][\"info\"][\"start_time\"] == 456\n\n    assert {\"key\": \"model_route\", \"value\": \"my_route\"} in run_json[\"run\"][\"data\"][\"params\"]\n    assert {\"key\": \"prompt_template\", \"value\": \"my_prompt_template\"} in run_json[\"run\"][\"data\"][\n        \"params\"\n    ]\n    assert {\"key\": \"temperature\", \"value\": \"0.1\"} in run_json[\"run\"][\"data\"][\"params\"]\n\n    assert {\n        \"key\": \"mlflow.loggedArtifacts\",\n        \"value\": '[{\"path\": \"eval_results_table.json\", ' '\"type\": \"table\"}]',\n    } in run_json[\"run\"][\"data\"][\"tags\"]\n    assert {\"key\": \"mlflow.runSourceType\", \"value\": \"PROMPT_ENGINEERING\"} in run_json[\"run\"][\n        \"data\"\n    ][\"tags\"]\n\n\ndef test_gateway_proxy_handler_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    with _init_server(\n        backend_uri=mlflow_client.tracking_uri,\n        root_artifact_uri=mlflow_client.tracking_uri,\n        extra_env={\"MLFLOW_DEPLOYMENTS_TARGET\": \"http://localhost:5001\"},\n    ) as url:\n        patched_client = MlflowClient(url)\n\n        response = requests.post(\n            f\"{patched_client.tracking_uri}/ajax-api/2.0/mlflow/gateway-proxy\",\n            json={},\n        )\n        assert_response(\n            response,\n            \"Deployments proxy request must specify a gateway_path.\",\n        )\n\n\ndef test_upload_artifact_handler_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    experiment_id = mlflow_client.create_experiment(\"upload_artifacts_test\")\n    created_run = mlflow_client.create_run(experiment_id)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\", params={}\n    )\n    assert_response(response, \"Request must specify run_uuid.\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\n            \"run_uuid\": created_run.info.run_id,\n        },\n    )\n    assert_response(response, \"Request must specify path.\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\"run_uuid\": created_run.info.run_id, \"path\": \"\"},\n    )\n    assert_response(response, \"Request must specify path.\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\"run_uuid\": created_run.info.run_id, \"path\": \"../test.txt\"},\n    )\n    assert_response(response, \"Invalid path\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\n            \"run_uuid\": created_run.info.run_id,\n            \"path\": \"test.txt\",\n        },\n    )\n    assert_response(response, \"Request must specify data.\")\n\n\ndef test_upload_artifact_handler(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"upload_artifacts_test\")\n    created_run = mlflow_client.create_run(experiment_id)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\n            \"run_uuid\": created_run.info.run_id,\n            \"path\": \"test.txt\",\n        },\n        data=\"hello world\",\n    )\n    assert response.status_code == 200\n\n    response = requests.get(\n        f\"{mlflow_client.tracking_uri}/get-artifact\",\n        params={\n            \"run_uuid\": created_run.info.run_id,\n            \"path\": \"test.txt\",\n        },\n    )\n    assert response.status_code == 200\n    assert response.text == \"hello world\"\n", "import pathlib\nimport posixpath\n\nimport pytest\n\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.store.db.db_types import DATABASE_ENGINES\nfrom mlflow.utils.os import is_windows\nfrom mlflow.utils.uri import (\n    add_databricks_profile_info_to_artifact_uri,\n    append_to_uri_path,\n    append_to_uri_query_params,\n    dbfs_hdfs_uri_to_fuse_path,\n    extract_and_normalize_path,\n    extract_db_type_from_uri,\n    get_databricks_profile_uri_from_artifact_uri,\n    get_db_info_from_uri,\n    get_uri_scheme,\n    is_databricks_acled_artifacts_uri,\n    is_databricks_uri,\n    is_fuse_or_uc_volumes_uri,\n    is_http_uri,\n    is_local_uri,\n    is_valid_dbfs_uri,\n    remove_databricks_profile_info_from_artifact_uri,\n    resolve_uri_if_local,\n)\n\n\ndef test_extract_db_type_from_uri():\n    uri = \"{}://username:password@host:port/database\"\n    for legit_db in DATABASE_ENGINES:\n        assert legit_db == extract_db_type_from_uri(uri.format(legit_db))\n        assert legit_db == get_uri_scheme(uri.format(legit_db))\n\n        with_driver = legit_db + \"+driver-string\"\n        assert legit_db == extract_db_type_from_uri(uri.format(with_driver))\n        assert legit_db == get_uri_scheme(uri.format(with_driver))\n\n    for unsupported_db in [\"a\", \"aa\", \"sql\"]:\n        with pytest.raises(MlflowException, match=\"Invalid database engine\"):\n            extract_db_type_from_uri(unsupported_db)\n\n\n@pytest.mark.parametrize(\n    (\"server_uri\", \"result\"),\n    [\n        (\"databricks://aAbB\", (\"aAbB\", None)),\n        (\"databricks://aAbB/\", (\"aAbB\", None)),\n        (\"databricks://aAbB/path\", (\"aAbB\", None)),\n        (\"databricks://profile:prefix\", (\"profile\", \"prefix\")),\n        (\"databricks://profile:prefix/extra\", (\"profile\", \"prefix\")),\n        (\"nondatabricks://profile:prefix\", (None, None)),\n        (\"databricks://profile\", (\"profile\", None)),\n        (\"databricks://profile/\", (\"profile\", None)),\n        (\"databricks-uc://profile:prefix\", (\"profile\", \"prefix\")),\n        (\"databricks-uc://profile:prefix/extra\", (\"profile\", \"prefix\")),\n        (\"databricks-uc://profile\", (\"profile\", None)),\n        (\"databricks-uc://profile/\", (\"profile\", None)),\n    ],\n)\ndef test_get_db_info_from_uri(server_uri, result):\n    assert get_db_info_from_uri(server_uri) == result\n\n\n@pytest.mark.parametrize(\n    \"server_uri\",\n    [\"databricks:/profile:prefix\", \"databricks:/\", \"databricks://\"],\n)\ndef test_get_db_info_from_uri_errors_no_netloc(server_uri):\n    with pytest.raises(MlflowException, match=\"URI is formatted incorrectly\"):\n        get_db_info_from_uri(server_uri)\n\n\n@pytest.mark.parametrize(\n    \"server_uri\",\n    [\n        \"databricks://profile:prefix:extra\",\n        \"databricks://profile:prefix:extra  \",\n        \"databricks://profile:prefix extra\",\n        \"databricks://profile:prefix  \",\n        \"databricks://profile \",\n        \"databricks://profile:\",\n        \"databricks://profile: \",\n    ],\n)\ndef test_get_db_info_from_uri_errors_invalid_profile(server_uri):\n    with pytest.raises(MlflowException, match=\"Unsupported Databricks profile\"):\n        get_db_info_from_uri(server_uri)\n\n\ndef test_is_local_uri():\n    assert is_local_uri(\"mlruns\")\n    assert is_local_uri(\"./mlruns\")\n    assert is_local_uri(\"file:///foo/mlruns\")\n    assert is_local_uri(\"file:foo/mlruns\")\n    assert is_local_uri(\"file://./mlruns\")\n    assert is_local_uri(\"file://localhost/mlruns\")\n    assert is_local_uri(\"file://localhost:5000/mlruns\")\n    assert is_local_uri(\"file://127.0.0.1/mlruns\")\n    assert is_local_uri(\"file://127.0.0.1:5000/mlruns\")\n    assert is_local_uri(\"//proc/self/root\")\n    assert is_local_uri(\"/proc/self/root\")\n\n    assert not is_local_uri(\"file://myhostname/path/to/file\")\n    assert not is_local_uri(\"https://whatever\")\n    assert not is_local_uri(\"http://whatever\")\n    assert not is_local_uri(\"databricks\")\n    assert not is_local_uri(\"databricks:whatever\")\n    assert not is_local_uri(\"databricks://whatever\")\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"Windows-only test\")\ndef test_is_local_uri_windows():\n    assert is_local_uri(\"C:\\\\foo\\\\mlruns\")\n    assert is_local_uri(\"C:/foo/mlruns\")\n    assert is_local_uri(\"file:///C:\\\\foo\\\\mlruns\")\n    assert not is_local_uri(\"\\\\\\\\server\\\\aa\\\\bb\")\n\n\ndef test_is_databricks_uri():\n    assert is_databricks_uri(\"databricks\")\n    assert is_databricks_uri(\"databricks:whatever\")\n    assert is_databricks_uri(\"databricks://whatever\")\n    assert not is_databricks_uri(\"mlruns\")\n    assert not is_databricks_uri(\"http://whatever\")\n\n\ndef test_is_http_uri():\n    assert is_http_uri(\"http://whatever\")\n    assert is_http_uri(\"https://whatever\")\n    assert not is_http_uri(\"file://whatever\")\n    assert not is_http_uri(\"databricks://whatever\")\n    assert not is_http_uri(\"mlruns\")\n\n\ndef validate_append_to_uri_path_test_cases(cases):\n    for input_uri, input_path, expected_output_uri in cases:\n        assert append_to_uri_path(input_uri, input_path) == expected_output_uri\n        assert append_to_uri_path(input_uri, *posixpath.split(input_path)) == expected_output_uri\n\n\ndef test_append_to_uri_path_joins_uri_paths_and_posixpaths_correctly():\n    validate_append_to_uri_path_test_cases(\n        [\n            (\"\", \"path\", \"path\"),\n            (\"\", \"/path\", \"/path\"),\n            (\"path\", \"\", \"path/\"),\n            (\"path\", \"subpath\", \"path/subpath\"),\n            (\"path/\", \"subpath\", \"path/subpath\"),\n            (\"path/\", \"/subpath\", \"path/subpath\"),\n            (\"path\", \"/subpath\", \"path/subpath\"),\n            (\"/path\", \"/subpath\", \"/path/subpath\"),\n            (\"//path\", \"/subpath\", \"//path/subpath\"),\n            (\"///path\", \"/subpath\", \"///path/subpath\"),\n            (\"/path\", \"/subpath/subdir\", \"/path/subpath/subdir\"),\n            (\"file:path\", \"\", \"file:path/\"),\n            (\"file:path/\", \"\", \"file:path/\"),\n            (\"file:path\", \"subpath\", \"file:path/subpath\"),\n            (\"file:path\", \"/subpath\", \"file:path/subpath\"),\n            (\"file:/\", \"\", \"file:///\"),\n            (\"file:/path\", \"/subpath\", \"file:///path/subpath\"),\n            (\"file:///\", \"\", \"file:///\"),\n            (\"file:///\", \"subpath\", \"file:///subpath\"),\n            (\"file:///path\", \"/subpath\", \"file:///path/subpath\"),\n            (\"file:///path/\", \"subpath\", \"file:///path/subpath\"),\n            (\"file:///path\", \"subpath\", \"file:///path/subpath\"),\n            (\"s3://\", \"\", \"s3:\"),\n            (\"s3://\", \"subpath\", \"s3:subpath\"),\n            (\"s3://\", \"/subpath\", \"s3:/subpath\"),\n            (\"s3://host\", \"subpath\", \"s3://host/subpath\"),\n            (\"s3://host\", \"/subpath\", \"s3://host/subpath\"),\n            (\"s3://host/\", \"subpath\", \"s3://host/subpath\"),\n            (\"s3://host/\", \"/subpath\", \"s3://host/subpath\"),\n            (\"s3://host\", \"subpath/subdir\", \"s3://host/subpath/subdir\"),\n        ]\n    )\n\n\ndef test_append_to_uri_path_handles_special_uri_characters_in_posixpaths():\n    \"\"\"\n    Certain characters are treated specially when parsing and interpreting URIs. However, in the\n    case where a URI input for `append_to_uri_path` is simply a POSIX path, these characters should\n    not receive special treatment. This test case verifies that `append_to_uri_path` properly joins\n    POSIX paths containing these characters.\n    \"\"\"\n\n    def create_char_case(special_char):\n        def char_case(*case_args):\n            return tuple([item.format(c=special_char) for item in case_args])\n\n        return char_case\n\n    for special_char in [\n        \".\",\n        \"-\",\n        \"+\",\n        \":\",\n        \"?\",\n        \"@\",\n        \"&\",\n        \"$\",\n        \"%\",\n        \"/\",\n        \"[\",\n        \"]\",\n        \"(\",\n        \")\",\n        \"*\",\n        \"'\",\n        \",\",\n    ]:\n        char_case = create_char_case(special_char)\n        validate_append_to_uri_path_test_cases(\n            [\n                char_case(\"\", \"{c}subpath\", \"{c}subpath\"),\n                char_case(\"\", \"/{c}subpath\", \"/{c}subpath\"),\n                char_case(\"dirwith{c}{c}chars\", \"\", \"dirwith{c}{c}chars/\"),\n                char_case(\"dirwith{c}{c}chars\", \"subpath\", \"dirwith{c}{c}chars/subpath\"),\n                char_case(\"{c}{c}charsdir\", \"\", \"{c}{c}charsdir/\"),\n                char_case(\"/{c}{c}charsdir\", \"\", \"/{c}{c}charsdir/\"),\n                char_case(\"/{c}{c}charsdir\", \"subpath\", \"/{c}{c}charsdir/subpath\"),\n                char_case(\"/{c}{c}charsdir\", \"subpath\", \"/{c}{c}charsdir/subpath\"),\n            ]\n        )\n\n    validate_append_to_uri_path_test_cases(\n        [\n            (\"#?charsdir:\", \":?subpath#\", \"#?charsdir:/:?subpath#\"),\n            (\"/#--+charsdir.//:\", \"/../:?subpath#\", \"/#--+charsdir.//:/../:?subpath#\"),\n            (\"$@''(,\", \")]*%\", \"$@''(,/)]*%\"),\n        ]\n    )\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"existing_query_params\", \"query_params\", \"expected\"),\n    [\n        (\"https://example.com\", \"\", [(\"key\", \"value\")], \"https://example.com?key=value\"),\n        (\n            \"https://example.com\",\n            \"existing_key=existing_value\",\n            [(\"new_key\", \"new_value\")],\n            \"https://example.com?existing_key=existing_value&new_key=new_value\",\n        ),\n        (\n            \"https://example.com\",\n            \"\",\n            [(\"key1\", \"value1\"), (\"key2\", \"value2\"), (\"key3\", \"value3\")],\n            \"https://example.com?key1=value1&key2=value2&key3=value3\",\n        ),\n        (\n            \"https://example.com\",\n            \"\",\n            [(\"key\", \"value with spaces\"), (\"key2\", \"special#characters\")],\n            \"https://example.com?key=value+with+spaces&key2=special%23characters\",\n        ),\n        (\"\", \"\", [(\"key\", \"value\")], \"?key=value\"),\n        (\"https://example.com\", \"\", [], \"https://example.com\"),\n        (\n            \"https://example.com\",\n            \"\",\n            [(\"key1\", 123), (\"key2\", 456)],\n            \"https://example.com?key1=123&key2=456\",\n        ),\n        (\n            \"https://example.com?existing_key=existing_value\",\n            \"\",\n            [(\"existing_key\", \"new_value\"), (\"existing_key\", \"new_value_2\")],\n            \"https://example.com?existing_key=existing_value&existing_key=new_value&existing_key=new_value_2\",\n        ),\n        (\n            \"s3://bucket/key\",\n            \"prev1=foo&prev2=bar\",\n            [(\"param1\", \"value1\"), (\"param2\", \"value2\")],\n            \"s3://bucket/key?prev1=foo&prev2=bar&param1=value1&param2=value2\",\n        ),\n        (\n            \"s3://bucket/key?existing_param=existing_value\",\n            \"\",\n            [(\"new_param\", \"new_value\")],\n            \"s3://bucket/key?existing_param=existing_value&new_param=new_value\",\n        ),\n    ],\n)\ndef test_append_to_uri_query_params_appends_as_expected(\n    uri, existing_query_params, query_params, expected\n):\n    if existing_query_params:\n        uri += f\"?{existing_query_params}\"\n\n    result = append_to_uri_query_params(uri, *query_params)\n    assert result == expected\n\n\ndef test_append_to_uri_path_preserves_uri_schemes_hosts_queries_and_fragments():\n    validate_append_to_uri_path_test_cases(\n        [\n            (\"dbscheme+dbdriver:\", \"\", \"dbscheme+dbdriver:\"),\n            (\"dbscheme+dbdriver:\", \"subpath\", \"dbscheme+dbdriver:subpath\"),\n            (\"dbscheme+dbdriver:path\", \"subpath\", \"dbscheme+dbdriver:path/subpath\"),\n            (\"dbscheme+dbdriver://host/path\", \"/subpath\", \"dbscheme+dbdriver://host/path/subpath\"),\n            (\"dbscheme+dbdriver:///path\", \"subpath\", \"dbscheme+dbdriver:/path/subpath\"),\n            (\"dbscheme+dbdriver:?somequery\", \"subpath\", \"dbscheme+dbdriver:subpath?somequery\"),\n            (\"dbscheme+dbdriver:?somequery\", \"/subpath\", \"dbscheme+dbdriver:/subpath?somequery\"),\n            (\"dbscheme+dbdriver:/?somequery\", \"subpath\", \"dbscheme+dbdriver:/subpath?somequery\"),\n            (\"dbscheme+dbdriver://?somequery\", \"subpath\", \"dbscheme+dbdriver:subpath?somequery\"),\n            (\"dbscheme+dbdriver:///?somequery\", \"/subpath\", \"dbscheme+dbdriver:/subpath?somequery\"),\n            (\"dbscheme+dbdriver:#somefrag\", \"subpath\", \"dbscheme+dbdriver:subpath#somefrag\"),\n            (\"dbscheme+dbdriver:#somefrag\", \"/subpath\", \"dbscheme+dbdriver:/subpath#somefrag\"),\n            (\"dbscheme+dbdriver:/#somefrag\", \"subpath\", \"dbscheme+dbdriver:/subpath#somefrag\"),\n            (\"dbscheme+dbdriver://#somefrag\", \"subpath\", \"dbscheme+dbdriver:subpath#somefrag\"),\n            (\"dbscheme+dbdriver:///#somefrag\", \"/subpath\", \"dbscheme+dbdriver:/subpath#somefrag\"),\n            (\n                \"dbscheme+dbdriver://root:password?creds=creds\",\n                \"subpath\",\n                \"dbscheme+dbdriver://root:password/subpath?creds=creds\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password/path/?creds=creds\",\n                \"/subpath/anotherpath\",\n                \"dbscheme+dbdriver://root:password/path/subpath/anotherpath?creds=creds\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password///path/?creds=creds\",\n                \"subpath/anotherpath\",\n                \"dbscheme+dbdriver://root:password///path/subpath/anotherpath?creds=creds\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password///path/?creds=creds\",\n                \"/subpath\",\n                \"dbscheme+dbdriver://root:password///path/subpath?creds=creds\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password#myfragment\",\n                \"/subpath\",\n                \"dbscheme+dbdriver://root:password/subpath#myfragment\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password//path/#fragmentwith$pecial@\",\n                \"subpath/anotherpath\",\n                \"dbscheme+dbdriver://root:password//path/subpath/anotherpath#fragmentwith$pecial@\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password@host?creds=creds#fragmentwith$pecial@\",\n                \"subpath\",\n                \"dbscheme+dbdriver://root:password@host/subpath?creds=creds#fragmentwith$pecial@\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password@host.com/path?creds=creds#*frag@*\",\n                \"subpath/dir\",\n                \"dbscheme+dbdriver://root:password@host.com/path/subpath/dir?creds=creds#*frag@*\",\n            ),\n            (\n                \"dbscheme-dbdriver://root:password@host.com/path?creds=creds#*frag@*\",\n                \"subpath/dir\",\n                \"dbscheme-dbdriver://root:password@host.com/path/subpath/dir?creds=creds#*frag@*\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password@host.com/path?creds=creds,param=value#*frag@*\",\n                \"subpath/dir\",\n                \"dbscheme+dbdriver://root:password@host.com/path/subpath/dir?\"\n                \"creds=creds,param=value#*frag@*\",\n            ),\n        ]\n    )\n\n\ndef test_extract_and_normalize_path():\n    base_uri = \"databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\"\n    assert (\n        extract_and_normalize_path(\"dbfs:databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\")\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\"dbfs:/databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\")\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\"dbfs:///databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\")\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\n            \"dbfs:/databricks///mlflow-tracking///EXP_ID///RUN_ID///artifacts/\"\n        )\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\n            \"dbfs:///databricks///mlflow-tracking//EXP_ID//RUN_ID///artifacts//\"\n        )\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\n            \"dbfs:databricks///mlflow-tracking//EXP_ID//RUN_ID///artifacts//\"\n        )\n        == base_uri\n    )\n\n\ndef test_is_databricks_acled_artifacts_uri():\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:/databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:///databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:/databricks///mlflow-tracking///EXP_ID///RUN_ID///artifacts/\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:///databricks///mlflow-tracking//EXP_ID//RUN_ID///artifacts//\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:databricks///mlflow-tracking//EXP_ID//RUN_ID///artifacts//\"\n    )\n    assert not is_databricks_acled_artifacts_uri(\n        \"dbfs:/databricks/mlflow//EXP_ID//RUN_ID///artifacts//\"\n    )\n\n\ndef _get_databricks_profile_uri_test_cases():\n    # Each test case is (uri, result, result_scheme)\n    test_case_groups = [\n        [\n            # URIs with no databricks profile info -> return None\n            (\"ftp://user:pass@realhost:port/path/to/nowhere\", None, result_scheme),\n            (\"dbfs:/path/to/nowhere\", None, result_scheme),\n            (\"dbfs://nondatabricks/path/to/nowhere\", None, result_scheme),\n            (\"dbfs://incorrect:netloc:format/path/to/nowhere\", None, result_scheme),\n            # URIs with legit databricks profile info\n            (f\"dbfs://{result_scheme}\", result_scheme, result_scheme),\n            (f\"dbfs://{result_scheme}/\", result_scheme, result_scheme),\n            (f\"dbfs://{result_scheme}/path/to/nowhere\", result_scheme, result_scheme),\n            (f\"dbfs://{result_scheme}:port/path/to/nowhere\", result_scheme, result_scheme),\n            (f\"dbfs://@{result_scheme}/path/to/nowhere\", result_scheme, result_scheme),\n            (f\"dbfs://@{result_scheme}:port/path/to/nowhere\", result_scheme, result_scheme),\n            (\n                f\"dbfs://profile@{result_scheme}/path/to/nowhere\",\n                f\"{result_scheme}://profile\",\n                result_scheme,\n            ),\n            (\n                f\"dbfs://profile@{result_scheme}:port/path/to/nowhere\",\n                f\"{result_scheme}://profile\",\n                result_scheme,\n            ),\n            (\n                f\"dbfs://scope:key_prefix@{result_scheme}/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n            (\n                f\"dbfs://scope:key_prefix@{result_scheme}:port/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n            # Doesn't care about the scheme of the artifact URI\n            (\n                f\"runs://scope:key_prefix@{result_scheme}/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n            (\n                f\"models://scope:key_prefix@{result_scheme}/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n            (\n                f\"s3://scope:key_prefix@{result_scheme}/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n        ]\n        for result_scheme in [\"databricks\", \"databricks-uc\"]\n    ]\n    return [test_case for test_case_group in test_case_groups for test_case in test_case_group]\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"result\", \"result_scheme\"), _get_databricks_profile_uri_test_cases()\n)\ndef test_get_databricks_profile_uri_from_artifact_uri(uri, result, result_scheme):\n    assert get_databricks_profile_uri_from_artifact_uri(uri, result_scheme=result_scheme) == result\n\n\n@pytest.mark.parametrize(\n    \"uri\",\n    [\n        # Treats secret key prefixes with \":\" to be invalid\n        \"dbfs://incorrect:netloc:format@databricks/path/a\",\n        \"dbfs://scope::key_prefix@databricks/path/abc\",\n        \"dbfs://scope:key_prefix:@databricks/path/abc\",\n    ],\n)\ndef test_get_databricks_profile_uri_from_artifact_uri_error_cases(uri):\n    with pytest.raises(MlflowException, match=\"Unsupported Databricks profile\"):\n        get_databricks_profile_uri_from_artifact_uri(uri)\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"result\"),\n    [\n        # URIs with no databricks profile info should stay the same\n        (\n            \"ftp://user:pass@realhost:port/path/nowhere\",\n            \"ftp://user:pass@realhost:port/path/nowhere\",\n        ),\n        (\"dbfs:/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://nondatabricks/path/to/nowhere\", \"dbfs://nondatabricks/path/to/nowhere\"),\n        (\"dbfs://incorrect:netloc:format/path/\", \"dbfs://incorrect:netloc:format/path/\"),\n        # URIs with legit databricks profile info\n        (\"dbfs://databricks\", \"dbfs:\"),\n        (\"dbfs://databricks/\", \"dbfs:/\"),\n        (\"dbfs://databricks/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://databricks:port/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://@databricks/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://@databricks:port/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://profile@databricks/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://profile@databricks:port/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://scope:key_prefix@databricks/path/abc\", \"dbfs:/path/abc\"),\n        (\"dbfs://scope:key_prefix@databricks:port/path/abc\", \"dbfs:/path/abc\"),\n        # Treats secret key prefixes with \":\" to be valid\n        (\"dbfs://incorrect:netloc:format@databricks/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        # Doesn't care about the scheme of the artifact URI\n        (\"runs://scope:key_prefix@databricks/path/abc\", \"runs:/path/abc\"),\n        (\"models://scope:key_prefix@databricks/path/abc\", \"models:/path/abc\"),\n        (\"s3://scope:key_prefix@databricks/path/abc\", \"s3:/path/abc\"),\n    ],\n)\ndef test_remove_databricks_profile_info_from_artifact_uri(uri, result):\n    assert remove_databricks_profile_info_from_artifact_uri(uri) == result\n\n\n@pytest.mark.parametrize(\n    (\"artifact_uri\", \"profile_uri\", \"result\"),\n    [\n        # test various profile URIs\n        (\"dbfs:/path/a/b\", \"databricks\", \"dbfs://databricks/path/a/b\"),\n        (\"dbfs:/path/a/b/\", \"databricks\", \"dbfs://databricks/path/a/b/\"),\n        (\"dbfs:/path/a/b/\", \"databricks://Profile\", \"dbfs://Profile@databricks/path/a/b/\"),\n        (\"dbfs:/path/a/b/\", \"databricks://profile/\", \"dbfs://profile@databricks/path/a/b/\"),\n        (\"dbfs:/path/a/b/\", \"databricks://scope:key\", \"dbfs://scope:key@databricks/path/a/b/\"),\n        (\n            \"dbfs:/path/a/b/\",\n            \"databricks://scope:key/random_stuff\",\n            \"dbfs://scope:key@databricks/path/a/b/\",\n        ),\n        (\"dbfs:/path/a/b/\", \"nondatabricks://profile\", \"dbfs:/path/a/b/\"),\n        # test various artifact schemes\n        (\"runs:/path/a/b/\", \"databricks://Profile\", \"runs://Profile@databricks/path/a/b/\"),\n        (\"runs:/path/a/b/\", \"nondatabricks://profile\", \"runs:/path/a/b/\"),\n        (\"models:/path/a/b/\", \"databricks://profile\", \"models://profile@databricks/path/a/b/\"),\n        (\"models:/path/a/b/\", \"nondatabricks://Profile\", \"models:/path/a/b/\"),\n        (\"s3:/path/a/b/\", \"databricks://Profile\", \"s3:/path/a/b/\"),\n        (\"s3:/path/a/b/\", \"nondatabricks://profile\", \"s3:/path/a/b/\"),\n        (\"ftp:/path/a/b/\", \"databricks://profile\", \"ftp:/path/a/b/\"),\n        (\"ftp:/path/a/b/\", \"nondatabricks://Profile\", \"ftp:/path/a/b/\"),\n        # test artifact URIs already with authority\n        (\"ftp://user:pass@host:port/a/b\", \"databricks://Profile\", \"ftp://user:pass@host:port/a/b\"),\n        (\"ftp://user:pass@host:port/a/b\", \"nothing://Profile\", \"ftp://user:pass@host:port/a/b\"),\n        (\"dbfs://databricks\", \"databricks://OtherProfile\", \"dbfs://databricks\"),\n        (\"dbfs://databricks\", \"nondatabricks://Profile\", \"dbfs://databricks\"),\n        (\"dbfs://databricks/path/a/b\", \"databricks://OtherProfile\", \"dbfs://databricks/path/a/b\"),\n        (\"dbfs://databricks/path/a/b\", \"nondatabricks://Profile\", \"dbfs://databricks/path/a/b\"),\n        (\"dbfs://@databricks/path/a/b\", \"databricks://OtherProfile\", \"dbfs://@databricks/path/a/b\"),\n        (\"dbfs://@databricks/path/a/b\", \"nondatabricks://Profile\", \"dbfs://@databricks/path/a/b\"),\n        (\n            \"dbfs://profile@databricks/pp\",\n            \"databricks://OtherProfile\",\n            \"dbfs://profile@databricks/pp\",\n        ),\n        (\n            \"dbfs://profile@databricks/path\",\n            \"databricks://profile\",\n            \"dbfs://profile@databricks/path\",\n        ),\n        (\n            \"dbfs://profile@databricks/path\",\n            \"nondatabricks://Profile\",\n            \"dbfs://profile@databricks/path\",\n        ),\n    ],\n)\ndef test_add_databricks_profile_info_to_artifact_uri(artifact_uri, profile_uri, result):\n    assert add_databricks_profile_info_to_artifact_uri(artifact_uri, profile_uri) == result\n\n\n@pytest.mark.parametrize(\n    (\"artifact_uri\", \"profile_uri\"),\n    [\n        (\"dbfs:/path/a/b\", \"databricks://not:legit:auth\"),\n        (\"dbfs:/path/a/b/\", \"databricks://scope::key\"),\n        (\"dbfs:/path/a/b/\", \"databricks://scope:key:/\"),\n        (\"dbfs:/path/a/b/\", \"databricks://scope:key \"),\n    ],\n)\ndef test_add_databricks_profile_info_to_artifact_uri_errors(artifact_uri, profile_uri):\n    with pytest.raises(MlflowException, match=\"Unsupported Databricks profile\"):\n        add_databricks_profile_info_to_artifact_uri(artifact_uri, profile_uri)\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"result\"),\n    [\n        (\"dbfs:/path/a/b\", True),\n        (\"dbfs://databricks/a/b\", True),\n        (\"dbfs://@databricks/a/b\", True),\n        (\"dbfs://profile@databricks/a/b\", True),\n        (\"dbfs://scope:key@databricks/a/b\", True),\n        (\"dbfs://scope:key:@databricks/a/b\", False),\n        (\"dbfs://scope::key@databricks/a/b\", False),\n        (\"dbfs://profile@notdatabricks/a/b\", False),\n        (\"dbfs://scope:key@notdatabricks/a/b\", False),\n        (\"dbfs://scope:key/a/b\", False),\n        (\"dbfs://notdatabricks/a/b\", False),\n        (\"s3:/path/a/b\", False),\n        (\"ftp://user:pass@host:port/path/a/b\", False),\n        (\"ftp://user:pass@databricks/path/a/b\", False),\n    ],\n)\ndef test_is_valid_dbfs_uri(uri, result):\n    assert is_valid_dbfs_uri(uri) == result\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"result\"),\n    [\n        (\"/tmp/path\", \"/dbfs/tmp/path\"),\n        (\"dbfs:/path\", \"/dbfs/path\"),\n        (\"dbfs:/path/a/b\", \"/dbfs/path/a/b\"),\n        (\"dbfs:/dbfs/123/abc\", \"/dbfs/dbfs/123/abc\"),\n    ],\n)\ndef test_dbfs_hdfs_uri_to_fuse_path(uri, result):\n    assert dbfs_hdfs_uri_to_fuse_path(uri) == result\n\n\n@pytest.mark.parametrize(\n    \"path\",\n    [\"some/relative/local/path\", \"s3:/some/s3/path\", \"C:/cool/windows/path\"],\n)\ndef test_dbfs_hdfs_uri_to_fuse_path_raises(path):\n    with pytest.raises(MlflowException, match=\"did not start with expected DBFS URI prefix\"):\n        dbfs_hdfs_uri_to_fuse_path(path)\n\n\ndef _assert_resolve_uri_if_local(input_uri, expected_uri):\n    cwd = pathlib.Path.cwd().as_posix()\n    drive = pathlib.Path.cwd().drive\n    if is_windows():\n        cwd = f\"/{cwd}\"\n        drive = f\"{drive}/\"\n    assert resolve_uri_if_local(input_uri) == expected_uri.format(cwd=cwd, drive=drive)\n\n\n@pytest.mark.skipif(is_windows(), reason=\"This test fails on Windows\")\n@pytest.mark.parametrize(\n    (\"input_uri\", \"expected_uri\"),\n    [\n        (\"my/path\", \"{cwd}/my/path\"),\n        (\"#my/path?a=b\", \"{cwd}/#my/path?a=b\"),\n        (\"file://myhostname/my/path\", \"file://myhostname/my/path\"),\n        (\"file:///my/path\", \"file:///{drive}my/path\"),\n        (\"file:my/path\", \"file://{cwd}/my/path\"),\n        (\"/home/my/path\", \"/home/my/path\"),\n        (\"dbfs://databricks/a/b\", \"dbfs://databricks/a/b\"),\n        (\"s3://host/my/path\", \"s3://host/my/path\"),\n    ],\n)\ndef test_resolve_uri_if_local(input_uri, expected_uri):\n    _assert_resolve_uri_if_local(input_uri, expected_uri)\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"This test only passes on Windows\")\n@pytest.mark.parametrize(\n    (\"input_uri\", \"expected_uri\"),\n    [\n        (\"my/path\", \"file://{cwd}/my/path\"),\n        (\"#my/path?a=b\", \"file://{cwd}/#my/path?a=b\"),\n        (\"file://myhostname/my/path\", \"file://myhostname/my/path\"),\n        (\"file:///my/path\", \"file:///{drive}my/path\"),\n        (\"file:my/path\", \"file://{cwd}/my/path\"),\n        (\"/home/my/path\", \"file:///{drive}home/my/path\"),\n        (\"dbfs://databricks/a/b\", \"dbfs://databricks/a/b\"),\n        (\"s3://host/my/path\", \"s3://host/my/path\"),\n    ],\n)\ndef test_resolve_uri_if_local_on_windows(input_uri, expected_uri):\n    _assert_resolve_uri_if_local(input_uri, expected_uri)\n\n\n@pytest.mark.parametrize(\n    \"uri\",\n    [\n        \"/dbfs/my_path\",\n        \"dbfs:/my_path\",\n        \"/Volumes/my_path\",\n        \"/.fuse-mounts/my_path\",\n        \"//dbfs////my_path\",\n        \"///Volumes/\",\n        \"dbfs://my///path\",\n    ],\n)\ndef test_correctly_detect_fuse_and_uc_uris(uri):\n    assert is_fuse_or_uc_volumes_uri(uri)\n\n\n@pytest.mark.parametrize(\n    \"uri\",\n    [\n        \"/My_Volumes/my_path\",\n        \"s3a:/my_path\",\n        \"Volumes/my_path\",\n        \"Volume:/my_path\",\n        \"dbfs/my_path\",\n        \"/fuse-mounts/my_path\",\n    ],\n)\ndef test_negative_detection(uri):\n    assert not is_fuse_or_uc_volumes_uri(uri)\n"], "fixing_code": ["import os\nimport pathlib\nimport posixpath\nimport re\nimport urllib.parse\nimport uuid\nfrom typing import Any, Tuple\n\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import INVALID_PARAMETER_VALUE\nfrom mlflow.store.db.db_types import DATABASE_ENGINES\nfrom mlflow.utils.os import is_windows\nfrom mlflow.utils.validation import _validate_db_type_string\n\n_INVALID_DB_URI_MSG = (\n    \"Please refer to https://mlflow.org/docs/latest/tracking.html#storage for \"\n    \"format specifications.\"\n)\n\n_DBFS_FUSE_PREFIX = \"/dbfs/\"\n_DBFS_HDFS_URI_PREFIX = \"dbfs:/\"\n_UC_VOLUMES_URI_PREFIX = \"/Volumes/\"\n_UC_DBFS_SYMLINK_PREFIX = \"/.fuse-mounts/\"\n_DATABRICKS_UNITY_CATALOG_SCHEME = \"databricks-uc\"\n\n\ndef is_local_uri(uri, is_tracking_or_registry_uri=True):\n    \"\"\"\n    Returns true if the specified URI is a local file path (/foo or file:/foo).\n\n    :param uri: The URI.\n    :param is_tracking_uri: Whether or not the specified URI is an MLflow Tracking or MLflow\n                            Model Registry URI. Examples of other URIs are MLflow artifact URIs,\n                            filesystem paths, etc.\n    \"\"\"\n    if uri == \"databricks\" and is_tracking_or_registry_uri:\n        return False\n\n    if is_windows() and uri.startswith(\"\\\\\\\\\"):\n        # windows network drive path looks like: \"\\\\<server name>\\path\\...\"\n        return False\n\n    parsed_uri = urllib.parse.urlparse(uri)\n    scheme = parsed_uri.scheme\n    if scheme == \"\":\n        return True\n\n    if parsed_uri.hostname and not (\n        parsed_uri.hostname == \".\"\n        or parsed_uri.hostname.startswith(\"localhost\")\n        or parsed_uri.hostname.startswith(\"127.0.0.1\")\n    ):\n        return False\n\n    if scheme == \"file\":\n        return True\n\n    if is_windows() and len(scheme) == 1 and scheme.lower() == pathlib.Path(uri).drive.lower()[0]:\n        return True\n\n    return False\n\n\ndef is_file_uri(uri):\n    return urllib.parse.urlparse(uri).scheme == \"file\"\n\n\ndef is_http_uri(uri):\n    scheme = urllib.parse.urlparse(uri).scheme\n    return scheme == \"http\" or scheme == \"https\"\n\n\ndef is_databricks_uri(uri):\n    \"\"\"\n    Databricks URIs look like 'databricks' (default profile) or 'databricks://profile'\n    or 'databricks://secret_scope:secret_key_prefix'.\n    \"\"\"\n    scheme = urllib.parse.urlparse(uri).scheme\n    return scheme == \"databricks\" or uri == \"databricks\"\n\n\ndef is_fuse_or_uc_volumes_uri(uri):\n    \"\"\"\n    Validates whether a provided URI is directed to a FUSE mount point or a UC volumes mount point.\n    Multiple directory paths are collapsed into a single designator for root path validation.\n    example:\n    \"////Volumes/\" will resolve to \"/Volumes/\" for validation purposes.\n    \"\"\"\n    resolved_uri = re.sub(\"/+\", \"/\", uri)\n    return any(\n        resolved_uri.startswith(x)\n        for x in [\n            _DBFS_FUSE_PREFIX,\n            _DBFS_HDFS_URI_PREFIX,\n            _UC_VOLUMES_URI_PREFIX,\n            _UC_DBFS_SYMLINK_PREFIX,\n        ]\n    )\n\n\ndef is_databricks_unity_catalog_uri(uri):\n    scheme = urllib.parse.urlparse(uri).scheme\n    return scheme == _DATABRICKS_UNITY_CATALOG_SCHEME or uri == _DATABRICKS_UNITY_CATALOG_SCHEME\n\n\ndef construct_db_uri_from_profile(profile):\n    if profile:\n        return \"databricks://\" + profile\n\n\n# Both scope and key_prefix should not contain special chars for URIs, like '/'\n# and ':'.\ndef validate_db_scope_prefix_info(scope, prefix):\n    for c in [\"/\", \":\", \" \"]:\n        if c in scope:\n            raise MlflowException(\n                f\"Unsupported Databricks profile name: {scope}.\"\n                f\" Profile names cannot contain '{c}'.\"\n            )\n        if prefix and c in prefix:\n            raise MlflowException(\n                f\"Unsupported Databricks profile key prefix: {prefix}.\"\n                f\" Key prefixes cannot contain '{c}'.\"\n            )\n    if prefix is not None and prefix.strip() == \"\":\n        raise MlflowException(\n            f\"Unsupported Databricks profile key prefix: '{prefix}'.\"\n            \" Key prefixes cannot be empty.\"\n        )\n\n\ndef get_db_info_from_uri(uri):\n    \"\"\"\n    Get the Databricks profile specified by the tracking URI (if any), otherwise\n    returns None.\n    \"\"\"\n    parsed_uri = urllib.parse.urlparse(uri)\n    if parsed_uri.scheme == \"databricks\" or parsed_uri.scheme == _DATABRICKS_UNITY_CATALOG_SCHEME:\n        # netloc should not be an empty string unless URI is formatted incorrectly.\n        if parsed_uri.netloc == \"\":\n            raise MlflowException(\n                f\"URI is formatted incorrectly: no netloc in URI '{uri}'.\"\n                \" This may be the case if there is only one slash in the URI.\"\n            )\n        profile_tokens = parsed_uri.netloc.split(\":\")\n        parsed_scope = profile_tokens[0]\n        if len(profile_tokens) == 1:\n            parsed_key_prefix = None\n        elif len(profile_tokens) == 2:\n            parsed_key_prefix = profile_tokens[1]\n        else:\n            # parse the content before the first colon as the profile.\n            parsed_key_prefix = \":\".join(profile_tokens[1:])\n        validate_db_scope_prefix_info(parsed_scope, parsed_key_prefix)\n        return parsed_scope, parsed_key_prefix\n    return None, None\n\n\ndef get_databricks_profile_uri_from_artifact_uri(uri, result_scheme=\"databricks\"):\n    \"\"\"\n    Retrieves the netloc portion of the URI as a ``databricks://`` or `databricks-uc://` URI,\n    if it is a proper Databricks profile specification, e.g.\n    ``profile@databricks`` or ``secret_scope:key_prefix@databricks``.\n    \"\"\"\n    parsed = urllib.parse.urlparse(uri)\n    if not parsed.netloc or parsed.hostname != result_scheme:\n        return None\n    if not parsed.username:  # no profile or scope:key\n        return result_scheme  # the default tracking/registry URI\n    validate_db_scope_prefix_info(parsed.username, parsed.password)\n    key_prefix = \":\" + parsed.password if parsed.password else \"\"\n    return f\"{result_scheme}://\" + parsed.username + key_prefix\n\n\ndef remove_databricks_profile_info_from_artifact_uri(artifact_uri):\n    \"\"\"\n    Only removes the netloc portion of the URI if it is a Databricks\n    profile specification, e.g.\n    ``profile@databricks`` or ``secret_scope:key_prefix@databricks``.\n    \"\"\"\n    parsed = urllib.parse.urlparse(artifact_uri)\n    if not parsed.netloc or parsed.hostname != \"databricks\":\n        return artifact_uri\n    return urllib.parse.urlunparse(parsed._replace(netloc=\"\"))\n\n\ndef add_databricks_profile_info_to_artifact_uri(artifact_uri, databricks_profile_uri):\n    \"\"\"\n    Throws an exception if ``databricks_profile_uri`` is not valid.\n    \"\"\"\n    if not databricks_profile_uri or not is_databricks_uri(databricks_profile_uri):\n        return artifact_uri\n    artifact_uri_parsed = urllib.parse.urlparse(artifact_uri)\n    # Do not overwrite the authority section if there is already one\n    if artifact_uri_parsed.netloc:\n        return artifact_uri\n\n    scheme = artifact_uri_parsed.scheme\n    if scheme == \"dbfs\" or scheme == \"runs\" or scheme == \"models\":\n        if databricks_profile_uri == \"databricks\":\n            netloc = \"databricks\"\n        else:\n            (profile, key_prefix) = get_db_info_from_uri(databricks_profile_uri)\n            prefix = \":\" + key_prefix if key_prefix else \"\"\n            netloc = profile + prefix + \"@databricks\"\n        new_parsed = artifact_uri_parsed._replace(netloc=netloc)\n        return urllib.parse.urlunparse(new_parsed)\n    else:\n        return artifact_uri\n\n\ndef extract_db_type_from_uri(db_uri):\n    \"\"\"\n    Parse the specified DB URI to extract the database type. Confirm the database type is\n    supported. If a driver is specified, confirm it passes a plausible regex.\n    \"\"\"\n    scheme = urllib.parse.urlparse(db_uri).scheme\n    scheme_plus_count = scheme.count(\"+\")\n\n    if scheme_plus_count == 0:\n        db_type = scheme\n    elif scheme_plus_count == 1:\n        db_type, _ = scheme.split(\"+\")\n    else:\n        error_msg = f\"Invalid database URI: '{db_uri}'. {_INVALID_DB_URI_MSG}\"\n        raise MlflowException(error_msg, INVALID_PARAMETER_VALUE)\n\n    _validate_db_type_string(db_type)\n\n    return db_type\n\n\ndef get_uri_scheme(uri_or_path):\n    scheme = urllib.parse.urlparse(uri_or_path).scheme\n    if any(scheme.lower().startswith(db) for db in DATABASE_ENGINES):\n        return extract_db_type_from_uri(uri_or_path)\n    return scheme\n\n\ndef extract_and_normalize_path(uri):\n    parsed_uri_path = urllib.parse.urlparse(uri).path\n    normalized_path = posixpath.normpath(parsed_uri_path)\n    return normalized_path.lstrip(\"/\")\n\n\ndef append_to_uri_path(uri, *paths):\n    \"\"\"\n    Appends the specified POSIX `paths` to the path component of the specified `uri`.\n\n    :param uri: The input URI, represented as a string.\n    :param paths: The POSIX paths to append to the specified `uri`'s path component.\n    :return: A new URI with a path component consisting of the specified `paths` appended to\n             the path component of the specified `uri`.\n\n    >>> uri1 = \"s3://root/base/path?param=value\"\n    >>> uri1 = append_to_uri_path(uri1, \"some/subpath\", \"/anotherpath\")\n    >>> assert uri1 == \"s3://root/base/path/some/subpath/anotherpath?param=value\"\n    >>> uri2 = \"a/posix/path\"\n    >>> uri2 = append_to_uri_path(uri2, \"/some\", \"subpath\")\n    >>> assert uri2 == \"a/posixpath/some/subpath\"\n    \"\"\"\n    path = \"\"\n    for subpath in paths:\n        path = _join_posixpaths_and_append_absolute_suffixes(path, subpath)\n\n    parsed_uri = urllib.parse.urlparse(uri)\n    if len(parsed_uri.scheme) == 0:\n        # If the input URI does not define a scheme, we assume that it is a POSIX path\n        # and join it with the specified input paths\n        return _join_posixpaths_and_append_absolute_suffixes(uri, path)\n\n    prefix = \"\"\n    if not parsed_uri.path.startswith(\"/\"):\n        # For certain URI schemes (e.g., \"file:\"), urllib's unparse routine does\n        # not preserve the relative URI path component properly. In certain cases,\n        # urlunparse converts relative paths to absolute paths. We introduce this logic\n        # to circumvent urlunparse's erroneous conversion\n        prefix = parsed_uri.scheme + \":\"\n        parsed_uri = parsed_uri._replace(scheme=\"\")\n\n    new_uri_path = _join_posixpaths_and_append_absolute_suffixes(parsed_uri.path, path)\n    new_parsed_uri = parsed_uri._replace(path=new_uri_path)\n    return prefix + urllib.parse.urlunparse(new_parsed_uri)\n\n\ndef append_to_uri_query_params(uri, *query_params: Tuple[str, Any]) -> str:\n    \"\"\"\n    Appends the specified query parameters to an existing URI.\n\n    :param uri: The URI to which to append query parameters.\n    :param query_params: Query parameters to append. Each parameter should\n                         be a 2-element tuple. For example, ``(\"key\", \"value\")``.\n    \"\"\"\n    parsed_uri = urllib.parse.urlparse(uri)\n    parsed_query = urllib.parse.parse_qsl(parsed_uri.query)\n    new_parsed_query = parsed_query + list(query_params)\n    new_query = urllib.parse.urlencode(new_parsed_query)\n    new_parsed_uri = parsed_uri._replace(query=new_query)\n    return urllib.parse.urlunparse(new_parsed_uri)\n\n\ndef _join_posixpaths_and_append_absolute_suffixes(prefix_path, suffix_path):\n    \"\"\"\n    Joins the POSIX path `prefix_path` with the POSIX path `suffix_path`. Unlike posixpath.join(),\n    if `suffix_path` is an absolute path, it is appended to prefix_path.\n\n    >>> result1 = _join_posixpaths_and_append_absolute_suffixes(\"relpath1\", \"relpath2\")\n    >>> assert result1 == \"relpath1/relpath2\"\n    >>> result2 = _join_posixpaths_and_append_absolute_suffixes(\"relpath\", \"/absolutepath\")\n    >>> assert result2 == \"relpath/absolutepath\"\n    >>> result3 = _join_posixpaths_and_append_absolute_suffixes(\"/absolutepath\", \"relpath\")\n    >>> assert result3 == \"/absolutepath/relpath\"\n    >>> result4 = _join_posixpaths_and_append_absolute_suffixes(\"/absolutepath1\", \"/absolutepath2\")\n    >>> assert result4 == \"/absolutepath1/absolutepath2\"\n    \"\"\"\n    if len(prefix_path) == 0:\n        return suffix_path\n\n    # If the specified prefix path is non-empty, we must relativize the suffix path by removing\n    # the leading slash, if present. Otherwise, posixpath.join() would omit the prefix from the\n    # joined path\n    suffix_path = suffix_path.lstrip(posixpath.sep)\n    return posixpath.join(prefix_path, suffix_path)\n\n\ndef is_databricks_acled_artifacts_uri(artifact_uri):\n    _ACLED_ARTIFACT_URI = \"databricks/mlflow-tracking/\"\n    artifact_uri_path = extract_and_normalize_path(artifact_uri)\n    return artifact_uri_path.startswith(_ACLED_ARTIFACT_URI)\n\n\ndef is_databricks_model_registry_artifacts_uri(artifact_uri):\n    _MODEL_REGISTRY_ARTIFACT_URI = \"databricks/mlflow-registry/\"\n    artifact_uri_path = extract_and_normalize_path(artifact_uri)\n    return artifact_uri_path.startswith(_MODEL_REGISTRY_ARTIFACT_URI)\n\n\ndef is_valid_dbfs_uri(uri):\n    parsed = urllib.parse.urlparse(uri)\n    if parsed.scheme != \"dbfs\":\n        return False\n    try:\n        db_profile_uri = get_databricks_profile_uri_from_artifact_uri(uri)\n    except MlflowException:\n        db_profile_uri = None\n    return not parsed.netloc or db_profile_uri is not None\n\n\ndef dbfs_hdfs_uri_to_fuse_path(dbfs_uri):\n    \"\"\"\n    Converts the provided DBFS URI into a DBFS FUSE path\n    :param dbfs_uri: A DBFS URI like \"dbfs:/my-directory\". Can also be a scheme-less URI like\n                     \"/my-directory\" if running in an environment where the default HDFS filesystem\n                     is \"dbfs:/\" (e.g. Databricks)\n    :return A DBFS FUSE-style path, e.g. \"/dbfs/my-directory\"\n    \"\"\"\n    if not is_valid_dbfs_uri(dbfs_uri) and dbfs_uri == posixpath.abspath(dbfs_uri):\n        # Convert posixpaths (e.g. \"/tmp/mlflow\") to DBFS URIs by adding \"dbfs:/\" as a prefix\n        dbfs_uri = \"dbfs:\" + dbfs_uri\n    if not dbfs_uri.startswith(_DBFS_HDFS_URI_PREFIX):\n        raise MlflowException(\n            f\"Path '{dbfs_uri}' did not start with expected DBFS URI \"\n            f\"prefix '{_DBFS_HDFS_URI_PREFIX}'\",\n        )\n\n    return _DBFS_FUSE_PREFIX + dbfs_uri[len(_DBFS_HDFS_URI_PREFIX) :]\n\n\ndef resolve_uri_if_local(local_uri):\n    \"\"\"\n    if `local_uri` is passed in as a relative local path, this function\n    resolves it to absolute path relative to current working directory.\n\n    :param local_uri: Relative or absolute path or local file uri\n\n    :return: a fully-formed absolute uri path or an absolute filesystem path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    if local_uri is not None and is_local_uri(local_uri):\n        scheme = get_uri_scheme(local_uri)\n        cwd = pathlib.Path.cwd()\n        local_path = local_file_uri_to_path(local_uri)\n        if not pathlib.Path(local_path).is_absolute():\n            if scheme == \"\":\n                if is_windows():\n                    return urllib.parse.urlunsplit(\n                        (\n                            \"file\",\n                            None,\n                            cwd.joinpath(local_path).as_posix(),\n                            None,\n                            None,\n                        )\n                    )\n                return cwd.joinpath(local_path).as_posix()\n            local_uri_split = urllib.parse.urlsplit(local_uri)\n            return urllib.parse.urlunsplit(\n                (\n                    local_uri_split.scheme,\n                    None,\n                    cwd.joinpath(local_path).as_posix(),\n                    local_uri_split.query,\n                    local_uri_split.fragment,\n                )\n            )\n    return local_uri\n\n\ndef generate_tmp_dfs_path(dfs_tmp):\n    return posixpath.join(dfs_tmp, str(uuid.uuid4()))\n\n\ndef join_paths(*paths: str) -> str:\n    stripped = (p.strip(\"/\") for p in paths)\n    return \"/\" + posixpath.normpath(posixpath.join(*stripped))\n\n\n_OS_ALT_SEPS = [sep for sep in [os.sep, os.path.altsep] if sep is not None and sep != \"/\"]\n\n\ndef validate_path_is_safe(path):\n    \"\"\"\n    Validates that the specified path is safe to join with a trusted prefix. This is a security\n    measure to prevent path traversal attacks.\n    A valid path should:\n        not contain separators other than '/'\n        not contain .. to navigate to parent dir in path\n        not be an absolute path\n    \"\"\"\n    from mlflow.utils.file_utils import local_file_uri_to_path\n\n    # We must decode URL before validating it\n    path = urllib.parse.unquote(path)\n\n    exc = MlflowException(\"Invalid path\", error_code=INVALID_PARAMETER_VALUE)\n    if any((s in path) for s in (\"#\", \"%23\")):\n        raise exc\n\n    if is_file_uri(path):\n        path = local_file_uri_to_path(path)\n    if (\n        any((s in path) for s in _OS_ALT_SEPS)\n        or \"..\" in path.split(\"/\")\n        or pathlib.PureWindowsPath(path).is_absolute()\n        or pathlib.PurePosixPath(path).is_absolute()\n        or (is_windows() and len(path) >= 2 and path[1] == \":\")\n    ):\n        raise exc\n", "import json\nimport uuid\nfrom unittest import mock\n\nimport pytest\n\nimport mlflow\nfrom mlflow.entities import ViewType\nfrom mlflow.entities.model_registry import (\n    ModelVersion,\n    ModelVersionTag,\n    RegisteredModel,\n    RegisteredModelTag,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.protos.databricks_pb2 import INTERNAL_ERROR, INVALID_PARAMETER_VALUE, ErrorCode\nfrom mlflow.protos.model_registry_pb2 import (\n    CreateModelVersion,\n    CreateRegisteredModel,\n    DeleteModelVersion,\n    DeleteModelVersionTag,\n    DeleteRegisteredModel,\n    DeleteRegisteredModelAlias,\n    DeleteRegisteredModelTag,\n    GetLatestVersions,\n    GetModelVersion,\n    GetModelVersionByAlias,\n    GetModelVersionDownloadUri,\n    GetRegisteredModel,\n    RenameRegisteredModel,\n    SearchModelVersions,\n    SearchRegisteredModels,\n    SetModelVersionTag,\n    SetRegisteredModelAlias,\n    SetRegisteredModelTag,\n    TransitionModelVersionStage,\n    UpdateModelVersion,\n    UpdateRegisteredModel,\n)\nfrom mlflow.protos.service_pb2 import CreateExperiment, SearchRuns\nfrom mlflow.server import BACKEND_STORE_URI_ENV_VAR, SERVE_ARTIFACTS_ENV_VAR, app\nfrom mlflow.server.handlers import (\n    _create_experiment,\n    _create_model_version,\n    _create_registered_model,\n    _delete_artifact_mlflow_artifacts,\n    _delete_model_version,\n    _delete_model_version_tag,\n    _delete_registered_model,\n    _delete_registered_model_alias,\n    _delete_registered_model_tag,\n    _get_latest_versions,\n    _get_model_version,\n    _get_model_version_by_alias,\n    _get_model_version_download_uri,\n    _get_registered_model,\n    _get_request_message,\n    _log_batch,\n    _rename_registered_model,\n    _search_model_versions,\n    _search_registered_models,\n    _search_runs,\n    _set_model_version_tag,\n    _set_registered_model_alias,\n    _set_registered_model_tag,\n    _transition_stage,\n    _update_model_version,\n    _update_registered_model,\n    catch_mlflow_exception,\n    get_endpoints,\n)\nfrom mlflow.store.entities.paged_list import PagedList\nfrom mlflow.store.model_registry import (\n    SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,\n    SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,\n)\nfrom mlflow.utils.proto_json_utils import message_to_json\nfrom mlflow.utils.validation import MAX_BATCH_LOG_REQUEST_SIZE\n\n\n@pytest.fixture\ndef mock_get_request_message():\n    with mock.patch(\"mlflow.server.handlers._get_request_message\") as m:\n        yield m\n\n\n@pytest.fixture\ndef mock_get_request_json():\n    with mock.patch(\"mlflow.server.handlers._get_request_json\") as m:\n        yield m\n\n\n@pytest.fixture\ndef mock_tracking_store():\n    with mock.patch(\"mlflow.server.handlers._get_tracking_store\") as m:\n        mock_store = mock.MagicMock()\n        m.return_value = mock_store\n        yield mock_store\n\n\n@pytest.fixture\ndef mock_model_registry_store():\n    with mock.patch(\"mlflow.server.handlers._get_model_registry_store\") as m:\n        mock_store = mock.MagicMock()\n        m.return_value = mock_store\n        yield mock_store\n\n\n@pytest.fixture\ndef enable_serve_artifacts(monkeypatch):\n    monkeypatch.setenv(SERVE_ARTIFACTS_ENV_VAR, \"true\")\n\n\ndef test_health():\n    with app.test_client() as c:\n        response = c.get(\"/health\")\n        assert response.status_code == 200\n        assert response.get_data().decode() == \"OK\"\n\n\ndef test_version():\n    with app.test_client() as c:\n        response = c.get(\"/version\")\n        assert response.status_code == 200\n        assert response.get_data().decode() == mlflow.__version__\n\n\ndef test_get_endpoints():\n    endpoints = get_endpoints()\n    create_experiment_endpoint = [e for e in endpoints if e[1] == _create_experiment]\n    assert len(create_experiment_endpoint) == 2\n\n\ndef test_all_model_registry_endpoints_available():\n    endpoints = {handler: method for (path, handler, method) in get_endpoints()}\n\n    # Test that each of the handler is enabled as an endpoint with appropriate method.\n    expected_endpoints = {\n        \"POST\": [\n            _create_registered_model,\n            _create_model_version,\n            _rename_registered_model,\n            _transition_stage,\n        ],\n        \"PATCH\": [_update_registered_model, _update_model_version],\n        \"DELETE\": [_delete_registered_model, _delete_registered_model],\n        \"GET\": [\n            _search_model_versions,\n            _get_latest_versions,\n            _get_registered_model,\n            _get_model_version,\n            _get_model_version_download_uri,\n        ],\n    }\n    # TODO: efficient mechanism to test endpoint path\n    for method, handlers in expected_endpoints.items():\n        for handler in handlers:\n            assert handler in endpoints\n            assert endpoints[handler] == [method]\n\n\ndef test_can_parse_json():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"application/json\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\"}\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello\"\n\n\ndef test_can_parse_post_json_with_unknown_fields():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"application/json\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\", \"WHAT IS THIS FIELD EVEN\": \"DOING\"}\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello\"\n\n\ndef test_can_parse_post_json_with_content_type_params():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"application/json; charset=utf-8\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\"}\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello\"\n\n\ndef test_can_parse_get_json_with_unknown_fields():\n    request = mock.MagicMock()\n    request.method = \"GET\"\n    request.query_string = b\"name=hello&superDuperUnknown=field\"\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello\"\n\n\n# Previous versions of the client sent a doubly string encoded JSON blob,\n# so this test ensures continued compliance with such clients.\ndef test_can_parse_json_string():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"application/json\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = '{\"name\": \"hello2\"}'\n    msg = _get_request_message(CreateExperiment(), flask_request=request)\n    assert msg.name == \"hello2\"\n\n\ndef test_can_block_post_request_with_invalid_content_type():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = \"text/plain\"\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\"}\n    with pytest.raises(MlflowException, match=r\"Bad Request. Content-Type\"):\n        _get_request_message(CreateExperiment(), flask_request=request)\n\n\ndef test_can_block_post_request_with_missing_content_type():\n    request = mock.MagicMock()\n    request.method = \"POST\"\n    request.content_type = None\n    request.get_json = mock.MagicMock()\n    request.get_json.return_value = {\"name\": \"hello\"}\n    with pytest.raises(MlflowException, match=r\"Bad Request. Content-Type\"):\n        _get_request_message(CreateExperiment(), flask_request=request)\n\n\ndef test_search_runs_default_view_type(mock_get_request_message, mock_tracking_store):\n    \"\"\"\n    Search Runs default view type is filled in as ViewType.ACTIVE_ONLY\n    \"\"\"\n    mock_get_request_message.return_value = SearchRuns(experiment_ids=[\"0\"])\n    mock_tracking_store.search_runs.return_value = PagedList([], None)\n    _search_runs()\n    args, _ = mock_tracking_store.search_runs.call_args\n    assert args[2] == ViewType.ACTIVE_ONLY\n\n\ndef test_log_batch_api_req(mock_get_request_json):\n    mock_get_request_json.return_value = \"a\" * (MAX_BATCH_LOG_REQUEST_SIZE + 1)\n    response = _log_batch()\n    assert response.status_code == 400\n    json_response = json.loads(response.get_data())\n    assert json_response[\"error_code\"] == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    assert (\n        f\"Batched logging API requests must be at most {MAX_BATCH_LOG_REQUEST_SIZE} bytes\"\n        in json_response[\"message\"]\n    )\n\n\ndef test_catch_mlflow_exception():\n    @catch_mlflow_exception\n    def test_handler():\n        raise MlflowException(\"test error\", error_code=INTERNAL_ERROR)\n\n    # pylint: disable=assignment-from-no-return\n    response = test_handler()\n    json_response = json.loads(response.get_data())\n    assert response.status_code == 500\n    assert json_response[\"error_code\"] == ErrorCode.Name(INTERNAL_ERROR)\n    assert json_response[\"message\"] == \"test error\"\n\n\ndef test_mlflow_server_with_installed_plugin(tmp_path, monkeypatch):\n    \"\"\"This test requires the package in tests/resources/mlflow-test-plugin to be installed\"\"\"\n    from mlflow_test_plugin.file_store import PluginFileStore\n\n    monkeypatch.setenv(BACKEND_STORE_URI_ENV_VAR, f\"file-plugin:{tmp_path}\")\n    monkeypatch.setattr(mlflow.server.handlers, \"_tracking_store\", None)\n    plugin_file_store = mlflow.server.handlers._get_tracking_store()\n    assert isinstance(plugin_file_store, PluginFileStore)\n    assert plugin_file_store.is_plugin\n\n\ndef jsonify(obj):\n    def _jsonify(obj):\n        return json.loads(message_to_json(obj.to_proto()))\n\n    if isinstance(obj, list):\n        return [_jsonify(o) for o in obj]\n    else:\n        return _jsonify(obj)\n\n\n# Tests for Model Registry handlers\ndef test_create_registered_model(mock_get_request_message, mock_model_registry_store):\n    tags = [\n        RegisteredModelTag(key=\"key\", value=\"value\"),\n        RegisteredModelTag(key=\"anotherKey\", value=\"some other value\"),\n    ]\n    mock_get_request_message.return_value = CreateRegisteredModel(\n        name=\"model_1\", tags=[tag.to_proto() for tag in tags]\n    )\n    rm = RegisteredModel(\"model_1\", tags=tags)\n    mock_model_registry_store.create_registered_model.return_value = rm\n    resp = _create_registered_model()\n    _, args = mock_model_registry_store.create_registered_model.call_args\n    assert args[\"name\"] == \"model_1\"\n    assert {tag.key: tag.value for tag in args[\"tags\"]} == {tag.key: tag.value for tag in tags}\n    assert json.loads(resp.get_data()) == {\"registered_model\": jsonify(rm)}\n\n\ndef test_get_registered_model(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    mock_get_request_message.return_value = GetRegisteredModel(name=name)\n    rmd = RegisteredModel(\n        name=name,\n        creation_timestamp=111,\n        last_updated_timestamp=222,\n        description=\"Test model\",\n        latest_versions=[],\n    )\n    mock_model_registry_store.get_registered_model.return_value = rmd\n    resp = _get_registered_model()\n    _, args = mock_model_registry_store.get_registered_model.call_args\n    assert args == {\"name\": name}\n    assert json.loads(resp.get_data()) == {\"registered_model\": jsonify(rmd)}\n\n\ndef test_update_registered_model(mock_get_request_message, mock_model_registry_store):\n    name = \"model_1\"\n    description = \"Test model\"\n    mock_get_request_message.return_value = UpdateRegisteredModel(\n        name=name, description=description\n    )\n    rm2 = RegisteredModel(name, description=description)\n    mock_model_registry_store.update_registered_model.return_value = rm2\n    resp = _update_registered_model()\n    _, args = mock_model_registry_store.update_registered_model.call_args\n    assert args == {\"name\": name, \"description\": \"Test model\"}\n    assert json.loads(resp.get_data()) == {\"registered_model\": jsonify(rm2)}\n\n\ndef test_rename_registered_model(mock_get_request_message, mock_model_registry_store):\n    name = \"model_1\"\n    new_name = \"model_2\"\n    mock_get_request_message.return_value = RenameRegisteredModel(name=name, new_name=new_name)\n    rm2 = RegisteredModel(new_name)\n    mock_model_registry_store.rename_registered_model.return_value = rm2\n    resp = _rename_registered_model()\n    _, args = mock_model_registry_store.rename_registered_model.call_args\n    assert args == {\"name\": name, \"new_name\": new_name}\n    assert json.loads(resp.get_data()) == {\"registered_model\": jsonify(rm2)}\n\n\ndef test_delete_registered_model(mock_get_request_message, mock_model_registry_store):\n    name = \"model_1\"\n    mock_get_request_message.return_value = DeleteRegisteredModel(name=name)\n    _delete_registered_model()\n    _, args = mock_model_registry_store.delete_registered_model.call_args\n    assert args == {\"name\": name}\n\n\ndef test_search_registered_models(mock_get_request_message, mock_model_registry_store):\n    rmds = [\n        RegisteredModel(\n            name=\"model_1\",\n            creation_timestamp=111,\n            last_updated_timestamp=222,\n            description=\"Test model\",\n            latest_versions=[],\n        ),\n        RegisteredModel(\n            name=\"model_2\",\n            creation_timestamp=111,\n            last_updated_timestamp=333,\n            description=\"Another model\",\n            latest_versions=[],\n        ),\n    ]\n    mock_get_request_message.return_value = SearchRegisteredModels()\n    mock_model_registry_store.search_registered_models.return_value = PagedList(rmds, None)\n    resp = _search_registered_models()\n    _, args = mock_model_registry_store.search_registered_models.call_args\n    assert args == {\n        \"filter_string\": \"\",\n        \"max_results\": SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,\n        \"order_by\": [],\n        \"page_token\": \"\",\n    }\n    assert json.loads(resp.get_data()) == {\"registered_models\": jsonify(rmds)}\n\n    mock_get_request_message.return_value = SearchRegisteredModels(filter=\"hello\")\n    mock_model_registry_store.search_registered_models.return_value = PagedList(rmds[:1], \"tok\")\n    resp = _search_registered_models()\n    _, args = mock_model_registry_store.search_registered_models.call_args\n    assert args == {\n        \"filter_string\": \"hello\",\n        \"max_results\": SEARCH_REGISTERED_MODEL_MAX_RESULTS_DEFAULT,\n        \"order_by\": [],\n        \"page_token\": \"\",\n    }\n    assert json.loads(resp.get_data()) == {\n        \"registered_models\": jsonify(rmds[:1]),\n        \"next_page_token\": \"tok\",\n    }\n\n    mock_get_request_message.return_value = SearchRegisteredModels(filter=\"hi\", max_results=5)\n    mock_model_registry_store.search_registered_models.return_value = PagedList([rmds[0]], \"tik\")\n    resp = _search_registered_models()\n    _, args = mock_model_registry_store.search_registered_models.call_args\n    assert args == {\"filter_string\": \"hi\", \"max_results\": 5, \"order_by\": [], \"page_token\": \"\"}\n    assert json.loads(resp.get_data()) == {\n        \"registered_models\": jsonify([rmds[0]]),\n        \"next_page_token\": \"tik\",\n    }\n\n    mock_get_request_message.return_value = SearchRegisteredModels(\n        filter=\"hey\", max_results=500, order_by=[\"a\", \"B desc\"], page_token=\"prev\"\n    )\n    mock_model_registry_store.search_registered_models.return_value = PagedList(rmds, \"DONE\")\n    resp = _search_registered_models()\n    _, args = mock_model_registry_store.search_registered_models.call_args\n    assert args == {\n        \"filter_string\": \"hey\",\n        \"max_results\": 500,\n        \"order_by\": [\"a\", \"B desc\"],\n        \"page_token\": \"prev\",\n    }\n    assert json.loads(resp.get_data()) == {\n        \"registered_models\": jsonify(rmds),\n        \"next_page_token\": \"DONE\",\n    }\n\n\ndef test_get_latest_versions(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    mock_get_request_message.return_value = GetLatestVersions(name=name)\n    mvds = [\n        ModelVersion(\n            name=name,\n            version=\"5\",\n            creation_timestamp=1,\n            last_updated_timestamp=12,\n            description=\"v 5\",\n            user_id=\"u1\",\n            current_stage=\"Production\",\n            source=\"A/B\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=name,\n            version=\"1\",\n            creation_timestamp=1,\n            last_updated_timestamp=1200,\n            description=\"v 1\",\n            user_id=\"u1\",\n            current_stage=\"Archived\",\n            source=\"A/B2\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=name,\n            version=\"12\",\n            creation_timestamp=100,\n            last_updated_timestamp=None,\n            description=\"v 12\",\n            user_id=\"u2\",\n            current_stage=\"Staging\",\n            source=\"A/B3\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n    ]\n    mock_model_registry_store.get_latest_versions.return_value = mvds\n    resp = _get_latest_versions()\n    _, args = mock_model_registry_store.get_latest_versions.call_args\n    assert args == {\"name\": name, \"stages\": []}\n    assert json.loads(resp.get_data()) == {\"model_versions\": jsonify(mvds)}\n\n    for stages in [[], [\"None\"], [\"Staging\"], [\"Staging\", \"Production\"]]:\n        mock_get_request_message.return_value = GetLatestVersions(name=name, stages=stages)\n        _get_latest_versions()\n        _, args = mock_model_registry_store.get_latest_versions.call_args\n        assert args == {\"name\": name, \"stages\": stages}\n\n\ndef test_create_model_version(mock_get_request_message, mock_model_registry_store):\n    run_id = uuid.uuid4().hex\n    tags = [\n        ModelVersionTag(key=\"key\", value=\"value\"),\n        ModelVersionTag(key=\"anotherKey\", value=\"some other value\"),\n    ]\n    run_link = \"localhost:5000/path/to/run\"\n    mock_get_request_message.return_value = CreateModelVersion(\n        name=\"model_1\",\n        source=f\"runs:/{run_id}\",\n        run_id=run_id,\n        run_link=run_link,\n        tags=[tag.to_proto() for tag in tags],\n    )\n    mv = ModelVersion(\n        name=\"model_1\", version=\"12\", creation_timestamp=123, tags=tags, run_link=run_link\n    )\n    mock_model_registry_store.create_model_version.return_value = mv\n    resp = _create_model_version()\n    _, args = mock_model_registry_store.create_model_version.call_args\n    assert args[\"name\"] == \"model_1\"\n    assert args[\"source\"] == f\"runs:/{run_id}\"\n    assert args[\"run_id\"] == run_id\n    assert {tag.key: tag.value for tag in args[\"tags\"]} == {tag.key: tag.value for tag in tags}\n    assert args[\"run_link\"] == run_link\n    assert json.loads(resp.get_data()) == {\"model_version\": jsonify(mv)}\n\n\ndef test_set_registered_model_tag(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    tag = RegisteredModelTag(key=\"some weird key\", value=\"some value\")\n    mock_get_request_message.return_value = SetRegisteredModelTag(\n        name=name, key=tag.key, value=tag.value\n    )\n    _set_registered_model_tag()\n    _, args = mock_model_registry_store.set_registered_model_tag.call_args\n    assert args == {\"name\": name, \"tag\": tag}\n\n\ndef test_delete_registered_model_tag(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    key = \"some weird key\"\n    mock_get_request_message.return_value = DeleteRegisteredModelTag(name=name, key=key)\n    _delete_registered_model_tag()\n    _, args = mock_model_registry_store.delete_registered_model_tag.call_args\n    assert args == {\"name\": name, \"key\": key}\n\n\ndef test_get_model_version_details(mock_get_request_message, mock_model_registry_store):\n    mock_get_request_message.return_value = GetModelVersion(name=\"model1\", version=\"32\")\n    mvd = ModelVersion(\n        name=\"model1\",\n        version=\"5\",\n        creation_timestamp=1,\n        last_updated_timestamp=12,\n        description=\"v 5\",\n        user_id=\"u1\",\n        current_stage=\"Production\",\n        source=\"A/B\",\n        run_id=uuid.uuid4().hex,\n        status=\"READY\",\n        status_message=None,\n    )\n    mock_model_registry_store.get_model_version.return_value = mvd\n    resp = _get_model_version()\n    _, args = mock_model_registry_store.get_model_version.call_args\n    assert args == {\"name\": \"model1\", \"version\": \"32\"}\n    assert json.loads(resp.get_data()) == {\"model_version\": jsonify(mvd)}\n\n\ndef test_update_model_version(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"32\"\n    description = \"Great model!\"\n    mock_get_request_message.return_value = UpdateModelVersion(\n        name=name, version=version, description=description\n    )\n\n    mv = ModelVersion(name=name, version=version, creation_timestamp=123, description=description)\n    mock_model_registry_store.update_model_version.return_value = mv\n    _update_model_version()\n    _, args = mock_model_registry_store.update_model_version.call_args\n    assert args == {\"name\": name, \"version\": version, \"description\": description}\n\n\ndef test_transition_model_version_stage(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"32\"\n    stage = \"Production\"\n    mock_get_request_message.return_value = TransitionModelVersionStage(\n        name=name, version=version, stage=stage\n    )\n    mv = ModelVersion(name=name, version=version, creation_timestamp=123, current_stage=stage)\n    mock_model_registry_store.transition_model_version_stage.return_value = mv\n    _transition_stage()\n    _, args = mock_model_registry_store.transition_model_version_stage.call_args\n    assert args == {\n        \"name\": name,\n        \"version\": version,\n        \"stage\": stage,\n        \"archive_existing_versions\": False,\n    }\n\n\ndef test_delete_model_version(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"32\"\n    mock_get_request_message.return_value = DeleteModelVersion(name=name, version=version)\n    _delete_model_version()\n    _, args = mock_model_registry_store.delete_model_version.call_args\n    assert args == {\"name\": name, \"version\": version}\n\n\ndef test_get_model_version_download_uri(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"32\"\n    mock_get_request_message.return_value = GetModelVersionDownloadUri(name=name, version=version)\n    mock_model_registry_store.get_model_version_download_uri.return_value = \"some/download/path\"\n    resp = _get_model_version_download_uri()\n    _, args = mock_model_registry_store.get_model_version_download_uri.call_args\n    assert args == {\"name\": name, \"version\": version}\n    assert json.loads(resp.get_data()) == {\"artifact_uri\": \"some/download/path\"}\n\n\ndef test_search_model_versions(mock_get_request_message, mock_model_registry_store):\n    mvds = [\n        ModelVersion(\n            name=\"model_1\",\n            version=\"5\",\n            creation_timestamp=100,\n            last_updated_timestamp=3200,\n            description=\"v 5\",\n            user_id=\"u1\",\n            current_stage=\"Production\",\n            source=\"A/B/CD\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=\"model_1\",\n            version=\"12\",\n            creation_timestamp=110,\n            last_updated_timestamp=2000,\n            description=\"v 12\",\n            user_id=\"u2\",\n            current_stage=\"Production\",\n            source=\"A/B/CD\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=\"ads_model\",\n            version=\"8\",\n            creation_timestamp=200,\n            last_updated_timestamp=1000,\n            description=\"v 8\",\n            user_id=\"u1\",\n            current_stage=\"Staging\",\n            source=\"A/B/CD\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n        ModelVersion(\n            name=\"fraud_detection_model\",\n            version=\"345\",\n            creation_timestamp=1000,\n            last_updated_timestamp=999,\n            description=\"newest version\",\n            user_id=\"u12\",\n            current_stage=\"None\",\n            source=\"A/B/CD\",\n            run_id=uuid.uuid4().hex,\n            status=\"READY\",\n            status_message=None,\n        ),\n    ]\n    mock_get_request_message.return_value = SearchModelVersions(filter=\"source_path = 'A/B/CD'\")\n    mock_model_registry_store.search_model_versions.return_value = PagedList(mvds, None)\n    resp = _search_model_versions()\n    mock_model_registry_store.search_model_versions.assert_called_with(\n        filter_string=\"source_path = 'A/B/CD'\",\n        max_results=SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,\n        order_by=[],\n        page_token=\"\",\n    )\n    assert json.loads(resp.get_data()) == {\"model_versions\": jsonify(mvds)}\n\n    mock_get_request_message.return_value = SearchModelVersions(filter=\"name='model_1'\")\n    mock_model_registry_store.search_model_versions.return_value = PagedList(mvds[:1], \"tok\")\n    resp = _search_model_versions()\n    mock_model_registry_store.search_model_versions.assert_called_with(\n        filter_string=\"name='model_1'\",\n        max_results=SEARCH_MODEL_VERSION_MAX_RESULTS_THRESHOLD,\n        order_by=[],\n        page_token=\"\",\n    )\n    assert json.loads(resp.get_data()) == {\n        \"model_versions\": jsonify(mvds[:1]),\n        \"next_page_token\": \"tok\",\n    }\n\n    mock_get_request_message.return_value = SearchModelVersions(filter=\"version<=12\", max_results=2)\n    mock_model_registry_store.search_model_versions.return_value = PagedList(\n        [mvds[0], mvds[2]], \"next\"\n    )\n    resp = _search_model_versions()\n    mock_model_registry_store.search_model_versions.assert_called_with(\n        filter_string=\"version<=12\", max_results=2, order_by=[], page_token=\"\"\n    )\n    assert json.loads(resp.get_data()) == {\n        \"model_versions\": jsonify([mvds[0], mvds[2]]),\n        \"next_page_token\": \"next\",\n    }\n\n    mock_get_request_message.return_value = SearchModelVersions(\n        filter=\"version<=12\", max_results=2, order_by=[\"version DESC\"], page_token=\"prev\"\n    )\n    mock_model_registry_store.search_model_versions.return_value = PagedList(mvds[1:3], \"next\")\n    resp = _search_model_versions()\n    mock_model_registry_store.search_model_versions.assert_called_with(\n        filter_string=\"version<=12\", max_results=2, order_by=[\"version DESC\"], page_token=\"prev\"\n    )\n    assert json.loads(resp.get_data()) == {\n        \"model_versions\": jsonify(mvds[1:3]),\n        \"next_page_token\": \"next\",\n    }\n\n\ndef test_set_model_version_tag(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"1\"\n    tag = ModelVersionTag(key=\"some weird key\", value=\"some value\")\n    mock_get_request_message.return_value = SetModelVersionTag(\n        name=name, version=version, key=tag.key, value=tag.value\n    )\n    _set_model_version_tag()\n    _, args = mock_model_registry_store.set_model_version_tag.call_args\n    assert args == {\"name\": name, \"version\": version, \"tag\": tag}\n\n\ndef test_delete_model_version_tag(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    version = \"1\"\n    key = \"some weird key\"\n    mock_get_request_message.return_value = DeleteModelVersionTag(\n        name=name, version=version, key=key\n    )\n    _delete_model_version_tag()\n    _, args = mock_model_registry_store.delete_model_version_tag.call_args\n    assert args == {\"name\": name, \"version\": version, \"key\": key}\n\n\ndef test_set_registered_model_alias(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    alias = \"test_alias\"\n    version = \"1\"\n    mock_get_request_message.return_value = SetRegisteredModelAlias(\n        name=name, alias=alias, version=version\n    )\n    _set_registered_model_alias()\n    _, args = mock_model_registry_store.set_registered_model_alias.call_args\n    assert args == {\"name\": name, \"alias\": alias, \"version\": version}\n\n\ndef test_delete_registered_model_alias(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    alias = \"test_alias\"\n    mock_get_request_message.return_value = DeleteRegisteredModelAlias(name=name, alias=alias)\n    _delete_registered_model_alias()\n    _, args = mock_model_registry_store.delete_registered_model_alias.call_args\n    assert args == {\"name\": name, \"alias\": alias}\n\n\ndef test_get_model_version_by_alias(mock_get_request_message, mock_model_registry_store):\n    name = \"model1\"\n    alias = \"test_alias\"\n    mock_get_request_message.return_value = GetModelVersionByAlias(name=name, alias=alias)\n    mvd = ModelVersion(\n        name=\"model1\",\n        version=\"5\",\n        creation_timestamp=1,\n        last_updated_timestamp=12,\n        description=\"v 5\",\n        user_id=\"u1\",\n        current_stage=\"Production\",\n        source=\"A/B\",\n        run_id=uuid.uuid4().hex,\n        status=\"READY\",\n        status_message=None,\n        aliases=[\"test_alias\"],\n    )\n    mock_model_registry_store.get_model_version_by_alias.return_value = mvd\n    resp = _get_model_version_by_alias()\n    _, args = mock_model_registry_store.get_model_version_by_alias.call_args\n    assert args == {\"name\": name, \"alias\": alias}\n    assert json.loads(resp.get_data()) == {\"model_version\": jsonify(mvd)}\n\n\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        \"/path\",\n        \"path/../to/file\",\n        \"/etc/passwd\",\n        \"/etc/passwd%00.jpg\",\n        \"/file://etc/passwd\",\n        \"%2E%2E%2F%2E%2E%2Fpath\",\n    ],\n)\ndef test_delete_artifact_mlflow_artifacts_throws_for_malicious_path(enable_serve_artifacts, path):\n    response = _delete_artifact_mlflow_artifacts(path)\n    assert response.status_code == 400\n    json_response = json.loads(response.get_data())\n    assert json_response[\"error_code\"] == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n    assert json_response[\"message\"] == \"Invalid path\"\n", "import os\nimport posixpath\nfrom unittest import mock\n\nimport pytest\nfrom requests import HTTPError\n\nfrom mlflow.entities.multipart_upload import (\n    CreateMultipartUploadResponse,\n    MultipartUploadCredential,\n    MultipartUploadPart,\n)\nfrom mlflow.environment_variables import (\n    MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE,\n    MLFLOW_TRACKING_CLIENT_CERT_PATH,\n    MLFLOW_TRACKING_INSECURE_TLS,\n    MLFLOW_TRACKING_PASSWORD,\n    MLFLOW_TRACKING_SERVER_CERT_PATH,\n    MLFLOW_TRACKING_TOKEN,\n    MLFLOW_TRACKING_USERNAME,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.store.artifact.artifact_repository_registry import get_artifact_repository\nfrom mlflow.store.artifact.http_artifact_repo import HttpArtifactRepository\nfrom mlflow.tracking._tracking_service.utils import _get_default_host_creds\nfrom mlflow.utils.rest_utils import MlflowHostCreds\n\n\n@pytest.mark.parametrize(\"scheme\", [\"http\", \"https\"])\ndef test_artifact_uri_factory(scheme):\n    repo = get_artifact_repository(f\"{scheme}://test.com\")\n    assert isinstance(repo, HttpArtifactRepository)\n\n\nclass MockResponse:\n    def __init__(self, data, status_code):\n        self.data = data\n        self.status_code = status_code\n\n    def json(self):\n        return self.data\n\n    def raise_for_status(self):\n        if self.status_code >= 400:\n            raise Exception(\"request failed\")\n\n\nclass MockStreamResponse(MockResponse):\n    def iter_content(self, chunk_size):  # pylint: disable=unused-argument\n        yield self.data.encode(\"utf-8\")\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, *exc):\n        pass\n\n\nclass FileObjectMatcher:\n    def __init__(self, name, mode):\n        self.name = name\n        self.mode = mode\n\n    def __eq__(self, other):\n        return self.name == other.name and self.mode == other.mode\n\n\n@pytest.fixture\ndef http_artifact_repo():\n    artifact_uri = \"http://test.com/api/2.0/mlflow-artifacts/artifacts\"\n    return HttpArtifactRepository(artifact_uri)\n\n\n@pytest.mark.parametrize(\n    (\"filename\", \"expected_mime_type\"),\n    [\n        (\"c.txt\", \"text/plain\"),\n        (\"c.pkl\", \"application/octet-stream\"),\n        (\"MLmodel\", \"text/plain\"),\n    ],\n)\n@pytest.mark.parametrize(\"artifact_path\", [None, \"dir\"])\ndef test_log_artifact(\n    http_artifact_repo,\n    tmp_path,\n    artifact_path,\n    filename,\n    expected_mime_type,\n    monkeypatch,\n):\n    file_path = tmp_path.joinpath(filename)\n    file_path.write_text(\"0\")\n\n    def assert_called_log_artifact(mock_http_request):\n        paths = (artifact_path, file_path.name) if artifact_path else (file_path.name,)\n        mock_http_request.assert_called_once_with(\n            http_artifact_repo._host_creds,\n            posixpath.join(\"/\", *paths),\n            \"PUT\",\n            data=FileObjectMatcher(str(file_path), \"rb\"),\n            extra_headers={\"Content-Type\": expected_mime_type},\n        )\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_put:\n        http_artifact_repo.log_artifact(file_path, artifact_path)\n        assert_called_log_artifact(mock_put)\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 400),\n    ):\n        with pytest.raises(Exception, match=\"request failed\"):\n            http_artifact_repo.log_artifact(file_path, artifact_path)\n\n    monkeypatch.setenv(\"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", \"true\")\n    # assert mpu is triggered when file size is larger than minimum file size\n    file_path.write_text(\"0\" * MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE.get())\n    with mock.patch.object(\n        http_artifact_repo, \"_try_multipart_upload\", return_value=200\n    ) as mock_mpu:\n        http_artifact_repo.log_artifact(file_path, artifact_path)\n        mock_mpu.assert_called_once()\n\n    # assert reverted to normal upload when mpu is not supported\n    # mock that create_multipart_upload will returns a 400 error with appropriate message\n    with mock.patch.object(\n        http_artifact_repo,\n        \"create_multipart_upload\",\n        side_effect=HTTPError(\n            response=MockResponse(\n                data={\n                    \"message\": \"Multipart upload is not supported for the current \"\n                    \"artifact repository\"\n                },\n                status_code=501,\n            )\n        ),\n    ), mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_put:\n        http_artifact_repo.log_artifact(file_path, artifact_path)\n        assert_called_log_artifact(mock_put)\n\n    # assert if mpu is triggered but the uploads failed, mpu is aborted and exception is raised\n    with mock.patch(\"requests.put\", side_effect=Exception(\"MPU_UPLOAD_FAILS\")), mock.patch.object(\n        http_artifact_repo,\n        \"create_multipart_upload\",\n        return_value=CreateMultipartUploadResponse(\n            upload_id=\"upload_id\",\n            credentials=[MultipartUploadCredential(url=\"url\", part_number=1, headers={})],\n        ),\n    ), mock.patch.object(\n        http_artifact_repo,\n        \"abort_multipart_upload\",\n        return_value=None,\n    ) as mock_abort:\n        with pytest.raises(Exception, match=\"MPU_UPLOAD_FAILS\"):\n            http_artifact_repo.log_artifact(file_path, artifact_path)\n        mock_abort.assert_called_once()\n\n\n@pytest.mark.parametrize(\"artifact_path\", [None, \"dir\"])\ndef test_log_artifacts(http_artifact_repo, tmp_path, artifact_path):\n    tmp_path_a = tmp_path.joinpath(\"a.txt\")\n    d = tmp_path.joinpath(\"dir\")\n    d.mkdir()\n    tmp_path_b = d.joinpath(\"b.txt\")\n    tmp_path_a.write_text(\"0\")\n    tmp_path_b.write_text(\"1\")\n\n    with mock.patch.object(http_artifact_repo, \"log_artifact\") as mock_log_artifact:\n        http_artifact_repo.log_artifacts(tmp_path, artifact_path)\n        mock_log_artifact.assert_has_calls(\n            [\n                mock.call(str(tmp_path_a), artifact_path),\n                mock.call(\n                    str(tmp_path_b),\n                    posixpath.join(artifact_path, \"dir\") if artifact_path else \"dir\",\n                ),\n            ],\n        )\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 400),\n    ):\n        with pytest.raises(Exception, match=\"request failed\"):\n            http_artifact_repo.log_artifacts(tmp_path, artifact_path)\n\n\ndef test_list_artifacts(http_artifact_repo):\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_get:\n        assert http_artifact_repo.list_artifacts() == []\n        endpoint = \"/mlflow-artifacts/artifacts\"\n        url, _ = http_artifact_repo.artifact_uri.split(endpoint, maxsplit=1)\n        mock_get.assert_called_once_with(\n            _get_default_host_creds(url),\n            endpoint,\n            \"GET\",\n            params={\"path\": \"\"},\n        )\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse(\n            {\n                \"files\": [\n                    {\"path\": \"1.txt\", \"is_dir\": False, \"file_size\": 1},\n                    {\"path\": \"dir\", \"is_dir\": True},\n                ]\n            },\n            200,\n        ),\n    ):\n        assert [a.path for a in http_artifact_repo.list_artifacts()] == [\"1.txt\", \"dir\"]\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse(\n            {\n                \"files\": [\n                    {\"path\": \"1.txt\", \"is_dir\": False, \"file_size\": 1},\n                    {\"path\": \"dir\", \"is_dir\": True},\n                ]\n            },\n            200,\n        ),\n    ):\n        assert [a.path for a in http_artifact_repo.list_artifacts(path=\"path\")] == [\n            \"path/1.txt\",\n            \"path/dir\",\n        ]\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 400),\n    ):\n        with pytest.raises(Exception, match=\"request failed\"):\n            http_artifact_repo.list_artifacts()\n\n\n@pytest.mark.parametrize(\"path\", [\"/tmp/path\", \"../../path\", \"%2E%2E%2Fpath\"])\ndef test_list_artifacts_malicious_path(http_artifact_repo, path):\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse(\n            {\n                \"files\": [\n                    {\"path\": path, \"is_dir\": False, \"file_size\": 1},\n                ]\n            },\n            200,\n        ),\n    ):\n        with pytest.raises(MlflowException, match=\"Invalid path\"):\n            http_artifact_repo.list_artifacts()\n\n\ndef read_file(path):\n    with open(path) as f:\n        return f.read()\n\n\n@pytest.mark.parametrize(\"remote_file_path\", [\"a.txt\", \"dir/b.xtx\"])\ndef test_download_file(http_artifact_repo, tmp_path, remote_file_path):\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockStreamResponse(\"data\", 200),\n    ) as mock_get:\n        file_path = tmp_path.joinpath(posixpath.basename(remote_file_path))\n        http_artifact_repo._download_file(remote_file_path, file_path)\n        mock_get.assert_called_once_with(\n            http_artifact_repo._host_creds,\n            posixpath.join(\"/\", remote_file_path),\n            \"GET\",\n            stream=True,\n        )\n        assert file_path.read_text() == \"data\"\n\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockStreamResponse(\"data\", 400),\n    ):\n        with pytest.raises(Exception, match=\"request failed\"):\n            http_artifact_repo._download_file(remote_file_path, tmp_path)\n\n\ndef test_download_artifacts(http_artifact_repo, tmp_path):\n    # This test simulates downloading artifacts in the following structure:\n    # ---------\n    # - a.txt\n    # - dir\n    #   - b.txt\n    # ---------\n    def http_request(_host_creds, endpoint, _method, **kwargs):\n        # Responses for list_artifacts\n        params = kwargs.get(\"params\")\n        if params:\n            if params.get(\"path\") == \"\":\n                return MockResponse(\n                    {\n                        \"files\": [\n                            {\"path\": \"a.txt\", \"is_dir\": False, \"file_size\": 1},\n                            {\"path\": \"dir\", \"is_dir\": True},\n                        ]\n                    },\n                    200,\n                )\n            elif params.get(\"path\") == \"dir\":\n                return MockResponse(\n                    {\n                        \"files\": [\n                            {\"path\": \"b.txt\", \"is_dir\": False, \"file_size\": 1},\n                        ]\n                    },\n                    200,\n                )\n            else:\n                Exception(\"Unreachable\")\n\n        # Responses for _download_file\n        if endpoint == \"/a.txt\":\n            return MockStreamResponse(\"data_a\", 200)\n        elif endpoint == \"/dir/b.txt\":\n            return MockStreamResponse(\"data_b\", 200)\n        else:\n            raise Exception(\"Unreachable\")\n\n    with mock.patch(\"mlflow.store.artifact.http_artifact_repo.http_request\", http_request):\n        http_artifact_repo.download_artifacts(\"\", tmp_path)\n        paths = [os.path.join(root, f) for root, _, files in os.walk(tmp_path) for f in files]\n        assert [os.path.relpath(p, tmp_path) for p in paths] == [\n            \"a.txt\",\n            os.path.join(\"dir\", \"b.txt\"),\n        ]\n        assert read_file(paths[0]) == \"data_a\"\n        assert read_file(paths[1]) == \"data_b\"\n\n\ndef test_default_host_creds(monkeypatch):\n    artifact_uri = \"https://test.com\"\n    username = \"user\"\n    password = \"pass\"\n    token = \"token\"\n    ignore_tls_verification = False\n    client_cert_path = \"client_cert_path\"\n    server_cert_path = \"server_cert_path\"\n\n    expected_host_creds = MlflowHostCreds(\n        host=artifact_uri,\n        username=username,\n        password=password,\n        token=token,\n        ignore_tls_verification=ignore_tls_verification,\n        client_cert_path=client_cert_path,\n        server_cert_path=server_cert_path,\n    )\n\n    repo = HttpArtifactRepository(artifact_uri)\n\n    monkeypatch.setenvs(\n        {\n            MLFLOW_TRACKING_USERNAME.name: username,\n            MLFLOW_TRACKING_PASSWORD.name: password,\n            MLFLOW_TRACKING_TOKEN.name: token,\n            MLFLOW_TRACKING_INSECURE_TLS.name: str(ignore_tls_verification),\n            MLFLOW_TRACKING_CLIENT_CERT_PATH.name: client_cert_path,\n            MLFLOW_TRACKING_SERVER_CERT_PATH.name: server_cert_path,\n        }\n    )\n    assert repo._host_creds == expected_host_creds\n\n\n@pytest.mark.parametrize(\"remote_file_path\", [\"a.txt\", \"dir/b.txt\", None])\ndef test_delete_artifacts(http_artifact_repo, remote_file_path):\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockStreamResponse(\"data\", 200),\n    ) as mock_get:\n        http_artifact_repo.delete_artifacts(remote_file_path)\n        mock_get.assert_called_once_with(\n            http_artifact_repo._host_creds,\n            posixpath.join(\"/\", remote_file_path if remote_file_path else \"\"),\n            \"DELETE\",\n            stream=True,\n        )\n\n\ndef test_create_multipart_upload(http_artifact_repo, monkeypatch):\n    monkeypatch.setenv(\"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", \"true\")\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse(\n            {\n                \"upload_id\": \"upload_id\",\n                \"credentials\": [\n                    {\n                        \"url\": \"/some/url\",\n                        \"part_number\": 1,\n                        \"headers\": {},\n                    }\n                ],\n            },\n            200,\n        ),\n    ):\n        response = http_artifact_repo.create_multipart_upload(\"\", 1)\n        assert response.upload_id == \"upload_id\"\n        assert len(response.credentials) == 1\n        assert response.credentials[0].url == \"/some/url\"\n\n\ndef test_complete_multipart_upload(http_artifact_repo, monkeypatch):\n    monkeypatch.setenv(\"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", \"true\")\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_post:\n        http_artifact_repo.complete_multipart_upload(\n            local_file=\"local_file\",\n            upload_id=\"upload_id\",\n            parts=[\n                MultipartUploadPart(part_number=1, etag=\"etag1\"),\n                MultipartUploadPart(part_number=2, etag=\"etag2\"),\n            ],\n            artifact_path=\"artifact/path\",\n        )\n        endpoint = \"/mlflow-artifacts\"\n        url, _ = http_artifact_repo.artifact_uri.split(endpoint, maxsplit=1)\n        mock_post.assert_called_once_with(\n            _get_default_host_creds(url),\n            \"/mlflow-artifacts/mpu/complete/artifact/path\",\n            \"POST\",\n            json={\n                \"path\": \"local_file\",\n                \"upload_id\": \"upload_id\",\n                \"parts\": [\n                    {\"part_number\": 1, \"etag\": \"etag1\"},\n                    {\"part_number\": 2, \"etag\": \"etag2\"},\n                ],\n            },\n        )\n\n\ndef test_abort_multipart_upload(http_artifact_repo, monkeypatch):\n    monkeypatch.setenv(\"MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD\", \"true\")\n    with mock.patch(\n        \"mlflow.store.artifact.http_artifact_repo.http_request\",\n        return_value=MockResponse({}, 200),\n    ) as mock_post:\n        http_artifact_repo.abort_multipart_upload(\n            local_file=\"local_file\",\n            upload_id=\"upload_id\",\n            artifact_path=\"artifact/path\",\n        )\n        endpoint = \"/mlflow-artifacts\"\n        url, _ = http_artifact_repo.artifact_uri.split(endpoint, maxsplit=1)\n        mock_post.assert_called_once_with(\n            _get_default_host_creds(url),\n            \"/mlflow-artifacts/mpu/abort/artifact/path\",\n            \"POST\",\n            json={\n                \"path\": \"local_file\",\n                \"upload_id\": \"upload_id\",\n            },\n        )\n", "\"\"\"\nIntegration test which starts a local Tracking Server on an ephemeral port,\nand ensures we can use the tracking API to communicate with it.\n\"\"\"\nimport json\nimport logging\nimport math\nimport os\nimport pathlib\nimport posixpath\nimport sys\nimport time\nimport urllib.parse\nfrom unittest import mock\n\nimport flask\nimport pandas as pd\nimport pytest\nimport requests\n\nimport mlflow.experiments\nimport mlflow.pyfunc\nfrom mlflow import MlflowClient\nfrom mlflow.artifacts import download_artifacts\nfrom mlflow.data.pandas_dataset import from_pandas\nfrom mlflow.entities import (\n    Dataset,\n    DatasetInput,\n    InputTag,\n    Metric,\n    Param,\n    RunInputs,\n    RunTag,\n    ViewType,\n)\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.models import Model\nfrom mlflow.store.tracking.sqlalchemy_store import SqlAlchemyStore\nfrom mlflow.utils import mlflow_tags\nfrom mlflow.utils.file_utils import TempDir, path_to_local_file_uri\nfrom mlflow.utils.mlflow_tags import (\n    MLFLOW_DATASET_CONTEXT,\n    MLFLOW_GIT_COMMIT,\n    MLFLOW_PARENT_RUN_ID,\n    MLFLOW_PROJECT_ENTRY_POINT,\n    MLFLOW_SOURCE_NAME,\n    MLFLOW_SOURCE_TYPE,\n    MLFLOW_USER,\n)\nfrom mlflow.utils.os import is_windows\nfrom mlflow.utils.proto_json_utils import message_to_json\nfrom mlflow.utils.time import get_current_time_millis\n\nfrom tests.integration.utils import invoke_cli_runner\nfrom tests.tracking.integration_test_utils import (\n    _init_server,\n    _send_rest_tracking_post_request,\n)\n\n_logger = logging.getLogger(__name__)\n\n\n@pytest.fixture(params=[\"file\", \"sqlalchemy\"])\ndef mlflow_client(request, tmp_path):\n    \"\"\"Provides an MLflow Tracking API client pointed at the local tracking server.\"\"\"\n    if request.param == \"file\":\n        backend_uri = tmp_path.joinpath(\"file\").as_uri()\n    elif request.param == \"sqlalchemy\":\n        path = tmp_path.joinpath(\"sqlalchemy.db\").as_uri()\n        backend_uri = (\"sqlite://\" if sys.platform == \"win32\" else \"sqlite:////\") + path[\n            len(\"file://\") :\n        ]\n\n    with _init_server(backend_uri, root_artifact_uri=tmp_path.as_uri()) as url:\n        yield MlflowClient(url)\n\n\n@pytest.fixture\ndef cli_env(mlflow_client):\n    \"\"\"Provides an environment for the MLflow CLI pointed at the local tracking server.\"\"\"\n    return {\n        \"LC_ALL\": \"en_US.UTF-8\",\n        \"LANG\": \"en_US.UTF-8\",\n        \"MLFLOW_TRACKING_URI\": mlflow_client.tracking_uri,\n    }\n\n\ndef create_experiments(client, names):\n    return [client.create_experiment(n) for n in names]\n\n\ndef test_create_get_search_experiment(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        \"My Experiment\", artifact_location=\"my_location\", tags={\"key1\": \"val1\", \"key2\": \"val2\"}\n    )\n    exp = mlflow_client.get_experiment(experiment_id)\n    assert exp.name == \"My Experiment\"\n    if is_windows():\n        assert exp.artifact_location == pathlib.Path.cwd().joinpath(\"my_location\").as_uri()\n    else:\n        assert exp.artifact_location == str(pathlib.Path.cwd().joinpath(\"my_location\"))\n    assert len(exp.tags) == 2\n    assert exp.tags[\"key1\"] == \"val1\"\n    assert exp.tags[\"key2\"] == \"val2\"\n\n    experiments = mlflow_client.search_experiments()\n    assert {e.name for e in experiments} == {\"My Experiment\", \"Default\"}\n    mlflow_client.delete_experiment(experiment_id)\n    assert {e.name for e in mlflow_client.search_experiments()} == {\"Default\"}\n    assert {e.name for e in mlflow_client.search_experiments(view_type=ViewType.ACTIVE_ONLY)} == {\n        \"Default\"\n    }\n    assert {e.name for e in mlflow_client.search_experiments(view_type=ViewType.DELETED_ONLY)} == {\n        \"My Experiment\"\n    }\n    assert {e.name for e in mlflow_client.search_experiments(view_type=ViewType.ALL)} == {\n        \"My Experiment\",\n        \"Default\",\n    }\n    active_exps_paginated = mlflow_client.search_experiments(max_results=1)\n    assert {e.name for e in active_exps_paginated} == {\"Default\"}\n    assert active_exps_paginated.token is None\n\n    all_exps_paginated = mlflow_client.search_experiments(max_results=1, view_type=ViewType.ALL)\n    first_page_names = {e.name for e in all_exps_paginated}\n    all_exps_second_page = mlflow_client.search_experiments(\n        max_results=1, view_type=ViewType.ALL, page_token=all_exps_paginated.token\n    )\n    second_page_names = {e.name for e in all_exps_second_page}\n    assert len(first_page_names) == 1\n    assert len(second_page_names) == 1\n    assert first_page_names.union(second_page_names) == {\"Default\", \"My Experiment\"}\n\n\ndef test_create_experiment_validation(mlflow_client):\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/experiments/create\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    assert_bad_request(\n        {\n            \"name\": 123,\n        },\n        \"Invalid value 123 for parameter 'name'\",\n    )\n    assert_bad_request({}, \"Missing value for required parameter 'name'\")\n    assert_bad_request(\n        {\n            \"name\": \"experiment name\",\n            \"artifact_location\": 9.0,\n            \"tags\": [{\"key\": \"key\", \"value\": \"value\"}],\n        },\n        \"Invalid value 9.0 for parameter 'artifact_location'\",\n    )\n    assert_bad_request(\n        {\n            \"name\": \"experiment name\",\n            \"artifact_location\": \"my_location\",\n            \"tags\": \"5\",\n        },\n        \"Invalid value 5 for parameter 'tags'\",\n    )\n\n\ndef test_delete_restore_experiment(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Deleterious\")\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"active\"\n    mlflow_client.delete_experiment(experiment_id)\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"deleted\"\n    mlflow_client.restore_experiment(experiment_id)\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"active\"\n\n\ndef test_delete_restore_experiment_cli(mlflow_client, cli_env):\n    experiment_name = \"DeleteriousCLI\"\n    invoke_cli_runner(\n        mlflow.experiments.commands, [\"create\", \"--experiment-name\", experiment_name], env=cli_env\n    )\n    experiment_id = mlflow_client.get_experiment_by_name(experiment_name).experiment_id\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"active\"\n    invoke_cli_runner(\n        mlflow.experiments.commands, [\"delete\", \"-x\", str(experiment_id)], env=cli_env\n    )\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"deleted\"\n    invoke_cli_runner(\n        mlflow.experiments.commands, [\"restore\", \"-x\", str(experiment_id)], env=cli_env\n    )\n    assert mlflow_client.get_experiment(experiment_id).lifecycle_stage == \"active\"\n\n\ndef test_rename_experiment(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"BadName\")\n    assert mlflow_client.get_experiment(experiment_id).name == \"BadName\"\n    mlflow_client.rename_experiment(experiment_id, \"GoodName\")\n    assert mlflow_client.get_experiment(experiment_id).name == \"GoodName\"\n\n\ndef test_rename_experiment_cli(mlflow_client, cli_env):\n    bad_experiment_name = \"CLIBadName\"\n    good_experiment_name = \"CLIGoodName\"\n\n    invoke_cli_runner(\n        mlflow.experiments.commands, [\"create\", \"-n\", bad_experiment_name], env=cli_env\n    )\n    experiment_id = mlflow_client.get_experiment_by_name(bad_experiment_name).experiment_id\n    assert mlflow_client.get_experiment(experiment_id).name == bad_experiment_name\n    invoke_cli_runner(\n        mlflow.experiments.commands,\n        [\"rename\", \"--experiment-id\", str(experiment_id), \"--new-name\", good_experiment_name],\n        env=cli_env,\n    )\n    assert mlflow_client.get_experiment(experiment_id).name == good_experiment_name\n\n\n@pytest.mark.parametrize(\"parent_run_id_kwarg\", [None, \"my-parent-id\"])\ndef test_create_run_all_args(mlflow_client, parent_run_id_kwarg):\n    user = \"username\"\n    source_name = \"Hello\"\n    entry_point = \"entry\"\n    source_version = \"abc\"\n    create_run_kwargs = {\n        \"start_time\": 456,\n        \"run_name\": \"my name\",\n        \"tags\": {\n            MLFLOW_USER: user,\n            MLFLOW_SOURCE_TYPE: \"LOCAL\",\n            MLFLOW_SOURCE_NAME: source_name,\n            MLFLOW_PROJECT_ENTRY_POINT: entry_point,\n            MLFLOW_GIT_COMMIT: source_version,\n            MLFLOW_PARENT_RUN_ID: \"7\",\n            \"my\": \"tag\",\n            \"other\": \"tag\",\n        },\n    }\n    experiment_id = mlflow_client.create_experiment(\n        f\"Run A Lot (parent_run_id={parent_run_id_kwarg})\"\n    )\n    created_run = mlflow_client.create_run(experiment_id, **create_run_kwargs)\n    run_id = created_run.info.run_id\n    _logger.info(f\"Run id={run_id}\")\n    fetched_run = mlflow_client.get_run(run_id)\n    for run in [created_run, fetched_run]:\n        assert run.info.run_id == run_id\n        assert run.info.run_uuid == run_id\n        assert run.info.experiment_id == experiment_id\n        assert run.info.user_id == user\n        assert run.info.start_time == create_run_kwargs[\"start_time\"]\n        assert run.info.run_name == \"my name\"\n        for tag in create_run_kwargs[\"tags\"]:\n            assert tag in run.data.tags\n        assert run.data.tags.get(MLFLOW_USER) == user\n        assert run.data.tags.get(MLFLOW_PARENT_RUN_ID) == parent_run_id_kwarg or \"7\"\n        assert [run.info for run in mlflow_client.search_runs([experiment_id])] == [run.info]\n\n\ndef test_create_run_defaults(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Run A Little\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    run = mlflow_client.get_run(run_id)\n    assert run.info.run_id == run_id\n    assert run.info.experiment_id == experiment_id\n    assert run.info.user_id == \"unknown\"\n\n\ndef test_log_metrics_params_tags(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Oh My\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    mlflow_client.log_metric(run_id, key=\"metric\", value=123.456, timestamp=789, step=2)\n    mlflow_client.log_metric(run_id, key=\"nan_metric\", value=float(\"nan\"))\n    mlflow_client.log_metric(run_id, key=\"inf_metric\", value=float(\"inf\"))\n    mlflow_client.log_metric(run_id, key=\"-inf_metric\", value=-float(\"inf\"))\n    mlflow_client.log_metric(run_id, key=\"stepless-metric\", value=987.654, timestamp=321)\n    mlflow_client.log_param(run_id, \"param\", \"value\")\n    mlflow_client.set_tag(run_id, \"taggity\", \"do-dah\")\n    run = mlflow_client.get_run(run_id)\n    assert run.data.metrics.get(\"metric\") == 123.456\n    assert math.isnan(run.data.metrics.get(\"nan_metric\"))\n    assert run.data.metrics.get(\"inf_metric\") >= 1.7976931348623157e308\n    assert run.data.metrics.get(\"-inf_metric\") <= -1.7976931348623157e308\n    assert run.data.metrics.get(\"stepless-metric\") == 987.654\n    assert run.data.params.get(\"param\") == \"value\"\n    assert run.data.tags.get(\"taggity\") == \"do-dah\"\n    metric_history0 = mlflow_client.get_metric_history(run_id, \"metric\")\n    assert len(metric_history0) == 1\n    metric0 = metric_history0[0]\n    assert metric0.key == \"metric\"\n    assert metric0.value == 123.456\n    assert metric0.timestamp == 789\n    assert metric0.step == 2\n    metric_history1 = mlflow_client.get_metric_history(run_id, \"stepless-metric\")\n    assert len(metric_history1) == 1\n    metric1 = metric_history1[0]\n    assert metric1.key == \"stepless-metric\"\n    assert metric1.value == 987.654\n    assert metric1.timestamp == 321\n    assert metric1.step == 0\n\n    metric_history = mlflow_client.get_metric_history(run_id, \"a_test_accuracy\")\n    assert metric_history == []\n\n\ndef test_log_metric_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"metrics validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/log-metric\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    assert_bad_request(\n        {\n            \"run_id\": 31,\n            \"key\": \"metric\",\n            \"value\": 41,\n            \"timestamp\": 59,\n            \"step\": 26,\n        },\n        \"Invalid value 31 for parameter 'run_id' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": 31,\n            \"value\": 41,\n            \"timestamp\": 59,\n            \"step\": 26,\n        },\n        \"Invalid value 31 for parameter 'key' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": \"foo\",\n            \"value\": 31,\n            \"timestamp\": 59,\n            \"step\": \"foo\",\n        },\n        \"Invalid value foo for parameter 'step' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": \"foo\",\n            \"value\": 31,\n            \"timestamp\": \"foo\",\n            \"step\": 41,\n        },\n        \"Invalid value foo for parameter 'timestamp' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": None,\n            \"key\": \"foo\",\n            \"value\": 31,\n            \"timestamp\": 59,\n            \"step\": 41,\n        },\n        \"Missing value for required parameter 'run_id'\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            # Missing key\n            \"value\": 31,\n            \"timestamp\": 59,\n            \"step\": 41,\n        },\n        \"Missing value for required parameter 'key'\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": None,\n            \"value\": 31,\n            \"timestamp\": 59,\n            \"step\": 41,\n        },\n        \"Missing value for required parameter 'key'\",\n    )\n\n\ndef test_log_param_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"params validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/log-parameter\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    assert_bad_request(\n        {\n            \"run_id\": 31,\n            \"key\": \"param\",\n            \"value\": 41,\n        },\n        \"Invalid value 31 for parameter 'run_id' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": 31,\n            \"value\": 41,\n        },\n        \"Invalid value 31 for parameter 'key' supplied\",\n    )\n\n\ndef test_log_param_with_empty_string_as_value(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        test_log_param_with_empty_string_as_value.__name__\n    )\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    mlflow_client.log_param(run_id, \"param_key\", \"\")\n    assert {\"param_key\": \"\"}.items() <= mlflow_client.get_run(run_id).data.params.items()\n\n\ndef test_set_tag_with_empty_string_as_value(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        test_set_tag_with_empty_string_as_value.__name__\n    )\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    mlflow_client.set_tag(run_id, \"tag_key\", \"\")\n    assert {\"tag_key\": \"\"}.items() <= mlflow_client.get_run(run_id).data.tags.items()\n\n\ndef test_log_batch_containing_params_and_tags_with_empty_string_values(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        test_log_batch_containing_params_and_tags_with_empty_string_values.__name__\n    )\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    mlflow_client.log_batch(\n        run_id=run_id,\n        params=[Param(\"param_key\", \"\")],\n        tags=[RunTag(\"tag_key\", \"\")],\n    )\n    assert {\"param_key\": \"\"}.items() <= mlflow_client.get_run(run_id).data.params.items()\n    assert {\"tag_key\": \"\"}.items() <= mlflow_client.get_run(run_id).data.tags.items()\n\n\ndef test_set_tag_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"tags validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/set-tag\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    assert_bad_request(\n        {\n            \"run_id\": 31,\n            \"key\": \"tag\",\n            \"value\": 41,\n        },\n        \"Invalid value 31 for parameter 'run_id' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            \"key\": \"param\",\n            \"value\": 41,\n        },\n        \"Invalid value 41 for parameter 'value' supplied\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n            # Missing key\n            \"value\": \"value\",\n        },\n        \"Missing value for required parameter 'key'\",\n    )\n\n    response = _send_rest_tracking_post_request(\n        mlflow_client.tracking_uri,\n        \"/api/2.0/mlflow/runs/set-tag\",\n        {\n            \"run_uuid\": run_id,\n            \"key\": \"key\",\n            \"value\": \"value\",\n        },\n    )\n    assert response.status_code == 200\n\n\ndef test_path_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"tags validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    invalid_path = \"../path\"\n\n    def assert_response(resp):\n        assert resp.status_code == 400\n        assert response.json() == {\n            \"error_code\": \"INVALID_PARAMETER_VALUE\",\n            \"message\": \"Invalid path\",\n        }\n\n    response = requests.get(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/artifacts/list\",\n        params={\"run_id\": run_id, \"path\": invalid_path},\n    )\n    assert_response(response)\n\n    response = requests.get(\n        f\"{mlflow_client.tracking_uri}/get-artifact\",\n        params={\"run_id\": run_id, \"path\": invalid_path},\n    )\n    assert_response(response)\n\n    response = requests.get(\n        f\"{mlflow_client.tracking_uri}//model-versions/get-artifact\",\n        params={\"name\": \"model\", \"version\": 1, \"path\": invalid_path},\n    )\n    assert_response(response)\n\n\ndef test_set_experiment_tag(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"SetExperimentTagTest\")\n    mlflow_client.set_experiment_tag(experiment_id, \"dataset\", \"imagenet1K\")\n    experiment = mlflow_client.get_experiment(experiment_id)\n    assert \"dataset\" in experiment.tags\n    assert experiment.tags[\"dataset\"] == \"imagenet1K\"\n    # test that updating a tag works\n    mlflow_client.set_experiment_tag(experiment_id, \"dataset\", \"birdbike\")\n    experiment = mlflow_client.get_experiment(experiment_id)\n    assert \"dataset\" in experiment.tags\n    assert experiment.tags[\"dataset\"] == \"birdbike\"\n    # test that setting a tag on 1 experiment does not impact another experiment.\n    experiment_id_2 = mlflow_client.create_experiment(\"SetExperimentTagTest2\")\n    experiment2 = mlflow_client.get_experiment(experiment_id_2)\n    assert len(experiment2.tags) == 0\n    # test that setting a tag on different experiments maintain different values across experiments\n    mlflow_client.set_experiment_tag(experiment_id_2, \"dataset\", \"birds200\")\n    experiment = mlflow_client.get_experiment(experiment_id)\n    experiment2 = mlflow_client.get_experiment(experiment_id_2)\n    assert \"dataset\" in experiment.tags\n    assert experiment.tags[\"dataset\"] == \"birdbike\"\n    assert \"dataset\" in experiment2.tags\n    assert experiment2.tags[\"dataset\"] == \"birds200\"\n    # test can set multi-line tags\n    mlflow_client.set_experiment_tag(experiment_id, \"multiline tag\", \"value2\\nvalue2\\nvalue2\")\n    experiment = mlflow_client.get_experiment(experiment_id)\n    assert \"multiline tag\" in experiment.tags\n    assert experiment.tags[\"multiline tag\"] == \"value2\\nvalue2\\nvalue2\"\n\n\ndef test_set_experiment_tag_with_empty_string_as_value(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\n        test_set_experiment_tag_with_empty_string_as_value.__name__\n    )\n    mlflow_client.set_experiment_tag(experiment_id, \"tag_key\", \"\")\n    assert {\"tag_key\": \"\"}.items() <= mlflow_client.get_experiment(experiment_id).tags.items()\n\n\ndef test_delete_tag(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"DeleteTagExperiment\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    mlflow_client.log_metric(run_id, key=\"metric\", value=123.456, timestamp=789, step=2)\n    mlflow_client.log_metric(run_id, key=\"stepless-metric\", value=987.654, timestamp=321)\n    mlflow_client.log_param(run_id, \"param\", \"value\")\n    mlflow_client.set_tag(run_id, \"taggity\", \"do-dah\")\n    run = mlflow_client.get_run(run_id)\n    assert \"taggity\" in run.data.tags\n    assert run.data.tags[\"taggity\"] == \"do-dah\"\n    mlflow_client.delete_tag(run_id, \"taggity\")\n    run = mlflow_client.get_run(run_id)\n    assert \"taggity\" not in run.data.tags\n    with pytest.raises(MlflowException, match=r\"Run .+ not found\"):\n        mlflow_client.delete_tag(\"fake_run_id\", \"taggity\")\n    with pytest.raises(MlflowException, match=\"No tag with name: fakeTag\"):\n        mlflow_client.delete_tag(run_id, \"fakeTag\")\n    mlflow_client.delete_run(run_id)\n    with pytest.raises(MlflowException, match=f\"The run {run_id} must be in\"):\n        mlflow_client.delete_tag(run_id, \"taggity\")\n\n\ndef test_log_batch(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Batch em up\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    mlflow_client.log_batch(\n        run_id=run_id,\n        metrics=[Metric(\"metric\", 123.456, 789, 3)],\n        params=[Param(\"param\", \"value\")],\n        tags=[RunTag(\"taggity\", \"do-dah\")],\n    )\n    run = mlflow_client.get_run(run_id)\n    assert run.data.metrics.get(\"metric\") == 123.456\n    assert run.data.params.get(\"param\") == \"value\"\n    assert run.data.tags.get(\"taggity\") == \"do-dah\"\n    metric_history = mlflow_client.get_metric_history(run_id, \"metric\")\n    assert len(metric_history) == 1\n    metric = metric_history[0]\n    assert metric.key == \"metric\"\n    assert metric.value == 123.456\n    assert metric.timestamp == 789\n    assert metric.step == 3\n\n\ndef test_log_batch_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log_batch validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/log-batch\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    for request_parameter in [\"metrics\", \"params\", \"tags\"]:\n        assert_bad_request(\n            {\n                \"run_id\": run_id,\n                request_parameter: \"foo\",\n            },\n            f\"Invalid value foo for parameter '{request_parameter}' supplied\",\n        )\n\n    ## Should 400 if missing timestamp\n    assert_bad_request(\n        {\"run_id\": run_id, \"metrics\": [{\"key\": \"mae\", \"value\": 2.5}]},\n        \"Invalid value [{'key': 'mae', 'value': 2.5}] for parameter 'metrics' supplied\",\n    )\n\n    ## Should 200 if timestamp provided but step is not\n    response = _send_rest_tracking_post_request(\n        mlflow_client.tracking_uri,\n        \"/api/2.0/mlflow/runs/log-batch\",\n        {\"run_id\": run_id, \"metrics\": [{\"key\": \"mae\", \"value\": 2.5, \"timestamp\": 123456789}]},\n    )\n\n    assert response.status_code == 200\n\n\n@pytest.mark.allow_infer_pip_requirements_fallback\ndef test_log_model(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Log models\")\n    with TempDir(chdr=True):\n        model_paths = [f\"model/path/{i}\" for i in range(3)]\n        mlflow.set_tracking_uri(mlflow_client.tracking_uri)\n        with mlflow.start_run(experiment_id=experiment_id) as run:\n            for i, m in enumerate(model_paths):\n                mlflow.pyfunc.log_model(m, loader_module=\"mlflow.pyfunc\")\n                mlflow.pyfunc.save_model(\n                    m,\n                    mlflow_model=Model(artifact_path=m, run_id=run.info.run_id),\n                    loader_module=\"mlflow.pyfunc\",\n                )\n                model = Model.load(os.path.join(m, \"MLmodel\"))\n                run = mlflow.get_run(run.info.run_id)\n                tag = run.data.tags[\"mlflow.log-model.history\"]\n                models = json.loads(tag)\n                model.utc_time_created = models[i][\"utc_time_created\"]\n\n                history_model_meta = models[i].copy()\n                original_model_uuid = history_model_meta.pop(\"model_uuid\")\n                model_meta = model.to_dict().copy()\n                new_model_uuid = model_meta.pop(\"model_uuid\")\n                assert history_model_meta == model_meta\n                assert original_model_uuid != new_model_uuid\n                assert len(models) == i + 1\n                for j in range(0, i + 1):\n                    assert models[j][\"artifact_path\"] == model_paths[j]\n\n\ndef test_set_terminated_defaults(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Terminator 1\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    assert mlflow_client.get_run(run_id).info.status == \"RUNNING\"\n    assert mlflow_client.get_run(run_id).info.end_time is None\n    mlflow_client.set_terminated(run_id)\n    assert mlflow_client.get_run(run_id).info.status == \"FINISHED\"\n    assert mlflow_client.get_run(run_id).info.end_time <= get_current_time_millis()\n\n\ndef test_set_terminated_status(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"Terminator 2\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n    assert mlflow_client.get_run(run_id).info.status == \"RUNNING\"\n    assert mlflow_client.get_run(run_id).info.end_time is None\n    mlflow_client.set_terminated(run_id, \"FAILED\")\n    assert mlflow_client.get_run(run_id).info.status == \"FAILED\"\n    assert mlflow_client.get_run(run_id).info.end_time <= get_current_time_millis()\n\n\ndef test_artifacts(mlflow_client, tmp_path):\n    experiment_id = mlflow_client.create_experiment(\"Art In Fact\")\n    experiment_info = mlflow_client.get_experiment(experiment_id)\n    assert experiment_info.artifact_location.startswith(path_to_local_file_uri(str(tmp_path)))\n    artifact_path = urllib.parse.urlparse(experiment_info.artifact_location).path\n    assert posixpath.split(artifact_path)[-1] == experiment_id\n\n    created_run = mlflow_client.create_run(experiment_id)\n    assert created_run.info.artifact_uri.startswith(experiment_info.artifact_location)\n    run_id = created_run.info.run_id\n    src_dir = tmp_path.joinpath(\"test_artifacts_src\")\n    src_dir.mkdir()\n    src_file = os.path.join(src_dir, \"my.file\")\n    with open(src_file, \"w\") as f:\n        f.write(\"Hello, World!\")\n    mlflow_client.log_artifact(run_id, src_file, None)\n    mlflow_client.log_artifacts(run_id, src_dir, \"dir\")\n\n    root_artifacts_list = mlflow_client.list_artifacts(run_id)\n    assert {a.path for a in root_artifacts_list} == {\"my.file\", \"dir\"}\n\n    dir_artifacts_list = mlflow_client.list_artifacts(run_id, \"dir\")\n    assert {a.path for a in dir_artifacts_list} == {\"dir/my.file\"}\n\n    all_artifacts = download_artifacts(\n        run_id=run_id, artifact_path=\".\", tracking_uri=mlflow_client.tracking_uri\n    )\n    with open(f\"{all_artifacts}/my.file\") as f:\n        assert f.read() == \"Hello, World!\"\n    with open(f\"{all_artifacts}/dir/my.file\") as f:\n        assert f.read() == \"Hello, World!\"\n\n    dir_artifacts = download_artifacts(\n        run_id=run_id, artifact_path=\"dir\", tracking_uri=mlflow_client.tracking_uri\n    )\n    with open(f\"{dir_artifacts}/my.file\") as f:\n        assert f.read() == \"Hello, World!\"\n\n\ndef test_search_pagination(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"search_pagination\")\n    runs = [mlflow_client.create_run(experiment_id, start_time=1).info.run_id for _ in range(0, 10)]\n    runs = sorted(runs)\n    result = mlflow_client.search_runs([experiment_id], max_results=4, page_token=None)\n    assert [r.info.run_id for r in result] == runs[0:4]\n    assert result.token is not None\n    result = mlflow_client.search_runs([experiment_id], max_results=4, page_token=result.token)\n    assert [r.info.run_id for r in result] == runs[4:8]\n    assert result.token is not None\n    result = mlflow_client.search_runs([experiment_id], max_results=4, page_token=result.token)\n    assert [r.info.run_id for r in result] == runs[8:]\n    assert result.token is None\n\n\ndef test_search_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"search_validation\")\n    with pytest.raises(\n        MlflowException, match=r\"Invalid value 123456789 for parameter 'max_results' supplied\"\n    ):\n        mlflow_client.search_runs([experiment_id], max_results=123456789)\n\n\ndef test_get_experiment_by_name(mlflow_client):\n    name = \"test_get_experiment_by_name\"\n    experiment_id = mlflow_client.create_experiment(name)\n    res = mlflow_client.get_experiment_by_name(name)\n    assert res.experiment_id == experiment_id\n    assert res.name == name\n    assert mlflow_client.get_experiment_by_name(\"idontexist\") is None\n\n\ndef test_get_experiment(mlflow_client):\n    name = \"test_get_experiment\"\n    experiment_id = mlflow_client.create_experiment(name)\n    res = mlflow_client.get_experiment(experiment_id)\n    assert res.experiment_id == experiment_id\n    assert res.name == name\n\n\ndef test_search_experiments(mlflow_client):\n    # To ensure the default experiment and non-default experiments have different creation_time\n    # for deterministic search results, send a request to the server and initialize the tracking\n    # store.\n    assert mlflow_client.search_experiments()[0].name == \"Default\"\n\n    experiments = [\n        (\"a\", {\"key\": \"value\"}),\n        (\"ab\", {\"key\": \"vaLue\"}),\n        (\"Abc\", None),\n    ]\n    experiment_ids = []\n    for name, tags in experiments:\n        # sleep for windows file system current_time precision in Python to enforce\n        # deterministic ordering based on last_update_time (creation_time due to no\n        # mutation of experiment state)\n        time.sleep(0.001)\n        experiment_ids.append(mlflow_client.create_experiment(name, tags=tags))\n\n    # filter_string\n    experiments = mlflow_client.search_experiments(filter_string=\"attribute.name = 'a'\")\n    assert [e.name for e in experiments] == [\"a\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"attribute.name != 'a'\")\n    assert [e.name for e in experiments] == [\"Abc\", \"ab\", \"Default\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"name LIKE 'a%'\")\n    assert [e.name for e in experiments] == [\"ab\", \"a\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"tag.key = 'value'\")\n    assert [e.name for e in experiments] == [\"a\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"tag.key != 'value'\")\n    assert [e.name for e in experiments] == [\"ab\"]\n    experiments = mlflow_client.search_experiments(filter_string=\"tag.key ILIKE '%alu%'\")\n    assert [e.name for e in experiments] == [\"ab\", \"a\"]\n\n    # order_by\n    experiments = mlflow_client.search_experiments(order_by=[\"name DESC\"])\n    assert [e.name for e in experiments] == [\"ab\", \"a\", \"Default\", \"Abc\"]\n\n    # max_results\n    experiments = mlflow_client.search_experiments(max_results=2)\n    assert [e.name for e in experiments] == [\"Abc\", \"ab\"]\n    # page_token\n    experiments = mlflow_client.search_experiments(page_token=experiments.token)\n    assert [e.name for e in experiments] == [\"a\", \"Default\"]\n\n    # view_type\n    time.sleep(0.001)\n    mlflow_client.delete_experiment(experiment_ids[1])\n    experiments = mlflow_client.search_experiments(view_type=ViewType.ACTIVE_ONLY)\n    assert [e.name for e in experiments] == [\"Abc\", \"a\", \"Default\"]\n    experiments = mlflow_client.search_experiments(view_type=ViewType.DELETED_ONLY)\n    assert [e.name for e in experiments] == [\"ab\"]\n    experiments = mlflow_client.search_experiments(view_type=ViewType.ALL)\n    assert [e.name for e in experiments] == [\"Abc\", \"ab\", \"a\", \"Default\"]\n\n\ndef test_get_metric_history_bulk_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    response_no_run_ids_field = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"metric_key\": \"key\"},\n    )\n    assert_response(\n        response_no_run_ids_field,\n        \"GetMetricHistoryBulk request must specify at least one run_id\",\n    )\n\n    response_empty_run_ids = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [], \"metric_key\": \"key\"},\n    )\n    assert_response(\n        response_empty_run_ids,\n        \"GetMetricHistoryBulk request must specify at least one run_id\",\n    )\n\n    response_too_many_run_ids = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [f\"id_{i}\" for i in range(1000)], \"metric_key\": \"key\"},\n    )\n    assert_response(\n        response_too_many_run_ids,\n        \"GetMetricHistoryBulk request cannot specify more than\",\n    )\n\n    response_no_metric_key_field = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [\"123\"]},\n    )\n    assert_response(\n        response_no_metric_key_field,\n        \"GetMetricHistoryBulk request must specify a metric_key\",\n    )\n\n\ndef test_get_metric_history_bulk_returns_expected_metrics_in_expected_order(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"get metric history bulk\")\n    created_run1 = mlflow_client.create_run(experiment_id)\n    run_id1 = created_run1.info.run_id\n    created_run2 = mlflow_client.create_run(experiment_id)\n    run_id2 = created_run2.info.run_id\n    created_run3 = mlflow_client.create_run(experiment_id)\n    run_id3 = created_run3.info.run_id\n\n    metricA_history = [\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 2, \"value\": 10.0},\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 3, \"value\": 11.0},\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 3, \"value\": 12.0},\n        {\"key\": \"metricA\", \"timestamp\": 2, \"step\": 3, \"value\": 12.0},\n    ]\n    for metric in metricA_history:\n        mlflow_client.log_metric(run_id1, **metric)\n        metric_for_run2 = dict(metric)\n        metric_for_run2[\"value\"] += 1.0\n        mlflow_client.log_metric(run_id2, **metric_for_run2)\n\n    metricB_history = [\n        {\"key\": \"metricB\", \"timestamp\": 7, \"step\": -2, \"value\": -100.0},\n        {\"key\": \"metricB\", \"timestamp\": 8, \"step\": 0, \"value\": 0.0},\n        {\"key\": \"metricB\", \"timestamp\": 8, \"step\": 0, \"value\": 1.0},\n        {\"key\": \"metricB\", \"timestamp\": 9, \"step\": 1, \"value\": 12.0},\n    ]\n    for metric in metricB_history:\n        mlflow_client.log_metric(run_id1, **metric)\n        metric_for_run2 = dict(metric)\n        metric_for_run2[\"value\"] += 1.0\n        mlflow_client.log_metric(run_id2, **metric_for_run2)\n\n    response_run1_metricA = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id1], \"metric_key\": \"metricA\"},\n    )\n    assert response_run1_metricA.status_code == 200\n    assert response_run1_metricA.json().get(\"metrics\") == [\n        {**metric, \"run_id\": run_id1} for metric in metricA_history\n    ]\n\n    response_run2_metricB = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id2], \"metric_key\": \"metricB\"},\n    )\n    assert response_run2_metricB.status_code == 200\n    assert response_run2_metricB.json().get(\"metrics\") == [\n        {**metric, \"run_id\": run_id2, \"value\": metric[\"value\"] + 1.0} for metric in metricB_history\n    ]\n\n    response_run1_run2_metricA = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id1, run_id2], \"metric_key\": \"metricA\"},\n    )\n    assert response_run1_run2_metricA.status_code == 200\n    assert response_run1_run2_metricA.json().get(\"metrics\") == sorted(\n        [{**metric, \"run_id\": run_id1} for metric in metricA_history]\n        + [\n            {**metric, \"run_id\": run_id2, \"value\": metric[\"value\"] + 1.0}\n            for metric in metricA_history\n        ],\n        key=lambda metric: metric[\"run_id\"],\n    )\n\n    response_run1_run2_run_3_metricB = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id1, run_id2, run_id3], \"metric_key\": \"metricB\"},\n    )\n    assert response_run1_run2_run_3_metricB.status_code == 200\n    assert response_run1_run2_run_3_metricB.json().get(\"metrics\") == sorted(\n        [{**metric, \"run_id\": run_id1} for metric in metricB_history]\n        + [\n            {**metric, \"run_id\": run_id2, \"value\": metric[\"value\"] + 1.0}\n            for metric in metricB_history\n        ],\n        key=lambda metric: metric[\"run_id\"],\n    )\n\n\ndef test_get_metric_history_bulk_respects_max_results(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"get metric history bulk\")\n    run_id = mlflow_client.create_run(experiment_id).info.run_id\n    max_results = 2\n\n    metricA_history = [\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 2, \"value\": 10.0},\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 3, \"value\": 11.0},\n        {\"key\": \"metricA\", \"timestamp\": 1, \"step\": 3, \"value\": 12.0},\n        {\"key\": \"metricA\", \"timestamp\": 2, \"step\": 3, \"value\": 12.0},\n    ]\n    for metric in metricA_history:\n        mlflow_client.log_metric(run_id, **metric)\n\n    response_limited = requests.get(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/metrics/get-history-bulk\",\n        params={\"run_id\": [run_id], \"metric_key\": \"metricA\", \"max_results\": max_results},\n    )\n    assert response_limited.status_code == 200\n    assert response_limited.json().get(\"metrics\") == [\n        {**metric, \"run_id\": run_id} for metric in metricA_history[:max_results]\n    ]\n\n\ndef test_get_metric_history_bulk_calls_optimized_impl_when_expected(tmp_path):\n    from mlflow.server.handlers import get_metric_history_bulk_handler\n\n    path = path_to_local_file_uri(str(tmp_path.joinpath(\"sqlalchemy.db\")))\n    uri = (\"sqlite://\" if sys.platform == \"win32\" else \"sqlite:////\") + path[len(\"file://\") :]\n    mock_store = mock.Mock(wraps=SqlAlchemyStore(uri, str(tmp_path)))\n\n    flask_app = flask.Flask(\"test_flask_app\")\n\n    class MockRequestArgs:\n        def __init__(self, args_dict):\n            self.args_dict = args_dict\n\n        def to_dict(\n            self,\n            flat,  # pylint: disable=unused-argument\n        ):\n            return self.args_dict\n\n        def get(self, key, default=None):\n            return self.args_dict.get(key, default)\n\n    with mock.patch(\n        \"mlflow.server.handlers._get_tracking_store\", return_value=mock_store\n    ), flask_app.test_request_context() as mock_context:\n        run_ids = [str(i) for i in range(10)]\n        mock_context.request.args = MockRequestArgs(\n            {\n                \"run_id\": run_ids,\n                \"metric_key\": \"mock_key\",\n            }\n        )\n\n        get_metric_history_bulk_handler()\n\n        mock_store.get_metric_history_bulk.assert_called_once_with(\n            run_ids=run_ids,\n            metric_key=\"mock_key\",\n            max_results=25000,\n        )\n\n\ndef test_search_dataset_handler_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    response_no_experiment_id_field = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/experiments/search-datasets\",\n        json={},\n    )\n    assert_response(\n        response_no_experiment_id_field,\n        \"SearchDatasets request must specify at least one experiment_id.\",\n    )\n\n    response_empty_experiment_id_field = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/experiments/search-datasets\",\n        json={\"experiment_ids\": []},\n    )\n    assert_response(\n        response_empty_experiment_id_field,\n        \"SearchDatasets request must specify at least one experiment_id.\",\n    )\n\n    response_too_many_experiment_ids = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/experiments/search-datasets\",\n        json={\"experiment_ids\": [f\"id_{i}\" for i in range(1000)]},\n    )\n    assert_response(\n        response_too_many_experiment_ids,\n        \"SearchDatasets request cannot specify more than\",\n    )\n\n\ndef test_search_dataset_handler_returns_expected_results(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log inputs test\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    dataset1 = Dataset(\n        name=\"name1\",\n        digest=\"digest1\",\n        source_type=\"source_type1\",\n        source=\"source1\",\n    )\n    dataset_inputs1 = [\n        DatasetInput(\n            dataset=dataset1, tags=[InputTag(key=MLFLOW_DATASET_CONTEXT, value=\"training\")]\n        )\n    ]\n    mlflow_client.log_inputs(run_id, dataset_inputs1)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/experiments/search-datasets\",\n        json={\"experiment_ids\": [experiment_id]},\n    )\n    expected = {\n        \"experiment_id\": experiment_id,\n        \"name\": \"name1\",\n        \"digest\": \"digest1\",\n        \"context\": \"training\",\n    }\n\n    assert response.status_code == 200\n    assert response.json().get(\"dataset_summaries\") == [expected]\n\n\ndef test_create_model_version_with_path_source(mlflow_client):\n    name = \"model\"\n    mlflow_client.create_registered_model(name)\n    exp_id = mlflow_client.create_experiment(\"test\")\n    run = mlflow_client.create_run(experiment_id=exp_id)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri[len(\"file://\") :],\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # run_id is not specified\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri[len(\"file://\") :],\n        },\n    )\n    assert response.status_code == 400\n    assert \"To use a local path as a model version\" in response.json()[\"message\"]\n\n    # run_id is specified but source is not in the run's artifact directory\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"/tmp\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"To use a local path as a model version\" in response.json()[\"message\"]\n\n\ndef test_create_model_version_with_non_local_source(mlflow_client):\n    name = \"model\"\n    mlflow_client.create_registered_model(name)\n    exp_id = mlflow_client.create_experiment(\"test\")\n    run = mlflow_client.create_run(experiment_id=exp_id)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri[len(\"file://\") :],\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Test that remote uri's supplied as a source with absolute paths work fine\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts:/models\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # A single trailing slash\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts:/models/\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Multiple trailing slashes\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts:/models///\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Multiple slashes\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts:/models/foo///bar\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Multiple dots\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models/artifact/..../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # Test that invalid remote uri's cannot be created\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"http://host:9000/models/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"https://host/api/2.0/mlflow-artifacts/artifacts/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"s3a://my_bucket/api/2.0/mlflow-artifacts/artifacts/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"ftp://host:8888/api/2.0/mlflow-artifacts/artifacts/../../../\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models/..%2f..%2fartifacts\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"mlflow-artifacts://host:9000/models/artifact%00\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"If supplying a source as an http, https,\" in response.json()[\"message\"]\n\n\ndef test_create_model_version_with_file_uri(mlflow_client):\n    name = \"test\"\n    mlflow_client.create_registered_model(name)\n    exp_id = mlflow_client.create_experiment(\"test\")\n    run = mlflow_client.create_run(experiment_id=exp_id)\n    assert run.info.artifact_uri.startswith(\"file://\")\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri,\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": f\"{run.info.artifact_uri}/model\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": f\"{run.info.artifact_uri}/.\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": f\"{run.info.artifact_uri}/model/..\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 200\n\n    # run_id is not specified\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": run.info.artifact_uri,\n        },\n    )\n    assert response.status_code == 400\n    assert \"To use a local path as a model version\" in response.json()[\"message\"]\n\n    # run_id is specified but source is not in the run's artifact directory\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"file:///tmp\",\n        },\n    )\n    assert response.status_code == 400\n    assert \"To use a local path as a model version\" in response.json()[\"message\"]\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n        json={\n            \"name\": name,\n            \"source\": \"file://123.456.789.123/path/to/source\",\n            \"run_id\": run.info.run_id,\n        },\n    )\n    assert response.status_code == 400\n    assert \"MLflow tracking server doesn't allow\" in response.json()[\"message\"]\n\n\ndef test_create_model_version_with_file_uri_env_var(tmp_path):\n    backend_uri = tmp_path.joinpath(\"file\").as_uri()\n    with _init_server(\n        backend_uri,\n        root_artifact_uri=tmp_path.as_uri(),\n        extra_env={\"MLFLOW_ALLOW_FILE_URI_AS_MODEL_VERSION_SOURCE\": \"true\"},\n    ) as url:\n        mlflow_client = MlflowClient(url)\n\n        name = \"test\"\n        mlflow_client.create_registered_model(name)\n        exp_id = mlflow_client.create_experiment(\"test\")\n        run = mlflow_client.create_run(experiment_id=exp_id)\n        response = requests.post(\n            f\"{mlflow_client.tracking_uri}/api/2.0/mlflow/model-versions/create\",\n            json={\n                \"name\": name,\n                \"source\": \"file://123.456.789.123/path/to/source\",\n                \"run_id\": run.info.run_id,\n            },\n        )\n        assert response.status_code == 200\n\n\ndef test_logging_model_with_local_artifact_uri(mlflow_client):\n    from sklearn.linear_model import LogisticRegression\n\n    mlflow.set_tracking_uri(mlflow_client.tracking_uri)\n    with mlflow.start_run() as run:\n        assert run.info.artifact_uri.startswith(\"file://\")\n        mlflow.sklearn.log_model(LogisticRegression(), \"model\", registered_model_name=\"rmn\")\n        mlflow.pyfunc.load_model(\"models:/rmn/1\")\n\n\ndef test_log_input(mlflow_client, tmp_path):\n    df = pd.DataFrame([[1, 2, 3], [1, 2, 3]], columns=[\"a\", \"b\", \"c\"])\n    path = tmp_path / \"temp.csv\"\n    df.to_csv(path)\n    dataset = from_pandas(df, source=path)\n\n    mlflow.set_tracking_uri(mlflow_client.tracking_uri)\n\n    with mlflow.start_run() as run:\n        mlflow.log_input(dataset, \"train\", {\"foo\": \"baz\"})\n\n    dataset_inputs = mlflow_client.get_run(run.info.run_id).inputs.dataset_inputs\n\n    assert len(dataset_inputs) == 1\n    assert dataset_inputs[0].dataset.name == \"dataset\"\n    assert dataset_inputs[0].dataset.digest == \"f0f3e026\"\n    assert dataset_inputs[0].dataset.source_type == \"local\"\n    assert json.loads(dataset_inputs[0].dataset.source) == {\"uri\": str(path)}\n    assert json.loads(dataset_inputs[0].dataset.schema) == {\n        \"mlflow_colspec\": [\n            {\"name\": \"a\", \"type\": \"long\"},\n            {\"name\": \"b\", \"type\": \"long\"},\n            {\"name\": \"c\", \"type\": \"long\"},\n        ]\n    }\n    assert json.loads(dataset_inputs[0].dataset.profile) == {\"num_rows\": 2, \"num_elements\": 6}\n\n    assert len(dataset_inputs[0].tags) == 2\n    assert dataset_inputs[0].tags[0].key == \"foo\"\n    assert dataset_inputs[0].tags[0].value == \"baz\"\n    assert dataset_inputs[0].tags[1].key == mlflow_tags.MLFLOW_DATASET_CONTEXT\n    assert dataset_inputs[0].tags[1].value == \"train\"\n\n\ndef test_log_inputs(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log inputs test\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    dataset1 = Dataset(\n        name=\"name1\",\n        digest=\"digest1\",\n        source_type=\"source_type1\",\n        source=\"source1\",\n    )\n    dataset_inputs1 = [DatasetInput(dataset=dataset1, tags=[InputTag(key=\"tag1\", value=\"value1\")])]\n\n    mlflow_client.log_inputs(run_id, dataset_inputs1)\n    run = mlflow_client.get_run(run_id)\n    assert len(run.inputs.dataset_inputs) == 1\n\n    assert isinstance(run.inputs, RunInputs)\n    assert isinstance(run.inputs.dataset_inputs[0], DatasetInput)\n    assert isinstance(run.inputs.dataset_inputs[0].dataset, Dataset)\n    assert run.inputs.dataset_inputs[0].dataset.name == \"name1\"\n    assert run.inputs.dataset_inputs[0].dataset.digest == \"digest1\"\n    assert run.inputs.dataset_inputs[0].dataset.source_type == \"source_type1\"\n    assert run.inputs.dataset_inputs[0].dataset.source == \"source1\"\n    assert len(run.inputs.dataset_inputs[0].tags) == 1\n    assert run.inputs.dataset_inputs[0].tags[0].key == \"tag1\"\n    assert run.inputs.dataset_inputs[0].tags[0].value == \"value1\"\n\n\ndef test_log_inputs_validation(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log inputs validation\")\n    created_run = mlflow_client.create_run(experiment_id)\n    run_id = created_run.info.run_id\n\n    def assert_bad_request(payload, expected_error_message):\n        response = _send_rest_tracking_post_request(\n            mlflow_client.tracking_uri,\n            \"/api/2.0/mlflow/runs/log-inputs\",\n            payload,\n        )\n        assert response.status_code == 400\n        assert expected_error_message in response.text\n\n    dataset = Dataset(\n        name=\"name1\",\n        digest=\"digest1\",\n        source_type=\"source_type1\",\n        source=\"source1\",\n    )\n    tags = [InputTag(key=\"tag1\", value=\"value1\")]\n    dataset_inputs = [message_to_json(DatasetInput(dataset=dataset, tags=tags).to_proto())]\n    assert_bad_request(\n        {\n            \"datasets\": dataset_inputs,\n        },\n        \"Missing value for required parameter 'run_id'\",\n    )\n    assert_bad_request(\n        {\n            \"run_id\": run_id,\n        },\n        \"Missing value for required parameter 'datasets'\",\n    )\n\n\ndef test_update_run_name_without_changing_status(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"update run name\")\n    created_run = mlflow_client.create_run(experiment_id)\n    mlflow_client.set_terminated(created_run.info.run_id, \"FINISHED\")\n\n    mlflow_client.update_run(created_run.info.run_id, name=\"name_abc\")\n    updated_run_info = mlflow_client.get_run(created_run.info.run_id).info\n    assert updated_run_info.run_name == \"name_abc\"\n    assert updated_run_info.status == \"FINISHED\"\n\n\ndef test_create_promptlab_run_handler_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={},\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify experiment_id.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\"experiment_id\": \"123\"},\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify prompt_template.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\"experiment_id\": \"123\", \"prompt_template\": \"my_prompt_template\"},\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify prompt_parameters.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": \"123\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n        },\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify model_route.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": \"123\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n            \"model_route\": \"my_route\",\n        },\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify model_input.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": \"123\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n            \"model_route\": \"my_route\",\n            \"model_input\": \"my_input\",\n        },\n    )\n    assert_response(\n        response,\n        \"CreatePromptlabRun request must specify mlflow_version.\",\n    )\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": \"123\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n            \"model_route\": \"my_route\",\n            \"model_input\": \"my_input\",\n            \"mlflow_version\": \"1.0.0\",\n        },\n    )\n\n\ndef test_create_promptlab_run_handler_returns_expected_results(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"log inputs test\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/runs/create-promptlab-run\",\n        json={\n            \"experiment_id\": experiment_id,\n            \"run_name\": \"my_run_name\",\n            \"prompt_template\": \"my_prompt_template\",\n            \"prompt_parameters\": [{\"key\": \"my_key\", \"value\": \"my_value\"}],\n            \"model_route\": \"my_route\",\n            \"model_parameters\": [{\"key\": \"temperature\", \"value\": \"0.1\"}],\n            \"model_input\": \"my_input\",\n            \"model_output\": \"my_output\",\n            \"model_output_parameters\": [{\"key\": \"latency\", \"value\": \"100\"}],\n            \"mlflow_version\": \"1.0.0\",\n            \"user_id\": \"username\",\n            \"start_time\": 456,\n        },\n    )\n    assert response.status_code == 200\n    run_json = response.json()\n    assert run_json[\"run\"][\"info\"][\"run_name\"] == \"my_run_name\"\n    assert run_json[\"run\"][\"info\"][\"experiment_id\"] == experiment_id\n    assert run_json[\"run\"][\"info\"][\"user_id\"] == \"username\"\n    assert run_json[\"run\"][\"info\"][\"status\"] == \"FINISHED\"\n    assert run_json[\"run\"][\"info\"][\"start_time\"] == 456\n\n    assert {\"key\": \"model_route\", \"value\": \"my_route\"} in run_json[\"run\"][\"data\"][\"params\"]\n    assert {\"key\": \"prompt_template\", \"value\": \"my_prompt_template\"} in run_json[\"run\"][\"data\"][\n        \"params\"\n    ]\n    assert {\"key\": \"temperature\", \"value\": \"0.1\"} in run_json[\"run\"][\"data\"][\"params\"]\n\n    assert {\n        \"key\": \"mlflow.loggedArtifacts\",\n        \"value\": '[{\"path\": \"eval_results_table.json\", ' '\"type\": \"table\"}]',\n    } in run_json[\"run\"][\"data\"][\"tags\"]\n    assert {\"key\": \"mlflow.runSourceType\", \"value\": \"PROMPT_ENGINEERING\"} in run_json[\"run\"][\n        \"data\"\n    ][\"tags\"]\n\n\ndef test_gateway_proxy_handler_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    with _init_server(\n        backend_uri=mlflow_client.tracking_uri,\n        root_artifact_uri=mlflow_client.tracking_uri,\n        extra_env={\"MLFLOW_DEPLOYMENTS_TARGET\": \"http://localhost:5001\"},\n    ) as url:\n        patched_client = MlflowClient(url)\n\n        response = requests.post(\n            f\"{patched_client.tracking_uri}/ajax-api/2.0/mlflow/gateway-proxy\",\n            json={},\n        )\n        assert_response(\n            response,\n            \"Deployments proxy request must specify a gateway_path.\",\n        )\n\n\ndef test_upload_artifact_handler_rejects_invalid_requests(mlflow_client):\n    def assert_response(resp, message_part):\n        assert resp.status_code == 400\n        response_json = resp.json()\n        assert response_json.get(\"error_code\") == \"INVALID_PARAMETER_VALUE\"\n        assert message_part in response_json.get(\"message\", \"\")\n\n    experiment_id = mlflow_client.create_experiment(\"upload_artifacts_test\")\n    created_run = mlflow_client.create_run(experiment_id)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\", params={}\n    )\n    assert_response(response, \"Request must specify run_uuid.\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\n            \"run_uuid\": created_run.info.run_id,\n        },\n    )\n    assert_response(response, \"Request must specify path.\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\"run_uuid\": created_run.info.run_id, \"path\": \"\"},\n    )\n    assert_response(response, \"Request must specify path.\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\"run_uuid\": created_run.info.run_id, \"path\": \"../test.txt\"},\n    )\n    assert_response(response, \"Invalid path\")\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\n            \"run_uuid\": created_run.info.run_id,\n            \"path\": \"test.txt\",\n        },\n    )\n    assert_response(response, \"Request must specify data.\")\n\n\ndef test_upload_artifact_handler(mlflow_client):\n    experiment_id = mlflow_client.create_experiment(\"upload_artifacts_test\")\n    created_run = mlflow_client.create_run(experiment_id)\n\n    response = requests.post(\n        f\"{mlflow_client.tracking_uri}/ajax-api/2.0/mlflow/upload-artifact\",\n        params={\n            \"run_uuid\": created_run.info.run_id,\n            \"path\": \"test.txt\",\n        },\n        data=\"hello world\",\n    )\n    assert response.status_code == 200\n\n    response = requests.get(\n        f\"{mlflow_client.tracking_uri}/get-artifact\",\n        params={\n            \"run_uuid\": created_run.info.run_id,\n            \"path\": \"test.txt\",\n        },\n    )\n    assert response.status_code == 200\n    assert response.text == \"hello world\"\n", "import pathlib\nimport posixpath\n\nimport pytest\n\nfrom mlflow.exceptions import MlflowException\nfrom mlflow.store.db.db_types import DATABASE_ENGINES\nfrom mlflow.utils.os import is_windows\nfrom mlflow.utils.uri import (\n    add_databricks_profile_info_to_artifact_uri,\n    append_to_uri_path,\n    append_to_uri_query_params,\n    dbfs_hdfs_uri_to_fuse_path,\n    extract_and_normalize_path,\n    extract_db_type_from_uri,\n    get_databricks_profile_uri_from_artifact_uri,\n    get_db_info_from_uri,\n    get_uri_scheme,\n    is_databricks_acled_artifacts_uri,\n    is_databricks_uri,\n    is_fuse_or_uc_volumes_uri,\n    is_http_uri,\n    is_local_uri,\n    is_valid_dbfs_uri,\n    remove_databricks_profile_info_from_artifact_uri,\n    resolve_uri_if_local,\n    validate_path_is_safe,\n)\n\n\ndef test_extract_db_type_from_uri():\n    uri = \"{}://username:password@host:port/database\"\n    for legit_db in DATABASE_ENGINES:\n        assert legit_db == extract_db_type_from_uri(uri.format(legit_db))\n        assert legit_db == get_uri_scheme(uri.format(legit_db))\n\n        with_driver = legit_db + \"+driver-string\"\n        assert legit_db == extract_db_type_from_uri(uri.format(with_driver))\n        assert legit_db == get_uri_scheme(uri.format(with_driver))\n\n    for unsupported_db in [\"a\", \"aa\", \"sql\"]:\n        with pytest.raises(MlflowException, match=\"Invalid database engine\"):\n            extract_db_type_from_uri(unsupported_db)\n\n\n@pytest.mark.parametrize(\n    (\"server_uri\", \"result\"),\n    [\n        (\"databricks://aAbB\", (\"aAbB\", None)),\n        (\"databricks://aAbB/\", (\"aAbB\", None)),\n        (\"databricks://aAbB/path\", (\"aAbB\", None)),\n        (\"databricks://profile:prefix\", (\"profile\", \"prefix\")),\n        (\"databricks://profile:prefix/extra\", (\"profile\", \"prefix\")),\n        (\"nondatabricks://profile:prefix\", (None, None)),\n        (\"databricks://profile\", (\"profile\", None)),\n        (\"databricks://profile/\", (\"profile\", None)),\n        (\"databricks-uc://profile:prefix\", (\"profile\", \"prefix\")),\n        (\"databricks-uc://profile:prefix/extra\", (\"profile\", \"prefix\")),\n        (\"databricks-uc://profile\", (\"profile\", None)),\n        (\"databricks-uc://profile/\", (\"profile\", None)),\n    ],\n)\ndef test_get_db_info_from_uri(server_uri, result):\n    assert get_db_info_from_uri(server_uri) == result\n\n\n@pytest.mark.parametrize(\n    \"server_uri\",\n    [\"databricks:/profile:prefix\", \"databricks:/\", \"databricks://\"],\n)\ndef test_get_db_info_from_uri_errors_no_netloc(server_uri):\n    with pytest.raises(MlflowException, match=\"URI is formatted incorrectly\"):\n        get_db_info_from_uri(server_uri)\n\n\n@pytest.mark.parametrize(\n    \"server_uri\",\n    [\n        \"databricks://profile:prefix:extra\",\n        \"databricks://profile:prefix:extra  \",\n        \"databricks://profile:prefix extra\",\n        \"databricks://profile:prefix  \",\n        \"databricks://profile \",\n        \"databricks://profile:\",\n        \"databricks://profile: \",\n    ],\n)\ndef test_get_db_info_from_uri_errors_invalid_profile(server_uri):\n    with pytest.raises(MlflowException, match=\"Unsupported Databricks profile\"):\n        get_db_info_from_uri(server_uri)\n\n\ndef test_is_local_uri():\n    assert is_local_uri(\"mlruns\")\n    assert is_local_uri(\"./mlruns\")\n    assert is_local_uri(\"file:///foo/mlruns\")\n    assert is_local_uri(\"file:foo/mlruns\")\n    assert is_local_uri(\"file://./mlruns\")\n    assert is_local_uri(\"file://localhost/mlruns\")\n    assert is_local_uri(\"file://localhost:5000/mlruns\")\n    assert is_local_uri(\"file://127.0.0.1/mlruns\")\n    assert is_local_uri(\"file://127.0.0.1:5000/mlruns\")\n    assert is_local_uri(\"//proc/self/root\")\n    assert is_local_uri(\"/proc/self/root\")\n\n    assert not is_local_uri(\"file://myhostname/path/to/file\")\n    assert not is_local_uri(\"https://whatever\")\n    assert not is_local_uri(\"http://whatever\")\n    assert not is_local_uri(\"databricks\")\n    assert not is_local_uri(\"databricks:whatever\")\n    assert not is_local_uri(\"databricks://whatever\")\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"Windows-only test\")\ndef test_is_local_uri_windows():\n    assert is_local_uri(\"C:\\\\foo\\\\mlruns\")\n    assert is_local_uri(\"C:/foo/mlruns\")\n    assert is_local_uri(\"file:///C:\\\\foo\\\\mlruns\")\n    assert not is_local_uri(\"\\\\\\\\server\\\\aa\\\\bb\")\n\n\ndef test_is_databricks_uri():\n    assert is_databricks_uri(\"databricks\")\n    assert is_databricks_uri(\"databricks:whatever\")\n    assert is_databricks_uri(\"databricks://whatever\")\n    assert not is_databricks_uri(\"mlruns\")\n    assert not is_databricks_uri(\"http://whatever\")\n\n\ndef test_is_http_uri():\n    assert is_http_uri(\"http://whatever\")\n    assert is_http_uri(\"https://whatever\")\n    assert not is_http_uri(\"file://whatever\")\n    assert not is_http_uri(\"databricks://whatever\")\n    assert not is_http_uri(\"mlruns\")\n\n\ndef validate_append_to_uri_path_test_cases(cases):\n    for input_uri, input_path, expected_output_uri in cases:\n        assert append_to_uri_path(input_uri, input_path) == expected_output_uri\n        assert append_to_uri_path(input_uri, *posixpath.split(input_path)) == expected_output_uri\n\n\ndef test_append_to_uri_path_joins_uri_paths_and_posixpaths_correctly():\n    validate_append_to_uri_path_test_cases(\n        [\n            (\"\", \"path\", \"path\"),\n            (\"\", \"/path\", \"/path\"),\n            (\"path\", \"\", \"path/\"),\n            (\"path\", \"subpath\", \"path/subpath\"),\n            (\"path/\", \"subpath\", \"path/subpath\"),\n            (\"path/\", \"/subpath\", \"path/subpath\"),\n            (\"path\", \"/subpath\", \"path/subpath\"),\n            (\"/path\", \"/subpath\", \"/path/subpath\"),\n            (\"//path\", \"/subpath\", \"//path/subpath\"),\n            (\"///path\", \"/subpath\", \"///path/subpath\"),\n            (\"/path\", \"/subpath/subdir\", \"/path/subpath/subdir\"),\n            (\"file:path\", \"\", \"file:path/\"),\n            (\"file:path/\", \"\", \"file:path/\"),\n            (\"file:path\", \"subpath\", \"file:path/subpath\"),\n            (\"file:path\", \"/subpath\", \"file:path/subpath\"),\n            (\"file:/\", \"\", \"file:///\"),\n            (\"file:/path\", \"/subpath\", \"file:///path/subpath\"),\n            (\"file:///\", \"\", \"file:///\"),\n            (\"file:///\", \"subpath\", \"file:///subpath\"),\n            (\"file:///path\", \"/subpath\", \"file:///path/subpath\"),\n            (\"file:///path/\", \"subpath\", \"file:///path/subpath\"),\n            (\"file:///path\", \"subpath\", \"file:///path/subpath\"),\n            (\"s3://\", \"\", \"s3:\"),\n            (\"s3://\", \"subpath\", \"s3:subpath\"),\n            (\"s3://\", \"/subpath\", \"s3:/subpath\"),\n            (\"s3://host\", \"subpath\", \"s3://host/subpath\"),\n            (\"s3://host\", \"/subpath\", \"s3://host/subpath\"),\n            (\"s3://host/\", \"subpath\", \"s3://host/subpath\"),\n            (\"s3://host/\", \"/subpath\", \"s3://host/subpath\"),\n            (\"s3://host\", \"subpath/subdir\", \"s3://host/subpath/subdir\"),\n        ]\n    )\n\n\ndef test_append_to_uri_path_handles_special_uri_characters_in_posixpaths():\n    \"\"\"\n    Certain characters are treated specially when parsing and interpreting URIs. However, in the\n    case where a URI input for `append_to_uri_path` is simply a POSIX path, these characters should\n    not receive special treatment. This test case verifies that `append_to_uri_path` properly joins\n    POSIX paths containing these characters.\n    \"\"\"\n\n    def create_char_case(special_char):\n        def char_case(*case_args):\n            return tuple([item.format(c=special_char) for item in case_args])\n\n        return char_case\n\n    for special_char in [\n        \".\",\n        \"-\",\n        \"+\",\n        \":\",\n        \"?\",\n        \"@\",\n        \"&\",\n        \"$\",\n        \"%\",\n        \"/\",\n        \"[\",\n        \"]\",\n        \"(\",\n        \")\",\n        \"*\",\n        \"'\",\n        \",\",\n    ]:\n        char_case = create_char_case(special_char)\n        validate_append_to_uri_path_test_cases(\n            [\n                char_case(\"\", \"{c}subpath\", \"{c}subpath\"),\n                char_case(\"\", \"/{c}subpath\", \"/{c}subpath\"),\n                char_case(\"dirwith{c}{c}chars\", \"\", \"dirwith{c}{c}chars/\"),\n                char_case(\"dirwith{c}{c}chars\", \"subpath\", \"dirwith{c}{c}chars/subpath\"),\n                char_case(\"{c}{c}charsdir\", \"\", \"{c}{c}charsdir/\"),\n                char_case(\"/{c}{c}charsdir\", \"\", \"/{c}{c}charsdir/\"),\n                char_case(\"/{c}{c}charsdir\", \"subpath\", \"/{c}{c}charsdir/subpath\"),\n                char_case(\"/{c}{c}charsdir\", \"subpath\", \"/{c}{c}charsdir/subpath\"),\n            ]\n        )\n\n    validate_append_to_uri_path_test_cases(\n        [\n            (\"#?charsdir:\", \":?subpath#\", \"#?charsdir:/:?subpath#\"),\n            (\"/#--+charsdir.//:\", \"/../:?subpath#\", \"/#--+charsdir.//:/../:?subpath#\"),\n            (\"$@''(,\", \")]*%\", \"$@''(,/)]*%\"),\n        ]\n    )\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"existing_query_params\", \"query_params\", \"expected\"),\n    [\n        (\"https://example.com\", \"\", [(\"key\", \"value\")], \"https://example.com?key=value\"),\n        (\n            \"https://example.com\",\n            \"existing_key=existing_value\",\n            [(\"new_key\", \"new_value\")],\n            \"https://example.com?existing_key=existing_value&new_key=new_value\",\n        ),\n        (\n            \"https://example.com\",\n            \"\",\n            [(\"key1\", \"value1\"), (\"key2\", \"value2\"), (\"key3\", \"value3\")],\n            \"https://example.com?key1=value1&key2=value2&key3=value3\",\n        ),\n        (\n            \"https://example.com\",\n            \"\",\n            [(\"key\", \"value with spaces\"), (\"key2\", \"special#characters\")],\n            \"https://example.com?key=value+with+spaces&key2=special%23characters\",\n        ),\n        (\"\", \"\", [(\"key\", \"value\")], \"?key=value\"),\n        (\"https://example.com\", \"\", [], \"https://example.com\"),\n        (\n            \"https://example.com\",\n            \"\",\n            [(\"key1\", 123), (\"key2\", 456)],\n            \"https://example.com?key1=123&key2=456\",\n        ),\n        (\n            \"https://example.com?existing_key=existing_value\",\n            \"\",\n            [(\"existing_key\", \"new_value\"), (\"existing_key\", \"new_value_2\")],\n            \"https://example.com?existing_key=existing_value&existing_key=new_value&existing_key=new_value_2\",\n        ),\n        (\n            \"s3://bucket/key\",\n            \"prev1=foo&prev2=bar\",\n            [(\"param1\", \"value1\"), (\"param2\", \"value2\")],\n            \"s3://bucket/key?prev1=foo&prev2=bar&param1=value1&param2=value2\",\n        ),\n        (\n            \"s3://bucket/key?existing_param=existing_value\",\n            \"\",\n            [(\"new_param\", \"new_value\")],\n            \"s3://bucket/key?existing_param=existing_value&new_param=new_value\",\n        ),\n    ],\n)\ndef test_append_to_uri_query_params_appends_as_expected(\n    uri, existing_query_params, query_params, expected\n):\n    if existing_query_params:\n        uri += f\"?{existing_query_params}\"\n\n    result = append_to_uri_query_params(uri, *query_params)\n    assert result == expected\n\n\ndef test_append_to_uri_path_preserves_uri_schemes_hosts_queries_and_fragments():\n    validate_append_to_uri_path_test_cases(\n        [\n            (\"dbscheme+dbdriver:\", \"\", \"dbscheme+dbdriver:\"),\n            (\"dbscheme+dbdriver:\", \"subpath\", \"dbscheme+dbdriver:subpath\"),\n            (\"dbscheme+dbdriver:path\", \"subpath\", \"dbscheme+dbdriver:path/subpath\"),\n            (\"dbscheme+dbdriver://host/path\", \"/subpath\", \"dbscheme+dbdriver://host/path/subpath\"),\n            (\"dbscheme+dbdriver:///path\", \"subpath\", \"dbscheme+dbdriver:/path/subpath\"),\n            (\"dbscheme+dbdriver:?somequery\", \"subpath\", \"dbscheme+dbdriver:subpath?somequery\"),\n            (\"dbscheme+dbdriver:?somequery\", \"/subpath\", \"dbscheme+dbdriver:/subpath?somequery\"),\n            (\"dbscheme+dbdriver:/?somequery\", \"subpath\", \"dbscheme+dbdriver:/subpath?somequery\"),\n            (\"dbscheme+dbdriver://?somequery\", \"subpath\", \"dbscheme+dbdriver:subpath?somequery\"),\n            (\"dbscheme+dbdriver:///?somequery\", \"/subpath\", \"dbscheme+dbdriver:/subpath?somequery\"),\n            (\"dbscheme+dbdriver:#somefrag\", \"subpath\", \"dbscheme+dbdriver:subpath#somefrag\"),\n            (\"dbscheme+dbdriver:#somefrag\", \"/subpath\", \"dbscheme+dbdriver:/subpath#somefrag\"),\n            (\"dbscheme+dbdriver:/#somefrag\", \"subpath\", \"dbscheme+dbdriver:/subpath#somefrag\"),\n            (\"dbscheme+dbdriver://#somefrag\", \"subpath\", \"dbscheme+dbdriver:subpath#somefrag\"),\n            (\"dbscheme+dbdriver:///#somefrag\", \"/subpath\", \"dbscheme+dbdriver:/subpath#somefrag\"),\n            (\n                \"dbscheme+dbdriver://root:password?creds=creds\",\n                \"subpath\",\n                \"dbscheme+dbdriver://root:password/subpath?creds=creds\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password/path/?creds=creds\",\n                \"/subpath/anotherpath\",\n                \"dbscheme+dbdriver://root:password/path/subpath/anotherpath?creds=creds\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password///path/?creds=creds\",\n                \"subpath/anotherpath\",\n                \"dbscheme+dbdriver://root:password///path/subpath/anotherpath?creds=creds\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password///path/?creds=creds\",\n                \"/subpath\",\n                \"dbscheme+dbdriver://root:password///path/subpath?creds=creds\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password#myfragment\",\n                \"/subpath\",\n                \"dbscheme+dbdriver://root:password/subpath#myfragment\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password//path/#fragmentwith$pecial@\",\n                \"subpath/anotherpath\",\n                \"dbscheme+dbdriver://root:password//path/subpath/anotherpath#fragmentwith$pecial@\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password@host?creds=creds#fragmentwith$pecial@\",\n                \"subpath\",\n                \"dbscheme+dbdriver://root:password@host/subpath?creds=creds#fragmentwith$pecial@\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password@host.com/path?creds=creds#*frag@*\",\n                \"subpath/dir\",\n                \"dbscheme+dbdriver://root:password@host.com/path/subpath/dir?creds=creds#*frag@*\",\n            ),\n            (\n                \"dbscheme-dbdriver://root:password@host.com/path?creds=creds#*frag@*\",\n                \"subpath/dir\",\n                \"dbscheme-dbdriver://root:password@host.com/path/subpath/dir?creds=creds#*frag@*\",\n            ),\n            (\n                \"dbscheme+dbdriver://root:password@host.com/path?creds=creds,param=value#*frag@*\",\n                \"subpath/dir\",\n                \"dbscheme+dbdriver://root:password@host.com/path/subpath/dir?\"\n                \"creds=creds,param=value#*frag@*\",\n            ),\n        ]\n    )\n\n\ndef test_extract_and_normalize_path():\n    base_uri = \"databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\"\n    assert (\n        extract_and_normalize_path(\"dbfs:databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\")\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\"dbfs:/databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\")\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\"dbfs:///databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\")\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\n            \"dbfs:/databricks///mlflow-tracking///EXP_ID///RUN_ID///artifacts/\"\n        )\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\n            \"dbfs:///databricks///mlflow-tracking//EXP_ID//RUN_ID///artifacts//\"\n        )\n        == base_uri\n    )\n    assert (\n        extract_and_normalize_path(\n            \"dbfs:databricks///mlflow-tracking//EXP_ID//RUN_ID///artifacts//\"\n        )\n        == base_uri\n    )\n\n\ndef test_is_databricks_acled_artifacts_uri():\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:/databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:///databricks/mlflow-tracking/EXP_ID/RUN_ID/artifacts\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:/databricks///mlflow-tracking///EXP_ID///RUN_ID///artifacts/\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:///databricks///mlflow-tracking//EXP_ID//RUN_ID///artifacts//\"\n    )\n    assert is_databricks_acled_artifacts_uri(\n        \"dbfs:databricks///mlflow-tracking//EXP_ID//RUN_ID///artifacts//\"\n    )\n    assert not is_databricks_acled_artifacts_uri(\n        \"dbfs:/databricks/mlflow//EXP_ID//RUN_ID///artifacts//\"\n    )\n\n\ndef _get_databricks_profile_uri_test_cases():\n    # Each test case is (uri, result, result_scheme)\n    test_case_groups = [\n        [\n            # URIs with no databricks profile info -> return None\n            (\"ftp://user:pass@realhost:port/path/to/nowhere\", None, result_scheme),\n            (\"dbfs:/path/to/nowhere\", None, result_scheme),\n            (\"dbfs://nondatabricks/path/to/nowhere\", None, result_scheme),\n            (\"dbfs://incorrect:netloc:format/path/to/nowhere\", None, result_scheme),\n            # URIs with legit databricks profile info\n            (f\"dbfs://{result_scheme}\", result_scheme, result_scheme),\n            (f\"dbfs://{result_scheme}/\", result_scheme, result_scheme),\n            (f\"dbfs://{result_scheme}/path/to/nowhere\", result_scheme, result_scheme),\n            (f\"dbfs://{result_scheme}:port/path/to/nowhere\", result_scheme, result_scheme),\n            (f\"dbfs://@{result_scheme}/path/to/nowhere\", result_scheme, result_scheme),\n            (f\"dbfs://@{result_scheme}:port/path/to/nowhere\", result_scheme, result_scheme),\n            (\n                f\"dbfs://profile@{result_scheme}/path/to/nowhere\",\n                f\"{result_scheme}://profile\",\n                result_scheme,\n            ),\n            (\n                f\"dbfs://profile@{result_scheme}:port/path/to/nowhere\",\n                f\"{result_scheme}://profile\",\n                result_scheme,\n            ),\n            (\n                f\"dbfs://scope:key_prefix@{result_scheme}/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n            (\n                f\"dbfs://scope:key_prefix@{result_scheme}:port/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n            # Doesn't care about the scheme of the artifact URI\n            (\n                f\"runs://scope:key_prefix@{result_scheme}/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n            (\n                f\"models://scope:key_prefix@{result_scheme}/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n            (\n                f\"s3://scope:key_prefix@{result_scheme}/path/abc\",\n                f\"{result_scheme}://scope:key_prefix\",\n                result_scheme,\n            ),\n        ]\n        for result_scheme in [\"databricks\", \"databricks-uc\"]\n    ]\n    return [test_case for test_case_group in test_case_groups for test_case in test_case_group]\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"result\", \"result_scheme\"), _get_databricks_profile_uri_test_cases()\n)\ndef test_get_databricks_profile_uri_from_artifact_uri(uri, result, result_scheme):\n    assert get_databricks_profile_uri_from_artifact_uri(uri, result_scheme=result_scheme) == result\n\n\n@pytest.mark.parametrize(\n    \"uri\",\n    [\n        # Treats secret key prefixes with \":\" to be invalid\n        \"dbfs://incorrect:netloc:format@databricks/path/a\",\n        \"dbfs://scope::key_prefix@databricks/path/abc\",\n        \"dbfs://scope:key_prefix:@databricks/path/abc\",\n    ],\n)\ndef test_get_databricks_profile_uri_from_artifact_uri_error_cases(uri):\n    with pytest.raises(MlflowException, match=\"Unsupported Databricks profile\"):\n        get_databricks_profile_uri_from_artifact_uri(uri)\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"result\"),\n    [\n        # URIs with no databricks profile info should stay the same\n        (\n            \"ftp://user:pass@realhost:port/path/nowhere\",\n            \"ftp://user:pass@realhost:port/path/nowhere\",\n        ),\n        (\"dbfs:/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://nondatabricks/path/to/nowhere\", \"dbfs://nondatabricks/path/to/nowhere\"),\n        (\"dbfs://incorrect:netloc:format/path/\", \"dbfs://incorrect:netloc:format/path/\"),\n        # URIs with legit databricks profile info\n        (\"dbfs://databricks\", \"dbfs:\"),\n        (\"dbfs://databricks/\", \"dbfs:/\"),\n        (\"dbfs://databricks/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://databricks:port/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://@databricks/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://@databricks:port/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://profile@databricks/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://profile@databricks:port/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        (\"dbfs://scope:key_prefix@databricks/path/abc\", \"dbfs:/path/abc\"),\n        (\"dbfs://scope:key_prefix@databricks:port/path/abc\", \"dbfs:/path/abc\"),\n        # Treats secret key prefixes with \":\" to be valid\n        (\"dbfs://incorrect:netloc:format@databricks/path/to/nowhere\", \"dbfs:/path/to/nowhere\"),\n        # Doesn't care about the scheme of the artifact URI\n        (\"runs://scope:key_prefix@databricks/path/abc\", \"runs:/path/abc\"),\n        (\"models://scope:key_prefix@databricks/path/abc\", \"models:/path/abc\"),\n        (\"s3://scope:key_prefix@databricks/path/abc\", \"s3:/path/abc\"),\n    ],\n)\ndef test_remove_databricks_profile_info_from_artifact_uri(uri, result):\n    assert remove_databricks_profile_info_from_artifact_uri(uri) == result\n\n\n@pytest.mark.parametrize(\n    (\"artifact_uri\", \"profile_uri\", \"result\"),\n    [\n        # test various profile URIs\n        (\"dbfs:/path/a/b\", \"databricks\", \"dbfs://databricks/path/a/b\"),\n        (\"dbfs:/path/a/b/\", \"databricks\", \"dbfs://databricks/path/a/b/\"),\n        (\"dbfs:/path/a/b/\", \"databricks://Profile\", \"dbfs://Profile@databricks/path/a/b/\"),\n        (\"dbfs:/path/a/b/\", \"databricks://profile/\", \"dbfs://profile@databricks/path/a/b/\"),\n        (\"dbfs:/path/a/b/\", \"databricks://scope:key\", \"dbfs://scope:key@databricks/path/a/b/\"),\n        (\n            \"dbfs:/path/a/b/\",\n            \"databricks://scope:key/random_stuff\",\n            \"dbfs://scope:key@databricks/path/a/b/\",\n        ),\n        (\"dbfs:/path/a/b/\", \"nondatabricks://profile\", \"dbfs:/path/a/b/\"),\n        # test various artifact schemes\n        (\"runs:/path/a/b/\", \"databricks://Profile\", \"runs://Profile@databricks/path/a/b/\"),\n        (\"runs:/path/a/b/\", \"nondatabricks://profile\", \"runs:/path/a/b/\"),\n        (\"models:/path/a/b/\", \"databricks://profile\", \"models://profile@databricks/path/a/b/\"),\n        (\"models:/path/a/b/\", \"nondatabricks://Profile\", \"models:/path/a/b/\"),\n        (\"s3:/path/a/b/\", \"databricks://Profile\", \"s3:/path/a/b/\"),\n        (\"s3:/path/a/b/\", \"nondatabricks://profile\", \"s3:/path/a/b/\"),\n        (\"ftp:/path/a/b/\", \"databricks://profile\", \"ftp:/path/a/b/\"),\n        (\"ftp:/path/a/b/\", \"nondatabricks://Profile\", \"ftp:/path/a/b/\"),\n        # test artifact URIs already with authority\n        (\"ftp://user:pass@host:port/a/b\", \"databricks://Profile\", \"ftp://user:pass@host:port/a/b\"),\n        (\"ftp://user:pass@host:port/a/b\", \"nothing://Profile\", \"ftp://user:pass@host:port/a/b\"),\n        (\"dbfs://databricks\", \"databricks://OtherProfile\", \"dbfs://databricks\"),\n        (\"dbfs://databricks\", \"nondatabricks://Profile\", \"dbfs://databricks\"),\n        (\"dbfs://databricks/path/a/b\", \"databricks://OtherProfile\", \"dbfs://databricks/path/a/b\"),\n        (\"dbfs://databricks/path/a/b\", \"nondatabricks://Profile\", \"dbfs://databricks/path/a/b\"),\n        (\"dbfs://@databricks/path/a/b\", \"databricks://OtherProfile\", \"dbfs://@databricks/path/a/b\"),\n        (\"dbfs://@databricks/path/a/b\", \"nondatabricks://Profile\", \"dbfs://@databricks/path/a/b\"),\n        (\n            \"dbfs://profile@databricks/pp\",\n            \"databricks://OtherProfile\",\n            \"dbfs://profile@databricks/pp\",\n        ),\n        (\n            \"dbfs://profile@databricks/path\",\n            \"databricks://profile\",\n            \"dbfs://profile@databricks/path\",\n        ),\n        (\n            \"dbfs://profile@databricks/path\",\n            \"nondatabricks://Profile\",\n            \"dbfs://profile@databricks/path\",\n        ),\n    ],\n)\ndef test_add_databricks_profile_info_to_artifact_uri(artifact_uri, profile_uri, result):\n    assert add_databricks_profile_info_to_artifact_uri(artifact_uri, profile_uri) == result\n\n\n@pytest.mark.parametrize(\n    (\"artifact_uri\", \"profile_uri\"),\n    [\n        (\"dbfs:/path/a/b\", \"databricks://not:legit:auth\"),\n        (\"dbfs:/path/a/b/\", \"databricks://scope::key\"),\n        (\"dbfs:/path/a/b/\", \"databricks://scope:key:/\"),\n        (\"dbfs:/path/a/b/\", \"databricks://scope:key \"),\n    ],\n)\ndef test_add_databricks_profile_info_to_artifact_uri_errors(artifact_uri, profile_uri):\n    with pytest.raises(MlflowException, match=\"Unsupported Databricks profile\"):\n        add_databricks_profile_info_to_artifact_uri(artifact_uri, profile_uri)\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"result\"),\n    [\n        (\"dbfs:/path/a/b\", True),\n        (\"dbfs://databricks/a/b\", True),\n        (\"dbfs://@databricks/a/b\", True),\n        (\"dbfs://profile@databricks/a/b\", True),\n        (\"dbfs://scope:key@databricks/a/b\", True),\n        (\"dbfs://scope:key:@databricks/a/b\", False),\n        (\"dbfs://scope::key@databricks/a/b\", False),\n        (\"dbfs://profile@notdatabricks/a/b\", False),\n        (\"dbfs://scope:key@notdatabricks/a/b\", False),\n        (\"dbfs://scope:key/a/b\", False),\n        (\"dbfs://notdatabricks/a/b\", False),\n        (\"s3:/path/a/b\", False),\n        (\"ftp://user:pass@host:port/path/a/b\", False),\n        (\"ftp://user:pass@databricks/path/a/b\", False),\n    ],\n)\ndef test_is_valid_dbfs_uri(uri, result):\n    assert is_valid_dbfs_uri(uri) == result\n\n\n@pytest.mark.parametrize(\n    (\"uri\", \"result\"),\n    [\n        (\"/tmp/path\", \"/dbfs/tmp/path\"),\n        (\"dbfs:/path\", \"/dbfs/path\"),\n        (\"dbfs:/path/a/b\", \"/dbfs/path/a/b\"),\n        (\"dbfs:/dbfs/123/abc\", \"/dbfs/dbfs/123/abc\"),\n    ],\n)\ndef test_dbfs_hdfs_uri_to_fuse_path(uri, result):\n    assert dbfs_hdfs_uri_to_fuse_path(uri) == result\n\n\n@pytest.mark.parametrize(\n    \"path\",\n    [\"some/relative/local/path\", \"s3:/some/s3/path\", \"C:/cool/windows/path\"],\n)\ndef test_dbfs_hdfs_uri_to_fuse_path_raises(path):\n    with pytest.raises(MlflowException, match=\"did not start with expected DBFS URI prefix\"):\n        dbfs_hdfs_uri_to_fuse_path(path)\n\n\ndef _assert_resolve_uri_if_local(input_uri, expected_uri):\n    cwd = pathlib.Path.cwd().as_posix()\n    drive = pathlib.Path.cwd().drive\n    if is_windows():\n        cwd = f\"/{cwd}\"\n        drive = f\"{drive}/\"\n    assert resolve_uri_if_local(input_uri) == expected_uri.format(cwd=cwd, drive=drive)\n\n\n@pytest.mark.skipif(is_windows(), reason=\"This test fails on Windows\")\n@pytest.mark.parametrize(\n    (\"input_uri\", \"expected_uri\"),\n    [\n        (\"my/path\", \"{cwd}/my/path\"),\n        (\"#my/path?a=b\", \"{cwd}/#my/path?a=b\"),\n        (\"file://myhostname/my/path\", \"file://myhostname/my/path\"),\n        (\"file:///my/path\", \"file:///{drive}my/path\"),\n        (\"file:my/path\", \"file://{cwd}/my/path\"),\n        (\"/home/my/path\", \"/home/my/path\"),\n        (\"dbfs://databricks/a/b\", \"dbfs://databricks/a/b\"),\n        (\"s3://host/my/path\", \"s3://host/my/path\"),\n    ],\n)\ndef test_resolve_uri_if_local(input_uri, expected_uri):\n    _assert_resolve_uri_if_local(input_uri, expected_uri)\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"This test only passes on Windows\")\n@pytest.mark.parametrize(\n    (\"input_uri\", \"expected_uri\"),\n    [\n        (\"my/path\", \"file://{cwd}/my/path\"),\n        (\"#my/path?a=b\", \"file://{cwd}/#my/path?a=b\"),\n        (\"file://myhostname/my/path\", \"file://myhostname/my/path\"),\n        (\"file:///my/path\", \"file:///{drive}my/path\"),\n        (\"file:my/path\", \"file://{cwd}/my/path\"),\n        (\"/home/my/path\", \"file:///{drive}home/my/path\"),\n        (\"dbfs://databricks/a/b\", \"dbfs://databricks/a/b\"),\n        (\"s3://host/my/path\", \"s3://host/my/path\"),\n    ],\n)\ndef test_resolve_uri_if_local_on_windows(input_uri, expected_uri):\n    _assert_resolve_uri_if_local(input_uri, expected_uri)\n\n\n@pytest.mark.parametrize(\n    \"uri\",\n    [\n        \"/dbfs/my_path\",\n        \"dbfs:/my_path\",\n        \"/Volumes/my_path\",\n        \"/.fuse-mounts/my_path\",\n        \"//dbfs////my_path\",\n        \"///Volumes/\",\n        \"dbfs://my///path\",\n    ],\n)\ndef test_correctly_detect_fuse_and_uc_uris(uri):\n    assert is_fuse_or_uc_volumes_uri(uri)\n\n\n@pytest.mark.parametrize(\n    \"uri\",\n    [\n        \"/My_Volumes/my_path\",\n        \"s3a:/my_path\",\n        \"Volumes/my_path\",\n        \"Volume:/my_path\",\n        \"dbfs/my_path\",\n        \"/fuse-mounts/my_path\",\n    ],\n)\ndef test_negative_detection(uri):\n    assert not is_fuse_or_uc_volumes_uri(uri)\n\n\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        \"path\",\n        \"path/\",\n        \"path/to/file\",\n    ],\n)\ndef test_validate_path_is_safe_good(path):\n    validate_path_is_safe(path)\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"This test only passes on Windows\")\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        # relative path from current directory of C: drive\n        \".../...//\",\n    ],\n)\ndef test_validate_path_is_safe_windows_good(path):\n    validate_path_is_safe(path)\n\n\n@pytest.mark.skipif(is_windows(), reason=\"This test does not pass on Windows\")\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        \"/path\",\n        \"../path\",\n        \"../../path\",\n        \"./../path\",\n        \"path/../to/file\",\n        \"path/../../to/file\",\n        \"file://a#/..//tmp\",\n        \"file://a%23/..//tmp/\",\n        \"/etc/passwd\",\n        \"/etc/passwd%00.jpg\",\n        \"/etc/passwd%00.html\",\n        \"/etc/passwd%00.txt\",\n        \"/etc/passwd%00.php\",\n        \"/etc/passwd%00.asp\",\n        \"/file://etc/passwd\",\n        # Encoded paths with '..'\n        \"%2E%2E%2Fpath\",\n        \"%2E%2E%2F%2E%2E%2Fpath\",\n    ],\n)\ndef test_validate_path_is_safe_bad(path):\n    with pytest.raises(MlflowException, match=\"Invalid path\"):\n        validate_path_is_safe(path)\n\n\n@pytest.mark.skipif(not is_windows(), reason=\"This test only passes on Windows\")\n@pytest.mark.parametrize(\n    \"path\",\n    [\n        r\"../path\",\n        r\"../../path\",\n        r\"./../path\",\n        r\"path/../to/file\",\n        r\"path/../../to/file\",\n        r\"..\\path\",\n        r\"..\\..\\path\",\n        r\".\\..\\path\",\n        r\"path\\..\\to\\file\",\n        r\"path\\..\\..\\to\\file\",\n        # Drive-relative paths\n        r\"C:path\",\n        r\"C:path/\",\n        r\"C:path/to/file\",\n        r\"C:../path/to/file\",\n        r\"C:\\path\",\n        r\"C:/path\",\n        r\"C:\\path\\to\\file\",\n        r\"C:\\path/to/file\",\n        r\"C:\\path\\..\\to\\file\",\n        r\"C:/path/../to/file\",\n        # UNC(Universal Naming Convention) paths\n        r\"\\\\path\\to\\file\",\n        r\"\\\\path/to/file\",\n        r\"\\\\.\\\\C:\\path\\to\\file\",\n        r\"\\\\?\\C:\\path\\to\\file\",\n        r\"\\\\?\\UNC/path/to/file\",\n        # Other potential attackable paths\n        r\"/etc/password\",\n        r\"/path\",\n        r\"/etc/passwd%00.jpg\",\n        r\"/etc/passwd%00.html\",\n        r\"/etc/passwd%00.txt\",\n        r\"/etc/passwd%00.php\",\n        r\"/etc/passwd%00.asp\",\n        r\"/Windows/no/such/path\",\n        r\"/file://etc/passwd\",\n        r\"/file:c:/passwd\",\n        r\"/file://d:/windows/win.ini\",\n        r\"/file://./windows/win.ini\",\n        r\"file://c:/boot.ini\",\n        r\"file://C:path\",\n        r\"file://C:path/\",\n        r\"file://C:path/to/file\",\n        r\"file:///C:/Windows/System32/\",\n        r\"file:///etc/passwd\",\n        r\"file:///d:/windows/repair/sam\",\n        r\"file:///proc/version\",\n        r\"file:///inetpub/wwwroot/global.asa\",\n        r\"/file://../windows/win.ini\",\n        r\"../etc/passwd\",\n        r\"..\\Windows\\System32\\\\\",\n        r\"C:\\Windows\\System32\\\\\",\n        r\"/etc/passwd\",\n        r\"::Windows\\System32\",\n        r\"..\\..\\..\\..\\Windows\\System32\\\\\",\n        r\"../Windows/System32\",\n        r\"....\\\\\",\n        r\"\\\\?\\C:\\Windows\\System32\\\\\",\n        r\"\\\\.\\C:\\Windows\\System32\\\\\",\n        r\"\\\\UNC\\Server\\Share\\\\\",\n        r\"\\\\Server\\Share\\folder\\\\\",\n        r\"\\\\127.0.0.1\\c$\\Windows\\\\\",\n        r\"\\\\localhost\\c$\\Windows\\\\\",\n        r\"\\\\smbserver\\share\\path\\\\\",\n        r\"..\\\\?\\C:\\Windows\\System32\\\\\",\n        r\"C:/Windows/../Windows/System32/\",\n        r\"C:\\Windows\\..\\Windows\\System32\\\\\",\n        r\"../../../../../../../../../../../../Windows/System32\",\n        r\"../../../../../../../../../../../../etc/passwd\",\n        r\"../../../../../../../../../../../../var/www/html/index.html\",\n        r\"../../../../../../../../../../../../usr/local/etc/openvpn/server.conf\",\n        r\"../../../../../../../../../../../../Program Files (x86)\",\n        r\"/../../../../../../../../../../../../Windows/System32\",\n        r\"/Windows\\../etc/passwd\",\n        r\"/Windows\\..\\Windows\\System32\\\\\",\n        r\"/Windows\\..\\Windows\\System32\\cmd.exe\",\n        r\"/Windows\\..\\Windows\\System32\\msconfig.exe\",\n        r\"/Windows\\..\\Windows\\System32\\regedit.exe\",\n        r\"/Windows\\..\\Windows\\System32\\taskmgr.exe\",\n        r\"/Windows\\..\\Windows\\System32\\control.exe\",\n        r\"/Windows\\..\\Windows\\System32\\services.msc\",\n        r\"/Windows\\..\\Windows\\System32\\diskmgmt.msc\",\n        r\"/Windows\\..\\Windows\\System32\\eventvwr.msc\",\n        r\"/Windows/System32/drivers/etc/hosts\",\n    ],\n)\ndef test_validate_path_is_safe_windows_bad(path):\n    with pytest.raises(MlflowException, match=\"Invalid path\"):\n        validate_path_is_safe(path)\n"], "filenames": ["mlflow/utils/uri.py", "tests/server/test_handlers.py", "tests/store/artifact/test_http_artifact_repo.py", "tests/tracking/test_rest_tracking.py", "tests/utils/test_uri.py"], "buggy_code_start_loc": [433, 41, 249, 38, 26], "buggy_code_end_loc": [434, 779, 263, 674, 726], "fixing_code_start_loc": [433, 41, 249, 37, 27], "fixing_code_end_loc": [437, 805, 263, 527, 877], "type": "CWE-29", "message": "Path Traversal: '\\..\\filename' in GitHub repository mlflow/mlflow prior to 2.9.2.", "other": {"cve": {"id": "CVE-2023-6909", "sourceIdentifier": "security@huntr.dev", "published": "2023-12-18T04:15:52.367", "lastModified": "2024-02-06T20:16:01.753", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "Path Traversal: '\\..\\filename' in GitHub repository mlflow/mlflow prior to 2.9.2."}, {"lang": "es", "value": "Path traversal: '\\..\\filename' en el repositorio de GitHub mlflow/mlflow anterior a 2.9.2."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "NONE", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "security@huntr.dev", "type": "Primary", "description": [{"lang": "en", "value": "CWE-29"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:lfprojects:mlflow:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.9.2", "matchCriteriaId": "6B5585E2-CC70-4BED-AA89-B791F081ACFC"}]}]}], "references": [{"url": "https://github.com/mlflow/mlflow/commit/1da75dfcecd4d169e34809ade55748384e8af6c1", "source": "security@huntr.dev", "tags": ["Patch"]}, {"url": "https://huntr.com/bounties/11209efb-0f84-482f-add0-587ea6b7e850", "source": "security@huntr.dev", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/mlflow/mlflow/commit/1da75dfcecd4d169e34809ade55748384e8af6c1"}}
{"buggy_code": ["## 3.2\n\n### 3.2.0 - 2021-11-29\n\n#### New features added\n\n- Add rewrite_response [#209](https://github.com/jupyterhub/jupyter-server-proxy/pull/209) ([@maresb](https://github.com/maresb))\n\n#### Enhancements made\n\n- rewrite_response hook: (HTTP status) `code` updates should sometimes automatically update `reason` [#304](https://github.com/jupyterhub/jupyter-server-proxy/pull/304) ([@maresb](https://github.com/maresb))\n- Enable rewrite_response to modify status and headers [#300](https://github.com/jupyterhub/jupyter-server-proxy/pull/300) ([@ryanlovett](https://github.com/ryanlovett))\n- Apply `request_headers_override` to websocket requests [#287](https://github.com/jupyterhub/jupyter-server-proxy/pull/287) ([@sk1p](https://github.com/sk1p))\n\n#### Bugs fixed\n\n- fix: do not follow redirects when checking if server is up [#299](https://github.com/jupyterhub/jupyter-server-proxy/pull/299) ([@ableuler](https://github.com/ableuler))\n- propagate check_origin of JupyterHandler to enable CORS websocket access [#295](https://github.com/jupyterhub/jupyter-server-proxy/pull/295) ([@fhoehle](https://github.com/fhoehle))\n- fix path_info for JupyterLab [#294](https://github.com/jupyterhub/jupyter-server-proxy/pull/294) ([@jhgoebbert](https://github.com/jhgoebbert))\n- keep gzip-encoded content compressed [#290](https://github.com/jupyterhub/jupyter-server-proxy/pull/290) ([@axelmartenssonmodelon](https://github.com/axelmartenssonmodelon))\n\n#### Maintenance and upkeep improvements\n\n- resolve yarn.lock, bump builder version, some packaging metadata [#307](https://github.com/jupyterhub/jupyter-server-proxy/pull/307) ([@bollwyvl](https://github.com/bollwyvl))\n- Change the rewrite_response function signature to take a RewritableResponse object [#301](https://github.com/jupyterhub/jupyter-server-proxy/pull/301) ([@maresb](https://github.com/maresb))\n- Simplify wait logic for websocket connection [#292](https://github.com/jupyterhub/jupyter-server-proxy/pull/292) ([@mcg1969](https://github.com/mcg1969))\n\n#### Documentation improvements\n\n- Fix link to contributing.md [#291](https://github.com/jupyterhub/jupyter-server-proxy/pull/291) ([@kinow](https://github.com/kinow))\n\n#### Continuous integration\n\n- Test with lab [#298](https://github.com/jupyterhub/jupyter-server-proxy/pull/298) ([@maresb](https://github.com/maresb))\n- Open browser not required for running pytests [#273](https://github.com/jupyterhub/jupyter-server-proxy/pull/273) ([@candlerb](https://github.com/candlerb))\n\n#### Dependency updates\n\n- Bump tar from 6.1.5 to 6.1.11 in /jupyterlab-server-proxy [#293](https://github.com/jupyterhub/jupyter-server-proxy/pull/293) ([@dependabot](https://github.com/dependabot))\n- Bump path-parse from 1.0.6 to 1.0.7 in /jupyterlab-server-proxy [#285](https://github.com/jupyterhub/jupyter-server-proxy/pull/285) ([@dependabot](https://github.com/dependabot))\n- Bump tar from 6.1.0 to 6.1.5 in /jupyterlab-server-proxy [#284](https://github.com/jupyterhub/jupyter-server-proxy/pull/284) ([@dependabot](https://github.com/dependabot))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/jupyter-server-proxy/graphs/contributors?from=2021-07-03&to=2021-11-29&type=c))\n\n[@ableuler](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aableuler+updated%3A2021-07-03..2021-11-29&type=Issues) | [@axelmartenssonmodelon](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aaxelmartenssonmodelon+updated%3A2021-07-03..2021-11-29&type=Issues) | [@bollwyvl](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Abollwyvl+updated%3A2021-07-03..2021-11-29&type=Issues) | [@candlerb](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Acandlerb+updated%3A2021-07-03..2021-11-29&type=Issues) | [@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AconsideRatio+updated%3A2021-07-03..2021-11-29&type=Issues) | [@fhoehle](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Afhoehle+updated%3A2021-07-03..2021-11-29&type=Issues) | [@jhgoebbert](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajhgoebbert+updated%3A2021-07-03..2021-11-29&type=Issues) | [@kinow](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Akinow+updated%3A2021-07-03..2021-11-29&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amanics+updated%3A2021-07-03..2021-11-29&type=Issues) | [@maresb](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amaresb+updated%3A2021-07-03..2021-11-29&type=Issues) | [@mcg1969](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amcg1969+updated%3A2021-07-03..2021-11-29&type=Issues) | [@minrk](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aminrk+updated%3A2021-07-03..2021-11-29&type=Issues) | [@pisymbol](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Apisymbol+updated%3A2021-07-03..2021-11-29&type=Issues) | [@ryanlovett](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aryanlovett+updated%3A2021-07-03..2021-11-29&type=Issues) | [@sk1p](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ask1p+updated%3A2021-07-03..2021-11-29&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-07-03..2021-11-29&type=Issues)\n\n## 3.1\n\n### 3.1.0 - 2021-07-02\n\n#### New features added\n\n- Add path_info option under launcher_entry [#279](https://github.com/jupyterhub/jupyter-server-proxy/pull/279) ([@ryanlovett](https://github.com/ryanlovett))\n- Add request_headers_override configuration [#252](https://github.com/jupyterhub/jupyter-server-proxy/pull/252) ([@ryanlovett](https://github.com/ryanlovett))\n\n#### Bugs fixed\n\n- More precise regexp matching for /proxy/absolute/<host>:<port> [#271](https://github.com/jupyterhub/jupyter-server-proxy/pull/271) ([@candlerb](https://github.com/candlerb))\n\n#### Maintenance and upkeep improvements\n\n- Reduce (and test) sdist size [#263](https://github.com/jupyterhub/jupyter-server-proxy/pull/263) ([@bollwyvl](https://github.com/bollwyvl))\n\n#### Continuous integration\n\n- Add acceptance testing with robotframework(-jupyterlibrary) [#269](https://github.com/jupyterhub/jupyter-server-proxy/pull/269) ([@bollwyvl](https://github.com/bollwyvl))\n\n#### #### Dependency updates\n\n- Bump postcss from 7.0.35 to 7.0.36 in /jupyterlab-server-proxy [#277](https://github.com/jupyterhub/jupyter-server-proxy/pull/277) ([@dependabot](https://github.com/dependabot))\n- Bump normalize-url from 4.5.0 to 4.5.1 in /jupyterlab-server-proxy [#276](https://github.com/jupyterhub/jupyter-server-proxy/pull/276) ([@dependabot](https://github.com/dependabot))\n- Bump ws from 7.4.4 to 7.4.6 in /jupyterlab-server-proxy [#275](https://github.com/jupyterhub/jupyter-server-proxy/pull/275) ([@dependabot](https://github.com/dependabot))\n- Bump browserslist from 4.16.3 to 4.16.6 in /jupyterlab-server-proxy [#274](https://github.com/jupyterhub/jupyter-server-proxy/pull/274) ([@dependabot](https://github.com/dependabot))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/jupyter-server-proxy/graphs/contributors?from=2021-03-16&to=2021-07-03&type=c))\n\n[@bollwyvl](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Abollwyvl+updated%3A2021-03-16..2021-07-03&type=Issues) | [@candlerb](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Acandlerb+updated%3A2021-03-16..2021-07-03&type=Issues) | [@jhgoebbert](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajhgoebbert+updated%3A2021-03-16..2021-07-03&type=Issues) | [@jtpio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajtpio+updated%3A2021-03-16..2021-07-03&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amanics+updated%3A2021-03-16..2021-07-03&type=Issues) | [@ryanlovett](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aryanlovett+updated%3A2021-03-16..2021-07-03&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-03-16..2021-07-03&type=Issues)\n\n## 3.0\n\n### 3.0.2 - 2020-03-16\n\n#### Bugs fixed\n\n* Include jupyterlab-server-proxy in the sdist [#260](https://github.com/jupyterhub/jupyter-server-proxy/pull/260) ([@xhochy](https://github.com/xhochy))\n\n#### Contributors to this release\n\n[@xhochy](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Axhochy+updated%3A2021-03-16..2021-03-16&type=Issues)\n\n### 3.0.1 - 2020-03-16\n\n#### Bugs fixed\n\n* Fix PyPI url [#259](https://github.com/jupyterhub/jupyter-server-proxy/pull/259) ([@janjagusch](https://github.com/janjagusch))\n\n#### Contributors to this release\n\n[@janjagusch](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajanjagusch+updated%3A2021-03-15..2021-03-16&type=Issues)\n\n### 3.0.0 - 2020-03-15\n\nThis release drops support for Python 3.5 and now packages the JupyterLab\nextension with the Python package for use with JupyterLab 3. The JupyterLab\nextension is still available on NPM for use with JupyterLab 2 but support for\nJupyterLab 1 is dropped.\n\nThe Python package version jumps from 1.6.0 to 3.0.0, and the NPM package\nversion jumps from 2.1.2 to 3.0.0.\n\n#### Enhancements made\n\n* Package jupyter lab extension [#245](https://github.com/jupyterhub/jupyter-server-proxy/pull/245) ([@janjagusch](https://github.com/janjagusch))\n\n#### Maintenance and upkeep improvements\n\n* Breaking: Replace host_whitelist with host_allowlist [#256](https://github.com/jupyterhub/jupyter-server-proxy/pull/256) ([@manics](https://github.com/manics))\n* Switch from notebook to jupyter-server [#254](https://github.com/jupyterhub/jupyter-server-proxy/pull/254) ([@manics](https://github.com/manics))\n\n#### Continuous integration\n\n* Move build.yaml into test.yaml [#255](https://github.com/jupyterhub/jupyter-server-proxy/pull/255) ([@manics](https://github.com/manics))\n* Fix build.yaml workflow [#249](https://github.com/jupyterhub/jupyter-server-proxy/pull/249) ([@manics](https://github.com/manics))\n* Add publish PyPI and NPM workflow [#247](https://github.com/jupyterhub/jupyter-server-proxy/pull/247) ([@manics](https://github.com/manics))\n* tests: remove bad test, add new clarifying current behavior [#240](https://github.com/jupyterhub/jupyter-server-proxy/pull/240) ([@consideRatio](https://github.com/consideRatio))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/jupyter-server-proxy/graphs/contributors?from=2021-02-08&to=2021-03-15&type=c))\n\n[@AlJohri](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AAlJohri+updated%3A2021-02-08..2021-03-15&type=Issues) | [@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AconsideRatio+updated%3A2021-02-08..2021-03-15&type=Issues) | [@ian-r-rose](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aian-r-rose+updated%3A2021-02-08..2021-03-15&type=Issues) | [@janjagusch](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajanjagusch+updated%3A2021-02-08..2021-03-15&type=Issues) | [@JanJaguschQC](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AJanJaguschQC+updated%3A2021-02-08..2021-03-15&type=Issues) | [@jtpio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajtpio+updated%3A2021-02-08..2021-03-15&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amanics+updated%3A2021-02-08..2021-03-15&type=Issues) | [@maresb](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amaresb+updated%3A2021-02-08..2021-03-15&type=Issues) | [@minrk](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aminrk+updated%3A2021-02-08..2021-03-15&type=Issues) | [@ryanlovett](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aryanlovett+updated%3A2021-02-08..2021-03-15&type=Issues) | [@todo](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Atodo+updated%3A2021-02-08..2021-03-15&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-02-08..2021-03-15&type=Issues)\n\n## 1.6\n\n### 1.6.0 - 2021-02-10\n\nThis release adds support for JupyterLab 3.\n\nAt this point, the Jupyterlab extension of version 2.1.2, needs to be installed\nalongside the Python package for JupyterLab launcher buttons to show up as the\nextension isn't yet bundled with the python package.\n\n#### Enhancements made\n\n* Add Jupyter Server extension data file (JupyterLab 3 support) [#235](https://github.com/jupyterhub/jupyter-server-proxy/pull/235) ([@jtpio](https://github.com/jtpio))\n* Update dependencies to include jupyterlab 3.x.x (JupyterLab 3 support) [#229](https://github.com/jupyterhub/jupyter-server-proxy/pull/229) ([@dipanjank](https://github.com/dipanjank))\n\n#### Documentation improvements\n\n* Bump to 1.6.0 (setup.py) and add CHANGELOG.md [#238](https://github.com/jupyterhub/jupyter-server-proxy/pull/238) ([@consideRatio](https://github.com/consideRatio))\n* Replace server-process list with linkable headings [#236](https://github.com/jupyterhub/jupyter-server-proxy/pull/236) ([@manics](https://github.com/manics))\n* Rename the mamba-navigator example to gator in the documentation [#234](https://github.com/jupyterhub/jupyter-server-proxy/pull/234) ([@jtpio](https://github.com/jtpio))\n\n#### Contributors to this release\n\n[@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AconsideRatio+updated%3A2021-02-08..2021-02-25&type=Issues) | [@janjagusch](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajanjagusch+updated%3A2021-02-08..2021-02-25&type=Issues) | [@JanJaguschQC](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AJanJaguschQC+updated%3A2021-02-08..2021-02-25&type=Issues) | [@jtpio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajtpio+updated%3A2021-02-08..2021-02-25&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amanics+updated%3A2021-02-08..2021-02-25&type=Issues) | [@ryanlovett](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aryanlovett+updated%3A2021-02-08..2021-02-25&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-02-08..2021-02-25&type=Issues)\n", "\"\"\"\nAuthenticated HTTP proxy for Jupyter Notebooks\n\nSome original inspiration from https://github.com/senko/tornado-proxy\n\"\"\"\n\nimport inspect\nimport socket\nimport os\nfrom urllib.parse import urlunparse, urlparse, quote\nimport aiohttp\nfrom asyncio import Lock\nfrom copy import copy\n\nfrom tornado import gen, web, httpclient, httputil, process, websocket, ioloop, version_info\n\nfrom jupyter_server.utils import ensure_async, url_path_join\nfrom jupyter_server.base.handlers import JupyterHandler, utcnow\nfrom traitlets.traitlets import HasTraits\nfrom traitlets import Bytes, Dict, Instance, Integer, Unicode, Union, default, observe\n\nfrom .utils import call_with_asked_args\nfrom .websocket import WebSocketHandlerMixin, pingable_ws_connect\nfrom simpervisor import SupervisedProcess\n\n\nclass RewritableResponse(HasTraits):\n    \"\"\"\n    A class to hold the response to be rewritten by rewrite_response\n    \"\"\"\n    # The following should not be modified (or even accessed) by rewrite_response.\n    # It is used to initialize the default values of the traits.\n    orig_response = Instance(klass=httpclient.HTTPResponse)\n\n    # The following are modifiable by rewrite_response\n    headers = Union(trait_types=[Dict(), Instance(klass=httputil.HTTPHeaders)])\n    body = Bytes()\n    code = Integer()\n    reason = Unicode(allow_none=True)\n\n    @default('headers')\n    def _default_headers(self):\n        return copy(self.orig_response.headers)\n\n    @default('body')\n    def _default_body(self):\n        return self.orig_response.body\n\n    @default('code')\n    def _default_code(self):\n        return self.orig_response.code\n\n    @default('reason')\n    def _default_reason(self):\n        return self.orig_response.reason\n\n    @observe('code')\n    def _observe_code(self, change):\n        # HTTP status codes are mapped to short descriptions in the\n        # httputil.responses dictionary, 200 maps to \"OK\", 403 maps to\n        # \"Forbidden\" etc.\n        #\n        # If code is updated and it previously had a reason matching its short\n        # description, we update reason to match the new code's short\n        # description.\n        #\n        if self.reason == httputil.responses.get(change['old'], 'Unknown'):\n            self.reason = httputil.responses.get(change['new'], 'Unknown')\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Trigger the default value to be set from orig_response on instantiation.\n        # Otherwise _observe_code will receive change['old'] == 0.\n        self.code\n\n    def _apply_to_copy(self, func):\n        \"\"\"\n        Apply a function to a copy of self, and return the copy\n        \"\"\"\n        new = copy(self)\n        func(new)\n        return new\n\n\nclass AddSlashHandler(JupyterHandler):\n    \"\"\"Add trailing slash to URLs that need them.\"\"\"\n    @web.authenticated\n    def get(self, *args):\n        src = urlparse(self.request.uri)\n        dest = src._replace(path=src.path + '/')\n        self.redirect(urlunparse(dest))\n\nclass ProxyHandler(WebSocketHandlerMixin, JupyterHandler):\n    \"\"\"\n    A tornado request handler that proxies HTTP and websockets from\n    a given host/port combination. This class is not meant to be\n    used directly as a means of overriding CORS. This presents significant\n    security risks, and could allow arbitrary remote code access. Instead, it is\n    meant to be subclassed and used for proxying URLs from trusted sources.\n\n    Subclasses should implement open, http_get, post, put, delete, head, patch,\n    and options.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        self.proxy_base = ''\n        self.absolute_url = kwargs.pop('absolute_url', False)\n        self.host_allowlist = kwargs.pop('host_allowlist', ['localhost', '127.0.0.1'])\n        self.rewrite_response = kwargs.pop(\n            'rewrite_response',\n            tuple(),\n        )\n        self.subprotocols = None\n        super().__init__(*args, **kwargs)\n\n    # Support/use jupyter_server config arguments allow_origin and allow_origin_pat\n    # to enable cross origin requests propagated by e.g. inverting proxies.\n\n    def check_origin(self, origin=None):\n        return JupyterHandler.check_origin(self, origin)\n\n    # Support all the methods that tornado does by default except for GET which\n    # is passed to WebSocketHandlerMixin and then to WebSocketHandler.\n\n    async def open(self, port, proxied_path):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement open')\n\n    async def http_get(self, host, port, proxy_path=''):\n        '''Our non-websocket GET.'''\n        raise NotImplementedError('Subclasses of ProxyHandler should implement http_get')\n\n    def post(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement this post')\n\n    def put(self, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement this put')\n\n    def delete(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement delete')\n\n    def head(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement head')\n\n    def patch(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement patch')\n\n    def options(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement options')\n\n    def on_message(self, message):\n        \"\"\"\n        Called when we receive a message from our client.\n\n        We proxy it to the backend.\n        \"\"\"\n        self._record_activity()\n        if hasattr(self, 'ws'):\n            self.ws.write_message(message, binary=isinstance(message, bytes))\n\n    def on_ping(self, data):\n        \"\"\"\n        Called when the client pings our websocket connection.\n\n        We proxy it to the backend.\n        \"\"\"\n        self.log.debug('jupyter_server_proxy: on_ping: {}'.format(data))\n        self._record_activity()\n        if hasattr(self, 'ws'):\n            self.ws.protocol.write_ping(data)\n\n    def on_pong(self, data):\n        \"\"\"\n        Called when we receive a ping back.\n        \"\"\"\n        self.log.debug('jupyter_server_proxy: on_pong: {}'.format(data))\n\n    def on_close(self):\n        \"\"\"\n        Called when the client closes our websocket connection.\n\n        We close our connection to the backend too.\n        \"\"\"\n        if hasattr(self, 'ws'):\n            self.ws.close()\n\n    def _record_activity(self):\n        \"\"\"Record proxied activity as API activity\n\n        avoids proxied traffic being ignored by the notebook's\n        internal idle-shutdown mechanism\n        \"\"\"\n        self.settings['api_last_activity'] = utcnow()\n\n    def _get_context_path(self, host, port):\n        \"\"\"\n        Some applications need to know where they are being proxied from.\n        This is either:\n        - {base_url}/proxy/{port}\n        - {base_url}/proxy/{host}:{port}\n        - {base_url}/proxy/absolute/{port}\n        - {base_url}/proxy/absolute/{host}:{port}\n        - {base_url}/{proxy_base}\n        \"\"\"\n        host_and_port = str(port) if host == 'localhost' else host + \":\" + str(port)\n        if self.proxy_base:\n            return url_path_join(self.base_url, self.proxy_base)\n        if self.absolute_url:\n            return url_path_join(self.base_url, 'proxy', 'absolute', host_and_port)\n        else:\n            return url_path_join(self.base_url, 'proxy', host_and_port)\n\n    def get_client_uri(self, protocol, host, port, proxied_path):\n        context_path = self._get_context_path(host, port)\n        if self.absolute_url:\n            client_path = url_path_join(context_path, proxied_path)\n        else:\n            client_path = proxied_path\n\n        # Quote spaces, \u00e5\u00e4\u00f6 and such, but only enough to send a valid web\n        # request onwards. To do this, we mark the RFC 3986 specs' \"reserved\"\n        # and \"un-reserved\" characters as safe that won't need quoting. The\n        # un-reserved need to be marked safe to ensure the quote function behave\n        # the same in py36 as py37.\n        #\n        # ref: https://tools.ietf.org/html/rfc3986#section-2.2\n        client_path = quote(client_path, safe=\":/?#[]@!$&'()*+,;=-._~\")\n\n        client_uri = '{protocol}://{host}:{port}{path}'.format(\n            protocol=protocol,\n            host=host,\n            port=port,\n            path=client_path\n        )\n        if self.request.query:\n            client_uri += '?' + self.request.query\n\n        return client_uri\n\n    def _build_proxy_request(self, host, port, proxied_path, body):\n\n        headers = self.proxy_request_headers()\n\n        client_uri = self.get_client_uri('http', host, port, proxied_path)\n        # Some applications check X-Forwarded-Context and X-ProxyContextPath\n        # headers to see if and where they are being proxied from.\n        if not self.absolute_url:\n            context_path = self._get_context_path(host, port)\n            headers['X-Forwarded-Context'] = context_path\n            headers['X-ProxyContextPath'] = context_path\n            # to be compatible with flask/werkzeug wsgi applications\n            headers['X-Forwarded-Prefix'] = context_path\n\n        req = httpclient.HTTPRequest(\n            client_uri, method=self.request.method, body=body,\n            decompress_response=False,\n            headers=headers, **self.proxy_request_options())\n        return req\n\n    def _check_host_allowlist(self, host):\n        if callable(self.host_allowlist):\n            return self.host_allowlist(self, host)\n        else:\n            return host in self.host_allowlist\n\n    @web.authenticated\n    async def proxy(self, host, port, proxied_path):\n        '''\n        This serverextension handles:\n            {base_url}/proxy/{port([0-9]+)}/{proxied_path}\n            {base_url}/proxy/absolute/{port([0-9]+)}/{proxied_path}\n            {base_url}/{proxy_base}/{proxied_path}\n        '''\n\n        if not self._check_host_allowlist(host):\n            self.set_status(403)\n            self.write(\"Host '{host}' is not allowed. \"\n                       \"See https://jupyter-server-proxy.readthedocs.io/en/latest/arbitrary-ports-hosts.html for info.\".format(host=host))\n            return\n\n        if 'Proxy-Connection' in self.request.headers:\n            del self.request.headers['Proxy-Connection']\n\n        self._record_activity()\n\n        if self.request.headers.get(\"Upgrade\", \"\").lower() == 'websocket':\n            # We wanna websocket!\n            # jupyterhub/jupyter-server-proxy@36b3214\n            self.log.info(\"we wanna websocket, but we don't define WebSocketProxyHandler\")\n            self.set_status(500)\n\n        body = self.request.body\n        if not body:\n            if self.request.method == 'POST':\n                body = b''\n            else:\n                body = None\n\n        client = httpclient.AsyncHTTPClient()\n\n        req = self._build_proxy_request(host, port, proxied_path, body)\n\n        try:\n            # Here, \"response\" is a tornado.httpclient.HTTPResponse object.\n            response = await client.fetch(req, raise_error=False)\n        except httpclient.HTTPError as err:\n            # We need to capture the timeout error even with raise_error=False,\n            # because it only affects the HTTPError raised when a non-200 response \n            # code is used, instead of suppressing all errors.\n            # Ref: https://www.tornadoweb.org/en/stable/httpclient.html#tornado.httpclient.AsyncHTTPClient.fetch\n            if err.code == 599:\n                self._record_activity()\n                self.set_status(599)\n                self.write(str(err))\n                return\n            else:\n                raise\n\n        # record activity at start and end of requests\n        self._record_activity()\n\n        # For all non http errors...\n        if response.error and type(response.error) is not httpclient.HTTPError:\n            self.set_status(500)\n            self.write(str(response.error))\n        else:\n            # Represent the original response as a RewritableResponse object.\n            original_response = RewritableResponse(orig_response=response)\n            \n            # The function (or list of functions) which should be applied to modify the\n            # response.\n            rewrite_response = self.rewrite_response\n\n            # If this is a single function, wrap it in a list.\n            if isinstance(rewrite_response, (list, tuple)):\n                rewrite_responses = rewrite_response\n            else:\n                rewrite_responses = [rewrite_response]\n\n            # To be passed on-demand as args to the rewrite_response functions.\n            optional_args_to_rewrite_function = {\n                'request': self.request,\n                'orig_response': original_response,\n                'host': host,\n                'port': port,\n                'path': proxied_path\n            }\n\n            # Initial value for rewriting\n            rewritten_response = original_response\n\n            for rewrite in rewrite_responses:\n                # The rewrite function is a function of the RewritableResponse object\n                # ``response`` as well as several other optional arguments. We need to\n                # convert it to a function of only ``response`` by plugging in the\n                # known values for all the other parameters. (This is called partial\n                # evaluation.)\n                def rewrite_pe(rewritable_response: RewritableResponse):\n                    return call_with_asked_args(\n                        rewrite,\n                        {\n                            'response': rewritable_response,\n                            **optional_args_to_rewrite_function\n                        }\n                    )\n                # Now we can cleanly apply the partially evaulated function to a copy of\n                # the rewritten response.\n                rewritten_response = rewritten_response._apply_to_copy(rewrite_pe)\n\n            ## status\n            self.set_status(rewritten_response.code, rewritten_response.reason)\n\n            # clear tornado default header\n            self._headers = httputil.HTTPHeaders()\n            for header, v in rewritten_response.headers.get_all():\n                if header not in ('Content-Length', 'Transfer-Encoding',\n                                  'Connection'):\n                    # some header appear multiple times, eg 'Set-Cookie'\n                    self.add_header(header, v)\n\n            if rewritten_response.body:\n                self.write(rewritten_response.body)\n\n    async def proxy_open(self, host, port, proxied_path=''):\n        \"\"\"\n        Called when a client opens a websocket connection.\n\n        We establish a websocket connection to the proxied backend &\n        set up a callback to relay messages through.\n        \"\"\"\n\n        if not self._check_host_allowlist(host):\n            self.set_status(403)\n            self.log.info(\"Host '{host}' is not allowed. \"\n                          \"See https://jupyter-server-proxy.readthedocs.io/en/latest/arbitrary-ports-hosts.html for info.\".format(host=host))\n            self.close()\n            return\n\n        if not proxied_path.startswith('/'):\n            proxied_path = '/' + proxied_path\n\n        client_uri = self.get_client_uri('ws', host, port, proxied_path)\n        headers = self.proxy_request_headers()\n\n        def message_cb(message):\n            \"\"\"\n            Callback when the backend sends messages to us\n\n            We just pass it back to the frontend\n            \"\"\"\n            # Websockets support both string (utf-8) and binary data, so let's\n            # make sure we signal that appropriately when proxying\n            self._record_activity()\n            if message is None:\n                self.close()\n            else:\n                self.write_message(message, binary=isinstance(message, bytes))\n\n        def ping_cb(data):\n            \"\"\"\n            Callback when the backend sends pings to us.\n\n            We just pass it back to the frontend.\n            \"\"\"\n            self._record_activity()\n            self.ping(data)\n\n        async def start_websocket_connection():\n            self.log.info('Trying to establish websocket connection to {}'.format(client_uri))\n            self._record_activity()\n            request = httpclient.HTTPRequest(url=client_uri, headers=headers)\n            self.ws = await pingable_ws_connect(request=request,\n                on_message_callback=message_cb, on_ping_callback=ping_cb,\n                subprotocols=self.subprotocols)\n            self._record_activity()\n            self.log.info('Websocket connection established to {}'.format(client_uri))\n\n        # Wait for the WebSocket to be connected before resolving.\n        # Otherwise, messages sent by the client before the\n        # WebSocket successful connection would be dropped.\n        await start_websocket_connection()\n\n    def proxy_request_headers(self):\n        '''A dictionary of headers to be used when constructing\n        a tornado.httpclient.HTTPRequest instance for the proxy request.'''\n        headers = self.request.headers.copy()\n        # Merge any manually configured request headers\n        headers.update(self.get_request_headers_override())\n        return headers\n\n    def get_request_headers_override(self):\n        '''Add additional request headers. Typically overridden in subclasses.'''\n        return {}\n\n    def proxy_request_options(self):\n        '''A dictionary of options to be used when constructing\n        a tornado.httpclient.HTTPRequest instance for the proxy request.'''\n        return dict(follow_redirects=False, connect_timeout=250.0, request_timeout=300.0)\n\n    def check_xsrf_cookie(self):\n        '''\n        http://www.tornadoweb.org/en/stable/guide/security.html\n\n        Defer to proxied apps.\n        '''\n        pass\n\n    def select_subprotocol(self, subprotocols):\n        '''Select a single Sec-WebSocket-Protocol during handshake.'''\n        self.subprotocols = subprotocols\n        if isinstance(subprotocols, list) and subprotocols:\n            self.log.debug('Client sent subprotocols: {}'.format(subprotocols))\n            return subprotocols[0]\n        return super().select_subprotocol(subprotocols)\n\n\nclass LocalProxyHandler(ProxyHandler):\n    \"\"\"\n    A tornado request handler that proxies HTTP and websockets\n    from a port on the local system. Same as the above ProxyHandler,\n    but specific to 'localhost'.\n\n    The arguments \"port\" and \"proxied_path\" in each method are extracted from\n    the URL as capture groups in the regex specified in the add_handlers\n    method.\n    \"\"\"\n    async def http_get(self, port, proxied_path):\n        return await self.proxy(port, proxied_path)\n\n    async def open(self, port, proxied_path):\n        return await self.proxy_open('localhost', port, proxied_path)\n\n    def post(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def put(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def delete(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def head(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def patch(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def options(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def proxy(self, port, proxied_path):\n        return super().proxy('localhost', port, proxied_path)\n\nclass RemoteProxyHandler(ProxyHandler):\n    \"\"\"\n    A tornado request handler that proxies HTTP and websockets\n    from a port on a specified remote system.\n\n    The arguments \"host\", \"port\" and \"proxied_path\" in each method are\n    extracted from the URL as capture groups in the regex specified in the\n    add_handlers method.\n    \"\"\"\n\n    async def http_get(self, host, port, proxied_path):\n        return await self.proxy(host, port, proxied_path)\n\n    def post(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def put(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def delete(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def head(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def patch(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def options(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    async def open(self, host, port, proxied_path):\n        return await self.proxy_open(host, port, proxied_path)\n\n    def proxy(self, host, port, proxied_path):\n        return super().proxy(host, port, proxied_path)\n\n# FIXME: Move this to its own file. Too many packages now import this from nbrserverproxy.handlers\nclass SuperviseAndProxyHandler(LocalProxyHandler):\n    '''Manage a given process and requests to it '''\n\n    def __init__(self, *args, **kwargs):\n        self.requested_port = 0\n        self.mappath = {}\n        super().__init__(*args, **kwargs)\n\n    def initialize(self, state):\n        self.state = state\n        if 'proc_lock' not in state:\n            state['proc_lock'] = Lock()\n\n    name = 'process'\n\n    @property\n    def port(self):\n        \"\"\"\n        Allocate either the requested port or a random empty port for use by\n        application\n        \"\"\"\n        if 'port' not in self.state:\n            sock = socket.socket()\n            sock.bind(('', self.requested_port))\n            self.state['port'] = sock.getsockname()[1]\n            sock.close()\n        return self.state['port']\n\n    def get_cwd(self):\n        \"\"\"Get the current working directory for our process\n\n        Override in subclass to launch the process in a directory\n        other than the current.\n        \"\"\"\n        return os.getcwd()\n\n    def get_env(self):\n        '''Set up extra environment variables for process. Typically\n           overridden in subclasses.'''\n        return {}\n\n    def get_timeout(self):\n        \"\"\"\n        Return timeout (in s) to wait before giving up on process readiness\n        \"\"\"\n        return 5\n\n    async def _http_ready_func(self, p):\n        url = 'http://localhost:{}'.format(self.port)\n        async with aiohttp.ClientSession() as session:\n            try:\n                async with session.get(url, allow_redirects=False) as resp:\n                    # We only care if we get back *any* response, not just 200\n                    # If there's an error response, that can be shown directly to the user\n                    self.log.debug('Got code {} back from {}'.format(resp.status, url))\n                    return True\n            except aiohttp.ClientConnectionError:\n                self.log.debug('Connection to {} refused'.format(url))\n                return False\n\n    async def ensure_process(self):\n        \"\"\"\n        Start the process\n        \"\"\"\n        # We don't want multiple requests trying to start the process at the same time\n        # FIXME: Make sure this times out properly?\n        # Invariant here should be: when lock isn't being held, either 'proc' is in state &\n        # running, or not.\n        async with self.state['proc_lock']:\n            if 'proc' not in self.state:\n                # FIXME: Prevent races here\n                # FIXME: Handle graceful exits of spawned processes here\n                cmd = self.get_cmd()\n\n                # Set up extra environment variables for process\n                server_env = os.environ.copy()\n                server_env.update(self.get_env())\n\n                timeout = self.get_timeout()\n\n                proc = SupervisedProcess(self.name, *cmd, env=server_env, ready_func=self._http_ready_func, ready_timeout=timeout, log=self.log)\n                self.state['proc'] = proc\n\n                try:\n                    await proc.start()\n\n                    is_ready = await proc.ready()\n\n                    if not is_ready:\n                        await proc.kill()\n                        raise web.HTTPError(500, 'could not start {} in time'.format(self.name))\n                except:\n                    # Make sure we remove proc from state in any error condition\n                    del self.state['proc']\n                    raise\n\n\n    @web.authenticated\n    async def proxy(self, port, path):\n        if not path.startswith('/'):\n            path = '/' + path\n        if self.mappath:\n            if callable(self.mappath):\n                path = call_with_asked_args(self.mappath, {'path': path})\n            else:\n                path = self.mappath.get(path, path)\n\n        await self.ensure_process()\n\n        return await ensure_async(super().proxy(self.port, path))\n\n\n    async def http_get(self, path):\n        return await ensure_async(self.proxy(self.port, path))\n\n    async def open(self, path):\n        await self.ensure_process()\n        return await super().open(self.port, path)\n\n    def post(self, path):\n        return self.proxy(self.port, path)\n\n    def put(self, path):\n        return self.proxy(self.port, path)\n\n    def delete(self, path):\n        return self.proxy(self.port, path)\n\n    def head(self, path):\n        return self.proxy(self.port, path)\n\n    def patch(self, path):\n        return self.proxy(self.port, path)\n\n    def options(self, path):\n        return self.proxy(self.port, path)\n\n\ndef setup_handlers(web_app, serverproxy_config):\n    host_allowlist = serverproxy_config.host_allowlist\n    rewrite_response = serverproxy_config.non_service_rewrite_response\n    web_app.add_handlers('.*', [\n        (\n            url_path_join(\n                web_app.settings['base_url'],\n                r'/proxy/([^/]*):(\\d+)(.*)',\n            ),\n            RemoteProxyHandler,\n            {\n                'absolute_url': False,\n                'host_allowlist': host_allowlist,\n                'rewrite_response': rewrite_response,\n            }\n        ),\n        (\n            url_path_join(\n                web_app.settings['base_url'],\n                r'/proxy/absolute/([^/]*):(\\d+)(.*)',\n            ),\n            RemoteProxyHandler,\n            {\n                'absolute_url': True,\n                'host_allowlist': host_allowlist,\n                'rewrite_response': rewrite_response,\n            }\n        ),\n        (\n            url_path_join(\n                web_app.settings['base_url'],\n                r'/proxy/(\\d+)(.*)',\n            ),\n            LocalProxyHandler,\n            {\n                'absolute_url': False,\n                'rewrite_response': rewrite_response,\n            },\n        ),\n        (\n            url_path_join(\n                web_app.settings['base_url'],\n                r'/proxy/absolute/(\\d+)(.*)',\n            ),\n            LocalProxyHandler,\n            {\n                'absolute_url': True,\n                'rewrite_response': rewrite_response,\n            },\n        ),\n    ])\n\n# vim: set et ts=4 sw=4:\n", "import asyncio\nimport gzip\nfrom io import BytesIO\nimport json\nimport os\nfrom http.client import HTTPConnection\nfrom urllib.parse import quote\nimport pytest\nfrom tornado.websocket import websocket_connect\n\nPORT = os.getenv('TEST_PORT', 8888)\nTOKEN = os.getenv('JUPYTER_TOKEN', 'secret')\n\n\ndef request_get(port, path, token, host='localhost'):\n    h = HTTPConnection(host, port, 10)\n    if '?' in path:\n        url = '{}&token={}'.format(path, token)\n    else:\n        url = '{}?token={}'.format(path, token)\n    h.request('GET', url)\n    return h.getresponse()\n\n\ndef test_server_proxy_minimal_proxy_path_encoding():\n    \"\"\"Test that we don't encode anything more than we must to have a valid web\n    request.\"\"\"\n    special_path = quote(\"Hello world 123 \u00e5\u00e4\u00f6 \ud83c\udf89\u4f60\u597d\u4e16\u754c\u00b1\u00a5 :/[]@!$&'()*+,;=-._~?key1=value1\", safe=\":/?#[]@!$&'()*+,;=-._~\")\n    test_url = '/python-http/' + special_path\n    r = request_get(PORT, test_url, TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'GET /{}&token='.format(special_path) in s\n\n\ndef test_server_proxy_hash_sign_encoding():\n    \"\"\"\n    FIXME: This is a test to establish the current behavior, but if it should be\n           like this is a separate question not yet addressed.\n\n           Related: https://github.com/jupyterhub/jupyter-server-proxy/issues/109\n    \"\"\"\n    h = HTTPConnection(\"localhost\", PORT, 10)\n\n    # Case 0: a reference case\n    path = \"?token={}\".format(TOKEN)\n    h.request('GET', '/python-http/' + path)\n    r = h.getresponse()\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'GET /{} '.format(path) in s\n\n    # Case 1: #bla?token=secret -> everything following # ignored -> redirect because no token\n    path = \"#bla?token={}\".format(TOKEN)\n    h.request('GET', '/python-http/' + path)\n    r = h.getresponse()\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'GET / ' in s\n\n    # Case 2: %23bla?token=secret -> %23 is # -> everything following # ignored -> redirect because no token\n    path = \"%23?token={}\".format(TOKEN)\n    h.request('GET', '/python-http/' + path)\n    r = h.getresponse()\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'GET / ' in s\n\n    # Case 3: ?token=secret#test -> invalid token -> jupyter notebook server errors: NoneType can't be used in 'await' expression\n    #\n    #   [E 11:37:49.991 NotebookApp] Uncaught exception GET /python-http/?token=secrettest (127.0.0.1)\n    #   HTTPServerRequest(protocol='http', host='localhost:8888', method='GET', uri='/python-http/?token=secrettest', version='HTTP/1.1', remote_ip='127.0.0.1')\n    #   Traceback (most recent call last):\n    #   File \"/home/erik/py/lib/python3.7/site-packages/tornado/web.py\", line 1704, in _execute\n    #       result = await result\n    #   File \"/home/erik/py/lib/python3.7/site-packages/jupyter_server_proxy/websocket.py\", line 97, in get\n    #       return await self.http_get(*args, **kwargs)\n    #   File \"/home/erik/py/lib/python3.7/site-packages/jupyter_server_proxy/handlers.py\", line 539, in http_get\n    #       return await self.proxy(self.port, path)\n    #   TypeError: object NoneType can't be used in 'await' expression\n    path = \"?token={}#test\".format(TOKEN)\n    h.request('GET', '/python-http/' + path)\n    r = h.getresponse()\n    assert r.code == 302\n    s = r.read().decode('ascii')\n    assert s == ''\n\n\ndef test_server_rewrite_response():\n    r = request_get(PORT, '/python-http-rewrite-response/ciao-a-tutti', TOKEN)\n    assert r.code == 418\n    assert r.reason == \"I'm a teapot\"\n    assert (\"I-Like\", \"tacos\") in r.headers.items()\n    assert (\"Proxied-Host-Port\", \"localhost:54323\") in r.headers.items()\n    assert (\"Proxied-Path\", \"/ciao-a-tutti\") in r.headers.items()\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /hello-a-tutti?token=')\n\n\ndef test_chained_rewrite_response():\n    r = request_get(PORT, '/python-chained-rewrite-response/ciao-a-tutti', TOKEN)\n    assert r.code == 418\n    assert r.reason == \"I'm a teapot\"\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /foo-a-tutti?token=')\n\n\ndef test_cats_and_dogs_rewrite_response():\n    r = request_get(PORT, '/python-cats-only-rewrite-response/goats', TOKEN)\n    assert r.code == 200\n    r = request_get(PORT, '/python-cats-only-rewrite-response/cat-club', TOKEN)\n    s = r.read().decode('ascii')\n    assert r.code == 403\n    assert r.reason == \"Forbidden\"\n    assert s == \"dogs not allowed\"\n    r = request_get(PORT, '/python-dogs-only-rewrite-response/cat-club', TOKEN)\n    s = r.read().decode('ascii')\n    assert r.code == 403\n    assert r.reason == \"Forbidden\"\n    assert s == \"cats not allowed\"\n\n\ndef test_server_proxy_non_absolute():\n    r = request_get(PORT, '/python-http/abc', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /abc?token=')\n    assert 'X-Forwarded-Context: /python-http\\n' in s\n    assert 'X-Proxycontextpath: /python-http\\n' in s\n\n\ndef test_server_proxy_absolute():\n    r = request_get(PORT, '/python-http-abs/def', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /python-http-abs/def?token=')\n    assert 'X-Forwarded-Context' not in s\n    assert 'X-Proxycontextpath' not in s\n\n\ndef test_server_proxy_requested_port():\n    r = request_get(PORT, '/python-http-port54321/ghi', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /ghi?token=')\n    assert 'X-Forwarded-Context: /python-http-port54321\\n' in s\n    assert 'X-Proxycontextpath: /python-http-port54321\\n' in s\n\n    direct = request_get(54321, '/ghi', TOKEN)\n    assert direct.code == 200\n\n\ndef test_server_proxy_port_non_absolute():\n    r = request_get(PORT, '/proxy/54321/jkl', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /jkl?token=')\n    assert 'X-Forwarded-Context: /proxy/54321\\n' in s\n    assert 'X-Proxycontextpath: /proxy/54321\\n' in s\n\n\ndef test_server_proxy_port_absolute():\n    r = request_get(PORT, '/proxy/absolute/54321/nmo', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /proxy/absolute/54321/nmo?token=')\n    assert 'X-Forwarded-Context' not in s\n    assert 'X-Proxycontextpath' not in s\n\n\ndef test_server_proxy_host_non_absolute():\n    # note: localhost: is stripped but 127.0.0.1: is not\n    r = request_get(PORT, '/proxy/127.0.0.1:54321/jkl', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /jkl?token=')\n    assert 'X-Forwarded-Context: /proxy/127.0.0.1:54321\\n' in s\n    assert 'X-Proxycontextpath: /proxy/127.0.0.1:54321\\n' in s\n\n\ndef test_server_proxy_host_absolute():\n    r = request_get(PORT, '/proxy/absolute/127.0.0.1:54321/nmo', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /proxy/absolute/127.0.0.1:54321/nmo?token=')\n    assert 'X-Forwarded-Context' not in s\n    assert 'X-Proxycontextpath' not in s\n\ndef test_server_proxy_port_non_service_rewrite_response():\n    \"\"\"Test that 'hello' is replaced by 'foo'.\"\"\"\n    r = request_get(PORT, '/proxy/54321/hello', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /foo?token=')\n\n\n@pytest.mark.parametrize(\n    \"requestpath,expected\", [\n        ('/', '/index.html?token='),\n        ('/?q=1', '/index.html?q=1&token='),\n        ('/pqr?q=2', '/pqr?q=2&token='),\n    ]\n)\ndef test_server_proxy_mappath_dict(requestpath, expected):\n    r = request_get(PORT, '/python-http-mappath' + requestpath, TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET ' + expected)\n    assert 'X-Forwarded-Context: /python-http-mappath\\n' in s\n    assert 'X-Proxycontextpath: /python-http-mappath\\n' in s\n\n\n@pytest.mark.parametrize(\n    \"requestpath,expected\", [\n        ('/', '/mapped?token='),\n        ('/?q=1', '/mapped?q=1&token='),\n        ('/stu?q=2', '/stumapped?q=2&token='),\n    ]\n)\ndef test_server_proxy_mappath_callable(requestpath, expected):\n    r = request_get(PORT, '/python-http-mappathf' + requestpath, TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET ' + expected)\n    assert 'X-Forwarded-Context: /python-http-mappathf\\n' in s\n    assert 'X-Proxycontextpath: /python-http-mappathf\\n' in s\n\n\ndef test_server_proxy_remote():\n    r = request_get(PORT, '/newproxy', TOKEN, host='127.0.0.1')\n    assert r.code == 200\n\n\ndef test_server_request_headers():\n    r = request_get(PORT, '/python-request-headers/', TOKEN, host='127.0.0.1')\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'X-Custom-Header: pytest-23456\\n' in s\n\n\ndef test_server_content_encoding_header():\n    r = request_get(PORT, '/python-gzipserver/', TOKEN, host='127.0.0.1')\n    assert r.code == 200\n    assert r.headers['Content-Encoding'] == 'gzip'\n    with gzip.GzipFile(fileobj=BytesIO(r.read()), mode='r') as f:\n        assert f.read() == b'this is a test'\n\n\n@pytest.fixture(scope=\"module\")\ndef event_loop():\n    loop = asyncio.get_event_loop()\n    yield loop\n    loop.close()\n\n\nasync def _websocket_echo():\n    url = \"ws://localhost:{}/python-websocket/echosocket\".format(PORT)\n    conn = await websocket_connect(url)\n    expected_msg = \"Hello, world!\"\n    await conn.write_message(expected_msg)\n    msg = await conn.read_message()\n    assert msg == expected_msg\n\n\ndef test_server_proxy_websocket(event_loop):\n    event_loop.run_until_complete(_websocket_echo())\n\n\nasync def _websocket_headers():\n    url = \"ws://localhost:{}/python-websocket/headerssocket\".format(PORT)\n    conn = await websocket_connect(url)\n    await conn.write_message(\"Hello\")\n    msg = await conn.read_message()\n    headers = json.loads(msg)\n    assert 'X-Custom-Header' in headers\n    assert headers['X-Custom-Header'] == 'pytest-23456'\n\n\ndef test_server_proxy_websocket_headers(event_loop):\n    event_loop.run_until_complete(_websocket_headers())\n\n\nasync def _websocket_subprotocols():\n    url = \"ws://localhost:{}/python-websocket/subprotocolsocket\".format(PORT)\n    conn = await websocket_connect(url, subprotocols=[\"protocol_1\", \"protocol_2\"])\n    await conn.write_message(\"Hello, world!\")\n    msg = await conn.read_message()\n    assert json.loads(msg) == [\"protocol_1\", \"protocol_2\"]\n\n\ndef test_server_proxy_websocket_subprotocols(event_loop):\n    event_loop.run_until_complete(_websocket_subprotocols())\n\n"], "fixing_code": ["## 3.2\n\n### 3.2.1 - 2022-01-24\n\n3.2.1 is a security release, fixing a vulnerability [GHSA-gcv9-6737-pjqw](https://github.com/jupyterhub/jupyter-server-proxy/security/advisories/GHSA-gcv9-6737-pjqw) where `allowed_hosts` were not validated correctly.\n\n## Maintenance and upkeep improvements\n\n- Modernize docs without making changes to its content [#313](https://github.com/jupyterhub/jupyter-server-proxy/pull/313) ([@consideRatio](https://github.com/consideRatio))\n- Remove no longer needed logic involving six [#312](https://github.com/jupyterhub/jupyter-server-proxy/pull/312) ([@consideRatio](https://github.com/consideRatio))\n- Update language, from master to main [#311](https://github.com/jupyterhub/jupyter-server-proxy/pull/311) ([@consideRatio](https://github.com/consideRatio))\n\n## Other merged PRs\n\n- Remove empty JupyterLab style [#314](https://github.com/jupyterhub/jupyter-server-proxy/pull/314) ([@bollwyvl](https://github.com/bollwyvl))\n- ci: avoid triggering ci twice on pre-commit.ci/dependabot prs [#310](https://github.com/jupyterhub/jupyter-server-proxy/pull/310) ([@consideRatio](https://github.com/consideRatio))\n\n## Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/jupyter-server-proxy/graphs/contributors?from=2021-11-29&to=2022-01-19&type=c))\n\n[@bollwyvl](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Abollwyvl+updated%3A2021-11-29..2022-01-19&type=Issues) | [@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AconsideRatio+updated%3A2021-11-29..2022-01-19&type=Issues) | [@welcome](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Awelcome+updated%3A2021-11-29..2022-01-19&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-11-29..2022-01-19&type=Issues)\n\n\n### 3.2.0 - 2021-11-29\n\n#### New features added\n\n- Add rewrite_response [#209](https://github.com/jupyterhub/jupyter-server-proxy/pull/209) ([@maresb](https://github.com/maresb))\n\n#### Enhancements made\n\n- rewrite_response hook: (HTTP status) `code` updates should sometimes automatically update `reason` [#304](https://github.com/jupyterhub/jupyter-server-proxy/pull/304) ([@maresb](https://github.com/maresb))\n- Enable rewrite_response to modify status and headers [#300](https://github.com/jupyterhub/jupyter-server-proxy/pull/300) ([@ryanlovett](https://github.com/ryanlovett))\n- Apply `request_headers_override` to websocket requests [#287](https://github.com/jupyterhub/jupyter-server-proxy/pull/287) ([@sk1p](https://github.com/sk1p))\n\n#### Bugs fixed\n\n- fix: do not follow redirects when checking if server is up [#299](https://github.com/jupyterhub/jupyter-server-proxy/pull/299) ([@ableuler](https://github.com/ableuler))\n- propagate check_origin of JupyterHandler to enable CORS websocket access [#295](https://github.com/jupyterhub/jupyter-server-proxy/pull/295) ([@fhoehle](https://github.com/fhoehle))\n- fix path_info for JupyterLab [#294](https://github.com/jupyterhub/jupyter-server-proxy/pull/294) ([@jhgoebbert](https://github.com/jhgoebbert))\n- keep gzip-encoded content compressed [#290](https://github.com/jupyterhub/jupyter-server-proxy/pull/290) ([@axelmartenssonmodelon](https://github.com/axelmartenssonmodelon))\n\n#### Maintenance and upkeep improvements\n\n- resolve yarn.lock, bump builder version, some packaging metadata [#307](https://github.com/jupyterhub/jupyter-server-proxy/pull/307) ([@bollwyvl](https://github.com/bollwyvl))\n- Change the rewrite_response function signature to take a RewritableResponse object [#301](https://github.com/jupyterhub/jupyter-server-proxy/pull/301) ([@maresb](https://github.com/maresb))\n- Simplify wait logic for websocket connection [#292](https://github.com/jupyterhub/jupyter-server-proxy/pull/292) ([@mcg1969](https://github.com/mcg1969))\n\n#### Documentation improvements\n\n- Fix link to contributing.md [#291](https://github.com/jupyterhub/jupyter-server-proxy/pull/291) ([@kinow](https://github.com/kinow))\n\n#### Continuous integration\n\n- Test with lab [#298](https://github.com/jupyterhub/jupyter-server-proxy/pull/298) ([@maresb](https://github.com/maresb))\n- Open browser not required for running pytests [#273](https://github.com/jupyterhub/jupyter-server-proxy/pull/273) ([@candlerb](https://github.com/candlerb))\n\n#### Dependency updates\n\n- Bump tar from 6.1.5 to 6.1.11 in /jupyterlab-server-proxy [#293](https://github.com/jupyterhub/jupyter-server-proxy/pull/293) ([@dependabot](https://github.com/dependabot))\n- Bump path-parse from 1.0.6 to 1.0.7 in /jupyterlab-server-proxy [#285](https://github.com/jupyterhub/jupyter-server-proxy/pull/285) ([@dependabot](https://github.com/dependabot))\n- Bump tar from 6.1.0 to 6.1.5 in /jupyterlab-server-proxy [#284](https://github.com/jupyterhub/jupyter-server-proxy/pull/284) ([@dependabot](https://github.com/dependabot))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/jupyter-server-proxy/graphs/contributors?from=2021-07-03&to=2021-11-29&type=c))\n\n[@ableuler](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aableuler+updated%3A2021-07-03..2021-11-29&type=Issues) | [@axelmartenssonmodelon](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aaxelmartenssonmodelon+updated%3A2021-07-03..2021-11-29&type=Issues) | [@bollwyvl](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Abollwyvl+updated%3A2021-07-03..2021-11-29&type=Issues) | [@candlerb](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Acandlerb+updated%3A2021-07-03..2021-11-29&type=Issues) | [@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AconsideRatio+updated%3A2021-07-03..2021-11-29&type=Issues) | [@fhoehle](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Afhoehle+updated%3A2021-07-03..2021-11-29&type=Issues) | [@jhgoebbert](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajhgoebbert+updated%3A2021-07-03..2021-11-29&type=Issues) | [@kinow](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Akinow+updated%3A2021-07-03..2021-11-29&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amanics+updated%3A2021-07-03..2021-11-29&type=Issues) | [@maresb](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amaresb+updated%3A2021-07-03..2021-11-29&type=Issues) | [@mcg1969](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amcg1969+updated%3A2021-07-03..2021-11-29&type=Issues) | [@minrk](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aminrk+updated%3A2021-07-03..2021-11-29&type=Issues) | [@pisymbol](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Apisymbol+updated%3A2021-07-03..2021-11-29&type=Issues) | [@ryanlovett](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aryanlovett+updated%3A2021-07-03..2021-11-29&type=Issues) | [@sk1p](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ask1p+updated%3A2021-07-03..2021-11-29&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-07-03..2021-11-29&type=Issues)\n\n## 3.1\n\n### 3.1.0 - 2021-07-02\n\n#### New features added\n\n- Add path_info option under launcher_entry [#279](https://github.com/jupyterhub/jupyter-server-proxy/pull/279) ([@ryanlovett](https://github.com/ryanlovett))\n- Add request_headers_override configuration [#252](https://github.com/jupyterhub/jupyter-server-proxy/pull/252) ([@ryanlovett](https://github.com/ryanlovett))\n\n#### Bugs fixed\n\n- More precise regexp matching for /proxy/absolute/<host>:<port> [#271](https://github.com/jupyterhub/jupyter-server-proxy/pull/271) ([@candlerb](https://github.com/candlerb))\n\n#### Maintenance and upkeep improvements\n\n- Reduce (and test) sdist size [#263](https://github.com/jupyterhub/jupyter-server-proxy/pull/263) ([@bollwyvl](https://github.com/bollwyvl))\n\n#### Continuous integration\n\n- Add acceptance testing with robotframework(-jupyterlibrary) [#269](https://github.com/jupyterhub/jupyter-server-proxy/pull/269) ([@bollwyvl](https://github.com/bollwyvl))\n\n#### #### Dependency updates\n\n- Bump postcss from 7.0.35 to 7.0.36 in /jupyterlab-server-proxy [#277](https://github.com/jupyterhub/jupyter-server-proxy/pull/277) ([@dependabot](https://github.com/dependabot))\n- Bump normalize-url from 4.5.0 to 4.5.1 in /jupyterlab-server-proxy [#276](https://github.com/jupyterhub/jupyter-server-proxy/pull/276) ([@dependabot](https://github.com/dependabot))\n- Bump ws from 7.4.4 to 7.4.6 in /jupyterlab-server-proxy [#275](https://github.com/jupyterhub/jupyter-server-proxy/pull/275) ([@dependabot](https://github.com/dependabot))\n- Bump browserslist from 4.16.3 to 4.16.6 in /jupyterlab-server-proxy [#274](https://github.com/jupyterhub/jupyter-server-proxy/pull/274) ([@dependabot](https://github.com/dependabot))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/jupyter-server-proxy/graphs/contributors?from=2021-03-16&to=2021-07-03&type=c))\n\n[@bollwyvl](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Abollwyvl+updated%3A2021-03-16..2021-07-03&type=Issues) | [@candlerb](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Acandlerb+updated%3A2021-03-16..2021-07-03&type=Issues) | [@jhgoebbert](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajhgoebbert+updated%3A2021-03-16..2021-07-03&type=Issues) | [@jtpio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajtpio+updated%3A2021-03-16..2021-07-03&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amanics+updated%3A2021-03-16..2021-07-03&type=Issues) | [@ryanlovett](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aryanlovett+updated%3A2021-03-16..2021-07-03&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-03-16..2021-07-03&type=Issues)\n\n## 3.0\n\n### 3.0.2 - 2020-03-16\n\n#### Bugs fixed\n\n* Include jupyterlab-server-proxy in the sdist [#260](https://github.com/jupyterhub/jupyter-server-proxy/pull/260) ([@xhochy](https://github.com/xhochy))\n\n#### Contributors to this release\n\n[@xhochy](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Axhochy+updated%3A2021-03-16..2021-03-16&type=Issues)\n\n### 3.0.1 - 2020-03-16\n\n#### Bugs fixed\n\n* Fix PyPI url [#259](https://github.com/jupyterhub/jupyter-server-proxy/pull/259) ([@janjagusch](https://github.com/janjagusch))\n\n#### Contributors to this release\n\n[@janjagusch](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajanjagusch+updated%3A2021-03-15..2021-03-16&type=Issues)\n\n### 3.0.0 - 2020-03-15\n\nThis release drops support for Python 3.5 and now packages the JupyterLab\nextension with the Python package for use with JupyterLab 3. The JupyterLab\nextension is still available on NPM for use with JupyterLab 2 but support for\nJupyterLab 1 is dropped.\n\nThe Python package version jumps from 1.6.0 to 3.0.0, and the NPM package\nversion jumps from 2.1.2 to 3.0.0.\n\n#### Enhancements made\n\n* Package jupyter lab extension [#245](https://github.com/jupyterhub/jupyter-server-proxy/pull/245) ([@janjagusch](https://github.com/janjagusch))\n\n#### Maintenance and upkeep improvements\n\n* Breaking: Replace host_whitelist with host_allowlist [#256](https://github.com/jupyterhub/jupyter-server-proxy/pull/256) ([@manics](https://github.com/manics))\n* Switch from notebook to jupyter-server [#254](https://github.com/jupyterhub/jupyter-server-proxy/pull/254) ([@manics](https://github.com/manics))\n\n#### Continuous integration\n\n* Move build.yaml into test.yaml [#255](https://github.com/jupyterhub/jupyter-server-proxy/pull/255) ([@manics](https://github.com/manics))\n* Fix build.yaml workflow [#249](https://github.com/jupyterhub/jupyter-server-proxy/pull/249) ([@manics](https://github.com/manics))\n* Add publish PyPI and NPM workflow [#247](https://github.com/jupyterhub/jupyter-server-proxy/pull/247) ([@manics](https://github.com/manics))\n* tests: remove bad test, add new clarifying current behavior [#240](https://github.com/jupyterhub/jupyter-server-proxy/pull/240) ([@consideRatio](https://github.com/consideRatio))\n\n#### Contributors to this release\n\n([GitHub contributors page for this release](https://github.com/jupyterhub/jupyter-server-proxy/graphs/contributors?from=2021-02-08&to=2021-03-15&type=c))\n\n[@AlJohri](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AAlJohri+updated%3A2021-02-08..2021-03-15&type=Issues) | [@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AconsideRatio+updated%3A2021-02-08..2021-03-15&type=Issues) | [@ian-r-rose](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aian-r-rose+updated%3A2021-02-08..2021-03-15&type=Issues) | [@janjagusch](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajanjagusch+updated%3A2021-02-08..2021-03-15&type=Issues) | [@JanJaguschQC](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AJanJaguschQC+updated%3A2021-02-08..2021-03-15&type=Issues) | [@jtpio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajtpio+updated%3A2021-02-08..2021-03-15&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amanics+updated%3A2021-02-08..2021-03-15&type=Issues) | [@maresb](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amaresb+updated%3A2021-02-08..2021-03-15&type=Issues) | [@minrk](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aminrk+updated%3A2021-02-08..2021-03-15&type=Issues) | [@ryanlovett](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aryanlovett+updated%3A2021-02-08..2021-03-15&type=Issues) | [@todo](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Atodo+updated%3A2021-02-08..2021-03-15&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-02-08..2021-03-15&type=Issues)\n\n## 1.6\n\n### 1.6.0 - 2021-02-10\n\nThis release adds support for JupyterLab 3.\n\nAt this point, the Jupyterlab extension of version 2.1.2, needs to be installed\nalongside the Python package for JupyterLab launcher buttons to show up as the\nextension isn't yet bundled with the python package.\n\n#### Enhancements made\n\n* Add Jupyter Server extension data file (JupyterLab 3 support) [#235](https://github.com/jupyterhub/jupyter-server-proxy/pull/235) ([@jtpio](https://github.com/jtpio))\n* Update dependencies to include jupyterlab 3.x.x (JupyterLab 3 support) [#229](https://github.com/jupyterhub/jupyter-server-proxy/pull/229) ([@dipanjank](https://github.com/dipanjank))\n\n#### Documentation improvements\n\n* Bump to 1.6.0 (setup.py) and add CHANGELOG.md [#238](https://github.com/jupyterhub/jupyter-server-proxy/pull/238) ([@consideRatio](https://github.com/consideRatio))\n* Replace server-process list with linkable headings [#236](https://github.com/jupyterhub/jupyter-server-proxy/pull/236) ([@manics](https://github.com/manics))\n* Rename the mamba-navigator example to gator in the documentation [#234](https://github.com/jupyterhub/jupyter-server-proxy/pull/234) ([@jtpio](https://github.com/jtpio))\n\n#### Contributors to this release\n\n[@consideRatio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AconsideRatio+updated%3A2021-02-08..2021-02-25&type=Issues) | [@janjagusch](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajanjagusch+updated%3A2021-02-08..2021-02-25&type=Issues) | [@JanJaguschQC](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3AJanJaguschQC+updated%3A2021-02-08..2021-02-25&type=Issues) | [@jtpio](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ajtpio+updated%3A2021-02-08..2021-02-25&type=Issues) | [@manics](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Amanics+updated%3A2021-02-08..2021-02-25&type=Issues) | [@ryanlovett](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Aryanlovett+updated%3A2021-02-08..2021-02-25&type=Issues) | [@yuvipanda](https://github.com/search?q=repo%3Ajupyterhub%2Fjupyter-server-proxy+involves%3Ayuvipanda+updated%3A2021-02-08..2021-02-25&type=Issues)\n", "\"\"\"\nAuthenticated HTTP proxy for Jupyter Notebooks\n\nSome original inspiration from https://github.com/senko/tornado-proxy\n\"\"\"\n\nimport inspect\nimport socket\nimport os\nfrom urllib.parse import urlunparse, urlparse, quote\nimport aiohttp\nfrom asyncio import Lock\nfrom copy import copy\n\nfrom tornado import gen, web, httpclient, httputil, process, websocket, ioloop, version_info\n\nfrom jupyter_server.utils import ensure_async, url_path_join\nfrom jupyter_server.base.handlers import JupyterHandler, utcnow\nfrom traitlets.traitlets import HasTraits\nfrom traitlets import Bytes, Dict, Instance, Integer, Unicode, Union, default, observe\n\nfrom .utils import call_with_asked_args\nfrom .websocket import WebSocketHandlerMixin, pingable_ws_connect\nfrom simpervisor import SupervisedProcess\n\n\nclass RewritableResponse(HasTraits):\n    \"\"\"\n    A class to hold the response to be rewritten by rewrite_response\n    \"\"\"\n    # The following should not be modified (or even accessed) by rewrite_response.\n    # It is used to initialize the default values of the traits.\n    orig_response = Instance(klass=httpclient.HTTPResponse)\n\n    # The following are modifiable by rewrite_response\n    headers = Union(trait_types=[Dict(), Instance(klass=httputil.HTTPHeaders)])\n    body = Bytes()\n    code = Integer()\n    reason = Unicode(allow_none=True)\n\n    @default('headers')\n    def _default_headers(self):\n        return copy(self.orig_response.headers)\n\n    @default('body')\n    def _default_body(self):\n        return self.orig_response.body\n\n    @default('code')\n    def _default_code(self):\n        return self.orig_response.code\n\n    @default('reason')\n    def _default_reason(self):\n        return self.orig_response.reason\n\n    @observe('code')\n    def _observe_code(self, change):\n        # HTTP status codes are mapped to short descriptions in the\n        # httputil.responses dictionary, 200 maps to \"OK\", 403 maps to\n        # \"Forbidden\" etc.\n        #\n        # If code is updated and it previously had a reason matching its short\n        # description, we update reason to match the new code's short\n        # description.\n        #\n        if self.reason == httputil.responses.get(change['old'], 'Unknown'):\n            self.reason = httputil.responses.get(change['new'], 'Unknown')\n\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        # Trigger the default value to be set from orig_response on instantiation.\n        # Otherwise _observe_code will receive change['old'] == 0.\n        self.code\n\n    def _apply_to_copy(self, func):\n        \"\"\"\n        Apply a function to a copy of self, and return the copy\n        \"\"\"\n        new = copy(self)\n        func(new)\n        return new\n\n\nclass AddSlashHandler(JupyterHandler):\n    \"\"\"Add trailing slash to URLs that need them.\"\"\"\n    @web.authenticated\n    def get(self, *args):\n        src = urlparse(self.request.uri)\n        dest = src._replace(path=src.path + '/')\n        self.redirect(urlunparse(dest))\n\nclass ProxyHandler(WebSocketHandlerMixin, JupyterHandler):\n    \"\"\"\n    A tornado request handler that proxies HTTP and websockets from\n    a given host/port combination. This class is not meant to be\n    used directly as a means of overriding CORS. This presents significant\n    security risks, and could allow arbitrary remote code access. Instead, it is\n    meant to be subclassed and used for proxying URLs from trusted sources.\n\n    Subclasses should implement open, http_get, post, put, delete, head, patch,\n    and options.\n    \"\"\"\n    def __init__(self, *args, **kwargs):\n        self.proxy_base = ''\n        self.absolute_url = kwargs.pop('absolute_url', False)\n        self.host_allowlist = kwargs.pop('host_allowlist', ['localhost', '127.0.0.1'])\n        self.rewrite_response = kwargs.pop(\n            'rewrite_response',\n            tuple(),\n        )\n        self.subprotocols = None\n        super().__init__(*args, **kwargs)\n\n    # Support/use jupyter_server config arguments allow_origin and allow_origin_pat\n    # to enable cross origin requests propagated by e.g. inverting proxies.\n\n    def check_origin(self, origin=None):\n        return JupyterHandler.check_origin(self, origin)\n\n    # Support all the methods that tornado does by default except for GET which\n    # is passed to WebSocketHandlerMixin and then to WebSocketHandler.\n\n    async def open(self, port, proxied_path):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement open')\n\n    async def http_get(self, host, port, proxy_path=''):\n        '''Our non-websocket GET.'''\n        raise NotImplementedError('Subclasses of ProxyHandler should implement http_get')\n\n    def post(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement this post')\n\n    def put(self, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement this put')\n\n    def delete(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement delete')\n\n    def head(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement head')\n\n    def patch(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement patch')\n\n    def options(self, host, port, proxy_path=''):\n        raise NotImplementedError('Subclasses of ProxyHandler should implement options')\n\n    def on_message(self, message):\n        \"\"\"\n        Called when we receive a message from our client.\n\n        We proxy it to the backend.\n        \"\"\"\n        self._record_activity()\n        if hasattr(self, 'ws'):\n            self.ws.write_message(message, binary=isinstance(message, bytes))\n\n    def on_ping(self, data):\n        \"\"\"\n        Called when the client pings our websocket connection.\n\n        We proxy it to the backend.\n        \"\"\"\n        self.log.debug('jupyter_server_proxy: on_ping: {}'.format(data))\n        self._record_activity()\n        if hasattr(self, 'ws'):\n            self.ws.protocol.write_ping(data)\n\n    def on_pong(self, data):\n        \"\"\"\n        Called when we receive a ping back.\n        \"\"\"\n        self.log.debug('jupyter_server_proxy: on_pong: {}'.format(data))\n\n    def on_close(self):\n        \"\"\"\n        Called when the client closes our websocket connection.\n\n        We close our connection to the backend too.\n        \"\"\"\n        if hasattr(self, 'ws'):\n            self.ws.close()\n\n    def _record_activity(self):\n        \"\"\"Record proxied activity as API activity\n\n        avoids proxied traffic being ignored by the notebook's\n        internal idle-shutdown mechanism\n        \"\"\"\n        self.settings['api_last_activity'] = utcnow()\n\n    def _get_context_path(self, host, port):\n        \"\"\"\n        Some applications need to know where they are being proxied from.\n        This is either:\n        - {base_url}/proxy/{port}\n        - {base_url}/proxy/{host}:{port}\n        - {base_url}/proxy/absolute/{port}\n        - {base_url}/proxy/absolute/{host}:{port}\n        - {base_url}/{proxy_base}\n        \"\"\"\n        host_and_port = str(port) if host == 'localhost' else host + \":\" + str(port)\n        if self.proxy_base:\n            return url_path_join(self.base_url, self.proxy_base)\n        if self.absolute_url:\n            return url_path_join(self.base_url, 'proxy', 'absolute', host_and_port)\n        else:\n            return url_path_join(self.base_url, 'proxy', host_and_port)\n\n    def get_client_uri(self, protocol, host, port, proxied_path):\n        if self.absolute_url:\n            context_path = self._get_context_path(host, port)\n            client_path = url_path_join(context_path, proxied_path)\n        else:\n            client_path = proxied_path\n\n        # ensure client_path always starts with '/'\n        if not client_path.startswith(\"/\"):\n            client_path = \"/\" + client_path\n\n        # Quote spaces, \u00e5\u00e4\u00f6 and such, but only enough to send a valid web\n        # request onwards. To do this, we mark the RFC 3986 specs' \"reserved\"\n        # and \"un-reserved\" characters as safe that won't need quoting. The\n        # un-reserved need to be marked safe to ensure the quote function behave\n        # the same in py36 as py37.\n        #\n        # ref: https://tools.ietf.org/html/rfc3986#section-2.2\n        client_path = quote(client_path, safe=\":/?#[]@!$&'()*+,;=-._~\")\n\n        client_uri = '{protocol}://{host}:{port}{path}'.format(\n            protocol=protocol,\n            host=host,\n            port=port,\n            path=client_path,\n        )\n        if self.request.query:\n            client_uri += '?' + self.request.query\n\n        return client_uri\n\n    def _build_proxy_request(self, host, port, proxied_path, body):\n\n        headers = self.proxy_request_headers()\n\n        client_uri = self.get_client_uri('http', host, port, proxied_path)\n        # Some applications check X-Forwarded-Context and X-ProxyContextPath\n        # headers to see if and where they are being proxied from.\n        if not self.absolute_url:\n            context_path = self._get_context_path(host, port)\n            headers['X-Forwarded-Context'] = context_path\n            headers['X-ProxyContextPath'] = context_path\n            # to be compatible with flask/werkzeug wsgi applications\n            headers['X-Forwarded-Prefix'] = context_path\n\n        req = httpclient.HTTPRequest(\n            client_uri, method=self.request.method, body=body,\n            decompress_response=False,\n            headers=headers, **self.proxy_request_options())\n        return req\n\n    def _check_host_allowlist(self, host):\n        if callable(self.host_allowlist):\n            return self.host_allowlist(self, host)\n        else:\n            return host in self.host_allowlist\n\n    @web.authenticated\n    async def proxy(self, host, port, proxied_path):\n        '''\n        This serverextension handles:\n            {base_url}/proxy/{port([0-9]+)}/{proxied_path}\n            {base_url}/proxy/absolute/{port([0-9]+)}/{proxied_path}\n            {base_url}/{proxy_base}/{proxied_path}\n        '''\n\n        if not self._check_host_allowlist(host):\n            self.set_status(403)\n            self.write(\"Host '{host}' is not allowed. \"\n                       \"See https://jupyter-server-proxy.readthedocs.io/en/latest/arbitrary-ports-hosts.html for info.\".format(host=host))\n            return\n\n        if 'Proxy-Connection' in self.request.headers:\n            del self.request.headers['Proxy-Connection']\n\n        self._record_activity()\n\n        if self.request.headers.get(\"Upgrade\", \"\").lower() == 'websocket':\n            # We wanna websocket!\n            # jupyterhub/jupyter-server-proxy@36b3214\n            self.log.info(\"we wanna websocket, but we don't define WebSocketProxyHandler\")\n            self.set_status(500)\n\n        body = self.request.body\n        if not body:\n            if self.request.method == 'POST':\n                body = b''\n            else:\n                body = None\n\n        client = httpclient.AsyncHTTPClient()\n\n        req = self._build_proxy_request(host, port, proxied_path, body)\n        self.log.debug(f\"Proxying request to {req.url}\")\n\n        try:\n            # Here, \"response\" is a tornado.httpclient.HTTPResponse object.\n            response = await client.fetch(req, raise_error=False)\n        except httpclient.HTTPError as err:\n            # We need to capture the timeout error even with raise_error=False,\n            # because it only affects the HTTPError raised when a non-200 response\n            # code is used, instead of suppressing all errors.\n            # Ref: https://www.tornadoweb.org/en/stable/httpclient.html#tornado.httpclient.AsyncHTTPClient.fetch\n            if err.code == 599:\n                self._record_activity()\n                self.set_status(599)\n                self.write(str(err))\n                return\n            else:\n                raise\n\n        # record activity at start and end of requests\n        self._record_activity()\n\n        # For all non http errors...\n        if response.error and type(response.error) is not httpclient.HTTPError:\n            self.set_status(500)\n            self.write(str(response.error))\n        else:\n            # Represent the original response as a RewritableResponse object.\n            original_response = RewritableResponse(orig_response=response)\n\n            # The function (or list of functions) which should be applied to modify the\n            # response.\n            rewrite_response = self.rewrite_response\n\n            # If this is a single function, wrap it in a list.\n            if isinstance(rewrite_response, (list, tuple)):\n                rewrite_responses = rewrite_response\n            else:\n                rewrite_responses = [rewrite_response]\n\n            # To be passed on-demand as args to the rewrite_response functions.\n            optional_args_to_rewrite_function = {\n                'request': self.request,\n                'orig_response': original_response,\n                'host': host,\n                'port': port,\n                'path': proxied_path\n            }\n\n            # Initial value for rewriting\n            rewritten_response = original_response\n\n            for rewrite in rewrite_responses:\n                # The rewrite function is a function of the RewritableResponse object\n                # ``response`` as well as several other optional arguments. We need to\n                # convert it to a function of only ``response`` by plugging in the\n                # known values for all the other parameters. (This is called partial\n                # evaluation.)\n                def rewrite_pe(rewritable_response: RewritableResponse):\n                    return call_with_asked_args(\n                        rewrite,\n                        {\n                            'response': rewritable_response,\n                            **optional_args_to_rewrite_function\n                        }\n                    )\n                # Now we can cleanly apply the partially evaulated function to a copy of\n                # the rewritten response.\n                rewritten_response = rewritten_response._apply_to_copy(rewrite_pe)\n\n            ## status\n            self.set_status(rewritten_response.code, rewritten_response.reason)\n\n            # clear tornado default header\n            self._headers = httputil.HTTPHeaders()\n            for header, v in rewritten_response.headers.get_all():\n                if header not in ('Content-Length', 'Transfer-Encoding',\n                                  'Connection'):\n                    # some header appear multiple times, eg 'Set-Cookie'\n                    self.add_header(header, v)\n\n            if rewritten_response.body:\n                self.write(rewritten_response.body)\n\n    async def proxy_open(self, host, port, proxied_path=''):\n        \"\"\"\n        Called when a client opens a websocket connection.\n\n        We establish a websocket connection to the proxied backend &\n        set up a callback to relay messages through.\n        \"\"\"\n\n        if not self._check_host_allowlist(host):\n            self.set_status(403)\n            self.log.info(\"Host '{host}' is not allowed. \"\n                          \"See https://jupyter-server-proxy.readthedocs.io/en/latest/arbitrary-ports-hosts.html for info.\".format(host=host))\n            self.close()\n            return\n\n        if not proxied_path.startswith('/'):\n            proxied_path = '/' + proxied_path\n\n        client_uri = self.get_client_uri('ws', host, port, proxied_path)\n        headers = self.proxy_request_headers()\n\n        def message_cb(message):\n            \"\"\"\n            Callback when the backend sends messages to us\n\n            We just pass it back to the frontend\n            \"\"\"\n            # Websockets support both string (utf-8) and binary data, so let's\n            # make sure we signal that appropriately when proxying\n            self._record_activity()\n            if message is None:\n                self.close()\n            else:\n                self.write_message(message, binary=isinstance(message, bytes))\n\n        def ping_cb(data):\n            \"\"\"\n            Callback when the backend sends pings to us.\n\n            We just pass it back to the frontend.\n            \"\"\"\n            self._record_activity()\n            self.ping(data)\n\n        async def start_websocket_connection():\n            self.log.info('Trying to establish websocket connection to {}'.format(client_uri))\n            self._record_activity()\n            request = httpclient.HTTPRequest(url=client_uri, headers=headers)\n            self.ws = await pingable_ws_connect(request=request,\n                on_message_callback=message_cb, on_ping_callback=ping_cb,\n                subprotocols=self.subprotocols)\n            self._record_activity()\n            self.log.info('Websocket connection established to {}'.format(client_uri))\n\n        # Wait for the WebSocket to be connected before resolving.\n        # Otherwise, messages sent by the client before the\n        # WebSocket successful connection would be dropped.\n        await start_websocket_connection()\n\n    def proxy_request_headers(self):\n        '''A dictionary of headers to be used when constructing\n        a tornado.httpclient.HTTPRequest instance for the proxy request.'''\n        headers = self.request.headers.copy()\n        # Merge any manually configured request headers\n        headers.update(self.get_request_headers_override())\n        return headers\n\n    def get_request_headers_override(self):\n        '''Add additional request headers. Typically overridden in subclasses.'''\n        return {}\n\n    def proxy_request_options(self):\n        '''A dictionary of options to be used when constructing\n        a tornado.httpclient.HTTPRequest instance for the proxy request.'''\n        return dict(follow_redirects=False, connect_timeout=250.0, request_timeout=300.0)\n\n    def check_xsrf_cookie(self):\n        '''\n        http://www.tornadoweb.org/en/stable/guide/security.html\n\n        Defer to proxied apps.\n        '''\n        pass\n\n    def select_subprotocol(self, subprotocols):\n        '''Select a single Sec-WebSocket-Protocol during handshake.'''\n        self.subprotocols = subprotocols\n        if isinstance(subprotocols, list) and subprotocols:\n            self.log.debug('Client sent subprotocols: {}'.format(subprotocols))\n            return subprotocols[0]\n        return super().select_subprotocol(subprotocols)\n\n\nclass LocalProxyHandler(ProxyHandler):\n    \"\"\"\n    A tornado request handler that proxies HTTP and websockets\n    from a port on the local system. Same as the above ProxyHandler,\n    but specific to 'localhost'.\n\n    The arguments \"port\" and \"proxied_path\" in each method are extracted from\n    the URL as capture groups in the regex specified in the add_handlers\n    method.\n    \"\"\"\n    async def http_get(self, port, proxied_path):\n        return await self.proxy(port, proxied_path)\n\n    async def open(self, port, proxied_path):\n        return await self.proxy_open('localhost', port, proxied_path)\n\n    def post(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def put(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def delete(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def head(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def patch(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def options(self, port, proxied_path):\n        return self.proxy(port, proxied_path)\n\n    def proxy(self, port, proxied_path):\n        return super().proxy('localhost', port, proxied_path)\n\nclass RemoteProxyHandler(ProxyHandler):\n    \"\"\"\n    A tornado request handler that proxies HTTP and websockets\n    from a port on a specified remote system.\n\n    The arguments \"host\", \"port\" and \"proxied_path\" in each method are\n    extracted from the URL as capture groups in the regex specified in the\n    add_handlers method.\n    \"\"\"\n\n    async def http_get(self, host, port, proxied_path):\n        return await self.proxy(host, port, proxied_path)\n\n    def post(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def put(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def delete(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def head(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def patch(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    def options(self, host, port, proxied_path):\n        return self.proxy(host, port, proxied_path)\n\n    async def open(self, host, port, proxied_path):\n        return await self.proxy_open(host, port, proxied_path)\n\n    def proxy(self, host, port, proxied_path):\n        return super().proxy(host, port, proxied_path)\n\n# FIXME: Move this to its own file. Too many packages now import this from nbrserverproxy.handlers\nclass SuperviseAndProxyHandler(LocalProxyHandler):\n    '''Manage a given process and requests to it '''\n\n    def __init__(self, *args, **kwargs):\n        self.requested_port = 0\n        self.mappath = {}\n        super().__init__(*args, **kwargs)\n\n    def initialize(self, state):\n        self.state = state\n        if 'proc_lock' not in state:\n            state['proc_lock'] = Lock()\n\n    name = 'process'\n\n    @property\n    def port(self):\n        \"\"\"\n        Allocate either the requested port or a random empty port for use by\n        application\n        \"\"\"\n        if 'port' not in self.state:\n            sock = socket.socket()\n            sock.bind(('', self.requested_port))\n            self.state['port'] = sock.getsockname()[1]\n            sock.close()\n        return self.state['port']\n\n    def get_cwd(self):\n        \"\"\"Get the current working directory for our process\n\n        Override in subclass to launch the process in a directory\n        other than the current.\n        \"\"\"\n        return os.getcwd()\n\n    def get_env(self):\n        '''Set up extra environment variables for process. Typically\n           overridden in subclasses.'''\n        return {}\n\n    def get_timeout(self):\n        \"\"\"\n        Return timeout (in s) to wait before giving up on process readiness\n        \"\"\"\n        return 5\n\n    async def _http_ready_func(self, p):\n        url = 'http://localhost:{}'.format(self.port)\n        async with aiohttp.ClientSession() as session:\n            try:\n                async with session.get(url, allow_redirects=False) as resp:\n                    # We only care if we get back *any* response, not just 200\n                    # If there's an error response, that can be shown directly to the user\n                    self.log.debug('Got code {} back from {}'.format(resp.status, url))\n                    return True\n            except aiohttp.ClientConnectionError:\n                self.log.debug('Connection to {} refused'.format(url))\n                return False\n\n    async def ensure_process(self):\n        \"\"\"\n        Start the process\n        \"\"\"\n        # We don't want multiple requests trying to start the process at the same time\n        # FIXME: Make sure this times out properly?\n        # Invariant here should be: when lock isn't being held, either 'proc' is in state &\n        # running, or not.\n        async with self.state['proc_lock']:\n            if 'proc' not in self.state:\n                # FIXME: Prevent races here\n                # FIXME: Handle graceful exits of spawned processes here\n                cmd = self.get_cmd()\n\n                # Set up extra environment variables for process\n                server_env = os.environ.copy()\n                server_env.update(self.get_env())\n\n                timeout = self.get_timeout()\n\n                proc = SupervisedProcess(self.name, *cmd, env=server_env, ready_func=self._http_ready_func, ready_timeout=timeout, log=self.log)\n                self.state['proc'] = proc\n\n                try:\n                    await proc.start()\n\n                    is_ready = await proc.ready()\n\n                    if not is_ready:\n                        await proc.kill()\n                        raise web.HTTPError(500, 'could not start {} in time'.format(self.name))\n                except:\n                    # Make sure we remove proc from state in any error condition\n                    del self.state['proc']\n                    raise\n\n\n    @web.authenticated\n    async def proxy(self, port, path):\n        if not path.startswith('/'):\n            path = '/' + path\n        if self.mappath:\n            if callable(self.mappath):\n                path = call_with_asked_args(self.mappath, {'path': path})\n            else:\n                path = self.mappath.get(path, path)\n\n        await self.ensure_process()\n\n        return await ensure_async(super().proxy(self.port, path))\n\n\n    async def http_get(self, path):\n        return await ensure_async(self.proxy(self.port, path))\n\n    async def open(self, path):\n        await self.ensure_process()\n        return await super().open(self.port, path)\n\n    def post(self, path):\n        return self.proxy(self.port, path)\n\n    def put(self, path):\n        return self.proxy(self.port, path)\n\n    def delete(self, path):\n        return self.proxy(self.port, path)\n\n    def head(self, path):\n        return self.proxy(self.port, path)\n\n    def patch(self, path):\n        return self.proxy(self.port, path)\n\n    def options(self, path):\n        return self.proxy(self.port, path)\n\n\ndef setup_handlers(web_app, serverproxy_config):\n    host_allowlist = serverproxy_config.host_allowlist\n    rewrite_response = serverproxy_config.non_service_rewrite_response\n    web_app.add_handlers(\n        \".*\",\n        [\n            (\n                url_path_join(\n                    web_app.settings[\"base_url\"],\n                    r\"/proxy/([^/:@]+):(\\d+)(/.*|)\",\n                ),\n                RemoteProxyHandler,\n                {\n                    \"absolute_url\": False,\n                    \"host_allowlist\": host_allowlist,\n                    \"rewrite_response\": rewrite_response,\n                },\n            ),\n            (\n                url_path_join(\n                    web_app.settings[\"base_url\"],\n                    r\"/proxy/absolute/([^/:@]+):(\\d+)(/.*|)\",\n                ),\n                RemoteProxyHandler,\n                {\n                    \"absolute_url\": True,\n                    \"host_allowlist\": host_allowlist,\n                    \"rewrite_response\": rewrite_response,\n                },\n            ),\n            (\n                url_path_join(\n                    web_app.settings[\"base_url\"],\n                    r\"/proxy/(\\d+)(/.*|)\",\n                ),\n                LocalProxyHandler,\n                {\n                    \"absolute_url\": False,\n                    \"rewrite_response\": rewrite_response,\n                },\n            ),\n            (\n                url_path_join(\n                    web_app.settings[\"base_url\"],\n                    r\"/proxy/absolute/(\\d+)(/.*|)\",\n                ),\n                LocalProxyHandler,\n                {\n                    \"absolute_url\": True,\n                    \"rewrite_response\": rewrite_response,\n                },\n            ),\n        ],\n    )\n\n\n# vim: set et ts=4 sw=4:\n", "import asyncio\nimport gzip\nfrom io import BytesIO\nimport json\nimport os\nfrom http.client import HTTPConnection\nfrom urllib.parse import quote\nimport pytest\nfrom tornado.websocket import websocket_connect\n\nPORT = os.getenv('TEST_PORT', 8888)\nTOKEN = os.getenv('JUPYTER_TOKEN', 'secret')\n\n\ndef request_get(port, path, token, host='localhost'):\n    h = HTTPConnection(host, port, 10)\n    if '?' in path:\n        url = '{}&token={}'.format(path, token)\n    else:\n        url = '{}?token={}'.format(path, token)\n    h.request('GET', url)\n    return h.getresponse()\n\n\ndef test_server_proxy_minimal_proxy_path_encoding():\n    \"\"\"Test that we don't encode anything more than we must to have a valid web\n    request.\"\"\"\n    special_path = quote(\"Hello world 123 \u00e5\u00e4\u00f6 \ud83c\udf89\u4f60\u597d\u4e16\u754c\u00b1\u00a5 :/[]@!$&'()*+,;=-._~?key1=value1\", safe=\":/?#[]@!$&'()*+,;=-._~\")\n    test_url = '/python-http/' + special_path\n    r = request_get(PORT, test_url, TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'GET /{}&token='.format(special_path) in s\n\n\ndef test_server_proxy_hash_sign_encoding():\n    \"\"\"\n    FIXME: This is a test to establish the current behavior, but if it should be\n           like this is a separate question not yet addressed.\n\n           Related: https://github.com/jupyterhub/jupyter-server-proxy/issues/109\n    \"\"\"\n    h = HTTPConnection(\"localhost\", PORT, 10)\n\n    # Case 0: a reference case\n    path = \"?token={}\".format(TOKEN)\n    h.request('GET', '/python-http/' + path)\n    r = h.getresponse()\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'GET /{} '.format(path) in s\n\n    # Case 1: #bla?token=secret -> everything following # ignored -> redirect because no token\n    path = \"#bla?token={}\".format(TOKEN)\n    h.request('GET', '/python-http/' + path)\n    r = h.getresponse()\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'GET / ' in s\n\n    # Case 2: %23bla?token=secret -> %23 is # -> everything following # ignored -> redirect because no token\n    path = \"%23?token={}\".format(TOKEN)\n    h.request('GET', '/python-http/' + path)\n    r = h.getresponse()\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'GET / ' in s\n\n    # Case 3: ?token=secret#test -> invalid token -> jupyter notebook server errors: NoneType can't be used in 'await' expression\n    #\n    #   [E 11:37:49.991 NotebookApp] Uncaught exception GET /python-http/?token=secrettest (127.0.0.1)\n    #   HTTPServerRequest(protocol='http', host='localhost:8888', method='GET', uri='/python-http/?token=secrettest', version='HTTP/1.1', remote_ip='127.0.0.1')\n    #   Traceback (most recent call last):\n    #   File \"/home/erik/py/lib/python3.7/site-packages/tornado/web.py\", line 1704, in _execute\n    #       result = await result\n    #   File \"/home/erik/py/lib/python3.7/site-packages/jupyter_server_proxy/websocket.py\", line 97, in get\n    #       return await self.http_get(*args, **kwargs)\n    #   File \"/home/erik/py/lib/python3.7/site-packages/jupyter_server_proxy/handlers.py\", line 539, in http_get\n    #       return await self.proxy(self.port, path)\n    #   TypeError: object NoneType can't be used in 'await' expression\n    path = \"?token={}#test\".format(TOKEN)\n    h.request('GET', '/python-http/' + path)\n    r = h.getresponse()\n    assert r.code == 302\n    s = r.read().decode('ascii')\n    assert s == ''\n\n\ndef test_server_rewrite_response():\n    r = request_get(PORT, '/python-http-rewrite-response/ciao-a-tutti', TOKEN)\n    assert r.code == 418\n    assert r.reason == \"I'm a teapot\"\n    assert (\"I-Like\", \"tacos\") in r.headers.items()\n    assert (\"Proxied-Host-Port\", \"localhost:54323\") in r.headers.items()\n    assert (\"Proxied-Path\", \"/ciao-a-tutti\") in r.headers.items()\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /hello-a-tutti?token=')\n\n\ndef test_chained_rewrite_response():\n    r = request_get(PORT, '/python-chained-rewrite-response/ciao-a-tutti', TOKEN)\n    assert r.code == 418\n    assert r.reason == \"I'm a teapot\"\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /foo-a-tutti?token=')\n\n\ndef test_cats_and_dogs_rewrite_response():\n    r = request_get(PORT, '/python-cats-only-rewrite-response/goats', TOKEN)\n    assert r.code == 200\n    r = request_get(PORT, '/python-cats-only-rewrite-response/cat-club', TOKEN)\n    s = r.read().decode('ascii')\n    assert r.code == 403\n    assert r.reason == \"Forbidden\"\n    assert s == \"dogs not allowed\"\n    r = request_get(PORT, '/python-dogs-only-rewrite-response/cat-club', TOKEN)\n    s = r.read().decode('ascii')\n    assert r.code == 403\n    assert r.reason == \"Forbidden\"\n    assert s == \"cats not allowed\"\n\n\ndef test_server_proxy_non_absolute():\n    r = request_get(PORT, '/python-http/abc', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /abc?token=')\n    assert 'X-Forwarded-Context: /python-http\\n' in s\n    assert 'X-Proxycontextpath: /python-http\\n' in s\n\n\ndef test_server_proxy_absolute():\n    r = request_get(PORT, '/python-http-abs/def', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /python-http-abs/def?token=')\n    assert 'X-Forwarded-Context' not in s\n    assert 'X-Proxycontextpath' not in s\n\n\ndef test_server_proxy_requested_port():\n    r = request_get(PORT, '/python-http-port54321/ghi', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /ghi?token=')\n    assert 'X-Forwarded-Context: /python-http-port54321\\n' in s\n    assert 'X-Proxycontextpath: /python-http-port54321\\n' in s\n\n    direct = request_get(54321, '/ghi', TOKEN)\n    assert direct.code == 200\n\n\ndef test_server_proxy_port_non_absolute():\n    r = request_get(PORT, '/proxy/54321/jkl', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /jkl?token=')\n    assert 'X-Forwarded-Context: /proxy/54321\\n' in s\n    assert 'X-Proxycontextpath: /proxy/54321\\n' in s\n\n\ndef test_server_proxy_port_absolute():\n    r = request_get(PORT, '/proxy/absolute/54321/nmo', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /proxy/absolute/54321/nmo?token=')\n    assert 'X-Forwarded-Context' not in s\n    assert 'X-Proxycontextpath' not in s\n\n\ndef test_server_proxy_host_non_absolute():\n    # note: localhost: is stripped but 127.0.0.1: is not\n    r = request_get(PORT, '/proxy/127.0.0.1:54321/jkl', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /jkl?token=')\n    assert 'X-Forwarded-Context: /proxy/127.0.0.1:54321\\n' in s\n    assert 'X-Proxycontextpath: /proxy/127.0.0.1:54321\\n' in s\n\n\ndef test_server_proxy_host_absolute():\n    r = request_get(PORT, '/proxy/absolute/127.0.0.1:54321/nmo', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /proxy/absolute/127.0.0.1:54321/nmo?token=')\n    assert 'X-Forwarded-Context' not in s\n    assert 'X-Proxycontextpath' not in s\n\ndef test_server_proxy_port_non_service_rewrite_response():\n    \"\"\"Test that 'hello' is replaced by 'foo'.\"\"\"\n    r = request_get(PORT, '/proxy/54321/hello', TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET /foo?token=')\n\n\n@pytest.mark.parametrize(\n    \"requestpath,expected\", [\n        ('/', '/index.html?token='),\n        ('/?q=1', '/index.html?q=1&token='),\n        ('/pqr?q=2', '/pqr?q=2&token='),\n    ]\n)\ndef test_server_proxy_mappath_dict(requestpath, expected):\n    r = request_get(PORT, '/python-http-mappath' + requestpath, TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET ' + expected)\n    assert 'X-Forwarded-Context: /python-http-mappath\\n' in s\n    assert 'X-Proxycontextpath: /python-http-mappath\\n' in s\n\n\n@pytest.mark.parametrize(\n    \"requestpath,expected\", [\n        ('/', '/mapped?token='),\n        ('/?q=1', '/mapped?q=1&token='),\n        ('/stu?q=2', '/stumapped?q=2&token='),\n    ]\n)\ndef test_server_proxy_mappath_callable(requestpath, expected):\n    r = request_get(PORT, '/python-http-mappathf' + requestpath, TOKEN)\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert s.startswith('GET ' + expected)\n    assert 'X-Forwarded-Context: /python-http-mappathf\\n' in s\n    assert 'X-Proxycontextpath: /python-http-mappathf\\n' in s\n\n\ndef test_server_proxy_remote():\n    r = request_get(PORT, '/newproxy', TOKEN, host='127.0.0.1')\n    assert r.code == 200\n\n\ndef test_server_request_headers():\n    r = request_get(PORT, '/python-request-headers/', TOKEN, host='127.0.0.1')\n    assert r.code == 200\n    s = r.read().decode('ascii')\n    assert 'X-Custom-Header: pytest-23456\\n' in s\n\n\ndef test_server_content_encoding_header():\n    r = request_get(PORT, '/python-gzipserver/', TOKEN, host='127.0.0.1')\n    assert r.code == 200\n    assert r.headers['Content-Encoding'] == 'gzip'\n    with gzip.GzipFile(fileobj=BytesIO(r.read()), mode='r') as f:\n        assert f.read() == b'this is a test'\n\n\n@pytest.fixture(scope=\"module\")\ndef event_loop():\n    loop = asyncio.get_event_loop()\n    yield loop\n    loop.close()\n\n\nasync def _websocket_echo():\n    url = \"ws://localhost:{}/python-websocket/echosocket\".format(PORT)\n    conn = await websocket_connect(url)\n    expected_msg = \"Hello, world!\"\n    await conn.write_message(expected_msg)\n    msg = await conn.read_message()\n    assert msg == expected_msg\n\n\ndef test_server_proxy_websocket(event_loop):\n    event_loop.run_until_complete(_websocket_echo())\n\n\nasync def _websocket_headers():\n    url = \"ws://localhost:{}/python-websocket/headerssocket\".format(PORT)\n    conn = await websocket_connect(url)\n    await conn.write_message(\"Hello\")\n    msg = await conn.read_message()\n    headers = json.loads(msg)\n    assert 'X-Custom-Header' in headers\n    assert headers['X-Custom-Header'] == 'pytest-23456'\n\n\ndef test_server_proxy_websocket_headers(event_loop):\n    event_loop.run_until_complete(_websocket_headers())\n\n\nasync def _websocket_subprotocols():\n    url = \"ws://localhost:{}/python-websocket/subprotocolsocket\".format(PORT)\n    conn = await websocket_connect(url, subprotocols=[\"protocol_1\", \"protocol_2\"])\n    await conn.write_message(\"Hello, world!\")\n    msg = await conn.read_message()\n    assert json.loads(msg) == [\"protocol_1\", \"protocol_2\"]\n\n\ndef test_server_proxy_websocket_subprotocols(event_loop):\n    event_loop.run_until_complete(_websocket_subprotocols())\n\n@pytest.mark.parametrize(\n    \"proxy_path, status\",\n    [\n        (\"127.0.0.1\", 404),\n        (\"127.0.0.1/path\", 404),\n        (\"127.0.0.1@192.168.1.1\", 404),\n        (\"127.0.0.1@192.168.1.1/path\", 404),\n        (\"user:pass@host:123/foo\", 403),\n        (\"user:pass@host/foo\", 404),\n        (\"absolute/127.0.0.1:123@192.168.1.1/path\", 404),\n    ]\n)\ndef test_bad_server_proxy_url(proxy_path, status):\n    r = request_get(PORT, f\"/proxy/{proxy_path}\", TOKEN)\n    assert r.code == status\n    if status >= 400:\n        # request should not have been proxied\n        assert 'X-ProxyContextPath' not in r.headers\n"], "filenames": ["CHANGELOG.md", "jupyter_server_proxy/handlers.py", "tests/test_proxies.py"], "buggy_code_start_loc": [1, 212, 293], "buggy_code_end_loc": [1, 739, 293], "fixing_code_start_loc": [2, 211, 294], "fixing_code_end_loc": [24, 748, 312], "type": "CWE-918", "message": "Jupyter Server Proxy is a Jupyter notebook server extension to proxy web services. Versions of Jupyter Server Proxy prior to 3.2.1 are vulnerable to Server-Side Request Forgery (SSRF). Any user deploying Jupyter Server or Notebook with jupyter-proxy-server extension enabled is affected. A lack of input validation allows authenticated clients to proxy requests to other hosts, bypassing the `allowed_hosts` check. Because authentication is required, which already grants permissions to make the same requests via kernel or terminal execution, this is considered low to moderate severity. Users may upgrade to version 3.2.1 to receive a patch or, as a workaround, install the patch manually.", "other": {"cve": {"id": "CVE-2022-21697", "sourceIdentifier": "security-advisories@github.com", "published": "2022-01-25T14:15:08.907", "lastModified": "2022-02-01T16:31:51.293", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Jupyter Server Proxy is a Jupyter notebook server extension to proxy web services. Versions of Jupyter Server Proxy prior to 3.2.1 are vulnerable to Server-Side Request Forgery (SSRF). Any user deploying Jupyter Server or Notebook with jupyter-proxy-server extension enabled is affected. A lack of input validation allows authenticated clients to proxy requests to other hosts, bypassing the `allowed_hosts` check. Because authentication is required, which already grants permissions to make the same requests via kernel or terminal execution, this is considered low to moderate severity. Users may upgrade to version 3.2.1 to receive a patch or, as a workaround, install the patch manually."}, {"lang": "es", "value": "Jupyter Server Proxy es una extensi\u00f3n del servidor de cuadernos Jupyter para proxy de servicios web. Las versiones de Jupyter Server Proxy anteriores a la 3.2.1 son vulnerables a un ataque de tipo Server-Side Request Forgery (SSRF). Cualquier usuario que despliegue Jupyter Server o Notebook con la extensi\u00f3n jupyter-proxy-server habilitada est\u00e1 afectado. Una falta de comprobaci\u00f3n de la entrada permite a clientes autenticados enviar peticiones a otros hosts, omitiendo la comprobaci\u00f3n \"allowed_hosts\". Debido a que es requerida la autenticaci\u00f3n, que ya otorga permisos para realizar las mismas peticiones por medio del kernel o de la ejecuci\u00f3n del terminal, esto es considerado de gravedad baja a moderada. Los usuarios pueden actualizar a la versi\u00f3n 3.2.1 para recibir un parche o, como medida de mitigaci\u00f3n, instalar el parche manualmente"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 4.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:R/S:U/C:H/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 6.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.1, "impactScore": 4.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:S/C:P/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 5.5}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.0, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-918"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-918"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:jupyter:jupyter_server_proxy:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.2.1", "matchCriteriaId": "B0E4B627-7B2C-48EE-9B09-F461B01BC160"}]}]}], "references": [{"url": "https://github.com/jupyterhub/jupyter-server-proxy/commit/fd31930bacd12188c448c886e0783529436b99eb", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/jupyterhub/jupyter-server-proxy/compare/v3.2.0...v3.2.1.patch", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/jupyterhub/jupyter-server-proxy/security/advisories/GHSA-gcv9-6737-pjqw", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/jupyterhub/jupyter-server-proxy/commit/fd31930bacd12188c448c886e0783529436b99eb"}}
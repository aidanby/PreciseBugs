{"buggy_code": ["# coding: utf-8\nfrom __future__ import print_function, unicode_literals\n\nimport argparse  # typechk\nimport base64\nimport calendar\nimport copy\nimport errno\nimport gzip\nimport itertools\nimport json\nimport os\nimport random\nimport re\nimport stat\nimport string\nimport threading  # typechk\nimport time\nimport uuid\nfrom datetime import datetime\nfrom email.utils import formatdate, parsedate\nfrom operator import itemgetter\n\nimport jinja2  # typechk\n\ntry:\n    import lzma\nexcept:\n    pass\n\nfrom .__init__ import ANYWIN, PY2, TYPE_CHECKING, EnvParams, unicode\nfrom .__version__ import S_VERSION\nfrom .authsrv import VFS  # typechk\nfrom .bos import bos\nfrom .star import StreamTar\nfrom .sutil import StreamArc  # typechk\nfrom .szip import StreamZip\nfrom .util import (\n    HTTPCODE,\n    META_NOBOTS,\n    MultipartParser,\n    Pebkac,\n    UnrecvEOF,\n    alltrace,\n    absreal,\n    atomic_move,\n    exclude_dotfiles,\n    fsenc,\n    gen_filekey,\n    gen_filekey_dbg,\n    gencookie,\n    get_df,\n    get_spd,\n    guess_mime,\n    gzip_orig_sz,\n    hashcopy,\n    hidedir,\n    html_bescape,\n    html_escape,\n    humansize,\n    ipnorm,\n    loadpy,\n    min_ex,\n    quotep,\n    rand_name,\n    read_header,\n    read_socket,\n    read_socket_chunked,\n    read_socket_unbounded,\n    relchk,\n    ren_open,\n    runhook,\n    s3enc,\n    sanitize_fn,\n    sendfile_kern,\n    sendfile_py,\n    undot,\n    unescape_cookie,\n    unquote,\n    unquotep,\n    vjoin,\n    vol_san,\n    vsplit,\n    yieldfile,\n)\n\nif True:  # pylint: disable=using-constant-test\n    import typing\n    from typing import Any, Generator, Match, Optional, Pattern, Type, Union\n\nif TYPE_CHECKING:\n    from .httpconn import HttpConn\n\n_ = (argparse, threading)\n\nNO_CACHE = {\"Cache-Control\": \"no-cache\"}\n\n\nclass HttpCli(object):\n    \"\"\"\n    Spawned by HttpConn to process one http transaction\n    \"\"\"\n\n    def __init__(self, conn: \"HttpConn\") -> None:\n        assert conn.sr\n\n        self.t0 = time.time()\n        self.conn = conn\n        self.mutex = conn.mutex  # mypy404\n        self.s = conn.s\n        self.sr = conn.sr\n        self.ip = conn.addr[0]\n        self.addr: tuple[str, int] = conn.addr\n        self.args = conn.args  # mypy404\n        self.E: EnvParams = self.args.E\n        self.asrv = conn.asrv  # mypy404\n        self.ico = conn.ico  # mypy404\n        self.thumbcli = conn.thumbcli  # mypy404\n        self.u2fh = conn.u2fh  # mypy404\n        self.log_func = conn.log_func  # mypy404\n        self.log_src = conn.log_src  # mypy404\n        self.gen_fk = self._gen_fk if self.args.log_fk else gen_filekey\n        self.tls: bool = hasattr(self.s, \"cipher\")\n\n        # placeholders; assigned by run()\n        self.keepalive = False\n        self.is_https = False\n        self.is_vproxied = False\n        self.in_hdr_recv = True\n        self.headers: dict[str, str] = {}\n        self.mode = \" \"\n        self.req = \" \"\n        self.http_ver = \" \"\n        self.host = \" \"\n        self.ua = \" \"\n        self.is_rclone = False\n        self.ouparam: dict[str, str] = {}\n        self.uparam: dict[str, str] = {}\n        self.cookies: dict[str, str] = {}\n        self.avn: Optional[VFS] = None\n        self.vn = self.asrv.vfs\n        self.rem = \" \"\n        self.vpath = \" \"\n        self.uname = \" \"\n        self.pw = \" \"\n        self.rvol = [\" \"]\n        self.wvol = [\" \"]\n        self.mvol = [\" \"]\n        self.dvol = [\" \"]\n        self.gvol = [\" \"]\n        self.upvol = [\" \"]\n        self.avol = [\" \"]\n        self.do_log = True\n        self.can_read = False\n        self.can_write = False\n        self.can_move = False\n        self.can_delete = False\n        self.can_get = False\n        self.can_upget = False\n        self.can_admin = False\n        # post\n        self.parser: Optional[MultipartParser] = None\n        # end placeholders\n\n        self.bufsz = 1024 * 32\n        self.hint = \"\"\n        self.trailing_slash = True\n        self.out_headerlist: list[tuple[str, str]] = []\n        self.out_headers = {\n            \"Vary\": \"Origin, PW, Cookie\",\n            \"Cache-Control\": \"no-store, max-age=0\",\n        }\n        h = self.args.html_head\n        if self.args.no_robots:\n            h = META_NOBOTS + ((\"\\n\" + h) if h else \"\")\n            self.out_headers[\"X-Robots-Tag\"] = \"noindex, nofollow\"\n        self.html_head = h\n\n    def log(self, msg: str, c: Union[int, str] = 0) -> None:\n        ptn = self.asrv.re_pwd\n        if ptn and ptn.search(msg):\n            if self.asrv.ah.on:\n                msg = ptn.sub(\"\\033[7m pw \\033[27m\", msg)\n            else:\n                msg = ptn.sub(self.unpwd, msg)\n\n        self.log_func(self.log_src, msg, c)\n\n    def unpwd(self, m: Match[str]) -> str:\n        a, b, c = m.groups()\n        return \"{}\\033[7m {} \\033[27m{}\".format(a, self.asrv.iacct[b], c)\n\n    def _check_nonfatal(self, ex: Pebkac, post: bool) -> bool:\n        if post:\n            return ex.code < 300\n\n        return ex.code < 400 or ex.code in [404, 429]\n\n    def _assert_safe_rem(self, rem: str) -> None:\n        # sanity check to prevent any disasters\n        if rem.startswith(\"/\") or rem.startswith(\"../\") or \"/../\" in rem:\n            raise Exception(\"that was close\")\n\n    def _gen_fk(self, salt: str, fspath: str, fsize: int, inode: int) -> str:\n        return gen_filekey_dbg(salt, fspath, fsize, inode, self.log, self.args.log_fk)\n\n    def j2s(self, name: str, **ka: Any) -> str:\n        tpl = self.conn.hsrv.j2[name]\n        ka[\"r\"] = self.args.SR if self.is_vproxied else \"\"\n        ka[\"ts\"] = self.conn.hsrv.cachebuster()\n        ka[\"lang\"] = self.args.lang\n        ka[\"favico\"] = self.args.favico\n        ka[\"svcname\"] = self.args.doctitle\n        ka[\"html_head\"] = self.html_head\n        return tpl.render(**ka)  # type: ignore\n\n    def j2j(self, name: str) -> jinja2.Template:\n        return self.conn.hsrv.j2[name]\n\n    def run(self) -> bool:\n        \"\"\"returns true if connection can be reused\"\"\"\n        self.keepalive = False\n        self.is_https = False\n        self.headers = {}\n        self.hint = \"\"\n\n        if self.is_banned():\n            return False\n\n        try:\n            self.s.settimeout(2)\n            headerlines = read_header(self.sr, self.args.s_thead, self.args.s_thead)\n            self.in_hdr_recv = False\n            if not headerlines:\n                return False\n\n            if not headerlines[0]:\n                # seen after login with IE6.0.2900.5512.xpsp.080413-2111 (xp-sp3)\n                self.log(\"BUG: trailing newline from previous request\", c=\"1;31\")\n                headerlines.pop(0)\n\n            try:\n                self.mode, self.req, self.http_ver = headerlines[0].split(\" \")\n\n                # normalize incoming headers to lowercase;\n                # outgoing headers however are Correct-Case\n                for header_line in headerlines[1:]:\n                    k, zs = header_line.split(\":\", 1)\n                    self.headers[k.lower()] = zs.strip()\n            except:\n                msg = \" ]\\n#[ \".join(headerlines)\n                raise Pebkac(400, \"bad headers:\\n#[ \" + msg + \" ]\")\n\n        except Pebkac as ex:\n            self.mode = \"GET\"\n            self.req = \"[junk]\"\n            self.http_ver = \"HTTP/1.1\"\n            # self.log(\"pebkac at httpcli.run #1: \" + repr(ex))\n            self.keepalive = False\n            h = {\"WWW-Authenticate\": 'Basic realm=\"a\"'} if ex.code == 401 else {}\n            try:\n                self.loud_reply(unicode(ex), status=ex.code, headers=h, volsan=True)\n                return self.keepalive\n            except:\n                return False\n\n        self.ua = self.headers.get(\"user-agent\", \"\")\n        self.is_rclone = self.ua.startswith(\"rclone/\")\n\n        zs = self.headers.get(\"connection\", \"\").lower()\n        self.keepalive = \"close\" not in zs and (\n            self.http_ver != \"HTTP/1.0\" or zs == \"keep-alive\"\n        )\n        self.is_https = (\n            self.headers.get(\"x-forwarded-proto\", \"\").lower() == \"https\" or self.tls\n        )\n        self.host = self.headers.get(\"host\") or \"\"\n        if not self.host:\n            zs = \"%s:%s\" % self.s.getsockname()[:2]\n            self.host = zs[7:] if zs.startswith(\"::ffff:\") else zs\n\n        n = self.args.rproxy\n        if n:\n            zso = self.headers.get(\"x-forwarded-for\")\n            if zso and self.conn.addr[0] in [\"127.0.0.1\", \"::1\"]:\n                if n > 0:\n                    n -= 1\n\n                zsl = zso.split(\",\")\n                try:\n                    self.ip = zsl[n].strip()\n                except:\n                    self.ip = zsl[0].strip()\n                    t = \"rproxy={} oob x-fwd {}\"\n                    self.log(t.format(self.args.rproxy, zso), c=3)\n\n                self.log_src = self.conn.set_rproxy(self.ip)\n                self.is_vproxied = bool(self.args.R)\n                self.host = self.headers.get(\"x-forwarded-host\") or self.host\n\n        if self.is_banned():\n            return False\n\n        if self.conn.aclose:\n            nka = self.conn.aclose\n            ip = ipnorm(self.ip)\n            if ip in nka:\n                rt = nka[ip] - time.time()\n                if rt < 0:\n                    self.log(\"client uncapped\", 3)\n                    del nka[ip]\n                else:\n                    self.keepalive = False\n\n        ptn: Optional[Pattern[str]] = self.conn.lf_url  # mypy404\n        self.do_log = not ptn or not ptn.search(self.req)\n\n        if self.args.ihead and self.do_log:\n            keys = self.args.ihead\n            if \"*\" in keys:\n                keys = list(sorted(self.headers.keys()))\n\n            for k in keys:\n                zso = self.headers.get(k)\n                if zso is not None:\n                    self.log(\"[H] {}: \\033[33m[{}]\".format(k, zso), 6)\n\n        if \"&\" in self.req and \"?\" not in self.req:\n            self.hint = \"did you mean '?' instead of '&'\"\n\n        # split req into vpath + uparam\n        uparam = {}\n        if \"?\" not in self.req:\n            self.trailing_slash = self.req.endswith(\"/\")\n            vpath = undot(self.req)\n        else:\n            vpath, arglist = self.req.split(\"?\", 1)\n            self.trailing_slash = vpath.endswith(\"/\")\n            vpath = undot(vpath)\n            for k in arglist.split(\"&\"):\n                if \"=\" in k:\n                    k, zs = k.split(\"=\", 1)\n                    uparam[k.lower()] = unquotep(zs.strip().replace(\"+\", \" \"))\n                else:\n                    uparam[k.lower()] = \"\"\n\n        if self.is_vproxied:\n            if vpath.startswith(self.args.R):\n                vpath = vpath[len(self.args.R) + 1 :]\n            else:\n                t = \"incorrect --rp-loc or webserver config; expected vpath starting with [{}] but got [{}]\"\n                self.log(t.format(self.args.R, vpath), 1)\n\n        self.ouparam = {k: zs for k, zs in uparam.items()}\n\n        if self.args.rsp_slp:\n            time.sleep(self.args.rsp_slp)\n            if self.args.rsp_jtr:\n                time.sleep(random.random() * self.args.rsp_jtr)\n\n        zso = self.headers.get(\"cookie\")\n        if zso:\n            zsll = [x.split(\"=\", 1) for x in zso.split(\";\") if \"=\" in x]\n            cookies = {k.strip(): unescape_cookie(zs) for k, zs in zsll}\n            cookie_pw = cookies.get(\"cppws\") or cookies.get(\"cppwd\") or \"\"\n            if \"b\" in cookies and \"b\" not in uparam:\n                uparam[\"b\"] = cookies[\"b\"]\n        else:\n            cookies = {}\n            cookie_pw = \"\"\n\n        if len(uparam) > 10 or len(cookies) > 50:\n            raise Pebkac(400, \"u wot m8\")\n\n        self.uparam = uparam\n        self.cookies = cookies\n        self.vpath = unquotep(vpath)  # not query, so + means +\n\n        ok = \"\\x00\" not in self.vpath\n        if ANYWIN:\n            ok = ok and not relchk(self.vpath)\n\n        if not ok and (self.vpath != \"*\" or self.mode != \"OPTIONS\"):\n            self.log(\"invalid relpath [{}]\".format(self.vpath))\n            return self.tx_404() and self.keepalive\n\n        zso = self.headers.get(\"authorization\")\n        bauth = \"\"\n        if zso:\n            try:\n                zb = zso.split(\" \")[1].encode(\"ascii\")\n                zs = base64.b64decode(zb).decode(\"utf-8\")\n                # try \"pwd\", \"x:pwd\", \"pwd:x\"\n                for bauth in [zs] + zs.split(\":\", 1)[::-1]:\n                    hpw = self.asrv.ah.hash(bauth)\n                    if self.asrv.iacct.get(hpw):\n                        break\n            except:\n                pass\n\n        self.pw = uparam.get(\"pw\") or self.headers.get(\"pw\") or bauth or cookie_pw\n        self.uname = self.asrv.iacct.get(self.asrv.ah.hash(self.pw)) or \"*\"\n        self.rvol = self.asrv.vfs.aread[self.uname]\n        self.wvol = self.asrv.vfs.awrite[self.uname]\n        self.mvol = self.asrv.vfs.amove[self.uname]\n        self.dvol = self.asrv.vfs.adel[self.uname]\n        self.gvol = self.asrv.vfs.aget[self.uname]\n        self.upvol = self.asrv.vfs.apget[self.uname]\n        self.avol = self.asrv.vfs.aadmin[self.uname]\n\n        if self.pw and (\n            self.pw != cookie_pw or self.conn.freshen_pwd + 30 < time.time()\n        ):\n            self.conn.freshen_pwd = time.time()\n            self.get_pwd_cookie(self.pw)\n\n        if self.is_rclone:\n            # dots: always include dotfiles if permitted\n            # lt: probably more important showing the correct timestamps of any dupes it just uploaded rather than the lastmod time of any non-copyparty-managed symlinks\n            # b: basic-browser if it tries to parse the html listing\n            uparam[\"dots\"] = \"\"\n            uparam[\"lt\"] = \"\"\n            uparam[\"b\"] = \"\"\n            cookies[\"b\"] = \"\"\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, False, False)\n        if \"xdev\" in vn.flags or \"xvol\" in vn.flags:\n            ap = vn.canonical(rem)\n            avn = vn.chk_ap(ap)\n        else:\n            avn = vn\n\n        (\n            self.can_read,\n            self.can_write,\n            self.can_move,\n            self.can_delete,\n            self.can_get,\n            self.can_upget,\n            self.can_admin,\n        ) = (\n            avn.can_access(\"\", self.uname) if avn else [False] * 7\n        )\n        self.avn = avn\n        self.vn = vn\n        self.rem = rem\n\n        self.s.settimeout(self.args.s_tbody or None)\n\n        try:\n            cors_k = self._cors()\n            if self.mode in (\"GET\", \"HEAD\"):\n                return self.handle_get() and self.keepalive\n            if self.mode == \"OPTIONS\":\n                return self.handle_options() and self.keepalive\n\n            if not cors_k:\n                origin = self.headers.get(\"origin\", \"<?>\")\n                self.log(\"cors-reject {} from {}\".format(self.mode, origin), 3)\n                raise Pebkac(403, \"no surfing\")\n\n            # getattr(self.mode) is not yet faster than this\n            if self.mode == \"POST\":\n                return self.handle_post() and self.keepalive\n            elif self.mode == \"PUT\":\n                return self.handle_put() and self.keepalive\n            elif self.mode == \"PROPFIND\":\n                return self.handle_propfind() and self.keepalive\n            elif self.mode == \"DELETE\":\n                return self.handle_delete() and self.keepalive\n            elif self.mode == \"PROPPATCH\":\n                return self.handle_proppatch() and self.keepalive\n            elif self.mode == \"LOCK\":\n                return self.handle_lock() and self.keepalive\n            elif self.mode == \"UNLOCK\":\n                return self.handle_unlock() and self.keepalive\n            elif self.mode == \"MKCOL\":\n                return self.handle_mkcol() and self.keepalive\n            elif self.mode == \"MOVE\":\n                return self.handle_move() and self.keepalive\n            else:\n                raise Pebkac(400, 'invalid HTTP mode \"{0}\"'.format(self.mode))\n\n        except Exception as ex:\n            if not isinstance(ex, Pebkac):\n                pex = Pebkac(500)\n            else:\n                pex: Pebkac = ex  # type: ignore\n\n            try:\n                post = self.mode in [\"POST\", \"PUT\"] or \"content-length\" in self.headers\n                if not self._check_nonfatal(pex, post):\n                    self.keepalive = False\n\n                em = str(ex)\n                msg = em if pex == ex else min_ex()\n                if pex.code != 404 or self.do_log:\n                    self.log(\n                        \"{}\\033[0m, {}\".format(msg, self.vpath),\n                        6 if em.startswith(\"client d/c \") else 3,\n                    )\n\n                msg = \"{}\\r\\nURL: {}\\r\\n\".format(em, self.vpath)\n                if self.hint:\n                    msg += \"hint: {}\\r\\n\".format(self.hint)\n\n                if \"database is locked\" in em:\n                    self.conn.hsrv.broker.say(\"log_stacks\")\n                    msg += \"hint: important info in the server log\\r\\n\"\n\n                zb = b\"<pre>\" + html_escape(msg).encode(\"utf-8\", \"replace\")\n                h = {\"WWW-Authenticate\": 'Basic realm=\"a\"'} if pex.code == 401 else {}\n                self.reply(zb, status=pex.code, headers=h, volsan=True)\n                return self.keepalive\n            except Pebkac:\n                return False\n\n    def dip(self) -> str:\n        if self.args.plain_ip:\n            return self.ip.replace(\":\", \".\")\n        else:\n            return self.conn.iphash.s(self.ip)\n\n    def is_banned(self) -> bool:\n        if not self.conn.bans:\n            return False\n\n        bans = self.conn.bans\n        ip = ipnorm(self.ip)\n        if ip not in bans:\n            return False\n\n        rt = bans[ip] - time.time()\n        if rt < 0:\n            self.log(\"client unbanned\", 3)\n            del bans[ip]\n            return False\n\n        self.log(\"banned for {:.0f} sec\".format(rt), 6)\n        zb = b\"HTTP/1.0 403 Forbidden\\r\\n\\r\\nthank you for playing\"\n        self.s.sendall(zb)\n        return True\n\n    def permit_caching(self) -> None:\n        cache = self.uparam.get(\"cache\")\n        if cache is None:\n            self.out_headers.update(NO_CACHE)\n            return\n\n        n = \"604869\" if cache == \"i\" else cache or \"69\"\n        self.out_headers[\"Cache-Control\"] = \"max-age=\" + n\n\n    def k304(self) -> bool:\n        k304 = self.cookies.get(\"k304\")\n        return k304 == \"y\" or (\"; Trident/\" in self.ua and not k304)\n\n    def send_headers(\n        self,\n        length: Optional[int],\n        status: int = 200,\n        mime: Optional[str] = None,\n        headers: Optional[dict[str, str]] = None,\n    ) -> None:\n        response = [\"%s %s %s\" % (self.http_ver, status, HTTPCODE[status])]\n\n        if length is not None:\n            response.append(\"Content-Length: \" + unicode(length))\n\n        if status == 304 and self.k304():\n            self.keepalive = False\n\n        # close if unknown length, otherwise take client's preference\n        response.append(\"Connection: \" + (\"Keep-Alive\" if self.keepalive else \"Close\"))\n        response.append(\"Date: \" + formatdate(usegmt=True))\n\n        # headers{} overrides anything set previously\n        if headers:\n            self.out_headers.update(headers)\n\n        # default to utf8 html if no content-type is set\n        if not mime:\n            mime = self.out_headers.get(\"Content-Type\") or \"text/html; charset=utf-8\"\n\n        self.out_headers[\"Content-Type\"] = mime\n\n        for k, zs in list(self.out_headers.items()) + self.out_headerlist:\n            response.append(\"%s: %s\" % (k, zs))\n\n        try:\n            # best practice to separate headers and body into different packets\n            self.s.sendall(\"\\r\\n\".join(response).encode(\"utf-8\") + b\"\\r\\n\\r\\n\")\n        except:\n            raise Pebkac(400, \"client d/c while replying headers\")\n\n    def reply(\n        self,\n        body: bytes,\n        status: int = 200,\n        mime: Optional[str] = None,\n        headers: Optional[dict[str, str]] = None,\n        volsan: bool = False,\n    ) -> bytes:\n        if status == 404:\n            g = self.conn.hsrv.g404\n            if g.lim:\n                bonk, ip = g.bonk(self.ip, self.vpath)\n                if bonk:\n                    xban = self.vn.flags.get(\"xban\")\n                    if not xban or not runhook(\n                        self.log,\n                        xban,\n                        self.vn.canonical(self.rem),\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        time.time(),\n                        0,\n                        self.ip,\n                        time.time(),\n                        \"404\",\n                    ):\n                        self.log(\"client banned: 404s\", 1)\n                        self.conn.hsrv.bans[ip] = bonk\n\n        if volsan:\n            vols = list(self.asrv.vfs.all_vols.values())\n            body = vol_san(vols, body)\n\n        self.send_headers(len(body), status, mime, headers)\n\n        try:\n            if self.mode != \"HEAD\":\n                self.s.sendall(body)\n        except:\n            raise Pebkac(400, \"client d/c while replying body\")\n\n        return body\n\n    def loud_reply(self, body: str, *args: Any, **kwargs: Any) -> None:\n        if not kwargs.get(\"mime\"):\n            kwargs[\"mime\"] = \"text/plain; charset=utf-8\"\n\n        self.log(body.rstrip())\n        self.reply(body.encode(\"utf-8\") + b\"\\r\\n\", *list(args), **kwargs)\n\n    def urlq(self, add: dict[str, str], rm: list[str]) -> str:\n        \"\"\"\n        generates url query based on uparam (b, pw, all others)\n        removing anything in rm, adding pairs in add\n\n        also list faster than set until ~20 items\n        \"\"\"\n\n        if self.is_rclone:\n            return \"\"\n\n        kv = {k: zs for k, zs in self.uparam.items() if k not in rm}\n        if \"pw\" in kv:\n            pw = self.cookies.get(\"cppws\") or self.cookies.get(\"cppwd\")\n            if kv[\"pw\"] == pw:\n                del kv[\"pw\"]\n\n        kv.update(add)\n        if not kv:\n            return \"\"\n\n        r = [\"%s=%s\" % (k, quotep(zs)) if zs else k for k, zs in kv.items()]\n        return \"?\" + \"&amp;\".join(r)\n\n    def redirect(\n        self,\n        vpath: str,\n        suf: str = \"\",\n        msg: str = \"aight\",\n        flavor: str = \"go to\",\n        click: bool = True,\n        status: int = 200,\n        use302: bool = False,\n    ) -> bool:\n        vp = self.args.RS + vpath\n        html = self.j2s(\n            \"msg\",\n            h2='<a href=\"/{}\">{} /{}</a>'.format(\n                quotep(vp) + suf, flavor, html_escape(vp, crlf=True) + suf\n            ),\n            pre=msg,\n            click=click,\n        ).encode(\"utf-8\", \"replace\")\n\n        if use302:\n            self.reply(html, status=302, headers={\"Location\": \"/\" + vpath})\n        else:\n            self.reply(html, status=status)\n\n        return True\n\n    def _cors(self) -> bool:\n        ih = self.headers\n        origin = ih.get(\"origin\")\n        if not origin:\n            sfsite = ih.get(\"sec-fetch-site\")\n            if sfsite and sfsite.lower().startswith(\"cross\"):\n                origin = \":|\"  # sandboxed iframe\n            else:\n                return True\n\n        oh = self.out_headers\n        origin = origin.lower()\n        good_origins = self.args.acao + [\n            \"{}://{}\".format(\n                \"https\" if self.is_https else \"http\",\n                self.host.lower().split(\":\")[0],\n            )\n        ]\n        if re.sub(r\"(:[0-9]{1,5})?/?$\", \"\", origin) in good_origins:\n            good_origin = True\n            bad_hdrs = (\"\",)\n        else:\n            good_origin = False\n            bad_hdrs = (\"\", \"pw\")\n\n        # '*' blocks all credentials (cookies, http-auth);\n        # exact-match for Origin is necessary to unlock those,\n        # however yolo-requests (?pw=) are always allowed\n        acah = ih.get(\"access-control-request-headers\", \"\")\n        acao = (origin if good_origin else None) or (\n            \"*\" if \"*\" in good_origins else None\n        )\n        if self.args.allow_csrf:\n            acao = origin or acao or \"*\"  # explicitly permit impersonation\n            acam = \", \".join(self.conn.hsrv.mallow)  # and all methods + headers\n            oh[\"Access-Control-Allow-Credentials\"] = \"true\"\n            good_origin = True\n        else:\n            acam = \", \".join(self.args.acam)\n            # wash client-requested headers and roll with that\n            if \"range\" not in acah.lower():\n                acah += \",Range\"  # firefox\n            req_h = acah.split(\",\")\n            req_h = [x.strip() for x in req_h]\n            req_h = [x for x in req_h if x.lower() not in bad_hdrs]\n            acah = \", \".join(req_h)\n\n        if not acao:\n            return False\n\n        oh[\"Access-Control-Allow-Origin\"] = acao\n        oh[\"Access-Control-Allow-Methods\"] = acam.upper()\n        if acah:\n            oh[\"Access-Control-Allow-Headers\"] = acah\n\n        return good_origin\n\n    def handle_get(self) -> bool:\n        if self.do_log:\n            logmsg = \"%-4s %s @%s\" % (self.mode, self.req, self.uname)\n\n            if \"range\" in self.headers:\n                try:\n                    rval = self.headers[\"range\"].split(\"=\", 1)[1]\n                except:\n                    rval = self.headers[\"range\"]\n\n                logmsg += \" [\\033[36m\" + rval + \"\\033[0m]\"\n\n            self.log(logmsg)\n\n        # \"embedded\" resources\n        if self.vpath.startswith(\".cpr\"):\n            if self.vpath.startswith(\".cpr/ico/\"):\n                return self.tx_ico(self.vpath.split(\"/\")[-1], exact=True)\n\n            if self.vpath.startswith(\".cpr/ssdp\"):\n                return self.conn.hsrv.ssdp.reply(self)\n\n            if self.vpath.startswith(\".cpr/dd/\") and self.args.mpmc:\n                if self.args.mpmc == \".\":\n                    raise Pebkac(404)\n\n                loc = self.args.mpmc.rstrip(\"/\") + self.vpath[self.vpath.rfind(\"/\") :]\n                h = {\"Location\": loc, \"Cache-Control\": \"max-age=39\"}\n                self.reply(b\"\", 301, headers=h)\n                return True\n\n            path_base = os.path.join(self.E.mod, \"web\")\n            static_path = absreal(os.path.join(path_base, self.vpath[5:]))\n            if not static_path.startswith(path_base):\n                t = \"attempted path traversal [{}] => [{}]\"\n                self.log(t.format(self.vpath, static_path), 1)\n                self.tx_404()\n                return False\n\n            return self.tx_file(static_path)\n\n        if \"cf_challenge\" in self.uparam:\n            self.reply(self.j2s(\"cf\").encode(\"utf-8\", \"replace\"))\n            return True\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            t = \"@{} has no access to [{}]\"\n            self.log(t.format(self.uname, self.vpath))\n\n            if \"on403\" in self.vn.flags:\n                ret = self.on40x(self.vn.flags[\"on403\"], self.vn, self.rem)\n                if ret == \"true\":\n                    return True\n                elif ret == \"false\":\n                    return False\n                elif ret == \"allow\":\n                    self.log(\"plugin override; access permitted\")\n                    self.can_read = self.can_write = self.can_move = True\n                    self.can_delete = self.can_get = self.can_upget = True\n                    self.can_admin = True\n                else:\n                    return self.tx_404(True)\n            else:\n                if self.vpath:\n                    return self.tx_404(True)\n\n                self.uparam[\"h\"] = \"\"\n\n        if \"tree\" in self.uparam:\n            return self.tx_tree()\n\n        if \"scan\" in self.uparam:\n            return self.scanvol()\n\n        if self.args.getmod:\n            if \"delete\" in self.uparam:\n                return self.handle_rm([])\n\n            if \"move\" in self.uparam:\n                return self.handle_mv()\n\n        if not self.vpath:\n            if \"reload\" in self.uparam:\n                return self.handle_reload()\n\n            if \"stack\" in self.uparam:\n                return self.tx_stack()\n\n            if \"ups\" in self.uparam:\n                return self.tx_ups()\n\n            if \"k304\" in self.uparam:\n                return self.set_k304()\n\n            if \"setck\" in self.uparam:\n                return self.setck()\n\n            if \"reset\" in self.uparam:\n                return self.set_cfg_reset()\n\n            if \"hc\" in self.uparam:\n                return self.tx_svcs()\n\n        if \"h\" in self.uparam:\n            return self.tx_mounts()\n\n        # conditional redirect to single volumes\n        if self.vpath == \"\" and not self.ouparam:\n            nread = len(self.rvol)\n            nwrite = len(self.wvol)\n            if nread + nwrite == 1 or (self.rvol == self.wvol and nread == 1):\n                if nread == 1:\n                    vpath = self.rvol[0]\n                else:\n                    vpath = self.wvol[0]\n\n                if self.vpath != vpath:\n                    self.redirect(vpath, flavor=\"redirecting to\", use302=True)\n                    return True\n\n        return self.tx_browser()\n\n    def handle_propfind(self) -> bool:\n        if self.do_log:\n            self.log(\"PFIND %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, False, False, err=401)\n        tap = vn.canonical(rem)\n\n        if \"davauth\" in vn.flags and self.uname == \"*\":\n            self.can_read = self.can_write = self.can_get = False\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            self.log(\"inaccessible: [{}]\".format(self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from .dxml import parse_xml\n\n        # enc = \"windows-31j\"\n        # enc = \"shift_jis\"\n        enc = \"utf-8\"\n        uenc = enc.upper()\n\n        clen = int(self.headers.get(\"content-length\", 0))\n        if clen:\n            buf = b\"\"\n            for rbuf in self.get_body_reader()[0]:\n                buf += rbuf\n                if not rbuf or len(buf) >= 32768:\n                    break\n\n            xroot = parse_xml(buf.decode(enc, \"replace\"))\n            xtag = next(x for x in xroot if x.tag.split(\"}\")[-1] == \"prop\")\n            props_lst = [y.tag.split(\"}\")[-1] for y in xtag]\n        else:\n            props_lst = [\n                \"contentclass\",\n                \"creationdate\",\n                \"defaultdocument\",\n                \"displayname\",\n                \"getcontentlanguage\",\n                \"getcontentlength\",\n                \"getcontenttype\",\n                \"getlastmodified\",\n                \"href\",\n                \"iscollection\",\n                \"ishidden\",\n                \"isreadonly\",\n                \"isroot\",\n                \"isstructureddocument\",\n                \"lastaccessed\",\n                \"name\",\n                \"parentname\",\n                \"resourcetype\",\n                \"supportedlock\",\n            ]\n\n        props = set(props_lst)\n        depth = self.headers.get(\"depth\", \"infinity\").lower()\n\n        try:\n            topdir = {\"vp\": \"\", \"st\": bos.stat(tap)}\n        except OSError as ex:\n            if ex.errno not in (errno.ENOENT, errno.ENOTDIR):\n                raise\n            raise Pebkac(404)\n\n        if depth == \"0\" or not self.can_read or not stat.S_ISDIR(topdir[\"st\"].st_mode):\n            fgen = []\n\n        elif depth == \"infinity\":\n            if not self.args.dav_inf:\n                self.log(\"client wants --dav-inf\", 3)\n                zb = b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<D:error xmlns:D=\"DAV:\"><D:propfind-finite-depth/></D:error>'\n                self.reply(zb, 403, \"application/xml; charset=utf-8\")\n                return True\n\n            # this will return symlink-target timestamps\n            # because lstat=true would not recurse into subfolders\n            # and this is a rare case where we actually want that\n            fgen = vn.zipgen(\n                rem,\n                rem,\n                set(),\n                self.uname,\n                self.args.ed,\n                True,\n                not self.args.no_scandir,\n                wrap=False,\n            )\n\n        elif depth == \"1\":\n            _, vfs_ls, vfs_virt = vn.ls(\n                rem,\n                self.uname,\n                not self.args.no_scandir,\n                [[True, False]],\n                lstat=\"davrt\" not in vn.flags,\n            )\n            if not self.args.ed:\n                names = set(exclude_dotfiles([x[0] for x in vfs_ls]))\n                vfs_ls = [x for x in vfs_ls if x[0] in names]\n\n            zi = int(time.time())\n            zsr = os.stat_result((16877, -1, -1, 1, 1000, 1000, 8, zi, zi, zi))\n            ls = [{\"vp\": vp, \"st\": st} for vp, st in vfs_ls]\n            ls += [{\"vp\": v, \"st\": zsr} for v in vfs_virt]\n            fgen = ls  # type: ignore\n\n        else:\n            t = \"invalid depth value '{}' (must be either '0' or '1'{})\"\n            t2 = \" or 'infinity'\" if self.args.dav_inf else \"\"\n            raise Pebkac(412, t.format(depth, t2))\n\n        fgen = itertools.chain([topdir], fgen)  # type: ignore\n        vtop = vjoin(self.args.R, vjoin(vn.vpath, rem))\n\n        chunksz = 0x7FF8  # preferred by nginx or cf (dunno which)\n\n        self.send_headers(\n            None, 207, \"text/xml; charset=\" + enc, {\"Transfer-Encoding\": \"chunked\"}\n        )\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n<D:multistatus xmlns:D=\"DAV:\">'\n        ret = ret.format(uenc)\n        for x in fgen:\n            rp = vjoin(vtop, x[\"vp\"])\n            st: os.stat_result = x[\"st\"]\n            mtime = st.st_mtime\n            if stat.S_ISLNK(st.st_mode):\n                try:\n                    st = bos.stat(os.path.join(tap, x[\"vp\"]))\n                except:\n                    continue\n\n            isdir = stat.S_ISDIR(st.st_mode)\n\n            ret += \"<D:response><D:href>/%s%s</D:href><D:propstat><D:prop>\" % (\n                quotep(rp),\n                \"/\" if isdir and rp else \"\",\n            )\n\n            pvs: dict[str, str] = {\n                \"displayname\": html_escape(rp.split(\"/\")[-1]),\n                \"getlastmodified\": formatdate(mtime, usegmt=True),\n                \"resourcetype\": '<D:collection xmlns:D=\"DAV:\"/>' if isdir else \"\",\n                \"supportedlock\": '<D:lockentry xmlns:D=\"DAV:\"><D:lockscope><D:exclusive/></D:lockscope><D:locktype><D:write/></D:locktype></D:lockentry>',\n            }\n            if not isdir:\n                pvs[\"getcontenttype\"] = html_escape(guess_mime(rp))\n                pvs[\"getcontentlength\"] = str(st.st_size)\n\n            for k, v in pvs.items():\n                if k not in props:\n                    continue\n                elif v:\n                    ret += \"<D:%s>%s</D:%s>\" % (k, v, k)\n                else:\n                    ret += \"<D:%s/>\" % (k,)\n\n            ret += \"</D:prop><D:status>HTTP/1.1 200 OK</D:status></D:propstat>\"\n\n            missing = [\"<D:%s/>\" % (x,) for x in props if x not in pvs]\n            if missing and clen:\n                t = \"<D:propstat><D:prop>{}</D:prop><D:status>HTTP/1.1 404 Not Found</D:status></D:propstat>\"\n                ret += t.format(\"\".join(missing))\n\n            ret += \"</D:response>\"\n            while len(ret) >= chunksz:\n                ret = self.send_chunk(ret, enc, chunksz)\n\n        ret += \"</D:multistatus>\"\n        while ret:\n            ret = self.send_chunk(ret, enc, chunksz)\n\n        self.send_chunk(\"\", enc, chunksz)\n        # self.reply(ret.encode(enc, \"replace\"),207, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_proppatch(self) -> bool:\n        if self.do_log:\n            self.log(\"PPATCH %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        if not self.can_write:\n            self.log(\"{} tried to proppatch [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from xml.etree import ElementTree as ET\n\n        from .dxml import mkenod, mktnod, parse_xml\n\n        buf = b\"\"\n        for rbuf in self.get_body_reader()[0]:\n            buf += rbuf\n            if not rbuf or len(buf) >= 128 * 1024:\n                break\n\n        if self._applesan():\n            return True\n\n        txt = buf.decode(\"ascii\", \"replace\").lower()\n        enc = self.get_xml_enc(txt)\n        uenc = enc.upper()\n\n        txt = buf.decode(enc, \"replace\")\n        ET.register_namespace(\"D\", \"DAV:\")\n        xroot = mkenod(\"D:orz\")\n        xroot.insert(0, parse_xml(txt))\n        xprop = xroot.find(r\"./{DAV:}propertyupdate/{DAV:}set/{DAV:}prop\")\n        assert xprop\n        for ze in xprop:\n            ze.clear()\n\n        txt = \"\"\"<multistatus xmlns=\"DAV:\"><response><propstat><status>HTTP/1.1 403 Forbidden</status></propstat></response></multistatus>\"\"\"\n        xroot = parse_xml(txt)\n\n        el = xroot.find(r\"./{DAV:}response\")\n        assert el\n        e2 = mktnod(\"D:href\", quotep(self.args.SRS + self.vpath))\n        el.insert(0, e2)\n\n        el = xroot.find(r\"./{DAV:}response/{DAV:}propstat\")\n        assert el\n        el.insert(0, xprop)\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n'.format(uenc)\n        ret += ET.tostring(xroot).decode(\"utf-8\")\n\n        self.reply(ret.encode(enc, \"replace\"), 207, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_lock(self) -> bool:\n        if self.do_log:\n            self.log(\"LOCK %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        # win7+ deadlocks if we say no; just smile and nod\n        if not self.can_write and \"Microsoft-WebDAV\" not in self.ua:\n            self.log(\"{} tried to lock [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from xml.etree import ElementTree as ET\n\n        from .dxml import mkenod, mktnod, parse_xml\n\n        abspath = self.vn.dcanonical(self.rem)\n\n        buf = b\"\"\n        for rbuf in self.get_body_reader()[0]:\n            buf += rbuf\n            if not rbuf or len(buf) >= 128 * 1024:\n                break\n\n        if self._applesan():\n            return True\n\n        txt = buf.decode(\"ascii\", \"replace\").lower()\n        enc = self.get_xml_enc(txt)\n        uenc = enc.upper()\n\n        txt = buf.decode(enc, \"replace\")\n        ET.register_namespace(\"D\", \"DAV:\")\n        lk = parse_xml(txt)\n        assert lk.tag == \"{DAV:}lockinfo\"\n\n        token = str(uuid.uuid4())\n\n        if not lk.find(r\"./{DAV:}depth\"):\n            depth = self.headers.get(\"depth\", \"infinity\")\n            lk.append(mktnod(\"D:depth\", depth))\n\n        lk.append(mktnod(\"D:timeout\", \"Second-3310\"))\n        lk.append(mkenod(\"D:locktoken\", mktnod(\"D:href\", token)))\n        lk.append(\n            mkenod(\"D:lockroot\", mktnod(\"D:href\", quotep(self.args.SRS + self.vpath)))\n        )\n\n        lk2 = mkenod(\"D:activelock\")\n        xroot = mkenod(\"D:prop\", mkenod(\"D:lockdiscovery\", lk2))\n        for a in lk:\n            lk2.append(a)\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n'.format(uenc)\n        ret += ET.tostring(xroot).decode(\"utf-8\")\n\n        rc = 200\n        if self.can_write and not bos.path.isfile(abspath):\n            with open(fsenc(abspath), \"wb\") as _:\n                rc = 201\n\n        self.out_headers[\"Lock-Token\"] = \"<{}>\".format(token)\n        self.reply(ret.encode(enc, \"replace\"), rc, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_unlock(self) -> bool:\n        if self.do_log:\n            self.log(\"UNLOCK %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        if not self.can_write and \"Microsoft-WebDAV\" not in self.ua:\n            self.log(\"{} tried to lock [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        self.send_headers(None, 204)\n        return True\n\n    def handle_mkcol(self) -> bool:\n        if self._applesan():\n            return True\n\n        if self.do_log:\n            self.log(\"MKCOL %s @%s\" % (self.req, self.uname))\n\n        try:\n            return self._mkdir(self.vpath, True)\n        except Pebkac as ex:\n            if ex.code >= 500:\n                raise\n\n            self.reply(b\"\", ex.code)\n            return True\n\n    def handle_move(self) -> bool:\n        dst = self.headers[\"destination\"]\n        dst = re.sub(\"^https?://[^/]+\", \"\", dst).lstrip()\n        dst = unquotep(dst)\n        if not self._mv(self.vpath, dst.lstrip(\"/\")):\n            return False\n\n        return True\n\n    def _applesan(self) -> bool:\n        if self.args.dav_mac or \"Darwin/\" not in self.ua:\n            return False\n\n        vp = \"/\" + self.vpath\n        ptn = r\"/\\.(_|DS_Store|Spotlight-|fseventsd|Trashes|AppleDouble)|/__MACOS\"\n        if re.search(ptn, vp):\n            zt = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<D:error xmlns:D=\"DAV:\"><D:lock-token-submitted><D:href>{}</D:href></D:lock-token-submitted></D:error>'\n            zb = zt.format(vp).encode(\"utf-8\", \"replace\")\n            self.reply(zb, 423, \"text/xml; charset=utf-8\")\n            return True\n\n        return False\n\n    def send_chunk(self, txt: str, enc: str, bmax: int) -> str:\n        orig_len = len(txt)\n        buf = txt[:bmax].encode(enc, \"replace\")[:bmax]\n        try:\n            _ = buf.decode(enc)\n        except UnicodeDecodeError as ude:\n            buf = buf[: ude.start]\n\n        txt = txt[len(buf.decode(enc)) :]\n        if txt and len(txt) == orig_len:\n            raise Pebkac(500, \"chunk slicing failed\")\n\n        buf = \"{:x}\\r\\n\".format(len(buf)).encode(enc) + buf\n        self.s.sendall(buf + b\"\\r\\n\")\n        return txt\n\n    def handle_options(self) -> bool:\n        if self.do_log:\n            self.log(\"OPTIONS %s @%s\" % (self.req, self.uname))\n\n        oh = self.out_headers\n        oh[\"Allow\"] = \", \".join(self.conn.hsrv.mallow)\n\n        if not self.args.no_dav:\n            # PROPPATCH, LOCK, UNLOCK, COPY: noop (spec-must)\n            oh[\"Dav\"] = \"1, 2\"\n            oh[\"Ms-Author-Via\"] = \"DAV\"\n\n        # winxp-webdav doesnt know what 204 is\n        self.send_headers(0, 200)\n        return True\n\n    def handle_delete(self) -> bool:\n        self.log(\"DELETE %s @%s\" % (self.req, self.uname))\n        return self.handle_rm([])\n\n    def handle_put(self) -> bool:\n        self.log(\"PUT %s @%s\" % (self.req, self.uname))\n\n        if not self.can_write:\n            t = \"user {} does not have write-access here\"\n            raise Pebkac(403, t.format(self.uname))\n\n        if not self.args.no_dav and self._applesan():\n            return self.headers.get(\"content-length\") == \"0\"\n\n        if self.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            try:\n                self.s.sendall(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            except:\n                raise Pebkac(400, \"client d/c before 100 continue\")\n\n        return self.handle_stash(True)\n\n    def handle_post(self) -> bool:\n        self.log(\"POST %s @%s\" % (self.req, self.uname))\n\n        if self.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            try:\n                self.s.sendall(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            except:\n                raise Pebkac(400, \"client d/c before 100 continue\")\n\n        if \"raw\" in self.uparam:\n            return self.handle_stash(False)\n\n        ctype = self.headers.get(\"content-type\", \"\").lower()\n\n        if \"multipart/form-data\" in ctype:\n            return self.handle_post_multipart()\n\n        if (\n            \"application/json\" in ctype\n            or \"text/plain\" in ctype\n            or \"application/xml\" in ctype\n        ):\n            return self.handle_post_json()\n\n        if \"move\" in self.uparam:\n            return self.handle_mv()\n\n        if \"delete\" in self.uparam:\n            return self.handle_rm([])\n\n        if \"application/octet-stream\" in ctype:\n            return self.handle_post_binary()\n\n        if \"application/x-www-form-urlencoded\" in ctype:\n            opt = self.args.urlform\n            if \"stash\" in opt:\n                return self.handle_stash(False)\n\n            if \"save\" in opt:\n                post_sz, _, _, _, path, _ = self.dump_to_file(False)\n                self.log(\"urlform: {} bytes, {}\".format(post_sz, path))\n            elif \"print\" in opt:\n                reader, _ = self.get_body_reader()\n                buf = b\"\"\n                for rbuf in reader:\n                    buf += rbuf\n                    if not rbuf or len(buf) >= 32768:\n                        break\n\n                if buf:\n                    orig = buf.decode(\"utf-8\", \"replace\")\n                    t = \"urlform_raw {} @ {}\\n  {}\\n\"\n                    self.log(t.format(len(orig), self.vpath, orig))\n                    try:\n                        zb = unquote(buf.replace(b\"+\", b\" \"))\n                        plain = zb.decode(\"utf-8\", \"replace\")\n                        if buf.startswith(b\"msg=\"):\n                            plain = plain[4:]\n                            xm = self.vn.flags.get(\"xm\")\n                            if xm:\n                                runhook(\n                                    self.log,\n                                    xm,\n                                    self.vn.canonical(self.rem),\n                                    self.vpath,\n                                    self.host,\n                                    self.uname,\n                                    time.time(),\n                                    len(buf),\n                                    self.ip,\n                                    time.time(),\n                                    plain,\n                                )\n\n                        t = \"urlform_dec {} @ {}\\n  {}\\n\"\n                        self.log(t.format(len(plain), self.vpath, plain))\n\n                    except Exception as ex:\n                        self.log(repr(ex))\n\n            if \"get\" in opt:\n                return self.handle_get()\n\n            raise Pebkac(405, \"POST({}) is disabled in server config\".format(ctype))\n\n        raise Pebkac(405, \"don't know how to handle POST({})\".format(ctype))\n\n    def get_xml_enc(self, txt: str) -> str:\n        ofs = txt[:512].find(' encoding=\"')\n        enc = \"\"\n        if ofs + 1:\n            enc = txt[ofs + 6 :].split('\"')[1]\n        else:\n            enc = self.headers.get(\"content-type\", \"\").lower()\n            ofs = enc.find(\"charset=\")\n            if ofs + 1:\n                enc = enc[ofs + 4].split(\"=\")[1].split(\";\")[0].strip(\"\\\"'\")\n            else:\n                enc = \"\"\n\n        return enc or \"utf-8\"\n\n    def get_body_reader(self) -> tuple[Generator[bytes, None, None], int]:\n        if \"chunked\" in self.headers.get(\"transfer-encoding\", \"\").lower():\n            return read_socket_chunked(self.sr), -1\n\n        remains = int(self.headers.get(\"content-length\", -1))\n        if remains == -1:\n            self.keepalive = False\n            return read_socket_unbounded(self.sr), remains\n        else:\n            return read_socket(self.sr, remains), remains\n\n    def dump_to_file(self, is_put: bool) -> tuple[int, str, str, int, str, str]:\n        # post_sz, sha_hex, sha_b64, remains, path, url\n        reader, remains = self.get_body_reader()\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        rnd, _, lifetime, xbu, xau = self.upload_flags(vfs)\n        lim = vfs.get_dbv(rem)[0].lim\n        fdir = vfs.canonical(rem)\n        if lim:\n            fdir, rem = lim.all(\n                self.ip, rem, remains, vfs.realpath, fdir, self.conn.hsrv.broker\n            )\n\n        fn = None\n        if rem and not self.trailing_slash and not bos.path.isdir(fdir):\n            fdir, fn = os.path.split(fdir)\n            rem, _ = vsplit(rem)\n\n        bos.makedirs(fdir)\n\n        open_ka: dict[str, Any] = {\"fun\": open}\n        open_a = [\"wb\", 512 * 1024]\n\n        # user-request || config-force\n        if (\"gz\" in vfs.flags or \"xz\" in vfs.flags) and (\n            \"pk\" in vfs.flags\n            or \"pk\" in self.uparam\n            or \"gz\" in self.uparam\n            or \"xz\" in self.uparam\n        ):\n            fb = {\"gz\": 9, \"xz\": 0}  # default/fallback level\n            lv = {}  # selected level\n            alg = \"\"  # selected algo (gz=preferred)\n\n            # user-prefs first\n            if \"gz\" in self.uparam or \"pk\" in self.uparam:  # def.pk\n                alg = \"gz\"\n            if \"xz\" in self.uparam:\n                alg = \"xz\"\n            if alg:\n                zso = self.uparam.get(alg)\n                lv[alg] = fb[alg] if zso is None else int(zso)\n\n            if alg not in vfs.flags:\n                alg = \"gz\" if \"gz\" in vfs.flags else \"xz\"\n\n            # then server overrides\n            pk = vfs.flags.get(\"pk\")\n            if pk is not None:\n                # config-forced on\n                alg = alg or \"gz\"  # def.pk\n                try:\n                    # config-forced opts\n                    alg, nlv = pk.split(\",\")\n                    lv[alg] = int(nlv)\n                except:\n                    pass\n\n            lv[alg] = lv.get(alg) or fb.get(alg) or 0\n\n            self.log(\"compressing with {} level {}\".format(alg, lv.get(alg)))\n            if alg == \"gz\":\n                open_ka[\"fun\"] = gzip.GzipFile\n                open_a = [\"wb\", lv[alg], None, 0x5FEE6600]  # 2021-01-01\n            elif alg == \"xz\":\n                open_ka = {\"fun\": lzma.open, \"preset\": lv[alg]}\n                open_a = [\"wb\"]\n            else:\n                self.log(\"fallthrough? thats a bug\", 1)\n\n        suffix = \"-{:.6f}-{}\".format(time.time(), self.dip())\n        nameless = not fn\n        if nameless:\n            suffix += \".bin\"\n            fn = \"put\" + suffix\n\n        params = {\"suffix\": suffix, \"fdir\": fdir}\n        if self.args.nw:\n            params = {}\n            fn = os.devnull\n\n        params.update(open_ka)\n        assert fn\n\n        if not self.args.nw:\n            if rnd:\n                fn = rand_name(fdir, fn, rnd)\n\n            fn = sanitize_fn(fn or \"\", \"\", [\".prologue.html\", \".epilogue.html\"])\n\n        path = os.path.join(fdir, fn)\n\n        if xbu:\n            at = time.time() - lifetime\n            if not runhook(\n                self.log,\n                xbu,\n                path,\n                self.vpath,\n                self.host,\n                self.uname,\n                at,\n                remains,\n                self.ip,\n                at,\n                \"\",\n            ):\n                t = \"upload blocked by xbu server config\"\n                self.log(t, 1)\n                raise Pebkac(403, t)\n\n        if is_put and not (self.args.no_dav or self.args.nw) and bos.path.exists(path):\n            # allow overwrite if...\n            #  * volflag 'daw' is set, or client is definitely webdav\n            #  * and account has delete-access\n            # or...\n            #  * file exists, is empty, sufficiently new\n            #  * and there is no .PARTIAL\n\n            tnam = fn + \".PARTIAL\"\n            if self.args.dotpart:\n                tnam = \".\" + tnam\n\n            if (\n                self.can_delete\n                and (vfs.flags.get(\"daw\") or \"x-oc-mtime\" in self.headers)\n            ) or (\n                not bos.path.exists(os.path.join(fdir, tnam))\n                and not bos.path.getsize(path)\n                and bos.path.getmtime(path) >= time.time() - self.args.blank_wt\n            ):\n                # small toctou, but better than clobbering a hardlink\n                bos.unlink(path)\n\n        with ren_open(fn, *open_a, **params) as zfw:\n            f, fn = zfw[\"orz\"]\n            path = os.path.join(fdir, fn)\n            post_sz, sha_hex, sha_b64 = hashcopy(reader, f, self.args.s_wr_slp)\n\n        if lim:\n            lim.nup(self.ip)\n            lim.bup(self.ip, post_sz)\n            try:\n                lim.chk_sz(post_sz)\n                lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, post_sz)\n            except:\n                bos.unlink(path)\n                raise\n\n        if self.args.nw:\n            return post_sz, sha_hex, sha_b64, remains, path, \"\"\n\n        at = mt = time.time() - lifetime\n        cli_mt = self.headers.get(\"x-oc-mtime\")\n        if cli_mt:\n            try:\n                mt = int(cli_mt)\n                times = (int(time.time()), mt)\n                bos.utime(path, times, False)\n            except:\n                pass\n\n        if nameless and \"magic\" in vfs.flags:\n            try:\n                ext = self.conn.hsrv.magician.ext(path)\n            except Exception as ex:\n                self.log(\"filetype detection failed for [{}]: {}\".format(path, ex), 6)\n                ext = None\n\n            if ext:\n                if rnd:\n                    fn2 = rand_name(fdir, \"a.\" + ext, rnd)\n                else:\n                    fn2 = fn.rsplit(\".\", 1)[0] + \".\" + ext\n\n                params[\"suffix\"] = suffix[:-4]\n                with ren_open(fn, *open_a, **params) as zfw:\n                    f, fn = zfw[\"orz\"]\n\n                path2 = os.path.join(fdir, fn2)\n                atomic_move(path, path2)\n                fn = fn2\n                path = path2\n\n        if xau and not runhook(\n            self.log,\n            xau,\n            path,\n            self.vpath,\n            self.host,\n            self.uname,\n            mt,\n            post_sz,\n            self.ip,\n            at,\n            \"\",\n        ):\n            t = \"upload blocked by xau server config\"\n            self.log(t, 1)\n            os.unlink(path)\n            raise Pebkac(403, t)\n\n        vfs, rem = vfs.get_dbv(rem)\n        self.conn.hsrv.broker.say(\n            \"up2k.hash_file\",\n            vfs.realpath,\n            vfs.vpath,\n            vfs.flags,\n            rem,\n            fn,\n            self.ip,\n            at,\n            self.uname,\n            True,\n        )\n\n        vsuf = \"\"\n        if (self.can_read or self.can_upget) and \"fk\" in vfs.flags:\n            vsuf = \"?k=\" + self.gen_fk(\n                self.args.fk_salt,\n                path,\n                post_sz,\n                0 if ANYWIN else bos.stat(path).st_ino,\n            )[: vfs.flags[\"fk\"]]\n\n        vpath = \"/\".join([x for x in [vfs.vpath, rem, fn] if x])\n        vpath = quotep(vpath)\n\n        url = \"{}://{}/{}\".format(\n            \"https\" if self.is_https else \"http\",\n            self.host,\n            self.args.RS + vpath + vsuf,\n        )\n\n        return post_sz, sha_hex, sha_b64, remains, path, url\n\n    def handle_stash(self, is_put: bool) -> bool:\n        post_sz, sha_hex, sha_b64, remains, path, url = self.dump_to_file(is_put)\n        spd = self._spd(post_sz)\n        t = \"{} wrote {}/{} bytes to {}  # {}\"\n        self.log(t.format(spd, post_sz, remains, path, sha_b64[:28]))  # 21\n\n        ac = self.uparam.get(\n            \"want\", self.headers.get(\"accept\", \"\").lower().split(\";\")[-1]\n        )\n        if ac == \"url\":\n            t = url\n        else:\n            t = \"{}\\n{}\\n{}\\n{}\\n\".format(post_sz, sha_b64, sha_hex[:56], url)\n\n        h = {\"Location\": url} if is_put and url else {}\n\n        if \"x-oc-mtime\" in self.headers:\n            h[\"X-OC-MTime\"] = \"accepted\"\n            t = \"\"  # some webdav clients expect/prefer this\n\n        self.reply(t.encode(\"utf-8\"), 201, headers=h)\n        return True\n\n    def bakflip(self, f: typing.BinaryIO, ofs: int, sz: int, sha: str) -> None:\n        if not self.args.bak_flips or self.args.nw:\n            return\n\n        sdir = self.args.bf_dir\n        fp = os.path.join(sdir, sha)\n        if bos.path.exists(fp):\n            return self.log(\"no bakflip; have it\", 6)\n\n        if not bos.path.isdir(sdir):\n            bos.makedirs(sdir)\n\n        if len(bos.listdir(sdir)) >= self.args.bf_nc:\n            return self.log(\"no bakflip; too many\", 3)\n\n        nrem = sz\n        f.seek(ofs)\n        with open(fp, \"wb\") as fo:\n            while nrem:\n                buf = f.read(min(nrem, 512 * 1024))\n                if not buf:\n                    break\n\n                nrem -= len(buf)\n                fo.write(buf)\n\n        if nrem:\n            self.log(\"bakflip truncated; {} remains\".format(nrem), 1)\n            atomic_move(fp, fp + \".trunc\")\n        else:\n            self.log(\"bakflip ok\", 2)\n\n    def _spd(self, nbytes: int, add: bool = True) -> str:\n        if add:\n            self.conn.nbyte += nbytes\n\n        spd1 = get_spd(nbytes, self.t0)\n        spd2 = get_spd(self.conn.nbyte, self.conn.t0)\n        return \"%s %s n%s\" % (spd1, spd2, self.conn.nreq)\n\n    def handle_post_multipart(self) -> bool:\n        self.parser = MultipartParser(self.log, self.sr, self.headers)\n        self.parser.parse()\n\n        act = self.parser.require(\"act\", 64)\n\n        if act == \"login\":\n            return self.handle_login()\n\n        if act == \"mkdir\":\n            return self.handle_mkdir()\n\n        if act == \"new_md\":\n            # kinda silly but has the least side effects\n            return self.handle_new_md()\n\n        if act == \"bput\":\n            return self.handle_plain_upload()\n\n        if act == \"tput\":\n            return self.handle_text_upload()\n\n        if act == \"zip\":\n            return self.handle_zip_post()\n\n        raise Pebkac(422, 'invalid action \"{}\"'.format(act))\n\n    def handle_zip_post(self) -> bool:\n        assert self.parser\n        try:\n            k = next(x for x in self.uparam if x in (\"zip\", \"tar\"))\n        except:\n            raise Pebkac(422, \"need zip or tar keyword\")\n\n        v = self.uparam[k]\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, True, False)\n        zs = self.parser.require(\"files\", 1024 * 1024)\n        if not zs:\n            raise Pebkac(422, \"need files list\")\n\n        items = zs.replace(\"\\r\", \"\").split(\"\\n\")\n        items = [unquotep(x) for x in items if items]\n\n        self.parser.drop()\n        return self.tx_zip(k, v, \"\", vn, rem, items, self.args.ed)\n\n    def handle_post_json(self) -> bool:\n        try:\n            remains = int(self.headers[\"content-length\"])\n        except:\n            raise Pebkac(411)\n\n        if remains > 1024 * 1024:\n            raise Pebkac(413, \"json 2big\")\n\n        enc = \"utf-8\"\n        ctype = self.headers.get(\"content-type\", \"\").lower()\n        if \"charset\" in ctype:\n            enc = ctype.split(\"charset\")[1].strip(\" =\").split(\";\")[0].strip()\n\n        try:\n            json_buf = self.sr.recv_ex(remains)\n        except UnrecvEOF:\n            raise Pebkac(422, \"client disconnected while posting JSON\")\n\n        self.log(\"decoding {} bytes of {} json\".format(len(json_buf), enc))\n        try:\n            body = json.loads(json_buf.decode(enc, \"replace\"))\n        except:\n            raise Pebkac(422, \"you POSTed invalid json\")\n\n        # self.reply(b\"cloudflare\", 503)\n        # return True\n\n        if \"srch\" in self.uparam or \"srch\" in body:\n            return self.handle_search(body)\n\n        if \"delete\" in self.uparam:\n            return self.handle_rm(body)\n\n        name = undot(body[\"name\"])\n        if \"/\" in name:\n            raise Pebkac(400, \"your client is old; press CTRL-SHIFT-R and try again\")\n\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        dbv, vrem = vfs.get_dbv(rem)\n\n        body[\"vtop\"] = dbv.vpath\n        body[\"ptop\"] = dbv.realpath\n        body[\"prel\"] = vrem\n        body[\"host\"] = self.host\n        body[\"user\"] = self.uname\n        body[\"addr\"] = self.ip\n        body[\"vcfg\"] = dbv.flags\n\n        if not self.can_delete:\n            body.pop(\"replace\", None)\n\n        if rem:\n            dst = vfs.canonical(rem)\n            try:\n                if not bos.path.isdir(dst):\n                    bos.makedirs(dst)\n            except OSError as ex:\n                self.log(\"makedirs failed [{}]\".format(dst))\n                if not bos.path.isdir(dst):\n                    if ex.errno == errno.EACCES:\n                        raise Pebkac(500, \"the server OS denied write-access\")\n\n                    if ex.errno == errno.EEXIST:\n                        raise Pebkac(400, \"some file got your folder name\")\n\n                    raise Pebkac(500, min_ex())\n            except:\n                raise Pebkac(500, min_ex())\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_json\", body, self.u2fh.aps)\n        ret = x.get()\n        if self.is_vproxied:\n            if \"purl\" in ret:\n                ret[\"purl\"] = self.args.SR + ret[\"purl\"]\n\n        ret = json.dumps(ret)\n        self.log(ret)\n        self.reply(ret.encode(\"utf-8\"), mime=\"application/json\")\n        return True\n\n    def handle_search(self, body: dict[str, Any]) -> bool:\n        idx = self.conn.get_u2idx()\n        if not idx or not hasattr(idx, \"p_end\"):\n            raise Pebkac(500, \"sqlite3 is not available on the server; cannot search\")\n\n        vols = []\n        seen = {}\n        for vtop in self.rvol:\n            vfs, _ = self.asrv.vfs.get(vtop, self.uname, True, False)\n            vfs = vfs.dbv or vfs\n            if vfs in seen:\n                continue\n\n            seen[vfs] = True\n            vols.append((vfs.vpath, vfs.realpath, vfs.flags))\n\n        t0 = time.time()\n        if idx.p_end:\n            penalty = 0.7\n            t_idle = t0 - idx.p_end\n            if idx.p_dur > 0.7 and t_idle < penalty:\n                t = \"rate-limit {:.1f} sec, cost {:.2f}, idle {:.2f}\"\n                raise Pebkac(429, t.format(penalty, idx.p_dur, t_idle))\n\n        if \"srch\" in body:\n            # search by up2k hashlist\n            vbody = copy.deepcopy(body)\n            vbody[\"hash\"] = len(vbody[\"hash\"])\n            self.log(\"qj: \" + repr(vbody))\n            hits = idx.fsearch(vols, body)\n            msg: Any = repr(hits)\n            taglist: list[str] = []\n            trunc = False\n        else:\n            # search by query params\n            q = body[\"q\"]\n            n = body.get(\"n\", self.args.srch_hits)\n            self.log(\"qj: {} |{}|\".format(q, n))\n            hits, taglist, trunc = idx.search(vols, q, n)\n            msg = len(hits)\n\n        idx.p_end = time.time()\n        idx.p_dur = idx.p_end - t0\n        self.log(\"q#: {} ({:.2f}s)\".format(msg, idx.p_dur))\n\n        order = []\n        cfg = self.args.mte.split(\",\")\n        for t in cfg:\n            if t in taglist:\n                order.append(t)\n        for t in taglist:\n            if t not in order:\n                order.append(t)\n\n        if self.is_vproxied:\n            for hit in hits:\n                hit[\"rp\"] = self.args.RS + hit[\"rp\"]\n\n        rj = {\"hits\": hits, \"tag_order\": order, \"trunc\": trunc}\n        r = json.dumps(rj).encode(\"utf-8\")\n        self.reply(r, mime=\"application/json\")\n        return True\n\n    def handle_post_binary(self) -> bool:\n        try:\n            remains = int(self.headers[\"content-length\"])\n        except:\n            raise Pebkac(400, \"you must supply a content-length for binary POST\")\n\n        try:\n            chash = self.headers[\"x-up2k-hash\"]\n            wark = self.headers[\"x-up2k-wark\"]\n        except KeyError:\n            raise Pebkac(400, \"need hash and wark headers for binary POST\")\n\n        vfs, _ = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        ptop = (vfs.dbv or vfs).realpath\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_chunk\", ptop, wark, chash)\n        response = x.get()\n        chunksize, cstart, path, lastmod, sprs = response\n\n        try:\n            if self.args.nw:\n                path = os.devnull\n\n            if remains > chunksize:\n                raise Pebkac(400, \"your chunk is too big to fit\")\n\n            self.log(\"writing {} #{} @{} len {}\".format(path, chash, cstart, remains))\n\n            reader = read_socket(self.sr, remains)\n\n            f = None\n            fpool = not self.args.no_fpool and sprs\n            if fpool:\n                with self.mutex:\n                    try:\n                        f = self.u2fh.pop(path)\n                    except:\n                        pass\n\n            f = f or open(fsenc(path), \"rb+\", 512 * 1024)\n\n            try:\n                f.seek(cstart[0])\n                post_sz, _, sha_b64 = hashcopy(reader, f, self.args.s_wr_slp)\n\n                if sha_b64 != chash:\n                    try:\n                        self.bakflip(f, cstart[0], post_sz, sha_b64)\n                    except:\n                        self.log(\"bakflip failed: \" + min_ex())\n\n                    t = \"your chunk got corrupted somehow (received {} bytes); expected vs received hash:\\n{}\\n{}\"\n                    raise Pebkac(400, t.format(post_sz, chash, sha_b64))\n\n                if len(cstart) > 1 and path != os.devnull:\n                    self.log(\n                        \"clone {} to {}\".format(\n                            cstart[0], \" & \".join(unicode(x) for x in cstart[1:])\n                        )\n                    )\n                    ofs = 0\n                    while ofs < chunksize:\n                        bufsz = min(chunksize - ofs, 4 * 1024 * 1024)\n                        f.seek(cstart[0] + ofs)\n                        buf = f.read(bufsz)\n                        for wofs in cstart[1:]:\n                            f.seek(wofs + ofs)\n                            f.write(buf)\n\n                        ofs += len(buf)\n\n                    self.log(\"clone {} done\".format(cstart[0]))\n\n                if not fpool:\n                    f.close()\n                else:\n                    with self.mutex:\n                        self.u2fh.put(path, f)\n            except:\n                # maybe busted handle (eg. disk went full)\n                f.close()\n                raise\n        finally:\n            x = self.conn.hsrv.broker.ask(\"up2k.release_chunk\", ptop, wark, chash)\n            x.get()  # block client until released\n\n        x = self.conn.hsrv.broker.ask(\"up2k.confirm_chunk\", ptop, wark, chash)\n        ztis = x.get()\n        try:\n            num_left, fin_path = ztis\n        except:\n            self.loud_reply(ztis, status=500)\n            return False\n\n        if not num_left and fpool:\n            with self.mutex:\n                self.u2fh.close(path)\n\n        if not num_left and not self.args.nw:\n            self.conn.hsrv.broker.ask(\n                \"up2k.finish_upload\", ptop, wark, self.u2fh.aps\n            ).get()\n\n        cinf = self.headers.get(\"x-up2k-stat\", \"\")\n\n        spd = self._spd(post_sz)\n        self.log(\"{:70} thank {}\".format(spd, cinf))\n        self.reply(b\"thank\")\n        return True\n\n    def handle_login(self) -> bool:\n        assert self.parser\n        pwd = self.parser.require(\"cppwd\", 64)\n        self.parser.drop()\n\n        self.out_headerlist = [\n            x for x in self.out_headerlist if x[0] != \"Set-Cookie\" or \"cppw\" != x[1][:4]\n        ]\n\n        dst = self.args.SRS\n        if self.vpath:\n            dst += quotep(self.vpath)\n\n        msg = self.get_pwd_cookie(pwd)\n        html = self.j2s(\"msg\", h1=msg, h2='<a href=\"' + dst + '\">ack</a>', redir=dst)\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def get_pwd_cookie(self, pwd: str) -> str:\n        if self.asrv.ah.hash(pwd) in self.asrv.iacct:\n            msg = \"login ok\"\n            dur = int(60 * 60 * self.args.logout)\n        else:\n            self.log(\"invalid password: {}\".format(pwd), 3)\n            g = self.conn.hsrv.gpwd\n            if g.lim:\n                bonk, ip = g.bonk(self.ip, pwd)\n                if bonk:\n                    xban = self.vn.flags.get(\"xban\")\n                    if not xban or not runhook(\n                        self.log,\n                        xban,\n                        self.vn.canonical(self.rem),\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        time.time(),\n                        0,\n                        self.ip,\n                        time.time(),\n                        \"pw\",\n                    ):\n                        self.log(\"client banned: invalid passwords\", 1)\n                        self.conn.hsrv.bans[ip] = bonk\n\n            msg = \"naw dude\"\n            pwd = \"x\"  # nosec\n            dur = None\n\n        if pwd == \"x\":\n            # reset both plaintext and tls\n            # (only affects active tls cookies when tls)\n            for k in (\"cppwd\", \"cppws\") if self.is_https else (\"cppwd\",):\n                ck = gencookie(k, pwd, self.args.R, False, dur)\n                self.out_headerlist.append((\"Set-Cookie\", ck))\n        else:\n            k = \"cppws\" if self.is_https else \"cppwd\"\n            ck = gencookie(k, pwd, self.args.R, self.is_https, dur)\n            self.out_headerlist.append((\"Set-Cookie\", ck))\n\n        return msg\n\n    def handle_mkdir(self) -> bool:\n        assert self.parser\n        new_dir = self.parser.require(\"name\", 512)\n        self.parser.drop()\n\n        sanitized = sanitize_fn(new_dir, \"\", [])\n        return self._mkdir(vjoin(self.vpath, sanitized))\n\n    def _mkdir(self, vpath: str, dav: bool = False) -> bool:\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n        fn = vfs.canonical(rem)\n\n        if not nullwrite:\n            fdir = os.path.dirname(fn)\n\n            if not bos.path.isdir(fdir):\n                raise Pebkac(409, \"parent folder does not exist\")\n\n            if bos.path.isdir(fn):\n                raise Pebkac(405, \"that folder exists already\")\n\n            try:\n                bos.mkdir(fn)\n            except OSError as ex:\n                if ex.errno == errno.EACCES:\n                    raise Pebkac(500, \"the server OS denied write-access\")\n\n                raise Pebkac(500, \"mkdir failed:\\n\" + min_ex())\n            except:\n                raise Pebkac(500, min_ex())\n\n        self.out_headers[\"X-New-Dir\"] = quotep(vpath.split(\"/\")[-1])\n\n        if dav:\n            self.reply(b\"\", 201)\n        else:\n            self.redirect(vpath, status=201)\n\n        return True\n\n    def handle_new_md(self) -> bool:\n        assert self.parser\n        new_file = self.parser.require(\"name\", 512)\n        self.parser.drop()\n\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n\n        if not new_file.endswith(\".md\"):\n            new_file += \".md\"\n\n        sanitized = sanitize_fn(new_file, \"\", [])\n\n        if not nullwrite:\n            fdir = vfs.canonical(rem)\n            fn = os.path.join(fdir, sanitized)\n\n            if bos.path.exists(fn):\n                raise Pebkac(500, \"that file exists already\")\n\n            with open(fsenc(fn), \"wb\") as f:\n                f.write(b\"`GRUNNUR`\\n\")\n\n        vpath = \"{}/{}\".format(self.vpath, sanitized).lstrip(\"/\")\n        self.redirect(vpath, \"?edit\")\n        return True\n\n    def upload_flags(self, vfs: VFS) -> tuple[int, bool, int, list[str], list[str]]:\n        if self.args.nw:\n            rnd = 0\n        else:\n            rnd = int(self.uparam.get(\"rand\") or self.headers.get(\"rand\") or 0)\n            if vfs.flags.get(\"rand\"):  # force-enable\n                rnd = max(rnd, vfs.flags[\"nrand\"])\n\n        ac = self.uparam.get(\n            \"want\", self.headers.get(\"accept\", \"\").lower().split(\";\")[-1]\n        )\n        want_url = ac == \"url\"\n        zs = self.uparam.get(\"life\", self.headers.get(\"life\", \"\"))\n        if zs:\n            vlife = vfs.flags.get(\"lifetime\") or 0\n            lifetime = max(0, int(vlife - int(zs)))\n        else:\n            lifetime = 0\n\n        return (\n            rnd,\n            want_url,\n            lifetime,\n            vfs.flags.get(\"xbu\") or [],\n            vfs.flags.get(\"xau\") or [],\n        )\n\n    def handle_plain_upload(self) -> bool:\n        assert self.parser\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n\n        upload_vpath = self.vpath\n        lim = vfs.get_dbv(rem)[0].lim\n        fdir_base = vfs.canonical(rem)\n        if lim:\n            fdir_base, rem = lim.all(\n                self.ip, rem, -1, vfs.realpath, fdir_base, self.conn.hsrv.broker\n            )\n            upload_vpath = \"{}/{}\".format(vfs.vpath, rem).strip(\"/\")\n            if not nullwrite:\n                bos.makedirs(fdir_base)\n\n        rnd, want_url, lifetime, xbu, xau = self.upload_flags(vfs)\n\n        files: list[tuple[int, str, str, str, str, str]] = []\n        # sz, sha_hex, sha_b64, p_file, fname, abspath\n        errmsg = \"\"\n        dip = self.dip()\n        t0 = time.time()\n        try:\n            assert self.parser.gen\n            for nfile, (p_field, p_file, p_data) in enumerate(self.parser.gen):\n                if not p_file:\n                    self.log(\"discarding incoming file without filename\")\n                    # fallthrough\n\n                fdir = fdir_base\n                fname = sanitize_fn(\n                    p_file or \"\", \"\", [\".prologue.html\", \".epilogue.html\"]\n                )\n                if p_file and not nullwrite:\n                    if rnd:\n                        fname = rand_name(fdir, fname, rnd)\n\n                    if not bos.path.isdir(fdir):\n                        raise Pebkac(404, \"that folder does not exist\")\n\n                    suffix = \"-{:.6f}-{}\".format(time.time(), dip)\n                    open_args = {\"fdir\": fdir, \"suffix\": suffix}\n\n                    # reserve destination filename\n                    with ren_open(fname, \"wb\", fdir=fdir, suffix=suffix) as zfw:\n                        fname = zfw[\"orz\"][1]\n\n                    tnam = fname + \".PARTIAL\"\n                    if self.args.dotpart:\n                        tnam = \".\" + tnam\n\n                    abspath = os.path.join(fdir, fname)\n                else:\n                    open_args = {}\n                    tnam = fname = os.devnull\n                    fdir = abspath = \"\"\n\n                if xbu:\n                    at = time.time() - lifetime\n                    if not runhook(\n                        self.log,\n                        xbu,\n                        abspath,\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        at,\n                        0,\n                        self.ip,\n                        at,\n                        \"\",\n                    ):\n                        t = \"upload blocked by xbu server config\"\n                        self.log(t, 1)\n                        raise Pebkac(403, t)\n\n                if lim:\n                    lim.chk_bup(self.ip)\n                    lim.chk_nup(self.ip)\n\n                try:\n                    max_sz = 0\n                    if lim:\n                        v1 = lim.smax\n                        v2 = lim.dfv - lim.dfl\n                        max_sz = min(v1, v2) if v1 and v2 else v1 or v2\n\n                    with ren_open(tnam, \"wb\", 512 * 1024, **open_args) as zfw:\n                        f, tnam = zfw[\"orz\"]\n                        tabspath = os.path.join(fdir, tnam)\n                        self.log(\"writing to {}\".format(tabspath))\n                        sz, sha_hex, sha_b64 = hashcopy(\n                            p_data, f, self.args.s_wr_slp, max_sz\n                        )\n                        if sz == 0:\n                            raise Pebkac(400, \"empty files in post\")\n\n                    if lim:\n                        lim.nup(self.ip)\n                        lim.bup(self.ip, sz)\n                        try:\n                            lim.chk_df(tabspath, sz, True)\n                            lim.chk_sz(sz)\n                            lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, sz)\n                            lim.chk_bup(self.ip)\n                            lim.chk_nup(self.ip)\n                        except:\n                            if not nullwrite:\n                                bos.unlink(tabspath)\n                                bos.unlink(abspath)\n                            fname = os.devnull\n                            raise\n\n                    if not nullwrite:\n                        atomic_move(tabspath, abspath)\n\n                    files.append(\n                        (sz, sha_hex, sha_b64, p_file or \"(discarded)\", fname, abspath)\n                    )\n                    at = time.time() - lifetime\n                    if xau and not runhook(\n                        self.log,\n                        xau,\n                        abspath,\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        at,\n                        sz,\n                        self.ip,\n                        at,\n                        \"\",\n                    ):\n                        t = \"upload blocked by xau server config\"\n                        self.log(t, 1)\n                        os.unlink(abspath)\n                        raise Pebkac(403, t)\n\n                    dbv, vrem = vfs.get_dbv(rem)\n                    self.conn.hsrv.broker.say(\n                        \"up2k.hash_file\",\n                        dbv.realpath,\n                        vfs.vpath,\n                        dbv.flags,\n                        vrem,\n                        fname,\n                        self.ip,\n                        at,\n                        self.uname,\n                        True,\n                    )\n                    self.conn.nbyte += sz\n\n                except Pebkac:\n                    self.parser.drop()\n                    raise\n\n        except Pebkac as ex:\n            errmsg = vol_san(\n                list(self.asrv.vfs.all_vols.values()), unicode(ex).encode(\"utf-8\")\n            ).decode(\"utf-8\")\n\n        td = max(0.1, time.time() - t0)\n        sz_total = sum(x[0] for x in files)\n        spd = (sz_total / td) / (1024 * 1024)\n\n        status = \"OK\"\n        if errmsg:\n            self.log(errmsg, 3)\n            status = \"ERROR\"\n\n        msg = \"{} // {} bytes // {:.3f} MiB/s\\n\".format(status, sz_total, spd)\n        jmsg: dict[str, Any] = {\n            \"status\": status,\n            \"sz\": sz_total,\n            \"mbps\": round(spd, 3),\n            \"files\": [],\n        }\n\n        if errmsg:\n            msg += errmsg + \"\\n\"\n            jmsg[\"error\"] = errmsg\n            errmsg = \"ERROR: \" + errmsg\n\n        for sz, sha_hex, sha_b64, ofn, lfn, ap in files:\n            vsuf = \"\"\n            if (self.can_read or self.can_upget) and \"fk\" in vfs.flags:\n                vsuf = \"?k=\" + self.gen_fk(\n                    self.args.fk_salt,\n                    ap,\n                    sz,\n                    0 if ANYWIN or not ap else bos.stat(ap).st_ino,\n                )[: vfs.flags[\"fk\"]]\n\n            vpath = \"{}/{}\".format(upload_vpath, lfn).strip(\"/\")\n            rel_url = quotep(self.args.RS + vpath) + vsuf\n            msg += 'sha512: {} // {} // {} bytes // <a href=\"/{}\">{}</a> {}\\n'.format(\n                sha_hex[:56],\n                sha_b64,\n                sz,\n                rel_url,\n                html_escape(ofn, crlf=True),\n                vsuf,\n            )\n            # truncated SHA-512 prevents length extension attacks;\n            # using SHA-512/224, optionally SHA-512/256 = :64\n            jpart = {\n                \"url\": \"{}://{}/{}\".format(\n                    \"https\" if self.is_https else \"http\",\n                    self.host,\n                    rel_url,\n                ),\n                \"sha512\": sha_hex[:56],\n                \"sha_b64\": sha_b64,\n                \"sz\": sz,\n                \"fn\": lfn,\n                \"fn_orig\": ofn,\n                \"path\": rel_url,\n            }\n            jmsg[\"files\"].append(jpart)\n\n        vspd = self._spd(sz_total, False)\n        self.log(\"{} {}\".format(vspd, msg))\n\n        suf = \"\"\n        if not nullwrite and self.args.write_uplog:\n            try:\n                log_fn = \"up.{:.6f}.txt\".format(t0)\n                with open(log_fn, \"wb\") as f:\n                    ft = \"{}:{}\".format(self.ip, self.addr[1])\n                    ft = \"{}\\n{}\\n{}\\n\".format(ft, msg.rstrip(), errmsg)\n                    f.write(ft.encode(\"utf-8\"))\n            except Exception as ex:\n                suf = \"\\nfailed to write the upload report: {}\".format(ex)\n\n        sc = 400 if errmsg else 201\n        if want_url:\n            msg = \"\\n\".join([x[\"url\"] for x in jmsg[\"files\"]])\n            if errmsg:\n                msg += \"\\n\" + errmsg\n\n            self.reply(msg.encode(\"utf-8\", \"replace\"), status=sc)\n        elif \"j\" in self.uparam:\n            jtxt = json.dumps(jmsg, indent=2, sort_keys=True).encode(\"utf-8\", \"replace\")\n            self.reply(jtxt, mime=\"application/json\", status=sc)\n        else:\n            self.redirect(\n                self.vpath,\n                msg=msg + suf,\n                flavor=\"return to\",\n                click=False,\n                status=sc,\n            )\n\n        if errmsg:\n            return False\n\n        self.parser.drop()\n        return True\n\n    def handle_text_upload(self) -> bool:\n        assert self.parser\n        try:\n            cli_lastmod3 = int(self.parser.require(\"lastmod\", 16))\n        except:\n            raise Pebkac(400, \"could not read lastmod from request\")\n\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, True, True)\n        self._assert_safe_rem(rem)\n\n        clen = int(self.headers.get(\"content-length\", -1))\n        if clen == -1:\n            raise Pebkac(411)\n\n        rp, fn = vsplit(rem)\n        fp = vfs.canonical(rp)\n        lim = vfs.get_dbv(rem)[0].lim\n        if lim:\n            fp, rp = lim.all(self.ip, rp, clen, vfs.realpath, fp, self.conn.hsrv.broker)\n            bos.makedirs(fp)\n\n        fp = os.path.join(fp, fn)\n        rem = \"{}/{}\".format(rp, fn).strip(\"/\")\n\n        if not rem.endswith(\".md\"):\n            raise Pebkac(400, \"only markdown pls\")\n\n        if nullwrite:\n            response = json.dumps({\"ok\": True, \"lastmod\": 0})\n            self.log(response)\n            # TODO reply should parser.drop()\n            self.parser.drop()\n            self.reply(response.encode(\"utf-8\"))\n            return True\n\n        srv_lastmod = -1.0\n        srv_lastmod3 = -1\n        try:\n            st = bos.stat(fp)\n            srv_lastmod = st.st_mtime\n            srv_lastmod3 = int(srv_lastmod * 1000)\n        except OSError as ex:\n            if ex.errno != errno.ENOENT:\n                raise\n\n        # if file exists, chekc that timestamp matches the client's\n        if srv_lastmod >= 0:\n            same_lastmod = cli_lastmod3 in [-1, srv_lastmod3]\n            if not same_lastmod:\n                # some filesystems/transports limit precision to 1sec, hopefully floored\n                same_lastmod = (\n                    srv_lastmod == int(cli_lastmod3 / 1000)\n                    and cli_lastmod3 > srv_lastmod3\n                    and cli_lastmod3 - srv_lastmod3 < 1000\n                )\n\n            if not same_lastmod:\n                response = json.dumps(\n                    {\n                        \"ok\": False,\n                        \"lastmod\": srv_lastmod3,\n                        \"now\": int(time.time() * 1000),\n                    }\n                )\n                self.log(\n                    \"{} - {} = {}\".format(\n                        srv_lastmod3, cli_lastmod3, srv_lastmod3 - cli_lastmod3\n                    )\n                )\n                self.log(response)\n                self.parser.drop()\n                self.reply(response.encode(\"utf-8\"))\n                return True\n\n            mdir, mfile = os.path.split(fp)\n            mfile2 = \"{}.{:.3f}.md\".format(mfile[:-3], srv_lastmod)\n            try:\n                dp = os.path.join(mdir, \".hist\")\n                bos.mkdir(dp)\n                hidedir(dp)\n            except:\n                pass\n            bos.rename(fp, os.path.join(mdir, \".hist\", mfile2))\n\n        assert self.parser.gen\n        p_field, _, p_data = next(self.parser.gen)\n        if p_field != \"body\":\n            raise Pebkac(400, \"expected body, got {}\".format(p_field))\n\n        xbu = vfs.flags.get(\"xbu\")\n        if xbu:\n            if not runhook(\n                self.log,\n                xbu,\n                fp,\n                self.vpath,\n                self.host,\n                self.uname,\n                time.time(),\n                0,\n                self.ip,\n                time.time(),\n                \"\",\n            ):\n                t = \"save blocked by xbu server config\"\n                self.log(t, 1)\n                raise Pebkac(403, t)\n\n        if bos.path.exists(fp):\n            bos.unlink(fp)\n\n        with open(fsenc(fp), \"wb\", 512 * 1024) as f:\n            sz, sha512, _ = hashcopy(p_data, f, self.args.s_wr_slp)\n\n        if lim:\n            lim.nup(self.ip)\n            lim.bup(self.ip, sz)\n            try:\n                lim.chk_sz(sz)\n                lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, sz)\n            except:\n                bos.unlink(fp)\n                raise\n\n        new_lastmod = bos.stat(fp).st_mtime\n        new_lastmod3 = int(new_lastmod * 1000)\n        sha512 = sha512[:56]\n\n        xau = vfs.flags.get(\"xau\")\n        if xau and not runhook(\n            self.log,\n            xau,\n            fp,\n            self.vpath,\n            self.host,\n            self.uname,\n            new_lastmod,\n            sz,\n            self.ip,\n            new_lastmod,\n            \"\",\n        ):\n            t = \"save blocked by xau server config\"\n            self.log(t, 1)\n            os.unlink(fp)\n            raise Pebkac(403, t)\n\n        vfs, rem = vfs.get_dbv(rem)\n        self.conn.hsrv.broker.say(\n            \"up2k.hash_file\",\n            vfs.realpath,\n            vfs.vpath,\n            vfs.flags,\n            vsplit(rem)[0],\n            fn,\n            self.ip,\n            new_lastmod,\n            self.uname,\n            True,\n        )\n\n        response = json.dumps(\n            {\"ok\": True, \"lastmod\": new_lastmod3, \"size\": sz, \"sha512\": sha512}\n        )\n        self.log(response)\n        self.parser.drop()\n        self.reply(response.encode(\"utf-8\"))\n        return True\n\n    def _chk_lastmod(self, file_ts: int) -> tuple[str, bool]:\n        file_lastmod = formatdate(file_ts, usegmt=True)\n        cli_lastmod = self.headers.get(\"if-modified-since\")\n        if cli_lastmod:\n            try:\n                # some browser append \"; length=573\"\n                cli_lastmod = cli_lastmod.split(\";\")[0].strip()\n                cli_dt = parsedate(cli_lastmod)\n                assert cli_dt\n                cli_ts = calendar.timegm(cli_dt)\n                return file_lastmod, int(file_ts) > int(cli_ts)\n            except Exception as ex:\n                self.log(\n                    \"lastmod {}\\nremote: [{}]\\n local: [{}]\".format(\n                        repr(ex), cli_lastmod, file_lastmod\n                    )\n                )\n                return file_lastmod, file_lastmod != cli_lastmod\n\n        return file_lastmod, True\n\n    def tx_file(self, req_path: str) -> bool:\n        status = 200\n        logmsg = \"{:4} {} \".format(\"\", self.req)\n        logtail = \"\"\n\n        #\n        # if request is for foo.js, check if we have foo.js.{gz,br}\n\n        file_ts = 0\n        editions: dict[str, tuple[str, int]] = {}\n        for ext in [\"\", \".gz\", \".br\"]:\n            try:\n                fs_path = req_path + ext\n                st = bos.stat(fs_path)\n                if stat.S_ISDIR(st.st_mode):\n                    continue\n\n                if stat.S_ISBLK(st.st_mode):\n                    fd = bos.open(fs_path, os.O_RDONLY)\n                    try:\n                        sz = os.lseek(fd, 0, os.SEEK_END)\n                    finally:\n                        os.close(fd)\n                else:\n                    sz = st.st_size\n\n                file_ts = max(file_ts, int(st.st_mtime))\n                editions[ext or \"plain\"] = (fs_path, sz)\n            except:\n                pass\n            if not self.vpath.startswith(\".cpr/\"):\n                break\n\n        if not editions:\n            return self.tx_404()\n\n        #\n        # if-modified\n\n        file_lastmod, do_send = self._chk_lastmod(file_ts)\n        self.out_headers[\"Last-Modified\"] = file_lastmod\n        if not do_send:\n            status = 304\n\n        #\n        # Accept-Encoding and UA decides which edition to send\n\n        decompress = False\n        supported_editions = [\n            x.strip()\n            for x in self.headers.get(\"accept-encoding\", \"\").lower().split(\",\")\n        ]\n        if \".br\" in editions and \"br\" in supported_editions:\n            is_compressed = True\n            selected_edition = \".br\"\n            fs_path, file_sz = editions[\".br\"]\n            self.out_headers[\"Content-Encoding\"] = \"br\"\n        elif \".gz\" in editions:\n            is_compressed = True\n            selected_edition = \".gz\"\n            fs_path, file_sz = editions[\".gz\"]\n            if \"gzip\" not in supported_editions:\n                decompress = True\n            else:\n                if re.match(r\"MSIE [4-6]\\.\", self.ua) and \" SV1\" not in self.ua:\n                    decompress = True\n\n            if not decompress:\n                self.out_headers[\"Content-Encoding\"] = \"gzip\"\n        else:\n            is_compressed = False\n            selected_edition = \"plain\"\n\n        try:\n            fs_path, file_sz = editions[selected_edition]\n            logmsg += \"{} \".format(selected_edition.lstrip(\".\"))\n        except:\n            # client is old and we only have .br\n            # (could make brotli a dep to fix this but it's not worth)\n            raise Pebkac(404)\n\n        #\n        # partial\n\n        lower = 0\n        upper = file_sz\n        hrange = self.headers.get(\"range\")\n\n        # let's not support 206 with compression\n        # and multirange / multipart is also not-impl (mostly because calculating contentlength is a pain)\n        if do_send and not is_compressed and hrange and file_sz and \",\" not in hrange:\n            try:\n                if not hrange.lower().startswith(\"bytes\"):\n                    raise Exception()\n\n                a, b = hrange.split(\"=\", 1)[1].split(\"-\")\n\n                if a.strip():\n                    lower = int(a.strip())\n                else:\n                    lower = 0\n\n                if b.strip():\n                    upper = int(b.strip()) + 1\n                else:\n                    upper = file_sz\n\n                if upper > file_sz:\n                    upper = file_sz\n\n                if lower < 0 or lower >= upper:\n                    raise Exception()\n\n            except:\n                err = \"invalid range ({}), size={}\".format(hrange, file_sz)\n                self.loud_reply(\n                    err,\n                    status=416,\n                    headers={\"Content-Range\": \"bytes */{}\".format(file_sz)},\n                )\n                return True\n\n            status = 206\n            self.out_headers[\"Content-Range\"] = \"bytes {}-{}/{}\".format(\n                lower, upper - 1, file_sz\n            )\n\n            logtail += \" [\\033[36m{}-{}\\033[0m]\".format(lower, upper)\n\n        use_sendfile = False\n        if decompress:\n            open_func: Any = gzip.open\n            open_args: list[Any] = [fsenc(fs_path), \"rb\"]\n            # Content-Length := original file size\n            upper = gzip_orig_sz(fs_path)\n        else:\n            open_func = open\n            # 512 kB is optimal for huge files, use 64k\n            open_args = [fsenc(fs_path), \"rb\", 64 * 1024]\n            use_sendfile = (\n                not self.tls  #\n                and not self.args.no_sendfile\n                and hasattr(os, \"sendfile\")\n            )\n\n        #\n        # send reply\n\n        if is_compressed:\n            self.out_headers[\"Cache-Control\"] = \"max-age=604869\"\n        else:\n            self.permit_caching()\n\n        if \"txt\" in self.uparam:\n            mime = \"text/plain; charset={}\".format(self.uparam[\"txt\"] or \"utf-8\")\n        elif \"mime\" in self.uparam:\n            mime = str(self.uparam.get(\"mime\"))\n        else:\n            mime = guess_mime(req_path)\n\n        if \"nohtml\" in self.vn.flags and \"html\" in mime:\n            mime = \"text/plain; charset=utf-8\"\n\n        self.out_headers[\"Accept-Ranges\"] = \"bytes\"\n        self.send_headers(length=upper - lower, status=status, mime=mime)\n\n        logmsg += unicode(status) + logtail\n\n        if self.mode == \"HEAD\" or not do_send:\n            if self.do_log:\n                self.log(logmsg)\n\n            return True\n\n        ret = True\n        with open_func(*open_args) as f:\n            sendfun = sendfile_kern if use_sendfile else sendfile_py\n            remains = sendfun(\n                self.log, lower, upper, f, self.s, self.args.s_wr_sz, self.args.s_wr_slp\n            )\n\n        if remains > 0:\n            logmsg += \" \\033[31m\" + unicode(upper - remains) + \"\\033[0m\"\n            self.keepalive = False\n\n        spd = self._spd((upper - lower) - remains)\n        if self.do_log:\n            self.log(\"{},  {}\".format(logmsg, spd))\n\n        return ret\n\n    def tx_zip(\n        self,\n        fmt: str,\n        uarg: str,\n        vpath: str,\n        vn: VFS,\n        rem: str,\n        items: list[str],\n        dots: bool,\n    ) -> bool:\n        if self.args.no_zip:\n            raise Pebkac(400, \"not enabled\")\n\n        logmsg = \"{:4} {} \".format(\"\", self.req)\n        self.keepalive = False\n\n        if fmt == \"tar\":\n            mime = \"application/x-tar\"\n            packer: Type[StreamArc] = StreamTar\n        else:\n            mime = \"application/zip\"\n            packer = StreamZip\n\n        fn = items[0] if items and items[0] else self.vpath\n        if fn:\n            fn = fn.rstrip(\"/\").split(\"/\")[-1]\n        else:\n            fn = self.host.split(\":\")[0]\n\n        safe = (string.ascii_letters + string.digits).replace(\"%\", \"\")\n        afn = \"\".join([x if x in safe.replace('\"', \"\") else \"_\" for x in fn])\n        bascii = unicode(safe).encode(\"utf-8\")\n        zb = fn.encode(\"utf-8\", \"xmlcharrefreplace\")\n        if not PY2:\n            zbl = [\n                chr(x).encode(\"utf-8\")\n                if x in bascii\n                else \"%{:02x}\".format(x).encode(\"ascii\")\n                for x in zb\n            ]\n        else:\n            zbl = [unicode(x) if x in bascii else \"%{:02x}\".format(ord(x)) for x in zb]\n\n        ufn = b\"\".join(zbl).decode(\"ascii\")\n\n        cdis = \"attachment; filename=\\\"{}.{}\\\"; filename*=UTF-8''{}.{}\"\n        cdis = cdis.format(afn, fmt, ufn, fmt)\n        self.log(cdis)\n        self.send_headers(None, mime=mime, headers={\"Content-Disposition\": cdis})\n\n        fgen = vn.zipgen(\n            vpath, rem, set(items), self.uname, dots, False, not self.args.no_scandir\n        )\n        # for f in fgen: print(repr({k: f[k] for k in [\"vp\", \"ap\"]}))\n        bgen = packer(self.log, fgen, utf8=\"utf\" in uarg, pre_crc=\"crc\" in uarg)\n        bsent = 0\n        for buf in bgen.gen():\n            if not buf:\n                break\n\n            try:\n                self.s.sendall(buf)\n                bsent += len(buf)\n            except:\n                logmsg += \" \\033[31m\" + unicode(bsent) + \"\\033[0m\"\n                break\n\n        spd = self._spd(bsent)\n        self.log(\"{},  {}\".format(logmsg, spd))\n        return True\n\n    def tx_ico(self, ext: str, exact: bool = False) -> bool:\n        self.permit_caching()\n        if ext.endswith(\"/\"):\n            ext = \"folder\"\n            exact = True\n\n        bad = re.compile(r\"[](){}/ []|^[0-9_-]*$\")\n        n = ext.split(\".\")[::-1]\n        if not exact:\n            n = n[:-1]\n\n        ext = \"\"\n        for v in n:\n            if len(v) > 7 or bad.search(v):\n                break\n\n            ext = \"{}.{}\".format(v, ext)\n\n        ext = ext.rstrip(\".\") or \"unk\"\n        if len(ext) > 11:\n            ext = \"\u22ef\" + ext[-9:]\n\n        # chrome cannot handle more than ~2000 unique SVGs\n        chrome = \" rv:\" not in self.ua\n        mime, ico = self.ico.get(ext, not exact, chrome)\n\n        lm = formatdate(self.E.t0, usegmt=True)\n        self.reply(ico, mime=mime, headers={\"Last-Modified\": lm})\n        return True\n\n    def tx_md(self, fs_path: str) -> bool:\n        logmsg = \"     %s @%s \" % (self.req, self.uname)\n\n        if not self.can_write:\n            if \"edit\" in self.uparam or \"edit2\" in self.uparam:\n                return self.tx_404(True)\n\n        tpl = \"mde\" if \"edit2\" in self.uparam else \"md\"\n        html_path = os.path.join(self.E.mod, \"web\", \"{}.html\".format(tpl))\n        template = self.j2j(tpl)\n\n        st = bos.stat(fs_path)\n        ts_md = st.st_mtime\n\n        st = bos.stat(html_path)\n        ts_html = st.st_mtime\n\n        sz_md = 0\n        for buf in yieldfile(fs_path):\n            sz_md += len(buf)\n            for c, v in [(b\"&\", 4), (b\"<\", 3), (b\">\", 3)]:\n                sz_md += (len(buf) - len(buf.replace(c, b\"\"))) * v\n\n        file_ts = int(max(ts_md, ts_html, self.E.t0))\n        file_lastmod, do_send = self._chk_lastmod(file_ts)\n        self.out_headers[\"Last-Modified\"] = file_lastmod\n        self.out_headers.update(NO_CACHE)\n        status = 200 if do_send else 304\n\n        arg_base = \"?\"\n        if \"k\" in self.uparam:\n            arg_base = \"?k={}&\".format(self.uparam[\"k\"])\n\n        boundary = \"\\roll\\tide\"\n        targs = {\n            \"r\": self.args.SR if self.is_vproxied else \"\",\n            \"ts\": self.conn.hsrv.cachebuster(),\n            \"svcname\": self.args.doctitle,\n            \"html_head\": self.html_head,\n            \"edit\": \"edit\" in self.uparam,\n            \"title\": html_escape(self.vpath, crlf=True),\n            \"lastmod\": int(ts_md * 1000),\n            \"lang\": self.args.lang,\n            \"favico\": self.args.favico,\n            \"have_emp\": self.args.emp,\n            \"md_chk_rate\": self.args.mcr,\n            \"md\": boundary,\n            \"arg_base\": arg_base,\n        }\n        zs = template.render(**targs).encode(\"utf-8\", \"replace\")\n        html = zs.split(boundary.encode(\"utf-8\"))\n        if len(html) != 2:\n            raise Exception(\"boundary appears in \" + html_path)\n\n        self.send_headers(sz_md + len(html[0]) + len(html[1]), status)\n\n        logmsg += unicode(status)\n        if self.mode == \"HEAD\" or not do_send:\n            if self.do_log:\n                self.log(logmsg)\n\n            return True\n\n        try:\n            self.s.sendall(html[0])\n            for buf in yieldfile(fs_path):\n                self.s.sendall(html_bescape(buf))\n\n            self.s.sendall(html[1])\n\n        except:\n            self.log(logmsg + \" \\033[31md/c\\033[0m\")\n            return False\n\n        if self.do_log:\n            self.log(logmsg + \" \" + unicode(len(html)))\n\n        return True\n\n    def tx_svcs(self) -> bool:\n        aname = re.sub(\"[^0-9a-zA-Z]+\", \"\", self.args.name) or \"a\"\n        ep = self.host\n        host = ep.split(\":\")[0]\n        hport = ep[ep.find(\":\") :] if \":\" in ep else \"\"\n        rip = (\n            host\n            if self.args.rclone_mdns or not self.args.zm\n            else self.conn.hsrv.nm.map(self.ip) or host\n        )\n        # safer than html_escape/quotep since this avoids both XSS and shell-stuff\n        pw = re.sub(r\"[<>&$?`]\", \"_\", self.pw or \"pw\")\n        vp = re.sub(r\"[<>&$?`]\", \"_\", self.uparam[\"hc\"] or \"\").lstrip(\"/\")\n        html = self.j2s(\n            \"svcs\",\n            args=self.args,\n            accs=bool(self.asrv.acct),\n            s=\"s\" if self.is_https else \"\",\n            rip=rip,\n            ep=ep,\n            vp=vp,\n            rvp=vjoin(self.args.R, vp),\n            host=host,\n            hport=hport,\n            aname=aname,\n            pw=pw,\n        )\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def tx_mounts(self) -> bool:\n        suf = self.urlq({}, [\"h\"])\n        rvol, wvol, avol = [\n            [(\"/\" + x).rstrip(\"/\") + \"/\" for x in y]\n            for y in [self.rvol, self.wvol, self.avol]\n        ]\n\n        if self.avol and not self.args.no_rescan:\n            x = self.conn.hsrv.broker.ask(\"up2k.get_state\")\n            vs = json.loads(x.get())\n            vstate = {(\"/\" + k).rstrip(\"/\") + \"/\": v for k, v in vs[\"volstate\"].items()}\n        else:\n            vstate = {}\n            vs = {\n                \"scanning\": None,\n                \"hashq\": None,\n                \"tagq\": None,\n                \"mtpq\": None,\n                \"dbwt\": None,\n            }\n\n        fmt = self.uparam.get(\"ls\", \"\")\n        if not fmt and (self.ua.startswith(\"curl/\") or self.ua.startswith(\"fetch\")):\n            fmt = \"v\"\n\n        if fmt in [\"v\", \"t\", \"txt\"]:\n            if self.uname == \"*\":\n                txt = \"howdy stranger (you're not logged in)\"\n            else:\n                txt = \"welcome back {}\".format(self.uname)\n\n            if vstate:\n                txt += \"\\nstatus:\"\n                for k in [\"scanning\", \"hashq\", \"tagq\", \"mtpq\", \"dbwt\"]:\n                    txt += \" {}({})\".format(k, vs[k])\n\n            if rvol:\n                txt += \"\\nyou can browse:\"\n                for v in rvol:\n                    txt += \"\\n  \" + v\n\n            if wvol:\n                txt += \"\\nyou can upload to:\"\n                for v in wvol:\n                    txt += \"\\n  \" + v\n\n            zb = txt.encode(\"utf-8\", \"replace\") + b\"\\n\"\n            self.reply(zb, mime=\"text/plain; charset=utf-8\")\n            return True\n\n        html = self.j2s(\n            \"splash\",\n            this=self,\n            qvpath=quotep(self.vpath),\n            rvol=rvol,\n            wvol=wvol,\n            avol=avol,\n            vstate=vstate,\n            scanning=vs[\"scanning\"],\n            hashq=vs[\"hashq\"],\n            tagq=vs[\"tagq\"],\n            mtpq=vs[\"mtpq\"],\n            dbwt=vs[\"dbwt\"],\n            url_suf=suf,\n            k304=self.k304(),\n            ver=S_VERSION if self.args.ver else \"\",\n            ahttps=\"\" if self.is_https else \"https://\" + self.host + self.req,\n        )\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def set_k304(self) -> bool:\n        ck = gencookie(\"k304\", self.uparam[\"k304\"], self.args.R, False, 86400 * 299)\n        self.out_headerlist.append((\"Set-Cookie\", ck))\n        self.redirect(\"\", \"?h#cc\")\n        return True\n\n    def setck(self) -> bool:\n        k, v = self.uparam[\"setck\"].split(\"=\", 1)\n        t = None if v == \"\" else 86400 * 299\n        ck = gencookie(k, v, self.args.R, False, t)\n        self.out_headerlist.append((\"Set-Cookie\", ck))\n        self.reply(b\"o7\\n\")\n        return True\n\n    def set_cfg_reset(self) -> bool:\n        for k in (\"k304\", \"js\", \"idxh\", \"cppwd\", \"cppws\"):\n            cookie = gencookie(k, \"x\", self.args.R, False, None)\n            self.out_headerlist.append((\"Set-Cookie\", cookie))\n\n        self.redirect(\"\", \"?h#cc\")\n        return True\n\n    def tx_404(self, is_403: bool = False) -> bool:\n        rc = 404\n        if self.args.vague_403:\n            t = '<h1 id=\"n\">404 not found &nbsp;\u2510( \u00b4 -`)\u250c</h1><p id=\"o\">or maybe you don\\'t have access -- try logging in or <a href=\"{}/?h\">go home</a></p>'\n        elif is_403:\n            t = '<h1 id=\"p\">403 forbiddena &nbsp;~\u253b\u2501\u253b</h1><p id=\"q\">you\\'ll have to log in or <a href=\"{}/?h\">go home</a></p>'\n            rc = 403\n        else:\n            t = '<h1 id=\"n\">404 not found &nbsp;\u2510( \u00b4 -`)\u250c</h1><p><a id=\"r\" href=\"{}/?h\">go home</a></p>'\n\n        t = t.format(self.args.SR)\n        html = self.j2s(\"splash\", this=self, qvpath=quotep(self.vpath), msg=t)\n        self.reply(html.encode(\"utf-8\"), status=rc)\n        return True\n\n    def on40x(self, mods: list[str], vn: VFS, rem: str) -> str:\n        for mpath in mods:\n            try:\n                mod = loadpy(mpath, self.args.hot_handlers)\n            except Exception as ex:\n                self.log(\"import failed: {!r}\".format(ex))\n                continue\n\n            ret = mod.main(self, vn, rem)\n            if ret:\n                return ret.lower()\n\n        return \"\"  # unhandled / fallthrough\n\n    def scanvol(self) -> bool:\n        if not self.can_admin:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_rescan:\n            raise Pebkac(403, \"the rescan feature is disabled in server config\")\n\n        vn, _ = self.asrv.vfs.get(self.vpath, self.uname, True, True)\n\n        args = [self.asrv.vfs.all_vols, [vn.vpath], False, True]\n\n        x = self.conn.hsrv.broker.ask(\"up2k.rescan\", *args)\n        err = x.get()\n        if not err:\n            self.redirect(\"\", \"?h\")\n            return True\n\n        raise Pebkac(500, err)\n\n    def handle_reload(self) -> bool:\n        act = self.uparam.get(\"reload\")\n        if act != \"cfg\":\n            raise Pebkac(400, \"only config files ('cfg') can be reloaded rn\")\n\n        if not self.avol:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_reload:\n            raise Pebkac(403, \"the reload feature is disabled in server config\")\n\n        x = self.conn.hsrv.broker.ask(\"reload\")\n        return self.redirect(\"\", \"?h\", x.get(), \"return to\", False)\n\n    def tx_stack(self) -> bool:\n        if not self.avol and not [x for x in self.wvol if x in self.rvol]:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_stack:\n            raise Pebkac(403, \"the stackdump feature is disabled in server config\")\n\n        ret = \"<pre>{}\\n{}\".format(time.time(), html_escape(alltrace()))\n        self.reply(ret.encode(\"utf-8\"))\n        return True\n\n    def tx_tree(self) -> bool:\n        top = self.uparam[\"tree\"] or \"\"\n        dst = self.vpath\n        if top in [\".\", \"..\"]:\n            top = undot(self.vpath + \"/\" + top)\n\n        if top == dst:\n            dst = \"\"\n        elif top:\n            if not dst.startswith(top + \"/\"):\n                raise Pebkac(400, \"arg funk\")\n\n            dst = dst[len(top) + 1 :]\n\n        ret = self.gen_tree(top, dst)\n        if self.is_vproxied:\n            parents = self.args.R.split(\"/\")\n            for parent in reversed(parents):\n                ret = {\"k%s\" % (parent,): ret, \"a\": []}\n\n        zs = json.dumps(ret)\n        self.reply(zs.encode(\"utf-8\"), mime=\"application/json\")\n        return True\n\n    def gen_tree(self, top: str, target: str) -> dict[str, Any]:\n        ret: dict[str, Any] = {}\n        excl = None\n        if target:\n            excl, target = (target.split(\"/\", 1) + [\"\"])[:2]\n            sub = self.gen_tree(\"/\".join([top, excl]).strip(\"/\"), target)\n            ret[\"k\" + quotep(excl)] = sub\n\n        try:\n            vn, rem = self.asrv.vfs.get(top, self.uname, True, False)\n            fsroot, vfs_ls, vfs_virt = vn.ls(\n                rem,\n                self.uname,\n                not self.args.no_scandir,\n                [[True, False], [False, True]],\n            )\n        except:\n            vfs_ls = []\n            vfs_virt = {}\n            for v in self.rvol:\n                d1, d2 = v.rsplit(\"/\", 1) if \"/\" in v else [\"\", v]\n                if d1 == top:\n                    vfs_virt[d2] = self.asrv.vfs  # typechk, value never read\n\n        dirs = []\n\n        dirnames = [x[0] for x in vfs_ls if stat.S_ISDIR(x[1].st_mode)]\n\n        if not self.args.ed or \"dots\" not in self.uparam:\n            dirnames = exclude_dotfiles(dirnames)\n\n        for fn in [x for x in dirnames if x != excl]:\n            dirs.append(quotep(fn))\n\n        for x in vfs_virt:\n            if x != excl:\n                dirs.append(x)\n\n        ret[\"a\"] = dirs\n        return ret\n\n    def tx_ups(self) -> bool:\n        if not self.args.unpost:\n            raise Pebkac(403, \"the unpost feature is disabled in server config\")\n\n        idx = self.conn.get_u2idx()\n        if not idx or not hasattr(idx, \"p_end\"):\n            raise Pebkac(500, \"sqlite3 is not available on the server; cannot unpost\")\n\n        filt = self.uparam.get(\"filter\")\n        filt = unquotep(filt or \"\")\n        lm = \"ups [{}]\".format(filt)\n        self.log(lm)\n\n        ret: list[dict[str, Any]] = []\n        t0 = time.time()\n        lim = time.time() - self.args.unpost\n        fk_vols = {\n            vol: vol.flags[\"fk\"]\n            for vp, vol in self.asrv.vfs.all_vols.items()\n            if \"fk\" in vol.flags and (vp in self.rvol or vp in self.upvol)\n        }\n        for vol in self.asrv.vfs.all_vols.values():\n            cur = idx.get_cur(vol.realpath)\n            if not cur:\n                continue\n\n            nfk = fk_vols.get(vol, 0)\n\n            q = \"select sz, rd, fn, at from up where ip=? and at>?\"\n            for sz, rd, fn, at in cur.execute(q, (self.ip, lim)):\n                vp = \"/\" + \"/\".join(x for x in [vol.vpath, rd, fn] if x)\n                if filt and filt not in vp:\n                    continue\n\n                rv = {\"vp\": quotep(vp), \"sz\": sz, \"at\": at, \"nfk\": nfk}\n                if nfk:\n                    rv[\"ap\"] = vol.canonical(vjoin(rd, fn))\n\n                ret.append(rv)\n                if len(ret) > 3000:\n                    ret.sort(key=lambda x: x[\"at\"], reverse=True)  # type: ignore\n                    ret = ret[:2000]\n\n        ret.sort(key=lambda x: x[\"at\"], reverse=True)  # type: ignore\n        n = 0\n        for rv in ret[:11000]:\n            nfk = rv.pop(\"nfk\")\n            if not nfk:\n                continue\n\n            ap = rv.pop(\"ap\")\n            try:\n                st = bos.stat(ap)\n            except:\n                continue\n\n            fk = self.gen_fk(\n                self.args.fk_salt, ap, st.st_size, 0 if ANYWIN else st.st_ino\n            )\n            rv[\"vp\"] += \"?k=\" + fk[:nfk]\n\n            n += 1\n            if n > 2000:\n                break\n\n        ret = ret[:2000]\n\n        if self.is_vproxied:\n            for v in ret:\n                v[\"vp\"] = self.args.SR + v[\"vp\"]\n\n        jtxt = json.dumps(ret, indent=2, sort_keys=True).encode(\"utf-8\", \"replace\")\n        self.log(\"{} #{} {:.2f}sec\".format(lm, len(ret), time.time() - t0))\n        self.reply(jtxt, mime=\"application/json\")\n        return True\n\n    def handle_rm(self, req: list[str]) -> bool:\n        if not req and not self.can_delete:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_del:\n            raise Pebkac(403, \"the delete feature is disabled in server config\")\n\n        if not req:\n            req = [self.vpath]\n        elif self.is_vproxied:\n            req = [x[len(self.args.SR) :] for x in req]\n\n        nlim = int(self.uparam.get(\"lim\") or 0)\n        lim = [nlim, nlim] if nlim else []\n\n        x = self.conn.hsrv.broker.ask(\n            \"up2k.handle_rm\", self.uname, self.ip, req, lim, False\n        )\n        self.loud_reply(x.get())\n        return True\n\n    def handle_mv(self) -> bool:\n        # full path of new loc (incl filename)\n        dst = self.uparam.get(\"move\")\n\n        if self.is_vproxied and dst and dst.startswith(self.args.SR):\n            dst = dst[len(self.args.RS) :]\n\n        if not dst:\n            raise Pebkac(400, \"need dst vpath\")\n\n        # x-www-form-urlencoded (url query part) uses\n        # either + or %20 for 0x20 so handle both\n        dst = unquotep(dst.replace(\"+\", \" \"))\n        return self._mv(self.vpath, dst.lstrip(\"/\"))\n\n    def _mv(self, vsrc: str, vdst: str) -> bool:\n        if not self.can_move:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_mv:\n            raise Pebkac(403, \"the rename/move feature is disabled in server config\")\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_mv\", self.uname, vsrc, vdst)\n        self.loud_reply(x.get(), status=201)\n        return True\n\n    def tx_ls(self, ls: dict[str, Any]) -> bool:\n        dirs = ls[\"dirs\"]\n        files = ls[\"files\"]\n        arg = self.uparam[\"ls\"]\n        if arg in [\"v\", \"t\", \"txt\"]:\n            try:\n                biggest = max(ls[\"files\"] + ls[\"dirs\"], key=itemgetter(\"sz\"))[\"sz\"]\n            except:\n                biggest = 0\n\n            if arg == \"v\":\n                fmt = \"\\033[0;7;36m{{}}{{:>{}}}\\033[0m {{}}\"\n                nfmt = \"{}\"\n                biggest = 0\n                f2 = \"\".join(\n                    \"{}{{}}\".format(x)\n                    for x in [\n                        \"\\033[7m\",\n                        \"\\033[27m\",\n                        \"\",\n                        \"\\033[0;1m\",\n                        \"\\033[0;36m\",\n                        \"\\033[0m\",\n                    ]\n                )\n                ctab = {\"B\": 6, \"K\": 5, \"M\": 1, \"G\": 3}\n                for lst in [dirs, files]:\n                    for x in lst:\n                        a = x[\"dt\"].replace(\"-\", \" \").replace(\":\", \" \").split(\" \")\n                        x[\"dt\"] = f2.format(*list(a))\n                        sz = humansize(x[\"sz\"], True)\n                        x[\"sz\"] = \"\\033[0;3{}m {:>5}\".format(ctab.get(sz[-1:], 0), sz)\n            else:\n                fmt = \"{{}}  {{:{},}}  {{}}\"\n                nfmt = \"{:,}\"\n\n            for x in dirs:\n                n = x[\"name\"] + \"/\"\n                if arg == \"v\":\n                    n = \"\\033[94m\" + n\n\n                x[\"name\"] = n\n\n            fmt = fmt.format(len(nfmt.format(biggest)))\n            retl = [\n                \"# {}: {}\".format(x, ls[x])\n                for x in [\"acct\", \"perms\", \"srvinf\"]\n                if x in ls\n            ]\n            retl += [\n                fmt.format(x[\"dt\"], x[\"sz\"], x[\"name\"])\n                for y in [dirs, files]\n                for x in y\n            ]\n            ret = \"\\n\".join(retl)\n            mime = \"text/plain; charset=utf-8\"\n        else:\n            [x.pop(k) for k in [\"name\", \"dt\"] for y in [dirs, files] for x in y]\n\n            ret = json.dumps(ls)\n            mime = \"application/json\"\n\n        ret += \"\\n\\033[0m\" if arg == \"v\" else \"\\n\"\n        self.reply(ret.encode(\"utf-8\", \"replace\"), mime=mime)\n        return True\n\n    def tx_browser(self) -> bool:\n        vpath = \"\"\n        vpnodes = [[\"\", \"/\"]]\n        if self.vpath:\n            for node in self.vpath.split(\"/\"):\n                if not vpath:\n                    vpath = node\n                else:\n                    vpath += \"/\" + node\n\n                vpnodes.append([quotep(vpath) + \"/\", html_escape(node, crlf=True)])\n\n        vn = self.vn\n        rem = self.rem\n        abspath = vn.dcanonical(rem)\n        dbv, vrem = vn.get_dbv(rem)\n\n        try:\n            st = bos.stat(abspath)\n        except:\n            if \"on404\" not in vn.flags:\n                return self.tx_404()\n\n            ret = self.on40x(vn.flags[\"on404\"], vn, rem)\n            if ret == \"true\":\n                return True\n            elif ret == \"false\":\n                return False\n            elif ret == \"retry\":\n                try:\n                    st = bos.stat(abspath)\n                except:\n                    return self.tx_404()\n            else:\n                return self.tx_404()\n\n        if rem.startswith(\".hist/up2k.\") or (\n            rem.endswith(\"/dir.txt\") and rem.startswith(\".hist/th/\")\n        ):\n            raise Pebkac(403)\n\n        e2d = \"e2d\" in vn.flags\n        e2t = \"e2t\" in vn.flags\n\n        self.html_head = vn.flags.get(\"html_head\", \"\")\n        if vn.flags.get(\"norobots\") or \"b\" in self.uparam:\n            self.out_headers[\"X-Robots-Tag\"] = \"noindex, nofollow\"\n        else:\n            self.out_headers.pop(\"X-Robots-Tag\", None)\n\n        is_dir = stat.S_ISDIR(st.st_mode)\n        icur = None\n        if is_dir and (e2t or e2d):\n            idx = self.conn.get_u2idx()\n            if idx and hasattr(idx, \"p_end\"):\n                icur = idx.get_cur(dbv.realpath)\n\n        if self.can_read:\n            th_fmt = self.uparam.get(\"th\")\n            if th_fmt is not None:\n                if is_dir:\n                    vrem = vrem.rstrip(\"/\")\n                    if icur and vrem:\n                        q = \"select fn from cv where rd=? and dn=?\"\n                        crd, cdn = vrem.rsplit(\"/\", 1) if \"/\" in vrem else (\"\", vrem)\n                        # no mojibake support:\n                        try:\n                            cfn = icur.execute(q, (crd, cdn)).fetchone()\n                            if cfn:\n                                fn = cfn[0]\n                                fp = os.path.join(abspath, fn)\n                                if bos.path.exists(fp):\n                                    vrem = \"{}/{}\".format(vrem, fn).strip(\"/\")\n                                    is_dir = False\n                        except:\n                            pass\n                    else:\n                        for fn in self.args.th_covers:\n                            fp = os.path.join(abspath, fn)\n                            if bos.path.exists(fp):\n                                vrem = \"{}/{}\".format(vrem, fn).strip(\"/\")\n                                is_dir = False\n                                break\n\n                    if is_dir:\n                        return self.tx_ico(\"a.folder\")\n\n                thp = None\n                if self.thumbcli:\n                    thp = self.thumbcli.get(dbv, vrem, int(st.st_mtime), th_fmt)\n\n                if thp:\n                    return self.tx_file(thp)\n\n                if th_fmt == \"p\":\n                    raise Pebkac(404)\n\n                return self.tx_ico(rem)\n\n        if not is_dir and (self.can_read or self.can_get):\n            if not self.can_read and \"fk\" in vn.flags:\n                correct = self.gen_fk(\n                    self.args.fk_salt, abspath, st.st_size, 0 if ANYWIN else st.st_ino\n                )[: vn.flags[\"fk\"]]\n                got = self.uparam.get(\"k\")\n                if got != correct:\n                    self.log(\"wrong filekey, want {}, got {}\".format(correct, got))\n                    return self.tx_404()\n\n            if (\n                abspath.endswith(\".md\")\n                and \"nohtml\" not in vn.flags\n                and (\n                    \"v\" in self.uparam\n                    or \"edit\" in self.uparam\n                    or \"edit2\" in self.uparam\n                )\n            ):\n                return self.tx_md(abspath)\n\n            return self.tx_file(abspath)\n\n        elif is_dir and not self.can_read and not self.can_write:\n            return self.tx_404(True)\n\n        srv_info = []\n\n        try:\n            if not self.args.nih:\n                srv_info.append(self.args.name)\n        except:\n            self.log(\"#wow #whoa\")\n\n        if not self.args.nid:\n            free, total = get_df(abspath)\n            if total is not None:\n                h1 = humansize(free or 0)\n                h2 = humansize(total)\n                srv_info.append(\"{} free of {}\".format(h1, h2))\n            elif free is not None:\n                srv_info.append(humansize(free, True) + \" free\")\n\n        srv_infot = \"</span> // <span>\".join(srv_info)\n\n        perms = []\n        if self.can_read:\n            perms.append(\"read\")\n        if self.can_write:\n            perms.append(\"write\")\n        if self.can_move:\n            perms.append(\"move\")\n        if self.can_delete:\n            perms.append(\"delete\")\n        if self.can_get:\n            perms.append(\"get\")\n        if self.can_upget:\n            perms.append(\"upget\")\n        if self.can_admin:\n            perms.append(\"admin\")\n\n        url_suf = self.urlq({}, [\"k\"])\n        is_ls = \"ls\" in self.uparam\n        is_js = self.args.force_js or self.cookies.get(\"js\") == \"y\"\n\n        if not is_ls and (self.ua.startswith(\"curl/\") or self.ua.startswith(\"fetch\")):\n            self.uparam[\"ls\"] = \"v\"\n            is_ls = True\n\n        tpl = \"browser\"\n        if \"b\" in self.uparam:\n            tpl = \"browser2\"\n            is_js = False\n\n        logues = [\"\", \"\"]\n        if not self.args.no_logues:\n            for n, fn in enumerate([\".prologue.html\", \".epilogue.html\"]):\n                fn = os.path.join(abspath, fn)\n                if bos.path.exists(fn):\n                    with open(fsenc(fn), \"rb\") as f:\n                        logues[n] = f.read().decode(\"utf-8\")\n\n        readme = \"\"\n        if not self.args.no_readme and not logues[1]:\n            for fn in [\"README.md\", \"readme.md\"]:\n                fn = os.path.join(abspath, fn)\n                if bos.path.isfile(fn):\n                    with open(fsenc(fn), \"rb\") as f:\n                        readme = f.read().decode(\"utf-8\")\n                        break\n\n        vf = vn.flags\n        unlist = vf.get(\"unlist\", \"\")\n        ls_ret = {\n            \"dirs\": [],\n            \"files\": [],\n            \"taglist\": [],\n            \"srvinf\": srv_infot,\n            \"acct\": self.uname,\n            \"idx\": e2d,\n            \"itag\": e2t,\n            \"lifetime\": vn.flags.get(\"lifetime\") or 0,\n            \"frand\": bool(vn.flags.get(\"rand\")),\n            \"unlist\": unlist,\n            \"perms\": perms,\n            \"logues\": logues,\n            \"readme\": readme,\n        }\n        j2a = {\n            \"vdir\": quotep(self.vpath),\n            \"vpnodes\": vpnodes,\n            \"files\": [],\n            \"ls0\": None,\n            \"acct\": self.uname,\n            \"perms\": json.dumps(perms),\n            \"lifetime\": ls_ret[\"lifetime\"],\n            \"frand\": bool(vn.flags.get(\"rand\")),\n            \"taglist\": [],\n            \"def_hcols\": [],\n            \"have_emp\": self.args.emp,\n            \"have_up2k_idx\": e2d,\n            \"have_tags_idx\": e2t,\n            \"have_acode\": (not self.args.no_acode),\n            \"have_mv\": (not self.args.no_mv),\n            \"have_del\": (not self.args.no_del),\n            \"have_zip\": (not self.args.no_zip),\n            \"have_unpost\": int(self.args.unpost),\n            \"have_b_u\": (self.can_write and self.uparam.get(\"b\") == \"u\"),\n            \"sb_md\": \"\" if \"no_sb_md\" in vf else (vf.get(\"md_sbf\") or \"y\"),\n            \"sb_lg\": \"\" if \"no_sb_lg\" in vf else (vf.get(\"lg_sbf\") or \"y\"),\n            \"url_suf\": url_suf,\n            \"logues\": logues,\n            \"readme\": readme,\n            \"title\": html_escape(self.vpath, crlf=True) or \"\ud83d\udcbe\ud83c\udf89\",\n            \"srv_info\": srv_infot,\n            \"dgrid\": \"grid\" in vf,\n            \"unlist\": unlist,\n            \"dtheme\": self.args.theme,\n            \"themes\": self.args.themes,\n            \"turbolvl\": self.args.turbo,\n            \"idxh\": int(self.args.ih),\n            \"u2sort\": self.args.u2sort,\n        }\n\n        if self.args.js_browser:\n            j2a[\"js\"] = self.args.js_browser\n\n        if self.args.css_browser:\n            j2a[\"css\"] = self.args.css_browser\n\n        if not self.conn.hsrv.prism:\n            j2a[\"no_prism\"] = True\n\n        if not self.can_read:\n            if is_ls:\n                return self.tx_ls(ls_ret)\n\n            if not stat.S_ISDIR(st.st_mode):\n                return self.tx_404(True)\n\n            if \"zip\" in self.uparam or \"tar\" in self.uparam:\n                raise Pebkac(403)\n\n            html = self.j2s(tpl, **j2a)\n            self.reply(html.encode(\"utf-8\", \"replace\"))\n            return True\n\n        for k in [\"zip\", \"tar\"]:\n            v = self.uparam.get(k)\n            if v is not None:\n                return self.tx_zip(k, v, self.vpath, vn, rem, [], self.args.ed)\n\n        fsroot, vfs_ls, vfs_virt = vn.ls(\n            rem,\n            self.uname,\n            not self.args.no_scandir,\n            [[True, False], [False, True]],\n            lstat=\"lt\" in self.uparam,\n        )\n        stats = {k: v for k, v in vfs_ls}\n        ls_names = [x[0] for x in vfs_ls]\n        ls_names.extend(list(vfs_virt.keys()))\n\n        # check for old versions of files,\n        # [num-backups, most-recent, hist-path]\n        hist: dict[str, tuple[int, float, str]] = {}\n        histdir = os.path.join(fsroot, \".hist\")\n        ptn = re.compile(r\"(.*)\\.([0-9]+\\.[0-9]{3})(\\.[^\\.]+)$\")\n        try:\n            for hfn in bos.listdir(histdir):\n                m = ptn.match(hfn)\n                if not m:\n                    continue\n\n                fn = m.group(1) + m.group(3)\n                n, ts, _ = hist.get(fn, (0, 0, \"\"))\n                hist[fn] = (n + 1, max(ts, float(m.group(2))), hfn)\n        except:\n            pass\n\n        # show dotfiles if permitted and requested\n        if not self.args.ed or \"dots\" not in self.uparam:\n            ls_names = exclude_dotfiles(ls_names)\n\n        add_fk = vn.flags.get(\"fk\")\n\n        dirs = []\n        files = []\n        for fn in ls_names:\n            base = \"\"\n            href = fn\n            if not is_ls and not is_js and not self.trailing_slash and vpath:\n                base = \"/\" + vpath + \"/\"\n                href = base + fn\n\n            if fn in vfs_virt:\n                fspath = vfs_virt[fn].realpath\n            else:\n                fspath = fsroot + \"/\" + fn\n\n            try:\n                linf = stats.get(fn) or bos.lstat(fspath)\n                inf = bos.stat(fspath) if stat.S_ISLNK(linf.st_mode) else linf\n            except:\n                self.log(\"broken symlink: {}\".format(repr(fspath)))\n                continue\n\n            is_dir = stat.S_ISDIR(inf.st_mode)\n            if is_dir:\n                href += \"/\"\n                if self.args.no_zip:\n                    margin = \"DIR\"\n                else:\n                    margin = '<a href=\"%s?zip\" rel=\"nofollow\">zip</a>' % (quotep(href),)\n            elif fn in hist:\n                margin = '<a href=\"%s.hist/%s\">#%s</a>' % (\n                    base,\n                    html_escape(hist[fn][2], quot=True, crlf=True),\n                    hist[fn][0],\n                )\n            else:\n                margin = \"-\"\n\n            sz = inf.st_size\n            zd = datetime.utcfromtimestamp(linf.st_mtime)\n            dt = \"%04d-%02d-%02d %02d:%02d:%02d\" % (\n                zd.year,\n                zd.month,\n                zd.day,\n                zd.hour,\n                zd.minute,\n                zd.second,\n            )\n\n            try:\n                ext = \"---\" if is_dir else fn.rsplit(\".\", 1)[1]\n                if len(ext) > 16:\n                    ext = ext[:16]\n            except:\n                ext = \"%\"\n\n            if add_fk:\n                href = \"%s?k=%s\" % (\n                    quotep(href),\n                    self.gen_fk(\n                        self.args.fk_salt, fspath, sz, 0 if ANYWIN else inf.st_ino\n                    )[:add_fk],\n                )\n            else:\n                href = quotep(href)\n\n            item = {\n                \"lead\": margin,\n                \"href\": href,\n                \"name\": fn,\n                \"sz\": sz,\n                \"ext\": ext,\n                \"dt\": dt,\n                \"ts\": int(linf.st_mtime),\n            }\n            if is_dir:\n                dirs.append(item)\n            else:\n                files.append(item)\n                item[\"rd\"] = rem\n\n        if (\n            self.cookies.get(\"idxh\") == \"y\"\n            and \"ls\" not in self.uparam\n            and \"v\" not in self.uparam\n        ):\n            idx_html = set([\"index.htm\", \"index.html\"])\n            for item in files:\n                if item[\"name\"] in idx_html:\n                    # do full resolve in case of shadowed file\n                    vp = vjoin(self.vpath.split(\"?\")[0], item[\"name\"])\n                    vn, rem = self.asrv.vfs.get(vp, self.uname, True, False)\n                    ap = vn.canonical(rem)\n                    return self.tx_file(ap)  # is no-cache\n\n        tagset: set[str] = set()\n        for fe in files:\n            fn = fe[\"name\"]\n            rd = fe[\"rd\"]\n            del fe[\"rd\"]\n            if not icur:\n                continue\n\n            if vn != dbv:\n                _, rd = vn.get_dbv(rd)\n\n            erd_efn = (rd, fn)\n            q = \"select mt.k, mt.v from up inner join mt on mt.w = substr(up.w,1,16) where up.rd = ? and up.fn = ? and +mt.k != 'x'\"\n            try:\n                r = icur.execute(q, erd_efn)\n            except Exception as ex:\n                if \"database is locked\" in str(ex):\n                    break\n\n                try:\n                    erd_efn = s3enc(idx.mem_cur, rd, fn)\n                    r = icur.execute(q, erd_efn)\n                except:\n                    t = \"tag read error, {}/{}\\n{}\"\n                    self.log(t.format(rd, fn, min_ex()))\n                    break\n\n            fe[\"tags\"] = {k: v for k, v in r}\n\n            if self.can_admin:\n                q = \"select ip, at from up where rd=? and fn=?\"\n                try:\n                    zs1, zs2 = icur.execute(q, erd_efn).fetchone()\n                    fe[\"tags\"][\"up_ip\"] = zs1\n                    fe[\"tags\"][\".up_at\"] = zs2\n                except:\n                    pass\n\n            _ = [tagset.add(k) for k in fe[\"tags\"]]\n\n        if icur:\n            mte = vn.flags.get(\"mte\") or \"up_ip,.up_at\"\n            taglist = [k for k in mte.split(\",\") if k in tagset]\n            for fe in dirs:\n                fe[\"tags\"] = {}\n        else:\n            taglist = list(tagset)\n\n        if is_ls:\n            ls_ret[\"dirs\"] = dirs\n            ls_ret[\"files\"] = files\n            ls_ret[\"taglist\"] = taglist\n            return self.tx_ls(ls_ret)\n\n        doc = self.uparam.get(\"doc\") if self.can_read else None\n        if doc:\n            doc = unquotep(doc.replace(\"+\", \" \").split(\"?\")[0])\n            j2a[\"docname\"] = doc\n            doctxt = None\n            if next((x for x in files if x[\"name\"] == doc), None):\n                docpath = os.path.join(abspath, doc)\n                sz = bos.path.getsize(docpath)\n                if sz < 1024 * self.args.txt_max:\n                    with open(fsenc(docpath), \"rb\") as f:\n                        doctxt = f.read().decode(\"utf-8\", \"replace\")\n            else:\n                self.log(\"doc 404: [{}]\".format(doc), c=6)\n                doctxt = \"( textfile not found )\"\n\n            if doctxt is not None:\n                j2a[\"doc\"] = doctxt\n\n        for d in dirs:\n            d[\"name\"] += \"/\"\n\n        dirs.sort(key=itemgetter(\"name\"))\n\n        if is_js:\n            j2a[\"ls0\"] = {\n                \"dirs\": dirs,\n                \"files\": files,\n                \"taglist\": taglist,\n                \"unlist\": unlist,\n            }\n            j2a[\"files\"] = []\n        else:\n            j2a[\"files\"] = dirs + files\n\n        j2a[\"taglist\"] = taglist\n        j2a[\"txt_ext\"] = self.args.textfiles.replace(\",\", \" \")\n\n        if \"mth\" in vn.flags:\n            j2a[\"def_hcols\"] = vn.flags[\"mth\"].split(\",\")\n\n        html = self.j2s(tpl, **j2a)\n        self.reply(html.encode(\"utf-8\", \"replace\"))\n        return True\n", "# coding: utf-8\nfrom __future__ import print_function, unicode_literals\n\nimport base64\nimport math\nimport os\nimport socket\nimport sys\nimport threading\nimport time\n\nimport queue\n\nfrom .__init__ import ANYWIN, CORES, EXE, MACOS, TYPE_CHECKING, EnvParams\n\ntry:\n    MNFE = ModuleNotFoundError\nexcept:\n    MNFE = ImportError\n\ntry:\n    import jinja2\nexcept MNFE:\n    if EXE:\n        raise\n\n    print(\n        \"\"\"\\033[1;31m\n  you do not have jinja2 installed,\\033[33m\n  choose one of these:\\033[0m\n   * apt install python-jinja2\n   * {} -m pip install --user jinja2\n   * (try another python version, if you have one)\n   * (try copyparty.sfx instead)\n\"\"\".format(\n            sys.executable\n        )\n    )\n    sys.exit(1)\nexcept SyntaxError:\n    if EXE:\n        raise\n\n    print(\n        \"\"\"\\033[1;31m\n  your jinja2 version is incompatible with your python version;\\033[33m\n  please try to replace it with an older version:\\033[0m\n   * {} -m pip install --user jinja2==2.11.3\n   * (try another python version, if you have one)\n   * (try copyparty.sfx instead)\n\"\"\".format(\n            sys.executable\n        )\n    )\n    sys.exit(1)\n\nfrom .bos import bos\nfrom .httpconn import HttpConn\nfrom .u2idx import U2idx\nfrom .util import (\n    E_SCK,\n    FHC,\n    Daemon,\n    Garda,\n    Magician,\n    Netdev,\n    NetMap,\n    ipnorm,\n    min_ex,\n    shut_socket,\n    spack,\n    start_log_thrs,\n    start_stackmon,\n)\n\nif TYPE_CHECKING:\n    from .broker_util import BrokerCli\n    from .ssdp import SSDPr\n\nif True:  # pylint: disable=using-constant-test\n    from typing import Any, Optional\n\n\nclass HttpSrv(object):\n    \"\"\"\n    handles incoming connections using HttpConn to process http,\n    relying on MpSrv for performance (HttpSrv is just plain threads)\n    \"\"\"\n\n    def __init__(self, broker: \"BrokerCli\", nid: Optional[int]) -> None:\n        self.broker = broker\n        self.nid = nid\n        self.args = broker.args\n        self.E: EnvParams = self.args.E\n        self.log = broker.log\n        self.asrv = broker.asrv\n\n        # redefine in case of multiprocessing\n        socket.setdefaulttimeout(120)\n\n        nsuf = \"-n{}-i{:x}\".format(nid, os.getpid()) if nid else \"\"\n        self.magician = Magician()\n        self.nm = NetMap([], {})\n        self.ssdp: Optional[\"SSDPr\"] = None\n        self.gpwd = Garda(self.args.ban_pw)\n        self.g404 = Garda(self.args.ban_404)\n        self.bans: dict[str, int] = {}\n        self.aclose: dict[str, int] = {}\n\n        self.bound: set[tuple[str, int]] = set()\n        self.name = \"hsrv\" + nsuf\n        self.mutex = threading.Lock()\n        self.stopping = False\n\n        self.tp_nthr = 0  # actual\n        self.tp_ncli = 0  # fading\n        self.tp_time = 0.0  # latest worker collect\n        self.tp_q: Optional[queue.LifoQueue[Any]] = (\n            None if self.args.no_htp else queue.LifoQueue()\n        )\n        self.t_periodic: Optional[threading.Thread] = None\n\n        self.u2fh = FHC()\n        self.srvs: list[socket.socket] = []\n        self.ncli = 0  # exact\n        self.clients: set[HttpConn] = set()  # laggy\n        self.nclimax = 0\n        self.cb_ts = 0.0\n        self.cb_v = \"\"\n\n        self.u2idx_free: dict[str, U2idx] = {}\n        self.u2idx_n = 0\n\n        env = jinja2.Environment()\n        env.loader = jinja2.FileSystemLoader(os.path.join(self.E.mod, \"web\"))\n        jn = [\"splash\", \"svcs\", \"browser\", \"browser2\", \"msg\", \"md\", \"mde\", \"cf\"]\n        self.j2 = {x: env.get_template(x + \".html\") for x in jn}\n        zs = os.path.join(self.E.mod, \"web\", \"deps\", \"prism.js.gz\")\n        self.prism = os.path.exists(zs)\n\n        self.mallow = \"GET HEAD POST PUT DELETE OPTIONS\".split()\n        if not self.args.no_dav:\n            zs = \"PROPFIND PROPPATCH LOCK UNLOCK MKCOL COPY MOVE\"\n            self.mallow += zs.split()\n\n        if self.args.zs:\n            from .ssdp import SSDPr\n\n            self.ssdp = SSDPr(broker)\n\n        if self.tp_q:\n            self.start_threads(4)\n\n        if nid:\n            if self.args.stackmon:\n                start_stackmon(self.args.stackmon, nid)\n\n            if self.args.log_thrs:\n                start_log_thrs(self.log, self.args.log_thrs, nid)\n\n        self.th_cfg: dict[str, Any] = {}\n        Daemon(self.post_init, \"hsrv-init2\")\n\n    def post_init(self) -> None:\n        try:\n            x = self.broker.ask(\"thumbsrv.getcfg\")\n            self.th_cfg = x.get()\n        except:\n            pass\n\n    def set_netdevs(self, netdevs: dict[str, Netdev]) -> None:\n        ips = set()\n        for ip, _ in self.bound:\n            ips.add(ip)\n\n        self.nm = NetMap(list(ips), netdevs)\n\n    def start_threads(self, n: int) -> None:\n        self.tp_nthr += n\n        if self.args.log_htp:\n            self.log(self.name, \"workers += {} = {}\".format(n, self.tp_nthr), 6)\n\n        for _ in range(n):\n            Daemon(self.thr_poolw, self.name + \"-poolw\")\n\n    def stop_threads(self, n: int) -> None:\n        self.tp_nthr -= n\n        if self.args.log_htp:\n            self.log(self.name, \"workers -= {} = {}\".format(n, self.tp_nthr), 6)\n\n        assert self.tp_q\n        for _ in range(n):\n            self.tp_q.put(None)\n\n    def periodic(self) -> None:\n        while True:\n            time.sleep(2 if self.tp_ncli or self.ncli else 10)\n            with self.mutex:\n                self.u2fh.clean()\n                if self.tp_q:\n                    self.tp_ncli = max(self.ncli, self.tp_ncli - 2)\n                    if self.tp_nthr > self.tp_ncli + 8:\n                        self.stop_threads(4)\n\n                if not self.ncli and not self.u2fh.cache and self.tp_nthr <= 8:\n                    self.t_periodic = None\n                    return\n\n    def listen(self, sck: socket.socket, nlisteners: int) -> None:\n        if self.args.j != 1:\n            # lost in the pickle; redefine\n            if not ANYWIN or self.args.reuseaddr:\n                sck.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n            sck.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n            sck.settimeout(None)  # < does not inherit, ^ opts above do\n\n        ip, port = sck.getsockname()[:2]\n        self.srvs.append(sck)\n        self.bound.add((ip, port))\n        self.nclimax = math.ceil(self.args.nc * 1.0 / nlisteners)\n        Daemon(\n            self.thr_listen,\n            \"httpsrv-n{}-listen-{}-{}\".format(self.nid or \"0\", ip, port),\n            (sck,),\n        )\n\n    def thr_listen(self, srv_sck: socket.socket) -> None:\n        \"\"\"listens on a shared tcp server\"\"\"\n        ip, port = srv_sck.getsockname()[:2]\n        fno = srv_sck.fileno()\n        hip = \"[{}]\".format(ip) if \":\" in ip else ip\n        msg = \"subscribed @ {}:{}  f{} p{}\".format(hip, port, fno, os.getpid())\n        self.log(self.name, msg)\n\n        def fun() -> None:\n            self.broker.say(\"cb_httpsrv_up\")\n\n        threading.Thread(target=fun, name=\"sig-hsrv-up1\").start()\n\n        while not self.stopping:\n            if self.args.log_conn:\n                self.log(self.name, \"|%sC-ncli\" % (\"-\" * 1,), c=\"90\")\n\n            spins = 0\n            while self.ncli >= self.nclimax:\n                if not spins:\n                    self.log(self.name, \"at connection limit; waiting\", 3)\n\n                spins += 1\n                time.sleep(0.1)\n                if spins != 50 or not self.args.aclose:\n                    continue\n\n                ipfreq: dict[str, int] = {}\n                with self.mutex:\n                    for c in self.clients:\n                        ip = ipnorm(c.ip)\n                        try:\n                            ipfreq[ip] += 1\n                        except:\n                            ipfreq[ip] = 1\n\n                ip, n = sorted(ipfreq.items(), key=lambda x: x[1], reverse=True)[0]\n                if n < self.nclimax / 2:\n                    continue\n\n                self.aclose[ip] = int(time.time() + self.args.aclose * 60)\n                nclose = 0\n                nloris = 0\n                nconn = 0\n                with self.mutex:\n                    for c in self.clients:\n                        cip = ipnorm(c.ip)\n                        if ip != cip:\n                            continue\n\n                        nconn += 1\n                        try:\n                            if (\n                                c.nreq >= 1\n                                or not c.cli\n                                or c.cli.in_hdr_recv\n                                or c.cli.keepalive\n                            ):\n                                Daemon(c.shutdown)\n                                nclose += 1\n                                if c.nreq <= 0 and (not c.cli or c.cli.in_hdr_recv):\n                                    nloris += 1\n                        except:\n                            pass\n\n                t = \"{} downgraded to connection:close for {} min; dropped {}/{} connections\"\n                self.log(self.name, t.format(ip, self.args.aclose, nclose, nconn), 1)\n\n                if nloris < nconn / 2:\n                    continue\n\n                t = \"slowloris (idle-conn): {} banned for {} min\"\n                self.log(self.name, t.format(ip, self.args.loris, nclose), 1)\n                self.bans[ip] = int(time.time() + self.args.loris * 60)\n\n            if self.args.log_conn:\n                self.log(self.name, \"|%sC-acc1\" % (\"-\" * 2,), c=\"90\")\n\n            try:\n                sck, saddr = srv_sck.accept()\n                cip, cport = saddr[:2]\n                if cip.startswith(\"::ffff:\"):\n                    cip = cip[7:]\n\n                addr = (cip, cport)\n            except (OSError, socket.error) as ex:\n                if self.stopping:\n                    break\n\n                self.log(self.name, \"accept({}): {}\".format(fno, ex), c=6)\n                time.sleep(0.02)\n                continue\n\n            if self.args.log_conn:\n                t = \"|{}C-acc2 \\033[0;36m{} \\033[3{}m{}\".format(\n                    \"-\" * 3, ip, port % 8, port\n                )\n                self.log(\"%s %s\" % addr, t, c=\"90\")\n\n            self.accept(sck, addr)\n\n    def accept(self, sck: socket.socket, addr: tuple[str, int]) -> None:\n        \"\"\"takes an incoming tcp connection and creates a thread to handle it\"\"\"\n        now = time.time()\n\n        if now - (self.tp_time or now) > 300:\n            t = \"httpserver threadpool died: tpt {:.2f}, now {:.2f}, nthr {}, ncli {}\"\n            self.log(self.name, t.format(self.tp_time, now, self.tp_nthr, self.ncli), 1)\n            self.tp_time = 0\n            self.tp_q = None\n\n        with self.mutex:\n            self.ncli += 1\n            if not self.t_periodic:\n                name = \"hsrv-pt\"\n                if self.nid:\n                    name += \"-{}\".format(self.nid)\n\n                self.t_periodic = Daemon(self.periodic, name)\n\n            if self.tp_q:\n                self.tp_time = self.tp_time or now\n                self.tp_ncli = max(self.tp_ncli, self.ncli)\n                if self.tp_nthr < self.ncli + 4:\n                    self.start_threads(8)\n\n                self.tp_q.put((sck, addr))\n                return\n\n        if not self.args.no_htp:\n            t = \"looks like the httpserver threadpool died; please make an issue on github and tell me the story of how you pulled that off, thanks and dog bless\\n\"\n            self.log(self.name, t, 1)\n\n        Daemon(\n            self.thr_client,\n            \"httpconn-{}-{}\".format(addr[0].split(\".\", 2)[-1][-6:], addr[1]),\n            (sck, addr),\n        )\n\n    def thr_poolw(self) -> None:\n        assert self.tp_q\n        while True:\n            task = self.tp_q.get()\n            if not task:\n                break\n\n            with self.mutex:\n                self.tp_time = 0\n\n            try:\n                sck, addr = task\n                me = threading.current_thread()\n                me.name = \"httpconn-{}-{}\".format(\n                    addr[0].split(\".\", 2)[-1][-6:], addr[1]\n                )\n                self.thr_client(sck, addr)\n                me.name = self.name + \"-poolw\"\n            except Exception as ex:\n                if str(ex).startswith(\"client d/c \"):\n                    self.log(self.name, \"thr_client: \" + str(ex), 6)\n                else:\n                    self.log(self.name, \"thr_client: \" + min_ex(), 3)\n\n    def shutdown(self) -> None:\n        self.stopping = True\n        for srv in self.srvs:\n            try:\n                srv.close()\n            except:\n                pass\n\n        thrs = []\n        clients = list(self.clients)\n        for cli in clients:\n            t = threading.Thread(target=cli.shutdown)\n            thrs.append(t)\n            t.start()\n\n        if self.tp_q:\n            self.stop_threads(self.tp_nthr)\n            for _ in range(10):\n                time.sleep(0.05)\n                if self.tp_q.empty():\n                    break\n\n        for t in thrs:\n            t.join()\n\n        self.log(self.name, \"ok bye\")\n\n    def thr_client(self, sck: socket.socket, addr: tuple[str, int]) -> None:\n        \"\"\"thread managing one tcp client\"\"\"\n        cli = HttpConn(sck, addr, self)\n        with self.mutex:\n            self.clients.add(cli)\n\n        # print(\"{}\\n\".format(len(self.clients)), end=\"\")\n        fno = sck.fileno()\n        try:\n            if self.args.log_conn:\n                self.log(\"%s %s\" % addr, \"|%sC-crun\" % (\"-\" * 4,), c=\"90\")\n\n            cli.run()\n\n        except (OSError, socket.error) as ex:\n            if ex.errno not in E_SCK:\n                self.log(\n                    \"%s %s\" % addr,\n                    \"run({}): {}\".format(fno, ex),\n                    c=6,\n                )\n\n        finally:\n            sck = cli.s\n            if self.args.log_conn:\n                self.log(\"%s %s\" % addr, \"|%sC-cdone\" % (\"-\" * 5,), c=\"90\")\n\n            try:\n                fno = sck.fileno()\n                shut_socket(cli.log, sck)\n            except (OSError, socket.error) as ex:\n                if not MACOS:\n                    self.log(\n                        \"%s %s\" % addr,\n                        \"shut({}): {}\".format(fno, ex),\n                        c=\"90\",\n                    )\n                if ex.errno not in E_SCK:\n                    raise\n            finally:\n                with self.mutex:\n                    self.clients.remove(cli)\n                    self.ncli -= 1\n\n                if cli.u2idx:\n                    self.put_u2idx(str(addr), cli.u2idx)\n\n    def cachebuster(self) -> str:\n        if time.time() - self.cb_ts < 1:\n            return self.cb_v\n\n        with self.mutex:\n            if time.time() - self.cb_ts < 1:\n                return self.cb_v\n\n            v = self.E.t0\n            try:\n                with os.scandir(os.path.join(self.E.mod, \"web\")) as dh:\n                    for fh in dh:\n                        inf = fh.stat()\n                        v = max(v, inf.st_mtime)\n            except:\n                pass\n\n            v = base64.urlsafe_b64encode(spack(b\">xxL\", int(v)))\n            self.cb_v = v.decode(\"ascii\")[-4:]\n            self.cb_ts = time.time()\n            return self.cb_v\n\n    def get_u2idx(self, ident: str) -> Optional[U2idx]:\n        utab = self.u2idx_free\n        for _ in range(100):  # 5/0.05 = 5sec\n            with self.mutex:\n                if utab:\n                    if ident in utab:\n                        return utab.pop(ident)\n\n                    return utab.pop(list(utab.keys())[0])\n\n                if self.u2idx_n < CORES:\n                    self.u2idx_n += 1\n                    return U2idx(self)\n\n            time.sleep(0.05)\n            # not using conditional waits, on a hunch that\n            # average performance will be faster like this\n            # since most servers won't be fully saturated\n\n        return None\n\n    def put_u2idx(self, ident: str, u2idx: U2idx) -> None:\n        with self.mutex:\n            while ident in self.u2idx_free:\n                ident += \"a\"\n\n            self.u2idx_free[ident] = u2idx\n", "# coding: utf-8\nfrom __future__ import print_function, unicode_literals\n\nimport base64\nimport contextlib\nimport errno\nimport hashlib\nimport hmac\nimport json\nimport logging\nimport math\nimport mimetypes\nimport os\nimport platform\nimport re\nimport select\nimport shutil\nimport signal\nimport socket\nimport stat\nimport struct\nimport subprocess as sp  # nosec\nimport sys\nimport threading\nimport time\nimport traceback\nfrom collections import Counter\nfrom datetime import datetime\nfrom email.utils import formatdate\n\nfrom ipaddress import IPv4Address, IPv4Network, IPv6Address, IPv6Network\nfrom queue import Queue\n\nfrom .__init__ import ANYWIN, EXE, MACOS, PY2, TYPE_CHECKING, VT100, WINDOWS\nfrom .__version__ import S_BUILD_DT, S_VERSION\nfrom .stolen import surrogateescape\n\n\ndef _ens(want: str) -> tuple[int, ...]:\n    ret: list[int] = []\n    for v in want.split():\n        try:\n            ret.append(getattr(errno, v))\n        except:\n            pass\n\n    return tuple(ret)\n\n\n# WSAECONNRESET - foribly closed by remote\n# WSAENOTSOCK - no longer a socket\n# EUNATCH - can't assign requested address (wifi down)\nE_SCK = _ens(\"ENOTCONN EUNATCH EBADF WSAENOTSOCK WSAECONNRESET\")\nE_ADDR_NOT_AVAIL = _ens(\"EADDRNOTAVAIL WSAEADDRNOTAVAIL\")\nE_ADDR_IN_USE = _ens(\"EADDRINUSE WSAEADDRINUSE\")\nE_ACCESS = _ens(\"EACCES WSAEACCES\")\nE_UNREACH = _ens(\"EHOSTUNREACH WSAEHOSTUNREACH ENETUNREACH WSAENETUNREACH\")\n\n\ntry:\n    import ctypes\n    import fcntl\n    import termios\nexcept:\n    pass\n\ntry:\n    HAVE_SQLITE3 = True\n    import sqlite3  # pylint: disable=unused-import  # typechk\nexcept:\n    HAVE_SQLITE3 = False\n\ntry:\n    HAVE_PSUTIL = True\n    import psutil\nexcept:\n    HAVE_PSUTIL = False\n\nif True:  # pylint: disable=using-constant-test\n    import types\n    from collections.abc import Callable, Iterable\n\n    import typing\n    from typing import Any, Generator, Optional, Pattern, Protocol, Union\n\n    class RootLogger(Protocol):\n        def __call__(self, src: str, msg: str, c: Union[int, str] = 0) -> None:\n            return None\n\n    class NamedLogger(Protocol):\n        def __call__(self, msg: str, c: Union[int, str] = 0) -> None:\n            return None\n\n\nif TYPE_CHECKING:\n    import magic\n\n    from .authsrv import VFS\n\nFAKE_MP = False\n\ntry:\n    import multiprocessing as mp\n\n    # import multiprocessing.dummy as mp\nexcept ImportError:\n    # support jython\n    mp = None  # type: ignore\n\nif not PY2:\n    from io import BytesIO\n    from urllib.parse import quote_from_bytes as quote\n    from urllib.parse import unquote_to_bytes as unquote\nelse:\n    from StringIO import StringIO as BytesIO\n    from urllib import quote  # pylint: disable=no-name-in-module\n    from urllib import unquote  # pylint: disable=no-name-in-module\n\n\ntry:\n    struct.unpack(b\">i\", b\"idgi\")\n    spack = struct.pack\n    sunpack = struct.unpack\nexcept:\n\n    def spack(fmt: bytes, *a: Any) -> bytes:\n        return struct.pack(fmt.decode(\"ascii\"), *a)\n\n    def sunpack(fmt: bytes, a: bytes) -> tuple[Any, ...]:\n        return struct.unpack(fmt.decode(\"ascii\"), a)\n\n\nansi_re = re.compile(\"\\033\\\\[[^mK]*[mK]\")\n\n\nsurrogateescape.register_surrogateescape()\nif WINDOWS and PY2:\n    FS_ENCODING = \"utf-8\"\nelse:\n    FS_ENCODING = sys.getfilesystemencoding()\n\n\nSYMTIME = sys.version_info > (3, 6) and os.utime in os.supports_follow_symlinks\n\nMETA_NOBOTS = '<meta name=\"robots\" content=\"noindex, nofollow\">'\n\nFFMPEG_URL = \"https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z\"\n\nHTTPCODE = {\n    200: \"OK\",\n    201: \"Created\",\n    204: \"No Content\",\n    206: \"Partial Content\",\n    207: \"Multi-Status\",\n    301: \"Moved Permanently\",\n    302: \"Found\",\n    304: \"Not Modified\",\n    400: \"Bad Request\",\n    401: \"Unauthorized\",\n    403: \"Forbidden\",\n    404: \"Not Found\",\n    405: \"Method Not Allowed\",\n    409: \"Conflict\",\n    411: \"Length Required\",\n    412: \"Precondition Failed\",\n    413: \"Payload Too Large\",\n    416: \"Requested Range Not Satisfiable\",\n    422: \"Unprocessable Entity\",\n    423: \"Locked\",\n    429: \"Too Many Requests\",\n    500: \"Internal Server Error\",\n    501: \"Not Implemented\",\n    503: \"Service Unavailable\",\n}\n\n\nIMPLICATIONS = [\n    [\"e2dsa\", \"e2ds\"],\n    [\"e2ds\", \"e2d\"],\n    [\"e2tsr\", \"e2ts\"],\n    [\"e2ts\", \"e2t\"],\n    [\"e2t\", \"e2d\"],\n    [\"e2vu\", \"e2v\"],\n    [\"e2vp\", \"e2v\"],\n    [\"e2v\", \"e2d\"],\n    [\"smbw\", \"smb\"],\n    [\"smb1\", \"smb\"],\n    [\"smbvvv\", \"smbvv\"],\n    [\"smbvv\", \"smbv\"],\n    [\"smbv\", \"smb\"],\n    [\"zv\", \"zmv\"],\n    [\"zv\", \"zsv\"],\n    [\"z\", \"zm\"],\n    [\"z\", \"zs\"],\n    [\"zmvv\", \"zmv\"],\n    [\"zm4\", \"zm\"],\n    [\"zm6\", \"zm\"],\n    [\"zmv\", \"zm\"],\n    [\"zms\", \"zm\"],\n    [\"zsv\", \"zs\"],\n]\nif ANYWIN:\n    IMPLICATIONS.extend([[\"z\", \"zm4\"]])\n\n\nUNPLICATIONS = [[\"no_dav\", \"daw\"]]\n\n\nMIMES = {\n    \"opus\": \"audio/ogg; codecs=opus\",\n}\n\n\ndef _add_mimes() -> None:\n    # `mimetypes` is woefully unpopulated on windows\n    # but will be used as fallback on linux\n\n    for ln in \"\"\"text css html csv\napplication json wasm xml pdf rtf zip jar fits wasm\nimage webp jpeg png gif bmp jxl jp2 jxs jxr tiff bpg heic heif avif\naudio aac ogg wav flac ape amr\nvideo webm mp4 mpeg\nfont woff woff2 otf ttf\n\"\"\".splitlines():\n        k, vs = ln.split(\" \", 1)\n        for v in vs.strip().split():\n            MIMES[v] = \"{}/{}\".format(k, v)\n\n    for ln in \"\"\"text md=plain txt=plain js=javascript\napplication 7z=x-7z-compressed tar=x-tar bz2=x-bzip2 gz=gzip rar=x-rar-compressed zst=zstd xz=x-xz lz=lzip cpio=x-cpio\napplication msi=x-ms-installer cab=vnd.ms-cab-compressed rpm=x-rpm crx=x-chrome-extension\napplication epub=epub+zip mobi=x-mobipocket-ebook lit=x-ms-reader rss=rss+xml atom=atom+xml torrent=x-bittorrent\napplication p7s=pkcs7-signature dcm=dicom shx=vnd.shx shp=vnd.shp dbf=x-dbf gml=gml+xml gpx=gpx+xml amf=x-amf\napplication swf=x-shockwave-flash m3u=vnd.apple.mpegurl db3=vnd.sqlite3 sqlite=vnd.sqlite3\ntext ass=plain ssa=plain\nimage jpg=jpeg xpm=x-xpixmap psd=vnd.adobe.photoshop jpf=jpx tif=tiff ico=x-icon djvu=vnd.djvu\nimage heic=heic-sequence heif=heif-sequence hdr=vnd.radiance svg=svg+xml\naudio caf=x-caf mp3=mpeg m4a=mp4 mid=midi mpc=musepack aif=aiff au=basic qcp=qcelp\nvideo mkv=x-matroska mov=quicktime avi=x-msvideo m4v=x-m4v ts=mp2t\nvideo asf=x-ms-asf flv=x-flv 3gp=3gpp 3g2=3gpp2 rmvb=vnd.rn-realmedia-vbr\nfont ttc=collection\n\"\"\".splitlines():\n        k, ems = ln.split(\" \", 1)\n        for em in ems.strip().split():\n            ext, mime = em.split(\"=\")\n            MIMES[ext] = \"{}/{}\".format(k, mime)\n\n\n_add_mimes()\n\n\nEXTS: dict[str, str] = {v: k for k, v in MIMES.items()}\n\nEXTS[\"vnd.mozilla.apng\"] = \"png\"\n\nMAGIC_MAP = {\"jpeg\": \"jpg\"}\n\n\nREKOBO_KEY = {\n    v: ln.split(\" \", 1)[0]\n    for ln in \"\"\"\n1B 6d B\n2B 7d Gb F#\n3B 8d Db C#\n4B 9d Ab G#\n5B 10d Eb D#\n6B 11d Bb A#\n7B 12d F\n8B 1d C\n9B 2d G\n10B 3d D\n11B 4d A\n12B 5d E\n1A 6m Abm G#m\n2A 7m Ebm D#m\n3A 8m Bbm A#m\n4A 9m Fm\n5A 10m Cm\n6A 11m Gm\n7A 12m Dm\n8A 1m Am\n9A 2m Em\n10A 3m Bm\n11A 4m Gbm F#m\n12A 5m Dbm C#m\n\"\"\".strip().split(\n        \"\\n\"\n    )\n    for v in ln.strip().split(\" \")[1:]\n    if v\n}\n\nREKOBO_LKEY = {k.lower(): v for k, v in REKOBO_KEY.items()}\n\n\npybin = sys.executable or \"\"\nif EXE:\n    pybin = \"\"\n    for zsg in \"python3 python\".split():\n        try:\n            zsg = shutil.which(zsg)\n            if zsg:\n                pybin = zsg\n                break\n        except:\n            pass\n\n\ndef py_desc() -> str:\n    interp = platform.python_implementation()\n    py_ver = \".\".join([str(x) for x in sys.version_info])\n    ofs = py_ver.find(\".final.\")\n    if ofs > 0:\n        py_ver = py_ver[:ofs]\n\n    try:\n        bitness = struct.calcsize(b\"P\") * 8\n    except:\n        bitness = struct.calcsize(\"P\") * 8\n\n    host_os = platform.system()\n    compiler = platform.python_compiler().split(\"http\")[0]\n\n    m = re.search(r\"([0-9]+\\.[0-9\\.]+)\", platform.version())\n    os_ver = m.group(1) if m else \"\"\n\n    return \"{:>9} v{} on {}{} {} [{}]\".format(\n        interp, py_ver, host_os, bitness, os_ver, compiler\n    )\n\n\ndef _sqlite_ver() -> str:\n    try:\n        co = sqlite3.connect(\":memory:\")\n        cur = co.cursor()\n        try:\n            vs = cur.execute(\"select * from pragma_compile_options\").fetchall()\n        except:\n            vs = cur.execute(\"pragma compile_options\").fetchall()\n\n        v = next(x[0].split(\"=\")[1] for x in vs if x[0].startswith(\"THREADSAFE=\"))\n        cur.close()\n        co.close()\n    except:\n        v = \"W\"\n\n    return \"{}*{}\".format(sqlite3.sqlite_version, v)\n\n\ntry:\n    SQLITE_VER = _sqlite_ver()\nexcept:\n    SQLITE_VER = \"(None)\"\n\ntry:\n    from jinja2 import __version__ as JINJA_VER\nexcept:\n    JINJA_VER = \"(None)\"\n\ntry:\n    from pyftpdlib.__init__ import __ver__ as PYFTPD_VER\nexcept:\n    PYFTPD_VER = \"(None)\"\n\n\nVERSIONS = \"copyparty v{} ({})\\n{}\\n   sqlite v{} | jinja v{} | pyftpd v{}\".format(\n    S_VERSION, S_BUILD_DT, py_desc(), SQLITE_VER, JINJA_VER, PYFTPD_VER\n)\n\n\n_: Any = (mp, BytesIO, quote, unquote, SQLITE_VER, JINJA_VER, PYFTPD_VER)\n__all__ = [\"mp\", \"BytesIO\", \"quote\", \"unquote\", \"SQLITE_VER\", \"JINJA_VER\", \"PYFTPD_VER\"]\n\n\nclass Daemon(threading.Thread):\n    def __init__(\n        self,\n        target: Any,\n        name: Optional[str] = None,\n        a: Optional[Iterable[Any]] = None,\n        r: bool = True,\n        ka: Optional[dict[Any, Any]] = None,\n    ) -> None:\n        threading.Thread.__init__(\n            self, target=target, name=name, args=a or (), kwargs=ka\n        )\n        self.daemon = True\n        if r:\n            self.start()\n\n\nclass Netdev(object):\n    def __init__(self, ip: str, idx: int, name: str, desc: str):\n        self.ip = ip\n        self.idx = idx\n        self.name = name\n        self.desc = desc\n\n    def __str__(self):\n        return \"{}-{}{}\".format(self.idx, self.name, self.desc)\n\n    def __repr__(self):\n        return \"'{}-{}'\".format(self.idx, self.name)\n\n    def __lt__(self, rhs):\n        return str(self) < str(rhs)\n\n    def __eq__(self, rhs):\n        return str(self) == str(rhs)\n\n\nclass Cooldown(object):\n    def __init__(self, maxage: float) -> None:\n        self.maxage = maxage\n        self.mutex = threading.Lock()\n        self.hist: dict[str, float] = {}\n        self.oldest = 0.0\n\n    def poke(self, key: str) -> bool:\n        with self.mutex:\n            now = time.time()\n\n            ret = False\n            pv: float = self.hist.get(key, 0)\n            if now - pv > self.maxage:\n                self.hist[key] = now\n                ret = True\n\n            if self.oldest - now > self.maxage * 2:\n                self.hist = {\n                    k: v for k, v in self.hist.items() if now - v < self.maxage\n                }\n                self.oldest = sorted(self.hist.values())[0]\n\n            return ret\n\n\nclass HLog(logging.Handler):\n    def __init__(self, log_func: \"RootLogger\") -> None:\n        logging.Handler.__init__(self)\n        self.log_func = log_func\n        self.ptn_ftp = re.compile(r\"^([0-9a-f:\\.]+:[0-9]{1,5})-\\[\")\n        self.ptn_smb_ign = re.compile(r\"^(Callback added|Config file parsed)\")\n\n    def __repr__(self) -> str:\n        level = logging.getLevelName(self.level)\n        return \"<%s cpp(%s)>\" % (self.__class__.__name__, level)\n\n    def flush(self) -> None:\n        pass\n\n    def emit(self, record: logging.LogRecord) -> None:\n        msg = self.format(record)\n        lv = record.levelno\n        if lv < logging.INFO:\n            c = 6\n        elif lv < logging.WARNING:\n            c = 0\n        elif lv < logging.ERROR:\n            c = 3\n        else:\n            c = 1\n\n        if record.name == \"pyftpdlib\":\n            m = self.ptn_ftp.match(msg)\n            if m:\n                ip = m.group(1)\n                msg = msg[len(ip) + 1 :]\n                if ip.startswith(\"::ffff:\"):\n                    record.name = ip[7:]\n                else:\n                    record.name = ip\n        elif record.name.startswith(\"impacket\"):\n            if self.ptn_smb_ign.match(msg):\n                return\n\n        self.log_func(record.name[-21:], msg, c)\n\n\nclass NetMap(object):\n    def __init__(self, ips: list[str], netdevs: dict[str, Netdev]) -> None:\n        if \"::\" in ips:\n            ips = [x for x in ips if x != \"::\"] + list(\n                [x.split(\"/\")[0] for x in netdevs if \":\" in x]\n            )\n            ips.append(\"0.0.0.0\")\n\n        if \"0.0.0.0\" in ips:\n            ips = [x for x in ips if x != \"0.0.0.0\"] + list(\n                [x.split(\"/\")[0] for x in netdevs if \":\" not in x]\n            )\n\n        ips = [x for x in ips if x not in (\"::1\", \"127.0.0.1\")]\n        ips = find_prefix(ips, netdevs)\n\n        self.cache: dict[str, str] = {}\n        self.b2sip: dict[bytes, str] = {}\n        self.b2net: dict[bytes, Union[IPv4Network, IPv6Network]] = {}\n        self.bip: list[bytes] = []\n        for ip in ips:\n            v6 = \":\" in ip\n            fam = socket.AF_INET6 if v6 else socket.AF_INET\n            bip = socket.inet_pton(fam, ip.split(\"/\")[0])\n            self.bip.append(bip)\n            self.b2sip[bip] = ip.split(\"/\")[0]\n            self.b2net[bip] = (IPv6Network if v6 else IPv4Network)(ip, False)\n\n        self.bip.sort(reverse=True)\n\n    def map(self, ip: str) -> str:\n        try:\n            return self.cache[ip]\n        except:\n            pass\n\n        v6 = \":\" in ip\n        ci = IPv6Address(ip) if v6 else IPv4Address(ip)\n        bip = next((x for x in self.bip if ci in self.b2net[x]), None)\n        ret = self.b2sip[bip] if bip else \"\"\n        if len(self.cache) > 9000:\n            self.cache = {}\n        self.cache[ip] = ret\n        return ret\n\n\nclass UnrecvEOF(OSError):\n    pass\n\n\nclass _Unrecv(object):\n    \"\"\"\n    undo any number of socket recv ops\n    \"\"\"\n\n    def __init__(self, s: socket.socket, log: Optional[\"NamedLogger\"]) -> None:\n        self.s = s\n        self.log = log\n        self.buf: bytes = b\"\"\n\n    def recv(self, nbytes: int, spins: int = 1) -> bytes:\n        if self.buf:\n            ret = self.buf[:nbytes]\n            self.buf = self.buf[nbytes:]\n            return ret\n\n        while True:\n            try:\n                ret = self.s.recv(nbytes)\n                break\n            except socket.timeout:\n                spins -= 1\n                if spins <= 0:\n                    ret = b\"\"\n                    break\n                continue\n            except:\n                ret = b\"\"\n                break\n\n        if not ret:\n            raise UnrecvEOF(\"client stopped sending data\")\n\n        return ret\n\n    def recv_ex(self, nbytes: int, raise_on_trunc: bool = True) -> bytes:\n        \"\"\"read an exact number of bytes\"\"\"\n        ret = b\"\"\n        try:\n            while nbytes > len(ret):\n                ret += self.recv(nbytes - len(ret))\n        except OSError:\n            t = \"client only sent {} of {} expected bytes\".format(len(ret), nbytes)\n            if len(ret) <= 16:\n                t += \"; got {!r}\".format(ret)\n\n            if raise_on_trunc:\n                raise UnrecvEOF(5, t)\n            elif self.log:\n                self.log(t, 3)\n\n        return ret\n\n    def unrecv(self, buf: bytes) -> None:\n        self.buf = buf + self.buf\n\n\nclass _LUnrecv(object):\n    \"\"\"\n    with expensive debug logging\n    \"\"\"\n\n    def __init__(self, s: socket.socket, log: Optional[\"NamedLogger\"]) -> None:\n        self.s = s\n        self.log = log\n        self.buf = b\"\"\n\n    def recv(self, nbytes: int, spins: int) -> bytes:\n        if self.buf:\n            ret = self.buf[:nbytes]\n            self.buf = self.buf[nbytes:]\n            t = \"\\033[0;7mur:pop:\\033[0;1;32m {}\\n\\033[0;7mur:rem:\\033[0;1;35m {}\\033[0m\"\n            print(t.format(ret, self.buf))\n            return ret\n\n        ret = self.s.recv(nbytes)\n        t = \"\\033[0;7mur:recv\\033[0;1;33m {}\\033[0m\"\n        print(t.format(ret))\n        if not ret:\n            raise UnrecvEOF(\"client stopped sending data\")\n\n        return ret\n\n    def recv_ex(self, nbytes: int, raise_on_trunc: bool = True) -> bytes:\n        \"\"\"read an exact number of bytes\"\"\"\n        try:\n            ret = self.recv(nbytes, 1)\n            err = False\n        except:\n            ret = b\"\"\n            err = True\n\n        while not err and len(ret) < nbytes:\n            try:\n                ret += self.recv(nbytes - len(ret), 1)\n            except OSError:\n                err = True\n\n        if err:\n            t = \"client only sent {} of {} expected bytes\".format(len(ret), nbytes)\n            if raise_on_trunc:\n                raise UnrecvEOF(t)\n            elif self.log:\n                self.log(t, 3)\n\n        return ret\n\n    def unrecv(self, buf: bytes) -> None:\n        self.buf = buf + self.buf\n        t = \"\\033[0;7mur:push\\033[0;1;31m {}\\n\\033[0;7mur:rem:\\033[0;1;35m {}\\033[0m\"\n        print(t.format(buf, self.buf))\n\n\nUnrecv = _Unrecv\n\n\nclass CachedSet(object):\n    def __init__(self, maxage: float) -> None:\n        self.c: dict[Any, float] = {}\n        self.maxage = maxage\n        self.oldest = 0.0\n\n    def add(self, v: Any) -> None:\n        self.c[v] = time.time()\n\n    def cln(self) -> None:\n        now = time.time()\n        if now - self.oldest < self.maxage:\n            return\n\n        c = self.c = {k: v for k, v in self.c.items() if now - v < self.maxage}\n        try:\n            self.oldest = c[min(c, key=c.get)]\n        except:\n            self.oldest = now\n\n\nclass FHC(object):\n    class CE(object):\n        def __init__(self, fh: typing.BinaryIO) -> None:\n            self.ts: float = 0\n            self.fhs = [fh]\n\n    def __init__(self) -> None:\n        self.cache: dict[str, FHC.CE] = {}\n        self.aps: set[str] = set()\n\n    def close(self, path: str) -> None:\n        try:\n            ce = self.cache[path]\n        except:\n            return\n\n        for fh in ce.fhs:\n            fh.close()\n\n        del self.cache[path]\n        self.aps.remove(path)\n\n    def clean(self) -> None:\n        if not self.cache:\n            return\n\n        keep = {}\n        now = time.time()\n        for path, ce in self.cache.items():\n            if now < ce.ts + 5:\n                keep[path] = ce\n            else:\n                for fh in ce.fhs:\n                    fh.close()\n\n        self.cache = keep\n\n    def pop(self, path: str) -> typing.BinaryIO:\n        return self.cache[path].fhs.pop()\n\n    def put(self, path: str, fh: typing.BinaryIO) -> None:\n        self.aps.add(path)\n        try:\n            ce = self.cache[path]\n            ce.fhs.append(fh)\n        except:\n            ce = self.CE(fh)\n            self.cache[path] = ce\n\n        ce.ts = time.time()\n\n\nclass ProgressPrinter(threading.Thread):\n    \"\"\"\n    periodically print progress info without linefeeds\n    \"\"\"\n\n    def __init__(self) -> None:\n        threading.Thread.__init__(self, name=\"pp\")\n        self.daemon = True\n        self.msg = \"\"\n        self.end = False\n        self.n = -1\n        self.start()\n\n    def run(self) -> None:\n        msg = None\n        fmt = \" {}\\033[K\\r\" if VT100 else \" {} $\\r\"\n        while not self.end:\n            time.sleep(0.1)\n            if msg == self.msg or self.end:\n                continue\n\n            msg = self.msg\n            uprint(fmt.format(msg))\n            if PY2:\n                sys.stdout.flush()\n\n        if VT100:\n            print(\"\\033[K\", end=\"\")\n        elif msg:\n            print(\"------------------------\")\n\n        sys.stdout.flush()  # necessary on win10 even w/ stderr btw\n\n\nclass MTHash(object):\n    def __init__(self, cores: int):\n        self.pp: Optional[ProgressPrinter] = None\n        self.f: Optional[typing.BinaryIO] = None\n        self.sz = 0\n        self.csz = 0\n        self.stop = False\n        self.omutex = threading.Lock()\n        self.imutex = threading.Lock()\n        self.work_q: Queue[int] = Queue()\n        self.done_q: Queue[tuple[int, str, int, int]] = Queue()\n        self.thrs = []\n        for n in range(cores):\n            t = Daemon(self.worker, \"mth-\" + str(n))\n            self.thrs.append(t)\n\n    def hash(\n        self,\n        f: typing.BinaryIO,\n        fsz: int,\n        chunksz: int,\n        pp: Optional[ProgressPrinter] = None,\n        prefix: str = \"\",\n        suffix: str = \"\",\n    ) -> list[tuple[str, int, int]]:\n        with self.omutex:\n            self.f = f\n            self.sz = fsz\n            self.csz = chunksz\n\n            chunks: dict[int, tuple[str, int, int]] = {}\n            nchunks = int(math.ceil(fsz / chunksz))\n            for nch in range(nchunks):\n                self.work_q.put(nch)\n\n            ex = \"\"\n            for nch in range(nchunks):\n                qe = self.done_q.get()\n                try:\n                    nch, dig, ofs, csz = qe\n                    chunks[nch] = (dig, ofs, csz)\n                except:\n                    ex = ex or str(qe)\n\n                if pp:\n                    mb = int((fsz - nch * chunksz) / 1024 / 1024)\n                    pp.msg = prefix + str(mb) + suffix\n\n            if ex:\n                raise Exception(ex)\n\n            ret = []\n            for n in range(nchunks):\n                ret.append(chunks[n])\n\n            self.f = None\n            self.csz = 0\n            self.sz = 0\n            return ret\n\n    def worker(self) -> None:\n        while True:\n            ofs = self.work_q.get()\n            try:\n                v = self.hash_at(ofs)\n            except Exception as ex:\n                v = str(ex)  # type: ignore\n\n            self.done_q.put(v)\n\n    def hash_at(self, nch: int) -> tuple[int, str, int, int]:\n        f = self.f\n        ofs = ofs0 = nch * self.csz\n        chunk_sz = chunk_rem = min(self.csz, self.sz - ofs)\n        if self.stop:\n            return nch, \"\", ofs0, chunk_sz\n\n        assert f\n        hashobj = hashlib.sha512()\n        while chunk_rem > 0:\n            with self.imutex:\n                f.seek(ofs)\n                buf = f.read(min(chunk_rem, 1024 * 1024 * 12))\n\n            if not buf:\n                raise Exception(\"EOF at \" + str(ofs))\n\n            hashobj.update(buf)\n            chunk_rem -= len(buf)\n            ofs += len(buf)\n\n        bdig = hashobj.digest()[:33]\n        udig = base64.urlsafe_b64encode(bdig).decode(\"utf-8\")\n        return nch, udig, ofs0, chunk_sz\n\n\nclass HMaccas(object):\n    def __init__(self, keypath: str, retlen: int) -> None:\n        self.retlen = retlen\n        self.cache: dict[bytes, str] = {}\n        try:\n            with open(keypath, \"rb\") as f:\n                self.key = f.read()\n                if len(self.key) != 64:\n                    raise Exception()\n        except:\n            self.key = os.urandom(64)\n            with open(keypath, \"wb\") as f:\n                f.write(self.key)\n\n    def b(self, msg: bytes) -> str:\n        try:\n            return self.cache[msg]\n        except:\n            if len(self.cache) > 9000:\n                self.cache = {}\n\n            zb = hmac.new(self.key, msg, hashlib.sha512).digest()\n            zs = base64.urlsafe_b64encode(zb)[: self.retlen].decode(\"utf-8\")\n            self.cache[msg] = zs\n            return zs\n\n    def s(self, msg: str) -> str:\n        return self.b(msg.encode(\"utf-8\", \"replace\"))\n\n\nclass Magician(object):\n    def __init__(self) -> None:\n        self.bad_magic = False\n        self.mutex = threading.Lock()\n        self.magic: Optional[\"magic.Magic\"] = None\n\n    def ext(self, fpath: str) -> str:\n        import magic\n\n        try:\n            if self.bad_magic:\n                raise Exception()\n\n            if not self.magic:\n                try:\n                    with self.mutex:\n                        if not self.magic:\n                            self.magic = magic.Magic(uncompress=False, extension=True)\n                except:\n                    self.bad_magic = True\n                    raise\n\n            with self.mutex:\n                ret = self.magic.from_file(fpath)\n        except:\n            ret = \"?\"\n\n        ret = ret.split(\"/\")[0]\n        ret = MAGIC_MAP.get(ret, ret)\n        if \"?\" not in ret:\n            return ret\n\n        mime = magic.from_file(fpath, mime=True)\n        mime = re.split(\"[; ]\", mime, 1)[0]\n        try:\n            return EXTS[mime]\n        except:\n            pass\n\n        mg = mimetypes.guess_extension(mime)\n        if mg:\n            return mg[1:]\n        else:\n            raise Exception()\n\n\nclass Garda(object):\n    \"\"\"ban clients for repeated offenses\"\"\"\n\n    def __init__(self, cfg: str) -> None:\n        try:\n            a, b, c = cfg.strip().split(\",\")\n            self.lim = int(a)\n            self.win = int(b) * 60\n            self.pen = int(c) * 60\n        except:\n            self.lim = self.win = self.pen = 0\n\n        self.ct: dict[str, list[int]] = {}\n        self.prev: dict[str, str] = {}\n        self.last_cln = 0\n\n    def cln(self, ip: str) -> None:\n        n = 0\n        ok = int(time.time() - self.win)\n        for v in self.ct[ip]:\n            if v < ok:\n                n += 1\n            else:\n                break\n        if n:\n            te = self.ct[ip][n:]\n            if te:\n                self.ct[ip] = te\n            else:\n                del self.ct[ip]\n                try:\n                    del self.prev[ip]\n                except:\n                    pass\n\n    def allcln(self) -> None:\n        for k in list(self.ct):\n            self.cln(k)\n\n        self.last_cln = int(time.time())\n\n    def bonk(self, ip: str, prev: str) -> tuple[int, str]:\n        if not self.lim:\n            return 0, ip\n\n        if \":\" in ip:\n            # assume /64 clients; drop 4 groups\n            ip = IPv6Address(ip).exploded[:-20]\n\n        if prev:\n            if self.prev.get(ip) == prev:\n                return 0, ip\n\n            self.prev[ip] = prev\n\n        now = int(time.time())\n        try:\n            self.ct[ip].append(now)\n        except:\n            self.ct[ip] = [now]\n\n        if now - self.last_cln > 300:\n            self.allcln()\n        else:\n            self.cln(ip)\n\n        if len(self.ct[ip]) >= self.lim:\n            return now + self.pen, ip\n        else:\n            return 0, ip\n\n\nif WINDOWS and sys.version_info < (3, 8):\n    _popen = sp.Popen\n\n    def _spopen(c, *a, **ka):\n        enc = sys.getfilesystemencoding()\n        c = [x.decode(enc, \"replace\") if hasattr(x, \"decode\") else x for x in c]\n        return _popen(c, *a, **ka)\n\n    sp.Popen = _spopen\n\n\ndef uprint(msg: str) -> None:\n    try:\n        print(msg, end=\"\")\n    except UnicodeEncodeError:\n        try:\n            print(msg.encode(\"utf-8\", \"replace\").decode(), end=\"\")\n        except:\n            print(msg.encode(\"ascii\", \"replace\").decode(), end=\"\")\n\n\ndef nuprint(msg: str) -> None:\n    uprint(\"{}\\n\".format(msg))\n\n\ndef rice_tid() -> str:\n    tid = threading.current_thread().ident\n    c = sunpack(b\"B\" * 5, spack(b\">Q\", tid)[-5:])\n    return \"\".join(\"\\033[1;37;48;5;{0}m{0:02x}\".format(x) for x in c) + \"\\033[0m\"\n\n\ndef trace(*args: Any, **kwargs: Any) -> None:\n    t = time.time()\n    stack = \"\".join(\n        \"\\033[36m{}\\033[33m{}\".format(x[0].split(os.sep)[-1][:-3], x[1])\n        for x in traceback.extract_stack()[3:-1]\n    )\n    parts = [\"{:.6f}\".format(t), rice_tid(), stack]\n\n    if args:\n        parts.append(repr(args))\n\n    if kwargs:\n        parts.append(repr(kwargs))\n\n    msg = \"\\033[0m \".join(parts)\n    # _tracebuf.append(msg)\n    nuprint(msg)\n\n\ndef alltrace() -> str:\n    threads: dict[str, types.FrameType] = {}\n    names = dict([(t.ident, t.name) for t in threading.enumerate()])\n    for tid, stack in sys._current_frames().items():\n        name = \"{} ({:x})\".format(names.get(tid), tid)\n        threads[name] = stack\n\n    rret: list[str] = []\n    bret: list[str] = []\n    for name, stack in sorted(threads.items()):\n        ret = [\"\\n\\n# {}\".format(name)]\n        pad = None\n        for fn, lno, name, line in traceback.extract_stack(stack):\n            fn = os.sep.join(fn.split(os.sep)[-3:])\n            ret.append('File: \"{}\", line {}, in {}'.format(fn, lno, name))\n            if line:\n                ret.append(\"  \" + str(line.strip()))\n                if \"self.not_empty.wait()\" in line:\n                    pad = \" \" * 4\n\n        if pad:\n            bret += [ret[0]] + [pad + x for x in ret[1:]]\n        else:\n            rret += ret\n\n    return \"\\n\".join(rret + bret) + \"\\n\"\n\n\ndef start_stackmon(arg_str: str, nid: int) -> None:\n    suffix = \"-{}\".format(nid) if nid else \"\"\n    fp, f = arg_str.rsplit(\",\", 1)\n    zi = int(f)\n    Daemon(stackmon, \"stackmon\" + suffix, (fp, zi, suffix))\n\n\ndef stackmon(fp: str, ival: float, suffix: str) -> None:\n    ctr = 0\n    fp0 = fp\n    while True:\n        ctr += 1\n        fp = fp0\n        time.sleep(ival)\n        st = \"{}, {}\\n{}\".format(ctr, time.time(), alltrace())\n        buf = st.encode(\"utf-8\", \"replace\")\n\n        if fp.endswith(\".gz\"):\n            import gzip\n\n            # 2459b 2304b 2241b 2202b 2194b 2191b lv3..8\n            # 0.06s 0.08s 0.11s 0.13s 0.16s 0.19s\n            buf = gzip.compress(buf, compresslevel=6)\n\n        elif fp.endswith(\".xz\"):\n            import lzma\n\n            # 2276b 2216b 2200b 2192b 2168b lv0..4\n            # 0.04s 0.10s 0.22s 0.41s 0.70s\n            buf = lzma.compress(buf, preset=0)\n\n        if \"%\" in fp:\n            dt = datetime.utcnow()\n            for fs in \"YmdHMS\":\n                fs = \"%\" + fs\n                if fs in fp:\n                    fp = fp.replace(fs, dt.strftime(fs))\n\n        if \"/\" in fp:\n            try:\n                os.makedirs(fp.rsplit(\"/\", 1)[0])\n            except:\n                pass\n\n        with open(fp + suffix, \"wb\") as f:\n            f.write(buf)\n\n\ndef start_log_thrs(\n    logger: Callable[[str, str, int], None], ival: float, nid: int\n) -> None:\n    ival = float(ival)\n    tname = lname = \"log-thrs\"\n    if nid:\n        tname = \"logthr-n{}-i{:x}\".format(nid, os.getpid())\n        lname = tname[3:]\n\n    Daemon(log_thrs, tname, (logger, ival, lname))\n\n\ndef log_thrs(log: Callable[[str, str, int], None], ival: float, name: str) -> None:\n    while True:\n        time.sleep(ival)\n        tv = [x.name for x in threading.enumerate()]\n        tv = [\n            x.split(\"-\")[0]\n            if x.split(\"-\")[0] in [\"httpconn\", \"thumb\", \"tagger\"]\n            else \"listen\"\n            if \"-listen-\" in x\n            else x\n            for x in tv\n            if not x.startswith(\"pydevd.\")\n        ]\n        tv = [\"{}\\033[36m{}\".format(v, k) for k, v in sorted(Counter(tv).items())]\n        log(name, \"\\033[0m \\033[33m\".join(tv), 3)\n\n\ndef vol_san(vols: list[\"VFS\"], txt: bytes) -> bytes:\n    for vol in vols:\n        txt = txt.replace(vol.realpath.encode(\"utf-8\"), vol.vpath.encode(\"utf-8\"))\n        txt = txt.replace(\n            vol.realpath.encode(\"utf-8\").replace(b\"\\\\\", b\"\\\\\\\\\"),\n            vol.vpath.encode(\"utf-8\"),\n        )\n\n    return txt\n\n\ndef min_ex(max_lines: int = 8, reverse: bool = False) -> str:\n    et, ev, tb = sys.exc_info()\n    stb = traceback.extract_tb(tb)\n    fmt = \"{} @ {} <{}>: {}\"\n    ex = [fmt.format(fp.split(os.sep)[-1], ln, fun, txt) for fp, ln, fun, txt in stb]\n    ex.append(\"[{}] {}\".format(et.__name__ if et else \"(anonymous)\", ev))\n    return \"\\n\".join(ex[-max_lines:][:: -1 if reverse else 1])\n\n\n@contextlib.contextmanager\ndef ren_open(\n    fname: str, *args: Any, **kwargs: Any\n) -> Generator[dict[str, tuple[typing.IO[Any], str]], None, None]:\n    fun = kwargs.pop(\"fun\", open)\n    fdir = kwargs.pop(\"fdir\", None)\n    suffix = kwargs.pop(\"suffix\", None)\n\n    if fname == os.devnull:\n        with fun(fname, *args, **kwargs) as f:\n            yield {\"orz\": (f, fname)}\n            return\n\n    if suffix:\n        ext = fname.split(\".\")[-1]\n        if len(ext) < 7:\n            suffix += \".\" + ext\n\n    orig_name = fname\n    bname = fname\n    ext = \"\"\n    while True:\n        ofs = bname.rfind(\".\")\n        if ofs < 0 or ofs < len(bname) - 7:\n            # doesn't look like an extension anymore\n            break\n\n        ext = bname[ofs:] + ext\n        bname = bname[:ofs]\n\n    asciified = False\n    b64 = \"\"\n    while True:\n        try:\n            if fdir:\n                fpath = os.path.join(fdir, fname)\n            else:\n                fpath = fname\n\n            if suffix and os.path.lexists(fsenc(fpath)):\n                fpath += suffix\n                fname += suffix\n                ext += suffix\n\n            with fun(fsenc(fpath), *args, **kwargs) as f:\n                if b64:\n                    assert fdir\n                    fp2 = \"fn-trunc.{}.txt\".format(b64)\n                    fp2 = os.path.join(fdir, fp2)\n                    with open(fsenc(fp2), \"wb\") as f2:\n                        f2.write(orig_name.encode(\"utf-8\"))\n\n                yield {\"orz\": (f, fname)}\n                return\n\n        except OSError as ex_:\n            ex = ex_\n\n            if ex.errno == errno.EINVAL and not asciified:\n                asciified = True\n                bname, fname = [\n                    zs.encode(\"ascii\", \"replace\").decode(\"ascii\").replace(\"?\", \"_\")\n                    for zs in [bname, fname]\n                ]\n                continue\n\n            # ENOTSUP: zfs on ubuntu 20.04\n            if ex.errno not in (errno.ENAMETOOLONG, errno.ENOSR, errno.ENOTSUP) and (\n                not WINDOWS or ex.errno != errno.EINVAL\n            ):\n                raise\n\n        if not b64:\n            zs = \"{}\\n{}\".format(orig_name, suffix).encode(\"utf-8\", \"replace\")\n            zs = hashlib.sha512(zs).digest()[:12]\n            b64 = base64.urlsafe_b64encode(zs).decode(\"utf-8\")\n\n        badlen = len(fname)\n        while len(fname) >= badlen:\n            if len(bname) < 8:\n                raise ex\n\n            if len(bname) > len(ext):\n                # drop the last letter of the filename\n                bname = bname[:-1]\n            else:\n                try:\n                    # drop the leftmost sub-extension\n                    _, ext = ext.split(\".\", 1)\n                except:\n                    # okay do the first letter then\n                    ext = \".\" + ext[2:]\n\n            fname = \"{}~{}{}\".format(bname, b64, ext)\n\n\nclass MultipartParser(object):\n    def __init__(\n        self, log_func: \"NamedLogger\", sr: Unrecv, http_headers: dict[str, str]\n    ):\n        self.sr = sr\n        self.log = log_func\n        self.headers = http_headers\n\n        self.re_ctype = re.compile(r\"^content-type: *([^; ]+)\", re.IGNORECASE)\n        self.re_cdisp = re.compile(r\"^content-disposition: *([^; ]+)\", re.IGNORECASE)\n        self.re_cdisp_field = re.compile(\n            r'^content-disposition:(?: *|.*; *)name=\"([^\"]+)\"', re.IGNORECASE\n        )\n        self.re_cdisp_file = re.compile(\n            r'^content-disposition:(?: *|.*; *)filename=\"(.*)\"', re.IGNORECASE\n        )\n\n        self.boundary = b\"\"\n        self.gen: Optional[\n            Generator[\n                tuple[str, Optional[str], Generator[bytes, None, None]], None, None\n            ]\n        ] = None\n\n    def _read_header(self) -> tuple[str, Optional[str]]:\n        \"\"\"\n        returns [fieldname, filename] after eating a block of multipart headers\n        while doing a decent job at dealing with the absolute mess that is\n        rfc1341/rfc1521/rfc2047/rfc2231/rfc2388/rfc6266/the-real-world\n        (only the fallback non-js uploader relies on these filenames)\n        \"\"\"\n        for ln in read_header(self.sr, 2, 2592000):\n            self.log(ln)\n\n            m = self.re_ctype.match(ln)\n            if m:\n                if m.group(1).lower() == \"multipart/mixed\":\n                    # rfc-7578 overrides rfc-2388 so this is not-impl\n                    # (opera >=9 <11.10 is the only thing i've ever seen use it)\n                    raise Pebkac(\n                        400,\n                        \"you can't use that browser to upload multiple files at once\",\n                    )\n\n                continue\n\n            # the only other header we care about is content-disposition\n            m = self.re_cdisp.match(ln)\n            if not m:\n                continue\n\n            if m.group(1).lower() != \"form-data\":\n                raise Pebkac(400, \"not form-data: {}\".format(ln))\n\n            try:\n                field = self.re_cdisp_field.match(ln).group(1)  # type: ignore\n            except:\n                raise Pebkac(400, \"missing field name: {}\".format(ln))\n\n            try:\n                fn = self.re_cdisp_file.match(ln).group(1)  # type: ignore\n            except:\n                # this is not a file upload, we're done\n                return field, None\n\n            try:\n                is_webkit = \"applewebkit\" in self.headers[\"user-agent\"].lower()\n            except:\n                is_webkit = False\n\n            # chromes ignore the spec and makes this real easy\n            if is_webkit:\n                # quotes become %22 but they don't escape the %\n                # so unescaping the quotes could turn messi\n                return field, fn.split('\"')[0]\n\n            # also ez if filename doesn't contain \"\n            if not fn.split('\"')[0].endswith(\"\\\\\"):\n                return field, fn.split('\"')[0]\n\n            # this breaks on firefox uploads that contain \\\"\n            # since firefox escapes \" but forgets to escape \\\n            # so it'll truncate after the \\\n            ret = \"\"\n            esc = False\n            for ch in fn:\n                if esc:\n                    esc = False\n                    if ch not in ['\"', \"\\\\\"]:\n                        ret += \"\\\\\"\n                    ret += ch\n                elif ch == \"\\\\\":\n                    esc = True\n                elif ch == '\"':\n                    break\n                else:\n                    ret += ch\n\n            return field, ret\n\n        raise Pebkac(400, \"server expected a multipart header but you never sent one\")\n\n    def _read_data(self) -> Generator[bytes, None, None]:\n        blen = len(self.boundary)\n        bufsz = 32 * 1024\n        while True:\n            try:\n                buf = self.sr.recv(bufsz)\n            except:\n                # abort: client disconnected\n                raise Pebkac(400, \"client d/c during multipart post\")\n\n            while True:\n                ofs = buf.find(self.boundary)\n                if ofs != -1:\n                    self.sr.unrecv(buf[ofs + blen :])\n                    yield buf[:ofs]\n                    return\n\n                d = len(buf) - blen\n                if d > 0:\n                    # buffer growing large; yield everything except\n                    # the part at the end (maybe start of boundary)\n                    yield buf[:d]\n                    buf = buf[d:]\n\n                # look for boundary near the end of the buffer\n                n = 0\n                for n in range(1, len(buf) + 1):\n                    if not buf[-n:] in self.boundary:\n                        n -= 1\n                        break\n\n                if n == 0 or not self.boundary.startswith(buf[-n:]):\n                    # no boundary contents near the buffer edge\n                    break\n\n                if blen == n:\n                    # EOF: found boundary\n                    yield buf[:-n]\n                    return\n\n                try:\n                    buf += self.sr.recv(bufsz)\n                except:\n                    # abort: client disconnected\n                    raise Pebkac(400, \"client d/c during multipart post\")\n\n            yield buf\n\n    def _run_gen(\n        self,\n    ) -> Generator[tuple[str, Optional[str], Generator[bytes, None, None]], None, None]:\n        \"\"\"\n        yields [fieldname, unsanitized_filename, fieldvalue]\n        where fieldvalue yields chunks of data\n        \"\"\"\n        run = True\n        while run:\n            fieldname, filename = self._read_header()\n            yield (fieldname, filename, self._read_data())\n\n            tail = self.sr.recv_ex(2, False)\n\n            if tail == b\"--\":\n                # EOF indicated by this immediately after final boundary\n                tail = self.sr.recv_ex(2, False)\n                run = False\n\n            if tail != b\"\\r\\n\":\n                t = \"protocol error after field value: want b'\\\\r\\\\n', got {!r}\"\n                raise Pebkac(400, t.format(tail))\n\n    def _read_value(self, iterable: Iterable[bytes], max_len: int) -> bytes:\n        ret = b\"\"\n        for buf in iterable:\n            ret += buf\n            if len(ret) > max_len:\n                raise Pebkac(400, \"field length is too long\")\n\n        return ret\n\n    def parse(self) -> None:\n        # spec says there might be junk before the first boundary,\n        # can't have the leading \\r\\n if that's not the case\n        self.boundary = b\"--\" + get_boundary(self.headers).encode(\"utf-8\")\n\n        # discard junk before the first boundary\n        for junk in self._read_data():\n            self.log(\n                \"discarding preamble: [{}]\".format(junk.decode(\"utf-8\", \"replace\"))\n            )\n\n        # nice, now make it fast\n        self.boundary = b\"\\r\\n\" + self.boundary\n        self.gen = self._run_gen()\n\n    def require(self, field_name: str, max_len: int) -> str:\n        \"\"\"\n        returns the value of the next field in the multipart body,\n        raises if the field name is not as expected\n        \"\"\"\n        assert self.gen\n        p_field, _, p_data = next(self.gen)\n        if p_field != field_name:\n            raise Pebkac(\n                422, 'expected field \"{}\", got \"{}\"'.format(field_name, p_field)\n            )\n\n        return self._read_value(p_data, max_len).decode(\"utf-8\", \"surrogateescape\")\n\n    def drop(self) -> None:\n        \"\"\"discards the remaining multipart body\"\"\"\n        assert self.gen\n        for _, _, data in self.gen:\n            for _ in data:\n                pass\n\n\ndef get_boundary(headers: dict[str, str]) -> str:\n    # boundaries contain a-z A-Z 0-9 ' ( ) + _ , - . / : = ?\n    # (whitespace allowed except as the last char)\n    ptn = r\"^multipart/form-data *; *(.*; *)?boundary=([^;]+)\"\n    ct = headers[\"content-type\"]\n    m = re.match(ptn, ct, re.IGNORECASE)\n    if not m:\n        raise Pebkac(400, \"invalid content-type for a multipart post: {}\".format(ct))\n\n    return m.group(2)\n\n\ndef read_header(sr: Unrecv, t_idle: int, t_tot: int) -> list[str]:\n    t0 = time.time()\n    ret = b\"\"\n    while True:\n        if time.time() - t0 >= t_tot:\n            return []\n\n        try:\n            ret += sr.recv(1024, t_idle // 2)\n        except:\n            if not ret:\n                return []\n\n            raise Pebkac(\n                400,\n                \"protocol error while reading headers:\\n\"\n                + ret.decode(\"utf-8\", \"replace\"),\n            )\n\n        ofs = ret.find(b\"\\r\\n\\r\\n\")\n        if ofs < 0:\n            if len(ret) > 1024 * 64:\n                raise Pebkac(400, \"header 2big\")\n            else:\n                continue\n\n        if len(ret) > ofs + 4:\n            sr.unrecv(ret[ofs + 4 :])\n\n        return ret[:ofs].decode(\"utf-8\", \"surrogateescape\").lstrip(\"\\r\\n\").split(\"\\r\\n\")\n\n\ndef rand_name(fdir: str, fn: str, rnd: int) -> str:\n    ok = False\n    try:\n        ext = \".\" + fn.rsplit(\".\", 1)[1]\n    except:\n        ext = \"\"\n\n    for extra in range(16):\n        for _ in range(16):\n            if ok:\n                break\n\n            nc = rnd + extra\n            nb = int((6 + 6 * nc) / 8)\n            zb = os.urandom(nb)\n            zb = base64.urlsafe_b64encode(zb)\n            fn = zb[:nc].decode(\"utf-8\") + ext\n            ok = not os.path.exists(fsenc(os.path.join(fdir, fn)))\n\n    return fn\n\n\ndef gen_filekey(salt: str, fspath: str, fsize: int, inode: int) -> str:\n    return base64.urlsafe_b64encode(\n        hashlib.sha512(\n            (\"%s %s %s %s\" % (salt, fspath, fsize, inode)).encode(\"utf-8\", \"replace\")\n        ).digest()\n    ).decode(\"ascii\")\n\n\ndef gen_filekey_dbg(\n    salt: str,\n    fspath: str,\n    fsize: int,\n    inode: int,\n    log: \"NamedLogger\",\n    log_ptn: Optional[Pattern[str]],\n) -> str:\n    ret = gen_filekey(salt, fspath, fsize, inode)\n\n    assert log_ptn\n    if log_ptn.search(fspath):\n        try:\n            import inspect\n\n            ctx = \",\".join(inspect.stack()[n].function for n in range(2, 5))\n        except:\n            ctx = \"\"\n\n        p2 = \"a\"\n        try:\n            p2 = absreal(fspath)\n            if p2 != fspath:\n                raise Exception()\n        except:\n            t = \"maybe wrong abspath for filekey;\\norig: {}\\nreal: {}\"\n            log(t.format(fspath, p2), 1)\n\n        t = \"fk({}) salt({}) size({}) inode({}) fspath({}) at({})\"\n        log(t.format(ret[:8], salt, fsize, inode, fspath, ctx), 5)\n\n    return ret\n\n\ndef gencookie(k: str, v: str, r: str, tls: bool, dur: Optional[int]) -> str:\n    v = v.replace(\"%\", \"%25\").replace(\";\", \"%3B\")\n    if dur:\n        exp = formatdate(time.time() + dur, usegmt=True)\n    else:\n        exp = \"Fri, 15 Aug 1997 01:00:00 GMT\"\n\n    return \"{}={}; Path=/{}; Expires={}{}; SameSite=Lax\".format(\n        k, v, r, exp, \"; Secure\" if tls else \"\"\n    )\n\n\ndef humansize(sz: float, terse: bool = False) -> str:\n    for unit in [\"B\", \"KiB\", \"MiB\", \"GiB\", \"TiB\"]:\n        if sz < 1024:\n            break\n\n        sz /= 1024.0\n\n    ret = \" \".join([str(sz)[:4].rstrip(\".\"), unit])\n\n    if not terse:\n        return ret\n\n    return ret.replace(\"iB\", \"\").replace(\" \", \"\")\n\n\ndef unhumanize(sz: str) -> int:\n    try:\n        return int(sz)\n    except:\n        pass\n\n    mc = sz[-1:].lower()\n    mi = {\n        \"k\": 1024,\n        \"m\": 1024 * 1024,\n        \"g\": 1024 * 1024 * 1024,\n        \"t\": 1024 * 1024 * 1024 * 1024,\n    }.get(mc, 1)\n    return int(float(sz[:-1]) * mi)\n\n\ndef get_spd(nbyte: int, t0: float, t: Optional[float] = None) -> str:\n    if t is None:\n        t = time.time()\n\n    bps = nbyte / ((t - t0) + 0.001)\n    s1 = humansize(nbyte).replace(\" \", \"\\033[33m\").replace(\"iB\", \"\")\n    s2 = humansize(bps).replace(\" \", \"\\033[35m\").replace(\"iB\", \"\")\n    return \"{} \\033[0m{}/s\\033[0m\".format(s1, s2)\n\n\ndef s2hms(s: float, optional_h: bool = False) -> str:\n    s = int(s)\n    h, s = divmod(s, 3600)\n    m, s = divmod(s, 60)\n    if not h and optional_h:\n        return \"{}:{:02}\".format(m, s)\n\n    return \"{}:{:02}:{:02}\".format(h, m, s)\n\n\ndef djoin(*paths: str) -> str:\n    \"\"\"joins without adding a trailing slash on blank args\"\"\"\n    return os.path.join(*[x for x in paths if x])\n\n\ndef uncyg(path: str) -> str:\n    if len(path) < 2 or not path.startswith(\"/\"):\n        return path\n\n    if len(path) > 2 and path[2] != \"/\":\n        return path\n\n    return \"%s:\\\\%s\" % (path[1], path[3:])\n\n\ndef undot(path: str) -> str:\n    ret: list[str] = []\n    for node in path.split(\"/\"):\n        if node in [\"\", \".\"]:\n            continue\n\n        if node == \"..\":\n            if ret:\n                ret.pop()\n            continue\n\n        ret.append(node)\n\n    return \"/\".join(ret)\n\n\ndef sanitize_fn(fn: str, ok: str, bad: list[str]) -> str:\n    if \"/\" not in ok:\n        fn = fn.replace(\"\\\\\", \"/\").split(\"/\")[-1]\n\n    if fn.lower() in bad:\n        fn = \"_\" + fn\n\n    if ANYWIN:\n        remap = [\n            [\"<\", \"\uff1c\"],\n            [\">\", \"\uff1e\"],\n            [\":\", \"\uff1a\"],\n            ['\"', \"\uff02\"],\n            [\"/\", \"\uff0f\"],\n            [\"\\\\\", \"\uff3c\"],\n            [\"|\", \"\uff5c\"],\n            [\"?\", \"\uff1f\"],\n            [\"*\", \"\uff0a\"],\n        ]\n        for a, b in [x for x in remap if x[0] not in ok]:\n            fn = fn.replace(a, b)\n\n        bad = [\"con\", \"prn\", \"aux\", \"nul\"]\n        for n in range(1, 10):\n            bad += (\"com%s lpt%s\" % (n, n)).split(\" \")\n\n        if fn.lower().split(\".\")[0] in bad:\n            fn = \"_\" + fn\n\n    return fn.strip()\n\n\ndef relchk(rp: str) -> str:\n    if ANYWIN:\n        if \"\\n\" in rp or \"\\r\" in rp:\n            return \"x\\nx\"\n\n        p = re.sub(r'[\\\\:*?\"<>|]', \"\", rp)\n        if p != rp:\n            return \"[{}]\".format(p)\n\n    return \"\"\n\n\ndef absreal(fpath: str) -> str:\n    try:\n        return fsdec(os.path.abspath(os.path.realpath(afsenc(fpath))))\n    except:\n        if not WINDOWS:\n            raise\n\n        # cpython bug introduced in 3.8, still exists in 3.9.1,\n        # some win7sp1 and win10:20H2 boxes cannot realpath a\n        # networked drive letter such as b\"n:\" or b\"n:\\\\\"\n        return os.path.abspath(os.path.realpath(fpath))\n\n\ndef u8safe(txt: str) -> str:\n    try:\n        return txt.encode(\"utf-8\", \"xmlcharrefreplace\").decode(\"utf-8\", \"replace\")\n    except:\n        return txt.encode(\"utf-8\", \"replace\").decode(\"utf-8\", \"replace\")\n\n\ndef exclude_dotfiles(filepaths: list[str]) -> list[str]:\n    return [x for x in filepaths if not x.split(\"/\")[-1].startswith(\".\")]\n\n\ndef ipnorm(ip: str) -> str:\n    if \":\" in ip:\n        # assume /64 clients; drop 4 groups\n        return IPv6Address(ip).exploded[:-20]\n\n    return ip\n\n\ndef find_prefix(ips: list[str], netdevs: dict[str, Netdev]) -> list[str]:\n    ret = []\n    for ip in ips:\n        hit = next((x for x in netdevs if x.startswith(ip + \"/\")), None)\n        if hit:\n            ret.append(hit)\n    return ret\n\n\ndef html_escape(s: str, quot: bool = False, crlf: bool = False) -> str:\n    \"\"\"html.escape but also newlines\"\"\"\n    s = s.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n    if quot:\n        s = s.replace('\"', \"&quot;\").replace(\"'\", \"&#x27;\")\n    if crlf:\n        s = s.replace(\"\\r\", \"&#13;\").replace(\"\\n\", \"&#10;\")\n\n    return s\n\n\ndef html_bescape(s: bytes, quot: bool = False, crlf: bool = False) -> bytes:\n    \"\"\"html.escape but bytestrings\"\"\"\n    s = s.replace(b\"&\", b\"&amp;\").replace(b\"<\", b\"&lt;\").replace(b\">\", b\"&gt;\")\n    if quot:\n        s = s.replace(b'\"', b\"&quot;\").replace(b\"'\", b\"&#x27;\")\n    if crlf:\n        s = s.replace(b\"\\r\", b\"&#13;\").replace(b\"\\n\", b\"&#10;\")\n\n    return s\n\n\ndef _quotep2(txt: str) -> str:\n    \"\"\"url quoter which deals with bytes correctly\"\"\"\n    btxt = w8enc(txt)\n    quot = quote(btxt, safe=b\"/\")\n    return w8dec(quot.replace(b\" \", b\"+\"))\n\n\ndef _quotep3(txt: str) -> str:\n    \"\"\"url quoter which deals with bytes correctly\"\"\"\n    btxt = w8enc(txt)\n    quot = quote(btxt, safe=b\"/\").encode(\"utf-8\")\n    return w8dec(quot.replace(b\" \", b\"+\"))\n\n\nquotep = _quotep3 if not PY2 else _quotep2\n\n\ndef unquotep(txt: str) -> str:\n    \"\"\"url unquoter which deals with bytes correctly\"\"\"\n    btxt = w8enc(txt)\n    # btxt = btxt.replace(b\"+\", b\" \")\n    unq2 = unquote(btxt)\n    return w8dec(unq2)\n\n\ndef vsplit(vpath: str) -> tuple[str, str]:\n    if \"/\" not in vpath:\n        return \"\", vpath\n\n    return vpath.rsplit(\"/\", 1)  # type: ignore\n\n\ndef vjoin(rd: str, fn: str) -> str:\n    if rd and fn:\n        return rd + \"/\" + fn\n    else:\n        return rd or fn\n\n\ndef _w8dec2(txt: bytes) -> str:\n    \"\"\"decodes filesystem-bytes to wtf8\"\"\"\n    return surrogateescape.decodefilename(txt)\n\n\ndef _w8enc2(txt: str) -> bytes:\n    \"\"\"encodes wtf8 to filesystem-bytes\"\"\"\n    return surrogateescape.encodefilename(txt)\n\n\ndef _w8dec3(txt: bytes) -> str:\n    \"\"\"decodes filesystem-bytes to wtf8\"\"\"\n    return txt.decode(FS_ENCODING, \"surrogateescape\")\n\n\ndef _w8enc3(txt: str) -> bytes:\n    \"\"\"encodes wtf8 to filesystem-bytes\"\"\"\n    return txt.encode(FS_ENCODING, \"surrogateescape\")\n\n\ndef _msdec(txt: bytes) -> str:\n    ret = txt.decode(FS_ENCODING, \"surrogateescape\")\n    return ret[4:] if ret.startswith(\"\\\\\\\\?\\\\\") else ret\n\n\ndef _msaenc(txt: str) -> bytes:\n    return txt.replace(\"/\", \"\\\\\").encode(FS_ENCODING, \"surrogateescape\")\n\n\ndef _uncify(txt: str) -> str:\n    txt = txt.replace(\"/\", \"\\\\\")\n    if \":\" not in txt and not txt.startswith(\"\\\\\\\\\"):\n        txt = absreal(txt)\n\n    return txt if txt.startswith(\"\\\\\\\\\") else \"\\\\\\\\?\\\\\" + txt\n\n\ndef _msenc(txt: str) -> bytes:\n    txt = txt.replace(\"/\", \"\\\\\")\n    if \":\" not in txt and not txt.startswith(\"\\\\\\\\\"):\n        txt = absreal(txt)\n\n    ret = txt.encode(FS_ENCODING, \"surrogateescape\")\n    return ret if ret.startswith(b\"\\\\\\\\\") else b\"\\\\\\\\?\\\\\" + ret\n\n\nw8dec = _w8dec3 if not PY2 else _w8dec2\nw8enc = _w8enc3 if not PY2 else _w8enc2\n\n\ndef w8b64dec(txt: str) -> str:\n    \"\"\"decodes base64(filesystem-bytes) to wtf8\"\"\"\n    return w8dec(base64.urlsafe_b64decode(txt.encode(\"ascii\")))\n\n\ndef w8b64enc(txt: str) -> str:\n    \"\"\"encodes wtf8 to base64(filesystem-bytes)\"\"\"\n    return base64.urlsafe_b64encode(w8enc(txt)).decode(\"ascii\")\n\n\nif not PY2 and WINDOWS:\n    sfsenc = w8enc\n    afsenc = _msaenc\n    fsenc = _msenc\n    fsdec = _msdec\n    uncify = _uncify\nelif not PY2 or not WINDOWS:\n    fsenc = afsenc = sfsenc = w8enc\n    fsdec = w8dec\n    uncify = str\nelse:\n    # moonrunes become \\x3f with bytestrings,\n    # losing mojibake support is worth\n    def _not_actually_mbcs_enc(txt: str) -> bytes:\n        return txt\n\n    def _not_actually_mbcs_dec(txt: bytes) -> str:\n        return txt\n\n    fsenc = afsenc = sfsenc = _not_actually_mbcs_enc\n    fsdec = _not_actually_mbcs_dec\n    uncify = str\n\n\ndef s3enc(mem_cur: \"sqlite3.Cursor\", rd: str, fn: str) -> tuple[str, str]:\n    ret: list[str] = []\n    for v in [rd, fn]:\n        try:\n            mem_cur.execute(\"select * from a where b = ?\", (v,))\n            ret.append(v)\n        except:\n            ret.append(\"//\" + w8b64enc(v))\n            # self.log(\"mojien [{}] {}\".format(v, ret[-1][2:]))\n\n    return ret[0], ret[1]\n\n\ndef s3dec(rd: str, fn: str) -> tuple[str, str]:\n    return (\n        w8b64dec(rd[2:]) if rd.startswith(\"//\") else rd,\n        w8b64dec(fn[2:]) if fn.startswith(\"//\") else fn,\n    )\n\n\ndef db_ex_chk(log: \"NamedLogger\", ex: Exception, db_path: str) -> bool:\n    if str(ex) != \"database is locked\":\n        return False\n\n    Daemon(lsof, \"dbex\", (log, db_path))\n    return True\n\n\ndef lsof(log: \"NamedLogger\", abspath: str) -> None:\n    try:\n        rc, so, se = runcmd([b\"lsof\", b\"-R\", fsenc(abspath)], timeout=45)\n        zs = (so.strip() + \"\\n\" + se.strip()).strip()\n        log(\"lsof {} = {}\\n{}\".format(abspath, rc, zs), 3)\n    except:\n        log(\"lsof failed; \" + min_ex(), 3)\n\n\ndef atomic_move(usrc: str, udst: str) -> None:\n    src = fsenc(usrc)\n    dst = fsenc(udst)\n    if not PY2:\n        os.replace(src, dst)\n    else:\n        if os.path.exists(dst):\n            os.unlink(dst)\n\n        os.rename(src, dst)\n\n\ndef get_df(abspath: str) -> tuple[Optional[int], Optional[int]]:\n    try:\n        # some fuses misbehave\n        if ANYWIN:\n            bfree = ctypes.c_ulonglong(0)\n            ctypes.windll.kernel32.GetDiskFreeSpaceExW(  # type: ignore\n                ctypes.c_wchar_p(abspath), None, None, ctypes.pointer(bfree)\n            )\n            return (bfree.value, None)\n        else:\n            sv = os.statvfs(fsenc(abspath))\n            free = sv.f_frsize * sv.f_bfree\n            total = sv.f_frsize * sv.f_blocks\n            return (free, total)\n    except:\n        return (None, None)\n\n\nif not ANYWIN and not MACOS:\n\n    def siocoutq(sck: socket.socket) -> int:\n        # SIOCOUTQ^sockios.h == TIOCOUTQ^ioctl.h\n        try:\n            zb = fcntl.ioctl(sck.fileno(), termios.TIOCOUTQ, b\"AAAA\")\n            return sunpack(b\"I\", zb)[0]  # type: ignore\n        except:\n            return 1\n\nelse:\n    # macos: getsockopt(fd, SOL_SOCKET, SO_NWRITE, ...)\n    # windows: TcpConnectionEstatsSendBuff\n\n    def siocoutq(sck: socket.socket) -> int:\n        return 1\n\n\ndef shut_socket(log: \"NamedLogger\", sck: socket.socket, timeout: int = 3) -> None:\n    t0 = time.time()\n    fd = sck.fileno()\n    if fd == -1:\n        sck.close()\n        return\n\n    try:\n        sck.settimeout(timeout)\n        sck.shutdown(socket.SHUT_WR)\n        try:\n            while time.time() - t0 < timeout:\n                if not siocoutq(sck):\n                    # kernel says tx queue empty, we good\n                    break\n\n                # on windows in particular, drain rx until client shuts\n                if not sck.recv(32 * 1024):\n                    break\n\n            sck.shutdown(socket.SHUT_RDWR)\n        except:\n            pass\n    except Exception as ex:\n        log(\"shut({}): {}\".format(fd, ex), \"90\")\n    finally:\n        td = time.time() - t0\n        if td >= 1:\n            log(\"shut({}) in {:.3f} sec\".format(fd, td), \"90\")\n\n        sck.close()\n\n\ndef read_socket(sr: Unrecv, total_size: int) -> Generator[bytes, None, None]:\n    remains = total_size\n    while remains > 0:\n        bufsz = 32 * 1024\n        if bufsz > remains:\n            bufsz = remains\n\n        try:\n            buf = sr.recv(bufsz)\n        except OSError:\n            t = \"client d/c during binary post after {} bytes, {} bytes remaining\"\n            raise Pebkac(400, t.format(total_size - remains, remains))\n\n        remains -= len(buf)\n        yield buf\n\n\ndef read_socket_unbounded(sr: Unrecv) -> Generator[bytes, None, None]:\n    try:\n        while True:\n            yield sr.recv(32 * 1024)\n    except:\n        return\n\n\ndef read_socket_chunked(\n    sr: Unrecv, log: Optional[\"NamedLogger\"] = None\n) -> Generator[bytes, None, None]:\n    err = \"upload aborted: expected chunk length, got [{}] |{}| instead\"\n    while True:\n        buf = b\"\"\n        while b\"\\r\" not in buf:\n            try:\n                buf += sr.recv(2)\n                if len(buf) > 16:\n                    raise Exception()\n            except:\n                err = err.format(buf.decode(\"utf-8\", \"replace\"), len(buf))\n                raise Pebkac(400, err)\n\n        if not buf.endswith(b\"\\n\"):\n            sr.recv(1)\n\n        try:\n            chunklen = int(buf.rstrip(b\"\\r\\n\"), 16)\n        except:\n            err = err.format(buf.decode(\"utf-8\", \"replace\"), len(buf))\n            raise Pebkac(400, err)\n\n        if chunklen == 0:\n            x = sr.recv_ex(2, False)\n            if x == b\"\\r\\n\":\n                return\n\n            t = \"protocol error after final chunk: want b'\\\\r\\\\n', got {!r}\"\n            raise Pebkac(400, t.format(x))\n\n        if log:\n            log(\"receiving {} byte chunk\".format(chunklen))\n\n        for chunk in read_socket(sr, chunklen):\n            yield chunk\n\n        x = sr.recv_ex(2, False)\n        if x != b\"\\r\\n\":\n            t = \"protocol error in chunk separator: want b'\\\\r\\\\n', got {!r}\"\n            raise Pebkac(400, t.format(x))\n\n\ndef list_ips() -> list[str]:\n    from .stolen.ifaddr import get_adapters\n\n    ret: set[str] = set()\n    for nic in get_adapters():\n        for ipo in nic.ips:\n            if len(ipo.ip) < 7:\n                ret.add(ipo.ip[0])  # ipv6 is (ip,0,0)\n            else:\n                ret.add(ipo.ip)\n\n    return list(ret)\n\n\ndef yieldfile(fn: str) -> Generator[bytes, None, None]:\n    with open(fsenc(fn), \"rb\", 512 * 1024) as f:\n        while True:\n            buf = f.read(64 * 1024)\n            if not buf:\n                break\n\n            yield buf\n\n\ndef hashcopy(\n    fin: Generator[bytes, None, None],\n    fout: Union[typing.BinaryIO, typing.IO[Any]],\n    slp: int = 0,\n    max_sz: int = 0,\n) -> tuple[int, str, str]:\n    hashobj = hashlib.sha512()\n    tlen = 0\n    for buf in fin:\n        tlen += len(buf)\n        if max_sz and tlen > max_sz:\n            continue\n\n        hashobj.update(buf)\n        fout.write(buf)\n        if slp:\n            time.sleep(slp)\n\n    digest = hashobj.digest()[:33]\n    digest_b64 = base64.urlsafe_b64encode(digest).decode(\"utf-8\")\n\n    return tlen, hashobj.hexdigest(), digest_b64\n\n\ndef sendfile_py(\n    log: \"NamedLogger\",\n    lower: int,\n    upper: int,\n    f: typing.BinaryIO,\n    s: socket.socket,\n    bufsz: int,\n    slp: int,\n) -> int:\n    remains = upper - lower\n    f.seek(lower)\n    while remains > 0:\n        if slp:\n            time.sleep(slp)\n\n        buf = f.read(min(bufsz, remains))\n        if not buf:\n            return remains\n\n        try:\n            s.sendall(buf)\n            remains -= len(buf)\n        except:\n            return remains\n\n    return 0\n\n\ndef sendfile_kern(\n    log: \"NamedLogger\",\n    lower: int,\n    upper: int,\n    f: typing.BinaryIO,\n    s: socket.socket,\n    bufsz: int,\n    slp: int,\n) -> int:\n    out_fd = s.fileno()\n    in_fd = f.fileno()\n    ofs = lower\n    stuck = 0.0\n    while ofs < upper:\n        stuck = stuck or time.time()\n        try:\n            req = min(2 ** 30, upper - ofs)\n            select.select([], [out_fd], [], 10)\n            n = os.sendfile(out_fd, in_fd, ofs, req)\n            stuck = 0\n        except OSError as ex:\n            # client stopped reading; do another select\n            d = time.time() - stuck\n            if d < 3600 and ex.errno == errno.EWOULDBLOCK:\n                continue\n\n            n = 0\n        except Exception as ex:\n            n = 0\n            d = time.time() - stuck\n            log(\"sendfile failed after {:.3f} sec: {!r}\".format(d, ex))\n\n        if n <= 0:\n            return upper - ofs\n\n        ofs += n\n        # print(\"sendfile: ok, sent {} now, {} total, {} remains\".format(n, ofs - lower, upper - ofs))\n\n    return 0\n\n\ndef statdir(\n    logger: Optional[\"RootLogger\"], scandir: bool, lstat: bool, top: str\n) -> Generator[tuple[str, os.stat_result], None, None]:\n    if lstat and ANYWIN:\n        lstat = False\n\n    if lstat and (PY2 or os.stat not in os.supports_follow_symlinks):\n        scandir = False\n\n    src = \"statdir\"\n    try:\n        btop = fsenc(top)\n        if scandir and hasattr(os, \"scandir\"):\n            src = \"scandir\"\n            with os.scandir(btop) as dh:\n                for fh in dh:\n                    try:\n                        yield (fsdec(fh.name), fh.stat(follow_symlinks=not lstat))\n                    except Exception as ex:\n                        if not logger:\n                            continue\n\n                        logger(src, \"[s] {} @ {}\".format(repr(ex), fsdec(fh.path)), 6)\n        else:\n            src = \"listdir\"\n            fun: Any = os.lstat if lstat else os.stat\n            for name in os.listdir(btop):\n                abspath = os.path.join(btop, name)\n                try:\n                    yield (fsdec(name), fun(abspath))\n                except Exception as ex:\n                    if not logger:\n                        continue\n\n                    logger(src, \"[s] {} @ {}\".format(repr(ex), fsdec(abspath)), 6)\n\n    except Exception as ex:\n        t = \"{} @ {}\".format(repr(ex), top)\n        if logger:\n            logger(src, t, 1)\n        else:\n            print(t)\n\n\ndef rmdirs(\n    logger: \"RootLogger\", scandir: bool, lstat: bool, top: str, depth: int\n) -> tuple[list[str], list[str]]:\n    \"\"\"rmdir all descendants, then self\"\"\"\n    if not os.path.isdir(fsenc(top)):\n        top = os.path.dirname(top)\n        depth -= 1\n\n    stats = statdir(logger, scandir, lstat, top)\n    dirs = [x[0] for x in stats if stat.S_ISDIR(x[1].st_mode)]\n    dirs = [os.path.join(top, x) for x in dirs]\n    ok = []\n    ng = []\n    for d in reversed(dirs):\n        a, b = rmdirs(logger, scandir, lstat, d, depth + 1)\n        ok += a\n        ng += b\n\n    if depth:\n        try:\n            os.rmdir(fsenc(top))\n            ok.append(top)\n        except:\n            ng.append(top)\n\n    return ok, ng\n\n\ndef rmdirs_up(top: str, stop: str) -> tuple[list[str], list[str]]:\n    \"\"\"rmdir on self, then all parents\"\"\"\n    if top == stop:\n        return [], [top]\n\n    try:\n        os.rmdir(fsenc(top))\n    except:\n        return [], [top]\n\n    par = os.path.dirname(top)\n    if not par or par == stop:\n        return [top], []\n\n    ok, ng = rmdirs_up(par, stop)\n    return [top] + ok, ng\n\n\ndef unescape_cookie(orig: str) -> str:\n    # mw=idk; doot=qwe%2Crty%3Basd+fgh%2Bjkl%25zxc%26vbn  # qwe,rty;asd fgh+jkl%zxc&vbn\n    ret = \"\"\n    esc = \"\"\n    for ch in orig:\n        if ch == \"%\":\n            if len(esc) > 0:\n                ret += esc\n            esc = ch\n\n        elif len(esc) > 0:\n            esc += ch\n            if len(esc) == 3:\n                try:\n                    ret += chr(int(esc[1:], 16))\n                except:\n                    ret += esc\n                esc = \"\"\n\n        else:\n            ret += ch\n\n    if len(esc) > 0:\n        ret += esc\n\n    return ret\n\n\ndef guess_mime(url: str, fallback: str = \"application/octet-stream\") -> str:\n    try:\n        _, ext = url.rsplit(\".\", 1)\n    except:\n        return fallback\n\n    ret = MIMES.get(ext)\n\n    if not ret:\n        x = mimetypes.guess_type(url)\n        ret = \"application/{}\".format(x[1]) if x[1] else x[0]\n\n    if not ret:\n        ret = fallback\n\n    if \";\" not in ret:\n        if ret.startswith(\"text/\") or ret.endswith(\"/javascript\"):\n            ret += \"; charset=utf-8\"\n\n    return ret\n\n\ndef getalive(pids: list[int], pgid: int) -> list[int]:\n    alive = []\n    for pid in pids:\n        try:\n            if pgid:\n                # check if still one of ours\n                if os.getpgid(pid) == pgid:\n                    alive.append(pid)\n            else:\n                # windows doesn't have pgroups; assume\n                psutil.Process(pid)\n                alive.append(pid)\n        except:\n            pass\n\n    return alive\n\n\ndef killtree(root: int) -> None:\n    \"\"\"still racy but i tried\"\"\"\n    try:\n        # limit the damage where possible (unixes)\n        pgid = os.getpgid(os.getpid())\n    except:\n        pgid = 0\n\n    if HAVE_PSUTIL:\n        pids = [root]\n        parent = psutil.Process(root)\n        for child in parent.children(recursive=True):\n            pids.append(child.pid)\n            child.terminate()\n        parent.terminate()\n        parent = None\n    elif pgid:\n        # linux-only\n        pids = []\n        chk = [root]\n        while chk:\n            pid = chk[0]\n            chk = chk[1:]\n            pids.append(pid)\n            _, t, _ = runcmd([\"pgrep\", \"-P\", str(pid)])\n            chk += [int(x) for x in t.strip().split(\"\\n\") if x]\n\n        pids = getalive(pids, pgid)  # filter to our pgroup\n        for pid in pids:\n            os.kill(pid, signal.SIGTERM)\n    else:\n        # windows gets minimal effort sorry\n        os.kill(root, signal.SIGTERM)\n        return\n\n    for n in range(10):\n        time.sleep(0.1)\n        pids = getalive(pids, pgid)\n        if not pids or n > 3 and pids == [root]:\n            break\n\n    for pid in pids:\n        try:\n            os.kill(pid, signal.SIGKILL)\n        except:\n            pass\n\n\ndef runcmd(\n    argv: Union[list[bytes], list[str]], timeout: Optional[float] = None, **ka: Any\n) -> tuple[int, str, str]:\n    kill = ka.pop(\"kill\", \"t\")  # [t]ree [m]ain [n]one\n    capture = ka.pop(\"capture\", 3)  # 0=none 1=stdout 2=stderr 3=both\n\n    sin: Optional[bytes] = ka.pop(\"sin\", None)\n    if sin:\n        ka[\"stdin\"] = sp.PIPE\n\n    cout = sp.PIPE if capture in [1, 3] else None\n    cerr = sp.PIPE if capture in [2, 3] else None\n    bout: bytes\n    berr: bytes\n\n    p = sp.Popen(argv, stdout=cout, stderr=cerr, **ka)\n    if not timeout or PY2:\n        bout, berr = p.communicate(sin)\n    else:\n        try:\n            bout, berr = p.communicate(sin, timeout=timeout)\n        except sp.TimeoutExpired:\n            if kill == \"n\":\n                return -18, \"\", \"\"  # SIGCONT; leave it be\n            elif kill == \"m\":\n                p.kill()\n            else:\n                killtree(p.pid)\n\n            try:\n                bout, berr = p.communicate(timeout=1)\n            except:\n                bout = b\"\"\n                berr = b\"\"\n\n    stdout = bout.decode(\"utf-8\", \"replace\") if cout else \"\"\n    stderr = berr.decode(\"utf-8\", \"replace\") if cerr else \"\"\n\n    rc: int = p.returncode\n    if rc is None:\n        rc = -14  # SIGALRM; failed to kill\n\n    return rc, stdout, stderr\n\n\ndef chkcmd(argv: Union[list[bytes], list[str]], **ka: Any) -> tuple[str, str]:\n    ok, sout, serr = runcmd(argv, **ka)\n    if ok != 0:\n        retchk(ok, argv, serr)\n        raise Exception(serr)\n\n    return sout, serr\n\n\ndef mchkcmd(argv: Union[list[bytes], list[str]], timeout: float = 10) -> None:\n    if PY2:\n        with open(os.devnull, \"wb\") as f:\n            rv = sp.call(argv, stdout=f, stderr=f)\n    else:\n        rv = sp.call(argv, stdout=sp.DEVNULL, stderr=sp.DEVNULL, timeout=timeout)\n\n    if rv:\n        raise sp.CalledProcessError(rv, (argv[0], b\"...\", argv[-1]))\n\n\ndef retchk(\n    rc: int,\n    cmd: Union[list[bytes], list[str]],\n    serr: str,\n    logger: Optional[\"NamedLogger\"] = None,\n    color: Union[int, str] = 0,\n    verbose: bool = False,\n) -> None:\n    if rc < 0:\n        rc = 128 - rc\n\n    if not rc or rc < 126 and not verbose:\n        return\n\n    s = None\n    if rc > 128:\n        try:\n            s = str(signal.Signals(rc - 128))\n        except:\n            pass\n    elif rc == 126:\n        s = \"invalid program\"\n    elif rc == 127:\n        s = \"program not found\"\n    elif verbose:\n        s = \"unknown\"\n    else:\n        s = \"invalid retcode\"\n\n    if s:\n        t = \"{} <{}>\".format(rc, s)\n    else:\n        t = str(rc)\n\n    try:\n        c = \" \".join([fsdec(x) for x in cmd])  # type: ignore\n    except:\n        c = str(cmd)\n\n    t = \"error {} from [{}]\".format(t, c)\n    if serr:\n        t += \"\\n\" + serr\n\n    if logger:\n        logger(t, color)\n    else:\n        raise Exception(t)\n\n\ndef _parsehook(\n    log: Optional[\"NamedLogger\"], cmd: str\n) -> tuple[bool, bool, bool, float, dict[str, Any], str]:\n    chk = False\n    fork = False\n    jtxt = False\n    wait = 0.0\n    tout = 0.0\n    kill = \"t\"\n    cap = 0\n    ocmd = cmd\n    while \",\" in cmd[:6]:\n        arg, cmd = cmd.split(\",\", 1)\n        if arg == \"c\":\n            chk = True\n        elif arg == \"f\":\n            fork = True\n        elif arg == \"j\":\n            jtxt = True\n        elif arg.startswith(\"w\"):\n            wait = float(arg[1:])\n        elif arg.startswith(\"t\"):\n            tout = float(arg[1:])\n        elif arg.startswith(\"c\"):\n            cap = int(arg[1:])  # 0=none 1=stdout 2=stderr 3=both\n        elif arg.startswith(\"k\"):\n            kill = arg[1:]  # [t]ree [m]ain [n]one\n        elif arg.startswith(\"i\"):\n            pass\n        else:\n            t = \"hook: invalid flag {} in {}\"\n            (log or print)(t.format(arg, ocmd))\n\n    env = os.environ.copy()\n    try:\n        if EXE:\n            raise Exception()\n\n        pypath = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n        zsl = [str(pypath)] + [str(x) for x in sys.path if x]\n        pypath = str(os.pathsep.join(zsl))\n        env[\"PYTHONPATH\"] = pypath\n    except:\n        if not EXE:\n            raise\n\n    sp_ka = {\n        \"env\": env,\n        \"timeout\": tout,\n        \"kill\": kill,\n        \"capture\": cap,\n    }\n\n    if cmd.startswith(\"~\"):\n        cmd = os.path.expanduser(cmd)\n\n    return chk, fork, jtxt, wait, sp_ka, cmd\n\n\ndef runihook(\n    log: Optional[\"NamedLogger\"],\n    cmd: str,\n    vol: \"VFS\",\n    ups: list[tuple[str, int, int, str, str, str, int]],\n) -> bool:\n    ocmd = cmd\n    chk, fork, jtxt, wait, sp_ka, cmd = _parsehook(log, cmd)\n    bcmd = [sfsenc(cmd)]\n    if cmd.endswith(\".py\"):\n        bcmd = [sfsenc(pybin)] + bcmd\n\n    vps = [vjoin(*list(s3dec(x[3], x[4]))) for x in ups]\n    aps = [djoin(vol.realpath, x) for x in vps]\n    if jtxt:\n        # 0w 1mt 2sz 3rd 4fn 5ip 6at\n        ja = [\n            {\n                \"ap\": uncify(ap),  # utf8 for json\n                \"vp\": vp,\n                \"wark\": x[0][:16],\n                \"mt\": x[1],\n                \"sz\": x[2],\n                \"ip\": x[5],\n                \"at\": x[6],\n            }\n            for x, vp, ap in zip(ups, vps, aps)\n        ]\n        sp_ka[\"sin\"] = json.dumps(ja).encode(\"utf-8\", \"replace\")\n    else:\n        sp_ka[\"sin\"] = b\"\\n\".join(fsenc(x) for x in aps)\n\n    t0 = time.time()\n    if fork:\n        Daemon(runcmd, ocmd, [bcmd], ka=sp_ka)\n    else:\n        rc, v, err = runcmd(bcmd, **sp_ka)  # type: ignore\n        if chk and rc:\n            retchk(rc, bcmd, err, log, 5)\n            return False\n\n    wait -= time.time() - t0\n    if wait > 0:\n        time.sleep(wait)\n\n    return True\n\n\ndef _runhook(\n    log: Optional[\"NamedLogger\"],\n    cmd: str,\n    ap: str,\n    vp: str,\n    host: str,\n    uname: str,\n    mt: float,\n    sz: int,\n    ip: str,\n    at: float,\n    txt: str,\n) -> bool:\n    ocmd = cmd\n    chk, fork, jtxt, wait, sp_ka, cmd = _parsehook(log, cmd)\n    if jtxt:\n        ja = {\n            \"ap\": ap,\n            \"vp\": vp,\n            \"mt\": mt,\n            \"sz\": sz,\n            \"ip\": ip,\n            \"at\": at or time.time(),\n            \"host\": host,\n            \"user\": uname,\n            \"txt\": txt,\n        }\n        arg = json.dumps(ja)\n    else:\n        arg = txt or ap\n\n    acmd = [cmd, arg]\n    if cmd.endswith(\".py\"):\n        acmd = [pybin] + acmd\n\n    bcmd = [fsenc(x) if x == ap else sfsenc(x) for x in acmd]\n\n    t0 = time.time()\n    if fork:\n        Daemon(runcmd, ocmd, [bcmd], ka=sp_ka)\n    else:\n        rc, v, err = runcmd(bcmd, **sp_ka)  # type: ignore\n        if chk and rc:\n            retchk(rc, bcmd, err, log, 5)\n            return False\n\n    wait -= time.time() - t0\n    if wait > 0:\n        time.sleep(wait)\n\n    return True\n\n\ndef runhook(\n    log: Optional[\"NamedLogger\"],\n    cmds: list[str],\n    ap: str,\n    vp: str,\n    host: str,\n    uname: str,\n    mt: float,\n    sz: int,\n    ip: str,\n    at: float,\n    txt: str,\n) -> bool:\n    vp = vp.replace(\"\\\\\", \"/\")\n    for cmd in cmds:\n        try:\n            if not _runhook(log, cmd, ap, vp, host, uname, mt, sz, ip, at, txt):\n                return False\n        except Exception as ex:\n            (log or print)(\"hook: {}\".format(ex))\n            if \",c,\" in \",\" + cmd:\n                return False\n            break\n\n    return True\n\n\ndef loadpy(ap: str, hot: bool) -> Any:\n    \"\"\"\n    a nice can of worms capable of causing all sorts of bugs\n    depending on what other inconveniently named files happen\n    to be in the same folder\n    \"\"\"\n    if ap.startswith(\"~\"):\n        ap = os.path.expanduser(ap)\n\n    mdir, mfile = os.path.split(absreal(ap))\n    mname = mfile.rsplit(\".\", 1)[0]\n    sys.path.insert(0, mdir)\n\n    if PY2:\n        mod = __import__(mname)\n        if hot:\n            reload(mod)\n    else:\n        import importlib\n\n        mod = importlib.import_module(mname)\n        if hot:\n            importlib.reload(mod)\n\n    sys.path.remove(mdir)\n    return mod\n\n\ndef gzip_orig_sz(fn: str) -> int:\n    with open(fsenc(fn), \"rb\") as f:\n        f.seek(-4, 2)\n        rv = f.read(4)\n        return sunpack(b\"I\", rv)[0]  # type: ignore\n\n\ndef align_tab(lines: list[str]) -> list[str]:\n    rows = []\n    ncols = 0\n    for ln in lines:\n        row = [x for x in ln.split(\" \") if x]\n        ncols = max(ncols, len(row))\n        rows.append(row)\n\n    lens = [0] * ncols\n    for row in rows:\n        for n, col in enumerate(row):\n            lens[n] = max(lens[n], len(col))\n\n    return [\"\".join(x.ljust(y + 2) for x, y in zip(row, lens)) for row in rows]\n\n\ndef visual_length(txt: str) -> int:\n    # from r0c\n    eoc = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n    clen = 0\n    pend = None\n    counting = True\n    for ch in txt:\n\n        # escape sequences can never contain ESC;\n        # treat pend as regular text if so\n        if ch == \"\\033\" and pend:\n            clen += len(pend)\n            counting = True\n            pend = None\n\n        if not counting:\n            if ch in eoc:\n                counting = True\n        else:\n            if pend:\n                pend += ch\n                if pend.startswith(\"\\033[\"):\n                    counting = False\n                else:\n                    clen += len(pend)\n                    counting = True\n                pend = None\n            else:\n                if ch == \"\\033\":\n                    pend = \"{0}\".format(ch)\n                else:\n                    co = ord(ch)\n                    # the safe parts of latin1 and cp437 (no greek stuff)\n                    if (\n                        co < 0x100  # ascii + lower half of latin1\n                        or (co >= 0x2500 and co <= 0x25A0)  # box drawings\n                        or (co >= 0x2800 and co <= 0x28FF)  # braille\n                    ):\n                        clen += 1\n                    else:\n                        # assume moonrunes or other double-width\n                        clen += 2\n    return clen\n\n\ndef wrap(txt: str, maxlen: int, maxlen2: int) -> list[str]:\n    # from r0c\n    words = re.sub(r\"([, ])\", r\"\\1\\n\", txt.rstrip()).split(\"\\n\")\n    pad = maxlen - maxlen2\n    ret = []\n    for word in words:\n        if len(word) * 2 < maxlen or visual_length(word) < maxlen:\n            ret.append(word)\n        else:\n            while visual_length(word) >= maxlen:\n                ret.append(word[: maxlen - 1] + \"-\")\n                word = word[maxlen - 1 :]\n            if word:\n                ret.append(word)\n\n    words = ret\n    ret = []\n    ln = \"\"\n    spent = 0\n    for word in words:\n        wl = visual_length(word)\n        if spent + wl > maxlen:\n            ret.append(ln)\n            maxlen = maxlen2\n            spent = 0\n            ln = \" \" * pad\n        ln += word\n        spent += wl\n    if ln:\n        ret.append(ln)\n\n    return ret\n\n\ndef termsize() -> tuple[int, int]:\n    # from hashwalk\n    env = os.environ\n\n    def ioctl_GWINSZ(fd: int) -> Optional[tuple[int, int]]:\n        try:\n            cr = sunpack(b\"hh\", fcntl.ioctl(fd, termios.TIOCGWINSZ, b\"AAAA\"))\n            return cr[::-1]\n        except:\n            return None\n\n    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)\n    if not cr:\n        try:\n            fd = os.open(os.ctermid(), os.O_RDONLY)\n            cr = ioctl_GWINSZ(fd)\n            os.close(fd)\n        except:\n            pass\n\n    try:\n        return cr or (int(env[\"COLUMNS\"]), int(env[\"LINES\"]))\n    except:\n        return 80, 25\n\n\ndef hidedir(dp) -> None:\n    if ANYWIN:\n        try:\n            k32 = ctypes.WinDLL(\"kernel32\")\n            attrs = k32.GetFileAttributesW(dp)\n            if attrs >= 0:\n                k32.SetFileAttributesW(dp, attrs | 2)\n        except:\n            pass\n\n\nclass Pebkac(Exception):\n    def __init__(self, code: int, msg: Optional[str] = None) -> None:\n        super(Pebkac, self).__init__(msg or HTTPCODE[code])\n        self.code = code\n\n    def __repr__(self) -> str:\n        return \"Pebkac({}, {})\".format(self.code, repr(self.args))\n"], "fixing_code": ["# coding: utf-8\nfrom __future__ import print_function, unicode_literals\n\nimport argparse  # typechk\nimport base64\nimport calendar\nimport copy\nimport errno\nimport gzip\nimport itertools\nimport json\nimport os\nimport random\nimport re\nimport stat\nimport string\nimport threading  # typechk\nimport time\nimport uuid\nfrom datetime import datetime\nfrom email.utils import formatdate, parsedate\nfrom operator import itemgetter\n\nimport jinja2  # typechk\n\ntry:\n    import lzma\nexcept:\n    pass\n\nfrom .__init__ import ANYWIN, PY2, TYPE_CHECKING, EnvParams, unicode\nfrom .__version__ import S_VERSION\nfrom .authsrv import VFS  # typechk\nfrom .bos import bos\nfrom .star import StreamTar\nfrom .sutil import StreamArc  # typechk\nfrom .szip import StreamZip\nfrom .util import (\n    HTTPCODE,\n    META_NOBOTS,\n    MultipartParser,\n    Pebkac,\n    UnrecvEOF,\n    alltrace,\n    absreal,\n    atomic_move,\n    exclude_dotfiles,\n    fsenc,\n    gen_filekey,\n    gen_filekey_dbg,\n    gencookie,\n    get_df,\n    get_spd,\n    guess_mime,\n    gzip_orig_sz,\n    hashcopy,\n    hidedir,\n    html_bescape,\n    html_escape,\n    humansize,\n    ipnorm,\n    loadpy,\n    min_ex,\n    quotep,\n    rand_name,\n    read_header,\n    read_socket,\n    read_socket_chunked,\n    read_socket_unbounded,\n    relchk,\n    ren_open,\n    runhook,\n    s3enc,\n    sanitize_fn,\n    sendfile_kern,\n    sendfile_py,\n    undot,\n    unescape_cookie,\n    unquote,\n    unquotep,\n    vjoin,\n    vol_san,\n    vsplit,\n    yieldfile,\n)\n\nif True:  # pylint: disable=using-constant-test\n    import typing\n    from typing import Any, Generator, Match, Optional, Pattern, Type, Union\n\nif TYPE_CHECKING:\n    from .httpconn import HttpConn\n\n_ = (argparse, threading)\n\nNO_CACHE = {\"Cache-Control\": \"no-cache\"}\n\n\nclass HttpCli(object):\n    \"\"\"\n    Spawned by HttpConn to process one http transaction\n    \"\"\"\n\n    def __init__(self, conn: \"HttpConn\") -> None:\n        assert conn.sr\n\n        self.t0 = time.time()\n        self.conn = conn\n        self.mutex = conn.mutex  # mypy404\n        self.s = conn.s\n        self.sr = conn.sr\n        self.ip = conn.addr[0]\n        self.addr: tuple[str, int] = conn.addr\n        self.args = conn.args  # mypy404\n        self.E: EnvParams = self.args.E\n        self.asrv = conn.asrv  # mypy404\n        self.ico = conn.ico  # mypy404\n        self.thumbcli = conn.thumbcli  # mypy404\n        self.u2fh = conn.u2fh  # mypy404\n        self.log_func = conn.log_func  # mypy404\n        self.log_src = conn.log_src  # mypy404\n        self.gen_fk = self._gen_fk if self.args.log_fk else gen_filekey\n        self.tls: bool = hasattr(self.s, \"cipher\")\n\n        # placeholders; assigned by run()\n        self.keepalive = False\n        self.is_https = False\n        self.is_vproxied = False\n        self.in_hdr_recv = True\n        self.headers: dict[str, str] = {}\n        self.mode = \" \"\n        self.req = \" \"\n        self.http_ver = \" \"\n        self.host = \" \"\n        self.ua = \" \"\n        self.is_rclone = False\n        self.ouparam: dict[str, str] = {}\n        self.uparam: dict[str, str] = {}\n        self.cookies: dict[str, str] = {}\n        self.avn: Optional[VFS] = None\n        self.vn = self.asrv.vfs\n        self.rem = \" \"\n        self.vpath = \" \"\n        self.uname = \" \"\n        self.pw = \" \"\n        self.rvol = [\" \"]\n        self.wvol = [\" \"]\n        self.mvol = [\" \"]\n        self.dvol = [\" \"]\n        self.gvol = [\" \"]\n        self.upvol = [\" \"]\n        self.avol = [\" \"]\n        self.do_log = True\n        self.can_read = False\n        self.can_write = False\n        self.can_move = False\n        self.can_delete = False\n        self.can_get = False\n        self.can_upget = False\n        self.can_admin = False\n        # post\n        self.parser: Optional[MultipartParser] = None\n        # end placeholders\n\n        self.bufsz = 1024 * 32\n        self.hint = \"\"\n        self.trailing_slash = True\n        self.out_headerlist: list[tuple[str, str]] = []\n        self.out_headers = {\n            \"Vary\": \"Origin, PW, Cookie\",\n            \"Cache-Control\": \"no-store, max-age=0\",\n        }\n        h = self.args.html_head\n        if self.args.no_robots:\n            h = META_NOBOTS + ((\"\\n\" + h) if h else \"\")\n            self.out_headers[\"X-Robots-Tag\"] = \"noindex, nofollow\"\n        self.html_head = h\n\n    def log(self, msg: str, c: Union[int, str] = 0) -> None:\n        ptn = self.asrv.re_pwd\n        if ptn and ptn.search(msg):\n            if self.asrv.ah.on:\n                msg = ptn.sub(\"\\033[7m pw \\033[27m\", msg)\n            else:\n                msg = ptn.sub(self.unpwd, msg)\n\n        self.log_func(self.log_src, msg, c)\n\n    def unpwd(self, m: Match[str]) -> str:\n        a, b, c = m.groups()\n        return \"{}\\033[7m {} \\033[27m{}\".format(a, self.asrv.iacct[b], c)\n\n    def _check_nonfatal(self, ex: Pebkac, post: bool) -> bool:\n        if post:\n            return ex.code < 300\n\n        return ex.code < 400 or ex.code in [404, 429]\n\n    def _assert_safe_rem(self, rem: str) -> None:\n        # sanity check to prevent any disasters\n        if rem.startswith(\"/\") or rem.startswith(\"../\") or \"/../\" in rem:\n            raise Exception(\"that was close\")\n\n    def _gen_fk(self, salt: str, fspath: str, fsize: int, inode: int) -> str:\n        return gen_filekey_dbg(salt, fspath, fsize, inode, self.log, self.args.log_fk)\n\n    def j2s(self, name: str, **ka: Any) -> str:\n        tpl = self.conn.hsrv.j2[name]\n        ka[\"r\"] = self.args.SR if self.is_vproxied else \"\"\n        ka[\"ts\"] = self.conn.hsrv.cachebuster()\n        ka[\"lang\"] = self.args.lang\n        ka[\"favico\"] = self.args.favico\n        ka[\"svcname\"] = self.args.doctitle\n        ka[\"html_head\"] = self.html_head\n        return tpl.render(**ka)  # type: ignore\n\n    def j2j(self, name: str) -> jinja2.Template:\n        return self.conn.hsrv.j2[name]\n\n    def run(self) -> bool:\n        \"\"\"returns true if connection can be reused\"\"\"\n        self.keepalive = False\n        self.is_https = False\n        self.headers = {}\n        self.hint = \"\"\n\n        if self.is_banned():\n            return False\n\n        try:\n            self.s.settimeout(2)\n            headerlines = read_header(self.sr, self.args.s_thead, self.args.s_thead)\n            self.in_hdr_recv = False\n            if not headerlines:\n                return False\n\n            if not headerlines[0]:\n                # seen after login with IE6.0.2900.5512.xpsp.080413-2111 (xp-sp3)\n                self.log(\"BUG: trailing newline from previous request\", c=\"1;31\")\n                headerlines.pop(0)\n\n            try:\n                self.mode, self.req, self.http_ver = headerlines[0].split(\" \")\n\n                # normalize incoming headers to lowercase;\n                # outgoing headers however are Correct-Case\n                for header_line in headerlines[1:]:\n                    k, zs = header_line.split(\":\", 1)\n                    self.headers[k.lower()] = zs.strip()\n            except:\n                msg = \" ]\\n#[ \".join(headerlines)\n                raise Pebkac(400, \"bad headers:\\n#[ \" + msg + \" ]\")\n\n        except Pebkac as ex:\n            self.mode = \"GET\"\n            self.req = \"[junk]\"\n            self.http_ver = \"HTTP/1.1\"\n            # self.log(\"pebkac at httpcli.run #1: \" + repr(ex))\n            self.keepalive = False\n            h = {\"WWW-Authenticate\": 'Basic realm=\"a\"'} if ex.code == 401 else {}\n            try:\n                self.loud_reply(unicode(ex), status=ex.code, headers=h, volsan=True)\n                return self.keepalive\n            except:\n                return False\n\n        self.ua = self.headers.get(\"user-agent\", \"\")\n        self.is_rclone = self.ua.startswith(\"rclone/\")\n\n        zs = self.headers.get(\"connection\", \"\").lower()\n        self.keepalive = \"close\" not in zs and (\n            self.http_ver != \"HTTP/1.0\" or zs == \"keep-alive\"\n        )\n        self.is_https = (\n            self.headers.get(\"x-forwarded-proto\", \"\").lower() == \"https\" or self.tls\n        )\n        self.host = self.headers.get(\"host\") or \"\"\n        if not self.host:\n            zs = \"%s:%s\" % self.s.getsockname()[:2]\n            self.host = zs[7:] if zs.startswith(\"::ffff:\") else zs\n\n        n = self.args.rproxy\n        if n:\n            zso = self.headers.get(\"x-forwarded-for\")\n            if zso and self.conn.addr[0] in [\"127.0.0.1\", \"::1\"]:\n                if n > 0:\n                    n -= 1\n\n                zsl = zso.split(\",\")\n                try:\n                    self.ip = zsl[n].strip()\n                except:\n                    self.ip = zsl[0].strip()\n                    t = \"rproxy={} oob x-fwd {}\"\n                    self.log(t.format(self.args.rproxy, zso), c=3)\n\n                self.log_src = self.conn.set_rproxy(self.ip)\n                self.is_vproxied = bool(self.args.R)\n                self.host = self.headers.get(\"x-forwarded-host\") or self.host\n\n        if self.is_banned():\n            return False\n\n        if self.conn.aclose:\n            nka = self.conn.aclose\n            ip = ipnorm(self.ip)\n            if ip in nka:\n                rt = nka[ip] - time.time()\n                if rt < 0:\n                    self.log(\"client uncapped\", 3)\n                    del nka[ip]\n                else:\n                    self.keepalive = False\n\n        ptn: Optional[Pattern[str]] = self.conn.lf_url  # mypy404\n        self.do_log = not ptn or not ptn.search(self.req)\n\n        if self.args.ihead and self.do_log:\n            keys = self.args.ihead\n            if \"*\" in keys:\n                keys = list(sorted(self.headers.keys()))\n\n            for k in keys:\n                zso = self.headers.get(k)\n                if zso is not None:\n                    self.log(\"[H] {}: \\033[33m[{}]\".format(k, zso), 6)\n\n        if \"&\" in self.req and \"?\" not in self.req:\n            self.hint = \"did you mean '?' instead of '&'\"\n\n        # split req into vpath + uparam\n        uparam = {}\n        if \"?\" not in self.req:\n            self.trailing_slash = self.req.endswith(\"/\")\n            vpath = undot(self.req)\n        else:\n            vpath, arglist = self.req.split(\"?\", 1)\n            self.trailing_slash = vpath.endswith(\"/\")\n            vpath = undot(vpath)\n\n            zs = unquotep(arglist)\n            m = self.conn.hsrv.ptn_cc.search(zs)\n            if m:\n                hit = zs[m.span()[0] :]\n                t = \"malicious user; Cc in query [{}] => [{!r}]\"\n                self.log(t.format(self.req, hit), 1)\n                return False\n\n            for k in arglist.split(\"&\"):\n                if \"=\" in k:\n                    k, zs = k.split(\"=\", 1)\n                    uparam[k.lower()] = unquotep(zs.strip().replace(\"+\", \" \"))\n                else:\n                    uparam[k.lower()] = \"\"\n\n        if self.is_vproxied:\n            if vpath.startswith(self.args.R):\n                vpath = vpath[len(self.args.R) + 1 :]\n            else:\n                t = \"incorrect --rp-loc or webserver config; expected vpath starting with [{}] but got [{}]\"\n                self.log(t.format(self.args.R, vpath), 1)\n\n        self.ouparam = {k: zs for k, zs in uparam.items()}\n\n        if self.args.rsp_slp:\n            time.sleep(self.args.rsp_slp)\n            if self.args.rsp_jtr:\n                time.sleep(random.random() * self.args.rsp_jtr)\n\n        zso = self.headers.get(\"cookie\")\n        if zso:\n            zsll = [x.split(\"=\", 1) for x in zso.split(\";\") if \"=\" in x]\n            cookies = {k.strip(): unescape_cookie(zs) for k, zs in zsll}\n            cookie_pw = cookies.get(\"cppws\") or cookies.get(\"cppwd\") or \"\"\n            if \"b\" in cookies and \"b\" not in uparam:\n                uparam[\"b\"] = cookies[\"b\"]\n        else:\n            cookies = {}\n            cookie_pw = \"\"\n\n        if len(uparam) > 10 or len(cookies) > 50:\n            raise Pebkac(400, \"u wot m8\")\n\n        self.uparam = uparam\n        self.cookies = cookies\n        self.vpath = unquotep(vpath)  # not query, so + means +\n\n        ok = \"\\x00\" not in self.vpath\n        if ANYWIN:\n            ok = ok and not relchk(self.vpath)\n\n        if not ok and (self.vpath != \"*\" or self.mode != \"OPTIONS\"):\n            self.log(\"invalid relpath [{}]\".format(self.vpath))\n            return self.tx_404() and self.keepalive\n\n        zso = self.headers.get(\"authorization\")\n        bauth = \"\"\n        if zso:\n            try:\n                zb = zso.split(\" \")[1].encode(\"ascii\")\n                zs = base64.b64decode(zb).decode(\"utf-8\")\n                # try \"pwd\", \"x:pwd\", \"pwd:x\"\n                for bauth in [zs] + zs.split(\":\", 1)[::-1]:\n                    hpw = self.asrv.ah.hash(bauth)\n                    if self.asrv.iacct.get(hpw):\n                        break\n            except:\n                pass\n\n        self.pw = uparam.get(\"pw\") or self.headers.get(\"pw\") or bauth or cookie_pw\n        self.uname = self.asrv.iacct.get(self.asrv.ah.hash(self.pw)) or \"*\"\n        self.rvol = self.asrv.vfs.aread[self.uname]\n        self.wvol = self.asrv.vfs.awrite[self.uname]\n        self.mvol = self.asrv.vfs.amove[self.uname]\n        self.dvol = self.asrv.vfs.adel[self.uname]\n        self.gvol = self.asrv.vfs.aget[self.uname]\n        self.upvol = self.asrv.vfs.apget[self.uname]\n        self.avol = self.asrv.vfs.aadmin[self.uname]\n\n        if self.pw and (\n            self.pw != cookie_pw or self.conn.freshen_pwd + 30 < time.time()\n        ):\n            self.conn.freshen_pwd = time.time()\n            self.get_pwd_cookie(self.pw)\n\n        if self.is_rclone:\n            # dots: always include dotfiles if permitted\n            # lt: probably more important showing the correct timestamps of any dupes it just uploaded rather than the lastmod time of any non-copyparty-managed symlinks\n            # b: basic-browser if it tries to parse the html listing\n            uparam[\"dots\"] = \"\"\n            uparam[\"lt\"] = \"\"\n            uparam[\"b\"] = \"\"\n            cookies[\"b\"] = \"\"\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, False, False)\n        if \"xdev\" in vn.flags or \"xvol\" in vn.flags:\n            ap = vn.canonical(rem)\n            avn = vn.chk_ap(ap)\n        else:\n            avn = vn\n\n        (\n            self.can_read,\n            self.can_write,\n            self.can_move,\n            self.can_delete,\n            self.can_get,\n            self.can_upget,\n            self.can_admin,\n        ) = (\n            avn.can_access(\"\", self.uname) if avn else [False] * 7\n        )\n        self.avn = avn\n        self.vn = vn\n        self.rem = rem\n\n        self.s.settimeout(self.args.s_tbody or None)\n\n        try:\n            cors_k = self._cors()\n            if self.mode in (\"GET\", \"HEAD\"):\n                return self.handle_get() and self.keepalive\n            if self.mode == \"OPTIONS\":\n                return self.handle_options() and self.keepalive\n\n            if not cors_k:\n                origin = self.headers.get(\"origin\", \"<?>\")\n                self.log(\"cors-reject {} from {}\".format(self.mode, origin), 3)\n                raise Pebkac(403, \"no surfing\")\n\n            # getattr(self.mode) is not yet faster than this\n            if self.mode == \"POST\":\n                return self.handle_post() and self.keepalive\n            elif self.mode == \"PUT\":\n                return self.handle_put() and self.keepalive\n            elif self.mode == \"PROPFIND\":\n                return self.handle_propfind() and self.keepalive\n            elif self.mode == \"DELETE\":\n                return self.handle_delete() and self.keepalive\n            elif self.mode == \"PROPPATCH\":\n                return self.handle_proppatch() and self.keepalive\n            elif self.mode == \"LOCK\":\n                return self.handle_lock() and self.keepalive\n            elif self.mode == \"UNLOCK\":\n                return self.handle_unlock() and self.keepalive\n            elif self.mode == \"MKCOL\":\n                return self.handle_mkcol() and self.keepalive\n            elif self.mode == \"MOVE\":\n                return self.handle_move() and self.keepalive\n            else:\n                raise Pebkac(400, 'invalid HTTP mode \"{0}\"'.format(self.mode))\n\n        except Exception as ex:\n            if not isinstance(ex, Pebkac):\n                pex = Pebkac(500)\n            else:\n                pex: Pebkac = ex  # type: ignore\n\n            try:\n                if pex.code == 999:\n                    return False\n\n                post = self.mode in [\"POST\", \"PUT\"] or \"content-length\" in self.headers\n                if not self._check_nonfatal(pex, post):\n                    self.keepalive = False\n\n                em = str(ex)\n                msg = em if pex == ex else min_ex()\n                if pex.code != 404 or self.do_log:\n                    self.log(\n                        \"{}\\033[0m, {}\".format(msg, self.vpath),\n                        6 if em.startswith(\"client d/c \") else 3,\n                    )\n\n                msg = \"{}\\r\\nURL: {}\\r\\n\".format(em, self.vpath)\n                if self.hint:\n                    msg += \"hint: {}\\r\\n\".format(self.hint)\n\n                if \"database is locked\" in em:\n                    self.conn.hsrv.broker.say(\"log_stacks\")\n                    msg += \"hint: important info in the server log\\r\\n\"\n\n                zb = b\"<pre>\" + html_escape(msg).encode(\"utf-8\", \"replace\")\n                h = {\"WWW-Authenticate\": 'Basic realm=\"a\"'} if pex.code == 401 else {}\n                self.reply(zb, status=pex.code, headers=h, volsan=True)\n                return self.keepalive\n            except Pebkac:\n                return False\n\n    def dip(self) -> str:\n        if self.args.plain_ip:\n            return self.ip.replace(\":\", \".\")\n        else:\n            return self.conn.iphash.s(self.ip)\n\n    def is_banned(self) -> bool:\n        if not self.conn.bans:\n            return False\n\n        bans = self.conn.bans\n        ip = ipnorm(self.ip)\n        if ip not in bans:\n            return False\n\n        rt = bans[ip] - time.time()\n        if rt < 0:\n            self.log(\"client unbanned\", 3)\n            del bans[ip]\n            return False\n\n        self.log(\"banned for {:.0f} sec\".format(rt), 6)\n        zb = b\"HTTP/1.0 403 Forbidden\\r\\n\\r\\nthank you for playing\"\n        self.s.sendall(zb)\n        return True\n\n    def permit_caching(self) -> None:\n        cache = self.uparam.get(\"cache\")\n        if cache is None:\n            self.out_headers.update(NO_CACHE)\n            return\n\n        n = \"604869\" if cache == \"i\" else cache or \"69\"\n        self.out_headers[\"Cache-Control\"] = \"max-age=\" + n\n\n    def k304(self) -> bool:\n        k304 = self.cookies.get(\"k304\")\n        return k304 == \"y\" or (\"; Trident/\" in self.ua and not k304)\n\n    def send_headers(\n        self,\n        length: Optional[int],\n        status: int = 200,\n        mime: Optional[str] = None,\n        headers: Optional[dict[str, str]] = None,\n    ) -> None:\n        response = [\"%s %s %s\" % (self.http_ver, status, HTTPCODE[status])]\n\n        if length is not None:\n            response.append(\"Content-Length: \" + unicode(length))\n\n        if status == 304 and self.k304():\n            self.keepalive = False\n\n        # close if unknown length, otherwise take client's preference\n        response.append(\"Connection: \" + (\"Keep-Alive\" if self.keepalive else \"Close\"))\n        response.append(\"Date: \" + formatdate(usegmt=True))\n\n        # headers{} overrides anything set previously\n        if headers:\n            self.out_headers.update(headers)\n\n        # default to utf8 html if no content-type is set\n        if not mime:\n            mime = self.out_headers.get(\"Content-Type\") or \"text/html; charset=utf-8\"\n\n        self.out_headers[\"Content-Type\"] = mime\n\n        for k, zs in list(self.out_headers.items()) + self.out_headerlist:\n            response.append(\"%s: %s\" % (k, zs))\n\n        for zs in response:\n            m = self.conn.hsrv.ptn_cc.search(zs)\n            if m:\n                hit = zs[m.span()[0] :]\n                t = \"malicious user; Cc in out-hdr {!r} => [{!r}]\"\n                self.log(t.format(zs, hit), 1)\n                raise Pebkac(999)\n\n        try:\n            # best practice to separate headers and body into different packets\n            self.s.sendall(\"\\r\\n\".join(response).encode(\"utf-8\") + b\"\\r\\n\\r\\n\")\n        except:\n            raise Pebkac(400, \"client d/c while replying headers\")\n\n    def reply(\n        self,\n        body: bytes,\n        status: int = 200,\n        mime: Optional[str] = None,\n        headers: Optional[dict[str, str]] = None,\n        volsan: bool = False,\n    ) -> bytes:\n        if status == 404:\n            g = self.conn.hsrv.g404\n            if g.lim:\n                bonk, ip = g.bonk(self.ip, self.vpath)\n                if bonk:\n                    xban = self.vn.flags.get(\"xban\")\n                    if not xban or not runhook(\n                        self.log,\n                        xban,\n                        self.vn.canonical(self.rem),\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        time.time(),\n                        0,\n                        self.ip,\n                        time.time(),\n                        \"404\",\n                    ):\n                        self.log(\"client banned: 404s\", 1)\n                        self.conn.hsrv.bans[ip] = bonk\n\n        if volsan:\n            vols = list(self.asrv.vfs.all_vols.values())\n            body = vol_san(vols, body)\n\n        self.send_headers(len(body), status, mime, headers)\n\n        try:\n            if self.mode != \"HEAD\":\n                self.s.sendall(body)\n        except:\n            raise Pebkac(400, \"client d/c while replying body\")\n\n        return body\n\n    def loud_reply(self, body: str, *args: Any, **kwargs: Any) -> None:\n        if not kwargs.get(\"mime\"):\n            kwargs[\"mime\"] = \"text/plain; charset=utf-8\"\n\n        self.log(body.rstrip())\n        self.reply(body.encode(\"utf-8\") + b\"\\r\\n\", *list(args), **kwargs)\n\n    def urlq(self, add: dict[str, str], rm: list[str]) -> str:\n        \"\"\"\n        generates url query based on uparam (b, pw, all others)\n        removing anything in rm, adding pairs in add\n\n        also list faster than set until ~20 items\n        \"\"\"\n\n        if self.is_rclone:\n            return \"\"\n\n        kv = {k: zs for k, zs in self.uparam.items() if k not in rm}\n        if \"pw\" in kv:\n            pw = self.cookies.get(\"cppws\") or self.cookies.get(\"cppwd\")\n            if kv[\"pw\"] == pw:\n                del kv[\"pw\"]\n\n        kv.update(add)\n        if not kv:\n            return \"\"\n\n        r = [\"%s=%s\" % (k, quotep(zs)) if zs else k for k, zs in kv.items()]\n        return \"?\" + \"&amp;\".join(r)\n\n    def redirect(\n        self,\n        vpath: str,\n        suf: str = \"\",\n        msg: str = \"aight\",\n        flavor: str = \"go to\",\n        click: bool = True,\n        status: int = 200,\n        use302: bool = False,\n    ) -> bool:\n        vp = self.args.RS + vpath\n        html = self.j2s(\n            \"msg\",\n            h2='<a href=\"/{}\">{} /{}</a>'.format(\n                quotep(vp) + suf, flavor, html_escape(vp, crlf=True) + suf\n            ),\n            pre=msg,\n            click=click,\n        ).encode(\"utf-8\", \"replace\")\n\n        if use302:\n            self.reply(html, status=302, headers={\"Location\": \"/\" + vpath})\n        else:\n            self.reply(html, status=status)\n\n        return True\n\n    def _cors(self) -> bool:\n        ih = self.headers\n        origin = ih.get(\"origin\")\n        if not origin:\n            sfsite = ih.get(\"sec-fetch-site\")\n            if sfsite and sfsite.lower().startswith(\"cross\"):\n                origin = \":|\"  # sandboxed iframe\n            else:\n                return True\n\n        oh = self.out_headers\n        origin = origin.lower()\n        good_origins = self.args.acao + [\n            \"{}://{}\".format(\n                \"https\" if self.is_https else \"http\",\n                self.host.lower().split(\":\")[0],\n            )\n        ]\n        if re.sub(r\"(:[0-9]{1,5})?/?$\", \"\", origin) in good_origins:\n            good_origin = True\n            bad_hdrs = (\"\",)\n        else:\n            good_origin = False\n            bad_hdrs = (\"\", \"pw\")\n\n        # '*' blocks all credentials (cookies, http-auth);\n        # exact-match for Origin is necessary to unlock those,\n        # however yolo-requests (?pw=) are always allowed\n        acah = ih.get(\"access-control-request-headers\", \"\")\n        acao = (origin if good_origin else None) or (\n            \"*\" if \"*\" in good_origins else None\n        )\n        if self.args.allow_csrf:\n            acao = origin or acao or \"*\"  # explicitly permit impersonation\n            acam = \", \".join(self.conn.hsrv.mallow)  # and all methods + headers\n            oh[\"Access-Control-Allow-Credentials\"] = \"true\"\n            good_origin = True\n        else:\n            acam = \", \".join(self.args.acam)\n            # wash client-requested headers and roll with that\n            if \"range\" not in acah.lower():\n                acah += \",Range\"  # firefox\n            req_h = acah.split(\",\")\n            req_h = [x.strip() for x in req_h]\n            req_h = [x for x in req_h if x.lower() not in bad_hdrs]\n            acah = \", \".join(req_h)\n\n        if not acao:\n            return False\n\n        oh[\"Access-Control-Allow-Origin\"] = acao\n        oh[\"Access-Control-Allow-Methods\"] = acam.upper()\n        if acah:\n            oh[\"Access-Control-Allow-Headers\"] = acah\n\n        return good_origin\n\n    def handle_get(self) -> bool:\n        if self.do_log:\n            logmsg = \"%-4s %s @%s\" % (self.mode, self.req, self.uname)\n\n            if \"range\" in self.headers:\n                try:\n                    rval = self.headers[\"range\"].split(\"=\", 1)[1]\n                except:\n                    rval = self.headers[\"range\"]\n\n                logmsg += \" [\\033[36m\" + rval + \"\\033[0m]\"\n\n            self.log(logmsg)\n\n        # \"embedded\" resources\n        if self.vpath.startswith(\".cpr\"):\n            if self.vpath.startswith(\".cpr/ico/\"):\n                return self.tx_ico(self.vpath.split(\"/\")[-1], exact=True)\n\n            if self.vpath.startswith(\".cpr/ssdp\"):\n                return self.conn.hsrv.ssdp.reply(self)\n\n            if self.vpath.startswith(\".cpr/dd/\") and self.args.mpmc:\n                if self.args.mpmc == \".\":\n                    raise Pebkac(404)\n\n                loc = self.args.mpmc.rstrip(\"/\") + self.vpath[self.vpath.rfind(\"/\") :]\n                h = {\"Location\": loc, \"Cache-Control\": \"max-age=39\"}\n                self.reply(b\"\", 301, headers=h)\n                return True\n\n            path_base = os.path.join(self.E.mod, \"web\")\n            static_path = absreal(os.path.join(path_base, self.vpath[5:]))\n            if not static_path.startswith(path_base):\n                t = \"malicious user; attempted path traversal [{}] => [{}]\"\n                self.log(t.format(self.vpath, static_path), 1)\n                self.tx_404()\n                return False\n\n            return self.tx_file(static_path)\n\n        if \"cf_challenge\" in self.uparam:\n            self.reply(self.j2s(\"cf\").encode(\"utf-8\", \"replace\"))\n            return True\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            t = \"@{} has no access to [{}]\"\n            self.log(t.format(self.uname, self.vpath))\n\n            if \"on403\" in self.vn.flags:\n                ret = self.on40x(self.vn.flags[\"on403\"], self.vn, self.rem)\n                if ret == \"true\":\n                    return True\n                elif ret == \"false\":\n                    return False\n                elif ret == \"allow\":\n                    self.log(\"plugin override; access permitted\")\n                    self.can_read = self.can_write = self.can_move = True\n                    self.can_delete = self.can_get = self.can_upget = True\n                    self.can_admin = True\n                else:\n                    return self.tx_404(True)\n            else:\n                if self.vpath:\n                    return self.tx_404(True)\n\n                self.uparam[\"h\"] = \"\"\n\n        if \"tree\" in self.uparam:\n            return self.tx_tree()\n\n        if \"scan\" in self.uparam:\n            return self.scanvol()\n\n        if self.args.getmod:\n            if \"delete\" in self.uparam:\n                return self.handle_rm([])\n\n            if \"move\" in self.uparam:\n                return self.handle_mv()\n\n        if not self.vpath:\n            if \"reload\" in self.uparam:\n                return self.handle_reload()\n\n            if \"stack\" in self.uparam:\n                return self.tx_stack()\n\n            if \"ups\" in self.uparam:\n                return self.tx_ups()\n\n            if \"k304\" in self.uparam:\n                return self.set_k304()\n\n            if \"setck\" in self.uparam:\n                return self.setck()\n\n            if \"reset\" in self.uparam:\n                return self.set_cfg_reset()\n\n            if \"hc\" in self.uparam:\n                return self.tx_svcs()\n\n        if \"h\" in self.uparam:\n            return self.tx_mounts()\n\n        # conditional redirect to single volumes\n        if self.vpath == \"\" and not self.ouparam:\n            nread = len(self.rvol)\n            nwrite = len(self.wvol)\n            if nread + nwrite == 1 or (self.rvol == self.wvol and nread == 1):\n                if nread == 1:\n                    vpath = self.rvol[0]\n                else:\n                    vpath = self.wvol[0]\n\n                if self.vpath != vpath:\n                    self.redirect(vpath, flavor=\"redirecting to\", use302=True)\n                    return True\n\n        return self.tx_browser()\n\n    def handle_propfind(self) -> bool:\n        if self.do_log:\n            self.log(\"PFIND %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, False, False, err=401)\n        tap = vn.canonical(rem)\n\n        if \"davauth\" in vn.flags and self.uname == \"*\":\n            self.can_read = self.can_write = self.can_get = False\n\n        if not self.can_read and not self.can_write and not self.can_get:\n            self.log(\"inaccessible: [{}]\".format(self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from .dxml import parse_xml\n\n        # enc = \"windows-31j\"\n        # enc = \"shift_jis\"\n        enc = \"utf-8\"\n        uenc = enc.upper()\n\n        clen = int(self.headers.get(\"content-length\", 0))\n        if clen:\n            buf = b\"\"\n            for rbuf in self.get_body_reader()[0]:\n                buf += rbuf\n                if not rbuf or len(buf) >= 32768:\n                    break\n\n            xroot = parse_xml(buf.decode(enc, \"replace\"))\n            xtag = next(x for x in xroot if x.tag.split(\"}\")[-1] == \"prop\")\n            props_lst = [y.tag.split(\"}\")[-1] for y in xtag]\n        else:\n            props_lst = [\n                \"contentclass\",\n                \"creationdate\",\n                \"defaultdocument\",\n                \"displayname\",\n                \"getcontentlanguage\",\n                \"getcontentlength\",\n                \"getcontenttype\",\n                \"getlastmodified\",\n                \"href\",\n                \"iscollection\",\n                \"ishidden\",\n                \"isreadonly\",\n                \"isroot\",\n                \"isstructureddocument\",\n                \"lastaccessed\",\n                \"name\",\n                \"parentname\",\n                \"resourcetype\",\n                \"supportedlock\",\n            ]\n\n        props = set(props_lst)\n        depth = self.headers.get(\"depth\", \"infinity\").lower()\n\n        try:\n            topdir = {\"vp\": \"\", \"st\": bos.stat(tap)}\n        except OSError as ex:\n            if ex.errno not in (errno.ENOENT, errno.ENOTDIR):\n                raise\n            raise Pebkac(404)\n\n        if depth == \"0\" or not self.can_read or not stat.S_ISDIR(topdir[\"st\"].st_mode):\n            fgen = []\n\n        elif depth == \"infinity\":\n            if not self.args.dav_inf:\n                self.log(\"client wants --dav-inf\", 3)\n                zb = b'<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<D:error xmlns:D=\"DAV:\"><D:propfind-finite-depth/></D:error>'\n                self.reply(zb, 403, \"application/xml; charset=utf-8\")\n                return True\n\n            # this will return symlink-target timestamps\n            # because lstat=true would not recurse into subfolders\n            # and this is a rare case where we actually want that\n            fgen = vn.zipgen(\n                rem,\n                rem,\n                set(),\n                self.uname,\n                self.args.ed,\n                True,\n                not self.args.no_scandir,\n                wrap=False,\n            )\n\n        elif depth == \"1\":\n            _, vfs_ls, vfs_virt = vn.ls(\n                rem,\n                self.uname,\n                not self.args.no_scandir,\n                [[True, False]],\n                lstat=\"davrt\" not in vn.flags,\n            )\n            if not self.args.ed:\n                names = set(exclude_dotfiles([x[0] for x in vfs_ls]))\n                vfs_ls = [x for x in vfs_ls if x[0] in names]\n\n            zi = int(time.time())\n            zsr = os.stat_result((16877, -1, -1, 1, 1000, 1000, 8, zi, zi, zi))\n            ls = [{\"vp\": vp, \"st\": st} for vp, st in vfs_ls]\n            ls += [{\"vp\": v, \"st\": zsr} for v in vfs_virt]\n            fgen = ls  # type: ignore\n\n        else:\n            t = \"invalid depth value '{}' (must be either '0' or '1'{})\"\n            t2 = \" or 'infinity'\" if self.args.dav_inf else \"\"\n            raise Pebkac(412, t.format(depth, t2))\n\n        fgen = itertools.chain([topdir], fgen)  # type: ignore\n        vtop = vjoin(self.args.R, vjoin(vn.vpath, rem))\n\n        chunksz = 0x7FF8  # preferred by nginx or cf (dunno which)\n\n        self.send_headers(\n            None, 207, \"text/xml; charset=\" + enc, {\"Transfer-Encoding\": \"chunked\"}\n        )\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n<D:multistatus xmlns:D=\"DAV:\">'\n        ret = ret.format(uenc)\n        for x in fgen:\n            rp = vjoin(vtop, x[\"vp\"])\n            st: os.stat_result = x[\"st\"]\n            mtime = st.st_mtime\n            if stat.S_ISLNK(st.st_mode):\n                try:\n                    st = bos.stat(os.path.join(tap, x[\"vp\"]))\n                except:\n                    continue\n\n            isdir = stat.S_ISDIR(st.st_mode)\n\n            ret += \"<D:response><D:href>/%s%s</D:href><D:propstat><D:prop>\" % (\n                quotep(rp),\n                \"/\" if isdir and rp else \"\",\n            )\n\n            pvs: dict[str, str] = {\n                \"displayname\": html_escape(rp.split(\"/\")[-1]),\n                \"getlastmodified\": formatdate(mtime, usegmt=True),\n                \"resourcetype\": '<D:collection xmlns:D=\"DAV:\"/>' if isdir else \"\",\n                \"supportedlock\": '<D:lockentry xmlns:D=\"DAV:\"><D:lockscope><D:exclusive/></D:lockscope><D:locktype><D:write/></D:locktype></D:lockentry>',\n            }\n            if not isdir:\n                pvs[\"getcontenttype\"] = html_escape(guess_mime(rp))\n                pvs[\"getcontentlength\"] = str(st.st_size)\n\n            for k, v in pvs.items():\n                if k not in props:\n                    continue\n                elif v:\n                    ret += \"<D:%s>%s</D:%s>\" % (k, v, k)\n                else:\n                    ret += \"<D:%s/>\" % (k,)\n\n            ret += \"</D:prop><D:status>HTTP/1.1 200 OK</D:status></D:propstat>\"\n\n            missing = [\"<D:%s/>\" % (x,) for x in props if x not in pvs]\n            if missing and clen:\n                t = \"<D:propstat><D:prop>{}</D:prop><D:status>HTTP/1.1 404 Not Found</D:status></D:propstat>\"\n                ret += t.format(\"\".join(missing))\n\n            ret += \"</D:response>\"\n            while len(ret) >= chunksz:\n                ret = self.send_chunk(ret, enc, chunksz)\n\n        ret += \"</D:multistatus>\"\n        while ret:\n            ret = self.send_chunk(ret, enc, chunksz)\n\n        self.send_chunk(\"\", enc, chunksz)\n        # self.reply(ret.encode(enc, \"replace\"),207, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_proppatch(self) -> bool:\n        if self.do_log:\n            self.log(\"PPATCH %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        if not self.can_write:\n            self.log(\"{} tried to proppatch [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from xml.etree import ElementTree as ET\n\n        from .dxml import mkenod, mktnod, parse_xml\n\n        buf = b\"\"\n        for rbuf in self.get_body_reader()[0]:\n            buf += rbuf\n            if not rbuf or len(buf) >= 128 * 1024:\n                break\n\n        if self._applesan():\n            return True\n\n        txt = buf.decode(\"ascii\", \"replace\").lower()\n        enc = self.get_xml_enc(txt)\n        uenc = enc.upper()\n\n        txt = buf.decode(enc, \"replace\")\n        ET.register_namespace(\"D\", \"DAV:\")\n        xroot = mkenod(\"D:orz\")\n        xroot.insert(0, parse_xml(txt))\n        xprop = xroot.find(r\"./{DAV:}propertyupdate/{DAV:}set/{DAV:}prop\")\n        assert xprop\n        for ze in xprop:\n            ze.clear()\n\n        txt = \"\"\"<multistatus xmlns=\"DAV:\"><response><propstat><status>HTTP/1.1 403 Forbidden</status></propstat></response></multistatus>\"\"\"\n        xroot = parse_xml(txt)\n\n        el = xroot.find(r\"./{DAV:}response\")\n        assert el\n        e2 = mktnod(\"D:href\", quotep(self.args.SRS + self.vpath))\n        el.insert(0, e2)\n\n        el = xroot.find(r\"./{DAV:}response/{DAV:}propstat\")\n        assert el\n        el.insert(0, xprop)\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n'.format(uenc)\n        ret += ET.tostring(xroot).decode(\"utf-8\")\n\n        self.reply(ret.encode(enc, \"replace\"), 207, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_lock(self) -> bool:\n        if self.do_log:\n            self.log(\"LOCK %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        # win7+ deadlocks if we say no; just smile and nod\n        if not self.can_write and \"Microsoft-WebDAV\" not in self.ua:\n            self.log(\"{} tried to lock [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        from xml.etree import ElementTree as ET\n\n        from .dxml import mkenod, mktnod, parse_xml\n\n        abspath = self.vn.dcanonical(self.rem)\n\n        buf = b\"\"\n        for rbuf in self.get_body_reader()[0]:\n            buf += rbuf\n            if not rbuf or len(buf) >= 128 * 1024:\n                break\n\n        if self._applesan():\n            return True\n\n        txt = buf.decode(\"ascii\", \"replace\").lower()\n        enc = self.get_xml_enc(txt)\n        uenc = enc.upper()\n\n        txt = buf.decode(enc, \"replace\")\n        ET.register_namespace(\"D\", \"DAV:\")\n        lk = parse_xml(txt)\n        assert lk.tag == \"{DAV:}lockinfo\"\n\n        token = str(uuid.uuid4())\n\n        if not lk.find(r\"./{DAV:}depth\"):\n            depth = self.headers.get(\"depth\", \"infinity\")\n            lk.append(mktnod(\"D:depth\", depth))\n\n        lk.append(mktnod(\"D:timeout\", \"Second-3310\"))\n        lk.append(mkenod(\"D:locktoken\", mktnod(\"D:href\", token)))\n        lk.append(\n            mkenod(\"D:lockroot\", mktnod(\"D:href\", quotep(self.args.SRS + self.vpath)))\n        )\n\n        lk2 = mkenod(\"D:activelock\")\n        xroot = mkenod(\"D:prop\", mkenod(\"D:lockdiscovery\", lk2))\n        for a in lk:\n            lk2.append(a)\n\n        ret = '<?xml version=\"1.0\" encoding=\"{}\"?>\\n'.format(uenc)\n        ret += ET.tostring(xroot).decode(\"utf-8\")\n\n        rc = 200\n        if self.can_write and not bos.path.isfile(abspath):\n            with open(fsenc(abspath), \"wb\") as _:\n                rc = 201\n\n        self.out_headers[\"Lock-Token\"] = \"<{}>\".format(token)\n        self.reply(ret.encode(enc, \"replace\"), rc, \"text/xml; charset=\" + enc)\n        return True\n\n    def handle_unlock(self) -> bool:\n        if self.do_log:\n            self.log(\"UNLOCK %s @%s\" % (self.req, self.uname))\n\n        if self.args.no_dav:\n            raise Pebkac(405, \"WebDAV is disabled in server config\")\n\n        if not self.can_write and \"Microsoft-WebDAV\" not in self.ua:\n            self.log(\"{} tried to lock [{}]\".format(self.uname, self.vpath))\n            raise Pebkac(401, \"authenticate\")\n\n        self.send_headers(None, 204)\n        return True\n\n    def handle_mkcol(self) -> bool:\n        if self._applesan():\n            return True\n\n        if self.do_log:\n            self.log(\"MKCOL %s @%s\" % (self.req, self.uname))\n\n        try:\n            return self._mkdir(self.vpath, True)\n        except Pebkac as ex:\n            if ex.code >= 500:\n                raise\n\n            self.reply(b\"\", ex.code)\n            return True\n\n    def handle_move(self) -> bool:\n        dst = self.headers[\"destination\"]\n        dst = re.sub(\"^https?://[^/]+\", \"\", dst).lstrip()\n        dst = unquotep(dst)\n        if not self._mv(self.vpath, dst.lstrip(\"/\")):\n            return False\n\n        return True\n\n    def _applesan(self) -> bool:\n        if self.args.dav_mac or \"Darwin/\" not in self.ua:\n            return False\n\n        vp = \"/\" + self.vpath\n        ptn = r\"/\\.(_|DS_Store|Spotlight-|fseventsd|Trashes|AppleDouble)|/__MACOS\"\n        if re.search(ptn, vp):\n            zt = '<?xml version=\"1.0\" encoding=\"utf-8\"?>\\n<D:error xmlns:D=\"DAV:\"><D:lock-token-submitted><D:href>{}</D:href></D:lock-token-submitted></D:error>'\n            zb = zt.format(vp).encode(\"utf-8\", \"replace\")\n            self.reply(zb, 423, \"text/xml; charset=utf-8\")\n            return True\n\n        return False\n\n    def send_chunk(self, txt: str, enc: str, bmax: int) -> str:\n        orig_len = len(txt)\n        buf = txt[:bmax].encode(enc, \"replace\")[:bmax]\n        try:\n            _ = buf.decode(enc)\n        except UnicodeDecodeError as ude:\n            buf = buf[: ude.start]\n\n        txt = txt[len(buf.decode(enc)) :]\n        if txt and len(txt) == orig_len:\n            raise Pebkac(500, \"chunk slicing failed\")\n\n        buf = \"{:x}\\r\\n\".format(len(buf)).encode(enc) + buf\n        self.s.sendall(buf + b\"\\r\\n\")\n        return txt\n\n    def handle_options(self) -> bool:\n        if self.do_log:\n            self.log(\"OPTIONS %s @%s\" % (self.req, self.uname))\n\n        oh = self.out_headers\n        oh[\"Allow\"] = \", \".join(self.conn.hsrv.mallow)\n\n        if not self.args.no_dav:\n            # PROPPATCH, LOCK, UNLOCK, COPY: noop (spec-must)\n            oh[\"Dav\"] = \"1, 2\"\n            oh[\"Ms-Author-Via\"] = \"DAV\"\n\n        # winxp-webdav doesnt know what 204 is\n        self.send_headers(0, 200)\n        return True\n\n    def handle_delete(self) -> bool:\n        self.log(\"DELETE %s @%s\" % (self.req, self.uname))\n        return self.handle_rm([])\n\n    def handle_put(self) -> bool:\n        self.log(\"PUT %s @%s\" % (self.req, self.uname))\n\n        if not self.can_write:\n            t = \"user {} does not have write-access here\"\n            raise Pebkac(403, t.format(self.uname))\n\n        if not self.args.no_dav and self._applesan():\n            return self.headers.get(\"content-length\") == \"0\"\n\n        if self.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            try:\n                self.s.sendall(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            except:\n                raise Pebkac(400, \"client d/c before 100 continue\")\n\n        return self.handle_stash(True)\n\n    def handle_post(self) -> bool:\n        self.log(\"POST %s @%s\" % (self.req, self.uname))\n\n        if self.headers.get(\"expect\", \"\").lower() == \"100-continue\":\n            try:\n                self.s.sendall(b\"HTTP/1.1 100 Continue\\r\\n\\r\\n\")\n            except:\n                raise Pebkac(400, \"client d/c before 100 continue\")\n\n        if \"raw\" in self.uparam:\n            return self.handle_stash(False)\n\n        ctype = self.headers.get(\"content-type\", \"\").lower()\n\n        if \"multipart/form-data\" in ctype:\n            return self.handle_post_multipart()\n\n        if (\n            \"application/json\" in ctype\n            or \"text/plain\" in ctype\n            or \"application/xml\" in ctype\n        ):\n            return self.handle_post_json()\n\n        if \"move\" in self.uparam:\n            return self.handle_mv()\n\n        if \"delete\" in self.uparam:\n            return self.handle_rm([])\n\n        if \"application/octet-stream\" in ctype:\n            return self.handle_post_binary()\n\n        if \"application/x-www-form-urlencoded\" in ctype:\n            opt = self.args.urlform\n            if \"stash\" in opt:\n                return self.handle_stash(False)\n\n            if \"save\" in opt:\n                post_sz, _, _, _, path, _ = self.dump_to_file(False)\n                self.log(\"urlform: {} bytes, {}\".format(post_sz, path))\n            elif \"print\" in opt:\n                reader, _ = self.get_body_reader()\n                buf = b\"\"\n                for rbuf in reader:\n                    buf += rbuf\n                    if not rbuf or len(buf) >= 32768:\n                        break\n\n                if buf:\n                    orig = buf.decode(\"utf-8\", \"replace\")\n                    t = \"urlform_raw {} @ {}\\n  {}\\n\"\n                    self.log(t.format(len(orig), self.vpath, orig))\n                    try:\n                        zb = unquote(buf.replace(b\"+\", b\" \"))\n                        plain = zb.decode(\"utf-8\", \"replace\")\n                        if buf.startswith(b\"msg=\"):\n                            plain = plain[4:]\n                            xm = self.vn.flags.get(\"xm\")\n                            if xm:\n                                runhook(\n                                    self.log,\n                                    xm,\n                                    self.vn.canonical(self.rem),\n                                    self.vpath,\n                                    self.host,\n                                    self.uname,\n                                    time.time(),\n                                    len(buf),\n                                    self.ip,\n                                    time.time(),\n                                    plain,\n                                )\n\n                        t = \"urlform_dec {} @ {}\\n  {}\\n\"\n                        self.log(t.format(len(plain), self.vpath, plain))\n\n                    except Exception as ex:\n                        self.log(repr(ex))\n\n            if \"get\" in opt:\n                return self.handle_get()\n\n            raise Pebkac(405, \"POST({}) is disabled in server config\".format(ctype))\n\n        raise Pebkac(405, \"don't know how to handle POST({})\".format(ctype))\n\n    def get_xml_enc(self, txt: str) -> str:\n        ofs = txt[:512].find(' encoding=\"')\n        enc = \"\"\n        if ofs + 1:\n            enc = txt[ofs + 6 :].split('\"')[1]\n        else:\n            enc = self.headers.get(\"content-type\", \"\").lower()\n            ofs = enc.find(\"charset=\")\n            if ofs + 1:\n                enc = enc[ofs + 4].split(\"=\")[1].split(\";\")[0].strip(\"\\\"'\")\n            else:\n                enc = \"\"\n\n        return enc or \"utf-8\"\n\n    def get_body_reader(self) -> tuple[Generator[bytes, None, None], int]:\n        if \"chunked\" in self.headers.get(\"transfer-encoding\", \"\").lower():\n            return read_socket_chunked(self.sr), -1\n\n        remains = int(self.headers.get(\"content-length\", -1))\n        if remains == -1:\n            self.keepalive = False\n            return read_socket_unbounded(self.sr), remains\n        else:\n            return read_socket(self.sr, remains), remains\n\n    def dump_to_file(self, is_put: bool) -> tuple[int, str, str, int, str, str]:\n        # post_sz, sha_hex, sha_b64, remains, path, url\n        reader, remains = self.get_body_reader()\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        rnd, _, lifetime, xbu, xau = self.upload_flags(vfs)\n        lim = vfs.get_dbv(rem)[0].lim\n        fdir = vfs.canonical(rem)\n        if lim:\n            fdir, rem = lim.all(\n                self.ip, rem, remains, vfs.realpath, fdir, self.conn.hsrv.broker\n            )\n\n        fn = None\n        if rem and not self.trailing_slash and not bos.path.isdir(fdir):\n            fdir, fn = os.path.split(fdir)\n            rem, _ = vsplit(rem)\n\n        bos.makedirs(fdir)\n\n        open_ka: dict[str, Any] = {\"fun\": open}\n        open_a = [\"wb\", 512 * 1024]\n\n        # user-request || config-force\n        if (\"gz\" in vfs.flags or \"xz\" in vfs.flags) and (\n            \"pk\" in vfs.flags\n            or \"pk\" in self.uparam\n            or \"gz\" in self.uparam\n            or \"xz\" in self.uparam\n        ):\n            fb = {\"gz\": 9, \"xz\": 0}  # default/fallback level\n            lv = {}  # selected level\n            alg = \"\"  # selected algo (gz=preferred)\n\n            # user-prefs first\n            if \"gz\" in self.uparam or \"pk\" in self.uparam:  # def.pk\n                alg = \"gz\"\n            if \"xz\" in self.uparam:\n                alg = \"xz\"\n            if alg:\n                zso = self.uparam.get(alg)\n                lv[alg] = fb[alg] if zso is None else int(zso)\n\n            if alg not in vfs.flags:\n                alg = \"gz\" if \"gz\" in vfs.flags else \"xz\"\n\n            # then server overrides\n            pk = vfs.flags.get(\"pk\")\n            if pk is not None:\n                # config-forced on\n                alg = alg or \"gz\"  # def.pk\n                try:\n                    # config-forced opts\n                    alg, nlv = pk.split(\",\")\n                    lv[alg] = int(nlv)\n                except:\n                    pass\n\n            lv[alg] = lv.get(alg) or fb.get(alg) or 0\n\n            self.log(\"compressing with {} level {}\".format(alg, lv.get(alg)))\n            if alg == \"gz\":\n                open_ka[\"fun\"] = gzip.GzipFile\n                open_a = [\"wb\", lv[alg], None, 0x5FEE6600]  # 2021-01-01\n            elif alg == \"xz\":\n                open_ka = {\"fun\": lzma.open, \"preset\": lv[alg]}\n                open_a = [\"wb\"]\n            else:\n                self.log(\"fallthrough? thats a bug\", 1)\n\n        suffix = \"-{:.6f}-{}\".format(time.time(), self.dip())\n        nameless = not fn\n        if nameless:\n            suffix += \".bin\"\n            fn = \"put\" + suffix\n\n        params = {\"suffix\": suffix, \"fdir\": fdir}\n        if self.args.nw:\n            params = {}\n            fn = os.devnull\n\n        params.update(open_ka)\n        assert fn\n\n        if not self.args.nw:\n            if rnd:\n                fn = rand_name(fdir, fn, rnd)\n\n            fn = sanitize_fn(fn or \"\", \"\", [\".prologue.html\", \".epilogue.html\"])\n\n        path = os.path.join(fdir, fn)\n\n        if xbu:\n            at = time.time() - lifetime\n            if not runhook(\n                self.log,\n                xbu,\n                path,\n                self.vpath,\n                self.host,\n                self.uname,\n                at,\n                remains,\n                self.ip,\n                at,\n                \"\",\n            ):\n                t = \"upload blocked by xbu server config\"\n                self.log(t, 1)\n                raise Pebkac(403, t)\n\n        if is_put and not (self.args.no_dav or self.args.nw) and bos.path.exists(path):\n            # allow overwrite if...\n            #  * volflag 'daw' is set, or client is definitely webdav\n            #  * and account has delete-access\n            # or...\n            #  * file exists, is empty, sufficiently new\n            #  * and there is no .PARTIAL\n\n            tnam = fn + \".PARTIAL\"\n            if self.args.dotpart:\n                tnam = \".\" + tnam\n\n            if (\n                self.can_delete\n                and (vfs.flags.get(\"daw\") or \"x-oc-mtime\" in self.headers)\n            ) or (\n                not bos.path.exists(os.path.join(fdir, tnam))\n                and not bos.path.getsize(path)\n                and bos.path.getmtime(path) >= time.time() - self.args.blank_wt\n            ):\n                # small toctou, but better than clobbering a hardlink\n                bos.unlink(path)\n\n        with ren_open(fn, *open_a, **params) as zfw:\n            f, fn = zfw[\"orz\"]\n            path = os.path.join(fdir, fn)\n            post_sz, sha_hex, sha_b64 = hashcopy(reader, f, self.args.s_wr_slp)\n\n        if lim:\n            lim.nup(self.ip)\n            lim.bup(self.ip, post_sz)\n            try:\n                lim.chk_sz(post_sz)\n                lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, post_sz)\n            except:\n                bos.unlink(path)\n                raise\n\n        if self.args.nw:\n            return post_sz, sha_hex, sha_b64, remains, path, \"\"\n\n        at = mt = time.time() - lifetime\n        cli_mt = self.headers.get(\"x-oc-mtime\")\n        if cli_mt:\n            try:\n                mt = int(cli_mt)\n                times = (int(time.time()), mt)\n                bos.utime(path, times, False)\n            except:\n                pass\n\n        if nameless and \"magic\" in vfs.flags:\n            try:\n                ext = self.conn.hsrv.magician.ext(path)\n            except Exception as ex:\n                self.log(\"filetype detection failed for [{}]: {}\".format(path, ex), 6)\n                ext = None\n\n            if ext:\n                if rnd:\n                    fn2 = rand_name(fdir, \"a.\" + ext, rnd)\n                else:\n                    fn2 = fn.rsplit(\".\", 1)[0] + \".\" + ext\n\n                params[\"suffix\"] = suffix[:-4]\n                with ren_open(fn, *open_a, **params) as zfw:\n                    f, fn = zfw[\"orz\"]\n\n                path2 = os.path.join(fdir, fn2)\n                atomic_move(path, path2)\n                fn = fn2\n                path = path2\n\n        if xau and not runhook(\n            self.log,\n            xau,\n            path,\n            self.vpath,\n            self.host,\n            self.uname,\n            mt,\n            post_sz,\n            self.ip,\n            at,\n            \"\",\n        ):\n            t = \"upload blocked by xau server config\"\n            self.log(t, 1)\n            os.unlink(path)\n            raise Pebkac(403, t)\n\n        vfs, rem = vfs.get_dbv(rem)\n        self.conn.hsrv.broker.say(\n            \"up2k.hash_file\",\n            vfs.realpath,\n            vfs.vpath,\n            vfs.flags,\n            rem,\n            fn,\n            self.ip,\n            at,\n            self.uname,\n            True,\n        )\n\n        vsuf = \"\"\n        if (self.can_read or self.can_upget) and \"fk\" in vfs.flags:\n            vsuf = \"?k=\" + self.gen_fk(\n                self.args.fk_salt,\n                path,\n                post_sz,\n                0 if ANYWIN else bos.stat(path).st_ino,\n            )[: vfs.flags[\"fk\"]]\n\n        vpath = \"/\".join([x for x in [vfs.vpath, rem, fn] if x])\n        vpath = quotep(vpath)\n\n        url = \"{}://{}/{}\".format(\n            \"https\" if self.is_https else \"http\",\n            self.host,\n            self.args.RS + vpath + vsuf,\n        )\n\n        return post_sz, sha_hex, sha_b64, remains, path, url\n\n    def handle_stash(self, is_put: bool) -> bool:\n        post_sz, sha_hex, sha_b64, remains, path, url = self.dump_to_file(is_put)\n        spd = self._spd(post_sz)\n        t = \"{} wrote {}/{} bytes to {}  # {}\"\n        self.log(t.format(spd, post_sz, remains, path, sha_b64[:28]))  # 21\n\n        ac = self.uparam.get(\n            \"want\", self.headers.get(\"accept\", \"\").lower().split(\";\")[-1]\n        )\n        if ac == \"url\":\n            t = url\n        else:\n            t = \"{}\\n{}\\n{}\\n{}\\n\".format(post_sz, sha_b64, sha_hex[:56], url)\n\n        h = {\"Location\": url} if is_put and url else {}\n\n        if \"x-oc-mtime\" in self.headers:\n            h[\"X-OC-MTime\"] = \"accepted\"\n            t = \"\"  # some webdav clients expect/prefer this\n\n        self.reply(t.encode(\"utf-8\"), 201, headers=h)\n        return True\n\n    def bakflip(self, f: typing.BinaryIO, ofs: int, sz: int, sha: str) -> None:\n        if not self.args.bak_flips or self.args.nw:\n            return\n\n        sdir = self.args.bf_dir\n        fp = os.path.join(sdir, sha)\n        if bos.path.exists(fp):\n            return self.log(\"no bakflip; have it\", 6)\n\n        if not bos.path.isdir(sdir):\n            bos.makedirs(sdir)\n\n        if len(bos.listdir(sdir)) >= self.args.bf_nc:\n            return self.log(\"no bakflip; too many\", 3)\n\n        nrem = sz\n        f.seek(ofs)\n        with open(fp, \"wb\") as fo:\n            while nrem:\n                buf = f.read(min(nrem, 512 * 1024))\n                if not buf:\n                    break\n\n                nrem -= len(buf)\n                fo.write(buf)\n\n        if nrem:\n            self.log(\"bakflip truncated; {} remains\".format(nrem), 1)\n            atomic_move(fp, fp + \".trunc\")\n        else:\n            self.log(\"bakflip ok\", 2)\n\n    def _spd(self, nbytes: int, add: bool = True) -> str:\n        if add:\n            self.conn.nbyte += nbytes\n\n        spd1 = get_spd(nbytes, self.t0)\n        spd2 = get_spd(self.conn.nbyte, self.conn.t0)\n        return \"%s %s n%s\" % (spd1, spd2, self.conn.nreq)\n\n    def handle_post_multipart(self) -> bool:\n        self.parser = MultipartParser(self.log, self.sr, self.headers)\n        self.parser.parse()\n\n        act = self.parser.require(\"act\", 64)\n\n        if act == \"login\":\n            return self.handle_login()\n\n        if act == \"mkdir\":\n            return self.handle_mkdir()\n\n        if act == \"new_md\":\n            # kinda silly but has the least side effects\n            return self.handle_new_md()\n\n        if act == \"bput\":\n            return self.handle_plain_upload()\n\n        if act == \"tput\":\n            return self.handle_text_upload()\n\n        if act == \"zip\":\n            return self.handle_zip_post()\n\n        raise Pebkac(422, 'invalid action \"{}\"'.format(act))\n\n    def handle_zip_post(self) -> bool:\n        assert self.parser\n        try:\n            k = next(x for x in self.uparam if x in (\"zip\", \"tar\"))\n        except:\n            raise Pebkac(422, \"need zip or tar keyword\")\n\n        v = self.uparam[k]\n\n        vn, rem = self.asrv.vfs.get(self.vpath, self.uname, True, False)\n        zs = self.parser.require(\"files\", 1024 * 1024)\n        if not zs:\n            raise Pebkac(422, \"need files list\")\n\n        items = zs.replace(\"\\r\", \"\").split(\"\\n\")\n        items = [unquotep(x) for x in items if items]\n\n        self.parser.drop()\n        return self.tx_zip(k, v, \"\", vn, rem, items, self.args.ed)\n\n    def handle_post_json(self) -> bool:\n        try:\n            remains = int(self.headers[\"content-length\"])\n        except:\n            raise Pebkac(411)\n\n        if remains > 1024 * 1024:\n            raise Pebkac(413, \"json 2big\")\n\n        enc = \"utf-8\"\n        ctype = self.headers.get(\"content-type\", \"\").lower()\n        if \"charset\" in ctype:\n            enc = ctype.split(\"charset\")[1].strip(\" =\").split(\";\")[0].strip()\n\n        try:\n            json_buf = self.sr.recv_ex(remains)\n        except UnrecvEOF:\n            raise Pebkac(422, \"client disconnected while posting JSON\")\n\n        self.log(\"decoding {} bytes of {} json\".format(len(json_buf), enc))\n        try:\n            body = json.loads(json_buf.decode(enc, \"replace\"))\n        except:\n            raise Pebkac(422, \"you POSTed invalid json\")\n\n        # self.reply(b\"cloudflare\", 503)\n        # return True\n\n        if \"srch\" in self.uparam or \"srch\" in body:\n            return self.handle_search(body)\n\n        if \"delete\" in self.uparam:\n            return self.handle_rm(body)\n\n        name = undot(body[\"name\"])\n        if \"/\" in name:\n            raise Pebkac(400, \"your client is old; press CTRL-SHIFT-R and try again\")\n\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        dbv, vrem = vfs.get_dbv(rem)\n\n        body[\"vtop\"] = dbv.vpath\n        body[\"ptop\"] = dbv.realpath\n        body[\"prel\"] = vrem\n        body[\"host\"] = self.host\n        body[\"user\"] = self.uname\n        body[\"addr\"] = self.ip\n        body[\"vcfg\"] = dbv.flags\n\n        if not self.can_delete:\n            body.pop(\"replace\", None)\n\n        if rem:\n            dst = vfs.canonical(rem)\n            try:\n                if not bos.path.isdir(dst):\n                    bos.makedirs(dst)\n            except OSError as ex:\n                self.log(\"makedirs failed [{}]\".format(dst))\n                if not bos.path.isdir(dst):\n                    if ex.errno == errno.EACCES:\n                        raise Pebkac(500, \"the server OS denied write-access\")\n\n                    if ex.errno == errno.EEXIST:\n                        raise Pebkac(400, \"some file got your folder name\")\n\n                    raise Pebkac(500, min_ex())\n            except:\n                raise Pebkac(500, min_ex())\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_json\", body, self.u2fh.aps)\n        ret = x.get()\n        if self.is_vproxied:\n            if \"purl\" in ret:\n                ret[\"purl\"] = self.args.SR + ret[\"purl\"]\n\n        ret = json.dumps(ret)\n        self.log(ret)\n        self.reply(ret.encode(\"utf-8\"), mime=\"application/json\")\n        return True\n\n    def handle_search(self, body: dict[str, Any]) -> bool:\n        idx = self.conn.get_u2idx()\n        if not idx or not hasattr(idx, \"p_end\"):\n            raise Pebkac(500, \"sqlite3 is not available on the server; cannot search\")\n\n        vols = []\n        seen = {}\n        for vtop in self.rvol:\n            vfs, _ = self.asrv.vfs.get(vtop, self.uname, True, False)\n            vfs = vfs.dbv or vfs\n            if vfs in seen:\n                continue\n\n            seen[vfs] = True\n            vols.append((vfs.vpath, vfs.realpath, vfs.flags))\n\n        t0 = time.time()\n        if idx.p_end:\n            penalty = 0.7\n            t_idle = t0 - idx.p_end\n            if idx.p_dur > 0.7 and t_idle < penalty:\n                t = \"rate-limit {:.1f} sec, cost {:.2f}, idle {:.2f}\"\n                raise Pebkac(429, t.format(penalty, idx.p_dur, t_idle))\n\n        if \"srch\" in body:\n            # search by up2k hashlist\n            vbody = copy.deepcopy(body)\n            vbody[\"hash\"] = len(vbody[\"hash\"])\n            self.log(\"qj: \" + repr(vbody))\n            hits = idx.fsearch(vols, body)\n            msg: Any = repr(hits)\n            taglist: list[str] = []\n            trunc = False\n        else:\n            # search by query params\n            q = body[\"q\"]\n            n = body.get(\"n\", self.args.srch_hits)\n            self.log(\"qj: {} |{}|\".format(q, n))\n            hits, taglist, trunc = idx.search(vols, q, n)\n            msg = len(hits)\n\n        idx.p_end = time.time()\n        idx.p_dur = idx.p_end - t0\n        self.log(\"q#: {} ({:.2f}s)\".format(msg, idx.p_dur))\n\n        order = []\n        cfg = self.args.mte.split(\",\")\n        for t in cfg:\n            if t in taglist:\n                order.append(t)\n        for t in taglist:\n            if t not in order:\n                order.append(t)\n\n        if self.is_vproxied:\n            for hit in hits:\n                hit[\"rp\"] = self.args.RS + hit[\"rp\"]\n\n        rj = {\"hits\": hits, \"tag_order\": order, \"trunc\": trunc}\n        r = json.dumps(rj).encode(\"utf-8\")\n        self.reply(r, mime=\"application/json\")\n        return True\n\n    def handle_post_binary(self) -> bool:\n        try:\n            remains = int(self.headers[\"content-length\"])\n        except:\n            raise Pebkac(400, \"you must supply a content-length for binary POST\")\n\n        try:\n            chash = self.headers[\"x-up2k-hash\"]\n            wark = self.headers[\"x-up2k-wark\"]\n        except KeyError:\n            raise Pebkac(400, \"need hash and wark headers for binary POST\")\n\n        vfs, _ = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        ptop = (vfs.dbv or vfs).realpath\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_chunk\", ptop, wark, chash)\n        response = x.get()\n        chunksize, cstart, path, lastmod, sprs = response\n\n        try:\n            if self.args.nw:\n                path = os.devnull\n\n            if remains > chunksize:\n                raise Pebkac(400, \"your chunk is too big to fit\")\n\n            self.log(\"writing {} #{} @{} len {}\".format(path, chash, cstart, remains))\n\n            reader = read_socket(self.sr, remains)\n\n            f = None\n            fpool = not self.args.no_fpool and sprs\n            if fpool:\n                with self.mutex:\n                    try:\n                        f = self.u2fh.pop(path)\n                    except:\n                        pass\n\n            f = f or open(fsenc(path), \"rb+\", 512 * 1024)\n\n            try:\n                f.seek(cstart[0])\n                post_sz, _, sha_b64 = hashcopy(reader, f, self.args.s_wr_slp)\n\n                if sha_b64 != chash:\n                    try:\n                        self.bakflip(f, cstart[0], post_sz, sha_b64)\n                    except:\n                        self.log(\"bakflip failed: \" + min_ex())\n\n                    t = \"your chunk got corrupted somehow (received {} bytes); expected vs received hash:\\n{}\\n{}\"\n                    raise Pebkac(400, t.format(post_sz, chash, sha_b64))\n\n                if len(cstart) > 1 and path != os.devnull:\n                    self.log(\n                        \"clone {} to {}\".format(\n                            cstart[0], \" & \".join(unicode(x) for x in cstart[1:])\n                        )\n                    )\n                    ofs = 0\n                    while ofs < chunksize:\n                        bufsz = min(chunksize - ofs, 4 * 1024 * 1024)\n                        f.seek(cstart[0] + ofs)\n                        buf = f.read(bufsz)\n                        for wofs in cstart[1:]:\n                            f.seek(wofs + ofs)\n                            f.write(buf)\n\n                        ofs += len(buf)\n\n                    self.log(\"clone {} done\".format(cstart[0]))\n\n                if not fpool:\n                    f.close()\n                else:\n                    with self.mutex:\n                        self.u2fh.put(path, f)\n            except:\n                # maybe busted handle (eg. disk went full)\n                f.close()\n                raise\n        finally:\n            x = self.conn.hsrv.broker.ask(\"up2k.release_chunk\", ptop, wark, chash)\n            x.get()  # block client until released\n\n        x = self.conn.hsrv.broker.ask(\"up2k.confirm_chunk\", ptop, wark, chash)\n        ztis = x.get()\n        try:\n            num_left, fin_path = ztis\n        except:\n            self.loud_reply(ztis, status=500)\n            return False\n\n        if not num_left and fpool:\n            with self.mutex:\n                self.u2fh.close(path)\n\n        if not num_left and not self.args.nw:\n            self.conn.hsrv.broker.ask(\n                \"up2k.finish_upload\", ptop, wark, self.u2fh.aps\n            ).get()\n\n        cinf = self.headers.get(\"x-up2k-stat\", \"\")\n\n        spd = self._spd(post_sz)\n        self.log(\"{:70} thank {}\".format(spd, cinf))\n        self.reply(b\"thank\")\n        return True\n\n    def handle_login(self) -> bool:\n        assert self.parser\n        pwd = self.parser.require(\"cppwd\", 64)\n        self.parser.drop()\n\n        self.out_headerlist = [\n            x for x in self.out_headerlist if x[0] != \"Set-Cookie\" or \"cppw\" != x[1][:4]\n        ]\n\n        dst = self.args.SRS\n        if self.vpath:\n            dst += quotep(self.vpath)\n\n        msg = self.get_pwd_cookie(pwd)\n        html = self.j2s(\"msg\", h1=msg, h2='<a href=\"' + dst + '\">ack</a>', redir=dst)\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def get_pwd_cookie(self, pwd: str) -> str:\n        if self.asrv.ah.hash(pwd) in self.asrv.iacct:\n            msg = \"login ok\"\n            dur = int(60 * 60 * self.args.logout)\n        else:\n            self.log(\"invalid password: {}\".format(pwd), 3)\n            g = self.conn.hsrv.gpwd\n            if g.lim:\n                bonk, ip = g.bonk(self.ip, pwd)\n                if bonk:\n                    xban = self.vn.flags.get(\"xban\")\n                    if not xban or not runhook(\n                        self.log,\n                        xban,\n                        self.vn.canonical(self.rem),\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        time.time(),\n                        0,\n                        self.ip,\n                        time.time(),\n                        \"pw\",\n                    ):\n                        self.log(\"client banned: invalid passwords\", 1)\n                        self.conn.hsrv.bans[ip] = bonk\n\n            msg = \"naw dude\"\n            pwd = \"x\"  # nosec\n            dur = None\n\n        if pwd == \"x\":\n            # reset both plaintext and tls\n            # (only affects active tls cookies when tls)\n            for k in (\"cppwd\", \"cppws\") if self.is_https else (\"cppwd\",):\n                ck = gencookie(k, pwd, self.args.R, False, dur)\n                self.out_headerlist.append((\"Set-Cookie\", ck))\n        else:\n            k = \"cppws\" if self.is_https else \"cppwd\"\n            ck = gencookie(k, pwd, self.args.R, self.is_https, dur)\n            self.out_headerlist.append((\"Set-Cookie\", ck))\n\n        return msg\n\n    def handle_mkdir(self) -> bool:\n        assert self.parser\n        new_dir = self.parser.require(\"name\", 512)\n        self.parser.drop()\n\n        sanitized = sanitize_fn(new_dir, \"\", [])\n        return self._mkdir(vjoin(self.vpath, sanitized))\n\n    def _mkdir(self, vpath: str, dav: bool = False) -> bool:\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n        fn = vfs.canonical(rem)\n\n        if not nullwrite:\n            fdir = os.path.dirname(fn)\n\n            if not bos.path.isdir(fdir):\n                raise Pebkac(409, \"parent folder does not exist\")\n\n            if bos.path.isdir(fn):\n                raise Pebkac(405, \"that folder exists already\")\n\n            try:\n                bos.mkdir(fn)\n            except OSError as ex:\n                if ex.errno == errno.EACCES:\n                    raise Pebkac(500, \"the server OS denied write-access\")\n\n                raise Pebkac(500, \"mkdir failed:\\n\" + min_ex())\n            except:\n                raise Pebkac(500, min_ex())\n\n        self.out_headers[\"X-New-Dir\"] = quotep(vpath.split(\"/\")[-1])\n\n        if dav:\n            self.reply(b\"\", 201)\n        else:\n            self.redirect(vpath, status=201)\n\n        return True\n\n    def handle_new_md(self) -> bool:\n        assert self.parser\n        new_file = self.parser.require(\"name\", 512)\n        self.parser.drop()\n\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n\n        if not new_file.endswith(\".md\"):\n            new_file += \".md\"\n\n        sanitized = sanitize_fn(new_file, \"\", [])\n\n        if not nullwrite:\n            fdir = vfs.canonical(rem)\n            fn = os.path.join(fdir, sanitized)\n\n            if bos.path.exists(fn):\n                raise Pebkac(500, \"that file exists already\")\n\n            with open(fsenc(fn), \"wb\") as f:\n                f.write(b\"`GRUNNUR`\\n\")\n\n        vpath = \"{}/{}\".format(self.vpath, sanitized).lstrip(\"/\")\n        self.redirect(vpath, \"?edit\")\n        return True\n\n    def upload_flags(self, vfs: VFS) -> tuple[int, bool, int, list[str], list[str]]:\n        if self.args.nw:\n            rnd = 0\n        else:\n            rnd = int(self.uparam.get(\"rand\") or self.headers.get(\"rand\") or 0)\n            if vfs.flags.get(\"rand\"):  # force-enable\n                rnd = max(rnd, vfs.flags[\"nrand\"])\n\n        ac = self.uparam.get(\n            \"want\", self.headers.get(\"accept\", \"\").lower().split(\";\")[-1]\n        )\n        want_url = ac == \"url\"\n        zs = self.uparam.get(\"life\", self.headers.get(\"life\", \"\"))\n        if zs:\n            vlife = vfs.flags.get(\"lifetime\") or 0\n            lifetime = max(0, int(vlife - int(zs)))\n        else:\n            lifetime = 0\n\n        return (\n            rnd,\n            want_url,\n            lifetime,\n            vfs.flags.get(\"xbu\") or [],\n            vfs.flags.get(\"xau\") or [],\n        )\n\n    def handle_plain_upload(self) -> bool:\n        assert self.parser\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, False, True)\n        self._assert_safe_rem(rem)\n\n        upload_vpath = self.vpath\n        lim = vfs.get_dbv(rem)[0].lim\n        fdir_base = vfs.canonical(rem)\n        if lim:\n            fdir_base, rem = lim.all(\n                self.ip, rem, -1, vfs.realpath, fdir_base, self.conn.hsrv.broker\n            )\n            upload_vpath = \"{}/{}\".format(vfs.vpath, rem).strip(\"/\")\n            if not nullwrite:\n                bos.makedirs(fdir_base)\n\n        rnd, want_url, lifetime, xbu, xau = self.upload_flags(vfs)\n\n        files: list[tuple[int, str, str, str, str, str]] = []\n        # sz, sha_hex, sha_b64, p_file, fname, abspath\n        errmsg = \"\"\n        dip = self.dip()\n        t0 = time.time()\n        try:\n            assert self.parser.gen\n            for nfile, (p_field, p_file, p_data) in enumerate(self.parser.gen):\n                if not p_file:\n                    self.log(\"discarding incoming file without filename\")\n                    # fallthrough\n\n                fdir = fdir_base\n                fname = sanitize_fn(\n                    p_file or \"\", \"\", [\".prologue.html\", \".epilogue.html\"]\n                )\n                if p_file and not nullwrite:\n                    if rnd:\n                        fname = rand_name(fdir, fname, rnd)\n\n                    if not bos.path.isdir(fdir):\n                        raise Pebkac(404, \"that folder does not exist\")\n\n                    suffix = \"-{:.6f}-{}\".format(time.time(), dip)\n                    open_args = {\"fdir\": fdir, \"suffix\": suffix}\n\n                    # reserve destination filename\n                    with ren_open(fname, \"wb\", fdir=fdir, suffix=suffix) as zfw:\n                        fname = zfw[\"orz\"][1]\n\n                    tnam = fname + \".PARTIAL\"\n                    if self.args.dotpart:\n                        tnam = \".\" + tnam\n\n                    abspath = os.path.join(fdir, fname)\n                else:\n                    open_args = {}\n                    tnam = fname = os.devnull\n                    fdir = abspath = \"\"\n\n                if xbu:\n                    at = time.time() - lifetime\n                    if not runhook(\n                        self.log,\n                        xbu,\n                        abspath,\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        at,\n                        0,\n                        self.ip,\n                        at,\n                        \"\",\n                    ):\n                        t = \"upload blocked by xbu server config\"\n                        self.log(t, 1)\n                        raise Pebkac(403, t)\n\n                if lim:\n                    lim.chk_bup(self.ip)\n                    lim.chk_nup(self.ip)\n\n                try:\n                    max_sz = 0\n                    if lim:\n                        v1 = lim.smax\n                        v2 = lim.dfv - lim.dfl\n                        max_sz = min(v1, v2) if v1 and v2 else v1 or v2\n\n                    with ren_open(tnam, \"wb\", 512 * 1024, **open_args) as zfw:\n                        f, tnam = zfw[\"orz\"]\n                        tabspath = os.path.join(fdir, tnam)\n                        self.log(\"writing to {}\".format(tabspath))\n                        sz, sha_hex, sha_b64 = hashcopy(\n                            p_data, f, self.args.s_wr_slp, max_sz\n                        )\n                        if sz == 0:\n                            raise Pebkac(400, \"empty files in post\")\n\n                    if lim:\n                        lim.nup(self.ip)\n                        lim.bup(self.ip, sz)\n                        try:\n                            lim.chk_df(tabspath, sz, True)\n                            lim.chk_sz(sz)\n                            lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, sz)\n                            lim.chk_bup(self.ip)\n                            lim.chk_nup(self.ip)\n                        except:\n                            if not nullwrite:\n                                bos.unlink(tabspath)\n                                bos.unlink(abspath)\n                            fname = os.devnull\n                            raise\n\n                    if not nullwrite:\n                        atomic_move(tabspath, abspath)\n\n                    files.append(\n                        (sz, sha_hex, sha_b64, p_file or \"(discarded)\", fname, abspath)\n                    )\n                    at = time.time() - lifetime\n                    if xau and not runhook(\n                        self.log,\n                        xau,\n                        abspath,\n                        self.vpath,\n                        self.host,\n                        self.uname,\n                        at,\n                        sz,\n                        self.ip,\n                        at,\n                        \"\",\n                    ):\n                        t = \"upload blocked by xau server config\"\n                        self.log(t, 1)\n                        os.unlink(abspath)\n                        raise Pebkac(403, t)\n\n                    dbv, vrem = vfs.get_dbv(rem)\n                    self.conn.hsrv.broker.say(\n                        \"up2k.hash_file\",\n                        dbv.realpath,\n                        vfs.vpath,\n                        dbv.flags,\n                        vrem,\n                        fname,\n                        self.ip,\n                        at,\n                        self.uname,\n                        True,\n                    )\n                    self.conn.nbyte += sz\n\n                except Pebkac:\n                    self.parser.drop()\n                    raise\n\n        except Pebkac as ex:\n            errmsg = vol_san(\n                list(self.asrv.vfs.all_vols.values()), unicode(ex).encode(\"utf-8\")\n            ).decode(\"utf-8\")\n\n        td = max(0.1, time.time() - t0)\n        sz_total = sum(x[0] for x in files)\n        spd = (sz_total / td) / (1024 * 1024)\n\n        status = \"OK\"\n        if errmsg:\n            self.log(errmsg, 3)\n            status = \"ERROR\"\n\n        msg = \"{} // {} bytes // {:.3f} MiB/s\\n\".format(status, sz_total, spd)\n        jmsg: dict[str, Any] = {\n            \"status\": status,\n            \"sz\": sz_total,\n            \"mbps\": round(spd, 3),\n            \"files\": [],\n        }\n\n        if errmsg:\n            msg += errmsg + \"\\n\"\n            jmsg[\"error\"] = errmsg\n            errmsg = \"ERROR: \" + errmsg\n\n        for sz, sha_hex, sha_b64, ofn, lfn, ap in files:\n            vsuf = \"\"\n            if (self.can_read or self.can_upget) and \"fk\" in vfs.flags:\n                vsuf = \"?k=\" + self.gen_fk(\n                    self.args.fk_salt,\n                    ap,\n                    sz,\n                    0 if ANYWIN or not ap else bos.stat(ap).st_ino,\n                )[: vfs.flags[\"fk\"]]\n\n            vpath = \"{}/{}\".format(upload_vpath, lfn).strip(\"/\")\n            rel_url = quotep(self.args.RS + vpath) + vsuf\n            msg += 'sha512: {} // {} // {} bytes // <a href=\"/{}\">{}</a> {}\\n'.format(\n                sha_hex[:56],\n                sha_b64,\n                sz,\n                rel_url,\n                html_escape(ofn, crlf=True),\n                vsuf,\n            )\n            # truncated SHA-512 prevents length extension attacks;\n            # using SHA-512/224, optionally SHA-512/256 = :64\n            jpart = {\n                \"url\": \"{}://{}/{}\".format(\n                    \"https\" if self.is_https else \"http\",\n                    self.host,\n                    rel_url,\n                ),\n                \"sha512\": sha_hex[:56],\n                \"sha_b64\": sha_b64,\n                \"sz\": sz,\n                \"fn\": lfn,\n                \"fn_orig\": ofn,\n                \"path\": rel_url,\n            }\n            jmsg[\"files\"].append(jpart)\n\n        vspd = self._spd(sz_total, False)\n        self.log(\"{} {}\".format(vspd, msg))\n\n        suf = \"\"\n        if not nullwrite and self.args.write_uplog:\n            try:\n                log_fn = \"up.{:.6f}.txt\".format(t0)\n                with open(log_fn, \"wb\") as f:\n                    ft = \"{}:{}\".format(self.ip, self.addr[1])\n                    ft = \"{}\\n{}\\n{}\\n\".format(ft, msg.rstrip(), errmsg)\n                    f.write(ft.encode(\"utf-8\"))\n            except Exception as ex:\n                suf = \"\\nfailed to write the upload report: {}\".format(ex)\n\n        sc = 400 if errmsg else 201\n        if want_url:\n            msg = \"\\n\".join([x[\"url\"] for x in jmsg[\"files\"]])\n            if errmsg:\n                msg += \"\\n\" + errmsg\n\n            self.reply(msg.encode(\"utf-8\", \"replace\"), status=sc)\n        elif \"j\" in self.uparam:\n            jtxt = json.dumps(jmsg, indent=2, sort_keys=True).encode(\"utf-8\", \"replace\")\n            self.reply(jtxt, mime=\"application/json\", status=sc)\n        else:\n            self.redirect(\n                self.vpath,\n                msg=msg + suf,\n                flavor=\"return to\",\n                click=False,\n                status=sc,\n            )\n\n        if errmsg:\n            return False\n\n        self.parser.drop()\n        return True\n\n    def handle_text_upload(self) -> bool:\n        assert self.parser\n        try:\n            cli_lastmod3 = int(self.parser.require(\"lastmod\", 16))\n        except:\n            raise Pebkac(400, \"could not read lastmod from request\")\n\n        nullwrite = self.args.nw\n        vfs, rem = self.asrv.vfs.get(self.vpath, self.uname, True, True)\n        self._assert_safe_rem(rem)\n\n        clen = int(self.headers.get(\"content-length\", -1))\n        if clen == -1:\n            raise Pebkac(411)\n\n        rp, fn = vsplit(rem)\n        fp = vfs.canonical(rp)\n        lim = vfs.get_dbv(rem)[0].lim\n        if lim:\n            fp, rp = lim.all(self.ip, rp, clen, vfs.realpath, fp, self.conn.hsrv.broker)\n            bos.makedirs(fp)\n\n        fp = os.path.join(fp, fn)\n        rem = \"{}/{}\".format(rp, fn).strip(\"/\")\n\n        if not rem.endswith(\".md\"):\n            raise Pebkac(400, \"only markdown pls\")\n\n        if nullwrite:\n            response = json.dumps({\"ok\": True, \"lastmod\": 0})\n            self.log(response)\n            # TODO reply should parser.drop()\n            self.parser.drop()\n            self.reply(response.encode(\"utf-8\"))\n            return True\n\n        srv_lastmod = -1.0\n        srv_lastmod3 = -1\n        try:\n            st = bos.stat(fp)\n            srv_lastmod = st.st_mtime\n            srv_lastmod3 = int(srv_lastmod * 1000)\n        except OSError as ex:\n            if ex.errno != errno.ENOENT:\n                raise\n\n        # if file exists, chekc that timestamp matches the client's\n        if srv_lastmod >= 0:\n            same_lastmod = cli_lastmod3 in [-1, srv_lastmod3]\n            if not same_lastmod:\n                # some filesystems/transports limit precision to 1sec, hopefully floored\n                same_lastmod = (\n                    srv_lastmod == int(cli_lastmod3 / 1000)\n                    and cli_lastmod3 > srv_lastmod3\n                    and cli_lastmod3 - srv_lastmod3 < 1000\n                )\n\n            if not same_lastmod:\n                response = json.dumps(\n                    {\n                        \"ok\": False,\n                        \"lastmod\": srv_lastmod3,\n                        \"now\": int(time.time() * 1000),\n                    }\n                )\n                self.log(\n                    \"{} - {} = {}\".format(\n                        srv_lastmod3, cli_lastmod3, srv_lastmod3 - cli_lastmod3\n                    )\n                )\n                self.log(response)\n                self.parser.drop()\n                self.reply(response.encode(\"utf-8\"))\n                return True\n\n            mdir, mfile = os.path.split(fp)\n            mfile2 = \"{}.{:.3f}.md\".format(mfile[:-3], srv_lastmod)\n            try:\n                dp = os.path.join(mdir, \".hist\")\n                bos.mkdir(dp)\n                hidedir(dp)\n            except:\n                pass\n            bos.rename(fp, os.path.join(mdir, \".hist\", mfile2))\n\n        assert self.parser.gen\n        p_field, _, p_data = next(self.parser.gen)\n        if p_field != \"body\":\n            raise Pebkac(400, \"expected body, got {}\".format(p_field))\n\n        xbu = vfs.flags.get(\"xbu\")\n        if xbu:\n            if not runhook(\n                self.log,\n                xbu,\n                fp,\n                self.vpath,\n                self.host,\n                self.uname,\n                time.time(),\n                0,\n                self.ip,\n                time.time(),\n                \"\",\n            ):\n                t = \"save blocked by xbu server config\"\n                self.log(t, 1)\n                raise Pebkac(403, t)\n\n        if bos.path.exists(fp):\n            bos.unlink(fp)\n\n        with open(fsenc(fp), \"wb\", 512 * 1024) as f:\n            sz, sha512, _ = hashcopy(p_data, f, self.args.s_wr_slp)\n\n        if lim:\n            lim.nup(self.ip)\n            lim.bup(self.ip, sz)\n            try:\n                lim.chk_sz(sz)\n                lim.chk_vsz(self.conn.hsrv.broker, vfs.realpath, sz)\n            except:\n                bos.unlink(fp)\n                raise\n\n        new_lastmod = bos.stat(fp).st_mtime\n        new_lastmod3 = int(new_lastmod * 1000)\n        sha512 = sha512[:56]\n\n        xau = vfs.flags.get(\"xau\")\n        if xau and not runhook(\n            self.log,\n            xau,\n            fp,\n            self.vpath,\n            self.host,\n            self.uname,\n            new_lastmod,\n            sz,\n            self.ip,\n            new_lastmod,\n            \"\",\n        ):\n            t = \"save blocked by xau server config\"\n            self.log(t, 1)\n            os.unlink(fp)\n            raise Pebkac(403, t)\n\n        vfs, rem = vfs.get_dbv(rem)\n        self.conn.hsrv.broker.say(\n            \"up2k.hash_file\",\n            vfs.realpath,\n            vfs.vpath,\n            vfs.flags,\n            vsplit(rem)[0],\n            fn,\n            self.ip,\n            new_lastmod,\n            self.uname,\n            True,\n        )\n\n        response = json.dumps(\n            {\"ok\": True, \"lastmod\": new_lastmod3, \"size\": sz, \"sha512\": sha512}\n        )\n        self.log(response)\n        self.parser.drop()\n        self.reply(response.encode(\"utf-8\"))\n        return True\n\n    def _chk_lastmod(self, file_ts: int) -> tuple[str, bool]:\n        file_lastmod = formatdate(file_ts, usegmt=True)\n        cli_lastmod = self.headers.get(\"if-modified-since\")\n        if cli_lastmod:\n            try:\n                # some browser append \"; length=573\"\n                cli_lastmod = cli_lastmod.split(\";\")[0].strip()\n                cli_dt = parsedate(cli_lastmod)\n                assert cli_dt\n                cli_ts = calendar.timegm(cli_dt)\n                return file_lastmod, int(file_ts) > int(cli_ts)\n            except Exception as ex:\n                self.log(\n                    \"lastmod {}\\nremote: [{}]\\n local: [{}]\".format(\n                        repr(ex), cli_lastmod, file_lastmod\n                    )\n                )\n                return file_lastmod, file_lastmod != cli_lastmod\n\n        return file_lastmod, True\n\n    def tx_file(self, req_path: str) -> bool:\n        status = 200\n        logmsg = \"{:4} {} \".format(\"\", self.req)\n        logtail = \"\"\n\n        #\n        # if request is for foo.js, check if we have foo.js.{gz,br}\n\n        file_ts = 0\n        editions: dict[str, tuple[str, int]] = {}\n        for ext in [\"\", \".gz\", \".br\"]:\n            try:\n                fs_path = req_path + ext\n                st = bos.stat(fs_path)\n                if stat.S_ISDIR(st.st_mode):\n                    continue\n\n                if stat.S_ISBLK(st.st_mode):\n                    fd = bos.open(fs_path, os.O_RDONLY)\n                    try:\n                        sz = os.lseek(fd, 0, os.SEEK_END)\n                    finally:\n                        os.close(fd)\n                else:\n                    sz = st.st_size\n\n                file_ts = max(file_ts, int(st.st_mtime))\n                editions[ext or \"plain\"] = (fs_path, sz)\n            except:\n                pass\n            if not self.vpath.startswith(\".cpr/\"):\n                break\n\n        if not editions:\n            return self.tx_404()\n\n        #\n        # if-modified\n\n        file_lastmod, do_send = self._chk_lastmod(file_ts)\n        self.out_headers[\"Last-Modified\"] = file_lastmod\n        if not do_send:\n            status = 304\n\n        #\n        # Accept-Encoding and UA decides which edition to send\n\n        decompress = False\n        supported_editions = [\n            x.strip()\n            for x in self.headers.get(\"accept-encoding\", \"\").lower().split(\",\")\n        ]\n        if \".br\" in editions and \"br\" in supported_editions:\n            is_compressed = True\n            selected_edition = \".br\"\n            fs_path, file_sz = editions[\".br\"]\n            self.out_headers[\"Content-Encoding\"] = \"br\"\n        elif \".gz\" in editions:\n            is_compressed = True\n            selected_edition = \".gz\"\n            fs_path, file_sz = editions[\".gz\"]\n            if \"gzip\" not in supported_editions:\n                decompress = True\n            else:\n                if re.match(r\"MSIE [4-6]\\.\", self.ua) and \" SV1\" not in self.ua:\n                    decompress = True\n\n            if not decompress:\n                self.out_headers[\"Content-Encoding\"] = \"gzip\"\n        else:\n            is_compressed = False\n            selected_edition = \"plain\"\n\n        try:\n            fs_path, file_sz = editions[selected_edition]\n            logmsg += \"{} \".format(selected_edition.lstrip(\".\"))\n        except:\n            # client is old and we only have .br\n            # (could make brotli a dep to fix this but it's not worth)\n            raise Pebkac(404)\n\n        #\n        # partial\n\n        lower = 0\n        upper = file_sz\n        hrange = self.headers.get(\"range\")\n\n        # let's not support 206 with compression\n        # and multirange / multipart is also not-impl (mostly because calculating contentlength is a pain)\n        if do_send and not is_compressed and hrange and file_sz and \",\" not in hrange:\n            try:\n                if not hrange.lower().startswith(\"bytes\"):\n                    raise Exception()\n\n                a, b = hrange.split(\"=\", 1)[1].split(\"-\")\n\n                if a.strip():\n                    lower = int(a.strip())\n                else:\n                    lower = 0\n\n                if b.strip():\n                    upper = int(b.strip()) + 1\n                else:\n                    upper = file_sz\n\n                if upper > file_sz:\n                    upper = file_sz\n\n                if lower < 0 or lower >= upper:\n                    raise Exception()\n\n            except:\n                err = \"invalid range ({}), size={}\".format(hrange, file_sz)\n                self.loud_reply(\n                    err,\n                    status=416,\n                    headers={\"Content-Range\": \"bytes */{}\".format(file_sz)},\n                )\n                return True\n\n            status = 206\n            self.out_headers[\"Content-Range\"] = \"bytes {}-{}/{}\".format(\n                lower, upper - 1, file_sz\n            )\n\n            logtail += \" [\\033[36m{}-{}\\033[0m]\".format(lower, upper)\n\n        use_sendfile = False\n        if decompress:\n            open_func: Any = gzip.open\n            open_args: list[Any] = [fsenc(fs_path), \"rb\"]\n            # Content-Length := original file size\n            upper = gzip_orig_sz(fs_path)\n        else:\n            open_func = open\n            # 512 kB is optimal for huge files, use 64k\n            open_args = [fsenc(fs_path), \"rb\", 64 * 1024]\n            use_sendfile = (\n                not self.tls  #\n                and not self.args.no_sendfile\n                and hasattr(os, \"sendfile\")\n            )\n\n        #\n        # send reply\n\n        if is_compressed:\n            self.out_headers[\"Cache-Control\"] = \"max-age=604869\"\n        else:\n            self.permit_caching()\n\n        if \"txt\" in self.uparam:\n            mime = \"text/plain; charset={}\".format(self.uparam[\"txt\"] or \"utf-8\")\n        elif \"mime\" in self.uparam:\n            mime = str(self.uparam.get(\"mime\"))\n        else:\n            mime = guess_mime(req_path)\n\n        if \"nohtml\" in self.vn.flags and \"html\" in mime:\n            mime = \"text/plain; charset=utf-8\"\n\n        self.out_headers[\"Accept-Ranges\"] = \"bytes\"\n        self.send_headers(length=upper - lower, status=status, mime=mime)\n\n        logmsg += unicode(status) + logtail\n\n        if self.mode == \"HEAD\" or not do_send:\n            if self.do_log:\n                self.log(logmsg)\n\n            return True\n\n        ret = True\n        with open_func(*open_args) as f:\n            sendfun = sendfile_kern if use_sendfile else sendfile_py\n            remains = sendfun(\n                self.log, lower, upper, f, self.s, self.args.s_wr_sz, self.args.s_wr_slp\n            )\n\n        if remains > 0:\n            logmsg += \" \\033[31m\" + unicode(upper - remains) + \"\\033[0m\"\n            self.keepalive = False\n\n        spd = self._spd((upper - lower) - remains)\n        if self.do_log:\n            self.log(\"{},  {}\".format(logmsg, spd))\n\n        return ret\n\n    def tx_zip(\n        self,\n        fmt: str,\n        uarg: str,\n        vpath: str,\n        vn: VFS,\n        rem: str,\n        items: list[str],\n        dots: bool,\n    ) -> bool:\n        if self.args.no_zip:\n            raise Pebkac(400, \"not enabled\")\n\n        logmsg = \"{:4} {} \".format(\"\", self.req)\n        self.keepalive = False\n\n        if fmt == \"tar\":\n            mime = \"application/x-tar\"\n            packer: Type[StreamArc] = StreamTar\n        else:\n            mime = \"application/zip\"\n            packer = StreamZip\n\n        fn = items[0] if items and items[0] else self.vpath\n        if fn:\n            fn = fn.rstrip(\"/\").split(\"/\")[-1]\n        else:\n            fn = self.host.split(\":\")[0]\n\n        safe = (string.ascii_letters + string.digits).replace(\"%\", \"\")\n        afn = \"\".join([x if x in safe.replace('\"', \"\") else \"_\" for x in fn])\n        bascii = unicode(safe).encode(\"utf-8\")\n        zb = fn.encode(\"utf-8\", \"xmlcharrefreplace\")\n        if not PY2:\n            zbl = [\n                chr(x).encode(\"utf-8\")\n                if x in bascii\n                else \"%{:02x}\".format(x).encode(\"ascii\")\n                for x in zb\n            ]\n        else:\n            zbl = [unicode(x) if x in bascii else \"%{:02x}\".format(ord(x)) for x in zb]\n\n        ufn = b\"\".join(zbl).decode(\"ascii\")\n\n        cdis = \"attachment; filename=\\\"{}.{}\\\"; filename*=UTF-8''{}.{}\"\n        cdis = cdis.format(afn, fmt, ufn, fmt)\n        self.log(cdis)\n        self.send_headers(None, mime=mime, headers={\"Content-Disposition\": cdis})\n\n        fgen = vn.zipgen(\n            vpath, rem, set(items), self.uname, dots, False, not self.args.no_scandir\n        )\n        # for f in fgen: print(repr({k: f[k] for k in [\"vp\", \"ap\"]}))\n        bgen = packer(self.log, fgen, utf8=\"utf\" in uarg, pre_crc=\"crc\" in uarg)\n        bsent = 0\n        for buf in bgen.gen():\n            if not buf:\n                break\n\n            try:\n                self.s.sendall(buf)\n                bsent += len(buf)\n            except:\n                logmsg += \" \\033[31m\" + unicode(bsent) + \"\\033[0m\"\n                break\n\n        spd = self._spd(bsent)\n        self.log(\"{},  {}\".format(logmsg, spd))\n        return True\n\n    def tx_ico(self, ext: str, exact: bool = False) -> bool:\n        self.permit_caching()\n        if ext.endswith(\"/\"):\n            ext = \"folder\"\n            exact = True\n\n        bad = re.compile(r\"[](){}/ []|^[0-9_-]*$\")\n        n = ext.split(\".\")[::-1]\n        if not exact:\n            n = n[:-1]\n\n        ext = \"\"\n        for v in n:\n            if len(v) > 7 or bad.search(v):\n                break\n\n            ext = \"{}.{}\".format(v, ext)\n\n        ext = ext.rstrip(\".\") or \"unk\"\n        if len(ext) > 11:\n            ext = \"\u22ef\" + ext[-9:]\n\n        # chrome cannot handle more than ~2000 unique SVGs\n        chrome = \" rv:\" not in self.ua\n        mime, ico = self.ico.get(ext, not exact, chrome)\n\n        lm = formatdate(self.E.t0, usegmt=True)\n        self.reply(ico, mime=mime, headers={\"Last-Modified\": lm})\n        return True\n\n    def tx_md(self, fs_path: str) -> bool:\n        logmsg = \"     %s @%s \" % (self.req, self.uname)\n\n        if not self.can_write:\n            if \"edit\" in self.uparam or \"edit2\" in self.uparam:\n                return self.tx_404(True)\n\n        tpl = \"mde\" if \"edit2\" in self.uparam else \"md\"\n        html_path = os.path.join(self.E.mod, \"web\", \"{}.html\".format(tpl))\n        template = self.j2j(tpl)\n\n        st = bos.stat(fs_path)\n        ts_md = st.st_mtime\n\n        st = bos.stat(html_path)\n        ts_html = st.st_mtime\n\n        sz_md = 0\n        for buf in yieldfile(fs_path):\n            sz_md += len(buf)\n            for c, v in [(b\"&\", 4), (b\"<\", 3), (b\">\", 3)]:\n                sz_md += (len(buf) - len(buf.replace(c, b\"\"))) * v\n\n        file_ts = int(max(ts_md, ts_html, self.E.t0))\n        file_lastmod, do_send = self._chk_lastmod(file_ts)\n        self.out_headers[\"Last-Modified\"] = file_lastmod\n        self.out_headers.update(NO_CACHE)\n        status = 200 if do_send else 304\n\n        arg_base = \"?\"\n        if \"k\" in self.uparam:\n            arg_base = \"?k={}&\".format(self.uparam[\"k\"])\n\n        boundary = \"\\roll\\tide\"\n        targs = {\n            \"r\": self.args.SR if self.is_vproxied else \"\",\n            \"ts\": self.conn.hsrv.cachebuster(),\n            \"svcname\": self.args.doctitle,\n            \"html_head\": self.html_head,\n            \"edit\": \"edit\" in self.uparam,\n            \"title\": html_escape(self.vpath, crlf=True),\n            \"lastmod\": int(ts_md * 1000),\n            \"lang\": self.args.lang,\n            \"favico\": self.args.favico,\n            \"have_emp\": self.args.emp,\n            \"md_chk_rate\": self.args.mcr,\n            \"md\": boundary,\n            \"arg_base\": arg_base,\n        }\n        zs = template.render(**targs).encode(\"utf-8\", \"replace\")\n        html = zs.split(boundary.encode(\"utf-8\"))\n        if len(html) != 2:\n            raise Exception(\"boundary appears in \" + html_path)\n\n        self.send_headers(sz_md + len(html[0]) + len(html[1]), status)\n\n        logmsg += unicode(status)\n        if self.mode == \"HEAD\" or not do_send:\n            if self.do_log:\n                self.log(logmsg)\n\n            return True\n\n        try:\n            self.s.sendall(html[0])\n            for buf in yieldfile(fs_path):\n                self.s.sendall(html_bescape(buf))\n\n            self.s.sendall(html[1])\n\n        except:\n            self.log(logmsg + \" \\033[31md/c\\033[0m\")\n            return False\n\n        if self.do_log:\n            self.log(logmsg + \" \" + unicode(len(html)))\n\n        return True\n\n    def tx_svcs(self) -> bool:\n        aname = re.sub(\"[^0-9a-zA-Z]+\", \"\", self.args.name) or \"a\"\n        ep = self.host\n        host = ep.split(\":\")[0]\n        hport = ep[ep.find(\":\") :] if \":\" in ep else \"\"\n        rip = (\n            host\n            if self.args.rclone_mdns or not self.args.zm\n            else self.conn.hsrv.nm.map(self.ip) or host\n        )\n        # safer than html_escape/quotep since this avoids both XSS and shell-stuff\n        pw = re.sub(r\"[<>&$?`]\", \"_\", self.pw or \"pw\")\n        vp = re.sub(r\"[<>&$?`]\", \"_\", self.uparam[\"hc\"] or \"\").lstrip(\"/\")\n        html = self.j2s(\n            \"svcs\",\n            args=self.args,\n            accs=bool(self.asrv.acct),\n            s=\"s\" if self.is_https else \"\",\n            rip=rip,\n            ep=ep,\n            vp=vp,\n            rvp=vjoin(self.args.R, vp),\n            host=host,\n            hport=hport,\n            aname=aname,\n            pw=pw,\n        )\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def tx_mounts(self) -> bool:\n        suf = self.urlq({}, [\"h\"])\n        rvol, wvol, avol = [\n            [(\"/\" + x).rstrip(\"/\") + \"/\" for x in y]\n            for y in [self.rvol, self.wvol, self.avol]\n        ]\n\n        if self.avol and not self.args.no_rescan:\n            x = self.conn.hsrv.broker.ask(\"up2k.get_state\")\n            vs = json.loads(x.get())\n            vstate = {(\"/\" + k).rstrip(\"/\") + \"/\": v for k, v in vs[\"volstate\"].items()}\n        else:\n            vstate = {}\n            vs = {\n                \"scanning\": None,\n                \"hashq\": None,\n                \"tagq\": None,\n                \"mtpq\": None,\n                \"dbwt\": None,\n            }\n\n        fmt = self.uparam.get(\"ls\", \"\")\n        if not fmt and (self.ua.startswith(\"curl/\") or self.ua.startswith(\"fetch\")):\n            fmt = \"v\"\n\n        if fmt in [\"v\", \"t\", \"txt\"]:\n            if self.uname == \"*\":\n                txt = \"howdy stranger (you're not logged in)\"\n            else:\n                txt = \"welcome back {}\".format(self.uname)\n\n            if vstate:\n                txt += \"\\nstatus:\"\n                for k in [\"scanning\", \"hashq\", \"tagq\", \"mtpq\", \"dbwt\"]:\n                    txt += \" {}({})\".format(k, vs[k])\n\n            if rvol:\n                txt += \"\\nyou can browse:\"\n                for v in rvol:\n                    txt += \"\\n  \" + v\n\n            if wvol:\n                txt += \"\\nyou can upload to:\"\n                for v in wvol:\n                    txt += \"\\n  \" + v\n\n            zb = txt.encode(\"utf-8\", \"replace\") + b\"\\n\"\n            self.reply(zb, mime=\"text/plain; charset=utf-8\")\n            return True\n\n        html = self.j2s(\n            \"splash\",\n            this=self,\n            qvpath=quotep(self.vpath),\n            rvol=rvol,\n            wvol=wvol,\n            avol=avol,\n            vstate=vstate,\n            scanning=vs[\"scanning\"],\n            hashq=vs[\"hashq\"],\n            tagq=vs[\"tagq\"],\n            mtpq=vs[\"mtpq\"],\n            dbwt=vs[\"dbwt\"],\n            url_suf=suf,\n            k304=self.k304(),\n            ver=S_VERSION if self.args.ver else \"\",\n            ahttps=\"\" if self.is_https else \"https://\" + self.host + self.req,\n        )\n        self.reply(html.encode(\"utf-8\"))\n        return True\n\n    def set_k304(self) -> bool:\n        v = self.uparam[\"k304\"].lower()\n        if v == \"y\":\n            dur = 86400 * 299\n        else:\n            dur = None\n            v = \"x\"\n\n        ck = gencookie(\"k304\", v, self.args.R, False, dur)\n        self.out_headerlist.append((\"Set-Cookie\", ck))\n        self.redirect(\"\", \"?h#cc\")\n        return True\n\n    def setck(self) -> bool:\n        k, v = self.uparam[\"setck\"].split(\"=\", 1)\n        t = None if v == \"\" else 86400 * 299\n        ck = gencookie(k, v, self.args.R, False, t)\n        self.out_headerlist.append((\"Set-Cookie\", ck))\n        self.reply(b\"o7\\n\")\n        return True\n\n    def set_cfg_reset(self) -> bool:\n        for k in (\"k304\", \"js\", \"idxh\", \"cppwd\", \"cppws\"):\n            cookie = gencookie(k, \"x\", self.args.R, False, None)\n            self.out_headerlist.append((\"Set-Cookie\", cookie))\n\n        self.redirect(\"\", \"?h#cc\")\n        return True\n\n    def tx_404(self, is_403: bool = False) -> bool:\n        rc = 404\n        if self.args.vague_403:\n            t = '<h1 id=\"n\">404 not found &nbsp;\u2510( \u00b4 -`)\u250c</h1><p id=\"o\">or maybe you don\\'t have access -- try logging in or <a href=\"{}/?h\">go home</a></p>'\n        elif is_403:\n            t = '<h1 id=\"p\">403 forbiddena &nbsp;~\u253b\u2501\u253b</h1><p id=\"q\">you\\'ll have to log in or <a href=\"{}/?h\">go home</a></p>'\n            rc = 403\n        else:\n            t = '<h1 id=\"n\">404 not found &nbsp;\u2510( \u00b4 -`)\u250c</h1><p><a id=\"r\" href=\"{}/?h\">go home</a></p>'\n\n        t = t.format(self.args.SR)\n        html = self.j2s(\"splash\", this=self, qvpath=quotep(self.vpath), msg=t)\n        self.reply(html.encode(\"utf-8\"), status=rc)\n        return True\n\n    def on40x(self, mods: list[str], vn: VFS, rem: str) -> str:\n        for mpath in mods:\n            try:\n                mod = loadpy(mpath, self.args.hot_handlers)\n            except Exception as ex:\n                self.log(\"import failed: {!r}\".format(ex))\n                continue\n\n            ret = mod.main(self, vn, rem)\n            if ret:\n                return ret.lower()\n\n        return \"\"  # unhandled / fallthrough\n\n    def scanvol(self) -> bool:\n        if not self.can_admin:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_rescan:\n            raise Pebkac(403, \"the rescan feature is disabled in server config\")\n\n        vn, _ = self.asrv.vfs.get(self.vpath, self.uname, True, True)\n\n        args = [self.asrv.vfs.all_vols, [vn.vpath], False, True]\n\n        x = self.conn.hsrv.broker.ask(\"up2k.rescan\", *args)\n        err = x.get()\n        if not err:\n            self.redirect(\"\", \"?h\")\n            return True\n\n        raise Pebkac(500, err)\n\n    def handle_reload(self) -> bool:\n        act = self.uparam.get(\"reload\")\n        if act != \"cfg\":\n            raise Pebkac(400, \"only config files ('cfg') can be reloaded rn\")\n\n        if not self.avol:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_reload:\n            raise Pebkac(403, \"the reload feature is disabled in server config\")\n\n        x = self.conn.hsrv.broker.ask(\"reload\")\n        return self.redirect(\"\", \"?h\", x.get(), \"return to\", False)\n\n    def tx_stack(self) -> bool:\n        if not self.avol and not [x for x in self.wvol if x in self.rvol]:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_stack:\n            raise Pebkac(403, \"the stackdump feature is disabled in server config\")\n\n        ret = \"<pre>{}\\n{}\".format(time.time(), html_escape(alltrace()))\n        self.reply(ret.encode(\"utf-8\"))\n        return True\n\n    def tx_tree(self) -> bool:\n        top = self.uparam[\"tree\"] or \"\"\n        dst = self.vpath\n        if top in [\".\", \"..\"]:\n            top = undot(self.vpath + \"/\" + top)\n\n        if top == dst:\n            dst = \"\"\n        elif top:\n            if not dst.startswith(top + \"/\"):\n                raise Pebkac(400, \"arg funk\")\n\n            dst = dst[len(top) + 1 :]\n\n        ret = self.gen_tree(top, dst)\n        if self.is_vproxied:\n            parents = self.args.R.split(\"/\")\n            for parent in reversed(parents):\n                ret = {\"k%s\" % (parent,): ret, \"a\": []}\n\n        zs = json.dumps(ret)\n        self.reply(zs.encode(\"utf-8\"), mime=\"application/json\")\n        return True\n\n    def gen_tree(self, top: str, target: str) -> dict[str, Any]:\n        ret: dict[str, Any] = {}\n        excl = None\n        if target:\n            excl, target = (target.split(\"/\", 1) + [\"\"])[:2]\n            sub = self.gen_tree(\"/\".join([top, excl]).strip(\"/\"), target)\n            ret[\"k\" + quotep(excl)] = sub\n\n        try:\n            vn, rem = self.asrv.vfs.get(top, self.uname, True, False)\n            fsroot, vfs_ls, vfs_virt = vn.ls(\n                rem,\n                self.uname,\n                not self.args.no_scandir,\n                [[True, False], [False, True]],\n            )\n        except:\n            vfs_ls = []\n            vfs_virt = {}\n            for v in self.rvol:\n                d1, d2 = v.rsplit(\"/\", 1) if \"/\" in v else [\"\", v]\n                if d1 == top:\n                    vfs_virt[d2] = self.asrv.vfs  # typechk, value never read\n\n        dirs = []\n\n        dirnames = [x[0] for x in vfs_ls if stat.S_ISDIR(x[1].st_mode)]\n\n        if not self.args.ed or \"dots\" not in self.uparam:\n            dirnames = exclude_dotfiles(dirnames)\n\n        for fn in [x for x in dirnames if x != excl]:\n            dirs.append(quotep(fn))\n\n        for x in vfs_virt:\n            if x != excl:\n                dirs.append(x)\n\n        ret[\"a\"] = dirs\n        return ret\n\n    def tx_ups(self) -> bool:\n        if not self.args.unpost:\n            raise Pebkac(403, \"the unpost feature is disabled in server config\")\n\n        idx = self.conn.get_u2idx()\n        if not idx or not hasattr(idx, \"p_end\"):\n            raise Pebkac(500, \"sqlite3 is not available on the server; cannot unpost\")\n\n        filt = self.uparam.get(\"filter\")\n        filt = unquotep(filt or \"\")\n        lm = \"ups [{}]\".format(filt)\n        self.log(lm)\n\n        ret: list[dict[str, Any]] = []\n        t0 = time.time()\n        lim = time.time() - self.args.unpost\n        fk_vols = {\n            vol: vol.flags[\"fk\"]\n            for vp, vol in self.asrv.vfs.all_vols.items()\n            if \"fk\" in vol.flags and (vp in self.rvol or vp in self.upvol)\n        }\n        for vol in self.asrv.vfs.all_vols.values():\n            cur = idx.get_cur(vol.realpath)\n            if not cur:\n                continue\n\n            nfk = fk_vols.get(vol, 0)\n\n            q = \"select sz, rd, fn, at from up where ip=? and at>?\"\n            for sz, rd, fn, at in cur.execute(q, (self.ip, lim)):\n                vp = \"/\" + \"/\".join(x for x in [vol.vpath, rd, fn] if x)\n                if filt and filt not in vp:\n                    continue\n\n                rv = {\"vp\": quotep(vp), \"sz\": sz, \"at\": at, \"nfk\": nfk}\n                if nfk:\n                    rv[\"ap\"] = vol.canonical(vjoin(rd, fn))\n\n                ret.append(rv)\n                if len(ret) > 3000:\n                    ret.sort(key=lambda x: x[\"at\"], reverse=True)  # type: ignore\n                    ret = ret[:2000]\n\n        ret.sort(key=lambda x: x[\"at\"], reverse=True)  # type: ignore\n        n = 0\n        for rv in ret[:11000]:\n            nfk = rv.pop(\"nfk\")\n            if not nfk:\n                continue\n\n            ap = rv.pop(\"ap\")\n            try:\n                st = bos.stat(ap)\n            except:\n                continue\n\n            fk = self.gen_fk(\n                self.args.fk_salt, ap, st.st_size, 0 if ANYWIN else st.st_ino\n            )\n            rv[\"vp\"] += \"?k=\" + fk[:nfk]\n\n            n += 1\n            if n > 2000:\n                break\n\n        ret = ret[:2000]\n\n        if self.is_vproxied:\n            for v in ret:\n                v[\"vp\"] = self.args.SR + v[\"vp\"]\n\n        jtxt = json.dumps(ret, indent=2, sort_keys=True).encode(\"utf-8\", \"replace\")\n        self.log(\"{} #{} {:.2f}sec\".format(lm, len(ret), time.time() - t0))\n        self.reply(jtxt, mime=\"application/json\")\n        return True\n\n    def handle_rm(self, req: list[str]) -> bool:\n        if not req and not self.can_delete:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_del:\n            raise Pebkac(403, \"the delete feature is disabled in server config\")\n\n        if not req:\n            req = [self.vpath]\n        elif self.is_vproxied:\n            req = [x[len(self.args.SR) :] for x in req]\n\n        nlim = int(self.uparam.get(\"lim\") or 0)\n        lim = [nlim, nlim] if nlim else []\n\n        x = self.conn.hsrv.broker.ask(\n            \"up2k.handle_rm\", self.uname, self.ip, req, lim, False\n        )\n        self.loud_reply(x.get())\n        return True\n\n    def handle_mv(self) -> bool:\n        # full path of new loc (incl filename)\n        dst = self.uparam.get(\"move\")\n\n        if self.is_vproxied and dst and dst.startswith(self.args.SR):\n            dst = dst[len(self.args.RS) :]\n\n        if not dst:\n            raise Pebkac(400, \"need dst vpath\")\n\n        # x-www-form-urlencoded (url query part) uses\n        # either + or %20 for 0x20 so handle both\n        dst = unquotep(dst.replace(\"+\", \" \"))\n        return self._mv(self.vpath, dst.lstrip(\"/\"))\n\n    def _mv(self, vsrc: str, vdst: str) -> bool:\n        if not self.can_move:\n            raise Pebkac(403, \"not allowed for user \" + self.uname)\n\n        if self.args.no_mv:\n            raise Pebkac(403, \"the rename/move feature is disabled in server config\")\n\n        x = self.conn.hsrv.broker.ask(\"up2k.handle_mv\", self.uname, vsrc, vdst)\n        self.loud_reply(x.get(), status=201)\n        return True\n\n    def tx_ls(self, ls: dict[str, Any]) -> bool:\n        dirs = ls[\"dirs\"]\n        files = ls[\"files\"]\n        arg = self.uparam[\"ls\"]\n        if arg in [\"v\", \"t\", \"txt\"]:\n            try:\n                biggest = max(ls[\"files\"] + ls[\"dirs\"], key=itemgetter(\"sz\"))[\"sz\"]\n            except:\n                biggest = 0\n\n            if arg == \"v\":\n                fmt = \"\\033[0;7;36m{{}}{{:>{}}}\\033[0m {{}}\"\n                nfmt = \"{}\"\n                biggest = 0\n                f2 = \"\".join(\n                    \"{}{{}}\".format(x)\n                    for x in [\n                        \"\\033[7m\",\n                        \"\\033[27m\",\n                        \"\",\n                        \"\\033[0;1m\",\n                        \"\\033[0;36m\",\n                        \"\\033[0m\",\n                    ]\n                )\n                ctab = {\"B\": 6, \"K\": 5, \"M\": 1, \"G\": 3}\n                for lst in [dirs, files]:\n                    for x in lst:\n                        a = x[\"dt\"].replace(\"-\", \" \").replace(\":\", \" \").split(\" \")\n                        x[\"dt\"] = f2.format(*list(a))\n                        sz = humansize(x[\"sz\"], True)\n                        x[\"sz\"] = \"\\033[0;3{}m {:>5}\".format(ctab.get(sz[-1:], 0), sz)\n            else:\n                fmt = \"{{}}  {{:{},}}  {{}}\"\n                nfmt = \"{:,}\"\n\n            for x in dirs:\n                n = x[\"name\"] + \"/\"\n                if arg == \"v\":\n                    n = \"\\033[94m\" + n\n\n                x[\"name\"] = n\n\n            fmt = fmt.format(len(nfmt.format(biggest)))\n            retl = [\n                \"# {}: {}\".format(x, ls[x])\n                for x in [\"acct\", \"perms\", \"srvinf\"]\n                if x in ls\n            ]\n            retl += [\n                fmt.format(x[\"dt\"], x[\"sz\"], x[\"name\"])\n                for y in [dirs, files]\n                for x in y\n            ]\n            ret = \"\\n\".join(retl)\n            mime = \"text/plain; charset=utf-8\"\n        else:\n            [x.pop(k) for k in [\"name\", \"dt\"] for y in [dirs, files] for x in y]\n\n            ret = json.dumps(ls)\n            mime = \"application/json\"\n\n        ret += \"\\n\\033[0m\" if arg == \"v\" else \"\\n\"\n        self.reply(ret.encode(\"utf-8\", \"replace\"), mime=mime)\n        return True\n\n    def tx_browser(self) -> bool:\n        vpath = \"\"\n        vpnodes = [[\"\", \"/\"]]\n        if self.vpath:\n            for node in self.vpath.split(\"/\"):\n                if not vpath:\n                    vpath = node\n                else:\n                    vpath += \"/\" + node\n\n                vpnodes.append([quotep(vpath) + \"/\", html_escape(node, crlf=True)])\n\n        vn = self.vn\n        rem = self.rem\n        abspath = vn.dcanonical(rem)\n        dbv, vrem = vn.get_dbv(rem)\n\n        try:\n            st = bos.stat(abspath)\n        except:\n            if \"on404\" not in vn.flags:\n                return self.tx_404()\n\n            ret = self.on40x(vn.flags[\"on404\"], vn, rem)\n            if ret == \"true\":\n                return True\n            elif ret == \"false\":\n                return False\n            elif ret == \"retry\":\n                try:\n                    st = bos.stat(abspath)\n                except:\n                    return self.tx_404()\n            else:\n                return self.tx_404()\n\n        if rem.startswith(\".hist/up2k.\") or (\n            rem.endswith(\"/dir.txt\") and rem.startswith(\".hist/th/\")\n        ):\n            raise Pebkac(403)\n\n        e2d = \"e2d\" in vn.flags\n        e2t = \"e2t\" in vn.flags\n\n        self.html_head = vn.flags.get(\"html_head\", \"\")\n        if vn.flags.get(\"norobots\") or \"b\" in self.uparam:\n            self.out_headers[\"X-Robots-Tag\"] = \"noindex, nofollow\"\n        else:\n            self.out_headers.pop(\"X-Robots-Tag\", None)\n\n        is_dir = stat.S_ISDIR(st.st_mode)\n        icur = None\n        if is_dir and (e2t or e2d):\n            idx = self.conn.get_u2idx()\n            if idx and hasattr(idx, \"p_end\"):\n                icur = idx.get_cur(dbv.realpath)\n\n        if self.can_read:\n            th_fmt = self.uparam.get(\"th\")\n            if th_fmt is not None:\n                if is_dir:\n                    vrem = vrem.rstrip(\"/\")\n                    if icur and vrem:\n                        q = \"select fn from cv where rd=? and dn=?\"\n                        crd, cdn = vrem.rsplit(\"/\", 1) if \"/\" in vrem else (\"\", vrem)\n                        # no mojibake support:\n                        try:\n                            cfn = icur.execute(q, (crd, cdn)).fetchone()\n                            if cfn:\n                                fn = cfn[0]\n                                fp = os.path.join(abspath, fn)\n                                if bos.path.exists(fp):\n                                    vrem = \"{}/{}\".format(vrem, fn).strip(\"/\")\n                                    is_dir = False\n                        except:\n                            pass\n                    else:\n                        for fn in self.args.th_covers:\n                            fp = os.path.join(abspath, fn)\n                            if bos.path.exists(fp):\n                                vrem = \"{}/{}\".format(vrem, fn).strip(\"/\")\n                                is_dir = False\n                                break\n\n                    if is_dir:\n                        return self.tx_ico(\"a.folder\")\n\n                thp = None\n                if self.thumbcli:\n                    thp = self.thumbcli.get(dbv, vrem, int(st.st_mtime), th_fmt)\n\n                if thp:\n                    return self.tx_file(thp)\n\n                if th_fmt == \"p\":\n                    raise Pebkac(404)\n\n                return self.tx_ico(rem)\n\n        if not is_dir and (self.can_read or self.can_get):\n            if not self.can_read and \"fk\" in vn.flags:\n                correct = self.gen_fk(\n                    self.args.fk_salt, abspath, st.st_size, 0 if ANYWIN else st.st_ino\n                )[: vn.flags[\"fk\"]]\n                got = self.uparam.get(\"k\")\n                if got != correct:\n                    self.log(\"wrong filekey, want {}, got {}\".format(correct, got))\n                    return self.tx_404()\n\n            if (\n                abspath.endswith(\".md\")\n                and \"nohtml\" not in vn.flags\n                and (\n                    \"v\" in self.uparam\n                    or \"edit\" in self.uparam\n                    or \"edit2\" in self.uparam\n                )\n            ):\n                return self.tx_md(abspath)\n\n            return self.tx_file(abspath)\n\n        elif is_dir and not self.can_read and not self.can_write:\n            return self.tx_404(True)\n\n        srv_info = []\n\n        try:\n            if not self.args.nih:\n                srv_info.append(self.args.name)\n        except:\n            self.log(\"#wow #whoa\")\n\n        if not self.args.nid:\n            free, total = get_df(abspath)\n            if total is not None:\n                h1 = humansize(free or 0)\n                h2 = humansize(total)\n                srv_info.append(\"{} free of {}\".format(h1, h2))\n            elif free is not None:\n                srv_info.append(humansize(free, True) + \" free\")\n\n        srv_infot = \"</span> // <span>\".join(srv_info)\n\n        perms = []\n        if self.can_read:\n            perms.append(\"read\")\n        if self.can_write:\n            perms.append(\"write\")\n        if self.can_move:\n            perms.append(\"move\")\n        if self.can_delete:\n            perms.append(\"delete\")\n        if self.can_get:\n            perms.append(\"get\")\n        if self.can_upget:\n            perms.append(\"upget\")\n        if self.can_admin:\n            perms.append(\"admin\")\n\n        url_suf = self.urlq({}, [\"k\"])\n        is_ls = \"ls\" in self.uparam\n        is_js = self.args.force_js or self.cookies.get(\"js\") == \"y\"\n\n        if not is_ls and (self.ua.startswith(\"curl/\") or self.ua.startswith(\"fetch\")):\n            self.uparam[\"ls\"] = \"v\"\n            is_ls = True\n\n        tpl = \"browser\"\n        if \"b\" in self.uparam:\n            tpl = \"browser2\"\n            is_js = False\n\n        logues = [\"\", \"\"]\n        if not self.args.no_logues:\n            for n, fn in enumerate([\".prologue.html\", \".epilogue.html\"]):\n                fn = os.path.join(abspath, fn)\n                if bos.path.exists(fn):\n                    with open(fsenc(fn), \"rb\") as f:\n                        logues[n] = f.read().decode(\"utf-8\")\n\n        readme = \"\"\n        if not self.args.no_readme and not logues[1]:\n            for fn in [\"README.md\", \"readme.md\"]:\n                fn = os.path.join(abspath, fn)\n                if bos.path.isfile(fn):\n                    with open(fsenc(fn), \"rb\") as f:\n                        readme = f.read().decode(\"utf-8\")\n                        break\n\n        vf = vn.flags\n        unlist = vf.get(\"unlist\", \"\")\n        ls_ret = {\n            \"dirs\": [],\n            \"files\": [],\n            \"taglist\": [],\n            \"srvinf\": srv_infot,\n            \"acct\": self.uname,\n            \"idx\": e2d,\n            \"itag\": e2t,\n            \"lifetime\": vn.flags.get(\"lifetime\") or 0,\n            \"frand\": bool(vn.flags.get(\"rand\")),\n            \"unlist\": unlist,\n            \"perms\": perms,\n            \"logues\": logues,\n            \"readme\": readme,\n        }\n        j2a = {\n            \"vdir\": quotep(self.vpath),\n            \"vpnodes\": vpnodes,\n            \"files\": [],\n            \"ls0\": None,\n            \"acct\": self.uname,\n            \"perms\": json.dumps(perms),\n            \"lifetime\": ls_ret[\"lifetime\"],\n            \"frand\": bool(vn.flags.get(\"rand\")),\n            \"taglist\": [],\n            \"def_hcols\": [],\n            \"have_emp\": self.args.emp,\n            \"have_up2k_idx\": e2d,\n            \"have_tags_idx\": e2t,\n            \"have_acode\": (not self.args.no_acode),\n            \"have_mv\": (not self.args.no_mv),\n            \"have_del\": (not self.args.no_del),\n            \"have_zip\": (not self.args.no_zip),\n            \"have_unpost\": int(self.args.unpost),\n            \"have_b_u\": (self.can_write and self.uparam.get(\"b\") == \"u\"),\n            \"sb_md\": \"\" if \"no_sb_md\" in vf else (vf.get(\"md_sbf\") or \"y\"),\n            \"sb_lg\": \"\" if \"no_sb_lg\" in vf else (vf.get(\"lg_sbf\") or \"y\"),\n            \"url_suf\": url_suf,\n            \"logues\": logues,\n            \"readme\": readme,\n            \"title\": html_escape(self.vpath, crlf=True) or \"\ud83d\udcbe\ud83c\udf89\",\n            \"srv_info\": srv_infot,\n            \"dgrid\": \"grid\" in vf,\n            \"unlist\": unlist,\n            \"dtheme\": self.args.theme,\n            \"themes\": self.args.themes,\n            \"turbolvl\": self.args.turbo,\n            \"idxh\": int(self.args.ih),\n            \"u2sort\": self.args.u2sort,\n        }\n\n        if self.args.js_browser:\n            j2a[\"js\"] = self.args.js_browser\n\n        if self.args.css_browser:\n            j2a[\"css\"] = self.args.css_browser\n\n        if not self.conn.hsrv.prism:\n            j2a[\"no_prism\"] = True\n\n        if not self.can_read:\n            if is_ls:\n                return self.tx_ls(ls_ret)\n\n            if not stat.S_ISDIR(st.st_mode):\n                return self.tx_404(True)\n\n            if \"zip\" in self.uparam or \"tar\" in self.uparam:\n                raise Pebkac(403)\n\n            html = self.j2s(tpl, **j2a)\n            self.reply(html.encode(\"utf-8\", \"replace\"))\n            return True\n\n        for k in [\"zip\", \"tar\"]:\n            v = self.uparam.get(k)\n            if v is not None:\n                return self.tx_zip(k, v, self.vpath, vn, rem, [], self.args.ed)\n\n        fsroot, vfs_ls, vfs_virt = vn.ls(\n            rem,\n            self.uname,\n            not self.args.no_scandir,\n            [[True, False], [False, True]],\n            lstat=\"lt\" in self.uparam,\n        )\n        stats = {k: v for k, v in vfs_ls}\n        ls_names = [x[0] for x in vfs_ls]\n        ls_names.extend(list(vfs_virt.keys()))\n\n        # check for old versions of files,\n        # [num-backups, most-recent, hist-path]\n        hist: dict[str, tuple[int, float, str]] = {}\n        histdir = os.path.join(fsroot, \".hist\")\n        ptn = re.compile(r\"(.*)\\.([0-9]+\\.[0-9]{3})(\\.[^\\.]+)$\")\n        try:\n            for hfn in bos.listdir(histdir):\n                m = ptn.match(hfn)\n                if not m:\n                    continue\n\n                fn = m.group(1) + m.group(3)\n                n, ts, _ = hist.get(fn, (0, 0, \"\"))\n                hist[fn] = (n + 1, max(ts, float(m.group(2))), hfn)\n        except:\n            pass\n\n        # show dotfiles if permitted and requested\n        if not self.args.ed or \"dots\" not in self.uparam:\n            ls_names = exclude_dotfiles(ls_names)\n\n        add_fk = vn.flags.get(\"fk\")\n\n        dirs = []\n        files = []\n        for fn in ls_names:\n            base = \"\"\n            href = fn\n            if not is_ls and not is_js and not self.trailing_slash and vpath:\n                base = \"/\" + vpath + \"/\"\n                href = base + fn\n\n            if fn in vfs_virt:\n                fspath = vfs_virt[fn].realpath\n            else:\n                fspath = fsroot + \"/\" + fn\n\n            try:\n                linf = stats.get(fn) or bos.lstat(fspath)\n                inf = bos.stat(fspath) if stat.S_ISLNK(linf.st_mode) else linf\n            except:\n                self.log(\"broken symlink: {}\".format(repr(fspath)))\n                continue\n\n            is_dir = stat.S_ISDIR(inf.st_mode)\n            if is_dir:\n                href += \"/\"\n                if self.args.no_zip:\n                    margin = \"DIR\"\n                else:\n                    margin = '<a href=\"%s?zip\" rel=\"nofollow\">zip</a>' % (quotep(href),)\n            elif fn in hist:\n                margin = '<a href=\"%s.hist/%s\">#%s</a>' % (\n                    base,\n                    html_escape(hist[fn][2], quot=True, crlf=True),\n                    hist[fn][0],\n                )\n            else:\n                margin = \"-\"\n\n            sz = inf.st_size\n            zd = datetime.utcfromtimestamp(linf.st_mtime)\n            dt = \"%04d-%02d-%02d %02d:%02d:%02d\" % (\n                zd.year,\n                zd.month,\n                zd.day,\n                zd.hour,\n                zd.minute,\n                zd.second,\n            )\n\n            try:\n                ext = \"---\" if is_dir else fn.rsplit(\".\", 1)[1]\n                if len(ext) > 16:\n                    ext = ext[:16]\n            except:\n                ext = \"%\"\n\n            if add_fk:\n                href = \"%s?k=%s\" % (\n                    quotep(href),\n                    self.gen_fk(\n                        self.args.fk_salt, fspath, sz, 0 if ANYWIN else inf.st_ino\n                    )[:add_fk],\n                )\n            else:\n                href = quotep(href)\n\n            item = {\n                \"lead\": margin,\n                \"href\": href,\n                \"name\": fn,\n                \"sz\": sz,\n                \"ext\": ext,\n                \"dt\": dt,\n                \"ts\": int(linf.st_mtime),\n            }\n            if is_dir:\n                dirs.append(item)\n            else:\n                files.append(item)\n                item[\"rd\"] = rem\n\n        if (\n            self.cookies.get(\"idxh\") == \"y\"\n            and \"ls\" not in self.uparam\n            and \"v\" not in self.uparam\n        ):\n            idx_html = set([\"index.htm\", \"index.html\"])\n            for item in files:\n                if item[\"name\"] in idx_html:\n                    # do full resolve in case of shadowed file\n                    vp = vjoin(self.vpath.split(\"?\")[0], item[\"name\"])\n                    vn, rem = self.asrv.vfs.get(vp, self.uname, True, False)\n                    ap = vn.canonical(rem)\n                    return self.tx_file(ap)  # is no-cache\n\n        tagset: set[str] = set()\n        for fe in files:\n            fn = fe[\"name\"]\n            rd = fe[\"rd\"]\n            del fe[\"rd\"]\n            if not icur:\n                continue\n\n            if vn != dbv:\n                _, rd = vn.get_dbv(rd)\n\n            erd_efn = (rd, fn)\n            q = \"select mt.k, mt.v from up inner join mt on mt.w = substr(up.w,1,16) where up.rd = ? and up.fn = ? and +mt.k != 'x'\"\n            try:\n                r = icur.execute(q, erd_efn)\n            except Exception as ex:\n                if \"database is locked\" in str(ex):\n                    break\n\n                try:\n                    erd_efn = s3enc(idx.mem_cur, rd, fn)\n                    r = icur.execute(q, erd_efn)\n                except:\n                    t = \"tag read error, {}/{}\\n{}\"\n                    self.log(t.format(rd, fn, min_ex()))\n                    break\n\n            fe[\"tags\"] = {k: v for k, v in r}\n\n            if self.can_admin:\n                q = \"select ip, at from up where rd=? and fn=?\"\n                try:\n                    zs1, zs2 = icur.execute(q, erd_efn).fetchone()\n                    fe[\"tags\"][\"up_ip\"] = zs1\n                    fe[\"tags\"][\".up_at\"] = zs2\n                except:\n                    pass\n\n            _ = [tagset.add(k) for k in fe[\"tags\"]]\n\n        if icur:\n            mte = vn.flags.get(\"mte\") or \"up_ip,.up_at\"\n            taglist = [k for k in mte.split(\",\") if k in tagset]\n            for fe in dirs:\n                fe[\"tags\"] = {}\n        else:\n            taglist = list(tagset)\n\n        if is_ls:\n            ls_ret[\"dirs\"] = dirs\n            ls_ret[\"files\"] = files\n            ls_ret[\"taglist\"] = taglist\n            return self.tx_ls(ls_ret)\n\n        doc = self.uparam.get(\"doc\") if self.can_read else None\n        if doc:\n            doc = unquotep(doc.replace(\"+\", \" \").split(\"?\")[0])\n            j2a[\"docname\"] = doc\n            doctxt = None\n            if next((x for x in files if x[\"name\"] == doc), None):\n                docpath = os.path.join(abspath, doc)\n                sz = bos.path.getsize(docpath)\n                if sz < 1024 * self.args.txt_max:\n                    with open(fsenc(docpath), \"rb\") as f:\n                        doctxt = f.read().decode(\"utf-8\", \"replace\")\n            else:\n                self.log(\"doc 404: [{}]\".format(doc), c=6)\n                doctxt = \"( textfile not found )\"\n\n            if doctxt is not None:\n                j2a[\"doc\"] = doctxt\n\n        for d in dirs:\n            d[\"name\"] += \"/\"\n\n        dirs.sort(key=itemgetter(\"name\"))\n\n        if is_js:\n            j2a[\"ls0\"] = {\n                \"dirs\": dirs,\n                \"files\": files,\n                \"taglist\": taglist,\n                \"unlist\": unlist,\n            }\n            j2a[\"files\"] = []\n        else:\n            j2a[\"files\"] = dirs + files\n\n        j2a[\"taglist\"] = taglist\n        j2a[\"txt_ext\"] = self.args.textfiles.replace(\",\", \" \")\n\n        if \"mth\" in vn.flags:\n            j2a[\"def_hcols\"] = vn.flags[\"mth\"].split(\",\")\n\n        html = self.j2s(tpl, **j2a)\n        self.reply(html.encode(\"utf-8\", \"replace\"))\n        return True\n", "# coding: utf-8\nfrom __future__ import print_function, unicode_literals\n\nimport base64\nimport math\nimport os\nimport re\nimport socket\nimport sys\nimport threading\nimport time\n\nimport queue\n\nfrom .__init__ import ANYWIN, CORES, EXE, MACOS, TYPE_CHECKING, EnvParams\n\ntry:\n    MNFE = ModuleNotFoundError\nexcept:\n    MNFE = ImportError\n\ntry:\n    import jinja2\nexcept MNFE:\n    if EXE:\n        raise\n\n    print(\n        \"\"\"\\033[1;31m\n  you do not have jinja2 installed,\\033[33m\n  choose one of these:\\033[0m\n   * apt install python-jinja2\n   * {} -m pip install --user jinja2\n   * (try another python version, if you have one)\n   * (try copyparty.sfx instead)\n\"\"\".format(\n            sys.executable\n        )\n    )\n    sys.exit(1)\nexcept SyntaxError:\n    if EXE:\n        raise\n\n    print(\n        \"\"\"\\033[1;31m\n  your jinja2 version is incompatible with your python version;\\033[33m\n  please try to replace it with an older version:\\033[0m\n   * {} -m pip install --user jinja2==2.11.3\n   * (try another python version, if you have one)\n   * (try copyparty.sfx instead)\n\"\"\".format(\n            sys.executable\n        )\n    )\n    sys.exit(1)\n\nfrom .bos import bos\nfrom .httpconn import HttpConn\nfrom .u2idx import U2idx\nfrom .util import (\n    E_SCK,\n    FHC,\n    Daemon,\n    Garda,\n    Magician,\n    Netdev,\n    NetMap,\n    ipnorm,\n    min_ex,\n    shut_socket,\n    spack,\n    start_log_thrs,\n    start_stackmon,\n)\n\nif TYPE_CHECKING:\n    from .broker_util import BrokerCli\n    from .ssdp import SSDPr\n\nif True:  # pylint: disable=using-constant-test\n    from typing import Any, Optional\n\n\nclass HttpSrv(object):\n    \"\"\"\n    handles incoming connections using HttpConn to process http,\n    relying on MpSrv for performance (HttpSrv is just plain threads)\n    \"\"\"\n\n    def __init__(self, broker: \"BrokerCli\", nid: Optional[int]) -> None:\n        self.broker = broker\n        self.nid = nid\n        self.args = broker.args\n        self.E: EnvParams = self.args.E\n        self.log = broker.log\n        self.asrv = broker.asrv\n\n        # redefine in case of multiprocessing\n        socket.setdefaulttimeout(120)\n\n        nsuf = \"-n{}-i{:x}\".format(nid, os.getpid()) if nid else \"\"\n        self.magician = Magician()\n        self.nm = NetMap([], {})\n        self.ssdp: Optional[\"SSDPr\"] = None\n        self.gpwd = Garda(self.args.ban_pw)\n        self.g404 = Garda(self.args.ban_404)\n        self.bans: dict[str, int] = {}\n        self.aclose: dict[str, int] = {}\n\n        self.bound: set[tuple[str, int]] = set()\n        self.name = \"hsrv\" + nsuf\n        self.mutex = threading.Lock()\n        self.stopping = False\n\n        self.tp_nthr = 0  # actual\n        self.tp_ncli = 0  # fading\n        self.tp_time = 0.0  # latest worker collect\n        self.tp_q: Optional[queue.LifoQueue[Any]] = (\n            None if self.args.no_htp else queue.LifoQueue()\n        )\n        self.t_periodic: Optional[threading.Thread] = None\n\n        self.u2fh = FHC()\n        self.srvs: list[socket.socket] = []\n        self.ncli = 0  # exact\n        self.clients: set[HttpConn] = set()  # laggy\n        self.nclimax = 0\n        self.cb_ts = 0.0\n        self.cb_v = \"\"\n\n        self.u2idx_free: dict[str, U2idx] = {}\n        self.u2idx_n = 0\n\n        env = jinja2.Environment()\n        env.loader = jinja2.FileSystemLoader(os.path.join(self.E.mod, \"web\"))\n        jn = [\"splash\", \"svcs\", \"browser\", \"browser2\", \"msg\", \"md\", \"mde\", \"cf\"]\n        self.j2 = {x: env.get_template(x + \".html\") for x in jn}\n        zs = os.path.join(self.E.mod, \"web\", \"deps\", \"prism.js.gz\")\n        self.prism = os.path.exists(zs)\n\n        self.ptn_cc = re.compile(r\"[\\x00-\\x1f]\")\n\n        self.mallow = \"GET HEAD POST PUT DELETE OPTIONS\".split()\n        if not self.args.no_dav:\n            zs = \"PROPFIND PROPPATCH LOCK UNLOCK MKCOL COPY MOVE\"\n            self.mallow += zs.split()\n\n        if self.args.zs:\n            from .ssdp import SSDPr\n\n            self.ssdp = SSDPr(broker)\n\n        if self.tp_q:\n            self.start_threads(4)\n\n        if nid:\n            if self.args.stackmon:\n                start_stackmon(self.args.stackmon, nid)\n\n            if self.args.log_thrs:\n                start_log_thrs(self.log, self.args.log_thrs, nid)\n\n        self.th_cfg: dict[str, Any] = {}\n        Daemon(self.post_init, \"hsrv-init2\")\n\n    def post_init(self) -> None:\n        try:\n            x = self.broker.ask(\"thumbsrv.getcfg\")\n            self.th_cfg = x.get()\n        except:\n            pass\n\n    def set_netdevs(self, netdevs: dict[str, Netdev]) -> None:\n        ips = set()\n        for ip, _ in self.bound:\n            ips.add(ip)\n\n        self.nm = NetMap(list(ips), netdevs)\n\n    def start_threads(self, n: int) -> None:\n        self.tp_nthr += n\n        if self.args.log_htp:\n            self.log(self.name, \"workers += {} = {}\".format(n, self.tp_nthr), 6)\n\n        for _ in range(n):\n            Daemon(self.thr_poolw, self.name + \"-poolw\")\n\n    def stop_threads(self, n: int) -> None:\n        self.tp_nthr -= n\n        if self.args.log_htp:\n            self.log(self.name, \"workers -= {} = {}\".format(n, self.tp_nthr), 6)\n\n        assert self.tp_q\n        for _ in range(n):\n            self.tp_q.put(None)\n\n    def periodic(self) -> None:\n        while True:\n            time.sleep(2 if self.tp_ncli or self.ncli else 10)\n            with self.mutex:\n                self.u2fh.clean()\n                if self.tp_q:\n                    self.tp_ncli = max(self.ncli, self.tp_ncli - 2)\n                    if self.tp_nthr > self.tp_ncli + 8:\n                        self.stop_threads(4)\n\n                if not self.ncli and not self.u2fh.cache and self.tp_nthr <= 8:\n                    self.t_periodic = None\n                    return\n\n    def listen(self, sck: socket.socket, nlisteners: int) -> None:\n        if self.args.j != 1:\n            # lost in the pickle; redefine\n            if not ANYWIN or self.args.reuseaddr:\n                sck.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n\n            sck.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n            sck.settimeout(None)  # < does not inherit, ^ opts above do\n\n        ip, port = sck.getsockname()[:2]\n        self.srvs.append(sck)\n        self.bound.add((ip, port))\n        self.nclimax = math.ceil(self.args.nc * 1.0 / nlisteners)\n        Daemon(\n            self.thr_listen,\n            \"httpsrv-n{}-listen-{}-{}\".format(self.nid or \"0\", ip, port),\n            (sck,),\n        )\n\n    def thr_listen(self, srv_sck: socket.socket) -> None:\n        \"\"\"listens on a shared tcp server\"\"\"\n        ip, port = srv_sck.getsockname()[:2]\n        fno = srv_sck.fileno()\n        hip = \"[{}]\".format(ip) if \":\" in ip else ip\n        msg = \"subscribed @ {}:{}  f{} p{}\".format(hip, port, fno, os.getpid())\n        self.log(self.name, msg)\n\n        def fun() -> None:\n            self.broker.say(\"cb_httpsrv_up\")\n\n        threading.Thread(target=fun, name=\"sig-hsrv-up1\").start()\n\n        while not self.stopping:\n            if self.args.log_conn:\n                self.log(self.name, \"|%sC-ncli\" % (\"-\" * 1,), c=\"90\")\n\n            spins = 0\n            while self.ncli >= self.nclimax:\n                if not spins:\n                    self.log(self.name, \"at connection limit; waiting\", 3)\n\n                spins += 1\n                time.sleep(0.1)\n                if spins != 50 or not self.args.aclose:\n                    continue\n\n                ipfreq: dict[str, int] = {}\n                with self.mutex:\n                    for c in self.clients:\n                        ip = ipnorm(c.ip)\n                        try:\n                            ipfreq[ip] += 1\n                        except:\n                            ipfreq[ip] = 1\n\n                ip, n = sorted(ipfreq.items(), key=lambda x: x[1], reverse=True)[0]\n                if n < self.nclimax / 2:\n                    continue\n\n                self.aclose[ip] = int(time.time() + self.args.aclose * 60)\n                nclose = 0\n                nloris = 0\n                nconn = 0\n                with self.mutex:\n                    for c in self.clients:\n                        cip = ipnorm(c.ip)\n                        if ip != cip:\n                            continue\n\n                        nconn += 1\n                        try:\n                            if (\n                                c.nreq >= 1\n                                or not c.cli\n                                or c.cli.in_hdr_recv\n                                or c.cli.keepalive\n                            ):\n                                Daemon(c.shutdown)\n                                nclose += 1\n                                if c.nreq <= 0 and (not c.cli or c.cli.in_hdr_recv):\n                                    nloris += 1\n                        except:\n                            pass\n\n                t = \"{} downgraded to connection:close for {} min; dropped {}/{} connections\"\n                self.log(self.name, t.format(ip, self.args.aclose, nclose, nconn), 1)\n\n                if nloris < nconn / 2:\n                    continue\n\n                t = \"slowloris (idle-conn): {} banned for {} min\"\n                self.log(self.name, t.format(ip, self.args.loris, nclose), 1)\n                self.bans[ip] = int(time.time() + self.args.loris * 60)\n\n            if self.args.log_conn:\n                self.log(self.name, \"|%sC-acc1\" % (\"-\" * 2,), c=\"90\")\n\n            try:\n                sck, saddr = srv_sck.accept()\n                cip, cport = saddr[:2]\n                if cip.startswith(\"::ffff:\"):\n                    cip = cip[7:]\n\n                addr = (cip, cport)\n            except (OSError, socket.error) as ex:\n                if self.stopping:\n                    break\n\n                self.log(self.name, \"accept({}): {}\".format(fno, ex), c=6)\n                time.sleep(0.02)\n                continue\n\n            if self.args.log_conn:\n                t = \"|{}C-acc2 \\033[0;36m{} \\033[3{}m{}\".format(\n                    \"-\" * 3, ip, port % 8, port\n                )\n                self.log(\"%s %s\" % addr, t, c=\"90\")\n\n            self.accept(sck, addr)\n\n    def accept(self, sck: socket.socket, addr: tuple[str, int]) -> None:\n        \"\"\"takes an incoming tcp connection and creates a thread to handle it\"\"\"\n        now = time.time()\n\n        if now - (self.tp_time or now) > 300:\n            t = \"httpserver threadpool died: tpt {:.2f}, now {:.2f}, nthr {}, ncli {}\"\n            self.log(self.name, t.format(self.tp_time, now, self.tp_nthr, self.ncli), 1)\n            self.tp_time = 0\n            self.tp_q = None\n\n        with self.mutex:\n            self.ncli += 1\n            if not self.t_periodic:\n                name = \"hsrv-pt\"\n                if self.nid:\n                    name += \"-{}\".format(self.nid)\n\n                self.t_periodic = Daemon(self.periodic, name)\n\n            if self.tp_q:\n                self.tp_time = self.tp_time or now\n                self.tp_ncli = max(self.tp_ncli, self.ncli)\n                if self.tp_nthr < self.ncli + 4:\n                    self.start_threads(8)\n\n                self.tp_q.put((sck, addr))\n                return\n\n        if not self.args.no_htp:\n            t = \"looks like the httpserver threadpool died; please make an issue on github and tell me the story of how you pulled that off, thanks and dog bless\\n\"\n            self.log(self.name, t, 1)\n\n        Daemon(\n            self.thr_client,\n            \"httpconn-{}-{}\".format(addr[0].split(\".\", 2)[-1][-6:], addr[1]),\n            (sck, addr),\n        )\n\n    def thr_poolw(self) -> None:\n        assert self.tp_q\n        while True:\n            task = self.tp_q.get()\n            if not task:\n                break\n\n            with self.mutex:\n                self.tp_time = 0\n\n            try:\n                sck, addr = task\n                me = threading.current_thread()\n                me.name = \"httpconn-{}-{}\".format(\n                    addr[0].split(\".\", 2)[-1][-6:], addr[1]\n                )\n                self.thr_client(sck, addr)\n                me.name = self.name + \"-poolw\"\n            except Exception as ex:\n                if str(ex).startswith(\"client d/c \"):\n                    self.log(self.name, \"thr_client: \" + str(ex), 6)\n                else:\n                    self.log(self.name, \"thr_client: \" + min_ex(), 3)\n\n    def shutdown(self) -> None:\n        self.stopping = True\n        for srv in self.srvs:\n            try:\n                srv.close()\n            except:\n                pass\n\n        thrs = []\n        clients = list(self.clients)\n        for cli in clients:\n            t = threading.Thread(target=cli.shutdown)\n            thrs.append(t)\n            t.start()\n\n        if self.tp_q:\n            self.stop_threads(self.tp_nthr)\n            for _ in range(10):\n                time.sleep(0.05)\n                if self.tp_q.empty():\n                    break\n\n        for t in thrs:\n            t.join()\n\n        self.log(self.name, \"ok bye\")\n\n    def thr_client(self, sck: socket.socket, addr: tuple[str, int]) -> None:\n        \"\"\"thread managing one tcp client\"\"\"\n        cli = HttpConn(sck, addr, self)\n        with self.mutex:\n            self.clients.add(cli)\n\n        # print(\"{}\\n\".format(len(self.clients)), end=\"\")\n        fno = sck.fileno()\n        try:\n            if self.args.log_conn:\n                self.log(\"%s %s\" % addr, \"|%sC-crun\" % (\"-\" * 4,), c=\"90\")\n\n            cli.run()\n\n        except (OSError, socket.error) as ex:\n            if ex.errno not in E_SCK:\n                self.log(\n                    \"%s %s\" % addr,\n                    \"run({}): {}\".format(fno, ex),\n                    c=6,\n                )\n\n        finally:\n            sck = cli.s\n            if self.args.log_conn:\n                self.log(\"%s %s\" % addr, \"|%sC-cdone\" % (\"-\" * 5,), c=\"90\")\n\n            try:\n                fno = sck.fileno()\n                shut_socket(cli.log, sck)\n            except (OSError, socket.error) as ex:\n                if not MACOS:\n                    self.log(\n                        \"%s %s\" % addr,\n                        \"shut({}): {}\".format(fno, ex),\n                        c=\"90\",\n                    )\n                if ex.errno not in E_SCK:\n                    raise\n            finally:\n                with self.mutex:\n                    self.clients.remove(cli)\n                    self.ncli -= 1\n\n                if cli.u2idx:\n                    self.put_u2idx(str(addr), cli.u2idx)\n\n    def cachebuster(self) -> str:\n        if time.time() - self.cb_ts < 1:\n            return self.cb_v\n\n        with self.mutex:\n            if time.time() - self.cb_ts < 1:\n                return self.cb_v\n\n            v = self.E.t0\n            try:\n                with os.scandir(os.path.join(self.E.mod, \"web\")) as dh:\n                    for fh in dh:\n                        inf = fh.stat()\n                        v = max(v, inf.st_mtime)\n            except:\n                pass\n\n            v = base64.urlsafe_b64encode(spack(b\">xxL\", int(v)))\n            self.cb_v = v.decode(\"ascii\")[-4:]\n            self.cb_ts = time.time()\n            return self.cb_v\n\n    def get_u2idx(self, ident: str) -> Optional[U2idx]:\n        utab = self.u2idx_free\n        for _ in range(100):  # 5/0.05 = 5sec\n            with self.mutex:\n                if utab:\n                    if ident in utab:\n                        return utab.pop(ident)\n\n                    return utab.pop(list(utab.keys())[0])\n\n                if self.u2idx_n < CORES:\n                    self.u2idx_n += 1\n                    return U2idx(self)\n\n            time.sleep(0.05)\n            # not using conditional waits, on a hunch that\n            # average performance will be faster like this\n            # since most servers won't be fully saturated\n\n        return None\n\n    def put_u2idx(self, ident: str, u2idx: U2idx) -> None:\n        with self.mutex:\n            while ident in self.u2idx_free:\n                ident += \"a\"\n\n            self.u2idx_free[ident] = u2idx\n", "# coding: utf-8\nfrom __future__ import print_function, unicode_literals\n\nimport base64\nimport contextlib\nimport errno\nimport hashlib\nimport hmac\nimport json\nimport logging\nimport math\nimport mimetypes\nimport os\nimport platform\nimport re\nimport select\nimport shutil\nimport signal\nimport socket\nimport stat\nimport struct\nimport subprocess as sp  # nosec\nimport sys\nimport threading\nimport time\nimport traceback\nfrom collections import Counter\nfrom datetime import datetime\nfrom email.utils import formatdate\n\nfrom ipaddress import IPv4Address, IPv4Network, IPv6Address, IPv6Network\nfrom queue import Queue\n\nfrom .__init__ import ANYWIN, EXE, MACOS, PY2, TYPE_CHECKING, VT100, WINDOWS\nfrom .__version__ import S_BUILD_DT, S_VERSION\nfrom .stolen import surrogateescape\n\n\ndef _ens(want: str) -> tuple[int, ...]:\n    ret: list[int] = []\n    for v in want.split():\n        try:\n            ret.append(getattr(errno, v))\n        except:\n            pass\n\n    return tuple(ret)\n\n\n# WSAECONNRESET - foribly closed by remote\n# WSAENOTSOCK - no longer a socket\n# EUNATCH - can't assign requested address (wifi down)\nE_SCK = _ens(\"ENOTCONN EUNATCH EBADF WSAENOTSOCK WSAECONNRESET\")\nE_ADDR_NOT_AVAIL = _ens(\"EADDRNOTAVAIL WSAEADDRNOTAVAIL\")\nE_ADDR_IN_USE = _ens(\"EADDRINUSE WSAEADDRINUSE\")\nE_ACCESS = _ens(\"EACCES WSAEACCES\")\nE_UNREACH = _ens(\"EHOSTUNREACH WSAEHOSTUNREACH ENETUNREACH WSAENETUNREACH\")\n\n\ntry:\n    import ctypes\n    import fcntl\n    import termios\nexcept:\n    pass\n\ntry:\n    HAVE_SQLITE3 = True\n    import sqlite3  # pylint: disable=unused-import  # typechk\nexcept:\n    HAVE_SQLITE3 = False\n\ntry:\n    HAVE_PSUTIL = True\n    import psutil\nexcept:\n    HAVE_PSUTIL = False\n\nif True:  # pylint: disable=using-constant-test\n    import types\n    from collections.abc import Callable, Iterable\n\n    import typing\n    from typing import Any, Generator, Optional, Pattern, Protocol, Union\n\n    class RootLogger(Protocol):\n        def __call__(self, src: str, msg: str, c: Union[int, str] = 0) -> None:\n            return None\n\n    class NamedLogger(Protocol):\n        def __call__(self, msg: str, c: Union[int, str] = 0) -> None:\n            return None\n\n\nif TYPE_CHECKING:\n    import magic\n\n    from .authsrv import VFS\n\nFAKE_MP = False\n\ntry:\n    import multiprocessing as mp\n\n    # import multiprocessing.dummy as mp\nexcept ImportError:\n    # support jython\n    mp = None  # type: ignore\n\nif not PY2:\n    from io import BytesIO\n    from urllib.parse import quote_from_bytes as quote\n    from urllib.parse import unquote_to_bytes as unquote\nelse:\n    from StringIO import StringIO as BytesIO\n    from urllib import quote  # pylint: disable=no-name-in-module\n    from urllib import unquote  # pylint: disable=no-name-in-module\n\n\ntry:\n    struct.unpack(b\">i\", b\"idgi\")\n    spack = struct.pack\n    sunpack = struct.unpack\nexcept:\n\n    def spack(fmt: bytes, *a: Any) -> bytes:\n        return struct.pack(fmt.decode(\"ascii\"), *a)\n\n    def sunpack(fmt: bytes, a: bytes) -> tuple[Any, ...]:\n        return struct.unpack(fmt.decode(\"ascii\"), a)\n\n\nansi_re = re.compile(\"\\033\\\\[[^mK]*[mK]\")\n\n\nsurrogateescape.register_surrogateescape()\nif WINDOWS and PY2:\n    FS_ENCODING = \"utf-8\"\nelse:\n    FS_ENCODING = sys.getfilesystemencoding()\n\n\nSYMTIME = sys.version_info > (3, 6) and os.utime in os.supports_follow_symlinks\n\nMETA_NOBOTS = '<meta name=\"robots\" content=\"noindex, nofollow\">'\n\nFFMPEG_URL = \"https://www.gyan.dev/ffmpeg/builds/ffmpeg-git-full.7z\"\n\nHTTPCODE = {\n    200: \"OK\",\n    201: \"Created\",\n    204: \"No Content\",\n    206: \"Partial Content\",\n    207: \"Multi-Status\",\n    301: \"Moved Permanently\",\n    302: \"Found\",\n    304: \"Not Modified\",\n    400: \"Bad Request\",\n    401: \"Unauthorized\",\n    403: \"Forbidden\",\n    404: \"Not Found\",\n    405: \"Method Not Allowed\",\n    409: \"Conflict\",\n    411: \"Length Required\",\n    412: \"Precondition Failed\",\n    413: \"Payload Too Large\",\n    416: \"Requested Range Not Satisfiable\",\n    422: \"Unprocessable Entity\",\n    423: \"Locked\",\n    429: \"Too Many Requests\",\n    500: \"Internal Server Error\",\n    501: \"Not Implemented\",\n    503: \"Service Unavailable\",\n    999: \"MissingNo\",\n}\n\n\nIMPLICATIONS = [\n    [\"e2dsa\", \"e2ds\"],\n    [\"e2ds\", \"e2d\"],\n    [\"e2tsr\", \"e2ts\"],\n    [\"e2ts\", \"e2t\"],\n    [\"e2t\", \"e2d\"],\n    [\"e2vu\", \"e2v\"],\n    [\"e2vp\", \"e2v\"],\n    [\"e2v\", \"e2d\"],\n    [\"smbw\", \"smb\"],\n    [\"smb1\", \"smb\"],\n    [\"smbvvv\", \"smbvv\"],\n    [\"smbvv\", \"smbv\"],\n    [\"smbv\", \"smb\"],\n    [\"zv\", \"zmv\"],\n    [\"zv\", \"zsv\"],\n    [\"z\", \"zm\"],\n    [\"z\", \"zs\"],\n    [\"zmvv\", \"zmv\"],\n    [\"zm4\", \"zm\"],\n    [\"zm6\", \"zm\"],\n    [\"zmv\", \"zm\"],\n    [\"zms\", \"zm\"],\n    [\"zsv\", \"zs\"],\n]\nif ANYWIN:\n    IMPLICATIONS.extend([[\"z\", \"zm4\"]])\n\n\nUNPLICATIONS = [[\"no_dav\", \"daw\"]]\n\n\nMIMES = {\n    \"opus\": \"audio/ogg; codecs=opus\",\n}\n\n\ndef _add_mimes() -> None:\n    # `mimetypes` is woefully unpopulated on windows\n    # but will be used as fallback on linux\n\n    for ln in \"\"\"text css html csv\napplication json wasm xml pdf rtf zip jar fits wasm\nimage webp jpeg png gif bmp jxl jp2 jxs jxr tiff bpg heic heif avif\naudio aac ogg wav flac ape amr\nvideo webm mp4 mpeg\nfont woff woff2 otf ttf\n\"\"\".splitlines():\n        k, vs = ln.split(\" \", 1)\n        for v in vs.strip().split():\n            MIMES[v] = \"{}/{}\".format(k, v)\n\n    for ln in \"\"\"text md=plain txt=plain js=javascript\napplication 7z=x-7z-compressed tar=x-tar bz2=x-bzip2 gz=gzip rar=x-rar-compressed zst=zstd xz=x-xz lz=lzip cpio=x-cpio\napplication msi=x-ms-installer cab=vnd.ms-cab-compressed rpm=x-rpm crx=x-chrome-extension\napplication epub=epub+zip mobi=x-mobipocket-ebook lit=x-ms-reader rss=rss+xml atom=atom+xml torrent=x-bittorrent\napplication p7s=pkcs7-signature dcm=dicom shx=vnd.shx shp=vnd.shp dbf=x-dbf gml=gml+xml gpx=gpx+xml amf=x-amf\napplication swf=x-shockwave-flash m3u=vnd.apple.mpegurl db3=vnd.sqlite3 sqlite=vnd.sqlite3\ntext ass=plain ssa=plain\nimage jpg=jpeg xpm=x-xpixmap psd=vnd.adobe.photoshop jpf=jpx tif=tiff ico=x-icon djvu=vnd.djvu\nimage heic=heic-sequence heif=heif-sequence hdr=vnd.radiance svg=svg+xml\naudio caf=x-caf mp3=mpeg m4a=mp4 mid=midi mpc=musepack aif=aiff au=basic qcp=qcelp\nvideo mkv=x-matroska mov=quicktime avi=x-msvideo m4v=x-m4v ts=mp2t\nvideo asf=x-ms-asf flv=x-flv 3gp=3gpp 3g2=3gpp2 rmvb=vnd.rn-realmedia-vbr\nfont ttc=collection\n\"\"\".splitlines():\n        k, ems = ln.split(\" \", 1)\n        for em in ems.strip().split():\n            ext, mime = em.split(\"=\")\n            MIMES[ext] = \"{}/{}\".format(k, mime)\n\n\n_add_mimes()\n\n\nEXTS: dict[str, str] = {v: k for k, v in MIMES.items()}\n\nEXTS[\"vnd.mozilla.apng\"] = \"png\"\n\nMAGIC_MAP = {\"jpeg\": \"jpg\"}\n\n\nREKOBO_KEY = {\n    v: ln.split(\" \", 1)[0]\n    for ln in \"\"\"\n1B 6d B\n2B 7d Gb F#\n3B 8d Db C#\n4B 9d Ab G#\n5B 10d Eb D#\n6B 11d Bb A#\n7B 12d F\n8B 1d C\n9B 2d G\n10B 3d D\n11B 4d A\n12B 5d E\n1A 6m Abm G#m\n2A 7m Ebm D#m\n3A 8m Bbm A#m\n4A 9m Fm\n5A 10m Cm\n6A 11m Gm\n7A 12m Dm\n8A 1m Am\n9A 2m Em\n10A 3m Bm\n11A 4m Gbm F#m\n12A 5m Dbm C#m\n\"\"\".strip().split(\n        \"\\n\"\n    )\n    for v in ln.strip().split(\" \")[1:]\n    if v\n}\n\nREKOBO_LKEY = {k.lower(): v for k, v in REKOBO_KEY.items()}\n\n\npybin = sys.executable or \"\"\nif EXE:\n    pybin = \"\"\n    for zsg in \"python3 python\".split():\n        try:\n            zsg = shutil.which(zsg)\n            if zsg:\n                pybin = zsg\n                break\n        except:\n            pass\n\n\ndef py_desc() -> str:\n    interp = platform.python_implementation()\n    py_ver = \".\".join([str(x) for x in sys.version_info])\n    ofs = py_ver.find(\".final.\")\n    if ofs > 0:\n        py_ver = py_ver[:ofs]\n\n    try:\n        bitness = struct.calcsize(b\"P\") * 8\n    except:\n        bitness = struct.calcsize(\"P\") * 8\n\n    host_os = platform.system()\n    compiler = platform.python_compiler().split(\"http\")[0]\n\n    m = re.search(r\"([0-9]+\\.[0-9\\.]+)\", platform.version())\n    os_ver = m.group(1) if m else \"\"\n\n    return \"{:>9} v{} on {}{} {} [{}]\".format(\n        interp, py_ver, host_os, bitness, os_ver, compiler\n    )\n\n\ndef _sqlite_ver() -> str:\n    try:\n        co = sqlite3.connect(\":memory:\")\n        cur = co.cursor()\n        try:\n            vs = cur.execute(\"select * from pragma_compile_options\").fetchall()\n        except:\n            vs = cur.execute(\"pragma compile_options\").fetchall()\n\n        v = next(x[0].split(\"=\")[1] for x in vs if x[0].startswith(\"THREADSAFE=\"))\n        cur.close()\n        co.close()\n    except:\n        v = \"W\"\n\n    return \"{}*{}\".format(sqlite3.sqlite_version, v)\n\n\ntry:\n    SQLITE_VER = _sqlite_ver()\nexcept:\n    SQLITE_VER = \"(None)\"\n\ntry:\n    from jinja2 import __version__ as JINJA_VER\nexcept:\n    JINJA_VER = \"(None)\"\n\ntry:\n    from pyftpdlib.__init__ import __ver__ as PYFTPD_VER\nexcept:\n    PYFTPD_VER = \"(None)\"\n\n\nVERSIONS = \"copyparty v{} ({})\\n{}\\n   sqlite v{} | jinja v{} | pyftpd v{}\".format(\n    S_VERSION, S_BUILD_DT, py_desc(), SQLITE_VER, JINJA_VER, PYFTPD_VER\n)\n\n\n_: Any = (mp, BytesIO, quote, unquote, SQLITE_VER, JINJA_VER, PYFTPD_VER)\n__all__ = [\"mp\", \"BytesIO\", \"quote\", \"unquote\", \"SQLITE_VER\", \"JINJA_VER\", \"PYFTPD_VER\"]\n\n\nclass Daemon(threading.Thread):\n    def __init__(\n        self,\n        target: Any,\n        name: Optional[str] = None,\n        a: Optional[Iterable[Any]] = None,\n        r: bool = True,\n        ka: Optional[dict[Any, Any]] = None,\n    ) -> None:\n        threading.Thread.__init__(\n            self, target=target, name=name, args=a or (), kwargs=ka\n        )\n        self.daemon = True\n        if r:\n            self.start()\n\n\nclass Netdev(object):\n    def __init__(self, ip: str, idx: int, name: str, desc: str):\n        self.ip = ip\n        self.idx = idx\n        self.name = name\n        self.desc = desc\n\n    def __str__(self):\n        return \"{}-{}{}\".format(self.idx, self.name, self.desc)\n\n    def __repr__(self):\n        return \"'{}-{}'\".format(self.idx, self.name)\n\n    def __lt__(self, rhs):\n        return str(self) < str(rhs)\n\n    def __eq__(self, rhs):\n        return str(self) == str(rhs)\n\n\nclass Cooldown(object):\n    def __init__(self, maxage: float) -> None:\n        self.maxage = maxage\n        self.mutex = threading.Lock()\n        self.hist: dict[str, float] = {}\n        self.oldest = 0.0\n\n    def poke(self, key: str) -> bool:\n        with self.mutex:\n            now = time.time()\n\n            ret = False\n            pv: float = self.hist.get(key, 0)\n            if now - pv > self.maxage:\n                self.hist[key] = now\n                ret = True\n\n            if self.oldest - now > self.maxage * 2:\n                self.hist = {\n                    k: v for k, v in self.hist.items() if now - v < self.maxage\n                }\n                self.oldest = sorted(self.hist.values())[0]\n\n            return ret\n\n\nclass HLog(logging.Handler):\n    def __init__(self, log_func: \"RootLogger\") -> None:\n        logging.Handler.__init__(self)\n        self.log_func = log_func\n        self.ptn_ftp = re.compile(r\"^([0-9a-f:\\.]+:[0-9]{1,5})-\\[\")\n        self.ptn_smb_ign = re.compile(r\"^(Callback added|Config file parsed)\")\n\n    def __repr__(self) -> str:\n        level = logging.getLevelName(self.level)\n        return \"<%s cpp(%s)>\" % (self.__class__.__name__, level)\n\n    def flush(self) -> None:\n        pass\n\n    def emit(self, record: logging.LogRecord) -> None:\n        msg = self.format(record)\n        lv = record.levelno\n        if lv < logging.INFO:\n            c = 6\n        elif lv < logging.WARNING:\n            c = 0\n        elif lv < logging.ERROR:\n            c = 3\n        else:\n            c = 1\n\n        if record.name == \"pyftpdlib\":\n            m = self.ptn_ftp.match(msg)\n            if m:\n                ip = m.group(1)\n                msg = msg[len(ip) + 1 :]\n                if ip.startswith(\"::ffff:\"):\n                    record.name = ip[7:]\n                else:\n                    record.name = ip\n        elif record.name.startswith(\"impacket\"):\n            if self.ptn_smb_ign.match(msg):\n                return\n\n        self.log_func(record.name[-21:], msg, c)\n\n\nclass NetMap(object):\n    def __init__(self, ips: list[str], netdevs: dict[str, Netdev]) -> None:\n        if \"::\" in ips:\n            ips = [x for x in ips if x != \"::\"] + list(\n                [x.split(\"/\")[0] for x in netdevs if \":\" in x]\n            )\n            ips.append(\"0.0.0.0\")\n\n        if \"0.0.0.0\" in ips:\n            ips = [x for x in ips if x != \"0.0.0.0\"] + list(\n                [x.split(\"/\")[0] for x in netdevs if \":\" not in x]\n            )\n\n        ips = [x for x in ips if x not in (\"::1\", \"127.0.0.1\")]\n        ips = find_prefix(ips, netdevs)\n\n        self.cache: dict[str, str] = {}\n        self.b2sip: dict[bytes, str] = {}\n        self.b2net: dict[bytes, Union[IPv4Network, IPv6Network]] = {}\n        self.bip: list[bytes] = []\n        for ip in ips:\n            v6 = \":\" in ip\n            fam = socket.AF_INET6 if v6 else socket.AF_INET\n            bip = socket.inet_pton(fam, ip.split(\"/\")[0])\n            self.bip.append(bip)\n            self.b2sip[bip] = ip.split(\"/\")[0]\n            self.b2net[bip] = (IPv6Network if v6 else IPv4Network)(ip, False)\n\n        self.bip.sort(reverse=True)\n\n    def map(self, ip: str) -> str:\n        try:\n            return self.cache[ip]\n        except:\n            pass\n\n        v6 = \":\" in ip\n        ci = IPv6Address(ip) if v6 else IPv4Address(ip)\n        bip = next((x for x in self.bip if ci in self.b2net[x]), None)\n        ret = self.b2sip[bip] if bip else \"\"\n        if len(self.cache) > 9000:\n            self.cache = {}\n        self.cache[ip] = ret\n        return ret\n\n\nclass UnrecvEOF(OSError):\n    pass\n\n\nclass _Unrecv(object):\n    \"\"\"\n    undo any number of socket recv ops\n    \"\"\"\n\n    def __init__(self, s: socket.socket, log: Optional[\"NamedLogger\"]) -> None:\n        self.s = s\n        self.log = log\n        self.buf: bytes = b\"\"\n\n    def recv(self, nbytes: int, spins: int = 1) -> bytes:\n        if self.buf:\n            ret = self.buf[:nbytes]\n            self.buf = self.buf[nbytes:]\n            return ret\n\n        while True:\n            try:\n                ret = self.s.recv(nbytes)\n                break\n            except socket.timeout:\n                spins -= 1\n                if spins <= 0:\n                    ret = b\"\"\n                    break\n                continue\n            except:\n                ret = b\"\"\n                break\n\n        if not ret:\n            raise UnrecvEOF(\"client stopped sending data\")\n\n        return ret\n\n    def recv_ex(self, nbytes: int, raise_on_trunc: bool = True) -> bytes:\n        \"\"\"read an exact number of bytes\"\"\"\n        ret = b\"\"\n        try:\n            while nbytes > len(ret):\n                ret += self.recv(nbytes - len(ret))\n        except OSError:\n            t = \"client only sent {} of {} expected bytes\".format(len(ret), nbytes)\n            if len(ret) <= 16:\n                t += \"; got {!r}\".format(ret)\n\n            if raise_on_trunc:\n                raise UnrecvEOF(5, t)\n            elif self.log:\n                self.log(t, 3)\n\n        return ret\n\n    def unrecv(self, buf: bytes) -> None:\n        self.buf = buf + self.buf\n\n\nclass _LUnrecv(object):\n    \"\"\"\n    with expensive debug logging\n    \"\"\"\n\n    def __init__(self, s: socket.socket, log: Optional[\"NamedLogger\"]) -> None:\n        self.s = s\n        self.log = log\n        self.buf = b\"\"\n\n    def recv(self, nbytes: int, spins: int) -> bytes:\n        if self.buf:\n            ret = self.buf[:nbytes]\n            self.buf = self.buf[nbytes:]\n            t = \"\\033[0;7mur:pop:\\033[0;1;32m {}\\n\\033[0;7mur:rem:\\033[0;1;35m {}\\033[0m\"\n            print(t.format(ret, self.buf))\n            return ret\n\n        ret = self.s.recv(nbytes)\n        t = \"\\033[0;7mur:recv\\033[0;1;33m {}\\033[0m\"\n        print(t.format(ret))\n        if not ret:\n            raise UnrecvEOF(\"client stopped sending data\")\n\n        return ret\n\n    def recv_ex(self, nbytes: int, raise_on_trunc: bool = True) -> bytes:\n        \"\"\"read an exact number of bytes\"\"\"\n        try:\n            ret = self.recv(nbytes, 1)\n            err = False\n        except:\n            ret = b\"\"\n            err = True\n\n        while not err and len(ret) < nbytes:\n            try:\n                ret += self.recv(nbytes - len(ret), 1)\n            except OSError:\n                err = True\n\n        if err:\n            t = \"client only sent {} of {} expected bytes\".format(len(ret), nbytes)\n            if raise_on_trunc:\n                raise UnrecvEOF(t)\n            elif self.log:\n                self.log(t, 3)\n\n        return ret\n\n    def unrecv(self, buf: bytes) -> None:\n        self.buf = buf + self.buf\n        t = \"\\033[0;7mur:push\\033[0;1;31m {}\\n\\033[0;7mur:rem:\\033[0;1;35m {}\\033[0m\"\n        print(t.format(buf, self.buf))\n\n\nUnrecv = _Unrecv\n\n\nclass CachedSet(object):\n    def __init__(self, maxage: float) -> None:\n        self.c: dict[Any, float] = {}\n        self.maxage = maxage\n        self.oldest = 0.0\n\n    def add(self, v: Any) -> None:\n        self.c[v] = time.time()\n\n    def cln(self) -> None:\n        now = time.time()\n        if now - self.oldest < self.maxage:\n            return\n\n        c = self.c = {k: v for k, v in self.c.items() if now - v < self.maxage}\n        try:\n            self.oldest = c[min(c, key=c.get)]\n        except:\n            self.oldest = now\n\n\nclass FHC(object):\n    class CE(object):\n        def __init__(self, fh: typing.BinaryIO) -> None:\n            self.ts: float = 0\n            self.fhs = [fh]\n\n    def __init__(self) -> None:\n        self.cache: dict[str, FHC.CE] = {}\n        self.aps: set[str] = set()\n\n    def close(self, path: str) -> None:\n        try:\n            ce = self.cache[path]\n        except:\n            return\n\n        for fh in ce.fhs:\n            fh.close()\n\n        del self.cache[path]\n        self.aps.remove(path)\n\n    def clean(self) -> None:\n        if not self.cache:\n            return\n\n        keep = {}\n        now = time.time()\n        for path, ce in self.cache.items():\n            if now < ce.ts + 5:\n                keep[path] = ce\n            else:\n                for fh in ce.fhs:\n                    fh.close()\n\n        self.cache = keep\n\n    def pop(self, path: str) -> typing.BinaryIO:\n        return self.cache[path].fhs.pop()\n\n    def put(self, path: str, fh: typing.BinaryIO) -> None:\n        self.aps.add(path)\n        try:\n            ce = self.cache[path]\n            ce.fhs.append(fh)\n        except:\n            ce = self.CE(fh)\n            self.cache[path] = ce\n\n        ce.ts = time.time()\n\n\nclass ProgressPrinter(threading.Thread):\n    \"\"\"\n    periodically print progress info without linefeeds\n    \"\"\"\n\n    def __init__(self) -> None:\n        threading.Thread.__init__(self, name=\"pp\")\n        self.daemon = True\n        self.msg = \"\"\n        self.end = False\n        self.n = -1\n        self.start()\n\n    def run(self) -> None:\n        msg = None\n        fmt = \" {}\\033[K\\r\" if VT100 else \" {} $\\r\"\n        while not self.end:\n            time.sleep(0.1)\n            if msg == self.msg or self.end:\n                continue\n\n            msg = self.msg\n            uprint(fmt.format(msg))\n            if PY2:\n                sys.stdout.flush()\n\n        if VT100:\n            print(\"\\033[K\", end=\"\")\n        elif msg:\n            print(\"------------------------\")\n\n        sys.stdout.flush()  # necessary on win10 even w/ stderr btw\n\n\nclass MTHash(object):\n    def __init__(self, cores: int):\n        self.pp: Optional[ProgressPrinter] = None\n        self.f: Optional[typing.BinaryIO] = None\n        self.sz = 0\n        self.csz = 0\n        self.stop = False\n        self.omutex = threading.Lock()\n        self.imutex = threading.Lock()\n        self.work_q: Queue[int] = Queue()\n        self.done_q: Queue[tuple[int, str, int, int]] = Queue()\n        self.thrs = []\n        for n in range(cores):\n            t = Daemon(self.worker, \"mth-\" + str(n))\n            self.thrs.append(t)\n\n    def hash(\n        self,\n        f: typing.BinaryIO,\n        fsz: int,\n        chunksz: int,\n        pp: Optional[ProgressPrinter] = None,\n        prefix: str = \"\",\n        suffix: str = \"\",\n    ) -> list[tuple[str, int, int]]:\n        with self.omutex:\n            self.f = f\n            self.sz = fsz\n            self.csz = chunksz\n\n            chunks: dict[int, tuple[str, int, int]] = {}\n            nchunks = int(math.ceil(fsz / chunksz))\n            for nch in range(nchunks):\n                self.work_q.put(nch)\n\n            ex = \"\"\n            for nch in range(nchunks):\n                qe = self.done_q.get()\n                try:\n                    nch, dig, ofs, csz = qe\n                    chunks[nch] = (dig, ofs, csz)\n                except:\n                    ex = ex or str(qe)\n\n                if pp:\n                    mb = int((fsz - nch * chunksz) / 1024 / 1024)\n                    pp.msg = prefix + str(mb) + suffix\n\n            if ex:\n                raise Exception(ex)\n\n            ret = []\n            for n in range(nchunks):\n                ret.append(chunks[n])\n\n            self.f = None\n            self.csz = 0\n            self.sz = 0\n            return ret\n\n    def worker(self) -> None:\n        while True:\n            ofs = self.work_q.get()\n            try:\n                v = self.hash_at(ofs)\n            except Exception as ex:\n                v = str(ex)  # type: ignore\n\n            self.done_q.put(v)\n\n    def hash_at(self, nch: int) -> tuple[int, str, int, int]:\n        f = self.f\n        ofs = ofs0 = nch * self.csz\n        chunk_sz = chunk_rem = min(self.csz, self.sz - ofs)\n        if self.stop:\n            return nch, \"\", ofs0, chunk_sz\n\n        assert f\n        hashobj = hashlib.sha512()\n        while chunk_rem > 0:\n            with self.imutex:\n                f.seek(ofs)\n                buf = f.read(min(chunk_rem, 1024 * 1024 * 12))\n\n            if not buf:\n                raise Exception(\"EOF at \" + str(ofs))\n\n            hashobj.update(buf)\n            chunk_rem -= len(buf)\n            ofs += len(buf)\n\n        bdig = hashobj.digest()[:33]\n        udig = base64.urlsafe_b64encode(bdig).decode(\"utf-8\")\n        return nch, udig, ofs0, chunk_sz\n\n\nclass HMaccas(object):\n    def __init__(self, keypath: str, retlen: int) -> None:\n        self.retlen = retlen\n        self.cache: dict[bytes, str] = {}\n        try:\n            with open(keypath, \"rb\") as f:\n                self.key = f.read()\n                if len(self.key) != 64:\n                    raise Exception()\n        except:\n            self.key = os.urandom(64)\n            with open(keypath, \"wb\") as f:\n                f.write(self.key)\n\n    def b(self, msg: bytes) -> str:\n        try:\n            return self.cache[msg]\n        except:\n            if len(self.cache) > 9000:\n                self.cache = {}\n\n            zb = hmac.new(self.key, msg, hashlib.sha512).digest()\n            zs = base64.urlsafe_b64encode(zb)[: self.retlen].decode(\"utf-8\")\n            self.cache[msg] = zs\n            return zs\n\n    def s(self, msg: str) -> str:\n        return self.b(msg.encode(\"utf-8\", \"replace\"))\n\n\nclass Magician(object):\n    def __init__(self) -> None:\n        self.bad_magic = False\n        self.mutex = threading.Lock()\n        self.magic: Optional[\"magic.Magic\"] = None\n\n    def ext(self, fpath: str) -> str:\n        import magic\n\n        try:\n            if self.bad_magic:\n                raise Exception()\n\n            if not self.magic:\n                try:\n                    with self.mutex:\n                        if not self.magic:\n                            self.magic = magic.Magic(uncompress=False, extension=True)\n                except:\n                    self.bad_magic = True\n                    raise\n\n            with self.mutex:\n                ret = self.magic.from_file(fpath)\n        except:\n            ret = \"?\"\n\n        ret = ret.split(\"/\")[0]\n        ret = MAGIC_MAP.get(ret, ret)\n        if \"?\" not in ret:\n            return ret\n\n        mime = magic.from_file(fpath, mime=True)\n        mime = re.split(\"[; ]\", mime, 1)[0]\n        try:\n            return EXTS[mime]\n        except:\n            pass\n\n        mg = mimetypes.guess_extension(mime)\n        if mg:\n            return mg[1:]\n        else:\n            raise Exception()\n\n\nclass Garda(object):\n    \"\"\"ban clients for repeated offenses\"\"\"\n\n    def __init__(self, cfg: str) -> None:\n        try:\n            a, b, c = cfg.strip().split(\",\")\n            self.lim = int(a)\n            self.win = int(b) * 60\n            self.pen = int(c) * 60\n        except:\n            self.lim = self.win = self.pen = 0\n\n        self.ct: dict[str, list[int]] = {}\n        self.prev: dict[str, str] = {}\n        self.last_cln = 0\n\n    def cln(self, ip: str) -> None:\n        n = 0\n        ok = int(time.time() - self.win)\n        for v in self.ct[ip]:\n            if v < ok:\n                n += 1\n            else:\n                break\n        if n:\n            te = self.ct[ip][n:]\n            if te:\n                self.ct[ip] = te\n            else:\n                del self.ct[ip]\n                try:\n                    del self.prev[ip]\n                except:\n                    pass\n\n    def allcln(self) -> None:\n        for k in list(self.ct):\n            self.cln(k)\n\n        self.last_cln = int(time.time())\n\n    def bonk(self, ip: str, prev: str) -> tuple[int, str]:\n        if not self.lim:\n            return 0, ip\n\n        if \":\" in ip:\n            # assume /64 clients; drop 4 groups\n            ip = IPv6Address(ip).exploded[:-20]\n\n        if prev:\n            if self.prev.get(ip) == prev:\n                return 0, ip\n\n            self.prev[ip] = prev\n\n        now = int(time.time())\n        try:\n            self.ct[ip].append(now)\n        except:\n            self.ct[ip] = [now]\n\n        if now - self.last_cln > 300:\n            self.allcln()\n        else:\n            self.cln(ip)\n\n        if len(self.ct[ip]) >= self.lim:\n            return now + self.pen, ip\n        else:\n            return 0, ip\n\n\nif WINDOWS and sys.version_info < (3, 8):\n    _popen = sp.Popen\n\n    def _spopen(c, *a, **ka):\n        enc = sys.getfilesystemencoding()\n        c = [x.decode(enc, \"replace\") if hasattr(x, \"decode\") else x for x in c]\n        return _popen(c, *a, **ka)\n\n    sp.Popen = _spopen\n\n\ndef uprint(msg: str) -> None:\n    try:\n        print(msg, end=\"\")\n    except UnicodeEncodeError:\n        try:\n            print(msg.encode(\"utf-8\", \"replace\").decode(), end=\"\")\n        except:\n            print(msg.encode(\"ascii\", \"replace\").decode(), end=\"\")\n\n\ndef nuprint(msg: str) -> None:\n    uprint(\"{}\\n\".format(msg))\n\n\ndef rice_tid() -> str:\n    tid = threading.current_thread().ident\n    c = sunpack(b\"B\" * 5, spack(b\">Q\", tid)[-5:])\n    return \"\".join(\"\\033[1;37;48;5;{0}m{0:02x}\".format(x) for x in c) + \"\\033[0m\"\n\n\ndef trace(*args: Any, **kwargs: Any) -> None:\n    t = time.time()\n    stack = \"\".join(\n        \"\\033[36m{}\\033[33m{}\".format(x[0].split(os.sep)[-1][:-3], x[1])\n        for x in traceback.extract_stack()[3:-1]\n    )\n    parts = [\"{:.6f}\".format(t), rice_tid(), stack]\n\n    if args:\n        parts.append(repr(args))\n\n    if kwargs:\n        parts.append(repr(kwargs))\n\n    msg = \"\\033[0m \".join(parts)\n    # _tracebuf.append(msg)\n    nuprint(msg)\n\n\ndef alltrace() -> str:\n    threads: dict[str, types.FrameType] = {}\n    names = dict([(t.ident, t.name) for t in threading.enumerate()])\n    for tid, stack in sys._current_frames().items():\n        name = \"{} ({:x})\".format(names.get(tid), tid)\n        threads[name] = stack\n\n    rret: list[str] = []\n    bret: list[str] = []\n    for name, stack in sorted(threads.items()):\n        ret = [\"\\n\\n# {}\".format(name)]\n        pad = None\n        for fn, lno, name, line in traceback.extract_stack(stack):\n            fn = os.sep.join(fn.split(os.sep)[-3:])\n            ret.append('File: \"{}\", line {}, in {}'.format(fn, lno, name))\n            if line:\n                ret.append(\"  \" + str(line.strip()))\n                if \"self.not_empty.wait()\" in line:\n                    pad = \" \" * 4\n\n        if pad:\n            bret += [ret[0]] + [pad + x for x in ret[1:]]\n        else:\n            rret += ret\n\n    return \"\\n\".join(rret + bret) + \"\\n\"\n\n\ndef start_stackmon(arg_str: str, nid: int) -> None:\n    suffix = \"-{}\".format(nid) if nid else \"\"\n    fp, f = arg_str.rsplit(\",\", 1)\n    zi = int(f)\n    Daemon(stackmon, \"stackmon\" + suffix, (fp, zi, suffix))\n\n\ndef stackmon(fp: str, ival: float, suffix: str) -> None:\n    ctr = 0\n    fp0 = fp\n    while True:\n        ctr += 1\n        fp = fp0\n        time.sleep(ival)\n        st = \"{}, {}\\n{}\".format(ctr, time.time(), alltrace())\n        buf = st.encode(\"utf-8\", \"replace\")\n\n        if fp.endswith(\".gz\"):\n            import gzip\n\n            # 2459b 2304b 2241b 2202b 2194b 2191b lv3..8\n            # 0.06s 0.08s 0.11s 0.13s 0.16s 0.19s\n            buf = gzip.compress(buf, compresslevel=6)\n\n        elif fp.endswith(\".xz\"):\n            import lzma\n\n            # 2276b 2216b 2200b 2192b 2168b lv0..4\n            # 0.04s 0.10s 0.22s 0.41s 0.70s\n            buf = lzma.compress(buf, preset=0)\n\n        if \"%\" in fp:\n            dt = datetime.utcnow()\n            for fs in \"YmdHMS\":\n                fs = \"%\" + fs\n                if fs in fp:\n                    fp = fp.replace(fs, dt.strftime(fs))\n\n        if \"/\" in fp:\n            try:\n                os.makedirs(fp.rsplit(\"/\", 1)[0])\n            except:\n                pass\n\n        with open(fp + suffix, \"wb\") as f:\n            f.write(buf)\n\n\ndef start_log_thrs(\n    logger: Callable[[str, str, int], None], ival: float, nid: int\n) -> None:\n    ival = float(ival)\n    tname = lname = \"log-thrs\"\n    if nid:\n        tname = \"logthr-n{}-i{:x}\".format(nid, os.getpid())\n        lname = tname[3:]\n\n    Daemon(log_thrs, tname, (logger, ival, lname))\n\n\ndef log_thrs(log: Callable[[str, str, int], None], ival: float, name: str) -> None:\n    while True:\n        time.sleep(ival)\n        tv = [x.name for x in threading.enumerate()]\n        tv = [\n            x.split(\"-\")[0]\n            if x.split(\"-\")[0] in [\"httpconn\", \"thumb\", \"tagger\"]\n            else \"listen\"\n            if \"-listen-\" in x\n            else x\n            for x in tv\n            if not x.startswith(\"pydevd.\")\n        ]\n        tv = [\"{}\\033[36m{}\".format(v, k) for k, v in sorted(Counter(tv).items())]\n        log(name, \"\\033[0m \\033[33m\".join(tv), 3)\n\n\ndef vol_san(vols: list[\"VFS\"], txt: bytes) -> bytes:\n    for vol in vols:\n        txt = txt.replace(vol.realpath.encode(\"utf-8\"), vol.vpath.encode(\"utf-8\"))\n        txt = txt.replace(\n            vol.realpath.encode(\"utf-8\").replace(b\"\\\\\", b\"\\\\\\\\\"),\n            vol.vpath.encode(\"utf-8\"),\n        )\n\n    return txt\n\n\ndef min_ex(max_lines: int = 8, reverse: bool = False) -> str:\n    et, ev, tb = sys.exc_info()\n    stb = traceback.extract_tb(tb)\n    fmt = \"{} @ {} <{}>: {}\"\n    ex = [fmt.format(fp.split(os.sep)[-1], ln, fun, txt) for fp, ln, fun, txt in stb]\n    ex.append(\"[{}] {}\".format(et.__name__ if et else \"(anonymous)\", ev))\n    return \"\\n\".join(ex[-max_lines:][:: -1 if reverse else 1])\n\n\n@contextlib.contextmanager\ndef ren_open(\n    fname: str, *args: Any, **kwargs: Any\n) -> Generator[dict[str, tuple[typing.IO[Any], str]], None, None]:\n    fun = kwargs.pop(\"fun\", open)\n    fdir = kwargs.pop(\"fdir\", None)\n    suffix = kwargs.pop(\"suffix\", None)\n\n    if fname == os.devnull:\n        with fun(fname, *args, **kwargs) as f:\n            yield {\"orz\": (f, fname)}\n            return\n\n    if suffix:\n        ext = fname.split(\".\")[-1]\n        if len(ext) < 7:\n            suffix += \".\" + ext\n\n    orig_name = fname\n    bname = fname\n    ext = \"\"\n    while True:\n        ofs = bname.rfind(\".\")\n        if ofs < 0 or ofs < len(bname) - 7:\n            # doesn't look like an extension anymore\n            break\n\n        ext = bname[ofs:] + ext\n        bname = bname[:ofs]\n\n    asciified = False\n    b64 = \"\"\n    while True:\n        try:\n            if fdir:\n                fpath = os.path.join(fdir, fname)\n            else:\n                fpath = fname\n\n            if suffix and os.path.lexists(fsenc(fpath)):\n                fpath += suffix\n                fname += suffix\n                ext += suffix\n\n            with fun(fsenc(fpath), *args, **kwargs) as f:\n                if b64:\n                    assert fdir\n                    fp2 = \"fn-trunc.{}.txt\".format(b64)\n                    fp2 = os.path.join(fdir, fp2)\n                    with open(fsenc(fp2), \"wb\") as f2:\n                        f2.write(orig_name.encode(\"utf-8\"))\n\n                yield {\"orz\": (f, fname)}\n                return\n\n        except OSError as ex_:\n            ex = ex_\n\n            if ex.errno == errno.EINVAL and not asciified:\n                asciified = True\n                bname, fname = [\n                    zs.encode(\"ascii\", \"replace\").decode(\"ascii\").replace(\"?\", \"_\")\n                    for zs in [bname, fname]\n                ]\n                continue\n\n            # ENOTSUP: zfs on ubuntu 20.04\n            if ex.errno not in (errno.ENAMETOOLONG, errno.ENOSR, errno.ENOTSUP) and (\n                not WINDOWS or ex.errno != errno.EINVAL\n            ):\n                raise\n\n        if not b64:\n            zs = \"{}\\n{}\".format(orig_name, suffix).encode(\"utf-8\", \"replace\")\n            zs = hashlib.sha512(zs).digest()[:12]\n            b64 = base64.urlsafe_b64encode(zs).decode(\"utf-8\")\n\n        badlen = len(fname)\n        while len(fname) >= badlen:\n            if len(bname) < 8:\n                raise ex\n\n            if len(bname) > len(ext):\n                # drop the last letter of the filename\n                bname = bname[:-1]\n            else:\n                try:\n                    # drop the leftmost sub-extension\n                    _, ext = ext.split(\".\", 1)\n                except:\n                    # okay do the first letter then\n                    ext = \".\" + ext[2:]\n\n            fname = \"{}~{}{}\".format(bname, b64, ext)\n\n\nclass MultipartParser(object):\n    def __init__(\n        self, log_func: \"NamedLogger\", sr: Unrecv, http_headers: dict[str, str]\n    ):\n        self.sr = sr\n        self.log = log_func\n        self.headers = http_headers\n\n        self.re_ctype = re.compile(r\"^content-type: *([^; ]+)\", re.IGNORECASE)\n        self.re_cdisp = re.compile(r\"^content-disposition: *([^; ]+)\", re.IGNORECASE)\n        self.re_cdisp_field = re.compile(\n            r'^content-disposition:(?: *|.*; *)name=\"([^\"]+)\"', re.IGNORECASE\n        )\n        self.re_cdisp_file = re.compile(\n            r'^content-disposition:(?: *|.*; *)filename=\"(.*)\"', re.IGNORECASE\n        )\n\n        self.boundary = b\"\"\n        self.gen: Optional[\n            Generator[\n                tuple[str, Optional[str], Generator[bytes, None, None]], None, None\n            ]\n        ] = None\n\n    def _read_header(self) -> tuple[str, Optional[str]]:\n        \"\"\"\n        returns [fieldname, filename] after eating a block of multipart headers\n        while doing a decent job at dealing with the absolute mess that is\n        rfc1341/rfc1521/rfc2047/rfc2231/rfc2388/rfc6266/the-real-world\n        (only the fallback non-js uploader relies on these filenames)\n        \"\"\"\n        for ln in read_header(self.sr, 2, 2592000):\n            self.log(ln)\n\n            m = self.re_ctype.match(ln)\n            if m:\n                if m.group(1).lower() == \"multipart/mixed\":\n                    # rfc-7578 overrides rfc-2388 so this is not-impl\n                    # (opera >=9 <11.10 is the only thing i've ever seen use it)\n                    raise Pebkac(\n                        400,\n                        \"you can't use that browser to upload multiple files at once\",\n                    )\n\n                continue\n\n            # the only other header we care about is content-disposition\n            m = self.re_cdisp.match(ln)\n            if not m:\n                continue\n\n            if m.group(1).lower() != \"form-data\":\n                raise Pebkac(400, \"not form-data: {}\".format(ln))\n\n            try:\n                field = self.re_cdisp_field.match(ln).group(1)  # type: ignore\n            except:\n                raise Pebkac(400, \"missing field name: {}\".format(ln))\n\n            try:\n                fn = self.re_cdisp_file.match(ln).group(1)  # type: ignore\n            except:\n                # this is not a file upload, we're done\n                return field, None\n\n            try:\n                is_webkit = \"applewebkit\" in self.headers[\"user-agent\"].lower()\n            except:\n                is_webkit = False\n\n            # chromes ignore the spec and makes this real easy\n            if is_webkit:\n                # quotes become %22 but they don't escape the %\n                # so unescaping the quotes could turn messi\n                return field, fn.split('\"')[0]\n\n            # also ez if filename doesn't contain \"\n            if not fn.split('\"')[0].endswith(\"\\\\\"):\n                return field, fn.split('\"')[0]\n\n            # this breaks on firefox uploads that contain \\\"\n            # since firefox escapes \" but forgets to escape \\\n            # so it'll truncate after the \\\n            ret = \"\"\n            esc = False\n            for ch in fn:\n                if esc:\n                    esc = False\n                    if ch not in ['\"', \"\\\\\"]:\n                        ret += \"\\\\\"\n                    ret += ch\n                elif ch == \"\\\\\":\n                    esc = True\n                elif ch == '\"':\n                    break\n                else:\n                    ret += ch\n\n            return field, ret\n\n        raise Pebkac(400, \"server expected a multipart header but you never sent one\")\n\n    def _read_data(self) -> Generator[bytes, None, None]:\n        blen = len(self.boundary)\n        bufsz = 32 * 1024\n        while True:\n            try:\n                buf = self.sr.recv(bufsz)\n            except:\n                # abort: client disconnected\n                raise Pebkac(400, \"client d/c during multipart post\")\n\n            while True:\n                ofs = buf.find(self.boundary)\n                if ofs != -1:\n                    self.sr.unrecv(buf[ofs + blen :])\n                    yield buf[:ofs]\n                    return\n\n                d = len(buf) - blen\n                if d > 0:\n                    # buffer growing large; yield everything except\n                    # the part at the end (maybe start of boundary)\n                    yield buf[:d]\n                    buf = buf[d:]\n\n                # look for boundary near the end of the buffer\n                n = 0\n                for n in range(1, len(buf) + 1):\n                    if not buf[-n:] in self.boundary:\n                        n -= 1\n                        break\n\n                if n == 0 or not self.boundary.startswith(buf[-n:]):\n                    # no boundary contents near the buffer edge\n                    break\n\n                if blen == n:\n                    # EOF: found boundary\n                    yield buf[:-n]\n                    return\n\n                try:\n                    buf += self.sr.recv(bufsz)\n                except:\n                    # abort: client disconnected\n                    raise Pebkac(400, \"client d/c during multipart post\")\n\n            yield buf\n\n    def _run_gen(\n        self,\n    ) -> Generator[tuple[str, Optional[str], Generator[bytes, None, None]], None, None]:\n        \"\"\"\n        yields [fieldname, unsanitized_filename, fieldvalue]\n        where fieldvalue yields chunks of data\n        \"\"\"\n        run = True\n        while run:\n            fieldname, filename = self._read_header()\n            yield (fieldname, filename, self._read_data())\n\n            tail = self.sr.recv_ex(2, False)\n\n            if tail == b\"--\":\n                # EOF indicated by this immediately after final boundary\n                tail = self.sr.recv_ex(2, False)\n                run = False\n\n            if tail != b\"\\r\\n\":\n                t = \"protocol error after field value: want b'\\\\r\\\\n', got {!r}\"\n                raise Pebkac(400, t.format(tail))\n\n    def _read_value(self, iterable: Iterable[bytes], max_len: int) -> bytes:\n        ret = b\"\"\n        for buf in iterable:\n            ret += buf\n            if len(ret) > max_len:\n                raise Pebkac(400, \"field length is too long\")\n\n        return ret\n\n    def parse(self) -> None:\n        # spec says there might be junk before the first boundary,\n        # can't have the leading \\r\\n if that's not the case\n        self.boundary = b\"--\" + get_boundary(self.headers).encode(\"utf-8\")\n\n        # discard junk before the first boundary\n        for junk in self._read_data():\n            self.log(\n                \"discarding preamble: [{}]\".format(junk.decode(\"utf-8\", \"replace\"))\n            )\n\n        # nice, now make it fast\n        self.boundary = b\"\\r\\n\" + self.boundary\n        self.gen = self._run_gen()\n\n    def require(self, field_name: str, max_len: int) -> str:\n        \"\"\"\n        returns the value of the next field in the multipart body,\n        raises if the field name is not as expected\n        \"\"\"\n        assert self.gen\n        p_field, _, p_data = next(self.gen)\n        if p_field != field_name:\n            raise Pebkac(\n                422, 'expected field \"{}\", got \"{}\"'.format(field_name, p_field)\n            )\n\n        return self._read_value(p_data, max_len).decode(\"utf-8\", \"surrogateescape\")\n\n    def drop(self) -> None:\n        \"\"\"discards the remaining multipart body\"\"\"\n        assert self.gen\n        for _, _, data in self.gen:\n            for _ in data:\n                pass\n\n\ndef get_boundary(headers: dict[str, str]) -> str:\n    # boundaries contain a-z A-Z 0-9 ' ( ) + _ , - . / : = ?\n    # (whitespace allowed except as the last char)\n    ptn = r\"^multipart/form-data *; *(.*; *)?boundary=([^;]+)\"\n    ct = headers[\"content-type\"]\n    m = re.match(ptn, ct, re.IGNORECASE)\n    if not m:\n        raise Pebkac(400, \"invalid content-type for a multipart post: {}\".format(ct))\n\n    return m.group(2)\n\n\ndef read_header(sr: Unrecv, t_idle: int, t_tot: int) -> list[str]:\n    t0 = time.time()\n    ret = b\"\"\n    while True:\n        if time.time() - t0 >= t_tot:\n            return []\n\n        try:\n            ret += sr.recv(1024, t_idle // 2)\n        except:\n            if not ret:\n                return []\n\n            raise Pebkac(\n                400,\n                \"protocol error while reading headers:\\n\"\n                + ret.decode(\"utf-8\", \"replace\"),\n            )\n\n        ofs = ret.find(b\"\\r\\n\\r\\n\")\n        if ofs < 0:\n            if len(ret) > 1024 * 64:\n                raise Pebkac(400, \"header 2big\")\n            else:\n                continue\n\n        if len(ret) > ofs + 4:\n            sr.unrecv(ret[ofs + 4 :])\n\n        return ret[:ofs].decode(\"utf-8\", \"surrogateescape\").lstrip(\"\\r\\n\").split(\"\\r\\n\")\n\n\ndef rand_name(fdir: str, fn: str, rnd: int) -> str:\n    ok = False\n    try:\n        ext = \".\" + fn.rsplit(\".\", 1)[1]\n    except:\n        ext = \"\"\n\n    for extra in range(16):\n        for _ in range(16):\n            if ok:\n                break\n\n            nc = rnd + extra\n            nb = int((6 + 6 * nc) / 8)\n            zb = os.urandom(nb)\n            zb = base64.urlsafe_b64encode(zb)\n            fn = zb[:nc].decode(\"utf-8\") + ext\n            ok = not os.path.exists(fsenc(os.path.join(fdir, fn)))\n\n    return fn\n\n\ndef gen_filekey(salt: str, fspath: str, fsize: int, inode: int) -> str:\n    return base64.urlsafe_b64encode(\n        hashlib.sha512(\n            (\"%s %s %s %s\" % (salt, fspath, fsize, inode)).encode(\"utf-8\", \"replace\")\n        ).digest()\n    ).decode(\"ascii\")\n\n\ndef gen_filekey_dbg(\n    salt: str,\n    fspath: str,\n    fsize: int,\n    inode: int,\n    log: \"NamedLogger\",\n    log_ptn: Optional[Pattern[str]],\n) -> str:\n    ret = gen_filekey(salt, fspath, fsize, inode)\n\n    assert log_ptn\n    if log_ptn.search(fspath):\n        try:\n            import inspect\n\n            ctx = \",\".join(inspect.stack()[n].function for n in range(2, 5))\n        except:\n            ctx = \"\"\n\n        p2 = \"a\"\n        try:\n            p2 = absreal(fspath)\n            if p2 != fspath:\n                raise Exception()\n        except:\n            t = \"maybe wrong abspath for filekey;\\norig: {}\\nreal: {}\"\n            log(t.format(fspath, p2), 1)\n\n        t = \"fk({}) salt({}) size({}) inode({}) fspath({}) at({})\"\n        log(t.format(ret[:8], salt, fsize, inode, fspath, ctx), 5)\n\n    return ret\n\n\ndef gencookie(k: str, v: str, r: str, tls: bool, dur: Optional[int]) -> str:\n    v = v.replace(\"%\", \"%25\").replace(\";\", \"%3B\")\n    if dur:\n        exp = formatdate(time.time() + dur, usegmt=True)\n    else:\n        exp = \"Fri, 15 Aug 1997 01:00:00 GMT\"\n\n    return \"{}={}; Path=/{}; Expires={}{}; SameSite=Lax\".format(\n        k, v, r, exp, \"; Secure\" if tls else \"\"\n    )\n\n\ndef humansize(sz: float, terse: bool = False) -> str:\n    for unit in [\"B\", \"KiB\", \"MiB\", \"GiB\", \"TiB\"]:\n        if sz < 1024:\n            break\n\n        sz /= 1024.0\n\n    ret = \" \".join([str(sz)[:4].rstrip(\".\"), unit])\n\n    if not terse:\n        return ret\n\n    return ret.replace(\"iB\", \"\").replace(\" \", \"\")\n\n\ndef unhumanize(sz: str) -> int:\n    try:\n        return int(sz)\n    except:\n        pass\n\n    mc = sz[-1:].lower()\n    mi = {\n        \"k\": 1024,\n        \"m\": 1024 * 1024,\n        \"g\": 1024 * 1024 * 1024,\n        \"t\": 1024 * 1024 * 1024 * 1024,\n    }.get(mc, 1)\n    return int(float(sz[:-1]) * mi)\n\n\ndef get_spd(nbyte: int, t0: float, t: Optional[float] = None) -> str:\n    if t is None:\n        t = time.time()\n\n    bps = nbyte / ((t - t0) + 0.001)\n    s1 = humansize(nbyte).replace(\" \", \"\\033[33m\").replace(\"iB\", \"\")\n    s2 = humansize(bps).replace(\" \", \"\\033[35m\").replace(\"iB\", \"\")\n    return \"{} \\033[0m{}/s\\033[0m\".format(s1, s2)\n\n\ndef s2hms(s: float, optional_h: bool = False) -> str:\n    s = int(s)\n    h, s = divmod(s, 3600)\n    m, s = divmod(s, 60)\n    if not h and optional_h:\n        return \"{}:{:02}\".format(m, s)\n\n    return \"{}:{:02}:{:02}\".format(h, m, s)\n\n\ndef djoin(*paths: str) -> str:\n    \"\"\"joins without adding a trailing slash on blank args\"\"\"\n    return os.path.join(*[x for x in paths if x])\n\n\ndef uncyg(path: str) -> str:\n    if len(path) < 2 or not path.startswith(\"/\"):\n        return path\n\n    if len(path) > 2 and path[2] != \"/\":\n        return path\n\n    return \"%s:\\\\%s\" % (path[1], path[3:])\n\n\ndef undot(path: str) -> str:\n    ret: list[str] = []\n    for node in path.split(\"/\"):\n        if node in [\"\", \".\"]:\n            continue\n\n        if node == \"..\":\n            if ret:\n                ret.pop()\n            continue\n\n        ret.append(node)\n\n    return \"/\".join(ret)\n\n\ndef sanitize_fn(fn: str, ok: str, bad: list[str]) -> str:\n    if \"/\" not in ok:\n        fn = fn.replace(\"\\\\\", \"/\").split(\"/\")[-1]\n\n    if fn.lower() in bad:\n        fn = \"_\" + fn\n\n    if ANYWIN:\n        remap = [\n            [\"<\", \"\uff1c\"],\n            [\">\", \"\uff1e\"],\n            [\":\", \"\uff1a\"],\n            ['\"', \"\uff02\"],\n            [\"/\", \"\uff0f\"],\n            [\"\\\\\", \"\uff3c\"],\n            [\"|\", \"\uff5c\"],\n            [\"?\", \"\uff1f\"],\n            [\"*\", \"\uff0a\"],\n        ]\n        for a, b in [x for x in remap if x[0] not in ok]:\n            fn = fn.replace(a, b)\n\n        bad = [\"con\", \"prn\", \"aux\", \"nul\"]\n        for n in range(1, 10):\n            bad += (\"com%s lpt%s\" % (n, n)).split(\" \")\n\n        if fn.lower().split(\".\")[0] in bad:\n            fn = \"_\" + fn\n\n    return fn.strip()\n\n\ndef relchk(rp: str) -> str:\n    if ANYWIN:\n        if \"\\n\" in rp or \"\\r\" in rp:\n            return \"x\\nx\"\n\n        p = re.sub(r'[\\\\:*?\"<>|]', \"\", rp)\n        if p != rp:\n            return \"[{}]\".format(p)\n\n    return \"\"\n\n\ndef absreal(fpath: str) -> str:\n    try:\n        return fsdec(os.path.abspath(os.path.realpath(afsenc(fpath))))\n    except:\n        if not WINDOWS:\n            raise\n\n        # cpython bug introduced in 3.8, still exists in 3.9.1,\n        # some win7sp1 and win10:20H2 boxes cannot realpath a\n        # networked drive letter such as b\"n:\" or b\"n:\\\\\"\n        return os.path.abspath(os.path.realpath(fpath))\n\n\ndef u8safe(txt: str) -> str:\n    try:\n        return txt.encode(\"utf-8\", \"xmlcharrefreplace\").decode(\"utf-8\", \"replace\")\n    except:\n        return txt.encode(\"utf-8\", \"replace\").decode(\"utf-8\", \"replace\")\n\n\ndef exclude_dotfiles(filepaths: list[str]) -> list[str]:\n    return [x for x in filepaths if not x.split(\"/\")[-1].startswith(\".\")]\n\n\ndef ipnorm(ip: str) -> str:\n    if \":\" in ip:\n        # assume /64 clients; drop 4 groups\n        return IPv6Address(ip).exploded[:-20]\n\n    return ip\n\n\ndef find_prefix(ips: list[str], netdevs: dict[str, Netdev]) -> list[str]:\n    ret = []\n    for ip in ips:\n        hit = next((x for x in netdevs if x.startswith(ip + \"/\")), None)\n        if hit:\n            ret.append(hit)\n    return ret\n\n\ndef html_escape(s: str, quot: bool = False, crlf: bool = False) -> str:\n    \"\"\"html.escape but also newlines\"\"\"\n    s = s.replace(\"&\", \"&amp;\").replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n    if quot:\n        s = s.replace('\"', \"&quot;\").replace(\"'\", \"&#x27;\")\n    if crlf:\n        s = s.replace(\"\\r\", \"&#13;\").replace(\"\\n\", \"&#10;\")\n\n    return s\n\n\ndef html_bescape(s: bytes, quot: bool = False, crlf: bool = False) -> bytes:\n    \"\"\"html.escape but bytestrings\"\"\"\n    s = s.replace(b\"&\", b\"&amp;\").replace(b\"<\", b\"&lt;\").replace(b\">\", b\"&gt;\")\n    if quot:\n        s = s.replace(b'\"', b\"&quot;\").replace(b\"'\", b\"&#x27;\")\n    if crlf:\n        s = s.replace(b\"\\r\", b\"&#13;\").replace(b\"\\n\", b\"&#10;\")\n\n    return s\n\n\ndef _quotep2(txt: str) -> str:\n    \"\"\"url quoter which deals with bytes correctly\"\"\"\n    btxt = w8enc(txt)\n    quot = quote(btxt, safe=b\"/\")\n    return w8dec(quot.replace(b\" \", b\"+\"))\n\n\ndef _quotep3(txt: str) -> str:\n    \"\"\"url quoter which deals with bytes correctly\"\"\"\n    btxt = w8enc(txt)\n    quot = quote(btxt, safe=b\"/\").encode(\"utf-8\")\n    return w8dec(quot.replace(b\" \", b\"+\"))\n\n\nquotep = _quotep3 if not PY2 else _quotep2\n\n\ndef unquotep(txt: str) -> str:\n    \"\"\"url unquoter which deals with bytes correctly\"\"\"\n    btxt = w8enc(txt)\n    # btxt = btxt.replace(b\"+\", b\" \")\n    unq2 = unquote(btxt)\n    return w8dec(unq2)\n\n\ndef vsplit(vpath: str) -> tuple[str, str]:\n    if \"/\" not in vpath:\n        return \"\", vpath\n\n    return vpath.rsplit(\"/\", 1)  # type: ignore\n\n\ndef vjoin(rd: str, fn: str) -> str:\n    if rd and fn:\n        return rd + \"/\" + fn\n    else:\n        return rd or fn\n\n\ndef _w8dec2(txt: bytes) -> str:\n    \"\"\"decodes filesystem-bytes to wtf8\"\"\"\n    return surrogateescape.decodefilename(txt)\n\n\ndef _w8enc2(txt: str) -> bytes:\n    \"\"\"encodes wtf8 to filesystem-bytes\"\"\"\n    return surrogateescape.encodefilename(txt)\n\n\ndef _w8dec3(txt: bytes) -> str:\n    \"\"\"decodes filesystem-bytes to wtf8\"\"\"\n    return txt.decode(FS_ENCODING, \"surrogateescape\")\n\n\ndef _w8enc3(txt: str) -> bytes:\n    \"\"\"encodes wtf8 to filesystem-bytes\"\"\"\n    return txt.encode(FS_ENCODING, \"surrogateescape\")\n\n\ndef _msdec(txt: bytes) -> str:\n    ret = txt.decode(FS_ENCODING, \"surrogateescape\")\n    return ret[4:] if ret.startswith(\"\\\\\\\\?\\\\\") else ret\n\n\ndef _msaenc(txt: str) -> bytes:\n    return txt.replace(\"/\", \"\\\\\").encode(FS_ENCODING, \"surrogateescape\")\n\n\ndef _uncify(txt: str) -> str:\n    txt = txt.replace(\"/\", \"\\\\\")\n    if \":\" not in txt and not txt.startswith(\"\\\\\\\\\"):\n        txt = absreal(txt)\n\n    return txt if txt.startswith(\"\\\\\\\\\") else \"\\\\\\\\?\\\\\" + txt\n\n\ndef _msenc(txt: str) -> bytes:\n    txt = txt.replace(\"/\", \"\\\\\")\n    if \":\" not in txt and not txt.startswith(\"\\\\\\\\\"):\n        txt = absreal(txt)\n\n    ret = txt.encode(FS_ENCODING, \"surrogateescape\")\n    return ret if ret.startswith(b\"\\\\\\\\\") else b\"\\\\\\\\?\\\\\" + ret\n\n\nw8dec = _w8dec3 if not PY2 else _w8dec2\nw8enc = _w8enc3 if not PY2 else _w8enc2\n\n\ndef w8b64dec(txt: str) -> str:\n    \"\"\"decodes base64(filesystem-bytes) to wtf8\"\"\"\n    return w8dec(base64.urlsafe_b64decode(txt.encode(\"ascii\")))\n\n\ndef w8b64enc(txt: str) -> str:\n    \"\"\"encodes wtf8 to base64(filesystem-bytes)\"\"\"\n    return base64.urlsafe_b64encode(w8enc(txt)).decode(\"ascii\")\n\n\nif not PY2 and WINDOWS:\n    sfsenc = w8enc\n    afsenc = _msaenc\n    fsenc = _msenc\n    fsdec = _msdec\n    uncify = _uncify\nelif not PY2 or not WINDOWS:\n    fsenc = afsenc = sfsenc = w8enc\n    fsdec = w8dec\n    uncify = str\nelse:\n    # moonrunes become \\x3f with bytestrings,\n    # losing mojibake support is worth\n    def _not_actually_mbcs_enc(txt: str) -> bytes:\n        return txt\n\n    def _not_actually_mbcs_dec(txt: bytes) -> str:\n        return txt\n\n    fsenc = afsenc = sfsenc = _not_actually_mbcs_enc\n    fsdec = _not_actually_mbcs_dec\n    uncify = str\n\n\ndef s3enc(mem_cur: \"sqlite3.Cursor\", rd: str, fn: str) -> tuple[str, str]:\n    ret: list[str] = []\n    for v in [rd, fn]:\n        try:\n            mem_cur.execute(\"select * from a where b = ?\", (v,))\n            ret.append(v)\n        except:\n            ret.append(\"//\" + w8b64enc(v))\n            # self.log(\"mojien [{}] {}\".format(v, ret[-1][2:]))\n\n    return ret[0], ret[1]\n\n\ndef s3dec(rd: str, fn: str) -> tuple[str, str]:\n    return (\n        w8b64dec(rd[2:]) if rd.startswith(\"//\") else rd,\n        w8b64dec(fn[2:]) if fn.startswith(\"//\") else fn,\n    )\n\n\ndef db_ex_chk(log: \"NamedLogger\", ex: Exception, db_path: str) -> bool:\n    if str(ex) != \"database is locked\":\n        return False\n\n    Daemon(lsof, \"dbex\", (log, db_path))\n    return True\n\n\ndef lsof(log: \"NamedLogger\", abspath: str) -> None:\n    try:\n        rc, so, se = runcmd([b\"lsof\", b\"-R\", fsenc(abspath)], timeout=45)\n        zs = (so.strip() + \"\\n\" + se.strip()).strip()\n        log(\"lsof {} = {}\\n{}\".format(abspath, rc, zs), 3)\n    except:\n        log(\"lsof failed; \" + min_ex(), 3)\n\n\ndef atomic_move(usrc: str, udst: str) -> None:\n    src = fsenc(usrc)\n    dst = fsenc(udst)\n    if not PY2:\n        os.replace(src, dst)\n    else:\n        if os.path.exists(dst):\n            os.unlink(dst)\n\n        os.rename(src, dst)\n\n\ndef get_df(abspath: str) -> tuple[Optional[int], Optional[int]]:\n    try:\n        # some fuses misbehave\n        if ANYWIN:\n            bfree = ctypes.c_ulonglong(0)\n            ctypes.windll.kernel32.GetDiskFreeSpaceExW(  # type: ignore\n                ctypes.c_wchar_p(abspath), None, None, ctypes.pointer(bfree)\n            )\n            return (bfree.value, None)\n        else:\n            sv = os.statvfs(fsenc(abspath))\n            free = sv.f_frsize * sv.f_bfree\n            total = sv.f_frsize * sv.f_blocks\n            return (free, total)\n    except:\n        return (None, None)\n\n\nif not ANYWIN and not MACOS:\n\n    def siocoutq(sck: socket.socket) -> int:\n        # SIOCOUTQ^sockios.h == TIOCOUTQ^ioctl.h\n        try:\n            zb = fcntl.ioctl(sck.fileno(), termios.TIOCOUTQ, b\"AAAA\")\n            return sunpack(b\"I\", zb)[0]  # type: ignore\n        except:\n            return 1\n\nelse:\n    # macos: getsockopt(fd, SOL_SOCKET, SO_NWRITE, ...)\n    # windows: TcpConnectionEstatsSendBuff\n\n    def siocoutq(sck: socket.socket) -> int:\n        return 1\n\n\ndef shut_socket(log: \"NamedLogger\", sck: socket.socket, timeout: int = 3) -> None:\n    t0 = time.time()\n    fd = sck.fileno()\n    if fd == -1:\n        sck.close()\n        return\n\n    try:\n        sck.settimeout(timeout)\n        sck.shutdown(socket.SHUT_WR)\n        try:\n            while time.time() - t0 < timeout:\n                if not siocoutq(sck):\n                    # kernel says tx queue empty, we good\n                    break\n\n                # on windows in particular, drain rx until client shuts\n                if not sck.recv(32 * 1024):\n                    break\n\n            sck.shutdown(socket.SHUT_RDWR)\n        except:\n            pass\n    except Exception as ex:\n        log(\"shut({}): {}\".format(fd, ex), \"90\")\n    finally:\n        td = time.time() - t0\n        if td >= 1:\n            log(\"shut({}) in {:.3f} sec\".format(fd, td), \"90\")\n\n        sck.close()\n\n\ndef read_socket(sr: Unrecv, total_size: int) -> Generator[bytes, None, None]:\n    remains = total_size\n    while remains > 0:\n        bufsz = 32 * 1024\n        if bufsz > remains:\n            bufsz = remains\n\n        try:\n            buf = sr.recv(bufsz)\n        except OSError:\n            t = \"client d/c during binary post after {} bytes, {} bytes remaining\"\n            raise Pebkac(400, t.format(total_size - remains, remains))\n\n        remains -= len(buf)\n        yield buf\n\n\ndef read_socket_unbounded(sr: Unrecv) -> Generator[bytes, None, None]:\n    try:\n        while True:\n            yield sr.recv(32 * 1024)\n    except:\n        return\n\n\ndef read_socket_chunked(\n    sr: Unrecv, log: Optional[\"NamedLogger\"] = None\n) -> Generator[bytes, None, None]:\n    err = \"upload aborted: expected chunk length, got [{}] |{}| instead\"\n    while True:\n        buf = b\"\"\n        while b\"\\r\" not in buf:\n            try:\n                buf += sr.recv(2)\n                if len(buf) > 16:\n                    raise Exception()\n            except:\n                err = err.format(buf.decode(\"utf-8\", \"replace\"), len(buf))\n                raise Pebkac(400, err)\n\n        if not buf.endswith(b\"\\n\"):\n            sr.recv(1)\n\n        try:\n            chunklen = int(buf.rstrip(b\"\\r\\n\"), 16)\n        except:\n            err = err.format(buf.decode(\"utf-8\", \"replace\"), len(buf))\n            raise Pebkac(400, err)\n\n        if chunklen == 0:\n            x = sr.recv_ex(2, False)\n            if x == b\"\\r\\n\":\n                return\n\n            t = \"protocol error after final chunk: want b'\\\\r\\\\n', got {!r}\"\n            raise Pebkac(400, t.format(x))\n\n        if log:\n            log(\"receiving {} byte chunk\".format(chunklen))\n\n        for chunk in read_socket(sr, chunklen):\n            yield chunk\n\n        x = sr.recv_ex(2, False)\n        if x != b\"\\r\\n\":\n            t = \"protocol error in chunk separator: want b'\\\\r\\\\n', got {!r}\"\n            raise Pebkac(400, t.format(x))\n\n\ndef list_ips() -> list[str]:\n    from .stolen.ifaddr import get_adapters\n\n    ret: set[str] = set()\n    for nic in get_adapters():\n        for ipo in nic.ips:\n            if len(ipo.ip) < 7:\n                ret.add(ipo.ip[0])  # ipv6 is (ip,0,0)\n            else:\n                ret.add(ipo.ip)\n\n    return list(ret)\n\n\ndef yieldfile(fn: str) -> Generator[bytes, None, None]:\n    with open(fsenc(fn), \"rb\", 512 * 1024) as f:\n        while True:\n            buf = f.read(64 * 1024)\n            if not buf:\n                break\n\n            yield buf\n\n\ndef hashcopy(\n    fin: Generator[bytes, None, None],\n    fout: Union[typing.BinaryIO, typing.IO[Any]],\n    slp: int = 0,\n    max_sz: int = 0,\n) -> tuple[int, str, str]:\n    hashobj = hashlib.sha512()\n    tlen = 0\n    for buf in fin:\n        tlen += len(buf)\n        if max_sz and tlen > max_sz:\n            continue\n\n        hashobj.update(buf)\n        fout.write(buf)\n        if slp:\n            time.sleep(slp)\n\n    digest = hashobj.digest()[:33]\n    digest_b64 = base64.urlsafe_b64encode(digest).decode(\"utf-8\")\n\n    return tlen, hashobj.hexdigest(), digest_b64\n\n\ndef sendfile_py(\n    log: \"NamedLogger\",\n    lower: int,\n    upper: int,\n    f: typing.BinaryIO,\n    s: socket.socket,\n    bufsz: int,\n    slp: int,\n) -> int:\n    remains = upper - lower\n    f.seek(lower)\n    while remains > 0:\n        if slp:\n            time.sleep(slp)\n\n        buf = f.read(min(bufsz, remains))\n        if not buf:\n            return remains\n\n        try:\n            s.sendall(buf)\n            remains -= len(buf)\n        except:\n            return remains\n\n    return 0\n\n\ndef sendfile_kern(\n    log: \"NamedLogger\",\n    lower: int,\n    upper: int,\n    f: typing.BinaryIO,\n    s: socket.socket,\n    bufsz: int,\n    slp: int,\n) -> int:\n    out_fd = s.fileno()\n    in_fd = f.fileno()\n    ofs = lower\n    stuck = 0.0\n    while ofs < upper:\n        stuck = stuck or time.time()\n        try:\n            req = min(2 ** 30, upper - ofs)\n            select.select([], [out_fd], [], 10)\n            n = os.sendfile(out_fd, in_fd, ofs, req)\n            stuck = 0\n        except OSError as ex:\n            # client stopped reading; do another select\n            d = time.time() - stuck\n            if d < 3600 and ex.errno == errno.EWOULDBLOCK:\n                continue\n\n            n = 0\n        except Exception as ex:\n            n = 0\n            d = time.time() - stuck\n            log(\"sendfile failed after {:.3f} sec: {!r}\".format(d, ex))\n\n        if n <= 0:\n            return upper - ofs\n\n        ofs += n\n        # print(\"sendfile: ok, sent {} now, {} total, {} remains\".format(n, ofs - lower, upper - ofs))\n\n    return 0\n\n\ndef statdir(\n    logger: Optional[\"RootLogger\"], scandir: bool, lstat: bool, top: str\n) -> Generator[tuple[str, os.stat_result], None, None]:\n    if lstat and ANYWIN:\n        lstat = False\n\n    if lstat and (PY2 or os.stat not in os.supports_follow_symlinks):\n        scandir = False\n\n    src = \"statdir\"\n    try:\n        btop = fsenc(top)\n        if scandir and hasattr(os, \"scandir\"):\n            src = \"scandir\"\n            with os.scandir(btop) as dh:\n                for fh in dh:\n                    try:\n                        yield (fsdec(fh.name), fh.stat(follow_symlinks=not lstat))\n                    except Exception as ex:\n                        if not logger:\n                            continue\n\n                        logger(src, \"[s] {} @ {}\".format(repr(ex), fsdec(fh.path)), 6)\n        else:\n            src = \"listdir\"\n            fun: Any = os.lstat if lstat else os.stat\n            for name in os.listdir(btop):\n                abspath = os.path.join(btop, name)\n                try:\n                    yield (fsdec(name), fun(abspath))\n                except Exception as ex:\n                    if not logger:\n                        continue\n\n                    logger(src, \"[s] {} @ {}\".format(repr(ex), fsdec(abspath)), 6)\n\n    except Exception as ex:\n        t = \"{} @ {}\".format(repr(ex), top)\n        if logger:\n            logger(src, t, 1)\n        else:\n            print(t)\n\n\ndef rmdirs(\n    logger: \"RootLogger\", scandir: bool, lstat: bool, top: str, depth: int\n) -> tuple[list[str], list[str]]:\n    \"\"\"rmdir all descendants, then self\"\"\"\n    if not os.path.isdir(fsenc(top)):\n        top = os.path.dirname(top)\n        depth -= 1\n\n    stats = statdir(logger, scandir, lstat, top)\n    dirs = [x[0] for x in stats if stat.S_ISDIR(x[1].st_mode)]\n    dirs = [os.path.join(top, x) for x in dirs]\n    ok = []\n    ng = []\n    for d in reversed(dirs):\n        a, b = rmdirs(logger, scandir, lstat, d, depth + 1)\n        ok += a\n        ng += b\n\n    if depth:\n        try:\n            os.rmdir(fsenc(top))\n            ok.append(top)\n        except:\n            ng.append(top)\n\n    return ok, ng\n\n\ndef rmdirs_up(top: str, stop: str) -> tuple[list[str], list[str]]:\n    \"\"\"rmdir on self, then all parents\"\"\"\n    if top == stop:\n        return [], [top]\n\n    try:\n        os.rmdir(fsenc(top))\n    except:\n        return [], [top]\n\n    par = os.path.dirname(top)\n    if not par or par == stop:\n        return [top], []\n\n    ok, ng = rmdirs_up(par, stop)\n    return [top] + ok, ng\n\n\ndef unescape_cookie(orig: str) -> str:\n    # mw=idk; doot=qwe%2Crty%3Basd+fgh%2Bjkl%25zxc%26vbn  # qwe,rty;asd fgh+jkl%zxc&vbn\n    ret = \"\"\n    esc = \"\"\n    for ch in orig:\n        if ch == \"%\":\n            if len(esc) > 0:\n                ret += esc\n            esc = ch\n\n        elif len(esc) > 0:\n            esc += ch\n            if len(esc) == 3:\n                try:\n                    ret += chr(int(esc[1:], 16))\n                except:\n                    ret += esc\n                esc = \"\"\n\n        else:\n            ret += ch\n\n    if len(esc) > 0:\n        ret += esc\n\n    return ret\n\n\ndef guess_mime(url: str, fallback: str = \"application/octet-stream\") -> str:\n    try:\n        _, ext = url.rsplit(\".\", 1)\n    except:\n        return fallback\n\n    ret = MIMES.get(ext)\n\n    if not ret:\n        x = mimetypes.guess_type(url)\n        ret = \"application/{}\".format(x[1]) if x[1] else x[0]\n\n    if not ret:\n        ret = fallback\n\n    if \";\" not in ret:\n        if ret.startswith(\"text/\") or ret.endswith(\"/javascript\"):\n            ret += \"; charset=utf-8\"\n\n    return ret\n\n\ndef getalive(pids: list[int], pgid: int) -> list[int]:\n    alive = []\n    for pid in pids:\n        try:\n            if pgid:\n                # check if still one of ours\n                if os.getpgid(pid) == pgid:\n                    alive.append(pid)\n            else:\n                # windows doesn't have pgroups; assume\n                psutil.Process(pid)\n                alive.append(pid)\n        except:\n            pass\n\n    return alive\n\n\ndef killtree(root: int) -> None:\n    \"\"\"still racy but i tried\"\"\"\n    try:\n        # limit the damage where possible (unixes)\n        pgid = os.getpgid(os.getpid())\n    except:\n        pgid = 0\n\n    if HAVE_PSUTIL:\n        pids = [root]\n        parent = psutil.Process(root)\n        for child in parent.children(recursive=True):\n            pids.append(child.pid)\n            child.terminate()\n        parent.terminate()\n        parent = None\n    elif pgid:\n        # linux-only\n        pids = []\n        chk = [root]\n        while chk:\n            pid = chk[0]\n            chk = chk[1:]\n            pids.append(pid)\n            _, t, _ = runcmd([\"pgrep\", \"-P\", str(pid)])\n            chk += [int(x) for x in t.strip().split(\"\\n\") if x]\n\n        pids = getalive(pids, pgid)  # filter to our pgroup\n        for pid in pids:\n            os.kill(pid, signal.SIGTERM)\n    else:\n        # windows gets minimal effort sorry\n        os.kill(root, signal.SIGTERM)\n        return\n\n    for n in range(10):\n        time.sleep(0.1)\n        pids = getalive(pids, pgid)\n        if not pids or n > 3 and pids == [root]:\n            break\n\n    for pid in pids:\n        try:\n            os.kill(pid, signal.SIGKILL)\n        except:\n            pass\n\n\ndef runcmd(\n    argv: Union[list[bytes], list[str]], timeout: Optional[float] = None, **ka: Any\n) -> tuple[int, str, str]:\n    kill = ka.pop(\"kill\", \"t\")  # [t]ree [m]ain [n]one\n    capture = ka.pop(\"capture\", 3)  # 0=none 1=stdout 2=stderr 3=both\n\n    sin: Optional[bytes] = ka.pop(\"sin\", None)\n    if sin:\n        ka[\"stdin\"] = sp.PIPE\n\n    cout = sp.PIPE if capture in [1, 3] else None\n    cerr = sp.PIPE if capture in [2, 3] else None\n    bout: bytes\n    berr: bytes\n\n    p = sp.Popen(argv, stdout=cout, stderr=cerr, **ka)\n    if not timeout or PY2:\n        bout, berr = p.communicate(sin)\n    else:\n        try:\n            bout, berr = p.communicate(sin, timeout=timeout)\n        except sp.TimeoutExpired:\n            if kill == \"n\":\n                return -18, \"\", \"\"  # SIGCONT; leave it be\n            elif kill == \"m\":\n                p.kill()\n            else:\n                killtree(p.pid)\n\n            try:\n                bout, berr = p.communicate(timeout=1)\n            except:\n                bout = b\"\"\n                berr = b\"\"\n\n    stdout = bout.decode(\"utf-8\", \"replace\") if cout else \"\"\n    stderr = berr.decode(\"utf-8\", \"replace\") if cerr else \"\"\n\n    rc: int = p.returncode\n    if rc is None:\n        rc = -14  # SIGALRM; failed to kill\n\n    return rc, stdout, stderr\n\n\ndef chkcmd(argv: Union[list[bytes], list[str]], **ka: Any) -> tuple[str, str]:\n    ok, sout, serr = runcmd(argv, **ka)\n    if ok != 0:\n        retchk(ok, argv, serr)\n        raise Exception(serr)\n\n    return sout, serr\n\n\ndef mchkcmd(argv: Union[list[bytes], list[str]], timeout: float = 10) -> None:\n    if PY2:\n        with open(os.devnull, \"wb\") as f:\n            rv = sp.call(argv, stdout=f, stderr=f)\n    else:\n        rv = sp.call(argv, stdout=sp.DEVNULL, stderr=sp.DEVNULL, timeout=timeout)\n\n    if rv:\n        raise sp.CalledProcessError(rv, (argv[0], b\"...\", argv[-1]))\n\n\ndef retchk(\n    rc: int,\n    cmd: Union[list[bytes], list[str]],\n    serr: str,\n    logger: Optional[\"NamedLogger\"] = None,\n    color: Union[int, str] = 0,\n    verbose: bool = False,\n) -> None:\n    if rc < 0:\n        rc = 128 - rc\n\n    if not rc or rc < 126 and not verbose:\n        return\n\n    s = None\n    if rc > 128:\n        try:\n            s = str(signal.Signals(rc - 128))\n        except:\n            pass\n    elif rc == 126:\n        s = \"invalid program\"\n    elif rc == 127:\n        s = \"program not found\"\n    elif verbose:\n        s = \"unknown\"\n    else:\n        s = \"invalid retcode\"\n\n    if s:\n        t = \"{} <{}>\".format(rc, s)\n    else:\n        t = str(rc)\n\n    try:\n        c = \" \".join([fsdec(x) for x in cmd])  # type: ignore\n    except:\n        c = str(cmd)\n\n    t = \"error {} from [{}]\".format(t, c)\n    if serr:\n        t += \"\\n\" + serr\n\n    if logger:\n        logger(t, color)\n    else:\n        raise Exception(t)\n\n\ndef _parsehook(\n    log: Optional[\"NamedLogger\"], cmd: str\n) -> tuple[bool, bool, bool, float, dict[str, Any], str]:\n    chk = False\n    fork = False\n    jtxt = False\n    wait = 0.0\n    tout = 0.0\n    kill = \"t\"\n    cap = 0\n    ocmd = cmd\n    while \",\" in cmd[:6]:\n        arg, cmd = cmd.split(\",\", 1)\n        if arg == \"c\":\n            chk = True\n        elif arg == \"f\":\n            fork = True\n        elif arg == \"j\":\n            jtxt = True\n        elif arg.startswith(\"w\"):\n            wait = float(arg[1:])\n        elif arg.startswith(\"t\"):\n            tout = float(arg[1:])\n        elif arg.startswith(\"c\"):\n            cap = int(arg[1:])  # 0=none 1=stdout 2=stderr 3=both\n        elif arg.startswith(\"k\"):\n            kill = arg[1:]  # [t]ree [m]ain [n]one\n        elif arg.startswith(\"i\"):\n            pass\n        else:\n            t = \"hook: invalid flag {} in {}\"\n            (log or print)(t.format(arg, ocmd))\n\n    env = os.environ.copy()\n    try:\n        if EXE:\n            raise Exception()\n\n        pypath = os.path.abspath(os.path.dirname(os.path.dirname(__file__)))\n        zsl = [str(pypath)] + [str(x) for x in sys.path if x]\n        pypath = str(os.pathsep.join(zsl))\n        env[\"PYTHONPATH\"] = pypath\n    except:\n        if not EXE:\n            raise\n\n    sp_ka = {\n        \"env\": env,\n        \"timeout\": tout,\n        \"kill\": kill,\n        \"capture\": cap,\n    }\n\n    if cmd.startswith(\"~\"):\n        cmd = os.path.expanduser(cmd)\n\n    return chk, fork, jtxt, wait, sp_ka, cmd\n\n\ndef runihook(\n    log: Optional[\"NamedLogger\"],\n    cmd: str,\n    vol: \"VFS\",\n    ups: list[tuple[str, int, int, str, str, str, int]],\n) -> bool:\n    ocmd = cmd\n    chk, fork, jtxt, wait, sp_ka, cmd = _parsehook(log, cmd)\n    bcmd = [sfsenc(cmd)]\n    if cmd.endswith(\".py\"):\n        bcmd = [sfsenc(pybin)] + bcmd\n\n    vps = [vjoin(*list(s3dec(x[3], x[4]))) for x in ups]\n    aps = [djoin(vol.realpath, x) for x in vps]\n    if jtxt:\n        # 0w 1mt 2sz 3rd 4fn 5ip 6at\n        ja = [\n            {\n                \"ap\": uncify(ap),  # utf8 for json\n                \"vp\": vp,\n                \"wark\": x[0][:16],\n                \"mt\": x[1],\n                \"sz\": x[2],\n                \"ip\": x[5],\n                \"at\": x[6],\n            }\n            for x, vp, ap in zip(ups, vps, aps)\n        ]\n        sp_ka[\"sin\"] = json.dumps(ja).encode(\"utf-8\", \"replace\")\n    else:\n        sp_ka[\"sin\"] = b\"\\n\".join(fsenc(x) for x in aps)\n\n    t0 = time.time()\n    if fork:\n        Daemon(runcmd, ocmd, [bcmd], ka=sp_ka)\n    else:\n        rc, v, err = runcmd(bcmd, **sp_ka)  # type: ignore\n        if chk and rc:\n            retchk(rc, bcmd, err, log, 5)\n            return False\n\n    wait -= time.time() - t0\n    if wait > 0:\n        time.sleep(wait)\n\n    return True\n\n\ndef _runhook(\n    log: Optional[\"NamedLogger\"],\n    cmd: str,\n    ap: str,\n    vp: str,\n    host: str,\n    uname: str,\n    mt: float,\n    sz: int,\n    ip: str,\n    at: float,\n    txt: str,\n) -> bool:\n    ocmd = cmd\n    chk, fork, jtxt, wait, sp_ka, cmd = _parsehook(log, cmd)\n    if jtxt:\n        ja = {\n            \"ap\": ap,\n            \"vp\": vp,\n            \"mt\": mt,\n            \"sz\": sz,\n            \"ip\": ip,\n            \"at\": at or time.time(),\n            \"host\": host,\n            \"user\": uname,\n            \"txt\": txt,\n        }\n        arg = json.dumps(ja)\n    else:\n        arg = txt or ap\n\n    acmd = [cmd, arg]\n    if cmd.endswith(\".py\"):\n        acmd = [pybin] + acmd\n\n    bcmd = [fsenc(x) if x == ap else sfsenc(x) for x in acmd]\n\n    t0 = time.time()\n    if fork:\n        Daemon(runcmd, ocmd, [bcmd], ka=sp_ka)\n    else:\n        rc, v, err = runcmd(bcmd, **sp_ka)  # type: ignore\n        if chk and rc:\n            retchk(rc, bcmd, err, log, 5)\n            return False\n\n    wait -= time.time() - t0\n    if wait > 0:\n        time.sleep(wait)\n\n    return True\n\n\ndef runhook(\n    log: Optional[\"NamedLogger\"],\n    cmds: list[str],\n    ap: str,\n    vp: str,\n    host: str,\n    uname: str,\n    mt: float,\n    sz: int,\n    ip: str,\n    at: float,\n    txt: str,\n) -> bool:\n    vp = vp.replace(\"\\\\\", \"/\")\n    for cmd in cmds:\n        try:\n            if not _runhook(log, cmd, ap, vp, host, uname, mt, sz, ip, at, txt):\n                return False\n        except Exception as ex:\n            (log or print)(\"hook: {}\".format(ex))\n            if \",c,\" in \",\" + cmd:\n                return False\n            break\n\n    return True\n\n\ndef loadpy(ap: str, hot: bool) -> Any:\n    \"\"\"\n    a nice can of worms capable of causing all sorts of bugs\n    depending on what other inconveniently named files happen\n    to be in the same folder\n    \"\"\"\n    if ap.startswith(\"~\"):\n        ap = os.path.expanduser(ap)\n\n    mdir, mfile = os.path.split(absreal(ap))\n    mname = mfile.rsplit(\".\", 1)[0]\n    sys.path.insert(0, mdir)\n\n    if PY2:\n        mod = __import__(mname)\n        if hot:\n            reload(mod)\n    else:\n        import importlib\n\n        mod = importlib.import_module(mname)\n        if hot:\n            importlib.reload(mod)\n\n    sys.path.remove(mdir)\n    return mod\n\n\ndef gzip_orig_sz(fn: str) -> int:\n    with open(fsenc(fn), \"rb\") as f:\n        f.seek(-4, 2)\n        rv = f.read(4)\n        return sunpack(b\"I\", rv)[0]  # type: ignore\n\n\ndef align_tab(lines: list[str]) -> list[str]:\n    rows = []\n    ncols = 0\n    for ln in lines:\n        row = [x for x in ln.split(\" \") if x]\n        ncols = max(ncols, len(row))\n        rows.append(row)\n\n    lens = [0] * ncols\n    for row in rows:\n        for n, col in enumerate(row):\n            lens[n] = max(lens[n], len(col))\n\n    return [\"\".join(x.ljust(y + 2) for x, y in zip(row, lens)) for row in rows]\n\n\ndef visual_length(txt: str) -> int:\n    # from r0c\n    eoc = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n    clen = 0\n    pend = None\n    counting = True\n    for ch in txt:\n\n        # escape sequences can never contain ESC;\n        # treat pend as regular text if so\n        if ch == \"\\033\" and pend:\n            clen += len(pend)\n            counting = True\n            pend = None\n\n        if not counting:\n            if ch in eoc:\n                counting = True\n        else:\n            if pend:\n                pend += ch\n                if pend.startswith(\"\\033[\"):\n                    counting = False\n                else:\n                    clen += len(pend)\n                    counting = True\n                pend = None\n            else:\n                if ch == \"\\033\":\n                    pend = \"{0}\".format(ch)\n                else:\n                    co = ord(ch)\n                    # the safe parts of latin1 and cp437 (no greek stuff)\n                    if (\n                        co < 0x100  # ascii + lower half of latin1\n                        or (co >= 0x2500 and co <= 0x25A0)  # box drawings\n                        or (co >= 0x2800 and co <= 0x28FF)  # braille\n                    ):\n                        clen += 1\n                    else:\n                        # assume moonrunes or other double-width\n                        clen += 2\n    return clen\n\n\ndef wrap(txt: str, maxlen: int, maxlen2: int) -> list[str]:\n    # from r0c\n    words = re.sub(r\"([, ])\", r\"\\1\\n\", txt.rstrip()).split(\"\\n\")\n    pad = maxlen - maxlen2\n    ret = []\n    for word in words:\n        if len(word) * 2 < maxlen or visual_length(word) < maxlen:\n            ret.append(word)\n        else:\n            while visual_length(word) >= maxlen:\n                ret.append(word[: maxlen - 1] + \"-\")\n                word = word[maxlen - 1 :]\n            if word:\n                ret.append(word)\n\n    words = ret\n    ret = []\n    ln = \"\"\n    spent = 0\n    for word in words:\n        wl = visual_length(word)\n        if spent + wl > maxlen:\n            ret.append(ln)\n            maxlen = maxlen2\n            spent = 0\n            ln = \" \" * pad\n        ln += word\n        spent += wl\n    if ln:\n        ret.append(ln)\n\n    return ret\n\n\ndef termsize() -> tuple[int, int]:\n    # from hashwalk\n    env = os.environ\n\n    def ioctl_GWINSZ(fd: int) -> Optional[tuple[int, int]]:\n        try:\n            cr = sunpack(b\"hh\", fcntl.ioctl(fd, termios.TIOCGWINSZ, b\"AAAA\"))\n            return cr[::-1]\n        except:\n            return None\n\n    cr = ioctl_GWINSZ(0) or ioctl_GWINSZ(1) or ioctl_GWINSZ(2)\n    if not cr:\n        try:\n            fd = os.open(os.ctermid(), os.O_RDONLY)\n            cr = ioctl_GWINSZ(fd)\n            os.close(fd)\n        except:\n            pass\n\n    try:\n        return cr or (int(env[\"COLUMNS\"]), int(env[\"LINES\"]))\n    except:\n        return 80, 25\n\n\ndef hidedir(dp) -> None:\n    if ANYWIN:\n        try:\n            k32 = ctypes.WinDLL(\"kernel32\")\n            attrs = k32.GetFileAttributesW(dp)\n            if attrs >= 0:\n                k32.SetFileAttributesW(dp, attrs | 2)\n        except:\n            pass\n\n\nclass Pebkac(Exception):\n    def __init__(self, code: int, msg: Optional[str] = None) -> None:\n        super(Pebkac, self).__init__(msg or HTTPCODE[code])\n        self.code = code\n\n    def __repr__(self) -> str:\n        return \"Pebkac({}, {})\".format(self.code, repr(self.args))\n"], "filenames": ["copyparty/httpcli.py", "copyparty/httpsrv.py", "copyparty/util.py"], "buggy_code_start_loc": [339, 6, 173], "buggy_code_end_loc": [3081, 140, 173], "fixing_code_start_loc": [340, 7, 174], "fixing_code_end_loc": [3108, 144, 175], "type": "CWE-79", "message": "copyparty is file server software. Prior to version 1.8.7, the application contains a reflected cross-site scripting via URL-parameter `?k304=...` and `?setck=...`. The worst-case outcome of this is being able to move or delete existing files on the server, or upload new files, using the account of the person who clicks the malicious link. It is recommended to change the passwords of one's copyparty accounts, unless one have inspected one's logs and found no trace of attacks. Version 1.8.7 contains a patch for the issue.", "other": {"cve": {"id": "CVE-2023-38501", "sourceIdentifier": "security-advisories@github.com", "published": "2023-07-25T22:15:10.600", "lastModified": "2023-08-02T19:50:56.147", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "copyparty is file server software. Prior to version 1.8.7, the application contains a reflected cross-site scripting via URL-parameter `?k304=...` and `?setck=...`. The worst-case outcome of this is being able to move or delete existing files on the server, or upload new files, using the account of the person who clicks the malicious link. It is recommended to change the passwords of one's copyparty accounts, unless one have inspected one's logs and found no trace of attacks. Version 1.8.7 contains a patch for the issue."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:L/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "CHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 6.1, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 2.7}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:U/C:L/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 6.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.4}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-79"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:copyparty_project:copyparty:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.8.7", "matchCriteriaId": "FA6436E9-0F22-49D5-B344-7EE9371CE469"}]}]}], "references": [{"url": "http://packetstormsecurity.com/files/173821/Copyparty-1.8.6-Cross-Site-Scripting.html", "source": "security-advisories@github.com", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://github.com/9001/copyparty/commit/007d948cb982daa05bc6619cd20ee55b7e834c38", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/9001/copyparty/security/advisories/GHSA-f54q-j679-p9hh", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/9001/copyparty/commit/007d948cb982daa05bc6619cd20ee55b7e834c38"}}
{"buggy_code": ["/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n#include \"tensorflow/lite/micro/kernels/kernel_util.h\"\n#include \"tensorflow/lite/micro/micro_utils.h\"\n\nnamespace tflite {\nnamespace {\n\nconstexpr int kParams = 0;\nconstexpr int kIndices = 1;\nconstexpr int kOutputTensor = 0;\nconstexpr int MAX_INDICES_ND = 5;\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  MicroContext* micro_context = GetMicroContext(context);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  TfLiteTensor* params = micro_context->AllocateTempInputTensor(node, kParams);\n  TF_LITE_ENSURE(context, params != nullptr);\n  TfLiteTensor* indices =\n      micro_context->AllocateTempInputTensor(node, kIndices);\n  TF_LITE_ENSURE(context, indices != nullptr);\n  TfLiteTensor* output =\n      micro_context->AllocateTempOutputTensor(node, kOutputTensor);\n  TF_LITE_ENSURE(context, output != nullptr);\n\n  switch (params->type) {\n    case kTfLiteFloat32:\n    case kTfLiteInt8:\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Params of type '%s' are not supported by gather_nd.\",\n                         TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n      break;\n  }\n  switch (indices->type) {\n    case kTfLiteInt32:\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Indices of type '%s' are not supported by gather_nd.\",\n                         TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n\n  const int params_rank = NumDimensions(params);\n  const int indices_rank = NumDimensions(indices);\n  const int indices_nd = SizeOfDimension(indices, indices_rank - 1);\n  if (params_rank < 1) {\n    TF_LITE_KERNEL_LOG(context, \"Params must be at least a vector.\");\n    return kTfLiteError;\n  }\n  if (indices_rank < 1) {\n    TF_LITE_KERNEL_LOG(context, \"Indices must be at least a vector.\");\n    return kTfLiteError;\n  }\n  if (indices_nd > params_rank) {\n    TF_LITE_KERNEL_LOG(\n        context, \"Index innermost dimension length must be <= params rank.\");\n    return kTfLiteError;\n  }\n  if (indices_nd > MAX_INDICES_ND) {\n    TF_LITE_KERNEL_LOG(context,\n                       \"Index innermost dimension length must not exceed %d.\",\n                       MAX_INDICES_ND);\n    return kTfLiteError;\n  }\n\n  // Assign to output the input type.\n  output->type = params->type;\n\n  // TFLM gather_nd does not create the output tensor, but it needs to ensure\n  // that the output shape is correct. The result shape is\n  // indices.shape[:-1] + params.shape[indices.shape[-1]:]\n  TfLiteIntArray* output_shape = output->dims;\n  int output_index = 0;\n  for (int i = 0; i < indices_rank - 1; ++i) {\n    output_shape->data[output_index++] = indices->dims->data[i];\n  }\n  for (int i = indices_nd; i < params_rank; ++i) {\n    output_shape->data[output_index++] = params->dims->data[i];\n  }\n  output_shape->size = output_index;\n\n  micro_context->DeallocateTempTfLiteTensor(params);\n  micro_context->DeallocateTempTfLiteTensor(indices);\n  micro_context->DeallocateTempTfLiteTensor(output);\n  return kTfLiteOk;\n}\n\ntemplate <typename ParamsT, typename IndicesT>\nTfLiteStatus GatherNd(const TfLiteEvalTensor* params,\n                      const TfLiteEvalTensor* indices,\n                      TfLiteEvalTensor* output) {\n  const int indices_dims = indices->dims->size;\n  const int indices_nd = indices->dims->data[indices_dims - 1];\n  const int params_dims = params->dims->size;\n  const IndicesT* index_data = tflite::micro::GetTensorData<IndicesT>(indices);\n  const ParamsT* param_data = tflite::micro::GetTensorData<ParamsT>(params);\n  ParamsT* output_data = tflite::micro::GetTensorData<ParamsT>(output);\n\n  int n_slices = 1;\n  for (int i = 0; i < indices_dims - 1; ++i) {\n    n_slices *= indices->dims->data[i];\n  }\n\n  // If indices[-1] == params.rank, fetch single elements.\n  // If indices[-1] < params.rank, fetch slices.\n  int slice_size = 1;\n  for (int i = indices_nd; i < params_dims; ++i) {\n    slice_size *= params->dims->data[i];\n  }\n\n  int remain_flat_size = ElementCount(*params->dims);\n\n  // Number of elements per dimension\n  int dims_to_count[MAX_INDICES_ND];\n  for (int i = 0; i < indices_nd; ++i) {\n    dims_to_count[i] = remain_flat_size / params->dims->data[i];\n    remain_flat_size = dims_to_count[i];\n  }\n\n  for (int i = 0; i < n_slices; ++i) {\n    int from_pos = 0;\n    for (int j = 0; j < indices_nd; ++j) {\n      int offset = i * indices_nd + j;\n      IndicesT index = index_data[offset];\n      from_pos += index * dims_to_count[j];\n    }\n    std::memcpy(output_data + i * slice_size, param_data + from_pos,\n                sizeof(ParamsT) * slice_size);\n  }\n  return kTfLiteOk;\n}\n\ntemplate <typename IndicesT>\nTfLiteStatus EvalGatherNd(TfLiteContext* context,\n                          const TfLiteEvalTensor* params,\n                          const TfLiteEvalTensor* indices,\n                          TfLiteEvalTensor* output) {\n  switch (params->type) {\n    case kTfLiteFloat32:\n      return GatherNd<float, IndicesT>(params, indices, output);\n      break;\n    case kTfLiteInt8:\n      return GatherNd<int8_t, IndicesT>(params, indices, output);\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Params type '%s' are not supported by gather_nd.\",\n                         TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteEvalTensor* params =\n      tflite::micro::GetEvalInput(context, node, kParams);\n  const TfLiteEvalTensor* indices =\n      tflite::micro::GetEvalInput(context, node, kIndices);\n  TfLiteEvalTensor* output =\n      tflite::micro::GetEvalOutput(context, node, kOutputTensor);\n\n  switch (indices->type) {\n    case kTfLiteInt32:\n      return EvalGatherNd<int32_t>(context, params, indices, output);\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Indices of type '%s' are not supported by gather_nd.\",\n                         TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n}\n}  // namespace\n\nTfLiteRegistration Register_GATHER_ND() {\n  return tflite::micro::RegisterOp(nullptr, Prepare, Eval);\n}\n\n}  // namespace tflite\n", "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/micro/all_ops_resolver.h\"\n#include \"tensorflow/lite/micro/kernels/kernel_runner.h\"\n#include \"tensorflow/lite/micro/test_helpers.h\"\n#include \"tensorflow/lite/micro/testing/micro_test.h\"\n\nnamespace tflite {\nnamespace testing {\nnamespace {\n\ntemplate <typename ParamType, typename IndexType>\nvoid TestGatherNd(int* param_dims, const ParamType* param_data, int* index_dims,\n                  const IndexType* index_data, int* output_dims,\n                  ParamType* output_data,\n                  const ParamType* expected_output_data) {\n  TfLiteIntArray* pdims = IntArrayFromInts(param_dims);\n  TfLiteIntArray* idims = IntArrayFromInts(index_dims);\n  TfLiteIntArray* odims = IntArrayFromInts(output_dims);\n\n  constexpr int inputs_size = 2;\n  constexpr int outputs_size = 1;\n  constexpr int tensors_size = inputs_size + outputs_size;\n  TfLiteTensor tensors[tensors_size] = {\n      CreateTensor(param_data, pdims),\n      CreateTensor(index_data, idims),\n      CreateTensor(output_data, odims),\n  };\n  int inputs_array_data[] = {2, 0, 1};\n  TfLiteIntArray* inputs_array = IntArrayFromInts(inputs_array_data);\n  int outputs_array_data[] = {1, 2};\n  TfLiteIntArray* outputs_array = IntArrayFromInts(outputs_array_data);\n\n  const TfLiteRegistration registration = Register_GATHER_ND();\n  micro::KernelRunner runner(registration, tensors, tensors_size, inputs_array,\n                             outputs_array, /*builtin_data=*/nullptr);\n  TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, runner.InitAndPrepare());\n  TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, runner.Invoke());\n\n  // The output tensor's data and shape have been updated by the kernel.\n  TfLiteTensor* actual_output_tensor = &tensors[2];\n  TfLiteIntArray* actual_output_dims = actual_output_tensor->dims;\n  const int output_size = ElementCount(*actual_output_dims);\n  for (int i = 0; i < output_size; ++i) {\n    TF_LITE_MICRO_EXPECT_EQ(expected_output_data[i], output_data[i]);\n  }\n}\n\n}  // namespace\n}  // namespace testing\n}  // namespace tflite\n\nTF_LITE_MICRO_TESTS_BEGIN\n\nTF_LITE_MICRO_TEST(GatherNd_ElementIndexingIntoMatrix) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 0, 1, 1};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {1.1, 2.2};\n  float output_data[2];\n  int output_dims[] = {1, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_SliceIndexingIntoMatrix) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {2, 2, 1};\n  const int32_t index_data[] = {1, 0};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {2.1, 2.2, 1.1, 1.2};\n  float output_data[4];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoMatrix1) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {3, 2, 1, 1};\n  const int32_t index_data[] = {1, 0};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {2.1, 2.2, 1.1, 1.2};\n  float output_data[4];\n  int output_dims[] = {3, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoMatrix2) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {3, 2, 1, 2};\n  const int32_t index_data[] = {0, 0, 1, 1};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {1.1, 2.2};\n  float output_data[2];\n  int output_dims[] = {3, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_DuplicateIndexingIntoMatrix) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 0, 0, 0};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {1.1, 1.1};\n  float output_data[2];\n  int output_dims[] = {1, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_ElementIndexingIntoRank3Tensor) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 1, 2, 3};\n  const int32_t index_data[] = {0, 0, 1, 1, 1, 0};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-1.2, -4.1};\n  float output_data[2];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_SliceIndexingIntoRank3Tensor) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {2, 2, 1};\n  const int32_t index_data[] = {0, 2};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {1.1, -1.2, 1.3, -2.1, 2.2,  2.3,\n                               5.1, -5.2, 5.3, 6.1,  -6.2, 6.3};\n  float output_data[12];\n  int output_dims[] = {3, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoRank3Tensor1) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 2, 1, 3};\n  const int32_t index_data[] = {0, 0, 1, 1, 1, 0};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-1.2, -4.1};\n  float output_data[2];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoRank3Tensor2) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 3, 1, 1};\n  const int32_t index_data[] = {1, 2, 0};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,\n                               5.1, -5.2, 5.3,  6.1,  -6.2, 6.3,\n                               1.1, -1.2, 1.3,  -2.1, 2.2,  2.3};\n  float output_data[18];\n  int output_dims[] = {4, 0, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoRank3Tensor3) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 2, 2, 2};\n  const int32_t index_data[] = {0, 1, 1, 0, 0, 0, 2, 1};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-2.1, 2.2,  2.3, 3.1, 3.2,  -3.3,\n                               1.1,  -1.2, 1.3, 6.1, -6.2, 6.3};\n  float output_data[12];\n  int output_dims[] = {3, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoRank3Tensor4) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 2, 2, 3};\n  const int32_t index_data[] = {0, 0, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-1.2, 3.2, 4.3, 6.3};\n  float output_data[4];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_DuplicateIndexingIntoRank3Tensor) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 1, 0, 1};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-2.1, 2.2, 2.3, -2.1, 2.2, 2.3};\n  float output_data[6];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_Float32Int32) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 1, 1, 0};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-2.1, 2.2, 2.3, 3.1, 3.2, -3.3};\n  float output_data[6];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_Int8Int32) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 1, 1, 0};\n  const int8_t input_data[] = {1, -1, 1,  -2, 2,  2,  //\n                               3, 3,  -3, -4, -4, 4,  //\n                               5, -5, 5,  6,  -6, 6};\n  const int8_t golden_data[] = {-2, 2, 2, 3, 3, -3};\n  int8_t output_data[6];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<int8_t, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TESTS_END\n"], "fixing_code": ["/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/kernels/internal/tensor_ctypes.h\"\n#include \"tensorflow/lite/kernels/kernel_util.h\"\n#include \"tensorflow/lite/micro/kernels/kernel_util.h\"\n#include \"tensorflow/lite/micro/micro_utils.h\"\n\nnamespace tflite {\nnamespace {\n\nconstexpr int kParams = 0;\nconstexpr int kIndices = 1;\nconstexpr int kOutputTensor = 0;\nconstexpr int MAX_INDICES_ND = 5;\n\nTfLiteStatus Prepare(TfLiteContext* context, TfLiteNode* node) {\n  MicroContext* micro_context = GetMicroContext(context);\n\n  TF_LITE_ENSURE_EQ(context, NumInputs(node), 2);\n  TF_LITE_ENSURE_EQ(context, NumOutputs(node), 1);\n\n  TfLiteTensor* params = micro_context->AllocateTempInputTensor(node, kParams);\n  TF_LITE_ENSURE(context, params != nullptr);\n  TfLiteTensor* indices =\n      micro_context->AllocateTempInputTensor(node, kIndices);\n  TF_LITE_ENSURE(context, indices != nullptr);\n  TfLiteTensor* output =\n      micro_context->AllocateTempOutputTensor(node, kOutputTensor);\n  TF_LITE_ENSURE(context, output != nullptr);\n\n  switch (params->type) {\n    case kTfLiteFloat32:\n    case kTfLiteInt8:\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Params of type '%s' are not supported by gather_nd.\",\n                         TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n      break;\n  }\n  switch (indices->type) {\n    case kTfLiteInt32:\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Indices of type '%s' are not supported by gather_nd.\",\n                         TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n\n  const int params_rank = NumDimensions(params);\n  const int indices_rank = NumDimensions(indices);\n  const int indices_nd = SizeOfDimension(indices, indices_rank - 1);\n  if (params_rank < 1) {\n    TF_LITE_KERNEL_LOG(context, \"Params must be at least a vector.\");\n    return kTfLiteError;\n  }\n  if (indices_rank < 1) {\n    TF_LITE_KERNEL_LOG(context, \"Indices must be at least a vector.\");\n    return kTfLiteError;\n  }\n  if (indices_nd > params_rank) {\n    TF_LITE_KERNEL_LOG(\n        context, \"Index innermost dimension length must be <= params rank.\");\n    return kTfLiteError;\n  }\n  if (indices_nd > MAX_INDICES_ND) {\n    TF_LITE_KERNEL_LOG(context,\n                       \"Index innermost dimension length must not exceed %d.\",\n                       MAX_INDICES_ND);\n    return kTfLiteError;\n  }\n\n  // Assign to output the input type.\n  output->type = params->type;\n\n  // TFLM gather_nd does not create the output tensor, but it needs to ensure\n  // that the output shape is correct. The result shape is\n  // indices.shape[:-1] + params.shape[indices.shape[-1]:]\n  TfLiteIntArray* output_shape = output->dims;\n  int output_index = 0;\n  for (int i = 0; i < indices_rank - 1; ++i) {\n    output_shape->data[output_index++] = indices->dims->data[i];\n  }\n  for (int i = indices_nd; i < params_rank; ++i) {\n    output_shape->data[output_index++] = params->dims->data[i];\n  }\n  output_shape->size = output_index;\n\n  micro_context->DeallocateTempTfLiteTensor(params);\n  micro_context->DeallocateTempTfLiteTensor(indices);\n  micro_context->DeallocateTempTfLiteTensor(output);\n  return kTfLiteOk;\n}\n\ntemplate <typename ParamsT, typename IndicesT>\nTfLiteStatus GatherNd(const TfLiteEvalTensor* params,\n                      const TfLiteEvalTensor* indices,\n                      TfLiteEvalTensor* output) {\n  const int indices_dims = indices->dims->size;\n  const int indices_nd = indices->dims->data[indices_dims - 1];\n  const int params_dims = params->dims->size;\n  const IndicesT* index_data = tflite::micro::GetTensorData<IndicesT>(indices);\n  const ParamsT* param_data = tflite::micro::GetTensorData<ParamsT>(params);\n  ParamsT* output_data = tflite::micro::GetTensorData<ParamsT>(output);\n\n  int n_slices = 1;\n  for (int i = 0; i < indices_dims - 1; ++i) {\n    n_slices *= indices->dims->data[i];\n  }\n\n  // If indices[-1] == params.rank, fetch single elements.\n  // If indices[-1] < params.rank, fetch slices.\n  int slice_size = 1;\n  for (int i = indices_nd; i < params_dims; ++i) {\n    slice_size *= params->dims->data[i];\n  }\n\n  int params_flat_size = ElementCount(*params->dims);\n  int remain_flat_size = params_flat_size;\n\n  // Number of elements per dimension\n  int dims_to_count[MAX_INDICES_ND];\n  for (int i = 0; i < indices_nd; ++i) {\n    dims_to_count[i] = remain_flat_size / params->dims->data[i];\n    remain_flat_size = dims_to_count[i];\n  }\n\n  for (int i = 0; i < n_slices; ++i) {\n    int from_pos = 0;\n    for (int j = 0; j < indices_nd; ++j) {\n      int offset = i * indices_nd + j;\n      IndicesT index = index_data[offset];\n      from_pos += index * dims_to_count[j];\n    }\n    if (from_pos < 0 || from_pos + slice_size > params_flat_size) {\n      return kTfLiteError;\n    }\n    std::memcpy(output_data + i * slice_size, param_data + from_pos,\n                sizeof(ParamsT) * slice_size);\n  }\n  return kTfLiteOk;\n}\n\ntemplate <typename IndicesT>\nTfLiteStatus EvalGatherNd(TfLiteContext* context,\n                          const TfLiteEvalTensor* params,\n                          const TfLiteEvalTensor* indices,\n                          TfLiteEvalTensor* output) {\n  TfLiteStatus status = kTfLiteError;\n  switch (params->type) {\n    case kTfLiteFloat32:\n      status = GatherNd<float, IndicesT>(params, indices, output);\n      break;\n    case kTfLiteInt8:\n      status = GatherNd<int8_t, IndicesT>(params, indices, output);\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Params type '%s' are not supported by gather_nd.\",\n                         TfLiteTypeGetName(params->type));\n      return kTfLiteError;\n  }\n  if (status != kTfLiteOk) {\n    TF_LITE_KERNEL_LOG(context, \"gather_nd index out of bounds\");\n  }\n  return status;\n}\n\nTfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  const TfLiteEvalTensor* params =\n      tflite::micro::GetEvalInput(context, node, kParams);\n  const TfLiteEvalTensor* indices =\n      tflite::micro::GetEvalInput(context, node, kIndices);\n  TfLiteEvalTensor* output =\n      tflite::micro::GetEvalOutput(context, node, kOutputTensor);\n\n  switch (indices->type) {\n    case kTfLiteInt32:\n      return EvalGatherNd<int32_t>(context, params, indices, output);\n      break;\n    default:\n      TF_LITE_KERNEL_LOG(context,\n                         \"Indices of type '%s' are not supported by gather_nd.\",\n                         TfLiteTypeGetName(indices->type));\n      return kTfLiteError;\n  }\n}\n}  // namespace\n\nTfLiteRegistration Register_GATHER_ND() {\n  return tflite::micro::RegisterOp(nullptr, Prepare, Eval);\n}\n\n}  // namespace tflite\n", "/* Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n#include \"tensorflow/lite/c/common.h\"\n#include \"tensorflow/lite/micro/all_ops_resolver.h\"\n#include \"tensorflow/lite/micro/kernels/kernel_runner.h\"\n#include \"tensorflow/lite/micro/test_helpers.h\"\n#include \"tensorflow/lite/micro/testing/micro_test.h\"\n\nnamespace tflite {\nnamespace testing {\nnamespace {\n\ntemplate <typename ParamType, typename IndexType>\nvoid TestGatherNd(int* param_dims, const ParamType* param_data, int* index_dims,\n                  const IndexType* index_data, int* output_dims,\n                  ParamType* output_data, const ParamType* expected_output_data,\n                  const TfLiteStatus expected_status = kTfLiteOk) {\n  TfLiteIntArray* pdims = IntArrayFromInts(param_dims);\n  TfLiteIntArray* idims = IntArrayFromInts(index_dims);\n  TfLiteIntArray* odims = IntArrayFromInts(output_dims);\n\n  constexpr int inputs_size = 2;\n  constexpr int outputs_size = 1;\n  constexpr int tensors_size = inputs_size + outputs_size;\n  TfLiteTensor tensors[tensors_size] = {\n      CreateTensor(param_data, pdims),\n      CreateTensor(index_data, idims),\n      CreateTensor(output_data, odims),\n  };\n  int inputs_array_data[] = {2, 0, 1};\n  TfLiteIntArray* inputs_array = IntArrayFromInts(inputs_array_data);\n  int outputs_array_data[] = {1, 2};\n  TfLiteIntArray* outputs_array = IntArrayFromInts(outputs_array_data);\n\n  const TfLiteRegistration registration = Register_GATHER_ND();\n  micro::KernelRunner runner(registration, tensors, tensors_size, inputs_array,\n                             outputs_array, /*builtin_data=*/nullptr);\n  TF_LITE_MICRO_EXPECT_EQ(kTfLiteOk, runner.InitAndPrepare());\n  TF_LITE_MICRO_EXPECT_EQ(expected_status, runner.Invoke());\n\n  if (expected_status == kTfLiteOk) {\n    // The output tensor's data and shape have been updated by the kernel.\n    TfLiteTensor* actual_output_tensor = &tensors[2];\n    TfLiteIntArray* actual_output_dims = actual_output_tensor->dims;\n    const int output_size = ElementCount(*actual_output_dims);\n    for (int i = 0; i < output_size; ++i) {\n      TF_LITE_MICRO_EXPECT_EQ(expected_output_data[i], output_data[i]);\n    }\n  }\n}\n\n}  // namespace\n}  // namespace testing\n}  // namespace tflite\n\nTF_LITE_MICRO_TESTS_BEGIN\n\nTF_LITE_MICRO_TEST(GatherNd_ElementIndexingIntoMatrix) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 0, 1, 1};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {1.1, 2.2};\n  float output_data[2];\n  int output_dims[] = {1, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_SliceIndexingIntoMatrix) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {2, 2, 1};\n  const int32_t index_data[] = {1, 0};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {2.1, 2.2, 1.1, 1.2};\n  float output_data[4];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoMatrix1) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {3, 2, 1, 1};\n  const int32_t index_data[] = {1, 0};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {2.1, 2.2, 1.1, 1.2};\n  float output_data[4];\n  int output_dims[] = {3, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoMatrix2) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {3, 2, 1, 2};\n  const int32_t index_data[] = {0, 0, 1, 1};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {1.1, 2.2};\n  float output_data[2];\n  int output_dims[] = {3, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_DuplicateIndexingIntoMatrix) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 0, 0, 0};\n  const float input_data[] = {1.1, 1.2, 2.1, 2.2};\n  const float golden_data[] = {1.1, 1.1};\n  float output_data[2];\n  int output_dims[] = {1, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_ElementIndexingIntoRank3Tensor) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 1, 2, 3};\n  const int32_t index_data[] = {0, 0, 1, 1, 1, 0};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-1.2, -4.1};\n  float output_data[2];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_SliceIndexingIntoRank3Tensor) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {2, 2, 1};\n  const int32_t index_data[] = {0, 2};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {1.1, -1.2, 1.3, -2.1, 2.2,  2.3,\n                               5.1, -5.2, 5.3, 6.1,  -6.2, 6.3};\n  float output_data[12];\n  int output_dims[] = {3, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoRank3Tensor1) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 2, 1, 3};\n  const int32_t index_data[] = {0, 0, 1, 1, 1, 0};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-1.2, -4.1};\n  float output_data[2];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoRank3Tensor2) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 3, 1, 1};\n  const int32_t index_data[] = {1, 2, 0};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,\n                               5.1, -5.2, 5.3,  6.1,  -6.2, 6.3,\n                               1.1, -1.2, 1.3,  -2.1, 2.2,  2.3};\n  float output_data[18];\n  int output_dims[] = {4, 0, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoRank3Tensor3) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 2, 2, 2};\n  const int32_t index_data[] = {0, 1, 1, 0, 0, 0, 2, 1};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-2.1, 2.2,  2.3, 3.1, 3.2,  -3.3,\n                               1.1,  -1.2, 1.3, 6.1, -6.2, 6.3};\n  float output_data[12];\n  int output_dims[] = {3, 0, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_BatchedIndexingIntoRank3Tensor4) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {3, 2, 2, 3};\n  const int32_t index_data[] = {0, 0, 1, 1, 0, 1, 1, 1, 2, 2, 1, 2};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-1.2, 3.2, 4.3, 6.3};\n  float output_data[4];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_DuplicateIndexingIntoRank3Tensor) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 1, 0, 1};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-2.1, 2.2, 2.3, -2.1, 2.2, 2.3};\n  float output_data[6];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_Float32Int32) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 1, 1, 0};\n  const float input_data[] = {1.1, -1.2, 1.3,  -2.1, 2.2,  2.3,  //\n                              3.1, 3.2,  -3.3, -4.1, -4.2, 4.3,  //\n                              5.1, -5.2, 5.3,  6.1,  -6.2, 6.3};\n  const float golden_data[] = {-2.1, 2.2, 2.3, 3.1, 3.2, -3.3};\n  float output_data[6];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<float, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_Int8Int32) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {3, 3, 2, 3};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 1, 1, 0};\n  const int8_t input_data[] = {1, -1, 1,  -2, 2,  2,  //\n                               3, 3,  -3, -4, -4, 4,  //\n                               5, -5, 5,  6,  -6, 6};\n  const int8_t golden_data[] = {-2, 2, 2, 3, 3, -3};\n  int8_t output_data[6];\n  int output_dims[] = {2, 0, 0};\n  tflite::testing::TestGatherNd<int8_t, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, output_data,\n      golden_data);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_ReadOOB) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, 1, 2, 0};\n  const int8_t input_data[] = {1, -1, 1, -2};\n  int8_t output_data;\n  int output_dims[] = {1, 0, 0};\n  tflite::testing::TestGatherNd<int8_t, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, &output_data,\n      nullptr, kTfLiteError);\n}\n\nTF_LITE_MICRO_TEST(GatherNd_ReadOOBNegative) {\n  // For input_dims[], index_dims[], or output_dims[], element 0 is the\n  // number of dimensions in that array, not the actual dimension data.\n  int input_dims[] = {2, 2, 2};\n  int index_dims[] = {2, 2, 2};\n  const int32_t index_data[] = {0, -1, 1, 0};\n  const int8_t input_data[] = {1, -1, 1, -2};\n  int8_t output_data;\n  int output_dims[] = {1, 0, 0};\n  tflite::testing::TestGatherNd<int8_t, int32_t>(\n      input_dims, input_data, index_dims, index_data, output_dims, &output_data,\n      nullptr, kTfLiteError);\n}\n\nTF_LITE_MICRO_TESTS_END\n"], "filenames": ["tensorflow/lite/micro/kernels/gather_nd.cc", "tensorflow/lite/micro/kernels/gather_nd_test.cc"], "buggy_code_start_loc": [134, 29], "buggy_code_end_loc": [173, 300], "fixing_code_start_loc": [134, 29], "fixing_code_end_loc": [183, 331], "type": "CWE-125", "message": "TensorFlow is an open source platform for machine learning. The `GatherNd` function takes arguments that determine the sizes of inputs and outputs. If the inputs given are greater than or equal to the sizes of the outputs, an out-of-bounds memory read or a crash is triggered. This issue has been patched in GitHub commit 4142e47e9e31db481781b955ed3ff807a781b494. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue.", "other": {"cve": {"id": "CVE-2022-35938", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-16T20:15:10.177", "lastModified": "2022-09-20T16:32:50.690", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an open source platform for machine learning. The `GatherNd` function takes arguments that determine the sizes of inputs and outputs. If the inputs given are greater than or equal to the sizes of the outputs, an out-of-bounds memory read or a crash is triggered. This issue has been patched in GitHub commit 4142e47e9e31db481781b955ed3ff807a781b494. The fix will be included in TensorFlow 2.10.0. We will also cherrypick this commit on TensorFlow 2.9.1, TensorFlow 2.8.1, and TensorFlow 2.7.2, as these are also affected and still in supported range. There are no known workarounds for this issue."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto para el aprendizaje autom\u00e1tico. La funci\u00f3n \"GatherNd\" toma argumentos que determinan el tama\u00f1o de las entradas y salidas. Si las entradas dadas son mayores o iguales a los tama\u00f1os de las salidas, es desencadenada una lectura de memoria fuera de los l\u00edmites o un bloqueo. Este problema ha sido corregido en el commit 4142e47e9e31db481781b955ed3ff807a781b494 de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.10.0. Tambi\u00e9n seleccionaremos este compromiso en TensorFlow versi\u00f3n 2.9.1, TensorFlow versi\u00f3n 2.8.1, y TensorFlow versi\u00f3n 2.7.2, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango admitido. No se presentan mitigaciones conocidas para este problema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 9.1, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.2}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:H/PR:N/UI:N/S:U/C:L/I:L/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "HIGH", "baseScore": 7.0, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 4.7}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.7.0", "versionEndExcluding": "2.7.2", "matchCriteriaId": "C4DFBF2D-5283-42F6-8800-D653BFA5CE82"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.8.0", "versionEndExcluding": "2.8.1", "matchCriteriaId": "0F9D273D-02DC-441E-AA91-EAC8DEAA4B44"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.9.0", "versionEndExcluding": "2.9.1", "matchCriteriaId": "FE4F8A81-6CC2-4F7F-9602-C170FDD926E7"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc0:*:*:*:*:*:*", "matchCriteriaId": "1DBFBCE2-0A01-4575-BE45-6775ABFB8B28"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc1:*:*:*:*:*:*", "matchCriteriaId": "89806CF9-E423-4CA6-A01A-8175C260CB24"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc2:*:*:*:*:*:*", "matchCriteriaId": "F2B80690-A257-4E16-BD27-9AE045BC56ED"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.10:rc3:*:*:*:*:*:*", "matchCriteriaId": "F335F9A4-5AB8-4E53-BC18-E01F7C653E5E"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-3m3g-pf5v-5hpj", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tflite-micro/blob/1bc98621180a350eb4e8d3318ea8e228c7559b37/tensorflow/lite/micro/kernels/gather_nd.cc#L143-L154", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tflite-micro/commit/4142e47e9e31db481781b955ed3ff807a781b494", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tflite-micro/commit/4142e47e9e31db481781b955ed3ff807a781b494"}}
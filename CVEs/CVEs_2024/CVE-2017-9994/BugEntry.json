{"buggy_code": ["/*\n * VP7/VP8 compatible video decoder\n *\n * Copyright (C) 2010 David Conrad\n * Copyright (C) 2010 Ronald S. Bultje\n * Copyright (C) 2010 Fiona Glaser\n * Copyright (C) 2012 Daniel Kang\n * Copyright (C) 2014 Peter Ross\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"libavutil/imgutils.h\"\n\n#include \"avcodec.h\"\n#include \"internal.h\"\n#include \"mathops.h\"\n#include \"rectangle.h\"\n#include \"thread.h\"\n#include \"vp8.h\"\n#include \"vp8data.h\"\n\n#if ARCH_ARM\n#   include \"arm/vp8.h\"\n#endif\n\n#if CONFIG_VP7_DECODER && CONFIG_VP8_DECODER\n#define VPX(vp7, f) (vp7 ? vp7_ ## f : vp8_ ## f)\n#elif CONFIG_VP7_DECODER\n#define VPX(vp7, f) vp7_ ## f\n#else // CONFIG_VP8_DECODER\n#define VPX(vp7, f) vp8_ ## f\n#endif\n\nstatic void free_buffers(VP8Context *s)\n{\n    int i;\n    if (s->thread_data)\n        for (i = 0; i < MAX_THREADS; i++) {\n#if HAVE_THREADS\n            pthread_cond_destroy(&s->thread_data[i].cond);\n            pthread_mutex_destroy(&s->thread_data[i].lock);\n#endif\n            av_freep(&s->thread_data[i].filter_strength);\n        }\n    av_freep(&s->thread_data);\n    av_freep(&s->macroblocks_base);\n    av_freep(&s->intra4x4_pred_mode_top);\n    av_freep(&s->top_nnz);\n    av_freep(&s->top_border);\n\n    s->macroblocks = NULL;\n}\n\nstatic int vp8_alloc_frame(VP8Context *s, VP8Frame *f, int ref)\n{\n    int ret;\n    if ((ret = ff_thread_get_buffer(s->avctx, &f->tf,\n                                    ref ? AV_GET_BUFFER_FLAG_REF : 0)) < 0)\n        return ret;\n    if (!(f->seg_map = av_buffer_allocz(s->mb_width * s->mb_height))) {\n        ff_thread_release_buffer(s->avctx, &f->tf);\n        return AVERROR(ENOMEM);\n    }\n    return 0;\n}\n\nstatic void vp8_release_frame(VP8Context *s, VP8Frame *f)\n{\n    av_buffer_unref(&f->seg_map);\n    ff_thread_release_buffer(s->avctx, &f->tf);\n}\n\n#if CONFIG_VP8_DECODER\nstatic int vp8_ref_frame(VP8Context *s, VP8Frame *dst, VP8Frame *src)\n{\n    int ret;\n\n    vp8_release_frame(s, dst);\n\n    if ((ret = ff_thread_ref_frame(&dst->tf, &src->tf)) < 0)\n        return ret;\n    if (src->seg_map &&\n        !(dst->seg_map = av_buffer_ref(src->seg_map))) {\n        vp8_release_frame(s, dst);\n        return AVERROR(ENOMEM);\n    }\n\n    return 0;\n}\n#endif /* CONFIG_VP8_DECODER */\n\nstatic void vp8_decode_flush_impl(AVCodecContext *avctx, int free_mem)\n{\n    VP8Context *s = avctx->priv_data;\n    int i;\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->frames); i++)\n        vp8_release_frame(s, &s->frames[i]);\n    memset(s->framep, 0, sizeof(s->framep));\n\n    if (free_mem)\n        free_buffers(s);\n}\n\nstatic void vp8_decode_flush(AVCodecContext *avctx)\n{\n    vp8_decode_flush_impl(avctx, 0);\n}\n\nstatic VP8Frame *vp8_find_free_buffer(VP8Context *s)\n{\n    VP8Frame *frame = NULL;\n    int i;\n\n    // find a free buffer\n    for (i = 0; i < 5; i++)\n        if (&s->frames[i] != s->framep[VP56_FRAME_CURRENT]  &&\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN]   &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2]) {\n            frame = &s->frames[i];\n            break;\n        }\n    if (i == 5) {\n        av_log(s->avctx, AV_LOG_FATAL, \"Ran out of free frames!\\n\");\n        abort();\n    }\n    if (frame->tf.f->data[0])\n        vp8_release_frame(s, frame);\n\n    return frame;\n}\n\nstatic av_always_inline\nint update_dimensions(VP8Context *s, int width, int height, int is_vp7)\n{\n    AVCodecContext *avctx = s->avctx;\n    int i, ret;\n\n    if (width  != s->avctx->width || ((width+15)/16 != s->mb_width || (height+15)/16 != s->mb_height) && s->macroblocks_base ||\n        height != s->avctx->height) {\n        vp8_decode_flush_impl(s->avctx, 1);\n\n        ret = ff_set_dimensions(s->avctx, width, height);\n        if (ret < 0)\n            return ret;\n    }\n\n    s->mb_width  = (s->avctx->coded_width  + 15) / 16;\n    s->mb_height = (s->avctx->coded_height + 15) / 16;\n\n    s->mb_layout = is_vp7 || avctx->active_thread_type == FF_THREAD_SLICE &&\n                   avctx->thread_count > 1;\n    if (!s->mb_layout) { // Frame threading and one thread\n        s->macroblocks_base       = av_mallocz((s->mb_width + s->mb_height * 2 + 1) *\n                                               sizeof(*s->macroblocks));\n        s->intra4x4_pred_mode_top = av_mallocz(s->mb_width * 4);\n    } else // Sliced threading\n        s->macroblocks_base = av_mallocz((s->mb_width + 2) * (s->mb_height + 2) *\n                                         sizeof(*s->macroblocks));\n    s->top_nnz     = av_mallocz(s->mb_width * sizeof(*s->top_nnz));\n    s->top_border  = av_mallocz((s->mb_width + 1) * sizeof(*s->top_border));\n    s->thread_data = av_mallocz(MAX_THREADS * sizeof(VP8ThreadData));\n\n    if (!s->macroblocks_base || !s->top_nnz || !s->top_border ||\n        !s->thread_data || (!s->intra4x4_pred_mode_top && !s->mb_layout)) {\n        free_buffers(s);\n        return AVERROR(ENOMEM);\n    }\n\n    for (i = 0; i < MAX_THREADS; i++) {\n        s->thread_data[i].filter_strength =\n            av_mallocz(s->mb_width * sizeof(*s->thread_data[0].filter_strength));\n        if (!s->thread_data[i].filter_strength) {\n            free_buffers(s);\n            return AVERROR(ENOMEM);\n        }\n#if HAVE_THREADS\n        pthread_mutex_init(&s->thread_data[i].lock, NULL);\n        pthread_cond_init(&s->thread_data[i].cond, NULL);\n#endif\n    }\n\n    s->macroblocks = s->macroblocks_base + 1;\n\n    return 0;\n}\n\nstatic int vp7_update_dimensions(VP8Context *s, int width, int height)\n{\n    return update_dimensions(s, width, height, IS_VP7);\n}\n\nstatic int vp8_update_dimensions(VP8Context *s, int width, int height)\n{\n    return update_dimensions(s, width, height, IS_VP8);\n}\n\n\nstatic void parse_segment_info(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n    int i;\n\n    s->segmentation.update_map = vp8_rac_get(c);\n\n    if (vp8_rac_get(c)) { // update segment feature data\n        s->segmentation.absolute_vals = vp8_rac_get(c);\n\n        for (i = 0; i < 4; i++)\n            s->segmentation.base_quant[i]   = vp8_rac_get_sint(c, 7);\n\n        for (i = 0; i < 4; i++)\n            s->segmentation.filter_level[i] = vp8_rac_get_sint(c, 6);\n    }\n    if (s->segmentation.update_map)\n        for (i = 0; i < 3; i++)\n            s->prob->segmentid[i] = vp8_rac_get(c) ? vp8_rac_get_uint(c, 8) : 255;\n}\n\nstatic void update_lf_deltas(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n    int i;\n\n    for (i = 0; i < 4; i++) {\n        if (vp8_rac_get(c)) {\n            s->lf_delta.ref[i] = vp8_rac_get_uint(c, 6);\n\n            if (vp8_rac_get(c))\n                s->lf_delta.ref[i] = -s->lf_delta.ref[i];\n        }\n    }\n\n    for (i = MODE_I4x4; i <= VP8_MVMODE_SPLIT; i++) {\n        if (vp8_rac_get(c)) {\n            s->lf_delta.mode[i] = vp8_rac_get_uint(c, 6);\n\n            if (vp8_rac_get(c))\n                s->lf_delta.mode[i] = -s->lf_delta.mode[i];\n        }\n    }\n}\n\nstatic int setup_partitions(VP8Context *s, const uint8_t *buf, int buf_size)\n{\n    const uint8_t *sizes = buf;\n    int i;\n    int ret;\n\n    s->num_coeff_partitions = 1 << vp8_rac_get_uint(&s->c, 2);\n\n    buf      += 3 * (s->num_coeff_partitions - 1);\n    buf_size -= 3 * (s->num_coeff_partitions - 1);\n    if (buf_size < 0)\n        return -1;\n\n    for (i = 0; i < s->num_coeff_partitions - 1; i++) {\n        int size = AV_RL24(sizes + 3 * i);\n        if (buf_size - size < 0)\n            return -1;\n\n        ret = ff_vp56_init_range_decoder(&s->coeff_partition[i], buf, size);\n        if (ret < 0)\n            return ret;\n        buf      += size;\n        buf_size -= size;\n    }\n    return ff_vp56_init_range_decoder(&s->coeff_partition[i], buf, buf_size);\n}\n\nstatic void vp7_get_quants(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n\n    int yac_qi  = vp8_rac_get_uint(c, 7);\n    int ydc_qi  = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n    int y2dc_qi = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n    int y2ac_qi = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n    int uvdc_qi = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n    int uvac_qi = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n\n    s->qmat[0].luma_qmul[0]    =       vp7_ydc_qlookup[ydc_qi];\n    s->qmat[0].luma_qmul[1]    =       vp7_yac_qlookup[yac_qi];\n    s->qmat[0].luma_dc_qmul[0] =       vp7_y2dc_qlookup[y2dc_qi];\n    s->qmat[0].luma_dc_qmul[1] =       vp7_y2ac_qlookup[y2ac_qi];\n    s->qmat[0].chroma_qmul[0]  = FFMIN(vp7_ydc_qlookup[uvdc_qi], 132);\n    s->qmat[0].chroma_qmul[1]  =       vp7_yac_qlookup[uvac_qi];\n}\n\nstatic void vp8_get_quants(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n    int i, base_qi;\n\n    int yac_qi     = vp8_rac_get_uint(c, 7);\n    int ydc_delta  = vp8_rac_get_sint(c, 4);\n    int y2dc_delta = vp8_rac_get_sint(c, 4);\n    int y2ac_delta = vp8_rac_get_sint(c, 4);\n    int uvdc_delta = vp8_rac_get_sint(c, 4);\n    int uvac_delta = vp8_rac_get_sint(c, 4);\n\n    for (i = 0; i < 4; i++) {\n        if (s->segmentation.enabled) {\n            base_qi = s->segmentation.base_quant[i];\n            if (!s->segmentation.absolute_vals)\n                base_qi += yac_qi;\n        } else\n            base_qi = yac_qi;\n\n        s->qmat[i].luma_qmul[0]    = vp8_dc_qlookup[av_clip_uintp2(base_qi + ydc_delta,  7)];\n        s->qmat[i].luma_qmul[1]    = vp8_ac_qlookup[av_clip_uintp2(base_qi,              7)];\n        s->qmat[i].luma_dc_qmul[0] = vp8_dc_qlookup[av_clip_uintp2(base_qi + y2dc_delta, 7)] * 2;\n        /* 101581>>16 is equivalent to 155/100 */\n        s->qmat[i].luma_dc_qmul[1] = vp8_ac_qlookup[av_clip_uintp2(base_qi + y2ac_delta, 7)] * 101581 >> 16;\n        s->qmat[i].chroma_qmul[0]  = vp8_dc_qlookup[av_clip_uintp2(base_qi + uvdc_delta, 7)];\n        s->qmat[i].chroma_qmul[1]  = vp8_ac_qlookup[av_clip_uintp2(base_qi + uvac_delta, 7)];\n\n        s->qmat[i].luma_dc_qmul[1] = FFMAX(s->qmat[i].luma_dc_qmul[1], 8);\n        s->qmat[i].chroma_qmul[0]  = FFMIN(s->qmat[i].chroma_qmul[0], 132);\n    }\n}\n\n/**\n * Determine which buffers golden and altref should be updated with after this frame.\n * The spec isn't clear here, so I'm going by my understanding of what libvpx does\n *\n * Intra frames update all 3 references\n * Inter frames update VP56_FRAME_PREVIOUS if the update_last flag is set\n * If the update (golden|altref) flag is set, it's updated with the current frame\n *      if update_last is set, and VP56_FRAME_PREVIOUS otherwise.\n * If the flag is not set, the number read means:\n *      0: no update\n *      1: VP56_FRAME_PREVIOUS\n *      2: update golden with altref, or update altref with golden\n */\nstatic VP56Frame ref_to_update(VP8Context *s, int update, VP56Frame ref)\n{\n    VP56RangeCoder *c = &s->c;\n\n    if (update)\n        return VP56_FRAME_CURRENT;\n\n    switch (vp8_rac_get_uint(c, 2)) {\n    case 1:\n        return VP56_FRAME_PREVIOUS;\n    case 2:\n        return (ref == VP56_FRAME_GOLDEN) ? VP56_FRAME_GOLDEN2 : VP56_FRAME_GOLDEN;\n    }\n    return VP56_FRAME_NONE;\n}\n\nstatic void vp78_reset_probability_tables(VP8Context *s)\n{\n    int i, j;\n    for (i = 0; i < 4; i++)\n        for (j = 0; j < 16; j++)\n            memcpy(s->prob->token[i][j], vp8_token_default_probs[i][vp8_coeff_band[j]],\n                   sizeof(s->prob->token[i][j]));\n}\n\nstatic void vp78_update_probability_tables(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n    int i, j, k, l, m;\n\n    for (i = 0; i < 4; i++)\n        for (j = 0; j < 8; j++)\n            for (k = 0; k < 3; k++)\n                for (l = 0; l < NUM_DCT_TOKENS-1; l++)\n                    if (vp56_rac_get_prob_branchy(c, vp8_token_update_probs[i][j][k][l])) {\n                        int prob = vp8_rac_get_uint(c, 8);\n                        for (m = 0; vp8_coeff_band_indexes[j][m] >= 0; m++)\n                            s->prob->token[i][vp8_coeff_band_indexes[j][m]][k][l] = prob;\n                    }\n}\n\n#define VP7_MVC_SIZE 17\n#define VP8_MVC_SIZE 19\n\nstatic void vp78_update_pred16x16_pred8x8_mvc_probabilities(VP8Context *s,\n                                                            int mvc_size)\n{\n    VP56RangeCoder *c = &s->c;\n    int i, j;\n\n    if (vp8_rac_get(c))\n        for (i = 0; i < 4; i++)\n            s->prob->pred16x16[i] = vp8_rac_get_uint(c, 8);\n    if (vp8_rac_get(c))\n        for (i = 0; i < 3; i++)\n            s->prob->pred8x8c[i]  = vp8_rac_get_uint(c, 8);\n\n    // 17.2 MV probability update\n    for (i = 0; i < 2; i++)\n        for (j = 0; j < mvc_size; j++)\n            if (vp56_rac_get_prob_branchy(c, vp8_mv_update_prob[i][j]))\n                s->prob->mvc[i][j] = vp8_rac_get_nn(c);\n}\n\nstatic void update_refs(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n\n    int update_golden = vp8_rac_get(c);\n    int update_altref = vp8_rac_get(c);\n\n    s->update_golden = ref_to_update(s, update_golden, VP56_FRAME_GOLDEN);\n    s->update_altref = ref_to_update(s, update_altref, VP56_FRAME_GOLDEN2);\n}\n\nstatic void copy_chroma(AVFrame *dst, AVFrame *src, int width, int height)\n{\n    int i, j;\n\n    for (j = 1; j < 3; j++) {\n        for (i = 0; i < height / 2; i++)\n            memcpy(dst->data[j] + i * dst->linesize[j],\n                   src->data[j] + i * src->linesize[j], width / 2);\n    }\n}\n\nstatic void fade(uint8_t *dst, ptrdiff_t dst_linesize,\n                 const uint8_t *src, ptrdiff_t src_linesize,\n                 int width, int height,\n                 int alpha, int beta)\n{\n    int i, j;\n    for (j = 0; j < height; j++) {\n        for (i = 0; i < width; i++) {\n            uint8_t y = src[j * src_linesize + i];\n            dst[j * dst_linesize + i] = av_clip_uint8(y + ((y * beta) >> 8) + alpha);\n        }\n    }\n}\n\nstatic int vp7_fade_frame(VP8Context *s, VP56RangeCoder *c)\n{\n    int alpha = (int8_t) vp8_rac_get_uint(c, 8);\n    int beta  = (int8_t) vp8_rac_get_uint(c, 8);\n    int ret;\n\n    if (!s->keyframe && (alpha || beta)) {\n        int width  = s->mb_width * 16;\n        int height = s->mb_height * 16;\n        AVFrame *src, *dst;\n\n        if (!s->framep[VP56_FRAME_PREVIOUS] ||\n            !s->framep[VP56_FRAME_GOLDEN]) {\n            av_log(s->avctx, AV_LOG_WARNING, \"Discarding interframe without a prior keyframe!\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        dst =\n        src = s->framep[VP56_FRAME_PREVIOUS]->tf.f;\n\n        /* preserve the golden frame, write a new previous frame */\n        if (s->framep[VP56_FRAME_GOLDEN] == s->framep[VP56_FRAME_PREVIOUS]) {\n            s->framep[VP56_FRAME_PREVIOUS] = vp8_find_free_buffer(s);\n            if ((ret = vp8_alloc_frame(s, s->framep[VP56_FRAME_PREVIOUS], 1)) < 0)\n                return ret;\n\n            dst = s->framep[VP56_FRAME_PREVIOUS]->tf.f;\n\n            copy_chroma(dst, src, width, height);\n        }\n\n        fade(dst->data[0], dst->linesize[0],\n             src->data[0], src->linesize[0],\n             width, height, alpha, beta);\n    }\n\n    return 0;\n}\n\nstatic int vp7_decode_frame_header(VP8Context *s, const uint8_t *buf, int buf_size)\n{\n    VP56RangeCoder *c = &s->c;\n    int part1_size, hscale, vscale, i, j, ret;\n    int width  = s->avctx->width;\n    int height = s->avctx->height;\n\n    if (buf_size < 4) {\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->profile = (buf[0] >> 1) & 7;\n    if (s->profile > 1) {\n        avpriv_request_sample(s->avctx, \"Unknown profile %d\", s->profile);\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->keyframe  = !(buf[0] & 1);\n    s->invisible = 0;\n    part1_size   = AV_RL24(buf) >> 4;\n\n    if (buf_size < 4 - s->profile + part1_size) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Buffer size %d is too small, needed : %d\\n\", buf_size, 4 - s->profile + part1_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    buf      += 4 - s->profile;\n    buf_size -= 4 - s->profile;\n\n    memcpy(s->put_pixels_tab, s->vp8dsp.put_vp8_epel_pixels_tab, sizeof(s->put_pixels_tab));\n\n    ret = ff_vp56_init_range_decoder(c, buf, part1_size);\n    if (ret < 0)\n        return ret;\n    buf      += part1_size;\n    buf_size -= part1_size;\n\n    /* A. Dimension information (keyframes only) */\n    if (s->keyframe) {\n        width  = vp8_rac_get_uint(c, 12);\n        height = vp8_rac_get_uint(c, 12);\n        hscale = vp8_rac_get_uint(c, 2);\n        vscale = vp8_rac_get_uint(c, 2);\n        if (hscale || vscale)\n            avpriv_request_sample(s->avctx, \"Upscaling\");\n\n        s->update_golden = s->update_altref = VP56_FRAME_CURRENT;\n        vp78_reset_probability_tables(s);\n        memcpy(s->prob->pred16x16, vp8_pred16x16_prob_inter,\n               sizeof(s->prob->pred16x16));\n        memcpy(s->prob->pred8x8c, vp8_pred8x8c_prob_inter,\n               sizeof(s->prob->pred8x8c));\n        for (i = 0; i < 2; i++)\n            memcpy(s->prob->mvc[i], vp7_mv_default_prob[i],\n                   sizeof(vp7_mv_default_prob[i]));\n        memset(&s->segmentation, 0, sizeof(s->segmentation));\n        memset(&s->lf_delta, 0, sizeof(s->lf_delta));\n        memcpy(s->prob[0].scan, ff_zigzag_scan, sizeof(s->prob[0].scan));\n    }\n\n    if (s->keyframe || s->profile > 0)\n        memset(s->inter_dc_pred, 0 , sizeof(s->inter_dc_pred));\n\n    /* B. Decoding information for all four macroblock-level features */\n    for (i = 0; i < 4; i++) {\n        s->feature_enabled[i] = vp8_rac_get(c);\n        if (s->feature_enabled[i]) {\n             s->feature_present_prob[i] = vp8_rac_get_uint(c, 8);\n\n             for (j = 0; j < 3; j++)\n                 s->feature_index_prob[i][j] =\n                     vp8_rac_get(c) ? vp8_rac_get_uint(c, 8) : 255;\n\n             if (vp7_feature_value_size[s->profile][i])\n                 for (j = 0; j < 4; j++)\n                     s->feature_value[i][j] =\n                        vp8_rac_get(c) ? vp8_rac_get_uint(c, vp7_feature_value_size[s->profile][i]) : 0;\n        }\n    }\n\n    s->segmentation.enabled    = 0;\n    s->segmentation.update_map = 0;\n    s->lf_delta.enabled        = 0;\n\n    s->num_coeff_partitions = 1;\n    ret = ff_vp56_init_range_decoder(&s->coeff_partition[0], buf, buf_size);\n    if (ret < 0)\n        return ret;\n\n    if (!s->macroblocks_base || /* first frame */\n        width != s->avctx->width || height != s->avctx->height ||\n        (width + 15) / 16 != s->mb_width || (height + 15) / 16 != s->mb_height) {\n        if ((ret = vp7_update_dimensions(s, width, height)) < 0)\n            return ret;\n    }\n\n    /* C. Dequantization indices */\n    vp7_get_quants(s);\n\n    /* D. Golden frame update flag (a Flag) for interframes only */\n    if (!s->keyframe) {\n        s->update_golden = vp8_rac_get(c) ? VP56_FRAME_CURRENT : VP56_FRAME_NONE;\n        s->sign_bias[VP56_FRAME_GOLDEN] = 0;\n    }\n\n    s->update_last          = 1;\n    s->update_probabilities = 1;\n    s->fade_present         = 1;\n\n    if (s->profile > 0) {\n        s->update_probabilities = vp8_rac_get(c);\n        if (!s->update_probabilities)\n            s->prob[1] = s->prob[0];\n\n        if (!s->keyframe)\n            s->fade_present = vp8_rac_get(c);\n    }\n\n    /* E. Fading information for previous frame */\n    if (s->fade_present && vp8_rac_get(c)) {\n        if ((ret = vp7_fade_frame(s ,c)) < 0)\n            return ret;\n    }\n\n    /* F. Loop filter type */\n    if (!s->profile)\n        s->filter.simple = vp8_rac_get(c);\n\n    /* G. DCT coefficient ordering specification */\n    if (vp8_rac_get(c))\n        for (i = 1; i < 16; i++)\n            s->prob[0].scan[i] = ff_zigzag_scan[vp8_rac_get_uint(c, 4)];\n\n    /* H. Loop filter levels  */\n    if (s->profile > 0)\n        s->filter.simple = vp8_rac_get(c);\n    s->filter.level     = vp8_rac_get_uint(c, 6);\n    s->filter.sharpness = vp8_rac_get_uint(c, 3);\n\n    /* I. DCT coefficient probability update; 13.3 Token Probability Updates */\n    vp78_update_probability_tables(s);\n\n    s->mbskip_enabled = 0;\n\n    /* J. The remaining frame header data occurs ONLY FOR INTERFRAMES */\n    if (!s->keyframe) {\n        s->prob->intra  = vp8_rac_get_uint(c, 8);\n        s->prob->last   = vp8_rac_get_uint(c, 8);\n        vp78_update_pred16x16_pred8x8_mvc_probabilities(s, VP7_MVC_SIZE);\n    }\n\n    return 0;\n}\n\nstatic int vp8_decode_frame_header(VP8Context *s, const uint8_t *buf, int buf_size)\n{\n    VP56RangeCoder *c = &s->c;\n    int header_size, hscale, vscale, ret;\n    int width  = s->avctx->width;\n    int height = s->avctx->height;\n\n    if (buf_size < 3) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Insufficent data (%d) for header\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->keyframe  = !(buf[0] & 1);\n    s->profile   =  (buf[0]>>1) & 7;\n    s->invisible = !(buf[0] & 0x10);\n    header_size  = AV_RL24(buf) >> 5;\n    buf      += 3;\n    buf_size -= 3;\n\n    if (s->profile > 3)\n        av_log(s->avctx, AV_LOG_WARNING, \"Unknown profile %d\\n\", s->profile);\n\n    if (!s->profile)\n        memcpy(s->put_pixels_tab, s->vp8dsp.put_vp8_epel_pixels_tab,\n               sizeof(s->put_pixels_tab));\n    else    // profile 1-3 use bilinear, 4+ aren't defined so whatever\n        memcpy(s->put_pixels_tab, s->vp8dsp.put_vp8_bilinear_pixels_tab,\n               sizeof(s->put_pixels_tab));\n\n    if (header_size > buf_size - 7 * s->keyframe) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Header size larger than data provided\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (s->keyframe) {\n        if (AV_RL24(buf) != 0x2a019d) {\n            av_log(s->avctx, AV_LOG_ERROR,\n                   \"Invalid start code 0x%x\\n\", AV_RL24(buf));\n            return AVERROR_INVALIDDATA;\n        }\n        width     = AV_RL16(buf + 3) & 0x3fff;\n        height    = AV_RL16(buf + 5) & 0x3fff;\n        hscale    = buf[4] >> 6;\n        vscale    = buf[6] >> 6;\n        buf      += 7;\n        buf_size -= 7;\n\n        if (hscale || vscale)\n            avpriv_request_sample(s->avctx, \"Upscaling\");\n\n        s->update_golden = s->update_altref = VP56_FRAME_CURRENT;\n        vp78_reset_probability_tables(s);\n        memcpy(s->prob->pred16x16, vp8_pred16x16_prob_inter,\n               sizeof(s->prob->pred16x16));\n        memcpy(s->prob->pred8x8c, vp8_pred8x8c_prob_inter,\n               sizeof(s->prob->pred8x8c));\n        memcpy(s->prob->mvc, vp8_mv_default_prob,\n               sizeof(s->prob->mvc));\n        memset(&s->segmentation, 0, sizeof(s->segmentation));\n        memset(&s->lf_delta, 0, sizeof(s->lf_delta));\n    }\n\n    ret = ff_vp56_init_range_decoder(c, buf, header_size);\n    if (ret < 0)\n        return ret;\n    buf      += header_size;\n    buf_size -= header_size;\n\n    if (s->keyframe) {\n        s->colorspace = vp8_rac_get(c);\n        if (s->colorspace)\n            av_log(s->avctx, AV_LOG_WARNING, \"Unspecified colorspace\\n\");\n        s->fullrange = vp8_rac_get(c);\n    }\n\n    if ((s->segmentation.enabled = vp8_rac_get(c)))\n        parse_segment_info(s);\n    else\n        s->segmentation.update_map = 0; // FIXME: move this to some init function?\n\n    s->filter.simple    = vp8_rac_get(c);\n    s->filter.level     = vp8_rac_get_uint(c, 6);\n    s->filter.sharpness = vp8_rac_get_uint(c, 3);\n\n    if ((s->lf_delta.enabled = vp8_rac_get(c)))\n        if (vp8_rac_get(c))\n            update_lf_deltas(s);\n\n    if (setup_partitions(s, buf, buf_size)) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid partitions\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!s->macroblocks_base || /* first frame */\n        width != s->avctx->width || height != s->avctx->height ||\n        (width+15)/16 != s->mb_width || (height+15)/16 != s->mb_height)\n        if ((ret = vp8_update_dimensions(s, width, height)) < 0)\n            return ret;\n\n    vp8_get_quants(s);\n\n    if (!s->keyframe) {\n        update_refs(s);\n        s->sign_bias[VP56_FRAME_GOLDEN]               = vp8_rac_get(c);\n        s->sign_bias[VP56_FRAME_GOLDEN2 /* altref */] = vp8_rac_get(c);\n    }\n\n    // if we aren't saving this frame's probabilities for future frames,\n    // make a copy of the current probabilities\n    if (!(s->update_probabilities = vp8_rac_get(c)))\n        s->prob[1] = s->prob[0];\n\n    s->update_last = s->keyframe || vp8_rac_get(c);\n\n    vp78_update_probability_tables(s);\n\n    if ((s->mbskip_enabled = vp8_rac_get(c)))\n        s->prob->mbskip = vp8_rac_get_uint(c, 8);\n\n    if (!s->keyframe) {\n        s->prob->intra  = vp8_rac_get_uint(c, 8);\n        s->prob->last   = vp8_rac_get_uint(c, 8);\n        s->prob->golden = vp8_rac_get_uint(c, 8);\n        vp78_update_pred16x16_pred8x8_mvc_probabilities(s, VP8_MVC_SIZE);\n    }\n\n    return 0;\n}\n\nstatic av_always_inline\nvoid clamp_mv(VP8mvbounds *s, VP56mv *dst, const VP56mv *src)\n{\n    dst->x = av_clip(src->x, av_clip(s->mv_min.x, INT16_MIN, INT16_MAX),\n                             av_clip(s->mv_max.x, INT16_MIN, INT16_MAX));\n    dst->y = av_clip(src->y, av_clip(s->mv_min.y, INT16_MIN, INT16_MAX),\n                             av_clip(s->mv_max.y, INT16_MIN, INT16_MAX));\n}\n\n/**\n * Motion vector coding, 17.1.\n */\nstatic av_always_inline int read_mv_component(VP56RangeCoder *c, const uint8_t *p, int vp7)\n{\n    int bit, x = 0;\n\n    if (vp56_rac_get_prob_branchy(c, p[0])) {\n        int i;\n\n        for (i = 0; i < 3; i++)\n            x += vp56_rac_get_prob(c, p[9 + i]) << i;\n        for (i = (vp7 ? 7 : 9); i > 3; i--)\n            x += vp56_rac_get_prob(c, p[9 + i]) << i;\n        if (!(x & (vp7 ? 0xF0 : 0xFFF0)) || vp56_rac_get_prob(c, p[12]))\n            x += 8;\n    } else {\n        // small_mvtree\n        const uint8_t *ps = p + 2;\n        bit = vp56_rac_get_prob(c, *ps);\n        ps += 1 + 3 * bit;\n        x  += 4 * bit;\n        bit = vp56_rac_get_prob(c, *ps);\n        ps += 1 + bit;\n        x  += 2 * bit;\n        x  += vp56_rac_get_prob(c, *ps);\n    }\n\n    return (x && vp56_rac_get_prob(c, p[1])) ? -x : x;\n}\n\nstatic int vp7_read_mv_component(VP56RangeCoder *c, const uint8_t *p)\n{\n    return read_mv_component(c, p, 1);\n}\n\nstatic int vp8_read_mv_component(VP56RangeCoder *c, const uint8_t *p)\n{\n    return read_mv_component(c, p, 0);\n}\n\nstatic av_always_inline\nconst uint8_t *get_submv_prob(uint32_t left, uint32_t top, int is_vp7)\n{\n    if (is_vp7)\n        return vp7_submv_prob;\n\n    if (left == top)\n        return vp8_submv_prob[4 - !!left];\n    if (!top)\n        return vp8_submv_prob[2];\n    return vp8_submv_prob[1 - !!left];\n}\n\n/**\n * Split motion vector prediction, 16.4.\n * @returns the number of motion vectors parsed (2, 4 or 16)\n */\nstatic av_always_inline\nint decode_splitmvs(VP8Context *s, VP56RangeCoder *c, VP8Macroblock *mb,\n                    int layout, int is_vp7)\n{\n    int part_idx;\n    int n, num;\n    VP8Macroblock *top_mb;\n    VP8Macroblock *left_mb = &mb[-1];\n    const uint8_t *mbsplits_left = vp8_mbsplits[left_mb->partitioning];\n    const uint8_t *mbsplits_top, *mbsplits_cur, *firstidx;\n    VP56mv *top_mv;\n    VP56mv *left_mv = left_mb->bmv;\n    VP56mv *cur_mv  = mb->bmv;\n\n    if (!layout) // layout is inlined, s->mb_layout is not\n        top_mb = &mb[2];\n    else\n        top_mb = &mb[-s->mb_width - 1];\n    mbsplits_top = vp8_mbsplits[top_mb->partitioning];\n    top_mv       = top_mb->bmv;\n\n    if (vp56_rac_get_prob_branchy(c, vp8_mbsplit_prob[0])) {\n        if (vp56_rac_get_prob_branchy(c, vp8_mbsplit_prob[1]))\n            part_idx = VP8_SPLITMVMODE_16x8 + vp56_rac_get_prob(c, vp8_mbsplit_prob[2]);\n        else\n            part_idx = VP8_SPLITMVMODE_8x8;\n    } else {\n        part_idx = VP8_SPLITMVMODE_4x4;\n    }\n\n    num              = vp8_mbsplit_count[part_idx];\n    mbsplits_cur     = vp8_mbsplits[part_idx],\n    firstidx         = vp8_mbfirstidx[part_idx];\n    mb->partitioning = part_idx;\n\n    for (n = 0; n < num; n++) {\n        int k = firstidx[n];\n        uint32_t left, above;\n        const uint8_t *submv_prob;\n\n        if (!(k & 3))\n            left = AV_RN32A(&left_mv[mbsplits_left[k + 3]]);\n        else\n            left = AV_RN32A(&cur_mv[mbsplits_cur[k - 1]]);\n        if (k <= 3)\n            above = AV_RN32A(&top_mv[mbsplits_top[k + 12]]);\n        else\n            above = AV_RN32A(&cur_mv[mbsplits_cur[k - 4]]);\n\n        submv_prob = get_submv_prob(left, above, is_vp7);\n\n        if (vp56_rac_get_prob_branchy(c, submv_prob[0])) {\n            if (vp56_rac_get_prob_branchy(c, submv_prob[1])) {\n                if (vp56_rac_get_prob_branchy(c, submv_prob[2])) {\n                    mb->bmv[n].y = mb->mv.y +\n                                   read_mv_component(c, s->prob->mvc[0], is_vp7);\n                    mb->bmv[n].x = mb->mv.x +\n                                   read_mv_component(c, s->prob->mvc[1], is_vp7);\n                } else {\n                    AV_ZERO32(&mb->bmv[n]);\n                }\n            } else {\n                AV_WN32A(&mb->bmv[n], above);\n            }\n        } else {\n            AV_WN32A(&mb->bmv[n], left);\n        }\n    }\n\n    return num;\n}\n\n/**\n * The vp7 reference decoder uses a padding macroblock column (added to right\n * edge of the frame) to guard against illegal macroblock offsets. The\n * algorithm has bugs that permit offsets to straddle the padding column.\n * This function replicates those bugs.\n *\n * @param[out] edge_x macroblock x address\n * @param[out] edge_y macroblock y address\n *\n * @return macroblock offset legal (boolean)\n */\nstatic int vp7_calculate_mb_offset(int mb_x, int mb_y, int mb_width,\n                                   int xoffset, int yoffset, int boundary,\n                                   int *edge_x, int *edge_y)\n{\n    int vwidth = mb_width + 1;\n    int new = (mb_y + yoffset) * vwidth + mb_x + xoffset;\n    if (new < boundary || new % vwidth == vwidth - 1)\n        return 0;\n    *edge_y = new / vwidth;\n    *edge_x = new % vwidth;\n    return 1;\n}\n\nstatic const VP56mv *get_bmv_ptr(const VP8Macroblock *mb, int subblock)\n{\n    return &mb->bmv[mb->mode == VP8_MVMODE_SPLIT ? vp8_mbsplits[mb->partitioning][subblock] : 0];\n}\n\nstatic av_always_inline\nvoid vp7_decode_mvs(VP8Context *s, VP8Macroblock *mb,\n                    int mb_x, int mb_y, int layout)\n{\n    VP8Macroblock *mb_edge[12];\n    enum { CNT_ZERO, CNT_NEAREST, CNT_NEAR };\n    enum { VP8_EDGE_TOP, VP8_EDGE_LEFT, VP8_EDGE_TOPLEFT };\n    int idx = CNT_ZERO;\n    VP56mv near_mv[3];\n    uint8_t cnt[3] = { 0 };\n    VP56RangeCoder *c = &s->c;\n    int i;\n\n    AV_ZERO32(&near_mv[0]);\n    AV_ZERO32(&near_mv[1]);\n    AV_ZERO32(&near_mv[2]);\n\n    for (i = 0; i < VP7_MV_PRED_COUNT; i++) {\n        const VP7MVPred * pred = &vp7_mv_pred[i];\n        int edge_x, edge_y;\n\n        if (vp7_calculate_mb_offset(mb_x, mb_y, s->mb_width, pred->xoffset,\n                                    pred->yoffset, !s->profile, &edge_x, &edge_y)) {\n            VP8Macroblock *edge = mb_edge[i] = (s->mb_layout == 1)\n                                             ? s->macroblocks_base + 1 + edge_x +\n                                               (s->mb_width + 1) * (edge_y + 1)\n                                             : s->macroblocks + edge_x +\n                                               (s->mb_height - edge_y - 1) * 2;\n            uint32_t mv = AV_RN32A(get_bmv_ptr(edge, vp7_mv_pred[i].subblock));\n            if (mv) {\n                if (AV_RN32A(&near_mv[CNT_NEAREST])) {\n                    if (mv == AV_RN32A(&near_mv[CNT_NEAREST])) {\n                        idx = CNT_NEAREST;\n                    } else if (AV_RN32A(&near_mv[CNT_NEAR])) {\n                        if (mv != AV_RN32A(&near_mv[CNT_NEAR]))\n                            continue;\n                        idx = CNT_NEAR;\n                    } else {\n                        AV_WN32A(&near_mv[CNT_NEAR], mv);\n                        idx = CNT_NEAR;\n                    }\n                } else {\n                    AV_WN32A(&near_mv[CNT_NEAREST], mv);\n                    idx = CNT_NEAREST;\n                }\n            } else {\n                idx = CNT_ZERO;\n            }\n        } else {\n            idx = CNT_ZERO;\n        }\n        cnt[idx] += vp7_mv_pred[i].score;\n    }\n\n    mb->partitioning = VP8_SPLITMVMODE_NONE;\n\n    if (vp56_rac_get_prob_branchy(c, vp7_mode_contexts[cnt[CNT_ZERO]][0])) {\n        mb->mode = VP8_MVMODE_MV;\n\n        if (vp56_rac_get_prob_branchy(c, vp7_mode_contexts[cnt[CNT_NEAREST]][1])) {\n\n            if (vp56_rac_get_prob_branchy(c, vp7_mode_contexts[cnt[CNT_NEAR]][2])) {\n\n                if (cnt[CNT_NEAREST] > cnt[CNT_NEAR])\n                    AV_WN32A(&mb->mv, cnt[CNT_ZERO] > cnt[CNT_NEAREST] ? 0 : AV_RN32A(&near_mv[CNT_NEAREST]));\n                else\n                    AV_WN32A(&mb->mv, cnt[CNT_ZERO] > cnt[CNT_NEAR]    ? 0 : AV_RN32A(&near_mv[CNT_NEAR]));\n\n                if (vp56_rac_get_prob_branchy(c, vp7_mode_contexts[cnt[CNT_NEAR]][3])) {\n                    mb->mode = VP8_MVMODE_SPLIT;\n                    mb->mv = mb->bmv[decode_splitmvs(s, c, mb, layout, IS_VP7) - 1];\n                } else {\n                    mb->mv.y += vp7_read_mv_component(c, s->prob->mvc[0]);\n                    mb->mv.x += vp7_read_mv_component(c, s->prob->mvc[1]);\n                    mb->bmv[0] = mb->mv;\n                }\n            } else {\n                mb->mv = near_mv[CNT_NEAR];\n                mb->bmv[0] = mb->mv;\n            }\n        } else {\n            mb->mv = near_mv[CNT_NEAREST];\n            mb->bmv[0] = mb->mv;\n        }\n    } else {\n        mb->mode = VP8_MVMODE_ZERO;\n        AV_ZERO32(&mb->mv);\n        mb->bmv[0] = mb->mv;\n    }\n}\n\nstatic av_always_inline\nvoid vp8_decode_mvs(VP8Context *s, VP8mvbounds *mv_bounds, VP8Macroblock *mb,\n                    int mb_x, int mb_y, int layout)\n{\n    VP8Macroblock *mb_edge[3] = { 0      /* top */,\n                                  mb - 1 /* left */,\n                                  0      /* top-left */ };\n    enum { CNT_ZERO, CNT_NEAREST, CNT_NEAR, CNT_SPLITMV };\n    enum { VP8_EDGE_TOP, VP8_EDGE_LEFT, VP8_EDGE_TOPLEFT };\n    int idx = CNT_ZERO;\n    int cur_sign_bias = s->sign_bias[mb->ref_frame];\n    int8_t *sign_bias = s->sign_bias;\n    VP56mv near_mv[4];\n    uint8_t cnt[4] = { 0 };\n    VP56RangeCoder *c = &s->c;\n\n    if (!layout) { // layout is inlined (s->mb_layout is not)\n        mb_edge[0] = mb + 2;\n        mb_edge[2] = mb + 1;\n    } else {\n        mb_edge[0] = mb - s->mb_width - 1;\n        mb_edge[2] = mb - s->mb_width - 2;\n    }\n\n    AV_ZERO32(&near_mv[0]);\n    AV_ZERO32(&near_mv[1]);\n    AV_ZERO32(&near_mv[2]);\n\n    /* Process MB on top, left and top-left */\n#define MV_EDGE_CHECK(n)                                                      \\\n    {                                                                         \\\n        VP8Macroblock *edge = mb_edge[n];                                     \\\n        int edge_ref = edge->ref_frame;                                       \\\n        if (edge_ref != VP56_FRAME_CURRENT) {                                 \\\n            uint32_t mv = AV_RN32A(&edge->mv);                                \\\n            if (mv) {                                                         \\\n                if (cur_sign_bias != sign_bias[edge_ref]) {                   \\\n                    /* SWAR negate of the values in mv. */                    \\\n                    mv = ~mv;                                                 \\\n                    mv = ((mv & 0x7fff7fff) +                                 \\\n                          0x00010001) ^ (mv & 0x80008000);                    \\\n                }                                                             \\\n                if (!n || mv != AV_RN32A(&near_mv[idx]))                      \\\n                    AV_WN32A(&near_mv[++idx], mv);                            \\\n                cnt[idx] += 1 + (n != 2);                                     \\\n            } else                                                            \\\n                cnt[CNT_ZERO] += 1 + (n != 2);                                \\\n        }                                                                     \\\n    }\n\n    MV_EDGE_CHECK(0)\n    MV_EDGE_CHECK(1)\n    MV_EDGE_CHECK(2)\n\n    mb->partitioning = VP8_SPLITMVMODE_NONE;\n    if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_ZERO]][0])) {\n        mb->mode = VP8_MVMODE_MV;\n\n        /* If we have three distinct MVs, merge first and last if they're the same */\n        if (cnt[CNT_SPLITMV] &&\n            AV_RN32A(&near_mv[1 + VP8_EDGE_TOP]) == AV_RN32A(&near_mv[1 + VP8_EDGE_TOPLEFT]))\n            cnt[CNT_NEAREST] += 1;\n\n        /* Swap near and nearest if necessary */\n        if (cnt[CNT_NEAR] > cnt[CNT_NEAREST]) {\n            FFSWAP(uint8_t,     cnt[CNT_NEAREST],     cnt[CNT_NEAR]);\n            FFSWAP( VP56mv, near_mv[CNT_NEAREST], near_mv[CNT_NEAR]);\n        }\n\n        if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_NEAREST]][1])) {\n            if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_NEAR]][2])) {\n                /* Choose the best mv out of 0,0 and the nearest mv */\n                clamp_mv(mv_bounds, &mb->mv, &near_mv[CNT_ZERO + (cnt[CNT_NEAREST] >= cnt[CNT_ZERO])]);\n                cnt[CNT_SPLITMV] = ((mb_edge[VP8_EDGE_LEFT]->mode    == VP8_MVMODE_SPLIT) +\n                                    (mb_edge[VP8_EDGE_TOP]->mode     == VP8_MVMODE_SPLIT)) * 2 +\n                                    (mb_edge[VP8_EDGE_TOPLEFT]->mode == VP8_MVMODE_SPLIT);\n\n                if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_SPLITMV]][3])) {\n                    mb->mode = VP8_MVMODE_SPLIT;\n                    mb->mv = mb->bmv[decode_splitmvs(s, c, mb, layout, IS_VP8) - 1];\n                } else {\n                    mb->mv.y  += vp8_read_mv_component(c, s->prob->mvc[0]);\n                    mb->mv.x  += vp8_read_mv_component(c, s->prob->mvc[1]);\n                    mb->bmv[0] = mb->mv;\n                }\n            } else {\n                clamp_mv(mv_bounds, &mb->mv, &near_mv[CNT_NEAR]);\n                mb->bmv[0] = mb->mv;\n            }\n        } else {\n            clamp_mv(mv_bounds, &mb->mv, &near_mv[CNT_NEAREST]);\n            mb->bmv[0] = mb->mv;\n        }\n    } else {\n        mb->mode = VP8_MVMODE_ZERO;\n        AV_ZERO32(&mb->mv);\n        mb->bmv[0] = mb->mv;\n    }\n}\n\nstatic av_always_inline\nvoid decode_intra4x4_modes(VP8Context *s, VP56RangeCoder *c, VP8Macroblock *mb,\n                           int mb_x, int keyframe, int layout)\n{\n    uint8_t *intra4x4 = mb->intra4x4_pred_mode_mb;\n\n    if (layout) {\n        VP8Macroblock *mb_top = mb - s->mb_width - 1;\n        memcpy(mb->intra4x4_pred_mode_top, mb_top->intra4x4_pred_mode_top, 4);\n    }\n    if (keyframe) {\n        int x, y;\n        uint8_t *top;\n        uint8_t *const left = s->intra4x4_pred_mode_left;\n        if (layout)\n            top = mb->intra4x4_pred_mode_top;\n        else\n            top = s->intra4x4_pred_mode_top + 4 * mb_x;\n        for (y = 0; y < 4; y++) {\n            for (x = 0; x < 4; x++) {\n                const uint8_t *ctx;\n                ctx       = vp8_pred4x4_prob_intra[top[x]][left[y]];\n                *intra4x4 = vp8_rac_get_tree(c, vp8_pred4x4_tree, ctx);\n                left[y]   = top[x] = *intra4x4;\n                intra4x4++;\n            }\n        }\n    } else {\n        int i;\n        for (i = 0; i < 16; i++)\n            intra4x4[i] = vp8_rac_get_tree(c, vp8_pred4x4_tree,\n                                           vp8_pred4x4_prob_inter);\n    }\n}\n\nstatic av_always_inline\nvoid decode_mb_mode(VP8Context *s, VP8mvbounds *mv_bounds,\n                    VP8Macroblock *mb, int mb_x, int mb_y,\n                    uint8_t *segment, uint8_t *ref, int layout, int is_vp7)\n{\n    VP56RangeCoder *c = &s->c;\n    static const char *vp7_feature_name[] = { \"q-index\",\n                                              \"lf-delta\",\n                                              \"partial-golden-update\",\n                                              \"blit-pitch\" };\n    if (is_vp7) {\n        int i;\n        *segment = 0;\n        for (i = 0; i < 4; i++) {\n            if (s->feature_enabled[i]) {\n                if (vp56_rac_get_prob_branchy(c, s->feature_present_prob[i])) {\n                      int index = vp8_rac_get_tree(c, vp7_feature_index_tree,\n                                                   s->feature_index_prob[i]);\n                      av_log(s->avctx, AV_LOG_WARNING,\n                             \"Feature %s present in macroblock (value 0x%x)\\n\",\n                             vp7_feature_name[i], s->feature_value[i][index]);\n                }\n           }\n        }\n    } else if (s->segmentation.update_map) {\n        int bit  = vp56_rac_get_prob(c, s->prob->segmentid[0]);\n        *segment = vp56_rac_get_prob(c, s->prob->segmentid[1+bit]) + 2*bit;\n    } else if (s->segmentation.enabled)\n        *segment = ref ? *ref : *segment;\n    mb->segment = *segment;\n\n    mb->skip = s->mbskip_enabled ? vp56_rac_get_prob(c, s->prob->mbskip) : 0;\n\n    if (s->keyframe) {\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_intra,\n                                    vp8_pred16x16_prob_intra);\n\n        if (mb->mode == MODE_I4x4) {\n            decode_intra4x4_modes(s, c, mb, mb_x, 1, layout);\n        } else {\n            const uint32_t modes = (is_vp7 ? vp7_pred4x4_mode\n                                           : vp8_pred4x4_mode)[mb->mode] * 0x01010101u;\n            if (s->mb_layout)\n                AV_WN32A(mb->intra4x4_pred_mode_top, modes);\n            else\n                AV_WN32A(s->intra4x4_pred_mode_top + 4 * mb_x, modes);\n            AV_WN32A(s->intra4x4_pred_mode_left, modes);\n        }\n\n        mb->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree,\n                                                vp8_pred8x8c_prob_intra);\n        mb->ref_frame        = VP56_FRAME_CURRENT;\n    } else if (vp56_rac_get_prob_branchy(c, s->prob->intra)) {\n        // inter MB, 16.2\n        if (vp56_rac_get_prob_branchy(c, s->prob->last))\n            mb->ref_frame =\n                (!is_vp7 && vp56_rac_get_prob(c, s->prob->golden)) ? VP56_FRAME_GOLDEN2 /* altref */\n                                                                   : VP56_FRAME_GOLDEN;\n        else\n            mb->ref_frame = VP56_FRAME_PREVIOUS;\n        s->ref_count[mb->ref_frame - 1]++;\n\n        // motion vectors, 16.3\n        if (is_vp7)\n            vp7_decode_mvs(s, mb, mb_x, mb_y, layout);\n        else\n            vp8_decode_mvs(s, mv_bounds, mb, mb_x, mb_y, layout);\n    } else {\n        // intra MB, 16.1\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_inter, s->prob->pred16x16);\n\n        if (mb->mode == MODE_I4x4)\n            decode_intra4x4_modes(s, c, mb, mb_x, 0, layout);\n\n        mb->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree,\n                                                s->prob->pred8x8c);\n        mb->ref_frame        = VP56_FRAME_CURRENT;\n        mb->partitioning     = VP8_SPLITMVMODE_NONE;\n        AV_ZERO32(&mb->bmv[0]);\n    }\n}\n\n/**\n * @param r     arithmetic bitstream reader context\n * @param block destination for block coefficients\n * @param probs probabilities to use when reading trees from the bitstream\n * @param i     initial coeff index, 0 unless a separate DC block is coded\n * @param qmul  array holding the dc/ac dequant factor at position 0/1\n *\n * @return 0 if no coeffs were decoded\n *         otherwise, the index of the last coeff decoded plus one\n */\nstatic av_always_inline\nint decode_block_coeffs_internal(VP56RangeCoder *r, int16_t block[16],\n                                 uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n                                 int i, uint8_t *token_prob, int16_t qmul[2],\n                                 const uint8_t scan[16], int vp7)\n{\n    VP56RangeCoder c = *r;\n    goto skip_eob;\n    do {\n        int coeff;\nrestart:\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[0]))   // DCT_EOB\n            break;\n\nskip_eob:\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[1])) { // DCT_0\n            if (++i == 16)\n                break; // invalid input; blocks should end with EOB\n            token_prob = probs[i][0];\n            if (vp7)\n                goto restart;\n            goto skip_eob;\n        }\n\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[2])) { // DCT_1\n            coeff = 1;\n            token_prob = probs[i + 1][1];\n        } else {\n            if (!vp56_rac_get_prob_branchy(&c, token_prob[3])) { // DCT 2,3,4\n                coeff = vp56_rac_get_prob_branchy(&c, token_prob[4]);\n                if (coeff)\n                    coeff += vp56_rac_get_prob(&c, token_prob[5]);\n                coeff += 2;\n            } else {\n                // DCT_CAT*\n                if (!vp56_rac_get_prob_branchy(&c, token_prob[6])) {\n                    if (!vp56_rac_get_prob_branchy(&c, token_prob[7])) { // DCT_CAT1\n                        coeff = 5 + vp56_rac_get_prob(&c, vp8_dct_cat1_prob[0]);\n                    } else {                                    // DCT_CAT2\n                        coeff  = 7;\n                        coeff += vp56_rac_get_prob(&c, vp8_dct_cat2_prob[0]) << 1;\n                        coeff += vp56_rac_get_prob(&c, vp8_dct_cat2_prob[1]);\n                    }\n                } else {    // DCT_CAT3 and up\n                    int a   = vp56_rac_get_prob(&c, token_prob[8]);\n                    int b   = vp56_rac_get_prob(&c, token_prob[9 + a]);\n                    int cat = (a << 1) + b;\n                    coeff  = 3 + (8 << cat);\n                    coeff += vp8_rac_get_coeff(&c, ff_vp8_dct_cat_prob[cat]);\n                }\n            }\n            token_prob = probs[i + 1][2];\n        }\n        block[scan[i]] = (vp8_rac_get(&c) ? -coeff : coeff) * qmul[!!i];\n    } while (++i < 16);\n\n    *r = c;\n    return i;\n}\n\nstatic av_always_inline\nint inter_predict_dc(int16_t block[16], int16_t pred[2])\n{\n    int16_t dc = block[0];\n    int ret = 0;\n\n    if (pred[1] > 3) {\n        dc += pred[0];\n        ret = 1;\n    }\n\n    if (!pred[0] | !dc | ((int32_t)pred[0] ^ (int32_t)dc) >> 31) {\n        block[0] = pred[0] = dc;\n        pred[1] = 0;\n    } else {\n        if (pred[0] == dc)\n            pred[1]++;\n        block[0] = pred[0] = dc;\n    }\n\n    return ret;\n}\n\nstatic int vp7_decode_block_coeffs_internal(VP56RangeCoder *r,\n                                            int16_t block[16],\n                                            uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n                                            int i, uint8_t *token_prob,\n                                            int16_t qmul[2],\n                                            const uint8_t scan[16])\n{\n    return decode_block_coeffs_internal(r, block, probs, i,\n                                        token_prob, qmul, scan, IS_VP7);\n}\n\n#ifndef vp8_decode_block_coeffs_internal\nstatic int vp8_decode_block_coeffs_internal(VP56RangeCoder *r,\n                                            int16_t block[16],\n                                            uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n                                            int i, uint8_t *token_prob,\n                                            int16_t qmul[2])\n{\n    return decode_block_coeffs_internal(r, block, probs, i,\n                                        token_prob, qmul, ff_zigzag_scan, IS_VP8);\n}\n#endif\n\n/**\n * @param c          arithmetic bitstream reader context\n * @param block      destination for block coefficients\n * @param probs      probabilities to use when reading trees from the bitstream\n * @param i          initial coeff index, 0 unless a separate DC block is coded\n * @param zero_nhood the initial prediction context for number of surrounding\n *                   all-zero blocks (only left/top, so 0-2)\n * @param qmul       array holding the dc/ac dequant factor at position 0/1\n * @param scan       scan pattern (VP7 only)\n *\n * @return 0 if no coeffs were decoded\n *         otherwise, the index of the last coeff decoded plus one\n */\nstatic av_always_inline\nint decode_block_coeffs(VP56RangeCoder *c, int16_t block[16],\n                        uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n                        int i, int zero_nhood, int16_t qmul[2],\n                        const uint8_t scan[16], int vp7)\n{\n    uint8_t *token_prob = probs[i][zero_nhood];\n    if (!vp56_rac_get_prob_branchy(c, token_prob[0]))   // DCT_EOB\n        return 0;\n    return vp7 ? vp7_decode_block_coeffs_internal(c, block, probs, i,\n                                                  token_prob, qmul, scan)\n               : vp8_decode_block_coeffs_internal(c, block, probs, i,\n                                                  token_prob, qmul);\n}\n\nstatic av_always_inline\nvoid decode_mb_coeffs(VP8Context *s, VP8ThreadData *td, VP56RangeCoder *c,\n                      VP8Macroblock *mb, uint8_t t_nnz[9], uint8_t l_nnz[9],\n                      int is_vp7)\n{\n    int i, x, y, luma_start = 0, luma_ctx = 3;\n    int nnz_pred, nnz, nnz_total = 0;\n    int segment = mb->segment;\n    int block_dc = 0;\n\n    if (mb->mode != MODE_I4x4 && (is_vp7 || mb->mode != VP8_MVMODE_SPLIT)) {\n        nnz_pred = t_nnz[8] + l_nnz[8];\n\n        // decode DC values and do hadamard\n        nnz = decode_block_coeffs(c, td->block_dc, s->prob->token[1], 0,\n                                  nnz_pred, s->qmat[segment].luma_dc_qmul,\n                                  ff_zigzag_scan, is_vp7);\n        l_nnz[8] = t_nnz[8] = !!nnz;\n\n        if (is_vp7 && mb->mode > MODE_I4x4) {\n            nnz |=  inter_predict_dc(td->block_dc,\n                                     s->inter_dc_pred[mb->ref_frame - 1]);\n        }\n\n        if (nnz) {\n            nnz_total += nnz;\n            block_dc   = 1;\n            if (nnz == 1)\n                s->vp8dsp.vp8_luma_dc_wht_dc(td->block, td->block_dc);\n            else\n                s->vp8dsp.vp8_luma_dc_wht(td->block, td->block_dc);\n        }\n        luma_start = 1;\n        luma_ctx   = 0;\n    }\n\n    // luma blocks\n    for (y = 0; y < 4; y++)\n        for (x = 0; x < 4; x++) {\n            nnz_pred = l_nnz[y] + t_nnz[x];\n            nnz = decode_block_coeffs(c, td->block[y][x],\n                                      s->prob->token[luma_ctx],\n                                      luma_start, nnz_pred,\n                                      s->qmat[segment].luma_qmul,\n                                      s->prob[0].scan, is_vp7);\n            /* nnz+block_dc may be one more than the actual last index,\n             * but we don't care */\n            td->non_zero_count_cache[y][x] = nnz + block_dc;\n            t_nnz[x] = l_nnz[y] = !!nnz;\n            nnz_total += nnz;\n        }\n\n    // chroma blocks\n    // TODO: what to do about dimensions? 2nd dim for luma is x,\n    // but for chroma it's (y<<1)|x\n    for (i = 4; i < 6; i++)\n        for (y = 0; y < 2; y++)\n            for (x = 0; x < 2; x++) {\n                nnz_pred = l_nnz[i + 2 * y] + t_nnz[i + 2 * x];\n                nnz = decode_block_coeffs(c, td->block[i][(y << 1) + x],\n                                          s->prob->token[2], 0, nnz_pred,\n                                          s->qmat[segment].chroma_qmul,\n                                          s->prob[0].scan, is_vp7);\n                td->non_zero_count_cache[i][(y << 1) + x] = nnz;\n                t_nnz[i + 2 * x] = l_nnz[i + 2 * y] = !!nnz;\n                nnz_total += nnz;\n            }\n\n    // if there were no coded coeffs despite the macroblock not being marked skip,\n    // we MUST not do the inner loop filter and should not do IDCT\n    // Since skip isn't used for bitstream prediction, just manually set it.\n    if (!nnz_total)\n        mb->skip = 1;\n}\n\nstatic av_always_inline\nvoid backup_mb_border(uint8_t *top_border, uint8_t *src_y,\n                      uint8_t *src_cb, uint8_t *src_cr,\n                      ptrdiff_t linesize, ptrdiff_t uvlinesize, int simple)\n{\n    AV_COPY128(top_border, src_y + 15 * linesize);\n    if (!simple) {\n        AV_COPY64(top_border + 16, src_cb + 7 * uvlinesize);\n        AV_COPY64(top_border + 24, src_cr + 7 * uvlinesize);\n    }\n}\n\nstatic av_always_inline\nvoid xchg_mb_border(uint8_t *top_border, uint8_t *src_y, uint8_t *src_cb,\n                    uint8_t *src_cr, ptrdiff_t linesize, ptrdiff_t uvlinesize, int mb_x,\n                    int mb_y, int mb_width, int simple, int xchg)\n{\n    uint8_t *top_border_m1 = top_border - 32;     // for TL prediction\n    src_y  -= linesize;\n    src_cb -= uvlinesize;\n    src_cr -= uvlinesize;\n\n#define XCHG(a, b, xchg)                                                      \\\n    do {                                                                      \\\n        if (xchg)                                                             \\\n            AV_SWAP64(b, a);                                                  \\\n        else                                                                  \\\n            AV_COPY64(b, a);                                                  \\\n    } while (0)\n\n    XCHG(top_border_m1 + 8, src_y - 8, xchg);\n    XCHG(top_border, src_y, xchg);\n    XCHG(top_border + 8, src_y + 8, 1);\n    if (mb_x < mb_width - 1)\n        XCHG(top_border + 32, src_y + 16, 1);\n\n    // only copy chroma for normal loop filter\n    // or to initialize the top row to 127\n    if (!simple || !mb_y) {\n        XCHG(top_border_m1 + 16, src_cb - 8, xchg);\n        XCHG(top_border_m1 + 24, src_cr - 8, xchg);\n        XCHG(top_border + 16, src_cb, 1);\n        XCHG(top_border + 24, src_cr, 1);\n    }\n}\n\nstatic av_always_inline\nint check_dc_pred8x8_mode(int mode, int mb_x, int mb_y)\n{\n    if (!mb_x)\n        return mb_y ? TOP_DC_PRED8x8 : DC_128_PRED8x8;\n    else\n        return mb_y ? mode : LEFT_DC_PRED8x8;\n}\n\nstatic av_always_inline\nint check_tm_pred8x8_mode(int mode, int mb_x, int mb_y, int vp7)\n{\n    if (!mb_x)\n        return mb_y ? VERT_PRED8x8 : (vp7 ? DC_128_PRED8x8 : DC_129_PRED8x8);\n    else\n        return mb_y ? mode : HOR_PRED8x8;\n}\n\nstatic av_always_inline\nint check_intra_pred8x8_mode_emuedge(int mode, int mb_x, int mb_y, int vp7)\n{\n    switch (mode) {\n    case DC_PRED8x8:\n        return check_dc_pred8x8_mode(mode, mb_x, mb_y);\n    case VERT_PRED8x8:\n        return !mb_y ? (vp7 ? DC_128_PRED8x8 : DC_127_PRED8x8) : mode;\n    case HOR_PRED8x8:\n        return !mb_x ? (vp7 ? DC_128_PRED8x8 : DC_129_PRED8x8) : mode;\n    case PLANE_PRED8x8: /* TM */\n        return check_tm_pred8x8_mode(mode, mb_x, mb_y, vp7);\n    }\n    return mode;\n}\n\nstatic av_always_inline\nint check_tm_pred4x4_mode(int mode, int mb_x, int mb_y, int vp7)\n{\n    if (!mb_x) {\n        return mb_y ? VERT_VP8_PRED : (vp7 ? DC_128_PRED : DC_129_PRED);\n    } else {\n        return mb_y ? mode : HOR_VP8_PRED;\n    }\n}\n\nstatic av_always_inline\nint check_intra_pred4x4_mode_emuedge(int mode, int mb_x, int mb_y,\n                                     int *copy_buf, int vp7)\n{\n    switch (mode) {\n    case VERT_PRED:\n        if (!mb_x && mb_y) {\n            *copy_buf = 1;\n            return mode;\n        }\n        /* fall-through */\n    case DIAG_DOWN_LEFT_PRED:\n    case VERT_LEFT_PRED:\n        return !mb_y ? (vp7 ? DC_128_PRED : DC_127_PRED) : mode;\n    case HOR_PRED:\n        if (!mb_y) {\n            *copy_buf = 1;\n            return mode;\n        }\n        /* fall-through */\n    case HOR_UP_PRED:\n        return !mb_x ? (vp7 ? DC_128_PRED : DC_129_PRED) : mode;\n    case TM_VP8_PRED:\n        return check_tm_pred4x4_mode(mode, mb_x, mb_y, vp7);\n    case DC_PRED: /* 4x4 DC doesn't use the same \"H.264-style\" exceptions\n                   * as 16x16/8x8 DC */\n    case DIAG_DOWN_RIGHT_PRED:\n    case VERT_RIGHT_PRED:\n    case HOR_DOWN_PRED:\n        if (!mb_y || !mb_x)\n            *copy_buf = 1;\n        return mode;\n    }\n    return mode;\n}\n\nstatic av_always_inline\nvoid intra_predict(VP8Context *s, VP8ThreadData *td, uint8_t *dst[3],\n                   VP8Macroblock *mb, int mb_x, int mb_y, int is_vp7)\n{\n    int x, y, mode, nnz;\n    uint32_t tr;\n\n    /* for the first row, we need to run xchg_mb_border to init the top edge\n     * to 127 otherwise, skip it if we aren't going to deblock */\n    if (mb_y && (s->deblock_filter || !mb_y) && td->thread_nr == 0)\n        xchg_mb_border(s->top_border[mb_x + 1], dst[0], dst[1], dst[2],\n                       s->linesize, s->uvlinesize, mb_x, mb_y, s->mb_width,\n                       s->filter.simple, 1);\n\n    if (mb->mode < MODE_I4x4) {\n        mode = check_intra_pred8x8_mode_emuedge(mb->mode, mb_x, mb_y, is_vp7);\n        s->hpc.pred16x16[mode](dst[0], s->linesize);\n    } else {\n        uint8_t *ptr = dst[0];\n        uint8_t *intra4x4 = mb->intra4x4_pred_mode_mb;\n        const uint8_t lo = is_vp7 ? 128 : 127;\n        const uint8_t hi = is_vp7 ? 128 : 129;\n        uint8_t tr_top[4] = { lo, lo, lo, lo };\n\n        // all blocks on the right edge of the macroblock use bottom edge\n        // the top macroblock for their topright edge\n        uint8_t *tr_right = ptr - s->linesize + 16;\n\n        // if we're on the right edge of the frame, said edge is extended\n        // from the top macroblock\n        if (mb_y && mb_x == s->mb_width - 1) {\n            tr       = tr_right[-1] * 0x01010101u;\n            tr_right = (uint8_t *) &tr;\n        }\n\n        if (mb->skip)\n            AV_ZERO128(td->non_zero_count_cache);\n\n        for (y = 0; y < 4; y++) {\n            uint8_t *topright = ptr + 4 - s->linesize;\n            for (x = 0; x < 4; x++) {\n                int copy = 0;\n                ptrdiff_t linesize = s->linesize;\n                uint8_t *dst = ptr + 4 * x;\n                LOCAL_ALIGNED(4, uint8_t, copy_dst, [5 * 8]);\n\n                if ((y == 0 || x == 3) && mb_y == 0) {\n                    topright = tr_top;\n                } else if (x == 3)\n                    topright = tr_right;\n\n                mode = check_intra_pred4x4_mode_emuedge(intra4x4[x], mb_x + x,\n                                                        mb_y + y, &copy, is_vp7);\n                if (copy) {\n                    dst      = copy_dst + 12;\n                    linesize = 8;\n                    if (!(mb_y + y)) {\n                        copy_dst[3] = lo;\n                        AV_WN32A(copy_dst + 4, lo * 0x01010101U);\n                    } else {\n                        AV_COPY32(copy_dst + 4, ptr + 4 * x - s->linesize);\n                        if (!(mb_x + x)) {\n                            copy_dst[3] = hi;\n                        } else {\n                            copy_dst[3] = ptr[4 * x - s->linesize - 1];\n                        }\n                    }\n                    if (!(mb_x + x)) {\n                        copy_dst[11] =\n                        copy_dst[19] =\n                        copy_dst[27] =\n                        copy_dst[35] = hi;\n                    } else {\n                        copy_dst[11] = ptr[4 * x                   - 1];\n                        copy_dst[19] = ptr[4 * x + s->linesize     - 1];\n                        copy_dst[27] = ptr[4 * x + s->linesize * 2 - 1];\n                        copy_dst[35] = ptr[4 * x + s->linesize * 3 - 1];\n                    }\n                }\n                s->hpc.pred4x4[mode](dst, topright, linesize);\n                if (copy) {\n                    AV_COPY32(ptr + 4 * x,                   copy_dst + 12);\n                    AV_COPY32(ptr + 4 * x + s->linesize,     copy_dst + 20);\n                    AV_COPY32(ptr + 4 * x + s->linesize * 2, copy_dst + 28);\n                    AV_COPY32(ptr + 4 * x + s->linesize * 3, copy_dst + 36);\n                }\n\n                nnz = td->non_zero_count_cache[y][x];\n                if (nnz) {\n                    if (nnz == 1)\n                        s->vp8dsp.vp8_idct_dc_add(ptr + 4 * x,\n                                                  td->block[y][x], s->linesize);\n                    else\n                        s->vp8dsp.vp8_idct_add(ptr + 4 * x,\n                                               td->block[y][x], s->linesize);\n                }\n                topright += 4;\n            }\n\n            ptr      += 4 * s->linesize;\n            intra4x4 += 4;\n        }\n    }\n\n    mode = check_intra_pred8x8_mode_emuedge(mb->chroma_pred_mode,\n                                            mb_x, mb_y, is_vp7);\n    s->hpc.pred8x8[mode](dst[1], s->uvlinesize);\n    s->hpc.pred8x8[mode](dst[2], s->uvlinesize);\n\n    if (mb_y && (s->deblock_filter || !mb_y) && td->thread_nr == 0)\n        xchg_mb_border(s->top_border[mb_x + 1], dst[0], dst[1], dst[2],\n                       s->linesize, s->uvlinesize, mb_x, mb_y, s->mb_width,\n                       s->filter.simple, 0);\n}\n\nstatic const uint8_t subpel_idx[3][8] = {\n    { 0, 1, 2, 1, 2, 1, 2, 1 }, // nr. of left extra pixels,\n                                // also function pointer index\n    { 0, 3, 5, 3, 5, 3, 5, 3 }, // nr. of extra pixels required\n    { 0, 2, 3, 2, 3, 2, 3, 2 }, // nr. of right extra pixels\n};\n\n/**\n * luma MC function\n *\n * @param s        VP8 decoding context\n * @param dst      target buffer for block data at block position\n * @param ref      reference picture buffer at origin (0, 0)\n * @param mv       motion vector (relative to block position) to get pixel data from\n * @param x_off    horizontal position of block from origin (0, 0)\n * @param y_off    vertical position of block from origin (0, 0)\n * @param block_w  width of block (16, 8 or 4)\n * @param block_h  height of block (always same as block_w)\n * @param width    width of src/dst plane data\n * @param height   height of src/dst plane data\n * @param linesize size of a single line of plane data, including padding\n * @param mc_func  motion compensation function pointers (bilinear or sixtap MC)\n */\nstatic av_always_inline\nvoid vp8_mc_luma(VP8Context *s, VP8ThreadData *td, uint8_t *dst,\n                 ThreadFrame *ref, const VP56mv *mv,\n                 int x_off, int y_off, int block_w, int block_h,\n                 int width, int height, ptrdiff_t linesize,\n                 vp8_mc_func mc_func[3][3])\n{\n    uint8_t *src = ref->f->data[0];\n\n    if (AV_RN32A(mv)) {\n        ptrdiff_t src_linesize = linesize;\n\n        int mx = (mv->x * 2) & 7, mx_idx = subpel_idx[0][mx];\n        int my = (mv->y * 2) & 7, my_idx = subpel_idx[0][my];\n\n        x_off += mv->x >> 2;\n        y_off += mv->y >> 2;\n\n        // edge emulation\n        ff_thread_await_progress(ref, (3 + y_off + block_h + subpel_idx[2][my]) >> 4, 0);\n        src += y_off * linesize + x_off;\n        if (x_off < mx_idx || x_off >= width  - block_w - subpel_idx[2][mx] ||\n            y_off < my_idx || y_off >= height - block_h - subpel_idx[2][my]) {\n            s->vdsp.emulated_edge_mc(td->edge_emu_buffer,\n                                     src - my_idx * linesize - mx_idx,\n                                     EDGE_EMU_LINESIZE, linesize,\n                                     block_w + subpel_idx[1][mx],\n                                     block_h + subpel_idx[1][my],\n                                     x_off - mx_idx, y_off - my_idx,\n                                     width, height);\n            src = td->edge_emu_buffer + mx_idx + EDGE_EMU_LINESIZE * my_idx;\n            src_linesize = EDGE_EMU_LINESIZE;\n        }\n        mc_func[my_idx][mx_idx](dst, linesize, src, src_linesize, block_h, mx, my);\n    } else {\n        ff_thread_await_progress(ref, (3 + y_off + block_h) >> 4, 0);\n        mc_func[0][0](dst, linesize, src + y_off * linesize + x_off,\n                      linesize, block_h, 0, 0);\n    }\n}\n\n/**\n * chroma MC function\n *\n * @param s        VP8 decoding context\n * @param dst1     target buffer for block data at block position (U plane)\n * @param dst2     target buffer for block data at block position (V plane)\n * @param ref      reference picture buffer at origin (0, 0)\n * @param mv       motion vector (relative to block position) to get pixel data from\n * @param x_off    horizontal position of block from origin (0, 0)\n * @param y_off    vertical position of block from origin (0, 0)\n * @param block_w  width of block (16, 8 or 4)\n * @param block_h  height of block (always same as block_w)\n * @param width    width of src/dst plane data\n * @param height   height of src/dst plane data\n * @param linesize size of a single line of plane data, including padding\n * @param mc_func  motion compensation function pointers (bilinear or sixtap MC)\n */\nstatic av_always_inline\nvoid vp8_mc_chroma(VP8Context *s, VP8ThreadData *td, uint8_t *dst1,\n                   uint8_t *dst2, ThreadFrame *ref, const VP56mv *mv,\n                   int x_off, int y_off, int block_w, int block_h,\n                   int width, int height, ptrdiff_t linesize,\n                   vp8_mc_func mc_func[3][3])\n{\n    uint8_t *src1 = ref->f->data[1], *src2 = ref->f->data[2];\n\n    if (AV_RN32A(mv)) {\n        int mx = mv->x & 7, mx_idx = subpel_idx[0][mx];\n        int my = mv->y & 7, my_idx = subpel_idx[0][my];\n\n        x_off += mv->x >> 3;\n        y_off += mv->y >> 3;\n\n        // edge emulation\n        src1 += y_off * linesize + x_off;\n        src2 += y_off * linesize + x_off;\n        ff_thread_await_progress(ref, (3 + y_off + block_h + subpel_idx[2][my]) >> 3, 0);\n        if (x_off < mx_idx || x_off >= width  - block_w - subpel_idx[2][mx] ||\n            y_off < my_idx || y_off >= height - block_h - subpel_idx[2][my]) {\n            s->vdsp.emulated_edge_mc(td->edge_emu_buffer,\n                                     src1 - my_idx * linesize - mx_idx,\n                                     EDGE_EMU_LINESIZE, linesize,\n                                     block_w + subpel_idx[1][mx],\n                                     block_h + subpel_idx[1][my],\n                                     x_off - mx_idx, y_off - my_idx, width, height);\n            src1 = td->edge_emu_buffer + mx_idx + EDGE_EMU_LINESIZE * my_idx;\n            mc_func[my_idx][mx_idx](dst1, linesize, src1, EDGE_EMU_LINESIZE, block_h, mx, my);\n\n            s->vdsp.emulated_edge_mc(td->edge_emu_buffer,\n                                     src2 - my_idx * linesize - mx_idx,\n                                     EDGE_EMU_LINESIZE, linesize,\n                                     block_w + subpel_idx[1][mx],\n                                     block_h + subpel_idx[1][my],\n                                     x_off - mx_idx, y_off - my_idx, width, height);\n            src2 = td->edge_emu_buffer + mx_idx + EDGE_EMU_LINESIZE * my_idx;\n            mc_func[my_idx][mx_idx](dst2, linesize, src2, EDGE_EMU_LINESIZE, block_h, mx, my);\n        } else {\n            mc_func[my_idx][mx_idx](dst1, linesize, src1, linesize, block_h, mx, my);\n            mc_func[my_idx][mx_idx](dst2, linesize, src2, linesize, block_h, mx, my);\n        }\n    } else {\n        ff_thread_await_progress(ref, (3 + y_off + block_h) >> 3, 0);\n        mc_func[0][0](dst1, linesize, src1 + y_off * linesize + x_off, linesize, block_h, 0, 0);\n        mc_func[0][0](dst2, linesize, src2 + y_off * linesize + x_off, linesize, block_h, 0, 0);\n    }\n}\n\nstatic av_always_inline\nvoid vp8_mc_part(VP8Context *s, VP8ThreadData *td, uint8_t *dst[3],\n                 ThreadFrame *ref_frame, int x_off, int y_off,\n                 int bx_off, int by_off, int block_w, int block_h,\n                 int width, int height, VP56mv *mv)\n{\n    VP56mv uvmv = *mv;\n\n    /* Y */\n    vp8_mc_luma(s, td, dst[0] + by_off * s->linesize + bx_off,\n                ref_frame, mv, x_off + bx_off, y_off + by_off,\n                block_w, block_h, width, height, s->linesize,\n                s->put_pixels_tab[block_w == 8]);\n\n    /* U/V */\n    if (s->profile == 3) {\n        /* this block only applies VP8; it is safe to check\n         * only the profile, as VP7 profile <= 1 */\n        uvmv.x &= ~7;\n        uvmv.y &= ~7;\n    }\n    x_off   >>= 1;\n    y_off   >>= 1;\n    bx_off  >>= 1;\n    by_off  >>= 1;\n    width   >>= 1;\n    height  >>= 1;\n    block_w >>= 1;\n    block_h >>= 1;\n    vp8_mc_chroma(s, td, dst[1] + by_off * s->uvlinesize + bx_off,\n                  dst[2] + by_off * s->uvlinesize + bx_off, ref_frame,\n                  &uvmv, x_off + bx_off, y_off + by_off,\n                  block_w, block_h, width, height, s->uvlinesize,\n                  s->put_pixels_tab[1 + (block_w == 4)]);\n}\n\n/* Fetch pixels for estimated mv 4 macroblocks ahead.\n * Optimized for 64-byte cache lines. Inspired by ffh264 prefetch_motion. */\nstatic av_always_inline\nvoid prefetch_motion(VP8Context *s, VP8Macroblock *mb, int mb_x, int mb_y,\n                     int mb_xy, int ref)\n{\n    /* Don't prefetch refs that haven't been used very often this frame. */\n    if (s->ref_count[ref - 1] > (mb_xy >> 5)) {\n        int x_off = mb_x << 4, y_off = mb_y << 4;\n        int mx = (mb->mv.x >> 2) + x_off + 8;\n        int my = (mb->mv.y >> 2) + y_off;\n        uint8_t **src = s->framep[ref]->tf.f->data;\n        int off = mx + (my + (mb_x & 3) * 4) * s->linesize + 64;\n        /* For threading, a ff_thread_await_progress here might be useful, but\n         * it actually slows down the decoder. Since a bad prefetch doesn't\n         * generate bad decoder output, we don't run it here. */\n        s->vdsp.prefetch(src[0] + off, s->linesize, 4);\n        off = (mx >> 1) + ((my >> 1) + (mb_x & 7)) * s->uvlinesize + 64;\n        s->vdsp.prefetch(src[1] + off, src[2] - src[1], 2);\n    }\n}\n\n/**\n * Apply motion vectors to prediction buffer, chapter 18.\n */\nstatic av_always_inline\nvoid inter_predict(VP8Context *s, VP8ThreadData *td, uint8_t *dst[3],\n                   VP8Macroblock *mb, int mb_x, int mb_y)\n{\n    int x_off = mb_x << 4, y_off = mb_y << 4;\n    int width = 16 * s->mb_width, height = 16 * s->mb_height;\n    ThreadFrame *ref = &s->framep[mb->ref_frame]->tf;\n    VP56mv *bmv = mb->bmv;\n\n    switch (mb->partitioning) {\n    case VP8_SPLITMVMODE_NONE:\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 0, 16, 16, width, height, &mb->mv);\n        break;\n    case VP8_SPLITMVMODE_4x4: {\n        int x, y;\n        VP56mv uvmv;\n\n        /* Y */\n        for (y = 0; y < 4; y++) {\n            for (x = 0; x < 4; x++) {\n                vp8_mc_luma(s, td, dst[0] + 4 * y * s->linesize + x * 4,\n                            ref, &bmv[4 * y + x],\n                            4 * x + x_off, 4 * y + y_off, 4, 4,\n                            width, height, s->linesize,\n                            s->put_pixels_tab[2]);\n            }\n        }\n\n        /* U/V */\n        x_off  >>= 1;\n        y_off  >>= 1;\n        width  >>= 1;\n        height >>= 1;\n        for (y = 0; y < 2; y++) {\n            for (x = 0; x < 2; x++) {\n                uvmv.x = mb->bmv[2 * y       * 4 + 2 * x    ].x +\n                         mb->bmv[2 * y       * 4 + 2 * x + 1].x +\n                         mb->bmv[(2 * y + 1) * 4 + 2 * x    ].x +\n                         mb->bmv[(2 * y + 1) * 4 + 2 * x + 1].x;\n                uvmv.y = mb->bmv[2 * y       * 4 + 2 * x    ].y +\n                         mb->bmv[2 * y       * 4 + 2 * x + 1].y +\n                         mb->bmv[(2 * y + 1) * 4 + 2 * x    ].y +\n                         mb->bmv[(2 * y + 1) * 4 + 2 * x + 1].y;\n                uvmv.x = (uvmv.x + 2 + FF_SIGNBIT(uvmv.x)) >> 2;\n                uvmv.y = (uvmv.y + 2 + FF_SIGNBIT(uvmv.y)) >> 2;\n                if (s->profile == 3) {\n                    uvmv.x &= ~7;\n                    uvmv.y &= ~7;\n                }\n                vp8_mc_chroma(s, td, dst[1] + 4 * y * s->uvlinesize + x * 4,\n                              dst[2] + 4 * y * s->uvlinesize + x * 4, ref,\n                              &uvmv, 4 * x + x_off, 4 * y + y_off, 4, 4,\n                              width, height, s->uvlinesize,\n                              s->put_pixels_tab[2]);\n            }\n        }\n        break;\n    }\n    case VP8_SPLITMVMODE_16x8:\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 0, 16, 8, width, height, &bmv[0]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 8, 16, 8, width, height, &bmv[1]);\n        break;\n    case VP8_SPLITMVMODE_8x16:\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 0, 8, 16, width, height, &bmv[0]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    8, 0, 8, 16, width, height, &bmv[1]);\n        break;\n    case VP8_SPLITMVMODE_8x8:\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 0, 8, 8, width, height, &bmv[0]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    8, 0, 8, 8, width, height, &bmv[1]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 8, 8, 8, width, height, &bmv[2]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    8, 8, 8, 8, width, height, &bmv[3]);\n        break;\n    }\n}\n\nstatic av_always_inline\nvoid idct_mb(VP8Context *s, VP8ThreadData *td, uint8_t *dst[3], VP8Macroblock *mb)\n{\n    int x, y, ch;\n\n    if (mb->mode != MODE_I4x4) {\n        uint8_t *y_dst = dst[0];\n        for (y = 0; y < 4; y++) {\n            uint32_t nnz4 = AV_RL32(td->non_zero_count_cache[y]);\n            if (nnz4) {\n                if (nnz4 & ~0x01010101) {\n                    for (x = 0; x < 4; x++) {\n                        if ((uint8_t) nnz4 == 1)\n                            s->vp8dsp.vp8_idct_dc_add(y_dst + 4 * x,\n                                                      td->block[y][x],\n                                                      s->linesize);\n                        else if ((uint8_t) nnz4 > 1)\n                            s->vp8dsp.vp8_idct_add(y_dst + 4 * x,\n                                                   td->block[y][x],\n                                                   s->linesize);\n                        nnz4 >>= 8;\n                        if (!nnz4)\n                            break;\n                    }\n                } else {\n                    s->vp8dsp.vp8_idct_dc_add4y(y_dst, td->block[y], s->linesize);\n                }\n            }\n            y_dst += 4 * s->linesize;\n        }\n    }\n\n    for (ch = 0; ch < 2; ch++) {\n        uint32_t nnz4 = AV_RL32(td->non_zero_count_cache[4 + ch]);\n        if (nnz4) {\n            uint8_t *ch_dst = dst[1 + ch];\n            if (nnz4 & ~0x01010101) {\n                for (y = 0; y < 2; y++) {\n                    for (x = 0; x < 2; x++) {\n                        if ((uint8_t) nnz4 == 1)\n                            s->vp8dsp.vp8_idct_dc_add(ch_dst + 4 * x,\n                                                      td->block[4 + ch][(y << 1) + x],\n                                                      s->uvlinesize);\n                        else if ((uint8_t) nnz4 > 1)\n                            s->vp8dsp.vp8_idct_add(ch_dst + 4 * x,\n                                                   td->block[4 + ch][(y << 1) + x],\n                                                   s->uvlinesize);\n                        nnz4 >>= 8;\n                        if (!nnz4)\n                            goto chroma_idct_end;\n                    }\n                    ch_dst += 4 * s->uvlinesize;\n                }\n            } else {\n                s->vp8dsp.vp8_idct_dc_add4uv(ch_dst, td->block[4 + ch], s->uvlinesize);\n            }\n        }\nchroma_idct_end:\n        ;\n    }\n}\n\nstatic av_always_inline\nvoid filter_level_for_mb(VP8Context *s, VP8Macroblock *mb,\n                         VP8FilterStrength *f, int is_vp7)\n{\n    int interior_limit, filter_level;\n\n    if (s->segmentation.enabled) {\n        filter_level = s->segmentation.filter_level[mb->segment];\n        if (!s->segmentation.absolute_vals)\n            filter_level += s->filter.level;\n    } else\n        filter_level = s->filter.level;\n\n    if (s->lf_delta.enabled) {\n        filter_level += s->lf_delta.ref[mb->ref_frame];\n        filter_level += s->lf_delta.mode[mb->mode];\n    }\n\n    filter_level = av_clip_uintp2(filter_level, 6);\n\n    interior_limit = filter_level;\n    if (s->filter.sharpness) {\n        interior_limit >>= (s->filter.sharpness + 3) >> 2;\n        interior_limit = FFMIN(interior_limit, 9 - s->filter.sharpness);\n    }\n    interior_limit = FFMAX(interior_limit, 1);\n\n    f->filter_level = filter_level;\n    f->inner_limit = interior_limit;\n    f->inner_filter = is_vp7 || !mb->skip || mb->mode == MODE_I4x4 ||\n                      mb->mode == VP8_MVMODE_SPLIT;\n}\n\nstatic av_always_inline\nvoid filter_mb(VP8Context *s, uint8_t *dst[3], VP8FilterStrength *f,\n               int mb_x, int mb_y, int is_vp7)\n{\n    int mbedge_lim, bedge_lim_y, bedge_lim_uv, hev_thresh;\n    int filter_level = f->filter_level;\n    int inner_limit = f->inner_limit;\n    int inner_filter = f->inner_filter;\n    ptrdiff_t linesize   = s->linesize;\n    ptrdiff_t uvlinesize = s->uvlinesize;\n    static const uint8_t hev_thresh_lut[2][64] = {\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n          3, 3, 3, 3 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2 }\n    };\n\n    if (!filter_level)\n        return;\n\n    if (is_vp7) {\n        bedge_lim_y  = filter_level;\n        bedge_lim_uv = filter_level * 2;\n        mbedge_lim   = filter_level + 2;\n    } else {\n        bedge_lim_y  =\n        bedge_lim_uv = filter_level * 2 + inner_limit;\n        mbedge_lim   = bedge_lim_y + 4;\n    }\n\n    hev_thresh = hev_thresh_lut[s->keyframe][filter_level];\n\n    if (mb_x) {\n        s->vp8dsp.vp8_h_loop_filter16y(dst[0], linesize,\n                                       mbedge_lim, inner_limit, hev_thresh);\n        s->vp8dsp.vp8_h_loop_filter8uv(dst[1], dst[2], uvlinesize,\n                                       mbedge_lim, inner_limit, hev_thresh);\n    }\n\n#define H_LOOP_FILTER_16Y_INNER(cond)                                         \\\n    if (cond && inner_filter) {                                               \\\n        s->vp8dsp.vp8_h_loop_filter16y_inner(dst[0] +  4, linesize,           \\\n                                             bedge_lim_y, inner_limit,        \\\n                                             hev_thresh);                     \\\n        s->vp8dsp.vp8_h_loop_filter16y_inner(dst[0] +  8, linesize,           \\\n                                             bedge_lim_y, inner_limit,        \\\n                                             hev_thresh);                     \\\n        s->vp8dsp.vp8_h_loop_filter16y_inner(dst[0] + 12, linesize,           \\\n                                             bedge_lim_y, inner_limit,        \\\n                                             hev_thresh);                     \\\n        s->vp8dsp.vp8_h_loop_filter8uv_inner(dst[1] +  4, dst[2] + 4,         \\\n                                             uvlinesize,  bedge_lim_uv,       \\\n                                             inner_limit, hev_thresh);        \\\n    }\n\n    H_LOOP_FILTER_16Y_INNER(!is_vp7)\n\n    if (mb_y) {\n        s->vp8dsp.vp8_v_loop_filter16y(dst[0], linesize,\n                                       mbedge_lim, inner_limit, hev_thresh);\n        s->vp8dsp.vp8_v_loop_filter8uv(dst[1], dst[2], uvlinesize,\n                                       mbedge_lim, inner_limit, hev_thresh);\n    }\n\n    if (inner_filter) {\n        s->vp8dsp.vp8_v_loop_filter16y_inner(dst[0] +  4 * linesize,\n                                             linesize, bedge_lim_y,\n                                             inner_limit, hev_thresh);\n        s->vp8dsp.vp8_v_loop_filter16y_inner(dst[0] +  8 * linesize,\n                                             linesize, bedge_lim_y,\n                                             inner_limit, hev_thresh);\n        s->vp8dsp.vp8_v_loop_filter16y_inner(dst[0] + 12 * linesize,\n                                             linesize, bedge_lim_y,\n                                             inner_limit, hev_thresh);\n        s->vp8dsp.vp8_v_loop_filter8uv_inner(dst[1] +  4 * uvlinesize,\n                                             dst[2] +  4 * uvlinesize,\n                                             uvlinesize, bedge_lim_uv,\n                                             inner_limit, hev_thresh);\n    }\n\n    H_LOOP_FILTER_16Y_INNER(is_vp7)\n}\n\nstatic av_always_inline\nvoid filter_mb_simple(VP8Context *s, uint8_t *dst, VP8FilterStrength *f,\n                      int mb_x, int mb_y)\n{\n    int mbedge_lim, bedge_lim;\n    int filter_level = f->filter_level;\n    int inner_limit  = f->inner_limit;\n    int inner_filter = f->inner_filter;\n    ptrdiff_t linesize = s->linesize;\n\n    if (!filter_level)\n        return;\n\n    bedge_lim  = 2 * filter_level + inner_limit;\n    mbedge_lim = bedge_lim + 4;\n\n    if (mb_x)\n        s->vp8dsp.vp8_h_loop_filter_simple(dst, linesize, mbedge_lim);\n    if (inner_filter) {\n        s->vp8dsp.vp8_h_loop_filter_simple(dst +  4, linesize, bedge_lim);\n        s->vp8dsp.vp8_h_loop_filter_simple(dst +  8, linesize, bedge_lim);\n        s->vp8dsp.vp8_h_loop_filter_simple(dst + 12, linesize, bedge_lim);\n    }\n\n    if (mb_y)\n        s->vp8dsp.vp8_v_loop_filter_simple(dst, linesize, mbedge_lim);\n    if (inner_filter) {\n        s->vp8dsp.vp8_v_loop_filter_simple(dst +  4 * linesize, linesize, bedge_lim);\n        s->vp8dsp.vp8_v_loop_filter_simple(dst +  8 * linesize, linesize, bedge_lim);\n        s->vp8dsp.vp8_v_loop_filter_simple(dst + 12 * linesize, linesize, bedge_lim);\n    }\n}\n\n#define MARGIN (16 << 2)\nstatic av_always_inline\nvoid vp78_decode_mv_mb_modes(AVCodecContext *avctx, VP8Frame *curframe,\n                                    VP8Frame *prev_frame, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    int mb_x, mb_y;\n\n    s->mv_bounds.mv_min.y = -MARGIN;\n    s->mv_bounds.mv_max.y = ((s->mb_height - 1) << 6) + MARGIN;\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n        VP8Macroblock *mb = s->macroblocks_base +\n                            ((s->mb_width + 1) * (mb_y + 1) + 1);\n        int mb_xy = mb_y * s->mb_width;\n\n        AV_WN32A(s->intra4x4_pred_mode_left, DC_PRED * 0x01010101);\n\n        s->mv_bounds.mv_min.x = -MARGIN;\n        s->mv_bounds.mv_max.x = ((s->mb_width - 1) << 6) + MARGIN;\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++, mb_xy++, mb++) {\n            if (mb_y == 0)\n                AV_WN32A((mb - s->mb_width - 1)->intra4x4_pred_mode_top,\n                         DC_PRED * 0x01010101);\n            decode_mb_mode(s, &s->mv_bounds, mb, mb_x, mb_y, curframe->seg_map->data + mb_xy,\n                           prev_frame && prev_frame->seg_map ?\n                           prev_frame->seg_map->data + mb_xy : NULL, 1, is_vp7);\n            s->mv_bounds.mv_min.x -= 64;\n            s->mv_bounds.mv_max.x -= 64;\n        }\n        s->mv_bounds.mv_min.y -= 64;\n        s->mv_bounds.mv_max.y -= 64;\n    }\n}\n\nstatic void vp7_decode_mv_mb_modes(AVCodecContext *avctx, VP8Frame *cur_frame,\n                                   VP8Frame *prev_frame)\n{\n    vp78_decode_mv_mb_modes(avctx, cur_frame, prev_frame, IS_VP7);\n}\n\nstatic void vp8_decode_mv_mb_modes(AVCodecContext *avctx, VP8Frame *cur_frame,\n                                   VP8Frame *prev_frame)\n{\n    vp78_decode_mv_mb_modes(avctx, cur_frame, prev_frame, IS_VP8);\n}\n\n#if HAVE_THREADS\n#define check_thread_pos(td, otd, mb_x_check, mb_y_check)                     \\\n    do {                                                                      \\\n        int tmp = (mb_y_check << 16) | (mb_x_check & 0xFFFF);                 \\\n        if (atomic_load(&otd->thread_mb_pos) < tmp) {                         \\\n            pthread_mutex_lock(&otd->lock);                                   \\\n            atomic_store(&td->wait_mb_pos, tmp);                              \\\n            do {                                                              \\\n                if (atomic_load(&otd->thread_mb_pos) >= tmp)                  \\\n                    break;                                                    \\\n                pthread_cond_wait(&otd->cond, &otd->lock);                    \\\n            } while (1);                                                      \\\n            atomic_store(&td->wait_mb_pos, INT_MAX);                          \\\n            pthread_mutex_unlock(&otd->lock);                                 \\\n        }                                                                     \\\n    } while (0)\n\n#define update_pos(td, mb_y, mb_x)                                            \\\n    do {                                                                      \\\n        int pos              = (mb_y << 16) | (mb_x & 0xFFFF);                \\\n        int sliced_threading = (avctx->active_thread_type == FF_THREAD_SLICE) && \\\n                               (num_jobs > 1);                                \\\n        int is_null          = !next_td || !prev_td;                          \\\n        int pos_check        = (is_null) ? 1 :                                \\\n            (next_td != td && pos >= atomic_load(&next_td->wait_mb_pos)) ||   \\\n            (prev_td != td && pos >= atomic_load(&prev_td->wait_mb_pos));     \\\n        atomic_store(&td->thread_mb_pos, pos);                                \\\n        if (sliced_threading && pos_check) {                                  \\\n            pthread_mutex_lock(&td->lock);                                    \\\n            pthread_cond_broadcast(&td->cond);                                \\\n            pthread_mutex_unlock(&td->lock);                                  \\\n        }                                                                     \\\n    } while (0)\n#else\n#define check_thread_pos(td, otd, mb_x_check, mb_y_check) while(0)\n#define update_pos(td, mb_y, mb_x) while(0)\n#endif\n\nstatic av_always_inline int decode_mb_row_no_filter(AVCodecContext *avctx, void *tdata,\n                                        int jobnr, int threadnr, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    VP8ThreadData *prev_td, *next_td, *td = &s->thread_data[threadnr];\n    int mb_y = atomic_load(&td->thread_mb_pos) >> 16;\n    int mb_x, mb_xy = mb_y * s->mb_width;\n    int num_jobs = s->num_jobs;\n    VP8Frame *curframe = s->curframe, *prev_frame = s->prev_frame;\n    VP56RangeCoder *c  = &s->coeff_partition[mb_y & (s->num_coeff_partitions - 1)];\n    VP8Macroblock *mb;\n    uint8_t *dst[3] = {\n        curframe->tf.f->data[0] + 16 * mb_y * s->linesize,\n        curframe->tf.f->data[1] +  8 * mb_y * s->uvlinesize,\n        curframe->tf.f->data[2] +  8 * mb_y * s->uvlinesize\n    };\n\n    if (c->end <= c->buffer && c->bits >= 0)\n         return AVERROR_INVALIDDATA;\n\n    if (mb_y == 0)\n        prev_td = td;\n    else\n        prev_td = &s->thread_data[(jobnr + num_jobs - 1) % num_jobs];\n    if (mb_y == s->mb_height - 1)\n        next_td = td;\n    else\n        next_td = &s->thread_data[(jobnr + 1) % num_jobs];\n    if (s->mb_layout == 1)\n        mb = s->macroblocks_base + ((s->mb_width + 1) * (mb_y + 1) + 1);\n    else {\n        // Make sure the previous frame has read its segmentation map,\n        // if we re-use the same map.\n        if (prev_frame && s->segmentation.enabled &&\n            !s->segmentation.update_map)\n            ff_thread_await_progress(&prev_frame->tf, mb_y, 0);\n        mb = s->macroblocks + (s->mb_height - mb_y - 1) * 2;\n        memset(mb - 1, 0, sizeof(*mb)); // zero left macroblock\n        AV_WN32A(s->intra4x4_pred_mode_left, DC_PRED * 0x01010101);\n    }\n\n    if (!is_vp7 || mb_y == 0)\n        memset(td->left_nnz, 0, sizeof(td->left_nnz));\n\n    td->mv_bounds.mv_min.x = -MARGIN;\n    td->mv_bounds.mv_max.x = ((s->mb_width - 1) << 6) + MARGIN;\n\n    for (mb_x = 0; mb_x < s->mb_width; mb_x++, mb_xy++, mb++) {\n        if (c->end <= c->buffer && c->bits >= 0)\n            return AVERROR_INVALIDDATA;\n        // Wait for previous thread to read mb_x+2, and reach mb_y-1.\n        if (prev_td != td) {\n            if (threadnr != 0) {\n                check_thread_pos(td, prev_td,\n                                 mb_x + (is_vp7 ? 2 : 1),\n                                 mb_y - (is_vp7 ? 2 : 1));\n            } else {\n                check_thread_pos(td, prev_td,\n                                 mb_x + (is_vp7 ? 2 : 1) + s->mb_width + 3,\n                                 mb_y - (is_vp7 ? 2 : 1));\n            }\n        }\n\n        s->vdsp.prefetch(dst[0] + (mb_x & 3) * 4 * s->linesize + 64,\n                         s->linesize, 4);\n        s->vdsp.prefetch(dst[1] + (mb_x & 7) * s->uvlinesize + 64,\n                         dst[2] - dst[1], 2);\n\n        if (!s->mb_layout)\n            decode_mb_mode(s, &td->mv_bounds, mb, mb_x, mb_y, curframe->seg_map->data + mb_xy,\n                           prev_frame && prev_frame->seg_map ?\n                           prev_frame->seg_map->data + mb_xy : NULL, 0, is_vp7);\n\n        prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_PREVIOUS);\n\n        if (!mb->skip)\n            decode_mb_coeffs(s, td, c, mb, s->top_nnz[mb_x], td->left_nnz, is_vp7);\n\n        if (mb->mode <= MODE_I4x4)\n            intra_predict(s, td, dst, mb, mb_x, mb_y, is_vp7);\n        else\n            inter_predict(s, td, dst, mb, mb_x, mb_y);\n\n        prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_GOLDEN);\n\n        if (!mb->skip) {\n            idct_mb(s, td, dst, mb);\n        } else {\n            AV_ZERO64(td->left_nnz);\n            AV_WN64(s->top_nnz[mb_x], 0);   // array of 9, so unaligned\n\n            /* Reset DC block predictors if they would exist\n             * if the mb had coefficients */\n            if (mb->mode != MODE_I4x4 && mb->mode != VP8_MVMODE_SPLIT) {\n                td->left_nnz[8]     = 0;\n                s->top_nnz[mb_x][8] = 0;\n            }\n        }\n\n        if (s->deblock_filter)\n            filter_level_for_mb(s, mb, &td->filter_strength[mb_x], is_vp7);\n\n        if (s->deblock_filter && num_jobs != 1 && threadnr == num_jobs - 1) {\n            if (s->filter.simple)\n                backup_mb_border(s->top_border[mb_x + 1], dst[0],\n                                 NULL, NULL, s->linesize, 0, 1);\n            else\n                backup_mb_border(s->top_border[mb_x + 1], dst[0],\n                                 dst[1], dst[2], s->linesize, s->uvlinesize, 0);\n        }\n\n        prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_GOLDEN2);\n\n        dst[0]      += 16;\n        dst[1]      += 8;\n        dst[2]      += 8;\n        td->mv_bounds.mv_min.x -= 64;\n        td->mv_bounds.mv_max.x -= 64;\n\n        if (mb_x == s->mb_width + 1) {\n            update_pos(td, mb_y, s->mb_width + 3);\n        } else {\n            update_pos(td, mb_y, mb_x);\n        }\n    }\n    return 0;\n}\n\nstatic int vp7_decode_mb_row_no_filter(AVCodecContext *avctx, void *tdata,\n                                        int jobnr, int threadnr)\n{\n    return decode_mb_row_no_filter(avctx, tdata, jobnr, threadnr, 1);\n}\n\nstatic int vp8_decode_mb_row_no_filter(AVCodecContext *avctx, void *tdata,\n                                        int jobnr, int threadnr)\n{\n    return decode_mb_row_no_filter(avctx, tdata, jobnr, threadnr, 0);\n}\n\nstatic av_always_inline void filter_mb_row(AVCodecContext *avctx, void *tdata,\n                              int jobnr, int threadnr, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    VP8ThreadData *td = &s->thread_data[threadnr];\n    int mb_x, mb_y = atomic_load(&td->thread_mb_pos) >> 16, num_jobs = s->num_jobs;\n    AVFrame *curframe = s->curframe->tf.f;\n    VP8Macroblock *mb;\n    VP8ThreadData *prev_td, *next_td;\n    uint8_t *dst[3] = {\n        curframe->data[0] + 16 * mb_y * s->linesize,\n        curframe->data[1] +  8 * mb_y * s->uvlinesize,\n        curframe->data[2] +  8 * mb_y * s->uvlinesize\n    };\n\n    if (s->mb_layout == 1)\n        mb = s->macroblocks_base + ((s->mb_width + 1) * (mb_y + 1) + 1);\n    else\n        mb = s->macroblocks + (s->mb_height - mb_y - 1) * 2;\n\n    if (mb_y == 0)\n        prev_td = td;\n    else\n        prev_td = &s->thread_data[(jobnr + num_jobs - 1) % num_jobs];\n    if (mb_y == s->mb_height - 1)\n        next_td = td;\n    else\n        next_td = &s->thread_data[(jobnr + 1) % num_jobs];\n\n    for (mb_x = 0; mb_x < s->mb_width; mb_x++, mb++) {\n        VP8FilterStrength *f = &td->filter_strength[mb_x];\n        if (prev_td != td)\n            check_thread_pos(td, prev_td,\n                             (mb_x + 1) + (s->mb_width + 3), mb_y - 1);\n        if (next_td != td)\n            if (next_td != &s->thread_data[0])\n                check_thread_pos(td, next_td, mb_x + 1, mb_y + 1);\n\n        if (num_jobs == 1) {\n            if (s->filter.simple)\n                backup_mb_border(s->top_border[mb_x + 1], dst[0],\n                                 NULL, NULL, s->linesize, 0, 1);\n            else\n                backup_mb_border(s->top_border[mb_x + 1], dst[0],\n                                 dst[1], dst[2], s->linesize, s->uvlinesize, 0);\n        }\n\n        if (s->filter.simple)\n            filter_mb_simple(s, dst[0], f, mb_x, mb_y);\n        else\n            filter_mb(s, dst, f, mb_x, mb_y, is_vp7);\n        dst[0] += 16;\n        dst[1] += 8;\n        dst[2] += 8;\n\n        update_pos(td, mb_y, (s->mb_width + 3) + mb_x);\n    }\n}\n\nstatic void vp7_filter_mb_row(AVCodecContext *avctx, void *tdata,\n                              int jobnr, int threadnr)\n{\n    filter_mb_row(avctx, tdata, jobnr, threadnr, 1);\n}\n\nstatic void vp8_filter_mb_row(AVCodecContext *avctx, void *tdata,\n                              int jobnr, int threadnr)\n{\n    filter_mb_row(avctx, tdata, jobnr, threadnr, 0);\n}\n\nstatic av_always_inline\nint vp78_decode_mb_row_sliced(AVCodecContext *avctx, void *tdata, int jobnr,\n                              int threadnr, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    VP8ThreadData *td = &s->thread_data[jobnr];\n    VP8ThreadData *next_td = NULL, *prev_td = NULL;\n    VP8Frame *curframe = s->curframe;\n    int mb_y, num_jobs = s->num_jobs;\n    int ret;\n\n    td->thread_nr = threadnr;\n    td->mv_bounds.mv_min.y   = -MARGIN - 64 * threadnr;\n    td->mv_bounds.mv_max.y   = ((s->mb_height - 1) << 6) + MARGIN - 64 * threadnr;\n    for (mb_y = jobnr; mb_y < s->mb_height; mb_y += num_jobs) {\n        atomic_store(&td->thread_mb_pos, mb_y << 16);\n        ret = s->decode_mb_row_no_filter(avctx, tdata, jobnr, threadnr);\n        if (ret < 0) {\n            update_pos(td, s->mb_height, INT_MAX & 0xFFFF);\n            return ret;\n        }\n        if (s->deblock_filter)\n            s->filter_mb_row(avctx, tdata, jobnr, threadnr);\n        update_pos(td, mb_y, INT_MAX & 0xFFFF);\n\n        td->mv_bounds.mv_min.y -= 64 * num_jobs;\n        td->mv_bounds.mv_max.y -= 64 * num_jobs;\n\n        if (avctx->active_thread_type == FF_THREAD_FRAME)\n            ff_thread_report_progress(&curframe->tf, mb_y, 0);\n    }\n\n    return 0;\n}\n\nstatic int vp7_decode_mb_row_sliced(AVCodecContext *avctx, void *tdata,\n                                    int jobnr, int threadnr)\n{\n    return vp78_decode_mb_row_sliced(avctx, tdata, jobnr, threadnr, IS_VP7);\n}\n\nstatic int vp8_decode_mb_row_sliced(AVCodecContext *avctx, void *tdata,\n                                    int jobnr, int threadnr)\n{\n    return vp78_decode_mb_row_sliced(avctx, tdata, jobnr, threadnr, IS_VP8);\n}\n\n\nstatic av_always_inline\nint vp78_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                      AVPacket *avpkt, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    int ret, i, referenced, num_jobs;\n    enum AVDiscard skip_thresh;\n    VP8Frame *av_uninit(curframe), *prev_frame;\n\n    if (is_vp7)\n        ret = vp7_decode_frame_header(s, avpkt->data, avpkt->size);\n    else\n        ret = vp8_decode_frame_header(s, avpkt->data, avpkt->size);\n\n    if (ret < 0)\n        goto err;\n\n    prev_frame = s->framep[VP56_FRAME_CURRENT];\n\n    referenced = s->update_last || s->update_golden == VP56_FRAME_CURRENT ||\n                 s->update_altref == VP56_FRAME_CURRENT;\n\n    skip_thresh = !referenced ? AVDISCARD_NONREF\n                              : !s->keyframe ? AVDISCARD_NONKEY\n                                             : AVDISCARD_ALL;\n\n    if (avctx->skip_frame >= skip_thresh) {\n        s->invisible = 1;\n        memcpy(&s->next_framep[0], &s->framep[0], sizeof(s->framep[0]) * 4);\n        goto skip_decode;\n    }\n    s->deblock_filter = s->filter.level && avctx->skip_loop_filter < skip_thresh;\n\n    // release no longer referenced frames\n    for (i = 0; i < 5; i++)\n        if (s->frames[i].tf.f->data[0] &&\n            &s->frames[i] != prev_frame &&\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN]   &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2])\n            vp8_release_frame(s, &s->frames[i]);\n\n    curframe = s->framep[VP56_FRAME_CURRENT] = vp8_find_free_buffer(s);\n\n    if (!s->colorspace)\n        avctx->colorspace = AVCOL_SPC_BT470BG;\n    if (s->fullrange)\n        avctx->color_range = AVCOL_RANGE_JPEG;\n    else\n        avctx->color_range = AVCOL_RANGE_MPEG;\n\n    /* Given that arithmetic probabilities are updated every frame, it's quite\n     * likely that the values we have on a random interframe are complete\n     * junk if we didn't start decode on a keyframe. So just don't display\n     * anything rather than junk. */\n    if (!s->keyframe && (!s->framep[VP56_FRAME_PREVIOUS] ||\n                         !s->framep[VP56_FRAME_GOLDEN]   ||\n                         !s->framep[VP56_FRAME_GOLDEN2])) {\n        av_log(avctx, AV_LOG_WARNING,\n               \"Discarding interframe without a prior keyframe!\\n\");\n        ret = AVERROR_INVALIDDATA;\n        goto err;\n    }\n\n    curframe->tf.f->key_frame = s->keyframe;\n    curframe->tf.f->pict_type = s->keyframe ? AV_PICTURE_TYPE_I\n                                            : AV_PICTURE_TYPE_P;\n    if ((ret = vp8_alloc_frame(s, curframe, referenced)) < 0)\n        goto err;\n\n    // check if golden and altref are swapped\n    if (s->update_altref != VP56_FRAME_NONE)\n        s->next_framep[VP56_FRAME_GOLDEN2] = s->framep[s->update_altref];\n    else\n        s->next_framep[VP56_FRAME_GOLDEN2] = s->framep[VP56_FRAME_GOLDEN2];\n\n    if (s->update_golden != VP56_FRAME_NONE)\n        s->next_framep[VP56_FRAME_GOLDEN] = s->framep[s->update_golden];\n    else\n        s->next_framep[VP56_FRAME_GOLDEN] = s->framep[VP56_FRAME_GOLDEN];\n\n    if (s->update_last)\n        s->next_framep[VP56_FRAME_PREVIOUS] = curframe;\n    else\n        s->next_framep[VP56_FRAME_PREVIOUS] = s->framep[VP56_FRAME_PREVIOUS];\n\n    s->next_framep[VP56_FRAME_CURRENT] = curframe;\n\n    if (avctx->codec->update_thread_context)\n        ff_thread_finish_setup(avctx);\n\n    s->linesize   = curframe->tf.f->linesize[0];\n    s->uvlinesize = curframe->tf.f->linesize[1];\n\n    memset(s->top_nnz, 0, s->mb_width * sizeof(*s->top_nnz));\n    /* Zero macroblock structures for top/top-left prediction\n     * from outside the frame. */\n    if (!s->mb_layout)\n        memset(s->macroblocks + s->mb_height * 2 - 1, 0,\n               (s->mb_width + 1) * sizeof(*s->macroblocks));\n    if (!s->mb_layout && s->keyframe)\n        memset(s->intra4x4_pred_mode_top, DC_PRED, s->mb_width * 4);\n\n    memset(s->ref_count, 0, sizeof(s->ref_count));\n\n    if (s->mb_layout == 1) {\n        // Make sure the previous frame has read its segmentation map,\n        // if we re-use the same map.\n        if (prev_frame && s->segmentation.enabled &&\n            !s->segmentation.update_map)\n            ff_thread_await_progress(&prev_frame->tf, 1, 0);\n        if (is_vp7)\n            vp7_decode_mv_mb_modes(avctx, curframe, prev_frame);\n        else\n            vp8_decode_mv_mb_modes(avctx, curframe, prev_frame);\n    }\n\n    if (avctx->active_thread_type == FF_THREAD_FRAME)\n        num_jobs = 1;\n    else\n        num_jobs = FFMIN(s->num_coeff_partitions, avctx->thread_count);\n    s->num_jobs   = num_jobs;\n    s->curframe   = curframe;\n    s->prev_frame = prev_frame;\n    s->mv_bounds.mv_min.y   = -MARGIN;\n    s->mv_bounds.mv_max.y   = ((s->mb_height - 1) << 6) + MARGIN;\n    for (i = 0; i < MAX_THREADS; i++) {\n        VP8ThreadData *td = &s->thread_data[i];\n        atomic_init(&td->thread_mb_pos, 0);\n        atomic_init(&td->wait_mb_pos, INT_MAX);\n    }\n    if (is_vp7)\n        avctx->execute2(avctx, vp7_decode_mb_row_sliced, s->thread_data, NULL,\n                        num_jobs);\n    else\n        avctx->execute2(avctx, vp8_decode_mb_row_sliced, s->thread_data, NULL,\n                        num_jobs);\n\n    ff_thread_report_progress(&curframe->tf, INT_MAX, 0);\n    memcpy(&s->framep[0], &s->next_framep[0], sizeof(s->framep[0]) * 4);\n\nskip_decode:\n    // if future frames don't use the updated probabilities,\n    // reset them to the values we saved\n    if (!s->update_probabilities)\n        s->prob[0] = s->prob[1];\n\n    if (!s->invisible) {\n        if ((ret = av_frame_ref(data, curframe->tf.f)) < 0)\n            return ret;\n        *got_frame = 1;\n    }\n\n    return avpkt->size;\nerr:\n    memcpy(&s->next_framep[0], &s->framep[0], sizeof(s->framep[0]) * 4);\n    return ret;\n}\n\nint ff_vp8_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                        AVPacket *avpkt)\n{\n    return vp78_decode_frame(avctx, data, got_frame, avpkt, IS_VP8);\n}\n\n#if CONFIG_VP7_DECODER\nstatic int vp7_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                            AVPacket *avpkt)\n{\n    return vp78_decode_frame(avctx, data, got_frame, avpkt, IS_VP7);\n}\n#endif /* CONFIG_VP7_DECODER */\n\nav_cold int ff_vp8_decode_free(AVCodecContext *avctx)\n{\n    VP8Context *s = avctx->priv_data;\n    int i;\n\n    if (!s)\n        return 0;\n\n    vp8_decode_flush_impl(avctx, 1);\n    for (i = 0; i < FF_ARRAY_ELEMS(s->frames); i++)\n        av_frame_free(&s->frames[i].tf.f);\n\n    return 0;\n}\n\nstatic av_cold int vp8_init_frames(VP8Context *s)\n{\n    int i;\n    for (i = 0; i < FF_ARRAY_ELEMS(s->frames); i++) {\n        s->frames[i].tf.f = av_frame_alloc();\n        if (!s->frames[i].tf.f)\n            return AVERROR(ENOMEM);\n    }\n    return 0;\n}\n\nstatic av_always_inline\nint vp78_decode_init(AVCodecContext *avctx, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    int ret;\n\n    s->avctx = avctx;\n    s->vp7   = avctx->codec->id == AV_CODEC_ID_VP7;\n    avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n    avctx->internal->allocate_progress = 1;\n\n    ff_videodsp_init(&s->vdsp, 8);\n\n    ff_vp78dsp_init(&s->vp8dsp);\n    if (CONFIG_VP7_DECODER && is_vp7) {\n        ff_h264_pred_init(&s->hpc, AV_CODEC_ID_VP7, 8, 1);\n        ff_vp7dsp_init(&s->vp8dsp);\n        s->decode_mb_row_no_filter = vp7_decode_mb_row_no_filter;\n        s->filter_mb_row           = vp7_filter_mb_row;\n    } else if (CONFIG_VP8_DECODER && !is_vp7) {\n        ff_h264_pred_init(&s->hpc, AV_CODEC_ID_VP8, 8, 1);\n        ff_vp8dsp_init(&s->vp8dsp);\n        s->decode_mb_row_no_filter = vp8_decode_mb_row_no_filter;\n        s->filter_mb_row           = vp8_filter_mb_row;\n    }\n\n    /* does not change for VP8 */\n    memcpy(s->prob[0].scan, ff_zigzag_scan, sizeof(s->prob[0].scan));\n\n    if ((ret = vp8_init_frames(s)) < 0) {\n        ff_vp8_decode_free(avctx);\n        return ret;\n    }\n\n    return 0;\n}\n\n#if CONFIG_VP7_DECODER\nstatic int vp7_decode_init(AVCodecContext *avctx)\n{\n    return vp78_decode_init(avctx, IS_VP7);\n}\n#endif /* CONFIG_VP7_DECODER */\n\nav_cold int ff_vp8_decode_init(AVCodecContext *avctx)\n{\n    return vp78_decode_init(avctx, IS_VP8);\n}\n\n#if CONFIG_VP8_DECODER\n#if HAVE_THREADS\nstatic av_cold int vp8_decode_init_thread_copy(AVCodecContext *avctx)\n{\n    VP8Context *s = avctx->priv_data;\n    int ret;\n\n    s->avctx = avctx;\n\n    if ((ret = vp8_init_frames(s)) < 0) {\n        ff_vp8_decode_free(avctx);\n        return ret;\n    }\n\n    return 0;\n}\n\n#define REBASE(pic) ((pic) ? (pic) - &s_src->frames[0] + &s->frames[0] : NULL)\n\nstatic int vp8_decode_update_thread_context(AVCodecContext *dst,\n                                            const AVCodecContext *src)\n{\n    VP8Context *s = dst->priv_data, *s_src = src->priv_data;\n    int i;\n\n    if (s->macroblocks_base &&\n        (s_src->mb_width != s->mb_width || s_src->mb_height != s->mb_height)) {\n        free_buffers(s);\n        s->mb_width  = s_src->mb_width;\n        s->mb_height = s_src->mb_height;\n    }\n\n    s->prob[0]      = s_src->prob[!s_src->update_probabilities];\n    s->segmentation = s_src->segmentation;\n    s->lf_delta     = s_src->lf_delta;\n    memcpy(s->sign_bias, s_src->sign_bias, sizeof(s->sign_bias));\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s_src->frames); i++) {\n        if (s_src->frames[i].tf.f->data[0]) {\n            int ret = vp8_ref_frame(s, &s->frames[i], &s_src->frames[i]);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    s->framep[0] = REBASE(s_src->next_framep[0]);\n    s->framep[1] = REBASE(s_src->next_framep[1]);\n    s->framep[2] = REBASE(s_src->next_framep[2]);\n    s->framep[3] = REBASE(s_src->next_framep[3]);\n\n    return 0;\n}\n#endif /* HAVE_THREADS */\n#endif /* CONFIG_VP8_DECODER */\n\n#if CONFIG_VP7_DECODER\nAVCodec ff_vp7_decoder = {\n    .name                  = \"vp7\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"On2 VP7\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_VP7,\n    .priv_data_size        = sizeof(VP8Context),\n    .init                  = vp7_decode_init,\n    .close                 = ff_vp8_decode_free,\n    .decode                = vp7_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1,\n    .flush                 = vp8_decode_flush,\n};\n#endif /* CONFIG_VP7_DECODER */\n\n#if CONFIG_VP8_DECODER\nAVCodec ff_vp8_decoder = {\n    .name                  = \"vp8\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"On2 VP8\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_VP8,\n    .priv_data_size        = sizeof(VP8Context),\n    .init                  = ff_vp8_decode_init,\n    .close                 = ff_vp8_decode_free,\n    .decode                = ff_vp8_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_FRAME_THREADS |\n                             AV_CODEC_CAP_SLICE_THREADS,\n    .flush                 = vp8_decode_flush,\n    .init_thread_copy      = ONLY_IF_THREADS_ENABLED(vp8_decode_init_thread_copy),\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(vp8_decode_update_thread_context),\n};\n#endif /* CONFIG_VP7_DECODER */\n", "/*\n * WebP (.webp) image decoder\n * Copyright (c) 2013 Aneesh Dogra <aneesh@sugarlabs.org>\n * Copyright (c) 2013 Justin Ruggles <justin.ruggles@gmail.com>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * WebP image decoder\n *\n * @author Aneesh Dogra <aneesh@sugarlabs.org>\n * Container and Lossy decoding\n *\n * @author Justin Ruggles <justin.ruggles@gmail.com>\n * Lossless decoder\n * Compressed alpha for lossy\n *\n * @author James Almer <jamrial@gmail.com>\n * Exif metadata\n *\n * Unimplemented:\n *   - Animation\n *   - ICC profile\n *   - XMP metadata\n */\n\n#include \"libavutil/imgutils.h\"\n\n#define BITSTREAM_READER_LE\n#include \"avcodec.h\"\n#include \"bytestream.h\"\n#include \"exif.h\"\n#include \"get_bits.h\"\n#include \"internal.h\"\n#include \"thread.h\"\n#include \"vp8.h\"\n\n#define VP8X_FLAG_ANIMATION             0x02\n#define VP8X_FLAG_XMP_METADATA          0x04\n#define VP8X_FLAG_EXIF_METADATA         0x08\n#define VP8X_FLAG_ALPHA                 0x10\n#define VP8X_FLAG_ICC                   0x20\n\n#define MAX_PALETTE_SIZE                256\n#define MAX_CACHE_BITS                  11\n#define NUM_CODE_LENGTH_CODES           19\n#define HUFFMAN_CODES_PER_META_CODE     5\n#define NUM_LITERAL_CODES               256\n#define NUM_LENGTH_CODES                24\n#define NUM_DISTANCE_CODES              40\n#define NUM_SHORT_DISTANCES             120\n#define MAX_HUFFMAN_CODE_LENGTH         15\n\nstatic const uint16_t alphabet_sizes[HUFFMAN_CODES_PER_META_CODE] = {\n    NUM_LITERAL_CODES + NUM_LENGTH_CODES,\n    NUM_LITERAL_CODES, NUM_LITERAL_CODES, NUM_LITERAL_CODES,\n    NUM_DISTANCE_CODES\n};\n\nstatic const uint8_t code_length_code_order[NUM_CODE_LENGTH_CODES] = {\n    17, 18, 0, 1, 2, 3, 4, 5, 16, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n};\n\nstatic const int8_t lz77_distance_offsets[NUM_SHORT_DISTANCES][2] = {\n    {  0, 1 }, {  1, 0 }, {  1, 1 }, { -1, 1 }, {  0, 2 }, {  2, 0 }, {  1, 2 }, { -1, 2 },\n    {  2, 1 }, { -2, 1 }, {  2, 2 }, { -2, 2 }, {  0, 3 }, {  3, 0 }, {  1, 3 }, { -1, 3 },\n    {  3, 1 }, { -3, 1 }, {  2, 3 }, { -2, 3 }, {  3, 2 }, { -3, 2 }, {  0, 4 }, {  4, 0 },\n    {  1, 4 }, { -1, 4 }, {  4, 1 }, { -4, 1 }, {  3, 3 }, { -3, 3 }, {  2, 4 }, { -2, 4 },\n    {  4, 2 }, { -4, 2 }, {  0, 5 }, {  3, 4 }, { -3, 4 }, {  4, 3 }, { -4, 3 }, {  5, 0 },\n    {  1, 5 }, { -1, 5 }, {  5, 1 }, { -5, 1 }, {  2, 5 }, { -2, 5 }, {  5, 2 }, { -5, 2 },\n    {  4, 4 }, { -4, 4 }, {  3, 5 }, { -3, 5 }, {  5, 3 }, { -5, 3 }, {  0, 6 }, {  6, 0 },\n    {  1, 6 }, { -1, 6 }, {  6, 1 }, { -6, 1 }, {  2, 6 }, { -2, 6 }, {  6, 2 }, { -6, 2 },\n    {  4, 5 }, { -4, 5 }, {  5, 4 }, { -5, 4 }, {  3, 6 }, { -3, 6 }, {  6, 3 }, { -6, 3 },\n    {  0, 7 }, {  7, 0 }, {  1, 7 }, { -1, 7 }, {  5, 5 }, { -5, 5 }, {  7, 1 }, { -7, 1 },\n    {  4, 6 }, { -4, 6 }, {  6, 4 }, { -6, 4 }, {  2, 7 }, { -2, 7 }, {  7, 2 }, { -7, 2 },\n    {  3, 7 }, { -3, 7 }, {  7, 3 }, { -7, 3 }, {  5, 6 }, { -5, 6 }, {  6, 5 }, { -6, 5 },\n    {  8, 0 }, {  4, 7 }, { -4, 7 }, {  7, 4 }, { -7, 4 }, {  8, 1 }, {  8, 2 }, {  6, 6 },\n    { -6, 6 }, {  8, 3 }, {  5, 7 }, { -5, 7 }, {  7, 5 }, { -7, 5 }, {  8, 4 }, {  6, 7 },\n    { -6, 7 }, {  7, 6 }, { -7, 6 }, {  8, 5 }, {  7, 7 }, { -7, 7 }, {  8, 6 }, {  8, 7 }\n};\n\nenum AlphaCompression {\n    ALPHA_COMPRESSION_NONE,\n    ALPHA_COMPRESSION_VP8L,\n};\n\nenum AlphaFilter {\n    ALPHA_FILTER_NONE,\n    ALPHA_FILTER_HORIZONTAL,\n    ALPHA_FILTER_VERTICAL,\n    ALPHA_FILTER_GRADIENT,\n};\n\nenum TransformType {\n    PREDICTOR_TRANSFORM      = 0,\n    COLOR_TRANSFORM          = 1,\n    SUBTRACT_GREEN           = 2,\n    COLOR_INDEXING_TRANSFORM = 3,\n};\n\nenum PredictionMode {\n    PRED_MODE_BLACK,\n    PRED_MODE_L,\n    PRED_MODE_T,\n    PRED_MODE_TR,\n    PRED_MODE_TL,\n    PRED_MODE_AVG_T_AVG_L_TR,\n    PRED_MODE_AVG_L_TL,\n    PRED_MODE_AVG_L_T,\n    PRED_MODE_AVG_TL_T,\n    PRED_MODE_AVG_T_TR,\n    PRED_MODE_AVG_AVG_L_TL_AVG_T_TR,\n    PRED_MODE_SELECT,\n    PRED_MODE_ADD_SUBTRACT_FULL,\n    PRED_MODE_ADD_SUBTRACT_HALF,\n};\n\nenum HuffmanIndex {\n    HUFF_IDX_GREEN = 0,\n    HUFF_IDX_RED   = 1,\n    HUFF_IDX_BLUE  = 2,\n    HUFF_IDX_ALPHA = 3,\n    HUFF_IDX_DIST  = 4\n};\n\n/* The structure of WebP lossless is an optional series of transformation data,\n * followed by the primary image. The primary image also optionally contains\n * an entropy group mapping if there are multiple entropy groups. There is a\n * basic image type called an \"entropy coded image\" that is used for all of\n * these. The type of each entropy coded image is referred to by the\n * specification as its role. */\nenum ImageRole {\n    /* Primary Image: Stores the actual pixels of the image. */\n    IMAGE_ROLE_ARGB,\n\n    /* Entropy Image: Defines which Huffman group to use for different areas of\n     *                the primary image. */\n    IMAGE_ROLE_ENTROPY,\n\n    /* Predictors: Defines which predictor type to use for different areas of\n     *             the primary image. */\n    IMAGE_ROLE_PREDICTOR,\n\n    /* Color Transform Data: Defines the color transformation for different\n     *                       areas of the primary image. */\n    IMAGE_ROLE_COLOR_TRANSFORM,\n\n    /* Color Index: Stored as an image of height == 1. */\n    IMAGE_ROLE_COLOR_INDEXING,\n\n    IMAGE_ROLE_NB,\n};\n\ntypedef struct HuffReader {\n    VLC vlc;                            /* Huffman decoder context */\n    int simple;                         /* whether to use simple mode */\n    int nb_symbols;                     /* number of coded symbols */\n    uint16_t simple_symbols[2];         /* symbols for simple mode */\n} HuffReader;\n\ntypedef struct ImageContext {\n    enum ImageRole role;                /* role of this image */\n    AVFrame *frame;                     /* AVFrame for data */\n    int color_cache_bits;               /* color cache size, log2 */\n    uint32_t *color_cache;              /* color cache data */\n    int nb_huffman_groups;              /* number of huffman groups */\n    HuffReader *huffman_groups;         /* reader for each huffman group */\n    int size_reduction;                 /* relative size compared to primary image, log2 */\n    int is_alpha_primary;\n} ImageContext;\n\ntypedef struct WebPContext {\n    VP8Context v;                       /* VP8 Context used for lossy decoding */\n    GetBitContext gb;                   /* bitstream reader for main image chunk */\n    AVFrame *alpha_frame;               /* AVFrame for alpha data decompressed from VP8L */\n    AVCodecContext *avctx;              /* parent AVCodecContext */\n    int initialized;                    /* set once the VP8 context is initialized */\n    int has_alpha;                      /* has a separate alpha chunk */\n    enum AlphaCompression alpha_compression; /* compression type for alpha chunk */\n    enum AlphaFilter alpha_filter;      /* filtering method for alpha chunk */\n    uint8_t *alpha_data;                /* alpha chunk data */\n    int alpha_data_size;                /* alpha chunk data size */\n    int has_exif;                       /* set after an EXIF chunk has been processed */\n    int width;                          /* image width */\n    int height;                         /* image height */\n    int lossless;                       /* indicates lossless or lossy */\n\n    int nb_transforms;                  /* number of transforms */\n    enum TransformType transforms[4];   /* transformations used in the image, in order */\n    int reduced_width;                  /* reduced width for index image, if applicable */\n    int nb_huffman_groups;              /* number of huffman groups in the primary image */\n    ImageContext image[IMAGE_ROLE_NB];  /* image context for each role */\n} WebPContext;\n\n#define GET_PIXEL(frame, x, y) \\\n    ((frame)->data[0] + (y) * frame->linesize[0] + 4 * (x))\n\n#define GET_PIXEL_COMP(frame, x, y, c) \\\n    (*((frame)->data[0] + (y) * frame->linesize[0] + 4 * (x) + c))\n\nstatic void image_ctx_free(ImageContext *img)\n{\n    int i, j;\n\n    av_free(img->color_cache);\n    if (img->role != IMAGE_ROLE_ARGB && !img->is_alpha_primary)\n        av_frame_free(&img->frame);\n    if (img->huffman_groups) {\n        for (i = 0; i < img->nb_huffman_groups; i++) {\n            for (j = 0; j < HUFFMAN_CODES_PER_META_CODE; j++)\n                ff_free_vlc(&img->huffman_groups[i * HUFFMAN_CODES_PER_META_CODE + j].vlc);\n        }\n        av_free(img->huffman_groups);\n    }\n    memset(img, 0, sizeof(*img));\n}\n\n\n/* Differs from get_vlc2() in the following ways:\n *   - codes are bit-reversed\n *   - assumes 8-bit table to make reversal simpler\n *   - assumes max depth of 2 since the max code length for WebP is 15\n */\nstatic av_always_inline int webp_get_vlc(GetBitContext *gb, VLC_TYPE (*table)[2])\n{\n    int n, nb_bits;\n    unsigned int index;\n    int code;\n\n    OPEN_READER(re, gb);\n    UPDATE_CACHE(re, gb);\n\n    index = SHOW_UBITS(re, gb, 8);\n    index = ff_reverse[index];\n    code  = table[index][0];\n    n     = table[index][1];\n\n    if (n < 0) {\n        LAST_SKIP_BITS(re, gb, 8);\n        UPDATE_CACHE(re, gb);\n\n        nb_bits = -n;\n\n        index = SHOW_UBITS(re, gb, nb_bits);\n        index = (ff_reverse[index] >> (8 - nb_bits)) + code;\n        code  = table[index][0];\n        n     = table[index][1];\n    }\n    SKIP_BITS(re, gb, n);\n\n    CLOSE_READER(re, gb);\n\n    return code;\n}\n\nstatic int huff_reader_get_symbol(HuffReader *r, GetBitContext *gb)\n{\n    if (r->simple) {\n        if (r->nb_symbols == 1)\n            return r->simple_symbols[0];\n        else\n            return r->simple_symbols[get_bits1(gb)];\n    } else\n        return webp_get_vlc(gb, r->vlc.table);\n}\n\nstatic int huff_reader_build_canonical(HuffReader *r, int *code_lengths,\n                                       int alphabet_size)\n{\n    int len = 0, sym, code = 0, ret;\n    int max_code_length = 0;\n    uint16_t *codes;\n\n    /* special-case 1 symbol since the vlc reader cannot handle it */\n    for (sym = 0; sym < alphabet_size; sym++) {\n        if (code_lengths[sym] > 0) {\n            len++;\n            code = sym;\n            if (len > 1)\n                break;\n        }\n    }\n    if (len == 1) {\n        r->nb_symbols = 1;\n        r->simple_symbols[0] = code;\n        r->simple = 1;\n        return 0;\n    }\n\n    for (sym = 0; sym < alphabet_size; sym++)\n        max_code_length = FFMAX(max_code_length, code_lengths[sym]);\n\n    if (max_code_length == 0 || max_code_length > MAX_HUFFMAN_CODE_LENGTH)\n        return AVERROR(EINVAL);\n\n    codes = av_malloc_array(alphabet_size, sizeof(*codes));\n    if (!codes)\n        return AVERROR(ENOMEM);\n\n    code = 0;\n    r->nb_symbols = 0;\n    for (len = 1; len <= max_code_length; len++) {\n        for (sym = 0; sym < alphabet_size; sym++) {\n            if (code_lengths[sym] != len)\n                continue;\n            codes[sym] = code++;\n            r->nb_symbols++;\n        }\n        code <<= 1;\n    }\n    if (!r->nb_symbols) {\n        av_free(codes);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ret = init_vlc(&r->vlc, 8, alphabet_size,\n                   code_lengths, sizeof(*code_lengths), sizeof(*code_lengths),\n                   codes, sizeof(*codes), sizeof(*codes), 0);\n    if (ret < 0) {\n        av_free(codes);\n        return ret;\n    }\n    r->simple = 0;\n\n    av_free(codes);\n    return 0;\n}\n\nstatic void read_huffman_code_simple(WebPContext *s, HuffReader *hc)\n{\n    hc->nb_symbols = get_bits1(&s->gb) + 1;\n\n    if (get_bits1(&s->gb))\n        hc->simple_symbols[0] = get_bits(&s->gb, 8);\n    else\n        hc->simple_symbols[0] = get_bits1(&s->gb);\n\n    if (hc->nb_symbols == 2)\n        hc->simple_symbols[1] = get_bits(&s->gb, 8);\n\n    hc->simple = 1;\n}\n\nstatic int read_huffman_code_normal(WebPContext *s, HuffReader *hc,\n                                    int alphabet_size)\n{\n    HuffReader code_len_hc = { { 0 }, 0, 0, { 0 } };\n    int *code_lengths = NULL;\n    int code_length_code_lengths[NUM_CODE_LENGTH_CODES] = { 0 };\n    int i, symbol, max_symbol, prev_code_len, ret;\n    int num_codes = 4 + get_bits(&s->gb, 4);\n\n    if (num_codes > NUM_CODE_LENGTH_CODES)\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < num_codes; i++)\n        code_length_code_lengths[code_length_code_order[i]] = get_bits(&s->gb, 3);\n\n    ret = huff_reader_build_canonical(&code_len_hc, code_length_code_lengths,\n                                      NUM_CODE_LENGTH_CODES);\n    if (ret < 0)\n        goto finish;\n\n    code_lengths = av_mallocz_array(alphabet_size, sizeof(*code_lengths));\n    if (!code_lengths) {\n        ret = AVERROR(ENOMEM);\n        goto finish;\n    }\n\n    if (get_bits1(&s->gb)) {\n        int bits   = 2 + 2 * get_bits(&s->gb, 3);\n        max_symbol = 2 + get_bits(&s->gb, bits);\n        if (max_symbol > alphabet_size) {\n            av_log(s->avctx, AV_LOG_ERROR, \"max symbol %d > alphabet size %d\\n\",\n                   max_symbol, alphabet_size);\n            ret = AVERROR_INVALIDDATA;\n            goto finish;\n        }\n    } else {\n        max_symbol = alphabet_size;\n    }\n\n    prev_code_len = 8;\n    symbol        = 0;\n    while (symbol < alphabet_size) {\n        int code_len;\n\n        if (!max_symbol--)\n            break;\n        code_len = huff_reader_get_symbol(&code_len_hc, &s->gb);\n        if (code_len < 16) {\n            /* Code length code [0..15] indicates literal code lengths. */\n            code_lengths[symbol++] = code_len;\n            if (code_len)\n                prev_code_len = code_len;\n        } else {\n            int repeat = 0, length = 0;\n            switch (code_len) {\n            case 16:\n                /* Code 16 repeats the previous non-zero value [3..6] times,\n                 * i.e., 3 + ReadBits(2) times. If code 16 is used before a\n                 * non-zero value has been emitted, a value of 8 is repeated. */\n                repeat = 3 + get_bits(&s->gb, 2);\n                length = prev_code_len;\n                break;\n            case 17:\n                /* Code 17 emits a streak of zeros [3..10], i.e.,\n                 * 3 + ReadBits(3) times. */\n                repeat = 3 + get_bits(&s->gb, 3);\n                break;\n            case 18:\n                /* Code 18 emits a streak of zeros of length [11..138], i.e.,\n                 * 11 + ReadBits(7) times. */\n                repeat = 11 + get_bits(&s->gb, 7);\n                break;\n            }\n            if (symbol + repeat > alphabet_size) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"invalid symbol %d + repeat %d > alphabet size %d\\n\",\n                       symbol, repeat, alphabet_size);\n                ret = AVERROR_INVALIDDATA;\n                goto finish;\n            }\n            while (repeat-- > 0)\n                code_lengths[symbol++] = length;\n        }\n    }\n\n    ret = huff_reader_build_canonical(hc, code_lengths, alphabet_size);\n\nfinish:\n    ff_free_vlc(&code_len_hc.vlc);\n    av_free(code_lengths);\n    return ret;\n}\n\nstatic int decode_entropy_coded_image(WebPContext *s, enum ImageRole role,\n                                      int w, int h);\n\n#define PARSE_BLOCK_SIZE(w, h) do {                                         \\\n    block_bits = get_bits(&s->gb, 3) + 2;                                   \\\n    blocks_w   = FFALIGN((w), 1 << block_bits) >> block_bits;               \\\n    blocks_h   = FFALIGN((h), 1 << block_bits) >> block_bits;               \\\n} while (0)\n\nstatic int decode_entropy_image(WebPContext *s)\n{\n    ImageContext *img;\n    int ret, block_bits, width, blocks_w, blocks_h, x, y, max;\n\n    width = s->width;\n    if (s->reduced_width > 0)\n        width = s->reduced_width;\n\n    PARSE_BLOCK_SIZE(width, s->height);\n\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_ENTROPY, blocks_w, blocks_h);\n    if (ret < 0)\n        return ret;\n\n    img = &s->image[IMAGE_ROLE_ENTROPY];\n    img->size_reduction = block_bits;\n\n    /* the number of huffman groups is determined by the maximum group number\n     * coded in the entropy image */\n    max = 0;\n    for (y = 0; y < img->frame->height; y++) {\n        for (x = 0; x < img->frame->width; x++) {\n            int p0 = GET_PIXEL_COMP(img->frame, x, y, 1);\n            int p1 = GET_PIXEL_COMP(img->frame, x, y, 2);\n            int p  = p0 << 8 | p1;\n            max = FFMAX(max, p);\n        }\n    }\n    s->nb_huffman_groups = max + 1;\n\n    return 0;\n}\n\nstatic int parse_transform_predictor(WebPContext *s)\n{\n    int block_bits, blocks_w, blocks_h, ret;\n\n    PARSE_BLOCK_SIZE(s->width, s->height);\n\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_PREDICTOR, blocks_w,\n                                     blocks_h);\n    if (ret < 0)\n        return ret;\n\n    s->image[IMAGE_ROLE_PREDICTOR].size_reduction = block_bits;\n\n    return 0;\n}\n\nstatic int parse_transform_color(WebPContext *s)\n{\n    int block_bits, blocks_w, blocks_h, ret;\n\n    PARSE_BLOCK_SIZE(s->width, s->height);\n\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_COLOR_TRANSFORM, blocks_w,\n                                     blocks_h);\n    if (ret < 0)\n        return ret;\n\n    s->image[IMAGE_ROLE_COLOR_TRANSFORM].size_reduction = block_bits;\n\n    return 0;\n}\n\nstatic int parse_transform_color_indexing(WebPContext *s)\n{\n    ImageContext *img;\n    int width_bits, index_size, ret, x;\n    uint8_t *ct;\n\n    index_size = get_bits(&s->gb, 8) + 1;\n\n    if (index_size <= 2)\n        width_bits = 3;\n    else if (index_size <= 4)\n        width_bits = 2;\n    else if (index_size <= 16)\n        width_bits = 1;\n    else\n        width_bits = 0;\n\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_COLOR_INDEXING,\n                                     index_size, 1);\n    if (ret < 0)\n        return ret;\n\n    img = &s->image[IMAGE_ROLE_COLOR_INDEXING];\n    img->size_reduction = width_bits;\n    if (width_bits > 0)\n        s->reduced_width = (s->width + ((1 << width_bits) - 1)) >> width_bits;\n\n    /* color index values are delta-coded */\n    ct  = img->frame->data[0] + 4;\n    for (x = 4; x < img->frame->width * 4; x++, ct++)\n        ct[0] += ct[-4];\n\n    return 0;\n}\n\nstatic HuffReader *get_huffman_group(WebPContext *s, ImageContext *img,\n                                     int x, int y)\n{\n    ImageContext *gimg = &s->image[IMAGE_ROLE_ENTROPY];\n    int group = 0;\n\n    if (gimg->size_reduction > 0) {\n        int group_x = x >> gimg->size_reduction;\n        int group_y = y >> gimg->size_reduction;\n        int g0      = GET_PIXEL_COMP(gimg->frame, group_x, group_y, 1);\n        int g1      = GET_PIXEL_COMP(gimg->frame, group_x, group_y, 2);\n        group       = g0 << 8 | g1;\n    }\n\n    return &img->huffman_groups[group * HUFFMAN_CODES_PER_META_CODE];\n}\n\nstatic av_always_inline void color_cache_put(ImageContext *img, uint32_t c)\n{\n    uint32_t cache_idx = (0x1E35A7BD * c) >> (32 - img->color_cache_bits);\n    img->color_cache[cache_idx] = c;\n}\n\nstatic int decode_entropy_coded_image(WebPContext *s, enum ImageRole role,\n                                      int w, int h)\n{\n    ImageContext *img;\n    HuffReader *hg;\n    int i, j, ret, x, y, width;\n\n    img       = &s->image[role];\n    img->role = role;\n\n    if (!img->frame) {\n        img->frame = av_frame_alloc();\n        if (!img->frame)\n            return AVERROR(ENOMEM);\n    }\n\n    img->frame->format = AV_PIX_FMT_ARGB;\n    img->frame->width  = w;\n    img->frame->height = h;\n\n    if (role == IMAGE_ROLE_ARGB && !img->is_alpha_primary) {\n        ThreadFrame pt = { .f = img->frame };\n        ret = ff_thread_get_buffer(s->avctx, &pt, 0);\n    } else\n        ret = av_frame_get_buffer(img->frame, 1);\n    if (ret < 0)\n        return ret;\n\n    if (get_bits1(&s->gb)) {\n        img->color_cache_bits = get_bits(&s->gb, 4);\n        if (img->color_cache_bits < 1 || img->color_cache_bits > 11) {\n            av_log(s->avctx, AV_LOG_ERROR, \"invalid color cache bits: %d\\n\",\n                   img->color_cache_bits);\n            return AVERROR_INVALIDDATA;\n        }\n        img->color_cache = av_mallocz_array(1 << img->color_cache_bits,\n                                            sizeof(*img->color_cache));\n        if (!img->color_cache)\n            return AVERROR(ENOMEM);\n    } else {\n        img->color_cache_bits = 0;\n    }\n\n    img->nb_huffman_groups = 1;\n    if (role == IMAGE_ROLE_ARGB && get_bits1(&s->gb)) {\n        ret = decode_entropy_image(s);\n        if (ret < 0)\n            return ret;\n        img->nb_huffman_groups = s->nb_huffman_groups;\n    }\n    img->huffman_groups = av_mallocz_array(img->nb_huffman_groups *\n                                           HUFFMAN_CODES_PER_META_CODE,\n                                           sizeof(*img->huffman_groups));\n    if (!img->huffman_groups)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < img->nb_huffman_groups; i++) {\n        hg = &img->huffman_groups[i * HUFFMAN_CODES_PER_META_CODE];\n        for (j = 0; j < HUFFMAN_CODES_PER_META_CODE; j++) {\n            int alphabet_size = alphabet_sizes[j];\n            if (!j && img->color_cache_bits > 0)\n                alphabet_size += 1 << img->color_cache_bits;\n\n            if (get_bits1(&s->gb)) {\n                read_huffman_code_simple(s, &hg[j]);\n            } else {\n                ret = read_huffman_code_normal(s, &hg[j], alphabet_size);\n                if (ret < 0)\n                    return ret;\n            }\n        }\n    }\n\n    width = img->frame->width;\n    if (role == IMAGE_ROLE_ARGB && s->reduced_width > 0)\n        width = s->reduced_width;\n\n    x = 0; y = 0;\n    while (y < img->frame->height) {\n        int v;\n\n        hg = get_huffman_group(s, img, x, y);\n        v = huff_reader_get_symbol(&hg[HUFF_IDX_GREEN], &s->gb);\n        if (v < NUM_LITERAL_CODES) {\n            /* literal pixel values */\n            uint8_t *p = GET_PIXEL(img->frame, x, y);\n            p[2] = v;\n            p[1] = huff_reader_get_symbol(&hg[HUFF_IDX_RED],   &s->gb);\n            p[3] = huff_reader_get_symbol(&hg[HUFF_IDX_BLUE],  &s->gb);\n            p[0] = huff_reader_get_symbol(&hg[HUFF_IDX_ALPHA], &s->gb);\n            if (img->color_cache_bits)\n                color_cache_put(img, AV_RB32(p));\n            x++;\n            if (x == width) {\n                x = 0;\n                y++;\n            }\n        } else if (v < NUM_LITERAL_CODES + NUM_LENGTH_CODES) {\n            /* LZ77 backwards mapping */\n            int prefix_code, length, distance, ref_x, ref_y;\n\n            /* parse length and distance */\n            prefix_code = v - NUM_LITERAL_CODES;\n            if (prefix_code < 4) {\n                length = prefix_code + 1;\n            } else {\n                int extra_bits = (prefix_code - 2) >> 1;\n                int offset     = 2 + (prefix_code & 1) << extra_bits;\n                length = offset + get_bits(&s->gb, extra_bits) + 1;\n            }\n            prefix_code = huff_reader_get_symbol(&hg[HUFF_IDX_DIST], &s->gb);\n            if (prefix_code > 39) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"distance prefix code too large: %d\\n\", prefix_code);\n                return AVERROR_INVALIDDATA;\n            }\n            if (prefix_code < 4) {\n                distance = prefix_code + 1;\n            } else {\n                int extra_bits = prefix_code - 2 >> 1;\n                int offset     = 2 + (prefix_code & 1) << extra_bits;\n                distance = offset + get_bits(&s->gb, extra_bits) + 1;\n            }\n\n            /* find reference location */\n            if (distance <= NUM_SHORT_DISTANCES) {\n                int xi = lz77_distance_offsets[distance - 1][0];\n                int yi = lz77_distance_offsets[distance - 1][1];\n                distance = FFMAX(1, xi + yi * width);\n            } else {\n                distance -= NUM_SHORT_DISTANCES;\n            }\n            ref_x = x;\n            ref_y = y;\n            if (distance <= x) {\n                ref_x -= distance;\n                distance = 0;\n            } else {\n                ref_x = 0;\n                distance -= x;\n            }\n            while (distance >= width) {\n                ref_y--;\n                distance -= width;\n            }\n            if (distance > 0) {\n                ref_x = width - distance;\n                ref_y--;\n            }\n            ref_x = FFMAX(0, ref_x);\n            ref_y = FFMAX(0, ref_y);\n\n            /* copy pixels\n             * source and dest regions can overlap and wrap lines, so just\n             * copy per-pixel */\n            for (i = 0; i < length; i++) {\n                uint8_t *p_ref = GET_PIXEL(img->frame, ref_x, ref_y);\n                uint8_t *p     = GET_PIXEL(img->frame,     x,     y);\n\n                AV_COPY32(p, p_ref);\n                if (img->color_cache_bits)\n                    color_cache_put(img, AV_RB32(p));\n                x++;\n                ref_x++;\n                if (x == width) {\n                    x = 0;\n                    y++;\n                }\n                if (ref_x == width) {\n                    ref_x = 0;\n                    ref_y++;\n                }\n                if (y == img->frame->height || ref_y == img->frame->height)\n                    break;\n            }\n        } else {\n            /* read from color cache */\n            uint8_t *p = GET_PIXEL(img->frame, x, y);\n            int cache_idx = v - (NUM_LITERAL_CODES + NUM_LENGTH_CODES);\n\n            if (!img->color_cache_bits) {\n                av_log(s->avctx, AV_LOG_ERROR, \"color cache not found\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            if (cache_idx >= 1 << img->color_cache_bits) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"color cache index out-of-bounds\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            AV_WB32(p, img->color_cache[cache_idx]);\n            x++;\n            if (x == width) {\n                x = 0;\n                y++;\n            }\n        }\n    }\n\n    return 0;\n}\n\n/* PRED_MODE_BLACK */\nstatic void inv_predict_0(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_WB32(p, 0xFF000000);\n}\n\n/* PRED_MODE_L */\nstatic void inv_predict_1(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_COPY32(p, p_l);\n}\n\n/* PRED_MODE_T */\nstatic void inv_predict_2(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_COPY32(p, p_t);\n}\n\n/* PRED_MODE_TR */\nstatic void inv_predict_3(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_COPY32(p, p_tr);\n}\n\n/* PRED_MODE_TL */\nstatic void inv_predict_4(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_COPY32(p, p_tl);\n}\n\n/* PRED_MODE_AVG_T_AVG_L_TR */\nstatic void inv_predict_5(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_t[0] + (p_l[0] + p_tr[0] >> 1) >> 1;\n    p[1] = p_t[1] + (p_l[1] + p_tr[1] >> 1) >> 1;\n    p[2] = p_t[2] + (p_l[2] + p_tr[2] >> 1) >> 1;\n    p[3] = p_t[3] + (p_l[3] + p_tr[3] >> 1) >> 1;\n}\n\n/* PRED_MODE_AVG_L_TL */\nstatic void inv_predict_6(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_l[0] + p_tl[0] >> 1;\n    p[1] = p_l[1] + p_tl[1] >> 1;\n    p[2] = p_l[2] + p_tl[2] >> 1;\n    p[3] = p_l[3] + p_tl[3] >> 1;\n}\n\n/* PRED_MODE_AVG_L_T */\nstatic void inv_predict_7(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_l[0] + p_t[0] >> 1;\n    p[1] = p_l[1] + p_t[1] >> 1;\n    p[2] = p_l[2] + p_t[2] >> 1;\n    p[3] = p_l[3] + p_t[3] >> 1;\n}\n\n/* PRED_MODE_AVG_TL_T */\nstatic void inv_predict_8(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_tl[0] + p_t[0] >> 1;\n    p[1] = p_tl[1] + p_t[1] >> 1;\n    p[2] = p_tl[2] + p_t[2] >> 1;\n    p[3] = p_tl[3] + p_t[3] >> 1;\n}\n\n/* PRED_MODE_AVG_T_TR */\nstatic void inv_predict_9(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_t[0] + p_tr[0] >> 1;\n    p[1] = p_t[1] + p_tr[1] >> 1;\n    p[2] = p_t[2] + p_tr[2] >> 1;\n    p[3] = p_t[3] + p_tr[3] >> 1;\n}\n\n/* PRED_MODE_AVG_AVG_L_TL_AVG_T_TR */\nstatic void inv_predict_10(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                           const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = (p_l[0] + p_tl[0] >> 1) + (p_t[0] + p_tr[0] >> 1) >> 1;\n    p[1] = (p_l[1] + p_tl[1] >> 1) + (p_t[1] + p_tr[1] >> 1) >> 1;\n    p[2] = (p_l[2] + p_tl[2] >> 1) + (p_t[2] + p_tr[2] >> 1) >> 1;\n    p[3] = (p_l[3] + p_tl[3] >> 1) + (p_t[3] + p_tr[3] >> 1) >> 1;\n}\n\n/* PRED_MODE_SELECT */\nstatic void inv_predict_11(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                           const uint8_t *p_t, const uint8_t *p_tr)\n{\n    int diff = (FFABS(p_l[0] - p_tl[0]) - FFABS(p_t[0] - p_tl[0])) +\n               (FFABS(p_l[1] - p_tl[1]) - FFABS(p_t[1] - p_tl[1])) +\n               (FFABS(p_l[2] - p_tl[2]) - FFABS(p_t[2] - p_tl[2])) +\n               (FFABS(p_l[3] - p_tl[3]) - FFABS(p_t[3] - p_tl[3]));\n    if (diff <= 0)\n        AV_COPY32(p, p_t);\n    else\n        AV_COPY32(p, p_l);\n}\n\n/* PRED_MODE_ADD_SUBTRACT_FULL */\nstatic void inv_predict_12(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                           const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = av_clip_uint8(p_l[0] + p_t[0] - p_tl[0]);\n    p[1] = av_clip_uint8(p_l[1] + p_t[1] - p_tl[1]);\n    p[2] = av_clip_uint8(p_l[2] + p_t[2] - p_tl[2]);\n    p[3] = av_clip_uint8(p_l[3] + p_t[3] - p_tl[3]);\n}\n\nstatic av_always_inline uint8_t clamp_add_subtract_half(int a, int b, int c)\n{\n    int d = a + b >> 1;\n    return av_clip_uint8(d + (d - c) / 2);\n}\n\n/* PRED_MODE_ADD_SUBTRACT_HALF */\nstatic void inv_predict_13(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                           const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = clamp_add_subtract_half(p_l[0], p_t[0], p_tl[0]);\n    p[1] = clamp_add_subtract_half(p_l[1], p_t[1], p_tl[1]);\n    p[2] = clamp_add_subtract_half(p_l[2], p_t[2], p_tl[2]);\n    p[3] = clamp_add_subtract_half(p_l[3], p_t[3], p_tl[3]);\n}\n\ntypedef void (*inv_predict_func)(uint8_t *p, const uint8_t *p_l,\n                                 const uint8_t *p_tl, const uint8_t *p_t,\n                                 const uint8_t *p_tr);\n\nstatic const inv_predict_func inverse_predict[14] = {\n    inv_predict_0,  inv_predict_1,  inv_predict_2,  inv_predict_3,\n    inv_predict_4,  inv_predict_5,  inv_predict_6,  inv_predict_7,\n    inv_predict_8,  inv_predict_9,  inv_predict_10, inv_predict_11,\n    inv_predict_12, inv_predict_13,\n};\n\nstatic void inverse_prediction(AVFrame *frame, enum PredictionMode m, int x, int y)\n{\n    uint8_t *dec, *p_l, *p_tl, *p_t, *p_tr;\n    uint8_t p[4];\n\n    dec  = GET_PIXEL(frame, x,     y);\n    p_l  = GET_PIXEL(frame, x - 1, y);\n    p_tl = GET_PIXEL(frame, x - 1, y - 1);\n    p_t  = GET_PIXEL(frame, x,     y - 1);\n    if (x == frame->width - 1)\n        p_tr = GET_PIXEL(frame, 0, y);\n    else\n        p_tr = GET_PIXEL(frame, x + 1, y - 1);\n\n    inverse_predict[m](p, p_l, p_tl, p_t, p_tr);\n\n    dec[0] += p[0];\n    dec[1] += p[1];\n    dec[2] += p[2];\n    dec[3] += p[3];\n}\n\nstatic int apply_predictor_transform(WebPContext *s)\n{\n    ImageContext *img  = &s->image[IMAGE_ROLE_ARGB];\n    ImageContext *pimg = &s->image[IMAGE_ROLE_PREDICTOR];\n    int x, y;\n\n    for (y = 0; y < img->frame->height; y++) {\n        for (x = 0; x < img->frame->width; x++) {\n            int tx = x >> pimg->size_reduction;\n            int ty = y >> pimg->size_reduction;\n            enum PredictionMode m = GET_PIXEL_COMP(pimg->frame, tx, ty, 2);\n\n            if (x == 0) {\n                if (y == 0)\n                    m = PRED_MODE_BLACK;\n                else\n                    m = PRED_MODE_T;\n            } else if (y == 0)\n                m = PRED_MODE_L;\n\n            if (m > 13) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"invalid predictor mode: %d\\n\", m);\n                return AVERROR_INVALIDDATA;\n            }\n            inverse_prediction(img->frame, m, x, y);\n        }\n    }\n    return 0;\n}\n\nstatic av_always_inline uint8_t color_transform_delta(uint8_t color_pred,\n                                                      uint8_t color)\n{\n    return (int)ff_u8_to_s8(color_pred) * ff_u8_to_s8(color) >> 5;\n}\n\nstatic int apply_color_transform(WebPContext *s)\n{\n    ImageContext *img, *cimg;\n    int x, y, cx, cy;\n    uint8_t *p, *cp;\n\n    img  = &s->image[IMAGE_ROLE_ARGB];\n    cimg = &s->image[IMAGE_ROLE_COLOR_TRANSFORM];\n\n    for (y = 0; y < img->frame->height; y++) {\n        for (x = 0; x < img->frame->width; x++) {\n            cx = x >> cimg->size_reduction;\n            cy = y >> cimg->size_reduction;\n            cp = GET_PIXEL(cimg->frame, cx, cy);\n            p  = GET_PIXEL(img->frame,   x,  y);\n\n            p[1] += color_transform_delta(cp[3], p[2]);\n            p[3] += color_transform_delta(cp[2], p[2]) +\n                    color_transform_delta(cp[1], p[1]);\n        }\n    }\n    return 0;\n}\n\nstatic int apply_subtract_green_transform(WebPContext *s)\n{\n    int x, y;\n    ImageContext *img = &s->image[IMAGE_ROLE_ARGB];\n\n    for (y = 0; y < img->frame->height; y++) {\n        for (x = 0; x < img->frame->width; x++) {\n            uint8_t *p = GET_PIXEL(img->frame, x, y);\n            p[1] += p[2];\n            p[3] += p[2];\n        }\n    }\n    return 0;\n}\n\nstatic int apply_color_indexing_transform(WebPContext *s)\n{\n    ImageContext *img;\n    ImageContext *pal;\n    int i, x, y;\n    uint8_t *p;\n\n    img = &s->image[IMAGE_ROLE_ARGB];\n    pal = &s->image[IMAGE_ROLE_COLOR_INDEXING];\n\n    if (pal->size_reduction > 0) {\n        GetBitContext gb_g;\n        uint8_t *line;\n        int pixel_bits = 8 >> pal->size_reduction;\n\n        line = av_malloc(img->frame->linesize[0]);\n        if (!line)\n            return AVERROR(ENOMEM);\n\n        for (y = 0; y < img->frame->height; y++) {\n            p = GET_PIXEL(img->frame, 0, y);\n            memcpy(line, p, img->frame->linesize[0]);\n            init_get_bits(&gb_g, line, img->frame->linesize[0] * 8);\n            skip_bits(&gb_g, 16);\n            i = 0;\n            for (x = 0; x < img->frame->width; x++) {\n                p    = GET_PIXEL(img->frame, x, y);\n                p[2] = get_bits(&gb_g, pixel_bits);\n                i++;\n                if (i == 1 << pal->size_reduction) {\n                    skip_bits(&gb_g, 24);\n                    i = 0;\n                }\n            }\n        }\n        av_free(line);\n    }\n\n    // switch to local palette if it's worth initializing it\n    if (img->frame->height * img->frame->width > 300) {\n        uint8_t palette[256 * 4];\n        const int size = pal->frame->width * 4;\n        av_assert0(size <= 1024U);\n        memcpy(palette, GET_PIXEL(pal->frame, 0, 0), size);   // copy palette\n        // set extra entries to transparent black\n        memset(palette + size, 0, 256 * 4 - size);\n        for (y = 0; y < img->frame->height; y++) {\n            for (x = 0; x < img->frame->width; x++) {\n                p = GET_PIXEL(img->frame, x, y);\n                i = p[2];\n                AV_COPY32(p, &palette[i * 4]);\n            }\n        }\n    } else {\n        for (y = 0; y < img->frame->height; y++) {\n            for (x = 0; x < img->frame->width; x++) {\n                p = GET_PIXEL(img->frame, x, y);\n                i = p[2];\n                if (i >= pal->frame->width) {\n                    AV_WB32(p, 0x00000000);\n                } else {\n                    const uint8_t *pi = GET_PIXEL(pal->frame, i, 0);\n                    AV_COPY32(p, pi);\n                }\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic void update_canvas_size(AVCodecContext *avctx, int w, int h)\n{\n    WebPContext *s = avctx->priv_data;\n    if (s->width && s->width != w) {\n        av_log(avctx, AV_LOG_WARNING, \"Width mismatch. %d != %d\\n\",\n               s->width, w);\n    }\n    s->width = w;\n    if (s->height && s->height != h) {\n        av_log(avctx, AV_LOG_WARNING, \"Height mismatch. %d != %d\\n\",\n               s->height, h);\n    }\n    s->height = h;\n}\n\nstatic int vp8_lossless_decode_frame(AVCodecContext *avctx, AVFrame *p,\n                                     int *got_frame, uint8_t *data_start,\n                                     unsigned int data_size, int is_alpha_chunk)\n{\n    WebPContext *s = avctx->priv_data;\n    int w, h, ret, i, used;\n\n    if (!is_alpha_chunk) {\n        s->lossless = 1;\n        avctx->pix_fmt = AV_PIX_FMT_ARGB;\n    }\n\n    ret = init_get_bits8(&s->gb, data_start, data_size);\n    if (ret < 0)\n        return ret;\n\n    if (!is_alpha_chunk) {\n        if (get_bits(&s->gb, 8) != 0x2F) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid WebP Lossless signature\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        w = get_bits(&s->gb, 14) + 1;\n        h = get_bits(&s->gb, 14) + 1;\n\n        update_canvas_size(avctx, w, h);\n\n        ret = ff_set_dimensions(avctx, s->width, s->height);\n        if (ret < 0)\n            return ret;\n\n        s->has_alpha = get_bits1(&s->gb);\n\n        if (get_bits(&s->gb, 3) != 0x0) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid WebP Lossless version\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    } else {\n        if (!s->width || !s->height)\n            return AVERROR_BUG;\n        w = s->width;\n        h = s->height;\n    }\n\n    /* parse transformations */\n    s->nb_transforms = 0;\n    s->reduced_width = 0;\n    used = 0;\n    while (get_bits1(&s->gb)) {\n        enum TransformType transform = get_bits(&s->gb, 2);\n        if (used & (1 << transform)) {\n            av_log(avctx, AV_LOG_ERROR, \"Transform %d used more than once\\n\",\n                   transform);\n            ret = AVERROR_INVALIDDATA;\n            goto free_and_return;\n        }\n        used |= (1 << transform);\n        s->transforms[s->nb_transforms++] = transform;\n        switch (transform) {\n        case PREDICTOR_TRANSFORM:\n            ret = parse_transform_predictor(s);\n            break;\n        case COLOR_TRANSFORM:\n            ret = parse_transform_color(s);\n            break;\n        case COLOR_INDEXING_TRANSFORM:\n            ret = parse_transform_color_indexing(s);\n            break;\n        }\n        if (ret < 0)\n            goto free_and_return;\n    }\n\n    /* decode primary image */\n    s->image[IMAGE_ROLE_ARGB].frame = p;\n    if (is_alpha_chunk)\n        s->image[IMAGE_ROLE_ARGB].is_alpha_primary = 1;\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_ARGB, w, h);\n    if (ret < 0)\n        goto free_and_return;\n\n    /* apply transformations */\n    for (i = s->nb_transforms - 1; i >= 0; i--) {\n        switch (s->transforms[i]) {\n        case PREDICTOR_TRANSFORM:\n            ret = apply_predictor_transform(s);\n            break;\n        case COLOR_TRANSFORM:\n            ret = apply_color_transform(s);\n            break;\n        case SUBTRACT_GREEN:\n            ret = apply_subtract_green_transform(s);\n            break;\n        case COLOR_INDEXING_TRANSFORM:\n            ret = apply_color_indexing_transform(s);\n            break;\n        }\n        if (ret < 0)\n            goto free_and_return;\n    }\n\n    *got_frame   = 1;\n    p->pict_type = AV_PICTURE_TYPE_I;\n    p->key_frame = 1;\n    ret          = data_size;\n\nfree_and_return:\n    for (i = 0; i < IMAGE_ROLE_NB; i++)\n        image_ctx_free(&s->image[i]);\n\n    return ret;\n}\n\nstatic void alpha_inverse_prediction(AVFrame *frame, enum AlphaFilter m)\n{\n    int x, y, ls;\n    uint8_t *dec;\n\n    ls = frame->linesize[3];\n\n    /* filter first row using horizontal filter */\n    dec = frame->data[3] + 1;\n    for (x = 1; x < frame->width; x++, dec++)\n        *dec += *(dec - 1);\n\n    /* filter first column using vertical filter */\n    dec = frame->data[3] + ls;\n    for (y = 1; y < frame->height; y++, dec += ls)\n        *dec += *(dec - ls);\n\n    /* filter the rest using the specified filter */\n    switch (m) {\n    case ALPHA_FILTER_HORIZONTAL:\n        for (y = 1; y < frame->height; y++) {\n            dec = frame->data[3] + y * ls + 1;\n            for (x = 1; x < frame->width; x++, dec++)\n                *dec += *(dec - 1);\n        }\n        break;\n    case ALPHA_FILTER_VERTICAL:\n        for (y = 1; y < frame->height; y++) {\n            dec = frame->data[3] + y * ls + 1;\n            for (x = 1; x < frame->width; x++, dec++)\n                *dec += *(dec - ls);\n        }\n        break;\n    case ALPHA_FILTER_GRADIENT:\n        for (y = 1; y < frame->height; y++) {\n            dec = frame->data[3] + y * ls + 1;\n            for (x = 1; x < frame->width; x++, dec++)\n                dec[0] += av_clip_uint8(*(dec - 1) + *(dec - ls) - *(dec - ls - 1));\n        }\n        break;\n    }\n}\n\nstatic int vp8_lossy_decode_alpha(AVCodecContext *avctx, AVFrame *p,\n                                  uint8_t *data_start,\n                                  unsigned int data_size)\n{\n    WebPContext *s = avctx->priv_data;\n    int x, y, ret;\n\n    if (s->alpha_compression == ALPHA_COMPRESSION_NONE) {\n        GetByteContext gb;\n\n        bytestream2_init(&gb, data_start, data_size);\n        for (y = 0; y < s->height; y++)\n            bytestream2_get_buffer(&gb, p->data[3] + p->linesize[3] * y,\n                                   s->width);\n    } else if (s->alpha_compression == ALPHA_COMPRESSION_VP8L) {\n        uint8_t *ap, *pp;\n        int alpha_got_frame = 0;\n\n        s->alpha_frame = av_frame_alloc();\n        if (!s->alpha_frame)\n            return AVERROR(ENOMEM);\n\n        ret = vp8_lossless_decode_frame(avctx, s->alpha_frame, &alpha_got_frame,\n                                        data_start, data_size, 1);\n        if (ret < 0) {\n            av_frame_free(&s->alpha_frame);\n            return ret;\n        }\n        if (!alpha_got_frame) {\n            av_frame_free(&s->alpha_frame);\n            return AVERROR_INVALIDDATA;\n        }\n\n        /* copy green component of alpha image to alpha plane of primary image */\n        for (y = 0; y < s->height; y++) {\n            ap = GET_PIXEL(s->alpha_frame, 0, y) + 2;\n            pp = p->data[3] + p->linesize[3] * y;\n            for (x = 0; x < s->width; x++) {\n                *pp = *ap;\n                pp++;\n                ap += 4;\n            }\n        }\n        av_frame_free(&s->alpha_frame);\n    }\n\n    /* apply alpha filtering */\n    if (s->alpha_filter)\n        alpha_inverse_prediction(p, s->alpha_filter);\n\n    return 0;\n}\n\nstatic int vp8_lossy_decode_frame(AVCodecContext *avctx, AVFrame *p,\n                                  int *got_frame, uint8_t *data_start,\n                                  unsigned int data_size)\n{\n    WebPContext *s = avctx->priv_data;\n    AVPacket pkt;\n    int ret;\n\n    if (!s->initialized) {\n        ff_vp8_decode_init(avctx);\n        s->initialized = 1;\n        if (s->has_alpha)\n            avctx->pix_fmt = AV_PIX_FMT_YUVA420P;\n    }\n    s->lossless = 0;\n\n    if (data_size > INT_MAX) {\n        av_log(avctx, AV_LOG_ERROR, \"unsupported chunk size\\n\");\n        return AVERROR_PATCHWELCOME;\n    }\n\n    av_init_packet(&pkt);\n    pkt.data = data_start;\n    pkt.size = data_size;\n\n    ret = ff_vp8_decode_frame(avctx, p, got_frame, &pkt);\n    if (ret < 0)\n        return ret;\n\n    update_canvas_size(avctx, avctx->width, avctx->height);\n\n    if (s->has_alpha) {\n        ret = vp8_lossy_decode_alpha(avctx, p, s->alpha_data,\n                                     s->alpha_data_size);\n        if (ret < 0)\n            return ret;\n    }\n    return ret;\n}\n\nstatic int webp_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                             AVPacket *avpkt)\n{\n    AVFrame * const p = data;\n    WebPContext *s = avctx->priv_data;\n    GetByteContext gb;\n    int ret;\n    uint32_t chunk_type, chunk_size;\n    int vp8x_flags = 0;\n\n    s->avctx     = avctx;\n    s->width     = 0;\n    s->height    = 0;\n    *got_frame   = 0;\n    s->has_alpha = 0;\n    s->has_exif  = 0;\n    bytestream2_init(&gb, avpkt->data, avpkt->size);\n\n    if (bytestream2_get_bytes_left(&gb) < 12)\n        return AVERROR_INVALIDDATA;\n\n    if (bytestream2_get_le32(&gb) != MKTAG('R', 'I', 'F', 'F')) {\n        av_log(avctx, AV_LOG_ERROR, \"missing RIFF tag\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    chunk_size = bytestream2_get_le32(&gb);\n    if (bytestream2_get_bytes_left(&gb) < chunk_size)\n        return AVERROR_INVALIDDATA;\n\n    if (bytestream2_get_le32(&gb) != MKTAG('W', 'E', 'B', 'P')) {\n        av_log(avctx, AV_LOG_ERROR, \"missing WEBP tag\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    while (bytestream2_get_bytes_left(&gb) > 8) {\n        char chunk_str[5] = { 0 };\n\n        chunk_type = bytestream2_get_le32(&gb);\n        chunk_size = bytestream2_get_le32(&gb);\n        if (chunk_size == UINT32_MAX)\n            return AVERROR_INVALIDDATA;\n        chunk_size += chunk_size & 1;\n\n        if (bytestream2_get_bytes_left(&gb) < chunk_size)\n            return AVERROR_INVALIDDATA;\n\n        switch (chunk_type) {\n        case MKTAG('V', 'P', '8', ' '):\n            if (!*got_frame) {\n                ret = vp8_lossy_decode_frame(avctx, p, got_frame,\n                                             avpkt->data + bytestream2_tell(&gb),\n                                             chunk_size);\n                if (ret < 0)\n                    return ret;\n            }\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        case MKTAG('V', 'P', '8', 'L'):\n            if (!*got_frame) {\n                ret = vp8_lossless_decode_frame(avctx, p, got_frame,\n                                                avpkt->data + bytestream2_tell(&gb),\n                                                chunk_size, 0);\n                if (ret < 0)\n                    return ret;\n                avctx->properties |= FF_CODEC_PROPERTY_LOSSLESS;\n            }\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        case MKTAG('V', 'P', '8', 'X'):\n            if (s->width || s->height || *got_frame) {\n                av_log(avctx, AV_LOG_ERROR, \"Canvas dimensions are already set\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            vp8x_flags = bytestream2_get_byte(&gb);\n            bytestream2_skip(&gb, 3);\n            s->width  = bytestream2_get_le24(&gb) + 1;\n            s->height = bytestream2_get_le24(&gb) + 1;\n            ret = av_image_check_size(s->width, s->height, 0, avctx);\n            if (ret < 0)\n                return ret;\n            break;\n        case MKTAG('A', 'L', 'P', 'H'): {\n            int alpha_header, filter_m, compression;\n\n            if (!(vp8x_flags & VP8X_FLAG_ALPHA)) {\n                av_log(avctx, AV_LOG_WARNING,\n                       \"ALPHA chunk present, but alpha bit not set in the \"\n                       \"VP8X header\\n\");\n            }\n            if (chunk_size == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"invalid ALPHA chunk size\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            alpha_header       = bytestream2_get_byte(&gb);\n            s->alpha_data      = avpkt->data + bytestream2_tell(&gb);\n            s->alpha_data_size = chunk_size - 1;\n            bytestream2_skip(&gb, s->alpha_data_size);\n\n            filter_m    = (alpha_header >> 2) & 0x03;\n            compression =  alpha_header       & 0x03;\n\n            if (compression > ALPHA_COMPRESSION_VP8L) {\n                av_log(avctx, AV_LOG_VERBOSE,\n                       \"skipping unsupported ALPHA chunk\\n\");\n            } else {\n                s->has_alpha         = 1;\n                s->alpha_compression = compression;\n                s->alpha_filter      = filter_m;\n            }\n\n            break;\n        }\n        case MKTAG('E', 'X', 'I', 'F'): {\n            int le, ifd_offset, exif_offset = bytestream2_tell(&gb);\n            AVDictionary *exif_metadata = NULL;\n            GetByteContext exif_gb;\n\n            if (s->has_exif) {\n                av_log(avctx, AV_LOG_VERBOSE, \"Ignoring extra EXIF chunk\\n\");\n                goto exif_end;\n            }\n            if (!(vp8x_flags & VP8X_FLAG_EXIF_METADATA))\n                av_log(avctx, AV_LOG_WARNING,\n                       \"EXIF chunk present, but Exif bit not set in the \"\n                       \"VP8X header\\n\");\n\n            s->has_exif = 1;\n            bytestream2_init(&exif_gb, avpkt->data + exif_offset,\n                             avpkt->size - exif_offset);\n            if (ff_tdecode_header(&exif_gb, &le, &ifd_offset) < 0) {\n                av_log(avctx, AV_LOG_ERROR, \"invalid TIFF header \"\n                       \"in Exif data\\n\");\n                goto exif_end;\n            }\n\n            bytestream2_seek(&exif_gb, ifd_offset, SEEK_SET);\n            if (avpriv_exif_decode_ifd(avctx, &exif_gb, le, 0, &exif_metadata) < 0) {\n                av_log(avctx, AV_LOG_ERROR, \"error decoding Exif data\\n\");\n                goto exif_end;\n            }\n\n            av_dict_copy(&((AVFrame *) data)->metadata, exif_metadata, 0);\n\nexif_end:\n            av_dict_free(&exif_metadata);\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        }\n        case MKTAG('I', 'C', 'C', 'P'):\n        case MKTAG('A', 'N', 'I', 'M'):\n        case MKTAG('A', 'N', 'M', 'F'):\n        case MKTAG('X', 'M', 'P', ' '):\n            AV_WL32(chunk_str, chunk_type);\n            av_log(avctx, AV_LOG_WARNING, \"skipping unsupported chunk: %s\\n\",\n                   chunk_str);\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        default:\n            AV_WL32(chunk_str, chunk_type);\n            av_log(avctx, AV_LOG_VERBOSE, \"skipping unknown chunk: %s\\n\",\n                   chunk_str);\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        }\n    }\n\n    if (!*got_frame) {\n        av_log(avctx, AV_LOG_ERROR, \"image data not found\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    return avpkt->size;\n}\n\nstatic av_cold int webp_decode_close(AVCodecContext *avctx)\n{\n    WebPContext *s = avctx->priv_data;\n\n    if (s->initialized)\n        return ff_vp8_decode_free(avctx);\n\n    return 0;\n}\n\nAVCodec ff_webp_decoder = {\n    .name           = \"webp\",\n    .long_name      = NULL_IF_CONFIG_SMALL(\"WebP image\"),\n    .type           = AVMEDIA_TYPE_VIDEO,\n    .id             = AV_CODEC_ID_WEBP,\n    .priv_data_size = sizeof(WebPContext),\n    .decode         = webp_decode_frame,\n    .close          = webp_decode_close,\n    .capabilities   = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_FRAME_THREADS,\n};\n"], "fixing_code": ["/*\n * VP7/VP8 compatible video decoder\n *\n * Copyright (C) 2010 David Conrad\n * Copyright (C) 2010 Ronald S. Bultje\n * Copyright (C) 2010 Fiona Glaser\n * Copyright (C) 2012 Daniel Kang\n * Copyright (C) 2014 Peter Ross\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n#include \"libavutil/imgutils.h\"\n\n#include \"avcodec.h\"\n#include \"internal.h\"\n#include \"mathops.h\"\n#include \"rectangle.h\"\n#include \"thread.h\"\n#include \"vp8.h\"\n#include \"vp8data.h\"\n\n#if ARCH_ARM\n#   include \"arm/vp8.h\"\n#endif\n\n#if CONFIG_VP7_DECODER && CONFIG_VP8_DECODER\n#define VPX(vp7, f) (vp7 ? vp7_ ## f : vp8_ ## f)\n#elif CONFIG_VP7_DECODER\n#define VPX(vp7, f) vp7_ ## f\n#else // CONFIG_VP8_DECODER\n#define VPX(vp7, f) vp8_ ## f\n#endif\n\nstatic void free_buffers(VP8Context *s)\n{\n    int i;\n    if (s->thread_data)\n        for (i = 0; i < MAX_THREADS; i++) {\n#if HAVE_THREADS\n            pthread_cond_destroy(&s->thread_data[i].cond);\n            pthread_mutex_destroy(&s->thread_data[i].lock);\n#endif\n            av_freep(&s->thread_data[i].filter_strength);\n        }\n    av_freep(&s->thread_data);\n    av_freep(&s->macroblocks_base);\n    av_freep(&s->intra4x4_pred_mode_top);\n    av_freep(&s->top_nnz);\n    av_freep(&s->top_border);\n\n    s->macroblocks = NULL;\n}\n\nstatic int vp8_alloc_frame(VP8Context *s, VP8Frame *f, int ref)\n{\n    int ret;\n    if ((ret = ff_thread_get_buffer(s->avctx, &f->tf,\n                                    ref ? AV_GET_BUFFER_FLAG_REF : 0)) < 0)\n        return ret;\n    if (!(f->seg_map = av_buffer_allocz(s->mb_width * s->mb_height))) {\n        ff_thread_release_buffer(s->avctx, &f->tf);\n        return AVERROR(ENOMEM);\n    }\n    return 0;\n}\n\nstatic void vp8_release_frame(VP8Context *s, VP8Frame *f)\n{\n    av_buffer_unref(&f->seg_map);\n    ff_thread_release_buffer(s->avctx, &f->tf);\n}\n\n#if CONFIG_VP8_DECODER\nstatic int vp8_ref_frame(VP8Context *s, VP8Frame *dst, VP8Frame *src)\n{\n    int ret;\n\n    vp8_release_frame(s, dst);\n\n    if ((ret = ff_thread_ref_frame(&dst->tf, &src->tf)) < 0)\n        return ret;\n    if (src->seg_map &&\n        !(dst->seg_map = av_buffer_ref(src->seg_map))) {\n        vp8_release_frame(s, dst);\n        return AVERROR(ENOMEM);\n    }\n\n    return 0;\n}\n#endif /* CONFIG_VP8_DECODER */\n\nstatic void vp8_decode_flush_impl(AVCodecContext *avctx, int free_mem)\n{\n    VP8Context *s = avctx->priv_data;\n    int i;\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s->frames); i++)\n        vp8_release_frame(s, &s->frames[i]);\n    memset(s->framep, 0, sizeof(s->framep));\n\n    if (free_mem)\n        free_buffers(s);\n}\n\nstatic void vp8_decode_flush(AVCodecContext *avctx)\n{\n    vp8_decode_flush_impl(avctx, 0);\n}\n\nstatic VP8Frame *vp8_find_free_buffer(VP8Context *s)\n{\n    VP8Frame *frame = NULL;\n    int i;\n\n    // find a free buffer\n    for (i = 0; i < 5; i++)\n        if (&s->frames[i] != s->framep[VP56_FRAME_CURRENT]  &&\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN]   &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2]) {\n            frame = &s->frames[i];\n            break;\n        }\n    if (i == 5) {\n        av_log(s->avctx, AV_LOG_FATAL, \"Ran out of free frames!\\n\");\n        abort();\n    }\n    if (frame->tf.f->data[0])\n        vp8_release_frame(s, frame);\n\n    return frame;\n}\n\nstatic av_always_inline\nint update_dimensions(VP8Context *s, int width, int height, int is_vp7)\n{\n    AVCodecContext *avctx = s->avctx;\n    int i, ret;\n\n    if (width  != s->avctx->width || ((width+15)/16 != s->mb_width || (height+15)/16 != s->mb_height) && s->macroblocks_base ||\n        height != s->avctx->height) {\n        vp8_decode_flush_impl(s->avctx, 1);\n\n        ret = ff_set_dimensions(s->avctx, width, height);\n        if (ret < 0)\n            return ret;\n    }\n\n    s->mb_width  = (s->avctx->coded_width  + 15) / 16;\n    s->mb_height = (s->avctx->coded_height + 15) / 16;\n\n    s->mb_layout = is_vp7 || avctx->active_thread_type == FF_THREAD_SLICE &&\n                   avctx->thread_count > 1;\n    if (!s->mb_layout) { // Frame threading and one thread\n        s->macroblocks_base       = av_mallocz((s->mb_width + s->mb_height * 2 + 1) *\n                                               sizeof(*s->macroblocks));\n        s->intra4x4_pred_mode_top = av_mallocz(s->mb_width * 4);\n    } else // Sliced threading\n        s->macroblocks_base = av_mallocz((s->mb_width + 2) * (s->mb_height + 2) *\n                                         sizeof(*s->macroblocks));\n    s->top_nnz     = av_mallocz(s->mb_width * sizeof(*s->top_nnz));\n    s->top_border  = av_mallocz((s->mb_width + 1) * sizeof(*s->top_border));\n    s->thread_data = av_mallocz(MAX_THREADS * sizeof(VP8ThreadData));\n\n    if (!s->macroblocks_base || !s->top_nnz || !s->top_border ||\n        !s->thread_data || (!s->intra4x4_pred_mode_top && !s->mb_layout)) {\n        free_buffers(s);\n        return AVERROR(ENOMEM);\n    }\n\n    for (i = 0; i < MAX_THREADS; i++) {\n        s->thread_data[i].filter_strength =\n            av_mallocz(s->mb_width * sizeof(*s->thread_data[0].filter_strength));\n        if (!s->thread_data[i].filter_strength) {\n            free_buffers(s);\n            return AVERROR(ENOMEM);\n        }\n#if HAVE_THREADS\n        pthread_mutex_init(&s->thread_data[i].lock, NULL);\n        pthread_cond_init(&s->thread_data[i].cond, NULL);\n#endif\n    }\n\n    s->macroblocks = s->macroblocks_base + 1;\n\n    return 0;\n}\n\nstatic int vp7_update_dimensions(VP8Context *s, int width, int height)\n{\n    return update_dimensions(s, width, height, IS_VP7);\n}\n\nstatic int vp8_update_dimensions(VP8Context *s, int width, int height)\n{\n    return update_dimensions(s, width, height, IS_VP8);\n}\n\n\nstatic void parse_segment_info(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n    int i;\n\n    s->segmentation.update_map = vp8_rac_get(c);\n\n    if (vp8_rac_get(c)) { // update segment feature data\n        s->segmentation.absolute_vals = vp8_rac_get(c);\n\n        for (i = 0; i < 4; i++)\n            s->segmentation.base_quant[i]   = vp8_rac_get_sint(c, 7);\n\n        for (i = 0; i < 4; i++)\n            s->segmentation.filter_level[i] = vp8_rac_get_sint(c, 6);\n    }\n    if (s->segmentation.update_map)\n        for (i = 0; i < 3; i++)\n            s->prob->segmentid[i] = vp8_rac_get(c) ? vp8_rac_get_uint(c, 8) : 255;\n}\n\nstatic void update_lf_deltas(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n    int i;\n\n    for (i = 0; i < 4; i++) {\n        if (vp8_rac_get(c)) {\n            s->lf_delta.ref[i] = vp8_rac_get_uint(c, 6);\n\n            if (vp8_rac_get(c))\n                s->lf_delta.ref[i] = -s->lf_delta.ref[i];\n        }\n    }\n\n    for (i = MODE_I4x4; i <= VP8_MVMODE_SPLIT; i++) {\n        if (vp8_rac_get(c)) {\n            s->lf_delta.mode[i] = vp8_rac_get_uint(c, 6);\n\n            if (vp8_rac_get(c))\n                s->lf_delta.mode[i] = -s->lf_delta.mode[i];\n        }\n    }\n}\n\nstatic int setup_partitions(VP8Context *s, const uint8_t *buf, int buf_size)\n{\n    const uint8_t *sizes = buf;\n    int i;\n    int ret;\n\n    s->num_coeff_partitions = 1 << vp8_rac_get_uint(&s->c, 2);\n\n    buf      += 3 * (s->num_coeff_partitions - 1);\n    buf_size -= 3 * (s->num_coeff_partitions - 1);\n    if (buf_size < 0)\n        return -1;\n\n    for (i = 0; i < s->num_coeff_partitions - 1; i++) {\n        int size = AV_RL24(sizes + 3 * i);\n        if (buf_size - size < 0)\n            return -1;\n\n        ret = ff_vp56_init_range_decoder(&s->coeff_partition[i], buf, size);\n        if (ret < 0)\n            return ret;\n        buf      += size;\n        buf_size -= size;\n    }\n    return ff_vp56_init_range_decoder(&s->coeff_partition[i], buf, buf_size);\n}\n\nstatic void vp7_get_quants(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n\n    int yac_qi  = vp8_rac_get_uint(c, 7);\n    int ydc_qi  = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n    int y2dc_qi = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n    int y2ac_qi = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n    int uvdc_qi = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n    int uvac_qi = vp8_rac_get(c) ? vp8_rac_get_uint(c, 7) : yac_qi;\n\n    s->qmat[0].luma_qmul[0]    =       vp7_ydc_qlookup[ydc_qi];\n    s->qmat[0].luma_qmul[1]    =       vp7_yac_qlookup[yac_qi];\n    s->qmat[0].luma_dc_qmul[0] =       vp7_y2dc_qlookup[y2dc_qi];\n    s->qmat[0].luma_dc_qmul[1] =       vp7_y2ac_qlookup[y2ac_qi];\n    s->qmat[0].chroma_qmul[0]  = FFMIN(vp7_ydc_qlookup[uvdc_qi], 132);\n    s->qmat[0].chroma_qmul[1]  =       vp7_yac_qlookup[uvac_qi];\n}\n\nstatic void vp8_get_quants(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n    int i, base_qi;\n\n    int yac_qi     = vp8_rac_get_uint(c, 7);\n    int ydc_delta  = vp8_rac_get_sint(c, 4);\n    int y2dc_delta = vp8_rac_get_sint(c, 4);\n    int y2ac_delta = vp8_rac_get_sint(c, 4);\n    int uvdc_delta = vp8_rac_get_sint(c, 4);\n    int uvac_delta = vp8_rac_get_sint(c, 4);\n\n    for (i = 0; i < 4; i++) {\n        if (s->segmentation.enabled) {\n            base_qi = s->segmentation.base_quant[i];\n            if (!s->segmentation.absolute_vals)\n                base_qi += yac_qi;\n        } else\n            base_qi = yac_qi;\n\n        s->qmat[i].luma_qmul[0]    = vp8_dc_qlookup[av_clip_uintp2(base_qi + ydc_delta,  7)];\n        s->qmat[i].luma_qmul[1]    = vp8_ac_qlookup[av_clip_uintp2(base_qi,              7)];\n        s->qmat[i].luma_dc_qmul[0] = vp8_dc_qlookup[av_clip_uintp2(base_qi + y2dc_delta, 7)] * 2;\n        /* 101581>>16 is equivalent to 155/100 */\n        s->qmat[i].luma_dc_qmul[1] = vp8_ac_qlookup[av_clip_uintp2(base_qi + y2ac_delta, 7)] * 101581 >> 16;\n        s->qmat[i].chroma_qmul[0]  = vp8_dc_qlookup[av_clip_uintp2(base_qi + uvdc_delta, 7)];\n        s->qmat[i].chroma_qmul[1]  = vp8_ac_qlookup[av_clip_uintp2(base_qi + uvac_delta, 7)];\n\n        s->qmat[i].luma_dc_qmul[1] = FFMAX(s->qmat[i].luma_dc_qmul[1], 8);\n        s->qmat[i].chroma_qmul[0]  = FFMIN(s->qmat[i].chroma_qmul[0], 132);\n    }\n}\n\n/**\n * Determine which buffers golden and altref should be updated with after this frame.\n * The spec isn't clear here, so I'm going by my understanding of what libvpx does\n *\n * Intra frames update all 3 references\n * Inter frames update VP56_FRAME_PREVIOUS if the update_last flag is set\n * If the update (golden|altref) flag is set, it's updated with the current frame\n *      if update_last is set, and VP56_FRAME_PREVIOUS otherwise.\n * If the flag is not set, the number read means:\n *      0: no update\n *      1: VP56_FRAME_PREVIOUS\n *      2: update golden with altref, or update altref with golden\n */\nstatic VP56Frame ref_to_update(VP8Context *s, int update, VP56Frame ref)\n{\n    VP56RangeCoder *c = &s->c;\n\n    if (update)\n        return VP56_FRAME_CURRENT;\n\n    switch (vp8_rac_get_uint(c, 2)) {\n    case 1:\n        return VP56_FRAME_PREVIOUS;\n    case 2:\n        return (ref == VP56_FRAME_GOLDEN) ? VP56_FRAME_GOLDEN2 : VP56_FRAME_GOLDEN;\n    }\n    return VP56_FRAME_NONE;\n}\n\nstatic void vp78_reset_probability_tables(VP8Context *s)\n{\n    int i, j;\n    for (i = 0; i < 4; i++)\n        for (j = 0; j < 16; j++)\n            memcpy(s->prob->token[i][j], vp8_token_default_probs[i][vp8_coeff_band[j]],\n                   sizeof(s->prob->token[i][j]));\n}\n\nstatic void vp78_update_probability_tables(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n    int i, j, k, l, m;\n\n    for (i = 0; i < 4; i++)\n        for (j = 0; j < 8; j++)\n            for (k = 0; k < 3; k++)\n                for (l = 0; l < NUM_DCT_TOKENS-1; l++)\n                    if (vp56_rac_get_prob_branchy(c, vp8_token_update_probs[i][j][k][l])) {\n                        int prob = vp8_rac_get_uint(c, 8);\n                        for (m = 0; vp8_coeff_band_indexes[j][m] >= 0; m++)\n                            s->prob->token[i][vp8_coeff_band_indexes[j][m]][k][l] = prob;\n                    }\n}\n\n#define VP7_MVC_SIZE 17\n#define VP8_MVC_SIZE 19\n\nstatic void vp78_update_pred16x16_pred8x8_mvc_probabilities(VP8Context *s,\n                                                            int mvc_size)\n{\n    VP56RangeCoder *c = &s->c;\n    int i, j;\n\n    if (vp8_rac_get(c))\n        for (i = 0; i < 4; i++)\n            s->prob->pred16x16[i] = vp8_rac_get_uint(c, 8);\n    if (vp8_rac_get(c))\n        for (i = 0; i < 3; i++)\n            s->prob->pred8x8c[i]  = vp8_rac_get_uint(c, 8);\n\n    // 17.2 MV probability update\n    for (i = 0; i < 2; i++)\n        for (j = 0; j < mvc_size; j++)\n            if (vp56_rac_get_prob_branchy(c, vp8_mv_update_prob[i][j]))\n                s->prob->mvc[i][j] = vp8_rac_get_nn(c);\n}\n\nstatic void update_refs(VP8Context *s)\n{\n    VP56RangeCoder *c = &s->c;\n\n    int update_golden = vp8_rac_get(c);\n    int update_altref = vp8_rac_get(c);\n\n    s->update_golden = ref_to_update(s, update_golden, VP56_FRAME_GOLDEN);\n    s->update_altref = ref_to_update(s, update_altref, VP56_FRAME_GOLDEN2);\n}\n\nstatic void copy_chroma(AVFrame *dst, AVFrame *src, int width, int height)\n{\n    int i, j;\n\n    for (j = 1; j < 3; j++) {\n        for (i = 0; i < height / 2; i++)\n            memcpy(dst->data[j] + i * dst->linesize[j],\n                   src->data[j] + i * src->linesize[j], width / 2);\n    }\n}\n\nstatic void fade(uint8_t *dst, ptrdiff_t dst_linesize,\n                 const uint8_t *src, ptrdiff_t src_linesize,\n                 int width, int height,\n                 int alpha, int beta)\n{\n    int i, j;\n    for (j = 0; j < height; j++) {\n        for (i = 0; i < width; i++) {\n            uint8_t y = src[j * src_linesize + i];\n            dst[j * dst_linesize + i] = av_clip_uint8(y + ((y * beta) >> 8) + alpha);\n        }\n    }\n}\n\nstatic int vp7_fade_frame(VP8Context *s, VP56RangeCoder *c)\n{\n    int alpha = (int8_t) vp8_rac_get_uint(c, 8);\n    int beta  = (int8_t) vp8_rac_get_uint(c, 8);\n    int ret;\n\n    if (!s->keyframe && (alpha || beta)) {\n        int width  = s->mb_width * 16;\n        int height = s->mb_height * 16;\n        AVFrame *src, *dst;\n\n        if (!s->framep[VP56_FRAME_PREVIOUS] ||\n            !s->framep[VP56_FRAME_GOLDEN]) {\n            av_log(s->avctx, AV_LOG_WARNING, \"Discarding interframe without a prior keyframe!\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        dst =\n        src = s->framep[VP56_FRAME_PREVIOUS]->tf.f;\n\n        /* preserve the golden frame, write a new previous frame */\n        if (s->framep[VP56_FRAME_GOLDEN] == s->framep[VP56_FRAME_PREVIOUS]) {\n            s->framep[VP56_FRAME_PREVIOUS] = vp8_find_free_buffer(s);\n            if ((ret = vp8_alloc_frame(s, s->framep[VP56_FRAME_PREVIOUS], 1)) < 0)\n                return ret;\n\n            dst = s->framep[VP56_FRAME_PREVIOUS]->tf.f;\n\n            copy_chroma(dst, src, width, height);\n        }\n\n        fade(dst->data[0], dst->linesize[0],\n             src->data[0], src->linesize[0],\n             width, height, alpha, beta);\n    }\n\n    return 0;\n}\n\nstatic int vp7_decode_frame_header(VP8Context *s, const uint8_t *buf, int buf_size)\n{\n    VP56RangeCoder *c = &s->c;\n    int part1_size, hscale, vscale, i, j, ret;\n    int width  = s->avctx->width;\n    int height = s->avctx->height;\n\n    if (buf_size < 4) {\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->profile = (buf[0] >> 1) & 7;\n    if (s->profile > 1) {\n        avpriv_request_sample(s->avctx, \"Unknown profile %d\", s->profile);\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->keyframe  = !(buf[0] & 1);\n    s->invisible = 0;\n    part1_size   = AV_RL24(buf) >> 4;\n\n    if (buf_size < 4 - s->profile + part1_size) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Buffer size %d is too small, needed : %d\\n\", buf_size, 4 - s->profile + part1_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    buf      += 4 - s->profile;\n    buf_size -= 4 - s->profile;\n\n    memcpy(s->put_pixels_tab, s->vp8dsp.put_vp8_epel_pixels_tab, sizeof(s->put_pixels_tab));\n\n    ret = ff_vp56_init_range_decoder(c, buf, part1_size);\n    if (ret < 0)\n        return ret;\n    buf      += part1_size;\n    buf_size -= part1_size;\n\n    /* A. Dimension information (keyframes only) */\n    if (s->keyframe) {\n        width  = vp8_rac_get_uint(c, 12);\n        height = vp8_rac_get_uint(c, 12);\n        hscale = vp8_rac_get_uint(c, 2);\n        vscale = vp8_rac_get_uint(c, 2);\n        if (hscale || vscale)\n            avpriv_request_sample(s->avctx, \"Upscaling\");\n\n        s->update_golden = s->update_altref = VP56_FRAME_CURRENT;\n        vp78_reset_probability_tables(s);\n        memcpy(s->prob->pred16x16, vp8_pred16x16_prob_inter,\n               sizeof(s->prob->pred16x16));\n        memcpy(s->prob->pred8x8c, vp8_pred8x8c_prob_inter,\n               sizeof(s->prob->pred8x8c));\n        for (i = 0; i < 2; i++)\n            memcpy(s->prob->mvc[i], vp7_mv_default_prob[i],\n                   sizeof(vp7_mv_default_prob[i]));\n        memset(&s->segmentation, 0, sizeof(s->segmentation));\n        memset(&s->lf_delta, 0, sizeof(s->lf_delta));\n        memcpy(s->prob[0].scan, ff_zigzag_scan, sizeof(s->prob[0].scan));\n    }\n\n    if (s->keyframe || s->profile > 0)\n        memset(s->inter_dc_pred, 0 , sizeof(s->inter_dc_pred));\n\n    /* B. Decoding information for all four macroblock-level features */\n    for (i = 0; i < 4; i++) {\n        s->feature_enabled[i] = vp8_rac_get(c);\n        if (s->feature_enabled[i]) {\n             s->feature_present_prob[i] = vp8_rac_get_uint(c, 8);\n\n             for (j = 0; j < 3; j++)\n                 s->feature_index_prob[i][j] =\n                     vp8_rac_get(c) ? vp8_rac_get_uint(c, 8) : 255;\n\n             if (vp7_feature_value_size[s->profile][i])\n                 for (j = 0; j < 4; j++)\n                     s->feature_value[i][j] =\n                        vp8_rac_get(c) ? vp8_rac_get_uint(c, vp7_feature_value_size[s->profile][i]) : 0;\n        }\n    }\n\n    s->segmentation.enabled    = 0;\n    s->segmentation.update_map = 0;\n    s->lf_delta.enabled        = 0;\n\n    s->num_coeff_partitions = 1;\n    ret = ff_vp56_init_range_decoder(&s->coeff_partition[0], buf, buf_size);\n    if (ret < 0)\n        return ret;\n\n    if (!s->macroblocks_base || /* first frame */\n        width != s->avctx->width || height != s->avctx->height ||\n        (width + 15) / 16 != s->mb_width || (height + 15) / 16 != s->mb_height) {\n        if ((ret = vp7_update_dimensions(s, width, height)) < 0)\n            return ret;\n    }\n\n    /* C. Dequantization indices */\n    vp7_get_quants(s);\n\n    /* D. Golden frame update flag (a Flag) for interframes only */\n    if (!s->keyframe) {\n        s->update_golden = vp8_rac_get(c) ? VP56_FRAME_CURRENT : VP56_FRAME_NONE;\n        s->sign_bias[VP56_FRAME_GOLDEN] = 0;\n    }\n\n    s->update_last          = 1;\n    s->update_probabilities = 1;\n    s->fade_present         = 1;\n\n    if (s->profile > 0) {\n        s->update_probabilities = vp8_rac_get(c);\n        if (!s->update_probabilities)\n            s->prob[1] = s->prob[0];\n\n        if (!s->keyframe)\n            s->fade_present = vp8_rac_get(c);\n    }\n\n    /* E. Fading information for previous frame */\n    if (s->fade_present && vp8_rac_get(c)) {\n        if ((ret = vp7_fade_frame(s ,c)) < 0)\n            return ret;\n    }\n\n    /* F. Loop filter type */\n    if (!s->profile)\n        s->filter.simple = vp8_rac_get(c);\n\n    /* G. DCT coefficient ordering specification */\n    if (vp8_rac_get(c))\n        for (i = 1; i < 16; i++)\n            s->prob[0].scan[i] = ff_zigzag_scan[vp8_rac_get_uint(c, 4)];\n\n    /* H. Loop filter levels  */\n    if (s->profile > 0)\n        s->filter.simple = vp8_rac_get(c);\n    s->filter.level     = vp8_rac_get_uint(c, 6);\n    s->filter.sharpness = vp8_rac_get_uint(c, 3);\n\n    /* I. DCT coefficient probability update; 13.3 Token Probability Updates */\n    vp78_update_probability_tables(s);\n\n    s->mbskip_enabled = 0;\n\n    /* J. The remaining frame header data occurs ONLY FOR INTERFRAMES */\n    if (!s->keyframe) {\n        s->prob->intra  = vp8_rac_get_uint(c, 8);\n        s->prob->last   = vp8_rac_get_uint(c, 8);\n        vp78_update_pred16x16_pred8x8_mvc_probabilities(s, VP7_MVC_SIZE);\n    }\n\n    return 0;\n}\n\nstatic int vp8_decode_frame_header(VP8Context *s, const uint8_t *buf, int buf_size)\n{\n    VP56RangeCoder *c = &s->c;\n    int header_size, hscale, vscale, ret;\n    int width  = s->avctx->width;\n    int height = s->avctx->height;\n\n    if (buf_size < 3) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Insufficent data (%d) for header\\n\", buf_size);\n        return AVERROR_INVALIDDATA;\n    }\n\n    s->keyframe  = !(buf[0] & 1);\n    s->profile   =  (buf[0]>>1) & 7;\n    s->invisible = !(buf[0] & 0x10);\n    header_size  = AV_RL24(buf) >> 5;\n    buf      += 3;\n    buf_size -= 3;\n\n    if (s->profile > 3)\n        av_log(s->avctx, AV_LOG_WARNING, \"Unknown profile %d\\n\", s->profile);\n\n    if (!s->profile)\n        memcpy(s->put_pixels_tab, s->vp8dsp.put_vp8_epel_pixels_tab,\n               sizeof(s->put_pixels_tab));\n    else    // profile 1-3 use bilinear, 4+ aren't defined so whatever\n        memcpy(s->put_pixels_tab, s->vp8dsp.put_vp8_bilinear_pixels_tab,\n               sizeof(s->put_pixels_tab));\n\n    if (header_size > buf_size - 7 * s->keyframe) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Header size larger than data provided\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (s->keyframe) {\n        if (AV_RL24(buf) != 0x2a019d) {\n            av_log(s->avctx, AV_LOG_ERROR,\n                   \"Invalid start code 0x%x\\n\", AV_RL24(buf));\n            return AVERROR_INVALIDDATA;\n        }\n        width     = AV_RL16(buf + 3) & 0x3fff;\n        height    = AV_RL16(buf + 5) & 0x3fff;\n        hscale    = buf[4] >> 6;\n        vscale    = buf[6] >> 6;\n        buf      += 7;\n        buf_size -= 7;\n\n        if (hscale || vscale)\n            avpriv_request_sample(s->avctx, \"Upscaling\");\n\n        s->update_golden = s->update_altref = VP56_FRAME_CURRENT;\n        vp78_reset_probability_tables(s);\n        memcpy(s->prob->pred16x16, vp8_pred16x16_prob_inter,\n               sizeof(s->prob->pred16x16));\n        memcpy(s->prob->pred8x8c, vp8_pred8x8c_prob_inter,\n               sizeof(s->prob->pred8x8c));\n        memcpy(s->prob->mvc, vp8_mv_default_prob,\n               sizeof(s->prob->mvc));\n        memset(&s->segmentation, 0, sizeof(s->segmentation));\n        memset(&s->lf_delta, 0, sizeof(s->lf_delta));\n    }\n\n    ret = ff_vp56_init_range_decoder(c, buf, header_size);\n    if (ret < 0)\n        return ret;\n    buf      += header_size;\n    buf_size -= header_size;\n\n    if (s->keyframe) {\n        s->colorspace = vp8_rac_get(c);\n        if (s->colorspace)\n            av_log(s->avctx, AV_LOG_WARNING, \"Unspecified colorspace\\n\");\n        s->fullrange = vp8_rac_get(c);\n    }\n\n    if ((s->segmentation.enabled = vp8_rac_get(c)))\n        parse_segment_info(s);\n    else\n        s->segmentation.update_map = 0; // FIXME: move this to some init function?\n\n    s->filter.simple    = vp8_rac_get(c);\n    s->filter.level     = vp8_rac_get_uint(c, 6);\n    s->filter.sharpness = vp8_rac_get_uint(c, 3);\n\n    if ((s->lf_delta.enabled = vp8_rac_get(c)))\n        if (vp8_rac_get(c))\n            update_lf_deltas(s);\n\n    if (setup_partitions(s, buf, buf_size)) {\n        av_log(s->avctx, AV_LOG_ERROR, \"Invalid partitions\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    if (!s->macroblocks_base || /* first frame */\n        width != s->avctx->width || height != s->avctx->height ||\n        (width+15)/16 != s->mb_width || (height+15)/16 != s->mb_height)\n        if ((ret = vp8_update_dimensions(s, width, height)) < 0)\n            return ret;\n\n    vp8_get_quants(s);\n\n    if (!s->keyframe) {\n        update_refs(s);\n        s->sign_bias[VP56_FRAME_GOLDEN]               = vp8_rac_get(c);\n        s->sign_bias[VP56_FRAME_GOLDEN2 /* altref */] = vp8_rac_get(c);\n    }\n\n    // if we aren't saving this frame's probabilities for future frames,\n    // make a copy of the current probabilities\n    if (!(s->update_probabilities = vp8_rac_get(c)))\n        s->prob[1] = s->prob[0];\n\n    s->update_last = s->keyframe || vp8_rac_get(c);\n\n    vp78_update_probability_tables(s);\n\n    if ((s->mbskip_enabled = vp8_rac_get(c)))\n        s->prob->mbskip = vp8_rac_get_uint(c, 8);\n\n    if (!s->keyframe) {\n        s->prob->intra  = vp8_rac_get_uint(c, 8);\n        s->prob->last   = vp8_rac_get_uint(c, 8);\n        s->prob->golden = vp8_rac_get_uint(c, 8);\n        vp78_update_pred16x16_pred8x8_mvc_probabilities(s, VP8_MVC_SIZE);\n    }\n\n    return 0;\n}\n\nstatic av_always_inline\nvoid clamp_mv(VP8mvbounds *s, VP56mv *dst, const VP56mv *src)\n{\n    dst->x = av_clip(src->x, av_clip(s->mv_min.x, INT16_MIN, INT16_MAX),\n                             av_clip(s->mv_max.x, INT16_MIN, INT16_MAX));\n    dst->y = av_clip(src->y, av_clip(s->mv_min.y, INT16_MIN, INT16_MAX),\n                             av_clip(s->mv_max.y, INT16_MIN, INT16_MAX));\n}\n\n/**\n * Motion vector coding, 17.1.\n */\nstatic av_always_inline int read_mv_component(VP56RangeCoder *c, const uint8_t *p, int vp7)\n{\n    int bit, x = 0;\n\n    if (vp56_rac_get_prob_branchy(c, p[0])) {\n        int i;\n\n        for (i = 0; i < 3; i++)\n            x += vp56_rac_get_prob(c, p[9 + i]) << i;\n        for (i = (vp7 ? 7 : 9); i > 3; i--)\n            x += vp56_rac_get_prob(c, p[9 + i]) << i;\n        if (!(x & (vp7 ? 0xF0 : 0xFFF0)) || vp56_rac_get_prob(c, p[12]))\n            x += 8;\n    } else {\n        // small_mvtree\n        const uint8_t *ps = p + 2;\n        bit = vp56_rac_get_prob(c, *ps);\n        ps += 1 + 3 * bit;\n        x  += 4 * bit;\n        bit = vp56_rac_get_prob(c, *ps);\n        ps += 1 + bit;\n        x  += 2 * bit;\n        x  += vp56_rac_get_prob(c, *ps);\n    }\n\n    return (x && vp56_rac_get_prob(c, p[1])) ? -x : x;\n}\n\nstatic int vp7_read_mv_component(VP56RangeCoder *c, const uint8_t *p)\n{\n    return read_mv_component(c, p, 1);\n}\n\nstatic int vp8_read_mv_component(VP56RangeCoder *c, const uint8_t *p)\n{\n    return read_mv_component(c, p, 0);\n}\n\nstatic av_always_inline\nconst uint8_t *get_submv_prob(uint32_t left, uint32_t top, int is_vp7)\n{\n    if (is_vp7)\n        return vp7_submv_prob;\n\n    if (left == top)\n        return vp8_submv_prob[4 - !!left];\n    if (!top)\n        return vp8_submv_prob[2];\n    return vp8_submv_prob[1 - !!left];\n}\n\n/**\n * Split motion vector prediction, 16.4.\n * @returns the number of motion vectors parsed (2, 4 or 16)\n */\nstatic av_always_inline\nint decode_splitmvs(VP8Context *s, VP56RangeCoder *c, VP8Macroblock *mb,\n                    int layout, int is_vp7)\n{\n    int part_idx;\n    int n, num;\n    VP8Macroblock *top_mb;\n    VP8Macroblock *left_mb = &mb[-1];\n    const uint8_t *mbsplits_left = vp8_mbsplits[left_mb->partitioning];\n    const uint8_t *mbsplits_top, *mbsplits_cur, *firstidx;\n    VP56mv *top_mv;\n    VP56mv *left_mv = left_mb->bmv;\n    VP56mv *cur_mv  = mb->bmv;\n\n    if (!layout) // layout is inlined, s->mb_layout is not\n        top_mb = &mb[2];\n    else\n        top_mb = &mb[-s->mb_width - 1];\n    mbsplits_top = vp8_mbsplits[top_mb->partitioning];\n    top_mv       = top_mb->bmv;\n\n    if (vp56_rac_get_prob_branchy(c, vp8_mbsplit_prob[0])) {\n        if (vp56_rac_get_prob_branchy(c, vp8_mbsplit_prob[1]))\n            part_idx = VP8_SPLITMVMODE_16x8 + vp56_rac_get_prob(c, vp8_mbsplit_prob[2]);\n        else\n            part_idx = VP8_SPLITMVMODE_8x8;\n    } else {\n        part_idx = VP8_SPLITMVMODE_4x4;\n    }\n\n    num              = vp8_mbsplit_count[part_idx];\n    mbsplits_cur     = vp8_mbsplits[part_idx],\n    firstidx         = vp8_mbfirstidx[part_idx];\n    mb->partitioning = part_idx;\n\n    for (n = 0; n < num; n++) {\n        int k = firstidx[n];\n        uint32_t left, above;\n        const uint8_t *submv_prob;\n\n        if (!(k & 3))\n            left = AV_RN32A(&left_mv[mbsplits_left[k + 3]]);\n        else\n            left = AV_RN32A(&cur_mv[mbsplits_cur[k - 1]]);\n        if (k <= 3)\n            above = AV_RN32A(&top_mv[mbsplits_top[k + 12]]);\n        else\n            above = AV_RN32A(&cur_mv[mbsplits_cur[k - 4]]);\n\n        submv_prob = get_submv_prob(left, above, is_vp7);\n\n        if (vp56_rac_get_prob_branchy(c, submv_prob[0])) {\n            if (vp56_rac_get_prob_branchy(c, submv_prob[1])) {\n                if (vp56_rac_get_prob_branchy(c, submv_prob[2])) {\n                    mb->bmv[n].y = mb->mv.y +\n                                   read_mv_component(c, s->prob->mvc[0], is_vp7);\n                    mb->bmv[n].x = mb->mv.x +\n                                   read_mv_component(c, s->prob->mvc[1], is_vp7);\n                } else {\n                    AV_ZERO32(&mb->bmv[n]);\n                }\n            } else {\n                AV_WN32A(&mb->bmv[n], above);\n            }\n        } else {\n            AV_WN32A(&mb->bmv[n], left);\n        }\n    }\n\n    return num;\n}\n\n/**\n * The vp7 reference decoder uses a padding macroblock column (added to right\n * edge of the frame) to guard against illegal macroblock offsets. The\n * algorithm has bugs that permit offsets to straddle the padding column.\n * This function replicates those bugs.\n *\n * @param[out] edge_x macroblock x address\n * @param[out] edge_y macroblock y address\n *\n * @return macroblock offset legal (boolean)\n */\nstatic int vp7_calculate_mb_offset(int mb_x, int mb_y, int mb_width,\n                                   int xoffset, int yoffset, int boundary,\n                                   int *edge_x, int *edge_y)\n{\n    int vwidth = mb_width + 1;\n    int new = (mb_y + yoffset) * vwidth + mb_x + xoffset;\n    if (new < boundary || new % vwidth == vwidth - 1)\n        return 0;\n    *edge_y = new / vwidth;\n    *edge_x = new % vwidth;\n    return 1;\n}\n\nstatic const VP56mv *get_bmv_ptr(const VP8Macroblock *mb, int subblock)\n{\n    return &mb->bmv[mb->mode == VP8_MVMODE_SPLIT ? vp8_mbsplits[mb->partitioning][subblock] : 0];\n}\n\nstatic av_always_inline\nvoid vp7_decode_mvs(VP8Context *s, VP8Macroblock *mb,\n                    int mb_x, int mb_y, int layout)\n{\n    VP8Macroblock *mb_edge[12];\n    enum { CNT_ZERO, CNT_NEAREST, CNT_NEAR };\n    enum { VP8_EDGE_TOP, VP8_EDGE_LEFT, VP8_EDGE_TOPLEFT };\n    int idx = CNT_ZERO;\n    VP56mv near_mv[3];\n    uint8_t cnt[3] = { 0 };\n    VP56RangeCoder *c = &s->c;\n    int i;\n\n    AV_ZERO32(&near_mv[0]);\n    AV_ZERO32(&near_mv[1]);\n    AV_ZERO32(&near_mv[2]);\n\n    for (i = 0; i < VP7_MV_PRED_COUNT; i++) {\n        const VP7MVPred * pred = &vp7_mv_pred[i];\n        int edge_x, edge_y;\n\n        if (vp7_calculate_mb_offset(mb_x, mb_y, s->mb_width, pred->xoffset,\n                                    pred->yoffset, !s->profile, &edge_x, &edge_y)) {\n            VP8Macroblock *edge = mb_edge[i] = (s->mb_layout == 1)\n                                             ? s->macroblocks_base + 1 + edge_x +\n                                               (s->mb_width + 1) * (edge_y + 1)\n                                             : s->macroblocks + edge_x +\n                                               (s->mb_height - edge_y - 1) * 2;\n            uint32_t mv = AV_RN32A(get_bmv_ptr(edge, vp7_mv_pred[i].subblock));\n            if (mv) {\n                if (AV_RN32A(&near_mv[CNT_NEAREST])) {\n                    if (mv == AV_RN32A(&near_mv[CNT_NEAREST])) {\n                        idx = CNT_NEAREST;\n                    } else if (AV_RN32A(&near_mv[CNT_NEAR])) {\n                        if (mv != AV_RN32A(&near_mv[CNT_NEAR]))\n                            continue;\n                        idx = CNT_NEAR;\n                    } else {\n                        AV_WN32A(&near_mv[CNT_NEAR], mv);\n                        idx = CNT_NEAR;\n                    }\n                } else {\n                    AV_WN32A(&near_mv[CNT_NEAREST], mv);\n                    idx = CNT_NEAREST;\n                }\n            } else {\n                idx = CNT_ZERO;\n            }\n        } else {\n            idx = CNT_ZERO;\n        }\n        cnt[idx] += vp7_mv_pred[i].score;\n    }\n\n    mb->partitioning = VP8_SPLITMVMODE_NONE;\n\n    if (vp56_rac_get_prob_branchy(c, vp7_mode_contexts[cnt[CNT_ZERO]][0])) {\n        mb->mode = VP8_MVMODE_MV;\n\n        if (vp56_rac_get_prob_branchy(c, vp7_mode_contexts[cnt[CNT_NEAREST]][1])) {\n\n            if (vp56_rac_get_prob_branchy(c, vp7_mode_contexts[cnt[CNT_NEAR]][2])) {\n\n                if (cnt[CNT_NEAREST] > cnt[CNT_NEAR])\n                    AV_WN32A(&mb->mv, cnt[CNT_ZERO] > cnt[CNT_NEAREST] ? 0 : AV_RN32A(&near_mv[CNT_NEAREST]));\n                else\n                    AV_WN32A(&mb->mv, cnt[CNT_ZERO] > cnt[CNT_NEAR]    ? 0 : AV_RN32A(&near_mv[CNT_NEAR]));\n\n                if (vp56_rac_get_prob_branchy(c, vp7_mode_contexts[cnt[CNT_NEAR]][3])) {\n                    mb->mode = VP8_MVMODE_SPLIT;\n                    mb->mv = mb->bmv[decode_splitmvs(s, c, mb, layout, IS_VP7) - 1];\n                } else {\n                    mb->mv.y += vp7_read_mv_component(c, s->prob->mvc[0]);\n                    mb->mv.x += vp7_read_mv_component(c, s->prob->mvc[1]);\n                    mb->bmv[0] = mb->mv;\n                }\n            } else {\n                mb->mv = near_mv[CNT_NEAR];\n                mb->bmv[0] = mb->mv;\n            }\n        } else {\n            mb->mv = near_mv[CNT_NEAREST];\n            mb->bmv[0] = mb->mv;\n        }\n    } else {\n        mb->mode = VP8_MVMODE_ZERO;\n        AV_ZERO32(&mb->mv);\n        mb->bmv[0] = mb->mv;\n    }\n}\n\nstatic av_always_inline\nvoid vp8_decode_mvs(VP8Context *s, VP8mvbounds *mv_bounds, VP8Macroblock *mb,\n                    int mb_x, int mb_y, int layout)\n{\n    VP8Macroblock *mb_edge[3] = { 0      /* top */,\n                                  mb - 1 /* left */,\n                                  0      /* top-left */ };\n    enum { CNT_ZERO, CNT_NEAREST, CNT_NEAR, CNT_SPLITMV };\n    enum { VP8_EDGE_TOP, VP8_EDGE_LEFT, VP8_EDGE_TOPLEFT };\n    int idx = CNT_ZERO;\n    int cur_sign_bias = s->sign_bias[mb->ref_frame];\n    int8_t *sign_bias = s->sign_bias;\n    VP56mv near_mv[4];\n    uint8_t cnt[4] = { 0 };\n    VP56RangeCoder *c = &s->c;\n\n    if (!layout) { // layout is inlined (s->mb_layout is not)\n        mb_edge[0] = mb + 2;\n        mb_edge[2] = mb + 1;\n    } else {\n        mb_edge[0] = mb - s->mb_width - 1;\n        mb_edge[2] = mb - s->mb_width - 2;\n    }\n\n    AV_ZERO32(&near_mv[0]);\n    AV_ZERO32(&near_mv[1]);\n    AV_ZERO32(&near_mv[2]);\n\n    /* Process MB on top, left and top-left */\n#define MV_EDGE_CHECK(n)                                                      \\\n    {                                                                         \\\n        VP8Macroblock *edge = mb_edge[n];                                     \\\n        int edge_ref = edge->ref_frame;                                       \\\n        if (edge_ref != VP56_FRAME_CURRENT) {                                 \\\n            uint32_t mv = AV_RN32A(&edge->mv);                                \\\n            if (mv) {                                                         \\\n                if (cur_sign_bias != sign_bias[edge_ref]) {                   \\\n                    /* SWAR negate of the values in mv. */                    \\\n                    mv = ~mv;                                                 \\\n                    mv = ((mv & 0x7fff7fff) +                                 \\\n                          0x00010001) ^ (mv & 0x80008000);                    \\\n                }                                                             \\\n                if (!n || mv != AV_RN32A(&near_mv[idx]))                      \\\n                    AV_WN32A(&near_mv[++idx], mv);                            \\\n                cnt[idx] += 1 + (n != 2);                                     \\\n            } else                                                            \\\n                cnt[CNT_ZERO] += 1 + (n != 2);                                \\\n        }                                                                     \\\n    }\n\n    MV_EDGE_CHECK(0)\n    MV_EDGE_CHECK(1)\n    MV_EDGE_CHECK(2)\n\n    mb->partitioning = VP8_SPLITMVMODE_NONE;\n    if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_ZERO]][0])) {\n        mb->mode = VP8_MVMODE_MV;\n\n        /* If we have three distinct MVs, merge first and last if they're the same */\n        if (cnt[CNT_SPLITMV] &&\n            AV_RN32A(&near_mv[1 + VP8_EDGE_TOP]) == AV_RN32A(&near_mv[1 + VP8_EDGE_TOPLEFT]))\n            cnt[CNT_NEAREST] += 1;\n\n        /* Swap near and nearest if necessary */\n        if (cnt[CNT_NEAR] > cnt[CNT_NEAREST]) {\n            FFSWAP(uint8_t,     cnt[CNT_NEAREST],     cnt[CNT_NEAR]);\n            FFSWAP( VP56mv, near_mv[CNT_NEAREST], near_mv[CNT_NEAR]);\n        }\n\n        if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_NEAREST]][1])) {\n            if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_NEAR]][2])) {\n                /* Choose the best mv out of 0,0 and the nearest mv */\n                clamp_mv(mv_bounds, &mb->mv, &near_mv[CNT_ZERO + (cnt[CNT_NEAREST] >= cnt[CNT_ZERO])]);\n                cnt[CNT_SPLITMV] = ((mb_edge[VP8_EDGE_LEFT]->mode    == VP8_MVMODE_SPLIT) +\n                                    (mb_edge[VP8_EDGE_TOP]->mode     == VP8_MVMODE_SPLIT)) * 2 +\n                                    (mb_edge[VP8_EDGE_TOPLEFT]->mode == VP8_MVMODE_SPLIT);\n\n                if (vp56_rac_get_prob_branchy(c, vp8_mode_contexts[cnt[CNT_SPLITMV]][3])) {\n                    mb->mode = VP8_MVMODE_SPLIT;\n                    mb->mv = mb->bmv[decode_splitmvs(s, c, mb, layout, IS_VP8) - 1];\n                } else {\n                    mb->mv.y  += vp8_read_mv_component(c, s->prob->mvc[0]);\n                    mb->mv.x  += vp8_read_mv_component(c, s->prob->mvc[1]);\n                    mb->bmv[0] = mb->mv;\n                }\n            } else {\n                clamp_mv(mv_bounds, &mb->mv, &near_mv[CNT_NEAR]);\n                mb->bmv[0] = mb->mv;\n            }\n        } else {\n            clamp_mv(mv_bounds, &mb->mv, &near_mv[CNT_NEAREST]);\n            mb->bmv[0] = mb->mv;\n        }\n    } else {\n        mb->mode = VP8_MVMODE_ZERO;\n        AV_ZERO32(&mb->mv);\n        mb->bmv[0] = mb->mv;\n    }\n}\n\nstatic av_always_inline\nvoid decode_intra4x4_modes(VP8Context *s, VP56RangeCoder *c, VP8Macroblock *mb,\n                           int mb_x, int keyframe, int layout)\n{\n    uint8_t *intra4x4 = mb->intra4x4_pred_mode_mb;\n\n    if (layout) {\n        VP8Macroblock *mb_top = mb - s->mb_width - 1;\n        memcpy(mb->intra4x4_pred_mode_top, mb_top->intra4x4_pred_mode_top, 4);\n    }\n    if (keyframe) {\n        int x, y;\n        uint8_t *top;\n        uint8_t *const left = s->intra4x4_pred_mode_left;\n        if (layout)\n            top = mb->intra4x4_pred_mode_top;\n        else\n            top = s->intra4x4_pred_mode_top + 4 * mb_x;\n        for (y = 0; y < 4; y++) {\n            for (x = 0; x < 4; x++) {\n                const uint8_t *ctx;\n                ctx       = vp8_pred4x4_prob_intra[top[x]][left[y]];\n                *intra4x4 = vp8_rac_get_tree(c, vp8_pred4x4_tree, ctx);\n                left[y]   = top[x] = *intra4x4;\n                intra4x4++;\n            }\n        }\n    } else {\n        int i;\n        for (i = 0; i < 16; i++)\n            intra4x4[i] = vp8_rac_get_tree(c, vp8_pred4x4_tree,\n                                           vp8_pred4x4_prob_inter);\n    }\n}\n\nstatic av_always_inline\nvoid decode_mb_mode(VP8Context *s, VP8mvbounds *mv_bounds,\n                    VP8Macroblock *mb, int mb_x, int mb_y,\n                    uint8_t *segment, uint8_t *ref, int layout, int is_vp7)\n{\n    VP56RangeCoder *c = &s->c;\n    static const char *vp7_feature_name[] = { \"q-index\",\n                                              \"lf-delta\",\n                                              \"partial-golden-update\",\n                                              \"blit-pitch\" };\n    if (is_vp7) {\n        int i;\n        *segment = 0;\n        for (i = 0; i < 4; i++) {\n            if (s->feature_enabled[i]) {\n                if (vp56_rac_get_prob_branchy(c, s->feature_present_prob[i])) {\n                      int index = vp8_rac_get_tree(c, vp7_feature_index_tree,\n                                                   s->feature_index_prob[i]);\n                      av_log(s->avctx, AV_LOG_WARNING,\n                             \"Feature %s present in macroblock (value 0x%x)\\n\",\n                             vp7_feature_name[i], s->feature_value[i][index]);\n                }\n           }\n        }\n    } else if (s->segmentation.update_map) {\n        int bit  = vp56_rac_get_prob(c, s->prob->segmentid[0]);\n        *segment = vp56_rac_get_prob(c, s->prob->segmentid[1+bit]) + 2*bit;\n    } else if (s->segmentation.enabled)\n        *segment = ref ? *ref : *segment;\n    mb->segment = *segment;\n\n    mb->skip = s->mbskip_enabled ? vp56_rac_get_prob(c, s->prob->mbskip) : 0;\n\n    if (s->keyframe) {\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_intra,\n                                    vp8_pred16x16_prob_intra);\n\n        if (mb->mode == MODE_I4x4) {\n            decode_intra4x4_modes(s, c, mb, mb_x, 1, layout);\n        } else {\n            const uint32_t modes = (is_vp7 ? vp7_pred4x4_mode\n                                           : vp8_pred4x4_mode)[mb->mode] * 0x01010101u;\n            if (s->mb_layout)\n                AV_WN32A(mb->intra4x4_pred_mode_top, modes);\n            else\n                AV_WN32A(s->intra4x4_pred_mode_top + 4 * mb_x, modes);\n            AV_WN32A(s->intra4x4_pred_mode_left, modes);\n        }\n\n        mb->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree,\n                                                vp8_pred8x8c_prob_intra);\n        mb->ref_frame        = VP56_FRAME_CURRENT;\n    } else if (vp56_rac_get_prob_branchy(c, s->prob->intra)) {\n        // inter MB, 16.2\n        if (vp56_rac_get_prob_branchy(c, s->prob->last))\n            mb->ref_frame =\n                (!is_vp7 && vp56_rac_get_prob(c, s->prob->golden)) ? VP56_FRAME_GOLDEN2 /* altref */\n                                                                   : VP56_FRAME_GOLDEN;\n        else\n            mb->ref_frame = VP56_FRAME_PREVIOUS;\n        s->ref_count[mb->ref_frame - 1]++;\n\n        // motion vectors, 16.3\n        if (is_vp7)\n            vp7_decode_mvs(s, mb, mb_x, mb_y, layout);\n        else\n            vp8_decode_mvs(s, mv_bounds, mb, mb_x, mb_y, layout);\n    } else {\n        // intra MB, 16.1\n        mb->mode = vp8_rac_get_tree(c, vp8_pred16x16_tree_inter, s->prob->pred16x16);\n\n        if (mb->mode == MODE_I4x4)\n            decode_intra4x4_modes(s, c, mb, mb_x, 0, layout);\n\n        mb->chroma_pred_mode = vp8_rac_get_tree(c, vp8_pred8x8c_tree,\n                                                s->prob->pred8x8c);\n        mb->ref_frame        = VP56_FRAME_CURRENT;\n        mb->partitioning     = VP8_SPLITMVMODE_NONE;\n        AV_ZERO32(&mb->bmv[0]);\n    }\n}\n\n/**\n * @param r     arithmetic bitstream reader context\n * @param block destination for block coefficients\n * @param probs probabilities to use when reading trees from the bitstream\n * @param i     initial coeff index, 0 unless a separate DC block is coded\n * @param qmul  array holding the dc/ac dequant factor at position 0/1\n *\n * @return 0 if no coeffs were decoded\n *         otherwise, the index of the last coeff decoded plus one\n */\nstatic av_always_inline\nint decode_block_coeffs_internal(VP56RangeCoder *r, int16_t block[16],\n                                 uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n                                 int i, uint8_t *token_prob, int16_t qmul[2],\n                                 const uint8_t scan[16], int vp7)\n{\n    VP56RangeCoder c = *r;\n    goto skip_eob;\n    do {\n        int coeff;\nrestart:\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[0]))   // DCT_EOB\n            break;\n\nskip_eob:\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[1])) { // DCT_0\n            if (++i == 16)\n                break; // invalid input; blocks should end with EOB\n            token_prob = probs[i][0];\n            if (vp7)\n                goto restart;\n            goto skip_eob;\n        }\n\n        if (!vp56_rac_get_prob_branchy(&c, token_prob[2])) { // DCT_1\n            coeff = 1;\n            token_prob = probs[i + 1][1];\n        } else {\n            if (!vp56_rac_get_prob_branchy(&c, token_prob[3])) { // DCT 2,3,4\n                coeff = vp56_rac_get_prob_branchy(&c, token_prob[4]);\n                if (coeff)\n                    coeff += vp56_rac_get_prob(&c, token_prob[5]);\n                coeff += 2;\n            } else {\n                // DCT_CAT*\n                if (!vp56_rac_get_prob_branchy(&c, token_prob[6])) {\n                    if (!vp56_rac_get_prob_branchy(&c, token_prob[7])) { // DCT_CAT1\n                        coeff = 5 + vp56_rac_get_prob(&c, vp8_dct_cat1_prob[0]);\n                    } else {                                    // DCT_CAT2\n                        coeff  = 7;\n                        coeff += vp56_rac_get_prob(&c, vp8_dct_cat2_prob[0]) << 1;\n                        coeff += vp56_rac_get_prob(&c, vp8_dct_cat2_prob[1]);\n                    }\n                } else {    // DCT_CAT3 and up\n                    int a   = vp56_rac_get_prob(&c, token_prob[8]);\n                    int b   = vp56_rac_get_prob(&c, token_prob[9 + a]);\n                    int cat = (a << 1) + b;\n                    coeff  = 3 + (8 << cat);\n                    coeff += vp8_rac_get_coeff(&c, ff_vp8_dct_cat_prob[cat]);\n                }\n            }\n            token_prob = probs[i + 1][2];\n        }\n        block[scan[i]] = (vp8_rac_get(&c) ? -coeff : coeff) * qmul[!!i];\n    } while (++i < 16);\n\n    *r = c;\n    return i;\n}\n\nstatic av_always_inline\nint inter_predict_dc(int16_t block[16], int16_t pred[2])\n{\n    int16_t dc = block[0];\n    int ret = 0;\n\n    if (pred[1] > 3) {\n        dc += pred[0];\n        ret = 1;\n    }\n\n    if (!pred[0] | !dc | ((int32_t)pred[0] ^ (int32_t)dc) >> 31) {\n        block[0] = pred[0] = dc;\n        pred[1] = 0;\n    } else {\n        if (pred[0] == dc)\n            pred[1]++;\n        block[0] = pred[0] = dc;\n    }\n\n    return ret;\n}\n\nstatic int vp7_decode_block_coeffs_internal(VP56RangeCoder *r,\n                                            int16_t block[16],\n                                            uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n                                            int i, uint8_t *token_prob,\n                                            int16_t qmul[2],\n                                            const uint8_t scan[16])\n{\n    return decode_block_coeffs_internal(r, block, probs, i,\n                                        token_prob, qmul, scan, IS_VP7);\n}\n\n#ifndef vp8_decode_block_coeffs_internal\nstatic int vp8_decode_block_coeffs_internal(VP56RangeCoder *r,\n                                            int16_t block[16],\n                                            uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n                                            int i, uint8_t *token_prob,\n                                            int16_t qmul[2])\n{\n    return decode_block_coeffs_internal(r, block, probs, i,\n                                        token_prob, qmul, ff_zigzag_scan, IS_VP8);\n}\n#endif\n\n/**\n * @param c          arithmetic bitstream reader context\n * @param block      destination for block coefficients\n * @param probs      probabilities to use when reading trees from the bitstream\n * @param i          initial coeff index, 0 unless a separate DC block is coded\n * @param zero_nhood the initial prediction context for number of surrounding\n *                   all-zero blocks (only left/top, so 0-2)\n * @param qmul       array holding the dc/ac dequant factor at position 0/1\n * @param scan       scan pattern (VP7 only)\n *\n * @return 0 if no coeffs were decoded\n *         otherwise, the index of the last coeff decoded plus one\n */\nstatic av_always_inline\nint decode_block_coeffs(VP56RangeCoder *c, int16_t block[16],\n                        uint8_t probs[16][3][NUM_DCT_TOKENS - 1],\n                        int i, int zero_nhood, int16_t qmul[2],\n                        const uint8_t scan[16], int vp7)\n{\n    uint8_t *token_prob = probs[i][zero_nhood];\n    if (!vp56_rac_get_prob_branchy(c, token_prob[0]))   // DCT_EOB\n        return 0;\n    return vp7 ? vp7_decode_block_coeffs_internal(c, block, probs, i,\n                                                  token_prob, qmul, scan)\n               : vp8_decode_block_coeffs_internal(c, block, probs, i,\n                                                  token_prob, qmul);\n}\n\nstatic av_always_inline\nvoid decode_mb_coeffs(VP8Context *s, VP8ThreadData *td, VP56RangeCoder *c,\n                      VP8Macroblock *mb, uint8_t t_nnz[9], uint8_t l_nnz[9],\n                      int is_vp7)\n{\n    int i, x, y, luma_start = 0, luma_ctx = 3;\n    int nnz_pred, nnz, nnz_total = 0;\n    int segment = mb->segment;\n    int block_dc = 0;\n\n    if (mb->mode != MODE_I4x4 && (is_vp7 || mb->mode != VP8_MVMODE_SPLIT)) {\n        nnz_pred = t_nnz[8] + l_nnz[8];\n\n        // decode DC values and do hadamard\n        nnz = decode_block_coeffs(c, td->block_dc, s->prob->token[1], 0,\n                                  nnz_pred, s->qmat[segment].luma_dc_qmul,\n                                  ff_zigzag_scan, is_vp7);\n        l_nnz[8] = t_nnz[8] = !!nnz;\n\n        if (is_vp7 && mb->mode > MODE_I4x4) {\n            nnz |=  inter_predict_dc(td->block_dc,\n                                     s->inter_dc_pred[mb->ref_frame - 1]);\n        }\n\n        if (nnz) {\n            nnz_total += nnz;\n            block_dc   = 1;\n            if (nnz == 1)\n                s->vp8dsp.vp8_luma_dc_wht_dc(td->block, td->block_dc);\n            else\n                s->vp8dsp.vp8_luma_dc_wht(td->block, td->block_dc);\n        }\n        luma_start = 1;\n        luma_ctx   = 0;\n    }\n\n    // luma blocks\n    for (y = 0; y < 4; y++)\n        for (x = 0; x < 4; x++) {\n            nnz_pred = l_nnz[y] + t_nnz[x];\n            nnz = decode_block_coeffs(c, td->block[y][x],\n                                      s->prob->token[luma_ctx],\n                                      luma_start, nnz_pred,\n                                      s->qmat[segment].luma_qmul,\n                                      s->prob[0].scan, is_vp7);\n            /* nnz+block_dc may be one more than the actual last index,\n             * but we don't care */\n            td->non_zero_count_cache[y][x] = nnz + block_dc;\n            t_nnz[x] = l_nnz[y] = !!nnz;\n            nnz_total += nnz;\n        }\n\n    // chroma blocks\n    // TODO: what to do about dimensions? 2nd dim for luma is x,\n    // but for chroma it's (y<<1)|x\n    for (i = 4; i < 6; i++)\n        for (y = 0; y < 2; y++)\n            for (x = 0; x < 2; x++) {\n                nnz_pred = l_nnz[i + 2 * y] + t_nnz[i + 2 * x];\n                nnz = decode_block_coeffs(c, td->block[i][(y << 1) + x],\n                                          s->prob->token[2], 0, nnz_pred,\n                                          s->qmat[segment].chroma_qmul,\n                                          s->prob[0].scan, is_vp7);\n                td->non_zero_count_cache[i][(y << 1) + x] = nnz;\n                t_nnz[i + 2 * x] = l_nnz[i + 2 * y] = !!nnz;\n                nnz_total += nnz;\n            }\n\n    // if there were no coded coeffs despite the macroblock not being marked skip,\n    // we MUST not do the inner loop filter and should not do IDCT\n    // Since skip isn't used for bitstream prediction, just manually set it.\n    if (!nnz_total)\n        mb->skip = 1;\n}\n\nstatic av_always_inline\nvoid backup_mb_border(uint8_t *top_border, uint8_t *src_y,\n                      uint8_t *src_cb, uint8_t *src_cr,\n                      ptrdiff_t linesize, ptrdiff_t uvlinesize, int simple)\n{\n    AV_COPY128(top_border, src_y + 15 * linesize);\n    if (!simple) {\n        AV_COPY64(top_border + 16, src_cb + 7 * uvlinesize);\n        AV_COPY64(top_border + 24, src_cr + 7 * uvlinesize);\n    }\n}\n\nstatic av_always_inline\nvoid xchg_mb_border(uint8_t *top_border, uint8_t *src_y, uint8_t *src_cb,\n                    uint8_t *src_cr, ptrdiff_t linesize, ptrdiff_t uvlinesize, int mb_x,\n                    int mb_y, int mb_width, int simple, int xchg)\n{\n    uint8_t *top_border_m1 = top_border - 32;     // for TL prediction\n    src_y  -= linesize;\n    src_cb -= uvlinesize;\n    src_cr -= uvlinesize;\n\n#define XCHG(a, b, xchg)                                                      \\\n    do {                                                                      \\\n        if (xchg)                                                             \\\n            AV_SWAP64(b, a);                                                  \\\n        else                                                                  \\\n            AV_COPY64(b, a);                                                  \\\n    } while (0)\n\n    XCHG(top_border_m1 + 8, src_y - 8, xchg);\n    XCHG(top_border, src_y, xchg);\n    XCHG(top_border + 8, src_y + 8, 1);\n    if (mb_x < mb_width - 1)\n        XCHG(top_border + 32, src_y + 16, 1);\n\n    // only copy chroma for normal loop filter\n    // or to initialize the top row to 127\n    if (!simple || !mb_y) {\n        XCHG(top_border_m1 + 16, src_cb - 8, xchg);\n        XCHG(top_border_m1 + 24, src_cr - 8, xchg);\n        XCHG(top_border + 16, src_cb, 1);\n        XCHG(top_border + 24, src_cr, 1);\n    }\n}\n\nstatic av_always_inline\nint check_dc_pred8x8_mode(int mode, int mb_x, int mb_y)\n{\n    if (!mb_x)\n        return mb_y ? TOP_DC_PRED8x8 : DC_128_PRED8x8;\n    else\n        return mb_y ? mode : LEFT_DC_PRED8x8;\n}\n\nstatic av_always_inline\nint check_tm_pred8x8_mode(int mode, int mb_x, int mb_y, int vp7)\n{\n    if (!mb_x)\n        return mb_y ? VERT_PRED8x8 : (vp7 ? DC_128_PRED8x8 : DC_129_PRED8x8);\n    else\n        return mb_y ? mode : HOR_PRED8x8;\n}\n\nstatic av_always_inline\nint check_intra_pred8x8_mode_emuedge(int mode, int mb_x, int mb_y, int vp7)\n{\n    switch (mode) {\n    case DC_PRED8x8:\n        return check_dc_pred8x8_mode(mode, mb_x, mb_y);\n    case VERT_PRED8x8:\n        return !mb_y ? (vp7 ? DC_128_PRED8x8 : DC_127_PRED8x8) : mode;\n    case HOR_PRED8x8:\n        return !mb_x ? (vp7 ? DC_128_PRED8x8 : DC_129_PRED8x8) : mode;\n    case PLANE_PRED8x8: /* TM */\n        return check_tm_pred8x8_mode(mode, mb_x, mb_y, vp7);\n    }\n    return mode;\n}\n\nstatic av_always_inline\nint check_tm_pred4x4_mode(int mode, int mb_x, int mb_y, int vp7)\n{\n    if (!mb_x) {\n        return mb_y ? VERT_VP8_PRED : (vp7 ? DC_128_PRED : DC_129_PRED);\n    } else {\n        return mb_y ? mode : HOR_VP8_PRED;\n    }\n}\n\nstatic av_always_inline\nint check_intra_pred4x4_mode_emuedge(int mode, int mb_x, int mb_y,\n                                     int *copy_buf, int vp7)\n{\n    switch (mode) {\n    case VERT_PRED:\n        if (!mb_x && mb_y) {\n            *copy_buf = 1;\n            return mode;\n        }\n        /* fall-through */\n    case DIAG_DOWN_LEFT_PRED:\n    case VERT_LEFT_PRED:\n        return !mb_y ? (vp7 ? DC_128_PRED : DC_127_PRED) : mode;\n    case HOR_PRED:\n        if (!mb_y) {\n            *copy_buf = 1;\n            return mode;\n        }\n        /* fall-through */\n    case HOR_UP_PRED:\n        return !mb_x ? (vp7 ? DC_128_PRED : DC_129_PRED) : mode;\n    case TM_VP8_PRED:\n        return check_tm_pred4x4_mode(mode, mb_x, mb_y, vp7);\n    case DC_PRED: /* 4x4 DC doesn't use the same \"H.264-style\" exceptions\n                   * as 16x16/8x8 DC */\n    case DIAG_DOWN_RIGHT_PRED:\n    case VERT_RIGHT_PRED:\n    case HOR_DOWN_PRED:\n        if (!mb_y || !mb_x)\n            *copy_buf = 1;\n        return mode;\n    }\n    return mode;\n}\n\nstatic av_always_inline\nvoid intra_predict(VP8Context *s, VP8ThreadData *td, uint8_t *dst[3],\n                   VP8Macroblock *mb, int mb_x, int mb_y, int is_vp7)\n{\n    int x, y, mode, nnz;\n    uint32_t tr;\n\n    /* for the first row, we need to run xchg_mb_border to init the top edge\n     * to 127 otherwise, skip it if we aren't going to deblock */\n    if (mb_y && (s->deblock_filter || !mb_y) && td->thread_nr == 0)\n        xchg_mb_border(s->top_border[mb_x + 1], dst[0], dst[1], dst[2],\n                       s->linesize, s->uvlinesize, mb_x, mb_y, s->mb_width,\n                       s->filter.simple, 1);\n\n    if (mb->mode < MODE_I4x4) {\n        mode = check_intra_pred8x8_mode_emuedge(mb->mode, mb_x, mb_y, is_vp7);\n        s->hpc.pred16x16[mode](dst[0], s->linesize);\n    } else {\n        uint8_t *ptr = dst[0];\n        uint8_t *intra4x4 = mb->intra4x4_pred_mode_mb;\n        const uint8_t lo = is_vp7 ? 128 : 127;\n        const uint8_t hi = is_vp7 ? 128 : 129;\n        uint8_t tr_top[4] = { lo, lo, lo, lo };\n\n        // all blocks on the right edge of the macroblock use bottom edge\n        // the top macroblock for their topright edge\n        uint8_t *tr_right = ptr - s->linesize + 16;\n\n        // if we're on the right edge of the frame, said edge is extended\n        // from the top macroblock\n        if (mb_y && mb_x == s->mb_width - 1) {\n            tr       = tr_right[-1] * 0x01010101u;\n            tr_right = (uint8_t *) &tr;\n        }\n\n        if (mb->skip)\n            AV_ZERO128(td->non_zero_count_cache);\n\n        for (y = 0; y < 4; y++) {\n            uint8_t *topright = ptr + 4 - s->linesize;\n            for (x = 0; x < 4; x++) {\n                int copy = 0;\n                ptrdiff_t linesize = s->linesize;\n                uint8_t *dst = ptr + 4 * x;\n                LOCAL_ALIGNED(4, uint8_t, copy_dst, [5 * 8]);\n\n                if ((y == 0 || x == 3) && mb_y == 0) {\n                    topright = tr_top;\n                } else if (x == 3)\n                    topright = tr_right;\n\n                mode = check_intra_pred4x4_mode_emuedge(intra4x4[x], mb_x + x,\n                                                        mb_y + y, &copy, is_vp7);\n                if (copy) {\n                    dst      = copy_dst + 12;\n                    linesize = 8;\n                    if (!(mb_y + y)) {\n                        copy_dst[3] = lo;\n                        AV_WN32A(copy_dst + 4, lo * 0x01010101U);\n                    } else {\n                        AV_COPY32(copy_dst + 4, ptr + 4 * x - s->linesize);\n                        if (!(mb_x + x)) {\n                            copy_dst[3] = hi;\n                        } else {\n                            copy_dst[3] = ptr[4 * x - s->linesize - 1];\n                        }\n                    }\n                    if (!(mb_x + x)) {\n                        copy_dst[11] =\n                        copy_dst[19] =\n                        copy_dst[27] =\n                        copy_dst[35] = hi;\n                    } else {\n                        copy_dst[11] = ptr[4 * x                   - 1];\n                        copy_dst[19] = ptr[4 * x + s->linesize     - 1];\n                        copy_dst[27] = ptr[4 * x + s->linesize * 2 - 1];\n                        copy_dst[35] = ptr[4 * x + s->linesize * 3 - 1];\n                    }\n                }\n                s->hpc.pred4x4[mode](dst, topright, linesize);\n                if (copy) {\n                    AV_COPY32(ptr + 4 * x,                   copy_dst + 12);\n                    AV_COPY32(ptr + 4 * x + s->linesize,     copy_dst + 20);\n                    AV_COPY32(ptr + 4 * x + s->linesize * 2, copy_dst + 28);\n                    AV_COPY32(ptr + 4 * x + s->linesize * 3, copy_dst + 36);\n                }\n\n                nnz = td->non_zero_count_cache[y][x];\n                if (nnz) {\n                    if (nnz == 1)\n                        s->vp8dsp.vp8_idct_dc_add(ptr + 4 * x,\n                                                  td->block[y][x], s->linesize);\n                    else\n                        s->vp8dsp.vp8_idct_add(ptr + 4 * x,\n                                               td->block[y][x], s->linesize);\n                }\n                topright += 4;\n            }\n\n            ptr      += 4 * s->linesize;\n            intra4x4 += 4;\n        }\n    }\n\n    mode = check_intra_pred8x8_mode_emuedge(mb->chroma_pred_mode,\n                                            mb_x, mb_y, is_vp7);\n    s->hpc.pred8x8[mode](dst[1], s->uvlinesize);\n    s->hpc.pred8x8[mode](dst[2], s->uvlinesize);\n\n    if (mb_y && (s->deblock_filter || !mb_y) && td->thread_nr == 0)\n        xchg_mb_border(s->top_border[mb_x + 1], dst[0], dst[1], dst[2],\n                       s->linesize, s->uvlinesize, mb_x, mb_y, s->mb_width,\n                       s->filter.simple, 0);\n}\n\nstatic const uint8_t subpel_idx[3][8] = {\n    { 0, 1, 2, 1, 2, 1, 2, 1 }, // nr. of left extra pixels,\n                                // also function pointer index\n    { 0, 3, 5, 3, 5, 3, 5, 3 }, // nr. of extra pixels required\n    { 0, 2, 3, 2, 3, 2, 3, 2 }, // nr. of right extra pixels\n};\n\n/**\n * luma MC function\n *\n * @param s        VP8 decoding context\n * @param dst      target buffer for block data at block position\n * @param ref      reference picture buffer at origin (0, 0)\n * @param mv       motion vector (relative to block position) to get pixel data from\n * @param x_off    horizontal position of block from origin (0, 0)\n * @param y_off    vertical position of block from origin (0, 0)\n * @param block_w  width of block (16, 8 or 4)\n * @param block_h  height of block (always same as block_w)\n * @param width    width of src/dst plane data\n * @param height   height of src/dst plane data\n * @param linesize size of a single line of plane data, including padding\n * @param mc_func  motion compensation function pointers (bilinear or sixtap MC)\n */\nstatic av_always_inline\nvoid vp8_mc_luma(VP8Context *s, VP8ThreadData *td, uint8_t *dst,\n                 ThreadFrame *ref, const VP56mv *mv,\n                 int x_off, int y_off, int block_w, int block_h,\n                 int width, int height, ptrdiff_t linesize,\n                 vp8_mc_func mc_func[3][3])\n{\n    uint8_t *src = ref->f->data[0];\n\n    if (AV_RN32A(mv)) {\n        ptrdiff_t src_linesize = linesize;\n\n        int mx = (mv->x * 2) & 7, mx_idx = subpel_idx[0][mx];\n        int my = (mv->y * 2) & 7, my_idx = subpel_idx[0][my];\n\n        x_off += mv->x >> 2;\n        y_off += mv->y >> 2;\n\n        // edge emulation\n        ff_thread_await_progress(ref, (3 + y_off + block_h + subpel_idx[2][my]) >> 4, 0);\n        src += y_off * linesize + x_off;\n        if (x_off < mx_idx || x_off >= width  - block_w - subpel_idx[2][mx] ||\n            y_off < my_idx || y_off >= height - block_h - subpel_idx[2][my]) {\n            s->vdsp.emulated_edge_mc(td->edge_emu_buffer,\n                                     src - my_idx * linesize - mx_idx,\n                                     EDGE_EMU_LINESIZE, linesize,\n                                     block_w + subpel_idx[1][mx],\n                                     block_h + subpel_idx[1][my],\n                                     x_off - mx_idx, y_off - my_idx,\n                                     width, height);\n            src = td->edge_emu_buffer + mx_idx + EDGE_EMU_LINESIZE * my_idx;\n            src_linesize = EDGE_EMU_LINESIZE;\n        }\n        mc_func[my_idx][mx_idx](dst, linesize, src, src_linesize, block_h, mx, my);\n    } else {\n        ff_thread_await_progress(ref, (3 + y_off + block_h) >> 4, 0);\n        mc_func[0][0](dst, linesize, src + y_off * linesize + x_off,\n                      linesize, block_h, 0, 0);\n    }\n}\n\n/**\n * chroma MC function\n *\n * @param s        VP8 decoding context\n * @param dst1     target buffer for block data at block position (U plane)\n * @param dst2     target buffer for block data at block position (V plane)\n * @param ref      reference picture buffer at origin (0, 0)\n * @param mv       motion vector (relative to block position) to get pixel data from\n * @param x_off    horizontal position of block from origin (0, 0)\n * @param y_off    vertical position of block from origin (0, 0)\n * @param block_w  width of block (16, 8 or 4)\n * @param block_h  height of block (always same as block_w)\n * @param width    width of src/dst plane data\n * @param height   height of src/dst plane data\n * @param linesize size of a single line of plane data, including padding\n * @param mc_func  motion compensation function pointers (bilinear or sixtap MC)\n */\nstatic av_always_inline\nvoid vp8_mc_chroma(VP8Context *s, VP8ThreadData *td, uint8_t *dst1,\n                   uint8_t *dst2, ThreadFrame *ref, const VP56mv *mv,\n                   int x_off, int y_off, int block_w, int block_h,\n                   int width, int height, ptrdiff_t linesize,\n                   vp8_mc_func mc_func[3][3])\n{\n    uint8_t *src1 = ref->f->data[1], *src2 = ref->f->data[2];\n\n    if (AV_RN32A(mv)) {\n        int mx = mv->x & 7, mx_idx = subpel_idx[0][mx];\n        int my = mv->y & 7, my_idx = subpel_idx[0][my];\n\n        x_off += mv->x >> 3;\n        y_off += mv->y >> 3;\n\n        // edge emulation\n        src1 += y_off * linesize + x_off;\n        src2 += y_off * linesize + x_off;\n        ff_thread_await_progress(ref, (3 + y_off + block_h + subpel_idx[2][my]) >> 3, 0);\n        if (x_off < mx_idx || x_off >= width  - block_w - subpel_idx[2][mx] ||\n            y_off < my_idx || y_off >= height - block_h - subpel_idx[2][my]) {\n            s->vdsp.emulated_edge_mc(td->edge_emu_buffer,\n                                     src1 - my_idx * linesize - mx_idx,\n                                     EDGE_EMU_LINESIZE, linesize,\n                                     block_w + subpel_idx[1][mx],\n                                     block_h + subpel_idx[1][my],\n                                     x_off - mx_idx, y_off - my_idx, width, height);\n            src1 = td->edge_emu_buffer + mx_idx + EDGE_EMU_LINESIZE * my_idx;\n            mc_func[my_idx][mx_idx](dst1, linesize, src1, EDGE_EMU_LINESIZE, block_h, mx, my);\n\n            s->vdsp.emulated_edge_mc(td->edge_emu_buffer,\n                                     src2 - my_idx * linesize - mx_idx,\n                                     EDGE_EMU_LINESIZE, linesize,\n                                     block_w + subpel_idx[1][mx],\n                                     block_h + subpel_idx[1][my],\n                                     x_off - mx_idx, y_off - my_idx, width, height);\n            src2 = td->edge_emu_buffer + mx_idx + EDGE_EMU_LINESIZE * my_idx;\n            mc_func[my_idx][mx_idx](dst2, linesize, src2, EDGE_EMU_LINESIZE, block_h, mx, my);\n        } else {\n            mc_func[my_idx][mx_idx](dst1, linesize, src1, linesize, block_h, mx, my);\n            mc_func[my_idx][mx_idx](dst2, linesize, src2, linesize, block_h, mx, my);\n        }\n    } else {\n        ff_thread_await_progress(ref, (3 + y_off + block_h) >> 3, 0);\n        mc_func[0][0](dst1, linesize, src1 + y_off * linesize + x_off, linesize, block_h, 0, 0);\n        mc_func[0][0](dst2, linesize, src2 + y_off * linesize + x_off, linesize, block_h, 0, 0);\n    }\n}\n\nstatic av_always_inline\nvoid vp8_mc_part(VP8Context *s, VP8ThreadData *td, uint8_t *dst[3],\n                 ThreadFrame *ref_frame, int x_off, int y_off,\n                 int bx_off, int by_off, int block_w, int block_h,\n                 int width, int height, VP56mv *mv)\n{\n    VP56mv uvmv = *mv;\n\n    /* Y */\n    vp8_mc_luma(s, td, dst[0] + by_off * s->linesize + bx_off,\n                ref_frame, mv, x_off + bx_off, y_off + by_off,\n                block_w, block_h, width, height, s->linesize,\n                s->put_pixels_tab[block_w == 8]);\n\n    /* U/V */\n    if (s->profile == 3) {\n        /* this block only applies VP8; it is safe to check\n         * only the profile, as VP7 profile <= 1 */\n        uvmv.x &= ~7;\n        uvmv.y &= ~7;\n    }\n    x_off   >>= 1;\n    y_off   >>= 1;\n    bx_off  >>= 1;\n    by_off  >>= 1;\n    width   >>= 1;\n    height  >>= 1;\n    block_w >>= 1;\n    block_h >>= 1;\n    vp8_mc_chroma(s, td, dst[1] + by_off * s->uvlinesize + bx_off,\n                  dst[2] + by_off * s->uvlinesize + bx_off, ref_frame,\n                  &uvmv, x_off + bx_off, y_off + by_off,\n                  block_w, block_h, width, height, s->uvlinesize,\n                  s->put_pixels_tab[1 + (block_w == 4)]);\n}\n\n/* Fetch pixels for estimated mv 4 macroblocks ahead.\n * Optimized for 64-byte cache lines. Inspired by ffh264 prefetch_motion. */\nstatic av_always_inline\nvoid prefetch_motion(VP8Context *s, VP8Macroblock *mb, int mb_x, int mb_y,\n                     int mb_xy, int ref)\n{\n    /* Don't prefetch refs that haven't been used very often this frame. */\n    if (s->ref_count[ref - 1] > (mb_xy >> 5)) {\n        int x_off = mb_x << 4, y_off = mb_y << 4;\n        int mx = (mb->mv.x >> 2) + x_off + 8;\n        int my = (mb->mv.y >> 2) + y_off;\n        uint8_t **src = s->framep[ref]->tf.f->data;\n        int off = mx + (my + (mb_x & 3) * 4) * s->linesize + 64;\n        /* For threading, a ff_thread_await_progress here might be useful, but\n         * it actually slows down the decoder. Since a bad prefetch doesn't\n         * generate bad decoder output, we don't run it here. */\n        s->vdsp.prefetch(src[0] + off, s->linesize, 4);\n        off = (mx >> 1) + ((my >> 1) + (mb_x & 7)) * s->uvlinesize + 64;\n        s->vdsp.prefetch(src[1] + off, src[2] - src[1], 2);\n    }\n}\n\n/**\n * Apply motion vectors to prediction buffer, chapter 18.\n */\nstatic av_always_inline\nvoid inter_predict(VP8Context *s, VP8ThreadData *td, uint8_t *dst[3],\n                   VP8Macroblock *mb, int mb_x, int mb_y)\n{\n    int x_off = mb_x << 4, y_off = mb_y << 4;\n    int width = 16 * s->mb_width, height = 16 * s->mb_height;\n    ThreadFrame *ref = &s->framep[mb->ref_frame]->tf;\n    VP56mv *bmv = mb->bmv;\n\n    switch (mb->partitioning) {\n    case VP8_SPLITMVMODE_NONE:\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 0, 16, 16, width, height, &mb->mv);\n        break;\n    case VP8_SPLITMVMODE_4x4: {\n        int x, y;\n        VP56mv uvmv;\n\n        /* Y */\n        for (y = 0; y < 4; y++) {\n            for (x = 0; x < 4; x++) {\n                vp8_mc_luma(s, td, dst[0] + 4 * y * s->linesize + x * 4,\n                            ref, &bmv[4 * y + x],\n                            4 * x + x_off, 4 * y + y_off, 4, 4,\n                            width, height, s->linesize,\n                            s->put_pixels_tab[2]);\n            }\n        }\n\n        /* U/V */\n        x_off  >>= 1;\n        y_off  >>= 1;\n        width  >>= 1;\n        height >>= 1;\n        for (y = 0; y < 2; y++) {\n            for (x = 0; x < 2; x++) {\n                uvmv.x = mb->bmv[2 * y       * 4 + 2 * x    ].x +\n                         mb->bmv[2 * y       * 4 + 2 * x + 1].x +\n                         mb->bmv[(2 * y + 1) * 4 + 2 * x    ].x +\n                         mb->bmv[(2 * y + 1) * 4 + 2 * x + 1].x;\n                uvmv.y = mb->bmv[2 * y       * 4 + 2 * x    ].y +\n                         mb->bmv[2 * y       * 4 + 2 * x + 1].y +\n                         mb->bmv[(2 * y + 1) * 4 + 2 * x    ].y +\n                         mb->bmv[(2 * y + 1) * 4 + 2 * x + 1].y;\n                uvmv.x = (uvmv.x + 2 + FF_SIGNBIT(uvmv.x)) >> 2;\n                uvmv.y = (uvmv.y + 2 + FF_SIGNBIT(uvmv.y)) >> 2;\n                if (s->profile == 3) {\n                    uvmv.x &= ~7;\n                    uvmv.y &= ~7;\n                }\n                vp8_mc_chroma(s, td, dst[1] + 4 * y * s->uvlinesize + x * 4,\n                              dst[2] + 4 * y * s->uvlinesize + x * 4, ref,\n                              &uvmv, 4 * x + x_off, 4 * y + y_off, 4, 4,\n                              width, height, s->uvlinesize,\n                              s->put_pixels_tab[2]);\n            }\n        }\n        break;\n    }\n    case VP8_SPLITMVMODE_16x8:\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 0, 16, 8, width, height, &bmv[0]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 8, 16, 8, width, height, &bmv[1]);\n        break;\n    case VP8_SPLITMVMODE_8x16:\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 0, 8, 16, width, height, &bmv[0]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    8, 0, 8, 16, width, height, &bmv[1]);\n        break;\n    case VP8_SPLITMVMODE_8x8:\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 0, 8, 8, width, height, &bmv[0]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    8, 0, 8, 8, width, height, &bmv[1]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    0, 8, 8, 8, width, height, &bmv[2]);\n        vp8_mc_part(s, td, dst, ref, x_off, y_off,\n                    8, 8, 8, 8, width, height, &bmv[3]);\n        break;\n    }\n}\n\nstatic av_always_inline\nvoid idct_mb(VP8Context *s, VP8ThreadData *td, uint8_t *dst[3], VP8Macroblock *mb)\n{\n    int x, y, ch;\n\n    if (mb->mode != MODE_I4x4) {\n        uint8_t *y_dst = dst[0];\n        for (y = 0; y < 4; y++) {\n            uint32_t nnz4 = AV_RL32(td->non_zero_count_cache[y]);\n            if (nnz4) {\n                if (nnz4 & ~0x01010101) {\n                    for (x = 0; x < 4; x++) {\n                        if ((uint8_t) nnz4 == 1)\n                            s->vp8dsp.vp8_idct_dc_add(y_dst + 4 * x,\n                                                      td->block[y][x],\n                                                      s->linesize);\n                        else if ((uint8_t) nnz4 > 1)\n                            s->vp8dsp.vp8_idct_add(y_dst + 4 * x,\n                                                   td->block[y][x],\n                                                   s->linesize);\n                        nnz4 >>= 8;\n                        if (!nnz4)\n                            break;\n                    }\n                } else {\n                    s->vp8dsp.vp8_idct_dc_add4y(y_dst, td->block[y], s->linesize);\n                }\n            }\n            y_dst += 4 * s->linesize;\n        }\n    }\n\n    for (ch = 0; ch < 2; ch++) {\n        uint32_t nnz4 = AV_RL32(td->non_zero_count_cache[4 + ch]);\n        if (nnz4) {\n            uint8_t *ch_dst = dst[1 + ch];\n            if (nnz4 & ~0x01010101) {\n                for (y = 0; y < 2; y++) {\n                    for (x = 0; x < 2; x++) {\n                        if ((uint8_t) nnz4 == 1)\n                            s->vp8dsp.vp8_idct_dc_add(ch_dst + 4 * x,\n                                                      td->block[4 + ch][(y << 1) + x],\n                                                      s->uvlinesize);\n                        else if ((uint8_t) nnz4 > 1)\n                            s->vp8dsp.vp8_idct_add(ch_dst + 4 * x,\n                                                   td->block[4 + ch][(y << 1) + x],\n                                                   s->uvlinesize);\n                        nnz4 >>= 8;\n                        if (!nnz4)\n                            goto chroma_idct_end;\n                    }\n                    ch_dst += 4 * s->uvlinesize;\n                }\n            } else {\n                s->vp8dsp.vp8_idct_dc_add4uv(ch_dst, td->block[4 + ch], s->uvlinesize);\n            }\n        }\nchroma_idct_end:\n        ;\n    }\n}\n\nstatic av_always_inline\nvoid filter_level_for_mb(VP8Context *s, VP8Macroblock *mb,\n                         VP8FilterStrength *f, int is_vp7)\n{\n    int interior_limit, filter_level;\n\n    if (s->segmentation.enabled) {\n        filter_level = s->segmentation.filter_level[mb->segment];\n        if (!s->segmentation.absolute_vals)\n            filter_level += s->filter.level;\n    } else\n        filter_level = s->filter.level;\n\n    if (s->lf_delta.enabled) {\n        filter_level += s->lf_delta.ref[mb->ref_frame];\n        filter_level += s->lf_delta.mode[mb->mode];\n    }\n\n    filter_level = av_clip_uintp2(filter_level, 6);\n\n    interior_limit = filter_level;\n    if (s->filter.sharpness) {\n        interior_limit >>= (s->filter.sharpness + 3) >> 2;\n        interior_limit = FFMIN(interior_limit, 9 - s->filter.sharpness);\n    }\n    interior_limit = FFMAX(interior_limit, 1);\n\n    f->filter_level = filter_level;\n    f->inner_limit = interior_limit;\n    f->inner_filter = is_vp7 || !mb->skip || mb->mode == MODE_I4x4 ||\n                      mb->mode == VP8_MVMODE_SPLIT;\n}\n\nstatic av_always_inline\nvoid filter_mb(VP8Context *s, uint8_t *dst[3], VP8FilterStrength *f,\n               int mb_x, int mb_y, int is_vp7)\n{\n    int mbedge_lim, bedge_lim_y, bedge_lim_uv, hev_thresh;\n    int filter_level = f->filter_level;\n    int inner_limit = f->inner_limit;\n    int inner_filter = f->inner_filter;\n    ptrdiff_t linesize   = s->linesize;\n    ptrdiff_t uvlinesize = s->uvlinesize;\n    static const uint8_t hev_thresh_lut[2][64] = {\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n          3, 3, 3, 3 },\n        { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n          2, 2, 2, 2 }\n    };\n\n    if (!filter_level)\n        return;\n\n    if (is_vp7) {\n        bedge_lim_y  = filter_level;\n        bedge_lim_uv = filter_level * 2;\n        mbedge_lim   = filter_level + 2;\n    } else {\n        bedge_lim_y  =\n        bedge_lim_uv = filter_level * 2 + inner_limit;\n        mbedge_lim   = bedge_lim_y + 4;\n    }\n\n    hev_thresh = hev_thresh_lut[s->keyframe][filter_level];\n\n    if (mb_x) {\n        s->vp8dsp.vp8_h_loop_filter16y(dst[0], linesize,\n                                       mbedge_lim, inner_limit, hev_thresh);\n        s->vp8dsp.vp8_h_loop_filter8uv(dst[1], dst[2], uvlinesize,\n                                       mbedge_lim, inner_limit, hev_thresh);\n    }\n\n#define H_LOOP_FILTER_16Y_INNER(cond)                                         \\\n    if (cond && inner_filter) {                                               \\\n        s->vp8dsp.vp8_h_loop_filter16y_inner(dst[0] +  4, linesize,           \\\n                                             bedge_lim_y, inner_limit,        \\\n                                             hev_thresh);                     \\\n        s->vp8dsp.vp8_h_loop_filter16y_inner(dst[0] +  8, linesize,           \\\n                                             bedge_lim_y, inner_limit,        \\\n                                             hev_thresh);                     \\\n        s->vp8dsp.vp8_h_loop_filter16y_inner(dst[0] + 12, linesize,           \\\n                                             bedge_lim_y, inner_limit,        \\\n                                             hev_thresh);                     \\\n        s->vp8dsp.vp8_h_loop_filter8uv_inner(dst[1] +  4, dst[2] + 4,         \\\n                                             uvlinesize,  bedge_lim_uv,       \\\n                                             inner_limit, hev_thresh);        \\\n    }\n\n    H_LOOP_FILTER_16Y_INNER(!is_vp7)\n\n    if (mb_y) {\n        s->vp8dsp.vp8_v_loop_filter16y(dst[0], linesize,\n                                       mbedge_lim, inner_limit, hev_thresh);\n        s->vp8dsp.vp8_v_loop_filter8uv(dst[1], dst[2], uvlinesize,\n                                       mbedge_lim, inner_limit, hev_thresh);\n    }\n\n    if (inner_filter) {\n        s->vp8dsp.vp8_v_loop_filter16y_inner(dst[0] +  4 * linesize,\n                                             linesize, bedge_lim_y,\n                                             inner_limit, hev_thresh);\n        s->vp8dsp.vp8_v_loop_filter16y_inner(dst[0] +  8 * linesize,\n                                             linesize, bedge_lim_y,\n                                             inner_limit, hev_thresh);\n        s->vp8dsp.vp8_v_loop_filter16y_inner(dst[0] + 12 * linesize,\n                                             linesize, bedge_lim_y,\n                                             inner_limit, hev_thresh);\n        s->vp8dsp.vp8_v_loop_filter8uv_inner(dst[1] +  4 * uvlinesize,\n                                             dst[2] +  4 * uvlinesize,\n                                             uvlinesize, bedge_lim_uv,\n                                             inner_limit, hev_thresh);\n    }\n\n    H_LOOP_FILTER_16Y_INNER(is_vp7)\n}\n\nstatic av_always_inline\nvoid filter_mb_simple(VP8Context *s, uint8_t *dst, VP8FilterStrength *f,\n                      int mb_x, int mb_y)\n{\n    int mbedge_lim, bedge_lim;\n    int filter_level = f->filter_level;\n    int inner_limit  = f->inner_limit;\n    int inner_filter = f->inner_filter;\n    ptrdiff_t linesize = s->linesize;\n\n    if (!filter_level)\n        return;\n\n    bedge_lim  = 2 * filter_level + inner_limit;\n    mbedge_lim = bedge_lim + 4;\n\n    if (mb_x)\n        s->vp8dsp.vp8_h_loop_filter_simple(dst, linesize, mbedge_lim);\n    if (inner_filter) {\n        s->vp8dsp.vp8_h_loop_filter_simple(dst +  4, linesize, bedge_lim);\n        s->vp8dsp.vp8_h_loop_filter_simple(dst +  8, linesize, bedge_lim);\n        s->vp8dsp.vp8_h_loop_filter_simple(dst + 12, linesize, bedge_lim);\n    }\n\n    if (mb_y)\n        s->vp8dsp.vp8_v_loop_filter_simple(dst, linesize, mbedge_lim);\n    if (inner_filter) {\n        s->vp8dsp.vp8_v_loop_filter_simple(dst +  4 * linesize, linesize, bedge_lim);\n        s->vp8dsp.vp8_v_loop_filter_simple(dst +  8 * linesize, linesize, bedge_lim);\n        s->vp8dsp.vp8_v_loop_filter_simple(dst + 12 * linesize, linesize, bedge_lim);\n    }\n}\n\n#define MARGIN (16 << 2)\nstatic av_always_inline\nvoid vp78_decode_mv_mb_modes(AVCodecContext *avctx, VP8Frame *curframe,\n                                    VP8Frame *prev_frame, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    int mb_x, mb_y;\n\n    s->mv_bounds.mv_min.y = -MARGIN;\n    s->mv_bounds.mv_max.y = ((s->mb_height - 1) << 6) + MARGIN;\n    for (mb_y = 0; mb_y < s->mb_height; mb_y++) {\n        VP8Macroblock *mb = s->macroblocks_base +\n                            ((s->mb_width + 1) * (mb_y + 1) + 1);\n        int mb_xy = mb_y * s->mb_width;\n\n        AV_WN32A(s->intra4x4_pred_mode_left, DC_PRED * 0x01010101);\n\n        s->mv_bounds.mv_min.x = -MARGIN;\n        s->mv_bounds.mv_max.x = ((s->mb_width - 1) << 6) + MARGIN;\n        for (mb_x = 0; mb_x < s->mb_width; mb_x++, mb_xy++, mb++) {\n            if (mb_y == 0)\n                AV_WN32A((mb - s->mb_width - 1)->intra4x4_pred_mode_top,\n                         DC_PRED * 0x01010101);\n            decode_mb_mode(s, &s->mv_bounds, mb, mb_x, mb_y, curframe->seg_map->data + mb_xy,\n                           prev_frame && prev_frame->seg_map ?\n                           prev_frame->seg_map->data + mb_xy : NULL, 1, is_vp7);\n            s->mv_bounds.mv_min.x -= 64;\n            s->mv_bounds.mv_max.x -= 64;\n        }\n        s->mv_bounds.mv_min.y -= 64;\n        s->mv_bounds.mv_max.y -= 64;\n    }\n}\n\nstatic void vp7_decode_mv_mb_modes(AVCodecContext *avctx, VP8Frame *cur_frame,\n                                   VP8Frame *prev_frame)\n{\n    vp78_decode_mv_mb_modes(avctx, cur_frame, prev_frame, IS_VP7);\n}\n\nstatic void vp8_decode_mv_mb_modes(AVCodecContext *avctx, VP8Frame *cur_frame,\n                                   VP8Frame *prev_frame)\n{\n    vp78_decode_mv_mb_modes(avctx, cur_frame, prev_frame, IS_VP8);\n}\n\n#if HAVE_THREADS\n#define check_thread_pos(td, otd, mb_x_check, mb_y_check)                     \\\n    do {                                                                      \\\n        int tmp = (mb_y_check << 16) | (mb_x_check & 0xFFFF);                 \\\n        if (atomic_load(&otd->thread_mb_pos) < tmp) {                         \\\n            pthread_mutex_lock(&otd->lock);                                   \\\n            atomic_store(&td->wait_mb_pos, tmp);                              \\\n            do {                                                              \\\n                if (atomic_load(&otd->thread_mb_pos) >= tmp)                  \\\n                    break;                                                    \\\n                pthread_cond_wait(&otd->cond, &otd->lock);                    \\\n            } while (1);                                                      \\\n            atomic_store(&td->wait_mb_pos, INT_MAX);                          \\\n            pthread_mutex_unlock(&otd->lock);                                 \\\n        }                                                                     \\\n    } while (0)\n\n#define update_pos(td, mb_y, mb_x)                                            \\\n    do {                                                                      \\\n        int pos              = (mb_y << 16) | (mb_x & 0xFFFF);                \\\n        int sliced_threading = (avctx->active_thread_type == FF_THREAD_SLICE) && \\\n                               (num_jobs > 1);                                \\\n        int is_null          = !next_td || !prev_td;                          \\\n        int pos_check        = (is_null) ? 1 :                                \\\n            (next_td != td && pos >= atomic_load(&next_td->wait_mb_pos)) ||   \\\n            (prev_td != td && pos >= atomic_load(&prev_td->wait_mb_pos));     \\\n        atomic_store(&td->thread_mb_pos, pos);                                \\\n        if (sliced_threading && pos_check) {                                  \\\n            pthread_mutex_lock(&td->lock);                                    \\\n            pthread_cond_broadcast(&td->cond);                                \\\n            pthread_mutex_unlock(&td->lock);                                  \\\n        }                                                                     \\\n    } while (0)\n#else\n#define check_thread_pos(td, otd, mb_x_check, mb_y_check) while(0)\n#define update_pos(td, mb_y, mb_x) while(0)\n#endif\n\nstatic av_always_inline int decode_mb_row_no_filter(AVCodecContext *avctx, void *tdata,\n                                        int jobnr, int threadnr, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    VP8ThreadData *prev_td, *next_td, *td = &s->thread_data[threadnr];\n    int mb_y = atomic_load(&td->thread_mb_pos) >> 16;\n    int mb_x, mb_xy = mb_y * s->mb_width;\n    int num_jobs = s->num_jobs;\n    VP8Frame *curframe = s->curframe, *prev_frame = s->prev_frame;\n    VP56RangeCoder *c  = &s->coeff_partition[mb_y & (s->num_coeff_partitions - 1)];\n    VP8Macroblock *mb;\n    uint8_t *dst[3] = {\n        curframe->tf.f->data[0] + 16 * mb_y * s->linesize,\n        curframe->tf.f->data[1] +  8 * mb_y * s->uvlinesize,\n        curframe->tf.f->data[2] +  8 * mb_y * s->uvlinesize\n    };\n\n    if (c->end <= c->buffer && c->bits >= 0)\n         return AVERROR_INVALIDDATA;\n\n    if (mb_y == 0)\n        prev_td = td;\n    else\n        prev_td = &s->thread_data[(jobnr + num_jobs - 1) % num_jobs];\n    if (mb_y == s->mb_height - 1)\n        next_td = td;\n    else\n        next_td = &s->thread_data[(jobnr + 1) % num_jobs];\n    if (s->mb_layout == 1)\n        mb = s->macroblocks_base + ((s->mb_width + 1) * (mb_y + 1) + 1);\n    else {\n        // Make sure the previous frame has read its segmentation map,\n        // if we re-use the same map.\n        if (prev_frame && s->segmentation.enabled &&\n            !s->segmentation.update_map)\n            ff_thread_await_progress(&prev_frame->tf, mb_y, 0);\n        mb = s->macroblocks + (s->mb_height - mb_y - 1) * 2;\n        memset(mb - 1, 0, sizeof(*mb)); // zero left macroblock\n        AV_WN32A(s->intra4x4_pred_mode_left, DC_PRED * 0x01010101);\n    }\n\n    if (!is_vp7 || mb_y == 0)\n        memset(td->left_nnz, 0, sizeof(td->left_nnz));\n\n    td->mv_bounds.mv_min.x = -MARGIN;\n    td->mv_bounds.mv_max.x = ((s->mb_width - 1) << 6) + MARGIN;\n\n    for (mb_x = 0; mb_x < s->mb_width; mb_x++, mb_xy++, mb++) {\n        if (c->end <= c->buffer && c->bits >= 0)\n            return AVERROR_INVALIDDATA;\n        // Wait for previous thread to read mb_x+2, and reach mb_y-1.\n        if (prev_td != td) {\n            if (threadnr != 0) {\n                check_thread_pos(td, prev_td,\n                                 mb_x + (is_vp7 ? 2 : 1),\n                                 mb_y - (is_vp7 ? 2 : 1));\n            } else {\n                check_thread_pos(td, prev_td,\n                                 mb_x + (is_vp7 ? 2 : 1) + s->mb_width + 3,\n                                 mb_y - (is_vp7 ? 2 : 1));\n            }\n        }\n\n        s->vdsp.prefetch(dst[0] + (mb_x & 3) * 4 * s->linesize + 64,\n                         s->linesize, 4);\n        s->vdsp.prefetch(dst[1] + (mb_x & 7) * s->uvlinesize + 64,\n                         dst[2] - dst[1], 2);\n\n        if (!s->mb_layout)\n            decode_mb_mode(s, &td->mv_bounds, mb, mb_x, mb_y, curframe->seg_map->data + mb_xy,\n                           prev_frame && prev_frame->seg_map ?\n                           prev_frame->seg_map->data + mb_xy : NULL, 0, is_vp7);\n\n        prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_PREVIOUS);\n\n        if (!mb->skip)\n            decode_mb_coeffs(s, td, c, mb, s->top_nnz[mb_x], td->left_nnz, is_vp7);\n\n        if (mb->mode <= MODE_I4x4)\n            intra_predict(s, td, dst, mb, mb_x, mb_y, is_vp7);\n        else\n            inter_predict(s, td, dst, mb, mb_x, mb_y);\n\n        prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_GOLDEN);\n\n        if (!mb->skip) {\n            idct_mb(s, td, dst, mb);\n        } else {\n            AV_ZERO64(td->left_nnz);\n            AV_WN64(s->top_nnz[mb_x], 0);   // array of 9, so unaligned\n\n            /* Reset DC block predictors if they would exist\n             * if the mb had coefficients */\n            if (mb->mode != MODE_I4x4 && mb->mode != VP8_MVMODE_SPLIT) {\n                td->left_nnz[8]     = 0;\n                s->top_nnz[mb_x][8] = 0;\n            }\n        }\n\n        if (s->deblock_filter)\n            filter_level_for_mb(s, mb, &td->filter_strength[mb_x], is_vp7);\n\n        if (s->deblock_filter && num_jobs != 1 && threadnr == num_jobs - 1) {\n            if (s->filter.simple)\n                backup_mb_border(s->top_border[mb_x + 1], dst[0],\n                                 NULL, NULL, s->linesize, 0, 1);\n            else\n                backup_mb_border(s->top_border[mb_x + 1], dst[0],\n                                 dst[1], dst[2], s->linesize, s->uvlinesize, 0);\n        }\n\n        prefetch_motion(s, mb, mb_x, mb_y, mb_xy, VP56_FRAME_GOLDEN2);\n\n        dst[0]      += 16;\n        dst[1]      += 8;\n        dst[2]      += 8;\n        td->mv_bounds.mv_min.x -= 64;\n        td->mv_bounds.mv_max.x -= 64;\n\n        if (mb_x == s->mb_width + 1) {\n            update_pos(td, mb_y, s->mb_width + 3);\n        } else {\n            update_pos(td, mb_y, mb_x);\n        }\n    }\n    return 0;\n}\n\nstatic int vp7_decode_mb_row_no_filter(AVCodecContext *avctx, void *tdata,\n                                        int jobnr, int threadnr)\n{\n    return decode_mb_row_no_filter(avctx, tdata, jobnr, threadnr, 1);\n}\n\nstatic int vp8_decode_mb_row_no_filter(AVCodecContext *avctx, void *tdata,\n                                        int jobnr, int threadnr)\n{\n    return decode_mb_row_no_filter(avctx, tdata, jobnr, threadnr, 0);\n}\n\nstatic av_always_inline void filter_mb_row(AVCodecContext *avctx, void *tdata,\n                              int jobnr, int threadnr, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    VP8ThreadData *td = &s->thread_data[threadnr];\n    int mb_x, mb_y = atomic_load(&td->thread_mb_pos) >> 16, num_jobs = s->num_jobs;\n    AVFrame *curframe = s->curframe->tf.f;\n    VP8Macroblock *mb;\n    VP8ThreadData *prev_td, *next_td;\n    uint8_t *dst[3] = {\n        curframe->data[0] + 16 * mb_y * s->linesize,\n        curframe->data[1] +  8 * mb_y * s->uvlinesize,\n        curframe->data[2] +  8 * mb_y * s->uvlinesize\n    };\n\n    if (s->mb_layout == 1)\n        mb = s->macroblocks_base + ((s->mb_width + 1) * (mb_y + 1) + 1);\n    else\n        mb = s->macroblocks + (s->mb_height - mb_y - 1) * 2;\n\n    if (mb_y == 0)\n        prev_td = td;\n    else\n        prev_td = &s->thread_data[(jobnr + num_jobs - 1) % num_jobs];\n    if (mb_y == s->mb_height - 1)\n        next_td = td;\n    else\n        next_td = &s->thread_data[(jobnr + 1) % num_jobs];\n\n    for (mb_x = 0; mb_x < s->mb_width; mb_x++, mb++) {\n        VP8FilterStrength *f = &td->filter_strength[mb_x];\n        if (prev_td != td)\n            check_thread_pos(td, prev_td,\n                             (mb_x + 1) + (s->mb_width + 3), mb_y - 1);\n        if (next_td != td)\n            if (next_td != &s->thread_data[0])\n                check_thread_pos(td, next_td, mb_x + 1, mb_y + 1);\n\n        if (num_jobs == 1) {\n            if (s->filter.simple)\n                backup_mb_border(s->top_border[mb_x + 1], dst[0],\n                                 NULL, NULL, s->linesize, 0, 1);\n            else\n                backup_mb_border(s->top_border[mb_x + 1], dst[0],\n                                 dst[1], dst[2], s->linesize, s->uvlinesize, 0);\n        }\n\n        if (s->filter.simple)\n            filter_mb_simple(s, dst[0], f, mb_x, mb_y);\n        else\n            filter_mb(s, dst, f, mb_x, mb_y, is_vp7);\n        dst[0] += 16;\n        dst[1] += 8;\n        dst[2] += 8;\n\n        update_pos(td, mb_y, (s->mb_width + 3) + mb_x);\n    }\n}\n\nstatic void vp7_filter_mb_row(AVCodecContext *avctx, void *tdata,\n                              int jobnr, int threadnr)\n{\n    filter_mb_row(avctx, tdata, jobnr, threadnr, 1);\n}\n\nstatic void vp8_filter_mb_row(AVCodecContext *avctx, void *tdata,\n                              int jobnr, int threadnr)\n{\n    filter_mb_row(avctx, tdata, jobnr, threadnr, 0);\n}\n\nstatic av_always_inline\nint vp78_decode_mb_row_sliced(AVCodecContext *avctx, void *tdata, int jobnr,\n                              int threadnr, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    VP8ThreadData *td = &s->thread_data[jobnr];\n    VP8ThreadData *next_td = NULL, *prev_td = NULL;\n    VP8Frame *curframe = s->curframe;\n    int mb_y, num_jobs = s->num_jobs;\n    int ret;\n\n    td->thread_nr = threadnr;\n    td->mv_bounds.mv_min.y   = -MARGIN - 64 * threadnr;\n    td->mv_bounds.mv_max.y   = ((s->mb_height - 1) << 6) + MARGIN - 64 * threadnr;\n    for (mb_y = jobnr; mb_y < s->mb_height; mb_y += num_jobs) {\n        atomic_store(&td->thread_mb_pos, mb_y << 16);\n        ret = s->decode_mb_row_no_filter(avctx, tdata, jobnr, threadnr);\n        if (ret < 0) {\n            update_pos(td, s->mb_height, INT_MAX & 0xFFFF);\n            return ret;\n        }\n        if (s->deblock_filter)\n            s->filter_mb_row(avctx, tdata, jobnr, threadnr);\n        update_pos(td, mb_y, INT_MAX & 0xFFFF);\n\n        td->mv_bounds.mv_min.y -= 64 * num_jobs;\n        td->mv_bounds.mv_max.y -= 64 * num_jobs;\n\n        if (avctx->active_thread_type == FF_THREAD_FRAME)\n            ff_thread_report_progress(&curframe->tf, mb_y, 0);\n    }\n\n    return 0;\n}\n\nstatic int vp7_decode_mb_row_sliced(AVCodecContext *avctx, void *tdata,\n                                    int jobnr, int threadnr)\n{\n    return vp78_decode_mb_row_sliced(avctx, tdata, jobnr, threadnr, IS_VP7);\n}\n\nstatic int vp8_decode_mb_row_sliced(AVCodecContext *avctx, void *tdata,\n                                    int jobnr, int threadnr)\n{\n    return vp78_decode_mb_row_sliced(avctx, tdata, jobnr, threadnr, IS_VP8);\n}\n\n\nstatic av_always_inline\nint vp78_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                      AVPacket *avpkt, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    int ret, i, referenced, num_jobs;\n    enum AVDiscard skip_thresh;\n    VP8Frame *av_uninit(curframe), *prev_frame;\n\n    av_assert0(avctx->pix_fmt == AV_PIX_FMT_YUVA420P || avctx->pix_fmt == AV_PIX_FMT_YUV420P);\n\n    if (is_vp7)\n        ret = vp7_decode_frame_header(s, avpkt->data, avpkt->size);\n    else\n        ret = vp8_decode_frame_header(s, avpkt->data, avpkt->size);\n\n    if (ret < 0)\n        goto err;\n\n    prev_frame = s->framep[VP56_FRAME_CURRENT];\n\n    referenced = s->update_last || s->update_golden == VP56_FRAME_CURRENT ||\n                 s->update_altref == VP56_FRAME_CURRENT;\n\n    skip_thresh = !referenced ? AVDISCARD_NONREF\n                              : !s->keyframe ? AVDISCARD_NONKEY\n                                             : AVDISCARD_ALL;\n\n    if (avctx->skip_frame >= skip_thresh) {\n        s->invisible = 1;\n        memcpy(&s->next_framep[0], &s->framep[0], sizeof(s->framep[0]) * 4);\n        goto skip_decode;\n    }\n    s->deblock_filter = s->filter.level && avctx->skip_loop_filter < skip_thresh;\n\n    // release no longer referenced frames\n    for (i = 0; i < 5; i++)\n        if (s->frames[i].tf.f->data[0] &&\n            &s->frames[i] != prev_frame &&\n            &s->frames[i] != s->framep[VP56_FRAME_PREVIOUS] &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN]   &&\n            &s->frames[i] != s->framep[VP56_FRAME_GOLDEN2])\n            vp8_release_frame(s, &s->frames[i]);\n\n    curframe = s->framep[VP56_FRAME_CURRENT] = vp8_find_free_buffer(s);\n\n    if (!s->colorspace)\n        avctx->colorspace = AVCOL_SPC_BT470BG;\n    if (s->fullrange)\n        avctx->color_range = AVCOL_RANGE_JPEG;\n    else\n        avctx->color_range = AVCOL_RANGE_MPEG;\n\n    /* Given that arithmetic probabilities are updated every frame, it's quite\n     * likely that the values we have on a random interframe are complete\n     * junk if we didn't start decode on a keyframe. So just don't display\n     * anything rather than junk. */\n    if (!s->keyframe && (!s->framep[VP56_FRAME_PREVIOUS] ||\n                         !s->framep[VP56_FRAME_GOLDEN]   ||\n                         !s->framep[VP56_FRAME_GOLDEN2])) {\n        av_log(avctx, AV_LOG_WARNING,\n               \"Discarding interframe without a prior keyframe!\\n\");\n        ret = AVERROR_INVALIDDATA;\n        goto err;\n    }\n\n    curframe->tf.f->key_frame = s->keyframe;\n    curframe->tf.f->pict_type = s->keyframe ? AV_PICTURE_TYPE_I\n                                            : AV_PICTURE_TYPE_P;\n    if ((ret = vp8_alloc_frame(s, curframe, referenced)) < 0)\n        goto err;\n\n    // check if golden and altref are swapped\n    if (s->update_altref != VP56_FRAME_NONE)\n        s->next_framep[VP56_FRAME_GOLDEN2] = s->framep[s->update_altref];\n    else\n        s->next_framep[VP56_FRAME_GOLDEN2] = s->framep[VP56_FRAME_GOLDEN2];\n\n    if (s->update_golden != VP56_FRAME_NONE)\n        s->next_framep[VP56_FRAME_GOLDEN] = s->framep[s->update_golden];\n    else\n        s->next_framep[VP56_FRAME_GOLDEN] = s->framep[VP56_FRAME_GOLDEN];\n\n    if (s->update_last)\n        s->next_framep[VP56_FRAME_PREVIOUS] = curframe;\n    else\n        s->next_framep[VP56_FRAME_PREVIOUS] = s->framep[VP56_FRAME_PREVIOUS];\n\n    s->next_framep[VP56_FRAME_CURRENT] = curframe;\n\n    if (avctx->codec->update_thread_context)\n        ff_thread_finish_setup(avctx);\n\n    s->linesize   = curframe->tf.f->linesize[0];\n    s->uvlinesize = curframe->tf.f->linesize[1];\n\n    memset(s->top_nnz, 0, s->mb_width * sizeof(*s->top_nnz));\n    /* Zero macroblock structures for top/top-left prediction\n     * from outside the frame. */\n    if (!s->mb_layout)\n        memset(s->macroblocks + s->mb_height * 2 - 1, 0,\n               (s->mb_width + 1) * sizeof(*s->macroblocks));\n    if (!s->mb_layout && s->keyframe)\n        memset(s->intra4x4_pred_mode_top, DC_PRED, s->mb_width * 4);\n\n    memset(s->ref_count, 0, sizeof(s->ref_count));\n\n    if (s->mb_layout == 1) {\n        // Make sure the previous frame has read its segmentation map,\n        // if we re-use the same map.\n        if (prev_frame && s->segmentation.enabled &&\n            !s->segmentation.update_map)\n            ff_thread_await_progress(&prev_frame->tf, 1, 0);\n        if (is_vp7)\n            vp7_decode_mv_mb_modes(avctx, curframe, prev_frame);\n        else\n            vp8_decode_mv_mb_modes(avctx, curframe, prev_frame);\n    }\n\n    if (avctx->active_thread_type == FF_THREAD_FRAME)\n        num_jobs = 1;\n    else\n        num_jobs = FFMIN(s->num_coeff_partitions, avctx->thread_count);\n    s->num_jobs   = num_jobs;\n    s->curframe   = curframe;\n    s->prev_frame = prev_frame;\n    s->mv_bounds.mv_min.y   = -MARGIN;\n    s->mv_bounds.mv_max.y   = ((s->mb_height - 1) << 6) + MARGIN;\n    for (i = 0; i < MAX_THREADS; i++) {\n        VP8ThreadData *td = &s->thread_data[i];\n        atomic_init(&td->thread_mb_pos, 0);\n        atomic_init(&td->wait_mb_pos, INT_MAX);\n    }\n    if (is_vp7)\n        avctx->execute2(avctx, vp7_decode_mb_row_sliced, s->thread_data, NULL,\n                        num_jobs);\n    else\n        avctx->execute2(avctx, vp8_decode_mb_row_sliced, s->thread_data, NULL,\n                        num_jobs);\n\n    ff_thread_report_progress(&curframe->tf, INT_MAX, 0);\n    memcpy(&s->framep[0], &s->next_framep[0], sizeof(s->framep[0]) * 4);\n\nskip_decode:\n    // if future frames don't use the updated probabilities,\n    // reset them to the values we saved\n    if (!s->update_probabilities)\n        s->prob[0] = s->prob[1];\n\n    if (!s->invisible) {\n        if ((ret = av_frame_ref(data, curframe->tf.f)) < 0)\n            return ret;\n        *got_frame = 1;\n    }\n\n    return avpkt->size;\nerr:\n    memcpy(&s->next_framep[0], &s->framep[0], sizeof(s->framep[0]) * 4);\n    return ret;\n}\n\nint ff_vp8_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                        AVPacket *avpkt)\n{\n    return vp78_decode_frame(avctx, data, got_frame, avpkt, IS_VP8);\n}\n\n#if CONFIG_VP7_DECODER\nstatic int vp7_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                            AVPacket *avpkt)\n{\n    return vp78_decode_frame(avctx, data, got_frame, avpkt, IS_VP7);\n}\n#endif /* CONFIG_VP7_DECODER */\n\nav_cold int ff_vp8_decode_free(AVCodecContext *avctx)\n{\n    VP8Context *s = avctx->priv_data;\n    int i;\n\n    if (!s)\n        return 0;\n\n    vp8_decode_flush_impl(avctx, 1);\n    for (i = 0; i < FF_ARRAY_ELEMS(s->frames); i++)\n        av_frame_free(&s->frames[i].tf.f);\n\n    return 0;\n}\n\nstatic av_cold int vp8_init_frames(VP8Context *s)\n{\n    int i;\n    for (i = 0; i < FF_ARRAY_ELEMS(s->frames); i++) {\n        s->frames[i].tf.f = av_frame_alloc();\n        if (!s->frames[i].tf.f)\n            return AVERROR(ENOMEM);\n    }\n    return 0;\n}\n\nstatic av_always_inline\nint vp78_decode_init(AVCodecContext *avctx, int is_vp7)\n{\n    VP8Context *s = avctx->priv_data;\n    int ret;\n\n    s->avctx = avctx;\n    s->vp7   = avctx->codec->id == AV_CODEC_ID_VP7;\n    avctx->pix_fmt = AV_PIX_FMT_YUV420P;\n    avctx->internal->allocate_progress = 1;\n\n    ff_videodsp_init(&s->vdsp, 8);\n\n    ff_vp78dsp_init(&s->vp8dsp);\n    if (CONFIG_VP7_DECODER && is_vp7) {\n        ff_h264_pred_init(&s->hpc, AV_CODEC_ID_VP7, 8, 1);\n        ff_vp7dsp_init(&s->vp8dsp);\n        s->decode_mb_row_no_filter = vp7_decode_mb_row_no_filter;\n        s->filter_mb_row           = vp7_filter_mb_row;\n    } else if (CONFIG_VP8_DECODER && !is_vp7) {\n        ff_h264_pred_init(&s->hpc, AV_CODEC_ID_VP8, 8, 1);\n        ff_vp8dsp_init(&s->vp8dsp);\n        s->decode_mb_row_no_filter = vp8_decode_mb_row_no_filter;\n        s->filter_mb_row           = vp8_filter_mb_row;\n    }\n\n    /* does not change for VP8 */\n    memcpy(s->prob[0].scan, ff_zigzag_scan, sizeof(s->prob[0].scan));\n\n    if ((ret = vp8_init_frames(s)) < 0) {\n        ff_vp8_decode_free(avctx);\n        return ret;\n    }\n\n    return 0;\n}\n\n#if CONFIG_VP7_DECODER\nstatic int vp7_decode_init(AVCodecContext *avctx)\n{\n    return vp78_decode_init(avctx, IS_VP7);\n}\n#endif /* CONFIG_VP7_DECODER */\n\nav_cold int ff_vp8_decode_init(AVCodecContext *avctx)\n{\n    return vp78_decode_init(avctx, IS_VP8);\n}\n\n#if CONFIG_VP8_DECODER\n#if HAVE_THREADS\nstatic av_cold int vp8_decode_init_thread_copy(AVCodecContext *avctx)\n{\n    VP8Context *s = avctx->priv_data;\n    int ret;\n\n    s->avctx = avctx;\n\n    if ((ret = vp8_init_frames(s)) < 0) {\n        ff_vp8_decode_free(avctx);\n        return ret;\n    }\n\n    return 0;\n}\n\n#define REBASE(pic) ((pic) ? (pic) - &s_src->frames[0] + &s->frames[0] : NULL)\n\nstatic int vp8_decode_update_thread_context(AVCodecContext *dst,\n                                            const AVCodecContext *src)\n{\n    VP8Context *s = dst->priv_data, *s_src = src->priv_data;\n    int i;\n\n    if (s->macroblocks_base &&\n        (s_src->mb_width != s->mb_width || s_src->mb_height != s->mb_height)) {\n        free_buffers(s);\n        s->mb_width  = s_src->mb_width;\n        s->mb_height = s_src->mb_height;\n    }\n\n    s->prob[0]      = s_src->prob[!s_src->update_probabilities];\n    s->segmentation = s_src->segmentation;\n    s->lf_delta     = s_src->lf_delta;\n    memcpy(s->sign_bias, s_src->sign_bias, sizeof(s->sign_bias));\n\n    for (i = 0; i < FF_ARRAY_ELEMS(s_src->frames); i++) {\n        if (s_src->frames[i].tf.f->data[0]) {\n            int ret = vp8_ref_frame(s, &s->frames[i], &s_src->frames[i]);\n            if (ret < 0)\n                return ret;\n        }\n    }\n\n    s->framep[0] = REBASE(s_src->next_framep[0]);\n    s->framep[1] = REBASE(s_src->next_framep[1]);\n    s->framep[2] = REBASE(s_src->next_framep[2]);\n    s->framep[3] = REBASE(s_src->next_framep[3]);\n\n    return 0;\n}\n#endif /* HAVE_THREADS */\n#endif /* CONFIG_VP8_DECODER */\n\n#if CONFIG_VP7_DECODER\nAVCodec ff_vp7_decoder = {\n    .name                  = \"vp7\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"On2 VP7\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_VP7,\n    .priv_data_size        = sizeof(VP8Context),\n    .init                  = vp7_decode_init,\n    .close                 = ff_vp8_decode_free,\n    .decode                = vp7_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1,\n    .flush                 = vp8_decode_flush,\n};\n#endif /* CONFIG_VP7_DECODER */\n\n#if CONFIG_VP8_DECODER\nAVCodec ff_vp8_decoder = {\n    .name                  = \"vp8\",\n    .long_name             = NULL_IF_CONFIG_SMALL(\"On2 VP8\"),\n    .type                  = AVMEDIA_TYPE_VIDEO,\n    .id                    = AV_CODEC_ID_VP8,\n    .priv_data_size        = sizeof(VP8Context),\n    .init                  = ff_vp8_decode_init,\n    .close                 = ff_vp8_decode_free,\n    .decode                = ff_vp8_decode_frame,\n    .capabilities          = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_FRAME_THREADS |\n                             AV_CODEC_CAP_SLICE_THREADS,\n    .flush                 = vp8_decode_flush,\n    .init_thread_copy      = ONLY_IF_THREADS_ENABLED(vp8_decode_init_thread_copy),\n    .update_thread_context = ONLY_IF_THREADS_ENABLED(vp8_decode_update_thread_context),\n};\n#endif /* CONFIG_VP7_DECODER */\n", "/*\n * WebP (.webp) image decoder\n * Copyright (c) 2013 Aneesh Dogra <aneesh@sugarlabs.org>\n * Copyright (c) 2013 Justin Ruggles <justin.ruggles@gmail.com>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * WebP image decoder\n *\n * @author Aneesh Dogra <aneesh@sugarlabs.org>\n * Container and Lossy decoding\n *\n * @author Justin Ruggles <justin.ruggles@gmail.com>\n * Lossless decoder\n * Compressed alpha for lossy\n *\n * @author James Almer <jamrial@gmail.com>\n * Exif metadata\n *\n * Unimplemented:\n *   - Animation\n *   - ICC profile\n *   - XMP metadata\n */\n\n#include \"libavutil/imgutils.h\"\n\n#define BITSTREAM_READER_LE\n#include \"avcodec.h\"\n#include \"bytestream.h\"\n#include \"exif.h\"\n#include \"get_bits.h\"\n#include \"internal.h\"\n#include \"thread.h\"\n#include \"vp8.h\"\n\n#define VP8X_FLAG_ANIMATION             0x02\n#define VP8X_FLAG_XMP_METADATA          0x04\n#define VP8X_FLAG_EXIF_METADATA         0x08\n#define VP8X_FLAG_ALPHA                 0x10\n#define VP8X_FLAG_ICC                   0x20\n\n#define MAX_PALETTE_SIZE                256\n#define MAX_CACHE_BITS                  11\n#define NUM_CODE_LENGTH_CODES           19\n#define HUFFMAN_CODES_PER_META_CODE     5\n#define NUM_LITERAL_CODES               256\n#define NUM_LENGTH_CODES                24\n#define NUM_DISTANCE_CODES              40\n#define NUM_SHORT_DISTANCES             120\n#define MAX_HUFFMAN_CODE_LENGTH         15\n\nstatic const uint16_t alphabet_sizes[HUFFMAN_CODES_PER_META_CODE] = {\n    NUM_LITERAL_CODES + NUM_LENGTH_CODES,\n    NUM_LITERAL_CODES, NUM_LITERAL_CODES, NUM_LITERAL_CODES,\n    NUM_DISTANCE_CODES\n};\n\nstatic const uint8_t code_length_code_order[NUM_CODE_LENGTH_CODES] = {\n    17, 18, 0, 1, 2, 3, 4, 5, 16, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15\n};\n\nstatic const int8_t lz77_distance_offsets[NUM_SHORT_DISTANCES][2] = {\n    {  0, 1 }, {  1, 0 }, {  1, 1 }, { -1, 1 }, {  0, 2 }, {  2, 0 }, {  1, 2 }, { -1, 2 },\n    {  2, 1 }, { -2, 1 }, {  2, 2 }, { -2, 2 }, {  0, 3 }, {  3, 0 }, {  1, 3 }, { -1, 3 },\n    {  3, 1 }, { -3, 1 }, {  2, 3 }, { -2, 3 }, {  3, 2 }, { -3, 2 }, {  0, 4 }, {  4, 0 },\n    {  1, 4 }, { -1, 4 }, {  4, 1 }, { -4, 1 }, {  3, 3 }, { -3, 3 }, {  2, 4 }, { -2, 4 },\n    {  4, 2 }, { -4, 2 }, {  0, 5 }, {  3, 4 }, { -3, 4 }, {  4, 3 }, { -4, 3 }, {  5, 0 },\n    {  1, 5 }, { -1, 5 }, {  5, 1 }, { -5, 1 }, {  2, 5 }, { -2, 5 }, {  5, 2 }, { -5, 2 },\n    {  4, 4 }, { -4, 4 }, {  3, 5 }, { -3, 5 }, {  5, 3 }, { -5, 3 }, {  0, 6 }, {  6, 0 },\n    {  1, 6 }, { -1, 6 }, {  6, 1 }, { -6, 1 }, {  2, 6 }, { -2, 6 }, {  6, 2 }, { -6, 2 },\n    {  4, 5 }, { -4, 5 }, {  5, 4 }, { -5, 4 }, {  3, 6 }, { -3, 6 }, {  6, 3 }, { -6, 3 },\n    {  0, 7 }, {  7, 0 }, {  1, 7 }, { -1, 7 }, {  5, 5 }, { -5, 5 }, {  7, 1 }, { -7, 1 },\n    {  4, 6 }, { -4, 6 }, {  6, 4 }, { -6, 4 }, {  2, 7 }, { -2, 7 }, {  7, 2 }, { -7, 2 },\n    {  3, 7 }, { -3, 7 }, {  7, 3 }, { -7, 3 }, {  5, 6 }, { -5, 6 }, {  6, 5 }, { -6, 5 },\n    {  8, 0 }, {  4, 7 }, { -4, 7 }, {  7, 4 }, { -7, 4 }, {  8, 1 }, {  8, 2 }, {  6, 6 },\n    { -6, 6 }, {  8, 3 }, {  5, 7 }, { -5, 7 }, {  7, 5 }, { -7, 5 }, {  8, 4 }, {  6, 7 },\n    { -6, 7 }, {  7, 6 }, { -7, 6 }, {  8, 5 }, {  7, 7 }, { -7, 7 }, {  8, 6 }, {  8, 7 }\n};\n\nenum AlphaCompression {\n    ALPHA_COMPRESSION_NONE,\n    ALPHA_COMPRESSION_VP8L,\n};\n\nenum AlphaFilter {\n    ALPHA_FILTER_NONE,\n    ALPHA_FILTER_HORIZONTAL,\n    ALPHA_FILTER_VERTICAL,\n    ALPHA_FILTER_GRADIENT,\n};\n\nenum TransformType {\n    PREDICTOR_TRANSFORM      = 0,\n    COLOR_TRANSFORM          = 1,\n    SUBTRACT_GREEN           = 2,\n    COLOR_INDEXING_TRANSFORM = 3,\n};\n\nenum PredictionMode {\n    PRED_MODE_BLACK,\n    PRED_MODE_L,\n    PRED_MODE_T,\n    PRED_MODE_TR,\n    PRED_MODE_TL,\n    PRED_MODE_AVG_T_AVG_L_TR,\n    PRED_MODE_AVG_L_TL,\n    PRED_MODE_AVG_L_T,\n    PRED_MODE_AVG_TL_T,\n    PRED_MODE_AVG_T_TR,\n    PRED_MODE_AVG_AVG_L_TL_AVG_T_TR,\n    PRED_MODE_SELECT,\n    PRED_MODE_ADD_SUBTRACT_FULL,\n    PRED_MODE_ADD_SUBTRACT_HALF,\n};\n\nenum HuffmanIndex {\n    HUFF_IDX_GREEN = 0,\n    HUFF_IDX_RED   = 1,\n    HUFF_IDX_BLUE  = 2,\n    HUFF_IDX_ALPHA = 3,\n    HUFF_IDX_DIST  = 4\n};\n\n/* The structure of WebP lossless is an optional series of transformation data,\n * followed by the primary image. The primary image also optionally contains\n * an entropy group mapping if there are multiple entropy groups. There is a\n * basic image type called an \"entropy coded image\" that is used for all of\n * these. The type of each entropy coded image is referred to by the\n * specification as its role. */\nenum ImageRole {\n    /* Primary Image: Stores the actual pixels of the image. */\n    IMAGE_ROLE_ARGB,\n\n    /* Entropy Image: Defines which Huffman group to use for different areas of\n     *                the primary image. */\n    IMAGE_ROLE_ENTROPY,\n\n    /* Predictors: Defines which predictor type to use for different areas of\n     *             the primary image. */\n    IMAGE_ROLE_PREDICTOR,\n\n    /* Color Transform Data: Defines the color transformation for different\n     *                       areas of the primary image. */\n    IMAGE_ROLE_COLOR_TRANSFORM,\n\n    /* Color Index: Stored as an image of height == 1. */\n    IMAGE_ROLE_COLOR_INDEXING,\n\n    IMAGE_ROLE_NB,\n};\n\ntypedef struct HuffReader {\n    VLC vlc;                            /* Huffman decoder context */\n    int simple;                         /* whether to use simple mode */\n    int nb_symbols;                     /* number of coded symbols */\n    uint16_t simple_symbols[2];         /* symbols for simple mode */\n} HuffReader;\n\ntypedef struct ImageContext {\n    enum ImageRole role;                /* role of this image */\n    AVFrame *frame;                     /* AVFrame for data */\n    int color_cache_bits;               /* color cache size, log2 */\n    uint32_t *color_cache;              /* color cache data */\n    int nb_huffman_groups;              /* number of huffman groups */\n    HuffReader *huffman_groups;         /* reader for each huffman group */\n    int size_reduction;                 /* relative size compared to primary image, log2 */\n    int is_alpha_primary;\n} ImageContext;\n\ntypedef struct WebPContext {\n    VP8Context v;                       /* VP8 Context used for lossy decoding */\n    GetBitContext gb;                   /* bitstream reader for main image chunk */\n    AVFrame *alpha_frame;               /* AVFrame for alpha data decompressed from VP8L */\n    AVCodecContext *avctx;              /* parent AVCodecContext */\n    int initialized;                    /* set once the VP8 context is initialized */\n    int has_alpha;                      /* has a separate alpha chunk */\n    enum AlphaCompression alpha_compression; /* compression type for alpha chunk */\n    enum AlphaFilter alpha_filter;      /* filtering method for alpha chunk */\n    uint8_t *alpha_data;                /* alpha chunk data */\n    int alpha_data_size;                /* alpha chunk data size */\n    int has_exif;                       /* set after an EXIF chunk has been processed */\n    int width;                          /* image width */\n    int height;                         /* image height */\n    int lossless;                       /* indicates lossless or lossy */\n\n    int nb_transforms;                  /* number of transforms */\n    enum TransformType transforms[4];   /* transformations used in the image, in order */\n    int reduced_width;                  /* reduced width for index image, if applicable */\n    int nb_huffman_groups;              /* number of huffman groups in the primary image */\n    ImageContext image[IMAGE_ROLE_NB];  /* image context for each role */\n} WebPContext;\n\n#define GET_PIXEL(frame, x, y) \\\n    ((frame)->data[0] + (y) * frame->linesize[0] + 4 * (x))\n\n#define GET_PIXEL_COMP(frame, x, y, c) \\\n    (*((frame)->data[0] + (y) * frame->linesize[0] + 4 * (x) + c))\n\nstatic void image_ctx_free(ImageContext *img)\n{\n    int i, j;\n\n    av_free(img->color_cache);\n    if (img->role != IMAGE_ROLE_ARGB && !img->is_alpha_primary)\n        av_frame_free(&img->frame);\n    if (img->huffman_groups) {\n        for (i = 0; i < img->nb_huffman_groups; i++) {\n            for (j = 0; j < HUFFMAN_CODES_PER_META_CODE; j++)\n                ff_free_vlc(&img->huffman_groups[i * HUFFMAN_CODES_PER_META_CODE + j].vlc);\n        }\n        av_free(img->huffman_groups);\n    }\n    memset(img, 0, sizeof(*img));\n}\n\n\n/* Differs from get_vlc2() in the following ways:\n *   - codes are bit-reversed\n *   - assumes 8-bit table to make reversal simpler\n *   - assumes max depth of 2 since the max code length for WebP is 15\n */\nstatic av_always_inline int webp_get_vlc(GetBitContext *gb, VLC_TYPE (*table)[2])\n{\n    int n, nb_bits;\n    unsigned int index;\n    int code;\n\n    OPEN_READER(re, gb);\n    UPDATE_CACHE(re, gb);\n\n    index = SHOW_UBITS(re, gb, 8);\n    index = ff_reverse[index];\n    code  = table[index][0];\n    n     = table[index][1];\n\n    if (n < 0) {\n        LAST_SKIP_BITS(re, gb, 8);\n        UPDATE_CACHE(re, gb);\n\n        nb_bits = -n;\n\n        index = SHOW_UBITS(re, gb, nb_bits);\n        index = (ff_reverse[index] >> (8 - nb_bits)) + code;\n        code  = table[index][0];\n        n     = table[index][1];\n    }\n    SKIP_BITS(re, gb, n);\n\n    CLOSE_READER(re, gb);\n\n    return code;\n}\n\nstatic int huff_reader_get_symbol(HuffReader *r, GetBitContext *gb)\n{\n    if (r->simple) {\n        if (r->nb_symbols == 1)\n            return r->simple_symbols[0];\n        else\n            return r->simple_symbols[get_bits1(gb)];\n    } else\n        return webp_get_vlc(gb, r->vlc.table);\n}\n\nstatic int huff_reader_build_canonical(HuffReader *r, int *code_lengths,\n                                       int alphabet_size)\n{\n    int len = 0, sym, code = 0, ret;\n    int max_code_length = 0;\n    uint16_t *codes;\n\n    /* special-case 1 symbol since the vlc reader cannot handle it */\n    for (sym = 0; sym < alphabet_size; sym++) {\n        if (code_lengths[sym] > 0) {\n            len++;\n            code = sym;\n            if (len > 1)\n                break;\n        }\n    }\n    if (len == 1) {\n        r->nb_symbols = 1;\n        r->simple_symbols[0] = code;\n        r->simple = 1;\n        return 0;\n    }\n\n    for (sym = 0; sym < alphabet_size; sym++)\n        max_code_length = FFMAX(max_code_length, code_lengths[sym]);\n\n    if (max_code_length == 0 || max_code_length > MAX_HUFFMAN_CODE_LENGTH)\n        return AVERROR(EINVAL);\n\n    codes = av_malloc_array(alphabet_size, sizeof(*codes));\n    if (!codes)\n        return AVERROR(ENOMEM);\n\n    code = 0;\n    r->nb_symbols = 0;\n    for (len = 1; len <= max_code_length; len++) {\n        for (sym = 0; sym < alphabet_size; sym++) {\n            if (code_lengths[sym] != len)\n                continue;\n            codes[sym] = code++;\n            r->nb_symbols++;\n        }\n        code <<= 1;\n    }\n    if (!r->nb_symbols) {\n        av_free(codes);\n        return AVERROR_INVALIDDATA;\n    }\n\n    ret = init_vlc(&r->vlc, 8, alphabet_size,\n                   code_lengths, sizeof(*code_lengths), sizeof(*code_lengths),\n                   codes, sizeof(*codes), sizeof(*codes), 0);\n    if (ret < 0) {\n        av_free(codes);\n        return ret;\n    }\n    r->simple = 0;\n\n    av_free(codes);\n    return 0;\n}\n\nstatic void read_huffman_code_simple(WebPContext *s, HuffReader *hc)\n{\n    hc->nb_symbols = get_bits1(&s->gb) + 1;\n\n    if (get_bits1(&s->gb))\n        hc->simple_symbols[0] = get_bits(&s->gb, 8);\n    else\n        hc->simple_symbols[0] = get_bits1(&s->gb);\n\n    if (hc->nb_symbols == 2)\n        hc->simple_symbols[1] = get_bits(&s->gb, 8);\n\n    hc->simple = 1;\n}\n\nstatic int read_huffman_code_normal(WebPContext *s, HuffReader *hc,\n                                    int alphabet_size)\n{\n    HuffReader code_len_hc = { { 0 }, 0, 0, { 0 } };\n    int *code_lengths = NULL;\n    int code_length_code_lengths[NUM_CODE_LENGTH_CODES] = { 0 };\n    int i, symbol, max_symbol, prev_code_len, ret;\n    int num_codes = 4 + get_bits(&s->gb, 4);\n\n    if (num_codes > NUM_CODE_LENGTH_CODES)\n        return AVERROR_INVALIDDATA;\n\n    for (i = 0; i < num_codes; i++)\n        code_length_code_lengths[code_length_code_order[i]] = get_bits(&s->gb, 3);\n\n    ret = huff_reader_build_canonical(&code_len_hc, code_length_code_lengths,\n                                      NUM_CODE_LENGTH_CODES);\n    if (ret < 0)\n        goto finish;\n\n    code_lengths = av_mallocz_array(alphabet_size, sizeof(*code_lengths));\n    if (!code_lengths) {\n        ret = AVERROR(ENOMEM);\n        goto finish;\n    }\n\n    if (get_bits1(&s->gb)) {\n        int bits   = 2 + 2 * get_bits(&s->gb, 3);\n        max_symbol = 2 + get_bits(&s->gb, bits);\n        if (max_symbol > alphabet_size) {\n            av_log(s->avctx, AV_LOG_ERROR, \"max symbol %d > alphabet size %d\\n\",\n                   max_symbol, alphabet_size);\n            ret = AVERROR_INVALIDDATA;\n            goto finish;\n        }\n    } else {\n        max_symbol = alphabet_size;\n    }\n\n    prev_code_len = 8;\n    symbol        = 0;\n    while (symbol < alphabet_size) {\n        int code_len;\n\n        if (!max_symbol--)\n            break;\n        code_len = huff_reader_get_symbol(&code_len_hc, &s->gb);\n        if (code_len < 16) {\n            /* Code length code [0..15] indicates literal code lengths. */\n            code_lengths[symbol++] = code_len;\n            if (code_len)\n                prev_code_len = code_len;\n        } else {\n            int repeat = 0, length = 0;\n            switch (code_len) {\n            case 16:\n                /* Code 16 repeats the previous non-zero value [3..6] times,\n                 * i.e., 3 + ReadBits(2) times. If code 16 is used before a\n                 * non-zero value has been emitted, a value of 8 is repeated. */\n                repeat = 3 + get_bits(&s->gb, 2);\n                length = prev_code_len;\n                break;\n            case 17:\n                /* Code 17 emits a streak of zeros [3..10], i.e.,\n                 * 3 + ReadBits(3) times. */\n                repeat = 3 + get_bits(&s->gb, 3);\n                break;\n            case 18:\n                /* Code 18 emits a streak of zeros of length [11..138], i.e.,\n                 * 11 + ReadBits(7) times. */\n                repeat = 11 + get_bits(&s->gb, 7);\n                break;\n            }\n            if (symbol + repeat > alphabet_size) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"invalid symbol %d + repeat %d > alphabet size %d\\n\",\n                       symbol, repeat, alphabet_size);\n                ret = AVERROR_INVALIDDATA;\n                goto finish;\n            }\n            while (repeat-- > 0)\n                code_lengths[symbol++] = length;\n        }\n    }\n\n    ret = huff_reader_build_canonical(hc, code_lengths, alphabet_size);\n\nfinish:\n    ff_free_vlc(&code_len_hc.vlc);\n    av_free(code_lengths);\n    return ret;\n}\n\nstatic int decode_entropy_coded_image(WebPContext *s, enum ImageRole role,\n                                      int w, int h);\n\n#define PARSE_BLOCK_SIZE(w, h) do {                                         \\\n    block_bits = get_bits(&s->gb, 3) + 2;                                   \\\n    blocks_w   = FFALIGN((w), 1 << block_bits) >> block_bits;               \\\n    blocks_h   = FFALIGN((h), 1 << block_bits) >> block_bits;               \\\n} while (0)\n\nstatic int decode_entropy_image(WebPContext *s)\n{\n    ImageContext *img;\n    int ret, block_bits, width, blocks_w, blocks_h, x, y, max;\n\n    width = s->width;\n    if (s->reduced_width > 0)\n        width = s->reduced_width;\n\n    PARSE_BLOCK_SIZE(width, s->height);\n\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_ENTROPY, blocks_w, blocks_h);\n    if (ret < 0)\n        return ret;\n\n    img = &s->image[IMAGE_ROLE_ENTROPY];\n    img->size_reduction = block_bits;\n\n    /* the number of huffman groups is determined by the maximum group number\n     * coded in the entropy image */\n    max = 0;\n    for (y = 0; y < img->frame->height; y++) {\n        for (x = 0; x < img->frame->width; x++) {\n            int p0 = GET_PIXEL_COMP(img->frame, x, y, 1);\n            int p1 = GET_PIXEL_COMP(img->frame, x, y, 2);\n            int p  = p0 << 8 | p1;\n            max = FFMAX(max, p);\n        }\n    }\n    s->nb_huffman_groups = max + 1;\n\n    return 0;\n}\n\nstatic int parse_transform_predictor(WebPContext *s)\n{\n    int block_bits, blocks_w, blocks_h, ret;\n\n    PARSE_BLOCK_SIZE(s->width, s->height);\n\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_PREDICTOR, blocks_w,\n                                     blocks_h);\n    if (ret < 0)\n        return ret;\n\n    s->image[IMAGE_ROLE_PREDICTOR].size_reduction = block_bits;\n\n    return 0;\n}\n\nstatic int parse_transform_color(WebPContext *s)\n{\n    int block_bits, blocks_w, blocks_h, ret;\n\n    PARSE_BLOCK_SIZE(s->width, s->height);\n\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_COLOR_TRANSFORM, blocks_w,\n                                     blocks_h);\n    if (ret < 0)\n        return ret;\n\n    s->image[IMAGE_ROLE_COLOR_TRANSFORM].size_reduction = block_bits;\n\n    return 0;\n}\n\nstatic int parse_transform_color_indexing(WebPContext *s)\n{\n    ImageContext *img;\n    int width_bits, index_size, ret, x;\n    uint8_t *ct;\n\n    index_size = get_bits(&s->gb, 8) + 1;\n\n    if (index_size <= 2)\n        width_bits = 3;\n    else if (index_size <= 4)\n        width_bits = 2;\n    else if (index_size <= 16)\n        width_bits = 1;\n    else\n        width_bits = 0;\n\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_COLOR_INDEXING,\n                                     index_size, 1);\n    if (ret < 0)\n        return ret;\n\n    img = &s->image[IMAGE_ROLE_COLOR_INDEXING];\n    img->size_reduction = width_bits;\n    if (width_bits > 0)\n        s->reduced_width = (s->width + ((1 << width_bits) - 1)) >> width_bits;\n\n    /* color index values are delta-coded */\n    ct  = img->frame->data[0] + 4;\n    for (x = 4; x < img->frame->width * 4; x++, ct++)\n        ct[0] += ct[-4];\n\n    return 0;\n}\n\nstatic HuffReader *get_huffman_group(WebPContext *s, ImageContext *img,\n                                     int x, int y)\n{\n    ImageContext *gimg = &s->image[IMAGE_ROLE_ENTROPY];\n    int group = 0;\n\n    if (gimg->size_reduction > 0) {\n        int group_x = x >> gimg->size_reduction;\n        int group_y = y >> gimg->size_reduction;\n        int g0      = GET_PIXEL_COMP(gimg->frame, group_x, group_y, 1);\n        int g1      = GET_PIXEL_COMP(gimg->frame, group_x, group_y, 2);\n        group       = g0 << 8 | g1;\n    }\n\n    return &img->huffman_groups[group * HUFFMAN_CODES_PER_META_CODE];\n}\n\nstatic av_always_inline void color_cache_put(ImageContext *img, uint32_t c)\n{\n    uint32_t cache_idx = (0x1E35A7BD * c) >> (32 - img->color_cache_bits);\n    img->color_cache[cache_idx] = c;\n}\n\nstatic int decode_entropy_coded_image(WebPContext *s, enum ImageRole role,\n                                      int w, int h)\n{\n    ImageContext *img;\n    HuffReader *hg;\n    int i, j, ret, x, y, width;\n\n    img       = &s->image[role];\n    img->role = role;\n\n    if (!img->frame) {\n        img->frame = av_frame_alloc();\n        if (!img->frame)\n            return AVERROR(ENOMEM);\n    }\n\n    img->frame->format = AV_PIX_FMT_ARGB;\n    img->frame->width  = w;\n    img->frame->height = h;\n\n    if (role == IMAGE_ROLE_ARGB && !img->is_alpha_primary) {\n        ThreadFrame pt = { .f = img->frame };\n        ret = ff_thread_get_buffer(s->avctx, &pt, 0);\n    } else\n        ret = av_frame_get_buffer(img->frame, 1);\n    if (ret < 0)\n        return ret;\n\n    if (get_bits1(&s->gb)) {\n        img->color_cache_bits = get_bits(&s->gb, 4);\n        if (img->color_cache_bits < 1 || img->color_cache_bits > 11) {\n            av_log(s->avctx, AV_LOG_ERROR, \"invalid color cache bits: %d\\n\",\n                   img->color_cache_bits);\n            return AVERROR_INVALIDDATA;\n        }\n        img->color_cache = av_mallocz_array(1 << img->color_cache_bits,\n                                            sizeof(*img->color_cache));\n        if (!img->color_cache)\n            return AVERROR(ENOMEM);\n    } else {\n        img->color_cache_bits = 0;\n    }\n\n    img->nb_huffman_groups = 1;\n    if (role == IMAGE_ROLE_ARGB && get_bits1(&s->gb)) {\n        ret = decode_entropy_image(s);\n        if (ret < 0)\n            return ret;\n        img->nb_huffman_groups = s->nb_huffman_groups;\n    }\n    img->huffman_groups = av_mallocz_array(img->nb_huffman_groups *\n                                           HUFFMAN_CODES_PER_META_CODE,\n                                           sizeof(*img->huffman_groups));\n    if (!img->huffman_groups)\n        return AVERROR(ENOMEM);\n\n    for (i = 0; i < img->nb_huffman_groups; i++) {\n        hg = &img->huffman_groups[i * HUFFMAN_CODES_PER_META_CODE];\n        for (j = 0; j < HUFFMAN_CODES_PER_META_CODE; j++) {\n            int alphabet_size = alphabet_sizes[j];\n            if (!j && img->color_cache_bits > 0)\n                alphabet_size += 1 << img->color_cache_bits;\n\n            if (get_bits1(&s->gb)) {\n                read_huffman_code_simple(s, &hg[j]);\n            } else {\n                ret = read_huffman_code_normal(s, &hg[j], alphabet_size);\n                if (ret < 0)\n                    return ret;\n            }\n        }\n    }\n\n    width = img->frame->width;\n    if (role == IMAGE_ROLE_ARGB && s->reduced_width > 0)\n        width = s->reduced_width;\n\n    x = 0; y = 0;\n    while (y < img->frame->height) {\n        int v;\n\n        hg = get_huffman_group(s, img, x, y);\n        v = huff_reader_get_symbol(&hg[HUFF_IDX_GREEN], &s->gb);\n        if (v < NUM_LITERAL_CODES) {\n            /* literal pixel values */\n            uint8_t *p = GET_PIXEL(img->frame, x, y);\n            p[2] = v;\n            p[1] = huff_reader_get_symbol(&hg[HUFF_IDX_RED],   &s->gb);\n            p[3] = huff_reader_get_symbol(&hg[HUFF_IDX_BLUE],  &s->gb);\n            p[0] = huff_reader_get_symbol(&hg[HUFF_IDX_ALPHA], &s->gb);\n            if (img->color_cache_bits)\n                color_cache_put(img, AV_RB32(p));\n            x++;\n            if (x == width) {\n                x = 0;\n                y++;\n            }\n        } else if (v < NUM_LITERAL_CODES + NUM_LENGTH_CODES) {\n            /* LZ77 backwards mapping */\n            int prefix_code, length, distance, ref_x, ref_y;\n\n            /* parse length and distance */\n            prefix_code = v - NUM_LITERAL_CODES;\n            if (prefix_code < 4) {\n                length = prefix_code + 1;\n            } else {\n                int extra_bits = (prefix_code - 2) >> 1;\n                int offset     = 2 + (prefix_code & 1) << extra_bits;\n                length = offset + get_bits(&s->gb, extra_bits) + 1;\n            }\n            prefix_code = huff_reader_get_symbol(&hg[HUFF_IDX_DIST], &s->gb);\n            if (prefix_code > 39) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"distance prefix code too large: %d\\n\", prefix_code);\n                return AVERROR_INVALIDDATA;\n            }\n            if (prefix_code < 4) {\n                distance = prefix_code + 1;\n            } else {\n                int extra_bits = prefix_code - 2 >> 1;\n                int offset     = 2 + (prefix_code & 1) << extra_bits;\n                distance = offset + get_bits(&s->gb, extra_bits) + 1;\n            }\n\n            /* find reference location */\n            if (distance <= NUM_SHORT_DISTANCES) {\n                int xi = lz77_distance_offsets[distance - 1][0];\n                int yi = lz77_distance_offsets[distance - 1][1];\n                distance = FFMAX(1, xi + yi * width);\n            } else {\n                distance -= NUM_SHORT_DISTANCES;\n            }\n            ref_x = x;\n            ref_y = y;\n            if (distance <= x) {\n                ref_x -= distance;\n                distance = 0;\n            } else {\n                ref_x = 0;\n                distance -= x;\n            }\n            while (distance >= width) {\n                ref_y--;\n                distance -= width;\n            }\n            if (distance > 0) {\n                ref_x = width - distance;\n                ref_y--;\n            }\n            ref_x = FFMAX(0, ref_x);\n            ref_y = FFMAX(0, ref_y);\n\n            /* copy pixels\n             * source and dest regions can overlap and wrap lines, so just\n             * copy per-pixel */\n            for (i = 0; i < length; i++) {\n                uint8_t *p_ref = GET_PIXEL(img->frame, ref_x, ref_y);\n                uint8_t *p     = GET_PIXEL(img->frame,     x,     y);\n\n                AV_COPY32(p, p_ref);\n                if (img->color_cache_bits)\n                    color_cache_put(img, AV_RB32(p));\n                x++;\n                ref_x++;\n                if (x == width) {\n                    x = 0;\n                    y++;\n                }\n                if (ref_x == width) {\n                    ref_x = 0;\n                    ref_y++;\n                }\n                if (y == img->frame->height || ref_y == img->frame->height)\n                    break;\n            }\n        } else {\n            /* read from color cache */\n            uint8_t *p = GET_PIXEL(img->frame, x, y);\n            int cache_idx = v - (NUM_LITERAL_CODES + NUM_LENGTH_CODES);\n\n            if (!img->color_cache_bits) {\n                av_log(s->avctx, AV_LOG_ERROR, \"color cache not found\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            if (cache_idx >= 1 << img->color_cache_bits) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"color cache index out-of-bounds\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            AV_WB32(p, img->color_cache[cache_idx]);\n            x++;\n            if (x == width) {\n                x = 0;\n                y++;\n            }\n        }\n    }\n\n    return 0;\n}\n\n/* PRED_MODE_BLACK */\nstatic void inv_predict_0(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_WB32(p, 0xFF000000);\n}\n\n/* PRED_MODE_L */\nstatic void inv_predict_1(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_COPY32(p, p_l);\n}\n\n/* PRED_MODE_T */\nstatic void inv_predict_2(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_COPY32(p, p_t);\n}\n\n/* PRED_MODE_TR */\nstatic void inv_predict_3(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_COPY32(p, p_tr);\n}\n\n/* PRED_MODE_TL */\nstatic void inv_predict_4(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    AV_COPY32(p, p_tl);\n}\n\n/* PRED_MODE_AVG_T_AVG_L_TR */\nstatic void inv_predict_5(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_t[0] + (p_l[0] + p_tr[0] >> 1) >> 1;\n    p[1] = p_t[1] + (p_l[1] + p_tr[1] >> 1) >> 1;\n    p[2] = p_t[2] + (p_l[2] + p_tr[2] >> 1) >> 1;\n    p[3] = p_t[3] + (p_l[3] + p_tr[3] >> 1) >> 1;\n}\n\n/* PRED_MODE_AVG_L_TL */\nstatic void inv_predict_6(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_l[0] + p_tl[0] >> 1;\n    p[1] = p_l[1] + p_tl[1] >> 1;\n    p[2] = p_l[2] + p_tl[2] >> 1;\n    p[3] = p_l[3] + p_tl[3] >> 1;\n}\n\n/* PRED_MODE_AVG_L_T */\nstatic void inv_predict_7(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_l[0] + p_t[0] >> 1;\n    p[1] = p_l[1] + p_t[1] >> 1;\n    p[2] = p_l[2] + p_t[2] >> 1;\n    p[3] = p_l[3] + p_t[3] >> 1;\n}\n\n/* PRED_MODE_AVG_TL_T */\nstatic void inv_predict_8(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_tl[0] + p_t[0] >> 1;\n    p[1] = p_tl[1] + p_t[1] >> 1;\n    p[2] = p_tl[2] + p_t[2] >> 1;\n    p[3] = p_tl[3] + p_t[3] >> 1;\n}\n\n/* PRED_MODE_AVG_T_TR */\nstatic void inv_predict_9(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                          const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = p_t[0] + p_tr[0] >> 1;\n    p[1] = p_t[1] + p_tr[1] >> 1;\n    p[2] = p_t[2] + p_tr[2] >> 1;\n    p[3] = p_t[3] + p_tr[3] >> 1;\n}\n\n/* PRED_MODE_AVG_AVG_L_TL_AVG_T_TR */\nstatic void inv_predict_10(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                           const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = (p_l[0] + p_tl[0] >> 1) + (p_t[0] + p_tr[0] >> 1) >> 1;\n    p[1] = (p_l[1] + p_tl[1] >> 1) + (p_t[1] + p_tr[1] >> 1) >> 1;\n    p[2] = (p_l[2] + p_tl[2] >> 1) + (p_t[2] + p_tr[2] >> 1) >> 1;\n    p[3] = (p_l[3] + p_tl[3] >> 1) + (p_t[3] + p_tr[3] >> 1) >> 1;\n}\n\n/* PRED_MODE_SELECT */\nstatic void inv_predict_11(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                           const uint8_t *p_t, const uint8_t *p_tr)\n{\n    int diff = (FFABS(p_l[0] - p_tl[0]) - FFABS(p_t[0] - p_tl[0])) +\n               (FFABS(p_l[1] - p_tl[1]) - FFABS(p_t[1] - p_tl[1])) +\n               (FFABS(p_l[2] - p_tl[2]) - FFABS(p_t[2] - p_tl[2])) +\n               (FFABS(p_l[3] - p_tl[3]) - FFABS(p_t[3] - p_tl[3]));\n    if (diff <= 0)\n        AV_COPY32(p, p_t);\n    else\n        AV_COPY32(p, p_l);\n}\n\n/* PRED_MODE_ADD_SUBTRACT_FULL */\nstatic void inv_predict_12(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                           const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = av_clip_uint8(p_l[0] + p_t[0] - p_tl[0]);\n    p[1] = av_clip_uint8(p_l[1] + p_t[1] - p_tl[1]);\n    p[2] = av_clip_uint8(p_l[2] + p_t[2] - p_tl[2]);\n    p[3] = av_clip_uint8(p_l[3] + p_t[3] - p_tl[3]);\n}\n\nstatic av_always_inline uint8_t clamp_add_subtract_half(int a, int b, int c)\n{\n    int d = a + b >> 1;\n    return av_clip_uint8(d + (d - c) / 2);\n}\n\n/* PRED_MODE_ADD_SUBTRACT_HALF */\nstatic void inv_predict_13(uint8_t *p, const uint8_t *p_l, const uint8_t *p_tl,\n                           const uint8_t *p_t, const uint8_t *p_tr)\n{\n    p[0] = clamp_add_subtract_half(p_l[0], p_t[0], p_tl[0]);\n    p[1] = clamp_add_subtract_half(p_l[1], p_t[1], p_tl[1]);\n    p[2] = clamp_add_subtract_half(p_l[2], p_t[2], p_tl[2]);\n    p[3] = clamp_add_subtract_half(p_l[3], p_t[3], p_tl[3]);\n}\n\ntypedef void (*inv_predict_func)(uint8_t *p, const uint8_t *p_l,\n                                 const uint8_t *p_tl, const uint8_t *p_t,\n                                 const uint8_t *p_tr);\n\nstatic const inv_predict_func inverse_predict[14] = {\n    inv_predict_0,  inv_predict_1,  inv_predict_2,  inv_predict_3,\n    inv_predict_4,  inv_predict_5,  inv_predict_6,  inv_predict_7,\n    inv_predict_8,  inv_predict_9,  inv_predict_10, inv_predict_11,\n    inv_predict_12, inv_predict_13,\n};\n\nstatic void inverse_prediction(AVFrame *frame, enum PredictionMode m, int x, int y)\n{\n    uint8_t *dec, *p_l, *p_tl, *p_t, *p_tr;\n    uint8_t p[4];\n\n    dec  = GET_PIXEL(frame, x,     y);\n    p_l  = GET_PIXEL(frame, x - 1, y);\n    p_tl = GET_PIXEL(frame, x - 1, y - 1);\n    p_t  = GET_PIXEL(frame, x,     y - 1);\n    if (x == frame->width - 1)\n        p_tr = GET_PIXEL(frame, 0, y);\n    else\n        p_tr = GET_PIXEL(frame, x + 1, y - 1);\n\n    inverse_predict[m](p, p_l, p_tl, p_t, p_tr);\n\n    dec[0] += p[0];\n    dec[1] += p[1];\n    dec[2] += p[2];\n    dec[3] += p[3];\n}\n\nstatic int apply_predictor_transform(WebPContext *s)\n{\n    ImageContext *img  = &s->image[IMAGE_ROLE_ARGB];\n    ImageContext *pimg = &s->image[IMAGE_ROLE_PREDICTOR];\n    int x, y;\n\n    for (y = 0; y < img->frame->height; y++) {\n        for (x = 0; x < img->frame->width; x++) {\n            int tx = x >> pimg->size_reduction;\n            int ty = y >> pimg->size_reduction;\n            enum PredictionMode m = GET_PIXEL_COMP(pimg->frame, tx, ty, 2);\n\n            if (x == 0) {\n                if (y == 0)\n                    m = PRED_MODE_BLACK;\n                else\n                    m = PRED_MODE_T;\n            } else if (y == 0)\n                m = PRED_MODE_L;\n\n            if (m > 13) {\n                av_log(s->avctx, AV_LOG_ERROR,\n                       \"invalid predictor mode: %d\\n\", m);\n                return AVERROR_INVALIDDATA;\n            }\n            inverse_prediction(img->frame, m, x, y);\n        }\n    }\n    return 0;\n}\n\nstatic av_always_inline uint8_t color_transform_delta(uint8_t color_pred,\n                                                      uint8_t color)\n{\n    return (int)ff_u8_to_s8(color_pred) * ff_u8_to_s8(color) >> 5;\n}\n\nstatic int apply_color_transform(WebPContext *s)\n{\n    ImageContext *img, *cimg;\n    int x, y, cx, cy;\n    uint8_t *p, *cp;\n\n    img  = &s->image[IMAGE_ROLE_ARGB];\n    cimg = &s->image[IMAGE_ROLE_COLOR_TRANSFORM];\n\n    for (y = 0; y < img->frame->height; y++) {\n        for (x = 0; x < img->frame->width; x++) {\n            cx = x >> cimg->size_reduction;\n            cy = y >> cimg->size_reduction;\n            cp = GET_PIXEL(cimg->frame, cx, cy);\n            p  = GET_PIXEL(img->frame,   x,  y);\n\n            p[1] += color_transform_delta(cp[3], p[2]);\n            p[3] += color_transform_delta(cp[2], p[2]) +\n                    color_transform_delta(cp[1], p[1]);\n        }\n    }\n    return 0;\n}\n\nstatic int apply_subtract_green_transform(WebPContext *s)\n{\n    int x, y;\n    ImageContext *img = &s->image[IMAGE_ROLE_ARGB];\n\n    for (y = 0; y < img->frame->height; y++) {\n        for (x = 0; x < img->frame->width; x++) {\n            uint8_t *p = GET_PIXEL(img->frame, x, y);\n            p[1] += p[2];\n            p[3] += p[2];\n        }\n    }\n    return 0;\n}\n\nstatic int apply_color_indexing_transform(WebPContext *s)\n{\n    ImageContext *img;\n    ImageContext *pal;\n    int i, x, y;\n    uint8_t *p;\n\n    img = &s->image[IMAGE_ROLE_ARGB];\n    pal = &s->image[IMAGE_ROLE_COLOR_INDEXING];\n\n    if (pal->size_reduction > 0) {\n        GetBitContext gb_g;\n        uint8_t *line;\n        int pixel_bits = 8 >> pal->size_reduction;\n\n        line = av_malloc(img->frame->linesize[0]);\n        if (!line)\n            return AVERROR(ENOMEM);\n\n        for (y = 0; y < img->frame->height; y++) {\n            p = GET_PIXEL(img->frame, 0, y);\n            memcpy(line, p, img->frame->linesize[0]);\n            init_get_bits(&gb_g, line, img->frame->linesize[0] * 8);\n            skip_bits(&gb_g, 16);\n            i = 0;\n            for (x = 0; x < img->frame->width; x++) {\n                p    = GET_PIXEL(img->frame, x, y);\n                p[2] = get_bits(&gb_g, pixel_bits);\n                i++;\n                if (i == 1 << pal->size_reduction) {\n                    skip_bits(&gb_g, 24);\n                    i = 0;\n                }\n            }\n        }\n        av_free(line);\n    }\n\n    // switch to local palette if it's worth initializing it\n    if (img->frame->height * img->frame->width > 300) {\n        uint8_t palette[256 * 4];\n        const int size = pal->frame->width * 4;\n        av_assert0(size <= 1024U);\n        memcpy(palette, GET_PIXEL(pal->frame, 0, 0), size);   // copy palette\n        // set extra entries to transparent black\n        memset(palette + size, 0, 256 * 4 - size);\n        for (y = 0; y < img->frame->height; y++) {\n            for (x = 0; x < img->frame->width; x++) {\n                p = GET_PIXEL(img->frame, x, y);\n                i = p[2];\n                AV_COPY32(p, &palette[i * 4]);\n            }\n        }\n    } else {\n        for (y = 0; y < img->frame->height; y++) {\n            for (x = 0; x < img->frame->width; x++) {\n                p = GET_PIXEL(img->frame, x, y);\n                i = p[2];\n                if (i >= pal->frame->width) {\n                    AV_WB32(p, 0x00000000);\n                } else {\n                    const uint8_t *pi = GET_PIXEL(pal->frame, i, 0);\n                    AV_COPY32(p, pi);\n                }\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic void update_canvas_size(AVCodecContext *avctx, int w, int h)\n{\n    WebPContext *s = avctx->priv_data;\n    if (s->width && s->width != w) {\n        av_log(avctx, AV_LOG_WARNING, \"Width mismatch. %d != %d\\n\",\n               s->width, w);\n    }\n    s->width = w;\n    if (s->height && s->height != h) {\n        av_log(avctx, AV_LOG_WARNING, \"Height mismatch. %d != %d\\n\",\n               s->height, h);\n    }\n    s->height = h;\n}\n\nstatic int vp8_lossless_decode_frame(AVCodecContext *avctx, AVFrame *p,\n                                     int *got_frame, uint8_t *data_start,\n                                     unsigned int data_size, int is_alpha_chunk)\n{\n    WebPContext *s = avctx->priv_data;\n    int w, h, ret, i, used;\n\n    if (!is_alpha_chunk) {\n        s->lossless = 1;\n        avctx->pix_fmt = AV_PIX_FMT_ARGB;\n    }\n\n    ret = init_get_bits8(&s->gb, data_start, data_size);\n    if (ret < 0)\n        return ret;\n\n    if (!is_alpha_chunk) {\n        if (get_bits(&s->gb, 8) != 0x2F) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid WebP Lossless signature\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n\n        w = get_bits(&s->gb, 14) + 1;\n        h = get_bits(&s->gb, 14) + 1;\n\n        update_canvas_size(avctx, w, h);\n\n        ret = ff_set_dimensions(avctx, s->width, s->height);\n        if (ret < 0)\n            return ret;\n\n        s->has_alpha = get_bits1(&s->gb);\n\n        if (get_bits(&s->gb, 3) != 0x0) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid WebP Lossless version\\n\");\n            return AVERROR_INVALIDDATA;\n        }\n    } else {\n        if (!s->width || !s->height)\n            return AVERROR_BUG;\n        w = s->width;\n        h = s->height;\n    }\n\n    /* parse transformations */\n    s->nb_transforms = 0;\n    s->reduced_width = 0;\n    used = 0;\n    while (get_bits1(&s->gb)) {\n        enum TransformType transform = get_bits(&s->gb, 2);\n        if (used & (1 << transform)) {\n            av_log(avctx, AV_LOG_ERROR, \"Transform %d used more than once\\n\",\n                   transform);\n            ret = AVERROR_INVALIDDATA;\n            goto free_and_return;\n        }\n        used |= (1 << transform);\n        s->transforms[s->nb_transforms++] = transform;\n        switch (transform) {\n        case PREDICTOR_TRANSFORM:\n            ret = parse_transform_predictor(s);\n            break;\n        case COLOR_TRANSFORM:\n            ret = parse_transform_color(s);\n            break;\n        case COLOR_INDEXING_TRANSFORM:\n            ret = parse_transform_color_indexing(s);\n            break;\n        }\n        if (ret < 0)\n            goto free_and_return;\n    }\n\n    /* decode primary image */\n    s->image[IMAGE_ROLE_ARGB].frame = p;\n    if (is_alpha_chunk)\n        s->image[IMAGE_ROLE_ARGB].is_alpha_primary = 1;\n    ret = decode_entropy_coded_image(s, IMAGE_ROLE_ARGB, w, h);\n    if (ret < 0)\n        goto free_and_return;\n\n    /* apply transformations */\n    for (i = s->nb_transforms - 1; i >= 0; i--) {\n        switch (s->transforms[i]) {\n        case PREDICTOR_TRANSFORM:\n            ret = apply_predictor_transform(s);\n            break;\n        case COLOR_TRANSFORM:\n            ret = apply_color_transform(s);\n            break;\n        case SUBTRACT_GREEN:\n            ret = apply_subtract_green_transform(s);\n            break;\n        case COLOR_INDEXING_TRANSFORM:\n            ret = apply_color_indexing_transform(s);\n            break;\n        }\n        if (ret < 0)\n            goto free_and_return;\n    }\n\n    *got_frame   = 1;\n    p->pict_type = AV_PICTURE_TYPE_I;\n    p->key_frame = 1;\n    ret          = data_size;\n\nfree_and_return:\n    for (i = 0; i < IMAGE_ROLE_NB; i++)\n        image_ctx_free(&s->image[i]);\n\n    return ret;\n}\n\nstatic void alpha_inverse_prediction(AVFrame *frame, enum AlphaFilter m)\n{\n    int x, y, ls;\n    uint8_t *dec;\n\n    ls = frame->linesize[3];\n\n    /* filter first row using horizontal filter */\n    dec = frame->data[3] + 1;\n    for (x = 1; x < frame->width; x++, dec++)\n        *dec += *(dec - 1);\n\n    /* filter first column using vertical filter */\n    dec = frame->data[3] + ls;\n    for (y = 1; y < frame->height; y++, dec += ls)\n        *dec += *(dec - ls);\n\n    /* filter the rest using the specified filter */\n    switch (m) {\n    case ALPHA_FILTER_HORIZONTAL:\n        for (y = 1; y < frame->height; y++) {\n            dec = frame->data[3] + y * ls + 1;\n            for (x = 1; x < frame->width; x++, dec++)\n                *dec += *(dec - 1);\n        }\n        break;\n    case ALPHA_FILTER_VERTICAL:\n        for (y = 1; y < frame->height; y++) {\n            dec = frame->data[3] + y * ls + 1;\n            for (x = 1; x < frame->width; x++, dec++)\n                *dec += *(dec - ls);\n        }\n        break;\n    case ALPHA_FILTER_GRADIENT:\n        for (y = 1; y < frame->height; y++) {\n            dec = frame->data[3] + y * ls + 1;\n            for (x = 1; x < frame->width; x++, dec++)\n                dec[0] += av_clip_uint8(*(dec - 1) + *(dec - ls) - *(dec - ls - 1));\n        }\n        break;\n    }\n}\n\nstatic int vp8_lossy_decode_alpha(AVCodecContext *avctx, AVFrame *p,\n                                  uint8_t *data_start,\n                                  unsigned int data_size)\n{\n    WebPContext *s = avctx->priv_data;\n    int x, y, ret;\n\n    if (s->alpha_compression == ALPHA_COMPRESSION_NONE) {\n        GetByteContext gb;\n\n        bytestream2_init(&gb, data_start, data_size);\n        for (y = 0; y < s->height; y++)\n            bytestream2_get_buffer(&gb, p->data[3] + p->linesize[3] * y,\n                                   s->width);\n    } else if (s->alpha_compression == ALPHA_COMPRESSION_VP8L) {\n        uint8_t *ap, *pp;\n        int alpha_got_frame = 0;\n\n        s->alpha_frame = av_frame_alloc();\n        if (!s->alpha_frame)\n            return AVERROR(ENOMEM);\n\n        ret = vp8_lossless_decode_frame(avctx, s->alpha_frame, &alpha_got_frame,\n                                        data_start, data_size, 1);\n        if (ret < 0) {\n            av_frame_free(&s->alpha_frame);\n            return ret;\n        }\n        if (!alpha_got_frame) {\n            av_frame_free(&s->alpha_frame);\n            return AVERROR_INVALIDDATA;\n        }\n\n        /* copy green component of alpha image to alpha plane of primary image */\n        for (y = 0; y < s->height; y++) {\n            ap = GET_PIXEL(s->alpha_frame, 0, y) + 2;\n            pp = p->data[3] + p->linesize[3] * y;\n            for (x = 0; x < s->width; x++) {\n                *pp = *ap;\n                pp++;\n                ap += 4;\n            }\n        }\n        av_frame_free(&s->alpha_frame);\n    }\n\n    /* apply alpha filtering */\n    if (s->alpha_filter)\n        alpha_inverse_prediction(p, s->alpha_filter);\n\n    return 0;\n}\n\nstatic int vp8_lossy_decode_frame(AVCodecContext *avctx, AVFrame *p,\n                                  int *got_frame, uint8_t *data_start,\n                                  unsigned int data_size)\n{\n    WebPContext *s = avctx->priv_data;\n    AVPacket pkt;\n    int ret;\n\n    if (!s->initialized) {\n        ff_vp8_decode_init(avctx);\n        s->initialized = 1;\n    }\n    avctx->pix_fmt = s->has_alpha ? AV_PIX_FMT_YUVA420P : AV_PIX_FMT_YUV420P;\n    s->lossless = 0;\n\n    if (data_size > INT_MAX) {\n        av_log(avctx, AV_LOG_ERROR, \"unsupported chunk size\\n\");\n        return AVERROR_PATCHWELCOME;\n    }\n\n    av_init_packet(&pkt);\n    pkt.data = data_start;\n    pkt.size = data_size;\n\n    ret = ff_vp8_decode_frame(avctx, p, got_frame, &pkt);\n    if (ret < 0)\n        return ret;\n\n    update_canvas_size(avctx, avctx->width, avctx->height);\n\n    if (s->has_alpha) {\n        ret = vp8_lossy_decode_alpha(avctx, p, s->alpha_data,\n                                     s->alpha_data_size);\n        if (ret < 0)\n            return ret;\n    }\n    return ret;\n}\n\nstatic int webp_decode_frame(AVCodecContext *avctx, void *data, int *got_frame,\n                             AVPacket *avpkt)\n{\n    AVFrame * const p = data;\n    WebPContext *s = avctx->priv_data;\n    GetByteContext gb;\n    int ret;\n    uint32_t chunk_type, chunk_size;\n    int vp8x_flags = 0;\n\n    s->avctx     = avctx;\n    s->width     = 0;\n    s->height    = 0;\n    *got_frame   = 0;\n    s->has_alpha = 0;\n    s->has_exif  = 0;\n    bytestream2_init(&gb, avpkt->data, avpkt->size);\n\n    if (bytestream2_get_bytes_left(&gb) < 12)\n        return AVERROR_INVALIDDATA;\n\n    if (bytestream2_get_le32(&gb) != MKTAG('R', 'I', 'F', 'F')) {\n        av_log(avctx, AV_LOG_ERROR, \"missing RIFF tag\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    chunk_size = bytestream2_get_le32(&gb);\n    if (bytestream2_get_bytes_left(&gb) < chunk_size)\n        return AVERROR_INVALIDDATA;\n\n    if (bytestream2_get_le32(&gb) != MKTAG('W', 'E', 'B', 'P')) {\n        av_log(avctx, AV_LOG_ERROR, \"missing WEBP tag\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    while (bytestream2_get_bytes_left(&gb) > 8) {\n        char chunk_str[5] = { 0 };\n\n        chunk_type = bytestream2_get_le32(&gb);\n        chunk_size = bytestream2_get_le32(&gb);\n        if (chunk_size == UINT32_MAX)\n            return AVERROR_INVALIDDATA;\n        chunk_size += chunk_size & 1;\n\n        if (bytestream2_get_bytes_left(&gb) < chunk_size)\n            return AVERROR_INVALIDDATA;\n\n        switch (chunk_type) {\n        case MKTAG('V', 'P', '8', ' '):\n            if (!*got_frame) {\n                ret = vp8_lossy_decode_frame(avctx, p, got_frame,\n                                             avpkt->data + bytestream2_tell(&gb),\n                                             chunk_size);\n                if (ret < 0)\n                    return ret;\n            }\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        case MKTAG('V', 'P', '8', 'L'):\n            if (!*got_frame) {\n                ret = vp8_lossless_decode_frame(avctx, p, got_frame,\n                                                avpkt->data + bytestream2_tell(&gb),\n                                                chunk_size, 0);\n                if (ret < 0)\n                    return ret;\n                avctx->properties |= FF_CODEC_PROPERTY_LOSSLESS;\n            }\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        case MKTAG('V', 'P', '8', 'X'):\n            if (s->width || s->height || *got_frame) {\n                av_log(avctx, AV_LOG_ERROR, \"Canvas dimensions are already set\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            vp8x_flags = bytestream2_get_byte(&gb);\n            bytestream2_skip(&gb, 3);\n            s->width  = bytestream2_get_le24(&gb) + 1;\n            s->height = bytestream2_get_le24(&gb) + 1;\n            ret = av_image_check_size(s->width, s->height, 0, avctx);\n            if (ret < 0)\n                return ret;\n            break;\n        case MKTAG('A', 'L', 'P', 'H'): {\n            int alpha_header, filter_m, compression;\n\n            if (!(vp8x_flags & VP8X_FLAG_ALPHA)) {\n                av_log(avctx, AV_LOG_WARNING,\n                       \"ALPHA chunk present, but alpha bit not set in the \"\n                       \"VP8X header\\n\");\n            }\n            if (chunk_size == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"invalid ALPHA chunk size\\n\");\n                return AVERROR_INVALIDDATA;\n            }\n            alpha_header       = bytestream2_get_byte(&gb);\n            s->alpha_data      = avpkt->data + bytestream2_tell(&gb);\n            s->alpha_data_size = chunk_size - 1;\n            bytestream2_skip(&gb, s->alpha_data_size);\n\n            filter_m    = (alpha_header >> 2) & 0x03;\n            compression =  alpha_header       & 0x03;\n\n            if (compression > ALPHA_COMPRESSION_VP8L) {\n                av_log(avctx, AV_LOG_VERBOSE,\n                       \"skipping unsupported ALPHA chunk\\n\");\n            } else {\n                s->has_alpha         = 1;\n                s->alpha_compression = compression;\n                s->alpha_filter      = filter_m;\n            }\n\n            break;\n        }\n        case MKTAG('E', 'X', 'I', 'F'): {\n            int le, ifd_offset, exif_offset = bytestream2_tell(&gb);\n            AVDictionary *exif_metadata = NULL;\n            GetByteContext exif_gb;\n\n            if (s->has_exif) {\n                av_log(avctx, AV_LOG_VERBOSE, \"Ignoring extra EXIF chunk\\n\");\n                goto exif_end;\n            }\n            if (!(vp8x_flags & VP8X_FLAG_EXIF_METADATA))\n                av_log(avctx, AV_LOG_WARNING,\n                       \"EXIF chunk present, but Exif bit not set in the \"\n                       \"VP8X header\\n\");\n\n            s->has_exif = 1;\n            bytestream2_init(&exif_gb, avpkt->data + exif_offset,\n                             avpkt->size - exif_offset);\n            if (ff_tdecode_header(&exif_gb, &le, &ifd_offset) < 0) {\n                av_log(avctx, AV_LOG_ERROR, \"invalid TIFF header \"\n                       \"in Exif data\\n\");\n                goto exif_end;\n            }\n\n            bytestream2_seek(&exif_gb, ifd_offset, SEEK_SET);\n            if (avpriv_exif_decode_ifd(avctx, &exif_gb, le, 0, &exif_metadata) < 0) {\n                av_log(avctx, AV_LOG_ERROR, \"error decoding Exif data\\n\");\n                goto exif_end;\n            }\n\n            av_dict_copy(&((AVFrame *) data)->metadata, exif_metadata, 0);\n\nexif_end:\n            av_dict_free(&exif_metadata);\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        }\n        case MKTAG('I', 'C', 'C', 'P'):\n        case MKTAG('A', 'N', 'I', 'M'):\n        case MKTAG('A', 'N', 'M', 'F'):\n        case MKTAG('X', 'M', 'P', ' '):\n            AV_WL32(chunk_str, chunk_type);\n            av_log(avctx, AV_LOG_WARNING, \"skipping unsupported chunk: %s\\n\",\n                   chunk_str);\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        default:\n            AV_WL32(chunk_str, chunk_type);\n            av_log(avctx, AV_LOG_VERBOSE, \"skipping unknown chunk: %s\\n\",\n                   chunk_str);\n            bytestream2_skip(&gb, chunk_size);\n            break;\n        }\n    }\n\n    if (!*got_frame) {\n        av_log(avctx, AV_LOG_ERROR, \"image data not found\\n\");\n        return AVERROR_INVALIDDATA;\n    }\n\n    return avpkt->size;\n}\n\nstatic av_cold int webp_decode_close(AVCodecContext *avctx)\n{\n    WebPContext *s = avctx->priv_data;\n\n    if (s->initialized)\n        return ff_vp8_decode_free(avctx);\n\n    return 0;\n}\n\nAVCodec ff_webp_decoder = {\n    .name           = \"webp\",\n    .long_name      = NULL_IF_CONFIG_SMALL(\"WebP image\"),\n    .type           = AVMEDIA_TYPE_VIDEO,\n    .id             = AV_CODEC_ID_WEBP,\n    .priv_data_size = sizeof(WebPContext),\n    .decode         = webp_decode_frame,\n    .close          = webp_decode_close,\n    .capabilities   = AV_CODEC_CAP_DR1 | AV_CODEC_CAP_FRAME_THREADS,\n};\n"], "filenames": ["libavcodec/vp8.c", "libavcodec/webp.c"], "buggy_code_start_loc": [2552, 1337], "buggy_code_end_loc": [2552, 1340], "fixing_code_start_loc": [2553, 1337], "fixing_code_end_loc": [2555, 1339], "type": "CWE-119", "message": "libavcodec/webp.c in FFmpeg before 2.8.12, 3.0.x before 3.0.8, 3.1.x before 3.1.8, 3.2.x before 3.2.5, and 3.3.x before 3.3.1 does not ensure that pix_fmt is set, which allows remote attackers to cause a denial of service (heap-based buffer overflow and application crash) or possibly have unspecified other impact via a crafted file, related to the vp8_decode_mb_row_no_filter and pred8x8_128_dc_8_c functions.", "other": {"cve": {"id": "CVE-2017-9994", "sourceIdentifier": "cve@mitre.org", "published": "2017-06-28T06:29:00.550", "lastModified": "2019-03-20T16:18:40.383", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "libavcodec/webp.c in FFmpeg before 2.8.12, 3.0.x before 3.0.8, 3.1.x before 3.1.8, 3.2.x before 3.2.5, and 3.3.x before 3.3.1 does not ensure that pix_fmt is set, which allows remote attackers to cause a denial of service (heap-based buffer overflow and application crash) or possibly have unspecified other impact via a crafted file, related to the vp8_decode_mb_row_no_filter and pred8x8_128_dc_8_c functions."}, {"lang": "es", "value": "El archivo libavcodec/webp.c en Ffmpeg en sus versiones anteriores a 2.8.12, 3.0.x en sus versiones anteriores a la 3.0.8, 3.1.x en sus versiones anteriores a la 3.1.8, 3.2.x en sus versiones anteriores a la 3.2.5, y 3.3.x en sus versiones anteriores a la 3.3.1 no asegura que pix_dmt sea puesto, lo que permite a un atacante remoto provocar una denegaci\u00f3n de servicio (buffer overflow en la memoria din\u00e1mica -heap- y ca\u00edda de la aplicaci\u00f3n) u otro posible impacto no especificado mediante la manipulaci\u00f3n del archivo, relacionado a las funciones vp8_decode_mb_row_no_filter y pred8x8_128_dc_8_c."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:L/AC:L/PR:N/UI:R/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": true}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-119"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionEndExcluding": "2.8.12", "matchCriteriaId": "941B47E5-FDBB-437A-8A4D-A9788019E5EC"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.0", "versionEndExcluding": "3.0.8", "matchCriteriaId": "23E6910A-C467-44FD-B9CA-3D6049AFB1BF"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.1", "versionEndExcluding": "3.1.8", "matchCriteriaId": "58FFC631-648C-44BE-9EE5-CF3210E632C0"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.2", "versionEndExcluding": "3.2.5", "matchCriteriaId": "248F96A2-0FAF-4737-8011-3ACAC8115829"}, {"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.3", "versionEndExcluding": "3.3.1", "matchCriteriaId": "F0E75E33-237A-43F9-9193-002687E3470D"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}]}]}], "references": [{"url": "http://www.securityfocus.com/bid/99317", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=1434", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=1435", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Third Party Advisory"]}, {"url": "https://github.com/FFmpeg/FFmpeg/commit/6b5d3fb26fb4be48e4966e4b1d97c2165538d4ef", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2019/01/msg00006.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/FFmpeg/FFmpeg/commit/6b5d3fb26fb4be48e4966e4b1d97c2165538d4ef"}}
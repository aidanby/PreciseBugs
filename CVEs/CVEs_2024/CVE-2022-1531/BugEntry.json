{"buggy_code": ["import sqlite3\nimport re\nimport timeit\nimport sys\nimport os\n\npathlist = os.path.realpath(__file__).split(os.path.sep)\nRTXindex = pathlist.index(\"RTX\")\nsys.path.append(os.path.sep.join([*pathlist[:(RTXindex + 1)], 'code']))\nfrom RTXConfiguration import RTXConfiguration\n\nRTXConfig = RTXConfiguration()\nautocomplete_filepath = os.path.sep.join([*pathlist[:(RTXindex + 1)], 'code', 'autocomplete'])\n\n\nconn = None\ncursor = None\n\n\ndef load():\n    global conn\n    global cursor\n    database_name = f\"{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}\"\n    conn = sqlite3.connect(database_name)\n    cursor = conn.cursor()\n    return True\n\n\ndef get_nodes_like(word,requested_limit):\n\n    debug = False\n\n    t0 = timeit.default_timer()\n    requested_limit = int(requested_limit)\n\n    values = []\n    n_values = 0\n\n    if len(word) < 2:\n        return values\n\n    floor = word[:-1]\n    ceiling = floor + 'zz'\n\n    #### Get a list of matching node names that begin with these letters\n    if debug:\n        print(f\"INFO: Query 1\")\n    #cursor.execute(\"SELECT term FROM term WHERE term LIKE \\\"%s%%\\\" ORDER BY length(term),term LIMIT %s\" % (word,1000))\n    cursor.execute(f\"SELECT term FROM terms WHERE term > \\\"{floor}\\\" AND term < \\\"{ceiling}\\\" AND term LIKE \\\"{word}%%\\\" ORDER BY length(term),term LIMIT {requested_limit}\")\n    rows = cursor.fetchall()\n    values_dict = {}\n    for row in rows:\n        term = row[0]\n        if term.upper() not in values_dict:\n            if debug:\n                print(f\"    - {term}\")\n            properties = { \"curie\": '??', \"name\": term, \"type\": '??' }\n            values.append(properties)\n            values_dict[term.upper()] = 1\n            n_values += 1\n            if n_values >= requested_limit:\n                break\n    t1 = timeit.default_timer()\n    if debug:\n        print(f\"INFO: Query 1 in {t1-t0} sec\")\n\n    #### If we haven't reached the limit yet, add a list of matching terms that contain this string\n    if n_values < requested_limit:\n        if debug:\n            print(f\"INFO: Query 2\")\n\n        #### See if there is a cached entry already\n        word_part = word\n        found_fragment = None\n        while len(word_part) > 2:\n            cursor.execute(f\"SELECT rowid, fragment FROM cached_fragments WHERE fragment == \\\"{word_part}\\\"\")\n            rows = cursor.fetchall()\n            if len(rows) > 0:\n                fragment_id = rows[0][0]\n                found_fragment = rows[0][1]\n                break\n            word_part = word_part[:-1]\n\n        if found_fragment:\n            if debug:\n                print(f\"Found matching fragment {found_fragment} as fragment_id {fragment_id}\")\n\n            cursor.execute(f\"SELECT term FROM cached_fragment_terms WHERE fragment_id = {fragment_id} AND term LIKE \\\"%%{word}%%\\\"\")\n            rows = cursor.fetchall()\n\n            for row in rows:\n                term = row[0]\n                if term.upper() not in values_dict:\n\n                    if n_values < requested_limit:\n                        if debug:\n                            print(f\"    - {term}\")\n                        properties = { \"curie\": '??', \"name\": term, \"type\": '??' }\n                        values.append(properties)\n                        n_values += 1\n\n\n        if found_fragment is None:\n\n            #### Cache this fragment in the database\n            cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))\n            fragment_id = cursor.lastrowid\n            if debug:\n                print(f\"fragment_id = {fragment_id}\")\n\n            #### Execute an expensive LIKE query\n            cursor.execute(\"SELECT term FROM terms WHERE term LIKE \\\"%%%s%%\\\" ORDER BY length(term),term LIMIT %s\" % (word,10000))\n            rows = cursor.fetchall()\n\n            for row in rows:\n                term = row[0]\n                if term.upper() not in values_dict:\n\n                    if n_values < requested_limit:\n                        if debug:\n                            print(f\"    - {term}\")\n                        properties = { \"curie\": '??', \"name\": term, \"type\": '??' }\n                        values.append(properties)\n                        n_values += 1\n\n                    values_dict[term.upper()] = 1\n                    cursor.execute(\"INSERT INTO cached_fragment_terms(fragment_id, term) VALUES(?,?)\", (fragment_id, term,))\n            conn.commit()\n\n        t2 = timeit.default_timer()\n        if debug:\n            print(f\"INFO: Query 2 in {t2-t1} sec\")\n\n\n    return(values)\n\n"], "fixing_code": ["import sqlite3\nimport re\nimport timeit\nimport sys\nimport os\n\npathlist = os.path.realpath(__file__).split(os.path.sep)\nRTXindex = pathlist.index(\"RTX\")\nsys.path.append(os.path.sep.join([*pathlist[:(RTXindex + 1)], 'code']))\nfrom RTXConfiguration import RTXConfiguration\n\nRTXConfig = RTXConfiguration()\nautocomplete_filepath = os.path.sep.join([*pathlist[:(RTXindex + 1)], 'code', 'autocomplete'])\n\n\nconn = None\ncursor = None\n\n\ndef load():\n    global conn\n    global cursor\n    database_name = f\"{autocomplete_filepath}{os.path.sep}{RTXConfig.autocomplete_path.split('/')[-1]}\"\n    conn = sqlite3.connect(database_name)\n    cursor = conn.cursor()\n    #print(f\"INFO: Connected to {database_name}\",file=sys.stderr)\n    return True\n\n\ndef get_nodes_like(word,requested_limit):\n\n    debug = False\n\n    t0 = timeit.default_timer()\n    requested_limit = int(requested_limit)\n\n    values = []\n    n_values = 0\n\n    if len(word) < 2:\n        return values\n\n    #### Try to avoid SQL injection exploits by sanitizing input #1823\n    word = word.replace('\"','')\n\n    floor = word[:-1]\n    ceiling = floor + 'zz'\n\n    #### Get a list of matching node names that begin with these letters\n    if debug:\n        print(f\"INFO: Query 1\")\n    #cursor.execute(\"SELECT term FROM term WHERE term LIKE \\\"%s%%\\\" ORDER BY length(term),term LIMIT %s\" % (word,1000))\n    cursor.execute(f\"SELECT term FROM terms WHERE term > \\\"{floor}\\\" AND term < \\\"{ceiling}\\\" AND term LIKE \\\"{word}%%\\\" ORDER BY length(term),term LIMIT {requested_limit}\")\n    rows = cursor.fetchall()\n    values_dict = {}\n    for row in rows:\n        term = row[0]\n        if term.upper() not in values_dict:\n            if debug:\n                print(f\"    - {term}\")\n            properties = { \"curie\": '??', \"name\": term, \"type\": '??' }\n            values.append(properties)\n            values_dict[term.upper()] = 1\n            n_values += 1\n            if n_values >= requested_limit:\n                break\n    t1 = timeit.default_timer()\n    if debug:\n        print(f\"INFO: Query 1 in {t1-t0} sec\")\n\n    #### If we haven't reached the limit yet, add a list of matching terms that contain this string\n    if n_values < requested_limit:\n        if debug:\n            print(f\"INFO: Query 2\")\n\n        #### See if there is a cached entry already\n        word_part = word\n        found_fragment = None\n        while len(word_part) > 2:\n            cursor.execute(f\"SELECT rowid, fragment FROM cached_fragments WHERE fragment == \\\"{word_part}\\\"\")\n            rows = cursor.fetchall()\n            if len(rows) > 0:\n                fragment_id = rows[0][0]\n                found_fragment = rows[0][1]\n                break\n            word_part = word_part[:-1]\n\n        if found_fragment:\n            if debug:\n                print(f\"Found matching fragment {found_fragment} as fragment_id {fragment_id}\")\n\n            cursor.execute(f\"SELECT term FROM cached_fragment_terms WHERE fragment_id = {fragment_id} AND term LIKE \\\"%%{word}%%\\\"\")\n            rows = cursor.fetchall()\n\n            for row in rows:\n                term = row[0]\n                if term.upper() not in values_dict:\n\n                    if n_values < requested_limit:\n                        if debug:\n                            print(f\"    - {term}\")\n                        properties = { \"curie\": '??', \"name\": term, \"type\": '??' }\n                        values.append(properties)\n                        n_values += 1\n\n\n        if found_fragment is None:\n\n            #### Cache this fragment in the database\n            try:\n                cursor.execute(\"INSERT INTO cached_fragments(fragment) VALUES(?)\", (word,))\n                fragment_id = cursor.lastrowid\n            except:\n                print(f\"ERROR: Unable to INSERT into cached_fragments(fragment)\",file=sys.stderr)\n                fragment_id = 0\n            if debug:\n                print(f\"fragment_id = {fragment_id}\")\n\n            #### Execute an expensive LIKE query\n            cursor.execute(\"SELECT term FROM terms WHERE term LIKE \\\"%%%s%%\\\" ORDER BY length(term),term LIMIT %s\" % (word,10000))\n            rows = cursor.fetchall()\n\n            for row in rows:\n                term = row[0]\n                if term.upper() not in values_dict:\n\n                    if n_values < requested_limit:\n                        if debug:\n                            print(f\"    - {term}\")\n                        properties = { \"curie\": '??', \"name\": term, \"type\": '??' }\n                        values.append(properties)\n                        n_values += 1\n\n                    values_dict[term.upper()] = 1\n                    cursor.execute(\"INSERT INTO cached_fragment_terms(fragment_id, term) VALUES(?,?)\", (fragment_id, term,))\n            conn.commit()\n\n        t2 = timeit.default_timer()\n        if debug:\n            print(f\"INFO: Query 2 in {t2-t1} sec\")\n\n\n    return(values)\n\n"], "filenames": ["code/autocomplete/rtxcomplete.py"], "buggy_code_start_loc": [25], "buggy_code_end_loc": [108], "fixing_code_start_loc": [26], "fixing_code_end_loc": [116], "type": "CWE-89", "message": "SQL injection vulnerability in ARAX-UI Synonym Lookup functionality in GitHub repository rtxteam/rtx prior to checkpoint_2022-04-20 . This vulnerability is critical as it can lead to remote code execution and thus complete server takeover.", "other": {"cve": {"id": "CVE-2022-1531", "sourceIdentifier": "security@huntr.dev", "published": "2022-04-29T09:15:08.903", "lastModified": "2023-03-07T22:36:04.080", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "SQL injection vulnerability in ARAX-UI Synonym Lookup functionality in GitHub repository rtxteam/rtx prior to checkpoint_2022-04-20 . This vulnerability is critical as it can lead to remote code execution and thus complete server takeover."}, {"lang": "es", "value": "Una vulnerabilidad de inyecci\u00f3n SQL en la funcionalidad Synonym Lookup de ARAX-UI en el repositorio de GitHub rtxteam/rtx versiones anteriores a checkpoint_2022-04-20 . Esta vulnerabilidad es cr\u00edtica ya que puede conllevar a una ejecuci\u00f3n de c\u00f3digo remota y por tanto la toma completa del servidor"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:C/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "CHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 10.0, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 6.0}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 10.0}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-89"}]}, {"source": "security@huntr.dev", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-89"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:rtx_project:rtx:*:*:*:*:*:*:*:*", "versionEndExcluding": "2022-04-20", "matchCriteriaId": "E1D825FE-F5D4-4BF1-A9F6-6DA86CB32E65"}]}]}], "references": [{"url": "https://github.com/rtxteam/rtx/commit/fa2797e656e3dba18f990a2db1f0f029d41f1921", "source": "security@huntr.dev", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://huntr.dev/bounties/fc4eb544-ef1e-412d-9fdb-0ceb04e038fe", "source": "security@huntr.dev", "tags": ["Exploit", "Issue Tracking", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/rtxteam/rtx/commit/fa2797e656e3dba18f990a2db1f0f029d41f1921"}}
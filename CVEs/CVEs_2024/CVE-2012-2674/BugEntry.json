{"buggy_code": ["/*\n * Copyright (C) 2008 The Android Open Source Project\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in\n *    the documentation and/or other materials provided with the\n *    distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n * COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS\n * OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED\n * AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT\n * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n#include <errno.h>\n#include <pthread.h>\n#include <stdio.h>\n#include <arpa/inet.h>\n#include <sys/socket.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <errno.h>\n#include <stddef.h>\n#include <stdarg.h>\n#include <fcntl.h>\n#include <unwind.h>\n#include <dlfcn.h>\n\n#include <sys/socket.h>\n#include <sys/un.h>\n#include <sys/select.h>\n#include <sys/types.h>\n#include <sys/system_properties.h>\n\n#include \"dlmalloc.h\"\n#include \"logd.h\"\n#include \"malloc_debug_common.h\"\n\n// This file should be included into the build only when\n// MALLOC_LEAK_CHECK, or MALLOC_QEMU_INSTRUMENT, or both\n// macros are defined.\n#ifndef MALLOC_LEAK_CHECK\n#error MALLOC_LEAK_CHECK is not defined.\n#endif  // !MALLOC_LEAK_CHECK\n\n// Global variables defined in malloc_debug_common.c\nextern int gMallocLeakZygoteChild;\nextern pthread_mutex_t gAllocationsMutex;\nextern HashTable gHashTable;\nextern const MallocDebug __libc_malloc_default_dispatch;\nextern const MallocDebug* __libc_malloc_dispatch;\n\n// =============================================================================\n// log functions\n// =============================================================================\n\n#define debug_log(format, ...)  \\\n    __libc_android_log_print(ANDROID_LOG_DEBUG, \"malloc_leak_check\", (format), ##__VA_ARGS__ )\n#define error_log(format, ...)  \\\n    __libc_android_log_print(ANDROID_LOG_ERROR, \"malloc_leak_check\", (format), ##__VA_ARGS__ )\n#define info_log(format, ...)  \\\n    __libc_android_log_print(ANDROID_LOG_INFO, \"malloc_leak_check\", (format), ##__VA_ARGS__ )\n\nstatic int gTrapOnError = 1;\n\n#define MALLOC_ALIGNMENT    8\n#define GUARD               0x48151642\n#define DEBUG               0\n\n// =============================================================================\n// Structures\n// =============================================================================\ntypedef struct AllocationEntry AllocationEntry;\nstruct AllocationEntry {\n    HashEntry* entry;\n    uint32_t guard;\n};\n\n\n// =============================================================================\n// Hash Table functions\n// =============================================================================\nstatic uint32_t get_hash(intptr_t* backtrace, size_t numEntries)\n{\n    if (backtrace == NULL) return 0;\n\n    int hash = 0;\n    size_t i;\n    for (i = 0 ; i < numEntries ; i++) {\n        hash = (hash * 33) + (backtrace[i] >> 2);\n    }\n\n    return hash;\n}\n\nstatic HashEntry* find_entry(HashTable* table, int slot,\n        intptr_t* backtrace, size_t numEntries, size_t size)\n{\n    HashEntry* entry = table->slots[slot];\n    while (entry != NULL) {\n        //debug_log(\"backtrace: %p, entry: %p entry->backtrace: %p\\n\",\n        //        backtrace, entry, (entry != NULL) ? entry->backtrace : NULL);\n        /*\n         * See if the entry matches exactly.  We compare the \"size\" field,\n         * including the flag bits.\n         */\n        if (entry->size == size && entry->numEntries == numEntries &&\n                !memcmp(backtrace, entry->backtrace, numEntries * sizeof(intptr_t))) {\n            return entry;\n        }\n\n        entry = entry->next;\n    }\n\n    return NULL;\n}\n\nstatic HashEntry* record_backtrace(intptr_t* backtrace, size_t numEntries, size_t size)\n{\n    size_t hash = get_hash(backtrace, numEntries);\n    size_t slot = hash % HASHTABLE_SIZE;\n\n    if (size & SIZE_FLAG_MASK) {\n        debug_log(\"malloc_debug: allocation %zx exceeds bit width\\n\", size);\n        abort();\n    }\n\n    if (gMallocLeakZygoteChild)\n        size |= SIZE_FLAG_ZYGOTE_CHILD;\n\n    HashEntry* entry = find_entry(&gHashTable, slot, backtrace, numEntries, size);\n\n    if (entry != NULL) {\n        entry->allocations++;\n    } else {\n        // create a new entry\n        entry = (HashEntry*)dlmalloc(sizeof(HashEntry) + numEntries*sizeof(intptr_t));\n        if (!entry)\n            return NULL;\n        entry->allocations = 1;\n        entry->slot = slot;\n        entry->prev = NULL;\n        entry->next = gHashTable.slots[slot];\n        entry->numEntries = numEntries;\n        entry->size = size;\n\n        memcpy(entry->backtrace, backtrace, numEntries * sizeof(intptr_t));\n\n        gHashTable.slots[slot] = entry;\n\n        if (entry->next != NULL) {\n            entry->next->prev = entry;\n        }\n\n        // we just added an entry, increase the size of the hashtable\n        gHashTable.count++;\n    }\n\n    return entry;\n}\n\nstatic int is_valid_entry(HashEntry* entry)\n{\n    if (entry != NULL) {\n        int i;\n        for (i = 0 ; i < HASHTABLE_SIZE ; i++) {\n            HashEntry* e1 = gHashTable.slots[i];\n\n            while (e1 != NULL) {\n                if (e1 == entry) {\n                    return 1;\n                }\n\n                e1 = e1->next;\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic void remove_entry(HashEntry* entry)\n{\n    HashEntry* prev = entry->prev;\n    HashEntry* next = entry->next;\n\n    if (prev != NULL) entry->prev->next = next;\n    if (next != NULL) entry->next->prev = prev;\n\n    if (prev == NULL) {\n        // we are the head of the list. set the head to be next\n        gHashTable.slots[entry->slot] = entry->next;\n    }\n\n    // we just removed and entry, decrease the size of the hashtable\n    gHashTable.count--;\n}\n\n\n// =============================================================================\n// stack trace functions\n// =============================================================================\n\ntypedef struct\n{\n    size_t count;\n    intptr_t* addrs;\n} stack_crawl_state_t;\n\n\n/* depends how the system includes define this */\n#ifdef HAVE_UNWIND_CONTEXT_STRUCT\ntypedef struct _Unwind_Context __unwind_context;\n#else\ntypedef _Unwind_Context __unwind_context;\n#endif\n\nstatic _Unwind_Reason_Code trace_function(__unwind_context *context, void *arg)\n{\n    stack_crawl_state_t* state = (stack_crawl_state_t*)arg;\n    if (state->count) {\n        intptr_t ip = (intptr_t)_Unwind_GetIP(context);\n        if (ip) {\n            state->addrs[0] = ip;\n            state->addrs++;\n            state->count--;\n            return _URC_NO_REASON;\n        }\n    }\n    /*\n     * If we run out of space to record the address or 0 has been seen, stop\n     * unwinding the stack.\n     */\n    return _URC_END_OF_STACK;\n}\n\nstatic inline\nint get_backtrace(intptr_t* addrs, size_t max_entries)\n{\n    stack_crawl_state_t state;\n    state.count = max_entries;\n    state.addrs = (intptr_t*)addrs;\n    _Unwind_Backtrace(trace_function, (void*)&state);\n    return max_entries - state.count;\n}\n\n// =============================================================================\n// malloc check functions\n// =============================================================================\n\n#define CHK_FILL_FREE           0xef\n#define CHK_SENTINEL_VALUE      (char)0xeb\n#define CHK_SENTINEL_HEAD_SIZE  16\n#define CHK_SENTINEL_TAIL_SIZE  16\n#define CHK_OVERHEAD_SIZE       (   CHK_SENTINEL_HEAD_SIZE +    \\\n                                    CHK_SENTINEL_TAIL_SIZE +    \\\n                                    sizeof(size_t) )\n\nstatic void dump_stack_trace()\n{\n    intptr_t addrs[20];\n    int c = get_backtrace(addrs, 20);\n    char buf[16];\n    char tmp[16*20];\n    int i;\n\n    tmp[0] = 0; // Need to initialize tmp[0] for the first strcat\n    for (i=0 ; i<c; i++) {\n        snprintf(buf, sizeof buf, \"%2d: %08x\\n\", i, addrs[i]);\n        strlcat(tmp, buf, sizeof tmp);\n    }\n    __libc_android_log_print(ANDROID_LOG_ERROR, \"libc\", \"call stack:\\n%s\", tmp);\n}\n\nstatic int is_valid_malloc_pointer(void* addr)\n{\n    return 1;\n}\n\nstatic void assert_log_message(const char* format, ...)\n{\n    va_list  args;\n\n    pthread_mutex_lock(&gAllocationsMutex);\n    {\n        const MallocDebug* current_dispatch = __libc_malloc_dispatch;\n        __libc_malloc_dispatch = &__libc_malloc_default_dispatch;\n        va_start(args, format);\n        __libc_android_log_vprint(ANDROID_LOG_ERROR, \"libc\",\n                                format, args);\n        va_end(args);\n        dump_stack_trace();\n        if (gTrapOnError) {\n            __builtin_trap();\n        }\n        __libc_malloc_dispatch = current_dispatch;\n    }\n    pthread_mutex_unlock(&gAllocationsMutex);\n}\n\nstatic void assert_valid_malloc_pointer(void* mem)\n{\n    if (mem && !is_valid_malloc_pointer(mem)) {\n        assert_log_message(\n            \"*** MALLOC CHECK: buffer %p, is not a valid \"\n            \"malloc pointer (are you mixing up new/delete \"\n            \"and malloc/free?)\", mem);\n    }\n}\n\n/* Check that a given address corresponds to a guarded block,\n * and returns its original allocation size in '*allocated'.\n * 'func' is the capitalized name of the caller function.\n * Returns 0 on success, or -1 on failure.\n * NOTE: Does not return if gTrapOnError is set.\n */\nstatic int chk_mem_check(void*       mem,\n                         size_t*     allocated,\n                         const char* func)\n{\n    char*  buffer;\n    size_t offset, bytes;\n    int    i;\n    char*  buf;\n\n    /* first check the bytes in the sentinel header */\n    buf = (char*)mem - CHK_SENTINEL_HEAD_SIZE;\n    for (i=0 ; i<CHK_SENTINEL_HEAD_SIZE ; i++) {\n        if (buf[i] != CHK_SENTINEL_VALUE) {\n            assert_log_message(\n                \"*** %s CHECK: buffer %p \"\n                \"corrupted %d bytes before allocation\",\n                func, mem, CHK_SENTINEL_HEAD_SIZE-i);\n            return -1;\n        }\n    }\n\n    /* then the ones in the sentinel trailer */\n    buffer = (char*)mem - CHK_SENTINEL_HEAD_SIZE;\n    offset = dlmalloc_usable_size(buffer) - sizeof(size_t);\n    bytes  = *(size_t *)(buffer + offset);\n\n    buf = (char*)mem + bytes;\n    for (i=CHK_SENTINEL_TAIL_SIZE-1 ; i>=0 ; i--) {\n        if (buf[i] != CHK_SENTINEL_VALUE) {\n            assert_log_message(\n                \"*** %s CHECK: buffer %p, size=%lu, \"\n                \"corrupted %d bytes after allocation\",\n                func, buffer, bytes, i+1);\n            return -1;\n        }\n    }\n\n    *allocated = bytes;\n    return 0;\n}\n\n\nvoid* chk_malloc(size_t bytes)\n{\n    char* buffer = (char*)dlmalloc(bytes + CHK_OVERHEAD_SIZE);\n    if (buffer) {\n        memset(buffer, CHK_SENTINEL_VALUE, bytes + CHK_OVERHEAD_SIZE);\n        size_t offset = dlmalloc_usable_size(buffer) - sizeof(size_t);\n        *(size_t *)(buffer + offset) = bytes;\n        buffer += CHK_SENTINEL_HEAD_SIZE;\n    }\n    return buffer;\n}\n\nvoid  chk_free(void* mem)\n{\n    assert_valid_malloc_pointer(mem);\n    if (mem) {\n        size_t  size;\n        char*   buffer;\n\n        if (chk_mem_check(mem, &size, \"FREE\") == 0) {\n            buffer = (char*)mem - CHK_SENTINEL_HEAD_SIZE;\n            memset(buffer, CHK_FILL_FREE, size + CHK_OVERHEAD_SIZE);\n            dlfree(buffer);\n        }\n    }\n}\n\nvoid* chk_calloc(size_t n_elements, size_t elem_size)\n{\n    size_t  size;\n    void*   ptr;\n\n    /* Fail on overflow - just to be safe even though this code runs only\n     * within the debugging C library, not the production one */\n    if (n_elements && MAX_SIZE_T / n_elements < elem_size) {\n        return NULL;\n    }\n    size = n_elements * elem_size;\n    ptr  = chk_malloc(size);\n    if (ptr != NULL) {\n        memset(ptr, 0, size);\n    }\n    return ptr;\n}\n\nvoid* chk_realloc(void* mem, size_t bytes)\n{\n    char*   buffer;\n    int     ret;\n    size_t  old_bytes = 0;\n\n    assert_valid_malloc_pointer(mem);\n\n    if (mem != NULL && chk_mem_check(mem, &old_bytes, \"REALLOC\") < 0)\n        return NULL;\n\n    char* new_buffer = chk_malloc(bytes);\n    if (mem == NULL) {\n        return new_buffer;\n    }\n\n    if (new_buffer) {\n        if (bytes > old_bytes)\n            bytes = old_bytes;\n        memcpy(new_buffer, mem, bytes);\n        chk_free(mem);\n    }\n\n    return new_buffer;\n}\n\nvoid* chk_memalign(size_t alignment, size_t bytes)\n{\n    // XXX: it's better to use malloc, than being wrong\n    return chk_malloc(bytes);\n}\n\n// =============================================================================\n// malloc fill functions\n// =============================================================================\n\nvoid* fill_malloc(size_t bytes)\n{\n    void* buffer = dlmalloc(bytes);\n    if (buffer) {\n        memset(buffer, CHK_SENTINEL_VALUE, bytes);\n    }\n    return buffer;\n}\n\nvoid  fill_free(void* mem)\n{\n    size_t bytes = dlmalloc_usable_size(mem);\n    memset(mem, CHK_FILL_FREE, bytes);\n    dlfree(mem);\n}\n\nvoid* fill_realloc(void* mem, size_t bytes)\n{\n    void* buffer = fill_malloc(bytes);\n    if (mem == NULL) {\n        return buffer;\n    }\n    if (buffer) {\n        size_t old_size = dlmalloc_usable_size(mem);\n        size_t size = (bytes < old_size)?(bytes):(old_size);\n        memcpy(buffer, mem, size);\n        fill_free(mem);\n    }\n    return buffer;\n}\n\nvoid* fill_memalign(size_t alignment, size_t bytes)\n{\n    void* buffer = dlmemalign(alignment, bytes);\n    if (buffer) {\n        memset(buffer, CHK_SENTINEL_VALUE, bytes);\n    }\n    return buffer;\n}\n\n// =============================================================================\n// malloc leak functions\n// =============================================================================\n\n#define MEMALIGN_GUARD  ((void*)0xA1A41520)\n\nvoid* leak_malloc(size_t bytes)\n{\n    // allocate enough space infront of the allocation to store the pointer for\n    // the alloc structure. This will making free'ing the structer really fast!\n\n    // 1. allocate enough memory and include our header\n    // 2. set the base pointer to be right after our header\n\n    void* base = dlmalloc(bytes + sizeof(AllocationEntry));\n    if (base != NULL) {\n        pthread_mutex_lock(&gAllocationsMutex);\n\n            intptr_t backtrace[BACKTRACE_SIZE];\n            size_t numEntries = get_backtrace(backtrace, BACKTRACE_SIZE);\n\n            AllocationEntry* header = (AllocationEntry*)base;\n            header->entry = record_backtrace(backtrace, numEntries, bytes);\n            header->guard = GUARD;\n\n            // now increment base to point to after our header.\n            // this should just work since our header is 8 bytes.\n            base = (AllocationEntry*)base + 1;\n\n        pthread_mutex_unlock(&gAllocationsMutex);\n    }\n\n    return base;\n}\n\nvoid leak_free(void* mem)\n{\n    if (mem != NULL) {\n        pthread_mutex_lock(&gAllocationsMutex);\n\n        // check the guard to make sure it is valid\n        AllocationEntry* header = (AllocationEntry*)mem - 1;\n\n        if (header->guard != GUARD) {\n            // could be a memaligned block\n            if (((void**)mem)[-1] == MEMALIGN_GUARD) {\n                mem = ((void**)mem)[-2];\n                header = (AllocationEntry*)mem - 1;\n            }\n        }\n\n        if (header->guard == GUARD || is_valid_entry(header->entry)) {\n            // decrement the allocations\n            HashEntry* entry = header->entry;\n            entry->allocations--;\n            if (entry->allocations <= 0) {\n                remove_entry(entry);\n                dlfree(entry);\n            }\n\n            // now free the memory!\n            dlfree(header);\n        } else {\n            debug_log(\"WARNING bad header guard: '0x%x'! and invalid entry: %p\\n\",\n                    header->guard, header->entry);\n        }\n\n        pthread_mutex_unlock(&gAllocationsMutex);\n    }\n}\n\nvoid* leak_calloc(size_t n_elements, size_t elem_size)\n{\n    size_t  size;\n    void*   ptr;\n\n    /* Fail on overflow - just to be safe even though this code runs only\n     * within the debugging C library, not the production one */\n    if (n_elements && MAX_SIZE_T / n_elements < elem_size) {\n        return NULL;\n    }\n    size = n_elements * elem_size;\n    ptr  = leak_malloc(size);\n    if (ptr != NULL) {\n        memset(ptr, 0, size);\n    }\n    return ptr;\n}\n\nvoid* leak_realloc(void* oldMem, size_t bytes)\n{\n    if (oldMem == NULL) {\n        return leak_malloc(bytes);\n    }\n    void* newMem = NULL;\n    AllocationEntry* header = (AllocationEntry*)oldMem - 1;\n    if (header && header->guard == GUARD) {\n        size_t oldSize = header->entry->size & ~SIZE_FLAG_MASK;\n        newMem = leak_malloc(bytes);\n        if (newMem != NULL) {\n            size_t copySize = (oldSize <= bytes) ? oldSize : bytes;\n            memcpy(newMem, oldMem, copySize);\n            leak_free(oldMem);\n        }\n    } else {\n        newMem = dlrealloc(oldMem, bytes);\n    }\n    return newMem;\n}\n\nvoid* leak_memalign(size_t alignment, size_t bytes)\n{\n    // we can just use malloc\n    if (alignment <= MALLOC_ALIGNMENT)\n        return leak_malloc(bytes);\n\n    // need to make sure it's a power of two\n    if (alignment & (alignment-1))\n        alignment = 1L << (31 - __builtin_clz(alignment));\n\n    // here, aligment is at least MALLOC_ALIGNMENT<<1 bytes\n    // we will align by at least MALLOC_ALIGNMENT bytes\n    // and at most alignment-MALLOC_ALIGNMENT bytes\n    size_t size = (alignment-MALLOC_ALIGNMENT) + bytes;\n    void* base = leak_malloc(size);\n    if (base != NULL) {\n        intptr_t ptr = (intptr_t)base;\n        if ((ptr % alignment) == 0)\n            return base;\n\n        // align the pointer\n        ptr += ((-ptr) % alignment);\n\n        // there is always enough space for the base pointer and the guard\n        ((void**)ptr)[-1] = MEMALIGN_GUARD;\n        ((void**)ptr)[-2] = base;\n\n        return (void*)ptr;\n    }\n    return base;\n}\n\n/* Initializes malloc debugging framework.\n * See comments on MallocDebugInit in malloc_debug_common.h\n */\nint malloc_debug_initialize(void)\n{\n    // We don't really have anything that requires initialization here.\n    return 0;\n}\n"], "fixing_code": ["/*\n * Copyright (C) 2008 The Android Open Source Project\n * All rights reserved.\n *\n * Redistribution and use in source and binary forms, with or without\n * modification, are permitted provided that the following conditions\n * are met:\n *  * Redistributions of source code must retain the above copyright\n *    notice, this list of conditions and the following disclaimer.\n *  * Redistributions in binary form must reproduce the above copyright\n *    notice, this list of conditions and the following disclaimer in\n *    the documentation and/or other materials provided with the\n *    distribution.\n *\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS\n * FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE\n * COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,\n * INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,\n * BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS\n * OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED\n * AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,\n * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT\n * OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF\n * SUCH DAMAGE.\n */\n\n#include <dlfcn.h>\n#include <errno.h>\n#include <fcntl.h>\n#include <pthread.h>\n#include <stdarg.h>\n#include <stddef.h>\n#include <stdint.h>\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <unistd.h>\n#include <unwind.h>\n\n#include <arpa/inet.h>\n#include <sys/select.h>\n#include <sys/socket.h>\n#include <sys/system_properties.h>\n#include <sys/types.h>\n#include <sys/un.h>\n\n#include \"dlmalloc.h\"\n#include \"logd.h\"\n#include \"malloc_debug_common.h\"\n\n// This file should be included into the build only when\n// MALLOC_LEAK_CHECK, or MALLOC_QEMU_INSTRUMENT, or both\n// macros are defined.\n#ifndef MALLOC_LEAK_CHECK\n#error MALLOC_LEAK_CHECK is not defined.\n#endif  // !MALLOC_LEAK_CHECK\n\n// Global variables defined in malloc_debug_common.c\nextern int gMallocLeakZygoteChild;\nextern pthread_mutex_t gAllocationsMutex;\nextern HashTable gHashTable;\nextern const MallocDebug __libc_malloc_default_dispatch;\nextern const MallocDebug* __libc_malloc_dispatch;\n\n// =============================================================================\n// log functions\n// =============================================================================\n\n#define debug_log(format, ...)  \\\n    __libc_android_log_print(ANDROID_LOG_DEBUG, \"malloc_leak_check\", (format), ##__VA_ARGS__ )\n#define error_log(format, ...)  \\\n    __libc_android_log_print(ANDROID_LOG_ERROR, \"malloc_leak_check\", (format), ##__VA_ARGS__ )\n#define info_log(format, ...)  \\\n    __libc_android_log_print(ANDROID_LOG_INFO, \"malloc_leak_check\", (format), ##__VA_ARGS__ )\n\nstatic int gTrapOnError = 1;\n\n#define MALLOC_ALIGNMENT    8\n#define GUARD               0x48151642\n#define DEBUG               0\n\n// =============================================================================\n// Structures\n// =============================================================================\ntypedef struct AllocationEntry AllocationEntry;\nstruct AllocationEntry {\n    HashEntry* entry;\n    uint32_t guard;\n};\n\n\n// =============================================================================\n// Hash Table functions\n// =============================================================================\nstatic uint32_t get_hash(intptr_t* backtrace, size_t numEntries)\n{\n    if (backtrace == NULL) return 0;\n\n    int hash = 0;\n    size_t i;\n    for (i = 0 ; i < numEntries ; i++) {\n        hash = (hash * 33) + (backtrace[i] >> 2);\n    }\n\n    return hash;\n}\n\nstatic HashEntry* find_entry(HashTable* table, int slot,\n        intptr_t* backtrace, size_t numEntries, size_t size)\n{\n    HashEntry* entry = table->slots[slot];\n    while (entry != NULL) {\n        //debug_log(\"backtrace: %p, entry: %p entry->backtrace: %p\\n\",\n        //        backtrace, entry, (entry != NULL) ? entry->backtrace : NULL);\n        /*\n         * See if the entry matches exactly.  We compare the \"size\" field,\n         * including the flag bits.\n         */\n        if (entry->size == size && entry->numEntries == numEntries &&\n                !memcmp(backtrace, entry->backtrace, numEntries * sizeof(intptr_t))) {\n            return entry;\n        }\n\n        entry = entry->next;\n    }\n\n    return NULL;\n}\n\nstatic HashEntry* record_backtrace(intptr_t* backtrace, size_t numEntries, size_t size)\n{\n    size_t hash = get_hash(backtrace, numEntries);\n    size_t slot = hash % HASHTABLE_SIZE;\n\n    if (size & SIZE_FLAG_MASK) {\n        debug_log(\"malloc_debug: allocation %zx exceeds bit width\\n\", size);\n        abort();\n    }\n\n    if (gMallocLeakZygoteChild)\n        size |= SIZE_FLAG_ZYGOTE_CHILD;\n\n    HashEntry* entry = find_entry(&gHashTable, slot, backtrace, numEntries, size);\n\n    if (entry != NULL) {\n        entry->allocations++;\n    } else {\n        // create a new entry\n        entry = (HashEntry*)dlmalloc(sizeof(HashEntry) + numEntries*sizeof(intptr_t));\n        if (!entry)\n            return NULL;\n        entry->allocations = 1;\n        entry->slot = slot;\n        entry->prev = NULL;\n        entry->next = gHashTable.slots[slot];\n        entry->numEntries = numEntries;\n        entry->size = size;\n\n        memcpy(entry->backtrace, backtrace, numEntries * sizeof(intptr_t));\n\n        gHashTable.slots[slot] = entry;\n\n        if (entry->next != NULL) {\n            entry->next->prev = entry;\n        }\n\n        // we just added an entry, increase the size of the hashtable\n        gHashTable.count++;\n    }\n\n    return entry;\n}\n\nstatic int is_valid_entry(HashEntry* entry)\n{\n    if (entry != NULL) {\n        int i;\n        for (i = 0 ; i < HASHTABLE_SIZE ; i++) {\n            HashEntry* e1 = gHashTable.slots[i];\n\n            while (e1 != NULL) {\n                if (e1 == entry) {\n                    return 1;\n                }\n\n                e1 = e1->next;\n            }\n        }\n    }\n\n    return 0;\n}\n\nstatic void remove_entry(HashEntry* entry)\n{\n    HashEntry* prev = entry->prev;\n    HashEntry* next = entry->next;\n\n    if (prev != NULL) entry->prev->next = next;\n    if (next != NULL) entry->next->prev = prev;\n\n    if (prev == NULL) {\n        // we are the head of the list. set the head to be next\n        gHashTable.slots[entry->slot] = entry->next;\n    }\n\n    // we just removed and entry, decrease the size of the hashtable\n    gHashTable.count--;\n}\n\n\n// =============================================================================\n// stack trace functions\n// =============================================================================\n\ntypedef struct\n{\n    size_t count;\n    intptr_t* addrs;\n} stack_crawl_state_t;\n\n\n/* depends how the system includes define this */\n#ifdef HAVE_UNWIND_CONTEXT_STRUCT\ntypedef struct _Unwind_Context __unwind_context;\n#else\ntypedef _Unwind_Context __unwind_context;\n#endif\n\nstatic _Unwind_Reason_Code trace_function(__unwind_context *context, void *arg)\n{\n    stack_crawl_state_t* state = (stack_crawl_state_t*)arg;\n    if (state->count) {\n        intptr_t ip = (intptr_t)_Unwind_GetIP(context);\n        if (ip) {\n            state->addrs[0] = ip;\n            state->addrs++;\n            state->count--;\n            return _URC_NO_REASON;\n        }\n    }\n    /*\n     * If we run out of space to record the address or 0 has been seen, stop\n     * unwinding the stack.\n     */\n    return _URC_END_OF_STACK;\n}\n\nstatic inline\nint get_backtrace(intptr_t* addrs, size_t max_entries)\n{\n    stack_crawl_state_t state;\n    state.count = max_entries;\n    state.addrs = (intptr_t*)addrs;\n    _Unwind_Backtrace(trace_function, (void*)&state);\n    return max_entries - state.count;\n}\n\n// =============================================================================\n// malloc check functions\n// =============================================================================\n\n#define CHK_FILL_FREE           0xef\n#define CHK_SENTINEL_VALUE      (char)0xeb\n#define CHK_SENTINEL_HEAD_SIZE  16\n#define CHK_SENTINEL_TAIL_SIZE  16\n#define CHK_OVERHEAD_SIZE       (   CHK_SENTINEL_HEAD_SIZE +    \\\n                                    CHK_SENTINEL_TAIL_SIZE +    \\\n                                    sizeof(size_t) )\n\nstatic void dump_stack_trace()\n{\n    intptr_t addrs[20];\n    int c = get_backtrace(addrs, 20);\n    char buf[16];\n    char tmp[16*20];\n    int i;\n\n    tmp[0] = 0; // Need to initialize tmp[0] for the first strcat\n    for (i=0 ; i<c; i++) {\n        snprintf(buf, sizeof buf, \"%2d: %08x\\n\", i, addrs[i]);\n        strlcat(tmp, buf, sizeof tmp);\n    }\n    __libc_android_log_print(ANDROID_LOG_ERROR, \"libc\", \"call stack:\\n%s\", tmp);\n}\n\nstatic int is_valid_malloc_pointer(void* addr)\n{\n    return 1;\n}\n\nstatic void assert_log_message(const char* format, ...)\n{\n    va_list  args;\n\n    pthread_mutex_lock(&gAllocationsMutex);\n    {\n        const MallocDebug* current_dispatch = __libc_malloc_dispatch;\n        __libc_malloc_dispatch = &__libc_malloc_default_dispatch;\n        va_start(args, format);\n        __libc_android_log_vprint(ANDROID_LOG_ERROR, \"libc\",\n                                format, args);\n        va_end(args);\n        dump_stack_trace();\n        if (gTrapOnError) {\n            __builtin_trap();\n        }\n        __libc_malloc_dispatch = current_dispatch;\n    }\n    pthread_mutex_unlock(&gAllocationsMutex);\n}\n\nstatic void assert_valid_malloc_pointer(void* mem)\n{\n    if (mem && !is_valid_malloc_pointer(mem)) {\n        assert_log_message(\n            \"*** MALLOC CHECK: buffer %p, is not a valid \"\n            \"malloc pointer (are you mixing up new/delete \"\n            \"and malloc/free?)\", mem);\n    }\n}\n\n/* Check that a given address corresponds to a guarded block,\n * and returns its original allocation size in '*allocated'.\n * 'func' is the capitalized name of the caller function.\n * Returns 0 on success, or -1 on failure.\n * NOTE: Does not return if gTrapOnError is set.\n */\nstatic int chk_mem_check(void*       mem,\n                         size_t*     allocated,\n                         const char* func)\n{\n    char*  buffer;\n    size_t offset, bytes;\n    int    i;\n    char*  buf;\n\n    /* first check the bytes in the sentinel header */\n    buf = (char*)mem - CHK_SENTINEL_HEAD_SIZE;\n    for (i=0 ; i<CHK_SENTINEL_HEAD_SIZE ; i++) {\n        if (buf[i] != CHK_SENTINEL_VALUE) {\n            assert_log_message(\n                \"*** %s CHECK: buffer %p \"\n                \"corrupted %d bytes before allocation\",\n                func, mem, CHK_SENTINEL_HEAD_SIZE-i);\n            return -1;\n        }\n    }\n\n    /* then the ones in the sentinel trailer */\n    buffer = (char*)mem - CHK_SENTINEL_HEAD_SIZE;\n    offset = dlmalloc_usable_size(buffer) - sizeof(size_t);\n    bytes  = *(size_t *)(buffer + offset);\n\n    buf = (char*)mem + bytes;\n    for (i=CHK_SENTINEL_TAIL_SIZE-1 ; i>=0 ; i--) {\n        if (buf[i] != CHK_SENTINEL_VALUE) {\n            assert_log_message(\n                \"*** %s CHECK: buffer %p, size=%lu, \"\n                \"corrupted %d bytes after allocation\",\n                func, buffer, bytes, i+1);\n            return -1;\n        }\n    }\n\n    *allocated = bytes;\n    return 0;\n}\n\n\nvoid* chk_malloc(size_t bytes)\n{\n    size_t size = bytes + CHK_OVERHEAD_SIZE;\n    if (size < bytes) { // Overflow.\n        return NULL;\n    }\n    uint8_t* buffer = (uint8_t*) dlmalloc(size);\n    if (buffer) {\n        memset(buffer, CHK_SENTINEL_VALUE, bytes + CHK_OVERHEAD_SIZE);\n        size_t offset = dlmalloc_usable_size(buffer) - sizeof(size_t);\n        *(size_t *)(buffer + offset) = bytes;\n        buffer += CHK_SENTINEL_HEAD_SIZE;\n    }\n    return buffer;\n}\n\nvoid  chk_free(void* mem)\n{\n    assert_valid_malloc_pointer(mem);\n    if (mem) {\n        size_t  size;\n        char*   buffer;\n\n        if (chk_mem_check(mem, &size, \"FREE\") == 0) {\n            buffer = (char*)mem - CHK_SENTINEL_HEAD_SIZE;\n            memset(buffer, CHK_FILL_FREE, size + CHK_OVERHEAD_SIZE);\n            dlfree(buffer);\n        }\n    }\n}\n\nvoid* chk_calloc(size_t n_elements, size_t elem_size)\n{\n    size_t  size;\n    void*   ptr;\n\n    /* Fail on overflow - just to be safe even though this code runs only\n     * within the debugging C library, not the production one */\n    if (n_elements && MAX_SIZE_T / n_elements < elem_size) {\n        return NULL;\n    }\n    size = n_elements * elem_size;\n    ptr  = chk_malloc(size);\n    if (ptr != NULL) {\n        memset(ptr, 0, size);\n    }\n    return ptr;\n}\n\nvoid* chk_realloc(void* mem, size_t bytes)\n{\n    char*   buffer;\n    int     ret;\n    size_t  old_bytes = 0;\n\n    assert_valid_malloc_pointer(mem);\n\n    if (mem != NULL && chk_mem_check(mem, &old_bytes, \"REALLOC\") < 0)\n        return NULL;\n\n    char* new_buffer = chk_malloc(bytes);\n    if (mem == NULL) {\n        return new_buffer;\n    }\n\n    if (new_buffer) {\n        if (bytes > old_bytes)\n            bytes = old_bytes;\n        memcpy(new_buffer, mem, bytes);\n        chk_free(mem);\n    }\n\n    return new_buffer;\n}\n\nvoid* chk_memalign(size_t alignment, size_t bytes)\n{\n    // XXX: it's better to use malloc, than being wrong\n    return chk_malloc(bytes);\n}\n\n// =============================================================================\n// malloc fill functions\n// =============================================================================\n\nvoid* fill_malloc(size_t bytes)\n{\n    void* buffer = dlmalloc(bytes);\n    if (buffer) {\n        memset(buffer, CHK_SENTINEL_VALUE, bytes);\n    }\n    return buffer;\n}\n\nvoid  fill_free(void* mem)\n{\n    size_t bytes = dlmalloc_usable_size(mem);\n    memset(mem, CHK_FILL_FREE, bytes);\n    dlfree(mem);\n}\n\nvoid* fill_realloc(void* mem, size_t bytes)\n{\n    void* buffer = fill_malloc(bytes);\n    if (mem == NULL) {\n        return buffer;\n    }\n    if (buffer) {\n        size_t old_size = dlmalloc_usable_size(mem);\n        size_t size = (bytes < old_size)?(bytes):(old_size);\n        memcpy(buffer, mem, size);\n        fill_free(mem);\n    }\n    return buffer;\n}\n\nvoid* fill_memalign(size_t alignment, size_t bytes)\n{\n    void* buffer = dlmemalign(alignment, bytes);\n    if (buffer) {\n        memset(buffer, CHK_SENTINEL_VALUE, bytes);\n    }\n    return buffer;\n}\n\n// =============================================================================\n// malloc leak functions\n// =============================================================================\n\n#define MEMALIGN_GUARD  ((void*)0xA1A41520)\n\nvoid* leak_malloc(size_t bytes)\n{\n    // allocate enough space infront of the allocation to store the pointer for\n    // the alloc structure. This will making free'ing the structer really fast!\n\n    // 1. allocate enough memory and include our header\n    // 2. set the base pointer to be right after our header\n\n    size_t size = bytes + sizeof(AllocationEntry);\n    if (size < bytes) { // Overflow.\n        return NULL;\n    }\n\n    void* base = dlmalloc(size);\n    if (base != NULL) {\n        pthread_mutex_lock(&gAllocationsMutex);\n\n            intptr_t backtrace[BACKTRACE_SIZE];\n            size_t numEntries = get_backtrace(backtrace, BACKTRACE_SIZE);\n\n            AllocationEntry* header = (AllocationEntry*)base;\n            header->entry = record_backtrace(backtrace, numEntries, bytes);\n            header->guard = GUARD;\n\n            // now increment base to point to after our header.\n            // this should just work since our header is 8 bytes.\n            base = (AllocationEntry*)base + 1;\n\n        pthread_mutex_unlock(&gAllocationsMutex);\n    }\n\n    return base;\n}\n\nvoid leak_free(void* mem)\n{\n    if (mem != NULL) {\n        pthread_mutex_lock(&gAllocationsMutex);\n\n        // check the guard to make sure it is valid\n        AllocationEntry* header = (AllocationEntry*)mem - 1;\n\n        if (header->guard != GUARD) {\n            // could be a memaligned block\n            if (((void**)mem)[-1] == MEMALIGN_GUARD) {\n                mem = ((void**)mem)[-2];\n                header = (AllocationEntry*)mem - 1;\n            }\n        }\n\n        if (header->guard == GUARD || is_valid_entry(header->entry)) {\n            // decrement the allocations\n            HashEntry* entry = header->entry;\n            entry->allocations--;\n            if (entry->allocations <= 0) {\n                remove_entry(entry);\n                dlfree(entry);\n            }\n\n            // now free the memory!\n            dlfree(header);\n        } else {\n            debug_log(\"WARNING bad header guard: '0x%x'! and invalid entry: %p\\n\",\n                    header->guard, header->entry);\n        }\n\n        pthread_mutex_unlock(&gAllocationsMutex);\n    }\n}\n\nvoid* leak_calloc(size_t n_elements, size_t elem_size)\n{\n    size_t  size;\n    void*   ptr;\n\n    /* Fail on overflow - just to be safe even though this code runs only\n     * within the debugging C library, not the production one */\n    if (n_elements && MAX_SIZE_T / n_elements < elem_size) {\n        return NULL;\n    }\n    size = n_elements * elem_size;\n    ptr  = leak_malloc(size);\n    if (ptr != NULL) {\n        memset(ptr, 0, size);\n    }\n    return ptr;\n}\n\nvoid* leak_realloc(void* oldMem, size_t bytes)\n{\n    if (oldMem == NULL) {\n        return leak_malloc(bytes);\n    }\n    void* newMem = NULL;\n    AllocationEntry* header = (AllocationEntry*)oldMem - 1;\n    if (header && header->guard == GUARD) {\n        size_t oldSize = header->entry->size & ~SIZE_FLAG_MASK;\n        newMem = leak_malloc(bytes);\n        if (newMem != NULL) {\n            size_t copySize = (oldSize <= bytes) ? oldSize : bytes;\n            memcpy(newMem, oldMem, copySize);\n            leak_free(oldMem);\n        }\n    } else {\n        newMem = dlrealloc(oldMem, bytes);\n    }\n    return newMem;\n}\n\nvoid* leak_memalign(size_t alignment, size_t bytes)\n{\n    // we can just use malloc\n    if (alignment <= MALLOC_ALIGNMENT)\n        return leak_malloc(bytes);\n\n    // need to make sure it's a power of two\n    if (alignment & (alignment-1))\n        alignment = 1L << (31 - __builtin_clz(alignment));\n\n    // here, aligment is at least MALLOC_ALIGNMENT<<1 bytes\n    // we will align by at least MALLOC_ALIGNMENT bytes\n    // and at most alignment-MALLOC_ALIGNMENT bytes\n    size_t size = (alignment-MALLOC_ALIGNMENT) + bytes;\n    if (size < bytes) { // Overflow.\n        return NULL;\n    }\n\n    void* base = leak_malloc(size);\n    if (base != NULL) {\n        intptr_t ptr = (intptr_t)base;\n        if ((ptr % alignment) == 0)\n            return base;\n\n        // align the pointer\n        ptr += ((-ptr) % alignment);\n\n        // there is always enough space for the base pointer and the guard\n        ((void**)ptr)[-1] = MEMALIGN_GUARD;\n        ((void**)ptr)[-2] = base;\n\n        return (void*)ptr;\n    }\n    return base;\n}\n\n/* Initializes malloc debugging framework.\n * See comments on MallocDebugInit in malloc_debug_common.h\n */\nint malloc_debug_initialize(void)\n{\n    // We don't really have anything that requires initialization here.\n    return 0;\n}\n"], "filenames": ["libc/bionic/malloc_debug_leak.c"], "buggy_code_start_loc": [27], "buggy_code_end_loc": [617], "fixing_code_start_loc": [28], "fixing_code_end_loc": [631], "type": "CWE-189", "message": "Multiple integer overflows in the (1) chk_malloc, (2) leak_malloc, and (3) leak_memalign functions in libc/bionic/malloc_debug_leak.c in Bionic (libc) for Android, when libc.debug.malloc is set, make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.", "other": {"cve": {"id": "CVE-2012-2674", "sourceIdentifier": "secalert@redhat.com", "published": "2012-07-25T19:55:02.820", "lastModified": "2012-08-24T04:00:00.000", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Multiple integer overflows in the (1) chk_malloc, (2) leak_malloc, and (3) leak_memalign functions in libc/bionic/malloc_debug_leak.c in Bionic (libc) for Android, when libc.debug.malloc is set, make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected."}, {"lang": "es", "value": "M\u00faltiples desbordamientos de enteros en la chk_malloc (1), leak_malloc (2), y (3) las funciones de leak_memalign en libc/bionic/malloc_debug_leak.c en Bionic (libc) para Android, libc.debug.malloc cuando se establece, facilitar a los atacantes dependientes de contexto para llevar a cabo ataques relacionados con la memoria, tales como desbordamientos de b\u00fafer a trav\u00e9s de un valor de gran tama\u00f1o, lo que hace que se asigne menos memoria de lo esperado."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-189"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:bionic:-:*:*:*:*:android:*:*", "matchCriteriaId": "36B0A10E-022D-4DD8-A9E8-9CB3AD9A47F6"}]}]}], "references": [{"url": "http://kqueue.org/blog/2012/03/05/memory-allocator-security-revisited/", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2012/06/05/1", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2012/06/07/13", "source": "secalert@redhat.com"}, {"url": "https://github.com/android/platform_bionic/commit/7f5aa4f35e23fd37425b3a5041737cdf58f87385", "source": "secalert@redhat.com", "tags": ["Exploit", "Patch"]}]}, "github_commit_url": "https://github.com/android/platform_bionic/commit/7f5aa4f35e23fd37425b3a5041737cdf58f87385"}}
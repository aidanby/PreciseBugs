{"buggy_code": ["# repo.py\n# Copyright (C) 2008, 2009 Michael Trier (mtrier@gmail.com) and contributors\n#\n# This module is part of GitPython and is released under\n# the BSD License: http://www.opensource.org/licenses/bsd-license.php\nfrom __future__ import annotations\nimport logging\nimport os\nimport re\nimport shlex\nimport warnings\n\nfrom pathlib import Path\n\nfrom gitdb.db.loose import LooseObjectDB\n\nfrom gitdb.exc import BadObject\n\nfrom git.cmd import Git, handle_process_output\nfrom git.compat import (\n    defenc,\n    safe_decode,\n    is_win,\n)\nfrom git.config import GitConfigParser\nfrom git.db import GitCmdObjectDB\nfrom git.exc import (\n    GitCommandError,\n    InvalidGitRepositoryError,\n    NoSuchPathError,\n)\nfrom git.index import IndexFile\nfrom git.objects import Submodule, RootModule, Commit\nfrom git.refs import HEAD, Head, Reference, TagReference\nfrom git.remote import Remote, add_progress, to_progress_instance\nfrom git.util import (\n    Actor,\n    finalize_process,\n    cygpath,\n    hex_to_bin,\n    expand_path,\n    remove_password_if_present,\n)\nimport os.path as osp\n\nfrom .fun import (\n    rev_parse,\n    is_git_dir,\n    find_submodule_git_dir,\n    touch,\n    find_worktree_git_dir,\n)\nimport gc\nimport gitdb\n\n# typing ------------------------------------------------------\n\nfrom git.types import (\n    TBD,\n    PathLike,\n    Lit_config_levels,\n    Commit_ish,\n    Tree_ish,\n    assert_never,\n)\nfrom typing import (\n    Any,\n    BinaryIO,\n    Callable,\n    Dict,\n    Iterator,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    TextIO,\n    Tuple,\n    Type,\n    Union,\n    NamedTuple,\n    cast,\n    TYPE_CHECKING,\n)\n\nfrom git.types import ConfigLevels_Tup, TypedDict\n\nif TYPE_CHECKING:\n    from git.util import IterableList\n    from git.refs.symbolic import SymbolicReference\n    from git.objects import Tree\n    from git.objects.submodule.base import UpdateProgress\n    from git.remote import RemoteProgress\n\n# -----------------------------------------------------------\n\nlog = logging.getLogger(__name__)\n\n__all__ = (\"Repo\",)\n\n\nclass BlameEntry(NamedTuple):\n    commit: Dict[str, \"Commit\"]\n    linenos: range\n    orig_path: Optional[str]\n    orig_linenos: range\n\n\nclass Repo(object):\n    \"\"\"Represents a git repository and allows you to query references,\n    gather commit information, generate diffs, create and clone repositories query\n    the log.\n\n    The following attributes are worth using:\n\n    'working_dir' is the working directory of the git command, which is the working tree\n    directory if available or the .git directory in case of bare repositories\n\n    'working_tree_dir' is the working tree directory, but will return None\n    if we are a bare repository.\n\n    'git_dir' is the .git repository directory, which is always set.\"\"\"\n\n    DAEMON_EXPORT_FILE = \"git-daemon-export-ok\"\n\n    git = cast(\"Git\", None)  # Must exist, or  __del__  will fail in case we raise on `__init__()`\n    working_dir: PathLike\n    _working_tree_dir: Optional[PathLike] = None\n    git_dir: PathLike\n    _common_dir: PathLike = \"\"\n\n    # precompiled regex\n    re_whitespace = re.compile(r\"\\s+\")\n    re_hexsha_only = re.compile(\"^[0-9A-Fa-f]{40}$\")\n    re_hexsha_shortened = re.compile(\"^[0-9A-Fa-f]{4,40}$\")\n    re_envvars = re.compile(r\"(\\$(\\{\\s?)?[a-zA-Z_]\\w*(\\}\\s?)?|%\\s?[a-zA-Z_]\\w*\\s?%)\")\n    re_author_committer_start = re.compile(r\"^(author|committer)\")\n    re_tab_full_line = re.compile(r\"^\\t(.*)$\")\n\n    unsafe_git_clone_options = [\n        # This option allows users to execute arbitrary commands.\n        # https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---upload-packltupload-packgt\n        \"--upload-pack\",\n        \"-u\",\n        # Users can override configuration variables\n        # like `protocol.allow` or `core.gitProxy` to execute arbitrary commands.\n        # https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---configltkeygtltvaluegt\n        \"--config\",\n        \"-c\",\n    ]\n\n    # invariants\n    # represents the configuration level of a configuration file\n    config_level: ConfigLevels_Tup = (\"system\", \"user\", \"global\", \"repository\")\n\n    # Subclass configuration\n    # Subclasses may easily bring in their own custom types by placing a constructor or type here\n    GitCommandWrapperType = Git\n\n    def __init__(\n        self,\n        path: Optional[PathLike] = None,\n        odbt: Type[LooseObjectDB] = GitCmdObjectDB,\n        search_parent_directories: bool = False,\n        expand_vars: bool = True,\n    ) -> None:\n        \"\"\"Create a new Repo instance\n\n        :param path:\n            the path to either the root git directory or the bare git repo::\n\n                repo = Repo(\"/Users/mtrier/Development/git-python\")\n                repo = Repo(\"/Users/mtrier/Development/git-python.git\")\n                repo = Repo(\"~/Development/git-python.git\")\n                repo = Repo(\"$REPOSITORIES/Development/git-python.git\")\n                repo = Repo(\"C:\\\\Users\\\\mtrier\\\\Development\\\\git-python\\\\.git\")\n\n            - In *Cygwin*, path may be a `'cygdrive/...'` prefixed path.\n            - If it evaluates to false, :envvar:`GIT_DIR` is used, and if this also evals to false,\n              the current-directory is used.\n        :param odbt:\n            Object DataBase type - a type which is constructed by providing\n            the directory containing the database objects, i.e. .git/objects. It will\n            be used to access all object data\n        :param search_parent_directories:\n            if True, all parent directories will be searched for a valid repo as well.\n\n            Please note that this was the default behaviour in older versions of GitPython,\n            which is considered a bug though.\n        :raise InvalidGitRepositoryError:\n        :raise NoSuchPathError:\n        :return: git.Repo\"\"\"\n\n        epath = path or os.getenv(\"GIT_DIR\")\n        if not epath:\n            epath = os.getcwd()\n        if Git.is_cygwin():\n            # Given how the tests are written, this seems more likely to catch\n            # Cygwin git used from Windows than Windows git used from Cygwin.\n            # Therefore changing to Cygwin-style paths is the relevant operation.\n            epath = cygpath(epath)\n\n        epath = epath or path or os.getcwd()\n        if not isinstance(epath, str):\n            epath = str(epath)\n        if expand_vars and re.search(self.re_envvars, epath):\n            warnings.warn(\n                \"The use of environment variables in paths is deprecated\"\n                + \"\\nfor security reasons and may be removed in the future!!\"\n            )\n        epath = expand_path(epath, expand_vars)\n        if epath is not None:\n            if not os.path.exists(epath):\n                raise NoSuchPathError(epath)\n\n        ## Walk up the path to find the `.git` dir.\n        #\n        curpath = epath\n        git_dir = None\n        while curpath:\n            # ABOUT osp.NORMPATH\n            # It's important to normalize the paths, as submodules will otherwise initialize their\n            # repo instances with paths that depend on path-portions that will not exist after being\n            # removed. It's just cleaner.\n            if is_git_dir(curpath):\n                git_dir = curpath\n                # from man git-config : core.worktree\n                # Set the path to the root of the working tree. If GIT_COMMON_DIR environment\n                # variable is set, core.worktree is ignored and not used for determining the\n                # root of working tree. This can be overridden by the GIT_WORK_TREE environment\n                # variable. The value can be an absolute path or relative to the path to the .git\n                # directory, which is either specified by GIT_DIR, or automatically discovered.\n                # If GIT_DIR is specified but none of GIT_WORK_TREE and core.worktree is specified,\n                # the current working directory is regarded as the top level of your working tree.\n                self._working_tree_dir = os.path.dirname(git_dir)\n                if os.environ.get(\"GIT_COMMON_DIR\") is None:\n                    gitconf = self._config_reader(\"repository\", git_dir)\n                    if gitconf.has_option(\"core\", \"worktree\"):\n                        self._working_tree_dir = gitconf.get(\"core\", \"worktree\")\n                if \"GIT_WORK_TREE\" in os.environ:\n                    self._working_tree_dir = os.getenv(\"GIT_WORK_TREE\")\n                break\n\n            dotgit = osp.join(curpath, \".git\")\n            sm_gitpath = find_submodule_git_dir(dotgit)\n            if sm_gitpath is not None:\n                git_dir = osp.normpath(sm_gitpath)\n\n            sm_gitpath = find_submodule_git_dir(dotgit)\n            if sm_gitpath is None:\n                sm_gitpath = find_worktree_git_dir(dotgit)\n\n            if sm_gitpath is not None:\n                git_dir = expand_path(sm_gitpath, expand_vars)\n                self._working_tree_dir = curpath\n                break\n\n            if not search_parent_directories:\n                break\n            curpath, tail = osp.split(curpath)\n            if not tail:\n                break\n        # END while curpath\n\n        if git_dir is None:\n            raise InvalidGitRepositoryError(epath)\n        self.git_dir = git_dir\n\n        self._bare = False\n        try:\n            self._bare = self.config_reader(\"repository\").getboolean(\"core\", \"bare\")\n        except Exception:\n            # lets not assume the option exists, although it should\n            pass\n\n        try:\n            common_dir = (Path(self.git_dir) / \"commondir\").read_text().splitlines()[0].strip()\n            self._common_dir = osp.join(self.git_dir, common_dir)\n        except OSError:\n            self._common_dir = \"\"\n\n        # adjust the wd in case we are actually bare - we didn't know that\n        # in the first place\n        if self._bare:\n            self._working_tree_dir = None\n        # END working dir handling\n\n        self.working_dir: PathLike = self._working_tree_dir or self.common_dir\n        self.git = self.GitCommandWrapperType(self.working_dir)\n\n        # special handling, in special times\n        rootpath = osp.join(self.common_dir, \"objects\")\n        if issubclass(odbt, GitCmdObjectDB):\n            self.odb = odbt(rootpath, self.git)\n        else:\n            self.odb = odbt(rootpath)\n\n    def __enter__(self) -> \"Repo\":\n        return self\n\n    def __exit__(self, *args: Any) -> None:\n        self.close()\n\n    def __del__(self) -> None:\n        try:\n            self.close()\n        except Exception:\n            pass\n\n    def close(self) -> None:\n        if self.git:\n            self.git.clear_cache()\n            # Tempfiles objects on Windows are holding references to\n            # open files until they are collected by the garbage\n            # collector, thus preventing deletion.\n            # TODO: Find these references and ensure they are closed\n            # and deleted synchronously rather than forcing a gc\n            # collection.\n            if is_win:\n                gc.collect()\n            gitdb.util.mman.collect()\n            if is_win:\n                gc.collect()\n\n    def __eq__(self, rhs: object) -> bool:\n        if isinstance(rhs, Repo):\n            return self.git_dir == rhs.git_dir\n        return False\n\n    def __ne__(self, rhs: object) -> bool:\n        return not self.__eq__(rhs)\n\n    def __hash__(self) -> int:\n        return hash(self.git_dir)\n\n    # Description property\n    def _get_description(self) -> str:\n        filename = osp.join(self.git_dir, \"description\")\n        with open(filename, \"rb\") as fp:\n            return fp.read().rstrip().decode(defenc)\n\n    def _set_description(self, descr: str) -> None:\n        filename = osp.join(self.git_dir, \"description\")\n        with open(filename, \"wb\") as fp:\n            fp.write((descr + \"\\n\").encode(defenc))\n\n    description = property(_get_description, _set_description, doc=\"the project's description\")\n    del _get_description\n    del _set_description\n\n    @property\n    def working_tree_dir(self) -> Optional[PathLike]:\n        \"\"\":return: The working tree directory of our git repository. If this is a bare repository, None is returned.\"\"\"\n        return self._working_tree_dir\n\n    @property\n    def common_dir(self) -> PathLike:\n        \"\"\"\n        :return: The git dir that holds everything except possibly HEAD,\n            FETCH_HEAD, ORIG_HEAD, COMMIT_EDITMSG, index, and logs/.\"\"\"\n        return self._common_dir or self.git_dir\n\n    @property\n    def bare(self) -> bool:\n        \"\"\":return: True if the repository is bare\"\"\"\n        return self._bare\n\n    @property\n    def heads(self) -> \"IterableList[Head]\":\n        \"\"\"A list of ``Head`` objects representing the branch heads in\n        this repo\n\n        :return: ``git.IterableList(Head, ...)``\"\"\"\n        return Head.list_items(self)\n\n    @property\n    def references(self) -> \"IterableList[Reference]\":\n        \"\"\"A list of Reference objects representing tags, heads and remote references.\n\n        :return: IterableList(Reference, ...)\"\"\"\n        return Reference.list_items(self)\n\n    # alias for references\n    refs = references\n\n    # alias for heads\n    branches = heads\n\n    @property\n    def index(self) -> \"IndexFile\":\n        \"\"\":return: IndexFile representing this repository's index.\n        :note: This property can be expensive, as the returned ``IndexFile`` will be\n         reinitialized. It's recommended to re-use the object.\"\"\"\n        return IndexFile(self)\n\n    @property\n    def head(self) -> \"HEAD\":\n        \"\"\":return: HEAD Object pointing to the current head reference\"\"\"\n        return HEAD(self, \"HEAD\")\n\n    @property\n    def remotes(self) -> \"IterableList[Remote]\":\n        \"\"\"A list of Remote objects allowing to access and manipulate remotes\n\n        :return: ``git.IterableList(Remote, ...)``\"\"\"\n        return Remote.list_items(self)\n\n    def remote(self, name: str = \"origin\") -> \"Remote\":\n        \"\"\":return: Remote with the specified name\n        :raise ValueError:  if no remote with such a name exists\"\"\"\n        r = Remote(self, name)\n        if not r.exists():\n            raise ValueError(\"Remote named '%s' didn't exist\" % name)\n        return r\n\n    # { Submodules\n\n    @property\n    def submodules(self) -> \"IterableList[Submodule]\":\n        \"\"\"\n        :return: git.IterableList(Submodule, ...) of direct submodules\n            available from the current head\"\"\"\n        return Submodule.list_items(self)\n\n    def submodule(self, name: str) -> \"Submodule\":\n        \"\"\":return: Submodule with the given name\n        :raise ValueError: If no such submodule exists\"\"\"\n        try:\n            return self.submodules[name]\n        except IndexError as e:\n            raise ValueError(\"Didn't find submodule named %r\" % name) from e\n        # END exception handling\n\n    def create_submodule(self, *args: Any, **kwargs: Any) -> Submodule:\n        \"\"\"Create a new submodule\n\n        :note: See the documentation of Submodule.add for a description of the\n            applicable parameters\n        :return: created submodules\"\"\"\n        return Submodule.add(self, *args, **kwargs)\n\n    def iter_submodules(self, *args: Any, **kwargs: Any) -> Iterator[Submodule]:\n        \"\"\"An iterator yielding Submodule instances, see Traversable interface\n        for a description of args and kwargs\n\n        :return: Iterator\"\"\"\n        return RootModule(self).traverse(*args, **kwargs)\n\n    def submodule_update(self, *args: Any, **kwargs: Any) -> Iterator[Submodule]:\n        \"\"\"Update the submodules, keeping the repository consistent as it will\n        take the previous state into consideration. For more information, please\n        see the documentation of RootModule.update\"\"\"\n        return RootModule(self).update(*args, **kwargs)\n\n    # }END submodules\n\n    @property\n    def tags(self) -> \"IterableList[TagReference]\":\n        \"\"\"A list of ``Tag`` objects that are available in this repo\n\n        :return: ``git.IterableList(TagReference, ...)``\"\"\"\n        return TagReference.list_items(self)\n\n    def tag(self, path: PathLike) -> TagReference:\n        \"\"\":return: TagReference Object, reference pointing to a Commit or Tag\n        :param path: path to the tag reference, i.e. 0.1.5 or tags/0.1.5\"\"\"\n        full_path = self._to_full_tag_path(path)\n        return TagReference(self, full_path)\n\n    @staticmethod\n    def _to_full_tag_path(path: PathLike) -> str:\n        path_str = str(path)\n        if path_str.startswith(TagReference._common_path_default + \"/\"):\n            return path_str\n        if path_str.startswith(TagReference._common_default + \"/\"):\n            return Reference._common_path_default + \"/\" + path_str\n        else:\n            return TagReference._common_path_default + \"/\" + path_str\n\n    def create_head(\n        self,\n        path: PathLike,\n        commit: Union[\"SymbolicReference\", \"str\"] = \"HEAD\",\n        force: bool = False,\n        logmsg: Optional[str] = None,\n    ) -> \"Head\":\n        \"\"\"Create a new head within the repository.\n        For more documentation, please see the Head.create method.\n\n        :return: newly created Head Reference\"\"\"\n        return Head.create(self, path, commit, logmsg, force)\n\n    def delete_head(self, *heads: \"Union[str, Head]\", **kwargs: Any) -> None:\n        \"\"\"Delete the given heads\n\n        :param kwargs: Additional keyword arguments to be passed to git-branch\"\"\"\n        return Head.delete(self, *heads, **kwargs)\n\n    def create_tag(\n        self,\n        path: PathLike,\n        ref: Union[str, 'SymbolicReference'] = \"HEAD\",\n        message: Optional[str] = None,\n        force: bool = False,\n        **kwargs: Any,\n    ) -> TagReference:\n        \"\"\"Create a new tag reference.\n        For more documentation, please see the TagReference.create method.\n\n        :return: TagReference object\"\"\"\n        return TagReference.create(self, path, ref, message, force, **kwargs)\n\n    def delete_tag(self, *tags: TagReference) -> None:\n        \"\"\"Delete the given tag references\"\"\"\n        return TagReference.delete(self, *tags)\n\n    def create_remote(self, name: str, url: str, **kwargs: Any) -> Remote:\n        \"\"\"Create a new remote.\n\n        For more information, please see the documentation of the Remote.create\n        methods\n\n        :return: Remote reference\"\"\"\n        return Remote.create(self, name, url, **kwargs)\n\n    def delete_remote(self, remote: \"Remote\") -> str:\n        \"\"\"Delete the given remote.\"\"\"\n        return Remote.remove(self, remote)\n\n    def _get_config_path(self, config_level: Lit_config_levels, git_dir: Optional[PathLike] = None) -> str:\n        if git_dir is None:\n            git_dir = self.git_dir\n        # we do not support an absolute path of the gitconfig on windows ,\n        # use the global config instead\n        if is_win and config_level == \"system\":\n            config_level = \"global\"\n\n        if config_level == \"system\":\n            return \"/etc/gitconfig\"\n        elif config_level == \"user\":\n            config_home = os.environ.get(\"XDG_CONFIG_HOME\") or osp.join(os.environ.get(\"HOME\", \"~\"), \".config\")\n            return osp.normpath(osp.expanduser(osp.join(config_home, \"git\", \"config\")))\n        elif config_level == \"global\":\n            return osp.normpath(osp.expanduser(\"~/.gitconfig\"))\n        elif config_level == \"repository\":\n            repo_dir = self._common_dir or git_dir\n            if not repo_dir:\n                raise NotADirectoryError\n            else:\n                return osp.normpath(osp.join(repo_dir, \"config\"))\n        else:\n\n            assert_never(\n                config_level,  # type:ignore[unreachable]\n                ValueError(f\"Invalid configuration level: {config_level!r}\"),\n            )\n\n    def config_reader(\n        self,\n        config_level: Optional[Lit_config_levels] = None,\n    ) -> GitConfigParser:\n        \"\"\"\n        :return:\n            GitConfigParser allowing to read the full git configuration, but not to write it\n\n            The configuration will include values from the system, user and repository\n            configuration files.\n\n        :param config_level:\n            For possible values, see config_writer method\n            If None, all applicable levels will be used. Specify a level in case\n            you know which file you wish to read to prevent reading multiple files.\n        :note: On windows, system configuration cannot currently be read as the path is\n            unknown, instead the global path will be used.\"\"\"\n        return self._config_reader(config_level=config_level)\n\n    def _config_reader(\n        self,\n        config_level: Optional[Lit_config_levels] = None,\n        git_dir: Optional[PathLike] = None,\n    ) -> GitConfigParser:\n        if config_level is None:\n            files = [\n                self._get_config_path(cast(Lit_config_levels, f), git_dir)\n                for f in self.config_level\n                if cast(Lit_config_levels, f)\n            ]\n        else:\n            files = [self._get_config_path(config_level, git_dir)]\n        return GitConfigParser(files, read_only=True, repo=self)\n\n    def config_writer(self, config_level: Lit_config_levels = \"repository\") -> GitConfigParser:\n        \"\"\"\n        :return:\n            GitConfigParser allowing to write values of the specified configuration file level.\n            Config writers should be retrieved, used to change the configuration, and written\n            right away as they will lock the configuration file in question and prevent other's\n            to write it.\n\n        :param config_level:\n            One of the following values\n            system = system wide configuration file\n            global = user level configuration file\n            repository = configuration file for this repository only\"\"\"\n        return GitConfigParser(self._get_config_path(config_level), read_only=False, repo=self)\n\n    def commit(self, rev: Union[str, Commit_ish, None] = None) -> Commit:\n        \"\"\"The Commit object for the specified revision\n\n        :param rev: revision specifier, see git-rev-parse for viable options.\n        :return: ``git.Commit``\n        \"\"\"\n        if rev is None:\n            return self.head.commit\n        return self.rev_parse(str(rev) + \"^0\")\n\n    def iter_trees(self, *args: Any, **kwargs: Any) -> Iterator[\"Tree\"]:\n        \"\"\":return: Iterator yielding Tree objects\n        :note: Takes all arguments known to iter_commits method\"\"\"\n        return (c.tree for c in self.iter_commits(*args, **kwargs))\n\n    def tree(self, rev: Union[Tree_ish, str, None] = None) -> \"Tree\":\n        \"\"\"The Tree object for the given treeish revision\n        Examples::\n\n              repo.tree(repo.heads[0])\n\n        :param rev: is a revision pointing to a Treeish ( being a commit or tree )\n        :return: ``git.Tree``\n\n        :note:\n            If you need a non-root level tree, find it by iterating the root tree. Otherwise\n            it cannot know about its path relative to the repository root and subsequent\n            operations might have unexpected results.\"\"\"\n        if rev is None:\n            return self.head.commit.tree\n        return self.rev_parse(str(rev) + \"^{tree}\")\n\n    def iter_commits(\n        self,\n        rev: Union[str, Commit, \"SymbolicReference\", None] = None,\n        paths: Union[PathLike, Sequence[PathLike]] = \"\",\n        **kwargs: Any,\n    ) -> Iterator[Commit]:\n        \"\"\"A list of Commit objects representing the history of a given ref/commit\n\n        :param rev:\n            revision specifier, see git-rev-parse for viable options.\n            If None, the active branch will be used.\n\n        :param paths:\n            is an optional path or a list of paths; if set only commits that include the path\n            or paths will be returned\n\n        :param kwargs:\n            Arguments to be passed to git-rev-list - common ones are\n            max_count and skip\n\n        :note: to receive only commits between two named revisions, use the\n            \"revA...revB\" revision specifier\n\n        :return: ``git.Commit[]``\"\"\"\n        if rev is None:\n            rev = self.head.commit\n\n        return Commit.iter_items(self, rev, paths, **kwargs)\n\n    def merge_base(self, *rev: TBD, **kwargs: Any) -> List[Union[Commit_ish, None]]:\n        \"\"\"Find the closest common ancestor for the given revision (e.g. Commits, Tags, References, etc)\n\n        :param rev: At least two revs to find the common ancestor for.\n        :param kwargs: Additional arguments to be passed to the repo.git.merge_base() command which does all the work.\n        :return: A list of Commit objects. If --all was not specified as kwarg, the list will have at max one Commit,\n            or is empty if no common merge base exists.\n        :raises ValueError: If not at least two revs are provided\n        \"\"\"\n        if len(rev) < 2:\n            raise ValueError(\"Please specify at least two revs, got only %i\" % len(rev))\n        # end handle input\n\n        res: List[Union[Commit_ish, None]] = []\n        try:\n            lines = self.git.merge_base(*rev, **kwargs).splitlines()  # List[str]\n        except GitCommandError as err:\n            if err.status == 128:\n                raise\n            # end handle invalid rev\n            # Status code 1 is returned if there is no merge-base\n            # (see https://github.com/git/git/blob/master/builtin/merge-base.c#L16)\n            return res\n        # end exception handling\n\n        for line in lines:\n            res.append(self.commit(line))\n        # end for each merge-base\n\n        return res\n\n    def is_ancestor(self, ancestor_rev: \"Commit\", rev: \"Commit\") -> bool:\n        \"\"\"Check if a commit is an ancestor of another\n\n        :param ancestor_rev: Rev which should be an ancestor\n        :param rev: Rev to test against ancestor_rev\n        :return: ``True``, ancestor_rev is an ancestor to rev.\n        \"\"\"\n        try:\n            self.git.merge_base(ancestor_rev, rev, is_ancestor=True)\n        except GitCommandError as err:\n            if err.status == 1:\n                return False\n            raise\n        return True\n\n    def is_valid_object(self, sha: str, object_type: Union[str, None] = None) -> bool:\n        try:\n            complete_sha = self.odb.partial_to_complete_sha_hex(sha)\n            object_info = self.odb.info(complete_sha)\n            if object_type:\n                if object_info.type == object_type.encode():\n                    return True\n                else:\n                    log.debug(\n                        \"Commit hash points to an object of type '%s'. Requested were objects of type '%s'\",\n                        object_info.type.decode(),\n                        object_type,\n                    )\n                    return False\n            else:\n                return True\n        except BadObject:\n            log.debug(\"Commit hash is invalid.\")\n            return False\n\n    def _get_daemon_export(self) -> bool:\n        if self.git_dir:\n            filename = osp.join(self.git_dir, self.DAEMON_EXPORT_FILE)\n        return osp.exists(filename)\n\n    def _set_daemon_export(self, value: object) -> None:\n        if self.git_dir:\n            filename = osp.join(self.git_dir, self.DAEMON_EXPORT_FILE)\n        fileexists = osp.exists(filename)\n        if value and not fileexists:\n            touch(filename)\n        elif not value and fileexists:\n            os.unlink(filename)\n\n    daemon_export = property(\n        _get_daemon_export,\n        _set_daemon_export,\n        doc=\"If True, git-daemon may export this repository\",\n    )\n    del _get_daemon_export\n    del _set_daemon_export\n\n    def _get_alternates(self) -> List[str]:\n        \"\"\"The list of alternates for this repo from which objects can be retrieved\n\n        :return: list of strings being pathnames of alternates\"\"\"\n        if self.git_dir:\n            alternates_path = osp.join(self.git_dir, \"objects\", \"info\", \"alternates\")\n\n        if osp.exists(alternates_path):\n            with open(alternates_path, \"rb\") as f:\n                alts = f.read().decode(defenc)\n            return alts.strip().splitlines()\n        return []\n\n    def _set_alternates(self, alts: List[str]) -> None:\n        \"\"\"Sets the alternates\n\n        :param alts:\n            is the array of string paths representing the alternates at which\n            git should look for objects, i.e. /home/user/repo/.git/objects\n\n        :raise NoSuchPathError:\n        :note:\n            The method does not check for the existence of the paths in alts\n            as the caller is responsible.\"\"\"\n        alternates_path = osp.join(self.common_dir, \"objects\", \"info\", \"alternates\")\n        if not alts:\n            if osp.isfile(alternates_path):\n                os.remove(alternates_path)\n        else:\n            with open(alternates_path, \"wb\") as f:\n                f.write(\"\\n\".join(alts).encode(defenc))\n\n    alternates = property(\n        _get_alternates,\n        _set_alternates,\n        doc=\"Retrieve a list of alternates paths or set a list paths to be used as alternates\",\n    )\n\n    def is_dirty(\n        self,\n        index: bool = True,\n        working_tree: bool = True,\n        untracked_files: bool = False,\n        submodules: bool = True,\n        path: Optional[PathLike] = None,\n    ) -> bool:\n        \"\"\"\n        :return:\n            ``True``, the repository is considered dirty. By default it will react\n            like a git-status without untracked files, hence it is dirty if the\n            index or the working copy have changes.\"\"\"\n        if self._bare:\n            # Bare repositories with no associated working directory are\n            # always considered to be clean.\n            return False\n\n        # start from the one which is fastest to evaluate\n        default_args = [\"--abbrev=40\", \"--full-index\", \"--raw\"]\n        if not submodules:\n            default_args.append(\"--ignore-submodules\")\n        if path:\n            default_args.extend([\"--\", str(path)])\n        if index:\n            # diff index against HEAD\n            if osp.isfile(self.index.path) and len(self.git.diff(\"--cached\", *default_args)):\n                return True\n        # END index handling\n        if working_tree:\n            # diff index against working tree\n            if len(self.git.diff(*default_args)):\n                return True\n        # END working tree handling\n        if untracked_files:\n            if len(self._get_untracked_files(path, ignore_submodules=not submodules)):\n                return True\n        # END untracked files\n        return False\n\n    @property\n    def untracked_files(self) -> List[str]:\n        \"\"\"\n        :return:\n            list(str,...)\n\n            Files currently untracked as they have not been staged yet. Paths\n            are relative to the current working directory of the git command.\n\n        :note:\n            ignored files will not appear here, i.e. files mentioned in .gitignore\n        :note:\n            This property is expensive, as no cache is involved. To process the result, please\n            consider caching it yourself.\"\"\"\n        return self._get_untracked_files()\n\n    def _get_untracked_files(self, *args: Any, **kwargs: Any) -> List[str]:\n        # make sure we get all files, not only untracked directories\n        proc = self.git.status(*args, porcelain=True, untracked_files=True, as_process=True, **kwargs)\n        # Untracked files prefix in porcelain mode\n        prefix = \"?? \"\n        untracked_files = []\n        for line in proc.stdout:\n            line = line.decode(defenc)\n            if not line.startswith(prefix):\n                continue\n            filename = line[len(prefix) :].rstrip(\"\\n\")\n            # Special characters are escaped\n            if filename[0] == filename[-1] == '\"':\n                filename = filename[1:-1]\n                # WHATEVER ... it's a mess, but works for me\n                filename = filename.encode(\"ascii\").decode(\"unicode_escape\").encode(\"latin1\").decode(defenc)\n            untracked_files.append(filename)\n        finalize_process(proc)\n        return untracked_files\n\n    def ignored(self, *paths: PathLike) -> List[str]:\n        \"\"\"Checks if paths are ignored via .gitignore\n        Doing so using the \"git check-ignore\" method.\n\n        :param paths: List of paths to check whether they are ignored or not\n        :return: subset of those paths which are ignored\n        \"\"\"\n        try:\n            proc: str = self.git.check_ignore(*paths)\n        except GitCommandError as err:\n            # If return code is 1, this means none of the items in *paths\n            # are ignored by Git, so return an empty list.  Raise the\n            # exception on all other return codes.\n            if err.status == 1:\n                return []\n            else:\n                raise\n\n        return proc.replace(\"\\\\\\\\\", \"\\\\\").replace('\"', \"\").split(\"\\n\")\n\n    @property\n    def active_branch(self) -> Head:\n        \"\"\"The name of the currently active branch.\n\n        :raises\tTypeError: If HEAD is detached\n        :return: Head to the active branch\"\"\"\n        # reveal_type(self.head.reference)  # => Reference\n        return self.head.reference\n\n    def blame_incremental(self, rev: str | HEAD, file: str, **kwargs: Any) -> Iterator[\"BlameEntry\"]:\n        \"\"\"Iterator for blame information for the given file at the given revision.\n\n        Unlike .blame(), this does not return the actual file's contents, only\n        a stream of BlameEntry tuples.\n\n        :param rev: revision specifier, see git-rev-parse for viable options.\n        :return: lazy iterator of BlameEntry tuples, where the commit\n                 indicates the commit to blame for the line, and range\n                 indicates a span of line numbers in the resulting file.\n\n        If you combine all line number ranges outputted by this command, you\n        should get a continuous range spanning all line numbers in the file.\n        \"\"\"\n\n        data: bytes = self.git.blame(rev, \"--\", file, p=True, incremental=True, stdout_as_string=False, **kwargs)\n        commits: Dict[bytes, Commit] = {}\n\n        stream = (line for line in data.split(b\"\\n\") if line)\n        while True:\n            try:\n                line = next(stream)  # when exhausted, causes a StopIteration, terminating this function\n            except StopIteration:\n                return\n            split_line = line.split()\n            hexsha, orig_lineno_b, lineno_b, num_lines_b = split_line\n            lineno = int(lineno_b)\n            num_lines = int(num_lines_b)\n            orig_lineno = int(orig_lineno_b)\n            if hexsha not in commits:\n                # Now read the next few lines and build up a dict of properties\n                # for this commit\n                props: Dict[bytes, bytes] = {}\n                while True:\n                    try:\n                        line = next(stream)\n                    except StopIteration:\n                        return\n                    if line == b\"boundary\":\n                        # \"boundary\" indicates a root commit and occurs\n                        # instead of the \"previous\" tag\n                        continue\n\n                    tag, value = line.split(b\" \", 1)\n                    props[tag] = value\n                    if tag == b\"filename\":\n                        # \"filename\" formally terminates the entry for --incremental\n                        orig_filename = value\n                        break\n\n                c = Commit(\n                    self,\n                    hex_to_bin(hexsha),\n                    author=Actor(\n                        safe_decode(props[b\"author\"]),\n                        safe_decode(props[b\"author-mail\"].lstrip(b\"<\").rstrip(b\">\")),\n                    ),\n                    authored_date=int(props[b\"author-time\"]),\n                    committer=Actor(\n                        safe_decode(props[b\"committer\"]),\n                        safe_decode(props[b\"committer-mail\"].lstrip(b\"<\").rstrip(b\">\")),\n                    ),\n                    committed_date=int(props[b\"committer-time\"]),\n                )\n                commits[hexsha] = c\n            else:\n                # Discard all lines until we find \"filename\" which is\n                # guaranteed to be the last line\n                while True:\n                    try:\n                        line = next(stream)  # will fail if we reach the EOF unexpectedly\n                    except StopIteration:\n                        return\n                    tag, value = line.split(b\" \", 1)\n                    if tag == b\"filename\":\n                        orig_filename = value\n                        break\n\n            yield BlameEntry(\n                commits[hexsha],\n                range(lineno, lineno + num_lines),\n                safe_decode(orig_filename),\n                range(orig_lineno, orig_lineno + num_lines),\n            )\n\n    def blame(\n        self,\n        rev: Union[str, HEAD],\n        file: str,\n        incremental: bool = False,\n        rev_opts: Optional[List[str]] = None,\n        **kwargs: Any,\n    ) -> List[List[Commit | List[str | bytes] | None]] | Iterator[BlameEntry] | None:\n        \"\"\"The blame information for the given file at the given revision.\n\n        :param rev: revision specifier, see git-rev-parse for viable options.\n        :return:\n            list: [git.Commit, list: [<line>]]\n            A list of lists associating a Commit object with a list of lines that\n            changed within the given commit. The Commit objects will be given in order\n            of appearance.\"\"\"\n        if incremental:\n            return self.blame_incremental(rev, file, **kwargs)\n        rev_opts = rev_opts or []\n        data: bytes = self.git.blame(rev, *rev_opts, \"--\", file, p=True, stdout_as_string=False, **kwargs)\n        commits: Dict[str, Commit] = {}\n        blames: List[List[Commit | List[str | bytes] | None]] = []\n\n        class InfoTD(TypedDict, total=False):\n            sha: str\n            id: str\n            filename: str\n            summary: str\n            author: str\n            author_email: str\n            author_date: int\n            committer: str\n            committer_email: str\n            committer_date: int\n\n        info: InfoTD = {}\n\n        keepends = True\n        for line_bytes in data.splitlines(keepends):\n            try:\n                line_str = line_bytes.rstrip().decode(defenc)\n            except UnicodeDecodeError:\n                firstpart = \"\"\n                parts = []\n                is_binary = True\n            else:\n                # As we don't have an idea when the binary data ends, as it could contain multiple newlines\n                # in the process. So we rely on being able to decode to tell us what is is.\n                # This can absolutely fail even on text files, but even if it does, we should be fine treating it\n                # as binary instead\n                parts = self.re_whitespace.split(line_str, 1)\n                firstpart = parts[0]\n                is_binary = False\n            # end handle decode of line\n\n            if self.re_hexsha_only.search(firstpart):\n                # handles\n                # 634396b2f541a9f2d58b00be1a07f0c358b999b3 1 1 7        - indicates blame-data start\n                # 634396b2f541a9f2d58b00be1a07f0c358b999b3 2 2          - indicates\n                # another line of blame with the same data\n                digits = parts[-1].split(\" \")\n                if len(digits) == 3:\n                    info = {\"id\": firstpart}\n                    blames.append([None, []])\n                elif info[\"id\"] != firstpart:\n                    info = {\"id\": firstpart}\n                    blames.append([commits.get(firstpart), []])\n                # END blame data initialization\n            else:\n                m = self.re_author_committer_start.search(firstpart)\n                if m:\n                    # handles:\n                    # author Tom Preston-Werner\n                    # author-mail <tom@mojombo.com>\n                    # author-time 1192271832\n                    # author-tz -0700\n                    # committer Tom Preston-Werner\n                    # committer-mail <tom@mojombo.com>\n                    # committer-time 1192271832\n                    # committer-tz -0700  - IGNORED BY US\n                    role = m.group(0)\n                    if role == \"author\":\n                        if firstpart.endswith(\"-mail\"):\n                            info[\"author_email\"] = parts[-1]\n                        elif firstpart.endswith(\"-time\"):\n                            info[\"author_date\"] = int(parts[-1])\n                        elif role == firstpart:\n                            info[\"author\"] = parts[-1]\n                    elif role == \"committer\":\n                        if firstpart.endswith(\"-mail\"):\n                            info[\"committer_email\"] = parts[-1]\n                        elif firstpart.endswith(\"-time\"):\n                            info[\"committer_date\"] = int(parts[-1])\n                        elif role == firstpart:\n                            info[\"committer\"] = parts[-1]\n                    # END distinguish mail,time,name\n                else:\n                    # handle\n                    # filename lib/grit.rb\n                    # summary add Blob\n                    # <and rest>\n                    if firstpart.startswith(\"filename\"):\n                        info[\"filename\"] = parts[-1]\n                    elif firstpart.startswith(\"summary\"):\n                        info[\"summary\"] = parts[-1]\n                    elif firstpart == \"\":\n                        if info:\n                            sha = info[\"id\"]\n                            c = commits.get(sha)\n                            if c is None:\n                                c = Commit(\n                                    self,\n                                    hex_to_bin(sha),\n                                    author=Actor._from_string(f\"{info['author']} {info['author_email']}\"),\n                                    authored_date=info[\"author_date\"],\n                                    committer=Actor._from_string(f\"{info['committer']} {info['committer_email']}\"),\n                                    committed_date=info[\"committer_date\"],\n                                )\n                                commits[sha] = c\n                            blames[-1][0] = c\n                            # END if commit objects needs initial creation\n\n                            if blames[-1][1] is not None:\n                                line: str | bytes\n                                if not is_binary:\n                                    if line_str and line_str[0] == \"\\t\":\n                                        line_str = line_str[1:]\n                                    line = line_str\n                                else:\n                                    line = line_bytes\n                                    # NOTE: We are actually parsing lines out of binary data, which can lead to the\n                                    # binary being split up along the newline separator. We will append this to the\n                                    # blame we are currently looking at, even though it should be concatenated with\n                                    # the last line we have seen.\n                                blames[-1][1].append(line)\n\n                            info = {\"id\": sha}\n                        # END if we collected commit info\n                    # END distinguish filename,summary,rest\n                # END distinguish author|committer vs filename,summary,rest\n            # END distinguish hexsha vs other information\n        return blames\n\n    @classmethod\n    def init(\n        cls,\n        path: Union[PathLike, None] = None,\n        mkdir: bool = True,\n        odbt: Type[GitCmdObjectDB] = GitCmdObjectDB,\n        expand_vars: bool = True,\n        **kwargs: Any,\n    ) -> \"Repo\":\n        \"\"\"Initialize a git repository at the given path if specified\n\n        :param path:\n            is the full path to the repo (traditionally ends with /<name>.git)\n            or None in which case the repository will be created in the current\n            working directory\n\n        :param mkdir:\n            if specified will create the repository directory if it doesn't\n            already exists. Creates the directory with a mode=0755.\n            Only effective if a path is explicitly given\n\n        :param odbt:\n            Object DataBase type - a type which is constructed by providing\n            the directory containing the database objects, i.e. .git/objects.\n            It will be used to access all object data\n\n        :param expand_vars:\n            if specified, environment variables will not be escaped. This\n            can lead to information disclosure, allowing attackers to\n            access the contents of environment variables\n\n        :param kwargs:\n            keyword arguments serving as additional options to the git-init command\n\n        :return: ``git.Repo`` (the newly created repo)\"\"\"\n        if path:\n            path = expand_path(path, expand_vars)\n        if mkdir and path and not osp.exists(path):\n            os.makedirs(path, 0o755)\n\n        # git command automatically chdir into the directory\n        git = cls.GitCommandWrapperType(path)\n        git.init(**kwargs)\n        return cls(path, odbt=odbt)\n\n    @classmethod\n    def _clone(\n        cls,\n        git: \"Git\",\n        url: PathLike,\n        path: PathLike,\n        odb_default_type: Type[GitCmdObjectDB],\n        progress: Union[\"RemoteProgress\", \"UpdateProgress\", Callable[..., \"RemoteProgress\"], None] = None,\n        multi_options: Optional[List[str]] = None,\n        allow_unsafe_protocols: bool = False,\n        allow_unsafe_options: bool = False,\n        **kwargs: Any,\n    ) -> \"Repo\":\n        odbt = kwargs.pop(\"odbt\", odb_default_type)\n\n        # when pathlib.Path or other classbased path is passed\n        if not isinstance(path, str):\n            path = str(path)\n\n        ## A bug win cygwin's Git, when `--bare` or `--separate-git-dir`\n        #  it prepends the cwd or(?) the `url` into the `path, so::\n        #        git clone --bare  /cygwin/d/foo.git  C:\\\\Work\n        #  becomes::\n        #        git clone --bare  /cygwin/d/foo.git  /cygwin/d/C:\\\\Work\n        #\n        clone_path = Git.polish_url(path) if Git.is_cygwin() and \"bare\" in kwargs else path\n        sep_dir = kwargs.get(\"separate_git_dir\")\n        if sep_dir:\n            kwargs[\"separate_git_dir\"] = Git.polish_url(sep_dir)\n        multi = None\n        if multi_options:\n            multi = shlex.split(\" \".join(multi_options))\n\n        if not allow_unsafe_protocols:\n            Git.check_unsafe_protocols(str(url))\n        if not allow_unsafe_options and multi_options:\n            Git.check_unsafe_options(options=multi_options, unsafe_options=cls.unsafe_git_clone_options)\n\n        proc = git.clone(\n            multi,\n            \"--\",\n            Git.polish_url(str(url)),\n            clone_path,\n            with_extended_output=True,\n            as_process=True,\n            v=True,\n            universal_newlines=True,\n            **add_progress(kwargs, git, progress),\n        )\n        if progress:\n            handle_process_output(\n                proc,\n                None,\n                to_progress_instance(progress).new_message_handler(),\n                finalize_process,\n                decode_streams=False,\n            )\n        else:\n            (stdout, stderr) = proc.communicate()\n            cmdline = getattr(proc, \"args\", \"\")\n            cmdline = remove_password_if_present(cmdline)\n\n            log.debug(\"Cmd(%s)'s unused stdout: %s\", cmdline, stdout)\n            finalize_process(proc, stderr=stderr)\n\n        # our git command could have a different working dir than our actual\n        # environment, hence we prepend its working dir if required\n        if not osp.isabs(path):\n            path = osp.join(git._working_dir, path) if git._working_dir is not None else path\n\n        repo = cls(path, odbt=odbt)\n\n        # retain env values that were passed to _clone()\n        repo.git.update_environment(**git.environment())\n\n        # adjust remotes - there may be operating systems which use backslashes,\n        # These might be given as initial paths, but when handling the config file\n        # that contains the remote from which we were clones, git stops liking it\n        # as it will escape the backslashes. Hence we undo the escaping just to be\n        # sure\n        if repo.remotes:\n            with repo.remotes[0].config_writer as writer:\n                writer.set_value(\"url\", Git.polish_url(repo.remotes[0].url))\n        # END handle remote repo\n        return repo\n\n    def clone(\n        self,\n        path: PathLike,\n        progress: Optional[Callable] = None,\n        multi_options: Optional[List[str]] = None,\n        allow_unsafe_protocols: bool = False,\n        allow_unsafe_options: bool = False,\n        **kwargs: Any,\n    ) -> \"Repo\":\n        \"\"\"Create a clone from this repository.\n\n        :param path: is the full path of the new repo (traditionally ends with ./<name>.git).\n        :param progress: See 'git.remote.Remote.push'.\n        :param multi_options: A list of Clone options that can be provided multiple times.  One\n            option per list item which is passed exactly as specified to clone.\n            For example ['--config core.filemode=false', '--config core.ignorecase',\n            '--recurse-submodule=repo1_path', '--recurse-submodule=repo2_path']\n        :param allow_unsafe_protocols: Allow unsafe protocols to be used, like ext\n        :param allow_unsafe_options: Allow unsafe options to be used, like --upload-pack\n        :param kwargs:\n            * odbt = ObjectDatabase Type, allowing to determine the object database\n              implementation used by the returned Repo instance\n            * All remaining keyword arguments are given to the git-clone command\n\n        :return: ``git.Repo`` (the newly cloned repo)\"\"\"\n        return self._clone(\n            self.git,\n            self.common_dir,\n            path,\n            type(self.odb),\n            progress,\n            multi_options,\n            allow_unsafe_protocols=allow_unsafe_protocols,\n            allow_unsafe_options=allow_unsafe_options,\n            **kwargs,\n        )\n\n    @classmethod\n    def clone_from(\n        cls,\n        url: PathLike,\n        to_path: PathLike,\n        progress: Optional[Callable] = None,\n        env: Optional[Mapping[str, str]] = None,\n        multi_options: Optional[List[str]] = None,\n        allow_unsafe_protocols: bool = False,\n        allow_unsafe_options: bool = False,\n        **kwargs: Any,\n    ) -> \"Repo\":\n        \"\"\"Create a clone from the given URL\n\n        :param url: valid git url, see http://www.kernel.org/pub/software/scm/git/docs/git-clone.html#URLS\n        :param to_path: Path to which the repository should be cloned to\n        :param progress: See 'git.remote.Remote.push'.\n        :param env: Optional dictionary containing the desired environment variables.\n            Note: Provided variables will be used to update the execution\n            environment for `git`. If some variable is not specified in `env`\n            and is defined in `os.environ`, value from `os.environ` will be used.\n            If you want to unset some variable, consider providing empty string\n            as its value.\n        :param multi_options: See ``clone`` method\n        :param allow_unsafe_protocols: Allow unsafe protocols to be used, like ext\n        :param allow_unsafe_options: Allow unsafe options to be used, like --upload-pack\n        :param kwargs: see the ``clone`` method\n        :return: Repo instance pointing to the cloned directory\"\"\"\n        git = cls.GitCommandWrapperType(os.getcwd())\n        if env is not None:\n            git.update_environment(**env)\n        return cls._clone(\n            git,\n            url,\n            to_path,\n            GitCmdObjectDB,\n            progress,\n            multi_options,\n            allow_unsafe_protocols=allow_unsafe_protocols,\n            allow_unsafe_options=allow_unsafe_options,\n            **kwargs,\n        )\n\n    def archive(\n        self,\n        ostream: Union[TextIO, BinaryIO],\n        treeish: Optional[str] = None,\n        prefix: Optional[str] = None,\n        **kwargs: Any,\n    ) -> Repo:\n        \"\"\"Archive the tree at the given revision.\n\n        :param ostream: file compatible stream object to which the archive will be written as bytes\n        :param treeish: is the treeish name/id, defaults to active branch\n        :param prefix: is the optional prefix to prepend to each filename in the archive\n        :param kwargs: Additional arguments passed to git-archive\n\n            * Use the 'format' argument to define the kind of format. Use\n              specialized ostreams to write any format supported by python.\n            * You may specify the special **path** keyword, which may either be a repository-relative\n              path to a directory or file to place into the archive, or a list or tuple of multiple paths.\n\n        :raise GitCommandError: in case something went wrong\n        :return: self\"\"\"\n        if treeish is None:\n            treeish = self.head.commit\n        if prefix and \"prefix\" not in kwargs:\n            kwargs[\"prefix\"] = prefix\n        kwargs[\"output_stream\"] = ostream\n        path = kwargs.pop(\"path\", [])\n        path = cast(Union[PathLike, List[PathLike], Tuple[PathLike, ...]], path)\n        if not isinstance(path, (tuple, list)):\n            path = [path]\n        # end assure paths is list\n        self.git.archive(\"--\", treeish, *path, **kwargs)\n        return self\n\n    def has_separate_working_tree(self) -> bool:\n        \"\"\"\n        :return: True if our git_dir is not at the root of our working_tree_dir, but a .git file with a\n            platform agnositic symbolic link. Our git_dir will be wherever the .git file points to\n        :note: bare repositories will always return False here\n        \"\"\"\n        if self.bare:\n            return False\n        if self.working_tree_dir:\n            return osp.isfile(osp.join(self.working_tree_dir, \".git\"))\n        else:\n            return False  # or raise Error?\n\n    rev_parse = rev_parse\n\n    def __repr__(self) -> str:\n        clazz = self.__class__\n        return \"<%s.%s %r>\" % (clazz.__module__, clazz.__name__, self.git_dir)\n\n    def currently_rebasing_on(self) -> Commit | None:\n        \"\"\"\n        :return: The commit which is currently being replayed while rebasing.\n\n        None if we are not currently rebasing.\n        \"\"\"\n        if self.git_dir:\n            rebase_head_file = osp.join(self.git_dir, \"REBASE_HEAD\")\n        if not osp.isfile(rebase_head_file):\n            return None\n        with open(rebase_head_file, \"rt\") as f:\n            content = f.readline().strip()\n        return self.commit(content)\n", "# -*- coding: utf-8 -*-\n# test_repo.py\n# Copyright (C) 2008, 2009 Michael Trier (mtrier@gmail.com) and contributors\n#\n# This module is part of GitPython and is released under\n# the BSD License: http://www.opensource.org/licenses/bsd-license.php\nimport glob\nimport io\nfrom io import BytesIO\nimport itertools\nimport os\nimport pathlib\nimport pickle\nimport sys\nimport tempfile\nfrom unittest import mock, skipIf, SkipTest\n\nimport pytest\n\nfrom git import (\n    InvalidGitRepositoryError,\n    Repo,\n    NoSuchPathError,\n    Head,\n    Commit,\n    Object,\n    Tree,\n    IndexFile,\n    Git,\n    Reference,\n    GitDB,\n    Submodule,\n    GitCmdObjectDB,\n    Remote,\n    BadName,\n    GitCommandError,\n)\nfrom git.exc import (\n    BadObject,\n    UnsafeOptionError,\n    UnsafeProtocolError,\n)\nfrom git.repo.fun import touch\nfrom test.lib import TestBase, with_rw_repo, fixture\nfrom git.util import HIDE_WINDOWS_KNOWN_ERRORS, cygpath\nfrom test.lib import with_rw_directory\nfrom git.util import join_path_native, rmtree, rmfile, bin_to_hex\n\nimport os.path as osp\n\n\ndef iter_flatten(lol):\n    for items in lol:\n        for item in items:\n            yield item\n\n\ndef flatten(lol):\n    return list(iter_flatten(lol))\n\n\n_tc_lock_fpaths = osp.join(osp.dirname(__file__), \"../../.git/*.lock\")\n\n\ndef _rm_lock_files():\n    for lfp in glob.glob(_tc_lock_fpaths):\n        rmfile(lfp)\n\n\nclass TestRepo(TestBase):\n    def setUp(self):\n        _rm_lock_files()\n\n    def tearDown(self):\n        for lfp in glob.glob(_tc_lock_fpaths):\n            if osp.isfile(lfp):\n                raise AssertionError(\"Previous TC left hanging git-lock file: {}\".format(lfp))\n        import gc\n\n        gc.collect()\n\n    def test_new_should_raise_on_invalid_repo_location(self):\n        self.assertRaises(InvalidGitRepositoryError, Repo, tempfile.gettempdir())\n\n    def test_new_should_raise_on_non_existent_path(self):\n        self.assertRaises(NoSuchPathError, Repo, \"repos/foobar\")\n\n    @with_rw_repo(\"0.3.2.1\")\n    def test_repo_creation_from_different_paths(self, rw_repo):\n        r_from_gitdir = Repo(rw_repo.git_dir)\n        self.assertEqual(r_from_gitdir.git_dir, rw_repo.git_dir)\n        assert r_from_gitdir.git_dir.endswith(\".git\")\n        assert not rw_repo.git.working_dir.endswith(\".git\")\n        self.assertEqual(r_from_gitdir.git.working_dir, rw_repo.git.working_dir)\n\n    @with_rw_repo(\"0.3.2.1\")\n    def test_repo_creation_pathlib(self, rw_repo):\n        r_from_gitdir = Repo(pathlib.Path(rw_repo.git_dir))\n        self.assertEqual(r_from_gitdir.git_dir, rw_repo.git_dir)\n\n    def test_description(self):\n        txt = \"Test repository\"\n        self.rorepo.description = txt\n        self.assertEqual(self.rorepo.description, txt)\n\n    def test_heads_should_return_array_of_head_objects(self):\n        for head in self.rorepo.heads:\n            self.assertEqual(Head, head.__class__)\n\n    def test_heads_should_populate_head_data(self):\n        for head in self.rorepo.heads:\n            assert head.name\n            self.assertIsInstance(head.commit, Commit)\n        # END for each head\n\n        self.assertIsInstance(self.rorepo.heads.master, Head)\n        self.assertIsInstance(self.rorepo.heads[\"master\"], Head)\n\n    def test_tree_from_revision(self):\n        tree = self.rorepo.tree(\"0.1.6\")\n        self.assertEqual(len(tree.hexsha), 40)\n        self.assertEqual(tree.type, \"tree\")\n        self.assertEqual(self.rorepo.tree(tree), tree)\n\n        # try from invalid revision that does not exist\n        self.assertRaises(BadName, self.rorepo.tree, \"hello world\")\n\n    def test_pickleable(self):\n        pickle.loads(pickle.dumps(self.rorepo))\n\n    def test_commit_from_revision(self):\n        commit = self.rorepo.commit(\"0.1.4\")\n        self.assertEqual(commit.type, \"commit\")\n        self.assertEqual(self.rorepo.commit(commit), commit)\n\n    def test_commits(self):\n        mc = 10\n        commits = list(self.rorepo.iter_commits(\"0.1.6\", max_count=mc))\n        self.assertEqual(len(commits), mc)\n\n        c = commits[0]\n        self.assertEqual(\"9a4b1d4d11eee3c5362a4152216376e634bd14cf\", c.hexsha)\n        self.assertEqual([\"c76852d0bff115720af3f27acdb084c59361e5f6\"], [p.hexsha for p in c.parents])\n        self.assertEqual(\"ce41fc29549042f1aa09cc03174896cf23f112e3\", c.tree.hexsha)\n        self.assertEqual(\"Michael Trier\", c.author.name)\n        self.assertEqual(\"mtrier@gmail.com\", c.author.email)\n        self.assertEqual(1232829715, c.authored_date)\n        self.assertEqual(5 * 3600, c.author_tz_offset)\n        self.assertEqual(\"Michael Trier\", c.committer.name)\n        self.assertEqual(\"mtrier@gmail.com\", c.committer.email)\n        self.assertEqual(1232829715, c.committed_date)\n        self.assertEqual(5 * 3600, c.committer_tz_offset)\n        self.assertEqual(\"Bumped version 0.1.6\\n\", c.message)\n\n        c = commits[1]\n        self.assertIsInstance(c.parents, tuple)\n\n    def test_trees(self):\n        mc = 30\n        num_trees = 0\n        for tree in self.rorepo.iter_trees(\"0.1.5\", max_count=mc):\n            num_trees += 1\n            self.assertIsInstance(tree, Tree)\n        # END for each tree\n        self.assertEqual(num_trees, mc)\n\n    def _assert_empty_repo(self, repo):\n        # test all kinds of things with an empty, freshly initialized repo.\n        # It should throw good errors\n\n        # entries should be empty\n        self.assertEqual(len(repo.index.entries), 0)\n\n        # head is accessible\n        assert repo.head\n        assert repo.head.ref\n        assert not repo.head.is_valid()\n\n        # we can change the head to some other ref\n        head_ref = Head.from_path(repo, Head.to_full_path(\"some_head\"))\n        assert not head_ref.is_valid()\n        repo.head.ref = head_ref\n\n        # is_dirty can handle all kwargs\n        for args in ((1, 0, 0), (0, 1, 0), (0, 0, 1)):\n            assert not repo.is_dirty(*args)\n        # END for each arg\n\n        # we can add a file to the index ( if we are not bare )\n        if not repo.bare:\n            pass\n        # END test repos with working tree\n\n    @with_rw_directory\n    def test_clone_from_keeps_env(self, rw_dir):\n        original_repo = Repo.init(osp.join(rw_dir, \"repo\"))\n        environment = {\"entry1\": \"value\", \"another_entry\": \"10\"}\n\n        cloned = Repo.clone_from(original_repo.git_dir, osp.join(rw_dir, \"clone\"), env=environment)\n\n        self.assertEqual(environment, cloned.git.environment())\n\n    @with_rw_directory\n    def test_date_format(self, rw_dir):\n        repo = Repo.init(osp.join(rw_dir, \"repo\"))\n        # @-timestamp is the format used by git commit hooks\n        repo.index.commit(\"Commit messages\", commit_date=\"@1400000000 +0000\")\n\n    @with_rw_directory\n    def test_clone_from_pathlib(self, rw_dir):\n        original_repo = Repo.init(osp.join(rw_dir, \"repo\"))\n\n        Repo.clone_from(original_repo.git_dir, pathlib.Path(rw_dir) / \"clone_pathlib\")\n\n    @with_rw_directory\n    def test_clone_from_pathlib_withConfig(self, rw_dir):\n        original_repo = Repo.init(osp.join(rw_dir, \"repo\"))\n\n        cloned = Repo.clone_from(\n            original_repo.git_dir,\n            pathlib.Path(rw_dir) / \"clone_pathlib_withConfig\",\n            multi_options=[\n                \"--recurse-submodules=repo\",\n                \"--config core.filemode=false\",\n                \"--config submodule.repo.update=checkout\",\n                \"--config filter.lfs.clean='git-lfs clean -- %f'\",\n            ],\n            allow_unsafe_options=True,\n        )\n\n        self.assertEqual(cloned.config_reader().get_value(\"submodule\", \"active\"), \"repo\")\n        self.assertEqual(cloned.config_reader().get_value(\"core\", \"filemode\"), False)\n        self.assertEqual(cloned.config_reader().get_value('submodule \"repo\"', \"update\"), \"checkout\")\n        self.assertEqual(\n            cloned.config_reader().get_value('filter \"lfs\"', \"clean\"),\n            \"git-lfs clean -- %f\",\n        )\n\n    def test_clone_from_with_path_contains_unicode(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            unicode_dir_name = \"\\u0394\"\n            path_with_unicode = os.path.join(tmpdir, unicode_dir_name)\n            os.makedirs(path_with_unicode)\n\n            try:\n                Repo.clone_from(\n                    url=self._small_repo_url(),\n                    to_path=path_with_unicode,\n                )\n            except UnicodeEncodeError:\n                self.fail(\"Raised UnicodeEncodeError\")\n\n    @with_rw_directory\n    def test_leaking_password_in_clone_logs(self, rw_dir):\n        password = \"fakepassword1234\"\n        try:\n            Repo.clone_from(\n                url=\"https://fakeuser:{}@fakerepo.example.com/testrepo\".format(password),\n                to_path=rw_dir,\n            )\n        except GitCommandError as err:\n            assert password not in str(err), \"The error message '%s' should not contain the password\" % err\n        # Working example from a blank private project\n        Repo.clone_from(\n            url=\"https://gitlab+deploy-token-392045:mLWhVus7bjLsy8xj8q2V@gitlab.com/mercierm/test_git_python\",\n            to_path=rw_dir,\n        )\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_unsafe_options(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            unsafe_options = [\n                f\"--upload-pack='touch {tmp_file}'\",\n                f\"-u 'touch {tmp_file}'\",\n                \"--config=protocol.ext.allow=always\",\n                \"-c protocol.ext.allow=always\",\n            ]\n            for unsafe_option in unsafe_options:\n                with self.assertRaises(UnsafeOptionError):\n                    rw_repo.clone(tmp_dir, multi_options=[unsafe_option])\n                assert not tmp_file.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_unsafe_options_allowed(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            unsafe_options = [\n                f\"--upload-pack='touch {tmp_file}'\",\n                f\"-u 'touch {tmp_file}'\",\n            ]\n            for i, unsafe_option in enumerate(unsafe_options):\n                destination = tmp_dir / str(i)\n                assert not tmp_file.exists()\n                # The options will be allowed, but the command will fail.\n                with self.assertRaises(GitCommandError):\n                    rw_repo.clone(destination, multi_options=[unsafe_option], allow_unsafe_options=True)\n                assert tmp_file.exists()\n                tmp_file.unlink()\n\n            unsafe_options = [\n                \"--config=protocol.ext.allow=always\",\n                \"-c protocol.ext.allow=always\",\n            ]\n            for i, unsafe_option in enumerate(unsafe_options):\n                destination = tmp_dir / str(i)\n                assert not destination.exists()\n                rw_repo.clone(destination, multi_options=[unsafe_option], allow_unsafe_options=True)\n                assert destination.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_safe_options(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            options = [\n                \"--depth=1\",\n                \"--single-branch\",\n                \"-q\",\n            ]\n            for option in options:\n                destination = tmp_dir / option\n                assert not destination.exists()\n                rw_repo.clone(destination, multi_options=[option])\n                assert destination.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_from_unsafe_options(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            unsafe_options = [\n                f\"--upload-pack='touch {tmp_file}'\",\n                f\"-u 'touch {tmp_file}'\",\n                \"--config=protocol.ext.allow=always\",\n                \"-c protocol.ext.allow=always\",\n            ]\n            for unsafe_option in unsafe_options:\n                with self.assertRaises(UnsafeOptionError):\n                    Repo.clone_from(rw_repo.working_dir, tmp_dir, multi_options=[unsafe_option])\n                assert not tmp_file.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_from_unsafe_options_allowed(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            unsafe_options = [\n                f\"--upload-pack='touch {tmp_file}'\",\n                f\"-u 'touch {tmp_file}'\",\n            ]\n            for i, unsafe_option in enumerate(unsafe_options):\n                destination = tmp_dir / str(i)\n                assert not tmp_file.exists()\n                # The options will be allowed, but the command will fail.\n                with self.assertRaises(GitCommandError):\n                    Repo.clone_from(\n                        rw_repo.working_dir, destination, multi_options=[unsafe_option], allow_unsafe_options=True\n                    )\n                assert tmp_file.exists()\n                tmp_file.unlink()\n\n            unsafe_options = [\n                \"--config=protocol.ext.allow=always\",\n                \"-c protocol.ext.allow=always\",\n            ]\n            for i, unsafe_option in enumerate(unsafe_options):\n                destination = tmp_dir / str(i)\n                assert not destination.exists()\n                Repo.clone_from(rw_repo.working_dir, destination, multi_options=[unsafe_option], allow_unsafe_options=True)\n                assert destination.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_from_safe_options(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            options = [\n                \"--depth=1\",\n                \"--single-branch\",\n                \"-q\",\n            ]\n            for option in options:\n                destination = tmp_dir / option\n                assert not destination.exists()\n                Repo.clone_from(rw_repo.common_dir, destination, multi_options=[option])\n                assert destination.exists()\n\n    def test_clone_from_unsafe_protocol(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            urls = [\n                f\"ext::sh -c touch% {tmp_file}\",\n                \"fd::17/foo\",\n            ]\n            for url in urls:\n                with self.assertRaises(UnsafeProtocolError):\n                    Repo.clone_from(url, tmp_dir / \"repo\")\n                assert not tmp_file.exists()\n\n    def test_clone_from_unsafe_protocol_allowed(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            urls = [\n                f\"ext::sh -c touch% {tmp_file}\",\n                \"fd::/foo\",\n            ]\n            for url in urls:\n                # The URL will be allowed into the command, but the command will\n                # fail since we don't have that protocol enabled in the Git config file.\n                with self.assertRaises(GitCommandError):\n                    Repo.clone_from(url, tmp_dir / \"repo\", allow_unsafe_protocols=True)\n                assert not tmp_file.exists()\n\n    def test_clone_from_unsafe_protocol_allowed_and_enabled(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            urls = [\n                f\"ext::sh -c touch% {tmp_file}\",\n            ]\n            allow_ext = [\n                \"--config=protocol.ext.allow=always\",\n            ]\n            for url in urls:\n                # The URL will be allowed into the command, and the protocol is enabled,\n                # but the command will fail since it can't read from the remote repo.\n                assert not tmp_file.exists()\n                with self.assertRaises(GitCommandError):\n                    Repo.clone_from(\n                        url,\n                        tmp_dir / \"repo\",\n                        multi_options=allow_ext,\n                        allow_unsafe_protocols=True,\n                        allow_unsafe_options=True,\n                    )\n                assert tmp_file.exists()\n                tmp_file.unlink()\n\n    @with_rw_repo(\"HEAD\")\n    def test_max_chunk_size(self, repo):\n        class TestOutputStream(TestBase):\n            def __init__(self, max_chunk_size):\n                self.max_chunk_size = max_chunk_size\n\n            def write(self, b):\n                self.assertTrue(len(b) <= self.max_chunk_size)\n\n        for chunk_size in [16, 128, 1024]:\n            repo.git.status(output_stream=TestOutputStream(chunk_size), max_chunk_size=chunk_size)\n\n        repo.git.log(\n            n=100,\n            output_stream=TestOutputStream(io.DEFAULT_BUFFER_SIZE),\n            max_chunk_size=None,\n        )\n        repo.git.log(\n            n=100,\n            output_stream=TestOutputStream(io.DEFAULT_BUFFER_SIZE),\n            max_chunk_size=-10,\n        )\n        repo.git.log(n=100, output_stream=TestOutputStream(io.DEFAULT_BUFFER_SIZE))\n\n    def test_init(self):\n        prev_cwd = os.getcwd()\n        os.chdir(tempfile.gettempdir())\n        git_dir_rela = \"repos/foo/bar.git\"\n        del_dir_abs = osp.abspath(\"repos\")\n        git_dir_abs = osp.abspath(git_dir_rela)\n        try:\n            # with specific path\n            for path in (git_dir_rela, git_dir_abs):\n                r = Repo.init(path=path, bare=True)\n                self.assertIsInstance(r, Repo)\n                assert r.bare is True\n                assert not r.has_separate_working_tree()\n                assert osp.isdir(r.git_dir)\n\n                self._assert_empty_repo(r)\n\n                # test clone\n                clone_path = path + \"_clone\"\n                rc = r.clone(clone_path)\n                self._assert_empty_repo(rc)\n\n                try:\n                    rmtree(clone_path)\n                except OSError:\n                    # when relative paths are used, the clone may actually be inside\n                    # of the parent directory\n                    pass\n                # END exception handling\n\n                # try again, this time with the absolute version\n                rc = Repo.clone_from(r.git_dir, clone_path)\n                self._assert_empty_repo(rc)\n\n                rmtree(git_dir_abs)\n                try:\n                    rmtree(clone_path)\n                except OSError:\n                    # when relative paths are used, the clone may actually be inside\n                    # of the parent directory\n                    pass\n                # END exception handling\n\n            # END for each path\n\n            os.makedirs(git_dir_rela)\n            os.chdir(git_dir_rela)\n            r = Repo.init(bare=False)\n            assert r.bare is False\n            assert not r.has_separate_working_tree()\n\n            self._assert_empty_repo(r)\n        finally:\n            try:\n                rmtree(del_dir_abs)\n            except OSError:\n                pass\n            os.chdir(prev_cwd)\n        # END restore previous state\n\n    def test_bare_property(self):\n        self.rorepo.bare\n\n    def test_daemon_export(self):\n        orig_val = self.rorepo.daemon_export\n        self.rorepo.daemon_export = not orig_val\n        self.assertEqual(self.rorepo.daemon_export, (not orig_val))\n        self.rorepo.daemon_export = orig_val\n        self.assertEqual(self.rorepo.daemon_export, orig_val)\n\n    def test_alternates(self):\n        cur_alternates = self.rorepo.alternates\n        # empty alternates\n        self.rorepo.alternates = []\n        self.assertEqual(self.rorepo.alternates, [])\n        alts = [\"other/location\", \"this/location\"]\n        self.rorepo.alternates = alts\n        self.assertEqual(alts, self.rorepo.alternates)\n        self.rorepo.alternates = cur_alternates\n\n    def test_repr(self):\n        assert repr(self.rorepo).startswith(\"<git.repo.base.Repo \")\n\n    def test_is_dirty_with_bare_repository(self):\n        orig_value = self.rorepo._bare\n        self.rorepo._bare = True\n        self.assertFalse(self.rorepo.is_dirty())\n        self.rorepo._bare = orig_value\n\n    def test_is_dirty(self):\n        self.rorepo._bare = False\n        for index in (0, 1):\n            for working_tree in (0, 1):\n                for untracked_files in (0, 1):\n                    assert self.rorepo.is_dirty(index, working_tree, untracked_files) in (True, False)\n                # END untracked files\n            # END working tree\n        # END index\n        orig_val = self.rorepo._bare\n        self.rorepo._bare = True\n        assert self.rorepo.is_dirty() is False\n        self.rorepo._bare = orig_val\n\n    def test_is_dirty_pathspec(self):\n        self.rorepo._bare = False\n        for index in (0, 1):\n            for working_tree in (0, 1):\n                for untracked_files in (0, 1):\n                    assert self.rorepo.is_dirty(index, working_tree, untracked_files, path=\":!foo\") in (True, False)\n                # END untracked files\n            # END working tree\n        # END index\n        orig_val = self.rorepo._bare\n        self.rorepo._bare = True\n        assert self.rorepo.is_dirty() is False\n        self.rorepo._bare = orig_val\n\n    @with_rw_repo(\"HEAD\")\n    def test_is_dirty_with_path(self, rwrepo):\n        assert rwrepo.is_dirty(path=\"git\") is False\n\n        with open(osp.join(rwrepo.working_dir, \"git\", \"util.py\"), \"at\") as f:\n            f.write(\"junk\")\n        assert rwrepo.is_dirty(path=\"git\") is True\n        assert rwrepo.is_dirty(path=\"doc\") is False\n\n        rwrepo.git.add(Git.polish_url(osp.join(\"git\", \"util.py\")))\n        assert rwrepo.is_dirty(index=False, path=\"git\") is False\n        assert rwrepo.is_dirty(path=\"git\") is True\n\n        with open(osp.join(rwrepo.working_dir, \"doc\", \"no-such-file.txt\"), \"wt\") as f:\n            f.write(\"junk\")\n        assert rwrepo.is_dirty(path=\"doc\") is False\n        assert rwrepo.is_dirty(untracked_files=True, path=\"doc\") is True\n\n    def test_head(self):\n        self.assertEqual(self.rorepo.head.reference.object, self.rorepo.active_branch.object)\n\n    def test_index(self):\n        index = self.rorepo.index\n        self.assertIsInstance(index, IndexFile)\n\n    def test_tag(self):\n        assert self.rorepo.tag(\"refs/tags/0.1.5\").commit\n\n    def test_tag_to_full_tag_path(self):\n        tags = [\"0.1.5\", \"tags/0.1.5\", \"refs/tags/0.1.5\"]\n        value_errors = []\n        for tag in tags:\n            try:\n                self.rorepo.tag(tag)\n            except ValueError as valueError:\n                value_errors.append(valueError.args[0])\n        self.assertEqual(value_errors, [])\n\n    def test_archive(self):\n        tmpfile = tempfile.mktemp(suffix=\"archive-test\")\n        with open(tmpfile, \"wb\") as stream:\n            self.rorepo.archive(stream, \"0.1.6\", path=\"doc\")\n            assert stream.tell()\n        os.remove(tmpfile)\n\n    @mock.patch.object(Git, \"_call_process\")\n    def test_should_display_blame_information(self, git):\n        git.return_value = fixture(\"blame\")\n        b = self.rorepo.blame(\"master\", \"lib/git.py\")\n        self.assertEqual(13, len(b))\n        self.assertEqual(2, len(b[0]))\n        # self.assertEqual(25, reduce(lambda acc, x: acc + len(x[-1]), b))\n        self.assertEqual(hash(b[0][0]), hash(b[9][0]))\n        c = b[0][0]\n        self.assertTrue(git.called)\n\n        self.assertEqual(\"634396b2f541a9f2d58b00be1a07f0c358b999b3\", c.hexsha)\n        self.assertEqual(\"Tom Preston-Werner\", c.author.name)\n        self.assertEqual(\"tom@mojombo.com\", c.author.email)\n        self.assertEqual(1191997100, c.authored_date)\n        self.assertEqual(\"Tom Preston-Werner\", c.committer.name)\n        self.assertEqual(\"tom@mojombo.com\", c.committer.email)\n        self.assertEqual(1191997100, c.committed_date)\n        self.assertRaisesRegex(\n            ValueError,\n            \"634396b2f541a9f2d58b00be1a07f0c358b999b3 missing\",\n            lambda: c.message,\n        )\n\n        # test the 'lines per commit' entries\n        tlist = b[0][1]\n        self.assertTrue(tlist)\n        self.assertTrue(isinstance(tlist[0], str))\n        self.assertTrue(len(tlist) < sum(len(t) for t in tlist))  # test for single-char bug\n\n        # BINARY BLAME\n        git.return_value = fixture(\"blame_binary\")\n        blames = self.rorepo.blame(\"master\", \"rps\")\n        self.assertEqual(len(blames), 2)\n\n    def test_blame_real(self):\n        c = 0\n        nml = 0  # amount of multi-lines per blame\n        for item in self.rorepo.head.commit.tree.traverse(\n            predicate=lambda i, d: i.type == \"blob\" and i.path.endswith(\".py\")\n        ):\n            c += 1\n\n            for b in self.rorepo.blame(self.rorepo.head, item.path):\n                nml += int(len(b[1]) > 1)\n        # END for each item to traverse\n        assert c, \"Should have executed at least one blame command\"\n        assert nml, \"There should at least be one blame commit that contains multiple lines\"\n\n    @mock.patch.object(Git, \"_call_process\")\n    def test_blame_incremental(self, git):\n        # loop over two fixtures, create a test fixture for 2.11.1+ syntax\n        for git_fixture in (\"blame_incremental\", \"blame_incremental_2.11.1_plus\"):\n            git.return_value = fixture(git_fixture)\n            blame_output = self.rorepo.blame_incremental(\"9debf6b0aafb6f7781ea9d1383c86939a1aacde3\", \"AUTHORS\")\n            blame_output = list(blame_output)\n            self.assertEqual(len(blame_output), 5)\n\n            # Check all outputted line numbers\n            ranges = flatten([entry.linenos for entry in blame_output])\n            self.assertEqual(\n                ranges,\n                flatten(\n                    [\n                        range(2, 3),\n                        range(14, 15),\n                        range(1, 2),\n                        range(3, 14),\n                        range(15, 17),\n                    ]\n                ),\n            )\n\n            commits = [entry.commit.hexsha[:7] for entry in blame_output]\n            self.assertEqual(commits, [\"82b8902\", \"82b8902\", \"c76852d\", \"c76852d\", \"c76852d\"])\n\n            # Original filenames\n            self.assertSequenceEqual(\n                [entry.orig_path for entry in blame_output],\n                [\"AUTHORS\"] * len(blame_output),\n            )\n\n            # Original line numbers\n            orig_ranges = flatten([entry.orig_linenos for entry in blame_output])\n            self.assertEqual(\n                orig_ranges,\n                flatten(\n                    [\n                        range(2, 3),\n                        range(14, 15),\n                        range(1, 2),\n                        range(2, 13),\n                        range(13, 15),\n                    ]\n                ),\n            )  # noqa E501\n\n    @mock.patch.object(Git, \"_call_process\")\n    def test_blame_complex_revision(self, git):\n        git.return_value = fixture(\"blame_complex_revision\")\n        res = self.rorepo.blame(\"HEAD~10..HEAD\", \"README.md\")\n        self.assertEqual(len(res), 1)\n        self.assertEqual(len(res[0][1]), 83, \"Unexpected amount of parsed blame lines\")\n\n    @mock.patch.object(Git, \"_call_process\")\n    def test_blame_accepts_rev_opts(self, git):\n        res = self.rorepo.blame(\"HEAD\", \"README.md\", rev_opts=[\"-M\", \"-C\", \"-C\"])\n        expected_args = ['blame', 'HEAD', '-M', '-C', '-C', '--', 'README.md']\n        boilerplate_kwargs = {\"p\" : True, \"stdout_as_string\": False}\n        git.assert_called_once_with(*expected_args, **boilerplate_kwargs)\n\n    @skipIf(\n        HIDE_WINDOWS_KNOWN_ERRORS and Git.is_cygwin(),\n        \"\"\"FIXME: File \"C:\\\\projects\\\\gitpython\\\\git\\\\cmd.py\", line 671, in execute\n                    raise GitCommandError(command, status, stderr_value, stdout_value)\n                GitCommandError: Cmd('git') failed due to: exit code(128)\n                  cmdline: git add 1__\ufffd\ufffdava verb\ufffd\ufffdten 1_test _myfile 1_test_other_file\n                          1_\ufffd\ufffdava-----verb\ufffd\ufffdten\n                  stderr: 'fatal: pathspec '\"1__\u00e7ava verb\u00f6ten\"' did not match any files'\n                \"\"\",\n    )\n    @with_rw_repo(\"HEAD\", bare=False)\n    def test_untracked_files(self, rwrepo):\n        for run, repo_add in enumerate((rwrepo.index.add, rwrepo.git.add)):\n            base = rwrepo.working_tree_dir\n            files = (\n                join_path_native(base, \"%i_test _myfile\" % run),\n                join_path_native(base, \"%i_test_other_file\" % run),\n                join_path_native(base, \"%i__\u00e7ava verb\u00f6ten\" % run),\n                join_path_native(base, \"%i_\u00e7ava-----verb\u00f6ten\" % run),\n            )\n\n            num_recently_untracked = 0\n            for fpath in files:\n                with open(fpath, \"wb\"):\n                    pass\n            untracked_files = rwrepo.untracked_files\n            num_recently_untracked = len(untracked_files)\n\n            # assure we have all names - they are relative to the git-dir\n            num_test_untracked = 0\n            for utfile in untracked_files:\n                num_test_untracked += join_path_native(base, utfile) in files\n            self.assertEqual(len(files), num_test_untracked)\n\n            repo_add(untracked_files)\n            self.assertEqual(len(rwrepo.untracked_files), (num_recently_untracked - len(files)))\n        # end for each run\n\n    def test_config_reader(self):\n        reader = self.rorepo.config_reader()  # all config files\n        assert reader.read_only\n        reader = self.rorepo.config_reader(\"repository\")  # single config file\n        assert reader.read_only\n\n    def test_config_writer(self):\n        for config_level in self.rorepo.config_level:\n            try:\n                with self.rorepo.config_writer(config_level) as writer:\n                    self.assertFalse(writer.read_only)\n            except IOError:\n                # its okay not to get a writer for some configuration files if we\n                # have no permissions\n                pass\n\n    def test_config_level_paths(self):\n        for config_level in self.rorepo.config_level:\n            assert self.rorepo._get_config_path(config_level)\n\n    def test_creation_deletion(self):\n        # just a very quick test to assure it generally works. There are\n        # specialized cases in the test_refs module\n        head = self.rorepo.create_head(\"new_head\", \"HEAD~1\")\n        self.rorepo.delete_head(head)\n\n        try:\n            tag = self.rorepo.create_tag(\"new_tag\", \"HEAD~2\")\n        finally:\n            self.rorepo.delete_tag(tag)\n        with self.rorepo.config_writer():\n            pass\n        try:\n            remote = self.rorepo.create_remote(\"new_remote\", \"git@server:repo.git\")\n        finally:\n            self.rorepo.delete_remote(remote)\n\n    def test_comparison_and_hash(self):\n        # this is only a preliminary test, more testing done in test_index\n        self.assertEqual(self.rorepo, self.rorepo)\n        self.assertFalse(self.rorepo != self.rorepo)\n        self.assertEqual(len({self.rorepo, self.rorepo}), 1)\n\n    @with_rw_directory\n    def test_tilde_and_env_vars_in_repo_path(self, rw_dir):\n        ph = os.environ.get(\"HOME\")\n        try:\n            os.environ[\"HOME\"] = rw_dir\n            Repo.init(osp.join(\"~\", \"test.git\"), bare=True)\n\n            os.environ[\"FOO\"] = rw_dir\n            Repo.init(osp.join(\"$FOO\", \"test.git\"), bare=True)\n        finally:\n            if ph:\n                os.environ[\"HOME\"] = ph\n                del os.environ[\"FOO\"]\n        # end assure HOME gets reset to what it was\n\n    def test_git_cmd(self):\n        # test CatFileContentStream, just to be very sure we have no fencepost errors\n        # last \\n is the terminating newline that it expects\n        l1 = b\"0123456789\\n\"\n        l2 = b\"abcdefghijklmnopqrstxy\\n\"\n        l3 = b\"z\\n\"\n        d = l1 + l2 + l3 + b\"\\n\"\n\n        l1p = l1[:5]\n\n        # full size\n        # size is without terminating newline\n        def mkfull():\n            return Git.CatFileContentStream(len(d) - 1, BytesIO(d))\n\n        ts = 5\n\n        def mktiny():\n            return Git.CatFileContentStream(ts, BytesIO(d))\n\n        # readlines no limit\n        s = mkfull()\n        lines = s.readlines()\n        self.assertEqual(len(lines), 3)\n        self.assertTrue(lines[-1].endswith(b\"\\n\"), lines[-1])\n        self.assertEqual(s._stream.tell(), len(d))  # must have scrubbed to the end\n\n        # realines line limit\n        s = mkfull()\n        lines = s.readlines(5)\n        self.assertEqual(len(lines), 1)\n\n        # readlines on tiny sections\n        s = mktiny()\n        lines = s.readlines()\n        self.assertEqual(len(lines), 1)\n        self.assertEqual(lines[0], l1p)\n        self.assertEqual(s._stream.tell(), ts + 1)\n\n        # readline no limit\n        s = mkfull()\n        self.assertEqual(s.readline(), l1)\n        self.assertEqual(s.readline(), l2)\n        self.assertEqual(s.readline(), l3)\n        self.assertEqual(s.readline(), b\"\")\n        self.assertEqual(s._stream.tell(), len(d))\n\n        # readline limit\n        s = mkfull()\n        self.assertEqual(s.readline(5), l1p)\n        self.assertEqual(s.readline(), l1[5:])\n\n        # readline on tiny section\n        s = mktiny()\n        self.assertEqual(s.readline(), l1p)\n        self.assertEqual(s.readline(), b\"\")\n        self.assertEqual(s._stream.tell(), ts + 1)\n\n        # read no limit\n        s = mkfull()\n        self.assertEqual(s.read(), d[:-1])\n        self.assertEqual(s.read(), b\"\")\n        self.assertEqual(s._stream.tell(), len(d))\n\n        # read limit\n        s = mkfull()\n        self.assertEqual(s.read(5), l1p)\n        self.assertEqual(s.read(6), l1[5:])\n        self.assertEqual(s._stream.tell(), 5 + 6)  # its not yet done\n\n        # read tiny\n        s = mktiny()\n        self.assertEqual(s.read(2), l1[:2])\n        self.assertEqual(s._stream.tell(), 2)\n        self.assertEqual(s.read(), l1[2:ts])\n        self.assertEqual(s._stream.tell(), ts + 1)\n\n    def _assert_rev_parse_types(self, name, rev_obj):\n        rev_parse = self.rorepo.rev_parse\n\n        if rev_obj.type == \"tag\":\n            rev_obj = rev_obj.object\n\n        # tree and blob type\n        obj = rev_parse(name + \"^{tree}\")\n        self.assertEqual(obj, rev_obj.tree)\n\n        obj = rev_parse(name + \":CHANGES\")\n        self.assertEqual(obj.type, \"blob\")\n        self.assertEqual(obj.path, \"CHANGES\")\n        self.assertEqual(rev_obj.tree[\"CHANGES\"], obj)\n\n    def _assert_rev_parse(self, name):\n        \"\"\"tries multiple different rev-parse syntaxes with the given name\n        :return: parsed object\"\"\"\n        rev_parse = self.rorepo.rev_parse\n        orig_obj = rev_parse(name)\n        if orig_obj.type == \"tag\":\n            obj = orig_obj.object\n        else:\n            obj = orig_obj\n        # END deref tags by default\n\n        # try history\n        rev = name + \"~\"\n        obj2 = rev_parse(rev)\n        self.assertEqual(obj2, obj.parents[0])\n        self._assert_rev_parse_types(rev, obj2)\n\n        # history with number\n        ni = 11\n        history = [obj.parents[0]]\n        for pn in range(ni):\n            history.append(history[-1].parents[0])\n        # END get given amount of commits\n\n        for pn in range(11):\n            rev = name + \"~%i\" % (pn + 1)\n            obj2 = rev_parse(rev)\n            self.assertEqual(obj2, history[pn])\n            self._assert_rev_parse_types(rev, obj2)\n        # END history check\n\n        # parent ( default )\n        rev = name + \"^\"\n        obj2 = rev_parse(rev)\n        self.assertEqual(obj2, obj.parents[0])\n        self._assert_rev_parse_types(rev, obj2)\n\n        # parent with number\n        for pn, parent in enumerate(obj.parents):\n            rev = name + \"^%i\" % (pn + 1)\n            self.assertEqual(rev_parse(rev), parent)\n            self._assert_rev_parse_types(rev, parent)\n        # END for each parent\n\n        return orig_obj\n\n    @with_rw_repo(\"HEAD\", bare=False)\n    def test_rw_rev_parse(self, rwrepo):\n        # verify it does not confuse branches with hexsha ids\n        ahead = rwrepo.create_head(\"aaaaaaaa\")\n        assert rwrepo.rev_parse(str(ahead)) == ahead.commit\n\n    def test_rev_parse(self):\n        rev_parse = self.rorepo.rev_parse\n\n        # try special case: This one failed at some point, make sure its fixed\n        self.assertEqual(rev_parse(\"33ebe\").hexsha, \"33ebe7acec14b25c5f84f35a664803fcab2f7781\")\n\n        # start from reference\n        num_resolved = 0\n\n        for ref_no, ref in enumerate(Reference.iter_items(self.rorepo)):\n            path_tokens = ref.path.split(\"/\")\n            for pt in range(len(path_tokens)):\n                path_section = \"/\".join(path_tokens[-(pt + 1) :])\n                try:\n                    obj = self._assert_rev_parse(path_section)\n                    self.assertEqual(obj.type, ref.object.type)\n                    num_resolved += 1\n                except (BadName, BadObject):\n                    print(\"failed on %s\" % path_section)\n                    # is fine, in case we have something like 112, which belongs to remotes/rname/merge-requests/112\n                # END exception handling\n            # END for each token\n            if ref_no == 3 - 1:\n                break\n        # END for each reference\n        assert num_resolved\n\n        # it works with tags !\n        tag = self._assert_rev_parse(\"0.1.4\")\n        self.assertEqual(tag.type, \"tag\")\n\n        # try full sha directly ( including type conversion )\n        self.assertEqual(tag.object, rev_parse(tag.object.hexsha))\n        self._assert_rev_parse_types(tag.object.hexsha, tag.object)\n\n        # multiple tree types result in the same tree: HEAD^{tree}^{tree}:CHANGES\n        rev = \"0.1.4^{tree}^{tree}\"\n        self.assertEqual(rev_parse(rev), tag.object.tree)\n        self.assertEqual(rev_parse(rev + \":CHANGES\"), tag.object.tree[\"CHANGES\"])\n\n        # try to get parents from first revision - it should fail as no such revision\n        # exists\n        first_rev = \"33ebe7acec14b25c5f84f35a664803fcab2f7781\"\n        commit = rev_parse(first_rev)\n        self.assertEqual(len(commit.parents), 0)\n        self.assertEqual(commit.hexsha, first_rev)\n        self.assertRaises(BadName, rev_parse, first_rev + \"~\")\n        self.assertRaises(BadName, rev_parse, first_rev + \"^\")\n\n        # short SHA1\n        commit2 = rev_parse(first_rev[:20])\n        self.assertEqual(commit2, commit)\n        commit2 = rev_parse(first_rev[:5])\n        self.assertEqual(commit2, commit)\n\n        # todo: dereference tag into a blob 0.1.7^{blob} - quite a special one\n        # needs a tag which points to a blob\n\n        # ref^0 returns commit being pointed to, same with ref~0, and ^{}\n        tag = rev_parse(\"0.1.4\")\n        for token in (\"~0\", \"^0\", \"^{}\"):\n            self.assertEqual(tag.object, rev_parse(\"0.1.4%s\" % token))\n        # END handle multiple tokens\n\n        # try partial parsing\n        max_items = 40\n        for i, binsha in enumerate(self.rorepo.odb.sha_iter()):\n            self.assertEqual(\n                rev_parse(bin_to_hex(binsha)[: 8 - (i % 2)].decode(\"ascii\")).binsha,\n                binsha,\n            )\n            if i > max_items:\n                # this is rather slow currently, as rev_parse returns an object\n                # which requires accessing packs, it has some additional overhead\n                break\n        # END for each binsha in repo\n\n        # missing closing brace commit^{tree\n        self.assertRaises(ValueError, rev_parse, \"0.1.4^{tree\")\n\n        # missing starting brace\n        self.assertRaises(ValueError, rev_parse, \"0.1.4^tree}\")\n\n        # REVLOG\n        #######\n        head = self.rorepo.head\n\n        # need to specify a ref when using the @ syntax\n        self.assertRaises(BadObject, rev_parse, \"%s@{0}\" % head.commit.hexsha)\n\n        # uses HEAD.ref by default\n        self.assertEqual(rev_parse(\"@{0}\"), head.commit)\n        if not head.is_detached:\n            refspec = \"%s@{0}\" % head.ref.name\n            self.assertEqual(rev_parse(refspec), head.ref.commit)\n            # all additional specs work as well\n            self.assertEqual(rev_parse(refspec + \"^{tree}\"), head.commit.tree)\n            self.assertEqual(rev_parse(refspec + \":CHANGES\").type, \"blob\")\n        # END operate on non-detached head\n\n        # position doesn't exist\n        self.assertRaises(IndexError, rev_parse, \"@{10000}\")\n\n        # currently, nothing more is supported\n        self.assertRaises(NotImplementedError, rev_parse, \"@{1 week ago}\")\n\n        # the last position\n        assert rev_parse(\"@{1}\") != head.commit\n\n    def test_repo_odbtype(self):\n        target_type = GitCmdObjectDB\n        self.assertIsInstance(self.rorepo.odb, target_type)\n\n    @pytest.mark.xfail(\n        sys.platform == \"cygwin\",\n        reason=\"Cygwin GitPython can't find submodule SHA\",\n        raises=ValueError\n    )\n    def test_submodules(self):\n        self.assertEqual(len(self.rorepo.submodules), 1)  # non-recursive\n        self.assertGreaterEqual(len(list(self.rorepo.iter_submodules())), 2)\n\n        self.assertIsInstance(self.rorepo.submodule(\"gitdb\"), Submodule)\n        self.assertRaises(ValueError, self.rorepo.submodule, \"doesn't exist\")\n\n    @with_rw_repo(\"HEAD\", bare=False)\n    def test_submodule_update(self, rwrepo):\n        # fails in bare mode\n        rwrepo._bare = True\n        self.assertRaises(InvalidGitRepositoryError, rwrepo.submodule_update)\n        rwrepo._bare = False\n\n        # test create submodule\n        sm = rwrepo.submodules[0]\n        sm = rwrepo.create_submodule(\n            \"my_new_sub\",\n            \"some_path\",\n            join_path_native(self.rorepo.working_tree_dir, sm.path),\n        )\n        self.assertIsInstance(sm, Submodule)\n\n        # note: the rest of this functionality is tested in test_submodule\n\n    @with_rw_repo(\"HEAD\")\n    def test_git_file(self, rwrepo):\n        # Move the .git directory to another location and create the .git file.\n        real_path_abs = osp.abspath(join_path_native(rwrepo.working_tree_dir, \".real\"))\n        os.rename(rwrepo.git_dir, real_path_abs)\n        git_file_path = join_path_native(rwrepo.working_tree_dir, \".git\")\n        with open(git_file_path, \"wb\") as fp:\n            fp.write(fixture(\"git_file\"))\n\n        # Create a repo and make sure it's pointing to the relocated .git directory.\n        git_file_repo = Repo(rwrepo.working_tree_dir)\n        self.assertEqual(osp.abspath(git_file_repo.git_dir), real_path_abs)\n\n        # Test using an absolute gitdir path in the .git file.\n        with open(git_file_path, \"wb\") as fp:\n            fp.write((\"gitdir: %s\\n\" % real_path_abs).encode(\"ascii\"))\n        git_file_repo = Repo(rwrepo.working_tree_dir)\n        self.assertEqual(osp.abspath(git_file_repo.git_dir), real_path_abs)\n\n    def test_file_handle_leaks(self):\n        def last_commit(repo, rev, path):\n            commit = next(repo.iter_commits(rev, path, max_count=1))\n            commit.tree[path]\n\n        # This is based on this comment\n        # https://github.com/gitpython-developers/GitPython/issues/60#issuecomment-23558741\n        # And we expect to set max handles to a low value, like 64\n        # You should set ulimit -n X, see .travis.yml\n        # The loops below would easily create 500 handles if these would leak (4 pipes + multiple mapped files)\n        for _ in range(64):\n            for repo_type in (GitCmdObjectDB, GitDB):\n                repo = Repo(self.rorepo.working_tree_dir, odbt=repo_type)\n                last_commit(repo, \"master\", \"test/test_base.py\")\n            # end for each repository type\n        # end for each iteration\n\n    def test_remote_method(self):\n        self.assertRaises(ValueError, self.rorepo.remote, \"foo-blue\")\n        self.assertIsInstance(self.rorepo.remote(name=\"origin\"), Remote)\n\n    @with_rw_directory\n    def test_empty_repo(self, rw_dir):\n        \"\"\"Assure we can handle empty repositories\"\"\"\n        r = Repo.init(rw_dir, mkdir=False)\n        # It's ok not to be able to iterate a commit, as there is none\n        self.assertRaises(ValueError, r.iter_commits)\n        self.assertEqual(r.active_branch.name, \"master\")\n        assert not r.active_branch.is_valid(), \"Branch is yet to be born\"\n\n        # actually, when trying to create a new branch without a commit, git itself fails\n        # We should, however, not fail ungracefully\n        self.assertRaises(BadName, r.create_head, \"foo\")\n        self.assertRaises(BadName, r.create_head, \"master\")\n        # It's expected to not be able to access a tree\n        self.assertRaises(ValueError, r.tree)\n\n        new_file_path = osp.join(rw_dir, \"new_file.ext\")\n        touch(new_file_path)\n        r.index.add([new_file_path])\n        r.index.commit(\"initial commit\\nBAD MESSAGE 1\\n\")\n\n        # Now a branch should be creatable\n        nb = r.create_head(\"foo\")\n        assert nb.is_valid()\n\n        with open(new_file_path, \"w\") as f:\n            f.write(\"Line 1\\n\")\n\n        r.index.add([new_file_path])\n        r.index.commit(\"add line 1\\nBAD MESSAGE 2\\n\")\n\n        with open(\"%s/.git/logs/refs/heads/master\" % (rw_dir,), \"r\") as f:\n            contents = f.read()\n\n        assert \"BAD MESSAGE\" not in contents, \"log is corrupt\"\n\n    def test_merge_base(self):\n        repo = self.rorepo\n        c1 = \"f6aa8d1\"\n        c2 = repo.commit(\"d46e3fe\")\n        c3 = \"763ef75\"\n        self.assertRaises(ValueError, repo.merge_base)\n        self.assertRaises(ValueError, repo.merge_base, \"foo\")\n\n        # two commit merge-base\n        res = repo.merge_base(c1, c2)\n        self.assertIsInstance(res, list)\n        self.assertEqual(len(res), 1)\n        self.assertIsInstance(res[0], Commit)\n        self.assertTrue(res[0].hexsha.startswith(\"3936084\"))\n\n        for kw in (\"a\", \"all\"):\n            res = repo.merge_base(c1, c2, c3, **{kw: True})\n            self.assertIsInstance(res, list)\n            self.assertEqual(len(res), 1)\n        # end for each keyword signalling all merge-bases to be returned\n\n        # Test for no merge base - can't do as we have\n        self.assertRaises(GitCommandError, repo.merge_base, c1, \"ffffff\")\n\n    def test_is_ancestor(self):\n        git = self.rorepo.git\n        if git.version_info[:3] < (1, 8, 0):\n            raise SkipTest(\"git merge-base --is-ancestor feature unsupported\")\n\n        repo = self.rorepo\n        c1 = \"f6aa8d1\"\n        c2 = \"763ef75\"\n        self.assertTrue(repo.is_ancestor(c1, c1))\n        self.assertTrue(repo.is_ancestor(\"master\", \"master\"))\n        self.assertTrue(repo.is_ancestor(c1, c2))\n        self.assertTrue(repo.is_ancestor(c1, \"master\"))\n        self.assertFalse(repo.is_ancestor(c2, c1))\n        self.assertFalse(repo.is_ancestor(\"master\", c1))\n        for i, j in itertools.permutations([c1, \"ffffff\", \"\"], r=2):\n            self.assertRaises(GitCommandError, repo.is_ancestor, i, j)\n\n    def test_is_valid_object(self):\n        repo = self.rorepo\n        commit_sha = \"f6aa8d1\"\n        blob_sha = \"1fbe3e4375\"\n        tree_sha = \"960b40fe36\"\n        tag_sha = \"42c2f60c43\"\n\n        # Check for valid objects\n        self.assertTrue(repo.is_valid_object(commit_sha))\n        self.assertTrue(repo.is_valid_object(blob_sha))\n        self.assertTrue(repo.is_valid_object(tree_sha))\n        self.assertTrue(repo.is_valid_object(tag_sha))\n\n        # Check for valid objects of specific type\n        self.assertTrue(repo.is_valid_object(commit_sha, \"commit\"))\n        self.assertTrue(repo.is_valid_object(blob_sha, \"blob\"))\n        self.assertTrue(repo.is_valid_object(tree_sha, \"tree\"))\n        self.assertTrue(repo.is_valid_object(tag_sha, \"tag\"))\n\n        # Check for invalid objects\n        self.assertFalse(repo.is_valid_object(b\"1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a\", \"blob\"))\n\n        # Check for invalid objects of specific type\n        self.assertFalse(repo.is_valid_object(commit_sha, \"blob\"))\n        self.assertFalse(repo.is_valid_object(blob_sha, \"commit\"))\n        self.assertFalse(repo.is_valid_object(tree_sha, \"commit\"))\n        self.assertFalse(repo.is_valid_object(tag_sha, \"commit\"))\n\n    @with_rw_directory\n    def test_git_work_tree_dotgit(self, rw_dir):\n        \"\"\"Check that we find .git as a worktree file and find the worktree\n        based on it.\"\"\"\n        git = Git(rw_dir)\n        if git.version_info[:3] < (2, 5, 1):\n            raise SkipTest(\"worktree feature unsupported\")\n\n        rw_master = self.rorepo.clone(join_path_native(rw_dir, \"master_repo\"))\n        branch = rw_master.create_head(\"aaaaaaaa\")\n        worktree_path = join_path_native(rw_dir, \"worktree_repo\")\n        if Git.is_cygwin():\n            worktree_path = cygpath(worktree_path)\n        rw_master.git.worktree(\"add\", worktree_path, branch.name)\n\n        # this ensures that we can read the repo's gitdir correctly\n        repo = Repo(worktree_path)\n        self.assertIsInstance(repo, Repo)\n\n        # this ensures we're able to actually read the refs in the tree, which\n        # means we can read commondir correctly.\n        commit = repo.head.commit\n        self.assertIsInstance(commit, Object)\n\n        # this ensures we can read the remotes, which confirms we're reading\n        # the config correctly.\n        origin = repo.remotes.origin\n        self.assertIsInstance(origin, Remote)\n\n        self.assertIsInstance(repo.heads[\"aaaaaaaa\"], Head)\n\n    @with_rw_directory\n    def test_git_work_tree_env(self, rw_dir):\n        \"\"\"Check that we yield to GIT_WORK_TREE\"\"\"\n        # clone a repo\n        # move .git directory to a subdirectory\n        # set GIT_DIR and GIT_WORK_TREE appropriately\n        # check that repo.working_tree_dir == rw_dir\n        self.rorepo.clone(join_path_native(rw_dir, \"master_repo\"))\n\n        repo_dir = join_path_native(rw_dir, \"master_repo\")\n        old_git_dir = join_path_native(repo_dir, \".git\")\n        new_subdir = join_path_native(repo_dir, \"gitdir\")\n        new_git_dir = join_path_native(new_subdir, \"git\")\n        os.mkdir(new_subdir)\n        os.rename(old_git_dir, new_git_dir)\n\n        oldenv = os.environ.copy()\n        os.environ[\"GIT_DIR\"] = new_git_dir\n        os.environ[\"GIT_WORK_TREE\"] = repo_dir\n\n        try:\n            r = Repo()\n            self.assertEqual(r.working_tree_dir, repo_dir)\n            self.assertEqual(r.working_dir, repo_dir)\n        finally:\n            os.environ = oldenv\n\n    @with_rw_directory\n    def test_rebasing(self, rw_dir):\n        r = Repo.init(rw_dir)\n        fp = osp.join(rw_dir, \"hello.txt\")\n        r.git.commit(\n            \"--allow-empty\",\n            message=\"init\",\n        )\n        with open(fp, \"w\") as fs:\n            fs.write(\"hello world\")\n        r.git.add(Git.polish_url(fp))\n        r.git.commit(message=\"English\")\n        self.assertEqual(r.currently_rebasing_on(), None)\n        r.git.checkout(\"HEAD^1\")\n        with open(fp, \"w\") as fs:\n            fs.write(\"Hola Mundo\")\n        r.git.add(Git.polish_url(fp))\n        r.git.commit(message=\"Spanish\")\n        commitSpanish = r.commit()\n        try:\n            r.git.rebase(\"master\")\n        except GitCommandError:\n            pass\n        self.assertEqual(r.currently_rebasing_on(), commitSpanish)\n\n    @with_rw_directory\n    def test_do_not_strip_newline_in_stdout(self, rw_dir):\n        r = Repo.init(rw_dir)\n        fp = osp.join(rw_dir, \"hello.txt\")\n        with open(fp, \"w\") as fs:\n            fs.write(\"hello\\n\")\n        r.git.add(Git.polish_url(fp))\n        r.git.commit(message=\"init\")\n        self.assertEqual(r.git.show(\"HEAD:hello.txt\", strip_newline_in_stdout=False), \"hello\\n\")\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_command_injection(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            unexpected_file = tmp_dir / \"pwn\"\n            assert not unexpected_file.exists()\n\n            payload = f\"--upload-pack=touch {unexpected_file}\"\n            rw_repo.clone(payload)\n\n            assert not unexpected_file.exists()\n            # A repo was cloned with the payload as name\n            assert pathlib.Path(payload).exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_from_command_injection(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            temp_repo = Repo.init(tmp_dir / \"repo\")\n            unexpected_file = tmp_dir / \"pwn\"\n\n            assert not unexpected_file.exists()\n            payload = f\"--upload-pack=touch {unexpected_file}\"\n            with self.assertRaises(GitCommandError):\n                rw_repo.clone_from(payload, temp_repo.common_dir)\n\n            assert not unexpected_file.exists()\n\n    def test_ignored_items_reported(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            temp_repo = Repo.init(tmp_dir / \"repo\")\n\n            gi = tmp_dir / \"repo\" / \".gitignore\"\n\n            with open(gi, 'w') as file:\n                file.write('ignored_file.txt\\n')\n                file.write('ignored_dir/\\n')\n\n            assert temp_repo.ignored(['included_file.txt', 'included_dir/file.txt']) == []\n            assert temp_repo.ignored(['ignored_file.txt']) == ['ignored_file.txt']\n            assert temp_repo.ignored(['included_file.txt', 'ignored_file.txt']) == ['ignored_file.txt']\n            assert temp_repo.ignored(['included_file.txt', 'ignored_file.txt', 'included_dir/file.txt', 'ignored_dir/file.txt']) == ['ignored_file.txt', 'ignored_dir/file.txt']\n\n    def test_ignored_raises_error_w_symlink(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            temp_repo = Repo.init(tmp_dir / \"repo\")\n\n            os.mkdir(tmp_dir / \"target\")\n            os.symlink(tmp_dir / \"target\", tmp_dir / \"symlink\")\n\n            with pytest.raises(GitCommandError):\n                temp_repo.ignored(tmp_dir / \"symlink/file.txt\")"], "fixing_code": ["# repo.py\n# Copyright (C) 2008, 2009 Michael Trier (mtrier@gmail.com) and contributors\n#\n# This module is part of GitPython and is released under\n# the BSD License: http://www.opensource.org/licenses/bsd-license.php\nfrom __future__ import annotations\nimport logging\nimport os\nimport re\nimport shlex\nimport warnings\n\nfrom pathlib import Path\n\nfrom gitdb.db.loose import LooseObjectDB\n\nfrom gitdb.exc import BadObject\n\nfrom git.cmd import Git, handle_process_output\nfrom git.compat import (\n    defenc,\n    safe_decode,\n    is_win,\n)\nfrom git.config import GitConfigParser\nfrom git.db import GitCmdObjectDB\nfrom git.exc import (\n    GitCommandError,\n    InvalidGitRepositoryError,\n    NoSuchPathError,\n)\nfrom git.index import IndexFile\nfrom git.objects import Submodule, RootModule, Commit\nfrom git.refs import HEAD, Head, Reference, TagReference\nfrom git.remote import Remote, add_progress, to_progress_instance\nfrom git.util import (\n    Actor,\n    finalize_process,\n    cygpath,\n    hex_to_bin,\n    expand_path,\n    remove_password_if_present,\n)\nimport os.path as osp\n\nfrom .fun import (\n    rev_parse,\n    is_git_dir,\n    find_submodule_git_dir,\n    touch,\n    find_worktree_git_dir,\n)\nimport gc\nimport gitdb\n\n# typing ------------------------------------------------------\n\nfrom git.types import (\n    TBD,\n    PathLike,\n    Lit_config_levels,\n    Commit_ish,\n    Tree_ish,\n    assert_never,\n)\nfrom typing import (\n    Any,\n    BinaryIO,\n    Callable,\n    Dict,\n    Iterator,\n    List,\n    Mapping,\n    Optional,\n    Sequence,\n    TextIO,\n    Tuple,\n    Type,\n    Union,\n    NamedTuple,\n    cast,\n    TYPE_CHECKING,\n)\n\nfrom git.types import ConfigLevels_Tup, TypedDict\n\nif TYPE_CHECKING:\n    from git.util import IterableList\n    from git.refs.symbolic import SymbolicReference\n    from git.objects import Tree\n    from git.objects.submodule.base import UpdateProgress\n    from git.remote import RemoteProgress\n\n# -----------------------------------------------------------\n\nlog = logging.getLogger(__name__)\n\n__all__ = (\"Repo\",)\n\n\nclass BlameEntry(NamedTuple):\n    commit: Dict[str, \"Commit\"]\n    linenos: range\n    orig_path: Optional[str]\n    orig_linenos: range\n\n\nclass Repo(object):\n    \"\"\"Represents a git repository and allows you to query references,\n    gather commit information, generate diffs, create and clone repositories query\n    the log.\n\n    The following attributes are worth using:\n\n    'working_dir' is the working directory of the git command, which is the working tree\n    directory if available or the .git directory in case of bare repositories\n\n    'working_tree_dir' is the working tree directory, but will return None\n    if we are a bare repository.\n\n    'git_dir' is the .git repository directory, which is always set.\"\"\"\n\n    DAEMON_EXPORT_FILE = \"git-daemon-export-ok\"\n\n    git = cast(\"Git\", None)  # Must exist, or  __del__  will fail in case we raise on `__init__()`\n    working_dir: PathLike\n    _working_tree_dir: Optional[PathLike] = None\n    git_dir: PathLike\n    _common_dir: PathLike = \"\"\n\n    # precompiled regex\n    re_whitespace = re.compile(r\"\\s+\")\n    re_hexsha_only = re.compile(\"^[0-9A-Fa-f]{40}$\")\n    re_hexsha_shortened = re.compile(\"^[0-9A-Fa-f]{4,40}$\")\n    re_envvars = re.compile(r\"(\\$(\\{\\s?)?[a-zA-Z_]\\w*(\\}\\s?)?|%\\s?[a-zA-Z_]\\w*\\s?%)\")\n    re_author_committer_start = re.compile(r\"^(author|committer)\")\n    re_tab_full_line = re.compile(r\"^\\t(.*)$\")\n\n    unsafe_git_clone_options = [\n        # This option allows users to execute arbitrary commands.\n        # https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---upload-packltupload-packgt\n        \"--upload-pack\",\n        \"-u\",\n        # Users can override configuration variables\n        # like `protocol.allow` or `core.gitProxy` to execute arbitrary commands.\n        # https://git-scm.com/docs/git-clone#Documentation/git-clone.txt---configltkeygtltvaluegt\n        \"--config\",\n        \"-c\",\n    ]\n\n    # invariants\n    # represents the configuration level of a configuration file\n    config_level: ConfigLevels_Tup = (\"system\", \"user\", \"global\", \"repository\")\n\n    # Subclass configuration\n    # Subclasses may easily bring in their own custom types by placing a constructor or type here\n    GitCommandWrapperType = Git\n\n    def __init__(\n        self,\n        path: Optional[PathLike] = None,\n        odbt: Type[LooseObjectDB] = GitCmdObjectDB,\n        search_parent_directories: bool = False,\n        expand_vars: bool = True,\n    ) -> None:\n        \"\"\"Create a new Repo instance\n\n        :param path:\n            the path to either the root git directory or the bare git repo::\n\n                repo = Repo(\"/Users/mtrier/Development/git-python\")\n                repo = Repo(\"/Users/mtrier/Development/git-python.git\")\n                repo = Repo(\"~/Development/git-python.git\")\n                repo = Repo(\"$REPOSITORIES/Development/git-python.git\")\n                repo = Repo(\"C:\\\\Users\\\\mtrier\\\\Development\\\\git-python\\\\.git\")\n\n            - In *Cygwin*, path may be a `'cygdrive/...'` prefixed path.\n            - If it evaluates to false, :envvar:`GIT_DIR` is used, and if this also evals to false,\n              the current-directory is used.\n        :param odbt:\n            Object DataBase type - a type which is constructed by providing\n            the directory containing the database objects, i.e. .git/objects. It will\n            be used to access all object data\n        :param search_parent_directories:\n            if True, all parent directories will be searched for a valid repo as well.\n\n            Please note that this was the default behaviour in older versions of GitPython,\n            which is considered a bug though.\n        :raise InvalidGitRepositoryError:\n        :raise NoSuchPathError:\n        :return: git.Repo\"\"\"\n\n        epath = path or os.getenv(\"GIT_DIR\")\n        if not epath:\n            epath = os.getcwd()\n        if Git.is_cygwin():\n            # Given how the tests are written, this seems more likely to catch\n            # Cygwin git used from Windows than Windows git used from Cygwin.\n            # Therefore changing to Cygwin-style paths is the relevant operation.\n            epath = cygpath(epath)\n\n        epath = epath or path or os.getcwd()\n        if not isinstance(epath, str):\n            epath = str(epath)\n        if expand_vars and re.search(self.re_envvars, epath):\n            warnings.warn(\n                \"The use of environment variables in paths is deprecated\"\n                + \"\\nfor security reasons and may be removed in the future!!\"\n            )\n        epath = expand_path(epath, expand_vars)\n        if epath is not None:\n            if not os.path.exists(epath):\n                raise NoSuchPathError(epath)\n\n        ## Walk up the path to find the `.git` dir.\n        #\n        curpath = epath\n        git_dir = None\n        while curpath:\n            # ABOUT osp.NORMPATH\n            # It's important to normalize the paths, as submodules will otherwise initialize their\n            # repo instances with paths that depend on path-portions that will not exist after being\n            # removed. It's just cleaner.\n            if is_git_dir(curpath):\n                git_dir = curpath\n                # from man git-config : core.worktree\n                # Set the path to the root of the working tree. If GIT_COMMON_DIR environment\n                # variable is set, core.worktree is ignored and not used for determining the\n                # root of working tree. This can be overridden by the GIT_WORK_TREE environment\n                # variable. The value can be an absolute path or relative to the path to the .git\n                # directory, which is either specified by GIT_DIR, or automatically discovered.\n                # If GIT_DIR is specified but none of GIT_WORK_TREE and core.worktree is specified,\n                # the current working directory is regarded as the top level of your working tree.\n                self._working_tree_dir = os.path.dirname(git_dir)\n                if os.environ.get(\"GIT_COMMON_DIR\") is None:\n                    gitconf = self._config_reader(\"repository\", git_dir)\n                    if gitconf.has_option(\"core\", \"worktree\"):\n                        self._working_tree_dir = gitconf.get(\"core\", \"worktree\")\n                if \"GIT_WORK_TREE\" in os.environ:\n                    self._working_tree_dir = os.getenv(\"GIT_WORK_TREE\")\n                break\n\n            dotgit = osp.join(curpath, \".git\")\n            sm_gitpath = find_submodule_git_dir(dotgit)\n            if sm_gitpath is not None:\n                git_dir = osp.normpath(sm_gitpath)\n\n            sm_gitpath = find_submodule_git_dir(dotgit)\n            if sm_gitpath is None:\n                sm_gitpath = find_worktree_git_dir(dotgit)\n\n            if sm_gitpath is not None:\n                git_dir = expand_path(sm_gitpath, expand_vars)\n                self._working_tree_dir = curpath\n                break\n\n            if not search_parent_directories:\n                break\n            curpath, tail = osp.split(curpath)\n            if not tail:\n                break\n        # END while curpath\n\n        if git_dir is None:\n            raise InvalidGitRepositoryError(epath)\n        self.git_dir = git_dir\n\n        self._bare = False\n        try:\n            self._bare = self.config_reader(\"repository\").getboolean(\"core\", \"bare\")\n        except Exception:\n            # lets not assume the option exists, although it should\n            pass\n\n        try:\n            common_dir = (Path(self.git_dir) / \"commondir\").read_text().splitlines()[0].strip()\n            self._common_dir = osp.join(self.git_dir, common_dir)\n        except OSError:\n            self._common_dir = \"\"\n\n        # adjust the wd in case we are actually bare - we didn't know that\n        # in the first place\n        if self._bare:\n            self._working_tree_dir = None\n        # END working dir handling\n\n        self.working_dir: PathLike = self._working_tree_dir or self.common_dir\n        self.git = self.GitCommandWrapperType(self.working_dir)\n\n        # special handling, in special times\n        rootpath = osp.join(self.common_dir, \"objects\")\n        if issubclass(odbt, GitCmdObjectDB):\n            self.odb = odbt(rootpath, self.git)\n        else:\n            self.odb = odbt(rootpath)\n\n    def __enter__(self) -> \"Repo\":\n        return self\n\n    def __exit__(self, *args: Any) -> None:\n        self.close()\n\n    def __del__(self) -> None:\n        try:\n            self.close()\n        except Exception:\n            pass\n\n    def close(self) -> None:\n        if self.git:\n            self.git.clear_cache()\n            # Tempfiles objects on Windows are holding references to\n            # open files until they are collected by the garbage\n            # collector, thus preventing deletion.\n            # TODO: Find these references and ensure they are closed\n            # and deleted synchronously rather than forcing a gc\n            # collection.\n            if is_win:\n                gc.collect()\n            gitdb.util.mman.collect()\n            if is_win:\n                gc.collect()\n\n    def __eq__(self, rhs: object) -> bool:\n        if isinstance(rhs, Repo):\n            return self.git_dir == rhs.git_dir\n        return False\n\n    def __ne__(self, rhs: object) -> bool:\n        return not self.__eq__(rhs)\n\n    def __hash__(self) -> int:\n        return hash(self.git_dir)\n\n    # Description property\n    def _get_description(self) -> str:\n        filename = osp.join(self.git_dir, \"description\")\n        with open(filename, \"rb\") as fp:\n            return fp.read().rstrip().decode(defenc)\n\n    def _set_description(self, descr: str) -> None:\n        filename = osp.join(self.git_dir, \"description\")\n        with open(filename, \"wb\") as fp:\n            fp.write((descr + \"\\n\").encode(defenc))\n\n    description = property(_get_description, _set_description, doc=\"the project's description\")\n    del _get_description\n    del _set_description\n\n    @property\n    def working_tree_dir(self) -> Optional[PathLike]:\n        \"\"\":return: The working tree directory of our git repository. If this is a bare repository, None is returned.\"\"\"\n        return self._working_tree_dir\n\n    @property\n    def common_dir(self) -> PathLike:\n        \"\"\"\n        :return: The git dir that holds everything except possibly HEAD,\n            FETCH_HEAD, ORIG_HEAD, COMMIT_EDITMSG, index, and logs/.\"\"\"\n        return self._common_dir or self.git_dir\n\n    @property\n    def bare(self) -> bool:\n        \"\"\":return: True if the repository is bare\"\"\"\n        return self._bare\n\n    @property\n    def heads(self) -> \"IterableList[Head]\":\n        \"\"\"A list of ``Head`` objects representing the branch heads in\n        this repo\n\n        :return: ``git.IterableList(Head, ...)``\"\"\"\n        return Head.list_items(self)\n\n    @property\n    def references(self) -> \"IterableList[Reference]\":\n        \"\"\"A list of Reference objects representing tags, heads and remote references.\n\n        :return: IterableList(Reference, ...)\"\"\"\n        return Reference.list_items(self)\n\n    # alias for references\n    refs = references\n\n    # alias for heads\n    branches = heads\n\n    @property\n    def index(self) -> \"IndexFile\":\n        \"\"\":return: IndexFile representing this repository's index.\n        :note: This property can be expensive, as the returned ``IndexFile`` will be\n         reinitialized. It's recommended to re-use the object.\"\"\"\n        return IndexFile(self)\n\n    @property\n    def head(self) -> \"HEAD\":\n        \"\"\":return: HEAD Object pointing to the current head reference\"\"\"\n        return HEAD(self, \"HEAD\")\n\n    @property\n    def remotes(self) -> \"IterableList[Remote]\":\n        \"\"\"A list of Remote objects allowing to access and manipulate remotes\n\n        :return: ``git.IterableList(Remote, ...)``\"\"\"\n        return Remote.list_items(self)\n\n    def remote(self, name: str = \"origin\") -> \"Remote\":\n        \"\"\":return: Remote with the specified name\n        :raise ValueError:  if no remote with such a name exists\"\"\"\n        r = Remote(self, name)\n        if not r.exists():\n            raise ValueError(\"Remote named '%s' didn't exist\" % name)\n        return r\n\n    # { Submodules\n\n    @property\n    def submodules(self) -> \"IterableList[Submodule]\":\n        \"\"\"\n        :return: git.IterableList(Submodule, ...) of direct submodules\n            available from the current head\"\"\"\n        return Submodule.list_items(self)\n\n    def submodule(self, name: str) -> \"Submodule\":\n        \"\"\":return: Submodule with the given name\n        :raise ValueError: If no such submodule exists\"\"\"\n        try:\n            return self.submodules[name]\n        except IndexError as e:\n            raise ValueError(\"Didn't find submodule named %r\" % name) from e\n        # END exception handling\n\n    def create_submodule(self, *args: Any, **kwargs: Any) -> Submodule:\n        \"\"\"Create a new submodule\n\n        :note: See the documentation of Submodule.add for a description of the\n            applicable parameters\n        :return: created submodules\"\"\"\n        return Submodule.add(self, *args, **kwargs)\n\n    def iter_submodules(self, *args: Any, **kwargs: Any) -> Iterator[Submodule]:\n        \"\"\"An iterator yielding Submodule instances, see Traversable interface\n        for a description of args and kwargs\n\n        :return: Iterator\"\"\"\n        return RootModule(self).traverse(*args, **kwargs)\n\n    def submodule_update(self, *args: Any, **kwargs: Any) -> Iterator[Submodule]:\n        \"\"\"Update the submodules, keeping the repository consistent as it will\n        take the previous state into consideration. For more information, please\n        see the documentation of RootModule.update\"\"\"\n        return RootModule(self).update(*args, **kwargs)\n\n    # }END submodules\n\n    @property\n    def tags(self) -> \"IterableList[TagReference]\":\n        \"\"\"A list of ``Tag`` objects that are available in this repo\n\n        :return: ``git.IterableList(TagReference, ...)``\"\"\"\n        return TagReference.list_items(self)\n\n    def tag(self, path: PathLike) -> TagReference:\n        \"\"\":return: TagReference Object, reference pointing to a Commit or Tag\n        :param path: path to the tag reference, i.e. 0.1.5 or tags/0.1.5\"\"\"\n        full_path = self._to_full_tag_path(path)\n        return TagReference(self, full_path)\n\n    @staticmethod\n    def _to_full_tag_path(path: PathLike) -> str:\n        path_str = str(path)\n        if path_str.startswith(TagReference._common_path_default + \"/\"):\n            return path_str\n        if path_str.startswith(TagReference._common_default + \"/\"):\n            return Reference._common_path_default + \"/\" + path_str\n        else:\n            return TagReference._common_path_default + \"/\" + path_str\n\n    def create_head(\n        self,\n        path: PathLike,\n        commit: Union[\"SymbolicReference\", \"str\"] = \"HEAD\",\n        force: bool = False,\n        logmsg: Optional[str] = None,\n    ) -> \"Head\":\n        \"\"\"Create a new head within the repository.\n        For more documentation, please see the Head.create method.\n\n        :return: newly created Head Reference\"\"\"\n        return Head.create(self, path, commit, logmsg, force)\n\n    def delete_head(self, *heads: \"Union[str, Head]\", **kwargs: Any) -> None:\n        \"\"\"Delete the given heads\n\n        :param kwargs: Additional keyword arguments to be passed to git-branch\"\"\"\n        return Head.delete(self, *heads, **kwargs)\n\n    def create_tag(\n        self,\n        path: PathLike,\n        ref: Union[str, 'SymbolicReference'] = \"HEAD\",\n        message: Optional[str] = None,\n        force: bool = False,\n        **kwargs: Any,\n    ) -> TagReference:\n        \"\"\"Create a new tag reference.\n        For more documentation, please see the TagReference.create method.\n\n        :return: TagReference object\"\"\"\n        return TagReference.create(self, path, ref, message, force, **kwargs)\n\n    def delete_tag(self, *tags: TagReference) -> None:\n        \"\"\"Delete the given tag references\"\"\"\n        return TagReference.delete(self, *tags)\n\n    def create_remote(self, name: str, url: str, **kwargs: Any) -> Remote:\n        \"\"\"Create a new remote.\n\n        For more information, please see the documentation of the Remote.create\n        methods\n\n        :return: Remote reference\"\"\"\n        return Remote.create(self, name, url, **kwargs)\n\n    def delete_remote(self, remote: \"Remote\") -> str:\n        \"\"\"Delete the given remote.\"\"\"\n        return Remote.remove(self, remote)\n\n    def _get_config_path(self, config_level: Lit_config_levels, git_dir: Optional[PathLike] = None) -> str:\n        if git_dir is None:\n            git_dir = self.git_dir\n        # we do not support an absolute path of the gitconfig on windows ,\n        # use the global config instead\n        if is_win and config_level == \"system\":\n            config_level = \"global\"\n\n        if config_level == \"system\":\n            return \"/etc/gitconfig\"\n        elif config_level == \"user\":\n            config_home = os.environ.get(\"XDG_CONFIG_HOME\") or osp.join(os.environ.get(\"HOME\", \"~\"), \".config\")\n            return osp.normpath(osp.expanduser(osp.join(config_home, \"git\", \"config\")))\n        elif config_level == \"global\":\n            return osp.normpath(osp.expanduser(\"~/.gitconfig\"))\n        elif config_level == \"repository\":\n            repo_dir = self._common_dir or git_dir\n            if not repo_dir:\n                raise NotADirectoryError\n            else:\n                return osp.normpath(osp.join(repo_dir, \"config\"))\n        else:\n\n            assert_never(\n                config_level,  # type:ignore[unreachable]\n                ValueError(f\"Invalid configuration level: {config_level!r}\"),\n            )\n\n    def config_reader(\n        self,\n        config_level: Optional[Lit_config_levels] = None,\n    ) -> GitConfigParser:\n        \"\"\"\n        :return:\n            GitConfigParser allowing to read the full git configuration, but not to write it\n\n            The configuration will include values from the system, user and repository\n            configuration files.\n\n        :param config_level:\n            For possible values, see config_writer method\n            If None, all applicable levels will be used. Specify a level in case\n            you know which file you wish to read to prevent reading multiple files.\n        :note: On windows, system configuration cannot currently be read as the path is\n            unknown, instead the global path will be used.\"\"\"\n        return self._config_reader(config_level=config_level)\n\n    def _config_reader(\n        self,\n        config_level: Optional[Lit_config_levels] = None,\n        git_dir: Optional[PathLike] = None,\n    ) -> GitConfigParser:\n        if config_level is None:\n            files = [\n                self._get_config_path(cast(Lit_config_levels, f), git_dir)\n                for f in self.config_level\n                if cast(Lit_config_levels, f)\n            ]\n        else:\n            files = [self._get_config_path(config_level, git_dir)]\n        return GitConfigParser(files, read_only=True, repo=self)\n\n    def config_writer(self, config_level: Lit_config_levels = \"repository\") -> GitConfigParser:\n        \"\"\"\n        :return:\n            GitConfigParser allowing to write values of the specified configuration file level.\n            Config writers should be retrieved, used to change the configuration, and written\n            right away as they will lock the configuration file in question and prevent other's\n            to write it.\n\n        :param config_level:\n            One of the following values\n            system = system wide configuration file\n            global = user level configuration file\n            repository = configuration file for this repository only\"\"\"\n        return GitConfigParser(self._get_config_path(config_level), read_only=False, repo=self)\n\n    def commit(self, rev: Union[str, Commit_ish, None] = None) -> Commit:\n        \"\"\"The Commit object for the specified revision\n\n        :param rev: revision specifier, see git-rev-parse for viable options.\n        :return: ``git.Commit``\n        \"\"\"\n        if rev is None:\n            return self.head.commit\n        return self.rev_parse(str(rev) + \"^0\")\n\n    def iter_trees(self, *args: Any, **kwargs: Any) -> Iterator[\"Tree\"]:\n        \"\"\":return: Iterator yielding Tree objects\n        :note: Takes all arguments known to iter_commits method\"\"\"\n        return (c.tree for c in self.iter_commits(*args, **kwargs))\n\n    def tree(self, rev: Union[Tree_ish, str, None] = None) -> \"Tree\":\n        \"\"\"The Tree object for the given treeish revision\n        Examples::\n\n              repo.tree(repo.heads[0])\n\n        :param rev: is a revision pointing to a Treeish ( being a commit or tree )\n        :return: ``git.Tree``\n\n        :note:\n            If you need a non-root level tree, find it by iterating the root tree. Otherwise\n            it cannot know about its path relative to the repository root and subsequent\n            operations might have unexpected results.\"\"\"\n        if rev is None:\n            return self.head.commit.tree\n        return self.rev_parse(str(rev) + \"^{tree}\")\n\n    def iter_commits(\n        self,\n        rev: Union[str, Commit, \"SymbolicReference\", None] = None,\n        paths: Union[PathLike, Sequence[PathLike]] = \"\",\n        **kwargs: Any,\n    ) -> Iterator[Commit]:\n        \"\"\"A list of Commit objects representing the history of a given ref/commit\n\n        :param rev:\n            revision specifier, see git-rev-parse for viable options.\n            If None, the active branch will be used.\n\n        :param paths:\n            is an optional path or a list of paths; if set only commits that include the path\n            or paths will be returned\n\n        :param kwargs:\n            Arguments to be passed to git-rev-list - common ones are\n            max_count and skip\n\n        :note: to receive only commits between two named revisions, use the\n            \"revA...revB\" revision specifier\n\n        :return: ``git.Commit[]``\"\"\"\n        if rev is None:\n            rev = self.head.commit\n\n        return Commit.iter_items(self, rev, paths, **kwargs)\n\n    def merge_base(self, *rev: TBD, **kwargs: Any) -> List[Union[Commit_ish, None]]:\n        \"\"\"Find the closest common ancestor for the given revision (e.g. Commits, Tags, References, etc)\n\n        :param rev: At least two revs to find the common ancestor for.\n        :param kwargs: Additional arguments to be passed to the repo.git.merge_base() command which does all the work.\n        :return: A list of Commit objects. If --all was not specified as kwarg, the list will have at max one Commit,\n            or is empty if no common merge base exists.\n        :raises ValueError: If not at least two revs are provided\n        \"\"\"\n        if len(rev) < 2:\n            raise ValueError(\"Please specify at least two revs, got only %i\" % len(rev))\n        # end handle input\n\n        res: List[Union[Commit_ish, None]] = []\n        try:\n            lines = self.git.merge_base(*rev, **kwargs).splitlines()  # List[str]\n        except GitCommandError as err:\n            if err.status == 128:\n                raise\n            # end handle invalid rev\n            # Status code 1 is returned if there is no merge-base\n            # (see https://github.com/git/git/blob/master/builtin/merge-base.c#L16)\n            return res\n        # end exception handling\n\n        for line in lines:\n            res.append(self.commit(line))\n        # end for each merge-base\n\n        return res\n\n    def is_ancestor(self, ancestor_rev: \"Commit\", rev: \"Commit\") -> bool:\n        \"\"\"Check if a commit is an ancestor of another\n\n        :param ancestor_rev: Rev which should be an ancestor\n        :param rev: Rev to test against ancestor_rev\n        :return: ``True``, ancestor_rev is an ancestor to rev.\n        \"\"\"\n        try:\n            self.git.merge_base(ancestor_rev, rev, is_ancestor=True)\n        except GitCommandError as err:\n            if err.status == 1:\n                return False\n            raise\n        return True\n\n    def is_valid_object(self, sha: str, object_type: Union[str, None] = None) -> bool:\n        try:\n            complete_sha = self.odb.partial_to_complete_sha_hex(sha)\n            object_info = self.odb.info(complete_sha)\n            if object_type:\n                if object_info.type == object_type.encode():\n                    return True\n                else:\n                    log.debug(\n                        \"Commit hash points to an object of type '%s'. Requested were objects of type '%s'\",\n                        object_info.type.decode(),\n                        object_type,\n                    )\n                    return False\n            else:\n                return True\n        except BadObject:\n            log.debug(\"Commit hash is invalid.\")\n            return False\n\n    def _get_daemon_export(self) -> bool:\n        if self.git_dir:\n            filename = osp.join(self.git_dir, self.DAEMON_EXPORT_FILE)\n        return osp.exists(filename)\n\n    def _set_daemon_export(self, value: object) -> None:\n        if self.git_dir:\n            filename = osp.join(self.git_dir, self.DAEMON_EXPORT_FILE)\n        fileexists = osp.exists(filename)\n        if value and not fileexists:\n            touch(filename)\n        elif not value and fileexists:\n            os.unlink(filename)\n\n    daemon_export = property(\n        _get_daemon_export,\n        _set_daemon_export,\n        doc=\"If True, git-daemon may export this repository\",\n    )\n    del _get_daemon_export\n    del _set_daemon_export\n\n    def _get_alternates(self) -> List[str]:\n        \"\"\"The list of alternates for this repo from which objects can be retrieved\n\n        :return: list of strings being pathnames of alternates\"\"\"\n        if self.git_dir:\n            alternates_path = osp.join(self.git_dir, \"objects\", \"info\", \"alternates\")\n\n        if osp.exists(alternates_path):\n            with open(alternates_path, \"rb\") as f:\n                alts = f.read().decode(defenc)\n            return alts.strip().splitlines()\n        return []\n\n    def _set_alternates(self, alts: List[str]) -> None:\n        \"\"\"Sets the alternates\n\n        :param alts:\n            is the array of string paths representing the alternates at which\n            git should look for objects, i.e. /home/user/repo/.git/objects\n\n        :raise NoSuchPathError:\n        :note:\n            The method does not check for the existence of the paths in alts\n            as the caller is responsible.\"\"\"\n        alternates_path = osp.join(self.common_dir, \"objects\", \"info\", \"alternates\")\n        if not alts:\n            if osp.isfile(alternates_path):\n                os.remove(alternates_path)\n        else:\n            with open(alternates_path, \"wb\") as f:\n                f.write(\"\\n\".join(alts).encode(defenc))\n\n    alternates = property(\n        _get_alternates,\n        _set_alternates,\n        doc=\"Retrieve a list of alternates paths or set a list paths to be used as alternates\",\n    )\n\n    def is_dirty(\n        self,\n        index: bool = True,\n        working_tree: bool = True,\n        untracked_files: bool = False,\n        submodules: bool = True,\n        path: Optional[PathLike] = None,\n    ) -> bool:\n        \"\"\"\n        :return:\n            ``True``, the repository is considered dirty. By default it will react\n            like a git-status without untracked files, hence it is dirty if the\n            index or the working copy have changes.\"\"\"\n        if self._bare:\n            # Bare repositories with no associated working directory are\n            # always considered to be clean.\n            return False\n\n        # start from the one which is fastest to evaluate\n        default_args = [\"--abbrev=40\", \"--full-index\", \"--raw\"]\n        if not submodules:\n            default_args.append(\"--ignore-submodules\")\n        if path:\n            default_args.extend([\"--\", str(path)])\n        if index:\n            # diff index against HEAD\n            if osp.isfile(self.index.path) and len(self.git.diff(\"--cached\", *default_args)):\n                return True\n        # END index handling\n        if working_tree:\n            # diff index against working tree\n            if len(self.git.diff(*default_args)):\n                return True\n        # END working tree handling\n        if untracked_files:\n            if len(self._get_untracked_files(path, ignore_submodules=not submodules)):\n                return True\n        # END untracked files\n        return False\n\n    @property\n    def untracked_files(self) -> List[str]:\n        \"\"\"\n        :return:\n            list(str,...)\n\n            Files currently untracked as they have not been staged yet. Paths\n            are relative to the current working directory of the git command.\n\n        :note:\n            ignored files will not appear here, i.e. files mentioned in .gitignore\n        :note:\n            This property is expensive, as no cache is involved. To process the result, please\n            consider caching it yourself.\"\"\"\n        return self._get_untracked_files()\n\n    def _get_untracked_files(self, *args: Any, **kwargs: Any) -> List[str]:\n        # make sure we get all files, not only untracked directories\n        proc = self.git.status(*args, porcelain=True, untracked_files=True, as_process=True, **kwargs)\n        # Untracked files prefix in porcelain mode\n        prefix = \"?? \"\n        untracked_files = []\n        for line in proc.stdout:\n            line = line.decode(defenc)\n            if not line.startswith(prefix):\n                continue\n            filename = line[len(prefix) :].rstrip(\"\\n\")\n            # Special characters are escaped\n            if filename[0] == filename[-1] == '\"':\n                filename = filename[1:-1]\n                # WHATEVER ... it's a mess, but works for me\n                filename = filename.encode(\"ascii\").decode(\"unicode_escape\").encode(\"latin1\").decode(defenc)\n            untracked_files.append(filename)\n        finalize_process(proc)\n        return untracked_files\n\n    def ignored(self, *paths: PathLike) -> List[str]:\n        \"\"\"Checks if paths are ignored via .gitignore\n        Doing so using the \"git check-ignore\" method.\n\n        :param paths: List of paths to check whether they are ignored or not\n        :return: subset of those paths which are ignored\n        \"\"\"\n        try:\n            proc: str = self.git.check_ignore(*paths)\n        except GitCommandError as err:\n            # If return code is 1, this means none of the items in *paths\n            # are ignored by Git, so return an empty list.  Raise the\n            # exception on all other return codes.\n            if err.status == 1:\n                return []\n            else:\n                raise\n\n        return proc.replace(\"\\\\\\\\\", \"\\\\\").replace('\"', \"\").split(\"\\n\")\n\n    @property\n    def active_branch(self) -> Head:\n        \"\"\"The name of the currently active branch.\n\n        :raises\tTypeError: If HEAD is detached\n        :return: Head to the active branch\"\"\"\n        # reveal_type(self.head.reference)  # => Reference\n        return self.head.reference\n\n    def blame_incremental(self, rev: str | HEAD, file: str, **kwargs: Any) -> Iterator[\"BlameEntry\"]:\n        \"\"\"Iterator for blame information for the given file at the given revision.\n\n        Unlike .blame(), this does not return the actual file's contents, only\n        a stream of BlameEntry tuples.\n\n        :param rev: revision specifier, see git-rev-parse for viable options.\n        :return: lazy iterator of BlameEntry tuples, where the commit\n                 indicates the commit to blame for the line, and range\n                 indicates a span of line numbers in the resulting file.\n\n        If you combine all line number ranges outputted by this command, you\n        should get a continuous range spanning all line numbers in the file.\n        \"\"\"\n\n        data: bytes = self.git.blame(rev, \"--\", file, p=True, incremental=True, stdout_as_string=False, **kwargs)\n        commits: Dict[bytes, Commit] = {}\n\n        stream = (line for line in data.split(b\"\\n\") if line)\n        while True:\n            try:\n                line = next(stream)  # when exhausted, causes a StopIteration, terminating this function\n            except StopIteration:\n                return\n            split_line = line.split()\n            hexsha, orig_lineno_b, lineno_b, num_lines_b = split_line\n            lineno = int(lineno_b)\n            num_lines = int(num_lines_b)\n            orig_lineno = int(orig_lineno_b)\n            if hexsha not in commits:\n                # Now read the next few lines and build up a dict of properties\n                # for this commit\n                props: Dict[bytes, bytes] = {}\n                while True:\n                    try:\n                        line = next(stream)\n                    except StopIteration:\n                        return\n                    if line == b\"boundary\":\n                        # \"boundary\" indicates a root commit and occurs\n                        # instead of the \"previous\" tag\n                        continue\n\n                    tag, value = line.split(b\" \", 1)\n                    props[tag] = value\n                    if tag == b\"filename\":\n                        # \"filename\" formally terminates the entry for --incremental\n                        orig_filename = value\n                        break\n\n                c = Commit(\n                    self,\n                    hex_to_bin(hexsha),\n                    author=Actor(\n                        safe_decode(props[b\"author\"]),\n                        safe_decode(props[b\"author-mail\"].lstrip(b\"<\").rstrip(b\">\")),\n                    ),\n                    authored_date=int(props[b\"author-time\"]),\n                    committer=Actor(\n                        safe_decode(props[b\"committer\"]),\n                        safe_decode(props[b\"committer-mail\"].lstrip(b\"<\").rstrip(b\">\")),\n                    ),\n                    committed_date=int(props[b\"committer-time\"]),\n                )\n                commits[hexsha] = c\n            else:\n                # Discard all lines until we find \"filename\" which is\n                # guaranteed to be the last line\n                while True:\n                    try:\n                        line = next(stream)  # will fail if we reach the EOF unexpectedly\n                    except StopIteration:\n                        return\n                    tag, value = line.split(b\" \", 1)\n                    if tag == b\"filename\":\n                        orig_filename = value\n                        break\n\n            yield BlameEntry(\n                commits[hexsha],\n                range(lineno, lineno + num_lines),\n                safe_decode(orig_filename),\n                range(orig_lineno, orig_lineno + num_lines),\n            )\n\n    def blame(\n        self,\n        rev: Union[str, HEAD],\n        file: str,\n        incremental: bool = False,\n        rev_opts: Optional[List[str]] = None,\n        **kwargs: Any,\n    ) -> List[List[Commit | List[str | bytes] | None]] | Iterator[BlameEntry] | None:\n        \"\"\"The blame information for the given file at the given revision.\n\n        :param rev: revision specifier, see git-rev-parse for viable options.\n        :return:\n            list: [git.Commit, list: [<line>]]\n            A list of lists associating a Commit object with a list of lines that\n            changed within the given commit. The Commit objects will be given in order\n            of appearance.\"\"\"\n        if incremental:\n            return self.blame_incremental(rev, file, **kwargs)\n        rev_opts = rev_opts or []\n        data: bytes = self.git.blame(rev, *rev_opts, \"--\", file, p=True, stdout_as_string=False, **kwargs)\n        commits: Dict[str, Commit] = {}\n        blames: List[List[Commit | List[str | bytes] | None]] = []\n\n        class InfoTD(TypedDict, total=False):\n            sha: str\n            id: str\n            filename: str\n            summary: str\n            author: str\n            author_email: str\n            author_date: int\n            committer: str\n            committer_email: str\n            committer_date: int\n\n        info: InfoTD = {}\n\n        keepends = True\n        for line_bytes in data.splitlines(keepends):\n            try:\n                line_str = line_bytes.rstrip().decode(defenc)\n            except UnicodeDecodeError:\n                firstpart = \"\"\n                parts = []\n                is_binary = True\n            else:\n                # As we don't have an idea when the binary data ends, as it could contain multiple newlines\n                # in the process. So we rely on being able to decode to tell us what is is.\n                # This can absolutely fail even on text files, but even if it does, we should be fine treating it\n                # as binary instead\n                parts = self.re_whitespace.split(line_str, 1)\n                firstpart = parts[0]\n                is_binary = False\n            # end handle decode of line\n\n            if self.re_hexsha_only.search(firstpart):\n                # handles\n                # 634396b2f541a9f2d58b00be1a07f0c358b999b3 1 1 7        - indicates blame-data start\n                # 634396b2f541a9f2d58b00be1a07f0c358b999b3 2 2          - indicates\n                # another line of blame with the same data\n                digits = parts[-1].split(\" \")\n                if len(digits) == 3:\n                    info = {\"id\": firstpart}\n                    blames.append([None, []])\n                elif info[\"id\"] != firstpart:\n                    info = {\"id\": firstpart}\n                    blames.append([commits.get(firstpart), []])\n                # END blame data initialization\n            else:\n                m = self.re_author_committer_start.search(firstpart)\n                if m:\n                    # handles:\n                    # author Tom Preston-Werner\n                    # author-mail <tom@mojombo.com>\n                    # author-time 1192271832\n                    # author-tz -0700\n                    # committer Tom Preston-Werner\n                    # committer-mail <tom@mojombo.com>\n                    # committer-time 1192271832\n                    # committer-tz -0700  - IGNORED BY US\n                    role = m.group(0)\n                    if role == \"author\":\n                        if firstpart.endswith(\"-mail\"):\n                            info[\"author_email\"] = parts[-1]\n                        elif firstpart.endswith(\"-time\"):\n                            info[\"author_date\"] = int(parts[-1])\n                        elif role == firstpart:\n                            info[\"author\"] = parts[-1]\n                    elif role == \"committer\":\n                        if firstpart.endswith(\"-mail\"):\n                            info[\"committer_email\"] = parts[-1]\n                        elif firstpart.endswith(\"-time\"):\n                            info[\"committer_date\"] = int(parts[-1])\n                        elif role == firstpart:\n                            info[\"committer\"] = parts[-1]\n                    # END distinguish mail,time,name\n                else:\n                    # handle\n                    # filename lib/grit.rb\n                    # summary add Blob\n                    # <and rest>\n                    if firstpart.startswith(\"filename\"):\n                        info[\"filename\"] = parts[-1]\n                    elif firstpart.startswith(\"summary\"):\n                        info[\"summary\"] = parts[-1]\n                    elif firstpart == \"\":\n                        if info:\n                            sha = info[\"id\"]\n                            c = commits.get(sha)\n                            if c is None:\n                                c = Commit(\n                                    self,\n                                    hex_to_bin(sha),\n                                    author=Actor._from_string(f\"{info['author']} {info['author_email']}\"),\n                                    authored_date=info[\"author_date\"],\n                                    committer=Actor._from_string(f\"{info['committer']} {info['committer_email']}\"),\n                                    committed_date=info[\"committer_date\"],\n                                )\n                                commits[sha] = c\n                            blames[-1][0] = c\n                            # END if commit objects needs initial creation\n\n                            if blames[-1][1] is not None:\n                                line: str | bytes\n                                if not is_binary:\n                                    if line_str and line_str[0] == \"\\t\":\n                                        line_str = line_str[1:]\n                                    line = line_str\n                                else:\n                                    line = line_bytes\n                                    # NOTE: We are actually parsing lines out of binary data, which can lead to the\n                                    # binary being split up along the newline separator. We will append this to the\n                                    # blame we are currently looking at, even though it should be concatenated with\n                                    # the last line we have seen.\n                                blames[-1][1].append(line)\n\n                            info = {\"id\": sha}\n                        # END if we collected commit info\n                    # END distinguish filename,summary,rest\n                # END distinguish author|committer vs filename,summary,rest\n            # END distinguish hexsha vs other information\n        return blames\n\n    @classmethod\n    def init(\n        cls,\n        path: Union[PathLike, None] = None,\n        mkdir: bool = True,\n        odbt: Type[GitCmdObjectDB] = GitCmdObjectDB,\n        expand_vars: bool = True,\n        **kwargs: Any,\n    ) -> \"Repo\":\n        \"\"\"Initialize a git repository at the given path if specified\n\n        :param path:\n            is the full path to the repo (traditionally ends with /<name>.git)\n            or None in which case the repository will be created in the current\n            working directory\n\n        :param mkdir:\n            if specified will create the repository directory if it doesn't\n            already exists. Creates the directory with a mode=0755.\n            Only effective if a path is explicitly given\n\n        :param odbt:\n            Object DataBase type - a type which is constructed by providing\n            the directory containing the database objects, i.e. .git/objects.\n            It will be used to access all object data\n\n        :param expand_vars:\n            if specified, environment variables will not be escaped. This\n            can lead to information disclosure, allowing attackers to\n            access the contents of environment variables\n\n        :param kwargs:\n            keyword arguments serving as additional options to the git-init command\n\n        :return: ``git.Repo`` (the newly created repo)\"\"\"\n        if path:\n            path = expand_path(path, expand_vars)\n        if mkdir and path and not osp.exists(path):\n            os.makedirs(path, 0o755)\n\n        # git command automatically chdir into the directory\n        git = cls.GitCommandWrapperType(path)\n        git.init(**kwargs)\n        return cls(path, odbt=odbt)\n\n    @classmethod\n    def _clone(\n        cls,\n        git: \"Git\",\n        url: PathLike,\n        path: PathLike,\n        odb_default_type: Type[GitCmdObjectDB],\n        progress: Union[\"RemoteProgress\", \"UpdateProgress\", Callable[..., \"RemoteProgress\"], None] = None,\n        multi_options: Optional[List[str]] = None,\n        allow_unsafe_protocols: bool = False,\n        allow_unsafe_options: bool = False,\n        **kwargs: Any,\n    ) -> \"Repo\":\n        odbt = kwargs.pop(\"odbt\", odb_default_type)\n\n        # when pathlib.Path or other classbased path is passed\n        if not isinstance(path, str):\n            path = str(path)\n\n        ## A bug win cygwin's Git, when `--bare` or `--separate-git-dir`\n        #  it prepends the cwd or(?) the `url` into the `path, so::\n        #        git clone --bare  /cygwin/d/foo.git  C:\\\\Work\n        #  becomes::\n        #        git clone --bare  /cygwin/d/foo.git  /cygwin/d/C:\\\\Work\n        #\n        clone_path = Git.polish_url(path) if Git.is_cygwin() and \"bare\" in kwargs else path\n        sep_dir = kwargs.get(\"separate_git_dir\")\n        if sep_dir:\n            kwargs[\"separate_git_dir\"] = Git.polish_url(sep_dir)\n        multi = None\n        if multi_options:\n            multi = shlex.split(\" \".join(multi_options))\n\n        if not allow_unsafe_protocols:\n            Git.check_unsafe_protocols(str(url))\n        if not allow_unsafe_options:\n            Git.check_unsafe_options(options=list(kwargs.keys()), unsafe_options=cls.unsafe_git_clone_options)\n        if not allow_unsafe_options and multi_options:\n            Git.check_unsafe_options(options=multi_options, unsafe_options=cls.unsafe_git_clone_options)\n\n        proc = git.clone(\n            multi,\n            \"--\",\n            Git.polish_url(str(url)),\n            clone_path,\n            with_extended_output=True,\n            as_process=True,\n            v=True,\n            universal_newlines=True,\n            **add_progress(kwargs, git, progress),\n        )\n        if progress:\n            handle_process_output(\n                proc,\n                None,\n                to_progress_instance(progress).new_message_handler(),\n                finalize_process,\n                decode_streams=False,\n            )\n        else:\n            (stdout, stderr) = proc.communicate()\n            cmdline = getattr(proc, \"args\", \"\")\n            cmdline = remove_password_if_present(cmdline)\n\n            log.debug(\"Cmd(%s)'s unused stdout: %s\", cmdline, stdout)\n            finalize_process(proc, stderr=stderr)\n\n        # our git command could have a different working dir than our actual\n        # environment, hence we prepend its working dir if required\n        if not osp.isabs(path):\n            path = osp.join(git._working_dir, path) if git._working_dir is not None else path\n\n        repo = cls(path, odbt=odbt)\n\n        # retain env values that were passed to _clone()\n        repo.git.update_environment(**git.environment())\n\n        # adjust remotes - there may be operating systems which use backslashes,\n        # These might be given as initial paths, but when handling the config file\n        # that contains the remote from which we were clones, git stops liking it\n        # as it will escape the backslashes. Hence we undo the escaping just to be\n        # sure\n        if repo.remotes:\n            with repo.remotes[0].config_writer as writer:\n                writer.set_value(\"url\", Git.polish_url(repo.remotes[0].url))\n        # END handle remote repo\n        return repo\n\n    def clone(\n        self,\n        path: PathLike,\n        progress: Optional[Callable] = None,\n        multi_options: Optional[List[str]] = None,\n        allow_unsafe_protocols: bool = False,\n        allow_unsafe_options: bool = False,\n        **kwargs: Any,\n    ) -> \"Repo\":\n        \"\"\"Create a clone from this repository.\n\n        :param path: is the full path of the new repo (traditionally ends with ./<name>.git).\n        :param progress: See 'git.remote.Remote.push'.\n        :param multi_options: A list of Clone options that can be provided multiple times.  One\n            option per list item which is passed exactly as specified to clone.\n            For example ['--config core.filemode=false', '--config core.ignorecase',\n            '--recurse-submodule=repo1_path', '--recurse-submodule=repo2_path']\n        :param allow_unsafe_protocols: Allow unsafe protocols to be used, like ext\n        :param allow_unsafe_options: Allow unsafe options to be used, like --upload-pack\n        :param kwargs:\n            * odbt = ObjectDatabase Type, allowing to determine the object database\n              implementation used by the returned Repo instance\n            * All remaining keyword arguments are given to the git-clone command\n\n        :return: ``git.Repo`` (the newly cloned repo)\"\"\"\n        return self._clone(\n            self.git,\n            self.common_dir,\n            path,\n            type(self.odb),\n            progress,\n            multi_options,\n            allow_unsafe_protocols=allow_unsafe_protocols,\n            allow_unsafe_options=allow_unsafe_options,\n            **kwargs,\n        )\n\n    @classmethod\n    def clone_from(\n        cls,\n        url: PathLike,\n        to_path: PathLike,\n        progress: Optional[Callable] = None,\n        env: Optional[Mapping[str, str]] = None,\n        multi_options: Optional[List[str]] = None,\n        allow_unsafe_protocols: bool = False,\n        allow_unsafe_options: bool = False,\n        **kwargs: Any,\n    ) -> \"Repo\":\n        \"\"\"Create a clone from the given URL\n\n        :param url: valid git url, see http://www.kernel.org/pub/software/scm/git/docs/git-clone.html#URLS\n        :param to_path: Path to which the repository should be cloned to\n        :param progress: See 'git.remote.Remote.push'.\n        :param env: Optional dictionary containing the desired environment variables.\n            Note: Provided variables will be used to update the execution\n            environment for `git`. If some variable is not specified in `env`\n            and is defined in `os.environ`, value from `os.environ` will be used.\n            If you want to unset some variable, consider providing empty string\n            as its value.\n        :param multi_options: See ``clone`` method\n        :param allow_unsafe_protocols: Allow unsafe protocols to be used, like ext\n        :param allow_unsafe_options: Allow unsafe options to be used, like --upload-pack\n        :param kwargs: see the ``clone`` method\n        :return: Repo instance pointing to the cloned directory\"\"\"\n        git = cls.GitCommandWrapperType(os.getcwd())\n        if env is not None:\n            git.update_environment(**env)\n        return cls._clone(\n            git,\n            url,\n            to_path,\n            GitCmdObjectDB,\n            progress,\n            multi_options,\n            allow_unsafe_protocols=allow_unsafe_protocols,\n            allow_unsafe_options=allow_unsafe_options,\n            **kwargs,\n        )\n\n    def archive(\n        self,\n        ostream: Union[TextIO, BinaryIO],\n        treeish: Optional[str] = None,\n        prefix: Optional[str] = None,\n        **kwargs: Any,\n    ) -> Repo:\n        \"\"\"Archive the tree at the given revision.\n\n        :param ostream: file compatible stream object to which the archive will be written as bytes\n        :param treeish: is the treeish name/id, defaults to active branch\n        :param prefix: is the optional prefix to prepend to each filename in the archive\n        :param kwargs: Additional arguments passed to git-archive\n\n            * Use the 'format' argument to define the kind of format. Use\n              specialized ostreams to write any format supported by python.\n            * You may specify the special **path** keyword, which may either be a repository-relative\n              path to a directory or file to place into the archive, or a list or tuple of multiple paths.\n\n        :raise GitCommandError: in case something went wrong\n        :return: self\"\"\"\n        if treeish is None:\n            treeish = self.head.commit\n        if prefix and \"prefix\" not in kwargs:\n            kwargs[\"prefix\"] = prefix\n        kwargs[\"output_stream\"] = ostream\n        path = kwargs.pop(\"path\", [])\n        path = cast(Union[PathLike, List[PathLike], Tuple[PathLike, ...]], path)\n        if not isinstance(path, (tuple, list)):\n            path = [path]\n        # end assure paths is list\n        self.git.archive(\"--\", treeish, *path, **kwargs)\n        return self\n\n    def has_separate_working_tree(self) -> bool:\n        \"\"\"\n        :return: True if our git_dir is not at the root of our working_tree_dir, but a .git file with a\n            platform agnositic symbolic link. Our git_dir will be wherever the .git file points to\n        :note: bare repositories will always return False here\n        \"\"\"\n        if self.bare:\n            return False\n        if self.working_tree_dir:\n            return osp.isfile(osp.join(self.working_tree_dir, \".git\"))\n        else:\n            return False  # or raise Error?\n\n    rev_parse = rev_parse\n\n    def __repr__(self) -> str:\n        clazz = self.__class__\n        return \"<%s.%s %r>\" % (clazz.__module__, clazz.__name__, self.git_dir)\n\n    def currently_rebasing_on(self) -> Commit | None:\n        \"\"\"\n        :return: The commit which is currently being replayed while rebasing.\n\n        None if we are not currently rebasing.\n        \"\"\"\n        if self.git_dir:\n            rebase_head_file = osp.join(self.git_dir, \"REBASE_HEAD\")\n        if not osp.isfile(rebase_head_file):\n            return None\n        with open(rebase_head_file, \"rt\") as f:\n            content = f.readline().strip()\n        return self.commit(content)\n", "# -*- coding: utf-8 -*-\n# test_repo.py\n# Copyright (C) 2008, 2009 Michael Trier (mtrier@gmail.com) and contributors\n#\n# This module is part of GitPython and is released under\n# the BSD License: http://www.opensource.org/licenses/bsd-license.php\nimport glob\nimport io\nfrom io import BytesIO\nimport itertools\nimport os\nimport pathlib\nimport pickle\nimport sys\nimport tempfile\nfrom unittest import mock, skipIf, SkipTest\n\nimport pytest\n\nfrom git import (\n    InvalidGitRepositoryError,\n    Repo,\n    NoSuchPathError,\n    Head,\n    Commit,\n    Object,\n    Tree,\n    IndexFile,\n    Git,\n    Reference,\n    GitDB,\n    Submodule,\n    GitCmdObjectDB,\n    Remote,\n    BadName,\n    GitCommandError,\n)\nfrom git.exc import (\n    BadObject,\n    UnsafeOptionError,\n    UnsafeProtocolError,\n)\nfrom git.repo.fun import touch\nfrom test.lib import TestBase, with_rw_repo, fixture\nfrom git.util import HIDE_WINDOWS_KNOWN_ERRORS, cygpath\nfrom test.lib import with_rw_directory\nfrom git.util import join_path_native, rmtree, rmfile, bin_to_hex\n\nimport os.path as osp\n\n\ndef iter_flatten(lol):\n    for items in lol:\n        for item in items:\n            yield item\n\n\ndef flatten(lol):\n    return list(iter_flatten(lol))\n\n\n_tc_lock_fpaths = osp.join(osp.dirname(__file__), \"../../.git/*.lock\")\n\n\ndef _rm_lock_files():\n    for lfp in glob.glob(_tc_lock_fpaths):\n        rmfile(lfp)\n\n\nclass TestRepo(TestBase):\n    def setUp(self):\n        _rm_lock_files()\n\n    def tearDown(self):\n        for lfp in glob.glob(_tc_lock_fpaths):\n            if osp.isfile(lfp):\n                raise AssertionError(\"Previous TC left hanging git-lock file: {}\".format(lfp))\n        import gc\n\n        gc.collect()\n\n    def test_new_should_raise_on_invalid_repo_location(self):\n        self.assertRaises(InvalidGitRepositoryError, Repo, tempfile.gettempdir())\n\n    def test_new_should_raise_on_non_existent_path(self):\n        self.assertRaises(NoSuchPathError, Repo, \"repos/foobar\")\n\n    @with_rw_repo(\"0.3.2.1\")\n    def test_repo_creation_from_different_paths(self, rw_repo):\n        r_from_gitdir = Repo(rw_repo.git_dir)\n        self.assertEqual(r_from_gitdir.git_dir, rw_repo.git_dir)\n        assert r_from_gitdir.git_dir.endswith(\".git\")\n        assert not rw_repo.git.working_dir.endswith(\".git\")\n        self.assertEqual(r_from_gitdir.git.working_dir, rw_repo.git.working_dir)\n\n    @with_rw_repo(\"0.3.2.1\")\n    def test_repo_creation_pathlib(self, rw_repo):\n        r_from_gitdir = Repo(pathlib.Path(rw_repo.git_dir))\n        self.assertEqual(r_from_gitdir.git_dir, rw_repo.git_dir)\n\n    def test_description(self):\n        txt = \"Test repository\"\n        self.rorepo.description = txt\n        self.assertEqual(self.rorepo.description, txt)\n\n    def test_heads_should_return_array_of_head_objects(self):\n        for head in self.rorepo.heads:\n            self.assertEqual(Head, head.__class__)\n\n    def test_heads_should_populate_head_data(self):\n        for head in self.rorepo.heads:\n            assert head.name\n            self.assertIsInstance(head.commit, Commit)\n        # END for each head\n\n        self.assertIsInstance(self.rorepo.heads.master, Head)\n        self.assertIsInstance(self.rorepo.heads[\"master\"], Head)\n\n    def test_tree_from_revision(self):\n        tree = self.rorepo.tree(\"0.1.6\")\n        self.assertEqual(len(tree.hexsha), 40)\n        self.assertEqual(tree.type, \"tree\")\n        self.assertEqual(self.rorepo.tree(tree), tree)\n\n        # try from invalid revision that does not exist\n        self.assertRaises(BadName, self.rorepo.tree, \"hello world\")\n\n    def test_pickleable(self):\n        pickle.loads(pickle.dumps(self.rorepo))\n\n    def test_commit_from_revision(self):\n        commit = self.rorepo.commit(\"0.1.4\")\n        self.assertEqual(commit.type, \"commit\")\n        self.assertEqual(self.rorepo.commit(commit), commit)\n\n    def test_commits(self):\n        mc = 10\n        commits = list(self.rorepo.iter_commits(\"0.1.6\", max_count=mc))\n        self.assertEqual(len(commits), mc)\n\n        c = commits[0]\n        self.assertEqual(\"9a4b1d4d11eee3c5362a4152216376e634bd14cf\", c.hexsha)\n        self.assertEqual([\"c76852d0bff115720af3f27acdb084c59361e5f6\"], [p.hexsha for p in c.parents])\n        self.assertEqual(\"ce41fc29549042f1aa09cc03174896cf23f112e3\", c.tree.hexsha)\n        self.assertEqual(\"Michael Trier\", c.author.name)\n        self.assertEqual(\"mtrier@gmail.com\", c.author.email)\n        self.assertEqual(1232829715, c.authored_date)\n        self.assertEqual(5 * 3600, c.author_tz_offset)\n        self.assertEqual(\"Michael Trier\", c.committer.name)\n        self.assertEqual(\"mtrier@gmail.com\", c.committer.email)\n        self.assertEqual(1232829715, c.committed_date)\n        self.assertEqual(5 * 3600, c.committer_tz_offset)\n        self.assertEqual(\"Bumped version 0.1.6\\n\", c.message)\n\n        c = commits[1]\n        self.assertIsInstance(c.parents, tuple)\n\n    def test_trees(self):\n        mc = 30\n        num_trees = 0\n        for tree in self.rorepo.iter_trees(\"0.1.5\", max_count=mc):\n            num_trees += 1\n            self.assertIsInstance(tree, Tree)\n        # END for each tree\n        self.assertEqual(num_trees, mc)\n\n    def _assert_empty_repo(self, repo):\n        # test all kinds of things with an empty, freshly initialized repo.\n        # It should throw good errors\n\n        # entries should be empty\n        self.assertEqual(len(repo.index.entries), 0)\n\n        # head is accessible\n        assert repo.head\n        assert repo.head.ref\n        assert not repo.head.is_valid()\n\n        # we can change the head to some other ref\n        head_ref = Head.from_path(repo, Head.to_full_path(\"some_head\"))\n        assert not head_ref.is_valid()\n        repo.head.ref = head_ref\n\n        # is_dirty can handle all kwargs\n        for args in ((1, 0, 0), (0, 1, 0), (0, 0, 1)):\n            assert not repo.is_dirty(*args)\n        # END for each arg\n\n        # we can add a file to the index ( if we are not bare )\n        if not repo.bare:\n            pass\n        # END test repos with working tree\n\n    @with_rw_directory\n    def test_clone_from_keeps_env(self, rw_dir):\n        original_repo = Repo.init(osp.join(rw_dir, \"repo\"))\n        environment = {\"entry1\": \"value\", \"another_entry\": \"10\"}\n\n        cloned = Repo.clone_from(original_repo.git_dir, osp.join(rw_dir, \"clone\"), env=environment)\n\n        self.assertEqual(environment, cloned.git.environment())\n\n    @with_rw_directory\n    def test_date_format(self, rw_dir):\n        repo = Repo.init(osp.join(rw_dir, \"repo\"))\n        # @-timestamp is the format used by git commit hooks\n        repo.index.commit(\"Commit messages\", commit_date=\"@1400000000 +0000\")\n\n    @with_rw_directory\n    def test_clone_from_pathlib(self, rw_dir):\n        original_repo = Repo.init(osp.join(rw_dir, \"repo\"))\n\n        Repo.clone_from(original_repo.git_dir, pathlib.Path(rw_dir) / \"clone_pathlib\")\n\n    @with_rw_directory\n    def test_clone_from_pathlib_withConfig(self, rw_dir):\n        original_repo = Repo.init(osp.join(rw_dir, \"repo\"))\n\n        cloned = Repo.clone_from(\n            original_repo.git_dir,\n            pathlib.Path(rw_dir) / \"clone_pathlib_withConfig\",\n            multi_options=[\n                \"--recurse-submodules=repo\",\n                \"--config core.filemode=false\",\n                \"--config submodule.repo.update=checkout\",\n                \"--config filter.lfs.clean='git-lfs clean -- %f'\",\n            ],\n            allow_unsafe_options=True,\n        )\n\n        self.assertEqual(cloned.config_reader().get_value(\"submodule\", \"active\"), \"repo\")\n        self.assertEqual(cloned.config_reader().get_value(\"core\", \"filemode\"), False)\n        self.assertEqual(cloned.config_reader().get_value('submodule \"repo\"', \"update\"), \"checkout\")\n        self.assertEqual(\n            cloned.config_reader().get_value('filter \"lfs\"', \"clean\"),\n            \"git-lfs clean -- %f\",\n        )\n\n    def test_clone_from_with_path_contains_unicode(self):\n        with tempfile.TemporaryDirectory() as tmpdir:\n            unicode_dir_name = \"\\u0394\"\n            path_with_unicode = os.path.join(tmpdir, unicode_dir_name)\n            os.makedirs(path_with_unicode)\n\n            try:\n                Repo.clone_from(\n                    url=self._small_repo_url(),\n                    to_path=path_with_unicode,\n                )\n            except UnicodeEncodeError:\n                self.fail(\"Raised UnicodeEncodeError\")\n\n    @with_rw_directory\n    def test_leaking_password_in_clone_logs(self, rw_dir):\n        password = \"fakepassword1234\"\n        try:\n            Repo.clone_from(\n                url=\"https://fakeuser:{}@fakerepo.example.com/testrepo\".format(password),\n                to_path=rw_dir,\n            )\n        except GitCommandError as err:\n            assert password not in str(err), \"The error message '%s' should not contain the password\" % err\n        # Working example from a blank private project\n        Repo.clone_from(\n            url=\"https://gitlab+deploy-token-392045:mLWhVus7bjLsy8xj8q2V@gitlab.com/mercierm/test_git_python\",\n            to_path=rw_dir,\n        )\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_unsafe_options(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            unsafe_options = [\n                f\"--upload-pack='touch {tmp_file}'\",\n                f\"-u 'touch {tmp_file}'\",\n                \"--config=protocol.ext.allow=always\",\n                \"-c protocol.ext.allow=always\",\n            ]\n            for unsafe_option in unsafe_options:\n                with self.assertRaises(UnsafeOptionError):\n                    rw_repo.clone(tmp_dir, multi_options=[unsafe_option])\n                assert not tmp_file.exists()\n\n            unsafe_options = [\n                {\"upload-pack\": f\"touch {tmp_file}\"},\n                {\"u\": f\"touch {tmp_file}\"},\n                {\"config\": \"protocol.ext.allow=always\"},\n                {\"c\": \"protocol.ext.allow=always\"},\n            ]\n            for unsafe_option in unsafe_options:\n                with self.assertRaises(UnsafeOptionError):\n                    rw_repo.clone(tmp_dir, **unsafe_option)\n                assert not tmp_file.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_unsafe_options_allowed(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            unsafe_options = [\n                f\"--upload-pack='touch {tmp_file}'\",\n                f\"-u 'touch {tmp_file}'\",\n            ]\n            for i, unsafe_option in enumerate(unsafe_options):\n                destination = tmp_dir / str(i)\n                assert not tmp_file.exists()\n                # The options will be allowed, but the command will fail.\n                with self.assertRaises(GitCommandError):\n                    rw_repo.clone(destination, multi_options=[unsafe_option], allow_unsafe_options=True)\n                assert tmp_file.exists()\n                tmp_file.unlink()\n\n            unsafe_options = [\n                \"--config=protocol.ext.allow=always\",\n                \"-c protocol.ext.allow=always\",\n            ]\n            for i, unsafe_option in enumerate(unsafe_options):\n                destination = tmp_dir / str(i)\n                assert not destination.exists()\n                rw_repo.clone(destination, multi_options=[unsafe_option], allow_unsafe_options=True)\n                assert destination.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_safe_options(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            options = [\n                \"--depth=1\",\n                \"--single-branch\",\n                \"-q\",\n            ]\n            for option in options:\n                destination = tmp_dir / option\n                assert not destination.exists()\n                rw_repo.clone(destination, multi_options=[option])\n                assert destination.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_from_unsafe_options(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            unsafe_options = [\n                f\"--upload-pack='touch {tmp_file}'\",\n                f\"-u 'touch {tmp_file}'\",\n                \"--config=protocol.ext.allow=always\",\n                \"-c protocol.ext.allow=always\",\n            ]\n            for unsafe_option in unsafe_options:\n                with self.assertRaises(UnsafeOptionError):\n                    Repo.clone_from(rw_repo.working_dir, tmp_dir, multi_options=[unsafe_option])\n                assert not tmp_file.exists()\n\n            unsafe_options = [\n                {\"upload-pack\": f\"touch {tmp_file}\"},\n                {\"u\": f\"touch {tmp_file}\"},\n                {\"config\": \"protocol.ext.allow=always\"},\n                {\"c\": \"protocol.ext.allow=always\"},\n            ]\n            for unsafe_option in unsafe_options:\n                with self.assertRaises(UnsafeOptionError):\n                    Repo.clone_from(rw_repo.working_dir, tmp_dir, **unsafe_option)\n                assert not tmp_file.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_from_unsafe_options_allowed(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            unsafe_options = [\n                f\"--upload-pack='touch {tmp_file}'\",\n                f\"-u 'touch {tmp_file}'\",\n            ]\n            for i, unsafe_option in enumerate(unsafe_options):\n                destination = tmp_dir / str(i)\n                assert not tmp_file.exists()\n                # The options will be allowed, but the command will fail.\n                with self.assertRaises(GitCommandError):\n                    Repo.clone_from(\n                        rw_repo.working_dir, destination, multi_options=[unsafe_option], allow_unsafe_options=True\n                    )\n                assert tmp_file.exists()\n                tmp_file.unlink()\n\n            unsafe_options = [\n                \"--config=protocol.ext.allow=always\",\n                \"-c protocol.ext.allow=always\",\n            ]\n            for i, unsafe_option in enumerate(unsafe_options):\n                destination = tmp_dir / str(i)\n                assert not destination.exists()\n                Repo.clone_from(rw_repo.working_dir, destination, multi_options=[unsafe_option], allow_unsafe_options=True)\n                assert destination.exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_from_safe_options(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            options = [\n                \"--depth=1\",\n                \"--single-branch\",\n                \"-q\",\n            ]\n            for option in options:\n                destination = tmp_dir / option\n                assert not destination.exists()\n                Repo.clone_from(rw_repo.common_dir, destination, multi_options=[option])\n                assert destination.exists()\n\n    def test_clone_from_unsafe_protocol(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            urls = [\n                f\"ext::sh -c touch% {tmp_file}\",\n                \"fd::17/foo\",\n            ]\n            for url in urls:\n                with self.assertRaises(UnsafeProtocolError):\n                    Repo.clone_from(url, tmp_dir / \"repo\")\n                assert not tmp_file.exists()\n\n    def test_clone_from_unsafe_protocol_allowed(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            urls = [\n                f\"ext::sh -c touch% {tmp_file}\",\n                \"fd::/foo\",\n            ]\n            for url in urls:\n                # The URL will be allowed into the command, but the command will\n                # fail since we don't have that protocol enabled in the Git config file.\n                with self.assertRaises(GitCommandError):\n                    Repo.clone_from(url, tmp_dir / \"repo\", allow_unsafe_protocols=True)\n                assert not tmp_file.exists()\n\n    def test_clone_from_unsafe_protocol_allowed_and_enabled(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            tmp_file = tmp_dir / \"pwn\"\n            urls = [\n                f\"ext::sh -c touch% {tmp_file}\",\n            ]\n            allow_ext = [\n                \"--config=protocol.ext.allow=always\",\n            ]\n            for url in urls:\n                # The URL will be allowed into the command, and the protocol is enabled,\n                # but the command will fail since it can't read from the remote repo.\n                assert not tmp_file.exists()\n                with self.assertRaises(GitCommandError):\n                    Repo.clone_from(\n                        url,\n                        tmp_dir / \"repo\",\n                        multi_options=allow_ext,\n                        allow_unsafe_protocols=True,\n                        allow_unsafe_options=True,\n                    )\n                assert tmp_file.exists()\n                tmp_file.unlink()\n\n    @with_rw_repo(\"HEAD\")\n    def test_max_chunk_size(self, repo):\n        class TestOutputStream(TestBase):\n            def __init__(self, max_chunk_size):\n                self.max_chunk_size = max_chunk_size\n\n            def write(self, b):\n                self.assertTrue(len(b) <= self.max_chunk_size)\n\n        for chunk_size in [16, 128, 1024]:\n            repo.git.status(output_stream=TestOutputStream(chunk_size), max_chunk_size=chunk_size)\n\n        repo.git.log(\n            n=100,\n            output_stream=TestOutputStream(io.DEFAULT_BUFFER_SIZE),\n            max_chunk_size=None,\n        )\n        repo.git.log(\n            n=100,\n            output_stream=TestOutputStream(io.DEFAULT_BUFFER_SIZE),\n            max_chunk_size=-10,\n        )\n        repo.git.log(n=100, output_stream=TestOutputStream(io.DEFAULT_BUFFER_SIZE))\n\n    def test_init(self):\n        prev_cwd = os.getcwd()\n        os.chdir(tempfile.gettempdir())\n        git_dir_rela = \"repos/foo/bar.git\"\n        del_dir_abs = osp.abspath(\"repos\")\n        git_dir_abs = osp.abspath(git_dir_rela)\n        try:\n            # with specific path\n            for path in (git_dir_rela, git_dir_abs):\n                r = Repo.init(path=path, bare=True)\n                self.assertIsInstance(r, Repo)\n                assert r.bare is True\n                assert not r.has_separate_working_tree()\n                assert osp.isdir(r.git_dir)\n\n                self._assert_empty_repo(r)\n\n                # test clone\n                clone_path = path + \"_clone\"\n                rc = r.clone(clone_path)\n                self._assert_empty_repo(rc)\n\n                try:\n                    rmtree(clone_path)\n                except OSError:\n                    # when relative paths are used, the clone may actually be inside\n                    # of the parent directory\n                    pass\n                # END exception handling\n\n                # try again, this time with the absolute version\n                rc = Repo.clone_from(r.git_dir, clone_path)\n                self._assert_empty_repo(rc)\n\n                rmtree(git_dir_abs)\n                try:\n                    rmtree(clone_path)\n                except OSError:\n                    # when relative paths are used, the clone may actually be inside\n                    # of the parent directory\n                    pass\n                # END exception handling\n\n            # END for each path\n\n            os.makedirs(git_dir_rela)\n            os.chdir(git_dir_rela)\n            r = Repo.init(bare=False)\n            assert r.bare is False\n            assert not r.has_separate_working_tree()\n\n            self._assert_empty_repo(r)\n        finally:\n            try:\n                rmtree(del_dir_abs)\n            except OSError:\n                pass\n            os.chdir(prev_cwd)\n        # END restore previous state\n\n    def test_bare_property(self):\n        self.rorepo.bare\n\n    def test_daemon_export(self):\n        orig_val = self.rorepo.daemon_export\n        self.rorepo.daemon_export = not orig_val\n        self.assertEqual(self.rorepo.daemon_export, (not orig_val))\n        self.rorepo.daemon_export = orig_val\n        self.assertEqual(self.rorepo.daemon_export, orig_val)\n\n    def test_alternates(self):\n        cur_alternates = self.rorepo.alternates\n        # empty alternates\n        self.rorepo.alternates = []\n        self.assertEqual(self.rorepo.alternates, [])\n        alts = [\"other/location\", \"this/location\"]\n        self.rorepo.alternates = alts\n        self.assertEqual(alts, self.rorepo.alternates)\n        self.rorepo.alternates = cur_alternates\n\n    def test_repr(self):\n        assert repr(self.rorepo).startswith(\"<git.repo.base.Repo \")\n\n    def test_is_dirty_with_bare_repository(self):\n        orig_value = self.rorepo._bare\n        self.rorepo._bare = True\n        self.assertFalse(self.rorepo.is_dirty())\n        self.rorepo._bare = orig_value\n\n    def test_is_dirty(self):\n        self.rorepo._bare = False\n        for index in (0, 1):\n            for working_tree in (0, 1):\n                for untracked_files in (0, 1):\n                    assert self.rorepo.is_dirty(index, working_tree, untracked_files) in (True, False)\n                # END untracked files\n            # END working tree\n        # END index\n        orig_val = self.rorepo._bare\n        self.rorepo._bare = True\n        assert self.rorepo.is_dirty() is False\n        self.rorepo._bare = orig_val\n\n    def test_is_dirty_pathspec(self):\n        self.rorepo._bare = False\n        for index in (0, 1):\n            for working_tree in (0, 1):\n                for untracked_files in (0, 1):\n                    assert self.rorepo.is_dirty(index, working_tree, untracked_files, path=\":!foo\") in (True, False)\n                # END untracked files\n            # END working tree\n        # END index\n        orig_val = self.rorepo._bare\n        self.rorepo._bare = True\n        assert self.rorepo.is_dirty() is False\n        self.rorepo._bare = orig_val\n\n    @with_rw_repo(\"HEAD\")\n    def test_is_dirty_with_path(self, rwrepo):\n        assert rwrepo.is_dirty(path=\"git\") is False\n\n        with open(osp.join(rwrepo.working_dir, \"git\", \"util.py\"), \"at\") as f:\n            f.write(\"junk\")\n        assert rwrepo.is_dirty(path=\"git\") is True\n        assert rwrepo.is_dirty(path=\"doc\") is False\n\n        rwrepo.git.add(Git.polish_url(osp.join(\"git\", \"util.py\")))\n        assert rwrepo.is_dirty(index=False, path=\"git\") is False\n        assert rwrepo.is_dirty(path=\"git\") is True\n\n        with open(osp.join(rwrepo.working_dir, \"doc\", \"no-such-file.txt\"), \"wt\") as f:\n            f.write(\"junk\")\n        assert rwrepo.is_dirty(path=\"doc\") is False\n        assert rwrepo.is_dirty(untracked_files=True, path=\"doc\") is True\n\n    def test_head(self):\n        self.assertEqual(self.rorepo.head.reference.object, self.rorepo.active_branch.object)\n\n    def test_index(self):\n        index = self.rorepo.index\n        self.assertIsInstance(index, IndexFile)\n\n    def test_tag(self):\n        assert self.rorepo.tag(\"refs/tags/0.1.5\").commit\n\n    def test_tag_to_full_tag_path(self):\n        tags = [\"0.1.5\", \"tags/0.1.5\", \"refs/tags/0.1.5\"]\n        value_errors = []\n        for tag in tags:\n            try:\n                self.rorepo.tag(tag)\n            except ValueError as valueError:\n                value_errors.append(valueError.args[0])\n        self.assertEqual(value_errors, [])\n\n    def test_archive(self):\n        tmpfile = tempfile.mktemp(suffix=\"archive-test\")\n        with open(tmpfile, \"wb\") as stream:\n            self.rorepo.archive(stream, \"0.1.6\", path=\"doc\")\n            assert stream.tell()\n        os.remove(tmpfile)\n\n    @mock.patch.object(Git, \"_call_process\")\n    def test_should_display_blame_information(self, git):\n        git.return_value = fixture(\"blame\")\n        b = self.rorepo.blame(\"master\", \"lib/git.py\")\n        self.assertEqual(13, len(b))\n        self.assertEqual(2, len(b[0]))\n        # self.assertEqual(25, reduce(lambda acc, x: acc + len(x[-1]), b))\n        self.assertEqual(hash(b[0][0]), hash(b[9][0]))\n        c = b[0][0]\n        self.assertTrue(git.called)\n\n        self.assertEqual(\"634396b2f541a9f2d58b00be1a07f0c358b999b3\", c.hexsha)\n        self.assertEqual(\"Tom Preston-Werner\", c.author.name)\n        self.assertEqual(\"tom@mojombo.com\", c.author.email)\n        self.assertEqual(1191997100, c.authored_date)\n        self.assertEqual(\"Tom Preston-Werner\", c.committer.name)\n        self.assertEqual(\"tom@mojombo.com\", c.committer.email)\n        self.assertEqual(1191997100, c.committed_date)\n        self.assertRaisesRegex(\n            ValueError,\n            \"634396b2f541a9f2d58b00be1a07f0c358b999b3 missing\",\n            lambda: c.message,\n        )\n\n        # test the 'lines per commit' entries\n        tlist = b[0][1]\n        self.assertTrue(tlist)\n        self.assertTrue(isinstance(tlist[0], str))\n        self.assertTrue(len(tlist) < sum(len(t) for t in tlist))  # test for single-char bug\n\n        # BINARY BLAME\n        git.return_value = fixture(\"blame_binary\")\n        blames = self.rorepo.blame(\"master\", \"rps\")\n        self.assertEqual(len(blames), 2)\n\n    def test_blame_real(self):\n        c = 0\n        nml = 0  # amount of multi-lines per blame\n        for item in self.rorepo.head.commit.tree.traverse(\n            predicate=lambda i, d: i.type == \"blob\" and i.path.endswith(\".py\")\n        ):\n            c += 1\n\n            for b in self.rorepo.blame(self.rorepo.head, item.path):\n                nml += int(len(b[1]) > 1)\n        # END for each item to traverse\n        assert c, \"Should have executed at least one blame command\"\n        assert nml, \"There should at least be one blame commit that contains multiple lines\"\n\n    @mock.patch.object(Git, \"_call_process\")\n    def test_blame_incremental(self, git):\n        # loop over two fixtures, create a test fixture for 2.11.1+ syntax\n        for git_fixture in (\"blame_incremental\", \"blame_incremental_2.11.1_plus\"):\n            git.return_value = fixture(git_fixture)\n            blame_output = self.rorepo.blame_incremental(\"9debf6b0aafb6f7781ea9d1383c86939a1aacde3\", \"AUTHORS\")\n            blame_output = list(blame_output)\n            self.assertEqual(len(blame_output), 5)\n\n            # Check all outputted line numbers\n            ranges = flatten([entry.linenos for entry in blame_output])\n            self.assertEqual(\n                ranges,\n                flatten(\n                    [\n                        range(2, 3),\n                        range(14, 15),\n                        range(1, 2),\n                        range(3, 14),\n                        range(15, 17),\n                    ]\n                ),\n            )\n\n            commits = [entry.commit.hexsha[:7] for entry in blame_output]\n            self.assertEqual(commits, [\"82b8902\", \"82b8902\", \"c76852d\", \"c76852d\", \"c76852d\"])\n\n            # Original filenames\n            self.assertSequenceEqual(\n                [entry.orig_path for entry in blame_output],\n                [\"AUTHORS\"] * len(blame_output),\n            )\n\n            # Original line numbers\n            orig_ranges = flatten([entry.orig_linenos for entry in blame_output])\n            self.assertEqual(\n                orig_ranges,\n                flatten(\n                    [\n                        range(2, 3),\n                        range(14, 15),\n                        range(1, 2),\n                        range(2, 13),\n                        range(13, 15),\n                    ]\n                ),\n            )  # noqa E501\n\n    @mock.patch.object(Git, \"_call_process\")\n    def test_blame_complex_revision(self, git):\n        git.return_value = fixture(\"blame_complex_revision\")\n        res = self.rorepo.blame(\"HEAD~10..HEAD\", \"README.md\")\n        self.assertEqual(len(res), 1)\n        self.assertEqual(len(res[0][1]), 83, \"Unexpected amount of parsed blame lines\")\n\n    @mock.patch.object(Git, \"_call_process\")\n    def test_blame_accepts_rev_opts(self, git):\n        res = self.rorepo.blame(\"HEAD\", \"README.md\", rev_opts=[\"-M\", \"-C\", \"-C\"])\n        expected_args = ['blame', 'HEAD', '-M', '-C', '-C', '--', 'README.md']\n        boilerplate_kwargs = {\"p\" : True, \"stdout_as_string\": False}\n        git.assert_called_once_with(*expected_args, **boilerplate_kwargs)\n\n    @skipIf(\n        HIDE_WINDOWS_KNOWN_ERRORS and Git.is_cygwin(),\n        \"\"\"FIXME: File \"C:\\\\projects\\\\gitpython\\\\git\\\\cmd.py\", line 671, in execute\n                    raise GitCommandError(command, status, stderr_value, stdout_value)\n                GitCommandError: Cmd('git') failed due to: exit code(128)\n                  cmdline: git add 1__\ufffd\ufffdava verb\ufffd\ufffdten 1_test _myfile 1_test_other_file\n                          1_\ufffd\ufffdava-----verb\ufffd\ufffdten\n                  stderr: 'fatal: pathspec '\"1__\u00e7ava verb\u00f6ten\"' did not match any files'\n                \"\"\",\n    )\n    @with_rw_repo(\"HEAD\", bare=False)\n    def test_untracked_files(self, rwrepo):\n        for run, repo_add in enumerate((rwrepo.index.add, rwrepo.git.add)):\n            base = rwrepo.working_tree_dir\n            files = (\n                join_path_native(base, \"%i_test _myfile\" % run),\n                join_path_native(base, \"%i_test_other_file\" % run),\n                join_path_native(base, \"%i__\u00e7ava verb\u00f6ten\" % run),\n                join_path_native(base, \"%i_\u00e7ava-----verb\u00f6ten\" % run),\n            )\n\n            num_recently_untracked = 0\n            for fpath in files:\n                with open(fpath, \"wb\"):\n                    pass\n            untracked_files = rwrepo.untracked_files\n            num_recently_untracked = len(untracked_files)\n\n            # assure we have all names - they are relative to the git-dir\n            num_test_untracked = 0\n            for utfile in untracked_files:\n                num_test_untracked += join_path_native(base, utfile) in files\n            self.assertEqual(len(files), num_test_untracked)\n\n            repo_add(untracked_files)\n            self.assertEqual(len(rwrepo.untracked_files), (num_recently_untracked - len(files)))\n        # end for each run\n\n    def test_config_reader(self):\n        reader = self.rorepo.config_reader()  # all config files\n        assert reader.read_only\n        reader = self.rorepo.config_reader(\"repository\")  # single config file\n        assert reader.read_only\n\n    def test_config_writer(self):\n        for config_level in self.rorepo.config_level:\n            try:\n                with self.rorepo.config_writer(config_level) as writer:\n                    self.assertFalse(writer.read_only)\n            except IOError:\n                # its okay not to get a writer for some configuration files if we\n                # have no permissions\n                pass\n\n    def test_config_level_paths(self):\n        for config_level in self.rorepo.config_level:\n            assert self.rorepo._get_config_path(config_level)\n\n    def test_creation_deletion(self):\n        # just a very quick test to assure it generally works. There are\n        # specialized cases in the test_refs module\n        head = self.rorepo.create_head(\"new_head\", \"HEAD~1\")\n        self.rorepo.delete_head(head)\n\n        try:\n            tag = self.rorepo.create_tag(\"new_tag\", \"HEAD~2\")\n        finally:\n            self.rorepo.delete_tag(tag)\n        with self.rorepo.config_writer():\n            pass\n        try:\n            remote = self.rorepo.create_remote(\"new_remote\", \"git@server:repo.git\")\n        finally:\n            self.rorepo.delete_remote(remote)\n\n    def test_comparison_and_hash(self):\n        # this is only a preliminary test, more testing done in test_index\n        self.assertEqual(self.rorepo, self.rorepo)\n        self.assertFalse(self.rorepo != self.rorepo)\n        self.assertEqual(len({self.rorepo, self.rorepo}), 1)\n\n    @with_rw_directory\n    def test_tilde_and_env_vars_in_repo_path(self, rw_dir):\n        ph = os.environ.get(\"HOME\")\n        try:\n            os.environ[\"HOME\"] = rw_dir\n            Repo.init(osp.join(\"~\", \"test.git\"), bare=True)\n\n            os.environ[\"FOO\"] = rw_dir\n            Repo.init(osp.join(\"$FOO\", \"test.git\"), bare=True)\n        finally:\n            if ph:\n                os.environ[\"HOME\"] = ph\n                del os.environ[\"FOO\"]\n        # end assure HOME gets reset to what it was\n\n    def test_git_cmd(self):\n        # test CatFileContentStream, just to be very sure we have no fencepost errors\n        # last \\n is the terminating newline that it expects\n        l1 = b\"0123456789\\n\"\n        l2 = b\"abcdefghijklmnopqrstxy\\n\"\n        l3 = b\"z\\n\"\n        d = l1 + l2 + l3 + b\"\\n\"\n\n        l1p = l1[:5]\n\n        # full size\n        # size is without terminating newline\n        def mkfull():\n            return Git.CatFileContentStream(len(d) - 1, BytesIO(d))\n\n        ts = 5\n\n        def mktiny():\n            return Git.CatFileContentStream(ts, BytesIO(d))\n\n        # readlines no limit\n        s = mkfull()\n        lines = s.readlines()\n        self.assertEqual(len(lines), 3)\n        self.assertTrue(lines[-1].endswith(b\"\\n\"), lines[-1])\n        self.assertEqual(s._stream.tell(), len(d))  # must have scrubbed to the end\n\n        # realines line limit\n        s = mkfull()\n        lines = s.readlines(5)\n        self.assertEqual(len(lines), 1)\n\n        # readlines on tiny sections\n        s = mktiny()\n        lines = s.readlines()\n        self.assertEqual(len(lines), 1)\n        self.assertEqual(lines[0], l1p)\n        self.assertEqual(s._stream.tell(), ts + 1)\n\n        # readline no limit\n        s = mkfull()\n        self.assertEqual(s.readline(), l1)\n        self.assertEqual(s.readline(), l2)\n        self.assertEqual(s.readline(), l3)\n        self.assertEqual(s.readline(), b\"\")\n        self.assertEqual(s._stream.tell(), len(d))\n\n        # readline limit\n        s = mkfull()\n        self.assertEqual(s.readline(5), l1p)\n        self.assertEqual(s.readline(), l1[5:])\n\n        # readline on tiny section\n        s = mktiny()\n        self.assertEqual(s.readline(), l1p)\n        self.assertEqual(s.readline(), b\"\")\n        self.assertEqual(s._stream.tell(), ts + 1)\n\n        # read no limit\n        s = mkfull()\n        self.assertEqual(s.read(), d[:-1])\n        self.assertEqual(s.read(), b\"\")\n        self.assertEqual(s._stream.tell(), len(d))\n\n        # read limit\n        s = mkfull()\n        self.assertEqual(s.read(5), l1p)\n        self.assertEqual(s.read(6), l1[5:])\n        self.assertEqual(s._stream.tell(), 5 + 6)  # its not yet done\n\n        # read tiny\n        s = mktiny()\n        self.assertEqual(s.read(2), l1[:2])\n        self.assertEqual(s._stream.tell(), 2)\n        self.assertEqual(s.read(), l1[2:ts])\n        self.assertEqual(s._stream.tell(), ts + 1)\n\n    def _assert_rev_parse_types(self, name, rev_obj):\n        rev_parse = self.rorepo.rev_parse\n\n        if rev_obj.type == \"tag\":\n            rev_obj = rev_obj.object\n\n        # tree and blob type\n        obj = rev_parse(name + \"^{tree}\")\n        self.assertEqual(obj, rev_obj.tree)\n\n        obj = rev_parse(name + \":CHANGES\")\n        self.assertEqual(obj.type, \"blob\")\n        self.assertEqual(obj.path, \"CHANGES\")\n        self.assertEqual(rev_obj.tree[\"CHANGES\"], obj)\n\n    def _assert_rev_parse(self, name):\n        \"\"\"tries multiple different rev-parse syntaxes with the given name\n        :return: parsed object\"\"\"\n        rev_parse = self.rorepo.rev_parse\n        orig_obj = rev_parse(name)\n        if orig_obj.type == \"tag\":\n            obj = orig_obj.object\n        else:\n            obj = orig_obj\n        # END deref tags by default\n\n        # try history\n        rev = name + \"~\"\n        obj2 = rev_parse(rev)\n        self.assertEqual(obj2, obj.parents[0])\n        self._assert_rev_parse_types(rev, obj2)\n\n        # history with number\n        ni = 11\n        history = [obj.parents[0]]\n        for pn in range(ni):\n            history.append(history[-1].parents[0])\n        # END get given amount of commits\n\n        for pn in range(11):\n            rev = name + \"~%i\" % (pn + 1)\n            obj2 = rev_parse(rev)\n            self.assertEqual(obj2, history[pn])\n            self._assert_rev_parse_types(rev, obj2)\n        # END history check\n\n        # parent ( default )\n        rev = name + \"^\"\n        obj2 = rev_parse(rev)\n        self.assertEqual(obj2, obj.parents[0])\n        self._assert_rev_parse_types(rev, obj2)\n\n        # parent with number\n        for pn, parent in enumerate(obj.parents):\n            rev = name + \"^%i\" % (pn + 1)\n            self.assertEqual(rev_parse(rev), parent)\n            self._assert_rev_parse_types(rev, parent)\n        # END for each parent\n\n        return orig_obj\n\n    @with_rw_repo(\"HEAD\", bare=False)\n    def test_rw_rev_parse(self, rwrepo):\n        # verify it does not confuse branches with hexsha ids\n        ahead = rwrepo.create_head(\"aaaaaaaa\")\n        assert rwrepo.rev_parse(str(ahead)) == ahead.commit\n\n    def test_rev_parse(self):\n        rev_parse = self.rorepo.rev_parse\n\n        # try special case: This one failed at some point, make sure its fixed\n        self.assertEqual(rev_parse(\"33ebe\").hexsha, \"33ebe7acec14b25c5f84f35a664803fcab2f7781\")\n\n        # start from reference\n        num_resolved = 0\n\n        for ref_no, ref in enumerate(Reference.iter_items(self.rorepo)):\n            path_tokens = ref.path.split(\"/\")\n            for pt in range(len(path_tokens)):\n                path_section = \"/\".join(path_tokens[-(pt + 1) :])\n                try:\n                    obj = self._assert_rev_parse(path_section)\n                    self.assertEqual(obj.type, ref.object.type)\n                    num_resolved += 1\n                except (BadName, BadObject):\n                    print(\"failed on %s\" % path_section)\n                    # is fine, in case we have something like 112, which belongs to remotes/rname/merge-requests/112\n                # END exception handling\n            # END for each token\n            if ref_no == 3 - 1:\n                break\n        # END for each reference\n        assert num_resolved\n\n        # it works with tags !\n        tag = self._assert_rev_parse(\"0.1.4\")\n        self.assertEqual(tag.type, \"tag\")\n\n        # try full sha directly ( including type conversion )\n        self.assertEqual(tag.object, rev_parse(tag.object.hexsha))\n        self._assert_rev_parse_types(tag.object.hexsha, tag.object)\n\n        # multiple tree types result in the same tree: HEAD^{tree}^{tree}:CHANGES\n        rev = \"0.1.4^{tree}^{tree}\"\n        self.assertEqual(rev_parse(rev), tag.object.tree)\n        self.assertEqual(rev_parse(rev + \":CHANGES\"), tag.object.tree[\"CHANGES\"])\n\n        # try to get parents from first revision - it should fail as no such revision\n        # exists\n        first_rev = \"33ebe7acec14b25c5f84f35a664803fcab2f7781\"\n        commit = rev_parse(first_rev)\n        self.assertEqual(len(commit.parents), 0)\n        self.assertEqual(commit.hexsha, first_rev)\n        self.assertRaises(BadName, rev_parse, first_rev + \"~\")\n        self.assertRaises(BadName, rev_parse, first_rev + \"^\")\n\n        # short SHA1\n        commit2 = rev_parse(first_rev[:20])\n        self.assertEqual(commit2, commit)\n        commit2 = rev_parse(first_rev[:5])\n        self.assertEqual(commit2, commit)\n\n        # todo: dereference tag into a blob 0.1.7^{blob} - quite a special one\n        # needs a tag which points to a blob\n\n        # ref^0 returns commit being pointed to, same with ref~0, and ^{}\n        tag = rev_parse(\"0.1.4\")\n        for token in (\"~0\", \"^0\", \"^{}\"):\n            self.assertEqual(tag.object, rev_parse(\"0.1.4%s\" % token))\n        # END handle multiple tokens\n\n        # try partial parsing\n        max_items = 40\n        for i, binsha in enumerate(self.rorepo.odb.sha_iter()):\n            self.assertEqual(\n                rev_parse(bin_to_hex(binsha)[: 8 - (i % 2)].decode(\"ascii\")).binsha,\n                binsha,\n            )\n            if i > max_items:\n                # this is rather slow currently, as rev_parse returns an object\n                # which requires accessing packs, it has some additional overhead\n                break\n        # END for each binsha in repo\n\n        # missing closing brace commit^{tree\n        self.assertRaises(ValueError, rev_parse, \"0.1.4^{tree\")\n\n        # missing starting brace\n        self.assertRaises(ValueError, rev_parse, \"0.1.4^tree}\")\n\n        # REVLOG\n        #######\n        head = self.rorepo.head\n\n        # need to specify a ref when using the @ syntax\n        self.assertRaises(BadObject, rev_parse, \"%s@{0}\" % head.commit.hexsha)\n\n        # uses HEAD.ref by default\n        self.assertEqual(rev_parse(\"@{0}\"), head.commit)\n        if not head.is_detached:\n            refspec = \"%s@{0}\" % head.ref.name\n            self.assertEqual(rev_parse(refspec), head.ref.commit)\n            # all additional specs work as well\n            self.assertEqual(rev_parse(refspec + \"^{tree}\"), head.commit.tree)\n            self.assertEqual(rev_parse(refspec + \":CHANGES\").type, \"blob\")\n        # END operate on non-detached head\n\n        # position doesn't exist\n        self.assertRaises(IndexError, rev_parse, \"@{10000}\")\n\n        # currently, nothing more is supported\n        self.assertRaises(NotImplementedError, rev_parse, \"@{1 week ago}\")\n\n        # the last position\n        assert rev_parse(\"@{1}\") != head.commit\n\n    def test_repo_odbtype(self):\n        target_type = GitCmdObjectDB\n        self.assertIsInstance(self.rorepo.odb, target_type)\n\n    @pytest.mark.xfail(\n        sys.platform == \"cygwin\",\n        reason=\"Cygwin GitPython can't find submodule SHA\",\n        raises=ValueError\n    )\n    def test_submodules(self):\n        self.assertEqual(len(self.rorepo.submodules), 1)  # non-recursive\n        self.assertGreaterEqual(len(list(self.rorepo.iter_submodules())), 2)\n\n        self.assertIsInstance(self.rorepo.submodule(\"gitdb\"), Submodule)\n        self.assertRaises(ValueError, self.rorepo.submodule, \"doesn't exist\")\n\n    @with_rw_repo(\"HEAD\", bare=False)\n    def test_submodule_update(self, rwrepo):\n        # fails in bare mode\n        rwrepo._bare = True\n        self.assertRaises(InvalidGitRepositoryError, rwrepo.submodule_update)\n        rwrepo._bare = False\n\n        # test create submodule\n        sm = rwrepo.submodules[0]\n        sm = rwrepo.create_submodule(\n            \"my_new_sub\",\n            \"some_path\",\n            join_path_native(self.rorepo.working_tree_dir, sm.path),\n        )\n        self.assertIsInstance(sm, Submodule)\n\n        # note: the rest of this functionality is tested in test_submodule\n\n    @with_rw_repo(\"HEAD\")\n    def test_git_file(self, rwrepo):\n        # Move the .git directory to another location and create the .git file.\n        real_path_abs = osp.abspath(join_path_native(rwrepo.working_tree_dir, \".real\"))\n        os.rename(rwrepo.git_dir, real_path_abs)\n        git_file_path = join_path_native(rwrepo.working_tree_dir, \".git\")\n        with open(git_file_path, \"wb\") as fp:\n            fp.write(fixture(\"git_file\"))\n\n        # Create a repo and make sure it's pointing to the relocated .git directory.\n        git_file_repo = Repo(rwrepo.working_tree_dir)\n        self.assertEqual(osp.abspath(git_file_repo.git_dir), real_path_abs)\n\n        # Test using an absolute gitdir path in the .git file.\n        with open(git_file_path, \"wb\") as fp:\n            fp.write((\"gitdir: %s\\n\" % real_path_abs).encode(\"ascii\"))\n        git_file_repo = Repo(rwrepo.working_tree_dir)\n        self.assertEqual(osp.abspath(git_file_repo.git_dir), real_path_abs)\n\n    def test_file_handle_leaks(self):\n        def last_commit(repo, rev, path):\n            commit = next(repo.iter_commits(rev, path, max_count=1))\n            commit.tree[path]\n\n        # This is based on this comment\n        # https://github.com/gitpython-developers/GitPython/issues/60#issuecomment-23558741\n        # And we expect to set max handles to a low value, like 64\n        # You should set ulimit -n X, see .travis.yml\n        # The loops below would easily create 500 handles if these would leak (4 pipes + multiple mapped files)\n        for _ in range(64):\n            for repo_type in (GitCmdObjectDB, GitDB):\n                repo = Repo(self.rorepo.working_tree_dir, odbt=repo_type)\n                last_commit(repo, \"master\", \"test/test_base.py\")\n            # end for each repository type\n        # end for each iteration\n\n    def test_remote_method(self):\n        self.assertRaises(ValueError, self.rorepo.remote, \"foo-blue\")\n        self.assertIsInstance(self.rorepo.remote(name=\"origin\"), Remote)\n\n    @with_rw_directory\n    def test_empty_repo(self, rw_dir):\n        \"\"\"Assure we can handle empty repositories\"\"\"\n        r = Repo.init(rw_dir, mkdir=False)\n        # It's ok not to be able to iterate a commit, as there is none\n        self.assertRaises(ValueError, r.iter_commits)\n        self.assertEqual(r.active_branch.name, \"master\")\n        assert not r.active_branch.is_valid(), \"Branch is yet to be born\"\n\n        # actually, when trying to create a new branch without a commit, git itself fails\n        # We should, however, not fail ungracefully\n        self.assertRaises(BadName, r.create_head, \"foo\")\n        self.assertRaises(BadName, r.create_head, \"master\")\n        # It's expected to not be able to access a tree\n        self.assertRaises(ValueError, r.tree)\n\n        new_file_path = osp.join(rw_dir, \"new_file.ext\")\n        touch(new_file_path)\n        r.index.add([new_file_path])\n        r.index.commit(\"initial commit\\nBAD MESSAGE 1\\n\")\n\n        # Now a branch should be creatable\n        nb = r.create_head(\"foo\")\n        assert nb.is_valid()\n\n        with open(new_file_path, \"w\") as f:\n            f.write(\"Line 1\\n\")\n\n        r.index.add([new_file_path])\n        r.index.commit(\"add line 1\\nBAD MESSAGE 2\\n\")\n\n        with open(\"%s/.git/logs/refs/heads/master\" % (rw_dir,), \"r\") as f:\n            contents = f.read()\n\n        assert \"BAD MESSAGE\" not in contents, \"log is corrupt\"\n\n    def test_merge_base(self):\n        repo = self.rorepo\n        c1 = \"f6aa8d1\"\n        c2 = repo.commit(\"d46e3fe\")\n        c3 = \"763ef75\"\n        self.assertRaises(ValueError, repo.merge_base)\n        self.assertRaises(ValueError, repo.merge_base, \"foo\")\n\n        # two commit merge-base\n        res = repo.merge_base(c1, c2)\n        self.assertIsInstance(res, list)\n        self.assertEqual(len(res), 1)\n        self.assertIsInstance(res[0], Commit)\n        self.assertTrue(res[0].hexsha.startswith(\"3936084\"))\n\n        for kw in (\"a\", \"all\"):\n            res = repo.merge_base(c1, c2, c3, **{kw: True})\n            self.assertIsInstance(res, list)\n            self.assertEqual(len(res), 1)\n        # end for each keyword signalling all merge-bases to be returned\n\n        # Test for no merge base - can't do as we have\n        self.assertRaises(GitCommandError, repo.merge_base, c1, \"ffffff\")\n\n    def test_is_ancestor(self):\n        git = self.rorepo.git\n        if git.version_info[:3] < (1, 8, 0):\n            raise SkipTest(\"git merge-base --is-ancestor feature unsupported\")\n\n        repo = self.rorepo\n        c1 = \"f6aa8d1\"\n        c2 = \"763ef75\"\n        self.assertTrue(repo.is_ancestor(c1, c1))\n        self.assertTrue(repo.is_ancestor(\"master\", \"master\"))\n        self.assertTrue(repo.is_ancestor(c1, c2))\n        self.assertTrue(repo.is_ancestor(c1, \"master\"))\n        self.assertFalse(repo.is_ancestor(c2, c1))\n        self.assertFalse(repo.is_ancestor(\"master\", c1))\n        for i, j in itertools.permutations([c1, \"ffffff\", \"\"], r=2):\n            self.assertRaises(GitCommandError, repo.is_ancestor, i, j)\n\n    def test_is_valid_object(self):\n        repo = self.rorepo\n        commit_sha = \"f6aa8d1\"\n        blob_sha = \"1fbe3e4375\"\n        tree_sha = \"960b40fe36\"\n        tag_sha = \"42c2f60c43\"\n\n        # Check for valid objects\n        self.assertTrue(repo.is_valid_object(commit_sha))\n        self.assertTrue(repo.is_valid_object(blob_sha))\n        self.assertTrue(repo.is_valid_object(tree_sha))\n        self.assertTrue(repo.is_valid_object(tag_sha))\n\n        # Check for valid objects of specific type\n        self.assertTrue(repo.is_valid_object(commit_sha, \"commit\"))\n        self.assertTrue(repo.is_valid_object(blob_sha, \"blob\"))\n        self.assertTrue(repo.is_valid_object(tree_sha, \"tree\"))\n        self.assertTrue(repo.is_valid_object(tag_sha, \"tag\"))\n\n        # Check for invalid objects\n        self.assertFalse(repo.is_valid_object(b\"1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a1a\", \"blob\"))\n\n        # Check for invalid objects of specific type\n        self.assertFalse(repo.is_valid_object(commit_sha, \"blob\"))\n        self.assertFalse(repo.is_valid_object(blob_sha, \"commit\"))\n        self.assertFalse(repo.is_valid_object(tree_sha, \"commit\"))\n        self.assertFalse(repo.is_valid_object(tag_sha, \"commit\"))\n\n    @with_rw_directory\n    def test_git_work_tree_dotgit(self, rw_dir):\n        \"\"\"Check that we find .git as a worktree file and find the worktree\n        based on it.\"\"\"\n        git = Git(rw_dir)\n        if git.version_info[:3] < (2, 5, 1):\n            raise SkipTest(\"worktree feature unsupported\")\n\n        rw_master = self.rorepo.clone(join_path_native(rw_dir, \"master_repo\"))\n        branch = rw_master.create_head(\"aaaaaaaa\")\n        worktree_path = join_path_native(rw_dir, \"worktree_repo\")\n        if Git.is_cygwin():\n            worktree_path = cygpath(worktree_path)\n        rw_master.git.worktree(\"add\", worktree_path, branch.name)\n\n        # this ensures that we can read the repo's gitdir correctly\n        repo = Repo(worktree_path)\n        self.assertIsInstance(repo, Repo)\n\n        # this ensures we're able to actually read the refs in the tree, which\n        # means we can read commondir correctly.\n        commit = repo.head.commit\n        self.assertIsInstance(commit, Object)\n\n        # this ensures we can read the remotes, which confirms we're reading\n        # the config correctly.\n        origin = repo.remotes.origin\n        self.assertIsInstance(origin, Remote)\n\n        self.assertIsInstance(repo.heads[\"aaaaaaaa\"], Head)\n\n    @with_rw_directory\n    def test_git_work_tree_env(self, rw_dir):\n        \"\"\"Check that we yield to GIT_WORK_TREE\"\"\"\n        # clone a repo\n        # move .git directory to a subdirectory\n        # set GIT_DIR and GIT_WORK_TREE appropriately\n        # check that repo.working_tree_dir == rw_dir\n        self.rorepo.clone(join_path_native(rw_dir, \"master_repo\"))\n\n        repo_dir = join_path_native(rw_dir, \"master_repo\")\n        old_git_dir = join_path_native(repo_dir, \".git\")\n        new_subdir = join_path_native(repo_dir, \"gitdir\")\n        new_git_dir = join_path_native(new_subdir, \"git\")\n        os.mkdir(new_subdir)\n        os.rename(old_git_dir, new_git_dir)\n\n        oldenv = os.environ.copy()\n        os.environ[\"GIT_DIR\"] = new_git_dir\n        os.environ[\"GIT_WORK_TREE\"] = repo_dir\n\n        try:\n            r = Repo()\n            self.assertEqual(r.working_tree_dir, repo_dir)\n            self.assertEqual(r.working_dir, repo_dir)\n        finally:\n            os.environ = oldenv\n\n    @with_rw_directory\n    def test_rebasing(self, rw_dir):\n        r = Repo.init(rw_dir)\n        fp = osp.join(rw_dir, \"hello.txt\")\n        r.git.commit(\n            \"--allow-empty\",\n            message=\"init\",\n        )\n        with open(fp, \"w\") as fs:\n            fs.write(\"hello world\")\n        r.git.add(Git.polish_url(fp))\n        r.git.commit(message=\"English\")\n        self.assertEqual(r.currently_rebasing_on(), None)\n        r.git.checkout(\"HEAD^1\")\n        with open(fp, \"w\") as fs:\n            fs.write(\"Hola Mundo\")\n        r.git.add(Git.polish_url(fp))\n        r.git.commit(message=\"Spanish\")\n        commitSpanish = r.commit()\n        try:\n            r.git.rebase(\"master\")\n        except GitCommandError:\n            pass\n        self.assertEqual(r.currently_rebasing_on(), commitSpanish)\n\n    @with_rw_directory\n    def test_do_not_strip_newline_in_stdout(self, rw_dir):\n        r = Repo.init(rw_dir)\n        fp = osp.join(rw_dir, \"hello.txt\")\n        with open(fp, \"w\") as fs:\n            fs.write(\"hello\\n\")\n        r.git.add(Git.polish_url(fp))\n        r.git.commit(message=\"init\")\n        self.assertEqual(r.git.show(\"HEAD:hello.txt\", strip_newline_in_stdout=False), \"hello\\n\")\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_command_injection(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            unexpected_file = tmp_dir / \"pwn\"\n            assert not unexpected_file.exists()\n\n            payload = f\"--upload-pack=touch {unexpected_file}\"\n            rw_repo.clone(payload)\n\n            assert not unexpected_file.exists()\n            # A repo was cloned with the payload as name\n            assert pathlib.Path(payload).exists()\n\n    @with_rw_repo(\"HEAD\")\n    def test_clone_from_command_injection(self, rw_repo):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            temp_repo = Repo.init(tmp_dir / \"repo\")\n            unexpected_file = tmp_dir / \"pwn\"\n\n            assert not unexpected_file.exists()\n            payload = f\"--upload-pack=touch {unexpected_file}\"\n            with self.assertRaises(GitCommandError):\n                rw_repo.clone_from(payload, temp_repo.common_dir)\n\n            assert not unexpected_file.exists()\n\n    def test_ignored_items_reported(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            temp_repo = Repo.init(tmp_dir / \"repo\")\n\n            gi = tmp_dir / \"repo\" / \".gitignore\"\n\n            with open(gi, 'w') as file:\n                file.write('ignored_file.txt\\n')\n                file.write('ignored_dir/\\n')\n\n            assert temp_repo.ignored(['included_file.txt', 'included_dir/file.txt']) == []\n            assert temp_repo.ignored(['ignored_file.txt']) == ['ignored_file.txt']\n            assert temp_repo.ignored(['included_file.txt', 'ignored_file.txt']) == ['ignored_file.txt']\n            assert temp_repo.ignored(['included_file.txt', 'ignored_file.txt', 'included_dir/file.txt', 'ignored_dir/file.txt']) == ['ignored_file.txt', 'ignored_dir/file.txt']\n\n    def test_ignored_raises_error_w_symlink(self):\n        with tempfile.TemporaryDirectory() as tdir:\n            tmp_dir = pathlib.Path(tdir)\n            temp_repo = Repo.init(tmp_dir / \"repo\")\n\n            os.mkdir(tmp_dir / \"target\")\n            os.symlink(tmp_dir / \"target\", tmp_dir / \"symlink\")\n\n            with pytest.raises(GitCommandError):\n                temp_repo.ignored(tmp_dir / \"symlink/file.txt\")\n"], "filenames": ["git/repo/base.py", "test/test_repo.py"], "buggy_code_start_loc": [1205, 284], "buggy_code_end_loc": [1205, 1414], "fixing_code_start_loc": [1206, 285], "fixing_code_end_loc": [1208, 1436], "type": "NVD-CWE-noinfo", "message": "GitPython before 3.1.32 does not block insecure non-multi options in clone and clone_from. NOTE: this issue exists because of an incomplete fix for CVE-2022-24439.", "other": {"cve": {"id": "CVE-2023-40267", "sourceIdentifier": "cve@mitre.org", "published": "2023-08-11T07:15:09.647", "lastModified": "2023-11-07T04:20:10.150", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "GitPython before 3.1.32 does not block insecure non-multi options in clone and clone_from. NOTE: this issue exists because of an incomplete fix for CVE-2022-24439."}, {"lang": "es", "value": "GitPython antes de 3.1.32 no bloquea opciones inseguras no multi en clone y clone_from. NOTA: este problema existe debido a una correcci\u00f3n incompleta de CVE-2022-24439.\n"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:gitpython_project:gitpython:*:*:*:*:*:python:*:*", "versionEndExcluding": "3.1.32", "matchCriteriaId": "06EB5A55-DB8A-4F86-9C77-F1FE464525FF"}]}]}], "references": [{"url": "https://github.com/gitpython-developers/GitPython/commit/ca965ecc81853bca7675261729143f54e5bf4cdd", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://github.com/gitpython-developers/GitPython/pull/1609", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/AV5DV7GBLMOZT7U3Q4TDOJO5R6G3V6GH/", "source": "cve@mitre.org"}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce%40lists.fedoraproject.org/message/PF6AXUTC5BO7L2SBJMCVKJSPKWY52I5R/", "source": "cve@mitre.org"}]}, "github_commit_url": "https://github.com/gitpython-developers/GitPython/commit/ca965ecc81853bca7675261729143f54e5bf4cdd"}}
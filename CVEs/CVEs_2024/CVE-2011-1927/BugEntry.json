{"buggy_code": ["/*\n * INET\t\tAn implementation of the TCP/IP protocol suite for the LINUX\n *\t\toperating system.  INET is implemented using the  BSD Socket\n *\t\tinterface as the means of communication with the user level.\n *\n *\t\tThe IP fragmentation functionality.\n *\n * Authors:\tFred N. van Kempen <waltje@uWalt.NL.Mugnet.ORG>\n *\t\tAlan Cox <alan@lxorguk.ukuu.org.uk>\n *\n * Fixes:\n *\t\tAlan Cox\t:\tSplit from ip.c , see ip_input.c for history.\n *\t\tDavid S. Miller :\tBegin massive cleanup...\n *\t\tAndi Kleen\t:\tAdd sysctls.\n *\t\txxxx\t\t:\tOverlapfrag bug.\n *\t\tUltima          :       ip_expire() kernel panic.\n *\t\tBill Hawes\t:\tFrag accounting and evictor fixes.\n *\t\tJohn McDonald\t:\t0 length frag bug.\n *\t\tAlexey Kuznetsov:\tSMP races, threading, cleanup.\n *\t\tPatrick McHardy :\tLRU queue of frag heads for evictor.\n */\n\n#include <linux/compiler.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/mm.h>\n#include <linux/jiffies.h>\n#include <linux/skbuff.h>\n#include <linux/list.h>\n#include <linux/ip.h>\n#include <linux/icmp.h>\n#include <linux/netdevice.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/slab.h>\n#include <net/route.h>\n#include <net/dst.h>\n#include <net/sock.h>\n#include <net/ip.h>\n#include <net/icmp.h>\n#include <net/checksum.h>\n#include <net/inetpeer.h>\n#include <net/inet_frag.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n#include <linux/inet.h>\n#include <linux/netfilter_ipv4.h>\n#include <net/inet_ecn.h>\n\n/* NOTE. Logic of IP defragmentation is parallel to corresponding IPv6\n * code now. If you change something here, _PLEASE_ update ipv6/reassembly.c\n * as well. Or notify me, at least. --ANK\n */\n\nstatic int sysctl_ipfrag_max_dist __read_mostly = 64;\n\nstruct ipfrag_skb_cb\n{\n\tstruct inet_skb_parm\th;\n\tint\t\t\toffset;\n};\n\n#define FRAG_CB(skb)\t((struct ipfrag_skb_cb *)((skb)->cb))\n\n/* Describe an entry in the \"incomplete datagrams\" queue. */\nstruct ipq {\n\tstruct inet_frag_queue q;\n\n\tu32\t\tuser;\n\t__be32\t\tsaddr;\n\t__be32\t\tdaddr;\n\t__be16\t\tid;\n\tu8\t\tprotocol;\n\tu8\t\tecn; /* RFC3168 support */\n\tint             iif;\n\tunsigned int    rid;\n\tstruct inet_peer *peer;\n};\n\n#define IPFRAG_ECN_CLEAR  0x01 /* one frag had INET_ECN_NOT_ECT */\n#define IPFRAG_ECN_SET_CE 0x04 /* one frag had INET_ECN_CE */\n\nstatic inline u8 ip4_frag_ecn(u8 tos)\n{\n\ttos = (tos & INET_ECN_MASK) + 1;\n\t/*\n\t * After the last operation we have (in binary):\n\t * INET_ECN_NOT_ECT => 001\n\t * INET_ECN_ECT_1   => 010\n\t * INET_ECN_ECT_0   => 011\n\t * INET_ECN_CE      => 100\n\t */\n\treturn (tos & 2) ? 0 : tos;\n}\n\nstatic struct inet_frags ip4_frags;\n\nint ip_frag_nqueues(struct net *net)\n{\n\treturn net->ipv4.frags.nqueues;\n}\n\nint ip_frag_mem(struct net *net)\n{\n\treturn atomic_read(&net->ipv4.frags.mem);\n}\n\nstatic int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,\n\t\t\t struct net_device *dev);\n\nstruct ip4_create_arg {\n\tstruct iphdr *iph;\n\tu32 user;\n};\n\nstatic unsigned int ipqhashfn(__be16 id, __be32 saddr, __be32 daddr, u8 prot)\n{\n\treturn jhash_3words((__force u32)id << 16 | prot,\n\t\t\t    (__force u32)saddr, (__force u32)daddr,\n\t\t\t    ip4_frags.rnd) & (INETFRAGS_HASHSZ - 1);\n}\n\nstatic unsigned int ip4_hashfn(struct inet_frag_queue *q)\n{\n\tstruct ipq *ipq;\n\n\tipq = container_of(q, struct ipq, q);\n\treturn ipqhashfn(ipq->id, ipq->saddr, ipq->daddr, ipq->protocol);\n}\n\nstatic int ip4_frag_match(struct inet_frag_queue *q, void *a)\n{\n\tstruct ipq *qp;\n\tstruct ip4_create_arg *arg = a;\n\n\tqp = container_of(q, struct ipq, q);\n\treturn\tqp->id == arg->iph->id &&\n\t\t\tqp->saddr == arg->iph->saddr &&\n\t\t\tqp->daddr == arg->iph->daddr &&\n\t\t\tqp->protocol == arg->iph->protocol &&\n\t\t\tqp->user == arg->user;\n}\n\n/* Memory Tracking Functions. */\nstatic void frag_kfree_skb(struct netns_frags *nf, struct sk_buff *skb)\n{\n\tatomic_sub(skb->truesize, &nf->mem);\n\tkfree_skb(skb);\n}\n\nstatic void ip4_frag_init(struct inet_frag_queue *q, void *a)\n{\n\tstruct ipq *qp = container_of(q, struct ipq, q);\n\tstruct ip4_create_arg *arg = a;\n\n\tqp->protocol = arg->iph->protocol;\n\tqp->id = arg->iph->id;\n\tqp->ecn = ip4_frag_ecn(arg->iph->tos);\n\tqp->saddr = arg->iph->saddr;\n\tqp->daddr = arg->iph->daddr;\n\tqp->user = arg->user;\n\tqp->peer = sysctl_ipfrag_max_dist ?\n\t\tinet_getpeer_v4(arg->iph->saddr, 1) : NULL;\n}\n\nstatic __inline__ void ip4_frag_free(struct inet_frag_queue *q)\n{\n\tstruct ipq *qp;\n\n\tqp = container_of(q, struct ipq, q);\n\tif (qp->peer)\n\t\tinet_putpeer(qp->peer);\n}\n\n\n/* Destruction primitives. */\n\nstatic __inline__ void ipq_put(struct ipq *ipq)\n{\n\tinet_frag_put(&ipq->q, &ip4_frags);\n}\n\n/* Kill ipq entry. It is not destroyed immediately,\n * because caller (and someone more) holds reference count.\n */\nstatic void ipq_kill(struct ipq *ipq)\n{\n\tinet_frag_kill(&ipq->q, &ip4_frags);\n}\n\n/* Memory limiting on fragments.  Evictor trashes the oldest\n * fragment queue until we are back under the threshold.\n */\nstatic void ip_evictor(struct net *net)\n{\n\tint evicted;\n\n\tevicted = inet_frag_evictor(&net->ipv4.frags, &ip4_frags);\n\tif (evicted)\n\t\tIP_ADD_STATS_BH(net, IPSTATS_MIB_REASMFAILS, evicted);\n}\n\n/*\n * Oops, a fragment queue timed out.  Kill it and send an ICMP reply.\n */\nstatic void ip_expire(unsigned long arg)\n{\n\tstruct ipq *qp;\n\tstruct net *net;\n\n\tqp = container_of((struct inet_frag_queue *) arg, struct ipq, q);\n\tnet = container_of(qp->q.net, struct net, ipv4.frags);\n\n\tspin_lock(&qp->q.lock);\n\n\tif (qp->q.last_in & INET_FRAG_COMPLETE)\n\t\tgoto out;\n\n\tipq_kill(qp);\n\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMTIMEOUT);\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);\n\n\tif ((qp->q.last_in & INET_FRAG_FIRST_IN) && qp->q.fragments != NULL) {\n\t\tstruct sk_buff *head = qp->q.fragments;\n\n\t\trcu_read_lock();\n\t\thead->dev = dev_get_by_index_rcu(net, qp->iif);\n\t\tif (!head->dev)\n\t\t\tgoto out_rcu_unlock;\n\n\t\t/*\n\t\t * Only search router table for the head fragment,\n\t\t * when defraging timeout at PRE_ROUTING HOOK.\n\t\t */\n\t\tif (qp->user == IP_DEFRAG_CONNTRACK_IN && !skb_dst(head)) {\n\t\t\tconst struct iphdr *iph = ip_hdr(head);\n\t\t\tint err = ip_route_input(head, iph->daddr, iph->saddr,\n\t\t\t\t\t\t iph->tos, head->dev);\n\t\t\tif (unlikely(err))\n\t\t\t\tgoto out_rcu_unlock;\n\n\t\t\t/*\n\t\t\t * Only an end host needs to send an ICMP\n\t\t\t * \"Fragment Reassembly Timeout\" message, per RFC792.\n\t\t\t */\n\t\t\tif (skb_rtable(head)->rt_type != RTN_LOCAL)\n\t\t\t\tgoto out_rcu_unlock;\n\n\t\t}\n\n\t\t/* Send an ICMP \"Fragment Reassembly Timeout\" message. */\n\t\ticmp_send(head, ICMP_TIME_EXCEEDED, ICMP_EXC_FRAGTIME, 0);\nout_rcu_unlock:\n\t\trcu_read_unlock();\n\t}\nout:\n\tspin_unlock(&qp->q.lock);\n\tipq_put(qp);\n}\n\n/* Find the correct entry in the \"incomplete datagrams\" queue for\n * this IP datagram, and create new one, if nothing is found.\n */\nstatic inline struct ipq *ip_find(struct net *net, struct iphdr *iph, u32 user)\n{\n\tstruct inet_frag_queue *q;\n\tstruct ip4_create_arg arg;\n\tunsigned int hash;\n\n\targ.iph = iph;\n\targ.user = user;\n\n\tread_lock(&ip4_frags.lock);\n\thash = ipqhashfn(iph->id, iph->saddr, iph->daddr, iph->protocol);\n\n\tq = inet_frag_find(&net->ipv4.frags, &ip4_frags, &arg, hash);\n\tif (q == NULL)\n\t\tgoto out_nomem;\n\n\treturn container_of(q, struct ipq, q);\n\nout_nomem:\n\tLIMIT_NETDEBUG(KERN_ERR \"ip_frag_create: no memory left !\\n\");\n\treturn NULL;\n}\n\n/* Is the fragment too far ahead to be part of ipq? */\nstatic inline int ip_frag_too_far(struct ipq *qp)\n{\n\tstruct inet_peer *peer = qp->peer;\n\tunsigned int max = sysctl_ipfrag_max_dist;\n\tunsigned int start, end;\n\n\tint rc;\n\n\tif (!peer || !max)\n\t\treturn 0;\n\n\tstart = qp->rid;\n\tend = atomic_inc_return(&peer->rid);\n\tqp->rid = end;\n\n\trc = qp->q.fragments && (end - start) > max;\n\n\tif (rc) {\n\t\tstruct net *net;\n\n\t\tnet = container_of(qp->q.net, struct net, ipv4.frags);\n\t\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);\n\t}\n\n\treturn rc;\n}\n\nstatic int ip_frag_reinit(struct ipq *qp)\n{\n\tstruct sk_buff *fp;\n\n\tif (!mod_timer(&qp->q.timer, jiffies + qp->q.net->timeout)) {\n\t\tatomic_inc(&qp->q.refcnt);\n\t\treturn -ETIMEDOUT;\n\t}\n\n\tfp = qp->q.fragments;\n\tdo {\n\t\tstruct sk_buff *xp = fp->next;\n\t\tfrag_kfree_skb(qp->q.net, fp);\n\t\tfp = xp;\n\t} while (fp);\n\n\tqp->q.last_in = 0;\n\tqp->q.len = 0;\n\tqp->q.meat = 0;\n\tqp->q.fragments = NULL;\n\tqp->q.fragments_tail = NULL;\n\tqp->iif = 0;\n\tqp->ecn = 0;\n\n\treturn 0;\n}\n\n/* Add new segment to existing queue. */\nstatic int ip_frag_queue(struct ipq *qp, struct sk_buff *skb)\n{\n\tstruct sk_buff *prev, *next;\n\tstruct net_device *dev;\n\tint flags, offset;\n\tint ihl, end;\n\tint err = -ENOENT;\n\tu8 ecn;\n\n\tif (qp->q.last_in & INET_FRAG_COMPLETE)\n\t\tgoto err;\n\n\tif (!(IPCB(skb)->flags & IPSKB_FRAG_COMPLETE) &&\n\t    unlikely(ip_frag_too_far(qp)) &&\n\t    unlikely(err = ip_frag_reinit(qp))) {\n\t\tipq_kill(qp);\n\t\tgoto err;\n\t}\n\n\tecn = ip4_frag_ecn(ip_hdr(skb)->tos);\n\toffset = ntohs(ip_hdr(skb)->frag_off);\n\tflags = offset & ~IP_OFFSET;\n\toffset &= IP_OFFSET;\n\toffset <<= 3;\t\t/* offset is in 8-byte chunks */\n\tihl = ip_hdrlen(skb);\n\n\t/* Determine the position of this fragment. */\n\tend = offset + skb->len - ihl;\n\terr = -EINVAL;\n\n\t/* Is this the final fragment? */\n\tif ((flags & IP_MF) == 0) {\n\t\t/* If we already have some bits beyond end\n\t\t * or have different end, the segment is corrrupted.\n\t\t */\n\t\tif (end < qp->q.len ||\n\t\t    ((qp->q.last_in & INET_FRAG_LAST_IN) && end != qp->q.len))\n\t\t\tgoto err;\n\t\tqp->q.last_in |= INET_FRAG_LAST_IN;\n\t\tqp->q.len = end;\n\t} else {\n\t\tif (end&7) {\n\t\t\tend &= ~7;\n\t\t\tif (skb->ip_summed != CHECKSUM_UNNECESSARY)\n\t\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t}\n\t\tif (end > qp->q.len) {\n\t\t\t/* Some bits beyond end -> corruption. */\n\t\t\tif (qp->q.last_in & INET_FRAG_LAST_IN)\n\t\t\t\tgoto err;\n\t\t\tqp->q.len = end;\n\t\t}\n\t}\n\tif (end == offset)\n\t\tgoto err;\n\n\terr = -ENOMEM;\n\tif (pskb_pull(skb, ihl) == NULL)\n\t\tgoto err;\n\n\terr = pskb_trim_rcsum(skb, end - offset);\n\tif (err)\n\t\tgoto err;\n\n\t/* Find out which fragments are in front and at the back of us\n\t * in the chain of fragments so far.  We must know where to put\n\t * this fragment, right?\n\t */\n\tprev = qp->q.fragments_tail;\n\tif (!prev || FRAG_CB(prev)->offset < offset) {\n\t\tnext = NULL;\n\t\tgoto found;\n\t}\n\tprev = NULL;\n\tfor (next = qp->q.fragments; next != NULL; next = next->next) {\n\t\tif (FRAG_CB(next)->offset >= offset)\n\t\t\tbreak;\t/* bingo! */\n\t\tprev = next;\n\t}\n\nfound:\n\t/* We found where to put this one.  Check for overlap with\n\t * preceding fragment, and, if needed, align things so that\n\t * any overlaps are eliminated.\n\t */\n\tif (prev) {\n\t\tint i = (FRAG_CB(prev)->offset + prev->len) - offset;\n\n\t\tif (i > 0) {\n\t\t\toffset += i;\n\t\t\terr = -EINVAL;\n\t\t\tif (end <= offset)\n\t\t\t\tgoto err;\n\t\t\terr = -ENOMEM;\n\t\t\tif (!pskb_pull(skb, i))\n\t\t\t\tgoto err;\n\t\t\tif (skb->ip_summed != CHECKSUM_UNNECESSARY)\n\t\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t}\n\t}\n\n\terr = -ENOMEM;\n\n\twhile (next && FRAG_CB(next)->offset < end) {\n\t\tint i = end - FRAG_CB(next)->offset; /* overlap is 'i' bytes */\n\n\t\tif (i < next->len) {\n\t\t\t/* Eat head of the next overlapped fragment\n\t\t\t * and leave the loop. The next ones cannot overlap.\n\t\t\t */\n\t\t\tif (!pskb_pull(next, i))\n\t\t\t\tgoto err;\n\t\t\tFRAG_CB(next)->offset += i;\n\t\t\tqp->q.meat -= i;\n\t\t\tif (next->ip_summed != CHECKSUM_UNNECESSARY)\n\t\t\t\tnext->ip_summed = CHECKSUM_NONE;\n\t\t\tbreak;\n\t\t} else {\n\t\t\tstruct sk_buff *free_it = next;\n\n\t\t\t/* Old fragment is completely overridden with\n\t\t\t * new one drop it.\n\t\t\t */\n\t\t\tnext = next->next;\n\n\t\t\tif (prev)\n\t\t\t\tprev->next = next;\n\t\t\telse\n\t\t\t\tqp->q.fragments = next;\n\n\t\t\tqp->q.meat -= free_it->len;\n\t\t\tfrag_kfree_skb(qp->q.net, free_it);\n\t\t}\n\t}\n\n\tFRAG_CB(skb)->offset = offset;\n\n\t/* Insert this fragment in the chain of fragments. */\n\tskb->next = next;\n\tif (!next)\n\t\tqp->q.fragments_tail = skb;\n\tif (prev)\n\t\tprev->next = skb;\n\telse\n\t\tqp->q.fragments = skb;\n\n\tdev = skb->dev;\n\tif (dev) {\n\t\tqp->iif = dev->ifindex;\n\t\tskb->dev = NULL;\n\t}\n\tqp->q.stamp = skb->tstamp;\n\tqp->q.meat += skb->len;\n\tqp->ecn |= ecn;\n\tatomic_add(skb->truesize, &qp->q.net->mem);\n\tif (offset == 0)\n\t\tqp->q.last_in |= INET_FRAG_FIRST_IN;\n\n\tif (qp->q.last_in == (INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN) &&\n\t    qp->q.meat == qp->q.len)\n\t\treturn ip_frag_reasm(qp, prev, dev);\n\n\twrite_lock(&ip4_frags.lock);\n\tlist_move_tail(&qp->q.lru_list, &qp->q.net->lru_list);\n\twrite_unlock(&ip4_frags.lock);\n\treturn -EINPROGRESS;\n\nerr:\n\tkfree_skb(skb);\n\treturn err;\n}\n\n\n/* Build a new IP datagram from all its fragments. */\n\nstatic int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,\n\t\t\t struct net_device *dev)\n{\n\tstruct net *net = container_of(qp->q.net, struct net, ipv4.frags);\n\tstruct iphdr *iph;\n\tstruct sk_buff *fp, *head = qp->q.fragments;\n\tint len;\n\tint ihlen;\n\tint err;\n\n\tipq_kill(qp);\n\n\t/* Make the one we just received the head. */\n\tif (prev) {\n\t\thead = prev->next;\n\t\tfp = skb_clone(head, GFP_ATOMIC);\n\t\tif (!fp)\n\t\t\tgoto out_nomem;\n\n\t\tfp->next = head->next;\n\t\tif (!fp->next)\n\t\t\tqp->q.fragments_tail = fp;\n\t\tprev->next = fp;\n\n\t\tskb_morph(head, qp->q.fragments);\n\t\thead->next = qp->q.fragments->next;\n\n\t\tkfree_skb(qp->q.fragments);\n\t\tqp->q.fragments = head;\n\t}\n\n\tWARN_ON(head == NULL);\n\tWARN_ON(FRAG_CB(head)->offset != 0);\n\n\t/* Allocate a new buffer for the datagram. */\n\tihlen = ip_hdrlen(head);\n\tlen = ihlen + qp->q.len;\n\n\terr = -E2BIG;\n\tif (len > 65535)\n\t\tgoto out_oversize;\n\n\t/* Head of list must not be cloned. */\n\tif (skb_cloned(head) && pskb_expand_head(head, 0, 0, GFP_ATOMIC))\n\t\tgoto out_nomem;\n\n\t/* If the first fragment is fragmented itself, we split\n\t * it to two chunks: the first with data and paged part\n\t * and the second, holding only fragments. */\n\tif (skb_has_frag_list(head)) {\n\t\tstruct sk_buff *clone;\n\t\tint i, plen = 0;\n\n\t\tif ((clone = alloc_skb(0, GFP_ATOMIC)) == NULL)\n\t\t\tgoto out_nomem;\n\t\tclone->next = head->next;\n\t\thead->next = clone;\n\t\tskb_shinfo(clone)->frag_list = skb_shinfo(head)->frag_list;\n\t\tskb_frag_list_init(head);\n\t\tfor (i=0; i<skb_shinfo(head)->nr_frags; i++)\n\t\t\tplen += skb_shinfo(head)->frags[i].size;\n\t\tclone->len = clone->data_len = head->data_len - plen;\n\t\thead->data_len -= clone->len;\n\t\thead->len -= clone->len;\n\t\tclone->csum = 0;\n\t\tclone->ip_summed = head->ip_summed;\n\t\tatomic_add(clone->truesize, &qp->q.net->mem);\n\t}\n\n\tskb_shinfo(head)->frag_list = head->next;\n\tskb_push(head, head->data - skb_network_header(head));\n\n\tfor (fp=head->next; fp; fp = fp->next) {\n\t\thead->data_len += fp->len;\n\t\thead->len += fp->len;\n\t\tif (head->ip_summed != fp->ip_summed)\n\t\t\thead->ip_summed = CHECKSUM_NONE;\n\t\telse if (head->ip_summed == CHECKSUM_COMPLETE)\n\t\t\thead->csum = csum_add(head->csum, fp->csum);\n\t\thead->truesize += fp->truesize;\n\t}\n\tatomic_sub(head->truesize, &qp->q.net->mem);\n\n\thead->next = NULL;\n\thead->dev = dev;\n\thead->tstamp = qp->q.stamp;\n\n\tiph = ip_hdr(head);\n\tiph->frag_off = 0;\n\tiph->tot_len = htons(len);\n\t/* RFC3168 5.3 Fragmentation support\n\t * If one fragment had INET_ECN_NOT_ECT,\n\t *\treassembled frame also has INET_ECN_NOT_ECT\n\t * Elif one fragment had INET_ECN_CE\n\t *\treassembled frame also has INET_ECN_CE\n\t */\n\tif (qp->ecn & IPFRAG_ECN_CLEAR)\n\t\tiph->tos &= ~INET_ECN_MASK;\n\telse if (qp->ecn & IPFRAG_ECN_SET_CE)\n\t\tiph->tos |= INET_ECN_CE;\n\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMOKS);\n\tqp->q.fragments = NULL;\n\tqp->q.fragments_tail = NULL;\n\treturn 0;\n\nout_nomem:\n\tLIMIT_NETDEBUG(KERN_ERR \"IP: queue_glue: no memory for gluing \"\n\t\t\t      \"queue %p\\n\", qp);\n\terr = -ENOMEM;\n\tgoto out_fail;\nout_oversize:\n\tif (net_ratelimit())\n\t\tprintk(KERN_INFO \"Oversized IP packet from %pI4.\\n\",\n\t\t\t&qp->saddr);\nout_fail:\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);\n\treturn err;\n}\n\n/* Process an incoming IP datagram fragment. */\nint ip_defrag(struct sk_buff *skb, u32 user)\n{\n\tstruct ipq *qp;\n\tstruct net *net;\n\n\tnet = skb->dev ? dev_net(skb->dev) : dev_net(skb_dst(skb)->dev);\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMREQDS);\n\n\t/* Start by cleaning up the memory. */\n\tif (atomic_read(&net->ipv4.frags.mem) > net->ipv4.frags.high_thresh)\n\t\tip_evictor(net);\n\n\t/* Lookup (or create) queue header */\n\tif ((qp = ip_find(net, ip_hdr(skb), user)) != NULL) {\n\t\tint ret;\n\n\t\tspin_lock(&qp->q.lock);\n\n\t\tret = ip_frag_queue(qp, skb);\n\n\t\tspin_unlock(&qp->q.lock);\n\t\tipq_put(qp);\n\t\treturn ret;\n\t}\n\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);\n\tkfree_skb(skb);\n\treturn -ENOMEM;\n}\nEXPORT_SYMBOL(ip_defrag);\n\n#ifdef CONFIG_SYSCTL\nstatic int zero;\n\nstatic struct ctl_table ip4_frags_ns_ctl_table[] = {\n\t{\n\t\t.procname\t= \"ipfrag_high_thresh\",\n\t\t.data\t\t= &init_net.ipv4.frags.high_thresh,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec\n\t},\n\t{\n\t\t.procname\t= \"ipfrag_low_thresh\",\n\t\t.data\t\t= &init_net.ipv4.frags.low_thresh,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec\n\t},\n\t{\n\t\t.procname\t= \"ipfrag_time\",\n\t\t.data\t\t= &init_net.ipv4.frags.timeout,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{ }\n};\n\nstatic struct ctl_table ip4_frags_ctl_table[] = {\n\t{\n\t\t.procname\t= \"ipfrag_secret_interval\",\n\t\t.data\t\t= &ip4_frags.secret_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"ipfrag_max_dist\",\n\t\t.data\t\t= &sysctl_ipfrag_max_dist,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_minmax,\n\t\t.extra1\t\t= &zero\n\t},\n\t{ }\n};\n\nstatic int __net_init ip4_frags_ns_ctl_register(struct net *net)\n{\n\tstruct ctl_table *table;\n\tstruct ctl_table_header *hdr;\n\n\ttable = ip4_frags_ns_ctl_table;\n\tif (!net_eq(net, &init_net)) {\n\t\ttable = kmemdup(table, sizeof(ip4_frags_ns_ctl_table), GFP_KERNEL);\n\t\tif (table == NULL)\n\t\t\tgoto err_alloc;\n\n\t\ttable[0].data = &net->ipv4.frags.high_thresh;\n\t\ttable[1].data = &net->ipv4.frags.low_thresh;\n\t\ttable[2].data = &net->ipv4.frags.timeout;\n\t}\n\n\thdr = register_net_sysctl_table(net, net_ipv4_ctl_path, table);\n\tif (hdr == NULL)\n\t\tgoto err_reg;\n\n\tnet->ipv4.frags_hdr = hdr;\n\treturn 0;\n\nerr_reg:\n\tif (!net_eq(net, &init_net))\n\t\tkfree(table);\nerr_alloc:\n\treturn -ENOMEM;\n}\n\nstatic void __net_exit ip4_frags_ns_ctl_unregister(struct net *net)\n{\n\tstruct ctl_table *table;\n\n\ttable = net->ipv4.frags_hdr->ctl_table_arg;\n\tunregister_net_sysctl_table(net->ipv4.frags_hdr);\n\tkfree(table);\n}\n\nstatic void ip4_frags_ctl_register(void)\n{\n\tregister_net_sysctl_rotable(net_ipv4_ctl_path, ip4_frags_ctl_table);\n}\n#else\nstatic inline int ip4_frags_ns_ctl_register(struct net *net)\n{\n\treturn 0;\n}\n\nstatic inline void ip4_frags_ns_ctl_unregister(struct net *net)\n{\n}\n\nstatic inline void ip4_frags_ctl_register(void)\n{\n}\n#endif\n\nstatic int __net_init ipv4_frags_init_net(struct net *net)\n{\n\t/*\n\t * Fragment cache limits. We will commit 256K at one time. Should we\n\t * cross that limit we will prune down to 192K. This should cope with\n\t * even the most extreme cases without allowing an attacker to\n\t * measurably harm machine performance.\n\t */\n\tnet->ipv4.frags.high_thresh = 256 * 1024;\n\tnet->ipv4.frags.low_thresh = 192 * 1024;\n\t/*\n\t * Important NOTE! Fragment queue must be destroyed before MSL expires.\n\t * RFC791 is wrong proposing to prolongate timer each fragment arrival\n\t * by TTL.\n\t */\n\tnet->ipv4.frags.timeout = IP_FRAG_TIME;\n\n\tinet_frags_init_net(&net->ipv4.frags);\n\n\treturn ip4_frags_ns_ctl_register(net);\n}\n\nstatic void __net_exit ipv4_frags_exit_net(struct net *net)\n{\n\tip4_frags_ns_ctl_unregister(net);\n\tinet_frags_exit_net(&net->ipv4.frags, &ip4_frags);\n}\n\nstatic struct pernet_operations ip4_frags_ops = {\n\t.init = ipv4_frags_init_net,\n\t.exit = ipv4_frags_exit_net,\n};\n\nvoid __init ipfrag_init(void)\n{\n\tip4_frags_ctl_register();\n\tregister_pernet_subsys(&ip4_frags_ops);\n\tip4_frags.hashfn = ip4_hashfn;\n\tip4_frags.constructor = ip4_frag_init;\n\tip4_frags.destructor = ip4_frag_free;\n\tip4_frags.skb_free = NULL;\n\tip4_frags.qsize = sizeof(struct ipq);\n\tip4_frags.match = ip4_frag_match;\n\tip4_frags.frag_expire = ip_expire;\n\tip4_frags.secret_interval = 10 * 60 * HZ;\n\tinet_frags_init(&ip4_frags);\n}\n"], "fixing_code": ["/*\n * INET\t\tAn implementation of the TCP/IP protocol suite for the LINUX\n *\t\toperating system.  INET is implemented using the  BSD Socket\n *\t\tinterface as the means of communication with the user level.\n *\n *\t\tThe IP fragmentation functionality.\n *\n * Authors:\tFred N. van Kempen <waltje@uWalt.NL.Mugnet.ORG>\n *\t\tAlan Cox <alan@lxorguk.ukuu.org.uk>\n *\n * Fixes:\n *\t\tAlan Cox\t:\tSplit from ip.c , see ip_input.c for history.\n *\t\tDavid S. Miller :\tBegin massive cleanup...\n *\t\tAndi Kleen\t:\tAdd sysctls.\n *\t\txxxx\t\t:\tOverlapfrag bug.\n *\t\tUltima          :       ip_expire() kernel panic.\n *\t\tBill Hawes\t:\tFrag accounting and evictor fixes.\n *\t\tJohn McDonald\t:\t0 length frag bug.\n *\t\tAlexey Kuznetsov:\tSMP races, threading, cleanup.\n *\t\tPatrick McHardy :\tLRU queue of frag heads for evictor.\n */\n\n#include <linux/compiler.h>\n#include <linux/module.h>\n#include <linux/types.h>\n#include <linux/mm.h>\n#include <linux/jiffies.h>\n#include <linux/skbuff.h>\n#include <linux/list.h>\n#include <linux/ip.h>\n#include <linux/icmp.h>\n#include <linux/netdevice.h>\n#include <linux/jhash.h>\n#include <linux/random.h>\n#include <linux/slab.h>\n#include <net/route.h>\n#include <net/dst.h>\n#include <net/sock.h>\n#include <net/ip.h>\n#include <net/icmp.h>\n#include <net/checksum.h>\n#include <net/inetpeer.h>\n#include <net/inet_frag.h>\n#include <linux/tcp.h>\n#include <linux/udp.h>\n#include <linux/inet.h>\n#include <linux/netfilter_ipv4.h>\n#include <net/inet_ecn.h>\n\n/* NOTE. Logic of IP defragmentation is parallel to corresponding IPv6\n * code now. If you change something here, _PLEASE_ update ipv6/reassembly.c\n * as well. Or notify me, at least. --ANK\n */\n\nstatic int sysctl_ipfrag_max_dist __read_mostly = 64;\n\nstruct ipfrag_skb_cb\n{\n\tstruct inet_skb_parm\th;\n\tint\t\t\toffset;\n};\n\n#define FRAG_CB(skb)\t((struct ipfrag_skb_cb *)((skb)->cb))\n\n/* Describe an entry in the \"incomplete datagrams\" queue. */\nstruct ipq {\n\tstruct inet_frag_queue q;\n\n\tu32\t\tuser;\n\t__be32\t\tsaddr;\n\t__be32\t\tdaddr;\n\t__be16\t\tid;\n\tu8\t\tprotocol;\n\tu8\t\tecn; /* RFC3168 support */\n\tint             iif;\n\tunsigned int    rid;\n\tstruct inet_peer *peer;\n};\n\n#define IPFRAG_ECN_CLEAR  0x01 /* one frag had INET_ECN_NOT_ECT */\n#define IPFRAG_ECN_SET_CE 0x04 /* one frag had INET_ECN_CE */\n\nstatic inline u8 ip4_frag_ecn(u8 tos)\n{\n\ttos = (tos & INET_ECN_MASK) + 1;\n\t/*\n\t * After the last operation we have (in binary):\n\t * INET_ECN_NOT_ECT => 001\n\t * INET_ECN_ECT_1   => 010\n\t * INET_ECN_ECT_0   => 011\n\t * INET_ECN_CE      => 100\n\t */\n\treturn (tos & 2) ? 0 : tos;\n}\n\nstatic struct inet_frags ip4_frags;\n\nint ip_frag_nqueues(struct net *net)\n{\n\treturn net->ipv4.frags.nqueues;\n}\n\nint ip_frag_mem(struct net *net)\n{\n\treturn atomic_read(&net->ipv4.frags.mem);\n}\n\nstatic int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,\n\t\t\t struct net_device *dev);\n\nstruct ip4_create_arg {\n\tstruct iphdr *iph;\n\tu32 user;\n};\n\nstatic unsigned int ipqhashfn(__be16 id, __be32 saddr, __be32 daddr, u8 prot)\n{\n\treturn jhash_3words((__force u32)id << 16 | prot,\n\t\t\t    (__force u32)saddr, (__force u32)daddr,\n\t\t\t    ip4_frags.rnd) & (INETFRAGS_HASHSZ - 1);\n}\n\nstatic unsigned int ip4_hashfn(struct inet_frag_queue *q)\n{\n\tstruct ipq *ipq;\n\n\tipq = container_of(q, struct ipq, q);\n\treturn ipqhashfn(ipq->id, ipq->saddr, ipq->daddr, ipq->protocol);\n}\n\nstatic int ip4_frag_match(struct inet_frag_queue *q, void *a)\n{\n\tstruct ipq *qp;\n\tstruct ip4_create_arg *arg = a;\n\n\tqp = container_of(q, struct ipq, q);\n\treturn\tqp->id == arg->iph->id &&\n\t\t\tqp->saddr == arg->iph->saddr &&\n\t\t\tqp->daddr == arg->iph->daddr &&\n\t\t\tqp->protocol == arg->iph->protocol &&\n\t\t\tqp->user == arg->user;\n}\n\n/* Memory Tracking Functions. */\nstatic void frag_kfree_skb(struct netns_frags *nf, struct sk_buff *skb)\n{\n\tatomic_sub(skb->truesize, &nf->mem);\n\tkfree_skb(skb);\n}\n\nstatic void ip4_frag_init(struct inet_frag_queue *q, void *a)\n{\n\tstruct ipq *qp = container_of(q, struct ipq, q);\n\tstruct ip4_create_arg *arg = a;\n\n\tqp->protocol = arg->iph->protocol;\n\tqp->id = arg->iph->id;\n\tqp->ecn = ip4_frag_ecn(arg->iph->tos);\n\tqp->saddr = arg->iph->saddr;\n\tqp->daddr = arg->iph->daddr;\n\tqp->user = arg->user;\n\tqp->peer = sysctl_ipfrag_max_dist ?\n\t\tinet_getpeer_v4(arg->iph->saddr, 1) : NULL;\n}\n\nstatic __inline__ void ip4_frag_free(struct inet_frag_queue *q)\n{\n\tstruct ipq *qp;\n\n\tqp = container_of(q, struct ipq, q);\n\tif (qp->peer)\n\t\tinet_putpeer(qp->peer);\n}\n\n\n/* Destruction primitives. */\n\nstatic __inline__ void ipq_put(struct ipq *ipq)\n{\n\tinet_frag_put(&ipq->q, &ip4_frags);\n}\n\n/* Kill ipq entry. It is not destroyed immediately,\n * because caller (and someone more) holds reference count.\n */\nstatic void ipq_kill(struct ipq *ipq)\n{\n\tinet_frag_kill(&ipq->q, &ip4_frags);\n}\n\n/* Memory limiting on fragments.  Evictor trashes the oldest\n * fragment queue until we are back under the threshold.\n */\nstatic void ip_evictor(struct net *net)\n{\n\tint evicted;\n\n\tevicted = inet_frag_evictor(&net->ipv4.frags, &ip4_frags);\n\tif (evicted)\n\t\tIP_ADD_STATS_BH(net, IPSTATS_MIB_REASMFAILS, evicted);\n}\n\n/*\n * Oops, a fragment queue timed out.  Kill it and send an ICMP reply.\n */\nstatic void ip_expire(unsigned long arg)\n{\n\tstruct ipq *qp;\n\tstruct net *net;\n\n\tqp = container_of((struct inet_frag_queue *) arg, struct ipq, q);\n\tnet = container_of(qp->q.net, struct net, ipv4.frags);\n\n\tspin_lock(&qp->q.lock);\n\n\tif (qp->q.last_in & INET_FRAG_COMPLETE)\n\t\tgoto out;\n\n\tipq_kill(qp);\n\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMTIMEOUT);\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);\n\n\tif ((qp->q.last_in & INET_FRAG_FIRST_IN) && qp->q.fragments != NULL) {\n\t\tstruct sk_buff *head = qp->q.fragments;\n\t\tconst struct iphdr *iph;\n\t\tint err;\n\n\t\trcu_read_lock();\n\t\thead->dev = dev_get_by_index_rcu(net, qp->iif);\n\t\tif (!head->dev)\n\t\t\tgoto out_rcu_unlock;\n\n\t\t/* skb dst is stale, drop it, and perform route lookup again */\n\t\tskb_dst_drop(head);\n\t\tiph = ip_hdr(head);\n\t\terr = ip_route_input_noref(head, iph->daddr, iph->saddr,\n\t\t\t\t\t   iph->tos, head->dev);\n\t\tif (err)\n\t\t\tgoto out_rcu_unlock;\n\n\t\t/*\n\t\t * Only an end host needs to send an ICMP\n\t\t * \"Fragment Reassembly Timeout\" message, per RFC792.\n\t\t */\n\t\tif (qp->user == IP_DEFRAG_CONNTRACK_IN &&\n\t\t    skb_rtable(head)->rt_type != RTN_LOCAL)\n\t\t\tgoto out_rcu_unlock;\n\n\n\t\t/* Send an ICMP \"Fragment Reassembly Timeout\" message. */\n\t\ticmp_send(head, ICMP_TIME_EXCEEDED, ICMP_EXC_FRAGTIME, 0);\nout_rcu_unlock:\n\t\trcu_read_unlock();\n\t}\nout:\n\tspin_unlock(&qp->q.lock);\n\tipq_put(qp);\n}\n\n/* Find the correct entry in the \"incomplete datagrams\" queue for\n * this IP datagram, and create new one, if nothing is found.\n */\nstatic inline struct ipq *ip_find(struct net *net, struct iphdr *iph, u32 user)\n{\n\tstruct inet_frag_queue *q;\n\tstruct ip4_create_arg arg;\n\tunsigned int hash;\n\n\targ.iph = iph;\n\targ.user = user;\n\n\tread_lock(&ip4_frags.lock);\n\thash = ipqhashfn(iph->id, iph->saddr, iph->daddr, iph->protocol);\n\n\tq = inet_frag_find(&net->ipv4.frags, &ip4_frags, &arg, hash);\n\tif (q == NULL)\n\t\tgoto out_nomem;\n\n\treturn container_of(q, struct ipq, q);\n\nout_nomem:\n\tLIMIT_NETDEBUG(KERN_ERR \"ip_frag_create: no memory left !\\n\");\n\treturn NULL;\n}\n\n/* Is the fragment too far ahead to be part of ipq? */\nstatic inline int ip_frag_too_far(struct ipq *qp)\n{\n\tstruct inet_peer *peer = qp->peer;\n\tunsigned int max = sysctl_ipfrag_max_dist;\n\tunsigned int start, end;\n\n\tint rc;\n\n\tif (!peer || !max)\n\t\treturn 0;\n\n\tstart = qp->rid;\n\tend = atomic_inc_return(&peer->rid);\n\tqp->rid = end;\n\n\trc = qp->q.fragments && (end - start) > max;\n\n\tif (rc) {\n\t\tstruct net *net;\n\n\t\tnet = container_of(qp->q.net, struct net, ipv4.frags);\n\t\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);\n\t}\n\n\treturn rc;\n}\n\nstatic int ip_frag_reinit(struct ipq *qp)\n{\n\tstruct sk_buff *fp;\n\n\tif (!mod_timer(&qp->q.timer, jiffies + qp->q.net->timeout)) {\n\t\tatomic_inc(&qp->q.refcnt);\n\t\treturn -ETIMEDOUT;\n\t}\n\n\tfp = qp->q.fragments;\n\tdo {\n\t\tstruct sk_buff *xp = fp->next;\n\t\tfrag_kfree_skb(qp->q.net, fp);\n\t\tfp = xp;\n\t} while (fp);\n\n\tqp->q.last_in = 0;\n\tqp->q.len = 0;\n\tqp->q.meat = 0;\n\tqp->q.fragments = NULL;\n\tqp->q.fragments_tail = NULL;\n\tqp->iif = 0;\n\tqp->ecn = 0;\n\n\treturn 0;\n}\n\n/* Add new segment to existing queue. */\nstatic int ip_frag_queue(struct ipq *qp, struct sk_buff *skb)\n{\n\tstruct sk_buff *prev, *next;\n\tstruct net_device *dev;\n\tint flags, offset;\n\tint ihl, end;\n\tint err = -ENOENT;\n\tu8 ecn;\n\n\tif (qp->q.last_in & INET_FRAG_COMPLETE)\n\t\tgoto err;\n\n\tif (!(IPCB(skb)->flags & IPSKB_FRAG_COMPLETE) &&\n\t    unlikely(ip_frag_too_far(qp)) &&\n\t    unlikely(err = ip_frag_reinit(qp))) {\n\t\tipq_kill(qp);\n\t\tgoto err;\n\t}\n\n\tecn = ip4_frag_ecn(ip_hdr(skb)->tos);\n\toffset = ntohs(ip_hdr(skb)->frag_off);\n\tflags = offset & ~IP_OFFSET;\n\toffset &= IP_OFFSET;\n\toffset <<= 3;\t\t/* offset is in 8-byte chunks */\n\tihl = ip_hdrlen(skb);\n\n\t/* Determine the position of this fragment. */\n\tend = offset + skb->len - ihl;\n\terr = -EINVAL;\n\n\t/* Is this the final fragment? */\n\tif ((flags & IP_MF) == 0) {\n\t\t/* If we already have some bits beyond end\n\t\t * or have different end, the segment is corrrupted.\n\t\t */\n\t\tif (end < qp->q.len ||\n\t\t    ((qp->q.last_in & INET_FRAG_LAST_IN) && end != qp->q.len))\n\t\t\tgoto err;\n\t\tqp->q.last_in |= INET_FRAG_LAST_IN;\n\t\tqp->q.len = end;\n\t} else {\n\t\tif (end&7) {\n\t\t\tend &= ~7;\n\t\t\tif (skb->ip_summed != CHECKSUM_UNNECESSARY)\n\t\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t}\n\t\tif (end > qp->q.len) {\n\t\t\t/* Some bits beyond end -> corruption. */\n\t\t\tif (qp->q.last_in & INET_FRAG_LAST_IN)\n\t\t\t\tgoto err;\n\t\t\tqp->q.len = end;\n\t\t}\n\t}\n\tif (end == offset)\n\t\tgoto err;\n\n\terr = -ENOMEM;\n\tif (pskb_pull(skb, ihl) == NULL)\n\t\tgoto err;\n\n\terr = pskb_trim_rcsum(skb, end - offset);\n\tif (err)\n\t\tgoto err;\n\n\t/* Find out which fragments are in front and at the back of us\n\t * in the chain of fragments so far.  We must know where to put\n\t * this fragment, right?\n\t */\n\tprev = qp->q.fragments_tail;\n\tif (!prev || FRAG_CB(prev)->offset < offset) {\n\t\tnext = NULL;\n\t\tgoto found;\n\t}\n\tprev = NULL;\n\tfor (next = qp->q.fragments; next != NULL; next = next->next) {\n\t\tif (FRAG_CB(next)->offset >= offset)\n\t\t\tbreak;\t/* bingo! */\n\t\tprev = next;\n\t}\n\nfound:\n\t/* We found where to put this one.  Check for overlap with\n\t * preceding fragment, and, if needed, align things so that\n\t * any overlaps are eliminated.\n\t */\n\tif (prev) {\n\t\tint i = (FRAG_CB(prev)->offset + prev->len) - offset;\n\n\t\tif (i > 0) {\n\t\t\toffset += i;\n\t\t\terr = -EINVAL;\n\t\t\tif (end <= offset)\n\t\t\t\tgoto err;\n\t\t\terr = -ENOMEM;\n\t\t\tif (!pskb_pull(skb, i))\n\t\t\t\tgoto err;\n\t\t\tif (skb->ip_summed != CHECKSUM_UNNECESSARY)\n\t\t\t\tskb->ip_summed = CHECKSUM_NONE;\n\t\t}\n\t}\n\n\terr = -ENOMEM;\n\n\twhile (next && FRAG_CB(next)->offset < end) {\n\t\tint i = end - FRAG_CB(next)->offset; /* overlap is 'i' bytes */\n\n\t\tif (i < next->len) {\n\t\t\t/* Eat head of the next overlapped fragment\n\t\t\t * and leave the loop. The next ones cannot overlap.\n\t\t\t */\n\t\t\tif (!pskb_pull(next, i))\n\t\t\t\tgoto err;\n\t\t\tFRAG_CB(next)->offset += i;\n\t\t\tqp->q.meat -= i;\n\t\t\tif (next->ip_summed != CHECKSUM_UNNECESSARY)\n\t\t\t\tnext->ip_summed = CHECKSUM_NONE;\n\t\t\tbreak;\n\t\t} else {\n\t\t\tstruct sk_buff *free_it = next;\n\n\t\t\t/* Old fragment is completely overridden with\n\t\t\t * new one drop it.\n\t\t\t */\n\t\t\tnext = next->next;\n\n\t\t\tif (prev)\n\t\t\t\tprev->next = next;\n\t\t\telse\n\t\t\t\tqp->q.fragments = next;\n\n\t\t\tqp->q.meat -= free_it->len;\n\t\t\tfrag_kfree_skb(qp->q.net, free_it);\n\t\t}\n\t}\n\n\tFRAG_CB(skb)->offset = offset;\n\n\t/* Insert this fragment in the chain of fragments. */\n\tskb->next = next;\n\tif (!next)\n\t\tqp->q.fragments_tail = skb;\n\tif (prev)\n\t\tprev->next = skb;\n\telse\n\t\tqp->q.fragments = skb;\n\n\tdev = skb->dev;\n\tif (dev) {\n\t\tqp->iif = dev->ifindex;\n\t\tskb->dev = NULL;\n\t}\n\tqp->q.stamp = skb->tstamp;\n\tqp->q.meat += skb->len;\n\tqp->ecn |= ecn;\n\tatomic_add(skb->truesize, &qp->q.net->mem);\n\tif (offset == 0)\n\t\tqp->q.last_in |= INET_FRAG_FIRST_IN;\n\n\tif (qp->q.last_in == (INET_FRAG_FIRST_IN | INET_FRAG_LAST_IN) &&\n\t    qp->q.meat == qp->q.len)\n\t\treturn ip_frag_reasm(qp, prev, dev);\n\n\twrite_lock(&ip4_frags.lock);\n\tlist_move_tail(&qp->q.lru_list, &qp->q.net->lru_list);\n\twrite_unlock(&ip4_frags.lock);\n\treturn -EINPROGRESS;\n\nerr:\n\tkfree_skb(skb);\n\treturn err;\n}\n\n\n/* Build a new IP datagram from all its fragments. */\n\nstatic int ip_frag_reasm(struct ipq *qp, struct sk_buff *prev,\n\t\t\t struct net_device *dev)\n{\n\tstruct net *net = container_of(qp->q.net, struct net, ipv4.frags);\n\tstruct iphdr *iph;\n\tstruct sk_buff *fp, *head = qp->q.fragments;\n\tint len;\n\tint ihlen;\n\tint err;\n\n\tipq_kill(qp);\n\n\t/* Make the one we just received the head. */\n\tif (prev) {\n\t\thead = prev->next;\n\t\tfp = skb_clone(head, GFP_ATOMIC);\n\t\tif (!fp)\n\t\t\tgoto out_nomem;\n\n\t\tfp->next = head->next;\n\t\tif (!fp->next)\n\t\t\tqp->q.fragments_tail = fp;\n\t\tprev->next = fp;\n\n\t\tskb_morph(head, qp->q.fragments);\n\t\thead->next = qp->q.fragments->next;\n\n\t\tkfree_skb(qp->q.fragments);\n\t\tqp->q.fragments = head;\n\t}\n\n\tWARN_ON(head == NULL);\n\tWARN_ON(FRAG_CB(head)->offset != 0);\n\n\t/* Allocate a new buffer for the datagram. */\n\tihlen = ip_hdrlen(head);\n\tlen = ihlen + qp->q.len;\n\n\terr = -E2BIG;\n\tif (len > 65535)\n\t\tgoto out_oversize;\n\n\t/* Head of list must not be cloned. */\n\tif (skb_cloned(head) && pskb_expand_head(head, 0, 0, GFP_ATOMIC))\n\t\tgoto out_nomem;\n\n\t/* If the first fragment is fragmented itself, we split\n\t * it to two chunks: the first with data and paged part\n\t * and the second, holding only fragments. */\n\tif (skb_has_frag_list(head)) {\n\t\tstruct sk_buff *clone;\n\t\tint i, plen = 0;\n\n\t\tif ((clone = alloc_skb(0, GFP_ATOMIC)) == NULL)\n\t\t\tgoto out_nomem;\n\t\tclone->next = head->next;\n\t\thead->next = clone;\n\t\tskb_shinfo(clone)->frag_list = skb_shinfo(head)->frag_list;\n\t\tskb_frag_list_init(head);\n\t\tfor (i=0; i<skb_shinfo(head)->nr_frags; i++)\n\t\t\tplen += skb_shinfo(head)->frags[i].size;\n\t\tclone->len = clone->data_len = head->data_len - plen;\n\t\thead->data_len -= clone->len;\n\t\thead->len -= clone->len;\n\t\tclone->csum = 0;\n\t\tclone->ip_summed = head->ip_summed;\n\t\tatomic_add(clone->truesize, &qp->q.net->mem);\n\t}\n\n\tskb_shinfo(head)->frag_list = head->next;\n\tskb_push(head, head->data - skb_network_header(head));\n\n\tfor (fp=head->next; fp; fp = fp->next) {\n\t\thead->data_len += fp->len;\n\t\thead->len += fp->len;\n\t\tif (head->ip_summed != fp->ip_summed)\n\t\t\thead->ip_summed = CHECKSUM_NONE;\n\t\telse if (head->ip_summed == CHECKSUM_COMPLETE)\n\t\t\thead->csum = csum_add(head->csum, fp->csum);\n\t\thead->truesize += fp->truesize;\n\t}\n\tatomic_sub(head->truesize, &qp->q.net->mem);\n\n\thead->next = NULL;\n\thead->dev = dev;\n\thead->tstamp = qp->q.stamp;\n\n\tiph = ip_hdr(head);\n\tiph->frag_off = 0;\n\tiph->tot_len = htons(len);\n\t/* RFC3168 5.3 Fragmentation support\n\t * If one fragment had INET_ECN_NOT_ECT,\n\t *\treassembled frame also has INET_ECN_NOT_ECT\n\t * Elif one fragment had INET_ECN_CE\n\t *\treassembled frame also has INET_ECN_CE\n\t */\n\tif (qp->ecn & IPFRAG_ECN_CLEAR)\n\t\tiph->tos &= ~INET_ECN_MASK;\n\telse if (qp->ecn & IPFRAG_ECN_SET_CE)\n\t\tiph->tos |= INET_ECN_CE;\n\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMOKS);\n\tqp->q.fragments = NULL;\n\tqp->q.fragments_tail = NULL;\n\treturn 0;\n\nout_nomem:\n\tLIMIT_NETDEBUG(KERN_ERR \"IP: queue_glue: no memory for gluing \"\n\t\t\t      \"queue %p\\n\", qp);\n\terr = -ENOMEM;\n\tgoto out_fail;\nout_oversize:\n\tif (net_ratelimit())\n\t\tprintk(KERN_INFO \"Oversized IP packet from %pI4.\\n\",\n\t\t\t&qp->saddr);\nout_fail:\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);\n\treturn err;\n}\n\n/* Process an incoming IP datagram fragment. */\nint ip_defrag(struct sk_buff *skb, u32 user)\n{\n\tstruct ipq *qp;\n\tstruct net *net;\n\n\tnet = skb->dev ? dev_net(skb->dev) : dev_net(skb_dst(skb)->dev);\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMREQDS);\n\n\t/* Start by cleaning up the memory. */\n\tif (atomic_read(&net->ipv4.frags.mem) > net->ipv4.frags.high_thresh)\n\t\tip_evictor(net);\n\n\t/* Lookup (or create) queue header */\n\tif ((qp = ip_find(net, ip_hdr(skb), user)) != NULL) {\n\t\tint ret;\n\n\t\tspin_lock(&qp->q.lock);\n\n\t\tret = ip_frag_queue(qp, skb);\n\n\t\tspin_unlock(&qp->q.lock);\n\t\tipq_put(qp);\n\t\treturn ret;\n\t}\n\n\tIP_INC_STATS_BH(net, IPSTATS_MIB_REASMFAILS);\n\tkfree_skb(skb);\n\treturn -ENOMEM;\n}\nEXPORT_SYMBOL(ip_defrag);\n\n#ifdef CONFIG_SYSCTL\nstatic int zero;\n\nstatic struct ctl_table ip4_frags_ns_ctl_table[] = {\n\t{\n\t\t.procname\t= \"ipfrag_high_thresh\",\n\t\t.data\t\t= &init_net.ipv4.frags.high_thresh,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec\n\t},\n\t{\n\t\t.procname\t= \"ipfrag_low_thresh\",\n\t\t.data\t\t= &init_net.ipv4.frags.low_thresh,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec\n\t},\n\t{\n\t\t.procname\t= \"ipfrag_time\",\n\t\t.data\t\t= &init_net.ipv4.frags.timeout,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{ }\n};\n\nstatic struct ctl_table ip4_frags_ctl_table[] = {\n\t{\n\t\t.procname\t= \"ipfrag_secret_interval\",\n\t\t.data\t\t= &ip4_frags.secret_interval,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_jiffies,\n\t},\n\t{\n\t\t.procname\t= \"ipfrag_max_dist\",\n\t\t.data\t\t= &sysctl_ipfrag_max_dist,\n\t\t.maxlen\t\t= sizeof(int),\n\t\t.mode\t\t= 0644,\n\t\t.proc_handler\t= proc_dointvec_minmax,\n\t\t.extra1\t\t= &zero\n\t},\n\t{ }\n};\n\nstatic int __net_init ip4_frags_ns_ctl_register(struct net *net)\n{\n\tstruct ctl_table *table;\n\tstruct ctl_table_header *hdr;\n\n\ttable = ip4_frags_ns_ctl_table;\n\tif (!net_eq(net, &init_net)) {\n\t\ttable = kmemdup(table, sizeof(ip4_frags_ns_ctl_table), GFP_KERNEL);\n\t\tif (table == NULL)\n\t\t\tgoto err_alloc;\n\n\t\ttable[0].data = &net->ipv4.frags.high_thresh;\n\t\ttable[1].data = &net->ipv4.frags.low_thresh;\n\t\ttable[2].data = &net->ipv4.frags.timeout;\n\t}\n\n\thdr = register_net_sysctl_table(net, net_ipv4_ctl_path, table);\n\tif (hdr == NULL)\n\t\tgoto err_reg;\n\n\tnet->ipv4.frags_hdr = hdr;\n\treturn 0;\n\nerr_reg:\n\tif (!net_eq(net, &init_net))\n\t\tkfree(table);\nerr_alloc:\n\treturn -ENOMEM;\n}\n\nstatic void __net_exit ip4_frags_ns_ctl_unregister(struct net *net)\n{\n\tstruct ctl_table *table;\n\n\ttable = net->ipv4.frags_hdr->ctl_table_arg;\n\tunregister_net_sysctl_table(net->ipv4.frags_hdr);\n\tkfree(table);\n}\n\nstatic void ip4_frags_ctl_register(void)\n{\n\tregister_net_sysctl_rotable(net_ipv4_ctl_path, ip4_frags_ctl_table);\n}\n#else\nstatic inline int ip4_frags_ns_ctl_register(struct net *net)\n{\n\treturn 0;\n}\n\nstatic inline void ip4_frags_ns_ctl_unregister(struct net *net)\n{\n}\n\nstatic inline void ip4_frags_ctl_register(void)\n{\n}\n#endif\n\nstatic int __net_init ipv4_frags_init_net(struct net *net)\n{\n\t/*\n\t * Fragment cache limits. We will commit 256K at one time. Should we\n\t * cross that limit we will prune down to 192K. This should cope with\n\t * even the most extreme cases without allowing an attacker to\n\t * measurably harm machine performance.\n\t */\n\tnet->ipv4.frags.high_thresh = 256 * 1024;\n\tnet->ipv4.frags.low_thresh = 192 * 1024;\n\t/*\n\t * Important NOTE! Fragment queue must be destroyed before MSL expires.\n\t * RFC791 is wrong proposing to prolongate timer each fragment arrival\n\t * by TTL.\n\t */\n\tnet->ipv4.frags.timeout = IP_FRAG_TIME;\n\n\tinet_frags_init_net(&net->ipv4.frags);\n\n\treturn ip4_frags_ns_ctl_register(net);\n}\n\nstatic void __net_exit ipv4_frags_exit_net(struct net *net)\n{\n\tip4_frags_ns_ctl_unregister(net);\n\tinet_frags_exit_net(&net->ipv4.frags, &ip4_frags);\n}\n\nstatic struct pernet_operations ip4_frags_ops = {\n\t.init = ipv4_frags_init_net,\n\t.exit = ipv4_frags_exit_net,\n};\n\nvoid __init ipfrag_init(void)\n{\n\tip4_frags_ctl_register();\n\tregister_pernet_subsys(&ip4_frags_ops);\n\tip4_frags.hashfn = ip4_hashfn;\n\tip4_frags.constructor = ip4_frag_init;\n\tip4_frags.destructor = ip4_frag_free;\n\tip4_frags.skb_free = NULL;\n\tip4_frags.qsize = sizeof(struct ipq);\n\tip4_frags.match = ip4_frag_match;\n\tip4_frags.frag_expire = ip_expire;\n\tip4_frags.secret_interval = 10 * 60 * HZ;\n\tinet_frags_init(&ip4_frags);\n}\n"], "filenames": ["net/ipv4/ip_fragment.c"], "buggy_code_start_loc": [225], "buggy_code_end_loc": [251], "fixing_code_start_loc": [226], "fixing_code_end_loc": [250], "type": "NVD-CWE-Other", "message": "The ip_expire function in net/ipv4/ip_fragment.c in the Linux kernel before 2.6.39 does not properly construct ICMP_TIME_EXCEEDED packets after a timeout, which allows remote attackers to cause a denial of service (invalid pointer dereference) via crafted fragmented packets.", "other": {"cve": {"id": "CVE-2011-1927", "sourceIdentifier": "secalert@redhat.com", "published": "2012-06-13T10:24:54.343", "lastModified": "2023-02-13T01:19:33.477", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The ip_expire function in net/ipv4/ip_fragment.c in the Linux kernel before 2.6.39 does not properly construct ICMP_TIME_EXCEEDED packets after a timeout, which allows remote attackers to cause a denial of service (invalid pointer dereference) via crafted fragmented packets."}, {"lang": "es", "value": "La funci\u00f3n ip_expire de net/ipv4/ip_fragment.c del kernel de Linux en versiones anteriores a la 2.6.39 no construye apropiadamente paquetes ICMP_TIME_EXCEEDED despu\u00e9s de un timeout. Lo que permite a atacantes remotos provocar una denegaci\u00f3n de servicio (resoluci\u00f3n de puntero inv\u00e1lido) a trav\u00e9s de paquetes fragmentados modificados."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-Other"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.6.38.8", "matchCriteriaId": "57A0A2B0-3B9F-40C2-8C7A-CD9590B51315"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:*:*:*:*:*:*:*", "matchCriteriaId": "7462DB6D-E0A6-4DBB-8E21-66B875184FFC"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc1:*:*:*:*:*:*", "matchCriteriaId": "2DDCB342-4F5F-4BF1-9624-882BBC57330D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc2:*:*:*:*:*:*", "matchCriteriaId": "C3AB4113-BF83-4587-8A85-0E4FECEE7D9B"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc3:*:*:*:*:*:*", "matchCriteriaId": "4B57F5AD-A697-4090-89B9-81BC12993A1A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc4:*:*:*:*:*:*", "matchCriteriaId": "CA141BCB-A705-4DF5-9EED-746B62C86111"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc5:*:*:*:*:*:*", "matchCriteriaId": "E9ECE134-58A3-4B9D-B9B3-F836C0EDD64C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc6:*:*:*:*:*:*", "matchCriteriaId": "56186720-6B4C-4D71-85C5-7EAC5C5D84A1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc7:*:*:*:*:*:*", "matchCriteriaId": "9BBB4630-CBED-43B9-B203-BE65BBF011AA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38:rc8:*:*:*:*:*:*", "matchCriteriaId": "FD375A78-63D7-441A-9FB0-7BC878AB4EDD"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.1:*:*:*:*:*:*:*", "matchCriteriaId": "A5BEFFDD-02BB-4A05-8372-891DBDB9AC5A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.2:*:*:*:*:*:*:*", "matchCriteriaId": "766E193D-819C-42EA-8411-AE0013AC15FA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.3:*:*:*:*:*:*:*", "matchCriteriaId": "3B39B6AF-6A83-48C2-BED2-79228F8513A6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.4:*:*:*:*:*:*:*", "matchCriteriaId": "CD8A68D1-DFE9-4ADB-9FB8-4D69AB4CAFF8"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.5:*:*:*:*:*:*:*", "matchCriteriaId": "0D6EF951-AF15-4C30-A3A5-3392AA61813C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.6:*:*:*:*:*:*:*", "matchCriteriaId": "15154FA0-65DC-4855-AC70-3ACF92313F49"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:2.6.38.7:*:*:*:*:*:*:*", "matchCriteriaId": "F4B3A9F4-A61F-4919-A173-3E459F0C5AF8"}]}]}], "references": [{"url": "http://ftp.osuosl.org/pub/linux/kernel/v2.6/ChangeLog-2.6.39", "source": "secalert@redhat.com"}, {"url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git%3Ba=commit%3Bh=64f3b9e203bd06855072e295557dca1485a2ecba", "source": "secalert@redhat.com"}, {"url": "http://www.openwall.com/lists/oss-security/2011/05/18/2", "source": "secalert@redhat.com"}, {"url": "https://github.com/torvalds/linux/commit/64f3b9e203bd06855072e295557dca1485a2ecba", "source": "secalert@redhat.com", "tags": ["Exploit", "Patch"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/64f3b9e203bd06855072e295557dca1485a2ecba"}}
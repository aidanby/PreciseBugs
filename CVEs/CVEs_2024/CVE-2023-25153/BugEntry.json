{"buggy_code": ["/*\n   Copyright The containerd Authors.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n*/\n\n// Package archive provides a Docker and OCI compatible importer\npackage archive\n\nimport (\n\t\"archive/tar\"\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"path\"\n\n\t\"github.com/containerd/containerd/archive/compression\"\n\t\"github.com/containerd/containerd/content\"\n\t\"github.com/containerd/containerd/errdefs\"\n\t\"github.com/containerd/containerd/images\"\n\t\"github.com/containerd/containerd/log\"\n\t\"github.com/containerd/containerd/platforms\"\n\tdigest \"github.com/opencontainers/go-digest\"\n\tspecs \"github.com/opencontainers/image-spec/specs-go\"\n\tocispec \"github.com/opencontainers/image-spec/specs-go/v1\"\n)\n\ntype importOpts struct {\n\tcompress bool\n}\n\n// ImportOpt is an option for importing an OCI index\ntype ImportOpt func(*importOpts) error\n\n// WithImportCompression compresses uncompressed layers on import.\n// This is used for import formats which do not include the manifest.\nfunc WithImportCompression() ImportOpt {\n\treturn func(io *importOpts) error {\n\t\tio.compress = true\n\t\treturn nil\n\t}\n}\n\n// ImportIndex imports an index from a tar archive image bundle\n//   - implements Docker v1.1, v1.2 and OCI v1.\n//   - prefers OCI v1 when provided\n//   - creates OCI index for Docker formats\n//   - normalizes Docker references and adds as OCI ref name\n//     e.g. alpine:latest -> docker.io/library/alpine:latest\n//   - existing OCI reference names are untouched\nfunc ImportIndex(ctx context.Context, store content.Store, reader io.Reader, opts ...ImportOpt) (ocispec.Descriptor, error) {\n\tvar (\n\t\ttr = tar.NewReader(reader)\n\n\t\tociLayout ocispec.ImageLayout\n\t\tmfsts     []struct {\n\t\t\tConfig   string\n\t\t\tRepoTags []string\n\t\t\tLayers   []string\n\t\t}\n\t\tsymlinks = make(map[string]string)\n\t\tblobs    = make(map[string]ocispec.Descriptor)\n\t\tiopts    importOpts\n\t)\n\n\tfor _, o := range opts {\n\t\tif err := o(&iopts); err != nil {\n\t\t\treturn ocispec.Descriptor{}, err\n\t\t}\n\t}\n\n\tfor {\n\t\thdr, err := tr.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, err\n\t\t}\n\t\tif hdr.Typeflag == tar.TypeSymlink {\n\t\t\tsymlinks[hdr.Name] = path.Join(path.Dir(hdr.Name), hdr.Linkname)\n\t\t}\n\n\t\tif hdr.Typeflag != tar.TypeReg && hdr.Typeflag != tar.TypeRegA {\n\t\t\tif hdr.Typeflag != tar.TypeDir {\n\t\t\t\tlog.G(ctx).WithField(\"file\", hdr.Name).Debug(\"file type ignored\")\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\thdrName := path.Clean(hdr.Name)\n\t\tif hdrName == ocispec.ImageLayoutFile {\n\t\t\tif err = onUntarJSON(tr, &ociLayout); err != nil {\n\t\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"untar oci layout %q: %w\", hdr.Name, err)\n\t\t\t}\n\t\t} else if hdrName == \"manifest.json\" {\n\t\t\tif err = onUntarJSON(tr, &mfsts); err != nil {\n\t\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"untar manifest %q: %w\", hdr.Name, err)\n\t\t\t}\n\t\t} else {\n\t\t\tdgst, err := onUntarBlob(ctx, tr, store, hdr.Size, \"tar-\"+hdrName)\n\t\t\tif err != nil {\n\t\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to ingest %q: %w\", hdr.Name, err)\n\t\t\t}\n\n\t\t\tblobs[hdrName] = ocispec.Descriptor{\n\t\t\t\tDigest: dgst,\n\t\t\t\tSize:   hdr.Size,\n\t\t\t}\n\t\t}\n\t}\n\n\t// If OCI layout was given, interpret the tar as an OCI layout.\n\t// When not provided, the layout of the tar will be interpreted\n\t// as Docker v1.1 or v1.2.\n\tif ociLayout.Version != \"\" {\n\t\tif ociLayout.Version != ocispec.ImageLayoutVersion {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"unsupported OCI version %s\", ociLayout.Version)\n\t\t}\n\n\t\tidx, ok := blobs[\"index.json\"]\n\t\tif !ok {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"missing index.json in OCI layout %s\", ocispec.ImageLayoutVersion)\n\t\t}\n\n\t\tidx.MediaType = ocispec.MediaTypeImageIndex\n\t\treturn idx, nil\n\t}\n\n\tif mfsts == nil {\n\t\treturn ocispec.Descriptor{}, errors.New(\"unrecognized image format\")\n\t}\n\n\tfor name, linkname := range symlinks {\n\t\tdesc, ok := blobs[linkname]\n\t\tif !ok {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"no target for symlink layer from %q to %q\", name, linkname)\n\t\t}\n\t\tblobs[name] = desc\n\t}\n\n\tidx := ocispec.Index{\n\t\tVersioned: specs.Versioned{\n\t\t\tSchemaVersion: 2,\n\t\t},\n\t}\n\tfor _, mfst := range mfsts {\n\t\tconfig, ok := blobs[mfst.Config]\n\t\tif !ok {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"image config %q not found\", mfst.Config)\n\t\t}\n\t\tconfig.MediaType = images.MediaTypeDockerSchema2Config\n\n\t\tlayers, err := resolveLayers(ctx, store, mfst.Layers, blobs, iopts.compress)\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to resolve layers: %w\", err)\n\t\t}\n\n\t\tmanifest := struct {\n\t\t\tSchemaVersion int                  `json:\"schemaVersion\"`\n\t\t\tMediaType     string               `json:\"mediaType\"`\n\t\t\tConfig        ocispec.Descriptor   `json:\"config\"`\n\t\t\tLayers        []ocispec.Descriptor `json:\"layers\"`\n\t\t}{\n\t\t\tSchemaVersion: 2,\n\t\t\tMediaType:     images.MediaTypeDockerSchema2Manifest,\n\t\t\tConfig:        config,\n\t\t\tLayers:        layers,\n\t\t}\n\n\t\tdesc, err := writeManifest(ctx, store, manifest, manifest.MediaType)\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"write docker manifest: %w\", err)\n\t\t}\n\n\t\timgPlatforms, err := images.Platforms(ctx, store, desc)\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"unable to resolve platform: %w\", err)\n\t\t}\n\t\tif len(imgPlatforms) > 0 {\n\t\t\t// Only one platform can be resolved from non-index manifest,\n\t\t\t// The platform can only come from the config included above,\n\t\t\t// if the config has no platform it can be safely omitted.\n\t\t\tdesc.Platform = &imgPlatforms[0]\n\n\t\t\t// If the image we've just imported is a Windows image without the OSVersion set,\n\t\t\t// we could just assume it matches this host's OS Version. Without this, the\n\t\t\t// children labels might not be set on the image content, leading to it being\n\t\t\t// garbage collected, breaking the image.\n\t\t\t// See: https://github.com/containerd/containerd/issues/5690\n\t\t\tif desc.Platform.OS == \"windows\" && desc.Platform.OSVersion == \"\" {\n\t\t\t\tplatform := platforms.DefaultSpec()\n\t\t\t\tdesc.Platform.OSVersion = platform.OSVersion\n\t\t\t}\n\t\t}\n\n\t\tif len(mfst.RepoTags) == 0 {\n\t\t\tidx.Manifests = append(idx.Manifests, desc)\n\t\t} else {\n\t\t\t// Add descriptor per tag\n\t\t\tfor _, ref := range mfst.RepoTags {\n\t\t\t\tmfstdesc := desc\n\n\t\t\t\tnormalized, err := normalizeReference(ref)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn ocispec.Descriptor{}, err\n\t\t\t\t}\n\n\t\t\t\tmfstdesc.Annotations = map[string]string{\n\t\t\t\t\timages.AnnotationImageName: normalized,\n\t\t\t\t\tocispec.AnnotationRefName:  ociReferenceName(normalized),\n\t\t\t\t}\n\n\t\t\t\tidx.Manifests = append(idx.Manifests, mfstdesc)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn writeManifest(ctx, store, idx, ocispec.MediaTypeImageIndex)\n}\n\nfunc onUntarJSON(r io.Reader, j interface{}) error {\n\tb, err := io.ReadAll(r)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn json.Unmarshal(b, j)\n}\n\nfunc onUntarBlob(ctx context.Context, r io.Reader, store content.Ingester, size int64, ref string) (digest.Digest, error) {\n\tdgstr := digest.Canonical.Digester()\n\n\tif err := content.WriteBlob(ctx, store, ref, io.TeeReader(r, dgstr.Hash()), ocispec.Descriptor{Size: size}); err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn dgstr.Digest(), nil\n}\n\nfunc resolveLayers(ctx context.Context, store content.Store, layerFiles []string, blobs map[string]ocispec.Descriptor, compress bool) ([]ocispec.Descriptor, error) {\n\tlayers := make([]ocispec.Descriptor, len(layerFiles))\n\tdescs := map[digest.Digest]*ocispec.Descriptor{}\n\tfilters := []string{}\n\tfor i, f := range layerFiles {\n\t\tdesc, ok := blobs[f]\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"layer %q not found\", f)\n\t\t}\n\t\tlayers[i] = desc\n\t\tdescs[desc.Digest] = &layers[i]\n\t\tfilters = append(filters, \"labels.\\\"containerd.io/uncompressed\\\"==\"+desc.Digest.String())\n\t}\n\n\terr := store.Walk(ctx, func(info content.Info) error {\n\t\tdgst, ok := info.Labels[\"containerd.io/uncompressed\"]\n\t\tif ok {\n\t\t\tdesc := descs[digest.Digest(dgst)]\n\t\t\tif desc != nil {\n\t\t\t\tdesc.Digest = info.Digest\n\t\t\t\tdesc.Size = info.Size\n\t\t\t\tmediaType, err := detectLayerMediaType(ctx, store, *desc)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"failed to detect media type of layer: %w\", err)\n\t\t\t\t}\n\t\t\t\tdesc.MediaType = mediaType\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}, filters...)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failure checking for compressed blobs: %w\", err)\n\t}\n\n\tfor i, desc := range layers {\n\t\tif desc.MediaType != \"\" {\n\t\t\tcontinue\n\t\t}\n\t\t// Open blob, resolve media type\n\t\tra, err := store.ReaderAt(ctx, desc)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to open %q (%s): %w\", layerFiles[i], desc.Digest, err)\n\t\t}\n\t\ts, err := compression.DecompressStream(content.NewReader(ra))\n\t\tif err != nil {\n\t\t\tra.Close()\n\t\t\treturn nil, fmt.Errorf(\"failed to detect compression for %q: %w\", layerFiles[i], err)\n\t\t}\n\t\tif s.GetCompression() == compression.Uncompressed {\n\t\t\tif compress {\n\t\t\t\tif err := desc.Digest.Validate(); err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tref := fmt.Sprintf(\"compress-blob-%s-%s\", desc.Digest.Algorithm().String(), desc.Digest.Encoded())\n\t\t\t\tlabels := map[string]string{\n\t\t\t\t\t\"containerd.io/uncompressed\": desc.Digest.String(),\n\t\t\t\t}\n\t\t\t\tlayers[i], err = compressBlob(ctx, store, s, ref, content.WithLabels(labels))\n\t\t\t\tif err != nil {\n\t\t\t\t\ts.Close()\n\t\t\t\t\tra.Close()\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tlayers[i].MediaType = images.MediaTypeDockerSchema2LayerGzip\n\t\t\t} else {\n\t\t\t\tlayers[i].MediaType = images.MediaTypeDockerSchema2Layer\n\t\t\t}\n\t\t} else {\n\t\t\tlayers[i].MediaType = images.MediaTypeDockerSchema2LayerGzip\n\t\t}\n\t\ts.Close()\n\t\tra.Close()\n\t}\n\treturn layers, nil\n}\n\nfunc compressBlob(ctx context.Context, cs content.Store, r io.Reader, ref string, opts ...content.Opt) (desc ocispec.Descriptor, err error) {\n\tw, err := content.OpenWriter(ctx, cs, content.WithRef(ref))\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to open writer: %w\", err)\n\t}\n\n\tdefer func() {\n\t\tw.Close()\n\t\tif err != nil {\n\t\t\tcs.Abort(ctx, ref)\n\t\t}\n\t}()\n\tif err := w.Truncate(0); err != nil {\n\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to truncate writer: %w\", err)\n\t}\n\n\tcw, err := compression.CompressStream(w, compression.Gzip)\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\n\tif _, err := io.Copy(cw, r); err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\tif err := cw.Close(); err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\n\tcst, err := w.Status()\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to get writer status: %w\", err)\n\t}\n\n\tdesc.Digest = w.Digest()\n\tdesc.Size = cst.Offset\n\n\tif err := w.Commit(ctx, desc.Size, desc.Digest, opts...); err != nil {\n\t\tif !errdefs.IsAlreadyExists(err) {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to commit: %w\", err)\n\t\t}\n\t}\n\n\treturn desc, nil\n}\n\nfunc writeManifest(ctx context.Context, cs content.Ingester, manifest interface{}, mediaType string) (ocispec.Descriptor, error) {\n\tmanifestBytes, err := json.Marshal(manifest)\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\n\tdesc := ocispec.Descriptor{\n\t\tMediaType: mediaType,\n\t\tDigest:    digest.FromBytes(manifestBytes),\n\t\tSize:      int64(len(manifestBytes)),\n\t}\n\tif err := content.WriteBlob(ctx, cs, \"manifest-\"+desc.Digest.String(), bytes.NewReader(manifestBytes), desc); err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\n\treturn desc, nil\n}\n\nfunc detectLayerMediaType(ctx context.Context, store content.Store, desc ocispec.Descriptor) (string, error) {\n\tvar mediaType string\n\t// need to parse existing blob to use the proper media type\n\tbytes := make([]byte, 10)\n\tra, err := store.ReaderAt(ctx, desc)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to read content store to detect layer media type: %w\", err)\n\t}\n\tdefer ra.Close()\n\t_, err = ra.ReadAt(bytes, 0)\n\tif err != nil && err != io.EOF {\n\t\treturn \"\", fmt.Errorf(\"failed to read header bytes from layer to detect media type: %w\", err)\n\t}\n\tif err == io.EOF {\n\t\t// in the case of an empty layer then the media type should be uncompressed\n\t\treturn images.MediaTypeDockerSchema2Layer, nil\n\t}\n\tswitch c := compression.DetectCompression(bytes); c {\n\tcase compression.Uncompressed:\n\t\tmediaType = images.MediaTypeDockerSchema2Layer\n\tdefault:\n\t\tmediaType = images.MediaTypeDockerSchema2LayerGzip\n\t}\n\treturn mediaType, nil\n}\n"], "fixing_code": ["/*\n   Copyright The containerd Authors.\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n*/\n\n// Package archive provides a Docker and OCI compatible importer\npackage archive\n\nimport (\n\t\"archive/tar\"\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"path\"\n\n\t\"github.com/containerd/containerd/archive/compression\"\n\t\"github.com/containerd/containerd/content\"\n\t\"github.com/containerd/containerd/errdefs\"\n\t\"github.com/containerd/containerd/images\"\n\t\"github.com/containerd/containerd/log\"\n\t\"github.com/containerd/containerd/platforms\"\n\tdigest \"github.com/opencontainers/go-digest\"\n\tspecs \"github.com/opencontainers/image-spec/specs-go\"\n\tocispec \"github.com/opencontainers/image-spec/specs-go/v1\"\n)\n\ntype importOpts struct {\n\tcompress bool\n}\n\n// ImportOpt is an option for importing an OCI index\ntype ImportOpt func(*importOpts) error\n\n// WithImportCompression compresses uncompressed layers on import.\n// This is used for import formats which do not include the manifest.\nfunc WithImportCompression() ImportOpt {\n\treturn func(io *importOpts) error {\n\t\tio.compress = true\n\t\treturn nil\n\t}\n}\n\n// ImportIndex imports an index from a tar archive image bundle\n//   - implements Docker v1.1, v1.2 and OCI v1.\n//   - prefers OCI v1 when provided\n//   - creates OCI index for Docker formats\n//   - normalizes Docker references and adds as OCI ref name\n//     e.g. alpine:latest -> docker.io/library/alpine:latest\n//   - existing OCI reference names are untouched\nfunc ImportIndex(ctx context.Context, store content.Store, reader io.Reader, opts ...ImportOpt) (ocispec.Descriptor, error) {\n\tvar (\n\t\ttr = tar.NewReader(reader)\n\n\t\tociLayout ocispec.ImageLayout\n\t\tmfsts     []struct {\n\t\t\tConfig   string\n\t\t\tRepoTags []string\n\t\t\tLayers   []string\n\t\t}\n\t\tsymlinks = make(map[string]string)\n\t\tblobs    = make(map[string]ocispec.Descriptor)\n\t\tiopts    importOpts\n\t)\n\n\tfor _, o := range opts {\n\t\tif err := o(&iopts); err != nil {\n\t\t\treturn ocispec.Descriptor{}, err\n\t\t}\n\t}\n\n\tfor {\n\t\thdr, err := tr.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, err\n\t\t}\n\t\tif hdr.Typeflag == tar.TypeSymlink {\n\t\t\tsymlinks[hdr.Name] = path.Join(path.Dir(hdr.Name), hdr.Linkname)\n\t\t}\n\n\t\tif hdr.Typeflag != tar.TypeReg && hdr.Typeflag != tar.TypeRegA {\n\t\t\tif hdr.Typeflag != tar.TypeDir {\n\t\t\t\tlog.G(ctx).WithField(\"file\", hdr.Name).Debug(\"file type ignored\")\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\thdrName := path.Clean(hdr.Name)\n\t\tif hdrName == ocispec.ImageLayoutFile {\n\t\t\tif err = onUntarJSON(tr, &ociLayout); err != nil {\n\t\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"untar oci layout %q: %w\", hdr.Name, err)\n\t\t\t}\n\t\t} else if hdrName == \"manifest.json\" {\n\t\t\tif err = onUntarJSON(tr, &mfsts); err != nil {\n\t\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"untar manifest %q: %w\", hdr.Name, err)\n\t\t\t}\n\t\t} else {\n\t\t\tdgst, err := onUntarBlob(ctx, tr, store, hdr.Size, \"tar-\"+hdrName)\n\t\t\tif err != nil {\n\t\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to ingest %q: %w\", hdr.Name, err)\n\t\t\t}\n\n\t\t\tblobs[hdrName] = ocispec.Descriptor{\n\t\t\t\tDigest: dgst,\n\t\t\t\tSize:   hdr.Size,\n\t\t\t}\n\t\t}\n\t}\n\n\t// If OCI layout was given, interpret the tar as an OCI layout.\n\t// When not provided, the layout of the tar will be interpreted\n\t// as Docker v1.1 or v1.2.\n\tif ociLayout.Version != \"\" {\n\t\tif ociLayout.Version != ocispec.ImageLayoutVersion {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"unsupported OCI version %s\", ociLayout.Version)\n\t\t}\n\n\t\tidx, ok := blobs[\"index.json\"]\n\t\tif !ok {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"missing index.json in OCI layout %s\", ocispec.ImageLayoutVersion)\n\t\t}\n\n\t\tidx.MediaType = ocispec.MediaTypeImageIndex\n\t\treturn idx, nil\n\t}\n\n\tif mfsts == nil {\n\t\treturn ocispec.Descriptor{}, errors.New(\"unrecognized image format\")\n\t}\n\n\tfor name, linkname := range symlinks {\n\t\tdesc, ok := blobs[linkname]\n\t\tif !ok {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"no target for symlink layer from %q to %q\", name, linkname)\n\t\t}\n\t\tblobs[name] = desc\n\t}\n\n\tidx := ocispec.Index{\n\t\tVersioned: specs.Versioned{\n\t\t\tSchemaVersion: 2,\n\t\t},\n\t}\n\tfor _, mfst := range mfsts {\n\t\tconfig, ok := blobs[mfst.Config]\n\t\tif !ok {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"image config %q not found\", mfst.Config)\n\t\t}\n\t\tconfig.MediaType = images.MediaTypeDockerSchema2Config\n\n\t\tlayers, err := resolveLayers(ctx, store, mfst.Layers, blobs, iopts.compress)\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to resolve layers: %w\", err)\n\t\t}\n\n\t\tmanifest := struct {\n\t\t\tSchemaVersion int                  `json:\"schemaVersion\"`\n\t\t\tMediaType     string               `json:\"mediaType\"`\n\t\t\tConfig        ocispec.Descriptor   `json:\"config\"`\n\t\t\tLayers        []ocispec.Descriptor `json:\"layers\"`\n\t\t}{\n\t\t\tSchemaVersion: 2,\n\t\t\tMediaType:     images.MediaTypeDockerSchema2Manifest,\n\t\t\tConfig:        config,\n\t\t\tLayers:        layers,\n\t\t}\n\n\t\tdesc, err := writeManifest(ctx, store, manifest, manifest.MediaType)\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"write docker manifest: %w\", err)\n\t\t}\n\n\t\timgPlatforms, err := images.Platforms(ctx, store, desc)\n\t\tif err != nil {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"unable to resolve platform: %w\", err)\n\t\t}\n\t\tif len(imgPlatforms) > 0 {\n\t\t\t// Only one platform can be resolved from non-index manifest,\n\t\t\t// The platform can only come from the config included above,\n\t\t\t// if the config has no platform it can be safely omitted.\n\t\t\tdesc.Platform = &imgPlatforms[0]\n\n\t\t\t// If the image we've just imported is a Windows image without the OSVersion set,\n\t\t\t// we could just assume it matches this host's OS Version. Without this, the\n\t\t\t// children labels might not be set on the image content, leading to it being\n\t\t\t// garbage collected, breaking the image.\n\t\t\t// See: https://github.com/containerd/containerd/issues/5690\n\t\t\tif desc.Platform.OS == \"windows\" && desc.Platform.OSVersion == \"\" {\n\t\t\t\tplatform := platforms.DefaultSpec()\n\t\t\t\tdesc.Platform.OSVersion = platform.OSVersion\n\t\t\t}\n\t\t}\n\n\t\tif len(mfst.RepoTags) == 0 {\n\t\t\tidx.Manifests = append(idx.Manifests, desc)\n\t\t} else {\n\t\t\t// Add descriptor per tag\n\t\t\tfor _, ref := range mfst.RepoTags {\n\t\t\t\tmfstdesc := desc\n\n\t\t\t\tnormalized, err := normalizeReference(ref)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn ocispec.Descriptor{}, err\n\t\t\t\t}\n\n\t\t\t\tmfstdesc.Annotations = map[string]string{\n\t\t\t\t\timages.AnnotationImageName: normalized,\n\t\t\t\t\tocispec.AnnotationRefName:  ociReferenceName(normalized),\n\t\t\t\t}\n\n\t\t\t\tidx.Manifests = append(idx.Manifests, mfstdesc)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn writeManifest(ctx, store, idx, ocispec.MediaTypeImageIndex)\n}\n\nconst (\n\tkib       = 1024\n\tmib       = 1024 * kib\n\tjsonLimit = 20 * mib\n)\n\nfunc onUntarJSON(r io.Reader, j interface{}) error {\n\treturn json.NewDecoder(io.LimitReader(r, jsonLimit)).Decode(j)\n}\n\nfunc onUntarBlob(ctx context.Context, r io.Reader, store content.Ingester, size int64, ref string) (digest.Digest, error) {\n\tdgstr := digest.Canonical.Digester()\n\n\tif err := content.WriteBlob(ctx, store, ref, io.TeeReader(r, dgstr.Hash()), ocispec.Descriptor{Size: size}); err != nil {\n\t\treturn \"\", err\n\t}\n\n\treturn dgstr.Digest(), nil\n}\n\nfunc resolveLayers(ctx context.Context, store content.Store, layerFiles []string, blobs map[string]ocispec.Descriptor, compress bool) ([]ocispec.Descriptor, error) {\n\tlayers := make([]ocispec.Descriptor, len(layerFiles))\n\tdescs := map[digest.Digest]*ocispec.Descriptor{}\n\tfilters := []string{}\n\tfor i, f := range layerFiles {\n\t\tdesc, ok := blobs[f]\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"layer %q not found\", f)\n\t\t}\n\t\tlayers[i] = desc\n\t\tdescs[desc.Digest] = &layers[i]\n\t\tfilters = append(filters, \"labels.\\\"containerd.io/uncompressed\\\"==\"+desc.Digest.String())\n\t}\n\n\terr := store.Walk(ctx, func(info content.Info) error {\n\t\tdgst, ok := info.Labels[\"containerd.io/uncompressed\"]\n\t\tif ok {\n\t\t\tdesc := descs[digest.Digest(dgst)]\n\t\t\tif desc != nil {\n\t\t\t\tdesc.Digest = info.Digest\n\t\t\t\tdesc.Size = info.Size\n\t\t\t\tmediaType, err := detectLayerMediaType(ctx, store, *desc)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"failed to detect media type of layer: %w\", err)\n\t\t\t\t}\n\t\t\t\tdesc.MediaType = mediaType\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}, filters...)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failure checking for compressed blobs: %w\", err)\n\t}\n\n\tfor i, desc := range layers {\n\t\tif desc.MediaType != \"\" {\n\t\t\tcontinue\n\t\t}\n\t\t// Open blob, resolve media type\n\t\tra, err := store.ReaderAt(ctx, desc)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to open %q (%s): %w\", layerFiles[i], desc.Digest, err)\n\t\t}\n\t\ts, err := compression.DecompressStream(content.NewReader(ra))\n\t\tif err != nil {\n\t\t\tra.Close()\n\t\t\treturn nil, fmt.Errorf(\"failed to detect compression for %q: %w\", layerFiles[i], err)\n\t\t}\n\t\tif s.GetCompression() == compression.Uncompressed {\n\t\t\tif compress {\n\t\t\t\tif err := desc.Digest.Validate(); err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tref := fmt.Sprintf(\"compress-blob-%s-%s\", desc.Digest.Algorithm().String(), desc.Digest.Encoded())\n\t\t\t\tlabels := map[string]string{\n\t\t\t\t\t\"containerd.io/uncompressed\": desc.Digest.String(),\n\t\t\t\t}\n\t\t\t\tlayers[i], err = compressBlob(ctx, store, s, ref, content.WithLabels(labels))\n\t\t\t\tif err != nil {\n\t\t\t\t\ts.Close()\n\t\t\t\t\tra.Close()\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tlayers[i].MediaType = images.MediaTypeDockerSchema2LayerGzip\n\t\t\t} else {\n\t\t\t\tlayers[i].MediaType = images.MediaTypeDockerSchema2Layer\n\t\t\t}\n\t\t} else {\n\t\t\tlayers[i].MediaType = images.MediaTypeDockerSchema2LayerGzip\n\t\t}\n\t\ts.Close()\n\t\tra.Close()\n\t}\n\treturn layers, nil\n}\n\nfunc compressBlob(ctx context.Context, cs content.Store, r io.Reader, ref string, opts ...content.Opt) (desc ocispec.Descriptor, err error) {\n\tw, err := content.OpenWriter(ctx, cs, content.WithRef(ref))\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to open writer: %w\", err)\n\t}\n\n\tdefer func() {\n\t\tw.Close()\n\t\tif err != nil {\n\t\t\tcs.Abort(ctx, ref)\n\t\t}\n\t}()\n\tif err := w.Truncate(0); err != nil {\n\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to truncate writer: %w\", err)\n\t}\n\n\tcw, err := compression.CompressStream(w, compression.Gzip)\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\n\tif _, err := io.Copy(cw, r); err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\tif err := cw.Close(); err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\n\tcst, err := w.Status()\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to get writer status: %w\", err)\n\t}\n\n\tdesc.Digest = w.Digest()\n\tdesc.Size = cst.Offset\n\n\tif err := w.Commit(ctx, desc.Size, desc.Digest, opts...); err != nil {\n\t\tif !errdefs.IsAlreadyExists(err) {\n\t\t\treturn ocispec.Descriptor{}, fmt.Errorf(\"failed to commit: %w\", err)\n\t\t}\n\t}\n\n\treturn desc, nil\n}\n\nfunc writeManifest(ctx context.Context, cs content.Ingester, manifest interface{}, mediaType string) (ocispec.Descriptor, error) {\n\tmanifestBytes, err := json.Marshal(manifest)\n\tif err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\n\tdesc := ocispec.Descriptor{\n\t\tMediaType: mediaType,\n\t\tDigest:    digest.FromBytes(manifestBytes),\n\t\tSize:      int64(len(manifestBytes)),\n\t}\n\tif err := content.WriteBlob(ctx, cs, \"manifest-\"+desc.Digest.String(), bytes.NewReader(manifestBytes), desc); err != nil {\n\t\treturn ocispec.Descriptor{}, err\n\t}\n\n\treturn desc, nil\n}\n\nfunc detectLayerMediaType(ctx context.Context, store content.Store, desc ocispec.Descriptor) (string, error) {\n\tvar mediaType string\n\t// need to parse existing blob to use the proper media type\n\tbytes := make([]byte, 10)\n\tra, err := store.ReaderAt(ctx, desc)\n\tif err != nil {\n\t\treturn \"\", fmt.Errorf(\"failed to read content store to detect layer media type: %w\", err)\n\t}\n\tdefer ra.Close()\n\t_, err = ra.ReadAt(bytes, 0)\n\tif err != nil && err != io.EOF {\n\t\treturn \"\", fmt.Errorf(\"failed to read header bytes from layer to detect media type: %w\", err)\n\t}\n\tif err == io.EOF {\n\t\t// in the case of an empty layer then the media type should be uncompressed\n\t\treturn images.MediaTypeDockerSchema2Layer, nil\n\t}\n\tswitch c := compression.DetectCompression(bytes); c {\n\tcase compression.Uncompressed:\n\t\tmediaType = images.MediaTypeDockerSchema2Layer\n\tdefault:\n\t\tmediaType = images.MediaTypeDockerSchema2LayerGzip\n\t}\n\treturn mediaType, nil\n}\n"], "filenames": ["images/archive/importer.go"], "buggy_code_start_loc": [234], "buggy_code_end_loc": [241], "fixing_code_start_loc": [235], "fixing_code_end_loc": [243], "type": "CWE-770", "message": "containerd is an open source container runtime. Before versions 1.6.18 and 1.5.18, when importing an OCI image, there was no limit on the number of bytes read for certain files. A maliciously crafted image with a large file where a limit was not applied could cause a denial of service. This bug has been fixed in containerd 1.6.18 and 1.5.18. Users should update to these versions to resolve the issue. As a workaround, ensure that only trusted images are used and that only trusted users have permissions to import images.", "other": {"cve": {"id": "CVE-2023-25153", "sourceIdentifier": "security-advisories@github.com", "published": "2023-02-16T15:15:19.477", "lastModified": "2023-02-24T16:41:17.167", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "containerd is an open source container runtime. Before versions 1.6.18 and 1.5.18, when importing an OCI image, there was no limit on the number of bytes read for certain files. A maliciously crafted image with a large file where a limit was not applied could cause a denial of service. This bug has been fixed in containerd 1.6.18 and 1.5.18. Users should update to these versions to resolve the issue. As a workaround, ensure that only trusted images are used and that only trusted users have permissions to import images."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:R/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "REQUIRED", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 6.2, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.5, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-770"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-770"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:containerd:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.5.18", "matchCriteriaId": "4C98A2DA-3CDD-4438-AECC-DDDA67E61935"}, {"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:containerd:*:*:*:*:*:*:*:*", "versionStartIncluding": "1.6.0", "versionEndExcluding": "1.6.18", "matchCriteriaId": "BDD5FC3E-BEEB-4CAA-845E-3BADF39E46B2"}]}]}], "references": [{"url": "https://github.com/containerd/containerd/commit/0c314901076a74a7b797a545d2f462285fdbb8c4", "source": "security-advisories@github.com", "tags": ["Patch"]}, {"url": "https://github.com/containerd/containerd/releases/tag/v1.5.18", "source": "security-advisories@github.com", "tags": ["Release Notes"]}, {"url": "https://github.com/containerd/containerd/releases/tag/v1.6.18", "source": "security-advisories@github.com", "tags": ["Release Notes"]}, {"url": "https://github.com/containerd/containerd/security/advisories/GHSA-259w-8hf6-59c2", "source": "security-advisories@github.com", "tags": ["Vendor Advisory"]}]}, "github_commit_url": "https://github.com/containerd/containerd/commit/0c314901076a74a7b797a545d2f462285fdbb8c4"}}
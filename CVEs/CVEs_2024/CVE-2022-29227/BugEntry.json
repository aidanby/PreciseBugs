{"buggy_code": ["#include \"source/common/http/conn_manager_impl.h\"\n\n#include <cstdint>\n#include <functional>\n#include <list>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"envoy/buffer/buffer.h\"\n#include \"envoy/common/time.h\"\n#include \"envoy/event/dispatcher.h\"\n#include \"envoy/event/scaled_range_timer_manager.h\"\n#include \"envoy/extensions/filters/network/http_connection_manager/v3/http_connection_manager.pb.h\"\n#include \"envoy/http/header_map.h\"\n#include \"envoy/network/drain_decision.h\"\n#include \"envoy/router/router.h\"\n#include \"envoy/ssl/connection.h\"\n#include \"envoy/stats/scope.h\"\n#include \"envoy/stream_info/filter_state.h\"\n#include \"envoy/stream_info/stream_info.h\"\n#include \"envoy/tracing/http_tracer.h\"\n#include \"envoy/type/v3/percent.pb.h\"\n\n#include \"source/common/buffer/buffer_impl.h\"\n#include \"source/common/common/assert.h\"\n#include \"source/common/common/empty_string.h\"\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/fmt.h\"\n#include \"source/common/common/perf_tracing.h\"\n#include \"source/common/common/scope_tracker.h\"\n#include \"source/common/common/utility.h\"\n#include \"source/common/http/codes.h\"\n#include \"source/common/http/conn_manager_utility.h\"\n#include \"source/common/http/exception.h\"\n#include \"source/common/http/header_map_impl.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/http/headers.h\"\n#include \"source/common/http/http1/codec_impl.h\"\n#include \"source/common/http/http2/codec_impl.h\"\n#include \"source/common/http/path_utility.h\"\n#include \"source/common/http/status.h\"\n#include \"source/common/http/utility.h\"\n#include \"source/common/network/utility.h\"\n#include \"source/common/router/config_impl.h\"\n#include \"source/common/runtime/runtime_features.h\"\n#include \"source/common/stats/timespan_impl.h\"\n#include \"source/common/stream_info/utility.h\"\n\n#include \"absl/strings/escaping.h\"\n#include \"absl/strings/match.h\"\n#include \"absl/strings/str_cat.h\"\n\nnamespace Envoy {\nnamespace Http {\n\nbool requestWasConnect(const RequestHeaderMapPtr& headers, Protocol protocol) {\n  if (!headers) {\n    return false;\n  }\n  if (protocol <= Protocol::Http11) {\n    return HeaderUtility::isConnect(*headers);\n  }\n  // All HTTP/2 style upgrades were originally connect requests.\n  return HeaderUtility::isConnect(*headers) || Utility::isUpgrade(*headers);\n}\n\nConnectionManagerStats ConnectionManagerImpl::generateStats(const std::string& prefix,\n                                                            Stats::Scope& scope) {\n  return ConnectionManagerStats(\n      {ALL_HTTP_CONN_MAN_STATS(POOL_COUNTER_PREFIX(scope, prefix), POOL_GAUGE_PREFIX(scope, prefix),\n                               POOL_HISTOGRAM_PREFIX(scope, prefix))},\n      prefix, scope);\n}\n\nConnectionManagerTracingStats ConnectionManagerImpl::generateTracingStats(const std::string& prefix,\n                                                                          Stats::Scope& scope) {\n  return {CONN_MAN_TRACING_STATS(POOL_COUNTER_PREFIX(scope, prefix + \"tracing.\"))};\n}\n\nConnectionManagerListenerStats\nConnectionManagerImpl::generateListenerStats(const std::string& prefix, Stats::Scope& scope) {\n  return {CONN_MAN_LISTENER_STATS(POOL_COUNTER_PREFIX(scope, prefix))};\n}\n\nConnectionManagerImpl::ConnectionManagerImpl(ConnectionManagerConfig& config,\n                                             const Network::DrainDecision& drain_close,\n                                             Random::RandomGenerator& random_generator,\n                                             Http::Context& http_context, Runtime::Loader& runtime,\n                                             const LocalInfo::LocalInfo& local_info,\n                                             Upstream::ClusterManager& cluster_manager,\n                                             Server::OverloadManager& overload_manager,\n                                             TimeSource& time_source)\n    : config_(config), stats_(config_.stats()),\n      conn_length_(new Stats::HistogramCompletableTimespanImpl(\n          stats_.named_.downstream_cx_length_ms_, time_source)),\n      drain_close_(drain_close), user_agent_(http_context.userAgentContext()),\n      random_generator_(random_generator), http_context_(http_context), runtime_(runtime),\n      local_info_(local_info), cluster_manager_(cluster_manager),\n      listener_stats_(config_.listenerStats()),\n      overload_state_(overload_manager.getThreadLocalOverloadState()),\n      overload_stop_accepting_requests_ref_(\n          overload_state_.getState(Server::OverloadActionNames::get().StopAcceptingRequests)),\n      overload_disable_keepalive_ref_(\n          overload_state_.getState(Server::OverloadActionNames::get().DisableHttpKeepAlive)),\n      time_source_(time_source), proxy_name_(StreamInfo::ProxyStatusUtils::makeProxyName(\n                                     /*node_id=*/local_info_.node().id(),\n                                     /*server_name=*/config_.serverName(),\n                                     /*proxy_status_config=*/config_.proxyStatusConfig())) {}\n\nconst ResponseHeaderMap& ConnectionManagerImpl::continueHeader() {\n  static const auto headers = createHeaderMap<ResponseHeaderMapImpl>(\n      {{Http::Headers::get().Status, std::to_string(enumToInt(Code::Continue))}});\n  return *headers;\n}\n\nvoid ConnectionManagerImpl::initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) {\n  read_callbacks_ = &callbacks;\n  stats_.named_.downstream_cx_total_.inc();\n  stats_.named_.downstream_cx_active_.inc();\n  if (read_callbacks_->connection().ssl()) {\n    stats_.named_.downstream_cx_ssl_total_.inc();\n    stats_.named_.downstream_cx_ssl_active_.inc();\n  }\n\n  read_callbacks_->connection().addConnectionCallbacks(*this);\n\n  if (!read_callbacks_->connection()\n           .streamInfo()\n           .filterState()\n           ->hasData<Network::ProxyProtocolFilterState>(Network::ProxyProtocolFilterState::key())) {\n    read_callbacks_->connection().streamInfo().filterState()->setData(\n        Network::ProxyProtocolFilterState::key(),\n        std::make_unique<Network::ProxyProtocolFilterState>(Network::ProxyProtocolData{\n            read_callbacks_->connection().connectionInfoProvider().remoteAddress(),\n            read_callbacks_->connection().connectionInfoProvider().localAddress()}),\n        StreamInfo::FilterState::StateType::ReadOnly,\n        StreamInfo::FilterState::LifeSpan::Connection);\n  }\n\n  if (config_.idleTimeout()) {\n    connection_idle_timer_ = read_callbacks_->connection().dispatcher().createScaledTimer(\n        Event::ScaledTimerType::HttpDownstreamIdleConnectionTimeout,\n        [this]() -> void { onIdleTimeout(); });\n    connection_idle_timer_->enableTimer(config_.idleTimeout().value());\n  }\n\n  if (config_.maxConnectionDuration()) {\n    connection_duration_timer_ = read_callbacks_->connection().dispatcher().createTimer(\n        [this]() -> void { onConnectionDurationTimeout(); });\n    connection_duration_timer_->enableTimer(config_.maxConnectionDuration().value());\n  }\n\n  read_callbacks_->connection().setDelayedCloseTimeout(config_.delayedCloseTimeout());\n\n  read_callbacks_->connection().setConnectionStats(\n      {stats_.named_.downstream_cx_rx_bytes_total_, stats_.named_.downstream_cx_rx_bytes_buffered_,\n       stats_.named_.downstream_cx_tx_bytes_total_, stats_.named_.downstream_cx_tx_bytes_buffered_,\n       nullptr, &stats_.named_.downstream_cx_delayed_close_timeout_});\n}\n\nConnectionManagerImpl::~ConnectionManagerImpl() {\n  stats_.named_.downstream_cx_destroy_.inc();\n\n  stats_.named_.downstream_cx_active_.dec();\n  if (read_callbacks_->connection().ssl()) {\n    stats_.named_.downstream_cx_ssl_active_.dec();\n  }\n\n  if (codec_) {\n    if (codec_->protocol() == Protocol::Http2) {\n      stats_.named_.downstream_cx_http2_active_.dec();\n    } else if (codec_->protocol() == Protocol::Http3) {\n      stats_.named_.downstream_cx_http3_active_.dec();\n    } else {\n      stats_.named_.downstream_cx_http1_active_.dec();\n    }\n  }\n\n  conn_length_->complete();\n  user_agent_.completeConnectionLength(*conn_length_);\n}\n\nvoid ConnectionManagerImpl::checkForDeferredClose(bool skip_delay_close) {\n  Network::ConnectionCloseType close = Network::ConnectionCloseType::FlushWriteAndDelay;\n  if (Runtime::runtimeFeatureEnabled(\"envoy.reloadable_features.skip_delay_close\") &&\n      skip_delay_close) {\n    close = Network::ConnectionCloseType::FlushWrite;\n  }\n  if (drain_state_ == DrainState::Closing && streams_.empty() && !codec_->wantsToWrite()) {\n    doConnectionClose(close, absl::nullopt,\n                      StreamInfo::ResponseCodeDetails::get().DownstreamLocalDisconnect);\n  }\n}\n\nvoid ConnectionManagerImpl::doEndStream(ActiveStream& stream) {\n  // The order of what happens in this routine is important and a little complicated. We first see\n  // if the stream needs to be reset. If it needs to be, this will end up invoking reset callbacks\n  // and then moving the stream to the deferred destruction list. If the stream has not been reset,\n  // we move it to the deferred deletion list here. Then, we potentially close the connection. This\n  // must be done after deleting the stream since the stream refers to the connection and must be\n  // deleted first.\n  bool reset_stream = false;\n  // If the response encoder is still associated with the stream, reset the stream. The exception\n  // here is when Envoy \"ends\" the stream by calling recreateStream at which point recreateStream\n  // explicitly nulls out response_encoder to avoid the downstream being notified of the\n  // Envoy-internal stream instance being ended.\n  if (stream.response_encoder_ != nullptr && (!stream.filter_manager_.remoteDecodeComplete() ||\n                                              !stream.state_.codec_saw_local_complete_)) {\n    // Indicate local is complete at this point so that if we reset during a continuation, we don't\n    // raise further data or trailers.\n    ENVOY_STREAM_LOG(debug, \"doEndStream() resetting stream\", stream);\n    // TODO(snowp): This call might not be necessary, try to clean up + remove setter function.\n    stream.filter_manager_.setLocalComplete();\n    stream.state_.codec_saw_local_complete_ = true;\n\n    // Per https://tools.ietf.org/html/rfc7540#section-8.3 if there was an error\n    // with the TCP connection during a CONNECT request, it should be\n    // communicated via CONNECT_ERROR\n    if (requestWasConnect(stream.request_headers_, codec_->protocol()) &&\n        (stream.filter_manager_.streamInfo().hasResponseFlag(\n             StreamInfo::ResponseFlag::UpstreamConnectionFailure) ||\n         stream.filter_manager_.streamInfo().hasResponseFlag(\n             StreamInfo::ResponseFlag::UpstreamConnectionTermination))) {\n      stream.response_encoder_->getStream().resetStream(StreamResetReason::ConnectError);\n    } else {\n      if (stream.filter_manager_.streamInfo().hasResponseFlag(\n              StreamInfo::ResponseFlag::UpstreamProtocolError)) {\n        stream.response_encoder_->getStream().resetStream(StreamResetReason::ProtocolError);\n      } else {\n        stream.response_encoder_->getStream().resetStream(StreamResetReason::LocalReset);\n      }\n    }\n    reset_stream = true;\n  }\n\n  if (!reset_stream) {\n    doDeferredStreamDestroy(stream);\n  }\n\n  if (reset_stream && codec_->protocol() < Protocol::Http2) {\n    drain_state_ = DrainState::Closing;\n  }\n\n  // If HTTP/1.0 has no content length, it is framed by close and won't consider\n  // the request complete until the FIN is read. Don't delay close in this case.\n  bool http_10_sans_cl = (codec_->protocol() == Protocol::Http10) &&\n                         (!stream.response_headers_ || !stream.response_headers_->ContentLength());\n  // We also don't delay-close in the case of HTTP/1.1 where the request is\n  // fully read, as there's no race condition to avoid.\n  bool connection_close = stream.state_.saw_connection_close_;\n  bool request_complete = stream.filter_manager_.remoteDecodeComplete();\n\n  checkForDeferredClose(connection_close && (request_complete || http_10_sans_cl));\n}\n\nvoid ConnectionManagerImpl::doDeferredStreamDestroy(ActiveStream& stream) {\n  if (stream.max_stream_duration_timer_) {\n    stream.max_stream_duration_timer_->disableTimer();\n    stream.max_stream_duration_timer_ = nullptr;\n  }\n  if (stream.stream_idle_timer_ != nullptr) {\n    stream.stream_idle_timer_->disableTimer();\n    stream.stream_idle_timer_ = nullptr;\n  }\n  stream.filter_manager_.disarmRequestTimeout();\n  if (stream.request_header_timer_ != nullptr) {\n    stream.request_header_timer_->disableTimer();\n    stream.request_header_timer_ = nullptr;\n  }\n\n  stream.completeRequest();\n  stream.filter_manager_.onStreamComplete();\n  stream.filter_manager_.log();\n\n  stream.filter_manager_.destroyFilters();\n\n  read_callbacks_->connection().dispatcher().deferredDelete(stream.removeFromList(streams_));\n\n  // The response_encoder should never be dangling (unless we're destroying a\n  // stream we are recreating) as the codec level stream will either outlive the\n  // ActiveStream, or be alive in deferred deletion queue at this point.\n  if (stream.response_encoder_) {\n    stream.response_encoder_->getStream().removeCallbacks(stream);\n  }\n\n  if (connection_idle_timer_ && streams_.empty()) {\n    connection_idle_timer_->enableTimer(config_.idleTimeout().value());\n  }\n}\n\nRequestDecoder& ConnectionManagerImpl::newStream(ResponseEncoder& response_encoder,\n                                                 bool is_internally_created) {\n  TRACE_EVENT(\"core\", \"ConnectionManagerImpl::newStream\");\n  if (connection_idle_timer_) {\n    connection_idle_timer_->disableTimer();\n  }\n\n  ENVOY_CONN_LOG(debug, \"new stream\", read_callbacks_->connection());\n\n  // Create account, wiring the stream to use it for tracking bytes.\n  // If tracking is disabled, the wiring becomes a NOP.\n  auto& buffer_factory = read_callbacks_->connection().dispatcher().getWatermarkFactory();\n  Buffer::BufferMemoryAccountSharedPtr downstream_stream_account =\n      buffer_factory.createAccount(response_encoder.getStream());\n  response_encoder.getStream().setAccount(downstream_stream_account);\n  ActiveStreamPtr new_stream(new ActiveStream(*this, response_encoder.getStream().bufferLimit(),\n                                              std::move(downstream_stream_account)));\n\n  accumulated_requests_++;\n  if (config_.maxRequestsPerConnection() > 0 &&\n      accumulated_requests_ >= config_.maxRequestsPerConnection()) {\n    if (codec_->protocol() < Protocol::Http2) {\n      new_stream->state_.saw_connection_close_ = true;\n      // Prevent erroneous debug log of closing due to incoming connection close header.\n      drain_state_ = DrainState::Closing;\n    } else if (drain_state_ == DrainState::NotDraining) {\n      startDrainSequence();\n    }\n    ENVOY_CONN_LOG(debug, \"max requests per connection reached\", read_callbacks_->connection());\n    stats_.named_.downstream_cx_max_requests_reached_.inc();\n  }\n\n  new_stream->state_.is_internally_created_ = is_internally_created;\n  new_stream->response_encoder_ = &response_encoder;\n  new_stream->response_encoder_->getStream().addCallbacks(*new_stream);\n  new_stream->response_encoder_->getStream().setFlushTimeout(new_stream->idle_timeout_ms_);\n  new_stream->streamInfo().setDownstreamBytesMeter(response_encoder.getStream().bytesMeter());\n  // If the network connection is backed up, the stream should be made aware of it on creation.\n  // Both HTTP/1.x and HTTP/2 codecs handle this in StreamCallbackHelper::addCallbacksHelper.\n  ASSERT(read_callbacks_->connection().aboveHighWatermark() == false ||\n         new_stream->filter_manager_.aboveHighWatermark());\n  LinkedList::moveIntoList(std::move(new_stream), streams_);\n  return **streams_.begin();\n}\n\nvoid ConnectionManagerImpl::handleCodecError(absl::string_view error) {\n  ENVOY_CONN_LOG(debug, \"dispatch error: {}\", read_callbacks_->connection(), error);\n  read_callbacks_->connection().streamInfo().setResponseFlag(\n      StreamInfo::ResponseFlag::DownstreamProtocolError);\n\n  // HTTP/1.1 codec has already sent a 400 response if possible. HTTP/2 codec has already sent\n  // GOAWAY.\n  doConnectionClose(Network::ConnectionCloseType::FlushWriteAndDelay,\n                    StreamInfo::ResponseFlag::DownstreamProtocolError,\n                    absl::StrCat(\"codec_error:\", StringUtil::replaceAllEmptySpace(error)));\n}\n\nvoid ConnectionManagerImpl::createCodec(Buffer::Instance& data) {\n  ASSERT(!codec_);\n  codec_ = config_.createCodec(read_callbacks_->connection(), data, *this);\n\n  switch (codec_->protocol()) {\n  case Protocol::Http3:\n    stats_.named_.downstream_cx_http3_total_.inc();\n    stats_.named_.downstream_cx_http3_active_.inc();\n    break;\n  case Protocol::Http2:\n    stats_.named_.downstream_cx_http2_total_.inc();\n    stats_.named_.downstream_cx_http2_active_.inc();\n    break;\n  case Protocol::Http11:\n  case Protocol::Http10:\n    stats_.named_.downstream_cx_http1_total_.inc();\n    stats_.named_.downstream_cx_http1_active_.inc();\n    break;\n  }\n}\n\nNetwork::FilterStatus ConnectionManagerImpl::onData(Buffer::Instance& data, bool) {\n  if (!codec_) {\n    // Http3 codec should have been instantiated by now.\n    createCodec(data);\n  }\n\n  bool redispatch;\n  do {\n    redispatch = false;\n\n    const Status status = codec_->dispatch(data);\n\n    if (isBufferFloodError(status) || isInboundFramesWithEmptyPayloadError(status)) {\n      handleCodecError(status.message());\n      return Network::FilterStatus::StopIteration;\n    } else if (isCodecProtocolError(status)) {\n      stats_.named_.downstream_cx_protocol_error_.inc();\n      handleCodecError(status.message());\n      return Network::FilterStatus::StopIteration;\n    }\n    ASSERT(status.ok());\n\n    // Processing incoming data may release outbound data so check for closure here as well.\n    checkForDeferredClose(false);\n\n    // The HTTP/1 codec will pause dispatch after a single message is complete. We want to\n    // either redispatch if there are no streams and we have more data. If we have a single\n    // complete non-WebSocket stream but have not responded yet we will pause socket reads\n    // to apply back pressure.\n    if (codec_->protocol() < Protocol::Http2) {\n      if (read_callbacks_->connection().state() == Network::Connection::State::Open &&\n          data.length() > 0 && streams_.empty()) {\n        redispatch = true;\n      }\n    }\n  } while (redispatch);\n\n  if (!read_callbacks_->connection().streamInfo().protocol()) {\n    read_callbacks_->connection().streamInfo().protocol(codec_->protocol());\n  }\n\n  return Network::FilterStatus::StopIteration;\n}\n\nNetwork::FilterStatus ConnectionManagerImpl::onNewConnection() {\n  if (!read_callbacks_->connection().streamInfo().protocol()) {\n    // For Non-QUIC traffic, continue passing data to filters.\n    return Network::FilterStatus::Continue;\n  }\n  // Only QUIC connection's stream_info_ specifies protocol.\n  Buffer::OwnedImpl dummy;\n  createCodec(dummy);\n  ASSERT(codec_->protocol() == Protocol::Http3);\n  // Stop iterating through each filters for QUIC. Currently a QUIC connection\n  // only supports one filter, HCM, and bypasses the onData() interface. Because\n  // QUICHE already handles de-multiplexing.\n  return Network::FilterStatus::StopIteration;\n}\n\nvoid ConnectionManagerImpl::resetAllStreams(absl::optional<StreamInfo::ResponseFlag> response_flag,\n                                            absl::string_view details) {\n  while (!streams_.empty()) {\n    // Mimic a downstream reset in this case. We must also remove callbacks here. Though we are\n    // about to close the connection and will disable further reads, it is possible that flushing\n    // data out can cause stream callbacks to fire (e.g., low watermark callbacks).\n    //\n    // TODO(mattklein123): I tried to actually reset through the codec here, but ran into issues\n    // with nghttp2 state and being unhappy about sending reset frames after the connection had\n    // been terminated via GOAWAY. It might be possible to do something better here inside the h2\n    // codec but there are no easy answers and this seems simpler.\n    auto& stream = *streams_.front();\n    stream.response_encoder_->getStream().removeCallbacks(stream);\n    if (!stream.response_encoder_->getStream().responseDetails().empty()) {\n      stream.filter_manager_.streamInfo().setResponseCodeDetails(\n          stream.response_encoder_->getStream().responseDetails());\n    } else if (!details.empty()) {\n      stream.filter_manager_.streamInfo().setResponseCodeDetails(details);\n    }\n    if (response_flag.has_value()) {\n      stream.filter_manager_.streamInfo().setResponseFlag(response_flag.value());\n    }\n    stream.onResetStream(StreamResetReason::ConnectionTermination, absl::string_view());\n  }\n}\n\nvoid ConnectionManagerImpl::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::LocalClose) {\n    stats_.named_.downstream_cx_destroy_local_.inc();\n  }\n\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    if (event == Network::ConnectionEvent::RemoteClose) {\n      remote_close_ = true;\n      stats_.named_.downstream_cx_destroy_remote_.inc();\n    }\n    absl::string_view details =\n        event == Network::ConnectionEvent::RemoteClose\n            ? StreamInfo::ResponseCodeDetails::get().DownstreamRemoteDisconnect\n            : StreamInfo::ResponseCodeDetails::get().DownstreamLocalDisconnect;\n    // TODO(mattklein123): It is technically possible that something outside of the filter causes\n    // a local connection close, so we still guard against that here. A better solution would be to\n    // have some type of \"pre-close\" callback that we could hook for cleanup that would get called\n    // regardless of where local close is invoked from.\n    // NOTE: that this will cause doConnectionClose() to get called twice in the common local close\n    // cases, but the method protects against that.\n    // NOTE: In the case where a local close comes from outside the filter, this will cause any\n    // stream closures to increment remote close stats. We should do better here in the future,\n    // via the pre-close callback mentioned above.\n    doConnectionClose(absl::nullopt, absl::nullopt, details);\n  }\n}\n\nvoid ConnectionManagerImpl::doConnectionClose(\n    absl::optional<Network::ConnectionCloseType> close_type,\n    absl::optional<StreamInfo::ResponseFlag> response_flag, absl::string_view details) {\n  if (connection_idle_timer_) {\n    connection_idle_timer_->disableTimer();\n    connection_idle_timer_.reset();\n  }\n\n  if (connection_duration_timer_) {\n    connection_duration_timer_->disableTimer();\n    connection_duration_timer_.reset();\n  }\n\n  if (drain_timer_) {\n    drain_timer_->disableTimer();\n    drain_timer_.reset();\n  }\n\n  if (!streams_.empty()) {\n    const Network::ConnectionEvent event = close_type.has_value()\n                                               ? Network::ConnectionEvent::LocalClose\n                                               : Network::ConnectionEvent::RemoteClose;\n    if (event == Network::ConnectionEvent::LocalClose) {\n      stats_.named_.downstream_cx_destroy_local_active_rq_.inc();\n    }\n    if (event == Network::ConnectionEvent::RemoteClose) {\n      stats_.named_.downstream_cx_destroy_remote_active_rq_.inc();\n    }\n\n    stats_.named_.downstream_cx_destroy_active_rq_.inc();\n    user_agent_.onConnectionDestroy(event, true);\n    // Note that resetAllStreams() does not actually write anything to the wire. It just resets\n    // all upstream streams and their filter stacks. Thus, there are no issues around recursive\n    // entry.\n    resetAllStreams(response_flag, details);\n  }\n\n  if (close_type.has_value()) {\n    read_callbacks_->connection().close(close_type.value());\n  }\n}\n\nvoid ConnectionManagerImpl::onGoAway(GoAwayErrorCode) {\n  // Currently we do nothing with remote go away frames. In the future we can decide to no longer\n  // push resources if applicable.\n}\n\nvoid ConnectionManagerImpl::onIdleTimeout() {\n  ENVOY_CONN_LOG(debug, \"idle timeout\", read_callbacks_->connection());\n  stats_.named_.downstream_cx_idle_timeout_.inc();\n  if (!codec_) {\n    // No need to delay close after flushing since an idle timeout has already fired. Attempt to\n    // write out buffered data one last time and issue a local close if successful.\n    doConnectionClose(Network::ConnectionCloseType::FlushWrite, absl::nullopt, \"\");\n  } else if (drain_state_ == DrainState::NotDraining) {\n    startDrainSequence();\n  }\n}\n\nvoid ConnectionManagerImpl::onConnectionDurationTimeout() {\n  ENVOY_CONN_LOG(debug, \"max connection duration reached\", read_callbacks_->connection());\n  stats_.named_.downstream_cx_max_duration_reached_.inc();\n  if (!codec_) {\n    // Attempt to write out buffered data one last time and issue a local close if successful.\n    doConnectionClose(Network::ConnectionCloseType::FlushWrite,\n                      StreamInfo::ResponseFlag::DurationTimeout,\n                      StreamInfo::ResponseCodeDetails::get().DurationTimeout);\n  } else if (drain_state_ == DrainState::NotDraining) {\n    startDrainSequence();\n  }\n}\n\nvoid ConnectionManagerImpl::onDrainTimeout() {\n  ASSERT(drain_state_ != DrainState::NotDraining);\n  codec_->goAway();\n  drain_state_ = DrainState::Closing;\n  checkForDeferredClose(false);\n}\n\nvoid ConnectionManagerImpl::chargeTracingStats(const Tracing::Reason& tracing_reason,\n                                               ConnectionManagerTracingStats& tracing_stats) {\n  switch (tracing_reason) {\n  case Tracing::Reason::ClientForced:\n    tracing_stats.client_enabled_.inc();\n    break;\n  case Tracing::Reason::Sampling:\n    tracing_stats.random_sampling_.inc();\n    break;\n  case Tracing::Reason::ServiceForced:\n    tracing_stats.service_forced_.inc();\n    break;\n  default:\n    tracing_stats.not_traceable_.inc();\n    break;\n  }\n}\n\n// TODO(chaoqin-li1123): Make on demand vhds and on demand srds works at the same time.\nvoid ConnectionManagerImpl::RdsRouteConfigUpdateRequester::requestRouteConfigUpdate(\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  absl::optional<Router::ConfigConstSharedPtr> route_config = parent_.routeConfig();\n  Event::Dispatcher& thread_local_dispatcher =\n      parent_.connection_manager_.read_callbacks_->connection().dispatcher();\n  if (route_config.has_value() && route_config.value()->usesVhds()) {\n    ASSERT(!parent_.request_headers_->Host()->value().empty());\n    const auto& host_header = absl::AsciiStrToLower(parent_.request_headers_->getHostValue());\n    requestVhdsUpdate(host_header, thread_local_dispatcher, std::move(route_config_updated_cb));\n    return;\n  } else if (parent_.snapped_scoped_routes_config_ != nullptr) {\n    Router::ScopeKeyPtr scope_key =\n        parent_.snapped_scoped_routes_config_->computeScopeKey(*parent_.request_headers_);\n    // If scope_key is not null, the scope exists but RouteConfiguration is not initialized.\n    if (scope_key != nullptr) {\n      requestSrdsUpdate(std::move(scope_key), thread_local_dispatcher,\n                        std::move(route_config_updated_cb));\n      return;\n    }\n  }\n  // Continue the filter chain if no on demand update is requested.\n  (*route_config_updated_cb)(false);\n}\n\nvoid ConnectionManagerImpl::RdsRouteConfigUpdateRequester::requestVhdsUpdate(\n    const std::string& host_header, Event::Dispatcher& thread_local_dispatcher,\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  route_config_provider_->requestVirtualHostsUpdate(host_header, thread_local_dispatcher,\n                                                    std::move(route_config_updated_cb));\n}\n\nvoid ConnectionManagerImpl::RdsRouteConfigUpdateRequester::requestSrdsUpdate(\n    Router::ScopeKeyPtr scope_key, Event::Dispatcher& thread_local_dispatcher,\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  // Since inline scope_route_config_provider is not fully implemented and never used,\n  // dynamic cast in constructor always succeed and the pointer should not be null here.\n  ASSERT(scoped_route_config_provider_ != nullptr);\n  Http::RouteConfigUpdatedCallback scoped_route_config_updated_cb =\n      Http::RouteConfigUpdatedCallback(\n          [this, weak_route_config_updated_cb = std::weak_ptr<Http::RouteConfigUpdatedCallback>(\n                     route_config_updated_cb)](bool scope_exist) {\n            // If the callback can be locked, this ActiveStream is still alive.\n            if (auto cb = weak_route_config_updated_cb.lock()) {\n              // Refresh the route before continue the filter chain.\n              if (scope_exist) {\n                parent_.refreshCachedRoute();\n              }\n              (*cb)(scope_exist && parent_.hasCachedRoute());\n            }\n          });\n  scoped_route_config_provider_->onDemandRdsUpdate(std::move(scope_key), thread_local_dispatcher,\n                                                   std::move(scoped_route_config_updated_cb));\n}\n\nConnectionManagerImpl::ActiveStream::ActiveStream(ConnectionManagerImpl& connection_manager,\n                                                  uint32_t buffer_limit,\n                                                  Buffer::BufferMemoryAccountSharedPtr account)\n    : connection_manager_(connection_manager),\n      stream_id_(connection_manager.random_generator_.random()),\n      filter_manager_(*this, connection_manager_.read_callbacks_->connection().dispatcher(),\n                      connection_manager_.read_callbacks_->connection(), stream_id_,\n                      std::move(account), connection_manager_.config_.proxy100Continue(),\n                      buffer_limit, connection_manager_.config_.filterFactory(),\n                      connection_manager_.config_.localReply(),\n                      connection_manager_.codec_->protocol(), connection_manager_.timeSource(),\n                      connection_manager_.read_callbacks_->connection().streamInfo().filterState(),\n                      StreamInfo::FilterState::LifeSpan::Connection),\n      request_response_timespan_(new Stats::HistogramCompletableTimespanImpl(\n          connection_manager_.stats_.named_.downstream_rq_time_,\n          connection_manager_.timeSource())) {\n  ASSERT(!connection_manager.config_.isRoutable() ||\n             ((connection_manager.config_.routeConfigProvider() == nullptr &&\n               connection_manager.config_.scopedRouteConfigProvider() != nullptr) ||\n              (connection_manager.config_.routeConfigProvider() != nullptr &&\n               connection_manager.config_.scopedRouteConfigProvider() == nullptr)),\n         \"Either routeConfigProvider or scopedRouteConfigProvider should be set in \"\n         \"ConnectionManagerImpl.\");\n  for (const AccessLog::InstanceSharedPtr& access_log : connection_manager_.config_.accessLogs()) {\n    filter_manager_.addAccessLogHandler(access_log);\n  }\n\n  filter_manager_.streamInfo().setRequestIDProvider(\n      connection_manager.config_.requestIDExtension());\n\n  if (connection_manager_.config_.isRoutable() &&\n      connection_manager.config_.routeConfigProvider() != nullptr) {\n    route_config_update_requester_ =\n        std::make_unique<ConnectionManagerImpl::RdsRouteConfigUpdateRequester>(\n            connection_manager.config_.routeConfigProvider(), *this);\n  } else if (connection_manager_.config_.isRoutable() &&\n             connection_manager.config_.scopedRouteConfigProvider() != nullptr) {\n    route_config_update_requester_ =\n        std::make_unique<ConnectionManagerImpl::RdsRouteConfigUpdateRequester>(\n            connection_manager.config_.scopedRouteConfigProvider(), *this);\n  }\n  ScopeTrackerScopeState scope(this,\n                               connection_manager_.read_callbacks_->connection().dispatcher());\n\n  connection_manager_.stats_.named_.downstream_rq_total_.inc();\n  connection_manager_.stats_.named_.downstream_rq_active_.inc();\n  if (connection_manager_.codec_->protocol() == Protocol::Http2) {\n    connection_manager_.stats_.named_.downstream_rq_http2_total_.inc();\n  } else if (connection_manager_.codec_->protocol() == Protocol::Http3) {\n    connection_manager_.stats_.named_.downstream_rq_http3_total_.inc();\n  } else {\n    connection_manager_.stats_.named_.downstream_rq_http1_total_.inc();\n  }\n\n  if (connection_manager_.config_.streamIdleTimeout().count()) {\n    idle_timeout_ms_ = connection_manager_.config_.streamIdleTimeout();\n    stream_idle_timer_ =\n        connection_manager_.read_callbacks_->connection().dispatcher().createScaledTimer(\n            Event::ScaledTimerType::HttpDownstreamIdleStreamTimeout,\n            [this]() -> void { onIdleTimeout(); });\n    resetIdleTimer();\n  }\n\n  if (connection_manager_.config_.requestTimeout().count()) {\n    std::chrono::milliseconds request_timeout = connection_manager_.config_.requestTimeout();\n    request_timer_ = connection_manager.read_callbacks_->connection().dispatcher().createTimer(\n        [this]() -> void { onRequestTimeout(); });\n    request_timer_->enableTimer(request_timeout, this);\n  }\n\n  if (connection_manager_.config_.requestHeadersTimeout().count()) {\n    std::chrono::milliseconds request_headers_timeout =\n        connection_manager_.config_.requestHeadersTimeout();\n    request_header_timer_ =\n        connection_manager.read_callbacks_->connection().dispatcher().createTimer(\n            [this]() -> void { onRequestHeaderTimeout(); });\n    request_header_timer_->enableTimer(request_headers_timeout, this);\n  }\n\n  const auto max_stream_duration = connection_manager_.config_.maxStreamDuration();\n  if (max_stream_duration.has_value() && max_stream_duration.value().count()) {\n    max_stream_duration_timer_ =\n        connection_manager.read_callbacks_->connection().dispatcher().createTimer(\n            [this]() -> void { onStreamMaxDurationReached(); });\n    max_stream_duration_timer_->enableTimer(connection_manager_.config_.maxStreamDuration().value(),\n                                            this);\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::completeRequest() {\n  filter_manager_.streamInfo().onRequestComplete();\n\n  if (connection_manager_.remote_close_) {\n    filter_manager_.streamInfo().setResponseCodeDetails(\n        StreamInfo::ResponseCodeDetails::get().DownstreamRemoteDisconnect);\n    filter_manager_.streamInfo().setResponseFlag(\n        StreamInfo::ResponseFlag::DownstreamConnectionTermination);\n  }\n  connection_manager_.stats_.named_.downstream_rq_active_.dec();\n  if (filter_manager_.streamInfo().healthCheck()) {\n    connection_manager_.config_.tracingStats().health_check_.inc();\n  }\n\n  if (active_span_) {\n    Tracing::HttpTracerUtility::finalizeDownstreamSpan(\n        *active_span_, request_headers_.get(), response_headers_.get(), response_trailers_.get(),\n        filter_manager_.streamInfo(), *this);\n  }\n  if (state_.successful_upgrade_) {\n    connection_manager_.stats_.named_.downstream_cx_upgrades_active_.dec();\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::resetIdleTimer() {\n  if (stream_idle_timer_ != nullptr) {\n    // TODO(htuch): If this shows up in performance profiles, optimize by only\n    // updating a timestamp here and doing periodic checks for idle timeouts\n    // instead, or reducing the accuracy of timers.\n    stream_idle_timer_->enableTimer(idle_timeout_ms_);\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onIdleTimeout() {\n  connection_manager_.stats_.named_.downstream_rq_idle_timeout_.inc();\n\n  // See below for more information on this early return block.\n  if (Runtime::runtimeFeatureEnabled(\n          \"envoy.reloadable_features.override_request_timeout_by_gateway_timeout\")) {\n    filter_manager_.streamInfo().setResponseFlag(StreamInfo::ResponseFlag::StreamIdleTimeout);\n    sendLocalReply(Http::Utility::maybeRequestTimeoutCode(filter_manager_.remoteDecodeComplete()),\n                   \"stream timeout\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().StreamIdleTimeout);\n    return;\n  }\n\n  // There are 2 issues in the blow code. First, `responseHeaders().has_value()` is not the best\n  // predicate. `remoteDecodeComplete()` is preferable. Second, `sendLocalReply()` smartly ends the\n  // stream if any response was pushed to decoder and explicitly `endStream()` is not required.\n  //\n  // The above code is expected to resolve both. The original code here before it is fully verified.\n  //\n  // TODO(lambdai): delete the block below along with the removal of\n  // `override_request_timeout_by_gateway_timeout`.\n\n  // If headers have not been sent to the user, send a 408.\n  if (responseHeaders().has_value()) {\n    // TODO(htuch): We could send trailers here with an x-envoy timeout header\n    // or gRPC status code, and/or set H2 RST_STREAM error.\n    filter_manager_.streamInfo().setResponseCodeDetails(\n        StreamInfo::ResponseCodeDetails::get().StreamIdleTimeout);\n    connection_manager_.doEndStream(*this);\n  } else {\n    filter_manager_.streamInfo().setResponseFlag(StreamInfo::ResponseFlag::StreamIdleTimeout);\n    sendLocalReply(Http::Code::RequestTimeout, \"stream timeout\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().StreamIdleTimeout);\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onRequestTimeout() {\n  connection_manager_.stats_.named_.downstream_rq_timeout_.inc();\n  sendLocalReply(Http::Utility::maybeRequestTimeoutCode(filter_manager_.remoteDecodeComplete()),\n                 \"request timeout\", nullptr, absl::nullopt,\n                 StreamInfo::ResponseCodeDetails::get().RequestOverallTimeout);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onRequestHeaderTimeout() {\n  connection_manager_.stats_.named_.downstream_rq_header_timeout_.inc();\n  sendLocalReply(Http::Utility::maybeRequestTimeoutCode(filter_manager_.remoteDecodeComplete()),\n                 \"request header timeout\", nullptr, absl::nullopt,\n                 StreamInfo::ResponseCodeDetails::get().RequestHeaderTimeout);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onStreamMaxDurationReached() {\n  ENVOY_STREAM_LOG(debug, \"Stream max duration time reached\", *this);\n  connection_manager_.stats_.named_.downstream_rq_max_duration_reached_.inc();\n  sendLocalReply(Http::Utility::maybeRequestTimeoutCode(filter_manager_.remoteDecodeComplete()),\n                 \"downstream duration timeout\", nullptr,\n                 Grpc::Status::WellKnownGrpcStatus::DeadlineExceeded,\n                 StreamInfo::ResponseCodeDetails::get().MaxDurationTimeout);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::chargeStats(const ResponseHeaderMap& headers) {\n  uint64_t response_code = Utility::getResponseStatus(headers);\n  filter_manager_.streamInfo().response_code_ = response_code;\n\n  if (filter_manager_.streamInfo().health_check_request_) {\n    return;\n  }\n\n  // No response is sent back downstream for internal redirects, so don't charge downstream stats.\n  const absl::optional<std::string>& response_code_details =\n      filter_manager_.streamInfo().responseCodeDetails();\n  if (response_code_details.has_value() &&\n      response_code_details == Envoy::StreamInfo::ResponseCodeDetails::get().InternalRedirect) {\n    return;\n  }\n\n  connection_manager_.stats_.named_.downstream_rq_completed_.inc();\n  connection_manager_.listener_stats_.downstream_rq_completed_.inc();\n  if (CodeUtility::is1xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_1xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_1xx_.inc();\n  } else if (CodeUtility::is2xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_2xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_2xx_.inc();\n  } else if (CodeUtility::is3xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_3xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_3xx_.inc();\n  } else if (CodeUtility::is4xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_4xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_4xx_.inc();\n  } else if (CodeUtility::is5xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_5xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_5xx_.inc();\n  }\n}\n\nconst Network::Connection* ConnectionManagerImpl::ActiveStream::connection() {\n  return &connection_manager_.read_callbacks_->connection();\n}\n\nuint32_t ConnectionManagerImpl::ActiveStream::localPort() {\n  auto ip = connection()->connectionInfoProvider().localAddress()->ip();\n  if (ip == nullptr) {\n    return 0;\n  }\n  return ip->port();\n}\n\n// Ordering in this function is complicated, but important.\n//\n// We want to do minimal work before selecting route and creating a filter\n// chain to maximize the number of requests which get custom filter behavior,\n// e.g. registering access logging.\n//\n// This must be balanced by doing sanity checking for invalid requests (one\n// can't route select properly without full headers), checking state required to\n// serve error responses (connection close, head requests, etc), and\n// modifications which may themselves affect route selection.\nvoid ConnectionManagerImpl::ActiveStream::decodeHeaders(RequestHeaderMapPtr&& headers,\n                                                        bool end_stream) {\n  ScopeTrackerScopeState scope(this,\n                               connection_manager_.read_callbacks_->connection().dispatcher());\n  request_headers_ = std::move(headers);\n  filter_manager_.requestHeadersInitialized();\n  if (request_header_timer_ != nullptr) {\n    request_header_timer_->disableTimer();\n    request_header_timer_.reset();\n  }\n\n  // Both saw_connection_close_ and is_head_request_ affect local replies: set\n  // them as early as possible.\n  const Protocol protocol = connection_manager_.codec_->protocol();\n  state_.saw_connection_close_ = HeaderUtility::shouldCloseConnection(protocol, *request_headers_);\n\n  // We need to snap snapped_route_config_ here as it's used in mutateRequestHeaders later.\n  if (connection_manager_.config_.isRoutable()) {\n    if (connection_manager_.config_.routeConfigProvider() != nullptr) {\n      snapped_route_config_ = connection_manager_.config_.routeConfigProvider()->configCast();\n    } else if (connection_manager_.config_.scopedRouteConfigProvider() != nullptr) {\n      snapped_scoped_routes_config_ =\n          connection_manager_.config_.scopedRouteConfigProvider()->config<Router::ScopedConfig>();\n      snapScopedRouteConfig();\n    }\n  } else {\n    snapped_route_config_ = connection_manager_.config_.routeConfigProvider()->configCast();\n  }\n\n  ENVOY_STREAM_LOG(debug, \"request headers complete (end_stream={}):\\n{}\", *this, end_stream,\n                   *request_headers_);\n\n  // We end the decode here only if the request is header only. If we convert the request to a\n  // header only, the stream will be marked as done once a subsequent decodeData/decodeTrailers is\n  // called with end_stream=true.\n  filter_manager_.maybeEndDecode(end_stream);\n\n  // Drop new requests when overloaded as soon as we have decoded the headers.\n  if (connection_manager_.random_generator_.bernoulli(\n          connection_manager_.overload_stop_accepting_requests_ref_.value())) {\n    // In this one special case, do not create the filter chain. If there is a risk of memory\n    // overload it is more important to avoid unnecessary allocation than to create the filters.\n    filter_manager_.skipFilterChainCreation();\n    connection_manager_.stats_.named_.downstream_rq_overload_close_.inc();\n    sendLocalReply(Http::Code::ServiceUnavailable, \"envoy overloaded\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().Overload);\n    return;\n  }\n\n  // This lambda should be erased when\n  // `envoy.reloadable_features.http_100_continue_case_insensitive` is removed.\n  auto is100Continue = [](absl::string_view request_expect) {\n    return request_expect == Headers::get().ExpectValues._100Continue ||\n           (Runtime::runtimeFeatureEnabled(\n                \"envoy.reloadable_features.http_100_continue_case_insensitive\") &&\n            // The Expect field-value is case-insensitive.\n            // https://tools.ietf.org/html/rfc7231#section-5.1.1\n            absl::EqualsIgnoreCase(request_expect, Headers::get().ExpectValues._100Continue));\n  };\n\n  if (!connection_manager_.config_.proxy100Continue() && request_headers_->Expect() &&\n      is100Continue(request_headers_->Expect()->value().getStringView())) {\n    // Note in the case Envoy is handling 100-Continue complexity, it skips the filter chain\n    // and sends the 100-Continue directly to the encoder.\n    chargeStats(continueHeader());\n    response_encoder_->encode1xxHeaders(continueHeader());\n    // Remove the Expect header so it won't be handled again upstream.\n    request_headers_->removeExpect();\n  }\n\n  connection_manager_.user_agent_.initializeFromHeaders(*request_headers_,\n                                                        connection_manager_.stats_.prefixStatName(),\n                                                        connection_manager_.stats_.scope_);\n\n  // Make sure we are getting a codec version we support.\n  if (protocol == Protocol::Http10) {\n    // Assume this is HTTP/1.0. This is fine for HTTP/0.9 but this code will also affect any\n    // requests with non-standard version numbers (0.9, 1.3), basically anything which is not\n    // HTTP/1.1.\n    //\n    // The protocol may have shifted in the HTTP/1.0 case so reset it.\n    filter_manager_.streamInfo().protocol(protocol);\n    if (!connection_manager_.config_.http1Settings().accept_http_10_) {\n      // Send \"Upgrade Required\" if HTTP/1.0 support is not explicitly configured on.\n      sendLocalReply(Code::UpgradeRequired, \"\", nullptr, absl::nullopt,\n                     StreamInfo::ResponseCodeDetails::get().LowVersion);\n      return;\n    }\n    if (!request_headers_->Host() &&\n        !connection_manager_.config_.http1Settings().default_host_for_http_10_.empty()) {\n      // Add a default host if configured to do so.\n      request_headers_->setHost(\n          connection_manager_.config_.http1Settings().default_host_for_http_10_);\n    }\n  }\n\n  if (!request_headers_->Host()) {\n    // Require host header. For HTTP/1.1 Host has already been translated to :authority.\n    sendLocalReply(Code::BadRequest, \"\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().MissingHost);\n    return;\n  }\n\n  // Verify header sanity checks which should have been performed by the codec.\n  ASSERT(HeaderUtility::requestHeadersValid(*request_headers_).has_value() == false);\n\n  // Check for the existence of the :path header for non-CONNECT requests, or present-but-empty\n  // :path header for CONNECT requests. We expect the codec to have broken the path into pieces if\n  // applicable. NOTE: Currently the HTTP/1.1 codec only does this when the allow_absolute_url flag\n  // is enabled on the HCM.\n  if ((!HeaderUtility::isConnect(*request_headers_) || request_headers_->Path()) &&\n      request_headers_->getPathValue().empty()) {\n    sendLocalReply(Code::NotFound, \"\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().MissingPath);\n    return;\n  }\n\n  // Currently we only support relative paths at the application layer.\n  if (!request_headers_->getPathValue().empty() && request_headers_->getPathValue()[0] != '/') {\n    connection_manager_.stats_.named_.downstream_rq_non_relative_path_.inc();\n    sendLocalReply(Code::NotFound, \"\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().AbsolutePath);\n    return;\n  }\n\n  // Path sanitization should happen before any path access other than the above sanity check.\n  const auto action =\n      ConnectionManagerUtility::maybeNormalizePath(*request_headers_, connection_manager_.config_);\n  // gRPC requests are rejected if Envoy is configured to redirect post-normalization. This is\n  // because gRPC clients do not support redirect.\n  if (action == ConnectionManagerUtility::NormalizePathAction::Reject ||\n      (action == ConnectionManagerUtility::NormalizePathAction::Redirect &&\n       Grpc::Common::hasGrpcContentType(*request_headers_))) {\n    connection_manager_.stats_.named_.downstream_rq_failed_path_normalization_.inc();\n    sendLocalReply(Code::BadRequest, \"\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().PathNormalizationFailed);\n    return;\n  } else if (action == ConnectionManagerUtility::NormalizePathAction::Redirect) {\n    connection_manager_.stats_.named_.downstream_rq_redirected_with_normalized_path_.inc();\n    sendLocalReply(\n        Code::TemporaryRedirect, \"\",\n        [new_path = request_headers_->Path()->value().getStringView()](\n            Http::ResponseHeaderMap& response_headers) -> void {\n          response_headers.addReferenceKey(Http::Headers::get().Location, new_path);\n        },\n        absl::nullopt, StreamInfo::ResponseCodeDetails::get().PathNormalizationFailed);\n    return;\n  }\n\n  ASSERT(action == ConnectionManagerUtility::NormalizePathAction::Continue);\n  auto optional_port = ConnectionManagerUtility::maybeNormalizeHost(\n      *request_headers_, connection_manager_.config_, localPort());\n  if (optional_port.has_value() &&\n      requestWasConnect(request_headers_, connection_manager_.codec_->protocol())) {\n    filter_manager_.streamInfo().filterState()->setData(\n        Router::OriginalConnectPort::key(),\n        std::make_unique<Router::OriginalConnectPort>(optional_port.value()),\n        StreamInfo::FilterState::StateType::ReadOnly, StreamInfo::FilterState::LifeSpan::Request);\n  }\n\n  if (!state_.is_internally_created_) { // Only sanitize headers on first pass.\n    // Modify the downstream remote address depending on configuration and headers.\n    const auto mutate_result = ConnectionManagerUtility::mutateRequestHeaders(\n        *request_headers_, connection_manager_.read_callbacks_->connection(),\n        connection_manager_.config_, *snapped_route_config_, connection_manager_.local_info_);\n\n    // IP detection failed, reject the request.\n    if (mutate_result.reject_request.has_value()) {\n      const auto& reject_request_params = mutate_result.reject_request.value();\n      connection_manager_.stats_.named_.downstream_rq_rejected_via_ip_detection_.inc();\n      sendLocalReply(reject_request_params.response_code, reject_request_params.body, nullptr,\n                     absl::nullopt,\n                     StreamInfo::ResponseCodeDetails::get().OriginalIPDetectionFailed);\n      return;\n    }\n\n    filter_manager_.setDownstreamRemoteAddress(mutate_result.final_remote_address);\n  }\n  ASSERT(filter_manager_.streamInfo().downstreamAddressProvider().remoteAddress() != nullptr);\n\n  ASSERT(!cached_route_);\n  refreshCachedRoute();\n\n  if (!state_.is_internally_created_) { // Only mutate tracing headers on first pass.\n    filter_manager_.streamInfo().setTraceReason(\n        ConnectionManagerUtility::mutateTracingRequestHeader(\n            *request_headers_, connection_manager_.runtime_, connection_manager_.config_,\n            cached_route_.value().get()));\n  }\n\n  filter_manager_.streamInfo().setRequestHeaders(*request_headers_);\n\n  const bool upgrade_rejected = filter_manager_.createFilterChain() == false;\n\n  // TODO if there are no filters when starting a filter iteration, the connection manager\n  // should return 404. The current returns no response if there is no router filter.\n  if (hasCachedRoute()) {\n    // Do not allow upgrades if the route does not support it.\n    if (upgrade_rejected) {\n      // While downstream servers should not send upgrade payload without the upgrade being\n      // accepted, err on the side of caution and refuse to process any further requests on this\n      // connection, to avoid a class of HTTP/1.1 smuggling bugs where Upgrade or CONNECT payload\n      // contains a smuggled HTTP request.\n      state_.saw_connection_close_ = true;\n      connection_manager_.stats_.named_.downstream_rq_ws_on_non_ws_route_.inc();\n      sendLocalReply(Code::Forbidden, \"\", nullptr, absl::nullopt,\n                     StreamInfo::ResponseCodeDetails::get().UpgradeFailed);\n      return;\n    }\n    // Allow non websocket requests to go through websocket enabled routes.\n  }\n\n  if (hasCachedRoute()) {\n    const Router::RouteEntry* route_entry = cached_route_.value()->routeEntry();\n    if (route_entry != nullptr && route_entry->idleTimeout()) {\n      // TODO(mattklein123): Technically if the cached route changes, we should also see if the\n      // route idle timeout has changed and update the value.\n      idle_timeout_ms_ = route_entry->idleTimeout().value();\n      response_encoder_->getStream().setFlushTimeout(idle_timeout_ms_);\n      if (idle_timeout_ms_.count()) {\n        // If we have a route-level idle timeout but no global stream idle timeout, create a timer.\n        if (stream_idle_timer_ == nullptr) {\n          stream_idle_timer_ =\n              connection_manager_.read_callbacks_->connection().dispatcher().createScaledTimer(\n                  Event::ScaledTimerType::HttpDownstreamIdleStreamTimeout,\n                  [this]() -> void { onIdleTimeout(); });\n        }\n      } else if (stream_idle_timer_ != nullptr) {\n        // If we had a global stream idle timeout but the route-level idle timeout is set to zero\n        // (to override), we disable the idle timer.\n        stream_idle_timer_->disableTimer();\n        stream_idle_timer_ = nullptr;\n      }\n    }\n  }\n\n  // Check if tracing is enabled at all.\n  if (connection_manager_.config_.tracingConfig()) {\n    traceRequest();\n  }\n\n  filter_manager_.decodeHeaders(*request_headers_, end_stream);\n\n  // Reset it here for both global and overridden cases.\n  resetIdleTimer();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::traceRequest() {\n  const Tracing::Decision tracing_decision =\n      Tracing::HttpTracerUtility::shouldTraceRequest(filter_manager_.streamInfo());\n  ConnectionManagerImpl::chargeTracingStats(tracing_decision.reason,\n                                            connection_manager_.config_.tracingStats());\n\n  active_span_ = connection_manager_.tracer().startSpan(\n      *this, *request_headers_, filter_manager_.streamInfo(), tracing_decision);\n\n  if (!active_span_) {\n    return;\n  }\n\n  // TODO: Need to investigate the following code based on the cached route, as may\n  // be broken in the case a filter changes the route.\n\n  // If a decorator has been defined, apply it to the active span.\n  if (hasCachedRoute() && cached_route_.value()->decorator()) {\n    const Router::Decorator* decorator = cached_route_.value()->decorator();\n\n    decorator->apply(*active_span_);\n\n    state_.decorated_propagate_ = decorator->propagate();\n\n    // Cache decorated operation.\n    if (!decorator->getOperation().empty()) {\n      decorated_operation_ = &decorator->getOperation();\n    }\n  }\n\n  if (connection_manager_.config_.tracingConfig()->operation_name_ ==\n      Tracing::OperationName::Egress) {\n    // For egress (outbound) requests, pass the decorator's operation name (if defined and\n    // propagation enabled) as a request header to enable the receiving service to use it in its\n    // server span.\n    if (decorated_operation_ && state_.decorated_propagate_) {\n      request_headers_->setEnvoyDecoratorOperation(*decorated_operation_);\n    }\n  } else {\n    const HeaderEntry* req_operation_override = request_headers_->EnvoyDecoratorOperation();\n\n    // For ingress (inbound) requests, if a decorator operation name has been provided, it\n    // should be used to override the active span's operation.\n    if (req_operation_override) {\n      if (!req_operation_override->value().empty()) {\n        active_span_->setOperation(req_operation_override->value().getStringView());\n\n        // Clear the decorated operation so won't be used in the response header, as\n        // it has been overridden by the inbound decorator operation request header.\n        decorated_operation_ = nullptr;\n      }\n      // Remove header so not propagated to service\n      request_headers_->removeEnvoyDecoratorOperation();\n    }\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::decodeData(Buffer::Instance& data, bool end_stream) {\n  ScopeTrackerScopeState scope(this,\n                               connection_manager_.read_callbacks_->connection().dispatcher());\n  filter_manager_.maybeEndDecode(end_stream);\n  filter_manager_.streamInfo().addBytesReceived(data.length());\n\n  filter_manager_.decodeData(data, end_stream);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::decodeTrailers(RequestTrailerMapPtr&& trailers) {\n  ScopeTrackerScopeState scope(this,\n                               connection_manager_.read_callbacks_->connection().dispatcher());\n  resetIdleTimer();\n\n  ASSERT(!request_trailers_);\n  request_trailers_ = std::move(trailers);\n  filter_manager_.maybeEndDecode(true);\n  filter_manager_.decodeTrailers(*request_trailers_);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::decodeMetadata(MetadataMapPtr&& metadata_map) {\n  resetIdleTimer();\n  // After going through filters, the ownership of metadata_map will be passed to terminal filter.\n  // The terminal filter may encode metadata_map to the next hop immediately or store metadata_map\n  // and encode later when connection pool is ready.\n  filter_manager_.decodeMetadata(*metadata_map);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::disarmRequestTimeout() {\n  if (request_timer_) {\n    request_timer_->disableTimer();\n  }\n}\n\nvoid ConnectionManagerImpl::startDrainSequence() {\n  ASSERT(drain_state_ == DrainState::NotDraining);\n  drain_state_ = DrainState::Draining;\n  codec_->shutdownNotice();\n  drain_timer_ = read_callbacks_->connection().dispatcher().createTimer(\n      [this]() -> void { onDrainTimeout(); });\n  drain_timer_->enableTimer(config_.drainTimeout());\n}\n\nvoid ConnectionManagerImpl::ActiveStream::snapScopedRouteConfig() {\n  // NOTE: if a RDS subscription hasn't got a RouteConfiguration back, a Router::NullConfigImpl is\n  // returned, in that case we let it pass.\n  snapped_route_config_ = snapped_scoped_routes_config_->getRouteConfig(*request_headers_);\n  if (snapped_route_config_ == nullptr) {\n    ENVOY_STREAM_LOG(trace, \"can't find SRDS scope.\", *this);\n    // TODO(stevenzzzz): Consider to pass an error message to router filter, so that it can\n    // send back 404 with some more details.\n    snapped_route_config_ = std::make_shared<Router::NullConfigImpl>();\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::refreshCachedRoute() { refreshCachedRoute(nullptr); }\n\nvoid ConnectionManagerImpl::ActiveStream::refreshDurationTimeout() {\n  if (!filter_manager_.streamInfo().route() ||\n      !filter_manager_.streamInfo().route()->routeEntry() || !request_headers_) {\n    return;\n  }\n  const auto& route = filter_manager_.streamInfo().route()->routeEntry();\n\n  auto grpc_timeout = Grpc::Common::getGrpcTimeout(*request_headers_);\n  std::chrono::milliseconds timeout;\n  bool disable_timer = false;\n\n  if (!grpc_timeout || !route->grpcTimeoutHeaderMax()) {\n    // Either there is no grpc-timeout header or special timeouts for it are not\n    // configured. Use stream duration.\n    if (route->maxStreamDuration()) {\n      timeout = route->maxStreamDuration().value();\n      if (timeout == std::chrono::milliseconds(0)) {\n        // Explicitly configured 0 means no timeout.\n        disable_timer = true;\n      }\n    } else {\n      // Fall back to HCM config. If no HCM duration limit exists, disable\n      // timers set by any prior route configuration.\n      const auto max_stream_duration = connection_manager_.config_.maxStreamDuration();\n      if (max_stream_duration.has_value() && max_stream_duration.value().count()) {\n        timeout = max_stream_duration.value();\n      } else {\n        disable_timer = true;\n      }\n    }\n  } else {\n    // Start with the timeout equal to the gRPC timeout header.\n    timeout = grpc_timeout.value();\n    // If there's a valid cap, apply it.\n    if (timeout > route->grpcTimeoutHeaderMax().value() &&\n        route->grpcTimeoutHeaderMax().value() != std::chrono::milliseconds(0)) {\n      timeout = route->grpcTimeoutHeaderMax().value();\n    }\n\n    // Apply the configured offset.\n    if (timeout != std::chrono::milliseconds(0) && route->grpcTimeoutHeaderOffset()) {\n      const auto offset = route->grpcTimeoutHeaderOffset().value();\n      if (offset < timeout) {\n        timeout -= offset;\n      } else {\n        timeout = std::chrono::milliseconds(0);\n      }\n    }\n  }\n\n  // Disable any existing timer if configured to do so.\n  if (disable_timer) {\n    if (max_stream_duration_timer_) {\n      max_stream_duration_timer_->disableTimer();\n      if (route->usingNewTimeouts() && Grpc::Common::isGrpcRequestHeaders(*request_headers_)) {\n        request_headers_->removeGrpcTimeout();\n      }\n    }\n    return;\n  }\n\n  // Set the header timeout before doing used-time adjustments.\n  // This may result in the upstream not getting the latest results, but also\n  // avoids every request getting a custom timeout based on envoy think time.\n  if (route->usingNewTimeouts() && Grpc::Common::isGrpcRequestHeaders(*request_headers_)) {\n    Grpc::Common::toGrpcTimeout(std::chrono::milliseconds(timeout), *request_headers_);\n  }\n\n  // See how long this stream has been alive, and adjust the timeout\n  // accordingly.\n  std::chrono::duration time_used = std::chrono::duration_cast<std::chrono::milliseconds>(\n      connection_manager_.timeSource().monotonicTime() -\n      filter_manager_.streamInfo().startTimeMonotonic());\n  if (timeout > time_used) {\n    timeout -= time_used;\n  } else {\n    timeout = std::chrono::milliseconds(0);\n  }\n\n  // Finally create (if necessary) and enable the timer.\n  if (!max_stream_duration_timer_) {\n    max_stream_duration_timer_ =\n        connection_manager_.read_callbacks_->connection().dispatcher().createTimer(\n            [this]() -> void { onStreamMaxDurationReached(); });\n  }\n  max_stream_duration_timer_->enableTimer(timeout);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::refreshCachedRoute(const Router::RouteCallback& cb) {\n  Router::RouteConstSharedPtr route;\n  if (request_headers_ != nullptr) {\n    if (connection_manager_.config_.isRoutable() &&\n        connection_manager_.config_.scopedRouteConfigProvider() != nullptr) {\n      // NOTE: re-select scope as well in case the scope key header has been changed by a filter.\n      snapScopedRouteConfig();\n    }\n    if (snapped_route_config_ != nullptr) {\n      route = snapped_route_config_->route(cb, *request_headers_, filter_manager_.streamInfo(),\n                                           stream_id_);\n    }\n  }\n\n  setRoute(route);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::refreshCachedTracingCustomTags() {\n  if (!connection_manager_.config_.tracingConfig()) {\n    return;\n  }\n  const Tracing::CustomTagMap& conn_manager_tags =\n      connection_manager_.config_.tracingConfig()->custom_tags_;\n  const Tracing::CustomTagMap* route_tags = nullptr;\n  if (hasCachedRoute() && cached_route_.value()->tracingConfig()) {\n    route_tags = &cached_route_.value()->tracingConfig()->getCustomTags();\n  }\n  const bool configured_in_conn = !conn_manager_tags.empty();\n  const bool configured_in_route = route_tags && !route_tags->empty();\n  if (!configured_in_conn && !configured_in_route) {\n    return;\n  }\n  Tracing::CustomTagMap& custom_tag_map = getOrMakeTracingCustomTagMap();\n  if (configured_in_route) {\n    custom_tag_map.insert(route_tags->begin(), route_tags->end());\n  }\n  if (configured_in_conn) {\n    custom_tag_map.insert(conn_manager_tags.begin(), conn_manager_tags.end());\n  }\n}\n\n// TODO(chaoqin-li1123): Make on demand vhds and on demand srds works at the same time.\nvoid ConnectionManagerImpl::ActiveStream::requestRouteConfigUpdate(\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  route_config_update_requester_->requestRouteConfigUpdate(route_config_updated_cb);\n}\n\nabsl::optional<Router::ConfigConstSharedPtr> ConnectionManagerImpl::ActiveStream::routeConfig() {\n  if (connection_manager_.config_.routeConfigProvider() != nullptr) {\n    return absl::optional<Router::ConfigConstSharedPtr>(\n        connection_manager_.config_.routeConfigProvider()->configCast());\n  }\n  return {};\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onLocalReply(Code code) {\n  // The BadRequest error code indicates there has been a messaging error.\n  if (code == Http::Code::BadRequest && connection_manager_.codec_->protocol() < Protocol::Http2 &&\n      !response_encoder_->streamErrorOnInvalidHttpMessage()) {\n    state_.saw_connection_close_ = true;\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encode1xxHeaders(ResponseHeaderMap& response_headers) {\n  // Strip the T-E headers etc. Defer other header additions as well as drain-close logic to the\n  // continuation headers.\n  ConnectionManagerUtility::mutateResponseHeaders(\n      response_headers, request_headers_.get(), connection_manager_.config_, EMPTY_STRING,\n      filter_manager_.streamInfo(), connection_manager_.proxy_name_,\n      connection_manager_.clear_hop_by_hop_response_headers_);\n\n  // Count both the 1xx and follow-up response code in stats.\n  chargeStats(response_headers);\n\n  ENVOY_STREAM_LOG(debug, \"encoding 100 continue headers via codec:\\n{}\", *this, response_headers);\n\n  // Now actually encode via the codec.\n  response_encoder_->encode1xxHeaders(response_headers);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encodeHeaders(ResponseHeaderMap& headers,\n                                                        bool end_stream) {\n  // Base headers.\n\n  // We want to preserve the original date header, but we add a date header if it is absent\n  if (!headers.Date()) {\n    connection_manager_.config_.dateProvider().setDateHeader(headers);\n  }\n\n  // Following setReference() is safe because serverName() is constant for the life of the\n  // listener.\n  const auto transformation = connection_manager_.config_.serverHeaderTransformation();\n  if (transformation == ConnectionManagerConfig::HttpConnectionManagerProto::OVERWRITE ||\n      (transformation == ConnectionManagerConfig::HttpConnectionManagerProto::APPEND_IF_ABSENT &&\n       headers.Server() == nullptr)) {\n    headers.setReferenceServer(connection_manager_.config_.serverName());\n  }\n  ConnectionManagerUtility::mutateResponseHeaders(\n      headers, request_headers_.get(), connection_manager_.config_,\n      connection_manager_.config_.via(), filter_manager_.streamInfo(),\n      connection_manager_.proxy_name_, connection_manager_.clear_hop_by_hop_response_headers_);\n\n  bool drain_connection_due_to_overload = false;\n  if (connection_manager_.drain_state_ == DrainState::NotDraining &&\n      connection_manager_.random_generator_.bernoulli(\n          connection_manager_.overload_disable_keepalive_ref_.value())) {\n    ENVOY_STREAM_LOG(debug, \"disabling keepalive due to envoy overload\", *this);\n    drain_connection_due_to_overload = true;\n    connection_manager_.stats_.named_.downstream_cx_overload_disable_keepalive_.inc();\n  }\n\n  // See if we want to drain/close the connection. Send the go away frame prior to encoding the\n  // header block.\n  if (connection_manager_.drain_state_ == DrainState::NotDraining &&\n      (connection_manager_.drain_close_.drainClose() || drain_connection_due_to_overload)) {\n\n    // This doesn't really do anything for HTTP/1.1 other then give the connection another boost\n    // of time to race with incoming requests. For HTTP/2 connections, send a GOAWAY frame to\n    // prevent any new streams.\n    connection_manager_.startDrainSequence();\n    connection_manager_.stats_.named_.downstream_cx_drain_close_.inc();\n    ENVOY_STREAM_LOG(debug, \"drain closing connection\", *this);\n  }\n\n  if (connection_manager_.codec_->protocol() == Protocol::Http10) {\n    // As HTTP/1.0 and below can not do chunked encoding, if there is no content\n    // length the response will be framed by connection close.\n    if (!headers.ContentLength()) {\n      state_.saw_connection_close_ = true;\n    }\n    // If the request came with a keep-alive and no other factor resulted in a\n    // connection close header, send an explicit keep-alive header.\n    if (!state_.saw_connection_close_) {\n      headers.setConnection(Headers::get().ConnectionValues.KeepAlive);\n    }\n  }\n\n  if (connection_manager_.drain_state_ == DrainState::NotDraining && state_.saw_connection_close_) {\n    ENVOY_STREAM_LOG(debug, \"closing connection due to connection close header\", *this);\n    connection_manager_.drain_state_ = DrainState::Closing;\n  }\n\n  // If we are destroying a stream before remote is complete and the connection does not support\n  // multiplexing, we should disconnect since we don't want to wait around for the request to\n  // finish.\n  if (!filter_manager_.remoteDecodeComplete()) {\n    if (connection_manager_.codec_->protocol() < Protocol::Http2) {\n      connection_manager_.drain_state_ = DrainState::Closing;\n    }\n\n    connection_manager_.stats_.named_.downstream_rq_response_before_rq_complete_.inc();\n  }\n\n  if (connection_manager_.drain_state_ != DrainState::NotDraining &&\n      connection_manager_.codec_->protocol() < Protocol::Http2) {\n    // If the connection manager is draining send \"Connection: Close\" on HTTP/1.1 connections.\n    // Do not do this for H2 (which drains via GOAWAY) or Upgrade or CONNECT (as the\n    // payload is no longer HTTP/1.1)\n    if (!Utility::isUpgrade(headers) &&\n        !HeaderUtility::isConnectResponse(request_headers_.get(), *responseHeaders())) {\n      headers.setReferenceConnection(Headers::get().ConnectionValues.Close);\n    }\n  }\n\n  if (connection_manager_.config_.tracingConfig()) {\n    if (connection_manager_.config_.tracingConfig()->operation_name_ ==\n        Tracing::OperationName::Ingress) {\n      // For ingress (inbound) responses, if the request headers do not include a\n      // decorator operation (override), and the decorated operation should be\n      // propagated, then pass the decorator's operation name (if defined)\n      // as a response header to enable the client service to use it in its client span.\n      if (decorated_operation_ && state_.decorated_propagate_) {\n        headers.setEnvoyDecoratorOperation(*decorated_operation_);\n      }\n    } else if (connection_manager_.config_.tracingConfig()->operation_name_ ==\n               Tracing::OperationName::Egress) {\n      const HeaderEntry* resp_operation_override = headers.EnvoyDecoratorOperation();\n\n      // For Egress (outbound) response, if a decorator operation name has been provided, it\n      // should be used to override the active span's operation.\n      if (resp_operation_override) {\n        if (!resp_operation_override->value().empty() && active_span_) {\n          active_span_->setOperation(resp_operation_override->value().getStringView());\n        }\n        // Remove header so not propagated to service.\n        headers.removeEnvoyDecoratorOperation();\n      }\n    }\n  }\n\n  chargeStats(headers);\n\n  ENVOY_STREAM_LOG(debug, \"encoding headers via codec (end_stream={}):\\n{}\", *this, end_stream,\n                   headers);\n\n  // Now actually encode via the codec.\n  filter_manager_.streamInfo().downstreamTiming().onFirstDownstreamTxByteSent(\n      connection_manager_.time_source_);\n  response_encoder_->encodeHeaders(headers, end_stream);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encodeData(Buffer::Instance& data, bool end_stream) {\n  ENVOY_STREAM_LOG(trace, \"encoding data via codec (size={} end_stream={})\", *this, data.length(),\n                   end_stream);\n\n  filter_manager_.streamInfo().addBytesSent(data.length());\n  response_encoder_->encodeData(data, end_stream);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encodeTrailers(ResponseTrailerMap& trailers) {\n  ENVOY_STREAM_LOG(debug, \"encoding trailers via codec:\\n{}\", *this, trailers);\n\n  response_encoder_->encodeTrailers(trailers);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encodeMetadata(MetadataMapVector& metadata) {\n  ENVOY_STREAM_LOG(debug, \"encoding metadata via codec:\\n{}\", *this, metadata);\n  response_encoder_->encodeMetadata(metadata);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onDecoderFilterBelowWriteBufferLowWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Read-enabling downstream stream due to filter callbacks.\", *this);\n  // If the state is destroyed, the codec's stream is already torn down. On\n  // teardown the codec will unwind any remaining read disable calls.\n  if (!filter_manager_.destroyed()) {\n    response_encoder_->getStream().readDisable(false);\n  }\n  connection_manager_.stats_.named_.downstream_flow_control_resumed_reading_total_.inc();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onDecoderFilterAboveWriteBufferHighWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Read-disabling downstream stream due to filter callbacks.\", *this);\n  response_encoder_->getStream().readDisable(true);\n  connection_manager_.stats_.named_.downstream_flow_control_paused_reading_total_.inc();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onResetStream(StreamResetReason reset_reason,\n                                                        absl::string_view) {\n  // NOTE: This function gets called in all of the following cases:\n  //       1) We TX an app level reset\n  //       2) The codec TX a codec level reset\n  //       3) The codec RX a reset\n  //       4) The overload manager reset the stream\n  //       If we need to differentiate we need to do it inside the codec. Can start with this.\n  ENVOY_STREAM_LOG(debug, \"stream reset\", *this);\n  connection_manager_.stats_.named_.downstream_rq_rx_reset_.inc();\n\n  // If the codec sets its responseDetails() for a reason other than peer reset, set a\n  // DownstreamProtocolError. Either way, propagate details.\n  const absl::string_view encoder_details = response_encoder_->getStream().responseDetails();\n  if (!encoder_details.empty() && reset_reason == StreamResetReason::LocalReset) {\n    filter_manager_.streamInfo().setResponseFlag(StreamInfo::ResponseFlag::DownstreamProtocolError);\n  }\n  if (!encoder_details.empty()) {\n    filter_manager_.streamInfo().setResponseCodeDetails(encoder_details);\n  }\n\n  // Check if we're in the overload manager reset case.\n  // encoder_details should be empty in this case as we don't have a codec error.\n  if (encoder_details.empty() && reset_reason == StreamResetReason::OverloadManager) {\n    filter_manager_.streamInfo().setResponseFlag(StreamInfo::ResponseFlag::OverloadManager);\n    filter_manager_.streamInfo().setResponseCodeDetails(\n        StreamInfo::ResponseCodeDetails::get().Overload);\n  }\n  if (Runtime::runtimeFeatureEnabled(\n          \"envoy.reloadable_features.handle_stream_reset_during_hcm_encoding\")) {\n    filter_manager_.onDownstreamReset();\n  }\n\n  connection_manager_.doDeferredStreamDestroy(*this);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onAboveWriteBufferHighWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Disabling upstream stream due to downstream stream watermark.\", *this);\n  filter_manager_.callHighWatermarkCallbacks();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onBelowWriteBufferLowWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Enabling upstream stream due to downstream stream watermark.\", *this);\n  filter_manager_.callLowWatermarkCallbacks();\n}\n\nTracing::OperationName ConnectionManagerImpl::ActiveStream::operationName() const {\n  return connection_manager_.config_.tracingConfig()->operation_name_;\n}\n\nconst Tracing::CustomTagMap* ConnectionManagerImpl::ActiveStream::customTags() const {\n  return tracing_custom_tags_.get();\n}\n\nbool ConnectionManagerImpl::ActiveStream::verbose() const {\n  return connection_manager_.config_.tracingConfig()->verbose_;\n}\n\nuint32_t ConnectionManagerImpl::ActiveStream::maxPathTagLength() const {\n  return connection_manager_.config_.tracingConfig()->max_path_tag_length_;\n}\n\nconst Router::RouteEntry::UpgradeMap* ConnectionManagerImpl::ActiveStream::upgradeMap() {\n  // We must check if the 'cached_route_' optional is populated since this function can be called\n  // early via sendLocalReply(), before the cached route is populated.\n  if (hasCachedRoute() && cached_route_.value()->routeEntry()) {\n    return &cached_route_.value()->routeEntry()->upgradeMap();\n  }\n\n  return nullptr;\n}\n\nTracing::Span& ConnectionManagerImpl::ActiveStream::activeSpan() {\n  if (active_span_) {\n    return *active_span_;\n  } else {\n    return Tracing::NullSpan::instance();\n  }\n}\n\nTracing::Config& ConnectionManagerImpl::ActiveStream::tracingConfig() { return *this; }\n\nconst ScopeTrackedObject& ConnectionManagerImpl::ActiveStream::scope() { return *this; }\n\nUpstream::ClusterInfoConstSharedPtr ConnectionManagerImpl::ActiveStream::clusterInfo() {\n  // NOTE: Refreshing route caches clusterInfo as well.\n  if (!cached_route_.has_value()) {\n    refreshCachedRoute();\n  }\n\n  return cached_cluster_info_.value();\n}\n\nRouter::RouteConstSharedPtr\nConnectionManagerImpl::ActiveStream::route(const Router::RouteCallback& cb) {\n  if (cached_route_.has_value()) {\n    return cached_route_.value();\n  }\n  refreshCachedRoute(cb);\n  return cached_route_.value();\n}\n\n/**\n * Sets the cached route to the RouteConstSharedPtr argument passed in. Handles setting the\n * cached_route_/cached_cluster_info_ ActiveStream attributes, the FilterManager streamInfo, tracing\n * tags, and timeouts.\n *\n * Declared as a StreamFilterCallbacks member function for filters to call directly, but also\n * functions as a helper to refreshCachedRoute(const Router::RouteCallback& cb).\n */\nvoid ConnectionManagerImpl::ActiveStream::setRoute(Router::RouteConstSharedPtr route) {\n  filter_manager_.streamInfo().route_ = route;\n  cached_route_ = std::move(route);\n  if (nullptr == filter_manager_.streamInfo().route() ||\n      nullptr == filter_manager_.streamInfo().route()->routeEntry()) {\n    cached_cluster_info_ = nullptr;\n  } else {\n    Upstream::ThreadLocalCluster* local_cluster =\n        connection_manager_.cluster_manager_.getThreadLocalCluster(\n            filter_manager_.streamInfo().route()->routeEntry()->clusterName());\n    cached_cluster_info_ = (nullptr == local_cluster) ? nullptr : local_cluster->info();\n  }\n\n  filter_manager_.streamInfo().setUpstreamClusterInfo(cached_cluster_info_.value());\n  refreshCachedTracingCustomTags();\n  refreshDurationTimeout();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::clearRouteCache() {\n  cached_route_ = absl::optional<Router::RouteConstSharedPtr>();\n  cached_cluster_info_ = absl::optional<Upstream::ClusterInfoConstSharedPtr>();\n  if (tracing_custom_tags_) {\n    tracing_custom_tags_->clear();\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onRequestDataTooLarge() {\n  connection_manager_.stats_.named_.downstream_rq_too_large_.inc();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::recreateStream(\n    StreamInfo::FilterStateSharedPtr filter_state) {\n  // n.b. we do not currently change the codecs to point at the new stream\n  // decoder because the decoder callbacks are complete. It would be good to\n  // null out that pointer but should not be necessary.\n  ResponseEncoder* response_encoder = response_encoder_;\n  response_encoder_ = nullptr;\n\n  Buffer::InstancePtr request_data = std::make_unique<Buffer::OwnedImpl>();\n  const auto& buffered_request_data = filter_manager_.bufferedRequestData();\n  const bool proxy_body = buffered_request_data != nullptr && buffered_request_data->length() > 0;\n  if (proxy_body) {\n    request_data->move(*buffered_request_data);\n  }\n\n  response_encoder->getStream().removeCallbacks(*this);\n  // This functionally deletes the stream (via deferred delete) so do not\n  // reference anything beyond this point.\n  connection_manager_.doEndStream(*this);\n\n  RequestDecoder& new_stream = connection_manager_.newStream(*response_encoder, true);\n  // We don't need to copy over the old parent FilterState from the old StreamInfo if it did not\n  // store any objects with a LifeSpan at or above DownstreamRequest. This is to avoid unnecessary\n  // heap allocation.\n  // TODO(snowp): In the case where connection level filter state has been set on the connection\n  // FilterState that we inherit, we'll end up copying this every time even though we could get\n  // away with just resetting it to the HCM filter_state_.\n  if (filter_state->hasDataAtOrAboveLifeSpan(StreamInfo::FilterState::LifeSpan::Request)) {\n    (*connection_manager_.streams_.begin())->filter_manager_.streamInfo().filter_state_ =\n        std::make_shared<StreamInfo::FilterStateImpl>(\n            filter_state->parent(), StreamInfo::FilterState::LifeSpan::FilterChain);\n  }\n\n  new_stream.decodeHeaders(std::move(request_headers_), !proxy_body);\n  if (proxy_body) {\n    // This functionality is currently only used for internal redirects, which the router only\n    // allows if the full request has been read (end_stream = true) so we don't need to handle the\n    // case of upstream sending an early response mid-request.\n    new_stream.decodeData(*request_data, true);\n  }\n}\n\nHttp1StreamEncoderOptionsOptRef ConnectionManagerImpl::ActiveStream::http1StreamEncoderOptions() {\n  return response_encoder_->http1StreamEncoderOptions();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onResponseDataTooLarge() {\n  connection_manager_.stats_.named_.rs_too_large_.inc();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::resetStream() {\n  connection_manager_.stats_.named_.downstream_rq_tx_reset_.inc();\n  connection_manager_.doEndStream(*this);\n}\n\n} // namespace Http\n} // namespace Envoy\n", "#include \"source/common/http/filter_manager.h\"\n\n#include <functional>\n\n#include \"envoy/http/header_map.h\"\n#include \"envoy/matcher/matcher.h\"\n\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/scope_tracked_object_stack.h\"\n#include \"source/common/common/scope_tracker.h\"\n#include \"source/common/http/codes.h\"\n#include \"source/common/http/header_map_impl.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/http/utility.h\"\n\n#include \"matching/data_impl.h\"\n\nnamespace Envoy {\nnamespace Http {\n\nnamespace {\nREGISTER_FACTORY(SkipActionFactory, Matcher::ActionFactory<Matching::HttpFilterActionContext>);\n\ntemplate <class T> using FilterList = std::list<std::unique_ptr<T>>;\n\n// Shared helper for recording the latest filter used.\ntemplate <class T>\nvoid recordLatestDataFilter(const typename FilterList<T>::iterator current_filter,\n                            T*& latest_filter, const FilterList<T>& filters) {\n  // If this is the first time we're calling onData, just record the current filter.\n  if (latest_filter == nullptr) {\n    latest_filter = current_filter->get();\n    return;\n  }\n\n  // We want to keep this pointing at the latest filter in the filter list that has received the\n  // onData callback. To do so, we compare the current latest with the *previous* filter. If they\n  // match, then we must be processing a new filter for the first time. We omit this check if we're\n  // the first filter, since the above check handles that case.\n  //\n  // We compare against the previous filter to avoid multiple filter iterations from resetting the\n  // pointer: If we just set latest to current, then the first onData filter iteration would\n  // correctly iterate over the filters and set latest, but on subsequent onData iterations\n  // we'd start from the beginning again, potentially allowing filter N to modify the buffer even\n  // though filter M > N was the filter that inserted data into the buffer.\n  if (current_filter != filters.begin() && latest_filter == std::prev(current_filter)->get()) {\n    latest_filter = current_filter->get();\n  }\n}\n\n} // namespace\n\nvoid ActiveStreamFilterBase::commonContinue() {\n  // TODO(mattklein123): Raise an error if this is called during a callback.\n  if (!canContinue()) {\n    ENVOY_STREAM_LOG(trace, \"cannot continue filter chain: filter={}\", *this,\n                     static_cast<const void*>(this));\n    return;\n  }\n\n  // Set ScopeTrackerScopeState if there's no existing crash context.\n  ScopeTrackedObjectStack encapsulated_object;\n  absl::optional<ScopeTrackerScopeState> state;\n  if (parent_.dispatcher_.trackedObjectStackIsEmpty()) {\n    restoreContextOnContinue(encapsulated_object);\n    state.emplace(&encapsulated_object, parent_.dispatcher_);\n  }\n\n  ENVOY_STREAM_LOG(trace, \"continuing filter chain: filter={}\", *this,\n                   static_cast<const void*>(this));\n  ASSERT(!canIterate(),\n         \"Attempting to continue iteration while the IterationState is already Continue\");\n  // If iteration has stopped for all frame types, set iterate_from_current_filter_ to true so the\n  // filter iteration starts with the current filter instead of the next one.\n  if (stoppedAll()) {\n    iterate_from_current_filter_ = true;\n  }\n  allowIteration();\n\n  // Only resume with do1xxHeaders() if we've actually seen 1xx headers.\n  if (has1xxHeaders()) {\n    continued_1xx_headers_ = true;\n    do1xxHeaders();\n    // If the response headers have not yet come in, don't continue on with\n    // headers and body. doHeaders expects request headers to exist.\n    if (!parent_.filter_manager_callbacks_.responseHeaders()) {\n      return;\n    }\n  }\n\n  // Make sure that we handle the zero byte data frame case. We make no effort to optimize this\n  // case in terms of merging it into a header only request/response. This could be done in the\n  // future.\n  if (!headers_continued_) {\n    headers_continued_ = true;\n    doHeaders(complete() && !bufferedData() && !hasTrailers());\n  }\n\n  doMetadata();\n\n  // It is possible for trailers to be added during doData(). doData() itself handles continuation\n  // of trailers for the non-continuation case. Thus, we must keep track of whether we had\n  // trailers prior to calling doData(). If we do, then we continue them here, otherwise we rely\n  // on doData() to do so.\n  const bool had_trailers_before_data = hasTrailers();\n  if (bufferedData()) {\n    doData(complete() && !had_trailers_before_data);\n  }\n\n  if (had_trailers_before_data) {\n    doTrailers();\n  }\n\n  iterate_from_current_filter_ = false;\n}\n\nbool ActiveStreamFilterBase::commonHandleAfter1xxHeadersCallback(FilterHeadersStatus status) {\n  ASSERT(parent_.state_.has_1xx_headers_);\n  ASSERT(!continued_1xx_headers_);\n  ASSERT(canIterate());\n\n  if (status == FilterHeadersStatus::StopIteration) {\n    iteration_state_ = IterationState::StopSingleIteration;\n    return false;\n  } else {\n    ASSERT(status == FilterHeadersStatus::Continue);\n    continued_1xx_headers_ = true;\n    return true;\n  }\n}\n\nbool ActiveStreamFilterBase::commonHandleAfterHeadersCallback(FilterHeadersStatus status,\n                                                              bool& end_stream) {\n  ASSERT(!headers_continued_);\n  ASSERT(canIterate());\n\n  switch (status) {\n  case FilterHeadersStatus::StopIteration:\n    iteration_state_ = IterationState::StopSingleIteration;\n    break;\n  case FilterHeadersStatus::StopAllIterationAndBuffer:\n    iteration_state_ = IterationState::StopAllBuffer;\n    break;\n  case FilterHeadersStatus::StopAllIterationAndWatermark:\n    iteration_state_ = IterationState::StopAllWatermark;\n    break;\n  case FilterHeadersStatus::ContinueAndDontEndStream:\n    end_stream = false;\n    headers_continued_ = true;\n    ENVOY_STREAM_LOG(debug, \"converting to headers and body (body not available yet)\", parent_);\n    break;\n  case FilterHeadersStatus::Continue:\n    headers_continued_ = true;\n    break;\n  }\n\n  handleMetadataAfterHeadersCallback();\n\n  if (stoppedAll() || status == FilterHeadersStatus::StopIteration) {\n    return false;\n  } else {\n    return true;\n  }\n}\n\nvoid ActiveStreamFilterBase::commonHandleBufferData(Buffer::Instance& provided_data) {\n\n  // The way we do buffering is a little complicated which is why we have this common function\n  // which is used for both encoding and decoding. When data first comes into our filter pipeline,\n  // we send it through. Any filter can choose to stop iteration and buffer or not. If we then\n  // continue iteration in the future, we use the buffered data. A future filter can stop and\n  // buffer again. In this case, since we are already operating on buffered data, we don't\n  // rebuffer, because we assume the filter has modified the buffer as it wishes in place.\n  if (bufferedData().get() != &provided_data) {\n    if (!bufferedData()) {\n      bufferedData() = createBuffer();\n    }\n    bufferedData()->move(provided_data);\n  }\n}\n\nbool ActiveStreamFilterBase::commonHandleAfterDataCallback(FilterDataStatus status,\n                                                           Buffer::Instance& provided_data,\n                                                           bool& buffer_was_streaming) {\n\n  if (status == FilterDataStatus::Continue) {\n    if (iteration_state_ == IterationState::StopSingleIteration) {\n      commonHandleBufferData(provided_data);\n      commonContinue();\n      return false;\n    } else {\n      ASSERT(headers_continued_);\n    }\n  } else {\n    iteration_state_ = IterationState::StopSingleIteration;\n    if (status == FilterDataStatus::StopIterationAndBuffer ||\n        status == FilterDataStatus::StopIterationAndWatermark) {\n      buffer_was_streaming = status == FilterDataStatus::StopIterationAndWatermark;\n      commonHandleBufferData(provided_data);\n    } else if (complete() && !hasTrailers() && !bufferedData() &&\n               // If the stream is destroyed, no need to handle the data buffer or trailers.\n               // This can occur if the filter calls sendLocalReply.\n               !parent_.state_.destroyed_) {\n      // If this filter is doing StopIterationNoBuffer and this stream is terminated with a zero\n      // byte data frame, we need to create an empty buffer to make sure that when commonContinue\n      // is called, the pipeline resumes with an empty data frame with end_stream = true\n      ASSERT(end_stream_);\n      bufferedData() = createBuffer();\n    }\n\n    return false;\n  }\n\n  return true;\n}\n\nbool ActiveStreamFilterBase::commonHandleAfterTrailersCallback(FilterTrailersStatus status) {\n\n  if (status == FilterTrailersStatus::Continue) {\n    if (iteration_state_ == IterationState::StopSingleIteration) {\n      commonContinue();\n      return false;\n    } else {\n      ASSERT(headers_continued_);\n    }\n  } else if (status == FilterTrailersStatus::StopIteration) {\n    if (canIterate()) {\n      iteration_state_ = IterationState::StopSingleIteration;\n    }\n    return false;\n  }\n\n  return true;\n}\n\nconst Network::Connection* ActiveStreamFilterBase::connection() { return parent_.connection(); }\n\nEvent::Dispatcher& ActiveStreamFilterBase::dispatcher() { return parent_.dispatcher_; }\n\nStreamInfo::StreamInfo& ActiveStreamFilterBase::streamInfo() { return parent_.stream_info_; }\n\nTracing::Span& ActiveStreamFilterBase::activeSpan() {\n  return parent_.filter_manager_callbacks_.activeSpan();\n}\n\nconst ScopeTrackedObject& ActiveStreamFilterBase::scope() {\n  return parent_.filter_manager_callbacks_.scope();\n}\n\nvoid ActiveStreamFilterBase::restoreContextOnContinue(\n    ScopeTrackedObjectStack& tracked_object_stack) {\n  parent_.contextOnContinue(tracked_object_stack);\n}\n\nTracing::Config& ActiveStreamFilterBase::tracingConfig() {\n  return parent_.filter_manager_callbacks_.tracingConfig();\n}\n\nUpstream::ClusterInfoConstSharedPtr ActiveStreamFilterBase::clusterInfo() {\n  return parent_.filter_manager_callbacks_.clusterInfo();\n}\n\nRouter::RouteConstSharedPtr ActiveStreamFilterBase::route() { return route(nullptr); }\n\nRouter::RouteConstSharedPtr ActiveStreamFilterBase::route(const Router::RouteCallback& cb) {\n  return parent_.filter_manager_callbacks_.route(cb);\n}\n\nvoid ActiveStreamFilterBase::setRoute(Router::RouteConstSharedPtr route) {\n  parent_.filter_manager_callbacks_.setRoute(std::move(route));\n}\n\nvoid ActiveStreamFilterBase::clearRouteCache() {\n  parent_.filter_manager_callbacks_.clearRouteCache();\n}\n\nvoid ActiveStreamFilterBase::resetIdleTimer() {\n  parent_.filter_manager_callbacks_.resetIdleTimer();\n}\n\nvoid FilterMatchState::evaluateMatchTreeWithNewData(MatchDataUpdateFunc update_func) {\n  if (match_tree_evaluated_ || !matching_data_) {\n    return;\n  }\n\n  update_func(*matching_data_);\n\n  const auto match_result = Matcher::evaluateMatch<HttpMatchingData>(*match_tree_, *matching_data_);\n\n  match_tree_evaluated_ = match_result.match_state_ == Matcher::MatchState::MatchComplete;\n\n  if (match_tree_evaluated_ && match_result.result_) {\n    const auto result = match_result.result_();\n    if (SkipAction().typeUrl() == result->typeUrl()) {\n      skip_filter_ = true;\n    } else {\n      filter_->onMatchCallback(*result);\n    }\n  }\n}\n\nbool ActiveStreamDecoderFilter::canContinue() {\n  // It is possible for the connection manager to respond directly to a request even while\n  // a filter is trying to continue. If a response has already happened, we should not\n  // continue to further filters. A concrete example of this is a filter buffering data, the\n  // last data frame comes in and the filter continues, but the final buffering takes the stream\n  // over the high watermark such that a 413 is returned.\n  return !parent_.state_.local_complete_;\n}\n\nbool ActiveStreamEncoderFilter::canContinue() {\n  // As with ActiveStreamDecoderFilter::canContinue() make sure we do not\n  // continue if a local reply has been sent.\n  return !parent_.state_.remote_encode_complete_;\n}\n\nBuffer::InstancePtr ActiveStreamDecoderFilter::createBuffer() {\n  auto buffer = dispatcher().getWatermarkFactory().createBuffer(\n      [this]() -> void { this->requestDataDrained(); },\n      [this]() -> void { this->requestDataTooLarge(); },\n      []() -> void { /* TODO(adisuissa): Handle overflow watermark */ });\n  buffer->setWatermarks(parent_.buffer_limit_);\n  return buffer;\n}\n\nBuffer::InstancePtr& ActiveStreamDecoderFilter::bufferedData() {\n  return parent_.buffered_request_data_;\n}\n\nbool ActiveStreamDecoderFilter::complete() { return parent_.state_.remote_decode_complete_; }\n\nvoid ActiveStreamDecoderFilter::doHeaders(bool end_stream) {\n  parent_.decodeHeaders(this, *parent_.filter_manager_callbacks_.requestHeaders(), end_stream);\n}\n\nvoid ActiveStreamDecoderFilter::doData(bool end_stream) {\n  parent_.decodeData(this, *parent_.buffered_request_data_, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\n\nvoid ActiveStreamDecoderFilter::doTrailers() {\n  parent_.decodeTrailers(this, *parent_.filter_manager_callbacks_.requestTrailers());\n}\nbool ActiveStreamDecoderFilter::hasTrailers() {\n  return parent_.filter_manager_callbacks_.requestTrailers().has_value();\n}\n\nvoid ActiveStreamDecoderFilter::drainSavedRequestMetadata() {\n  ASSERT(saved_request_metadata_ != nullptr);\n  for (auto& metadata_map : *getSavedRequestMetadata()) {\n    parent_.decodeMetadata(this, *metadata_map);\n  }\n  getSavedRequestMetadata()->clear();\n}\n\nvoid ActiveStreamDecoderFilter::handleMetadataAfterHeadersCallback() {\n  // If we drain accumulated metadata, the iteration must start with the current filter.\n  const bool saved_state = iterate_from_current_filter_;\n  iterate_from_current_filter_ = true;\n  // If decodeHeaders() returns StopAllIteration, we should skip draining metadata, and wait\n  // for doMetadata() to drain the metadata after iteration continues.\n  if (!stoppedAll() && saved_request_metadata_ != nullptr && !getSavedRequestMetadata()->empty()) {\n    drainSavedRequestMetadata();\n  }\n  // Restores the original value of iterate_from_current_filter_.\n  iterate_from_current_filter_ = saved_state;\n}\n\nRequestTrailerMap& ActiveStreamDecoderFilter::addDecodedTrailers() {\n  return parent_.addDecodedTrailers();\n}\n\nvoid ActiveStreamDecoderFilter::addDecodedData(Buffer::Instance& data, bool streaming) {\n  parent_.addDecodedData(*this, data, streaming);\n}\n\nMetadataMapVector& ActiveStreamDecoderFilter::addDecodedMetadata() {\n  return parent_.addDecodedMetadata();\n}\n\nvoid ActiveStreamDecoderFilter::injectDecodedDataToFilterChain(Buffer::Instance& data,\n                                                               bool end_stream) {\n  if (!headers_continued_) {\n    headers_continued_ = true;\n    doHeaders(false);\n  }\n  parent_.decodeData(this, data, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\n\nvoid ActiveStreamDecoderFilter::continueDecoding() { commonContinue(); }\nconst Buffer::Instance* ActiveStreamDecoderFilter::decodingBuffer() {\n  return parent_.buffered_request_data_.get();\n}\n\nvoid ActiveStreamDecoderFilter::modifyDecodingBuffer(\n    std::function<void(Buffer::Instance&)> callback) {\n  ASSERT(parent_.state_.latest_data_decoding_filter_ == this);\n  callback(*parent_.buffered_request_data_.get());\n}\n\nvoid ActiveStreamDecoderFilter::sendLocalReply(\n    Code code, absl::string_view body,\n    std::function<void(ResponseHeaderMap& headers)> modify_headers,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details) {\n  parent_.sendLocalReply(code, body, modify_headers, grpc_status, details);\n}\n\nvoid ActiveStreamDecoderFilter::encode1xxHeaders(ResponseHeaderMapPtr&& headers) {\n  // If Envoy is not configured to proxy 100-Continue responses, swallow the 100 Continue\n  // here. This avoids the potential situation where Envoy strips Expect: 100-Continue and sends a\n  // 100-Continue, then proxies a duplicate 100 Continue from upstream.\n  if (parent_.proxy_100_continue_) {\n    parent_.filter_manager_callbacks_.setInformationalHeaders(std::move(headers));\n    parent_.encode1xxHeaders(nullptr, *parent_.filter_manager_callbacks_.informationalHeaders());\n  }\n}\n\nResponseHeaderMapOptRef ActiveStreamDecoderFilter::informationalHeaders() const {\n  return parent_.filter_manager_callbacks_.informationalHeaders();\n}\n\nvoid ActiveStreamDecoderFilter::encodeHeaders(ResponseHeaderMapPtr&& headers, bool end_stream,\n                                              absl::string_view details) {\n  parent_.stream_info_.setResponseCodeDetails(details);\n  parent_.filter_manager_callbacks_.setResponseHeaders(std::move(headers));\n  parent_.encodeHeaders(nullptr, *parent_.filter_manager_callbacks_.responseHeaders(), end_stream);\n}\n\nResponseHeaderMapOptRef ActiveStreamDecoderFilter::responseHeaders() const {\n  return parent_.filter_manager_callbacks_.responseHeaders();\n}\n\nvoid ActiveStreamDecoderFilter::encodeData(Buffer::Instance& data, bool end_stream) {\n  parent_.encodeData(nullptr, data, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\n\nvoid ActiveStreamDecoderFilter::encodeTrailers(ResponseTrailerMapPtr&& trailers) {\n  parent_.filter_manager_callbacks_.setResponseTrailers(std::move(trailers));\n  parent_.encodeTrailers(nullptr, *parent_.filter_manager_callbacks_.responseTrailers());\n}\n\nResponseTrailerMapOptRef ActiveStreamDecoderFilter::responseTrailers() const {\n  return parent_.filter_manager_callbacks_.responseTrailers();\n}\n\nvoid ActiveStreamDecoderFilter::encodeMetadata(MetadataMapPtr&& metadata_map_ptr) {\n  parent_.encodeMetadata(nullptr, std::move(metadata_map_ptr));\n}\n\nvoid ActiveStreamDecoderFilter::onDecoderFilterAboveWriteBufferHighWatermark() {\n  parent_.filter_manager_callbacks_.onDecoderFilterAboveWriteBufferHighWatermark();\n}\n\nvoid ActiveStreamDecoderFilter::requestDataTooLarge() {\n  ENVOY_STREAM_LOG(debug, \"request data too large watermark exceeded\", parent_);\n  if (parent_.state_.decoder_filters_streaming_) {\n    onDecoderFilterAboveWriteBufferHighWatermark();\n  } else {\n    parent_.filter_manager_callbacks_.onRequestDataTooLarge();\n    sendLocalReply(Code::PayloadTooLarge, CodeUtility::toString(Code::PayloadTooLarge), nullptr,\n                   absl::nullopt, StreamInfo::ResponseCodeDetails::get().RequestPayloadTooLarge);\n  }\n}\n\nvoid FilterManager::addStreamDecoderFilterWorker(StreamDecoderFilterSharedPtr filter,\n                                                 FilterMatchStateSharedPtr match_state,\n                                                 bool dual_filter) {\n  ActiveStreamDecoderFilterPtr wrapper(\n      new ActiveStreamDecoderFilter(*this, filter, match_state, dual_filter));\n\n  // If we're a dual handling filter, have the encoding wrapper be the only thing registering itself\n  // as the handling filter.\n  if (match_state) {\n    match_state->filter_ = filter.get();\n  }\n\n  filter->setDecoderFilterCallbacks(*wrapper);\n  // Note: configured decoder filters are appended to decoder_filters_.\n  // This means that if filters are configured in the following order (assume all three filters are\n  // both decoder/encoder filters):\n  //   http_filters:\n  //     - A\n  //     - B\n  //     - C\n  // The decoder filter chain will iterate through filters A, B, C.\n  LinkedList::moveIntoListBack(std::move(wrapper), decoder_filters_);\n}\n\nvoid FilterManager::addStreamEncoderFilterWorker(StreamEncoderFilterSharedPtr filter,\n                                                 FilterMatchStateSharedPtr match_state,\n                                                 bool dual_filter) {\n  ActiveStreamEncoderFilterPtr wrapper(\n      new ActiveStreamEncoderFilter(*this, filter, match_state, dual_filter));\n\n  if (match_state) {\n    match_state->filter_ = filter.get();\n  }\n\n  filter->setEncoderFilterCallbacks(*wrapper);\n  // Note: configured encoder filters are prepended to encoder_filters_.\n  // This means that if filters are configured in the following order (assume all three filters are\n  // both decoder/encoder filters):\n  //   http_filters:\n  //     - A\n  //     - B\n  //     - C\n  // The encoder filter chain will iterate through filters C, B, A.\n  LinkedList::moveIntoList(std::move(wrapper), encoder_filters_);\n}\n\nvoid FilterManager::addAccessLogHandler(AccessLog::InstanceSharedPtr handler) {\n  access_log_handlers_.push_back(handler);\n}\n\nvoid FilterManager::maybeContinueDecoding(\n    const std::list<ActiveStreamDecoderFilterPtr>::iterator& continue_data_entry) {\n  if (continue_data_entry != decoder_filters_.end()) {\n    // We use the continueDecoding() code since it will correctly handle not calling\n    // decodeHeaders() again. Fake setting StopSingleIteration since the continueDecoding() code\n    // expects it.\n    ASSERT(buffered_request_data_);\n    (*continue_data_entry)->iteration_state_ =\n        ActiveStreamFilterBase::IterationState::StopSingleIteration;\n    (*continue_data_entry)->continueDecoding();\n  }\n}\n\nvoid FilterManager::decodeHeaders(ActiveStreamDecoderFilter* filter, RequestHeaderMap& headers,\n                                  bool end_stream) {\n  // Headers filter iteration should always start with the next filter if available.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator entry =\n      commonDecodePrefix(filter, FilterIterationStartState::AlwaysStartFromNext);\n  std::list<ActiveStreamDecoderFilterPtr>::iterator continue_data_entry = decoder_filters_.end();\n\n  for (; entry != decoder_filters_.end(); entry++) {\n    (*entry)->maybeEvaluateMatchTreeWithNewData(\n        [&](auto& matching_data) { matching_data.onRequestHeaders(headers); });\n\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::DecodeHeaders));\n    state_.filter_call_state_ |= FilterCallState::DecodeHeaders;\n    (*entry)->end_stream_ = (end_stream && continue_data_entry == decoder_filters_.end());\n    FilterHeadersStatus status = (*entry)->decodeHeaders(headers, (*entry)->end_stream_);\n    if (state_.decoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace,\n                       \"decodeHeaders filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      status = FilterHeadersStatus::StopIteration;\n    }\n\n    ASSERT(!(status == FilterHeadersStatus::ContinueAndDontEndStream && !(*entry)->end_stream_),\n           \"Filters should not return FilterHeadersStatus::ContinueAndDontEndStream from \"\n           \"decodeHeaders when end_stream is already false\");\n\n    state_.filter_call_state_ &= ~FilterCallState::DecodeHeaders;\n    ENVOY_STREAM_LOG(trace, \"decode headers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n\n    (*entry)->decode_headers_called_ = true;\n\n    const auto continue_iteration = (*entry)->commonHandleAfterHeadersCallback(status, end_stream);\n    ENVOY_BUG(!continue_iteration || !state_.local_complete_,\n              \"Filter did not return StopAll or StopIteration after sending a local reply.\");\n\n    // If this filter ended the stream, decodeComplete() should be called for it.\n    if ((*entry)->end_stream_) {\n      (*entry)->handle_->decodeComplete();\n    }\n\n    // Skip processing metadata after sending local reply\n    if (state_.local_complete_ && std::next(entry) != decoder_filters_.end()) {\n      maybeContinueDecoding(continue_data_entry);\n      return;\n    }\n\n    const bool new_metadata_added = processNewlyAddedMetadata();\n    // If end_stream is set in headers, and a filter adds new metadata, we need to delay end_stream\n    // in headers by inserting an empty data frame with end_stream set. The empty data frame is sent\n    // after the new metadata.\n    if ((*entry)->end_stream_ && new_metadata_added && !buffered_request_data_) {\n      Buffer::OwnedImpl empty_data(\"\");\n      ENVOY_STREAM_LOG(\n          trace, \"inserting an empty data frame for end_stream due metadata being added.\", *this);\n      // Metadata frame doesn't carry end of stream bit. We need an empty data frame to end the\n      // stream.\n      addDecodedData(*((*entry).get()), empty_data, true);\n    }\n\n    if (!continue_iteration && std::next(entry) != decoder_filters_.end()) {\n      // Stop iteration IFF this is not the last filter. If it is the last filter, continue with\n      // processing since we need to handle the case where a terminal filter wants to buffer, but\n      // a previous filter has added body.\n      maybeContinueDecoding(continue_data_entry);\n      return;\n    }\n\n    // Here we handle the case where we have a header only request, but a filter adds a body\n    // to it. We need to not raise end_stream = true to further filters during inline iteration.\n    if (end_stream && buffered_request_data_ && continue_data_entry == decoder_filters_.end()) {\n      continue_data_entry = entry;\n    }\n  }\n\n  maybeContinueDecoding(continue_data_entry);\n\n  if (end_stream) {\n    disarmRequestTimeout();\n  }\n}\n\nvoid FilterManager::decodeData(ActiveStreamDecoderFilter* filter, Buffer::Instance& data,\n                               bool end_stream,\n                               FilterIterationStartState filter_iteration_start_state) {\n  ScopeTrackerScopeState scope(&*this, dispatcher_);\n  filter_manager_callbacks_.resetIdleTimer();\n\n  const bool fix_added_trailers =\n      Runtime::runtimeFeatureEnabled(\"envoy.reloadable_features.fix_added_trailers\");\n\n  // If a response is complete or a reset has been sent, filters do not care about further body\n  // data. Just drop it.\n  if (state_.local_complete_) {\n    return;\n  }\n\n  auto trailers_added_entry = decoder_filters_.end();\n  const bool trailers_exists_at_start = filter_manager_callbacks_.requestTrailers().has_value();\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator entry =\n      commonDecodePrefix(filter, filter_iteration_start_state);\n\n  for (; entry != decoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    // If the filter pointed by entry has stopped for all frame types, return now.\n    if (handleDataIfStopAll(**entry, data, state_.decoder_filters_streaming_)) {\n      return;\n    }\n    // If end_stream_ is marked for a filter, the data is not for this filter and filters after.\n    //\n    // In following case, ActiveStreamFilterBase::commonContinue() could be called recursively and\n    // its doData() is called with wrong data.\n    //\n    //  There are 3 decode filters and \"wrapper\" refers to ActiveStreamFilter object.\n    //\n    //  filter0->decodeHeaders(_, true)\n    //    return STOP\n    //  filter0->continueDecoding()\n    //    wrapper0->commonContinue()\n    //      wrapper0->decodeHeaders(_, _, true)\n    //        filter1->decodeHeaders(_, true)\n    //          filter1->addDecodeData()\n    //          return CONTINUE\n    //        filter2->decodeHeaders(_, false)\n    //          return CONTINUE\n    //        wrapper1->commonContinue() // Detects data is added.\n    //          wrapper1->doData()\n    //            wrapper1->decodeData()\n    //              filter2->decodeData(_, true)\n    //                 return CONTINUE\n    //      wrapper0->doData() // This should not be called\n    //        wrapper0->decodeData()\n    //          filter1->decodeData(_, true)  // It will cause assertions.\n    //\n    // One way to solve this problem is to mark end_stream_ for each filter.\n    // If a filter is already marked as end_stream_ when decodeData() is called, bails out the\n    // whole function. If just skip the filter, the codes after the loop will be called with\n    // wrong data. For encodeData, the response_encoder->encode() will be called.\n    if ((*entry)->end_stream_) {\n      return;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::DecodeData));\n\n    // We check the request_trailers_ pointer here in case addDecodedTrailers\n    // is called in decodeData during a previous filter invocation, at which point we communicate to\n    // the current and future filters that the stream has not yet ended.\n    if (end_stream) {\n      state_.filter_call_state_ |= FilterCallState::LastDataFrame;\n    }\n\n    recordLatestDataFilter(entry, state_.latest_data_decoding_filter_, decoder_filters_);\n\n    state_.filter_call_state_ |= FilterCallState::DecodeData;\n    (*entry)->end_stream_ = end_stream && !filter_manager_callbacks_.requestTrailers();\n    FilterDataStatus status = (*entry)->handle_->decodeData(data, (*entry)->end_stream_);\n    if ((*entry)->end_stream_) {\n      (*entry)->handle_->decodeComplete();\n    }\n    state_.filter_call_state_ &= ~FilterCallState::DecodeData;\n    if (end_stream) {\n      state_.filter_call_state_ &= ~FilterCallState::LastDataFrame;\n    }\n    ENVOY_STREAM_LOG(trace, \"decode data called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n    if (state_.decoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace, \"decodeData filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      return;\n    }\n\n    processNewlyAddedMetadata();\n\n    if (!trailers_exists_at_start && filter_manager_callbacks_.requestTrailers() &&\n        trailers_added_entry == decoder_filters_.end()) {\n      if (fix_added_trailers) {\n        end_stream = false;\n      }\n      trailers_added_entry = entry;\n    }\n\n    if (!(*entry)->commonHandleAfterDataCallback(status, data, state_.decoder_filters_streaming_) &&\n        std::next(entry) != decoder_filters_.end()) {\n      // Stop iteration IFF this is not the last filter. If it is the last filter, continue with\n      // processing since we need to handle the case where a terminal filter wants to buffer, but\n      // a previous filter has added trailers.\n      if (fix_added_trailers) {\n        break;\n      } else {\n        return;\n      }\n    }\n  }\n\n  // If trailers were adding during decodeData we need to trigger decodeTrailers in order\n  // to allow filters to process the trailers.\n  if (trailers_added_entry != decoder_filters_.end()) {\n    decodeTrailers(trailers_added_entry->get(), *filter_manager_callbacks_.requestTrailers());\n  }\n\n  if (end_stream) {\n    disarmRequestTimeout();\n  }\n}\n\nRequestTrailerMap& FilterManager::addDecodedTrailers() {\n  // Trailers can only be added during the last data frame (i.e. end_stream = true).\n  ASSERT(state_.filter_call_state_ & FilterCallState::LastDataFrame);\n\n  filter_manager_callbacks_.setRequestTrailers(RequestTrailerMapImpl::create());\n  return *filter_manager_callbacks_.requestTrailers();\n}\n\nvoid FilterManager::addDecodedData(ActiveStreamDecoderFilter& filter, Buffer::Instance& data,\n                                   bool streaming) {\n  if (state_.filter_call_state_ == 0 ||\n      (state_.filter_call_state_ & FilterCallState::DecodeHeaders) ||\n      (state_.filter_call_state_ & FilterCallState::DecodeData) ||\n      ((state_.filter_call_state_ & FilterCallState::DecodeTrailers) && !filter.canIterate())) {\n    // Make sure if this triggers watermarks, the correct action is taken.\n    state_.decoder_filters_streaming_ = streaming;\n    // If no call is happening or we are in the decode headers/data callback, buffer the data.\n    // Inline processing happens in the decodeHeaders() callback if necessary.\n    filter.commonHandleBufferData(data);\n  } else if (state_.filter_call_state_ & FilterCallState::DecodeTrailers) {\n    // In this case we need to inline dispatch the data to further filters. If those filters\n    // choose to buffer/stop iteration that's fine.\n    decodeData(&filter, data, false, FilterIterationStartState::AlwaysStartFromNext);\n  } else {\n    IS_ENVOY_BUG(\"Invalid request data\");\n    sendLocalReply(Http::Code::BadGateway, \"Filter error\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().FilterAddedInvalidRequestData);\n  }\n}\n\nMetadataMapVector& FilterManager::addDecodedMetadata() { return *getRequestMetadataMapVector(); }\n\nvoid FilterManager::decodeTrailers(ActiveStreamDecoderFilter* filter, RequestTrailerMap& trailers) {\n  // See decodeData() above for why we check local_complete_ here.\n  if (state_.local_complete_) {\n    return;\n  }\n\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator entry =\n      commonDecodePrefix(filter, FilterIterationStartState::CanStartFromCurrent);\n\n  for (; entry != decoder_filters_.end(); entry++) {\n    (*entry)->maybeEvaluateMatchTreeWithNewData(\n        [&](auto& matching_data) { matching_data.onRequestTrailers(trailers); });\n\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n\n    // If the filter pointed by entry has stopped for all frame type, return now.\n    if ((*entry)->stoppedAll()) {\n      return;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::DecodeTrailers));\n    state_.filter_call_state_ |= FilterCallState::DecodeTrailers;\n    FilterTrailersStatus status = (*entry)->handle_->decodeTrailers(trailers);\n    (*entry)->handle_->decodeComplete();\n    (*entry)->end_stream_ = true;\n    state_.filter_call_state_ &= ~FilterCallState::DecodeTrailers;\n    ENVOY_STREAM_LOG(trace, \"decode trailers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n    if (state_.decoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace,\n                       \"decodeTrailers filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      status = FilterTrailersStatus::StopIteration;\n    }\n\n    processNewlyAddedMetadata();\n\n    if (!(*entry)->commonHandleAfterTrailersCallback(status)) {\n      return;\n    }\n  }\n  disarmRequestTimeout();\n}\n\nvoid FilterManager::decodeMetadata(ActiveStreamDecoderFilter* filter, MetadataMap& metadata_map) {\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator entry =\n      commonDecodePrefix(filter, FilterIterationStartState::CanStartFromCurrent);\n\n  for (; entry != decoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    // If the filter pointed by entry has stopped for all frame type, stores metadata and returns.\n    // If the filter pointed by entry hasn't returned from decodeHeaders, stores newly added\n    // metadata in case decodeHeaders returns StopAllIteration. The latter can happen when headers\n    // callbacks generate new metadata.\n    if (!(*entry)->decode_headers_called_ || (*entry)->stoppedAll()) {\n      Http::MetadataMapPtr metadata_map_ptr = std::make_unique<Http::MetadataMap>(metadata_map);\n      (*entry)->getSavedRequestMetadata()->emplace_back(std::move(metadata_map_ptr));\n      return;\n    }\n\n    FilterMetadataStatus status = (*entry)->handle_->decodeMetadata(metadata_map);\n    ENVOY_STREAM_LOG(trace, \"decode metadata called: filter={} status={}, metadata: {}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status),\n                     metadata_map);\n  }\n}\n\nvoid FilterManager::maybeEndDecode(bool end_stream) {\n  ASSERT(!state_.remote_decode_complete_);\n  state_.remote_decode_complete_ = end_stream;\n  if (end_stream) {\n    stream_info_.downstreamTiming().onLastDownstreamRxByteReceived(dispatcher().timeSource());\n    ENVOY_STREAM_LOG(debug, \"request end stream\", *this);\n  }\n}\n\nvoid FilterManager::disarmRequestTimeout() { filter_manager_callbacks_.disarmRequestTimeout(); }\n\nstd::list<ActiveStreamEncoderFilterPtr>::iterator\nFilterManager::commonEncodePrefix(ActiveStreamEncoderFilter* filter, bool end_stream,\n                                  FilterIterationStartState filter_iteration_start_state) {\n  // Only do base state setting on the initial call. Subsequent calls for filtering do not touch\n  // the base state.\n  if (filter == nullptr) {\n    ASSERT(!state_.local_complete_);\n    state_.local_complete_ = end_stream;\n    return encoder_filters_.begin();\n  }\n\n  if (filter_iteration_start_state == FilterIterationStartState::CanStartFromCurrent &&\n      (*(filter->entry()))->iterate_from_current_filter_) {\n    // The filter iteration has been stopped for all frame types, and now the iteration continues.\n    // The current filter's encoding callback has not be called. Call it now.\n    return filter->entry();\n  }\n  return std::next(filter->entry());\n}\n\nstd::list<ActiveStreamDecoderFilterPtr>::iterator\nFilterManager::commonDecodePrefix(ActiveStreamDecoderFilter* filter,\n                                  FilterIterationStartState filter_iteration_start_state) {\n  if (!filter) {\n    return decoder_filters_.begin();\n  }\n  if (filter_iteration_start_state == FilterIterationStartState::CanStartFromCurrent &&\n      (*(filter->entry()))->iterate_from_current_filter_) {\n    // The filter iteration has been stopped for all frame types, and now the iteration continues.\n    // The current filter's callback function has not been called. Call it now.\n    return filter->entry();\n  }\n  return std::next(filter->entry());\n}\n\nvoid FilterManager::onLocalReply(StreamFilterBase::LocalReplyData& data) {\n  state_.under_on_local_reply_ = true;\n  filter_manager_callbacks_.onLocalReply(data.code_);\n\n  for (auto entry : filters_) {\n    if (entry->onLocalReply(data) == LocalErrorStatus::ContinueAndResetStream) {\n      data.reset_imminent_ = true;\n    }\n  }\n  state_.under_on_local_reply_ = false;\n}\n\nvoid FilterManager::sendLocalReply(\n    Code code, absl::string_view body,\n    const std::function<void(ResponseHeaderMap& headers)>& modify_headers,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details) {\n  ASSERT(!state_.under_on_local_reply_);\n  const bool is_head_request = state_.is_head_request_;\n  const bool is_grpc_request = state_.is_grpc_request_;\n\n  // Stop filter chain iteration if local reply was sent while filter decoding or encoding callbacks\n  // are running.\n  if (state_.filter_call_state_ & (FilterCallState::DecodeHeaders | FilterCallState::DecodeData |\n                                   FilterCallState::DecodeTrailers)) {\n    state_.decoder_filter_chain_aborted_ = true;\n  } else if (state_.filter_call_state_ &\n             (FilterCallState::EncodeHeaders | FilterCallState::EncodeData |\n              FilterCallState::EncodeTrailers)) {\n    state_.encoder_filter_chain_aborted_ = true;\n  }\n\n  stream_info_.setResponseCodeDetails(details);\n  StreamFilterBase::LocalReplyData data{code, details, false};\n  FilterManager::onLocalReply(data);\n  if (data.reset_imminent_) {\n    ENVOY_STREAM_LOG(debug, \"Resetting stream due to {}. onLocalReply requested reset.\", *this,\n                     details);\n    filter_manager_callbacks_.resetStream();\n    return;\n  }\n\n  if (!filter_manager_callbacks_.responseHeaders().has_value()) {\n    // If the response has not started at all, send the response through the filter chain.\n    sendLocalReplyViaFilterChain(is_grpc_request, code, body, modify_headers, is_head_request,\n                                 grpc_status, details);\n  } else if (!state_.non_100_response_headers_encoded_) {\n    ENVOY_STREAM_LOG(debug, \"Sending local reply with details {} directly to the encoder\", *this,\n                     details);\n    // In this case, at least the header and possibly the body has started\n    // processing through the filter chain, but no non-informational headers\n    // have been sent downstream. To ensure that filters don't get their\n    // state machine screwed up, bypass the filter chain and send the local\n    // reply directly to the codec.\n    //\n    sendDirectLocalReply(code, body, modify_headers, state_.is_head_request_, grpc_status);\n  } else {\n    // If we land in this branch, response headers have already been sent to the client.\n    // All we can do at this point is reset the stream.\n    ENVOY_STREAM_LOG(debug, \"Resetting stream due to {}. Prior headers have already been sent\",\n                     *this, details);\n    // TODO(snowp): This means we increment the tx_reset stat which we weren't doing previously.\n    // Intended?\n    filter_manager_callbacks_.resetStream();\n  }\n}\n\nvoid FilterManager::sendLocalReplyViaFilterChain(\n    bool is_grpc_request, Code code, absl::string_view body,\n    const std::function<void(ResponseHeaderMap& headers)>& modify_headers, bool is_head_request,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details) {\n  ENVOY_STREAM_LOG(debug, \"Sending local reply with details {}\", *this, details);\n  ASSERT(!filter_manager_callbacks_.responseHeaders().has_value());\n  // For early error handling, do a best-effort attempt to create a filter chain\n  // to ensure access logging. If the filter chain already exists this will be\n  // a no-op.\n  createFilterChain();\n\n  Utility::sendLocalReply(\n      state_.destroyed_,\n      Utility::EncodeFunctions{\n          [this, modify_headers](ResponseHeaderMap& headers) -> void {\n            if (streamInfo().route() && streamInfo().route()->routeEntry()) {\n              streamInfo().route()->routeEntry()->finalizeResponseHeaders(headers, streamInfo());\n            }\n            if (modify_headers) {\n              modify_headers(headers);\n            }\n          },\n          [this](ResponseHeaderMap& response_headers, Code& code, std::string& body,\n                 absl::string_view& content_type) -> void {\n            // TODO(snowp): This &get() business isn't nice, rework LocalReply and others to accept\n            // opt refs.\n            local_reply_.rewrite(filter_manager_callbacks_.requestHeaders().ptr(), response_headers,\n                                 stream_info_, code, body, content_type);\n          },\n          [this, modify_headers](ResponseHeaderMapPtr&& headers, bool end_stream) -> void {\n            filter_manager_callbacks_.setResponseHeaders(std::move(headers));\n            // TODO: Start encoding from the last decoder filter that saw the\n            // request instead.\n            encodeHeaders(nullptr, filter_manager_callbacks_.responseHeaders().ref(), end_stream);\n          },\n          [this](Buffer::Instance& data, bool end_stream) -> void {\n            // TODO: Start encoding from the last decoder filter that saw the\n            // request instead.\n            encodeData(nullptr, data, end_stream,\n                       FilterManager::FilterIterationStartState::CanStartFromCurrent);\n          }},\n      Utility::LocalReplyData{is_grpc_request, code, body, grpc_status, is_head_request});\n}\n\nvoid FilterManager::sendDirectLocalReply(\n    Code code, absl::string_view body,\n    const std::function<void(ResponseHeaderMap&)>& modify_headers, bool is_head_request,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status) {\n  // Make sure we won't end up with nested watermark calls from the body buffer.\n  state_.encoder_filters_streaming_ = true;\n  Http::Utility::sendLocalReply(\n      state_.destroyed_,\n      Utility::EncodeFunctions{\n          [this, modify_headers](ResponseHeaderMap& headers) -> void {\n            if (streamInfo().route() && streamInfo().route()->routeEntry()) {\n              streamInfo().route()->routeEntry()->finalizeResponseHeaders(headers, streamInfo());\n            }\n            if (modify_headers) {\n              modify_headers(headers);\n            }\n          },\n          [&](ResponseHeaderMap& response_headers, Code& code, std::string& body,\n              absl::string_view& content_type) -> void {\n            local_reply_.rewrite(filter_manager_callbacks_.requestHeaders().ptr(), response_headers,\n                                 stream_info_, code, body, content_type);\n          },\n          [&](ResponseHeaderMapPtr&& response_headers, bool end_stream) -> void {\n            // Move the response headers into the FilterManager to make sure they're visible to\n            // access logs.\n            filter_manager_callbacks_.setResponseHeaders(std::move(response_headers));\n\n            state_.non_100_response_headers_encoded_ = true;\n            filter_manager_callbacks_.encodeHeaders(*filter_manager_callbacks_.responseHeaders(),\n                                                    end_stream);\n            if (state_.saw_downstream_reset_) {\n              return;\n            }\n            maybeEndEncode(end_stream);\n          },\n          [&](Buffer::Instance& data, bool end_stream) -> void {\n            filter_manager_callbacks_.encodeData(data, end_stream);\n            if (state_.saw_downstream_reset_) {\n              return;\n            }\n            maybeEndEncode(end_stream);\n          }},\n      Utility::LocalReplyData{state_.is_grpc_request_, code, body, grpc_status, is_head_request});\n}\n\nvoid FilterManager::encode1xxHeaders(ActiveStreamEncoderFilter* filter,\n                                     ResponseHeaderMap& headers) {\n  filter_manager_callbacks_.resetIdleTimer();\n  ASSERT(proxy_100_continue_);\n  // The caller must guarantee that encode1xxHeaders() is invoked at most once.\n  ASSERT(!state_.has_1xx_headers_ || filter != nullptr);\n  // Make sure commonContinue continues encode1xxHeaders.\n  state_.has_1xx_headers_ = true;\n\n  // Similar to the block in encodeHeaders, run encode1xxHeaders on each\n  // filter. This is simpler than that case because 100 continue implies no\n  // end-stream, and because there are normal headers coming there's no need for\n  // complex continuation logic.\n  // 100-continue filter iteration should always start with the next filter if available.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, false, FilterIterationStartState::AlwaysStartFromNext);\n  for (; entry != encoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::Encode1xxHeaders));\n    state_.filter_call_state_ |= FilterCallState::Encode1xxHeaders;\n    FilterHeadersStatus status = (*entry)->handle_->encode1xxHeaders(headers);\n    state_.filter_call_state_ &= ~FilterCallState::Encode1xxHeaders;\n    ENVOY_STREAM_LOG(trace, \"encode 1xx continue headers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n    if (!(*entry)->commonHandleAfter1xxHeadersCallback(status)) {\n      return;\n    }\n  }\n\n  filter_manager_callbacks_.encode1xxHeaders(headers);\n}\n\nvoid FilterManager::maybeContinueEncoding(\n    const std::list<ActiveStreamEncoderFilterPtr>::iterator& continue_data_entry) {\n  if (continue_data_entry != encoder_filters_.end()) {\n    // We use the continueEncoding() code since it will correctly handle not calling\n    // encodeHeaders() again. Fake setting StopSingleIteration since the continueEncoding() code\n    // expects it.\n    ASSERT(buffered_response_data_);\n    (*continue_data_entry)->iteration_state_ =\n        ActiveStreamFilterBase::IterationState::StopSingleIteration;\n    (*continue_data_entry)->continueEncoding();\n  }\n}\n\nvoid FilterManager::encodeHeaders(ActiveStreamEncoderFilter* filter, ResponseHeaderMap& headers,\n                                  bool end_stream) {\n  // See encodeHeaders() comments in include/envoy/http/filter.h for why the 1xx precondition holds.\n  ASSERT(!CodeUtility::is1xx(Utility::getResponseStatus(headers)) ||\n         Utility::getResponseStatus(headers) == enumToInt(Http::Code::SwitchingProtocols));\n  filter_manager_callbacks_.resetIdleTimer();\n  disarmRequestTimeout();\n\n  // Headers filter iteration should always start with the next filter if available.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, end_stream, FilterIterationStartState::AlwaysStartFromNext);\n  std::list<ActiveStreamEncoderFilterPtr>::iterator continue_data_entry = encoder_filters_.end();\n\n  for (; entry != encoder_filters_.end(); entry++) {\n    (*entry)->maybeEvaluateMatchTreeWithNewData(\n        [&headers](auto& matching_data) { matching_data.onResponseHeaders(headers); });\n\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::EncodeHeaders));\n    state_.filter_call_state_ |= FilterCallState::EncodeHeaders;\n    (*entry)->end_stream_ = (end_stream && continue_data_entry == encoder_filters_.end());\n    FilterHeadersStatus status = (*entry)->handle_->encodeHeaders(headers, (*entry)->end_stream_);\n    if (state_.encoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace,\n                       \"encodeHeaders filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      status = FilterHeadersStatus::StopIteration;\n    }\n\n    ASSERT(!(status == FilterHeadersStatus::ContinueAndDontEndStream && !(*entry)->end_stream_),\n           \"Filters should not return FilterHeadersStatus::ContinueAndDontEndStream from \"\n           \"encodeHeaders when end_stream is already false\");\n\n    state_.filter_call_state_ &= ~FilterCallState::EncodeHeaders;\n    ENVOY_STREAM_LOG(trace, \"encode headers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n\n    (*entry)->encode_headers_called_ = true;\n\n    const auto continue_iteration = (*entry)->commonHandleAfterHeadersCallback(status, end_stream);\n\n    // If this filter ended the stream, encodeComplete() should be called for it.\n    if ((*entry)->end_stream_) {\n      (*entry)->handle_->encodeComplete();\n    }\n\n    if (!continue_iteration) {\n      if (!(*entry)->end_stream_) {\n        maybeContinueEncoding(continue_data_entry);\n      }\n      return;\n    }\n\n    // Here we handle the case where we have a header only response, but a filter adds a body\n    // to it. We need to not raise end_stream = true to further filters during inline iteration.\n    if (end_stream && buffered_response_data_ && continue_data_entry == encoder_filters_.end()) {\n      continue_data_entry = entry;\n    }\n  }\n\n  // Check if the filter chain above did not remove critical headers or set malformed header values.\n  // We could do this at the codec in order to prevent other places than the filter chain from\n  // removing critical headers, but it will come with the implementation complexity.\n  // See the previous attempt (#15658) for detail, and for now we choose to protect only against\n  // filter chains.\n  const auto status = HeaderUtility::checkRequiredResponseHeaders(headers);\n  if (!status.ok()) {\n    // If the check failed, then we reply with BadGateway, and stop the further processing.\n    sendLocalReply(\n        Http::Code::BadGateway, status.message(), nullptr, absl::nullopt,\n        absl::StrCat(StreamInfo::ResponseCodeDetails::get().FilterRemovedRequiredResponseHeaders,\n                     \"{\", StringUtil::replaceAllEmptySpace(status.message()), \"}\"));\n    return;\n  }\n\n  const bool modified_end_stream = (end_stream && continue_data_entry == encoder_filters_.end());\n  state_.non_100_response_headers_encoded_ = true;\n  filter_manager_callbacks_.encodeHeaders(headers, modified_end_stream);\n  if (state_.saw_downstream_reset_) {\n    return;\n  }\n  maybeEndEncode(modified_end_stream);\n\n  if (!modified_end_stream) {\n    maybeContinueEncoding(continue_data_entry);\n  }\n}\n\nvoid FilterManager::encodeMetadata(ActiveStreamEncoderFilter* filter,\n                                   MetadataMapPtr&& metadata_map_ptr) {\n  filter_manager_callbacks_.resetIdleTimer();\n\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, false, FilterIterationStartState::CanStartFromCurrent);\n\n  for (; entry != encoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    // If the filter pointed by entry has stopped for all frame type, stores metadata and returns.\n    // If the filter pointed by entry hasn't returned from encodeHeaders, stores newly added\n    // metadata in case encodeHeaders returns StopAllIteration. The latter can happen when headers\n    // callbacks generate new metadata.\n    if (!(*entry)->encode_headers_called_ || (*entry)->stoppedAll()) {\n      (*entry)->getSavedResponseMetadata()->emplace_back(std::move(metadata_map_ptr));\n      return;\n    }\n\n    FilterMetadataStatus status = (*entry)->handle_->encodeMetadata(*metadata_map_ptr);\n    ENVOY_STREAM_LOG(trace, \"encode metadata called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n  }\n  // TODO(soya3129): update stats with metadata.\n\n  // Now encode metadata via the codec.\n  if (!metadata_map_ptr->empty()) {\n    MetadataMapVector metadata_map_vector;\n    metadata_map_vector.emplace_back(std::move(metadata_map_ptr));\n    filter_manager_callbacks_.encodeMetadata(metadata_map_vector);\n  }\n}\n\nResponseTrailerMap& FilterManager::addEncodedTrailers() {\n  // Trailers can only be added during the last data frame (i.e. end_stream = true).\n  ASSERT(state_.filter_call_state_ & FilterCallState::LastDataFrame);\n\n  // Trailers can only be added once.\n  ASSERT(!filter_manager_callbacks_.responseTrailers());\n\n  filter_manager_callbacks_.setResponseTrailers(ResponseTrailerMapImpl::create());\n  return *filter_manager_callbacks_.responseTrailers();\n}\n\nvoid FilterManager::addEncodedData(ActiveStreamEncoderFilter& filter, Buffer::Instance& data,\n                                   bool streaming) {\n  if (state_.filter_call_state_ == 0 ||\n      (state_.filter_call_state_ & FilterCallState::EncodeHeaders) ||\n      (state_.filter_call_state_ & FilterCallState::EncodeData) ||\n      ((state_.filter_call_state_ & FilterCallState::EncodeTrailers) && !filter.canIterate())) {\n    // Make sure if this triggers watermarks, the correct action is taken.\n    state_.encoder_filters_streaming_ = streaming;\n    // If no call is happening or we are in the decode headers/data callback, buffer the data.\n    // Inline processing happens in the decodeHeaders() callback if necessary.\n    filter.commonHandleBufferData(data);\n  } else if (state_.filter_call_state_ & FilterCallState::EncodeTrailers) {\n    // In this case we need to inline dispatch the data to further filters. If those filters\n    // choose to buffer/stop iteration that's fine.\n    encodeData(&filter, data, false, FilterIterationStartState::AlwaysStartFromNext);\n  } else {\n    IS_ENVOY_BUG(\"Invalid response data\");\n    sendLocalReply(Http::Code::BadGateway, \"Filter error\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().FilterAddedInvalidResponseData);\n  }\n}\n\nvoid FilterManager::encodeData(ActiveStreamEncoderFilter* filter, Buffer::Instance& data,\n                               bool end_stream,\n                               FilterIterationStartState filter_iteration_start_state) {\n  filter_manager_callbacks_.resetIdleTimer();\n\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, end_stream, filter_iteration_start_state);\n  auto trailers_added_entry = encoder_filters_.end();\n\n  const bool trailers_exists_at_start = filter_manager_callbacks_.responseTrailers().has_value();\n  for (; entry != encoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    // If the filter pointed by entry has stopped for all frame type, return now.\n    if (handleDataIfStopAll(**entry, data, state_.encoder_filters_streaming_)) {\n      return;\n    }\n    // If end_stream_ is marked for a filter, the data is not for this filter and filters after.\n    // For details, please see the comment in the ActiveStream::decodeData() function.\n    if ((*entry)->end_stream_) {\n      return;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::EncodeData));\n\n    // We check the response_trailers_ pointer here in case addEncodedTrailers\n    // is called in encodeData during a previous filter invocation, at which point we communicate to\n    // the current and future filters that the stream has not yet ended.\n    state_.filter_call_state_ |= FilterCallState::EncodeData;\n    if (end_stream) {\n      state_.filter_call_state_ |= FilterCallState::LastDataFrame;\n    }\n\n    recordLatestDataFilter(entry, state_.latest_data_encoding_filter_, encoder_filters_);\n\n    (*entry)->end_stream_ = end_stream && !filter_manager_callbacks_.responseTrailers();\n    FilterDataStatus status = (*entry)->handle_->encodeData(data, (*entry)->end_stream_);\n    if (state_.encoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace, \"encodeData filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      status = FilterDataStatus::StopIterationNoBuffer;\n    }\n    if ((*entry)->end_stream_) {\n      (*entry)->handle_->encodeComplete();\n    }\n    state_.filter_call_state_ &= ~FilterCallState::EncodeData;\n    if (end_stream) {\n      state_.filter_call_state_ &= ~FilterCallState::LastDataFrame;\n    }\n    ENVOY_STREAM_LOG(trace, \"encode data called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n\n    if (!trailers_exists_at_start && filter_manager_callbacks_.responseTrailers() &&\n        trailers_added_entry == encoder_filters_.end()) {\n      trailers_added_entry = entry;\n    }\n\n    if (!(*entry)->commonHandleAfterDataCallback(status, data, state_.encoder_filters_streaming_)) {\n      return;\n    }\n  }\n\n  const bool modified_end_stream = end_stream && trailers_added_entry == encoder_filters_.end();\n  filter_manager_callbacks_.encodeData(data, modified_end_stream);\n  if (state_.saw_downstream_reset_) {\n    return;\n  }\n  maybeEndEncode(modified_end_stream);\n\n  // If trailers were adding during encodeData we need to trigger decodeTrailers in order\n  // to allow filters to process the trailers.\n  if (trailers_added_entry != encoder_filters_.end()) {\n    encodeTrailers(trailers_added_entry->get(), *filter_manager_callbacks_.responseTrailers());\n  }\n}\n\nvoid FilterManager::encodeTrailers(ActiveStreamEncoderFilter* filter,\n                                   ResponseTrailerMap& trailers) {\n  filter_manager_callbacks_.resetIdleTimer();\n\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, true, FilterIterationStartState::CanStartFromCurrent);\n  for (; entry != encoder_filters_.end(); entry++) {\n    (*entry)->maybeEvaluateMatchTreeWithNewData(\n        [&](auto& matching_data) { matching_data.onResponseTrailers(trailers); });\n\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n\n    // If the filter pointed by entry has stopped for all frame type, return now.\n    if ((*entry)->stoppedAll()) {\n      return;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::EncodeTrailers));\n    state_.filter_call_state_ |= FilterCallState::EncodeTrailers;\n    FilterTrailersStatus status = (*entry)->handle_->encodeTrailers(trailers);\n    (*entry)->handle_->encodeComplete();\n    (*entry)->end_stream_ = true;\n    state_.filter_call_state_ &= ~FilterCallState::EncodeTrailers;\n    ENVOY_STREAM_LOG(trace, \"encode trailers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n    if (!(*entry)->commonHandleAfterTrailersCallback(status)) {\n      return;\n    }\n  }\n\n  filter_manager_callbacks_.encodeTrailers(trailers);\n  if (state_.saw_downstream_reset_) {\n    return;\n  }\n  maybeEndEncode(true);\n}\n\nvoid FilterManager::maybeEndEncode(bool end_stream) {\n  if (end_stream) {\n    ASSERT(!state_.remote_encode_complete_);\n    state_.remote_encode_complete_ = true;\n    filter_manager_callbacks_.endStream();\n  }\n}\n\nbool FilterManager::processNewlyAddedMetadata() {\n  if (request_metadata_map_vector_ == nullptr) {\n    return false;\n  }\n  for (const auto& metadata_map : *getRequestMetadataMapVector()) {\n    decodeMetadata(nullptr, *metadata_map);\n  }\n  getRequestMetadataMapVector()->clear();\n  return true;\n}\n\nbool FilterManager::handleDataIfStopAll(ActiveStreamFilterBase& filter, Buffer::Instance& data,\n                                        bool& filter_streaming) {\n  if (filter.stoppedAll()) {\n    ASSERT(!filter.canIterate());\n    filter_streaming =\n        filter.iteration_state_ == ActiveStreamFilterBase::IterationState::StopAllWatermark;\n    filter.commonHandleBufferData(data);\n    return true;\n  }\n  return false;\n}\n\nvoid FilterManager::callHighWatermarkCallbacks() {\n  ++high_watermark_count_;\n  for (auto watermark_callbacks : watermark_callbacks_) {\n    watermark_callbacks->onAboveWriteBufferHighWatermark();\n  }\n}\n\nvoid FilterManager::callLowWatermarkCallbacks() {\n  ASSERT(high_watermark_count_ > 0);\n  --high_watermark_count_;\n  for (auto watermark_callbacks : watermark_callbacks_) {\n    watermark_callbacks->onBelowWriteBufferLowWatermark();\n  }\n}\n\nvoid FilterManager::setBufferLimit(uint32_t new_limit) {\n  ENVOY_STREAM_LOG(debug, \"setting buffer limit to {}\", *this, new_limit);\n  buffer_limit_ = new_limit;\n  if (buffered_request_data_) {\n    buffered_request_data_->setWatermarks(buffer_limit_);\n  }\n  if (buffered_response_data_) {\n    buffered_response_data_->setWatermarks(buffer_limit_);\n  }\n}\n\nvoid FilterManager::contextOnContinue(ScopeTrackedObjectStack& tracked_object_stack) {\n  tracked_object_stack.add(connection_);\n  tracked_object_stack.add(filter_manager_callbacks_.scope());\n}\n\nbool FilterManager::createFilterChain() {\n  if (state_.created_filter_chain_) {\n    return false;\n  }\n  bool upgrade_rejected = false;\n  const HeaderEntry* upgrade = nullptr;\n  if (filter_manager_callbacks_.requestHeaders()) {\n    upgrade = filter_manager_callbacks_.requestHeaders()->Upgrade();\n\n    // Treat CONNECT requests as a special upgrade case.\n    if (!upgrade && HeaderUtility::isConnect(*filter_manager_callbacks_.requestHeaders())) {\n      upgrade = filter_manager_callbacks_.requestHeaders()->Method();\n    }\n  }\n\n  state_.created_filter_chain_ = true;\n  if (upgrade != nullptr) {\n    const Router::RouteEntry::UpgradeMap* upgrade_map = filter_manager_callbacks_.upgradeMap();\n\n    if (filter_chain_factory_.createUpgradeFilterChain(upgrade->value().getStringView(),\n                                                       upgrade_map, *this)) {\n      filter_manager_callbacks_.upgradeFilterChainCreated();\n      return true;\n    } else {\n      upgrade_rejected = true;\n      // Fall through to the default filter chain. The function calling this\n      // will send a local reply indicating that the upgrade failed.\n    }\n  }\n\n  filter_chain_factory_.createFilterChain(*this);\n  return !upgrade_rejected;\n}\n\nvoid ActiveStreamDecoderFilter::requestDataDrained() {\n  // If this is called it means the call to requestDataTooLarge() was a\n  // streaming call, or a 413 would have been sent.\n  onDecoderFilterBelowWriteBufferLowWatermark();\n}\n\nvoid ActiveStreamDecoderFilter::onDecoderFilterBelowWriteBufferLowWatermark() {\n  parent_.filter_manager_callbacks_.onDecoderFilterBelowWriteBufferLowWatermark();\n}\n\nvoid ActiveStreamDecoderFilter::addDownstreamWatermarkCallbacks(\n    DownstreamWatermarkCallbacks& watermark_callbacks) {\n  // This is called exactly once per upstream-stream, by the router filter. Therefore, we\n  // expect the same callbacks to not be registered twice.\n  ASSERT(std::find(parent_.watermark_callbacks_.begin(), parent_.watermark_callbacks_.end(),\n                   &watermark_callbacks) == parent_.watermark_callbacks_.end());\n  parent_.watermark_callbacks_.emplace(parent_.watermark_callbacks_.end(), &watermark_callbacks);\n  for (uint32_t i = 0; i < parent_.high_watermark_count_; ++i) {\n    watermark_callbacks.onAboveWriteBufferHighWatermark();\n  }\n}\n\nvoid ActiveStreamDecoderFilter::removeDownstreamWatermarkCallbacks(\n    DownstreamWatermarkCallbacks& watermark_callbacks) {\n  ASSERT(std::find(parent_.watermark_callbacks_.begin(), parent_.watermark_callbacks_.end(),\n                   &watermark_callbacks) != parent_.watermark_callbacks_.end());\n  parent_.watermark_callbacks_.remove(&watermark_callbacks);\n}\n\nvoid ActiveStreamDecoderFilter::setDecoderBufferLimit(uint32_t limit) {\n  parent_.setBufferLimit(limit);\n}\n\nuint32_t ActiveStreamDecoderFilter::decoderBufferLimit() { return parent_.buffer_limit_; }\n\nbool ActiveStreamDecoderFilter::recreateStream(const ResponseHeaderMap* headers) {\n  // Because the filter's and the HCM view of if the stream has a body and if\n  // the stream is complete may differ, re-check bytesReceived() to make sure\n  // there was no body from the HCM's point of view.\n  if (!complete()) {\n    return false;\n  }\n\n  parent_.stream_info_.setResponseCodeDetails(\n      StreamInfo::ResponseCodeDetails::get().InternalRedirect);\n\n  if (headers != nullptr) {\n    // The call to setResponseHeaders is needed to ensure that the headers are properly logged in\n    // access logs before the stream is destroyed. Since the function expects a ResponseHeaderPtr&&,\n    // ownership of the headers must be passed. This cannot happen earlier in the flow (such as in\n    // the call to setupRedirect) because at that point it is still possible for the headers to be\n    // used in a different logical branch. We work around this by creating a copy and passing\n    // ownership of the copy instead.\n    ResponseHeaderMapPtr headers_copy = createHeaderMap<ResponseHeaderMapImpl>(*headers);\n    parent_.filter_manager_callbacks_.setResponseHeaders(std::move(headers_copy));\n    parent_.filter_manager_callbacks_.chargeStats(*headers);\n  }\n\n  parent_.filter_manager_callbacks_.recreateStream(parent_.stream_info_.filter_state_);\n\n  return true;\n}\n\nvoid ActiveStreamDecoderFilter::addUpstreamSocketOptions(\n    const Network::Socket::OptionsSharedPtr& options) {\n\n  Network::Socket::appendOptions(parent_.upstream_options_, options);\n}\n\nNetwork::Socket::OptionsSharedPtr ActiveStreamDecoderFilter::getUpstreamSocketOptions() const {\n  return parent_.upstream_options_;\n}\n\nvoid ActiveStreamDecoderFilter::requestRouteConfigUpdate(\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  parent_.filter_manager_callbacks_.requestRouteConfigUpdate(std::move(route_config_updated_cb));\n}\n\nabsl::optional<Router::ConfigConstSharedPtr> ActiveStreamDecoderFilter::routeConfig() {\n  return parent_.filter_manager_callbacks_.routeConfig();\n}\n\nBuffer::InstancePtr ActiveStreamEncoderFilter::createBuffer() {\n  auto buffer = dispatcher().getWatermarkFactory().createBuffer(\n      [this]() -> void { this->responseDataDrained(); },\n      [this]() -> void { this->responseDataTooLarge(); },\n      []() -> void { /* TODO(adisuissa): Handle overflow watermark */ });\n  buffer->setWatermarks(parent_.buffer_limit_);\n  return buffer;\n}\nBuffer::InstancePtr& ActiveStreamEncoderFilter::bufferedData() {\n  return parent_.buffered_response_data_;\n}\nbool ActiveStreamEncoderFilter::complete() { return parent_.state_.local_complete_; }\nbool ActiveStreamEncoderFilter::has1xxHeaders() {\n  return parent_.state_.has_1xx_headers_ && !continued_1xx_headers_;\n}\nvoid ActiveStreamEncoderFilter::do1xxHeaders() {\n  parent_.encode1xxHeaders(this, *parent_.filter_manager_callbacks_.informationalHeaders());\n}\nvoid ActiveStreamEncoderFilter::doHeaders(bool end_stream) {\n  parent_.encodeHeaders(this, *parent_.filter_manager_callbacks_.responseHeaders(), end_stream);\n}\nvoid ActiveStreamEncoderFilter::doData(bool end_stream) {\n  parent_.encodeData(this, *parent_.buffered_response_data_, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\nvoid ActiveStreamEncoderFilter::drainSavedResponseMetadata() {\n  ASSERT(saved_response_metadata_ != nullptr);\n  for (auto& metadata_map : *getSavedResponseMetadata()) {\n    parent_.encodeMetadata(this, std::move(metadata_map));\n  }\n  getSavedResponseMetadata()->clear();\n}\n\nvoid ActiveStreamEncoderFilter::handleMetadataAfterHeadersCallback() {\n  // If we drain accumulated metadata, the iteration must start with the current filter.\n  const bool saved_state = iterate_from_current_filter_;\n  iterate_from_current_filter_ = true;\n  // If encodeHeaders() returns StopAllIteration, we should skip draining metadata, and wait\n  // for doMetadata() to drain the metadata after iteration continues.\n  if (!stoppedAll() && saved_response_metadata_ != nullptr &&\n      !getSavedResponseMetadata()->empty()) {\n    drainSavedResponseMetadata();\n  }\n  // Restores the original value of iterate_from_current_filter_.\n  iterate_from_current_filter_ = saved_state;\n}\nvoid ActiveStreamEncoderFilter::doTrailers() {\n  parent_.encodeTrailers(this, *parent_.filter_manager_callbacks_.responseTrailers());\n}\nbool ActiveStreamEncoderFilter::hasTrailers() {\n  return parent_.filter_manager_callbacks_.responseTrailers().has_value();\n}\nvoid ActiveStreamEncoderFilter::addEncodedData(Buffer::Instance& data, bool streaming) {\n  return parent_.addEncodedData(*this, data, streaming);\n}\n\nvoid ActiveStreamEncoderFilter::injectEncodedDataToFilterChain(Buffer::Instance& data,\n                                                               bool end_stream) {\n  if (!headers_continued_) {\n    headers_continued_ = true;\n    doHeaders(false);\n  }\n  parent_.encodeData(this, data, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\n\nResponseTrailerMap& ActiveStreamEncoderFilter::addEncodedTrailers() {\n  return parent_.addEncodedTrailers();\n}\n\nvoid ActiveStreamEncoderFilter::addEncodedMetadata(MetadataMapPtr&& metadata_map_ptr) {\n  return parent_.encodeMetadata(this, std::move(metadata_map_ptr));\n}\n\nvoid ActiveStreamEncoderFilter::onEncoderFilterAboveWriteBufferHighWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Disabling upstream stream due to filter callbacks.\", parent_);\n  parent_.callHighWatermarkCallbacks();\n}\n\nvoid ActiveStreamEncoderFilter::onEncoderFilterBelowWriteBufferLowWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Enabling upstream stream due to filter callbacks.\", parent_);\n  parent_.callLowWatermarkCallbacks();\n}\n\nvoid ActiveStreamEncoderFilter::setEncoderBufferLimit(uint32_t limit) {\n  parent_.setBufferLimit(limit);\n}\n\nuint32_t ActiveStreamEncoderFilter::encoderBufferLimit() { return parent_.buffer_limit_; }\n\nvoid ActiveStreamEncoderFilter::continueEncoding() { commonContinue(); }\n\nconst Buffer::Instance* ActiveStreamEncoderFilter::encodingBuffer() {\n  return parent_.buffered_response_data_.get();\n}\n\nvoid ActiveStreamEncoderFilter::modifyEncodingBuffer(\n    std::function<void(Buffer::Instance&)> callback) {\n  ASSERT(parent_.state_.latest_data_encoding_filter_ == this);\n  callback(*parent_.buffered_response_data_.get());\n}\n\nvoid ActiveStreamEncoderFilter::sendLocalReply(\n    Code code, absl::string_view body,\n    std::function<void(ResponseHeaderMap& headers)> modify_headers,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details) {\n  parent_.sendLocalReply(code, body, modify_headers, grpc_status, details);\n}\n\nHttp1StreamEncoderOptionsOptRef ActiveStreamEncoderFilter::http1StreamEncoderOptions() {\n  // TODO(mattklein123): At some point we might want to actually wrap this interface but for now\n  // we give the filter direct access to the encoder options.\n  return parent_.filter_manager_callbacks_.http1StreamEncoderOptions();\n}\n\nvoid ActiveStreamEncoderFilter::responseDataTooLarge() {\n  ENVOY_STREAM_LOG(debug, \"response data too large watermark exceeded\", parent_);\n  if (parent_.state_.encoder_filters_streaming_) {\n    onEncoderFilterAboveWriteBufferHighWatermark();\n  } else {\n    parent_.filter_manager_callbacks_.onResponseDataTooLarge();\n\n    // In this case, sendLocalReply will either send a response directly to the encoder, or\n    // reset the stream.\n    parent_.sendLocalReply(\n        Http::Code::InternalServerError, CodeUtility::toString(Http::Code::InternalServerError),\n        nullptr, absl::nullopt, StreamInfo::ResponseCodeDetails::get().ResponsePayloadTooLarge);\n  }\n}\n\nvoid ActiveStreamEncoderFilter::responseDataDrained() {\n  onEncoderFilterBelowWriteBufferLowWatermark();\n}\n\nvoid ActiveStreamFilterBase::resetStream() { parent_.filter_manager_callbacks_.resetStream(); }\n\nuint64_t ActiveStreamFilterBase::streamId() const { return parent_.streamId(); }\n\nBuffer::BufferMemoryAccountSharedPtr ActiveStreamDecoderFilter::account() const {\n  return parent_.account();\n}\n\nvoid ActiveStreamDecoderFilter::setUpstreamOverrideHost(absl::string_view host) {\n  parent_.upstream_override_host_.emplace(std::move(host));\n}\n\nabsl::optional<absl::string_view> ActiveStreamDecoderFilter::upstreamOverrideHost() const {\n  return parent_.upstream_override_host_;\n}\n\n} // namespace Http\n} // namespace Envoy\n", "#pragma once\n\n#include <functional>\n#include <memory>\n\n#include \"envoy/buffer/buffer.h\"\n#include \"envoy/common/optref.h\"\n#include \"envoy/extensions/filters/common/matcher/action/v3/skip_action.pb.h\"\n#include \"envoy/extensions/filters/network/http_connection_manager/v3/http_connection_manager.pb.h\"\n#include \"envoy/extensions/filters/network/http_connection_manager/v3/http_connection_manager.pb.validate.h\"\n#include \"envoy/http/filter.h\"\n#include \"envoy/http/header_map.h\"\n#include \"envoy/matcher/matcher.h\"\n#include \"envoy/network/socket.h\"\n#include \"envoy/protobuf/message_validator.h\"\n#include \"envoy/type/matcher/v3/http_inputs.pb.validate.h\"\n\n#include \"source/common/buffer/watermark_buffer.h\"\n#include \"source/common/common/dump_state_utils.h\"\n#include \"source/common/common/linked_object.h\"\n#include \"source/common/common/logger.h\"\n#include \"source/common/grpc/common.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/http/headers.h\"\n#include \"source/common/http/matching/data_impl.h\"\n#include \"source/common/local_reply/local_reply.h\"\n#include \"source/common/matcher/matcher.h\"\n#include \"source/common/protobuf/utility.h\"\n#include \"source/common/stream_info/stream_info_impl.h\"\n\nnamespace Envoy {\nnamespace Http {\n\nclass FilterManager;\n\nclass SkipAction : public Matcher::ActionBase<\n                       envoy::extensions::filters::common::matcher::action::v3::SkipFilter> {};\n\nstruct ActiveStreamFilterBase;\n\nusing MatchDataUpdateFunc = std::function<void(Matching::HttpMatchingDataImpl&)>;\n/**\n * Manages the shared match state between one or two filters.\n * The need for this class comes from the fact that a single instantiated filter can be wrapped by\n * two different ActiveStreamFilters, one for encoding and one for decoding. Certain match actions\n * should be made visible to both wrappers (e.g. the skip action), while other actions should be\n * sent to the underlying filter exactly once.\n */\nclass FilterMatchState {\npublic:\n  FilterMatchState(Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree,\n                   Matching::HttpMatchingDataImplSharedPtr matching_data)\n      : match_tree_(std::move(match_tree)), matching_data_(std::move(matching_data)),\n        match_tree_evaluated_(false), skip_filter_(false) {}\n\n  void evaluateMatchTreeWithNewData(MatchDataUpdateFunc update_func);\n\n  StreamFilterBase* filter_{};\n\n  bool skipFilter() const { return skip_filter_; }\n\nprivate:\n  Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree_;\n  Matching::HttpMatchingDataImplSharedPtr matching_data_;\n  bool match_tree_evaluated_ : 1;\n  bool skip_filter_ : 1;\n};\n\nusing FilterMatchStateSharedPtr = std::shared_ptr<FilterMatchState>;\n\nclass SkipActionFactory : public Matcher::ActionFactory<Matching::HttpFilterActionContext> {\npublic:\n  std::string name() const override { return \"skip\"; }\n  Matcher::ActionFactoryCb createActionFactoryCb(const Protobuf::Message&,\n                                                 Matching::HttpFilterActionContext&,\n                                                 ProtobufMessage::ValidationVisitor&) override {\n    return []() { return std::make_unique<SkipAction>(); };\n  }\n  ProtobufTypes::MessagePtr createEmptyConfigProto() override {\n    return std::make_unique<envoy::extensions::filters::common::matcher::action::v3::SkipFilter>();\n  }\n};\n\n/**\n * Base class wrapper for both stream encoder and decoder filters.\n *\n * This class is responsible for performing matching and updating match data when a match tree is\n * configured for the associated filter. When not using a match tree, only minimal overhead (i.e.\n * memory overhead of unused fields) should apply.\n */\nstruct ActiveStreamFilterBase : public virtual StreamFilterCallbacks,\n                                Logger::Loggable<Logger::Id::http> {\n  ActiveStreamFilterBase(FilterManager& parent, bool dual_filter,\n                         FilterMatchStateSharedPtr match_state)\n      : parent_(parent), iteration_state_(IterationState::Continue),\n        filter_match_state_(std::move(match_state)), iterate_from_current_filter_(false),\n        headers_continued_(false), continued_1xx_headers_(false), end_stream_(false),\n        dual_filter_(dual_filter), decode_headers_called_(false), encode_headers_called_(false) {}\n\n  // Functions in the following block are called after the filter finishes processing\n  // corresponding data. Those functions handle state updates and data storage (if needed)\n  // according to the status returned by filter's callback functions.\n  bool commonHandleAfter1xxHeadersCallback(FilterHeadersStatus status);\n  bool commonHandleAfterHeadersCallback(FilterHeadersStatus status, bool& end_stream);\n  bool commonHandleAfterDataCallback(FilterDataStatus status, Buffer::Instance& provided_data,\n                                     bool& buffer_was_streaming);\n  bool commonHandleAfterTrailersCallback(FilterTrailersStatus status);\n\n  // Buffers provided_data.\n  void commonHandleBufferData(Buffer::Instance& provided_data);\n\n  // If iteration has stopped for all frame types, calls this function to buffer the data before\n  // the filter processes data. The function also updates streaming state.\n  void commonBufferDataIfStopAll(Buffer::Instance& provided_data, bool& buffer_was_streaming);\n\n  void commonContinue();\n  virtual bool canContinue() PURE;\n  virtual Buffer::InstancePtr createBuffer() PURE;\n  virtual Buffer::InstancePtr& bufferedData() PURE;\n  virtual bool complete() PURE;\n  virtual bool has1xxHeaders() PURE;\n  virtual void do1xxHeaders() PURE;\n  virtual void doHeaders(bool end_stream) PURE;\n  virtual void doData(bool end_stream) PURE;\n  virtual void doTrailers() PURE;\n  virtual bool hasTrailers() PURE;\n  virtual void doMetadata() PURE;\n  // TODO(soya3129): make this pure when adding impl to encoder filter.\n  virtual void handleMetadataAfterHeadersCallback() PURE;\n\n  virtual void onMatchCallback(const Matcher::Action& action) PURE;\n\n  // Http::StreamFilterCallbacks\n  const Network::Connection* connection() override;\n  Event::Dispatcher& dispatcher() override;\n  void resetStream() override;\n  Router::RouteConstSharedPtr route() override;\n  Router::RouteConstSharedPtr route(const Router::RouteCallback& cb) override;\n  void setRoute(Router::RouteConstSharedPtr route) override;\n  Upstream::ClusterInfoConstSharedPtr clusterInfo() override;\n  void clearRouteCache() override;\n  uint64_t streamId() const override;\n  StreamInfo::StreamInfo& streamInfo() override;\n  Tracing::Span& activeSpan() override;\n  Tracing::Config& tracingConfig() override;\n  const ScopeTrackedObject& scope() override;\n  void restoreContextOnContinue(ScopeTrackedObjectStack& tracked_object_stack) override;\n  void resetIdleTimer() override;\n\n  // Functions to set or get iteration state.\n  bool canIterate() { return iteration_state_ == IterationState::Continue; }\n  bool stoppedAll() {\n    return iteration_state_ == IterationState::StopAllBuffer ||\n           iteration_state_ == IterationState::StopAllWatermark;\n  }\n  void allowIteration() {\n    ASSERT(iteration_state_ != IterationState::Continue);\n    iteration_state_ = IterationState::Continue;\n  }\n  MetadataMapVector* getSavedRequestMetadata() {\n    if (saved_request_metadata_ == nullptr) {\n      saved_request_metadata_ = std::make_unique<MetadataMapVector>();\n    }\n    return saved_request_metadata_.get();\n  }\n  MetadataMapVector* getSavedResponseMetadata() {\n    if (saved_response_metadata_ == nullptr) {\n      saved_response_metadata_ = std::make_unique<MetadataMapVector>();\n    }\n    return saved_response_metadata_.get();\n  }\n  bool skipFilter() const { return filter_match_state_ && filter_match_state_->skipFilter(); }\n  void maybeEvaluateMatchTreeWithNewData(MatchDataUpdateFunc update_func) {\n    if (filter_match_state_) {\n      filter_match_state_->evaluateMatchTreeWithNewData(update_func);\n    }\n  }\n\n  // A vector to save metadata when the current filter's [de|en]codeMetadata() can not be called,\n  // either because [de|en]codeHeaders() of the current filter returns StopAllIteration or because\n  // [de|en]codeHeaders() adds new metadata to [de|en]code, but we don't know\n  // [de|en]codeHeaders()'s return value yet. The storage is created on demand.\n  std::unique_ptr<MetadataMapVector> saved_request_metadata_{nullptr};\n  std::unique_ptr<MetadataMapVector> saved_response_metadata_{nullptr};\n  // The state of iteration.\n  enum class IterationState {\n    Continue,            // Iteration has not stopped for any frame type.\n    StopSingleIteration, // Iteration has stopped for headers, 100-continue, or data.\n    StopAllBuffer,       // Iteration has stopped for all frame types, and following data should\n                         // be buffered.\n    StopAllWatermark,    // Iteration has stopped for all frame types, and following data should\n                         // be buffered until high watermark is reached.\n  };\n  FilterManager& parent_;\n  IterationState iteration_state_;\n\n  FilterMatchStateSharedPtr filter_match_state_;\n  // If the filter resumes iteration from a StopAllBuffer/Watermark state, the current filter\n  // hasn't parsed data and trailers. As a result, the filter iteration should start with the\n  // current filter instead of the next one. If true, filter iteration starts with the current\n  // filter. Otherwise, starts with the next filter in the chain.\n  bool iterate_from_current_filter_ : 1;\n  bool headers_continued_ : 1;\n  bool continued_1xx_headers_ : 1;\n  // If true, end_stream is called for this filter.\n  bool end_stream_ : 1;\n  const bool dual_filter_ : 1;\n  bool decode_headers_called_ : 1;\n  bool encode_headers_called_ : 1;\n\n  friend FilterMatchState;\n};\n\n/**\n * Wrapper for a stream decoder filter.\n */\nstruct ActiveStreamDecoderFilter : public ActiveStreamFilterBase,\n                                   public StreamDecoderFilterCallbacks,\n                                   LinkedObject<ActiveStreamDecoderFilter> {\n  ActiveStreamDecoderFilter(FilterManager& parent, StreamDecoderFilterSharedPtr filter,\n                            FilterMatchStateSharedPtr match_state, bool dual_filter)\n      : ActiveStreamFilterBase(parent, dual_filter, std::move(match_state)), handle_(filter) {}\n\n  // ActiveStreamFilterBase\n  bool canContinue() override;\n  Buffer::InstancePtr createBuffer() override;\n  Buffer::InstancePtr& bufferedData() override;\n  bool complete() override;\n  bool has1xxHeaders() override { return false; }\n  void do1xxHeaders() override { IS_ENVOY_BUG(\"unexpected 1xx headers\"); }\n  void doHeaders(bool end_stream) override;\n  void doData(bool end_stream) override;\n  void doMetadata() override {\n    if (saved_request_metadata_ != nullptr) {\n      drainSavedRequestMetadata();\n    }\n  }\n  void doTrailers() override;\n  bool hasTrailers() override;\n\n  void drainSavedRequestMetadata();\n  // This function is called after the filter calls decodeHeaders() to drain accumulated metadata.\n  void handleMetadataAfterHeadersCallback() override;\n  void onMatchCallback(const Matcher::Action& action) override {\n    handle_->onMatchCallback(std::move(action));\n  }\n\n  // Http::StreamDecoderFilterCallbacks\n  void addDecodedData(Buffer::Instance& data, bool streaming) override;\n  void injectDecodedDataToFilterChain(Buffer::Instance& data, bool end_stream) override;\n  RequestTrailerMap& addDecodedTrailers() override;\n  MetadataMapVector& addDecodedMetadata() override;\n  void continueDecoding() override;\n  const Buffer::Instance* decodingBuffer() override;\n\n  void modifyDecodingBuffer(std::function<void(Buffer::Instance&)> callback) override;\n\n  void sendLocalReply(Code code, absl::string_view body,\n                      std::function<void(ResponseHeaderMap& headers)> modify_headers,\n                      const absl::optional<Grpc::Status::GrpcStatus> grpc_status,\n                      absl::string_view details) override;\n  void encode1xxHeaders(ResponseHeaderMapPtr&& headers) override;\n  ResponseHeaderMapOptRef informationalHeaders() const override;\n  void encodeHeaders(ResponseHeaderMapPtr&& headers, bool end_stream,\n                     absl::string_view details) override;\n  ResponseHeaderMapOptRef responseHeaders() const override;\n  void encodeData(Buffer::Instance& data, bool end_stream) override;\n  void encodeTrailers(ResponseTrailerMapPtr&& trailers) override;\n  ResponseTrailerMapOptRef responseTrailers() const override;\n  void encodeMetadata(MetadataMapPtr&& metadata_map_ptr) override;\n  void onDecoderFilterAboveWriteBufferHighWatermark() override;\n  void onDecoderFilterBelowWriteBufferLowWatermark() override;\n  void addDownstreamWatermarkCallbacks(DownstreamWatermarkCallbacks& watermark_callbacks) override;\n  void\n  removeDownstreamWatermarkCallbacks(DownstreamWatermarkCallbacks& watermark_callbacks) override;\n  void setDecoderBufferLimit(uint32_t limit) override;\n  uint32_t decoderBufferLimit() override;\n  bool recreateStream(const Http::ResponseHeaderMap* original_response_headers) override;\n\n  void addUpstreamSocketOptions(const Network::Socket::OptionsSharedPtr& options) override;\n\n  Network::Socket::OptionsSharedPtr getUpstreamSocketOptions() const override;\n  Buffer::BufferMemoryAccountSharedPtr account() const override;\n  void setUpstreamOverrideHost(absl::string_view host) override;\n  absl::optional<absl::string_view> upstreamOverrideHost() const override;\n\n  // Each decoder filter instance checks if the request passed to the filter is gRPC\n  // so that we can issue gRPC local responses to gRPC requests. Filter's decodeHeaders()\n  // called here may change the content type, so we must check it before the call.\n  FilterHeadersStatus decodeHeaders(RequestHeaderMap& headers, bool end_stream) {\n    is_grpc_request_ = Grpc::Common::isGrpcRequestHeaders(headers);\n    FilterHeadersStatus status = handle_->decodeHeaders(headers, end_stream);\n    return status;\n  }\n\n  void requestDataTooLarge();\n  void requestDataDrained();\n\n  void requestRouteConfigUpdate(\n      Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) override;\n  absl::optional<Router::ConfigConstSharedPtr> routeConfig();\n\n  StreamDecoderFilterSharedPtr handle_;\n  bool is_grpc_request_{};\n};\n\nusing ActiveStreamDecoderFilterPtr = std::unique_ptr<ActiveStreamDecoderFilter>;\n\n/**\n * Wrapper for a stream encoder filter.\n */\nstruct ActiveStreamEncoderFilter : public ActiveStreamFilterBase,\n                                   public StreamEncoderFilterCallbacks,\n                                   LinkedObject<ActiveStreamEncoderFilter> {\n  ActiveStreamEncoderFilter(FilterManager& parent, StreamEncoderFilterSharedPtr filter,\n                            FilterMatchStateSharedPtr match_state, bool dual_filter)\n      : ActiveStreamFilterBase(parent, dual_filter, std::move(match_state)), handle_(filter) {}\n\n  // ActiveStreamFilterBase\n  bool canContinue() override;\n  Buffer::InstancePtr createBuffer() override;\n  Buffer::InstancePtr& bufferedData() override;\n  bool complete() override;\n  bool has1xxHeaders() override;\n  void do1xxHeaders() override;\n  void doHeaders(bool end_stream) override;\n  void doData(bool end_stream) override;\n  void drainSavedResponseMetadata();\n  void handleMetadataAfterHeadersCallback() override;\n  void onMatchCallback(const Matcher::Action& action) override { handle_->onMatchCallback(action); }\n\n  void doMetadata() override {\n    if (saved_response_metadata_ != nullptr) {\n      drainSavedResponseMetadata();\n    }\n  }\n  void doTrailers() override;\n  bool hasTrailers() override;\n\n  // Http::StreamEncoderFilterCallbacks\n  void addEncodedData(Buffer::Instance& data, bool streaming) override;\n  void injectEncodedDataToFilterChain(Buffer::Instance& data, bool end_stream) override;\n  ResponseTrailerMap& addEncodedTrailers() override;\n  void addEncodedMetadata(MetadataMapPtr&& metadata_map) override;\n  void onEncoderFilterAboveWriteBufferHighWatermark() override;\n  void onEncoderFilterBelowWriteBufferLowWatermark() override;\n  void setEncoderBufferLimit(uint32_t limit) override;\n  uint32_t encoderBufferLimit() override;\n  void continueEncoding() override;\n  const Buffer::Instance* encodingBuffer() override;\n  void modifyEncodingBuffer(std::function<void(Buffer::Instance&)> callback) override;\n  void sendLocalReply(Code code, absl::string_view body,\n                      std::function<void(ResponseHeaderMap& headers)> modify_headers,\n                      const absl::optional<Grpc::Status::GrpcStatus> grpc_status,\n                      absl::string_view details) override;\n  Http1StreamEncoderOptionsOptRef http1StreamEncoderOptions() override;\n\n  void responseDataTooLarge();\n  void responseDataDrained();\n\n  StreamEncoderFilterSharedPtr handle_;\n};\n\nusing ActiveStreamEncoderFilterPtr = std::unique_ptr<ActiveStreamEncoderFilter>;\n\n/**\n * Callbacks invoked by the FilterManager to pass filter data/events back to the caller.\n */\nclass FilterManagerCallbacks {\npublic:\n  virtual ~FilterManagerCallbacks() = default;\n\n  /**\n   * Called when the provided headers have been encoded by all the filters in the chain.\n   * @param response_headers the encoded headers.\n   * @param end_stream whether this is a header only response.\n   */\n  virtual void encodeHeaders(ResponseHeaderMap& response_headers, bool end_stream) PURE;\n\n  /**\n   * Called when the provided 100 Continue headers have been encoded by all the filters in the\n   * chain.\n   * @param response_headers the encoded headers.\n   */\n  virtual void encode1xxHeaders(ResponseHeaderMap& response_headers) PURE;\n\n  /**\n   * Called when the provided data has been encoded by all filters in the chain.\n   * @param data the encoded data.\n   * @param end_stream whether this is the end of the response.\n   */\n  virtual void encodeData(Buffer::Instance& data, bool end_stream) PURE;\n\n  /**\n   * Called when the provided trailers have been encoded by all filters in the chain.\n   * @param trailers the encoded trailers.\n   */\n  virtual void encodeTrailers(ResponseTrailerMap& trailers) PURE;\n\n  /**\n   * Called when the provided metadata has been encoded by all filters in the chain.\n   * @param trailers the encoded trailers.\n   */\n  virtual void encodeMetadata(MetadataMapVector& metadata) PURE;\n\n  /**\n   * Injects request trailers into a stream that originally did not have request trailers.\n   */\n  virtual void setRequestTrailers(RequestTrailerMapPtr&& request_trailers) PURE;\n\n  /**\n   * Passes ownership of received informational headers to the parent. This may be called multiple\n   * times in the case of multiple upstream calls.\n   */\n  virtual void setInformationalHeaders(ResponseHeaderMapPtr&& response_headers) PURE;\n\n  /**\n   * Passes ownership of received response headers to the parent. This may be called multiple times\n   * in the case of multiple upstream calls.\n   */\n  virtual void setResponseHeaders(ResponseHeaderMapPtr&& response_headers) PURE;\n\n  /**\n   * Passes ownership of received response trailers to the parent. This may be called multiple times\n   * in the case of multiple upstream calls.\n   */\n  virtual void setResponseTrailers(ResponseTrailerMapPtr&& response_trailers) PURE;\n\n  /**\n   * Updates response code stats based on the details in the headers.\n   */\n  virtual void chargeStats(const ResponseHeaderMap& headers) PURE;\n\n  // TODO(snowp): We should consider moving filter access to headers/trailers to happen via the\n  // callbacks instead of via the encode/decode callbacks on the filters.\n\n  /**\n   * The downstream request headers if set.\n   */\n  virtual RequestHeaderMapOptRef requestHeaders() PURE;\n\n  /**\n   * The downstream request trailers if present.\n   */\n  virtual RequestTrailerMapOptRef requestTrailers() PURE;\n\n  /**\n   * Retrieves a pointer to the continue headers set via the call to setInformationalHeaders.\n   */\n  virtual ResponseHeaderMapOptRef informationalHeaders() PURE;\n\n  /**\n   * Retrieves a pointer to the response headers set via the last call to setResponseHeaders.\n   * Note that response headers might be set multiple times (e.g. if a local reply is issued after\n   * headers have been received but before headers have been encoded), so it is not safe in general\n   * to assume that any set of headers will be valid for the duration of a stream.\n   */\n  virtual ResponseHeaderMapOptRef responseHeaders() PURE;\n\n  /**\n   * Retrieves a pointer to the last response trailers set via setResponseTrailers.\n   * Note that response trailers might be set multiple times, so it is not safe in general to assume\n   * that any set of trailers will be valid for the duration of the stream.\n   */\n  virtual ResponseTrailerMapOptRef responseTrailers() PURE;\n\n  /**\n   * Called after encoding has completed.\n   */\n  virtual void endStream() PURE;\n\n  /**\n   * Called when the stream write buffer is no longer above the low watermark.\n   */\n  virtual void onDecoderFilterBelowWriteBufferLowWatermark() PURE;\n\n  /**\n   * Called when the stream write buffer is above above the high watermark.\n   */\n  virtual void onDecoderFilterAboveWriteBufferHighWatermark() PURE;\n\n  /**\n   * Called when the FilterManager creates an Upgrade filter chain.\n   */\n  virtual void upgradeFilterChainCreated() PURE;\n\n  /**\n   * Called when request activity indicates that the request timeout should be disarmed.\n   */\n  virtual void disarmRequestTimeout() PURE;\n\n  /**\n   * Called when stream activity indicates that the stream idle timeout should be reset.\n   */\n  virtual void resetIdleTimer() PURE;\n\n  /**\n   * Called when the stream should be re-created, e.g. for an internal redirect.\n   */\n  virtual void recreateStream(StreamInfo::FilterStateSharedPtr filter_state) PURE;\n\n  /**\n   * Called when the stream should be reset.\n   */\n  virtual void resetStream() PURE;\n\n  /**\n   * Returns the upgrade map for the current route entry.\n   */\n  virtual const Router::RouteEntry::UpgradeMap* upgradeMap() PURE;\n\n  /**\n   * Returns the cluster info for the current route entry.\n   */\n  virtual Upstream::ClusterInfoConstSharedPtr clusterInfo() PURE;\n\n  /**\n   * Returns the current route.\n   */\n  virtual Router::RouteConstSharedPtr route(const Router::RouteCallback& cb) PURE;\n\n  /**\n   * Sets the current route.\n   */\n  virtual void setRoute(Router::RouteConstSharedPtr route) PURE;\n\n  /**\n   * Clears the cached route.\n   */\n  virtual void clearRouteCache() PURE;\n\n  /**\n   * Returns the current route configuration.\n   */\n  virtual absl::optional<Router::ConfigConstSharedPtr> routeConfig() PURE;\n\n  /**\n   * Update the current route configuration.\n   */\n  virtual void\n  requestRouteConfigUpdate(Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) PURE;\n\n  /**\n   * Returns the current active span.\n   */\n  virtual Tracing::Span& activeSpan() PURE;\n\n  // TODO(snowp): It might make more sense to pass (optional?) counters to the FM instead of\n  // calling back out to the AS to record them.\n  /**\n   * Called when a stream fails due to the response data being too large.\n   */\n  virtual void onResponseDataTooLarge() PURE;\n\n  /**\n   * Called when a stream fails due to the request data being too large.\n   */\n  virtual void onRequestDataTooLarge() PURE;\n\n  /**\n   * Returns the Http1StreamEncoderOptions associated with the response encoder.\n   */\n  virtual Http1StreamEncoderOptionsOptRef http1StreamEncoderOptions() PURE;\n\n  /**\n   * Called when a local reply is made by the filter manager.\n   * @param code the response code of the local reply.\n   */\n  virtual void onLocalReply(Code code) PURE;\n\n  /**\n   * Returns the tracing configuration to use for this stream.\n   */\n  virtual Tracing::Config& tracingConfig() PURE;\n\n  /**\n   * Returns the tracked scope to use for this stream.\n   */\n  virtual const ScopeTrackedObject& scope() PURE;\n};\n\n/**\n * This class allows the remote address to be overridden for HTTP stream info. This is used for\n * XFF handling. This is required to avoid providing stream info with a non-const connection info\n * provider. Private inheritance from ConnectionInfoProvider is used to make sure users get the\n * address provider via the normal getter.\n */\nclass OverridableRemoteConnectionInfoSetterStreamInfo : public StreamInfo::StreamInfoImpl,\n                                                        private Network::ConnectionInfoProvider {\npublic:\n  using StreamInfoImpl::StreamInfoImpl;\n\n  void setDownstreamRemoteAddress(\n      const Network::Address::InstanceConstSharedPtr& downstream_remote_address) {\n    // TODO(rgs1): we should assert overridden_downstream_remote_address_ is nullptr,\n    // but we are currently relaxing this as a workaround to:\n    //\n    // https://github.com/envoyproxy/envoy/pull/14432#issuecomment-758167614\n    overridden_downstream_remote_address_ = downstream_remote_address;\n  }\n\n  // StreamInfo::StreamInfo\n  const Network::ConnectionInfoProvider& downstreamAddressProvider() const override {\n    return *this;\n  }\n\n  // Network::ConnectionInfoProvider\n  const Network::Address::InstanceConstSharedPtr& localAddress() const override {\n    return StreamInfoImpl::downstreamAddressProvider().localAddress();\n  }\n  bool localAddressRestored() const override {\n    return StreamInfoImpl::downstreamAddressProvider().localAddressRestored();\n  }\n  const Network::Address::InstanceConstSharedPtr& remoteAddress() const override {\n    return overridden_downstream_remote_address_ != nullptr\n               ? overridden_downstream_remote_address_\n               : StreamInfoImpl::downstreamAddressProvider().remoteAddress();\n  }\n  const Network::Address::InstanceConstSharedPtr& directRemoteAddress() const override {\n    return StreamInfoImpl::downstreamAddressProvider().directRemoteAddress();\n  }\n  absl::string_view requestedServerName() const override {\n    return StreamInfoImpl::downstreamAddressProvider().requestedServerName();\n  }\n  absl::optional<uint64_t> connectionID() const override {\n    return StreamInfoImpl::downstreamAddressProvider().connectionID();\n  }\n  absl::optional<absl::string_view> interfaceName() const override {\n    return StreamInfoImpl::downstreamAddressProvider().interfaceName();\n  }\n  Ssl::ConnectionInfoConstSharedPtr sslConnection() const override {\n    return StreamInfoImpl::downstreamAddressProvider().sslConnection();\n  }\n  void dumpState(std::ostream& os, int indent_level) const override {\n    StreamInfoImpl::dumpState(os, indent_level);\n\n    const char* spaces = spacesForLevel(indent_level);\n    os << spaces << \"OverridableRemoteConnectionInfoSetterStreamInfo \" << this\n       << DUMP_MEMBER_AS(remoteAddress(), remoteAddress()->asStringView())\n       << DUMP_MEMBER_AS(directRemoteAddress(), directRemoteAddress()->asStringView())\n       << DUMP_MEMBER_AS(localAddress(), localAddress()->asStringView()) << \"\\n\";\n  }\n  absl::string_view ja3Hash() const override {\n    return StreamInfoImpl::downstreamAddressProvider().ja3Hash();\n  }\n\nprivate:\n  Network::Address::InstanceConstSharedPtr overridden_downstream_remote_address_;\n};\n\n/**\n * FilterManager manages decoding a request through a series of decoding filter and the encoding\n * of the resulting response.\n */\nclass FilterManager : public ScopeTrackedObject,\n                      FilterChainFactoryCallbacks,\n                      Logger::Loggable<Logger::Id::http> {\npublic:\n  FilterManager(FilterManagerCallbacks& filter_manager_callbacks, Event::Dispatcher& dispatcher,\n                const Network::Connection& connection, uint64_t stream_id,\n                Buffer::BufferMemoryAccountSharedPtr account, bool proxy_100_continue,\n                uint32_t buffer_limit, FilterChainFactory& filter_chain_factory,\n                const LocalReply::LocalReply& local_reply, Http::Protocol protocol,\n                TimeSource& time_source, StreamInfo::FilterStateSharedPtr parent_filter_state,\n                StreamInfo::FilterState::LifeSpan filter_state_life_span)\n      : filter_manager_callbacks_(filter_manager_callbacks), dispatcher_(dispatcher),\n        connection_(connection), stream_id_(stream_id), account_(std::move(account)),\n        proxy_100_continue_(proxy_100_continue), buffer_limit_(buffer_limit),\n        filter_chain_factory_(filter_chain_factory), local_reply_(local_reply),\n        stream_info_(protocol, time_source, connection.connectionInfoProviderSharedPtr(),\n                     parent_filter_state, filter_state_life_span) {}\n  ~FilterManager() override {\n    ASSERT(state_.destroyed_);\n    ASSERT(state_.filter_call_state_ == 0);\n  }\n\n  // ScopeTrackedObject\n  void dumpState(std::ostream& os, int indent_level = 0) const override {\n    const char* spaces = spacesForLevel(indent_level);\n    os << spaces << \"FilterManager \" << this << DUMP_MEMBER(state_.has_1xx_headers_) << \"\\n\";\n\n    DUMP_DETAILS(filter_manager_callbacks_.requestHeaders());\n    DUMP_DETAILS(filter_manager_callbacks_.requestTrailers());\n    DUMP_DETAILS(filter_manager_callbacks_.responseHeaders());\n    DUMP_DETAILS(filter_manager_callbacks_.responseTrailers());\n    DUMP_DETAILS(&stream_info_);\n  }\n\n  // Http::FilterChainFactoryCallbacks\n  Event::Dispatcher& dispatcher() override { return dispatcher_; }\n  void addStreamDecoderFilter(StreamDecoderFilterSharedPtr filter) override {\n    addStreamDecoderFilterWorker(filter, nullptr, false);\n    filters_.push_back(filter.get());\n  }\n  void addStreamDecoderFilter(StreamDecoderFilterSharedPtr filter,\n                              Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree) override {\n    if (match_tree) {\n      addStreamDecoderFilterWorker(\n          filter,\n          std::make_shared<FilterMatchState>(std::move(match_tree),\n                                             std::make_shared<Matching::HttpMatchingDataImpl>()),\n          false);\n      return;\n    }\n\n    addStreamDecoderFilterWorker(filter, nullptr, false);\n  }\n  void addStreamEncoderFilter(StreamEncoderFilterSharedPtr filter) override {\n    addStreamEncoderFilterWorker(filter, nullptr, false);\n    filters_.push_back(filter.get());\n  }\n  void addStreamEncoderFilter(StreamEncoderFilterSharedPtr filter,\n                              Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree) override {\n    if (match_tree) {\n      addStreamEncoderFilterWorker(\n          filter,\n          std::make_shared<FilterMatchState>(std::move(match_tree),\n                                             std::make_shared<Matching::HttpMatchingDataImpl>()),\n          false);\n      return;\n    }\n\n    addStreamEncoderFilterWorker(filter, nullptr, false);\n  }\n  void addStreamFilter(StreamFilterSharedPtr filter) override {\n    addStreamDecoderFilterWorker(filter, nullptr, true);\n    addStreamEncoderFilterWorker(filter, nullptr, true);\n    StreamDecoderFilter* decoder_filter = filter.get();\n    filters_.push_back(decoder_filter);\n  }\n  void addStreamFilter(StreamFilterSharedPtr filter,\n                       Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree) override {\n    // Note that we share the match data and tree between the two filters to allow things like\n    // matching on both request and response data.\n    // TODO(snowp): The match tree might be fully evaluated twice, ideally we should expose\n    // the result to both filters after the first match evaluation.\n    if (match_tree) {\n      auto matching_state = std::make_shared<FilterMatchState>(\n          std::move(match_tree), std::make_shared<Matching::HttpMatchingDataImpl>());\n      addStreamDecoderFilterWorker(filter, matching_state, true);\n      addStreamEncoderFilterWorker(filter, std::move(matching_state), true);\n      return;\n    }\n\n    addStreamDecoderFilterWorker(filter, nullptr, true);\n    addStreamEncoderFilterWorker(filter, nullptr, true);\n  }\n  void addAccessLogHandler(AccessLog::InstanceSharedPtr handler) override;\n\n  void log() {\n    RequestHeaderMap* request_headers = nullptr;\n    if (filter_manager_callbacks_.requestHeaders()) {\n      request_headers = filter_manager_callbacks_.requestHeaders().ptr();\n    }\n    ResponseHeaderMap* response_headers = nullptr;\n    if (filter_manager_callbacks_.responseHeaders()) {\n      response_headers = filter_manager_callbacks_.responseHeaders().ptr();\n    }\n    ResponseTrailerMap* response_trailers = nullptr;\n    if (filter_manager_callbacks_.responseTrailers()) {\n      response_trailers = filter_manager_callbacks_.responseTrailers().ptr();\n    }\n\n    for (const auto& log_handler : access_log_handlers_) {\n      log_handler->log(request_headers, response_headers, response_trailers, stream_info_);\n    }\n  }\n\n  void onStreamComplete() {\n    for (auto& filter : decoder_filters_) {\n      filter->handle_->onStreamComplete();\n    }\n\n    for (auto& filter : encoder_filters_) {\n      // Do not call onStreamComplete twice for dual registered filters.\n      if (!filter->dual_filter_) {\n        filter->handle_->onStreamComplete();\n      }\n    }\n  }\n\n  void destroyFilters() {\n    state_.destroyed_ = true;\n\n    for (auto& filter : decoder_filters_) {\n      filter->handle_->onDestroy();\n    }\n\n    for (auto& filter : encoder_filters_) {\n      // Do not call on destroy twice for dual registered filters.\n      if (!filter->dual_filter_) {\n        filter->handle_->onDestroy();\n      }\n    }\n  }\n\n  /**\n   * Decodes the provided headers starting at the first filter in the chain.\n   * @param headers the headers to decode.\n   * @param end_stream whether the request is header only.\n   */\n  void decodeHeaders(RequestHeaderMap& headers, bool end_stream) {\n    decodeHeaders(nullptr, headers, end_stream);\n  }\n\n  /**\n   * Decodes the provided data starting at the first filter in the chain.\n   * @param data the data to decode.\n   * @param end_stream whether this data is the end of the request.\n   */\n  void decodeData(Buffer::Instance& data, bool end_stream) {\n    decodeData(nullptr, data, end_stream, FilterIterationStartState::CanStartFromCurrent);\n  }\n\n  /**\n   * Decodes the provided trailers starting at the first filter in the chain.\n   * @param trailers the trailers to decode.\n   */\n  void decodeTrailers(RequestTrailerMap& trailers) { decodeTrailers(nullptr, trailers); }\n\n  /**\n   * Decodes the provided metadata starting at the first filter in the chain.\n   * @param metadata_map the metadata to decode.\n   */\n  void decodeMetadata(MetadataMap& metadata_map) { decodeMetadata(nullptr, metadata_map); }\n\n  // TODO(snowp): Make private as filter chain construction is moved into FM.\n  void addStreamDecoderFilterWorker(StreamDecoderFilterSharedPtr filter,\n                                    FilterMatchStateSharedPtr match_state, bool dual_filter);\n  void addStreamEncoderFilterWorker(StreamEncoderFilterSharedPtr filter,\n                                    FilterMatchStateSharedPtr match_state, bool dual_filter);\n\n  void disarmRequestTimeout();\n\n  /**\n   * If end_stream is true, marks decoding as complete. This is a noop if end_stream is false.\n   * @param end_stream whether decoding is complete.\n   */\n  void maybeEndDecode(bool end_stream);\n\n  /**\n   * If end_stream is true, marks encoding as complete. This is a noop if end_stream is false.\n   * @param end_stream whether encoding is complete.\n   */\n  void maybeEndEncode(bool end_stream);\n\n  /**\n   * Called before local reply is made by the filter manager.\n   * @param data the data associated with the local reply.\n   */\n  void onLocalReply(StreamFilterBase::LocalReplyData& data);\n\n  void sendLocalReply(Code code, absl::string_view body,\n                      const std::function<void(ResponseHeaderMap& headers)>& modify_headers,\n                      const absl::optional<Grpc::Status::GrpcStatus> grpc_status,\n                      absl::string_view details);\n  /**\n   * Sends a local reply by constructing a response and passing it through all the encoder\n   * filters. The resulting response will be passed out via the FilterManagerCallbacks.\n   */\n  void sendLocalReplyViaFilterChain(\n      bool is_grpc_request, Code code, absl::string_view body,\n      const std::function<void(ResponseHeaderMap& headers)>& modify_headers, bool is_head_request,\n      const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details);\n\n  /**\n   * Sends a local reply by constructing a response and skipping the encoder filters. The\n   * resulting response will be passed out via the FilterManagerCallbacks.\n   */\n  void sendDirectLocalReply(Code code, absl::string_view body,\n                            const std::function<void(ResponseHeaderMap& headers)>& modify_headers,\n                            bool is_head_request,\n                            const absl::optional<Grpc::Status::GrpcStatus> grpc_status);\n\n  // Possibly increases buffer_limit_ to the value of limit.\n  void setBufferLimit(uint32_t limit);\n\n  /**\n   * @return bool whether any above high watermark triggers are currently active\n   */\n  bool aboveHighWatermark() { return high_watermark_count_ != 0; }\n\n  // Pass on watermark callbacks to watermark subscribers. This boils down to passing watermark\n  // events for this stream and the downstream connection to the router filter.\n  void callHighWatermarkCallbacks();\n  void callLowWatermarkCallbacks();\n\n  void requestHeadersInitialized() {\n    if (Http::Headers::get().MethodValues.Head ==\n        filter_manager_callbacks_.requestHeaders()->getMethodValue()) {\n      state_.is_head_request_ = true;\n    }\n    state_.is_grpc_request_ =\n        Grpc::Common::isGrpcRequestHeaders(filter_manager_callbacks_.requestHeaders().ref());\n  }\n\n  /**\n   * Marks local processing as complete.\n   */\n  void setLocalComplete() { state_.local_complete_ = true; }\n\n  /**\n   * Whether the filters have been destroyed.\n   */\n  bool destroyed() const { return state_.destroyed_; }\n\n  /**\n   * Whether remote processing has been marked as complete.\n   */\n  bool remoteDecodeComplete() const { return state_.remote_decode_complete_; }\n\n  /**\n   * Instructs the FilterManager to not create a filter chain. This makes it possible to issue\n   * a local reply without the overhead of creating and traversing the filters.\n   */\n  void skipFilterChainCreation() {\n    ASSERT(!state_.created_filter_chain_);\n    state_.created_filter_chain_ = true;\n  }\n\n  // TODO(snowp): This should probably return a StreamInfo instead of the impl.\n  StreamInfo::StreamInfoImpl& streamInfo() { return stream_info_; }\n  const StreamInfo::StreamInfoImpl& streamInfo() const { return stream_info_; }\n  void setDownstreamRemoteAddress(\n      const Network::Address::InstanceConstSharedPtr& downstream_remote_address) {\n    stream_info_.setDownstreamRemoteAddress(downstream_remote_address);\n  }\n\n  // Set up the Encoder/Decoder filter chain.\n  bool createFilterChain();\n\n  const Network::Connection* connection() const { return &connection_; }\n\n  uint64_t streamId() const { return stream_id_; }\n  Buffer::BufferMemoryAccountSharedPtr account() const { return account_; }\n\n  Buffer::InstancePtr& bufferedRequestData() { return buffered_request_data_; }\n\n  void contextOnContinue(ScopeTrackedObjectStack& tracked_object_stack);\n\n  void onDownstreamReset() { state_.saw_downstream_reset_ = true; }\n\nprivate:\n  // Indicates which filter to start the iteration with.\n  enum class FilterIterationStartState { AlwaysStartFromNext, CanStartFromCurrent };\n\n  // Returns the encoder filter to start iteration with.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator\n  commonEncodePrefix(ActiveStreamEncoderFilter* filter, bool end_stream,\n                     FilterIterationStartState filter_iteration_start_state);\n  // Returns the decoder filter to start iteration with.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator\n  commonDecodePrefix(ActiveStreamDecoderFilter* filter,\n                     FilterIterationStartState filter_iteration_start_state);\n  void addDecodedData(ActiveStreamDecoderFilter& filter, Buffer::Instance& data, bool streaming);\n  RequestTrailerMap& addDecodedTrailers();\n  MetadataMapVector& addDecodedMetadata();\n  // Helper function for the case where we have a header only request, but a filter adds a body\n  // to it.\n  void maybeContinueDecoding(\n      const std::list<ActiveStreamDecoderFilterPtr>::iterator& maybe_continue_data_entry);\n  void decodeHeaders(ActiveStreamDecoderFilter* filter, RequestHeaderMap& headers, bool end_stream);\n  // Sends data through decoding filter chains. filter_iteration_start_state indicates which\n  // filter to start the iteration with.\n  void decodeData(ActiveStreamDecoderFilter* filter, Buffer::Instance& data, bool end_stream,\n                  FilterIterationStartState filter_iteration_start_state);\n  void decodeTrailers(ActiveStreamDecoderFilter* filter, RequestTrailerMap& trailers);\n  void decodeMetadata(ActiveStreamDecoderFilter* filter, MetadataMap& metadata_map);\n  void addEncodedData(ActiveStreamEncoderFilter& filter, Buffer::Instance& data, bool streaming);\n  ResponseTrailerMap& addEncodedTrailers();\n  void encode1xxHeaders(ActiveStreamEncoderFilter* filter, ResponseHeaderMap& headers);\n  // As with most of the encode functions, this runs encodeHeaders on various\n  // filters before calling encodeHeadersInternal which does final header munging and passes the\n  // headers to the encoder.\n  void maybeContinueEncoding(\n      const std::list<ActiveStreamEncoderFilterPtr>::iterator& maybe_continue_data_entry);\n  void encodeHeaders(ActiveStreamEncoderFilter* filter, ResponseHeaderMap& headers,\n                     bool end_stream);\n  // Sends data through encoding filter chains. filter_iteration_start_state indicates which\n  // filter to start the iteration with, and finally calls encodeDataInternal\n  // to update stats, do end stream bookkeeping, and send the data to encoder.\n  void encodeData(ActiveStreamEncoderFilter* filter, Buffer::Instance& data, bool end_stream,\n                  FilterIterationStartState filter_iteration_start_state);\n  void encodeTrailers(ActiveStreamEncoderFilter* filter, ResponseTrailerMap& trailers);\n  void encodeMetadata(ActiveStreamEncoderFilter* filter, MetadataMapPtr&& metadata_map_ptr);\n\n  // Returns true if new metadata is decoded. Otherwise, returns false.\n  bool processNewlyAddedMetadata();\n\n  // Returns true if filter has stopped iteration for all frame types. Otherwise, returns false.\n  // filter_streaming is the variable to indicate if stream is streaming, and its value may be\n  // changed by the function.\n  bool handleDataIfStopAll(ActiveStreamFilterBase& filter, Buffer::Instance& data,\n                           bool& filter_streaming);\n\n  MetadataMapVector* getRequestMetadataMapVector() {\n    if (request_metadata_map_vector_ == nullptr) {\n      request_metadata_map_vector_ = std::make_unique<MetadataMapVector>();\n    }\n    return request_metadata_map_vector_.get();\n  }\n\n  FilterManagerCallbacks& filter_manager_callbacks_;\n  Event::Dispatcher& dispatcher_;\n  const Network::Connection& connection_;\n  const uint64_t stream_id_;\n  Buffer::BufferMemoryAccountSharedPtr account_;\n  const bool proxy_100_continue_;\n\n  std::list<ActiveStreamDecoderFilterPtr> decoder_filters_;\n  std::list<ActiveStreamEncoderFilterPtr> encoder_filters_;\n  std::list<StreamFilterBase*> filters_;\n  std::list<AccessLog::InstanceSharedPtr> access_log_handlers_;\n\n  // Stores metadata added in the decoding filter that is being processed. Will be cleared before\n  // processing the next filter. The storage is created on demand. We need to store metadata\n  // temporarily in the filter in case the filter has stopped all while processing headers.\n  std::unique_ptr<MetadataMapVector> request_metadata_map_vector_;\n  Buffer::InstancePtr buffered_response_data_;\n  Buffer::InstancePtr buffered_request_data_;\n  uint32_t buffer_limit_{0};\n  uint32_t high_watermark_count_{0};\n  std::list<DownstreamWatermarkCallbacks*> watermark_callbacks_;\n  Network::Socket::OptionsSharedPtr upstream_options_ =\n      std::make_shared<Network::Socket::Options>();\n  absl::optional<absl::string_view> upstream_override_host_;\n\n  FilterChainFactory& filter_chain_factory_;\n  const LocalReply::LocalReply& local_reply_;\n  OverridableRemoteConnectionInfoSetterStreamInfo stream_info_;\n  // TODO(snowp): Once FM has been moved to its own file we'll make these private classes of FM,\n  // at which point they no longer need to be friends.\n  friend ActiveStreamFilterBase;\n  friend ActiveStreamDecoderFilter;\n  friend ActiveStreamEncoderFilter;\n\n  /**\n   * Flags that keep track of which filter calls are currently in progress.\n   */\n  // clang-format off\n    struct FilterCallState {\n      static constexpr uint32_t DecodeHeaders   = 0x01;\n      static constexpr uint32_t DecodeData      = 0x02;\n      static constexpr uint32_t DecodeTrailers  = 0x04;\n      static constexpr uint32_t EncodeHeaders   = 0x08;\n      static constexpr uint32_t EncodeData      = 0x10;\n      static constexpr uint32_t EncodeTrailers  = 0x20;\n      // Encode1xxHeaders is a bit of a special state as 1xx\n      // headers may be sent during request processing. This state is only used\n      // to verify we do not encode1xx headers more than once per\n      // filter.\n      static constexpr uint32_t Encode1xxHeaders  = 0x40;\n      // Used to indicate that we're processing the final [En|De]codeData frame,\n      // i.e. end_stream = true\n      static constexpr uint32_t LastDataFrame = 0x80;\n    };\n  // clang-format on\n\n  struct State {\n    State()\n        : remote_encode_complete_(false), remote_decode_complete_(false), local_complete_(false),\n          has_1xx_headers_(false), created_filter_chain_(false), is_head_request_(false),\n          is_grpc_request_(false), non_100_response_headers_encoded_(false),\n          under_on_local_reply_(false), decoder_filter_chain_aborted_(false),\n          encoder_filter_chain_aborted_(false), saw_downstream_reset_(false) {}\n    uint32_t filter_call_state_{0};\n\n    bool remote_encode_complete_ : 1;\n    bool remote_decode_complete_ : 1;\n    bool local_complete_ : 1; // This indicates that local is complete prior to filter processing.\n                              // A filter can still stop the stream from being complete as seen\n                              // by the codec.\n    // By default, we will assume there are no 1xx. If encode1xxHeaders\n    // is ever called, this is set to true so commonContinue resumes processing the 1xx.\n    bool has_1xx_headers_ : 1;\n    bool created_filter_chain_ : 1;\n    // These two are latched on initial header read, to determine if the original headers\n    // constituted a HEAD or gRPC request, respectively.\n    bool is_head_request_ : 1;\n    bool is_grpc_request_ : 1;\n    // Tracks if headers other than 100-Continue have been encoded to the codec.\n    bool non_100_response_headers_encoded_ : 1;\n    // True under the stack of onLocalReply, false otherwise.\n    bool under_on_local_reply_ : 1;\n    // True when the filter chain iteration was aborted with local reply.\n    bool decoder_filter_chain_aborted_ : 1;\n    bool encoder_filter_chain_aborted_ : 1;\n    bool saw_downstream_reset_ : 1;\n\n    // The following 3 members are booleans rather than part of the space-saving bitfield as they\n    // are passed as arguments to functions expecting bools. Extend State using the bitfield\n    // where possible.\n    bool encoder_filters_streaming_{true};\n    bool decoder_filters_streaming_{true};\n    bool destroyed_{false};\n\n    // Used to track which filter is the latest filter that has received data.\n    ActiveStreamEncoderFilter* latest_data_encoding_filter_{};\n    ActiveStreamDecoderFilter* latest_data_decoding_filter_{};\n  };\n\n  State state_;\n};\n\n} // namespace Http\n} // namespace Envoy\n", "#include \"source/common/http/http1/codec_impl.h\"\n\n#include <memory>\n#include <string>\n\n#include \"envoy/buffer/buffer.h\"\n#include \"envoy/common/optref.h\"\n#include \"envoy/http/codec.h\"\n#include \"envoy/http/header_map.h\"\n#include \"envoy/network/connection.h\"\n\n#include \"source/common/common/cleanup.h\"\n#include \"source/common/common/dump_state_utils.h\"\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/scope_tracker.h\"\n#include \"source/common/common/statusor.h\"\n#include \"source/common/common/utility.h\"\n#include \"source/common/grpc/common.h\"\n#include \"source/common/http/exception.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/http/headers.h\"\n#include \"source/common/http/http1/header_formatter.h\"\n#include \"source/common/http/http1/legacy_parser_impl.h\"\n#include \"source/common/http/utility.h\"\n#include \"source/common/runtime/runtime_features.h\"\n\n#include \"absl/container/fixed_array.h\"\n#include \"absl/strings/ascii.h\"\n\nnamespace Envoy {\nnamespace Http {\nnamespace Http1 {\nnamespace {\n\n// Changes or additions to details should be reflected in\n// docs/root/configuration/http/http_conn_man/response_code_details.rst\nstruct Http1ResponseCodeDetailValues {\n  const absl::string_view TooManyHeaders = \"http1.too_many_headers\";\n  const absl::string_view HeadersTooLarge = \"http1.headers_too_large\";\n  const absl::string_view HttpCodecError = \"http1.codec_error\";\n  const absl::string_view InvalidCharacters = \"http1.invalid_characters\";\n  const absl::string_view ConnectionHeaderSanitization = \"http1.connection_header_rejected\";\n  const absl::string_view InvalidUrl = \"http1.invalid_url\";\n  const absl::string_view InvalidTransferEncoding = \"http1.invalid_transfer_encoding\";\n  const absl::string_view BodyDisallowed = \"http1.body_disallowed\";\n  const absl::string_view TransferEncodingNotAllowed = \"http1.transfer_encoding_not_allowed\";\n  const absl::string_view ContentLengthNotAllowed = \"http1.content_length_not_allowed\";\n  const absl::string_view InvalidUnderscore = \"http1.unexpected_underscore\";\n  const absl::string_view ChunkedContentLength = \"http1.content_length_and_chunked_not_allowed\";\n  const absl::string_view HttpsInPlaintext = \"http1.https_url_on_plaintext_connection\";\n  const absl::string_view InvalidScheme = \"http1.invalid_scheme\";\n};\n\nstruct Http1HeaderTypesValues {\n  const absl::string_view Headers = \"headers\";\n  const absl::string_view Trailers = \"trailers\";\n};\n\n// Pipelining is generally not well supported on the internet and has a series of dangerous\n// overflow bugs. As such Envoy disabled it.\nstatic constexpr uint32_t kMaxOutboundResponses = 2;\n\nusing Http1ResponseCodeDetails = ConstSingleton<Http1ResponseCodeDetailValues>;\nusing Http1HeaderTypes = ConstSingleton<Http1HeaderTypesValues>;\n\nconst StringUtil::CaseUnorderedSet& caseUnorderdSetContainingUpgradeAndHttp2Settings() {\n  CONSTRUCT_ON_FIRST_USE(StringUtil::CaseUnorderedSet,\n                         Http::Headers::get().ConnectionValues.Upgrade,\n                         Http::Headers::get().ConnectionValues.Http2Settings);\n}\n\nHeaderKeyFormatterConstPtr encodeOnlyFormatterFromSettings(const Http::Http1Settings& settings) {\n  if (settings.header_key_format_ == Http1Settings::HeaderKeyFormat::ProperCase) {\n    return std::make_unique<ProperCaseHeaderKeyFormatter>();\n  }\n\n  return nullptr;\n}\n\nStatefulHeaderKeyFormatterPtr statefulFormatterFromSettings(const Http::Http1Settings& settings) {\n  if (settings.header_key_format_ == Http1Settings::HeaderKeyFormat::StatefulFormatter) {\n    return settings.stateful_header_key_formatter_->create();\n  }\n  return nullptr;\n}\n\nconstexpr size_t CRLF_SIZE = 2;\n\n} // namespace\n\nstatic constexpr absl::string_view CRLF = \"\\r\\n\";\n// Last chunk as defined here https://tools.ietf.org/html/rfc7230#section-4.1\nstatic constexpr absl::string_view LAST_CHUNK = \"0\\r\\n\";\n\nstatic constexpr absl::string_view SPACE = \" \";\nstatic constexpr absl::string_view COLON_SPACE = \": \";\n\nStreamEncoderImpl::StreamEncoderImpl(ConnectionImpl& connection,\n                                     StreamInfo::BytesMeterSharedPtr&& bytes_meter)\n    : connection_(connection), disable_chunk_encoding_(false), chunk_encoding_(true),\n      connect_request_(false), is_tcp_tunneling_(false), is_response_to_head_request_(false),\n      is_response_to_connect_request_(false), bytes_meter_(std::move(bytes_meter)) {\n  if (!bytes_meter_) {\n    bytes_meter_ = std::make_shared<StreamInfo::BytesMeter>();\n  }\n  if (connection_.connection().aboveHighWatermark()) {\n    runHighWatermarkCallbacks();\n  }\n}\n\nvoid StreamEncoderImpl::encodeHeader(absl::string_view key, absl::string_view value) {\n  ASSERT(!key.empty());\n\n  const uint64_t header_size = connection_.buffer().addFragments({key, COLON_SPACE, value, CRLF});\n\n  bytes_meter_->addHeaderBytesSent(header_size);\n}\n\nvoid StreamEncoderImpl::encodeFormattedHeader(absl::string_view key, absl::string_view value,\n                                              HeaderKeyFormatterOptConstRef formatter) {\n  if (formatter.has_value()) {\n    encodeHeader(formatter->format(key), value);\n  } else {\n    encodeHeader(key, value);\n  }\n}\n\nvoid ResponseEncoderImpl::encode1xxHeaders(const ResponseHeaderMap& headers) {\n  ASSERT(HeaderUtility::isSpecial1xx(headers));\n  encodeHeaders(headers, false);\n}\n\nvoid StreamEncoderImpl::encodeHeadersBase(const RequestOrResponseHeaderMap& headers,\n                                          absl::optional<uint64_t> status, bool end_stream,\n                                          bool bodiless_request) {\n  HeaderKeyFormatterOptConstRef formatter(headers.formatter());\n  if (!formatter.has_value()) {\n    formatter = connection_.formatter();\n  }\n\n  const Http::HeaderValues& header_values = Http::Headers::get();\n  bool saw_content_length = false;\n  headers.iterate(\n      [this, &header_values, formatter](const HeaderEntry& header) -> HeaderMap::Iterate {\n        absl::string_view key_to_use = header.key().getStringView();\n        uint32_t key_size_to_use = header.key().size();\n        // Translate :authority -> host so that upper layers do not need to deal with this.\n        if (key_size_to_use > 1 && key_to_use[0] == ':' && key_to_use[1] == 'a') {\n          key_to_use = absl::string_view(header_values.HostLegacy.get());\n          key_size_to_use = header_values.HostLegacy.get().size();\n        }\n\n        // Skip all headers starting with ':' that make it here.\n        if (key_to_use[0] == ':') {\n          return HeaderMap::Iterate::Continue;\n        }\n\n        encodeFormattedHeader(key_to_use, header.value().getStringView(), formatter);\n\n        return HeaderMap::Iterate::Continue;\n      });\n\n  if (headers.ContentLength()) {\n    saw_content_length = true;\n  }\n\n  ASSERT(!headers.TransferEncoding());\n\n  // Assume we are chunk encoding unless we are passed a content length or this is a header only\n  // response. Upper layers generally should strip transfer-encoding since it only applies to\n  // HTTP/1.1. The codec will infer it based on the type of response.\n  // for streaming (e.g. SSE stream sent to hystrix dashboard), we do not want\n  // chunk transfer encoding but we don't have a content-length so disable_chunk_encoding_ is\n  // consulted before enabling chunk encoding.\n  //\n  // Note that for HEAD requests Envoy does best-effort guessing when there is no\n  // content-length. If a client makes a HEAD request for an upstream resource\n  // with no bytes but the upstream response doesn't include \"Content-length: 0\",\n  // Envoy will incorrectly assume a subsequent response to GET will be chunk encoded.\n  if (saw_content_length || disable_chunk_encoding_) {\n    chunk_encoding_ = false;\n  } else {\n    if (status && (*status < 200 || *status == 204)) {\n      // For 1xx and 204 responses, do not send the chunked encoding header or enable chunked\n      // encoding: https://tools.ietf.org/html/rfc7230#section-3.3.1\n      chunk_encoding_ = false;\n    } else if (status && *status == 304) {\n      // For 304 response, since it should never have a body, we should not need to chunk_encode at\n      // all.\n      chunk_encoding_ = false;\n    } else if (end_stream && !is_response_to_head_request_) {\n      // If this is a headers-only stream, append an explicit \"Content-Length: 0\" unless it's a\n      // response to a HEAD request.\n      // For 204s and 1xx where content length is disallowed, don't append the content length but\n      // also don't chunk encode.\n      // Also do not add content length for requests which should not have a\n      // body, per https://tools.ietf.org/html/rfc7230#section-3.3.2\n      if (!status || (*status >= 200 && *status != 204)) {\n        if (!bodiless_request) {\n          encodeFormattedHeader(header_values.ContentLength.get(), \"0\", formatter);\n        }\n      }\n      chunk_encoding_ = false;\n    } else if (connection_.protocol() == Protocol::Http10) {\n      chunk_encoding_ = false;\n    } else {\n      // For responses to connect requests, do not send the chunked encoding header:\n      // https://tools.ietf.org/html/rfc7231#section-4.3.6.\n      if (!is_response_to_connect_request_) {\n        encodeFormattedHeader(header_values.TransferEncoding.get(),\n                              header_values.TransferEncodingValues.Chunked, formatter);\n      }\n      // We do not apply chunk encoding for HTTP upgrades, including CONNECT style upgrades.\n      // If there is a body in a response on the upgrade path, the chunks will be\n      // passed through via maybeDirectDispatch so we need to avoid appending\n      // extra chunk boundaries.\n      //\n      // When sending a response to a HEAD request Envoy may send an informational\n      // \"Transfer-Encoding: chunked\" header, but should not send a chunk encoded body.\n      chunk_encoding_ = !Utility::isUpgrade(headers) && !is_response_to_head_request_ &&\n                        !is_response_to_connect_request_;\n    }\n  }\n\n  connection_.buffer().add(CRLF);\n\n  if (end_stream) {\n    endEncode();\n  } else {\n    flushOutput();\n  }\n}\n\nvoid StreamEncoderImpl::encodeData(Buffer::Instance& data, bool end_stream) {\n  // end_stream may be indicated with a zero length data buffer. If that is the case, so not\n  // actually write the zero length buffer out.\n  if (data.length() > 0) {\n    if (chunk_encoding_) {\n      std::string chunk_header = absl::StrCat(absl::Hex(data.length()), CRLF);\n      connection_.buffer().add(std::move(chunk_header));\n    }\n\n    connection_.buffer().move(data);\n\n    if (chunk_encoding_) {\n      connection_.buffer().add(CRLF);\n    }\n  }\n\n  if (end_stream) {\n    endEncode();\n  } else {\n    flushOutput();\n  }\n}\n\nvoid StreamEncoderImpl::flushOutput(bool end_encode) {\n  auto encoded_bytes = connection_.flushOutput(end_encode);\n  bytes_meter_->addWireBytesSent(encoded_bytes);\n}\n\nvoid StreamEncoderImpl::encodeTrailersBase(const HeaderMap& trailers) {\n  if (!connection_.enableTrailers()) {\n    return endEncode();\n  }\n  // Trailers only matter if it is a chunk transfer encoding\n  // https://tools.ietf.org/html/rfc7230#section-4.4\n  if (chunk_encoding_) {\n    // Finalize the body\n    connection_.buffer().add(LAST_CHUNK);\n\n    // TODO(mattklein123): Wire up the formatter if someone actually asks for this (very unlikely).\n    trailers.iterate([this](const HeaderEntry& header) -> HeaderMap::Iterate {\n      encodeFormattedHeader(header.key().getStringView(), header.value().getStringView(),\n                            HeaderKeyFormatterOptConstRef());\n      return HeaderMap::Iterate::Continue;\n    });\n\n    connection_.buffer().add(CRLF);\n  }\n\n  flushOutput();\n  connection_.onEncodeComplete();\n}\n\nvoid StreamEncoderImpl::encodeMetadata(const MetadataMapVector&) {\n  connection_.stats().metadata_not_supported_error_.inc();\n}\n\nvoid StreamEncoderImpl::endEncode() {\n  if (chunk_encoding_) {\n    connection_.buffer().addFragments({LAST_CHUNK, CRLF});\n  }\n\n  flushOutput(true);\n  connection_.onEncodeComplete();\n  // With CONNECT or TCP tunneling, half-closing the connection is used to signal end stream.\n  if (connect_request_ || is_tcp_tunneling_) {\n    connection_.connection().close(Network::ConnectionCloseType::FlushWriteAndDelay);\n  }\n}\n\nvoid ServerConnectionImpl::maybeAddSentinelBufferFragment(Buffer::Instance& output_buffer) {\n  // It's messy and complicated to try to tag the final write of an HTTP response for response\n  // tracking for flood protection. Instead, write an empty buffer fragment after the response,\n  // to allow for tracking.\n  // When the response is written out, the fragment will be deleted and the counter will be updated\n  // by ServerConnectionImpl::releaseOutboundResponse()\n  auto fragment =\n      Buffer::OwnedBufferFragmentImpl::create(absl::string_view(\"\", 0), response_buffer_releasor_);\n  output_buffer.addBufferFragment(*fragment.release());\n  ASSERT(outbound_responses_ < kMaxOutboundResponses);\n  outbound_responses_++;\n}\n\nStatus ServerConnectionImpl::doFloodProtectionChecks() const {\n  ASSERT(dispatching_);\n  // Before processing another request, make sure that we are below the response flood protection\n  // threshold.\n  if (outbound_responses_ >= kMaxOutboundResponses) {\n    ENVOY_CONN_LOG(trace, \"error accepting request: too many pending responses queued\",\n                   connection_);\n    stats_.response_flood_.inc();\n    return bufferFloodError(\"Too many responses queued.\");\n  }\n  return okStatus();\n}\n\nuint64_t ConnectionImpl::flushOutput(bool end_encode) {\n  if (end_encode) {\n    // If this is an HTTP response in ServerConnectionImpl, track outbound responses for flood\n    // protection\n    maybeAddSentinelBufferFragment(*output_buffer_);\n  }\n  const uint64_t bytes_encoded = output_buffer_->length();\n  connection().write(*output_buffer_, false);\n  ASSERT(0UL == output_buffer_->length());\n  return bytes_encoded;\n}\n\nvoid StreamEncoderImpl::resetStream(StreamResetReason reason) {\n  connection_.onResetStreamBase(reason);\n}\n\nvoid ResponseEncoderImpl::resetStream(StreamResetReason reason) {\n  // Clear the downstream on the account since we're resetting the downstream.\n  if (buffer_memory_account_) {\n    buffer_memory_account_->clearDownstream();\n  }\n\n  // For H1, we use idleTimeouts to cancel streams unless there was an\n  // explicit protocol error prior to sending a response to the downstream\n  // in which case we send a local reply.\n  // TODO(kbaichoo): If we want snappier resets of H1 streams we can\n  //  1) Send local reply if no response data sent yet\n  //  2) Invoke the idle timeout sooner to close underlying connection\n  StreamEncoderImpl::resetStream(reason);\n}\n\nvoid StreamEncoderImpl::readDisable(bool disable) {\n  if (disable) {\n    ++read_disable_calls_;\n  } else {\n    ASSERT(read_disable_calls_ != 0);\n    if (read_disable_calls_ != 0) {\n      --read_disable_calls_;\n    }\n  }\n  connection_.readDisable(disable);\n}\n\nuint32_t StreamEncoderImpl::bufferLimit() const { return connection_.bufferLimit(); }\n\nconst Network::Address::InstanceConstSharedPtr& StreamEncoderImpl::connectionLocalAddress() {\n  return connection_.connection().connectionInfoProvider().localAddress();\n}\n\nstatic constexpr absl::string_view RESPONSE_PREFIX = \"HTTP/1.1 \";\nstatic constexpr absl::string_view HTTP_10_RESPONSE_PREFIX = \"HTTP/1.0 \";\n\nvoid ResponseEncoderImpl::encodeHeaders(const ResponseHeaderMap& headers, bool end_stream) {\n  started_response_ = true;\n\n  // The contract is that client codecs must ensure that :status is present.\n  ASSERT(headers.Status() != nullptr);\n  uint64_t numeric_status = Utility::getResponseStatus(headers);\n\n  absl::string_view response_prefix;\n  if (connection_.protocol() == Protocol::Http10 && connection_.supportsHttp10()) {\n    response_prefix = HTTP_10_RESPONSE_PREFIX;\n  } else {\n    response_prefix = RESPONSE_PREFIX;\n  }\n\n  StatefulHeaderKeyFormatterOptConstRef formatter(headers.formatter());\n\n  absl::string_view reason_phrase;\n  if (formatter.has_value() && !formatter->getReasonPhrase().empty()) {\n    reason_phrase = formatter->getReasonPhrase();\n  } else {\n    const char* status_string = CodeUtility::toString(static_cast<Code>(numeric_status));\n    uint32_t status_string_len = strlen(status_string);\n    reason_phrase = {status_string, status_string_len};\n  }\n\n  connection_.buffer().addFragments(\n      {response_prefix, absl::StrCat(numeric_status), SPACE, reason_phrase, CRLF});\n\n  if (numeric_status >= 300) {\n    // Don't do special CONNECT logic if the CONNECT was rejected.\n    is_response_to_connect_request_ = false;\n  }\n\n  encodeHeadersBase(headers, absl::make_optional<uint64_t>(numeric_status), end_stream, false);\n}\n\nstatic constexpr absl::string_view REQUEST_POSTFIX = \" HTTP/1.1\\r\\n\";\n\nStatus RequestEncoderImpl::encodeHeaders(const RequestHeaderMap& headers, bool end_stream) {\n  // Required headers must be present. This can only happen by some erroneous processing after the\n  // downstream codecs decode.\n  RETURN_IF_ERROR(HeaderUtility::checkRequiredRequestHeaders(headers));\n\n  const HeaderEntry* method = headers.Method();\n  const HeaderEntry* path = headers.Path();\n  const HeaderEntry* host = headers.Host();\n  bool is_connect = HeaderUtility::isConnect(headers);\n  const Http::HeaderValues& header_values = Http::Headers::get();\n\n  if (method->value() == header_values.MethodValues.Head) {\n    head_request_ = true;\n  } else if (method->value() == header_values.MethodValues.Connect) {\n    disableChunkEncoding();\n    connection_.connection().enableHalfClose(true);\n    connect_request_ = true;\n  }\n  if (Utility::isUpgrade(headers)) {\n    upgrade_request_ = true;\n  }\n\n  absl::string_view host_or_path_view;\n  if (is_connect) {\n    host_or_path_view = host->value().getStringView();\n  } else {\n    host_or_path_view = path->value().getStringView();\n  }\n\n  connection_.buffer().addFragments(\n      {method->value().getStringView(), SPACE, host_or_path_view, REQUEST_POSTFIX});\n\n  encodeHeadersBase(headers, absl::nullopt, end_stream,\n                    HeaderUtility::requestShouldHaveNoBody(headers));\n  return okStatus();\n}\n\nint ConnectionImpl::setAndCheckCallbackStatus(Status&& status) {\n  ASSERT(codec_status_.ok());\n  codec_status_ = std::move(status);\n  return codec_status_.ok() ? parser_->statusToInt(ParserStatus::Success)\n                            : parser_->statusToInt(ParserStatus::Error);\n}\n\nint ConnectionImpl::setAndCheckCallbackStatusOr(Envoy::StatusOr<ParserStatus>&& statusor) {\n  ASSERT(codec_status_.ok());\n  if (statusor.ok()) {\n    return parser_->statusToInt(statusor.value());\n  } else {\n    codec_status_ = std::move(statusor.status());\n    return parser_->statusToInt(ParserStatus::Error);\n  }\n}\n\nConnectionImpl::ConnectionImpl(Network::Connection& connection, CodecStats& stats,\n                               const Http1Settings& settings, MessageType type,\n                               uint32_t max_headers_kb, const uint32_t max_headers_count)\n    : connection_(connection), stats_(stats), codec_settings_(settings),\n      encode_only_header_key_formatter_(encodeOnlyFormatterFromSettings(settings)),\n      processing_trailers_(false), handling_upgrade_(false), reset_stream_called_(false),\n      deferred_end_stream_headers_(false), dispatching_(false),\n      output_buffer_(connection.dispatcher().getWatermarkFactory().createBuffer(\n          [&]() -> void { this->onBelowLowWatermark(); },\n          [&]() -> void { this->onAboveHighWatermark(); },\n          []() -> void { /* TODO(adisuissa): Handle overflow watermark */ })),\n      max_headers_kb_(max_headers_kb), max_headers_count_(max_headers_count) {\n  output_buffer_->setWatermarks(connection.bufferLimit());\n  parser_ = std::make_unique<LegacyHttpParserImpl>(type, this);\n}\n\nStatus ConnectionImpl::completeLastHeader() {\n  ASSERT(dispatching_);\n  ENVOY_CONN_LOG(trace, \"completed header: key={} value={}\", connection_,\n                 current_header_field_.getStringView(), current_header_value_.getStringView());\n  auto& headers_or_trailers = headersOrTrailers();\n\n  // Account for \":\" and \"\\r\\n\" bytes between the header key value pair.\n  getBytesMeter().addHeaderBytesReceived(CRLF_SIZE + 1);\n\n  // TODO(10646): Switch to use HeaderUtility::checkHeaderNameForUnderscores().\n  RETURN_IF_ERROR(checkHeaderNameForUnderscores());\n  if (!current_header_field_.empty()) {\n    // Strip trailing whitespace of the current header value if any. Leading whitespace was trimmed\n    // in ConnectionImpl::onHeaderValue. http_parser does not strip leading or trailing whitespace\n    // as the spec requires: https://tools.ietf.org/html/rfc7230#section-3.2.4\n    current_header_value_.rtrim();\n\n    // If there is a stateful formatter installed, remember the original header key before\n    // converting to lower case.\n    auto formatter = headers_or_trailers.formatter();\n    if (formatter.has_value()) {\n      formatter->processKey(current_header_field_.getStringView());\n    }\n    current_header_field_.inlineTransform([](char c) { return absl::ascii_tolower(c); });\n\n    headers_or_trailers.addViaMove(std::move(current_header_field_),\n                                   std::move(current_header_value_));\n  }\n\n  // Check if the number of headers exceeds the limit.\n  if (headers_or_trailers.size() > max_headers_count_) {\n    error_code_ = Http::Code::RequestHeaderFieldsTooLarge;\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().TooManyHeaders));\n    const absl::string_view header_type =\n        processing_trailers_ ? Http1HeaderTypes::get().Trailers : Http1HeaderTypes::get().Headers;\n    return codecProtocolError(absl::StrCat(header_type, \" count exceeds limit\"));\n  }\n\n  header_parsing_state_ = HeaderParsingState::Field;\n  ASSERT(current_header_field_.empty());\n  ASSERT(current_header_value_.empty());\n  return okStatus();\n}\n\nuint32_t ConnectionImpl::getHeadersSize() {\n  return current_header_field_.size() + current_header_value_.size() +\n         headersOrTrailers().byteSize();\n}\n\nStatus ConnectionImpl::checkMaxHeadersSize() {\n  const uint32_t total = getHeadersSize();\n  if (total > (max_headers_kb_ * 1024)) {\n    const absl::string_view header_type =\n        processing_trailers_ ? Http1HeaderTypes::get().Trailers : Http1HeaderTypes::get().Headers;\n    error_code_ = Http::Code::RequestHeaderFieldsTooLarge;\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().HeadersTooLarge));\n    return codecProtocolError(absl::StrCat(header_type, \" size exceeds limit\"));\n  }\n  return okStatus();\n}\n\nbool ConnectionImpl::maybeDirectDispatch(Buffer::Instance& data) {\n  if (!handling_upgrade_) {\n    // Only direct dispatch for Upgrade requests.\n    return false;\n  }\n\n  ENVOY_CONN_LOG(trace, \"direct-dispatched {} bytes\", connection_, data.length());\n  onBody(data);\n  data.drain(data.length());\n  return true;\n}\n\nvoid ConnectionImpl::onDispatch(const Buffer::Instance& data) {\n  getBytesMeter().addWireBytesReceived(data.length());\n}\n\nHttp::Status ClientConnectionImpl::dispatch(Buffer::Instance& data) {\n  Http::Status status = ConnectionImpl::dispatch(data);\n  if (status.ok() && data.length() > 0) {\n    // The HTTP/1.1 codec pauses dispatch after a single response is complete. Extraneous data\n    // after a response is complete indicates an error.\n    return codecProtocolError(\"http/1.1 protocol error: extraneous data after response complete\");\n  }\n  return status;\n}\n\nHttp::Status ConnectionImpl::dispatch(Buffer::Instance& data) {\n  // Add self to the Dispatcher's tracked object stack.\n  ScopeTrackerScopeState scope(this, connection_.dispatcher());\n  ENVOY_CONN_LOG(trace, \"parsing {} bytes\", connection_, data.length());\n  // Make sure that dispatching_ is set to false after dispatching, even when\n  // http_parser exits early with an error code.\n  Cleanup cleanup([this]() { dispatching_ = false; });\n  ASSERT(!dispatching_);\n  ASSERT(codec_status_.ok());\n  ASSERT(buffered_body_.length() == 0);\n\n  dispatching_ = true;\n  onDispatch(data);\n  if (maybeDirectDispatch(data)) {\n    return Http::okStatus();\n  }\n\n  // Always resume before dispatch.\n  parser_->resume();\n\n  ssize_t total_parsed = 0;\n  if (data.length() > 0) {\n    current_dispatching_buffer_ = &data;\n    while (data.length() > 0) {\n      auto slice = data.frontSlice();\n      dispatching_slice_already_drained_ = false;\n      auto statusor_parsed = dispatchSlice(static_cast<const char*>(slice.mem_), slice.len_);\n      if (!statusor_parsed.ok()) {\n        return statusor_parsed.status();\n      }\n      if (!dispatching_slice_already_drained_) {\n        ASSERT(statusor_parsed.value() <= slice.len_);\n        data.drain(statusor_parsed.value());\n      }\n\n      total_parsed += statusor_parsed.value();\n      if (parser_->getStatus() != ParserStatus::Success) {\n        // Parse errors trigger an exception in dispatchSlice so we are guaranteed to be paused at\n        // this point.\n        ASSERT(parser_->getStatus() == ParserStatus::Paused);\n        break;\n      }\n    }\n    current_dispatching_buffer_ = nullptr;\n    dispatchBufferedBody();\n  } else {\n    auto result = dispatchSlice(nullptr, 0);\n    if (!result.ok()) {\n      return result.status();\n    }\n  }\n  ASSERT(buffered_body_.length() == 0);\n\n  ENVOY_CONN_LOG(trace, \"parsed {} bytes\", connection_, total_parsed);\n\n  // If an upgrade has been handled and there is body data or early upgrade\n  // payload to send on, send it on.\n  maybeDirectDispatch(data);\n  return Http::okStatus();\n}\n\nEnvoy::StatusOr<size_t> ConnectionImpl::dispatchSlice(const char* slice, size_t len) {\n  ASSERT(codec_status_.ok() && dispatching_);\n  auto [nread, rc] = parser_->execute(slice, len);\n  if (!codec_status_.ok()) {\n    return codec_status_;\n  }\n\n  if (rc != parser_->statusToInt(ParserStatus::Success) &&\n      rc != parser_->statusToInt(ParserStatus::Paused)) {\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().HttpCodecError));\n    // Avoid overwriting the codec_status_ set in the callbacks.\n    ASSERT(codec_status_.ok());\n    codec_status_ =\n        codecProtocolError(absl::StrCat(\"http/1.1 protocol error: \", parser_->errnoName(rc)));\n    return codec_status_;\n  }\n\n  return nread;\n}\n\nStatus ConnectionImpl::onHeaderField(const char* data, size_t length) {\n  ASSERT(dispatching_);\n\n  getBytesMeter().addHeaderBytesReceived(length);\n\n  // We previously already finished up the headers, these headers are\n  // now trailers.\n  if (header_parsing_state_ == HeaderParsingState::Done) {\n    if (!enableTrailers()) {\n      // Ignore trailers.\n      return okStatus();\n    }\n    processing_trailers_ = true;\n    header_parsing_state_ = HeaderParsingState::Field;\n    allocTrailers();\n  }\n  if (header_parsing_state_ == HeaderParsingState::Value) {\n    RETURN_IF_ERROR(completeLastHeader());\n  }\n\n  current_header_field_.append(data, length);\n\n  return checkMaxHeadersSize();\n}\n\nStatus ConnectionImpl::onHeaderValue(const char* data, size_t length) {\n  ASSERT(dispatching_);\n\n  getBytesMeter().addHeaderBytesReceived(length);\n\n  if (header_parsing_state_ == HeaderParsingState::Done && !enableTrailers()) {\n    // Ignore trailers.\n    return okStatus();\n  }\n\n  absl::string_view header_value{data, length};\n  if (!Http::HeaderUtility::headerValueIsValid(header_value)) {\n    ENVOY_CONN_LOG(debug, \"invalid header value: {}\", connection_, header_value);\n    error_code_ = Http::Code::BadRequest;\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidCharacters));\n    return codecProtocolError(\"http/1.1 protocol error: header value contains invalid chars\");\n  }\n\n  header_parsing_state_ = HeaderParsingState::Value;\n  if (current_header_value_.empty()) {\n    // Strip leading whitespace if the current header value input contains the first bytes of the\n    // encoded header value. Trailing whitespace is stripped once the full header value is known in\n    // ConnectionImpl::completeLastHeader. http_parser does not strip leading or trailing whitespace\n    // as the spec requires: https://tools.ietf.org/html/rfc7230#section-3.2.4 .\n    header_value = StringUtil::ltrim(header_value);\n  }\n  current_header_value_.append(header_value.data(), header_value.length());\n\n  return checkMaxHeadersSize();\n}\n\nStatusOr<ParserStatus> ConnectionImpl::onHeadersComplete() {\n  ASSERT(!processing_trailers_);\n  ASSERT(dispatching_);\n  ENVOY_CONN_LOG(trace, \"onHeadersCompleteBase\", connection_);\n  RETURN_IF_ERROR(completeLastHeader());\n\n  if (!(parser_->httpMajor() == 1 && parser_->httpMinor() == 1)) {\n    // This is not necessarily true, but it's good enough since higher layers only care if this is\n    // HTTP/1.1 or not.\n    protocol_ = Protocol::Http10;\n  }\n  RequestOrResponseHeaderMap& request_or_response_headers = requestOrResponseHeaders();\n  const Http::HeaderValues& header_values = Http::Headers::get();\n  if (Utility::isUpgrade(request_or_response_headers) && upgradeAllowed()) {\n    // Ignore h2c upgrade requests until we support them.\n    // See https://github.com/envoyproxy/envoy/issues/7161 for details.\n    if (absl::EqualsIgnoreCase(request_or_response_headers.getUpgradeValue(),\n                               header_values.UpgradeValues.H2c)) {\n      ENVOY_CONN_LOG(trace, \"removing unsupported h2c upgrade headers.\", connection_);\n      request_or_response_headers.removeUpgrade();\n      if (request_or_response_headers.Connection()) {\n        const auto& tokens_to_remove = caseUnorderdSetContainingUpgradeAndHttp2Settings();\n        std::string new_value = StringUtil::removeTokens(\n            request_or_response_headers.getConnectionValue(), \",\", tokens_to_remove, \",\");\n        if (new_value.empty()) {\n          request_or_response_headers.removeConnection();\n        } else {\n          request_or_response_headers.setConnection(new_value);\n        }\n      }\n      request_or_response_headers.remove(header_values.Http2Settings);\n    } else {\n      ENVOY_CONN_LOG(trace, \"codec entering upgrade mode.\", connection_);\n      handling_upgrade_ = true;\n    }\n  }\n  if (parser_->methodName() == header_values.MethodValues.Connect) {\n    if (request_or_response_headers.ContentLength()) {\n      if (request_or_response_headers.getContentLengthValue() == \"0\") {\n        request_or_response_headers.removeContentLength();\n      } else {\n        // Per https://tools.ietf.org/html/rfc7231#section-4.3.6 a payload with a\n        // CONNECT request has no defined semantics, and may be rejected.\n        error_code_ = Http::Code::BadRequest;\n        RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().BodyDisallowed));\n        return codecProtocolError(\"http/1.1 protocol error: unsupported content length\");\n      }\n    }\n    ENVOY_CONN_LOG(trace, \"codec entering upgrade mode for CONNECT request.\", connection_);\n    handling_upgrade_ = true;\n  }\n\n  // https://tools.ietf.org/html/rfc7230#section-3.3.3\n  // If a message is received with both a Transfer-Encoding and a\n  // Content-Length header field, the Transfer-Encoding overrides the\n  // Content-Length. Such a message might indicate an attempt to\n  // perform request smuggling (Section 9.5) or response splitting\n  // (Section 9.4) and ought to be handled as an error. A sender MUST\n  // remove the received Content-Length field prior to forwarding such\n  // a message.\n\n  // Reject message with Http::Code::BadRequest if both Transfer-Encoding and Content-Length\n  // headers are present or if allowed by http1 codec settings and 'Transfer-Encoding'\n  // is chunked - remove Content-Length and serve request.\n  if (parser_->hasTransferEncoding() != 0 && request_or_response_headers.ContentLength()) {\n    if (parser_->isChunked() && codec_settings_.allow_chunked_length_) {\n      request_or_response_headers.removeContentLength();\n    } else {\n      error_code_ = Http::Code::BadRequest;\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().ChunkedContentLength));\n      return codecProtocolError(\n          \"http/1.1 protocol error: both 'Content-Length' and 'Transfer-Encoding' are set.\");\n    }\n  }\n\n  // Per https://tools.ietf.org/html/rfc7230#section-3.3.1 Envoy should reject\n  // transfer-codings it does not understand.\n  // Per https://tools.ietf.org/html/rfc7231#section-4.3.6 a payload with a\n  // CONNECT request has no defined semantics, and may be rejected.\n  if (request_or_response_headers.TransferEncoding()) {\n    const absl::string_view encoding = request_or_response_headers.getTransferEncodingValue();\n    if (!absl::EqualsIgnoreCase(encoding, header_values.TransferEncodingValues.Chunked) ||\n        parser_->methodName() == header_values.MethodValues.Connect) {\n      error_code_ = Http::Code::NotImplemented;\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidTransferEncoding));\n      return codecProtocolError(\"http/1.1 protocol error: unsupported transfer encoding\");\n    }\n  }\n\n  auto statusor = onHeadersCompleteBase();\n  if (!statusor.ok()) {\n    RETURN_IF_ERROR(statusor.status());\n  }\n\n  header_parsing_state_ = HeaderParsingState::Done;\n\n  // Returning ParserStatus::NoBodyData informs http_parser to not expect a body or further data\n  // on this connection.\n  return handling_upgrade_ ? ParserStatus::NoBodyData : statusor.value();\n}\n\nvoid ConnectionImpl::bufferBody(const char* data, size_t length) {\n  auto slice = current_dispatching_buffer_->frontSlice();\n  if (data == slice.mem_ && length == slice.len_) {\n    buffered_body_.move(*current_dispatching_buffer_, length);\n    dispatching_slice_already_drained_ = true;\n  } else {\n    buffered_body_.add(data, length);\n  }\n}\n\nvoid ConnectionImpl::dispatchBufferedBody() {\n  ASSERT(parser_->getStatus() == ParserStatus::Success ||\n         parser_->getStatus() == ParserStatus::Paused);\n  ASSERT(codec_status_.ok());\n  if (buffered_body_.length() > 0) {\n    onBody(buffered_body_);\n    buffered_body_.drain(buffered_body_.length());\n  }\n}\n\nvoid ConnectionImpl::onChunkHeader(bool is_final_chunk) {\n  if (is_final_chunk) {\n    // Dispatch body before parsing trailers, so body ends up dispatched even if an error is found\n    // while processing trailers.\n    dispatchBufferedBody();\n  }\n}\n\nStatusOr<ParserStatus> ConnectionImpl::onMessageComplete() {\n  ENVOY_CONN_LOG(trace, \"message complete\", connection_);\n\n  dispatchBufferedBody();\n\n  if (handling_upgrade_) {\n    // If this is an upgrade request, swallow the onMessageComplete. The\n    // upgrade payload will be treated as stream body.\n    ASSERT(!deferred_end_stream_headers_);\n    ENVOY_CONN_LOG(trace, \"Pausing parser due to upgrade.\", connection_);\n    return parser_->pause();\n  }\n\n  // If true, this indicates we were processing trailers and must\n  // move the last header into current_header_map_\n  if (header_parsing_state_ == HeaderParsingState::Value) {\n    RETURN_IF_ERROR(completeLastHeader());\n  }\n\n  return onMessageCompleteBase();\n}\n\nStatus ConnectionImpl::onMessageBegin() {\n  ENVOY_CONN_LOG(trace, \"message begin\", connection_);\n  // Make sure that if HTTP/1.0 and HTTP/1.1 requests share a connection Envoy correctly sets\n  // protocol for each request. Envoy defaults to 1.1 but sets the protocol to 1.0 where applicable\n  // in onHeadersCompleteBase\n  protocol_ = Protocol::Http11;\n  processing_trailers_ = false;\n  header_parsing_state_ = HeaderParsingState::Field;\n  allocHeaders(statefulFormatterFromSettings(codec_settings_));\n  return onMessageBeginBase();\n}\n\nvoid ConnectionImpl::onResetStreamBase(StreamResetReason reason) {\n  ASSERT(!reset_stream_called_);\n  reset_stream_called_ = true;\n  onResetStream(reason);\n}\n\nvoid ConnectionImpl::dumpState(std::ostream& os, int indent_level) const {\n  const char* spaces = spacesForLevel(indent_level);\n  os << spaces << \"Http1::ConnectionImpl \" << this << DUMP_MEMBER(dispatching_)\n     << DUMP_MEMBER(dispatching_slice_already_drained_) << DUMP_MEMBER(reset_stream_called_)\n     << DUMP_MEMBER(handling_upgrade_) << DUMP_MEMBER(deferred_end_stream_headers_)\n     << DUMP_MEMBER(processing_trailers_) << DUMP_MEMBER(buffered_body_.length());\n\n  // Dump header parsing state, and any progress on headers.\n  os << DUMP_MEMBER(header_parsing_state_);\n  os << DUMP_MEMBER_AS(current_header_field_, current_header_field_.getStringView());\n  os << DUMP_MEMBER_AS(current_header_value_, current_header_value_.getStringView());\n\n  // Dump Child\n  os << '\\n';\n  dumpAdditionalState(os, indent_level);\n\n  // Dump the first slice of the dispatching buffer if not drained escaping\n  // certain characters. We do this last as the slice could be rather large.\n  if (current_dispatching_buffer_ == nullptr || dispatching_slice_already_drained_) {\n    // Buffer is either null or already drained (in the body).\n    // Use the macro for consistent formatting.\n    os << DUMP_NULLABLE_MEMBER(current_dispatching_buffer_, \"drained\");\n    return;\n  } else {\n    absl::string_view front_slice = [](Buffer::RawSlice slice) {\n      return absl::string_view(static_cast<const char*>(slice.mem_), slice.len_);\n    }(current_dispatching_buffer_->frontSlice());\n\n    // Dump buffer data escaping \\r, \\n, \\t, \", ', and \\.\n    // This is not the most performant implementation, but we're crashing and\n    // cannot allocate memory.\n    os << spaces << \"current_dispatching_buffer_ front_slice length: \" << front_slice.length()\n       << \" contents: \\\"\";\n    StringUtil::escapeToOstream(os, front_slice);\n    os << \"\\\"\\n\";\n  }\n}\n\nvoid ServerConnectionImpl::dumpAdditionalState(std::ostream& os, int indent_level) const {\n  const char* spaces = spacesForLevel(indent_level);\n\n  DUMP_DETAILS(active_request_);\n  os << '\\n';\n\n  // Dump header map, it may be null if it was moved to the request, and\n  // request_url.\n  if (absl::holds_alternative<RequestHeaderMapPtr>(headers_or_trailers_)) {\n    DUMP_DETAILS(absl::get<RequestHeaderMapPtr>(headers_or_trailers_));\n  } else {\n    DUMP_DETAILS(absl::get<RequestTrailerMapPtr>(headers_or_trailers_));\n  }\n}\n\nvoid ClientConnectionImpl::dumpAdditionalState(std::ostream& os, int indent_level) const {\n  const char* spaces = spacesForLevel(indent_level);\n  // Dump header map, it may be null if it was moved to the request.\n  if (absl::holds_alternative<ResponseHeaderMapPtr>(headers_or_trailers_)) {\n    DUMP_DETAILS(absl::get<ResponseHeaderMapPtr>(headers_or_trailers_));\n  } else {\n    DUMP_DETAILS(absl::get<ResponseTrailerMapPtr>(headers_or_trailers_));\n  }\n\n  // Dump the associated request.\n  os << spaces << \"Dumping corresponding downstream request:\";\n  if (pending_response_.has_value()) {\n    os << '\\n';\n    const ResponseDecoder* decoder = pending_response_.value().decoder_;\n    DUMP_DETAILS(decoder);\n  } else {\n    os << \" null\\n\";\n  }\n}\n\nServerConnectionImpl::ServerConnectionImpl(\n    Network::Connection& connection, CodecStats& stats, ServerConnectionCallbacks& callbacks,\n    const Http1Settings& settings, uint32_t max_request_headers_kb,\n    const uint32_t max_request_headers_count,\n    envoy::config::core::v3::HttpProtocolOptions::HeadersWithUnderscoresAction\n        headers_with_underscores_action)\n    : ConnectionImpl(connection, stats, settings, MessageType::Request, max_request_headers_kb,\n                     max_request_headers_count),\n      callbacks_(callbacks),\n      response_buffer_releasor_([this](const Buffer::OwnedBufferFragmentImpl* fragment) {\n        releaseOutboundResponse(fragment);\n      }),\n      headers_with_underscores_action_(headers_with_underscores_action),\n      runtime_lazy_read_disable_(\n          Runtime::runtimeFeatureEnabled(\"envoy.reloadable_features.http1_lazy_read_disable\")) {}\n\nuint32_t ServerConnectionImpl::getHeadersSize() {\n  // Add in the size of the request URL if processing request headers.\n  const uint32_t url_size =\n      (!processing_trailers_ && active_request_) ? active_request_->request_url_.size() : 0;\n  return url_size + ConnectionImpl::getHeadersSize();\n}\n\nvoid ServerConnectionImpl::onEncodeComplete() {\n  if (active_request_->remote_complete_) {\n    // Only do this if remote is complete. If we are replying before the request is complete the\n    // only logical thing to do is for higher level code to reset() / close the connection so we\n    // leave the request around so that it can fire reset callbacks.\n    connection_.dispatcher().deferredDelete(std::move(active_request_));\n  }\n}\n\nStatus ServerConnectionImpl::handlePath(RequestHeaderMap& headers, absl::string_view method) {\n  const Http::HeaderValues& header_values = Http::Headers::get();\n  HeaderString path(header_values.Path);\n\n  bool is_connect = (method == header_values.MethodValues.Connect);\n\n  // The url is relative or a wildcard when the method is OPTIONS. Nothing to do here.\n  if (!is_connect && !active_request_->request_url_.getStringView().empty() &&\n      (active_request_->request_url_.getStringView()[0] == '/' ||\n       (method == header_values.MethodValues.Options &&\n        active_request_->request_url_.getStringView()[0] == '*'))) {\n    headers.addViaMove(std::move(path), std::move(active_request_->request_url_));\n    return okStatus();\n  }\n\n  // If absolute_urls and/or connect are not going be handled, copy the url and return.\n  // This forces the behavior to be backwards compatible with the old codec behavior.\n  // CONNECT \"urls\" are actually host:port so look like absolute URLs to the above checks.\n  // Absolute URLS in CONNECT requests will be rejected below by the URL class validation.\n  if (!codec_settings_.allow_absolute_url_ && !is_connect) {\n    headers.addViaMove(std::move(path), std::move(active_request_->request_url_));\n    return okStatus();\n  }\n\n  Utility::Url absolute_url;\n  if (!absolute_url.initialize(active_request_->request_url_.getStringView(), is_connect)) {\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidUrl));\n    return codecProtocolError(\"http/1.1 protocol error: invalid url in request line\");\n  }\n  // RFC7230#5.7\n  // When a proxy receives a request with an absolute-form of\n  // request-target, the proxy MUST ignore the received Host header field\n  // (if any) and instead replace it with the host information of the\n  // request-target. A proxy that forwards such a request MUST generate a\n  // new Host field-value based on the received request-target rather than\n  // forward the received Host field-value.\n  headers.setHost(absolute_url.hostAndPort());\n  // Add the scheme and validate to ensure no https://\n  // requests are accepted over unencrypted connections by front-line Envoys.\n  if (!is_connect) {\n    headers.setScheme(absolute_url.scheme());\n    if (!HeaderUtility::schemeIsValid(absolute_url.scheme())) {\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidScheme));\n      return codecProtocolError(\"http/1.1 protocol error: invalid scheme\");\n    }\n    if (codec_settings_.validate_scheme_ &&\n        absolute_url.scheme() == header_values.SchemeValues.Https && !connection().ssl()) {\n      error_code_ = Http::Code::Forbidden;\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().HttpsInPlaintext));\n      return codecProtocolError(\"http/1.1 protocol error: https in the clear\");\n    }\n  }\n\n  if (!absolute_url.pathAndQueryParams().empty()) {\n    headers.setPath(absolute_url.pathAndQueryParams());\n  }\n  active_request_->request_url_.clear();\n  return okStatus();\n}\n\nEnvoy::StatusOr<ParserStatus> ServerConnectionImpl::onHeadersCompleteBase() {\n  // Handle the case where response happens prior to request complete. It's up to upper layer code\n  // to disconnect the connection but we shouldn't fire any more events since it doesn't make\n  // sense.\n  if (active_request_) {\n    auto& headers = absl::get<RequestHeaderMapPtr>(headers_or_trailers_);\n    ENVOY_CONN_LOG(trace, \"Server: onHeadersComplete size={}\", connection_, headers->size());\n\n    if (!handling_upgrade_ && headers->Connection()) {\n      // If we fail to sanitize the request, return a 400 to the client\n      if (!Utility::sanitizeConnectionHeader(*headers)) {\n        absl::string_view header_value = headers->getConnectionValue();\n        ENVOY_CONN_LOG(debug, \"Invalid nominated headers in Connection: {}\", connection_,\n                       header_value);\n        error_code_ = Http::Code::BadRequest;\n        RETURN_IF_ERROR(\n            sendProtocolError(Http1ResponseCodeDetails::get().ConnectionHeaderSanitization));\n        return codecProtocolError(\"Invalid nominated headers in Connection.\");\n      }\n    }\n\n    // Inform the response encoder about any HEAD method, so it can set content\n    // length and transfer encoding headers correctly.\n    const Http::HeaderValues& header_values = Http::Headers::get();\n    active_request_->response_encoder_.setIsResponseToHeadRequest(parser_->methodName() ==\n                                                                  header_values.MethodValues.Head);\n    active_request_->response_encoder_.setIsResponseToConnectRequest(\n        parser_->methodName() == header_values.MethodValues.Connect);\n\n    RETURN_IF_ERROR(handlePath(*headers, parser_->methodName()));\n    ASSERT(active_request_->request_url_.empty());\n\n    headers->setMethod(parser_->methodName());\n\n    // Make sure the host is valid.\n    auto details = HeaderUtility::requestHeadersValid(*headers);\n    if (details.has_value()) {\n      RETURN_IF_ERROR(sendProtocolError(details.value().get()));\n      return codecProtocolError(\n          \"http/1.1 protocol error: request headers failed spec compliance checks\");\n    }\n\n    // Determine here whether we have a body or not. This uses the new RFC semantics where the\n    // presence of content-length or chunked transfer-encoding indicates a body vs. a particular\n    // method. If there is no body, we defer raising decodeHeaders() until the parser is flushed\n    // with message complete. This allows upper layers to behave like HTTP/2 and prevents a proxy\n    // scenario where the higher layers stream through and implicitly switch to chunked transfer\n    // encoding because end stream with zero body length has not yet been indicated.\n    if (parser_->isChunked() ||\n        (parser_->contentLength().has_value() && parser_->contentLength().value() > 0) ||\n        handling_upgrade_) {\n      active_request_->request_decoder_->decodeHeaders(std::move(headers), false);\n\n      // If the connection has been closed (or is closing) after decoding headers, pause the parser\n      // so we return control to the caller.\n      if (connection_.state() != Network::Connection::State::Open) {\n        return parser_->pause();\n      }\n    } else {\n      deferred_end_stream_headers_ = true;\n    }\n  }\n\n  return ParserStatus::Success;\n}\n\nStatus ServerConnectionImpl::onMessageBeginBase() {\n  if (!resetStreamCalled()) {\n    ASSERT(active_request_ == nullptr);\n    active_request_ = std::make_unique<ActiveRequest>(*this, std::move(bytes_meter_before_stream_));\n    if (resetStreamCalled()) {\n      return codecClientError(\"cannot create new streams after calling reset\");\n    }\n    active_request_->request_decoder_ = &callbacks_.newStream(active_request_->response_encoder_);\n\n    // Check for pipelined request flood as we prepare to accept a new request.\n    // Parse errors that happen prior to onMessageBegin result in stream termination, it is not\n    // possible to overflow output buffers with early parse errors.\n    RETURN_IF_ERROR(doFloodProtectionChecks());\n  }\n  return okStatus();\n}\n\nStatus ServerConnectionImpl::onUrl(const char* data, size_t length) {\n  if (active_request_) {\n    active_request_->request_url_.append(data, length);\n\n    RETURN_IF_ERROR(checkMaxHeadersSize());\n  }\n\n  return okStatus();\n}\n\nvoid ServerConnectionImpl::onBody(Buffer::Instance& data) {\n  ASSERT(!deferred_end_stream_headers_);\n  if (active_request_) {\n    ENVOY_CONN_LOG(trace, \"body size={}\", connection_, data.length());\n    active_request_->request_decoder_->decodeData(data, false);\n  }\n}\n\nHttp::Status ServerConnectionImpl::dispatch(Buffer::Instance& data) {\n  if (runtime_lazy_read_disable_ && active_request_ != nullptr &&\n      active_request_->remote_complete_) {\n    // Eagerly read disable the connection if the downstream is sending pipelined requests as we\n    // serially process them. Reading from the connection will be re-enabled after the active\n    // request is completed.\n    active_request_->response_encoder_.readDisable(true);\n    return okStatus();\n  }\n\n  Http::Status status = ConnectionImpl::dispatch(data);\n\n  if (runtime_lazy_read_disable_ && active_request_ != nullptr &&\n      active_request_->remote_complete_) {\n    // Read disable the connection if the downstream is sending additional data while we are working\n    // on an existing request. Reading from the connection will be re-enabled after the active\n    // request is completed.\n    if (data.length() > 0) {\n      active_request_->response_encoder_.readDisable(true);\n    }\n  }\n  return status;\n}\n\nParserStatus ServerConnectionImpl::onMessageCompleteBase() {\n  ASSERT(!handling_upgrade_);\n  if (active_request_) {\n\n    // The request_decoder should be non-null after we've called the newStream on callbacks.\n    ASSERT(active_request_->request_decoder_);\n    if (!runtime_lazy_read_disable_) {\n      active_request_->response_encoder_.readDisable(true);\n    }\n    active_request_->remote_complete_ = true;\n\n    if (deferred_end_stream_headers_) {\n      active_request_->request_decoder_->decodeHeaders(\n          std::move(absl::get<RequestHeaderMapPtr>(headers_or_trailers_)), true);\n      deferred_end_stream_headers_ = false;\n    } else if (processing_trailers_) {\n      active_request_->request_decoder_->decodeTrailers(\n          std::move(absl::get<RequestTrailerMapPtr>(headers_or_trailers_)));\n    } else {\n      Buffer::OwnedImpl buffer;\n      active_request_->request_decoder_->decodeData(buffer, true);\n    }\n\n    // Reset to ensure no information from one requests persists to the next.\n    headers_or_trailers_.emplace<RequestHeaderMapPtr>(nullptr);\n  }\n\n  // Always pause the parser so that the calling code can process 1 request at a time and apply\n  // back pressure. However this means that the calling code needs to detect if there is more data\n  // in the buffer and dispatch it again.\n  return parser_->pause();\n}\n\nvoid ServerConnectionImpl::onResetStream(StreamResetReason reason) {\n  active_request_->response_encoder_.runResetCallbacks(reason);\n  connection_.dispatcher().deferredDelete(std::move(active_request_));\n}\n\nStatus ServerConnectionImpl::sendProtocolError(absl::string_view details) {\n  // We do this here because we may get a protocol error before we have a logical stream.\n  if (active_request_ == nullptr) {\n    RETURN_IF_ERROR(onMessageBegin());\n  }\n  ASSERT(active_request_);\n\n  active_request_->response_encoder_.setDetails(details);\n  if (!active_request_->response_encoder_.startedResponse()) {\n    active_request_->request_decoder_->sendLocalReply(\n        error_code_, CodeUtility::toString(error_code_), nullptr, absl::nullopt, details);\n  }\n  return okStatus();\n}\n\nvoid ServerConnectionImpl::onAboveHighWatermark() {\n  if (active_request_) {\n    active_request_->response_encoder_.runHighWatermarkCallbacks();\n  }\n}\nvoid ServerConnectionImpl::onBelowLowWatermark() {\n  if (active_request_) {\n    active_request_->response_encoder_.runLowWatermarkCallbacks();\n  }\n}\n\nvoid ServerConnectionImpl::releaseOutboundResponse(\n    const Buffer::OwnedBufferFragmentImpl* fragment) {\n  ASSERT(outbound_responses_ >= 1);\n  --outbound_responses_;\n  delete fragment;\n}\n\nStatus ServerConnectionImpl::checkHeaderNameForUnderscores() {\n  if (headers_with_underscores_action_ != envoy::config::core::v3::HttpProtocolOptions::ALLOW &&\n      Http::HeaderUtility::headerNameContainsUnderscore(current_header_field_.getStringView())) {\n    if (headers_with_underscores_action_ ==\n        envoy::config::core::v3::HttpProtocolOptions::DROP_HEADER) {\n      ENVOY_CONN_LOG(debug, \"Dropping header with invalid characters in its name: {}\", connection_,\n                     current_header_field_.getStringView());\n      stats_.dropped_headers_with_underscores_.inc();\n      current_header_field_.clear();\n      current_header_value_.clear();\n    } else {\n      ENVOY_CONN_LOG(debug, \"Rejecting request due to header name with underscores: {}\",\n                     connection_, current_header_field_.getStringView());\n      error_code_ = Http::Code::BadRequest;\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidUnderscore));\n      stats_.requests_rejected_with_underscores_in_headers_.inc();\n      return codecProtocolError(\"http/1.1 protocol error: header name contains underscores\");\n    }\n  }\n  return okStatus();\n}\n\nvoid ServerConnectionImpl::ActiveRequest::dumpState(std::ostream& os, int indent_level) const {\n  (void)indent_level;\n  os << DUMP_MEMBER_AS(\n      request_url_, !request_url_.getStringView().empty() ? request_url_.getStringView() : \"null\");\n  os << DUMP_MEMBER(response_encoder_.local_end_stream_);\n}\n\nClientConnectionImpl::ClientConnectionImpl(Network::Connection& connection, CodecStats& stats,\n                                           ConnectionCallbacks&, const Http1Settings& settings,\n                                           const uint32_t max_response_headers_count)\n    : ConnectionImpl(connection, stats, settings, MessageType::Response, MAX_RESPONSE_HEADERS_KB,\n                     max_response_headers_count) {}\n\nbool ClientConnectionImpl::cannotHaveBody() {\n  if (pending_response_.has_value() && pending_response_.value().encoder_.headRequest()) {\n    ASSERT(!pending_response_done_);\n    return true;\n  } else if (parser_->statusCode() == 204 || parser_->statusCode() == 304 ||\n             (parser_->statusCode() >= 200 &&\n              (parser_->contentLength().has_value() && parser_->contentLength().value() == 0) &&\n              !parser_->isChunked())) {\n    return true;\n  } else {\n    return false;\n  }\n}\n\nRequestEncoder& ClientConnectionImpl::newStream(ResponseDecoder& response_decoder) {\n  // If reads were disabled due to flow control, we expect reads to always be enabled again before\n  // reusing this connection. This is done when the response is received.\n  ASSERT(connection_.readEnabled());\n\n  ASSERT(!pending_response_.has_value());\n  ASSERT(pending_response_done_);\n  pending_response_.emplace(*this, std::move(bytes_meter_before_stream_), &response_decoder);\n  pending_response_done_ = false;\n  return pending_response_.value().encoder_;\n}\n\nStatus ClientConnectionImpl::onStatus(const char* data, size_t length) {\n  auto& headers = absl::get<ResponseHeaderMapPtr>(headers_or_trailers_);\n  StatefulHeaderKeyFormatterOptRef formatter(headers->formatter());\n  if (formatter.has_value()) {\n    formatter->setReasonPhrase(absl::string_view(data, length));\n  }\n\n  return okStatus();\n}\n\nEnvoy::StatusOr<ParserStatus> ClientConnectionImpl::onHeadersCompleteBase() {\n  ENVOY_CONN_LOG(trace, \"status_code {}\", connection_, parser_->statusCode());\n\n  // Handle the case where the client is closing a kept alive connection (by sending a 408\n  // with a 'Connection: close' header). In this case we just let response flush out followed\n  // by the remote close.\n  if (!pending_response_.has_value() && !resetStreamCalled()) {\n    return prematureResponseError(\"\", static_cast<Http::Code>(parser_->statusCode()));\n  } else if (pending_response_.has_value()) {\n    ASSERT(!pending_response_done_);\n    auto& headers = absl::get<ResponseHeaderMapPtr>(headers_or_trailers_);\n    ENVOY_CONN_LOG(trace, \"Client: onHeadersComplete size={}\", connection_, headers->size());\n    headers->setStatus(parser_->statusCode());\n\n    if (parser_->statusCode() >= 200 && parser_->statusCode() < 300 &&\n        pending_response_.value().encoder_.connectRequest()) {\n      ENVOY_CONN_LOG(trace, \"codec entering upgrade mode for CONNECT response.\", connection_);\n      handling_upgrade_ = true;\n    }\n\n    if (parser_->statusCode() < 200 || parser_->statusCode() == 204) {\n      if (headers->TransferEncoding()) {\n        RETURN_IF_ERROR(\n            sendProtocolError(Http1ResponseCodeDetails::get().TransferEncodingNotAllowed));\n        return codecProtocolError(\n            \"http/1.1 protocol error: transfer encoding not allowed in 1xx or 204\");\n      }\n\n      if (headers->ContentLength()) {\n        // Report a protocol error for non-zero Content-Length, but paper over zero Content-Length.\n        if (headers->ContentLength()->value().getStringView() != \"0\") {\n          RETURN_IF_ERROR(\n              sendProtocolError(Http1ResponseCodeDetails::get().ContentLengthNotAllowed));\n          return codecProtocolError(\n              \"http/1.1 protocol error: content length not allowed in 1xx or 204\");\n        }\n\n        headers->removeContentLength();\n      }\n    }\n\n    if (HeaderUtility::isSpecial1xx(*headers)) {\n      pending_response_.value().decoder_->decode1xxHeaders(std::move(headers));\n    } else if (cannotHaveBody() && !handling_upgrade_) {\n      deferred_end_stream_headers_ = true;\n    } else {\n      pending_response_.value().decoder_->decodeHeaders(std::move(headers), false);\n    }\n\n    // http-parser treats 1xx headers as their own complete response. Swallow the spurious\n    // onMessageComplete and continue processing for purely informational headers.\n    // 101-SwitchingProtocols is exempt as all data after the header is proxied through after\n    // upgrading.\n    if (CodeUtility::is1xx(parser_->statusCode()) &&\n        parser_->statusCode() != enumToInt(Http::Code::SwitchingProtocols)) {\n      ignore_message_complete_for_1xx_ = true;\n      // Reset to ensure no information from the 1xx headers is used for the response headers.\n      headers_or_trailers_.emplace<ResponseHeaderMapPtr>(nullptr);\n    }\n  }\n\n  // Here we deal with cases where the response cannot have a body by returning\n  // ParserStatus::NoBody, but http_parser does not deal with it for us.\n  return cannotHaveBody() ? ParserStatus::NoBody : ParserStatus::Success;\n}\n\nbool ClientConnectionImpl::upgradeAllowed() const {\n  if (pending_response_.has_value()) {\n    return pending_response_->encoder_.upgradeRequest();\n  }\n  return false;\n}\n\nvoid ClientConnectionImpl::onBody(Buffer::Instance& data) {\n  ASSERT(!deferred_end_stream_headers_);\n  if (pending_response_.has_value()) {\n    ASSERT(!pending_response_done_);\n    pending_response_.value().decoder_->decodeData(data, false);\n  }\n}\n\nParserStatus ClientConnectionImpl::onMessageCompleteBase() {\n  ENVOY_CONN_LOG(trace, \"message complete\", connection_);\n  if (ignore_message_complete_for_1xx_) {\n    ignore_message_complete_for_1xx_ = false;\n    return ParserStatus::Success;\n  }\n  if (pending_response_.has_value()) {\n    ASSERT(!pending_response_done_);\n    // After calling decodeData() with end stream set to true, we should no longer be able to reset.\n    PendingResponse& response = pending_response_.value();\n    // Encoder is used as part of decode* calls later in this function so pending_response_ can not\n    // be reset just yet. Preserve the state in pending_response_done_ instead.\n    pending_response_done_ = true;\n\n    if (deferred_end_stream_headers_) {\n      response.decoder_->decodeHeaders(\n          std::move(absl::get<ResponseHeaderMapPtr>(headers_or_trailers_)), true);\n      deferred_end_stream_headers_ = false;\n    } else if (processing_trailers_) {\n      response.decoder_->decodeTrailers(\n          std::move(absl::get<ResponseTrailerMapPtr>(headers_or_trailers_)));\n    } else {\n      Buffer::OwnedImpl buffer;\n      response.decoder_->decodeData(buffer, true);\n    }\n\n    // Reset to ensure no information from one requests persists to the next.\n    pending_response_.reset();\n    headers_or_trailers_.emplace<ResponseHeaderMapPtr>(nullptr);\n  }\n\n  // Pause the parser after a response is complete. Any remaining data indicates an error.\n  return parser_->pause();\n}\n\nvoid ClientConnectionImpl::onResetStream(StreamResetReason reason) {\n  // Only raise reset if we did not already dispatch a complete response.\n  if (pending_response_.has_value() && !pending_response_done_) {\n    pending_response_.value().encoder_.runResetCallbacks(reason);\n    pending_response_done_ = true;\n    pending_response_.reset();\n  }\n}\n\nStatus ClientConnectionImpl::sendProtocolError(absl::string_view details) {\n  if (pending_response_.has_value()) {\n    ASSERT(!pending_response_done_);\n    pending_response_.value().encoder_.setDetails(details);\n  }\n  return okStatus();\n}\n\nvoid ClientConnectionImpl::onAboveHighWatermark() {\n  // This should never happen without an active stream/request.\n  pending_response_.value().encoder_.runHighWatermarkCallbacks();\n}\n\nvoid ClientConnectionImpl::onBelowLowWatermark() {\n  // This can get called without an active stream/request when the response completion causes us to\n  // close the connection, but in doing so go below low watermark.\n  if (pending_response_.has_value() && !pending_response_done_) {\n    pending_response_.value().encoder_.runLowWatermarkCallbacks();\n  }\n}\n\n} // namespace Http1\n} // namespace Http\n} // namespace Envoy\n", "#pragma once\n\n#include <chrono>\n#include <cstdint>\n\n#include \"envoy/common/time.h\"\n#include \"envoy/config/core/v3/base.pb.h\"\n#include \"envoy/http/header_map.h\"\n#include \"envoy/http/request_id_extension.h\"\n#include \"envoy/network/socket.h\"\n#include \"envoy/stream_info/stream_info.h\"\n#include \"envoy/tracing/trace_reason.h\"\n\n#include \"source/common/common/assert.h\"\n#include \"source/common/common/dump_state_utils.h\"\n#include \"source/common/common/macros.h\"\n#include \"source/common/common/utility.h\"\n#include \"source/common/network/socket_impl.h\"\n#include \"source/common/stream_info/filter_state_impl.h\"\n\n#include \"absl/strings/str_replace.h\"\n\nnamespace Envoy {\nnamespace StreamInfo {\n\nstruct UpstreamInfoImpl : public UpstreamInfo {\n  void setUpstreamConnectionId(uint64_t id) override { upstream_connection_id_ = id; }\n\n  absl::optional<uint64_t> upstreamConnectionId() const override { return upstream_connection_id_; }\n\n  void setUpstreamInterfaceName(absl::string_view interface_name) override {\n    upstream_connection_interface_name_ = std::string(interface_name);\n  }\n\n  absl::optional<absl::string_view> upstreamInterfaceName() const override {\n    return upstream_connection_interface_name_;\n  }\n\n  void\n  setUpstreamSslConnection(const Ssl::ConnectionInfoConstSharedPtr& ssl_connection_info) override {\n    upstream_ssl_info_ = ssl_connection_info;\n  }\n\n  Ssl::ConnectionInfoConstSharedPtr upstreamSslConnection() const override {\n    return upstream_ssl_info_;\n  }\n  UpstreamTiming& upstreamTiming() override { return upstream_timing_; }\n  const UpstreamTiming& upstreamTiming() const override { return upstream_timing_; }\n  const Network::Address::InstanceConstSharedPtr& upstreamLocalAddress() const override {\n    return upstream_local_address_;\n  }\n  void setUpstreamLocalAddress(\n      const Network::Address::InstanceConstSharedPtr& upstream_local_address) override {\n    upstream_local_address_ = upstream_local_address;\n  }\n  void setUpstreamTransportFailureReason(absl::string_view failure_reason) override {\n    upstream_transport_failure_reason_ = std::string(failure_reason);\n  }\n  const std::string& upstreamTransportFailureReason() const override {\n    return upstream_transport_failure_reason_;\n  }\n  void setUpstreamHost(Upstream::HostDescriptionConstSharedPtr host) override {\n    upstream_host_ = host;\n  }\n  const FilterStateSharedPtr& upstreamFilterState() const override {\n    return upstream_filter_state_;\n  }\n  void setUpstreamFilterState(const FilterStateSharedPtr& filter_state) override {\n    upstream_filter_state_ = filter_state;\n  }\n\n  Upstream::HostDescriptionConstSharedPtr upstreamHost() const override { return upstream_host_; }\n\n  void dumpState(std::ostream& os, int indent_level = 0) const override {\n    const char* spaces = spacesForLevel(indent_level);\n    os << spaces << \"UpstreamInfoImpl \" << this << DUMP_OPTIONAL_MEMBER(upstream_connection_id_)\n       << \"\\n\";\n  }\n  void setUpstreamNumStreams(uint64_t num_streams) override { num_streams_ = num_streams; }\n  uint64_t upstreamNumStreams() const override { return num_streams_; }\n\n  Upstream::HostDescriptionConstSharedPtr upstream_host_{};\n  Network::Address::InstanceConstSharedPtr upstream_local_address_;\n  UpstreamTiming upstream_timing_;\n  Ssl::ConnectionInfoConstSharedPtr upstream_ssl_info_;\n  absl::optional<uint64_t> upstream_connection_id_;\n  absl::optional<std::string> upstream_connection_interface_name_;\n  std::string upstream_transport_failure_reason_;\n  FilterStateSharedPtr upstream_filter_state_;\n  size_t num_streams_{};\n};\n\nstruct StreamInfoImpl : public StreamInfo {\n  StreamInfoImpl(\n      TimeSource& time_source,\n      const Network::ConnectionInfoProviderSharedPtr& downstream_connection_info_provider,\n      FilterState::LifeSpan life_span = FilterState::LifeSpan::FilterChain)\n      : StreamInfoImpl(absl::nullopt, time_source, downstream_connection_info_provider,\n                       std::make_shared<FilterStateImpl>(life_span)) {}\n\n  StreamInfoImpl(\n      Http::Protocol protocol, TimeSource& time_source,\n      const Network::ConnectionInfoProviderSharedPtr& downstream_connection_info_provider)\n      : StreamInfoImpl(protocol, time_source, downstream_connection_info_provider,\n                       std::make_shared<FilterStateImpl>(FilterState::LifeSpan::FilterChain)) {}\n\n  StreamInfoImpl(\n      Http::Protocol protocol, TimeSource& time_source,\n      const Network::ConnectionInfoProviderSharedPtr& downstream_connection_info_provider,\n      FilterStateSharedPtr parent_filter_state, FilterState::LifeSpan life_span)\n      : StreamInfoImpl(\n            protocol, time_source, downstream_connection_info_provider,\n            std::make_shared<FilterStateImpl>(\n                FilterStateImpl::LazyCreateAncestor(std::move(parent_filter_state), life_span),\n                FilterState::LifeSpan::FilterChain)) {}\n\n  SystemTime startTime() const override { return start_time_; }\n\n  MonotonicTime startTimeMonotonic() const override { return start_time_monotonic_; }\n\n  absl::optional<std::chrono::nanoseconds> duration(absl::optional<MonotonicTime> time) const {\n    if (!time) {\n      return {};\n    }\n\n    return std::chrono::duration_cast<std::chrono::nanoseconds>(time.value() -\n                                                                start_time_monotonic_);\n  }\n\n  void setUpstreamInfo(std::shared_ptr<UpstreamInfo> info) override { upstream_info_ = info; }\n\n  std::shared_ptr<UpstreamInfo> upstreamInfo() override { return upstream_info_; }\n\n  OptRef<const UpstreamInfo> upstreamInfo() const override {\n    if (!upstream_info_) {\n      return {};\n    }\n    return *upstream_info_;\n  }\n\n  absl::optional<std::chrono::nanoseconds> requestComplete() const override {\n    return duration(final_time_);\n  }\n\n  void onRequestComplete() override {\n    ASSERT(!final_time_);\n    final_time_ = time_source_.monotonicTime();\n  }\n\n  DownstreamTiming& downstreamTiming() override {\n    if (!downstream_timing_.has_value()) {\n      downstream_timing_ = DownstreamTiming();\n    }\n    return downstream_timing_.value();\n  }\n  OptRef<const DownstreamTiming> downstreamTiming() const override {\n    if (!downstream_timing_.has_value()) {\n      return {};\n    }\n    return {*downstream_timing_};\n  }\n\n  void addBytesReceived(uint64_t bytes_received) override { bytes_received_ += bytes_received; }\n\n  uint64_t bytesReceived() const override { return bytes_received_; }\n\n  absl::optional<Http::Protocol> protocol() const override { return protocol_; }\n\n  void protocol(Http::Protocol protocol) override { protocol_ = protocol; }\n\n  absl::optional<uint32_t> responseCode() const override { return response_code_; }\n\n  const absl::optional<std::string>& responseCodeDetails() const override {\n    return response_code_details_;\n  }\n\n  void setResponseCode(uint32_t code) override { response_code_ = code; }\n\n  void setResponseCodeDetails(absl::string_view rc_details) override {\n    ASSERT(!StringUtil::hasEmptySpace(rc_details));\n    response_code_details_.emplace(rc_details);\n  }\n\n  const absl::optional<std::string>& connectionTerminationDetails() const override {\n    return connection_termination_details_;\n  }\n\n  void setConnectionTerminationDetails(absl::string_view connection_termination_details) override {\n    connection_termination_details_.emplace(connection_termination_details);\n  }\n\n  void addBytesSent(uint64_t bytes_sent) override { bytes_sent_ += bytes_sent; }\n\n  uint64_t bytesSent() const override { return bytes_sent_; }\n\n  void setResponseFlag(ResponseFlag response_flag) override { response_flags_ |= response_flag; }\n\n  bool intersectResponseFlags(uint64_t response_flags) const override {\n    return (response_flags_ & response_flags) != 0;\n  }\n\n  bool hasResponseFlag(ResponseFlag flag) const override { return response_flags_ & flag; }\n\n  bool hasAnyResponseFlag() const override { return response_flags_ != 0; }\n\n  uint64_t responseFlags() const override { return response_flags_; }\n\n  void setRouteName(absl::string_view route_name) override {\n    route_name_ = std::string(route_name);\n  }\n\n  const std::string& getRouteName() const override { return route_name_; }\n\n  void setVirtualClusterName(const absl::optional<std::string>& virtual_cluster_name) override {\n    virtual_cluster_name_ = virtual_cluster_name;\n  }\n\n  const absl::optional<std::string>& virtualClusterName() const override {\n    return virtual_cluster_name_;\n  }\n\n  bool healthCheck() const override { return health_check_request_; }\n\n  void healthCheck(bool is_health_check) override { health_check_request_ = is_health_check; }\n\n  const Network::ConnectionInfoProvider& downstreamAddressProvider() const override {\n    return *downstream_connection_info_provider_;\n  }\n\n  Router::RouteConstSharedPtr route() const override { return route_; }\n\n  envoy::config::core::v3::Metadata& dynamicMetadata() override { return metadata_; };\n  const envoy::config::core::v3::Metadata& dynamicMetadata() const override { return metadata_; };\n\n  void setDynamicMetadata(const std::string& name, const ProtobufWkt::Struct& value) override {\n    (*metadata_.mutable_filter_metadata())[name].MergeFrom(value);\n  };\n\n  const FilterStateSharedPtr& filterState() override { return filter_state_; }\n  const FilterState& filterState() const override { return *filter_state_; }\n\n  void setRequestHeaders(const Http::RequestHeaderMap& headers) override {\n    request_headers_ = &headers;\n  }\n\n  const Http::RequestHeaderMap* getRequestHeaders() const override { return request_headers_; }\n\n  void setRequestIDProvider(const Http::RequestIdStreamInfoProviderSharedPtr& provider) override {\n    ASSERT(provider != nullptr);\n    request_id_provider_ = provider;\n  }\n  const Http::RequestIdStreamInfoProvider* getRequestIDProvider() const override {\n    return request_id_provider_.get();\n  }\n\n  void setTraceReason(Tracing::Reason reason) override { trace_reason_ = reason; }\n  Tracing::Reason traceReason() const override { return trace_reason_; }\n\n  void dumpState(std::ostream& os, int indent_level = 0) const {\n    const char* spaces = spacesForLevel(indent_level);\n    os << spaces << \"StreamInfoImpl \" << this << DUMP_OPTIONAL_MEMBER(protocol_)\n       << DUMP_OPTIONAL_MEMBER(response_code_) << DUMP_OPTIONAL_MEMBER(response_code_details_)\n       << DUMP_OPTIONAL_MEMBER(attempt_count_) << DUMP_MEMBER(health_check_request_)\n       << DUMP_MEMBER(route_name_);\n    DUMP_DETAILS(upstream_info_);\n  }\n\n  void setUpstreamClusterInfo(\n      const Upstream::ClusterInfoConstSharedPtr& upstream_cluster_info) override {\n    upstream_cluster_info_ = upstream_cluster_info;\n  }\n\n  absl::optional<Upstream::ClusterInfoConstSharedPtr> upstreamClusterInfo() const override {\n    return upstream_cluster_info_;\n  }\n\n  void setFilterChainName(absl::string_view filter_chain_name) override {\n    filter_chain_name_ = std::string(filter_chain_name);\n  }\n\n  const std::string& filterChainName() const override { return filter_chain_name_; }\n  void setAttemptCount(uint32_t attempt_count) override { attempt_count_ = attempt_count; }\n\n  absl::optional<uint32_t> attemptCount() const override { return attempt_count_; }\n\n  const BytesMeterSharedPtr& getUpstreamBytesMeter() const override {\n    return upstream_bytes_meter_;\n  }\n\n  const BytesMeterSharedPtr& getDownstreamBytesMeter() const override {\n    return downstream_bytes_meter_;\n  }\n\n  void setUpstreamBytesMeter(const BytesMeterSharedPtr& upstream_bytes_meter) override {\n    // Accumulate the byte measurement from previous upstream request during a retry.\n    upstream_bytes_meter->addWireBytesSent(upstream_bytes_meter_->wireBytesSent());\n    upstream_bytes_meter->addWireBytesReceived(upstream_bytes_meter_->wireBytesReceived());\n    upstream_bytes_meter->addHeaderBytesSent(upstream_bytes_meter_->headerBytesSent());\n    upstream_bytes_meter->addHeaderBytesReceived(upstream_bytes_meter_->headerBytesReceived());\n    upstream_bytes_meter_ = upstream_bytes_meter;\n  }\n\n  void setDownstreamBytesMeter(const BytesMeterSharedPtr& downstream_bytes_meter) override {\n    // Downstream bytes counter don't reset during a retry.\n    if (downstream_bytes_meter_ == nullptr) {\n      downstream_bytes_meter_ = downstream_bytes_meter;\n    }\n    ASSERT(downstream_bytes_meter_.get() == downstream_bytes_meter.get());\n  }\n\n  TimeSource& time_source_;\n  const SystemTime start_time_;\n  const MonotonicTime start_time_monotonic_;\n  absl::optional<MonotonicTime> final_time_;\n\n  absl::optional<Http::Protocol> protocol_;\n  absl::optional<uint32_t> response_code_;\n  absl::optional<std::string> response_code_details_;\n  absl::optional<std::string> connection_termination_details_;\n  uint64_t response_flags_{};\n  bool health_check_request_{};\n  Router::RouteConstSharedPtr route_;\n  envoy::config::core::v3::Metadata metadata_{};\n  FilterStateSharedPtr filter_state_;\n  std::string route_name_;\n  absl::optional<uint32_t> attempt_count_;\n  // TODO(agrawroh): Check if the owner of this storage outlives the StreamInfo. We should only copy\n  // the string if it could outlive the StreamInfo.\n  absl::optional<std::string> virtual_cluster_name_;\n\nprivate:\n  static Network::ConnectionInfoProviderSharedPtr emptyDownstreamAddressProvider() {\n    MUTABLE_CONSTRUCT_ON_FIRST_USE(\n        Network::ConnectionInfoProviderSharedPtr,\n        std::make_shared<Network::ConnectionInfoSetterImpl>(nullptr, nullptr));\n  }\n\n  StreamInfoImpl(\n      absl::optional<Http::Protocol> protocol, TimeSource& time_source,\n      const Network::ConnectionInfoProviderSharedPtr& downstream_connection_info_provider,\n      FilterStateSharedPtr filter_state)\n      : time_source_(time_source), start_time_(time_source.systemTime()),\n        start_time_monotonic_(time_source.monotonicTime()), protocol_(protocol),\n        filter_state_(std::move(filter_state)),\n        downstream_connection_info_provider_(downstream_connection_info_provider != nullptr\n                                                 ? downstream_connection_info_provider\n                                                 : emptyDownstreamAddressProvider()),\n        trace_reason_(Tracing::Reason::NotTraceable) {}\n\n  std::shared_ptr<UpstreamInfo> upstream_info_;\n  uint64_t bytes_received_{};\n  uint64_t bytes_sent_{};\n  const Network::ConnectionInfoProviderSharedPtr downstream_connection_info_provider_;\n  const Http::RequestHeaderMap* request_headers_{};\n  Http::RequestIdStreamInfoProviderSharedPtr request_id_provider_;\n  absl::optional<DownstreamTiming> downstream_timing_;\n  absl::optional<Upstream::ClusterInfoConstSharedPtr> upstream_cluster_info_;\n  std::string filter_chain_name_;\n  Tracing::Reason trace_reason_;\n  // Default construct the object because upstream stream is not constructed in some cases.\n  BytesMeterSharedPtr upstream_bytes_meter_{std::make_shared<BytesMeter>()};\n  BytesMeterSharedPtr downstream_bytes_meter_;\n};\n\n} // namespace StreamInfo\n} // namespace Envoy\n", "#include <chrono>\n#include <functional>\n\n#include \"envoy/http/protocol.h\"\n#include \"envoy/stream_info/filter_state.h\"\n#include \"envoy/upstream/host_description.h\"\n\n#include \"source/common/common/fmt.h\"\n#include \"source/common/protobuf/utility.h\"\n#include \"source/common/stream_info/stream_info_impl.h\"\n#include \"source/common/stream_info/utility.h\"\n\n#include \"test/common/stream_info/test_int_accessor.h\"\n#include \"test/mocks/router/mocks.h\"\n#include \"test/mocks/ssl/mocks.h\"\n#include \"test/mocks/upstream/cluster_info.h\"\n#include \"test/mocks/upstream/host.h\"\n#include \"test/test_common/test_time.h\"\n#include \"test/test_common/utility.h\"\n\n#include \"gmock/gmock.h\"\n#include \"gtest/gtest.h\"\n\nnamespace Envoy {\nnamespace StreamInfo {\nnamespace {\n\nstd::chrono::nanoseconds checkDuration(std::chrono::nanoseconds last,\n                                       absl::optional<std::chrono::nanoseconds> timing) {\n  EXPECT_TRUE(timing);\n  EXPECT_LE(last, timing.value());\n  return timing.value();\n}\n\nclass StreamInfoImplTest : public testing::Test {\nprotected:\n  DangerousDeprecatedTestTime test_time_;\n};\n\nTEST_F(StreamInfoImplTest, TimingTest) {\n  MonotonicTime pre_start = test_time_.timeSystem().monotonicTime();\n  StreamInfoImpl info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n  info.setUpstreamInfo(std::make_shared<UpstreamInfoImpl>());\n  UpstreamTiming& upstream_timing = info.upstreamInfo()->upstreamTiming();\n  MonotonicTime post_start = test_time_.timeSystem().monotonicTime();\n\n  const MonotonicTime& start = info.startTimeMonotonic();\n\n  EXPECT_LE(pre_start, start) << \"Start time was lower than expected\";\n  EXPECT_GE(post_start, start) << \"Start time was higher than expected\";\n\n  TimingUtility timing(info);\n  EXPECT_FALSE(timing.lastDownstreamRxByteReceived());\n  info.downstreamTiming().onLastDownstreamRxByteReceived(test_time_.timeSystem());\n  std::chrono::nanoseconds dur =\n      checkDuration(std::chrono::nanoseconds{0}, timing.lastDownstreamRxByteReceived());\n\n  EXPECT_FALSE(timing.firstUpstreamTxByteSent());\n  upstream_timing.onFirstUpstreamTxByteSent(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.firstUpstreamTxByteSent());\n\n  EXPECT_FALSE(timing.lastUpstreamTxByteSent());\n  upstream_timing.onLastUpstreamTxByteSent(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.lastUpstreamTxByteSent());\n\n  EXPECT_FALSE(timing.firstUpstreamRxByteReceived());\n  upstream_timing.onFirstUpstreamRxByteReceived(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.firstUpstreamRxByteReceived());\n\n  EXPECT_FALSE(timing.lastUpstreamRxByteReceived());\n  upstream_timing.onLastUpstreamRxByteReceived(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.lastUpstreamRxByteReceived());\n\n  EXPECT_FALSE(timing.firstDownstreamTxByteSent());\n  info.downstreamTiming().onFirstDownstreamTxByteSent(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.firstDownstreamTxByteSent());\n\n  EXPECT_FALSE(timing.lastDownstreamTxByteSent());\n  info.downstreamTiming().onLastDownstreamTxByteSent(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.lastDownstreamTxByteSent());\n\n  EXPECT_FALSE(info.requestComplete());\n  info.onRequestComplete();\n  dur = checkDuration(dur, info.requestComplete());\n}\n\nTEST_F(StreamInfoImplTest, BytesTest) {\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n  const uint64_t bytes_sent = 7;\n  const uint64_t bytes_received = 12;\n\n  stream_info.addBytesSent(bytes_sent);\n  stream_info.addBytesReceived(bytes_received);\n\n  EXPECT_EQ(bytes_sent, stream_info.bytesSent());\n  EXPECT_EQ(bytes_received, stream_info.bytesReceived());\n}\n\nTEST_F(StreamInfoImplTest, ResponseFlagTest) {\n  const std::vector<ResponseFlag> responseFlags = {FailedLocalHealthCheck,\n                                                   NoHealthyUpstream,\n                                                   UpstreamRequestTimeout,\n                                                   LocalReset,\n                                                   UpstreamRemoteReset,\n                                                   UpstreamConnectionFailure,\n                                                   UpstreamConnectionTermination,\n                                                   UpstreamOverflow,\n                                                   NoRouteFound,\n                                                   DelayInjected,\n                                                   FaultInjected,\n                                                   RateLimited};\n\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n  EXPECT_FALSE(stream_info.hasAnyResponseFlag());\n  EXPECT_FALSE(stream_info.intersectResponseFlags(0));\n  for (ResponseFlag flag : responseFlags) {\n    // Test cumulative setting of response flags.\n    EXPECT_FALSE(stream_info.hasResponseFlag(flag))\n        << fmt::format(\"Flag: {} was already set\", flag);\n    stream_info.setResponseFlag(flag);\n    EXPECT_TRUE(stream_info.hasResponseFlag(flag))\n        << fmt::format(\"Flag: {} was expected to be set\", flag);\n  }\n  EXPECT_TRUE(stream_info.hasAnyResponseFlag());\n  EXPECT_EQ(0xFFF, stream_info.responseFlags());\n\n  StreamInfoImpl stream_info2(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n  stream_info2.setResponseFlag(FailedLocalHealthCheck);\n\n  EXPECT_TRUE(stream_info2.intersectResponseFlags(FailedLocalHealthCheck));\n}\n\nTEST_F(StreamInfoImplTest, MiscSettersAndGetters) {\n  {\n    StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n    EXPECT_EQ(nullptr, stream_info.upstreamInfo());\n    EXPECT_EQ(Http::Protocol::Http2, stream_info.protocol().value());\n    stream_info.setUpstreamInfo(std::make_shared<UpstreamInfoImpl>());\n\n    stream_info.protocol(Http::Protocol::Http10);\n    EXPECT_EQ(Http::Protocol::Http10, stream_info.protocol().value());\n\n    EXPECT_FALSE(stream_info.responseCode());\n    stream_info.response_code_ = 200;\n    ASSERT_TRUE(stream_info.responseCode());\n    EXPECT_EQ(200, stream_info.responseCode().value());\n\n    EXPECT_FALSE(stream_info.attemptCount().has_value());\n    stream_info.setAttemptCount(93);\n    ASSERT_TRUE(stream_info.attemptCount().has_value());\n    EXPECT_EQ(stream_info.attemptCount().value(), 93);\n\n    EXPECT_FALSE(stream_info.responseCodeDetails().has_value());\n    stream_info.setResponseCodeDetails(ResponseCodeDetails::get().ViaUpstream);\n    ASSERT_TRUE(stream_info.responseCodeDetails().has_value());\n    EXPECT_EQ(ResponseCodeDetails::get().ViaUpstream, stream_info.responseCodeDetails().value());\n\n    EXPECT_FALSE(stream_info.connectionTerminationDetails().has_value());\n    stream_info.setConnectionTerminationDetails(\"access_denied\");\n    ASSERT_TRUE(stream_info.connectionTerminationDetails().has_value());\n    EXPECT_EQ(\"access_denied\", stream_info.connectionTerminationDetails().value());\n\n    EXPECT_EQ(nullptr, stream_info.upstreamInfo()->upstreamHost());\n    Upstream::HostDescriptionConstSharedPtr host(new NiceMock<Upstream::MockHostDescription>());\n    stream_info.upstreamInfo()->setUpstreamHost(host);\n    EXPECT_EQ(host, stream_info.upstreamInfo()->upstreamHost());\n\n    EXPECT_FALSE(stream_info.healthCheck());\n    stream_info.healthCheck(true);\n    EXPECT_TRUE(stream_info.healthCheck());\n\n    EXPECT_EQ(nullptr, stream_info.route());\n    std::shared_ptr<NiceMock<Router::MockRoute>> route =\n        std::make_shared<NiceMock<Router::MockRoute>>();\n    stream_info.route_ = route;\n    EXPECT_EQ(route, stream_info.route());\n\n    stream_info.filterState()->setData(\"test\", std::make_unique<TestIntAccessor>(1),\n                                       FilterState::StateType::ReadOnly,\n                                       FilterState::LifeSpan::FilterChain);\n    EXPECT_EQ(1, stream_info.filterState()->getDataReadOnly<TestIntAccessor>(\"test\")->access());\n\n    stream_info.upstreamInfo()->setUpstreamFilterState(stream_info.filterState());\n    EXPECT_EQ(1, stream_info.upstreamInfo()\n                     ->upstreamFilterState()\n                     ->getDataReadOnly<TestIntAccessor>(\"test\")\n                     ->access());\n\n    EXPECT_EQ(absl::nullopt, stream_info.upstreamClusterInfo());\n    Upstream::ClusterInfoConstSharedPtr cluster_info(new NiceMock<Upstream::MockClusterInfo>());\n    stream_info.setUpstreamClusterInfo(cluster_info);\n    EXPECT_NE(absl::nullopt, stream_info.upstreamClusterInfo());\n    EXPECT_EQ(\"fake_cluster\", stream_info.upstreamClusterInfo().value()->name());\n\n    const std::string session_id =\n        \"D62A523A65695219D46FE1FFE285A4C371425ACE421B110B5B8D11D3EB4D5F0B\";\n    auto ssl_info = std::make_shared<Ssl::MockConnectionInfo>();\n    EXPECT_CALL(*ssl_info, sessionId()).WillRepeatedly(testing::ReturnRef(session_id));\n    stream_info.upstreamInfo()->setUpstreamSslConnection(ssl_info);\n    EXPECT_EQ(session_id, stream_info.upstreamInfo()->upstreamSslConnection()->sessionId());\n\n    EXPECT_FALSE(stream_info.upstreamInfo()->upstreamConnectionId().has_value());\n    stream_info.upstreamInfo()->setUpstreamConnectionId(12345);\n    ASSERT_TRUE(stream_info.upstreamInfo()->upstreamConnectionId().has_value());\n    EXPECT_EQ(12345, stream_info.upstreamInfo()->upstreamConnectionId().value());\n\n    EXPECT_FALSE(stream_info.upstreamInfo()->upstreamInterfaceName().has_value());\n    stream_info.upstreamInfo()->setUpstreamInterfaceName(\"lo\");\n    ASSERT_TRUE(stream_info.upstreamInfo()->upstreamInterfaceName().has_value());\n    EXPECT_EQ(\"lo\", stream_info.upstreamInfo()->upstreamInterfaceName().value());\n\n    std::shared_ptr<UpstreamInfo> new_info = std::make_shared<UpstreamInfoImpl>();\n    EXPECT_NE(stream_info.upstreamInfo(), new_info);\n    stream_info.setUpstreamInfo(new_info);\n    EXPECT_EQ(stream_info.upstreamInfo(), new_info);\n  }\n}\n\nTEST_F(StreamInfoImplTest, DynamicMetadataTest) {\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n  EXPECT_EQ(0, stream_info.dynamicMetadata().filter_metadata_size());\n  stream_info.setDynamicMetadata(\"com.test\", MessageUtil::keyValueStruct(\"test_key\", \"test_value\"));\n  EXPECT_EQ(\"test_value\",\n            Config::Metadata::metadataValue(&stream_info.dynamicMetadata(), \"com.test\", \"test_key\")\n                .string_value());\n  ProtobufWkt::Struct struct_obj2;\n  ProtobufWkt::Value val2;\n  val2.set_string_value(\"another_value\");\n  (*struct_obj2.mutable_fields())[\"another_key\"] = val2;\n  stream_info.setDynamicMetadata(\"com.test\", struct_obj2);\n  EXPECT_EQ(\"another_value\", Config::Metadata::metadataValue(&stream_info.dynamicMetadata(),\n                                                             \"com.test\", \"another_key\")\n                                 .string_value());\n  // make sure \"test_key:test_value\" still exists\n  EXPECT_EQ(\"test_value\",\n            Config::Metadata::metadataValue(&stream_info.dynamicMetadata(), \"com.test\", \"test_key\")\n                .string_value());\n  std::string json;\n  const auto test_struct = stream_info.dynamicMetadata().filter_metadata().at(\"com.test\");\n  const auto status = Protobuf::util::MessageToJsonString(test_struct, &json);\n  EXPECT_TRUE(status.ok());\n  // check json contains the key and values we set\n  EXPECT_TRUE(json.find(\"\\\"test_key\\\":\\\"test_value\\\"\") != std::string::npos);\n  EXPECT_TRUE(json.find(\"\\\"another_key\\\":\\\"another_value\\\"\") != std::string::npos);\n}\n\nTEST_F(StreamInfoImplTest, DumpStateTest) {\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n  std::string prefix = \"\";\n\n  for (int i = 0; i < 7; ++i) {\n    std::stringstream out;\n    stream_info.dumpState(out, i);\n    std::string state = out.str();\n    EXPECT_TRUE(absl::StartsWith(state, prefix));\n    EXPECT_THAT(state, testing::HasSubstr(\"protocol_: 2\"));\n    prefix = prefix + \"  \";\n  }\n}\n\nTEST_F(StreamInfoImplTest, RequestHeadersTest) {\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n  EXPECT_FALSE(stream_info.getRequestHeaders());\n\n  Http::TestRequestHeaderMapImpl headers;\n  stream_info.setRequestHeaders(headers);\n  EXPECT_EQ(&headers, stream_info.getRequestHeaders());\n}\n\nTEST_F(StreamInfoImplTest, DefaultRequestIDExtensionTest) {\n  StreamInfoImpl stream_info(test_time_.timeSystem(), nullptr);\n  EXPECT_EQ(nullptr, stream_info.getRequestIDProvider());\n}\n\nTEST_F(StreamInfoImplTest, Details) {\n  StreamInfoImpl stream_info(test_time_.timeSystem(), nullptr);\n  EXPECT_FALSE(stream_info.responseCodeDetails().has_value());\n  stream_info.setResponseCodeDetails(\"two_words\");\n  ASSERT_TRUE(stream_info.responseCodeDetails().has_value());\n  EXPECT_EQ(stream_info.responseCodeDetails().value(), \"two_words\");\n}\n\nTEST(UpstreamInfoImplTest, DumpState) {\n  UpstreamInfoImpl upstream_info;\n\n  {\n    std::stringstream out;\n    upstream_info.dumpState(out, 0);\n    std::string state = out.str();\n    EXPECT_THAT(state, testing::HasSubstr(\"upstream_connection_id_: null\"));\n  }\n  upstream_info.setUpstreamConnectionId(5);\n  {\n    std::stringstream out;\n    upstream_info.dumpState(out, 0);\n    std::string state = out.str();\n    EXPECT_THAT(state, testing::HasSubstr(\"upstream_connection_id_: 5\"));\n  }\n}\n\n} // namespace\n} // namespace StreamInfo\n} // namespace Envoy\n", "#include \"envoy/config/cluster/v3/cluster.pb.h\"\n#include \"envoy/grpc/status.h\"\n#include \"envoy/service/discovery/v3/discovery.pb.h\"\n#include \"envoy/stats/scope.h\"\n\n#include \"source/common/config/protobuf_link_hacks.h\"\n#include \"source/common/protobuf/protobuf.h\"\n#include \"source/common/protobuf/utility.h\"\n\n#include \"test/common/grpc/grpc_client_integration.h\"\n#include \"test/config/v2_link_hacks.h\"\n#include \"test/integration/http_integration.h\"\n#include \"test/integration/utility.h\"\n#include \"test/test_common/network_utility.h\"\n#include \"test/test_common/resources.h\"\n#include \"test/test_common/simulated_time_system.h\"\n#include \"test/test_common/utility.h\"\n\n#include \"absl/synchronization/notification.h\"\n#include \"gtest/gtest.h\"\n\nusing testing::AssertionResult;\n\nnamespace Envoy {\nnamespace {\n\nconst char ClusterName1[] = \"cluster_1\";\nconst char ClusterName2[] = \"cluster_2\";\nconst int UpstreamIndex1 = 1;\nconst int UpstreamIndex2 = 2;\n\nclass CdsIntegrationTest : public Grpc::DeltaSotwIntegrationParamTest, public HttpIntegrationTest {\npublic:\n  CdsIntegrationTest()\n      : HttpIntegrationTest(Http::CodecType::HTTP2, ipVersion(),\n                            ConfigHelper::discoveredClustersBootstrap(\n                                sotwOrDelta() == Grpc::SotwOrDelta::Sotw ||\n                                        sotwOrDelta() == Grpc::SotwOrDelta::UnifiedSotw\n                                    ? \"GRPC\"\n                                    : \"DELTA_GRPC\")),\n        cluster_creator_(&ConfigHelper::buildStaticCluster) {\n    if (sotwOrDelta() == Grpc::SotwOrDelta::UnifiedSotw ||\n        sotwOrDelta() == Grpc::SotwOrDelta::UnifiedDelta) {\n      config_helper_.addRuntimeOverride(\"envoy.reloadable_features.unified_mux\", \"true\");\n    }\n    use_lds_ = false;\n    sotw_or_delta_ = sotwOrDelta();\n  }\n\n  void TearDown() override {\n    if (!test_skipped_) {\n      cleanUpXdsConnection();\n    }\n  }\n\n  // Overridden to insert this stuff into the initialize() at the very beginning of\n  // HttpIntegrationTest::testRouterHeaderOnlyRequestAndResponse().\n  void initialize() override {\n    use_lds_ = false;\n    test_skipped_ = false;\n    // Controls how many addFakeUpstream() will happen in\n    // BaseIntegrationTest::createUpstreams() (which is part of initialize()).\n    // Make sure this number matches the size of the 'clusters' repeated field in the bootstrap\n    // config that you use!\n    setUpstreamCount(1);                         // the CDS cluster\n    setUpstreamProtocol(Http::CodecType::HTTP2); // CDS uses gRPC uses HTTP2.\n\n    // HttpIntegrationTest::initialize() does many things:\n    // 1) It appends to fake_upstreams_ as many as you asked for via setUpstreamCount().\n    // 2) It updates your bootstrap config with the ports your fake upstreams are actually listening\n    //    on (since you're supposed to leave them as 0).\n    // 3) It creates and starts an IntegrationTestServer - the thing that wraps the almost-actual\n    //    Envoy used in the tests.\n    // 4) Bringing up the server usually entails waiting to ensure that any listeners specified in\n    //    the bootstrap config have come up, and registering them in a port map (see lookupPort()).\n    //    However, this test needs to defer all of that to later.\n    defer_listener_finalization_ = true;\n    HttpIntegrationTest::initialize();\n\n    // Create the regular (i.e. not an xDS server) upstreams. We create them manually here after\n    // initialize() because finalize() expects all fake_upstreams_ to correspond to a static\n    // cluster in the bootstrap config - which we don't want since we're testing dynamic CDS!\n    addFakeUpstream(upstream_codec_type_);\n    addFakeUpstream(upstream_codec_type_);\n    cluster1_ = cluster_creator_(\n        ClusterName1, fake_upstreams_[UpstreamIndex1]->localAddress()->ip()->port(),\n        Network::Test::getLoopbackAddressString(ipVersion()), \"ROUND_ROBIN\");\n    cluster2_ = cluster_creator_(\n        ClusterName2, fake_upstreams_[UpstreamIndex2]->localAddress()->ip()->port(),\n        Network::Test::getLoopbackAddressString(ipVersion()), \"ROUND_ROBIN\");\n\n    // Let Envoy establish its connection to the CDS server.\n    acceptXdsConnection();\n\n    // Do the initial compareDiscoveryRequest / sendDiscoveryResponse for cluster_1.\n    EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"\", {}, {}, {}, true));\n    sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                               {cluster1_}, {cluster1_}, {}, \"55\");\n\n    // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n    // the DiscoveryResponse describing cluster_1 that we sent.\n    // 2 because the statically specified CDS server itself counts as a cluster.\n    test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 2);\n\n    // Wait for our statically specified listener to become ready, and register its port in the\n    // test framework's downstream listener port map.\n    test_server_->waitUntilListenersReady();\n    registerTestServerPorts({\"http\"});\n  }\n\n  // Regression test to catch the code declaring a gRPC service method for {SotW,delta}\n  // when the user's bootstrap config asks for the other type.\n  void verifyGrpcServiceMethod() {\n    EXPECT_TRUE(xds_stream_->waitForHeadersComplete());\n    Envoy::Http::LowerCaseString path_string(\":path\");\n    std::string expected_method(\n        sotwOrDelta() == Grpc::SotwOrDelta::Sotw || sotwOrDelta() == Grpc::SotwOrDelta::UnifiedSotw\n            ? \"/envoy.service.cluster.v3.ClusterDiscoveryService/StreamClusters\"\n            : \"/envoy.service.cluster.v3.ClusterDiscoveryService/DeltaClusters\");\n    EXPECT_EQ(xds_stream_->headers().get(path_string)[0]->value(), expected_method);\n  }\n\n  void acceptXdsConnection() {\n    AssertionResult result = // xds_connection_ is filled with the new FakeHttpConnection.\n        fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, xds_connection_);\n    RELEASE_ASSERT(result, result.message());\n    result = xds_connection_->waitForNewStream(*dispatcher_, xds_stream_);\n    RELEASE_ASSERT(result, result.message());\n    xds_stream_->startGrpcStream();\n    verifyGrpcServiceMethod();\n  }\n\n  envoy::config::cluster::v3::Cluster cluster1_;\n  envoy::config::cluster::v3::Cluster cluster2_;\n  // True if we decided not to run the test after all.\n  bool test_skipped_{true};\n  Http::CodecType upstream_codec_type_{Http::CodecType::HTTP2};\n  std::function<envoy::config::cluster::v3::Cluster(const std::string&, int, const std::string&,\n                                                    const std::string&)>\n      cluster_creator_;\n};\n\nINSTANTIATE_TEST_SUITE_P(IpVersionsClientTypeDelta, CdsIntegrationTest,\n                         DELTA_SOTW_GRPC_CLIENT_INTEGRATION_PARAMS);\n\n// 1) Envoy starts up with no static clusters (other than the CDS-over-gRPC server).\n// 2) Envoy is told of a cluster via CDS.\n// 3) We send Envoy a request, which we verify is properly proxied to and served by that cluster.\n// 4) Envoy is told that cluster is gone.\n// 5) We send Envoy a request, which should 503.\n// 6) Envoy is told that the cluster is back.\n// 7) We send Envoy a request, which we verify is properly proxied to and served by that cluster.\nTEST_P(CdsIntegrationTest, CdsClusterUpDownUp) {\n  // Calls our initialize(), which includes establishing a listener, route, and cluster.\n  config_helper_.addConfigModifier(configureProxyStatus());\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n\n  // Tell Envoy that cluster_1 is gone.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  // Now that cluster_1 is gone, the listener (with its routing to cluster_1) should 503.\n  BufferingStreamDecoderPtr response = IntegrationUtil::makeSingleRequest(\n      lookupPort(\"http\"), \"GET\", \"/cluster1\", \"\", downstream_protocol_, version_, \"foo.com\");\n  ASSERT_TRUE(response->complete());\n  EXPECT_EQ(\"503\", response->headers().getStatusValue());\n  EXPECT_EQ(response->headers().getProxyStatusValue(),\n            \"envoy; error=destination_unavailable; details=\\\"cluster_not_found; NC\\\"\");\n\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Tell Envoy that cluster_1 is back.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"42\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                             {cluster1_}, {cluster1_}, {}, \"413\");\n\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse describing cluster_1 that we sent. Again, 2 includes CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 2);\n\n  // Does *not* call our initialize().\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n\n  cleanupUpstreamAndDownstream();\n}\n\n// Make sure that clusters won't create new connections on teardown.\nTEST_P(CdsIntegrationTest, CdsClusterTeardownWhileConnecting) {\n  initialize();\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n  test_server_->waitForCounterExists(\"cluster.cluster_1.upstream_cx_total\");\n  Stats::CounterSharedPtr cx_counter = test_server_->counter(\"cluster.cluster_1.upstream_cx_total\");\n  // Confirm no upstream connection is attempted so far.\n  EXPECT_EQ(0, cx_counter->value());\n\n  // Make the upstreams stop working, to ensure the connection was not\n  // established.\n  fake_upstreams_[1]->dispatcher()->exit();\n  fake_upstreams_[2]->dispatcher()->exit();\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  auto encoder_decoder = codec_client_->startRequest(Http::TestRequestHeaderMapImpl{\n      {\":method\", \"GET\"}, {\":path\", \"/cluster1\"}, {\":scheme\", \"http\"}, {\":authority\", \"host\"}});\n\n  // Tell Envoy that cluster_1 is gone.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n  codec_client_->sendReset(encoder_decoder.first);\n  cleanupUpstreamAndDownstream();\n\n  // Either 0 or 1 upstream connection is attempted but no more.\n  EXPECT_LE(cx_counter->value(), 1);\n}\n\n// Test the fast addition and removal of clusters when they use ThreadAwareLb.\nTEST_P(CdsIntegrationTest, CdsClusterWithThreadAwareLbCycleUpDownUp) {\n  // Calls our initialize(), which includes establishing a listener, route, and cluster.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n\n  // Tell Envoy that cluster_1 is gone.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // Make sure that Envoy's ClusterManager has made use of the DiscoveryResponse that says cluster_1\n  // is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  // Update cluster1_ to use MAGLEV load balancer policy.\n  cluster1_ = ConfigHelper::buildStaticCluster(\n      ClusterName1, fake_upstreams_[UpstreamIndex1]->localAddress()->ip()->port(),\n      Network::Test::getLoopbackAddressString(ipVersion()), \"MAGLEV\");\n\n  // Cyclically add and remove cluster with ThreadAwareLb.\n  for (int i = 42; i < 142; i += 2) {\n    EXPECT_TRUE(\n        compareDiscoveryRequest(Config::TypeUrl::get().Cluster, absl::StrCat(i), {}, {}, {}));\n    sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n        Config::TypeUrl::get().Cluster, {cluster1_}, {cluster1_}, {}, absl::StrCat(i + 1));\n    EXPECT_TRUE(\n        compareDiscoveryRequest(Config::TypeUrl::get().Cluster, absl::StrCat(i + 1), {}, {}, {}));\n    sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n        Config::TypeUrl::get().Cluster, {}, {}, {ClusterName1}, absl::StrCat(i + 2));\n  }\n\n  cleanupUpstreamAndDownstream();\n}\n\n// Tests adding a cluster, adding another, then removing the first.\nTEST_P(CdsIntegrationTest, TwoClusters) {\n  // Calls our initialize(), which includes establishing a listener, route, and cluster.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Tell Envoy that cluster_2 is here.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n      Config::TypeUrl::get().Cluster, {cluster1_, cluster2_}, {cluster2_}, {}, \"42\");\n  // The '3' includes the fake CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 3);\n\n  // A request for cluster_2 should be fine.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex2, \"/cluster2\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Tell Envoy that cluster_1 is gone.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"42\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                             {cluster2_}, {}, {ClusterName1}, \"43\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  // Even with cluster_1 gone, a request for cluster_2 should be fine.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex2, \"/cluster2\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Tell Envoy that cluster_1 is back.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"43\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n      Config::TypeUrl::get().Cluster, {cluster1_, cluster2_}, {cluster1_}, {}, \"413\");\n\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse describing cluster_1 that we sent. Again, 3 includes CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 3);\n\n  // Does *not* call our initialize().\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n\n  cleanupUpstreamAndDownstream();\n}\n\n// Tests that when Envoy's delta xDS stream dis/reconnects, Envoy can inform the server of the\n// resources it already has: the reconnected stream need not start with a state-of-the-world update.\nTEST_P(CdsIntegrationTest, VersionsRememberedAfterReconnect) {\n  SKIP_IF_XDS_IS(Grpc::SotwOrDelta::Sotw);\n  SKIP_IF_XDS_IS(Grpc::SotwOrDelta::UnifiedSotw);\n\n  // Calls our initialize(), which includes establishing a listener, route, and cluster.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Close the connection carrying Envoy's xDS gRPC stream...\n  AssertionResult result = xds_connection_->close();\n  RELEASE_ASSERT(result, result.message());\n  result = xds_connection_->waitForDisconnect();\n  RELEASE_ASSERT(result, result.message());\n  xds_connection_.reset();\n  // ...and reconnect it.\n  acceptXdsConnection();\n\n  // Upon reconnecting, the Envoy should tell us its current resource versions.\n  envoy::service::discovery::v3::DeltaDiscoveryRequest request;\n  result = xds_stream_->waitForGrpcMessage(*dispatcher_, request);\n  RELEASE_ASSERT(result, result.message());\n  const auto& initial_resource_versions = request.initial_resource_versions();\n  EXPECT_EQ(\"55\", initial_resource_versions.at(std::string(ClusterName1)));\n  EXPECT_EQ(1, initial_resource_versions.size());\n\n  // Tell Envoy that cluster_2 is here. This update does *not* need to include cluster_1,\n  // which Envoy should already know about despite the disconnect.\n  sendDeltaDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                                  {cluster2_}, {}, \"42\");\n  // The '3' includes the fake CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 3);\n\n  // A request for cluster_1 should be fine.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n  // A request for cluster_2 should be fine.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex2, \"/cluster2\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n}\n\n// This test verifies that Envoy can delete a cluster with a lot of idle connections.\n// The original problem was recursive closure of idle connections that can run out\n// of stack when there are a lot of idle connections.\nTEST_P(CdsIntegrationTest, CdsClusterDownWithLotsOfIdleConnections) {\n  constexpr int num_requests = 2000;\n  // Make upstream H/1 so it creates connection for each request\n  upstream_codec_type_ = Http::CodecType::HTTP1;\n  // Relax default circuit breaker limits and timeouts so Envoy can accumulate a lot of idle\n  // connections\n  cluster_creator_ = &ConfigHelper::buildH1ClusterWithHighCircuitBreakersLimits;\n  config_helper_.addConfigModifier(\n      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n              hcm) -> void {\n        hcm.mutable_route_config()\n            ->mutable_virtual_hosts(0)\n            ->mutable_routes(0)\n            ->mutable_route()\n            ->mutable_timeout()\n            ->set_seconds(600);\n        hcm.mutable_route_config()\n            ->mutable_virtual_hosts(0)\n            ->mutable_routes(0)\n            ->mutable_route()\n            ->mutable_idle_timeout()\n            ->set_seconds(600);\n      });\n  initialize();\n  std::vector<IntegrationStreamDecoderPtr> responses;\n  std::vector<FakeHttpConnectionPtr> upstream_connections;\n  std::vector<FakeStreamPtr> upstream_requests;\n  codec_client_ = makeHttpConnection(makeClientConnection((lookupPort(\"http\"))));\n  // The first loop establishes a lot of open connections with active requests to upstream\n  for (int i = 0; i < num_requests; ++i) {\n    Http::TestRequestHeaderMapImpl request_headers{{\":method\", \"GET\"},\n                                                   {\":path\", \"/cluster1\"},\n                                                   {\":scheme\", \"http\"},\n                                                   {\":authority\", \"host\"},\n                                                   {\"x-lyft-user-id\", absl::StrCat(i)}};\n\n    auto response = codec_client_->makeHeaderOnlyRequest(request_headers);\n    responses.push_back(std::move(response));\n\n    FakeHttpConnectionPtr fake_upstream_connection;\n    waitForNextUpstreamConnection({UpstreamIndex1}, TestUtility::DefaultTimeout,\n                                  fake_upstream_connection);\n    // Wait for the next stream on the upstream connection.\n    FakeStreamPtr upstream_request;\n    AssertionResult result =\n        fake_upstream_connection->waitForNewStream(*dispatcher_, upstream_request);\n    RELEASE_ASSERT(result, result.message());\n    // Wait for the stream to be completely received.\n    result = upstream_request->waitForEndStream(*dispatcher_);\n    RELEASE_ASSERT(result, result.message());\n    upstream_connections.push_back(std::move(fake_upstream_connection));\n    upstream_requests.push_back(std::move(upstream_request));\n  }\n\n  // This loop completes all requests making the all upstream connections idle\n  for (int i = 0; i < num_requests; ++i) {\n    // Send response headers, and end_stream if there is no response body.\n    upstream_requests[i]->encodeHeaders(default_response_headers_, true);\n    // Wait for the response to be read by the codec client.\n    RELEASE_ASSERT(responses[i]->waitForEndStream(), \"unexpected timeout\");\n    ASSERT_TRUE(responses[i]->complete());\n    EXPECT_EQ(\"200\", responses[i]->headers().getStatusValue());\n  }\n\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n\n  // Tell Envoy that cluster_1 is gone. Envoy will try to close all idle connections\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  // If we made it this far then everything is ok.\n  for (int i = 0; i < num_requests; ++i) {\n    AssertionResult result = upstream_connections[i]->close();\n    RELEASE_ASSERT(result, result.message());\n    result = upstream_connections[i]->waitForDisconnect();\n    RELEASE_ASSERT(result, result.message());\n  }\n  upstream_connections.clear();\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n}\n\n// This test verifies that Envoy can delete a cluster with a lot of connections in the connecting\n// state and associated pending requests. The recursion guard in the\n// ConnPoolImplBase::closeIdleConnectionsForDrainingPool() would fire if it was called recursively.\n//\n// Test is currently disabled as there is presently no reliable way of making upstream connections\n// hang in connecting state.\nTEST_P(CdsIntegrationTest, DISABLED_CdsClusterDownWithLotsOfConnectingConnections) {\n  // Use low number of pending connections to prevent bumping into the default\n  // limit of 128, since the upstream will be prevented below from\n  // accepting connections.\n  constexpr int num_requests = 64;\n  // Make upstream H/1 so it creates connection for each request\n  upstream_codec_type_ = Http::CodecType::HTTP1;\n  cluster_creator_ = &ConfigHelper::buildH1ClusterWithHighCircuitBreakersLimits;\n  config_helper_.addConfigModifier(\n      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n              hcm) -> void {\n        hcm.mutable_route_config()\n            ->mutable_virtual_hosts(0)\n            ->mutable_routes(0)\n            ->mutable_route()\n            ->mutable_timeout()\n            ->set_seconds(600);\n        hcm.mutable_route_config()\n            ->mutable_virtual_hosts(0)\n            ->mutable_routes(0)\n            ->mutable_route()\n            ->mutable_idle_timeout()\n            ->set_seconds(600);\n      });\n  initialize();\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n  std::vector<IntegrationStreamDecoderPtr> responses;\n  codec_client_ = makeHttpConnection(makeClientConnection((lookupPort(\"http\"))));\n  // Stop upstream at UpstreamIndex1 dispatcher, to prevent it from accepting TCP connections.\n  // This will cause Envoy's connections to that upstream hang in the connecting state.\n  fake_upstreams_[UpstreamIndex1]->dispatcher()->exit();\n  for (int i = 0; i < num_requests; ++i) {\n    Http::TestRequestHeaderMapImpl request_headers{{\":method\", \"GET\"},\n                                                   {\":path\", \"/cluster1\"},\n                                                   {\":scheme\", \"http\"},\n                                                   {\":authority\", \"host\"},\n                                                   {\"x-lyft-user-id\", absl::StrCat(i)}};\n\n    auto response = codec_client_->makeHeaderOnlyRequest(request_headers);\n    responses.push_back(std::move(response));\n  }\n\n  // Wait for Envoy to try to establish all expected connections\n  test_server_->waitForCounterEq(\"cluster.cluster_1.upstream_cx_total\", num_requests);\n\n  // Tell Envoy that cluster_1 is gone. Envoy will try to close all pending connections\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n  // If we got here it means that the recursion guard in the\n  // ConnPoolImplBase::closeIdleConnectionsForDrainingPool() did not fire, which is what this test\n  // validates.\n}\n\n} // namespace\n} // namespace Envoy\n"], "fixing_code": ["#include \"source/common/http/conn_manager_impl.h\"\n\n#include <cstdint>\n#include <functional>\n#include <list>\n#include <memory>\n#include <string>\n#include <vector>\n\n#include \"envoy/buffer/buffer.h\"\n#include \"envoy/common/time.h\"\n#include \"envoy/event/dispatcher.h\"\n#include \"envoy/event/scaled_range_timer_manager.h\"\n#include \"envoy/extensions/filters/network/http_connection_manager/v3/http_connection_manager.pb.h\"\n#include \"envoy/http/header_map.h\"\n#include \"envoy/network/drain_decision.h\"\n#include \"envoy/router/router.h\"\n#include \"envoy/ssl/connection.h\"\n#include \"envoy/stats/scope.h\"\n#include \"envoy/stream_info/filter_state.h\"\n#include \"envoy/stream_info/stream_info.h\"\n#include \"envoy/tracing/http_tracer.h\"\n#include \"envoy/type/v3/percent.pb.h\"\n\n#include \"source/common/buffer/buffer_impl.h\"\n#include \"source/common/common/assert.h\"\n#include \"source/common/common/empty_string.h\"\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/fmt.h\"\n#include \"source/common/common/perf_tracing.h\"\n#include \"source/common/common/scope_tracker.h\"\n#include \"source/common/common/utility.h\"\n#include \"source/common/http/codes.h\"\n#include \"source/common/http/conn_manager_utility.h\"\n#include \"source/common/http/exception.h\"\n#include \"source/common/http/header_map_impl.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/http/headers.h\"\n#include \"source/common/http/http1/codec_impl.h\"\n#include \"source/common/http/http2/codec_impl.h\"\n#include \"source/common/http/path_utility.h\"\n#include \"source/common/http/status.h\"\n#include \"source/common/http/utility.h\"\n#include \"source/common/network/utility.h\"\n#include \"source/common/router/config_impl.h\"\n#include \"source/common/runtime/runtime_features.h\"\n#include \"source/common/stats/timespan_impl.h\"\n#include \"source/common/stream_info/utility.h\"\n\n#include \"absl/strings/escaping.h\"\n#include \"absl/strings/match.h\"\n#include \"absl/strings/str_cat.h\"\n\nnamespace Envoy {\nnamespace Http {\n\nbool requestWasConnect(const RequestHeaderMapPtr& headers, Protocol protocol) {\n  if (!headers) {\n    return false;\n  }\n  if (protocol <= Protocol::Http11) {\n    return HeaderUtility::isConnect(*headers);\n  }\n  // All HTTP/2 style upgrades were originally connect requests.\n  return HeaderUtility::isConnect(*headers) || Utility::isUpgrade(*headers);\n}\n\nConnectionManagerStats ConnectionManagerImpl::generateStats(const std::string& prefix,\n                                                            Stats::Scope& scope) {\n  return ConnectionManagerStats(\n      {ALL_HTTP_CONN_MAN_STATS(POOL_COUNTER_PREFIX(scope, prefix), POOL_GAUGE_PREFIX(scope, prefix),\n                               POOL_HISTOGRAM_PREFIX(scope, prefix))},\n      prefix, scope);\n}\n\nConnectionManagerTracingStats ConnectionManagerImpl::generateTracingStats(const std::string& prefix,\n                                                                          Stats::Scope& scope) {\n  return {CONN_MAN_TRACING_STATS(POOL_COUNTER_PREFIX(scope, prefix + \"tracing.\"))};\n}\n\nConnectionManagerListenerStats\nConnectionManagerImpl::generateListenerStats(const std::string& prefix, Stats::Scope& scope) {\n  return {CONN_MAN_LISTENER_STATS(POOL_COUNTER_PREFIX(scope, prefix))};\n}\n\nConnectionManagerImpl::ConnectionManagerImpl(ConnectionManagerConfig& config,\n                                             const Network::DrainDecision& drain_close,\n                                             Random::RandomGenerator& random_generator,\n                                             Http::Context& http_context, Runtime::Loader& runtime,\n                                             const LocalInfo::LocalInfo& local_info,\n                                             Upstream::ClusterManager& cluster_manager,\n                                             Server::OverloadManager& overload_manager,\n                                             TimeSource& time_source)\n    : config_(config), stats_(config_.stats()),\n      conn_length_(new Stats::HistogramCompletableTimespanImpl(\n          stats_.named_.downstream_cx_length_ms_, time_source)),\n      drain_close_(drain_close), user_agent_(http_context.userAgentContext()),\n      random_generator_(random_generator), http_context_(http_context), runtime_(runtime),\n      local_info_(local_info), cluster_manager_(cluster_manager),\n      listener_stats_(config_.listenerStats()),\n      overload_state_(overload_manager.getThreadLocalOverloadState()),\n      overload_stop_accepting_requests_ref_(\n          overload_state_.getState(Server::OverloadActionNames::get().StopAcceptingRequests)),\n      overload_disable_keepalive_ref_(\n          overload_state_.getState(Server::OverloadActionNames::get().DisableHttpKeepAlive)),\n      time_source_(time_source), proxy_name_(StreamInfo::ProxyStatusUtils::makeProxyName(\n                                     /*node_id=*/local_info_.node().id(),\n                                     /*server_name=*/config_.serverName(),\n                                     /*proxy_status_config=*/config_.proxyStatusConfig())) {}\n\nconst ResponseHeaderMap& ConnectionManagerImpl::continueHeader() {\n  static const auto headers = createHeaderMap<ResponseHeaderMapImpl>(\n      {{Http::Headers::get().Status, std::to_string(enumToInt(Code::Continue))}});\n  return *headers;\n}\n\nvoid ConnectionManagerImpl::initializeReadFilterCallbacks(Network::ReadFilterCallbacks& callbacks) {\n  read_callbacks_ = &callbacks;\n  stats_.named_.downstream_cx_total_.inc();\n  stats_.named_.downstream_cx_active_.inc();\n  if (read_callbacks_->connection().ssl()) {\n    stats_.named_.downstream_cx_ssl_total_.inc();\n    stats_.named_.downstream_cx_ssl_active_.inc();\n  }\n\n  read_callbacks_->connection().addConnectionCallbacks(*this);\n\n  if (!read_callbacks_->connection()\n           .streamInfo()\n           .filterState()\n           ->hasData<Network::ProxyProtocolFilterState>(Network::ProxyProtocolFilterState::key())) {\n    read_callbacks_->connection().streamInfo().filterState()->setData(\n        Network::ProxyProtocolFilterState::key(),\n        std::make_unique<Network::ProxyProtocolFilterState>(Network::ProxyProtocolData{\n            read_callbacks_->connection().connectionInfoProvider().remoteAddress(),\n            read_callbacks_->connection().connectionInfoProvider().localAddress()}),\n        StreamInfo::FilterState::StateType::ReadOnly,\n        StreamInfo::FilterState::LifeSpan::Connection);\n  }\n\n  if (config_.idleTimeout()) {\n    connection_idle_timer_ = read_callbacks_->connection().dispatcher().createScaledTimer(\n        Event::ScaledTimerType::HttpDownstreamIdleConnectionTimeout,\n        [this]() -> void { onIdleTimeout(); });\n    connection_idle_timer_->enableTimer(config_.idleTimeout().value());\n  }\n\n  if (config_.maxConnectionDuration()) {\n    connection_duration_timer_ = read_callbacks_->connection().dispatcher().createTimer(\n        [this]() -> void { onConnectionDurationTimeout(); });\n    connection_duration_timer_->enableTimer(config_.maxConnectionDuration().value());\n  }\n\n  read_callbacks_->connection().setDelayedCloseTimeout(config_.delayedCloseTimeout());\n\n  read_callbacks_->connection().setConnectionStats(\n      {stats_.named_.downstream_cx_rx_bytes_total_, stats_.named_.downstream_cx_rx_bytes_buffered_,\n       stats_.named_.downstream_cx_tx_bytes_total_, stats_.named_.downstream_cx_tx_bytes_buffered_,\n       nullptr, &stats_.named_.downstream_cx_delayed_close_timeout_});\n}\n\nConnectionManagerImpl::~ConnectionManagerImpl() {\n  stats_.named_.downstream_cx_destroy_.inc();\n\n  stats_.named_.downstream_cx_active_.dec();\n  if (read_callbacks_->connection().ssl()) {\n    stats_.named_.downstream_cx_ssl_active_.dec();\n  }\n\n  if (codec_) {\n    if (codec_->protocol() == Protocol::Http2) {\n      stats_.named_.downstream_cx_http2_active_.dec();\n    } else if (codec_->protocol() == Protocol::Http3) {\n      stats_.named_.downstream_cx_http3_active_.dec();\n    } else {\n      stats_.named_.downstream_cx_http1_active_.dec();\n    }\n  }\n\n  conn_length_->complete();\n  user_agent_.completeConnectionLength(*conn_length_);\n}\n\nvoid ConnectionManagerImpl::checkForDeferredClose(bool skip_delay_close) {\n  Network::ConnectionCloseType close = Network::ConnectionCloseType::FlushWriteAndDelay;\n  if (Runtime::runtimeFeatureEnabled(\"envoy.reloadable_features.skip_delay_close\") &&\n      skip_delay_close) {\n    close = Network::ConnectionCloseType::FlushWrite;\n  }\n  if (drain_state_ == DrainState::Closing && streams_.empty() && !codec_->wantsToWrite()) {\n    doConnectionClose(close, absl::nullopt,\n                      StreamInfo::ResponseCodeDetails::get().DownstreamLocalDisconnect);\n  }\n}\n\nvoid ConnectionManagerImpl::doEndStream(ActiveStream& stream) {\n  // The order of what happens in this routine is important and a little complicated. We first see\n  // if the stream needs to be reset. If it needs to be, this will end up invoking reset callbacks\n  // and then moving the stream to the deferred destruction list. If the stream has not been reset,\n  // we move it to the deferred deletion list here. Then, we potentially close the connection. This\n  // must be done after deleting the stream since the stream refers to the connection and must be\n  // deleted first.\n  bool reset_stream = false;\n  // If the response encoder is still associated with the stream, reset the stream. The exception\n  // here is when Envoy \"ends\" the stream by calling recreateStream at which point recreateStream\n  // explicitly nulls out response_encoder to avoid the downstream being notified of the\n  // Envoy-internal stream instance being ended.\n  if (stream.response_encoder_ != nullptr && (!stream.filter_manager_.remoteDecodeComplete() ||\n                                              !stream.state_.codec_saw_local_complete_)) {\n    // Indicate local is complete at this point so that if we reset during a continuation, we don't\n    // raise further data or trailers.\n    ENVOY_STREAM_LOG(debug, \"doEndStream() resetting stream\", stream);\n    // TODO(snowp): This call might not be necessary, try to clean up + remove setter function.\n    stream.filter_manager_.setLocalComplete();\n    stream.state_.codec_saw_local_complete_ = true;\n\n    // Per https://tools.ietf.org/html/rfc7540#section-8.3 if there was an error\n    // with the TCP connection during a CONNECT request, it should be\n    // communicated via CONNECT_ERROR\n    if (requestWasConnect(stream.request_headers_, codec_->protocol()) &&\n        (stream.filter_manager_.streamInfo().hasResponseFlag(\n             StreamInfo::ResponseFlag::UpstreamConnectionFailure) ||\n         stream.filter_manager_.streamInfo().hasResponseFlag(\n             StreamInfo::ResponseFlag::UpstreamConnectionTermination))) {\n      stream.response_encoder_->getStream().resetStream(StreamResetReason::ConnectError);\n    } else {\n      if (stream.filter_manager_.streamInfo().hasResponseFlag(\n              StreamInfo::ResponseFlag::UpstreamProtocolError)) {\n        stream.response_encoder_->getStream().resetStream(StreamResetReason::ProtocolError);\n      } else {\n        stream.response_encoder_->getStream().resetStream(StreamResetReason::LocalReset);\n      }\n    }\n    reset_stream = true;\n  }\n\n  if (!reset_stream) {\n    doDeferredStreamDestroy(stream);\n  }\n\n  if (reset_stream && codec_->protocol() < Protocol::Http2) {\n    drain_state_ = DrainState::Closing;\n  }\n\n  // If HTTP/1.0 has no content length, it is framed by close and won't consider\n  // the request complete until the FIN is read. Don't delay close in this case.\n  bool http_10_sans_cl = (codec_->protocol() == Protocol::Http10) &&\n                         (!stream.response_headers_ || !stream.response_headers_->ContentLength());\n  // We also don't delay-close in the case of HTTP/1.1 where the request is\n  // fully read, as there's no race condition to avoid.\n  bool connection_close = stream.state_.saw_connection_close_;\n  bool request_complete = stream.filter_manager_.remoteDecodeComplete();\n\n  checkForDeferredClose(connection_close && (request_complete || http_10_sans_cl));\n}\n\nvoid ConnectionManagerImpl::doDeferredStreamDestroy(ActiveStream& stream) {\n  if (stream.max_stream_duration_timer_) {\n    stream.max_stream_duration_timer_->disableTimer();\n    stream.max_stream_duration_timer_ = nullptr;\n  }\n  if (stream.stream_idle_timer_ != nullptr) {\n    stream.stream_idle_timer_->disableTimer();\n    stream.stream_idle_timer_ = nullptr;\n  }\n  stream.filter_manager_.disarmRequestTimeout();\n  if (stream.request_header_timer_ != nullptr) {\n    stream.request_header_timer_->disableTimer();\n    stream.request_header_timer_ = nullptr;\n  }\n\n  stream.completeRequest();\n  stream.filter_manager_.onStreamComplete();\n  stream.filter_manager_.log();\n\n  stream.filter_manager_.destroyFilters();\n\n  read_callbacks_->connection().dispatcher().deferredDelete(stream.removeFromList(streams_));\n\n  // The response_encoder should never be dangling (unless we're destroying a\n  // stream we are recreating) as the codec level stream will either outlive the\n  // ActiveStream, or be alive in deferred deletion queue at this point.\n  if (stream.response_encoder_) {\n    stream.response_encoder_->getStream().removeCallbacks(stream);\n  }\n\n  if (connection_idle_timer_ && streams_.empty()) {\n    connection_idle_timer_->enableTimer(config_.idleTimeout().value());\n  }\n}\n\nRequestDecoder& ConnectionManagerImpl::newStream(ResponseEncoder& response_encoder,\n                                                 bool is_internally_created) {\n  TRACE_EVENT(\"core\", \"ConnectionManagerImpl::newStream\");\n  if (connection_idle_timer_) {\n    connection_idle_timer_->disableTimer();\n  }\n\n  ENVOY_CONN_LOG(debug, \"new stream\", read_callbacks_->connection());\n\n  // Create account, wiring the stream to use it for tracking bytes.\n  // If tracking is disabled, the wiring becomes a NOP.\n  auto& buffer_factory = read_callbacks_->connection().dispatcher().getWatermarkFactory();\n  Buffer::BufferMemoryAccountSharedPtr downstream_stream_account =\n      buffer_factory.createAccount(response_encoder.getStream());\n  response_encoder.getStream().setAccount(downstream_stream_account);\n  ActiveStreamPtr new_stream(new ActiveStream(*this, response_encoder.getStream().bufferLimit(),\n                                              std::move(downstream_stream_account)));\n\n  accumulated_requests_++;\n  if (config_.maxRequestsPerConnection() > 0 &&\n      accumulated_requests_ >= config_.maxRequestsPerConnection()) {\n    if (codec_->protocol() < Protocol::Http2) {\n      new_stream->state_.saw_connection_close_ = true;\n      // Prevent erroneous debug log of closing due to incoming connection close header.\n      drain_state_ = DrainState::Closing;\n    } else if (drain_state_ == DrainState::NotDraining) {\n      startDrainSequence();\n    }\n    ENVOY_CONN_LOG(debug, \"max requests per connection reached\", read_callbacks_->connection());\n    stats_.named_.downstream_cx_max_requests_reached_.inc();\n  }\n\n  new_stream->state_.is_internally_created_ = is_internally_created;\n  new_stream->response_encoder_ = &response_encoder;\n  new_stream->response_encoder_->getStream().addCallbacks(*new_stream);\n  new_stream->response_encoder_->getStream().setFlushTimeout(new_stream->idle_timeout_ms_);\n  new_stream->streamInfo().setDownstreamBytesMeter(response_encoder.getStream().bytesMeter());\n  // If the network connection is backed up, the stream should be made aware of it on creation.\n  // Both HTTP/1.x and HTTP/2 codecs handle this in StreamCallbackHelper::addCallbacksHelper.\n  ASSERT(read_callbacks_->connection().aboveHighWatermark() == false ||\n         new_stream->filter_manager_.aboveHighWatermark());\n  LinkedList::moveIntoList(std::move(new_stream), streams_);\n  return **streams_.begin();\n}\n\nvoid ConnectionManagerImpl::handleCodecError(absl::string_view error) {\n  ENVOY_CONN_LOG(debug, \"dispatch error: {}\", read_callbacks_->connection(), error);\n  read_callbacks_->connection().streamInfo().setResponseFlag(\n      StreamInfo::ResponseFlag::DownstreamProtocolError);\n\n  // HTTP/1.1 codec has already sent a 400 response if possible. HTTP/2 codec has already sent\n  // GOAWAY.\n  doConnectionClose(Network::ConnectionCloseType::FlushWriteAndDelay,\n                    StreamInfo::ResponseFlag::DownstreamProtocolError,\n                    absl::StrCat(\"codec_error:\", StringUtil::replaceAllEmptySpace(error)));\n}\n\nvoid ConnectionManagerImpl::createCodec(Buffer::Instance& data) {\n  ASSERT(!codec_);\n  codec_ = config_.createCodec(read_callbacks_->connection(), data, *this);\n\n  switch (codec_->protocol()) {\n  case Protocol::Http3:\n    stats_.named_.downstream_cx_http3_total_.inc();\n    stats_.named_.downstream_cx_http3_active_.inc();\n    break;\n  case Protocol::Http2:\n    stats_.named_.downstream_cx_http2_total_.inc();\n    stats_.named_.downstream_cx_http2_active_.inc();\n    break;\n  case Protocol::Http11:\n  case Protocol::Http10:\n    stats_.named_.downstream_cx_http1_total_.inc();\n    stats_.named_.downstream_cx_http1_active_.inc();\n    break;\n  }\n}\n\nNetwork::FilterStatus ConnectionManagerImpl::onData(Buffer::Instance& data, bool) {\n  if (!codec_) {\n    // Http3 codec should have been instantiated by now.\n    createCodec(data);\n  }\n\n  bool redispatch;\n  do {\n    redispatch = false;\n\n    const Status status = codec_->dispatch(data);\n\n    if (isBufferFloodError(status) || isInboundFramesWithEmptyPayloadError(status)) {\n      handleCodecError(status.message());\n      return Network::FilterStatus::StopIteration;\n    } else if (isCodecProtocolError(status)) {\n      stats_.named_.downstream_cx_protocol_error_.inc();\n      handleCodecError(status.message());\n      return Network::FilterStatus::StopIteration;\n    }\n    ASSERT(status.ok());\n\n    // Processing incoming data may release outbound data so check for closure here as well.\n    checkForDeferredClose(false);\n\n    // The HTTP/1 codec will pause dispatch after a single message is complete. We want to\n    // either redispatch if there are no streams and we have more data. If we have a single\n    // complete non-WebSocket stream but have not responded yet we will pause socket reads\n    // to apply back pressure.\n    if (codec_->protocol() < Protocol::Http2) {\n      if (read_callbacks_->connection().state() == Network::Connection::State::Open &&\n          data.length() > 0 && streams_.empty()) {\n        redispatch = true;\n      }\n    }\n  } while (redispatch);\n\n  if (!read_callbacks_->connection().streamInfo().protocol()) {\n    read_callbacks_->connection().streamInfo().protocol(codec_->protocol());\n  }\n\n  return Network::FilterStatus::StopIteration;\n}\n\nNetwork::FilterStatus ConnectionManagerImpl::onNewConnection() {\n  if (!read_callbacks_->connection().streamInfo().protocol()) {\n    // For Non-QUIC traffic, continue passing data to filters.\n    return Network::FilterStatus::Continue;\n  }\n  // Only QUIC connection's stream_info_ specifies protocol.\n  Buffer::OwnedImpl dummy;\n  createCodec(dummy);\n  ASSERT(codec_->protocol() == Protocol::Http3);\n  // Stop iterating through each filters for QUIC. Currently a QUIC connection\n  // only supports one filter, HCM, and bypasses the onData() interface. Because\n  // QUICHE already handles de-multiplexing.\n  return Network::FilterStatus::StopIteration;\n}\n\nvoid ConnectionManagerImpl::resetAllStreams(absl::optional<StreamInfo::ResponseFlag> response_flag,\n                                            absl::string_view details) {\n  while (!streams_.empty()) {\n    // Mimic a downstream reset in this case. We must also remove callbacks here. Though we are\n    // about to close the connection and will disable further reads, it is possible that flushing\n    // data out can cause stream callbacks to fire (e.g., low watermark callbacks).\n    //\n    // TODO(mattklein123): I tried to actually reset through the codec here, but ran into issues\n    // with nghttp2 state and being unhappy about sending reset frames after the connection had\n    // been terminated via GOAWAY. It might be possible to do something better here inside the h2\n    // codec but there are no easy answers and this seems simpler.\n    auto& stream = *streams_.front();\n    stream.response_encoder_->getStream().removeCallbacks(stream);\n    if (!stream.response_encoder_->getStream().responseDetails().empty()) {\n      stream.filter_manager_.streamInfo().setResponseCodeDetails(\n          stream.response_encoder_->getStream().responseDetails());\n    } else if (!details.empty()) {\n      stream.filter_manager_.streamInfo().setResponseCodeDetails(details);\n    }\n    if (response_flag.has_value()) {\n      stream.filter_manager_.streamInfo().setResponseFlag(response_flag.value());\n    }\n    stream.onResetStream(StreamResetReason::ConnectionTermination, absl::string_view());\n  }\n}\n\nvoid ConnectionManagerImpl::onEvent(Network::ConnectionEvent event) {\n  if (event == Network::ConnectionEvent::LocalClose) {\n    stats_.named_.downstream_cx_destroy_local_.inc();\n  }\n\n  if (event == Network::ConnectionEvent::RemoteClose ||\n      event == Network::ConnectionEvent::LocalClose) {\n    if (event == Network::ConnectionEvent::RemoteClose) {\n      remote_close_ = true;\n      stats_.named_.downstream_cx_destroy_remote_.inc();\n    }\n    absl::string_view details =\n        event == Network::ConnectionEvent::RemoteClose\n            ? StreamInfo::ResponseCodeDetails::get().DownstreamRemoteDisconnect\n            : StreamInfo::ResponseCodeDetails::get().DownstreamLocalDisconnect;\n    // TODO(mattklein123): It is technically possible that something outside of the filter causes\n    // a local connection close, so we still guard against that here. A better solution would be to\n    // have some type of \"pre-close\" callback that we could hook for cleanup that would get called\n    // regardless of where local close is invoked from.\n    // NOTE: that this will cause doConnectionClose() to get called twice in the common local close\n    // cases, but the method protects against that.\n    // NOTE: In the case where a local close comes from outside the filter, this will cause any\n    // stream closures to increment remote close stats. We should do better here in the future,\n    // via the pre-close callback mentioned above.\n    doConnectionClose(absl::nullopt, absl::nullopt, details);\n  }\n}\n\nvoid ConnectionManagerImpl::doConnectionClose(\n    absl::optional<Network::ConnectionCloseType> close_type,\n    absl::optional<StreamInfo::ResponseFlag> response_flag, absl::string_view details) {\n  if (connection_idle_timer_) {\n    connection_idle_timer_->disableTimer();\n    connection_idle_timer_.reset();\n  }\n\n  if (connection_duration_timer_) {\n    connection_duration_timer_->disableTimer();\n    connection_duration_timer_.reset();\n  }\n\n  if (drain_timer_) {\n    drain_timer_->disableTimer();\n    drain_timer_.reset();\n  }\n\n  if (!streams_.empty()) {\n    const Network::ConnectionEvent event = close_type.has_value()\n                                               ? Network::ConnectionEvent::LocalClose\n                                               : Network::ConnectionEvent::RemoteClose;\n    if (event == Network::ConnectionEvent::LocalClose) {\n      stats_.named_.downstream_cx_destroy_local_active_rq_.inc();\n    }\n    if (event == Network::ConnectionEvent::RemoteClose) {\n      stats_.named_.downstream_cx_destroy_remote_active_rq_.inc();\n    }\n\n    stats_.named_.downstream_cx_destroy_active_rq_.inc();\n    user_agent_.onConnectionDestroy(event, true);\n    // Note that resetAllStreams() does not actually write anything to the wire. It just resets\n    // all upstream streams and their filter stacks. Thus, there are no issues around recursive\n    // entry.\n    resetAllStreams(response_flag, details);\n  }\n\n  if (close_type.has_value()) {\n    read_callbacks_->connection().close(close_type.value());\n  }\n}\n\nvoid ConnectionManagerImpl::onGoAway(GoAwayErrorCode) {\n  // Currently we do nothing with remote go away frames. In the future we can decide to no longer\n  // push resources if applicable.\n}\n\nvoid ConnectionManagerImpl::onIdleTimeout() {\n  ENVOY_CONN_LOG(debug, \"idle timeout\", read_callbacks_->connection());\n  stats_.named_.downstream_cx_idle_timeout_.inc();\n  if (!codec_) {\n    // No need to delay close after flushing since an idle timeout has already fired. Attempt to\n    // write out buffered data one last time and issue a local close if successful.\n    doConnectionClose(Network::ConnectionCloseType::FlushWrite, absl::nullopt, \"\");\n  } else if (drain_state_ == DrainState::NotDraining) {\n    startDrainSequence();\n  }\n}\n\nvoid ConnectionManagerImpl::onConnectionDurationTimeout() {\n  ENVOY_CONN_LOG(debug, \"max connection duration reached\", read_callbacks_->connection());\n  stats_.named_.downstream_cx_max_duration_reached_.inc();\n  if (!codec_) {\n    // Attempt to write out buffered data one last time and issue a local close if successful.\n    doConnectionClose(Network::ConnectionCloseType::FlushWrite,\n                      StreamInfo::ResponseFlag::DurationTimeout,\n                      StreamInfo::ResponseCodeDetails::get().DurationTimeout);\n  } else if (drain_state_ == DrainState::NotDraining) {\n    startDrainSequence();\n  }\n}\n\nvoid ConnectionManagerImpl::onDrainTimeout() {\n  ASSERT(drain_state_ != DrainState::NotDraining);\n  codec_->goAway();\n  drain_state_ = DrainState::Closing;\n  checkForDeferredClose(false);\n}\n\nvoid ConnectionManagerImpl::chargeTracingStats(const Tracing::Reason& tracing_reason,\n                                               ConnectionManagerTracingStats& tracing_stats) {\n  switch (tracing_reason) {\n  case Tracing::Reason::ClientForced:\n    tracing_stats.client_enabled_.inc();\n    break;\n  case Tracing::Reason::Sampling:\n    tracing_stats.random_sampling_.inc();\n    break;\n  case Tracing::Reason::ServiceForced:\n    tracing_stats.service_forced_.inc();\n    break;\n  default:\n    tracing_stats.not_traceable_.inc();\n    break;\n  }\n}\n\n// TODO(chaoqin-li1123): Make on demand vhds and on demand srds works at the same time.\nvoid ConnectionManagerImpl::RdsRouteConfigUpdateRequester::requestRouteConfigUpdate(\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  absl::optional<Router::ConfigConstSharedPtr> route_config = parent_.routeConfig();\n  Event::Dispatcher& thread_local_dispatcher =\n      parent_.connection_manager_.read_callbacks_->connection().dispatcher();\n  if (route_config.has_value() && route_config.value()->usesVhds()) {\n    ASSERT(!parent_.request_headers_->Host()->value().empty());\n    const auto& host_header = absl::AsciiStrToLower(parent_.request_headers_->getHostValue());\n    requestVhdsUpdate(host_header, thread_local_dispatcher, std::move(route_config_updated_cb));\n    return;\n  } else if (parent_.snapped_scoped_routes_config_ != nullptr) {\n    Router::ScopeKeyPtr scope_key =\n        parent_.snapped_scoped_routes_config_->computeScopeKey(*parent_.request_headers_);\n    // If scope_key is not null, the scope exists but RouteConfiguration is not initialized.\n    if (scope_key != nullptr) {\n      requestSrdsUpdate(std::move(scope_key), thread_local_dispatcher,\n                        std::move(route_config_updated_cb));\n      return;\n    }\n  }\n  // Continue the filter chain if no on demand update is requested.\n  (*route_config_updated_cb)(false);\n}\n\nvoid ConnectionManagerImpl::RdsRouteConfigUpdateRequester::requestVhdsUpdate(\n    const std::string& host_header, Event::Dispatcher& thread_local_dispatcher,\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  route_config_provider_->requestVirtualHostsUpdate(host_header, thread_local_dispatcher,\n                                                    std::move(route_config_updated_cb));\n}\n\nvoid ConnectionManagerImpl::RdsRouteConfigUpdateRequester::requestSrdsUpdate(\n    Router::ScopeKeyPtr scope_key, Event::Dispatcher& thread_local_dispatcher,\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  // Since inline scope_route_config_provider is not fully implemented and never used,\n  // dynamic cast in constructor always succeed and the pointer should not be null here.\n  ASSERT(scoped_route_config_provider_ != nullptr);\n  Http::RouteConfigUpdatedCallback scoped_route_config_updated_cb =\n      Http::RouteConfigUpdatedCallback(\n          [this, weak_route_config_updated_cb = std::weak_ptr<Http::RouteConfigUpdatedCallback>(\n                     route_config_updated_cb)](bool scope_exist) {\n            // If the callback can be locked, this ActiveStream is still alive.\n            if (auto cb = weak_route_config_updated_cb.lock()) {\n              // Refresh the route before continue the filter chain.\n              if (scope_exist) {\n                parent_.refreshCachedRoute();\n              }\n              (*cb)(scope_exist && parent_.hasCachedRoute());\n            }\n          });\n  scoped_route_config_provider_->onDemandRdsUpdate(std::move(scope_key), thread_local_dispatcher,\n                                                   std::move(scoped_route_config_updated_cb));\n}\n\nConnectionManagerImpl::ActiveStream::ActiveStream(ConnectionManagerImpl& connection_manager,\n                                                  uint32_t buffer_limit,\n                                                  Buffer::BufferMemoryAccountSharedPtr account)\n    : connection_manager_(connection_manager),\n      stream_id_(connection_manager.random_generator_.random()),\n      filter_manager_(*this, connection_manager_.read_callbacks_->connection().dispatcher(),\n                      connection_manager_.read_callbacks_->connection(), stream_id_,\n                      std::move(account), connection_manager_.config_.proxy100Continue(),\n                      buffer_limit, connection_manager_.config_.filterFactory(),\n                      connection_manager_.config_.localReply(),\n                      connection_manager_.codec_->protocol(), connection_manager_.timeSource(),\n                      connection_manager_.read_callbacks_->connection().streamInfo().filterState(),\n                      StreamInfo::FilterState::LifeSpan::Connection),\n      request_response_timespan_(new Stats::HistogramCompletableTimespanImpl(\n          connection_manager_.stats_.named_.downstream_rq_time_,\n          connection_manager_.timeSource())) {\n  ASSERT(!connection_manager.config_.isRoutable() ||\n             ((connection_manager.config_.routeConfigProvider() == nullptr &&\n               connection_manager.config_.scopedRouteConfigProvider() != nullptr) ||\n              (connection_manager.config_.routeConfigProvider() != nullptr &&\n               connection_manager.config_.scopedRouteConfigProvider() == nullptr)),\n         \"Either routeConfigProvider or scopedRouteConfigProvider should be set in \"\n         \"ConnectionManagerImpl.\");\n  for (const AccessLog::InstanceSharedPtr& access_log : connection_manager_.config_.accessLogs()) {\n    filter_manager_.addAccessLogHandler(access_log);\n  }\n\n  filter_manager_.streamInfo().setRequestIDProvider(\n      connection_manager.config_.requestIDExtension());\n\n  if (connection_manager_.config_.isRoutable() &&\n      connection_manager.config_.routeConfigProvider() != nullptr) {\n    route_config_update_requester_ =\n        std::make_unique<ConnectionManagerImpl::RdsRouteConfigUpdateRequester>(\n            connection_manager.config_.routeConfigProvider(), *this);\n  } else if (connection_manager_.config_.isRoutable() &&\n             connection_manager.config_.scopedRouteConfigProvider() != nullptr) {\n    route_config_update_requester_ =\n        std::make_unique<ConnectionManagerImpl::RdsRouteConfigUpdateRequester>(\n            connection_manager.config_.scopedRouteConfigProvider(), *this);\n  }\n  ScopeTrackerScopeState scope(this,\n                               connection_manager_.read_callbacks_->connection().dispatcher());\n\n  connection_manager_.stats_.named_.downstream_rq_total_.inc();\n  connection_manager_.stats_.named_.downstream_rq_active_.inc();\n  if (connection_manager_.codec_->protocol() == Protocol::Http2) {\n    connection_manager_.stats_.named_.downstream_rq_http2_total_.inc();\n  } else if (connection_manager_.codec_->protocol() == Protocol::Http3) {\n    connection_manager_.stats_.named_.downstream_rq_http3_total_.inc();\n  } else {\n    connection_manager_.stats_.named_.downstream_rq_http1_total_.inc();\n  }\n\n  if (connection_manager_.config_.streamIdleTimeout().count()) {\n    idle_timeout_ms_ = connection_manager_.config_.streamIdleTimeout();\n    stream_idle_timer_ =\n        connection_manager_.read_callbacks_->connection().dispatcher().createScaledTimer(\n            Event::ScaledTimerType::HttpDownstreamIdleStreamTimeout,\n            [this]() -> void { onIdleTimeout(); });\n    resetIdleTimer();\n  }\n\n  if (connection_manager_.config_.requestTimeout().count()) {\n    std::chrono::milliseconds request_timeout = connection_manager_.config_.requestTimeout();\n    request_timer_ = connection_manager.read_callbacks_->connection().dispatcher().createTimer(\n        [this]() -> void { onRequestTimeout(); });\n    request_timer_->enableTimer(request_timeout, this);\n  }\n\n  if (connection_manager_.config_.requestHeadersTimeout().count()) {\n    std::chrono::milliseconds request_headers_timeout =\n        connection_manager_.config_.requestHeadersTimeout();\n    request_header_timer_ =\n        connection_manager.read_callbacks_->connection().dispatcher().createTimer(\n            [this]() -> void { onRequestHeaderTimeout(); });\n    request_header_timer_->enableTimer(request_headers_timeout, this);\n  }\n\n  const auto max_stream_duration = connection_manager_.config_.maxStreamDuration();\n  if (max_stream_duration.has_value() && max_stream_duration.value().count()) {\n    max_stream_duration_timer_ =\n        connection_manager.read_callbacks_->connection().dispatcher().createTimer(\n            [this]() -> void { onStreamMaxDurationReached(); });\n    max_stream_duration_timer_->enableTimer(connection_manager_.config_.maxStreamDuration().value(),\n                                            this);\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::completeRequest() {\n  filter_manager_.streamInfo().onRequestComplete();\n\n  if (connection_manager_.remote_close_) {\n    filter_manager_.streamInfo().setResponseCodeDetails(\n        StreamInfo::ResponseCodeDetails::get().DownstreamRemoteDisconnect);\n    filter_manager_.streamInfo().setResponseFlag(\n        StreamInfo::ResponseFlag::DownstreamConnectionTermination);\n  }\n  connection_manager_.stats_.named_.downstream_rq_active_.dec();\n  if (filter_manager_.streamInfo().healthCheck()) {\n    connection_manager_.config_.tracingStats().health_check_.inc();\n  }\n\n  if (active_span_) {\n    Tracing::HttpTracerUtility::finalizeDownstreamSpan(\n        *active_span_, request_headers_.get(), response_headers_.get(), response_trailers_.get(),\n        filter_manager_.streamInfo(), *this);\n  }\n  if (state_.successful_upgrade_) {\n    connection_manager_.stats_.named_.downstream_cx_upgrades_active_.dec();\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::resetIdleTimer() {\n  if (stream_idle_timer_ != nullptr) {\n    // TODO(htuch): If this shows up in performance profiles, optimize by only\n    // updating a timestamp here and doing periodic checks for idle timeouts\n    // instead, or reducing the accuracy of timers.\n    stream_idle_timer_->enableTimer(idle_timeout_ms_);\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onIdleTimeout() {\n  connection_manager_.stats_.named_.downstream_rq_idle_timeout_.inc();\n\n  // See below for more information on this early return block.\n  if (Runtime::runtimeFeatureEnabled(\n          \"envoy.reloadable_features.override_request_timeout_by_gateway_timeout\")) {\n    filter_manager_.streamInfo().setResponseFlag(StreamInfo::ResponseFlag::StreamIdleTimeout);\n    sendLocalReply(Http::Utility::maybeRequestTimeoutCode(filter_manager_.remoteDecodeComplete()),\n                   \"stream timeout\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().StreamIdleTimeout);\n    return;\n  }\n\n  // There are 2 issues in the blow code. First, `responseHeaders().has_value()` is not the best\n  // predicate. `remoteDecodeComplete()` is preferable. Second, `sendLocalReply()` smartly ends the\n  // stream if any response was pushed to decoder and explicitly `endStream()` is not required.\n  //\n  // The above code is expected to resolve both. The original code here before it is fully verified.\n  //\n  // TODO(lambdai): delete the block below along with the removal of\n  // `override_request_timeout_by_gateway_timeout`.\n\n  // If headers have not been sent to the user, send a 408.\n  if (responseHeaders().has_value()) {\n    // TODO(htuch): We could send trailers here with an x-envoy timeout header\n    // or gRPC status code, and/or set H2 RST_STREAM error.\n    filter_manager_.streamInfo().setResponseCodeDetails(\n        StreamInfo::ResponseCodeDetails::get().StreamIdleTimeout);\n    connection_manager_.doEndStream(*this);\n  } else {\n    filter_manager_.streamInfo().setResponseFlag(StreamInfo::ResponseFlag::StreamIdleTimeout);\n    sendLocalReply(Http::Code::RequestTimeout, \"stream timeout\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().StreamIdleTimeout);\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onRequestTimeout() {\n  connection_manager_.stats_.named_.downstream_rq_timeout_.inc();\n  sendLocalReply(Http::Utility::maybeRequestTimeoutCode(filter_manager_.remoteDecodeComplete()),\n                 \"request timeout\", nullptr, absl::nullopt,\n                 StreamInfo::ResponseCodeDetails::get().RequestOverallTimeout);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onRequestHeaderTimeout() {\n  connection_manager_.stats_.named_.downstream_rq_header_timeout_.inc();\n  sendLocalReply(Http::Utility::maybeRequestTimeoutCode(filter_manager_.remoteDecodeComplete()),\n                 \"request header timeout\", nullptr, absl::nullopt,\n                 StreamInfo::ResponseCodeDetails::get().RequestHeaderTimeout);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onStreamMaxDurationReached() {\n  ENVOY_STREAM_LOG(debug, \"Stream max duration time reached\", *this);\n  connection_manager_.stats_.named_.downstream_rq_max_duration_reached_.inc();\n  sendLocalReply(Http::Utility::maybeRequestTimeoutCode(filter_manager_.remoteDecodeComplete()),\n                 \"downstream duration timeout\", nullptr,\n                 Grpc::Status::WellKnownGrpcStatus::DeadlineExceeded,\n                 StreamInfo::ResponseCodeDetails::get().MaxDurationTimeout);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::chargeStats(const ResponseHeaderMap& headers) {\n  uint64_t response_code = Utility::getResponseStatus(headers);\n  filter_manager_.streamInfo().response_code_ = response_code;\n\n  if (filter_manager_.streamInfo().health_check_request_) {\n    return;\n  }\n\n  // No response is sent back downstream for internal redirects, so don't charge downstream stats.\n  const absl::optional<std::string>& response_code_details =\n      filter_manager_.streamInfo().responseCodeDetails();\n  if (response_code_details.has_value() &&\n      response_code_details == Envoy::StreamInfo::ResponseCodeDetails::get().InternalRedirect) {\n    return;\n  }\n\n  connection_manager_.stats_.named_.downstream_rq_completed_.inc();\n  connection_manager_.listener_stats_.downstream_rq_completed_.inc();\n  if (CodeUtility::is1xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_1xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_1xx_.inc();\n  } else if (CodeUtility::is2xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_2xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_2xx_.inc();\n  } else if (CodeUtility::is3xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_3xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_3xx_.inc();\n  } else if (CodeUtility::is4xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_4xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_4xx_.inc();\n  } else if (CodeUtility::is5xx(response_code)) {\n    connection_manager_.stats_.named_.downstream_rq_5xx_.inc();\n    connection_manager_.listener_stats_.downstream_rq_5xx_.inc();\n  }\n}\n\nconst Network::Connection* ConnectionManagerImpl::ActiveStream::connection() {\n  return &connection_manager_.read_callbacks_->connection();\n}\n\nuint32_t ConnectionManagerImpl::ActiveStream::localPort() {\n  auto ip = connection()->connectionInfoProvider().localAddress()->ip();\n  if (ip == nullptr) {\n    return 0;\n  }\n  return ip->port();\n}\n\n// Ordering in this function is complicated, but important.\n//\n// We want to do minimal work before selecting route and creating a filter\n// chain to maximize the number of requests which get custom filter behavior,\n// e.g. registering access logging.\n//\n// This must be balanced by doing sanity checking for invalid requests (one\n// can't route select properly without full headers), checking state required to\n// serve error responses (connection close, head requests, etc), and\n// modifications which may themselves affect route selection.\nvoid ConnectionManagerImpl::ActiveStream::decodeHeaders(RequestHeaderMapPtr&& headers,\n                                                        bool end_stream) {\n  ScopeTrackerScopeState scope(this,\n                               connection_manager_.read_callbacks_->connection().dispatcher());\n  request_headers_ = std::move(headers);\n  filter_manager_.requestHeadersInitialized();\n  if (request_header_timer_ != nullptr) {\n    request_header_timer_->disableTimer();\n    request_header_timer_.reset();\n  }\n\n  // Both saw_connection_close_ and is_head_request_ affect local replies: set\n  // them as early as possible.\n  const Protocol protocol = connection_manager_.codec_->protocol();\n  state_.saw_connection_close_ = HeaderUtility::shouldCloseConnection(protocol, *request_headers_);\n\n  // We need to snap snapped_route_config_ here as it's used in mutateRequestHeaders later.\n  if (connection_manager_.config_.isRoutable()) {\n    if (connection_manager_.config_.routeConfigProvider() != nullptr) {\n      snapped_route_config_ = connection_manager_.config_.routeConfigProvider()->configCast();\n    } else if (connection_manager_.config_.scopedRouteConfigProvider() != nullptr) {\n      snapped_scoped_routes_config_ =\n          connection_manager_.config_.scopedRouteConfigProvider()->config<Router::ScopedConfig>();\n      snapScopedRouteConfig();\n    }\n  } else {\n    snapped_route_config_ = connection_manager_.config_.routeConfigProvider()->configCast();\n  }\n\n  ENVOY_STREAM_LOG(debug, \"request headers complete (end_stream={}):\\n{}\", *this, end_stream,\n                   *request_headers_);\n\n  // We end the decode here only if the request is header only. If we convert the request to a\n  // header only, the stream will be marked as done once a subsequent decodeData/decodeTrailers is\n  // called with end_stream=true.\n  filter_manager_.maybeEndDecode(end_stream);\n\n  // Drop new requests when overloaded as soon as we have decoded the headers.\n  if (connection_manager_.random_generator_.bernoulli(\n          connection_manager_.overload_stop_accepting_requests_ref_.value())) {\n    // In this one special case, do not create the filter chain. If there is a risk of memory\n    // overload it is more important to avoid unnecessary allocation than to create the filters.\n    filter_manager_.skipFilterChainCreation();\n    connection_manager_.stats_.named_.downstream_rq_overload_close_.inc();\n    sendLocalReply(Http::Code::ServiceUnavailable, \"envoy overloaded\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().Overload);\n    return;\n  }\n\n  // This lambda should be erased when\n  // `envoy.reloadable_features.http_100_continue_case_insensitive` is removed.\n  auto is100Continue = [](absl::string_view request_expect) {\n    return request_expect == Headers::get().ExpectValues._100Continue ||\n           (Runtime::runtimeFeatureEnabled(\n                \"envoy.reloadable_features.http_100_continue_case_insensitive\") &&\n            // The Expect field-value is case-insensitive.\n            // https://tools.ietf.org/html/rfc7231#section-5.1.1\n            absl::EqualsIgnoreCase(request_expect, Headers::get().ExpectValues._100Continue));\n  };\n\n  if (!connection_manager_.config_.proxy100Continue() && request_headers_->Expect() &&\n      is100Continue(request_headers_->Expect()->value().getStringView())) {\n    // Note in the case Envoy is handling 100-Continue complexity, it skips the filter chain\n    // and sends the 100-Continue directly to the encoder.\n    chargeStats(continueHeader());\n    response_encoder_->encode1xxHeaders(continueHeader());\n    // Remove the Expect header so it won't be handled again upstream.\n    request_headers_->removeExpect();\n  }\n\n  connection_manager_.user_agent_.initializeFromHeaders(*request_headers_,\n                                                        connection_manager_.stats_.prefixStatName(),\n                                                        connection_manager_.stats_.scope_);\n\n  // Make sure we are getting a codec version we support.\n  if (protocol == Protocol::Http10) {\n    // Assume this is HTTP/1.0. This is fine for HTTP/0.9 but this code will also affect any\n    // requests with non-standard version numbers (0.9, 1.3), basically anything which is not\n    // HTTP/1.1.\n    //\n    // The protocol may have shifted in the HTTP/1.0 case so reset it.\n    filter_manager_.streamInfo().protocol(protocol);\n    if (!connection_manager_.config_.http1Settings().accept_http_10_) {\n      // Send \"Upgrade Required\" if HTTP/1.0 support is not explicitly configured on.\n      sendLocalReply(Code::UpgradeRequired, \"\", nullptr, absl::nullopt,\n                     StreamInfo::ResponseCodeDetails::get().LowVersion);\n      return;\n    }\n    if (!request_headers_->Host() &&\n        !connection_manager_.config_.http1Settings().default_host_for_http_10_.empty()) {\n      // Add a default host if configured to do so.\n      request_headers_->setHost(\n          connection_manager_.config_.http1Settings().default_host_for_http_10_);\n    }\n  }\n\n  if (!request_headers_->Host()) {\n    // Require host header. For HTTP/1.1 Host has already been translated to :authority.\n    sendLocalReply(Code::BadRequest, \"\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().MissingHost);\n    return;\n  }\n\n  // Verify header sanity checks which should have been performed by the codec.\n  ASSERT(HeaderUtility::requestHeadersValid(*request_headers_).has_value() == false);\n\n  // Check for the existence of the :path header for non-CONNECT requests, or present-but-empty\n  // :path header for CONNECT requests. We expect the codec to have broken the path into pieces if\n  // applicable. NOTE: Currently the HTTP/1.1 codec only does this when the allow_absolute_url flag\n  // is enabled on the HCM.\n  if ((!HeaderUtility::isConnect(*request_headers_) || request_headers_->Path()) &&\n      request_headers_->getPathValue().empty()) {\n    sendLocalReply(Code::NotFound, \"\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().MissingPath);\n    return;\n  }\n\n  // Currently we only support relative paths at the application layer.\n  if (!request_headers_->getPathValue().empty() && request_headers_->getPathValue()[0] != '/') {\n    connection_manager_.stats_.named_.downstream_rq_non_relative_path_.inc();\n    sendLocalReply(Code::NotFound, \"\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().AbsolutePath);\n    return;\n  }\n\n  // Path sanitization should happen before any path access other than the above sanity check.\n  const auto action =\n      ConnectionManagerUtility::maybeNormalizePath(*request_headers_, connection_manager_.config_);\n  // gRPC requests are rejected if Envoy is configured to redirect post-normalization. This is\n  // because gRPC clients do not support redirect.\n  if (action == ConnectionManagerUtility::NormalizePathAction::Reject ||\n      (action == ConnectionManagerUtility::NormalizePathAction::Redirect &&\n       Grpc::Common::hasGrpcContentType(*request_headers_))) {\n    connection_manager_.stats_.named_.downstream_rq_failed_path_normalization_.inc();\n    sendLocalReply(Code::BadRequest, \"\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().PathNormalizationFailed);\n    return;\n  } else if (action == ConnectionManagerUtility::NormalizePathAction::Redirect) {\n    connection_manager_.stats_.named_.downstream_rq_redirected_with_normalized_path_.inc();\n    sendLocalReply(\n        Code::TemporaryRedirect, \"\",\n        [new_path = request_headers_->Path()->value().getStringView()](\n            Http::ResponseHeaderMap& response_headers) -> void {\n          response_headers.addReferenceKey(Http::Headers::get().Location, new_path);\n        },\n        absl::nullopt, StreamInfo::ResponseCodeDetails::get().PathNormalizationFailed);\n    return;\n  }\n\n  ASSERT(action == ConnectionManagerUtility::NormalizePathAction::Continue);\n  auto optional_port = ConnectionManagerUtility::maybeNormalizeHost(\n      *request_headers_, connection_manager_.config_, localPort());\n  if (optional_port.has_value() &&\n      requestWasConnect(request_headers_, connection_manager_.codec_->protocol())) {\n    filter_manager_.streamInfo().filterState()->setData(\n        Router::OriginalConnectPort::key(),\n        std::make_unique<Router::OriginalConnectPort>(optional_port.value()),\n        StreamInfo::FilterState::StateType::ReadOnly, StreamInfo::FilterState::LifeSpan::Request);\n  }\n\n  if (!state_.is_internally_created_) { // Only sanitize headers on first pass.\n    // Modify the downstream remote address depending on configuration and headers.\n    const auto mutate_result = ConnectionManagerUtility::mutateRequestHeaders(\n        *request_headers_, connection_manager_.read_callbacks_->connection(),\n        connection_manager_.config_, *snapped_route_config_, connection_manager_.local_info_);\n\n    // IP detection failed, reject the request.\n    if (mutate_result.reject_request.has_value()) {\n      const auto& reject_request_params = mutate_result.reject_request.value();\n      connection_manager_.stats_.named_.downstream_rq_rejected_via_ip_detection_.inc();\n      sendLocalReply(reject_request_params.response_code, reject_request_params.body, nullptr,\n                     absl::nullopt,\n                     StreamInfo::ResponseCodeDetails::get().OriginalIPDetectionFailed);\n      return;\n    }\n\n    filter_manager_.setDownstreamRemoteAddress(mutate_result.final_remote_address);\n  }\n  ASSERT(filter_manager_.streamInfo().downstreamAddressProvider().remoteAddress() != nullptr);\n\n  ASSERT(!cached_route_);\n  refreshCachedRoute();\n\n  if (!state_.is_internally_created_) { // Only mutate tracing headers on first pass.\n    filter_manager_.streamInfo().setTraceReason(\n        ConnectionManagerUtility::mutateTracingRequestHeader(\n            *request_headers_, connection_manager_.runtime_, connection_manager_.config_,\n            cached_route_.value().get()));\n  }\n\n  filter_manager_.streamInfo().setRequestHeaders(*request_headers_);\n\n  const bool upgrade_rejected = filter_manager_.createFilterChain() == false;\n\n  // TODO if there are no filters when starting a filter iteration, the connection manager\n  // should return 404. The current returns no response if there is no router filter.\n  if (hasCachedRoute()) {\n    // Do not allow upgrades if the route does not support it.\n    if (upgrade_rejected) {\n      // While downstream servers should not send upgrade payload without the upgrade being\n      // accepted, err on the side of caution and refuse to process any further requests on this\n      // connection, to avoid a class of HTTP/1.1 smuggling bugs where Upgrade or CONNECT payload\n      // contains a smuggled HTTP request.\n      state_.saw_connection_close_ = true;\n      connection_manager_.stats_.named_.downstream_rq_ws_on_non_ws_route_.inc();\n      sendLocalReply(Code::Forbidden, \"\", nullptr, absl::nullopt,\n                     StreamInfo::ResponseCodeDetails::get().UpgradeFailed);\n      return;\n    }\n    // Allow non websocket requests to go through websocket enabled routes.\n  }\n\n  if (hasCachedRoute()) {\n    const Router::RouteEntry* route_entry = cached_route_.value()->routeEntry();\n    if (route_entry != nullptr && route_entry->idleTimeout()) {\n      // TODO(mattklein123): Technically if the cached route changes, we should also see if the\n      // route idle timeout has changed and update the value.\n      idle_timeout_ms_ = route_entry->idleTimeout().value();\n      response_encoder_->getStream().setFlushTimeout(idle_timeout_ms_);\n      if (idle_timeout_ms_.count()) {\n        // If we have a route-level idle timeout but no global stream idle timeout, create a timer.\n        if (stream_idle_timer_ == nullptr) {\n          stream_idle_timer_ =\n              connection_manager_.read_callbacks_->connection().dispatcher().createScaledTimer(\n                  Event::ScaledTimerType::HttpDownstreamIdleStreamTimeout,\n                  [this]() -> void { onIdleTimeout(); });\n        }\n      } else if (stream_idle_timer_ != nullptr) {\n        // If we had a global stream idle timeout but the route-level idle timeout is set to zero\n        // (to override), we disable the idle timer.\n        stream_idle_timer_->disableTimer();\n        stream_idle_timer_ = nullptr;\n      }\n    }\n  }\n\n  // Check if tracing is enabled at all.\n  if (connection_manager_.config_.tracingConfig()) {\n    traceRequest();\n  }\n\n  filter_manager_.decodeHeaders(*request_headers_, end_stream);\n\n  // Reset it here for both global and overridden cases.\n  resetIdleTimer();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::traceRequest() {\n  const Tracing::Decision tracing_decision =\n      Tracing::HttpTracerUtility::shouldTraceRequest(filter_manager_.streamInfo());\n  ConnectionManagerImpl::chargeTracingStats(tracing_decision.reason,\n                                            connection_manager_.config_.tracingStats());\n\n  active_span_ = connection_manager_.tracer().startSpan(\n      *this, *request_headers_, filter_manager_.streamInfo(), tracing_decision);\n\n  if (!active_span_) {\n    return;\n  }\n\n  // TODO: Need to investigate the following code based on the cached route, as may\n  // be broken in the case a filter changes the route.\n\n  // If a decorator has been defined, apply it to the active span.\n  if (hasCachedRoute() && cached_route_.value()->decorator()) {\n    const Router::Decorator* decorator = cached_route_.value()->decorator();\n\n    decorator->apply(*active_span_);\n\n    state_.decorated_propagate_ = decorator->propagate();\n\n    // Cache decorated operation.\n    if (!decorator->getOperation().empty()) {\n      decorated_operation_ = &decorator->getOperation();\n    }\n  }\n\n  if (connection_manager_.config_.tracingConfig()->operation_name_ ==\n      Tracing::OperationName::Egress) {\n    // For egress (outbound) requests, pass the decorator's operation name (if defined and\n    // propagation enabled) as a request header to enable the receiving service to use it in its\n    // server span.\n    if (decorated_operation_ && state_.decorated_propagate_) {\n      request_headers_->setEnvoyDecoratorOperation(*decorated_operation_);\n    }\n  } else {\n    const HeaderEntry* req_operation_override = request_headers_->EnvoyDecoratorOperation();\n\n    // For ingress (inbound) requests, if a decorator operation name has been provided, it\n    // should be used to override the active span's operation.\n    if (req_operation_override) {\n      if (!req_operation_override->value().empty()) {\n        active_span_->setOperation(req_operation_override->value().getStringView());\n\n        // Clear the decorated operation so won't be used in the response header, as\n        // it has been overridden by the inbound decorator operation request header.\n        decorated_operation_ = nullptr;\n      }\n      // Remove header so not propagated to service\n      request_headers_->removeEnvoyDecoratorOperation();\n    }\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::decodeData(Buffer::Instance& data, bool end_stream) {\n  ScopeTrackerScopeState scope(this,\n                               connection_manager_.read_callbacks_->connection().dispatcher());\n  filter_manager_.maybeEndDecode(end_stream);\n  filter_manager_.streamInfo().addBytesReceived(data.length());\n\n  filter_manager_.decodeData(data, end_stream);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::decodeTrailers(RequestTrailerMapPtr&& trailers) {\n  ScopeTrackerScopeState scope(this,\n                               connection_manager_.read_callbacks_->connection().dispatcher());\n  resetIdleTimer();\n\n  ASSERT(!request_trailers_);\n  request_trailers_ = std::move(trailers);\n  filter_manager_.maybeEndDecode(true);\n  filter_manager_.decodeTrailers(*request_trailers_);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::decodeMetadata(MetadataMapPtr&& metadata_map) {\n  resetIdleTimer();\n  // After going through filters, the ownership of metadata_map will be passed to terminal filter.\n  // The terminal filter may encode metadata_map to the next hop immediately or store metadata_map\n  // and encode later when connection pool is ready.\n  filter_manager_.decodeMetadata(*metadata_map);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::disarmRequestTimeout() {\n  if (request_timer_) {\n    request_timer_->disableTimer();\n  }\n}\n\nvoid ConnectionManagerImpl::startDrainSequence() {\n  ASSERT(drain_state_ == DrainState::NotDraining);\n  drain_state_ = DrainState::Draining;\n  codec_->shutdownNotice();\n  drain_timer_ = read_callbacks_->connection().dispatcher().createTimer(\n      [this]() -> void { onDrainTimeout(); });\n  drain_timer_->enableTimer(config_.drainTimeout());\n}\n\nvoid ConnectionManagerImpl::ActiveStream::snapScopedRouteConfig() {\n  // NOTE: if a RDS subscription hasn't got a RouteConfiguration back, a Router::NullConfigImpl is\n  // returned, in that case we let it pass.\n  snapped_route_config_ = snapped_scoped_routes_config_->getRouteConfig(*request_headers_);\n  if (snapped_route_config_ == nullptr) {\n    ENVOY_STREAM_LOG(trace, \"can't find SRDS scope.\", *this);\n    // TODO(stevenzzzz): Consider to pass an error message to router filter, so that it can\n    // send back 404 with some more details.\n    snapped_route_config_ = std::make_shared<Router::NullConfigImpl>();\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::refreshCachedRoute() { refreshCachedRoute(nullptr); }\n\nvoid ConnectionManagerImpl::ActiveStream::refreshDurationTimeout() {\n  if (!filter_manager_.streamInfo().route() ||\n      !filter_manager_.streamInfo().route()->routeEntry() || !request_headers_) {\n    return;\n  }\n  const auto& route = filter_manager_.streamInfo().route()->routeEntry();\n\n  auto grpc_timeout = Grpc::Common::getGrpcTimeout(*request_headers_);\n  std::chrono::milliseconds timeout;\n  bool disable_timer = false;\n\n  if (!grpc_timeout || !route->grpcTimeoutHeaderMax()) {\n    // Either there is no grpc-timeout header or special timeouts for it are not\n    // configured. Use stream duration.\n    if (route->maxStreamDuration()) {\n      timeout = route->maxStreamDuration().value();\n      if (timeout == std::chrono::milliseconds(0)) {\n        // Explicitly configured 0 means no timeout.\n        disable_timer = true;\n      }\n    } else {\n      // Fall back to HCM config. If no HCM duration limit exists, disable\n      // timers set by any prior route configuration.\n      const auto max_stream_duration = connection_manager_.config_.maxStreamDuration();\n      if (max_stream_duration.has_value() && max_stream_duration.value().count()) {\n        timeout = max_stream_duration.value();\n      } else {\n        disable_timer = true;\n      }\n    }\n  } else {\n    // Start with the timeout equal to the gRPC timeout header.\n    timeout = grpc_timeout.value();\n    // If there's a valid cap, apply it.\n    if (timeout > route->grpcTimeoutHeaderMax().value() &&\n        route->grpcTimeoutHeaderMax().value() != std::chrono::milliseconds(0)) {\n      timeout = route->grpcTimeoutHeaderMax().value();\n    }\n\n    // Apply the configured offset.\n    if (timeout != std::chrono::milliseconds(0) && route->grpcTimeoutHeaderOffset()) {\n      const auto offset = route->grpcTimeoutHeaderOffset().value();\n      if (offset < timeout) {\n        timeout -= offset;\n      } else {\n        timeout = std::chrono::milliseconds(0);\n      }\n    }\n  }\n\n  // Disable any existing timer if configured to do so.\n  if (disable_timer) {\n    if (max_stream_duration_timer_) {\n      max_stream_duration_timer_->disableTimer();\n      if (route->usingNewTimeouts() && Grpc::Common::isGrpcRequestHeaders(*request_headers_)) {\n        request_headers_->removeGrpcTimeout();\n      }\n    }\n    return;\n  }\n\n  // Set the header timeout before doing used-time adjustments.\n  // This may result in the upstream not getting the latest results, but also\n  // avoids every request getting a custom timeout based on envoy think time.\n  if (route->usingNewTimeouts() && Grpc::Common::isGrpcRequestHeaders(*request_headers_)) {\n    Grpc::Common::toGrpcTimeout(std::chrono::milliseconds(timeout), *request_headers_);\n  }\n\n  // See how long this stream has been alive, and adjust the timeout\n  // accordingly.\n  std::chrono::duration time_used = std::chrono::duration_cast<std::chrono::milliseconds>(\n      connection_manager_.timeSource().monotonicTime() -\n      filter_manager_.streamInfo().startTimeMonotonic());\n  if (timeout > time_used) {\n    timeout -= time_used;\n  } else {\n    timeout = std::chrono::milliseconds(0);\n  }\n\n  // Finally create (if necessary) and enable the timer.\n  if (!max_stream_duration_timer_) {\n    max_stream_duration_timer_ =\n        connection_manager_.read_callbacks_->connection().dispatcher().createTimer(\n            [this]() -> void { onStreamMaxDurationReached(); });\n  }\n  max_stream_duration_timer_->enableTimer(timeout);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::refreshCachedRoute(const Router::RouteCallback& cb) {\n  Router::RouteConstSharedPtr route;\n  if (request_headers_ != nullptr) {\n    if (connection_manager_.config_.isRoutable() &&\n        connection_manager_.config_.scopedRouteConfigProvider() != nullptr) {\n      // NOTE: re-select scope as well in case the scope key header has been changed by a filter.\n      snapScopedRouteConfig();\n    }\n    if (snapped_route_config_ != nullptr) {\n      route = snapped_route_config_->route(cb, *request_headers_, filter_manager_.streamInfo(),\n                                           stream_id_);\n    }\n  }\n\n  setRoute(route);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::refreshCachedTracingCustomTags() {\n  if (!connection_manager_.config_.tracingConfig()) {\n    return;\n  }\n  const Tracing::CustomTagMap& conn_manager_tags =\n      connection_manager_.config_.tracingConfig()->custom_tags_;\n  const Tracing::CustomTagMap* route_tags = nullptr;\n  if (hasCachedRoute() && cached_route_.value()->tracingConfig()) {\n    route_tags = &cached_route_.value()->tracingConfig()->getCustomTags();\n  }\n  const bool configured_in_conn = !conn_manager_tags.empty();\n  const bool configured_in_route = route_tags && !route_tags->empty();\n  if (!configured_in_conn && !configured_in_route) {\n    return;\n  }\n  Tracing::CustomTagMap& custom_tag_map = getOrMakeTracingCustomTagMap();\n  if (configured_in_route) {\n    custom_tag_map.insert(route_tags->begin(), route_tags->end());\n  }\n  if (configured_in_conn) {\n    custom_tag_map.insert(conn_manager_tags.begin(), conn_manager_tags.end());\n  }\n}\n\n// TODO(chaoqin-li1123): Make on demand vhds and on demand srds works at the same time.\nvoid ConnectionManagerImpl::ActiveStream::requestRouteConfigUpdate(\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  route_config_update_requester_->requestRouteConfigUpdate(route_config_updated_cb);\n}\n\nabsl::optional<Router::ConfigConstSharedPtr> ConnectionManagerImpl::ActiveStream::routeConfig() {\n  if (connection_manager_.config_.routeConfigProvider() != nullptr) {\n    return absl::optional<Router::ConfigConstSharedPtr>(\n        connection_manager_.config_.routeConfigProvider()->configCast());\n  }\n  return {};\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onLocalReply(Code code) {\n  // The BadRequest error code indicates there has been a messaging error.\n  if (code == Http::Code::BadRequest && connection_manager_.codec_->protocol() < Protocol::Http2 &&\n      !response_encoder_->streamErrorOnInvalidHttpMessage()) {\n    state_.saw_connection_close_ = true;\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encode1xxHeaders(ResponseHeaderMap& response_headers) {\n  // Strip the T-E headers etc. Defer other header additions as well as drain-close logic to the\n  // continuation headers.\n  ConnectionManagerUtility::mutateResponseHeaders(\n      response_headers, request_headers_.get(), connection_manager_.config_, EMPTY_STRING,\n      filter_manager_.streamInfo(), connection_manager_.proxy_name_,\n      connection_manager_.clear_hop_by_hop_response_headers_);\n\n  // Count both the 1xx and follow-up response code in stats.\n  chargeStats(response_headers);\n\n  ENVOY_STREAM_LOG(debug, \"encoding 100 continue headers via codec:\\n{}\", *this, response_headers);\n\n  // Now actually encode via the codec.\n  response_encoder_->encode1xxHeaders(response_headers);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encodeHeaders(ResponseHeaderMap& headers,\n                                                        bool end_stream) {\n  // Base headers.\n\n  // We want to preserve the original date header, but we add a date header if it is absent\n  if (!headers.Date()) {\n    connection_manager_.config_.dateProvider().setDateHeader(headers);\n  }\n\n  // Following setReference() is safe because serverName() is constant for the life of the\n  // listener.\n  const auto transformation = connection_manager_.config_.serverHeaderTransformation();\n  if (transformation == ConnectionManagerConfig::HttpConnectionManagerProto::OVERWRITE ||\n      (transformation == ConnectionManagerConfig::HttpConnectionManagerProto::APPEND_IF_ABSENT &&\n       headers.Server() == nullptr)) {\n    headers.setReferenceServer(connection_manager_.config_.serverName());\n  }\n  ConnectionManagerUtility::mutateResponseHeaders(\n      headers, request_headers_.get(), connection_manager_.config_,\n      connection_manager_.config_.via(), filter_manager_.streamInfo(),\n      connection_manager_.proxy_name_, connection_manager_.clear_hop_by_hop_response_headers_);\n\n  bool drain_connection_due_to_overload = false;\n  if (connection_manager_.drain_state_ == DrainState::NotDraining &&\n      connection_manager_.random_generator_.bernoulli(\n          connection_manager_.overload_disable_keepalive_ref_.value())) {\n    ENVOY_STREAM_LOG(debug, \"disabling keepalive due to envoy overload\", *this);\n    drain_connection_due_to_overload = true;\n    connection_manager_.stats_.named_.downstream_cx_overload_disable_keepalive_.inc();\n  }\n\n  // See if we want to drain/close the connection. Send the go away frame prior to encoding the\n  // header block.\n  if (connection_manager_.drain_state_ == DrainState::NotDraining &&\n      (connection_manager_.drain_close_.drainClose() || drain_connection_due_to_overload)) {\n\n    // This doesn't really do anything for HTTP/1.1 other then give the connection another boost\n    // of time to race with incoming requests. For HTTP/2 connections, send a GOAWAY frame to\n    // prevent any new streams.\n    connection_manager_.startDrainSequence();\n    connection_manager_.stats_.named_.downstream_cx_drain_close_.inc();\n    ENVOY_STREAM_LOG(debug, \"drain closing connection\", *this);\n  }\n\n  if (connection_manager_.codec_->protocol() == Protocol::Http10) {\n    // As HTTP/1.0 and below can not do chunked encoding, if there is no content\n    // length the response will be framed by connection close.\n    if (!headers.ContentLength()) {\n      state_.saw_connection_close_ = true;\n    }\n    // If the request came with a keep-alive and no other factor resulted in a\n    // connection close header, send an explicit keep-alive header.\n    if (!state_.saw_connection_close_) {\n      headers.setConnection(Headers::get().ConnectionValues.KeepAlive);\n    }\n  }\n\n  if (connection_manager_.drain_state_ == DrainState::NotDraining && state_.saw_connection_close_) {\n    ENVOY_STREAM_LOG(debug, \"closing connection due to connection close header\", *this);\n    connection_manager_.drain_state_ = DrainState::Closing;\n  }\n\n  // If we are destroying a stream before remote is complete and the connection does not support\n  // multiplexing, we should disconnect since we don't want to wait around for the request to\n  // finish.\n  if (!filter_manager_.remoteDecodeComplete()) {\n    if (connection_manager_.codec_->protocol() < Protocol::Http2) {\n      connection_manager_.drain_state_ = DrainState::Closing;\n    }\n\n    connection_manager_.stats_.named_.downstream_rq_response_before_rq_complete_.inc();\n  }\n\n  if (connection_manager_.drain_state_ != DrainState::NotDraining &&\n      connection_manager_.codec_->protocol() < Protocol::Http2) {\n    // If the connection manager is draining send \"Connection: Close\" on HTTP/1.1 connections.\n    // Do not do this for H2 (which drains via GOAWAY) or Upgrade or CONNECT (as the\n    // payload is no longer HTTP/1.1)\n    if (!Utility::isUpgrade(headers) &&\n        !HeaderUtility::isConnectResponse(request_headers_.get(), *responseHeaders())) {\n      headers.setReferenceConnection(Headers::get().ConnectionValues.Close);\n    }\n  }\n\n  if (connection_manager_.config_.tracingConfig()) {\n    if (connection_manager_.config_.tracingConfig()->operation_name_ ==\n        Tracing::OperationName::Ingress) {\n      // For ingress (inbound) responses, if the request headers do not include a\n      // decorator operation (override), and the decorated operation should be\n      // propagated, then pass the decorator's operation name (if defined)\n      // as a response header to enable the client service to use it in its client span.\n      if (decorated_operation_ && state_.decorated_propagate_) {\n        headers.setEnvoyDecoratorOperation(*decorated_operation_);\n      }\n    } else if (connection_manager_.config_.tracingConfig()->operation_name_ ==\n               Tracing::OperationName::Egress) {\n      const HeaderEntry* resp_operation_override = headers.EnvoyDecoratorOperation();\n\n      // For Egress (outbound) response, if a decorator operation name has been provided, it\n      // should be used to override the active span's operation.\n      if (resp_operation_override) {\n        if (!resp_operation_override->value().empty() && active_span_) {\n          active_span_->setOperation(resp_operation_override->value().getStringView());\n        }\n        // Remove header so not propagated to service.\n        headers.removeEnvoyDecoratorOperation();\n      }\n    }\n  }\n\n  chargeStats(headers);\n\n  ENVOY_STREAM_LOG(debug, \"encoding headers via codec (end_stream={}):\\n{}\", *this, end_stream,\n                   headers);\n\n  // Now actually encode via the codec.\n  filter_manager_.streamInfo().downstreamTiming().onFirstDownstreamTxByteSent(\n      connection_manager_.time_source_);\n  response_encoder_->encodeHeaders(headers, end_stream);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encodeData(Buffer::Instance& data, bool end_stream) {\n  ENVOY_STREAM_LOG(trace, \"encoding data via codec (size={} end_stream={})\", *this, data.length(),\n                   end_stream);\n\n  filter_manager_.streamInfo().addBytesSent(data.length());\n  response_encoder_->encodeData(data, end_stream);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encodeTrailers(ResponseTrailerMap& trailers) {\n  ENVOY_STREAM_LOG(debug, \"encoding trailers via codec:\\n{}\", *this, trailers);\n\n  response_encoder_->encodeTrailers(trailers);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::encodeMetadata(MetadataMapVector& metadata) {\n  ENVOY_STREAM_LOG(debug, \"encoding metadata via codec:\\n{}\", *this, metadata);\n  response_encoder_->encodeMetadata(metadata);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onDecoderFilterBelowWriteBufferLowWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Read-enabling downstream stream due to filter callbacks.\", *this);\n  // If the state is destroyed, the codec's stream is already torn down. On\n  // teardown the codec will unwind any remaining read disable calls.\n  if (!filter_manager_.destroyed()) {\n    response_encoder_->getStream().readDisable(false);\n  }\n  connection_manager_.stats_.named_.downstream_flow_control_resumed_reading_total_.inc();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onDecoderFilterAboveWriteBufferHighWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Read-disabling downstream stream due to filter callbacks.\", *this);\n  response_encoder_->getStream().readDisable(true);\n  connection_manager_.stats_.named_.downstream_flow_control_paused_reading_total_.inc();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onResetStream(StreamResetReason reset_reason,\n                                                        absl::string_view) {\n  // NOTE: This function gets called in all of the following cases:\n  //       1) We TX an app level reset\n  //       2) The codec TX a codec level reset\n  //       3) The codec RX a reset\n  //       4) The overload manager reset the stream\n  //       If we need to differentiate we need to do it inside the codec. Can start with this.\n  ENVOY_STREAM_LOG(debug, \"stream reset\", *this);\n  connection_manager_.stats_.named_.downstream_rq_rx_reset_.inc();\n\n  // If the codec sets its responseDetails() for a reason other than peer reset, set a\n  // DownstreamProtocolError. Either way, propagate details.\n  const absl::string_view encoder_details = response_encoder_->getStream().responseDetails();\n  if (!encoder_details.empty() && reset_reason == StreamResetReason::LocalReset) {\n    filter_manager_.streamInfo().setResponseFlag(StreamInfo::ResponseFlag::DownstreamProtocolError);\n  }\n  if (!encoder_details.empty()) {\n    filter_manager_.streamInfo().setResponseCodeDetails(encoder_details);\n  }\n\n  // Check if we're in the overload manager reset case.\n  // encoder_details should be empty in this case as we don't have a codec error.\n  if (encoder_details.empty() && reset_reason == StreamResetReason::OverloadManager) {\n    filter_manager_.streamInfo().setResponseFlag(StreamInfo::ResponseFlag::OverloadManager);\n    filter_manager_.streamInfo().setResponseCodeDetails(\n        StreamInfo::ResponseCodeDetails::get().Overload);\n  }\n  if (Runtime::runtimeFeatureEnabled(\n          \"envoy.reloadable_features.handle_stream_reset_during_hcm_encoding\")) {\n    filter_manager_.onDownstreamReset();\n  }\n\n  connection_manager_.doDeferredStreamDestroy(*this);\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onAboveWriteBufferHighWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Disabling upstream stream due to downstream stream watermark.\", *this);\n  filter_manager_.callHighWatermarkCallbacks();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onBelowWriteBufferLowWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Enabling upstream stream due to downstream stream watermark.\", *this);\n  filter_manager_.callLowWatermarkCallbacks();\n}\n\nTracing::OperationName ConnectionManagerImpl::ActiveStream::operationName() const {\n  return connection_manager_.config_.tracingConfig()->operation_name_;\n}\n\nconst Tracing::CustomTagMap* ConnectionManagerImpl::ActiveStream::customTags() const {\n  return tracing_custom_tags_.get();\n}\n\nbool ConnectionManagerImpl::ActiveStream::verbose() const {\n  return connection_manager_.config_.tracingConfig()->verbose_;\n}\n\nuint32_t ConnectionManagerImpl::ActiveStream::maxPathTagLength() const {\n  return connection_manager_.config_.tracingConfig()->max_path_tag_length_;\n}\n\nconst Router::RouteEntry::UpgradeMap* ConnectionManagerImpl::ActiveStream::upgradeMap() {\n  // We must check if the 'cached_route_' optional is populated since this function can be called\n  // early via sendLocalReply(), before the cached route is populated.\n  if (hasCachedRoute() && cached_route_.value()->routeEntry()) {\n    return &cached_route_.value()->routeEntry()->upgradeMap();\n  }\n\n  return nullptr;\n}\n\nTracing::Span& ConnectionManagerImpl::ActiveStream::activeSpan() {\n  if (active_span_) {\n    return *active_span_;\n  } else {\n    return Tracing::NullSpan::instance();\n  }\n}\n\nTracing::Config& ConnectionManagerImpl::ActiveStream::tracingConfig() { return *this; }\n\nconst ScopeTrackedObject& ConnectionManagerImpl::ActiveStream::scope() { return *this; }\n\nUpstream::ClusterInfoConstSharedPtr ConnectionManagerImpl::ActiveStream::clusterInfo() {\n  // NOTE: Refreshing route caches clusterInfo as well.\n  if (!cached_route_.has_value()) {\n    refreshCachedRoute();\n  }\n\n  return cached_cluster_info_.value();\n}\n\nRouter::RouteConstSharedPtr\nConnectionManagerImpl::ActiveStream::route(const Router::RouteCallback& cb) {\n  if (cached_route_.has_value()) {\n    return cached_route_.value();\n  }\n  refreshCachedRoute(cb);\n  return cached_route_.value();\n}\n\n/**\n * Sets the cached route to the RouteConstSharedPtr argument passed in. Handles setting the\n * cached_route_/cached_cluster_info_ ActiveStream attributes, the FilterManager streamInfo, tracing\n * tags, and timeouts.\n *\n * Declared as a StreamFilterCallbacks member function for filters to call directly, but also\n * functions as a helper to refreshCachedRoute(const Router::RouteCallback& cb).\n */\nvoid ConnectionManagerImpl::ActiveStream::setRoute(Router::RouteConstSharedPtr route) {\n  filter_manager_.streamInfo().route_ = route;\n  cached_route_ = std::move(route);\n  if (nullptr == filter_manager_.streamInfo().route() ||\n      nullptr == filter_manager_.streamInfo().route()->routeEntry()) {\n    cached_cluster_info_ = nullptr;\n  } else {\n    Upstream::ThreadLocalCluster* local_cluster =\n        connection_manager_.cluster_manager_.getThreadLocalCluster(\n            filter_manager_.streamInfo().route()->routeEntry()->clusterName());\n    cached_cluster_info_ = (nullptr == local_cluster) ? nullptr : local_cluster->info();\n  }\n\n  filter_manager_.streamInfo().setUpstreamClusterInfo(cached_cluster_info_.value());\n  refreshCachedTracingCustomTags();\n  refreshDurationTimeout();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::clearRouteCache() {\n  cached_route_ = absl::optional<Router::RouteConstSharedPtr>();\n  cached_cluster_info_ = absl::optional<Upstream::ClusterInfoConstSharedPtr>();\n  if (tracing_custom_tags_) {\n    tracing_custom_tags_->clear();\n  }\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onRequestDataTooLarge() {\n  connection_manager_.stats_.named_.downstream_rq_too_large_.inc();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::recreateStream(\n    StreamInfo::FilterStateSharedPtr filter_state) {\n  // n.b. we do not currently change the codecs to point at the new stream\n  // decoder because the decoder callbacks are complete. It would be good to\n  // null out that pointer but should not be necessary.\n  ResponseEncoder* response_encoder = response_encoder_;\n  response_encoder_ = nullptr;\n\n  Buffer::InstancePtr request_data = std::make_unique<Buffer::OwnedImpl>();\n  const auto& buffered_request_data = filter_manager_.bufferedRequestData();\n  const bool proxy_body = buffered_request_data != nullptr && buffered_request_data->length() > 0;\n  if (proxy_body) {\n    request_data->move(*buffered_request_data);\n  }\n\n  response_encoder->getStream().removeCallbacks(*this);\n  // This functionally deletes the stream (via deferred delete) so do not\n  // reference anything beyond this point.\n  connection_manager_.doEndStream(*this);\n\n  RequestDecoder& new_stream = connection_manager_.newStream(*response_encoder, true);\n  // We don't need to copy over the old parent FilterState from the old StreamInfo if it did not\n  // store any objects with a LifeSpan at or above DownstreamRequest. This is to avoid unnecessary\n  // heap allocation.\n  // TODO(snowp): In the case where connection level filter state has been set on the connection\n  // FilterState that we inherit, we'll end up copying this every time even though we could get\n  // away with just resetting it to the HCM filter_state_.\n  if (filter_state->hasDataAtOrAboveLifeSpan(StreamInfo::FilterState::LifeSpan::Request)) {\n    (*connection_manager_.streams_.begin())->filter_manager_.streamInfo().filter_state_ =\n        std::make_shared<StreamInfo::FilterStateImpl>(\n            filter_state->parent(), StreamInfo::FilterState::LifeSpan::FilterChain);\n  }\n\n  // Make sure that relevant information makes it from the original stream info\n  // to the new one. Generally this should consist of all downstream related\n  // data, and not include upstream related data.\n  (*connection_manager_.streams_.begin())\n      ->filter_manager_.streamInfo()\n      .setFromForRecreateStream(filter_manager_.streamInfo());\n  new_stream.decodeHeaders(std::move(request_headers_), !proxy_body);\n  if (proxy_body) {\n    // This functionality is currently only used for internal redirects, which the router only\n    // allows if the full request has been read (end_stream = true) so we don't need to handle the\n    // case of upstream sending an early response mid-request.\n    new_stream.decodeData(*request_data, true);\n  }\n}\n\nHttp1StreamEncoderOptionsOptRef ConnectionManagerImpl::ActiveStream::http1StreamEncoderOptions() {\n  return response_encoder_->http1StreamEncoderOptions();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::onResponseDataTooLarge() {\n  connection_manager_.stats_.named_.rs_too_large_.inc();\n}\n\nvoid ConnectionManagerImpl::ActiveStream::resetStream() {\n  connection_manager_.stats_.named_.downstream_rq_tx_reset_.inc();\n  connection_manager_.doEndStream(*this);\n}\n\n} // namespace Http\n} // namespace Envoy\n", "#include \"source/common/http/filter_manager.h\"\n\n#include <functional>\n\n#include \"envoy/http/header_map.h\"\n#include \"envoy/matcher/matcher.h\"\n\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/scope_tracked_object_stack.h\"\n#include \"source/common/common/scope_tracker.h\"\n#include \"source/common/http/codes.h\"\n#include \"source/common/http/header_map_impl.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/http/utility.h\"\n\n#include \"matching/data_impl.h\"\n\nnamespace Envoy {\nnamespace Http {\n\nnamespace {\nREGISTER_FACTORY(SkipActionFactory, Matcher::ActionFactory<Matching::HttpFilterActionContext>);\n\ntemplate <class T> using FilterList = std::list<std::unique_ptr<T>>;\n\n// Shared helper for recording the latest filter used.\ntemplate <class T>\nvoid recordLatestDataFilter(const typename FilterList<T>::iterator current_filter,\n                            T*& latest_filter, const FilterList<T>& filters) {\n  // If this is the first time we're calling onData, just record the current filter.\n  if (latest_filter == nullptr) {\n    latest_filter = current_filter->get();\n    return;\n  }\n\n  // We want to keep this pointing at the latest filter in the filter list that has received the\n  // onData callback. To do so, we compare the current latest with the *previous* filter. If they\n  // match, then we must be processing a new filter for the first time. We omit this check if we're\n  // the first filter, since the above check handles that case.\n  //\n  // We compare against the previous filter to avoid multiple filter iterations from resetting the\n  // pointer: If we just set latest to current, then the first onData filter iteration would\n  // correctly iterate over the filters and set latest, but on subsequent onData iterations\n  // we'd start from the beginning again, potentially allowing filter N to modify the buffer even\n  // though filter M > N was the filter that inserted data into the buffer.\n  if (current_filter != filters.begin() && latest_filter == std::prev(current_filter)->get()) {\n    latest_filter = current_filter->get();\n  }\n}\n\n} // namespace\n\nvoid ActiveStreamFilterBase::commonContinue() {\n  // TODO(mattklein123): Raise an error if this is called during a callback.\n  if (!canContinue()) {\n    ENVOY_STREAM_LOG(trace, \"cannot continue filter chain: filter={}\", *this,\n                     static_cast<const void*>(this));\n    return;\n  }\n\n  // Set ScopeTrackerScopeState if there's no existing crash context.\n  ScopeTrackedObjectStack encapsulated_object;\n  absl::optional<ScopeTrackerScopeState> state;\n  if (parent_.dispatcher_.trackedObjectStackIsEmpty()) {\n    restoreContextOnContinue(encapsulated_object);\n    state.emplace(&encapsulated_object, parent_.dispatcher_);\n  }\n\n  ENVOY_STREAM_LOG(trace, \"continuing filter chain: filter={}\", *this,\n                   static_cast<const void*>(this));\n  ASSERT(!canIterate(),\n         \"Attempting to continue iteration while the IterationState is already Continue\");\n  // If iteration has stopped for all frame types, set iterate_from_current_filter_ to true so the\n  // filter iteration starts with the current filter instead of the next one.\n  if (stoppedAll()) {\n    iterate_from_current_filter_ = true;\n  }\n  allowIteration();\n\n  // Only resume with do1xxHeaders() if we've actually seen 1xx headers.\n  if (has1xxHeaders()) {\n    continued_1xx_headers_ = true;\n    do1xxHeaders();\n    // If the response headers have not yet come in, don't continue on with\n    // headers and body. doHeaders expects request headers to exist.\n    if (!parent_.filter_manager_callbacks_.responseHeaders()) {\n      return;\n    }\n  }\n\n  // Make sure that we handle the zero byte data frame case. We make no effort to optimize this\n  // case in terms of merging it into a header only request/response. This could be done in the\n  // future.\n  if (!headers_continued_) {\n    headers_continued_ = true;\n    doHeaders(complete() && !bufferedData() && !hasTrailers());\n  }\n\n  doMetadata();\n\n  // It is possible for trailers to be added during doData(). doData() itself handles continuation\n  // of trailers for the non-continuation case. Thus, we must keep track of whether we had\n  // trailers prior to calling doData(). If we do, then we continue them here, otherwise we rely\n  // on doData() to do so.\n  const bool had_trailers_before_data = hasTrailers();\n  if (bufferedData()) {\n    doData(complete() && !had_trailers_before_data);\n  }\n\n  if (had_trailers_before_data) {\n    doTrailers();\n  }\n\n  iterate_from_current_filter_ = false;\n}\n\nbool ActiveStreamFilterBase::commonHandleAfter1xxHeadersCallback(FilterHeadersStatus status) {\n  ASSERT(parent_.state_.has_1xx_headers_);\n  ASSERT(!continued_1xx_headers_);\n  ASSERT(canIterate());\n\n  if (status == FilterHeadersStatus::StopIteration) {\n    iteration_state_ = IterationState::StopSingleIteration;\n    return false;\n  } else {\n    ASSERT(status == FilterHeadersStatus::Continue);\n    continued_1xx_headers_ = true;\n    return true;\n  }\n}\n\nbool ActiveStreamFilterBase::commonHandleAfterHeadersCallback(FilterHeadersStatus status,\n                                                              bool& end_stream) {\n  ASSERT(!headers_continued_);\n  ASSERT(canIterate());\n\n  switch (status) {\n  case FilterHeadersStatus::StopIteration:\n    iteration_state_ = IterationState::StopSingleIteration;\n    break;\n  case FilterHeadersStatus::StopAllIterationAndBuffer:\n    iteration_state_ = IterationState::StopAllBuffer;\n    break;\n  case FilterHeadersStatus::StopAllIterationAndWatermark:\n    iteration_state_ = IterationState::StopAllWatermark;\n    break;\n  case FilterHeadersStatus::ContinueAndDontEndStream:\n    end_stream = false;\n    headers_continued_ = true;\n    ENVOY_STREAM_LOG(debug, \"converting to headers and body (body not available yet)\", parent_);\n    break;\n  case FilterHeadersStatus::Continue:\n    headers_continued_ = true;\n    break;\n  }\n\n  handleMetadataAfterHeadersCallback();\n\n  if (stoppedAll() || status == FilterHeadersStatus::StopIteration) {\n    return false;\n  } else {\n    return true;\n  }\n}\n\nvoid ActiveStreamFilterBase::commonHandleBufferData(Buffer::Instance& provided_data) {\n\n  // The way we do buffering is a little complicated which is why we have this common function\n  // which is used for both encoding and decoding. When data first comes into our filter pipeline,\n  // we send it through. Any filter can choose to stop iteration and buffer or not. If we then\n  // continue iteration in the future, we use the buffered data. A future filter can stop and\n  // buffer again. In this case, since we are already operating on buffered data, we don't\n  // rebuffer, because we assume the filter has modified the buffer as it wishes in place.\n  if (bufferedData().get() != &provided_data) {\n    if (!bufferedData()) {\n      bufferedData() = createBuffer();\n    }\n    bufferedData()->move(provided_data);\n  }\n}\n\nbool ActiveStreamFilterBase::commonHandleAfterDataCallback(FilterDataStatus status,\n                                                           Buffer::Instance& provided_data,\n                                                           bool& buffer_was_streaming) {\n\n  if (status == FilterDataStatus::Continue) {\n    if (iteration_state_ == IterationState::StopSingleIteration) {\n      commonHandleBufferData(provided_data);\n      commonContinue();\n      return false;\n    } else {\n      ASSERT(headers_continued_);\n    }\n  } else {\n    iteration_state_ = IterationState::StopSingleIteration;\n    if (status == FilterDataStatus::StopIterationAndBuffer ||\n        status == FilterDataStatus::StopIterationAndWatermark) {\n      buffer_was_streaming = status == FilterDataStatus::StopIterationAndWatermark;\n      commonHandleBufferData(provided_data);\n    } else if (complete() && !hasTrailers() && !bufferedData() &&\n               // If the stream is destroyed, no need to handle the data buffer or trailers.\n               // This can occur if the filter calls sendLocalReply.\n               !parent_.state_.destroyed_) {\n      // If this filter is doing StopIterationNoBuffer and this stream is terminated with a zero\n      // byte data frame, we need to create an empty buffer to make sure that when commonContinue\n      // is called, the pipeline resumes with an empty data frame with end_stream = true\n      ASSERT(end_stream_);\n      bufferedData() = createBuffer();\n    }\n\n    return false;\n  }\n\n  return true;\n}\n\nbool ActiveStreamFilterBase::commonHandleAfterTrailersCallback(FilterTrailersStatus status) {\n\n  if (status == FilterTrailersStatus::Continue) {\n    if (iteration_state_ == IterationState::StopSingleIteration) {\n      commonContinue();\n      return false;\n    } else {\n      ASSERT(headers_continued_);\n    }\n  } else if (status == FilterTrailersStatus::StopIteration) {\n    if (canIterate()) {\n      iteration_state_ = IterationState::StopSingleIteration;\n    }\n    return false;\n  }\n\n  return true;\n}\n\nconst Network::Connection* ActiveStreamFilterBase::connection() { return parent_.connection(); }\n\nEvent::Dispatcher& ActiveStreamFilterBase::dispatcher() { return parent_.dispatcher_; }\n\nStreamInfo::StreamInfo& ActiveStreamFilterBase::streamInfo() { return parent_.stream_info_; }\n\nTracing::Span& ActiveStreamFilterBase::activeSpan() {\n  return parent_.filter_manager_callbacks_.activeSpan();\n}\n\nconst ScopeTrackedObject& ActiveStreamFilterBase::scope() {\n  return parent_.filter_manager_callbacks_.scope();\n}\n\nvoid ActiveStreamFilterBase::restoreContextOnContinue(\n    ScopeTrackedObjectStack& tracked_object_stack) {\n  parent_.contextOnContinue(tracked_object_stack);\n}\n\nTracing::Config& ActiveStreamFilterBase::tracingConfig() {\n  return parent_.filter_manager_callbacks_.tracingConfig();\n}\n\nUpstream::ClusterInfoConstSharedPtr ActiveStreamFilterBase::clusterInfo() {\n  return parent_.filter_manager_callbacks_.clusterInfo();\n}\n\nRouter::RouteConstSharedPtr ActiveStreamFilterBase::route() { return route(nullptr); }\n\nRouter::RouteConstSharedPtr ActiveStreamFilterBase::route(const Router::RouteCallback& cb) {\n  return parent_.filter_manager_callbacks_.route(cb);\n}\n\nvoid ActiveStreamFilterBase::setRoute(Router::RouteConstSharedPtr route) {\n  parent_.filter_manager_callbacks_.setRoute(std::move(route));\n}\n\nvoid ActiveStreamFilterBase::clearRouteCache() {\n  parent_.filter_manager_callbacks_.clearRouteCache();\n}\n\nvoid ActiveStreamFilterBase::resetIdleTimer() {\n  parent_.filter_manager_callbacks_.resetIdleTimer();\n}\n\nvoid FilterMatchState::evaluateMatchTreeWithNewData(MatchDataUpdateFunc update_func) {\n  if (match_tree_evaluated_ || !matching_data_) {\n    return;\n  }\n\n  update_func(*matching_data_);\n\n  const auto match_result = Matcher::evaluateMatch<HttpMatchingData>(*match_tree_, *matching_data_);\n\n  match_tree_evaluated_ = match_result.match_state_ == Matcher::MatchState::MatchComplete;\n\n  if (match_tree_evaluated_ && match_result.result_) {\n    const auto result = match_result.result_();\n    if (SkipAction().typeUrl() == result->typeUrl()) {\n      skip_filter_ = true;\n    } else {\n      filter_->onMatchCallback(*result);\n    }\n  }\n}\n\nbool ActiveStreamDecoderFilter::canContinue() {\n  // It is possible for the connection manager to respond directly to a request even while\n  // a filter is trying to continue. If a response has already happened, we should not\n  // continue to further filters. A concrete example of this is a filter buffering data, the\n  // last data frame comes in and the filter continues, but the final buffering takes the stream\n  // over the high watermark such that a 413 is returned.\n  return !parent_.state_.local_complete_;\n}\n\nbool ActiveStreamEncoderFilter::canContinue() {\n  // As with ActiveStreamDecoderFilter::canContinue() make sure we do not\n  // continue if a local reply has been sent.\n  return !parent_.state_.remote_encode_complete_;\n}\n\nBuffer::InstancePtr ActiveStreamDecoderFilter::createBuffer() {\n  auto buffer = dispatcher().getWatermarkFactory().createBuffer(\n      [this]() -> void { this->requestDataDrained(); },\n      [this]() -> void { this->requestDataTooLarge(); },\n      []() -> void { /* TODO(adisuissa): Handle overflow watermark */ });\n  buffer->setWatermarks(parent_.buffer_limit_);\n  return buffer;\n}\n\nBuffer::InstancePtr& ActiveStreamDecoderFilter::bufferedData() {\n  return parent_.buffered_request_data_;\n}\n\nbool ActiveStreamDecoderFilter::complete() { return parent_.remoteDecodeComplete(); }\n\nvoid ActiveStreamDecoderFilter::doHeaders(bool end_stream) {\n  parent_.decodeHeaders(this, *parent_.filter_manager_callbacks_.requestHeaders(), end_stream);\n}\n\nvoid ActiveStreamDecoderFilter::doData(bool end_stream) {\n  parent_.decodeData(this, *parent_.buffered_request_data_, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\n\nvoid ActiveStreamDecoderFilter::doTrailers() {\n  parent_.decodeTrailers(this, *parent_.filter_manager_callbacks_.requestTrailers());\n}\nbool ActiveStreamDecoderFilter::hasTrailers() {\n  return parent_.filter_manager_callbacks_.requestTrailers().has_value();\n}\n\nvoid ActiveStreamDecoderFilter::drainSavedRequestMetadata() {\n  ASSERT(saved_request_metadata_ != nullptr);\n  for (auto& metadata_map : *getSavedRequestMetadata()) {\n    parent_.decodeMetadata(this, *metadata_map);\n  }\n  getSavedRequestMetadata()->clear();\n}\n\nvoid ActiveStreamDecoderFilter::handleMetadataAfterHeadersCallback() {\n  // If we drain accumulated metadata, the iteration must start with the current filter.\n  const bool saved_state = iterate_from_current_filter_;\n  iterate_from_current_filter_ = true;\n  // If decodeHeaders() returns StopAllIteration, we should skip draining metadata, and wait\n  // for doMetadata() to drain the metadata after iteration continues.\n  if (!stoppedAll() && saved_request_metadata_ != nullptr && !getSavedRequestMetadata()->empty()) {\n    drainSavedRequestMetadata();\n  }\n  // Restores the original value of iterate_from_current_filter_.\n  iterate_from_current_filter_ = saved_state;\n}\n\nRequestTrailerMap& ActiveStreamDecoderFilter::addDecodedTrailers() {\n  return parent_.addDecodedTrailers();\n}\n\nvoid ActiveStreamDecoderFilter::addDecodedData(Buffer::Instance& data, bool streaming) {\n  parent_.addDecodedData(*this, data, streaming);\n}\n\nMetadataMapVector& ActiveStreamDecoderFilter::addDecodedMetadata() {\n  return parent_.addDecodedMetadata();\n}\n\nvoid ActiveStreamDecoderFilter::injectDecodedDataToFilterChain(Buffer::Instance& data,\n                                                               bool end_stream) {\n  if (!headers_continued_) {\n    headers_continued_ = true;\n    doHeaders(false);\n  }\n  parent_.decodeData(this, data, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\n\nvoid ActiveStreamDecoderFilter::continueDecoding() { commonContinue(); }\nconst Buffer::Instance* ActiveStreamDecoderFilter::decodingBuffer() {\n  return parent_.buffered_request_data_.get();\n}\n\nvoid ActiveStreamDecoderFilter::modifyDecodingBuffer(\n    std::function<void(Buffer::Instance&)> callback) {\n  ASSERT(parent_.state_.latest_data_decoding_filter_ == this);\n  callback(*parent_.buffered_request_data_.get());\n}\n\nvoid ActiveStreamDecoderFilter::sendLocalReply(\n    Code code, absl::string_view body,\n    std::function<void(ResponseHeaderMap& headers)> modify_headers,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details) {\n  parent_.sendLocalReply(code, body, modify_headers, grpc_status, details);\n}\n\nvoid ActiveStreamDecoderFilter::encode1xxHeaders(ResponseHeaderMapPtr&& headers) {\n  // If Envoy is not configured to proxy 100-Continue responses, swallow the 100 Continue\n  // here. This avoids the potential situation where Envoy strips Expect: 100-Continue and sends a\n  // 100-Continue, then proxies a duplicate 100 Continue from upstream.\n  if (parent_.proxy_100_continue_) {\n    parent_.filter_manager_callbacks_.setInformationalHeaders(std::move(headers));\n    parent_.encode1xxHeaders(nullptr, *parent_.filter_manager_callbacks_.informationalHeaders());\n  }\n}\n\nResponseHeaderMapOptRef ActiveStreamDecoderFilter::informationalHeaders() const {\n  return parent_.filter_manager_callbacks_.informationalHeaders();\n}\n\nvoid ActiveStreamDecoderFilter::encodeHeaders(ResponseHeaderMapPtr&& headers, bool end_stream,\n                                              absl::string_view details) {\n  parent_.stream_info_.setResponseCodeDetails(details);\n  parent_.filter_manager_callbacks_.setResponseHeaders(std::move(headers));\n  parent_.encodeHeaders(nullptr, *parent_.filter_manager_callbacks_.responseHeaders(), end_stream);\n}\n\nResponseHeaderMapOptRef ActiveStreamDecoderFilter::responseHeaders() const {\n  return parent_.filter_manager_callbacks_.responseHeaders();\n}\n\nvoid ActiveStreamDecoderFilter::encodeData(Buffer::Instance& data, bool end_stream) {\n  parent_.encodeData(nullptr, data, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\n\nvoid ActiveStreamDecoderFilter::encodeTrailers(ResponseTrailerMapPtr&& trailers) {\n  parent_.filter_manager_callbacks_.setResponseTrailers(std::move(trailers));\n  parent_.encodeTrailers(nullptr, *parent_.filter_manager_callbacks_.responseTrailers());\n}\n\nResponseTrailerMapOptRef ActiveStreamDecoderFilter::responseTrailers() const {\n  return parent_.filter_manager_callbacks_.responseTrailers();\n}\n\nvoid ActiveStreamDecoderFilter::encodeMetadata(MetadataMapPtr&& metadata_map_ptr) {\n  parent_.encodeMetadata(nullptr, std::move(metadata_map_ptr));\n}\n\nvoid ActiveStreamDecoderFilter::onDecoderFilterAboveWriteBufferHighWatermark() {\n  parent_.filter_manager_callbacks_.onDecoderFilterAboveWriteBufferHighWatermark();\n}\n\nvoid ActiveStreamDecoderFilter::requestDataTooLarge() {\n  ENVOY_STREAM_LOG(debug, \"request data too large watermark exceeded\", parent_);\n  if (parent_.state_.decoder_filters_streaming_) {\n    onDecoderFilterAboveWriteBufferHighWatermark();\n  } else {\n    parent_.filter_manager_callbacks_.onRequestDataTooLarge();\n    sendLocalReply(Code::PayloadTooLarge, CodeUtility::toString(Code::PayloadTooLarge), nullptr,\n                   absl::nullopt, StreamInfo::ResponseCodeDetails::get().RequestPayloadTooLarge);\n  }\n}\n\nvoid FilterManager::addStreamDecoderFilterWorker(StreamDecoderFilterSharedPtr filter,\n                                                 FilterMatchStateSharedPtr match_state,\n                                                 bool dual_filter) {\n  ActiveStreamDecoderFilterPtr wrapper(\n      new ActiveStreamDecoderFilter(*this, filter, match_state, dual_filter));\n\n  // If we're a dual handling filter, have the encoding wrapper be the only thing registering itself\n  // as the handling filter.\n  if (match_state) {\n    match_state->filter_ = filter.get();\n  }\n\n  filter->setDecoderFilterCallbacks(*wrapper);\n  // Note: configured decoder filters are appended to decoder_filters_.\n  // This means that if filters are configured in the following order (assume all three filters are\n  // both decoder/encoder filters):\n  //   http_filters:\n  //     - A\n  //     - B\n  //     - C\n  // The decoder filter chain will iterate through filters A, B, C.\n  LinkedList::moveIntoListBack(std::move(wrapper), decoder_filters_);\n}\n\nvoid FilterManager::addStreamEncoderFilterWorker(StreamEncoderFilterSharedPtr filter,\n                                                 FilterMatchStateSharedPtr match_state,\n                                                 bool dual_filter) {\n  ActiveStreamEncoderFilterPtr wrapper(\n      new ActiveStreamEncoderFilter(*this, filter, match_state, dual_filter));\n\n  if (match_state) {\n    match_state->filter_ = filter.get();\n  }\n\n  filter->setEncoderFilterCallbacks(*wrapper);\n  // Note: configured encoder filters are prepended to encoder_filters_.\n  // This means that if filters are configured in the following order (assume all three filters are\n  // both decoder/encoder filters):\n  //   http_filters:\n  //     - A\n  //     - B\n  //     - C\n  // The encoder filter chain will iterate through filters C, B, A.\n  LinkedList::moveIntoList(std::move(wrapper), encoder_filters_);\n}\n\nvoid FilterManager::addAccessLogHandler(AccessLog::InstanceSharedPtr handler) {\n  access_log_handlers_.push_back(handler);\n}\n\nvoid FilterManager::maybeContinueDecoding(\n    const std::list<ActiveStreamDecoderFilterPtr>::iterator& continue_data_entry) {\n  if (continue_data_entry != decoder_filters_.end()) {\n    // We use the continueDecoding() code since it will correctly handle not calling\n    // decodeHeaders() again. Fake setting StopSingleIteration since the continueDecoding() code\n    // expects it.\n    ASSERT(buffered_request_data_);\n    (*continue_data_entry)->iteration_state_ =\n        ActiveStreamFilterBase::IterationState::StopSingleIteration;\n    (*continue_data_entry)->continueDecoding();\n  }\n}\n\nvoid FilterManager::decodeHeaders(ActiveStreamDecoderFilter* filter, RequestHeaderMap& headers,\n                                  bool end_stream) {\n  // Headers filter iteration should always start with the next filter if available.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator entry =\n      commonDecodePrefix(filter, FilterIterationStartState::AlwaysStartFromNext);\n  std::list<ActiveStreamDecoderFilterPtr>::iterator continue_data_entry = decoder_filters_.end();\n\n  for (; entry != decoder_filters_.end(); entry++) {\n    (*entry)->maybeEvaluateMatchTreeWithNewData(\n        [&](auto& matching_data) { matching_data.onRequestHeaders(headers); });\n\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::DecodeHeaders));\n    state_.filter_call_state_ |= FilterCallState::DecodeHeaders;\n    (*entry)->end_stream_ = (end_stream && continue_data_entry == decoder_filters_.end());\n    FilterHeadersStatus status = (*entry)->decodeHeaders(headers, (*entry)->end_stream_);\n    if (state_.decoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace,\n                       \"decodeHeaders filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      status = FilterHeadersStatus::StopIteration;\n    }\n\n    ASSERT(!(status == FilterHeadersStatus::ContinueAndDontEndStream && !(*entry)->end_stream_),\n           \"Filters should not return FilterHeadersStatus::ContinueAndDontEndStream from \"\n           \"decodeHeaders when end_stream is already false\");\n\n    state_.filter_call_state_ &= ~FilterCallState::DecodeHeaders;\n    ENVOY_STREAM_LOG(trace, \"decode headers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n\n    (*entry)->decode_headers_called_ = true;\n\n    const auto continue_iteration = (*entry)->commonHandleAfterHeadersCallback(status, end_stream);\n    ENVOY_BUG(!continue_iteration || !state_.local_complete_,\n              \"Filter did not return StopAll or StopIteration after sending a local reply.\");\n\n    // If this filter ended the stream, decodeComplete() should be called for it.\n    if ((*entry)->end_stream_) {\n      (*entry)->handle_->decodeComplete();\n    }\n\n    // Skip processing metadata after sending local reply\n    if (state_.local_complete_ && std::next(entry) != decoder_filters_.end()) {\n      maybeContinueDecoding(continue_data_entry);\n      return;\n    }\n\n    const bool new_metadata_added = processNewlyAddedMetadata();\n    // If end_stream is set in headers, and a filter adds new metadata, we need to delay end_stream\n    // in headers by inserting an empty data frame with end_stream set. The empty data frame is sent\n    // after the new metadata.\n    if ((*entry)->end_stream_ && new_metadata_added && !buffered_request_data_) {\n      Buffer::OwnedImpl empty_data(\"\");\n      ENVOY_STREAM_LOG(\n          trace, \"inserting an empty data frame for end_stream due metadata being added.\", *this);\n      // Metadata frame doesn't carry end of stream bit. We need an empty data frame to end the\n      // stream.\n      addDecodedData(*((*entry).get()), empty_data, true);\n    }\n\n    if (!continue_iteration && std::next(entry) != decoder_filters_.end()) {\n      // Stop iteration IFF this is not the last filter. If it is the last filter, continue with\n      // processing since we need to handle the case where a terminal filter wants to buffer, but\n      // a previous filter has added body.\n      maybeContinueDecoding(continue_data_entry);\n      return;\n    }\n\n    // Here we handle the case where we have a header only request, but a filter adds a body\n    // to it. We need to not raise end_stream = true to further filters during inline iteration.\n    if (end_stream && buffered_request_data_ && continue_data_entry == decoder_filters_.end()) {\n      continue_data_entry = entry;\n    }\n  }\n\n  maybeContinueDecoding(continue_data_entry);\n\n  if (end_stream) {\n    disarmRequestTimeout();\n  }\n}\n\nvoid FilterManager::decodeData(ActiveStreamDecoderFilter* filter, Buffer::Instance& data,\n                               bool end_stream,\n                               FilterIterationStartState filter_iteration_start_state) {\n  ScopeTrackerScopeState scope(&*this, dispatcher_);\n  filter_manager_callbacks_.resetIdleTimer();\n\n  const bool fix_added_trailers =\n      Runtime::runtimeFeatureEnabled(\"envoy.reloadable_features.fix_added_trailers\");\n\n  // If a response is complete or a reset has been sent, filters do not care about further body\n  // data. Just drop it.\n  if (state_.local_complete_) {\n    return;\n  }\n\n  auto trailers_added_entry = decoder_filters_.end();\n  const bool trailers_exists_at_start = filter_manager_callbacks_.requestTrailers().has_value();\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator entry =\n      commonDecodePrefix(filter, filter_iteration_start_state);\n\n  for (; entry != decoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    // If the filter pointed by entry has stopped for all frame types, return now.\n    if (handleDataIfStopAll(**entry, data, state_.decoder_filters_streaming_)) {\n      return;\n    }\n    // If end_stream_ is marked for a filter, the data is not for this filter and filters after.\n    //\n    // In following case, ActiveStreamFilterBase::commonContinue() could be called recursively and\n    // its doData() is called with wrong data.\n    //\n    //  There are 3 decode filters and \"wrapper\" refers to ActiveStreamFilter object.\n    //\n    //  filter0->decodeHeaders(_, true)\n    //    return STOP\n    //  filter0->continueDecoding()\n    //    wrapper0->commonContinue()\n    //      wrapper0->decodeHeaders(_, _, true)\n    //        filter1->decodeHeaders(_, true)\n    //          filter1->addDecodeData()\n    //          return CONTINUE\n    //        filter2->decodeHeaders(_, false)\n    //          return CONTINUE\n    //        wrapper1->commonContinue() // Detects data is added.\n    //          wrapper1->doData()\n    //            wrapper1->decodeData()\n    //              filter2->decodeData(_, true)\n    //                 return CONTINUE\n    //      wrapper0->doData() // This should not be called\n    //        wrapper0->decodeData()\n    //          filter1->decodeData(_, true)  // It will cause assertions.\n    //\n    // One way to solve this problem is to mark end_stream_ for each filter.\n    // If a filter is already marked as end_stream_ when decodeData() is called, bails out the\n    // whole function. If just skip the filter, the codes after the loop will be called with\n    // wrong data. For encodeData, the response_encoder->encode() will be called.\n    if ((*entry)->end_stream_) {\n      return;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::DecodeData));\n\n    // We check the request_trailers_ pointer here in case addDecodedTrailers\n    // is called in decodeData during a previous filter invocation, at which point we communicate to\n    // the current and future filters that the stream has not yet ended.\n    if (end_stream) {\n      state_.filter_call_state_ |= FilterCallState::LastDataFrame;\n    }\n\n    recordLatestDataFilter(entry, state_.latest_data_decoding_filter_, decoder_filters_);\n\n    state_.filter_call_state_ |= FilterCallState::DecodeData;\n    (*entry)->end_stream_ = end_stream && !filter_manager_callbacks_.requestTrailers();\n    FilterDataStatus status = (*entry)->handle_->decodeData(data, (*entry)->end_stream_);\n    if ((*entry)->end_stream_) {\n      (*entry)->handle_->decodeComplete();\n    }\n    state_.filter_call_state_ &= ~FilterCallState::DecodeData;\n    if (end_stream) {\n      state_.filter_call_state_ &= ~FilterCallState::LastDataFrame;\n    }\n    ENVOY_STREAM_LOG(trace, \"decode data called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n    if (state_.decoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace, \"decodeData filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      return;\n    }\n\n    processNewlyAddedMetadata();\n\n    if (!trailers_exists_at_start && filter_manager_callbacks_.requestTrailers() &&\n        trailers_added_entry == decoder_filters_.end()) {\n      if (fix_added_trailers) {\n        end_stream = false;\n      }\n      trailers_added_entry = entry;\n    }\n\n    if (!(*entry)->commonHandleAfterDataCallback(status, data, state_.decoder_filters_streaming_) &&\n        std::next(entry) != decoder_filters_.end()) {\n      // Stop iteration IFF this is not the last filter. If it is the last filter, continue with\n      // processing since we need to handle the case where a terminal filter wants to buffer, but\n      // a previous filter has added trailers.\n      if (fix_added_trailers) {\n        break;\n      } else {\n        return;\n      }\n    }\n  }\n\n  // If trailers were adding during decodeData we need to trigger decodeTrailers in order\n  // to allow filters to process the trailers.\n  if (trailers_added_entry != decoder_filters_.end()) {\n    decodeTrailers(trailers_added_entry->get(), *filter_manager_callbacks_.requestTrailers());\n  }\n\n  if (end_stream) {\n    disarmRequestTimeout();\n  }\n}\n\nRequestTrailerMap& FilterManager::addDecodedTrailers() {\n  // Trailers can only be added during the last data frame (i.e. end_stream = true).\n  ASSERT(state_.filter_call_state_ & FilterCallState::LastDataFrame);\n\n  filter_manager_callbacks_.setRequestTrailers(RequestTrailerMapImpl::create());\n  return *filter_manager_callbacks_.requestTrailers();\n}\n\nvoid FilterManager::addDecodedData(ActiveStreamDecoderFilter& filter, Buffer::Instance& data,\n                                   bool streaming) {\n  if (state_.filter_call_state_ == 0 ||\n      (state_.filter_call_state_ & FilterCallState::DecodeHeaders) ||\n      (state_.filter_call_state_ & FilterCallState::DecodeData) ||\n      ((state_.filter_call_state_ & FilterCallState::DecodeTrailers) && !filter.canIterate())) {\n    // Make sure if this triggers watermarks, the correct action is taken.\n    state_.decoder_filters_streaming_ = streaming;\n    // If no call is happening or we are in the decode headers/data callback, buffer the data.\n    // Inline processing happens in the decodeHeaders() callback if necessary.\n    filter.commonHandleBufferData(data);\n  } else if (state_.filter_call_state_ & FilterCallState::DecodeTrailers) {\n    // In this case we need to inline dispatch the data to further filters. If those filters\n    // choose to buffer/stop iteration that's fine.\n    decodeData(&filter, data, false, FilterIterationStartState::AlwaysStartFromNext);\n  } else {\n    IS_ENVOY_BUG(\"Invalid request data\");\n    sendLocalReply(Http::Code::BadGateway, \"Filter error\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().FilterAddedInvalidRequestData);\n  }\n}\n\nMetadataMapVector& FilterManager::addDecodedMetadata() { return *getRequestMetadataMapVector(); }\n\nvoid FilterManager::decodeTrailers(ActiveStreamDecoderFilter* filter, RequestTrailerMap& trailers) {\n  // See decodeData() above for why we check local_complete_ here.\n  if (state_.local_complete_) {\n    return;\n  }\n\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator entry =\n      commonDecodePrefix(filter, FilterIterationStartState::CanStartFromCurrent);\n\n  for (; entry != decoder_filters_.end(); entry++) {\n    (*entry)->maybeEvaluateMatchTreeWithNewData(\n        [&](auto& matching_data) { matching_data.onRequestTrailers(trailers); });\n\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n\n    // If the filter pointed by entry has stopped for all frame type, return now.\n    if ((*entry)->stoppedAll()) {\n      return;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::DecodeTrailers));\n    state_.filter_call_state_ |= FilterCallState::DecodeTrailers;\n    FilterTrailersStatus status = (*entry)->handle_->decodeTrailers(trailers);\n    (*entry)->handle_->decodeComplete();\n    (*entry)->end_stream_ = true;\n    state_.filter_call_state_ &= ~FilterCallState::DecodeTrailers;\n    ENVOY_STREAM_LOG(trace, \"decode trailers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n    if (state_.decoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace,\n                       \"decodeTrailers filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      status = FilterTrailersStatus::StopIteration;\n    }\n\n    processNewlyAddedMetadata();\n\n    if (!(*entry)->commonHandleAfterTrailersCallback(status)) {\n      return;\n    }\n  }\n  disarmRequestTimeout();\n}\n\nvoid FilterManager::decodeMetadata(ActiveStreamDecoderFilter* filter, MetadataMap& metadata_map) {\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator entry =\n      commonDecodePrefix(filter, FilterIterationStartState::CanStartFromCurrent);\n\n  for (; entry != decoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    // If the filter pointed by entry has stopped for all frame type, stores metadata and returns.\n    // If the filter pointed by entry hasn't returned from decodeHeaders, stores newly added\n    // metadata in case decodeHeaders returns StopAllIteration. The latter can happen when headers\n    // callbacks generate new metadata.\n    if (!(*entry)->decode_headers_called_ || (*entry)->stoppedAll()) {\n      Http::MetadataMapPtr metadata_map_ptr = std::make_unique<Http::MetadataMap>(metadata_map);\n      (*entry)->getSavedRequestMetadata()->emplace_back(std::move(metadata_map_ptr));\n      return;\n    }\n\n    FilterMetadataStatus status = (*entry)->handle_->decodeMetadata(metadata_map);\n    ENVOY_STREAM_LOG(trace, \"decode metadata called: filter={} status={}, metadata: {}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status),\n                     metadata_map);\n  }\n}\n\nvoid FilterManager::maybeEndDecode(bool end_stream) {\n  // If recreateStream is called, the HCM rewinds state and may send more encodeData calls.\n  if (end_stream && !remoteDecodeComplete()) {\n    stream_info_.downstreamTiming().onLastDownstreamRxByteReceived(dispatcher().timeSource());\n    ENVOY_STREAM_LOG(debug, \"request end stream\", *this);\n  }\n}\n\nvoid FilterManager::disarmRequestTimeout() { filter_manager_callbacks_.disarmRequestTimeout(); }\n\nstd::list<ActiveStreamEncoderFilterPtr>::iterator\nFilterManager::commonEncodePrefix(ActiveStreamEncoderFilter* filter, bool end_stream,\n                                  FilterIterationStartState filter_iteration_start_state) {\n  // Only do base state setting on the initial call. Subsequent calls for filtering do not touch\n  // the base state.\n  if (filter == nullptr) {\n    ASSERT(!state_.local_complete_);\n    state_.local_complete_ = end_stream;\n    return encoder_filters_.begin();\n  }\n\n  if (filter_iteration_start_state == FilterIterationStartState::CanStartFromCurrent &&\n      (*(filter->entry()))->iterate_from_current_filter_) {\n    // The filter iteration has been stopped for all frame types, and now the iteration continues.\n    // The current filter's encoding callback has not be called. Call it now.\n    return filter->entry();\n  }\n  return std::next(filter->entry());\n}\n\nstd::list<ActiveStreamDecoderFilterPtr>::iterator\nFilterManager::commonDecodePrefix(ActiveStreamDecoderFilter* filter,\n                                  FilterIterationStartState filter_iteration_start_state) {\n  if (!filter) {\n    return decoder_filters_.begin();\n  }\n  if (filter_iteration_start_state == FilterIterationStartState::CanStartFromCurrent &&\n      (*(filter->entry()))->iterate_from_current_filter_) {\n    // The filter iteration has been stopped for all frame types, and now the iteration continues.\n    // The current filter's callback function has not been called. Call it now.\n    return filter->entry();\n  }\n  return std::next(filter->entry());\n}\n\nvoid FilterManager::onLocalReply(StreamFilterBase::LocalReplyData& data) {\n  state_.under_on_local_reply_ = true;\n  filter_manager_callbacks_.onLocalReply(data.code_);\n\n  for (auto entry : filters_) {\n    if (entry->onLocalReply(data) == LocalErrorStatus::ContinueAndResetStream) {\n      data.reset_imminent_ = true;\n    }\n  }\n  state_.under_on_local_reply_ = false;\n}\n\nvoid FilterManager::sendLocalReply(\n    Code code, absl::string_view body,\n    const std::function<void(ResponseHeaderMap& headers)>& modify_headers,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details) {\n  ASSERT(!state_.under_on_local_reply_);\n  const bool is_head_request = state_.is_head_request_;\n  const bool is_grpc_request = state_.is_grpc_request_;\n\n  // Stop filter chain iteration if local reply was sent while filter decoding or encoding callbacks\n  // are running.\n  if (state_.filter_call_state_ & (FilterCallState::DecodeHeaders | FilterCallState::DecodeData |\n                                   FilterCallState::DecodeTrailers)) {\n    state_.decoder_filter_chain_aborted_ = true;\n  } else if (state_.filter_call_state_ &\n             (FilterCallState::EncodeHeaders | FilterCallState::EncodeData |\n              FilterCallState::EncodeTrailers)) {\n    state_.encoder_filter_chain_aborted_ = true;\n  }\n\n  stream_info_.setResponseCodeDetails(details);\n  StreamFilterBase::LocalReplyData data{code, details, false};\n  FilterManager::onLocalReply(data);\n  if (data.reset_imminent_) {\n    ENVOY_STREAM_LOG(debug, \"Resetting stream due to {}. onLocalReply requested reset.\", *this,\n                     details);\n    filter_manager_callbacks_.resetStream();\n    return;\n  }\n\n  if (!filter_manager_callbacks_.responseHeaders().has_value()) {\n    // If the response has not started at all, send the response through the filter chain.\n    sendLocalReplyViaFilterChain(is_grpc_request, code, body, modify_headers, is_head_request,\n                                 grpc_status, details);\n  } else if (!state_.non_100_response_headers_encoded_) {\n    ENVOY_STREAM_LOG(debug, \"Sending local reply with details {} directly to the encoder\", *this,\n                     details);\n    // In this case, at least the header and possibly the body has started\n    // processing through the filter chain, but no non-informational headers\n    // have been sent downstream. To ensure that filters don't get their\n    // state machine screwed up, bypass the filter chain and send the local\n    // reply directly to the codec.\n    //\n    sendDirectLocalReply(code, body, modify_headers, state_.is_head_request_, grpc_status);\n  } else {\n    // If we land in this branch, response headers have already been sent to the client.\n    // All we can do at this point is reset the stream.\n    ENVOY_STREAM_LOG(debug, \"Resetting stream due to {}. Prior headers have already been sent\",\n                     *this, details);\n    // TODO(snowp): This means we increment the tx_reset stat which we weren't doing previously.\n    // Intended?\n    filter_manager_callbacks_.resetStream();\n  }\n}\n\nvoid FilterManager::sendLocalReplyViaFilterChain(\n    bool is_grpc_request, Code code, absl::string_view body,\n    const std::function<void(ResponseHeaderMap& headers)>& modify_headers, bool is_head_request,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details) {\n  ENVOY_STREAM_LOG(debug, \"Sending local reply with details {}\", *this, details);\n  ASSERT(!filter_manager_callbacks_.responseHeaders().has_value());\n  // For early error handling, do a best-effort attempt to create a filter chain\n  // to ensure access logging. If the filter chain already exists this will be\n  // a no-op.\n  createFilterChain();\n\n  Utility::sendLocalReply(\n      state_.destroyed_,\n      Utility::EncodeFunctions{\n          [this, modify_headers](ResponseHeaderMap& headers) -> void {\n            if (streamInfo().route() && streamInfo().route()->routeEntry()) {\n              streamInfo().route()->routeEntry()->finalizeResponseHeaders(headers, streamInfo());\n            }\n            if (modify_headers) {\n              modify_headers(headers);\n            }\n          },\n          [this](ResponseHeaderMap& response_headers, Code& code, std::string& body,\n                 absl::string_view& content_type) -> void {\n            // TODO(snowp): This &get() business isn't nice, rework LocalReply and others to accept\n            // opt refs.\n            local_reply_.rewrite(filter_manager_callbacks_.requestHeaders().ptr(), response_headers,\n                                 stream_info_, code, body, content_type);\n          },\n          [this, modify_headers](ResponseHeaderMapPtr&& headers, bool end_stream) -> void {\n            filter_manager_callbacks_.setResponseHeaders(std::move(headers));\n            // TODO: Start encoding from the last decoder filter that saw the\n            // request instead.\n            encodeHeaders(nullptr, filter_manager_callbacks_.responseHeaders().ref(), end_stream);\n          },\n          [this](Buffer::Instance& data, bool end_stream) -> void {\n            // TODO: Start encoding from the last decoder filter that saw the\n            // request instead.\n            encodeData(nullptr, data, end_stream,\n                       FilterManager::FilterIterationStartState::CanStartFromCurrent);\n          }},\n      Utility::LocalReplyData{is_grpc_request, code, body, grpc_status, is_head_request});\n}\n\nvoid FilterManager::sendDirectLocalReply(\n    Code code, absl::string_view body,\n    const std::function<void(ResponseHeaderMap&)>& modify_headers, bool is_head_request,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status) {\n  // Make sure we won't end up with nested watermark calls from the body buffer.\n  state_.encoder_filters_streaming_ = true;\n  Http::Utility::sendLocalReply(\n      state_.destroyed_,\n      Utility::EncodeFunctions{\n          [this, modify_headers](ResponseHeaderMap& headers) -> void {\n            if (streamInfo().route() && streamInfo().route()->routeEntry()) {\n              streamInfo().route()->routeEntry()->finalizeResponseHeaders(headers, streamInfo());\n            }\n            if (modify_headers) {\n              modify_headers(headers);\n            }\n          },\n          [&](ResponseHeaderMap& response_headers, Code& code, std::string& body,\n              absl::string_view& content_type) -> void {\n            local_reply_.rewrite(filter_manager_callbacks_.requestHeaders().ptr(), response_headers,\n                                 stream_info_, code, body, content_type);\n          },\n          [&](ResponseHeaderMapPtr&& response_headers, bool end_stream) -> void {\n            // Move the response headers into the FilterManager to make sure they're visible to\n            // access logs.\n            filter_manager_callbacks_.setResponseHeaders(std::move(response_headers));\n\n            state_.non_100_response_headers_encoded_ = true;\n            filter_manager_callbacks_.encodeHeaders(*filter_manager_callbacks_.responseHeaders(),\n                                                    end_stream);\n            if (state_.saw_downstream_reset_) {\n              return;\n            }\n            maybeEndEncode(end_stream);\n          },\n          [&](Buffer::Instance& data, bool end_stream) -> void {\n            filter_manager_callbacks_.encodeData(data, end_stream);\n            if (state_.saw_downstream_reset_) {\n              return;\n            }\n            maybeEndEncode(end_stream);\n          }},\n      Utility::LocalReplyData{state_.is_grpc_request_, code, body, grpc_status, is_head_request});\n}\n\nvoid FilterManager::encode1xxHeaders(ActiveStreamEncoderFilter* filter,\n                                     ResponseHeaderMap& headers) {\n  filter_manager_callbacks_.resetIdleTimer();\n  ASSERT(proxy_100_continue_);\n  // The caller must guarantee that encode1xxHeaders() is invoked at most once.\n  ASSERT(!state_.has_1xx_headers_ || filter != nullptr);\n  // Make sure commonContinue continues encode1xxHeaders.\n  state_.has_1xx_headers_ = true;\n\n  // Similar to the block in encodeHeaders, run encode1xxHeaders on each\n  // filter. This is simpler than that case because 100 continue implies no\n  // end-stream, and because there are normal headers coming there's no need for\n  // complex continuation logic.\n  // 100-continue filter iteration should always start with the next filter if available.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, false, FilterIterationStartState::AlwaysStartFromNext);\n  for (; entry != encoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::Encode1xxHeaders));\n    state_.filter_call_state_ |= FilterCallState::Encode1xxHeaders;\n    FilterHeadersStatus status = (*entry)->handle_->encode1xxHeaders(headers);\n    state_.filter_call_state_ &= ~FilterCallState::Encode1xxHeaders;\n    ENVOY_STREAM_LOG(trace, \"encode 1xx continue headers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n    if (!(*entry)->commonHandleAfter1xxHeadersCallback(status)) {\n      return;\n    }\n  }\n\n  filter_manager_callbacks_.encode1xxHeaders(headers);\n}\n\nvoid FilterManager::maybeContinueEncoding(\n    const std::list<ActiveStreamEncoderFilterPtr>::iterator& continue_data_entry) {\n  if (continue_data_entry != encoder_filters_.end()) {\n    // We use the continueEncoding() code since it will correctly handle not calling\n    // encodeHeaders() again. Fake setting StopSingleIteration since the continueEncoding() code\n    // expects it.\n    ASSERT(buffered_response_data_);\n    (*continue_data_entry)->iteration_state_ =\n        ActiveStreamFilterBase::IterationState::StopSingleIteration;\n    (*continue_data_entry)->continueEncoding();\n  }\n}\n\nvoid FilterManager::encodeHeaders(ActiveStreamEncoderFilter* filter, ResponseHeaderMap& headers,\n                                  bool end_stream) {\n  // See encodeHeaders() comments in include/envoy/http/filter.h for why the 1xx precondition holds.\n  ASSERT(!CodeUtility::is1xx(Utility::getResponseStatus(headers)) ||\n         Utility::getResponseStatus(headers) == enumToInt(Http::Code::SwitchingProtocols));\n  filter_manager_callbacks_.resetIdleTimer();\n  disarmRequestTimeout();\n\n  // Headers filter iteration should always start with the next filter if available.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, end_stream, FilterIterationStartState::AlwaysStartFromNext);\n  std::list<ActiveStreamEncoderFilterPtr>::iterator continue_data_entry = encoder_filters_.end();\n\n  for (; entry != encoder_filters_.end(); entry++) {\n    (*entry)->maybeEvaluateMatchTreeWithNewData(\n        [&headers](auto& matching_data) { matching_data.onResponseHeaders(headers); });\n\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::EncodeHeaders));\n    state_.filter_call_state_ |= FilterCallState::EncodeHeaders;\n    (*entry)->end_stream_ = (end_stream && continue_data_entry == encoder_filters_.end());\n    FilterHeadersStatus status = (*entry)->handle_->encodeHeaders(headers, (*entry)->end_stream_);\n    if (state_.encoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace,\n                       \"encodeHeaders filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      status = FilterHeadersStatus::StopIteration;\n    }\n\n    ASSERT(!(status == FilterHeadersStatus::ContinueAndDontEndStream && !(*entry)->end_stream_),\n           \"Filters should not return FilterHeadersStatus::ContinueAndDontEndStream from \"\n           \"encodeHeaders when end_stream is already false\");\n\n    state_.filter_call_state_ &= ~FilterCallState::EncodeHeaders;\n    ENVOY_STREAM_LOG(trace, \"encode headers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n\n    (*entry)->encode_headers_called_ = true;\n\n    const auto continue_iteration = (*entry)->commonHandleAfterHeadersCallback(status, end_stream);\n\n    // If this filter ended the stream, encodeComplete() should be called for it.\n    if ((*entry)->end_stream_) {\n      (*entry)->handle_->encodeComplete();\n    }\n\n    if (!continue_iteration) {\n      if (!(*entry)->end_stream_) {\n        maybeContinueEncoding(continue_data_entry);\n      }\n      return;\n    }\n\n    // Here we handle the case where we have a header only response, but a filter adds a body\n    // to it. We need to not raise end_stream = true to further filters during inline iteration.\n    if (end_stream && buffered_response_data_ && continue_data_entry == encoder_filters_.end()) {\n      continue_data_entry = entry;\n    }\n  }\n\n  // Check if the filter chain above did not remove critical headers or set malformed header values.\n  // We could do this at the codec in order to prevent other places than the filter chain from\n  // removing critical headers, but it will come with the implementation complexity.\n  // See the previous attempt (#15658) for detail, and for now we choose to protect only against\n  // filter chains.\n  const auto status = HeaderUtility::checkRequiredResponseHeaders(headers);\n  if (!status.ok()) {\n    // If the check failed, then we reply with BadGateway, and stop the further processing.\n    sendLocalReply(\n        Http::Code::BadGateway, status.message(), nullptr, absl::nullopt,\n        absl::StrCat(StreamInfo::ResponseCodeDetails::get().FilterRemovedRequiredResponseHeaders,\n                     \"{\", StringUtil::replaceAllEmptySpace(status.message()), \"}\"));\n    return;\n  }\n\n  const bool modified_end_stream = (end_stream && continue_data_entry == encoder_filters_.end());\n  state_.non_100_response_headers_encoded_ = true;\n  filter_manager_callbacks_.encodeHeaders(headers, modified_end_stream);\n  if (state_.saw_downstream_reset_) {\n    return;\n  }\n  maybeEndEncode(modified_end_stream);\n\n  if (!modified_end_stream) {\n    maybeContinueEncoding(continue_data_entry);\n  }\n}\n\nvoid FilterManager::encodeMetadata(ActiveStreamEncoderFilter* filter,\n                                   MetadataMapPtr&& metadata_map_ptr) {\n  filter_manager_callbacks_.resetIdleTimer();\n\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, false, FilterIterationStartState::CanStartFromCurrent);\n\n  for (; entry != encoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    // If the filter pointed by entry has stopped for all frame type, stores metadata and returns.\n    // If the filter pointed by entry hasn't returned from encodeHeaders, stores newly added\n    // metadata in case encodeHeaders returns StopAllIteration. The latter can happen when headers\n    // callbacks generate new metadata.\n    if (!(*entry)->encode_headers_called_ || (*entry)->stoppedAll()) {\n      (*entry)->getSavedResponseMetadata()->emplace_back(std::move(metadata_map_ptr));\n      return;\n    }\n\n    FilterMetadataStatus status = (*entry)->handle_->encodeMetadata(*metadata_map_ptr);\n    ENVOY_STREAM_LOG(trace, \"encode metadata called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n  }\n  // TODO(soya3129): update stats with metadata.\n\n  // Now encode metadata via the codec.\n  if (!metadata_map_ptr->empty()) {\n    MetadataMapVector metadata_map_vector;\n    metadata_map_vector.emplace_back(std::move(metadata_map_ptr));\n    filter_manager_callbacks_.encodeMetadata(metadata_map_vector);\n  }\n}\n\nResponseTrailerMap& FilterManager::addEncodedTrailers() {\n  // Trailers can only be added during the last data frame (i.e. end_stream = true).\n  ASSERT(state_.filter_call_state_ & FilterCallState::LastDataFrame);\n\n  // Trailers can only be added once.\n  ASSERT(!filter_manager_callbacks_.responseTrailers());\n\n  filter_manager_callbacks_.setResponseTrailers(ResponseTrailerMapImpl::create());\n  return *filter_manager_callbacks_.responseTrailers();\n}\n\nvoid FilterManager::addEncodedData(ActiveStreamEncoderFilter& filter, Buffer::Instance& data,\n                                   bool streaming) {\n  if (state_.filter_call_state_ == 0 ||\n      (state_.filter_call_state_ & FilterCallState::EncodeHeaders) ||\n      (state_.filter_call_state_ & FilterCallState::EncodeData) ||\n      ((state_.filter_call_state_ & FilterCallState::EncodeTrailers) && !filter.canIterate())) {\n    // Make sure if this triggers watermarks, the correct action is taken.\n    state_.encoder_filters_streaming_ = streaming;\n    // If no call is happening or we are in the decode headers/data callback, buffer the data.\n    // Inline processing happens in the decodeHeaders() callback if necessary.\n    filter.commonHandleBufferData(data);\n  } else if (state_.filter_call_state_ & FilterCallState::EncodeTrailers) {\n    // In this case we need to inline dispatch the data to further filters. If those filters\n    // choose to buffer/stop iteration that's fine.\n    encodeData(&filter, data, false, FilterIterationStartState::AlwaysStartFromNext);\n  } else {\n    IS_ENVOY_BUG(\"Invalid response data\");\n    sendLocalReply(Http::Code::BadGateway, \"Filter error\", nullptr, absl::nullopt,\n                   StreamInfo::ResponseCodeDetails::get().FilterAddedInvalidResponseData);\n  }\n}\n\nvoid FilterManager::encodeData(ActiveStreamEncoderFilter* filter, Buffer::Instance& data,\n                               bool end_stream,\n                               FilterIterationStartState filter_iteration_start_state) {\n  filter_manager_callbacks_.resetIdleTimer();\n\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, end_stream, filter_iteration_start_state);\n  auto trailers_added_entry = encoder_filters_.end();\n\n  const bool trailers_exists_at_start = filter_manager_callbacks_.responseTrailers().has_value();\n  for (; entry != encoder_filters_.end(); entry++) {\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n    // If the filter pointed by entry has stopped for all frame type, return now.\n    if (handleDataIfStopAll(**entry, data, state_.encoder_filters_streaming_)) {\n      return;\n    }\n    // If end_stream_ is marked for a filter, the data is not for this filter and filters after.\n    // For details, please see the comment in the ActiveStream::decodeData() function.\n    if ((*entry)->end_stream_) {\n      return;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::EncodeData));\n\n    // We check the response_trailers_ pointer here in case addEncodedTrailers\n    // is called in encodeData during a previous filter invocation, at which point we communicate to\n    // the current and future filters that the stream has not yet ended.\n    state_.filter_call_state_ |= FilterCallState::EncodeData;\n    if (end_stream) {\n      state_.filter_call_state_ |= FilterCallState::LastDataFrame;\n    }\n\n    recordLatestDataFilter(entry, state_.latest_data_encoding_filter_, encoder_filters_);\n\n    (*entry)->end_stream_ = end_stream && !filter_manager_callbacks_.responseTrailers();\n    FilterDataStatus status = (*entry)->handle_->encodeData(data, (*entry)->end_stream_);\n    if (state_.encoder_filter_chain_aborted_) {\n      ENVOY_STREAM_LOG(trace, \"encodeData filter iteration aborted due to local reply: filter={}\",\n                       *this, static_cast<const void*>((*entry).get()));\n      status = FilterDataStatus::StopIterationNoBuffer;\n    }\n    if ((*entry)->end_stream_) {\n      (*entry)->handle_->encodeComplete();\n    }\n    state_.filter_call_state_ &= ~FilterCallState::EncodeData;\n    if (end_stream) {\n      state_.filter_call_state_ &= ~FilterCallState::LastDataFrame;\n    }\n    ENVOY_STREAM_LOG(trace, \"encode data called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n\n    if (!trailers_exists_at_start && filter_manager_callbacks_.responseTrailers() &&\n        trailers_added_entry == encoder_filters_.end()) {\n      trailers_added_entry = entry;\n    }\n\n    if (!(*entry)->commonHandleAfterDataCallback(status, data, state_.encoder_filters_streaming_)) {\n      return;\n    }\n  }\n\n  const bool modified_end_stream = end_stream && trailers_added_entry == encoder_filters_.end();\n  filter_manager_callbacks_.encodeData(data, modified_end_stream);\n  if (state_.saw_downstream_reset_) {\n    return;\n  }\n  maybeEndEncode(modified_end_stream);\n\n  // If trailers were adding during encodeData we need to trigger decodeTrailers in order\n  // to allow filters to process the trailers.\n  if (trailers_added_entry != encoder_filters_.end()) {\n    encodeTrailers(trailers_added_entry->get(), *filter_manager_callbacks_.responseTrailers());\n  }\n}\n\nvoid FilterManager::encodeTrailers(ActiveStreamEncoderFilter* filter,\n                                   ResponseTrailerMap& trailers) {\n  filter_manager_callbacks_.resetIdleTimer();\n\n  // Filter iteration may start at the current filter.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator entry =\n      commonEncodePrefix(filter, true, FilterIterationStartState::CanStartFromCurrent);\n  for (; entry != encoder_filters_.end(); entry++) {\n    (*entry)->maybeEvaluateMatchTreeWithNewData(\n        [&](auto& matching_data) { matching_data.onResponseTrailers(trailers); });\n\n    if ((*entry)->skipFilter()) {\n      continue;\n    }\n\n    // If the filter pointed by entry has stopped for all frame type, return now.\n    if ((*entry)->stoppedAll()) {\n      return;\n    }\n    ASSERT(!(state_.filter_call_state_ & FilterCallState::EncodeTrailers));\n    state_.filter_call_state_ |= FilterCallState::EncodeTrailers;\n    FilterTrailersStatus status = (*entry)->handle_->encodeTrailers(trailers);\n    (*entry)->handle_->encodeComplete();\n    (*entry)->end_stream_ = true;\n    state_.filter_call_state_ &= ~FilterCallState::EncodeTrailers;\n    ENVOY_STREAM_LOG(trace, \"encode trailers called: filter={} status={}\", *this,\n                     static_cast<const void*>((*entry).get()), static_cast<uint64_t>(status));\n    if (!(*entry)->commonHandleAfterTrailersCallback(status)) {\n      return;\n    }\n  }\n\n  filter_manager_callbacks_.encodeTrailers(trailers);\n  if (state_.saw_downstream_reset_) {\n    return;\n  }\n  maybeEndEncode(true);\n}\n\nvoid FilterManager::maybeEndEncode(bool end_stream) {\n  if (end_stream) {\n    ASSERT(!state_.remote_encode_complete_);\n    state_.remote_encode_complete_ = true;\n    filter_manager_callbacks_.endStream();\n  }\n}\n\nbool FilterManager::processNewlyAddedMetadata() {\n  if (request_metadata_map_vector_ == nullptr) {\n    return false;\n  }\n  for (const auto& metadata_map : *getRequestMetadataMapVector()) {\n    decodeMetadata(nullptr, *metadata_map);\n  }\n  getRequestMetadataMapVector()->clear();\n  return true;\n}\n\nbool FilterManager::handleDataIfStopAll(ActiveStreamFilterBase& filter, Buffer::Instance& data,\n                                        bool& filter_streaming) {\n  if (filter.stoppedAll()) {\n    ASSERT(!filter.canIterate());\n    filter_streaming =\n        filter.iteration_state_ == ActiveStreamFilterBase::IterationState::StopAllWatermark;\n    filter.commonHandleBufferData(data);\n    return true;\n  }\n  return false;\n}\n\nvoid FilterManager::callHighWatermarkCallbacks() {\n  ++high_watermark_count_;\n  for (auto watermark_callbacks : watermark_callbacks_) {\n    watermark_callbacks->onAboveWriteBufferHighWatermark();\n  }\n}\n\nvoid FilterManager::callLowWatermarkCallbacks() {\n  ASSERT(high_watermark_count_ > 0);\n  --high_watermark_count_;\n  for (auto watermark_callbacks : watermark_callbacks_) {\n    watermark_callbacks->onBelowWriteBufferLowWatermark();\n  }\n}\n\nvoid FilterManager::setBufferLimit(uint32_t new_limit) {\n  ENVOY_STREAM_LOG(debug, \"setting buffer limit to {}\", *this, new_limit);\n  buffer_limit_ = new_limit;\n  if (buffered_request_data_) {\n    buffered_request_data_->setWatermarks(buffer_limit_);\n  }\n  if (buffered_response_data_) {\n    buffered_response_data_->setWatermarks(buffer_limit_);\n  }\n}\n\nvoid FilterManager::contextOnContinue(ScopeTrackedObjectStack& tracked_object_stack) {\n  tracked_object_stack.add(connection_);\n  tracked_object_stack.add(filter_manager_callbacks_.scope());\n}\n\nbool FilterManager::createFilterChain() {\n  if (state_.created_filter_chain_) {\n    return false;\n  }\n  bool upgrade_rejected = false;\n  const HeaderEntry* upgrade = nullptr;\n  if (filter_manager_callbacks_.requestHeaders()) {\n    upgrade = filter_manager_callbacks_.requestHeaders()->Upgrade();\n\n    // Treat CONNECT requests as a special upgrade case.\n    if (!upgrade && HeaderUtility::isConnect(*filter_manager_callbacks_.requestHeaders())) {\n      upgrade = filter_manager_callbacks_.requestHeaders()->Method();\n    }\n  }\n\n  state_.created_filter_chain_ = true;\n  if (upgrade != nullptr) {\n    const Router::RouteEntry::UpgradeMap* upgrade_map = filter_manager_callbacks_.upgradeMap();\n\n    if (filter_chain_factory_.createUpgradeFilterChain(upgrade->value().getStringView(),\n                                                       upgrade_map, *this)) {\n      filter_manager_callbacks_.upgradeFilterChainCreated();\n      return true;\n    } else {\n      upgrade_rejected = true;\n      // Fall through to the default filter chain. The function calling this\n      // will send a local reply indicating that the upgrade failed.\n    }\n  }\n\n  filter_chain_factory_.createFilterChain(*this);\n  return !upgrade_rejected;\n}\n\nvoid ActiveStreamDecoderFilter::requestDataDrained() {\n  // If this is called it means the call to requestDataTooLarge() was a\n  // streaming call, or a 413 would have been sent.\n  onDecoderFilterBelowWriteBufferLowWatermark();\n}\n\nvoid ActiveStreamDecoderFilter::onDecoderFilterBelowWriteBufferLowWatermark() {\n  parent_.filter_manager_callbacks_.onDecoderFilterBelowWriteBufferLowWatermark();\n}\n\nvoid ActiveStreamDecoderFilter::addDownstreamWatermarkCallbacks(\n    DownstreamWatermarkCallbacks& watermark_callbacks) {\n  // This is called exactly once per upstream-stream, by the router filter. Therefore, we\n  // expect the same callbacks to not be registered twice.\n  ASSERT(std::find(parent_.watermark_callbacks_.begin(), parent_.watermark_callbacks_.end(),\n                   &watermark_callbacks) == parent_.watermark_callbacks_.end());\n  parent_.watermark_callbacks_.emplace(parent_.watermark_callbacks_.end(), &watermark_callbacks);\n  for (uint32_t i = 0; i < parent_.high_watermark_count_; ++i) {\n    watermark_callbacks.onAboveWriteBufferHighWatermark();\n  }\n}\n\nvoid ActiveStreamDecoderFilter::removeDownstreamWatermarkCallbacks(\n    DownstreamWatermarkCallbacks& watermark_callbacks) {\n  ASSERT(std::find(parent_.watermark_callbacks_.begin(), parent_.watermark_callbacks_.end(),\n                   &watermark_callbacks) != parent_.watermark_callbacks_.end());\n  parent_.watermark_callbacks_.remove(&watermark_callbacks);\n}\n\nvoid ActiveStreamDecoderFilter::setDecoderBufferLimit(uint32_t limit) {\n  parent_.setBufferLimit(limit);\n}\n\nuint32_t ActiveStreamDecoderFilter::decoderBufferLimit() { return parent_.buffer_limit_; }\n\nbool ActiveStreamDecoderFilter::recreateStream(const ResponseHeaderMap* headers) {\n  // Because the filter's and the HCM view of if the stream has a body and if\n  // the stream is complete may differ, re-check bytesReceived() to make sure\n  // there was no body from the HCM's point of view.\n  if (!complete()) {\n    return false;\n  }\n\n  parent_.stream_info_.setResponseCodeDetails(\n      StreamInfo::ResponseCodeDetails::get().InternalRedirect);\n\n  if (headers != nullptr) {\n    // The call to setResponseHeaders is needed to ensure that the headers are properly logged in\n    // access logs before the stream is destroyed. Since the function expects a ResponseHeaderPtr&&,\n    // ownership of the headers must be passed. This cannot happen earlier in the flow (such as in\n    // the call to setupRedirect) because at that point it is still possible for the headers to be\n    // used in a different logical branch. We work around this by creating a copy and passing\n    // ownership of the copy instead.\n    ResponseHeaderMapPtr headers_copy = createHeaderMap<ResponseHeaderMapImpl>(*headers);\n    parent_.filter_manager_callbacks_.setResponseHeaders(std::move(headers_copy));\n    parent_.filter_manager_callbacks_.chargeStats(*headers);\n  }\n\n  parent_.filter_manager_callbacks_.recreateStream(parent_.stream_info_.filter_state_);\n\n  return true;\n}\n\nvoid ActiveStreamDecoderFilter::addUpstreamSocketOptions(\n    const Network::Socket::OptionsSharedPtr& options) {\n\n  Network::Socket::appendOptions(parent_.upstream_options_, options);\n}\n\nNetwork::Socket::OptionsSharedPtr ActiveStreamDecoderFilter::getUpstreamSocketOptions() const {\n  return parent_.upstream_options_;\n}\n\nvoid ActiveStreamDecoderFilter::requestRouteConfigUpdate(\n    Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) {\n  parent_.filter_manager_callbacks_.requestRouteConfigUpdate(std::move(route_config_updated_cb));\n}\n\nabsl::optional<Router::ConfigConstSharedPtr> ActiveStreamDecoderFilter::routeConfig() {\n  return parent_.filter_manager_callbacks_.routeConfig();\n}\n\nBuffer::InstancePtr ActiveStreamEncoderFilter::createBuffer() {\n  auto buffer = dispatcher().getWatermarkFactory().createBuffer(\n      [this]() -> void { this->responseDataDrained(); },\n      [this]() -> void { this->responseDataTooLarge(); },\n      []() -> void { /* TODO(adisuissa): Handle overflow watermark */ });\n  buffer->setWatermarks(parent_.buffer_limit_);\n  return buffer;\n}\nBuffer::InstancePtr& ActiveStreamEncoderFilter::bufferedData() {\n  return parent_.buffered_response_data_;\n}\nbool ActiveStreamEncoderFilter::complete() { return parent_.state_.local_complete_; }\nbool ActiveStreamEncoderFilter::has1xxHeaders() {\n  return parent_.state_.has_1xx_headers_ && !continued_1xx_headers_;\n}\nvoid ActiveStreamEncoderFilter::do1xxHeaders() {\n  parent_.encode1xxHeaders(this, *parent_.filter_manager_callbacks_.informationalHeaders());\n}\nvoid ActiveStreamEncoderFilter::doHeaders(bool end_stream) {\n  parent_.encodeHeaders(this, *parent_.filter_manager_callbacks_.responseHeaders(), end_stream);\n}\nvoid ActiveStreamEncoderFilter::doData(bool end_stream) {\n  parent_.encodeData(this, *parent_.buffered_response_data_, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\nvoid ActiveStreamEncoderFilter::drainSavedResponseMetadata() {\n  ASSERT(saved_response_metadata_ != nullptr);\n  for (auto& metadata_map : *getSavedResponseMetadata()) {\n    parent_.encodeMetadata(this, std::move(metadata_map));\n  }\n  getSavedResponseMetadata()->clear();\n}\n\nvoid ActiveStreamEncoderFilter::handleMetadataAfterHeadersCallback() {\n  // If we drain accumulated metadata, the iteration must start with the current filter.\n  const bool saved_state = iterate_from_current_filter_;\n  iterate_from_current_filter_ = true;\n  // If encodeHeaders() returns StopAllIteration, we should skip draining metadata, and wait\n  // for doMetadata() to drain the metadata after iteration continues.\n  if (!stoppedAll() && saved_response_metadata_ != nullptr &&\n      !getSavedResponseMetadata()->empty()) {\n    drainSavedResponseMetadata();\n  }\n  // Restores the original value of iterate_from_current_filter_.\n  iterate_from_current_filter_ = saved_state;\n}\nvoid ActiveStreamEncoderFilter::doTrailers() {\n  parent_.encodeTrailers(this, *parent_.filter_manager_callbacks_.responseTrailers());\n}\nbool ActiveStreamEncoderFilter::hasTrailers() {\n  return parent_.filter_manager_callbacks_.responseTrailers().has_value();\n}\nvoid ActiveStreamEncoderFilter::addEncodedData(Buffer::Instance& data, bool streaming) {\n  return parent_.addEncodedData(*this, data, streaming);\n}\n\nvoid ActiveStreamEncoderFilter::injectEncodedDataToFilterChain(Buffer::Instance& data,\n                                                               bool end_stream) {\n  if (!headers_continued_) {\n    headers_continued_ = true;\n    doHeaders(false);\n  }\n  parent_.encodeData(this, data, end_stream,\n                     FilterManager::FilterIterationStartState::CanStartFromCurrent);\n}\n\nResponseTrailerMap& ActiveStreamEncoderFilter::addEncodedTrailers() {\n  return parent_.addEncodedTrailers();\n}\n\nvoid ActiveStreamEncoderFilter::addEncodedMetadata(MetadataMapPtr&& metadata_map_ptr) {\n  return parent_.encodeMetadata(this, std::move(metadata_map_ptr));\n}\n\nvoid ActiveStreamEncoderFilter::onEncoderFilterAboveWriteBufferHighWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Disabling upstream stream due to filter callbacks.\", parent_);\n  parent_.callHighWatermarkCallbacks();\n}\n\nvoid ActiveStreamEncoderFilter::onEncoderFilterBelowWriteBufferLowWatermark() {\n  ENVOY_STREAM_LOG(debug, \"Enabling upstream stream due to filter callbacks.\", parent_);\n  parent_.callLowWatermarkCallbacks();\n}\n\nvoid ActiveStreamEncoderFilter::setEncoderBufferLimit(uint32_t limit) {\n  parent_.setBufferLimit(limit);\n}\n\nuint32_t ActiveStreamEncoderFilter::encoderBufferLimit() { return parent_.buffer_limit_; }\n\nvoid ActiveStreamEncoderFilter::continueEncoding() { commonContinue(); }\n\nconst Buffer::Instance* ActiveStreamEncoderFilter::encodingBuffer() {\n  return parent_.buffered_response_data_.get();\n}\n\nvoid ActiveStreamEncoderFilter::modifyEncodingBuffer(\n    std::function<void(Buffer::Instance&)> callback) {\n  ASSERT(parent_.state_.latest_data_encoding_filter_ == this);\n  callback(*parent_.buffered_response_data_.get());\n}\n\nvoid ActiveStreamEncoderFilter::sendLocalReply(\n    Code code, absl::string_view body,\n    std::function<void(ResponseHeaderMap& headers)> modify_headers,\n    const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details) {\n  parent_.sendLocalReply(code, body, modify_headers, grpc_status, details);\n}\n\nHttp1StreamEncoderOptionsOptRef ActiveStreamEncoderFilter::http1StreamEncoderOptions() {\n  // TODO(mattklein123): At some point we might want to actually wrap this interface but for now\n  // we give the filter direct access to the encoder options.\n  return parent_.filter_manager_callbacks_.http1StreamEncoderOptions();\n}\n\nvoid ActiveStreamEncoderFilter::responseDataTooLarge() {\n  ENVOY_STREAM_LOG(debug, \"response data too large watermark exceeded\", parent_);\n  if (parent_.state_.encoder_filters_streaming_) {\n    onEncoderFilterAboveWriteBufferHighWatermark();\n  } else {\n    parent_.filter_manager_callbacks_.onResponseDataTooLarge();\n\n    // In this case, sendLocalReply will either send a response directly to the encoder, or\n    // reset the stream.\n    parent_.sendLocalReply(\n        Http::Code::InternalServerError, CodeUtility::toString(Http::Code::InternalServerError),\n        nullptr, absl::nullopt, StreamInfo::ResponseCodeDetails::get().ResponsePayloadTooLarge);\n  }\n}\n\nvoid ActiveStreamEncoderFilter::responseDataDrained() {\n  onEncoderFilterBelowWriteBufferLowWatermark();\n}\n\nvoid ActiveStreamFilterBase::resetStream() { parent_.filter_manager_callbacks_.resetStream(); }\n\nuint64_t ActiveStreamFilterBase::streamId() const { return parent_.streamId(); }\n\nBuffer::BufferMemoryAccountSharedPtr ActiveStreamDecoderFilter::account() const {\n  return parent_.account();\n}\n\nvoid ActiveStreamDecoderFilter::setUpstreamOverrideHost(absl::string_view host) {\n  parent_.upstream_override_host_.emplace(std::move(host));\n}\n\nabsl::optional<absl::string_view> ActiveStreamDecoderFilter::upstreamOverrideHost() const {\n  return parent_.upstream_override_host_;\n}\n\n} // namespace Http\n} // namespace Envoy\n", "#pragma once\n\n#include <functional>\n#include <memory>\n\n#include \"envoy/buffer/buffer.h\"\n#include \"envoy/common/optref.h\"\n#include \"envoy/extensions/filters/common/matcher/action/v3/skip_action.pb.h\"\n#include \"envoy/extensions/filters/network/http_connection_manager/v3/http_connection_manager.pb.h\"\n#include \"envoy/extensions/filters/network/http_connection_manager/v3/http_connection_manager.pb.validate.h\"\n#include \"envoy/http/filter.h\"\n#include \"envoy/http/header_map.h\"\n#include \"envoy/matcher/matcher.h\"\n#include \"envoy/network/socket.h\"\n#include \"envoy/protobuf/message_validator.h\"\n#include \"envoy/type/matcher/v3/http_inputs.pb.validate.h\"\n\n#include \"source/common/buffer/watermark_buffer.h\"\n#include \"source/common/common/dump_state_utils.h\"\n#include \"source/common/common/linked_object.h\"\n#include \"source/common/common/logger.h\"\n#include \"source/common/grpc/common.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/http/headers.h\"\n#include \"source/common/http/matching/data_impl.h\"\n#include \"source/common/local_reply/local_reply.h\"\n#include \"source/common/matcher/matcher.h\"\n#include \"source/common/protobuf/utility.h\"\n#include \"source/common/stream_info/stream_info_impl.h\"\n\nnamespace Envoy {\nnamespace Http {\n\nclass FilterManager;\n\nclass SkipAction : public Matcher::ActionBase<\n                       envoy::extensions::filters::common::matcher::action::v3::SkipFilter> {};\n\nstruct ActiveStreamFilterBase;\n\nusing MatchDataUpdateFunc = std::function<void(Matching::HttpMatchingDataImpl&)>;\n/**\n * Manages the shared match state between one or two filters.\n * The need for this class comes from the fact that a single instantiated filter can be wrapped by\n * two different ActiveStreamFilters, one for encoding and one for decoding. Certain match actions\n * should be made visible to both wrappers (e.g. the skip action), while other actions should be\n * sent to the underlying filter exactly once.\n */\nclass FilterMatchState {\npublic:\n  FilterMatchState(Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree,\n                   Matching::HttpMatchingDataImplSharedPtr matching_data)\n      : match_tree_(std::move(match_tree)), matching_data_(std::move(matching_data)),\n        match_tree_evaluated_(false), skip_filter_(false) {}\n\n  void evaluateMatchTreeWithNewData(MatchDataUpdateFunc update_func);\n\n  StreamFilterBase* filter_{};\n\n  bool skipFilter() const { return skip_filter_; }\n\nprivate:\n  Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree_;\n  Matching::HttpMatchingDataImplSharedPtr matching_data_;\n  bool match_tree_evaluated_ : 1;\n  bool skip_filter_ : 1;\n};\n\nusing FilterMatchStateSharedPtr = std::shared_ptr<FilterMatchState>;\n\nclass SkipActionFactory : public Matcher::ActionFactory<Matching::HttpFilterActionContext> {\npublic:\n  std::string name() const override { return \"skip\"; }\n  Matcher::ActionFactoryCb createActionFactoryCb(const Protobuf::Message&,\n                                                 Matching::HttpFilterActionContext&,\n                                                 ProtobufMessage::ValidationVisitor&) override {\n    return []() { return std::make_unique<SkipAction>(); };\n  }\n  ProtobufTypes::MessagePtr createEmptyConfigProto() override {\n    return std::make_unique<envoy::extensions::filters::common::matcher::action::v3::SkipFilter>();\n  }\n};\n\n/**\n * Base class wrapper for both stream encoder and decoder filters.\n *\n * This class is responsible for performing matching and updating match data when a match tree is\n * configured for the associated filter. When not using a match tree, only minimal overhead (i.e.\n * memory overhead of unused fields) should apply.\n */\nstruct ActiveStreamFilterBase : public virtual StreamFilterCallbacks,\n                                Logger::Loggable<Logger::Id::http> {\n  ActiveStreamFilterBase(FilterManager& parent, bool dual_filter,\n                         FilterMatchStateSharedPtr match_state)\n      : parent_(parent), iteration_state_(IterationState::Continue),\n        filter_match_state_(std::move(match_state)), iterate_from_current_filter_(false),\n        headers_continued_(false), continued_1xx_headers_(false), end_stream_(false),\n        dual_filter_(dual_filter), decode_headers_called_(false), encode_headers_called_(false) {}\n\n  // Functions in the following block are called after the filter finishes processing\n  // corresponding data. Those functions handle state updates and data storage (if needed)\n  // according to the status returned by filter's callback functions.\n  bool commonHandleAfter1xxHeadersCallback(FilterHeadersStatus status);\n  bool commonHandleAfterHeadersCallback(FilterHeadersStatus status, bool& end_stream);\n  bool commonHandleAfterDataCallback(FilterDataStatus status, Buffer::Instance& provided_data,\n                                     bool& buffer_was_streaming);\n  bool commonHandleAfterTrailersCallback(FilterTrailersStatus status);\n\n  // Buffers provided_data.\n  void commonHandleBufferData(Buffer::Instance& provided_data);\n\n  // If iteration has stopped for all frame types, calls this function to buffer the data before\n  // the filter processes data. The function also updates streaming state.\n  void commonBufferDataIfStopAll(Buffer::Instance& provided_data, bool& buffer_was_streaming);\n\n  void commonContinue();\n  virtual bool canContinue() PURE;\n  virtual Buffer::InstancePtr createBuffer() PURE;\n  virtual Buffer::InstancePtr& bufferedData() PURE;\n  virtual bool complete() PURE;\n  virtual bool has1xxHeaders() PURE;\n  virtual void do1xxHeaders() PURE;\n  virtual void doHeaders(bool end_stream) PURE;\n  virtual void doData(bool end_stream) PURE;\n  virtual void doTrailers() PURE;\n  virtual bool hasTrailers() PURE;\n  virtual void doMetadata() PURE;\n  // TODO(soya3129): make this pure when adding impl to encoder filter.\n  virtual void handleMetadataAfterHeadersCallback() PURE;\n\n  virtual void onMatchCallback(const Matcher::Action& action) PURE;\n\n  // Http::StreamFilterCallbacks\n  const Network::Connection* connection() override;\n  Event::Dispatcher& dispatcher() override;\n  void resetStream() override;\n  Router::RouteConstSharedPtr route() override;\n  Router::RouteConstSharedPtr route(const Router::RouteCallback& cb) override;\n  void setRoute(Router::RouteConstSharedPtr route) override;\n  Upstream::ClusterInfoConstSharedPtr clusterInfo() override;\n  void clearRouteCache() override;\n  uint64_t streamId() const override;\n  StreamInfo::StreamInfo& streamInfo() override;\n  Tracing::Span& activeSpan() override;\n  Tracing::Config& tracingConfig() override;\n  const ScopeTrackedObject& scope() override;\n  void restoreContextOnContinue(ScopeTrackedObjectStack& tracked_object_stack) override;\n  void resetIdleTimer() override;\n\n  // Functions to set or get iteration state.\n  bool canIterate() { return iteration_state_ == IterationState::Continue; }\n  bool stoppedAll() {\n    return iteration_state_ == IterationState::StopAllBuffer ||\n           iteration_state_ == IterationState::StopAllWatermark;\n  }\n  void allowIteration() {\n    ASSERT(iteration_state_ != IterationState::Continue);\n    iteration_state_ = IterationState::Continue;\n  }\n  MetadataMapVector* getSavedRequestMetadata() {\n    if (saved_request_metadata_ == nullptr) {\n      saved_request_metadata_ = std::make_unique<MetadataMapVector>();\n    }\n    return saved_request_metadata_.get();\n  }\n  MetadataMapVector* getSavedResponseMetadata() {\n    if (saved_response_metadata_ == nullptr) {\n      saved_response_metadata_ = std::make_unique<MetadataMapVector>();\n    }\n    return saved_response_metadata_.get();\n  }\n  bool skipFilter() const { return filter_match_state_ && filter_match_state_->skipFilter(); }\n  void maybeEvaluateMatchTreeWithNewData(MatchDataUpdateFunc update_func) {\n    if (filter_match_state_) {\n      filter_match_state_->evaluateMatchTreeWithNewData(update_func);\n    }\n  }\n\n  // A vector to save metadata when the current filter's [de|en]codeMetadata() can not be called,\n  // either because [de|en]codeHeaders() of the current filter returns StopAllIteration or because\n  // [de|en]codeHeaders() adds new metadata to [de|en]code, but we don't know\n  // [de|en]codeHeaders()'s return value yet. The storage is created on demand.\n  std::unique_ptr<MetadataMapVector> saved_request_metadata_{nullptr};\n  std::unique_ptr<MetadataMapVector> saved_response_metadata_{nullptr};\n  // The state of iteration.\n  enum class IterationState {\n    Continue,            // Iteration has not stopped for any frame type.\n    StopSingleIteration, // Iteration has stopped for headers, 100-continue, or data.\n    StopAllBuffer,       // Iteration has stopped for all frame types, and following data should\n                         // be buffered.\n    StopAllWatermark,    // Iteration has stopped for all frame types, and following data should\n                         // be buffered until high watermark is reached.\n  };\n  FilterManager& parent_;\n  IterationState iteration_state_;\n\n  FilterMatchStateSharedPtr filter_match_state_;\n  // If the filter resumes iteration from a StopAllBuffer/Watermark state, the current filter\n  // hasn't parsed data and trailers. As a result, the filter iteration should start with the\n  // current filter instead of the next one. If true, filter iteration starts with the current\n  // filter. Otherwise, starts with the next filter in the chain.\n  bool iterate_from_current_filter_ : 1;\n  bool headers_continued_ : 1;\n  bool continued_1xx_headers_ : 1;\n  // If true, end_stream is called for this filter.\n  bool end_stream_ : 1;\n  const bool dual_filter_ : 1;\n  bool decode_headers_called_ : 1;\n  bool encode_headers_called_ : 1;\n\n  friend FilterMatchState;\n};\n\n/**\n * Wrapper for a stream decoder filter.\n */\nstruct ActiveStreamDecoderFilter : public ActiveStreamFilterBase,\n                                   public StreamDecoderFilterCallbacks,\n                                   LinkedObject<ActiveStreamDecoderFilter> {\n  ActiveStreamDecoderFilter(FilterManager& parent, StreamDecoderFilterSharedPtr filter,\n                            FilterMatchStateSharedPtr match_state, bool dual_filter)\n      : ActiveStreamFilterBase(parent, dual_filter, std::move(match_state)), handle_(filter) {}\n\n  // ActiveStreamFilterBase\n  bool canContinue() override;\n  Buffer::InstancePtr createBuffer() override;\n  Buffer::InstancePtr& bufferedData() override;\n  bool complete() override;\n  bool has1xxHeaders() override { return false; }\n  void do1xxHeaders() override { IS_ENVOY_BUG(\"unexpected 1xx headers\"); }\n  void doHeaders(bool end_stream) override;\n  void doData(bool end_stream) override;\n  void doMetadata() override {\n    if (saved_request_metadata_ != nullptr) {\n      drainSavedRequestMetadata();\n    }\n  }\n  void doTrailers() override;\n  bool hasTrailers() override;\n\n  void drainSavedRequestMetadata();\n  // This function is called after the filter calls decodeHeaders() to drain accumulated metadata.\n  void handleMetadataAfterHeadersCallback() override;\n  void onMatchCallback(const Matcher::Action& action) override {\n    handle_->onMatchCallback(std::move(action));\n  }\n\n  // Http::StreamDecoderFilterCallbacks\n  void addDecodedData(Buffer::Instance& data, bool streaming) override;\n  void injectDecodedDataToFilterChain(Buffer::Instance& data, bool end_stream) override;\n  RequestTrailerMap& addDecodedTrailers() override;\n  MetadataMapVector& addDecodedMetadata() override;\n  void continueDecoding() override;\n  const Buffer::Instance* decodingBuffer() override;\n\n  void modifyDecodingBuffer(std::function<void(Buffer::Instance&)> callback) override;\n\n  void sendLocalReply(Code code, absl::string_view body,\n                      std::function<void(ResponseHeaderMap& headers)> modify_headers,\n                      const absl::optional<Grpc::Status::GrpcStatus> grpc_status,\n                      absl::string_view details) override;\n  void encode1xxHeaders(ResponseHeaderMapPtr&& headers) override;\n  ResponseHeaderMapOptRef informationalHeaders() const override;\n  void encodeHeaders(ResponseHeaderMapPtr&& headers, bool end_stream,\n                     absl::string_view details) override;\n  ResponseHeaderMapOptRef responseHeaders() const override;\n  void encodeData(Buffer::Instance& data, bool end_stream) override;\n  void encodeTrailers(ResponseTrailerMapPtr&& trailers) override;\n  ResponseTrailerMapOptRef responseTrailers() const override;\n  void encodeMetadata(MetadataMapPtr&& metadata_map_ptr) override;\n  void onDecoderFilterAboveWriteBufferHighWatermark() override;\n  void onDecoderFilterBelowWriteBufferLowWatermark() override;\n  void addDownstreamWatermarkCallbacks(DownstreamWatermarkCallbacks& watermark_callbacks) override;\n  void\n  removeDownstreamWatermarkCallbacks(DownstreamWatermarkCallbacks& watermark_callbacks) override;\n  void setDecoderBufferLimit(uint32_t limit) override;\n  uint32_t decoderBufferLimit() override;\n  bool recreateStream(const Http::ResponseHeaderMap* original_response_headers) override;\n\n  void addUpstreamSocketOptions(const Network::Socket::OptionsSharedPtr& options) override;\n\n  Network::Socket::OptionsSharedPtr getUpstreamSocketOptions() const override;\n  Buffer::BufferMemoryAccountSharedPtr account() const override;\n  void setUpstreamOverrideHost(absl::string_view host) override;\n  absl::optional<absl::string_view> upstreamOverrideHost() const override;\n\n  // Each decoder filter instance checks if the request passed to the filter is gRPC\n  // so that we can issue gRPC local responses to gRPC requests. Filter's decodeHeaders()\n  // called here may change the content type, so we must check it before the call.\n  FilterHeadersStatus decodeHeaders(RequestHeaderMap& headers, bool end_stream) {\n    is_grpc_request_ = Grpc::Common::isGrpcRequestHeaders(headers);\n    FilterHeadersStatus status = handle_->decodeHeaders(headers, end_stream);\n    return status;\n  }\n\n  void requestDataTooLarge();\n  void requestDataDrained();\n\n  void requestRouteConfigUpdate(\n      Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) override;\n  absl::optional<Router::ConfigConstSharedPtr> routeConfig();\n\n  StreamDecoderFilterSharedPtr handle_;\n  bool is_grpc_request_{};\n};\n\nusing ActiveStreamDecoderFilterPtr = std::unique_ptr<ActiveStreamDecoderFilter>;\n\n/**\n * Wrapper for a stream encoder filter.\n */\nstruct ActiveStreamEncoderFilter : public ActiveStreamFilterBase,\n                                   public StreamEncoderFilterCallbacks,\n                                   LinkedObject<ActiveStreamEncoderFilter> {\n  ActiveStreamEncoderFilter(FilterManager& parent, StreamEncoderFilterSharedPtr filter,\n                            FilterMatchStateSharedPtr match_state, bool dual_filter)\n      : ActiveStreamFilterBase(parent, dual_filter, std::move(match_state)), handle_(filter) {}\n\n  // ActiveStreamFilterBase\n  bool canContinue() override;\n  Buffer::InstancePtr createBuffer() override;\n  Buffer::InstancePtr& bufferedData() override;\n  bool complete() override;\n  bool has1xxHeaders() override;\n  void do1xxHeaders() override;\n  void doHeaders(bool end_stream) override;\n  void doData(bool end_stream) override;\n  void drainSavedResponseMetadata();\n  void handleMetadataAfterHeadersCallback() override;\n  void onMatchCallback(const Matcher::Action& action) override { handle_->onMatchCallback(action); }\n\n  void doMetadata() override {\n    if (saved_response_metadata_ != nullptr) {\n      drainSavedResponseMetadata();\n    }\n  }\n  void doTrailers() override;\n  bool hasTrailers() override;\n\n  // Http::StreamEncoderFilterCallbacks\n  void addEncodedData(Buffer::Instance& data, bool streaming) override;\n  void injectEncodedDataToFilterChain(Buffer::Instance& data, bool end_stream) override;\n  ResponseTrailerMap& addEncodedTrailers() override;\n  void addEncodedMetadata(MetadataMapPtr&& metadata_map) override;\n  void onEncoderFilterAboveWriteBufferHighWatermark() override;\n  void onEncoderFilterBelowWriteBufferLowWatermark() override;\n  void setEncoderBufferLimit(uint32_t limit) override;\n  uint32_t encoderBufferLimit() override;\n  void continueEncoding() override;\n  const Buffer::Instance* encodingBuffer() override;\n  void modifyEncodingBuffer(std::function<void(Buffer::Instance&)> callback) override;\n  void sendLocalReply(Code code, absl::string_view body,\n                      std::function<void(ResponseHeaderMap& headers)> modify_headers,\n                      const absl::optional<Grpc::Status::GrpcStatus> grpc_status,\n                      absl::string_view details) override;\n  Http1StreamEncoderOptionsOptRef http1StreamEncoderOptions() override;\n\n  void responseDataTooLarge();\n  void responseDataDrained();\n\n  StreamEncoderFilterSharedPtr handle_;\n};\n\nusing ActiveStreamEncoderFilterPtr = std::unique_ptr<ActiveStreamEncoderFilter>;\n\n/**\n * Callbacks invoked by the FilterManager to pass filter data/events back to the caller.\n */\nclass FilterManagerCallbacks {\npublic:\n  virtual ~FilterManagerCallbacks() = default;\n\n  /**\n   * Called when the provided headers have been encoded by all the filters in the chain.\n   * @param response_headers the encoded headers.\n   * @param end_stream whether this is a header only response.\n   */\n  virtual void encodeHeaders(ResponseHeaderMap& response_headers, bool end_stream) PURE;\n\n  /**\n   * Called when the provided 100 Continue headers have been encoded by all the filters in the\n   * chain.\n   * @param response_headers the encoded headers.\n   */\n  virtual void encode1xxHeaders(ResponseHeaderMap& response_headers) PURE;\n\n  /**\n   * Called when the provided data has been encoded by all filters in the chain.\n   * @param data the encoded data.\n   * @param end_stream whether this is the end of the response.\n   */\n  virtual void encodeData(Buffer::Instance& data, bool end_stream) PURE;\n\n  /**\n   * Called when the provided trailers have been encoded by all filters in the chain.\n   * @param trailers the encoded trailers.\n   */\n  virtual void encodeTrailers(ResponseTrailerMap& trailers) PURE;\n\n  /**\n   * Called when the provided metadata has been encoded by all filters in the chain.\n   * @param trailers the encoded trailers.\n   */\n  virtual void encodeMetadata(MetadataMapVector& metadata) PURE;\n\n  /**\n   * Injects request trailers into a stream that originally did not have request trailers.\n   */\n  virtual void setRequestTrailers(RequestTrailerMapPtr&& request_trailers) PURE;\n\n  /**\n   * Passes ownership of received informational headers to the parent. This may be called multiple\n   * times in the case of multiple upstream calls.\n   */\n  virtual void setInformationalHeaders(ResponseHeaderMapPtr&& response_headers) PURE;\n\n  /**\n   * Passes ownership of received response headers to the parent. This may be called multiple times\n   * in the case of multiple upstream calls.\n   */\n  virtual void setResponseHeaders(ResponseHeaderMapPtr&& response_headers) PURE;\n\n  /**\n   * Passes ownership of received response trailers to the parent. This may be called multiple times\n   * in the case of multiple upstream calls.\n   */\n  virtual void setResponseTrailers(ResponseTrailerMapPtr&& response_trailers) PURE;\n\n  /**\n   * Updates response code stats based on the details in the headers.\n   */\n  virtual void chargeStats(const ResponseHeaderMap& headers) PURE;\n\n  // TODO(snowp): We should consider moving filter access to headers/trailers to happen via the\n  // callbacks instead of via the encode/decode callbacks on the filters.\n\n  /**\n   * The downstream request headers if set.\n   */\n  virtual RequestHeaderMapOptRef requestHeaders() PURE;\n\n  /**\n   * The downstream request trailers if present.\n   */\n  virtual RequestTrailerMapOptRef requestTrailers() PURE;\n\n  /**\n   * Retrieves a pointer to the continue headers set via the call to setInformationalHeaders.\n   */\n  virtual ResponseHeaderMapOptRef informationalHeaders() PURE;\n\n  /**\n   * Retrieves a pointer to the response headers set via the last call to setResponseHeaders.\n   * Note that response headers might be set multiple times (e.g. if a local reply is issued after\n   * headers have been received but before headers have been encoded), so it is not safe in general\n   * to assume that any set of headers will be valid for the duration of a stream.\n   */\n  virtual ResponseHeaderMapOptRef responseHeaders() PURE;\n\n  /**\n   * Retrieves a pointer to the last response trailers set via setResponseTrailers.\n   * Note that response trailers might be set multiple times, so it is not safe in general to assume\n   * that any set of trailers will be valid for the duration of the stream.\n   */\n  virtual ResponseTrailerMapOptRef responseTrailers() PURE;\n\n  /**\n   * Called after encoding has completed.\n   */\n  virtual void endStream() PURE;\n\n  /**\n   * Called when the stream write buffer is no longer above the low watermark.\n   */\n  virtual void onDecoderFilterBelowWriteBufferLowWatermark() PURE;\n\n  /**\n   * Called when the stream write buffer is above above the high watermark.\n   */\n  virtual void onDecoderFilterAboveWriteBufferHighWatermark() PURE;\n\n  /**\n   * Called when the FilterManager creates an Upgrade filter chain.\n   */\n  virtual void upgradeFilterChainCreated() PURE;\n\n  /**\n   * Called when request activity indicates that the request timeout should be disarmed.\n   */\n  virtual void disarmRequestTimeout() PURE;\n\n  /**\n   * Called when stream activity indicates that the stream idle timeout should be reset.\n   */\n  virtual void resetIdleTimer() PURE;\n\n  /**\n   * Called when the stream should be re-created, e.g. for an internal redirect.\n   */\n  virtual void recreateStream(StreamInfo::FilterStateSharedPtr filter_state) PURE;\n\n  /**\n   * Called when the stream should be reset.\n   */\n  virtual void resetStream() PURE;\n\n  /**\n   * Returns the upgrade map for the current route entry.\n   */\n  virtual const Router::RouteEntry::UpgradeMap* upgradeMap() PURE;\n\n  /**\n   * Returns the cluster info for the current route entry.\n   */\n  virtual Upstream::ClusterInfoConstSharedPtr clusterInfo() PURE;\n\n  /**\n   * Returns the current route.\n   */\n  virtual Router::RouteConstSharedPtr route(const Router::RouteCallback& cb) PURE;\n\n  /**\n   * Sets the current route.\n   */\n  virtual void setRoute(Router::RouteConstSharedPtr route) PURE;\n\n  /**\n   * Clears the cached route.\n   */\n  virtual void clearRouteCache() PURE;\n\n  /**\n   * Returns the current route configuration.\n   */\n  virtual absl::optional<Router::ConfigConstSharedPtr> routeConfig() PURE;\n\n  /**\n   * Update the current route configuration.\n   */\n  virtual void\n  requestRouteConfigUpdate(Http::RouteConfigUpdatedCallbackSharedPtr route_config_updated_cb) PURE;\n\n  /**\n   * Returns the current active span.\n   */\n  virtual Tracing::Span& activeSpan() PURE;\n\n  // TODO(snowp): It might make more sense to pass (optional?) counters to the FM instead of\n  // calling back out to the AS to record them.\n  /**\n   * Called when a stream fails due to the response data being too large.\n   */\n  virtual void onResponseDataTooLarge() PURE;\n\n  /**\n   * Called when a stream fails due to the request data being too large.\n   */\n  virtual void onRequestDataTooLarge() PURE;\n\n  /**\n   * Returns the Http1StreamEncoderOptions associated with the response encoder.\n   */\n  virtual Http1StreamEncoderOptionsOptRef http1StreamEncoderOptions() PURE;\n\n  /**\n   * Called when a local reply is made by the filter manager.\n   * @param code the response code of the local reply.\n   */\n  virtual void onLocalReply(Code code) PURE;\n\n  /**\n   * Returns the tracing configuration to use for this stream.\n   */\n  virtual Tracing::Config& tracingConfig() PURE;\n\n  /**\n   * Returns the tracked scope to use for this stream.\n   */\n  virtual const ScopeTrackedObject& scope() PURE;\n};\n\n/**\n * This class allows the remote address to be overridden for HTTP stream info. This is used for\n * XFF handling. This is required to avoid providing stream info with a non-const connection info\n * provider. Private inheritance from ConnectionInfoProvider is used to make sure users get the\n * address provider via the normal getter.\n */\nclass OverridableRemoteConnectionInfoSetterStreamInfo : public StreamInfo::StreamInfoImpl,\n                                                        private Network::ConnectionInfoProvider {\npublic:\n  using StreamInfoImpl::StreamInfoImpl;\n\n  void setDownstreamRemoteAddress(\n      const Network::Address::InstanceConstSharedPtr& downstream_remote_address) {\n    // TODO(rgs1): we should assert overridden_downstream_remote_address_ is nullptr,\n    // but we are currently relaxing this as a workaround to:\n    //\n    // https://github.com/envoyproxy/envoy/pull/14432#issuecomment-758167614\n    overridden_downstream_remote_address_ = downstream_remote_address;\n  }\n\n  // StreamInfo::StreamInfo\n  const Network::ConnectionInfoProvider& downstreamAddressProvider() const override {\n    return *this;\n  }\n\n  // Network::ConnectionInfoProvider\n  const Network::Address::InstanceConstSharedPtr& localAddress() const override {\n    return StreamInfoImpl::downstreamAddressProvider().localAddress();\n  }\n  bool localAddressRestored() const override {\n    return StreamInfoImpl::downstreamAddressProvider().localAddressRestored();\n  }\n  const Network::Address::InstanceConstSharedPtr& remoteAddress() const override {\n    return overridden_downstream_remote_address_ != nullptr\n               ? overridden_downstream_remote_address_\n               : StreamInfoImpl::downstreamAddressProvider().remoteAddress();\n  }\n  const Network::Address::InstanceConstSharedPtr& directRemoteAddress() const override {\n    return StreamInfoImpl::downstreamAddressProvider().directRemoteAddress();\n  }\n  absl::string_view requestedServerName() const override {\n    return StreamInfoImpl::downstreamAddressProvider().requestedServerName();\n  }\n  absl::optional<uint64_t> connectionID() const override {\n    return StreamInfoImpl::downstreamAddressProvider().connectionID();\n  }\n  absl::optional<absl::string_view> interfaceName() const override {\n    return StreamInfoImpl::downstreamAddressProvider().interfaceName();\n  }\n  Ssl::ConnectionInfoConstSharedPtr sslConnection() const override {\n    return StreamInfoImpl::downstreamAddressProvider().sslConnection();\n  }\n  void dumpState(std::ostream& os, int indent_level) const override {\n    StreamInfoImpl::dumpState(os, indent_level);\n\n    const char* spaces = spacesForLevel(indent_level);\n    os << spaces << \"OverridableRemoteConnectionInfoSetterStreamInfo \" << this\n       << DUMP_MEMBER_AS(remoteAddress(), remoteAddress()->asStringView())\n       << DUMP_MEMBER_AS(directRemoteAddress(), directRemoteAddress()->asStringView())\n       << DUMP_MEMBER_AS(localAddress(), localAddress()->asStringView()) << \"\\n\";\n  }\n  absl::string_view ja3Hash() const override {\n    return StreamInfoImpl::downstreamAddressProvider().ja3Hash();\n  }\n\nprivate:\n  Network::Address::InstanceConstSharedPtr overridden_downstream_remote_address_;\n};\n\n/**\n * FilterManager manages decoding a request through a series of decoding filter and the encoding\n * of the resulting response.\n */\nclass FilterManager : public ScopeTrackedObject,\n                      FilterChainFactoryCallbacks,\n                      Logger::Loggable<Logger::Id::http> {\npublic:\n  FilterManager(FilterManagerCallbacks& filter_manager_callbacks, Event::Dispatcher& dispatcher,\n                const Network::Connection& connection, uint64_t stream_id,\n                Buffer::BufferMemoryAccountSharedPtr account, bool proxy_100_continue,\n                uint32_t buffer_limit, FilterChainFactory& filter_chain_factory,\n                const LocalReply::LocalReply& local_reply, Http::Protocol protocol,\n                TimeSource& time_source, StreamInfo::FilterStateSharedPtr parent_filter_state,\n                StreamInfo::FilterState::LifeSpan filter_state_life_span)\n      : filter_manager_callbacks_(filter_manager_callbacks), dispatcher_(dispatcher),\n        connection_(connection), stream_id_(stream_id), account_(std::move(account)),\n        proxy_100_continue_(proxy_100_continue), buffer_limit_(buffer_limit),\n        filter_chain_factory_(filter_chain_factory), local_reply_(local_reply),\n        stream_info_(protocol, time_source, connection.connectionInfoProviderSharedPtr(),\n                     parent_filter_state, filter_state_life_span) {}\n  ~FilterManager() override {\n    ASSERT(state_.destroyed_);\n    ASSERT(state_.filter_call_state_ == 0);\n  }\n\n  // ScopeTrackedObject\n  void dumpState(std::ostream& os, int indent_level = 0) const override {\n    const char* spaces = spacesForLevel(indent_level);\n    os << spaces << \"FilterManager \" << this << DUMP_MEMBER(state_.has_1xx_headers_) << \"\\n\";\n\n    DUMP_DETAILS(filter_manager_callbacks_.requestHeaders());\n    DUMP_DETAILS(filter_manager_callbacks_.requestTrailers());\n    DUMP_DETAILS(filter_manager_callbacks_.responseHeaders());\n    DUMP_DETAILS(filter_manager_callbacks_.responseTrailers());\n    DUMP_DETAILS(&stream_info_);\n  }\n\n  // Http::FilterChainFactoryCallbacks\n  Event::Dispatcher& dispatcher() override { return dispatcher_; }\n  void addStreamDecoderFilter(StreamDecoderFilterSharedPtr filter) override {\n    addStreamDecoderFilterWorker(filter, nullptr, false);\n    filters_.push_back(filter.get());\n  }\n  void addStreamDecoderFilter(StreamDecoderFilterSharedPtr filter,\n                              Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree) override {\n    if (match_tree) {\n      addStreamDecoderFilterWorker(\n          filter,\n          std::make_shared<FilterMatchState>(std::move(match_tree),\n                                             std::make_shared<Matching::HttpMatchingDataImpl>()),\n          false);\n      return;\n    }\n\n    addStreamDecoderFilterWorker(filter, nullptr, false);\n  }\n  void addStreamEncoderFilter(StreamEncoderFilterSharedPtr filter) override {\n    addStreamEncoderFilterWorker(filter, nullptr, false);\n    filters_.push_back(filter.get());\n  }\n  void addStreamEncoderFilter(StreamEncoderFilterSharedPtr filter,\n                              Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree) override {\n    if (match_tree) {\n      addStreamEncoderFilterWorker(\n          filter,\n          std::make_shared<FilterMatchState>(std::move(match_tree),\n                                             std::make_shared<Matching::HttpMatchingDataImpl>()),\n          false);\n      return;\n    }\n\n    addStreamEncoderFilterWorker(filter, nullptr, false);\n  }\n  void addStreamFilter(StreamFilterSharedPtr filter) override {\n    addStreamDecoderFilterWorker(filter, nullptr, true);\n    addStreamEncoderFilterWorker(filter, nullptr, true);\n    StreamDecoderFilter* decoder_filter = filter.get();\n    filters_.push_back(decoder_filter);\n  }\n  void addStreamFilter(StreamFilterSharedPtr filter,\n                       Matcher::MatchTreeSharedPtr<HttpMatchingData> match_tree) override {\n    // Note that we share the match data and tree between the two filters to allow things like\n    // matching on both request and response data.\n    // TODO(snowp): The match tree might be fully evaluated twice, ideally we should expose\n    // the result to both filters after the first match evaluation.\n    if (match_tree) {\n      auto matching_state = std::make_shared<FilterMatchState>(\n          std::move(match_tree), std::make_shared<Matching::HttpMatchingDataImpl>());\n      addStreamDecoderFilterWorker(filter, matching_state, true);\n      addStreamEncoderFilterWorker(filter, std::move(matching_state), true);\n      return;\n    }\n\n    addStreamDecoderFilterWorker(filter, nullptr, true);\n    addStreamEncoderFilterWorker(filter, nullptr, true);\n  }\n  void addAccessLogHandler(AccessLog::InstanceSharedPtr handler) override;\n\n  void log() {\n    RequestHeaderMap* request_headers = nullptr;\n    if (filter_manager_callbacks_.requestHeaders()) {\n      request_headers = filter_manager_callbacks_.requestHeaders().ptr();\n    }\n    ResponseHeaderMap* response_headers = nullptr;\n    if (filter_manager_callbacks_.responseHeaders()) {\n      response_headers = filter_manager_callbacks_.responseHeaders().ptr();\n    }\n    ResponseTrailerMap* response_trailers = nullptr;\n    if (filter_manager_callbacks_.responseTrailers()) {\n      response_trailers = filter_manager_callbacks_.responseTrailers().ptr();\n    }\n\n    for (const auto& log_handler : access_log_handlers_) {\n      log_handler->log(request_headers, response_headers, response_trailers, stream_info_);\n    }\n  }\n\n  void onStreamComplete() {\n    for (auto& filter : decoder_filters_) {\n      filter->handle_->onStreamComplete();\n    }\n\n    for (auto& filter : encoder_filters_) {\n      // Do not call onStreamComplete twice for dual registered filters.\n      if (!filter->dual_filter_) {\n        filter->handle_->onStreamComplete();\n      }\n    }\n  }\n\n  void destroyFilters() {\n    state_.destroyed_ = true;\n\n    for (auto& filter : decoder_filters_) {\n      filter->handle_->onDestroy();\n    }\n\n    for (auto& filter : encoder_filters_) {\n      // Do not call on destroy twice for dual registered filters.\n      if (!filter->dual_filter_) {\n        filter->handle_->onDestroy();\n      }\n    }\n  }\n\n  /**\n   * Decodes the provided headers starting at the first filter in the chain.\n   * @param headers the headers to decode.\n   * @param end_stream whether the request is header only.\n   */\n  void decodeHeaders(RequestHeaderMap& headers, bool end_stream) {\n    decodeHeaders(nullptr, headers, end_stream);\n  }\n\n  /**\n   * Decodes the provided data starting at the first filter in the chain.\n   * @param data the data to decode.\n   * @param end_stream whether this data is the end of the request.\n   */\n  void decodeData(Buffer::Instance& data, bool end_stream) {\n    decodeData(nullptr, data, end_stream, FilterIterationStartState::CanStartFromCurrent);\n  }\n\n  /**\n   * Decodes the provided trailers starting at the first filter in the chain.\n   * @param trailers the trailers to decode.\n   */\n  void decodeTrailers(RequestTrailerMap& trailers) { decodeTrailers(nullptr, trailers); }\n\n  /**\n   * Decodes the provided metadata starting at the first filter in the chain.\n   * @param metadata_map the metadata to decode.\n   */\n  void decodeMetadata(MetadataMap& metadata_map) { decodeMetadata(nullptr, metadata_map); }\n\n  // TODO(snowp): Make private as filter chain construction is moved into FM.\n  void addStreamDecoderFilterWorker(StreamDecoderFilterSharedPtr filter,\n                                    FilterMatchStateSharedPtr match_state, bool dual_filter);\n  void addStreamEncoderFilterWorker(StreamEncoderFilterSharedPtr filter,\n                                    FilterMatchStateSharedPtr match_state, bool dual_filter);\n\n  void disarmRequestTimeout();\n\n  /**\n   * If end_stream is true, marks decoding as complete. This is a noop if end_stream is false.\n   * @param end_stream whether decoding is complete.\n   */\n  void maybeEndDecode(bool end_stream);\n\n  /**\n   * If end_stream is true, marks encoding as complete. This is a noop if end_stream is false.\n   * @param end_stream whether encoding is complete.\n   */\n  void maybeEndEncode(bool end_stream);\n\n  /**\n   * Called before local reply is made by the filter manager.\n   * @param data the data associated with the local reply.\n   */\n  void onLocalReply(StreamFilterBase::LocalReplyData& data);\n\n  void sendLocalReply(Code code, absl::string_view body,\n                      const std::function<void(ResponseHeaderMap& headers)>& modify_headers,\n                      const absl::optional<Grpc::Status::GrpcStatus> grpc_status,\n                      absl::string_view details);\n  /**\n   * Sends a local reply by constructing a response and passing it through all the encoder\n   * filters. The resulting response will be passed out via the FilterManagerCallbacks.\n   */\n  void sendLocalReplyViaFilterChain(\n      bool is_grpc_request, Code code, absl::string_view body,\n      const std::function<void(ResponseHeaderMap& headers)>& modify_headers, bool is_head_request,\n      const absl::optional<Grpc::Status::GrpcStatus> grpc_status, absl::string_view details);\n\n  /**\n   * Sends a local reply by constructing a response and skipping the encoder filters. The\n   * resulting response will be passed out via the FilterManagerCallbacks.\n   */\n  void sendDirectLocalReply(Code code, absl::string_view body,\n                            const std::function<void(ResponseHeaderMap& headers)>& modify_headers,\n                            bool is_head_request,\n                            const absl::optional<Grpc::Status::GrpcStatus> grpc_status);\n\n  // Possibly increases buffer_limit_ to the value of limit.\n  void setBufferLimit(uint32_t limit);\n\n  /**\n   * @return bool whether any above high watermark triggers are currently active\n   */\n  bool aboveHighWatermark() { return high_watermark_count_ != 0; }\n\n  // Pass on watermark callbacks to watermark subscribers. This boils down to passing watermark\n  // events for this stream and the downstream connection to the router filter.\n  void callHighWatermarkCallbacks();\n  void callLowWatermarkCallbacks();\n\n  void requestHeadersInitialized() {\n    if (Http::Headers::get().MethodValues.Head ==\n        filter_manager_callbacks_.requestHeaders()->getMethodValue()) {\n      state_.is_head_request_ = true;\n    }\n    state_.is_grpc_request_ =\n        Grpc::Common::isGrpcRequestHeaders(filter_manager_callbacks_.requestHeaders().ref());\n  }\n\n  /**\n   * Marks local processing as complete.\n   */\n  void setLocalComplete() { state_.local_complete_ = true; }\n\n  /**\n   * Whether the filters have been destroyed.\n   */\n  bool destroyed() const { return state_.destroyed_; }\n\n  /**\n   * Whether remote processing has been marked as complete.\n   */\n  bool remoteDecodeComplete() const {\n    return stream_info_.downstreamTiming() &&\n           stream_info_.downstreamTiming()->lastDownstreamRxByteReceived().has_value();\n  }\n\n  /**\n   * Instructs the FilterManager to not create a filter chain. This makes it possible to issue\n   * a local reply without the overhead of creating and traversing the filters.\n   */\n  void skipFilterChainCreation() {\n    ASSERT(!state_.created_filter_chain_);\n    state_.created_filter_chain_ = true;\n  }\n\n  // TODO(snowp): This should probably return a StreamInfo instead of the impl.\n  StreamInfo::StreamInfoImpl& streamInfo() { return stream_info_; }\n  const StreamInfo::StreamInfoImpl& streamInfo() const { return stream_info_; }\n  void setDownstreamRemoteAddress(\n      const Network::Address::InstanceConstSharedPtr& downstream_remote_address) {\n    stream_info_.setDownstreamRemoteAddress(downstream_remote_address);\n  }\n\n  // Set up the Encoder/Decoder filter chain.\n  bool createFilterChain();\n\n  const Network::Connection* connection() const { return &connection_; }\n\n  uint64_t streamId() const { return stream_id_; }\n  Buffer::BufferMemoryAccountSharedPtr account() const { return account_; }\n\n  Buffer::InstancePtr& bufferedRequestData() { return buffered_request_data_; }\n\n  void contextOnContinue(ScopeTrackedObjectStack& tracked_object_stack);\n\n  void onDownstreamReset() { state_.saw_downstream_reset_ = true; }\n\nprivate:\n  // Indicates which filter to start the iteration with.\n  enum class FilterIterationStartState { AlwaysStartFromNext, CanStartFromCurrent };\n\n  // Returns the encoder filter to start iteration with.\n  std::list<ActiveStreamEncoderFilterPtr>::iterator\n  commonEncodePrefix(ActiveStreamEncoderFilter* filter, bool end_stream,\n                     FilterIterationStartState filter_iteration_start_state);\n  // Returns the decoder filter to start iteration with.\n  std::list<ActiveStreamDecoderFilterPtr>::iterator\n  commonDecodePrefix(ActiveStreamDecoderFilter* filter,\n                     FilterIterationStartState filter_iteration_start_state);\n  void addDecodedData(ActiveStreamDecoderFilter& filter, Buffer::Instance& data, bool streaming);\n  RequestTrailerMap& addDecodedTrailers();\n  MetadataMapVector& addDecodedMetadata();\n  // Helper function for the case where we have a header only request, but a filter adds a body\n  // to it.\n  void maybeContinueDecoding(\n      const std::list<ActiveStreamDecoderFilterPtr>::iterator& maybe_continue_data_entry);\n  void decodeHeaders(ActiveStreamDecoderFilter* filter, RequestHeaderMap& headers, bool end_stream);\n  // Sends data through decoding filter chains. filter_iteration_start_state indicates which\n  // filter to start the iteration with.\n  void decodeData(ActiveStreamDecoderFilter* filter, Buffer::Instance& data, bool end_stream,\n                  FilterIterationStartState filter_iteration_start_state);\n  void decodeTrailers(ActiveStreamDecoderFilter* filter, RequestTrailerMap& trailers);\n  void decodeMetadata(ActiveStreamDecoderFilter* filter, MetadataMap& metadata_map);\n  void addEncodedData(ActiveStreamEncoderFilter& filter, Buffer::Instance& data, bool streaming);\n  ResponseTrailerMap& addEncodedTrailers();\n  void encode1xxHeaders(ActiveStreamEncoderFilter* filter, ResponseHeaderMap& headers);\n  // As with most of the encode functions, this runs encodeHeaders on various\n  // filters before calling encodeHeadersInternal which does final header munging and passes the\n  // headers to the encoder.\n  void maybeContinueEncoding(\n      const std::list<ActiveStreamEncoderFilterPtr>::iterator& maybe_continue_data_entry);\n  void encodeHeaders(ActiveStreamEncoderFilter* filter, ResponseHeaderMap& headers,\n                     bool end_stream);\n  // Sends data through encoding filter chains. filter_iteration_start_state indicates which\n  // filter to start the iteration with, and finally calls encodeDataInternal\n  // to update stats, do end stream bookkeeping, and send the data to encoder.\n  void encodeData(ActiveStreamEncoderFilter* filter, Buffer::Instance& data, bool end_stream,\n                  FilterIterationStartState filter_iteration_start_state);\n  void encodeTrailers(ActiveStreamEncoderFilter* filter, ResponseTrailerMap& trailers);\n  void encodeMetadata(ActiveStreamEncoderFilter* filter, MetadataMapPtr&& metadata_map_ptr);\n\n  // Returns true if new metadata is decoded. Otherwise, returns false.\n  bool processNewlyAddedMetadata();\n\n  // Returns true if filter has stopped iteration for all frame types. Otherwise, returns false.\n  // filter_streaming is the variable to indicate if stream is streaming, and its value may be\n  // changed by the function.\n  bool handleDataIfStopAll(ActiveStreamFilterBase& filter, Buffer::Instance& data,\n                           bool& filter_streaming);\n\n  MetadataMapVector* getRequestMetadataMapVector() {\n    if (request_metadata_map_vector_ == nullptr) {\n      request_metadata_map_vector_ = std::make_unique<MetadataMapVector>();\n    }\n    return request_metadata_map_vector_.get();\n  }\n\n  FilterManagerCallbacks& filter_manager_callbacks_;\n  Event::Dispatcher& dispatcher_;\n  const Network::Connection& connection_;\n  const uint64_t stream_id_;\n  Buffer::BufferMemoryAccountSharedPtr account_;\n  const bool proxy_100_continue_;\n\n  std::list<ActiveStreamDecoderFilterPtr> decoder_filters_;\n  std::list<ActiveStreamEncoderFilterPtr> encoder_filters_;\n  std::list<StreamFilterBase*> filters_;\n  std::list<AccessLog::InstanceSharedPtr> access_log_handlers_;\n\n  // Stores metadata added in the decoding filter that is being processed. Will be cleared before\n  // processing the next filter. The storage is created on demand. We need to store metadata\n  // temporarily in the filter in case the filter has stopped all while processing headers.\n  std::unique_ptr<MetadataMapVector> request_metadata_map_vector_;\n  Buffer::InstancePtr buffered_response_data_;\n  Buffer::InstancePtr buffered_request_data_;\n  uint32_t buffer_limit_{0};\n  uint32_t high_watermark_count_{0};\n  std::list<DownstreamWatermarkCallbacks*> watermark_callbacks_;\n  Network::Socket::OptionsSharedPtr upstream_options_ =\n      std::make_shared<Network::Socket::Options>();\n  absl::optional<absl::string_view> upstream_override_host_;\n\n  FilterChainFactory& filter_chain_factory_;\n  const LocalReply::LocalReply& local_reply_;\n  OverridableRemoteConnectionInfoSetterStreamInfo stream_info_;\n  // TODO(snowp): Once FM has been moved to its own file we'll make these private classes of FM,\n  // at which point they no longer need to be friends.\n  friend ActiveStreamFilterBase;\n  friend ActiveStreamDecoderFilter;\n  friend ActiveStreamEncoderFilter;\n\n  /**\n   * Flags that keep track of which filter calls are currently in progress.\n   */\n  // clang-format off\n    struct FilterCallState {\n      static constexpr uint32_t DecodeHeaders   = 0x01;\n      static constexpr uint32_t DecodeData      = 0x02;\n      static constexpr uint32_t DecodeTrailers  = 0x04;\n      static constexpr uint32_t EncodeHeaders   = 0x08;\n      static constexpr uint32_t EncodeData      = 0x10;\n      static constexpr uint32_t EncodeTrailers  = 0x20;\n      // Encode1xxHeaders is a bit of a special state as 1xx\n      // headers may be sent during request processing. This state is only used\n      // to verify we do not encode1xx headers more than once per\n      // filter.\n      static constexpr uint32_t Encode1xxHeaders  = 0x40;\n      // Used to indicate that we're processing the final [En|De]codeData frame,\n      // i.e. end_stream = true\n      static constexpr uint32_t LastDataFrame = 0x80;\n    };\n  // clang-format on\n\n  struct State {\n    State()\n        : remote_encode_complete_(false), local_complete_(false), has_1xx_headers_(false),\n          created_filter_chain_(false), is_head_request_(false), is_grpc_request_(false),\n          non_100_response_headers_encoded_(false), under_on_local_reply_(false),\n          decoder_filter_chain_aborted_(false), encoder_filter_chain_aborted_(false),\n          saw_downstream_reset_(false) {}\n    uint32_t filter_call_state_{0};\n\n    bool remote_encode_complete_ : 1;\n    bool local_complete_ : 1; // This indicates that local is complete prior to filter processing.\n                              // A filter can still stop the stream from being complete as seen\n                              // by the codec.\n    // By default, we will assume there are no 1xx. If encode1xxHeaders\n    // is ever called, this is set to true so commonContinue resumes processing the 1xx.\n    bool has_1xx_headers_ : 1;\n    bool created_filter_chain_ : 1;\n    // These two are latched on initial header read, to determine if the original headers\n    // constituted a HEAD or gRPC request, respectively.\n    bool is_head_request_ : 1;\n    bool is_grpc_request_ : 1;\n    // Tracks if headers other than 100-Continue have been encoded to the codec.\n    bool non_100_response_headers_encoded_ : 1;\n    // True under the stack of onLocalReply, false otherwise.\n    bool under_on_local_reply_ : 1;\n    // True when the filter chain iteration was aborted with local reply.\n    bool decoder_filter_chain_aborted_ : 1;\n    bool encoder_filter_chain_aborted_ : 1;\n    bool saw_downstream_reset_ : 1;\n\n    // The following 3 members are booleans rather than part of the space-saving bitfield as they\n    // are passed as arguments to functions expecting bools. Extend State using the bitfield\n    // where possible.\n    bool encoder_filters_streaming_{true};\n    bool decoder_filters_streaming_{true};\n    bool destroyed_{false};\n\n    // Used to track which filter is the latest filter that has received data.\n    ActiveStreamEncoderFilter* latest_data_encoding_filter_{};\n    ActiveStreamDecoderFilter* latest_data_decoding_filter_{};\n  };\n\n  State state_;\n};\n\n} // namespace Http\n} // namespace Envoy\n", "#include \"source/common/http/http1/codec_impl.h\"\n\n#include <memory>\n#include <string>\n\n#include \"envoy/buffer/buffer.h\"\n#include \"envoy/common/optref.h\"\n#include \"envoy/http/codec.h\"\n#include \"envoy/http/header_map.h\"\n#include \"envoy/network/connection.h\"\n\n#include \"source/common/common/cleanup.h\"\n#include \"source/common/common/dump_state_utils.h\"\n#include \"source/common/common/enum_to_int.h\"\n#include \"source/common/common/scope_tracker.h\"\n#include \"source/common/common/statusor.h\"\n#include \"source/common/common/utility.h\"\n#include \"source/common/grpc/common.h\"\n#include \"source/common/http/exception.h\"\n#include \"source/common/http/header_utility.h\"\n#include \"source/common/http/headers.h\"\n#include \"source/common/http/http1/header_formatter.h\"\n#include \"source/common/http/http1/legacy_parser_impl.h\"\n#include \"source/common/http/utility.h\"\n#include \"source/common/runtime/runtime_features.h\"\n\n#include \"absl/container/fixed_array.h\"\n#include \"absl/strings/ascii.h\"\n\nnamespace Envoy {\nnamespace Http {\nnamespace Http1 {\nnamespace {\n\n// Changes or additions to details should be reflected in\n// docs/root/configuration/http/http_conn_man/response_code_details.rst\nstruct Http1ResponseCodeDetailValues {\n  const absl::string_view TooManyHeaders = \"http1.too_many_headers\";\n  const absl::string_view HeadersTooLarge = \"http1.headers_too_large\";\n  const absl::string_view HttpCodecError = \"http1.codec_error\";\n  const absl::string_view InvalidCharacters = \"http1.invalid_characters\";\n  const absl::string_view ConnectionHeaderSanitization = \"http1.connection_header_rejected\";\n  const absl::string_view InvalidUrl = \"http1.invalid_url\";\n  const absl::string_view InvalidTransferEncoding = \"http1.invalid_transfer_encoding\";\n  const absl::string_view BodyDisallowed = \"http1.body_disallowed\";\n  const absl::string_view TransferEncodingNotAllowed = \"http1.transfer_encoding_not_allowed\";\n  const absl::string_view ContentLengthNotAllowed = \"http1.content_length_not_allowed\";\n  const absl::string_view InvalidUnderscore = \"http1.unexpected_underscore\";\n  const absl::string_view ChunkedContentLength = \"http1.content_length_and_chunked_not_allowed\";\n  const absl::string_view HttpsInPlaintext = \"http1.https_url_on_plaintext_connection\";\n  const absl::string_view InvalidScheme = \"http1.invalid_scheme\";\n};\n\nstruct Http1HeaderTypesValues {\n  const absl::string_view Headers = \"headers\";\n  const absl::string_view Trailers = \"trailers\";\n};\n\n// Pipelining is generally not well supported on the internet and has a series of dangerous\n// overflow bugs. As such Envoy disabled it.\nstatic constexpr uint32_t kMaxOutboundResponses = 2;\n\nusing Http1ResponseCodeDetails = ConstSingleton<Http1ResponseCodeDetailValues>;\nusing Http1HeaderTypes = ConstSingleton<Http1HeaderTypesValues>;\n\nconst StringUtil::CaseUnorderedSet& caseUnorderdSetContainingUpgradeAndHttp2Settings() {\n  CONSTRUCT_ON_FIRST_USE(StringUtil::CaseUnorderedSet,\n                         Http::Headers::get().ConnectionValues.Upgrade,\n                         Http::Headers::get().ConnectionValues.Http2Settings);\n}\n\nHeaderKeyFormatterConstPtr encodeOnlyFormatterFromSettings(const Http::Http1Settings& settings) {\n  if (settings.header_key_format_ == Http1Settings::HeaderKeyFormat::ProperCase) {\n    return std::make_unique<ProperCaseHeaderKeyFormatter>();\n  }\n\n  return nullptr;\n}\n\nStatefulHeaderKeyFormatterPtr statefulFormatterFromSettings(const Http::Http1Settings& settings) {\n  if (settings.header_key_format_ == Http1Settings::HeaderKeyFormat::StatefulFormatter) {\n    return settings.stateful_header_key_formatter_->create();\n  }\n  return nullptr;\n}\n\nconstexpr size_t CRLF_SIZE = 2;\n\n} // namespace\n\nstatic constexpr absl::string_view CRLF = \"\\r\\n\";\n// Last chunk as defined here https://tools.ietf.org/html/rfc7230#section-4.1\nstatic constexpr absl::string_view LAST_CHUNK = \"0\\r\\n\";\n\nstatic constexpr absl::string_view SPACE = \" \";\nstatic constexpr absl::string_view COLON_SPACE = \": \";\n\nStreamEncoderImpl::StreamEncoderImpl(ConnectionImpl& connection,\n                                     StreamInfo::BytesMeterSharedPtr&& bytes_meter)\n    : connection_(connection), disable_chunk_encoding_(false), chunk_encoding_(true),\n      connect_request_(false), is_tcp_tunneling_(false), is_response_to_head_request_(false),\n      is_response_to_connect_request_(false), bytes_meter_(std::move(bytes_meter)) {\n  if (!bytes_meter_) {\n    bytes_meter_ = std::make_shared<StreamInfo::BytesMeter>();\n  }\n  if (connection_.connection().aboveHighWatermark()) {\n    runHighWatermarkCallbacks();\n  }\n}\n\nvoid StreamEncoderImpl::encodeHeader(absl::string_view key, absl::string_view value) {\n  ASSERT(!key.empty());\n\n  const uint64_t header_size = connection_.buffer().addFragments({key, COLON_SPACE, value, CRLF});\n\n  bytes_meter_->addHeaderBytesSent(header_size);\n}\n\nvoid StreamEncoderImpl::encodeFormattedHeader(absl::string_view key, absl::string_view value,\n                                              HeaderKeyFormatterOptConstRef formatter) {\n  if (formatter.has_value()) {\n    encodeHeader(formatter->format(key), value);\n  } else {\n    encodeHeader(key, value);\n  }\n}\n\nvoid ResponseEncoderImpl::encode1xxHeaders(const ResponseHeaderMap& headers) {\n  ASSERT(HeaderUtility::isSpecial1xx(headers));\n  encodeHeaders(headers, false);\n}\n\nvoid StreamEncoderImpl::encodeHeadersBase(const RequestOrResponseHeaderMap& headers,\n                                          absl::optional<uint64_t> status, bool end_stream,\n                                          bool bodiless_request) {\n  HeaderKeyFormatterOptConstRef formatter(headers.formatter());\n  if (!formatter.has_value()) {\n    formatter = connection_.formatter();\n  }\n\n  const Http::HeaderValues& header_values = Http::Headers::get();\n  bool saw_content_length = false;\n  headers.iterate(\n      [this, &header_values, formatter](const HeaderEntry& header) -> HeaderMap::Iterate {\n        absl::string_view key_to_use = header.key().getStringView();\n        uint32_t key_size_to_use = header.key().size();\n        // Translate :authority -> host so that upper layers do not need to deal with this.\n        if (key_size_to_use > 1 && key_to_use[0] == ':' && key_to_use[1] == 'a') {\n          key_to_use = absl::string_view(header_values.HostLegacy.get());\n          key_size_to_use = header_values.HostLegacy.get().size();\n        }\n\n        // Skip all headers starting with ':' that make it here.\n        if (key_to_use[0] == ':') {\n          return HeaderMap::Iterate::Continue;\n        }\n\n        encodeFormattedHeader(key_to_use, header.value().getStringView(), formatter);\n\n        return HeaderMap::Iterate::Continue;\n      });\n\n  if (headers.ContentLength()) {\n    saw_content_length = true;\n  }\n\n  ASSERT(!headers.TransferEncoding());\n\n  // Assume we are chunk encoding unless we are passed a content length or this is a header only\n  // response. Upper layers generally should strip transfer-encoding since it only applies to\n  // HTTP/1.1. The codec will infer it based on the type of response.\n  // for streaming (e.g. SSE stream sent to hystrix dashboard), we do not want\n  // chunk transfer encoding but we don't have a content-length so disable_chunk_encoding_ is\n  // consulted before enabling chunk encoding.\n  //\n  // Note that for HEAD requests Envoy does best-effort guessing when there is no\n  // content-length. If a client makes a HEAD request for an upstream resource\n  // with no bytes but the upstream response doesn't include \"Content-length: 0\",\n  // Envoy will incorrectly assume a subsequent response to GET will be chunk encoded.\n  if (saw_content_length || disable_chunk_encoding_) {\n    chunk_encoding_ = false;\n  } else {\n    if (status && (*status < 200 || *status == 204)) {\n      // For 1xx and 204 responses, do not send the chunked encoding header or enable chunked\n      // encoding: https://tools.ietf.org/html/rfc7230#section-3.3.1\n      chunk_encoding_ = false;\n    } else if (status && *status == 304) {\n      // For 304 response, since it should never have a body, we should not need to chunk_encode at\n      // all.\n      chunk_encoding_ = false;\n    } else if (end_stream && !is_response_to_head_request_) {\n      // If this is a headers-only stream, append an explicit \"Content-Length: 0\" unless it's a\n      // response to a HEAD request.\n      // For 204s and 1xx where content length is disallowed, don't append the content length but\n      // also don't chunk encode.\n      // Also do not add content length for requests which should not have a\n      // body, per https://tools.ietf.org/html/rfc7230#section-3.3.2\n      if (!status || (*status >= 200 && *status != 204)) {\n        if (!bodiless_request) {\n          encodeFormattedHeader(header_values.ContentLength.get(), \"0\", formatter);\n        }\n      }\n      chunk_encoding_ = false;\n    } else if (connection_.protocol() == Protocol::Http10) {\n      chunk_encoding_ = false;\n    } else {\n      // For responses to connect requests, do not send the chunked encoding header:\n      // https://tools.ietf.org/html/rfc7231#section-4.3.6.\n      if (!is_response_to_connect_request_) {\n        encodeFormattedHeader(header_values.TransferEncoding.get(),\n                              header_values.TransferEncodingValues.Chunked, formatter);\n      }\n      // We do not apply chunk encoding for HTTP upgrades, including CONNECT style upgrades.\n      // If there is a body in a response on the upgrade path, the chunks will be\n      // passed through via maybeDirectDispatch so we need to avoid appending\n      // extra chunk boundaries.\n      //\n      // When sending a response to a HEAD request Envoy may send an informational\n      // \"Transfer-Encoding: chunked\" header, but should not send a chunk encoded body.\n      chunk_encoding_ = !Utility::isUpgrade(headers) && !is_response_to_head_request_ &&\n                        !is_response_to_connect_request_;\n    }\n  }\n\n  connection_.buffer().add(CRLF);\n\n  if (end_stream) {\n    endEncode();\n  } else {\n    flushOutput();\n  }\n}\n\nvoid StreamEncoderImpl::encodeData(Buffer::Instance& data, bool end_stream) {\n  // end_stream may be indicated with a zero length data buffer. If that is the case, so not\n  // actually write the zero length buffer out.\n  if (data.length() > 0) {\n    if (chunk_encoding_) {\n      std::string chunk_header = absl::StrCat(absl::Hex(data.length()), CRLF);\n      connection_.buffer().add(std::move(chunk_header));\n    }\n\n    connection_.buffer().move(data);\n\n    if (chunk_encoding_) {\n      connection_.buffer().add(CRLF);\n    }\n  }\n\n  if (end_stream) {\n    endEncode();\n  } else {\n    flushOutput();\n  }\n}\n\nvoid StreamEncoderImpl::flushOutput(bool end_encode) {\n  auto encoded_bytes = connection_.flushOutput(end_encode);\n  bytes_meter_->addWireBytesSent(encoded_bytes);\n}\n\nvoid StreamEncoderImpl::encodeTrailersBase(const HeaderMap& trailers) {\n  if (!connection_.enableTrailers()) {\n    return endEncode();\n  }\n  // Trailers only matter if it is a chunk transfer encoding\n  // https://tools.ietf.org/html/rfc7230#section-4.4\n  if (chunk_encoding_) {\n    // Finalize the body\n    connection_.buffer().add(LAST_CHUNK);\n\n    // TODO(mattklein123): Wire up the formatter if someone actually asks for this (very unlikely).\n    trailers.iterate([this](const HeaderEntry& header) -> HeaderMap::Iterate {\n      encodeFormattedHeader(header.key().getStringView(), header.value().getStringView(),\n                            HeaderKeyFormatterOptConstRef());\n      return HeaderMap::Iterate::Continue;\n    });\n\n    connection_.buffer().add(CRLF);\n  }\n\n  flushOutput();\n  connection_.onEncodeComplete();\n}\n\nvoid StreamEncoderImpl::encodeMetadata(const MetadataMapVector&) {\n  connection_.stats().metadata_not_supported_error_.inc();\n}\n\nvoid StreamEncoderImpl::endEncode() {\n  if (chunk_encoding_) {\n    connection_.buffer().addFragments({LAST_CHUNK, CRLF});\n  }\n\n  flushOutput(true);\n  connection_.onEncodeComplete();\n  // With CONNECT or TCP tunneling, half-closing the connection is used to signal end stream.\n  if (connect_request_ || is_tcp_tunneling_) {\n    connection_.connection().close(Network::ConnectionCloseType::FlushWriteAndDelay);\n  }\n}\n\nvoid ServerConnectionImpl::maybeAddSentinelBufferFragment(Buffer::Instance& output_buffer) {\n  // It's messy and complicated to try to tag the final write of an HTTP response for response\n  // tracking for flood protection. Instead, write an empty buffer fragment after the response,\n  // to allow for tracking.\n  // When the response is written out, the fragment will be deleted and the counter will be updated\n  // by ServerConnectionImpl::releaseOutboundResponse()\n  auto fragment =\n      Buffer::OwnedBufferFragmentImpl::create(absl::string_view(\"\", 0), response_buffer_releasor_);\n  output_buffer.addBufferFragment(*fragment.release());\n  ASSERT(outbound_responses_ < kMaxOutboundResponses);\n  outbound_responses_++;\n}\n\nStatus ServerConnectionImpl::doFloodProtectionChecks() const {\n  ASSERT(dispatching_);\n  // Before processing another request, make sure that we are below the response flood protection\n  // threshold.\n  if (outbound_responses_ >= kMaxOutboundResponses) {\n    ENVOY_CONN_LOG(trace, \"error accepting request: too many pending responses queued\",\n                   connection_);\n    stats_.response_flood_.inc();\n    return bufferFloodError(\"Too many responses queued.\");\n  }\n  return okStatus();\n}\n\nuint64_t ConnectionImpl::flushOutput(bool end_encode) {\n  if (end_encode) {\n    // If this is an HTTP response in ServerConnectionImpl, track outbound responses for flood\n    // protection\n    maybeAddSentinelBufferFragment(*output_buffer_);\n  }\n  const uint64_t bytes_encoded = output_buffer_->length();\n  connection().write(*output_buffer_, false);\n  ASSERT(0UL == output_buffer_->length());\n  return bytes_encoded;\n}\n\nvoid StreamEncoderImpl::resetStream(StreamResetReason reason) {\n  connection_.onResetStreamBase(reason);\n}\n\nvoid ResponseEncoderImpl::resetStream(StreamResetReason reason) {\n  // Clear the downstream on the account since we're resetting the downstream.\n  if (buffer_memory_account_) {\n    buffer_memory_account_->clearDownstream();\n  }\n\n  // For H1, we use idleTimeouts to cancel streams unless there was an\n  // explicit protocol error prior to sending a response to the downstream\n  // in which case we send a local reply.\n  // TODO(kbaichoo): If we want snappier resets of H1 streams we can\n  //  1) Send local reply if no response data sent yet\n  //  2) Invoke the idle timeout sooner to close underlying connection\n  StreamEncoderImpl::resetStream(reason);\n}\n\nvoid StreamEncoderImpl::readDisable(bool disable) {\n  if (disable) {\n    ++read_disable_calls_;\n  } else {\n    ASSERT(read_disable_calls_ != 0);\n    if (read_disable_calls_ != 0) {\n      --read_disable_calls_;\n    }\n  }\n  connection_.readDisable(disable);\n}\n\nuint32_t StreamEncoderImpl::bufferLimit() const { return connection_.bufferLimit(); }\n\nconst Network::Address::InstanceConstSharedPtr& StreamEncoderImpl::connectionLocalAddress() {\n  return connection_.connection().connectionInfoProvider().localAddress();\n}\n\nstatic constexpr absl::string_view RESPONSE_PREFIX = \"HTTP/1.1 \";\nstatic constexpr absl::string_view HTTP_10_RESPONSE_PREFIX = \"HTTP/1.0 \";\n\nvoid ResponseEncoderImpl::encodeHeaders(const ResponseHeaderMap& headers, bool end_stream) {\n  started_response_ = true;\n\n  // The contract is that client codecs must ensure that :status is present.\n  ASSERT(headers.Status() != nullptr);\n  uint64_t numeric_status = Utility::getResponseStatus(headers);\n\n  absl::string_view response_prefix;\n  if (connection_.protocol() == Protocol::Http10 && connection_.supportsHttp10()) {\n    response_prefix = HTTP_10_RESPONSE_PREFIX;\n  } else {\n    response_prefix = RESPONSE_PREFIX;\n  }\n\n  StatefulHeaderKeyFormatterOptConstRef formatter(headers.formatter());\n\n  absl::string_view reason_phrase;\n  if (formatter.has_value() && !formatter->getReasonPhrase().empty()) {\n    reason_phrase = formatter->getReasonPhrase();\n  } else {\n    const char* status_string = CodeUtility::toString(static_cast<Code>(numeric_status));\n    uint32_t status_string_len = strlen(status_string);\n    reason_phrase = {status_string, status_string_len};\n  }\n\n  connection_.buffer().addFragments(\n      {response_prefix, absl::StrCat(numeric_status), SPACE, reason_phrase, CRLF});\n\n  if (numeric_status >= 300) {\n    // Don't do special CONNECT logic if the CONNECT was rejected.\n    is_response_to_connect_request_ = false;\n  }\n\n  encodeHeadersBase(headers, absl::make_optional<uint64_t>(numeric_status), end_stream, false);\n}\n\nstatic constexpr absl::string_view REQUEST_POSTFIX = \" HTTP/1.1\\r\\n\";\n\nStatus RequestEncoderImpl::encodeHeaders(const RequestHeaderMap& headers, bool end_stream) {\n  // Required headers must be present. This can only happen by some erroneous processing after the\n  // downstream codecs decode.\n  RETURN_IF_ERROR(HeaderUtility::checkRequiredRequestHeaders(headers));\n\n  const HeaderEntry* method = headers.Method();\n  const HeaderEntry* path = headers.Path();\n  const HeaderEntry* host = headers.Host();\n  bool is_connect = HeaderUtility::isConnect(headers);\n  const Http::HeaderValues& header_values = Http::Headers::get();\n\n  if (method->value() == header_values.MethodValues.Head) {\n    head_request_ = true;\n  } else if (method->value() == header_values.MethodValues.Connect) {\n    disableChunkEncoding();\n    connection_.connection().enableHalfClose(true);\n    connect_request_ = true;\n  }\n  if (Utility::isUpgrade(headers)) {\n    upgrade_request_ = true;\n  }\n\n  absl::string_view host_or_path_view;\n  if (is_connect) {\n    host_or_path_view = host->value().getStringView();\n  } else {\n    host_or_path_view = path->value().getStringView();\n  }\n\n  connection_.buffer().addFragments(\n      {method->value().getStringView(), SPACE, host_or_path_view, REQUEST_POSTFIX});\n\n  encodeHeadersBase(headers, absl::nullopt, end_stream,\n                    HeaderUtility::requestShouldHaveNoBody(headers));\n  return okStatus();\n}\n\nint ConnectionImpl::setAndCheckCallbackStatus(Status&& status) {\n  ASSERT(codec_status_.ok());\n  codec_status_ = std::move(status);\n  return codec_status_.ok() ? parser_->statusToInt(ParserStatus::Success)\n                            : parser_->statusToInt(ParserStatus::Error);\n}\n\nint ConnectionImpl::setAndCheckCallbackStatusOr(Envoy::StatusOr<ParserStatus>&& statusor) {\n  ASSERT(codec_status_.ok());\n  if (statusor.ok()) {\n    return parser_->statusToInt(statusor.value());\n  } else {\n    codec_status_ = std::move(statusor.status());\n    return parser_->statusToInt(ParserStatus::Error);\n  }\n}\n\nConnectionImpl::ConnectionImpl(Network::Connection& connection, CodecStats& stats,\n                               const Http1Settings& settings, MessageType type,\n                               uint32_t max_headers_kb, const uint32_t max_headers_count)\n    : connection_(connection), stats_(stats), codec_settings_(settings),\n      encode_only_header_key_formatter_(encodeOnlyFormatterFromSettings(settings)),\n      processing_trailers_(false), handling_upgrade_(false), reset_stream_called_(false),\n      deferred_end_stream_headers_(false), dispatching_(false),\n      output_buffer_(connection.dispatcher().getWatermarkFactory().createBuffer(\n          [&]() -> void { this->onBelowLowWatermark(); },\n          [&]() -> void { this->onAboveHighWatermark(); },\n          []() -> void { /* TODO(adisuissa): Handle overflow watermark */ })),\n      max_headers_kb_(max_headers_kb), max_headers_count_(max_headers_count) {\n  output_buffer_->setWatermarks(connection.bufferLimit());\n  parser_ = std::make_unique<LegacyHttpParserImpl>(type, this);\n}\n\nStatus ConnectionImpl::completeLastHeader() {\n  ASSERT(dispatching_);\n  ENVOY_CONN_LOG(trace, \"completed header: key={} value={}\", connection_,\n                 current_header_field_.getStringView(), current_header_value_.getStringView());\n  auto& headers_or_trailers = headersOrTrailers();\n\n  // Account for \":\" and \"\\r\\n\" bytes between the header key value pair.\n  getBytesMeter().addHeaderBytesReceived(CRLF_SIZE + 1);\n\n  // TODO(10646): Switch to use HeaderUtility::checkHeaderNameForUnderscores().\n  RETURN_IF_ERROR(checkHeaderNameForUnderscores());\n  if (!current_header_field_.empty()) {\n    // Strip trailing whitespace of the current header value if any. Leading whitespace was trimmed\n    // in ConnectionImpl::onHeaderValue. http_parser does not strip leading or trailing whitespace\n    // as the spec requires: https://tools.ietf.org/html/rfc7230#section-3.2.4\n    current_header_value_.rtrim();\n\n    // If there is a stateful formatter installed, remember the original header key before\n    // converting to lower case.\n    auto formatter = headers_or_trailers.formatter();\n    if (formatter.has_value()) {\n      formatter->processKey(current_header_field_.getStringView());\n    }\n    current_header_field_.inlineTransform([](char c) { return absl::ascii_tolower(c); });\n\n    headers_or_trailers.addViaMove(std::move(current_header_field_),\n                                   std::move(current_header_value_));\n  }\n\n  // Check if the number of headers exceeds the limit.\n  if (headers_or_trailers.size() > max_headers_count_) {\n    error_code_ = Http::Code::RequestHeaderFieldsTooLarge;\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().TooManyHeaders));\n    const absl::string_view header_type =\n        processing_trailers_ ? Http1HeaderTypes::get().Trailers : Http1HeaderTypes::get().Headers;\n    return codecProtocolError(absl::StrCat(header_type, \" count exceeds limit\"));\n  }\n\n  header_parsing_state_ = HeaderParsingState::Field;\n  ASSERT(current_header_field_.empty());\n  ASSERT(current_header_value_.empty());\n  return okStatus();\n}\n\nuint32_t ConnectionImpl::getHeadersSize() {\n  return current_header_field_.size() + current_header_value_.size() +\n         headersOrTrailers().byteSize();\n}\n\nStatus ConnectionImpl::checkMaxHeadersSize() {\n  const uint32_t total = getHeadersSize();\n  if (total > (max_headers_kb_ * 1024)) {\n    const absl::string_view header_type =\n        processing_trailers_ ? Http1HeaderTypes::get().Trailers : Http1HeaderTypes::get().Headers;\n    error_code_ = Http::Code::RequestHeaderFieldsTooLarge;\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().HeadersTooLarge));\n    return codecProtocolError(absl::StrCat(header_type, \" size exceeds limit\"));\n  }\n  return okStatus();\n}\n\nbool ConnectionImpl::maybeDirectDispatch(Buffer::Instance& data) {\n  if (!handling_upgrade_) {\n    // Only direct dispatch for Upgrade requests.\n    return false;\n  }\n\n  ENVOY_CONN_LOG(trace, \"direct-dispatched {} bytes\", connection_, data.length());\n  onBody(data);\n  data.drain(data.length());\n  return true;\n}\n\nvoid ConnectionImpl::onDispatch(const Buffer::Instance& data) {\n  getBytesMeter().addWireBytesReceived(data.length());\n}\n\nHttp::Status ClientConnectionImpl::dispatch(Buffer::Instance& data) {\n  Http::Status status = ConnectionImpl::dispatch(data);\n  if (status.ok() && data.length() > 0) {\n    // The HTTP/1.1 codec pauses dispatch after a single response is complete. Extraneous data\n    // after a response is complete indicates an error.\n    return codecProtocolError(\"http/1.1 protocol error: extraneous data after response complete\");\n  }\n  return status;\n}\n\nHttp::Status ConnectionImpl::dispatch(Buffer::Instance& data) {\n  // Add self to the Dispatcher's tracked object stack.\n  ScopeTrackerScopeState scope(this, connection_.dispatcher());\n  ENVOY_CONN_LOG(trace, \"parsing {} bytes\", connection_, data.length());\n  // Make sure that dispatching_ is set to false after dispatching, even when\n  // http_parser exits early with an error code.\n  Cleanup cleanup([this]() { dispatching_ = false; });\n  ASSERT(!dispatching_);\n  ASSERT(codec_status_.ok());\n  ASSERT(buffered_body_.length() == 0);\n\n  dispatching_ = true;\n  onDispatch(data);\n  if (maybeDirectDispatch(data)) {\n    return Http::okStatus();\n  }\n\n  // Always resume before dispatch.\n  parser_->resume();\n\n  ssize_t total_parsed = 0;\n  if (data.length() > 0) {\n    current_dispatching_buffer_ = &data;\n    while (data.length() > 0) {\n      auto slice = data.frontSlice();\n      dispatching_slice_already_drained_ = false;\n      auto statusor_parsed = dispatchSlice(static_cast<const char*>(slice.mem_), slice.len_);\n      if (!statusor_parsed.ok()) {\n        return statusor_parsed.status();\n      }\n      if (!dispatching_slice_already_drained_) {\n        ASSERT(statusor_parsed.value() <= slice.len_);\n        data.drain(statusor_parsed.value());\n      }\n\n      total_parsed += statusor_parsed.value();\n      if (parser_->getStatus() != ParserStatus::Success) {\n        // Parse errors trigger an exception in dispatchSlice so we are guaranteed to be paused at\n        // this point.\n        ASSERT(parser_->getStatus() == ParserStatus::Paused);\n        break;\n      }\n    }\n    current_dispatching_buffer_ = nullptr;\n    dispatchBufferedBody();\n  } else {\n    auto result = dispatchSlice(nullptr, 0);\n    if (!result.ok()) {\n      return result.status();\n    }\n  }\n  ASSERT(buffered_body_.length() == 0);\n\n  ENVOY_CONN_LOG(trace, \"parsed {} bytes\", connection_, total_parsed);\n\n  // If an upgrade has been handled and there is body data or early upgrade\n  // payload to send on, send it on.\n  maybeDirectDispatch(data);\n  return Http::okStatus();\n}\n\nEnvoy::StatusOr<size_t> ConnectionImpl::dispatchSlice(const char* slice, size_t len) {\n  ASSERT(codec_status_.ok() && dispatching_);\n  auto [nread, rc] = parser_->execute(slice, len);\n  if (!codec_status_.ok()) {\n    return codec_status_;\n  }\n\n  if (rc != parser_->statusToInt(ParserStatus::Success) &&\n      rc != parser_->statusToInt(ParserStatus::Paused)) {\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().HttpCodecError));\n    // Avoid overwriting the codec_status_ set in the callbacks.\n    ASSERT(codec_status_.ok());\n    codec_status_ =\n        codecProtocolError(absl::StrCat(\"http/1.1 protocol error: \", parser_->errnoName(rc)));\n    return codec_status_;\n  }\n\n  return nread;\n}\n\nStatus ConnectionImpl::onHeaderField(const char* data, size_t length) {\n  ASSERT(dispatching_);\n\n  getBytesMeter().addHeaderBytesReceived(length);\n\n  // We previously already finished up the headers, these headers are\n  // now trailers.\n  if (header_parsing_state_ == HeaderParsingState::Done) {\n    if (!enableTrailers()) {\n      // Ignore trailers.\n      return okStatus();\n    }\n    processing_trailers_ = true;\n    header_parsing_state_ = HeaderParsingState::Field;\n    allocTrailers();\n  }\n  if (header_parsing_state_ == HeaderParsingState::Value) {\n    RETURN_IF_ERROR(completeLastHeader());\n  }\n\n  current_header_field_.append(data, length);\n\n  return checkMaxHeadersSize();\n}\n\nStatus ConnectionImpl::onHeaderValue(const char* data, size_t length) {\n  ASSERT(dispatching_);\n\n  getBytesMeter().addHeaderBytesReceived(length);\n\n  if (header_parsing_state_ == HeaderParsingState::Done && !enableTrailers()) {\n    // Ignore trailers.\n    return okStatus();\n  }\n\n  absl::string_view header_value{data, length};\n  if (!Http::HeaderUtility::headerValueIsValid(header_value)) {\n    ENVOY_CONN_LOG(debug, \"invalid header value: {}\", connection_, header_value);\n    error_code_ = Http::Code::BadRequest;\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidCharacters));\n    return codecProtocolError(\"http/1.1 protocol error: header value contains invalid chars\");\n  }\n\n  header_parsing_state_ = HeaderParsingState::Value;\n  if (current_header_value_.empty()) {\n    // Strip leading whitespace if the current header value input contains the first bytes of the\n    // encoded header value. Trailing whitespace is stripped once the full header value is known in\n    // ConnectionImpl::completeLastHeader. http_parser does not strip leading or trailing whitespace\n    // as the spec requires: https://tools.ietf.org/html/rfc7230#section-3.2.4 .\n    header_value = StringUtil::ltrim(header_value);\n  }\n  current_header_value_.append(header_value.data(), header_value.length());\n\n  return checkMaxHeadersSize();\n}\n\nStatusOr<ParserStatus> ConnectionImpl::onHeadersComplete() {\n  ASSERT(!processing_trailers_);\n  ASSERT(dispatching_);\n  ENVOY_CONN_LOG(trace, \"onHeadersCompleteBase\", connection_);\n  RETURN_IF_ERROR(completeLastHeader());\n\n  if (!(parser_->httpMajor() == 1 && parser_->httpMinor() == 1)) {\n    // This is not necessarily true, but it's good enough since higher layers only care if this is\n    // HTTP/1.1 or not.\n    protocol_ = Protocol::Http10;\n  }\n  RequestOrResponseHeaderMap& request_or_response_headers = requestOrResponseHeaders();\n  const Http::HeaderValues& header_values = Http::Headers::get();\n  if (Utility::isUpgrade(request_or_response_headers) && upgradeAllowed()) {\n    // Ignore h2c upgrade requests until we support them.\n    // See https://github.com/envoyproxy/envoy/issues/7161 for details.\n    if (absl::EqualsIgnoreCase(request_or_response_headers.getUpgradeValue(),\n                               header_values.UpgradeValues.H2c)) {\n      ENVOY_CONN_LOG(trace, \"removing unsupported h2c upgrade headers.\", connection_);\n      request_or_response_headers.removeUpgrade();\n      if (request_or_response_headers.Connection()) {\n        const auto& tokens_to_remove = caseUnorderdSetContainingUpgradeAndHttp2Settings();\n        std::string new_value = StringUtil::removeTokens(\n            request_or_response_headers.getConnectionValue(), \",\", tokens_to_remove, \",\");\n        if (new_value.empty()) {\n          request_or_response_headers.removeConnection();\n        } else {\n          request_or_response_headers.setConnection(new_value);\n        }\n      }\n      request_or_response_headers.remove(header_values.Http2Settings);\n    } else {\n      ENVOY_CONN_LOG(trace, \"codec entering upgrade mode.\", connection_);\n      handling_upgrade_ = true;\n    }\n  }\n  if (parser_->methodName() == header_values.MethodValues.Connect) {\n    if (request_or_response_headers.ContentLength()) {\n      if (request_or_response_headers.getContentLengthValue() == \"0\") {\n        request_or_response_headers.removeContentLength();\n      } else {\n        // Per https://tools.ietf.org/html/rfc7231#section-4.3.6 a payload with a\n        // CONNECT request has no defined semantics, and may be rejected.\n        error_code_ = Http::Code::BadRequest;\n        RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().BodyDisallowed));\n        return codecProtocolError(\"http/1.1 protocol error: unsupported content length\");\n      }\n    }\n    ENVOY_CONN_LOG(trace, \"codec entering upgrade mode for CONNECT request.\", connection_);\n    handling_upgrade_ = true;\n  }\n\n  // https://tools.ietf.org/html/rfc7230#section-3.3.3\n  // If a message is received with both a Transfer-Encoding and a\n  // Content-Length header field, the Transfer-Encoding overrides the\n  // Content-Length. Such a message might indicate an attempt to\n  // perform request smuggling (Section 9.5) or response splitting\n  // (Section 9.4) and ought to be handled as an error. A sender MUST\n  // remove the received Content-Length field prior to forwarding such\n  // a message.\n\n  // Reject message with Http::Code::BadRequest if both Transfer-Encoding and Content-Length\n  // headers are present or if allowed by http1 codec settings and 'Transfer-Encoding'\n  // is chunked - remove Content-Length and serve request.\n  if (parser_->hasTransferEncoding() != 0 && request_or_response_headers.ContentLength()) {\n    if (parser_->isChunked() && codec_settings_.allow_chunked_length_) {\n      request_or_response_headers.removeContentLength();\n    } else {\n      error_code_ = Http::Code::BadRequest;\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().ChunkedContentLength));\n      return codecProtocolError(\n          \"http/1.1 protocol error: both 'Content-Length' and 'Transfer-Encoding' are set.\");\n    }\n  }\n\n  // Per https://tools.ietf.org/html/rfc7230#section-3.3.1 Envoy should reject\n  // transfer-codings it does not understand.\n  // Per https://tools.ietf.org/html/rfc7231#section-4.3.6 a payload with a\n  // CONNECT request has no defined semantics, and may be rejected.\n  if (request_or_response_headers.TransferEncoding()) {\n    const absl::string_view encoding = request_or_response_headers.getTransferEncodingValue();\n    if (!absl::EqualsIgnoreCase(encoding, header_values.TransferEncodingValues.Chunked) ||\n        parser_->methodName() == header_values.MethodValues.Connect) {\n      error_code_ = Http::Code::NotImplemented;\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidTransferEncoding));\n      return codecProtocolError(\"http/1.1 protocol error: unsupported transfer encoding\");\n    }\n  }\n\n  auto statusor = onHeadersCompleteBase();\n  if (!statusor.ok()) {\n    RETURN_IF_ERROR(statusor.status());\n  }\n\n  header_parsing_state_ = HeaderParsingState::Done;\n\n  // Returning ParserStatus::NoBodyData informs http_parser to not expect a body or further data\n  // on this connection.\n  return handling_upgrade_ ? ParserStatus::NoBodyData : statusor.value();\n}\n\nvoid ConnectionImpl::bufferBody(const char* data, size_t length) {\n  auto slice = current_dispatching_buffer_->frontSlice();\n  if (data == slice.mem_ && length == slice.len_) {\n    buffered_body_.move(*current_dispatching_buffer_, length);\n    dispatching_slice_already_drained_ = true;\n  } else {\n    buffered_body_.add(data, length);\n  }\n}\n\nvoid ConnectionImpl::dispatchBufferedBody() {\n  ASSERT(parser_->getStatus() == ParserStatus::Success ||\n         parser_->getStatus() == ParserStatus::Paused);\n  ASSERT(codec_status_.ok());\n  if (buffered_body_.length() > 0) {\n    onBody(buffered_body_);\n    buffered_body_.drain(buffered_body_.length());\n  }\n}\n\nvoid ConnectionImpl::onChunkHeader(bool is_final_chunk) {\n  if (is_final_chunk) {\n    // Dispatch body before parsing trailers, so body ends up dispatched even if an error is found\n    // while processing trailers.\n    dispatchBufferedBody();\n  }\n}\n\nStatusOr<ParserStatus> ConnectionImpl::onMessageComplete() {\n  ENVOY_CONN_LOG(trace, \"message complete\", connection_);\n\n  dispatchBufferedBody();\n\n  if (handling_upgrade_) {\n    // If this is an upgrade request, swallow the onMessageComplete. The\n    // upgrade payload will be treated as stream body.\n    ASSERT(!deferred_end_stream_headers_);\n    ENVOY_CONN_LOG(trace, \"Pausing parser due to upgrade.\", connection_);\n    return parser_->pause();\n  }\n\n  // If true, this indicates we were processing trailers and must\n  // move the last header into current_header_map_\n  if (header_parsing_state_ == HeaderParsingState::Value) {\n    RETURN_IF_ERROR(completeLastHeader());\n  }\n\n  return onMessageCompleteBase();\n}\n\nStatus ConnectionImpl::onMessageBegin() {\n  ENVOY_CONN_LOG(trace, \"message begin\", connection_);\n  // Make sure that if HTTP/1.0 and HTTP/1.1 requests share a connection Envoy correctly sets\n  // protocol for each request. Envoy defaults to 1.1 but sets the protocol to 1.0 where applicable\n  // in onHeadersCompleteBase\n  protocol_ = Protocol::Http11;\n  processing_trailers_ = false;\n  header_parsing_state_ = HeaderParsingState::Field;\n  allocHeaders(statefulFormatterFromSettings(codec_settings_));\n  return onMessageBeginBase();\n}\n\nvoid ConnectionImpl::onResetStreamBase(StreamResetReason reason) {\n  ASSERT(!reset_stream_called_);\n  reset_stream_called_ = true;\n  onResetStream(reason);\n}\n\nvoid ConnectionImpl::dumpState(std::ostream& os, int indent_level) const {\n  const char* spaces = spacesForLevel(indent_level);\n  os << spaces << \"Http1::ConnectionImpl \" << this << DUMP_MEMBER(dispatching_)\n     << DUMP_MEMBER(dispatching_slice_already_drained_) << DUMP_MEMBER(reset_stream_called_)\n     << DUMP_MEMBER(handling_upgrade_) << DUMP_MEMBER(deferred_end_stream_headers_)\n     << DUMP_MEMBER(processing_trailers_) << DUMP_MEMBER(buffered_body_.length());\n\n  // Dump header parsing state, and any progress on headers.\n  os << DUMP_MEMBER(header_parsing_state_);\n  os << DUMP_MEMBER_AS(current_header_field_, current_header_field_.getStringView());\n  os << DUMP_MEMBER_AS(current_header_value_, current_header_value_.getStringView());\n\n  // Dump Child\n  os << '\\n';\n  dumpAdditionalState(os, indent_level);\n\n  // Dump the first slice of the dispatching buffer if not drained escaping\n  // certain characters. We do this last as the slice could be rather large.\n  if (current_dispatching_buffer_ == nullptr || dispatching_slice_already_drained_) {\n    // Buffer is either null or already drained (in the body).\n    // Use the macro for consistent formatting.\n    os << DUMP_NULLABLE_MEMBER(current_dispatching_buffer_, \"drained\");\n    return;\n  } else {\n    absl::string_view front_slice = [](Buffer::RawSlice slice) {\n      return absl::string_view(static_cast<const char*>(slice.mem_), slice.len_);\n    }(current_dispatching_buffer_->frontSlice());\n\n    // Dump buffer data escaping \\r, \\n, \\t, \", ', and \\.\n    // This is not the most performant implementation, but we're crashing and\n    // cannot allocate memory.\n    os << spaces << \"current_dispatching_buffer_ front_slice length: \" << front_slice.length()\n       << \" contents: \\\"\";\n    StringUtil::escapeToOstream(os, front_slice);\n    os << \"\\\"\\n\";\n  }\n}\n\nvoid ServerConnectionImpl::dumpAdditionalState(std::ostream& os, int indent_level) const {\n  const char* spaces = spacesForLevel(indent_level);\n\n  DUMP_DETAILS(active_request_);\n  os << '\\n';\n\n  // Dump header map, it may be null if it was moved to the request, and\n  // request_url.\n  if (absl::holds_alternative<RequestHeaderMapPtr>(headers_or_trailers_)) {\n    DUMP_DETAILS(absl::get<RequestHeaderMapPtr>(headers_or_trailers_));\n  } else {\n    DUMP_DETAILS(absl::get<RequestTrailerMapPtr>(headers_or_trailers_));\n  }\n}\n\nvoid ClientConnectionImpl::dumpAdditionalState(std::ostream& os, int indent_level) const {\n  const char* spaces = spacesForLevel(indent_level);\n  // Dump header map, it may be null if it was moved to the request.\n  if (absl::holds_alternative<ResponseHeaderMapPtr>(headers_or_trailers_)) {\n    DUMP_DETAILS(absl::get<ResponseHeaderMapPtr>(headers_or_trailers_));\n  } else {\n    DUMP_DETAILS(absl::get<ResponseTrailerMapPtr>(headers_or_trailers_));\n  }\n\n  // Dump the associated request.\n  os << spaces << \"Dumping corresponding downstream request:\";\n  if (pending_response_.has_value()) {\n    os << '\\n';\n    const ResponseDecoder* decoder = pending_response_.value().decoder_;\n    DUMP_DETAILS(decoder);\n  } else {\n    os << \" null\\n\";\n  }\n}\n\nServerConnectionImpl::ServerConnectionImpl(\n    Network::Connection& connection, CodecStats& stats, ServerConnectionCallbacks& callbacks,\n    const Http1Settings& settings, uint32_t max_request_headers_kb,\n    const uint32_t max_request_headers_count,\n    envoy::config::core::v3::HttpProtocolOptions::HeadersWithUnderscoresAction\n        headers_with_underscores_action)\n    : ConnectionImpl(connection, stats, settings, MessageType::Request, max_request_headers_kb,\n                     max_request_headers_count),\n      callbacks_(callbacks),\n      response_buffer_releasor_([this](const Buffer::OwnedBufferFragmentImpl* fragment) {\n        releaseOutboundResponse(fragment);\n      }),\n      headers_with_underscores_action_(headers_with_underscores_action),\n      runtime_lazy_read_disable_(\n          Runtime::runtimeFeatureEnabled(\"envoy.reloadable_features.http1_lazy_read_disable\")) {}\n\nuint32_t ServerConnectionImpl::getHeadersSize() {\n  // Add in the size of the request URL if processing request headers.\n  const uint32_t url_size =\n      (!processing_trailers_ && active_request_) ? active_request_->request_url_.size() : 0;\n  return url_size + ConnectionImpl::getHeadersSize();\n}\n\nvoid ServerConnectionImpl::onEncodeComplete() {\n  if (active_request_->remote_complete_) {\n    // Only do this if remote is complete. If we are replying before the request is complete the\n    // only logical thing to do is for higher level code to reset() / close the connection so we\n    // leave the request around so that it can fire reset callbacks.\n    connection_.dispatcher().deferredDelete(std::move(active_request_));\n  }\n}\n\nStatus ServerConnectionImpl::handlePath(RequestHeaderMap& headers, absl::string_view method) {\n  const Http::HeaderValues& header_values = Http::Headers::get();\n  HeaderString path(header_values.Path);\n\n  bool is_connect = (method == header_values.MethodValues.Connect);\n\n  // The url is relative or a wildcard when the method is OPTIONS. Nothing to do here.\n  if (!is_connect && !active_request_->request_url_.getStringView().empty() &&\n      (active_request_->request_url_.getStringView()[0] == '/' ||\n       (method == header_values.MethodValues.Options &&\n        active_request_->request_url_.getStringView()[0] == '*'))) {\n    headers.addViaMove(std::move(path), std::move(active_request_->request_url_));\n    return okStatus();\n  }\n\n  // If absolute_urls and/or connect are not going be handled, copy the url and return.\n  // This forces the behavior to be backwards compatible with the old codec behavior.\n  // CONNECT \"urls\" are actually host:port so look like absolute URLs to the above checks.\n  // Absolute URLS in CONNECT requests will be rejected below by the URL class validation.\n  if (!codec_settings_.allow_absolute_url_ && !is_connect) {\n    headers.addViaMove(std::move(path), std::move(active_request_->request_url_));\n    return okStatus();\n  }\n\n  Utility::Url absolute_url;\n  if (!absolute_url.initialize(active_request_->request_url_.getStringView(), is_connect)) {\n    RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidUrl));\n    return codecProtocolError(\"http/1.1 protocol error: invalid url in request line\");\n  }\n  // RFC7230#5.7\n  // When a proxy receives a request with an absolute-form of\n  // request-target, the proxy MUST ignore the received Host header field\n  // (if any) and instead replace it with the host information of the\n  // request-target. A proxy that forwards such a request MUST generate a\n  // new Host field-value based on the received request-target rather than\n  // forward the received Host field-value.\n  headers.setHost(absolute_url.hostAndPort());\n  // Add the scheme and validate to ensure no https://\n  // requests are accepted over unencrypted connections by front-line Envoys.\n  if (!is_connect) {\n    headers.setScheme(absolute_url.scheme());\n    if (!HeaderUtility::schemeIsValid(absolute_url.scheme())) {\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidScheme));\n      return codecProtocolError(\"http/1.1 protocol error: invalid scheme\");\n    }\n    if (codec_settings_.validate_scheme_ &&\n        absolute_url.scheme() == header_values.SchemeValues.Https && !connection().ssl()) {\n      error_code_ = Http::Code::Forbidden;\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().HttpsInPlaintext));\n      return codecProtocolError(\"http/1.1 protocol error: https in the clear\");\n    }\n  }\n\n  if (!absolute_url.pathAndQueryParams().empty()) {\n    headers.setPath(absolute_url.pathAndQueryParams());\n  }\n  active_request_->request_url_.clear();\n  return okStatus();\n}\n\nEnvoy::StatusOr<ParserStatus> ServerConnectionImpl::onHeadersCompleteBase() {\n  // Handle the case where response happens prior to request complete. It's up to upper layer code\n  // to disconnect the connection but we shouldn't fire any more events since it doesn't make\n  // sense.\n  if (active_request_) {\n    auto& headers = absl::get<RequestHeaderMapPtr>(headers_or_trailers_);\n    ENVOY_CONN_LOG(trace, \"Server: onHeadersComplete size={}\", connection_, headers->size());\n\n    if (!handling_upgrade_ && headers->Connection()) {\n      // If we fail to sanitize the request, return a 400 to the client\n      if (!Utility::sanitizeConnectionHeader(*headers)) {\n        absl::string_view header_value = headers->getConnectionValue();\n        ENVOY_CONN_LOG(debug, \"Invalid nominated headers in Connection: {}\", connection_,\n                       header_value);\n        error_code_ = Http::Code::BadRequest;\n        RETURN_IF_ERROR(\n            sendProtocolError(Http1ResponseCodeDetails::get().ConnectionHeaderSanitization));\n        return codecProtocolError(\"Invalid nominated headers in Connection.\");\n      }\n    }\n\n    // Inform the response encoder about any HEAD method, so it can set content\n    // length and transfer encoding headers correctly.\n    const Http::HeaderValues& header_values = Http::Headers::get();\n    active_request_->response_encoder_.setIsResponseToHeadRequest(parser_->methodName() ==\n                                                                  header_values.MethodValues.Head);\n    active_request_->response_encoder_.setIsResponseToConnectRequest(\n        parser_->methodName() == header_values.MethodValues.Connect);\n\n    RETURN_IF_ERROR(handlePath(*headers, parser_->methodName()));\n    ASSERT(active_request_->request_url_.empty());\n\n    headers->setMethod(parser_->methodName());\n\n    // Make sure the host is valid.\n    auto details = HeaderUtility::requestHeadersValid(*headers);\n    if (details.has_value()) {\n      RETURN_IF_ERROR(sendProtocolError(details.value().get()));\n      return codecProtocolError(\n          \"http/1.1 protocol error: request headers failed spec compliance checks\");\n    }\n\n    // Determine here whether we have a body or not. This uses the new RFC semantics where the\n    // presence of content-length or chunked transfer-encoding indicates a body vs. a particular\n    // method. If there is no body, we defer raising decodeHeaders() until the parser is flushed\n    // with message complete. This allows upper layers to behave like HTTP/2 and prevents a proxy\n    // scenario where the higher layers stream through and implicitly switch to chunked transfer\n    // encoding because end stream with zero body length has not yet been indicated.\n    if (parser_->isChunked() ||\n        (parser_->contentLength().has_value() && parser_->contentLength().value() > 0) ||\n        handling_upgrade_) {\n      active_request_->request_decoder_->decodeHeaders(std::move(headers), false);\n\n      // If the connection has been closed (or is closing) after decoding headers, pause the parser\n      // so we return control to the caller.\n      if (connection_.state() != Network::Connection::State::Open) {\n        return parser_->pause();\n      }\n    } else {\n      deferred_end_stream_headers_ = true;\n    }\n  }\n\n  return ParserStatus::Success;\n}\n\nStatus ServerConnectionImpl::onMessageBeginBase() {\n  if (!resetStreamCalled()) {\n    ASSERT(active_request_ == nullptr);\n    active_request_ = std::make_unique<ActiveRequest>(*this, std::move(bytes_meter_before_stream_));\n    if (resetStreamCalled()) {\n      return codecClientError(\"cannot create new streams after calling reset\");\n    }\n    active_request_->request_decoder_ = &callbacks_.newStream(active_request_->response_encoder_);\n\n    // Check for pipelined request flood as we prepare to accept a new request.\n    // Parse errors that happen prior to onMessageBegin result in stream termination, it is not\n    // possible to overflow output buffers with early parse errors.\n    RETURN_IF_ERROR(doFloodProtectionChecks());\n  }\n  return okStatus();\n}\n\nStatus ServerConnectionImpl::onUrl(const char* data, size_t length) {\n  if (active_request_) {\n    active_request_->request_url_.append(data, length);\n\n    RETURN_IF_ERROR(checkMaxHeadersSize());\n  }\n\n  return okStatus();\n}\n\nvoid ServerConnectionImpl::onBody(Buffer::Instance& data) {\n  ASSERT(!deferred_end_stream_headers_);\n  if (active_request_) {\n    ENVOY_CONN_LOG(trace, \"body size={}\", connection_, data.length());\n    active_request_->request_decoder_->decodeData(data, false);\n  }\n}\n\nHttp::Status ServerConnectionImpl::dispatch(Buffer::Instance& data) {\n  if (runtime_lazy_read_disable_ && active_request_ != nullptr &&\n      active_request_->remote_complete_) {\n    // Eagerly read disable the connection if the downstream is sending pipelined requests as we\n    // serially process them. Reading from the connection will be re-enabled after the active\n    // request is completed.\n    active_request_->response_encoder_.readDisable(true);\n    return okStatus();\n  }\n\n  Http::Status status = ConnectionImpl::dispatch(data);\n\n  if (runtime_lazy_read_disable_ && active_request_ != nullptr &&\n      active_request_->remote_complete_) {\n    // Read disable the connection if the downstream is sending additional data while we are working\n    // on an existing request. Reading from the connection will be re-enabled after the active\n    // request is completed.\n    if (data.length() > 0) {\n      active_request_->response_encoder_.readDisable(true);\n    }\n  }\n  return status;\n}\n\nParserStatus ServerConnectionImpl::onMessageCompleteBase() {\n  ASSERT(!handling_upgrade_);\n  if (active_request_) {\n\n    // The request_decoder should be non-null after we've called the newStream on callbacks.\n    ASSERT(active_request_->request_decoder_);\n    if (!runtime_lazy_read_disable_) {\n      active_request_->response_encoder_.readDisable(true);\n    }\n    active_request_->remote_complete_ = true;\n\n    if (deferred_end_stream_headers_) {\n      active_request_->request_decoder_->decodeHeaders(\n          std::move(absl::get<RequestHeaderMapPtr>(headers_or_trailers_)), true);\n      deferred_end_stream_headers_ = false;\n    } else if (processing_trailers_) {\n      active_request_->request_decoder_->decodeTrailers(\n          std::move(absl::get<RequestTrailerMapPtr>(headers_or_trailers_)));\n    } else {\n      Buffer::OwnedImpl buffer;\n      active_request_->request_decoder_->decodeData(buffer, true);\n    }\n\n    // Reset to ensure no information from one requests persists to the next.\n    headers_or_trailers_.emplace<RequestHeaderMapPtr>(nullptr);\n  }\n\n  // Always pause the parser so that the calling code can process 1 request at a time and apply\n  // back pressure. However this means that the calling code needs to detect if there is more data\n  // in the buffer and dispatch it again.\n  return parser_->pause();\n}\n\nvoid ServerConnectionImpl::onResetStream(StreamResetReason reason) {\n  if (active_request_) {\n    active_request_->response_encoder_.runResetCallbacks(reason);\n    connection_.dispatcher().deferredDelete(std::move(active_request_));\n  }\n}\n\nStatus ServerConnectionImpl::sendProtocolError(absl::string_view details) {\n  // We do this here because we may get a protocol error before we have a logical stream.\n  if (active_request_ == nullptr) {\n    RETURN_IF_ERROR(onMessageBegin());\n  }\n  ASSERT(active_request_);\n\n  active_request_->response_encoder_.setDetails(details);\n  if (!active_request_->response_encoder_.startedResponse()) {\n    active_request_->request_decoder_->sendLocalReply(\n        error_code_, CodeUtility::toString(error_code_), nullptr, absl::nullopt, details);\n  }\n  return okStatus();\n}\n\nvoid ServerConnectionImpl::onAboveHighWatermark() {\n  if (active_request_) {\n    active_request_->response_encoder_.runHighWatermarkCallbacks();\n  }\n}\nvoid ServerConnectionImpl::onBelowLowWatermark() {\n  if (active_request_) {\n    active_request_->response_encoder_.runLowWatermarkCallbacks();\n  }\n}\n\nvoid ServerConnectionImpl::releaseOutboundResponse(\n    const Buffer::OwnedBufferFragmentImpl* fragment) {\n  ASSERT(outbound_responses_ >= 1);\n  --outbound_responses_;\n  delete fragment;\n}\n\nStatus ServerConnectionImpl::checkHeaderNameForUnderscores() {\n  if (headers_with_underscores_action_ != envoy::config::core::v3::HttpProtocolOptions::ALLOW &&\n      Http::HeaderUtility::headerNameContainsUnderscore(current_header_field_.getStringView())) {\n    if (headers_with_underscores_action_ ==\n        envoy::config::core::v3::HttpProtocolOptions::DROP_HEADER) {\n      ENVOY_CONN_LOG(debug, \"Dropping header with invalid characters in its name: {}\", connection_,\n                     current_header_field_.getStringView());\n      stats_.dropped_headers_with_underscores_.inc();\n      current_header_field_.clear();\n      current_header_value_.clear();\n    } else {\n      ENVOY_CONN_LOG(debug, \"Rejecting request due to header name with underscores: {}\",\n                     connection_, current_header_field_.getStringView());\n      error_code_ = Http::Code::BadRequest;\n      RETURN_IF_ERROR(sendProtocolError(Http1ResponseCodeDetails::get().InvalidUnderscore));\n      stats_.requests_rejected_with_underscores_in_headers_.inc();\n      return codecProtocolError(\"http/1.1 protocol error: header name contains underscores\");\n    }\n  }\n  return okStatus();\n}\n\nvoid ServerConnectionImpl::ActiveRequest::dumpState(std::ostream& os, int indent_level) const {\n  (void)indent_level;\n  os << DUMP_MEMBER_AS(\n      request_url_, !request_url_.getStringView().empty() ? request_url_.getStringView() : \"null\");\n  os << DUMP_MEMBER(response_encoder_.local_end_stream_);\n}\n\nClientConnectionImpl::ClientConnectionImpl(Network::Connection& connection, CodecStats& stats,\n                                           ConnectionCallbacks&, const Http1Settings& settings,\n                                           const uint32_t max_response_headers_count)\n    : ConnectionImpl(connection, stats, settings, MessageType::Response, MAX_RESPONSE_HEADERS_KB,\n                     max_response_headers_count) {}\n\nbool ClientConnectionImpl::cannotHaveBody() {\n  if (pending_response_.has_value() && pending_response_.value().encoder_.headRequest()) {\n    ASSERT(!pending_response_done_);\n    return true;\n  } else if (parser_->statusCode() == 204 || parser_->statusCode() == 304 ||\n             (parser_->statusCode() >= 200 &&\n              (parser_->contentLength().has_value() && parser_->contentLength().value() == 0) &&\n              !parser_->isChunked())) {\n    return true;\n  } else {\n    return false;\n  }\n}\n\nRequestEncoder& ClientConnectionImpl::newStream(ResponseDecoder& response_decoder) {\n  // If reads were disabled due to flow control, we expect reads to always be enabled again before\n  // reusing this connection. This is done when the response is received.\n  ASSERT(connection_.readEnabled());\n\n  ASSERT(!pending_response_.has_value());\n  ASSERT(pending_response_done_);\n  pending_response_.emplace(*this, std::move(bytes_meter_before_stream_), &response_decoder);\n  pending_response_done_ = false;\n  return pending_response_.value().encoder_;\n}\n\nStatus ClientConnectionImpl::onStatus(const char* data, size_t length) {\n  auto& headers = absl::get<ResponseHeaderMapPtr>(headers_or_trailers_);\n  StatefulHeaderKeyFormatterOptRef formatter(headers->formatter());\n  if (formatter.has_value()) {\n    formatter->setReasonPhrase(absl::string_view(data, length));\n  }\n\n  return okStatus();\n}\n\nEnvoy::StatusOr<ParserStatus> ClientConnectionImpl::onHeadersCompleteBase() {\n  ENVOY_CONN_LOG(trace, \"status_code {}\", connection_, parser_->statusCode());\n\n  // Handle the case where the client is closing a kept alive connection (by sending a 408\n  // with a 'Connection: close' header). In this case we just let response flush out followed\n  // by the remote close.\n  if (!pending_response_.has_value() && !resetStreamCalled()) {\n    return prematureResponseError(\"\", static_cast<Http::Code>(parser_->statusCode()));\n  } else if (pending_response_.has_value()) {\n    ASSERT(!pending_response_done_);\n    auto& headers = absl::get<ResponseHeaderMapPtr>(headers_or_trailers_);\n    ENVOY_CONN_LOG(trace, \"Client: onHeadersComplete size={}\", connection_, headers->size());\n    headers->setStatus(parser_->statusCode());\n\n    if (parser_->statusCode() >= 200 && parser_->statusCode() < 300 &&\n        pending_response_.value().encoder_.connectRequest()) {\n      ENVOY_CONN_LOG(trace, \"codec entering upgrade mode for CONNECT response.\", connection_);\n      handling_upgrade_ = true;\n    }\n\n    if (parser_->statusCode() < 200 || parser_->statusCode() == 204) {\n      if (headers->TransferEncoding()) {\n        RETURN_IF_ERROR(\n            sendProtocolError(Http1ResponseCodeDetails::get().TransferEncodingNotAllowed));\n        return codecProtocolError(\n            \"http/1.1 protocol error: transfer encoding not allowed in 1xx or 204\");\n      }\n\n      if (headers->ContentLength()) {\n        // Report a protocol error for non-zero Content-Length, but paper over zero Content-Length.\n        if (headers->ContentLength()->value().getStringView() != \"0\") {\n          RETURN_IF_ERROR(\n              sendProtocolError(Http1ResponseCodeDetails::get().ContentLengthNotAllowed));\n          return codecProtocolError(\n              \"http/1.1 protocol error: content length not allowed in 1xx or 204\");\n        }\n\n        headers->removeContentLength();\n      }\n    }\n\n    if (HeaderUtility::isSpecial1xx(*headers)) {\n      pending_response_.value().decoder_->decode1xxHeaders(std::move(headers));\n    } else if (cannotHaveBody() && !handling_upgrade_) {\n      deferred_end_stream_headers_ = true;\n    } else {\n      pending_response_.value().decoder_->decodeHeaders(std::move(headers), false);\n    }\n\n    // http-parser treats 1xx headers as their own complete response. Swallow the spurious\n    // onMessageComplete and continue processing for purely informational headers.\n    // 101-SwitchingProtocols is exempt as all data after the header is proxied through after\n    // upgrading.\n    if (CodeUtility::is1xx(parser_->statusCode()) &&\n        parser_->statusCode() != enumToInt(Http::Code::SwitchingProtocols)) {\n      ignore_message_complete_for_1xx_ = true;\n      // Reset to ensure no information from the 1xx headers is used for the response headers.\n      headers_or_trailers_.emplace<ResponseHeaderMapPtr>(nullptr);\n    }\n  }\n\n  // Here we deal with cases where the response cannot have a body by returning\n  // ParserStatus::NoBody, but http_parser does not deal with it for us.\n  return cannotHaveBody() ? ParserStatus::NoBody : ParserStatus::Success;\n}\n\nbool ClientConnectionImpl::upgradeAllowed() const {\n  if (pending_response_.has_value()) {\n    return pending_response_->encoder_.upgradeRequest();\n  }\n  return false;\n}\n\nvoid ClientConnectionImpl::onBody(Buffer::Instance& data) {\n  ASSERT(!deferred_end_stream_headers_);\n  if (pending_response_.has_value()) {\n    ASSERT(!pending_response_done_);\n    pending_response_.value().decoder_->decodeData(data, false);\n  }\n}\n\nParserStatus ClientConnectionImpl::onMessageCompleteBase() {\n  ENVOY_CONN_LOG(trace, \"message complete\", connection_);\n  if (ignore_message_complete_for_1xx_) {\n    ignore_message_complete_for_1xx_ = false;\n    return ParserStatus::Success;\n  }\n  if (pending_response_.has_value()) {\n    ASSERT(!pending_response_done_);\n    // After calling decodeData() with end stream set to true, we should no longer be able to reset.\n    PendingResponse& response = pending_response_.value();\n    // Encoder is used as part of decode* calls later in this function so pending_response_ can not\n    // be reset just yet. Preserve the state in pending_response_done_ instead.\n    pending_response_done_ = true;\n\n    if (deferred_end_stream_headers_) {\n      response.decoder_->decodeHeaders(\n          std::move(absl::get<ResponseHeaderMapPtr>(headers_or_trailers_)), true);\n      deferred_end_stream_headers_ = false;\n    } else if (processing_trailers_) {\n      response.decoder_->decodeTrailers(\n          std::move(absl::get<ResponseTrailerMapPtr>(headers_or_trailers_)));\n    } else {\n      Buffer::OwnedImpl buffer;\n      response.decoder_->decodeData(buffer, true);\n    }\n\n    // Reset to ensure no information from one requests persists to the next.\n    pending_response_.reset();\n    headers_or_trailers_.emplace<ResponseHeaderMapPtr>(nullptr);\n  }\n\n  // Pause the parser after a response is complete. Any remaining data indicates an error.\n  return parser_->pause();\n}\n\nvoid ClientConnectionImpl::onResetStream(StreamResetReason reason) {\n  // Only raise reset if we did not already dispatch a complete response.\n  if (pending_response_.has_value() && !pending_response_done_) {\n    pending_response_.value().encoder_.runResetCallbacks(reason);\n    pending_response_done_ = true;\n    pending_response_.reset();\n  }\n}\n\nStatus ClientConnectionImpl::sendProtocolError(absl::string_view details) {\n  if (pending_response_.has_value()) {\n    ASSERT(!pending_response_done_);\n    pending_response_.value().encoder_.setDetails(details);\n  }\n  return okStatus();\n}\n\nvoid ClientConnectionImpl::onAboveHighWatermark() {\n  // This should never happen without an active stream/request.\n  pending_response_.value().encoder_.runHighWatermarkCallbacks();\n}\n\nvoid ClientConnectionImpl::onBelowLowWatermark() {\n  // This can get called without an active stream/request when the response completion causes us to\n  // close the connection, but in doing so go below low watermark.\n  if (pending_response_.has_value() && !pending_response_done_) {\n    pending_response_.value().encoder_.runLowWatermarkCallbacks();\n  }\n}\n\n} // namespace Http1\n} // namespace Http\n} // namespace Envoy\n", "#pragma once\n\n#include <chrono>\n#include <cstdint>\n\n#include \"envoy/common/time.h\"\n#include \"envoy/config/core/v3/base.pb.h\"\n#include \"envoy/http/header_map.h\"\n#include \"envoy/http/request_id_extension.h\"\n#include \"envoy/network/socket.h\"\n#include \"envoy/stream_info/stream_info.h\"\n#include \"envoy/tracing/trace_reason.h\"\n\n#include \"source/common/common/assert.h\"\n#include \"source/common/common/dump_state_utils.h\"\n#include \"source/common/common/macros.h\"\n#include \"source/common/common/utility.h\"\n#include \"source/common/network/socket_impl.h\"\n#include \"source/common/stream_info/filter_state_impl.h\"\n\n#include \"absl/strings/str_replace.h\"\n\nnamespace Envoy {\nnamespace StreamInfo {\n\nstruct UpstreamInfoImpl : public UpstreamInfo {\n  void setUpstreamConnectionId(uint64_t id) override { upstream_connection_id_ = id; }\n\n  absl::optional<uint64_t> upstreamConnectionId() const override { return upstream_connection_id_; }\n\n  void setUpstreamInterfaceName(absl::string_view interface_name) override {\n    upstream_connection_interface_name_ = std::string(interface_name);\n  }\n\n  absl::optional<absl::string_view> upstreamInterfaceName() const override {\n    return upstream_connection_interface_name_;\n  }\n\n  void\n  setUpstreamSslConnection(const Ssl::ConnectionInfoConstSharedPtr& ssl_connection_info) override {\n    upstream_ssl_info_ = ssl_connection_info;\n  }\n\n  Ssl::ConnectionInfoConstSharedPtr upstreamSslConnection() const override {\n    return upstream_ssl_info_;\n  }\n  UpstreamTiming& upstreamTiming() override { return upstream_timing_; }\n  const UpstreamTiming& upstreamTiming() const override { return upstream_timing_; }\n  const Network::Address::InstanceConstSharedPtr& upstreamLocalAddress() const override {\n    return upstream_local_address_;\n  }\n  void setUpstreamLocalAddress(\n      const Network::Address::InstanceConstSharedPtr& upstream_local_address) override {\n    upstream_local_address_ = upstream_local_address;\n  }\n  void setUpstreamTransportFailureReason(absl::string_view failure_reason) override {\n    upstream_transport_failure_reason_ = std::string(failure_reason);\n  }\n  const std::string& upstreamTransportFailureReason() const override {\n    return upstream_transport_failure_reason_;\n  }\n  void setUpstreamHost(Upstream::HostDescriptionConstSharedPtr host) override {\n    upstream_host_ = host;\n  }\n  const FilterStateSharedPtr& upstreamFilterState() const override {\n    return upstream_filter_state_;\n  }\n  void setUpstreamFilterState(const FilterStateSharedPtr& filter_state) override {\n    upstream_filter_state_ = filter_state;\n  }\n\n  Upstream::HostDescriptionConstSharedPtr upstreamHost() const override { return upstream_host_; }\n\n  void dumpState(std::ostream& os, int indent_level = 0) const override {\n    const char* spaces = spacesForLevel(indent_level);\n    os << spaces << \"UpstreamInfoImpl \" << this << DUMP_OPTIONAL_MEMBER(upstream_connection_id_)\n       << \"\\n\";\n  }\n  void setUpstreamNumStreams(uint64_t num_streams) override { num_streams_ = num_streams; }\n  uint64_t upstreamNumStreams() const override { return num_streams_; }\n\n  Upstream::HostDescriptionConstSharedPtr upstream_host_{};\n  Network::Address::InstanceConstSharedPtr upstream_local_address_;\n  UpstreamTiming upstream_timing_;\n  Ssl::ConnectionInfoConstSharedPtr upstream_ssl_info_;\n  absl::optional<uint64_t> upstream_connection_id_;\n  absl::optional<std::string> upstream_connection_interface_name_;\n  std::string upstream_transport_failure_reason_;\n  FilterStateSharedPtr upstream_filter_state_;\n  size_t num_streams_{};\n};\n\nstruct StreamInfoImpl : public StreamInfo {\n  StreamInfoImpl(\n      TimeSource& time_source,\n      const Network::ConnectionInfoProviderSharedPtr& downstream_connection_info_provider,\n      FilterState::LifeSpan life_span = FilterState::LifeSpan::FilterChain)\n      : StreamInfoImpl(absl::nullopt, time_source, downstream_connection_info_provider,\n                       std::make_shared<FilterStateImpl>(life_span)) {}\n\n  StreamInfoImpl(\n      Http::Protocol protocol, TimeSource& time_source,\n      const Network::ConnectionInfoProviderSharedPtr& downstream_connection_info_provider)\n      : StreamInfoImpl(protocol, time_source, downstream_connection_info_provider,\n                       std::make_shared<FilterStateImpl>(FilterState::LifeSpan::FilterChain)) {}\n\n  StreamInfoImpl(\n      Http::Protocol protocol, TimeSource& time_source,\n      const Network::ConnectionInfoProviderSharedPtr& downstream_connection_info_provider,\n      FilterStateSharedPtr parent_filter_state, FilterState::LifeSpan life_span)\n      : StreamInfoImpl(\n            protocol, time_source, downstream_connection_info_provider,\n            std::make_shared<FilterStateImpl>(\n                FilterStateImpl::LazyCreateAncestor(std::move(parent_filter_state), life_span),\n                FilterState::LifeSpan::FilterChain)) {}\n\n  SystemTime startTime() const override { return start_time_; }\n\n  MonotonicTime startTimeMonotonic() const override { return start_time_monotonic_; }\n\n  absl::optional<std::chrono::nanoseconds> duration(absl::optional<MonotonicTime> time) const {\n    if (!time) {\n      return {};\n    }\n\n    return std::chrono::duration_cast<std::chrono::nanoseconds>(time.value() -\n                                                                start_time_monotonic_);\n  }\n\n  void setUpstreamInfo(std::shared_ptr<UpstreamInfo> info) override { upstream_info_ = info; }\n\n  std::shared_ptr<UpstreamInfo> upstreamInfo() override { return upstream_info_; }\n\n  OptRef<const UpstreamInfo> upstreamInfo() const override {\n    if (!upstream_info_) {\n      return {};\n    }\n    return *upstream_info_;\n  }\n\n  absl::optional<std::chrono::nanoseconds> requestComplete() const override {\n    return duration(final_time_);\n  }\n\n  void onRequestComplete() override {\n    ASSERT(!final_time_);\n    final_time_ = time_source_.monotonicTime();\n  }\n\n  DownstreamTiming& downstreamTiming() override {\n    if (!downstream_timing_.has_value()) {\n      downstream_timing_ = DownstreamTiming();\n    }\n    return downstream_timing_.value();\n  }\n  OptRef<const DownstreamTiming> downstreamTiming() const override {\n    if (!downstream_timing_.has_value()) {\n      return {};\n    }\n    return {*downstream_timing_};\n  }\n\n  void addBytesReceived(uint64_t bytes_received) override { bytes_received_ += bytes_received; }\n\n  uint64_t bytesReceived() const override { return bytes_received_; }\n\n  absl::optional<Http::Protocol> protocol() const override { return protocol_; }\n\n  void protocol(Http::Protocol protocol) override { protocol_ = protocol; }\n\n  absl::optional<uint32_t> responseCode() const override { return response_code_; }\n\n  const absl::optional<std::string>& responseCodeDetails() const override {\n    return response_code_details_;\n  }\n\n  void setResponseCode(uint32_t code) override { response_code_ = code; }\n\n  void setResponseCodeDetails(absl::string_view rc_details) override {\n    ASSERT(!StringUtil::hasEmptySpace(rc_details));\n    response_code_details_.emplace(rc_details);\n  }\n\n  const absl::optional<std::string>& connectionTerminationDetails() const override {\n    return connection_termination_details_;\n  }\n\n  void setConnectionTerminationDetails(absl::string_view connection_termination_details) override {\n    connection_termination_details_.emplace(connection_termination_details);\n  }\n\n  void addBytesSent(uint64_t bytes_sent) override { bytes_sent_ += bytes_sent; }\n\n  uint64_t bytesSent() const override { return bytes_sent_; }\n\n  void setResponseFlag(ResponseFlag response_flag) override { response_flags_ |= response_flag; }\n\n  bool intersectResponseFlags(uint64_t response_flags) const override {\n    return (response_flags_ & response_flags) != 0;\n  }\n\n  bool hasResponseFlag(ResponseFlag flag) const override { return response_flags_ & flag; }\n\n  bool hasAnyResponseFlag() const override { return response_flags_ != 0; }\n\n  uint64_t responseFlags() const override { return response_flags_; }\n\n  void setRouteName(absl::string_view route_name) override {\n    route_name_ = std::string(route_name);\n  }\n\n  const std::string& getRouteName() const override { return route_name_; }\n\n  void setVirtualClusterName(const absl::optional<std::string>& virtual_cluster_name) override {\n    virtual_cluster_name_ = virtual_cluster_name;\n  }\n\n  const absl::optional<std::string>& virtualClusterName() const override {\n    return virtual_cluster_name_;\n  }\n\n  bool healthCheck() const override { return health_check_request_; }\n\n  void healthCheck(bool is_health_check) override { health_check_request_ = is_health_check; }\n\n  const Network::ConnectionInfoProvider& downstreamAddressProvider() const override {\n    return *downstream_connection_info_provider_;\n  }\n\n  Router::RouteConstSharedPtr route() const override { return route_; }\n\n  envoy::config::core::v3::Metadata& dynamicMetadata() override { return metadata_; };\n  const envoy::config::core::v3::Metadata& dynamicMetadata() const override { return metadata_; };\n\n  void setDynamicMetadata(const std::string& name, const ProtobufWkt::Struct& value) override {\n    (*metadata_.mutable_filter_metadata())[name].MergeFrom(value);\n  };\n\n  const FilterStateSharedPtr& filterState() override { return filter_state_; }\n  const FilterState& filterState() const override { return *filter_state_; }\n\n  void setRequestHeaders(const Http::RequestHeaderMap& headers) override {\n    request_headers_ = &headers;\n  }\n\n  const Http::RequestHeaderMap* getRequestHeaders() const override { return request_headers_; }\n\n  void setRequestIDProvider(const Http::RequestIdStreamInfoProviderSharedPtr& provider) override {\n    ASSERT(provider != nullptr);\n    request_id_provider_ = provider;\n  }\n  const Http::RequestIdStreamInfoProvider* getRequestIDProvider() const override {\n    return request_id_provider_.get();\n  }\n\n  void setTraceReason(Tracing::Reason reason) override { trace_reason_ = reason; }\n  Tracing::Reason traceReason() const override { return trace_reason_; }\n\n  void dumpState(std::ostream& os, int indent_level = 0) const {\n    const char* spaces = spacesForLevel(indent_level);\n    os << spaces << \"StreamInfoImpl \" << this << DUMP_OPTIONAL_MEMBER(protocol_)\n       << DUMP_OPTIONAL_MEMBER(response_code_) << DUMP_OPTIONAL_MEMBER(response_code_details_)\n       << DUMP_OPTIONAL_MEMBER(attempt_count_) << DUMP_MEMBER(health_check_request_)\n       << DUMP_MEMBER(route_name_);\n    DUMP_DETAILS(upstream_info_);\n  }\n\n  void setUpstreamClusterInfo(\n      const Upstream::ClusterInfoConstSharedPtr& upstream_cluster_info) override {\n    upstream_cluster_info_ = upstream_cluster_info;\n  }\n\n  absl::optional<Upstream::ClusterInfoConstSharedPtr> upstreamClusterInfo() const override {\n    return upstream_cluster_info_;\n  }\n\n  void setFilterChainName(absl::string_view filter_chain_name) override {\n    filter_chain_name_ = std::string(filter_chain_name);\n  }\n\n  const std::string& filterChainName() const override { return filter_chain_name_; }\n  void setAttemptCount(uint32_t attempt_count) override { attempt_count_ = attempt_count; }\n\n  absl::optional<uint32_t> attemptCount() const override { return attempt_count_; }\n\n  const BytesMeterSharedPtr& getUpstreamBytesMeter() const override {\n    return upstream_bytes_meter_;\n  }\n\n  const BytesMeterSharedPtr& getDownstreamBytesMeter() const override {\n    return downstream_bytes_meter_;\n  }\n\n  void setUpstreamBytesMeter(const BytesMeterSharedPtr& upstream_bytes_meter) override {\n    // Accumulate the byte measurement from previous upstream request during a retry.\n    upstream_bytes_meter->addWireBytesSent(upstream_bytes_meter_->wireBytesSent());\n    upstream_bytes_meter->addWireBytesReceived(upstream_bytes_meter_->wireBytesReceived());\n    upstream_bytes_meter->addHeaderBytesSent(upstream_bytes_meter_->headerBytesSent());\n    upstream_bytes_meter->addHeaderBytesReceived(upstream_bytes_meter_->headerBytesReceived());\n    upstream_bytes_meter_ = upstream_bytes_meter;\n  }\n\n  void setDownstreamBytesMeter(const BytesMeterSharedPtr& downstream_bytes_meter) override {\n    // Downstream bytes counter don't reset during a retry.\n    if (downstream_bytes_meter_ == nullptr) {\n      downstream_bytes_meter_ = downstream_bytes_meter;\n    }\n    ASSERT(downstream_bytes_meter_.get() == downstream_bytes_meter.get());\n  }\n\n  // This function is used to persist relevant information from the original\n  // stream into to the new one, when recreating the stream. Generally this\n  // includes information about the downstream stream, but not the upstream\n  // stream.\n  void setFromForRecreateStream(StreamInfo& info) {\n    downstream_timing_ = info.downstreamTiming();\n    protocol_ = info.protocol();\n    bytes_received_ = info.bytesReceived();\n    downstream_bytes_meter_ = info.getDownstreamBytesMeter();\n    // These two are set in the constructor, but to T(recreate), and should be T(create)\n    start_time_ = info.startTime();\n    start_time_monotonic_ = info.startTimeMonotonic();\n  }\n\n  TimeSource& time_source_;\n  SystemTime start_time_;\n  MonotonicTime start_time_monotonic_;\n  absl::optional<MonotonicTime> final_time_;\n\n  absl::optional<Http::Protocol> protocol_;\n  absl::optional<uint32_t> response_code_;\n  absl::optional<std::string> response_code_details_;\n  absl::optional<std::string> connection_termination_details_;\n  uint64_t response_flags_{};\n  bool health_check_request_{};\n  Router::RouteConstSharedPtr route_;\n  envoy::config::core::v3::Metadata metadata_{};\n  FilterStateSharedPtr filter_state_;\n  std::string route_name_;\n  absl::optional<uint32_t> attempt_count_;\n  // TODO(agrawroh): Check if the owner of this storage outlives the StreamInfo. We should only copy\n  // the string if it could outlive the StreamInfo.\n  absl::optional<std::string> virtual_cluster_name_;\n\nprivate:\n  static Network::ConnectionInfoProviderSharedPtr emptyDownstreamAddressProvider() {\n    MUTABLE_CONSTRUCT_ON_FIRST_USE(\n        Network::ConnectionInfoProviderSharedPtr,\n        std::make_shared<Network::ConnectionInfoSetterImpl>(nullptr, nullptr));\n  }\n\n  StreamInfoImpl(\n      absl::optional<Http::Protocol> protocol, TimeSource& time_source,\n      const Network::ConnectionInfoProviderSharedPtr& downstream_connection_info_provider,\n      FilterStateSharedPtr filter_state)\n      : time_source_(time_source), start_time_(time_source.systemTime()),\n        start_time_monotonic_(time_source.monotonicTime()), protocol_(protocol),\n        filter_state_(std::move(filter_state)),\n        downstream_connection_info_provider_(downstream_connection_info_provider != nullptr\n                                                 ? downstream_connection_info_provider\n                                                 : emptyDownstreamAddressProvider()),\n        trace_reason_(Tracing::Reason::NotTraceable) {}\n\n  std::shared_ptr<UpstreamInfo> upstream_info_;\n  uint64_t bytes_received_{};\n  uint64_t bytes_sent_{};\n  const Network::ConnectionInfoProviderSharedPtr downstream_connection_info_provider_;\n  const Http::RequestHeaderMap* request_headers_{};\n  Http::RequestIdStreamInfoProviderSharedPtr request_id_provider_;\n  absl::optional<DownstreamTiming> downstream_timing_;\n  absl::optional<Upstream::ClusterInfoConstSharedPtr> upstream_cluster_info_;\n  std::string filter_chain_name_;\n  Tracing::Reason trace_reason_;\n  // Default construct the object because upstream stream is not constructed in some cases.\n  BytesMeterSharedPtr upstream_bytes_meter_{std::make_shared<BytesMeter>()};\n  BytesMeterSharedPtr downstream_bytes_meter_;\n};\n\n} // namespace StreamInfo\n} // namespace Envoy\n", "#include <chrono>\n#include <functional>\n\n#include \"envoy/http/protocol.h\"\n#include \"envoy/stream_info/filter_state.h\"\n#include \"envoy/upstream/host_description.h\"\n\n#include \"source/common/common/fmt.h\"\n#include \"source/common/protobuf/utility.h\"\n#include \"source/common/stream_info/stream_info_impl.h\"\n#include \"source/common/stream_info/utility.h\"\n\n#include \"test/common/stream_info/test_int_accessor.h\"\n#include \"test/mocks/router/mocks.h\"\n#include \"test/mocks/ssl/mocks.h\"\n#include \"test/mocks/upstream/cluster_info.h\"\n#include \"test/mocks/upstream/host.h\"\n#include \"test/test_common/test_time.h\"\n#include \"test/test_common/utility.h\"\n\n#include \"gmock/gmock.h\"\n#include \"gtest/gtest.h\"\n\nnamespace Envoy {\nnamespace StreamInfo {\nnamespace {\n\nstd::chrono::nanoseconds checkDuration(std::chrono::nanoseconds last,\n                                       absl::optional<std::chrono::nanoseconds> timing) {\n  EXPECT_TRUE(timing);\n  EXPECT_LE(last, timing.value());\n  return timing.value();\n}\n\nclass StreamInfoImplTest : public testing::Test {\nprotected:\n  DangerousDeprecatedTestTime test_time_;\n};\n\nTEST_F(StreamInfoImplTest, TimingTest) {\n  MonotonicTime pre_start = test_time_.timeSystem().monotonicTime();\n  StreamInfoImpl info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n  info.setUpstreamInfo(std::make_shared<UpstreamInfoImpl>());\n  UpstreamTiming& upstream_timing = info.upstreamInfo()->upstreamTiming();\n  MonotonicTime post_start = test_time_.timeSystem().monotonicTime();\n\n  const MonotonicTime& start = info.startTimeMonotonic();\n\n  EXPECT_LE(pre_start, start) << \"Start time was lower than expected\";\n  EXPECT_GE(post_start, start) << \"Start time was higher than expected\";\n\n  TimingUtility timing(info);\n  EXPECT_FALSE(timing.lastDownstreamRxByteReceived());\n  info.downstreamTiming().onLastDownstreamRxByteReceived(test_time_.timeSystem());\n  std::chrono::nanoseconds dur =\n      checkDuration(std::chrono::nanoseconds{0}, timing.lastDownstreamRxByteReceived());\n\n  EXPECT_FALSE(timing.firstUpstreamTxByteSent());\n  upstream_timing.onFirstUpstreamTxByteSent(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.firstUpstreamTxByteSent());\n\n  EXPECT_FALSE(timing.lastUpstreamTxByteSent());\n  upstream_timing.onLastUpstreamTxByteSent(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.lastUpstreamTxByteSent());\n\n  EXPECT_FALSE(timing.firstUpstreamRxByteReceived());\n  upstream_timing.onFirstUpstreamRxByteReceived(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.firstUpstreamRxByteReceived());\n\n  EXPECT_FALSE(timing.lastUpstreamRxByteReceived());\n  upstream_timing.onLastUpstreamRxByteReceived(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.lastUpstreamRxByteReceived());\n\n  EXPECT_FALSE(timing.firstDownstreamTxByteSent());\n  info.downstreamTiming().onFirstDownstreamTxByteSent(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.firstDownstreamTxByteSent());\n\n  EXPECT_FALSE(timing.lastDownstreamTxByteSent());\n  info.downstreamTiming().onLastDownstreamTxByteSent(test_time_.timeSystem());\n  dur = checkDuration(dur, timing.lastDownstreamTxByteSent());\n\n  EXPECT_FALSE(info.requestComplete());\n  info.onRequestComplete();\n  dur = checkDuration(dur, info.requestComplete());\n}\n\nTEST_F(StreamInfoImplTest, BytesTest) {\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n  const uint64_t bytes_sent = 7;\n  const uint64_t bytes_received = 12;\n\n  stream_info.addBytesSent(bytes_sent);\n  stream_info.addBytesReceived(bytes_received);\n\n  EXPECT_EQ(bytes_sent, stream_info.bytesSent());\n  EXPECT_EQ(bytes_received, stream_info.bytesReceived());\n}\n\nTEST_F(StreamInfoImplTest, ResponseFlagTest) {\n  const std::vector<ResponseFlag> responseFlags = {FailedLocalHealthCheck,\n                                                   NoHealthyUpstream,\n                                                   UpstreamRequestTimeout,\n                                                   LocalReset,\n                                                   UpstreamRemoteReset,\n                                                   UpstreamConnectionFailure,\n                                                   UpstreamConnectionTermination,\n                                                   UpstreamOverflow,\n                                                   NoRouteFound,\n                                                   DelayInjected,\n                                                   FaultInjected,\n                                                   RateLimited};\n\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n  EXPECT_FALSE(stream_info.hasAnyResponseFlag());\n  EXPECT_FALSE(stream_info.intersectResponseFlags(0));\n  for (ResponseFlag flag : responseFlags) {\n    // Test cumulative setting of response flags.\n    EXPECT_FALSE(stream_info.hasResponseFlag(flag))\n        << fmt::format(\"Flag: {} was already set\", flag);\n    stream_info.setResponseFlag(flag);\n    EXPECT_TRUE(stream_info.hasResponseFlag(flag))\n        << fmt::format(\"Flag: {} was expected to be set\", flag);\n  }\n  EXPECT_TRUE(stream_info.hasAnyResponseFlag());\n  EXPECT_EQ(0xFFF, stream_info.responseFlags());\n\n  StreamInfoImpl stream_info2(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n  stream_info2.setResponseFlag(FailedLocalHealthCheck);\n\n  EXPECT_TRUE(stream_info2.intersectResponseFlags(FailedLocalHealthCheck));\n}\n\nTEST_F(StreamInfoImplTest, MiscSettersAndGetters) {\n  {\n    StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n    EXPECT_EQ(nullptr, stream_info.upstreamInfo());\n    EXPECT_EQ(Http::Protocol::Http2, stream_info.protocol().value());\n    stream_info.setUpstreamInfo(std::make_shared<UpstreamInfoImpl>());\n\n    stream_info.protocol(Http::Protocol::Http10);\n    EXPECT_EQ(Http::Protocol::Http10, stream_info.protocol().value());\n\n    EXPECT_FALSE(stream_info.responseCode());\n    stream_info.response_code_ = 200;\n    ASSERT_TRUE(stream_info.responseCode());\n    EXPECT_EQ(200, stream_info.responseCode().value());\n\n    EXPECT_FALSE(stream_info.attemptCount().has_value());\n    stream_info.setAttemptCount(93);\n    ASSERT_TRUE(stream_info.attemptCount().has_value());\n    EXPECT_EQ(stream_info.attemptCount().value(), 93);\n\n    EXPECT_FALSE(stream_info.responseCodeDetails().has_value());\n    stream_info.setResponseCodeDetails(ResponseCodeDetails::get().ViaUpstream);\n    ASSERT_TRUE(stream_info.responseCodeDetails().has_value());\n    EXPECT_EQ(ResponseCodeDetails::get().ViaUpstream, stream_info.responseCodeDetails().value());\n\n    EXPECT_FALSE(stream_info.connectionTerminationDetails().has_value());\n    stream_info.setConnectionTerminationDetails(\"access_denied\");\n    ASSERT_TRUE(stream_info.connectionTerminationDetails().has_value());\n    EXPECT_EQ(\"access_denied\", stream_info.connectionTerminationDetails().value());\n\n    EXPECT_EQ(nullptr, stream_info.upstreamInfo()->upstreamHost());\n    Upstream::HostDescriptionConstSharedPtr host(new NiceMock<Upstream::MockHostDescription>());\n    stream_info.upstreamInfo()->setUpstreamHost(host);\n    EXPECT_EQ(host, stream_info.upstreamInfo()->upstreamHost());\n\n    EXPECT_FALSE(stream_info.healthCheck());\n    stream_info.healthCheck(true);\n    EXPECT_TRUE(stream_info.healthCheck());\n\n    EXPECT_EQ(nullptr, stream_info.route());\n    std::shared_ptr<NiceMock<Router::MockRoute>> route =\n        std::make_shared<NiceMock<Router::MockRoute>>();\n    stream_info.route_ = route;\n    EXPECT_EQ(route, stream_info.route());\n\n    stream_info.filterState()->setData(\"test\", std::make_unique<TestIntAccessor>(1),\n                                       FilterState::StateType::ReadOnly,\n                                       FilterState::LifeSpan::FilterChain);\n    EXPECT_EQ(1, stream_info.filterState()->getDataReadOnly<TestIntAccessor>(\"test\")->access());\n\n    stream_info.upstreamInfo()->setUpstreamFilterState(stream_info.filterState());\n    EXPECT_EQ(1, stream_info.upstreamInfo()\n                     ->upstreamFilterState()\n                     ->getDataReadOnly<TestIntAccessor>(\"test\")\n                     ->access());\n\n    EXPECT_EQ(absl::nullopt, stream_info.upstreamClusterInfo());\n    Upstream::ClusterInfoConstSharedPtr cluster_info(new NiceMock<Upstream::MockClusterInfo>());\n    stream_info.setUpstreamClusterInfo(cluster_info);\n    EXPECT_NE(absl::nullopt, stream_info.upstreamClusterInfo());\n    EXPECT_EQ(\"fake_cluster\", stream_info.upstreamClusterInfo().value()->name());\n\n    const std::string session_id =\n        \"D62A523A65695219D46FE1FFE285A4C371425ACE421B110B5B8D11D3EB4D5F0B\";\n    auto ssl_info = std::make_shared<Ssl::MockConnectionInfo>();\n    EXPECT_CALL(*ssl_info, sessionId()).WillRepeatedly(testing::ReturnRef(session_id));\n    stream_info.upstreamInfo()->setUpstreamSslConnection(ssl_info);\n    EXPECT_EQ(session_id, stream_info.upstreamInfo()->upstreamSslConnection()->sessionId());\n\n    EXPECT_FALSE(stream_info.upstreamInfo()->upstreamConnectionId().has_value());\n    stream_info.upstreamInfo()->setUpstreamConnectionId(12345);\n    ASSERT_TRUE(stream_info.upstreamInfo()->upstreamConnectionId().has_value());\n    EXPECT_EQ(12345, stream_info.upstreamInfo()->upstreamConnectionId().value());\n\n    EXPECT_FALSE(stream_info.upstreamInfo()->upstreamInterfaceName().has_value());\n    stream_info.upstreamInfo()->setUpstreamInterfaceName(\"lo\");\n    ASSERT_TRUE(stream_info.upstreamInfo()->upstreamInterfaceName().has_value());\n    EXPECT_EQ(\"lo\", stream_info.upstreamInfo()->upstreamInterfaceName().value());\n\n    std::shared_ptr<UpstreamInfo> new_info = std::make_shared<UpstreamInfoImpl>();\n    EXPECT_NE(stream_info.upstreamInfo(), new_info);\n    stream_info.setUpstreamInfo(new_info);\n    EXPECT_EQ(stream_info.upstreamInfo(), new_info);\n  }\n}\n\nTEST_F(StreamInfoImplTest, SetFrom) {\n  StreamInfoImpl s1(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n  s1.addBytesReceived(1);\n  s1.downstreamTiming().onLastDownstreamRxByteReceived(test_time_.timeSystem());\n\n#ifdef __clang__\n#if defined(__linux__)\n#if defined(__has_feature) && !(__has_feature(thread_sanitizer))\n  ASSERT_TRUE(sizeof(s1) == 760 || sizeof(s1) == 776 || sizeof(s1) == 800)\n      << \"If adding fields to StreamInfoImpl, please check to see if you \"\n         \"need to add them to setFromForRecreateStream! Current size \"\n      << sizeof(s1);\n#endif\n#endif\n#endif\n\n  StreamInfoImpl s2(Http::Protocol::Http11, test_time_.timeSystem(), nullptr);\n  s2.setFromForRecreateStream(s1);\n  EXPECT_EQ(s1.startTime(), s2.startTime());\n  EXPECT_EQ(s1.startTimeMonotonic(), s2.startTimeMonotonic());\n  EXPECT_EQ(s1.downstreamTiming().lastDownstreamRxByteReceived(),\n            s2.downstreamTiming().lastDownstreamRxByteReceived());\n  EXPECT_EQ(s1.protocol(), s2.protocol());\n  EXPECT_EQ(s1.bytesReceived(), s2.bytesReceived());\n  EXPECT_EQ(s1.getDownstreamBytesMeter(), s2.getDownstreamBytesMeter());\n}\n\nTEST_F(StreamInfoImplTest, DynamicMetadataTest) {\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n\n  EXPECT_EQ(0, stream_info.dynamicMetadata().filter_metadata_size());\n  stream_info.setDynamicMetadata(\"com.test\", MessageUtil::keyValueStruct(\"test_key\", \"test_value\"));\n  EXPECT_EQ(\"test_value\",\n            Config::Metadata::metadataValue(&stream_info.dynamicMetadata(), \"com.test\", \"test_key\")\n                .string_value());\n  ProtobufWkt::Struct struct_obj2;\n  ProtobufWkt::Value val2;\n  val2.set_string_value(\"another_value\");\n  (*struct_obj2.mutable_fields())[\"another_key\"] = val2;\n  stream_info.setDynamicMetadata(\"com.test\", struct_obj2);\n  EXPECT_EQ(\"another_value\", Config::Metadata::metadataValue(&stream_info.dynamicMetadata(),\n                                                             \"com.test\", \"another_key\")\n                                 .string_value());\n  // make sure \"test_key:test_value\" still exists\n  EXPECT_EQ(\"test_value\",\n            Config::Metadata::metadataValue(&stream_info.dynamicMetadata(), \"com.test\", \"test_key\")\n                .string_value());\n  std::string json;\n  const auto test_struct = stream_info.dynamicMetadata().filter_metadata().at(\"com.test\");\n  const auto status = Protobuf::util::MessageToJsonString(test_struct, &json);\n  EXPECT_TRUE(status.ok());\n  // check json contains the key and values we set\n  EXPECT_TRUE(json.find(\"\\\"test_key\\\":\\\"test_value\\\"\") != std::string::npos);\n  EXPECT_TRUE(json.find(\"\\\"another_key\\\":\\\"another_value\\\"\") != std::string::npos);\n}\n\nTEST_F(StreamInfoImplTest, DumpStateTest) {\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n  std::string prefix = \"\";\n\n  for (int i = 0; i < 7; ++i) {\n    std::stringstream out;\n    stream_info.dumpState(out, i);\n    std::string state = out.str();\n    EXPECT_TRUE(absl::StartsWith(state, prefix));\n    EXPECT_THAT(state, testing::HasSubstr(\"protocol_: 2\"));\n    prefix = prefix + \"  \";\n  }\n}\n\nTEST_F(StreamInfoImplTest, RequestHeadersTest) {\n  StreamInfoImpl stream_info(Http::Protocol::Http2, test_time_.timeSystem(), nullptr);\n  EXPECT_FALSE(stream_info.getRequestHeaders());\n\n  Http::TestRequestHeaderMapImpl headers;\n  stream_info.setRequestHeaders(headers);\n  EXPECT_EQ(&headers, stream_info.getRequestHeaders());\n}\n\nTEST_F(StreamInfoImplTest, DefaultRequestIDExtensionTest) {\n  StreamInfoImpl stream_info(test_time_.timeSystem(), nullptr);\n  EXPECT_EQ(nullptr, stream_info.getRequestIDProvider());\n}\n\nTEST_F(StreamInfoImplTest, Details) {\n  StreamInfoImpl stream_info(test_time_.timeSystem(), nullptr);\n  EXPECT_FALSE(stream_info.responseCodeDetails().has_value());\n  stream_info.setResponseCodeDetails(\"two_words\");\n  ASSERT_TRUE(stream_info.responseCodeDetails().has_value());\n  EXPECT_EQ(stream_info.responseCodeDetails().value(), \"two_words\");\n}\n\nTEST(UpstreamInfoImplTest, DumpState) {\n  UpstreamInfoImpl upstream_info;\n\n  {\n    std::stringstream out;\n    upstream_info.dumpState(out, 0);\n    std::string state = out.str();\n    EXPECT_THAT(state, testing::HasSubstr(\"upstream_connection_id_: null\"));\n  }\n  upstream_info.setUpstreamConnectionId(5);\n  {\n    std::stringstream out;\n    upstream_info.dumpState(out, 0);\n    std::string state = out.str();\n    EXPECT_THAT(state, testing::HasSubstr(\"upstream_connection_id_: 5\"));\n  }\n}\n\n} // namespace\n} // namespace StreamInfo\n} // namespace Envoy\n", "#include \"envoy/config/cluster/v3/cluster.pb.h\"\n#include \"envoy/grpc/status.h\"\n#include \"envoy/service/discovery/v3/discovery.pb.h\"\n#include \"envoy/stats/scope.h\"\n\n#include \"source/common/config/protobuf_link_hacks.h\"\n#include \"source/common/protobuf/protobuf.h\"\n#include \"source/common/protobuf/utility.h\"\n\n#include \"test/common/grpc/grpc_client_integration.h\"\n#include \"test/config/v2_link_hacks.h\"\n#include \"test/integration/http_integration.h\"\n#include \"test/integration/utility.h\"\n#include \"test/test_common/network_utility.h\"\n#include \"test/test_common/resources.h\"\n#include \"test/test_common/simulated_time_system.h\"\n#include \"test/test_common/utility.h\"\n\n#include \"absl/synchronization/notification.h\"\n#include \"gtest/gtest.h\"\n\nusing testing::AssertionResult;\n\nnamespace Envoy {\nnamespace {\n\nconst char ClusterName1[] = \"cluster_1\";\nconst char ClusterName2[] = \"cluster_2\";\nconst int UpstreamIndex1 = 1;\nconst int UpstreamIndex2 = 2;\n\nclass CdsIntegrationTest : public Grpc::DeltaSotwIntegrationParamTest, public HttpIntegrationTest {\npublic:\n  CdsIntegrationTest()\n      : HttpIntegrationTest(Http::CodecType::HTTP2, ipVersion(),\n                            ConfigHelper::discoveredClustersBootstrap(\n                                sotwOrDelta() == Grpc::SotwOrDelta::Sotw ||\n                                        sotwOrDelta() == Grpc::SotwOrDelta::UnifiedSotw\n                                    ? \"GRPC\"\n                                    : \"DELTA_GRPC\")),\n        cluster_creator_(&ConfigHelper::buildStaticCluster) {\n    if (sotwOrDelta() == Grpc::SotwOrDelta::UnifiedSotw ||\n        sotwOrDelta() == Grpc::SotwOrDelta::UnifiedDelta) {\n      config_helper_.addRuntimeOverride(\"envoy.reloadable_features.unified_mux\", \"true\");\n    }\n    use_lds_ = false;\n    sotw_or_delta_ = sotwOrDelta();\n  }\n\n  void TearDown() override {\n    if (!test_skipped_) {\n      cleanUpXdsConnection();\n    }\n  }\n\n  // Overridden to insert this stuff into the initialize() at the very beginning of\n  // HttpIntegrationTest::testRouterHeaderOnlyRequestAndResponse().\n  void initialize() override {\n    use_lds_ = false;\n    test_skipped_ = false;\n    // Controls how many addFakeUpstream() will happen in\n    // BaseIntegrationTest::createUpstreams() (which is part of initialize()).\n    // Make sure this number matches the size of the 'clusters' repeated field in the bootstrap\n    // config that you use!\n    setUpstreamCount(1);                         // the CDS cluster\n    setUpstreamProtocol(Http::CodecType::HTTP2); // CDS uses gRPC uses HTTP2.\n\n    // HttpIntegrationTest::initialize() does many things:\n    // 1) It appends to fake_upstreams_ as many as you asked for via setUpstreamCount().\n    // 2) It updates your bootstrap config with the ports your fake upstreams are actually listening\n    //    on (since you're supposed to leave them as 0).\n    // 3) It creates and starts an IntegrationTestServer - the thing that wraps the almost-actual\n    //    Envoy used in the tests.\n    // 4) Bringing up the server usually entails waiting to ensure that any listeners specified in\n    //    the bootstrap config have come up, and registering them in a port map (see lookupPort()).\n    //    However, this test needs to defer all of that to later.\n    defer_listener_finalization_ = true;\n    HttpIntegrationTest::initialize();\n\n    // Create the regular (i.e. not an xDS server) upstreams. We create them manually here after\n    // initialize() because finalize() expects all fake_upstreams_ to correspond to a static\n    // cluster in the bootstrap config - which we don't want since we're testing dynamic CDS!\n    addFakeUpstream(upstream_codec_type_);\n    addFakeUpstream(upstream_codec_type_);\n    cluster1_ = cluster_creator_(\n        ClusterName1, fake_upstreams_[UpstreamIndex1]->localAddress()->ip()->port(),\n        Network::Test::getLoopbackAddressString(ipVersion()), \"ROUND_ROBIN\");\n    cluster2_ = cluster_creator_(\n        ClusterName2, fake_upstreams_[UpstreamIndex2]->localAddress()->ip()->port(),\n        Network::Test::getLoopbackAddressString(ipVersion()), \"ROUND_ROBIN\");\n\n    // Let Envoy establish its connection to the CDS server.\n    acceptXdsConnection();\n\n    // Do the initial compareDiscoveryRequest / sendDiscoveryResponse for cluster_1.\n    EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"\", {}, {}, {}, true));\n    sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                               {cluster1_}, {cluster1_}, {}, \"55\");\n\n    // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n    // the DiscoveryResponse describing cluster_1 that we sent.\n    // 2 because the statically specified CDS server itself counts as a cluster.\n    test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 2);\n\n    // Wait for our statically specified listener to become ready, and register its port in the\n    // test framework's downstream listener port map.\n    test_server_->waitUntilListenersReady();\n    registerTestServerPorts({\"http\"});\n  }\n\n  // Regression test to catch the code declaring a gRPC service method for {SotW,delta}\n  // when the user's bootstrap config asks for the other type.\n  void verifyGrpcServiceMethod() {\n    EXPECT_TRUE(xds_stream_->waitForHeadersComplete());\n    Envoy::Http::LowerCaseString path_string(\":path\");\n    std::string expected_method(\n        sotwOrDelta() == Grpc::SotwOrDelta::Sotw || sotwOrDelta() == Grpc::SotwOrDelta::UnifiedSotw\n            ? \"/envoy.service.cluster.v3.ClusterDiscoveryService/StreamClusters\"\n            : \"/envoy.service.cluster.v3.ClusterDiscoveryService/DeltaClusters\");\n    EXPECT_EQ(xds_stream_->headers().get(path_string)[0]->value(), expected_method);\n  }\n\n  void acceptXdsConnection() {\n    AssertionResult result = // xds_connection_ is filled with the new FakeHttpConnection.\n        fake_upstreams_[0]->waitForHttpConnection(*dispatcher_, xds_connection_);\n    RELEASE_ASSERT(result, result.message());\n    result = xds_connection_->waitForNewStream(*dispatcher_, xds_stream_);\n    RELEASE_ASSERT(result, result.message());\n    xds_stream_->startGrpcStream();\n    verifyGrpcServiceMethod();\n  }\n\n  envoy::config::cluster::v3::Cluster cluster1_;\n  envoy::config::cluster::v3::Cluster cluster2_;\n  // True if we decided not to run the test after all.\n  bool test_skipped_{true};\n  Http::CodecType upstream_codec_type_{Http::CodecType::HTTP2};\n  std::function<envoy::config::cluster::v3::Cluster(const std::string&, int, const std::string&,\n                                                    const std::string&)>\n      cluster_creator_;\n};\n\nINSTANTIATE_TEST_SUITE_P(IpVersionsClientTypeDelta, CdsIntegrationTest,\n                         DELTA_SOTW_GRPC_CLIENT_INTEGRATION_PARAMS);\n\n// 1) Envoy starts up with no static clusters (other than the CDS-over-gRPC server).\n// 2) Envoy is told of a cluster via CDS.\n// 3) We send Envoy a request, which we verify is properly proxied to and served by that cluster.\n// 4) Envoy is told that cluster is gone.\n// 5) We send Envoy a request, which should 503.\n// 6) Envoy is told that the cluster is back.\n// 7) We send Envoy a request, which we verify is properly proxied to and served by that cluster.\nTEST_P(CdsIntegrationTest, CdsClusterUpDownUp) {\n  // Calls our initialize(), which includes establishing a listener, route, and cluster.\n  config_helper_.addConfigModifier(configureProxyStatus());\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n\n  // Tell Envoy that cluster_1 is gone.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  // Now that cluster_1 is gone, the listener (with its routing to cluster_1) should 503.\n  BufferingStreamDecoderPtr response = IntegrationUtil::makeSingleRequest(\n      lookupPort(\"http\"), \"GET\", \"/cluster1\", \"\", downstream_protocol_, version_, \"foo.com\");\n  ASSERT_TRUE(response->complete());\n  EXPECT_EQ(\"503\", response->headers().getStatusValue());\n  EXPECT_EQ(response->headers().getProxyStatusValue(),\n            \"envoy; error=destination_unavailable; details=\\\"cluster_not_found; NC\\\"\");\n\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Tell Envoy that cluster_1 is back.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"42\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                             {cluster1_}, {cluster1_}, {}, \"413\");\n\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse describing cluster_1 that we sent. Again, 2 includes CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 2);\n\n  // Does *not* call our initialize().\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n\n  cleanupUpstreamAndDownstream();\n}\n\n// Make sure that clusters won't create new connections on teardown.\nTEST_P(CdsIntegrationTest, CdsClusterTeardownWhileConnecting) {\n  initialize();\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n  test_server_->waitForCounterExists(\"cluster.cluster_1.upstream_cx_total\");\n  Stats::CounterSharedPtr cx_counter = test_server_->counter(\"cluster.cluster_1.upstream_cx_total\");\n  // Confirm no upstream connection is attempted so far.\n  EXPECT_EQ(0, cx_counter->value());\n\n  // Make the upstreams stop working, to ensure the connection was not\n  // established.\n  fake_upstreams_[1]->dispatcher()->exit();\n  fake_upstreams_[2]->dispatcher()->exit();\n  codec_client_ = makeHttpConnection(lookupPort(\"http\"));\n  auto encoder_decoder = codec_client_->startRequest(Http::TestRequestHeaderMapImpl{\n      {\":method\", \"GET\"}, {\":path\", \"/cluster1\"}, {\":scheme\", \"http\"}, {\":authority\", \"host\"}});\n\n  // Tell Envoy that cluster_1 is gone.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n  codec_client_->sendReset(encoder_decoder.first);\n  cleanupUpstreamAndDownstream();\n\n  // Either 0 or 1 upstream connection is attempted but no more.\n  EXPECT_LE(cx_counter->value(), 1);\n}\n\n// Test the fast addition and removal of clusters when they use ThreadAwareLb.\nTEST_P(CdsIntegrationTest, CdsClusterWithThreadAwareLbCycleUpDownUp) {\n  // Calls our initialize(), which includes establishing a listener, route, and cluster.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n\n  // Tell Envoy that cluster_1 is gone.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // Make sure that Envoy's ClusterManager has made use of the DiscoveryResponse that says cluster_1\n  // is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  // Update cluster1_ to use MAGLEV load balancer policy.\n  cluster1_ = ConfigHelper::buildStaticCluster(\n      ClusterName1, fake_upstreams_[UpstreamIndex1]->localAddress()->ip()->port(),\n      Network::Test::getLoopbackAddressString(ipVersion()), \"MAGLEV\");\n\n  // Cyclically add and remove cluster with ThreadAwareLb.\n  for (int i = 42; i < 142; i += 2) {\n    EXPECT_TRUE(\n        compareDiscoveryRequest(Config::TypeUrl::get().Cluster, absl::StrCat(i), {}, {}, {}));\n    sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n        Config::TypeUrl::get().Cluster, {cluster1_}, {cluster1_}, {}, absl::StrCat(i + 1));\n    EXPECT_TRUE(\n        compareDiscoveryRequest(Config::TypeUrl::get().Cluster, absl::StrCat(i + 1), {}, {}, {}));\n    sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n        Config::TypeUrl::get().Cluster, {}, {}, {ClusterName1}, absl::StrCat(i + 2));\n  }\n\n  cleanupUpstreamAndDownstream();\n}\n\n// Tests adding a cluster, adding another, then removing the first.\nTEST_P(CdsIntegrationTest, TwoClusters) {\n  // Calls our initialize(), which includes establishing a listener, route, and cluster.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Tell Envoy that cluster_2 is here.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n      Config::TypeUrl::get().Cluster, {cluster1_, cluster2_}, {cluster2_}, {}, \"42\");\n  // The '3' includes the fake CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 3);\n\n  // A request for cluster_2 should be fine.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex2, \"/cluster2\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Tell Envoy that cluster_1 is gone.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"42\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                             {cluster2_}, {}, {ClusterName1}, \"43\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  // Even with cluster_1 gone, a request for cluster_2 should be fine.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex2, \"/cluster2\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Tell Envoy that cluster_1 is back.\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"43\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n      Config::TypeUrl::get().Cluster, {cluster1_, cluster2_}, {cluster1_}, {}, \"413\");\n\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse describing cluster_1 that we sent. Again, 3 includes CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 3);\n\n  // Does *not* call our initialize().\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n\n  cleanupUpstreamAndDownstream();\n}\n\n// Test internal redirect to a cluster removed during the backend think time.\nTEST_P(CdsIntegrationTest, TwoClustersAndRedirects) {\n  setDownstreamProtocol(Http::CodecType::HTTP1);\n  config_helper_.addConfigModifier(\n      [](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n             hcm) {\n        auto* route = hcm.mutable_route_config()->mutable_virtual_hosts(0)->mutable_routes(1);\n        route->mutable_route()\n            ->mutable_internal_redirect_policy()\n            ->mutable_redirect_response_codes()\n            ->Add(302);\n      });\n\n  // Tell Envoy that cluster_2 is here.\n  initialize();\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(\n      Config::TypeUrl::get().Cluster, {cluster1_, cluster2_}, {cluster2_}, {}, \"42\");\n  // The '3' includes the fake CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 3);\n  // Tell Envoy that cluster_1 is gone.\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                             {cluster2_}, {}, {ClusterName1}, \"43\");\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  codec_client_ = makeHttpConnection(makeClientConnection((lookupPort(\"http\"))));\n  default_request_headers_.setPath(\"/cluster2\");\n  default_request_headers_.setContentLength(\"4\");\n  auto encoder_decoder = codec_client_->startRequest(default_request_headers_);\n  Buffer::OwnedImpl data(\"body\");\n  encoder_decoder.first.encodeData(data, true);\n  auto& response = encoder_decoder.second;\n\n  ASSERT_TRUE(fake_upstreams_[UpstreamIndex2]->waitForHttpConnection(*dispatcher_,\n                                                                     fake_upstream_connection_));\n  ASSERT_TRUE(fake_upstream_connection_->waitForNewStream(*dispatcher_, upstream_request_));\n  ASSERT_TRUE(upstream_request_->waitForEndStream(*dispatcher_));\n\n  Http::TestResponseHeaderMapImpl redirect_response{\n      {\":status\", \"302\"}, {\"content-length\", \"0\"}, {\"location\", \"http://host/cluster1\"}};\n\n  // Send a response to the original request redirecting to the deleted cluster.\n  upstream_request_->encodeHeaders(redirect_response, true);\n  ASSERT_TRUE(response->waitForEndStream());\n  EXPECT_EQ(\"503\", response->headers().getStatusValue());\n}\n\n// Tests that when Envoy's delta xDS stream dis/reconnects, Envoy can inform the server of the\n// resources it already has: the reconnected stream need not start with a state-of-the-world update.\nTEST_P(CdsIntegrationTest, VersionsRememberedAfterReconnect) {\n  SKIP_IF_XDS_IS(Grpc::SotwOrDelta::Sotw);\n  SKIP_IF_XDS_IS(Grpc::SotwOrDelta::UnifiedSotw);\n\n  // Calls our initialize(), which includes establishing a listener, route, and cluster.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n\n  // Close the connection carrying Envoy's xDS gRPC stream...\n  AssertionResult result = xds_connection_->close();\n  RELEASE_ASSERT(result, result.message());\n  result = xds_connection_->waitForDisconnect();\n  RELEASE_ASSERT(result, result.message());\n  xds_connection_.reset();\n  // ...and reconnect it.\n  acceptXdsConnection();\n\n  // Upon reconnecting, the Envoy should tell us its current resource versions.\n  envoy::service::discovery::v3::DeltaDiscoveryRequest request;\n  result = xds_stream_->waitForGrpcMessage(*dispatcher_, request);\n  RELEASE_ASSERT(result, result.message());\n  const auto& initial_resource_versions = request.initial_resource_versions();\n  EXPECT_EQ(\"55\", initial_resource_versions.at(std::string(ClusterName1)));\n  EXPECT_EQ(1, initial_resource_versions.size());\n\n  // Tell Envoy that cluster_2 is here. This update does *not* need to include cluster_1,\n  // which Envoy should already know about despite the disconnect.\n  sendDeltaDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster,\n                                                                  {cluster2_}, {}, \"42\");\n  // The '3' includes the fake CDS server.\n  test_server_->waitForGaugeGe(\"cluster_manager.active_clusters\", 3);\n\n  // A request for cluster_1 should be fine.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex1, \"/cluster1\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n  // A request for cluster_2 should be fine.\n  testRouterHeaderOnlyRequestAndResponse(nullptr, UpstreamIndex2, \"/cluster2\");\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n}\n\n// This test verifies that Envoy can delete a cluster with a lot of idle connections.\n// The original problem was recursive closure of idle connections that can run out\n// of stack when there are a lot of idle connections.\nTEST_P(CdsIntegrationTest, CdsClusterDownWithLotsOfIdleConnections) {\n  constexpr int num_requests = 2000;\n  // Make upstream H/1 so it creates connection for each request\n  upstream_codec_type_ = Http::CodecType::HTTP1;\n  // Relax default circuit breaker limits and timeouts so Envoy can accumulate a lot of idle\n  // connections\n  cluster_creator_ = &ConfigHelper::buildH1ClusterWithHighCircuitBreakersLimits;\n  config_helper_.addConfigModifier(\n      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n              hcm) -> void {\n        hcm.mutable_route_config()\n            ->mutable_virtual_hosts(0)\n            ->mutable_routes(0)\n            ->mutable_route()\n            ->mutable_timeout()\n            ->set_seconds(600);\n        hcm.mutable_route_config()\n            ->mutable_virtual_hosts(0)\n            ->mutable_routes(0)\n            ->mutable_route()\n            ->mutable_idle_timeout()\n            ->set_seconds(600);\n      });\n  initialize();\n  std::vector<IntegrationStreamDecoderPtr> responses;\n  std::vector<FakeHttpConnectionPtr> upstream_connections;\n  std::vector<FakeStreamPtr> upstream_requests;\n  codec_client_ = makeHttpConnection(makeClientConnection((lookupPort(\"http\"))));\n  // The first loop establishes a lot of open connections with active requests to upstream\n  for (int i = 0; i < num_requests; ++i) {\n    Http::TestRequestHeaderMapImpl request_headers{{\":method\", \"GET\"},\n                                                   {\":path\", \"/cluster1\"},\n                                                   {\":scheme\", \"http\"},\n                                                   {\":authority\", \"host\"},\n                                                   {\"x-lyft-user-id\", absl::StrCat(i)}};\n\n    auto response = codec_client_->makeHeaderOnlyRequest(request_headers);\n    responses.push_back(std::move(response));\n\n    FakeHttpConnectionPtr fake_upstream_connection;\n    waitForNextUpstreamConnection({UpstreamIndex1}, TestUtility::DefaultTimeout,\n                                  fake_upstream_connection);\n    // Wait for the next stream on the upstream connection.\n    FakeStreamPtr upstream_request;\n    AssertionResult result =\n        fake_upstream_connection->waitForNewStream(*dispatcher_, upstream_request);\n    RELEASE_ASSERT(result, result.message());\n    // Wait for the stream to be completely received.\n    result = upstream_request->waitForEndStream(*dispatcher_);\n    RELEASE_ASSERT(result, result.message());\n    upstream_connections.push_back(std::move(fake_upstream_connection));\n    upstream_requests.push_back(std::move(upstream_request));\n  }\n\n  // This loop completes all requests making the all upstream connections idle\n  for (int i = 0; i < num_requests; ++i) {\n    // Send response headers, and end_stream if there is no response body.\n    upstream_requests[i]->encodeHeaders(default_response_headers_, true);\n    // Wait for the response to be read by the codec client.\n    RELEASE_ASSERT(responses[i]->waitForEndStream(), \"unexpected timeout\");\n    ASSERT_TRUE(responses[i]->complete());\n    EXPECT_EQ(\"200\", responses[i]->headers().getStatusValue());\n  }\n\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n\n  // Tell Envoy that cluster_1 is gone. Envoy will try to close all idle connections\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  // If we made it this far then everything is ok.\n  for (int i = 0; i < num_requests; ++i) {\n    AssertionResult result = upstream_connections[i]->close();\n    RELEASE_ASSERT(result, result.message());\n    result = upstream_connections[i]->waitForDisconnect();\n    RELEASE_ASSERT(result, result.message());\n  }\n  upstream_connections.clear();\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n}\n\n// This test verifies that Envoy can delete a cluster with a lot of connections in the connecting\n// state and associated pending requests. The recursion guard in the\n// ConnPoolImplBase::closeIdleConnectionsForDrainingPool() would fire if it was called recursively.\n//\n// Test is currently disabled as there is presently no reliable way of making upstream connections\n// hang in connecting state.\nTEST_P(CdsIntegrationTest, DISABLED_CdsClusterDownWithLotsOfConnectingConnections) {\n  // Use low number of pending connections to prevent bumping into the default\n  // limit of 128, since the upstream will be prevented below from\n  // accepting connections.\n  constexpr int num_requests = 64;\n  // Make upstream H/1 so it creates connection for each request\n  upstream_codec_type_ = Http::CodecType::HTTP1;\n  cluster_creator_ = &ConfigHelper::buildH1ClusterWithHighCircuitBreakersLimits;\n  config_helper_.addConfigModifier(\n      [&](envoy::extensions::filters::network::http_connection_manager::v3::HttpConnectionManager&\n              hcm) -> void {\n        hcm.mutable_route_config()\n            ->mutable_virtual_hosts(0)\n            ->mutable_routes(0)\n            ->mutable_route()\n            ->mutable_timeout()\n            ->set_seconds(600);\n        hcm.mutable_route_config()\n            ->mutable_virtual_hosts(0)\n            ->mutable_routes(0)\n            ->mutable_route()\n            ->mutable_idle_timeout()\n            ->set_seconds(600);\n      });\n  initialize();\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_added\", 1);\n  std::vector<IntegrationStreamDecoderPtr> responses;\n  codec_client_ = makeHttpConnection(makeClientConnection((lookupPort(\"http\"))));\n  // Stop upstream at UpstreamIndex1 dispatcher, to prevent it from accepting TCP connections.\n  // This will cause Envoy's connections to that upstream hang in the connecting state.\n  fake_upstreams_[UpstreamIndex1]->dispatcher()->exit();\n  for (int i = 0; i < num_requests; ++i) {\n    Http::TestRequestHeaderMapImpl request_headers{{\":method\", \"GET\"},\n                                                   {\":path\", \"/cluster1\"},\n                                                   {\":scheme\", \"http\"},\n                                                   {\":authority\", \"host\"},\n                                                   {\"x-lyft-user-id\", absl::StrCat(i)}};\n\n    auto response = codec_client_->makeHeaderOnlyRequest(request_headers);\n    responses.push_back(std::move(response));\n  }\n\n  // Wait for Envoy to try to establish all expected connections\n  test_server_->waitForCounterEq(\"cluster.cluster_1.upstream_cx_total\", num_requests);\n\n  // Tell Envoy that cluster_1 is gone. Envoy will try to close all pending connections\n  EXPECT_TRUE(compareDiscoveryRequest(Config::TypeUrl::get().Cluster, \"55\", {}, {}, {}));\n  sendDiscoveryResponse<envoy::config::cluster::v3::Cluster>(Config::TypeUrl::get().Cluster, {}, {},\n                                                             {ClusterName1}, \"42\");\n  // We can continue the test once we're sure that Envoy's ClusterManager has made use of\n  // the DiscoveryResponse that says cluster_1 is gone.\n  test_server_->waitForCounterGe(\"cluster_manager.cluster_removed\", 1);\n\n  cleanupUpstreamAndDownstream();\n  ASSERT_TRUE(codec_client_->waitForDisconnect());\n  // If we got here it means that the recursion guard in the\n  // ConnPoolImplBase::closeIdleConnectionsForDrainingPool() did not fire, which is what this test\n  // validates.\n}\n\n} // namespace\n} // namespace Envoy\n"], "filenames": ["source/common/http/conn_manager_impl.cc", "source/common/http/filter_manager.cc", "source/common/http/filter_manager.h", "source/common/http/http1/codec_impl.cc", "source/common/stream_info/stream_info_impl.h", "test/common/stream_info/stream_info_impl_test.cc", "test/integration/cds_integration_test.cc"], "buggy_code_start_loc": [1731, 330, 910, 1206, 310, 219, 303], "buggy_code_end_loc": [1731, 849, 1070, 1208, 314, 219, 303], "fixing_code_start_loc": [1732, 330, 910, 1206, 311, 220, 304], "fixing_code_end_loc": [1738, 848, 1071, 1210, 328, 248, 350], "type": "CWE-416", "message": "Envoy is a cloud-native high-performance edge/middle/service proxy. In versions prior to 1.22.1 if Envoy attempts to send an internal redirect of an HTTP request consisting of more than HTTP headers, there\u00e2\u20ac\u2122s a lifetime bug which can be triggered. If while replaying the request Envoy sends a local reply when the redirect headers are processed, the downstream state indicates that the downstream stream is not complete. On sending the local reply, Envoy will attempt to reset the upstream stream, but as it is actually complete, and deleted, this result in a use-after-free. Users are advised to upgrade. Users unable to upgrade are advised to disable internal redirects if crashes are observed.", "other": {"cve": {"id": "CVE-2022-29227", "sourceIdentifier": "security-advisories@github.com", "published": "2022-06-09T20:15:08.140", "lastModified": "2022-06-16T19:31:10.943", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Envoy is a cloud-native high-performance edge/middle/service proxy. In versions prior to 1.22.1 if Envoy attempts to send an internal redirect of an HTTP request consisting of more than HTTP headers, there\u00e2\u20ac\u2122s a lifetime bug which can be triggered. If while replaying the request Envoy sends a local reply when the redirect headers are processed, the downstream state indicates that the downstream stream is not complete. On sending the local reply, Envoy will attempt to reset the upstream stream, but as it is actually complete, and deleted, this result in a use-after-free. Users are advised to upgrade. Users unable to upgrade are advised to disable internal redirects if crashes are observed."}, {"lang": "es", "value": "Envoy es un proxy de borde/medio/servicio de alto rendimiento nativo de la nube. En versiones anteriores a 1.22.1, si Envoy intenta enviar un redireccionamiento interno de una petici\u00f3n HTTP que consta de m\u00e1s encabezados HTTP, se presenta un error de por vida que puede desencadenarse. Si mientras es reproducida la petici\u00f3n Envoy env\u00eda una respuesta local cuando son procesados los encabezados del redireccionamiento, el estado descendente indica que el flujo descendente no est\u00e1 completo. Al enviar la respuesta local, Envoy intentar\u00e1 restablecer el flujo descendente, pero como en realidad est\u00e1 completo, y ha sido eliminado, esto resulta en un uso de memoria previamente liberada. es recomendado a usuarios actualizar. Es recomendado a usuarios que no puedan actualizar deshabilitar los redireccionamientos internos si son observados bloqueos"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-416"}]}, {"source": "security-advisories@github.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-416"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:envoyproxy:envoy:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.22.1", "matchCriteriaId": "343FE7CD-C2BF-42EE-8384-AAD008BE690D"}]}]}], "references": [{"url": "https://github.com/envoyproxy/envoy/commit/fe7c69c248f4fe5a9080c7ccb35275b5218bb5ab", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/envoyproxy/envoy/security/advisories/GHSA-rm2p-qvf6-pvr6", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/envoyproxy/envoy/commit/fe7c69c248f4fe5a9080c7ccb35275b5218bb5ab"}}
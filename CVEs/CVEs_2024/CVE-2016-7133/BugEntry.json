{"buggy_code": ["/*\n   +----------------------------------------------------------------------+\n   | Zend Engine                                                          |\n   +----------------------------------------------------------------------+\n   | Copyright (c) 1998-2016 Zend Technologies Ltd. (http://www.zend.com) |\n   +----------------------------------------------------------------------+\n   | This source file is subject to version 2.00 of the Zend license,     |\n   | that is bundled with this package in the file LICENSE, and is        |\n   | available through the world-wide-web at the following url:           |\n   | http://www.zend.com/license/2_00.txt.                                |\n   | If you did not receive a copy of the Zend license and are unable to  |\n   | obtain it through the world-wide-web, please send a note to          |\n   | license@zend.com so we can mail you a copy immediately.              |\n   +----------------------------------------------------------------------+\n   | Authors: Andi Gutmans <andi@zend.com>                                |\n   |          Zeev Suraski <zeev@zend.com>                                |\n   |          Dmitry Stogov <dmitry@zend.com>                             |\n   +----------------------------------------------------------------------+\n*/\n\n/* $Id$ */\n\n/*\n * zend_alloc is designed to be a modern CPU cache friendly memory manager\n * for PHP. Most ideas are taken from jemalloc and tcmalloc implementations.\n *\n * All allocations are split into 3 categories:\n *\n * Huge  - the size is greater than CHUNK size (~2M by default), allocation is\n *         performed using mmap(). The result is aligned on 2M boundary.\n *\n * Large - a number of 4096K pages inside a CHUNK. Large blocks\n *         are always aligned on page boundary.\n *\n * Small - less than 3/4 of page size. Small sizes are rounded up to nearest\n *         greater predefined small size (there are 30 predefined sizes:\n *         8, 16, 24, 32, ... 3072). Small blocks are allocated from\n *         RUNs. Each RUN is allocated as a single or few following pages.\n *         Allocation inside RUNs implemented using linked list of free\n *         elements. The result is aligned to 8 bytes.\n *\n * zend_alloc allocates memory from OS by CHUNKs, these CHUNKs and huge memory\n * blocks are always aligned to CHUNK boundary. So it's very easy to determine\n * the CHUNK owning the certain pointer. Regular CHUNKs reserve a single\n * page at start for special purpose. It contains bitset of free pages,\n * few bitset for available runs of predefined small sizes, map of pages that\n * keeps information about usage of each page in this CHUNK, etc.\n *\n * zend_alloc provides familiar emalloc/efree/erealloc API, but in addition it\n * provides specialized and optimized routines to allocate blocks of predefined\n * sizes (e.g. emalloc_2(), emallc_4(), ..., emalloc_large(), etc)\n * The library uses C preprocessor tricks that substitute calls to emalloc()\n * with more specialized routines when the requested size is known.\n */\n\n#include \"zend.h\"\n#include \"zend_alloc.h\"\n#include \"zend_globals.h\"\n#include \"zend_operators.h\"\n#include \"zend_multiply.h\"\n\n#ifdef HAVE_SIGNAL_H\n# include <signal.h>\n#endif\n#ifdef HAVE_UNISTD_H\n# include <unistd.h>\n#endif\n\n#ifdef ZEND_WIN32\n# include <wincrypt.h>\n# include <process.h>\n#endif\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include <sys/types.h>\n#include <sys/stat.h>\n#if HAVE_LIMITS_H\n#include <limits.h>\n#endif\n#include <fcntl.h>\n#include <errno.h>\n\n#ifndef _WIN32\n# ifdef HAVE_MREMAP\n#  ifndef _GNU_SOURCE\n#   define _GNU_SOURCE\n#  endif\n#  ifndef __USE_GNU\n#   define __USE_GNU\n#  endif\n# endif\n# include <sys/mman.h>\n# ifndef MAP_ANON\n#  ifdef MAP_ANONYMOUS\n#   define MAP_ANON MAP_ANONYMOUS\n#  endif\n# endif\n# ifndef MREMAP_MAYMOVE\n#  define MREMAP_MAYMOVE 0\n# endif\n# ifndef MAP_FAILED\n#  define MAP_FAILED ((void*)-1)\n# endif\n# ifndef MAP_POPULATE\n#  define MAP_POPULATE 0\n# endif\n#  if defined(_SC_PAGESIZE) || (_SC_PAGE_SIZE)\n#    define REAL_PAGE_SIZE _real_page_size\nstatic size_t _real_page_size = ZEND_MM_PAGE_SIZE;\n#  endif\n#endif\n\n#ifndef REAL_PAGE_SIZE\n# define REAL_PAGE_SIZE ZEND_MM_PAGE_SIZE\n#endif\n\n#ifndef ZEND_MM_STAT\n# define ZEND_MM_STAT 1    /* track current and peak memory usage            */\n#endif\n#ifndef ZEND_MM_LIMIT\n# define ZEND_MM_LIMIT 1   /* support for user-defined memory limit          */\n#endif\n#ifndef ZEND_MM_CUSTOM\n# define ZEND_MM_CUSTOM 1  /* support for custom memory allocator            */\n                           /* USE_ZEND_ALLOC=0 may switch to system malloc() */\n#endif\n#ifndef ZEND_MM_STORAGE\n# define ZEND_MM_STORAGE 1 /* support for custom memory storage              */\n#endif\n#ifndef ZEND_MM_ERROR\n# define ZEND_MM_ERROR 1   /* report system errors                           */\n#endif\n\n#ifndef ZEND_MM_CHECK\n# define ZEND_MM_CHECK(condition, message)  do { \\\n\t\tif (UNEXPECTED(!(condition))) { \\\n\t\t\tzend_mm_panic(message); \\\n\t\t} \\\n\t} while (0)\n#endif\n\ntypedef uint32_t   zend_mm_page_info; /* 4-byte integer */\ntypedef zend_ulong zend_mm_bitset;    /* 4-byte or 8-byte integer */\n\n#define ZEND_MM_ALIGNED_OFFSET(size, alignment) \\\n\t(((size_t)(size)) & ((alignment) - 1))\n#define ZEND_MM_ALIGNED_BASE(size, alignment) \\\n\t(((size_t)(size)) & ~((alignment) - 1))\n#define ZEND_MM_SIZE_TO_NUM(size, alignment) \\\n\t(((size_t)(size) + ((alignment) - 1)) / (alignment))\n\n#define ZEND_MM_BITSET_LEN\t\t(sizeof(zend_mm_bitset) * 8)       /* 32 or 64 */\n#define ZEND_MM_PAGE_MAP_LEN\t(ZEND_MM_PAGES / ZEND_MM_BITSET_LEN) /* 16 or 8 */\n\ntypedef zend_mm_bitset zend_mm_page_map[ZEND_MM_PAGE_MAP_LEN];     /* 64B */\n\n#define ZEND_MM_IS_FRUN                  0x00000000\n#define ZEND_MM_IS_LRUN                  0x40000000\n#define ZEND_MM_IS_SRUN                  0x80000000\n\n#define ZEND_MM_LRUN_PAGES_MASK          0x000003ff\n#define ZEND_MM_LRUN_PAGES_OFFSET        0\n\n#define ZEND_MM_SRUN_BIN_NUM_MASK        0x0000001f\n#define ZEND_MM_SRUN_BIN_NUM_OFFSET      0\n\n#define ZEND_MM_SRUN_FREE_COUNTER_MASK   0x01ff0000\n#define ZEND_MM_SRUN_FREE_COUNTER_OFFSET 16\n\n#define ZEND_MM_NRUN_OFFSET_MASK         0x01ff0000\n#define ZEND_MM_NRUN_OFFSET_OFFSET       16\n\n#define ZEND_MM_LRUN_PAGES(info)         (((info) & ZEND_MM_LRUN_PAGES_MASK) >> ZEND_MM_LRUN_PAGES_OFFSET)\n#define ZEND_MM_SRUN_BIN_NUM(info)       (((info) & ZEND_MM_SRUN_BIN_NUM_MASK) >> ZEND_MM_SRUN_BIN_NUM_OFFSET)\n#define ZEND_MM_SRUN_FREE_COUNTER(info)  (((info) & ZEND_MM_SRUN_FREE_COUNTER_MASK) >> ZEND_MM_SRUN_FREE_COUNTER_OFFSET)\n#define ZEND_MM_NRUN_OFFSET(info)        (((info) & ZEND_MM_NRUN_OFFSET_MASK) >> ZEND_MM_NRUN_OFFSET_OFFSET)\n\n#define ZEND_MM_FRUN()                   ZEND_MM_IS_FRUN\n#define ZEND_MM_LRUN(count)              (ZEND_MM_IS_LRUN | ((count) << ZEND_MM_LRUN_PAGES_OFFSET))\n#define ZEND_MM_SRUN(bin_num)            (ZEND_MM_IS_SRUN | ((bin_num) << ZEND_MM_SRUN_BIN_NUM_OFFSET))\n#define ZEND_MM_SRUN_EX(bin_num, count)  (ZEND_MM_IS_SRUN | ((bin_num) << ZEND_MM_SRUN_BIN_NUM_OFFSET) | ((count) << ZEND_MM_SRUN_FREE_COUNTER_OFFSET))\n#define ZEND_MM_NRUN(bin_num, offset)    (ZEND_MM_IS_SRUN | ZEND_MM_IS_LRUN | ((bin_num) << ZEND_MM_SRUN_BIN_NUM_OFFSET) | ((offset) << ZEND_MM_NRUN_OFFSET_OFFSET))\n\n#define ZEND_MM_BINS 30\n\ntypedef struct  _zend_mm_page      zend_mm_page;\ntypedef struct  _zend_mm_bin       zend_mm_bin;\ntypedef struct  _zend_mm_free_slot zend_mm_free_slot;\ntypedef struct  _zend_mm_chunk     zend_mm_chunk;\ntypedef struct  _zend_mm_huge_list zend_mm_huge_list;\n\n#ifdef _WIN64\n# define PTR_FMT \"0x%0.16I64x\"\n#elif SIZEOF_LONG == 8\n# define PTR_FMT \"0x%0.16lx\"\n#else\n# define PTR_FMT \"0x%0.8lx\"\n#endif\n\n#ifdef MAP_HUGETLB\nint zend_mm_use_huge_pages = 0;\n#endif\n\n/*\n * Memory is retrived from OS by chunks of fixed size 2MB.\n * Inside chunk it's managed by pages of fixed size 4096B.\n * So each chunk consists from 512 pages.\n * The first page of each chunk is reseved for chunk header.\n * It contains service information about all pages.\n *\n * free_pages - current number of free pages in this chunk\n *\n * free_tail  - number of continuous free pages at the end of chunk\n *\n * free_map   - bitset (a bit for each page). The bit is set if the corresponding\n *              page is allocated. Allocator for \"lage sizes\" may easily find a\n *              free page (or a continuous number of pages) searching for zero\n *              bits.\n *\n * map        - contains service information for each page. (32-bits for each\n *              page).\n *    usage:\n *\t\t\t\t(2 bits)\n * \t\t\t\tFRUN - free page,\n *              LRUN - first page of \"large\" allocation\n *              SRUN - first page of a bin used for \"small\" allocation\n *\n *    lrun_pages:\n *              (10 bits) number of allocated pages\n *\n *    srun_bin_num:\n *              (5 bits) bin number (e.g. 0 for sizes 0-2, 1 for 3-4,\n *               2 for 5-8, 3 for 9-16 etc) see zend_alloc_sizes.h\n */\n\nstruct _zend_mm_heap {\n#if ZEND_MM_CUSTOM\n\tint                use_custom_heap;\n#endif\n#if ZEND_MM_STORAGE\n\tzend_mm_storage   *storage;\n#endif\n#if ZEND_MM_STAT\n\tsize_t             size;                    /* current memory usage */\n\tsize_t             peak;                    /* peak memory usage */\n#endif\n\tzend_mm_free_slot *free_slot[ZEND_MM_BINS]; /* free lists for small sizes */\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\tsize_t             real_size;               /* current size of allocated pages */\n#endif\n#if ZEND_MM_STAT\n\tsize_t             real_peak;               /* peak size of allocated pages */\n#endif\n#if ZEND_MM_LIMIT\n\tsize_t             limit;                   /* memory limit */\n\tint                overflow;                /* memory overflow flag */\n#endif\n\n\tzend_mm_huge_list *huge_list;               /* list of huge allocated blocks */\n\n\tzend_mm_chunk     *main_chunk;\n\tzend_mm_chunk     *cached_chunks;\t\t\t/* list of unused chunks */\n\tint                chunks_count;\t\t\t/* number of alocated chunks */\n\tint                peak_chunks_count;\t\t/* peak number of allocated chunks for current request */\n\tint                cached_chunks_count;\t\t/* number of cached chunks */\n\tdouble             avg_chunks_count;\t\t/* average number of chunks allocated per request */\n#if ZEND_MM_CUSTOM\n\tunion {\n\t\tstruct {\n\t\t\tvoid      *(*_malloc)(size_t);\n\t\t\tvoid       (*_free)(void*);\n\t\t\tvoid      *(*_realloc)(void*, size_t);\n\t\t} std;\n\t\tstruct {\n\t\t\tvoid      *(*_malloc)(size_t ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n\t\t\tvoid       (*_free)(void*  ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n\t\t\tvoid      *(*_realloc)(void*, size_t  ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n\t\t} debug;\n\t} custom_heap;\n#endif\n};\n\nstruct _zend_mm_chunk {\n\tzend_mm_heap      *heap;\n\tzend_mm_chunk     *next;\n\tzend_mm_chunk     *prev;\n\tint                free_pages;\t\t\t\t/* number of free pages */\n\tint                free_tail;               /* number of free pages at the end of chunk */\n\tint                num;\n\tchar               reserve[64 - (sizeof(void*) * 3 + sizeof(int) * 3)];\n\tzend_mm_heap       heap_slot;               /* used only in main chunk */\n\tzend_mm_page_map   free_map;                /* 512 bits or 64 bytes */\n\tzend_mm_page_info  map[ZEND_MM_PAGES];      /* 2 KB = 512 * 4 */\n};\n\nstruct _zend_mm_page {\n\tchar               bytes[ZEND_MM_PAGE_SIZE];\n};\n\n/*\n * bin - is one or few continuous pages (up to 8) used for allocation of\n * a particular \"small size\".\n */\nstruct _zend_mm_bin {\n\tchar               bytes[ZEND_MM_PAGE_SIZE * 8];\n};\n\nstruct _zend_mm_free_slot {\n\tzend_mm_free_slot *next_free_slot;\n};\n\nstruct _zend_mm_huge_list {\n\tvoid              *ptr;\n\tsize_t             size;\n\tzend_mm_huge_list *next;\n#if ZEND_DEBUG\n\tzend_mm_debug_info dbg;\n#endif\n};\n\n#define ZEND_MM_PAGE_ADDR(chunk, page_num) \\\n\t((void*)(((zend_mm_page*)(chunk)) + (page_num)))\n\n#define _BIN_DATA_SIZE(num, size, elements, pages, x, y) size,\nstatic const unsigned int bin_data_size[] = {\n  ZEND_MM_BINS_INFO(_BIN_DATA_SIZE, x, y)\n};\n\n#define _BIN_DATA_ELEMENTS(num, size, elements, pages, x, y) elements,\nstatic const int bin_elements[] = {\n  ZEND_MM_BINS_INFO(_BIN_DATA_ELEMENTS, x, y)\n};\n\n#define _BIN_DATA_PAGES(num, size, elements, pages, x, y) pages,\nstatic const int bin_pages[] = {\n  ZEND_MM_BINS_INFO(_BIN_DATA_PAGES, x, y)\n};\n\n#if ZEND_DEBUG\nZEND_COLD void zend_debug_alloc_output(char *format, ...)\n{\n\tchar output_buf[256];\n\tva_list args;\n\n\tva_start(args, format);\n\tvsprintf(output_buf, format, args);\n\tva_end(args);\n\n#ifdef ZEND_WIN32\n\tOutputDebugString(output_buf);\n#else\n\tfprintf(stderr, \"%s\", output_buf);\n#endif\n}\n#endif\n\nstatic ZEND_COLD ZEND_NORETURN void zend_mm_panic(const char *message)\n{\n\tfprintf(stderr, \"%s\\n\", message);\n/* See http://support.microsoft.com/kb/190351 */\n#ifdef ZEND_WIN32\n\tfflush(stderr);\n#endif\n#if ZEND_DEBUG && defined(HAVE_KILL) && defined(HAVE_GETPID)\n\tkill(getpid(), SIGSEGV);\n#endif\n\texit(1);\n}\n\nstatic ZEND_COLD ZEND_NORETURN void zend_mm_safe_error(zend_mm_heap *heap,\n\tconst char *format,\n\tsize_t limit,\n#if ZEND_DEBUG\n\tconst char *filename,\n\tuint lineno,\n#endif\n\tsize_t size)\n{\n\n\theap->overflow = 1;\n\tzend_try {\n\t\tzend_error_noreturn(E_ERROR,\n\t\t\tformat,\n\t\t\tlimit,\n#if ZEND_DEBUG\n\t\t\tfilename,\n\t\t\tlineno,\n#endif\n\t\t\tsize);\n\t} zend_catch {\n\t}  zend_end_try();\n\theap->overflow = 0;\n\tzend_bailout();\n\texit(1);\n}\n\n#ifdef _WIN32\nvoid\nstderr_last_error(char *msg)\n{\n\tLPSTR buf = NULL;\n\tDWORD err = GetLastError();\n\n\tif (!FormatMessage(\n\t\t\tFORMAT_MESSAGE_ALLOCATE_BUFFER |\n\t\t\tFORMAT_MESSAGE_FROM_SYSTEM |\n\t\t\tFORMAT_MESSAGE_IGNORE_INSERTS,\n\t\t\tNULL,\n\t\t\terr,\n\t\t\tMAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT),\n\t\t\t(LPSTR)&buf,\n\t\t0, NULL)) {\n\t\tfprintf(stderr, \"\\n%s: [0x%08lx]\\n\", msg, err);\n\t}\n\telse {\n\t\tfprintf(stderr, \"\\n%s: [0x%08lx] %s\\n\", msg, err, buf);\n\t}\n}\n#endif\n\n/*****************/\n/* OS Allocation */\n/*****************/\n\nstatic void *zend_mm_mmap_fixed(void *addr, size_t size)\n{\n#ifdef _WIN32\n\treturn VirtualAlloc(addr, size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE);\n#else\n\t/* MAP_FIXED leads to discarding of the old mapping, so it can't be used. */\n\tvoid *ptr = mmap(addr, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON /*| MAP_POPULATE | MAP_HUGETLB*/, -1, 0);\n\n\tif (ptr == MAP_FAILED) {\n#if ZEND_MM_ERROR\n\t\tfprintf(stderr, \"\\nmmap() failed: [%d] %s\\n\", errno, strerror(errno));\n#endif\n\t\treturn NULL;\n\t} else if (ptr != addr) {\n\t\tif (munmap(ptr, size) != 0) {\n#if ZEND_MM_ERROR\n\t\t\tfprintf(stderr, \"\\nmunmap() failed: [%d] %s\\n\", errno, strerror(errno));\n#endif\n\t\t}\n\t\treturn NULL;\n\t}\n\treturn ptr;\n#endif\n}\n\nstatic void *zend_mm_mmap(size_t size)\n{\n#ifdef _WIN32\n\tvoid *ptr = VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE);\n\n\tif (ptr == NULL) {\n#if ZEND_MM_ERROR\n\t\tstderr_last_error(\"VirtualAlloc() failed\");\n#endif\n\t\treturn NULL;\n\t}\n\treturn ptr;\n#else\n\tvoid *ptr;\n\n#ifdef MAP_HUGETLB\n\tif (zend_mm_use_huge_pages && size == ZEND_MM_CHUNK_SIZE) {\n\t\tptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON | MAP_HUGETLB, -1, 0);\n\t\tif (ptr != MAP_FAILED) {\n\t\t\treturn ptr;\n\t\t}\n\t}\n#endif\n\n\tptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);\n\n\tif (ptr == MAP_FAILED) {\n#if ZEND_MM_ERROR\n\t\tfprintf(stderr, \"\\nmmap() failed: [%d] %s\\n\", errno, strerror(errno));\n#endif\n\t\treturn NULL;\n\t}\n\treturn ptr;\n#endif\n}\n\nstatic void zend_mm_munmap(void *addr, size_t size)\n{\n#ifdef _WIN32\n\tif (VirtualFree(addr, 0, MEM_RELEASE) == 0) {\n#if ZEND_MM_ERROR\n\t\tstderr_last_error(\"VirtualFree() failed\");\n#endif\n\t}\n#else\n\tif (munmap(addr, size) != 0) {\n#if ZEND_MM_ERROR\n\t\tfprintf(stderr, \"\\nmunmap() failed: [%d] %s\\n\", errno, strerror(errno));\n#endif\n\t}\n#endif\n}\n\n/***********/\n/* Bitmask */\n/***********/\n\n/* number of trailing set (1) bits */\nstatic zend_always_inline int zend_mm_bitset_nts(zend_mm_bitset bitset)\n{\n#if (defined(__GNUC__) || __has_builtin(__builtin_ctzl)) && SIZEOF_ZEND_LONG == SIZEOF_LONG && defined(PHP_HAVE_BUILTIN_CTZL)\n\treturn __builtin_ctzl(~bitset);\n#elif (defined(__GNUC__) || __has_builtin(__builtin_ctzll)) && defined(PHP_HAVE_BUILTIN_CTZLL)\n\treturn __builtin_ctzll(~bitset);\n#elif defined(_WIN32)\n\tunsigned long index;\n\n#if defined(_WIN64)\n\tif (!BitScanForward64(&index, ~bitset)) {\n#else\n\tif (!BitScanForward(&index, ~bitset)) {\n#endif\n\t\t/* undefined behavior */\n\t\treturn 32;\n\t}\n\n\treturn (int)index;\n#else\n\tint n;\n\n\tif (bitset == (zend_mm_bitset)-1) return ZEND_MM_BITSET_LEN;\n\n\tn = 0;\n#if SIZEOF_ZEND_LONG == 8\n\tif (sizeof(zend_mm_bitset) == 8) {\n\t\tif ((bitset & 0xffffffff) == 0xffffffff) {n += 32; bitset = bitset >> Z_UL(32);}\n\t}\n#endif\n\tif ((bitset & 0x0000ffff) == 0x0000ffff) {n += 16; bitset = bitset >> 16;}\n\tif ((bitset & 0x000000ff) == 0x000000ff) {n +=  8; bitset = bitset >>  8;}\n\tif ((bitset & 0x0000000f) == 0x0000000f) {n +=  4; bitset = bitset >>  4;}\n\tif ((bitset & 0x00000003) == 0x00000003) {n +=  2; bitset = bitset >>  2;}\n\treturn n + (bitset & 1);\n#endif\n}\n\n/* number of trailing zero bits (0x01 -> 1; 0x40 -> 6; 0x00 -> LEN) */\nstatic zend_always_inline int zend_mm_bitset_ntz(zend_mm_bitset bitset)\n{\n#if (defined(__GNUC__) || __has_builtin(__builtin_ctzl)) && SIZEOF_ZEND_LONG == SIZEOF_LONG && defined(PHP_HAVE_BUILTIN_CTZL)\n\treturn __builtin_ctzl(bitset);\n#elif (defined(__GNUC__) || __has_builtin(__builtin_ctzll)) && defined(PHP_HAVE_BUILTIN_CTZLL)\n\treturn __builtin_ctzll(bitset);\n#elif defined(_WIN32)\n\tunsigned long index;\n\n#if defined(_WIN64)\n\tif (!BitScanForward64(&index, bitset)) {\n#else\n\tif (!BitScanForward(&index, bitset)) {\n#endif\n\t\t/* undefined behavior */\n\t\treturn 32;\n\t}\n\n\treturn (int)index;\n#else\n\tint n;\n\n\tif (bitset == (zend_mm_bitset)0) return ZEND_MM_BITSET_LEN;\n\n\tn = 1;\n#if SIZEOF_ZEND_LONG == 8\n\tif (sizeof(zend_mm_bitset) == 8) {\n\t\tif ((bitset & 0xffffffff) == 0) {n += 32; bitset = bitset >> Z_UL(32);}\n\t}\n#endif\n\tif ((bitset & 0x0000ffff) == 0) {n += 16; bitset = bitset >> 16;}\n\tif ((bitset & 0x000000ff) == 0) {n +=  8; bitset = bitset >>  8;}\n\tif ((bitset & 0x0000000f) == 0) {n +=  4; bitset = bitset >>  4;}\n\tif ((bitset & 0x00000003) == 0) {n +=  2; bitset = bitset >>  2;}\n\treturn n - (bitset & 1);\n#endif\n}\n\nstatic zend_always_inline int zend_mm_bitset_find_zero(zend_mm_bitset *bitset, int size)\n{\n\tint i = 0;\n\n\tdo {\n\t\tzend_mm_bitset tmp = bitset[i];\n\t\tif (tmp != (zend_mm_bitset)-1) {\n\t\t\treturn i * ZEND_MM_BITSET_LEN + zend_mm_bitset_nts(tmp);\n\t\t}\n\t\ti++;\n\t} while (i < size);\n\treturn -1;\n}\n\nstatic zend_always_inline int zend_mm_bitset_find_one(zend_mm_bitset *bitset, int size)\n{\n\tint i = 0;\n\n\tdo {\n\t\tzend_mm_bitset tmp = bitset[i];\n\t\tif (tmp != 0) {\n\t\t\treturn i * ZEND_MM_BITSET_LEN + zend_mm_bitset_ntz(tmp);\n\t\t}\n\t\ti++;\n\t} while (i < size);\n\treturn -1;\n}\n\nstatic zend_always_inline int zend_mm_bitset_find_zero_and_set(zend_mm_bitset *bitset, int size)\n{\n\tint i = 0;\n\n\tdo {\n\t\tzend_mm_bitset tmp = bitset[i];\n\t\tif (tmp != (zend_mm_bitset)-1) {\n\t\t\tint n = zend_mm_bitset_nts(tmp);\n\t\t\tbitset[i] |= Z_UL(1) << n;\n\t\t\treturn i * ZEND_MM_BITSET_LEN + n;\n\t\t}\n\t\ti++;\n\t} while (i < size);\n\treturn -1;\n}\n\nstatic zend_always_inline int zend_mm_bitset_is_set(zend_mm_bitset *bitset, int bit)\n{\n\treturn (bitset[bit / ZEND_MM_BITSET_LEN] & (Z_L(1) << (bit & (ZEND_MM_BITSET_LEN-1)))) != 0;\n}\n\nstatic zend_always_inline void zend_mm_bitset_set_bit(zend_mm_bitset *bitset, int bit)\n{\n\tbitset[bit / ZEND_MM_BITSET_LEN] |= (Z_L(1) << (bit & (ZEND_MM_BITSET_LEN-1)));\n}\n\nstatic zend_always_inline void zend_mm_bitset_reset_bit(zend_mm_bitset *bitset, int bit)\n{\n\tbitset[bit / ZEND_MM_BITSET_LEN] &= ~(Z_L(1) << (bit & (ZEND_MM_BITSET_LEN-1)));\n}\n\nstatic zend_always_inline void zend_mm_bitset_set_range(zend_mm_bitset *bitset, int start, int len)\n{\n\tif (len == 1) {\n\t\tzend_mm_bitset_set_bit(bitset, start);\n\t} else {\n\t\tint pos = start / ZEND_MM_BITSET_LEN;\n\t\tint end = (start + len - 1) / ZEND_MM_BITSET_LEN;\n\t\tint bit = start & (ZEND_MM_BITSET_LEN - 1);\n\t\tzend_mm_bitset tmp;\n\n\t\tif (pos != end) {\n\t\t\t/* set bits from \"bit\" to ZEND_MM_BITSET_LEN-1 */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\tbitset[pos++] |= tmp;\n\t\t\twhile (pos != end) {\n\t\t\t\t/* set all bits */\n\t\t\t\tbitset[pos++] = (zend_mm_bitset)-1;\n\t\t\t}\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* set bits from \"0\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\tbitset[pos] |= tmp;\n\t\t} else {\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* set bits from \"bit\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\ttmp &= (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\tbitset[pos] |= tmp;\n\t\t}\n\t}\n}\n\nstatic zend_always_inline void zend_mm_bitset_reset_range(zend_mm_bitset *bitset, int start, int len)\n{\n\tif (len == 1) {\n\t\tzend_mm_bitset_reset_bit(bitset, start);\n\t} else {\n\t\tint pos = start / ZEND_MM_BITSET_LEN;\n\t\tint end = (start + len - 1) / ZEND_MM_BITSET_LEN;\n\t\tint bit = start & (ZEND_MM_BITSET_LEN - 1);\n\t\tzend_mm_bitset tmp;\n\n\t\tif (pos != end) {\n\t\t\t/* reset bits from \"bit\" to ZEND_MM_BITSET_LEN-1 */\n\t\t\ttmp = ~((Z_L(1) << bit) - 1);\n\t\t\tbitset[pos++] &= ~tmp;\n\t\t\twhile (pos != end) {\n\t\t\t\t/* set all bits */\n\t\t\t\tbitset[pos++] = 0;\n\t\t\t}\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* reset bits from \"0\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\tbitset[pos] &= ~tmp;\n\t\t} else {\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* reset bits from \"bit\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\ttmp &= (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\tbitset[pos] &= ~tmp;\n\t\t}\n\t}\n}\n\nstatic zend_always_inline int zend_mm_bitset_is_free_range(zend_mm_bitset *bitset, int start, int len)\n{\n\tif (len == 1) {\n\t\treturn !zend_mm_bitset_is_set(bitset, start);\n\t} else {\n\t\tint pos = start / ZEND_MM_BITSET_LEN;\n\t\tint end = (start + len - 1) / ZEND_MM_BITSET_LEN;\n\t\tint bit = start & (ZEND_MM_BITSET_LEN - 1);\n\t\tzend_mm_bitset tmp;\n\n\t\tif (pos != end) {\n\t\t\t/* set bits from \"bit\" to ZEND_MM_BITSET_LEN-1 */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\tif ((bitset[pos++] & tmp) != 0) {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\twhile (pos != end) {\n\t\t\t\t/* set all bits */\n\t\t\t\tif (bitset[pos++] != 0) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* set bits from \"0\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\treturn (bitset[pos] & tmp) == 0;\n\t\t} else {\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* set bits from \"bit\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\ttmp &= (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\treturn (bitset[pos] & tmp) == 0;\n\t\t}\n\t}\n}\n\n/**********/\n/* Chunks */\n/**********/\n\nstatic void *zend_mm_chunk_alloc_int(size_t size, size_t alignment)\n{\n\tvoid *ptr = zend_mm_mmap(size);\n\n\tif (ptr == NULL) {\n\t\treturn NULL;\n\t} else if (ZEND_MM_ALIGNED_OFFSET(ptr, alignment) == 0) {\n#ifdef MADV_HUGEPAGE\n\t    madvise(ptr, size, MADV_HUGEPAGE);\n#endif\n\t\treturn ptr;\n\t} else {\n\t\tsize_t offset;\n\n\t\t/* chunk has to be aligned */\n\t\tzend_mm_munmap(ptr, size);\n\t\tptr = zend_mm_mmap(size + alignment - REAL_PAGE_SIZE);\n#ifdef _WIN32\n\t\toffset = ZEND_MM_ALIGNED_OFFSET(ptr, alignment);\n\t\tzend_mm_munmap(ptr, size + alignment - REAL_PAGE_SIZE);\n\t\tptr = zend_mm_mmap_fixed((void*)((char*)ptr + (alignment - offset)), size);\n\t\toffset = ZEND_MM_ALIGNED_OFFSET(ptr, alignment);\n\t\tif (offset != 0) {\n\t\t\tzend_mm_munmap(ptr, size);\n\t\t\treturn NULL;\n\t\t}\n\t\treturn ptr;\n#else\n\t\toffset = ZEND_MM_ALIGNED_OFFSET(ptr, alignment);\n\t\tif (offset != 0) {\n\t\t\toffset = alignment - offset;\n\t\t\tzend_mm_munmap(ptr, offset);\n\t\t\tptr = (char*)ptr + offset;\n\t\t\talignment -= offset;\n\t\t}\n\t\tif (alignment > REAL_PAGE_SIZE) {\n\t\t\tzend_mm_munmap((char*)ptr + size, alignment - REAL_PAGE_SIZE);\n\t\t}\n# ifdef MADV_HUGEPAGE\n\t    madvise(ptr, size, MADV_HUGEPAGE);\n# endif\n#endif\n\t\treturn ptr;\n\t}\n}\n\nstatic void *zend_mm_chunk_alloc(zend_mm_heap *heap, size_t size, size_t alignment)\n{\n#if ZEND_MM_STORAGE\n\tif (UNEXPECTED(heap->storage)) {\n\t\tvoid *ptr = heap->storage->handlers.chunk_alloc(heap->storage, size, alignment);\n\t\tZEND_ASSERT(((zend_uintptr_t)((char*)ptr + (alignment-1)) & (alignment-1)) == (zend_uintptr_t)ptr);\n\t\treturn ptr;\n\t}\n#endif\n\treturn zend_mm_chunk_alloc_int(size, alignment);\n}\n\nstatic void zend_mm_chunk_free(zend_mm_heap *heap, void *addr, size_t size)\n{\n#if ZEND_MM_STORAGE\n\tif (UNEXPECTED(heap->storage)) {\n\t\theap->storage->handlers.chunk_free(heap->storage, addr, size);\n\t\treturn;\n\t}\n#endif\n\tzend_mm_munmap(addr, size);\n}\n\nstatic int zend_mm_chunk_truncate(zend_mm_heap *heap, void *addr, size_t old_size, size_t new_size)\n{\n#if ZEND_MM_STORAGE\n\tif (UNEXPECTED(heap->storage)) {\n\t\tif (heap->storage->handlers.chunk_truncate) {\n\t\t\treturn heap->storage->handlers.chunk_truncate(heap->storage, addr, old_size, new_size);\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n#ifndef _WIN32\n\tzend_mm_munmap((char*)addr + new_size, old_size - new_size);\n\treturn 1;\n#else\n\treturn 0;\n#endif\n}\n\nstatic int zend_mm_chunk_extend(zend_mm_heap *heap, void *addr, size_t old_size, size_t new_size)\n{\n#if ZEND_MM_STORAGE\n\tif (UNEXPECTED(heap->storage)) {\n\t\tif (heap->storage->handlers.chunk_extend) {\n\t\t\treturn heap->storage->handlers.chunk_extend(heap->storage, addr, old_size, new_size);\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n#ifndef _WIN32\n\treturn (zend_mm_mmap_fixed((char*)addr + old_size, new_size - old_size) != NULL);\n#else\n\treturn 0;\n#endif\n}\n\nstatic zend_always_inline void zend_mm_chunk_init(zend_mm_heap *heap, zend_mm_chunk *chunk)\n{\n\tchunk->heap = heap;\n\tchunk->next = heap->main_chunk;\n\tchunk->prev = heap->main_chunk->prev;\n\tchunk->prev->next = chunk;\n\tchunk->next->prev = chunk;\n\t/* mark first pages as allocated */\n\tchunk->free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\tchunk->free_tail = ZEND_MM_FIRST_PAGE;\n\t/* the younger chunks have bigger number */\n\tchunk->num = chunk->prev->num + 1;\n\t/* mark first pages as allocated */\n\tchunk->free_map[0] = (1L << ZEND_MM_FIRST_PAGE) - 1;\n\tchunk->map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE);\n}\n\n/***********************/\n/* Huge Runs (forward) */\n/***********************/\n\nstatic size_t zend_mm_get_huge_block_size(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\nstatic void *zend_mm_alloc_huge(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\nstatic void zend_mm_free_huge(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n\n#if ZEND_DEBUG\nstatic void zend_mm_change_huge_block_size(zend_mm_heap *heap, void *ptr, size_t size, size_t dbg_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n#else\nstatic void zend_mm_change_huge_block_size(zend_mm_heap *heap, void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n#endif\n\n/**************/\n/* Large Runs */\n/**************/\n\n#if ZEND_DEBUG\nstatic void *zend_mm_alloc_pages(zend_mm_heap *heap, int pages_count, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#else\nstatic void *zend_mm_alloc_pages(zend_mm_heap *heap, int pages_count ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#endif\n{\n\tzend_mm_chunk *chunk = heap->main_chunk;\n\tint page_num, len;\n\n\twhile (1) {\n\t\tif (UNEXPECTED(chunk->free_pages < pages_count)) {\n\t\t\tgoto not_found;\n#if 0\n\t\t} else if (UNEXPECTED(chunk->free_pages + chunk->free_tail == ZEND_MM_PAGES)) {\n\t\t\tif (UNEXPECTED(ZEND_MM_PAGES - chunk->free_tail < pages_count)) {\n\t\t\t\tgoto not_found;\n\t\t\t} else {\n\t\t\t\tpage_num = chunk->free_tail;\n\t\t\t\tgoto found;\n\t\t\t}\n\t\t} else if (0) {\n\t\t\t/* First-Fit Search */\n\t\t\tint free_tail = chunk->free_tail;\n\t\t\tzend_mm_bitset *bitset = chunk->free_map;\n\t\t\tzend_mm_bitset tmp = *(bitset++);\n\t\t\tint i = 0;\n\n\t\t\twhile (1) {\n\t\t\t\t/* skip allocated blocks */\n\t\t\t\twhile (tmp == (zend_mm_bitset)-1) {\n\t\t\t\t\ti += ZEND_MM_BITSET_LEN;\n\t\t\t\t\tif (i == ZEND_MM_PAGES) {\n\t\t\t\t\t\tgoto not_found;\n\t\t\t\t\t}\n\t\t\t\t\ttmp = *(bitset++);\n\t\t\t\t}\n\t\t\t\t/* find first 0 bit */\n\t\t\t\tpage_num = i + zend_mm_bitset_nts(tmp);\n\t\t\t\t/* reset bits from 0 to \"bit\" */\n\t\t\t\ttmp &= tmp + 1;\n\t\t\t\t/* skip free blocks */\n\t\t\t\twhile (tmp == 0) {\n\t\t\t\t\ti += ZEND_MM_BITSET_LEN;\n\t\t\t\t\tlen = i - page_num;\n\t\t\t\t\tif (len >= pages_count) {\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\t} else if (i >= free_tail) {\n\t\t\t\t\t\tgoto not_found;\n\t\t\t\t\t}\n\t\t\t\t\ttmp = *(bitset++);\n\t\t\t\t}\n\t\t\t\t/* find first 1 bit */\n\t\t\t\tlen = (i + zend_mm_bitset_ntz(tmp)) - page_num;\n\t\t\t\tif (len >= pages_count) {\n\t\t\t\t\tgoto found;\n\t\t\t\t}\n\t\t\t\t/* set bits from 0 to \"bit\" */\n\t\t\t\ttmp |= tmp - 1;\n\t\t\t}\n#endif\n\t\t} else {\n\t\t\t/* Best-Fit Search */\n\t\t\tint best = -1;\n\t\t\tint best_len = ZEND_MM_PAGES;\n\t\t\tint free_tail = chunk->free_tail;\n\t\t\tzend_mm_bitset *bitset = chunk->free_map;\n\t\t\tzend_mm_bitset tmp = *(bitset++);\n\t\t\tint i = 0;\n\n\t\t\twhile (1) {\n\t\t\t\t/* skip allocated blocks */\n\t\t\t\twhile (tmp == (zend_mm_bitset)-1) {\n\t\t\t\t\ti += ZEND_MM_BITSET_LEN;\n\t\t\t\t\tif (i == ZEND_MM_PAGES) {\n\t\t\t\t\t\tif (best > 0) {\n\t\t\t\t\t\t\tpage_num = best;\n\t\t\t\t\t\t\tgoto found;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tgoto not_found;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttmp = *(bitset++);\n\t\t\t\t}\n\t\t\t\t/* find first 0 bit */\n\t\t\t\tpage_num = i + zend_mm_bitset_nts(tmp);\n\t\t\t\t/* reset bits from 0 to \"bit\" */\n\t\t\t\ttmp &= tmp + 1;\n\t\t\t\t/* skip free blocks */\n\t\t\t\twhile (tmp == 0) {\n\t\t\t\t\ti += ZEND_MM_BITSET_LEN;\n\t\t\t\t\tif (i >= free_tail || i == ZEND_MM_PAGES) {\n\t\t\t\t\t\tlen = ZEND_MM_PAGES - page_num;\n\t\t\t\t\t\tif (len >= pages_count && len < best_len) {\n\t\t\t\t\t\t\tchunk->free_tail = page_num + pages_count;\n\t\t\t\t\t\t\tgoto found;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t/* set accurate value */\n\t\t\t\t\t\t\tchunk->free_tail = page_num;\n\t\t\t\t\t\t\tif (best > 0) {\n\t\t\t\t\t\t\t\tpage_num = best;\n\t\t\t\t\t\t\t\tgoto found;\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tgoto not_found;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttmp = *(bitset++);\n\t\t\t\t}\n\t\t\t\t/* find first 1 bit */\n\t\t\t\tlen = i + zend_mm_bitset_ntz(tmp) - page_num;\n\t\t\t\tif (len >= pages_count) {\n\t\t\t\t\tif (len == pages_count) {\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\t} else if (len < best_len) {\n\t\t\t\t\t\tbest_len = len;\n\t\t\t\t\t\tbest = page_num;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/* set bits from 0 to \"bit\" */\n\t\t\t\ttmp |= tmp - 1;\n\t\t\t}\n\t\t}\n\nnot_found:\n\t\tif (chunk->next == heap->main_chunk) {\nget_chunk:\n\t\t\tif (heap->cached_chunks) {\n\t\t\t\theap->cached_chunks_count--;\n\t\t\t\tchunk = heap->cached_chunks;\n\t\t\t\theap->cached_chunks = chunk->next;\n\t\t\t} else {\n#if ZEND_MM_LIMIT\n\t\t\t\tif (UNEXPECTED(heap->real_size + ZEND_MM_CHUNK_SIZE > heap->limit)) {\n\t\t\t\t\tif (zend_mm_gc(heap)) {\n\t\t\t\t\t\tgoto get_chunk;\n\t\t\t\t\t} else if (heap->overflow == 0) {\n#if ZEND_DEBUG\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted at %s:%d (tried to allocate %zu bytes)\", heap->limit, __zend_filename, __zend_lineno, size);\n#else\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted (tried to allocate %zu bytes)\", heap->limit, ZEND_MM_PAGE_SIZE * pages_count);\n#endif\n\t\t\t\t\t\treturn NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n#endif\n\t\t\t\tchunk = (zend_mm_chunk*)zend_mm_chunk_alloc(heap, ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE);\n\t\t\t\tif (UNEXPECTED(chunk == NULL)) {\n\t\t\t\t\t/* insufficient memory */\n\t\t\t\t\tif (zend_mm_gc(heap) &&\n\t\t\t\t\t    (chunk = (zend_mm_chunk*)zend_mm_chunk_alloc(heap, ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE)) != NULL) {\n\t\t\t\t\t\t/* pass */\n\t\t\t\t\t} else {\n#if !ZEND_MM_LIMIT\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Out of memory\");\n#elif ZEND_DEBUG\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Out of memory (allocated %zu) at %s:%d (tried to allocate %zu bytes)\", heap->real_size, __zend_filename, __zend_lineno, size);\n#else\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Out of memory (allocated %zu) (tried to allocate %zu bytes)\", heap->real_size, ZEND_MM_PAGE_SIZE * pages_count);\n#endif\n\t\t\t\t\t\treturn NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n#if ZEND_MM_STAT\n\t\t\t\tdo {\n\t\t\t\t\tsize_t size = heap->real_size + ZEND_MM_CHUNK_SIZE;\n\t\t\t\t\tsize_t peak = MAX(heap->real_peak, size);\n\t\t\t\t\theap->real_size = size;\n\t\t\t\t\theap->real_peak = peak;\n\t\t\t\t} while (0);\n#elif ZEND_MM_LIMIT\n\t\t\t\theap->real_size += ZEND_MM_CHUNK_SIZE;\n\n#endif\n\t\t\t}\n\t\t\theap->chunks_count++;\n\t\t\tif (heap->chunks_count > heap->peak_chunks_count) {\n\t\t\t\theap->peak_chunks_count = heap->chunks_count;\n\t\t\t}\n\t\t\tzend_mm_chunk_init(heap, chunk);\n\t\t\tpage_num = ZEND_MM_FIRST_PAGE;\n\t\t\tlen = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\t\t\tgoto found;\n\t\t} else {\n\t\t\tchunk = chunk->next;\n\t\t}\n\t}\n\nfound:\n\t/* mark run as allocated */\n\tchunk->free_pages -= pages_count;\n\tzend_mm_bitset_set_range(chunk->free_map, page_num, pages_count);\n\tchunk->map[page_num] = ZEND_MM_LRUN(pages_count);\n\tif (page_num == chunk->free_tail) {\n\t\tchunk->free_tail = page_num + pages_count;\n\t}\n\treturn ZEND_MM_PAGE_ADDR(chunk, page_num);\n}\n\nstatic zend_always_inline void *zend_mm_alloc_large(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tint pages_count = (int)ZEND_MM_SIZE_TO_NUM(size, ZEND_MM_PAGE_SIZE);\n#if ZEND_DEBUG\n\tvoid *ptr = zend_mm_alloc_pages(heap, pages_count, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\tvoid *ptr = zend_mm_alloc_pages(heap, pages_count ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n#if ZEND_MM_STAT\n\tdo {\n\t\tsize_t size = heap->size + pages_count * ZEND_MM_PAGE_SIZE;\n\t\tsize_t peak = MAX(heap->peak, size);\n\t\theap->size = size;\n\t\theap->peak = peak;\n\t} while (0);\n#endif\n\treturn ptr;\n}\n\nstatic zend_always_inline void zend_mm_delete_chunk(zend_mm_heap *heap, zend_mm_chunk *chunk)\n{\n\tchunk->next->prev = chunk->prev;\n\tchunk->prev->next = chunk->next;\n\theap->chunks_count--;\n\tif (heap->chunks_count + heap->cached_chunks_count < heap->avg_chunks_count + 0.1) {\n\t\t/* delay deletion */\n\t\theap->cached_chunks_count++;\n\t\tchunk->next = heap->cached_chunks;\n\t\theap->cached_chunks = chunk;\n\t} else {\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\t\theap->real_size -= ZEND_MM_CHUNK_SIZE;\n#endif\n\t\tif (!heap->cached_chunks || chunk->num > heap->cached_chunks->num) {\n\t\t\tzend_mm_chunk_free(heap, chunk, ZEND_MM_CHUNK_SIZE);\n\t\t} else {\n//TODO: select the best chunk to delete???\n\t\t\tchunk->next = heap->cached_chunks->next;\n\t\t\tzend_mm_chunk_free(heap, heap->cached_chunks, ZEND_MM_CHUNK_SIZE);\n\t\t\theap->cached_chunks = chunk;\n\t\t}\n\t}\n}\n\nstatic zend_always_inline void zend_mm_free_pages_ex(zend_mm_heap *heap, zend_mm_chunk *chunk, int page_num, int pages_count, int free_chunk)\n{\n\tchunk->free_pages += pages_count;\n\tzend_mm_bitset_reset_range(chunk->free_map, page_num, pages_count);\n\tchunk->map[page_num] = 0;\n\tif (chunk->free_tail == page_num + pages_count) {\n\t\t/* this setting may be not accurate */\n\t\tchunk->free_tail = page_num;\n\t}\n\tif (free_chunk && chunk->free_pages == ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE) {\n\t\tzend_mm_delete_chunk(heap, chunk);\n\t}\n}\n\nstatic void zend_mm_free_pages(zend_mm_heap *heap, zend_mm_chunk *chunk, int page_num, int pages_count)\n{\n\tzend_mm_free_pages_ex(heap, chunk, page_num, pages_count, 1);\n}\n\nstatic zend_always_inline void zend_mm_free_large(zend_mm_heap *heap, zend_mm_chunk *chunk, int page_num, int pages_count)\n{\n#if ZEND_MM_STAT\n\theap->size -= pages_count * ZEND_MM_PAGE_SIZE;\n#endif\n\tzend_mm_free_pages(heap, chunk, page_num, pages_count);\n}\n\n/**************/\n/* Small Runs */\n/**************/\n\n/* higher set bit number (0->N/A, 1->1, 2->2, 4->3, 8->4, 127->7, 128->8 etc) */\nstatic zend_always_inline int zend_mm_small_size_to_bit(int size)\n{\n#if (defined(__GNUC__) || __has_builtin(__builtin_clz))  && defined(PHP_HAVE_BUILTIN_CLZ)\n\treturn (__builtin_clz(size) ^ 0x1f) + 1;\n#elif defined(_WIN32)\n\tunsigned long index;\n\n\tif (!BitScanReverse(&index, (unsigned long)size)) {\n\t\t/* undefined behavior */\n\t\treturn 64;\n\t}\n\n\treturn (((31 - (int)index) ^ 0x1f) + 1);\n#else\n\tint n = 16;\n\tif (size <= 0x00ff) {n -= 8; size = size << 8;}\n\tif (size <= 0x0fff) {n -= 4; size = size << 4;}\n\tif (size <= 0x3fff) {n -= 2; size = size << 2;}\n\tif (size <= 0x7fff) {n -= 1;}\n\treturn n;\n#endif\n}\n\n#ifndef MAX\n# define MAX(a, b) (((a) > (b)) ? (a) : (b))\n#endif\n\n#ifndef MIN\n# define MIN(a, b) (((a) < (b)) ? (a) : (b))\n#endif\n\nstatic zend_always_inline int zend_mm_small_size_to_bin(size_t size)\n{\n#if 0\n\tint n;\n                            /*0,  1,  2,  3,  4,  5,  6,  7,  8,  9  10, 11, 12*/\n\tstatic const int f1[] = { 3,  3,  3,  3,  3,  3,  3,  4,  5,  6,  7,  8,  9};\n\tstatic const int f2[] = { 0,  0,  0,  0,  0,  0,  0,  4,  8, 12, 16, 20, 24};\n\n\tif (UNEXPECTED(size <= 2)) return 0;\n\tn = zend_mm_small_size_to_bit(size - 1);\n\treturn ((size-1) >> f1[n]) + f2[n];\n#else\n\tunsigned int t1, t2;\n\n\tif (size <= 64) {\n\t\t/* we need to support size == 0 ... */\n\t\treturn (size - !!size) >> 3;\n\t} else {\n\t\tt1 = size - 1;\n\t\tt2 = zend_mm_small_size_to_bit(t1) - 3;\n\t\tt1 = t1 >> t2;\n\t\tt2 = t2 - 3;\n\t\tt2 = t2 << 2;\n\t\treturn (int)(t1 + t2);\n\t}\n#endif\n}\n\n#define ZEND_MM_SMALL_SIZE_TO_BIN(size)  zend_mm_small_size_to_bin(size)\n\nstatic zend_never_inline void *zend_mm_alloc_small_slow(zend_mm_heap *heap, int bin_num ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n    zend_mm_chunk *chunk;\n    int page_num;\n\tzend_mm_bin *bin;\n\tzend_mm_free_slot *p, *end;\n\n#if ZEND_DEBUG\n\tbin = (zend_mm_bin*)zend_mm_alloc_pages(heap, bin_pages[bin_num], bin_data_size[bin_num] ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\tbin = (zend_mm_bin*)zend_mm_alloc_pages(heap, bin_pages[bin_num] ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n\tif (UNEXPECTED(bin == NULL)) {\n\t\t/* insufficient memory */\n\t\treturn NULL;\n\t}\n\n\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(bin, ZEND_MM_CHUNK_SIZE);\n\tpage_num = ZEND_MM_ALIGNED_OFFSET(bin, ZEND_MM_CHUNK_SIZE) / ZEND_MM_PAGE_SIZE;\n\tchunk->map[page_num] = ZEND_MM_SRUN(bin_num);\n\tif (bin_pages[bin_num] > 1) {\n\t\tint i = 1;\n\t\tdo {\n\t\t\tchunk->map[page_num+i] = ZEND_MM_NRUN(bin_num, i);\n\t\t\ti++;\n\t\t} while (i < bin_pages[bin_num]);\n\t}\n\n\t/* create a linked list of elements from 1 to last */\n\tend = (zend_mm_free_slot*)((char*)bin + (bin_data_size[bin_num] * (bin_elements[bin_num] - 1)));\n\theap->free_slot[bin_num] = p = (zend_mm_free_slot*)((char*)bin + bin_data_size[bin_num]);\n\tdo {\n\t\tp->next_free_slot = (zend_mm_free_slot*)((char*)p + bin_data_size[bin_num]);;\n#if ZEND_DEBUG\n\t\tdo {\n\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t\t\tdbg->size = 0;\n\t\t} while (0);\n#endif\n\t\tp = (zend_mm_free_slot*)((char*)p + bin_data_size[bin_num]);\n\t} while (p != end);\n\n\t/* terminate list using NULL */\n\tp->next_free_slot = NULL;\n#if ZEND_DEBUG\n\t\tdo {\n\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t\t\tdbg->size = 0;\n\t\t} while (0);\n#endif\n\n\t/* return first element */\n\treturn (char*)bin;\n}\n\nstatic zend_always_inline void *zend_mm_alloc_small(zend_mm_heap *heap, size_t size, int bin_num ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n#if ZEND_MM_STAT\n\tdo {\n\t\tsize_t size = heap->size + bin_data_size[bin_num];\n\t\tsize_t peak = MAX(heap->peak, size);\n\t\theap->size = size;\n\t\theap->peak = peak;\n\t} while (0);\n#endif\n\n\tif (EXPECTED(heap->free_slot[bin_num] != NULL)) {\n\t\tzend_mm_free_slot *p = heap->free_slot[bin_num];\n\t\theap->free_slot[bin_num] = p->next_free_slot;\n\t\treturn (void*)p;\n\t} else {\n\t\treturn zend_mm_alloc_small_slow(heap, bin_num ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t}\n}\n\nstatic zend_always_inline void zend_mm_free_small(zend_mm_heap *heap, void *ptr, int bin_num)\n{\n\tzend_mm_free_slot *p;\n\n#if ZEND_MM_STAT\n\theap->size -= bin_data_size[bin_num];\n#endif\n\n#if ZEND_DEBUG\n\tdo {\n\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)ptr + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t\tdbg->size = 0;\n\t} while (0);\n#endif\n\n    p = (zend_mm_free_slot*)ptr;\n    p->next_free_slot = heap->free_slot[bin_num];\n    heap->free_slot[bin_num] = p;\n}\n\n/********/\n/* Heap */\n/********/\n\n#if ZEND_DEBUG\nstatic zend_always_inline zend_mm_debug_info *zend_mm_get_debug_info(zend_mm_heap *heap, void *ptr)\n{\n\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\tzend_mm_chunk *chunk;\n\tint page_num;\n\tzend_mm_page_info info;\n\n\tZEND_MM_CHECK(page_offset != 0, \"zend_mm_heap corrupted\");\n\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\tpage_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\tinfo = chunk->map[page_num];\n\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\tif (EXPECTED(info & ZEND_MM_IS_SRUN)) {\n\t\tint bin_num = ZEND_MM_SRUN_BIN_NUM(info);\n\t\treturn (zend_mm_debug_info*)((char*)ptr + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t} else /* if (info & ZEND_MM_IS_LRUN) */ {\n\t\tint pages_count = ZEND_MM_LRUN_PAGES(info);\n\n\t\treturn (zend_mm_debug_info*)((char*)ptr + ZEND_MM_PAGE_SIZE * pages_count - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t}\n}\n#endif\n\nstatic zend_always_inline void *zend_mm_alloc_heap(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tvoid *ptr;\n#if ZEND_DEBUG\n\tsize_t real_size = size;\n\tzend_mm_debug_info *dbg;\n\n\t/* special handling for zero-size allocation */\n\tsize = MAX(size, 1);\n\tsize = ZEND_MM_ALIGNED_SIZE(size) + ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info));\n\tif (UNEXPECTED(size < real_size)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu + %zu)\", ZEND_MM_ALIGNED_SIZE(real_size), ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t\treturn NULL;\n\t}\n#endif\n\tif (size <= ZEND_MM_MAX_SMALL_SIZE) {\n\t\tptr = zend_mm_alloc_small(heap, size, ZEND_MM_SMALL_SIZE_TO_BIN(size) ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#if ZEND_DEBUG\n\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\tdbg->size = real_size;\n\t\tdbg->filename = __zend_filename;\n\t\tdbg->orig_filename = __zend_orig_filename;\n\t\tdbg->lineno = __zend_lineno;\n\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\treturn ptr;\n\t} else if (size <= ZEND_MM_MAX_LARGE_SIZE) {\n\t\tptr = zend_mm_alloc_large(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#if ZEND_DEBUG\n\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\tdbg->size = real_size;\n\t\tdbg->filename = __zend_filename;\n\t\tdbg->orig_filename = __zend_orig_filename;\n\t\tdbg->lineno = __zend_lineno;\n\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\treturn ptr;\n\t} else {\n#if ZEND_DEBUG\n\t\tsize = real_size;\n#endif\n\t\treturn zend_mm_alloc_huge(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t}\n}\n\nstatic zend_always_inline void zend_mm_free_heap(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\n\tif (UNEXPECTED(page_offset == 0)) {\n\t\tif (ptr != NULL) {\n\t\t\tzend_mm_free_huge(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t}\n\t} else {\n\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tint page_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\tzend_mm_page_info info = chunk->map[page_num];\n\n\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\tif (EXPECTED(info & ZEND_MM_IS_SRUN)) {\n\t\t\tzend_mm_free_small(heap, ptr, ZEND_MM_SRUN_BIN_NUM(info));\n\t\t} else /* if (info & ZEND_MM_IS_LRUN) */ {\n\t\t\tint pages_count = ZEND_MM_LRUN_PAGES(info);\n\n\t\t\tZEND_MM_CHECK(ZEND_MM_ALIGNED_OFFSET(page_offset, ZEND_MM_PAGE_SIZE) == 0, \"zend_mm_heap corrupted\");\n\t\t\tzend_mm_free_large(heap, chunk, page_num, pages_count);\n\t\t}\n\t}\n}\n\nstatic size_t zend_mm_size(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\n\tif (UNEXPECTED(page_offset == 0)) {\n\t\treturn zend_mm_get_huge_block_size(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t} else {\n\t\tzend_mm_chunk *chunk;\n#if 0 && ZEND_DEBUG\n\t\tzend_mm_debug_info *dbg = zend_mm_get_debug_info(heap, ptr);\n\t\treturn dbg->size;\n#else\n\t\tint page_num;\n\t\tzend_mm_page_info info;\n\n\t\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tpage_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\tinfo = chunk->map[page_num];\n\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\tif (EXPECTED(info & ZEND_MM_IS_SRUN)) {\n\t\t\treturn bin_data_size[ZEND_MM_SRUN_BIN_NUM(info)];\n\t\t} else /* if (info & ZEND_MM_IS_LARGE_RUN) */ {\n\t\t\treturn ZEND_MM_LRUN_PAGES(info) * ZEND_MM_PAGE_SIZE;\n\t\t}\n#endif\n\t}\n}\n\nstatic void *zend_mm_realloc_heap(zend_mm_heap *heap, void *ptr, size_t size, size_t copy_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t page_offset;\n\tsize_t old_size;\n\tsize_t new_size;\n\tvoid *ret;\n#if ZEND_DEBUG\n\tsize_t real_size;\n\tzend_mm_debug_info *dbg;\n#endif\n\n\tpage_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\tif (UNEXPECTED(page_offset == 0)) {\n\t\tif (UNEXPECTED(ptr == NULL)) {\n\t\t\treturn zend_mm_alloc_heap(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t}\n\t\told_size = zend_mm_get_huge_block_size(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#if ZEND_DEBUG\n\t\treal_size = size;\n\t\tsize = ZEND_MM_ALIGNED_SIZE(size) + ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info));\n#endif\n\t\tif (size > ZEND_MM_MAX_LARGE_SIZE) {\n#if ZEND_DEBUG\n\t\t\tsize = real_size;\n#endif\n#ifdef ZEND_WIN32\n\t\t\t/* On Windows we don't have ability to extend huge blocks in-place.\n\t\t\t * We allocate them with 2MB size granularity, to avoid many \n\t\t\t * reallocations when they are extended by small pieces\n\t\t\t */\n\t\t\tnew_size = ZEND_MM_ALIGNED_SIZE_EX(size, MAX(REAL_PAGE_SIZE, ZEND_MM_CHUNK_SIZE));\n#else\n\t\t\tnew_size = ZEND_MM_ALIGNED_SIZE_EX(size, REAL_PAGE_SIZE);\n#endif\n\t\t\tif (new_size == old_size) {\n#if ZEND_DEBUG\n\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size, real_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n\t\t\t\treturn ptr;\n\t\t\t} else if (new_size < old_size) {\n\t\t\t\t/* unmup tail */\n\t\t\t\tif (zend_mm_chunk_truncate(heap, ptr, old_size, new_size)) {\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\t\t\t\t\theap->real_size -= old_size - new_size;\n#endif\n#if ZEND_MM_STAT\n\t\t\t\t\theap->size -= old_size - new_size;\n#endif\n#if ZEND_DEBUG\n\t\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size, real_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\t\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t}\n\t\t\t} else /* if (new_size > old_size) */ {\n#if ZEND_MM_LIMIT\n\t\t\t\tif (UNEXPECTED(heap->real_size + (new_size - old_size) > heap->limit)) {\n\t\t\t\t\tif (zend_mm_gc(heap) && heap->real_size + (new_size - old_size) <= heap->limit) {\n\t\t\t\t\t\t/* pass */\n\t\t\t\t\t} else if (heap->overflow == 0) {\n#if ZEND_DEBUG\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted at %s:%d (tried to allocate %zu bytes)\", heap->limit, __zend_filename, __zend_lineno, size);\n#else\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted (tried to allocate %zu bytes)\", heap->limit, size);\n#endif\n\t\t\t\t\t\treturn NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n#endif\n\t\t\t\t/* try to map tail right after this block */\n\t\t\t\tif (zend_mm_chunk_extend(heap, ptr, old_size, new_size)) {\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\t\t\t\t\theap->real_size += new_size - old_size;\n#endif\n#if ZEND_MM_STAT\n\t\t\t\t\theap->real_peak = MAX(heap->real_peak, heap->real_size);\n\t\t\t\t\theap->size += new_size - old_size;\n\t\t\t\t\theap->peak = MAX(heap->peak, heap->size);\n#endif\n#if ZEND_DEBUG\n\t\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size, real_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\t\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tint page_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\tzend_mm_page_info info = chunk->map[page_num];\n#if ZEND_DEBUG\n\t\tsize_t real_size = size;\n\n\t\tsize = ZEND_MM_ALIGNED_SIZE(size) + ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info));\n#endif\n\n\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\tif (info & ZEND_MM_IS_SRUN) {\n\t\t\tint old_bin_num, bin_num;\n\n\t\t\told_bin_num = ZEND_MM_SRUN_BIN_NUM(info);\n\t\t\told_size = bin_data_size[old_bin_num];\n\t\t\tbin_num = ZEND_MM_SMALL_SIZE_TO_BIN(size);\n\t\t\tif (old_bin_num == bin_num) {\n#if ZEND_DEBUG\n\t\t\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\t\t\tdbg->size = real_size;\n\t\t\t\tdbg->filename = __zend_filename;\n\t\t\t\tdbg->orig_filename = __zend_orig_filename;\n\t\t\t\tdbg->lineno = __zend_lineno;\n\t\t\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\t\treturn ptr;\n\t\t\t}\n\t\t} else /* if (info & ZEND_MM_IS_LARGE_RUN) */ {\n\t\t\tZEND_MM_CHECK(ZEND_MM_ALIGNED_OFFSET(page_offset, ZEND_MM_PAGE_SIZE) == 0, \"zend_mm_heap corrupted\");\n\t\t\told_size = ZEND_MM_LRUN_PAGES(info) * ZEND_MM_PAGE_SIZE;\n\t\t\tif (size > ZEND_MM_MAX_SMALL_SIZE && size <= ZEND_MM_MAX_LARGE_SIZE) {\n\t\t\t\tnew_size = ZEND_MM_ALIGNED_SIZE_EX(size, ZEND_MM_PAGE_SIZE);\n\t\t\t\tif (new_size == old_size) {\n#if ZEND_DEBUG\n\t\t\t\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\t\t\t\tdbg->size = real_size;\n\t\t\t\t\tdbg->filename = __zend_filename;\n\t\t\t\t\tdbg->orig_filename = __zend_orig_filename;\n\t\t\t\t\tdbg->lineno = __zend_lineno;\n\t\t\t\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t} else if (new_size < old_size) {\n\t\t\t\t\t/* free tail pages */\n\t\t\t\t\tint new_pages_count = (int)(new_size / ZEND_MM_PAGE_SIZE);\n\t\t\t\t\tint rest_pages_count = (int)((old_size - new_size) / ZEND_MM_PAGE_SIZE);\n\n#if ZEND_MM_STAT\n\t\t\t\t\theap->size -= rest_pages_count * ZEND_MM_PAGE_SIZE;\n#endif\n\t\t\t\t\tchunk->map[page_num] = ZEND_MM_LRUN(new_pages_count);\n\t\t\t\t\tchunk->free_pages += rest_pages_count;\n\t\t\t\t\tzend_mm_bitset_reset_range(chunk->free_map, page_num + new_pages_count, rest_pages_count);\n#if ZEND_DEBUG\n\t\t\t\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\t\t\t\tdbg->size = real_size;\n\t\t\t\t\tdbg->filename = __zend_filename;\n\t\t\t\t\tdbg->orig_filename = __zend_orig_filename;\n\t\t\t\t\tdbg->lineno = __zend_lineno;\n\t\t\t\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t} else /* if (new_size > old_size) */ {\n\t\t\t\t\tint new_pages_count = (int)(new_size / ZEND_MM_PAGE_SIZE);\n\t\t\t\t\tint old_pages_count = (int)(old_size / ZEND_MM_PAGE_SIZE);\n\n\t\t\t\t\t/* try to allocate tail pages after this block */\n\t\t\t\t\tif (page_num + new_pages_count <= ZEND_MM_PAGES &&\n\t\t\t\t\t    zend_mm_bitset_is_free_range(chunk->free_map, page_num + old_pages_count, new_pages_count - old_pages_count)) {\n#if ZEND_MM_STAT\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tsize_t size = heap->size + (new_size - old_size);\n\t\t\t\t\t\t\tsize_t peak = MAX(heap->peak, size);\n\t\t\t\t\t\t\theap->size = size;\n\t\t\t\t\t\t\theap->peak = peak;\n\t\t\t\t\t\t} while (0);\n#endif\n\t\t\t\t\t\tchunk->free_pages -= new_pages_count - old_pages_count;\n\t\t\t\t\t\tzend_mm_bitset_set_range(chunk->free_map, page_num + old_pages_count, new_pages_count - old_pages_count);\n\t\t\t\t\t\tchunk->map[page_num] = ZEND_MM_LRUN(new_pages_count);\n#if ZEND_DEBUG\n\t\t\t\t\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\t\t\t\t\tdbg->size = real_size;\n\t\t\t\t\t\tdbg->filename = __zend_filename;\n\t\t\t\t\t\tdbg->orig_filename = __zend_orig_filename;\n\t\t\t\t\t\tdbg->lineno = __zend_lineno;\n\t\t\t\t\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\t\t\t\treturn ptr;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n#if ZEND_DEBUG\n\t\tsize = real_size;\n#endif\n\t}\n\n\t/* Naive reallocation */\n#if ZEND_MM_STAT\n\tdo {\n\t\tsize_t orig_peak = heap->peak;\n\t\tsize_t orig_real_peak = heap->real_peak;\n#endif\n\tret = zend_mm_alloc_heap(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tmemcpy(ret, ptr, MIN(old_size, copy_size));\n\tzend_mm_free_heap(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#if ZEND_MM_STAT\n\t\theap->peak = MAX(orig_peak, heap->size);\n\t\theap->real_peak = MAX(orig_real_peak, heap->real_size);\n\t} while (0);\n#endif\n\treturn ret;\n}\n\n/*********************/\n/* Huge Runs (again) */\n/*********************/\n\n#if ZEND_DEBUG\nstatic void zend_mm_add_huge_block(zend_mm_heap *heap, void *ptr, size_t size, size_t dbg_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#else\nstatic void zend_mm_add_huge_block(zend_mm_heap *heap, void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#endif\n{\n\tzend_mm_huge_list *list = (zend_mm_huge_list*)zend_mm_alloc_heap(heap, sizeof(zend_mm_huge_list) ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tlist->ptr = ptr;\n\tlist->size = size;\n\tlist->next = heap->huge_list;\n#if ZEND_DEBUG\n\tlist->dbg.size = dbg_size;\n\tlist->dbg.filename = __zend_filename;\n\tlist->dbg.orig_filename = __zend_orig_filename;\n\tlist->dbg.lineno = __zend_lineno;\n\tlist->dbg.orig_lineno = __zend_orig_lineno;\n#endif\n\theap->huge_list = list;\n}\n\nstatic size_t zend_mm_del_huge_block(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tzend_mm_huge_list *prev = NULL;\n\tzend_mm_huge_list *list = heap->huge_list;\n\twhile (list != NULL) {\n\t\tif (list->ptr == ptr) {\n\t\t\tsize_t size;\n\n\t\t\tif (prev) {\n\t\t\t\tprev->next = list->next;\n\t\t\t} else {\n\t\t\t\theap->huge_list = list->next;\n\t\t\t}\n\t\t\tsize = list->size;\n\t\t\tzend_mm_free_heap(heap, list ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t\treturn size;\n\t\t}\n\t\tprev = list;\n\t\tlist = list->next;\n\t}\n\tZEND_MM_CHECK(0, \"zend_mm_heap corrupted\");\n\treturn 0;\n}\n\nstatic size_t zend_mm_get_huge_block_size(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tzend_mm_huge_list *list = heap->huge_list;\n\twhile (list != NULL) {\n\t\tif (list->ptr == ptr) {\n\t\t\treturn list->size;\n\t\t}\n\t\tlist = list->next;\n\t}\n\tZEND_MM_CHECK(0, \"zend_mm_heap corrupted\");\n\treturn 0;\n}\n\n#if ZEND_DEBUG\nstatic void zend_mm_change_huge_block_size(zend_mm_heap *heap, void *ptr, size_t size, size_t dbg_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#else\nstatic void zend_mm_change_huge_block_size(zend_mm_heap *heap, void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#endif\n{\n\tzend_mm_huge_list *list = heap->huge_list;\n\twhile (list != NULL) {\n\t\tif (list->ptr == ptr) {\n\t\t\tlist->size = size;\n#if ZEND_DEBUG\n\t\t\tlist->dbg.size = dbg_size;\n\t\t\tlist->dbg.filename = __zend_filename;\n\t\t\tlist->dbg.orig_filename = __zend_orig_filename;\n\t\t\tlist->dbg.lineno = __zend_lineno;\n\t\t\tlist->dbg.orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\treturn;\n\t\t}\n\t\tlist = list->next;\n\t}\n}\n\nstatic void *zend_mm_alloc_huge(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n#ifdef ZEND_WIN32\n\t/* On Windows we don't have ability to extend huge blocks in-place.\n\t * We allocate them with 2MB size granularity, to avoid many \n\t * reallocations when they are extended by small pieces\n\t */\n\tsize_t new_size = ZEND_MM_ALIGNED_SIZE_EX(size, MAX(REAL_PAGE_SIZE, ZEND_MM_CHUNK_SIZE));\n#else\n\tsize_t new_size = ZEND_MM_ALIGNED_SIZE_EX(size, REAL_PAGE_SIZE);\n#endif\n\tvoid *ptr;\n\n#if ZEND_MM_LIMIT\n\tif (UNEXPECTED(heap->real_size + new_size > heap->limit)) {\n\t\tif (zend_mm_gc(heap) && heap->real_size + new_size <= heap->limit) {\n\t\t\t/* pass */\n\t\t} else if (heap->overflow == 0) {\n#if ZEND_DEBUG\n\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted at %s:%d (tried to allocate %zu bytes)\", heap->limit, __zend_filename, __zend_lineno, size);\n#else\n\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted (tried to allocate %zu bytes)\", heap->limit, size);\n#endif\n\t\t\treturn NULL;\n\t\t}\n\t}\n#endif\n\tptr = zend_mm_chunk_alloc(heap, new_size, ZEND_MM_CHUNK_SIZE);\n\tif (UNEXPECTED(ptr == NULL)) {\n\t\t/* insufficient memory */\n\t\tif (zend_mm_gc(heap) &&\n\t\t    (ptr = zend_mm_chunk_alloc(heap, new_size, ZEND_MM_CHUNK_SIZE)) != NULL) {\n\t\t\t/* pass */\n\t\t} else {\n#if !ZEND_MM_LIMIT\n\t\t\tzend_mm_safe_error(heap, \"Out of memory\");\n#elif ZEND_DEBUG\n\t\t\tzend_mm_safe_error(heap, \"Out of memory (allocated %zu) at %s:%d (tried to allocate %zu bytes)\", heap->real_size, __zend_filename, __zend_lineno, size);\n#else\n\t\t\tzend_mm_safe_error(heap, \"Out of memory (allocated %zu) (tried to allocate %zu bytes)\", heap->real_size, size);\n#endif\n\t\t\treturn NULL;\n\t\t}\n\t}\n#if ZEND_DEBUG\n\tzend_mm_add_huge_block(heap, ptr, new_size, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\tzend_mm_add_huge_block(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n#if ZEND_MM_STAT\n\tdo {\n\t\tsize_t size = heap->real_size + new_size;\n\t\tsize_t peak = MAX(heap->real_peak, size);\n\t\theap->real_size = size;\n\t\theap->real_peak = peak;\n\t} while (0);\n\tdo {\n\t\tsize_t size = heap->size + new_size;\n\t\tsize_t peak = MAX(heap->peak, size);\n\t\theap->size = size;\n\t\theap->peak = peak;\n\t} while (0);\n#elif ZEND_MM_LIMIT\n\theap->real_size += new_size;\n#endif\n\treturn ptr;\n}\n\nstatic void zend_mm_free_huge(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t size;\n\n\tZEND_MM_CHECK(ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE) == 0, \"zend_mm_heap corrupted\");\n\tsize = zend_mm_del_huge_block(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tzend_mm_chunk_free(heap, ptr, size);\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\theap->real_size -= size;\n#endif\n#if ZEND_MM_STAT\n\theap->size -= size;\n#endif\n}\n\n/******************/\n/* Initialization */\n/******************/\n\nstatic zend_mm_heap *zend_mm_init(void)\n{\n\tzend_mm_chunk *chunk = (zend_mm_chunk*)zend_mm_chunk_alloc_int(ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE);\n\tzend_mm_heap *heap;\n\n\tif (UNEXPECTED(chunk == NULL)) {\n#if ZEND_MM_ERROR\n#ifdef _WIN32\n\t\tstderr_last_error(\"Can't initialize heap\");\n#else\n\t\tfprintf(stderr, \"\\nCan't initialize heap: [%d] %s\\n\", errno, strerror(errno));\n#endif\n#endif\n\t\treturn NULL;\n\t}\n\theap = &chunk->heap_slot;\n\tchunk->heap = heap;\n\tchunk->next = chunk;\n\tchunk->prev = chunk;\n\tchunk->free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\tchunk->free_tail = ZEND_MM_FIRST_PAGE;\n\tchunk->num = 0;\n\tchunk->free_map[0] = (Z_L(1) << ZEND_MM_FIRST_PAGE) - 1;\n\tchunk->map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE);\n\theap->main_chunk = chunk;\n\theap->cached_chunks = NULL;\n\theap->chunks_count = 1;\n\theap->peak_chunks_count = 1;\n\theap->cached_chunks_count = 0;\n\theap->avg_chunks_count = 1.0;\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\theap->real_size = ZEND_MM_CHUNK_SIZE;\n#endif\n#if ZEND_MM_STAT\n\theap->real_peak = ZEND_MM_CHUNK_SIZE;\n\theap->size = 0;\n\theap->peak = 0;\n#endif\n#if ZEND_MM_LIMIT\n\theap->limit = (Z_L(-1) >> Z_L(1));\n\theap->overflow = 0;\n#endif\n#if ZEND_MM_CUSTOM\n\theap->use_custom_heap = ZEND_MM_CUSTOM_HEAP_NONE;\n#endif\n#if ZEND_MM_STORAGE\n\theap->storage = NULL;\n#endif\n\theap->huge_list = NULL;\n\treturn heap;\n}\n\nZEND_API size_t zend_mm_gc(zend_mm_heap *heap)\n{\n\tzend_mm_free_slot *p, **q;\n\tzend_mm_chunk *chunk;\n\tsize_t page_offset;\n\tint page_num;\n\tzend_mm_page_info info;\n\tint i, has_free_pages, free_counter;\n\tsize_t collected = 0;\n\n#if ZEND_MM_CUSTOM\n\tif (heap->use_custom_heap) {\n\t\treturn 0;\n\t}\n#endif\n\n\tfor (i = 0; i < ZEND_MM_BINS; i++) {\n\t\thas_free_pages = 0;\n\t\tp = heap->free_slot[i];\n\t\twhile (p != NULL) {\n\t\t\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(p, ZEND_MM_CHUNK_SIZE);\n\t\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\t\tpage_offset = ZEND_MM_ALIGNED_OFFSET(p, ZEND_MM_CHUNK_SIZE);\n\t\t\tZEND_ASSERT(page_offset != 0);\n\t\t\tpage_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\t\tinfo = chunk->map[page_num];\n\t\t\tZEND_ASSERT(info & ZEND_MM_IS_SRUN);\n\t\t\tif (info & ZEND_MM_IS_LRUN) {\n\t\t\t\tpage_num -= ZEND_MM_NRUN_OFFSET(info);\n\t\t\t\tinfo = chunk->map[page_num];\n\t\t\t\tZEND_ASSERT(info & ZEND_MM_IS_SRUN);\n\t\t\t\tZEND_ASSERT(!(info & ZEND_MM_IS_LRUN));\n\t\t\t}\n\t\t\tZEND_ASSERT(ZEND_MM_SRUN_BIN_NUM(info) == i);\n\t\t\tfree_counter = ZEND_MM_SRUN_FREE_COUNTER(info) + 1;\n\t\t\tif (free_counter == bin_elements[i]) {\n\t\t\t\thas_free_pages = 1;\n\t\t\t}\n\t\t\tchunk->map[page_num] = ZEND_MM_SRUN_EX(i, free_counter);;\n\t\t\tp = p->next_free_slot;\n\t\t}\n\n\t\tif (!has_free_pages) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tq = &heap->free_slot[i];\n\t\tp = *q;\n\t\twhile (p != NULL) {\n\t\t\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(p, ZEND_MM_CHUNK_SIZE);\n\t\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\t\tpage_offset = ZEND_MM_ALIGNED_OFFSET(p, ZEND_MM_CHUNK_SIZE);\n\t\t\tZEND_ASSERT(page_offset != 0);\n\t\t\tpage_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\t\tinfo = chunk->map[page_num];\n\t\t\tZEND_ASSERT(info & ZEND_MM_IS_SRUN);\n\t\t\tif (info & ZEND_MM_IS_LRUN) {\n\t\t\t\tpage_num -= ZEND_MM_NRUN_OFFSET(info);\n\t\t\t\tinfo = chunk->map[page_num];\n\t\t\t\tZEND_ASSERT(info & ZEND_MM_IS_SRUN);\n\t\t\t\tZEND_ASSERT(!(info & ZEND_MM_IS_LRUN));\n\t\t\t}\n\t\t\tZEND_ASSERT(ZEND_MM_SRUN_BIN_NUM(info) == i);\n\t\t\tif (ZEND_MM_SRUN_FREE_COUNTER(info) == bin_elements[i]) {\n\t\t\t\t/* remove from cache */\n\t\t\t\tp = p->next_free_slot;;\n\t\t\t\t*q = p;\n\t\t\t} else {\n\t\t\t\tq = &p->next_free_slot;\n\t\t\t\tp = *q;\n\t\t\t}\n\t\t}\n\t}\n\n\tchunk = heap->main_chunk;\n\tdo {\n\t\ti = ZEND_MM_FIRST_PAGE;\n\t\twhile (i < chunk->free_tail) {\n\t\t\tif (zend_mm_bitset_is_set(chunk->free_map, i)) {\n\t\t\t\tinfo = chunk->map[i];\n\t\t\t\tif (info & ZEND_MM_IS_SRUN) {\n\t\t\t\t\tint bin_num = ZEND_MM_SRUN_BIN_NUM(info);\n\t\t\t\t\tint pages_count = bin_pages[bin_num];\n\n\t\t\t\t\tif (ZEND_MM_SRUN_FREE_COUNTER(info) == bin_elements[bin_num]) {\n\t\t\t\t\t\t/* all elemens are free */\n\t\t\t\t\t\tzend_mm_free_pages_ex(heap, chunk, i, pages_count, 0);\n\t\t\t\t\t\tcollected += pages_count;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* reset counter */\n\t\t\t\t\t\tchunk->map[i] = ZEND_MM_SRUN(bin_num);\n\t\t\t\t\t}\n\t\t\t\t\ti += bin_pages[bin_num];\n\t\t\t\t} else /* if (info & ZEND_MM_IS_LRUN) */ {\n\t\t\t\t\ti += ZEND_MM_LRUN_PAGES(info);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\tif (chunk->free_pages == ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE) {\n\t\t\tzend_mm_chunk *next_chunk = chunk->next;\n\n\t\t\tzend_mm_delete_chunk(heap, chunk);\n\t\t\tchunk = next_chunk;\n\t\t} else {\n\t\t\tchunk = chunk->next;\n\t\t}\n\t} while (chunk != heap->main_chunk);\n\n\treturn collected * ZEND_MM_PAGE_SIZE;\n}\n\n#if ZEND_DEBUG\n/******************/\n/* Leak detection */\n/******************/\n\nstatic zend_long zend_mm_find_leaks_small(zend_mm_chunk *p, int i, int j, zend_leak_info *leak)\n{\n    int empty = 1;\n\tzend_long count = 0;\n\tint bin_num = ZEND_MM_SRUN_BIN_NUM(p->map[i]);\n\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * i + bin_data_size[bin_num] * (j + 1) - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\n\twhile (j < bin_elements[bin_num]) {\n\t\tif (dbg->size != 0) {\n\t\t\tif (dbg->filename == leak->filename && dbg->lineno == leak->lineno) {\n\t\t\t\tcount++;\n\t\t\t\tdbg->size = 0;\n\t\t\t\tdbg->filename = NULL;\n\t\t\t\tdbg->lineno = 0;\n\t\t\t} else {\n\t\t\t\tempty = 0;\n\t\t\t}\n\t\t}\n\t\tj++;\n\t\tdbg = (zend_mm_debug_info*)((char*)dbg + bin_data_size[bin_num]);\n\t}\n\tif (empty) {\n\t\tzend_mm_bitset_reset_range(p->free_map, i, bin_pages[bin_num]);\n\t}\n\treturn count;\n}\n\nstatic zend_long zend_mm_find_leaks(zend_mm_heap *heap, zend_mm_chunk *p, int i, zend_leak_info *leak)\n{\n\tzend_long count = 0;\n\n\tdo {\n\t\twhile (i < p->free_tail) {\n\t\t\tif (zend_mm_bitset_is_set(p->free_map, i)) {\n\t\t\t\tif (p->map[i] & ZEND_MM_IS_SRUN) {\n\t\t\t\t\tint bin_num = ZEND_MM_SRUN_BIN_NUM(p->map[i]);\n\t\t\t\t\tcount += zend_mm_find_leaks_small(p, i, 0, leak);\n\t\t\t\t\ti += bin_pages[bin_num];\n\t\t\t\t} else /* if (p->map[i] & ZEND_MM_IS_LRUN) */ {\n\t\t\t\t\tint pages_count = ZEND_MM_LRUN_PAGES(p->map[i]);\n\t\t\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * (i + pages_count) - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\n\t\t\t\t\tif (dbg->filename == leak->filename && dbg->lineno == leak->lineno) {\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t\tzend_mm_bitset_reset_range(p->free_map, i, pages_count);\n\t\t\t\t\ti += pages_count;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\tp = p->next;\n\t} while (p != heap->main_chunk);\n\treturn count;\n}\n\nstatic zend_long zend_mm_find_leaks_huge(zend_mm_heap *heap, zend_mm_huge_list *list)\n{\n\tzend_long count = 0;\n\tzend_mm_huge_list *prev = list;\n\tzend_mm_huge_list *p = list->next;\n\n\twhile (p) {\n\t\tif (p->dbg.filename == list->dbg.filename && p->dbg.lineno == list->dbg.lineno) {\n\t\t\tprev->next = p->next;\n\t\t\tzend_mm_chunk_free(heap, p->ptr, p->size);\n\t\t\tzend_mm_free_heap(heap, p, NULL, 0, NULL, 0);\n\t\t\tcount++;\n\t\t} else {\n\t\t\tprev = p;\n\t\t}\n\t\tp = prev->next;\n\t}\n\n\treturn count;\n}\n\nstatic void zend_mm_check_leaks(zend_mm_heap *heap)\n{\n\tzend_mm_huge_list *list;\n\tzend_mm_chunk *p;\n\tzend_leak_info leak;\n\tzend_long repeated = 0;\n\tuint32_t total = 0;\n\tint i, j;\n\n\t/* find leaked huge blocks and free them */\n\tlist = heap->huge_list;\n\twhile (list) {\n\t\tzend_mm_huge_list *q = list;\n\n\t\tleak.addr = list->ptr;\n\t\tleak.size = list->dbg.size;\n\t\tleak.filename = list->dbg.filename;\n\t\tleak.orig_filename = list->dbg.orig_filename;\n\t\tleak.lineno = list->dbg.lineno;\n\t\tleak.orig_lineno = list->dbg.orig_lineno;\n\n\t\tzend_message_dispatcher(ZMSG_LOG_SCRIPT_NAME, NULL);\n\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_DETECTED, &leak);\n\t\trepeated = zend_mm_find_leaks_huge(heap, list);\n\t\ttotal += 1 + repeated;\n\t\tif (repeated) {\n\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_REPEATED, (void *)(zend_uintptr_t)repeated);\n\t\t}\n\n\t\theap->huge_list = list = list->next;\n\t\tzend_mm_chunk_free(heap, q->ptr, q->size);\n\t\tzend_mm_free_heap(heap, q, NULL, 0, NULL, 0);\n\t}\n\n\t/* for each chunk */\n\tp = heap->main_chunk;\n\tdo {\n\t\ti = ZEND_MM_FIRST_PAGE;\n\t\twhile (i < p->free_tail) {\n\t\t\tif (zend_mm_bitset_is_set(p->free_map, i)) {\n\t\t\t\tif (p->map[i] & ZEND_MM_IS_SRUN) {\n\t\t\t\t\tint bin_num = ZEND_MM_SRUN_BIN_NUM(p->map[i]);\n\t\t\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * i + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\n\t\t\t\t\tj = 0;\n\t\t\t\t\twhile (j < bin_elements[bin_num]) {\n\t\t\t\t\t\tif (dbg->size != 0) {\n\t\t\t\t\t\t\tleak.addr = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * i + bin_data_size[bin_num] * j);\n\t\t\t\t\t\t\tleak.size = dbg->size;\n\t\t\t\t\t\t\tleak.filename = dbg->filename;\n\t\t\t\t\t\t\tleak.orig_filename = dbg->orig_filename;\n\t\t\t\t\t\t\tleak.lineno = dbg->lineno;\n\t\t\t\t\t\t\tleak.orig_lineno = dbg->orig_lineno;\n\n\t\t\t\t\t\t\tzend_message_dispatcher(ZMSG_LOG_SCRIPT_NAME, NULL);\n\t\t\t\t\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_DETECTED, &leak);\n\n\t\t\t\t\t\t\tdbg->size = 0;\n\t\t\t\t\t\t\tdbg->filename = NULL;\n\t\t\t\t\t\t\tdbg->lineno = 0;\n\n\t\t\t\t\t\t\trepeated = zend_mm_find_leaks_small(p, i, j + 1, &leak) +\n\t\t\t\t\t\t\t           zend_mm_find_leaks(heap, p, i + bin_pages[bin_num], &leak);\n\t\t\t\t\t\t\ttotal += 1 + repeated;\n\t\t\t\t\t\t\tif (repeated) {\n\t\t\t\t\t\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_REPEATED, (void *)(zend_uintptr_t)repeated);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdbg = (zend_mm_debug_info*)((char*)dbg + bin_data_size[bin_num]);\n\t\t\t\t\t\tj++;\n\t\t\t\t\t}\n\t\t\t\t\ti += bin_pages[bin_num];\n\t\t\t\t} else /* if (p->map[i] & ZEND_MM_IS_LRUN) */ {\n\t\t\t\t\tint pages_count = ZEND_MM_LRUN_PAGES(p->map[i]);\n\t\t\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * (i + pages_count) - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\n\t\t\t\t\tleak.addr = (void*)((char*)p + ZEND_MM_PAGE_SIZE * i);\n\t\t\t\t\tleak.size = dbg->size;\n\t\t\t\t\tleak.filename = dbg->filename;\n\t\t\t\t\tleak.orig_filename = dbg->orig_filename;\n\t\t\t\t\tleak.lineno = dbg->lineno;\n\t\t\t\t\tleak.orig_lineno = dbg->orig_lineno;\n\n\t\t\t\t\tzend_message_dispatcher(ZMSG_LOG_SCRIPT_NAME, NULL);\n\t\t\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_DETECTED, &leak);\n\n\t\t\t\t\tzend_mm_bitset_reset_range(p->free_map, i, pages_count);\n\n\t\t\t\t\trepeated = zend_mm_find_leaks(heap, p, i + pages_count, &leak);\n\t\t\t\t\ttotal += 1 + repeated;\n\t\t\t\t\tif (repeated) {\n\t\t\t\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_REPEATED, (void *)(zend_uintptr_t)repeated);\n\t\t\t\t\t}\n\t\t\t\t\ti += pages_count;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\tp = p->next;\n\t} while (p != heap->main_chunk);\n\tif (total) {\n\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAKS_GRAND_TOTAL, &total);\n\t}\n}\n#endif\n\nvoid zend_mm_shutdown(zend_mm_heap *heap, int full, int silent)\n{\n\tzend_mm_chunk *p;\n\tzend_mm_huge_list *list;\n\n#if ZEND_MM_CUSTOM\n\tif (heap->use_custom_heap) {\n\t\tif (full) {\n\t\t\tif (ZEND_DEBUG && heap->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\t\theap->custom_heap.debug._free(heap ZEND_FILE_LINE_CC ZEND_FILE_LINE_EMPTY_CC);\n\t\t\t} else {\n\t\t\t\theap->custom_heap.std._free(heap);\n\t\t\t}\n\t\t}\n\t\treturn;\n\t}\n#endif\n\n#if ZEND_DEBUG\n\tif (!silent) {\n\t\tzend_mm_check_leaks(heap);\n\t}\n#endif\n\n\t/* free huge blocks */\n\tlist = heap->huge_list;\n\theap->huge_list = NULL;\n\twhile (list) {\n\t\tzend_mm_huge_list *q = list;\n\t\tlist = list->next;\n\t\tzend_mm_chunk_free(heap, q->ptr, q->size);\n\t}\n\n\t/* move all chunks except of the first one into the cache */\n\tp = heap->main_chunk->next;\n\twhile (p != heap->main_chunk) {\n\t\tzend_mm_chunk *q = p->next;\n\t\tp->next = heap->cached_chunks;\n\t\theap->cached_chunks = p;\n\t\tp = q;\n\t\theap->chunks_count--;\n\t\theap->cached_chunks_count++;\n\t}\n\n\tif (full) {\n\t\t/* free all cached chunks */\n\t\twhile (heap->cached_chunks) {\n\t\t\tp = heap->cached_chunks;\n\t\t\theap->cached_chunks = p->next;\n\t\t\tzend_mm_chunk_free(heap, p, ZEND_MM_CHUNK_SIZE);\n\t\t}\n\t\t/* free the first chunk */\n\t\tzend_mm_chunk_free(heap, heap->main_chunk, ZEND_MM_CHUNK_SIZE);\n\t} else {\n\t\tzend_mm_heap old_heap;\n\n\t\t/* free some cached chunks to keep average count */\n\t\theap->avg_chunks_count = (heap->avg_chunks_count + (double)heap->peak_chunks_count) / 2.0;\n\t\twhile ((double)heap->cached_chunks_count + 0.9 > heap->avg_chunks_count &&\n\t\t       heap->cached_chunks) {\n\t\t\tp = heap->cached_chunks;\n\t\t\theap->cached_chunks = p->next;\n\t\t\tzend_mm_chunk_free(heap, p, ZEND_MM_CHUNK_SIZE);\n\t\t\theap->cached_chunks_count--;\n\t\t}\n\t\t/* clear cached chunks */\n\t\tp = heap->cached_chunks;\n\t\twhile (p != NULL) {\n\t\t\tzend_mm_chunk *q = p->next;\n\t\t\tmemset(p, 0, sizeof(zend_mm_chunk));\n\t\t\tp->next = q;\n\t\t\tp = q;\n\t\t}\n\n\t\t/* reinitialize the first chunk and heap */\n\t\told_heap = *heap;\n\t\tp = heap->main_chunk;\n\t\tmemset(p, 0, ZEND_MM_FIRST_PAGE * ZEND_MM_PAGE_SIZE);\n\t\t*heap = old_heap;\n\t\tmemset(heap->free_slot, 0, sizeof(heap->free_slot));\n\t\theap->main_chunk = p;\n\t\tp->heap = &p->heap_slot;\n\t\tp->next = p;\n\t\tp->prev = p;\n\t\tp->free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\t\tp->free_tail = ZEND_MM_FIRST_PAGE;\n\t\tp->free_map[0] = (1L << ZEND_MM_FIRST_PAGE) - 1;\n\t\tp->map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE);\n\t\theap->chunks_count = 1;\n\t\theap->peak_chunks_count = 1;\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\t\theap->real_size = ZEND_MM_CHUNK_SIZE;\n#endif\n#if ZEND_MM_STAT\n\t\theap->real_peak = ZEND_MM_CHUNK_SIZE;\n\t\theap->size = heap->peak = 0;\n#endif\n\t}\n}\n\n/**************/\n/* PUBLIC API */\n/**************/\n\nZEND_API void* ZEND_FASTCALL _zend_mm_alloc(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn zend_mm_alloc_heap(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void ZEND_FASTCALL _zend_mm_free(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tzend_mm_free_heap(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nvoid* ZEND_FASTCALL _zend_mm_realloc(zend_mm_heap *heap, void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn zend_mm_realloc_heap(heap, ptr, size, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nvoid* ZEND_FASTCALL _zend_mm_realloc2(zend_mm_heap *heap, void *ptr, size_t size, size_t copy_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn zend_mm_realloc_heap(heap, ptr, size, copy_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API size_t ZEND_FASTCALL _zend_mm_block_size(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn zend_mm_size(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\n/**********************/\n/* Allocation Manager */\n/**********************/\n\ntypedef struct _zend_alloc_globals {\n\tzend_mm_heap *mm_heap;\n} zend_alloc_globals;\n\n#ifdef ZTS\nstatic int alloc_globals_id;\n# define AG(v) ZEND_TSRMG(alloc_globals_id, zend_alloc_globals *, v)\n#else\n# define AG(v) (alloc_globals.v)\nstatic zend_alloc_globals alloc_globals;\n#endif\n\nZEND_API int is_zend_mm(void)\n{\n#if ZEND_MM_CUSTOM\n\treturn !AG(mm_heap)->use_custom_heap;\n#else\n\treturn 1;\n#endif\n}\n\n#if !ZEND_DEBUG && (!defined(_WIN32) || defined(__clang__))\n#undef _emalloc\n\n#if ZEND_MM_CUSTOM\n# define ZEND_MM_CUSTOM_ALLOCATOR(size) do { \\\n\t\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) { \\\n\t\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) { \\\n\t\t\t\treturn AG(mm_heap)->custom_heap.debug._malloc(size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); \\\n\t\t\t} else { \\\n\t\t\t\treturn AG(mm_heap)->custom_heap.std._malloc(size); \\\n\t\t\t} \\\n\t\t} \\\n\t} while (0)\n# define ZEND_MM_CUSTOM_DEALLOCATOR(ptr) do { \\\n\t\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) { \\\n\t\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) { \\\n\t\t\t\tAG(mm_heap)->custom_heap.debug._free(ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); \\\n\t\t\t} else { \\\n\t\t\t\tAG(mm_heap)->custom_heap.std._free(ptr); \\\n\t\t\t} \\\n\t\t\treturn; \\\n\t\t} \\\n\t} while (0)\n#else\n# define ZEND_MM_CUSTOM_ALLOCATOR(size)\n# define ZEND_MM_CUSTOM_DEALLOCATOR(ptr)\n#endif\n\n# define _ZEND_BIN_ALLOCATOR(_num, _size, _elements, _pages, x, y) \\\n\tZEND_API void* ZEND_FASTCALL _emalloc_ ## _size(void) { \\\n\t\tZEND_MM_CUSTOM_ALLOCATOR(_size); \\\n\t\treturn zend_mm_alloc_small(AG(mm_heap), _size, _num ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); \\\n\t}\n\nZEND_MM_BINS_INFO(_ZEND_BIN_ALLOCATOR, x, y)\n\nZEND_API void* ZEND_FASTCALL _emalloc_large(size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n\tZEND_MM_CUSTOM_ALLOCATOR(size);\n\treturn zend_mm_alloc_large(AG(mm_heap), size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void* ZEND_FASTCALL _emalloc_huge(size_t size)\n{\n\n\tZEND_MM_CUSTOM_ALLOCATOR(size);\n\treturn zend_mm_alloc_huge(AG(mm_heap), size);\n}\n\n#if ZEND_DEBUG\n# define _ZEND_BIN_FREE(_num, _size, _elements, _pages, x, y) \\\n\tZEND_API void ZEND_FASTCALL _efree_ ## _size(void *ptr) { \\\n\t\tZEND_MM_CUSTOM_DEALLOCATOR(ptr); \\\n\t\t{ \\\n\t\t\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE); \\\n\t\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE); \\\n\t\t\tint page_num = page_offset / ZEND_MM_PAGE_SIZE; \\\n\t\t\tZEND_MM_CHECK(chunk->heap == AG(mm_heap), \"zend_mm_heap corrupted\"); \\\n\t\t\tZEND_ASSERT(chunk->map[page_num] & ZEND_MM_IS_SRUN); \\\n\t\t\tZEND_ASSERT(ZEND_MM_SRUN_BIN_NUM(chunk->map[page_num]) == _num); \\\n\t\t\tzend_mm_free_small(AG(mm_heap), ptr, _num); \\\n\t\t} \\\n\t}\n#else\n# define _ZEND_BIN_FREE(_num, _size, _elements, _pages, x, y) \\\n\tZEND_API void ZEND_FASTCALL _efree_ ## _size(void *ptr) { \\\n\t\tZEND_MM_CUSTOM_DEALLOCATOR(ptr); \\\n\t\t{ \\\n\t\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE); \\\n\t\t\tZEND_MM_CHECK(chunk->heap == AG(mm_heap), \"zend_mm_heap corrupted\"); \\\n\t\t\tzend_mm_free_small(AG(mm_heap), ptr, _num); \\\n\t\t} \\\n\t}\n#endif\n\nZEND_MM_BINS_INFO(_ZEND_BIN_FREE, x, y)\n\nZEND_API void ZEND_FASTCALL _efree_large(void *ptr, size_t size)\n{\n\n\tZEND_MM_CUSTOM_DEALLOCATOR(ptr);\n\t{\n\t\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tint page_num = page_offset / ZEND_MM_PAGE_SIZE;\n\t\tint pages_count = ZEND_MM_ALIGNED_SIZE_EX(size, ZEND_MM_PAGE_SIZE) / ZEND_MM_PAGE_SIZE;\n\n\t\tZEND_MM_CHECK(chunk->heap == AG(mm_heap) && ZEND_MM_ALIGNED_OFFSET(page_offset, ZEND_MM_PAGE_SIZE) == 0, \"zend_mm_heap corrupted\");\n\t\tZEND_ASSERT(chunk->map[page_num] & ZEND_MM_IS_LRUN);\n\t\tZEND_ASSERT(ZEND_MM_LRUN_PAGES(chunk->map[page_num]) == pages_count);\n\t\tzend_mm_free_large(AG(mm_heap), chunk, page_num, pages_count);\n\t}\n}\n\nZEND_API void ZEND_FASTCALL _efree_huge(void *ptr, size_t size)\n{\n\n\tZEND_MM_CUSTOM_DEALLOCATOR(ptr);\n\tzend_mm_free_huge(AG(mm_heap), ptr);\n}\n#endif\n\nZEND_API void* ZEND_FASTCALL _emalloc(size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n#if ZEND_MM_CUSTOM\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\treturn AG(mm_heap)->custom_heap.debug._malloc(size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t} else {\n\t\t\treturn AG(mm_heap)->custom_heap.std._malloc(size);\n\t\t}\n\t}\n#endif\n\treturn zend_mm_alloc_heap(AG(mm_heap), size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void ZEND_FASTCALL _efree(void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n#if ZEND_MM_CUSTOM\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\tAG(mm_heap)->custom_heap.debug._free(ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t} else {\n\t\t\tAG(mm_heap)->custom_heap.std._free(ptr);\n\t    }\n\t\treturn;\n\t}\n#endif\n\tzend_mm_free_heap(AG(mm_heap), ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void* ZEND_FASTCALL _erealloc(void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\treturn AG(mm_heap)->custom_heap.debug._realloc(ptr, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t} else {\n\t\t\treturn AG(mm_heap)->custom_heap.std._realloc(ptr, size);\n\t\t}\n\t}\n\treturn zend_mm_realloc_heap(AG(mm_heap), ptr, size, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void* ZEND_FASTCALL _erealloc2(void *ptr, size_t size, size_t copy_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\treturn AG(mm_heap)->custom_heap.debug._realloc(ptr, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t} else {\n\t\t\treturn AG(mm_heap)->custom_heap.std._realloc(ptr, size);\n\t\t}\n\t}\n\treturn zend_mm_realloc_heap(AG(mm_heap), ptr, size, copy_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API size_t ZEND_FASTCALL _zend_mem_block_size(void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\treturn 0;\n\t}\n\treturn zend_mm_size(AG(mm_heap), ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nstatic zend_always_inline size_t safe_address(size_t nmemb, size_t size, size_t offset)\n{\n\tint overflow;\n\tsize_t ret = zend_safe_address(nmemb, size, offset, &overflow);\n\n\tif (UNEXPECTED(overflow)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu * %zu + %zu)\", nmemb, size, offset);\n\t\treturn 0;\n\t}\n\treturn ret;\n}\n\n\nZEND_API void* ZEND_FASTCALL _safe_emalloc(size_t nmemb, size_t size, size_t offset ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn emalloc_rel(safe_address(nmemb, size, offset));\n}\n\nZEND_API void* ZEND_FASTCALL _safe_malloc(size_t nmemb, size_t size, size_t offset)\n{\n\treturn pemalloc(safe_address(nmemb, size, offset), 1);\n}\n\nZEND_API void* ZEND_FASTCALL _safe_erealloc(void *ptr, size_t nmemb, size_t size, size_t offset ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn erealloc_rel(ptr, safe_address(nmemb, size, offset));\n}\n\nZEND_API void* ZEND_FASTCALL _safe_realloc(void *ptr, size_t nmemb, size_t size, size_t offset)\n{\n\treturn perealloc(ptr, safe_address(nmemb, size, offset), 1);\n}\n\n\nZEND_API void* ZEND_FASTCALL _ecalloc(size_t nmemb, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tvoid *p;\n\n\tp = _safe_emalloc(nmemb, size, 0 ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tif (UNEXPECTED(p == NULL)) {\n\t\treturn p;\n\t}\n\tmemset(p, 0, size * nmemb);\n\treturn p;\n}\n\nZEND_API char* ZEND_FASTCALL _estrdup(const char *s ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t length;\n\tchar *p;\n\n\tlength = strlen(s);\n\tif (UNEXPECTED(length + 1 == 0)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu * %zu + %zu)\", 1, length, 1);\n\t}\n\tp = (char *) _emalloc(length + 1 ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tif (UNEXPECTED(p == NULL)) {\n\t\treturn p;\n\t}\n\tmemcpy(p, s, length+1);\n\treturn p;\n}\n\nZEND_API char* ZEND_FASTCALL _estrndup(const char *s, size_t length ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tchar *p;\n\n\tif (UNEXPECTED(length + 1 == 0)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu * %zu + %zu)\", 1, length, 1);\n\t}\n\tp = (char *) _emalloc(length + 1 ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tif (UNEXPECTED(p == NULL)) {\n\t\treturn p;\n\t}\n\tmemcpy(p, s, length);\n\tp[length] = 0;\n\treturn p;\n}\n\n\nZEND_API char* ZEND_FASTCALL zend_strndup(const char *s, size_t length)\n{\n\tchar *p;\n\n\tif (UNEXPECTED(length + 1 == 0)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu * %zu + %zu)\", 1, length, 1);\n\t}\n\tp = (char *) malloc(length + 1);\n\tif (UNEXPECTED(p == NULL)) {\n\t\treturn p;\n\t}\n\tif (EXPECTED(length)) {\n\t\tmemcpy(p, s, length);\n\t}\n\tp[length] = 0;\n\treturn p;\n}\n\n\nZEND_API int zend_set_memory_limit(size_t memory_limit)\n{\n#if ZEND_MM_LIMIT\n\tAG(mm_heap)->limit = (memory_limit >= ZEND_MM_CHUNK_SIZE) ? memory_limit : ZEND_MM_CHUNK_SIZE;\n#endif\n\treturn SUCCESS;\n}\n\nZEND_API size_t zend_memory_usage(int real_usage)\n{\n#if ZEND_MM_STAT\n\tif (real_usage) {\n\t\treturn AG(mm_heap)->real_size;\n\t} else {\n\t\tsize_t usage = AG(mm_heap)->size;\n\t\treturn usage;\n\t}\n#endif\n\treturn 0;\n}\n\nZEND_API size_t zend_memory_peak_usage(int real_usage)\n{\n#if ZEND_MM_STAT\n\tif (real_usage) {\n\t\treturn AG(mm_heap)->real_peak;\n\t} else {\n\t\treturn AG(mm_heap)->peak;\n\t}\n#endif\n\treturn 0;\n}\n\nZEND_API void shutdown_memory_manager(int silent, int full_shutdown)\n{\n\tzend_mm_shutdown(AG(mm_heap), full_shutdown, silent);\n}\n\nstatic void alloc_globals_ctor(zend_alloc_globals *alloc_globals)\n{\n#if ZEND_MM_CUSTOM\n\tchar *tmp = getenv(\"USE_ZEND_ALLOC\");\n\n\tif (tmp && !zend_atoi(tmp, 0)) {\n\t\talloc_globals->mm_heap = malloc(sizeof(zend_mm_heap));\n\t\tmemset(alloc_globals->mm_heap, 0, sizeof(zend_mm_heap));\n\t\talloc_globals->mm_heap->use_custom_heap = ZEND_MM_CUSTOM_HEAP_STD;\n\t\talloc_globals->mm_heap->custom_heap.std._malloc = malloc;\n\t\talloc_globals->mm_heap->custom_heap.std._free = free;\n\t\talloc_globals->mm_heap->custom_heap.std._realloc = realloc;\n\t\treturn;\n\t}\n#endif\n#ifdef MAP_HUGETLB\n\ttmp = getenv(\"USE_ZEND_ALLOC_HUGE_PAGES\");\n\tif (tmp && zend_atoi(tmp, 0)) {\n\t\tzend_mm_use_huge_pages = 1;\n\t}\n#endif\n\tZEND_TSRMLS_CACHE_UPDATE();\n\talloc_globals->mm_heap = zend_mm_init();\n}\n\n#ifdef ZTS\nstatic void alloc_globals_dtor(zend_alloc_globals *alloc_globals)\n{\n\tzend_mm_shutdown(alloc_globals->mm_heap, 1, 1);\n}\n#endif\n\nZEND_API void start_memory_manager(void)\n{\n#ifdef ZTS\n\tts_allocate_id(&alloc_globals_id, sizeof(zend_alloc_globals), (ts_allocate_ctor) alloc_globals_ctor, (ts_allocate_dtor) alloc_globals_dtor);\n#else\n\talloc_globals_ctor(&alloc_globals);\n#endif\n#ifndef _WIN32\n#  if defined(_SC_PAGESIZE)\n\tREAL_PAGE_SIZE = sysconf(_SC_PAGESIZE);\n#  elif defined(_SC_PAGE_SIZE)\n\tREAL_PAGE_SIZE = sysconf(_SC_PAGE_SIZE);\n#  endif\n#endif\n}\n\nZEND_API zend_mm_heap *zend_mm_set_heap(zend_mm_heap *new_heap)\n{\n\tzend_mm_heap *old_heap;\n\n\told_heap = AG(mm_heap);\n\tAG(mm_heap) = (zend_mm_heap*)new_heap;\n\treturn (zend_mm_heap*)old_heap;\n}\n\nZEND_API zend_mm_heap *zend_mm_get_heap(void)\n{\n\treturn AG(mm_heap);\n}\n\nZEND_API int zend_mm_is_custom_heap(zend_mm_heap *new_heap)\n{\n#if ZEND_MM_CUSTOM\n\treturn AG(mm_heap)->use_custom_heap;\n#else\n\treturn 0;\n#endif\n}\n\nZEND_API void zend_mm_set_custom_handlers(zend_mm_heap *heap,\n                                          void* (*_malloc)(size_t),\n                                          void  (*_free)(void*),\n                                          void* (*_realloc)(void*, size_t))\n{\n#if ZEND_MM_CUSTOM\n\tzend_mm_heap *_heap = (zend_mm_heap*)heap;\n\n\t_heap->use_custom_heap = ZEND_MM_CUSTOM_HEAP_STD;\n\t_heap->custom_heap.std._malloc = _malloc;\n\t_heap->custom_heap.std._free = _free;\n\t_heap->custom_heap.std._realloc = _realloc;\n#endif\n}\n\nZEND_API void zend_mm_get_custom_handlers(zend_mm_heap *heap,\n                                          void* (**_malloc)(size_t),\n                                          void  (**_free)(void*),\n                                          void* (**_realloc)(void*, size_t))\n{\n#if ZEND_MM_CUSTOM\n\tzend_mm_heap *_heap = (zend_mm_heap*)heap;\n\n\tif (heap->use_custom_heap) {\n\t\t*_malloc = _heap->custom_heap.std._malloc;\n\t\t*_free = _heap->custom_heap.std._free;\n\t\t*_realloc = _heap->custom_heap.std._realloc;\n\t} else {\n\t\t*_malloc = NULL;\n\t\t*_free = NULL;\n\t\t*_realloc = NULL;\n\t}\n#else\n\t*_malloc = NULL;\n\t*_free = NULL;\n\t*_realloc = NULL;\n#endif\n}\n\n#if ZEND_DEBUG\nZEND_API void zend_mm_set_custom_debug_handlers(zend_mm_heap *heap,\n                                          void* (*_malloc)(size_t ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC),\n                                          void  (*_free)(void* ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC),\n                                          void* (*_realloc)(void*, size_t ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC))\n{\n#if ZEND_MM_CUSTOM\n\tzend_mm_heap *_heap = (zend_mm_heap*)heap;\n\n\t_heap->use_custom_heap = ZEND_MM_CUSTOM_HEAP_DEBUG;\n\t_heap->custom_heap.debug._malloc = _malloc;\n\t_heap->custom_heap.debug._free = _free;\n\t_heap->custom_heap.debug._realloc = _realloc;\n#endif\n}\n#endif\n\nZEND_API zend_mm_storage *zend_mm_get_storage(zend_mm_heap *heap)\n{\n#if ZEND_MM_STORAGE\n\treturn heap->storage;\n#else\n\treturn NULL\n#endif\n}\n\nZEND_API zend_mm_heap *zend_mm_startup(void)\n{\n\treturn zend_mm_init();\n}\n\nZEND_API zend_mm_heap *zend_mm_startup_ex(const zend_mm_handlers *handlers, void *data, size_t data_size)\n{\n#if ZEND_MM_STORAGE\n\tzend_mm_storage tmp_storage, *storage;\n\tzend_mm_chunk *chunk;\n\tzend_mm_heap *heap;\n\n\tmemcpy((zend_mm_handlers*)&tmp_storage.handlers, handlers, sizeof(zend_mm_handlers));\n\ttmp_storage.data = data;\n\tchunk = (zend_mm_chunk*)handlers->chunk_alloc(&tmp_storage, ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE);\n\tif (UNEXPECTED(chunk == NULL)) {\n#if ZEND_MM_ERROR\n#ifdef _WIN32\n\t\tstderr_last_error(\"Can't initialize heap\");\n#else\n\t\tfprintf(stderr, \"\\nCan't initialize heap: [%d] %s\\n\", errno, strerror(errno));\n#endif\n#endif\n\t\treturn NULL;\n\t}\n\theap = &chunk->heap_slot;\n\tchunk->heap = heap;\n\tchunk->next = chunk;\n\tchunk->prev = chunk;\n\tchunk->free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\tchunk->free_tail = ZEND_MM_FIRST_PAGE;\n\tchunk->num = 0;\n\tchunk->free_map[0] = (Z_L(1) << ZEND_MM_FIRST_PAGE) - 1;\n\tchunk->map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE);\n\theap->main_chunk = chunk;\n\theap->cached_chunks = NULL;\n\theap->chunks_count = 1;\n\theap->peak_chunks_count = 1;\n\theap->cached_chunks_count = 0;\n\theap->avg_chunks_count = 1.0;\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\theap->real_size = ZEND_MM_CHUNK_SIZE;\n#endif\n#if ZEND_MM_STAT\n\theap->real_peak = ZEND_MM_CHUNK_SIZE;\n\theap->size = 0;\n\theap->peak = 0;\n#endif\n#if ZEND_MM_LIMIT\n\theap->limit = (Z_L(-1) >> Z_L(1));\n\theap->overflow = 0;\n#endif\n#if ZEND_MM_CUSTOM\n\theap->use_custom_heap = 0;\n#endif\n\theap->storage = &tmp_storage;\n\theap->huge_list = NULL;\n\tmemset(heap->free_slot, 0, sizeof(heap->free_slot));\n\tstorage = _zend_mm_alloc(heap, sizeof(zend_mm_storage) + data_size ZEND_FILE_LINE_CC ZEND_FILE_LINE_CC);\n\tif (!storage) {\n\t\thandlers->chunk_free(&tmp_storage, chunk, ZEND_MM_CHUNK_SIZE);\n#if ZEND_MM_ERROR\n#ifdef _WIN32\n\t\tstderr_last_error(\"Can't initialize heap\");\n#else\n\t\tfprintf(stderr, \"\\nCan't initialize heap: [%d] %s\\n\", errno, strerror(errno));\n#endif\n#endif\n\t\treturn NULL;\n\t}\n\tmemcpy(storage, &tmp_storage, sizeof(zend_mm_storage));\n\tif (data) {\n\t\tstorage->data = (void*)(((char*)storage + sizeof(zend_mm_storage)));\n\t\tmemcpy(storage->data, data, data_size);\n\t}\n\theap->storage = storage;\n\treturn heap;\n#else\n\treturn NULL;\n#endif\n}\n\nstatic ZEND_COLD ZEND_NORETURN void zend_out_of_memory(void)\n{\n\tfprintf(stderr, \"Out of memory\\n\");\n\texit(1);\n}\n\nZEND_API void * __zend_malloc(size_t len)\n{\n\tvoid *tmp = malloc(len);\n\tif (EXPECTED(tmp)) {\n\t\treturn tmp;\n\t}\n\tzend_out_of_memory();\n}\n\nZEND_API void * __zend_calloc(size_t nmemb, size_t len)\n{\n\tvoid *tmp = _safe_malloc(nmemb, len, 0);\n\tmemset(tmp, 0, nmemb * len);\n\treturn tmp;\n}\n\nZEND_API void * __zend_realloc(void *p, size_t len)\n{\n\tp = realloc(p, len);\n\tif (EXPECTED(p)) {\n\t\treturn p;\n\t}\n\tzend_out_of_memory();\n}\n\n/*\n * Local variables:\n * tab-width: 4\n * c-basic-offset: 4\n * indent-tabs-mode: t\n * End:\n */\n"], "fixing_code": ["/*\n   +----------------------------------------------------------------------+\n   | Zend Engine                                                          |\n   +----------------------------------------------------------------------+\n   | Copyright (c) 1998-2016 Zend Technologies Ltd. (http://www.zend.com) |\n   +----------------------------------------------------------------------+\n   | This source file is subject to version 2.00 of the Zend license,     |\n   | that is bundled with this package in the file LICENSE, and is        |\n   | available through the world-wide-web at the following url:           |\n   | http://www.zend.com/license/2_00.txt.                                |\n   | If you did not receive a copy of the Zend license and are unable to  |\n   | obtain it through the world-wide-web, please send a note to          |\n   | license@zend.com so we can mail you a copy immediately.              |\n   +----------------------------------------------------------------------+\n   | Authors: Andi Gutmans <andi@zend.com>                                |\n   |          Zeev Suraski <zeev@zend.com>                                |\n   |          Dmitry Stogov <dmitry@zend.com>                             |\n   +----------------------------------------------------------------------+\n*/\n\n/* $Id$ */\n\n/*\n * zend_alloc is designed to be a modern CPU cache friendly memory manager\n * for PHP. Most ideas are taken from jemalloc and tcmalloc implementations.\n *\n * All allocations are split into 3 categories:\n *\n * Huge  - the size is greater than CHUNK size (~2M by default), allocation is\n *         performed using mmap(). The result is aligned on 2M boundary.\n *\n * Large - a number of 4096K pages inside a CHUNK. Large blocks\n *         are always aligned on page boundary.\n *\n * Small - less than 3/4 of page size. Small sizes are rounded up to nearest\n *         greater predefined small size (there are 30 predefined sizes:\n *         8, 16, 24, 32, ... 3072). Small blocks are allocated from\n *         RUNs. Each RUN is allocated as a single or few following pages.\n *         Allocation inside RUNs implemented using linked list of free\n *         elements. The result is aligned to 8 bytes.\n *\n * zend_alloc allocates memory from OS by CHUNKs, these CHUNKs and huge memory\n * blocks are always aligned to CHUNK boundary. So it's very easy to determine\n * the CHUNK owning the certain pointer. Regular CHUNKs reserve a single\n * page at start for special purpose. It contains bitset of free pages,\n * few bitset for available runs of predefined small sizes, map of pages that\n * keeps information about usage of each page in this CHUNK, etc.\n *\n * zend_alloc provides familiar emalloc/efree/erealloc API, but in addition it\n * provides specialized and optimized routines to allocate blocks of predefined\n * sizes (e.g. emalloc_2(), emallc_4(), ..., emalloc_large(), etc)\n * The library uses C preprocessor tricks that substitute calls to emalloc()\n * with more specialized routines when the requested size is known.\n */\n\n#include \"zend.h\"\n#include \"zend_alloc.h\"\n#include \"zend_globals.h\"\n#include \"zend_operators.h\"\n#include \"zend_multiply.h\"\n\n#ifdef HAVE_SIGNAL_H\n# include <signal.h>\n#endif\n#ifdef HAVE_UNISTD_H\n# include <unistd.h>\n#endif\n\n#ifdef ZEND_WIN32\n# include <wincrypt.h>\n# include <process.h>\n#endif\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n\n#include <sys/types.h>\n#include <sys/stat.h>\n#if HAVE_LIMITS_H\n#include <limits.h>\n#endif\n#include <fcntl.h>\n#include <errno.h>\n\n#ifndef _WIN32\n# ifdef HAVE_MREMAP\n#  ifndef _GNU_SOURCE\n#   define _GNU_SOURCE\n#  endif\n#  ifndef __USE_GNU\n#   define __USE_GNU\n#  endif\n# endif\n# include <sys/mman.h>\n# ifndef MAP_ANON\n#  ifdef MAP_ANONYMOUS\n#   define MAP_ANON MAP_ANONYMOUS\n#  endif\n# endif\n# ifndef MREMAP_MAYMOVE\n#  define MREMAP_MAYMOVE 0\n# endif\n# ifndef MAP_FAILED\n#  define MAP_FAILED ((void*)-1)\n# endif\n# ifndef MAP_POPULATE\n#  define MAP_POPULATE 0\n# endif\n#  if defined(_SC_PAGESIZE) || (_SC_PAGE_SIZE)\n#    define REAL_PAGE_SIZE _real_page_size\nstatic size_t _real_page_size = ZEND_MM_PAGE_SIZE;\n#  endif\n#endif\n\n#ifndef REAL_PAGE_SIZE\n# define REAL_PAGE_SIZE ZEND_MM_PAGE_SIZE\n#endif\n\n#ifndef ZEND_MM_STAT\n# define ZEND_MM_STAT 1    /* track current and peak memory usage            */\n#endif\n#ifndef ZEND_MM_LIMIT\n# define ZEND_MM_LIMIT 1   /* support for user-defined memory limit          */\n#endif\n#ifndef ZEND_MM_CUSTOM\n# define ZEND_MM_CUSTOM 1  /* support for custom memory allocator            */\n                           /* USE_ZEND_ALLOC=0 may switch to system malloc() */\n#endif\n#ifndef ZEND_MM_STORAGE\n# define ZEND_MM_STORAGE 1 /* support for custom memory storage              */\n#endif\n#ifndef ZEND_MM_ERROR\n# define ZEND_MM_ERROR 1   /* report system errors                           */\n#endif\n\n#ifndef ZEND_MM_CHECK\n# define ZEND_MM_CHECK(condition, message)  do { \\\n\t\tif (UNEXPECTED(!(condition))) { \\\n\t\t\tzend_mm_panic(message); \\\n\t\t} \\\n\t} while (0)\n#endif\n\ntypedef uint32_t   zend_mm_page_info; /* 4-byte integer */\ntypedef zend_ulong zend_mm_bitset;    /* 4-byte or 8-byte integer */\n\n#define ZEND_MM_ALIGNED_OFFSET(size, alignment) \\\n\t(((size_t)(size)) & ((alignment) - 1))\n#define ZEND_MM_ALIGNED_BASE(size, alignment) \\\n\t(((size_t)(size)) & ~((alignment) - 1))\n#define ZEND_MM_SIZE_TO_NUM(size, alignment) \\\n\t(((size_t)(size) + ((alignment) - 1)) / (alignment))\n\n#define ZEND_MM_BITSET_LEN\t\t(sizeof(zend_mm_bitset) * 8)       /* 32 or 64 */\n#define ZEND_MM_PAGE_MAP_LEN\t(ZEND_MM_PAGES / ZEND_MM_BITSET_LEN) /* 16 or 8 */\n\ntypedef zend_mm_bitset zend_mm_page_map[ZEND_MM_PAGE_MAP_LEN];     /* 64B */\n\n#define ZEND_MM_IS_FRUN                  0x00000000\n#define ZEND_MM_IS_LRUN                  0x40000000\n#define ZEND_MM_IS_SRUN                  0x80000000\n\n#define ZEND_MM_LRUN_PAGES_MASK          0x000003ff\n#define ZEND_MM_LRUN_PAGES_OFFSET        0\n\n#define ZEND_MM_SRUN_BIN_NUM_MASK        0x0000001f\n#define ZEND_MM_SRUN_BIN_NUM_OFFSET      0\n\n#define ZEND_MM_SRUN_FREE_COUNTER_MASK   0x01ff0000\n#define ZEND_MM_SRUN_FREE_COUNTER_OFFSET 16\n\n#define ZEND_MM_NRUN_OFFSET_MASK         0x01ff0000\n#define ZEND_MM_NRUN_OFFSET_OFFSET       16\n\n#define ZEND_MM_LRUN_PAGES(info)         (((info) & ZEND_MM_LRUN_PAGES_MASK) >> ZEND_MM_LRUN_PAGES_OFFSET)\n#define ZEND_MM_SRUN_BIN_NUM(info)       (((info) & ZEND_MM_SRUN_BIN_NUM_MASK) >> ZEND_MM_SRUN_BIN_NUM_OFFSET)\n#define ZEND_MM_SRUN_FREE_COUNTER(info)  (((info) & ZEND_MM_SRUN_FREE_COUNTER_MASK) >> ZEND_MM_SRUN_FREE_COUNTER_OFFSET)\n#define ZEND_MM_NRUN_OFFSET(info)        (((info) & ZEND_MM_NRUN_OFFSET_MASK) >> ZEND_MM_NRUN_OFFSET_OFFSET)\n\n#define ZEND_MM_FRUN()                   ZEND_MM_IS_FRUN\n#define ZEND_MM_LRUN(count)              (ZEND_MM_IS_LRUN | ((count) << ZEND_MM_LRUN_PAGES_OFFSET))\n#define ZEND_MM_SRUN(bin_num)            (ZEND_MM_IS_SRUN | ((bin_num) << ZEND_MM_SRUN_BIN_NUM_OFFSET))\n#define ZEND_MM_SRUN_EX(bin_num, count)  (ZEND_MM_IS_SRUN | ((bin_num) << ZEND_MM_SRUN_BIN_NUM_OFFSET) | ((count) << ZEND_MM_SRUN_FREE_COUNTER_OFFSET))\n#define ZEND_MM_NRUN(bin_num, offset)    (ZEND_MM_IS_SRUN | ZEND_MM_IS_LRUN | ((bin_num) << ZEND_MM_SRUN_BIN_NUM_OFFSET) | ((offset) << ZEND_MM_NRUN_OFFSET_OFFSET))\n\n#define ZEND_MM_BINS 30\n\ntypedef struct  _zend_mm_page      zend_mm_page;\ntypedef struct  _zend_mm_bin       zend_mm_bin;\ntypedef struct  _zend_mm_free_slot zend_mm_free_slot;\ntypedef struct  _zend_mm_chunk     zend_mm_chunk;\ntypedef struct  _zend_mm_huge_list zend_mm_huge_list;\n\n#ifdef _WIN64\n# define PTR_FMT \"0x%0.16I64x\"\n#elif SIZEOF_LONG == 8\n# define PTR_FMT \"0x%0.16lx\"\n#else\n# define PTR_FMT \"0x%0.8lx\"\n#endif\n\n#ifdef MAP_HUGETLB\nint zend_mm_use_huge_pages = 0;\n#endif\n\n/*\n * Memory is retrived from OS by chunks of fixed size 2MB.\n * Inside chunk it's managed by pages of fixed size 4096B.\n * So each chunk consists from 512 pages.\n * The first page of each chunk is reseved for chunk header.\n * It contains service information about all pages.\n *\n * free_pages - current number of free pages in this chunk\n *\n * free_tail  - number of continuous free pages at the end of chunk\n *\n * free_map   - bitset (a bit for each page). The bit is set if the corresponding\n *              page is allocated. Allocator for \"lage sizes\" may easily find a\n *              free page (or a continuous number of pages) searching for zero\n *              bits.\n *\n * map        - contains service information for each page. (32-bits for each\n *              page).\n *    usage:\n *\t\t\t\t(2 bits)\n * \t\t\t\tFRUN - free page,\n *              LRUN - first page of \"large\" allocation\n *              SRUN - first page of a bin used for \"small\" allocation\n *\n *    lrun_pages:\n *              (10 bits) number of allocated pages\n *\n *    srun_bin_num:\n *              (5 bits) bin number (e.g. 0 for sizes 0-2, 1 for 3-4,\n *               2 for 5-8, 3 for 9-16 etc) see zend_alloc_sizes.h\n */\n\nstruct _zend_mm_heap {\n#if ZEND_MM_CUSTOM\n\tint                use_custom_heap;\n#endif\n#if ZEND_MM_STORAGE\n\tzend_mm_storage   *storage;\n#endif\n#if ZEND_MM_STAT\n\tsize_t             size;                    /* current memory usage */\n\tsize_t             peak;                    /* peak memory usage */\n#endif\n\tzend_mm_free_slot *free_slot[ZEND_MM_BINS]; /* free lists for small sizes */\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\tsize_t             real_size;               /* current size of allocated pages */\n#endif\n#if ZEND_MM_STAT\n\tsize_t             real_peak;               /* peak size of allocated pages */\n#endif\n#if ZEND_MM_LIMIT\n\tsize_t             limit;                   /* memory limit */\n\tint                overflow;                /* memory overflow flag */\n#endif\n\n\tzend_mm_huge_list *huge_list;               /* list of huge allocated blocks */\n\n\tzend_mm_chunk     *main_chunk;\n\tzend_mm_chunk     *cached_chunks;\t\t\t/* list of unused chunks */\n\tint                chunks_count;\t\t\t/* number of alocated chunks */\n\tint                peak_chunks_count;\t\t/* peak number of allocated chunks for current request */\n\tint                cached_chunks_count;\t\t/* number of cached chunks */\n\tdouble             avg_chunks_count;\t\t/* average number of chunks allocated per request */\n#if ZEND_MM_CUSTOM\n\tunion {\n\t\tstruct {\n\t\t\tvoid      *(*_malloc)(size_t);\n\t\t\tvoid       (*_free)(void*);\n\t\t\tvoid      *(*_realloc)(void*, size_t);\n\t\t} std;\n\t\tstruct {\n\t\t\tvoid      *(*_malloc)(size_t ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n\t\t\tvoid       (*_free)(void*  ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n\t\t\tvoid      *(*_realloc)(void*, size_t  ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n\t\t} debug;\n\t} custom_heap;\n#endif\n};\n\nstruct _zend_mm_chunk {\n\tzend_mm_heap      *heap;\n\tzend_mm_chunk     *next;\n\tzend_mm_chunk     *prev;\n\tint                free_pages;\t\t\t\t/* number of free pages */\n\tint                free_tail;               /* number of free pages at the end of chunk */\n\tint                num;\n\tchar               reserve[64 - (sizeof(void*) * 3 + sizeof(int) * 3)];\n\tzend_mm_heap       heap_slot;               /* used only in main chunk */\n\tzend_mm_page_map   free_map;                /* 512 bits or 64 bytes */\n\tzend_mm_page_info  map[ZEND_MM_PAGES];      /* 2 KB = 512 * 4 */\n};\n\nstruct _zend_mm_page {\n\tchar               bytes[ZEND_MM_PAGE_SIZE];\n};\n\n/*\n * bin - is one or few continuous pages (up to 8) used for allocation of\n * a particular \"small size\".\n */\nstruct _zend_mm_bin {\n\tchar               bytes[ZEND_MM_PAGE_SIZE * 8];\n};\n\nstruct _zend_mm_free_slot {\n\tzend_mm_free_slot *next_free_slot;\n};\n\nstruct _zend_mm_huge_list {\n\tvoid              *ptr;\n\tsize_t             size;\n\tzend_mm_huge_list *next;\n#if ZEND_DEBUG\n\tzend_mm_debug_info dbg;\n#endif\n};\n\n#define ZEND_MM_PAGE_ADDR(chunk, page_num) \\\n\t((void*)(((zend_mm_page*)(chunk)) + (page_num)))\n\n#define _BIN_DATA_SIZE(num, size, elements, pages, x, y) size,\nstatic const unsigned int bin_data_size[] = {\n  ZEND_MM_BINS_INFO(_BIN_DATA_SIZE, x, y)\n};\n\n#define _BIN_DATA_ELEMENTS(num, size, elements, pages, x, y) elements,\nstatic const int bin_elements[] = {\n  ZEND_MM_BINS_INFO(_BIN_DATA_ELEMENTS, x, y)\n};\n\n#define _BIN_DATA_PAGES(num, size, elements, pages, x, y) pages,\nstatic const int bin_pages[] = {\n  ZEND_MM_BINS_INFO(_BIN_DATA_PAGES, x, y)\n};\n\n#if ZEND_DEBUG\nZEND_COLD void zend_debug_alloc_output(char *format, ...)\n{\n\tchar output_buf[256];\n\tva_list args;\n\n\tva_start(args, format);\n\tvsprintf(output_buf, format, args);\n\tva_end(args);\n\n#ifdef ZEND_WIN32\n\tOutputDebugString(output_buf);\n#else\n\tfprintf(stderr, \"%s\", output_buf);\n#endif\n}\n#endif\n\nstatic ZEND_COLD ZEND_NORETURN void zend_mm_panic(const char *message)\n{\n\tfprintf(stderr, \"%s\\n\", message);\n/* See http://support.microsoft.com/kb/190351 */\n#ifdef ZEND_WIN32\n\tfflush(stderr);\n#endif\n#if ZEND_DEBUG && defined(HAVE_KILL) && defined(HAVE_GETPID)\n\tkill(getpid(), SIGSEGV);\n#endif\n\texit(1);\n}\n\nstatic ZEND_COLD ZEND_NORETURN void zend_mm_safe_error(zend_mm_heap *heap,\n\tconst char *format,\n\tsize_t limit,\n#if ZEND_DEBUG\n\tconst char *filename,\n\tuint lineno,\n#endif\n\tsize_t size)\n{\n\n\theap->overflow = 1;\n\tzend_try {\n\t\tzend_error_noreturn(E_ERROR,\n\t\t\tformat,\n\t\t\tlimit,\n#if ZEND_DEBUG\n\t\t\tfilename,\n\t\t\tlineno,\n#endif\n\t\t\tsize);\n\t} zend_catch {\n\t}  zend_end_try();\n\theap->overflow = 0;\n\tzend_bailout();\n\texit(1);\n}\n\n#ifdef _WIN32\nvoid\nstderr_last_error(char *msg)\n{\n\tLPSTR buf = NULL;\n\tDWORD err = GetLastError();\n\n\tif (!FormatMessage(\n\t\t\tFORMAT_MESSAGE_ALLOCATE_BUFFER |\n\t\t\tFORMAT_MESSAGE_FROM_SYSTEM |\n\t\t\tFORMAT_MESSAGE_IGNORE_INSERTS,\n\t\t\tNULL,\n\t\t\terr,\n\t\t\tMAKELANGID(LANG_NEUTRAL, SUBLANG_DEFAULT),\n\t\t\t(LPSTR)&buf,\n\t\t0, NULL)) {\n\t\tfprintf(stderr, \"\\n%s: [0x%08lx]\\n\", msg, err);\n\t}\n\telse {\n\t\tfprintf(stderr, \"\\n%s: [0x%08lx] %s\\n\", msg, err, buf);\n\t}\n}\n#endif\n\n/*****************/\n/* OS Allocation */\n/*****************/\n\nstatic void *zend_mm_mmap_fixed(void *addr, size_t size)\n{\n#ifdef _WIN32\n\treturn VirtualAlloc(addr, size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE);\n#else\n\t/* MAP_FIXED leads to discarding of the old mapping, so it can't be used. */\n\tvoid *ptr = mmap(addr, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON /*| MAP_POPULATE | MAP_HUGETLB*/, -1, 0);\n\n\tif (ptr == MAP_FAILED) {\n#if ZEND_MM_ERROR\n\t\tfprintf(stderr, \"\\nmmap() failed: [%d] %s\\n\", errno, strerror(errno));\n#endif\n\t\treturn NULL;\n\t} else if (ptr != addr) {\n\t\tif (munmap(ptr, size) != 0) {\n#if ZEND_MM_ERROR\n\t\t\tfprintf(stderr, \"\\nmunmap() failed: [%d] %s\\n\", errno, strerror(errno));\n#endif\n\t\t}\n\t\treturn NULL;\n\t}\n\treturn ptr;\n#endif\n}\n\nstatic void *zend_mm_mmap(size_t size)\n{\n#ifdef _WIN32\n\tvoid *ptr = VirtualAlloc(NULL, size, MEM_COMMIT | MEM_RESERVE, PAGE_READWRITE);\n\n\tif (ptr == NULL) {\n#if ZEND_MM_ERROR\n\t\tstderr_last_error(\"VirtualAlloc() failed\");\n#endif\n\t\treturn NULL;\n\t}\n\treturn ptr;\n#else\n\tvoid *ptr;\n\n#ifdef MAP_HUGETLB\n\tif (zend_mm_use_huge_pages && size == ZEND_MM_CHUNK_SIZE) {\n\t\tptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON | MAP_HUGETLB, -1, 0);\n\t\tif (ptr != MAP_FAILED) {\n\t\t\treturn ptr;\n\t\t}\n\t}\n#endif\n\n\tptr = mmap(NULL, size, PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0);\n\n\tif (ptr == MAP_FAILED) {\n#if ZEND_MM_ERROR\n\t\tfprintf(stderr, \"\\nmmap() failed: [%d] %s\\n\", errno, strerror(errno));\n#endif\n\t\treturn NULL;\n\t}\n\treturn ptr;\n#endif\n}\n\nstatic void zend_mm_munmap(void *addr, size_t size)\n{\n#ifdef _WIN32\n\tif (VirtualFree(addr, 0, MEM_RELEASE) == 0) {\n#if ZEND_MM_ERROR\n\t\tstderr_last_error(\"VirtualFree() failed\");\n#endif\n\t}\n#else\n\tif (munmap(addr, size) != 0) {\n#if ZEND_MM_ERROR\n\t\tfprintf(stderr, \"\\nmunmap() failed: [%d] %s\\n\", errno, strerror(errno));\n#endif\n\t}\n#endif\n}\n\n/***********/\n/* Bitmask */\n/***********/\n\n/* number of trailing set (1) bits */\nstatic zend_always_inline int zend_mm_bitset_nts(zend_mm_bitset bitset)\n{\n#if (defined(__GNUC__) || __has_builtin(__builtin_ctzl)) && SIZEOF_ZEND_LONG == SIZEOF_LONG && defined(PHP_HAVE_BUILTIN_CTZL)\n\treturn __builtin_ctzl(~bitset);\n#elif (defined(__GNUC__) || __has_builtin(__builtin_ctzll)) && defined(PHP_HAVE_BUILTIN_CTZLL)\n\treturn __builtin_ctzll(~bitset);\n#elif defined(_WIN32)\n\tunsigned long index;\n\n#if defined(_WIN64)\n\tif (!BitScanForward64(&index, ~bitset)) {\n#else\n\tif (!BitScanForward(&index, ~bitset)) {\n#endif\n\t\t/* undefined behavior */\n\t\treturn 32;\n\t}\n\n\treturn (int)index;\n#else\n\tint n;\n\n\tif (bitset == (zend_mm_bitset)-1) return ZEND_MM_BITSET_LEN;\n\n\tn = 0;\n#if SIZEOF_ZEND_LONG == 8\n\tif (sizeof(zend_mm_bitset) == 8) {\n\t\tif ((bitset & 0xffffffff) == 0xffffffff) {n += 32; bitset = bitset >> Z_UL(32);}\n\t}\n#endif\n\tif ((bitset & 0x0000ffff) == 0x0000ffff) {n += 16; bitset = bitset >> 16;}\n\tif ((bitset & 0x000000ff) == 0x000000ff) {n +=  8; bitset = bitset >>  8;}\n\tif ((bitset & 0x0000000f) == 0x0000000f) {n +=  4; bitset = bitset >>  4;}\n\tif ((bitset & 0x00000003) == 0x00000003) {n +=  2; bitset = bitset >>  2;}\n\treturn n + (bitset & 1);\n#endif\n}\n\n/* number of trailing zero bits (0x01 -> 1; 0x40 -> 6; 0x00 -> LEN) */\nstatic zend_always_inline int zend_mm_bitset_ntz(zend_mm_bitset bitset)\n{\n#if (defined(__GNUC__) || __has_builtin(__builtin_ctzl)) && SIZEOF_ZEND_LONG == SIZEOF_LONG && defined(PHP_HAVE_BUILTIN_CTZL)\n\treturn __builtin_ctzl(bitset);\n#elif (defined(__GNUC__) || __has_builtin(__builtin_ctzll)) && defined(PHP_HAVE_BUILTIN_CTZLL)\n\treturn __builtin_ctzll(bitset);\n#elif defined(_WIN32)\n\tunsigned long index;\n\n#if defined(_WIN64)\n\tif (!BitScanForward64(&index, bitset)) {\n#else\n\tif (!BitScanForward(&index, bitset)) {\n#endif\n\t\t/* undefined behavior */\n\t\treturn 32;\n\t}\n\n\treturn (int)index;\n#else\n\tint n;\n\n\tif (bitset == (zend_mm_bitset)0) return ZEND_MM_BITSET_LEN;\n\n\tn = 1;\n#if SIZEOF_ZEND_LONG == 8\n\tif (sizeof(zend_mm_bitset) == 8) {\n\t\tif ((bitset & 0xffffffff) == 0) {n += 32; bitset = bitset >> Z_UL(32);}\n\t}\n#endif\n\tif ((bitset & 0x0000ffff) == 0) {n += 16; bitset = bitset >> 16;}\n\tif ((bitset & 0x000000ff) == 0) {n +=  8; bitset = bitset >>  8;}\n\tif ((bitset & 0x0000000f) == 0) {n +=  4; bitset = bitset >>  4;}\n\tif ((bitset & 0x00000003) == 0) {n +=  2; bitset = bitset >>  2;}\n\treturn n - (bitset & 1);\n#endif\n}\n\nstatic zend_always_inline int zend_mm_bitset_find_zero(zend_mm_bitset *bitset, int size)\n{\n\tint i = 0;\n\n\tdo {\n\t\tzend_mm_bitset tmp = bitset[i];\n\t\tif (tmp != (zend_mm_bitset)-1) {\n\t\t\treturn i * ZEND_MM_BITSET_LEN + zend_mm_bitset_nts(tmp);\n\t\t}\n\t\ti++;\n\t} while (i < size);\n\treturn -1;\n}\n\nstatic zend_always_inline int zend_mm_bitset_find_one(zend_mm_bitset *bitset, int size)\n{\n\tint i = 0;\n\n\tdo {\n\t\tzend_mm_bitset tmp = bitset[i];\n\t\tif (tmp != 0) {\n\t\t\treturn i * ZEND_MM_BITSET_LEN + zend_mm_bitset_ntz(tmp);\n\t\t}\n\t\ti++;\n\t} while (i < size);\n\treturn -1;\n}\n\nstatic zend_always_inline int zend_mm_bitset_find_zero_and_set(zend_mm_bitset *bitset, int size)\n{\n\tint i = 0;\n\n\tdo {\n\t\tzend_mm_bitset tmp = bitset[i];\n\t\tif (tmp != (zend_mm_bitset)-1) {\n\t\t\tint n = zend_mm_bitset_nts(tmp);\n\t\t\tbitset[i] |= Z_UL(1) << n;\n\t\t\treturn i * ZEND_MM_BITSET_LEN + n;\n\t\t}\n\t\ti++;\n\t} while (i < size);\n\treturn -1;\n}\n\nstatic zend_always_inline int zend_mm_bitset_is_set(zend_mm_bitset *bitset, int bit)\n{\n\treturn (bitset[bit / ZEND_MM_BITSET_LEN] & (Z_L(1) << (bit & (ZEND_MM_BITSET_LEN-1)))) != 0;\n}\n\nstatic zend_always_inline void zend_mm_bitset_set_bit(zend_mm_bitset *bitset, int bit)\n{\n\tbitset[bit / ZEND_MM_BITSET_LEN] |= (Z_L(1) << (bit & (ZEND_MM_BITSET_LEN-1)));\n}\n\nstatic zend_always_inline void zend_mm_bitset_reset_bit(zend_mm_bitset *bitset, int bit)\n{\n\tbitset[bit / ZEND_MM_BITSET_LEN] &= ~(Z_L(1) << (bit & (ZEND_MM_BITSET_LEN-1)));\n}\n\nstatic zend_always_inline void zend_mm_bitset_set_range(zend_mm_bitset *bitset, int start, int len)\n{\n\tif (len == 1) {\n\t\tzend_mm_bitset_set_bit(bitset, start);\n\t} else {\n\t\tint pos = start / ZEND_MM_BITSET_LEN;\n\t\tint end = (start + len - 1) / ZEND_MM_BITSET_LEN;\n\t\tint bit = start & (ZEND_MM_BITSET_LEN - 1);\n\t\tzend_mm_bitset tmp;\n\n\t\tif (pos != end) {\n\t\t\t/* set bits from \"bit\" to ZEND_MM_BITSET_LEN-1 */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\tbitset[pos++] |= tmp;\n\t\t\twhile (pos != end) {\n\t\t\t\t/* set all bits */\n\t\t\t\tbitset[pos++] = (zend_mm_bitset)-1;\n\t\t\t}\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* set bits from \"0\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\tbitset[pos] |= tmp;\n\t\t} else {\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* set bits from \"bit\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\ttmp &= (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\tbitset[pos] |= tmp;\n\t\t}\n\t}\n}\n\nstatic zend_always_inline void zend_mm_bitset_reset_range(zend_mm_bitset *bitset, int start, int len)\n{\n\tif (len == 1) {\n\t\tzend_mm_bitset_reset_bit(bitset, start);\n\t} else {\n\t\tint pos = start / ZEND_MM_BITSET_LEN;\n\t\tint end = (start + len - 1) / ZEND_MM_BITSET_LEN;\n\t\tint bit = start & (ZEND_MM_BITSET_LEN - 1);\n\t\tzend_mm_bitset tmp;\n\n\t\tif (pos != end) {\n\t\t\t/* reset bits from \"bit\" to ZEND_MM_BITSET_LEN-1 */\n\t\t\ttmp = ~((Z_L(1) << bit) - 1);\n\t\t\tbitset[pos++] &= ~tmp;\n\t\t\twhile (pos != end) {\n\t\t\t\t/* set all bits */\n\t\t\t\tbitset[pos++] = 0;\n\t\t\t}\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* reset bits from \"0\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\tbitset[pos] &= ~tmp;\n\t\t} else {\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* reset bits from \"bit\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\ttmp &= (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\tbitset[pos] &= ~tmp;\n\t\t}\n\t}\n}\n\nstatic zend_always_inline int zend_mm_bitset_is_free_range(zend_mm_bitset *bitset, int start, int len)\n{\n\tif (len == 1) {\n\t\treturn !zend_mm_bitset_is_set(bitset, start);\n\t} else {\n\t\tint pos = start / ZEND_MM_BITSET_LEN;\n\t\tint end = (start + len - 1) / ZEND_MM_BITSET_LEN;\n\t\tint bit = start & (ZEND_MM_BITSET_LEN - 1);\n\t\tzend_mm_bitset tmp;\n\n\t\tif (pos != end) {\n\t\t\t/* set bits from \"bit\" to ZEND_MM_BITSET_LEN-1 */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\tif ((bitset[pos++] & tmp) != 0) {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t\twhile (pos != end) {\n\t\t\t\t/* set all bits */\n\t\t\t\tif (bitset[pos++] != 0) {\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* set bits from \"0\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\treturn (bitset[pos] & tmp) == 0;\n\t\t} else {\n\t\t\tend = (start + len - 1) & (ZEND_MM_BITSET_LEN - 1);\n\t\t\t/* set bits from \"bit\" to \"end\" */\n\t\t\ttmp = (zend_mm_bitset)-1 << bit;\n\t\t\ttmp &= (zend_mm_bitset)-1 >> ((ZEND_MM_BITSET_LEN - 1) - end);\n\t\t\treturn (bitset[pos] & tmp) == 0;\n\t\t}\n\t}\n}\n\n/**********/\n/* Chunks */\n/**********/\n\nstatic void *zend_mm_chunk_alloc_int(size_t size, size_t alignment)\n{\n\tvoid *ptr = zend_mm_mmap(size);\n\n\tif (ptr == NULL) {\n\t\treturn NULL;\n\t} else if (ZEND_MM_ALIGNED_OFFSET(ptr, alignment) == 0) {\n#ifdef MADV_HUGEPAGE\n\t    madvise(ptr, size, MADV_HUGEPAGE);\n#endif\n\t\treturn ptr;\n\t} else {\n\t\tsize_t offset;\n\n\t\t/* chunk has to be aligned */\n\t\tzend_mm_munmap(ptr, size);\n\t\tptr = zend_mm_mmap(size + alignment - REAL_PAGE_SIZE);\n#ifdef _WIN32\n\t\toffset = ZEND_MM_ALIGNED_OFFSET(ptr, alignment);\n\t\tzend_mm_munmap(ptr, size + alignment - REAL_PAGE_SIZE);\n\t\tptr = zend_mm_mmap_fixed((void*)((char*)ptr + (alignment - offset)), size);\n\t\toffset = ZEND_MM_ALIGNED_OFFSET(ptr, alignment);\n\t\tif (offset != 0) {\n\t\t\tzend_mm_munmap(ptr, size);\n\t\t\treturn NULL;\n\t\t}\n\t\treturn ptr;\n#else\n\t\toffset = ZEND_MM_ALIGNED_OFFSET(ptr, alignment);\n\t\tif (offset != 0) {\n\t\t\toffset = alignment - offset;\n\t\t\tzend_mm_munmap(ptr, offset);\n\t\t\tptr = (char*)ptr + offset;\n\t\t\talignment -= offset;\n\t\t}\n\t\tif (alignment > REAL_PAGE_SIZE) {\n\t\t\tzend_mm_munmap((char*)ptr + size, alignment - REAL_PAGE_SIZE);\n\t\t}\n# ifdef MADV_HUGEPAGE\n\t    madvise(ptr, size, MADV_HUGEPAGE);\n# endif\n#endif\n\t\treturn ptr;\n\t}\n}\n\nstatic void *zend_mm_chunk_alloc(zend_mm_heap *heap, size_t size, size_t alignment)\n{\n#if ZEND_MM_STORAGE\n\tif (UNEXPECTED(heap->storage)) {\n\t\tvoid *ptr = heap->storage->handlers.chunk_alloc(heap->storage, size, alignment);\n\t\tZEND_ASSERT(((zend_uintptr_t)((char*)ptr + (alignment-1)) & (alignment-1)) == (zend_uintptr_t)ptr);\n\t\treturn ptr;\n\t}\n#endif\n\treturn zend_mm_chunk_alloc_int(size, alignment);\n}\n\nstatic void zend_mm_chunk_free(zend_mm_heap *heap, void *addr, size_t size)\n{\n#if ZEND_MM_STORAGE\n\tif (UNEXPECTED(heap->storage)) {\n\t\theap->storage->handlers.chunk_free(heap->storage, addr, size);\n\t\treturn;\n\t}\n#endif\n\tzend_mm_munmap(addr, size);\n}\n\nstatic int zend_mm_chunk_truncate(zend_mm_heap *heap, void *addr, size_t old_size, size_t new_size)\n{\n#if ZEND_MM_STORAGE\n\tif (UNEXPECTED(heap->storage)) {\n\t\tif (heap->storage->handlers.chunk_truncate) {\n\t\t\treturn heap->storage->handlers.chunk_truncate(heap->storage, addr, old_size, new_size);\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n#ifndef _WIN32\n\tzend_mm_munmap((char*)addr + new_size, old_size - new_size);\n\treturn 1;\n#else\n\treturn 0;\n#endif\n}\n\nstatic int zend_mm_chunk_extend(zend_mm_heap *heap, void *addr, size_t old_size, size_t new_size)\n{\n#if ZEND_MM_STORAGE\n\tif (UNEXPECTED(heap->storage)) {\n\t\tif (heap->storage->handlers.chunk_extend) {\n\t\t\treturn heap->storage->handlers.chunk_extend(heap->storage, addr, old_size, new_size);\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n#endif\n#ifndef _WIN32\n\treturn (zend_mm_mmap_fixed((char*)addr + old_size, new_size - old_size) != NULL);\n#else\n\treturn 0;\n#endif\n}\n\nstatic zend_always_inline void zend_mm_chunk_init(zend_mm_heap *heap, zend_mm_chunk *chunk)\n{\n\tchunk->heap = heap;\n\tchunk->next = heap->main_chunk;\n\tchunk->prev = heap->main_chunk->prev;\n\tchunk->prev->next = chunk;\n\tchunk->next->prev = chunk;\n\t/* mark first pages as allocated */\n\tchunk->free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\tchunk->free_tail = ZEND_MM_FIRST_PAGE;\n\t/* the younger chunks have bigger number */\n\tchunk->num = chunk->prev->num + 1;\n\t/* mark first pages as allocated */\n\tchunk->free_map[0] = (1L << ZEND_MM_FIRST_PAGE) - 1;\n\tchunk->map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE);\n}\n\n/***********************/\n/* Huge Runs (forward) */\n/***********************/\n\nstatic size_t zend_mm_get_huge_block_size(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\nstatic void *zend_mm_alloc_huge(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\nstatic void zend_mm_free_huge(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n\n#if ZEND_DEBUG\nstatic void zend_mm_change_huge_block_size(zend_mm_heap *heap, void *ptr, size_t size, size_t dbg_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n#else\nstatic void zend_mm_change_huge_block_size(zend_mm_heap *heap, void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC);\n#endif\n\n/**************/\n/* Large Runs */\n/**************/\n\n#if ZEND_DEBUG\nstatic void *zend_mm_alloc_pages(zend_mm_heap *heap, int pages_count, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#else\nstatic void *zend_mm_alloc_pages(zend_mm_heap *heap, int pages_count ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#endif\n{\n\tzend_mm_chunk *chunk = heap->main_chunk;\n\tint page_num, len;\n\n\twhile (1) {\n\t\tif (UNEXPECTED(chunk->free_pages < pages_count)) {\n\t\t\tgoto not_found;\n#if 0\n\t\t} else if (UNEXPECTED(chunk->free_pages + chunk->free_tail == ZEND_MM_PAGES)) {\n\t\t\tif (UNEXPECTED(ZEND_MM_PAGES - chunk->free_tail < pages_count)) {\n\t\t\t\tgoto not_found;\n\t\t\t} else {\n\t\t\t\tpage_num = chunk->free_tail;\n\t\t\t\tgoto found;\n\t\t\t}\n\t\t} else if (0) {\n\t\t\t/* First-Fit Search */\n\t\t\tint free_tail = chunk->free_tail;\n\t\t\tzend_mm_bitset *bitset = chunk->free_map;\n\t\t\tzend_mm_bitset tmp = *(bitset++);\n\t\t\tint i = 0;\n\n\t\t\twhile (1) {\n\t\t\t\t/* skip allocated blocks */\n\t\t\t\twhile (tmp == (zend_mm_bitset)-1) {\n\t\t\t\t\ti += ZEND_MM_BITSET_LEN;\n\t\t\t\t\tif (i == ZEND_MM_PAGES) {\n\t\t\t\t\t\tgoto not_found;\n\t\t\t\t\t}\n\t\t\t\t\ttmp = *(bitset++);\n\t\t\t\t}\n\t\t\t\t/* find first 0 bit */\n\t\t\t\tpage_num = i + zend_mm_bitset_nts(tmp);\n\t\t\t\t/* reset bits from 0 to \"bit\" */\n\t\t\t\ttmp &= tmp + 1;\n\t\t\t\t/* skip free blocks */\n\t\t\t\twhile (tmp == 0) {\n\t\t\t\t\ti += ZEND_MM_BITSET_LEN;\n\t\t\t\t\tlen = i - page_num;\n\t\t\t\t\tif (len >= pages_count) {\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\t} else if (i >= free_tail) {\n\t\t\t\t\t\tgoto not_found;\n\t\t\t\t\t}\n\t\t\t\t\ttmp = *(bitset++);\n\t\t\t\t}\n\t\t\t\t/* find first 1 bit */\n\t\t\t\tlen = (i + zend_mm_bitset_ntz(tmp)) - page_num;\n\t\t\t\tif (len >= pages_count) {\n\t\t\t\t\tgoto found;\n\t\t\t\t}\n\t\t\t\t/* set bits from 0 to \"bit\" */\n\t\t\t\ttmp |= tmp - 1;\n\t\t\t}\n#endif\n\t\t} else {\n\t\t\t/* Best-Fit Search */\n\t\t\tint best = -1;\n\t\t\tint best_len = ZEND_MM_PAGES;\n\t\t\tint free_tail = chunk->free_tail;\n\t\t\tzend_mm_bitset *bitset = chunk->free_map;\n\t\t\tzend_mm_bitset tmp = *(bitset++);\n\t\t\tint i = 0;\n\n\t\t\twhile (1) {\n\t\t\t\t/* skip allocated blocks */\n\t\t\t\twhile (tmp == (zend_mm_bitset)-1) {\n\t\t\t\t\ti += ZEND_MM_BITSET_LEN;\n\t\t\t\t\tif (i == ZEND_MM_PAGES) {\n\t\t\t\t\t\tif (best > 0) {\n\t\t\t\t\t\t\tpage_num = best;\n\t\t\t\t\t\t\tgoto found;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tgoto not_found;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttmp = *(bitset++);\n\t\t\t\t}\n\t\t\t\t/* find first 0 bit */\n\t\t\t\tpage_num = i + zend_mm_bitset_nts(tmp);\n\t\t\t\t/* reset bits from 0 to \"bit\" */\n\t\t\t\ttmp &= tmp + 1;\n\t\t\t\t/* skip free blocks */\n\t\t\t\twhile (tmp == 0) {\n\t\t\t\t\ti += ZEND_MM_BITSET_LEN;\n\t\t\t\t\tif (i >= free_tail || i == ZEND_MM_PAGES) {\n\t\t\t\t\t\tlen = ZEND_MM_PAGES - page_num;\n\t\t\t\t\t\tif (len >= pages_count && len < best_len) {\n\t\t\t\t\t\t\tchunk->free_tail = page_num + pages_count;\n\t\t\t\t\t\t\tgoto found;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t/* set accurate value */\n\t\t\t\t\t\t\tchunk->free_tail = page_num;\n\t\t\t\t\t\t\tif (best > 0) {\n\t\t\t\t\t\t\t\tpage_num = best;\n\t\t\t\t\t\t\t\tgoto found;\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\tgoto not_found;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\ttmp = *(bitset++);\n\t\t\t\t}\n\t\t\t\t/* find first 1 bit */\n\t\t\t\tlen = i + zend_mm_bitset_ntz(tmp) - page_num;\n\t\t\t\tif (len >= pages_count) {\n\t\t\t\t\tif (len == pages_count) {\n\t\t\t\t\t\tgoto found;\n\t\t\t\t\t} else if (len < best_len) {\n\t\t\t\t\t\tbest_len = len;\n\t\t\t\t\t\tbest = page_num;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t/* set bits from 0 to \"bit\" */\n\t\t\t\ttmp |= tmp - 1;\n\t\t\t}\n\t\t}\n\nnot_found:\n\t\tif (chunk->next == heap->main_chunk) {\nget_chunk:\n\t\t\tif (heap->cached_chunks) {\n\t\t\t\theap->cached_chunks_count--;\n\t\t\t\tchunk = heap->cached_chunks;\n\t\t\t\theap->cached_chunks = chunk->next;\n\t\t\t} else {\n#if ZEND_MM_LIMIT\n\t\t\t\tif (UNEXPECTED(heap->real_size + ZEND_MM_CHUNK_SIZE > heap->limit)) {\n\t\t\t\t\tif (zend_mm_gc(heap)) {\n\t\t\t\t\t\tgoto get_chunk;\n\t\t\t\t\t} else if (heap->overflow == 0) {\n#if ZEND_DEBUG\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted at %s:%d (tried to allocate %zu bytes)\", heap->limit, __zend_filename, __zend_lineno, size);\n#else\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted (tried to allocate %zu bytes)\", heap->limit, ZEND_MM_PAGE_SIZE * pages_count);\n#endif\n\t\t\t\t\t\treturn NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n#endif\n\t\t\t\tchunk = (zend_mm_chunk*)zend_mm_chunk_alloc(heap, ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE);\n\t\t\t\tif (UNEXPECTED(chunk == NULL)) {\n\t\t\t\t\t/* insufficient memory */\n\t\t\t\t\tif (zend_mm_gc(heap) &&\n\t\t\t\t\t    (chunk = (zend_mm_chunk*)zend_mm_chunk_alloc(heap, ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE)) != NULL) {\n\t\t\t\t\t\t/* pass */\n\t\t\t\t\t} else {\n#if !ZEND_MM_LIMIT\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Out of memory\");\n#elif ZEND_DEBUG\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Out of memory (allocated %zu) at %s:%d (tried to allocate %zu bytes)\", heap->real_size, __zend_filename, __zend_lineno, size);\n#else\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Out of memory (allocated %zu) (tried to allocate %zu bytes)\", heap->real_size, ZEND_MM_PAGE_SIZE * pages_count);\n#endif\n\t\t\t\t\t\treturn NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n#if ZEND_MM_STAT\n\t\t\t\tdo {\n\t\t\t\t\tsize_t size = heap->real_size + ZEND_MM_CHUNK_SIZE;\n\t\t\t\t\tsize_t peak = MAX(heap->real_peak, size);\n\t\t\t\t\theap->real_size = size;\n\t\t\t\t\theap->real_peak = peak;\n\t\t\t\t} while (0);\n#elif ZEND_MM_LIMIT\n\t\t\t\theap->real_size += ZEND_MM_CHUNK_SIZE;\n\n#endif\n\t\t\t}\n\t\t\theap->chunks_count++;\n\t\t\tif (heap->chunks_count > heap->peak_chunks_count) {\n\t\t\t\theap->peak_chunks_count = heap->chunks_count;\n\t\t\t}\n\t\t\tzend_mm_chunk_init(heap, chunk);\n\t\t\tpage_num = ZEND_MM_FIRST_PAGE;\n\t\t\tlen = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\t\t\tgoto found;\n\t\t} else {\n\t\t\tchunk = chunk->next;\n\t\t}\n\t}\n\nfound:\n\t/* mark run as allocated */\n\tchunk->free_pages -= pages_count;\n\tzend_mm_bitset_set_range(chunk->free_map, page_num, pages_count);\n\tchunk->map[page_num] = ZEND_MM_LRUN(pages_count);\n\tif (page_num == chunk->free_tail) {\n\t\tchunk->free_tail = page_num + pages_count;\n\t}\n\treturn ZEND_MM_PAGE_ADDR(chunk, page_num);\n}\n\nstatic zend_always_inline void *zend_mm_alloc_large(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tint pages_count = (int)ZEND_MM_SIZE_TO_NUM(size, ZEND_MM_PAGE_SIZE);\n#if ZEND_DEBUG\n\tvoid *ptr = zend_mm_alloc_pages(heap, pages_count, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\tvoid *ptr = zend_mm_alloc_pages(heap, pages_count ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n#if ZEND_MM_STAT\n\tdo {\n\t\tsize_t size = heap->size + pages_count * ZEND_MM_PAGE_SIZE;\n\t\tsize_t peak = MAX(heap->peak, size);\n\t\theap->size = size;\n\t\theap->peak = peak;\n\t} while (0);\n#endif\n\treturn ptr;\n}\n\nstatic zend_always_inline void zend_mm_delete_chunk(zend_mm_heap *heap, zend_mm_chunk *chunk)\n{\n\tchunk->next->prev = chunk->prev;\n\tchunk->prev->next = chunk->next;\n\theap->chunks_count--;\n\tif (heap->chunks_count + heap->cached_chunks_count < heap->avg_chunks_count + 0.1) {\n\t\t/* delay deletion */\n\t\theap->cached_chunks_count++;\n\t\tchunk->next = heap->cached_chunks;\n\t\theap->cached_chunks = chunk;\n\t} else {\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\t\theap->real_size -= ZEND_MM_CHUNK_SIZE;\n#endif\n\t\tif (!heap->cached_chunks || chunk->num > heap->cached_chunks->num) {\n\t\t\tzend_mm_chunk_free(heap, chunk, ZEND_MM_CHUNK_SIZE);\n\t\t} else {\n//TODO: select the best chunk to delete???\n\t\t\tchunk->next = heap->cached_chunks->next;\n\t\t\tzend_mm_chunk_free(heap, heap->cached_chunks, ZEND_MM_CHUNK_SIZE);\n\t\t\theap->cached_chunks = chunk;\n\t\t}\n\t}\n}\n\nstatic zend_always_inline void zend_mm_free_pages_ex(zend_mm_heap *heap, zend_mm_chunk *chunk, int page_num, int pages_count, int free_chunk)\n{\n\tchunk->free_pages += pages_count;\n\tzend_mm_bitset_reset_range(chunk->free_map, page_num, pages_count);\n\tchunk->map[page_num] = 0;\n\tif (chunk->free_tail == page_num + pages_count) {\n\t\t/* this setting may be not accurate */\n\t\tchunk->free_tail = page_num;\n\t}\n\tif (free_chunk && chunk->free_pages == ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE) {\n\t\tzend_mm_delete_chunk(heap, chunk);\n\t}\n}\n\nstatic void zend_mm_free_pages(zend_mm_heap *heap, zend_mm_chunk *chunk, int page_num, int pages_count)\n{\n\tzend_mm_free_pages_ex(heap, chunk, page_num, pages_count, 1);\n}\n\nstatic zend_always_inline void zend_mm_free_large(zend_mm_heap *heap, zend_mm_chunk *chunk, int page_num, int pages_count)\n{\n#if ZEND_MM_STAT\n\theap->size -= pages_count * ZEND_MM_PAGE_SIZE;\n#endif\n\tzend_mm_free_pages(heap, chunk, page_num, pages_count);\n}\n\n/**************/\n/* Small Runs */\n/**************/\n\n/* higher set bit number (0->N/A, 1->1, 2->2, 4->3, 8->4, 127->7, 128->8 etc) */\nstatic zend_always_inline int zend_mm_small_size_to_bit(int size)\n{\n#if (defined(__GNUC__) || __has_builtin(__builtin_clz))  && defined(PHP_HAVE_BUILTIN_CLZ)\n\treturn (__builtin_clz(size) ^ 0x1f) + 1;\n#elif defined(_WIN32)\n\tunsigned long index;\n\n\tif (!BitScanReverse(&index, (unsigned long)size)) {\n\t\t/* undefined behavior */\n\t\treturn 64;\n\t}\n\n\treturn (((31 - (int)index) ^ 0x1f) + 1);\n#else\n\tint n = 16;\n\tif (size <= 0x00ff) {n -= 8; size = size << 8;}\n\tif (size <= 0x0fff) {n -= 4; size = size << 4;}\n\tif (size <= 0x3fff) {n -= 2; size = size << 2;}\n\tif (size <= 0x7fff) {n -= 1;}\n\treturn n;\n#endif\n}\n\n#ifndef MAX\n# define MAX(a, b) (((a) > (b)) ? (a) : (b))\n#endif\n\n#ifndef MIN\n# define MIN(a, b) (((a) < (b)) ? (a) : (b))\n#endif\n\nstatic zend_always_inline int zend_mm_small_size_to_bin(size_t size)\n{\n#if 0\n\tint n;\n                            /*0,  1,  2,  3,  4,  5,  6,  7,  8,  9  10, 11, 12*/\n\tstatic const int f1[] = { 3,  3,  3,  3,  3,  3,  3,  4,  5,  6,  7,  8,  9};\n\tstatic const int f2[] = { 0,  0,  0,  0,  0,  0,  0,  4,  8, 12, 16, 20, 24};\n\n\tif (UNEXPECTED(size <= 2)) return 0;\n\tn = zend_mm_small_size_to_bit(size - 1);\n\treturn ((size-1) >> f1[n]) + f2[n];\n#else\n\tunsigned int t1, t2;\n\n\tif (size <= 64) {\n\t\t/* we need to support size == 0 ... */\n\t\treturn (size - !!size) >> 3;\n\t} else {\n\t\tt1 = size - 1;\n\t\tt2 = zend_mm_small_size_to_bit(t1) - 3;\n\t\tt1 = t1 >> t2;\n\t\tt2 = t2 - 3;\n\t\tt2 = t2 << 2;\n\t\treturn (int)(t1 + t2);\n\t}\n#endif\n}\n\n#define ZEND_MM_SMALL_SIZE_TO_BIN(size)  zend_mm_small_size_to_bin(size)\n\nstatic zend_never_inline void *zend_mm_alloc_small_slow(zend_mm_heap *heap, int bin_num ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n    zend_mm_chunk *chunk;\n    int page_num;\n\tzend_mm_bin *bin;\n\tzend_mm_free_slot *p, *end;\n\n#if ZEND_DEBUG\n\tbin = (zend_mm_bin*)zend_mm_alloc_pages(heap, bin_pages[bin_num], bin_data_size[bin_num] ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\tbin = (zend_mm_bin*)zend_mm_alloc_pages(heap, bin_pages[bin_num] ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n\tif (UNEXPECTED(bin == NULL)) {\n\t\t/* insufficient memory */\n\t\treturn NULL;\n\t}\n\n\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(bin, ZEND_MM_CHUNK_SIZE);\n\tpage_num = ZEND_MM_ALIGNED_OFFSET(bin, ZEND_MM_CHUNK_SIZE) / ZEND_MM_PAGE_SIZE;\n\tchunk->map[page_num] = ZEND_MM_SRUN(bin_num);\n\tif (bin_pages[bin_num] > 1) {\n\t\tint i = 1;\n\t\tdo {\n\t\t\tchunk->map[page_num+i] = ZEND_MM_NRUN(bin_num, i);\n\t\t\ti++;\n\t\t} while (i < bin_pages[bin_num]);\n\t}\n\n\t/* create a linked list of elements from 1 to last */\n\tend = (zend_mm_free_slot*)((char*)bin + (bin_data_size[bin_num] * (bin_elements[bin_num] - 1)));\n\theap->free_slot[bin_num] = p = (zend_mm_free_slot*)((char*)bin + bin_data_size[bin_num]);\n\tdo {\n\t\tp->next_free_slot = (zend_mm_free_slot*)((char*)p + bin_data_size[bin_num]);;\n#if ZEND_DEBUG\n\t\tdo {\n\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t\t\tdbg->size = 0;\n\t\t} while (0);\n#endif\n\t\tp = (zend_mm_free_slot*)((char*)p + bin_data_size[bin_num]);\n\t} while (p != end);\n\n\t/* terminate list using NULL */\n\tp->next_free_slot = NULL;\n#if ZEND_DEBUG\n\t\tdo {\n\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t\t\tdbg->size = 0;\n\t\t} while (0);\n#endif\n\n\t/* return first element */\n\treturn (char*)bin;\n}\n\nstatic zend_always_inline void *zend_mm_alloc_small(zend_mm_heap *heap, size_t size, int bin_num ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n#if ZEND_MM_STAT\n\tdo {\n\t\tsize_t size = heap->size + bin_data_size[bin_num];\n\t\tsize_t peak = MAX(heap->peak, size);\n\t\theap->size = size;\n\t\theap->peak = peak;\n\t} while (0);\n#endif\n\n\tif (EXPECTED(heap->free_slot[bin_num] != NULL)) {\n\t\tzend_mm_free_slot *p = heap->free_slot[bin_num];\n\t\theap->free_slot[bin_num] = p->next_free_slot;\n\t\treturn (void*)p;\n\t} else {\n\t\treturn zend_mm_alloc_small_slow(heap, bin_num ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t}\n}\n\nstatic zend_always_inline void zend_mm_free_small(zend_mm_heap *heap, void *ptr, int bin_num)\n{\n\tzend_mm_free_slot *p;\n\n#if ZEND_MM_STAT\n\theap->size -= bin_data_size[bin_num];\n#endif\n\n#if ZEND_DEBUG\n\tdo {\n\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)ptr + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t\tdbg->size = 0;\n\t} while (0);\n#endif\n\n    p = (zend_mm_free_slot*)ptr;\n    p->next_free_slot = heap->free_slot[bin_num];\n    heap->free_slot[bin_num] = p;\n}\n\n/********/\n/* Heap */\n/********/\n\n#if ZEND_DEBUG\nstatic zend_always_inline zend_mm_debug_info *zend_mm_get_debug_info(zend_mm_heap *heap, void *ptr)\n{\n\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\tzend_mm_chunk *chunk;\n\tint page_num;\n\tzend_mm_page_info info;\n\n\tZEND_MM_CHECK(page_offset != 0, \"zend_mm_heap corrupted\");\n\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\tpage_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\tinfo = chunk->map[page_num];\n\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\tif (EXPECTED(info & ZEND_MM_IS_SRUN)) {\n\t\tint bin_num = ZEND_MM_SRUN_BIN_NUM(info);\n\t\treturn (zend_mm_debug_info*)((char*)ptr + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t} else /* if (info & ZEND_MM_IS_LRUN) */ {\n\t\tint pages_count = ZEND_MM_LRUN_PAGES(info);\n\n\t\treturn (zend_mm_debug_info*)((char*)ptr + ZEND_MM_PAGE_SIZE * pages_count - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t}\n}\n#endif\n\nstatic zend_always_inline void *zend_mm_alloc_heap(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tvoid *ptr;\n#if ZEND_DEBUG\n\tsize_t real_size = size;\n\tzend_mm_debug_info *dbg;\n\n\t/* special handling for zero-size allocation */\n\tsize = MAX(size, 1);\n\tsize = ZEND_MM_ALIGNED_SIZE(size) + ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info));\n\tif (UNEXPECTED(size < real_size)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu + %zu)\", ZEND_MM_ALIGNED_SIZE(real_size), ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\t\treturn NULL;\n\t}\n#endif\n\tif (size <= ZEND_MM_MAX_SMALL_SIZE) {\n\t\tptr = zend_mm_alloc_small(heap, size, ZEND_MM_SMALL_SIZE_TO_BIN(size) ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#if ZEND_DEBUG\n\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\tdbg->size = real_size;\n\t\tdbg->filename = __zend_filename;\n\t\tdbg->orig_filename = __zend_orig_filename;\n\t\tdbg->lineno = __zend_lineno;\n\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\treturn ptr;\n\t} else if (size <= ZEND_MM_MAX_LARGE_SIZE) {\n\t\tptr = zend_mm_alloc_large(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#if ZEND_DEBUG\n\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\tdbg->size = real_size;\n\t\tdbg->filename = __zend_filename;\n\t\tdbg->orig_filename = __zend_orig_filename;\n\t\tdbg->lineno = __zend_lineno;\n\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\treturn ptr;\n\t} else {\n#if ZEND_DEBUG\n\t\tsize = real_size;\n#endif\n\t\treturn zend_mm_alloc_huge(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t}\n}\n\nstatic zend_always_inline void zend_mm_free_heap(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\n\tif (UNEXPECTED(page_offset == 0)) {\n\t\tif (ptr != NULL) {\n\t\t\tzend_mm_free_huge(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t}\n\t} else {\n\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tint page_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\tzend_mm_page_info info = chunk->map[page_num];\n\n\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\tif (EXPECTED(info & ZEND_MM_IS_SRUN)) {\n\t\t\tzend_mm_free_small(heap, ptr, ZEND_MM_SRUN_BIN_NUM(info));\n\t\t} else /* if (info & ZEND_MM_IS_LRUN) */ {\n\t\t\tint pages_count = ZEND_MM_LRUN_PAGES(info);\n\n\t\t\tZEND_MM_CHECK(ZEND_MM_ALIGNED_OFFSET(page_offset, ZEND_MM_PAGE_SIZE) == 0, \"zend_mm_heap corrupted\");\n\t\t\tzend_mm_free_large(heap, chunk, page_num, pages_count);\n\t\t}\n\t}\n}\n\nstatic size_t zend_mm_size(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\n\tif (UNEXPECTED(page_offset == 0)) {\n\t\treturn zend_mm_get_huge_block_size(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t} else {\n\t\tzend_mm_chunk *chunk;\n#if 0 && ZEND_DEBUG\n\t\tzend_mm_debug_info *dbg = zend_mm_get_debug_info(heap, ptr);\n\t\treturn dbg->size;\n#else\n\t\tint page_num;\n\t\tzend_mm_page_info info;\n\n\t\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tpage_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\tinfo = chunk->map[page_num];\n\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\tif (EXPECTED(info & ZEND_MM_IS_SRUN)) {\n\t\t\treturn bin_data_size[ZEND_MM_SRUN_BIN_NUM(info)];\n\t\t} else /* if (info & ZEND_MM_IS_LARGE_RUN) */ {\n\t\t\treturn ZEND_MM_LRUN_PAGES(info) * ZEND_MM_PAGE_SIZE;\n\t\t}\n#endif\n\t}\n}\n\nstatic void *zend_mm_realloc_heap(zend_mm_heap *heap, void *ptr, size_t size, size_t copy_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t page_offset;\n\tsize_t old_size;\n\tsize_t new_size;\n\tvoid *ret;\n#if ZEND_DEBUG\n\tsize_t real_size;\n\tzend_mm_debug_info *dbg;\n#endif\n\n\tpage_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\tif (UNEXPECTED(page_offset == 0)) {\n\t\tif (UNEXPECTED(ptr == NULL)) {\n\t\t\treturn zend_mm_alloc_heap(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t}\n\t\told_size = zend_mm_get_huge_block_size(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#if ZEND_DEBUG\n\t\treal_size = size;\n\t\tsize = ZEND_MM_ALIGNED_SIZE(size) + ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info));\n#endif\n\t\tif (size > ZEND_MM_MAX_LARGE_SIZE) {\n#if ZEND_DEBUG\n\t\t\tsize = real_size;\n#endif\n#ifdef ZEND_WIN32\n\t\t\t/* On Windows we don't have ability to extend huge blocks in-place.\n\t\t\t * We allocate them with 2MB size granularity, to avoid many \n\t\t\t * reallocations when they are extended by small pieces\n\t\t\t */\n\t\t\tnew_size = ZEND_MM_ALIGNED_SIZE_EX(size, MAX(REAL_PAGE_SIZE, ZEND_MM_CHUNK_SIZE));\n#else\n\t\t\tnew_size = ZEND_MM_ALIGNED_SIZE_EX(size, REAL_PAGE_SIZE);\n#endif\n\t\t\tif (new_size == old_size) {\n#if ZEND_DEBUG\n\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size, real_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n\t\t\t\treturn ptr;\n\t\t\t} else if (new_size < old_size) {\n\t\t\t\t/* unmup tail */\n\t\t\t\tif (zend_mm_chunk_truncate(heap, ptr, old_size, new_size)) {\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\t\t\t\t\theap->real_size -= old_size - new_size;\n#endif\n#if ZEND_MM_STAT\n\t\t\t\t\theap->size -= old_size - new_size;\n#endif\n#if ZEND_DEBUG\n\t\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size, real_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\t\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t}\n\t\t\t} else /* if (new_size > old_size) */ {\n#if ZEND_MM_LIMIT\n\t\t\t\tif (UNEXPECTED(heap->real_size + (new_size - old_size) > heap->limit)) {\n\t\t\t\t\tif (zend_mm_gc(heap) && heap->real_size + (new_size - old_size) <= heap->limit) {\n\t\t\t\t\t\t/* pass */\n\t\t\t\t\t} else if (heap->overflow == 0) {\n#if ZEND_DEBUG\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted at %s:%d (tried to allocate %zu bytes)\", heap->limit, __zend_filename, __zend_lineno, size);\n#else\n\t\t\t\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted (tried to allocate %zu bytes)\", heap->limit, size);\n#endif\n\t\t\t\t\t\treturn NULL;\n\t\t\t\t\t}\n\t\t\t\t}\n#endif\n\t\t\t\t/* try to map tail right after this block */\n\t\t\t\tif (zend_mm_chunk_extend(heap, ptr, old_size, new_size)) {\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\t\t\t\t\theap->real_size += new_size - old_size;\n#endif\n#if ZEND_MM_STAT\n\t\t\t\t\theap->real_peak = MAX(heap->real_peak, heap->real_size);\n\t\t\t\t\theap->size += new_size - old_size;\n\t\t\t\t\theap->peak = MAX(heap->peak, heap->size);\n#endif\n#if ZEND_DEBUG\n\t\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size, real_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\t\t\t\t\tzend_mm_change_huge_block_size(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t} else {\n\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tint page_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\tzend_mm_page_info info = chunk->map[page_num];\n#if ZEND_DEBUG\n\t\tsize_t real_size = size;\n\n\t\tsize = ZEND_MM_ALIGNED_SIZE(size) + ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info));\n#endif\n\n\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\tif (info & ZEND_MM_IS_SRUN) {\n\t\t\tint old_bin_num = ZEND_MM_SRUN_BIN_NUM(info);\n\t\t\told_size = bin_data_size[old_bin_num];\n\t\t\tif (size <= ZEND_MM_MAX_SMALL_SIZE) {\n\t\t\t\tint bin_num = ZEND_MM_SMALL_SIZE_TO_BIN(size);\n\t\t\t\tif (old_bin_num == bin_num) {\n#if ZEND_DEBUG\n\t\t\t\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\t\t\t\tdbg->size = real_size;\n\t\t\t\t\tdbg->filename = __zend_filename;\n\t\t\t\t\tdbg->orig_filename = __zend_orig_filename;\n\t\t\t\t\tdbg->lineno = __zend_lineno;\n\t\t\t\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t}\n\t\t\t}\n\t\t} else /* if (info & ZEND_MM_IS_LARGE_RUN) */ {\n\t\t\tZEND_MM_CHECK(ZEND_MM_ALIGNED_OFFSET(page_offset, ZEND_MM_PAGE_SIZE) == 0, \"zend_mm_heap corrupted\");\n\t\t\told_size = ZEND_MM_LRUN_PAGES(info) * ZEND_MM_PAGE_SIZE;\n\t\t\tif (size > ZEND_MM_MAX_SMALL_SIZE && size <= ZEND_MM_MAX_LARGE_SIZE) {\n\t\t\t\tnew_size = ZEND_MM_ALIGNED_SIZE_EX(size, ZEND_MM_PAGE_SIZE);\n\t\t\t\tif (new_size == old_size) {\n#if ZEND_DEBUG\n\t\t\t\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\t\t\t\tdbg->size = real_size;\n\t\t\t\t\tdbg->filename = __zend_filename;\n\t\t\t\t\tdbg->orig_filename = __zend_orig_filename;\n\t\t\t\t\tdbg->lineno = __zend_lineno;\n\t\t\t\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t} else if (new_size < old_size) {\n\t\t\t\t\t/* free tail pages */\n\t\t\t\t\tint new_pages_count = (int)(new_size / ZEND_MM_PAGE_SIZE);\n\t\t\t\t\tint rest_pages_count = (int)((old_size - new_size) / ZEND_MM_PAGE_SIZE);\n\n#if ZEND_MM_STAT\n\t\t\t\t\theap->size -= rest_pages_count * ZEND_MM_PAGE_SIZE;\n#endif\n\t\t\t\t\tchunk->map[page_num] = ZEND_MM_LRUN(new_pages_count);\n\t\t\t\t\tchunk->free_pages += rest_pages_count;\n\t\t\t\t\tzend_mm_bitset_reset_range(chunk->free_map, page_num + new_pages_count, rest_pages_count);\n#if ZEND_DEBUG\n\t\t\t\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\t\t\t\tdbg->size = real_size;\n\t\t\t\t\tdbg->filename = __zend_filename;\n\t\t\t\t\tdbg->orig_filename = __zend_orig_filename;\n\t\t\t\t\tdbg->lineno = __zend_lineno;\n\t\t\t\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\t\t\treturn ptr;\n\t\t\t\t} else /* if (new_size > old_size) */ {\n\t\t\t\t\tint new_pages_count = (int)(new_size / ZEND_MM_PAGE_SIZE);\n\t\t\t\t\tint old_pages_count = (int)(old_size / ZEND_MM_PAGE_SIZE);\n\n\t\t\t\t\t/* try to allocate tail pages after this block */\n\t\t\t\t\tif (page_num + new_pages_count <= ZEND_MM_PAGES &&\n\t\t\t\t\t    zend_mm_bitset_is_free_range(chunk->free_map, page_num + old_pages_count, new_pages_count - old_pages_count)) {\n#if ZEND_MM_STAT\n\t\t\t\t\t\tdo {\n\t\t\t\t\t\t\tsize_t size = heap->size + (new_size - old_size);\n\t\t\t\t\t\t\tsize_t peak = MAX(heap->peak, size);\n\t\t\t\t\t\t\theap->size = size;\n\t\t\t\t\t\t\theap->peak = peak;\n\t\t\t\t\t\t} while (0);\n#endif\n\t\t\t\t\t\tchunk->free_pages -= new_pages_count - old_pages_count;\n\t\t\t\t\t\tzend_mm_bitset_set_range(chunk->free_map, page_num + old_pages_count, new_pages_count - old_pages_count);\n\t\t\t\t\t\tchunk->map[page_num] = ZEND_MM_LRUN(new_pages_count);\n#if ZEND_DEBUG\n\t\t\t\t\t\tdbg = zend_mm_get_debug_info(heap, ptr);\n\t\t\t\t\t\tdbg->size = real_size;\n\t\t\t\t\t\tdbg->filename = __zend_filename;\n\t\t\t\t\t\tdbg->orig_filename = __zend_orig_filename;\n\t\t\t\t\t\tdbg->lineno = __zend_lineno;\n\t\t\t\t\t\tdbg->orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\t\t\t\treturn ptr;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n#if ZEND_DEBUG\n\t\tsize = real_size;\n#endif\n\t}\n\n\t/* Naive reallocation */\n#if ZEND_MM_STAT\n\tdo {\n\t\tsize_t orig_peak = heap->peak;\n\t\tsize_t orig_real_peak = heap->real_peak;\n#endif\n\tret = zend_mm_alloc_heap(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tmemcpy(ret, ptr, MIN(old_size, copy_size));\n\tzend_mm_free_heap(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#if ZEND_MM_STAT\n\t\theap->peak = MAX(orig_peak, heap->size);\n\t\theap->real_peak = MAX(orig_real_peak, heap->real_size);\n\t} while (0);\n#endif\n\treturn ret;\n}\n\n/*********************/\n/* Huge Runs (again) */\n/*********************/\n\n#if ZEND_DEBUG\nstatic void zend_mm_add_huge_block(zend_mm_heap *heap, void *ptr, size_t size, size_t dbg_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#else\nstatic void zend_mm_add_huge_block(zend_mm_heap *heap, void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#endif\n{\n\tzend_mm_huge_list *list = (zend_mm_huge_list*)zend_mm_alloc_heap(heap, sizeof(zend_mm_huge_list) ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tlist->ptr = ptr;\n\tlist->size = size;\n\tlist->next = heap->huge_list;\n#if ZEND_DEBUG\n\tlist->dbg.size = dbg_size;\n\tlist->dbg.filename = __zend_filename;\n\tlist->dbg.orig_filename = __zend_orig_filename;\n\tlist->dbg.lineno = __zend_lineno;\n\tlist->dbg.orig_lineno = __zend_orig_lineno;\n#endif\n\theap->huge_list = list;\n}\n\nstatic size_t zend_mm_del_huge_block(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tzend_mm_huge_list *prev = NULL;\n\tzend_mm_huge_list *list = heap->huge_list;\n\twhile (list != NULL) {\n\t\tif (list->ptr == ptr) {\n\t\t\tsize_t size;\n\n\t\t\tif (prev) {\n\t\t\t\tprev->next = list->next;\n\t\t\t} else {\n\t\t\t\theap->huge_list = list->next;\n\t\t\t}\n\t\t\tsize = list->size;\n\t\t\tzend_mm_free_heap(heap, list ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t\treturn size;\n\t\t}\n\t\tprev = list;\n\t\tlist = list->next;\n\t}\n\tZEND_MM_CHECK(0, \"zend_mm_heap corrupted\");\n\treturn 0;\n}\n\nstatic size_t zend_mm_get_huge_block_size(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tzend_mm_huge_list *list = heap->huge_list;\n\twhile (list != NULL) {\n\t\tif (list->ptr == ptr) {\n\t\t\treturn list->size;\n\t\t}\n\t\tlist = list->next;\n\t}\n\tZEND_MM_CHECK(0, \"zend_mm_heap corrupted\");\n\treturn 0;\n}\n\n#if ZEND_DEBUG\nstatic void zend_mm_change_huge_block_size(zend_mm_heap *heap, void *ptr, size_t size, size_t dbg_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#else\nstatic void zend_mm_change_huge_block_size(zend_mm_heap *heap, void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n#endif\n{\n\tzend_mm_huge_list *list = heap->huge_list;\n\twhile (list != NULL) {\n\t\tif (list->ptr == ptr) {\n\t\t\tlist->size = size;\n#if ZEND_DEBUG\n\t\t\tlist->dbg.size = dbg_size;\n\t\t\tlist->dbg.filename = __zend_filename;\n\t\t\tlist->dbg.orig_filename = __zend_orig_filename;\n\t\t\tlist->dbg.lineno = __zend_lineno;\n\t\t\tlist->dbg.orig_lineno = __zend_orig_lineno;\n#endif\n\t\t\treturn;\n\t\t}\n\t\tlist = list->next;\n\t}\n}\n\nstatic void *zend_mm_alloc_huge(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n#ifdef ZEND_WIN32\n\t/* On Windows we don't have ability to extend huge blocks in-place.\n\t * We allocate them with 2MB size granularity, to avoid many \n\t * reallocations when they are extended by small pieces\n\t */\n\tsize_t new_size = ZEND_MM_ALIGNED_SIZE_EX(size, MAX(REAL_PAGE_SIZE, ZEND_MM_CHUNK_SIZE));\n#else\n\tsize_t new_size = ZEND_MM_ALIGNED_SIZE_EX(size, REAL_PAGE_SIZE);\n#endif\n\tvoid *ptr;\n\n#if ZEND_MM_LIMIT\n\tif (UNEXPECTED(heap->real_size + new_size > heap->limit)) {\n\t\tif (zend_mm_gc(heap) && heap->real_size + new_size <= heap->limit) {\n\t\t\t/* pass */\n\t\t} else if (heap->overflow == 0) {\n#if ZEND_DEBUG\n\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted at %s:%d (tried to allocate %zu bytes)\", heap->limit, __zend_filename, __zend_lineno, size);\n#else\n\t\t\tzend_mm_safe_error(heap, \"Allowed memory size of %zu bytes exhausted (tried to allocate %zu bytes)\", heap->limit, size);\n#endif\n\t\t\treturn NULL;\n\t\t}\n\t}\n#endif\n\tptr = zend_mm_chunk_alloc(heap, new_size, ZEND_MM_CHUNK_SIZE);\n\tif (UNEXPECTED(ptr == NULL)) {\n\t\t/* insufficient memory */\n\t\tif (zend_mm_gc(heap) &&\n\t\t    (ptr = zend_mm_chunk_alloc(heap, new_size, ZEND_MM_CHUNK_SIZE)) != NULL) {\n\t\t\t/* pass */\n\t\t} else {\n#if !ZEND_MM_LIMIT\n\t\t\tzend_mm_safe_error(heap, \"Out of memory\");\n#elif ZEND_DEBUG\n\t\t\tzend_mm_safe_error(heap, \"Out of memory (allocated %zu) at %s:%d (tried to allocate %zu bytes)\", heap->real_size, __zend_filename, __zend_lineno, size);\n#else\n\t\t\tzend_mm_safe_error(heap, \"Out of memory (allocated %zu) (tried to allocate %zu bytes)\", heap->real_size, size);\n#endif\n\t\t\treturn NULL;\n\t\t}\n\t}\n#if ZEND_DEBUG\n\tzend_mm_add_huge_block(heap, ptr, new_size, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#else\n\tzend_mm_add_huge_block(heap, ptr, new_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n#endif\n#if ZEND_MM_STAT\n\tdo {\n\t\tsize_t size = heap->real_size + new_size;\n\t\tsize_t peak = MAX(heap->real_peak, size);\n\t\theap->real_size = size;\n\t\theap->real_peak = peak;\n\t} while (0);\n\tdo {\n\t\tsize_t size = heap->size + new_size;\n\t\tsize_t peak = MAX(heap->peak, size);\n\t\theap->size = size;\n\t\theap->peak = peak;\n\t} while (0);\n#elif ZEND_MM_LIMIT\n\theap->real_size += new_size;\n#endif\n\treturn ptr;\n}\n\nstatic void zend_mm_free_huge(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t size;\n\n\tZEND_MM_CHECK(ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE) == 0, \"zend_mm_heap corrupted\");\n\tsize = zend_mm_del_huge_block(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tzend_mm_chunk_free(heap, ptr, size);\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\theap->real_size -= size;\n#endif\n#if ZEND_MM_STAT\n\theap->size -= size;\n#endif\n}\n\n/******************/\n/* Initialization */\n/******************/\n\nstatic zend_mm_heap *zend_mm_init(void)\n{\n\tzend_mm_chunk *chunk = (zend_mm_chunk*)zend_mm_chunk_alloc_int(ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE);\n\tzend_mm_heap *heap;\n\n\tif (UNEXPECTED(chunk == NULL)) {\n#if ZEND_MM_ERROR\n#ifdef _WIN32\n\t\tstderr_last_error(\"Can't initialize heap\");\n#else\n\t\tfprintf(stderr, \"\\nCan't initialize heap: [%d] %s\\n\", errno, strerror(errno));\n#endif\n#endif\n\t\treturn NULL;\n\t}\n\theap = &chunk->heap_slot;\n\tchunk->heap = heap;\n\tchunk->next = chunk;\n\tchunk->prev = chunk;\n\tchunk->free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\tchunk->free_tail = ZEND_MM_FIRST_PAGE;\n\tchunk->num = 0;\n\tchunk->free_map[0] = (Z_L(1) << ZEND_MM_FIRST_PAGE) - 1;\n\tchunk->map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE);\n\theap->main_chunk = chunk;\n\theap->cached_chunks = NULL;\n\theap->chunks_count = 1;\n\theap->peak_chunks_count = 1;\n\theap->cached_chunks_count = 0;\n\theap->avg_chunks_count = 1.0;\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\theap->real_size = ZEND_MM_CHUNK_SIZE;\n#endif\n#if ZEND_MM_STAT\n\theap->real_peak = ZEND_MM_CHUNK_SIZE;\n\theap->size = 0;\n\theap->peak = 0;\n#endif\n#if ZEND_MM_LIMIT\n\theap->limit = (Z_L(-1) >> Z_L(1));\n\theap->overflow = 0;\n#endif\n#if ZEND_MM_CUSTOM\n\theap->use_custom_heap = ZEND_MM_CUSTOM_HEAP_NONE;\n#endif\n#if ZEND_MM_STORAGE\n\theap->storage = NULL;\n#endif\n\theap->huge_list = NULL;\n\treturn heap;\n}\n\nZEND_API size_t zend_mm_gc(zend_mm_heap *heap)\n{\n\tzend_mm_free_slot *p, **q;\n\tzend_mm_chunk *chunk;\n\tsize_t page_offset;\n\tint page_num;\n\tzend_mm_page_info info;\n\tint i, has_free_pages, free_counter;\n\tsize_t collected = 0;\n\n#if ZEND_MM_CUSTOM\n\tif (heap->use_custom_heap) {\n\t\treturn 0;\n\t}\n#endif\n\n\tfor (i = 0; i < ZEND_MM_BINS; i++) {\n\t\thas_free_pages = 0;\n\t\tp = heap->free_slot[i];\n\t\twhile (p != NULL) {\n\t\t\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(p, ZEND_MM_CHUNK_SIZE);\n\t\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\t\tpage_offset = ZEND_MM_ALIGNED_OFFSET(p, ZEND_MM_CHUNK_SIZE);\n\t\t\tZEND_ASSERT(page_offset != 0);\n\t\t\tpage_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\t\tinfo = chunk->map[page_num];\n\t\t\tZEND_ASSERT(info & ZEND_MM_IS_SRUN);\n\t\t\tif (info & ZEND_MM_IS_LRUN) {\n\t\t\t\tpage_num -= ZEND_MM_NRUN_OFFSET(info);\n\t\t\t\tinfo = chunk->map[page_num];\n\t\t\t\tZEND_ASSERT(info & ZEND_MM_IS_SRUN);\n\t\t\t\tZEND_ASSERT(!(info & ZEND_MM_IS_LRUN));\n\t\t\t}\n\t\t\tZEND_ASSERT(ZEND_MM_SRUN_BIN_NUM(info) == i);\n\t\t\tfree_counter = ZEND_MM_SRUN_FREE_COUNTER(info) + 1;\n\t\t\tif (free_counter == bin_elements[i]) {\n\t\t\t\thas_free_pages = 1;\n\t\t\t}\n\t\t\tchunk->map[page_num] = ZEND_MM_SRUN_EX(i, free_counter);;\n\t\t\tp = p->next_free_slot;\n\t\t}\n\n\t\tif (!has_free_pages) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tq = &heap->free_slot[i];\n\t\tp = *q;\n\t\twhile (p != NULL) {\n\t\t\tchunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(p, ZEND_MM_CHUNK_SIZE);\n\t\t\tZEND_MM_CHECK(chunk->heap == heap, \"zend_mm_heap corrupted\");\n\t\t\tpage_offset = ZEND_MM_ALIGNED_OFFSET(p, ZEND_MM_CHUNK_SIZE);\n\t\t\tZEND_ASSERT(page_offset != 0);\n\t\t\tpage_num = (int)(page_offset / ZEND_MM_PAGE_SIZE);\n\t\t\tinfo = chunk->map[page_num];\n\t\t\tZEND_ASSERT(info & ZEND_MM_IS_SRUN);\n\t\t\tif (info & ZEND_MM_IS_LRUN) {\n\t\t\t\tpage_num -= ZEND_MM_NRUN_OFFSET(info);\n\t\t\t\tinfo = chunk->map[page_num];\n\t\t\t\tZEND_ASSERT(info & ZEND_MM_IS_SRUN);\n\t\t\t\tZEND_ASSERT(!(info & ZEND_MM_IS_LRUN));\n\t\t\t}\n\t\t\tZEND_ASSERT(ZEND_MM_SRUN_BIN_NUM(info) == i);\n\t\t\tif (ZEND_MM_SRUN_FREE_COUNTER(info) == bin_elements[i]) {\n\t\t\t\t/* remove from cache */\n\t\t\t\tp = p->next_free_slot;;\n\t\t\t\t*q = p;\n\t\t\t} else {\n\t\t\t\tq = &p->next_free_slot;\n\t\t\t\tp = *q;\n\t\t\t}\n\t\t}\n\t}\n\n\tchunk = heap->main_chunk;\n\tdo {\n\t\ti = ZEND_MM_FIRST_PAGE;\n\t\twhile (i < chunk->free_tail) {\n\t\t\tif (zend_mm_bitset_is_set(chunk->free_map, i)) {\n\t\t\t\tinfo = chunk->map[i];\n\t\t\t\tif (info & ZEND_MM_IS_SRUN) {\n\t\t\t\t\tint bin_num = ZEND_MM_SRUN_BIN_NUM(info);\n\t\t\t\t\tint pages_count = bin_pages[bin_num];\n\n\t\t\t\t\tif (ZEND_MM_SRUN_FREE_COUNTER(info) == bin_elements[bin_num]) {\n\t\t\t\t\t\t/* all elemens are free */\n\t\t\t\t\t\tzend_mm_free_pages_ex(heap, chunk, i, pages_count, 0);\n\t\t\t\t\t\tcollected += pages_count;\n\t\t\t\t\t} else {\n\t\t\t\t\t\t/* reset counter */\n\t\t\t\t\t\tchunk->map[i] = ZEND_MM_SRUN(bin_num);\n\t\t\t\t\t}\n\t\t\t\t\ti += bin_pages[bin_num];\n\t\t\t\t} else /* if (info & ZEND_MM_IS_LRUN) */ {\n\t\t\t\t\ti += ZEND_MM_LRUN_PAGES(info);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\tif (chunk->free_pages == ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE) {\n\t\t\tzend_mm_chunk *next_chunk = chunk->next;\n\n\t\t\tzend_mm_delete_chunk(heap, chunk);\n\t\t\tchunk = next_chunk;\n\t\t} else {\n\t\t\tchunk = chunk->next;\n\t\t}\n\t} while (chunk != heap->main_chunk);\n\n\treturn collected * ZEND_MM_PAGE_SIZE;\n}\n\n#if ZEND_DEBUG\n/******************/\n/* Leak detection */\n/******************/\n\nstatic zend_long zend_mm_find_leaks_small(zend_mm_chunk *p, int i, int j, zend_leak_info *leak)\n{\n    int empty = 1;\n\tzend_long count = 0;\n\tint bin_num = ZEND_MM_SRUN_BIN_NUM(p->map[i]);\n\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * i + bin_data_size[bin_num] * (j + 1) - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\n\twhile (j < bin_elements[bin_num]) {\n\t\tif (dbg->size != 0) {\n\t\t\tif (dbg->filename == leak->filename && dbg->lineno == leak->lineno) {\n\t\t\t\tcount++;\n\t\t\t\tdbg->size = 0;\n\t\t\t\tdbg->filename = NULL;\n\t\t\t\tdbg->lineno = 0;\n\t\t\t} else {\n\t\t\t\tempty = 0;\n\t\t\t}\n\t\t}\n\t\tj++;\n\t\tdbg = (zend_mm_debug_info*)((char*)dbg + bin_data_size[bin_num]);\n\t}\n\tif (empty) {\n\t\tzend_mm_bitset_reset_range(p->free_map, i, bin_pages[bin_num]);\n\t}\n\treturn count;\n}\n\nstatic zend_long zend_mm_find_leaks(zend_mm_heap *heap, zend_mm_chunk *p, int i, zend_leak_info *leak)\n{\n\tzend_long count = 0;\n\n\tdo {\n\t\twhile (i < p->free_tail) {\n\t\t\tif (zend_mm_bitset_is_set(p->free_map, i)) {\n\t\t\t\tif (p->map[i] & ZEND_MM_IS_SRUN) {\n\t\t\t\t\tint bin_num = ZEND_MM_SRUN_BIN_NUM(p->map[i]);\n\t\t\t\t\tcount += zend_mm_find_leaks_small(p, i, 0, leak);\n\t\t\t\t\ti += bin_pages[bin_num];\n\t\t\t\t} else /* if (p->map[i] & ZEND_MM_IS_LRUN) */ {\n\t\t\t\t\tint pages_count = ZEND_MM_LRUN_PAGES(p->map[i]);\n\t\t\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * (i + pages_count) - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\n\t\t\t\t\tif (dbg->filename == leak->filename && dbg->lineno == leak->lineno) {\n\t\t\t\t\t\tcount++;\n\t\t\t\t\t}\n\t\t\t\t\tzend_mm_bitset_reset_range(p->free_map, i, pages_count);\n\t\t\t\t\ti += pages_count;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\tp = p->next;\n\t} while (p != heap->main_chunk);\n\treturn count;\n}\n\nstatic zend_long zend_mm_find_leaks_huge(zend_mm_heap *heap, zend_mm_huge_list *list)\n{\n\tzend_long count = 0;\n\tzend_mm_huge_list *prev = list;\n\tzend_mm_huge_list *p = list->next;\n\n\twhile (p) {\n\t\tif (p->dbg.filename == list->dbg.filename && p->dbg.lineno == list->dbg.lineno) {\n\t\t\tprev->next = p->next;\n\t\t\tzend_mm_chunk_free(heap, p->ptr, p->size);\n\t\t\tzend_mm_free_heap(heap, p, NULL, 0, NULL, 0);\n\t\t\tcount++;\n\t\t} else {\n\t\t\tprev = p;\n\t\t}\n\t\tp = prev->next;\n\t}\n\n\treturn count;\n}\n\nstatic void zend_mm_check_leaks(zend_mm_heap *heap)\n{\n\tzend_mm_huge_list *list;\n\tzend_mm_chunk *p;\n\tzend_leak_info leak;\n\tzend_long repeated = 0;\n\tuint32_t total = 0;\n\tint i, j;\n\n\t/* find leaked huge blocks and free them */\n\tlist = heap->huge_list;\n\twhile (list) {\n\t\tzend_mm_huge_list *q = list;\n\n\t\tleak.addr = list->ptr;\n\t\tleak.size = list->dbg.size;\n\t\tleak.filename = list->dbg.filename;\n\t\tleak.orig_filename = list->dbg.orig_filename;\n\t\tleak.lineno = list->dbg.lineno;\n\t\tleak.orig_lineno = list->dbg.orig_lineno;\n\n\t\tzend_message_dispatcher(ZMSG_LOG_SCRIPT_NAME, NULL);\n\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_DETECTED, &leak);\n\t\trepeated = zend_mm_find_leaks_huge(heap, list);\n\t\ttotal += 1 + repeated;\n\t\tif (repeated) {\n\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_REPEATED, (void *)(zend_uintptr_t)repeated);\n\t\t}\n\n\t\theap->huge_list = list = list->next;\n\t\tzend_mm_chunk_free(heap, q->ptr, q->size);\n\t\tzend_mm_free_heap(heap, q, NULL, 0, NULL, 0);\n\t}\n\n\t/* for each chunk */\n\tp = heap->main_chunk;\n\tdo {\n\t\ti = ZEND_MM_FIRST_PAGE;\n\t\twhile (i < p->free_tail) {\n\t\t\tif (zend_mm_bitset_is_set(p->free_map, i)) {\n\t\t\t\tif (p->map[i] & ZEND_MM_IS_SRUN) {\n\t\t\t\t\tint bin_num = ZEND_MM_SRUN_BIN_NUM(p->map[i]);\n\t\t\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * i + bin_data_size[bin_num] - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\n\t\t\t\t\tj = 0;\n\t\t\t\t\twhile (j < bin_elements[bin_num]) {\n\t\t\t\t\t\tif (dbg->size != 0) {\n\t\t\t\t\t\t\tleak.addr = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * i + bin_data_size[bin_num] * j);\n\t\t\t\t\t\t\tleak.size = dbg->size;\n\t\t\t\t\t\t\tleak.filename = dbg->filename;\n\t\t\t\t\t\t\tleak.orig_filename = dbg->orig_filename;\n\t\t\t\t\t\t\tleak.lineno = dbg->lineno;\n\t\t\t\t\t\t\tleak.orig_lineno = dbg->orig_lineno;\n\n\t\t\t\t\t\t\tzend_message_dispatcher(ZMSG_LOG_SCRIPT_NAME, NULL);\n\t\t\t\t\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_DETECTED, &leak);\n\n\t\t\t\t\t\t\tdbg->size = 0;\n\t\t\t\t\t\t\tdbg->filename = NULL;\n\t\t\t\t\t\t\tdbg->lineno = 0;\n\n\t\t\t\t\t\t\trepeated = zend_mm_find_leaks_small(p, i, j + 1, &leak) +\n\t\t\t\t\t\t\t           zend_mm_find_leaks(heap, p, i + bin_pages[bin_num], &leak);\n\t\t\t\t\t\t\ttotal += 1 + repeated;\n\t\t\t\t\t\t\tif (repeated) {\n\t\t\t\t\t\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_REPEATED, (void *)(zend_uintptr_t)repeated);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tdbg = (zend_mm_debug_info*)((char*)dbg + bin_data_size[bin_num]);\n\t\t\t\t\t\tj++;\n\t\t\t\t\t}\n\t\t\t\t\ti += bin_pages[bin_num];\n\t\t\t\t} else /* if (p->map[i] & ZEND_MM_IS_LRUN) */ {\n\t\t\t\t\tint pages_count = ZEND_MM_LRUN_PAGES(p->map[i]);\n\t\t\t\t\tzend_mm_debug_info *dbg = (zend_mm_debug_info*)((char*)p + ZEND_MM_PAGE_SIZE * (i + pages_count) - ZEND_MM_ALIGNED_SIZE(sizeof(zend_mm_debug_info)));\n\n\t\t\t\t\tleak.addr = (void*)((char*)p + ZEND_MM_PAGE_SIZE * i);\n\t\t\t\t\tleak.size = dbg->size;\n\t\t\t\t\tleak.filename = dbg->filename;\n\t\t\t\t\tleak.orig_filename = dbg->orig_filename;\n\t\t\t\t\tleak.lineno = dbg->lineno;\n\t\t\t\t\tleak.orig_lineno = dbg->orig_lineno;\n\n\t\t\t\t\tzend_message_dispatcher(ZMSG_LOG_SCRIPT_NAME, NULL);\n\t\t\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_DETECTED, &leak);\n\n\t\t\t\t\tzend_mm_bitset_reset_range(p->free_map, i, pages_count);\n\n\t\t\t\t\trepeated = zend_mm_find_leaks(heap, p, i + pages_count, &leak);\n\t\t\t\t\ttotal += 1 + repeated;\n\t\t\t\t\tif (repeated) {\n\t\t\t\t\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAK_REPEATED, (void *)(zend_uintptr_t)repeated);\n\t\t\t\t\t}\n\t\t\t\t\ti += pages_count;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\ti++;\n\t\t\t}\n\t\t}\n\t\tp = p->next;\n\t} while (p != heap->main_chunk);\n\tif (total) {\n\t\tzend_message_dispatcher(ZMSG_MEMORY_LEAKS_GRAND_TOTAL, &total);\n\t}\n}\n#endif\n\nvoid zend_mm_shutdown(zend_mm_heap *heap, int full, int silent)\n{\n\tzend_mm_chunk *p;\n\tzend_mm_huge_list *list;\n\n#if ZEND_MM_CUSTOM\n\tif (heap->use_custom_heap) {\n\t\tif (full) {\n\t\t\tif (ZEND_DEBUG && heap->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\t\theap->custom_heap.debug._free(heap ZEND_FILE_LINE_CC ZEND_FILE_LINE_EMPTY_CC);\n\t\t\t} else {\n\t\t\t\theap->custom_heap.std._free(heap);\n\t\t\t}\n\t\t}\n\t\treturn;\n\t}\n#endif\n\n#if ZEND_DEBUG\n\tif (!silent) {\n\t\tzend_mm_check_leaks(heap);\n\t}\n#endif\n\n\t/* free huge blocks */\n\tlist = heap->huge_list;\n\theap->huge_list = NULL;\n\twhile (list) {\n\t\tzend_mm_huge_list *q = list;\n\t\tlist = list->next;\n\t\tzend_mm_chunk_free(heap, q->ptr, q->size);\n\t}\n\n\t/* move all chunks except of the first one into the cache */\n\tp = heap->main_chunk->next;\n\twhile (p != heap->main_chunk) {\n\t\tzend_mm_chunk *q = p->next;\n\t\tp->next = heap->cached_chunks;\n\t\theap->cached_chunks = p;\n\t\tp = q;\n\t\theap->chunks_count--;\n\t\theap->cached_chunks_count++;\n\t}\n\n\tif (full) {\n\t\t/* free all cached chunks */\n\t\twhile (heap->cached_chunks) {\n\t\t\tp = heap->cached_chunks;\n\t\t\theap->cached_chunks = p->next;\n\t\t\tzend_mm_chunk_free(heap, p, ZEND_MM_CHUNK_SIZE);\n\t\t}\n\t\t/* free the first chunk */\n\t\tzend_mm_chunk_free(heap, heap->main_chunk, ZEND_MM_CHUNK_SIZE);\n\t} else {\n\t\tzend_mm_heap old_heap;\n\n\t\t/* free some cached chunks to keep average count */\n\t\theap->avg_chunks_count = (heap->avg_chunks_count + (double)heap->peak_chunks_count) / 2.0;\n\t\twhile ((double)heap->cached_chunks_count + 0.9 > heap->avg_chunks_count &&\n\t\t       heap->cached_chunks) {\n\t\t\tp = heap->cached_chunks;\n\t\t\theap->cached_chunks = p->next;\n\t\t\tzend_mm_chunk_free(heap, p, ZEND_MM_CHUNK_SIZE);\n\t\t\theap->cached_chunks_count--;\n\t\t}\n\t\t/* clear cached chunks */\n\t\tp = heap->cached_chunks;\n\t\twhile (p != NULL) {\n\t\t\tzend_mm_chunk *q = p->next;\n\t\t\tmemset(p, 0, sizeof(zend_mm_chunk));\n\t\t\tp->next = q;\n\t\t\tp = q;\n\t\t}\n\n\t\t/* reinitialize the first chunk and heap */\n\t\told_heap = *heap;\n\t\tp = heap->main_chunk;\n\t\tmemset(p, 0, ZEND_MM_FIRST_PAGE * ZEND_MM_PAGE_SIZE);\n\t\t*heap = old_heap;\n\t\tmemset(heap->free_slot, 0, sizeof(heap->free_slot));\n\t\theap->main_chunk = p;\n\t\tp->heap = &p->heap_slot;\n\t\tp->next = p;\n\t\tp->prev = p;\n\t\tp->free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\t\tp->free_tail = ZEND_MM_FIRST_PAGE;\n\t\tp->free_map[0] = (1L << ZEND_MM_FIRST_PAGE) - 1;\n\t\tp->map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE);\n\t\theap->chunks_count = 1;\n\t\theap->peak_chunks_count = 1;\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\t\theap->real_size = ZEND_MM_CHUNK_SIZE;\n#endif\n#if ZEND_MM_STAT\n\t\theap->real_peak = ZEND_MM_CHUNK_SIZE;\n\t\theap->size = heap->peak = 0;\n#endif\n\t}\n}\n\n/**************/\n/* PUBLIC API */\n/**************/\n\nZEND_API void* ZEND_FASTCALL _zend_mm_alloc(zend_mm_heap *heap, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn zend_mm_alloc_heap(heap, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void ZEND_FASTCALL _zend_mm_free(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tzend_mm_free_heap(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nvoid* ZEND_FASTCALL _zend_mm_realloc(zend_mm_heap *heap, void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn zend_mm_realloc_heap(heap, ptr, size, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nvoid* ZEND_FASTCALL _zend_mm_realloc2(zend_mm_heap *heap, void *ptr, size_t size, size_t copy_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn zend_mm_realloc_heap(heap, ptr, size, copy_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API size_t ZEND_FASTCALL _zend_mm_block_size(zend_mm_heap *heap, void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn zend_mm_size(heap, ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\n/**********************/\n/* Allocation Manager */\n/**********************/\n\ntypedef struct _zend_alloc_globals {\n\tzend_mm_heap *mm_heap;\n} zend_alloc_globals;\n\n#ifdef ZTS\nstatic int alloc_globals_id;\n# define AG(v) ZEND_TSRMG(alloc_globals_id, zend_alloc_globals *, v)\n#else\n# define AG(v) (alloc_globals.v)\nstatic zend_alloc_globals alloc_globals;\n#endif\n\nZEND_API int is_zend_mm(void)\n{\n#if ZEND_MM_CUSTOM\n\treturn !AG(mm_heap)->use_custom_heap;\n#else\n\treturn 1;\n#endif\n}\n\n#if !ZEND_DEBUG && (!defined(_WIN32) || defined(__clang__))\n#undef _emalloc\n\n#if ZEND_MM_CUSTOM\n# define ZEND_MM_CUSTOM_ALLOCATOR(size) do { \\\n\t\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) { \\\n\t\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) { \\\n\t\t\t\treturn AG(mm_heap)->custom_heap.debug._malloc(size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); \\\n\t\t\t} else { \\\n\t\t\t\treturn AG(mm_heap)->custom_heap.std._malloc(size); \\\n\t\t\t} \\\n\t\t} \\\n\t} while (0)\n# define ZEND_MM_CUSTOM_DEALLOCATOR(ptr) do { \\\n\t\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) { \\\n\t\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) { \\\n\t\t\t\tAG(mm_heap)->custom_heap.debug._free(ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); \\\n\t\t\t} else { \\\n\t\t\t\tAG(mm_heap)->custom_heap.std._free(ptr); \\\n\t\t\t} \\\n\t\t\treturn; \\\n\t\t} \\\n\t} while (0)\n#else\n# define ZEND_MM_CUSTOM_ALLOCATOR(size)\n# define ZEND_MM_CUSTOM_DEALLOCATOR(ptr)\n#endif\n\n# define _ZEND_BIN_ALLOCATOR(_num, _size, _elements, _pages, x, y) \\\n\tZEND_API void* ZEND_FASTCALL _emalloc_ ## _size(void) { \\\n\t\tZEND_MM_CUSTOM_ALLOCATOR(_size); \\\n\t\treturn zend_mm_alloc_small(AG(mm_heap), _size, _num ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC); \\\n\t}\n\nZEND_MM_BINS_INFO(_ZEND_BIN_ALLOCATOR, x, y)\n\nZEND_API void* ZEND_FASTCALL _emalloc_large(size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n\tZEND_MM_CUSTOM_ALLOCATOR(size);\n\treturn zend_mm_alloc_large(AG(mm_heap), size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void* ZEND_FASTCALL _emalloc_huge(size_t size)\n{\n\n\tZEND_MM_CUSTOM_ALLOCATOR(size);\n\treturn zend_mm_alloc_huge(AG(mm_heap), size);\n}\n\n#if ZEND_DEBUG\n# define _ZEND_BIN_FREE(_num, _size, _elements, _pages, x, y) \\\n\tZEND_API void ZEND_FASTCALL _efree_ ## _size(void *ptr) { \\\n\t\tZEND_MM_CUSTOM_DEALLOCATOR(ptr); \\\n\t\t{ \\\n\t\t\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE); \\\n\t\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE); \\\n\t\t\tint page_num = page_offset / ZEND_MM_PAGE_SIZE; \\\n\t\t\tZEND_MM_CHECK(chunk->heap == AG(mm_heap), \"zend_mm_heap corrupted\"); \\\n\t\t\tZEND_ASSERT(chunk->map[page_num] & ZEND_MM_IS_SRUN); \\\n\t\t\tZEND_ASSERT(ZEND_MM_SRUN_BIN_NUM(chunk->map[page_num]) == _num); \\\n\t\t\tzend_mm_free_small(AG(mm_heap), ptr, _num); \\\n\t\t} \\\n\t}\n#else\n# define _ZEND_BIN_FREE(_num, _size, _elements, _pages, x, y) \\\n\tZEND_API void ZEND_FASTCALL _efree_ ## _size(void *ptr) { \\\n\t\tZEND_MM_CUSTOM_DEALLOCATOR(ptr); \\\n\t\t{ \\\n\t\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE); \\\n\t\t\tZEND_MM_CHECK(chunk->heap == AG(mm_heap), \"zend_mm_heap corrupted\"); \\\n\t\t\tzend_mm_free_small(AG(mm_heap), ptr, _num); \\\n\t\t} \\\n\t}\n#endif\n\nZEND_MM_BINS_INFO(_ZEND_BIN_FREE, x, y)\n\nZEND_API void ZEND_FASTCALL _efree_large(void *ptr, size_t size)\n{\n\n\tZEND_MM_CUSTOM_DEALLOCATOR(ptr);\n\t{\n\t\tsize_t page_offset = ZEND_MM_ALIGNED_OFFSET(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tzend_mm_chunk *chunk = (zend_mm_chunk*)ZEND_MM_ALIGNED_BASE(ptr, ZEND_MM_CHUNK_SIZE);\n\t\tint page_num = page_offset / ZEND_MM_PAGE_SIZE;\n\t\tint pages_count = ZEND_MM_ALIGNED_SIZE_EX(size, ZEND_MM_PAGE_SIZE) / ZEND_MM_PAGE_SIZE;\n\n\t\tZEND_MM_CHECK(chunk->heap == AG(mm_heap) && ZEND_MM_ALIGNED_OFFSET(page_offset, ZEND_MM_PAGE_SIZE) == 0, \"zend_mm_heap corrupted\");\n\t\tZEND_ASSERT(chunk->map[page_num] & ZEND_MM_IS_LRUN);\n\t\tZEND_ASSERT(ZEND_MM_LRUN_PAGES(chunk->map[page_num]) == pages_count);\n\t\tzend_mm_free_large(AG(mm_heap), chunk, page_num, pages_count);\n\t}\n}\n\nZEND_API void ZEND_FASTCALL _efree_huge(void *ptr, size_t size)\n{\n\n\tZEND_MM_CUSTOM_DEALLOCATOR(ptr);\n\tzend_mm_free_huge(AG(mm_heap), ptr);\n}\n#endif\n\nZEND_API void* ZEND_FASTCALL _emalloc(size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n#if ZEND_MM_CUSTOM\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\treturn AG(mm_heap)->custom_heap.debug._malloc(size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t} else {\n\t\t\treturn AG(mm_heap)->custom_heap.std._malloc(size);\n\t\t}\n\t}\n#endif\n\treturn zend_mm_alloc_heap(AG(mm_heap), size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void ZEND_FASTCALL _efree(void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n#if ZEND_MM_CUSTOM\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\tAG(mm_heap)->custom_heap.debug._free(ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t} else {\n\t\t\tAG(mm_heap)->custom_heap.std._free(ptr);\n\t    }\n\t\treturn;\n\t}\n#endif\n\tzend_mm_free_heap(AG(mm_heap), ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void* ZEND_FASTCALL _erealloc(void *ptr, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\treturn AG(mm_heap)->custom_heap.debug._realloc(ptr, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t} else {\n\t\t\treturn AG(mm_heap)->custom_heap.std._realloc(ptr, size);\n\t\t}\n\t}\n\treturn zend_mm_realloc_heap(AG(mm_heap), ptr, size, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API void* ZEND_FASTCALL _erealloc2(void *ptr, size_t size, size_t copy_size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\tif (ZEND_DEBUG && AG(mm_heap)->use_custom_heap == ZEND_MM_CUSTOM_HEAP_DEBUG) {\n\t\t\treturn AG(mm_heap)->custom_heap.debug._realloc(ptr, size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\t\t} else {\n\t\t\treturn AG(mm_heap)->custom_heap.std._realloc(ptr, size);\n\t\t}\n\t}\n\treturn zend_mm_realloc_heap(AG(mm_heap), ptr, size, copy_size ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nZEND_API size_t ZEND_FASTCALL _zend_mem_block_size(void *ptr ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tif (UNEXPECTED(AG(mm_heap)->use_custom_heap)) {\n\t\treturn 0;\n\t}\n\treturn zend_mm_size(AG(mm_heap), ptr ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n}\n\nstatic zend_always_inline size_t safe_address(size_t nmemb, size_t size, size_t offset)\n{\n\tint overflow;\n\tsize_t ret = zend_safe_address(nmemb, size, offset, &overflow);\n\n\tif (UNEXPECTED(overflow)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu * %zu + %zu)\", nmemb, size, offset);\n\t\treturn 0;\n\t}\n\treturn ret;\n}\n\n\nZEND_API void* ZEND_FASTCALL _safe_emalloc(size_t nmemb, size_t size, size_t offset ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn emalloc_rel(safe_address(nmemb, size, offset));\n}\n\nZEND_API void* ZEND_FASTCALL _safe_malloc(size_t nmemb, size_t size, size_t offset)\n{\n\treturn pemalloc(safe_address(nmemb, size, offset), 1);\n}\n\nZEND_API void* ZEND_FASTCALL _safe_erealloc(void *ptr, size_t nmemb, size_t size, size_t offset ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\treturn erealloc_rel(ptr, safe_address(nmemb, size, offset));\n}\n\nZEND_API void* ZEND_FASTCALL _safe_realloc(void *ptr, size_t nmemb, size_t size, size_t offset)\n{\n\treturn perealloc(ptr, safe_address(nmemb, size, offset), 1);\n}\n\n\nZEND_API void* ZEND_FASTCALL _ecalloc(size_t nmemb, size_t size ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tvoid *p;\n\n\tp = _safe_emalloc(nmemb, size, 0 ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tif (UNEXPECTED(p == NULL)) {\n\t\treturn p;\n\t}\n\tmemset(p, 0, size * nmemb);\n\treturn p;\n}\n\nZEND_API char* ZEND_FASTCALL _estrdup(const char *s ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tsize_t length;\n\tchar *p;\n\n\tlength = strlen(s);\n\tif (UNEXPECTED(length + 1 == 0)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu * %zu + %zu)\", 1, length, 1);\n\t}\n\tp = (char *) _emalloc(length + 1 ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tif (UNEXPECTED(p == NULL)) {\n\t\treturn p;\n\t}\n\tmemcpy(p, s, length+1);\n\treturn p;\n}\n\nZEND_API char* ZEND_FASTCALL _estrndup(const char *s, size_t length ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC)\n{\n\tchar *p;\n\n\tif (UNEXPECTED(length + 1 == 0)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu * %zu + %zu)\", 1, length, 1);\n\t}\n\tp = (char *) _emalloc(length + 1 ZEND_FILE_LINE_RELAY_CC ZEND_FILE_LINE_ORIG_RELAY_CC);\n\tif (UNEXPECTED(p == NULL)) {\n\t\treturn p;\n\t}\n\tmemcpy(p, s, length);\n\tp[length] = 0;\n\treturn p;\n}\n\n\nZEND_API char* ZEND_FASTCALL zend_strndup(const char *s, size_t length)\n{\n\tchar *p;\n\n\tif (UNEXPECTED(length + 1 == 0)) {\n\t\tzend_error_noreturn(E_ERROR, \"Possible integer overflow in memory allocation (%zu * %zu + %zu)\", 1, length, 1);\n\t}\n\tp = (char *) malloc(length + 1);\n\tif (UNEXPECTED(p == NULL)) {\n\t\treturn p;\n\t}\n\tif (EXPECTED(length)) {\n\t\tmemcpy(p, s, length);\n\t}\n\tp[length] = 0;\n\treturn p;\n}\n\n\nZEND_API int zend_set_memory_limit(size_t memory_limit)\n{\n#if ZEND_MM_LIMIT\n\tAG(mm_heap)->limit = (memory_limit >= ZEND_MM_CHUNK_SIZE) ? memory_limit : ZEND_MM_CHUNK_SIZE;\n#endif\n\treturn SUCCESS;\n}\n\nZEND_API size_t zend_memory_usage(int real_usage)\n{\n#if ZEND_MM_STAT\n\tif (real_usage) {\n\t\treturn AG(mm_heap)->real_size;\n\t} else {\n\t\tsize_t usage = AG(mm_heap)->size;\n\t\treturn usage;\n\t}\n#endif\n\treturn 0;\n}\n\nZEND_API size_t zend_memory_peak_usage(int real_usage)\n{\n#if ZEND_MM_STAT\n\tif (real_usage) {\n\t\treturn AG(mm_heap)->real_peak;\n\t} else {\n\t\treturn AG(mm_heap)->peak;\n\t}\n#endif\n\treturn 0;\n}\n\nZEND_API void shutdown_memory_manager(int silent, int full_shutdown)\n{\n\tzend_mm_shutdown(AG(mm_heap), full_shutdown, silent);\n}\n\nstatic void alloc_globals_ctor(zend_alloc_globals *alloc_globals)\n{\n#if ZEND_MM_CUSTOM\n\tchar *tmp = getenv(\"USE_ZEND_ALLOC\");\n\n\tif (tmp && !zend_atoi(tmp, 0)) {\n\t\talloc_globals->mm_heap = malloc(sizeof(zend_mm_heap));\n\t\tmemset(alloc_globals->mm_heap, 0, sizeof(zend_mm_heap));\n\t\talloc_globals->mm_heap->use_custom_heap = ZEND_MM_CUSTOM_HEAP_STD;\n\t\talloc_globals->mm_heap->custom_heap.std._malloc = malloc;\n\t\talloc_globals->mm_heap->custom_heap.std._free = free;\n\t\talloc_globals->mm_heap->custom_heap.std._realloc = realloc;\n\t\treturn;\n\t}\n#endif\n#ifdef MAP_HUGETLB\n\ttmp = getenv(\"USE_ZEND_ALLOC_HUGE_PAGES\");\n\tif (tmp && zend_atoi(tmp, 0)) {\n\t\tzend_mm_use_huge_pages = 1;\n\t}\n#endif\n\tZEND_TSRMLS_CACHE_UPDATE();\n\talloc_globals->mm_heap = zend_mm_init();\n}\n\n#ifdef ZTS\nstatic void alloc_globals_dtor(zend_alloc_globals *alloc_globals)\n{\n\tzend_mm_shutdown(alloc_globals->mm_heap, 1, 1);\n}\n#endif\n\nZEND_API void start_memory_manager(void)\n{\n#ifdef ZTS\n\tts_allocate_id(&alloc_globals_id, sizeof(zend_alloc_globals), (ts_allocate_ctor) alloc_globals_ctor, (ts_allocate_dtor) alloc_globals_dtor);\n#else\n\talloc_globals_ctor(&alloc_globals);\n#endif\n#ifndef _WIN32\n#  if defined(_SC_PAGESIZE)\n\tREAL_PAGE_SIZE = sysconf(_SC_PAGESIZE);\n#  elif defined(_SC_PAGE_SIZE)\n\tREAL_PAGE_SIZE = sysconf(_SC_PAGE_SIZE);\n#  endif\n#endif\n}\n\nZEND_API zend_mm_heap *zend_mm_set_heap(zend_mm_heap *new_heap)\n{\n\tzend_mm_heap *old_heap;\n\n\told_heap = AG(mm_heap);\n\tAG(mm_heap) = (zend_mm_heap*)new_heap;\n\treturn (zend_mm_heap*)old_heap;\n}\n\nZEND_API zend_mm_heap *zend_mm_get_heap(void)\n{\n\treturn AG(mm_heap);\n}\n\nZEND_API int zend_mm_is_custom_heap(zend_mm_heap *new_heap)\n{\n#if ZEND_MM_CUSTOM\n\treturn AG(mm_heap)->use_custom_heap;\n#else\n\treturn 0;\n#endif\n}\n\nZEND_API void zend_mm_set_custom_handlers(zend_mm_heap *heap,\n                                          void* (*_malloc)(size_t),\n                                          void  (*_free)(void*),\n                                          void* (*_realloc)(void*, size_t))\n{\n#if ZEND_MM_CUSTOM\n\tzend_mm_heap *_heap = (zend_mm_heap*)heap;\n\n\t_heap->use_custom_heap = ZEND_MM_CUSTOM_HEAP_STD;\n\t_heap->custom_heap.std._malloc = _malloc;\n\t_heap->custom_heap.std._free = _free;\n\t_heap->custom_heap.std._realloc = _realloc;\n#endif\n}\n\nZEND_API void zend_mm_get_custom_handlers(zend_mm_heap *heap,\n                                          void* (**_malloc)(size_t),\n                                          void  (**_free)(void*),\n                                          void* (**_realloc)(void*, size_t))\n{\n#if ZEND_MM_CUSTOM\n\tzend_mm_heap *_heap = (zend_mm_heap*)heap;\n\n\tif (heap->use_custom_heap) {\n\t\t*_malloc = _heap->custom_heap.std._malloc;\n\t\t*_free = _heap->custom_heap.std._free;\n\t\t*_realloc = _heap->custom_heap.std._realloc;\n\t} else {\n\t\t*_malloc = NULL;\n\t\t*_free = NULL;\n\t\t*_realloc = NULL;\n\t}\n#else\n\t*_malloc = NULL;\n\t*_free = NULL;\n\t*_realloc = NULL;\n#endif\n}\n\n#if ZEND_DEBUG\nZEND_API void zend_mm_set_custom_debug_handlers(zend_mm_heap *heap,\n                                          void* (*_malloc)(size_t ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC),\n                                          void  (*_free)(void* ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC),\n                                          void* (*_realloc)(void*, size_t ZEND_FILE_LINE_DC ZEND_FILE_LINE_ORIG_DC))\n{\n#if ZEND_MM_CUSTOM\n\tzend_mm_heap *_heap = (zend_mm_heap*)heap;\n\n\t_heap->use_custom_heap = ZEND_MM_CUSTOM_HEAP_DEBUG;\n\t_heap->custom_heap.debug._malloc = _malloc;\n\t_heap->custom_heap.debug._free = _free;\n\t_heap->custom_heap.debug._realloc = _realloc;\n#endif\n}\n#endif\n\nZEND_API zend_mm_storage *zend_mm_get_storage(zend_mm_heap *heap)\n{\n#if ZEND_MM_STORAGE\n\treturn heap->storage;\n#else\n\treturn NULL\n#endif\n}\n\nZEND_API zend_mm_heap *zend_mm_startup(void)\n{\n\treturn zend_mm_init();\n}\n\nZEND_API zend_mm_heap *zend_mm_startup_ex(const zend_mm_handlers *handlers, void *data, size_t data_size)\n{\n#if ZEND_MM_STORAGE\n\tzend_mm_storage tmp_storage, *storage;\n\tzend_mm_chunk *chunk;\n\tzend_mm_heap *heap;\n\n\tmemcpy((zend_mm_handlers*)&tmp_storage.handlers, handlers, sizeof(zend_mm_handlers));\n\ttmp_storage.data = data;\n\tchunk = (zend_mm_chunk*)handlers->chunk_alloc(&tmp_storage, ZEND_MM_CHUNK_SIZE, ZEND_MM_CHUNK_SIZE);\n\tif (UNEXPECTED(chunk == NULL)) {\n#if ZEND_MM_ERROR\n#ifdef _WIN32\n\t\tstderr_last_error(\"Can't initialize heap\");\n#else\n\t\tfprintf(stderr, \"\\nCan't initialize heap: [%d] %s\\n\", errno, strerror(errno));\n#endif\n#endif\n\t\treturn NULL;\n\t}\n\theap = &chunk->heap_slot;\n\tchunk->heap = heap;\n\tchunk->next = chunk;\n\tchunk->prev = chunk;\n\tchunk->free_pages = ZEND_MM_PAGES - ZEND_MM_FIRST_PAGE;\n\tchunk->free_tail = ZEND_MM_FIRST_PAGE;\n\tchunk->num = 0;\n\tchunk->free_map[0] = (Z_L(1) << ZEND_MM_FIRST_PAGE) - 1;\n\tchunk->map[0] = ZEND_MM_LRUN(ZEND_MM_FIRST_PAGE);\n\theap->main_chunk = chunk;\n\theap->cached_chunks = NULL;\n\theap->chunks_count = 1;\n\theap->peak_chunks_count = 1;\n\theap->cached_chunks_count = 0;\n\theap->avg_chunks_count = 1.0;\n#if ZEND_MM_STAT || ZEND_MM_LIMIT\n\theap->real_size = ZEND_MM_CHUNK_SIZE;\n#endif\n#if ZEND_MM_STAT\n\theap->real_peak = ZEND_MM_CHUNK_SIZE;\n\theap->size = 0;\n\theap->peak = 0;\n#endif\n#if ZEND_MM_LIMIT\n\theap->limit = (Z_L(-1) >> Z_L(1));\n\theap->overflow = 0;\n#endif\n#if ZEND_MM_CUSTOM\n\theap->use_custom_heap = 0;\n#endif\n\theap->storage = &tmp_storage;\n\theap->huge_list = NULL;\n\tmemset(heap->free_slot, 0, sizeof(heap->free_slot));\n\tstorage = _zend_mm_alloc(heap, sizeof(zend_mm_storage) + data_size ZEND_FILE_LINE_CC ZEND_FILE_LINE_CC);\n\tif (!storage) {\n\t\thandlers->chunk_free(&tmp_storage, chunk, ZEND_MM_CHUNK_SIZE);\n#if ZEND_MM_ERROR\n#ifdef _WIN32\n\t\tstderr_last_error(\"Can't initialize heap\");\n#else\n\t\tfprintf(stderr, \"\\nCan't initialize heap: [%d] %s\\n\", errno, strerror(errno));\n#endif\n#endif\n\t\treturn NULL;\n\t}\n\tmemcpy(storage, &tmp_storage, sizeof(zend_mm_storage));\n\tif (data) {\n\t\tstorage->data = (void*)(((char*)storage + sizeof(zend_mm_storage)));\n\t\tmemcpy(storage->data, data, data_size);\n\t}\n\theap->storage = storage;\n\treturn heap;\n#else\n\treturn NULL;\n#endif\n}\n\nstatic ZEND_COLD ZEND_NORETURN void zend_out_of_memory(void)\n{\n\tfprintf(stderr, \"Out of memory\\n\");\n\texit(1);\n}\n\nZEND_API void * __zend_malloc(size_t len)\n{\n\tvoid *tmp = malloc(len);\n\tif (EXPECTED(tmp)) {\n\t\treturn tmp;\n\t}\n\tzend_out_of_memory();\n}\n\nZEND_API void * __zend_calloc(size_t nmemb, size_t len)\n{\n\tvoid *tmp = _safe_malloc(nmemb, len, 0);\n\tmemset(tmp, 0, nmemb * len);\n\treturn tmp;\n}\n\nZEND_API void * __zend_realloc(void *p, size_t len)\n{\n\tp = realloc(p, len);\n\tif (EXPECTED(p)) {\n\t\treturn p;\n\t}\n\tzend_out_of_memory();\n}\n\n/*\n * Local variables:\n * tab-width: 4\n * c-basic-offset: 4\n * indent-tabs-mode: t\n * End:\n */\n"], "filenames": ["Zend/zend_alloc.c"], "buggy_code_start_loc": [1551], "buggy_code_end_loc": [1566], "fixing_code_start_loc": [1551], "fixing_code_end_loc": [1566], "type": "CWE-190", "message": "Zend/zend_alloc.c in PHP 7.x before 7.0.10, when open_basedir is enabled, mishandles huge realloc operations, which allows remote attackers to cause a denial of service (integer overflow) or possibly have unspecified other impact via a long pathname.", "other": {"cve": {"id": "CVE-2016-7133", "sourceIdentifier": "cve@mitre.org", "published": "2016-09-12T01:59:11.787", "lastModified": "2017-07-01T01:30:05.610", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "Zend/zend_alloc.c in PHP 7.x before 7.0.10, when open_basedir is enabled, mishandles huge realloc operations, which allows remote attackers to cause a denial of service (integer overflow) or possibly have unspecified other impact via a long pathname."}, {"lang": "es", "value": "Zend/zend_alloc.c en PHP 7.x en versiones anteriores a 7.0.10, cuando la apertura de open_basedir est\u00e1 habilitada, no maneja adecuadamente operaciones de realloc enormes, lo que permite a atacantes remotos provocar una denegaci\u00f3n de servicio (desbordamiento de entero) o tener otro posible impacto no especificado a trav\u00e9s de un nombre de ruta largo."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:H/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "HIGH", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.2, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-190"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.0:*:*:*:*:*:*:*", "matchCriteriaId": "DB6890AF-8A0A-46EE-AAD5-CF9AAE14A321"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.1:*:*:*:*:*:*:*", "matchCriteriaId": "6B90B947-7B54-47F3-9637-2F4AC44079EE"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.2:*:*:*:*:*:*:*", "matchCriteriaId": "35848414-BD5D-4164-84DC-61ABBB1C4152"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.3:*:*:*:*:*:*:*", "matchCriteriaId": "2B1F8402-8551-4F66-A9A7-81D472AB058E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.4:*:*:*:*:*:*:*", "matchCriteriaId": "7A773E8E-48CD-4D35-A0FD-629BD9334486"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.5:*:*:*:*:*:*:*", "matchCriteriaId": "FC492340-79AF-4676-A161-079A97EC6F0C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.6:*:*:*:*:*:*:*", "matchCriteriaId": "F1C2D8FE-C380-4B43-B634-A3DBA4700A71"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.7:*:*:*:*:*:*:*", "matchCriteriaId": "3EB58393-0C10-413C-8D95-6BAA8BC19A1B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.8:*:*:*:*:*:*:*", "matchCriteriaId": "751F51CA-9D88-4971-A6EC-8C0B72E8E22B"}, {"vulnerable": true, "criteria": "cpe:2.3:a:php:php:7.0.9:*:*:*:*:*:*:*", "matchCriteriaId": "37B74118-8FC2-44CB-9673-A83DF777B2E6"}]}]}], "references": [{"url": "http://openwall.com/lists/oss-security/2016/09/02/9", "source": "cve@mitre.org", "tags": ["Mailing List"]}, {"url": "http://www.php.net/ChangeLog-7.php", "source": "cve@mitre.org", "tags": ["Release Notes"]}, {"url": "http://www.securityfocus.com/bid/92765", "source": "cve@mitre.org"}, {"url": "https://bugs.php.net/bug.php?id=72742", "source": "cve@mitre.org", "tags": ["Exploit", "Issue Tracking"]}, {"url": "https://github.com/php/php-src/commit/c2a13ced4272f2e65d2773e2ea6ca11c1ce4a911?w=1", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch"]}, {"url": "https://security.gentoo.org/glsa/201611-22", "source": "cve@mitre.org"}]}, "github_commit_url": "https://github.com/php/php-src/commit/c2a13ced4272f2e65d2773e2ea6ca11c1ce4a911?w=1"}}
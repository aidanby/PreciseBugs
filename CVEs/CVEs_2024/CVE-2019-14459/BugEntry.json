{"buggy_code": ["2019-07-25\n- Rework nfpcapd and add it officially to the nfdump collection.\n- Add nfpcapd man page\n\n2019-07-16\n- Add latency extension if dumping flowcache\n\n2019-07-15\n- Fix typos\n- Fix exporter struct inconsistancies. Coredump on ARM otherwise.\n\n2019-07-02\n- Add ipfix element #150, #151 unix time start/end\n- Fix display bug raw record\n\n2019-06-01\n- Add ipfix dyn element handling.\n- Add empty m4 directory - keep autoconf happy\n\n2019-06-01\n- Fix issue #162 - ipfix mpls sequece.\n- Fix issue #156 - print flowtable index error\n\n2019-03-17\n- Fix spec file\n- Remove non thread safe logging in nfpcapd\n\n2018-11-24\n- Fix protocol tag for protocol 87 - TCF - #130\n- Add TCP flags ECN,CVR - #132\n- Fix some error messages to be printed to the correct stream #135\n- Add missing -M command line help to nfcapd\n- Remove padding byte warning in log #141\n- Fix bug to accept -y compression flag in nfcapd. - #145\n\n2018-06-24\n- Fix bookkeeper type - use key_t\n- Add multiple packet repeaters to nfcapd/sfcapd. Up to 8 repeaters (-R) can be defined.\n- Ignore OSX .DS_Store files in -R file list\n- Add CISCO ASA elements initiatorPackets (298) responderPackets (299)\n- Merge #120 pull request for -z parameter to nfreplay\n- Update man page nfreplay\n\n2018-05-06\n- New bookkeeper hash broke NfSen. Fixed. ported back to release 1.6.17\n\n2018-04-20\n- Release 1.6.17\n\n2018-04-20\n- Fix bug in sorting when guessing flow direction. Issue #92\n- Update nfdump.1 man page for xsrcport & xdstport aggregations. Request #109\n- Fix minor bugs\n- Fix definition for InfluxDB in configure.ac Issue #98\n\n2018-04-01\n- Add program exit in nfx.c after panic with correupt data file\n- Add missing size check when reading nfdump 1.5.x common record blocks\n- Add missing option -M in man page. Issue #103\n- Add Fix processing of influx URL in nfprofile\n\n2018-02-11\n- Add missing json output format in nfdump help text\n- Add missing -v option in nfreplay help text\n\n2018-01-06\n- Merge pull request #51 Influxdb from Luca. Thx for the patch\n\n2018-01-01\n- IPFIX time stamps - Fix elements #21,#22 offset calculation, but timestamps not yet evaluated. (#160)\n- IPFIX add fwd status tag #89 compatible to v9 (1byte)\n\n2017-12-31\n- IPFIX sampling - sampling algorithm no longer required for tag #34\n- IPFIX sampling add tags #305 and #304 - set them identical to #34, #35\n\n2017-12-30\n- Add new output format json. Print each record as individual json object\n\n2017-12-28\n- Add sampling elements ID 302,304,305. put them identical to ID 48,49,50\n- Add option to label filter terms. syntax: (<filter>) %labelname.\n- Add %lbl option to print flow label in output\n- Update nfdump(1) man page for flowlabels\n\n2017-12-27\n- Add ipfix delta timestamp elements 158/159. \n- Update sflow code to commit 7322984 of https://github.com/sflow/sflowtool\n- Cleanup sflow code - uncomment unnecessary code\n- Fix header includes\"\n- Fix 64bit fts compat issue in fts_compat.c\n- Add more detailed autogen.sh - softlink bootstrap\n\n2017-12-22\n- Fix potential memory leaks in nfpcapd\n\n2017-12-21\n- Fix wrong offset calculation if unknown options are found\n- Add x-late src/dst ip aggregation, if compiled with NSEL support\n\n2017-12-17\n- Add ipfix sampling. Process option template/record with sampling elements 34 and 35\n- Report updates on existing samplers in v9 only if values change. issue 84\n\n2017-11-05 v1.6.16\n\n2017-12-10\n- Add lz4 compression\n- Remove old xstat legancy code, not needed\n- Remove automake files from git\n\n2017-12-03\n- Fix old 1.6.15 tags\n- Fix minor issues and compiler warnings\n\n2017-10-22\n- Add support for CISCO IOS 8 bytes timestamps ID 21/22\n- Fix issue #72 - multiple stat output\n- Change -B behaviour as proposed in issue #59. Should not impact with previous use, but is more flexible\n- Add bzip compress switch in usage output of nfpcapd\n- Fix compile issues on some platforms\n- nfpcapd improvements - still beta software.\n- Minor bug fixes\n\n2016-11-25\n- Add latency extension to nfpcapd\n- Smaller bug fixes to nfpcapd\n\n2016-07-23\n- Replace unreliable _ftok with more reliable string hash\n\n2016-07-20\n- Aggregate using in+out bytes for bidirectional flows\n\n2016-06-05 v.1.6.15\n- Fix Security issue http://www.security-assessment.com/files/documents/advisory/Nfdump%20nfcapd%201.6.14%20-%20Multiple%20Vulnerabilities.pdf\n- Fix obyte, opps and obps output records\n- Fix wrong bps type case in cvs output. Fix opbs ipbs typos\n\n2016-01-10 v.1.6.14\n- Fix CentOS compile issues with flow-tools converter\n- Fix FreeBSD,OpenBSD build problems\n- Fix timestamp overflow in sflow.c\n\n2015-12-23\n- Fix IP Fragmentation in sflow collector\n- Create libnfdump for dynamic linking\n\n2015-10-02\n- Fix compile errors on other platforms\n- Add -R to ModifyCompression\n- Add std sampler ID 4 Bytes and allow random sampler (tag 50)\n- Add BZ2 compression along existing LZ0\n- Add direct write to flowtools converter ft2nfdump\n- Fix zero alignment bug, if only half of an extension is sent\n- Fix nfanon time window bug in subsequent files in -R list\n- Fix CommonRecordV0Type conversion bug\n- Fix nfexport bug, if only one single map exists\n\n2014-11-16 v.1.6.13\n- Fix v1 extension size bug\n- Add htonll check for autoconf\n- Fix AddExtensionMap compare bug\n- Fix ipfix templare withdraw problems - free all maps correctly\n- Add minilzo 2.08 - fixes CVE-2014-4607\n- Cleanup some stat code. more needs to be done ..\n- Cleanup man pages for -O -n\n- Remove SunPro test in configure - no longer supported anyway\n- Cleanup NAT/NSEL filter differences\n\n2014-06-15 v1.6.12p1\n- Add pblock compare functions\n- Update extended filter: Allow modification left/right values\n\n2014-02-16 v1.6.12\n- Add NAT pool port allocation\n- Modify/fix NAT vrf tags. Add egress vrf ID\n- Modify common record due to exporter exhaustion. new common record\n  type 10 adds 4 extra bytes. Reads v1 common record transparently\n- Fix sflow potential crash\n\n2013-11-13 v1.6.11\n- Add ASA/NSEL 9.x protcol changes\n- Make it llvm compilable\n \n2013-08-12 v1.6.10p1\n- Fix -t +/- n timeslot option\n- Fix bug in nfanon - stat record update.\n- Fix bug in netflow v5 mudule: extension map size wrong.\n- Fix bug nfexport: In some cases could result in wrong flow counter. \n- Fix nftrack - could coredump in some cases.\n\n2013-05-16 v1.6.10\n- Fix SPARC compile/optimise bug\n- Add output packet/bytes counter to global stat - importatnt for NSEL flows ASA > 8.5\n- Add NSEL filter options xnet\n- Modify extension descriptor code for nfdump1.7. Still use 1.6 extension map layout for compatibility\n- Add prototype for nfpcapd - pcap -> nfdump collector. Converts traffoc directly to nfdump files.\n- Fix bug in ipfix module: uninitialised variable\n- Cleanup syslog/LogError calls\n- Fix minor non critical bugs and compile issues\n\n2013-03-02 v1.6.9\n- Fix some bugs in beta 1.6.9 NSEL code\n- Fix bug statistics update with aggreagted flow records\n- Fix sflow bug sfcapd stores wrong (ghost) dump by past samples in same sflow datagram\n\n2012-12-31\n- Add time received in csv output\n- ICMP should handled better now - somewhat\n- Implement ASA NSEL records\n- Add definitions in nffile and nx for ASA NSEL extensions\n\n2012-11-09 v1.6.8p1\n- Add dynamic source directory tree for multiple exporters\n- Fix exporter bug: 'too many exporters' with large time windows\n- Fix uninitialised exporter sysid in default sampler record - v9\n- Fix v9/ipfix cache initialisation with no templates > 1 in same packet\n\n2012-10-26 v1.6.8\n- Add ip list option for 'next ip' in filter syntax\n- Accept v9 sampler_id in 2bytes\n- Fix IPFIX mac address bug - did not get collected\n- Add IPFIX packet/octet TotalCount fields 85/86\n- Add received timestamp to sflow collector\n- Fix long flow duration calculation - 32bit overflow\n- Fix v9 sampling ID: allow 2 byte ID\n- Add IPFIX options as rfc5101 section-6.2\n- Add exporter records for sflow collector\n- Fix bug for MAC address printing %idmc and %odmc.\n- Add received time stamp extension\n- Add recursive format parser. Allows to extend predefined formats.\n- Change flow record sorting to heapsort. remove limit 1000\n- Merge -m option to -O tstart. -m now depricated.\n- Add -O tend. Print order according to tend of flows ascending\n- Apply -O print order for printing flow cache. Applies to -A\n\n2012-07-31 v1.6.7-tc-1\n- Special version for TC\n- Print exporter and sampling records with nfdump -E\n- Added exporter and sampling records to file.\n\n2012-07-30 v1.6.7\n- Prepare for file catalog in current file format.\n- Fix bug in ReadBlock when reading flow from stdin pipe\n- Add new more flexible translation engine for v9\n- Add nprobe client/server delay fields\n- Prepare for NSEL merging\n- Fix memory corruption with double -A flags\n- Fix bug in nfreader with compat15 mode files\n\n2012-03-12 v1.6.6\n- Minor IPFIX bug.\n- IPFIX implement template withdraw\n- For IPFIX, check packet sequence per template and observation domain\n- Fix time window, when no flows collected or no flows matched\n  while processing\n- Fixed typos\n- Fix seg fault bug - test for EMPTY_LIST was missing at several places.\n\n2012-02-19 v1.6.6b1\n- Fix bps/pps. make it uint64_t, as bps/pps > 4Gb/s overflows.\n- In record raw print mode: decode ICMP instead of src/dst ports\n- sflow use announced exporter IP instead of sending IP for router ID\n- sflow: Ignore extra fill bytes. Do not complain.\n- sflow: fix packet length issue.\n- Add IPFIX protokoll support\n\n2011-12-31 v1.6.5\n- Fix 64bit bug when using byte/packet limits\n- for v5 and sampling use 64bit counters to prevent overflow for large sampled flows.\n- Fixed Ident printig bug\n\n2011-07-11 v1.6.4\n- some code restructuring - prepare for IPFIX module\n- Add netflow v1 module. Some routers still use that\n- Add %sn, %dn output tags for src/dst networks\n- Fix buffer length check in v5.\n- Fix export bug: include last flow cache bucket, when exporting\n- number in all filter expressions accept hex values\n- fix an sflow colletor bug. Missing extension maps in rotated files\n- implement extended statistics. Currently ports and bpp distribution\n  vectors can be collected automatically be nfcapd. Still experimental\n\n2011-02-26 v1.6.3p1\n- Fix timebug fix :(, make it a compile time option\n- fix v7 sequence errors\n\n2011-02-15\n- Zero out unused fields after aggregation\n\n2011-02-05\n- Fix SysUptime 32bit overflow in v5 header\n- Add fix for strange first/last swap reported by some users.\n\n2011-01-09 v1.6.3 \n- Fix extension size bug\n- Move IP anonymisation to separate binary nfanon\n- Fix initialise bug of -o fmt: and not available fields\n\n2010-09-09 v1.6.2 \n- released\n- fixes some sflow bugs in sfcapd\n\n2010-04-28 v1.6.1p0\n- Update flow tools converter to build with Google-Code version 0.68.5\n- Fix sflow bugs\n\n2010-03-05 v1.6.1\n- Fix bug in man page for -t\n- Test sampler infos before using them ( nfcapd startup )\n- Add sampling tags #34, #35 used by JunOS\n- nfexpire: Fix empty .nfsat, when setting limits on an empty directory\n- Fix coredump for -B -m (-w) combination\n- Optimise some extension map code\n\n2009-12-28 stable v1.6\n- Few bug fixes in release candidates rc1, rc2 and rc3\n\n2009-11-16 snapshot-1.6b-20091116\n- Update sflow collector with new tags\n- Add router IP extension\n- Add router ID (engine type/ID) extension\n\n2009-09-30 snapshot-1.6b-20090930\n- snapshot bugfix release\n\n2009-11-0801 snapshot-1.6b-20090806\n- Add srcmask and dstmask aggregation\n- Add csv output mode. -o csv\n- Fix some bugs of previous beta\n- Add bidirectional aggregation of flows ( -b, -B )\n- Add possibility to save aggregated flows into file ( -w )\n  Note: This results in a behaviour change for -w in combination\n  with aggragation )\n- Extend -N ( do not scale numbers ) to all text output not just summary\n- Make extension handling more robust for some moody IOSes.\n- Remove header lines of -s stat, when using -q ( quiet ) \n  Note: This results in a behaviour change for -N\n- Remove -S option from nfdump ( legacy 1.4 compatibility )\n- Make use of log (syslog) functions for nfprofile.\n- Move log functions to util.c\n\n2009-06-19 snapshot-1.6b-20090717\n- Flow-tools converter updated - supports more common elements.\n- Sflow collector updated. Supports more common elements.\n- Add sampling to nfdump. Sampling is automatically recognised\n  in v5 undocumented header fields and in v9 option templates.\n  see nfcapd.1(1)\n- Add @include option for filter to include more filter files.\n- Add flexible aggregation comparable to Flexible Netflow (FNF)\n- All new tags can be selected in -o fmt:... see nfdump(1)\n- topN stat for all new tags is implemented\n- Integrate developer code to read from pcap files into stable\n- Update filter syntax for new tags\n- Added more v9 tags for netflow v9.\n  The detailed tags are listed in nfcapd(1)\n  Adding new tags also extended the binary file format with\n  data block format 2, which is extension based. File format \n  for version <= 1.5.* ( Data block format 1 ) is read \n  transparently. Data block 2 are skipped by nfdump 1.5.7.\n  32bit but AS and interface numbers are supported.\n- Add flexible storage option for nfcapd. To save disk space, the \n  data extensions to be stored in the data file are user selectable.\n- Added option for multiple netflow stream to same port.\n  -n <Ident,IP,base_directory>\n  Example: -n router1,192.168.100.1,/var/nfdump/router1\n  So multiple -n options may be given at the command line\n  Old style syntax still works for compatibility, ( -I .. -l ... )\n  but then only one source is supported.\n- Move to automake for building nfdump\n- Switch scaling factor ( k, M, G ) from 1024 to 1000.\n- Make nfdump fully 64bit compliant. ( 8bit data alignments and access )\n\n2009-04-17 stable 1.5.8\n- Fix daylight summer time bug, when guessing sub dirs. file access ( -M, -r )\n- Bug fixes for 64bits CPUs\n\n2008-02-22 stable-1,5.7\n- Add icmp type/code decoding\n- Add proper icmp v9 decoding\n- Fix memory leaks in -e auto expire mode in nfcapd.\n- Fix somee potential dead locks with file locking, when expiring\n- Fix multicast bug in nfreplay\n- Add hostname lookup for IP addresses in filter.\n\n2007-10-15\tstable-1.5.6\n- Fix odd CISCO behaviour for ICMP type/code in src port.\n- Add fast LZO1X-1 compression option (-z) for output file.\n- Add lists for port in syntax -> port in [ 135 137 445]\n- Add lists for AS syntax -> as in [ 1024 1025 ]\n- Bug fix in filter for syntax 'src as and dst as' \n\n2007-08-24  stable-1.5.5\n- Fix nfprofile bug, nfprofile crashes when last opts line is not valid for \n  some reason.\n- Fix potential hand for nfexpire, on empty flow directories.\n\n2007-08-08  snapshot-20070808\n- Idents may contain '-' in name.\n- Fixed install bugs in Makefile.in and configure.in\n- Installs now cleanly on Solaris\n- Handle 4byte interface numbers in v9. Quick fix: 4bytes reduced to 2bytes.\n- Fix aggregation bug in statistics.\n- ftok(3) C library call replaced by more reliable own implementation. \n  Did result in error messages like \"Another collector is already running\" \n- Fix minor bugs iin file range selction -R.\n- Add recursive behaviour for -R <directory>\n- New option -i can canche Ident descriptor in data files.\n\n2007-03-12  snapshot-20070312\n- Bug fix release of 20070306\n\n2007-03-06  snapshot-20070306\n- Fix bug in flist.c. Resulted in a coredump when using sub dirs and -R . ( all files )\n- Fix minor bug in nfcapd.c. \n- Extend nfprofile for alerting system of nfsen - special version of profiles\n- Extend nfprofile for shadow profiles.\n\n2007-08-10  snapshot-20070110\n- Fix some compiler warnings, when compiled on a 64bit LINUX\n- Fixes an sflow bug: IP address was printed in wrong direction. ( lower bits first )\n- Add new IP addr taging option -T for easy parsing for nfsen lookups\n- Add new IP list for massive address filtering:\n  syntax: ip in [ 12345 23456 3456 ....]\n- Change nfprofile for channel based profiling. This breaks with old nfprofile \n  functionality.\n- Remove space from ICMP type/code when followed by an IP address\n\n2006-07-21\tsnapshot-20060809\n- Make nfexpire ready for profile expiration\n- Fix bug in nfrpofile. sub dir hierarchy not handled correctly.\n\n2006-07-21\tsnapshot-20060721\n- Add -N option for plain number output in summary line\n\n2006-07-21\tsnapshot-20060721\n- Do recursive file selection when a directory is given by -R\n\n2006-06-14\tsnapshot-20060621\n- Add srcas/dstas/proto aggregation.\n  Note: This changes the default aggregation behaviour, but gives more flexibility\n- Add tos to element statistics list\n\n2006-06-14\tsnapshot-20060614\n- Add additional stat line at the end of output\n- Add new binary nfexpire. Manages data expiry on time and/or size based limits\n  Includes new bookkeeping records in nfcapd.  See nfexpire(1)\n- Add ICMP type/code decoding in flow listing instead of dst port\n- Add packet repeater in nfcapd/sfcapd. In addition, incoming UDP packets can \n  be directly forwarded to another IP address/Port. See new option -R\n- Add sub directory hierarchies: Files can be stored into various sub dir levels\n  based on different time formats. see new option -S\n- Some minor bug fixes.\n- Code cleanup in nfcapd. better daemonize code and communication with launcher.\n\n2006-04-xx\tv.1.5.1\n\t\t\tFix bug in nfdump.c: Writing anonymized flows to file did not work corretly\n\t\t\tstdin input format now compatible with file format, therefore\n\t\t\t'nfdump < file' works again as it did in nfdump 1.4.\n\t\t\tFix bug in nfcapd.c: Error handling not correct when receiving a non\n\t\t\trecognized netflow packet. Resulted in an endless loop\n2006-03-27\tsnapshot 1.5-20060327\n\t\t\tMake all element statistics -s transport layer protocol\n\t\t\tindependant by default. Add :p to stat name ( e.g. srcip:p ) to\n\t\t\tenable transport layer dependant statistics on request.\n2006-03-20\tsnapshot 1.5-20060320\n            Fix bug in filter engine: 'not flags xyz' produces wrong results\n\t\t\twhen more than a single flag is specified.\n\t\t\tMinor man page fixes.\n\n2006-03-06\tv1.5\n\t\t\tFix bug nfcapd. Laucher signaled too early. File not yet properly\n\t\t\tclosed.\n2006-02-14\tv1.5-beta-5\n\t\t\tAdd srcas, dstas, input and output interfaces in aggregated\n\t\t\toutput. \n\t\t\tFix IPv6 bug in filter: accept 1234:: address.\n\t\t\trename nfcapd.curent tmp file to nfcapd.curren.<pid>. Poorly\n\t\t\tconfigured nfcapd processes may mess up themselves otherwise.\n2006-02-02\tv1.5-beta-4\n\t\t\tFix netflow v5 dPkts <-> dOctets collector bug.\n\t\t\tUpdate pipe format to include more information\n\t\t\tAllow AS number 0 in filter syntax.\n\t\t\tAdd some more boundary checking - netflow exporters aren't bug free either - sigh ..\n2006-01-11\tv1.5-beta-3\n\t\t\tFix isnumber incompatibility in grammar.y\n\t\t\tAdd 'if' statistics\n2006-01-10\tv1.5-beta-2\nnf_common.c\tFix bug in format parser.\n\t\t\tExtended 'proto <protocol>' syntax to support all protocols\n\t\t\tChange time format in summary line to ISO format\n2005-12-20\tv1.5-beta-1\n*.*\t\t\tA lot of internal changes, not mentioned here. :(\n\nnfdump\t\tAdd subnet aggregation for option -A\n\t\t\tA new syntax e.g. srcip4/24, dstip6/64 is supported for subnet wise aggregation.\n\t\t\texample: traffic of a whole subnet -A srcip4/24 -s srcip/bytes\n\nnfdump\t\tAdd more stat element option. -s <stat> now supports:\n\t\t\tsrcip, dstip, ip, srcport, dstport, port, srcas, dstas, as, inif, outif, proto\n\nnfdump\t\tAdd -z. Suppress writing flows to data files. Only stat information is written.\nnfprofile\tUsed only be nfsen for upcoming shadow profiles. If you don't understand this\n\t\t\tsimply ignore it.\n\nnfdump\t\tAdd -q option to suppress header as well as stat information at the bottom\nnfprofile\tfor easier post processing with external programms.\n\nnf_common.c\tOutput format processsing rewritting for more flexibility. Besides standard\nnfdump.c\toutput formats line, long extended etc., user defined output formats are now \n\t\t\tpossible and can even be compiled into nfdump for easy access. See -o fmt:<format>\n\t\t\tand nfdump.c around line 100.\n\n*.*\t\t\tIntegrate netflow v9 into nfdump. Only a subset of v9 is stored into\n\t\t\tthe data files, basically everything needed for nfdump to work as it did before.\n\t\t\tThis also includes IPv6 support for any nfdump options. CryptoPAN extended\n\t\t\tto work with IPv6. IPv6 condensed output format for better readability.\n\t\t\tOutput formats available in long and condensed mode: e.g. line -> line6\n\t\t\textended -> extended6\n\n*.*\t\t\tReplace binary data file format. Old format not flexible enough for\n\t\t\tupcoming netflow v9/sflow data. *.stat files are gone. The same \n\t\t\tinformation is now available under nfdump -I\n\t\t\tNew format about 5% larger in size, but faster for reading and writing.\n\t\t\tspeed gain eaten up by more complex processing - sigh ..\n\t\t\tcompat14 mode enables transparent reading of old style format.\n\t\t\tnffile.[ch] now handles all data file stuff.\n\nnfreplay\tMulticast enabled:\n\t\t\tAdd -j <join group>. Joins the specified multicast group ( v4 or v6 )\n\t\t\tsending flows to this group.\n\nnfreplay\tIPv6 enabled:\n\t\t\tAdd option -4 and -6 to force a specific protocol, otherwise\n\t\t\tprotocol is automatically selected according the hostname to send flows to.\n\t\t\tAdd -K key, to send data anonymized, using CryptoPAn\n\nnfcapd\t\tMulticast enabled:\n\t\t\tAdd -j <join group>. Joins the specified multicast group ( v4 or v6 )\n\t\t\tfor listening.\n\nnfcapd\t\tIPv6 enabled:\n\t\t\tAdd option -4 and -6 for IPv4 and IPv6. By default, listen on IPv4.\n\t\t\tOption -b <host/IP> to bind for a specific host/IP address automatically\n\t\t\tselects appropriate protocol.\n\nnfnet.c\t\tAll functions to setup network sockets for listening/sending are \n\t\t\tput into this file.\n\n2005-08-22 v1.4\n- nfreplay:  Bug fix sending flows.\n- nfdump:    Add CryptoPAn code to anonymize IP addresses. New option -K\n- nfdump:    Change time format in output to ISO 8601 compatible: e.g. 1981-04-05 14:30:30.100\n- nfdump:    Add scaling factor k,m,g to number in filter syntax: e.g. bytes > 1m\n- nfdump:    Create new output format extended with additional fields pps, bps and bpp\n- nfdump:    Rename output format extended to raw\n- nfdump:    More than one single flow element statistic ( -s ) is now possible\n- nfdump:    Add user defined sort order in flow element statistic\n- nfdump:    Flow element statistic can be ordered by more than one order in the same run\n- nfdump:    Add pps, bps and bpp fields in flow element statistics\n- nfdump:    Add more symbolic protocols ESP, AH, GRP and RVSP to filter syntax\n- nfdump:    Add duration, pps, bps and bpp to filter syntax\n- nfdump:    Make nfdump miliseconds aware. Older versions skipped msecs.\n  Binary nfdump file format changed due to this.\n  output formats changed, due to this.\n- nfdump:    Add interface in/out if <num> syntax to filter\n- nfcapd:    Add flow_sequence check. Reports missing flows now.\n- nfcapd:    Report statistics to syslog LOG_INFO when data file is rotated.\n- ft2nfdump: Add ft2nfdump to read netflow data from flow-tools\n\n2005-04-21 v1.3\n- Add option -A for more flexible aggregation.\n- Correct spelling errors :(\n\n2005-03-04 v1.2.1\nBug fix release\n- nfcapd: launcher subprocess may hang on Linux 2.6.x kernels.\n  Cleaned up interrupt handling. \n- nfcapd: fix include order of socket.h and types.h in order to\n  compile cleanly under FreeBSD 4.x\n- nfcapd: clean up syslog logging.\n- nfdump: Multiple sources ( -M ) and sort flows ( -m ) with \n  -c <limit> did not list the correct flows.\n- nfprofile: Profiling with multiple sources may produce incorrect\n  profiles. \n\n2004-12-20 v1.2\n- nfcapd handles transparent v5 and v7 flows. v7 gets converted into v5\n- nfcapd can execute any command at the end of interval. New option -x\n- nfdump Extended filter syntax for flags, to, bytes and packets\n- Rearrange output formats in nfdump: new switch -o, remove switch -E\n  output formats: 'line', 'long', 'extended' and 'pipe'\n- More flexible statistic handling in nfdump: cleanup ugly -s -s -s\n  syntax. Replaced by -s <stat> option. New statistics for Port and AS.\n\n2004-09-20 v 1.1\nFirst public Version.\n", "/*  \n *  Copyright (c) 2012-2019, Peter Haag\n *  All rights reserved.\n *  \n *  Redistribution and use in source and binary forms, with or without \n *  modification, are permitted provided that the following conditions are met:\n *  \n *   * Redistributions of source code must retain the above copyright notice, \n *     this list of conditions and the following disclaimer.\n *   * Redistributions in binary form must reproduce the above copyright notice, \n *     this list of conditions and the following disclaimer in the documentation \n *     and/or other materials provided with the distribution.\n *   * Neither the name of the author nor the names of its contributors may be \n *     used to endorse or promote products derived from this software without \n *     specific prior written permission.\n *  \n *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" \n *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE \n *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE \n *  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE \n *  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR \n *  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF \n *  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS \n *  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN \n *  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) \n *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE \n *  POSSIBILITY OF SUCH DAMAGE.\n *  \n */\n\n#include \"config.h\"\n\n#include <stdio.h>\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <unistd.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#include <time.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n\n#ifdef HAVE_STDINT_H\n#include <stdint.h>\n#endif\n\n#include \"nffile.h\"\n#include \"nfx.h\"\n#include \"nfnet.h\"\n#include \"nf_common.h\"\n#include \"util.h\"\n#include \"bookkeeper.h\"\n#include \"collector.h\"\n#include \"exporter.h\"\n#include \"ipfix.h\"\n\n#ifndef DEVEL\n#   define dbg_printf(...) /* printf(__VA_ARGS__) */\n#else\n#   define dbg_printf(...) printf(__VA_ARGS__)\n#endif\n\n// a few handy macros\n#define GET_FLOWSET_ID(p) \t  (Get_val16(p))\n#define GET_FLOWSET_LENGTH(p) (Get_val16((void *)((p) + 2)))\n\n#define GET_TEMPLATE_ID(p) \t  (Get_val16(p))\n#define GET_TEMPLATE_COUNT(p) (Get_val16((void *)((p) + 2)))\n\n#define GET_OPTION_TEMPLATE_ID(p) \t  \t\t  \t\t (Get_val16(p))\n#define GET_OPTION_TEMPLATE_FIELD_COUNT(p)   (Get_val16((void *)((p) + 2)))\n#define GET_OPTION_TEMPLATE_SCOPE_FIELD_COUNT(p)   \t\t (Get_val16((void *)((p) + 4)))\n\n#define DYN_FIELD_LENGTH\t65535\n\n/* module limited globals */\n\n/* \n * sequence element to move data from data input to output\n * a sequence exists for each IPFIX element\n */\ntypedef struct sequence_map_s {\n/* sequence definition:\n   just move a certain number of bytes          -> moveXX\n   set a certain number of output bytes to zero -> zeroXX\n   process input data into appropriate output   -> AnyName\n */\n#define nop    \t\t\t0\n#define dyn_skip\t\t1\n#define move8   \t\t2\n#define move16  \t\t3\n#define move32  \t\t4\n#define move40  \t\t5\n#define move48  \t\t6\n#define move56  \t\t7\n#define move64  \t\t8\n#define move128 \t\t9\n#define move32_sampling 10\n#define move64_sampling 11\n#define move_mac\t\t12\n#define move_mpls \t\t13\n#define move_flags\t\t14\n#define Time64Mili \t\t15\n#define TimeDeltaMicro \t16\n#define TimeUnix \t\t17\n#define saveICMP \t\t18\n#define zero8\t\t\t19\n#define zero16\t\t\t20\n#define zero32\t\t\t21\n#define zero64\t\t\t22\n#define zero128\t\t\t23\n\n\tuint32_t\tid;\t\t\t\t// sequence ID as defined above\n\tuint16_t\tskip_count;\t\t// skip this number of bytes in input stream after reading\n\tuint16_t\ttype;\t\t\t// Element type\n\tuint16_t\tinput_length;\t// length of input element\n\tuint16_t\toutput_offset;\t// copy final data to this output offset\n\tvoid\t\t*stack;\t\t\t// optionally copy data onto this stack\n} sequence_map_t;\n\n/*\n * the IPFIX template records are processed and\n * for each template we create a a translation table, which contains\n * all information required, to transform the data records from\n * the exporter into nfdump internal data structurs.\n * All templates are chained in a linked list\n */ \ntypedef struct input_translation_s {\n\tstruct input_translation_s\t*next;\t// linked list\n\tuint32_t\tflags;\t\t\t\t\t// flags for output record\n\ttime_t\t\tupdated;\t\t\t\t// timestamp of last update/refresh\n\tuint32_t\tid;\t\t\t\t\t\t// template ID of exporter domains\n\tuint32_t\toutput_record_size;\t\t// required size in nfdump format\n\n\t// tmp vars needed while processing the data record\n\tint\t\t\tdelta_time;\t\t\t\t// delta micro or absolute ms time stamps\n\tuint64_t\tflow_start;\t\t\t\t// start time in msec\n\tuint64_t\tflow_end;\t\t\t\t// end time in msec\n\tuint32_t\ticmpTypeCodeIPv4;\t\t// ICMP type/code in data stream\n\tuint64_t    packets;\t\t\t\t// total (in)packets - sampling corrected\n\tuint64_t    bytes;\t\t\t\t\t// total (in)bytes - sampling corrected\n\tuint64_t    out_packets;\t\t\t// total out packets - sampling corrected\n\tuint64_t    out_bytes;\t\t\t\t// total out bytes - sampling corrected\n\tuint32_t\trouter_ip_offset;\n\tuint32_t\treceived_offset;\n\n\t// extension map infos\n\tuint32_t\textension_map_changed;\t// map changed while refreshing?\n\textension_info_t \t extension_info; // the extension map reflecting this template\n\n\t// sequence map information\n\tuint32_t\tmax_number_of_sequences; // max number of sequences for the translate \n\tuint32_t\tnumber_of_sequences;\t// number of sequences for the translate \n\tsequence_map_t *sequence;\t\t\t// sequence map\n} input_translation_t;\n\n/*\n * \tAll Obervation Domains from all exporter are stored in a linked list\n *\twhich uniquely can identify each exporter/Observation Domain\n */\ntypedef struct exporter_ipfix_domain_s {\n\tstruct exporter_ipfix_domain_s\t*next;\t// linkes list to next exporter\n\n\t// generic exporter information\n\texporter_info_record_t info;\n\n\tuint64_t\tpackets;\t\t\t// number of packets sent by this exporter\n\tuint64_t\tflows;\t\t\t\t// number of flow records sent by this exporter\n\tuint32_t\tsequence_failure;\t// number of sequence failues\n\tuint32_t\tpadding_errors;\t\t// number of sequence failues\n\n\t// generic sampler\n\tgeneric_sampler_t\t\t*sampler;\n\n\t// exporter parameters\n\tuint32_t\tExportTime;\n\n\t// Current sequence number\n\tuint32_t\tPacketSequence;\n\n\t// statistics\n\tuint64_t\tTemplateRecords;\t// stat counter\n\tuint64_t\tDataRecords;\t\t// stat counter\n\n\t// linked list of all templates sent by this exporter\n\tinput_translation_t\t*input_translation_table; \n\n\t// in order to prevent search through all lists keep\n\t// the last template we processed as a cache\n\tinput_translation_t *current_table;\n\n} exporter_ipfix_domain_t;\n\n\nstatic struct ipfix_element_map_s {\n\tuint16_t\tid;\t\t\t// IPFIX element id \n\tuint16_t\tlength;\t\t// type of this element ( input length )\n\tuint16_t\tout_length;\t// type of this element ( output length )\n\tuint32_t\tsequence;\t// \n\tuint32_t\tzero_sequence;\t// \n\tuint16_t\textension;\t// maps into nfdump extension ID\n} ipfix_element_map[] = {\n\t{0, 0, 0},\n\t{ IPFIX_octetDeltaCount, \t\t\t _8bytes, \t_8bytes,  move64_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_octetDeltaCount, \t\t\t _4bytes, \t_8bytes,  move32_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_packetDeltaCount, \t\t\t _8bytes, \t_8bytes,  move64_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_packetDeltaCount, \t\t\t _4bytes, \t_8bytes,  move32_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_octetTotalCount, \t\t\t _8bytes, \t_8bytes,  move64_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_octetTotalCount, \t\t\t _4bytes, \t_8bytes,  move32_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_packetTotalCount, \t\t\t _8bytes, \t_8bytes,  move64_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_packetTotalCount, \t\t\t _4bytes, \t_8bytes,  move32_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_forwardingStatus, \t \t\t _1byte,    _1byte,   move8, zero8, COMMON_BLOCK },\n\t{ IPFIX_protocolIdentifier, \t\t _1byte, \t_1byte,   move8,  zero8, COMMON_BLOCK },\n\t{ IPFIX_ipClassOfService, \t\t\t _1byte, \t_1byte,   move8, zero8, COMMON_BLOCK },\n\t{ IPFIX_tcpControlBits, \t\t\t _1byte, \t_1byte,   move8, zero8, COMMON_BLOCK },\n\t{ IPFIX_tcpControlBits, \t\t\t _2bytes, \t_1byte,   move_flags, zero8, COMMON_BLOCK },\n\t{ IPFIX_SourceTransportPort, \t\t _2bytes, \t_2bytes,  move16, zero16, COMMON_BLOCK },\n\t{ IPFIX_SourceIPv4Address, \t\t\t _4bytes, \t_4bytes,  move32, zero32, COMMON_BLOCK },\n\t{ IPFIX_SourceIPv4PrefixLength, \t _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_ingressInterface, \t\t\t _4bytes, \t_4bytes,  move32, zero32, EX_IO_SNMP_4 },\n\t{ IPFIX_ingressInterface, \t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_IO_SNMP_2 },\n\t{ IPFIX_DestinationTransportPort,\t _2bytes, \t_2bytes,  move16, zero16, COMMON_BLOCK },\n\t{ IPFIX_DestinationIPv4Address, \t _4bytes, \t_4bytes,  move32, zero32, COMMON_BLOCK },\n\t{ IPFIX_DestinationIPv4PrefixLength, _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_egressInterface, \t\t\t _4bytes, \t_4bytes,  move32, zero32, EX_IO_SNMP_4 },\n\t{ IPFIX_egressInterface, \t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_IO_SNMP_2 },\n\t{ IPFIX_ipNextHopIPv4Address, \t\t _4bytes, \t_4bytes,  move32, zero32, EX_NEXT_HOP_v4 },\n\t{ IPFIX_bgpSourceAsNumber, \t\t\t _4bytes, \t_4bytes,  move32, zero32, EX_AS_4 },\n\t{ IPFIX_bgpSourceAsNumber, \t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_AS_2 },\n\t{ IPFIX_bgpDestinationAsNumber, \t _4bytes, \t_4bytes,  move32, zero32, EX_AS_4 },\n\t{ IPFIX_bgpDestinationAsNumber, \t _2bytes, \t_2bytes,  move16, zero16, EX_AS_2 },\n\t{ IPFIX_bgpNextHopIPv4Address, \t\t _4bytes, \t_4bytes,  move32, zero32, EX_NEXT_HOP_BGP_v4},\n\t{ IPFIX_flowEndSysUpTime, \t\t\t _4bytes, \t_4bytes,  nop, nop,  COMMON_BLOCK },\n\t{ IPFIX_flowStartSysUpTime, \t\t _4bytes, \t_4bytes,  nop, nop, COMMON_BLOCK },\n\t{ IPFIX_postOctetDeltaCount, \t\t _8bytes, \t_8bytes,  move64, zero64, EX_OUT_BYTES_8 },\n\t{ IPFIX_postOctetDeltaCount, \t\t _4bytes, \t_4bytes,  move32, zero32, EX_OUT_BYTES_4 },\n\t{ IPFIX_postPacketDeltaCount, \t\t _8bytes, \t_8bytes,  move64, zero64, EX_OUT_PKG_8 },\n\t{ IPFIX_postPacketDeltaCount, \t\t _4bytes, \t_4bytes,  move32, zero32, EX_OUT_PKG_4 },\n\t{ IPFIX_SourceIPv6Address, \t\t\t _16bytes, \t_16bytes, move128, zero128, COMMON_BLOCK },\n\t{ IPFIX_DestinationIPv6Address, \t _16bytes, \t_16bytes, move128, zero128, COMMON_BLOCK },\n\t{ IPFIX_SourceIPv6PrefixLength, \t _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_DestinationIPv6PrefixLength, _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_icmpTypeCodeIPv4, \t\t\t _2bytes, \t_2bytes,  saveICMP, nop, COMMON_BLOCK },\n\t{ IPFIX_postIpClassOfService, \t\t _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_SourceMacAddress, \t\t\t _6bytes, \t_8bytes,  move_mac, zero64, EX_MAC_1},\n\t{ IPFIX_postDestinationMacAddress, \t _6bytes,\t_8bytes,  move_mac, zero64, EX_MAC_1},\n\t{ IPFIX_vlanId, \t\t\t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_VLAN}, \n\t{ IPFIX_postVlanId, \t\t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_VLAN},\n\t{ IPFIX_flowDirection, \t\t\t\t _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_ipNextHopIPv6Address, \t\t _16bytes, \t_16bytes, move128, zero128, EX_NEXT_HOP_v6},\n\t{ IPFIX_bgpNextHopIPv6Address, \t\t _16bytes, \t_16bytes, move128, zero128, EX_NEXT_HOP_BGP_v6},\n\t{ IPFIX_mplsTopLabelStackSection, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection2, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection3, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection4, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection5, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection6, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection7, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection8, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection9, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection10, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_DestinationMacAddress, \t\t _6bytes,   _8bytes,  move_mac, zero64, EX_MAC_2},\n\t{ IPFIX_postSourceMacAddress, \t\t _6bytes,   _8bytes,  move_mac, zero64, EX_MAC_2},\n\t{ IPFIX_flowStartMilliseconds, \t\t _8bytes,   _8bytes,  Time64Mili, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowEndMilliseconds, \t\t _8bytes,   _8bytes,  Time64Mili, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowStartSeconds, \t\t \t _4bytes,   _4bytes,  TimeUnix, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowEndSeconds,  \t \t\t _4bytes,   _4bytes,  TimeUnix, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowEndMilliseconds, \t\t _8bytes,   _8bytes,  Time64Mili, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowStartDeltaMicroseconds,\t _4bytes,   _4bytes,  TimeDeltaMicro, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowEndDeltaMicroseconds, \t _4bytes,   _4bytes,  TimeDeltaMicro, zero32, COMMON_BLOCK},\n\t{0, 0, 0}\n};\n\n// cache to be used while parsing a template\nstatic struct cache_s {\n\tstruct element_param_s {\n\t\tuint16_t index;\n\t\tuint16_t found;\n\t\tuint16_t length;\n\t}\t\t\t*lookup_info;\n\tstruct order_s {\n\t\tuint16_t type;\n\t\tuint16_t length;\n\t} *input_order;\n\tuint32_t\tinput_count;\n\tuint32_t\tmax_ipfix_elements;\n\tuint32_t\t*common_extensions;\n\t\n} cache;\n\n// module limited globals\nstatic uint32_t\tprocessed_records;\n\n// externals\nextern int verbose;\nextern uint32_t Max_num_extensions;\nextern extension_descriptor_t extension_descriptor[];\nextern uint32_t default_sampling;\nextern uint32_t overwrite_sampling;\nextern uint32_t\texporter_sysid;\n\n// prototypes\nstatic void InsertStdSamplerOffset(FlowSource_t *fs, uint16_t id, uint16_t offset_std_sampler_interval, \n\tuint16_t offset_std_sampler_algorithm);\n\nstatic void InsertSampler(FlowSource_t *fs, exporter_ipfix_domain_t *exporter, int32_t id, uint16_t mode, uint32_t interval);\n\nstatic input_translation_t *add_translation_table(exporter_ipfix_domain_t *exporter, uint16_t id);\n\nstatic void remove_translation_table(FlowSource_t *fs, exporter_ipfix_domain_t *exporter, uint16_t id);\n\nstatic void remove_all_translation_tables(exporter_ipfix_domain_t *exporter);\n\nstatic exporter_ipfix_domain_t *GetExporter(FlowSource_t *fs, ipfix_header_t *ipfix_header);\n\nstatic uint32_t MapElement(uint16_t Type, uint16_t Length, uint32_t order);\n\nstatic void PushSequence(input_translation_t *table, uint16_t Type, uint32_t *offset, void *stack);\n\nstatic int compact_input_order(void);\n\nstatic int reorder_sequencer(input_translation_t *table);\n\nstatic void Process_ipfix_templates(exporter_ipfix_domain_t *exporter, void *flowset_header, uint32_t size_left, FlowSource_t *fs);\n\nstatic void Process_ipfix_template_add(exporter_ipfix_domain_t *exporter, void *DataPtr, uint32_t size_left, FlowSource_t *fs);\n\nstatic void Process_ipfix_template_withdraw(exporter_ipfix_domain_t *exporter, void *DataPtr, uint32_t size_left, FlowSource_t *fs);\n\nstatic void  Process_ipfix_option_data(exporter_ipfix_domain_t *exporter, void *data_flowset, FlowSource_t *fs);\n\nstatic void Process_ipfix_data(exporter_ipfix_domain_t *exporter, uint32_t ExportTime, void *data_flowset, FlowSource_t *fs, input_translation_t *table );\n\n#include \"inline.c\"\n#include \"nffile_inline.c\"\n\nint Init_IPFIX(void) {\nint i;\n\n\tcache.lookup_info\t    = (struct element_param_s *)calloc(65536, sizeof(struct element_param_s));\n\tcache.common_extensions = (uint32_t *)malloc((Max_num_extensions+1)*sizeof(uint32_t));\n\tif ( !cache.common_extensions || !cache.lookup_info ) {\n\t\tLogError(\"Process_ipfix: Panic! malloc(): %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\treturn 0;\n\t}\n\n\t// init the helper element table\n\tfor (i=1; ipfix_element_map[i].id != 0; i++ ) {\n\t\tuint32_t Type = ipfix_element_map[i].id;\n\t\t// multiple same type - save first index only\n\t\t// iterate through same Types afterwards\n\t\tif ( cache.lookup_info[Type].index == 0 ) \n\t\t\tcache.lookup_info[Type].index  = i;\n\t}\n\tcache.max_ipfix_elements = i;\n\tcache.input_order = NULL;\n\n\tLogError(\"Init IPFIX: Max number of IPFIX tags: %u\", cache.max_ipfix_elements);\n\n\treturn 1;\n\n} // End of Init_IPFIX\n\nstatic exporter_ipfix_domain_t *GetExporter(FlowSource_t *fs, ipfix_header_t *ipfix_header) {\n#define IP_STRING_LEN   40\nchar ipstr[IP_STRING_LEN];\nexporter_ipfix_domain_t **e = (exporter_ipfix_domain_t **)&(fs->exporter_data);\nuint32_t ObservationDomain = ntohl(ipfix_header->ObservationDomain);\n\n\twhile ( *e ) {\n\t\tif ( (*e)->info.id == ObservationDomain && (*e)->info.version == 10 && \n\t\t\t (*e)->info.ip.V6[0] == fs->ip.V6[0] && (*e)->info.ip.V6[1] == fs->ip.V6[1]) \n\t\t\treturn *e;\n\t\te = &((*e)->next);\n\t}\n\n\tif ( fs->sa_family == AF_INET ) {\n\t\tuint32_t _ip = htonl(fs->ip.V4);\n\t\tinet_ntop(AF_INET, &_ip, ipstr, sizeof(ipstr));\n\t} else if ( fs->sa_family == AF_INET6 ) {\n\t\tuint64_t _ip[2];\n\t\t_ip[0] = htonll(fs->ip.V6[0]);\n\t\t_ip[1] = htonll(fs->ip.V6[1]);\n\t\tinet_ntop(AF_INET6, &_ip, ipstr, sizeof(ipstr));\n\t} else {\n\t\tstrncpy(ipstr, \"<unknown>\", IP_STRING_LEN);\n\t}\n\n\t// nothing found\n\t*e = (exporter_ipfix_domain_t *)malloc(sizeof(exporter_ipfix_domain_t));\n\tif ( !(*e)) {\n\t\tLogError(\"Process_ipfix: Panic! malloc() %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\treturn NULL;\n\t}\n\tmemset((void *)(*e), 0, sizeof(exporter_ipfix_domain_t));\n\t(*e)->info.header.type  = ExporterInfoRecordType;\n\t(*e)->info.header.size  = sizeof(exporter_info_record_t);\n\t(*e)->info.id \t\t\t= ObservationDomain;\n\t(*e)->info.ip\t\t\t= fs->ip;\n\t(*e)->info.sa_family\t= fs->sa_family;\n\t(*e)->info.version \t\t= 10;\n\t(*e)->info.sysid\t \t= 0;\n\n\t(*e)->TemplateRecords \t= 0;\n\t(*e)->DataRecords \t \t= 0;\n\t(*e)->sequence_failure \t= 0;\n\t(*e)->padding_errors \t= 0;\n\t(*e)->next\t \t\t\t= NULL;\n\t(*e)->sampler \t\t\t= NULL;\n\n\tFlushInfoExporter(fs, &((*e)->info));\n\n\tdbg_printf(\"[%u] New exporter: SysID: %u, Observation domain %u from: %s\\n\", \n\t\tObservationDomain, (*e)->info.sysid, ObservationDomain, ipstr);\n\tLogInfo(\"Process_ipfix: New exporter: SysID: %u, Observation domain %u from: %s\\n\", \n\t\t(*e)->info.sysid, ObservationDomain, ipstr);\n\n\n\treturn (*e);\n\n} // End of GetExporter\n\nstatic uint32_t MapElement(uint16_t Type, uint16_t Length, uint32_t order) {\nint\tindex;\n\n\tcache.input_order[order].type\t= Type;\n\tcache.input_order[order].length\t= Length;\n\n\tindex = cache.lookup_info[Type].index;\n\tif ( index ) {\n\t\twhile ( index && ipfix_element_map[index].id == Type ) {\n\t\t\tif ( Length == ipfix_element_map[index].length ) {\n\t\t\t\tcache.lookup_info[Type].found  = 1;\n\t\t\t\tcache.lookup_info[Type].length = Length;\n\t\t\t\tcache.lookup_info[Type].index  = index;\n\t\t\t\tdbg_printf(\"found extension %u for type: %u, input length: %u output length: %u Extension: %u\\n\", \n\t\t\t\t\tipfix_element_map[index].extension, ipfix_element_map[index].id, \n\t\t\t\t\tipfix_element_map[index].length, ipfix_element_map[index].out_length, ipfix_element_map[index].extension);\n\t\t\t\treturn ipfix_element_map[index].extension;\n\t\t\t}\n\t\t\tindex++;\n\t\t}\n\t\tdbg_printf(\"Skip known element type: %u, Unknown length: %u\\n\", Type, Length);\n\t} else {\n\t\tdbg_printf(\"Skip unknown element type: %u, Length: %u\\n\", Type, Length);\n\t}\n\n\tcache.input_order[order].type = SKIP_ELEMENT;\n\treturn 0;\n\n} // End of MapElement\n\nstatic input_translation_t *GetTranslationTable(exporter_ipfix_domain_t *exporter, uint16_t id) {\ninput_translation_t *table;\n\n\tif ( exporter->current_table && ( exporter->current_table->id == id ) )\n\t\treturn exporter->current_table;\n\n\ttable = exporter->input_translation_table;\n\twhile ( table ) {\n\t\tif ( table->id == id ) {\n\t\t\texporter->current_table = table;\n\t\t\treturn table;\n\t\t}\n\n\t\ttable = table->next;\n\t}\n\n\tdbg_printf(\"[%u] Get translation table %u: %s\\n\", exporter->info.id, id, table == NULL ? \"not found\" : \"found\");\n\n\texporter->current_table = table;\n\treturn table;\n\n} // End of GetTranslationTable\n\nstatic input_translation_t *add_translation_table(exporter_ipfix_domain_t *exporter, uint16_t id) {\ninput_translation_t **table;\n\n\ttable = &(exporter->input_translation_table);\n\twhile ( *table ) {\n\t\ttable = &((*table)->next);\n\t}\n\n\t// Allocate enough space for all potential ipfix tags, which we support\n\t// so template refreshing may change the table size without danger of overflowing \n\t*table = calloc(1, sizeof(input_translation_t));\n\tif ( !(*table) ) {\n\t\t\tLogError(\"Process_ipfix: Panic! calloc() %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\treturn NULL;\n\t}\n\t(*table)->max_number_of_sequences = 0;\n\t(*table)->number_of_sequences \t  = 0;\n\t(*table)->sequence = NULL;\n\t(*table)->id   \t   = id;\n\t(*table)->next\t   = NULL;\n\n\tdbg_printf(\"[%u] Get new translation table %u\\n\", exporter->info.id, id);\n\n\treturn *table;\n\n} // End of add_translation_table\n\nstatic void remove_translation_table(FlowSource_t *fs, exporter_ipfix_domain_t *exporter, uint16_t id) {\ninput_translation_t *table, *parent;\n\n\tLogInfo(\"Process_ipfix: [%u] Withdraw template id: %i\", \n\t\t\texporter->info.id, id);\n\n\tparent = NULL;\n\ttable = exporter->input_translation_table;\n\twhile ( table && ( table->id != id ) ) {\n\t\tparent = table;\n\t\ttable = table->next;\n\t}\n\n\tif ( table == NULL ) {\n\t\tLogError(\"Process_ipfix: [%u] Withdraw template id: %i. translation table not found\", \n\t\t\t\texporter->info.id, id);\n\t\treturn;\n\t}\n\n\tdbg_printf(\"\\n[%u] Withdraw template ID: %u\\n\", exporter->info.id, table->id);\n\n\t// clear table cache, if this is the table to delete\n\tif (exporter->current_table == table)\n\t\texporter->current_table = NULL;\n\n\tif ( parent ) {\n\t\t// remove table from list\n\t\tparent->next = table->next;\n\t} else {\n\t\t// last table removed\n\t\texporter->input_translation_table = NULL;\n\t}\n\n\tRemoveExtensionMap(fs, table->extension_info.map);\n\tfree(table->sequence);\n\tfree(table->extension_info.map);\n\tfree(table);\n\n} // End of remove_translation_table\n\nstatic void remove_all_translation_tables(exporter_ipfix_domain_t *exporter) {\ninput_translation_t *table, *next;\n\n\tLogInfo(\"Process_ipfix: Withdraw all templates from observation domain %u\\n\", \n\t\texporter->info.id);\n\n\ttable = exporter->input_translation_table;\n\twhile ( table ) {\n\t\tnext = table->next;\n\n\t\tdbg_printf(\"\\n[%u] Withdraw template ID: %u\\n\", exporter->info.id, table->id);\n\n\t\tfree(table->sequence);\n\t\tfree(table->extension_info.map);\n\t\tfree(table);\n\n\t\ttable = next;\n\t}\n\n\t// clear references\n\texporter->input_translation_table = NULL;\n\texporter->current_table = NULL;\n\n} // End of remove_all_translation_tables\n\nstatic int CheckSequenceMap(input_translation_t *table) {\n\n\tif ( table->number_of_sequences < table->max_number_of_sequences )\n\t\treturn 1;\n\n\tdbg_printf(\"Extend sequence map %u -> \", table->max_number_of_sequences);\n\tvoid *p = realloc(table->sequence,  (table->max_number_of_sequences + 1) * sizeof(sequence_map_t));\n\tif ( !p ) {\n\t\tLogError(\"Process_ipfix: realloc() at %s line %d: %s\", \n\t\t\t__FILE__, __LINE__, strerror (errno));\n\t\tdbg_printf(\"\\nProcess_ipfix: realloc() at %s line %d: %s\", \n\t\t\t__FILE__, __LINE__, strerror (errno));\n\t\treturn 0;\n\t}\n\ttable->sequence = p;\n\ttable->max_number_of_sequences += 1;\n\tdbg_printf(\"%u\\n\", table->max_number_of_sequences);\n\treturn 1;\n\n} // End of CheckSequenceMap\n\nstatic void PushSequence(input_translation_t *table, uint16_t Type, uint32_t *offset, void *stack) {\nuint32_t i = table->number_of_sequences;\nuint32_t index = cache.lookup_info[Type].index;\n\n\tif ( !CheckSequenceMap(table) )\n\t\treturn;\n\n\ttable->sequence[i].skip_count = 0;\n\ttable->sequence[i].type = Type;\n\tif ( cache.lookup_info[Type].found ) {\n\t\t\ttable->sequence[i].id = ipfix_element_map[index].sequence;\n\t\t\ttable->sequence[i].output_offset = offset ? *offset : 0;\n\t\t\ttable->sequence[i].stack = stack;\n\t\t\ttable->sequence[i].input_length = cache.lookup_info[Type].length;\n\t} else {\n\t\t\ttable->sequence[i].id = ipfix_element_map[index].zero_sequence;\n\t\t\ttable->sequence[i].output_offset = offset ? *offset : 0;\n\t\t\ttable->sequence[i].stack = NULL;\n\t}\n\tdbg_printf(\"Push: sequence: %u, Type: %u, in length: %u, out length: %u, id: %u, out offset: %u\\n\",\n\t\ti, Type, ipfix_element_map[index].length, ipfix_element_map[index].out_length, \n\t\ttable->sequence[i].id, table->sequence[i].output_offset);\n\ttable->number_of_sequences++;\n\tif ( offset ) \n\t\t(*offset) += ipfix_element_map[index].out_length;\n\n} // End of PushSequence\n\nstatic int compact_input_order(void) {\nint i;\n\n\tdbg_printf(\"\\nCompacting element input order: %u elements\\n\", cache.input_count);\n\tfor ( i=0; i< cache.input_count; i++ ) {\n\t\tdbg_printf(\"%i: type: %u, length: %u\\n\", \n\t\t\ti, cache.input_order[i].type, cache.input_order[i].length);\n\t\t\n\t\tif ( (cache.input_order[i].type == SKIP_ELEMENT) && (cache.input_order[i].length == DYN_FIELD_LENGTH) ) {\n\t\t\tdbg_printf(\"Dynamic length field: %u\\n\", cache.input_order[i].type);\n\t\t\tcontinue;\n\t\t}\n\t\twhile ( (i+1) < cache.input_count &&\n\t\t\t(cache.input_order[i].type == SKIP_ELEMENT) && (cache.input_order[i].length != DYN_FIELD_LENGTH) &&\n\t\t\t(cache.input_order[i+1].type == SKIP_ELEMENT) && (cache.input_order[i+1].length != DYN_FIELD_LENGTH)) {\n\t\t\t// merge multiple skipped fix length elements into 1 hole sequence\n\t\t\t\tint j;\n\t\t\t\tdbg_printf(\"%i: type: %u, length: %u\\n\", \n\t\t\t\t\ti+1, cache.input_order[i+1].type, cache.input_order[i+1].length);\n\t\t\t\tdbg_printf(\"Merge order %u and %u\\n\", i, i+1);\n\t\t\t\t// type set 0 to mark skip sequence\n\t\t\t\tcache.input_order[i].type = SKIP_ELEMENT;\n\t\t\t\tcache.input_order[i].length += cache.input_order[i+1].length;\n\t\t\n\t\t\t\t// shift up lower entries - fill \n\t\t\t\tfor ( j=i+1; (j+1)<cache.input_count; j++) {\n\t\t\t\t\tcache.input_order[j] = cache.input_order[j+1];\n\t\t\t\t}\n\t\t\t\tcache.input_count--;\n\t\t}\n\t}\n\n#ifdef DEVEL\n\tprintf(\"\\nCompacted input order table: count: %u\\n\", cache.input_count);\n\tfor ( i=0; i< cache.input_count; i++ ) {\n\t\tdbg_printf(\"%i: Type: %u, Length: %u\\n\", \n\t\t\ti, cache.input_order[i].type, cache.input_order[i].length);\n\t}\n\tprintf(\"\\n\");\n#endif\n\n\t// check for common input fields\n\tfor ( i=0; i< cache.input_count; i++ ) {\n\t\tif ( cache.input_order[i].type != SKIP_ELEMENT ) \n\t\t\t// common input field in table\n\t\t\treturn 1;\n\t}\n\t// if we skip all input fields \n\treturn 0;\n\n} // End of compact_input_order\n\nstatic int reorder_sequencer(input_translation_t *table) {\nint i, n;\nsequence_map_t *sequence = table->sequence;\n\n#ifdef DEVEL\n\tprintf(\"\\nReorder Sequencer. Sequence steps: %u\\n\", table->number_of_sequences);\n\tfor ( i=0; i<table->number_of_sequences; i++ ) {\n\t\tprintf(\"Order: %i, Sequence: %u, Type: %u, Input length: %u, Output offset: %u, Skip Count: %u\\n\",\n\t\t\ti, sequence[i].id, sequence[i].type, sequence[i].input_length, \n\t\t\tsequence[i].output_offset, sequence[i].skip_count);\n\t}\n#endif\n\n\tn = 0;\t// index into sequencer table\n\t// reorder Sequencer steps, so they follow input order\n\t// insert skip counts if needed\n\tfor ( i=0; i<cache.input_count; i++ ) {\n\t\tif ( cache.input_order[i].type == SKIP_ELEMENT ) {\n\t\t\t// skip dyn length or no previous slot in sequence map\n\t\t\tif ( cache.input_order[i].length == DYN_FIELD_LENGTH || n == 0 ) {\n\t\t\t\tint j;\n\t\t\t\t// insert skip sequence \n\n\t\t\t\tif ( !CheckSequenceMap(table) )\n\t\t\t\t\treturn 0;\n\n\t\t\t\t// make room for new sequence - shift down slots\n\t\t\t\tfor ( j=table->number_of_sequences-1; j>=n; j-- ) {\n\t\t\t\t\tsequence[j+1] = sequence[j];\n\t\t\t\t}\n\n\t\t\t\t// slot n now available - create nop sequence with skip count\n\t\t\t\tif ( cache.input_order[i].length == DYN_FIELD_LENGTH ) {\n\t\t\t\t\tsequence[n].id = dyn_skip;\n\t\t\t\t\tsequence[n].skip_count = 0;\n\t\t\t\t} else {\n\t\t\t\t\tsequence[n].id = nop;\n\t\t\t\t\tsequence[n].skip_count = cache.input_order[i].length;\n\t\t\t\t}\n\t\t\t\tsequence[n].type = SKIP_ELEMENT;\n\t\t\t\tsequence[n].input_length = 0;\n\t\t\t\tsequence[n].stack = NULL;\n\t\t\t\ttable->number_of_sequences++;\n\t\t\t\tdbg_printf(\"Insert skip sequence in slot: %u, skip count: %u, dyn: %u\\n\", \n\t\t\t\t\tn, sequence[n].skip_count, cache.input_order[i].length == DYN_FIELD_LENGTH ? 1 : 0);\n\t\t\t} else {\n\t\t\t\tsequence[n-1].skip_count += cache.input_order[i].length;\n\t\t\t\tdbg_printf(\"Merge skip count: %u into previous sequence: %u\\n\", cache.input_order[i].length, n-1);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\t// reorder input element if needed\n\t\t\tif ( sequence[n].type != cache.input_order[i].type ) {\n\t\t\t\tsequence_map_t _s;\n\t\t\t\tint j = n+1;\n\n\t\t\t\twhile ( sequence[j].type != cache.input_order[i].type && j < table->number_of_sequences )\n\t\t\t\t\tj++;\n\n\t\t\t\t// must never happen!\n\t\t\t\tif ( j == table->number_of_sequences ) {\n\t\t\t\t\t// skip this field\n\t\t\t\t\tif ( n == 0 ) {\n\t\t\t\t\t\t// XXX fix this\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsequence[n-1].skip_count += cache.input_order[i].length;\n\t\t\t\t\t\tdbg_printf(\"Merge skip count: %u into previous sequence: %u\\n\", cache.input_order[i].length, n-1);\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\t// swap slots\n\t\t\t\t_s = sequence[n];\n\t\t\t\tsequence[n] = sequence[j];\n\t\t\t\tsequence[j] = _s;\n\t\t\t\tdbg_printf(\"Swap slots %u <-> %u\\n\", n, j);\n\t\t\t} else {\n\t\t\t\tdbg_printf(\"In order slot %u\\n\", n);\n\t\t\t}\n\t\t}\n\t\t// advance sequence slot\n\t\tn++;\n\t}\n\n#ifdef DEVEL\n\tprintf(\"\\nReordered Sequencer. Sequence steps: %u\\n\", table->number_of_sequences);\n\tfor ( int i=0; i<table->number_of_sequences; i++ ) {\n\t\tprintf(\"Order: %i, Sequence: %u, Type: %u, Input length: %u, Output offset: %u, Skip Count: %u\\n\",\n\t\t\ti, sequence[i].id, sequence[i].type, sequence[i].input_length, \n\t\t\tsequence[i].output_offset, sequence[i].skip_count);\n\t}\n\tprintf(\"\\n\");\n#endif\n\n\treturn 1;\n\n} // End of reorder_sequencer\n\nstatic input_translation_t *setup_translation_table (exporter_ipfix_domain_t *exporter, uint16_t id) {\ninput_translation_t *table;\nextension_map_t \t*extension_map;\nuint32_t\t\t\ti, ipv6, offset, next_extension;\nsize_t\t\t\t\tsize_required;\n\n\tipv6 = 0;\n\n\ttable = GetTranslationTable(exporter, id);\n\tif ( !table ) {\n\t\tLogInfo(\"Process_ipfix: [%u] Add template %u\", exporter->info.id, id);\n\t\ttable = add_translation_table(exporter, id);\n\t\tif ( !table ) {\n\t\t\treturn NULL;\n\t\t}\n\t\t// Add an extension map\n\t\t// The number of extensions for this template is currently unknown\n\t\t// Allocate enough space for all configured extensions - some may be unused later\n\t\t// make sure memory is 4byte alligned\n\t\tsize_required = Max_num_extensions * sizeof(uint16_t) + sizeof(extension_map_t);\n\t\tsize_required = (size_required + 3) &~(size_t)3;\n\t\textension_map = malloc(size_required);\n\t\tif ( !extension_map ) {\n\t\t\tLogError(\"Process_ipfix: Panic! malloc() error in %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\treturn  NULL;\n\t\t}\n\t\textension_map->type \t   = ExtensionMapType;\n\t\t// Set size to an empty table - will be adapted later\n\t\textension_map->size \t   = sizeof(extension_map_t);\n\t\textension_map->map_id \t   = INIT_ID;\n\t\t// packed record size still unknown at this point - will be added later\n\t\textension_map->extension_size = 0;\n\n\t\ttable->extension_info.map \t = extension_map;\n\t\ttable->extension_map_changed = 1;\n\t\ttable->number_of_sequences \t = 0;\n \t} else {\n\t\textension_map = table->extension_info.map;\n\n\t\t// reset size/extension size - it's refreshed automatically\n\t\textension_map->size \t   \t  = sizeof(extension_map_t);\n\t\textension_map->extension_size = 0;\n\t\tfree((void *)table->sequence);\n\n\t\tdbg_printf(\"[%u] Refresh template %u\\n\", exporter->info.id, id);\n\t}\n\t// Add new sequence\n\ttable->sequence = calloc(cache.max_ipfix_elements, sizeof(sequence_map_t));\n\tif ( !table->sequence ) {\n\t\tLogError(\"Process_ipfix: Panic! malloc() error in %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\treturn  NULL;\n\t}\n\ttable->number_of_sequences = 0;\n\ttable->max_number_of_sequences = cache.max_ipfix_elements;\n\n\ttable->updated  \t= time(NULL);\n\t// IPFIX only has 64bit counters\n\ttable->flags\t\t\t= 0;\n\tSetFlag(table->flags, FLAG_PKG_64);\n\tSetFlag(table->flags, FLAG_BYTES_64);\n\ttable->delta_time\t\t= 0;\n\ttable->icmpTypeCodeIPv4\t= 0;\n\ttable->router_ip_offset = 0;\n\ttable->received_offset  = 0;\n\n\tdbg_printf(\"[%u] Build sequence table %u\\n\", exporter->info.id, id);\n\n\t// fill table\n\ttable->id \t\t\t= id;\n\n\t/* \n\t * common data block: The common record is expected in the output stream. If not available\n\t * in the template, fill values with 0\n\t */\n\n\t// All required extensions\n\t// The order we Push all ipfix elements, must corresponde to the structure of the common record\n\t// followed by all available extension in the extension map\n\toffset = BYTE_OFFSET_first;\n\tif ( cache.lookup_info[IPFIX_flowStartDeltaMicroseconds].found ) {\n\t\tPushSequence( table, IPFIX_flowStartDeltaMicroseconds, NULL, &table->flow_start);\n\t\tPushSequence( table, IPFIX_flowEndDeltaMicroseconds, NULL, &table->flow_end);\n\t\toffset = BYTE_OFFSET_first + 8;\n\t\ttable->delta_time = 1;\n\t\tdbg_printf(\"Time stamp: flow start/end delta microseconds: %u/%u\\n\",\n\t\t\tIPFIX_flowStartDeltaMicroseconds, IPFIX_flowEndDeltaMicroseconds);\n\t} else if ( cache.lookup_info[IPFIX_flowStartMilliseconds].found ) {\n\t\tPushSequence( table, IPFIX_flowStartMilliseconds, NULL, &table->flow_start);\n\t\tPushSequence( table, IPFIX_flowEndMilliseconds, NULL, &table->flow_end);\n\t\toffset = BYTE_OFFSET_first + 8;\n\t\tdbg_printf(\"Time stamp: flow start/end absolute milliseconds: %u/%u\\n\", \n\t\t\tIPFIX_flowStartMilliseconds, IPFIX_flowEndMilliseconds);\n\t} else if ( cache.lookup_info[IPFIX_flowStartSysUpTime].found ) {\n\t\tPushSequence( table, IPFIX_flowStartSysUpTime, NULL, &table->flow_start);\n\t\tPushSequence( table, IPFIX_flowEndSysUpTime, NULL, &table->flow_end);\n\t\toffset = BYTE_OFFSET_first + 8;\n\t\tdbg_printf(\"Time stamp: flow start/end relative milliseconds: %u/%u\\n\", \n\t\t\tIPFIX_flowStartSysUpTime, IPFIX_flowEndSysUpTime);\n\t} else if ( cache.lookup_info[IPFIX_flowStartSeconds].found ) {\n\t\tPushSequence( table, IPFIX_flowStartSeconds, NULL, &table->flow_start);\n\t\tPushSequence( table, IPFIX_flowEndSeconds, NULL, &table->flow_end);\n\t\toffset = BYTE_OFFSET_first + 8;\n\t\tdbg_printf(\"Time stamp: flow start/end absolute seconds: %u/%u\\n\", \n\t\t\tIPFIX_flowStartSeconds, IPFIX_flowEndSeconds);\n\t}else {\n\t\tdbg_printf(\"Time stamp: No known format found\\n\");\n\t\toffset = BYTE_OFFSET_first + 8;\n\t}\n\tPushSequence( table, IPFIX_forwardingStatus, &offset, NULL);\n\tPushSequence( table, IPFIX_tcpControlBits, &offset, NULL);\n\tPushSequence( table, IPFIX_protocolIdentifier, &offset, NULL);\n\tPushSequence( table, IPFIX_ipClassOfService, &offset, NULL);\n\n\tPushSequence( table, IPFIX_SourceTransportPort, &offset, NULL);\n\tPushSequence( table, IPFIX_DestinationTransportPort, &offset, NULL);\n\n\t// skip exporter_sysid and reserved\n\toffset += 4;\n\n\t/* IP address record\n\t * This record is expected in the output stream. If not available\n\t * in the template, assume empty v4 address.\n\t */\n\tif ( cache.lookup_info[IPFIX_SourceIPv4Address].found ) {\n\t\t// IPv4 addresses \n\t\tPushSequence( table, IPFIX_SourceIPv4Address, &offset, NULL);\n\t\tPushSequence( table, IPFIX_DestinationIPv4Address, &offset, NULL);\n\t} else if ( cache.lookup_info[IPFIX_SourceIPv6Address].found ) {\n\t\t// IPv6 addresses \n\t\tPushSequence( table, IPFIX_SourceIPv6Address, &offset, NULL);\n\t\tPushSequence( table, IPFIX_DestinationIPv6Address, &offset, NULL);\n\t\t// mark IPv6 \n\t\tSetFlag(table->flags, FLAG_IPV6_ADDR);\n\t\tipv6 = 1;\n\t} else {\n\t\t// should not happen, assume empty IPv4 addresses, zero\n\t\tPushSequence( table, IPFIX_SourceIPv4Address, &offset, NULL);\n\t\tPushSequence( table, IPFIX_DestinationIPv4Address, &offset, NULL);\n\t}\n\n\t// decide between Delta or Total  counters - prefer Total if available\n\tif ( cache.lookup_info[IPFIX_packetTotalCount].found )\n\t\tPushSequence( table, IPFIX_packetTotalCount, &offset, &table->packets);\n\telse\n\t\tPushSequence( table, IPFIX_packetDeltaCount, &offset, &table->packets);\n\tSetFlag(table->flags, FLAG_PKG_64);\n\n\tif ( cache.lookup_info[IPFIX_octetTotalCount].found )\n\t\tPushSequence( table, IPFIX_octetTotalCount, &offset, &table->bytes);\n\telse\n\t\tPushSequence( table, IPFIX_octetDeltaCount, &offset, &table->bytes);\n\tSetFlag(table->flags, FLAG_BYTES_64);\n\n\n\t// Optional extensions\n\tnext_extension = 0;\n\tfor (i=4; extension_descriptor[i].id; i++ ) {\n\t\tuint32_t map_index = i;\n\n\t\tif ( cache.common_extensions[i] == 0 )\n\t\t\tcontinue;\n\n\t\tswitch(i) {\n\t\t\tcase EX_IO_SNMP_2:\n\t\t\t\tPushSequence( table, IPFIX_ingressInterface, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_egressInterface, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_IO_SNMP_4:\n\t\t\t\tPushSequence( table, IPFIX_ingressInterface, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_egressInterface, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_AS_2:\n\t\t\t\tPushSequence( table, IPFIX_bgpSourceAsNumber, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_bgpDestinationAsNumber, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_AS_4:\n\t\t\t\tPushSequence( table, IPFIX_bgpSourceAsNumber, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_bgpDestinationAsNumber, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_MULIPLE:\n\t\t\t\tPushSequence( table, IPFIX_postIpClassOfService, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_flowDirection, &offset, NULL);\n\t\t\t\tif ( ipv6 ) {\n\t\t\t\t\t// IPv6\n\t\t\t\t\tPushSequence( table, IPFIX_SourceIPv6PrefixLength, &offset, NULL);\n\t\t\t\t\tPushSequence( table, IPFIX_DestinationIPv6PrefixLength, &offset, NULL);\n\t\t\t\t} else {\n\t\t\t\t\t// IPv4\n\t\t\t\t\tPushSequence( table, IPFIX_SourceIPv4PrefixLength, &offset, NULL);\n\t\t\t\t\tPushSequence( table, IPFIX_DestinationIPv4PrefixLength, &offset, NULL);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase EX_NEXT_HOP_v4:\n\t\t\t\tPushSequence( table, IPFIX_ipNextHopIPv4Address, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_NEXT_HOP_v6:\n\t\t\t\tPushSequence( table, IPFIX_ipNextHopIPv6Address, &offset, NULL);\n\t\t\t\tSetFlag(table->flags, FLAG_IPV6_NH);\n\t\t\t\tbreak;\n\t\t\tcase EX_NEXT_HOP_BGP_v4:\n\t\t\t\tPushSequence( table, IPFIX_bgpNextHopIPv4Address, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_NEXT_HOP_BGP_v6:\n\t\t\t\tPushSequence( table, IPFIX_bgpNextHopIPv6Address, &offset, NULL);\n\t\t\t\tSetFlag(table->flags, FLAG_IPV6_NHB);\n\t\t\t\tbreak;\n\t\t\tcase EX_VLAN:\n\t\t\t\tPushSequence( table, IPFIX_vlanId, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_postVlanId, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_OUT_PKG_4:\n\t\t\t\tPushSequence( table, IPFIX_postPacketDeltaCount, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_OUT_PKG_8:\n\t\t\t\tPushSequence( table, IPFIX_postPacketDeltaCount, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_OUT_BYTES_4:\n\t\t\t\tPushSequence( table, IPFIX_postOctetDeltaCount, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_OUT_BYTES_8:\n\t\t\t\tPushSequence( table, IPFIX_postOctetDeltaCount, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_AGGR_FLOWS_8:\n\t\t\t\tbreak;\n\t\t\tcase EX_MAC_1:\n\t\t\t\tPushSequence( table, IPFIX_SourceMacAddress, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_postDestinationMacAddress, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_MAC_2:\n\t\t\t\tPushSequence( table, IPFIX_DestinationMacAddress, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_postSourceMacAddress, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_MPLS:\n\t\t\t\tPushSequence( table, IPFIX_mplsTopLabelStackSection, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection2, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection3, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection4, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection5, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection6, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection7, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection8, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection9, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection10, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_ROUTER_IP_v4:\n\t\t\tcase EX_ROUTER_IP_v6:\n\t\t\t\tif ( exporter->info.sa_family == PF_INET6 ) {\n\t\t\t\t\ttable->router_ip_offset = offset;\n\t\t\t\t\tdbg_printf(\"Router IPv6: offset: %u, olen: %u\\n\", offset, 16 );\n\t\t\t\t\t// not an entry for the translateion table.\n\t\t\t\t\t// but reserve space in the output record for IPv6\n\t\t\t\t\toffset\t\t\t \t   += 16;\n\t\t\t\t\tSetFlag(table->flags, FLAG_IPV6_EXP);\n\t\t\t\t\tmap_index = EX_ROUTER_IP_v6;\n\t\t\t\t} else {\n\t\t\t\t\ttable->router_ip_offset = offset;\n\t\t\t\t\tdbg_printf(\"Router IPv4: offset: %u, olen: %u\\n\", offset, 4 );\n\t\t\t\t\t// not an entry for the translateion table.\n\t\t\t\t\t// but reserve space in the output record for IPv4\n\t\t\t\t\toffset\t\t\t\t   += 4;\n\t\t\t\t\tClearFlag(table->flags, FLAG_IPV6_EXP);\n\t\t\t\t\tmap_index = EX_ROUTER_IP_v4;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase EX_ROUTER_ID:\n\t\t\t\t// no value in ipfix \n\t\t\t\tbreak;\n\t\t\tcase EX_RECEIVED:\n\t\t\t\ttable->received_offset = offset;\n\t\t\t\tdbg_printf(\"Received offset: %u\\n\", offset);\n\t\t\t\toffset\t\t\t\t   += 8;\n\t\t\t\tbreak;\n\n\t\t}\n\t\textension_map->size += sizeof(uint16_t);\n\t\textension_map->extension_size += extension_descriptor[map_index].size;\n\n\n\t\t// found extension in map_index must be the same as in map - otherwise map is dirty\n\t\tif ( extension_map->ex_id[next_extension] != map_index ) {\n\t\t\t// dirty map - needs to be refreshed in output stream\n\t\t\textension_map->ex_id[next_extension] = map_index;\n\t\t\ttable->extension_map_changed = 1;\n\n\t\t}\n\t\tnext_extension++;\n\n\t}\n\textension_map->ex_id[next_extension++] = 0;\n\n\t// make sure map is aligned\n\tif ( extension_map->size & 0x3 ) {\n\t\textension_map->ex_id[next_extension] = 0;\n\t\textension_map->size = ( extension_map->size + 3 ) &~ 0x3;\n\t}\n \n\ttable->output_record_size = offset;\n\n\t// for netflow historical reason, ICMP type/code goes into dst port field\n\t// remember offset, for decoding\n\tif ( cache.lookup_info[IPFIX_icmpTypeCodeIPv4].found && cache.lookup_info[IPFIX_icmpTypeCodeIPv4].length == 2 ) {\n\t\tPushSequence( table, IPFIX_icmpTypeCodeIPv4, NULL, &table->icmpTypeCodeIPv4);\n\t}\n\n#ifdef DEVEL\n\tif ( table->extension_map_changed ) {\n\t\tprintf(\"Extension Map id=%u changed!\\n\", extension_map->map_id);\n\t} else {\n\t\tprintf(\"[%u] template %u unchanged\\n\", exporter->info.id, id);\n\t}\n\n\tprintf(\"Process_ipfix: Check extension map: id: %d, size: %u, extension_size: %u\\n\", \n\t\textension_map->map_id, extension_map->size, extension_map->extension_size);\n\t{ int i;\n\tfor (i=0; i<table->number_of_sequences; i++ ) {\n\t\tprintf(\"Sequence %i: id: %u, Type: %u, Length: %u, Output offset: %u, stack: %llu\\n\",\n\t\t\ti, table->sequence[i].id, table->sequence[i].type, table->sequence[i].input_length, \n\t\t\ttable->sequence[i].output_offset, (unsigned long long)table->sequence[i].stack);\n\t}\n\tprintf(\"Flags: 0x%x output record size: %u\\n\", table->flags, table->output_record_size); \n\t}\n\tPrintExtensionMap(extension_map);\n#endif\n\n\treturn table;\n\n} // End of setup_translation_table\n\nstatic void InsertStdSamplerOffset( FlowSource_t *fs, uint16_t id, uint16_t offset_std_sampler_interval, uint16_t offset_std_sampler_algorithm) {\noption_offset_t **t;\n\n\tt = &(fs->option_offset_table);\n\twhile ( *t ) {\n\t\tif ( (*t)->id == id ) { // table already known to us - update data\n\t\t\tdbg_printf(\"Found existing std sampling info in template %i\\n\", id);\n\t\t\tbreak;\n\t\t}\n\t\n\t\tt = &((*t)->next);\n\t}\n\n\tif ( *t == NULL ) { // new table\n\t\tdbg_printf(\"Allocate new std sampling info from template %i\\n\", id);\n\t\t*t = (option_offset_t *)calloc(1, sizeof(option_offset_t));\n\t\tif ( !*t ) {\n\t\t\tLogError(\"malloc() allocation error at %s line %u: %s\" , __FILE__, __LINE__, strerror (errno));\n\t\t\treturn ;\n\t\t} \n\t\tLogInfo(\"Process_v9: New std sampler: interval: %i, algorithm: %i\", \n\t\t\toffset_std_sampler_interval, offset_std_sampler_algorithm);\n\t}   // else existing table\n\n\tdbg_printf(\"Insert/Update sampling info from template %i\\n\", id);\n\tSetFlag((*t)->flags, HAS_STD_SAMPLER_DATA);\n\t(*t)->id\t\t\t\t= id;\n\t(*t)->offset_id\t\t\t= 0;\n\t(*t)->offset_mode\t\t= 0;\n\t(*t)->offset_interval\t= 0;\n\t(*t)->offset_std_sampler_interval   = offset_std_sampler_interval;\n\t(*t)->offset_std_sampler_algorithm  = offset_std_sampler_algorithm;\n\t\n} // End of InsertStdSamplerOffset\n\nstatic void InsertSampler(FlowSource_t *fs, exporter_ipfix_domain_t *exporter, int32_t id, uint16_t mode, uint32_t interval) {\ngeneric_sampler_t *sampler;\n\n\tdbg_printf(\"[%u] Insert Sampler: Exporter is 0x%llu\\n\", exporter->info.id, (long long unsigned)exporter);\n\tif ( !exporter->sampler ) {\n\t\t// no samplers so far \n\t\tsampler = (generic_sampler_t *)malloc(sizeof(generic_sampler_t));\n\t\tif ( !sampler ) {\n\t\t\tLogError( \"Process_v9: Panic! malloc(): %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\treturn;\n\t\t}\n\n\t\tsampler->info.header.type = SamplerInfoRecordype;\n\t\tsampler->info.header.size = sizeof(sampler_info_record_t);\n\t\tsampler->info.exporter_sysid = exporter->info.sysid;\n\t\tsampler->info.id\t   = id;\n\t\tsampler->info.mode\t = mode;\n\t\tsampler->info.interval = interval;\n\t\tsampler->next\t\t  = NULL;\n\t\texporter->sampler = sampler;\n\n\t\tFlushInfoSampler(fs, &(sampler->info));\n\t\tLogInfo( \"Add new sampler: ID: %i, mode: %u, interval: %u\\n\", \n\t\t\tid, mode, interval);\n\t\tdbg_printf(\"Add new sampler: ID: %i, mode: %u, interval: %u\\n\", \n\t\t\tid, mode, interval);\n\n\t} else {\n\t\tsampler = exporter->sampler;\n\t\twhile ( sampler ) {\n\t\t\t// test for update of existing sampler\n\t\t\tif ( sampler->info.id == id ) {\n\t\t\t\t// found same sampler id - update record\n\t\t\t\tdbg_printf(\"Update existing sampler id: %i, mode: %u, interval: %u\\n\", \n\t\t\t\t\tid, mode, interval);\n\n\t\t\t\t// we update only on changes\n\t\t\t\tif ( mode != sampler->info.mode || interval != sampler->info.interval ) {\n\t\t\t\t\tFlushInfoSampler(fs, &(sampler->info));\n\t\t\t\t\tsampler->info.mode\t = mode;\n\t\t\t\t\tsampler->info.interval = interval;\n\t\t\t\t\tLogInfo( \"Update existing sampler id: %i, mode: %u, interval: %u\\n\", \n\t\t\t\t\t\tid, mode, interval);\n\t\t\t\t} else {\n\t\t\t\t\tdbg_printf(\"Sampler unchanged!\\n\");\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// test for end of chain\n\t\t\tif ( sampler->next == NULL ) {\n\t\t\t\t// end of sampler chain - insert new sampler\n\t\t\t\tsampler->next = (generic_sampler_t *)malloc(sizeof(generic_sampler_t));\n\t\t\t\tif ( !sampler->next ) {\n\t\t\t\t\tLogError( \"Process_v9: Panic! malloc(): %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tsampler = sampler->next;\n\n\t\t\t\tsampler->info.header.type\t = SamplerInfoRecordype;\n\t\t\t\tsampler->info.header.size\t = sizeof(sampler_info_record_t);\n\t\t\t\tsampler->info.exporter_sysid = exporter->info.sysid;\n\t\t\t\tsampler->info.id\t   \t= id;\n\t\t\t\tsampler->info.mode\t\t= mode;\n\t\t\t\tsampler->info.interval\t= interval;\n\t\t\t\tsampler->next\t\t\t= NULL;\n\n\t\t\t\tFlushInfoSampler(fs, &(sampler->info));\n\n\t\t\t\tLogInfo( \"Append new sampler: ID: %u, mode: %u, interval: %u\\n\", \n\t\t\t\t\tid, mode, interval);\n\t\t\t\tdbg_printf(\"Append new sampler: ID: %u, mode: %u, interval: %u\\n\", \n\t\t\t\t\tid, mode, interval);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// advance\n\t\t\tsampler = sampler->next;\n\t\t}\n\t} \n\t\n} // End of InsertSampler\n\nstatic void Process_ipfix_templates(exporter_ipfix_domain_t *exporter, void *flowset_header, uint32_t size_left, FlowSource_t *fs) {\nipfix_template_record_t *ipfix_template_record;\nvoid *DataPtr;\nuint32_t count;\n\n\tsize_left \t   -= 4;\t// subtract message header\n\tDataPtr = flowset_header + 4;\n\n\tipfix_template_record = (ipfix_template_record_t *)DataPtr;\n\n\t// uint32_t\tid \t  = ntohs(ipfix_template_record->TemplateID);\n\tcount = ntohs(ipfix_template_record->FieldCount);\n\n\tif ( count == 0 ) {\n\t\t// withdraw template\n\t\tProcess_ipfix_template_withdraw(exporter, DataPtr, size_left, fs);\n\t} else {\n\t\t// refresh/add templates\n\t\tProcess_ipfix_template_add(exporter, DataPtr, size_left, fs);\n\t}\n\n} // End of Process_ipfix_templates\n\nstatic void Process_ipfix_template_add(exporter_ipfix_domain_t *exporter, void *DataPtr, uint32_t size_left, FlowSource_t *fs) {\ninput_translation_t *translation_table;\nipfix_template_record_t *ipfix_template_record;\nipfix_template_elements_std_t *NextElement;\nint i;\n\n\t// a template flowset can contain multiple records ( templates )\n\twhile ( size_left ) {\n\t\tuint32_t table_id, count, size_required;\n\t\tuint32_t num_extensions = 0;\n\n\t\tif ( size_left && size_left < 4 ) {\n\t\t\tLogError(\"Process_ipfix [%u] Template size error at %s line %u\" , \n\t\t\t\texporter->info.id, __FILE__, __LINE__, strerror (errno));\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// map next record.\n\t\tipfix_template_record = (ipfix_template_record_t *)DataPtr;\n\t\tsize_left \t\t-= 4;\n\n\t\ttable_id = ntohs(ipfix_template_record->TemplateID);\n\t\tcount\t = ntohs(ipfix_template_record->FieldCount);\n\n\t\tdbg_printf(\"\\n[%u] Template ID: %u\\n\", exporter->info.id, table_id);\n\t\tdbg_printf(\"FieldCount: %u buffersize: %u\\n\", count, size_left);\n\n\t\t// prepare\n\t\t// clear helper tables\n\t\tmemset((void *)cache.common_extensions, 0,  (Max_num_extensions+1)*sizeof(uint32_t));\n\t\tmemset((void *)cache.lookup_info, 0, 65536 * sizeof(struct element_param_s));\n\t\tfor (i=1; ipfix_element_map[i].id != 0; i++ ) {\n\t\t\tuint32_t Type = ipfix_element_map[i].id;\n\t\t\tif ( ipfix_element_map[i].id == ipfix_element_map[i-1].id )\n\t\t\t\tcontinue;\n\t\t\tcache.lookup_info[Type].index   = i;\n\t\t\t// other elements cleard be memset\n\t\t}\n\t\tcache.input_order = calloc(count, sizeof(struct order_s));\n\t\tif ( !cache.input_order ) {\n\t\t\tLogError(\"Process_ipfix: Panic! malloc(): %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tcache.input_count = count;\n\n\t\t// assume all elements in template are std elements. correct this value, if we find an enterprise element\n\t\tsize_required   = 4*count;\n\t\tif ( size_left < size_required ) {\n\t\t\t// if we fail this check, this flowset must be skipped.\n\t\t\tLogError(\"Process_ipfix: [%u] Not enough data for template elements! required: %i, left: %u\", \n\t\t\t\t\texporter->info.id, size_required, size_left);\n\t\t\tdbg_printf(\"ERROR: Not enough data for template elements! required: %i, left: %u\", size_required, size_left);\n\t\t\treturn;\n\t\t}\n\n\t\t// process all elements in this record\n\t\tNextElement \t = (ipfix_template_elements_std_t *)ipfix_template_record->elements;\n\t\tfor ( i=0; i<count; i++ ) {\n\t\t\tuint16_t Type, Length;\n\t\t\tuint32_t ext_id;\n\t\t\tint Enterprise;\n\t\n\t\t\tType   = ntohs(NextElement->Type);\n\t\t\tLength = ntohs(NextElement->Length);\n\t\t\tEnterprise = Type & 0x8000 ? 1 : 0;\n\t\t\tType = Type & 0x7FFF;\n\n\t\t\text_id = MapElement(Type, Length, i);\n\n\t\t\t// do we store this extension? enabled != 0\n\t\t\t// more than 1 v9 tag may map to an extension - so count this extension once only\n\t\t\tif ( ext_id && extension_descriptor[ext_id].enabled ) {\n\t\t\t\tif ( cache.common_extensions[ext_id] == 0 ) {\n\t\t\t\t\tcache.common_extensions[ext_id] = 1;\n\t\t\t\t\tnum_extensions++;\n\t\t\t\t}\n\t\t\t} \n\t\n\t\t\tif ( Enterprise ) {\n\t\t\t\tipfix_template_elements_e_t *e = (ipfix_template_elements_e_t *)NextElement;\n\t\t\t\tsize_required += 4;\t// ad 4 for enterprise value\n\t\t\t\tif ( size_left < size_required ) {\n\t\t\t\t\tLogError(\"Process_ipfix: [%u] Not enough data for template elements! required: %i, left: %u\", \n\t\t\t\t\t\t\texporter->info.id, size_required, size_left);\n\t\t\t\t\tdbg_printf(\"ERROR: Not enough data for template elements! required: %i, left: %u\", size_required, size_left);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif ( ntohl(e->EnterpriseNumber) == IPFIX_ReverseInformationElement ) {\n\t\t\t\t\tdbg_printf(\" [%i] Enterprise: 1, Type: %u, Length %u Reverse Information Element: %u\\n\", i, Type, Length, ntohl(e->EnterpriseNumber));\n\t\t\t\t} else {\n\t\t\t\t\tdbg_printf(\" [%i] Enterprise: 1, Type: %u, Length %u EnterpriseNumber: %u\\n\", i, Type, Length, ntohl(e->EnterpriseNumber));\n\t\t\t\t}\n\t\t\t\te++;\n\t\t\t\tNextElement = (ipfix_template_elements_std_t *)e;\n\t\t\t} else {\n\t\t\t\tdbg_printf(\" [%i] Enterprise: 0, Type: %u, Length %u\\n\", i, Type, Length);\n\t\t\t\tNextElement++;\n\t\t\t}\n\t\t}\n\n\t\tdbg_printf(\"Processed: %u\\n\", size_required);\n\n\t\t// compact input order and reorder sequencer\n\t\tif ( compact_input_order() ) {\n\t\t\t// valid template with common inout fields\n\n\t\t\t// as the router IP address extension is not part announced in a template, we need to deal with it here\n\t\t\tif ( extension_descriptor[EX_ROUTER_IP_v4].enabled ) {\n\t\t\t\tif ( cache.common_extensions[EX_ROUTER_IP_v4] == 0 ) {\n\t\t\t\t\tcache.common_extensions[EX_ROUTER_IP_v4] = 1;\n\t\t\t\t\tnum_extensions++;\n\t\t\t\t}\n\t\t\t\tdbg_printf(\"Add sending router IP address (%s) => Extension: %u\\n\", \n\t\t\t\t\tfs->sa_family == PF_INET6 ? \"ipv6\" : \"ipv4\", EX_ROUTER_IP_v4);\n\t\t\t}\n\t\n\t\t\t// XXX for now, we do not store router ID in IPFIX\n\t\t\textension_descriptor[EX_ROUTER_ID].enabled = 0;\n\n/*\t\n\t\t// as the router IP address extension is not part announced in a template, we need to deal with it here\n\t\tif ( extension_descriptor[EX_ROUTER_ID].enabled ) {\n\t\t\tif ( cache.common_extensions[EX_ROUTER_ID] == 0 ) {\n\t\t\t\tcache.common_extensions[EX_ROUTER_ID] = 1;\n\t\t\t\tnum_extensions++;\n\t\t\t}\n\t\t\tdbg_printf(\"Force add router ID (engine type/ID), Extension: %u\\n\", EX_ROUTER_ID);\n\t\t}\n*/\n\t\t\t// received time \n\t\t\tif ( extension_descriptor[EX_RECEIVED].enabled ) {\n\t\t\t\tif ( cache.common_extensions[EX_RECEIVED] == 0 ) {\n\t\t\t\t\tcache.common_extensions[EX_RECEIVED] = 1;\n\t\t\t\t\tnum_extensions++;\n\t\t\t\t}\n\t\t\t\tdbg_printf(\"Force add packet received time, Extension: %u\\n\", EX_RECEIVED);\n\t\t\t}\n\n#ifdef DEVEL\n\t\t{\n\t\t\tint i;\n\t\t\tfor (i=4; extension_descriptor[i].id; i++ ) {\n\t\t\t\tif ( cache.common_extensions[i] ) {\n\t\t\t\t\tprintf(\"Enabled extension: %i\\n\", i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n#endif\n\t\n\t\t\ttranslation_table = setup_translation_table(exporter, table_id);\n\t\t\tif (translation_table->extension_map_changed ) {\n\t\t\t\t// refresh he map in the ouput buffer\n\t\t\t\tdbg_printf(\"Translation Table changed! Add extension map ID: %i\\n\", translation_table->extension_info.map->map_id);\n\t\t\t\tAddExtensionMap(fs, translation_table->extension_info.map);\n\t\t\t\ttranslation_table->extension_map_changed = 0;\n\t\t\t\tdbg_printf(\"Translation Table added! map ID: %i\\n\", translation_table->extension_info.map->map_id);\n\t\t\t}\n\t\n\t\t\tif ( !reorder_sequencer(translation_table) ) {\n\t\t\t\tLogError(\"Process_ipfix: [%u] Failed to reorder sequencer. Remove table id: %u\", \n\t\t\t\t\t\t\texporter->info.id, table_id);\n\t\t\t\tremove_translation_table(fs, exporter, table_id);\n\t\t\t}\n\t\t} else {\n\t\t\tdbg_printf(\"Template does not contain any common fields - skip\\n\");\n\t\t}\n\t\t// update size left of this flowset\n\t\tsize_left -= size_required;\n\t\tDataPtr = DataPtr + size_required+4;\t// +4 for header\n\t\tif ( size_left < 4 ) {\n\t\t\t// pading\n\t\t\tdbg_printf(\"Skip %u bytes padding\\n\", size_left);\n\t\t\tsize_left = 0;\n\t\t}\n\t\tfree(cache.input_order);\n\t\tcache.input_order = NULL;\n\t}\n\n} // End of Process_ipfix_template_add\n\nstatic void Process_ipfix_template_withdraw(exporter_ipfix_domain_t *exporter, void *DataPtr, uint32_t size_left, FlowSource_t *fs) {\nipfix_template_record_t *ipfix_template_record;\n\n\t// a template flowset can contain multiple records ( templates )\n\twhile ( size_left ) {\n\t\tuint32_t id;\n\n\t\t// map next record.\n\t\tipfix_template_record = (ipfix_template_record_t *)DataPtr;\n\t\tsize_left \t\t-= 4;\n\n\t\tid \t  = ntohs(ipfix_template_record->TemplateID);\n\t\t// count = ntohs(ipfix_template_record->FieldCount);\n\n\t\tif ( id == IPFIX_TEMPLATE_FLOWSET_ID ) {\n\t\t\t// withdraw all templates\n\t\t\tremove_all_translation_tables(exporter);\n\t\t\tReInitExtensionMapList(fs);\n\t\t} else {\n\t\t\tremove_translation_table(fs, exporter, id);\n\t\t}\n\n\t\tDataPtr = DataPtr + 4;\n\t\tif ( size_left < 4 ) {\n\t\t\t// pading\n\t\t\tdbg_printf(\"Skip %u bytes padding\\n\", size_left);\n\t\t\tsize_left = 0;\n\t\t}\n\t}\n \n} // End of Process_ipfix_template_withdraw\n\nstatic void Process_ipfix_option_templates(exporter_ipfix_domain_t *exporter, void *option_template_flowset, FlowSource_t *fs) {\nuint8_t\t\t*DataPtr;\nuint32_t\tsize_left, size_required, i;\n// uint32_t nr_scopes, nr_options;\nuint16_t\tid, field_count, scope_field_count, offset;\nuint16_t\toffset_std_sampler_interval, offset_std_sampler_algorithm, found_std_sampling;\n\n\ti = 0;\t// keep compiler happy\n\tsize_left \t\t  = GET_FLOWSET_LENGTH(option_template_flowset) - 4; // -4 for flowset header -> id and length\n\tif ( size_left < 6 ) {\n\t\tLogError(\"Process_ipfix: [%u] option template length error: size left %u too small for an options template\", \n\t\t\texporter->info.id, size_left);\n\t\treturn;\n\t}\n\n\tDataPtr   \t\t  = option_template_flowset + 4;\n\tid \t  \t\t\t  = GET_OPTION_TEMPLATE_ID(DataPtr); \n\tfield_count \t  = GET_OPTION_TEMPLATE_FIELD_COUNT(DataPtr);\n\tscope_field_count = GET_OPTION_TEMPLATE_SCOPE_FIELD_COUNT(DataPtr);\n\tDataPtr   += 6;\n\tsize_left -= 6;\n\n\tdbg_printf(\"Decode Option Template. id: %u, field count: %u, scope field count: %u\\n\",\n\t\tid, field_count, scope_field_count);\n\n\tif ( scope_field_count == 0  ) {\n\t\tLogError(\"Process_ipfx: [%u] scope field count error: length must not be zero\", \n\t\t\texporter->info.id);\n\t\tdbg_printf(\"scope field count error: length must not be zero\\n\");\n\t\treturn;\n\t}\n\n\tsize_required = 2 * field_count * sizeof(uint16_t);\n\tdbg_printf(\"Size left: %u, size required: %u\\n\", size_left, size_required);\n\tif ( size_left < size_required ) {\n\t\tLogError(\"Process_ipfix: [%u] option template length error: size left %u too small for %u scopes length and %u options length\", \n\t\t\texporter->info.id, size_left, field_count, scope_field_count);\n\t\tdbg_printf(\"option template length error: size left %u too small for field_count %u\\n\", \n\t\t\tsize_left, field_count);\n\t\treturn;\n\t}\n\n\tif ( scope_field_count == 0  ) {\n\t\tLogError(\"Process_ipfxi: [%u] scope field count error: length must not be zero\", \n\t\t\texporter->info.id);\n\t\treturn;\n\t}\n\n\toffset_std_sampler_interval  = 0;\n\toffset_std_sampler_algorithm = 0;\n\tfound_std_sampling\t\t\t = 0;\n\toffset = 0;\n\n\tfor ( i=0; i<scope_field_count; i++ ) {\n\t\tuint16_t id, length;\n\t\tint Enterprise;\n\n\t\tif ( size_left && size_left < 4 ) {\n\t\t\tLogError(\"Process_ipfix [%u] Template size error at %s line %u\" , \n\t\t\t\texporter->info.id, __FILE__, __LINE__, strerror (errno));\n\t\t\treturn;\n\t\t}\n\t\tid \t   = Get_val16(DataPtr); DataPtr += 2;\n\t\tlength = Get_val16(DataPtr); DataPtr += 2;\n\t\tsize_left -= 4;\n\t\tEnterprise = id & 0x8000 ? 1 : 0;\n\t\tif ( Enterprise ) {\n\t\t\tsize_required += 4;\n\t\t\tif ( size_left < 4 ) {\n\t\t\t\tLogError(\"Process_ipfix: [%u] option template length error: size left %u too small\", \n\t\t\t\t\texporter->info.id, size_left);\n\t\t\t\tdbg_printf(\"option template length error: size left %u too small\\n\", size_left);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tDataPtr += 4;\n\t\t\tsize_left -= 4;\n\t\t\tdbg_printf(\" [%i] Enterprise: 1, scope id: %u, scope length %u enterprise value: %u\\n\", \n\t\t\t\ti, id, length, Get_val32(DataPtr));\n\t\t} else {\n\t\t\tdbg_printf(\" [%i] Enterprise: 0, scope id: %u, scope length %u\\n\", i, id, length);\n\t\t}\n\n\t\toffset += length;\n\t}\n\n\tfor ( ;i<field_count; i++ ) {\n\t\tuint32_t enterprise_value;\n\t\tuint16_t id, length;\n\t\tint Enterprise;\n\n\t\t// keep compiler happy\n\t\tUNUSED(enterprise_value);\n\t\tid \t   = Get_val16(DataPtr); DataPtr += 2;\n\t\tlength = Get_val16(DataPtr); DataPtr += 2;\n\t\tsize_left -= 4;\n\t\tEnterprise = id & 0x8000 ? 1 : 0;\n\t\tif ( Enterprise ) {\n\t\t\tsize_required += 4;\n\t\t\tif ( size_left < 4 ) {\n\t\t\t\tLogError(\"Process_ipfix: [%u] option template length error: size left %u too\", \n\t\t\t\t\texporter->info.id, size_left);\n\t\t\t\tdbg_printf(\"option template length error: size left %u too small\\n\", size_left);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tenterprise_value = Get_val32(DataPtr);\n\t\t\tDataPtr += 4;\n\t\t\tsize_left -= 4;\n\t\t\tdbg_printf(\" [%i] Enterprise: 1, option id: %u, option length %u enterprise value: %u\\n\", \n\t\t\t\ti, id, length, enterprise_value);\n\t\t} else {\n\t\t\tdbg_printf(\" [%i] Enterprise: 0, option id: %u, option length %u\\n\", i, id, length);\n\t\t}\n\n\t\tswitch (id) {\n\t\t\t// general sampling\n\t\t\tcase IPFIX_samplingInterval:\t\t// legacy #34\n\t\t\tcase IPFIX_samplingPacketInterval:\t// #305\n\t\t\t\tif ( length == 4 ) {\n\t\t\t\t\toffset_std_sampler_interval = offset;\n\t\t\t\t\tfound_std_sampling++;\n\t\t\t\t\tdbg_printf(\"\t4 byte sampling interval option at offset: %u\\n\", offset);\n\t\t\t\t} else {\n\t\t\t\t\tLogError(\"Process_ipfix: [%u] option template error: sampling option lenth != 4 bytes: %u\", \n\t\t\t\t\t\texporter->info.id, length);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase IPFIX_samplingAlgorithm:\t// legacy #35\n\t\t\tcase IPFIX_selectorAlgorithm:\t// #304\n\t\t\t\tif ( length == 1 ) {\n\t\t\t\t\toffset_std_sampler_algorithm = offset;\n\t\t\t\t\tdbg_printf(\"\t1 byte sampling algorithm option at offset: %u\\n\", offset);\n\t\t\t\t\tfound_std_sampling++;\n\t\t\t\t} else {\n\t\t\t\t\tLogError(\"Process_ipfix: [%u] option template error: algorithm option lenth != 1 byte: %u\", \n\t\t\t\t\t\texporter->info.id, length);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t}\n\n\t\toffset += length;\n\t}\n\n\tif ( offset_std_sampler_interval ) {\n        dbg_printf(\"[%u] Std sampling interval found. offset: %u\\n\", \n\t\t\texporter->info.id, offset_std_sampler_interval);\n\t\tif ( offset_std_sampler_algorithm )\n        \tdbg_printf(\"[%u] Std sampling algorithm found. offset: %u\\n\", \n\t\t\texporter->info.id, offset_std_sampler_algorithm);\n        InsertStdSamplerOffset(fs, id, offset_std_sampler_interval, offset_std_sampler_algorithm);\n\t\tdbg_printf(\"\\n\");\n\t}\n\n\tprocessed_records++;\n\n} // End of Process_ipfix_option_templates\n\n\nstatic void Process_ipfix_data(exporter_ipfix_domain_t *exporter, uint32_t ExportTime, void *data_flowset, FlowSource_t *fs, input_translation_t *table ){\nuint64_t\t\t\tsampling_rate;\nuint32_t\t\t\tsize_left;\nuint8_t\t\t\t\t*in, *out;\nint\t\t\t\t\ti;\nchar\t\t\t\t*string;\n\n\tsize_left = GET_FLOWSET_LENGTH(data_flowset) - 4; // -4 for data flowset header -> id and length\n\n\t// map input buffer as a byte array\n\tin  \t  = (uint8_t *)(data_flowset + 4);\t// skip flowset header\n\n\tdbg_printf(\"[%u] Process data flowset size: %u\\n\", exporter->info.id, size_left);\n\n\n\t// Check if sampling is announced\n\tsampling_rate = 1;\n\n\tgeneric_sampler_t *sampler = exporter->sampler;\n\twhile ( sampler && sampler->info.id != -1 ) \n\t\tsampler = sampler->next;\n\n\tif ( sampler ) {\n\t\tsampling_rate = sampler->info.interval;\n\t\tdbg_printf(\"[%u] Std sampling available for this flow source: Rate: %llu\\n\", exporter->info.id, (long long unsigned)sampling_rate);\n\t} else {\n\t\tsampling_rate = default_sampling;\n\t\tdbg_printf(\"[%u] No Sampling record found\\n\", exporter->info.id);\n\t}\n\n\tif ( overwrite_sampling > 0 )  {\n\t\tsampling_rate = overwrite_sampling;\n\t\tdbg_printf(\"[%u] Hard overwrite sampling rate: %llu\\n\", exporter->info.id, (long long unsigned)sampling_rate);\n\t} \n\n\tif ( sampling_rate != 1 )\n\t\tSetFlag(table->flags, FLAG_SAMPLED);\n\n\twhile (size_left) {\n\t\tint input_offset;\n\t\tcommon_record_t\t\t*data_record;\n\n\t\tif ( size_left < 4 ) {\t// rounding pads\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// check for enough space in output buffer\n\t\tif ( !CheckBufferSpace(fs->nffile, table->output_record_size) ) {\n\t\t\t// this should really never occur, because the buffer gets flushed ealier\n\t\t\tLogError(\"Process_ipfix: output buffer size error. Abort ipfix record processing\");\n\t\t\tdbg_printf(\"Process_ipfix: output buffer size error. Abort ipfix record processing\");\n\t\t\treturn;\n\t\t}\n\t\tprocessed_records++;\n\t\texporter->PacketSequence++;\n\n\t\t// map file record to output buffer\n\t\tdata_record\t= (common_record_t *)fs->nffile->buff_ptr;\n\t\t// map output buffer as a byte array\n\t\tout \t  = (uint8_t *)data_record;\n\n\t\tdbg_printf(\"[%u] Process data record: %u addr: %llu, buffer size_left: %u\\n\", \n\t\t\texporter->info.id, processed_records, (long long unsigned)((ptrdiff_t)in - (ptrdiff_t)data_flowset), \n\t\t\tsize_left);\n\n\t\t// fill the data record\n\t\tdata_record->flags \t\t    = table->flags;\n\t\tdata_record->size  \t\t    = table->output_record_size;\n\t\tdata_record->type  \t\t    = CommonRecordType;\n\t  \tdata_record->ext_map\t    = table->extension_info.map->map_id;\n\t\tdata_record->exporter_sysid = exporter->info.sysid;\n\t\tdata_record->reserved \t\t= 0;\n\n\t\ttable->flow_start \t\t    = 0;\n\t\ttable->flow_end \t\t    = 0;\n\t\ttable->packets \t\t  \t    = 0;\n\t\ttable->bytes \t\t  \t    = 0;\n\t\ttable->out_packets \t  \t    = 0;\n\t\ttable->out_bytes \t  \t    = 0;\n\n\t\tinput_offset = 0;\n\t\t// apply copy and processing sequence\n\t\tfor ( i=0; i<table->number_of_sequences; i++ ) {\n\t\t\tint output_offset = table->sequence[i].output_offset;\n\t\t\tvoid *stack = table->sequence[i].stack;\n\n\t\t\tif ( input_offset > size_left ) {\n\t\t\t\t// overrun\n\t\t\t\tLogError(\"Process ipfix: buffer overrun!! input_offset: %i > size left data buffer: %u\\n\", input_offset, size_left);\n\t\t\t\treturn;\n\t\t\t} \n\n\t\t\tswitch (table->sequence[i].id) {\n\t\t\t\tcase nop:\n\t\t\t\t\tbreak;\n\t\t\t\tcase dyn_skip: {\n\t\t\t\t\tuint16_t skip = in[input_offset];\n\t\t\t\t\tif ( skip < 255 ) {\n\t\t\t\t\t\tinput_offset += (skip+1);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tskip = Get_val16((void *)&in[input_offset+1]);\n\t\t\t\t\t\tinput_offset += (skip+3);\n\t\t\t\t\t}\n\t\t\t\t\t} break;\n\t\t\t\tcase move8:\n\t\t\t\t\tout[output_offset] = in[input_offset];\n\t\t\t\t\tbreak;\n\t\t\t\tcase move16:\n\t\t\t\t\t*((uint16_t *)&out[output_offset]) = Get_val16((void *)&in[input_offset]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase move32:\n\t\t\t\t\t*((uint32_t *)&out[output_offset]) = Get_val32((void *)&in[input_offset]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase move40:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\n\t\t\t\t\t\tt.val.val64 = Get_val40((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase move48:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t\tt.val.val64 = Get_val48((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase move56:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\n\t\t\t\t\t\tt.val.val64 = Get_val56((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase move64: \n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t\tt.val.val64 = Get_val64((void *)&in[input_offset]);\n\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t} break;\n\t\t\t\tcase move128: \n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t  \n\t\t\t\t\t\tt.val.val64 = Get_val64((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t  = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4])  = t.val.val32[1];\n\n\t\t\t\t\t\tt.val.val64 = Get_val64((void *)&in[input_offset+8]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+8])  = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+12]) = t.val.val32[1];\n\t\t\t\t\t} break;\n\t\t\t\tcase move32_sampling:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t\tt.val.val64 = Get_val32((void *)&in[input_offset]);\n\t\t\t\t\t\tt.val.val64 *= sampling_rate;\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t  \t*(uint64_t *)stack = t.val.val64;\n\t\t\t\t\t} break;\n\t\t\t\tcase move64_sampling:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t\tt.val.val64 = Get_val64((void *)&in[input_offset]);\n\n\t\t\t\t\t\tt.val.val64 *= sampling_rate;\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t  \t*(uint64_t *)stack = t.val.val64;\n\t\t\t\t\t} break;\n\t\t\t\tcase Time64Mili:\n\t\t\t\t\t{ uint64_t DateMiliseconds = Get_val64((void *)&in[input_offset]);\n\t\t\t\t\t  *(uint64_t *)stack = DateMiliseconds;\n\n\t\t\t\t\t} break;\n\t\t\t\tcase TimeUnix:\n\t\t\t\t\t{ uint64_t DateSeconds = Get_val32((void *)&in[input_offset]);\n\t\t\t\t\t  *(uint64_t *)stack = DateSeconds *1000LL;\n\n\t\t\t\t\t} break;\n\t\t\t\tcase TimeDeltaMicro:\n\t\t\t\t\t{ uint64_t DeltaMicroSec = Get_val32((void *)&in[input_offset]);\n\t\t\t\t\t  *(uint64_t *)stack = ((1000000LL * (uint64_t)ExportTime) - DeltaMicroSec) / 1000LL;\n\n\t\t\t\t\t} break;\n\t\t\t\tcase saveICMP:\n\t\t\t\t\t*(uint32_t *)stack = Get_val16((void *)&in[input_offset]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase move_mpls:\n\t\t\t\t\t*((uint32_t *)&out[output_offset]) = Get_val24((void *)&in[input_offset]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase move_flags: {\n\t\t\t\t\tuint16_t flags = Get_val16((void *)&in[input_offset]);\n\t\t\t\t\t// cut upper byte\n\t\t\t\t\tout[output_offset] = flags & 0xFF;\n\t\t\t\t\t} break;\n\t\t\t\tcase move_mac:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\n\t\t\t\t\t\tt.val.val64 = Get_val48((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset])   = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase zero8:\n\t\t\t\t\tout[output_offset] = 0;\n\t\t\t\t\tbreak;\n\t\t\t\tcase zero16:\n\t\t\t\t\t*((uint16_t *)&out[output_offset]) = 0;\n\t\t\t\t\tbreak;\n\t\t\t\tcase zero32:\n\t\t\t\t\t*((uint32_t *)&out[output_offset]) = 0;\n\t\t\t\t\tbreak;\n\t\t\t\tcase zero64: \n\t\t\t\t\t\t*((uint64_t *)&out[output_offset]) = 0;\n\t\t\t\t\t break;\n\t\t\t\tcase zero128: \n\t\t\t\t\t\t*((uint64_t *)&out[output_offset]) = 0;\n\t\t\t\t\t\t*((uint64_t *)&out[output_offset+8]) = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t\n\t\t\t\tdefault:\n\t\t\t\t\tLogError(\"Process_ipfix: Software bug! Unknown Sequence: %u. at %s line %d\", \n\t\t\t\t\t\ttable->sequence[i].id, __FILE__, __LINE__);\n\t\t\t\t\tdbg_printf(\"Software bug! Unknown Sequence: %u. at %s line %d\\n\", \n\t\t\t\t\t\ttable->sequence[i].id, __FILE__, __LINE__);\n\t\t\t}\n\t\t\tinput_offset += (table->sequence[i].input_length + table->sequence[i].skip_count);\n\t\t}\n\n\t\t// for netflow historical reason, ICMP type/code goes into dst port field\n\t\tif ( data_record->prot == IPPROTO_ICMP || data_record->prot == IPPROTO_ICMPV6 ) {\n\t\t\tif ( table->icmpTypeCodeIPv4 ) {\n\t\t\t\tdata_record->srcport = 0;\n\t\t\t\tdata_record->dstport = table->icmpTypeCodeIPv4;\n\t\t\t\t// data_record->dstport = Get_val16((void *)&in[table->ICMP_offset]);\n\t\t\t}\n\t\t}\n\n\t\t// check, if we need to store the packet received time\n\t\tif ( table->received_offset ) {\n\t\t\ttype_mask_t t;\n\t\t\tt.val.val64 = (uint64_t)((uint64_t)fs->received.tv_sec * 1000LL) + (uint64_t)((uint64_t)fs->received.tv_usec / 1000LL);\n\t\t\t\t*((uint32_t *)&out[table->received_offset])   = t.val.val32[0];\n\t\t\t\t*((uint32_t *)&out[table->received_offset+4]) = t.val.val32[1];\n\t\t}\n\n\t\t// split first/last time into epoch/msec values\n\t\tdata_record->first \t\t= table->flow_start / 1000;\n\t\tdata_record->msec_first = table->flow_start % 1000;\n\n\t\tdata_record->last \t\t= table->flow_end / 1000;\n\t\tdata_record->msec_last\t= table->flow_end % 1000;\n\n\t\t// update first_seen, last_seen\n\t\tif ( table->flow_start < fs->first_seen )\n\t\t\tfs->first_seen = table->flow_start;\n\t\tif ( table->flow_end > fs->last_seen )\n\t\t\tfs->last_seen = table->flow_end;\n\n\t\t// check if we need to record the router IP address\n\t\tif ( table->router_ip_offset ) {\n\t\t\tint output_offset = table->router_ip_offset;\n\t\t\tif ( exporter->info.sa_family == PF_INET6 ) {\n\t\t\t\t// 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs \n\t\t\t\ttype_mask_t t;\n\t\t\t\t\t  \n\t\t\t\tt.val.val64 = exporter->info.ip.V6[0];\n\t\t\t\t*((uint32_t *)&out[output_offset]) \t  = t.val.val32[0];\n\t\t\t\t*((uint32_t *)&out[output_offset+4])  = t.val.val32[1];\n\n\t\t\t\tt.val.val64 = exporter->info.ip.V6[1];\n\t\t\t\t*((uint32_t *)&out[output_offset+8])  = t.val.val32[0];\n\t\t\t\t*((uint32_t *)&out[output_offset+12]) = t.val.val32[1];\n\t\t\t} else {\n\t\t\t\t*((uint32_t *)&out[output_offset]) = exporter->info.ip.V4;\n\t\t\t}\n\t\t}\n\n\t\tswitch (data_record->prot ) { // switch protocol of\n\t\t\tcase IPPROTO_ICMP:\n\t\t\t\tfs->nffile->stat_record->numflows_icmp++;\n\t\t\t\tfs->nffile->stat_record->numpackets_icmp  += table->packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_icmp    += table->bytes;\n\t\t\t\tfs->nffile->stat_record->numpackets_icmp  += table->out_packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_icmp    += table->out_bytes;\n\t\t\t\tbreak;\n\t\t\tcase IPPROTO_TCP:\n\t\t\t\tfs->nffile->stat_record->numflows_tcp++;\n\t\t\t\tfs->nffile->stat_record->numpackets_tcp   += table->packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_tcp     += table->bytes;\n\t\t\t\tfs->nffile->stat_record->numpackets_tcp   += table->out_packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_tcp     += table->out_bytes;\n\t\t\t\tbreak;\n\t\t\tcase IPPROTO_UDP:\n\t\t\t\tfs->nffile->stat_record->numflows_udp++;\n\t\t\t\tfs->nffile->stat_record->numpackets_udp   += table->packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_udp     += table->bytes;\n\t\t\t\tfs->nffile->stat_record->numpackets_udp   += table->out_packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_udp     += table->out_bytes;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tfs->nffile->stat_record->numflows_other++;\n\t\t\t\tfs->nffile->stat_record->numpackets_other += table->packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_other   += table->bytes;\n\t\t\t\tfs->nffile->stat_record->numpackets_other += table->out_packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_other   += table->out_bytes;\n\t\t}\n\t\texporter->flows++;\n\t\tfs->nffile->stat_record->numflows++;\n\t\tfs->nffile->stat_record->numpackets\t+= table->packets;\n\t\tfs->nffile->stat_record->numbytes\t+= table->bytes;\n\t\tfs->nffile->stat_record->numpackets\t+= table->out_packets;\n\t\tfs->nffile->stat_record->numbytes\t+= table->out_bytes;\n\t\n\t\tif ( verbose ) {\n\t\t\tmaster_record_t master_record;\n\t\t\tmemset((void *)&master_record, 0, sizeof(master_record_t));\n\t\t\tExpandRecord_v2((common_record_t *)data_record, &(table->extension_info), &(exporter->info), &master_record);\n\t\t \tformat_file_block_record(&master_record, &string, 0);\n\t\t\tprintf(\"%s\\n\", string);\n\t\t}\n\n\t\tfs->nffile->block_header->size  += data_record->size;\n\t\tfs->nffile->block_header->NumRecords++;\n\t\tfs->nffile->buff_ptr\t= (common_record_t *)((pointer_addr_t)data_record + data_record->size);\n\n\t\t// advance input\n\t\tdbg_printf(\"Adjust input stream offset: %u\\n\", input_offset);\n\t\tif ( input_offset > size_left ) {\n\t\t\t// overrun\n\t\t\tLogError(\"Process ipfix: buffer overrun!! input_offset: %i > size left data buffer: %u\\n\", input_offset, size_left);\n\t\t\treturn;\n\t\t} \n\t\tsize_left \t\t   -= input_offset;\n\t\tin  \t  \t\t   += input_offset;\n\n\t\t// buffer size sanity check\n\t\tif ( fs->nffile->block_header->size  > BUFFSIZE ) {\n\t\t\t// should never happen\n\t\t\tLogError(\"### Software error ###: %s line %d\", __FILE__, __LINE__);\n\t\t\tLogError(\"Process ipfix: Output buffer overflow! Flush buffer and skip records.\");\n\t\t\tLogError(\"Buffer size: %u > %u\", fs->nffile->block_header->size, BUFFSIZE);\n\n\t\t\t// reset buffer\n\t\t\tfs->nffile->block_header->size \t\t= 0;\n\t\t\tfs->nffile->block_header->NumRecords = 0;\n\t\t\tfs->nffile->buff_ptr = (void *)((pointer_addr_t)fs->nffile->block_header + sizeof(data_block_header_t) );\n\t\t\treturn;\n\t\t}\n\n\t}\n\n} // End of Process_ipfix_data\n\nstatic void  Process_ipfix_option_data(exporter_ipfix_domain_t *exporter, void *data_flowset, FlowSource_t *fs) {\noption_offset_t *offset_table;\nuint32_t\tid;\nuint8_t\t *in;\n\n\tid  = GET_FLOWSET_ID(data_flowset);\n\n\toffset_table = fs->option_offset_table;\n\twhile ( offset_table && offset_table->id != id )\n\t\toffset_table = offset_table->next;\n\n\tif ( !offset_table ) {\n\t\t// should never happen - catch it anyway\n\t\tLogError( \"Process_ipfix: Panic! - No Offset table found! : %s line %d\", __FILE__, __LINE__);\n\t\treturn;\n\t}\n\n#ifdef DEVEL\n\tuint32_t size_left = GET_FLOWSET_LENGTH(data_flowset) - 4; // -4 for data flowset header -> id and length\n\tdbg_printf(\"[%u] Process option data flowset size: %u\\n\", exporter->info.id, size_left);\n#endif\n\n\t// map input buffer as a byte array\n\tin\t= (uint8_t *)(data_flowset + 4);  // skip flowset header\n\n\tif ( TestFlag(offset_table->flags, HAS_SAMPLER_DATA) ) {\n\t\tint32_t  id;\n\t\tuint16_t mode;\n\t\tuint32_t interval;\n\t\tif (offset_table->sampler_id_length == 2) {\n\t\t\tid = Get_val16((void *)&in[offset_table->offset_id]);\n\t\t} else {\n\t\t\tid = in[offset_table->offset_id];\n\t\t}\n\n\t\tmode = offset_table->offset_mode ? in[offset_table->offset_mode] : 0;\n\t\tinterval = Get_val32((void *)&in[offset_table->offset_interval]); \n\t\n\t\tInsertSampler(fs, exporter, id, mode, interval);\n\n\t\tdbg_printf(\"Extracted Sampler data:\\n\");\n\t\tdbg_printf(\"Sampler ID\t  : %u\\n\", id);\n\t\tdbg_printf(\"Sampler mode\t: %u\\n\", mode);\n\t\tdbg_printf(\"Sampler interval: %u\\n\", interval);\n\t}\n\n\tif ( TestFlag(offset_table->flags, HAS_STD_SAMPLER_DATA) ) {\n\t\tint32_t  id\t   = -1;\n\t\tuint16_t mode\t = offset_table->offset_std_sampler_algorithm ? in[offset_table->offset_std_sampler_algorithm] : 0;\n\t\tuint32_t interval = Get_val32((void *)&in[offset_table->offset_std_sampler_interval]);\n\n \t\tInsertSampler(fs, exporter, id, mode, interval);\n\n\t\tdbg_printf(\"Extracted Std Sampler data:\\n\");\n\t\tdbg_printf(\"Sampler ID\t   : %i\\n\", id);\n\t\tdbg_printf(\"Sampler algorithm: %u\\n\", mode);\n\t\tdbg_printf(\"Sampler interval : %u\\n\", interval);\n\n\t\tdbg_printf(\"Set std sampler: algorithm: %u, interval: %u\\n\", \n\t\t\t\tmode, interval);\n\t}\n\tprocessed_records++;\n\n} // End of Process_ipfix_option_data\n\nvoid Process_IPFIX(void *in_buff, ssize_t in_buff_cnt, FlowSource_t *fs) {\nexporter_ipfix_domain_t\t*exporter;\nssize_t\t\t\t\tsize_left;\nuint32_t\t\t\tExportTime, Sequence, flowset_length;\nipfix_header_t\t\t*ipfix_header;\nvoid\t\t\t\t*flowset_header;\n\n#ifdef DEVEL\nstatic uint32_t\t\tpacket_cntr = 0;\nuint32_t \t\t\tObservationDomain;\n#endif\n\n\tsize_left \t = in_buff_cnt;\n\tif ( size_left < IPFIX_HEADER_LENGTH ) {\n\t\tLogError(\"Process_ipfix: Too little data for ipfix packet: '%lli'\", (long long)size_left);\n\t\treturn;\n\t}\n\n\tipfix_header = (ipfix_header_t *)in_buff;\n\tExportTime \t\t\t = ntohl(ipfix_header->ExportTime);\n\tSequence \t\t\t = ntohl(ipfix_header->LastSequence);\n\n#ifdef DEVEL\n\tObservationDomain \t = ntohl(ipfix_header->ObservationDomain);\n\tpacket_cntr++;\n\tprintf(\"Next packet: %u\\n\", packet_cntr);\n#endif\n\n\texporter\t= GetExporter(fs, ipfix_header);\n\tif ( !exporter ) {\n\t\tLogError(\"Process_ipfix: Exporter NULL: Abort ipfix record processing\");\n\t\treturn;\n\t}\n\texporter->packets++;\n\t//exporter->PacketSequence = Sequence;\n\tflowset_header\t= (void *)ipfix_header + IPFIX_HEADER_LENGTH;\n\tsize_left \t   -= IPFIX_HEADER_LENGTH;\n\n\tdbg_printf(\"\\n[%u] process packet: %u, exported: %s, TemplateRecords: %llu, DataRecords: %llu, buffer: %li \\n\", \n\t\tObservationDomain, packet_cntr, UNIX2ISO(ExportTime), (long long unsigned)exporter->TemplateRecords, \n\t\t(long long unsigned)exporter->DataRecords, size_left);\n\n\tdbg_printf(\"[%u] Sequence: %u\\n\", ObservationDomain, Sequence);\n\n\t// sequence check\n\t// 2^32 wrap is handled automatically as both counters overflow\n\tif ( Sequence != exporter->PacketSequence ) {\n\t\tif ( exporter->DataRecords != 0 ) {\n\t\t\t// sync sequence on first data record without error report\n\t\t\tfs->nffile->stat_record->sequence_failure++;\n\t\t\texporter->sequence_failure++;\n\t\t\tdbg_printf(\"[%u] Sequence check failed: last seq: %u, seq %u\\n\", \n\t\t\t\texporter->info.id, Sequence, exporter->PacketSequence);\n\t\t\t/* maybee to noise on buggy exporters\n\t\t\tLogError(\"Process_ipfix [%u] Sequence error: last seq: %u, seq %u\\n\", \n\t\t\t\tinfo.id, exporter->LastSequence, Sequence);\n\t\t\t*/\n\t\t} else {\n\t\t\tdbg_printf(\"[%u] Sync Sequence: %u\\n\", exporter->info.id, Sequence);\n\t\t}\n\t\texporter->PacketSequence = Sequence;\n\t} else {\n\t\tdbg_printf(\"[%u] Sequence check ok\\n\", exporter->info.id);\n\t}\n\n\t// iterate over all set\n\tflowset_length = 0;\n\twhile (size_left) {\n\t\tuint16_t\tflowset_id;\n\n\t\tif ( size_left && size_left < 4 ) {\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tflowset_header = flowset_header + flowset_length;\n\n\t\tflowset_id \t\t= GET_FLOWSET_ID(flowset_header);\n\t\tflowset_length \t= GET_FLOWSET_LENGTH(flowset_header);\n\n\t\tdbg_printf(\"Process_ipfix: Next flowset id %u, length %u.\\n\", flowset_id, flowset_length);\n\n\t\tif ( flowset_length == 0 ) {\n\t\t\t/* \tthis should never happen, as 4 is an empty flowset \n\t\t\t\tand smaller is an illegal flowset anyway ...\n\t\t\t\tif it happends, we can't determine the next flowset, so skip the entire export packet\n\t\t\t */\n\t\t\tLogError(\"Process_ipfix: flowset zero length error.\");\n\t\t\tdbg_printf(\"Process_ipfix: flowset zero length error.\\n\");\n\t\t\treturn;\n\n\t\t}\n\n\t\t// possible padding\n\t\tif ( flowset_length <= 4 ) {\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif ( flowset_length > size_left ) {\n\t\t\tLogError(\"Process_ipfix: flowset length error. Expected bytes: %u > buffersize: %lli\", \n\t\t\t\tflowset_length, (long long)size_left);\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\n\t\tswitch (flowset_id) {\n\t\t\tcase IPFIX_TEMPLATE_FLOWSET_ID:\n\t\t\t\t// Process_ipfix_templates(exporter, flowset_header, fs);\n\t\t\t\texporter->TemplateRecords++;\n\t\t\t\tdbg_printf(\"Process template flowset, length: %u\\n\", flowset_length);\n\t\t\t\tProcess_ipfix_templates(exporter, flowset_header, flowset_length, fs);\n\t\t\t\tbreak;\n\t\t\tcase IPFIX_OPTIONS_FLOWSET_ID:\n\t\t\t\t// option_flowset = (option_template_flowset_t *)flowset_header;\n\t\t\t\texporter->TemplateRecords++;\n\t\t\t\tdbg_printf(\"Process option template flowset, length: %u\\n\", flowset_length);\n\t\t\t\tProcess_ipfix_option_templates(exporter, flowset_header, fs);\n\t\t\t\tbreak;\n\t\t\tdefault: {\n\t\t\t\tif ( flowset_id < IPFIX_MIN_RECORD_FLOWSET_ID ) {\n\t\t\t\t\tdbg_printf(\"Invalid flowset id: %u. Skip flowset\\n\", flowset_id);\n\t\t\t\t\tLogError(\"Process_ipfix: Invalid flowset id: %u. Skip flowset\", flowset_id);\n\t\t\t\t} else {\n\t\t\t\t\tinput_translation_t *table;\n\t\t\t\t\tdbg_printf(\"Process data flowset, length: %u\\n\", flowset_length);\n\t\t\t\t\ttable = GetTranslationTable(exporter, flowset_id);\n\t\t\t\t\tif ( table ) {\n\t\t\t\t\t\tProcess_ipfix_data(exporter, ExportTime, flowset_header, fs, table);\n\t\t\t\t\t\texporter->DataRecords++;\n\t\t\t\t\t} else if ( HasOptionTable(fs, flowset_id) ) {\n\t\t\t\t\t\tProcess_ipfix_option_data(exporter, flowset_header, fs);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// maybe a flowset with option data\n\t\t\t\t\t\tdbg_printf(\"Process ipfix: [%u] No table for id %u -> Skip record\\n\", \n\t\t\t\t\t\t\texporter->info.id, flowset_id);\n\t\t\t\t\t}\n\n\t\t\t\t}\n\t\t\t}\n\t\t} // End of switch\n\n\t\t// next record\n\t\tsize_left -= flowset_length;\n\n\t} // End of while\n\n} // End of Process_IPFIX\n\n"], "fixing_code": ["2019-07-25\n- Rework nfpcapd and add it officially to the nfdump collection.\n- Add nfpcapd man page\n- Fix potential unsigned integer underflow #171\n\n2019-07-16\n- Add latency extension if dumping flowcache\n\n2019-07-15\n- Fix typos\n- Fix exporter struct inconsistancies. Coredump on ARM otherwise.\n\n2019-07-02\n- Add ipfix element #150, #151 unix time start/end\n- Fix display bug raw record\n\n2019-06-01\n- Add ipfix dyn element handling.\n- Add empty m4 directory - keep autoconf happy\n\n2019-06-01\n- Fix issue #162 - ipfix mpls sequece.\n- Fix issue #156 - print flowtable index error\n\n2019-03-17\n- Fix spec file\n- Remove non thread safe logging in nfpcapd\n\n2018-11-24\n- Fix protocol tag for protocol 87 - TCF - #130\n- Add TCP flags ECN,CVR - #132\n- Fix some error messages to be printed to the correct stream #135\n- Add missing -M command line help to nfcapd\n- Remove padding byte warning in log #141\n- Fix bug to accept -y compression flag in nfcapd. - #145\n\n2018-06-24\n- Fix bookkeeper type - use key_t\n- Add multiple packet repeaters to nfcapd/sfcapd. Up to 8 repeaters (-R) can be defined.\n- Ignore OSX .DS_Store files in -R file list\n- Add CISCO ASA elements initiatorPackets (298) responderPackets (299)\n- Merge #120 pull request for -z parameter to nfreplay\n- Update man page nfreplay\n\n2018-05-06\n- New bookkeeper hash broke NfSen. Fixed. ported back to release 1.6.17\n\n2018-04-20\n- Release 1.6.17\n\n2018-04-20\n- Fix bug in sorting when guessing flow direction. Issue #92\n- Update nfdump.1 man page for xsrcport & xdstport aggregations. Request #109\n- Fix minor bugs\n- Fix definition for InfluxDB in configure.ac Issue #98\n\n2018-04-01\n- Add program exit in nfx.c after panic with correupt data file\n- Add missing size check when reading nfdump 1.5.x common record blocks\n- Add missing option -M in man page. Issue #103\n- Add Fix processing of influx URL in nfprofile\n\n2018-02-11\n- Add missing json output format in nfdump help text\n- Add missing -v option in nfreplay help text\n\n2018-01-06\n- Merge pull request #51 Influxdb from Luca. Thx for the patch\n\n2018-01-01\n- IPFIX time stamps - Fix elements #21,#22 offset calculation, but timestamps not yet evaluated. (#160)\n- IPFIX add fwd status tag #89 compatible to v9 (1byte)\n\n2017-12-31\n- IPFIX sampling - sampling algorithm no longer required for tag #34\n- IPFIX sampling add tags #305 and #304 - set them identical to #34, #35\n\n2017-12-30\n- Add new output format json. Print each record as individual json object\n\n2017-12-28\n- Add sampling elements ID 302,304,305. put them identical to ID 48,49,50\n- Add option to label filter terms. syntax: (<filter>) %labelname.\n- Add %lbl option to print flow label in output\n- Update nfdump(1) man page for flowlabels\n\n2017-12-27\n- Add ipfix delta timestamp elements 158/159. \n- Update sflow code to commit 7322984 of https://github.com/sflow/sflowtool\n- Cleanup sflow code - uncomment unnecessary code\n- Fix header includes\"\n- Fix 64bit fts compat issue in fts_compat.c\n- Add more detailed autogen.sh - softlink bootstrap\n\n2017-12-22\n- Fix potential memory leaks in nfpcapd\n\n2017-12-21\n- Fix wrong offset calculation if unknown options are found\n- Add x-late src/dst ip aggregation, if compiled with NSEL support\n\n2017-12-17\n- Add ipfix sampling. Process option template/record with sampling elements 34 and 35\n- Report updates on existing samplers in v9 only if values change. issue 84\n\n2017-11-05 v1.6.16\n\n2017-12-10\n- Add lz4 compression\n- Remove old xstat legancy code, not needed\n- Remove automake files from git\n\n2017-12-03\n- Fix old 1.6.15 tags\n- Fix minor issues and compiler warnings\n\n2017-10-22\n- Add support for CISCO IOS 8 bytes timestamps ID 21/22\n- Fix issue #72 - multiple stat output\n- Change -B behaviour as proposed in issue #59. Should not impact with previous use, but is more flexible\n- Add bzip compress switch in usage output of nfpcapd\n- Fix compile issues on some platforms\n- nfpcapd improvements - still beta software.\n- Minor bug fixes\n\n2016-11-25\n- Add latency extension to nfpcapd\n- Smaller bug fixes to nfpcapd\n\n2016-07-23\n- Replace unreliable _ftok with more reliable string hash\n\n2016-07-20\n- Aggregate using in+out bytes for bidirectional flows\n\n2016-06-05 v.1.6.15\n- Fix Security issue http://www.security-assessment.com/files/documents/advisory/Nfdump%20nfcapd%201.6.14%20-%20Multiple%20Vulnerabilities.pdf\n- Fix obyte, opps and obps output records\n- Fix wrong bps type case in cvs output. Fix opbs ipbs typos\n\n2016-01-10 v.1.6.14\n- Fix CentOS compile issues with flow-tools converter\n- Fix FreeBSD,OpenBSD build problems\n- Fix timestamp overflow in sflow.c\n\n2015-12-23\n- Fix IP Fragmentation in sflow collector\n- Create libnfdump for dynamic linking\n\n2015-10-02\n- Fix compile errors on other platforms\n- Add -R to ModifyCompression\n- Add std sampler ID 4 Bytes and allow random sampler (tag 50)\n- Add BZ2 compression along existing LZ0\n- Add direct write to flowtools converter ft2nfdump\n- Fix zero alignment bug, if only half of an extension is sent\n- Fix nfanon time window bug in subsequent files in -R list\n- Fix CommonRecordV0Type conversion bug\n- Fix nfexport bug, if only one single map exists\n\n2014-11-16 v.1.6.13\n- Fix v1 extension size bug\n- Add htonll check for autoconf\n- Fix AddExtensionMap compare bug\n- Fix ipfix templare withdraw problems - free all maps correctly\n- Add minilzo 2.08 - fixes CVE-2014-4607\n- Cleanup some stat code. more needs to be done ..\n- Cleanup man pages for -O -n\n- Remove SunPro test in configure - no longer supported anyway\n- Cleanup NAT/NSEL filter differences\n\n2014-06-15 v1.6.12p1\n- Add pblock compare functions\n- Update extended filter: Allow modification left/right values\n\n2014-02-16 v1.6.12\n- Add NAT pool port allocation\n- Modify/fix NAT vrf tags. Add egress vrf ID\n- Modify common record due to exporter exhaustion. new common record\n  type 10 adds 4 extra bytes. Reads v1 common record transparently\n- Fix sflow potential crash\n\n2013-11-13 v1.6.11\n- Add ASA/NSEL 9.x protcol changes\n- Make it llvm compilable\n \n2013-08-12 v1.6.10p1\n- Fix -t +/- n timeslot option\n- Fix bug in nfanon - stat record update.\n- Fix bug in netflow v5 mudule: extension map size wrong.\n- Fix bug nfexport: In some cases could result in wrong flow counter. \n- Fix nftrack - could coredump in some cases.\n\n2013-05-16 v1.6.10\n- Fix SPARC compile/optimise bug\n- Add output packet/bytes counter to global stat - importatnt for NSEL flows ASA > 8.5\n- Add NSEL filter options xnet\n- Modify extension descriptor code for nfdump1.7. Still use 1.6 extension map layout for compatibility\n- Add prototype for nfpcapd - pcap -> nfdump collector. Converts traffoc directly to nfdump files.\n- Fix bug in ipfix module: uninitialised variable\n- Cleanup syslog/LogError calls\n- Fix minor non critical bugs and compile issues\n\n2013-03-02 v1.6.9\n- Fix some bugs in beta 1.6.9 NSEL code\n- Fix bug statistics update with aggreagted flow records\n- Fix sflow bug sfcapd stores wrong (ghost) dump by past samples in same sflow datagram\n\n2012-12-31\n- Add time received in csv output\n- ICMP should handled better now - somewhat\n- Implement ASA NSEL records\n- Add definitions in nffile and nx for ASA NSEL extensions\n\n2012-11-09 v1.6.8p1\n- Add dynamic source directory tree for multiple exporters\n- Fix exporter bug: 'too many exporters' with large time windows\n- Fix uninitialised exporter sysid in default sampler record - v9\n- Fix v9/ipfix cache initialisation with no templates > 1 in same packet\n\n2012-10-26 v1.6.8\n- Add ip list option for 'next ip' in filter syntax\n- Accept v9 sampler_id in 2bytes\n- Fix IPFIX mac address bug - did not get collected\n- Add IPFIX packet/octet TotalCount fields 85/86\n- Add received timestamp to sflow collector\n- Fix long flow duration calculation - 32bit overflow\n- Fix v9 sampling ID: allow 2 byte ID\n- Add IPFIX options as rfc5101 section-6.2\n- Add exporter records for sflow collector\n- Fix bug for MAC address printing %idmc and %odmc.\n- Add received time stamp extension\n- Add recursive format parser. Allows to extend predefined formats.\n- Change flow record sorting to heapsort. remove limit 1000\n- Merge -m option to -O tstart. -m now depricated.\n- Add -O tend. Print order according to tend of flows ascending\n- Apply -O print order for printing flow cache. Applies to -A\n\n2012-07-31 v1.6.7-tc-1\n- Special version for TC\n- Print exporter and sampling records with nfdump -E\n- Added exporter and sampling records to file.\n\n2012-07-30 v1.6.7\n- Prepare for file catalog in current file format.\n- Fix bug in ReadBlock when reading flow from stdin pipe\n- Add new more flexible translation engine for v9\n- Add nprobe client/server delay fields\n- Prepare for NSEL merging\n- Fix memory corruption with double -A flags\n- Fix bug in nfreader with compat15 mode files\n\n2012-03-12 v1.6.6\n- Minor IPFIX bug.\n- IPFIX implement template withdraw\n- For IPFIX, check packet sequence per template and observation domain\n- Fix time window, when no flows collected or no flows matched\n  while processing\n- Fixed typos\n- Fix seg fault bug - test for EMPTY_LIST was missing at several places.\n\n2012-02-19 v1.6.6b1\n- Fix bps/pps. make it uint64_t, as bps/pps > 4Gb/s overflows.\n- In record raw print mode: decode ICMP instead of src/dst ports\n- sflow use announced exporter IP instead of sending IP for router ID\n- sflow: Ignore extra fill bytes. Do not complain.\n- sflow: fix packet length issue.\n- Add IPFIX protokoll support\n\n2011-12-31 v1.6.5\n- Fix 64bit bug when using byte/packet limits\n- for v5 and sampling use 64bit counters to prevent overflow for large sampled flows.\n- Fixed Ident printig bug\n\n2011-07-11 v1.6.4\n- some code restructuring - prepare for IPFIX module\n- Add netflow v1 module. Some routers still use that\n- Add %sn, %dn output tags for src/dst networks\n- Fix buffer length check in v5.\n- Fix export bug: include last flow cache bucket, when exporting\n- number in all filter expressions accept hex values\n- fix an sflow colletor bug. Missing extension maps in rotated files\n- implement extended statistics. Currently ports and bpp distribution\n  vectors can be collected automatically be nfcapd. Still experimental\n\n2011-02-26 v1.6.3p1\n- Fix timebug fix :(, make it a compile time option\n- fix v7 sequence errors\n\n2011-02-15\n- Zero out unused fields after aggregation\n\n2011-02-05\n- Fix SysUptime 32bit overflow in v5 header\n- Add fix for strange first/last swap reported by some users.\n\n2011-01-09 v1.6.3 \n- Fix extension size bug\n- Move IP anonymisation to separate binary nfanon\n- Fix initialise bug of -o fmt: and not available fields\n\n2010-09-09 v1.6.2 \n- released\n- fixes some sflow bugs in sfcapd\n\n2010-04-28 v1.6.1p0\n- Update flow tools converter to build with Google-Code version 0.68.5\n- Fix sflow bugs\n\n2010-03-05 v1.6.1\n- Fix bug in man page for -t\n- Test sampler infos before using them ( nfcapd startup )\n- Add sampling tags #34, #35 used by JunOS\n- nfexpire: Fix empty .nfsat, when setting limits on an empty directory\n- Fix coredump for -B -m (-w) combination\n- Optimise some extension map code\n\n2009-12-28 stable v1.6\n- Few bug fixes in release candidates rc1, rc2 and rc3\n\n2009-11-16 snapshot-1.6b-20091116\n- Update sflow collector with new tags\n- Add router IP extension\n- Add router ID (engine type/ID) extension\n\n2009-09-30 snapshot-1.6b-20090930\n- snapshot bugfix release\n\n2009-11-0801 snapshot-1.6b-20090806\n- Add srcmask and dstmask aggregation\n- Add csv output mode. -o csv\n- Fix some bugs of previous beta\n- Add bidirectional aggregation of flows ( -b, -B )\n- Add possibility to save aggregated flows into file ( -w )\n  Note: This results in a behaviour change for -w in combination\n  with aggragation )\n- Extend -N ( do not scale numbers ) to all text output not just summary\n- Make extension handling more robust for some moody IOSes.\n- Remove header lines of -s stat, when using -q ( quiet ) \n  Note: This results in a behaviour change for -N\n- Remove -S option from nfdump ( legacy 1.4 compatibility )\n- Make use of log (syslog) functions for nfprofile.\n- Move log functions to util.c\n\n2009-06-19 snapshot-1.6b-20090717\n- Flow-tools converter updated - supports more common elements.\n- Sflow collector updated. Supports more common elements.\n- Add sampling to nfdump. Sampling is automatically recognised\n  in v5 undocumented header fields and in v9 option templates.\n  see nfcapd.1(1)\n- Add @include option for filter to include more filter files.\n- Add flexible aggregation comparable to Flexible Netflow (FNF)\n- All new tags can be selected in -o fmt:... see nfdump(1)\n- topN stat for all new tags is implemented\n- Integrate developer code to read from pcap files into stable\n- Update filter syntax for new tags\n- Added more v9 tags for netflow v9.\n  The detailed tags are listed in nfcapd(1)\n  Adding new tags also extended the binary file format with\n  data block format 2, which is extension based. File format \n  for version <= 1.5.* ( Data block format 1 ) is read \n  transparently. Data block 2 are skipped by nfdump 1.5.7.\n  32bit but AS and interface numbers are supported.\n- Add flexible storage option for nfcapd. To save disk space, the \n  data extensions to be stored in the data file are user selectable.\n- Added option for multiple netflow stream to same port.\n  -n <Ident,IP,base_directory>\n  Example: -n router1,192.168.100.1,/var/nfdump/router1\n  So multiple -n options may be given at the command line\n  Old style syntax still works for compatibility, ( -I .. -l ... )\n  but then only one source is supported.\n- Move to automake for building nfdump\n- Switch scaling factor ( k, M, G ) from 1024 to 1000.\n- Make nfdump fully 64bit compliant. ( 8bit data alignments and access )\n\n2009-04-17 stable 1.5.8\n- Fix daylight summer time bug, when guessing sub dirs. file access ( -M, -r )\n- Bug fixes for 64bits CPUs\n\n2008-02-22 stable-1,5.7\n- Add icmp type/code decoding\n- Add proper icmp v9 decoding\n- Fix memory leaks in -e auto expire mode in nfcapd.\n- Fix somee potential dead locks with file locking, when expiring\n- Fix multicast bug in nfreplay\n- Add hostname lookup for IP addresses in filter.\n\n2007-10-15\tstable-1.5.6\n- Fix odd CISCO behaviour for ICMP type/code in src port.\n- Add fast LZO1X-1 compression option (-z) for output file.\n- Add lists for port in syntax -> port in [ 135 137 445]\n- Add lists for AS syntax -> as in [ 1024 1025 ]\n- Bug fix in filter for syntax 'src as and dst as' \n\n2007-08-24  stable-1.5.5\n- Fix nfprofile bug, nfprofile crashes when last opts line is not valid for \n  some reason.\n- Fix potential hand for nfexpire, on empty flow directories.\n\n2007-08-08  snapshot-20070808\n- Idents may contain '-' in name.\n- Fixed install bugs in Makefile.in and configure.in\n- Installs now cleanly on Solaris\n- Handle 4byte interface numbers in v9. Quick fix: 4bytes reduced to 2bytes.\n- Fix aggregation bug in statistics.\n- ftok(3) C library call replaced by more reliable own implementation. \n  Did result in error messages like \"Another collector is already running\" \n- Fix minor bugs iin file range selction -R.\n- Add recursive behaviour for -R <directory>\n- New option -i can canche Ident descriptor in data files.\n\n2007-03-12  snapshot-20070312\n- Bug fix release of 20070306\n\n2007-03-06  snapshot-20070306\n- Fix bug in flist.c. Resulted in a coredump when using sub dirs and -R . ( all files )\n- Fix minor bug in nfcapd.c. \n- Extend nfprofile for alerting system of nfsen - special version of profiles\n- Extend nfprofile for shadow profiles.\n\n2007-08-10  snapshot-20070110\n- Fix some compiler warnings, when compiled on a 64bit LINUX\n- Fixes an sflow bug: IP address was printed in wrong direction. ( lower bits first )\n- Add new IP addr taging option -T for easy parsing for nfsen lookups\n- Add new IP list for massive address filtering:\n  syntax: ip in [ 12345 23456 3456 ....]\n- Change nfprofile for channel based profiling. This breaks with old nfprofile \n  functionality.\n- Remove space from ICMP type/code when followed by an IP address\n\n2006-07-21\tsnapshot-20060809\n- Make nfexpire ready for profile expiration\n- Fix bug in nfrpofile. sub dir hierarchy not handled correctly.\n\n2006-07-21\tsnapshot-20060721\n- Add -N option for plain number output in summary line\n\n2006-07-21\tsnapshot-20060721\n- Do recursive file selection when a directory is given by -R\n\n2006-06-14\tsnapshot-20060621\n- Add srcas/dstas/proto aggregation.\n  Note: This changes the default aggregation behaviour, but gives more flexibility\n- Add tos to element statistics list\n\n2006-06-14\tsnapshot-20060614\n- Add additional stat line at the end of output\n- Add new binary nfexpire. Manages data expiry on time and/or size based limits\n  Includes new bookkeeping records in nfcapd.  See nfexpire(1)\n- Add ICMP type/code decoding in flow listing instead of dst port\n- Add packet repeater in nfcapd/sfcapd. In addition, incoming UDP packets can \n  be directly forwarded to another IP address/Port. See new option -R\n- Add sub directory hierarchies: Files can be stored into various sub dir levels\n  based on different time formats. see new option -S\n- Some minor bug fixes.\n- Code cleanup in nfcapd. better daemonize code and communication with launcher.\n\n2006-04-xx\tv.1.5.1\n\t\t\tFix bug in nfdump.c: Writing anonymized flows to file did not work corretly\n\t\t\tstdin input format now compatible with file format, therefore\n\t\t\t'nfdump < file' works again as it did in nfdump 1.4.\n\t\t\tFix bug in nfcapd.c: Error handling not correct when receiving a non\n\t\t\trecognized netflow packet. Resulted in an endless loop\n2006-03-27\tsnapshot 1.5-20060327\n\t\t\tMake all element statistics -s transport layer protocol\n\t\t\tindependant by default. Add :p to stat name ( e.g. srcip:p ) to\n\t\t\tenable transport layer dependant statistics on request.\n2006-03-20\tsnapshot 1.5-20060320\n            Fix bug in filter engine: 'not flags xyz' produces wrong results\n\t\t\twhen more than a single flag is specified.\n\t\t\tMinor man page fixes.\n\n2006-03-06\tv1.5\n\t\t\tFix bug nfcapd. Laucher signaled too early. File not yet properly\n\t\t\tclosed.\n2006-02-14\tv1.5-beta-5\n\t\t\tAdd srcas, dstas, input and output interfaces in aggregated\n\t\t\toutput. \n\t\t\tFix IPv6 bug in filter: accept 1234:: address.\n\t\t\trename nfcapd.curent tmp file to nfcapd.curren.<pid>. Poorly\n\t\t\tconfigured nfcapd processes may mess up themselves otherwise.\n2006-02-02\tv1.5-beta-4\n\t\t\tFix netflow v5 dPkts <-> dOctets collector bug.\n\t\t\tUpdate pipe format to include more information\n\t\t\tAllow AS number 0 in filter syntax.\n\t\t\tAdd some more boundary checking - netflow exporters aren't bug free either - sigh ..\n2006-01-11\tv1.5-beta-3\n\t\t\tFix isnumber incompatibility in grammar.y\n\t\t\tAdd 'if' statistics\n2006-01-10\tv1.5-beta-2\nnf_common.c\tFix bug in format parser.\n\t\t\tExtended 'proto <protocol>' syntax to support all protocols\n\t\t\tChange time format in summary line to ISO format\n2005-12-20\tv1.5-beta-1\n*.*\t\t\tA lot of internal changes, not mentioned here. :(\n\nnfdump\t\tAdd subnet aggregation for option -A\n\t\t\tA new syntax e.g. srcip4/24, dstip6/64 is supported for subnet wise aggregation.\n\t\t\texample: traffic of a whole subnet -A srcip4/24 -s srcip/bytes\n\nnfdump\t\tAdd more stat element option. -s <stat> now supports:\n\t\t\tsrcip, dstip, ip, srcport, dstport, port, srcas, dstas, as, inif, outif, proto\n\nnfdump\t\tAdd -z. Suppress writing flows to data files. Only stat information is written.\nnfprofile\tUsed only be nfsen for upcoming shadow profiles. If you don't understand this\n\t\t\tsimply ignore it.\n\nnfdump\t\tAdd -q option to suppress header as well as stat information at the bottom\nnfprofile\tfor easier post processing with external programms.\n\nnf_common.c\tOutput format processsing rewritting for more flexibility. Besides standard\nnfdump.c\toutput formats line, long extended etc., user defined output formats are now \n\t\t\tpossible and can even be compiled into nfdump for easy access. See -o fmt:<format>\n\t\t\tand nfdump.c around line 100.\n\n*.*\t\t\tIntegrate netflow v9 into nfdump. Only a subset of v9 is stored into\n\t\t\tthe data files, basically everything needed for nfdump to work as it did before.\n\t\t\tThis also includes IPv6 support for any nfdump options. CryptoPAN extended\n\t\t\tto work with IPv6. IPv6 condensed output format for better readability.\n\t\t\tOutput formats available in long and condensed mode: e.g. line -> line6\n\t\t\textended -> extended6\n\n*.*\t\t\tReplace binary data file format. Old format not flexible enough for\n\t\t\tupcoming netflow v9/sflow data. *.stat files are gone. The same \n\t\t\tinformation is now available under nfdump -I\n\t\t\tNew format about 5% larger in size, but faster for reading and writing.\n\t\t\tspeed gain eaten up by more complex processing - sigh ..\n\t\t\tcompat14 mode enables transparent reading of old style format.\n\t\t\tnffile.[ch] now handles all data file stuff.\n\nnfreplay\tMulticast enabled:\n\t\t\tAdd -j <join group>. Joins the specified multicast group ( v4 or v6 )\n\t\t\tsending flows to this group.\n\nnfreplay\tIPv6 enabled:\n\t\t\tAdd option -4 and -6 to force a specific protocol, otherwise\n\t\t\tprotocol is automatically selected according the hostname to send flows to.\n\t\t\tAdd -K key, to send data anonymized, using CryptoPAn\n\nnfcapd\t\tMulticast enabled:\n\t\t\tAdd -j <join group>. Joins the specified multicast group ( v4 or v6 )\n\t\t\tfor listening.\n\nnfcapd\t\tIPv6 enabled:\n\t\t\tAdd option -4 and -6 for IPv4 and IPv6. By default, listen on IPv4.\n\t\t\tOption -b <host/IP> to bind for a specific host/IP address automatically\n\t\t\tselects appropriate protocol.\n\nnfnet.c\t\tAll functions to setup network sockets for listening/sending are \n\t\t\tput into this file.\n\n2005-08-22 v1.4\n- nfreplay:  Bug fix sending flows.\n- nfdump:    Add CryptoPAn code to anonymize IP addresses. New option -K\n- nfdump:    Change time format in output to ISO 8601 compatible: e.g. 1981-04-05 14:30:30.100\n- nfdump:    Add scaling factor k,m,g to number in filter syntax: e.g. bytes > 1m\n- nfdump:    Create new output format extended with additional fields pps, bps and bpp\n- nfdump:    Rename output format extended to raw\n- nfdump:    More than one single flow element statistic ( -s ) is now possible\n- nfdump:    Add user defined sort order in flow element statistic\n- nfdump:    Flow element statistic can be ordered by more than one order in the same run\n- nfdump:    Add pps, bps and bpp fields in flow element statistics\n- nfdump:    Add more symbolic protocols ESP, AH, GRP and RVSP to filter syntax\n- nfdump:    Add duration, pps, bps and bpp to filter syntax\n- nfdump:    Make nfdump miliseconds aware. Older versions skipped msecs.\n  Binary nfdump file format changed due to this.\n  output formats changed, due to this.\n- nfdump:    Add interface in/out if <num> syntax to filter\n- nfcapd:    Add flow_sequence check. Reports missing flows now.\n- nfcapd:    Report statistics to syslog LOG_INFO when data file is rotated.\n- ft2nfdump: Add ft2nfdump to read netflow data from flow-tools\n\n2005-04-21 v1.3\n- Add option -A for more flexible aggregation.\n- Correct spelling errors :(\n\n2005-03-04 v1.2.1\nBug fix release\n- nfcapd: launcher subprocess may hang on Linux 2.6.x kernels.\n  Cleaned up interrupt handling. \n- nfcapd: fix include order of socket.h and types.h in order to\n  compile cleanly under FreeBSD 4.x\n- nfcapd: clean up syslog logging.\n- nfdump: Multiple sources ( -M ) and sort flows ( -m ) with \n  -c <limit> did not list the correct flows.\n- nfprofile: Profiling with multiple sources may produce incorrect\n  profiles. \n\n2004-12-20 v1.2\n- nfcapd handles transparent v5 and v7 flows. v7 gets converted into v5\n- nfcapd can execute any command at the end of interval. New option -x\n- nfdump Extended filter syntax for flags, to, bytes and packets\n- Rearrange output formats in nfdump: new switch -o, remove switch -E\n  output formats: 'line', 'long', 'extended' and 'pipe'\n- More flexible statistic handling in nfdump: cleanup ugly -s -s -s\n  syntax. Replaced by -s <stat> option. New statistics for Port and AS.\n\n2004-09-20 v 1.1\nFirst public Version.\n", "/*  \n *  Copyright (c) 2012-2019, Peter Haag\n *  All rights reserved.\n *  \n *  Redistribution and use in source and binary forms, with or without \n *  modification, are permitted provided that the following conditions are met:\n *  \n *   * Redistributions of source code must retain the above copyright notice, \n *     this list of conditions and the following disclaimer.\n *   * Redistributions in binary form must reproduce the above copyright notice, \n *     this list of conditions and the following disclaimer in the documentation \n *     and/or other materials provided with the distribution.\n *   * Neither the name of the author nor the names of its contributors may be \n *     used to endorse or promote products derived from this software without \n *     specific prior written permission.\n *  \n *  THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" \n *  AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE \n *  IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE \n *  ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE \n *  LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR \n *  CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF \n *  SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS \n *  INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN \n *  CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) \n *  ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE \n *  POSSIBILITY OF SUCH DAMAGE.\n *  \n */\n\n#include \"config.h\"\n\n#include <stdio.h>\n#include <sys/types.h>\n#include <sys/socket.h>\n#include <unistd.h>\n#include <stdlib.h>\n#include <string.h>\n#include <errno.h>\n#include <time.h>\n#include <netinet/in.h>\n#include <arpa/inet.h>\n\n#ifdef HAVE_STDINT_H\n#include <stdint.h>\n#endif\n\n#include \"nffile.h\"\n#include \"nfx.h\"\n#include \"nfnet.h\"\n#include \"nf_common.h\"\n#include \"util.h\"\n#include \"bookkeeper.h\"\n#include \"collector.h\"\n#include \"exporter.h\"\n#include \"ipfix.h\"\n\n#ifndef DEVEL\n#   define dbg_printf(...) /* printf(__VA_ARGS__) */\n#else\n#   define dbg_printf(...) printf(__VA_ARGS__)\n#endif\n\n// a few handy macros\n#define GET_FLOWSET_ID(p) \t  (Get_val16(p))\n#define GET_FLOWSET_LENGTH(p) (Get_val16((void *)((p) + 2)))\n\n#define GET_TEMPLATE_ID(p) \t  (Get_val16(p))\n#define GET_TEMPLATE_COUNT(p) (Get_val16((void *)((p) + 2)))\n\n#define GET_OPTION_TEMPLATE_ID(p) \t  \t\t  \t\t (Get_val16(p))\n#define GET_OPTION_TEMPLATE_FIELD_COUNT(p)   (Get_val16((void *)((p) + 2)))\n#define GET_OPTION_TEMPLATE_SCOPE_FIELD_COUNT(p)   \t\t (Get_val16((void *)((p) + 4)))\n\n#define DYN_FIELD_LENGTH\t65535\n\n/* module limited globals */\n\n/* \n * sequence element to move data from data input to output\n * a sequence exists for each IPFIX element\n */\ntypedef struct sequence_map_s {\n/* sequence definition:\n   just move a certain number of bytes          -> moveXX\n   set a certain number of output bytes to zero -> zeroXX\n   process input data into appropriate output   -> AnyName\n */\n#define nop    \t\t\t0\n#define dyn_skip\t\t1\n#define move8   \t\t2\n#define move16  \t\t3\n#define move32  \t\t4\n#define move40  \t\t5\n#define move48  \t\t6\n#define move56  \t\t7\n#define move64  \t\t8\n#define move128 \t\t9\n#define move32_sampling 10\n#define move64_sampling 11\n#define move_mac\t\t12\n#define move_mpls \t\t13\n#define move_flags\t\t14\n#define Time64Mili \t\t15\n#define TimeDeltaMicro \t16\n#define TimeUnix \t\t17\n#define saveICMP \t\t18\n#define zero8\t\t\t19\n#define zero16\t\t\t20\n#define zero32\t\t\t21\n#define zero64\t\t\t22\n#define zero128\t\t\t23\n\n\tuint32_t\tid;\t\t\t\t// sequence ID as defined above\n\tuint16_t\tskip_count;\t\t// skip this number of bytes in input stream after reading\n\tuint16_t\ttype;\t\t\t// Element type\n\tuint16_t\tinput_length;\t// length of input element\n\tuint16_t\toutput_offset;\t// copy final data to this output offset\n\tvoid\t\t*stack;\t\t\t// optionally copy data onto this stack\n} sequence_map_t;\n\n/*\n * the IPFIX template records are processed and\n * for each template we create a a translation table, which contains\n * all information required, to transform the data records from\n * the exporter into nfdump internal data structurs.\n * All templates are chained in a linked list\n */ \ntypedef struct input_translation_s {\n\tstruct input_translation_s\t*next;\t// linked list\n\tuint32_t\tflags;\t\t\t\t\t// flags for output record\n\ttime_t\t\tupdated;\t\t\t\t// timestamp of last update/refresh\n\tuint32_t\tid;\t\t\t\t\t\t// template ID of exporter domains\n\tuint32_t\toutput_record_size;\t\t// required size in nfdump format\n\n\t// tmp vars needed while processing the data record\n\tint\t\t\tdelta_time;\t\t\t\t// delta micro or absolute ms time stamps\n\tuint64_t\tflow_start;\t\t\t\t// start time in msec\n\tuint64_t\tflow_end;\t\t\t\t// end time in msec\n\tuint32_t\ticmpTypeCodeIPv4;\t\t// ICMP type/code in data stream\n\tuint64_t    packets;\t\t\t\t// total (in)packets - sampling corrected\n\tuint64_t    bytes;\t\t\t\t\t// total (in)bytes - sampling corrected\n\tuint64_t    out_packets;\t\t\t// total out packets - sampling corrected\n\tuint64_t    out_bytes;\t\t\t\t// total out bytes - sampling corrected\n\tuint32_t\trouter_ip_offset;\n\tuint32_t\treceived_offset;\n\n\t// extension map infos\n\tuint32_t\textension_map_changed;\t// map changed while refreshing?\n\textension_info_t \t extension_info; // the extension map reflecting this template\n\n\t// sequence map information\n\tuint32_t\tmax_number_of_sequences; // max number of sequences for the translate \n\tuint32_t\tnumber_of_sequences;\t// number of sequences for the translate \n\tsequence_map_t *sequence;\t\t\t// sequence map\n} input_translation_t;\n\n/*\n * \tAll Obervation Domains from all exporter are stored in a linked list\n *\twhich uniquely can identify each exporter/Observation Domain\n */\ntypedef struct exporter_ipfix_domain_s {\n\tstruct exporter_ipfix_domain_s\t*next;\t// linkes list to next exporter\n\n\t// generic exporter information\n\texporter_info_record_t info;\n\n\tuint64_t\tpackets;\t\t\t// number of packets sent by this exporter\n\tuint64_t\tflows;\t\t\t\t// number of flow records sent by this exporter\n\tuint32_t\tsequence_failure;\t// number of sequence failues\n\tuint32_t\tpadding_errors;\t\t// number of sequence failues\n\n\t// generic sampler\n\tgeneric_sampler_t\t\t*sampler;\n\n\t// exporter parameters\n\tuint32_t\tExportTime;\n\n\t// Current sequence number\n\tuint32_t\tPacketSequence;\n\n\t// statistics\n\tuint64_t\tTemplateRecords;\t// stat counter\n\tuint64_t\tDataRecords;\t\t// stat counter\n\n\t// linked list of all templates sent by this exporter\n\tinput_translation_t\t*input_translation_table; \n\n\t// in order to prevent search through all lists keep\n\t// the last template we processed as a cache\n\tinput_translation_t *current_table;\n\n} exporter_ipfix_domain_t;\n\n\nstatic struct ipfix_element_map_s {\n\tuint16_t\tid;\t\t\t// IPFIX element id \n\tuint16_t\tlength;\t\t// type of this element ( input length )\n\tuint16_t\tout_length;\t// type of this element ( output length )\n\tuint32_t\tsequence;\t// \n\tuint32_t\tzero_sequence;\t// \n\tuint16_t\textension;\t// maps into nfdump extension ID\n} ipfix_element_map[] = {\n\t{0, 0, 0},\n\t{ IPFIX_octetDeltaCount, \t\t\t _8bytes, \t_8bytes,  move64_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_octetDeltaCount, \t\t\t _4bytes, \t_8bytes,  move32_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_packetDeltaCount, \t\t\t _8bytes, \t_8bytes,  move64_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_packetDeltaCount, \t\t\t _4bytes, \t_8bytes,  move32_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_octetTotalCount, \t\t\t _8bytes, \t_8bytes,  move64_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_octetTotalCount, \t\t\t _4bytes, \t_8bytes,  move32_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_packetTotalCount, \t\t\t _8bytes, \t_8bytes,  move64_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_packetTotalCount, \t\t\t _4bytes, \t_8bytes,  move32_sampling, zero64, COMMON_BLOCK },\n\t{ IPFIX_forwardingStatus, \t \t\t _1byte,    _1byte,   move8, zero8, COMMON_BLOCK },\n\t{ IPFIX_protocolIdentifier, \t\t _1byte, \t_1byte,   move8,  zero8, COMMON_BLOCK },\n\t{ IPFIX_ipClassOfService, \t\t\t _1byte, \t_1byte,   move8, zero8, COMMON_BLOCK },\n\t{ IPFIX_tcpControlBits, \t\t\t _1byte, \t_1byte,   move8, zero8, COMMON_BLOCK },\n\t{ IPFIX_tcpControlBits, \t\t\t _2bytes, \t_1byte,   move_flags, zero8, COMMON_BLOCK },\n\t{ IPFIX_SourceTransportPort, \t\t _2bytes, \t_2bytes,  move16, zero16, COMMON_BLOCK },\n\t{ IPFIX_SourceIPv4Address, \t\t\t _4bytes, \t_4bytes,  move32, zero32, COMMON_BLOCK },\n\t{ IPFIX_SourceIPv4PrefixLength, \t _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_ingressInterface, \t\t\t _4bytes, \t_4bytes,  move32, zero32, EX_IO_SNMP_4 },\n\t{ IPFIX_ingressInterface, \t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_IO_SNMP_2 },\n\t{ IPFIX_DestinationTransportPort,\t _2bytes, \t_2bytes,  move16, zero16, COMMON_BLOCK },\n\t{ IPFIX_DestinationIPv4Address, \t _4bytes, \t_4bytes,  move32, zero32, COMMON_BLOCK },\n\t{ IPFIX_DestinationIPv4PrefixLength, _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_egressInterface, \t\t\t _4bytes, \t_4bytes,  move32, zero32, EX_IO_SNMP_4 },\n\t{ IPFIX_egressInterface, \t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_IO_SNMP_2 },\n\t{ IPFIX_ipNextHopIPv4Address, \t\t _4bytes, \t_4bytes,  move32, zero32, EX_NEXT_HOP_v4 },\n\t{ IPFIX_bgpSourceAsNumber, \t\t\t _4bytes, \t_4bytes,  move32, zero32, EX_AS_4 },\n\t{ IPFIX_bgpSourceAsNumber, \t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_AS_2 },\n\t{ IPFIX_bgpDestinationAsNumber, \t _4bytes, \t_4bytes,  move32, zero32, EX_AS_4 },\n\t{ IPFIX_bgpDestinationAsNumber, \t _2bytes, \t_2bytes,  move16, zero16, EX_AS_2 },\n\t{ IPFIX_bgpNextHopIPv4Address, \t\t _4bytes, \t_4bytes,  move32, zero32, EX_NEXT_HOP_BGP_v4},\n\t{ IPFIX_flowEndSysUpTime, \t\t\t _4bytes, \t_4bytes,  nop, nop,  COMMON_BLOCK },\n\t{ IPFIX_flowStartSysUpTime, \t\t _4bytes, \t_4bytes,  nop, nop, COMMON_BLOCK },\n\t{ IPFIX_postOctetDeltaCount, \t\t _8bytes, \t_8bytes,  move64, zero64, EX_OUT_BYTES_8 },\n\t{ IPFIX_postOctetDeltaCount, \t\t _4bytes, \t_4bytes,  move32, zero32, EX_OUT_BYTES_4 },\n\t{ IPFIX_postPacketDeltaCount, \t\t _8bytes, \t_8bytes,  move64, zero64, EX_OUT_PKG_8 },\n\t{ IPFIX_postPacketDeltaCount, \t\t _4bytes, \t_4bytes,  move32, zero32, EX_OUT_PKG_4 },\n\t{ IPFIX_SourceIPv6Address, \t\t\t _16bytes, \t_16bytes, move128, zero128, COMMON_BLOCK },\n\t{ IPFIX_DestinationIPv6Address, \t _16bytes, \t_16bytes, move128, zero128, COMMON_BLOCK },\n\t{ IPFIX_SourceIPv6PrefixLength, \t _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_DestinationIPv6PrefixLength, _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_icmpTypeCodeIPv4, \t\t\t _2bytes, \t_2bytes,  saveICMP, nop, COMMON_BLOCK },\n\t{ IPFIX_postIpClassOfService, \t\t _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_SourceMacAddress, \t\t\t _6bytes, \t_8bytes,  move_mac, zero64, EX_MAC_1},\n\t{ IPFIX_postDestinationMacAddress, \t _6bytes,\t_8bytes,  move_mac, zero64, EX_MAC_1},\n\t{ IPFIX_vlanId, \t\t\t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_VLAN}, \n\t{ IPFIX_postVlanId, \t\t\t\t _2bytes, \t_2bytes,  move16, zero16, EX_VLAN},\n\t{ IPFIX_flowDirection, \t\t\t\t _1byte, \t_1byte,   move8, zero8, EX_MULIPLE },\n\t{ IPFIX_ipNextHopIPv6Address, \t\t _16bytes, \t_16bytes, move128, zero128, EX_NEXT_HOP_v6},\n\t{ IPFIX_bgpNextHopIPv6Address, \t\t _16bytes, \t_16bytes, move128, zero128, EX_NEXT_HOP_BGP_v6},\n\t{ IPFIX_mplsTopLabelStackSection, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection2, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection3, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection4, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection5, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection6, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection7, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection8, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection9, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_mplsLabelStackSection10, \t _3bytes,   _4bytes,  move_mpls, zero32, EX_MPLS},\n\t{ IPFIX_DestinationMacAddress, \t\t _6bytes,   _8bytes,  move_mac, zero64, EX_MAC_2},\n\t{ IPFIX_postSourceMacAddress, \t\t _6bytes,   _8bytes,  move_mac, zero64, EX_MAC_2},\n\t{ IPFIX_flowStartMilliseconds, \t\t _8bytes,   _8bytes,  Time64Mili, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowEndMilliseconds, \t\t _8bytes,   _8bytes,  Time64Mili, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowStartSeconds, \t\t \t _4bytes,   _4bytes,  TimeUnix, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowEndSeconds,  \t \t\t _4bytes,   _4bytes,  TimeUnix, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowEndMilliseconds, \t\t _8bytes,   _8bytes,  Time64Mili, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowStartDeltaMicroseconds,\t _4bytes,   _4bytes,  TimeDeltaMicro, zero32, COMMON_BLOCK},\n\t{ IPFIX_flowEndDeltaMicroseconds, \t _4bytes,   _4bytes,  TimeDeltaMicro, zero32, COMMON_BLOCK},\n\t{0, 0, 0}\n};\n\n// cache to be used while parsing a template\nstatic struct cache_s {\n\tstruct element_param_s {\n\t\tuint16_t index;\n\t\tuint16_t found;\n\t\tuint16_t length;\n\t}\t\t\t*lookup_info;\n\tstruct order_s {\n\t\tuint16_t type;\n\t\tuint16_t length;\n\t} *input_order;\n\tuint32_t\tinput_count;\n\tuint32_t\tmax_ipfix_elements;\n\tuint32_t\t*common_extensions;\n\t\n} cache;\n\n// module limited globals\nstatic uint32_t\tprocessed_records;\n\n// externals\nextern int verbose;\nextern uint32_t Max_num_extensions;\nextern extension_descriptor_t extension_descriptor[];\nextern uint32_t default_sampling;\nextern uint32_t overwrite_sampling;\nextern uint32_t\texporter_sysid;\n\n// prototypes\nstatic void InsertStdSamplerOffset(FlowSource_t *fs, uint16_t id, uint16_t offset_std_sampler_interval, \n\tuint16_t offset_std_sampler_algorithm);\n\nstatic void InsertSampler(FlowSource_t *fs, exporter_ipfix_domain_t *exporter, int32_t id, uint16_t mode, uint32_t interval);\n\nstatic input_translation_t *add_translation_table(exporter_ipfix_domain_t *exporter, uint16_t id);\n\nstatic void remove_translation_table(FlowSource_t *fs, exporter_ipfix_domain_t *exporter, uint16_t id);\n\nstatic void remove_all_translation_tables(exporter_ipfix_domain_t *exporter);\n\nstatic exporter_ipfix_domain_t *GetExporter(FlowSource_t *fs, ipfix_header_t *ipfix_header);\n\nstatic uint32_t MapElement(uint16_t Type, uint16_t Length, uint32_t order);\n\nstatic void PushSequence(input_translation_t *table, uint16_t Type, uint32_t *offset, void *stack);\n\nstatic int compact_input_order(void);\n\nstatic int reorder_sequencer(input_translation_t *table);\n\nstatic void Process_ipfix_templates(exporter_ipfix_domain_t *exporter, void *flowset_header, uint32_t size_left, FlowSource_t *fs);\n\nstatic void Process_ipfix_template_add(exporter_ipfix_domain_t *exporter, void *DataPtr, uint32_t size_left, FlowSource_t *fs);\n\nstatic void Process_ipfix_template_withdraw(exporter_ipfix_domain_t *exporter, void *DataPtr, uint32_t size_left, FlowSource_t *fs);\n\nstatic void  Process_ipfix_option_data(exporter_ipfix_domain_t *exporter, void *data_flowset, FlowSource_t *fs);\n\nstatic void Process_ipfix_data(exporter_ipfix_domain_t *exporter, uint32_t ExportTime, void *data_flowset, FlowSource_t *fs, input_translation_t *table );\n\n#include \"inline.c\"\n#include \"nffile_inline.c\"\n\nint Init_IPFIX(void) {\nint i;\n\n\tcache.lookup_info\t    = (struct element_param_s *)calloc(65536, sizeof(struct element_param_s));\n\tcache.common_extensions = (uint32_t *)malloc((Max_num_extensions+1)*sizeof(uint32_t));\n\tif ( !cache.common_extensions || !cache.lookup_info ) {\n\t\tLogError(\"Process_ipfix: Panic! malloc(): %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\treturn 0;\n\t}\n\n\t// init the helper element table\n\tfor (i=1; ipfix_element_map[i].id != 0; i++ ) {\n\t\tuint32_t Type = ipfix_element_map[i].id;\n\t\t// multiple same type - save first index only\n\t\t// iterate through same Types afterwards\n\t\tif ( cache.lookup_info[Type].index == 0 ) \n\t\t\tcache.lookup_info[Type].index  = i;\n\t}\n\tcache.max_ipfix_elements = i;\n\tcache.input_order = NULL;\n\n\tLogError(\"Init IPFIX: Max number of IPFIX tags: %u\", cache.max_ipfix_elements);\n\n\treturn 1;\n\n} // End of Init_IPFIX\n\nstatic exporter_ipfix_domain_t *GetExporter(FlowSource_t *fs, ipfix_header_t *ipfix_header) {\n#define IP_STRING_LEN   40\nchar ipstr[IP_STRING_LEN];\nexporter_ipfix_domain_t **e = (exporter_ipfix_domain_t **)&(fs->exporter_data);\nuint32_t ObservationDomain = ntohl(ipfix_header->ObservationDomain);\n\n\twhile ( *e ) {\n\t\tif ( (*e)->info.id == ObservationDomain && (*e)->info.version == 10 && \n\t\t\t (*e)->info.ip.V6[0] == fs->ip.V6[0] && (*e)->info.ip.V6[1] == fs->ip.V6[1]) \n\t\t\treturn *e;\n\t\te = &((*e)->next);\n\t}\n\n\tif ( fs->sa_family == AF_INET ) {\n\t\tuint32_t _ip = htonl(fs->ip.V4);\n\t\tinet_ntop(AF_INET, &_ip, ipstr, sizeof(ipstr));\n\t} else if ( fs->sa_family == AF_INET6 ) {\n\t\tuint64_t _ip[2];\n\t\t_ip[0] = htonll(fs->ip.V6[0]);\n\t\t_ip[1] = htonll(fs->ip.V6[1]);\n\t\tinet_ntop(AF_INET6, &_ip, ipstr, sizeof(ipstr));\n\t} else {\n\t\tstrncpy(ipstr, \"<unknown>\", IP_STRING_LEN);\n\t}\n\n\t// nothing found\n\t*e = (exporter_ipfix_domain_t *)malloc(sizeof(exporter_ipfix_domain_t));\n\tif ( !(*e)) {\n\t\tLogError(\"Process_ipfix: Panic! malloc() %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\treturn NULL;\n\t}\n\tmemset((void *)(*e), 0, sizeof(exporter_ipfix_domain_t));\n\t(*e)->info.header.type  = ExporterInfoRecordType;\n\t(*e)->info.header.size  = sizeof(exporter_info_record_t);\n\t(*e)->info.id \t\t\t= ObservationDomain;\n\t(*e)->info.ip\t\t\t= fs->ip;\n\t(*e)->info.sa_family\t= fs->sa_family;\n\t(*e)->info.version \t\t= 10;\n\t(*e)->info.sysid\t \t= 0;\n\n\t(*e)->TemplateRecords \t= 0;\n\t(*e)->DataRecords \t \t= 0;\n\t(*e)->sequence_failure \t= 0;\n\t(*e)->padding_errors \t= 0;\n\t(*e)->next\t \t\t\t= NULL;\n\t(*e)->sampler \t\t\t= NULL;\n\n\tFlushInfoExporter(fs, &((*e)->info));\n\n\tdbg_printf(\"[%u] New exporter: SysID: %u, Observation domain %u from: %s\\n\", \n\t\tObservationDomain, (*e)->info.sysid, ObservationDomain, ipstr);\n\tLogInfo(\"Process_ipfix: New exporter: SysID: %u, Observation domain %u from: %s\\n\", \n\t\t(*e)->info.sysid, ObservationDomain, ipstr);\n\n\n\treturn (*e);\n\n} // End of GetExporter\n\nstatic uint32_t MapElement(uint16_t Type, uint16_t Length, uint32_t order) {\nint\tindex;\n\n\tcache.input_order[order].type\t= Type;\n\tcache.input_order[order].length\t= Length;\n\n\tindex = cache.lookup_info[Type].index;\n\tif ( index ) {\n\t\twhile ( index && ipfix_element_map[index].id == Type ) {\n\t\t\tif ( Length == ipfix_element_map[index].length ) {\n\t\t\t\tcache.lookup_info[Type].found  = 1;\n\t\t\t\tcache.lookup_info[Type].length = Length;\n\t\t\t\tcache.lookup_info[Type].index  = index;\n\t\t\t\tdbg_printf(\"found extension %u for type: %u, input length: %u output length: %u Extension: %u\\n\", \n\t\t\t\t\tipfix_element_map[index].extension, ipfix_element_map[index].id, \n\t\t\t\t\tipfix_element_map[index].length, ipfix_element_map[index].out_length, ipfix_element_map[index].extension);\n\t\t\t\treturn ipfix_element_map[index].extension;\n\t\t\t}\n\t\t\tindex++;\n\t\t}\n\t\tdbg_printf(\"Skip known element type: %u, Unknown length: %u\\n\", Type, Length);\n\t} else {\n\t\tdbg_printf(\"Skip unknown element type: %u, Length: %u\\n\", Type, Length);\n\t}\n\n\tcache.input_order[order].type = SKIP_ELEMENT;\n\treturn 0;\n\n} // End of MapElement\n\nstatic input_translation_t *GetTranslationTable(exporter_ipfix_domain_t *exporter, uint16_t id) {\ninput_translation_t *table;\n\n\tif ( exporter->current_table && ( exporter->current_table->id == id ) )\n\t\treturn exporter->current_table;\n\n\ttable = exporter->input_translation_table;\n\twhile ( table ) {\n\t\tif ( table->id == id ) {\n\t\t\texporter->current_table = table;\n\t\t\treturn table;\n\t\t}\n\n\t\ttable = table->next;\n\t}\n\n\tdbg_printf(\"[%u] Get translation table %u: %s\\n\", exporter->info.id, id, table == NULL ? \"not found\" : \"found\");\n\n\texporter->current_table = table;\n\treturn table;\n\n} // End of GetTranslationTable\n\nstatic input_translation_t *add_translation_table(exporter_ipfix_domain_t *exporter, uint16_t id) {\ninput_translation_t **table;\n\n\ttable = &(exporter->input_translation_table);\n\twhile ( *table ) {\n\t\ttable = &((*table)->next);\n\t}\n\n\t// Allocate enough space for all potential ipfix tags, which we support\n\t// so template refreshing may change the table size without danger of overflowing \n\t*table = calloc(1, sizeof(input_translation_t));\n\tif ( !(*table) ) {\n\t\t\tLogError(\"Process_ipfix: Panic! calloc() %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\treturn NULL;\n\t}\n\t(*table)->max_number_of_sequences = 0;\n\t(*table)->number_of_sequences \t  = 0;\n\t(*table)->sequence = NULL;\n\t(*table)->id   \t   = id;\n\t(*table)->next\t   = NULL;\n\n\tdbg_printf(\"[%u] Get new translation table %u\\n\", exporter->info.id, id);\n\n\treturn *table;\n\n} // End of add_translation_table\n\nstatic void remove_translation_table(FlowSource_t *fs, exporter_ipfix_domain_t *exporter, uint16_t id) {\ninput_translation_t *table, *parent;\n\n\tLogInfo(\"Process_ipfix: [%u] Withdraw template id: %i\", \n\t\t\texporter->info.id, id);\n\n\tparent = NULL;\n\ttable = exporter->input_translation_table;\n\twhile ( table && ( table->id != id ) ) {\n\t\tparent = table;\n\t\ttable = table->next;\n\t}\n\n\tif ( table == NULL ) {\n\t\tLogError(\"Process_ipfix: [%u] Withdraw template id: %i. translation table not found\", \n\t\t\t\texporter->info.id, id);\n\t\treturn;\n\t}\n\n\tdbg_printf(\"\\n[%u] Withdraw template ID: %u\\n\", exporter->info.id, table->id);\n\n\t// clear table cache, if this is the table to delete\n\tif (exporter->current_table == table)\n\t\texporter->current_table = NULL;\n\n\tif ( parent ) {\n\t\t// remove table from list\n\t\tparent->next = table->next;\n\t} else {\n\t\t// last table removed\n\t\texporter->input_translation_table = NULL;\n\t}\n\n\tRemoveExtensionMap(fs, table->extension_info.map);\n\tfree(table->sequence);\n\tfree(table->extension_info.map);\n\tfree(table);\n\n} // End of remove_translation_table\n\nstatic void remove_all_translation_tables(exporter_ipfix_domain_t *exporter) {\ninput_translation_t *table, *next;\n\n\tLogInfo(\"Process_ipfix: Withdraw all templates from observation domain %u\\n\", \n\t\texporter->info.id);\n\n\ttable = exporter->input_translation_table;\n\twhile ( table ) {\n\t\tnext = table->next;\n\n\t\tdbg_printf(\"\\n[%u] Withdraw template ID: %u\\n\", exporter->info.id, table->id);\n\n\t\tfree(table->sequence);\n\t\tfree(table->extension_info.map);\n\t\tfree(table);\n\n\t\ttable = next;\n\t}\n\n\t// clear references\n\texporter->input_translation_table = NULL;\n\texporter->current_table = NULL;\n\n} // End of remove_all_translation_tables\n\nstatic int CheckSequenceMap(input_translation_t *table) {\n\n\tif ( table->number_of_sequences < table->max_number_of_sequences )\n\t\treturn 1;\n\n\tdbg_printf(\"Extend sequence map %u -> \", table->max_number_of_sequences);\n\tvoid *p = realloc(table->sequence,  (table->max_number_of_sequences + 1) * sizeof(sequence_map_t));\n\tif ( !p ) {\n\t\tLogError(\"Process_ipfix: realloc() at %s line %d: %s\", \n\t\t\t__FILE__, __LINE__, strerror (errno));\n\t\tdbg_printf(\"\\nProcess_ipfix: realloc() at %s line %d: %s\", \n\t\t\t__FILE__, __LINE__, strerror (errno));\n\t\treturn 0;\n\t}\n\ttable->sequence = p;\n\ttable->max_number_of_sequences += 1;\n\tdbg_printf(\"%u\\n\", table->max_number_of_sequences);\n\treturn 1;\n\n} // End of CheckSequenceMap\n\nstatic void PushSequence(input_translation_t *table, uint16_t Type, uint32_t *offset, void *stack) {\nuint32_t i = table->number_of_sequences;\nuint32_t index = cache.lookup_info[Type].index;\n\n\tif ( !CheckSequenceMap(table) )\n\t\treturn;\n\n\ttable->sequence[i].skip_count = 0;\n\ttable->sequence[i].type = Type;\n\tif ( cache.lookup_info[Type].found ) {\n\t\t\ttable->sequence[i].id = ipfix_element_map[index].sequence;\n\t\t\ttable->sequence[i].output_offset = offset ? *offset : 0;\n\t\t\ttable->sequence[i].stack = stack;\n\t\t\ttable->sequence[i].input_length = cache.lookup_info[Type].length;\n\t} else {\n\t\t\ttable->sequence[i].id = ipfix_element_map[index].zero_sequence;\n\t\t\ttable->sequence[i].output_offset = offset ? *offset : 0;\n\t\t\ttable->sequence[i].stack = NULL;\n\t}\n\tdbg_printf(\"Push: sequence: %u, Type: %u, in length: %u, out length: %u, id: %u, out offset: %u\\n\",\n\t\ti, Type, ipfix_element_map[index].length, ipfix_element_map[index].out_length, \n\t\ttable->sequence[i].id, table->sequence[i].output_offset);\n\ttable->number_of_sequences++;\n\tif ( offset ) \n\t\t(*offset) += ipfix_element_map[index].out_length;\n\n} // End of PushSequence\n\nstatic int compact_input_order(void) {\nint i;\n\n\tdbg_printf(\"\\nCompacting element input order: %u elements\\n\", cache.input_count);\n\tfor ( i=0; i< cache.input_count; i++ ) {\n\t\tdbg_printf(\"%i: type: %u, length: %u\\n\", \n\t\t\ti, cache.input_order[i].type, cache.input_order[i].length);\n\t\t\n\t\tif ( (cache.input_order[i].type == SKIP_ELEMENT) && (cache.input_order[i].length == DYN_FIELD_LENGTH) ) {\n\t\t\tdbg_printf(\"Dynamic length field: %u\\n\", cache.input_order[i].type);\n\t\t\tcontinue;\n\t\t}\n\t\twhile ( (i+1) < cache.input_count &&\n\t\t\t(cache.input_order[i].type == SKIP_ELEMENT) && (cache.input_order[i].length != DYN_FIELD_LENGTH) &&\n\t\t\t(cache.input_order[i+1].type == SKIP_ELEMENT) && (cache.input_order[i+1].length != DYN_FIELD_LENGTH)) {\n\t\t\t// merge multiple skipped fix length elements into 1 hole sequence\n\t\t\t\tint j;\n\t\t\t\tdbg_printf(\"%i: type: %u, length: %u\\n\", \n\t\t\t\t\ti+1, cache.input_order[i+1].type, cache.input_order[i+1].length);\n\t\t\t\tdbg_printf(\"Merge order %u and %u\\n\", i, i+1);\n\t\t\t\t// type set 0 to mark skip sequence\n\t\t\t\tcache.input_order[i].type = SKIP_ELEMENT;\n\t\t\t\tcache.input_order[i].length += cache.input_order[i+1].length;\n\t\t\n\t\t\t\t// shift up lower entries - fill \n\t\t\t\tfor ( j=i+1; (j+1)<cache.input_count; j++) {\n\t\t\t\t\tcache.input_order[j] = cache.input_order[j+1];\n\t\t\t\t}\n\t\t\t\tcache.input_count--;\n\t\t}\n\t}\n\n#ifdef DEVEL\n\tprintf(\"\\nCompacted input order table: count: %u\\n\", cache.input_count);\n\tfor ( i=0; i< cache.input_count; i++ ) {\n\t\tdbg_printf(\"%i: Type: %u, Length: %u\\n\", \n\t\t\ti, cache.input_order[i].type, cache.input_order[i].length);\n\t}\n\tprintf(\"\\n\");\n#endif\n\n\t// check for common input fields\n\tfor ( i=0; i< cache.input_count; i++ ) {\n\t\tif ( cache.input_order[i].type != SKIP_ELEMENT ) \n\t\t\t// common input field in table\n\t\t\treturn 1;\n\t}\n\t// if we skip all input fields \n\treturn 0;\n\n} // End of compact_input_order\n\nstatic int reorder_sequencer(input_translation_t *table) {\nint i, n;\nsequence_map_t *sequence = table->sequence;\n\n#ifdef DEVEL\n\tprintf(\"\\nReorder Sequencer. Sequence steps: %u\\n\", table->number_of_sequences);\n\tfor ( i=0; i<table->number_of_sequences; i++ ) {\n\t\tprintf(\"Order: %i, Sequence: %u, Type: %u, Input length: %u, Output offset: %u, Skip Count: %u\\n\",\n\t\t\ti, sequence[i].id, sequence[i].type, sequence[i].input_length, \n\t\t\tsequence[i].output_offset, sequence[i].skip_count);\n\t}\n#endif\n\n\tn = 0;\t// index into sequencer table\n\t// reorder Sequencer steps, so they follow input order\n\t// insert skip counts if needed\n\tfor ( i=0; i<cache.input_count; i++ ) {\n\t\tif ( cache.input_order[i].type == SKIP_ELEMENT ) {\n\t\t\t// skip dyn length or no previous slot in sequence map\n\t\t\tif ( cache.input_order[i].length == DYN_FIELD_LENGTH || n == 0 ) {\n\t\t\t\tint j;\n\t\t\t\t// insert skip sequence \n\n\t\t\t\tif ( !CheckSequenceMap(table) )\n\t\t\t\t\treturn 0;\n\n\t\t\t\t// make room for new sequence - shift down slots\n\t\t\t\tfor ( j=table->number_of_sequences-1; j>=n; j-- ) {\n\t\t\t\t\tsequence[j+1] = sequence[j];\n\t\t\t\t}\n\n\t\t\t\t// slot n now available - create nop sequence with skip count\n\t\t\t\tif ( cache.input_order[i].length == DYN_FIELD_LENGTH ) {\n\t\t\t\t\tsequence[n].id = dyn_skip;\n\t\t\t\t\tsequence[n].skip_count = 0;\n\t\t\t\t} else {\n\t\t\t\t\tsequence[n].id = nop;\n\t\t\t\t\tsequence[n].skip_count = cache.input_order[i].length;\n\t\t\t\t}\n\t\t\t\tsequence[n].type = SKIP_ELEMENT;\n\t\t\t\tsequence[n].input_length = 0;\n\t\t\t\tsequence[n].stack = NULL;\n\t\t\t\ttable->number_of_sequences++;\n\t\t\t\tdbg_printf(\"Insert skip sequence in slot: %u, skip count: %u, dyn: %u\\n\", \n\t\t\t\t\tn, sequence[n].skip_count, cache.input_order[i].length == DYN_FIELD_LENGTH ? 1 : 0);\n\t\t\t} else {\n\t\t\t\tsequence[n-1].skip_count += cache.input_order[i].length;\n\t\t\t\tdbg_printf(\"Merge skip count: %u into previous sequence: %u\\n\", cache.input_order[i].length, n-1);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t} else {\n\t\t\t// reorder input element if needed\n\t\t\tif ( sequence[n].type != cache.input_order[i].type ) {\n\t\t\t\tsequence_map_t _s;\n\t\t\t\tint j = n+1;\n\n\t\t\t\twhile ( sequence[j].type != cache.input_order[i].type && j < table->number_of_sequences )\n\t\t\t\t\tj++;\n\n\t\t\t\t// must never happen!\n\t\t\t\tif ( j == table->number_of_sequences ) {\n\t\t\t\t\t// skip this field\n\t\t\t\t\tif ( n == 0 ) {\n\t\t\t\t\t\t// XXX fix this\n\t\t\t\t\t\treturn 0;\n\t\t\t\t\t} else {\n\t\t\t\t\t\tsequence[n-1].skip_count += cache.input_order[i].length;\n\t\t\t\t\t\tdbg_printf(\"Merge skip count: %u into previous sequence: %u\\n\", cache.input_order[i].length, n-1);\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t\t// swap slots\n\t\t\t\t_s = sequence[n];\n\t\t\t\tsequence[n] = sequence[j];\n\t\t\t\tsequence[j] = _s;\n\t\t\t\tdbg_printf(\"Swap slots %u <-> %u\\n\", n, j);\n\t\t\t} else {\n\t\t\t\tdbg_printf(\"In order slot %u\\n\", n);\n\t\t\t}\n\t\t}\n\t\t// advance sequence slot\n\t\tn++;\n\t}\n\n#ifdef DEVEL\n\tprintf(\"\\nReordered Sequencer. Sequence steps: %u\\n\", table->number_of_sequences);\n\tfor ( int i=0; i<table->number_of_sequences; i++ ) {\n\t\tprintf(\"Order: %i, Sequence: %u, Type: %u, Input length: %u, Output offset: %u, Skip Count: %u\\n\",\n\t\t\ti, sequence[i].id, sequence[i].type, sequence[i].input_length, \n\t\t\tsequence[i].output_offset, sequence[i].skip_count);\n\t}\n\tprintf(\"\\n\");\n#endif\n\n\treturn 1;\n\n} // End of reorder_sequencer\n\nstatic input_translation_t *setup_translation_table (exporter_ipfix_domain_t *exporter, uint16_t id) {\ninput_translation_t *table;\nextension_map_t \t*extension_map;\nuint32_t\t\t\ti, ipv6, offset, next_extension;\nsize_t\t\t\t\tsize_required;\n\n\tipv6 = 0;\n\n\ttable = GetTranslationTable(exporter, id);\n\tif ( !table ) {\n\t\tLogInfo(\"Process_ipfix: [%u] Add template %u\", exporter->info.id, id);\n\t\ttable = add_translation_table(exporter, id);\n\t\tif ( !table ) {\n\t\t\treturn NULL;\n\t\t}\n\t\t// Add an extension map\n\t\t// The number of extensions for this template is currently unknown\n\t\t// Allocate enough space for all configured extensions - some may be unused later\n\t\t// make sure memory is 4byte alligned\n\t\tsize_required = Max_num_extensions * sizeof(uint16_t) + sizeof(extension_map_t);\n\t\tsize_required = (size_required + 3) &~(size_t)3;\n\t\textension_map = malloc(size_required);\n\t\tif ( !extension_map ) {\n\t\t\tLogError(\"Process_ipfix: Panic! malloc() error in %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\treturn  NULL;\n\t\t}\n\t\textension_map->type \t   = ExtensionMapType;\n\t\t// Set size to an empty table - will be adapted later\n\t\textension_map->size \t   = sizeof(extension_map_t);\n\t\textension_map->map_id \t   = INIT_ID;\n\t\t// packed record size still unknown at this point - will be added later\n\t\textension_map->extension_size = 0;\n\n\t\ttable->extension_info.map \t = extension_map;\n\t\ttable->extension_map_changed = 1;\n\t\ttable->number_of_sequences \t = 0;\n \t} else {\n\t\textension_map = table->extension_info.map;\n\n\t\t// reset size/extension size - it's refreshed automatically\n\t\textension_map->size \t   \t  = sizeof(extension_map_t);\n\t\textension_map->extension_size = 0;\n\t\tfree((void *)table->sequence);\n\n\t\tdbg_printf(\"[%u] Refresh template %u\\n\", exporter->info.id, id);\n\t}\n\t// Add new sequence\n\ttable->sequence = calloc(cache.max_ipfix_elements, sizeof(sequence_map_t));\n\tif ( !table->sequence ) {\n\t\tLogError(\"Process_ipfix: Panic! malloc() error in %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\treturn  NULL;\n\t}\n\ttable->number_of_sequences = 0;\n\ttable->max_number_of_sequences = cache.max_ipfix_elements;\n\n\ttable->updated  \t= time(NULL);\n\t// IPFIX only has 64bit counters\n\ttable->flags\t\t\t= 0;\n\tSetFlag(table->flags, FLAG_PKG_64);\n\tSetFlag(table->flags, FLAG_BYTES_64);\n\ttable->delta_time\t\t= 0;\n\ttable->icmpTypeCodeIPv4\t= 0;\n\ttable->router_ip_offset = 0;\n\ttable->received_offset  = 0;\n\n\tdbg_printf(\"[%u] Build sequence table %u\\n\", exporter->info.id, id);\n\n\t// fill table\n\ttable->id \t\t\t= id;\n\n\t/* \n\t * common data block: The common record is expected in the output stream. If not available\n\t * in the template, fill values with 0\n\t */\n\n\t// All required extensions\n\t// The order we Push all ipfix elements, must corresponde to the structure of the common record\n\t// followed by all available extension in the extension map\n\toffset = BYTE_OFFSET_first;\n\tif ( cache.lookup_info[IPFIX_flowStartDeltaMicroseconds].found ) {\n\t\tPushSequence( table, IPFIX_flowStartDeltaMicroseconds, NULL, &table->flow_start);\n\t\tPushSequence( table, IPFIX_flowEndDeltaMicroseconds, NULL, &table->flow_end);\n\t\toffset = BYTE_OFFSET_first + 8;\n\t\ttable->delta_time = 1;\n\t\tdbg_printf(\"Time stamp: flow start/end delta microseconds: %u/%u\\n\",\n\t\t\tIPFIX_flowStartDeltaMicroseconds, IPFIX_flowEndDeltaMicroseconds);\n\t} else if ( cache.lookup_info[IPFIX_flowStartMilliseconds].found ) {\n\t\tPushSequence( table, IPFIX_flowStartMilliseconds, NULL, &table->flow_start);\n\t\tPushSequence( table, IPFIX_flowEndMilliseconds, NULL, &table->flow_end);\n\t\toffset = BYTE_OFFSET_first + 8;\n\t\tdbg_printf(\"Time stamp: flow start/end absolute milliseconds: %u/%u\\n\", \n\t\t\tIPFIX_flowStartMilliseconds, IPFIX_flowEndMilliseconds);\n\t} else if ( cache.lookup_info[IPFIX_flowStartSysUpTime].found ) {\n\t\tPushSequence( table, IPFIX_flowStartSysUpTime, NULL, &table->flow_start);\n\t\tPushSequence( table, IPFIX_flowEndSysUpTime, NULL, &table->flow_end);\n\t\toffset = BYTE_OFFSET_first + 8;\n\t\tdbg_printf(\"Time stamp: flow start/end relative milliseconds: %u/%u\\n\", \n\t\t\tIPFIX_flowStartSysUpTime, IPFIX_flowEndSysUpTime);\n\t} else if ( cache.lookup_info[IPFIX_flowStartSeconds].found ) {\n\t\tPushSequence( table, IPFIX_flowStartSeconds, NULL, &table->flow_start);\n\t\tPushSequence( table, IPFIX_flowEndSeconds, NULL, &table->flow_end);\n\t\toffset = BYTE_OFFSET_first + 8;\n\t\tdbg_printf(\"Time stamp: flow start/end absolute seconds: %u/%u\\n\", \n\t\t\tIPFIX_flowStartSeconds, IPFIX_flowEndSeconds);\n\t}else {\n\t\tdbg_printf(\"Time stamp: No known format found\\n\");\n\t\toffset = BYTE_OFFSET_first + 8;\n\t}\n\tPushSequence( table, IPFIX_forwardingStatus, &offset, NULL);\n\tPushSequence( table, IPFIX_tcpControlBits, &offset, NULL);\n\tPushSequence( table, IPFIX_protocolIdentifier, &offset, NULL);\n\tPushSequence( table, IPFIX_ipClassOfService, &offset, NULL);\n\n\tPushSequence( table, IPFIX_SourceTransportPort, &offset, NULL);\n\tPushSequence( table, IPFIX_DestinationTransportPort, &offset, NULL);\n\n\t// skip exporter_sysid and reserved\n\toffset += 4;\n\n\t/* IP address record\n\t * This record is expected in the output stream. If not available\n\t * in the template, assume empty v4 address.\n\t */\n\tif ( cache.lookup_info[IPFIX_SourceIPv4Address].found ) {\n\t\t// IPv4 addresses \n\t\tPushSequence( table, IPFIX_SourceIPv4Address, &offset, NULL);\n\t\tPushSequence( table, IPFIX_DestinationIPv4Address, &offset, NULL);\n\t} else if ( cache.lookup_info[IPFIX_SourceIPv6Address].found ) {\n\t\t// IPv6 addresses \n\t\tPushSequence( table, IPFIX_SourceIPv6Address, &offset, NULL);\n\t\tPushSequence( table, IPFIX_DestinationIPv6Address, &offset, NULL);\n\t\t// mark IPv6 \n\t\tSetFlag(table->flags, FLAG_IPV6_ADDR);\n\t\tipv6 = 1;\n\t} else {\n\t\t// should not happen, assume empty IPv4 addresses, zero\n\t\tPushSequence( table, IPFIX_SourceIPv4Address, &offset, NULL);\n\t\tPushSequence( table, IPFIX_DestinationIPv4Address, &offset, NULL);\n\t}\n\n\t// decide between Delta or Total  counters - prefer Total if available\n\tif ( cache.lookup_info[IPFIX_packetTotalCount].found )\n\t\tPushSequence( table, IPFIX_packetTotalCount, &offset, &table->packets);\n\telse\n\t\tPushSequence( table, IPFIX_packetDeltaCount, &offset, &table->packets);\n\tSetFlag(table->flags, FLAG_PKG_64);\n\n\tif ( cache.lookup_info[IPFIX_octetTotalCount].found )\n\t\tPushSequence( table, IPFIX_octetTotalCount, &offset, &table->bytes);\n\telse\n\t\tPushSequence( table, IPFIX_octetDeltaCount, &offset, &table->bytes);\n\tSetFlag(table->flags, FLAG_BYTES_64);\n\n\n\t// Optional extensions\n\tnext_extension = 0;\n\tfor (i=4; extension_descriptor[i].id; i++ ) {\n\t\tuint32_t map_index = i;\n\n\t\tif ( cache.common_extensions[i] == 0 )\n\t\t\tcontinue;\n\n\t\tswitch(i) {\n\t\t\tcase EX_IO_SNMP_2:\n\t\t\t\tPushSequence( table, IPFIX_ingressInterface, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_egressInterface, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_IO_SNMP_4:\n\t\t\t\tPushSequence( table, IPFIX_ingressInterface, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_egressInterface, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_AS_2:\n\t\t\t\tPushSequence( table, IPFIX_bgpSourceAsNumber, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_bgpDestinationAsNumber, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_AS_4:\n\t\t\t\tPushSequence( table, IPFIX_bgpSourceAsNumber, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_bgpDestinationAsNumber, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_MULIPLE:\n\t\t\t\tPushSequence( table, IPFIX_postIpClassOfService, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_flowDirection, &offset, NULL);\n\t\t\t\tif ( ipv6 ) {\n\t\t\t\t\t// IPv6\n\t\t\t\t\tPushSequence( table, IPFIX_SourceIPv6PrefixLength, &offset, NULL);\n\t\t\t\t\tPushSequence( table, IPFIX_DestinationIPv6PrefixLength, &offset, NULL);\n\t\t\t\t} else {\n\t\t\t\t\t// IPv4\n\t\t\t\t\tPushSequence( table, IPFIX_SourceIPv4PrefixLength, &offset, NULL);\n\t\t\t\t\tPushSequence( table, IPFIX_DestinationIPv4PrefixLength, &offset, NULL);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase EX_NEXT_HOP_v4:\n\t\t\t\tPushSequence( table, IPFIX_ipNextHopIPv4Address, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_NEXT_HOP_v6:\n\t\t\t\tPushSequence( table, IPFIX_ipNextHopIPv6Address, &offset, NULL);\n\t\t\t\tSetFlag(table->flags, FLAG_IPV6_NH);\n\t\t\t\tbreak;\n\t\t\tcase EX_NEXT_HOP_BGP_v4:\n\t\t\t\tPushSequence( table, IPFIX_bgpNextHopIPv4Address, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_NEXT_HOP_BGP_v6:\n\t\t\t\tPushSequence( table, IPFIX_bgpNextHopIPv6Address, &offset, NULL);\n\t\t\t\tSetFlag(table->flags, FLAG_IPV6_NHB);\n\t\t\t\tbreak;\n\t\t\tcase EX_VLAN:\n\t\t\t\tPushSequence( table, IPFIX_vlanId, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_postVlanId, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_OUT_PKG_4:\n\t\t\t\tPushSequence( table, IPFIX_postPacketDeltaCount, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_OUT_PKG_8:\n\t\t\t\tPushSequence( table, IPFIX_postPacketDeltaCount, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_OUT_BYTES_4:\n\t\t\t\tPushSequence( table, IPFIX_postOctetDeltaCount, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_OUT_BYTES_8:\n\t\t\t\tPushSequence( table, IPFIX_postOctetDeltaCount, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_AGGR_FLOWS_8:\n\t\t\t\tbreak;\n\t\t\tcase EX_MAC_1:\n\t\t\t\tPushSequence( table, IPFIX_SourceMacAddress, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_postDestinationMacAddress, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_MAC_2:\n\t\t\t\tPushSequence( table, IPFIX_DestinationMacAddress, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_postSourceMacAddress, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_MPLS:\n\t\t\t\tPushSequence( table, IPFIX_mplsTopLabelStackSection, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection2, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection3, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection4, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection5, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection6, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection7, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection8, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection9, &offset, NULL);\n\t\t\t\tPushSequence( table, IPFIX_mplsLabelStackSection10, &offset, NULL);\n\t\t\t\tbreak;\n\t\t\tcase EX_ROUTER_IP_v4:\n\t\t\tcase EX_ROUTER_IP_v6:\n\t\t\t\tif ( exporter->info.sa_family == PF_INET6 ) {\n\t\t\t\t\ttable->router_ip_offset = offset;\n\t\t\t\t\tdbg_printf(\"Router IPv6: offset: %u, olen: %u\\n\", offset, 16 );\n\t\t\t\t\t// not an entry for the translateion table.\n\t\t\t\t\t// but reserve space in the output record for IPv6\n\t\t\t\t\toffset\t\t\t \t   += 16;\n\t\t\t\t\tSetFlag(table->flags, FLAG_IPV6_EXP);\n\t\t\t\t\tmap_index = EX_ROUTER_IP_v6;\n\t\t\t\t} else {\n\t\t\t\t\ttable->router_ip_offset = offset;\n\t\t\t\t\tdbg_printf(\"Router IPv4: offset: %u, olen: %u\\n\", offset, 4 );\n\t\t\t\t\t// not an entry for the translateion table.\n\t\t\t\t\t// but reserve space in the output record for IPv4\n\t\t\t\t\toffset\t\t\t\t   += 4;\n\t\t\t\t\tClearFlag(table->flags, FLAG_IPV6_EXP);\n\t\t\t\t\tmap_index = EX_ROUTER_IP_v4;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase EX_ROUTER_ID:\n\t\t\t\t// no value in ipfix \n\t\t\t\tbreak;\n\t\t\tcase EX_RECEIVED:\n\t\t\t\ttable->received_offset = offset;\n\t\t\t\tdbg_printf(\"Received offset: %u\\n\", offset);\n\t\t\t\toffset\t\t\t\t   += 8;\n\t\t\t\tbreak;\n\n\t\t}\n\t\textension_map->size += sizeof(uint16_t);\n\t\textension_map->extension_size += extension_descriptor[map_index].size;\n\n\n\t\t// found extension in map_index must be the same as in map - otherwise map is dirty\n\t\tif ( extension_map->ex_id[next_extension] != map_index ) {\n\t\t\t// dirty map - needs to be refreshed in output stream\n\t\t\textension_map->ex_id[next_extension] = map_index;\n\t\t\ttable->extension_map_changed = 1;\n\n\t\t}\n\t\tnext_extension++;\n\n\t}\n\textension_map->ex_id[next_extension++] = 0;\n\n\t// make sure map is aligned\n\tif ( extension_map->size & 0x3 ) {\n\t\textension_map->ex_id[next_extension] = 0;\n\t\textension_map->size = ( extension_map->size + 3 ) &~ 0x3;\n\t}\n \n\ttable->output_record_size = offset;\n\n\t// for netflow historical reason, ICMP type/code goes into dst port field\n\t// remember offset, for decoding\n\tif ( cache.lookup_info[IPFIX_icmpTypeCodeIPv4].found && cache.lookup_info[IPFIX_icmpTypeCodeIPv4].length == 2 ) {\n\t\tPushSequence( table, IPFIX_icmpTypeCodeIPv4, NULL, &table->icmpTypeCodeIPv4);\n\t}\n\n#ifdef DEVEL\n\tif ( table->extension_map_changed ) {\n\t\tprintf(\"Extension Map id=%u changed!\\n\", extension_map->map_id);\n\t} else {\n\t\tprintf(\"[%u] template %u unchanged\\n\", exporter->info.id, id);\n\t}\n\n\tprintf(\"Process_ipfix: Check extension map: id: %d, size: %u, extension_size: %u\\n\", \n\t\textension_map->map_id, extension_map->size, extension_map->extension_size);\n\t{ int i;\n\tfor (i=0; i<table->number_of_sequences; i++ ) {\n\t\tprintf(\"Sequence %i: id: %u, Type: %u, Length: %u, Output offset: %u, stack: %llu\\n\",\n\t\t\ti, table->sequence[i].id, table->sequence[i].type, table->sequence[i].input_length, \n\t\t\ttable->sequence[i].output_offset, (unsigned long long)table->sequence[i].stack);\n\t}\n\tprintf(\"Flags: 0x%x output record size: %u\\n\", table->flags, table->output_record_size); \n\t}\n\tPrintExtensionMap(extension_map);\n#endif\n\n\treturn table;\n\n} // End of setup_translation_table\n\nstatic void InsertStdSamplerOffset( FlowSource_t *fs, uint16_t id, uint16_t offset_std_sampler_interval, uint16_t offset_std_sampler_algorithm) {\noption_offset_t **t;\n\n\tt = &(fs->option_offset_table);\n\twhile ( *t ) {\n\t\tif ( (*t)->id == id ) { // table already known to us - update data\n\t\t\tdbg_printf(\"Found existing std sampling info in template %i\\n\", id);\n\t\t\tbreak;\n\t\t}\n\t\n\t\tt = &((*t)->next);\n\t}\n\n\tif ( *t == NULL ) { // new table\n\t\tdbg_printf(\"Allocate new std sampling info from template %i\\n\", id);\n\t\t*t = (option_offset_t *)calloc(1, sizeof(option_offset_t));\n\t\tif ( !*t ) {\n\t\t\tLogError(\"malloc() allocation error at %s line %u: %s\" , __FILE__, __LINE__, strerror (errno));\n\t\t\treturn ;\n\t\t} \n\t\tLogInfo(\"Process_v9: New std sampler: interval: %i, algorithm: %i\", \n\t\t\toffset_std_sampler_interval, offset_std_sampler_algorithm);\n\t}   // else existing table\n\n\tdbg_printf(\"Insert/Update sampling info from template %i\\n\", id);\n\tSetFlag((*t)->flags, HAS_STD_SAMPLER_DATA);\n\t(*t)->id\t\t\t\t= id;\n\t(*t)->offset_id\t\t\t= 0;\n\t(*t)->offset_mode\t\t= 0;\n\t(*t)->offset_interval\t= 0;\n\t(*t)->offset_std_sampler_interval   = offset_std_sampler_interval;\n\t(*t)->offset_std_sampler_algorithm  = offset_std_sampler_algorithm;\n\t\n} // End of InsertStdSamplerOffset\n\nstatic void InsertSampler(FlowSource_t *fs, exporter_ipfix_domain_t *exporter, int32_t id, uint16_t mode, uint32_t interval) {\ngeneric_sampler_t *sampler;\n\n\tdbg_printf(\"[%u] Insert Sampler: Exporter is 0x%llu\\n\", exporter->info.id, (long long unsigned)exporter);\n\tif ( !exporter->sampler ) {\n\t\t// no samplers so far \n\t\tsampler = (generic_sampler_t *)malloc(sizeof(generic_sampler_t));\n\t\tif ( !sampler ) {\n\t\t\tLogError( \"Process_v9: Panic! malloc(): %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\treturn;\n\t\t}\n\n\t\tsampler->info.header.type = SamplerInfoRecordype;\n\t\tsampler->info.header.size = sizeof(sampler_info_record_t);\n\t\tsampler->info.exporter_sysid = exporter->info.sysid;\n\t\tsampler->info.id\t   = id;\n\t\tsampler->info.mode\t = mode;\n\t\tsampler->info.interval = interval;\n\t\tsampler->next\t\t  = NULL;\n\t\texporter->sampler = sampler;\n\n\t\tFlushInfoSampler(fs, &(sampler->info));\n\t\tLogInfo( \"Add new sampler: ID: %i, mode: %u, interval: %u\\n\", \n\t\t\tid, mode, interval);\n\t\tdbg_printf(\"Add new sampler: ID: %i, mode: %u, interval: %u\\n\", \n\t\t\tid, mode, interval);\n\n\t} else {\n\t\tsampler = exporter->sampler;\n\t\twhile ( sampler ) {\n\t\t\t// test for update of existing sampler\n\t\t\tif ( sampler->info.id == id ) {\n\t\t\t\t// found same sampler id - update record\n\t\t\t\tdbg_printf(\"Update existing sampler id: %i, mode: %u, interval: %u\\n\", \n\t\t\t\t\tid, mode, interval);\n\n\t\t\t\t// we update only on changes\n\t\t\t\tif ( mode != sampler->info.mode || interval != sampler->info.interval ) {\n\t\t\t\t\tFlushInfoSampler(fs, &(sampler->info));\n\t\t\t\t\tsampler->info.mode\t = mode;\n\t\t\t\t\tsampler->info.interval = interval;\n\t\t\t\t\tLogInfo( \"Update existing sampler id: %i, mode: %u, interval: %u\\n\", \n\t\t\t\t\t\tid, mode, interval);\n\t\t\t\t} else {\n\t\t\t\t\tdbg_printf(\"Sampler unchanged!\\n\");\n\t\t\t\t}\n\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// test for end of chain\n\t\t\tif ( sampler->next == NULL ) {\n\t\t\t\t// end of sampler chain - insert new sampler\n\t\t\t\tsampler->next = (generic_sampler_t *)malloc(sizeof(generic_sampler_t));\n\t\t\t\tif ( !sampler->next ) {\n\t\t\t\t\tLogError( \"Process_v9: Panic! malloc(): %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tsampler = sampler->next;\n\n\t\t\t\tsampler->info.header.type\t = SamplerInfoRecordype;\n\t\t\t\tsampler->info.header.size\t = sizeof(sampler_info_record_t);\n\t\t\t\tsampler->info.exporter_sysid = exporter->info.sysid;\n\t\t\t\tsampler->info.id\t   \t= id;\n\t\t\t\tsampler->info.mode\t\t= mode;\n\t\t\t\tsampler->info.interval\t= interval;\n\t\t\t\tsampler->next\t\t\t= NULL;\n\n\t\t\t\tFlushInfoSampler(fs, &(sampler->info));\n\n\t\t\t\tLogInfo( \"Append new sampler: ID: %u, mode: %u, interval: %u\\n\", \n\t\t\t\t\tid, mode, interval);\n\t\t\t\tdbg_printf(\"Append new sampler: ID: %u, mode: %u, interval: %u\\n\", \n\t\t\t\t\tid, mode, interval);\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t// advance\n\t\t\tsampler = sampler->next;\n\t\t}\n\t} \n\t\n} // End of InsertSampler\n\nstatic void Process_ipfix_templates(exporter_ipfix_domain_t *exporter, void *flowset_header, uint32_t size_left, FlowSource_t *fs) {\nipfix_template_record_t *ipfix_template_record;\nvoid *DataPtr;\nuint32_t count;\n\n\tsize_left \t   -= 4;\t// subtract message header\n\tDataPtr = flowset_header + 4;\n\n\tipfix_template_record = (ipfix_template_record_t *)DataPtr;\n\n\t// uint32_t\tid \t  = ntohs(ipfix_template_record->TemplateID);\n\tcount = ntohs(ipfix_template_record->FieldCount);\n\n\tif ( count == 0 ) {\n\t\t// withdraw template\n\t\tProcess_ipfix_template_withdraw(exporter, DataPtr, size_left, fs);\n\t} else {\n\t\t// refresh/add templates\n\t\tProcess_ipfix_template_add(exporter, DataPtr, size_left, fs);\n\t}\n\n} // End of Process_ipfix_templates\n\nstatic void Process_ipfix_template_add(exporter_ipfix_domain_t *exporter, void *DataPtr, uint32_t size_left, FlowSource_t *fs) {\ninput_translation_t *translation_table;\nipfix_template_record_t *ipfix_template_record;\nipfix_template_elements_std_t *NextElement;\nint i;\n\n\t// a template flowset can contain multiple records ( templates )\n\twhile ( size_left ) {\n\t\tuint32_t table_id, count, size_required;\n\t\tuint32_t num_extensions = 0;\n\n\t\tif ( size_left < 4 ) {\n\t\t\tLogError(\"Process_ipfix [%u] Template size error at %s line %u\" , \n\t\t\t\texporter->info.id, __FILE__, __LINE__, strerror (errno));\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// map next record.\n\t\tipfix_template_record = (ipfix_template_record_t *)DataPtr;\n\t\tsize_left \t\t-= 4;\n\n\t\ttable_id = ntohs(ipfix_template_record->TemplateID);\n\t\tcount\t = ntohs(ipfix_template_record->FieldCount);\n\n\t\tdbg_printf(\"\\n[%u] Template ID: %u\\n\", exporter->info.id, table_id);\n\t\tdbg_printf(\"FieldCount: %u buffersize: %u\\n\", count, size_left);\n\n\t\t// prepare\n\t\t// clear helper tables\n\t\tmemset((void *)cache.common_extensions, 0,  (Max_num_extensions+1)*sizeof(uint32_t));\n\t\tmemset((void *)cache.lookup_info, 0, 65536 * sizeof(struct element_param_s));\n\t\tfor (i=1; ipfix_element_map[i].id != 0; i++ ) {\n\t\t\tuint32_t Type = ipfix_element_map[i].id;\n\t\t\tif ( ipfix_element_map[i].id == ipfix_element_map[i-1].id )\n\t\t\t\tcontinue;\n\t\t\tcache.lookup_info[Type].index   = i;\n\t\t\t// other elements cleard be memset\n\t\t}\n\t\tcache.input_order = calloc(count, sizeof(struct order_s));\n\t\tif ( !cache.input_order ) {\n\t\t\tLogError(\"Process_ipfix: Panic! malloc(): %s line %d: %s\", __FILE__, __LINE__, strerror (errno));\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tcache.input_count = count;\n\n\t\t// assume all elements in template are std elements. correct this value, if we find an enterprise element\n\t\tsize_required   = 4*count;\n\t\tif ( size_left < size_required ) {\n\t\t\t// if we fail this check, this flowset must be skipped.\n\t\t\tLogError(\"Process_ipfix: [%u] Not enough data for template elements! required: %i, left: %u\", \n\t\t\t\t\texporter->info.id, size_required, size_left);\n\t\t\tdbg_printf(\"ERROR: Not enough data for template elements! required: %i, left: %u\", size_required, size_left);\n\t\t\treturn;\n\t\t}\n\n\t\t// process all elements in this record\n\t\tNextElement \t = (ipfix_template_elements_std_t *)ipfix_template_record->elements;\n\t\tfor ( i=0; i<count; i++ ) {\n\t\t\tuint16_t Type, Length;\n\t\t\tuint32_t ext_id;\n\t\t\tint Enterprise;\n\t\n\t\t\tType   = ntohs(NextElement->Type);\n\t\t\tLength = ntohs(NextElement->Length);\n\t\t\tEnterprise = Type & 0x8000 ? 1 : 0;\n\t\t\tType = Type & 0x7FFF;\n\n\t\t\text_id = MapElement(Type, Length, i);\n\n\t\t\t// do we store this extension? enabled != 0\n\t\t\t// more than 1 v9 tag may map to an extension - so count this extension once only\n\t\t\tif ( ext_id && extension_descriptor[ext_id].enabled ) {\n\t\t\t\tif ( cache.common_extensions[ext_id] == 0 ) {\n\t\t\t\t\tcache.common_extensions[ext_id] = 1;\n\t\t\t\t\tnum_extensions++;\n\t\t\t\t}\n\t\t\t} \n\t\n\t\t\tif ( Enterprise ) {\n\t\t\t\tipfix_template_elements_e_t *e = (ipfix_template_elements_e_t *)NextElement;\n\t\t\t\tsize_required += 4;\t// ad 4 for enterprise value\n\t\t\t\tif ( size_left < size_required ) {\n\t\t\t\t\tLogError(\"Process_ipfix: [%u] Not enough data for template elements! required: %i, left: %u\", \n\t\t\t\t\t\t\texporter->info.id, size_required, size_left);\n\t\t\t\t\tdbg_printf(\"ERROR: Not enough data for template elements! required: %i, left: %u\", size_required, size_left);\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tif ( ntohl(e->EnterpriseNumber) == IPFIX_ReverseInformationElement ) {\n\t\t\t\t\tdbg_printf(\" [%i] Enterprise: 1, Type: %u, Length %u Reverse Information Element: %u\\n\", i, Type, Length, ntohl(e->EnterpriseNumber));\n\t\t\t\t} else {\n\t\t\t\t\tdbg_printf(\" [%i] Enterprise: 1, Type: %u, Length %u EnterpriseNumber: %u\\n\", i, Type, Length, ntohl(e->EnterpriseNumber));\n\t\t\t\t}\n\t\t\t\te++;\n\t\t\t\tNextElement = (ipfix_template_elements_std_t *)e;\n\t\t\t} else {\n\t\t\t\tdbg_printf(\" [%i] Enterprise: 0, Type: %u, Length %u\\n\", i, Type, Length);\n\t\t\t\tNextElement++;\n\t\t\t}\n\t\t}\n\n\t\tdbg_printf(\"Processed: %u\\n\", size_required);\n\n\t\t// compact input order and reorder sequencer\n\t\tif ( compact_input_order() ) {\n\t\t\t// valid template with common inout fields\n\n\t\t\t// as the router IP address extension is not part announced in a template, we need to deal with it here\n\t\t\tif ( extension_descriptor[EX_ROUTER_IP_v4].enabled ) {\n\t\t\t\tif ( cache.common_extensions[EX_ROUTER_IP_v4] == 0 ) {\n\t\t\t\t\tcache.common_extensions[EX_ROUTER_IP_v4] = 1;\n\t\t\t\t\tnum_extensions++;\n\t\t\t\t}\n\t\t\t\tdbg_printf(\"Add sending router IP address (%s) => Extension: %u\\n\", \n\t\t\t\t\tfs->sa_family == PF_INET6 ? \"ipv6\" : \"ipv4\", EX_ROUTER_IP_v4);\n\t\t\t}\n\t\n\t\t\t// XXX for now, we do not store router ID in IPFIX\n\t\t\textension_descriptor[EX_ROUTER_ID].enabled = 0;\n\n/*\t\n\t\t// as the router IP address extension is not part announced in a template, we need to deal with it here\n\t\tif ( extension_descriptor[EX_ROUTER_ID].enabled ) {\n\t\t\tif ( cache.common_extensions[EX_ROUTER_ID] == 0 ) {\n\t\t\t\tcache.common_extensions[EX_ROUTER_ID] = 1;\n\t\t\t\tnum_extensions++;\n\t\t\t}\n\t\t\tdbg_printf(\"Force add router ID (engine type/ID), Extension: %u\\n\", EX_ROUTER_ID);\n\t\t}\n*/\n\t\t\t// received time \n\t\t\tif ( extension_descriptor[EX_RECEIVED].enabled ) {\n\t\t\t\tif ( cache.common_extensions[EX_RECEIVED] == 0 ) {\n\t\t\t\t\tcache.common_extensions[EX_RECEIVED] = 1;\n\t\t\t\t\tnum_extensions++;\n\t\t\t\t}\n\t\t\t\tdbg_printf(\"Force add packet received time, Extension: %u\\n\", EX_RECEIVED);\n\t\t\t}\n\n#ifdef DEVEL\n\t\t{\n\t\t\tint i;\n\t\t\tfor (i=4; extension_descriptor[i].id; i++ ) {\n\t\t\t\tif ( cache.common_extensions[i] ) {\n\t\t\t\t\tprintf(\"Enabled extension: %i\\n\", i);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n#endif\n\t\n\t\t\ttranslation_table = setup_translation_table(exporter, table_id);\n\t\t\tif (translation_table->extension_map_changed ) {\n\t\t\t\t// refresh he map in the ouput buffer\n\t\t\t\tdbg_printf(\"Translation Table changed! Add extension map ID: %i\\n\", translation_table->extension_info.map->map_id);\n\t\t\t\tAddExtensionMap(fs, translation_table->extension_info.map);\n\t\t\t\ttranslation_table->extension_map_changed = 0;\n\t\t\t\tdbg_printf(\"Translation Table added! map ID: %i\\n\", translation_table->extension_info.map->map_id);\n\t\t\t}\n\t\n\t\t\tif ( !reorder_sequencer(translation_table) ) {\n\t\t\t\tLogError(\"Process_ipfix: [%u] Failed to reorder sequencer. Remove table id: %u\", \n\t\t\t\t\t\t\texporter->info.id, table_id);\n\t\t\t\tremove_translation_table(fs, exporter, table_id);\n\t\t\t}\n\t\t} else {\n\t\t\tdbg_printf(\"Template does not contain any common fields - skip\\n\");\n\t\t}\n\t\t// update size left of this flowset\n\t\tsize_left -= size_required;\n\t\tDataPtr = DataPtr + size_required+4;\t// +4 for header\n\t\tif ( size_left < 4 ) {\n\t\t\t// pading\n\t\t\tdbg_printf(\"Skip %u bytes padding\\n\", size_left);\n\t\t\tsize_left = 0;\n\t\t}\n\t\tfree(cache.input_order);\n\t\tcache.input_order = NULL;\n\t}\n\n} // End of Process_ipfix_template_add\n\nstatic void Process_ipfix_template_withdraw(exporter_ipfix_domain_t *exporter, void *DataPtr, uint32_t size_left, FlowSource_t *fs) {\nipfix_template_record_t *ipfix_template_record;\n\n\t// a template flowset can contain multiple records ( templates )\n\twhile ( size_left ) {\n\t\tuint32_t id;\n\n\t\tif ( size_left < 4 ) {\n\t\t\tLogError(\"Process_ipfix [%u] Template withdraw size error at %s line %u\" , \n\t\t\t\texporter->info.id, __FILE__, __LINE__, strerror (errno));\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\n\t\t// map next record.\n\t\tipfix_template_record = (ipfix_template_record_t *)DataPtr;\n\t\tsize_left \t\t-= 4;\n\n\t\tid \t  = ntohs(ipfix_template_record->TemplateID);\n\t\t// count = ntohs(ipfix_template_record->FieldCount);\n\n\t\tif ( id == IPFIX_TEMPLATE_FLOWSET_ID ) {\n\t\t\t// withdraw all templates\n\t\t\tremove_all_translation_tables(exporter);\n\t\t\tReInitExtensionMapList(fs);\n\t\t} else {\n\t\t\tremove_translation_table(fs, exporter, id);\n\t\t}\n\n\t\tDataPtr = DataPtr + 4;\n\t\tif ( size_left < 4 ) {\n\t\t\t// pading\n\t\t\tdbg_printf(\"Skip %u bytes padding\\n\", size_left);\n\t\t\tsize_left = 0;\n\t\t}\n\t}\n \n} // End of Process_ipfix_template_withdraw\n\nstatic void Process_ipfix_option_templates(exporter_ipfix_domain_t *exporter, void *option_template_flowset, FlowSource_t *fs) {\nuint8_t\t\t*DataPtr;\nuint32_t\tsize_left, size_required, i;\n// uint32_t nr_scopes, nr_options;\nuint16_t\tid, field_count, scope_field_count, offset;\nuint16_t\toffset_std_sampler_interval, offset_std_sampler_algorithm, found_std_sampling;\n\n\ti = 0;\t// keep compiler happy\n\tsize_left \t\t  = GET_FLOWSET_LENGTH(option_template_flowset) - 4; // -4 for flowset header -> id and length\n\tif ( size_left < 6 ) {\n\t\tLogError(\"Process_ipfix: [%u] option template length error: size left %u too small for an options template\", \n\t\t\texporter->info.id, size_left);\n\t\treturn;\n\t}\n\n\tDataPtr   \t\t  = option_template_flowset + 4;\n\tid \t  \t\t\t  = GET_OPTION_TEMPLATE_ID(DataPtr); \n\tfield_count \t  = GET_OPTION_TEMPLATE_FIELD_COUNT(DataPtr);\n\tscope_field_count = GET_OPTION_TEMPLATE_SCOPE_FIELD_COUNT(DataPtr);\n\tDataPtr   += 6;\n\tsize_left -= 6;\n\n\tdbg_printf(\"Decode Option Template. id: %u, field count: %u, scope field count: %u\\n\",\n\t\tid, field_count, scope_field_count);\n\n\tif ( scope_field_count == 0  ) {\n\t\tLogError(\"Process_ipfx: [%u] scope field count error: length must not be zero\", \n\t\t\texporter->info.id);\n\t\tdbg_printf(\"scope field count error: length must not be zero\\n\");\n\t\treturn;\n\t}\n\n\tsize_required = 2 * field_count * sizeof(uint16_t);\n\tdbg_printf(\"Size left: %u, size required: %u\\n\", size_left, size_required);\n\tif ( size_left < size_required ) {\n\t\tLogError(\"Process_ipfix: [%u] option template length error: size left %u too small for %u scopes length and %u options length\", \n\t\t\texporter->info.id, size_left, field_count, scope_field_count);\n\t\tdbg_printf(\"option template length error: size left %u too small for field_count %u\\n\", \n\t\t\tsize_left, field_count);\n\t\treturn;\n\t}\n\n\tif ( scope_field_count == 0  ) {\n\t\tLogError(\"Process_ipfxi: [%u] scope field count error: length must not be zero\", \n\t\t\texporter->info.id);\n\t\treturn;\n\t}\n\n\toffset_std_sampler_interval  = 0;\n\toffset_std_sampler_algorithm = 0;\n\tfound_std_sampling\t\t\t = 0;\n\toffset = 0;\n\n\tfor ( i=0; i<scope_field_count; i++ ) {\n\t\tuint16_t id, length;\n\t\tint Enterprise;\n\n\t\tif ( size_left && size_left < 4 ) {\n\t\t\tLogError(\"Process_ipfix [%u] Template size error at %s line %u\" , \n\t\t\t\texporter->info.id, __FILE__, __LINE__, strerror (errno));\n\t\t\treturn;\n\t\t}\n\t\tid \t   = Get_val16(DataPtr); DataPtr += 2;\n\t\tlength = Get_val16(DataPtr); DataPtr += 2;\n\t\tsize_left -= 4;\n\t\tEnterprise = id & 0x8000 ? 1 : 0;\n\t\tif ( Enterprise ) {\n\t\t\tsize_required += 4;\n\t\t\tif ( size_left < 4 ) {\n\t\t\t\tLogError(\"Process_ipfix: [%u] option template length error: size left %u too small\", \n\t\t\t\t\texporter->info.id, size_left);\n\t\t\t\tdbg_printf(\"option template length error: size left %u too small\\n\", size_left);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tDataPtr += 4;\n\t\t\tsize_left -= 4;\n\t\t\tdbg_printf(\" [%i] Enterprise: 1, scope id: %u, scope length %u enterprise value: %u\\n\", \n\t\t\t\ti, id, length, Get_val32(DataPtr));\n\t\t} else {\n\t\t\tdbg_printf(\" [%i] Enterprise: 0, scope id: %u, scope length %u\\n\", i, id, length);\n\t\t}\n\n\t\toffset += length;\n\t}\n\n\tfor ( ;i<field_count; i++ ) {\n\t\tuint32_t enterprise_value;\n\t\tuint16_t id, length;\n\t\tint Enterprise;\n\n\t\t// keep compiler happy\n\t\tUNUSED(enterprise_value);\n\t\tid \t   = Get_val16(DataPtr); DataPtr += 2;\n\t\tlength = Get_val16(DataPtr); DataPtr += 2;\n\t\tsize_left -= 4;\n\t\tEnterprise = id & 0x8000 ? 1 : 0;\n\t\tif ( Enterprise ) {\n\t\t\tsize_required += 4;\n\t\t\tif ( size_left < 4 ) {\n\t\t\t\tLogError(\"Process_ipfix: [%u] option template length error: size left %u too\", \n\t\t\t\t\texporter->info.id, size_left);\n\t\t\t\tdbg_printf(\"option template length error: size left %u too small\\n\", size_left);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tenterprise_value = Get_val32(DataPtr);\n\t\t\tDataPtr += 4;\n\t\t\tsize_left -= 4;\n\t\t\tdbg_printf(\" [%i] Enterprise: 1, option id: %u, option length %u enterprise value: %u\\n\", \n\t\t\t\ti, id, length, enterprise_value);\n\t\t} else {\n\t\t\tdbg_printf(\" [%i] Enterprise: 0, option id: %u, option length %u\\n\", i, id, length);\n\t\t}\n\n\t\tswitch (id) {\n\t\t\t// general sampling\n\t\t\tcase IPFIX_samplingInterval:\t\t// legacy #34\n\t\t\tcase IPFIX_samplingPacketInterval:\t// #305\n\t\t\t\tif ( length == 4 ) {\n\t\t\t\t\toffset_std_sampler_interval = offset;\n\t\t\t\t\tfound_std_sampling++;\n\t\t\t\t\tdbg_printf(\"\t4 byte sampling interval option at offset: %u\\n\", offset);\n\t\t\t\t} else {\n\t\t\t\t\tLogError(\"Process_ipfix: [%u] option template error: sampling option lenth != 4 bytes: %u\", \n\t\t\t\t\t\texporter->info.id, length);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase IPFIX_samplingAlgorithm:\t// legacy #35\n\t\t\tcase IPFIX_selectorAlgorithm:\t// #304\n\t\t\t\tif ( length == 1 ) {\n\t\t\t\t\toffset_std_sampler_algorithm = offset;\n\t\t\t\t\tdbg_printf(\"\t1 byte sampling algorithm option at offset: %u\\n\", offset);\n\t\t\t\t\tfound_std_sampling++;\n\t\t\t\t} else {\n\t\t\t\t\tLogError(\"Process_ipfix: [%u] option template error: algorithm option lenth != 1 byte: %u\", \n\t\t\t\t\t\texporter->info.id, length);\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t}\n\n\t\toffset += length;\n\t}\n\n\tif ( offset_std_sampler_interval ) {\n        dbg_printf(\"[%u] Std sampling interval found. offset: %u\\n\", \n\t\t\texporter->info.id, offset_std_sampler_interval);\n\t\tif ( offset_std_sampler_algorithm )\n        \tdbg_printf(\"[%u] Std sampling algorithm found. offset: %u\\n\", \n\t\t\texporter->info.id, offset_std_sampler_algorithm);\n        InsertStdSamplerOffset(fs, id, offset_std_sampler_interval, offset_std_sampler_algorithm);\n\t\tdbg_printf(\"\\n\");\n\t}\n\n\tprocessed_records++;\n\n} // End of Process_ipfix_option_templates\n\n\nstatic void Process_ipfix_data(exporter_ipfix_domain_t *exporter, uint32_t ExportTime, void *data_flowset, FlowSource_t *fs, input_translation_t *table ){\nuint64_t\t\t\tsampling_rate;\nuint32_t\t\t\tsize_left;\nuint8_t\t\t\t\t*in, *out;\nint\t\t\t\t\ti;\nchar\t\t\t\t*string;\n\n\tsize_left = GET_FLOWSET_LENGTH(data_flowset) - 4; // -4 for data flowset header -> id and length\n\n\t// map input buffer as a byte array\n\tin  \t  = (uint8_t *)(data_flowset + 4);\t// skip flowset header\n\n\tdbg_printf(\"[%u] Process data flowset size: %u\\n\", exporter->info.id, size_left);\n\n\n\t// Check if sampling is announced\n\tsampling_rate = 1;\n\n\tgeneric_sampler_t *sampler = exporter->sampler;\n\twhile ( sampler && sampler->info.id != -1 ) \n\t\tsampler = sampler->next;\n\n\tif ( sampler ) {\n\t\tsampling_rate = sampler->info.interval;\n\t\tdbg_printf(\"[%u] Std sampling available for this flow source: Rate: %llu\\n\", exporter->info.id, (long long unsigned)sampling_rate);\n\t} else {\n\t\tsampling_rate = default_sampling;\n\t\tdbg_printf(\"[%u] No Sampling record found\\n\", exporter->info.id);\n\t}\n\n\tif ( overwrite_sampling > 0 )  {\n\t\tsampling_rate = overwrite_sampling;\n\t\tdbg_printf(\"[%u] Hard overwrite sampling rate: %llu\\n\", exporter->info.id, (long long unsigned)sampling_rate);\n\t} \n\n\tif ( sampling_rate != 1 )\n\t\tSetFlag(table->flags, FLAG_SAMPLED);\n\n\twhile (size_left) {\n\t\tint input_offset;\n\t\tcommon_record_t\t\t*data_record;\n\n\t\tif ( size_left < 4 ) {\t// rounding pads\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t// check for enough space in output buffer\n\t\tif ( !CheckBufferSpace(fs->nffile, table->output_record_size) ) {\n\t\t\t// this should really never occur, because the buffer gets flushed ealier\n\t\t\tLogError(\"Process_ipfix: output buffer size error. Abort ipfix record processing\");\n\t\t\tdbg_printf(\"Process_ipfix: output buffer size error. Abort ipfix record processing\");\n\t\t\treturn;\n\t\t}\n\t\tprocessed_records++;\n\t\texporter->PacketSequence++;\n\n\t\t// map file record to output buffer\n\t\tdata_record\t= (common_record_t *)fs->nffile->buff_ptr;\n\t\t// map output buffer as a byte array\n\t\tout \t  = (uint8_t *)data_record;\n\n\t\tdbg_printf(\"[%u] Process data record: %u addr: %llu, buffer size_left: %u\\n\", \n\t\t\texporter->info.id, processed_records, (long long unsigned)((ptrdiff_t)in - (ptrdiff_t)data_flowset), \n\t\t\tsize_left);\n\n\t\t// fill the data record\n\t\tdata_record->flags \t\t    = table->flags;\n\t\tdata_record->size  \t\t    = table->output_record_size;\n\t\tdata_record->type  \t\t    = CommonRecordType;\n\t  \tdata_record->ext_map\t    = table->extension_info.map->map_id;\n\t\tdata_record->exporter_sysid = exporter->info.sysid;\n\t\tdata_record->reserved \t\t= 0;\n\n\t\ttable->flow_start \t\t    = 0;\n\t\ttable->flow_end \t\t    = 0;\n\t\ttable->packets \t\t  \t    = 0;\n\t\ttable->bytes \t\t  \t    = 0;\n\t\ttable->out_packets \t  \t    = 0;\n\t\ttable->out_bytes \t  \t    = 0;\n\n\t\tinput_offset = 0;\n\t\t// apply copy and processing sequence\n\t\tfor ( i=0; i<table->number_of_sequences; i++ ) {\n\t\t\tint output_offset = table->sequence[i].output_offset;\n\t\t\tvoid *stack = table->sequence[i].stack;\n\n\t\t\tif ( input_offset > size_left ) {\n\t\t\t\t// overrun\n\t\t\t\tLogError(\"Process ipfix: buffer overrun!! input_offset: %i > size left data buffer: %u\\n\", input_offset, size_left);\n\t\t\t\treturn;\n\t\t\t} \n\n\t\t\tswitch (table->sequence[i].id) {\n\t\t\t\tcase nop:\n\t\t\t\t\tbreak;\n\t\t\t\tcase dyn_skip: {\n\t\t\t\t\tuint16_t skip = in[input_offset];\n\t\t\t\t\tif ( skip < 255 ) {\n\t\t\t\t\t\tinput_offset += (skip+1);\n\t\t\t\t\t} else {\n\t\t\t\t\t\tskip = Get_val16((void *)&in[input_offset+1]);\n\t\t\t\t\t\tinput_offset += (skip+3);\n\t\t\t\t\t}\n\t\t\t\t\t} break;\n\t\t\t\tcase move8:\n\t\t\t\t\tout[output_offset] = in[input_offset];\n\t\t\t\t\tbreak;\n\t\t\t\tcase move16:\n\t\t\t\t\t*((uint16_t *)&out[output_offset]) = Get_val16((void *)&in[input_offset]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase move32:\n\t\t\t\t\t*((uint32_t *)&out[output_offset]) = Get_val32((void *)&in[input_offset]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase move40:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\n\t\t\t\t\t\tt.val.val64 = Get_val40((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase move48:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t\tt.val.val64 = Get_val48((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase move56:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\n\t\t\t\t\t\tt.val.val64 = Get_val56((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase move64: \n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t\tt.val.val64 = Get_val64((void *)&in[input_offset]);\n\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t} break;\n\t\t\t\tcase move128: \n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t  \n\t\t\t\t\t\tt.val.val64 = Get_val64((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t  = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4])  = t.val.val32[1];\n\n\t\t\t\t\t\tt.val.val64 = Get_val64((void *)&in[input_offset+8]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+8])  = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+12]) = t.val.val32[1];\n\t\t\t\t\t} break;\n\t\t\t\tcase move32_sampling:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t\tt.val.val64 = Get_val32((void *)&in[input_offset]);\n\t\t\t\t\t\tt.val.val64 *= sampling_rate;\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t  \t*(uint64_t *)stack = t.val.val64;\n\t\t\t\t\t} break;\n\t\t\t\tcase move64_sampling:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\t\t\t\t\t\tt.val.val64 = Get_val64((void *)&in[input_offset]);\n\n\t\t\t\t\t\tt.val.val64 *= sampling_rate;\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset]) \t = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t  \t*(uint64_t *)stack = t.val.val64;\n\t\t\t\t\t} break;\n\t\t\t\tcase Time64Mili:\n\t\t\t\t\t{ uint64_t DateMiliseconds = Get_val64((void *)&in[input_offset]);\n\t\t\t\t\t  *(uint64_t *)stack = DateMiliseconds;\n\n\t\t\t\t\t} break;\n\t\t\t\tcase TimeUnix:\n\t\t\t\t\t{ uint64_t DateSeconds = Get_val32((void *)&in[input_offset]);\n\t\t\t\t\t  *(uint64_t *)stack = DateSeconds *1000LL;\n\n\t\t\t\t\t} break;\n\t\t\t\tcase TimeDeltaMicro:\n\t\t\t\t\t{ uint64_t DeltaMicroSec = Get_val32((void *)&in[input_offset]);\n\t\t\t\t\t  *(uint64_t *)stack = ((1000000LL * (uint64_t)ExportTime) - DeltaMicroSec) / 1000LL;\n\n\t\t\t\t\t} break;\n\t\t\t\tcase saveICMP:\n\t\t\t\t\t*(uint32_t *)stack = Get_val16((void *)&in[input_offset]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase move_mpls:\n\t\t\t\t\t*((uint32_t *)&out[output_offset]) = Get_val24((void *)&in[input_offset]);\n\t\t\t\t\tbreak;\n\t\t\t\tcase move_flags: {\n\t\t\t\t\tuint16_t flags = Get_val16((void *)&in[input_offset]);\n\t\t\t\t\t// cut upper byte\n\t\t\t\t\tout[output_offset] = flags & 0xFF;\n\t\t\t\t\t} break;\n\t\t\t\tcase move_mac:\n\t\t\t\t\t/* 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs */\n\t\t\t\t\t{ type_mask_t t;\n\n\t\t\t\t\t\tt.val.val64 = Get_val48((void *)&in[input_offset]);\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset])   = t.val.val32[0];\n\t\t\t\t\t\t*((uint32_t *)&out[output_offset+4]) = t.val.val32[1];\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\tcase zero8:\n\t\t\t\t\tout[output_offset] = 0;\n\t\t\t\t\tbreak;\n\t\t\t\tcase zero16:\n\t\t\t\t\t*((uint16_t *)&out[output_offset]) = 0;\n\t\t\t\t\tbreak;\n\t\t\t\tcase zero32:\n\t\t\t\t\t*((uint32_t *)&out[output_offset]) = 0;\n\t\t\t\t\tbreak;\n\t\t\t\tcase zero64: \n\t\t\t\t\t\t*((uint64_t *)&out[output_offset]) = 0;\n\t\t\t\t\t break;\n\t\t\t\tcase zero128: \n\t\t\t\t\t\t*((uint64_t *)&out[output_offset]) = 0;\n\t\t\t\t\t\t*((uint64_t *)&out[output_offset+8]) = 0;\n\t\t\t\t\tbreak;\n\t\t\t\t\n\t\t\t\tdefault:\n\t\t\t\t\tLogError(\"Process_ipfix: Software bug! Unknown Sequence: %u. at %s line %d\", \n\t\t\t\t\t\ttable->sequence[i].id, __FILE__, __LINE__);\n\t\t\t\t\tdbg_printf(\"Software bug! Unknown Sequence: %u. at %s line %d\\n\", \n\t\t\t\t\t\ttable->sequence[i].id, __FILE__, __LINE__);\n\t\t\t}\n\t\t\tinput_offset += (table->sequence[i].input_length + table->sequence[i].skip_count);\n\t\t}\n\n\t\t// for netflow historical reason, ICMP type/code goes into dst port field\n\t\tif ( data_record->prot == IPPROTO_ICMP || data_record->prot == IPPROTO_ICMPV6 ) {\n\t\t\tif ( table->icmpTypeCodeIPv4 ) {\n\t\t\t\tdata_record->srcport = 0;\n\t\t\t\tdata_record->dstport = table->icmpTypeCodeIPv4;\n\t\t\t\t// data_record->dstport = Get_val16((void *)&in[table->ICMP_offset]);\n\t\t\t}\n\t\t}\n\n\t\t// check, if we need to store the packet received time\n\t\tif ( table->received_offset ) {\n\t\t\ttype_mask_t t;\n\t\t\tt.val.val64 = (uint64_t)((uint64_t)fs->received.tv_sec * 1000LL) + (uint64_t)((uint64_t)fs->received.tv_usec / 1000LL);\n\t\t\t\t*((uint32_t *)&out[table->received_offset])   = t.val.val32[0];\n\t\t\t\t*((uint32_t *)&out[table->received_offset+4]) = t.val.val32[1];\n\t\t}\n\n\t\t// split first/last time into epoch/msec values\n\t\tdata_record->first \t\t= table->flow_start / 1000;\n\t\tdata_record->msec_first = table->flow_start % 1000;\n\n\t\tdata_record->last \t\t= table->flow_end / 1000;\n\t\tdata_record->msec_last\t= table->flow_end % 1000;\n\n\t\t// update first_seen, last_seen\n\t\tif ( table->flow_start < fs->first_seen )\n\t\t\tfs->first_seen = table->flow_start;\n\t\tif ( table->flow_end > fs->last_seen )\n\t\t\tfs->last_seen = table->flow_end;\n\n\t\t// check if we need to record the router IP address\n\t\tif ( table->router_ip_offset ) {\n\t\t\tint output_offset = table->router_ip_offset;\n\t\t\tif ( exporter->info.sa_family == PF_INET6 ) {\n\t\t\t\t// 64bit access to potentially unaligned output buffer. use 2 x 32bit for _LP64 CPUs \n\t\t\t\ttype_mask_t t;\n\t\t\t\t\t  \n\t\t\t\tt.val.val64 = exporter->info.ip.V6[0];\n\t\t\t\t*((uint32_t *)&out[output_offset]) \t  = t.val.val32[0];\n\t\t\t\t*((uint32_t *)&out[output_offset+4])  = t.val.val32[1];\n\n\t\t\t\tt.val.val64 = exporter->info.ip.V6[1];\n\t\t\t\t*((uint32_t *)&out[output_offset+8])  = t.val.val32[0];\n\t\t\t\t*((uint32_t *)&out[output_offset+12]) = t.val.val32[1];\n\t\t\t} else {\n\t\t\t\t*((uint32_t *)&out[output_offset]) = exporter->info.ip.V4;\n\t\t\t}\n\t\t}\n\n\t\tswitch (data_record->prot ) { // switch protocol of\n\t\t\tcase IPPROTO_ICMP:\n\t\t\t\tfs->nffile->stat_record->numflows_icmp++;\n\t\t\t\tfs->nffile->stat_record->numpackets_icmp  += table->packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_icmp    += table->bytes;\n\t\t\t\tfs->nffile->stat_record->numpackets_icmp  += table->out_packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_icmp    += table->out_bytes;\n\t\t\t\tbreak;\n\t\t\tcase IPPROTO_TCP:\n\t\t\t\tfs->nffile->stat_record->numflows_tcp++;\n\t\t\t\tfs->nffile->stat_record->numpackets_tcp   += table->packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_tcp     += table->bytes;\n\t\t\t\tfs->nffile->stat_record->numpackets_tcp   += table->out_packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_tcp     += table->out_bytes;\n\t\t\t\tbreak;\n\t\t\tcase IPPROTO_UDP:\n\t\t\t\tfs->nffile->stat_record->numflows_udp++;\n\t\t\t\tfs->nffile->stat_record->numpackets_udp   += table->packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_udp     += table->bytes;\n\t\t\t\tfs->nffile->stat_record->numpackets_udp   += table->out_packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_udp     += table->out_bytes;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tfs->nffile->stat_record->numflows_other++;\n\t\t\t\tfs->nffile->stat_record->numpackets_other += table->packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_other   += table->bytes;\n\t\t\t\tfs->nffile->stat_record->numpackets_other += table->out_packets;\n\t\t\t\tfs->nffile->stat_record->numbytes_other   += table->out_bytes;\n\t\t}\n\t\texporter->flows++;\n\t\tfs->nffile->stat_record->numflows++;\n\t\tfs->nffile->stat_record->numpackets\t+= table->packets;\n\t\tfs->nffile->stat_record->numbytes\t+= table->bytes;\n\t\tfs->nffile->stat_record->numpackets\t+= table->out_packets;\n\t\tfs->nffile->stat_record->numbytes\t+= table->out_bytes;\n\t\n\t\tif ( verbose ) {\n\t\t\tmaster_record_t master_record;\n\t\t\tmemset((void *)&master_record, 0, sizeof(master_record_t));\n\t\t\tExpandRecord_v2((common_record_t *)data_record, &(table->extension_info), &(exporter->info), &master_record);\n\t\t \tformat_file_block_record(&master_record, &string, 0);\n\t\t\tprintf(\"%s\\n\", string);\n\t\t}\n\n\t\tfs->nffile->block_header->size  += data_record->size;\n\t\tfs->nffile->block_header->NumRecords++;\n\t\tfs->nffile->buff_ptr\t= (common_record_t *)((pointer_addr_t)data_record + data_record->size);\n\n\t\t// advance input\n\t\tdbg_printf(\"Adjust input stream offset: %u\\n\", input_offset);\n\t\tif ( input_offset > size_left ) {\n\t\t\t// overrun\n\t\t\tLogError(\"Process ipfix: buffer overrun!! input_offset: %i > size left data buffer: %u\\n\", input_offset, size_left);\n\t\t\treturn;\n\t\t} \n\t\tsize_left \t\t   -= input_offset;\n\t\tin  \t  \t\t   += input_offset;\n\n\t\t// buffer size sanity check\n\t\tif ( fs->nffile->block_header->size  > BUFFSIZE ) {\n\t\t\t// should never happen\n\t\t\tLogError(\"### Software error ###: %s line %d\", __FILE__, __LINE__);\n\t\t\tLogError(\"Process ipfix: Output buffer overflow! Flush buffer and skip records.\");\n\t\t\tLogError(\"Buffer size: %u > %u\", fs->nffile->block_header->size, BUFFSIZE);\n\n\t\t\t// reset buffer\n\t\t\tfs->nffile->block_header->size \t\t= 0;\n\t\t\tfs->nffile->block_header->NumRecords = 0;\n\t\t\tfs->nffile->buff_ptr = (void *)((pointer_addr_t)fs->nffile->block_header + sizeof(data_block_header_t) );\n\t\t\treturn;\n\t\t}\n\n\t}\n\n} // End of Process_ipfix_data\n\nstatic void  Process_ipfix_option_data(exporter_ipfix_domain_t *exporter, void *data_flowset, FlowSource_t *fs) {\noption_offset_t *offset_table;\nuint32_t\tid;\nuint8_t\t *in;\n\n\tid  = GET_FLOWSET_ID(data_flowset);\n\n\toffset_table = fs->option_offset_table;\n\twhile ( offset_table && offset_table->id != id )\n\t\toffset_table = offset_table->next;\n\n\tif ( !offset_table ) {\n\t\t// should never happen - catch it anyway\n\t\tLogError( \"Process_ipfix: Panic! - No Offset table found! : %s line %d\", __FILE__, __LINE__);\n\t\treturn;\n\t}\n\n#ifdef DEVEL\n\tuint32_t size_left = GET_FLOWSET_LENGTH(data_flowset) - 4; // -4 for data flowset header -> id and length\n\tdbg_printf(\"[%u] Process option data flowset size: %u\\n\", exporter->info.id, size_left);\n#endif\n\n\t// map input buffer as a byte array\n\tin\t= (uint8_t *)(data_flowset + 4);  // skip flowset header\n\n\tif ( TestFlag(offset_table->flags, HAS_SAMPLER_DATA) ) {\n\t\tint32_t  id;\n\t\tuint16_t mode;\n\t\tuint32_t interval;\n\t\tif (offset_table->sampler_id_length == 2) {\n\t\t\tid = Get_val16((void *)&in[offset_table->offset_id]);\n\t\t} else {\n\t\t\tid = in[offset_table->offset_id];\n\t\t}\n\n\t\tmode = offset_table->offset_mode ? in[offset_table->offset_mode] : 0;\n\t\tinterval = Get_val32((void *)&in[offset_table->offset_interval]); \n\t\n\t\tInsertSampler(fs, exporter, id, mode, interval);\n\n\t\tdbg_printf(\"Extracted Sampler data:\\n\");\n\t\tdbg_printf(\"Sampler ID\t  : %u\\n\", id);\n\t\tdbg_printf(\"Sampler mode\t: %u\\n\", mode);\n\t\tdbg_printf(\"Sampler interval: %u\\n\", interval);\n\t}\n\n\tif ( TestFlag(offset_table->flags, HAS_STD_SAMPLER_DATA) ) {\n\t\tint32_t  id\t   = -1;\n\t\tuint16_t mode\t = offset_table->offset_std_sampler_algorithm ? in[offset_table->offset_std_sampler_algorithm] : 0;\n\t\tuint32_t interval = Get_val32((void *)&in[offset_table->offset_std_sampler_interval]);\n\n \t\tInsertSampler(fs, exporter, id, mode, interval);\n\n\t\tdbg_printf(\"Extracted Std Sampler data:\\n\");\n\t\tdbg_printf(\"Sampler ID\t   : %i\\n\", id);\n\t\tdbg_printf(\"Sampler algorithm: %u\\n\", mode);\n\t\tdbg_printf(\"Sampler interval : %u\\n\", interval);\n\n\t\tdbg_printf(\"Set std sampler: algorithm: %u, interval: %u\\n\", \n\t\t\t\tmode, interval);\n\t}\n\tprocessed_records++;\n\n} // End of Process_ipfix_option_data\n\nvoid Process_IPFIX(void *in_buff, ssize_t in_buff_cnt, FlowSource_t *fs) {\nexporter_ipfix_domain_t\t*exporter;\nssize_t\t\t\t\tsize_left;\nuint32_t\t\t\tExportTime, Sequence, flowset_length;\nipfix_header_t\t\t*ipfix_header;\nvoid\t\t\t\t*flowset_header;\n\n#ifdef DEVEL\nstatic uint32_t\t\tpacket_cntr = 0;\nuint32_t \t\t\tObservationDomain;\n#endif\n\n\tsize_left \t = in_buff_cnt;\n\tif ( size_left < IPFIX_HEADER_LENGTH ) {\n\t\tLogError(\"Process_ipfix: Too little data for ipfix packet: '%lli'\", (long long)size_left);\n\t\treturn;\n\t}\n\n\tipfix_header = (ipfix_header_t *)in_buff;\n\tExportTime \t\t\t = ntohl(ipfix_header->ExportTime);\n\tSequence \t\t\t = ntohl(ipfix_header->LastSequence);\n\n#ifdef DEVEL\n\tObservationDomain \t = ntohl(ipfix_header->ObservationDomain);\n\tpacket_cntr++;\n\tprintf(\"Next packet: %u\\n\", packet_cntr);\n#endif\n\n\texporter\t= GetExporter(fs, ipfix_header);\n\tif ( !exporter ) {\n\t\tLogError(\"Process_ipfix: Exporter NULL: Abort ipfix record processing\");\n\t\treturn;\n\t}\n\texporter->packets++;\n\t//exporter->PacketSequence = Sequence;\n\tflowset_header\t= (void *)ipfix_header + IPFIX_HEADER_LENGTH;\n\tsize_left \t   -= IPFIX_HEADER_LENGTH;\n\n\tdbg_printf(\"\\n[%u] process packet: %u, exported: %s, TemplateRecords: %llu, DataRecords: %llu, buffer: %li \\n\", \n\t\tObservationDomain, packet_cntr, UNIX2ISO(ExportTime), (long long unsigned)exporter->TemplateRecords, \n\t\t(long long unsigned)exporter->DataRecords, size_left);\n\n\tdbg_printf(\"[%u] Sequence: %u\\n\", ObservationDomain, Sequence);\n\n\t// sequence check\n\t// 2^32 wrap is handled automatically as both counters overflow\n\tif ( Sequence != exporter->PacketSequence ) {\n\t\tif ( exporter->DataRecords != 0 ) {\n\t\t\t// sync sequence on first data record without error report\n\t\t\tfs->nffile->stat_record->sequence_failure++;\n\t\t\texporter->sequence_failure++;\n\t\t\tdbg_printf(\"[%u] Sequence check failed: last seq: %u, seq %u\\n\", \n\t\t\t\texporter->info.id, Sequence, exporter->PacketSequence);\n\t\t\t/* maybee to noise on buggy exporters\n\t\t\tLogError(\"Process_ipfix [%u] Sequence error: last seq: %u, seq %u\\n\", \n\t\t\t\tinfo.id, exporter->LastSequence, Sequence);\n\t\t\t*/\n\t\t} else {\n\t\t\tdbg_printf(\"[%u] Sync Sequence: %u\\n\", exporter->info.id, Sequence);\n\t\t}\n\t\texporter->PacketSequence = Sequence;\n\t} else {\n\t\tdbg_printf(\"[%u] Sequence check ok\\n\", exporter->info.id);\n\t}\n\n\t// iterate over all set\n\tflowset_length = 0;\n\twhile (size_left) {\n\t\tuint16_t\tflowset_id;\n\n\t\tif ( size_left && size_left < 4 ) {\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tflowset_header = flowset_header + flowset_length;\n\n\t\tflowset_id \t\t= GET_FLOWSET_ID(flowset_header);\n\t\tflowset_length \t= GET_FLOWSET_LENGTH(flowset_header);\n\n\t\tdbg_printf(\"Process_ipfix: Next flowset id %u, length %u.\\n\", flowset_id, flowset_length);\n\n\t\tif ( flowset_length == 0 ) {\n\t\t\t/* \tthis should never happen, as 4 is an empty flowset \n\t\t\t\tand smaller is an illegal flowset anyway ...\n\t\t\t\tif it happends, we can't determine the next flowset, so skip the entire export packet\n\t\t\t */\n\t\t\tLogError(\"Process_ipfix: flowset zero length error.\");\n\t\t\tdbg_printf(\"Process_ipfix: flowset zero length error.\\n\");\n\t\t\treturn;\n\n\t\t}\n\n\t\t// possible padding\n\t\tif ( flowset_length <= 4 ) {\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif ( flowset_length > size_left ) {\n\t\t\tLogError(\"Process_ipfix: flowset length error. Expected bytes: %u > buffersize: %lli\", \n\t\t\t\tflowset_length, (long long)size_left);\n\t\t\tsize_left = 0;\n\t\t\tcontinue;\n\t\t}\n\n\n\t\tswitch (flowset_id) {\n\t\t\tcase IPFIX_TEMPLATE_FLOWSET_ID:\n\t\t\t\t// Process_ipfix_templates(exporter, flowset_header, fs);\n\t\t\t\texporter->TemplateRecords++;\n\t\t\t\tdbg_printf(\"Process template flowset, length: %u\\n\", flowset_length);\n\t\t\t\tProcess_ipfix_templates(exporter, flowset_header, flowset_length, fs);\n\t\t\t\tbreak;\n\t\t\tcase IPFIX_OPTIONS_FLOWSET_ID:\n\t\t\t\t// option_flowset = (option_template_flowset_t *)flowset_header;\n\t\t\t\texporter->TemplateRecords++;\n\t\t\t\tdbg_printf(\"Process option template flowset, length: %u\\n\", flowset_length);\n\t\t\t\tProcess_ipfix_option_templates(exporter, flowset_header, fs);\n\t\t\t\tbreak;\n\t\t\tdefault: {\n\t\t\t\tif ( flowset_id < IPFIX_MIN_RECORD_FLOWSET_ID ) {\n\t\t\t\t\tdbg_printf(\"Invalid flowset id: %u. Skip flowset\\n\", flowset_id);\n\t\t\t\t\tLogError(\"Process_ipfix: Invalid flowset id: %u. Skip flowset\", flowset_id);\n\t\t\t\t} else {\n\t\t\t\t\tinput_translation_t *table;\n\t\t\t\t\tdbg_printf(\"Process data flowset, length: %u\\n\", flowset_length);\n\t\t\t\t\ttable = GetTranslationTable(exporter, flowset_id);\n\t\t\t\t\tif ( table ) {\n\t\t\t\t\t\tProcess_ipfix_data(exporter, ExportTime, flowset_header, fs, table);\n\t\t\t\t\t\texporter->DataRecords++;\n\t\t\t\t\t} else if ( HasOptionTable(fs, flowset_id) ) {\n\t\t\t\t\t\tProcess_ipfix_option_data(exporter, flowset_header, fs);\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// maybe a flowset with option data\n\t\t\t\t\t\tdbg_printf(\"Process ipfix: [%u] No table for id %u -> Skip record\\n\", \n\t\t\t\t\t\t\texporter->info.id, flowset_id);\n\t\t\t\t\t}\n\n\t\t\t\t}\n\t\t\t}\n\t\t} // End of switch\n\n\t\t// next record\n\t\tsize_left -= flowset_length;\n\n\t} // End of while\n\n} // End of Process_IPFIX\n\n"], "filenames": ["ChangeLog", "bin/ipfix.c"], "buggy_code_start_loc": [3, 1250], "buggy_code_end_loc": [3, 1428], "fixing_code_start_loc": [4, 1250], "fixing_code_end_loc": [5, 1437], "type": "CWE-190", "message": "nfdump 1.6.17 and earlier is affected by an integer overflow in the function Process_ipfix_template_withdraw in ipfix.c that can be abused in order to crash the process remotely (denial of service).", "other": {"cve": {"id": "CVE-2019-14459", "sourceIdentifier": "cve@mitre.org", "published": "2019-07-31T21:15:11.390", "lastModified": "2023-03-03T18:35:21.700", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "nfdump 1.6.17 and earlier is affected by an integer overflow in the function Process_ipfix_template_withdraw in ipfix.c that can be abused in order to crash the process remotely (denial of service)."}, {"lang": "es", "value": "nfdump 1.6.17 y versiones anteriores se ven afectadas por un desbordamiento de enteros en la funci\u00f3n Process_ipfix_template_withdraw en ipfix.c que se puede abusar para bloquear el proceso de forma remota (denegaci\u00f3n de servicio)."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-190"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:nfdump_project:nfdump:*:*:*:*:*:*:*:*", "versionEndIncluding": "1.6.17", "matchCriteriaId": "16B8B673-B774-4F09-8F6B-ADA4C592DD44"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:29:*:*:*:*:*:*:*", "matchCriteriaId": "D100F7CE-FC64-4CC6-852A-6136D72DA419"}, {"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:30:*:*:*:*:*:*:*", "matchCriteriaId": "97A4B8DF-58DA-4AB6-A1F9-331B36409BA3"}]}]}], "references": [{"url": "https://github.com/phaag/nfdump/commit/3b006ededaf351f1723aea6c727c9edd1b1fff9b", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://github.com/phaag/nfdump/issues/171", "source": "cve@mitre.org", "tags": ["Exploit", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2020/09/msg00021.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/ULSZMKA7P7REJMANVL7D6WMZ2L7IRSET/", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/YTONOGJU5FSMFNRCT6OHXYUMDRKH4RPA/", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://security.gentoo.org/glsa/202003-17", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/phaag/nfdump/commit/3b006ededaf351f1723aea6c727c9edd1b1fff9b"}}
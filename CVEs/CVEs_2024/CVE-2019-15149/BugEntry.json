{"buggy_code": ["# Copyright 2019, David Wilson\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# 1. Redistributions of source code must retain the above copyright notice,\n# this list of conditions and the following disclaimer.\n#\n# 2. Redistributions in binary form must reproduce the above copyright notice,\n# this list of conditions and the following disclaimer in the documentation\n# and/or other materials provided with the distribution.\n#\n# 3. Neither the name of the copyright holder nor the names of its contributors\n# may be used to endorse or promote products derived from this software without\n# specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\n# !mitogen: minify_safe\n\n\"\"\"\nThis module implements most package functionality, but remains separate from\nnon-essential code in order to reduce its size, since it is also serves as the\nbootstrap implementation sent to every new slave context.\n\"\"\"\n\nimport binascii\nimport collections\nimport encodings.latin_1\nimport encodings.utf_8\nimport errno\nimport fcntl\nimport itertools\nimport linecache\nimport logging\nimport os\nimport pickle as py_pickle\nimport pstats\nimport signal\nimport socket\nimport struct\nimport sys\nimport syslog\nimport threading\nimport time\nimport traceback\nimport warnings\nimport weakref\nimport zlib\n\n# Python >3.7 deprecated the imp module.\nwarnings.filterwarnings('ignore', message='the imp module is deprecated')\nimport imp\n\n# Absolute imports for <2.5.\nselect = __import__('select')\n\ntry:\n    import cProfile\nexcept ImportError:\n    cProfile = None\n\ntry:\n    import thread\nexcept ImportError:\n    import threading as thread\n\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n\ntry:\n    from cStringIO import StringIO as BytesIO\nexcept ImportError:\n    from io import BytesIO\n\ntry:\n    BaseException\nexcept NameError:\n    BaseException = Exception\n\ntry:\n    ModuleNotFoundError\nexcept NameError:\n    ModuleNotFoundError = ImportError\n\n# TODO: usage of 'import' after setting __name__, but before fixing up\n# sys.modules generates a warning. This happens when profiling = True.\nwarnings.filterwarnings('ignore',\n    \"Parent module 'mitogen' not found while handling absolute import\")\n\nLOG = logging.getLogger('mitogen')\nIOLOG = logging.getLogger('mitogen.io')\nIOLOG.setLevel(logging.INFO)\n\n# str.encode() may take import lock. Deadlock possible if broker calls\n# .encode() on behalf of thread currently waiting for module.\nLATIN1_CODEC = encodings.latin_1.Codec()\n\n_v = False\n_vv = False\n\nGET_MODULE = 100\nCALL_FUNCTION = 101\nFORWARD_LOG = 102\nADD_ROUTE = 103\nDEL_ROUTE = 104\nALLOCATE_ID = 105\nSHUTDOWN = 106\nLOAD_MODULE = 107\nFORWARD_MODULE = 108\nDETACHING = 109\nCALL_SERVICE = 110\nSTUB_CALL_SERVICE = 111\n\n#: Special value used to signal disconnection or the inability to route a\n#: message, when it appears in the `reply_to` field. Usually causes\n#: :class:`mitogen.core.ChannelError` to be raised when it is received.\n#:\n#: It indicates the sender did not know how to process the message, or wishes\n#: no further messages to be delivered to it. It is used when:\n#:\n#:  * a remote receiver is disconnected or explicitly closed.\n#:  * a related message could not be delivered due to no route existing for it.\n#:  * a router is being torn down, as a sentinel value to notify\n#:    :meth:`mitogen.core.Router.add_handler` callbacks to clean up.\nIS_DEAD = 999\n\ntry:\n    BaseException\nexcept NameError:\n    BaseException = Exception\n\nPY24 = sys.version_info < (2, 5)\nPY3 = sys.version_info > (3,)\nif PY3:\n    b = str.encode\n    BytesType = bytes\n    UnicodeType = str\n    FsPathTypes = (str,)\n    BufferType = lambda buf, start: memoryview(buf)[start:]\n    long = int\nelse:\n    b = str\n    BytesType = str\n    FsPathTypes = (str, unicode)\n    BufferType = buffer\n    UnicodeType = unicode\n\nAnyTextType = (BytesType, UnicodeType)\n\ntry:\n    next\nexcept NameError:\n    next = lambda it: it.next()\n\n# #550: prehistoric WSL did not advertise itself in uname output.\ntry:\n    fp = open('/proc/sys/kernel/osrelease')\n    IS_WSL = 'Microsoft' in fp.read()\n    fp.close()\nexcept IOError:\n    IS_WSL = False\n\n\n#: Default size for calls to :meth:`Side.read` or :meth:`Side.write`, and the\n#: size of buffers configured by :func:`mitogen.parent.create_socketpair`. This\n#: value has many performance implications, 128KiB seems to be a sweet spot.\n#:\n#: * When set low, large messages cause many :class:`Broker` IO loop\n#:   iterations, burning CPU and reducing throughput.\n#: * When set high, excessive RAM is reserved by the OS for socket buffers (2x\n#:   per child), and an identically sized temporary userspace buffer is\n#:   allocated on each read that requires zeroing, and over a particular size\n#:   may require two system calls to allocate/deallocate.\n#:\n#: Care must be taken to ensure the underlying kernel object and receiving\n#: program support the desired size. For example,\n#:\n#: * Most UNIXes have TTYs with fixed 2KiB-4KiB buffers, making them unsuitable\n#:   for efficient IO.\n#: * Different UNIXes have varying presets for pipes, which may not be\n#:   configurable. On recent Linux the default pipe buffer size is 64KiB, but\n#:   under memory pressure may be as low as 4KiB for unprivileged processes.\n#: * When communication is via an intermediary process, its internal buffers\n#:   effect the speed OS buffers will drain. For example OpenSSH uses 64KiB\n#:   reads.\n#:\n#: An ideal :class:`Message` has a size that is a multiple of\n#: :data:`CHUNK_SIZE` inclusive of headers, to avoid wasting IO loop iterations\n#: writing small trailer chunks.\nCHUNK_SIZE = 131072\n\n_tls = threading.local()\n\n\nif __name__ == 'mitogen.core':\n    # When loaded using import mechanism, ExternalContext.main() will not have\n    # a chance to set the synthetic mitogen global, so just import it here.\n    import mitogen\nelse:\n    # When loaded as __main__, ensure classes and functions gain a __module__\n    # attribute consistent with the host process, so that pickling succeeds.\n    __name__ = 'mitogen.core'\n\n\nclass Error(Exception):\n    \"\"\"\n    Base for all exceptions raised by Mitogen.\n\n    :param str fmt:\n        Exception text, or format string if `args` is non-empty.\n    :param tuple args:\n        Format string arguments.\n    \"\"\"\n    def __init__(self, fmt=None, *args):\n        if args:\n            fmt %= args\n        if fmt and not isinstance(fmt, UnicodeType):\n            fmt = fmt.decode('utf-8')\n        Exception.__init__(self, fmt)\n\n\nclass LatchError(Error):\n    \"\"\"\n    Raised when an attempt is made to use a :class:`mitogen.core.Latch` that\n    has been marked closed.\n    \"\"\"\n    pass\n\n\nclass Blob(BytesType):\n    \"\"\"\n    A serializable bytes subclass whose content is summarized in repr() output,\n    making it suitable for logging binary data.\n    \"\"\"\n    def __repr__(self):\n        return '[blob: %d bytes]' % len(self)\n\n    def __reduce__(self):\n        return (Blob, (BytesType(self),))\n\n\nclass Secret(UnicodeType):\n    \"\"\"\n    A serializable unicode subclass whose content is masked in repr() output,\n    making it suitable for logging passwords.\n    \"\"\"\n    def __repr__(self):\n        return '[secret]'\n\n    if not PY3:\n        # TODO: what is this needed for in 2.x?\n        def __str__(self):\n            return UnicodeType(self)\n\n    def __reduce__(self):\n        return (Secret, (UnicodeType(self),))\n\n\nclass Kwargs(dict):\n    \"\"\"\n    A serializable dict subclass that indicates its keys should be coerced to\n    Unicode on Python 3 and bytes on Python<2.6.\n\n    Python 2 produces keyword argument dicts whose keys are bytes, requiring a\n    helper to ensure compatibility with Python 3 where Unicode is required,\n    whereas Python 3 produces keyword argument dicts whose keys are Unicode,\n    requiring a helper for Python 2.4/2.5, where bytes are required.\n    \"\"\"\n    if PY3:\n        def __init__(self, dct):\n            for k, v in dct.items():\n                if type(k) is bytes:\n                    self[k.decode()] = v\n                else:\n                    self[k] = v\n    elif sys.version_info < (2, 6, 5):\n        def __init__(self, dct):\n            for k, v in dct.iteritems():\n                if type(k) is unicode:\n                    k, _ = encodings.utf_8.encode(k)\n                self[k] = v\n\n    def __repr__(self):\n        return 'Kwargs(%s)' % (dict.__repr__(self),)\n\n    def __reduce__(self):\n        return (Kwargs, (dict(self),))\n\n\nclass CallError(Error):\n    \"\"\"\n    Serializable :class:`Error` subclass raised when :meth:`Context.call()\n    <mitogen.parent.Context.call>` fails. A copy of the traceback from the\n    external context is appended to the exception message.\n    \"\"\"\n    def __init__(self, fmt=None, *args):\n        if not isinstance(fmt, BaseException):\n            Error.__init__(self, fmt, *args)\n        else:\n            e = fmt\n            cls = e.__class__\n            fmt = '%s.%s: %s' % (cls.__module__, cls.__name__, e)\n            tb = sys.exc_info()[2]\n            if tb:\n                fmt += '\\n'\n                fmt += ''.join(traceback.format_tb(tb))\n            Error.__init__(self, fmt)\n\n    def __reduce__(self):\n        return (_unpickle_call_error, (self.args[0],))\n\n\ndef _unpickle_call_error(s):\n    if not (type(s) is UnicodeType and len(s) < 10000):\n        raise TypeError('cannot unpickle CallError: bad input')\n    return CallError(s)\n\n\nclass ChannelError(Error):\n    \"\"\"\n    Raised when a channel dies or has been closed.\n    \"\"\"\n    remote_msg = 'Channel closed by remote end.'\n    local_msg = 'Channel closed by local end.'\n\n\nclass StreamError(Error):\n    \"\"\"\n    Raised when a stream cannot be established.\n    \"\"\"\n    pass\n\n\nclass TimeoutError(Error):\n    \"\"\"\n    Raised when a timeout occurs on a stream.\n    \"\"\"\n    pass\n\n\ndef to_text(o):\n    \"\"\"\n    Coerce `o` to Unicode by decoding it from UTF-8 if it is an instance of\n    :class:`bytes`, otherwise pass it to the :class:`str` constructor. The\n    returned object is always a plain :class:`str`, any subclass is removed.\n    \"\"\"\n    if isinstance(o, BytesType):\n        return o.decode('utf-8')\n    return UnicodeType(o)\n\n\n# Python 2.4\ntry:\n    any\nexcept NameError:\n    def any(it):\n        for elem in it:\n            if elem:\n                return True\n\n\ndef _partition(s, sep, find):\n    \"\"\"\n    (str|unicode).(partition|rpartition) for Python 2.4/2.5.\n    \"\"\"\n    idx = find(sep)\n    if idx != -1:\n        left = s[0:idx]\n        return left, sep, s[len(left)+len(sep):]\n\n\nif hasattr(UnicodeType, 'rpartition'):\n    str_partition = UnicodeType.partition\n    str_rpartition = UnicodeType.rpartition\n    bytes_partition = BytesType.partition\nelse:\n    def str_partition(s, sep):\n        return _partition(s, sep, s.find) or (s, u'', u'')\n    def str_rpartition(s, sep):\n        return _partition(s, sep, s.rfind) or (u'', u'', s)\n    def bytes_partition(s, sep):\n        return _partition(s, sep, s.find) or (s, '', '')\n\n\ndef has_parent_authority(msg, _stream=None):\n    \"\"\"\n    Policy function for use with :class:`Receiver` and\n    :meth:`Router.add_handler` that requires incoming messages to originate\n    from a parent context, or on a :class:`Stream` whose :attr:`auth_id\n    <Stream.auth_id>` has been set to that of a parent context or the current\n    context.\n    \"\"\"\n    return (msg.auth_id == mitogen.context_id or\n            msg.auth_id in mitogen.parent_ids)\n\n\ndef _signals(obj, signal):\n    return (\n        obj.__dict__\n        .setdefault('_signals', {})\n        .setdefault(signal, [])\n    )\n\n\ndef listen(obj, name, func):\n    \"\"\"\n    Arrange for `func()` to be invoked when signal `name` is fired on `obj`.\n    \"\"\"\n    _signals(obj, name).append(func)\n\n\ndef unlisten(obj, name, func):\n    \"\"\"\n    Remove `func()` from the list of functions invoked when signal `name` is\n    fired by `obj`.\n\n    :raises ValueError:\n        `func()` was not on the list.\n    \"\"\"\n    _signals(obj, name).remove(func)\n\n\ndef fire(obj, name, *args, **kwargs):\n    \"\"\"\n    Arrange for `func(*args, **kwargs)` to be invoked for every function\n    registered for signal `name` on `obj`.\n    \"\"\"\n    for func in _signals(obj, name):\n        func(*args, **kwargs)\n\n\ndef takes_econtext(func):\n    func.mitogen_takes_econtext = True\n    return func\n\n\ndef takes_router(func):\n    func.mitogen_takes_router = True\n    return func\n\n\ndef is_blacklisted_import(importer, fullname):\n    \"\"\"\n    Return :data:`True` if `fullname` is part of a blacklisted package, or if\n    any packages have been whitelisted and `fullname` is not part of one.\n\n    NB:\n      - If a package is on both lists, then it is treated as blacklisted.\n      - If any package is whitelisted, then all non-whitelisted packages are\n        treated as blacklisted.\n    \"\"\"\n    return ((not any(fullname.startswith(s) for s in importer.whitelist)) or\n                (any(fullname.startswith(s) for s in importer.blacklist)))\n\n\ndef set_cloexec(fd):\n    \"\"\"\n    Set the file descriptor `fd` to automatically close on :func:`os.execve`.\n    This has no effect on file descriptors inherited across :func:`os.fork`,\n    they must be explicitly closed through some other means, such as\n    :func:`mitogen.fork.on_fork`.\n    \"\"\"\n    flags = fcntl.fcntl(fd, fcntl.F_GETFD)\n    assert fd > 2\n    fcntl.fcntl(fd, fcntl.F_SETFD, flags | fcntl.FD_CLOEXEC)\n\n\ndef set_nonblock(fd):\n    \"\"\"\n    Set the file descriptor `fd` to non-blocking mode. For most underlying file\n    types, this causes :func:`os.read` or :func:`os.write` to raise\n    :class:`OSError` with :data:`errno.EAGAIN` rather than block the thread\n    when the underlying kernel buffer is exhausted.\n    \"\"\"\n    flags = fcntl.fcntl(fd, fcntl.F_GETFL)\n    fcntl.fcntl(fd, fcntl.F_SETFL, flags | os.O_NONBLOCK)\n\n\ndef set_block(fd):\n    \"\"\"\n    Inverse of :func:`set_nonblock`, i.e. cause `fd` to block the thread when\n    the underlying kernel buffer is exhausted.\n    \"\"\"\n    flags = fcntl.fcntl(fd, fcntl.F_GETFL)\n    fcntl.fcntl(fd, fcntl.F_SETFL, flags & ~os.O_NONBLOCK)\n\n\ndef io_op(func, *args):\n    \"\"\"\n    Wrap `func(*args)` that may raise :class:`select.error`, :class:`IOError`,\n    or :class:`OSError`, trapping UNIX error codes relating to disconnection\n    and retry events in various subsystems:\n\n    * When a signal is delivered to the process on Python 2, system call retry\n      is signalled through :data:`errno.EINTR`. The invocation is automatically\n      restarted.\n    * When performing IO against a TTY, disconnection of the remote end is\n      signalled by :data:`errno.EIO`.\n    * When performing IO against a socket, disconnection of the remote end is\n      signalled by :data:`errno.ECONNRESET`.\n    * When performing IO against a pipe, disconnection of the remote end is\n      signalled by :data:`errno.EPIPE`.\n\n    :returns:\n        Tuple of `(return_value, disconnect_reason)`, where `return_value` is\n        the return value of `func(*args)`, and `disconnected` is an exception\n        instance when disconnection was detected, otherwise :data:`None`.\n    \"\"\"\n    while True:\n        try:\n            return func(*args), None\n        except (select.error, OSError, IOError):\n            e = sys.exc_info()[1]\n            _vv and IOLOG.debug('io_op(%r) -> OSError: %s', func, e)\n            if e.args[0] == errno.EINTR:\n                continue\n            if e.args[0] in (errno.EIO, errno.ECONNRESET, errno.EPIPE):\n                return None, e\n            raise\n\n\nclass PidfulStreamHandler(logging.StreamHandler):\n    \"\"\"\n    A :class:`logging.StreamHandler` subclass used when\n    :meth:`Router.enable_debug() <mitogen.master.Router.enable_debug>` has been\n    called, or the `debug` parameter was specified during context construction.\n    Verifies the process ID has not changed on each call to :meth:`emit`,\n    reopening the associated log file when a change is detected.\n\n    This ensures logging to the per-process output files happens correctly even\n    when uncooperative third party components call :func:`os.fork`.\n    \"\"\"\n    #: PID that last opened the log file.\n    open_pid = None\n\n    #: Output path template.\n    template = '/tmp/mitogen.%s.%s.log'\n\n    def _reopen(self):\n        self.acquire()\n        try:\n            if self.open_pid == os.getpid():\n                return\n            ts = time.strftime('%Y%m%d_%H%M%S')\n            path = self.template % (os.getpid(), ts)\n            self.stream = open(path, 'w', 1)\n            set_cloexec(self.stream.fileno())\n            self.stream.write('Parent PID: %s\\n' % (os.getppid(),))\n            self.stream.write('Created by:\\n\\n%s\\n' % (\n                ''.join(traceback.format_stack()),\n            ))\n            self.open_pid = os.getpid()\n        finally:\n            self.release()\n\n    def emit(self, record):\n        if self.open_pid != os.getpid():\n            self._reopen()\n        logging.StreamHandler.emit(self, record)\n\n\ndef enable_debug_logging():\n    global _v, _vv\n    _v = True\n    _vv = True\n    root = logging.getLogger()\n    root.setLevel(logging.DEBUG)\n    IOLOG.setLevel(logging.DEBUG)\n    handler = PidfulStreamHandler()\n    handler.formatter = logging.Formatter(\n        '%(asctime)s %(levelname).1s %(name)s: %(message)s',\n        '%H:%M:%S'\n    )\n    root.handlers.insert(0, handler)\n\n\n_profile_hook = lambda name, func, *args: func(*args)\n_profile_fmt = os.environ.get(\n    'MITOGEN_PROFILE_FMT',\n    '/tmp/mitogen.stats.%(pid)s.%(identity)s.%(now)s.%(ext)s',\n)\n\n\ndef _profile_hook(name, func, *args):\n    \"\"\"\n    Call `func(*args)` and return its result. This function is replaced by\n    :func:`_real_profile_hook` when :func:`enable_profiling` is called. This\n    interface is obsolete and will be replaced by a signals-based integration\n    later on.\n    \"\"\"\n    return func(*args)\n\n\ndef _real_profile_hook(name, func, *args):\n    profiler = cProfile.Profile()\n    profiler.enable()\n    try:\n        return func(*args)\n    finally:\n        path = _profile_fmt % {\n            'now': int(1e6 * time.time()),\n            'identity': name,\n            'pid': os.getpid(),\n            'ext': '%s'\n        }\n        profiler.dump_stats(path % ('pstats',))\n        profiler.create_stats()\n        fp = open(path % ('log',), 'w')\n        try:\n            stats = pstats.Stats(profiler, stream=fp)\n            stats.sort_stats('cumulative')\n            stats.print_stats()\n        finally:\n            fp.close()\n\n\ndef enable_profiling(econtext=None):\n    global _profile_hook\n    _profile_hook = _real_profile_hook\n\n\ndef import_module(modname):\n    \"\"\"\n    Import `module` and return the attribute named `attr`.\n    \"\"\"\n    return __import__(modname, None, None, [''])\n\n\ndef pipe():\n    \"\"\"\n    Create a UNIX pipe pair using :func:`os.pipe`, wrapping the returned\n    descriptors in Python file objects in order to manage their lifetime and\n    ensure they are closed when their last reference is discarded and they have\n    not been closed explicitly.\n    \"\"\"\n    rfd, wfd = os.pipe()\n    return (\n        os.fdopen(rfd, 'rb', 0),\n        os.fdopen(wfd, 'wb', 0)\n    )\n\n\ndef iter_split(buf, delim, func):\n    \"\"\"\n    Invoke `func(s)` for each `delim`-delimited chunk in the potentially large\n    `buf`, avoiding intermediate lists and quadratic string operations. Return\n    the trailing undelimited portion of `buf`, or any unprocessed portion of\n    `buf` after `func(s)` returned :data:`False`.\n\n    :returns:\n        `(trailer, cont)`, where `cont` is :data:`False` if the last call to\n        `func(s)` returned :data:`False`.\n    \"\"\"\n    dlen = len(delim)\n    start = 0\n    cont = True\n    while cont:\n        nl = buf.find(delim, start)\n        if nl == -1:\n            break\n        cont = not func(buf[start:nl]) is False\n        start = nl + dlen\n    return buf[start:], cont\n\n\nclass Py24Pickler(py_pickle.Pickler):\n    \"\"\"\n    Exceptions were classic classes until Python 2.5. Sadly for 2.4, cPickle\n    offers little control over how a classic instance is pickled. Therefore 2.4\n    uses a pure-Python pickler, so CallError can be made to look as it does on\n    newer Pythons.\n\n    This mess will go away once proper serialization exists.\n    \"\"\"\n    @classmethod\n    def dumps(cls, obj, protocol):\n        bio = BytesIO()\n        self = cls(bio, protocol=protocol)\n        self.dump(obj)\n        return bio.getvalue()\n\n    def save_exc_inst(self, obj):\n        if isinstance(obj, CallError):\n            func, args = obj.__reduce__()\n            self.save(func)\n            self.save(args)\n            self.write(py_pickle.REDUCE)\n        else:\n            py_pickle.Pickler.save_inst(self, obj)\n\n    if PY24:\n        dispatch = py_pickle.Pickler.dispatch.copy()\n        dispatch[py_pickle.InstanceType] = save_exc_inst\n\n\nif PY3:\n    # In 3.x Unpickler is a class exposing find_class as an overridable, but it\n    # cannot be overridden without subclassing.\n    class _Unpickler(pickle.Unpickler):\n        def find_class(self, module, func):\n            return self.find_global(module, func)\n    pickle__dumps = pickle.dumps\nelif PY24:\n    # On Python 2.4, we must use a pure-Python pickler.\n    pickle__dumps = Py24Pickler.dumps\n    _Unpickler = pickle.Unpickler\nelse:\n    pickle__dumps = pickle.dumps\n    # In 2.x Unpickler is a function exposing a writeable find_global\n    # attribute.\n    _Unpickler = pickle.Unpickler\n\n\nclass Message(object):\n    \"\"\"\n    Messages are the fundamental unit of communication, comprising fields from\n    the :ref:`stream-protocol` header, an optional reference to the receiving\n    :class:`mitogen.core.Router` for ingress messages, and helper methods for\n    deserialization and generating replies.\n    \"\"\"\n    #: Integer target context ID. :class:`Router` delivers messages locally\n    #: when their :attr:`dst_id` matches :data:`mitogen.context_id`, otherwise\n    #: they are routed up or downstream.\n    dst_id = None\n\n    #: Integer source context ID. Used as the target of replies if any are\n    #: generated.\n    src_id = None\n\n    #: Context ID under whose authority the message is acting. See\n    #: :ref:`source-verification`.\n    auth_id = None\n\n    #: Integer target handle in the destination context. This is one of the\n    #: :ref:`standard-handles`, or a dynamically generated handle used to\n    #: receive a one-time reply, such as the return value of a function call.\n    handle = None\n\n    #: Integer target handle to direct any reply to this message. Used to\n    #: receive a one-time reply, such as the return value of a function call.\n    #: :data:`IS_DEAD` has a special meaning when it appears in this field.\n    reply_to = None\n\n    #: Raw message data bytes.\n    data = b('')\n\n    _unpickled = object()\n\n    #: The :class:`Router` responsible for routing the message. This is\n    #: :data:`None` for locally originated messages.\n    router = None\n\n    #: The :class:`Receiver` over which the message was last received. Part of\n    #: the :class:`mitogen.select.Select` interface. Defaults to :data:`None`.\n    receiver = None\n\n    HEADER_FMT = '>hLLLLLL'\n    HEADER_LEN = struct.calcsize(HEADER_FMT)\n    HEADER_MAGIC = 0x4d49  # 'MI'\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Construct a message from from the supplied `kwargs`. :attr:`src_id` and\n        :attr:`auth_id` are always set to :data:`mitogen.context_id`.\n        \"\"\"\n        self.src_id = mitogen.context_id\n        self.auth_id = mitogen.context_id\n        vars(self).update(kwargs)\n        assert isinstance(self.data, BytesType)\n\n    def pack(self):\n        return (\n            struct.pack(self.HEADER_FMT, self.HEADER_MAGIC, self.dst_id,\n                        self.src_id, self.auth_id, self.handle,\n                        self.reply_to or 0, len(self.data))\n            + self.data\n        )\n\n    def _unpickle_context(self, context_id, name):\n        return _unpickle_context(context_id, name, router=self.router)\n\n    def _unpickle_sender(self, context_id, dst_handle):\n        return _unpickle_sender(self.router, context_id, dst_handle)\n\n    def _unpickle_bytes(self, s, encoding):\n        s, n = LATIN1_CODEC.encode(s)\n        return s\n\n    def _find_global(self, module, func):\n        \"\"\"\n        Return the class implementing `module_name.class_name` or raise\n        `StreamError` if the module is not whitelisted.\n        \"\"\"\n        if module == __name__:\n            if func == '_unpickle_call_error' or func == 'CallError':\n                return _unpickle_call_error\n            elif func == '_unpickle_sender':\n                return self._unpickle_sender\n            elif func == '_unpickle_context':\n                return self._unpickle_context\n            elif func == 'Blob':\n                return Blob\n            elif func == 'Secret':\n                return Secret\n            elif func == 'Kwargs':\n                return Kwargs\n        elif module == '_codecs' and func == 'encode':\n            return self._unpickle_bytes\n        elif module == '__builtin__' and func == 'bytes':\n            return BytesType\n        raise StreamError('cannot unpickle %r/%r', module, func)\n\n    @property\n    def is_dead(self):\n        \"\"\"\n        :data:`True` if :attr:`reply_to` is set to the magic value\n        :data:`IS_DEAD`, indicating the sender considers the channel dead. Dead\n        messages can be raised in a variety of circumstances, see\n        :data:`IS_DEAD` for more information.\n        \"\"\"\n        return self.reply_to == IS_DEAD\n\n    @classmethod\n    def dead(cls, reason=None, **kwargs):\n        \"\"\"\n        Syntax helper to construct a dead message.\n        \"\"\"\n        kwargs['data'], _ = encodings.utf_8.encode(reason or u'')\n        return cls(reply_to=IS_DEAD, **kwargs)\n\n    @classmethod\n    def pickled(cls, obj, **kwargs):\n        \"\"\"\n        Construct a pickled message, setting :attr:`data` to the serialization\n        of `obj`, and setting remaining fields using `kwargs`.\n\n        :returns:\n            The new message.\n        \"\"\"\n        self = cls(**kwargs)\n        try:\n            self.data = pickle__dumps(obj, protocol=2)\n        except pickle.PicklingError:\n            e = sys.exc_info()[1]\n            self.data = pickle__dumps(CallError(e), protocol=2)\n        return self\n\n    def reply(self, msg, router=None, **kwargs):\n        \"\"\"\n        Compose a reply to this message and send it using :attr:`router`, or\n        `router` is :attr:`router` is :data:`None`.\n\n        :param obj:\n            Either a :class:`Message`, or an object to be serialized in order\n            to construct a new message.\n        :param router:\n            Optional router to use if :attr:`router` is :data:`None`.\n        :param kwargs:\n            Optional keyword parameters overriding message fields in the reply.\n        \"\"\"\n        if not isinstance(msg, Message):\n            msg = Message.pickled(msg)\n        msg.dst_id = self.src_id\n        msg.handle = self.reply_to\n        vars(msg).update(kwargs)\n        if msg.handle:\n            (self.router or router).route(msg)\n        else:\n            LOG.debug('dropping reply to message with no return address: %r',\n                      msg)\n\n    if PY3:\n        UNPICKLER_KWARGS = {'encoding': 'bytes'}\n    else:\n        UNPICKLER_KWARGS = {}\n\n    def _throw_dead(self):\n        if len(self.data):\n            raise ChannelError(self.data.decode('utf-8', 'replace'))\n        elif self.src_id == mitogen.context_id:\n            raise ChannelError(ChannelError.local_msg)\n        else:\n            raise ChannelError(ChannelError.remote_msg)\n\n    def unpickle(self, throw=True, throw_dead=True):\n        \"\"\"\n        Unpickle :attr:`data`, optionally raising any exceptions present.\n\n        :param bool throw_dead:\n            If :data:`True`, raise exceptions, otherwise it is the caller's\n            responsibility.\n\n        :raises CallError:\n            The serialized data contained CallError exception.\n        :raises ChannelError:\n            The `is_dead` field was set.\n        \"\"\"\n        _vv and IOLOG.debug('%r.unpickle()', self)\n        if throw_dead and self.is_dead:\n            self._throw_dead()\n\n        obj = self._unpickled\n        if obj is Message._unpickled:\n            fp = BytesIO(self.data)\n            unpickler = _Unpickler(fp, **self.UNPICKLER_KWARGS)\n            unpickler.find_global = self._find_global\n            try:\n                # Must occur off the broker thread.\n                try:\n                    obj = unpickler.load()\n                except:\n                    LOG.error('raw pickle was: %r', self.data)\n                    raise\n                self._unpickled = obj\n            except (TypeError, ValueError):\n                e = sys.exc_info()[1]\n                raise StreamError('invalid message: %s', e)\n\n        if throw:\n            if isinstance(obj, CallError):\n                raise obj\n\n        return obj\n\n    def __repr__(self):\n        return 'Message(%r, %r, %r, %r, %r, %r..%d)' % (\n            self.dst_id, self.src_id, self.auth_id, self.handle,\n            self.reply_to, (self.data or '')[:50], len(self.data)\n        )\n\n\nclass Sender(object):\n    \"\"\"\n    Senders are used to send pickled messages to a handle in another context,\n    it is the inverse of :class:`mitogen.core.Receiver`.\n\n    Senders may be serialized, making them convenient to wire up data flows.\n    See :meth:`mitogen.core.Receiver.to_sender` for more information.\n\n    :param mitogen.core.Context context:\n        Context to send messages to.\n    :param int dst_handle:\n        Destination handle to send messages to.\n    \"\"\"\n    def __init__(self, context, dst_handle):\n        self.context = context\n        self.dst_handle = dst_handle\n\n    def send(self, data):\n        \"\"\"\n        Send `data` to the remote end.\n        \"\"\"\n        _vv and IOLOG.debug('%r.send(%r..)', self, repr(data)[:100])\n        self.context.send(Message.pickled(data, handle=self.dst_handle))\n\n    explicit_close_msg = 'Sender was explicitly closed'\n\n    def close(self):\n        \"\"\"\n        Send a dead message to the remote, causing :meth:`ChannelError` to be\n        raised in any waiting thread.\n        \"\"\"\n        _vv and IOLOG.debug('%r.close()', self)\n        self.context.send(\n            Message.dead(\n                reason=self.explicit_close_msg,\n                handle=self.dst_handle\n            )\n        )\n\n    def __repr__(self):\n        return 'Sender(%r, %r)' % (self.context, self.dst_handle)\n\n    def __reduce__(self):\n        return _unpickle_sender, (self.context.context_id, self.dst_handle)\n\n\ndef _unpickle_sender(router, context_id, dst_handle):\n    if not (isinstance(router, Router) and\n            isinstance(context_id, (int, long)) and context_id >= 0 and\n            isinstance(dst_handle, (int, long)) and dst_handle > 0):\n        raise TypeError('cannot unpickle Sender: bad input or missing router')\n    return Sender(Context(router, context_id), dst_handle)\n\n\nclass Receiver(object):\n    \"\"\"\n    Receivers maintain a thread-safe queue of messages sent to a handle of this\n    context from another context.\n\n    :param mitogen.core.Router router:\n        Router to register the handler on.\n\n    :param int handle:\n        If not :data:`None`, an explicit handle to register, otherwise an\n        unused handle is chosen.\n\n    :param bool persist:\n        If :data:`False`, unregister the handler after one message is received.\n        Single-message receivers are intended for RPC-like transactions, such\n        as in the case of :meth:`mitogen.parent.Context.call_async`.\n\n    :param mitogen.core.Context respondent:\n        Context this receiver is receiving from. If not :data:`None`, arranges\n        for the receiver to receive a dead message if messages can no longer be\n        routed to the context due to disconnection, and ignores messages that\n        did not originate from the respondent context.\n    \"\"\"\n    #: If not :data:`None`, a reference to a function invoked as\n    #: `notify(receiver)` when a new message is delivered to this receiver. The\n    #: function is invoked on the broker thread, therefore it must not block.\n    #: Used by :class:`mitogen.select.Select` to implement waiting on multiple\n    #: receivers.\n    notify = None\n\n    raise_channelerror = True\n\n    def __init__(self, router, handle=None, persist=True,\n                 respondent=None, policy=None, overwrite=False):\n        self.router = router\n        #: The handle.\n        self.handle = handle  # Avoid __repr__ crash in add_handler()\n        self._latch = Latch()  # Must exist prior to .add_handler()\n        self.handle = router.add_handler(\n            fn=self._on_receive,\n            handle=handle,\n            policy=policy,\n            persist=persist,\n            respondent=respondent,\n            overwrite=overwrite,\n        )\n\n    def __repr__(self):\n        return 'Receiver(%r, %r)' % (self.router, self.handle)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, _1, _2, _3):\n        self.close()\n\n    def to_sender(self):\n        \"\"\"\n        Return a :class:`Sender` configured to deliver messages to this\n        receiver. As senders are serializable, this makes it convenient to pass\n        `(context_id, handle)` pairs around::\n\n            def deliver_monthly_report(sender):\n                for line in open('monthly_report.txt'):\n                    sender.send(line)\n                sender.close()\n\n            @mitogen.main()\n            def main(router):\n                remote = router.ssh(hostname='mainframe')\n                recv = mitogen.core.Receiver(router)\n                remote.call(deliver_monthly_report, recv.to_sender())\n                for msg in recv:\n                    print(msg)\n        \"\"\"\n        return Sender(self.router.myself(), self.handle)\n\n    def _on_receive(self, msg):\n        \"\"\"\n        Callback registered for the handle with :class:`Router`; appends data\n        to the internal queue.\n        \"\"\"\n        _vv and IOLOG.debug('%r._on_receive(%r)', self, msg)\n        self._latch.put(msg)\n        if self.notify:\n            self.notify(self)\n\n    closed_msg = 'the Receiver has been closed'\n\n    def close(self):\n        \"\"\"\n        Unregister the receiver's handle from its associated router, and cause\n        :class:`ChannelError` to be raised in any thread waiting in :meth:`get`\n        on this receiver.\n        \"\"\"\n        if self.handle:\n            self.router.del_handler(self.handle)\n            self.handle = None\n        self._latch.close()\n\n    def size(self):\n        \"\"\"\n        Return the number of items currently buffered.\n\n        As with :class:`Queue.Queue`, `0` may be returned even though a\n        subsequent call to :meth:`get` will succeed, since a message may be\n        posted at any moment between :meth:`size` and :meth:`get`.\n\n        As with :class:`Queue.Queue`, `>0` may be returned even though a\n        subsequent call to :meth:`get` will block, since another waiting thread\n        may be woken at any moment between :meth:`size` and :meth:`get`.\n\n        :raises LatchError:\n            The underlying latch has already been marked closed.\n        \"\"\"\n        return self._latch.size()\n\n    def empty(self):\n        \"\"\"\n        Return `size() == 0`.\n\n        .. deprecated:: 0.2.8\n           Use :meth:`size` instead.\n\n        :raises LatchError:\n            The latch has already been marked closed.\n        \"\"\"\n        return self._latch.empty()\n\n    def get(self, timeout=None, block=True, throw_dead=True):\n        \"\"\"\n        Sleep waiting for a message to arrive on this receiver.\n\n        :param float timeout:\n            If not :data:`None`, specifies a timeout in seconds.\n\n        :raises mitogen.core.ChannelError:\n            The remote end indicated the channel should be closed,\n            communication with it was lost, or :meth:`close` was called in the\n            local process.\n\n        :raises mitogen.core.TimeoutError:\n            Timeout was reached.\n\n        :returns:\n            :class:`Message` that was received.\n        \"\"\"\n        _vv and IOLOG.debug('%r.get(timeout=%r, block=%r)', self, timeout, block)\n        try:\n            msg = self._latch.get(timeout=timeout, block=block)\n        except LatchError:\n            raise ChannelError(self.closed_msg)\n        if msg.is_dead and throw_dead:\n            msg._throw_dead()\n        return msg\n\n    def __iter__(self):\n        \"\"\"\n        Yield consecutive :class:`Message` instances delivered to this receiver\n        until :class:`ChannelError` is raised.\n        \"\"\"\n        while True:\n            try:\n                msg = self.get()\n            except ChannelError:\n                return\n            yield msg\n\n\nclass Channel(Sender, Receiver):\n    \"\"\"\n    A channel inherits from :class:`mitogen.core.Sender` and\n    `mitogen.core.Receiver` to provide bidirectional functionality.\n\n    .. deprecated:: 0.2.0\n        This class is incomplete and obsolete, it will be removed in Mitogen\n        0.3.\n\n    Channels were an early attempt at syntax sugar. It is always easier to pass\n    around unidirectional pairs of senders/receivers, even though the syntax is\n    baroque:\n\n    .. literalinclude:: ../examples/ping_pong.py\n\n    Since all handles aren't known until after both ends are constructed, for\n    both ends to communicate through a channel, it is necessary for one end to\n    retrieve the handle allocated to the other and reconfigure its own channel\n    to match. Currently this is a manual task.\n    \"\"\"\n    def __init__(self, router, context, dst_handle, handle=None):\n        Sender.__init__(self, context, dst_handle)\n        Receiver.__init__(self, router, handle)\n\n    def close(self):\n        Receiver.close(self)\n        Sender.close(self)\n\n    def __repr__(self):\n        return 'Channel(%s, %s)' % (\n            Sender.__repr__(self),\n            Receiver.__repr__(self)\n        )\n\n\nclass Importer(object):\n    \"\"\"\n    Import protocol implementation that fetches modules from the parent\n    process.\n\n    :param context: Context to communicate via.\n    \"\"\"\n    # The Mitogen package is handled specially, since the child context must\n    # construct it manually during startup.\n    MITOGEN_PKG_CONTENT = [\n        'buildah',\n        'compat',\n        'debug',\n        'doas',\n        'docker',\n        'kubectl',\n        'fakessh',\n        'fork',\n        'jail',\n        'lxc',\n        'lxd',\n        'master',\n        'minify',\n        'os_fork',\n        'parent',\n        'select',\n        'service',\n        'setns',\n        'ssh',\n        'su',\n        'sudo',\n        'utils',\n    ]\n\n    ALWAYS_BLACKLIST = [\n        # 2.x generates needless imports for 'builtins', while 3.x does the\n        # same for '__builtin__'. The correct one is built-in, the other always\n        # a negative round-trip.\n        'builtins',\n        '__builtin__',\n        'thread',\n\n        # org.python.core imported by copy, pickle, xml.sax; breaks Jython, but\n        # very unlikely to trigger a bug report.\n        'org',\n    ]\n\n    if PY3:\n        ALWAYS_BLACKLIST += ['cStringIO']\n\n    def __init__(self, router, context, core_src, whitelist=(), blacklist=()):\n        self._log = logging.getLogger('mitogen.importer')\n        self._context = context\n        self._present = {'mitogen': self.MITOGEN_PKG_CONTENT}\n        self._lock = threading.Lock()\n        self.whitelist = list(whitelist) or ['']\n        self.blacklist = list(blacklist) + self.ALWAYS_BLACKLIST\n\n        # Preserve copies of the original server-supplied whitelist/blacklist\n        # for later use by children.\n        self.master_whitelist = self.whitelist[:]\n        self.master_blacklist = self.blacklist[:]\n\n        # Presence of an entry in this map indicates in-flight GET_MODULE.\n        self._callbacks = {}\n        self._cache = {}\n        if core_src:\n            self._update_linecache('x/mitogen/core.py', core_src)\n            self._cache['mitogen.core'] = (\n                'mitogen.core',\n                None,\n                'x/mitogen/core.py',\n                zlib.compress(core_src, 9),\n                [],\n            )\n        self._install_handler(router)\n\n    def _update_linecache(self, path, data):\n        \"\"\"\n        The Python 2.4 linecache module, used to fetch source code for\n        tracebacks and :func:`inspect.getsource`, does not support PEP-302,\n        meaning it needs extra help to for Mitogen-loaded modules. Directly\n        populate its cache if a loaded module belongs to the Mitogen package.\n        \"\"\"\n        if PY24 and 'mitogen' in path:\n            linecache.cache[path] = (\n                len(data),\n                0.0,\n                [line+'\\n' for line in data.splitlines()],\n                path,\n            )\n\n    def _install_handler(self, router):\n        router.add_handler(\n            fn=self._on_load_module,\n            handle=LOAD_MODULE,\n            policy=has_parent_authority,\n        )\n\n    def __repr__(self):\n        return 'Importer'\n\n    def builtin_find_module(self, fullname):\n        # imp.find_module() will always succeed for __main__, because it is a\n        # built-in module. That means it exists on a special linked list deep\n        # within the bowels of the interpreter. We must special case it.\n        if fullname == '__main__':\n            raise ModuleNotFoundError()\n\n        parent, _, modname = str_rpartition(fullname, '.')\n        if parent:\n            path = sys.modules[parent].__path__\n        else:\n            path = None\n\n        fp, pathname, description = imp.find_module(modname, path)\n        if fp:\n            fp.close()\n\n    def find_module(self, fullname, path=None):\n        if hasattr(_tls, 'running'):\n            return None\n\n        _tls.running = True\n        try:\n            #_v and self._log.debug('Python requested %r', fullname)\n            fullname = to_text(fullname)\n            pkgname, dot, _ = str_rpartition(fullname, '.')\n            pkg = sys.modules.get(pkgname)\n            if pkgname and getattr(pkg, '__loader__', None) is not self:\n                self._log.debug('%s is submodule of a locally loaded package',\n                                fullname)\n                return None\n\n            suffix = fullname[len(pkgname+dot):]\n            if pkgname and suffix not in self._present.get(pkgname, ()):\n                self._log.debug('%s has no submodule %s', pkgname, suffix)\n                return None\n\n            # #114: explicitly whitelisted prefixes override any\n            # system-installed package.\n            if self.whitelist != ['']:\n                if any(fullname.startswith(s) for s in self.whitelist):\n                    return self\n\n            try:\n                self.builtin_find_module(fullname)\n                _vv and self._log.debug('%r is available locally', fullname)\n            except ImportError:\n                _vv and self._log.debug('we will try to load %r', fullname)\n                return self\n        finally:\n            del _tls.running\n\n    blacklisted_msg = (\n        '%r is present in the Mitogen importer blacklist, therefore this '\n        'context will not attempt to request it from the master, as the '\n        'request will always be refused.'\n    )\n    pkg_resources_msg = (\n        'pkg_resources is prohibited from importing __main__, as it causes '\n        'problems in applications whose main module is not designed to be '\n        're-imported by children.'\n    )\n    absent_msg = (\n        'The Mitogen master process was unable to serve %r. It may be a '\n        'native Python extension, or it may be missing entirely. Check the '\n        'importer debug logs on the master for more information.'\n    )\n\n    def _refuse_imports(self, fullname):\n        if is_blacklisted_import(self, fullname):\n            raise ModuleNotFoundError(self.blacklisted_msg % (fullname,))\n\n        f = sys._getframe(2)\n        requestee = f.f_globals['__name__']\n\n        if fullname == '__main__' and requestee == 'pkg_resources':\n            # Anything that imports pkg_resources will eventually cause\n            # pkg_resources to try and scan __main__ for its __requires__\n            # attribute (pkg_resources/__init__.py::_build_master()). This\n            # breaks any app that is not expecting its __main__ to suddenly be\n            # sucked over a network and injected into a remote process, like\n            # py.test.\n            raise ModuleNotFoundError(self.pkg_resources_msg)\n\n        if fullname == 'pbr':\n            # It claims to use pkg_resources to read version information, which\n            # would result in PEP-302 being used, but it actually does direct\n            # filesystem access. So instead smodge the environment to override\n            # any version that was defined. This will probably break something\n            # later.\n            os.environ['PBR_VERSION'] = '0.0.0'\n\n    def _on_load_module(self, msg):\n        if msg.is_dead:\n            return\n\n        tup = msg.unpickle()\n        fullname = tup[0]\n        _v and self._log.debug('received %s', fullname)\n\n        self._lock.acquire()\n        try:\n            self._cache[fullname] = tup\n            if tup[2] is not None and PY24:\n                self._update_linecache(\n                    path='master:' + tup[2],\n                    data=zlib.decompress(tup[3])\n                )\n            callbacks = self._callbacks.pop(fullname, [])\n        finally:\n            self._lock.release()\n\n        for callback in callbacks:\n            callback()\n\n    def _request_module(self, fullname, callback):\n        self._lock.acquire()\n        try:\n            present = fullname in self._cache\n            if not present:\n                funcs = self._callbacks.get(fullname)\n                if funcs is not None:\n                    _v and self._log.debug('existing request for %s in flight',\n                                           fullname)\n                    funcs.append(callback)\n                else:\n                    _v and self._log.debug('sending new %s request to parent',\n                                           fullname)\n                    self._callbacks[fullname] = [callback]\n                    self._context.send(\n                        Message(data=b(fullname), handle=GET_MODULE)\n                    )\n        finally:\n            self._lock.release()\n\n        if present:\n            callback()\n\n    def load_module(self, fullname):\n        fullname = to_text(fullname)\n        _v and self._log.debug('requesting %s', fullname)\n        self._refuse_imports(fullname)\n\n        event = threading.Event()\n        self._request_module(fullname, event.set)\n        event.wait()\n\n        ret = self._cache[fullname]\n        if ret[2] is None:\n            raise ModuleNotFoundError(self.absent_msg % (fullname,))\n\n        pkg_present = ret[1]\n        mod = sys.modules.setdefault(fullname, imp.new_module(fullname))\n        mod.__file__ = self.get_filename(fullname)\n        mod.__loader__ = self\n        if pkg_present is not None:  # it's a package.\n            mod.__path__ = []\n            mod.__package__ = fullname\n            self._present[fullname] = pkg_present\n        else:\n            mod.__package__ = str_rpartition(fullname, '.')[0] or None\n\n        if mod.__package__ and not PY3:\n            # 2.x requires __package__ to be exactly a string.\n            mod.__package__, _ = encodings.utf_8.encode(mod.__package__)\n\n        source = self.get_source(fullname)\n        try:\n            code = compile(source, mod.__file__, 'exec', 0, 1)\n        except SyntaxError:\n            LOG.exception('while importing %r', fullname)\n            raise\n\n        if PY3:\n            exec(code, vars(mod))\n        else:\n            exec('exec code in vars(mod)')\n\n        # #590: if a module replaces itself in sys.modules during import, below\n        # is necessary. This matches PyImport_ExecCodeModuleEx()\n        return sys.modules.get(fullname, mod)\n\n    def get_filename(self, fullname):\n        if fullname in self._cache:\n            path = self._cache[fullname][2]\n            if path is None:\n                # If find_loader() returns self but a subsequent master RPC\n                # reveals the module can't be loaded, and so load_module()\n                # throws ImportError, on Python 3.x it is still possible for\n                # the loader to be called to fetch metadata.\n                raise ModuleNotFoundError(self.absent_msg % (fullname,))\n            return u'master:' + self._cache[fullname][2]\n\n    def get_source(self, fullname):\n        if fullname in self._cache:\n            compressed = self._cache[fullname][3]\n            if compressed is None:\n                raise ModuleNotFoundError(self.absent_msg % (fullname,))\n\n            source = zlib.decompress(self._cache[fullname][3])\n            if PY3:\n                return to_text(source)\n            return source\n\n\nclass LogHandler(logging.Handler):\n    def __init__(self, context):\n        logging.Handler.__init__(self)\n        self.context = context\n        self.local = threading.local()\n        self._buffer = []\n        # Private synchronization is needed while corked, to ensure no\n        # concurrent call to _send() exists during uncork().\n        self._buffer_lock = threading.Lock()\n\n    def uncork(self):\n        \"\"\"\n        #305: during startup :class:`LogHandler` may be installed before it is\n        possible to route messages, therefore messages are buffered until\n        :meth:`uncork` is called by :class:`ExternalContext`.\n        \"\"\"\n        self._buffer_lock.acquire()\n        try:\n            self._send = self.context.send\n            for msg in self._buffer:\n                self._send(msg)\n            self._buffer = None\n        finally:\n            self._buffer_lock.release()\n\n    def _send(self, msg):\n        self._buffer_lock.acquire()\n        try:\n            if self._buffer is None:\n                # uncork() may run concurrent to _send()\n                self._send(msg)\n            else:\n                self._buffer.append(msg)\n        finally:\n            self._buffer_lock.release()\n\n    def emit(self, rec):\n        if rec.name == 'mitogen.io' or \\\n           getattr(self.local, 'in_emit', False):\n            return\n\n        self.local.in_emit = True\n        try:\n            msg = self.format(rec)\n            encoded = '%s\\x00%s\\x00%s' % (rec.name, rec.levelno, msg)\n            if isinstance(encoded, UnicodeType):\n                # Logging package emits both :(\n                encoded = encoded.encode('utf-8')\n            self._send(Message(data=encoded, handle=FORWARD_LOG))\n        finally:\n            self.local.in_emit = False\n\n\nclass Stream(object):\n    #: A :class:`Side` representing the stream's receive file descriptor.\n    receive_side = None\n\n    #: A :class:`Side` representing the stream's transmit file descriptor.\n    transmit_side = None\n\n    #: A :class:`Protocol` representing the protocol active on the stream.\n    protocol = None\n\n    #: In parents, the :class:`mitogen.parent.Connection` instance.\n    conn = None\n\n    name = u'default'\n\n    def set_protocol(self, protocol):\n        \"\"\"\n        Bind a protocol to this stream, by updating :attr:`Protocol.stream` to\n        refer to this stream, and updating this stream's\n        :attr:`Stream.protocol` to the refer to the protocol. Any prior\n        protocol's :attr:`Protocol.stream` is set to :data:`None`.\n        \"\"\"\n        if self.protocol:\n            self.protocol.stream = None\n        self.protocol = protocol\n        self.protocol.stream = self\n\n    def accept(self, rfp, wfp):\n        self.receive_side = Side(self, rfp)\n        self.transmit_side = Side(self, wfp)\n\n    def __repr__(self):\n        return \"<Stream %s>\" % (self.name,)\n\n    def on_receive(self, broker):\n        \"\"\"\n        Called by :class:`Broker` when the stream's :attr:`receive_side` has\n        been marked readable using :meth:`Broker.start_receive` and the broker\n        has detected the associated file descriptor is ready for reading.\n\n        Subclasses must implement this if :meth:`Broker.start_receive` is ever\n        called on them, and the method must call :meth:`on_disconect` if\n        reading produces an empty string.\n        \"\"\"\n        buf = self.receive_side.read(self.protocol.read_size)\n        if not buf:\n            LOG.debug('%r: empty read, disconnecting', self.receive_side)\n            return self.on_disconnect(broker)\n\n        self.protocol.on_receive(broker, buf)\n\n    def on_transmit(self, broker):\n        \"\"\"\n        Called by :class:`Broker` when the stream's :attr:`transmit_side`\n        has been marked writeable using :meth:`Broker._start_transmit` and\n        the broker has detected the associated file descriptor is ready for\n        writing.\n\n        Subclasses must implement this if :meth:`Broker._start_transmit` is\n        ever called on them.\n        \"\"\"\n        self.protocol.on_transmit(broker)\n\n    def on_shutdown(self, broker):\n        \"\"\"\n        Called by :meth:`Broker.shutdown` to allow the stream time to\n        gracefully shutdown. The base implementation simply called\n        :meth:`on_disconnect`.\n        \"\"\"\n        fire(self, 'shutdown')\n        self.protocol.on_shutdown(broker)\n\n    def on_disconnect(self, broker):\n        \"\"\"\n        Called by :class:`Broker` to force disconnect the stream. The base\n        implementation simply closes :attr:`receive_side` and\n        :attr:`transmit_side` and unregisters the stream from the broker.\n        \"\"\"\n        fire(self, 'disconnect')\n        self.protocol.on_disconnect(broker)\n\n\nclass Protocol(object):\n    \"\"\"\n    Implement the program behaviour associated with activity on a\n    :class:`Stream`. The protocol in use may vary over a stream's life, for\n    example to allow :class:`mitogen.parent.BootstrapProtocol` to initialize\n    the connected child before handing it off to :class:`MitogenProtocol`. A\n    stream's active protocol is tracked in the :attr:`Stream.protocol`\n    attribute, and modified via :meth:`Stream.set_protocol`.\n\n    Protocols do not handle IO, they are entirely reliant on the interface\n    provided by :class:`Stream` and :class:`Side`, allowing the underlying IO\n    implementation to be replaced without modifying behavioural logic.\n    \"\"\"\n    stream_class = Stream\n\n    #: The :class:`Stream` this protocol is currently bound to, or\n    #: :data:`None`.\n    stream = None\n\n    read_size = CHUNK_SIZE\n\n    @classmethod\n    def build_stream(cls, *args, **kwargs):\n        stream = cls.stream_class()\n        stream.set_protocol(cls(*args, **kwargs))\n        return stream\n\n    def __repr__(self):\n        return '%s(%s)' % (\n            self.__class__.__name__,\n            self.stream and self.stream.name,\n        )\n\n    def on_shutdown(self, broker):\n        _v and LOG.debug('%r: shutting down', self)\n        self.stream.on_disconnect(broker)\n\n    def on_disconnect(self, broker):\n        # Normally both sides an FD, so it is important that tranmit_side is\n        # deregistered from Poller before closing the receive side, as pollers\n        # like epoll and kqueue unregister all events on FD close, causing\n        # subsequent attempt to unregister the transmit side to fail.\n        LOG.debug('%r: disconnecting', self)\n        broker.stop_receive(self.stream)\n        if self.stream.transmit_side:\n            broker._stop_transmit(self.stream)\n\n        self.stream.receive_side.close()\n        if self.stream.transmit_side:\n            self.stream.transmit_side.close()\n\n\nclass DelimitedProtocol(Protocol):\n    \"\"\"\n    Provide a :meth:`Protocol.on_receive` implementation for protocols that are\n    delimited by a fixed string, like text based protocols. Each message is\n    passed to :meth:`on_line_received` as it arrives, with incomplete messages\n    passed to :meth:`on_partial_line_received`.\n\n    When emulating user input it is often necessary to respond to incomplete\n    lines, such as when a \"Password: \" prompt is sent.\n    :meth:`on_partial_line_received` may be called repeatedly with an\n    increasingly complete message. When a complete message is finally received,\n    :meth:`on_line_received` will be called once for it before the buffer is\n    discarded.\n\n    If :func:`on_line_received` returns :data:`False`, remaining data is passed\n    unprocessed to the stream's current protocol's :meth:`on_receive`. This\n    allows switching from line-oriented to binary while the input buffer\n    contains both kinds of data.\n    \"\"\"\n    #: The delimiter. Defaults to newline.\n    delimiter = b('\\n')\n    _trailer = b('')\n\n    def on_receive(self, broker, buf):\n        _vv and IOLOG.debug('%r.on_receive()', self)\n        stream = self.stream\n        self._trailer, cont = mitogen.core.iter_split(\n            buf=self._trailer + buf,\n            delim=self.delimiter,\n            func=self.on_line_received,\n        )\n\n        if self._trailer:\n            if cont:\n                self.on_partial_line_received(self._trailer)\n            else:\n                assert stream.protocol is not self\n                stream.protocol.on_receive(broker, self._trailer)\n\n    def on_line_received(self, line):\n        \"\"\"\n        Receive a line from the stream.\n\n        :param bytes line:\n            The encoded line, excluding the delimiter.\n        :returns:\n            :data:`False` to indicate this invocation modified the stream's\n            active protocol, and any remaining buffered data should be passed\n            to the new protocol's :meth:`on_receive` method.\n\n            Any other return value is ignored.\n        \"\"\"\n        pass\n\n    def on_partial_line_received(self, line):\n        \"\"\"\n        Receive a trailing unterminated partial line from the stream.\n\n        :param bytes line:\n            The encoded partial line.\n        \"\"\"\n        pass\n\n\nclass BufferedWriter(object):\n    \"\"\"\n    Implement buffered output while avoiding quadratic string operations. This\n    is currently constructed by each protocol, in future it may become fixed\n    for each stream instead.\n    \"\"\"\n    def __init__(self, broker, protocol):\n        self._broker = broker\n        self._protocol = protocol\n        self._buf = collections.deque()\n        self._len = 0\n\n    def write(self, s):\n        \"\"\"\n        Transmit `s` immediately, falling back to enqueuing it and marking the\n        stream writeable if no OS buffer space is available.\n        \"\"\"\n        if not self._len:\n            # Modifying epoll/Kqueue state is expensive, as are needless broker\n            # loops. Rather than wait for writeability, just write immediately,\n            # and fall back to the broker loop on error or full buffer.\n            try:\n                n = self._protocol.stream.transmit_side.write(s)\n                if n:\n                    if n == len(s):\n                        return\n                    s = s[n:]\n            except OSError:\n                pass\n\n            self._broker._start_transmit(self._protocol.stream)\n        self._buf.append(s)\n        self._len += len(s)\n\n    def on_transmit(self, broker):\n        \"\"\"\n        Respond to stream writeability by retrying previously buffered\n        :meth:`write` calls.\n        \"\"\"\n        if self._buf:\n            buf = self._buf.popleft()\n            written = self._protocol.stream.transmit_side.write(buf)\n            if not written:\n                _v and LOG.debug('disconnected during write to %r', self)\n                self._protocol.stream.on_disconnect(broker)\n                return\n            elif written != len(buf):\n                self._buf.appendleft(BufferType(buf, written))\n\n            _vv and IOLOG.debug('transmitted %d bytes to %r', written, self)\n            self._len -= written\n\n        if not self._buf:\n            broker._stop_transmit(self._protocol.stream)\n\n\nclass Side(object):\n    \"\"\"\n    Represent one side of a :class:`Stream`. This allows unidirectional (e.g.\n    pipe) and bidirectional (e.g. socket) streams to operate identically.\n\n    Sides are also responsible for tracking the open/closed state of the\n    underlying FD, preventing erroneous duplicate calls to :func:`os.close` due\n    to duplicate :meth:`Stream.on_disconnect` calls, which would otherwise risk\n    silently succeeding by closing an unrelated descriptor. For this reason, it\n    is crucial only one file object exists per unique descriptor.\n\n    :param mitogen.core.Stream stream:\n        The stream this side is associated with.\n    :param object fp:\n        The file or socket object managing the underlying file descriptor. Any\n        object may be used that supports `fileno()` and `close()` methods.\n    :param bool cloexec:\n        If :data:`True`, the descriptor has its :data:`fcntl.FD_CLOEXEC` flag\n        enabled using :func:`fcntl.fcntl`.\n    :param bool keep_alive:\n        If :data:`True`, the continued existence of this side will extend the\n        shutdown grace period until it has been unregistered from the broker.\n    :param bool blocking:\n        If :data:`False`, the descriptor has its :data:`os.O_NONBLOCK` flag\n        enabled using :func:`fcntl.fcntl`.\n    \"\"\"\n    _fork_refs = weakref.WeakValueDictionary()\n    closed = False\n\n    def __init__(self, stream, fp, cloexec=True, keep_alive=True, blocking=False):\n        #: The :class:`Stream` for which this is a read or write side.\n        self.stream = stream\n        # File or socket object responsible for the lifetime of its underlying\n        # file descriptor.\n        self.fp = fp\n        #: Integer file descriptor to perform IO on, or :data:`None` if\n        #: :meth:`close` has been called. This is saved separately from the\n        #: file object, since :meth:`file.fileno` cannot be called on it after\n        #: it has been closed.\n        self.fd = fp.fileno()\n        #: If :data:`True`, causes presence of this side in\n        #: :class:`Broker`'s active reader set to defer shutdown until the\n        #: side is disconnected.\n        self.keep_alive = keep_alive\n        self._fork_refs[id(self)] = self\n        if cloexec:\n            set_cloexec(self.fd)\n        if not blocking:\n            set_nonblock(self.fd)\n\n    def __repr__(self):\n        return '<Side of %s fd %s>' % (\n            self.stream.name or repr(self.stream),\n            self.fd\n        )\n\n    @classmethod\n    def _on_fork(cls):\n        while cls._fork_refs:\n            _, side = cls._fork_refs.popitem()\n            _vv and IOLOG.debug('Side._on_fork() closing %r', side)\n            side.close()\n\n    def close(self):\n        \"\"\"\n        Call :meth:`file.close` on :attr:`fp` if it is not :data:`None`,\n        then set it to :data:`None`.\n        \"\"\"\n        _vv and IOLOG.debug('%r.close()', self)\n        if not self.closed:\n            self.closed = True\n            self.fp.close()\n\n    def read(self, n=CHUNK_SIZE):\n        \"\"\"\n        Read up to `n` bytes from the file descriptor, wrapping the underlying\n        :func:`os.read` call with :func:`io_op` to trap common disconnection\n        conditions.\n\n        :meth:`read` always behaves as if it is reading from a regular UNIX\n        file; socket, pipe, and TTY disconnection errors are masked and result\n        in a 0-sized read like a regular file.\n\n        :returns:\n            Bytes read, or the empty string to indicate disconnection was\n            detected.\n        \"\"\"\n        if self.closed:\n            # Refuse to touch the handle after closed, it may have been reused\n            # by another thread. TODO: synchronize read()/write()/close().\n            return b('')\n        s, disconnected = io_op(os.read, self.fd, n)\n        if disconnected:\n            LOG.debug('%r: disconnected during read: %s', self, disconnected)\n            return b('')\n        return s\n\n    def write(self, s):\n        \"\"\"\n        Write as much of the bytes from `s` as possible to the file descriptor,\n        wrapping the underlying :func:`os.write` call with :func:`io_op` to\n        trap common disconnection conditions.\n\n        :returns:\n            Number of bytes written, or :data:`None` if disconnection was\n            detected.\n        \"\"\"\n        if self.closed:\n            # Don't touch the handle after close, it may be reused elsewhere.\n            return None\n\n        written, disconnected = io_op(os.write, self.fd, s)\n        if disconnected:\n            LOG.debug('%r: disconnected during write: %s', self, disconnected)\n            return None\n        return written\n\n\nclass MitogenProtocol(Protocol):\n    \"\"\"\n    :class:`Protocol` implementing mitogen's :ref:`stream protocol\n    <stream-protocol>`.\n    \"\"\"\n    #: If not :data:`None`, :class:`Router` stamps this into\n    #: :attr:`Message.auth_id` of every message received on this stream.\n    auth_id = None\n\n    #: If not :data:`False`, indicates the stream has :attr:`auth_id` set and\n    #: its value is the same as :data:`mitogen.context_id` or appears in\n    #: :data:`mitogen.parent_ids`.\n    is_privileged = False\n\n    def __init__(self, router, remote_id):\n        self._router = router\n        self.remote_id = remote_id\n        self.sent_modules = set(['mitogen', 'mitogen.core'])\n        self._input_buf = collections.deque()\n        self._input_buf_len = 0\n        self._writer = BufferedWriter(router.broker, self)\n\n        #: Routing records the dst_id of every message arriving from this\n        #: stream. Any arriving DEL_ROUTE is rebroadcast for any such ID.\n        self.egress_ids = set()\n\n    def on_receive(self, broker, buf):\n        \"\"\"\n        Handle the next complete message on the stream. Raise\n        :class:`StreamError` on failure.\n        \"\"\"\n        _vv and IOLOG.debug('%r.on_receive()', self)\n        if self._input_buf and self._input_buf_len < 128:\n            self._input_buf[0] += buf\n        else:\n            self._input_buf.append(buf)\n\n        self._input_buf_len += len(buf)\n        while self._receive_one(broker):\n            pass\n\n    corrupt_msg = (\n        '%s: Corruption detected: frame signature incorrect. This likely means'\n        ' some external process is interfering with the connection. Received:'\n        '\\n\\n'\n        '%r'\n    )\n\n    def _receive_one(self, broker):\n        if self._input_buf_len < Message.HEADER_LEN:\n            return False\n\n        msg = Message()\n        msg.router = self._router\n        (magic, msg.dst_id, msg.src_id, msg.auth_id,\n         msg.handle, msg.reply_to, msg_len) = struct.unpack(\n            Message.HEADER_FMT,\n            self._input_buf[0][:Message.HEADER_LEN],\n        )\n\n        if magic != Message.HEADER_MAGIC:\n            LOG.error(self.corrupt_msg, self.stream.name, self._input_buf[0][:2048])\n            self.stream.on_disconnect(broker)\n            return False\n\n        if msg_len > self._router.max_message_size:\n            LOG.error('Maximum message size exceeded (got %d, max %d)',\n                      msg_len, self._router.max_message_size)\n            self.stream.on_disconnect(broker)\n            return False\n\n        total_len = msg_len + Message.HEADER_LEN\n        if self._input_buf_len < total_len:\n            _vv and IOLOG.debug(\n                '%r: Input too short (want %d, got %d)',\n                self, msg_len, self._input_buf_len - Message.HEADER_LEN\n            )\n            return False\n\n        start = Message.HEADER_LEN\n        prev_start = start\n        remain = total_len\n        bits = []\n        while remain:\n            buf = self._input_buf.popleft()\n            bit = buf[start:remain]\n            bits.append(bit)\n            remain -= len(bit) + start\n            prev_start = start\n            start = 0\n\n        msg.data = b('').join(bits)\n        self._input_buf.appendleft(buf[prev_start+len(bit):])\n        self._input_buf_len -= total_len\n        self._router._async_route(msg, self.stream)\n        return True\n\n    def pending_bytes(self):\n        \"\"\"\n        Return the number of bytes queued for transmission on this stream. This\n        can be used to limit the amount of data buffered in RAM by an otherwise\n        unlimited consumer.\n\n        For an accurate result, this method should be called from the Broker\n        thread, for example by using :meth:`Broker.defer_sync`.\n        \"\"\"\n        return self._writer._len\n\n    def on_transmit(self, broker):\n        \"\"\"\n        Transmit buffered messages.\n        \"\"\"\n        _vv and IOLOG.debug('%r.on_transmit()', self)\n        self._writer.on_transmit(broker)\n\n    def _send(self, msg):\n        _vv and IOLOG.debug('%r._send(%r)', self, msg)\n        self._writer.write(msg.pack())\n\n    def send(self, msg):\n        \"\"\"\n        Send `data` to `handle`, and tell the broker we have output. May be\n        called from any thread.\n        \"\"\"\n        self._router.broker.defer(self._send, msg)\n\n    def on_shutdown(self, broker):\n        \"\"\"\n        Disable :class:`Protocol` immediate disconnect behaviour.\n        \"\"\"\n        _v and LOG.debug('%r: shutting down', self)\n\n\nclass Context(object):\n    \"\"\"\n    Represent a remote context regardless of the underlying connection method.\n    Context objects are simple facades that emit messages through an\n    associated router, and have :ref:`signals` raised against them in response\n    to various events relating to the context.\n\n    **Note:** This is the somewhat limited core version, used by child\n    contexts. The master subclass is documented below this one.\n\n    Contexts maintain no internal state and are thread-safe.\n\n    Prefer :meth:`Router.context_by_id` over constructing context objects\n    explicitly, as that method is deduplicating, and returns the only context\n    instance :ref:`signals` will be raised on.\n\n    :param mitogen.core.Router router:\n        Router to emit messages through.\n    :param int context_id:\n        Context ID.\n    :param str name:\n        Context name.\n    \"\"\"\n    name = None\n    remote_name = None\n\n    def __init__(self, router, context_id, name=None):\n        self.router = router\n        self.context_id = context_id\n        if name:\n            self.name = to_text(name)\n\n    def __reduce__(self):\n        return _unpickle_context, (self.context_id, self.name)\n\n    def on_disconnect(self):\n        _v and LOG.debug('%r: disconnecting', self)\n        fire(self, 'disconnect')\n\n    def send_async(self, msg, persist=False):\n        \"\"\"\n        Arrange for `msg` to be delivered to this context, with replies\n        directed to a newly constructed receiver. :attr:`dst_id\n        <Message.dst_id>` is set to the target context ID, and :attr:`reply_to\n        <Message.reply_to>` is set to the newly constructed receiver's handle.\n\n        :param bool persist:\n            If :data:`False`, the handler will be unregistered after a single\n            message has been received.\n\n        :param mitogen.core.Message msg:\n            The message.\n\n        :returns:\n            :class:`Receiver` configured to receive any replies sent to the\n            message's `reply_to` handle.\n        \"\"\"\n        receiver = Receiver(self.router, persist=persist, respondent=self)\n        msg.dst_id = self.context_id\n        msg.reply_to = receiver.handle\n\n        _v and LOG.debug('sending message to %r: %r', self, msg)\n        self.send(msg)\n        return receiver\n\n    def call_service_async(self, service_name, method_name, **kwargs):\n        _v and LOG.debug('calling service %s.%s of %r, args: %r',\n                         service_name, method_name, self, kwargs)\n        if isinstance(service_name, BytesType):\n            service_name = service_name.encode('utf-8')\n        elif not isinstance(service_name, UnicodeType):\n            service_name = service_name.name()  # Service.name()\n        tup = (service_name, to_text(method_name), Kwargs(kwargs))\n        msg = Message.pickled(tup, handle=CALL_SERVICE)\n        return self.send_async(msg)\n\n    def send(self, msg):\n        \"\"\"\n        Arrange for `msg` to be delivered to this context. :attr:`dst_id\n        <Message.dst_id>` is set to the target context ID.\n\n        :param Message msg:\n            Message.\n        \"\"\"\n        msg.dst_id = self.context_id\n        self.router.route(msg)\n\n    def call_service(self, service_name, method_name, **kwargs):\n        recv = self.call_service_async(service_name, method_name, **kwargs)\n        return recv.get().unpickle()\n\n    def send_await(self, msg, deadline=None):\n        \"\"\"\n        Like :meth:`send_async`, but expect a single reply (`persist=False`)\n        delivered within `deadline` seconds.\n\n        :param mitogen.core.Message msg:\n            The message.\n        :param float deadline:\n            If not :data:`None`, seconds before timing out waiting for a reply.\n        :returns:\n            Deserialized reply.\n        :raises TimeoutError:\n            No message was received and `deadline` passed.\n        \"\"\"\n        receiver = self.send_async(msg)\n        response = receiver.get(deadline)\n        data = response.unpickle()\n        _vv and IOLOG.debug('%r._send_await() -> %r', self, data)\n        return data\n\n    def __repr__(self):\n        return 'Context(%s, %r)' % (self.context_id, self.name)\n\n\ndef _unpickle_context(context_id, name, router=None):\n    if not (isinstance(context_id, (int, long)) and context_id >= 0 and (\n        (name is None) or\n        (isinstance(name, UnicodeType) and len(name) < 100))\n    ):\n        raise TypeError('cannot unpickle Context: bad input')\n\n    if isinstance(router, Router):\n        return router.context_by_id(context_id, name=name)\n    return Context(None, context_id, name)  # For plain Jane pickle.\n\n\nclass Poller(object):\n    \"\"\"\n    A poller manages OS file descriptors the user is waiting to become\n    available for IO. The :meth:`poll` method blocks the calling thread\n    until one or more become ready. The default implementation is based on\n    :func:`select.poll`.\n\n    Each descriptor has an associated `data` element, which is unique for each\n    readiness type, and defaults to being the same as the file descriptor. The\n    :meth:`poll` method yields the data associated with a descriptor, rather\n    than the descriptor itself, allowing concise loops like::\n\n        p = Poller()\n        p.start_receive(conn.fd, data=conn.on_read)\n        p.start_transmit(conn.fd, data=conn.on_write)\n\n        for callback in p.poll():\n            callback()  # invoke appropriate bound instance method\n\n    Pollers may be modified while :meth:`poll` is yielding results. Removals\n    are processed immediately, causing pending events for the descriptor to be\n    discarded.\n\n    The :meth:`close` method must be called when a poller is discarded to avoid\n    a resource leak.\n\n    Pollers may only be used by one thread at a time.\n    \"\"\"\n    SUPPORTED = True\n\n    # This changed from select() to poll() in Mitogen 0.2.4. Since poll() has\n    # no upper FD limit, it is suitable for use with Latch, which must handle\n    # FDs larger than select's limit during many-host runs. We want this\n    # because poll() requires no setup and teardown: just a single system call,\n    # which is important because Latch.get() creates a Poller on each\n    # invocation. In a microbenchmark, poll() vs. epoll_ctl() is 30% faster in\n    # this scenario. If select() must return in future, it is important\n    # Latch.poller_class is set from parent.py to point to the industrial\n    # strength poller for the OS, otherwise Latch will fail randomly.\n\n    #: Increments on every poll(). Used to version _rfds and _wfds.\n    _generation = 1\n\n    def __init__(self):\n        self._rfds = {}\n        self._wfds = {}\n\n    def __repr__(self):\n        return '%s' % (type(self).__name__,)\n\n    def _update(self, fd):\n        \"\"\"\n        Required by PollPoller subclass.\n        \"\"\"\n        pass\n\n    @property\n    def readers(self):\n        \"\"\"\n        Return a list of `(fd, data)` tuples for every FD registered for\n        receive readiness.\n        \"\"\"\n        return list((fd, data) for fd, (data, gen) in self._rfds.items())\n\n    @property\n    def writers(self):\n        \"\"\"\n        Return a list of `(fd, data)` tuples for every FD registered for\n        transmit readiness.\n        \"\"\"\n        return list((fd, data) for fd, (data, gen) in self._wfds.items())\n\n    def close(self):\n        \"\"\"\n        Close any underlying OS resource used by the poller.\n        \"\"\"\n        pass\n\n    def start_receive(self, fd, data=None):\n        \"\"\"\n        Cause :meth:`poll` to yield `data` when `fd` is readable.\n        \"\"\"\n        self._rfds[fd] = (data or fd, self._generation)\n        self._update(fd)\n\n    def stop_receive(self, fd):\n        \"\"\"\n        Stop yielding readability events for `fd`.\n\n        Redundant calls to :meth:`stop_receive` are silently ignored, this may\n        change in future.\n        \"\"\"\n        self._rfds.pop(fd, None)\n        self._update(fd)\n\n    def start_transmit(self, fd, data=None):\n        \"\"\"\n        Cause :meth:`poll` to yield `data` when `fd` is writeable.\n        \"\"\"\n        self._wfds[fd] = (data or fd, self._generation)\n        self._update(fd)\n\n    def stop_transmit(self, fd):\n        \"\"\"\n        Stop yielding writeability events for `fd`.\n\n        Redundant calls to :meth:`stop_transmit` are silently ignored, this may\n        change in future.\n        \"\"\"\n        self._wfds.pop(fd, None)\n        self._update(fd)\n\n    def _poll(self, timeout):\n        (rfds, wfds, _), _ = io_op(select.select,\n            self._rfds,\n            self._wfds,\n            (), timeout\n        )\n\n        for fd in rfds:\n            _vv and IOLOG.debug('%r: POLLIN for %r', self, fd)\n            data, gen = self._rfds.get(fd, (None, None))\n            if gen and gen < self._generation:\n                yield data\n\n        for fd in wfds:\n            _vv and IOLOG.debug('%r: POLLOUT for %r', self, fd)\n            data, gen = self._wfds.get(fd, (None, None))\n            if gen and gen < self._generation:\n                yield data\n\n    def poll(self, timeout=None):\n        \"\"\"\n        Block the calling thread until one or more FDs are ready for IO.\n\n        :param float timeout:\n            If not :data:`None`, seconds to wait without an event before\n            returning an empty iterable.\n        :returns:\n            Iterable of `data` elements associated with ready FDs.\n        \"\"\"\n        _vv and IOLOG.debug('%r.poll(%r)', self, timeout)\n        self._generation += 1\n        return self._poll(timeout)\n\n\nclass Latch(object):\n    \"\"\"\n    A latch is a :class:`Queue.Queue`-like object that supports mutation and\n    waiting from multiple threads, however unlike :class:`Queue.Queue`,\n    waiting threads always remain interruptible, so CTRL+C always succeeds, and\n    waits where a timeout is set experience no wake up latency. These\n    properties are not possible in combination using the built-in threading\n    primitives available in Python 2.x.\n\n    Latches implement queues using the UNIX self-pipe trick, and a per-thread\n    :func:`socket.socketpair` that is lazily created the first time any\n    latch attempts to sleep on a thread, and dynamically associated with the\n    waiting Latch only for duration of the wait.\n\n    See :ref:`waking-sleeping-threads` for further discussion.\n    \"\"\"\n    poller_class = Poller\n\n    notify = None\n\n    # The _cls_ prefixes here are to make it crystal clear in the code which\n    # state mutation isn't covered by :attr:`_lock`.\n\n    #: List of reusable :func:`socket.socketpair` tuples. The list is mutated\n    #: from multiple threads, the only safe operations are `append()` and\n    #: `pop()`.\n    _cls_idle_socketpairs = []\n\n    #: List of every socket object that must be closed by :meth:`_on_fork`.\n    #: Inherited descriptors cannot be reused, as the duplicated handles\n    #: reference the same underlying kernel object in use by the parent.\n    _cls_all_sockets = []\n\n    def __init__(self):\n        self.closed = False\n        self._lock = threading.Lock()\n        #: List of unconsumed enqueued items.\n        self._queue = []\n        #: List of `(wsock, cookie)` awaiting an element, where `wsock` is the\n        #: socketpair's write side, and `cookie` is the string to write.\n        self._sleeping = []\n        #: Number of elements of :attr:`_sleeping` that have already been\n        #: woken, and have a corresponding element index from :attr:`_queue`\n        #: assigned to them.\n        self._waking = 0\n\n    @classmethod\n    def _on_fork(cls):\n        \"\"\"\n        Clean up any files belonging to the parent process after a fork.\n        \"\"\"\n        cls._cls_idle_socketpairs = []\n        while cls._cls_all_sockets:\n            cls._cls_all_sockets.pop().close()\n\n    def close(self):\n        \"\"\"\n        Mark the latch as closed, and cause every sleeping thread to be woken,\n        with :class:`mitogen.core.LatchError` raised in each thread.\n        \"\"\"\n        self._lock.acquire()\n        try:\n            self.closed = True\n            while self._waking < len(self._sleeping):\n                wsock, cookie = self._sleeping[self._waking]\n                self._wake(wsock, cookie)\n                self._waking += 1\n        finally:\n            self._lock.release()\n\n    def size(self):\n        \"\"\"\n        Return the number of items currently buffered.\n\n        As with :class:`Queue.Queue`, `0` may be returned even though a\n        subsequent call to :meth:`get` will succeed, since a message may be\n        posted at any moment between :meth:`size` and :meth:`get`.\n\n        As with :class:`Queue.Queue`, `>0` may be returned even though a\n        subsequent call to :meth:`get` will block, since another waiting thread\n        may be woken at any moment between :meth:`size` and :meth:`get`.\n\n        :raises LatchError:\n            The latch has already been marked closed.\n        \"\"\"\n        self._lock.acquire()\n        try:\n            if self.closed:\n                raise LatchError()\n            return len(self._queue)\n        finally:\n            self._lock.release()\n\n    def empty(self):\n        \"\"\"\n        Return `size() == 0`.\n\n        .. deprecated:: 0.2.8\n           Use :meth:`size` instead.\n\n        :raises LatchError:\n            The latch has already been marked closed.\n        \"\"\"\n        return self.size() == 0\n\n    def _get_socketpair(self):\n        \"\"\"\n        Return an unused socketpair, creating one if none exist.\n        \"\"\"\n        try:\n            return self._cls_idle_socketpairs.pop()  # pop() must be atomic\n        except IndexError:\n            rsock, wsock = socket.socketpair()\n            set_cloexec(rsock.fileno())\n            set_cloexec(wsock.fileno())\n            self._cls_all_sockets.extend((rsock, wsock))\n            return rsock, wsock\n\n    COOKIE_MAGIC, = struct.unpack('L', b('LTCH') * (struct.calcsize('L')//4))\n    COOKIE_FMT = '>Qqqq'  # #545: id() and get_ident() may exceed long on armhfp.\n    COOKIE_SIZE = struct.calcsize(COOKIE_FMT)\n\n    def _make_cookie(self):\n        \"\"\"\n        Return a string encoding the ID of the process, instance and thread.\n        This disambiguates legitimate wake-ups, accidental writes to the FD,\n        and buggy internal FD sharing.\n        \"\"\"\n        return struct.pack(self.COOKIE_FMT, self.COOKIE_MAGIC,\n                           os.getpid(), id(self), thread.get_ident())\n\n    def get(self, timeout=None, block=True):\n        \"\"\"\n        Return the next enqueued object, or sleep waiting for one.\n\n        :param float timeout:\n            If not :data:`None`, specifies a timeout in seconds.\n\n        :param bool block:\n            If :data:`False`, immediately raise\n            :class:`mitogen.core.TimeoutError` if the latch is empty.\n\n        :raises mitogen.core.LatchError:\n            :meth:`close` has been called, and the object is no longer valid.\n\n        :raises mitogen.core.TimeoutError:\n            Timeout was reached.\n\n        :returns:\n            The de-queued object.\n        \"\"\"\n        _vv and IOLOG.debug('%r.get(timeout=%r, block=%r)',\n                            self, timeout, block)\n        self._lock.acquire()\n        try:\n            if self.closed:\n                raise LatchError()\n            i = len(self._sleeping)\n            if len(self._queue) > i:\n                _vv and IOLOG.debug('%r.get() -> %r', self, self._queue[i])\n                return self._queue.pop(i)\n            if not block:\n                raise TimeoutError()\n            rsock, wsock = self._get_socketpair()\n            cookie = self._make_cookie()\n            self._sleeping.append((wsock, cookie))\n        finally:\n            self._lock.release()\n\n        poller = self.poller_class()\n        poller.start_receive(rsock.fileno())\n        try:\n            return self._get_sleep(poller, timeout, block, rsock, wsock, cookie)\n        finally:\n            poller.close()\n\n    def _get_sleep(self, poller, timeout, block, rsock, wsock, cookie):\n        \"\"\"\n        When a result is not immediately available, sleep waiting for\n        :meth:`put` to write a byte to our socket pair.\n        \"\"\"\n        _vv and IOLOG.debug(\n            '%r._get_sleep(timeout=%r, block=%r, fd=%d/%d)',\n            self, timeout, block, rsock.fileno(), wsock.fileno()\n        )\n\n        e = None\n        woken = None\n        try:\n            woken = list(poller.poll(timeout))\n        except Exception:\n            e = sys.exc_info()[1]\n\n        self._lock.acquire()\n        try:\n            i = self._sleeping.index((wsock, cookie))\n            del self._sleeping[i]\n            if not woken:\n                raise e or TimeoutError()\n\n            got_cookie = rsock.recv(self.COOKIE_SIZE)\n            self._cls_idle_socketpairs.append((rsock, wsock))\n\n            assert cookie == got_cookie, (\n                \"Cookie incorrect; got %r, expected %r\" \\\n                % (binascii.hexlify(got_cookie),\n                   binascii.hexlify(cookie))\n            )\n            assert i < self._waking, (\n                \"Cookie correct, but no queue element assigned.\"\n            )\n            self._waking -= 1\n            if self.closed:\n                raise LatchError()\n            _vv and IOLOG.debug('%r.get() wake -> %r', self, self._queue[i])\n            return self._queue.pop(i)\n        finally:\n            self._lock.release()\n\n    def put(self, obj=None):\n        \"\"\"\n        Enqueue an object, waking the first thread waiting for a result, if one\n        exists.\n\n        :param obj:\n            Object to enqueue. Defaults to :data:`None` as a convenience when\n            using :class:`Latch` only for synchronization.\n        :raises mitogen.core.LatchError:\n            :meth:`close` has been called, and the object is no longer valid.\n        \"\"\"\n        _vv and IOLOG.debug('%r.put(%r)', self, obj)\n        self._lock.acquire()\n        try:\n            if self.closed:\n                raise LatchError()\n            self._queue.append(obj)\n\n            wsock = None\n            if self._waking < len(self._sleeping):\n                wsock, cookie = self._sleeping[self._waking]\n                self._waking += 1\n                _vv and IOLOG.debug('%r.put() -> waking wfd=%r',\n                                    self, wsock.fileno())\n            elif self.notify:\n                self.notify(self)\n        finally:\n            self._lock.release()\n\n        if wsock:\n            self._wake(wsock, cookie)\n\n    def _wake(self, wsock, cookie):\n        written, disconnected = io_op(os.write, wsock.fileno(), cookie)\n        assert written == len(cookie) and not disconnected\n\n    def __repr__(self):\n        return 'Latch(%#x, size=%d, t=%r)' % (\n            id(self),\n            len(self._queue),\n            threading.currentThread().getName(),\n        )\n\n\nclass Waker(Protocol):\n    \"\"\"\n    :class:`BasicStream` subclass implementing the `UNIX self-pipe trick`_.\n    Used to wake the multiplexer when another thread needs to modify its state\n    (via a cross-thread function call).\n\n    .. _UNIX self-pipe trick: https://cr.yp.to/docs/selfpipe.html\n    \"\"\"\n    read_size = 1\n    broker_ident = None\n\n    @classmethod\n    def build_stream(cls, broker):\n        stream = super(Waker, cls).build_stream(broker)\n        stream.accept(*pipe())\n        return stream\n\n    def __init__(self, broker):\n        self._broker = broker\n        self._lock = threading.Lock()\n        self._deferred = []\n\n    def __repr__(self):\n        return 'Waker(fd=%r/%r)' % (\n            self.stream.receive_side and self.stream.receive_side.fd,\n            self.stream.transmit_side and self.stream.transmit_side.fd,\n        )\n\n    @property\n    def keep_alive(self):\n        \"\"\"\n        Prevent immediate Broker shutdown while deferred functions remain.\n        \"\"\"\n        self._lock.acquire()\n        try:\n            return len(self._deferred)\n        finally:\n            self._lock.release()\n\n    def on_receive(self, broker, buf):\n        \"\"\"\n        Drain the pipe and fire callbacks. Since :attr:`_deferred` is\n        synchronized, :meth:`defer` and :meth:`on_receive` can conspire to\n        ensure only one byte needs to be pending regardless of queue length.\n        \"\"\"\n        _vv and IOLOG.debug('%r.on_receive()', self)\n        self._lock.acquire()\n        try:\n            deferred = self._deferred\n            self._deferred = []\n        finally:\n            self._lock.release()\n\n        for func, args, kwargs in deferred:\n            try:\n                func(*args, **kwargs)\n            except Exception:\n                LOG.exception('defer() crashed: %r(*%r, **%r)',\n                              func, args, kwargs)\n                broker.shutdown()\n\n    def _wake(self):\n        \"\"\"\n        Wake the multiplexer by writing a byte. If Broker is midway through\n        teardown, the FD may already be closed, so ignore EBADF.\n        \"\"\"\n        try:\n            self.stream.transmit_side.write(b(' '))\n        except OSError:\n            e = sys.exc_info()[1]\n            if e.args[0] != errno.EBADF:\n                raise\n\n    broker_shutdown_msg = (\n        \"An attempt was made to enqueue a message with a Broker that has \"\n        \"already exitted. It is likely your program called Broker.shutdown() \"\n        \"too early.\"\n    )\n\n    def defer(self, func, *args, **kwargs):\n        \"\"\"\n        Arrange for `func()` to execute on the broker thread. This function\n        returns immediately without waiting the result of `func()`. Use\n        :meth:`defer_sync` to block until a result is available.\n\n        :raises mitogen.core.Error:\n            :meth:`defer` was called after :class:`Broker` has begun shutdown.\n        \"\"\"\n        if thread.get_ident() == self.broker_ident:\n            _vv and IOLOG.debug('%r.defer() [immediate]', self)\n            return func(*args, **kwargs)\n        if self._broker._exitted:\n            raise Error(self.broker_shutdown_msg)\n\n        _vv and IOLOG.debug('%r.defer() [fd=%r]', self,\n                            self.stream.transmit_side.fd)\n        self._lock.acquire()\n        try:\n            should_wake = not self._deferred\n            self._deferred.append((func, args, kwargs))\n        finally:\n            self._lock.release()\n\n        if should_wake:\n            self._wake()\n\n\nclass IoLoggerProtocol(DelimitedProtocol):\n    \"\"\"\n    Handle redirection of standard IO into the :mod:`logging` package.\n    \"\"\"\n    @classmethod\n    def build_stream(cls, name, dest_fd):\n        \"\"\"\n        Even though the descriptor `dest_fd` will hold the opposite end of the\n        socket open, we must keep a separate dup() of it (i.e. wsock) in case\n        some code decides to overwrite `dest_fd` later, which would thus break\n        :meth:`on_shutdown`.\n        \"\"\"\n        rsock, wsock = socket.socketpair()\n        os.dup2(wsock.fileno(), dest_fd)\n        stream = super(IoLoggerProtocol, cls).build_stream(name)\n        stream.name = name\n        stream.accept(rsock, wsock)\n        return stream\n\n    def __init__(self, name):\n        self._log = logging.getLogger(name)\n        # #453: prevent accidental log initialization in a child creating a\n        # feedback loop.\n        self._log.propagate = False\n        self._log.handlers = logging.getLogger().handlers[:]\n\n    def on_shutdown(self, broker):\n        \"\"\"\n        Shut down the write end of the socket, preventing any further writes to\n        it by this process, or subprocess that inherited it. This allows any\n        remaining kernel-buffered data to be drained during graceful shutdown\n        without the buffer continuously refilling due to some out of control\n        child process.\n        \"\"\"\n        _v and LOG.debug('%r: shutting down', self)\n        if not IS_WSL:\n            # #333: WSL generates invalid readiness indication on shutdown().\n            # This modifies the *kernel object* inherited by children, causing\n            # EPIPE on subsequent writes to any dupped FD in any process. The\n            # read side can then drain completely of prior buffered data.\n            self.stream.transmit_side.fp.shutdown(socket.SHUT_WR)\n        self.stream.transmit_side.close()\n\n    def on_line_received(self, line):\n        \"\"\"\n        Decode the received line as UTF-8 and pass it to the logging framework.\n        \"\"\"\n        self._log.info('%s', line.decode('utf-8', 'replace'))\n\n\nclass Router(object):\n    \"\"\"\n    Route messages between contexts, and invoke local handlers for messages\n    addressed to this context. :meth:`Router.route() <route>` straddles the\n    :class:`Broker` thread and user threads, it is safe to call anywhere.\n\n    **Note:** This is the somewhat limited core version of the Router class\n    used by child contexts. The master subclass is documented below this one.\n    \"\"\"\n    #: The :class:`mitogen.core.Context` subclass to use when constructing new\n    #: :class:`Context` objects in :meth:`myself` and :meth:`context_by_id`.\n    #: Permits :class:`Router` subclasses to extend the :class:`Context`\n    #: interface, as done in :class:`mitogen.parent.Router`.\n    context_class = Context\n\n    max_message_size = 128 * 1048576\n\n    #: When :data:`True`, permit children to only communicate with the current\n    #: context or a parent of the current context. Routing between siblings or\n    #: children of parents is prohibited, ensuring no communication is possible\n    #: between intentionally partitioned networks, such as when a program\n    #: simultaneously manipulates hosts spread across a corporate and a\n    #: production network, or production networks that are otherwise\n    #: air-gapped.\n    #:\n    #: Sending a prohibited message causes an error to be logged and a dead\n    #: message to be sent in reply to the errant message, if that message has\n    #: ``reply_to`` set.\n    #:\n    #: The value of :data:`unidirectional` becomes the default for the\n    #: :meth:`local() <mitogen.master.Router.local>` `unidirectional`\n    #: parameter.\n    unidirectional = False\n\n    duplicate_handle_msg = 'cannot register a handle that already exists'\n    refused_msg = 'refused by policy'\n    invalid_handle_msg = 'invalid handle'\n    too_large_msg = 'message too large (max %d bytes)'\n    respondent_disconnect_msg = 'the respondent Context has disconnected'\n    broker_exit_msg = 'Broker has exitted'\n    no_route_msg = 'no route to %r, my ID is %r'\n    unidirectional_msg = (\n        'routing mode prevents forward of message from context %d via '\n        'context %d'\n    )\n\n    def __init__(self, broker):\n        self.broker = broker\n        listen(broker, 'exit', self._on_broker_exit)\n        self._setup_logging()\n\n        self._write_lock = threading.Lock()\n        #: context ID -> Stream; must hold _write_lock to edit or iterate\n        self._stream_by_id = {}\n        #: List of contexts to notify of shutdown; must hold _write_lock\n        self._context_by_id = {}\n        self._last_handle = itertools.count(1000)\n        #: handle -> (persistent?, func(msg))\n        self._handle_map = {}\n        #: Context -> set { handle, .. }\n        self._handles_by_respondent = {}\n        self.add_handler(self._on_del_route, DEL_ROUTE)\n\n    def __repr__(self):\n        return 'Router(%r)' % (self.broker,)\n\n    def _setup_logging(self):\n        \"\"\"\n        This is done in the :class:`Router` constructor for historical reasons.\n        It must be called before ExternalContext logs its first messages, but\n        after logging has been setup. It must also be called when any router is\n        constructed for a consumer app.\n        \"\"\"\n        # Here seems as good a place as any.\n        global _v, _vv\n        _v = logging.getLogger().level <= logging.DEBUG\n        _vv = IOLOG.level <= logging.DEBUG\n\n    def _on_del_route(self, msg):\n        \"\"\"\n        Stub :data:`DEL_ROUTE` handler; fires 'disconnect' events on the\n        corresponding :attr:`_context_by_id` member. This is replaced by\n        :class:`mitogen.parent.RouteMonitor` in an upgraded context.\n        \"\"\"\n        if msg.is_dead:\n            return\n\n        target_id_s, _, name = bytes_partition(msg.data, b(':'))\n        target_id = int(target_id_s, 10)\n        LOG.error('%r: deleting route to %s (%d)',\n                  self, to_text(name), target_id)\n        context = self._context_by_id.get(target_id)\n        if context:\n            fire(context, 'disconnect')\n        else:\n            LOG.debug('DEL_ROUTE for unknown ID %r: %r', target_id, msg)\n\n    def _on_stream_disconnect(self, stream):\n        notify = []\n        self._write_lock.acquire()\n        try:\n            for context in list(self._context_by_id.values()):\n                stream_ = self._stream_by_id.get(context.context_id)\n                if stream_ is stream:\n                    del self._stream_by_id[context.context_id]\n                    notify.append(context)\n        finally:\n            self._write_lock.release()\n\n        # Happens outside lock as e.g. RouteMonitor wants the same lock.\n        for context in notify:\n            context.on_disconnect()\n\n    def _on_broker_exit(self):\n        \"\"\"\n        Called prior to broker exit, informs callbacks registered with\n        :meth:`add_handler` the connection is dead.\n        \"\"\"\n        _v and LOG.debug('%r: broker has exitted', self)\n        while self._handle_map:\n            _, (_, func, _, _) = self._handle_map.popitem()\n            func(Message.dead(self.broker_exit_msg))\n\n    def myself(self):\n        \"\"\"\n        Return a :class:`Context` referring to the current process. Since\n        :class:`Context` is serializable, this is convenient to use in remote\n        function call parameter lists.\n        \"\"\"\n        return self.context_class(\n            router=self,\n            context_id=mitogen.context_id,\n            name='self',\n        )\n\n    def context_by_id(self, context_id, via_id=None, create=True, name=None):\n        \"\"\"\n        Return or construct a :class:`Context` given its ID. An internal\n        mapping of ID to the canonical :class:`Context` representing that ID,\n        so that :ref:`signals` can be raised.\n\n        This may be called from any thread, lookup and construction are atomic.\n\n        :param int context_id:\n            The context ID to look up.\n        :param int via_id:\n            If the :class:`Context` does not already exist, set its\n            :attr:`Context.via` to the :class:`Context` matching this ID.\n        :param bool create:\n            If the :class:`Context` does not already exist, create it.\n        :param str name:\n            If the :class:`Context` does not already exist, set its name.\n\n        :returns:\n            :class:`Context`, or return :data:`None` if `create` is\n            :data:`False` and no :class:`Context` previously existed.\n        \"\"\"\n        context = self._context_by_id.get(context_id)\n        if context:\n            return context\n\n        if create and via_id is not None:\n            via = self.context_by_id(via_id)\n        else:\n            via = None\n\n        self._write_lock.acquire()\n        try:\n            context = self._context_by_id.get(context_id)\n            if create and not context:\n                context = self.context_class(self, context_id, name=name)\n                context.via = via\n                self._context_by_id[context_id] = context\n        finally:\n            self._write_lock.release()\n\n        return context\n\n    def register(self, context, stream):\n        \"\"\"\n        Register a newly constructed context and its associated stream, and add\n        the stream's receive side to the I/O multiplexer. This method remains\n        public while the design has not yet settled.\n        \"\"\"\n        _v and LOG.debug('%s: registering %r to stream %r',\n                         self, context, stream)\n        self._write_lock.acquire()\n        try:\n            self._stream_by_id[context.context_id] = stream\n            self._context_by_id[context.context_id] = context\n        finally:\n            self._write_lock.release()\n\n        self.broker.start_receive(stream)\n        listen(stream, 'disconnect', lambda: self._on_stream_disconnect(stream))\n\n    def stream_by_id(self, dst_id):\n        \"\"\"\n        Return the :class:`Stream` that should be used to communicate with\n        `dst_id`. If a specific route for `dst_id` is not known, a reference to\n        the parent context's stream is returned. If the parent is disconnected,\n        or when running in the master context, return :data:`None` instead.\n\n        This can be used from any thread, but its output is only meaningful\n        from the context of the :class:`Broker` thread, as disconnection or\n        replacement could happen in parallel on the broker thread at any\n        moment. \n        \"\"\"\n        return (\n            self._stream_by_id.get(dst_id) or\n            self._stream_by_id.get(mitogen.parent_id)\n        )\n\n    def del_handler(self, handle):\n        \"\"\"\n        Remove the handle registered for `handle`\n\n        :raises KeyError:\n            The handle wasn't registered.\n        \"\"\"\n        _, _, _, respondent = self._handle_map.pop(handle)\n        if respondent:\n            self._handles_by_respondent[respondent].discard(handle)\n\n    def add_handler(self, fn, handle=None, persist=True,\n                    policy=None, respondent=None,\n                    overwrite=False):\n        \"\"\"\n        Invoke `fn(msg)` on the :class:`Broker` thread for each Message sent to\n        `handle` from this context. Unregister after one invocation if\n        `persist` is :data:`False`. If `handle` is :data:`None`, a new handle\n        is allocated and returned.\n\n        :param int handle:\n            If not :data:`None`, an explicit handle to register, usually one of\n            the ``mitogen.core.*`` constants. If unspecified, a new unused\n            handle will be allocated.\n\n        :param bool persist:\n            If :data:`False`, the handler will be unregistered after a single\n            message has been received.\n\n        :param mitogen.core.Context respondent:\n            Context that messages to this handle are expected to be sent from.\n            If specified, arranges for a dead message to be delivered to `fn`\n            when disconnection of the context is detected.\n\n            In future `respondent` will likely also be used to prevent other\n            contexts from sending messages to the handle.\n\n        :param function policy:\n            Function invoked as `policy(msg, stream)` where `msg` is a\n            :class:`mitogen.core.Message` about to be delivered, and `stream`\n            is the :class:`mitogen.core.Stream` on which it was received. The\n            function must return :data:`True`, otherwise an error is logged and\n            delivery is refused.\n\n            Two built-in policy functions exist:\n\n            * :func:`has_parent_authority`: requires the message arrived from a\n              parent context, or a context acting with a parent context's\n              authority (``auth_id``).\n\n            * :func:`mitogen.parent.is_immediate_child`: requires the\n              message arrived from an immediately connected child, for use in\n              messaging patterns where either something becomes buggy or\n              insecure by permitting indirect upstream communication.\n\n            In case of refusal, and the message's ``reply_to`` field is\n            nonzero, a :class:`mitogen.core.CallError` is delivered to the\n            sender indicating refusal occurred.\n\n        :param bool overwrite:\n            If :data:`True`, allow existing handles to be silently overwritten.\n\n        :return:\n            `handle`, or if `handle` was :data:`None`, the newly allocated\n            handle.\n        :raises Error:\n            Attemp to register handle that was already registered.\n        \"\"\"\n        handle = handle or next(self._last_handle)\n        _vv and IOLOG.debug('%r.add_handler(%r, %r, %r)', self, fn, handle, persist)\n        if handle in self._handle_map and not overwrite:\n            raise Error(self.duplicate_handle_msg)\n\n        self._handle_map[handle] = persist, fn, policy, respondent\n        if respondent:\n            if respondent not in self._handles_by_respondent:\n                self._handles_by_respondent[respondent] = set()\n                listen(respondent, 'disconnect',\n                       lambda: self._on_respondent_disconnect(respondent))\n            self._handles_by_respondent[respondent].add(handle)\n\n        return handle\n\n    def _on_respondent_disconnect(self, context):\n        for handle in self._handles_by_respondent.pop(context, ()):\n            _, fn, _, _  = self._handle_map[handle]\n            fn(Message.dead(self.respondent_disconnect_msg))\n            del self._handle_map[handle]\n\n    def _maybe_send_dead(self, msg, reason, *args):\n        if args:\n            reason %= args\n        LOG.debug('%r: %r is dead: %r', self, msg, reason)\n        if msg.reply_to and not msg.is_dead:\n            msg.reply(Message.dead(reason=reason), router=self)\n\n    def _invoke(self, msg, stream):\n        # IOLOG.debug('%r._invoke(%r)', self, msg)\n        try:\n            persist, fn, policy, respondent = self._handle_map[msg.handle]\n        except KeyError:\n            self._maybe_send_dead(msg, reason=self.invalid_handle_msg)\n            return\n\n        if respondent and not (msg.is_dead or\n                               msg.src_id == respondent.context_id):\n            self._maybe_send_dead(msg, 'reply from unexpected context')\n            return\n\n        if policy and not policy(msg, stream):\n            self._maybe_send_dead(msg, self.refused_msg)\n            return\n\n        if not persist:\n            self.del_handler(msg.handle)\n\n        try:\n            fn(msg)\n        except Exception:\n            LOG.exception('%r._invoke(%r): %r crashed', self, msg, fn)\n\n    def _async_route(self, msg, in_stream=None):\n        \"\"\"\n        Arrange for `msg` to be forwarded towards its destination. If its\n        destination is the local context, then arrange for it to be dispatched\n        using the local handlers.\n\n        This is a lower overhead version of :meth:`route` that may only be\n        called from the :class:`Broker` thread.\n\n        :param Stream in_stream:\n            If not :data:`None`, the stream the message arrived on. Used for\n            performing source route verification, to ensure sensitive messages\n            such as ``CALL_FUNCTION`` arrive only from trusted contexts.\n        \"\"\"\n        _vv and IOLOG.debug('%r._async_route(%r, %r)', self, msg, in_stream)\n\n        if len(msg.data) > self.max_message_size:\n            self._maybe_send_dead(msg, self.too_large_msg % (\n                self.max_message_size,\n            ))\n            return\n\n        # Perform source verification.\n        if in_stream:\n            parent = self._stream_by_id.get(mitogen.parent_id)\n            expect = self._stream_by_id.get(msg.auth_id, parent)\n            if in_stream != expect:\n                LOG.error('%r: bad auth_id: got %r via %r, not %r: %r',\n                          self, msg.auth_id, in_stream, expect, msg)\n                return\n\n            if msg.src_id != msg.auth_id:\n                expect = self._stream_by_id.get(msg.src_id, parent)\n                if in_stream != expect:\n                    LOG.error('%r: bad src_id: got %r via %r, not %r: %r',\n                              self, msg.src_id, in_stream, expect, msg)\n                    return\n\n            if in_stream.protocol.auth_id is not None:\n                msg.auth_id = in_stream.protocol.auth_id\n\n            # Maintain a set of IDs the source ever communicated with.\n            in_stream.protocol.egress_ids.add(msg.dst_id)\n\n        if msg.dst_id == mitogen.context_id:\n            return self._invoke(msg, in_stream)\n\n        out_stream = self._stream_by_id.get(msg.dst_id)\n        if out_stream is None:\n            out_stream = self._stream_by_id.get(mitogen.parent_id)\n\n        if out_stream is None:\n            self._maybe_send_dead(msg, self.no_route_msg,\n                                  msg.dst_id, mitogen.context_id)\n            return\n\n        if in_stream and self.unidirectional and not \\\n                (in_stream.protocol.is_privileged or\n                 out_stream.protocol.is_privileged):\n            self._maybe_send_dead(msg, self.unidirectional_msg,\n                in_stream.protocol.remote_id, out_stream.protocol.remote_id)\n            return\n\n        out_stream.protocol._send(msg)\n\n    def route(self, msg):\n        \"\"\"\n        Arrange for the :class:`Message` `msg` to be delivered to its\n        destination using any relevant downstream context, or if none is found,\n        by forwarding the message upstream towards the master context. If `msg`\n        is destined for the local context, it is dispatched using the handles\n        registered with :meth:`add_handler`.\n\n        This may be called from any thread.\n        \"\"\"\n        self.broker.defer(self._async_route, msg)\n\n\nclass NullTimerList(object):\n    def get_timeout(self):\n        return None\n\n\nclass Broker(object):\n    \"\"\"\n    Responsible for handling I/O multiplexing in a private thread.\n\n    **Note:** This somewhat limited core version is used by children. The\n    master subclass is documented below.\n    \"\"\"\n    poller_class = Poller\n    _waker = None\n    _thread = None\n\n    # :func:`mitogen.parent._upgrade_broker` replaces this with\n    # :class:`mitogen.parent.TimerList` during upgrade.\n    timers = NullTimerList()\n\n    #: Seconds grace to allow :class:`streams <Stream>` to shutdown gracefully\n    #: before force-disconnecting them during :meth:`shutdown`.\n    shutdown_timeout = 3.0\n\n    def __init__(self, poller_class=None, activate_compat=True):\n        self._alive = True\n        self._exitted = False\n        self._waker = Waker.build_stream(self)\n        #: Arrange for `func(\\*args, \\**kwargs)` to be executed on the broker\n        #: thread, or immediately if the current thread is the broker thread.\n        #: Safe to call from any thread.\n        self.defer = self._waker.protocol.defer\n        self.poller = self.poller_class()\n        self.poller.start_receive(\n            self._waker.receive_side.fd,\n            (self._waker.receive_side, self._waker.on_receive)\n        )\n        self._thread = threading.Thread(\n            target=self._broker_main,\n            name='mitogen.broker'\n        )\n        self._thread.start()\n        if activate_compat:\n            self._py24_25_compat()\n\n    def _py24_25_compat(self):\n        \"\"\"\n        Python 2.4/2.5 have grave difficulties with threads/fork. We\n        mandatorily quiesce all running threads during fork using a\n        monkey-patch there.\n        \"\"\"\n        if sys.version_info < (2, 6):\n            # import_module() is used to avoid dep scanner.\n            os_fork = import_module('mitogen.os_fork')\n            os_fork._notice_broker_or_pool(self)\n\n    def start_receive(self, stream):\n        \"\"\"\n        Mark the :attr:`receive_side <Stream.receive_side>` on `stream` as\n        ready for reading. Safe to call from any thread. When the associated\n        file descriptor becomes ready for reading,\n        :meth:`BasicStream.on_receive` will be called.\n        \"\"\"\n        _vv and IOLOG.debug('%r.start_receive(%r)', self, stream)\n        side = stream.receive_side\n        assert side and not side.closed\n        self.defer(self.poller.start_receive,\n                   side.fd, (side, stream.on_receive))\n\n    def stop_receive(self, stream):\n        \"\"\"\n        Mark the :attr:`receive_side <Stream.receive_side>` on `stream` as not\n        ready for reading. Safe to call from any thread.\n        \"\"\"\n        _vv and IOLOG.debug('%r.stop_receive(%r)', self, stream)\n        self.defer(self.poller.stop_receive, stream.receive_side.fd)\n\n    def _start_transmit(self, stream):\n        \"\"\"\n        Mark the :attr:`transmit_side <Stream.transmit_side>` on `stream` as\n        ready for writing. Must only be called from the Broker thread. When the\n        associated file descriptor becomes ready for writing,\n        :meth:`BasicStream.on_transmit` will be called.\n        \"\"\"\n        _vv and IOLOG.debug('%r._start_transmit(%r)', self, stream)\n        side = stream.transmit_side\n        assert side and not side.closed\n        self.poller.start_transmit(side.fd, (side, stream.on_transmit))\n\n    def _stop_transmit(self, stream):\n        \"\"\"\n        Mark the :attr:`transmit_side <Stream.receive_side>` on `stream` as not\n        ready for writing.\n        \"\"\"\n        _vv and IOLOG.debug('%r._stop_transmit(%r)', self, stream)\n        self.poller.stop_transmit(stream.transmit_side.fd)\n\n    def keep_alive(self):\n        \"\"\"\n        Return :data:`True` if any reader's :attr:`Side.keep_alive` attribute\n        is :data:`True`, or any :class:`Context` is still registered that is\n        not the master. Used to delay shutdown while some important work is in\n        progress (e.g. log draining).\n        \"\"\"\n        it = (side.keep_alive for (_, (side, _)) in self.poller.readers)\n        return sum(it, 0) > 0 or self.timers.get_timeout() is not None\n\n    def defer_sync(self, func):\n        \"\"\"\n        Arrange for `func()` to execute on :class:`Broker` thread, blocking the\n        current thread until a result or exception is available.\n\n        :returns:\n            Return value of `func()`.\n        \"\"\"\n        latch = Latch()\n        def wrapper():\n            try:\n                latch.put(func())\n            except Exception:\n                latch.put(sys.exc_info()[1])\n        self.defer(wrapper)\n        res = latch.get()\n        if isinstance(res, Exception):\n            raise res\n        return res\n\n    def _call(self, stream, func):\n        \"\"\"\n        Call `func(self)`, catching any exception that might occur, logging it,\n        and force-disconnecting the related `stream`.\n        \"\"\"\n        try:\n            func(self)\n        except Exception:\n            LOG.exception('%r crashed', stream)\n            stream.on_disconnect(self)\n\n    def _loop_once(self, timeout=None):\n        \"\"\"\n        Execute a single :class:`Poller` wait, dispatching any IO events that\n        caused the wait to complete.\n\n        :param float timeout:\n            If not :data:`None`, maximum time in seconds to wait for events.\n        \"\"\"\n        _vv and IOLOG.debug('%r._loop_once(%r, %r)',\n                            self, timeout, self.poller)\n\n        timer_to = self.timers.get_timeout()\n        if timeout is None:\n            timeout = timer_to\n        elif timer_to is not None and timer_to < timeout:\n            timeout = timer_to\n\n        #IOLOG.debug('readers =\\n%s', pformat(self.poller.readers))\n        #IOLOG.debug('writers =\\n%s', pformat(self.poller.writers))\n        for side, func in self.poller.poll(timeout):\n            self._call(side.stream, func)\n        if timer_to is not None:\n            self.timers.expire()\n\n    def _broker_exit(self):\n        \"\"\"\n        Forcefully call :meth:`Stream.on_disconnect` on any streams that failed\n        to shut down gracefully, then discard the :class:`Poller`.\n        \"\"\"\n        for _, (side, _) in self.poller.readers + self.poller.writers:\n            LOG.debug('%r: force disconnecting %r', self, side)\n            side.stream.on_disconnect(self)\n\n        self.poller.close()\n\n    def _broker_shutdown(self):\n        \"\"\"\n        Invoke :meth:`Stream.on_shutdown` for every active stream, then allow\n        up to :attr:`shutdown_timeout` seconds for the streams to unregister\n        themselves, logging an error if any did not unregister during the grace\n        period.\n        \"\"\"\n        for _, (side, _) in self.poller.readers + self.poller.writers:\n            self._call(side.stream, side.stream.on_shutdown)\n\n        deadline = time.time() + self.shutdown_timeout\n        while self.keep_alive() and time.time() < deadline:\n            self._loop_once(max(0, deadline - time.time()))\n\n        if self.keep_alive():\n            LOG.error('%r: pending work still existed %d seconds after '\n                      'shutdown began. This may be due to a timer that is yet '\n                      'to expire, or a child connection that did not fully '\n                      'shut down.', self, self.shutdown_timeout)\n\n    def _do_broker_main(self):\n        \"\"\"\n        Broker thread main function. Dispatches IO events until\n        :meth:`shutdown` is called.\n        \"\"\"\n        # For Python 2.4, no way to retrieve ident except on thread.\n        self._waker.protocol.broker_ident = thread.get_ident()\n        try:\n            while self._alive:\n                self._loop_once()\n\n            fire(self, 'shutdown')\n            self._broker_shutdown()\n        except Exception:\n            e = sys.exc_info()[1]\n            LOG.exception('broker crashed')\n            syslog.syslog(syslog.LOG_ERR, 'broker crashed: %s' % (e,))\n            syslog.closelog()  # prevent test 'fd leak'.\n\n        self._alive = False  # Ensure _alive is consistent on crash.\n        self._exitted = True\n        self._broker_exit()\n\n    def _broker_main(self):\n        try:\n            _profile_hook('mitogen.broker', self._do_broker_main)\n        finally:\n            # 'finally' to ensure _on_broker_exit() can always SIGTERM.\n            fire(self, 'exit')\n\n    def shutdown(self):\n        \"\"\"\n        Request broker gracefully disconnect streams and stop. Safe to call\n        from any thread.\n        \"\"\"\n        _v and LOG.debug('%r: shutting down', self)\n        def _shutdown():\n            self._alive = False\n        if self._alive and not self._exitted:\n            self.defer(_shutdown)\n\n    def join(self):\n        \"\"\"\n        Wait for the broker to stop, expected to be called after\n        :meth:`shutdown`.\n        \"\"\"\n        self._thread.join()\n\n    def __repr__(self):\n        return 'Broker(%04x)' % (id(self) & 0xffff,)\n\n\nclass Dispatcher(object):\n    \"\"\"\n    Implementation of the :data:`CALL_FUNCTION` handle for a child context.\n    Listens on the child's main thread for messages sent by\n    :class:`mitogen.parent.CallChain` and dispatches the function calls they\n    describe.\n\n    If a :class:`mitogen.parent.CallChain` sending a message is in pipelined\n    mode, any exception that occurs is recorded, and causes all subsequent\n    calls with the same `chain_id` to fail with the same exception.\n    \"\"\"\n    def __repr__(self):\n        return 'Dispatcher'\n\n    def __init__(self, econtext):\n        self.econtext = econtext\n        #: Chain ID -> CallError if prior call failed.\n        self._error_by_chain_id = {}\n        self.recv = Receiver(\n            router=econtext.router,\n            handle=CALL_FUNCTION,\n            policy=has_parent_authority,\n        )\n        #: The :data:`CALL_SERVICE` :class:`Receiver` that will eventually be\n        #: reused by :class:`mitogen.service.Pool`, should it ever be loaded.\n        #: This is necessary for race-free reception of all service requests\n        #: delivered regardless of whether the stub or real service pool are\n        #: loaded. See #547 for related sorrows.\n        Dispatcher._service_recv = Receiver(\n            router=econtext.router,\n            handle=CALL_SERVICE,\n            policy=has_parent_authority,\n        )\n        self._service_recv.notify = self._on_call_service\n        listen(econtext.broker, 'shutdown', self.recv.close)\n\n    @classmethod\n    @takes_econtext\n    def forget_chain(cls, chain_id, econtext):\n        econtext.dispatcher._error_by_chain_id.pop(chain_id, None)\n\n    def _parse_request(self, msg):\n        data = msg.unpickle(throw=False)\n        _v and LOG.debug('%r: dispatching %r', self, data)\n\n        chain_id, modname, klass, func, args, kwargs = data\n        obj = import_module(modname)\n        if klass:\n            obj = getattr(obj, klass)\n        fn = getattr(obj, func)\n        if getattr(fn, 'mitogen_takes_econtext', None):\n            kwargs.setdefault('econtext', self.econtext)\n        if getattr(fn, 'mitogen_takes_router', None):\n            kwargs.setdefault('router', self.econtext.router)\n\n        return chain_id, fn, args, kwargs\n\n    def _dispatch_one(self, msg):\n        try:\n            chain_id, fn, args, kwargs = self._parse_request(msg)\n        except Exception:\n            return None, CallError(sys.exc_info()[1])\n\n        if chain_id in self._error_by_chain_id:\n            return chain_id, self._error_by_chain_id[chain_id]\n\n        try:\n            return chain_id, fn(*args, **kwargs)\n        except Exception:\n            e = CallError(sys.exc_info()[1])\n            if chain_id is not None:\n                self._error_by_chain_id[chain_id] = e\n            return chain_id, e\n\n    def _on_call_service(self, recv):\n        \"\"\"\n        Notifier for the :data:`CALL_SERVICE` receiver. This is called on the\n        :class:`Broker` thread for any service messages arriving at this\n        context, for as long as no real service pool implementation is loaded.\n\n        In order to safely bootstrap the service pool implementation a sentinel\n        message is enqueued on the :data:`CALL_FUNCTION` receiver in order to\n        wake the main thread, where the importer can run without any\n        possibility of suffering deadlock due to concurrent uses of the\n        importer.\n\n        Should the main thread be blocked indefinitely, preventing the import\n        from ever running, if it is blocked waiting on a service call, then it\n        means :mod:`mitogen.service` has already been imported and\n        :func:`mitogen.service.get_or_create_pool` has already run, meaning the\n        service pool is already active and the duplicate initialization was not\n        needed anyway.\n\n        #547: This trickery is needed to avoid the alternate option of spinning\n        a temporary thread to import the service pool, which could deadlock if\n        a custom import hook executing on the main thread (under the importer\n        lock) would block waiting for some data that was in turn received by a\n        service. Main thread import lock can't be released until service is\n        running, service cannot satisfy request until import lock is released.\n        \"\"\"\n        self.recv._on_receive(Message(handle=STUB_CALL_SERVICE))\n\n    def _init_service_pool(self):\n        import mitogen.service\n        mitogen.service.get_or_create_pool(router=self.econtext.router)\n\n    def _dispatch_calls(self):\n        for msg in self.recv:\n            if msg.handle == STUB_CALL_SERVICE:\n                if msg.src_id == mitogen.context_id:\n                    self._init_service_pool()\n                continue\n\n            chain_id, ret = self._dispatch_one(msg)\n            _v and LOG.debug('%r: %r -> %r', self, msg, ret)\n            if msg.reply_to:\n                msg.reply(ret)\n            elif isinstance(ret, CallError) and chain_id is None:\n                LOG.error('No-reply function call failed: %s', ret)\n\n    def run(self):\n        if self.econtext.config.get('on_start'):\n            self.econtext.config['on_start'](self.econtext)\n\n        _profile_hook('mitogen.child_main', self._dispatch_calls)\n\n\nclass ExternalContext(object):\n    \"\"\"\n    External context implementation.\n\n    This class contains the main program implementation for new children. It is\n    responsible for setting up everything about the process environment, import\n    hooks, standard IO redirection, logging, configuring a :class:`Router` and\n    :class:`Broker`, and finally arranging for :class:`Dispatcher` to take over\n    the main thread after initialization is complete.\n\n    .. attribute:: broker\n\n        The :class:`mitogen.core.Broker` instance.\n\n    .. attribute:: context\n\n        The :class:`mitogen.core.Context` instance.\n\n    .. attribute:: channel\n\n        The :class:`mitogen.core.Channel` over which :data:`CALL_FUNCTION`\n        requests are received.\n\n    .. attribute:: importer\n\n        The :class:`mitogen.core.Importer` instance.\n\n    .. attribute:: stdout_log\n\n        The :class:`IoLogger` connected to :data:`sys.stdout`.\n\n    .. attribute:: stderr_log\n\n        The :class:`IoLogger` connected to :data:`sys.stderr`.\n    \"\"\"\n    detached = False\n\n    def __init__(self, config):\n        self.config = config\n\n    def _on_broker_exit(self):\n        if not self.config['profiling']:\n            os.kill(os.getpid(), signal.SIGTERM)\n\n    def _on_shutdown_msg(self, msg):\n        if not msg.is_dead:\n            _v and LOG.debug('shutdown request from context %d', msg.src_id)\n            self.broker.shutdown()\n\n    def _on_parent_disconnect(self):\n        if self.detached:\n            mitogen.parent_ids = []\n            mitogen.parent_id = None\n            LOG.info('Detachment complete')\n        else:\n            _v and LOG.debug('parent stream is gone, dying.')\n            self.broker.shutdown()\n\n    def detach(self):\n        self.detached = True\n        stream = self.router.stream_by_id(mitogen.parent_id)\n        if stream:  # not double-detach()'d\n            os.setsid()\n            self.parent.send_await(Message(handle=DETACHING))\n            LOG.info('Detaching from %r; parent is %s', stream, self.parent)\n            for x in range(20):\n                pending = self.broker.defer_sync(stream.protocol.pending_bytes)\n                if not pending:\n                    break\n                time.sleep(0.05)\n            if pending:\n                LOG.error('Stream had %d bytes after 2000ms', pending)\n            self.broker.defer(stream.on_disconnect, self.broker)\n\n    def _setup_master(self):\n        Router.max_message_size = self.config['max_message_size']\n        if self.config['profiling']:\n            enable_profiling()\n        self.broker = Broker(activate_compat=False)\n        self.router = Router(self.broker)\n        self.router.debug = self.config.get('debug', False)\n        self.router.undirectional = self.config['unidirectional']\n        self.router.add_handler(\n            fn=self._on_shutdown_msg,\n            handle=SHUTDOWN,\n            policy=has_parent_authority,\n        )\n        self.master = Context(self.router, 0, 'master')\n        parent_id = self.config['parent_ids'][0]\n        if parent_id == 0:\n            self.parent = self.master\n        else:\n            self.parent = Context(self.router, parent_id, 'parent')\n\n        in_fd = self.config.get('in_fd', 100)\n        in_fp = os.fdopen(os.dup(in_fd), 'rb', 0)\n        os.close(in_fd)\n\n        out_fp = os.fdopen(os.dup(self.config.get('out_fd', 1)), 'wb', 0)\n        self.stream = MitogenProtocol.build_stream(self.router, parent_id)\n        self.stream.accept(in_fp, out_fp)\n        self.stream.name = 'parent'\n        self.stream.receive_side.keep_alive = False\n\n        listen(self.stream, 'disconnect', self._on_parent_disconnect)\n        listen(self.broker, 'exit', self._on_broker_exit)\n\n    def _reap_first_stage(self):\n        try:\n            os.wait()  # Reap first stage.\n        except OSError:\n            pass  # No first stage exists (e.g. fakessh)\n\n    def _setup_logging(self):\n        self.log_handler = LogHandler(self.master)\n        root = logging.getLogger()\n        root.setLevel(self.config['log_level'])\n        root.handlers = [self.log_handler]\n        if self.config['debug']:\n            enable_debug_logging()\n\n    def _setup_importer(self):\n        importer = self.config.get('importer')\n        if importer:\n            importer._install_handler(self.router)\n            importer._context = self.parent\n        else:\n            core_src_fd = self.config.get('core_src_fd', 101)\n            if core_src_fd:\n                fp = os.fdopen(core_src_fd, 'rb', 1)\n                try:\n                    core_src = fp.read()\n                    # Strip \"ExternalContext.main()\" call from last line.\n                    core_src = b('\\n').join(core_src.splitlines()[:-1])\n                finally:\n                    fp.close()\n            else:\n                core_src = None\n\n            importer = Importer(\n                self.router,\n                self.parent,\n                core_src,\n                self.config.get('whitelist', ()),\n                self.config.get('blacklist', ()),\n            )\n\n        self.importer = importer\n        self.router.importer = importer\n        sys.meta_path.insert(0, self.importer)\n\n    def _setup_package(self):\n        global mitogen\n        mitogen = imp.new_module('mitogen')\n        mitogen.__package__ = 'mitogen'\n        mitogen.__path__ = []\n        mitogen.__loader__ = self.importer\n        mitogen.main = lambda *args, **kwargs: (lambda func: None)\n        mitogen.core = sys.modules['__main__']\n        mitogen.core.__file__ = 'x/mitogen/core.py'  # For inspect.getsource()\n        mitogen.core.__loader__ = self.importer\n        sys.modules['mitogen'] = mitogen\n        sys.modules['mitogen.core'] = mitogen.core\n        del sys.modules['__main__']\n\n    def _setup_globals(self):\n        mitogen.is_master = False\n        mitogen.__version__ = self.config['version']\n        mitogen.context_id = self.config['context_id']\n        mitogen.parent_ids = self.config['parent_ids'][:]\n        mitogen.parent_id = mitogen.parent_ids[0]\n\n    def _nullify_stdio(self):\n        \"\"\"\n        Open /dev/null to replace stdio temporarily. In case of odd startup,\n        assume we may be allocated a standard handle.\n        \"\"\"\n        for stdfd, mode in ((0, os.O_RDONLY), (1, os.O_RDWR), (2, os.O_RDWR)):\n            fd = os.open('/dev/null', mode)\n            if fd != stdfd:\n                os.dup2(fd, stdfd)\n                os.close(fd)\n\n    def _preserve_tty_fp(self):\n        \"\"\"\n        #481: when stderr is a TTY due to being started via tty_create_child()\n        or hybrid_tty_create_child(), and some privilege escalation tool like\n        prehistoric versions of sudo exec this process over the top of itself,\n        there is nothing left to keep the slave PTY open after we replace our\n        stdio. Therefore if stderr is a TTY, keep around a permanent dup() to\n        avoid receiving SIGHUP.\n        \"\"\"\n        try:\n            if os.isatty(2):\n                self.reserve_tty_fp = os.fdopen(os.dup(2), 'r+b', 0)\n                set_cloexec(self.reserve_tty_fp.fileno())\n        except OSError:\n            pass\n\n    def _setup_stdio(self):\n        self._preserve_tty_fp()\n        # When sys.stdout was opened by the runtime, overwriting it will not\n        # close FD 1. However when forking from a child that previously used\n        # fdopen(), overwriting it /will/ close FD 1. So we must swallow the\n        # close before IoLogger overwrites FD 1, otherwise its new FD 1 will be\n        # clobbered. Additionally, stdout must be replaced with /dev/null prior\n        # to stdout.close(), since if block buffering was active in the parent,\n        # any pre-fork buffered data will be flushed on close(), corrupting the\n        # connection to the parent.\n        self._nullify_stdio()\n        sys.stdout.close()\n        self._nullify_stdio()\n\n        self.loggers = []\n        for name, fd in (('stdout', 1), ('stderr', 2)):\n            log = IoLoggerProtocol.build_stream(name, fd)\n            self.broker.start_receive(log)\n            self.loggers.append(log)\n\n        # Reopen with line buffering.\n        sys.stdout = os.fdopen(1, 'w', 1)\n\n    def main(self):\n        self._setup_master()\n        try:\n            try:\n                self._setup_logging()\n                self._setup_importer()\n                self._reap_first_stage()\n                if self.config.get('setup_package', True):\n                    self._setup_package()\n                self._setup_globals()\n                if self.config.get('setup_stdio', True):\n                    self._setup_stdio()\n\n                self.dispatcher = Dispatcher(self)\n                self.router.register(self.parent, self.stream)\n                self.router._setup_logging()\n\n                sys.executable = os.environ.pop('ARGV0', sys.executable)\n                _v and LOG.debug('Parent is context %r (%s); my ID is %r',\n                                 self.parent.context_id, self.parent.name,\n                                 mitogen.context_id)\n                _v and LOG.debug('pid:%r ppid:%r uid:%r/%r, gid:%r/%r host:%r',\n                                 os.getpid(), os.getppid(), os.geteuid(),\n                                 os.getuid(), os.getegid(), os.getgid(),\n                                 socket.gethostname())\n                _v and LOG.debug('Recovered sys.executable: %r', sys.executable)\n\n                if self.config.get('send_ec2', True):\n                    self.stream.transmit_side.write(b('MITO002\\n'))\n                self.broker._py24_25_compat()\n                self.log_handler.uncork()\n                self.dispatcher.run()\n                _v and LOG.debug('ExternalContext.main() normal exit')\n            except KeyboardInterrupt:\n                LOG.debug('KeyboardInterrupt received, exiting gracefully.')\n            except BaseException:\n                LOG.exception('ExternalContext.main() crashed')\n                raise\n        finally:\n            self.broker.shutdown()\n            self.broker.join()\n", "import time\nimport zlib\n\nimport unittest2\n\nimport testlib\nimport mitogen.master\nimport mitogen.parent\nimport mitogen.utils\n\ntry:\n    import Queue\nexcept ImportError:\n    import queue as Queue\n\n\ndef ping():\n    return True\n\n\n@mitogen.core.takes_router\ndef ping_context(other, router):\n    other = mitogen.parent.Context(router, other.context_id)\n    other.call(ping)\n\n\n@mitogen.core.takes_router\ndef return_router_max_message_size(router):\n    return router.max_message_size\n\n\ndef send_n_sized_reply(sender, n):\n    sender.send(' ' * n)\n    return 123\n\n\nclass SourceVerifyTest(testlib.RouterMixin, testlib.TestCase):\n    def setUp(self):\n        super(SourceVerifyTest, self).setUp()\n        # Create some children, ping them, and store what their messages look\n        # like so we can mess with them later.\n        self.child1 = self.router.local()\n        self.child1_msg = self.child1.call_async(ping).get()\n        self.child1_stream = self.router._stream_by_id[self.child1.context_id]\n\n        self.child2 = self.router.local()\n        self.child2_msg = self.child2.call_async(ping).get()\n        self.child2_stream = self.router._stream_by_id[self.child2.context_id]\n\n    def test_bad_auth_id(self):\n        # Deliver a message locally from child2, but using child1's stream.\n        log = testlib.LogCapturer()\n        log.start()\n\n        # Used to ensure the message was dropped rather than routed after the\n        # error is logged.\n        recv = mitogen.core.Receiver(self.router)\n        self.child2_msg.handle = recv.handle\n\n        self.broker.defer(self.router._async_route,\n                          self.child2_msg,\n                          in_stream=self.child1_stream)\n\n        # Wait for IO loop to finish everything above.\n        self.sync_with_broker()\n\n        # Ensure message wasn't forwarded.\n        self.assertTrue(recv.empty())\n\n        # Ensure error was logged.\n        expect = 'bad auth_id: got %r via' % (self.child2_msg.auth_id,)\n        self.assertTrue(expect in log.stop())\n\n    def test_bad_src_id(self):\n        # Deliver a message locally from child2 with the correct auth_id, but\n        # the wrong src_id.\n        log = testlib.LogCapturer()\n        log.start()\n\n        # Used to ensure the message was dropped rather than routed after the\n        # error is logged.\n        recv = mitogen.core.Receiver(self.router)\n        self.child2_msg.handle = recv.handle\n        self.child2_msg.src_id = self.child1.context_id\n\n        self.broker.defer(self.router._async_route,\n                          self.child2_msg,\n                          self.child2_stream)\n\n        # Wait for IO loop to finish everything above.\n        self.sync_with_broker()\n\n        # Ensure message wasn't forwarded.\n        self.assertTrue(recv.empty())\n\n        # Ensure error was lgoged.\n        expect = 'bad src_id: got %d via' % (self.child1_msg.src_id,)\n        self.assertTrue(expect in log.stop())\n\n\nclass PolicyTest(testlib.RouterMixin, testlib.TestCase):\n    def test_allow_any(self):\n        # This guy gets everything.\n        recv = mitogen.core.Receiver(self.router)\n        recv.to_sender().send(123)\n        self.sync_with_broker()\n        self.assertFalse(recv.empty())\n        self.assertEquals(123, recv.get().unpickle())\n\n    def test_refuse_all(self):\n        # Deliver a message locally from child2 with the correct auth_id, but\n        # the wrong src_id.\n        log = testlib.LogCapturer()\n        log.start()\n\n        # This guy never gets anything.\n        recv = mitogen.core.Receiver(\n            router=self.router,\n            policy=(lambda msg, stream: False),\n        )\n\n        # This guy becomes the reply_to of our refused message.\n        reply_target = mitogen.core.Receiver(self.router)\n\n        # Send the message.\n        self.router.route(\n            mitogen.core.Message(\n                dst_id=mitogen.context_id,\n                handle=recv.handle,\n                reply_to=reply_target.handle,\n            )\n        )\n\n        # Wait for IO loop.\n        self.sync_with_broker()\n\n        # Verify log.\n        self.assertTrue(self.router.refused_msg in log.stop())\n\n        # Verify message was not delivered.\n        self.assertTrue(recv.empty())\n\n        # Verify CallError received by reply_to target.\n        e = self.assertRaises(mitogen.core.ChannelError,\n                              lambda: reply_target.get().unpickle())\n        self.assertEquals(e.args[0], self.router.refused_msg)\n\n\nclass CrashTest(testlib.BrokerMixin, testlib.TestCase):\n    # This is testing both Broker's ability to crash nicely, and Router's\n    # ability to respond to the crash event.\n    klass = mitogen.master.Router\n\n    def _naughty(self):\n        raise ValueError('eek')\n\n    def test_shutdown(self):\n        router = self.klass(self.broker)\n\n        sem = mitogen.core.Latch()\n        router.add_handler(sem.put)\n\n        log = testlib.LogCapturer('mitogen')\n        log.start()\n\n        # Force a crash and ensure it wakes up.\n        self.broker._loop_once = self._naughty\n        self.broker.defer(lambda: None)\n\n        # sem should have received dead message.\n        self.assertTrue(sem.get().is_dead)\n\n        # Ensure it was logged.\n        expect = 'broker crashed'\n        self.assertTrue(expect in log.stop())\n\n        self.broker.join()\n\n\nclass AddHandlerTest(testlib.TestCase):\n    klass = mitogen.master.Router\n\n    def test_dead_message_sent_at_shutdown(self):\n        router = self.klass()\n        queue = Queue.Queue()\n        handle = router.add_handler(queue.put)\n        router.broker.shutdown()\n        self.assertTrue(queue.get(timeout=5).is_dead)\n        router.broker.join()\n\n    def test_cannot_double_register(self):\n        router = self.klass()\n        try:\n            router.add_handler((lambda: None), handle=1234)\n            e = self.assertRaises(mitogen.core.Error,\n                lambda: router.add_handler((lambda: None), handle=1234))\n            self.assertEquals(router.duplicate_handle_msg, e.args[0])\n            router.del_handler(1234)\n        finally:\n            router.broker.shutdown()\n            router.broker.join()\n\n    def test_can_reregister(self):\n        router = self.klass()\n        try:\n            router.add_handler((lambda: None), handle=1234)\n            router.del_handler(1234)\n            router.add_handler((lambda: None), handle=1234)\n            router.del_handler(1234)\n        finally:\n            router.broker.shutdown()\n            router.broker.join()\n\n\nclass MyselfTest(testlib.RouterMixin, testlib.TestCase):\n    def test_myself(self):\n        myself = self.router.myself()\n        self.assertEquals(myself.context_id, mitogen.context_id)\n        # TODO: context should know its own name too.\n        self.assertEquals(myself.name, 'self')\n\n\nclass MessageSizeTest(testlib.BrokerMixin, testlib.TestCase):\n    klass = mitogen.master.Router\n\n    def test_local_exceeded(self):\n        router = self.klass(broker=self.broker, max_message_size=4096)\n\n        logs = testlib.LogCapturer()\n        logs.start()\n\n        # Send message and block for one IO loop, so _async_route can run.\n        router.route(mitogen.core.Message.pickled(' '*8192))\n        router.broker.defer_sync(lambda: None)\n\n        expect = 'message too large (max 4096 bytes)'\n        self.assertTrue(expect in logs.stop())\n\n    def test_local_dead_message(self):\n        # Local router should generate dead message when reply_to is set.\n        router = self.klass(broker=self.broker, max_message_size=4096)\n\n        logs = testlib.LogCapturer()\n        logs.start()\n\n        expect = router.too_large_msg % (4096,)\n\n        # Try function call. Receiver should be woken by a dead message sent by\n        # router due to message size exceeded.\n        child = router.local()\n        e = self.assertRaises(mitogen.core.ChannelError,\n            lambda: child.call(zlib.crc32, ' '*8192))\n        self.assertEquals(e.args[0], expect)\n\n        self.assertTrue(expect in logs.stop())\n\n    def test_remote_configured(self):\n        router = self.klass(broker=self.broker, max_message_size=64*1024)\n        remote = router.local()\n        size = remote.call(return_router_max_message_size)\n        self.assertEquals(size, 64*1024)\n\n    def test_remote_exceeded(self):\n        # Ensure new contexts receive a router with the same value.\n        router = self.klass(broker=self.broker, max_message_size=64*1024)\n        recv = mitogen.core.Receiver(router)\n\n        logs = testlib.LogCapturer()\n        logs.start()\n        remote = router.local()\n        remote.call(send_n_sized_reply, recv.to_sender(), 128*1024)\n\n        expect = 'message too large (max %d bytes)' % (64*1024,)\n        self.assertTrue(expect in logs.stop())\n\n\nclass NoRouteTest(testlib.RouterMixin, testlib.TestCase):\n    def test_invalid_handle_returns_dead(self):\n        # Verify sending a message to an invalid handle yields a dead message\n        # from the target context.\n        l1 = self.router.local()\n        recv = l1.send_async(mitogen.core.Message(handle=999))\n        msg = recv.get(throw_dead=False)\n        self.assertEquals(msg.is_dead, True)\n        self.assertEquals(msg.src_id, l1.context_id)\n        self.assertEquals(msg.data, self.router.invalid_handle_msg.encode())\n\n        recv = l1.send_async(mitogen.core.Message(handle=999))\n        e = self.assertRaises(mitogen.core.ChannelError,\n                              lambda: recv.get())\n        self.assertEquals(e.args[0], self.router.invalid_handle_msg)\n\n    def test_totally_invalid_context_returns_dead(self):\n        recv = mitogen.core.Receiver(self.router)\n        msg = mitogen.core.Message(\n            dst_id=1234,\n            handle=1234,\n            reply_to=recv.handle,\n        )\n        self.router.route(msg)\n        rmsg = recv.get(throw_dead=False)\n        self.assertEquals(rmsg.is_dead, True)\n        self.assertEquals(rmsg.src_id, mitogen.context_id)\n        self.assertEquals(rmsg.data, (self.router.no_route_msg % (\n            1234,\n            mitogen.context_id,\n        )).encode())\n\n        self.router.route(msg)\n        e = self.assertRaises(mitogen.core.ChannelError,\n                              lambda: recv.get())\n        self.assertEquals(e.args[0], (self.router.no_route_msg % (\n            1234,\n            mitogen.context_id,\n        )))\n\n    def test_previously_alive_context_returns_dead(self):\n        l1 = self.router.local()\n        l1.shutdown(wait=True)\n        recv = mitogen.core.Receiver(self.router)\n        msg = mitogen.core.Message(\n            dst_id=l1.context_id,\n            handle=mitogen.core.CALL_FUNCTION,\n            reply_to=recv.handle,\n        )\n        self.router.route(msg)\n        rmsg = recv.get(throw_dead=False)\n        self.assertEquals(rmsg.is_dead, True)\n        self.assertEquals(rmsg.src_id, mitogen.context_id)\n        self.assertEquals(rmsg.data, (self.router.no_route_msg % (\n            l1.context_id,\n            mitogen.context_id,\n        )).encode())\n\n        self.router.route(msg)\n        e = self.assertRaises(mitogen.core.ChannelError,\n                              lambda: recv.get())\n        self.assertEquals(e.args[0], self.router.no_route_msg % (\n            l1.context_id,\n            mitogen.context_id,\n        ))\n\n\nclass UnidirectionalTest(testlib.RouterMixin, testlib.TestCase):\n    def test_siblings_cant_talk(self):\n        self.router.unidirectional = True\n        l1 = self.router.local()\n        l2 = self.router.local()\n        logs = testlib.LogCapturer()\n        logs.start()\n        e = self.assertRaises(mitogen.core.CallError,\n                              lambda: l2.call(ping_context, l1))\n\n        msg = self.router.unidirectional_msg % (\n            l2.context_id,\n            l1.context_id,\n        )\n        self.assertTrue(msg in str(e))\n        self.assertTrue('routing mode prevents forward of ' in logs.stop())\n\n    def test_auth_id_can_talk(self):\n        self.router.unidirectional = True\n        # One stream has auth_id stamped to that of the master, so it should be\n        # treated like a parent.\n        l1 = self.router.local()\n        l1s = self.router.stream_by_id(l1.context_id)\n        l1s.protocol.auth_id = mitogen.context_id\n        l1s.protocol.is_privileged = True\n\n        l2 = self.router.local()\n        e = self.assertRaises(mitogen.core.CallError,\n                              lambda: l2.call(ping_context, l1))\n\n        msg = 'mitogen.core.ChannelError: %s' % (self.router.refused_msg,)\n        self.assertTrue(str(e).startswith(msg))\n\n\nclass EgressIdsTest(testlib.RouterMixin, testlib.TestCase):\n    def test_egress_ids_populated(self):\n        # Ensure Stream.egress_ids is populated on message reception.\n        c1 = self.router.local(name='c1')\n        c2 = self.router.local(name='c2')\n\n        c1s = self.router.stream_by_id(c1.context_id)\n        try:\n            c1.call(ping_context, c2)\n        except mitogen.core.CallError:\n            # Fails because siblings cant call funcs in each other, but this\n            # causes messages to be sent.\n            pass\n\n        self.assertEquals(c1s.protocol.egress_ids, set([\n            mitogen.context_id,\n            c2.context_id,\n        ]))\n\n\nif __name__ == '__main__':\n    unittest2.main()\n"], "fixing_code": ["# Copyright 2019, David Wilson\n#\n# Redistribution and use in source and binary forms, with or without\n# modification, are permitted provided that the following conditions are met:\n#\n# 1. Redistributions of source code must retain the above copyright notice,\n# this list of conditions and the following disclaimer.\n#\n# 2. Redistributions in binary form must reproduce the above copyright notice,\n# this list of conditions and the following disclaimer in the documentation\n# and/or other materials provided with the distribution.\n#\n# 3. Neither the name of the copyright holder nor the names of its contributors\n# may be used to endorse or promote products derived from this software without\n# specific prior written permission.\n#\n# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"\n# AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE\n# IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE\n# ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE\n# LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR\n# CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF\n# SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS\n# INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\n# CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n# POSSIBILITY OF SUCH DAMAGE.\n\n# !mitogen: minify_safe\n\n\"\"\"\nThis module implements most package functionality, but remains separate from\nnon-essential code in order to reduce its size, since it is also serves as the\nbootstrap implementation sent to every new slave context.\n\"\"\"\n\nimport binascii\nimport collections\nimport encodings.latin_1\nimport encodings.utf_8\nimport errno\nimport fcntl\nimport itertools\nimport linecache\nimport logging\nimport os\nimport pickle as py_pickle\nimport pstats\nimport signal\nimport socket\nimport struct\nimport sys\nimport syslog\nimport threading\nimport time\nimport traceback\nimport warnings\nimport weakref\nimport zlib\n\n# Python >3.7 deprecated the imp module.\nwarnings.filterwarnings('ignore', message='the imp module is deprecated')\nimport imp\n\n# Absolute imports for <2.5.\nselect = __import__('select')\n\ntry:\n    import cProfile\nexcept ImportError:\n    cProfile = None\n\ntry:\n    import thread\nexcept ImportError:\n    import threading as thread\n\ntry:\n    import cPickle as pickle\nexcept ImportError:\n    import pickle\n\ntry:\n    from cStringIO import StringIO as BytesIO\nexcept ImportError:\n    from io import BytesIO\n\ntry:\n    BaseException\nexcept NameError:\n    BaseException = Exception\n\ntry:\n    ModuleNotFoundError\nexcept NameError:\n    ModuleNotFoundError = ImportError\n\n# TODO: usage of 'import' after setting __name__, but before fixing up\n# sys.modules generates a warning. This happens when profiling = True.\nwarnings.filterwarnings('ignore',\n    \"Parent module 'mitogen' not found while handling absolute import\")\n\nLOG = logging.getLogger('mitogen')\nIOLOG = logging.getLogger('mitogen.io')\nIOLOG.setLevel(logging.INFO)\n\n# str.encode() may take import lock. Deadlock possible if broker calls\n# .encode() on behalf of thread currently waiting for module.\nLATIN1_CODEC = encodings.latin_1.Codec()\n\n_v = False\n_vv = False\n\nGET_MODULE = 100\nCALL_FUNCTION = 101\nFORWARD_LOG = 102\nADD_ROUTE = 103\nDEL_ROUTE = 104\nALLOCATE_ID = 105\nSHUTDOWN = 106\nLOAD_MODULE = 107\nFORWARD_MODULE = 108\nDETACHING = 109\nCALL_SERVICE = 110\nSTUB_CALL_SERVICE = 111\n\n#: Special value used to signal disconnection or the inability to route a\n#: message, when it appears in the `reply_to` field. Usually causes\n#: :class:`mitogen.core.ChannelError` to be raised when it is received.\n#:\n#: It indicates the sender did not know how to process the message, or wishes\n#: no further messages to be delivered to it. It is used when:\n#:\n#:  * a remote receiver is disconnected or explicitly closed.\n#:  * a related message could not be delivered due to no route existing for it.\n#:  * a router is being torn down, as a sentinel value to notify\n#:    :meth:`mitogen.core.Router.add_handler` callbacks to clean up.\nIS_DEAD = 999\n\ntry:\n    BaseException\nexcept NameError:\n    BaseException = Exception\n\nPY24 = sys.version_info < (2, 5)\nPY3 = sys.version_info > (3,)\nif PY3:\n    b = str.encode\n    BytesType = bytes\n    UnicodeType = str\n    FsPathTypes = (str,)\n    BufferType = lambda buf, start: memoryview(buf)[start:]\n    long = int\nelse:\n    b = str\n    BytesType = str\n    FsPathTypes = (str, unicode)\n    BufferType = buffer\n    UnicodeType = unicode\n\nAnyTextType = (BytesType, UnicodeType)\n\ntry:\n    next\nexcept NameError:\n    next = lambda it: it.next()\n\n# #550: prehistoric WSL did not advertise itself in uname output.\ntry:\n    fp = open('/proc/sys/kernel/osrelease')\n    IS_WSL = 'Microsoft' in fp.read()\n    fp.close()\nexcept IOError:\n    IS_WSL = False\n\n\n#: Default size for calls to :meth:`Side.read` or :meth:`Side.write`, and the\n#: size of buffers configured by :func:`mitogen.parent.create_socketpair`. This\n#: value has many performance implications, 128KiB seems to be a sweet spot.\n#:\n#: * When set low, large messages cause many :class:`Broker` IO loop\n#:   iterations, burning CPU and reducing throughput.\n#: * When set high, excessive RAM is reserved by the OS for socket buffers (2x\n#:   per child), and an identically sized temporary userspace buffer is\n#:   allocated on each read that requires zeroing, and over a particular size\n#:   may require two system calls to allocate/deallocate.\n#:\n#: Care must be taken to ensure the underlying kernel object and receiving\n#: program support the desired size. For example,\n#:\n#: * Most UNIXes have TTYs with fixed 2KiB-4KiB buffers, making them unsuitable\n#:   for efficient IO.\n#: * Different UNIXes have varying presets for pipes, which may not be\n#:   configurable. On recent Linux the default pipe buffer size is 64KiB, but\n#:   under memory pressure may be as low as 4KiB for unprivileged processes.\n#: * When communication is via an intermediary process, its internal buffers\n#:   effect the speed OS buffers will drain. For example OpenSSH uses 64KiB\n#:   reads.\n#:\n#: An ideal :class:`Message` has a size that is a multiple of\n#: :data:`CHUNK_SIZE` inclusive of headers, to avoid wasting IO loop iterations\n#: writing small trailer chunks.\nCHUNK_SIZE = 131072\n\n_tls = threading.local()\n\n\nif __name__ == 'mitogen.core':\n    # When loaded using import mechanism, ExternalContext.main() will not have\n    # a chance to set the synthetic mitogen global, so just import it here.\n    import mitogen\nelse:\n    # When loaded as __main__, ensure classes and functions gain a __module__\n    # attribute consistent with the host process, so that pickling succeeds.\n    __name__ = 'mitogen.core'\n\n\nclass Error(Exception):\n    \"\"\"\n    Base for all exceptions raised by Mitogen.\n\n    :param str fmt:\n        Exception text, or format string if `args` is non-empty.\n    :param tuple args:\n        Format string arguments.\n    \"\"\"\n    def __init__(self, fmt=None, *args):\n        if args:\n            fmt %= args\n        if fmt and not isinstance(fmt, UnicodeType):\n            fmt = fmt.decode('utf-8')\n        Exception.__init__(self, fmt)\n\n\nclass LatchError(Error):\n    \"\"\"\n    Raised when an attempt is made to use a :class:`mitogen.core.Latch` that\n    has been marked closed.\n    \"\"\"\n    pass\n\n\nclass Blob(BytesType):\n    \"\"\"\n    A serializable bytes subclass whose content is summarized in repr() output,\n    making it suitable for logging binary data.\n    \"\"\"\n    def __repr__(self):\n        return '[blob: %d bytes]' % len(self)\n\n    def __reduce__(self):\n        return (Blob, (BytesType(self),))\n\n\nclass Secret(UnicodeType):\n    \"\"\"\n    A serializable unicode subclass whose content is masked in repr() output,\n    making it suitable for logging passwords.\n    \"\"\"\n    def __repr__(self):\n        return '[secret]'\n\n    if not PY3:\n        # TODO: what is this needed for in 2.x?\n        def __str__(self):\n            return UnicodeType(self)\n\n    def __reduce__(self):\n        return (Secret, (UnicodeType(self),))\n\n\nclass Kwargs(dict):\n    \"\"\"\n    A serializable dict subclass that indicates its keys should be coerced to\n    Unicode on Python 3 and bytes on Python<2.6.\n\n    Python 2 produces keyword argument dicts whose keys are bytes, requiring a\n    helper to ensure compatibility with Python 3 where Unicode is required,\n    whereas Python 3 produces keyword argument dicts whose keys are Unicode,\n    requiring a helper for Python 2.4/2.5, where bytes are required.\n    \"\"\"\n    if PY3:\n        def __init__(self, dct):\n            for k, v in dct.items():\n                if type(k) is bytes:\n                    self[k.decode()] = v\n                else:\n                    self[k] = v\n    elif sys.version_info < (2, 6, 5):\n        def __init__(self, dct):\n            for k, v in dct.iteritems():\n                if type(k) is unicode:\n                    k, _ = encodings.utf_8.encode(k)\n                self[k] = v\n\n    def __repr__(self):\n        return 'Kwargs(%s)' % (dict.__repr__(self),)\n\n    def __reduce__(self):\n        return (Kwargs, (dict(self),))\n\n\nclass CallError(Error):\n    \"\"\"\n    Serializable :class:`Error` subclass raised when :meth:`Context.call()\n    <mitogen.parent.Context.call>` fails. A copy of the traceback from the\n    external context is appended to the exception message.\n    \"\"\"\n    def __init__(self, fmt=None, *args):\n        if not isinstance(fmt, BaseException):\n            Error.__init__(self, fmt, *args)\n        else:\n            e = fmt\n            cls = e.__class__\n            fmt = '%s.%s: %s' % (cls.__module__, cls.__name__, e)\n            tb = sys.exc_info()[2]\n            if tb:\n                fmt += '\\n'\n                fmt += ''.join(traceback.format_tb(tb))\n            Error.__init__(self, fmt)\n\n    def __reduce__(self):\n        return (_unpickle_call_error, (self.args[0],))\n\n\ndef _unpickle_call_error(s):\n    if not (type(s) is UnicodeType and len(s) < 10000):\n        raise TypeError('cannot unpickle CallError: bad input')\n    return CallError(s)\n\n\nclass ChannelError(Error):\n    \"\"\"\n    Raised when a channel dies or has been closed.\n    \"\"\"\n    remote_msg = 'Channel closed by remote end.'\n    local_msg = 'Channel closed by local end.'\n\n\nclass StreamError(Error):\n    \"\"\"\n    Raised when a stream cannot be established.\n    \"\"\"\n    pass\n\n\nclass TimeoutError(Error):\n    \"\"\"\n    Raised when a timeout occurs on a stream.\n    \"\"\"\n    pass\n\n\ndef to_text(o):\n    \"\"\"\n    Coerce `o` to Unicode by decoding it from UTF-8 if it is an instance of\n    :class:`bytes`, otherwise pass it to the :class:`str` constructor. The\n    returned object is always a plain :class:`str`, any subclass is removed.\n    \"\"\"\n    if isinstance(o, BytesType):\n        return o.decode('utf-8')\n    return UnicodeType(o)\n\n\n# Python 2.4\ntry:\n    any\nexcept NameError:\n    def any(it):\n        for elem in it:\n            if elem:\n                return True\n\n\ndef _partition(s, sep, find):\n    \"\"\"\n    (str|unicode).(partition|rpartition) for Python 2.4/2.5.\n    \"\"\"\n    idx = find(sep)\n    if idx != -1:\n        left = s[0:idx]\n        return left, sep, s[len(left)+len(sep):]\n\n\nif hasattr(UnicodeType, 'rpartition'):\n    str_partition = UnicodeType.partition\n    str_rpartition = UnicodeType.rpartition\n    bytes_partition = BytesType.partition\nelse:\n    def str_partition(s, sep):\n        return _partition(s, sep, s.find) or (s, u'', u'')\n    def str_rpartition(s, sep):\n        return _partition(s, sep, s.rfind) or (u'', u'', s)\n    def bytes_partition(s, sep):\n        return _partition(s, sep, s.find) or (s, '', '')\n\n\ndef has_parent_authority(msg, _stream=None):\n    \"\"\"\n    Policy function for use with :class:`Receiver` and\n    :meth:`Router.add_handler` that requires incoming messages to originate\n    from a parent context, or on a :class:`Stream` whose :attr:`auth_id\n    <Stream.auth_id>` has been set to that of a parent context or the current\n    context.\n    \"\"\"\n    return (msg.auth_id == mitogen.context_id or\n            msg.auth_id in mitogen.parent_ids)\n\n\ndef _signals(obj, signal):\n    return (\n        obj.__dict__\n        .setdefault('_signals', {})\n        .setdefault(signal, [])\n    )\n\n\ndef listen(obj, name, func):\n    \"\"\"\n    Arrange for `func()` to be invoked when signal `name` is fired on `obj`.\n    \"\"\"\n    _signals(obj, name).append(func)\n\n\ndef unlisten(obj, name, func):\n    \"\"\"\n    Remove `func()` from the list of functions invoked when signal `name` is\n    fired by `obj`.\n\n    :raises ValueError:\n        `func()` was not on the list.\n    \"\"\"\n    _signals(obj, name).remove(func)\n\n\ndef fire(obj, name, *args, **kwargs):\n    \"\"\"\n    Arrange for `func(*args, **kwargs)` to be invoked for every function\n    registered for signal `name` on `obj`.\n    \"\"\"\n    for func in _signals(obj, name):\n        func(*args, **kwargs)\n\n\ndef takes_econtext(func):\n    func.mitogen_takes_econtext = True\n    return func\n\n\ndef takes_router(func):\n    func.mitogen_takes_router = True\n    return func\n\n\ndef is_blacklisted_import(importer, fullname):\n    \"\"\"\n    Return :data:`True` if `fullname` is part of a blacklisted package, or if\n    any packages have been whitelisted and `fullname` is not part of one.\n\n    NB:\n      - If a package is on both lists, then it is treated as blacklisted.\n      - If any package is whitelisted, then all non-whitelisted packages are\n        treated as blacklisted.\n    \"\"\"\n    return ((not any(fullname.startswith(s) for s in importer.whitelist)) or\n                (any(fullname.startswith(s) for s in importer.blacklist)))\n\n\ndef set_cloexec(fd):\n    \"\"\"\n    Set the file descriptor `fd` to automatically close on :func:`os.execve`.\n    This has no effect on file descriptors inherited across :func:`os.fork`,\n    they must be explicitly closed through some other means, such as\n    :func:`mitogen.fork.on_fork`.\n    \"\"\"\n    flags = fcntl.fcntl(fd, fcntl.F_GETFD)\n    assert fd > 2\n    fcntl.fcntl(fd, fcntl.F_SETFD, flags | fcntl.FD_CLOEXEC)\n\n\ndef set_nonblock(fd):\n    \"\"\"\n    Set the file descriptor `fd` to non-blocking mode. For most underlying file\n    types, this causes :func:`os.read` or :func:`os.write` to raise\n    :class:`OSError` with :data:`errno.EAGAIN` rather than block the thread\n    when the underlying kernel buffer is exhausted.\n    \"\"\"\n    flags = fcntl.fcntl(fd, fcntl.F_GETFL)\n    fcntl.fcntl(fd, fcntl.F_SETFL, flags | os.O_NONBLOCK)\n\n\ndef set_block(fd):\n    \"\"\"\n    Inverse of :func:`set_nonblock`, i.e. cause `fd` to block the thread when\n    the underlying kernel buffer is exhausted.\n    \"\"\"\n    flags = fcntl.fcntl(fd, fcntl.F_GETFL)\n    fcntl.fcntl(fd, fcntl.F_SETFL, flags & ~os.O_NONBLOCK)\n\n\ndef io_op(func, *args):\n    \"\"\"\n    Wrap `func(*args)` that may raise :class:`select.error`, :class:`IOError`,\n    or :class:`OSError`, trapping UNIX error codes relating to disconnection\n    and retry events in various subsystems:\n\n    * When a signal is delivered to the process on Python 2, system call retry\n      is signalled through :data:`errno.EINTR`. The invocation is automatically\n      restarted.\n    * When performing IO against a TTY, disconnection of the remote end is\n      signalled by :data:`errno.EIO`.\n    * When performing IO against a socket, disconnection of the remote end is\n      signalled by :data:`errno.ECONNRESET`.\n    * When performing IO against a pipe, disconnection of the remote end is\n      signalled by :data:`errno.EPIPE`.\n\n    :returns:\n        Tuple of `(return_value, disconnect_reason)`, where `return_value` is\n        the return value of `func(*args)`, and `disconnected` is an exception\n        instance when disconnection was detected, otherwise :data:`None`.\n    \"\"\"\n    while True:\n        try:\n            return func(*args), None\n        except (select.error, OSError, IOError):\n            e = sys.exc_info()[1]\n            _vv and IOLOG.debug('io_op(%r) -> OSError: %s', func, e)\n            if e.args[0] == errno.EINTR:\n                continue\n            if e.args[0] in (errno.EIO, errno.ECONNRESET, errno.EPIPE):\n                return None, e\n            raise\n\n\nclass PidfulStreamHandler(logging.StreamHandler):\n    \"\"\"\n    A :class:`logging.StreamHandler` subclass used when\n    :meth:`Router.enable_debug() <mitogen.master.Router.enable_debug>` has been\n    called, or the `debug` parameter was specified during context construction.\n    Verifies the process ID has not changed on each call to :meth:`emit`,\n    reopening the associated log file when a change is detected.\n\n    This ensures logging to the per-process output files happens correctly even\n    when uncooperative third party components call :func:`os.fork`.\n    \"\"\"\n    #: PID that last opened the log file.\n    open_pid = None\n\n    #: Output path template.\n    template = '/tmp/mitogen.%s.%s.log'\n\n    def _reopen(self):\n        self.acquire()\n        try:\n            if self.open_pid == os.getpid():\n                return\n            ts = time.strftime('%Y%m%d_%H%M%S')\n            path = self.template % (os.getpid(), ts)\n            self.stream = open(path, 'w', 1)\n            set_cloexec(self.stream.fileno())\n            self.stream.write('Parent PID: %s\\n' % (os.getppid(),))\n            self.stream.write('Created by:\\n\\n%s\\n' % (\n                ''.join(traceback.format_stack()),\n            ))\n            self.open_pid = os.getpid()\n        finally:\n            self.release()\n\n    def emit(self, record):\n        if self.open_pid != os.getpid():\n            self._reopen()\n        logging.StreamHandler.emit(self, record)\n\n\ndef enable_debug_logging():\n    global _v, _vv\n    _v = True\n    _vv = True\n    root = logging.getLogger()\n    root.setLevel(logging.DEBUG)\n    IOLOG.setLevel(logging.DEBUG)\n    handler = PidfulStreamHandler()\n    handler.formatter = logging.Formatter(\n        '%(asctime)s %(levelname).1s %(name)s: %(message)s',\n        '%H:%M:%S'\n    )\n    root.handlers.insert(0, handler)\n\n\n_profile_hook = lambda name, func, *args: func(*args)\n_profile_fmt = os.environ.get(\n    'MITOGEN_PROFILE_FMT',\n    '/tmp/mitogen.stats.%(pid)s.%(identity)s.%(now)s.%(ext)s',\n)\n\n\ndef _profile_hook(name, func, *args):\n    \"\"\"\n    Call `func(*args)` and return its result. This function is replaced by\n    :func:`_real_profile_hook` when :func:`enable_profiling` is called. This\n    interface is obsolete and will be replaced by a signals-based integration\n    later on.\n    \"\"\"\n    return func(*args)\n\n\ndef _real_profile_hook(name, func, *args):\n    profiler = cProfile.Profile()\n    profiler.enable()\n    try:\n        return func(*args)\n    finally:\n        path = _profile_fmt % {\n            'now': int(1e6 * time.time()),\n            'identity': name,\n            'pid': os.getpid(),\n            'ext': '%s'\n        }\n        profiler.dump_stats(path % ('pstats',))\n        profiler.create_stats()\n        fp = open(path % ('log',), 'w')\n        try:\n            stats = pstats.Stats(profiler, stream=fp)\n            stats.sort_stats('cumulative')\n            stats.print_stats()\n        finally:\n            fp.close()\n\n\ndef enable_profiling(econtext=None):\n    global _profile_hook\n    _profile_hook = _real_profile_hook\n\n\ndef import_module(modname):\n    \"\"\"\n    Import `module` and return the attribute named `attr`.\n    \"\"\"\n    return __import__(modname, None, None, [''])\n\n\ndef pipe():\n    \"\"\"\n    Create a UNIX pipe pair using :func:`os.pipe`, wrapping the returned\n    descriptors in Python file objects in order to manage their lifetime and\n    ensure they are closed when their last reference is discarded and they have\n    not been closed explicitly.\n    \"\"\"\n    rfd, wfd = os.pipe()\n    return (\n        os.fdopen(rfd, 'rb', 0),\n        os.fdopen(wfd, 'wb', 0)\n    )\n\n\ndef iter_split(buf, delim, func):\n    \"\"\"\n    Invoke `func(s)` for each `delim`-delimited chunk in the potentially large\n    `buf`, avoiding intermediate lists and quadratic string operations. Return\n    the trailing undelimited portion of `buf`, or any unprocessed portion of\n    `buf` after `func(s)` returned :data:`False`.\n\n    :returns:\n        `(trailer, cont)`, where `cont` is :data:`False` if the last call to\n        `func(s)` returned :data:`False`.\n    \"\"\"\n    dlen = len(delim)\n    start = 0\n    cont = True\n    while cont:\n        nl = buf.find(delim, start)\n        if nl == -1:\n            break\n        cont = not func(buf[start:nl]) is False\n        start = nl + dlen\n    return buf[start:], cont\n\n\nclass Py24Pickler(py_pickle.Pickler):\n    \"\"\"\n    Exceptions were classic classes until Python 2.5. Sadly for 2.4, cPickle\n    offers little control over how a classic instance is pickled. Therefore 2.4\n    uses a pure-Python pickler, so CallError can be made to look as it does on\n    newer Pythons.\n\n    This mess will go away once proper serialization exists.\n    \"\"\"\n    @classmethod\n    def dumps(cls, obj, protocol):\n        bio = BytesIO()\n        self = cls(bio, protocol=protocol)\n        self.dump(obj)\n        return bio.getvalue()\n\n    def save_exc_inst(self, obj):\n        if isinstance(obj, CallError):\n            func, args = obj.__reduce__()\n            self.save(func)\n            self.save(args)\n            self.write(py_pickle.REDUCE)\n        else:\n            py_pickle.Pickler.save_inst(self, obj)\n\n    if PY24:\n        dispatch = py_pickle.Pickler.dispatch.copy()\n        dispatch[py_pickle.InstanceType] = save_exc_inst\n\n\nif PY3:\n    # In 3.x Unpickler is a class exposing find_class as an overridable, but it\n    # cannot be overridden without subclassing.\n    class _Unpickler(pickle.Unpickler):\n        def find_class(self, module, func):\n            return self.find_global(module, func)\n    pickle__dumps = pickle.dumps\nelif PY24:\n    # On Python 2.4, we must use a pure-Python pickler.\n    pickle__dumps = Py24Pickler.dumps\n    _Unpickler = pickle.Unpickler\nelse:\n    pickle__dumps = pickle.dumps\n    # In 2.x Unpickler is a function exposing a writeable find_global\n    # attribute.\n    _Unpickler = pickle.Unpickler\n\n\nclass Message(object):\n    \"\"\"\n    Messages are the fundamental unit of communication, comprising fields from\n    the :ref:`stream-protocol` header, an optional reference to the receiving\n    :class:`mitogen.core.Router` for ingress messages, and helper methods for\n    deserialization and generating replies.\n    \"\"\"\n    #: Integer target context ID. :class:`Router` delivers messages locally\n    #: when their :attr:`dst_id` matches :data:`mitogen.context_id`, otherwise\n    #: they are routed up or downstream.\n    dst_id = None\n\n    #: Integer source context ID. Used as the target of replies if any are\n    #: generated.\n    src_id = None\n\n    #: Context ID under whose authority the message is acting. See\n    #: :ref:`source-verification`.\n    auth_id = None\n\n    #: Integer target handle in the destination context. This is one of the\n    #: :ref:`standard-handles`, or a dynamically generated handle used to\n    #: receive a one-time reply, such as the return value of a function call.\n    handle = None\n\n    #: Integer target handle to direct any reply to this message. Used to\n    #: receive a one-time reply, such as the return value of a function call.\n    #: :data:`IS_DEAD` has a special meaning when it appears in this field.\n    reply_to = None\n\n    #: Raw message data bytes.\n    data = b('')\n\n    _unpickled = object()\n\n    #: The :class:`Router` responsible for routing the message. This is\n    #: :data:`None` for locally originated messages.\n    router = None\n\n    #: The :class:`Receiver` over which the message was last received. Part of\n    #: the :class:`mitogen.select.Select` interface. Defaults to :data:`None`.\n    receiver = None\n\n    HEADER_FMT = '>hLLLLLL'\n    HEADER_LEN = struct.calcsize(HEADER_FMT)\n    HEADER_MAGIC = 0x4d49  # 'MI'\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Construct a message from from the supplied `kwargs`. :attr:`src_id` and\n        :attr:`auth_id` are always set to :data:`mitogen.context_id`.\n        \"\"\"\n        self.src_id = mitogen.context_id\n        self.auth_id = mitogen.context_id\n        vars(self).update(kwargs)\n        assert isinstance(self.data, BytesType)\n\n    def pack(self):\n        return (\n            struct.pack(self.HEADER_FMT, self.HEADER_MAGIC, self.dst_id,\n                        self.src_id, self.auth_id, self.handle,\n                        self.reply_to or 0, len(self.data))\n            + self.data\n        )\n\n    def _unpickle_context(self, context_id, name):\n        return _unpickle_context(context_id, name, router=self.router)\n\n    def _unpickle_sender(self, context_id, dst_handle):\n        return _unpickle_sender(self.router, context_id, dst_handle)\n\n    def _unpickle_bytes(self, s, encoding):\n        s, n = LATIN1_CODEC.encode(s)\n        return s\n\n    def _find_global(self, module, func):\n        \"\"\"\n        Return the class implementing `module_name.class_name` or raise\n        `StreamError` if the module is not whitelisted.\n        \"\"\"\n        if module == __name__:\n            if func == '_unpickle_call_error' or func == 'CallError':\n                return _unpickle_call_error\n            elif func == '_unpickle_sender':\n                return self._unpickle_sender\n            elif func == '_unpickle_context':\n                return self._unpickle_context\n            elif func == 'Blob':\n                return Blob\n            elif func == 'Secret':\n                return Secret\n            elif func == 'Kwargs':\n                return Kwargs\n        elif module == '_codecs' and func == 'encode':\n            return self._unpickle_bytes\n        elif module == '__builtin__' and func == 'bytes':\n            return BytesType\n        raise StreamError('cannot unpickle %r/%r', module, func)\n\n    @property\n    def is_dead(self):\n        \"\"\"\n        :data:`True` if :attr:`reply_to` is set to the magic value\n        :data:`IS_DEAD`, indicating the sender considers the channel dead. Dead\n        messages can be raised in a variety of circumstances, see\n        :data:`IS_DEAD` for more information.\n        \"\"\"\n        return self.reply_to == IS_DEAD\n\n    @classmethod\n    def dead(cls, reason=None, **kwargs):\n        \"\"\"\n        Syntax helper to construct a dead message.\n        \"\"\"\n        kwargs['data'], _ = encodings.utf_8.encode(reason or u'')\n        return cls(reply_to=IS_DEAD, **kwargs)\n\n    @classmethod\n    def pickled(cls, obj, **kwargs):\n        \"\"\"\n        Construct a pickled message, setting :attr:`data` to the serialization\n        of `obj`, and setting remaining fields using `kwargs`.\n\n        :returns:\n            The new message.\n        \"\"\"\n        self = cls(**kwargs)\n        try:\n            self.data = pickle__dumps(obj, protocol=2)\n        except pickle.PicklingError:\n            e = sys.exc_info()[1]\n            self.data = pickle__dumps(CallError(e), protocol=2)\n        return self\n\n    def reply(self, msg, router=None, **kwargs):\n        \"\"\"\n        Compose a reply to this message and send it using :attr:`router`, or\n        `router` is :attr:`router` is :data:`None`.\n\n        :param obj:\n            Either a :class:`Message`, or an object to be serialized in order\n            to construct a new message.\n        :param router:\n            Optional router to use if :attr:`router` is :data:`None`.\n        :param kwargs:\n            Optional keyword parameters overriding message fields in the reply.\n        \"\"\"\n        if not isinstance(msg, Message):\n            msg = Message.pickled(msg)\n        msg.dst_id = self.src_id\n        msg.handle = self.reply_to\n        vars(msg).update(kwargs)\n        if msg.handle:\n            (self.router or router).route(msg)\n        else:\n            LOG.debug('dropping reply to message with no return address: %r',\n                      msg)\n\n    if PY3:\n        UNPICKLER_KWARGS = {'encoding': 'bytes'}\n    else:\n        UNPICKLER_KWARGS = {}\n\n    def _throw_dead(self):\n        if len(self.data):\n            raise ChannelError(self.data.decode('utf-8', 'replace'))\n        elif self.src_id == mitogen.context_id:\n            raise ChannelError(ChannelError.local_msg)\n        else:\n            raise ChannelError(ChannelError.remote_msg)\n\n    def unpickle(self, throw=True, throw_dead=True):\n        \"\"\"\n        Unpickle :attr:`data`, optionally raising any exceptions present.\n\n        :param bool throw_dead:\n            If :data:`True`, raise exceptions, otherwise it is the caller's\n            responsibility.\n\n        :raises CallError:\n            The serialized data contained CallError exception.\n        :raises ChannelError:\n            The `is_dead` field was set.\n        \"\"\"\n        _vv and IOLOG.debug('%r.unpickle()', self)\n        if throw_dead and self.is_dead:\n            self._throw_dead()\n\n        obj = self._unpickled\n        if obj is Message._unpickled:\n            fp = BytesIO(self.data)\n            unpickler = _Unpickler(fp, **self.UNPICKLER_KWARGS)\n            unpickler.find_global = self._find_global\n            try:\n                # Must occur off the broker thread.\n                try:\n                    obj = unpickler.load()\n                except:\n                    LOG.error('raw pickle was: %r', self.data)\n                    raise\n                self._unpickled = obj\n            except (TypeError, ValueError):\n                e = sys.exc_info()[1]\n                raise StreamError('invalid message: %s', e)\n\n        if throw:\n            if isinstance(obj, CallError):\n                raise obj\n\n        return obj\n\n    def __repr__(self):\n        return 'Message(%r, %r, %r, %r, %r, %r..%d)' % (\n            self.dst_id, self.src_id, self.auth_id, self.handle,\n            self.reply_to, (self.data or '')[:50], len(self.data)\n        )\n\n\nclass Sender(object):\n    \"\"\"\n    Senders are used to send pickled messages to a handle in another context,\n    it is the inverse of :class:`mitogen.core.Receiver`.\n\n    Senders may be serialized, making them convenient to wire up data flows.\n    See :meth:`mitogen.core.Receiver.to_sender` for more information.\n\n    :param mitogen.core.Context context:\n        Context to send messages to.\n    :param int dst_handle:\n        Destination handle to send messages to.\n    \"\"\"\n    def __init__(self, context, dst_handle):\n        self.context = context\n        self.dst_handle = dst_handle\n\n    def send(self, data):\n        \"\"\"\n        Send `data` to the remote end.\n        \"\"\"\n        _vv and IOLOG.debug('%r.send(%r..)', self, repr(data)[:100])\n        self.context.send(Message.pickled(data, handle=self.dst_handle))\n\n    explicit_close_msg = 'Sender was explicitly closed'\n\n    def close(self):\n        \"\"\"\n        Send a dead message to the remote, causing :meth:`ChannelError` to be\n        raised in any waiting thread.\n        \"\"\"\n        _vv and IOLOG.debug('%r.close()', self)\n        self.context.send(\n            Message.dead(\n                reason=self.explicit_close_msg,\n                handle=self.dst_handle\n            )\n        )\n\n    def __repr__(self):\n        return 'Sender(%r, %r)' % (self.context, self.dst_handle)\n\n    def __reduce__(self):\n        return _unpickle_sender, (self.context.context_id, self.dst_handle)\n\n\ndef _unpickle_sender(router, context_id, dst_handle):\n    if not (isinstance(router, Router) and\n            isinstance(context_id, (int, long)) and context_id >= 0 and\n            isinstance(dst_handle, (int, long)) and dst_handle > 0):\n        raise TypeError('cannot unpickle Sender: bad input or missing router')\n    return Sender(Context(router, context_id), dst_handle)\n\n\nclass Receiver(object):\n    \"\"\"\n    Receivers maintain a thread-safe queue of messages sent to a handle of this\n    context from another context.\n\n    :param mitogen.core.Router router:\n        Router to register the handler on.\n\n    :param int handle:\n        If not :data:`None`, an explicit handle to register, otherwise an\n        unused handle is chosen.\n\n    :param bool persist:\n        If :data:`False`, unregister the handler after one message is received.\n        Single-message receivers are intended for RPC-like transactions, such\n        as in the case of :meth:`mitogen.parent.Context.call_async`.\n\n    :param mitogen.core.Context respondent:\n        Context this receiver is receiving from. If not :data:`None`, arranges\n        for the receiver to receive a dead message if messages can no longer be\n        routed to the context due to disconnection, and ignores messages that\n        did not originate from the respondent context.\n    \"\"\"\n    #: If not :data:`None`, a reference to a function invoked as\n    #: `notify(receiver)` when a new message is delivered to this receiver. The\n    #: function is invoked on the broker thread, therefore it must not block.\n    #: Used by :class:`mitogen.select.Select` to implement waiting on multiple\n    #: receivers.\n    notify = None\n\n    raise_channelerror = True\n\n    def __init__(self, router, handle=None, persist=True,\n                 respondent=None, policy=None, overwrite=False):\n        self.router = router\n        #: The handle.\n        self.handle = handle  # Avoid __repr__ crash in add_handler()\n        self._latch = Latch()  # Must exist prior to .add_handler()\n        self.handle = router.add_handler(\n            fn=self._on_receive,\n            handle=handle,\n            policy=policy,\n            persist=persist,\n            respondent=respondent,\n            overwrite=overwrite,\n        )\n\n    def __repr__(self):\n        return 'Receiver(%r, %r)' % (self.router, self.handle)\n\n    def __enter__(self):\n        return self\n\n    def __exit__(self, _1, _2, _3):\n        self.close()\n\n    def to_sender(self):\n        \"\"\"\n        Return a :class:`Sender` configured to deliver messages to this\n        receiver. As senders are serializable, this makes it convenient to pass\n        `(context_id, handle)` pairs around::\n\n            def deliver_monthly_report(sender):\n                for line in open('monthly_report.txt'):\n                    sender.send(line)\n                sender.close()\n\n            @mitogen.main()\n            def main(router):\n                remote = router.ssh(hostname='mainframe')\n                recv = mitogen.core.Receiver(router)\n                remote.call(deliver_monthly_report, recv.to_sender())\n                for msg in recv:\n                    print(msg)\n        \"\"\"\n        return Sender(self.router.myself(), self.handle)\n\n    def _on_receive(self, msg):\n        \"\"\"\n        Callback registered for the handle with :class:`Router`; appends data\n        to the internal queue.\n        \"\"\"\n        _vv and IOLOG.debug('%r._on_receive(%r)', self, msg)\n        self._latch.put(msg)\n        if self.notify:\n            self.notify(self)\n\n    closed_msg = 'the Receiver has been closed'\n\n    def close(self):\n        \"\"\"\n        Unregister the receiver's handle from its associated router, and cause\n        :class:`ChannelError` to be raised in any thread waiting in :meth:`get`\n        on this receiver.\n        \"\"\"\n        if self.handle:\n            self.router.del_handler(self.handle)\n            self.handle = None\n        self._latch.close()\n\n    def size(self):\n        \"\"\"\n        Return the number of items currently buffered.\n\n        As with :class:`Queue.Queue`, `0` may be returned even though a\n        subsequent call to :meth:`get` will succeed, since a message may be\n        posted at any moment between :meth:`size` and :meth:`get`.\n\n        As with :class:`Queue.Queue`, `>0` may be returned even though a\n        subsequent call to :meth:`get` will block, since another waiting thread\n        may be woken at any moment between :meth:`size` and :meth:`get`.\n\n        :raises LatchError:\n            The underlying latch has already been marked closed.\n        \"\"\"\n        return self._latch.size()\n\n    def empty(self):\n        \"\"\"\n        Return `size() == 0`.\n\n        .. deprecated:: 0.2.8\n           Use :meth:`size` instead.\n\n        :raises LatchError:\n            The latch has already been marked closed.\n        \"\"\"\n        return self._latch.empty()\n\n    def get(self, timeout=None, block=True, throw_dead=True):\n        \"\"\"\n        Sleep waiting for a message to arrive on this receiver.\n\n        :param float timeout:\n            If not :data:`None`, specifies a timeout in seconds.\n\n        :raises mitogen.core.ChannelError:\n            The remote end indicated the channel should be closed,\n            communication with it was lost, or :meth:`close` was called in the\n            local process.\n\n        :raises mitogen.core.TimeoutError:\n            Timeout was reached.\n\n        :returns:\n            :class:`Message` that was received.\n        \"\"\"\n        _vv and IOLOG.debug('%r.get(timeout=%r, block=%r)', self, timeout, block)\n        try:\n            msg = self._latch.get(timeout=timeout, block=block)\n        except LatchError:\n            raise ChannelError(self.closed_msg)\n        if msg.is_dead and throw_dead:\n            msg._throw_dead()\n        return msg\n\n    def __iter__(self):\n        \"\"\"\n        Yield consecutive :class:`Message` instances delivered to this receiver\n        until :class:`ChannelError` is raised.\n        \"\"\"\n        while True:\n            try:\n                msg = self.get()\n            except ChannelError:\n                return\n            yield msg\n\n\nclass Channel(Sender, Receiver):\n    \"\"\"\n    A channel inherits from :class:`mitogen.core.Sender` and\n    `mitogen.core.Receiver` to provide bidirectional functionality.\n\n    .. deprecated:: 0.2.0\n        This class is incomplete and obsolete, it will be removed in Mitogen\n        0.3.\n\n    Channels were an early attempt at syntax sugar. It is always easier to pass\n    around unidirectional pairs of senders/receivers, even though the syntax is\n    baroque:\n\n    .. literalinclude:: ../examples/ping_pong.py\n\n    Since all handles aren't known until after both ends are constructed, for\n    both ends to communicate through a channel, it is necessary for one end to\n    retrieve the handle allocated to the other and reconfigure its own channel\n    to match. Currently this is a manual task.\n    \"\"\"\n    def __init__(self, router, context, dst_handle, handle=None):\n        Sender.__init__(self, context, dst_handle)\n        Receiver.__init__(self, router, handle)\n\n    def close(self):\n        Receiver.close(self)\n        Sender.close(self)\n\n    def __repr__(self):\n        return 'Channel(%s, %s)' % (\n            Sender.__repr__(self),\n            Receiver.__repr__(self)\n        )\n\n\nclass Importer(object):\n    \"\"\"\n    Import protocol implementation that fetches modules from the parent\n    process.\n\n    :param context: Context to communicate via.\n    \"\"\"\n    # The Mitogen package is handled specially, since the child context must\n    # construct it manually during startup.\n    MITOGEN_PKG_CONTENT = [\n        'buildah',\n        'compat',\n        'debug',\n        'doas',\n        'docker',\n        'kubectl',\n        'fakessh',\n        'fork',\n        'jail',\n        'lxc',\n        'lxd',\n        'master',\n        'minify',\n        'os_fork',\n        'parent',\n        'select',\n        'service',\n        'setns',\n        'ssh',\n        'su',\n        'sudo',\n        'utils',\n    ]\n\n    ALWAYS_BLACKLIST = [\n        # 2.x generates needless imports for 'builtins', while 3.x does the\n        # same for '__builtin__'. The correct one is built-in, the other always\n        # a negative round-trip.\n        'builtins',\n        '__builtin__',\n        'thread',\n\n        # org.python.core imported by copy, pickle, xml.sax; breaks Jython, but\n        # very unlikely to trigger a bug report.\n        'org',\n    ]\n\n    if PY3:\n        ALWAYS_BLACKLIST += ['cStringIO']\n\n    def __init__(self, router, context, core_src, whitelist=(), blacklist=()):\n        self._log = logging.getLogger('mitogen.importer')\n        self._context = context\n        self._present = {'mitogen': self.MITOGEN_PKG_CONTENT}\n        self._lock = threading.Lock()\n        self.whitelist = list(whitelist) or ['']\n        self.blacklist = list(blacklist) + self.ALWAYS_BLACKLIST\n\n        # Preserve copies of the original server-supplied whitelist/blacklist\n        # for later use by children.\n        self.master_whitelist = self.whitelist[:]\n        self.master_blacklist = self.blacklist[:]\n\n        # Presence of an entry in this map indicates in-flight GET_MODULE.\n        self._callbacks = {}\n        self._cache = {}\n        if core_src:\n            self._update_linecache('x/mitogen/core.py', core_src)\n            self._cache['mitogen.core'] = (\n                'mitogen.core',\n                None,\n                'x/mitogen/core.py',\n                zlib.compress(core_src, 9),\n                [],\n            )\n        self._install_handler(router)\n\n    def _update_linecache(self, path, data):\n        \"\"\"\n        The Python 2.4 linecache module, used to fetch source code for\n        tracebacks and :func:`inspect.getsource`, does not support PEP-302,\n        meaning it needs extra help to for Mitogen-loaded modules. Directly\n        populate its cache if a loaded module belongs to the Mitogen package.\n        \"\"\"\n        if PY24 and 'mitogen' in path:\n            linecache.cache[path] = (\n                len(data),\n                0.0,\n                [line+'\\n' for line in data.splitlines()],\n                path,\n            )\n\n    def _install_handler(self, router):\n        router.add_handler(\n            fn=self._on_load_module,\n            handle=LOAD_MODULE,\n            policy=has_parent_authority,\n        )\n\n    def __repr__(self):\n        return 'Importer'\n\n    def builtin_find_module(self, fullname):\n        # imp.find_module() will always succeed for __main__, because it is a\n        # built-in module. That means it exists on a special linked list deep\n        # within the bowels of the interpreter. We must special case it.\n        if fullname == '__main__':\n            raise ModuleNotFoundError()\n\n        parent, _, modname = str_rpartition(fullname, '.')\n        if parent:\n            path = sys.modules[parent].__path__\n        else:\n            path = None\n\n        fp, pathname, description = imp.find_module(modname, path)\n        if fp:\n            fp.close()\n\n    def find_module(self, fullname, path=None):\n        if hasattr(_tls, 'running'):\n            return None\n\n        _tls.running = True\n        try:\n            #_v and self._log.debug('Python requested %r', fullname)\n            fullname = to_text(fullname)\n            pkgname, dot, _ = str_rpartition(fullname, '.')\n            pkg = sys.modules.get(pkgname)\n            if pkgname and getattr(pkg, '__loader__', None) is not self:\n                self._log.debug('%s is submodule of a locally loaded package',\n                                fullname)\n                return None\n\n            suffix = fullname[len(pkgname+dot):]\n            if pkgname and suffix not in self._present.get(pkgname, ()):\n                self._log.debug('%s has no submodule %s', pkgname, suffix)\n                return None\n\n            # #114: explicitly whitelisted prefixes override any\n            # system-installed package.\n            if self.whitelist != ['']:\n                if any(fullname.startswith(s) for s in self.whitelist):\n                    return self\n\n            try:\n                self.builtin_find_module(fullname)\n                _vv and self._log.debug('%r is available locally', fullname)\n            except ImportError:\n                _vv and self._log.debug('we will try to load %r', fullname)\n                return self\n        finally:\n            del _tls.running\n\n    blacklisted_msg = (\n        '%r is present in the Mitogen importer blacklist, therefore this '\n        'context will not attempt to request it from the master, as the '\n        'request will always be refused.'\n    )\n    pkg_resources_msg = (\n        'pkg_resources is prohibited from importing __main__, as it causes '\n        'problems in applications whose main module is not designed to be '\n        're-imported by children.'\n    )\n    absent_msg = (\n        'The Mitogen master process was unable to serve %r. It may be a '\n        'native Python extension, or it may be missing entirely. Check the '\n        'importer debug logs on the master for more information.'\n    )\n\n    def _refuse_imports(self, fullname):\n        if is_blacklisted_import(self, fullname):\n            raise ModuleNotFoundError(self.blacklisted_msg % (fullname,))\n\n        f = sys._getframe(2)\n        requestee = f.f_globals['__name__']\n\n        if fullname == '__main__' and requestee == 'pkg_resources':\n            # Anything that imports pkg_resources will eventually cause\n            # pkg_resources to try and scan __main__ for its __requires__\n            # attribute (pkg_resources/__init__.py::_build_master()). This\n            # breaks any app that is not expecting its __main__ to suddenly be\n            # sucked over a network and injected into a remote process, like\n            # py.test.\n            raise ModuleNotFoundError(self.pkg_resources_msg)\n\n        if fullname == 'pbr':\n            # It claims to use pkg_resources to read version information, which\n            # would result in PEP-302 being used, but it actually does direct\n            # filesystem access. So instead smodge the environment to override\n            # any version that was defined. This will probably break something\n            # later.\n            os.environ['PBR_VERSION'] = '0.0.0'\n\n    def _on_load_module(self, msg):\n        if msg.is_dead:\n            return\n\n        tup = msg.unpickle()\n        fullname = tup[0]\n        _v and self._log.debug('received %s', fullname)\n\n        self._lock.acquire()\n        try:\n            self._cache[fullname] = tup\n            if tup[2] is not None and PY24:\n                self._update_linecache(\n                    path='master:' + tup[2],\n                    data=zlib.decompress(tup[3])\n                )\n            callbacks = self._callbacks.pop(fullname, [])\n        finally:\n            self._lock.release()\n\n        for callback in callbacks:\n            callback()\n\n    def _request_module(self, fullname, callback):\n        self._lock.acquire()\n        try:\n            present = fullname in self._cache\n            if not present:\n                funcs = self._callbacks.get(fullname)\n                if funcs is not None:\n                    _v and self._log.debug('existing request for %s in flight',\n                                           fullname)\n                    funcs.append(callback)\n                else:\n                    _v and self._log.debug('sending new %s request to parent',\n                                           fullname)\n                    self._callbacks[fullname] = [callback]\n                    self._context.send(\n                        Message(data=b(fullname), handle=GET_MODULE)\n                    )\n        finally:\n            self._lock.release()\n\n        if present:\n            callback()\n\n    def load_module(self, fullname):\n        fullname = to_text(fullname)\n        _v and self._log.debug('requesting %s', fullname)\n        self._refuse_imports(fullname)\n\n        event = threading.Event()\n        self._request_module(fullname, event.set)\n        event.wait()\n\n        ret = self._cache[fullname]\n        if ret[2] is None:\n            raise ModuleNotFoundError(self.absent_msg % (fullname,))\n\n        pkg_present = ret[1]\n        mod = sys.modules.setdefault(fullname, imp.new_module(fullname))\n        mod.__file__ = self.get_filename(fullname)\n        mod.__loader__ = self\n        if pkg_present is not None:  # it's a package.\n            mod.__path__ = []\n            mod.__package__ = fullname\n            self._present[fullname] = pkg_present\n        else:\n            mod.__package__ = str_rpartition(fullname, '.')[0] or None\n\n        if mod.__package__ and not PY3:\n            # 2.x requires __package__ to be exactly a string.\n            mod.__package__, _ = encodings.utf_8.encode(mod.__package__)\n\n        source = self.get_source(fullname)\n        try:\n            code = compile(source, mod.__file__, 'exec', 0, 1)\n        except SyntaxError:\n            LOG.exception('while importing %r', fullname)\n            raise\n\n        if PY3:\n            exec(code, vars(mod))\n        else:\n            exec('exec code in vars(mod)')\n\n        # #590: if a module replaces itself in sys.modules during import, below\n        # is necessary. This matches PyImport_ExecCodeModuleEx()\n        return sys.modules.get(fullname, mod)\n\n    def get_filename(self, fullname):\n        if fullname in self._cache:\n            path = self._cache[fullname][2]\n            if path is None:\n                # If find_loader() returns self but a subsequent master RPC\n                # reveals the module can't be loaded, and so load_module()\n                # throws ImportError, on Python 3.x it is still possible for\n                # the loader to be called to fetch metadata.\n                raise ModuleNotFoundError(self.absent_msg % (fullname,))\n            return u'master:' + self._cache[fullname][2]\n\n    def get_source(self, fullname):\n        if fullname in self._cache:\n            compressed = self._cache[fullname][3]\n            if compressed is None:\n                raise ModuleNotFoundError(self.absent_msg % (fullname,))\n\n            source = zlib.decompress(self._cache[fullname][3])\n            if PY3:\n                return to_text(source)\n            return source\n\n\nclass LogHandler(logging.Handler):\n    def __init__(self, context):\n        logging.Handler.__init__(self)\n        self.context = context\n        self.local = threading.local()\n        self._buffer = []\n        # Private synchronization is needed while corked, to ensure no\n        # concurrent call to _send() exists during uncork().\n        self._buffer_lock = threading.Lock()\n\n    def uncork(self):\n        \"\"\"\n        #305: during startup :class:`LogHandler` may be installed before it is\n        possible to route messages, therefore messages are buffered until\n        :meth:`uncork` is called by :class:`ExternalContext`.\n        \"\"\"\n        self._buffer_lock.acquire()\n        try:\n            self._send = self.context.send\n            for msg in self._buffer:\n                self._send(msg)\n            self._buffer = None\n        finally:\n            self._buffer_lock.release()\n\n    def _send(self, msg):\n        self._buffer_lock.acquire()\n        try:\n            if self._buffer is None:\n                # uncork() may run concurrent to _send()\n                self._send(msg)\n            else:\n                self._buffer.append(msg)\n        finally:\n            self._buffer_lock.release()\n\n    def emit(self, rec):\n        if rec.name == 'mitogen.io' or \\\n           getattr(self.local, 'in_emit', False):\n            return\n\n        self.local.in_emit = True\n        try:\n            msg = self.format(rec)\n            encoded = '%s\\x00%s\\x00%s' % (rec.name, rec.levelno, msg)\n            if isinstance(encoded, UnicodeType):\n                # Logging package emits both :(\n                encoded = encoded.encode('utf-8')\n            self._send(Message(data=encoded, handle=FORWARD_LOG))\n        finally:\n            self.local.in_emit = False\n\n\nclass Stream(object):\n    #: A :class:`Side` representing the stream's receive file descriptor.\n    receive_side = None\n\n    #: A :class:`Side` representing the stream's transmit file descriptor.\n    transmit_side = None\n\n    #: A :class:`Protocol` representing the protocol active on the stream.\n    protocol = None\n\n    #: In parents, the :class:`mitogen.parent.Connection` instance.\n    conn = None\n\n    name = u'default'\n\n    def set_protocol(self, protocol):\n        \"\"\"\n        Bind a protocol to this stream, by updating :attr:`Protocol.stream` to\n        refer to this stream, and updating this stream's\n        :attr:`Stream.protocol` to the refer to the protocol. Any prior\n        protocol's :attr:`Protocol.stream` is set to :data:`None`.\n        \"\"\"\n        if self.protocol:\n            self.protocol.stream = None\n        self.protocol = protocol\n        self.protocol.stream = self\n\n    def accept(self, rfp, wfp):\n        self.receive_side = Side(self, rfp)\n        self.transmit_side = Side(self, wfp)\n\n    def __repr__(self):\n        return \"<Stream %s>\" % (self.name,)\n\n    def on_receive(self, broker):\n        \"\"\"\n        Called by :class:`Broker` when the stream's :attr:`receive_side` has\n        been marked readable using :meth:`Broker.start_receive` and the broker\n        has detected the associated file descriptor is ready for reading.\n\n        Subclasses must implement this if :meth:`Broker.start_receive` is ever\n        called on them, and the method must call :meth:`on_disconect` if\n        reading produces an empty string.\n        \"\"\"\n        buf = self.receive_side.read(self.protocol.read_size)\n        if not buf:\n            LOG.debug('%r: empty read, disconnecting', self.receive_side)\n            return self.on_disconnect(broker)\n\n        self.protocol.on_receive(broker, buf)\n\n    def on_transmit(self, broker):\n        \"\"\"\n        Called by :class:`Broker` when the stream's :attr:`transmit_side`\n        has been marked writeable using :meth:`Broker._start_transmit` and\n        the broker has detected the associated file descriptor is ready for\n        writing.\n\n        Subclasses must implement this if :meth:`Broker._start_transmit` is\n        ever called on them.\n        \"\"\"\n        self.protocol.on_transmit(broker)\n\n    def on_shutdown(self, broker):\n        \"\"\"\n        Called by :meth:`Broker.shutdown` to allow the stream time to\n        gracefully shutdown. The base implementation simply called\n        :meth:`on_disconnect`.\n        \"\"\"\n        fire(self, 'shutdown')\n        self.protocol.on_shutdown(broker)\n\n    def on_disconnect(self, broker):\n        \"\"\"\n        Called by :class:`Broker` to force disconnect the stream. The base\n        implementation simply closes :attr:`receive_side` and\n        :attr:`transmit_side` and unregisters the stream from the broker.\n        \"\"\"\n        fire(self, 'disconnect')\n        self.protocol.on_disconnect(broker)\n\n\nclass Protocol(object):\n    \"\"\"\n    Implement the program behaviour associated with activity on a\n    :class:`Stream`. The protocol in use may vary over a stream's life, for\n    example to allow :class:`mitogen.parent.BootstrapProtocol` to initialize\n    the connected child before handing it off to :class:`MitogenProtocol`. A\n    stream's active protocol is tracked in the :attr:`Stream.protocol`\n    attribute, and modified via :meth:`Stream.set_protocol`.\n\n    Protocols do not handle IO, they are entirely reliant on the interface\n    provided by :class:`Stream` and :class:`Side`, allowing the underlying IO\n    implementation to be replaced without modifying behavioural logic.\n    \"\"\"\n    stream_class = Stream\n\n    #: The :class:`Stream` this protocol is currently bound to, or\n    #: :data:`None`.\n    stream = None\n\n    read_size = CHUNK_SIZE\n\n    @classmethod\n    def build_stream(cls, *args, **kwargs):\n        stream = cls.stream_class()\n        stream.set_protocol(cls(*args, **kwargs))\n        return stream\n\n    def __repr__(self):\n        return '%s(%s)' % (\n            self.__class__.__name__,\n            self.stream and self.stream.name,\n        )\n\n    def on_shutdown(self, broker):\n        _v and LOG.debug('%r: shutting down', self)\n        self.stream.on_disconnect(broker)\n\n    def on_disconnect(self, broker):\n        # Normally both sides an FD, so it is important that tranmit_side is\n        # deregistered from Poller before closing the receive side, as pollers\n        # like epoll and kqueue unregister all events on FD close, causing\n        # subsequent attempt to unregister the transmit side to fail.\n        LOG.debug('%r: disconnecting', self)\n        broker.stop_receive(self.stream)\n        if self.stream.transmit_side:\n            broker._stop_transmit(self.stream)\n\n        self.stream.receive_side.close()\n        if self.stream.transmit_side:\n            self.stream.transmit_side.close()\n\n\nclass DelimitedProtocol(Protocol):\n    \"\"\"\n    Provide a :meth:`Protocol.on_receive` implementation for protocols that are\n    delimited by a fixed string, like text based protocols. Each message is\n    passed to :meth:`on_line_received` as it arrives, with incomplete messages\n    passed to :meth:`on_partial_line_received`.\n\n    When emulating user input it is often necessary to respond to incomplete\n    lines, such as when a \"Password: \" prompt is sent.\n    :meth:`on_partial_line_received` may be called repeatedly with an\n    increasingly complete message. When a complete message is finally received,\n    :meth:`on_line_received` will be called once for it before the buffer is\n    discarded.\n\n    If :func:`on_line_received` returns :data:`False`, remaining data is passed\n    unprocessed to the stream's current protocol's :meth:`on_receive`. This\n    allows switching from line-oriented to binary while the input buffer\n    contains both kinds of data.\n    \"\"\"\n    #: The delimiter. Defaults to newline.\n    delimiter = b('\\n')\n    _trailer = b('')\n\n    def on_receive(self, broker, buf):\n        _vv and IOLOG.debug('%r.on_receive()', self)\n        stream = self.stream\n        self._trailer, cont = mitogen.core.iter_split(\n            buf=self._trailer + buf,\n            delim=self.delimiter,\n            func=self.on_line_received,\n        )\n\n        if self._trailer:\n            if cont:\n                self.on_partial_line_received(self._trailer)\n            else:\n                assert stream.protocol is not self\n                stream.protocol.on_receive(broker, self._trailer)\n\n    def on_line_received(self, line):\n        \"\"\"\n        Receive a line from the stream.\n\n        :param bytes line:\n            The encoded line, excluding the delimiter.\n        :returns:\n            :data:`False` to indicate this invocation modified the stream's\n            active protocol, and any remaining buffered data should be passed\n            to the new protocol's :meth:`on_receive` method.\n\n            Any other return value is ignored.\n        \"\"\"\n        pass\n\n    def on_partial_line_received(self, line):\n        \"\"\"\n        Receive a trailing unterminated partial line from the stream.\n\n        :param bytes line:\n            The encoded partial line.\n        \"\"\"\n        pass\n\n\nclass BufferedWriter(object):\n    \"\"\"\n    Implement buffered output while avoiding quadratic string operations. This\n    is currently constructed by each protocol, in future it may become fixed\n    for each stream instead.\n    \"\"\"\n    def __init__(self, broker, protocol):\n        self._broker = broker\n        self._protocol = protocol\n        self._buf = collections.deque()\n        self._len = 0\n\n    def write(self, s):\n        \"\"\"\n        Transmit `s` immediately, falling back to enqueuing it and marking the\n        stream writeable if no OS buffer space is available.\n        \"\"\"\n        if not self._len:\n            # Modifying epoll/Kqueue state is expensive, as are needless broker\n            # loops. Rather than wait for writeability, just write immediately,\n            # and fall back to the broker loop on error or full buffer.\n            try:\n                n = self._protocol.stream.transmit_side.write(s)\n                if n:\n                    if n == len(s):\n                        return\n                    s = s[n:]\n            except OSError:\n                pass\n\n            self._broker._start_transmit(self._protocol.stream)\n        self._buf.append(s)\n        self._len += len(s)\n\n    def on_transmit(self, broker):\n        \"\"\"\n        Respond to stream writeability by retrying previously buffered\n        :meth:`write` calls.\n        \"\"\"\n        if self._buf:\n            buf = self._buf.popleft()\n            written = self._protocol.stream.transmit_side.write(buf)\n            if not written:\n                _v and LOG.debug('disconnected during write to %r', self)\n                self._protocol.stream.on_disconnect(broker)\n                return\n            elif written != len(buf):\n                self._buf.appendleft(BufferType(buf, written))\n\n            _vv and IOLOG.debug('transmitted %d bytes to %r', written, self)\n            self._len -= written\n\n        if not self._buf:\n            broker._stop_transmit(self._protocol.stream)\n\n\nclass Side(object):\n    \"\"\"\n    Represent one side of a :class:`Stream`. This allows unidirectional (e.g.\n    pipe) and bidirectional (e.g. socket) streams to operate identically.\n\n    Sides are also responsible for tracking the open/closed state of the\n    underlying FD, preventing erroneous duplicate calls to :func:`os.close` due\n    to duplicate :meth:`Stream.on_disconnect` calls, which would otherwise risk\n    silently succeeding by closing an unrelated descriptor. For this reason, it\n    is crucial only one file object exists per unique descriptor.\n\n    :param mitogen.core.Stream stream:\n        The stream this side is associated with.\n    :param object fp:\n        The file or socket object managing the underlying file descriptor. Any\n        object may be used that supports `fileno()` and `close()` methods.\n    :param bool cloexec:\n        If :data:`True`, the descriptor has its :data:`fcntl.FD_CLOEXEC` flag\n        enabled using :func:`fcntl.fcntl`.\n    :param bool keep_alive:\n        If :data:`True`, the continued existence of this side will extend the\n        shutdown grace period until it has been unregistered from the broker.\n    :param bool blocking:\n        If :data:`False`, the descriptor has its :data:`os.O_NONBLOCK` flag\n        enabled using :func:`fcntl.fcntl`.\n    \"\"\"\n    _fork_refs = weakref.WeakValueDictionary()\n    closed = False\n\n    def __init__(self, stream, fp, cloexec=True, keep_alive=True, blocking=False):\n        #: The :class:`Stream` for which this is a read or write side.\n        self.stream = stream\n        # File or socket object responsible for the lifetime of its underlying\n        # file descriptor.\n        self.fp = fp\n        #: Integer file descriptor to perform IO on, or :data:`None` if\n        #: :meth:`close` has been called. This is saved separately from the\n        #: file object, since :meth:`file.fileno` cannot be called on it after\n        #: it has been closed.\n        self.fd = fp.fileno()\n        #: If :data:`True`, causes presence of this side in\n        #: :class:`Broker`'s active reader set to defer shutdown until the\n        #: side is disconnected.\n        self.keep_alive = keep_alive\n        self._fork_refs[id(self)] = self\n        if cloexec:\n            set_cloexec(self.fd)\n        if not blocking:\n            set_nonblock(self.fd)\n\n    def __repr__(self):\n        return '<Side of %s fd %s>' % (\n            self.stream.name or repr(self.stream),\n            self.fd\n        )\n\n    @classmethod\n    def _on_fork(cls):\n        while cls._fork_refs:\n            _, side = cls._fork_refs.popitem()\n            _vv and IOLOG.debug('Side._on_fork() closing %r', side)\n            side.close()\n\n    def close(self):\n        \"\"\"\n        Call :meth:`file.close` on :attr:`fp` if it is not :data:`None`,\n        then set it to :data:`None`.\n        \"\"\"\n        _vv and IOLOG.debug('%r.close()', self)\n        if not self.closed:\n            self.closed = True\n            self.fp.close()\n\n    def read(self, n=CHUNK_SIZE):\n        \"\"\"\n        Read up to `n` bytes from the file descriptor, wrapping the underlying\n        :func:`os.read` call with :func:`io_op` to trap common disconnection\n        conditions.\n\n        :meth:`read` always behaves as if it is reading from a regular UNIX\n        file; socket, pipe, and TTY disconnection errors are masked and result\n        in a 0-sized read like a regular file.\n\n        :returns:\n            Bytes read, or the empty string to indicate disconnection was\n            detected.\n        \"\"\"\n        if self.closed:\n            # Refuse to touch the handle after closed, it may have been reused\n            # by another thread. TODO: synchronize read()/write()/close().\n            return b('')\n        s, disconnected = io_op(os.read, self.fd, n)\n        if disconnected:\n            LOG.debug('%r: disconnected during read: %s', self, disconnected)\n            return b('')\n        return s\n\n    def write(self, s):\n        \"\"\"\n        Write as much of the bytes from `s` as possible to the file descriptor,\n        wrapping the underlying :func:`os.write` call with :func:`io_op` to\n        trap common disconnection conditions.\n\n        :returns:\n            Number of bytes written, or :data:`None` if disconnection was\n            detected.\n        \"\"\"\n        if self.closed:\n            # Don't touch the handle after close, it may be reused elsewhere.\n            return None\n\n        written, disconnected = io_op(os.write, self.fd, s)\n        if disconnected:\n            LOG.debug('%r: disconnected during write: %s', self, disconnected)\n            return None\n        return written\n\n\nclass MitogenProtocol(Protocol):\n    \"\"\"\n    :class:`Protocol` implementing mitogen's :ref:`stream protocol\n    <stream-protocol>`.\n    \"\"\"\n    #: If not :data:`None`, :class:`Router` stamps this into\n    #: :attr:`Message.auth_id` of every message received on this stream.\n    auth_id = None\n\n    #: If not :data:`False`, indicates the stream has :attr:`auth_id` set and\n    #: its value is the same as :data:`mitogen.context_id` or appears in\n    #: :data:`mitogen.parent_ids`.\n    is_privileged = False\n\n    def __init__(self, router, remote_id):\n        self._router = router\n        self.remote_id = remote_id\n        self.sent_modules = set(['mitogen', 'mitogen.core'])\n        self._input_buf = collections.deque()\n        self._input_buf_len = 0\n        self._writer = BufferedWriter(router.broker, self)\n\n        #: Routing records the dst_id of every message arriving from this\n        #: stream. Any arriving DEL_ROUTE is rebroadcast for any such ID.\n        self.egress_ids = set()\n\n    def on_receive(self, broker, buf):\n        \"\"\"\n        Handle the next complete message on the stream. Raise\n        :class:`StreamError` on failure.\n        \"\"\"\n        _vv and IOLOG.debug('%r.on_receive()', self)\n        if self._input_buf and self._input_buf_len < 128:\n            self._input_buf[0] += buf\n        else:\n            self._input_buf.append(buf)\n\n        self._input_buf_len += len(buf)\n        while self._receive_one(broker):\n            pass\n\n    corrupt_msg = (\n        '%s: Corruption detected: frame signature incorrect. This likely means'\n        ' some external process is interfering with the connection. Received:'\n        '\\n\\n'\n        '%r'\n    )\n\n    def _receive_one(self, broker):\n        if self._input_buf_len < Message.HEADER_LEN:\n            return False\n\n        msg = Message()\n        msg.router = self._router\n        (magic, msg.dst_id, msg.src_id, msg.auth_id,\n         msg.handle, msg.reply_to, msg_len) = struct.unpack(\n            Message.HEADER_FMT,\n            self._input_buf[0][:Message.HEADER_LEN],\n        )\n\n        if magic != Message.HEADER_MAGIC:\n            LOG.error(self.corrupt_msg, self.stream.name, self._input_buf[0][:2048])\n            self.stream.on_disconnect(broker)\n            return False\n\n        if msg_len > self._router.max_message_size:\n            LOG.error('Maximum message size exceeded (got %d, max %d)',\n                      msg_len, self._router.max_message_size)\n            self.stream.on_disconnect(broker)\n            return False\n\n        total_len = msg_len + Message.HEADER_LEN\n        if self._input_buf_len < total_len:\n            _vv and IOLOG.debug(\n                '%r: Input too short (want %d, got %d)',\n                self, msg_len, self._input_buf_len - Message.HEADER_LEN\n            )\n            return False\n\n        start = Message.HEADER_LEN\n        prev_start = start\n        remain = total_len\n        bits = []\n        while remain:\n            buf = self._input_buf.popleft()\n            bit = buf[start:remain]\n            bits.append(bit)\n            remain -= len(bit) + start\n            prev_start = start\n            start = 0\n\n        msg.data = b('').join(bits)\n        self._input_buf.appendleft(buf[prev_start+len(bit):])\n        self._input_buf_len -= total_len\n        self._router._async_route(msg, self.stream)\n        return True\n\n    def pending_bytes(self):\n        \"\"\"\n        Return the number of bytes queued for transmission on this stream. This\n        can be used to limit the amount of data buffered in RAM by an otherwise\n        unlimited consumer.\n\n        For an accurate result, this method should be called from the Broker\n        thread, for example by using :meth:`Broker.defer_sync`.\n        \"\"\"\n        return self._writer._len\n\n    def on_transmit(self, broker):\n        \"\"\"\n        Transmit buffered messages.\n        \"\"\"\n        _vv and IOLOG.debug('%r.on_transmit()', self)\n        self._writer.on_transmit(broker)\n\n    def _send(self, msg):\n        _vv and IOLOG.debug('%r._send(%r)', self, msg)\n        self._writer.write(msg.pack())\n\n    def send(self, msg):\n        \"\"\"\n        Send `data` to `handle`, and tell the broker we have output. May be\n        called from any thread.\n        \"\"\"\n        self._router.broker.defer(self._send, msg)\n\n    def on_shutdown(self, broker):\n        \"\"\"\n        Disable :class:`Protocol` immediate disconnect behaviour.\n        \"\"\"\n        _v and LOG.debug('%r: shutting down', self)\n\n\nclass Context(object):\n    \"\"\"\n    Represent a remote context regardless of the underlying connection method.\n    Context objects are simple facades that emit messages through an\n    associated router, and have :ref:`signals` raised against them in response\n    to various events relating to the context.\n\n    **Note:** This is the somewhat limited core version, used by child\n    contexts. The master subclass is documented below this one.\n\n    Contexts maintain no internal state and are thread-safe.\n\n    Prefer :meth:`Router.context_by_id` over constructing context objects\n    explicitly, as that method is deduplicating, and returns the only context\n    instance :ref:`signals` will be raised on.\n\n    :param mitogen.core.Router router:\n        Router to emit messages through.\n    :param int context_id:\n        Context ID.\n    :param str name:\n        Context name.\n    \"\"\"\n    name = None\n    remote_name = None\n\n    def __init__(self, router, context_id, name=None):\n        self.router = router\n        self.context_id = context_id\n        if name:\n            self.name = to_text(name)\n\n    def __reduce__(self):\n        return _unpickle_context, (self.context_id, self.name)\n\n    def on_disconnect(self):\n        _v and LOG.debug('%r: disconnecting', self)\n        fire(self, 'disconnect')\n\n    def send_async(self, msg, persist=False):\n        \"\"\"\n        Arrange for `msg` to be delivered to this context, with replies\n        directed to a newly constructed receiver. :attr:`dst_id\n        <Message.dst_id>` is set to the target context ID, and :attr:`reply_to\n        <Message.reply_to>` is set to the newly constructed receiver's handle.\n\n        :param bool persist:\n            If :data:`False`, the handler will be unregistered after a single\n            message has been received.\n\n        :param mitogen.core.Message msg:\n            The message.\n\n        :returns:\n            :class:`Receiver` configured to receive any replies sent to the\n            message's `reply_to` handle.\n        \"\"\"\n        receiver = Receiver(self.router, persist=persist, respondent=self)\n        msg.dst_id = self.context_id\n        msg.reply_to = receiver.handle\n\n        _v and LOG.debug('sending message to %r: %r', self, msg)\n        self.send(msg)\n        return receiver\n\n    def call_service_async(self, service_name, method_name, **kwargs):\n        _v and LOG.debug('calling service %s.%s of %r, args: %r',\n                         service_name, method_name, self, kwargs)\n        if isinstance(service_name, BytesType):\n            service_name = service_name.encode('utf-8')\n        elif not isinstance(service_name, UnicodeType):\n            service_name = service_name.name()  # Service.name()\n        tup = (service_name, to_text(method_name), Kwargs(kwargs))\n        msg = Message.pickled(tup, handle=CALL_SERVICE)\n        return self.send_async(msg)\n\n    def send(self, msg):\n        \"\"\"\n        Arrange for `msg` to be delivered to this context. :attr:`dst_id\n        <Message.dst_id>` is set to the target context ID.\n\n        :param Message msg:\n            Message.\n        \"\"\"\n        msg.dst_id = self.context_id\n        self.router.route(msg)\n\n    def call_service(self, service_name, method_name, **kwargs):\n        recv = self.call_service_async(service_name, method_name, **kwargs)\n        return recv.get().unpickle()\n\n    def send_await(self, msg, deadline=None):\n        \"\"\"\n        Like :meth:`send_async`, but expect a single reply (`persist=False`)\n        delivered within `deadline` seconds.\n\n        :param mitogen.core.Message msg:\n            The message.\n        :param float deadline:\n            If not :data:`None`, seconds before timing out waiting for a reply.\n        :returns:\n            Deserialized reply.\n        :raises TimeoutError:\n            No message was received and `deadline` passed.\n        \"\"\"\n        receiver = self.send_async(msg)\n        response = receiver.get(deadline)\n        data = response.unpickle()\n        _vv and IOLOG.debug('%r._send_await() -> %r', self, data)\n        return data\n\n    def __repr__(self):\n        return 'Context(%s, %r)' % (self.context_id, self.name)\n\n\ndef _unpickle_context(context_id, name, router=None):\n    if not (isinstance(context_id, (int, long)) and context_id >= 0 and (\n        (name is None) or\n        (isinstance(name, UnicodeType) and len(name) < 100))\n    ):\n        raise TypeError('cannot unpickle Context: bad input')\n\n    if isinstance(router, Router):\n        return router.context_by_id(context_id, name=name)\n    return Context(None, context_id, name)  # For plain Jane pickle.\n\n\nclass Poller(object):\n    \"\"\"\n    A poller manages OS file descriptors the user is waiting to become\n    available for IO. The :meth:`poll` method blocks the calling thread\n    until one or more become ready. The default implementation is based on\n    :func:`select.poll`.\n\n    Each descriptor has an associated `data` element, which is unique for each\n    readiness type, and defaults to being the same as the file descriptor. The\n    :meth:`poll` method yields the data associated with a descriptor, rather\n    than the descriptor itself, allowing concise loops like::\n\n        p = Poller()\n        p.start_receive(conn.fd, data=conn.on_read)\n        p.start_transmit(conn.fd, data=conn.on_write)\n\n        for callback in p.poll():\n            callback()  # invoke appropriate bound instance method\n\n    Pollers may be modified while :meth:`poll` is yielding results. Removals\n    are processed immediately, causing pending events for the descriptor to be\n    discarded.\n\n    The :meth:`close` method must be called when a poller is discarded to avoid\n    a resource leak.\n\n    Pollers may only be used by one thread at a time.\n    \"\"\"\n    SUPPORTED = True\n\n    # This changed from select() to poll() in Mitogen 0.2.4. Since poll() has\n    # no upper FD limit, it is suitable for use with Latch, which must handle\n    # FDs larger than select's limit during many-host runs. We want this\n    # because poll() requires no setup and teardown: just a single system call,\n    # which is important because Latch.get() creates a Poller on each\n    # invocation. In a microbenchmark, poll() vs. epoll_ctl() is 30% faster in\n    # this scenario. If select() must return in future, it is important\n    # Latch.poller_class is set from parent.py to point to the industrial\n    # strength poller for the OS, otherwise Latch will fail randomly.\n\n    #: Increments on every poll(). Used to version _rfds and _wfds.\n    _generation = 1\n\n    def __init__(self):\n        self._rfds = {}\n        self._wfds = {}\n\n    def __repr__(self):\n        return '%s' % (type(self).__name__,)\n\n    def _update(self, fd):\n        \"\"\"\n        Required by PollPoller subclass.\n        \"\"\"\n        pass\n\n    @property\n    def readers(self):\n        \"\"\"\n        Return a list of `(fd, data)` tuples for every FD registered for\n        receive readiness.\n        \"\"\"\n        return list((fd, data) for fd, (data, gen) in self._rfds.items())\n\n    @property\n    def writers(self):\n        \"\"\"\n        Return a list of `(fd, data)` tuples for every FD registered for\n        transmit readiness.\n        \"\"\"\n        return list((fd, data) for fd, (data, gen) in self._wfds.items())\n\n    def close(self):\n        \"\"\"\n        Close any underlying OS resource used by the poller.\n        \"\"\"\n        pass\n\n    def start_receive(self, fd, data=None):\n        \"\"\"\n        Cause :meth:`poll` to yield `data` when `fd` is readable.\n        \"\"\"\n        self._rfds[fd] = (data or fd, self._generation)\n        self._update(fd)\n\n    def stop_receive(self, fd):\n        \"\"\"\n        Stop yielding readability events for `fd`.\n\n        Redundant calls to :meth:`stop_receive` are silently ignored, this may\n        change in future.\n        \"\"\"\n        self._rfds.pop(fd, None)\n        self._update(fd)\n\n    def start_transmit(self, fd, data=None):\n        \"\"\"\n        Cause :meth:`poll` to yield `data` when `fd` is writeable.\n        \"\"\"\n        self._wfds[fd] = (data or fd, self._generation)\n        self._update(fd)\n\n    def stop_transmit(self, fd):\n        \"\"\"\n        Stop yielding writeability events for `fd`.\n\n        Redundant calls to :meth:`stop_transmit` are silently ignored, this may\n        change in future.\n        \"\"\"\n        self._wfds.pop(fd, None)\n        self._update(fd)\n\n    def _poll(self, timeout):\n        (rfds, wfds, _), _ = io_op(select.select,\n            self._rfds,\n            self._wfds,\n            (), timeout\n        )\n\n        for fd in rfds:\n            _vv and IOLOG.debug('%r: POLLIN for %r', self, fd)\n            data, gen = self._rfds.get(fd, (None, None))\n            if gen and gen < self._generation:\n                yield data\n\n        for fd in wfds:\n            _vv and IOLOG.debug('%r: POLLOUT for %r', self, fd)\n            data, gen = self._wfds.get(fd, (None, None))\n            if gen and gen < self._generation:\n                yield data\n\n    def poll(self, timeout=None):\n        \"\"\"\n        Block the calling thread until one or more FDs are ready for IO.\n\n        :param float timeout:\n            If not :data:`None`, seconds to wait without an event before\n            returning an empty iterable.\n        :returns:\n            Iterable of `data` elements associated with ready FDs.\n        \"\"\"\n        _vv and IOLOG.debug('%r.poll(%r)', self, timeout)\n        self._generation += 1\n        return self._poll(timeout)\n\n\nclass Latch(object):\n    \"\"\"\n    A latch is a :class:`Queue.Queue`-like object that supports mutation and\n    waiting from multiple threads, however unlike :class:`Queue.Queue`,\n    waiting threads always remain interruptible, so CTRL+C always succeeds, and\n    waits where a timeout is set experience no wake up latency. These\n    properties are not possible in combination using the built-in threading\n    primitives available in Python 2.x.\n\n    Latches implement queues using the UNIX self-pipe trick, and a per-thread\n    :func:`socket.socketpair` that is lazily created the first time any\n    latch attempts to sleep on a thread, and dynamically associated with the\n    waiting Latch only for duration of the wait.\n\n    See :ref:`waking-sleeping-threads` for further discussion.\n    \"\"\"\n    poller_class = Poller\n\n    notify = None\n\n    # The _cls_ prefixes here are to make it crystal clear in the code which\n    # state mutation isn't covered by :attr:`_lock`.\n\n    #: List of reusable :func:`socket.socketpair` tuples. The list is mutated\n    #: from multiple threads, the only safe operations are `append()` and\n    #: `pop()`.\n    _cls_idle_socketpairs = []\n\n    #: List of every socket object that must be closed by :meth:`_on_fork`.\n    #: Inherited descriptors cannot be reused, as the duplicated handles\n    #: reference the same underlying kernel object in use by the parent.\n    _cls_all_sockets = []\n\n    def __init__(self):\n        self.closed = False\n        self._lock = threading.Lock()\n        #: List of unconsumed enqueued items.\n        self._queue = []\n        #: List of `(wsock, cookie)` awaiting an element, where `wsock` is the\n        #: socketpair's write side, and `cookie` is the string to write.\n        self._sleeping = []\n        #: Number of elements of :attr:`_sleeping` that have already been\n        #: woken, and have a corresponding element index from :attr:`_queue`\n        #: assigned to them.\n        self._waking = 0\n\n    @classmethod\n    def _on_fork(cls):\n        \"\"\"\n        Clean up any files belonging to the parent process after a fork.\n        \"\"\"\n        cls._cls_idle_socketpairs = []\n        while cls._cls_all_sockets:\n            cls._cls_all_sockets.pop().close()\n\n    def close(self):\n        \"\"\"\n        Mark the latch as closed, and cause every sleeping thread to be woken,\n        with :class:`mitogen.core.LatchError` raised in each thread.\n        \"\"\"\n        self._lock.acquire()\n        try:\n            self.closed = True\n            while self._waking < len(self._sleeping):\n                wsock, cookie = self._sleeping[self._waking]\n                self._wake(wsock, cookie)\n                self._waking += 1\n        finally:\n            self._lock.release()\n\n    def size(self):\n        \"\"\"\n        Return the number of items currently buffered.\n\n        As with :class:`Queue.Queue`, `0` may be returned even though a\n        subsequent call to :meth:`get` will succeed, since a message may be\n        posted at any moment between :meth:`size` and :meth:`get`.\n\n        As with :class:`Queue.Queue`, `>0` may be returned even though a\n        subsequent call to :meth:`get` will block, since another waiting thread\n        may be woken at any moment between :meth:`size` and :meth:`get`.\n\n        :raises LatchError:\n            The latch has already been marked closed.\n        \"\"\"\n        self._lock.acquire()\n        try:\n            if self.closed:\n                raise LatchError()\n            return len(self._queue)\n        finally:\n            self._lock.release()\n\n    def empty(self):\n        \"\"\"\n        Return `size() == 0`.\n\n        .. deprecated:: 0.2.8\n           Use :meth:`size` instead.\n\n        :raises LatchError:\n            The latch has already been marked closed.\n        \"\"\"\n        return self.size() == 0\n\n    def _get_socketpair(self):\n        \"\"\"\n        Return an unused socketpair, creating one if none exist.\n        \"\"\"\n        try:\n            return self._cls_idle_socketpairs.pop()  # pop() must be atomic\n        except IndexError:\n            rsock, wsock = socket.socketpair()\n            set_cloexec(rsock.fileno())\n            set_cloexec(wsock.fileno())\n            self._cls_all_sockets.extend((rsock, wsock))\n            return rsock, wsock\n\n    COOKIE_MAGIC, = struct.unpack('L', b('LTCH') * (struct.calcsize('L')//4))\n    COOKIE_FMT = '>Qqqq'  # #545: id() and get_ident() may exceed long on armhfp.\n    COOKIE_SIZE = struct.calcsize(COOKIE_FMT)\n\n    def _make_cookie(self):\n        \"\"\"\n        Return a string encoding the ID of the process, instance and thread.\n        This disambiguates legitimate wake-ups, accidental writes to the FD,\n        and buggy internal FD sharing.\n        \"\"\"\n        return struct.pack(self.COOKIE_FMT, self.COOKIE_MAGIC,\n                           os.getpid(), id(self), thread.get_ident())\n\n    def get(self, timeout=None, block=True):\n        \"\"\"\n        Return the next enqueued object, or sleep waiting for one.\n\n        :param float timeout:\n            If not :data:`None`, specifies a timeout in seconds.\n\n        :param bool block:\n            If :data:`False`, immediately raise\n            :class:`mitogen.core.TimeoutError` if the latch is empty.\n\n        :raises mitogen.core.LatchError:\n            :meth:`close` has been called, and the object is no longer valid.\n\n        :raises mitogen.core.TimeoutError:\n            Timeout was reached.\n\n        :returns:\n            The de-queued object.\n        \"\"\"\n        _vv and IOLOG.debug('%r.get(timeout=%r, block=%r)',\n                            self, timeout, block)\n        self._lock.acquire()\n        try:\n            if self.closed:\n                raise LatchError()\n            i = len(self._sleeping)\n            if len(self._queue) > i:\n                _vv and IOLOG.debug('%r.get() -> %r', self, self._queue[i])\n                return self._queue.pop(i)\n            if not block:\n                raise TimeoutError()\n            rsock, wsock = self._get_socketpair()\n            cookie = self._make_cookie()\n            self._sleeping.append((wsock, cookie))\n        finally:\n            self._lock.release()\n\n        poller = self.poller_class()\n        poller.start_receive(rsock.fileno())\n        try:\n            return self._get_sleep(poller, timeout, block, rsock, wsock, cookie)\n        finally:\n            poller.close()\n\n    def _get_sleep(self, poller, timeout, block, rsock, wsock, cookie):\n        \"\"\"\n        When a result is not immediately available, sleep waiting for\n        :meth:`put` to write a byte to our socket pair.\n        \"\"\"\n        _vv and IOLOG.debug(\n            '%r._get_sleep(timeout=%r, block=%r, fd=%d/%d)',\n            self, timeout, block, rsock.fileno(), wsock.fileno()\n        )\n\n        e = None\n        woken = None\n        try:\n            woken = list(poller.poll(timeout))\n        except Exception:\n            e = sys.exc_info()[1]\n\n        self._lock.acquire()\n        try:\n            i = self._sleeping.index((wsock, cookie))\n            del self._sleeping[i]\n            if not woken:\n                raise e or TimeoutError()\n\n            got_cookie = rsock.recv(self.COOKIE_SIZE)\n            self._cls_idle_socketpairs.append((rsock, wsock))\n\n            assert cookie == got_cookie, (\n                \"Cookie incorrect; got %r, expected %r\" \\\n                % (binascii.hexlify(got_cookie),\n                   binascii.hexlify(cookie))\n            )\n            assert i < self._waking, (\n                \"Cookie correct, but no queue element assigned.\"\n            )\n            self._waking -= 1\n            if self.closed:\n                raise LatchError()\n            _vv and IOLOG.debug('%r.get() wake -> %r', self, self._queue[i])\n            return self._queue.pop(i)\n        finally:\n            self._lock.release()\n\n    def put(self, obj=None):\n        \"\"\"\n        Enqueue an object, waking the first thread waiting for a result, if one\n        exists.\n\n        :param obj:\n            Object to enqueue. Defaults to :data:`None` as a convenience when\n            using :class:`Latch` only for synchronization.\n        :raises mitogen.core.LatchError:\n            :meth:`close` has been called, and the object is no longer valid.\n        \"\"\"\n        _vv and IOLOG.debug('%r.put(%r)', self, obj)\n        self._lock.acquire()\n        try:\n            if self.closed:\n                raise LatchError()\n            self._queue.append(obj)\n\n            wsock = None\n            if self._waking < len(self._sleeping):\n                wsock, cookie = self._sleeping[self._waking]\n                self._waking += 1\n                _vv and IOLOG.debug('%r.put() -> waking wfd=%r',\n                                    self, wsock.fileno())\n            elif self.notify:\n                self.notify(self)\n        finally:\n            self._lock.release()\n\n        if wsock:\n            self._wake(wsock, cookie)\n\n    def _wake(self, wsock, cookie):\n        written, disconnected = io_op(os.write, wsock.fileno(), cookie)\n        assert written == len(cookie) and not disconnected\n\n    def __repr__(self):\n        return 'Latch(%#x, size=%d, t=%r)' % (\n            id(self),\n            len(self._queue),\n            threading.currentThread().getName(),\n        )\n\n\nclass Waker(Protocol):\n    \"\"\"\n    :class:`BasicStream` subclass implementing the `UNIX self-pipe trick`_.\n    Used to wake the multiplexer when another thread needs to modify its state\n    (via a cross-thread function call).\n\n    .. _UNIX self-pipe trick: https://cr.yp.to/docs/selfpipe.html\n    \"\"\"\n    read_size = 1\n    broker_ident = None\n\n    @classmethod\n    def build_stream(cls, broker):\n        stream = super(Waker, cls).build_stream(broker)\n        stream.accept(*pipe())\n        return stream\n\n    def __init__(self, broker):\n        self._broker = broker\n        self._lock = threading.Lock()\n        self._deferred = []\n\n    def __repr__(self):\n        return 'Waker(fd=%r/%r)' % (\n            self.stream.receive_side and self.stream.receive_side.fd,\n            self.stream.transmit_side and self.stream.transmit_side.fd,\n        )\n\n    @property\n    def keep_alive(self):\n        \"\"\"\n        Prevent immediate Broker shutdown while deferred functions remain.\n        \"\"\"\n        self._lock.acquire()\n        try:\n            return len(self._deferred)\n        finally:\n            self._lock.release()\n\n    def on_receive(self, broker, buf):\n        \"\"\"\n        Drain the pipe and fire callbacks. Since :attr:`_deferred` is\n        synchronized, :meth:`defer` and :meth:`on_receive` can conspire to\n        ensure only one byte needs to be pending regardless of queue length.\n        \"\"\"\n        _vv and IOLOG.debug('%r.on_receive()', self)\n        self._lock.acquire()\n        try:\n            deferred = self._deferred\n            self._deferred = []\n        finally:\n            self._lock.release()\n\n        for func, args, kwargs in deferred:\n            try:\n                func(*args, **kwargs)\n            except Exception:\n                LOG.exception('defer() crashed: %r(*%r, **%r)',\n                              func, args, kwargs)\n                broker.shutdown()\n\n    def _wake(self):\n        \"\"\"\n        Wake the multiplexer by writing a byte. If Broker is midway through\n        teardown, the FD may already be closed, so ignore EBADF.\n        \"\"\"\n        try:\n            self.stream.transmit_side.write(b(' '))\n        except OSError:\n            e = sys.exc_info()[1]\n            if e.args[0] != errno.EBADF:\n                raise\n\n    broker_shutdown_msg = (\n        \"An attempt was made to enqueue a message with a Broker that has \"\n        \"already exitted. It is likely your program called Broker.shutdown() \"\n        \"too early.\"\n    )\n\n    def defer(self, func, *args, **kwargs):\n        \"\"\"\n        Arrange for `func()` to execute on the broker thread. This function\n        returns immediately without waiting the result of `func()`. Use\n        :meth:`defer_sync` to block until a result is available.\n\n        :raises mitogen.core.Error:\n            :meth:`defer` was called after :class:`Broker` has begun shutdown.\n        \"\"\"\n        if thread.get_ident() == self.broker_ident:\n            _vv and IOLOG.debug('%r.defer() [immediate]', self)\n            return func(*args, **kwargs)\n        if self._broker._exitted:\n            raise Error(self.broker_shutdown_msg)\n\n        _vv and IOLOG.debug('%r.defer() [fd=%r]', self,\n                            self.stream.transmit_side.fd)\n        self._lock.acquire()\n        try:\n            should_wake = not self._deferred\n            self._deferred.append((func, args, kwargs))\n        finally:\n            self._lock.release()\n\n        if should_wake:\n            self._wake()\n\n\nclass IoLoggerProtocol(DelimitedProtocol):\n    \"\"\"\n    Handle redirection of standard IO into the :mod:`logging` package.\n    \"\"\"\n    @classmethod\n    def build_stream(cls, name, dest_fd):\n        \"\"\"\n        Even though the descriptor `dest_fd` will hold the opposite end of the\n        socket open, we must keep a separate dup() of it (i.e. wsock) in case\n        some code decides to overwrite `dest_fd` later, which would thus break\n        :meth:`on_shutdown`.\n        \"\"\"\n        rsock, wsock = socket.socketpair()\n        os.dup2(wsock.fileno(), dest_fd)\n        stream = super(IoLoggerProtocol, cls).build_stream(name)\n        stream.name = name\n        stream.accept(rsock, wsock)\n        return stream\n\n    def __init__(self, name):\n        self._log = logging.getLogger(name)\n        # #453: prevent accidental log initialization in a child creating a\n        # feedback loop.\n        self._log.propagate = False\n        self._log.handlers = logging.getLogger().handlers[:]\n\n    def on_shutdown(self, broker):\n        \"\"\"\n        Shut down the write end of the socket, preventing any further writes to\n        it by this process, or subprocess that inherited it. This allows any\n        remaining kernel-buffered data to be drained during graceful shutdown\n        without the buffer continuously refilling due to some out of control\n        child process.\n        \"\"\"\n        _v and LOG.debug('%r: shutting down', self)\n        if not IS_WSL:\n            # #333: WSL generates invalid readiness indication on shutdown().\n            # This modifies the *kernel object* inherited by children, causing\n            # EPIPE on subsequent writes to any dupped FD in any process. The\n            # read side can then drain completely of prior buffered data.\n            self.stream.transmit_side.fp.shutdown(socket.SHUT_WR)\n        self.stream.transmit_side.close()\n\n    def on_line_received(self, line):\n        \"\"\"\n        Decode the received line as UTF-8 and pass it to the logging framework.\n        \"\"\"\n        self._log.info('%s', line.decode('utf-8', 'replace'))\n\n\nclass Router(object):\n    \"\"\"\n    Route messages between contexts, and invoke local handlers for messages\n    addressed to this context. :meth:`Router.route() <route>` straddles the\n    :class:`Broker` thread and user threads, it is safe to call anywhere.\n\n    **Note:** This is the somewhat limited core version of the Router class\n    used by child contexts. The master subclass is documented below this one.\n    \"\"\"\n    #: The :class:`mitogen.core.Context` subclass to use when constructing new\n    #: :class:`Context` objects in :meth:`myself` and :meth:`context_by_id`.\n    #: Permits :class:`Router` subclasses to extend the :class:`Context`\n    #: interface, as done in :class:`mitogen.parent.Router`.\n    context_class = Context\n\n    max_message_size = 128 * 1048576\n\n    #: When :data:`True`, permit children to only communicate with the current\n    #: context or a parent of the current context. Routing between siblings or\n    #: children of parents is prohibited, ensuring no communication is possible\n    #: between intentionally partitioned networks, such as when a program\n    #: simultaneously manipulates hosts spread across a corporate and a\n    #: production network, or production networks that are otherwise\n    #: air-gapped.\n    #:\n    #: Sending a prohibited message causes an error to be logged and a dead\n    #: message to be sent in reply to the errant message, if that message has\n    #: ``reply_to`` set.\n    #:\n    #: The value of :data:`unidirectional` becomes the default for the\n    #: :meth:`local() <mitogen.master.Router.local>` `unidirectional`\n    #: parameter.\n    unidirectional = False\n\n    duplicate_handle_msg = 'cannot register a handle that already exists'\n    refused_msg = 'refused by policy'\n    invalid_handle_msg = 'invalid handle'\n    too_large_msg = 'message too large (max %d bytes)'\n    respondent_disconnect_msg = 'the respondent Context has disconnected'\n    broker_exit_msg = 'Broker has exitted'\n    no_route_msg = 'no route to %r, my ID is %r'\n    unidirectional_msg = (\n        'routing mode prevents forward of message from context %d via '\n        'context %d'\n    )\n\n    def __init__(self, broker):\n        self.broker = broker\n        listen(broker, 'exit', self._on_broker_exit)\n        self._setup_logging()\n\n        self._write_lock = threading.Lock()\n        #: context ID -> Stream; must hold _write_lock to edit or iterate\n        self._stream_by_id = {}\n        #: List of contexts to notify of shutdown; must hold _write_lock\n        self._context_by_id = {}\n        self._last_handle = itertools.count(1000)\n        #: handle -> (persistent?, func(msg))\n        self._handle_map = {}\n        #: Context -> set { handle, .. }\n        self._handles_by_respondent = {}\n        self.add_handler(self._on_del_route, DEL_ROUTE)\n\n    def __repr__(self):\n        return 'Router(%r)' % (self.broker,)\n\n    def _setup_logging(self):\n        \"\"\"\n        This is done in the :class:`Router` constructor for historical reasons.\n        It must be called before ExternalContext logs its first messages, but\n        after logging has been setup. It must also be called when any router is\n        constructed for a consumer app.\n        \"\"\"\n        # Here seems as good a place as any.\n        global _v, _vv\n        _v = logging.getLogger().level <= logging.DEBUG\n        _vv = IOLOG.level <= logging.DEBUG\n\n    def _on_del_route(self, msg):\n        \"\"\"\n        Stub :data:`DEL_ROUTE` handler; fires 'disconnect' events on the\n        corresponding :attr:`_context_by_id` member. This is replaced by\n        :class:`mitogen.parent.RouteMonitor` in an upgraded context.\n        \"\"\"\n        if msg.is_dead:\n            return\n\n        target_id_s, _, name = bytes_partition(msg.data, b(':'))\n        target_id = int(target_id_s, 10)\n        LOG.error('%r: deleting route to %s (%d)',\n                  self, to_text(name), target_id)\n        context = self._context_by_id.get(target_id)\n        if context:\n            fire(context, 'disconnect')\n        else:\n            LOG.debug('DEL_ROUTE for unknown ID %r: %r', target_id, msg)\n\n    def _on_stream_disconnect(self, stream):\n        notify = []\n        self._write_lock.acquire()\n        try:\n            for context in list(self._context_by_id.values()):\n                stream_ = self._stream_by_id.get(context.context_id)\n                if stream_ is stream:\n                    del self._stream_by_id[context.context_id]\n                    notify.append(context)\n        finally:\n            self._write_lock.release()\n\n        # Happens outside lock as e.g. RouteMonitor wants the same lock.\n        for context in notify:\n            context.on_disconnect()\n\n    def _on_broker_exit(self):\n        \"\"\"\n        Called prior to broker exit, informs callbacks registered with\n        :meth:`add_handler` the connection is dead.\n        \"\"\"\n        _v and LOG.debug('%r: broker has exitted', self)\n        while self._handle_map:\n            _, (_, func, _, _) = self._handle_map.popitem()\n            func(Message.dead(self.broker_exit_msg))\n\n    def myself(self):\n        \"\"\"\n        Return a :class:`Context` referring to the current process. Since\n        :class:`Context` is serializable, this is convenient to use in remote\n        function call parameter lists.\n        \"\"\"\n        return self.context_class(\n            router=self,\n            context_id=mitogen.context_id,\n            name='self',\n        )\n\n    def context_by_id(self, context_id, via_id=None, create=True, name=None):\n        \"\"\"\n        Return or construct a :class:`Context` given its ID. An internal\n        mapping of ID to the canonical :class:`Context` representing that ID,\n        so that :ref:`signals` can be raised.\n\n        This may be called from any thread, lookup and construction are atomic.\n\n        :param int context_id:\n            The context ID to look up.\n        :param int via_id:\n            If the :class:`Context` does not already exist, set its\n            :attr:`Context.via` to the :class:`Context` matching this ID.\n        :param bool create:\n            If the :class:`Context` does not already exist, create it.\n        :param str name:\n            If the :class:`Context` does not already exist, set its name.\n\n        :returns:\n            :class:`Context`, or return :data:`None` if `create` is\n            :data:`False` and no :class:`Context` previously existed.\n        \"\"\"\n        context = self._context_by_id.get(context_id)\n        if context:\n            return context\n\n        if create and via_id is not None:\n            via = self.context_by_id(via_id)\n        else:\n            via = None\n\n        self._write_lock.acquire()\n        try:\n            context = self._context_by_id.get(context_id)\n            if create and not context:\n                context = self.context_class(self, context_id, name=name)\n                context.via = via\n                self._context_by_id[context_id] = context\n        finally:\n            self._write_lock.release()\n\n        return context\n\n    def register(self, context, stream):\n        \"\"\"\n        Register a newly constructed context and its associated stream, and add\n        the stream's receive side to the I/O multiplexer. This method remains\n        public while the design has not yet settled.\n        \"\"\"\n        _v and LOG.debug('%s: registering %r to stream %r',\n                         self, context, stream)\n        self._write_lock.acquire()\n        try:\n            self._stream_by_id[context.context_id] = stream\n            self._context_by_id[context.context_id] = context\n        finally:\n            self._write_lock.release()\n\n        self.broker.start_receive(stream)\n        listen(stream, 'disconnect', lambda: self._on_stream_disconnect(stream))\n\n    def stream_by_id(self, dst_id):\n        \"\"\"\n        Return the :class:`Stream` that should be used to communicate with\n        `dst_id`. If a specific route for `dst_id` is not known, a reference to\n        the parent context's stream is returned. If the parent is disconnected,\n        or when running in the master context, return :data:`None` instead.\n\n        This can be used from any thread, but its output is only meaningful\n        from the context of the :class:`Broker` thread, as disconnection or\n        replacement could happen in parallel on the broker thread at any\n        moment. \n        \"\"\"\n        return (\n            self._stream_by_id.get(dst_id) or\n            self._stream_by_id.get(mitogen.parent_id)\n        )\n\n    def del_handler(self, handle):\n        \"\"\"\n        Remove the handle registered for `handle`\n\n        :raises KeyError:\n            The handle wasn't registered.\n        \"\"\"\n        _, _, _, respondent = self._handle_map.pop(handle)\n        if respondent:\n            self._handles_by_respondent[respondent].discard(handle)\n\n    def add_handler(self, fn, handle=None, persist=True,\n                    policy=None, respondent=None,\n                    overwrite=False):\n        \"\"\"\n        Invoke `fn(msg)` on the :class:`Broker` thread for each Message sent to\n        `handle` from this context. Unregister after one invocation if\n        `persist` is :data:`False`. If `handle` is :data:`None`, a new handle\n        is allocated and returned.\n\n        :param int handle:\n            If not :data:`None`, an explicit handle to register, usually one of\n            the ``mitogen.core.*`` constants. If unspecified, a new unused\n            handle will be allocated.\n\n        :param bool persist:\n            If :data:`False`, the handler will be unregistered after a single\n            message has been received.\n\n        :param mitogen.core.Context respondent:\n            Context that messages to this handle are expected to be sent from.\n            If specified, arranges for a dead message to be delivered to `fn`\n            when disconnection of the context is detected.\n\n            In future `respondent` will likely also be used to prevent other\n            contexts from sending messages to the handle.\n\n        :param function policy:\n            Function invoked as `policy(msg, stream)` where `msg` is a\n            :class:`mitogen.core.Message` about to be delivered, and `stream`\n            is the :class:`mitogen.core.Stream` on which it was received. The\n            function must return :data:`True`, otherwise an error is logged and\n            delivery is refused.\n\n            Two built-in policy functions exist:\n\n            * :func:`has_parent_authority`: requires the message arrived from a\n              parent context, or a context acting with a parent context's\n              authority (``auth_id``).\n\n            * :func:`mitogen.parent.is_immediate_child`: requires the\n              message arrived from an immediately connected child, for use in\n              messaging patterns where either something becomes buggy or\n              insecure by permitting indirect upstream communication.\n\n            In case of refusal, and the message's ``reply_to`` field is\n            nonzero, a :class:`mitogen.core.CallError` is delivered to the\n            sender indicating refusal occurred.\n\n        :param bool overwrite:\n            If :data:`True`, allow existing handles to be silently overwritten.\n\n        :return:\n            `handle`, or if `handle` was :data:`None`, the newly allocated\n            handle.\n        :raises Error:\n            Attemp to register handle that was already registered.\n        \"\"\"\n        handle = handle or next(self._last_handle)\n        _vv and IOLOG.debug('%r.add_handler(%r, %r, %r)', self, fn, handle, persist)\n        if handle in self._handle_map and not overwrite:\n            raise Error(self.duplicate_handle_msg)\n\n        self._handle_map[handle] = persist, fn, policy, respondent\n        if respondent:\n            if respondent not in self._handles_by_respondent:\n                self._handles_by_respondent[respondent] = set()\n                listen(respondent, 'disconnect',\n                       lambda: self._on_respondent_disconnect(respondent))\n            self._handles_by_respondent[respondent].add(handle)\n\n        return handle\n\n    def _on_respondent_disconnect(self, context):\n        for handle in self._handles_by_respondent.pop(context, ()):\n            _, fn, _, _  = self._handle_map[handle]\n            fn(Message.dead(self.respondent_disconnect_msg))\n            del self._handle_map[handle]\n\n    def _maybe_send_dead(self, msg, reason, *args):\n        if args:\n            reason %= args\n        LOG.debug('%r: %r is dead: %r', self, msg, reason)\n        if msg.reply_to and not msg.is_dead:\n            msg.reply(Message.dead(reason=reason), router=self)\n\n    def _invoke(self, msg, stream):\n        # IOLOG.debug('%r._invoke(%r)', self, msg)\n        try:\n            persist, fn, policy, respondent = self._handle_map[msg.handle]\n        except KeyError:\n            self._maybe_send_dead(msg, reason=self.invalid_handle_msg)\n            return\n\n        if respondent and not (msg.is_dead or\n                               msg.src_id == respondent.context_id):\n            self._maybe_send_dead(msg, 'reply from unexpected context')\n            return\n\n        if policy and not policy(msg, stream):\n            self._maybe_send_dead(msg, self.refused_msg)\n            return\n\n        if not persist:\n            self.del_handler(msg.handle)\n\n        try:\n            fn(msg)\n        except Exception:\n            LOG.exception('%r._invoke(%r): %r crashed', self, msg, fn)\n\n    def _async_route(self, msg, in_stream=None):\n        \"\"\"\n        Arrange for `msg` to be forwarded towards its destination. If its\n        destination is the local context, then arrange for it to be dispatched\n        using the local handlers.\n\n        This is a lower overhead version of :meth:`route` that may only be\n        called from the :class:`Broker` thread.\n\n        :param Stream in_stream:\n            If not :data:`None`, the stream the message arrived on. Used for\n            performing source route verification, to ensure sensitive messages\n            such as ``CALL_FUNCTION`` arrive only from trusted contexts.\n        \"\"\"\n        _vv and IOLOG.debug('%r._async_route(%r, %r)', self, msg, in_stream)\n\n        if len(msg.data) > self.max_message_size:\n            self._maybe_send_dead(msg, self.too_large_msg % (\n                self.max_message_size,\n            ))\n            return\n\n        # Perform source verification.\n        if in_stream:\n            parent = self._stream_by_id.get(mitogen.parent_id)\n            expect = self._stream_by_id.get(msg.auth_id, parent)\n            if in_stream != expect:\n                LOG.error('%r: bad auth_id: got %r via %r, not %r: %r',\n                          self, msg.auth_id, in_stream, expect, msg)\n                return\n\n            if msg.src_id != msg.auth_id:\n                expect = self._stream_by_id.get(msg.src_id, parent)\n                if in_stream != expect:\n                    LOG.error('%r: bad src_id: got %r via %r, not %r: %r',\n                              self, msg.src_id, in_stream, expect, msg)\n                    return\n\n            if in_stream.protocol.auth_id is not None:\n                msg.auth_id = in_stream.protocol.auth_id\n\n            # Maintain a set of IDs the source ever communicated with.\n            in_stream.protocol.egress_ids.add(msg.dst_id)\n\n        if msg.dst_id == mitogen.context_id:\n            return self._invoke(msg, in_stream)\n\n        out_stream = self._stream_by_id.get(msg.dst_id)\n        if out_stream is None:\n            out_stream = self._stream_by_id.get(mitogen.parent_id)\n\n        if out_stream is None:\n            self._maybe_send_dead(msg, self.no_route_msg,\n                                  msg.dst_id, mitogen.context_id)\n            return\n\n        if in_stream and self.unidirectional and not \\\n                (in_stream.protocol.is_privileged or\n                 out_stream.protocol.is_privileged):\n            self._maybe_send_dead(msg, self.unidirectional_msg,\n                in_stream.protocol.remote_id, out_stream.protocol.remote_id)\n            return\n\n        out_stream.protocol._send(msg)\n\n    def route(self, msg):\n        \"\"\"\n        Arrange for the :class:`Message` `msg` to be delivered to its\n        destination using any relevant downstream context, or if none is found,\n        by forwarding the message upstream towards the master context. If `msg`\n        is destined for the local context, it is dispatched using the handles\n        registered with :meth:`add_handler`.\n\n        This may be called from any thread.\n        \"\"\"\n        self.broker.defer(self._async_route, msg)\n\n\nclass NullTimerList(object):\n    def get_timeout(self):\n        return None\n\n\nclass Broker(object):\n    \"\"\"\n    Responsible for handling I/O multiplexing in a private thread.\n\n    **Note:** This somewhat limited core version is used by children. The\n    master subclass is documented below.\n    \"\"\"\n    poller_class = Poller\n    _waker = None\n    _thread = None\n\n    # :func:`mitogen.parent._upgrade_broker` replaces this with\n    # :class:`mitogen.parent.TimerList` during upgrade.\n    timers = NullTimerList()\n\n    #: Seconds grace to allow :class:`streams <Stream>` to shutdown gracefully\n    #: before force-disconnecting them during :meth:`shutdown`.\n    shutdown_timeout = 3.0\n\n    def __init__(self, poller_class=None, activate_compat=True):\n        self._alive = True\n        self._exitted = False\n        self._waker = Waker.build_stream(self)\n        #: Arrange for `func(\\*args, \\**kwargs)` to be executed on the broker\n        #: thread, or immediately if the current thread is the broker thread.\n        #: Safe to call from any thread.\n        self.defer = self._waker.protocol.defer\n        self.poller = self.poller_class()\n        self.poller.start_receive(\n            self._waker.receive_side.fd,\n            (self._waker.receive_side, self._waker.on_receive)\n        )\n        self._thread = threading.Thread(\n            target=self._broker_main,\n            name='mitogen.broker'\n        )\n        self._thread.start()\n        if activate_compat:\n            self._py24_25_compat()\n\n    def _py24_25_compat(self):\n        \"\"\"\n        Python 2.4/2.5 have grave difficulties with threads/fork. We\n        mandatorily quiesce all running threads during fork using a\n        monkey-patch there.\n        \"\"\"\n        if sys.version_info < (2, 6):\n            # import_module() is used to avoid dep scanner.\n            os_fork = import_module('mitogen.os_fork')\n            os_fork._notice_broker_or_pool(self)\n\n    def start_receive(self, stream):\n        \"\"\"\n        Mark the :attr:`receive_side <Stream.receive_side>` on `stream` as\n        ready for reading. Safe to call from any thread. When the associated\n        file descriptor becomes ready for reading,\n        :meth:`BasicStream.on_receive` will be called.\n        \"\"\"\n        _vv and IOLOG.debug('%r.start_receive(%r)', self, stream)\n        side = stream.receive_side\n        assert side and not side.closed\n        self.defer(self.poller.start_receive,\n                   side.fd, (side, stream.on_receive))\n\n    def stop_receive(self, stream):\n        \"\"\"\n        Mark the :attr:`receive_side <Stream.receive_side>` on `stream` as not\n        ready for reading. Safe to call from any thread.\n        \"\"\"\n        _vv and IOLOG.debug('%r.stop_receive(%r)', self, stream)\n        self.defer(self.poller.stop_receive, stream.receive_side.fd)\n\n    def _start_transmit(self, stream):\n        \"\"\"\n        Mark the :attr:`transmit_side <Stream.transmit_side>` on `stream` as\n        ready for writing. Must only be called from the Broker thread. When the\n        associated file descriptor becomes ready for writing,\n        :meth:`BasicStream.on_transmit` will be called.\n        \"\"\"\n        _vv and IOLOG.debug('%r._start_transmit(%r)', self, stream)\n        side = stream.transmit_side\n        assert side and not side.closed\n        self.poller.start_transmit(side.fd, (side, stream.on_transmit))\n\n    def _stop_transmit(self, stream):\n        \"\"\"\n        Mark the :attr:`transmit_side <Stream.receive_side>` on `stream` as not\n        ready for writing.\n        \"\"\"\n        _vv and IOLOG.debug('%r._stop_transmit(%r)', self, stream)\n        self.poller.stop_transmit(stream.transmit_side.fd)\n\n    def keep_alive(self):\n        \"\"\"\n        Return :data:`True` if any reader's :attr:`Side.keep_alive` attribute\n        is :data:`True`, or any :class:`Context` is still registered that is\n        not the master. Used to delay shutdown while some important work is in\n        progress (e.g. log draining).\n        \"\"\"\n        it = (side.keep_alive for (_, (side, _)) in self.poller.readers)\n        return sum(it, 0) > 0 or self.timers.get_timeout() is not None\n\n    def defer_sync(self, func):\n        \"\"\"\n        Arrange for `func()` to execute on :class:`Broker` thread, blocking the\n        current thread until a result or exception is available.\n\n        :returns:\n            Return value of `func()`.\n        \"\"\"\n        latch = Latch()\n        def wrapper():\n            try:\n                latch.put(func())\n            except Exception:\n                latch.put(sys.exc_info()[1])\n        self.defer(wrapper)\n        res = latch.get()\n        if isinstance(res, Exception):\n            raise res\n        return res\n\n    def _call(self, stream, func):\n        \"\"\"\n        Call `func(self)`, catching any exception that might occur, logging it,\n        and force-disconnecting the related `stream`.\n        \"\"\"\n        try:\n            func(self)\n        except Exception:\n            LOG.exception('%r crashed', stream)\n            stream.on_disconnect(self)\n\n    def _loop_once(self, timeout=None):\n        \"\"\"\n        Execute a single :class:`Poller` wait, dispatching any IO events that\n        caused the wait to complete.\n\n        :param float timeout:\n            If not :data:`None`, maximum time in seconds to wait for events.\n        \"\"\"\n        _vv and IOLOG.debug('%r._loop_once(%r, %r)',\n                            self, timeout, self.poller)\n\n        timer_to = self.timers.get_timeout()\n        if timeout is None:\n            timeout = timer_to\n        elif timer_to is not None and timer_to < timeout:\n            timeout = timer_to\n\n        #IOLOG.debug('readers =\\n%s', pformat(self.poller.readers))\n        #IOLOG.debug('writers =\\n%s', pformat(self.poller.writers))\n        for side, func in self.poller.poll(timeout):\n            self._call(side.stream, func)\n        if timer_to is not None:\n            self.timers.expire()\n\n    def _broker_exit(self):\n        \"\"\"\n        Forcefully call :meth:`Stream.on_disconnect` on any streams that failed\n        to shut down gracefully, then discard the :class:`Poller`.\n        \"\"\"\n        for _, (side, _) in self.poller.readers + self.poller.writers:\n            LOG.debug('%r: force disconnecting %r', self, side)\n            side.stream.on_disconnect(self)\n\n        self.poller.close()\n\n    def _broker_shutdown(self):\n        \"\"\"\n        Invoke :meth:`Stream.on_shutdown` for every active stream, then allow\n        up to :attr:`shutdown_timeout` seconds for the streams to unregister\n        themselves, logging an error if any did not unregister during the grace\n        period.\n        \"\"\"\n        for _, (side, _) in self.poller.readers + self.poller.writers:\n            self._call(side.stream, side.stream.on_shutdown)\n\n        deadline = time.time() + self.shutdown_timeout\n        while self.keep_alive() and time.time() < deadline:\n            self._loop_once(max(0, deadline - time.time()))\n\n        if self.keep_alive():\n            LOG.error('%r: pending work still existed %d seconds after '\n                      'shutdown began. This may be due to a timer that is yet '\n                      'to expire, or a child connection that did not fully '\n                      'shut down.', self, self.shutdown_timeout)\n\n    def _do_broker_main(self):\n        \"\"\"\n        Broker thread main function. Dispatches IO events until\n        :meth:`shutdown` is called.\n        \"\"\"\n        # For Python 2.4, no way to retrieve ident except on thread.\n        self._waker.protocol.broker_ident = thread.get_ident()\n        try:\n            while self._alive:\n                self._loop_once()\n\n            fire(self, 'shutdown')\n            self._broker_shutdown()\n        except Exception:\n            e = sys.exc_info()[1]\n            LOG.exception('broker crashed')\n            syslog.syslog(syslog.LOG_ERR, 'broker crashed: %s' % (e,))\n            syslog.closelog()  # prevent test 'fd leak'.\n\n        self._alive = False  # Ensure _alive is consistent on crash.\n        self._exitted = True\n        self._broker_exit()\n\n    def _broker_main(self):\n        try:\n            _profile_hook('mitogen.broker', self._do_broker_main)\n        finally:\n            # 'finally' to ensure _on_broker_exit() can always SIGTERM.\n            fire(self, 'exit')\n\n    def shutdown(self):\n        \"\"\"\n        Request broker gracefully disconnect streams and stop. Safe to call\n        from any thread.\n        \"\"\"\n        _v and LOG.debug('%r: shutting down', self)\n        def _shutdown():\n            self._alive = False\n        if self._alive and not self._exitted:\n            self.defer(_shutdown)\n\n    def join(self):\n        \"\"\"\n        Wait for the broker to stop, expected to be called after\n        :meth:`shutdown`.\n        \"\"\"\n        self._thread.join()\n\n    def __repr__(self):\n        return 'Broker(%04x)' % (id(self) & 0xffff,)\n\n\nclass Dispatcher(object):\n    \"\"\"\n    Implementation of the :data:`CALL_FUNCTION` handle for a child context.\n    Listens on the child's main thread for messages sent by\n    :class:`mitogen.parent.CallChain` and dispatches the function calls they\n    describe.\n\n    If a :class:`mitogen.parent.CallChain` sending a message is in pipelined\n    mode, any exception that occurs is recorded, and causes all subsequent\n    calls with the same `chain_id` to fail with the same exception.\n    \"\"\"\n    def __repr__(self):\n        return 'Dispatcher'\n\n    def __init__(self, econtext):\n        self.econtext = econtext\n        #: Chain ID -> CallError if prior call failed.\n        self._error_by_chain_id = {}\n        self.recv = Receiver(\n            router=econtext.router,\n            handle=CALL_FUNCTION,\n            policy=has_parent_authority,\n        )\n        #: The :data:`CALL_SERVICE` :class:`Receiver` that will eventually be\n        #: reused by :class:`mitogen.service.Pool`, should it ever be loaded.\n        #: This is necessary for race-free reception of all service requests\n        #: delivered regardless of whether the stub or real service pool are\n        #: loaded. See #547 for related sorrows.\n        Dispatcher._service_recv = Receiver(\n            router=econtext.router,\n            handle=CALL_SERVICE,\n            policy=has_parent_authority,\n        )\n        self._service_recv.notify = self._on_call_service\n        listen(econtext.broker, 'shutdown', self.recv.close)\n\n    @classmethod\n    @takes_econtext\n    def forget_chain(cls, chain_id, econtext):\n        econtext.dispatcher._error_by_chain_id.pop(chain_id, None)\n\n    def _parse_request(self, msg):\n        data = msg.unpickle(throw=False)\n        _v and LOG.debug('%r: dispatching %r', self, data)\n\n        chain_id, modname, klass, func, args, kwargs = data\n        obj = import_module(modname)\n        if klass:\n            obj = getattr(obj, klass)\n        fn = getattr(obj, func)\n        if getattr(fn, 'mitogen_takes_econtext', None):\n            kwargs.setdefault('econtext', self.econtext)\n        if getattr(fn, 'mitogen_takes_router', None):\n            kwargs.setdefault('router', self.econtext.router)\n\n        return chain_id, fn, args, kwargs\n\n    def _dispatch_one(self, msg):\n        try:\n            chain_id, fn, args, kwargs = self._parse_request(msg)\n        except Exception:\n            return None, CallError(sys.exc_info()[1])\n\n        if chain_id in self._error_by_chain_id:\n            return chain_id, self._error_by_chain_id[chain_id]\n\n        try:\n            return chain_id, fn(*args, **kwargs)\n        except Exception:\n            e = CallError(sys.exc_info()[1])\n            if chain_id is not None:\n                self._error_by_chain_id[chain_id] = e\n            return chain_id, e\n\n    def _on_call_service(self, recv):\n        \"\"\"\n        Notifier for the :data:`CALL_SERVICE` receiver. This is called on the\n        :class:`Broker` thread for any service messages arriving at this\n        context, for as long as no real service pool implementation is loaded.\n\n        In order to safely bootstrap the service pool implementation a sentinel\n        message is enqueued on the :data:`CALL_FUNCTION` receiver in order to\n        wake the main thread, where the importer can run without any\n        possibility of suffering deadlock due to concurrent uses of the\n        importer.\n\n        Should the main thread be blocked indefinitely, preventing the import\n        from ever running, if it is blocked waiting on a service call, then it\n        means :mod:`mitogen.service` has already been imported and\n        :func:`mitogen.service.get_or_create_pool` has already run, meaning the\n        service pool is already active and the duplicate initialization was not\n        needed anyway.\n\n        #547: This trickery is needed to avoid the alternate option of spinning\n        a temporary thread to import the service pool, which could deadlock if\n        a custom import hook executing on the main thread (under the importer\n        lock) would block waiting for some data that was in turn received by a\n        service. Main thread import lock can't be released until service is\n        running, service cannot satisfy request until import lock is released.\n        \"\"\"\n        self.recv._on_receive(Message(handle=STUB_CALL_SERVICE))\n\n    def _init_service_pool(self):\n        import mitogen.service\n        mitogen.service.get_or_create_pool(router=self.econtext.router)\n\n    def _dispatch_calls(self):\n        for msg in self.recv:\n            if msg.handle == STUB_CALL_SERVICE:\n                if msg.src_id == mitogen.context_id:\n                    self._init_service_pool()\n                continue\n\n            chain_id, ret = self._dispatch_one(msg)\n            _v and LOG.debug('%r: %r -> %r', self, msg, ret)\n            if msg.reply_to:\n                msg.reply(ret)\n            elif isinstance(ret, CallError) and chain_id is None:\n                LOG.error('No-reply function call failed: %s', ret)\n\n    def run(self):\n        if self.econtext.config.get('on_start'):\n            self.econtext.config['on_start'](self.econtext)\n\n        _profile_hook('mitogen.child_main', self._dispatch_calls)\n\n\nclass ExternalContext(object):\n    \"\"\"\n    External context implementation.\n\n    This class contains the main program implementation for new children. It is\n    responsible for setting up everything about the process environment, import\n    hooks, standard IO redirection, logging, configuring a :class:`Router` and\n    :class:`Broker`, and finally arranging for :class:`Dispatcher` to take over\n    the main thread after initialization is complete.\n\n    .. attribute:: broker\n\n        The :class:`mitogen.core.Broker` instance.\n\n    .. attribute:: context\n\n        The :class:`mitogen.core.Context` instance.\n\n    .. attribute:: channel\n\n        The :class:`mitogen.core.Channel` over which :data:`CALL_FUNCTION`\n        requests are received.\n\n    .. attribute:: importer\n\n        The :class:`mitogen.core.Importer` instance.\n\n    .. attribute:: stdout_log\n\n        The :class:`IoLogger` connected to :data:`sys.stdout`.\n\n    .. attribute:: stderr_log\n\n        The :class:`IoLogger` connected to :data:`sys.stderr`.\n    \"\"\"\n    detached = False\n\n    def __init__(self, config):\n        self.config = config\n\n    def _on_broker_exit(self):\n        if not self.config['profiling']:\n            os.kill(os.getpid(), signal.SIGTERM)\n\n    def _on_shutdown_msg(self, msg):\n        if not msg.is_dead:\n            _v and LOG.debug('shutdown request from context %d', msg.src_id)\n            self.broker.shutdown()\n\n    def _on_parent_disconnect(self):\n        if self.detached:\n            mitogen.parent_ids = []\n            mitogen.parent_id = None\n            LOG.info('Detachment complete')\n        else:\n            _v and LOG.debug('parent stream is gone, dying.')\n            self.broker.shutdown()\n\n    def detach(self):\n        self.detached = True\n        stream = self.router.stream_by_id(mitogen.parent_id)\n        if stream:  # not double-detach()'d\n            os.setsid()\n            self.parent.send_await(Message(handle=DETACHING))\n            LOG.info('Detaching from %r; parent is %s', stream, self.parent)\n            for x in range(20):\n                pending = self.broker.defer_sync(stream.protocol.pending_bytes)\n                if not pending:\n                    break\n                time.sleep(0.05)\n            if pending:\n                LOG.error('Stream had %d bytes after 2000ms', pending)\n            self.broker.defer(stream.on_disconnect, self.broker)\n\n    def _setup_master(self):\n        Router.max_message_size = self.config['max_message_size']\n        if self.config['profiling']:\n            enable_profiling()\n        self.broker = Broker(activate_compat=False)\n        self.router = Router(self.broker)\n        self.router.debug = self.config.get('debug', False)\n        self.router.unidirectional = self.config['unidirectional']\n        self.router.add_handler(\n            fn=self._on_shutdown_msg,\n            handle=SHUTDOWN,\n            policy=has_parent_authority,\n        )\n        self.master = Context(self.router, 0, 'master')\n        parent_id = self.config['parent_ids'][0]\n        if parent_id == 0:\n            self.parent = self.master\n        else:\n            self.parent = Context(self.router, parent_id, 'parent')\n\n        in_fd = self.config.get('in_fd', 100)\n        in_fp = os.fdopen(os.dup(in_fd), 'rb', 0)\n        os.close(in_fd)\n\n        out_fp = os.fdopen(os.dup(self.config.get('out_fd', 1)), 'wb', 0)\n        self.stream = MitogenProtocol.build_stream(self.router, parent_id)\n        self.stream.accept(in_fp, out_fp)\n        self.stream.name = 'parent'\n        self.stream.receive_side.keep_alive = False\n\n        listen(self.stream, 'disconnect', self._on_parent_disconnect)\n        listen(self.broker, 'exit', self._on_broker_exit)\n\n    def _reap_first_stage(self):\n        try:\n            os.wait()  # Reap first stage.\n        except OSError:\n            pass  # No first stage exists (e.g. fakessh)\n\n    def _setup_logging(self):\n        self.log_handler = LogHandler(self.master)\n        root = logging.getLogger()\n        root.setLevel(self.config['log_level'])\n        root.handlers = [self.log_handler]\n        if self.config['debug']:\n            enable_debug_logging()\n\n    def _setup_importer(self):\n        importer = self.config.get('importer')\n        if importer:\n            importer._install_handler(self.router)\n            importer._context = self.parent\n        else:\n            core_src_fd = self.config.get('core_src_fd', 101)\n            if core_src_fd:\n                fp = os.fdopen(core_src_fd, 'rb', 1)\n                try:\n                    core_src = fp.read()\n                    # Strip \"ExternalContext.main()\" call from last line.\n                    core_src = b('\\n').join(core_src.splitlines()[:-1])\n                finally:\n                    fp.close()\n            else:\n                core_src = None\n\n            importer = Importer(\n                self.router,\n                self.parent,\n                core_src,\n                self.config.get('whitelist', ()),\n                self.config.get('blacklist', ()),\n            )\n\n        self.importer = importer\n        self.router.importer = importer\n        sys.meta_path.insert(0, self.importer)\n\n    def _setup_package(self):\n        global mitogen\n        mitogen = imp.new_module('mitogen')\n        mitogen.__package__ = 'mitogen'\n        mitogen.__path__ = []\n        mitogen.__loader__ = self.importer\n        mitogen.main = lambda *args, **kwargs: (lambda func: None)\n        mitogen.core = sys.modules['__main__']\n        mitogen.core.__file__ = 'x/mitogen/core.py'  # For inspect.getsource()\n        mitogen.core.__loader__ = self.importer\n        sys.modules['mitogen'] = mitogen\n        sys.modules['mitogen.core'] = mitogen.core\n        del sys.modules['__main__']\n\n    def _setup_globals(self):\n        mitogen.is_master = False\n        mitogen.__version__ = self.config['version']\n        mitogen.context_id = self.config['context_id']\n        mitogen.parent_ids = self.config['parent_ids'][:]\n        mitogen.parent_id = mitogen.parent_ids[0]\n\n    def _nullify_stdio(self):\n        \"\"\"\n        Open /dev/null to replace stdio temporarily. In case of odd startup,\n        assume we may be allocated a standard handle.\n        \"\"\"\n        for stdfd, mode in ((0, os.O_RDONLY), (1, os.O_RDWR), (2, os.O_RDWR)):\n            fd = os.open('/dev/null', mode)\n            if fd != stdfd:\n                os.dup2(fd, stdfd)\n                os.close(fd)\n\n    def _preserve_tty_fp(self):\n        \"\"\"\n        #481: when stderr is a TTY due to being started via tty_create_child()\n        or hybrid_tty_create_child(), and some privilege escalation tool like\n        prehistoric versions of sudo exec this process over the top of itself,\n        there is nothing left to keep the slave PTY open after we replace our\n        stdio. Therefore if stderr is a TTY, keep around a permanent dup() to\n        avoid receiving SIGHUP.\n        \"\"\"\n        try:\n            if os.isatty(2):\n                self.reserve_tty_fp = os.fdopen(os.dup(2), 'r+b', 0)\n                set_cloexec(self.reserve_tty_fp.fileno())\n        except OSError:\n            pass\n\n    def _setup_stdio(self):\n        self._preserve_tty_fp()\n        # When sys.stdout was opened by the runtime, overwriting it will not\n        # close FD 1. However when forking from a child that previously used\n        # fdopen(), overwriting it /will/ close FD 1. So we must swallow the\n        # close before IoLogger overwrites FD 1, otherwise its new FD 1 will be\n        # clobbered. Additionally, stdout must be replaced with /dev/null prior\n        # to stdout.close(), since if block buffering was active in the parent,\n        # any pre-fork buffered data will be flushed on close(), corrupting the\n        # connection to the parent.\n        self._nullify_stdio()\n        sys.stdout.close()\n        self._nullify_stdio()\n\n        self.loggers = []\n        for name, fd in (('stdout', 1), ('stderr', 2)):\n            log = IoLoggerProtocol.build_stream(name, fd)\n            self.broker.start_receive(log)\n            self.loggers.append(log)\n\n        # Reopen with line buffering.\n        sys.stdout = os.fdopen(1, 'w', 1)\n\n    def main(self):\n        self._setup_master()\n        try:\n            try:\n                self._setup_logging()\n                self._setup_importer()\n                self._reap_first_stage()\n                if self.config.get('setup_package', True):\n                    self._setup_package()\n                self._setup_globals()\n                if self.config.get('setup_stdio', True):\n                    self._setup_stdio()\n\n                self.dispatcher = Dispatcher(self)\n                self.router.register(self.parent, self.stream)\n                self.router._setup_logging()\n\n                sys.executable = os.environ.pop('ARGV0', sys.executable)\n                _v and LOG.debug('Parent is context %r (%s); my ID is %r',\n                                 self.parent.context_id, self.parent.name,\n                                 mitogen.context_id)\n                _v and LOG.debug('pid:%r ppid:%r uid:%r/%r, gid:%r/%r host:%r',\n                                 os.getpid(), os.getppid(), os.geteuid(),\n                                 os.getuid(), os.getegid(), os.getgid(),\n                                 socket.gethostname())\n                _v and LOG.debug('Recovered sys.executable: %r', sys.executable)\n\n                if self.config.get('send_ec2', True):\n                    self.stream.transmit_side.write(b('MITO002\\n'))\n                self.broker._py24_25_compat()\n                self.log_handler.uncork()\n                self.dispatcher.run()\n                _v and LOG.debug('ExternalContext.main() normal exit')\n            except KeyboardInterrupt:\n                LOG.debug('KeyboardInterrupt received, exiting gracefully.')\n            except BaseException:\n                LOG.exception('ExternalContext.main() crashed')\n                raise\n        finally:\n            self.broker.shutdown()\n            self.broker.join()\n", "import sys\nimport time\nimport zlib\n\nimport unittest2\n\nimport testlib\nimport mitogen.core\nimport mitogen.master\nimport mitogen.parent\nimport mitogen.utils\n\ntry:\n    import Queue\nexcept ImportError:\n    import queue as Queue\n\n\ndef ping():\n    return True\n\n\n@mitogen.core.takes_router\ndef ping_context(other, router):\n    other = mitogen.parent.Context(router, other.context_id)\n    other.call(ping)\n\n\n@mitogen.core.takes_router\ndef return_router_max_message_size(router):\n    return router.max_message_size\n\n\ndef send_n_sized_reply(sender, n):\n    sender.send(' ' * n)\n    return 123\n\n\nclass SourceVerifyTest(testlib.RouterMixin, testlib.TestCase):\n    def setUp(self):\n        super(SourceVerifyTest, self).setUp()\n        # Create some children, ping them, and store what their messages look\n        # like so we can mess with them later.\n        self.child1 = self.router.local()\n        self.child1_msg = self.child1.call_async(ping).get()\n        self.child1_stream = self.router._stream_by_id[self.child1.context_id]\n\n        self.child2 = self.router.local()\n        self.child2_msg = self.child2.call_async(ping).get()\n        self.child2_stream = self.router._stream_by_id[self.child2.context_id]\n\n    def test_bad_auth_id(self):\n        # Deliver a message locally from child2, but using child1's stream.\n        log = testlib.LogCapturer()\n        log.start()\n\n        # Used to ensure the message was dropped rather than routed after the\n        # error is logged.\n        recv = mitogen.core.Receiver(self.router)\n        self.child2_msg.handle = recv.handle\n\n        self.broker.defer(self.router._async_route,\n                          self.child2_msg,\n                          in_stream=self.child1_stream)\n\n        # Wait for IO loop to finish everything above.\n        self.sync_with_broker()\n\n        # Ensure message wasn't forwarded.\n        self.assertTrue(recv.empty())\n\n        # Ensure error was logged.\n        expect = 'bad auth_id: got %r via' % (self.child2_msg.auth_id,)\n        self.assertTrue(expect in log.stop())\n\n    def test_bad_src_id(self):\n        # Deliver a message locally from child2 with the correct auth_id, but\n        # the wrong src_id.\n        log = testlib.LogCapturer()\n        log.start()\n\n        # Used to ensure the message was dropped rather than routed after the\n        # error is logged.\n        recv = mitogen.core.Receiver(self.router)\n        self.child2_msg.handle = recv.handle\n        self.child2_msg.src_id = self.child1.context_id\n\n        self.broker.defer(self.router._async_route,\n                          self.child2_msg,\n                          self.child2_stream)\n\n        # Wait for IO loop to finish everything above.\n        self.sync_with_broker()\n\n        # Ensure message wasn't forwarded.\n        self.assertTrue(recv.empty())\n\n        # Ensure error was lgoged.\n        expect = 'bad src_id: got %d via' % (self.child1_msg.src_id,)\n        self.assertTrue(expect in log.stop())\n\n\nclass PolicyTest(testlib.RouterMixin, testlib.TestCase):\n    def test_allow_any(self):\n        # This guy gets everything.\n        recv = mitogen.core.Receiver(self.router)\n        recv.to_sender().send(123)\n        self.sync_with_broker()\n        self.assertFalse(recv.empty())\n        self.assertEquals(123, recv.get().unpickle())\n\n    def test_refuse_all(self):\n        # Deliver a message locally from child2 with the correct auth_id, but\n        # the wrong src_id.\n        log = testlib.LogCapturer()\n        log.start()\n\n        # This guy never gets anything.\n        recv = mitogen.core.Receiver(\n            router=self.router,\n            policy=(lambda msg, stream: False),\n        )\n\n        # This guy becomes the reply_to of our refused message.\n        reply_target = mitogen.core.Receiver(self.router)\n\n        # Send the message.\n        self.router.route(\n            mitogen.core.Message(\n                dst_id=mitogen.context_id,\n                handle=recv.handle,\n                reply_to=reply_target.handle,\n            )\n        )\n\n        # Wait for IO loop.\n        self.sync_with_broker()\n\n        # Verify log.\n        self.assertTrue(self.router.refused_msg in log.stop())\n\n        # Verify message was not delivered.\n        self.assertTrue(recv.empty())\n\n        # Verify CallError received by reply_to target.\n        e = self.assertRaises(mitogen.core.ChannelError,\n                              lambda: reply_target.get().unpickle())\n        self.assertEquals(e.args[0], self.router.refused_msg)\n\n\nclass CrashTest(testlib.BrokerMixin, testlib.TestCase):\n    # This is testing both Broker's ability to crash nicely, and Router's\n    # ability to respond to the crash event.\n    klass = mitogen.master.Router\n\n    def _naughty(self):\n        raise ValueError('eek')\n\n    def test_shutdown(self):\n        router = self.klass(self.broker)\n\n        sem = mitogen.core.Latch()\n        router.add_handler(sem.put)\n\n        log = testlib.LogCapturer('mitogen')\n        log.start()\n\n        # Force a crash and ensure it wakes up.\n        self.broker._loop_once = self._naughty\n        self.broker.defer(lambda: None)\n\n        # sem should have received dead message.\n        self.assertTrue(sem.get().is_dead)\n\n        # Ensure it was logged.\n        expect = 'broker crashed'\n        self.assertTrue(expect in log.stop())\n\n        self.broker.join()\n\n\nclass AddHandlerTest(testlib.TestCase):\n    klass = mitogen.master.Router\n\n    def test_dead_message_sent_at_shutdown(self):\n        router = self.klass()\n        queue = Queue.Queue()\n        handle = router.add_handler(queue.put)\n        router.broker.shutdown()\n        self.assertTrue(queue.get(timeout=5).is_dead)\n        router.broker.join()\n\n    def test_cannot_double_register(self):\n        router = self.klass()\n        try:\n            router.add_handler((lambda: None), handle=1234)\n            e = self.assertRaises(mitogen.core.Error,\n                lambda: router.add_handler((lambda: None), handle=1234))\n            self.assertEquals(router.duplicate_handle_msg, e.args[0])\n            router.del_handler(1234)\n        finally:\n            router.broker.shutdown()\n            router.broker.join()\n\n    def test_can_reregister(self):\n        router = self.klass()\n        try:\n            router.add_handler((lambda: None), handle=1234)\n            router.del_handler(1234)\n            router.add_handler((lambda: None), handle=1234)\n            router.del_handler(1234)\n        finally:\n            router.broker.shutdown()\n            router.broker.join()\n\n\nclass MyselfTest(testlib.RouterMixin, testlib.TestCase):\n    def test_myself(self):\n        myself = self.router.myself()\n        self.assertEquals(myself.context_id, mitogen.context_id)\n        # TODO: context should know its own name too.\n        self.assertEquals(myself.name, 'self')\n\n\nclass MessageSizeTest(testlib.BrokerMixin, testlib.TestCase):\n    klass = mitogen.master.Router\n\n    def test_local_exceeded(self):\n        router = self.klass(broker=self.broker, max_message_size=4096)\n\n        logs = testlib.LogCapturer()\n        logs.start()\n\n        # Send message and block for one IO loop, so _async_route can run.\n        router.route(mitogen.core.Message.pickled(' '*8192))\n        router.broker.defer_sync(lambda: None)\n\n        expect = 'message too large (max 4096 bytes)'\n        self.assertTrue(expect in logs.stop())\n\n    def test_local_dead_message(self):\n        # Local router should generate dead message when reply_to is set.\n        router = self.klass(broker=self.broker, max_message_size=4096)\n\n        logs = testlib.LogCapturer()\n        logs.start()\n\n        expect = router.too_large_msg % (4096,)\n\n        # Try function call. Receiver should be woken by a dead message sent by\n        # router due to message size exceeded.\n        child = router.local()\n        e = self.assertRaises(mitogen.core.ChannelError,\n            lambda: child.call(zlib.crc32, ' '*8192))\n        self.assertEquals(e.args[0], expect)\n\n        self.assertTrue(expect in logs.stop())\n\n    def test_remote_configured(self):\n        router = self.klass(broker=self.broker, max_message_size=64*1024)\n        remote = router.local()\n        size = remote.call(return_router_max_message_size)\n        self.assertEquals(size, 64*1024)\n\n    def test_remote_exceeded(self):\n        # Ensure new contexts receive a router with the same value.\n        router = self.klass(broker=self.broker, max_message_size=64*1024)\n        recv = mitogen.core.Receiver(router)\n\n        logs = testlib.LogCapturer()\n        logs.start()\n        remote = router.local()\n        remote.call(send_n_sized_reply, recv.to_sender(), 128*1024)\n\n        expect = 'message too large (max %d bytes)' % (64*1024,)\n        self.assertTrue(expect in logs.stop())\n\n\nclass NoRouteTest(testlib.RouterMixin, testlib.TestCase):\n    def test_invalid_handle_returns_dead(self):\n        # Verify sending a message to an invalid handle yields a dead message\n        # from the target context.\n        l1 = self.router.local()\n        recv = l1.send_async(mitogen.core.Message(handle=999))\n        msg = recv.get(throw_dead=False)\n        self.assertEquals(msg.is_dead, True)\n        self.assertEquals(msg.src_id, l1.context_id)\n        self.assertEquals(msg.data, self.router.invalid_handle_msg.encode())\n\n        recv = l1.send_async(mitogen.core.Message(handle=999))\n        e = self.assertRaises(mitogen.core.ChannelError,\n                              lambda: recv.get())\n        self.assertEquals(e.args[0], self.router.invalid_handle_msg)\n\n    def test_totally_invalid_context_returns_dead(self):\n        recv = mitogen.core.Receiver(self.router)\n        msg = mitogen.core.Message(\n            dst_id=1234,\n            handle=1234,\n            reply_to=recv.handle,\n        )\n        self.router.route(msg)\n        rmsg = recv.get(throw_dead=False)\n        self.assertEquals(rmsg.is_dead, True)\n        self.assertEquals(rmsg.src_id, mitogen.context_id)\n        self.assertEquals(rmsg.data, (self.router.no_route_msg % (\n            1234,\n            mitogen.context_id,\n        )).encode())\n\n        self.router.route(msg)\n        e = self.assertRaises(mitogen.core.ChannelError,\n                              lambda: recv.get())\n        self.assertEquals(e.args[0], (self.router.no_route_msg % (\n            1234,\n            mitogen.context_id,\n        )))\n\n    def test_previously_alive_context_returns_dead(self):\n        l1 = self.router.local()\n        l1.shutdown(wait=True)\n        recv = mitogen.core.Receiver(self.router)\n        msg = mitogen.core.Message(\n            dst_id=l1.context_id,\n            handle=mitogen.core.CALL_FUNCTION,\n            reply_to=recv.handle,\n        )\n        self.router.route(msg)\n        rmsg = recv.get(throw_dead=False)\n        self.assertEquals(rmsg.is_dead, True)\n        self.assertEquals(rmsg.src_id, mitogen.context_id)\n        self.assertEquals(rmsg.data, (self.router.no_route_msg % (\n            l1.context_id,\n            mitogen.context_id,\n        )).encode())\n\n        self.router.route(msg)\n        e = self.assertRaises(mitogen.core.ChannelError,\n                              lambda: recv.get())\n        self.assertEquals(e.args[0], self.router.no_route_msg % (\n            l1.context_id,\n            mitogen.context_id,\n        ))\n\n\ndef test_siblings_cant_talk(router):\n    l1 = router.local()\n    l2 = router.local()\n    logs = testlib.LogCapturer()\n    logs.start()\n\n    try:\n        l2.call(ping_context, l1)\n    except mitogen.core.CallError:\n        e = sys.exc_info()[1]\n\n    msg = mitogen.core.Router.unidirectional_msg % (\n        l2.context_id,\n        l1.context_id,\n    )\n    assert msg in str(e)\n    assert 'routing mode prevents forward of ' in logs.stop()\n\n\n@mitogen.core.takes_econtext\ndef test_siblings_cant_talk_remote(econtext):\n    mitogen.parent.upgrade_router(econtext)\n    test_siblings_cant_talk(econtext.router)\n\n\nclass UnidirectionalTest(testlib.RouterMixin, testlib.TestCase):\n    def test_siblings_cant_talk_master(self):\n        self.router.unidirectional = True\n        test_siblings_cant_talk(self.router)\n\n    def test_siblings_cant_talk_parent(self):\n        # ensure 'unidirectional' attribute is respected for contexts started\n        # by children.\n        self.router.unidirectional = True\n        parent = self.router.local()\n        parent.call(test_siblings_cant_talk_remote)\n\n    def test_auth_id_can_talk(self):\n        self.router.unidirectional = True\n        # One stream has auth_id stamped to that of the master, so it should be\n        # treated like a parent.\n        l1 = self.router.local()\n        l1s = self.router.stream_by_id(l1.context_id)\n        l1s.protocol.auth_id = mitogen.context_id\n        l1s.protocol.is_privileged = True\n\n        l2 = self.router.local()\n        e = self.assertRaises(mitogen.core.CallError,\n                              lambda: l2.call(ping_context, l1))\n\n        msg = 'mitogen.core.ChannelError: %s' % (self.router.refused_msg,)\n        self.assertTrue(str(e).startswith(msg))\n\n\nclass EgressIdsTest(testlib.RouterMixin, testlib.TestCase):\n    def test_egress_ids_populated(self):\n        # Ensure Stream.egress_ids is populated on message reception.\n        c1 = self.router.local(name='c1')\n        c2 = self.router.local(name='c2')\n\n        c1s = self.router.stream_by_id(c1.context_id)\n        try:\n            c1.call(ping_context, c2)\n        except mitogen.core.CallError:\n            # Fails because siblings cant call funcs in each other, but this\n            # causes messages to be sent.\n            pass\n\n        self.assertEquals(c1s.protocol.egress_ids, set([\n            mitogen.context_id,\n            c2.context_id,\n        ]))\n\n\nif __name__ == '__main__':\n    unittest2.main()\n"], "filenames": ["mitogen/core.py", "tests/router_test.py"], "buggy_code_start_loc": [3626, 0], "buggy_code_end_loc": [3627, 360], "fixing_code_start_loc": [3626, 1], "fixing_code_end_loc": [3627, 382], "type": "CWE-254", "message": "** DISPUTED ** core.py in Mitogen before 0.2.8 has a typo that drops the unidirectional-routing protection mechanism in the case of a child that is initiated by another child. The Ansible extension is unaffected. NOTE: the vendor disputes this issue because it is exploitable only in conjunction with hypothetical other factors, i.e., an affected use case within a library caller, and a bug in the message receiver policy code that led to reliance on this extra protection mechanism.", "other": {"cve": {"id": "CVE-2019-15149", "sourceIdentifier": "cve@mitre.org", "published": "2019-08-18T20:15:09.220", "lastModified": "2019-08-30T11:38:14.643", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "** DISPUTED ** core.py in Mitogen before 0.2.8 has a typo that drops the unidirectional-routing protection mechanism in the case of a child that is initiated by another child. The Ansible extension is unaffected. NOTE: the vendor disputes this issue because it is exploitable only in conjunction with hypothetical other factors, i.e., an affected use case within a library caller, and a bug in the message receiver policy code that led to reliance on this extra protection mechanism."}, {"lang": "es", "value": "** EN DISPUTA ** core.py en Mitogen veriones anteriores a 0.2.8 tiene un error tipogr\u00e1fico que elimina el mecanismo de protecci\u00f3n de enrutamiento unidireccional en el caso de un proceso hijo iniciado por otro hijo. La extensi\u00f3n Ansible no se ve afectada. NOTA: el proveedor discute este problema porque es explotable solo junto con otros factores hipot\u00e9ticos, es decir, un caso de uso afectado dentro de una persona que llama a la biblioteca y un error en el c\u00f3digo de pol\u00edtica del receptor del mensaje que condujo a la dependencia de este mecanismo de protecci\u00f3n adicional."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 6.8}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-254"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:networkgenomics:mitogen:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.2.8", "matchCriteriaId": "9F98A242-4B87-4F23-8A17-08E0C6B3CCAC"}]}]}], "references": [{"url": "https://github.com/dw/mitogen/commit/5924af1566763e48c42028399ea0cd95c457b3dc", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://mitogen.networkgenomics.com/changelog.html#v0-2-8-2019-08-18", "source": "cve@mitre.org", "tags": ["Release Notes"]}]}, "github_commit_url": "https://github.com/dw/mitogen/commit/5924af1566763e48c42028399ea0cd95c457b3dc"}}
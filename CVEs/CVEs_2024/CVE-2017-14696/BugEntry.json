{"buggy_code": ["# -*- coding: utf-8 -*-\n'''\nThe crypt module manages all of the cryptography functions for minions and\nmasters, encrypting and decrypting payloads, preparing messages, and\nauthenticating peers\n'''\n# Import python libs\nfrom __future__ import absolute_import, print_function\nimport os\nimport sys\nimport copy\nimport time\nimport hmac\nimport base64\nimport hashlib\nimport logging\nimport stat\nimport traceback\nimport binascii\nimport weakref\nimport getpass\n\n# Import third party libs\nimport salt.ext.six as six\nfrom salt.ext.six.moves import zip  # pylint: disable=import-error,redefined-builtin\ntry:\n    from Cryptodome.Cipher import AES, PKCS1_OAEP\n    from Cryptodome.Hash import SHA\n    from Cryptodome.PublicKey import RSA\n    from Cryptodome.Signature import PKCS1_v1_5\n    import Cryptodome.Random  # pylint: disable=W0611\n    CDOME = True\nexcept ImportError:\n    CDOME = False\nif not CDOME:\n    try:\n        from Crypto.Cipher import AES, PKCS1_OAEP\n        from Crypto.Hash import SHA\n        from Crypto.PublicKey import RSA\n        from Crypto.Signature import PKCS1_v1_5\n        # let this be imported, if possible\n        import Crypto.Random  # pylint: disable=W0611\n    except ImportError:\n        # No need for crypt in local mode\n        pass\n\n# Import salt libs\nimport salt.defaults.exitcodes\nimport salt.utils\nimport salt.utils.decorators\nimport salt.payload\nimport salt.transport.client\nimport salt.transport.frame\nimport salt.utils.rsax931\nimport salt.utils.verify\nimport salt.version\nfrom salt.exceptions import (\n    AuthenticationError, SaltClientError, SaltReqTimeoutError\n)\n\nimport tornado.gen\n\nlog = logging.getLogger(__name__)\n\n\ndef dropfile(cachedir, user=None):\n    '''\n    Set an AES dropfile to request the master update the publish session key\n    '''\n    dfn = os.path.join(cachedir, '.dfn')\n    # set a mask (to avoid a race condition on file creation) and store original.\n    mask = os.umask(191)\n    try:\n        log.info('Rotating AES key')\n        if os.path.isfile(dfn):\n            log.info('AES key rotation already requested')\n            return\n\n        if os.path.isfile(dfn) and not os.access(dfn, os.W_OK):\n            os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)\n        with salt.utils.fopen(dfn, 'wb+') as fp_:\n            fp_.write(b'')\n        os.chmod(dfn, stat.S_IRUSR)\n        if user:\n            try:\n                import pwd\n                uid = pwd.getpwnam(user).pw_uid\n                os.chown(dfn, uid, -1)\n            except (KeyError, ImportError, OSError, IOError):\n                pass\n    finally:\n        os.umask(mask)  # restore original umask\n\n\ndef gen_keys(keydir, keyname, keysize, user=None):\n    '''\n    Generate a RSA public keypair for use with salt\n\n    :param str keydir: The directory to write the keypair to\n    :param str keyname: The type of salt server for whom this key should be written. (i.e. 'master' or 'minion')\n    :param int keysize: The number of bits in the key\n    :param str user: The user on the system who should own this keypair\n\n    :rtype: str\n    :return: Path on the filesystem to the RSA private key\n    '''\n    base = os.path.join(keydir, keyname)\n    priv = '{0}.pem'.format(base)\n    pub = '{0}.pub'.format(base)\n\n    salt.utils.reinit_crypto()\n    gen = RSA.generate(bits=keysize, e=65537)\n    if os.path.isfile(priv):\n        # Between first checking and the generation another process has made\n        # a key! Use the winner's key\n        return priv\n\n    # Do not try writing anything, if directory has no permissions.\n    if not os.access(keydir, os.W_OK):\n        raise IOError('Write access denied to \"{0}\" for user \"{1}\".'.format(os.path.abspath(keydir), getpass.getuser()))\n\n    cumask = os.umask(191)\n    with salt.utils.fopen(priv, 'wb+') as f:\n        f.write(gen.exportKey('PEM'))\n    os.umask(cumask)\n    with salt.utils.fopen(pub, 'wb+') as f:\n        f.write(gen.publickey().exportKey('PEM'))\n    os.chmod(priv, 256)\n    if user:\n        try:\n            import pwd\n            uid = pwd.getpwnam(user).pw_uid\n            os.chown(priv, uid, -1)\n            os.chown(pub, uid, -1)\n        except (KeyError, ImportError, OSError):\n            # The specified user was not found, allow the backup systems to\n            # report the error\n            pass\n    return priv\n\n\n@salt.utils.decorators.memoize\ndef _get_key_with_evict(path, timestamp):\n    '''\n    Load a key from disk.  `timestamp` above is intended to be the timestamp\n    of the file's last modification. This fn is memoized so if it is called with the\n    same path and timestamp (the file's last modified time) the second time\n    the result is returned from the memoiziation.  If the file gets modified\n    then the params are different and the key is loaded from disk.\n    '''\n    log.debug('salt.crypt._get_key_with_evict: Loading private key')\n    with salt.utils.fopen(path) as f:\n        key = RSA.importKey(f.read())\n    return key\n\n\ndef _get_rsa_key(path):\n    '''\n    Read a key off the disk.  Poor man's simple cache in effect here,\n    we memoize the result of calling _get_rsa_with_evict.  This means\n    the first time _get_key_with_evict is called with a path and a timestamp\n    the result is cached.  If the file (the private key) does not change\n    then its timestamp will not change and the next time the result is returned\n    from the cache.  If the key DOES change the next time _get_rsa_with_evict\n    is called it is called with different parameters and the fn is run fully to\n    retrieve the key from disk.\n    '''\n    log.debug('salt.crypt._get_rsa_key: Loading private key')\n    return _get_key_with_evict(path, str(os.path.getmtime(path)))\n\n\ndef sign_message(privkey_path, message):\n    '''\n    Use Crypto.Signature.PKCS1_v1_5 to sign a message. Returns the signature.\n    '''\n    key = _get_rsa_key(privkey_path)\n    log.debug('salt.crypt.sign_message: Signing message.')\n    signer = PKCS1_v1_5.new(key)\n    return signer.sign(SHA.new(message))\n\n\ndef verify_signature(pubkey_path, message, signature):\n    '''\n    Use Crypto.Signature.PKCS1_v1_5 to verify the signature on a message.\n    Returns True for valid signature.\n    '''\n    log.debug('salt.crypt.verify_signature: Loading public key')\n    with salt.utils.fopen(pubkey_path) as f:\n        pubkey = RSA.importKey(f.read())\n    log.debug('salt.crypt.verify_signature: Verifying signature')\n    verifier = PKCS1_v1_5.new(pubkey)\n    return verifier.verify(SHA.new(message), signature)\n\n\ndef gen_signature(priv_path, pub_path, sign_path):\n    '''\n    creates a signature for the given public-key with\n    the given private key and writes it to sign_path\n    '''\n\n    with salt.utils.fopen(pub_path) as fp_:\n        mpub_64 = fp_.read()\n\n    mpub_sig = sign_message(priv_path, mpub_64)\n    mpub_sig_64 = binascii.b2a_base64(mpub_sig)\n    if os.path.isfile(sign_path):\n        return False\n    log.trace('Calculating signature for {0} with {1}'\n              .format(os.path.basename(pub_path),\n                      os.path.basename(priv_path)))\n\n    if os.path.isfile(sign_path):\n        log.trace('Signature file {0} already exists, please '\n                  'remove it first and try again'.format(sign_path))\n    else:\n        with salt.utils.fopen(sign_path, 'wb+') as sig_f:\n            sig_f.write(salt.utils.to_bytes(mpub_sig_64))\n        log.trace('Wrote signature to {0}'.format(sign_path))\n    return True\n\n\ndef private_encrypt(key, message):\n    '''\n    Generate an M2Crypto-compatible signature\n\n    :param Crypto.PublicKey.RSA._RSAobj key: The RSA key object\n    :param str message: The message to sign\n    :rtype: str\n    :return: The signature, or an empty string if the signature operation failed\n    '''\n    signer = salt.utils.rsax931.RSAX931Signer(key.exportKey('PEM'))\n    return signer.sign(message)\n\n\ndef public_decrypt(pub, message):\n    '''\n    Verify an M2Crypto-compatible signature\n\n    :param Crypto.PublicKey.RSA._RSAobj key: The RSA public key object\n    :param str message: The signed message to verify\n    :rtype: str\n    :return: The message (or digest) recovered from the signature, or an\n        empty string if the verification failed\n    '''\n    verifier = salt.utils.rsax931.RSAX931Verifier(pub.exportKey('PEM'))\n    return verifier.verify(message)\n\n\nclass MasterKeys(dict):\n    '''\n    The Master Keys class is used to manage the RSA public key pair used for\n    authentication by the master.\n\n    It also generates a signing key-pair if enabled with master_sign_key_name.\n    '''\n    def __init__(self, opts):\n        super(MasterKeys, self).__init__()\n        self.opts = opts\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'master.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'master.pem')\n\n        self.key = self.__get_keys()\n        self.pub_signature = None\n\n        # set names for the signing key-pairs\n        if opts['master_sign_pubkey']:\n\n            # if only the signature is available, use that\n            if opts['master_use_pubkey_signature']:\n                self.sig_path = os.path.join(self.opts['pki_dir'],\n                                             opts['master_pubkey_signature'])\n                if os.path.isfile(self.sig_path):\n                    with salt.utils.fopen(self.sig_path) as fp_:\n                        self.pub_signature = fp_.read()\n                    log.info('Read {0}\\'s signature from {1}'\n                             ''.format(os.path.basename(self.pub_path),\n                                       self.opts['master_pubkey_signature']))\n                else:\n                    log.error('Signing the master.pub key with a signature is enabled '\n                              'but no signature file found at the defined location '\n                              '{0}'.format(self.sig_path))\n                    log.error('The signature-file may be either named differently '\n                               'or has to be created with \\'salt-key --gen-signature\\'')\n                    sys.exit(1)\n\n            # create a new signing key-pair to sign the masters\n            # auth-replies when a minion tries to connect\n            else:\n                self.pub_sign_path = os.path.join(self.opts['pki_dir'],\n                                                  opts['master_sign_key_name'] + '.pub')\n                self.rsa_sign_path = os.path.join(self.opts['pki_dir'],\n                                                  opts['master_sign_key_name'] + '.pem')\n                self.sign_key = self.__get_keys(name=opts['master_sign_key_name'])\n\n    # We need __setstate__ and __getstate__ to avoid pickling errors since\n    # some of the member variables correspond to Cython objects which are\n    # not picklable.\n    # These methods are only used when pickling so will not be used on\n    # non-Windows platforms.\n    def __setstate__(self, state):\n        self.__init__(state['opts'])\n\n    def __getstate__(self):\n        return {'opts': self.opts}\n\n    def __get_keys(self, name='master'):\n        '''\n        Returns a key object for a key in the pki-dir\n        '''\n        path = os.path.join(self.opts['pki_dir'],\n                            name + '.pem')\n        if os.path.exists(path):\n            with salt.utils.fopen(path) as f:\n                key = RSA.importKey(f.read())\n            log.debug('Loaded {0} key: {1}'.format(name, path))\n        else:\n            log.info('Generating {0} keys: {1}'.format(name, self.opts['pki_dir']))\n            gen_keys(self.opts['pki_dir'],\n                     name,\n                     self.opts['keysize'],\n                     self.opts.get('user'))\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n        return key\n\n    def get_pub_str(self, name='master'):\n        '''\n        Return the string representation of a public key\n        in the pki-directory\n        '''\n        path = os.path.join(self.opts['pki_dir'],\n                            name + '.pub')\n        if not os.path.isfile(path):\n            key = self.__get_keys()\n            with salt.utils.fopen(path, 'wb+') as wfh:\n                wfh.write(key.publickey().exportKey('PEM'))\n        with salt.utils.fopen(path) as rfh:\n            return rfh.read()\n\n    def get_mkey_paths(self):\n        return self.pub_path, self.rsa_path\n\n    def get_sign_paths(self):\n        return self.pub_sign_path, self.rsa_sign_path\n\n    def pubkey_signature(self):\n        '''\n        returns the base64 encoded signature from the signature file\n        or None if the master has its own signing keys\n        '''\n        return self.pub_signature\n\n\nclass AsyncAuth(object):\n    '''\n    Set up an Async object to maintain authentication with the salt master\n    '''\n    # This class is only a singleton per minion/master pair\n    # mapping of io_loop -> {key -> auth}\n    instance_map = weakref.WeakKeyDictionary()\n\n    # mapping of key -> creds\n    creds_map = {}\n\n    def __new__(cls, opts, io_loop=None):\n        '''\n        Only create one instance of AsyncAuth per __key()\n        '''\n        # do we have any mapping for this io_loop\n        io_loop = io_loop or tornado.ioloop.IOLoop.current()\n        if io_loop not in AsyncAuth.instance_map:\n            AsyncAuth.instance_map[io_loop] = weakref.WeakValueDictionary()\n        loop_instance_map = AsyncAuth.instance_map[io_loop]\n\n        key = cls.__key(opts)\n        auth = loop_instance_map.get(key)\n        if auth is None:\n            log.debug('Initializing new AsyncAuth for {0}'.format(key))\n            # we need to make a local variable for this, as we are going to store\n            # it in a WeakValueDictionary-- which will remove the item if no one\n            # references it-- this forces a reference while we return to the caller\n            auth = object.__new__(cls)\n            auth.__singleton_init__(opts, io_loop=io_loop)\n            loop_instance_map[key] = auth\n        else:\n            log.debug('Re-using AsyncAuth for {0}'.format(key))\n        return auth\n\n    @classmethod\n    def __key(cls, opts, io_loop=None):\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],  # master ID\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, io_loop=None):\n        pass\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, io_loop=None):\n        '''\n        Init an Auth instance\n\n        :param dict opts: Options for this server\n        :return: Auth instance\n        :rtype: Auth\n        '''\n        self.opts = opts\n        if six.PY2:\n            self.token = Crypticle.generate_key_string()\n        else:\n            self.token = salt.utils.to_bytes(Crypticle.generate_key_string())\n        self.serial = salt.payload.Serial(self.opts)\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'minion.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'minion.pem')\n        if self.opts['__role'] == 'syndic':\n            self.mpub = 'syndic_master.pub'\n        else:\n            self.mpub = 'minion_master.pub'\n        if not os.path.isfile(self.pub_path):\n            self.get_keys()\n\n        self.io_loop = io_loop or tornado.ioloop.IOLoop.current()\n\n        salt.utils.reinit_crypto()\n        key = self.__key(self.opts)\n        # TODO: if we already have creds for this key, lets just re-use\n        if key in AsyncAuth.creds_map:\n            creds = AsyncAuth.creds_map[key]\n            self._creds = creds\n            self._crypticle = Crypticle(self.opts, creds['aes'])\n            self._authenticate_future = tornado.concurrent.Future()\n            self._authenticate_future.set_result(True)\n        else:\n            self.authenticate()\n\n    def __deepcopy__(self, memo):\n        cls = self.__class__\n        result = cls.__new__(cls, copy.deepcopy(self.opts, memo), io_loop=None)\n        memo[id(self)] = result\n        for key in self.__dict__:\n            if key in ('io_loop',):\n                # The io_loop has a thread Lock which will fail to be deep\n                # copied. Skip it because it will just be recreated on the\n                # new copy.\n                continue\n            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))\n        return result\n\n    @property\n    def creds(self):\n        return self._creds\n\n    @property\n    def crypticle(self):\n        return self._crypticle\n\n    @property\n    def authenticated(self):\n        return hasattr(self, '_authenticate_future') and \\\n               self._authenticate_future.done() and \\\n               self._authenticate_future.exception() is None\n\n    def invalidate(self):\n        if self.authenticated:\n            del self._authenticate_future\n            key = self.__key(self.opts)\n            if key in AsyncAuth.creds_map:\n                del AsyncAuth.creds_map[key]\n\n    def authenticate(self, callback=None):\n        '''\n        Ask for this client to reconnect to the origin\n\n        This function will de-dupe all calls here and return a *single* future\n        for the sign-in-- whis way callers can all assume there aren't others\n        '''\n        # if an auth is in flight-- and not done-- just pass that back as the future to wait on\n        if hasattr(self, '_authenticate_future') and not self._authenticate_future.done():\n            future = self._authenticate_future\n        else:\n            future = tornado.concurrent.Future()\n            self._authenticate_future = future\n            self.io_loop.add_callback(self._authenticate)\n\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n\n        return future\n\n    @tornado.gen.coroutine\n    def _authenticate(self):\n        '''\n        Authenticate with the master, this method breaks the functional\n        paradigm, it will update the master information from a fresh sign\n        in, signing in can occur as often as needed to keep up with the\n        revolving master AES key.\n\n        :rtype: Crypticle\n        :returns: A crypticle used for encryption operations\n        '''\n        acceptance_wait_time = self.opts['acceptance_wait_time']\n        acceptance_wait_time_max = self.opts['acceptance_wait_time_max']\n        if not acceptance_wait_time_max:\n            acceptance_wait_time_max = acceptance_wait_time\n        creds = None\n        channel = salt.transport.client.AsyncReqChannel.factory(self.opts,\n                                                                crypt='clear',\n                                                                io_loop=self.io_loop)\n        error = None\n        while True:\n            try:\n                creds = yield self.sign_in(channel=channel)\n            except SaltClientError as exc:\n                error = exc\n                break\n            if creds == 'retry':\n                if self.opts.get('detect_mode') is True:\n                    error = SaltClientError('Detect mode is on')\n                    break\n                if self.opts.get('caller'):\n                    print('Minion failed to authenticate with the master, '\n                          'has the minion key been accepted?')\n                    sys.exit(2)\n                if acceptance_wait_time:\n                    log.info('Waiting {0} seconds before retry.'.format(acceptance_wait_time))\n                    yield tornado.gen.sleep(acceptance_wait_time)\n                if acceptance_wait_time < acceptance_wait_time_max:\n                    acceptance_wait_time += acceptance_wait_time\n                    log.debug('Authentication wait time is {0}'.format(acceptance_wait_time))\n                continue\n            break\n        if not isinstance(creds, dict) or 'aes' not in creds:\n            if self.opts.get('detect_mode') is True:\n                error = SaltClientError('-|RETRY|-')\n            try:\n                del AsyncAuth.creds_map[self.__key(self.opts)]\n            except KeyError:\n                pass\n            if not error:\n                error = SaltClientError('Attempt to authenticate with the salt master failed')\n            self._authenticate_future.set_exception(error)\n        else:\n            key = self.__key(self.opts)\n            AsyncAuth.creds_map[key] = creds\n            self._creds = creds\n            self._crypticle = Crypticle(self.opts, creds['aes'])\n            self._authenticate_future.set_result(True)  # mark the sign-in as complete\n            # Notify the bus about creds change\n            event = salt.utils.event.get_event(self.opts.get('__role'), opts=self.opts, listen=False)\n            event.fire_event({'key': key, 'creds': creds}, salt.utils.event.tagify(prefix='auth', suffix='creds'))\n\n    @tornado.gen.coroutine\n    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):\n        '''\n        Send a sign in request to the master, sets the key information and\n        returns a dict containing the master publish interface to bind to\n        and the decrypted aes key for transport decryption.\n\n        :param int timeout: Number of seconds to wait before timing out the sign-in request\n        :param bool safe: If True, do not raise an exception on timeout. Retry instead.\n        :param int tries: The number of times to try to authenticate before giving up.\n\n        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set\n\n        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary\n        with the publication port and the shared AES key.\n\n        '''\n        auth = {}\n\n        auth_timeout = self.opts.get('auth_timeout', None)\n        if auth_timeout is not None:\n            timeout = auth_timeout\n        auth_safemode = self.opts.get('auth_safemode', None)\n        if auth_safemode is not None:\n            safe = auth_safemode\n        auth_tries = self.opts.get('auth_tries', None)\n        if auth_tries is not None:\n            tries = auth_tries\n\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n\n        auth['master_uri'] = self.opts['master_uri']\n\n        if not channel:\n            channel = salt.transport.client.AsyncReqChannel.factory(self.opts,\n                                                                crypt='clear',\n                                                                io_loop=self.io_loop)\n\n        sign_in_payload = self.minion_sign_in_payload()\n        try:\n            payload = yield channel.send(\n                sign_in_payload,\n                tries=tries,\n                timeout=timeout\n            )\n        except SaltReqTimeoutError as e:\n            if safe:\n                log.warning('SaltReqTimeoutError: {0}'.format(e))\n                raise tornado.gen.Return('retry')\n            if self.opts.get('detect_mode') is True:\n                raise tornado.gen.Return('retry')\n            else:\n                raise SaltClientError('Attempt to authenticate with the salt master failed with timeout error')\n        if 'load' in payload:\n            if 'ret' in payload['load']:\n                if not payload['load']['ret']:\n                    if self.opts['rejected_retry']:\n                        log.error(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key.\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master.\\nThe Salt '\n                            'Minion will attempt to to re-authenicate.'\n                        )\n                        raise tornado.gen.Return('retry')\n                    else:\n                        log.critical(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key!\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master and restart this '\n                            'minion.\\nOr restart the Salt Master in open mode to '\n                            'clean out the keys. The Salt Minion will now exit.'\n                        )\n                        sys.exit(salt.defaults.exitcodes.EX_OK)\n                # has the master returned that its maxed out with minions?\n                elif payload['load']['ret'] == 'full':\n                    raise tornado.gen.Return('full')\n                else:\n                    log.error(\n                        'The Salt Master has cached the public key for this '\n                        'node, this salt minion will wait for {0} seconds '\n                        'before attempting to re-authenticate'.format(\n                            self.opts['acceptance_wait_time']\n                        )\n                    )\n                    raise tornado.gen.Return('retry')\n        auth['aes'] = self.verify_master(payload, master_pub='token' in sign_in_payload)\n        if not auth['aes']:\n            log.critical(\n                'The Salt Master server\\'s public key did not authenticate!\\n'\n                'The master may need to be updated if it is a version of Salt '\n                'lower than {0}, or\\n'\n                'If you are confident that you are connecting to a valid Salt '\n                'Master, then remove the master public key and restart the '\n                'Salt Minion.\\nThe master public key can be found '\n                'at:\\n{1}'.format(salt.version.__version__, m_pub_fn)\n            )\n            raise SaltClientError('Invalid master key')\n        if self.opts.get('syndic_master', False):  # Is syndic\n            syndic_finger = self.opts.get('syndic_finger', self.opts.get('master_finger', False))\n            if syndic_finger:\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != syndic_finger:\n                    self._finger_fail(syndic_finger, m_pub_fn)\n        else:\n            if self.opts.get('master_finger', False):\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != self.opts['master_finger']:\n                    self._finger_fail(self.opts['master_finger'], m_pub_fn)\n        auth['publish_port'] = payload['publish_port']\n        raise tornado.gen.Return(auth)\n\n    def get_keys(self):\n        '''\n        Return keypair object for the minion.\n\n        :rtype: Crypto.PublicKey.RSA._RSAobj\n        :return: The RSA keypair\n        '''\n        # Make sure all key parent directories are accessible\n        user = self.opts.get('user', 'root')\n        salt.utils.verify.check_path_traversal(self.opts['pki_dir'], user)\n\n        if os.path.exists(self.rsa_path):\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n            log.debug('Loaded minion key: {0}'.format(self.rsa_path))\n        else:\n            log.info('Generating keys: {0}'.format(self.opts['pki_dir']))\n            gen_keys(self.opts['pki_dir'],\n                     'minion',\n                     self.opts['keysize'],\n                     self.opts.get('user'))\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n        return key\n\n    def gen_token(self, clear_tok):\n        '''\n        Encrypt a string with the minion private key to verify identity\n        with the master.\n\n        :param str clear_tok: A plaintext token to encrypt\n        :return: Encrypted token\n        :rtype: str\n        '''\n        return private_encrypt(self.get_keys(), clear_tok)\n\n    def minion_sign_in_payload(self):\n        '''\n        Generates the payload used to authenticate with the master\n        server. This payload consists of the passed in id_ and the ssh\n        public key to encrypt the AES key sent back from the master.\n\n        :return: Payload dictionary\n        :rtype: dict\n        '''\n        payload = {}\n        payload['cmd'] = '_auth'\n        payload['id'] = self.opts['id']\n        try:\n            pubkey_path = os.path.join(self.opts['pki_dir'], self.mpub)\n            with salt.utils.fopen(pubkey_path) as f:\n                pub = RSA.importKey(f.read())\n            cipher = PKCS1_OAEP.new(pub)\n            payload['token'] = cipher.encrypt(self.token)\n        except Exception:\n            pass\n        with salt.utils.fopen(self.pub_path) as f:\n            payload['pub'] = f.read()\n        return payload\n\n    def decrypt_aes(self, payload, master_pub=True):\n        '''\n        This function is used to decrypt the AES seed phrase returned from\n        the master server. The seed phrase is decrypted with the SSH RSA\n        host key.\n\n        Pass in the encrypted AES key.\n        Returns the decrypted AES seed key, a string\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'sig': The message signature\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The public key of the sender.\n\n        :rtype: str\n        :return: The decrypted token that was provided, with padding.\n\n        :rtype: str\n        :return: The decrypted AES seed key\n        '''\n        if self.opts.get('auth_trb', False):\n            log.warning(\n                    'Auth Called: {0}'.format(\n                        ''.join(traceback.format_stack())\n                        )\n                    )\n        else:\n            log.debug('Decrypting the current master AES key')\n        key = self.get_keys()\n        cipher = PKCS1_OAEP.new(key)\n        key_str = cipher.decrypt(payload['aes'])\n        if 'sig' in payload:\n            m_path = os.path.join(self.opts['pki_dir'], self.mpub)\n            if os.path.exists(m_path):\n                try:\n                    with salt.utils.fopen(m_path) as f:\n                        mkey = RSA.importKey(f.read())\n                except Exception:\n                    return '', ''\n                digest = hashlib.sha256(key_str).hexdigest()\n                if six.PY3:\n                    digest = salt.utils.to_bytes(digest)\n                m_digest = public_decrypt(mkey.publickey(), payload['sig'])\n                if m_digest != digest:\n                    return '', ''\n        else:\n            return '', ''\n\n        if six.PY3:\n            key_str = salt.utils.to_str(key_str)\n\n        if '_|-' in key_str:\n            return key_str.split('_|-')\n        else:\n            if 'token' in payload:\n                token = cipher.decrypt(payload['token'])\n                return key_str, token\n            elif not master_pub:\n                return key_str, ''\n        return '', ''\n\n    def verify_pubkey_sig(self, message, sig):\n        '''\n        Wraps the verify_signature method so we have\n        additional checks.\n\n        :rtype: bool\n        :return: Success or failure of public key verification\n        '''\n        if self.opts['master_sign_key_name']:\n            path = os.path.join(self.opts['pki_dir'],\n                                self.opts['master_sign_key_name'] + '.pub')\n\n            if os.path.isfile(path):\n                res = verify_signature(path,\n                                       message,\n                                       binascii.a2b_base64(sig))\n            else:\n                log.error('Verification public key {0} does not exist. You '\n                          'need to copy it from the master to the minions '\n                          'pki directory'.format(os.path.basename(path)))\n                return False\n            if res:\n                log.debug('Successfully verified signature of master '\n                          'public key with verification public key '\n                          '{0}'.format(self.opts['master_sign_key_name'] + '.pub'))\n                return True\n            else:\n                log.debug('Failed to verify signature of public key')\n                return False\n        else:\n            log.error('Failed to verify the signature of the message because '\n                      'the verification key-pairs name is not defined. Please '\n                      'make sure that master_sign_key_name is defined.')\n            return False\n\n    def verify_signing_master(self, payload):\n        try:\n            if self.verify_pubkey_sig(payload['pub_key'],\n                                      payload['pub_sig']):\n                log.info('Received signed and verified master pubkey '\n                         'from master {0}'.format(self.opts['master']))\n                m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n                uid = salt.utils.get_uid(self.opts.get('user', None))\n                with salt.utils.fpopen(m_pub_fn, 'wb+', uid=uid) as wfh:\n                    wfh.write(salt.utils.to_bytes(payload['pub_key']))\n                return True\n            else:\n                log.error('Received signed public-key from master {0} '\n                          'but signature verification failed!'.format(self.opts['master']))\n                return False\n        except Exception as sign_exc:\n            log.error('There was an error while verifying the masters public-key signature')\n            raise Exception(sign_exc)\n\n    def check_auth_deps(self, payload):\n        '''\n        Checks if both master and minion either sign (master) and\n        verify (minion). If one side does not, it should fail.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', 'aes')\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n        '''\n        # master and minion sign and verify\n        if 'pub_sig' in payload and self.opts['verify_master_pubkey_sign']:\n            return True\n        # master and minion do NOT sign and do NOT verify\n        elif 'pub_sig' not in payload and not self.opts['verify_master_pubkey_sign']:\n            return True\n\n        # master signs, but minion does NOT verify\n        elif 'pub_sig' in payload and not self.opts['verify_master_pubkey_sign']:\n            log.error('The masters sent its public-key signature, but signature '\n                      'verification is not enabled on the minion. Either enable '\n                      'signature verification on the minion or disable signing '\n                      'the public key on the master!')\n            return False\n        # master does NOT sign but minion wants to verify\n        elif 'pub_sig' not in payload and self.opts['verify_master_pubkey_sign']:\n            log.error('The master did not send its public-key signature, but '\n                      'signature verification is enabled on the minion. Either '\n                      'disable signature verification on the minion or enable '\n                      'signing the public on the master!')\n            return False\n\n    def extract_aes(self, payload, master_pub=True):\n        '''\n        Return the AES key received from the master after the minion has been\n        successfully authenticated.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n\n        :rtype: str\n        :return: The shared AES key received from the master.\n        '''\n        if master_pub:\n            try:\n                aes, token = self.decrypt_aes(payload, master_pub)\n                if token != self.token:\n                    log.error(\n                        'The master failed to decrypt the random minion token'\n                    )\n                    return ''\n            except Exception:\n                log.error(\n                    'The master failed to decrypt the random minion token'\n                )\n                return ''\n            return aes\n        else:\n            aes, token = self.decrypt_aes(payload, master_pub)\n            return aes\n\n    def verify_master(self, payload, master_pub=True):\n        '''\n        Verify that the master is the same one that was previously accepted.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n        :param bool master_pub: Operate as if minion had no master pubkey when it sent auth request, i.e. don't verify\n        the minion signature\n\n        :rtype: str\n        :return: An empty string on verification failure. On success, the decrypted AES message in the payload.\n        '''\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n        m_pub_exists = os.path.isfile(m_pub_fn)\n        if m_pub_exists and master_pub and not self.opts['open_mode']:\n            with salt.utils.fopen(m_pub_fn) as fp_:\n                local_master_pub = fp_.read()\n\n            if payload['pub_key'].replace('\\n', '').replace('\\r', '') != \\\n                    local_master_pub.replace('\\n', '').replace('\\r', ''):\n                if not self.check_auth_deps(payload):\n                    return ''\n\n                if self.opts['verify_master_pubkey_sign']:\n                    if self.verify_signing_master(payload):\n                        return self.extract_aes(payload, master_pub=False)\n                    else:\n                        return ''\n                else:\n                    # This is not the last master we connected to\n                    log.error('The master key has changed, the salt master could '\n                              'have been subverted, verify salt master\\'s public '\n                              'key')\n                    return ''\n\n            else:\n                if not self.check_auth_deps(payload):\n                    return ''\n                # verify the signature of the pubkey even if it has\n                # not changed compared with the one we already have\n                if self.opts['always_verify_signature']:\n                    if self.verify_signing_master(payload):\n                        return self.extract_aes(payload)\n                    else:\n                        log.error('The masters public could not be verified. Is the '\n                                  'verification pubkey {0} up to date?'\n                                  ''.format(self.opts['master_sign_key_name'] + '.pub'))\n                        return ''\n\n                else:\n                    return self.extract_aes(payload)\n        else:\n            if not self.check_auth_deps(payload):\n                return ''\n\n            # verify the masters pubkey signature if the minion\n            # has not received any masters pubkey before\n            if self.opts['verify_master_pubkey_sign']:\n                if self.verify_signing_master(payload):\n                    return self.extract_aes(payload, master_pub=False)\n                else:\n                    return ''\n            else:\n                if not m_pub_exists:\n                    # the minion has not received any masters pubkey yet, write\n                    # the newly received pubkey to minion_master.pub\n                    with salt.utils.fopen(m_pub_fn, 'wb+') as fp_:\n                        fp_.write(salt.utils.to_bytes(payload['pub_key']))\n                return self.extract_aes(payload, master_pub=False)\n\n    def _finger_fail(self, finger, master_key):\n        log.critical(\n            'The specified fingerprint in the master configuration '\n            'file:\\n{0}\\nDoes not match the authenticating master\\'s '\n            'key:\\n{1}\\nVerify that the configured fingerprint '\n            'matches the fingerprint of the correct master and that '\n            'this minion is not subject to a man-in-the-middle attack.'\n            .format(\n                finger,\n                salt.utils.pem_finger(master_key, sum_type=self.opts['hash_type'])\n            )\n        )\n        sys.exit(42)\n\n\n# TODO: remove, we should just return a sync wrapper of AsyncAuth\nclass SAuth(AsyncAuth):\n    '''\n    Set up an object to maintain authentication with the salt master\n    '''\n    # This class is only a singleton per minion/master pair\n    instances = weakref.WeakValueDictionary()\n\n    def __new__(cls, opts, io_loop=None):\n        '''\n        Only create one instance of SAuth per __key()\n        '''\n        key = cls.__key(opts)\n        auth = SAuth.instances.get(key)\n        if auth is None:\n            log.debug('Initializing new SAuth for {0}'.format(key))\n            auth = object.__new__(cls)\n            auth.__singleton_init__(opts)\n            SAuth.instances[key] = auth\n        else:\n            log.debug('Re-using SAuth for {0}'.format(key))\n        return auth\n\n    @classmethod\n    def __key(cls, opts, io_loop=None):\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],  # master ID\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, io_loop=None):\n        super(SAuth, self).__init__(opts, io_loop=io_loop)\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, io_loop=None):\n        '''\n        Init an Auth instance\n\n        :param dict opts: Options for this server\n        :return: Auth instance\n        :rtype: Auth\n        '''\n        self.opts = opts\n        if six.PY2:\n            self.token = Crypticle.generate_key_string()\n        else:\n            self.token = salt.utils.to_bytes(Crypticle.generate_key_string())\n        self.serial = salt.payload.Serial(self.opts)\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'minion.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'minion.pem')\n        if 'syndic_master' in self.opts:\n            self.mpub = 'syndic_master.pub'\n        elif 'alert_master' in self.opts:\n            self.mpub = 'monitor_master.pub'\n        else:\n            self.mpub = 'minion_master.pub'\n        if not os.path.isfile(self.pub_path):\n            self.get_keys()\n\n    @property\n    def creds(self):\n        if not hasattr(self, '_creds'):\n            self.authenticate()\n        return self._creds\n\n    @property\n    def crypticle(self):\n        if not hasattr(self, '_crypticle'):\n            self.authenticate()\n        return self._crypticle\n\n    def authenticate(self, _=None):  # TODO: remove unused var\n        '''\n        Authenticate with the master, this method breaks the functional\n        paradigm, it will update the master information from a fresh sign\n        in, signing in can occur as often as needed to keep up with the\n        revolving master AES key.\n\n        :rtype: Crypticle\n        :returns: A crypticle used for encryption operations\n        '''\n        acceptance_wait_time = self.opts['acceptance_wait_time']\n        acceptance_wait_time_max = self.opts['acceptance_wait_time_max']\n        channel = salt.transport.client.ReqChannel.factory(self.opts, crypt='clear')\n        if not acceptance_wait_time_max:\n            acceptance_wait_time_max = acceptance_wait_time\n        while True:\n            creds = self.sign_in(channel=channel)\n            if creds == 'retry':\n                if self.opts.get('caller'):\n                    print('Minion failed to authenticate with the master, '\n                          'has the minion key been accepted?')\n                    sys.exit(2)\n                if acceptance_wait_time:\n                    log.info('Waiting {0} seconds before retry.'.format(acceptance_wait_time))\n                    time.sleep(acceptance_wait_time)\n                if acceptance_wait_time < acceptance_wait_time_max:\n                    acceptance_wait_time += acceptance_wait_time\n                    log.debug('Authentication wait time is {0}'.format(acceptance_wait_time))\n                continue\n            break\n        self._creds = creds\n        self._crypticle = Crypticle(self.opts, creds['aes'])\n\n    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):\n        '''\n        Send a sign in request to the master, sets the key information and\n        returns a dict containing the master publish interface to bind to\n        and the decrypted aes key for transport decryption.\n\n        :param int timeout: Number of seconds to wait before timing out the sign-in request\n        :param bool safe: If True, do not raise an exception on timeout. Retry instead.\n        :param int tries: The number of times to try to authenticate before giving up.\n\n        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set\n\n        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary\n        with the publication port and the shared AES key.\n\n        '''\n        auth = {}\n\n        auth_timeout = self.opts.get('auth_timeout', None)\n        if auth_timeout is not None:\n            timeout = auth_timeout\n        auth_safemode = self.opts.get('auth_safemode', None)\n        if auth_safemode is not None:\n            safe = auth_safemode\n        auth_tries = self.opts.get('auth_tries', None)\n        if auth_tries is not None:\n            tries = auth_tries\n\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n\n        auth['master_uri'] = self.opts['master_uri']\n\n        if not channel:\n            channel = salt.transport.client.ReqChannel.factory(self.opts, crypt='clear')\n\n        sign_in_payload = self.minion_sign_in_payload()\n        try:\n            payload = channel.send(\n                sign_in_payload,\n                tries=tries,\n                timeout=timeout\n            )\n        except SaltReqTimeoutError as e:\n            if safe:\n                log.warning('SaltReqTimeoutError: {0}'.format(e))\n                return 'retry'\n            raise SaltClientError('Attempt to authenticate with the salt master failed with timeout error')\n\n        if 'load' in payload:\n            if 'ret' in payload['load']:\n                if not payload['load']['ret']:\n                    if self.opts['rejected_retry']:\n                        log.error(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key.\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master.\\nThe Salt '\n                            'Minion will attempt to to re-authenicate.'\n                        )\n                        return 'retry'\n                    else:\n                        log.critical(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key!\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master and restart this '\n                            'minion.\\nOr restart the Salt Master in open mode to '\n                            'clean out the keys. The Salt Minion will now exit.'\n                        )\n                        sys.exit(salt.defaults.exitcodes.EX_OK)\n                # has the master returned that its maxed out with minions?\n                elif payload['load']['ret'] == 'full':\n                    return 'full'\n                else:\n                    log.error(\n                        'The Salt Master has cached the public key for this '\n                        'node. If this is the first time connecting to this master '\n                        'then this key may need to be accepted using \\'salt-key -a {0}\\' on '\n                        'the salt master. This salt minion will wait for {1} seconds '\n                        'before attempting to re-authenticate.'.format(\n                            self.opts['id'],\n                            self.opts['acceptance_wait_time']\n                        )\n                    )\n                    return 'retry'\n        auth['aes'] = self.verify_master(payload, master_pub='token' in sign_in_payload)\n        if not auth['aes']:\n            log.critical(\n                'The Salt Master server\\'s public key did not authenticate!\\n'\n                'The master may need to be updated if it is a version of Salt '\n                'lower than {0}, or\\n'\n                'If you are confident that you are connecting to a valid Salt '\n                'Master, then remove the master public key and restart the '\n                'Salt Minion.\\nThe master public key can be found '\n                'at:\\n{1}'.format(salt.version.__version__, m_pub_fn)\n            )\n            sys.exit(42)\n        if self.opts.get('syndic_master', False):  # Is syndic\n            syndic_finger = self.opts.get('syndic_finger', self.opts.get('master_finger', False))\n            if syndic_finger:\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != syndic_finger:\n                    self._finger_fail(syndic_finger, m_pub_fn)\n        else:\n            if self.opts.get('master_finger', False):\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != self.opts['master_finger']:\n                    self._finger_fail(self.opts['master_finger'], m_pub_fn)\n        auth['publish_port'] = payload['publish_port']\n        return auth\n\n\nclass Crypticle(object):\n    '''\n    Authenticated encryption class\n\n    Encryption algorithm: AES-CBC\n    Signing algorithm: HMAC-SHA256\n    '''\n\n    PICKLE_PAD = b'pickle::'\n    AES_BLOCK_SIZE = 16\n    SIG_SIZE = hashlib.sha256().digest_size\n\n    def __init__(self, opts, key_string, key_size=192):\n        self.key_string = key_string\n        self.keys = self.extract_keys(self.key_string, key_size)\n        self.key_size = key_size\n        self.serial = salt.payload.Serial(opts)\n\n    @classmethod\n    def generate_key_string(cls, key_size=192):\n        key = os.urandom(key_size // 8 + cls.SIG_SIZE)\n        b64key = base64.b64encode(key)\n        if six.PY3:\n            b64key = b64key.decode('utf-8')\n        return b64key.replace('\\n', '')\n\n    @classmethod\n    def extract_keys(cls, key_string, key_size):\n        if six.PY2:\n            key = key_string.decode('base64')\n        else:\n            key = salt.utils.to_bytes(base64.b64decode(key_string))\n        assert len(key) == key_size / 8 + cls.SIG_SIZE, 'invalid key'\n        return key[:-cls.SIG_SIZE], key[-cls.SIG_SIZE:]\n\n    def encrypt(self, data):\n        '''\n        encrypt data with AES-CBC and sign it with HMAC-SHA256\n        '''\n        aes_key, hmac_key = self.keys\n        pad = self.AES_BLOCK_SIZE - len(data) % self.AES_BLOCK_SIZE\n        if six.PY2:\n            data = data + pad * chr(pad)\n        else:\n            data = data + salt.utils.to_bytes(pad * chr(pad))\n        iv_bytes = os.urandom(self.AES_BLOCK_SIZE)\n        cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)\n        data = iv_bytes + cypher.encrypt(data)\n        sig = hmac.new(hmac_key, data, hashlib.sha256).digest()\n        return data + sig\n\n    def decrypt(self, data):\n        '''\n        verify HMAC-SHA256 signature and decrypt data with AES-CBC\n        '''\n        aes_key, hmac_key = self.keys\n        sig = data[-self.SIG_SIZE:]\n        data = data[:-self.SIG_SIZE]\n        if six.PY3 and not isinstance(data, bytes):\n            data = salt.utils.to_bytes(data)\n        mac_bytes = hmac.new(hmac_key, data, hashlib.sha256).digest()\n        if len(mac_bytes) != len(sig):\n            log.debug('Failed to authenticate message')\n            raise AuthenticationError('message authentication failed')\n        result = 0\n\n        if six.PY2:\n            for zipped_x, zipped_y in zip(mac_bytes, sig):\n                result |= ord(zipped_x) ^ ord(zipped_y)\n        else:\n            for zipped_x, zipped_y in zip(mac_bytes, sig):\n                result |= zipped_x ^ zipped_y\n        if result != 0:\n            log.debug('Failed to authenticate message')\n            raise AuthenticationError('message authentication failed')\n        iv_bytes = data[:self.AES_BLOCK_SIZE]\n        data = data[self.AES_BLOCK_SIZE:]\n        cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)\n        data = cypher.decrypt(data)\n        if six.PY2:\n            return data[:-ord(data[-1])]\n        else:\n            return data[:-data[-1]]\n\n    def dumps(self, obj):\n        '''\n        Serialize and encrypt a python object\n        '''\n        return self.encrypt(self.PICKLE_PAD + self.serial.dumps(obj))\n\n    def loads(self, data, raw=False):\n        '''\n        Decrypt and un-serialize a python object\n        '''\n        data = self.decrypt(data)\n        # simple integrity check to verify that we got meaningful data\n        if not data.startswith(self.PICKLE_PAD):\n            return {}\n        load = self.serial.loads(data[len(self.PICKLE_PAD):], raw=raw)\n        return load\n", "# -*- coding: utf-8 -*-\n'''\nTCP transport classes\n\nWire protocol: \"len(payload) msgpack({'head': SOMEHEADER, 'body': SOMEBODY})\"\n\n'''\n\n# Import Python Libs\nfrom __future__ import absolute_import\nimport logging\nimport msgpack\nimport socket\nimport os\nimport weakref\nimport time\nimport traceback\nimport errno\n\n# Import Salt Libs\nimport salt.crypt\nimport salt.utils\nimport salt.utils.verify\nimport salt.utils.event\nimport salt.utils.async\nimport salt.payload\nimport salt.exceptions\nimport salt.transport.frame\nimport salt.transport.ipc\nimport salt.transport.client\nimport salt.transport.server\nimport salt.transport.mixins.auth\nimport salt.ext.six as six\nfrom salt.exceptions import SaltReqTimeoutError, SaltClientError\nfrom salt.transport import iter_transport_opts\n\n# Import Tornado Libs\nimport tornado\nimport tornado.tcpserver\nimport tornado.gen\nimport tornado.concurrent\nimport tornado.tcpclient\nimport tornado.netutil\n\n# pylint: disable=import-error,no-name-in-module\nif six.PY2:\n    import urlparse\nelse:\n    import urllib.parse as urlparse\n# pylint: enable=import-error,no-name-in-module\n\n# Import third party libs\ntry:\n    from Cryptodome.Cipher import PKCS1_OAEP\nexcept ImportError:\n    from Crypto.Cipher import PKCS1_OAEP\n\nif six.PY3 and salt.utils.is_windows():\n    USE_LOAD_BALANCER = True\nelse:\n    USE_LOAD_BALANCER = False\n\nif USE_LOAD_BALANCER:\n    import threading\n    import multiprocessing\n    import errno\n    import tornado.util\n    from salt.utils.process import SignalHandlingMultiprocessingProcess\n\nlog = logging.getLogger(__name__)\n\n\ndef _set_tcp_keepalive(sock, opts):\n    '''\n    Ensure that TCP keepalives are set for the socket.\n    '''\n    if hasattr(socket, 'SO_KEEPALIVE'):\n        if opts.get('tcp_keepalive', False):\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n            if hasattr(socket, 'SOL_TCP'):\n                if hasattr(socket, 'TCP_KEEPIDLE'):\n                    tcp_keepalive_idle = opts.get('tcp_keepalive_idle', -1)\n                    if tcp_keepalive_idle > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPIDLE,\n                            int(tcp_keepalive_idle))\n                if hasattr(socket, 'TCP_KEEPCNT'):\n                    tcp_keepalive_cnt = opts.get('tcp_keepalive_cnt', -1)\n                    if tcp_keepalive_cnt > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPCNT,\n                            int(tcp_keepalive_cnt))\n                if hasattr(socket, 'TCP_KEEPINTVL'):\n                    tcp_keepalive_intvl = opts.get('tcp_keepalive_intvl', -1)\n                    if tcp_keepalive_intvl > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPINTVL,\n                            int(tcp_keepalive_intvl))\n            if hasattr(socket, 'SIO_KEEPALIVE_VALS'):\n                # Windows doesn't support TCP_KEEPIDLE, TCP_KEEPCNT, nor\n                # TCP_KEEPINTVL. Instead, it has its own proprietary\n                # SIO_KEEPALIVE_VALS.\n                tcp_keepalive_idle = opts.get('tcp_keepalive_idle', -1)\n                tcp_keepalive_intvl = opts.get('tcp_keepalive_intvl', -1)\n                # Windows doesn't support changing something equivalent to\n                # TCP_KEEPCNT.\n                if tcp_keepalive_idle > 0 or tcp_keepalive_intvl > 0:\n                    # Windows defaults may be found by using the link below.\n                    # Search for 'KeepAliveTime' and 'KeepAliveInterval'.\n                    # https://technet.microsoft.com/en-us/library/bb726981.aspx#EDAA\n                    # If one value is set and the other isn't, we still need\n                    # to send both values to SIO_KEEPALIVE_VALS and they both\n                    # need to be valid. So in that case, use the Windows\n                    # default.\n                    if tcp_keepalive_idle <= 0:\n                        tcp_keepalive_idle = 7200\n                    if tcp_keepalive_intvl <= 0:\n                        tcp_keepalive_intvl = 1\n                    # The values expected are in milliseconds, so multiply by\n                    # 1000.\n                    sock.ioctl(socket.SIO_KEEPALIVE_VALS, (\n                        1, int(tcp_keepalive_idle * 1000),\n                        int(tcp_keepalive_intvl * 1000)))\n        else:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 0)\n\n\nif USE_LOAD_BALANCER:\n    class LoadBalancerServer(SignalHandlingMultiprocessingProcess):\n        '''\n        Raw TCP server which runs in its own process and will listen\n        for incoming connections. Each incoming connection will be\n        sent via multiprocessing queue to the workers.\n        Since the queue is shared amongst workers, only one worker will\n        handle a given connection.\n        '''\n        # TODO: opts!\n        # Based on default used in tornado.netutil.bind_sockets()\n        backlog = 128\n\n        def __init__(self, opts, socket_queue, log_queue=None):\n            super(LoadBalancerServer, self).__init__(log_queue=log_queue)\n            self.opts = opts\n            self.socket_queue = socket_queue\n            self._socket = None\n\n        # __setstate__ and __getstate__ are only used on Windows.\n        # We do this so that __init__ will be invoked on Windows in the child\n        # process so that a register_after_fork() equivalent will work on\n        # Windows.\n        def __setstate__(self, state):\n            self._is_child = True\n            self.__init__(\n                state['opts'],\n                state['socket_queue'],\n                log_queue=state['log_queue']\n            )\n\n        def __getstate__(self):\n            return {'opts': self.opts,\n                    'socket_queue': self.socket_queue,\n                    'log_queue': self.log_queue}\n\n        def close(self):\n            if self._socket is not None:\n                self._socket.shutdown(socket.SHUT_RDWR)\n                self._socket.close()\n                self._socket = None\n\n        def __del__(self):\n            self.close()\n\n        def run(self):\n            '''\n            Start the load balancer\n            '''\n            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            _set_tcp_keepalive(self._socket, self.opts)\n            self._socket.setblocking(1)\n            self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n            self._socket.listen(self.backlog)\n\n            while True:\n                try:\n                    # Wait for a connection to occur since the socket is\n                    # blocking.\n                    connection, address = self._socket.accept()\n                    # Wait for a free slot to be available to put\n                    # the connection into.\n                    # Sockets are picklable on Windows in Python 3.\n                    self.socket_queue.put((connection, address), True, None)\n                except socket.error as e:\n                    # ECONNABORTED indicates that there was a connection\n                    # but it was closed while still in the accept queue.\n                    # (observed on FreeBSD).\n                    if tornado.util.errno_from_exception(e) == errno.ECONNABORTED:\n                        continue\n                    raise\n\n\n# TODO: move serial down into message library\nclass AsyncTCPReqChannel(salt.transport.client.ReqChannel):\n    '''\n    Encapsulate sending routines to tcp.\n\n    Note: this class returns a singleton\n    '''\n    # This class is only a singleton per minion/master pair\n    # mapping of io_loop -> {key -> channel}\n    instance_map = weakref.WeakKeyDictionary()\n\n    def __new__(cls, opts, **kwargs):\n        '''\n        Only create one instance of channel per __key()\n        '''\n        # do we have any mapping for this io_loop\n        io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n        if io_loop not in cls.instance_map:\n            cls.instance_map[io_loop] = weakref.WeakValueDictionary()\n        loop_instance_map = cls.instance_map[io_loop]\n\n        key = cls.__key(opts, **kwargs)\n        obj = loop_instance_map.get(key)\n        if obj is None:\n            log.debug('Initializing new AsyncTCPReqChannel for {0}'.format(key))\n            # we need to make a local variable for this, as we are going to store\n            # it in a WeakValueDictionary-- which will remove the item if no one\n            # references it-- this forces a reference while we return to the caller\n            obj = object.__new__(cls)\n            obj.__singleton_init__(opts, **kwargs)\n            loop_instance_map[key] = obj\n        else:\n            log.debug('Re-using AsyncTCPReqChannel for {0}'.format(key))\n        return obj\n\n    @classmethod\n    def __key(cls, opts, **kwargs):\n        if 'master_uri' in kwargs:\n            opts['master_uri'] = kwargs['master_uri']\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],\n                kwargs.get('crypt', 'aes'),  # TODO: use the same channel for crypt\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, **kwargs):\n        pass\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, **kwargs):\n        self.opts = dict(opts)\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        # crypt defaults to 'aes'\n        self.crypt = kwargs.get('crypt', 'aes')\n\n        self.io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n\n        if self.crypt != 'clear':\n            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)\n\n        resolver = kwargs.get('resolver')\n\n        parse = urlparse.urlparse(self.opts['master_uri'])\n        host, port = parse.netloc.rsplit(':', 1)\n        self.master_addr = (host, int(port))\n        self._closing = False\n        self.message_client = SaltMessageClientPool(self.opts,\n                                                    args=(self.opts, host, int(port),),\n                                                    kwargs={'io_loop': self.io_loop, 'resolver': resolver})\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        self.message_client.close()\n\n    def __del__(self):\n        self.close()\n\n    def _package_load(self, load):\n        return {\n            'enc': self.crypt,\n            'load': load,\n        }\n\n    @tornado.gen.coroutine\n    def crypted_transfer_decode_dictentry(self, load, dictkey=None, tries=3, timeout=60):\n        if not self.auth.authenticated:\n            yield self.auth.authenticate()\n        ret = yield self.message_client.send(self._package_load(self.auth.crypticle.dumps(load)), timeout=timeout)\n        key = self.auth.get_keys()\n        cipher = PKCS1_OAEP.new(key)\n        aes = cipher.decrypt(ret['key'])\n        pcrypt = salt.crypt.Crypticle(self.opts, aes)\n        data = pcrypt.loads(ret[dictkey])\n        if six.PY3:\n            data = salt.transport.frame.decode_embedded_strs(data)\n        raise tornado.gen.Return(data)\n\n    @tornado.gen.coroutine\n    def _crypted_transfer(self, load, tries=3, timeout=60):\n        '''\n        In case of authentication errors, try to renegotiate authentication\n        and retry the method.\n        Indeed, we can fail too early in case of a master restart during a\n        minion state execution call\n        '''\n        @tornado.gen.coroutine\n        def _do_transfer():\n            data = yield self.message_client.send(self._package_load(self.auth.crypticle.dumps(load)),\n                                                  timeout=timeout,\n                                                  )\n            # we may not have always data\n            # as for example for saltcall ret submission, this is a blind\n            # communication, we do not subscribe to return events, we just\n            # upload the results to the master\n            if data:\n                data = self.auth.crypticle.loads(data)\n                if six.PY3:\n                    data = salt.transport.frame.decode_embedded_strs(data)\n            raise tornado.gen.Return(data)\n\n        if not self.auth.authenticated:\n            yield self.auth.authenticate()\n        try:\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n        except salt.crypt.AuthenticationError:\n            yield self.auth.authenticate()\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def _uncrypted_transfer(self, load, tries=3, timeout=60):\n        ret = yield self.message_client.send(self._package_load(load), timeout=timeout)\n        raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def send(self, load, tries=3, timeout=60, raw=False):\n        '''\n        Send a request, return a future which will complete when we send the message\n        '''\n        try:\n            if self.crypt == 'clear':\n                ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)\n            else:\n                ret = yield self._crypted_transfer(load, tries=tries, timeout=timeout)\n        except tornado.iostream.StreamClosedError:\n            # Convert to 'SaltClientError' so that clients can handle this\n            # exception more appropriately.\n            raise SaltClientError('Connection to master lost')\n        raise tornado.gen.Return(ret)\n\n\nclass AsyncTCPPubChannel(salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel):\n    def __init__(self,\n                 opts,\n                 **kwargs):\n        self.opts = opts\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        self.crypt = kwargs.get('crypt', 'aes')\n        self.io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n        self.connected = False\n        self._closing = False\n        self._reconnected = False\n        self.event = salt.utils.event.get_event(\n            'minion',\n            opts=self.opts,\n            listen=False\n        )\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if hasattr(self, 'message_client'):\n            self.message_client.close()\n\n    def __del__(self):\n        self.close()\n\n    def _package_load(self, load):\n        return {\n            'enc': self.crypt,\n            'load': load,\n        }\n\n    @tornado.gen.coroutine\n    def send_id(self, tok, force_auth):\n        '''\n        Send the minion id to the master so that the master may better\n        track the connection state of the minion.\n        In case of authentication errors, try to renegotiate authentication\n        and retry the method.\n        '''\n        load = {'id': self.opts['id'], 'tok': tok}\n\n        @tornado.gen.coroutine\n        def _do_transfer():\n            msg = self._package_load(self.auth.crypticle.dumps(load))\n            package = salt.transport.frame.frame_msg(msg, header=None)\n            yield self.message_client.write_to_stream(package)\n            raise tornado.gen.Return(True)\n\n        if force_auth or not self.auth.authenticated:\n            count = 0\n            while count <= self.opts['tcp_authentication_retries'] or self.opts['tcp_authentication_retries'] < 0:\n                try:\n                    yield self.auth.authenticate()\n                    break\n                except SaltClientError as exc:\n                    log.debug(exc)\n                    count += 1\n        try:\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n        except salt.crypt.AuthenticationError:\n            yield self.auth.authenticate()\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def connect_callback(self, result):\n        if self._closing:\n            return\n        # Force re-auth on reconnect since the master\n        # may have been restarted\n        yield self.send_id(self.tok, self._reconnected)\n        self.connected = True\n        self.event.fire_event(\n            {'master': self.opts['master']},\n            '__master_connected'\n        )\n        if self._reconnected:\n            # On reconnects, fire a master event to notify that the minion is\n            # available.\n            if self.opts.get('__role') == 'syndic':\n                data = 'Syndic {0} started at {1}'.format(\n                    self.opts['id'],\n                    time.asctime()\n                )\n                tag = salt.utils.event.tagify(\n                    [self.opts['id'], 'start'],\n                    'syndic'\n                )\n            else:\n                data = 'Minion {0} started at {1}'.format(\n                    self.opts['id'],\n                    time.asctime()\n                )\n                tag = salt.utils.event.tagify(\n                    [self.opts['id'], 'start'],\n                    'minion'\n                )\n            load = {'id': self.opts['id'],\n                    'cmd': '_minion_event',\n                    'pretag': None,\n                    'tok': self.tok,\n                    'data': data,\n                    'tag': tag}\n            req_channel = salt.utils.async.SyncWrapper(\n                AsyncTCPReqChannel, (self.opts,)\n            )\n            try:\n                req_channel.send(load, timeout=60)\n            except salt.exceptions.SaltReqTimeoutError:\n                log.info('fire_master failed: master could not be contacted. Request timed out.')\n            except Exception:\n                log.info('fire_master failed: {0}'.format(\n                    traceback.format_exc())\n                )\n        else:\n            self._reconnected = True\n\n    def disconnect_callback(self):\n        if self._closing:\n            return\n        self.connected = False\n        self.event.fire_event(\n            {'master': self.opts['master']},\n            '__master_disconnected'\n        )\n\n    @tornado.gen.coroutine\n    def connect(self):\n        try:\n            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)\n            self.tok = self.auth.gen_token('salt')\n            if not self.auth.authenticated:\n                yield self.auth.authenticate()\n            if self.auth.authenticated:\n                self.message_client = SaltMessageClientPool(\n                    self.opts,\n                    args=(self.opts, self.opts['master_ip'], int(self.auth.creds['publish_port']),),\n                    kwargs={'io_loop': self.io_loop,\n                            'connect_callback': self.connect_callback,\n                            'disconnect_callback': self.disconnect_callback})\n                yield self.message_client.connect()  # wait for the client to be connected\n                self.connected = True\n        # TODO: better exception handling...\n        except KeyboardInterrupt:\n            raise\n        except Exception as exc:\n            if '-|RETRY|-' not in str(exc):\n                raise SaltClientError('Unable to sign_in to master: {0}'.format(exc))  # TODO: better error message\n\n    def on_recv(self, callback):\n        '''\n        Register an on_recv callback\n        '''\n        if callback is None:\n            return self.message_client.on_recv(callback)\n\n        @tornado.gen.coroutine\n        def wrap_callback(body):\n            if not isinstance(body, dict):\n                # TODO: For some reason we need to decode here for things\n                #       to work. Fix this.\n                body = msgpack.loads(body)\n                if six.PY3:\n                    body = salt.transport.frame.decode_embedded_strs(body)\n            ret = yield self._decode_payload(body)\n            callback(ret)\n        return self.message_client.on_recv(wrap_callback)\n\n\nclass TCPReqServerChannel(salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel):\n    # TODO: opts!\n    backlog = 5\n\n    def __init__(self, opts):\n        salt.transport.server.ReqServerChannel.__init__(self, opts)\n        self._socket = None\n\n    @property\n    def socket(self):\n        return self._socket\n\n    def close(self):\n        if self._socket is not None:\n            try:\n                self._socket.shutdown(socket.SHUT_RDWR)\n            except socket.error as exc:\n                if exc.errno == errno.ENOTCONN:\n                    # We may try to shutdown a socket which is already disconnected.\n                    # Ignore this condition and continue.\n                    pass\n                else:\n                    raise exc\n            self._socket.close()\n            self._socket = None\n\n    def __del__(self):\n        self.close()\n\n    def pre_fork(self, process_manager):\n        '''\n        Pre-fork we need to create the zmq router device\n        '''\n        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)\n        if USE_LOAD_BALANCER:\n            self.socket_queue = multiprocessing.Queue()\n            process_manager.add_process(\n                LoadBalancerServer, args=(self.opts, self.socket_queue)\n            )\n        elif not salt.utils.is_windows():\n            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            _set_tcp_keepalive(self._socket, self.opts)\n            self._socket.setblocking(0)\n            self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n\n    def post_fork(self, payload_handler, io_loop):\n        '''\n        After forking we need to create all of the local sockets to listen to the\n        router\n\n        payload_handler: function to call with your payloads\n        '''\n        self.payload_handler = payload_handler\n        self.io_loop = io_loop\n        self.serial = salt.payload.Serial(self.opts)\n        if USE_LOAD_BALANCER:\n            self.req_server = LoadBalancerWorker(self.socket_queue,\n                                                 self.handle_message,\n                                                 io_loop=self.io_loop,\n                                                 ssl_options=self.opts.get('ssl'))\n        else:\n            if salt.utils.is_windows():\n                self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                _set_tcp_keepalive(self._socket, self.opts)\n                self._socket.setblocking(0)\n                self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n            self.req_server = SaltMessageServer(self.handle_message,\n                                                io_loop=self.io_loop,\n                                                ssl_options=self.opts.get('ssl'))\n            self.req_server.add_socket(self._socket)\n            self._socket.listen(self.backlog)\n        salt.transport.mixins.auth.AESReqServerMixin.post_fork(self, payload_handler, io_loop)\n\n    @tornado.gen.coroutine\n    def handle_message(self, stream, header, payload):\n        '''\n        Handle incoming messages from underylying tcp streams\n        '''\n        try:\n            try:\n                payload = self._decode_payload(payload)\n            except Exception:\n                stream.write(salt.transport.frame.frame_msg('bad load', header=header))\n                raise tornado.gen.Return()\n\n            # TODO helper functions to normalize payload?\n            if not isinstance(payload, dict) or not isinstance(payload.get('load'), dict):\n                yield stream.write(salt.transport.frame.frame_msg(\n                    'payload and load must be a dict', header=header))\n                raise tornado.gen.Return()\n\n            # intercept the \"_auth\" commands, since the main daemon shouldn't know\n            # anything about our key auth\n            if payload['enc'] == 'clear' and payload.get('load', {}).get('cmd') == '_auth':\n                yield stream.write(salt.transport.frame.frame_msg(\n                    self._auth(payload['load']), header=header))\n                raise tornado.gen.Return()\n\n            # TODO: test\n            try:\n                ret, req_opts = yield self.payload_handler(payload)\n            except Exception as e:\n                # always attempt to return an error to the minion\n                stream.write('Some exception handling minion payload')\n                log.error('Some exception handling a payload from minion', exc_info=True)\n                stream.close()\n                raise tornado.gen.Return()\n\n            req_fun = req_opts.get('fun', 'send')\n            if req_fun == 'send_clear':\n                stream.write(salt.transport.frame.frame_msg(ret, header=header))\n            elif req_fun == 'send':\n                stream.write(salt.transport.frame.frame_msg(self.crypticle.dumps(ret), header=header))\n            elif req_fun == 'send_private':\n                stream.write(salt.transport.frame.frame_msg(self._encrypt_private(ret,\n                                                             req_opts['key'],\n                                                             req_opts['tgt'],\n                                                             ), header=header))\n            else:\n                log.error('Unknown req_fun {0}'.format(req_fun))\n                # always attempt to return an error to the minion\n                stream.write('Server-side exception handling payload')\n                stream.close()\n        except tornado.gen.Return:\n            raise\n        except tornado.iostream.StreamClosedError:\n            # Stream was closed. This could happen if the remote side\n            # closed the connection on its end (eg in a timeout or shutdown\n            # situation).\n            log.error('Connection was unexpectedly closed', exc_info=True)\n        except Exception as exc:  # pylint: disable=broad-except\n            # Absorb any other exceptions\n            log.error('Unexpected exception occurred: {0}'.format(exc), exc_info=True)\n\n        raise tornado.gen.Return()\n\n\nclass SaltMessageServer(tornado.tcpserver.TCPServer, object):\n    '''\n    Raw TCP server which will receive all of the TCP streams and re-assemble\n    messages that are sent through to us\n    '''\n    def __init__(self, message_handler, *args, **kwargs):\n        super(SaltMessageServer, self).__init__(*args, **kwargs)\n\n        self.clients = []\n        self.message_handler = message_handler\n\n    @tornado.gen.coroutine\n    def handle_stream(self, stream, address):\n        '''\n        Handle incoming streams and add messages to the incoming queue\n        '''\n        log.trace('Req client {0} connected'.format(address))\n        self.clients.append((stream, address))\n        unpacker = msgpack.Unpacker()\n        try:\n            while True:\n                wire_bytes = yield stream.read_bytes(4096, partial=True)\n                unpacker.feed(wire_bytes)\n                for framed_msg in unpacker:\n                    if six.PY3:\n                        framed_msg = salt.transport.frame.decode_embedded_strs(\n                            framed_msg\n                        )\n                    header = framed_msg['head']\n                    self.io_loop.spawn_callback(self.message_handler, stream, header, framed_msg['body'])\n\n        except tornado.iostream.StreamClosedError:\n            log.trace('req client disconnected {0}'.format(address))\n            self.clients.remove((stream, address))\n        except Exception as e:\n            log.trace('other master-side exception: {0}'.format(e))\n            self.clients.remove((stream, address))\n            stream.close()\n\n    def shutdown(self):\n        '''\n        Shutdown the whole server\n        '''\n        for item in self.clients:\n            client, address = item\n            client.close()\n            self.clients.remove(item)\n\n\nif USE_LOAD_BALANCER:\n    class LoadBalancerWorker(SaltMessageServer):\n        '''\n        This will receive TCP connections from 'LoadBalancerServer' via\n        a multiprocessing queue.\n        Since the queue is shared amongst workers, only one worker will handle\n        a given connection.\n        '''\n        def __init__(self, socket_queue, message_handler, *args, **kwargs):\n            super(LoadBalancerWorker, self).__init__(\n                message_handler, *args, **kwargs)\n            self.socket_queue = socket_queue\n\n            t = threading.Thread(target=self.socket_queue_thread)\n            t.start()\n\n        def socket_queue_thread(self):\n            try:\n                while True:\n                    client_socket, address = self.socket_queue.get(True, None)\n\n                    # 'self.io_loop' initialized in super class\n                    # 'tornado.tcpserver.TCPServer'.\n                    # 'self._handle_connection' defined in same super class.\n                    self.io_loop.spawn_callback(\n                        self._handle_connection, client_socket, address)\n            except (KeyboardInterrupt, SystemExit):\n                pass\n\n\nclass TCPClientKeepAlive(tornado.tcpclient.TCPClient):\n    '''\n    Override _create_stream() in TCPClient to enable keep alive support.\n    '''\n    def __init__(self, opts, resolver=None, io_loop=None):\n        self.opts = opts\n        super(TCPClientKeepAlive, self).__init__(\n            resolver=resolver, io_loop=io_loop)\n\n    def _create_stream(self, max_buffer_size, af, addr, **kwargs):  # pylint: disable=unused-argument\n        '''\n        Override _create_stream() in TCPClient.\n\n        Tornado 4.5 added the kwargs 'source_ip' and 'source_port'.\n        Due to this, use **kwargs to swallow these and any future\n        kwargs to maintain compatibility.\n        '''\n        # Always connect in plaintext; we'll convert to ssl if necessary\n        # after one connection has completed.\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        _set_tcp_keepalive(sock, self.opts)\n        stream = tornado.iostream.IOStream(\n            sock,\n            io_loop=self.io_loop,\n            max_buffer_size=max_buffer_size)\n        return stream.connect(addr)\n\n\nclass SaltMessageClientPool(salt.transport.MessageClientPool):\n    '''\n    Wrapper class of SaltMessageClient to avoid blocking waiting while writing data to socket.\n    '''\n    def __init__(self, opts, args=None, kwargs=None):\n        super(SaltMessageClientPool, self).__init__(SaltMessageClient, opts, args=args, kwargs=kwargs)\n\n    def __del__(self):\n        self.close()\n\n    def close(self):\n        for message_client in self.message_clients:\n            message_client.close()\n        self.message_clients = []\n\n    @tornado.gen.coroutine\n    def connect(self):\n        futures = []\n        for message_client in self.message_clients:\n            futures.append(message_client.connect())\n        for future in futures:\n            yield future\n        raise tornado.gen.Return(None)\n\n    def on_recv(self, *args, **kwargs):\n        for message_client in self.message_clients:\n            message_client.on_recv(*args, **kwargs)\n\n    def send(self, *args, **kwargs):\n        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))\n        return message_clients[0].send(*args, **kwargs)\n\n    def write_to_stream(self, *args, **kwargs):\n        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))\n        return message_clients[0]._stream.write(*args, **kwargs)\n\n\n# TODO consolidate with IPCClient\n# TODO: limit in-flight messages.\n# TODO: singleton? Something to not re-create the tcp connection so much\nclass SaltMessageClient(object):\n    '''\n    Low-level message sending client\n    '''\n    def __init__(self, opts, host, port, io_loop=None, resolver=None,\n                 connect_callback=None, disconnect_callback=None):\n        self.opts = opts\n        self.host = host\n        self.port = port\n        self.connect_callback = connect_callback\n        self.disconnect_callback = disconnect_callback\n\n        self.io_loop = io_loop or tornado.ioloop.IOLoop.current()\n\n        self._tcp_client = TCPClientKeepAlive(\n            opts, io_loop=self.io_loop, resolver=resolver)\n\n        self._mid = 1\n        self._max_messages = int((1 << 31) - 2)  # number of IDs before we wrap\n\n        # TODO: max queue size\n        self.send_queue = []  # queue of messages to be sent\n        self.send_future_map = {}  # mapping of request_id -> Future\n        self.send_timeout_map = {}  # request_id -> timeout_callback\n\n        self._read_until_future = None\n        self._on_recv = None\n        self._closing = False\n        self._connecting_future = self.connect()\n        self._stream_return_future = tornado.concurrent.Future()\n        self.io_loop.spawn_callback(self._stream_return)\n\n    # TODO: timeout inflight sessions\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if hasattr(self, '_stream') and not self._stream.closed():\n            self._stream.close()\n            if self._read_until_future is not None:\n                # This will prevent this message from showing up:\n                # '[ERROR   ] Future exception was never retrieved:\n                # StreamClosedError'\n                # This happens because the logic is always waiting to read\n                # the next message and the associated read future is marked\n                # 'StreamClosedError' when the stream is closed.\n                self._read_until_future.exc_info()\n                if (not self._stream_return_future.done() and\n                        self.io_loop != tornado.ioloop.IOLoop.current(\n                            instance=False)):\n                    # If _stream_return() hasn't completed, it means the IO\n                    # Loop is stopped (such as when using\n                    # 'salt.utils.async.SyncWrapper'). Ensure that\n                    # _stream_return() completes by restarting the IO Loop.\n                    # This will prevent potential errors on shutdown.\n                    orig_loop = tornado.ioloop.IOLoop.current()\n                    self.io_loop.make_current()\n                    try:\n                        self.io_loop.add_future(\n                            self._stream_return_future,\n                            lambda future: self.io_loop.stop()\n                        )\n                        self.io_loop.start()\n                    finally:\n                        orig_loop.make_current()\n        self._tcp_client.close()\n        # Clear callback references to allow the object that they belong to\n        # to be deleted.\n        self.connect_callback = None\n        self.disconnect_callback = None\n\n    def __del__(self):\n        self.close()\n\n    def connect(self):\n        '''\n        Ask for this client to reconnect to the origin\n        '''\n        if hasattr(self, '_connecting_future') and not self._connecting_future.done():\n            future = self._connecting_future\n        else:\n            future = tornado.concurrent.Future()\n            self._connecting_future = future\n            self.io_loop.add_callback(self._connect)\n\n            # Add the callback only when a new future is created\n            if self.connect_callback is not None:\n                def handle_future(future):\n                    response = future.result()\n                    self.io_loop.add_callback(self.connect_callback, response)\n                future.add_done_callback(handle_future)\n\n        return future\n\n    # TODO: tcp backoff opts\n    @tornado.gen.coroutine\n    def _connect(self):\n        '''\n        Try to connect for the rest of time!\n        '''\n        while True:\n            if self._closing:\n                break\n            try:\n                self._stream = yield self._tcp_client.connect(self.host,\n                                                              self.port,\n                                                              ssl_options=self.opts.get('ssl'))\n                self._connecting_future.set_result(True)\n                break\n            except Exception as e:\n                yield tornado.gen.sleep(1)  # TODO: backoff\n                #self._connecting_future.set_exception(e)\n\n    @tornado.gen.coroutine\n    def _stream_return(self):\n        try:\n            while not self._closing and (\n                    not self._connecting_future.done() or\n                    self._connecting_future.result() is not True):\n                yield self._connecting_future\n            unpacker = msgpack.Unpacker()\n            while not self._closing:\n                try:\n                    self._read_until_future = self._stream.read_bytes(4096, partial=True)\n                    wire_bytes = yield self._read_until_future\n                    unpacker.feed(wire_bytes)\n                    for framed_msg in unpacker:\n                        if six.PY3:\n                            framed_msg = salt.transport.frame.decode_embedded_strs(\n                                framed_msg\n                            )\n                        header = framed_msg['head']\n                        body = framed_msg['body']\n                        message_id = header.get('mid')\n\n                        if message_id in self.send_future_map:\n                            self.send_future_map.pop(message_id).set_result(body)\n                            self.remove_message_timeout(message_id)\n                        else:\n                            if self._on_recv is not None:\n                                self.io_loop.spawn_callback(self._on_recv, header, body)\n                            else:\n                                log.error('Got response for message_id {0} that we are not tracking'.format(message_id))\n                except tornado.iostream.StreamClosedError as e:\n                    log.debug('tcp stream to {0}:{1} closed, unable to recv'.format(self.host, self.port))\n                    for future in six.itervalues(self.send_future_map):\n                        future.set_exception(e)\n                    self.send_future_map = {}\n                    if self._closing:\n                        return\n                    if self.disconnect_callback:\n                        self.disconnect_callback()\n                    # if the last connect finished, then we need to make a new one\n                    if self._connecting_future.done():\n                        self._connecting_future = self.connect()\n                    yield self._connecting_future\n                except TypeError:\n                    # This is an invalid transport\n                    if 'detect_mode' in self.opts:\n                        log.info('There was an error trying to use TCP transport; '\n                                 'attempting to fallback to another transport')\n                    else:\n                        raise SaltClientError\n                except Exception as e:\n                    log.error('Exception parsing response', exc_info=True)\n                    for future in six.itervalues(self.send_future_map):\n                        future.set_exception(e)\n                    self.send_future_map = {}\n                    if self._closing:\n                        return\n                    if self.disconnect_callback:\n                        self.disconnect_callback()\n                    # if the last connect finished, then we need to make a new one\n                    if self._connecting_future.done():\n                        self._connecting_future = self.connect()\n                    yield self._connecting_future\n        finally:\n            self._stream_return_future.set_result(True)\n\n    @tornado.gen.coroutine\n    def _stream_send(self):\n        while not self._connecting_future.done() or self._connecting_future.result() is not True:\n            yield self._connecting_future\n        while len(self.send_queue) > 0:\n            message_id, item = self.send_queue[0]\n            try:\n                yield self._stream.write(item)\n                del self.send_queue[0]\n            # if the connection is dead, lets fail this send, and make sure we\n            # attempt to reconnect\n            except tornado.iostream.StreamClosedError as e:\n                if message_id in self.send_future_map:\n                    self.send_future_map.pop(message_id).set_exception(e)\n                self.remove_message_timeout(message_id)\n                del self.send_queue[0]\n                if self._closing:\n                    return\n                if self.disconnect_callback:\n                    self.disconnect_callback()\n                # if the last connect finished, then we need to make a new one\n                if self._connecting_future.done():\n                    self._connecting_future = self.connect()\n                yield self._connecting_future\n\n    def _message_id(self):\n        wrap = False\n        while self._mid in self.send_future_map:\n            if self._mid >= self._max_messages:\n                if wrap:\n                    # this shouldn't ever happen, but just in case\n                    raise Exception('Unable to find available messageid')\n                self._mid = 1\n                wrap = True\n            else:\n                self._mid += 1\n\n        return self._mid\n\n    # TODO: return a message object which takes care of multiplexing?\n    def on_recv(self, callback):\n        '''\n        Register a callback for received messages (that we didn't initiate)\n        '''\n        if callback is None:\n            self._on_recv = callback\n        else:\n            def wrap_recv(header, body):\n                callback(body)\n            self._on_recv = wrap_recv\n\n    def remove_message_timeout(self, message_id):\n        if message_id not in self.send_timeout_map:\n            return\n        timeout = self.send_timeout_map.pop(message_id)\n        self.io_loop.remove_timeout(timeout)\n\n    def timeout_message(self, message_id):\n        if message_id in self.send_timeout_map:\n            del self.send_timeout_map[message_id]\n        if message_id in self.send_future_map:\n            self.send_future_map.pop(message_id).set_exception(\n                SaltReqTimeoutError('Message timed out')\n            )\n\n    def send(self, msg, timeout=None, callback=None, raw=False):\n        '''\n        Send given message, and return a future\n        '''\n        message_id = self._message_id()\n        header = {'mid': message_id}\n\n        future = tornado.concurrent.Future()\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n        # Add this future to the mapping\n        self.send_future_map[message_id] = future\n\n        if self.opts.get('detect_mode') is True:\n            timeout = 1\n\n        if timeout is not None:\n            send_timeout = self.io_loop.call_later(timeout, self.timeout_message, message_id)\n            self.send_timeout_map[message_id] = send_timeout\n\n        # if we don't have a send queue, we need to spawn the callback to do the sending\n        if len(self.send_queue) == 0:\n            self.io_loop.spawn_callback(self._stream_send)\n        self.send_queue.append((message_id, salt.transport.frame.frame_msg(msg, header=header)))\n        return future\n\n\nclass Subscriber(object):\n    '''\n    Client object for use with the TCP publisher server\n    '''\n    def __init__(self, stream, address):\n        self.stream = stream\n        self.address = address\n        self._closing = False\n        self._read_until_future = None\n        self.id_ = None\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if not self.stream.closed():\n            self.stream.close()\n            if self._read_until_future is not None:\n                # This will prevent this message from showing up:\n                # '[ERROR   ] Future exception was never retrieved:\n                # StreamClosedError'\n                # This happens because the logic is always waiting to read\n                # the next message and the associated read future is marked\n                # 'StreamClosedError' when the stream is closed.\n                self._read_until_future.exc_info()\n\n    def __del__(self):\n        self.close()\n\n\nclass PubServer(tornado.tcpserver.TCPServer, object):\n    '''\n    TCP publisher\n    '''\n    def __init__(self, opts, io_loop=None):\n        super(PubServer, self).__init__(io_loop=io_loop, ssl_options=opts.get('ssl'))\n        self.opts = opts\n        self._closing = False\n        self.clients = set()\n        self.aes_funcs = salt.master.AESFuncs(self.opts)\n        self.present = {}\n        self.presence_events = False\n        if self.opts.get('presence_events', False):\n            tcp_only = True\n            for transport, _ in iter_transport_opts(self.opts):\n                if transport != 'tcp':\n                    tcp_only = False\n            if tcp_only:\n                # Only when the transport is TCP only, the presence events will\n                # be handled here. Otherwise, it will be handled in the\n                # 'Maintenance' process.\n                self.presence_events = True\n\n        if self.presence_events:\n            self.event = salt.utils.event.get_event(\n                'master',\n                opts=self.opts,\n                listen=False\n            )\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n\n    def __del__(self):\n        self.close()\n\n    def _add_client_present(self, client):\n        id_ = client.id_\n        if id_ in self.present:\n            clients = self.present[id_]\n            clients.add(client)\n        else:\n            self.present[id_] = set([client])\n            if self.presence_events:\n                data = {'new': [id_],\n                        'lost': []}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('change', 'presence')\n                )\n                data = {'present': list(self.present.keys())}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('present', 'presence')\n                )\n\n    def _remove_client_present(self, client):\n        id_ = client.id_\n        if id_ is None or id_ not in self.present:\n            # This is possible if _remove_client_present() is invoked\n            # before the minion's id is validated.\n            return\n\n        clients = self.present[id_]\n        if client not in clients:\n            # Since _remove_client_present() is potentially called from\n            # _stream_read() and/or publish_payload(), it is possible for\n            # it to be called twice, in which case we will get here.\n            # This is not an abnormal case, so no logging is required.\n            return\n\n        clients.remove(client)\n        if len(clients) == 0:\n            del self.present[id_]\n            if self.presence_events:\n                data = {'new': [],\n                        'lost': [id_]}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('change', 'presence')\n                )\n                data = {'present': list(self.present.keys())}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('present', 'presence')\n                )\n\n    @tornado.gen.coroutine\n    def _stream_read(self, client):\n        unpacker = msgpack.Unpacker()\n        while not self._closing:\n            try:\n                client._read_until_future = client.stream.read_bytes(4096, partial=True)\n                wire_bytes = yield client._read_until_future\n                unpacker.feed(wire_bytes)\n                for framed_msg in unpacker:\n                    if six.PY3:\n                        framed_msg = salt.transport.frame.decode_embedded_strs(\n                            framed_msg\n                        )\n                    body = framed_msg['body']\n                    if body['enc'] != 'aes':\n                        # We only accept 'aes' encoded messages for 'id'\n                        continue\n                    crypticle = salt.crypt.Crypticle(self.opts, salt.master.SMaster.secrets['aes']['secret'].value)\n                    load = crypticle.loads(body['load'])\n                    if six.PY3:\n                        load = salt.transport.frame.decode_embedded_strs(load)\n                    if not self.aes_funcs.verify_minion(load['id'], load['tok']):\n                        continue\n                    client.id_ = load['id']\n                    self._add_client_present(client)\n            except tornado.iostream.StreamClosedError as e:\n                log.debug('tcp stream to {0} closed, unable to recv'.format(client.address))\n                client.close()\n                self._remove_client_present(client)\n                self.clients.discard(client)\n                break\n            except Exception as e:\n                log.error('Exception parsing response', exc_info=True)\n                continue\n\n    def handle_stream(self, stream, address):\n        log.trace('Subscriber at {0} connected'.format(address))\n        client = Subscriber(stream, address)\n        self.clients.add(client)\n        self.io_loop.spawn_callback(self._stream_read, client)\n\n    # TODO: ACK the publish through IPC\n    @tornado.gen.coroutine\n    def publish_payload(self, package, _):\n        log.debug('TCP PubServer sending payload: {0}'.format(package))\n        payload = salt.transport.frame.frame_msg(package['payload'])\n\n        to_remove = []\n        if 'topic_lst' in package:\n            topic_lst = package['topic_lst']\n            for topic in topic_lst:\n                if topic in self.present:\n                    # This will rarely be a list of more than 1 item. It will\n                    # be more than 1 item if the minion disconnects from the\n                    # master in an unclean manner (eg cable yank), then\n                    # restarts and the master is yet to detect the disconnect\n                    # via TCP keep-alive.\n                    for client in self.present[topic]:\n                        try:\n                            # Write the packed str\n                            f = client.stream.write(payload)\n                            self.io_loop.add_future(f, lambda f: True)\n                        except tornado.iostream.StreamClosedError:\n                            to_remove.append(client)\n                else:\n                    log.debug('Publish target {0} not connected'.format(topic))\n        else:\n            for client in self.clients:\n                try:\n                    # Write the packed str\n                    f = client.stream.write(payload)\n                    self.io_loop.add_future(f, lambda f: True)\n                except tornado.iostream.StreamClosedError:\n                    to_remove.append(client)\n        for client in to_remove:\n            log.debug('Subscriber at {0} has disconnected from publisher'.format(client.address))\n            client.close()\n            self._remove_client_present(client)\n            self.clients.discard(client)\n        log.trace('TCP PubServer finished publishing payload')\n\n\nclass TCPPubServerChannel(salt.transport.server.PubServerChannel):\n    # TODO: opts!\n    # Based on default used in tornado.netutil.bind_sockets()\n    backlog = 128\n\n    def __init__(self, opts):\n        self.opts = opts\n        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?\n        self.io_loop = None\n\n    def __setstate__(self, state):\n        salt.master.SMaster.secrets = state['secrets']\n        self.__init__(state['opts'])\n\n    def __getstate__(self):\n        return {'opts': self.opts,\n                'secrets': salt.master.SMaster.secrets}\n\n    def _publish_daemon(self, log_queue=None):\n        '''\n        Bind to the interface specified in the configuration file\n        '''\n        salt.utils.appendproctitle(self.__class__.__name__)\n\n        if log_queue is not None:\n            salt.log.setup.set_multiprocessing_logging_queue(log_queue)\n        salt.log.setup.setup_multiprocessing_logging(log_queue)\n\n        # Check if io_loop was set outside\n        if self.io_loop is None:\n            self.io_loop = tornado.ioloop.IOLoop.current()\n\n        # Spin up the publisher\n        pub_server = PubServer(self.opts, io_loop=self.io_loop)\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        _set_tcp_keepalive(sock, self.opts)\n        sock.setblocking(0)\n        sock.bind((self.opts['interface'], int(self.opts['publish_port'])))\n        sock.listen(self.backlog)\n        # pub_server will take ownership of the socket\n        pub_server.add_socket(sock)\n\n        # Set up Salt IPC server\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = int(self.opts.get('tcp_master_publish_pull', 4514))\n        else:\n            pull_uri = os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n\n        pull_sock = salt.transport.ipc.IPCMessageServer(\n            pull_uri,\n            io_loop=self.io_loop,\n            payload_handler=pub_server.publish_payload,\n        )\n\n        # Securely create socket\n        log.info('Starting the Salt Puller on {0}'.format(pull_uri))\n        old_umask = os.umask(0o177)\n        try:\n            pull_sock.start()\n        finally:\n            os.umask(old_umask)\n\n        # run forever\n        try:\n            self.io_loop.start()\n        except (KeyboardInterrupt, SystemExit):\n            salt.log.setup.shutdown_multiprocessing_logging()\n\n    def pre_fork(self, process_manager):\n        '''\n        Do anything necessary pre-fork. Since this is on the master side this will\n        primarily be used to create IPC channels and create our daemon process to\n        do the actual publishing\n        '''\n        kwargs = {}\n        if salt.utils.is_windows():\n            kwargs['log_queue'] = (\n                salt.log.setup.get_multiprocessing_logging_queue()\n            )\n\n        process_manager.add_process(self._publish_daemon, kwargs=kwargs)\n\n    def publish(self, load):\n        '''\n        Publish \"load\" to minions\n        '''\n        payload = {'enc': 'aes'}\n\n        crypticle = salt.crypt.Crypticle(self.opts, salt.master.SMaster.secrets['aes']['secret'].value)\n        payload['load'] = crypticle.dumps(load)\n        if self.opts['sign_pub_messages']:\n            master_pem_path = os.path.join(self.opts['pki_dir'], 'master.pem')\n            log.debug(\"Signing data packet\")\n            payload['sig'] = salt.crypt.sign_message(master_pem_path, payload['load'])\n        # Use the Salt IPC server\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = int(self.opts.get('tcp_master_publish_pull', 4514))\n        else:\n            pull_uri = os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n        # TODO: switch to the actual async interface\n        #pub_sock = salt.transport.ipc.IPCMessageClient(self.opts, io_loop=self.io_loop)\n        pub_sock = salt.utils.async.SyncWrapper(\n            salt.transport.ipc.IPCMessageClient,\n            (pull_uri,)\n        )\n        pub_sock.connect()\n\n        int_payload = {'payload': self.serial.dumps(payload)}\n\n        # add some targeting stuff for lists only (for now)\n        if load['tgt_type'] == 'list':\n            int_payload['topic_lst'] = load['tgt']\n        # Send it over IPC!\n        pub_sock.send(int_payload)\n", "# -*- coding: utf-8 -*-\n'''\nZeromq transport classes\n'''\n\n# Import Python Libs\nfrom __future__ import absolute_import\nimport os\nimport sys\nimport copy\nimport errno\nimport signal\nimport hashlib\nimport logging\nimport weakref\nfrom random import randint\n\n# Import Salt Libs\nimport salt.auth\nimport salt.crypt\nimport salt.utils\nimport salt.utils.verify\nimport salt.utils.event\nimport salt.payload\nimport salt.transport.client\nimport salt.transport.server\nimport salt.transport.mixins.auth\nfrom salt.exceptions import SaltReqTimeoutError\n\nimport zmq\nimport zmq.error\nimport zmq.eventloop.ioloop\n# support pyzmq 13.0.x, TODO: remove once we force people to 14.0.x\nif not hasattr(zmq.eventloop.ioloop, 'ZMQIOLoop'):\n    zmq.eventloop.ioloop.ZMQIOLoop = zmq.eventloop.ioloop.IOLoop\nimport zmq.eventloop.zmqstream\ntry:\n    import zmq.utils.monitor\n    HAS_ZMQ_MONITOR = True\nexcept ImportError:\n    HAS_ZMQ_MONITOR = False\n\n# Import Tornado Libs\nimport tornado\nimport tornado.gen\nimport tornado.concurrent\n\n# Import third party libs\nimport salt.ext.six as six\ntry:\n    from Cryptodome.Cipher import PKCS1_OAEP\nexcept ImportError:\n    from Crypto.Cipher import PKCS1_OAEP\n\nlog = logging.getLogger(__name__)\n\n\nclass AsyncZeroMQReqChannel(salt.transport.client.ReqChannel):\n    '''\n    Encapsulate sending routines to ZeroMQ.\n\n    ZMQ Channels default to 'crypt=aes'\n    '''\n    # This class is only a singleton per minion/master pair\n    # mapping of io_loop -> {key -> channel}\n    instance_map = weakref.WeakKeyDictionary()\n\n    def __new__(cls, opts, **kwargs):\n        '''\n        Only create one instance of channel per __key()\n        '''\n\n        # do we have any mapping for this io_loop\n        io_loop = kwargs.get('io_loop')\n        if io_loop is None:\n            zmq.eventloop.ioloop.install()\n            io_loop = tornado.ioloop.IOLoop.current()\n        if io_loop not in cls.instance_map:\n            cls.instance_map[io_loop] = weakref.WeakValueDictionary()\n        loop_instance_map = cls.instance_map[io_loop]\n\n        key = cls.__key(opts, **kwargs)\n        obj = loop_instance_map.get(key)\n        if obj is None:\n            log.debug('Initializing new AsyncZeroMQReqChannel for {0}'.format(key))\n            # we need to make a local variable for this, as we are going to store\n            # it in a WeakValueDictionary-- which will remove the item if no one\n            # references it-- this forces a reference while we return to the caller\n            obj = object.__new__(cls)\n            obj.__singleton_init__(opts, **kwargs)\n            loop_instance_map[key] = obj\n            log.trace('Inserted key into loop_instance_map id {0} for key {1} and process {2}'.format(id(loop_instance_map), key, os.getpid()))\n        else:\n            log.debug('Re-using AsyncZeroMQReqChannel for {0}'.format(key))\n        return obj\n\n    def __deepcopy__(self, memo):\n        cls = self.__class__\n        result = cls.__new__(cls, copy.deepcopy(self.opts, memo))  # pylint: disable=too-many-function-args\n        memo[id(self)] = result\n        for key in self.__dict__:\n            if key in ('_io_loop',):\n                continue\n                # The _io_loop has a thread Lock which will fail to be deep\n                # copied. Skip it because it will just be recreated on the\n                # new copy.\n            if key == 'message_client':\n                # Recreate the message client because it will fail to be deep\n                # copied. The reason is the same as the io_loop skip above.\n                setattr(result, key,\n                        AsyncReqMessageClientPool(result.opts,\n                                                  args=(result.opts, self.master_uri,),\n                                                  kwargs={'io_loop': self._io_loop}))\n\n                continue\n            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))\n        return result\n\n    @classmethod\n    def __key(cls, opts, **kwargs):\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                kwargs.get('master_uri', opts.get('master_uri')),  # master ID\n                kwargs.get('crypt', 'aes'),  # TODO: use the same channel for crypt\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, **kwargs):\n        pass\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, **kwargs):\n        self.opts = dict(opts)\n        self.ttype = 'zeromq'\n\n        # crypt defaults to 'aes'\n        self.crypt = kwargs.get('crypt', 'aes')\n\n        if 'master_uri' in kwargs:\n            self.opts['master_uri'] = kwargs['master_uri']\n\n        self._io_loop = kwargs.get('io_loop')\n        if self._io_loop is None:\n            zmq.eventloop.ioloop.install()\n            self._io_loop = tornado.ioloop.IOLoop.current()\n\n        if self.crypt != 'clear':\n            # we don't need to worry about auth as a kwarg, since its a singleton\n            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self._io_loop)\n        self.message_client = AsyncReqMessageClientPool(self.opts,\n                                                        args=(self.opts, self.master_uri,),\n                                                        kwargs={'io_loop': self._io_loop})\n\n    def __del__(self):\n        '''\n        Since the message_client creates sockets and assigns them to the IOLoop we have to\n        specifically destroy them, since we aren't the only ones with references to the FDs\n        '''\n        if hasattr(self, 'message_client'):\n            self.message_client.destroy()\n        else:\n            log.debug('No message_client attr for AsyncZeroMQReqChannel found. Not destroying sockets.')\n\n    @property\n    def master_uri(self):\n        return self.opts['master_uri']\n\n    def _package_load(self, load):\n        return {\n            'enc': self.crypt,\n            'load': load,\n        }\n\n    @tornado.gen.coroutine\n    def crypted_transfer_decode_dictentry(self, load, dictkey=None, tries=3, timeout=60):\n        if not self.auth.authenticated:\n            # Return controle back to the caller, continue when authentication succeeds\n            yield self.auth.authenticate()\n        # Return control to the caller. When send() completes, resume by populating ret with the Future.result\n        ret = yield self.message_client.send(\n            self._package_load(self.auth.crypticle.dumps(load)),\n            timeout=timeout,\n            tries=tries,\n        )\n        key = self.auth.get_keys()\n        cipher = PKCS1_OAEP.new(key)\n        if 'key' not in ret:\n            # Reauth in the case our key is deleted on the master side.\n            yield self.auth.authenticate()\n            ret = yield self.message_client.send(\n                self._package_load(self.auth.crypticle.dumps(load)),\n                timeout=timeout,\n                tries=tries,\n            )\n        aes = cipher.decrypt(ret['key'])\n        pcrypt = salt.crypt.Crypticle(self.opts, aes)\n        data = pcrypt.loads(ret[dictkey])\n        if six.PY3:\n            data = salt.transport.frame.decode_embedded_strs(data)\n        raise tornado.gen.Return(data)\n\n    @tornado.gen.coroutine\n    def _crypted_transfer(self, load, tries=3, timeout=60, raw=False):\n        '''\n        Send a load across the wire, with encryption\n\n        In case of authentication errors, try to renegotiate authentication\n        and retry the method.\n\n        Indeed, we can fail too early in case of a master restart during a\n        minion state execution call\n\n        :param dict load: A load to send across the wire\n        :param int tries: The number of times to make before failure\n        :param int timeout: The number of seconds on a response before failing\n        '''\n        @tornado.gen.coroutine\n        def _do_transfer():\n            # Yield control to the caller. When send() completes, resume by populating data with the Future.result\n            data = yield self.message_client.send(\n                self._package_load(self.auth.crypticle.dumps(load)),\n                timeout=timeout,\n                tries=tries,\n            )\n            # we may not have always data\n            # as for example for saltcall ret submission, this is a blind\n            # communication, we do not subscribe to return events, we just\n            # upload the results to the master\n            if data:\n                data = self.auth.crypticle.loads(data, raw)\n            if six.PY3 and not raw:\n                data = salt.transport.frame.decode_embedded_strs(data)\n            raise tornado.gen.Return(data)\n        if not self.auth.authenticated:\n            # Return control back to the caller, resume when authentication succeeds\n            yield self.auth.authenticate()\n        try:\n            # We did not get data back the first time. Retry.\n            ret = yield _do_transfer()\n        except salt.crypt.AuthenticationError:\n            # If auth error, return control back to the caller, continue when authentication succeeds\n            yield self.auth.authenticate()\n            ret = yield _do_transfer()\n        raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def _uncrypted_transfer(self, load, tries=3, timeout=60):\n        '''\n        Send a load across the wire in cleartext\n\n        :param dict load: A load to send across the wire\n        :param int tries: The number of times to make before failure\n        :param int timeout: The number of seconds on a response before failing\n        '''\n        ret = yield self.message_client.send(\n            self._package_load(load),\n            timeout=timeout,\n            tries=tries,\n        )\n\n        raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def send(self, load, tries=3, timeout=60, raw=False):\n        '''\n        Send a request, return a future which will complete when we send the message\n        '''\n        if self.crypt == 'clear':\n            ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)\n        else:\n            ret = yield self._crypted_transfer(load, tries=tries, timeout=timeout, raw=raw)\n        raise tornado.gen.Return(ret)\n\n\nclass AsyncZeroMQPubChannel(salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel):\n    '''\n    A transport channel backed by ZeroMQ for a Salt Publisher to use to\n    publish commands to connected minions\n    '''\n    def __init__(self,\n                 opts,\n                 **kwargs):\n        self.opts = opts\n        self.ttype = 'zeromq'\n\n        self.io_loop = kwargs.get('io_loop')\n        if self.io_loop is None:\n            zmq.eventloop.ioloop.install()\n            self.io_loop = tornado.ioloop.IOLoop.current()\n\n        self.hexid = hashlib.sha1(six.b(self.opts['id'])).hexdigest()\n\n        self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        self.context = zmq.Context()\n        self._socket = self.context.socket(zmq.SUB)\n\n        if self.opts['zmq_filtering']:\n            # TODO: constants file for \"broadcast\"\n            self._socket.setsockopt(zmq.SUBSCRIBE, b'broadcast')\n            self._socket.setsockopt(zmq.SUBSCRIBE, self.hexid)\n        else:\n            self._socket.setsockopt(zmq.SUBSCRIBE, b'')\n\n        self._socket.setsockopt(zmq.IDENTITY, salt.utils.to_bytes(self.opts['id']))\n\n        # TODO: cleanup all the socket opts stuff\n        if hasattr(zmq, 'TCP_KEEPALIVE'):\n            self._socket.setsockopt(\n                zmq.TCP_KEEPALIVE, self.opts['tcp_keepalive']\n            )\n            self._socket.setsockopt(\n                zmq.TCP_KEEPALIVE_IDLE, self.opts['tcp_keepalive_idle']\n            )\n            self._socket.setsockopt(\n                zmq.TCP_KEEPALIVE_CNT, self.opts['tcp_keepalive_cnt']\n            )\n            self._socket.setsockopt(\n                zmq.TCP_KEEPALIVE_INTVL, self.opts['tcp_keepalive_intvl']\n            )\n\n        recon_delay = self.opts['recon_default']\n\n        if self.opts['recon_randomize']:\n            recon_delay = randint(self.opts['recon_default'],\n                                  self.opts['recon_default'] + self.opts['recon_max']\n                          )\n\n            log.debug(\"Generated random reconnect delay between '{0}ms' and '{1}ms' ({2})\".format(\n                self.opts['recon_default'],\n                self.opts['recon_default'] + self.opts['recon_max'],\n                recon_delay)\n            )\n\n        log.debug(\"Setting zmq_reconnect_ivl to '{0}ms'\".format(recon_delay))\n        self._socket.setsockopt(zmq.RECONNECT_IVL, recon_delay)\n\n        if hasattr(zmq, 'RECONNECT_IVL_MAX'):\n            log.debug(\"Setting zmq_reconnect_ivl_max to '{0}ms'\".format(\n                self.opts['recon_default'] + self.opts['recon_max'])\n            )\n\n            self._socket.setsockopt(\n                zmq.RECONNECT_IVL_MAX, self.opts['recon_max']\n            )\n\n        if (self.opts['ipv6'] is True or ':' in self.opts['master_ip']) and hasattr(zmq, 'IPV4ONLY'):\n            # IPv6 sockets work for both IPv6 and IPv4 addresses\n            self._socket.setsockopt(zmq.IPV4ONLY, 0)\n\n        if HAS_ZMQ_MONITOR and self.opts['zmq_monitor']:\n            self._monitor = ZeroMQSocketMonitor(self._socket)\n            self._monitor.start_io_loop(self.io_loop)\n\n    def destroy(self):\n        if hasattr(self, '_monitor') and self._monitor is not None:\n            self._monitor.stop()\n            self._monitor = None\n        if hasattr(self, '_stream'):\n            # TODO: Optionally call stream.close() on newer pyzmq? Its broken on some\n            self._stream.io_loop.remove_handler(self._stream.socket)\n            self._stream.socket.close(0)\n        elif hasattr(self, '_socket'):\n            self._socket.close(0)\n        if hasattr(self, 'context') and self.context.closed is False:\n            self.context.term()\n\n    def __del__(self):\n        self.destroy()\n\n    # TODO: this is the time to see if we are connected, maybe use the req channel to guess?\n    @tornado.gen.coroutine\n    def connect(self):\n        if not self.auth.authenticated:\n            yield self.auth.authenticate()\n        self.publish_port = self.auth.creds['publish_port']\n        self._socket.connect(self.master_pub)\n\n    @property\n    def master_pub(self):\n        '''\n        Return the master publish port\n        '''\n        return 'tcp://{ip}:{port}'.format(ip=self.opts['master_ip'],\n                                          port=self.publish_port)\n\n    @tornado.gen.coroutine\n    def _decode_messages(self, messages):\n        '''\n        Take the zmq messages, decrypt/decode them into a payload\n\n        :param list messages: A list of messages to be decoded\n        '''\n        messages_len = len(messages)\n        # if it was one message, then its old style\n        if messages_len == 1:\n            payload = self.serial.loads(messages[0])\n        # 2 includes a header which says who should do it\n        elif messages_len == 2:\n            if messages[0] not in ('broadcast', self.hexid):\n                log.debug('Publish received for not this minion: {0}'.format(messages[0]))\n                raise tornado.gen.Return(None)\n            payload = self.serial.loads(messages[1])\n        else:\n            raise Exception(('Invalid number of messages ({0}) in zeromq pub'\n                             'message from master').format(len(messages_len)))\n        # Yield control back to the caller. When the payload has been decoded, assign\n        # the decoded payload to 'ret' and resume operation\n        ret = yield self._decode_payload(payload)\n        raise tornado.gen.Return(ret)\n\n    @property\n    def stream(self):\n        '''\n        Return the current zmqstream, creating one if necessary\n        '''\n        if not hasattr(self, '_stream'):\n            self._stream = zmq.eventloop.zmqstream.ZMQStream(self._socket, io_loop=self.io_loop)\n        return self._stream\n\n    def on_recv(self, callback):\n        '''\n        Register a callback for received messages (that we didn't initiate)\n\n        :param func callback: A function which should be called when data is received\n        '''\n        if callback is None:\n            return self.stream.on_recv(None)\n\n        @tornado.gen.coroutine\n        def wrap_callback(messages):\n            payload = yield self._decode_messages(messages)\n            if payload is not None:\n                callback(payload)\n        return self.stream.on_recv(wrap_callback)\n\n\nclass ZeroMQReqServerChannel(salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel):\n\n    def __init__(self, opts):\n        salt.transport.server.ReqServerChannel.__init__(self, opts)\n        self._closing = False\n\n    def zmq_device(self):\n        '''\n        Multiprocessing target for the zmq queue device\n        '''\n        self.__setup_signals()\n        salt.utils.appendproctitle('MWorkerQueue')\n        self.context = zmq.Context(self.opts['worker_threads'])\n        # Prepare the zeromq sockets\n        self.uri = 'tcp://{interface}:{ret_port}'.format(**self.opts)\n        self.clients = self.context.socket(zmq.ROUTER)\n        if self.opts['ipv6'] is True and hasattr(zmq, 'IPV4ONLY'):\n            # IPv6 sockets work for both IPv6 and IPv4 addresses\n            self.clients.setsockopt(zmq.IPV4ONLY, 0)\n        self.clients.setsockopt(zmq.BACKLOG, self.opts.get('zmq_backlog', 1000))\n        if HAS_ZMQ_MONITOR and self.opts['zmq_monitor']:\n            # Socket monitor shall be used the only for debug  purposes so using threading doesn't look too bad here\n            import threading\n            self._monitor = ZeroMQSocketMonitor(self.clients)\n            t = threading.Thread(target=self._monitor.start_poll)\n            t.start()\n\n        self.workers = self.context.socket(zmq.DEALER)\n\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            self.w_uri = 'tcp://127.0.0.1:{0}'.format(\n                self.opts.get('tcp_master_workers', 4515)\n                )\n        else:\n            self.w_uri = 'ipc://{0}'.format(\n                os.path.join(self.opts['sock_dir'], 'workers.ipc')\n                )\n\n        log.info('Setting up the master communication server')\n        self.clients.bind(self.uri)\n\n        self.workers.bind(self.w_uri)\n\n        while True:\n            if self.clients.closed or self.workers.closed:\n                break\n            try:\n                zmq.device(zmq.QUEUE, self.clients, self.workers)\n            except zmq.ZMQError as exc:\n                if exc.errno == errno.EINTR:\n                    continue\n                raise exc\n            except (KeyboardInterrupt, SystemExit):\n                break\n\n    def close(self):\n        '''\n        Cleanly shutdown the router socket\n        '''\n        if self._closing:\n            return\n        log.info('MWorkerQueue under PID %s is closing', os.getpid())\n        self._closing = True\n        if hasattr(self, '_monitor') and self._monitor is not None:\n            self._monitor.stop()\n            self._monitor = None\n        if hasattr(self, '_w_monitor') and self._w_monitor is not None:\n            self._w_monitor.stop()\n            self._w_monitor = None\n        if hasattr(self, 'clients') and self.clients.closed is False:\n            self.clients.close()\n        if hasattr(self, 'workers') and self.workers.closed is False:\n            self.workers.close()\n        if hasattr(self, 'stream'):\n            self.stream.close()\n        if hasattr(self, '_socket') and self._socket.closed is False:\n            self._socket.close()\n        if hasattr(self, 'context') and self.context.closed is False:\n            self.context.term()\n\n    def pre_fork(self, process_manager):\n        '''\n        Pre-fork we need to create the zmq router device\n\n        :param func process_manager: An instance of salt.utils.process.ProcessManager\n        '''\n        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)\n        process_manager.add_process(self.zmq_device)\n\n    def post_fork(self, payload_handler, io_loop):\n        '''\n        After forking we need to create all of the local sockets to listen to the\n        router\n\n        :param func payload_handler: A function to called to handle incoming payloads as\n                                     they are picked up off the wire\n        :param IOLoop io_loop: An instance of a Tornado IOLoop, to handle event scheduling\n        '''\n        self.payload_handler = payload_handler\n        self.io_loop = io_loop\n\n        self.context = zmq.Context(1)\n        self._socket = self.context.socket(zmq.REP)\n        if HAS_ZMQ_MONITOR and self.opts['zmq_monitor']:\n            # Socket monitor shall be used the only for debug  purposes so using threading doesn't look too bad here\n            import threading\n            self._w_monitor = ZeroMQSocketMonitor(self._socket)\n            t = threading.Thread(target=self._w_monitor.start_poll)\n            t.start()\n\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            self.w_uri = 'tcp://127.0.0.1:{0}'.format(\n                self.opts.get('tcp_master_workers', 4515)\n                )\n        else:\n            self.w_uri = 'ipc://{0}'.format(\n                os.path.join(self.opts['sock_dir'], 'workers.ipc')\n                )\n        log.info('Worker binding to socket {0}'.format(self.w_uri))\n        self._socket.connect(self.w_uri)\n\n        salt.transport.mixins.auth.AESReqServerMixin.post_fork(self, payload_handler, io_loop)\n\n        self.stream = zmq.eventloop.zmqstream.ZMQStream(self._socket, io_loop=self.io_loop)\n        self.stream.on_recv_stream(self.handle_message)\n\n    @tornado.gen.coroutine\n    def handle_message(self, stream, payload):\n        '''\n        Handle incoming messages from underylying TCP streams\n\n        :stream ZMQStream stream: A ZeroMQ stream.\n        See http://zeromq.github.io/pyzmq/api/generated/zmq.eventloop.zmqstream.html\n\n        :param dict payload: A payload to process\n        '''\n        try:\n            payload = self.serial.loads(payload[0])\n            payload = self._decode_payload(payload)\n        except Exception as exc:\n            exc_type = type(exc).__name__\n            if exc_type == 'AuthenticationError':\n                log.debug(\n                    'Minion failed to auth to master. Since the payload is '\n                    'encrypted, it is not known which minion failed to '\n                    'authenticate. It is likely that this is a transient '\n                    'failure due to the master rotating its public key.'\n                )\n            else:\n                log.error('Bad load from minion: %s: %s', exc_type, exc)\n            stream.send(self.serial.dumps('bad load'))\n            raise tornado.gen.Return()\n\n        # TODO helper functions to normalize payload?\n        if not isinstance(payload, dict) or not isinstance(payload.get('load'), dict):\n            log.error('payload and load must be a dict. Payload was: {0} and load was {1}'.format(payload, payload.get('load')))\n            stream.send(self.serial.dumps('payload and load must be a dict'))\n            raise tornado.gen.Return()\n\n        # intercept the \"_auth\" commands, since the main daemon shouldn't know\n        # anything about our key auth\n        if payload['enc'] == 'clear' and payload.get('load', {}).get('cmd') == '_auth':\n            stream.send(self.serial.dumps(self._auth(payload['load'])))\n            raise tornado.gen.Return()\n\n        # TODO: test\n        try:\n            # Take the payload_handler function that was registered when we created the channel\n            # and call it, returning control to the caller until it completes\n            ret, req_opts = yield self.payload_handler(payload)\n        except Exception as e:\n            # always attempt to return an error to the minion\n            stream.send('Some exception handling minion payload')\n            log.error('Some exception handling a payload from minion', exc_info=True)\n            raise tornado.gen.Return()\n\n        req_fun = req_opts.get('fun', 'send')\n        if req_fun == 'send_clear':\n            stream.send(self.serial.dumps(ret))\n        elif req_fun == 'send':\n            stream.send(self.serial.dumps(self.crypticle.dumps(ret)))\n        elif req_fun == 'send_private':\n            stream.send(self.serial.dumps(self._encrypt_private(ret,\n                                                                req_opts['key'],\n                                                                req_opts['tgt'],\n                                                                )))\n        else:\n            log.error('Unknown req_fun {0}'.format(req_fun))\n            # always attempt to return an error to the minion\n            stream.send('Server-side exception handling payload')\n        raise tornado.gen.Return()\n\n    def __setup_signals(self):\n        signal.signal(signal.SIGINT, self._handle_signals)\n        signal.signal(signal.SIGTERM, self._handle_signals)\n\n    def _handle_signals(self, signum, sigframe):\n        msg = '{0} received a '.format(self.__class__.__name__)\n        if signum == signal.SIGINT:\n            msg += 'SIGINT'\n        elif signum == signal.SIGTERM:\n            msg += 'SIGTERM'\n        msg += '. Exiting'\n        log.debug(msg)\n        self.close()\n        sys.exit(salt.defaults.exitcodes.EX_OK)\n\n\ndef _set_tcp_keepalive(zmq_socket, opts):\n    '''\n    Ensure that TCP keepalives are set as specified in \"opts\".\n\n    Warning: Failure to set TCP keepalives on the salt-master can result in\n    not detecting the loss of a minion when the connection is lost or when\n    it's host has been terminated without first closing the socket.\n    Salt's Presence System depends on this connection status to know if a minion\n    is \"present\".\n\n    Warning: Failure to set TCP keepalives on minions can result in frequent or\n    unexpected disconnects!\n    '''\n    if hasattr(zmq, 'TCP_KEEPALIVE') and opts:\n        if 'tcp_keepalive' in opts:\n            zmq_socket.setsockopt(\n                zmq.TCP_KEEPALIVE, opts['tcp_keepalive']\n            )\n        if 'tcp_keepalive_idle' in opts:\n            zmq_socket.setsockopt(\n                zmq.TCP_KEEPALIVE_IDLE, opts['tcp_keepalive_idle']\n            )\n        if 'tcp_keepalive_cnt' in opts:\n            zmq_socket.setsockopt(\n                zmq.TCP_KEEPALIVE_CNT, opts['tcp_keepalive_cnt']\n            )\n        if 'tcp_keepalive_intvl' in opts:\n            zmq_socket.setsockopt(\n                zmq.TCP_KEEPALIVE_INTVL, opts['tcp_keepalive_intvl']\n            )\n\n\nclass ZeroMQPubServerChannel(salt.transport.server.PubServerChannel):\n    '''\n    Encapsulate synchronous operations for a publisher channel\n    '''\n    def __init__(self, opts):\n        self.opts = opts\n        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?\n        self.ckminions = salt.utils.minions.CkMinions(self.opts)\n\n    def connect(self):\n        return tornado.gen.sleep(5)\n\n    def _publish_daemon(self):\n        '''\n        Bind to the interface specified in the configuration file\n        '''\n        salt.utils.appendproctitle(self.__class__.__name__)\n        # Set up the context\n        context = zmq.Context(1)\n        # Prepare minion publish socket\n        pub_sock = context.socket(zmq.PUB)\n        _set_tcp_keepalive(pub_sock, self.opts)\n        # if 2.1 >= zmq < 3.0, we only have one HWM setting\n        try:\n            pub_sock.setsockopt(zmq.HWM, self.opts.get('pub_hwm', 1000))\n        # in zmq >= 3.0, there are separate send and receive HWM settings\n        except AttributeError:\n            # Set the High Water Marks. For more information on HWM, see:\n            # http://api.zeromq.org/4-1:zmq-setsockopt\n            pub_sock.setsockopt(zmq.SNDHWM, self.opts.get('pub_hwm', 1000))\n            pub_sock.setsockopt(zmq.RCVHWM, self.opts.get('pub_hwm', 1000))\n        if self.opts['ipv6'] is True and hasattr(zmq, 'IPV4ONLY'):\n            # IPv6 sockets work for both IPv6 and IPv4 addresses\n            pub_sock.setsockopt(zmq.IPV4ONLY, 0)\n        pub_sock.setsockopt(zmq.BACKLOG, self.opts.get('zmq_backlog', 1000))\n        pub_uri = 'tcp://{interface}:{publish_port}'.format(**self.opts)\n        # Prepare minion pull socket\n        pull_sock = context.socket(zmq.PULL)\n\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = 'tcp://127.0.0.1:{0}'.format(\n                self.opts.get('tcp_master_publish_pull', 4514)\n                )\n        else:\n            pull_uri = 'ipc://{0}'.format(\n                os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n                )\n        salt.utils.zeromq.check_ipc_path_max_len(pull_uri)\n\n        # Start the minion command publisher\n        log.info('Starting the Salt Publisher on {0}'.format(pub_uri))\n        pub_sock.bind(pub_uri)\n\n        # Securely create socket\n        log.info('Starting the Salt Puller on {0}'.format(pull_uri))\n        old_umask = os.umask(0o177)\n        try:\n            pull_sock.bind(pull_uri)\n        finally:\n            os.umask(old_umask)\n\n        try:\n            while True:\n                # Catch and handle EINTR from when this process is sent\n                # SIGUSR1 gracefully so we don't choke and die horribly\n                try:\n                    package = pull_sock.recv()\n                    unpacked_package = salt.payload.unpackage(package)\n                    if six.PY3:\n                        unpacked_package = salt.transport.frame.decode_embedded_strs(unpacked_package)\n                    payload = unpacked_package['payload']\n                    if self.opts['zmq_filtering']:\n                        # if you have a specific topic list, use that\n                        if 'topic_lst' in unpacked_package:\n                            for topic in unpacked_package['topic_lst']:\n                                # zmq filters are substring match, hash the topic\n                                # to avoid collisions\n                                htopic = hashlib.sha1(topic).hexdigest()\n                                pub_sock.send(htopic, flags=zmq.SNDMORE)\n                                pub_sock.send(payload)\n                                # otherwise its a broadcast\n                        else:\n                            # TODO: constants file for \"broadcast\"\n                            pub_sock.send('broadcast', flags=zmq.SNDMORE)\n                            pub_sock.send(payload)\n                    else:\n                        pub_sock.send(payload)\n                except zmq.ZMQError as exc:\n                    if exc.errno == errno.EINTR:\n                        continue\n                    raise exc\n\n        except KeyboardInterrupt:\n            # Cleanly close the sockets if we're shutting down\n            if pub_sock.closed is False:\n                pub_sock.setsockopt(zmq.LINGER, 1)\n                pub_sock.close()\n            if pull_sock.closed is False:\n                pull_sock.setsockopt(zmq.LINGER, 1)\n                pull_sock.close()\n            if context.closed is False:\n                context.term()\n\n    def pre_fork(self, process_manager):\n        '''\n        Do anything necessary pre-fork. Since this is on the master side this will\n        primarily be used to create IPC channels and create our daemon process to\n        do the actual publishing\n\n        :param func process_manager: A ProcessManager, from salt.utils.process.ProcessManager\n        '''\n        process_manager.add_process(self._publish_daemon)\n\n    def publish(self, load):\n        '''\n        Publish \"load\" to minions\n\n        :param dict load: A load to be sent across the wire to minions\n        '''\n        payload = {'enc': 'aes'}\n\n        crypticle = salt.crypt.Crypticle(self.opts, salt.master.SMaster.secrets['aes']['secret'].value)\n        payload['load'] = crypticle.dumps(load)\n        if self.opts['sign_pub_messages']:\n            master_pem_path = os.path.join(self.opts['pki_dir'], 'master.pem')\n            log.debug(\"Signing data packet\")\n            payload['sig'] = salt.crypt.sign_message(master_pem_path, payload['load'])\n        # Send 0MQ to the publisher\n        context = zmq.Context(1)\n        pub_sock = context.socket(zmq.PUSH)\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = 'tcp://127.0.0.1:{0}'.format(\n                self.opts.get('tcp_master_publish_pull', 4514)\n                )\n        else:\n            pull_uri = 'ipc://{0}'.format(\n                os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n                )\n        pub_sock.connect(pull_uri)\n        int_payload = {'payload': self.serial.dumps(payload)}\n\n        # add some targeting stuff for lists only (for now)\n        if load['tgt_type'] == 'list':\n            int_payload['topic_lst'] = load['tgt']\n\n        # If zmq_filtering is enabled, target matching has to happen master side\n        match_targets = [\"pcre\", \"glob\", \"list\"]\n        if self.opts['zmq_filtering'] and load['tgt_type'] in match_targets:\n            # Fetch a list of minions that match\n            match_ids = self.ckminions.check_minions(load['tgt'],\n                                                     tgt_type=load['tgt_type'])\n\n            log.debug(\"Publish Side Match: {0}\".format(match_ids))\n            # Send list of miions thru so zmq can target them\n            int_payload['topic_lst'] = match_ids\n\n        pub_sock.send(self.serial.dumps(int_payload))\n        pub_sock.close()\n        context.term()\n\n\nclass AsyncReqMessageClientPool(salt.transport.MessageClientPool):\n    '''\n    Wrapper class of AsyncReqMessageClientPool to avoid blocking waiting while writing data to socket.\n    '''\n    def __init__(self, opts, args=None, kwargs=None):\n        super(AsyncReqMessageClientPool, self).__init__(AsyncReqMessageClient, opts, args=args, kwargs=kwargs)\n\n    def __del__(self):\n        self.destroy()\n\n    def destroy(self):\n        for message_client in self.message_clients:\n            message_client.destroy()\n        self.message_clients = []\n\n    def send(self, *args, **kwargs):\n        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))\n        return message_clients[0].send(*args, **kwargs)\n\n\n# TODO: unit tests!\nclass AsyncReqMessageClient(object):\n    '''\n    This class wraps the underylying zeromq REQ socket and gives a future-based\n    interface to sending and recieving messages. This works around the primary\n    limitation of serialized send/recv on the underlying socket by queueing the\n    message sends in this class. In the future if we decide to attempt to multiplex\n    we can manage a pool of REQ/REP sockets-- but for now we'll just do them in serial\n    '''\n    def __init__(self, opts, addr, linger=0, io_loop=None):\n        '''\n        Create an asynchronous message client\n\n        :param dict opts: The salt opts dictionary\n        :param str addr: The interface IP address to bind to\n        :param int linger: The number of seconds to linger on a ZMQ socket. See\n                           http://api.zeromq.org/2-1:zmq-setsockopt [ZMQ_LINGER]\n        :param IOLoop io_loop: A Tornado IOLoop event scheduler [tornado.ioloop.IOLoop]\n        '''\n        self.opts = opts\n        self.addr = addr\n        self.linger = linger\n        if io_loop is None:\n            zmq.eventloop.ioloop.install()\n            tornado.ioloop.IOLoop.current()\n        else:\n            self.io_loop = io_loop\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        self.context = zmq.Context()\n\n        # wire up sockets\n        self._init_socket()\n\n        self.send_queue = []\n        # mapping of message -> future\n        self.send_future_map = {}\n\n        self.send_timeout_map = {}  # message -> timeout\n\n    # TODO: timeout all in-flight sessions, or error\n    def destroy(self):\n        if hasattr(self, 'stream') and self.stream is not None:\n            # TODO: Optionally call stream.close() on newer pyzmq? It is broken on some.\n            if self.stream.socket:\n                self.stream.socket.close()\n            self.stream.io_loop.remove_handler(self.stream.socket)\n            # set this to None, more hacks for messed up pyzmq\n            self.stream.socket = None\n            self.stream = None\n            self.socket.close()\n        if self.context.closed is False:\n            self.context.term()\n\n    def __del__(self):\n        self.destroy()\n\n    def _init_socket(self):\n        if hasattr(self, 'stream'):\n            self.stream.close()  # pylint: disable=E0203\n            self.socket.close()  # pylint: disable=E0203\n            del self.stream\n            del self.socket\n\n        self.socket = self.context.socket(zmq.REQ)\n\n        # socket options\n        if hasattr(zmq, 'RECONNECT_IVL_MAX'):\n            self.socket.setsockopt(\n                zmq.RECONNECT_IVL_MAX, 5000\n            )\n\n        _set_tcp_keepalive(self.socket, self.opts)\n        if self.addr.startswith('tcp://['):\n            # Hint PF type if bracket enclosed IPv6 address\n            if hasattr(zmq, 'IPV6'):\n                self.socket.setsockopt(zmq.IPV6, 1)\n            elif hasattr(zmq, 'IPV4ONLY'):\n                self.socket.setsockopt(zmq.IPV4ONLY, 0)\n        self.socket.linger = self.linger\n        self.socket.connect(self.addr)\n        self.stream = zmq.eventloop.zmqstream.ZMQStream(self.socket, io_loop=self.io_loop)\n\n    @tornado.gen.coroutine\n    def _internal_send_recv(self):\n        while len(self.send_queue) > 0:\n            message = self.send_queue[0]\n            future = self.send_future_map.get(message, None)\n            if future is None:\n                # Timedout\n                del self.send_queue[0]\n                continue\n\n            # send\n            def mark_future(msg):\n                if not future.done():\n                    data = self.serial.loads(msg[0])\n                    future.set_result(data)\n            self.stream.on_recv(mark_future)\n            self.stream.send(message)\n\n            try:\n                ret = yield future\n            except:  # pylint: disable=W0702\n                self._init_socket()  # re-init the zmq socket (no other way in zmq)\n                del self.send_queue[0]\n                continue\n            del self.send_queue[0]\n            self.send_future_map.pop(message, None)\n            self.remove_message_timeout(message)\n\n    def remove_message_timeout(self, message):\n        if message not in self.send_timeout_map:\n            return\n        timeout = self.send_timeout_map.pop(message, None)\n        if timeout is not None:\n            # Hasn't been already timedout\n            self.io_loop.remove_timeout(timeout)\n\n    def timeout_message(self, message):\n        '''\n        Handle a message timeout by removing it from the sending queue\n        and informing the caller\n\n        :raises: SaltReqTimeoutError\n        '''\n        future = self.send_future_map.pop(message, None)\n        # In a race condition the message might have been sent by the time\n        # we're timing it out. Make sure the future is not None\n        if future is not None:\n            del self.send_timeout_map[message]\n            if future.attempts < future.tries:\n                future.attempts += 1\n                log.debug('SaltReqTimeoutError, retrying. ({0}/{1})'.format(future.attempts, future.tries))\n                self.send(\n                    message,\n                    timeout=future.timeout,\n                    tries=future.tries,\n                    future=future,\n                )\n\n            else:\n                future.set_exception(SaltReqTimeoutError('Message timed out'))\n\n    def send(self, message, timeout=None, tries=3, future=None, callback=None, raw=False):\n        '''\n        Return a future which will be completed when the message has a response\n        '''\n        if future is None:\n            future = tornado.concurrent.Future()\n            future.tries = tries\n            future.attempts = 0\n            future.timeout = timeout\n            # if a future wasn't passed in, we need to serialize the message\n            message = self.serial.dumps(message)\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n        # Add this future to the mapping\n        self.send_future_map[message] = future\n\n        if self.opts.get('detect_mode') is True:\n            timeout = 1\n\n        if timeout is not None:\n            send_timeout = self.io_loop.call_later(timeout, self.timeout_message, message)\n            self.send_timeout_map[message] = send_timeout\n\n        if len(self.send_queue) == 0:\n            self.io_loop.spawn_callback(self._internal_send_recv)\n\n        self.send_queue.append(message)\n\n        return future\n\n\nclass ZeroMQSocketMonitor(object):\n    __EVENT_MAP = None\n\n    def __init__(self, socket):\n        '''\n        Create ZMQ monitor sockets\n\n        More information:\n            http://api.zeromq.org/4-0:zmq-socket-monitor\n        '''\n        self._socket = socket\n        self._monitor_socket = self._socket.get_monitor_socket()\n        self._monitor_stream = None\n\n    def start_io_loop(self, io_loop):\n        log.trace(\"Event monitor start!\")\n        self._monitor_stream = zmq.eventloop.zmqstream.ZMQStream(self._monitor_socket, io_loop=io_loop)\n        self._monitor_stream.on_recv(self.monitor_callback)\n\n    def start_poll(self):\n        log.trace(\"Event monitor start!\")\n        try:\n            while self._monitor_socket is not None and self._monitor_socket.poll():\n                msg = self._monitor_socket.recv_multipart()\n                self.monitor_callback(msg)\n        except (AttributeError, zmq.error.ContextTerminated):\n            # We cannot log here because we'll get an interrupted system call in trying\n            # to flush the logging buffer as we terminate\n            pass\n\n    @property\n    def event_map(self):\n        if ZeroMQSocketMonitor.__EVENT_MAP is None:\n            event_map = {}\n            for name in dir(zmq):\n                if name.startswith('EVENT_'):\n                    value = getattr(zmq, name)\n                    event_map[value] = name\n            ZeroMQSocketMonitor.__EVENT_MAP = event_map\n        return ZeroMQSocketMonitor.__EVENT_MAP\n\n    def monitor_callback(self, msg):\n        evt = zmq.utils.monitor.parse_monitor_message(msg)\n        evt['description'] = self.event_map[evt['event']]\n        log.debug(\"ZeroMQ event: {0}\".format(evt))\n        if evt['event'] == zmq.EVENT_MONITOR_STOPPED:\n            self.stop()\n\n    def stop(self):\n        if self._socket is None:\n            return\n        self._socket.disable_monitor()\n        self._socket = None\n        self._monitor_socket = None\n        if self._monitor_stream is not None:\n            self._monitor_stream.close()\n            self._monitor_stream = None\n        log.trace(\"Event monitor done!\")\n"], "fixing_code": ["# -*- coding: utf-8 -*-\n'''\nThe crypt module manages all of the cryptography functions for minions and\nmasters, encrypting and decrypting payloads, preparing messages, and\nauthenticating peers\n'''\n# Import python libs\nfrom __future__ import absolute_import, print_function\nimport os\nimport sys\nimport copy\nimport time\nimport hmac\nimport base64\nimport hashlib\nimport logging\nimport stat\nimport traceback\nimport binascii\nimport weakref\nimport getpass\n\n# Import third party libs\nimport salt.ext.six as six\nfrom salt.ext.six.moves import zip  # pylint: disable=import-error,redefined-builtin\ntry:\n    from Cryptodome.Cipher import AES, PKCS1_OAEP\n    from Cryptodome.Hash import SHA\n    from Cryptodome.PublicKey import RSA\n    from Cryptodome.Signature import PKCS1_v1_5\n    import Cryptodome.Random  # pylint: disable=W0611\n    CDOME = True\nexcept ImportError:\n    CDOME = False\nif not CDOME:\n    try:\n        from Crypto.Cipher import AES, PKCS1_OAEP\n        from Crypto.Hash import SHA\n        from Crypto.PublicKey import RSA\n        from Crypto.Signature import PKCS1_v1_5\n        # let this be imported, if possible\n        import Crypto.Random  # pylint: disable=W0611\n    except ImportError:\n        # No need for crypt in local mode\n        pass\n\n# Import salt libs\nimport salt.defaults.exitcodes\nimport salt.utils\nimport salt.utils.decorators\nimport salt.payload\nimport salt.transport.client\nimport salt.transport.frame\nimport salt.utils.rsax931\nimport salt.utils.verify\nimport salt.version\nfrom salt.exceptions import (\n    AuthenticationError, SaltClientError, SaltReqTimeoutError\n)\n\nimport tornado.gen\n\nlog = logging.getLogger(__name__)\n\n\ndef dropfile(cachedir, user=None):\n    '''\n    Set an AES dropfile to request the master update the publish session key\n    '''\n    dfn = os.path.join(cachedir, '.dfn')\n    # set a mask (to avoid a race condition on file creation) and store original.\n    mask = os.umask(191)\n    try:\n        log.info('Rotating AES key')\n        if os.path.isfile(dfn):\n            log.info('AES key rotation already requested')\n            return\n\n        if os.path.isfile(dfn) and not os.access(dfn, os.W_OK):\n            os.chmod(dfn, stat.S_IRUSR | stat.S_IWUSR)\n        with salt.utils.fopen(dfn, 'wb+') as fp_:\n            fp_.write(b'')\n        os.chmod(dfn, stat.S_IRUSR)\n        if user:\n            try:\n                import pwd\n                uid = pwd.getpwnam(user).pw_uid\n                os.chown(dfn, uid, -1)\n            except (KeyError, ImportError, OSError, IOError):\n                pass\n    finally:\n        os.umask(mask)  # restore original umask\n\n\ndef gen_keys(keydir, keyname, keysize, user=None):\n    '''\n    Generate a RSA public keypair for use with salt\n\n    :param str keydir: The directory to write the keypair to\n    :param str keyname: The type of salt server for whom this key should be written. (i.e. 'master' or 'minion')\n    :param int keysize: The number of bits in the key\n    :param str user: The user on the system who should own this keypair\n\n    :rtype: str\n    :return: Path on the filesystem to the RSA private key\n    '''\n    base = os.path.join(keydir, keyname)\n    priv = '{0}.pem'.format(base)\n    pub = '{0}.pub'.format(base)\n\n    salt.utils.reinit_crypto()\n    gen = RSA.generate(bits=keysize, e=65537)\n    if os.path.isfile(priv):\n        # Between first checking and the generation another process has made\n        # a key! Use the winner's key\n        return priv\n\n    # Do not try writing anything, if directory has no permissions.\n    if not os.access(keydir, os.W_OK):\n        raise IOError('Write access denied to \"{0}\" for user \"{1}\".'.format(os.path.abspath(keydir), getpass.getuser()))\n\n    cumask = os.umask(191)\n    with salt.utils.fopen(priv, 'wb+') as f:\n        f.write(gen.exportKey('PEM'))\n    os.umask(cumask)\n    with salt.utils.fopen(pub, 'wb+') as f:\n        f.write(gen.publickey().exportKey('PEM'))\n    os.chmod(priv, 256)\n    if user:\n        try:\n            import pwd\n            uid = pwd.getpwnam(user).pw_uid\n            os.chown(priv, uid, -1)\n            os.chown(pub, uid, -1)\n        except (KeyError, ImportError, OSError):\n            # The specified user was not found, allow the backup systems to\n            # report the error\n            pass\n    return priv\n\n\n@salt.utils.decorators.memoize\ndef _get_key_with_evict(path, timestamp):\n    '''\n    Load a key from disk.  `timestamp` above is intended to be the timestamp\n    of the file's last modification. This fn is memoized so if it is called with the\n    same path and timestamp (the file's last modified time) the second time\n    the result is returned from the memoiziation.  If the file gets modified\n    then the params are different and the key is loaded from disk.\n    '''\n    log.debug('salt.crypt._get_key_with_evict: Loading private key')\n    with salt.utils.fopen(path) as f:\n        key = RSA.importKey(f.read())\n    return key\n\n\ndef _get_rsa_key(path):\n    '''\n    Read a key off the disk.  Poor man's simple cache in effect here,\n    we memoize the result of calling _get_rsa_with_evict.  This means\n    the first time _get_key_with_evict is called with a path and a timestamp\n    the result is cached.  If the file (the private key) does not change\n    then its timestamp will not change and the next time the result is returned\n    from the cache.  If the key DOES change the next time _get_rsa_with_evict\n    is called it is called with different parameters and the fn is run fully to\n    retrieve the key from disk.\n    '''\n    log.debug('salt.crypt._get_rsa_key: Loading private key')\n    return _get_key_with_evict(path, str(os.path.getmtime(path)))\n\n\ndef sign_message(privkey_path, message):\n    '''\n    Use Crypto.Signature.PKCS1_v1_5 to sign a message. Returns the signature.\n    '''\n    key = _get_rsa_key(privkey_path)\n    log.debug('salt.crypt.sign_message: Signing message.')\n    signer = PKCS1_v1_5.new(key)\n    return signer.sign(SHA.new(message))\n\n\ndef verify_signature(pubkey_path, message, signature):\n    '''\n    Use Crypto.Signature.PKCS1_v1_5 to verify the signature on a message.\n    Returns True for valid signature.\n    '''\n    log.debug('salt.crypt.verify_signature: Loading public key')\n    with salt.utils.fopen(pubkey_path) as f:\n        pubkey = RSA.importKey(f.read())\n    log.debug('salt.crypt.verify_signature: Verifying signature')\n    verifier = PKCS1_v1_5.new(pubkey)\n    return verifier.verify(SHA.new(message), signature)\n\n\ndef gen_signature(priv_path, pub_path, sign_path):\n    '''\n    creates a signature for the given public-key with\n    the given private key and writes it to sign_path\n    '''\n\n    with salt.utils.fopen(pub_path) as fp_:\n        mpub_64 = fp_.read()\n\n    mpub_sig = sign_message(priv_path, mpub_64)\n    mpub_sig_64 = binascii.b2a_base64(mpub_sig)\n    if os.path.isfile(sign_path):\n        return False\n    log.trace('Calculating signature for {0} with {1}'\n              .format(os.path.basename(pub_path),\n                      os.path.basename(priv_path)))\n\n    if os.path.isfile(sign_path):\n        log.trace('Signature file {0} already exists, please '\n                  'remove it first and try again'.format(sign_path))\n    else:\n        with salt.utils.fopen(sign_path, 'wb+') as sig_f:\n            sig_f.write(salt.utils.to_bytes(mpub_sig_64))\n        log.trace('Wrote signature to {0}'.format(sign_path))\n    return True\n\n\ndef private_encrypt(key, message):\n    '''\n    Generate an M2Crypto-compatible signature\n\n    :param Crypto.PublicKey.RSA._RSAobj key: The RSA key object\n    :param str message: The message to sign\n    :rtype: str\n    :return: The signature, or an empty string if the signature operation failed\n    '''\n    signer = salt.utils.rsax931.RSAX931Signer(key.exportKey('PEM'))\n    return signer.sign(message)\n\n\ndef public_decrypt(pub, message):\n    '''\n    Verify an M2Crypto-compatible signature\n\n    :param Crypto.PublicKey.RSA._RSAobj key: The RSA public key object\n    :param str message: The signed message to verify\n    :rtype: str\n    :return: The message (or digest) recovered from the signature, or an\n        empty string if the verification failed\n    '''\n    verifier = salt.utils.rsax931.RSAX931Verifier(pub.exportKey('PEM'))\n    return verifier.verify(message)\n\n\nclass MasterKeys(dict):\n    '''\n    The Master Keys class is used to manage the RSA public key pair used for\n    authentication by the master.\n\n    It also generates a signing key-pair if enabled with master_sign_key_name.\n    '''\n    def __init__(self, opts):\n        super(MasterKeys, self).__init__()\n        self.opts = opts\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'master.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'master.pem')\n\n        self.key = self.__get_keys()\n        self.pub_signature = None\n\n        # set names for the signing key-pairs\n        if opts['master_sign_pubkey']:\n\n            # if only the signature is available, use that\n            if opts['master_use_pubkey_signature']:\n                self.sig_path = os.path.join(self.opts['pki_dir'],\n                                             opts['master_pubkey_signature'])\n                if os.path.isfile(self.sig_path):\n                    with salt.utils.fopen(self.sig_path) as fp_:\n                        self.pub_signature = fp_.read()\n                    log.info('Read {0}\\'s signature from {1}'\n                             ''.format(os.path.basename(self.pub_path),\n                                       self.opts['master_pubkey_signature']))\n                else:\n                    log.error('Signing the master.pub key with a signature is enabled '\n                              'but no signature file found at the defined location '\n                              '{0}'.format(self.sig_path))\n                    log.error('The signature-file may be either named differently '\n                               'or has to be created with \\'salt-key --gen-signature\\'')\n                    sys.exit(1)\n\n            # create a new signing key-pair to sign the masters\n            # auth-replies when a minion tries to connect\n            else:\n                self.pub_sign_path = os.path.join(self.opts['pki_dir'],\n                                                  opts['master_sign_key_name'] + '.pub')\n                self.rsa_sign_path = os.path.join(self.opts['pki_dir'],\n                                                  opts['master_sign_key_name'] + '.pem')\n                self.sign_key = self.__get_keys(name=opts['master_sign_key_name'])\n\n    # We need __setstate__ and __getstate__ to avoid pickling errors since\n    # some of the member variables correspond to Cython objects which are\n    # not picklable.\n    # These methods are only used when pickling so will not be used on\n    # non-Windows platforms.\n    def __setstate__(self, state):\n        self.__init__(state['opts'])\n\n    def __getstate__(self):\n        return {'opts': self.opts}\n\n    def __get_keys(self, name='master'):\n        '''\n        Returns a key object for a key in the pki-dir\n        '''\n        path = os.path.join(self.opts['pki_dir'],\n                            name + '.pem')\n        if os.path.exists(path):\n            with salt.utils.fopen(path) as f:\n                key = RSA.importKey(f.read())\n            log.debug('Loaded {0} key: {1}'.format(name, path))\n        else:\n            log.info('Generating {0} keys: {1}'.format(name, self.opts['pki_dir']))\n            gen_keys(self.opts['pki_dir'],\n                     name,\n                     self.opts['keysize'],\n                     self.opts.get('user'))\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n        return key\n\n    def get_pub_str(self, name='master'):\n        '''\n        Return the string representation of a public key\n        in the pki-directory\n        '''\n        path = os.path.join(self.opts['pki_dir'],\n                            name + '.pub')\n        if not os.path.isfile(path):\n            key = self.__get_keys()\n            with salt.utils.fopen(path, 'wb+') as wfh:\n                wfh.write(key.publickey().exportKey('PEM'))\n        with salt.utils.fopen(path) as rfh:\n            return rfh.read()\n\n    def get_mkey_paths(self):\n        return self.pub_path, self.rsa_path\n\n    def get_sign_paths(self):\n        return self.pub_sign_path, self.rsa_sign_path\n\n    def pubkey_signature(self):\n        '''\n        returns the base64 encoded signature from the signature file\n        or None if the master has its own signing keys\n        '''\n        return self.pub_signature\n\n\nclass AsyncAuth(object):\n    '''\n    Set up an Async object to maintain authentication with the salt master\n    '''\n    # This class is only a singleton per minion/master pair\n    # mapping of io_loop -> {key -> auth}\n    instance_map = weakref.WeakKeyDictionary()\n\n    # mapping of key -> creds\n    creds_map = {}\n\n    def __new__(cls, opts, io_loop=None):\n        '''\n        Only create one instance of AsyncAuth per __key()\n        '''\n        # do we have any mapping for this io_loop\n        io_loop = io_loop or tornado.ioloop.IOLoop.current()\n        if io_loop not in AsyncAuth.instance_map:\n            AsyncAuth.instance_map[io_loop] = weakref.WeakValueDictionary()\n        loop_instance_map = AsyncAuth.instance_map[io_loop]\n\n        key = cls.__key(opts)\n        auth = loop_instance_map.get(key)\n        if auth is None:\n            log.debug('Initializing new AsyncAuth for {0}'.format(key))\n            # we need to make a local variable for this, as we are going to store\n            # it in a WeakValueDictionary-- which will remove the item if no one\n            # references it-- this forces a reference while we return to the caller\n            auth = object.__new__(cls)\n            auth.__singleton_init__(opts, io_loop=io_loop)\n            loop_instance_map[key] = auth\n        else:\n            log.debug('Re-using AsyncAuth for {0}'.format(key))\n        return auth\n\n    @classmethod\n    def __key(cls, opts, io_loop=None):\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],  # master ID\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, io_loop=None):\n        pass\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, io_loop=None):\n        '''\n        Init an Auth instance\n\n        :param dict opts: Options for this server\n        :return: Auth instance\n        :rtype: Auth\n        '''\n        self.opts = opts\n        if six.PY2:\n            self.token = Crypticle.generate_key_string()\n        else:\n            self.token = salt.utils.to_bytes(Crypticle.generate_key_string())\n        self.serial = salt.payload.Serial(self.opts)\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'minion.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'minion.pem')\n        if self.opts['__role'] == 'syndic':\n            self.mpub = 'syndic_master.pub'\n        else:\n            self.mpub = 'minion_master.pub'\n        if not os.path.isfile(self.pub_path):\n            self.get_keys()\n\n        self.io_loop = io_loop or tornado.ioloop.IOLoop.current()\n\n        salt.utils.reinit_crypto()\n        key = self.__key(self.opts)\n        # TODO: if we already have creds for this key, lets just re-use\n        if key in AsyncAuth.creds_map:\n            creds = AsyncAuth.creds_map[key]\n            self._creds = creds\n            self._crypticle = Crypticle(self.opts, creds['aes'])\n            self._authenticate_future = tornado.concurrent.Future()\n            self._authenticate_future.set_result(True)\n        else:\n            self.authenticate()\n\n    def __deepcopy__(self, memo):\n        cls = self.__class__\n        result = cls.__new__(cls, copy.deepcopy(self.opts, memo), io_loop=None)\n        memo[id(self)] = result\n        for key in self.__dict__:\n            if key in ('io_loop',):\n                # The io_loop has a thread Lock which will fail to be deep\n                # copied. Skip it because it will just be recreated on the\n                # new copy.\n                continue\n            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))\n        return result\n\n    @property\n    def creds(self):\n        return self._creds\n\n    @property\n    def crypticle(self):\n        return self._crypticle\n\n    @property\n    def authenticated(self):\n        return hasattr(self, '_authenticate_future') and \\\n               self._authenticate_future.done() and \\\n               self._authenticate_future.exception() is None\n\n    def invalidate(self):\n        if self.authenticated:\n            del self._authenticate_future\n            key = self.__key(self.opts)\n            if key in AsyncAuth.creds_map:\n                del AsyncAuth.creds_map[key]\n\n    def authenticate(self, callback=None):\n        '''\n        Ask for this client to reconnect to the origin\n\n        This function will de-dupe all calls here and return a *single* future\n        for the sign-in-- whis way callers can all assume there aren't others\n        '''\n        # if an auth is in flight-- and not done-- just pass that back as the future to wait on\n        if hasattr(self, '_authenticate_future') and not self._authenticate_future.done():\n            future = self._authenticate_future\n        else:\n            future = tornado.concurrent.Future()\n            self._authenticate_future = future\n            self.io_loop.add_callback(self._authenticate)\n\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n\n        return future\n\n    @tornado.gen.coroutine\n    def _authenticate(self):\n        '''\n        Authenticate with the master, this method breaks the functional\n        paradigm, it will update the master information from a fresh sign\n        in, signing in can occur as often as needed to keep up with the\n        revolving master AES key.\n\n        :rtype: Crypticle\n        :returns: A crypticle used for encryption operations\n        '''\n        acceptance_wait_time = self.opts['acceptance_wait_time']\n        acceptance_wait_time_max = self.opts['acceptance_wait_time_max']\n        if not acceptance_wait_time_max:\n            acceptance_wait_time_max = acceptance_wait_time\n        creds = None\n        channel = salt.transport.client.AsyncReqChannel.factory(self.opts,\n                                                                crypt='clear',\n                                                                io_loop=self.io_loop)\n        error = None\n        while True:\n            try:\n                creds = yield self.sign_in(channel=channel)\n            except SaltClientError as exc:\n                error = exc\n                break\n            if creds == 'retry':\n                if self.opts.get('detect_mode') is True:\n                    error = SaltClientError('Detect mode is on')\n                    break\n                if self.opts.get('caller'):\n                    print('Minion failed to authenticate with the master, '\n                          'has the minion key been accepted?')\n                    sys.exit(2)\n                if acceptance_wait_time:\n                    log.info('Waiting {0} seconds before retry.'.format(acceptance_wait_time))\n                    yield tornado.gen.sleep(acceptance_wait_time)\n                if acceptance_wait_time < acceptance_wait_time_max:\n                    acceptance_wait_time += acceptance_wait_time\n                    log.debug('Authentication wait time is {0}'.format(acceptance_wait_time))\n                continue\n            break\n        if not isinstance(creds, dict) or 'aes' not in creds:\n            if self.opts.get('detect_mode') is True:\n                error = SaltClientError('-|RETRY|-')\n            try:\n                del AsyncAuth.creds_map[self.__key(self.opts)]\n            except KeyError:\n                pass\n            if not error:\n                error = SaltClientError('Attempt to authenticate with the salt master failed')\n            self._authenticate_future.set_exception(error)\n        else:\n            key = self.__key(self.opts)\n            AsyncAuth.creds_map[key] = creds\n            self._creds = creds\n            self._crypticle = Crypticle(self.opts, creds['aes'])\n            self._authenticate_future.set_result(True)  # mark the sign-in as complete\n            # Notify the bus about creds change\n            event = salt.utils.event.get_event(self.opts.get('__role'), opts=self.opts, listen=False)\n            event.fire_event({'key': key, 'creds': creds}, salt.utils.event.tagify(prefix='auth', suffix='creds'))\n\n    @tornado.gen.coroutine\n    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):\n        '''\n        Send a sign in request to the master, sets the key information and\n        returns a dict containing the master publish interface to bind to\n        and the decrypted aes key for transport decryption.\n\n        :param int timeout: Number of seconds to wait before timing out the sign-in request\n        :param bool safe: If True, do not raise an exception on timeout. Retry instead.\n        :param int tries: The number of times to try to authenticate before giving up.\n\n        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set\n\n        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary\n        with the publication port and the shared AES key.\n\n        '''\n        auth = {}\n\n        auth_timeout = self.opts.get('auth_timeout', None)\n        if auth_timeout is not None:\n            timeout = auth_timeout\n        auth_safemode = self.opts.get('auth_safemode', None)\n        if auth_safemode is not None:\n            safe = auth_safemode\n        auth_tries = self.opts.get('auth_tries', None)\n        if auth_tries is not None:\n            tries = auth_tries\n\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n\n        auth['master_uri'] = self.opts['master_uri']\n\n        if not channel:\n            channel = salt.transport.client.AsyncReqChannel.factory(self.opts,\n                                                                crypt='clear',\n                                                                io_loop=self.io_loop)\n\n        sign_in_payload = self.minion_sign_in_payload()\n        try:\n            payload = yield channel.send(\n                sign_in_payload,\n                tries=tries,\n                timeout=timeout\n            )\n        except SaltReqTimeoutError as e:\n            if safe:\n                log.warning('SaltReqTimeoutError: {0}'.format(e))\n                raise tornado.gen.Return('retry')\n            if self.opts.get('detect_mode') is True:\n                raise tornado.gen.Return('retry')\n            else:\n                raise SaltClientError('Attempt to authenticate with the salt master failed with timeout error')\n        if not isinstance(payload, dict):\n            log.error('Sign-in attempt failed: %s', payload)\n            raise tornado.gen.Return(False)\n        if 'load' in payload:\n            if 'ret' in payload['load']:\n                if not payload['load']['ret']:\n                    if self.opts['rejected_retry']:\n                        log.error(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key.\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master.\\nThe Salt '\n                            'Minion will attempt to to re-authenicate.'\n                        )\n                        raise tornado.gen.Return('retry')\n                    else:\n                        log.critical(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key!\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master and restart this '\n                            'minion.\\nOr restart the Salt Master in open mode to '\n                            'clean out the keys. The Salt Minion will now exit.'\n                        )\n                        sys.exit(salt.defaults.exitcodes.EX_OK)\n                # has the master returned that its maxed out with minions?\n                elif payload['load']['ret'] == 'full':\n                    raise tornado.gen.Return('full')\n                else:\n                    log.error(\n                        'The Salt Master has cached the public key for this '\n                        'node, this salt minion will wait for {0} seconds '\n                        'before attempting to re-authenticate'.format(\n                            self.opts['acceptance_wait_time']\n                        )\n                    )\n                    raise tornado.gen.Return('retry')\n        auth['aes'] = self.verify_master(payload, master_pub='token' in sign_in_payload)\n        if not auth['aes']:\n            log.critical(\n                'The Salt Master server\\'s public key did not authenticate!\\n'\n                'The master may need to be updated if it is a version of Salt '\n                'lower than {0}, or\\n'\n                'If you are confident that you are connecting to a valid Salt '\n                'Master, then remove the master public key and restart the '\n                'Salt Minion.\\nThe master public key can be found '\n                'at:\\n{1}'.format(salt.version.__version__, m_pub_fn)\n            )\n            raise SaltClientError('Invalid master key')\n        if self.opts.get('syndic_master', False):  # Is syndic\n            syndic_finger = self.opts.get('syndic_finger', self.opts.get('master_finger', False))\n            if syndic_finger:\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != syndic_finger:\n                    self._finger_fail(syndic_finger, m_pub_fn)\n        else:\n            if self.opts.get('master_finger', False):\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != self.opts['master_finger']:\n                    self._finger_fail(self.opts['master_finger'], m_pub_fn)\n        auth['publish_port'] = payload['publish_port']\n        raise tornado.gen.Return(auth)\n\n    def get_keys(self):\n        '''\n        Return keypair object for the minion.\n\n        :rtype: Crypto.PublicKey.RSA._RSAobj\n        :return: The RSA keypair\n        '''\n        # Make sure all key parent directories are accessible\n        user = self.opts.get('user', 'root')\n        salt.utils.verify.check_path_traversal(self.opts['pki_dir'], user)\n\n        if os.path.exists(self.rsa_path):\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n            log.debug('Loaded minion key: {0}'.format(self.rsa_path))\n        else:\n            log.info('Generating keys: {0}'.format(self.opts['pki_dir']))\n            gen_keys(self.opts['pki_dir'],\n                     'minion',\n                     self.opts['keysize'],\n                     self.opts.get('user'))\n            with salt.utils.fopen(self.rsa_path) as f:\n                key = RSA.importKey(f.read())\n        return key\n\n    def gen_token(self, clear_tok):\n        '''\n        Encrypt a string with the minion private key to verify identity\n        with the master.\n\n        :param str clear_tok: A plaintext token to encrypt\n        :return: Encrypted token\n        :rtype: str\n        '''\n        return private_encrypt(self.get_keys(), clear_tok)\n\n    def minion_sign_in_payload(self):\n        '''\n        Generates the payload used to authenticate with the master\n        server. This payload consists of the passed in id_ and the ssh\n        public key to encrypt the AES key sent back from the master.\n\n        :return: Payload dictionary\n        :rtype: dict\n        '''\n        payload = {}\n        payload['cmd'] = '_auth'\n        payload['id'] = self.opts['id']\n        try:\n            pubkey_path = os.path.join(self.opts['pki_dir'], self.mpub)\n            with salt.utils.fopen(pubkey_path) as f:\n                pub = RSA.importKey(f.read())\n            cipher = PKCS1_OAEP.new(pub)\n            payload['token'] = cipher.encrypt(self.token)\n        except Exception:\n            pass\n        with salt.utils.fopen(self.pub_path) as f:\n            payload['pub'] = f.read()\n        return payload\n\n    def decrypt_aes(self, payload, master_pub=True):\n        '''\n        This function is used to decrypt the AES seed phrase returned from\n        the master server. The seed phrase is decrypted with the SSH RSA\n        host key.\n\n        Pass in the encrypted AES key.\n        Returns the decrypted AES seed key, a string\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'sig': The message signature\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The public key of the sender.\n\n        :rtype: str\n        :return: The decrypted token that was provided, with padding.\n\n        :rtype: str\n        :return: The decrypted AES seed key\n        '''\n        if self.opts.get('auth_trb', False):\n            log.warning(\n                    'Auth Called: {0}'.format(\n                        ''.join(traceback.format_stack())\n                        )\n                    )\n        else:\n            log.debug('Decrypting the current master AES key')\n        key = self.get_keys()\n        cipher = PKCS1_OAEP.new(key)\n        key_str = cipher.decrypt(payload['aes'])\n        if 'sig' in payload:\n            m_path = os.path.join(self.opts['pki_dir'], self.mpub)\n            if os.path.exists(m_path):\n                try:\n                    with salt.utils.fopen(m_path) as f:\n                        mkey = RSA.importKey(f.read())\n                except Exception:\n                    return '', ''\n                digest = hashlib.sha256(key_str).hexdigest()\n                if six.PY3:\n                    digest = salt.utils.to_bytes(digest)\n                m_digest = public_decrypt(mkey.publickey(), payload['sig'])\n                if m_digest != digest:\n                    return '', ''\n        else:\n            return '', ''\n\n        if six.PY3:\n            key_str = salt.utils.to_str(key_str)\n\n        if '_|-' in key_str:\n            return key_str.split('_|-')\n        else:\n            if 'token' in payload:\n                token = cipher.decrypt(payload['token'])\n                return key_str, token\n            elif not master_pub:\n                return key_str, ''\n        return '', ''\n\n    def verify_pubkey_sig(self, message, sig):\n        '''\n        Wraps the verify_signature method so we have\n        additional checks.\n\n        :rtype: bool\n        :return: Success or failure of public key verification\n        '''\n        if self.opts['master_sign_key_name']:\n            path = os.path.join(self.opts['pki_dir'],\n                                self.opts['master_sign_key_name'] + '.pub')\n\n            if os.path.isfile(path):\n                res = verify_signature(path,\n                                       message,\n                                       binascii.a2b_base64(sig))\n            else:\n                log.error('Verification public key {0} does not exist. You '\n                          'need to copy it from the master to the minions '\n                          'pki directory'.format(os.path.basename(path)))\n                return False\n            if res:\n                log.debug('Successfully verified signature of master '\n                          'public key with verification public key '\n                          '{0}'.format(self.opts['master_sign_key_name'] + '.pub'))\n                return True\n            else:\n                log.debug('Failed to verify signature of public key')\n                return False\n        else:\n            log.error('Failed to verify the signature of the message because '\n                      'the verification key-pairs name is not defined. Please '\n                      'make sure that master_sign_key_name is defined.')\n            return False\n\n    def verify_signing_master(self, payload):\n        try:\n            if self.verify_pubkey_sig(payload['pub_key'],\n                                      payload['pub_sig']):\n                log.info('Received signed and verified master pubkey '\n                         'from master {0}'.format(self.opts['master']))\n                m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n                uid = salt.utils.get_uid(self.opts.get('user', None))\n                with salt.utils.fpopen(m_pub_fn, 'wb+', uid=uid) as wfh:\n                    wfh.write(salt.utils.to_bytes(payload['pub_key']))\n                return True\n            else:\n                log.error('Received signed public-key from master {0} '\n                          'but signature verification failed!'.format(self.opts['master']))\n                return False\n        except Exception as sign_exc:\n            log.error('There was an error while verifying the masters public-key signature')\n            raise Exception(sign_exc)\n\n    def check_auth_deps(self, payload):\n        '''\n        Checks if both master and minion either sign (master) and\n        verify (minion). If one side does not, it should fail.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', 'aes')\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n        '''\n        # master and minion sign and verify\n        if 'pub_sig' in payload and self.opts['verify_master_pubkey_sign']:\n            return True\n        # master and minion do NOT sign and do NOT verify\n        elif 'pub_sig' not in payload and not self.opts['verify_master_pubkey_sign']:\n            return True\n\n        # master signs, but minion does NOT verify\n        elif 'pub_sig' in payload and not self.opts['verify_master_pubkey_sign']:\n            log.error('The masters sent its public-key signature, but signature '\n                      'verification is not enabled on the minion. Either enable '\n                      'signature verification on the minion or disable signing '\n                      'the public key on the master!')\n            return False\n        # master does NOT sign but minion wants to verify\n        elif 'pub_sig' not in payload and self.opts['verify_master_pubkey_sign']:\n            log.error('The master did not send its public-key signature, but '\n                      'signature verification is enabled on the minion. Either '\n                      'disable signature verification on the minion or enable '\n                      'signing the public on the master!')\n            return False\n\n    def extract_aes(self, payload, master_pub=True):\n        '''\n        Return the AES key received from the master after the minion has been\n        successfully authenticated.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n\n        :rtype: str\n        :return: The shared AES key received from the master.\n        '''\n        if master_pub:\n            try:\n                aes, token = self.decrypt_aes(payload, master_pub)\n                if token != self.token:\n                    log.error(\n                        'The master failed to decrypt the random minion token'\n                    )\n                    return ''\n            except Exception:\n                log.error(\n                    'The master failed to decrypt the random minion token'\n                )\n                return ''\n            return aes\n        else:\n            aes, token = self.decrypt_aes(payload, master_pub)\n            return aes\n\n    def verify_master(self, payload, master_pub=True):\n        '''\n        Verify that the master is the same one that was previously accepted.\n\n        :param dict payload: The incoming payload. This is a dictionary which may have the following keys:\n            'aes': The shared AES key\n            'enc': The format of the message. ('clear', 'pub', etc)\n            'publish_port': The TCP port which published the message\n            'token': The encrypted token used to verify the message.\n            'pub_key': The RSA public key of the sender.\n        :param bool master_pub: Operate as if minion had no master pubkey when it sent auth request, i.e. don't verify\n        the minion signature\n\n        :rtype: str\n        :return: An empty string on verification failure. On success, the decrypted AES message in the payload.\n        '''\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n        m_pub_exists = os.path.isfile(m_pub_fn)\n        if m_pub_exists and master_pub and not self.opts['open_mode']:\n            with salt.utils.fopen(m_pub_fn) as fp_:\n                local_master_pub = fp_.read()\n\n            if payload['pub_key'].replace('\\n', '').replace('\\r', '') != \\\n                    local_master_pub.replace('\\n', '').replace('\\r', ''):\n                if not self.check_auth_deps(payload):\n                    return ''\n\n                if self.opts['verify_master_pubkey_sign']:\n                    if self.verify_signing_master(payload):\n                        return self.extract_aes(payload, master_pub=False)\n                    else:\n                        return ''\n                else:\n                    # This is not the last master we connected to\n                    log.error('The master key has changed, the salt master could '\n                              'have been subverted, verify salt master\\'s public '\n                              'key')\n                    return ''\n\n            else:\n                if not self.check_auth_deps(payload):\n                    return ''\n                # verify the signature of the pubkey even if it has\n                # not changed compared with the one we already have\n                if self.opts['always_verify_signature']:\n                    if self.verify_signing_master(payload):\n                        return self.extract_aes(payload)\n                    else:\n                        log.error('The masters public could not be verified. Is the '\n                                  'verification pubkey {0} up to date?'\n                                  ''.format(self.opts['master_sign_key_name'] + '.pub'))\n                        return ''\n\n                else:\n                    return self.extract_aes(payload)\n        else:\n            if not self.check_auth_deps(payload):\n                return ''\n\n            # verify the masters pubkey signature if the minion\n            # has not received any masters pubkey before\n            if self.opts['verify_master_pubkey_sign']:\n                if self.verify_signing_master(payload):\n                    return self.extract_aes(payload, master_pub=False)\n                else:\n                    return ''\n            else:\n                if not m_pub_exists:\n                    # the minion has not received any masters pubkey yet, write\n                    # the newly received pubkey to minion_master.pub\n                    with salt.utils.fopen(m_pub_fn, 'wb+') as fp_:\n                        fp_.write(salt.utils.to_bytes(payload['pub_key']))\n                return self.extract_aes(payload, master_pub=False)\n\n    def _finger_fail(self, finger, master_key):\n        log.critical(\n            'The specified fingerprint in the master configuration '\n            'file:\\n{0}\\nDoes not match the authenticating master\\'s '\n            'key:\\n{1}\\nVerify that the configured fingerprint '\n            'matches the fingerprint of the correct master and that '\n            'this minion is not subject to a man-in-the-middle attack.'\n            .format(\n                finger,\n                salt.utils.pem_finger(master_key, sum_type=self.opts['hash_type'])\n            )\n        )\n        sys.exit(42)\n\n\n# TODO: remove, we should just return a sync wrapper of AsyncAuth\nclass SAuth(AsyncAuth):\n    '''\n    Set up an object to maintain authentication with the salt master\n    '''\n    # This class is only a singleton per minion/master pair\n    instances = weakref.WeakValueDictionary()\n\n    def __new__(cls, opts, io_loop=None):\n        '''\n        Only create one instance of SAuth per __key()\n        '''\n        key = cls.__key(opts)\n        auth = SAuth.instances.get(key)\n        if auth is None:\n            log.debug('Initializing new SAuth for {0}'.format(key))\n            auth = object.__new__(cls)\n            auth.__singleton_init__(opts)\n            SAuth.instances[key] = auth\n        else:\n            log.debug('Re-using SAuth for {0}'.format(key))\n        return auth\n\n    @classmethod\n    def __key(cls, opts, io_loop=None):\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],  # master ID\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, io_loop=None):\n        super(SAuth, self).__init__(opts, io_loop=io_loop)\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, io_loop=None):\n        '''\n        Init an Auth instance\n\n        :param dict opts: Options for this server\n        :return: Auth instance\n        :rtype: Auth\n        '''\n        self.opts = opts\n        if six.PY2:\n            self.token = Crypticle.generate_key_string()\n        else:\n            self.token = salt.utils.to_bytes(Crypticle.generate_key_string())\n        self.serial = salt.payload.Serial(self.opts)\n        self.pub_path = os.path.join(self.opts['pki_dir'], 'minion.pub')\n        self.rsa_path = os.path.join(self.opts['pki_dir'], 'minion.pem')\n        if 'syndic_master' in self.opts:\n            self.mpub = 'syndic_master.pub'\n        elif 'alert_master' in self.opts:\n            self.mpub = 'monitor_master.pub'\n        else:\n            self.mpub = 'minion_master.pub'\n        if not os.path.isfile(self.pub_path):\n            self.get_keys()\n\n    @property\n    def creds(self):\n        if not hasattr(self, '_creds'):\n            self.authenticate()\n        return self._creds\n\n    @property\n    def crypticle(self):\n        if not hasattr(self, '_crypticle'):\n            self.authenticate()\n        return self._crypticle\n\n    def authenticate(self, _=None):  # TODO: remove unused var\n        '''\n        Authenticate with the master, this method breaks the functional\n        paradigm, it will update the master information from a fresh sign\n        in, signing in can occur as often as needed to keep up with the\n        revolving master AES key.\n\n        :rtype: Crypticle\n        :returns: A crypticle used for encryption operations\n        '''\n        acceptance_wait_time = self.opts['acceptance_wait_time']\n        acceptance_wait_time_max = self.opts['acceptance_wait_time_max']\n        channel = salt.transport.client.ReqChannel.factory(self.opts, crypt='clear')\n        if not acceptance_wait_time_max:\n            acceptance_wait_time_max = acceptance_wait_time\n        while True:\n            creds = self.sign_in(channel=channel)\n            if creds == 'retry':\n                if self.opts.get('caller'):\n                    print('Minion failed to authenticate with the master, '\n                          'has the minion key been accepted?')\n                    sys.exit(2)\n                if acceptance_wait_time:\n                    log.info('Waiting {0} seconds before retry.'.format(acceptance_wait_time))\n                    time.sleep(acceptance_wait_time)\n                if acceptance_wait_time < acceptance_wait_time_max:\n                    acceptance_wait_time += acceptance_wait_time\n                    log.debug('Authentication wait time is {0}'.format(acceptance_wait_time))\n                continue\n            break\n        self._creds = creds\n        self._crypticle = Crypticle(self.opts, creds['aes'])\n\n    def sign_in(self, timeout=60, safe=True, tries=1, channel=None):\n        '''\n        Send a sign in request to the master, sets the key information and\n        returns a dict containing the master publish interface to bind to\n        and the decrypted aes key for transport decryption.\n\n        :param int timeout: Number of seconds to wait before timing out the sign-in request\n        :param bool safe: If True, do not raise an exception on timeout. Retry instead.\n        :param int tries: The number of times to try to authenticate before giving up.\n\n        :raises SaltReqTimeoutError: If the sign-in request has timed out and :param safe: is not set\n\n        :return: Return a string on failure indicating the reason for failure. On success, return a dictionary\n        with the publication port and the shared AES key.\n\n        '''\n        auth = {}\n\n        auth_timeout = self.opts.get('auth_timeout', None)\n        if auth_timeout is not None:\n            timeout = auth_timeout\n        auth_safemode = self.opts.get('auth_safemode', None)\n        if auth_safemode is not None:\n            safe = auth_safemode\n        auth_tries = self.opts.get('auth_tries', None)\n        if auth_tries is not None:\n            tries = auth_tries\n\n        m_pub_fn = os.path.join(self.opts['pki_dir'], self.mpub)\n\n        auth['master_uri'] = self.opts['master_uri']\n\n        if not channel:\n            channel = salt.transport.client.ReqChannel.factory(self.opts, crypt='clear')\n\n        sign_in_payload = self.minion_sign_in_payload()\n        try:\n            payload = channel.send(\n                sign_in_payload,\n                tries=tries,\n                timeout=timeout\n            )\n        except SaltReqTimeoutError as e:\n            if safe:\n                log.warning('SaltReqTimeoutError: {0}'.format(e))\n                return 'retry'\n            raise SaltClientError('Attempt to authenticate with the salt master failed with timeout error')\n\n        if 'load' in payload:\n            if 'ret' in payload['load']:\n                if not payload['load']['ret']:\n                    if self.opts['rejected_retry']:\n                        log.error(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key.\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master.\\nThe Salt '\n                            'Minion will attempt to to re-authenicate.'\n                        )\n                        return 'retry'\n                    else:\n                        log.critical(\n                            'The Salt Master has rejected this minion\\'s public '\n                            'key!\\nTo repair this issue, delete the public key '\n                            'for this minion on the Salt Master and restart this '\n                            'minion.\\nOr restart the Salt Master in open mode to '\n                            'clean out the keys. The Salt Minion will now exit.'\n                        )\n                        sys.exit(salt.defaults.exitcodes.EX_OK)\n                # has the master returned that its maxed out with minions?\n                elif payload['load']['ret'] == 'full':\n                    return 'full'\n                else:\n                    log.error(\n                        'The Salt Master has cached the public key for this '\n                        'node. If this is the first time connecting to this master '\n                        'then this key may need to be accepted using \\'salt-key -a {0}\\' on '\n                        'the salt master. This salt minion will wait for {1} seconds '\n                        'before attempting to re-authenticate.'.format(\n                            self.opts['id'],\n                            self.opts['acceptance_wait_time']\n                        )\n                    )\n                    return 'retry'\n        auth['aes'] = self.verify_master(payload, master_pub='token' in sign_in_payload)\n        if not auth['aes']:\n            log.critical(\n                'The Salt Master server\\'s public key did not authenticate!\\n'\n                'The master may need to be updated if it is a version of Salt '\n                'lower than {0}, or\\n'\n                'If you are confident that you are connecting to a valid Salt '\n                'Master, then remove the master public key and restart the '\n                'Salt Minion.\\nThe master public key can be found '\n                'at:\\n{1}'.format(salt.version.__version__, m_pub_fn)\n            )\n            sys.exit(42)\n        if self.opts.get('syndic_master', False):  # Is syndic\n            syndic_finger = self.opts.get('syndic_finger', self.opts.get('master_finger', False))\n            if syndic_finger:\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != syndic_finger:\n                    self._finger_fail(syndic_finger, m_pub_fn)\n        else:\n            if self.opts.get('master_finger', False):\n                if salt.utils.pem_finger(m_pub_fn, sum_type=self.opts['hash_type']) != self.opts['master_finger']:\n                    self._finger_fail(self.opts['master_finger'], m_pub_fn)\n        auth['publish_port'] = payload['publish_port']\n        return auth\n\n\nclass Crypticle(object):\n    '''\n    Authenticated encryption class\n\n    Encryption algorithm: AES-CBC\n    Signing algorithm: HMAC-SHA256\n    '''\n\n    PICKLE_PAD = b'pickle::'\n    AES_BLOCK_SIZE = 16\n    SIG_SIZE = hashlib.sha256().digest_size\n\n    def __init__(self, opts, key_string, key_size=192):\n        self.key_string = key_string\n        self.keys = self.extract_keys(self.key_string, key_size)\n        self.key_size = key_size\n        self.serial = salt.payload.Serial(opts)\n\n    @classmethod\n    def generate_key_string(cls, key_size=192):\n        key = os.urandom(key_size // 8 + cls.SIG_SIZE)\n        b64key = base64.b64encode(key)\n        if six.PY3:\n            b64key = b64key.decode('utf-8')\n        return b64key.replace('\\n', '')\n\n    @classmethod\n    def extract_keys(cls, key_string, key_size):\n        if six.PY2:\n            key = key_string.decode('base64')\n        else:\n            key = salt.utils.to_bytes(base64.b64decode(key_string))\n        assert len(key) == key_size / 8 + cls.SIG_SIZE, 'invalid key'\n        return key[:-cls.SIG_SIZE], key[-cls.SIG_SIZE:]\n\n    def encrypt(self, data):\n        '''\n        encrypt data with AES-CBC and sign it with HMAC-SHA256\n        '''\n        aes_key, hmac_key = self.keys\n        pad = self.AES_BLOCK_SIZE - len(data) % self.AES_BLOCK_SIZE\n        if six.PY2:\n            data = data + pad * chr(pad)\n        else:\n            data = data + salt.utils.to_bytes(pad * chr(pad))\n        iv_bytes = os.urandom(self.AES_BLOCK_SIZE)\n        cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)\n        data = iv_bytes + cypher.encrypt(data)\n        sig = hmac.new(hmac_key, data, hashlib.sha256).digest()\n        return data + sig\n\n    def decrypt(self, data):\n        '''\n        verify HMAC-SHA256 signature and decrypt data with AES-CBC\n        '''\n        aes_key, hmac_key = self.keys\n        sig = data[-self.SIG_SIZE:]\n        data = data[:-self.SIG_SIZE]\n        if six.PY3 and not isinstance(data, bytes):\n            data = salt.utils.to_bytes(data)\n        mac_bytes = hmac.new(hmac_key, data, hashlib.sha256).digest()\n        if len(mac_bytes) != len(sig):\n            log.debug('Failed to authenticate message')\n            raise AuthenticationError('message authentication failed')\n        result = 0\n\n        if six.PY2:\n            for zipped_x, zipped_y in zip(mac_bytes, sig):\n                result |= ord(zipped_x) ^ ord(zipped_y)\n        else:\n            for zipped_x, zipped_y in zip(mac_bytes, sig):\n                result |= zipped_x ^ zipped_y\n        if result != 0:\n            log.debug('Failed to authenticate message')\n            raise AuthenticationError('message authentication failed')\n        iv_bytes = data[:self.AES_BLOCK_SIZE]\n        data = data[self.AES_BLOCK_SIZE:]\n        cypher = AES.new(aes_key, AES.MODE_CBC, iv_bytes)\n        data = cypher.decrypt(data)\n        if six.PY2:\n            return data[:-ord(data[-1])]\n        else:\n            return data[:-data[-1]]\n\n    def dumps(self, obj):\n        '''\n        Serialize and encrypt a python object\n        '''\n        return self.encrypt(self.PICKLE_PAD + self.serial.dumps(obj))\n\n    def loads(self, data, raw=False):\n        '''\n        Decrypt and un-serialize a python object\n        '''\n        data = self.decrypt(data)\n        # simple integrity check to verify that we got meaningful data\n        if not data.startswith(self.PICKLE_PAD):\n            return {}\n        load = self.serial.loads(data[len(self.PICKLE_PAD):], raw=raw)\n        return load\n", "# -*- coding: utf-8 -*-\n'''\nTCP transport classes\n\nWire protocol: \"len(payload) msgpack({'head': SOMEHEADER, 'body': SOMEBODY})\"\n\n'''\n\n# Import Python Libs\nfrom __future__ import absolute_import\nimport logging\nimport msgpack\nimport socket\nimport os\nimport weakref\nimport time\nimport traceback\nimport errno\n\n# Import Salt Libs\nimport salt.crypt\nimport salt.utils\nimport salt.utils.verify\nimport salt.utils.event\nimport salt.utils.async\nimport salt.payload\nimport salt.exceptions\nimport salt.transport.frame\nimport salt.transport.ipc\nimport salt.transport.client\nimport salt.transport.server\nimport salt.transport.mixins.auth\nimport salt.ext.six as six\nfrom salt.exceptions import SaltReqTimeoutError, SaltClientError\nfrom salt.transport import iter_transport_opts\n\n# Import Tornado Libs\nimport tornado\nimport tornado.tcpserver\nimport tornado.gen\nimport tornado.concurrent\nimport tornado.tcpclient\nimport tornado.netutil\n\n# pylint: disable=import-error,no-name-in-module\nif six.PY2:\n    import urlparse\nelse:\n    import urllib.parse as urlparse\n# pylint: enable=import-error,no-name-in-module\n\n# Import third party libs\ntry:\n    from Cryptodome.Cipher import PKCS1_OAEP\nexcept ImportError:\n    from Crypto.Cipher import PKCS1_OAEP\n\nif six.PY3 and salt.utils.is_windows():\n    USE_LOAD_BALANCER = True\nelse:\n    USE_LOAD_BALANCER = False\n\nif USE_LOAD_BALANCER:\n    import threading\n    import multiprocessing\n    import errno\n    import tornado.util\n    from salt.utils.process import SignalHandlingMultiprocessingProcess\n\nlog = logging.getLogger(__name__)\n\n\ndef _set_tcp_keepalive(sock, opts):\n    '''\n    Ensure that TCP keepalives are set for the socket.\n    '''\n    if hasattr(socket, 'SO_KEEPALIVE'):\n        if opts.get('tcp_keepalive', False):\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n            if hasattr(socket, 'SOL_TCP'):\n                if hasattr(socket, 'TCP_KEEPIDLE'):\n                    tcp_keepalive_idle = opts.get('tcp_keepalive_idle', -1)\n                    if tcp_keepalive_idle > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPIDLE,\n                            int(tcp_keepalive_idle))\n                if hasattr(socket, 'TCP_KEEPCNT'):\n                    tcp_keepalive_cnt = opts.get('tcp_keepalive_cnt', -1)\n                    if tcp_keepalive_cnt > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPCNT,\n                            int(tcp_keepalive_cnt))\n                if hasattr(socket, 'TCP_KEEPINTVL'):\n                    tcp_keepalive_intvl = opts.get('tcp_keepalive_intvl', -1)\n                    if tcp_keepalive_intvl > 0:\n                        sock.setsockopt(\n                            socket.SOL_TCP, socket.TCP_KEEPINTVL,\n                            int(tcp_keepalive_intvl))\n            if hasattr(socket, 'SIO_KEEPALIVE_VALS'):\n                # Windows doesn't support TCP_KEEPIDLE, TCP_KEEPCNT, nor\n                # TCP_KEEPINTVL. Instead, it has its own proprietary\n                # SIO_KEEPALIVE_VALS.\n                tcp_keepalive_idle = opts.get('tcp_keepalive_idle', -1)\n                tcp_keepalive_intvl = opts.get('tcp_keepalive_intvl', -1)\n                # Windows doesn't support changing something equivalent to\n                # TCP_KEEPCNT.\n                if tcp_keepalive_idle > 0 or tcp_keepalive_intvl > 0:\n                    # Windows defaults may be found by using the link below.\n                    # Search for 'KeepAliveTime' and 'KeepAliveInterval'.\n                    # https://technet.microsoft.com/en-us/library/bb726981.aspx#EDAA\n                    # If one value is set and the other isn't, we still need\n                    # to send both values to SIO_KEEPALIVE_VALS and they both\n                    # need to be valid. So in that case, use the Windows\n                    # default.\n                    if tcp_keepalive_idle <= 0:\n                        tcp_keepalive_idle = 7200\n                    if tcp_keepalive_intvl <= 0:\n                        tcp_keepalive_intvl = 1\n                    # The values expected are in milliseconds, so multiply by\n                    # 1000.\n                    sock.ioctl(socket.SIO_KEEPALIVE_VALS, (\n                        1, int(tcp_keepalive_idle * 1000),\n                        int(tcp_keepalive_intvl * 1000)))\n        else:\n            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 0)\n\n\nif USE_LOAD_BALANCER:\n    class LoadBalancerServer(SignalHandlingMultiprocessingProcess):\n        '''\n        Raw TCP server which runs in its own process and will listen\n        for incoming connections. Each incoming connection will be\n        sent via multiprocessing queue to the workers.\n        Since the queue is shared amongst workers, only one worker will\n        handle a given connection.\n        '''\n        # TODO: opts!\n        # Based on default used in tornado.netutil.bind_sockets()\n        backlog = 128\n\n        def __init__(self, opts, socket_queue, log_queue=None):\n            super(LoadBalancerServer, self).__init__(log_queue=log_queue)\n            self.opts = opts\n            self.socket_queue = socket_queue\n            self._socket = None\n\n        # __setstate__ and __getstate__ are only used on Windows.\n        # We do this so that __init__ will be invoked on Windows in the child\n        # process so that a register_after_fork() equivalent will work on\n        # Windows.\n        def __setstate__(self, state):\n            self._is_child = True\n            self.__init__(\n                state['opts'],\n                state['socket_queue'],\n                log_queue=state['log_queue']\n            )\n\n        def __getstate__(self):\n            return {'opts': self.opts,\n                    'socket_queue': self.socket_queue,\n                    'log_queue': self.log_queue}\n\n        def close(self):\n            if self._socket is not None:\n                self._socket.shutdown(socket.SHUT_RDWR)\n                self._socket.close()\n                self._socket = None\n\n        def __del__(self):\n            self.close()\n\n        def run(self):\n            '''\n            Start the load balancer\n            '''\n            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            _set_tcp_keepalive(self._socket, self.opts)\n            self._socket.setblocking(1)\n            self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n            self._socket.listen(self.backlog)\n\n            while True:\n                try:\n                    # Wait for a connection to occur since the socket is\n                    # blocking.\n                    connection, address = self._socket.accept()\n                    # Wait for a free slot to be available to put\n                    # the connection into.\n                    # Sockets are picklable on Windows in Python 3.\n                    self.socket_queue.put((connection, address), True, None)\n                except socket.error as e:\n                    # ECONNABORTED indicates that there was a connection\n                    # but it was closed while still in the accept queue.\n                    # (observed on FreeBSD).\n                    if tornado.util.errno_from_exception(e) == errno.ECONNABORTED:\n                        continue\n                    raise\n\n\n# TODO: move serial down into message library\nclass AsyncTCPReqChannel(salt.transport.client.ReqChannel):\n    '''\n    Encapsulate sending routines to tcp.\n\n    Note: this class returns a singleton\n    '''\n    # This class is only a singleton per minion/master pair\n    # mapping of io_loop -> {key -> channel}\n    instance_map = weakref.WeakKeyDictionary()\n\n    def __new__(cls, opts, **kwargs):\n        '''\n        Only create one instance of channel per __key()\n        '''\n        # do we have any mapping for this io_loop\n        io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n        if io_loop not in cls.instance_map:\n            cls.instance_map[io_loop] = weakref.WeakValueDictionary()\n        loop_instance_map = cls.instance_map[io_loop]\n\n        key = cls.__key(opts, **kwargs)\n        obj = loop_instance_map.get(key)\n        if obj is None:\n            log.debug('Initializing new AsyncTCPReqChannel for {0}'.format(key))\n            # we need to make a local variable for this, as we are going to store\n            # it in a WeakValueDictionary-- which will remove the item if no one\n            # references it-- this forces a reference while we return to the caller\n            obj = object.__new__(cls)\n            obj.__singleton_init__(opts, **kwargs)\n            loop_instance_map[key] = obj\n        else:\n            log.debug('Re-using AsyncTCPReqChannel for {0}'.format(key))\n        return obj\n\n    @classmethod\n    def __key(cls, opts, **kwargs):\n        if 'master_uri' in kwargs:\n            opts['master_uri'] = kwargs['master_uri']\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                opts['master_uri'],\n                kwargs.get('crypt', 'aes'),  # TODO: use the same channel for crypt\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, **kwargs):\n        pass\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, **kwargs):\n        self.opts = dict(opts)\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        # crypt defaults to 'aes'\n        self.crypt = kwargs.get('crypt', 'aes')\n\n        self.io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n\n        if self.crypt != 'clear':\n            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)\n\n        resolver = kwargs.get('resolver')\n\n        parse = urlparse.urlparse(self.opts['master_uri'])\n        host, port = parse.netloc.rsplit(':', 1)\n        self.master_addr = (host, int(port))\n        self._closing = False\n        self.message_client = SaltMessageClientPool(self.opts,\n                                                    args=(self.opts, host, int(port),),\n                                                    kwargs={'io_loop': self.io_loop, 'resolver': resolver})\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        self.message_client.close()\n\n    def __del__(self):\n        self.close()\n\n    def _package_load(self, load):\n        return {\n            'enc': self.crypt,\n            'load': load,\n        }\n\n    @tornado.gen.coroutine\n    def crypted_transfer_decode_dictentry(self, load, dictkey=None, tries=3, timeout=60):\n        if not self.auth.authenticated:\n            yield self.auth.authenticate()\n        ret = yield self.message_client.send(self._package_load(self.auth.crypticle.dumps(load)), timeout=timeout)\n        key = self.auth.get_keys()\n        cipher = PKCS1_OAEP.new(key)\n        aes = cipher.decrypt(ret['key'])\n        pcrypt = salt.crypt.Crypticle(self.opts, aes)\n        data = pcrypt.loads(ret[dictkey])\n        if six.PY3:\n            data = salt.transport.frame.decode_embedded_strs(data)\n        raise tornado.gen.Return(data)\n\n    @tornado.gen.coroutine\n    def _crypted_transfer(self, load, tries=3, timeout=60):\n        '''\n        In case of authentication errors, try to renegotiate authentication\n        and retry the method.\n        Indeed, we can fail too early in case of a master restart during a\n        minion state execution call\n        '''\n        @tornado.gen.coroutine\n        def _do_transfer():\n            data = yield self.message_client.send(self._package_load(self.auth.crypticle.dumps(load)),\n                                                  timeout=timeout,\n                                                  )\n            # we may not have always data\n            # as for example for saltcall ret submission, this is a blind\n            # communication, we do not subscribe to return events, we just\n            # upload the results to the master\n            if data:\n                data = self.auth.crypticle.loads(data)\n                if six.PY3:\n                    data = salt.transport.frame.decode_embedded_strs(data)\n            raise tornado.gen.Return(data)\n\n        if not self.auth.authenticated:\n            yield self.auth.authenticate()\n        try:\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n        except salt.crypt.AuthenticationError:\n            yield self.auth.authenticate()\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def _uncrypted_transfer(self, load, tries=3, timeout=60):\n        ret = yield self.message_client.send(self._package_load(load), timeout=timeout)\n        raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def send(self, load, tries=3, timeout=60, raw=False):\n        '''\n        Send a request, return a future which will complete when we send the message\n        '''\n        try:\n            if self.crypt == 'clear':\n                ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)\n            else:\n                ret = yield self._crypted_transfer(load, tries=tries, timeout=timeout)\n        except tornado.iostream.StreamClosedError:\n            # Convert to 'SaltClientError' so that clients can handle this\n            # exception more appropriately.\n            raise SaltClientError('Connection to master lost')\n        raise tornado.gen.Return(ret)\n\n\nclass AsyncTCPPubChannel(salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel):\n    def __init__(self,\n                 opts,\n                 **kwargs):\n        self.opts = opts\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        self.crypt = kwargs.get('crypt', 'aes')\n        self.io_loop = kwargs.get('io_loop') or tornado.ioloop.IOLoop.current()\n        self.connected = False\n        self._closing = False\n        self._reconnected = False\n        self.event = salt.utils.event.get_event(\n            'minion',\n            opts=self.opts,\n            listen=False\n        )\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if hasattr(self, 'message_client'):\n            self.message_client.close()\n\n    def __del__(self):\n        self.close()\n\n    def _package_load(self, load):\n        return {\n            'enc': self.crypt,\n            'load': load,\n        }\n\n    @tornado.gen.coroutine\n    def send_id(self, tok, force_auth):\n        '''\n        Send the minion id to the master so that the master may better\n        track the connection state of the minion.\n        In case of authentication errors, try to renegotiate authentication\n        and retry the method.\n        '''\n        load = {'id': self.opts['id'], 'tok': tok}\n\n        @tornado.gen.coroutine\n        def _do_transfer():\n            msg = self._package_load(self.auth.crypticle.dumps(load))\n            package = salt.transport.frame.frame_msg(msg, header=None)\n            yield self.message_client.write_to_stream(package)\n            raise tornado.gen.Return(True)\n\n        if force_auth or not self.auth.authenticated:\n            count = 0\n            while count <= self.opts['tcp_authentication_retries'] or self.opts['tcp_authentication_retries'] < 0:\n                try:\n                    yield self.auth.authenticate()\n                    break\n                except SaltClientError as exc:\n                    log.debug(exc)\n                    count += 1\n        try:\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n        except salt.crypt.AuthenticationError:\n            yield self.auth.authenticate()\n            ret = yield _do_transfer()\n            raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def connect_callback(self, result):\n        if self._closing:\n            return\n        # Force re-auth on reconnect since the master\n        # may have been restarted\n        yield self.send_id(self.tok, self._reconnected)\n        self.connected = True\n        self.event.fire_event(\n            {'master': self.opts['master']},\n            '__master_connected'\n        )\n        if self._reconnected:\n            # On reconnects, fire a master event to notify that the minion is\n            # available.\n            if self.opts.get('__role') == 'syndic':\n                data = 'Syndic {0} started at {1}'.format(\n                    self.opts['id'],\n                    time.asctime()\n                )\n                tag = salt.utils.event.tagify(\n                    [self.opts['id'], 'start'],\n                    'syndic'\n                )\n            else:\n                data = 'Minion {0} started at {1}'.format(\n                    self.opts['id'],\n                    time.asctime()\n                )\n                tag = salt.utils.event.tagify(\n                    [self.opts['id'], 'start'],\n                    'minion'\n                )\n            load = {'id': self.opts['id'],\n                    'cmd': '_minion_event',\n                    'pretag': None,\n                    'tok': self.tok,\n                    'data': data,\n                    'tag': tag}\n            req_channel = salt.utils.async.SyncWrapper(\n                AsyncTCPReqChannel, (self.opts,)\n            )\n            try:\n                req_channel.send(load, timeout=60)\n            except salt.exceptions.SaltReqTimeoutError:\n                log.info('fire_master failed: master could not be contacted. Request timed out.')\n            except Exception:\n                log.info('fire_master failed: {0}'.format(\n                    traceback.format_exc())\n                )\n        else:\n            self._reconnected = True\n\n    def disconnect_callback(self):\n        if self._closing:\n            return\n        self.connected = False\n        self.event.fire_event(\n            {'master': self.opts['master']},\n            '__master_disconnected'\n        )\n\n    @tornado.gen.coroutine\n    def connect(self):\n        try:\n            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)\n            self.tok = self.auth.gen_token('salt')\n            if not self.auth.authenticated:\n                yield self.auth.authenticate()\n            if self.auth.authenticated:\n                self.message_client = SaltMessageClientPool(\n                    self.opts,\n                    args=(self.opts, self.opts['master_ip'], int(self.auth.creds['publish_port']),),\n                    kwargs={'io_loop': self.io_loop,\n                            'connect_callback': self.connect_callback,\n                            'disconnect_callback': self.disconnect_callback})\n                yield self.message_client.connect()  # wait for the client to be connected\n                self.connected = True\n        # TODO: better exception handling...\n        except KeyboardInterrupt:\n            raise\n        except Exception as exc:\n            if '-|RETRY|-' not in str(exc):\n                raise SaltClientError('Unable to sign_in to master: {0}'.format(exc))  # TODO: better error message\n\n    def on_recv(self, callback):\n        '''\n        Register an on_recv callback\n        '''\n        if callback is None:\n            return self.message_client.on_recv(callback)\n\n        @tornado.gen.coroutine\n        def wrap_callback(body):\n            if not isinstance(body, dict):\n                # TODO: For some reason we need to decode here for things\n                #       to work. Fix this.\n                body = msgpack.loads(body)\n                if six.PY3:\n                    body = salt.transport.frame.decode_embedded_strs(body)\n            ret = yield self._decode_payload(body)\n            callback(ret)\n        return self.message_client.on_recv(wrap_callback)\n\n\nclass TCPReqServerChannel(salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel):\n    # TODO: opts!\n    backlog = 5\n\n    def __init__(self, opts):\n        salt.transport.server.ReqServerChannel.__init__(self, opts)\n        self._socket = None\n\n    @property\n    def socket(self):\n        return self._socket\n\n    def close(self):\n        if self._socket is not None:\n            try:\n                self._socket.shutdown(socket.SHUT_RDWR)\n            except socket.error as exc:\n                if exc.errno == errno.ENOTCONN:\n                    # We may try to shutdown a socket which is already disconnected.\n                    # Ignore this condition and continue.\n                    pass\n                else:\n                    raise exc\n            self._socket.close()\n            self._socket = None\n\n    def __del__(self):\n        self.close()\n\n    def pre_fork(self, process_manager):\n        '''\n        Pre-fork we need to create the zmq router device\n        '''\n        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)\n        if USE_LOAD_BALANCER:\n            self.socket_queue = multiprocessing.Queue()\n            process_manager.add_process(\n                LoadBalancerServer, args=(self.opts, self.socket_queue)\n            )\n        elif not salt.utils.is_windows():\n            self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n            self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n            _set_tcp_keepalive(self._socket, self.opts)\n            self._socket.setblocking(0)\n            self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n\n    def post_fork(self, payload_handler, io_loop):\n        '''\n        After forking we need to create all of the local sockets to listen to the\n        router\n\n        payload_handler: function to call with your payloads\n        '''\n        self.payload_handler = payload_handler\n        self.io_loop = io_loop\n        self.serial = salt.payload.Serial(self.opts)\n        if USE_LOAD_BALANCER:\n            self.req_server = LoadBalancerWorker(self.socket_queue,\n                                                 self.handle_message,\n                                                 io_loop=self.io_loop,\n                                                 ssl_options=self.opts.get('ssl'))\n        else:\n            if salt.utils.is_windows():\n                self._socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n                self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n                _set_tcp_keepalive(self._socket, self.opts)\n                self._socket.setblocking(0)\n                self._socket.bind((self.opts['interface'], int(self.opts['ret_port'])))\n            self.req_server = SaltMessageServer(self.handle_message,\n                                                io_loop=self.io_loop,\n                                                ssl_options=self.opts.get('ssl'))\n            self.req_server.add_socket(self._socket)\n            self._socket.listen(self.backlog)\n        salt.transport.mixins.auth.AESReqServerMixin.post_fork(self, payload_handler, io_loop)\n\n    @tornado.gen.coroutine\n    def handle_message(self, stream, header, payload):\n        '''\n        Handle incoming messages from underylying tcp streams\n        '''\n        try:\n            try:\n                payload = self._decode_payload(payload)\n            except Exception:\n                stream.write(salt.transport.frame.frame_msg('bad load', header=header))\n                raise tornado.gen.Return()\n\n            # TODO helper functions to normalize payload?\n            if not isinstance(payload, dict) or not isinstance(payload.get('load'), dict):\n                yield stream.write(salt.transport.frame.frame_msg(\n                    'payload and load must be a dict', header=header))\n                raise tornado.gen.Return()\n\n            try:\n                id_ = payload['load'].get('id', '')\n                if '\\0' in id_:\n                    log.error('Payload contains an id with a null byte: %s', payload)\n                    stream.send(self.serial.dumps('bad load: id contains a null byte'))\n                    raise tornado.gen.Return()\n            except TypeError:\n                log.error('Payload contains non-string id: %s', payload)\n                stream.send(self.serial.dumps('bad load: id {0} is not a string'.format(id_)))\n                raise tornado.gen.Return()\n\n            # intercept the \"_auth\" commands, since the main daemon shouldn't know\n            # anything about our key auth\n            if payload['enc'] == 'clear' and payload.get('load', {}).get('cmd') == '_auth':\n                yield stream.write(salt.transport.frame.frame_msg(\n                    self._auth(payload['load']), header=header))\n                raise tornado.gen.Return()\n\n            # TODO: test\n            try:\n                ret, req_opts = yield self.payload_handler(payload)\n            except Exception as e:\n                # always attempt to return an error to the minion\n                stream.write('Some exception handling minion payload')\n                log.error('Some exception handling a payload from minion', exc_info=True)\n                stream.close()\n                raise tornado.gen.Return()\n\n            req_fun = req_opts.get('fun', 'send')\n            if req_fun == 'send_clear':\n                stream.write(salt.transport.frame.frame_msg(ret, header=header))\n            elif req_fun == 'send':\n                stream.write(salt.transport.frame.frame_msg(self.crypticle.dumps(ret), header=header))\n            elif req_fun == 'send_private':\n                stream.write(salt.transport.frame.frame_msg(self._encrypt_private(ret,\n                                                             req_opts['key'],\n                                                             req_opts['tgt'],\n                                                             ), header=header))\n            else:\n                log.error('Unknown req_fun {0}'.format(req_fun))\n                # always attempt to return an error to the minion\n                stream.write('Server-side exception handling payload')\n                stream.close()\n        except tornado.gen.Return:\n            raise\n        except tornado.iostream.StreamClosedError:\n            # Stream was closed. This could happen if the remote side\n            # closed the connection on its end (eg in a timeout or shutdown\n            # situation).\n            log.error('Connection was unexpectedly closed', exc_info=True)\n        except Exception as exc:  # pylint: disable=broad-except\n            # Absorb any other exceptions\n            log.error('Unexpected exception occurred: {0}'.format(exc), exc_info=True)\n\n        raise tornado.gen.Return()\n\n\nclass SaltMessageServer(tornado.tcpserver.TCPServer, object):\n    '''\n    Raw TCP server which will receive all of the TCP streams and re-assemble\n    messages that are sent through to us\n    '''\n    def __init__(self, message_handler, *args, **kwargs):\n        super(SaltMessageServer, self).__init__(*args, **kwargs)\n\n        self.clients = []\n        self.message_handler = message_handler\n\n    @tornado.gen.coroutine\n    def handle_stream(self, stream, address):\n        '''\n        Handle incoming streams and add messages to the incoming queue\n        '''\n        log.trace('Req client {0} connected'.format(address))\n        self.clients.append((stream, address))\n        unpacker = msgpack.Unpacker()\n        try:\n            while True:\n                wire_bytes = yield stream.read_bytes(4096, partial=True)\n                unpacker.feed(wire_bytes)\n                for framed_msg in unpacker:\n                    if six.PY3:\n                        framed_msg = salt.transport.frame.decode_embedded_strs(\n                            framed_msg\n                        )\n                    header = framed_msg['head']\n                    self.io_loop.spawn_callback(self.message_handler, stream, header, framed_msg['body'])\n\n        except tornado.iostream.StreamClosedError:\n            log.trace('req client disconnected {0}'.format(address))\n            self.clients.remove((stream, address))\n        except Exception as e:\n            log.trace('other master-side exception: {0}'.format(e))\n            self.clients.remove((stream, address))\n            stream.close()\n\n    def shutdown(self):\n        '''\n        Shutdown the whole server\n        '''\n        for item in self.clients:\n            client, address = item\n            client.close()\n            self.clients.remove(item)\n\n\nif USE_LOAD_BALANCER:\n    class LoadBalancerWorker(SaltMessageServer):\n        '''\n        This will receive TCP connections from 'LoadBalancerServer' via\n        a multiprocessing queue.\n        Since the queue is shared amongst workers, only one worker will handle\n        a given connection.\n        '''\n        def __init__(self, socket_queue, message_handler, *args, **kwargs):\n            super(LoadBalancerWorker, self).__init__(\n                message_handler, *args, **kwargs)\n            self.socket_queue = socket_queue\n\n            t = threading.Thread(target=self.socket_queue_thread)\n            t.start()\n\n        def socket_queue_thread(self):\n            try:\n                while True:\n                    client_socket, address = self.socket_queue.get(True, None)\n\n                    # 'self.io_loop' initialized in super class\n                    # 'tornado.tcpserver.TCPServer'.\n                    # 'self._handle_connection' defined in same super class.\n                    self.io_loop.spawn_callback(\n                        self._handle_connection, client_socket, address)\n            except (KeyboardInterrupt, SystemExit):\n                pass\n\n\nclass TCPClientKeepAlive(tornado.tcpclient.TCPClient):\n    '''\n    Override _create_stream() in TCPClient to enable keep alive support.\n    '''\n    def __init__(self, opts, resolver=None, io_loop=None):\n        self.opts = opts\n        super(TCPClientKeepAlive, self).__init__(\n            resolver=resolver, io_loop=io_loop)\n\n    def _create_stream(self, max_buffer_size, af, addr, **kwargs):  # pylint: disable=unused-argument\n        '''\n        Override _create_stream() in TCPClient.\n\n        Tornado 4.5 added the kwargs 'source_ip' and 'source_port'.\n        Due to this, use **kwargs to swallow these and any future\n        kwargs to maintain compatibility.\n        '''\n        # Always connect in plaintext; we'll convert to ssl if necessary\n        # after one connection has completed.\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        _set_tcp_keepalive(sock, self.opts)\n        stream = tornado.iostream.IOStream(\n            sock,\n            io_loop=self.io_loop,\n            max_buffer_size=max_buffer_size)\n        return stream.connect(addr)\n\n\nclass SaltMessageClientPool(salt.transport.MessageClientPool):\n    '''\n    Wrapper class of SaltMessageClient to avoid blocking waiting while writing data to socket.\n    '''\n    def __init__(self, opts, args=None, kwargs=None):\n        super(SaltMessageClientPool, self).__init__(SaltMessageClient, opts, args=args, kwargs=kwargs)\n\n    def __del__(self):\n        self.close()\n\n    def close(self):\n        for message_client in self.message_clients:\n            message_client.close()\n        self.message_clients = []\n\n    @tornado.gen.coroutine\n    def connect(self):\n        futures = []\n        for message_client in self.message_clients:\n            futures.append(message_client.connect())\n        for future in futures:\n            yield future\n        raise tornado.gen.Return(None)\n\n    def on_recv(self, *args, **kwargs):\n        for message_client in self.message_clients:\n            message_client.on_recv(*args, **kwargs)\n\n    def send(self, *args, **kwargs):\n        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))\n        return message_clients[0].send(*args, **kwargs)\n\n    def write_to_stream(self, *args, **kwargs):\n        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))\n        return message_clients[0]._stream.write(*args, **kwargs)\n\n\n# TODO consolidate with IPCClient\n# TODO: limit in-flight messages.\n# TODO: singleton? Something to not re-create the tcp connection so much\nclass SaltMessageClient(object):\n    '''\n    Low-level message sending client\n    '''\n    def __init__(self, opts, host, port, io_loop=None, resolver=None,\n                 connect_callback=None, disconnect_callback=None):\n        self.opts = opts\n        self.host = host\n        self.port = port\n        self.connect_callback = connect_callback\n        self.disconnect_callback = disconnect_callback\n\n        self.io_loop = io_loop or tornado.ioloop.IOLoop.current()\n\n        self._tcp_client = TCPClientKeepAlive(\n            opts, io_loop=self.io_loop, resolver=resolver)\n\n        self._mid = 1\n        self._max_messages = int((1 << 31) - 2)  # number of IDs before we wrap\n\n        # TODO: max queue size\n        self.send_queue = []  # queue of messages to be sent\n        self.send_future_map = {}  # mapping of request_id -> Future\n        self.send_timeout_map = {}  # request_id -> timeout_callback\n\n        self._read_until_future = None\n        self._on_recv = None\n        self._closing = False\n        self._connecting_future = self.connect()\n        self._stream_return_future = tornado.concurrent.Future()\n        self.io_loop.spawn_callback(self._stream_return)\n\n    # TODO: timeout inflight sessions\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if hasattr(self, '_stream') and not self._stream.closed():\n            self._stream.close()\n            if self._read_until_future is not None:\n                # This will prevent this message from showing up:\n                # '[ERROR   ] Future exception was never retrieved:\n                # StreamClosedError'\n                # This happens because the logic is always waiting to read\n                # the next message and the associated read future is marked\n                # 'StreamClosedError' when the stream is closed.\n                self._read_until_future.exc_info()\n                if (not self._stream_return_future.done() and\n                        self.io_loop != tornado.ioloop.IOLoop.current(\n                            instance=False)):\n                    # If _stream_return() hasn't completed, it means the IO\n                    # Loop is stopped (such as when using\n                    # 'salt.utils.async.SyncWrapper'). Ensure that\n                    # _stream_return() completes by restarting the IO Loop.\n                    # This will prevent potential errors on shutdown.\n                    orig_loop = tornado.ioloop.IOLoop.current()\n                    self.io_loop.make_current()\n                    try:\n                        self.io_loop.add_future(\n                            self._stream_return_future,\n                            lambda future: self.io_loop.stop()\n                        )\n                        self.io_loop.start()\n                    finally:\n                        orig_loop.make_current()\n        self._tcp_client.close()\n        # Clear callback references to allow the object that they belong to\n        # to be deleted.\n        self.connect_callback = None\n        self.disconnect_callback = None\n\n    def __del__(self):\n        self.close()\n\n    def connect(self):\n        '''\n        Ask for this client to reconnect to the origin\n        '''\n        if hasattr(self, '_connecting_future') and not self._connecting_future.done():\n            future = self._connecting_future\n        else:\n            future = tornado.concurrent.Future()\n            self._connecting_future = future\n            self.io_loop.add_callback(self._connect)\n\n            # Add the callback only when a new future is created\n            if self.connect_callback is not None:\n                def handle_future(future):\n                    response = future.result()\n                    self.io_loop.add_callback(self.connect_callback, response)\n                future.add_done_callback(handle_future)\n\n        return future\n\n    # TODO: tcp backoff opts\n    @tornado.gen.coroutine\n    def _connect(self):\n        '''\n        Try to connect for the rest of time!\n        '''\n        while True:\n            if self._closing:\n                break\n            try:\n                self._stream = yield self._tcp_client.connect(self.host,\n                                                              self.port,\n                                                              ssl_options=self.opts.get('ssl'))\n                self._connecting_future.set_result(True)\n                break\n            except Exception as e:\n                yield tornado.gen.sleep(1)  # TODO: backoff\n                #self._connecting_future.set_exception(e)\n\n    @tornado.gen.coroutine\n    def _stream_return(self):\n        try:\n            while not self._closing and (\n                    not self._connecting_future.done() or\n                    self._connecting_future.result() is not True):\n                yield self._connecting_future\n            unpacker = msgpack.Unpacker()\n            while not self._closing:\n                try:\n                    self._read_until_future = self._stream.read_bytes(4096, partial=True)\n                    wire_bytes = yield self._read_until_future\n                    unpacker.feed(wire_bytes)\n                    for framed_msg in unpacker:\n                        if six.PY3:\n                            framed_msg = salt.transport.frame.decode_embedded_strs(\n                                framed_msg\n                            )\n                        header = framed_msg['head']\n                        body = framed_msg['body']\n                        message_id = header.get('mid')\n\n                        if message_id in self.send_future_map:\n                            self.send_future_map.pop(message_id).set_result(body)\n                            self.remove_message_timeout(message_id)\n                        else:\n                            if self._on_recv is not None:\n                                self.io_loop.spawn_callback(self._on_recv, header, body)\n                            else:\n                                log.error('Got response for message_id {0} that we are not tracking'.format(message_id))\n                except tornado.iostream.StreamClosedError as e:\n                    log.debug('tcp stream to {0}:{1} closed, unable to recv'.format(self.host, self.port))\n                    for future in six.itervalues(self.send_future_map):\n                        future.set_exception(e)\n                    self.send_future_map = {}\n                    if self._closing:\n                        return\n                    if self.disconnect_callback:\n                        self.disconnect_callback()\n                    # if the last connect finished, then we need to make a new one\n                    if self._connecting_future.done():\n                        self._connecting_future = self.connect()\n                    yield self._connecting_future\n                except TypeError:\n                    # This is an invalid transport\n                    if 'detect_mode' in self.opts:\n                        log.info('There was an error trying to use TCP transport; '\n                                 'attempting to fallback to another transport')\n                    else:\n                        raise SaltClientError\n                except Exception as e:\n                    log.error('Exception parsing response', exc_info=True)\n                    for future in six.itervalues(self.send_future_map):\n                        future.set_exception(e)\n                    self.send_future_map = {}\n                    if self._closing:\n                        return\n                    if self.disconnect_callback:\n                        self.disconnect_callback()\n                    # if the last connect finished, then we need to make a new one\n                    if self._connecting_future.done():\n                        self._connecting_future = self.connect()\n                    yield self._connecting_future\n        finally:\n            self._stream_return_future.set_result(True)\n\n    @tornado.gen.coroutine\n    def _stream_send(self):\n        while not self._connecting_future.done() or self._connecting_future.result() is not True:\n            yield self._connecting_future\n        while len(self.send_queue) > 0:\n            message_id, item = self.send_queue[0]\n            try:\n                yield self._stream.write(item)\n                del self.send_queue[0]\n            # if the connection is dead, lets fail this send, and make sure we\n            # attempt to reconnect\n            except tornado.iostream.StreamClosedError as e:\n                if message_id in self.send_future_map:\n                    self.send_future_map.pop(message_id).set_exception(e)\n                self.remove_message_timeout(message_id)\n                del self.send_queue[0]\n                if self._closing:\n                    return\n                if self.disconnect_callback:\n                    self.disconnect_callback()\n                # if the last connect finished, then we need to make a new one\n                if self._connecting_future.done():\n                    self._connecting_future = self.connect()\n                yield self._connecting_future\n\n    def _message_id(self):\n        wrap = False\n        while self._mid in self.send_future_map:\n            if self._mid >= self._max_messages:\n                if wrap:\n                    # this shouldn't ever happen, but just in case\n                    raise Exception('Unable to find available messageid')\n                self._mid = 1\n                wrap = True\n            else:\n                self._mid += 1\n\n        return self._mid\n\n    # TODO: return a message object which takes care of multiplexing?\n    def on_recv(self, callback):\n        '''\n        Register a callback for received messages (that we didn't initiate)\n        '''\n        if callback is None:\n            self._on_recv = callback\n        else:\n            def wrap_recv(header, body):\n                callback(body)\n            self._on_recv = wrap_recv\n\n    def remove_message_timeout(self, message_id):\n        if message_id not in self.send_timeout_map:\n            return\n        timeout = self.send_timeout_map.pop(message_id)\n        self.io_loop.remove_timeout(timeout)\n\n    def timeout_message(self, message_id):\n        if message_id in self.send_timeout_map:\n            del self.send_timeout_map[message_id]\n        if message_id in self.send_future_map:\n            self.send_future_map.pop(message_id).set_exception(\n                SaltReqTimeoutError('Message timed out')\n            )\n\n    def send(self, msg, timeout=None, callback=None, raw=False):\n        '''\n        Send given message, and return a future\n        '''\n        message_id = self._message_id()\n        header = {'mid': message_id}\n\n        future = tornado.concurrent.Future()\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n        # Add this future to the mapping\n        self.send_future_map[message_id] = future\n\n        if self.opts.get('detect_mode') is True:\n            timeout = 1\n\n        if timeout is not None:\n            send_timeout = self.io_loop.call_later(timeout, self.timeout_message, message_id)\n            self.send_timeout_map[message_id] = send_timeout\n\n        # if we don't have a send queue, we need to spawn the callback to do the sending\n        if len(self.send_queue) == 0:\n            self.io_loop.spawn_callback(self._stream_send)\n        self.send_queue.append((message_id, salt.transport.frame.frame_msg(msg, header=header)))\n        return future\n\n\nclass Subscriber(object):\n    '''\n    Client object for use with the TCP publisher server\n    '''\n    def __init__(self, stream, address):\n        self.stream = stream\n        self.address = address\n        self._closing = False\n        self._read_until_future = None\n        self.id_ = None\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n        if not self.stream.closed():\n            self.stream.close()\n            if self._read_until_future is not None:\n                # This will prevent this message from showing up:\n                # '[ERROR   ] Future exception was never retrieved:\n                # StreamClosedError'\n                # This happens because the logic is always waiting to read\n                # the next message and the associated read future is marked\n                # 'StreamClosedError' when the stream is closed.\n                self._read_until_future.exc_info()\n\n    def __del__(self):\n        self.close()\n\n\nclass PubServer(tornado.tcpserver.TCPServer, object):\n    '''\n    TCP publisher\n    '''\n    def __init__(self, opts, io_loop=None):\n        super(PubServer, self).__init__(io_loop=io_loop, ssl_options=opts.get('ssl'))\n        self.opts = opts\n        self._closing = False\n        self.clients = set()\n        self.aes_funcs = salt.master.AESFuncs(self.opts)\n        self.present = {}\n        self.presence_events = False\n        if self.opts.get('presence_events', False):\n            tcp_only = True\n            for transport, _ in iter_transport_opts(self.opts):\n                if transport != 'tcp':\n                    tcp_only = False\n            if tcp_only:\n                # Only when the transport is TCP only, the presence events will\n                # be handled here. Otherwise, it will be handled in the\n                # 'Maintenance' process.\n                self.presence_events = True\n\n        if self.presence_events:\n            self.event = salt.utils.event.get_event(\n                'master',\n                opts=self.opts,\n                listen=False\n            )\n\n    def close(self):\n        if self._closing:\n            return\n        self._closing = True\n\n    def __del__(self):\n        self.close()\n\n    def _add_client_present(self, client):\n        id_ = client.id_\n        if id_ in self.present:\n            clients = self.present[id_]\n            clients.add(client)\n        else:\n            self.present[id_] = set([client])\n            if self.presence_events:\n                data = {'new': [id_],\n                        'lost': []}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('change', 'presence')\n                )\n                data = {'present': list(self.present.keys())}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('present', 'presence')\n                )\n\n    def _remove_client_present(self, client):\n        id_ = client.id_\n        if id_ is None or id_ not in self.present:\n            # This is possible if _remove_client_present() is invoked\n            # before the minion's id is validated.\n            return\n\n        clients = self.present[id_]\n        if client not in clients:\n            # Since _remove_client_present() is potentially called from\n            # _stream_read() and/or publish_payload(), it is possible for\n            # it to be called twice, in which case we will get here.\n            # This is not an abnormal case, so no logging is required.\n            return\n\n        clients.remove(client)\n        if len(clients) == 0:\n            del self.present[id_]\n            if self.presence_events:\n                data = {'new': [],\n                        'lost': [id_]}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('change', 'presence')\n                )\n                data = {'present': list(self.present.keys())}\n                self.event.fire_event(\n                    data,\n                    salt.utils.event.tagify('present', 'presence')\n                )\n\n    @tornado.gen.coroutine\n    def _stream_read(self, client):\n        unpacker = msgpack.Unpacker()\n        while not self._closing:\n            try:\n                client._read_until_future = client.stream.read_bytes(4096, partial=True)\n                wire_bytes = yield client._read_until_future\n                unpacker.feed(wire_bytes)\n                for framed_msg in unpacker:\n                    if six.PY3:\n                        framed_msg = salt.transport.frame.decode_embedded_strs(\n                            framed_msg\n                        )\n                    body = framed_msg['body']\n                    if body['enc'] != 'aes':\n                        # We only accept 'aes' encoded messages for 'id'\n                        continue\n                    crypticle = salt.crypt.Crypticle(self.opts, salt.master.SMaster.secrets['aes']['secret'].value)\n                    load = crypticle.loads(body['load'])\n                    if six.PY3:\n                        load = salt.transport.frame.decode_embedded_strs(load)\n                    if not self.aes_funcs.verify_minion(load['id'], load['tok']):\n                        continue\n                    client.id_ = load['id']\n                    self._add_client_present(client)\n            except tornado.iostream.StreamClosedError as e:\n                log.debug('tcp stream to {0} closed, unable to recv'.format(client.address))\n                client.close()\n                self._remove_client_present(client)\n                self.clients.discard(client)\n                break\n            except Exception as e:\n                log.error('Exception parsing response', exc_info=True)\n                continue\n\n    def handle_stream(self, stream, address):\n        log.trace('Subscriber at {0} connected'.format(address))\n        client = Subscriber(stream, address)\n        self.clients.add(client)\n        self.io_loop.spawn_callback(self._stream_read, client)\n\n    # TODO: ACK the publish through IPC\n    @tornado.gen.coroutine\n    def publish_payload(self, package, _):\n        log.debug('TCP PubServer sending payload: {0}'.format(package))\n        payload = salt.transport.frame.frame_msg(package['payload'])\n\n        to_remove = []\n        if 'topic_lst' in package:\n            topic_lst = package['topic_lst']\n            for topic in topic_lst:\n                if topic in self.present:\n                    # This will rarely be a list of more than 1 item. It will\n                    # be more than 1 item if the minion disconnects from the\n                    # master in an unclean manner (eg cable yank), then\n                    # restarts and the master is yet to detect the disconnect\n                    # via TCP keep-alive.\n                    for client in self.present[topic]:\n                        try:\n                            # Write the packed str\n                            f = client.stream.write(payload)\n                            self.io_loop.add_future(f, lambda f: True)\n                        except tornado.iostream.StreamClosedError:\n                            to_remove.append(client)\n                else:\n                    log.debug('Publish target {0} not connected'.format(topic))\n        else:\n            for client in self.clients:\n                try:\n                    # Write the packed str\n                    f = client.stream.write(payload)\n                    self.io_loop.add_future(f, lambda f: True)\n                except tornado.iostream.StreamClosedError:\n                    to_remove.append(client)\n        for client in to_remove:\n            log.debug('Subscriber at {0} has disconnected from publisher'.format(client.address))\n            client.close()\n            self._remove_client_present(client)\n            self.clients.discard(client)\n        log.trace('TCP PubServer finished publishing payload')\n\n\nclass TCPPubServerChannel(salt.transport.server.PubServerChannel):\n    # TODO: opts!\n    # Based on default used in tornado.netutil.bind_sockets()\n    backlog = 128\n\n    def __init__(self, opts):\n        self.opts = opts\n        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?\n        self.io_loop = None\n\n    def __setstate__(self, state):\n        salt.master.SMaster.secrets = state['secrets']\n        self.__init__(state['opts'])\n\n    def __getstate__(self):\n        return {'opts': self.opts,\n                'secrets': salt.master.SMaster.secrets}\n\n    def _publish_daemon(self, log_queue=None):\n        '''\n        Bind to the interface specified in the configuration file\n        '''\n        salt.utils.appendproctitle(self.__class__.__name__)\n\n        if log_queue is not None:\n            salt.log.setup.set_multiprocessing_logging_queue(log_queue)\n        salt.log.setup.setup_multiprocessing_logging(log_queue)\n\n        # Check if io_loop was set outside\n        if self.io_loop is None:\n            self.io_loop = tornado.ioloop.IOLoop.current()\n\n        # Spin up the publisher\n        pub_server = PubServer(self.opts, io_loop=self.io_loop)\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)\n        _set_tcp_keepalive(sock, self.opts)\n        sock.setblocking(0)\n        sock.bind((self.opts['interface'], int(self.opts['publish_port'])))\n        sock.listen(self.backlog)\n        # pub_server will take ownership of the socket\n        pub_server.add_socket(sock)\n\n        # Set up Salt IPC server\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = int(self.opts.get('tcp_master_publish_pull', 4514))\n        else:\n            pull_uri = os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n\n        pull_sock = salt.transport.ipc.IPCMessageServer(\n            pull_uri,\n            io_loop=self.io_loop,\n            payload_handler=pub_server.publish_payload,\n        )\n\n        # Securely create socket\n        log.info('Starting the Salt Puller on {0}'.format(pull_uri))\n        old_umask = os.umask(0o177)\n        try:\n            pull_sock.start()\n        finally:\n            os.umask(old_umask)\n\n        # run forever\n        try:\n            self.io_loop.start()\n        except (KeyboardInterrupt, SystemExit):\n            salt.log.setup.shutdown_multiprocessing_logging()\n\n    def pre_fork(self, process_manager):\n        '''\n        Do anything necessary pre-fork. Since this is on the master side this will\n        primarily be used to create IPC channels and create our daemon process to\n        do the actual publishing\n        '''\n        kwargs = {}\n        if salt.utils.is_windows():\n            kwargs['log_queue'] = (\n                salt.log.setup.get_multiprocessing_logging_queue()\n            )\n\n        process_manager.add_process(self._publish_daemon, kwargs=kwargs)\n\n    def publish(self, load):\n        '''\n        Publish \"load\" to minions\n        '''\n        payload = {'enc': 'aes'}\n\n        crypticle = salt.crypt.Crypticle(self.opts, salt.master.SMaster.secrets['aes']['secret'].value)\n        payload['load'] = crypticle.dumps(load)\n        if self.opts['sign_pub_messages']:\n            master_pem_path = os.path.join(self.opts['pki_dir'], 'master.pem')\n            log.debug(\"Signing data packet\")\n            payload['sig'] = salt.crypt.sign_message(master_pem_path, payload['load'])\n        # Use the Salt IPC server\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = int(self.opts.get('tcp_master_publish_pull', 4514))\n        else:\n            pull_uri = os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n        # TODO: switch to the actual async interface\n        #pub_sock = salt.transport.ipc.IPCMessageClient(self.opts, io_loop=self.io_loop)\n        pub_sock = salt.utils.async.SyncWrapper(\n            salt.transport.ipc.IPCMessageClient,\n            (pull_uri,)\n        )\n        pub_sock.connect()\n\n        int_payload = {'payload': self.serial.dumps(payload)}\n\n        # add some targeting stuff for lists only (for now)\n        if load['tgt_type'] == 'list':\n            int_payload['topic_lst'] = load['tgt']\n        # Send it over IPC!\n        pub_sock.send(int_payload)\n", "# -*- coding: utf-8 -*-\n'''\nZeromq transport classes\n'''\n\n# Import Python Libs\nfrom __future__ import absolute_import\nimport os\nimport sys\nimport copy\nimport errno\nimport signal\nimport hashlib\nimport logging\nimport weakref\nfrom random import randint\n\n# Import Salt Libs\nimport salt.auth\nimport salt.crypt\nimport salt.utils\nimport salt.utils.verify\nimport salt.utils.event\nimport salt.payload\nimport salt.transport.client\nimport salt.transport.server\nimport salt.transport.mixins.auth\nfrom salt.exceptions import SaltReqTimeoutError\n\nimport zmq\nimport zmq.error\nimport zmq.eventloop.ioloop\n# support pyzmq 13.0.x, TODO: remove once we force people to 14.0.x\nif not hasattr(zmq.eventloop.ioloop, 'ZMQIOLoop'):\n    zmq.eventloop.ioloop.ZMQIOLoop = zmq.eventloop.ioloop.IOLoop\nimport zmq.eventloop.zmqstream\ntry:\n    import zmq.utils.monitor\n    HAS_ZMQ_MONITOR = True\nexcept ImportError:\n    HAS_ZMQ_MONITOR = False\n\n# Import Tornado Libs\nimport tornado\nimport tornado.gen\nimport tornado.concurrent\n\n# Import third party libs\nimport salt.ext.six as six\ntry:\n    from Cryptodome.Cipher import PKCS1_OAEP\nexcept ImportError:\n    from Crypto.Cipher import PKCS1_OAEP\n\nlog = logging.getLogger(__name__)\n\n\nclass AsyncZeroMQReqChannel(salt.transport.client.ReqChannel):\n    '''\n    Encapsulate sending routines to ZeroMQ.\n\n    ZMQ Channels default to 'crypt=aes'\n    '''\n    # This class is only a singleton per minion/master pair\n    # mapping of io_loop -> {key -> channel}\n    instance_map = weakref.WeakKeyDictionary()\n\n    def __new__(cls, opts, **kwargs):\n        '''\n        Only create one instance of channel per __key()\n        '''\n\n        # do we have any mapping for this io_loop\n        io_loop = kwargs.get('io_loop')\n        if io_loop is None:\n            zmq.eventloop.ioloop.install()\n            io_loop = tornado.ioloop.IOLoop.current()\n        if io_loop not in cls.instance_map:\n            cls.instance_map[io_loop] = weakref.WeakValueDictionary()\n        loop_instance_map = cls.instance_map[io_loop]\n\n        key = cls.__key(opts, **kwargs)\n        obj = loop_instance_map.get(key)\n        if obj is None:\n            log.debug('Initializing new AsyncZeroMQReqChannel for {0}'.format(key))\n            # we need to make a local variable for this, as we are going to store\n            # it in a WeakValueDictionary-- which will remove the item if no one\n            # references it-- this forces a reference while we return to the caller\n            obj = object.__new__(cls)\n            obj.__singleton_init__(opts, **kwargs)\n            loop_instance_map[key] = obj\n            log.trace('Inserted key into loop_instance_map id {0} for key {1} and process {2}'.format(id(loop_instance_map), key, os.getpid()))\n        else:\n            log.debug('Re-using AsyncZeroMQReqChannel for {0}'.format(key))\n        return obj\n\n    def __deepcopy__(self, memo):\n        cls = self.__class__\n        result = cls.__new__(cls, copy.deepcopy(self.opts, memo))  # pylint: disable=too-many-function-args\n        memo[id(self)] = result\n        for key in self.__dict__:\n            if key in ('_io_loop',):\n                continue\n                # The _io_loop has a thread Lock which will fail to be deep\n                # copied. Skip it because it will just be recreated on the\n                # new copy.\n            if key == 'message_client':\n                # Recreate the message client because it will fail to be deep\n                # copied. The reason is the same as the io_loop skip above.\n                setattr(result, key,\n                        AsyncReqMessageClientPool(result.opts,\n                                                  args=(result.opts, self.master_uri,),\n                                                  kwargs={'io_loop': self._io_loop}))\n\n                continue\n            setattr(result, key, copy.deepcopy(self.__dict__[key], memo))\n        return result\n\n    @classmethod\n    def __key(cls, opts, **kwargs):\n        return (opts['pki_dir'],     # where the keys are stored\n                opts['id'],          # minion ID\n                kwargs.get('master_uri', opts.get('master_uri')),  # master ID\n                kwargs.get('crypt', 'aes'),  # TODO: use the same channel for crypt\n                )\n\n    # has to remain empty for singletons, since __init__ will *always* be called\n    def __init__(self, opts, **kwargs):\n        pass\n\n    # an init for the singleton instance to call\n    def __singleton_init__(self, opts, **kwargs):\n        self.opts = dict(opts)\n        self.ttype = 'zeromq'\n\n        # crypt defaults to 'aes'\n        self.crypt = kwargs.get('crypt', 'aes')\n\n        if 'master_uri' in kwargs:\n            self.opts['master_uri'] = kwargs['master_uri']\n\n        self._io_loop = kwargs.get('io_loop')\n        if self._io_loop is None:\n            zmq.eventloop.ioloop.install()\n            self._io_loop = tornado.ioloop.IOLoop.current()\n\n        if self.crypt != 'clear':\n            # we don't need to worry about auth as a kwarg, since its a singleton\n            self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self._io_loop)\n        self.message_client = AsyncReqMessageClientPool(self.opts,\n                                                        args=(self.opts, self.master_uri,),\n                                                        kwargs={'io_loop': self._io_loop})\n\n    def __del__(self):\n        '''\n        Since the message_client creates sockets and assigns them to the IOLoop we have to\n        specifically destroy them, since we aren't the only ones with references to the FDs\n        '''\n        if hasattr(self, 'message_client'):\n            self.message_client.destroy()\n        else:\n            log.debug('No message_client attr for AsyncZeroMQReqChannel found. Not destroying sockets.')\n\n    @property\n    def master_uri(self):\n        return self.opts['master_uri']\n\n    def _package_load(self, load):\n        return {\n            'enc': self.crypt,\n            'load': load,\n        }\n\n    @tornado.gen.coroutine\n    def crypted_transfer_decode_dictentry(self, load, dictkey=None, tries=3, timeout=60):\n        if not self.auth.authenticated:\n            # Return controle back to the caller, continue when authentication succeeds\n            yield self.auth.authenticate()\n        # Return control to the caller. When send() completes, resume by populating ret with the Future.result\n        ret = yield self.message_client.send(\n            self._package_load(self.auth.crypticle.dumps(load)),\n            timeout=timeout,\n            tries=tries,\n        )\n        key = self.auth.get_keys()\n        cipher = PKCS1_OAEP.new(key)\n        if 'key' not in ret:\n            # Reauth in the case our key is deleted on the master side.\n            yield self.auth.authenticate()\n            ret = yield self.message_client.send(\n                self._package_load(self.auth.crypticle.dumps(load)),\n                timeout=timeout,\n                tries=tries,\n            )\n        aes = cipher.decrypt(ret['key'])\n        pcrypt = salt.crypt.Crypticle(self.opts, aes)\n        data = pcrypt.loads(ret[dictkey])\n        if six.PY3:\n            data = salt.transport.frame.decode_embedded_strs(data)\n        raise tornado.gen.Return(data)\n\n    @tornado.gen.coroutine\n    def _crypted_transfer(self, load, tries=3, timeout=60, raw=False):\n        '''\n        Send a load across the wire, with encryption\n\n        In case of authentication errors, try to renegotiate authentication\n        and retry the method.\n\n        Indeed, we can fail too early in case of a master restart during a\n        minion state execution call\n\n        :param dict load: A load to send across the wire\n        :param int tries: The number of times to make before failure\n        :param int timeout: The number of seconds on a response before failing\n        '''\n        @tornado.gen.coroutine\n        def _do_transfer():\n            # Yield control to the caller. When send() completes, resume by populating data with the Future.result\n            data = yield self.message_client.send(\n                self._package_load(self.auth.crypticle.dumps(load)),\n                timeout=timeout,\n                tries=tries,\n            )\n            # we may not have always data\n            # as for example for saltcall ret submission, this is a blind\n            # communication, we do not subscribe to return events, we just\n            # upload the results to the master\n            if data:\n                data = self.auth.crypticle.loads(data, raw)\n            if six.PY3 and not raw:\n                data = salt.transport.frame.decode_embedded_strs(data)\n            raise tornado.gen.Return(data)\n        if not self.auth.authenticated:\n            # Return control back to the caller, resume when authentication succeeds\n            yield self.auth.authenticate()\n        try:\n            # We did not get data back the first time. Retry.\n            ret = yield _do_transfer()\n        except salt.crypt.AuthenticationError:\n            # If auth error, return control back to the caller, continue when authentication succeeds\n            yield self.auth.authenticate()\n            ret = yield _do_transfer()\n        raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def _uncrypted_transfer(self, load, tries=3, timeout=60):\n        '''\n        Send a load across the wire in cleartext\n\n        :param dict load: A load to send across the wire\n        :param int tries: The number of times to make before failure\n        :param int timeout: The number of seconds on a response before failing\n        '''\n        ret = yield self.message_client.send(\n            self._package_load(load),\n            timeout=timeout,\n            tries=tries,\n        )\n\n        raise tornado.gen.Return(ret)\n\n    @tornado.gen.coroutine\n    def send(self, load, tries=3, timeout=60, raw=False):\n        '''\n        Send a request, return a future which will complete when we send the message\n        '''\n        if self.crypt == 'clear':\n            ret = yield self._uncrypted_transfer(load, tries=tries, timeout=timeout)\n        else:\n            ret = yield self._crypted_transfer(load, tries=tries, timeout=timeout, raw=raw)\n        raise tornado.gen.Return(ret)\n\n\nclass AsyncZeroMQPubChannel(salt.transport.mixins.auth.AESPubClientMixin, salt.transport.client.AsyncPubChannel):\n    '''\n    A transport channel backed by ZeroMQ for a Salt Publisher to use to\n    publish commands to connected minions\n    '''\n    def __init__(self,\n                 opts,\n                 **kwargs):\n        self.opts = opts\n        self.ttype = 'zeromq'\n\n        self.io_loop = kwargs.get('io_loop')\n        if self.io_loop is None:\n            zmq.eventloop.ioloop.install()\n            self.io_loop = tornado.ioloop.IOLoop.current()\n\n        self.hexid = hashlib.sha1(six.b(self.opts['id'])).hexdigest()\n\n        self.auth = salt.crypt.AsyncAuth(self.opts, io_loop=self.io_loop)\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        self.context = zmq.Context()\n        self._socket = self.context.socket(zmq.SUB)\n\n        if self.opts['zmq_filtering']:\n            # TODO: constants file for \"broadcast\"\n            self._socket.setsockopt(zmq.SUBSCRIBE, b'broadcast')\n            self._socket.setsockopt(zmq.SUBSCRIBE, self.hexid)\n        else:\n            self._socket.setsockopt(zmq.SUBSCRIBE, b'')\n\n        self._socket.setsockopt(zmq.IDENTITY, salt.utils.to_bytes(self.opts['id']))\n\n        # TODO: cleanup all the socket opts stuff\n        if hasattr(zmq, 'TCP_KEEPALIVE'):\n            self._socket.setsockopt(\n                zmq.TCP_KEEPALIVE, self.opts['tcp_keepalive']\n            )\n            self._socket.setsockopt(\n                zmq.TCP_KEEPALIVE_IDLE, self.opts['tcp_keepalive_idle']\n            )\n            self._socket.setsockopt(\n                zmq.TCP_KEEPALIVE_CNT, self.opts['tcp_keepalive_cnt']\n            )\n            self._socket.setsockopt(\n                zmq.TCP_KEEPALIVE_INTVL, self.opts['tcp_keepalive_intvl']\n            )\n\n        recon_delay = self.opts['recon_default']\n\n        if self.opts['recon_randomize']:\n            recon_delay = randint(self.opts['recon_default'],\n                                  self.opts['recon_default'] + self.opts['recon_max']\n                          )\n\n            log.debug(\"Generated random reconnect delay between '{0}ms' and '{1}ms' ({2})\".format(\n                self.opts['recon_default'],\n                self.opts['recon_default'] + self.opts['recon_max'],\n                recon_delay)\n            )\n\n        log.debug(\"Setting zmq_reconnect_ivl to '{0}ms'\".format(recon_delay))\n        self._socket.setsockopt(zmq.RECONNECT_IVL, recon_delay)\n\n        if hasattr(zmq, 'RECONNECT_IVL_MAX'):\n            log.debug(\"Setting zmq_reconnect_ivl_max to '{0}ms'\".format(\n                self.opts['recon_default'] + self.opts['recon_max'])\n            )\n\n            self._socket.setsockopt(\n                zmq.RECONNECT_IVL_MAX, self.opts['recon_max']\n            )\n\n        if (self.opts['ipv6'] is True or ':' in self.opts['master_ip']) and hasattr(zmq, 'IPV4ONLY'):\n            # IPv6 sockets work for both IPv6 and IPv4 addresses\n            self._socket.setsockopt(zmq.IPV4ONLY, 0)\n\n        if HAS_ZMQ_MONITOR and self.opts['zmq_monitor']:\n            self._monitor = ZeroMQSocketMonitor(self._socket)\n            self._monitor.start_io_loop(self.io_loop)\n\n    def destroy(self):\n        if hasattr(self, '_monitor') and self._monitor is not None:\n            self._monitor.stop()\n            self._monitor = None\n        if hasattr(self, '_stream'):\n            # TODO: Optionally call stream.close() on newer pyzmq? Its broken on some\n            self._stream.io_loop.remove_handler(self._stream.socket)\n            self._stream.socket.close(0)\n        elif hasattr(self, '_socket'):\n            self._socket.close(0)\n        if hasattr(self, 'context') and self.context.closed is False:\n            self.context.term()\n\n    def __del__(self):\n        self.destroy()\n\n    # TODO: this is the time to see if we are connected, maybe use the req channel to guess?\n    @tornado.gen.coroutine\n    def connect(self):\n        if not self.auth.authenticated:\n            yield self.auth.authenticate()\n        self.publish_port = self.auth.creds['publish_port']\n        self._socket.connect(self.master_pub)\n\n    @property\n    def master_pub(self):\n        '''\n        Return the master publish port\n        '''\n        return 'tcp://{ip}:{port}'.format(ip=self.opts['master_ip'],\n                                          port=self.publish_port)\n\n    @tornado.gen.coroutine\n    def _decode_messages(self, messages):\n        '''\n        Take the zmq messages, decrypt/decode them into a payload\n\n        :param list messages: A list of messages to be decoded\n        '''\n        messages_len = len(messages)\n        # if it was one message, then its old style\n        if messages_len == 1:\n            payload = self.serial.loads(messages[0])\n        # 2 includes a header which says who should do it\n        elif messages_len == 2:\n            if messages[0] not in ('broadcast', self.hexid):\n                log.debug('Publish received for not this minion: {0}'.format(messages[0]))\n                raise tornado.gen.Return(None)\n            payload = self.serial.loads(messages[1])\n        else:\n            raise Exception(('Invalid number of messages ({0}) in zeromq pub'\n                             'message from master').format(len(messages_len)))\n        # Yield control back to the caller. When the payload has been decoded, assign\n        # the decoded payload to 'ret' and resume operation\n        ret = yield self._decode_payload(payload)\n        raise tornado.gen.Return(ret)\n\n    @property\n    def stream(self):\n        '''\n        Return the current zmqstream, creating one if necessary\n        '''\n        if not hasattr(self, '_stream'):\n            self._stream = zmq.eventloop.zmqstream.ZMQStream(self._socket, io_loop=self.io_loop)\n        return self._stream\n\n    def on_recv(self, callback):\n        '''\n        Register a callback for received messages (that we didn't initiate)\n\n        :param func callback: A function which should be called when data is received\n        '''\n        if callback is None:\n            return self.stream.on_recv(None)\n\n        @tornado.gen.coroutine\n        def wrap_callback(messages):\n            payload = yield self._decode_messages(messages)\n            if payload is not None:\n                callback(payload)\n        return self.stream.on_recv(wrap_callback)\n\n\nclass ZeroMQReqServerChannel(salt.transport.mixins.auth.AESReqServerMixin, salt.transport.server.ReqServerChannel):\n\n    def __init__(self, opts):\n        salt.transport.server.ReqServerChannel.__init__(self, opts)\n        self._closing = False\n\n    def zmq_device(self):\n        '''\n        Multiprocessing target for the zmq queue device\n        '''\n        self.__setup_signals()\n        salt.utils.appendproctitle('MWorkerQueue')\n        self.context = zmq.Context(self.opts['worker_threads'])\n        # Prepare the zeromq sockets\n        self.uri = 'tcp://{interface}:{ret_port}'.format(**self.opts)\n        self.clients = self.context.socket(zmq.ROUTER)\n        if self.opts['ipv6'] is True and hasattr(zmq, 'IPV4ONLY'):\n            # IPv6 sockets work for both IPv6 and IPv4 addresses\n            self.clients.setsockopt(zmq.IPV4ONLY, 0)\n        self.clients.setsockopt(zmq.BACKLOG, self.opts.get('zmq_backlog', 1000))\n        if HAS_ZMQ_MONITOR and self.opts['zmq_monitor']:\n            # Socket monitor shall be used the only for debug  purposes so using threading doesn't look too bad here\n            import threading\n            self._monitor = ZeroMQSocketMonitor(self.clients)\n            t = threading.Thread(target=self._monitor.start_poll)\n            t.start()\n\n        self.workers = self.context.socket(zmq.DEALER)\n\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            self.w_uri = 'tcp://127.0.0.1:{0}'.format(\n                self.opts.get('tcp_master_workers', 4515)\n                )\n        else:\n            self.w_uri = 'ipc://{0}'.format(\n                os.path.join(self.opts['sock_dir'], 'workers.ipc')\n                )\n\n        log.info('Setting up the master communication server')\n        self.clients.bind(self.uri)\n\n        self.workers.bind(self.w_uri)\n\n        while True:\n            if self.clients.closed or self.workers.closed:\n                break\n            try:\n                zmq.device(zmq.QUEUE, self.clients, self.workers)\n            except zmq.ZMQError as exc:\n                if exc.errno == errno.EINTR:\n                    continue\n                raise exc\n            except (KeyboardInterrupt, SystemExit):\n                break\n\n    def close(self):\n        '''\n        Cleanly shutdown the router socket\n        '''\n        if self._closing:\n            return\n        log.info('MWorkerQueue under PID %s is closing', os.getpid())\n        self._closing = True\n        if hasattr(self, '_monitor') and self._monitor is not None:\n            self._monitor.stop()\n            self._monitor = None\n        if hasattr(self, '_w_monitor') and self._w_monitor is not None:\n            self._w_monitor.stop()\n            self._w_monitor = None\n        if hasattr(self, 'clients') and self.clients.closed is False:\n            self.clients.close()\n        if hasattr(self, 'workers') and self.workers.closed is False:\n            self.workers.close()\n        if hasattr(self, 'stream'):\n            self.stream.close()\n        if hasattr(self, '_socket') and self._socket.closed is False:\n            self._socket.close()\n        if hasattr(self, 'context') and self.context.closed is False:\n            self.context.term()\n\n    def pre_fork(self, process_manager):\n        '''\n        Pre-fork we need to create the zmq router device\n\n        :param func process_manager: An instance of salt.utils.process.ProcessManager\n        '''\n        salt.transport.mixins.auth.AESReqServerMixin.pre_fork(self, process_manager)\n        process_manager.add_process(self.zmq_device)\n\n    def post_fork(self, payload_handler, io_loop):\n        '''\n        After forking we need to create all of the local sockets to listen to the\n        router\n\n        :param func payload_handler: A function to called to handle incoming payloads as\n                                     they are picked up off the wire\n        :param IOLoop io_loop: An instance of a Tornado IOLoop, to handle event scheduling\n        '''\n        self.payload_handler = payload_handler\n        self.io_loop = io_loop\n\n        self.context = zmq.Context(1)\n        self._socket = self.context.socket(zmq.REP)\n        if HAS_ZMQ_MONITOR and self.opts['zmq_monitor']:\n            # Socket monitor shall be used the only for debug  purposes so using threading doesn't look too bad here\n            import threading\n            self._w_monitor = ZeroMQSocketMonitor(self._socket)\n            t = threading.Thread(target=self._w_monitor.start_poll)\n            t.start()\n\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            self.w_uri = 'tcp://127.0.0.1:{0}'.format(\n                self.opts.get('tcp_master_workers', 4515)\n                )\n        else:\n            self.w_uri = 'ipc://{0}'.format(\n                os.path.join(self.opts['sock_dir'], 'workers.ipc')\n                )\n        log.info('Worker binding to socket {0}'.format(self.w_uri))\n        self._socket.connect(self.w_uri)\n\n        salt.transport.mixins.auth.AESReqServerMixin.post_fork(self, payload_handler, io_loop)\n\n        self.stream = zmq.eventloop.zmqstream.ZMQStream(self._socket, io_loop=self.io_loop)\n        self.stream.on_recv_stream(self.handle_message)\n\n    @tornado.gen.coroutine\n    def handle_message(self, stream, payload):\n        '''\n        Handle incoming messages from underylying TCP streams\n\n        :stream ZMQStream stream: A ZeroMQ stream.\n        See http://zeromq.github.io/pyzmq/api/generated/zmq.eventloop.zmqstream.html\n\n        :param dict payload: A payload to process\n        '''\n        try:\n            payload = self.serial.loads(payload[0])\n            payload = self._decode_payload(payload)\n        except Exception as exc:\n            exc_type = type(exc).__name__\n            if exc_type == 'AuthenticationError':\n                log.debug(\n                    'Minion failed to auth to master. Since the payload is '\n                    'encrypted, it is not known which minion failed to '\n                    'authenticate. It is likely that this is a transient '\n                    'failure due to the master rotating its public key.'\n                )\n            else:\n                log.error('Bad load from minion: %s: %s', exc_type, exc)\n            stream.send(self.serial.dumps('bad load'))\n            raise tornado.gen.Return()\n\n        # TODO helper functions to normalize payload?\n        if not isinstance(payload, dict) or not isinstance(payload.get('load'), dict):\n            log.error('payload and load must be a dict. Payload was: {0} and load was {1}'.format(payload, payload.get('load')))\n            stream.send(self.serial.dumps('payload and load must be a dict'))\n            raise tornado.gen.Return()\n\n        try:\n            id_ = payload['load'].get('id', '')\n            if '\\0' in id_:\n                log.error('Payload contains an id with a null byte: %s', payload)\n                stream.send(self.serial.dumps('bad load: id contains a null byte'))\n                raise tornado.gen.Return()\n        except TypeError:\n            log.error('Payload contains non-string id: %s', payload)\n            stream.send(self.serial.dumps('bad load: id {0} is not a string'.format(id_)))\n            raise tornado.gen.Return()\n\n        # intercept the \"_auth\" commands, since the main daemon shouldn't know\n        # anything about our key auth\n        if payload['enc'] == 'clear' and payload.get('load', {}).get('cmd') == '_auth':\n            stream.send(self.serial.dumps(self._auth(payload['load'])))\n            raise tornado.gen.Return()\n\n        # TODO: test\n        try:\n            # Take the payload_handler function that was registered when we created the channel\n            # and call it, returning control to the caller until it completes\n            ret, req_opts = yield self.payload_handler(payload)\n        except Exception as e:\n            # always attempt to return an error to the minion\n            stream.send('Some exception handling minion payload')\n            log.error('Some exception handling a payload from minion', exc_info=True)\n            raise tornado.gen.Return()\n\n        req_fun = req_opts.get('fun', 'send')\n        if req_fun == 'send_clear':\n            stream.send(self.serial.dumps(ret))\n        elif req_fun == 'send':\n            stream.send(self.serial.dumps(self.crypticle.dumps(ret)))\n        elif req_fun == 'send_private':\n            stream.send(self.serial.dumps(self._encrypt_private(ret,\n                                                                req_opts['key'],\n                                                                req_opts['tgt'],\n                                                                )))\n        else:\n            log.error('Unknown req_fun {0}'.format(req_fun))\n            # always attempt to return an error to the minion\n            stream.send('Server-side exception handling payload')\n        raise tornado.gen.Return()\n\n    def __setup_signals(self):\n        signal.signal(signal.SIGINT, self._handle_signals)\n        signal.signal(signal.SIGTERM, self._handle_signals)\n\n    def _handle_signals(self, signum, sigframe):\n        msg = '{0} received a '.format(self.__class__.__name__)\n        if signum == signal.SIGINT:\n            msg += 'SIGINT'\n        elif signum == signal.SIGTERM:\n            msg += 'SIGTERM'\n        msg += '. Exiting'\n        log.debug(msg)\n        self.close()\n        sys.exit(salt.defaults.exitcodes.EX_OK)\n\n\ndef _set_tcp_keepalive(zmq_socket, opts):\n    '''\n    Ensure that TCP keepalives are set as specified in \"opts\".\n\n    Warning: Failure to set TCP keepalives on the salt-master can result in\n    not detecting the loss of a minion when the connection is lost or when\n    it's host has been terminated without first closing the socket.\n    Salt's Presence System depends on this connection status to know if a minion\n    is \"present\".\n\n    Warning: Failure to set TCP keepalives on minions can result in frequent or\n    unexpected disconnects!\n    '''\n    if hasattr(zmq, 'TCP_KEEPALIVE') and opts:\n        if 'tcp_keepalive' in opts:\n            zmq_socket.setsockopt(\n                zmq.TCP_KEEPALIVE, opts['tcp_keepalive']\n            )\n        if 'tcp_keepalive_idle' in opts:\n            zmq_socket.setsockopt(\n                zmq.TCP_KEEPALIVE_IDLE, opts['tcp_keepalive_idle']\n            )\n        if 'tcp_keepalive_cnt' in opts:\n            zmq_socket.setsockopt(\n                zmq.TCP_KEEPALIVE_CNT, opts['tcp_keepalive_cnt']\n            )\n        if 'tcp_keepalive_intvl' in opts:\n            zmq_socket.setsockopt(\n                zmq.TCP_KEEPALIVE_INTVL, opts['tcp_keepalive_intvl']\n            )\n\n\nclass ZeroMQPubServerChannel(salt.transport.server.PubServerChannel):\n    '''\n    Encapsulate synchronous operations for a publisher channel\n    '''\n    def __init__(self, opts):\n        self.opts = opts\n        self.serial = salt.payload.Serial(self.opts)  # TODO: in init?\n        self.ckminions = salt.utils.minions.CkMinions(self.opts)\n\n    def connect(self):\n        return tornado.gen.sleep(5)\n\n    def _publish_daemon(self):\n        '''\n        Bind to the interface specified in the configuration file\n        '''\n        salt.utils.appendproctitle(self.__class__.__name__)\n        # Set up the context\n        context = zmq.Context(1)\n        # Prepare minion publish socket\n        pub_sock = context.socket(zmq.PUB)\n        _set_tcp_keepalive(pub_sock, self.opts)\n        # if 2.1 >= zmq < 3.0, we only have one HWM setting\n        try:\n            pub_sock.setsockopt(zmq.HWM, self.opts.get('pub_hwm', 1000))\n        # in zmq >= 3.0, there are separate send and receive HWM settings\n        except AttributeError:\n            # Set the High Water Marks. For more information on HWM, see:\n            # http://api.zeromq.org/4-1:zmq-setsockopt\n            pub_sock.setsockopt(zmq.SNDHWM, self.opts.get('pub_hwm', 1000))\n            pub_sock.setsockopt(zmq.RCVHWM, self.opts.get('pub_hwm', 1000))\n        if self.opts['ipv6'] is True and hasattr(zmq, 'IPV4ONLY'):\n            # IPv6 sockets work for both IPv6 and IPv4 addresses\n            pub_sock.setsockopt(zmq.IPV4ONLY, 0)\n        pub_sock.setsockopt(zmq.BACKLOG, self.opts.get('zmq_backlog', 1000))\n        pub_uri = 'tcp://{interface}:{publish_port}'.format(**self.opts)\n        # Prepare minion pull socket\n        pull_sock = context.socket(zmq.PULL)\n\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = 'tcp://127.0.0.1:{0}'.format(\n                self.opts.get('tcp_master_publish_pull', 4514)\n                )\n        else:\n            pull_uri = 'ipc://{0}'.format(\n                os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n                )\n        salt.utils.zeromq.check_ipc_path_max_len(pull_uri)\n\n        # Start the minion command publisher\n        log.info('Starting the Salt Publisher on {0}'.format(pub_uri))\n        pub_sock.bind(pub_uri)\n\n        # Securely create socket\n        log.info('Starting the Salt Puller on {0}'.format(pull_uri))\n        old_umask = os.umask(0o177)\n        try:\n            pull_sock.bind(pull_uri)\n        finally:\n            os.umask(old_umask)\n\n        try:\n            while True:\n                # Catch and handle EINTR from when this process is sent\n                # SIGUSR1 gracefully so we don't choke and die horribly\n                try:\n                    package = pull_sock.recv()\n                    unpacked_package = salt.payload.unpackage(package)\n                    if six.PY3:\n                        unpacked_package = salt.transport.frame.decode_embedded_strs(unpacked_package)\n                    payload = unpacked_package['payload']\n                    if self.opts['zmq_filtering']:\n                        # if you have a specific topic list, use that\n                        if 'topic_lst' in unpacked_package:\n                            for topic in unpacked_package['topic_lst']:\n                                # zmq filters are substring match, hash the topic\n                                # to avoid collisions\n                                htopic = hashlib.sha1(topic).hexdigest()\n                                pub_sock.send(htopic, flags=zmq.SNDMORE)\n                                pub_sock.send(payload)\n                                # otherwise its a broadcast\n                        else:\n                            # TODO: constants file for \"broadcast\"\n                            pub_sock.send('broadcast', flags=zmq.SNDMORE)\n                            pub_sock.send(payload)\n                    else:\n                        pub_sock.send(payload)\n                except zmq.ZMQError as exc:\n                    if exc.errno == errno.EINTR:\n                        continue\n                    raise exc\n\n        except KeyboardInterrupt:\n            # Cleanly close the sockets if we're shutting down\n            if pub_sock.closed is False:\n                pub_sock.setsockopt(zmq.LINGER, 1)\n                pub_sock.close()\n            if pull_sock.closed is False:\n                pull_sock.setsockopt(zmq.LINGER, 1)\n                pull_sock.close()\n            if context.closed is False:\n                context.term()\n\n    def pre_fork(self, process_manager):\n        '''\n        Do anything necessary pre-fork. Since this is on the master side this will\n        primarily be used to create IPC channels and create our daemon process to\n        do the actual publishing\n\n        :param func process_manager: A ProcessManager, from salt.utils.process.ProcessManager\n        '''\n        process_manager.add_process(self._publish_daemon)\n\n    def publish(self, load):\n        '''\n        Publish \"load\" to minions\n\n        :param dict load: A load to be sent across the wire to minions\n        '''\n        payload = {'enc': 'aes'}\n\n        crypticle = salt.crypt.Crypticle(self.opts, salt.master.SMaster.secrets['aes']['secret'].value)\n        payload['load'] = crypticle.dumps(load)\n        if self.opts['sign_pub_messages']:\n            master_pem_path = os.path.join(self.opts['pki_dir'], 'master.pem')\n            log.debug(\"Signing data packet\")\n            payload['sig'] = salt.crypt.sign_message(master_pem_path, payload['load'])\n        # Send 0MQ to the publisher\n        context = zmq.Context(1)\n        pub_sock = context.socket(zmq.PUSH)\n        if self.opts.get('ipc_mode', '') == 'tcp':\n            pull_uri = 'tcp://127.0.0.1:{0}'.format(\n                self.opts.get('tcp_master_publish_pull', 4514)\n                )\n        else:\n            pull_uri = 'ipc://{0}'.format(\n                os.path.join(self.opts['sock_dir'], 'publish_pull.ipc')\n                )\n        pub_sock.connect(pull_uri)\n        int_payload = {'payload': self.serial.dumps(payload)}\n\n        # add some targeting stuff for lists only (for now)\n        if load['tgt_type'] == 'list':\n            int_payload['topic_lst'] = load['tgt']\n\n        # If zmq_filtering is enabled, target matching has to happen master side\n        match_targets = [\"pcre\", \"glob\", \"list\"]\n        if self.opts['zmq_filtering'] and load['tgt_type'] in match_targets:\n            # Fetch a list of minions that match\n            match_ids = self.ckminions.check_minions(load['tgt'],\n                                                     tgt_type=load['tgt_type'])\n\n            log.debug(\"Publish Side Match: {0}\".format(match_ids))\n            # Send list of miions thru so zmq can target them\n            int_payload['topic_lst'] = match_ids\n\n        pub_sock.send(self.serial.dumps(int_payload))\n        pub_sock.close()\n        context.term()\n\n\nclass AsyncReqMessageClientPool(salt.transport.MessageClientPool):\n    '''\n    Wrapper class of AsyncReqMessageClientPool to avoid blocking waiting while writing data to socket.\n    '''\n    def __init__(self, opts, args=None, kwargs=None):\n        super(AsyncReqMessageClientPool, self).__init__(AsyncReqMessageClient, opts, args=args, kwargs=kwargs)\n\n    def __del__(self):\n        self.destroy()\n\n    def destroy(self):\n        for message_client in self.message_clients:\n            message_client.destroy()\n        self.message_clients = []\n\n    def send(self, *args, **kwargs):\n        message_clients = sorted(self.message_clients, key=lambda x: len(x.send_queue))\n        return message_clients[0].send(*args, **kwargs)\n\n\n# TODO: unit tests!\nclass AsyncReqMessageClient(object):\n    '''\n    This class wraps the underylying zeromq REQ socket and gives a future-based\n    interface to sending and recieving messages. This works around the primary\n    limitation of serialized send/recv on the underlying socket by queueing the\n    message sends in this class. In the future if we decide to attempt to multiplex\n    we can manage a pool of REQ/REP sockets-- but for now we'll just do them in serial\n    '''\n    def __init__(self, opts, addr, linger=0, io_loop=None):\n        '''\n        Create an asynchronous message client\n\n        :param dict opts: The salt opts dictionary\n        :param str addr: The interface IP address to bind to\n        :param int linger: The number of seconds to linger on a ZMQ socket. See\n                           http://api.zeromq.org/2-1:zmq-setsockopt [ZMQ_LINGER]\n        :param IOLoop io_loop: A Tornado IOLoop event scheduler [tornado.ioloop.IOLoop]\n        '''\n        self.opts = opts\n        self.addr = addr\n        self.linger = linger\n        if io_loop is None:\n            zmq.eventloop.ioloop.install()\n            tornado.ioloop.IOLoop.current()\n        else:\n            self.io_loop = io_loop\n\n        self.serial = salt.payload.Serial(self.opts)\n\n        self.context = zmq.Context()\n\n        # wire up sockets\n        self._init_socket()\n\n        self.send_queue = []\n        # mapping of message -> future\n        self.send_future_map = {}\n\n        self.send_timeout_map = {}  # message -> timeout\n\n    # TODO: timeout all in-flight sessions, or error\n    def destroy(self):\n        if hasattr(self, 'stream') and self.stream is not None:\n            # TODO: Optionally call stream.close() on newer pyzmq? It is broken on some.\n            if self.stream.socket:\n                self.stream.socket.close()\n            self.stream.io_loop.remove_handler(self.stream.socket)\n            # set this to None, more hacks for messed up pyzmq\n            self.stream.socket = None\n            self.stream = None\n            self.socket.close()\n        if self.context.closed is False:\n            self.context.term()\n\n    def __del__(self):\n        self.destroy()\n\n    def _init_socket(self):\n        if hasattr(self, 'stream'):\n            self.stream.close()  # pylint: disable=E0203\n            self.socket.close()  # pylint: disable=E0203\n            del self.stream\n            del self.socket\n\n        self.socket = self.context.socket(zmq.REQ)\n\n        # socket options\n        if hasattr(zmq, 'RECONNECT_IVL_MAX'):\n            self.socket.setsockopt(\n                zmq.RECONNECT_IVL_MAX, 5000\n            )\n\n        _set_tcp_keepalive(self.socket, self.opts)\n        if self.addr.startswith('tcp://['):\n            # Hint PF type if bracket enclosed IPv6 address\n            if hasattr(zmq, 'IPV6'):\n                self.socket.setsockopt(zmq.IPV6, 1)\n            elif hasattr(zmq, 'IPV4ONLY'):\n                self.socket.setsockopt(zmq.IPV4ONLY, 0)\n        self.socket.linger = self.linger\n        self.socket.connect(self.addr)\n        self.stream = zmq.eventloop.zmqstream.ZMQStream(self.socket, io_loop=self.io_loop)\n\n    @tornado.gen.coroutine\n    def _internal_send_recv(self):\n        while len(self.send_queue) > 0:\n            message = self.send_queue[0]\n            future = self.send_future_map.get(message, None)\n            if future is None:\n                # Timedout\n                del self.send_queue[0]\n                continue\n\n            # send\n            def mark_future(msg):\n                if not future.done():\n                    data = self.serial.loads(msg[0])\n                    future.set_result(data)\n            self.stream.on_recv(mark_future)\n            self.stream.send(message)\n\n            try:\n                ret = yield future\n            except:  # pylint: disable=W0702\n                self._init_socket()  # re-init the zmq socket (no other way in zmq)\n                del self.send_queue[0]\n                continue\n            del self.send_queue[0]\n            self.send_future_map.pop(message, None)\n            self.remove_message_timeout(message)\n\n    def remove_message_timeout(self, message):\n        if message not in self.send_timeout_map:\n            return\n        timeout = self.send_timeout_map.pop(message, None)\n        if timeout is not None:\n            # Hasn't been already timedout\n            self.io_loop.remove_timeout(timeout)\n\n    def timeout_message(self, message):\n        '''\n        Handle a message timeout by removing it from the sending queue\n        and informing the caller\n\n        :raises: SaltReqTimeoutError\n        '''\n        future = self.send_future_map.pop(message, None)\n        # In a race condition the message might have been sent by the time\n        # we're timing it out. Make sure the future is not None\n        if future is not None:\n            del self.send_timeout_map[message]\n            if future.attempts < future.tries:\n                future.attempts += 1\n                log.debug('SaltReqTimeoutError, retrying. ({0}/{1})'.format(future.attempts, future.tries))\n                self.send(\n                    message,\n                    timeout=future.timeout,\n                    tries=future.tries,\n                    future=future,\n                )\n\n            else:\n                future.set_exception(SaltReqTimeoutError('Message timed out'))\n\n    def send(self, message, timeout=None, tries=3, future=None, callback=None, raw=False):\n        '''\n        Return a future which will be completed when the message has a response\n        '''\n        if future is None:\n            future = tornado.concurrent.Future()\n            future.tries = tries\n            future.attempts = 0\n            future.timeout = timeout\n            # if a future wasn't passed in, we need to serialize the message\n            message = self.serial.dumps(message)\n        if callback is not None:\n            def handle_future(future):\n                response = future.result()\n                self.io_loop.add_callback(callback, response)\n            future.add_done_callback(handle_future)\n        # Add this future to the mapping\n        self.send_future_map[message] = future\n\n        if self.opts.get('detect_mode') is True:\n            timeout = 1\n\n        if timeout is not None:\n            send_timeout = self.io_loop.call_later(timeout, self.timeout_message, message)\n            self.send_timeout_map[message] = send_timeout\n\n        if len(self.send_queue) == 0:\n            self.io_loop.spawn_callback(self._internal_send_recv)\n\n        self.send_queue.append(message)\n\n        return future\n\n\nclass ZeroMQSocketMonitor(object):\n    __EVENT_MAP = None\n\n    def __init__(self, socket):\n        '''\n        Create ZMQ monitor sockets\n\n        More information:\n            http://api.zeromq.org/4-0:zmq-socket-monitor\n        '''\n        self._socket = socket\n        self._monitor_socket = self._socket.get_monitor_socket()\n        self._monitor_stream = None\n\n    def start_io_loop(self, io_loop):\n        log.trace(\"Event monitor start!\")\n        self._monitor_stream = zmq.eventloop.zmqstream.ZMQStream(self._monitor_socket, io_loop=io_loop)\n        self._monitor_stream.on_recv(self.monitor_callback)\n\n    def start_poll(self):\n        log.trace(\"Event monitor start!\")\n        try:\n            while self._monitor_socket is not None and self._monitor_socket.poll():\n                msg = self._monitor_socket.recv_multipart()\n                self.monitor_callback(msg)\n        except (AttributeError, zmq.error.ContextTerminated):\n            # We cannot log here because we'll get an interrupted system call in trying\n            # to flush the logging buffer as we terminate\n            pass\n\n    @property\n    def event_map(self):\n        if ZeroMQSocketMonitor.__EVENT_MAP is None:\n            event_map = {}\n            for name in dir(zmq):\n                if name.startswith('EVENT_'):\n                    value = getattr(zmq, name)\n                    event_map[value] = name\n            ZeroMQSocketMonitor.__EVENT_MAP = event_map\n        return ZeroMQSocketMonitor.__EVENT_MAP\n\n    def monitor_callback(self, msg):\n        evt = zmq.utils.monitor.parse_monitor_message(msg)\n        evt['description'] = self.event_map[evt['event']]\n        log.debug(\"ZeroMQ event: {0}\".format(evt))\n        if evt['event'] == zmq.EVENT_MONITOR_STOPPED:\n            self.stop()\n\n    def stop(self):\n        if self._socket is None:\n            return\n        self._socket.disable_monitor()\n        self._socket = None\n        self._monitor_socket = None\n        if self._monitor_stream is not None:\n            self._monitor_stream.close()\n            self._monitor_stream = None\n        log.trace(\"Event monitor done!\")\n"], "filenames": ["salt/crypt.py", "salt/transport/tcp.py", "salt/transport/zeromq.py"], "buggy_code_start_loc": [609, 625, 596], "buggy_code_end_loc": [609, 625, 596], "fixing_code_start_loc": [610, 626, 597], "fixing_code_end_loc": [613, 637, 608], "type": "CWE-20", "message": "SaltStack Salt before 2016.3.8, 2016.11.x before 2016.11.8, and 2017.7.x before 2017.7.2 allows remote attackers to cause a denial of service via a crafted authentication request.", "other": {"cve": {"id": "CVE-2017-14696", "sourceIdentifier": "cve@mitre.org", "published": "2017-10-24T17:29:00.370", "lastModified": "2017-11-15T15:38:15.053", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "SaltStack Salt before 2016.3.8, 2016.11.x before 2016.11.8, and 2017.7.x before 2017.7.2 allows remote attackers to cause a denial of service via a crafted authentication request."}, {"lang": "es", "value": "SaltStack Salt en versiones anteriores a la 2016.3.8, en versiones 2016.11.x anteriores a la 2016.11.8 y versiones 2017.7.x anteriores a la 2017.7.2 permite que atacantes remotos provoquen una denegaci\u00f3n de servicio (DoS) mediante una petici\u00f3n de autenticaci\u00f3n manipulada."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:N/I:N/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 5.0}, "baseSeverity": "MEDIUM", "exploitabilityScore": 10.0, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:*:*:*:*:*:*:*:*", "versionEndIncluding": "2016.3.7", "matchCriteriaId": "CC5250DF-593F-42C2-A64F-47CE0E65070F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11:*:*:*:*:*:*:*", "matchCriteriaId": "689B37E8-7274-4B5A-9419-538A9AB7B99F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.0:*:*:*:*:*:*:*", "matchCriteriaId": "F5B7EDF4-414F-429A-BD20-0B967737598C"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.1:*:*:*:*:*:*:*", "matchCriteriaId": "594339CF-8192-425D-9C8C-AA51342D9477"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.1:rc1:*:*:*:*:*:*", "matchCriteriaId": "80E02A57-EA6E-4729-8E4E-4F444DA0A88E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.1:rc2:*:*:*:*:*:*", "matchCriteriaId": "6110046D-0532-41DB-9DF0-BB1BD1447D6E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.2:*:*:*:*:*:*:*", "matchCriteriaId": "E54FADCE-5311-4C8A-9527-1623F9AAC69E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.3:*:*:*:*:*:*:*", "matchCriteriaId": "4E904BB7-706A-43E0-96CE-2A9E671E4FB3"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.4:*:*:*:*:*:*:*", "matchCriteriaId": "0338B627-4E56-4B47-87BA-CE9446CB6345"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.5:*:*:*:*:*:*:*", "matchCriteriaId": "FB77EB21-90F0-4E5F-8C2F-2973460A1E05"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.6:*:*:*:*:*:*:*", "matchCriteriaId": "536FF3D1-C16D-4F40-8E80-D5956FC6693F"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2016.11.7:*:*:*:*:*:*:*", "matchCriteriaId": "CED0077F-8C9D-4043-B15E-61547A0EE58A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2017.7.0:*:*:*:*:*:*:*", "matchCriteriaId": "8F54D0CC-68F0-44E0-B565-BB9EFFE56817"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2017.7.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "97BDE3E9-E1C7-4D8D-B886-A3CE617BF12E"}, {"vulnerable": true, "criteria": "cpe:2.3:a:saltstack:salt:2017.7.1:*:*:*:*:*:*:*", "matchCriteriaId": "87ABC6C6-5E17-4732-B24C-032767D6EBC1"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-updates/2017-10/msg00073.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Release Notes", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-updates/2017-10/msg00075.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Release Notes", "Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1500742", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Release Notes", "Third Party Advisory"]}, {"url": "https://docs.saltstack.com/en/latest/topics/releases/2016.11.8.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Release Notes", "Vendor Advisory"]}, {"url": "https://docs.saltstack.com/en/latest/topics/releases/2016.3.8.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Release Notes", "Vendor Advisory"]}, {"url": "https://docs.saltstack.com/en/latest/topics/releases/2017.7.2.html", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Release Notes", "Vendor Advisory"]}, {"url": "https://github.com/saltstack/salt/commit/5f8b5e1a0f23fe0f2be5b3c3e04199b57a53db5b", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/saltstack/salt/commit/5f8b5e1a0f23fe0f2be5b3c3e04199b57a53db5b"}}
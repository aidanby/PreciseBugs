{"buggy_code": ["\tacpi=\t\t[HW,ACPI,X86,ARM64]\n\t\t\tAdvanced Configuration and Power Interface\n\t\t\tFormat: { force | on | off | strict | noirq | rsdt |\n\t\t\t\t  copy_dsdt }\n\t\t\tforce -- enable ACPI if default was off\n\t\t\ton -- enable ACPI but allow fallback to DT [arm64]\n\t\t\toff -- disable ACPI if default was on\n\t\t\tnoirq -- do not use ACPI for IRQ routing\n\t\t\tstrict -- Be less tolerant of platforms that are not\n\t\t\t\tstrictly ACPI specification compliant.\n\t\t\trsdt -- prefer RSDT over (default) XSDT\n\t\t\tcopy_dsdt -- copy DSDT to memory\n\t\t\tFor ARM64, ONLY \"acpi=off\", \"acpi=on\" or \"acpi=force\"\n\t\t\tare available\n\n\t\t\tSee also Documentation/power/runtime_pm.rst, pci=noacpi\n\n\tacpi_apic_instance=\t[ACPI, IOAPIC]\n\t\t\tFormat: <int>\n\t\t\t2: use 2nd APIC table, if available\n\t\t\t1,0: use 1st APIC table\n\t\t\tdefault: 0\n\n\tacpi_backlight=\t[HW,ACPI]\n\t\t\t{ vendor | video | native | none }\n\t\t\tIf set to vendor, prefer vendor-specific driver\n\t\t\t(e.g. thinkpad_acpi, sony_acpi, etc.) instead\n\t\t\tof the ACPI video.ko driver.\n\t\t\tIf set to video, use the ACPI video.ko driver.\n\t\t\tIf set to native, use the device's native backlight mode.\n\t\t\tIf set to none, disable the ACPI backlight interface.\n\n\tacpi_force_32bit_fadt_addr\n\t\t\tforce FADT to use 32 bit addresses rather than the\n\t\t\t64 bit X_* addresses. Some firmware have broken 64\n\t\t\tbit addresses for force ACPI ignore these and use\n\t\t\tthe older legacy 32 bit addresses.\n\n\tacpica_no_return_repair [HW, ACPI]\n\t\t\tDisable AML predefined validation mechanism\n\t\t\tThis mechanism can repair the evaluation result to make\n\t\t\tthe return objects more ACPI specification compliant.\n\t\t\tThis option is useful for developers to identify the\n\t\t\troot cause of an AML interpreter issue when the issue\n\t\t\thas something to do with the repair mechanism.\n\n\tacpi.debug_layer=\t[HW,ACPI,ACPI_DEBUG]\n\tacpi.debug_level=\t[HW,ACPI,ACPI_DEBUG]\n\t\t\tFormat: <int>\n\t\t\tCONFIG_ACPI_DEBUG must be enabled to produce any ACPI\n\t\t\tdebug output.  Bits in debug_layer correspond to a\n\t\t\t_COMPONENT in an ACPI source file, e.g.,\n\t\t\t    #define _COMPONENT ACPI_PCI_COMPONENT\n\t\t\tBits in debug_level correspond to a level in\n\t\t\tACPI_DEBUG_PRINT statements, e.g.,\n\t\t\t    ACPI_DEBUG_PRINT((ACPI_DB_INFO, ...\n\t\t\tThe debug_level mask defaults to \"info\".  See\n\t\t\tDocumentation/firmware-guide/acpi/debug.rst for more information about\n\t\t\tdebug layers and levels.\n\n\t\t\tEnable processor driver info messages:\n\t\t\t    acpi.debug_layer=0x20000000\n\t\t\tEnable PCI/PCI interrupt routing info messages:\n\t\t\t    acpi.debug_layer=0x400000\n\t\t\tEnable AML \"Debug\" output, i.e., stores to the Debug\n\t\t\tobject while interpreting AML:\n\t\t\t    acpi.debug_layer=0xffffffff acpi.debug_level=0x2\n\t\t\tEnable all messages related to ACPI hardware:\n\t\t\t    acpi.debug_layer=0x2 acpi.debug_level=0xffffffff\n\n\t\t\tSome values produce so much output that the system is\n\t\t\tunusable.  The \"log_buf_len\" parameter may be useful\n\t\t\tif you need to capture more output.\n\n\tacpi_enforce_resources=\t[ACPI]\n\t\t\t{ strict | lax | no }\n\t\t\tCheck for resource conflicts between native drivers\n\t\t\tand ACPI OperationRegions (SystemIO and SystemMemory\n\t\t\tonly). IO ports and memory declared in ACPI might be\n\t\t\tused by the ACPI subsystem in arbitrary AML code and\n\t\t\tcan interfere with legacy drivers.\n\t\t\tstrict (default): access to resources claimed by ACPI\n\t\t\tis denied; legacy drivers trying to access reserved\n\t\t\tresources will fail to bind to device using them.\n\t\t\tlax: access to resources claimed by ACPI is allowed;\n\t\t\tlegacy drivers trying to access reserved resources\n\t\t\twill bind successfully but a warning message is logged.\n\t\t\tno: ACPI OperationRegions are not marked as reserved,\n\t\t\tno further checks are performed.\n\n\tacpi_force_table_verification\t[HW,ACPI]\n\t\t\tEnable table checksum verification during early stage.\n\t\t\tBy default, this is disabled due to x86 early mapping\n\t\t\tsize limitation.\n\n\tacpi_irq_balance [HW,ACPI]\n\t\t\tACPI will balance active IRQs\n\t\t\tdefault in APIC mode\n\n\tacpi_irq_nobalance [HW,ACPI]\n\t\t\tACPI will not move active IRQs (default)\n\t\t\tdefault in PIC mode\n\n\tacpi_irq_isa=\t[HW,ACPI] If irq_balance, mark listed IRQs used by ISA\n\t\t\tFormat: <irq>,<irq>...\n\n\tacpi_irq_pci=\t[HW,ACPI] If irq_balance, clear listed IRQs for\n\t\t\tuse by PCI\n\t\t\tFormat: <irq>,<irq>...\n\n\tacpi_mask_gpe=\t[HW,ACPI]\n\t\t\tDue to the existence of _Lxx/_Exx, some GPEs triggered\n\t\t\tby unsupported hardware/firmware features can result in\n\t\t\tGPE floodings that cannot be automatically disabled by\n\t\t\tthe GPE dispatcher.\n\t\t\tThis facility can be used to prevent such uncontrolled\n\t\t\tGPE floodings.\n\t\t\tFormat: <byte>\n\n\tacpi_no_auto_serialize\t[HW,ACPI]\n\t\t\tDisable auto-serialization of AML methods\n\t\t\tAML control methods that contain the opcodes to create\n\t\t\tnamed objects will be marked as \"Serialized\" by the\n\t\t\tauto-serialization feature.\n\t\t\tThis feature is enabled by default.\n\t\t\tThis option allows to turn off the feature.\n\n\tacpi_no_memhotplug [ACPI] Disable memory hotplug.  Useful for kdump\n\t\t\t   kernels.\n\n\tacpi_no_static_ssdt\t[HW,ACPI]\n\t\t\tDisable installation of static SSDTs at early boot time\n\t\t\tBy default, SSDTs contained in the RSDT/XSDT will be\n\t\t\tinstalled automatically and they will appear under\n\t\t\t/sys/firmware/acpi/tables.\n\t\t\tThis option turns off this feature.\n\t\t\tNote that specifying this option does not affect\n\t\t\tdynamic table installation which will install SSDT\n\t\t\ttables to /sys/firmware/acpi/tables/dynamic.\n\n\tacpi_no_watchdog\t[HW,ACPI,WDT]\n\t\t\tIgnore the ACPI-based watchdog interface (WDAT) and let\n\t\t\ta native driver control the watchdog device instead.\n\n\tacpi_rsdp=\t[ACPI,EFI,KEXEC]\n\t\t\tPass the RSDP address to the kernel, mostly used\n\t\t\ton machines running EFI runtime service to boot the\n\t\t\tsecond kernel for kdump.\n\n\tacpi_os_name=\t[HW,ACPI] Tell ACPI BIOS the name of the OS\n\t\t\tFormat: To spoof as Windows 98: =\"Microsoft Windows\"\n\n\tacpi_rev_override [ACPI] Override the _REV object to return 5 (instead\n\t\t\tof 2 which is mandated by ACPI 6) as the supported ACPI\n\t\t\tspecification revision (when using this switch, it may\n\t\t\tbe necessary to carry out a cold reboot _twice_ in a\n\t\t\trow to make it take effect on the platform firmware).\n\n\tacpi_osi=\t[HW,ACPI] Modify list of supported OS interface strings\n\t\t\tacpi_osi=\"string1\"\t# add string1\n\t\t\tacpi_osi=\"!string2\"\t# remove string2\n\t\t\tacpi_osi=!*\t\t# remove all strings\n\t\t\tacpi_osi=!\t\t# disable all built-in OS vendor\n\t\t\t\t\t\t  strings\n\t\t\tacpi_osi=!!\t\t# enable all built-in OS vendor\n\t\t\t\t\t\t  strings\n\t\t\tacpi_osi=\t\t# disable all strings\n\n\t\t\t'acpi_osi=!' can be used in combination with single or\n\t\t\tmultiple 'acpi_osi=\"string1\"' to support specific OS\n\t\t\tvendor string(s).  Note that such command can only\n\t\t\taffect the default state of the OS vendor strings, thus\n\t\t\tit cannot affect the default state of the feature group\n\t\t\tstrings and the current state of the OS vendor strings,\n\t\t\tspecifying it multiple times through kernel command line\n\t\t\tis meaningless.  This command is useful when one do not\n\t\t\tcare about the state of the feature group strings which\n\t\t\tshould be controlled by the OSPM.\n\t\t\tExamples:\n\t\t\t  1. 'acpi_osi=! acpi_osi=\"Windows 2000\"' is equivalent\n\t\t\t     to 'acpi_osi=\"Windows 2000\" acpi_osi=!', they all\n\t\t\t     can make '_OSI(\"Windows 2000\")' TRUE.\n\n\t\t\t'acpi_osi=' cannot be used in combination with other\n\t\t\t'acpi_osi=' command lines, the _OSI method will not\n\t\t\texist in the ACPI namespace.  NOTE that such command can\n\t\t\tonly affect the _OSI support state, thus specifying it\n\t\t\tmultiple times through kernel command line is also\n\t\t\tmeaningless.\n\t\t\tExamples:\n\t\t\t  1. 'acpi_osi=' can make 'CondRefOf(_OSI, Local1)'\n\t\t\t     FALSE.\n\n\t\t\t'acpi_osi=!*' can be used in combination with single or\n\t\t\tmultiple 'acpi_osi=\"string1\"' to support specific\n\t\t\tstring(s).  Note that such command can affect the\n\t\t\tcurrent state of both the OS vendor strings and the\n\t\t\tfeature group strings, thus specifying it multiple times\n\t\t\tthrough kernel command line is meaningful.  But it may\n\t\t\tstill not able to affect the final state of a string if\n\t\t\tthere are quirks related to this string.  This command\n\t\t\tis useful when one want to control the state of the\n\t\t\tfeature group strings to debug BIOS issues related to\n\t\t\tthe OSPM features.\n\t\t\tExamples:\n\t\t\t  1. 'acpi_osi=\"Module Device\" acpi_osi=!*' can make\n\t\t\t     '_OSI(\"Module Device\")' FALSE.\n\t\t\t  2. 'acpi_osi=!* acpi_osi=\"Module Device\"' can make\n\t\t\t     '_OSI(\"Module Device\")' TRUE.\n\t\t\t  3. 'acpi_osi=! acpi_osi=!* acpi_osi=\"Windows 2000\"' is\n\t\t\t     equivalent to\n\t\t\t     'acpi_osi=!* acpi_osi=! acpi_osi=\"Windows 2000\"'\n\t\t\t     and\n\t\t\t     'acpi_osi=!* acpi_osi=\"Windows 2000\" acpi_osi=!',\n\t\t\t     they all will make '_OSI(\"Windows 2000\")' TRUE.\n\n\tacpi_pm_good\t[X86]\n\t\t\tOverride the pmtimer bug detection: force the kernel\n\t\t\tto assume that this machine's pmtimer latches its value\n\t\t\tand always returns good values.\n\n\tacpi_sci=\t[HW,ACPI] ACPI System Control Interrupt trigger mode\n\t\t\tFormat: { level | edge | high | low }\n\n\tacpi_skip_timer_override [HW,ACPI]\n\t\t\tRecognize and ignore IRQ0/pin2 Interrupt Override.\n\t\t\tFor broken nForce2 BIOS resulting in XT-PIC timer.\n\n\tacpi_sleep=\t[HW,ACPI] Sleep options\n\t\t\tFormat: { s3_bios, s3_mode, s3_beep, s4_nohwsig,\n\t\t\t\t  old_ordering, nonvs, sci_force_enable, nobl }\n\t\t\tSee Documentation/power/video.rst for information on\n\t\t\ts3_bios and s3_mode.\n\t\t\ts3_beep is for debugging; it makes the PC's speaker beep\n\t\t\tas soon as the kernel's real-mode entry point is called.\n\t\t\ts4_nohwsig prevents ACPI hardware signature from being\n\t\t\tused during resume from hibernation.\n\t\t\told_ordering causes the ACPI 1.0 ordering of the _PTS\n\t\t\tcontrol method, with respect to putting devices into\n\t\t\tlow power states, to be enforced (the ACPI 2.0 ordering\n\t\t\tof _PTS is used by default).\n\t\t\tnonvs prevents the kernel from saving/restoring the\n\t\t\tACPI NVS memory during suspend/hibernation and resume.\n\t\t\tsci_force_enable causes the kernel to set SCI_EN directly\n\t\t\ton resume from S1/S3 (which is against the ACPI spec,\n\t\t\tbut some broken systems don't work without it).\n\t\t\tnobl causes the internal blacklist of systems known to\n\t\t\tbehave incorrectly in some ways with respect to system\n\t\t\tsuspend and resume to be ignored (use wisely).\n\n\tacpi_use_timer_override [HW,ACPI]\n\t\t\tUse timer override. For some broken Nvidia NF5 boards\n\t\t\tthat require a timer override, but don't have HPET\n\n\tadd_efi_memmap\t[EFI; X86] Include EFI memory map in\n\t\t\tkernel's map of available physical RAM.\n\n\tagp=\t\t[AGP]\n\t\t\t{ off | try_unsupported }\n\t\t\toff: disable AGP support\n\t\t\ttry_unsupported: try to drive unsupported chipsets\n\t\t\t\t(may crash computer or cause data corruption)\n\n\tALSA\t\t[HW,ALSA]\n\t\t\tSee Documentation/sound/alsa-configuration.rst\n\n\talignment=\t[KNL,ARM]\n\t\t\tAllow the default userspace alignment fault handler\n\t\t\tbehaviour to be specified.  Bit 0 enables warnings,\n\t\t\tbit 1 enables fixups, and bit 2 sends a segfault.\n\n\talign_va_addr=\t[X86-64]\n\t\t\tAlign virtual addresses by clearing slice [14:12] when\n\t\t\tallocating a VMA at process creation time. This option\n\t\t\tgives you up to 3% performance improvement on AMD F15h\n\t\t\tmachines (where it is enabled by default) for a\n\t\t\tCPU-intensive style benchmark, and it can vary highly in\n\t\t\ta microbenchmark depending on workload and compiler.\n\n\t\t\t32: only for 32-bit processes\n\t\t\t64: only for 64-bit processes\n\t\t\ton: enable for both 32- and 64-bit processes\n\t\t\toff: disable for both 32- and 64-bit processes\n\n\talloc_snapshot\t[FTRACE]\n\t\t\tAllocate the ftrace snapshot buffer on boot up when the\n\t\t\tmain buffer is allocated. This is handy if debugging\n\t\t\tand you need to use tracing_snapshot() on boot up, and\n\t\t\tdo not want to use tracing_snapshot_alloc() as it needs\n\t\t\tto be done where GFP_KERNEL allocations are allowed.\n\n\tamd_iommu=\t[HW,X86-64]\n\t\t\tPass parameters to the AMD IOMMU driver in the system.\n\t\t\tPossible values are:\n\t\t\tfullflush - enable flushing of IO/TLB entries when\n\t\t\t\t    they are unmapped. Otherwise they are\n\t\t\t\t    flushed before they will be reused, which\n\t\t\t\t    is a lot of faster\n\t\t\toff\t  - do not initialize any AMD IOMMU found in\n\t\t\t\t    the system\n\t\t\tforce_isolation - Force device isolation for all\n\t\t\t\t\t  devices. The IOMMU driver is not\n\t\t\t\t\t  allowed anymore to lift isolation\n\t\t\t\t\t  requirements as needed. This option\n\t\t\t\t\t  does not override iommu=pt\n\n\tamd_iommu_dump=\t[HW,X86-64]\n\t\t\tEnable AMD IOMMU driver option to dump the ACPI table\n\t\t\tfor AMD IOMMU. With this option enabled, AMD IOMMU\n\t\t\tdriver will print ACPI tables for AMD IOMMU during\n\t\t\tIOMMU initialization.\n\n\tamd_iommu_intr=\t[HW,X86-64]\n\t\t\tSpecifies one of the following AMD IOMMU interrupt\n\t\t\tremapping modes:\n\t\t\tlegacy     - Use legacy interrupt remapping mode.\n\t\t\tvapic      - Use virtual APIC mode, which allows IOMMU\n\t\t\t             to inject interrupts directly into guest.\n\t\t\t             This mode requires kvm-amd.avic=1.\n\t\t\t             (Default when IOMMU HW support is present.)\n\n\tamijoy.map=\t[HW,JOY] Amiga joystick support\n\t\t\tMap of devices attached to JOY0DAT and JOY1DAT\n\t\t\tFormat: <a>,<b>\n\t\t\tSee also Documentation/input/joydev/joystick.rst\n\n\tanalog.map=\t[HW,JOY] Analog joystick and gamepad support\n\t\t\tSpecifies type or capabilities of an analog joystick\n\t\t\tconnected to one of 16 gameports\n\t\t\tFormat: <type1>,<type2>,..<type16>\n\n\tapc=\t\t[HW,SPARC]\n\t\t\tPower management functions (SPARCstation-4/5 + deriv.)\n\t\t\tFormat: noidle\n\t\t\tDisable APC CPU standby support. SPARCstation-Fox does\n\t\t\tnot play well with APC CPU idle - disable it if you have\n\t\t\tAPC and your system crashes randomly.\n\n\tapic=\t\t[APIC,X86] Advanced Programmable Interrupt Controller\n\t\t\tChange the output verbosity while booting\n\t\t\tFormat: { quiet (default) | verbose | debug }\n\t\t\tChange the amount of debugging information output\n\t\t\twhen initialising the APIC and IO-APIC components.\n\t\t\tFor X86-32, this can also be used to specify an APIC\n\t\t\tdriver name.\n\t\t\tFormat: apic=driver_name\n\t\t\tExamples: apic=bigsmp\n\n\tapic_extnmi=\t[APIC,X86] External NMI delivery setting\n\t\t\tFormat: { bsp (default) | all | none }\n\t\t\tbsp:  External NMI is delivered only to CPU 0\n\t\t\tall:  External NMIs are broadcast to all CPUs as a\n\t\t\t      backup of CPU 0\n\t\t\tnone: External NMI is masked for all CPUs. This is\n\t\t\t      useful so that a dump capture kernel won't be\n\t\t\t      shot down by NMI\n\n\tautoconf=\t[IPV6]\n\t\t\tSee Documentation/networking/ipv6.rst.\n\n\tshow_lapic=\t[APIC,X86] Advanced Programmable Interrupt Controller\n\t\t\tLimit apic dumping. The parameter defines the maximal\n\t\t\tnumber of local apics being dumped. Also it is possible\n\t\t\tto set it to \"all\" by meaning -- no limit here.\n\t\t\tFormat: { 1 (default) | 2 | ... | all }.\n\t\t\tThe parameter valid if only apic=debug or\n\t\t\tapic=verbose is specified.\n\t\t\tExample: apic=debug show_lapic=all\n\n\tapm=\t\t[APM] Advanced Power Management\n\t\t\tSee header of arch/x86/kernel/apm_32.c.\n\n\tarcrimi=\t[HW,NET] ARCnet - \"RIM I\" (entirely mem-mapped) cards\n\t\t\tFormat: <io>,<irq>,<nodeID>\n\n\tataflop=\t[HW,M68k]\n\n\tatarimouse=\t[HW,MOUSE] Atari Mouse\n\n\tatkbd.extra=\t[HW] Enable extra LEDs and keys on IBM RapidAccess,\n\t\t\tEzKey and similar keyboards\n\n\tatkbd.reset=\t[HW] Reset keyboard during initialization\n\n\tatkbd.set=\t[HW] Select keyboard code set\n\t\t\tFormat: <int> (2 = AT (default), 3 = PS/2)\n\n\tatkbd.scroll=\t[HW] Enable scroll wheel on MS Office and similar\n\t\t\tkeyboards\n\n\tatkbd.softraw=\t[HW] Choose between synthetic and real raw mode\n\t\t\tFormat: <bool> (0 = real, 1 = synthetic (default))\n\n\tatkbd.softrepeat= [HW]\n\t\t\tUse software keyboard repeat\n\n\taudit=\t\t[KNL] Enable the audit sub-system\n\t\t\tFormat: { \"0\" | \"1\" | \"off\" | \"on\" }\n\t\t\t0 | off - kernel audit is disabled and can not be\n\t\t\t    enabled until the next reboot\n\t\t\tunset - kernel audit is initialized but disabled and\n\t\t\t    will be fully enabled by the userspace auditd.\n\t\t\t1 | on - kernel audit is initialized and partially\n\t\t\t    enabled, storing at most audit_backlog_limit\n\t\t\t    messages in RAM until it is fully enabled by the\n\t\t\t    userspace auditd.\n\t\t\tDefault: unset\n\n\taudit_backlog_limit= [KNL] Set the audit queue size limit.\n\t\t\tFormat: <int> (must be >=0)\n\t\t\tDefault: 64\n\n\tbau=\t\t[X86_UV] Enable the BAU on SGI UV.  The default\n\t\t\tbehavior is to disable the BAU (i.e. bau=0).\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 - Disable the BAU.\n\t\t\t1 - Enable the BAU.\n\t\t\tunset - Disable the BAU.\n\n\tbaycom_epp=\t[HW,AX25]\n\t\t\tFormat: <io>,<mode>\n\n\tbaycom_par=\t[HW,AX25] BayCom Parallel Port AX.25 Modem\n\t\t\tFormat: <io>,<mode>\n\t\t\tSee header of drivers/net/hamradio/baycom_par.c.\n\n\tbaycom_ser_fdx=\t[HW,AX25]\n\t\t\tBayCom Serial Port AX.25 Modem (Full Duplex Mode)\n\t\t\tFormat: <io>,<irq>,<mode>[,<baud>]\n\t\t\tSee header of drivers/net/hamradio/baycom_ser_fdx.c.\n\n\tbaycom_ser_hdx=\t[HW,AX25]\n\t\t\tBayCom Serial Port AX.25 Modem (Half Duplex Mode)\n\t\t\tFormat: <io>,<irq>,<mode>\n\t\t\tSee header of drivers/net/hamradio/baycom_ser_hdx.c.\n\n\tblkdevparts=\tManual partition parsing of block device(s) for\n\t\t\tembedded devices based on command line input.\n\t\t\tSee Documentation/block/cmdline-partition.rst\n\n\tboot_delay=\tMilliseconds to delay each printk during boot.\n\t\t\tValues larger than 10 seconds (10000) are changed to\n\t\t\tno delay (0).\n\t\t\tFormat: integer\n\n\tbootconfig\t[KNL]\n\t\t\tExtended command line options can be added to an initrd\n\t\t\tand this will cause the kernel to look for it.\n\n\t\t\tSee Documentation/admin-guide/bootconfig.rst\n\n\tbert_disable\t[ACPI]\n\t\t\tDisable BERT OS support on buggy BIOSes.\n\n\tbgrt_disable\t[ACPI][X86]\n\t\t\tDisable BGRT to avoid flickering OEM logo.\n\n\tbttv.card=\t[HW,V4L] bttv (bt848 + bt878 based grabber cards)\n\tbttv.radio=\tMost important insmod options are available as\n\t\t\tkernel args too.\n\tbttv.pll=\tSee Documentation/admin-guide/media/bttv.rst\n\tbttv.tuner=\n\n\tbulk_remove=off\t[PPC]  This parameter disables the use of the pSeries\n\t\t\tfirmware feature for flushing multiple hpte entries\n\t\t\tat a time.\n\n\tc101=\t\t[NET] Moxa C101 synchronous serial card\n\n\tcachesize=\t[BUGS=X86-32] Override level 2 CPU cache size detection.\n\t\t\tSometimes CPU hardware bugs make them report the cache\n\t\t\tsize incorrectly. The kernel will attempt work arounds\n\t\t\tto fix known problems, but for some CPUs it is not\n\t\t\tpossible to determine what the correct size should be.\n\t\t\tThis option provides an override for these situations.\n\n\tcarrier_timeout=\n\t\t\t[NET] Specifies amount of time (in seconds) that\n\t\t\tthe kernel should wait for a network carrier. By default\n\t\t\tit waits 120 seconds.\n\n\tca_keys=\t[KEYS] This parameter identifies a specific key(s) on\n\t\t\tthe system trusted keyring to be used for certificate\n\t\t\ttrust validation.\n\t\t\tformat: { id:<keyid> | builtin }\n\n\tcca=\t\t[MIPS] Override the kernel pages' cache coherency\n\t\t\talgorithm.  Accepted values range from 0 to 7\n\t\t\tinclusive. See arch/mips/include/asm/pgtable-bits.h\n\t\t\tfor platform specific values (SB1, Loongson3 and\n\t\t\tothers).\n\n\tccw_timeout_log\t[S390]\n\t\t\tSee Documentation/s390/common_io.rst for details.\n\n\tcgroup_disable=\t[KNL] Disable a particular controller\n\t\t\tFormat: {name of the controller(s) to disable}\n\t\t\tThe effects of cgroup_disable=foo are:\n\t\t\t- foo isn't auto-mounted if you mount all cgroups in\n\t\t\t  a single hierarchy\n\t\t\t- foo isn't visible as an individually mountable\n\t\t\t  subsystem\n\t\t\t{Currently only \"memory\" controller deal with this and\n\t\t\tcut the overhead, others just disable the usage. So\n\t\t\tonly cgroup_disable=memory is actually worthy}\n\n\tcgroup_no_v1=\t[KNL] Disable cgroup controllers and named hierarchies in v1\n\t\t\tFormat: { { controller | \"all\" | \"named\" }\n\t\t\t          [,{ controller | \"all\" | \"named\" }...] }\n\t\t\tLike cgroup_disable, but only applies to cgroup v1;\n\t\t\tthe blacklisted controllers remain available in cgroup2.\n\t\t\t\"all\" blacklists all controllers and \"named\" disables\n\t\t\tnamed mounts. Specifying both \"all\" and \"named\" disables\n\t\t\tall v1 hierarchies.\n\n\tcgroup.memory=\t[KNL] Pass options to the cgroup memory controller.\n\t\t\tFormat: <string>\n\t\t\tnosocket -- Disable socket memory accounting.\n\t\t\tnokmem -- Disable kernel memory accounting.\n\n\tcheckreqprot\t[SELINUX] Set initial checkreqprot flag value.\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\tSee security/selinux/Kconfig help text.\n\t\t\t0 -- check protection applied by kernel (includes\n\t\t\t\tany implied execute protection).\n\t\t\t1 -- check protection requested by application.\n\t\t\tDefault value is set via a kernel config option.\n\t\t\tValue can be changed at runtime via\n\t\t\t\t/sys/fs/selinux/checkreqprot.\n\t\t\tSetting checkreqprot to 1 is deprecated.\n\n\tcio_ignore=\t[S390]\n\t\t\tSee Documentation/s390/common_io.rst for details.\n\tclk_ignore_unused\n\t\t\t[CLK]\n\t\t\tPrevents the clock framework from automatically gating\n\t\t\tclocks that have not been explicitly enabled by a Linux\n\t\t\tdevice driver but are enabled in hardware at reset or\n\t\t\tby the bootloader/firmware. Note that this does not\n\t\t\tforce such clocks to be always-on nor does it reserve\n\t\t\tthose clocks in any way. This parameter is useful for\n\t\t\tdebug and development, but should not be needed on a\n\t\t\tplatform with proper driver support.  For more\n\t\t\tinformation, see Documentation/driver-api/clk.rst.\n\n\tclock=\t\t[BUGS=X86-32, HW] gettimeofday clocksource override.\n\t\t\t[Deprecated]\n\t\t\tForces specified clocksource (if available) to be used\n\t\t\twhen calculating gettimeofday(). If specified\n\t\t\tclocksource is not available, it defaults to PIT.\n\t\t\tFormat: { pit | tsc | cyclone | pmtmr }\n\n\tclocksource=\tOverride the default clocksource\n\t\t\tFormat: <string>\n\t\t\tOverride the default clocksource and use the clocksource\n\t\t\twith the name specified.\n\t\t\tSome clocksource names to choose from, depending on\n\t\t\tthe platform:\n\t\t\t[all] jiffies (this is the base, fallback clocksource)\n\t\t\t[ACPI] acpi_pm\n\t\t\t[ARM] imx_timer1,OSTS,netx_timer,mpu_timer2,\n\t\t\t\tpxa_timer,timer3,32k_counter,timer0_1\n\t\t\t[X86-32] pit,hpet,tsc;\n\t\t\t\tscx200_hrt on Geode; cyclone on IBM x440\n\t\t\t[MIPS] MIPS\n\t\t\t[PARISC] cr16\n\t\t\t[S390] tod\n\t\t\t[SH] SuperH\n\t\t\t[SPARC64] tick\n\t\t\t[X86-64] hpet,tsc\n\n\tclocksource.arm_arch_timer.evtstrm=\n\t\t\t[ARM,ARM64]\n\t\t\tFormat: <bool>\n\t\t\tEnable/disable the eventstream feature of the ARM\n\t\t\tarchitected timer so that code using WFE-based polling\n\t\t\tloops can be debugged more effectively on production\n\t\t\tsystems.\n\n\tclearcpuid=BITNUM [X86]\n\t\t\tDisable CPUID feature X for the kernel. See\n\t\t\tarch/x86/include/asm/cpufeatures.h for the valid bit\n\t\t\tnumbers. Note the Linux specific bits are not necessarily\n\t\t\tstable over kernel options, but the vendor specific\n\t\t\tones should be.\n\t\t\tAlso note that user programs calling CPUID directly\n\t\t\tor using the feature without checking anything\n\t\t\twill still see it. This just prevents it from\n\t\t\tbeing used by the kernel or shown in /proc/cpuinfo.\n\t\t\tAlso note the kernel might malfunction if you disable\n\t\t\tsome critical bits.\n\n\tcma=nn[MG]@[start[MG][-end[MG]]]\n\t\t\t[ARM,X86,KNL]\n\t\t\tSets the size of kernel global memory area for\n\t\t\tcontiguous memory allocations and optionally the\n\t\t\tplacement constraint by the physical address range of\n\t\t\tmemory allocations. A value of 0 disables CMA\n\t\t\taltogether. For more information, see\n\t\t\tinclude/linux/dma-contiguous.h\n\n\tcmo_free_hint=\t[PPC] Format: { yes | no }\n\t\t\tSpecify whether pages are marked as being inactive\n\t\t\twhen they are freed.  This is used in CMO environments\n\t\t\tto determine OS memory pressure for page stealing by\n\t\t\ta hypervisor.\n\t\t\tDefault: yes\n\n\tcoherent_pool=nn[KMG]\t[ARM,KNL]\n\t\t\tSets the size of memory pool for coherent, atomic dma\n\t\t\tallocations, by default set to 256K.\n\n\tcom20020=\t[HW,NET] ARCnet - COM20020 chipset\n\t\t\tFormat:\n\t\t\t<io>[,<irq>[,<nodeID>[,<backplane>[,<ckp>[,<timeout>]]]]]\n\n\tcom90io=\t[HW,NET] ARCnet - COM90xx chipset (IO-mapped buffers)\n\t\t\tFormat: <io>[,<irq>]\n\n\tcom90xx=\t[HW,NET]\n\t\t\tARCnet - COM90xx chipset (memory-mapped buffers)\n\t\t\tFormat: <io>[,<irq>[,<memstart>]]\n\n\tcondev=\t\t[HW,S390] console device\n\tconmode=\n\n\tconsole=\t[KNL] Output console device and options.\n\n\t\ttty<n>\tUse the virtual console device <n>.\n\n\t\tttyS<n>[,options]\n\t\tttyUSB0[,options]\n\t\t\tUse the specified serial port.  The options are of\n\t\t\tthe form \"bbbbpnf\", where \"bbbb\" is the baud rate,\n\t\t\t\"p\" is parity (\"n\", \"o\", or \"e\"), \"n\" is number of\n\t\t\tbits, and \"f\" is flow control (\"r\" for RTS or\n\t\t\tomit it).  Default is \"9600n8\".\n\n\t\t\tSee Documentation/admin-guide/serial-console.rst for more\n\t\t\tinformation.  See\n\t\t\tDocumentation/networking/netconsole.rst for an\n\t\t\talternative.\n\n\t\tuart[8250],io,<addr>[,options]\n\t\tuart[8250],mmio,<addr>[,options]\n\t\tuart[8250],mmio16,<addr>[,options]\n\t\tuart[8250],mmio32,<addr>[,options]\n\t\tuart[8250],0x<addr>[,options]\n\t\t\tStart an early, polled-mode console on the 8250/16550\n\t\t\tUART at the specified I/O port or MMIO address,\n\t\t\tswitching to the matching ttyS device later.\n\t\t\tMMIO inter-register address stride is either 8-bit\n\t\t\t(mmio), 16-bit (mmio16), or 32-bit (mmio32).\n\t\t\tIf none of [io|mmio|mmio16|mmio32], <addr> is assumed\n\t\t\tto be equivalent to 'mmio'. 'options' are specified in\n\t\t\tthe same format described for ttyS above; if unspecified,\n\t\t\tthe h/w is not re-initialized.\n\n\t\thvc<n>\tUse the hypervisor console device <n>. This is for\n\t\t\tboth Xen and PowerPC hypervisors.\n\n\t\tIf the device connected to the port is not a TTY but a braille\n\t\tdevice, prepend \"brl,\" before the device type, for instance\n\t\t\tconsole=brl,ttyS0\n\t\tFor now, only VisioBraille is supported.\n\n\tconsole_msg_format=\n\t\t\t[KNL] Change console messages format\n\t\tdefault\n\t\t\tBy default we print messages on consoles in\n\t\t\t\"[time stamp] text\\n\" format (time stamp may not be\n\t\t\tprinted, depending on CONFIG_PRINTK_TIME or\n\t\t\t`printk_time' param).\n\t\tsyslog\n\t\t\tSwitch to syslog format: \"<%u>[time stamp] text\\n\"\n\t\t\tIOW, each message will have a facility and loglevel\n\t\t\tprefix. The format is similar to one used by syslog()\n\t\t\tsyscall, or to executing \"dmesg -S --raw\" or to reading\n\t\t\tfrom /proc/kmsg.\n\n\tconsoleblank=\t[KNL] The console blank (screen saver) timeout in\n\t\t\tseconds. A value of 0 disables the blank timer.\n\t\t\tDefaults to 0.\n\n\tcoredump_filter=\n\t\t\t[KNL] Change the default value for\n\t\t\t/proc/<pid>/coredump_filter.\n\t\t\tSee also Documentation/filesystems/proc.rst.\n\n\tcoresight_cpu_debug.enable\n\t\t\t[ARM,ARM64]\n\t\t\tFormat: <bool>\n\t\t\tEnable/disable the CPU sampling based debugging.\n\t\t\t0: default value, disable debugging\n\t\t\t1: enable debugging at boot time\n\n\tcpuidle.off=1\t[CPU_IDLE]\n\t\t\tdisable the cpuidle sub-system\n\n\tcpuidle.governor=\n\t\t\t[CPU_IDLE] Name of the cpuidle governor to use.\n\n\tcpufreq.off=1\t[CPU_FREQ]\n\t\t\tdisable the cpufreq sub-system\n\n\tcpufreq.default_governor=\n\t\t\t[CPU_FREQ] Name of the default cpufreq governor or\n\t\t\tpolicy to use. This governor must be registered in the\n\t\t\tkernel before the cpufreq driver probes.\n\n\tcpu_init_udelay=N\n\t\t\t[X86] Delay for N microsec between assert and de-assert\n\t\t\tof APIC INIT to start processors.  This delay occurs\n\t\t\ton every CPU online, such as boot, and resume from suspend.\n\t\t\tDefault: 10000\n\n\tcpcihp_generic=\t[HW,PCI] Generic port I/O CompactPCI driver\n\t\t\tFormat:\n\t\t\t<first_slot>,<last_slot>,<port>,<enum_bit>[,<debug>]\n\n\tcrashkernel=size[KMG][@offset[KMG]]\n\t\t\t[KNL] Using kexec, Linux can switch to a 'crash kernel'\n\t\t\tupon panic. This parameter reserves the physical\n\t\t\tmemory region [offset, offset + size] for that kernel\n\t\t\timage. If '@offset' is omitted, then a suitable offset\n\t\t\tis selected automatically.\n\t\t\t[KNL, X86-64] Select a region under 4G first, and\n\t\t\tfall back to reserve region above 4G when '@offset'\n\t\t\thasn't been specified.\n\t\t\tSee Documentation/admin-guide/kdump/kdump.rst for further details.\n\n\tcrashkernel=range1:size1[,range2:size2,...][@offset]\n\t\t\t[KNL] Same as above, but depends on the memory\n\t\t\tin the running system. The syntax of range is\n\t\t\tstart-[end] where start and end are both\n\t\t\ta memory unit (amount[KMG]). See also\n\t\t\tDocumentation/admin-guide/kdump/kdump.rst for an example.\n\n\tcrashkernel=size[KMG],high\n\t\t\t[KNL, X86-64] range could be above 4G. Allow kernel\n\t\t\tto allocate physical memory region from top, so could\n\t\t\tbe above 4G if system have more than 4G ram installed.\n\t\t\tOtherwise memory region will be allocated below 4G, if\n\t\t\tavailable.\n\t\t\tIt will be ignored if crashkernel=X is specified.\n\tcrashkernel=size[KMG],low\n\t\t\t[KNL, X86-64] range under 4G. When crashkernel=X,high\n\t\t\tis passed, kernel could allocate physical memory region\n\t\t\tabove 4G, that cause second kernel crash on system\n\t\t\tthat require some amount of low memory, e.g. swiotlb\n\t\t\trequires at least 64M+32K low memory, also enough extra\n\t\t\tlow memory is needed to make sure DMA buffers for 32-bit\n\t\t\tdevices won't run out. Kernel would try to allocate at\n\t\t\tat least 256M below 4G automatically.\n\t\t\tThis one let user to specify own low range under 4G\n\t\t\tfor second kernel instead.\n\t\t\t0: to disable low allocation.\n\t\t\tIt will be ignored when crashkernel=X,high is not used\n\t\t\tor memory reserved is below 4G.\n\n\tcryptomgr.notests\n\t\t\t[KNL] Disable crypto self-tests\n\n\tcs89x0_dma=\t[HW,NET]\n\t\t\tFormat: <dma>\n\n\tcs89x0_media=\t[HW,NET]\n\t\t\tFormat: { rj45 | aui | bnc }\n\n\tdasd=\t\t[HW,NET]\n\t\t\tSee header of drivers/s390/block/dasd_devmap.c.\n\n\tdb9.dev[2|3]=\t[HW,JOY] Multisystem joystick support via parallel port\n\t\t\t(one device per port)\n\t\t\tFormat: <port#>,<type>\n\t\t\tSee also Documentation/input/devices/joystick-parport.rst\n\n\tddebug_query=\t[KNL,DYNAMIC_DEBUG] Enable debug messages at early boot\n\t\t\ttime. See\n\t\t\tDocumentation/admin-guide/dynamic-debug-howto.rst for\n\t\t\tdetails.  Deprecated, see dyndbg.\n\n\tdebug\t\t[KNL] Enable kernel debugging (events log level).\n\n\tdebug_boot_weak_hash\n\t\t\t[KNL] Enable printing [hashed] pointers early in the\n\t\t\tboot sequence.  If enabled, we use a weak hash instead\n\t\t\tof siphash to hash pointers.  Use this option if you are\n\t\t\tseeing instances of '(___ptrval___)') and need to see a\n\t\t\tvalue (hashed pointer) instead. Cryptographically\n\t\t\tinsecure, please do not use on production kernels.\n\n\tdebug_locks_verbose=\n\t\t\t[KNL] verbose self-tests\n\t\t\tFormat=<0|1>\n\t\t\tPrint debugging info while doing the locking API\n\t\t\tself-tests.\n\t\t\tWe default to 0 (no extra messages), setting it to\n\t\t\t1 will print _a lot_ more information - normally\n\t\t\tonly useful to kernel developers.\n\n\tdebug_objects\t[KNL] Enable object debugging\n\n\tno_debug_objects\n\t\t\t[KNL] Disable object debugging\n\n\tdebug_guardpage_minorder=\n\t\t\t[KNL] When CONFIG_DEBUG_PAGEALLOC is set, this\n\t\t\tparameter allows control of the order of pages that will\n\t\t\tbe intentionally kept free (and hence protected) by the\n\t\t\tbuddy allocator. Bigger value increase the probability\n\t\t\tof catching random memory corruption, but reduce the\n\t\t\tamount of memory for normal system use. The maximum\n\t\t\tpossible value is MAX_ORDER/2.  Setting this parameter\n\t\t\tto 1 or 2 should be enough to identify most random\n\t\t\tmemory corruption problems caused by bugs in kernel or\n\t\t\tdriver code when a CPU writes to (or reads from) a\n\t\t\trandom memory location. Note that there exists a class\n\t\t\tof memory corruptions problems caused by buggy H/W or\n\t\t\tF/W or by drivers badly programing DMA (basically when\n\t\t\tmemory is written at bus level and the CPU MMU is\n\t\t\tbypassed) which are not detectable by\n\t\t\tCONFIG_DEBUG_PAGEALLOC, hence this option will not help\n\t\t\ttracking down these problems.\n\n\tdebug_pagealloc=\n\t\t\t[KNL] When CONFIG_DEBUG_PAGEALLOC is set, this parameter\n\t\t\tenables the feature at boot time. By default, it is\n\t\t\tdisabled and the system will work mostly the same as a\n\t\t\tkernel built without CONFIG_DEBUG_PAGEALLOC.\n\t\t\tNote: to get most of debug_pagealloc error reports, it's\n\t\t\tuseful to also enable the page_owner functionality.\n\t\t\ton: enable the feature\n\n\tdebugfs=    \t[KNL] This parameter enables what is exposed to userspace\n\t\t\tand debugfs internal clients.\n\t\t\tFormat: { on, no-mount, off }\n\t\t\ton: \tAll functions are enabled.\n\t\t\tno-mount:\n\t\t\t\tFilesystem is not registered but kernel clients can\n\t\t\t        access APIs and a crashkernel can be used to read\n\t\t\t\tits content. There is nothing to mount.\n\t\t\toff: \tFilesystem is not registered and clients\n\t\t\t        get a -EPERM as result when trying to register files\n\t\t\t\tor directories within debugfs.\n\t\t\t\tThis is equivalent of the runtime functionality if\n\t\t\t\tdebugfs was not enabled in the kernel at all.\n\t\t\tDefault value is set in build-time with a kernel configuration.\n\n\tdebugpat\t[X86] Enable PAT debugging\n\n\tdecnet.addr=\t[HW,NET]\n\t\t\tFormat: <area>[,<node>]\n\t\t\tSee also Documentation/networking/decnet.rst.\n\n\tdefault_hugepagesz=\n\t\t\t[HW] The size of the default HugeTLB page. This is\n\t\t\tthe size represented by the legacy /proc/ hugepages\n\t\t\tAPIs.  In addition, this is the default hugetlb size\n\t\t\tused for shmget(), mmap() and mounting hugetlbfs\n\t\t\tfilesystems.  If not specified, defaults to the\n\t\t\tarchitecture's default huge page size.  Huge page\n\t\t\tsizes are architecture dependent.  See also\n\t\t\tDocumentation/admin-guide/mm/hugetlbpage.rst.\n\t\t\tFormat: size[KMG]\n\n\tdeferred_probe_timeout=\n\t\t\t[KNL] Debugging option to set a timeout in seconds for\n\t\t\tdeferred probe to give up waiting on dependencies to\n\t\t\tprobe. Only specific dependencies (subsystems or\n\t\t\tdrivers) that have opted in will be ignored. A timeout of 0\n\t\t\twill timeout at the end of initcalls. This option will also\n\t\t\tdump out devices still on the deferred probe list after\n\t\t\tretrying.\n\n\tdfltcc=\t\t[HW,S390]\n\t\t\tFormat: { on | off | def_only | inf_only | always }\n\t\t\ton:       s390 zlib hardware support for compression on\n\t\t\t          level 1 and decompression (default)\n\t\t\toff:      No s390 zlib hardware support\n\t\t\tdef_only: s390 zlib hardware support for deflate\n\t\t\t          only (compression on level 1)\n\t\t\tinf_only: s390 zlib hardware support for inflate\n\t\t\t          only (decompression)\n\t\t\talways:   Same as 'on' but ignores the selected compression\n\t\t\t          level always using hardware support (used for debugging)\n\n\tdhash_entries=\t[KNL]\n\t\t\tSet number of hash buckets for dentry cache.\n\n\tdisable_1tb_segments [PPC]\n\t\t\tDisables the use of 1TB hash page table segments. This\n\t\t\tcauses the kernel to fall back to 256MB segments which\n\t\t\tcan be useful when debugging issues that require an SLB\n\t\t\tmiss to occur.\n\n\tstress_slb\t[PPC]\n\t\t\tLimits the number of kernel SLB entries, and flushes\n\t\t\tthem frequently to increase the rate of SLB faults\n\t\t\ton kernel addresses.\n\n\tdisable=\t[IPV6]\n\t\t\tSee Documentation/networking/ipv6.rst.\n\n\thardened_usercopy=\n                        [KNL] Under CONFIG_HARDENED_USERCOPY, whether\n                        hardening is enabled for this boot. Hardened\n                        usercopy checking is used to protect the kernel\n                        from reading or writing beyond known memory\n                        allocation boundaries as a proactive defense\n                        against bounds-checking flaws in the kernel's\n                        copy_to_user()/copy_from_user() interface.\n                on      Perform hardened usercopy checks (default).\n                off     Disable hardened usercopy checks.\n\n\tdisable_radix\t[PPC]\n\t\t\tDisable RADIX MMU mode on POWER9\n\n\tradix_hcall_invalidate=on  [PPC/PSERIES]\n\t\t\tDisable RADIX GTSE feature and use hcall for TLB\n\t\t\tinvalidate.\n\n\tdisable_tlbie\t[PPC]\n\t\t\tDisable TLBIE instruction. Currently does not work\n\t\t\twith KVM, with HASH MMU, or with coherent accelerators.\n\n\tdisable_cpu_apicid= [X86,APIC,SMP]\n\t\t\tFormat: <int>\n\t\t\tThe number of initial APIC ID for the\n\t\t\tcorresponding CPU to be disabled at boot,\n\t\t\tmostly used for the kdump 2nd kernel to\n\t\t\tdisable BSP to wake up multiple CPUs without\n\t\t\tcausing system reset or hang due to sending\n\t\t\tINIT from AP to BSP.\n\n\tperf_v4_pmi=\t[X86,INTEL]\n\t\t\tFormat: <bool>\n\t\t\tDisable Intel PMU counter freezing feature.\n\t\t\tThe feature only exists starting from\n\t\t\tArch Perfmon v4 (Skylake and newer).\n\n\tdisable_ddw\t[PPC/PSERIES]\n\t\t\tDisable Dynamic DMA Window support. Use this if\n\t\t\tto workaround buggy firmware.\n\n\tdisable_ipv6=\t[IPV6]\n\t\t\tSee Documentation/networking/ipv6.rst.\n\n\tdisable_mtrr_cleanup [X86]\n\t\t\tThe kernel tries to adjust MTRR layout from continuous\n\t\t\tto discrete, to make X server driver able to add WB\n\t\t\tentry later. This parameter disables that.\n\n\tdisable_mtrr_trim [X86, Intel and AMD only]\n\t\t\tBy default the kernel will trim any uncacheable\n\t\t\tmemory out of your available memory pool based on\n\t\t\tMTRR settings.  This parameter disables that behavior,\n\t\t\tpossibly causing your machine to run very slowly.\n\n\tdisable_timer_pin_1 [X86]\n\t\t\tDisable PIN 1 of APIC timer\n\t\t\tCan be useful to work around chipset bugs.\n\n\tdis_ucode_ldr\t[X86] Disable the microcode loader.\n\n\tdma_debug=off\tIf the kernel is compiled with DMA_API_DEBUG support,\n\t\t\tthis option disables the debugging code at boot.\n\n\tdma_debug_entries=<number>\n\t\t\tThis option allows to tune the number of preallocated\n\t\t\tentries for DMA-API debugging code. One entry is\n\t\t\trequired per DMA-API allocation. Use this if the\n\t\t\tDMA-API debugging code disables itself because the\n\t\t\tarchitectural default is too low.\n\n\tdma_debug_driver=<driver_name>\n\t\t\tWith this option the DMA-API debugging driver\n\t\t\tfilter feature can be enabled at boot time. Just\n\t\t\tpass the driver to filter for as the parameter.\n\t\t\tThe filter can be disabled or changed to another\n\t\t\tdriver later using sysfs.\n\n\tdriver_async_probe=  [KNL]\n\t\t\tList of driver names to be probed asynchronously.\n\t\t\tFormat: <driver_name1>,<driver_name2>...\n\n\tdrm.edid_firmware=[<connector>:]<file>[,[<connector>:]<file>]\n\t\t\tBroken monitors, graphic adapters, KVMs and EDIDless\n\t\t\tpanels may send no or incorrect EDID data sets.\n\t\t\tThis parameter allows to specify an EDID data sets\n\t\t\tin the /lib/firmware directory that are used instead.\n\t\t\tGeneric built-in EDID data sets are used, if one of\n\t\t\tedid/1024x768.bin, edid/1280x1024.bin,\n\t\t\tedid/1680x1050.bin, or edid/1920x1080.bin is given\n\t\t\tand no file with the same name exists. Details and\n\t\t\tinstructions how to build your own EDID data are\n\t\t\tavailable in Documentation/admin-guide/edid.rst. An EDID\n\t\t\tdata set will only be used for a particular connector,\n\t\t\tif its name and a colon are prepended to the EDID\n\t\t\tname. Each connector may use a unique EDID data\n\t\t\tset by separating the files with a comma.  An EDID\n\t\t\tdata set with no connector name will be used for\n\t\t\tany connectors not explicitly specified.\n\n\tdscc4.setup=\t[NET]\n\n\tdt_cpu_ftrs=\t[PPC]\n\t\t\tFormat: {\"off\" | \"known\"}\n\t\t\tControl how the dt_cpu_ftrs device-tree binding is\n\t\t\tused for CPU feature discovery and setup (if it\n\t\t\texists).\n\t\t\toff: Do not use it, fall back to legacy cpu table.\n\t\t\tknown: Do not pass through unknown features to guests\n\t\t\tor userspace, only those that the kernel is aware of.\n\n\tdump_apple_properties\t[X86]\n\t\t\tDump name and content of EFI device properties on\n\t\t\tx86 Macs.  Useful for driver authors to determine\n\t\t\twhat data is available or for reverse-engineering.\n\n\tdyndbg[=\"val\"]\t\t[KNL,DYNAMIC_DEBUG]\n\tmodule.dyndbg[=\"val\"]\n\t\t\tEnable debug messages at boot time.  See\n\t\t\tDocumentation/admin-guide/dynamic-debug-howto.rst\n\t\t\tfor details.\n\n\tnopku\t\t[X86] Disable Memory Protection Keys CPU feature found\n\t\t\tin some Intel CPUs.\n\n\tmodule.async_probe [KNL]\n\t\t\tEnable asynchronous probe on this module.\n\n\tearly_ioremap_debug [KNL]\n\t\t\tEnable debug messages in early_ioremap support. This\n\t\t\tis useful for tracking down temporary early mappings\n\t\t\twhich are not unmapped.\n\n\tearlycon=\t[KNL] Output early console device and options.\n\n\t\t\tWhen used with no options, the early console is\n\t\t\tdetermined by stdout-path property in device tree's\n\t\t\tchosen node or the ACPI SPCR table if supported by\n\t\t\tthe platform.\n\n\t\tcdns,<addr>[,options]\n\t\t\tStart an early, polled-mode console on a Cadence\n\t\t\t(xuartps) serial port at the specified address. Only\n\t\t\tsupported option is baud rate. If baud rate is not\n\t\t\tspecified, the serial port must already be setup and\n\t\t\tconfigured.\n\n\t\tuart[8250],io,<addr>[,options]\n\t\tuart[8250],mmio,<addr>[,options]\n\t\tuart[8250],mmio32,<addr>[,options]\n\t\tuart[8250],mmio32be,<addr>[,options]\n\t\tuart[8250],0x<addr>[,options]\n\t\t\tStart an early, polled-mode console on the 8250/16550\n\t\t\tUART at the specified I/O port or MMIO address.\n\t\t\tMMIO inter-register address stride is either 8-bit\n\t\t\t(mmio) or 32-bit (mmio32 or mmio32be).\n\t\t\tIf none of [io|mmio|mmio32|mmio32be], <addr> is assumed\n\t\t\tto be equivalent to 'mmio'. 'options' are specified\n\t\t\tin the same format described for \"console=ttyS<n>\"; if\n\t\t\tunspecified, the h/w is not initialized.\n\n\t\tpl011,<addr>\n\t\tpl011,mmio32,<addr>\n\t\t\tStart an early, polled-mode console on a pl011 serial\n\t\t\tport at the specified address. The pl011 serial port\n\t\t\tmust already be setup and configured. Options are not\n\t\t\tyet supported.  If 'mmio32' is specified, then only\n\t\t\tthe driver will use only 32-bit accessors to read/write\n\t\t\tthe device registers.\n\n\t\tmeson,<addr>\n\t\t\tStart an early, polled-mode console on a meson serial\n\t\t\tport at the specified address. The serial port must\n\t\t\talready be setup and configured. Options are not yet\n\t\t\tsupported.\n\n\t\tmsm_serial,<addr>\n\t\t\tStart an early, polled-mode console on an msm serial\n\t\t\tport at the specified address. The serial port\n\t\t\tmust already be setup and configured. Options are not\n\t\t\tyet supported.\n\n\t\tmsm_serial_dm,<addr>\n\t\t\tStart an early, polled-mode console on an msm serial\n\t\t\tdm port at the specified address. The serial port\n\t\t\tmust already be setup and configured. Options are not\n\t\t\tyet supported.\n\n\t\towl,<addr>\n\t\t\tStart an early, polled-mode console on a serial port\n\t\t\tof an Actions Semi SoC, such as S500 or S900, at the\n\t\t\tspecified address. The serial port must already be\n\t\t\tsetup and configured. Options are not yet supported.\n\n\t\trda,<addr>\n\t\t\tStart an early, polled-mode console on a serial port\n\t\t\tof an RDA Micro SoC, such as RDA8810PL, at the\n\t\t\tspecified address. The serial port must already be\n\t\t\tsetup and configured. Options are not yet supported.\n\n\t\tsbi\n\t\t\tUse RISC-V SBI (Supervisor Binary Interface) for early\n\t\t\tconsole.\n\n\t\tsmh\tUse ARM semihosting calls for early console.\n\n\t\ts3c2410,<addr>\n\t\ts3c2412,<addr>\n\t\ts3c2440,<addr>\n\t\ts3c6400,<addr>\n\t\ts5pv210,<addr>\n\t\texynos4210,<addr>\n\t\t\tUse early console provided by serial driver available\n\t\t\ton Samsung SoCs, requires selecting proper type and\n\t\t\ta correct base address of the selected UART port. The\n\t\t\tserial port must already be setup and configured.\n\t\t\tOptions are not yet supported.\n\n\t\tlantiq,<addr>\n\t\t\tStart an early, polled-mode console on a lantiq serial\n\t\t\t(lqasc) port at the specified address. The serial port\n\t\t\tmust already be setup and configured. Options are not\n\t\t\tyet supported.\n\n\t\tlpuart,<addr>\n\t\tlpuart32,<addr>\n\t\t\tUse early console provided by Freescale LP UART driver\n\t\t\tfound on Freescale Vybrid and QorIQ LS1021A processors.\n\t\t\tA valid base address must be provided, and the serial\n\t\t\tport must already be setup and configured.\n\n\t\tec_imx21,<addr>\n\t\tec_imx6q,<addr>\n\t\t\tStart an early, polled-mode, output-only console on the\n\t\t\tFreescale i.MX UART at the specified address. The UART\n\t\t\tmust already be setup and configured.\n\n\t\tar3700_uart,<addr>\n\t\t\tStart an early, polled-mode console on the\n\t\t\tArmada 3700 serial port at the specified\n\t\t\taddress. The serial port must already be setup\n\t\t\tand configured. Options are not yet supported.\n\n\t\tqcom_geni,<addr>\n\t\t\tStart an early, polled-mode console on a Qualcomm\n\t\t\tGeneric Interface (GENI) based serial port at the\n\t\t\tspecified address. The serial port must already be\n\t\t\tsetup and configured. Options are not yet supported.\n\n\t\tefifb,[options]\n\t\t\tStart an early, unaccelerated console on the EFI\n\t\t\tmemory mapped framebuffer (if available). On cache\n\t\t\tcoherent non-x86 systems that use system memory for\n\t\t\tthe framebuffer, pass the 'ram' option so that it is\n\t\t\tmapped with the correct attributes.\n\n\t\tlinflex,<addr>\n\t\t\tUse early console provided by Freescale LINFlexD UART\n\t\t\tserial driver for NXP S32V234 SoCs. A valid base\n\t\t\taddress must be provided, and the serial port must\n\t\t\talready be setup and configured.\n\n\tearlyprintk=\t[X86,SH,ARM,M68k,S390]\n\t\t\tearlyprintk=vga\n\t\t\tearlyprintk=sclp\n\t\t\tearlyprintk=xen\n\t\t\tearlyprintk=serial[,ttySn[,baudrate]]\n\t\t\tearlyprintk=serial[,0x...[,baudrate]]\n\t\t\tearlyprintk=ttySn[,baudrate]\n\t\t\tearlyprintk=dbgp[debugController#]\n\t\t\tearlyprintk=pciserial[,force],bus:device.function[,baudrate]\n\t\t\tearlyprintk=xdbc[xhciController#]\n\n\t\t\tearlyprintk is useful when the kernel crashes before\n\t\t\tthe normal console is initialized. It is not enabled by\n\t\t\tdefault because it has some cosmetic problems.\n\n\t\t\tAppend \",keep\" to not disable it when the real console\n\t\t\ttakes over.\n\n\t\t\tOnly one of vga, efi, serial, or usb debug port can\n\t\t\tbe used at a time.\n\n\t\t\tCurrently only ttyS0 and ttyS1 may be specified by\n\t\t\tname.  Other I/O ports may be explicitly specified\n\t\t\ton some architectures (x86 and arm at least) by\n\t\t\treplacing ttySn with an I/O port address, like this:\n\t\t\t\tearlyprintk=serial,0x1008,115200\n\t\t\tYou can find the port for a given device in\n\t\t\t/proc/tty/driver/serial:\n\t\t\t\t2: uart:ST16650V2 port:00001008 irq:18 ...\n\n\t\t\tInteraction with the standard serial driver is not\n\t\t\tvery good.\n\n\t\t\tThe VGA and EFI output is eventually overwritten by\n\t\t\tthe real console.\n\n\t\t\tThe xen output can only be used by Xen PV guests.\n\n\t\t\tThe sclp output can only be used on s390.\n\n\t\t\tThe optional \"force\" to \"pciserial\" enables use of a\n\t\t\tPCI device even when its classcode is not of the\n\t\t\tUART class.\n\n\tedac_report=\t[HW,EDAC] Control how to report EDAC event\n\t\t\tFormat: {\"on\" | \"off\" | \"force\"}\n\t\t\ton: enable EDAC to report H/W event. May be overridden\n\t\t\tby other higher priority error reporting module.\n\t\t\toff: disable H/W event reporting through EDAC.\n\t\t\tforce: enforce the use of EDAC to report H/W event.\n\t\t\tdefault: on.\n\n\tekgdboc=\t[X86,KGDB] Allow early kernel console debugging\n\t\t\tekgdboc=kbd\n\n\t\t\tThis is designed to be used in conjunction with\n\t\t\tthe boot argument: earlyprintk=vga\n\n\t\t\tThis parameter works in place of the kgdboc parameter\n\t\t\tbut can only be used if the backing tty is available\n\t\t\tvery early in the boot process. For early debugging\n\t\t\tvia a serial port see kgdboc_earlycon instead.\n\n\tedd=\t\t[EDD]\n\t\t\tFormat: {\"off\" | \"on\" | \"skip[mbr]\"}\n\n\tefi=\t\t[EFI]\n\t\t\tFormat: { \"debug\", \"disable_early_pci_dma\",\n\t\t\t\t  \"nochunk\", \"noruntime\", \"nosoftreserve\",\n\t\t\t\t  \"novamap\", \"no_disable_early_pci_dma\" }\n\t\t\tdebug: enable misc debug output.\n\t\t\tdisable_early_pci_dma: disable the busmaster bit on all\n\t\t\tPCI bridges while in the EFI boot stub.\n\t\t\tnochunk: disable reading files in \"chunks\" in the EFI\n\t\t\tboot stub, as chunking can cause problems with some\n\t\t\tfirmware implementations.\n\t\t\tnoruntime : disable EFI runtime services support\n\t\t\tnosoftreserve: The EFI_MEMORY_SP (Specific Purpose)\n\t\t\tattribute may cause the kernel to reserve the\n\t\t\tmemory range for a memory mapping driver to\n\t\t\tclaim. Specify efi=nosoftreserve to disable this\n\t\t\treservation and treat the memory by its base type\n\t\t\t(i.e. EFI_CONVENTIONAL_MEMORY / \"System RAM\").\n\t\t\tnovamap: do not call SetVirtualAddressMap().\n\t\t\tno_disable_early_pci_dma: Leave the busmaster bit set\n\t\t\ton all PCI bridges while in the EFI boot stub\n\n\tefi_no_storage_paranoia [EFI; X86]\n\t\t\tUsing this parameter you can use more than 50% of\n\t\t\tyour efi variable storage. Use this parameter only if\n\t\t\tyou are really sure that your UEFI does sane gc and\n\t\t\tfulfills the spec otherwise your board may brick.\n\n\tefi_fake_mem=\tnn[KMG]@ss[KMG]:aa[,nn[KMG]@ss[KMG]:aa,..] [EFI; X86]\n\t\t\tAdd arbitrary attribute to specific memory range by\n\t\t\tupdating original EFI memory map.\n\t\t\tRegion of memory which aa attribute is added to is\n\t\t\tfrom ss to ss+nn.\n\n\t\t\tIf efi_fake_mem=2G@4G:0x10000,2G@0x10a0000000:0x10000\n\t\t\tis specified, EFI_MEMORY_MORE_RELIABLE(0x10000)\n\t\t\tattribute is added to range 0x100000000-0x180000000 and\n\t\t\t0x10a0000000-0x1120000000.\n\n\t\t\tIf efi_fake_mem=8G@9G:0x40000 is specified, the\n\t\t\tEFI_MEMORY_SP(0x40000) attribute is added to\n\t\t\trange 0x240000000-0x43fffffff.\n\n\t\t\tUsing this parameter you can do debugging of EFI memmap\n\t\t\trelated features. For example, you can do debugging of\n\t\t\tAddress Range Mirroring feature even if your box\n\t\t\tdoesn't support it, or mark specific memory as\n\t\t\t\"soft reserved\".\n\n\tefivar_ssdt=\t[EFI; X86] Name of an EFI variable that contains an SSDT\n\t\t\tthat is to be dynamically loaded by Linux. If there are\n\t\t\tmultiple variables with the same name but with different\n\t\t\tvendor GUIDs, all of them will be loaded. See\n\t\t\tDocumentation/admin-guide/acpi/ssdt-overlays.rst for details.\n\n\n\teisa_irq_edge=\t[PARISC,HW]\n\t\t\tSee header of drivers/parisc/eisa.c.\n\n\telanfreq=\t[X86-32]\n\t\t\tSee comment before function elanfreq_setup() in\n\t\t\tarch/x86/kernel/cpu/cpufreq/elanfreq.c.\n\n\telfcorehdr=[size[KMG]@]offset[KMG] [IA64,PPC,SH,X86,S390]\n\t\t\tSpecifies physical address of start of kernel core\n\t\t\timage elf header and optionally the size. Generally\n\t\t\tkexec loader will pass this option to capture kernel.\n\t\t\tSee Documentation/admin-guide/kdump/kdump.rst for details.\n\n\tenable_mtrr_cleanup [X86]\n\t\t\tThe kernel tries to adjust MTRR layout from continuous\n\t\t\tto discrete, to make X server driver able to add WB\n\t\t\tentry later. This parameter enables that.\n\n\tenable_timer_pin_1 [X86]\n\t\t\tEnable PIN 1 of APIC timer\n\t\t\tCan be useful to work around chipset bugs\n\t\t\t(in particular on some ATI chipsets).\n\t\t\tThe kernel tries to set a reasonable default.\n\n\tenforcing\t[SELINUX] Set initial enforcing status.\n\t\t\tFormat: {\"0\" | \"1\"}\n\t\t\tSee security/selinux/Kconfig help text.\n\t\t\t0 -- permissive (log only, no denials).\n\t\t\t1 -- enforcing (deny and log).\n\t\t\tDefault value is 0.\n\t\t\tValue can be changed at runtime via\n\t\t\t/sys/fs/selinux/enforce.\n\n\terst_disable\t[ACPI]\n\t\t\tDisable Error Record Serialization Table (ERST)\n\t\t\tsupport.\n\n\tether=\t\t[HW,NET] Ethernet cards parameters\n\t\t\tThis option is obsoleted by the \"netdev=\" option, which\n\t\t\thas equivalent usage. See its documentation for details.\n\n\tevm=\t\t[EVM]\n\t\t\tFormat: { \"fix\" }\n\t\t\tPermit 'security.evm' to be updated regardless of\n\t\t\tcurrent integrity status.\n\n\tfailslab=\n\tfail_page_alloc=\n\tfail_make_request=[KNL]\n\t\t\tGeneral fault injection mechanism.\n\t\t\tFormat: <interval>,<probability>,<space>,<times>\n\t\t\tSee also Documentation/fault-injection/.\n\n\tfloppy=\t\t[HW]\n\t\t\tSee Documentation/admin-guide/blockdev/floppy.rst.\n\n\tforce_pal_cache_flush\n\t\t\t[IA-64] Avoid check_sal_cache_flush which may hang on\n\t\t\tbuggy SAL_CACHE_FLUSH implementations. Using this\n\t\t\tparameter will force ia64_sal_cache_flush to call\n\t\t\tia64_pal_cache_flush instead of SAL_CACHE_FLUSH.\n\n\tforcepae\t[X86-32]\n\t\t\tForcefully enable Physical Address Extension (PAE).\n\t\t\tMany Pentium M systems disable PAE but may have a\n\t\t\tfunctionally usable PAE implementation.\n\t\t\tWarning: use of this parameter will taint the kernel\n\t\t\tand may cause unknown problems.\n\n\tftrace=[tracer]\n\t\t\t[FTRACE] will set and start the specified tracer\n\t\t\tas early as possible in order to facilitate early\n\t\t\tboot debugging.\n\n\tftrace_dump_on_oops[=orig_cpu]\n\t\t\t[FTRACE] will dump the trace buffers on oops.\n\t\t\tIf no parameter is passed, ftrace will dump\n\t\t\tbuffers of all CPUs, but if you pass orig_cpu, it will\n\t\t\tdump only the buffer of the CPU that triggered the\n\t\t\toops.\n\n\tftrace_filter=[function-list]\n\t\t\t[FTRACE] Limit the functions traced by the function\n\t\t\ttracer at boot up. function-list is a comma separated\n\t\t\tlist of functions. This list can be changed at run\n\t\t\ttime by the set_ftrace_filter file in the debugfs\n\t\t\ttracing directory.\n\n\tftrace_notrace=[function-list]\n\t\t\t[FTRACE] Do not trace the functions specified in\n\t\t\tfunction-list. This list can be changed at run time\n\t\t\tby the set_ftrace_notrace file in the debugfs\n\t\t\ttracing directory.\n\n\tftrace_graph_filter=[function-list]\n\t\t\t[FTRACE] Limit the top level callers functions traced\n\t\t\tby the function graph tracer at boot up.\n\t\t\tfunction-list is a comma separated list of functions\n\t\t\tthat can be changed at run time by the\n\t\t\tset_graph_function file in the debugfs tracing directory.\n\n\tftrace_graph_notrace=[function-list]\n\t\t\t[FTRACE] Do not trace from the functions specified in\n\t\t\tfunction-list.  This list is a comma separated list of\n\t\t\tfunctions that can be changed at run time by the\n\t\t\tset_graph_notrace file in the debugfs tracing directory.\n\n\tftrace_graph_max_depth=<uint>\n\t\t\t[FTRACE] Used with the function graph tracer. This is\n\t\t\tthe max depth it will trace into a function. This value\n\t\t\tcan be changed at run time by the max_graph_depth file\n\t\t\tin the tracefs tracing directory. default: 0 (no limit)\n\n\tfw_devlink=\t[KNL] Create device links between consumer and supplier\n\t\t\tdevices by scanning the firmware to infer the\n\t\t\tconsumer/supplier relationships. This feature is\n\t\t\tespecially useful when drivers are loaded as modules as\n\t\t\tit ensures proper ordering of tasks like device probing\n\t\t\t(suppliers first, then consumers), supplier boot state\n\t\t\tclean up (only after all consumers have probed),\n\t\t\tsuspend/resume & runtime PM (consumers first, then\n\t\t\tsuppliers).\n\t\t\tFormat: { off | permissive | on | rpm }\n\t\t\toff --\tDon't create device links from firmware info.\n\t\t\tpermissive -- Create device links from firmware info\n\t\t\t\tbut use it only for ordering boot state clean\n\t\t\t\tup (sync_state() calls).\n\t\t\ton -- \tCreate device links from firmware info and use it\n\t\t\t\tto enforce probe and suspend/resume ordering.\n\t\t\trpm --\tLike \"on\", but also use to order runtime PM.\n\n\tgamecon.map[2|3]=\n\t\t\t[HW,JOY] Multisystem joystick and NES/SNES/PSX pad\n\t\t\tsupport via parallel port (up to 5 devices per port)\n\t\t\tFormat: <port#>,<pad1>,<pad2>,<pad3>,<pad4>,<pad5>\n\t\t\tSee also Documentation/input/devices/joystick-parport.rst\n\n\tgamma=\t\t[HW,DRM]\n\n\tgart_fix_e820=\t[X86-64] disable the fix e820 for K8 GART\n\t\t\tFormat: off | on\n\t\t\tdefault: on\n\n\tgcov_persist=\t[GCOV] When non-zero (default), profiling data for\n\t\t\tkernel modules is saved and remains accessible via\n\t\t\tdebugfs, even when the module is unloaded/reloaded.\n\t\t\tWhen zero, profiling data is discarded and associated\n\t\t\tdebugfs files are removed at module unload time.\n\n\tgoldfish\t[X86] Enable the goldfish android emulator platform.\n\t\t\tDon't use this when you are not running on the\n\t\t\tandroid emulator\n\n\tgpt\t\t[EFI] Forces disk with valid GPT signature but\n\t\t\tinvalid Protective MBR to be treated as GPT. If the\n\t\t\tprimary GPT is corrupted, it enables the backup/alternate\n\t\t\tGPT to be used instead.\n\n\tgrcan.enable0=\t[HW] Configuration of physical interface 0. Determines\n\t\t\tthe \"Enable 0\" bit of the configuration register.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault: 0\n\tgrcan.enable1=\t[HW] Configuration of physical interface 1. Determines\n\t\t\tthe \"Enable 0\" bit of the configuration register.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault: 0\n\tgrcan.select=\t[HW] Select which physical interface to use.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault: 0\n\tgrcan.txsize=\t[HW] Sets the size of the tx buffer.\n\t\t\tFormat: <unsigned int> such that (txsize & ~0x1fffc0) == 0.\n\t\t\tDefault: 1024\n\tgrcan.rxsize=\t[HW] Sets the size of the rx buffer.\n\t\t\tFormat: <unsigned int> such that (rxsize & ~0x1fffc0) == 0.\n\t\t\tDefault: 1024\n\n\tgpio-mockup.gpio_mockup_ranges\n\t\t\t[HW] Sets the ranges of gpiochip of for this device.\n\t\t\tFormat: <start1>,<end1>,<start2>,<end2>...\n\n\thardlockup_all_cpu_backtrace=\n\t\t\t[KNL] Should the hard-lockup detector generate\n\t\t\tbacktraces on all cpus.\n\t\t\tFormat: 0 | 1\n\n\thashdist=\t[KNL,NUMA] Large hashes allocated during boot\n\t\t\tare distributed across NUMA nodes.  Defaults on\n\t\t\tfor 64-bit NUMA, off otherwise.\n\t\t\tFormat: 0 | 1 (for off | on)\n\n\thcl=\t\t[IA-64] SGI's Hardware Graph compatibility layer\n\n\thd=\t\t[EIDE] (E)IDE hard drive subsystem geometry\n\t\t\tFormat: <cyl>,<head>,<sect>\n\n\thest_disable\t[ACPI]\n\t\t\tDisable Hardware Error Source Table (HEST) support;\n\t\t\tcorresponding firmware-first mode error processing\n\t\t\tlogic will be disabled.\n\n\thighmem=nn[KMG]\t[KNL,BOOT] forces the highmem zone to have an exact\n\t\t\tsize of <nn>. This works even on boxes that have no\n\t\t\thighmem otherwise. This also works to reduce highmem\n\t\t\tsize on bigger boxes.\n\n\thighres=\t[KNL] Enable/disable high resolution timer mode.\n\t\t\tValid parameters: \"on\", \"off\"\n\t\t\tDefault: \"on\"\n\n\thlt\t\t[BUGS=ARM,SH]\n\n\thpet=\t\t[X86-32,HPET] option to control HPET usage\n\t\t\tFormat: { enable (default) | disable | force |\n\t\t\t\tverbose }\n\t\t\tdisable: disable HPET and use PIT instead\n\t\t\tforce: allow force enabled of undocumented chips (ICH4,\n\t\t\t\tVIA, nVidia)\n\t\t\tverbose: show contents of HPET registers during setup\n\n\thpet_mmap=\t[X86, HPET_MMAP] Allow userspace to mmap HPET\n\t\t\tregisters.  Default set by CONFIG_HPET_MMAP_DEFAULT.\n\n\thugetlb_cma=\t[HW] The size of a cma area used for allocation\n\t\t\tof gigantic hugepages.\n\t\t\tFormat: nn[KMGTPE]\n\n\t\t\tReserve a cma area of given size and allocate gigantic\n\t\t\thugepages using the cma allocator. If enabled, the\n\t\t\tboot-time allocation of gigantic hugepages is skipped.\n\n\thugepages=\t[HW] Number of HugeTLB pages to allocate at boot.\n\t\t\tIf this follows hugepagesz (below), it specifies\n\t\t\tthe number of pages of hugepagesz to be allocated.\n\t\t\tIf this is the first HugeTLB parameter on the command\n\t\t\tline, it specifies the number of pages to allocate for\n\t\t\tthe default huge page size.  See also\n\t\t\tDocumentation/admin-guide/mm/hugetlbpage.rst.\n\t\t\tFormat: <integer>\n\n\thugepagesz=\n\t\t\t[HW] The size of the HugeTLB pages.  This is used in\n\t\t\tconjunction with hugepages (above) to allocate huge\n\t\t\tpages of a specific size at boot.  The pair\n\t\t\thugepagesz=X hugepages=Y can be specified once for\n\t\t\teach supported huge page size. Huge page sizes are\n\t\t\tarchitecture dependent.  See also\n\t\t\tDocumentation/admin-guide/mm/hugetlbpage.rst.\n\t\t\tFormat: size[KMG]\n\n\thung_task_panic=\n\t\t\t[KNL] Should the hung task detector generate panics.\n\t\t\tFormat: 0 | 1\n\n\t\t\tA value of 1 instructs the kernel to panic when a\n\t\t\thung task is detected. The default value is controlled\n\t\t\tby the CONFIG_BOOTPARAM_HUNG_TASK_PANIC build-time\n\t\t\toption. The value selected by this boot parameter can\n\t\t\tbe changed later by the kernel.hung_task_panic sysctl.\n\n\thvc_iucv=\t[S390]\tNumber of z/VM IUCV hypervisor console (HVC)\n\t\t\t\tterminal devices. Valid values: 0..8\n\thvc_iucv_allow=\t[S390]\tComma-separated list of z/VM user IDs.\n\t\t\t\tIf specified, z/VM IUCV HVC accepts connections\n\t\t\t\tfrom listed z/VM user IDs only.\n\n\thv_nopvspin\t[X86,HYPER_V] Disables the paravirt spinlock optimizations\n\t\t\t\t      which allow the hypervisor to 'idle' the\n\t\t\t\t      guest on lock contention.\n\n\tkeep_bootcon\t[KNL]\n\t\t\tDo not unregister boot console at start. This is only\n\t\t\tuseful for debugging when something happens in the window\n\t\t\tbetween unregistering the boot console and initializing\n\t\t\tthe real console.\n\n\ti2c_bus=\t[HW]\tOverride the default board specific I2C bus speed\n\t\t\t\tor register an additional I2C bus that is not\n\t\t\t\tregistered from board initialization code.\n\t\t\t\tFormat:\n\t\t\t\t<bus_id>,<clkrate>\n\n\ti8042.debug\t[HW] Toggle i8042 debug mode\n\ti8042.unmask_kbd_data\n\t\t\t[HW] Enable printing of interrupt data from the KBD port\n\t\t\t     (disabled by default, and as a pre-condition\n\t\t\t     requires that i8042.debug=1 be enabled)\n\ti8042.direct\t[HW] Put keyboard port into non-translated mode\n\ti8042.dumbkbd\t[HW] Pretend that controller can only read data from\n\t\t\t     keyboard and cannot control its state\n\t\t\t     (Don't attempt to blink the leds)\n\ti8042.noaux\t[HW] Don't check for auxiliary (== mouse) port\n\ti8042.nokbd\t[HW] Don't check/create keyboard port\n\ti8042.noloop\t[HW] Disable the AUX Loopback command while probing\n\t\t\t     for the AUX port\n\ti8042.nomux\t[HW] Don't check presence of an active multiplexing\n\t\t\t     controller\n\ti8042.nopnp\t[HW] Don't use ACPIPnP / PnPBIOS to discover KBD/AUX\n\t\t\t     controllers\n\ti8042.notimeout\t[HW] Ignore timeout condition signalled by controller\n\ti8042.reset\t[HW] Reset the controller during init, cleanup and\n\t\t\t     suspend-to-ram transitions, only during s2r\n\t\t\t     transitions, or never reset\n\t\t\tFormat: { 1 | Y | y | 0 | N | n }\n\t\t\t1, Y, y: always reset controller\n\t\t\t0, N, n: don't ever reset controller\n\t\t\tDefault: only on s2r transitions on x86; most other\n\t\t\tarchitectures force reset to be always executed\n\ti8042.unlock\t[HW] Unlock (ignore) the keylock\n\ti8042.kbdreset\t[HW] Reset device connected to KBD port\n\n\ti810=\t\t[HW,DRM]\n\n\ti8k.ignore_dmi\t[HW] Continue probing hardware even if DMI data\n\t\t\tindicates that the driver is running on unsupported\n\t\t\thardware.\n\ti8k.force\t[HW] Activate i8k driver even if SMM BIOS signature\n\t\t\tdoes not match list of supported models.\n\ti8k.power_status\n\t\t\t[HW] Report power status in /proc/i8k\n\t\t\t(disabled by default)\n\ti8k.restricted\t[HW] Allow controlling fans only if SYS_ADMIN\n\t\t\tcapability is set.\n\n\ti915.invert_brightness=\n\t\t\t[DRM] Invert the sense of the variable that is used to\n\t\t\tset the brightness of the panel backlight. Normally a\n\t\t\tbrightness value of 0 indicates backlight switched off,\n\t\t\tand the maximum of the brightness value sets the backlight\n\t\t\tto maximum brightness. If this parameter is set to 0\n\t\t\t(default) and the machine requires it, or this parameter\n\t\t\tis set to 1, a brightness value of 0 sets the backlight\n\t\t\tto maximum brightness, and the maximum of the brightness\n\t\t\tvalue switches the backlight off.\n\t\t\t-1 -- never invert brightness\n\t\t\t 0 -- machine default\n\t\t\t 1 -- force brightness inversion\n\n\ticn=\t\t[HW,ISDN]\n\t\t\tFormat: <io>[,<membase>[,<icn_id>[,<icn_id2>]]]\n\n\tide-core.nodma=\t[HW] (E)IDE subsystem\n\t\t\tFormat: =0.0 to prevent dma on hda, =0.1 hdb =1.0 hdc\n\t\t\t.vlb_clock .pci_clock .noflush .nohpa .noprobe .nowerr\n\t\t\t.cdrom .chs .ignore_cable are additional options\n\t\t\tSee Documentation/ide/ide.rst.\n\n\tide-generic.probe-mask= [HW] (E)IDE subsystem\n\t\t\tFormat: <int>\n\t\t\tProbe mask for legacy ISA IDE ports.  Depending on\n\t\t\tplatform up to 6 ports are supported, enabled by\n\t\t\tsetting corresponding bits in the mask to 1.  The\n\t\t\tdefault value is 0x0, which has a special meaning.\n\t\t\tOn systems that have PCI, it triggers scanning the\n\t\t\tPCI bus for the first and the second port, which\n\t\t\tare then probed.  On systems without PCI the value\n\t\t\tof 0x0 enables probing the two first ports as if it\n\t\t\twas 0x3.\n\n\tide-pci-generic.all-generic-ide [HW] (E)IDE subsystem\n\t\t\tClaim all unknown PCI IDE storage controllers.\n\n\tidle=\t\t[X86]\n\t\t\tFormat: idle=poll, idle=halt, idle=nomwait\n\t\t\tPoll forces a polling idle loop that can slightly\n\t\t\timprove the performance of waking up a idle CPU, but\n\t\t\twill use a lot of power and make the system run hot.\n\t\t\tNot recommended.\n\t\t\tidle=halt: Halt is forced to be used for CPU idle.\n\t\t\tIn such case C2/C3 won't be used again.\n\t\t\tidle=nomwait: Disable mwait for CPU C-states\n\n\tieee754=\t[MIPS] Select IEEE Std 754 conformance mode\n\t\t\tFormat: { strict | legacy | 2008 | relaxed }\n\t\t\tDefault: strict\n\n\t\t\tChoose which programs will be accepted for execution\n\t\t\tbased on the IEEE 754 NaN encoding(s) supported by\n\t\t\tthe FPU and the NaN encoding requested with the value\n\t\t\tof an ELF file header flag individually set by each\n\t\t\tbinary.  Hardware implementations are permitted to\n\t\t\tsupport either or both of the legacy and the 2008 NaN\n\t\t\tencoding mode.\n\n\t\t\tAvailable settings are as follows:\n\t\t\tstrict\taccept binaries that request a NaN encoding\n\t\t\t\tsupported by the FPU\n\t\t\tlegacy\tonly accept legacy-NaN binaries, if supported\n\t\t\t\tby the FPU\n\t\t\t2008\tonly accept 2008-NaN binaries, if supported\n\t\t\t\tby the FPU\n\t\t\trelaxed\taccept any binaries regardless of whether\n\t\t\t\tsupported by the FPU\n\n\t\t\tThe FPU emulator is always able to support both NaN\n\t\t\tencodings, so if no FPU hardware is present or it has\n\t\t\tbeen disabled with 'nofpu', then the settings of\n\t\t\t'legacy' and '2008' strap the emulator accordingly,\n\t\t\t'relaxed' straps the emulator for both legacy-NaN and\n\t\t\t2008-NaN, whereas 'strict' enables legacy-NaN only on\n\t\t\tlegacy processors and both NaN encodings on MIPS32 or\n\t\t\tMIPS64 CPUs.\n\n\t\t\tThe setting for ABS.fmt/NEG.fmt instruction execution\n\t\t\tmode generally follows that for the NaN encoding,\n\t\t\texcept where unsupported by hardware.\n\n\tignore_loglevel\t[KNL]\n\t\t\tIgnore loglevel setting - this will print /all/\n\t\t\tkernel messages to the console. Useful for debugging.\n\t\t\tWe also add it as printk module parameter, so users\n\t\t\tcould change it dynamically, usually by\n\t\t\t/sys/module/printk/parameters/ignore_loglevel.\n\n\tignore_rlimit_data\n\t\t\tIgnore RLIMIT_DATA setting for data mappings,\n\t\t\tprint warning at first misuse.  Can be changed via\n\t\t\t/sys/module/kernel/parameters/ignore_rlimit_data.\n\n\tihash_entries=\t[KNL]\n\t\t\tSet number of hash buckets for inode cache.\n\n\tima_appraise=\t[IMA] appraise integrity measurements\n\t\t\tFormat: { \"off\" | \"enforce\" | \"fix\" | \"log\" }\n\t\t\tdefault: \"enforce\"\n\n\tima_appraise_tcb [IMA] Deprecated.  Use ima_policy= instead.\n\t\t\tThe builtin appraise policy appraises all files\n\t\t\towned by uid=0.\n\n\tima_canonical_fmt [IMA]\n\t\t\tUse the canonical format for the binary runtime\n\t\t\tmeasurements, instead of host native format.\n\n\tima_hash=\t[IMA]\n\t\t\tFormat: { md5 | sha1 | rmd160 | sha256 | sha384\n\t\t\t\t   | sha512 | ... }\n\t\t\tdefault: \"sha1\"\n\n\t\t\tThe list of supported hash algorithms is defined\n\t\t\tin crypto/hash_info.h.\n\n\tima_policy=\t[IMA]\n\t\t\tThe builtin policies to load during IMA setup.\n\t\t\tFormat: \"tcb | appraise_tcb | secure_boot |\n\t\t\t\t fail_securely\"\n\n\t\t\tThe \"tcb\" policy measures all programs exec'd, files\n\t\t\tmmap'd for exec, and all files opened with the read\n\t\t\tmode bit set by either the effective uid (euid=0) or\n\t\t\tuid=0.\n\n\t\t\tThe \"appraise_tcb\" policy appraises the integrity of\n\t\t\tall files owned by root.\n\n\t\t\tThe \"secure_boot\" policy appraises the integrity\n\t\t\tof files (eg. kexec kernel image, kernel modules,\n\t\t\tfirmware, policy, etc) based on file signatures.\n\n\t\t\tThe \"fail_securely\" policy forces file signature\n\t\t\tverification failure also on privileged mounted\n\t\t\tfilesystems with the SB_I_UNVERIFIABLE_SIGNATURE\n\t\t\tflag.\n\n\tima_tcb\t\t[IMA] Deprecated.  Use ima_policy= instead.\n\t\t\tLoad a policy which meets the needs of the Trusted\n\t\t\tComputing Base.  This means IMA will measure all\n\t\t\tprograms exec'd, files mmap'd for exec, and all files\n\t\t\topened for read by uid=0.\n\n\tima_template=\t[IMA]\n\t\t\tSelect one of defined IMA measurements template formats.\n\t\t\tFormats: { \"ima\" | \"ima-ng\" | \"ima-sig\" }\n\t\t\tDefault: \"ima-ng\"\n\n\tima_template_fmt=\n\t\t\t[IMA] Define a custom template format.\n\t\t\tFormat: { \"field1|...|fieldN\" }\n\n\tima.ahash_minsize= [IMA] Minimum file size for asynchronous hash usage\n\t\t\tFormat: <min_file_size>\n\t\t\tSet the minimal file size for using asynchronous hash.\n\t\t\tIf left unspecified, ahash usage is disabled.\n\n\t\t\tahash performance varies for different data sizes on\n\t\t\tdifferent crypto accelerators. This option can be used\n\t\t\tto achieve the best performance for a particular HW.\n\n\tima.ahash_bufsize= [IMA] Asynchronous hash buffer size\n\t\t\tFormat: <bufsize>\n\t\t\tSet hashing buffer size. Default: 4k.\n\n\t\t\tahash performance varies for different chunk sizes on\n\t\t\tdifferent crypto accelerators. This option can be used\n\t\t\tto achieve best performance for particular HW.\n\n\tinit=\t\t[KNL]\n\t\t\tFormat: <full_path>\n\t\t\tRun specified binary instead of /sbin/init as init\n\t\t\tprocess.\n\n\tinitcall_debug\t[KNL] Trace initcalls as they are executed.  Useful\n\t\t\tfor working out where the kernel is dying during\n\t\t\tstartup.\n\n\tinitcall_blacklist=  [KNL] Do not execute a comma-separated list of\n\t\t\tinitcall functions.  Useful for debugging built-in\n\t\t\tmodules and initcalls.\n\n\tinitrd=\t\t[BOOT] Specify the location of the initial ramdisk\n\n\tinitrdmem=\t[KNL] Specify a physical address and size from which to\n\t\t\tload the initrd. If an initrd is compiled in or\n\t\t\tspecified in the bootparams, it takes priority over this\n\t\t\tsetting.\n\t\t\tFormat: ss[KMG],nn[KMG]\n\t\t\tDefault is 0, 0\n\n\tinit_on_alloc=\t[MM] Fill newly allocated pages and heap objects with\n\t\t\tzeroes.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault set by CONFIG_INIT_ON_ALLOC_DEFAULT_ON.\n\n\tinit_on_free=\t[MM] Fill freed pages and heap objects with zeroes.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault set by CONFIG_INIT_ON_FREE_DEFAULT_ON.\n\n\tinit_pkru=\t[X86] Specify the default memory protection keys rights\n\t\t\tregister contents for all processes.  0x55555554 by\n\t\t\tdefault (disallow access to all but pkey 0).  Can\n\t\t\toverride in debugfs after boot.\n\n\tinport.irq=\t[HW] Inport (ATI XL and Microsoft) busmouse driver\n\t\t\tFormat: <irq>\n\n\tint_pln_enable\t[X86] Enable power limit notification interrupt\n\n\tintegrity_audit=[IMA]\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 -- basic integrity auditing messages. (Default)\n\t\t\t1 -- additional integrity auditing messages.\n\n\tintel_iommu=\t[DMAR] Intel IOMMU driver (DMAR) option\n\t\ton\n\t\t\tEnable intel iommu driver.\n\t\toff\n\t\t\tDisable intel iommu driver.\n\t\tigfx_off [Default Off]\n\t\t\tBy default, gfx is mapped as normal device. If a gfx\n\t\t\tdevice has a dedicated DMAR unit, the DMAR unit is\n\t\t\tbypassed by not enabling DMAR with this option. In\n\t\t\tthis case, gfx device will use physical address for\n\t\t\tDMA.\n\t\tforcedac [X86-64]\n\t\t\tWith this option iommu will not optimize to look\n\t\t\tfor io virtual address below 32-bit forcing dual\n\t\t\taddress cycle on pci bus for cards supporting greater\n\t\t\tthan 32-bit addressing. The default is to look\n\t\t\tfor translation below 32-bit and if not available\n\t\t\tthen look in the higher range.\n\t\tstrict [Default Off]\n\t\t\tWith this option on every unmap_single operation will\n\t\t\tresult in a hardware IOTLB flush operation as opposed\n\t\t\tto batching them for performance.\n\t\tsp_off [Default Off]\n\t\t\tBy default, super page will be supported if Intel IOMMU\n\t\t\thas the capability. With this option, super page will\n\t\t\tnot be supported.\n\t\tsm_on [Default Off]\n\t\t\tBy default, scalable mode will be disabled even if the\n\t\t\thardware advertises that it has support for the scalable\n\t\t\tmode translation. With this option set, scalable mode\n\t\t\twill be used on hardware which claims to support it.\n\t\ttboot_noforce [Default Off]\n\t\t\tDo not force the Intel IOMMU enabled under tboot.\n\t\t\tBy default, tboot will force Intel IOMMU on, which\n\t\t\tcould harm performance of some high-throughput\n\t\t\tdevices like 40GBit network cards, even if identity\n\t\t\tmapping is enabled.\n\t\t\tNote that using this option lowers the security\n\t\t\tprovided by tboot because it makes the system\n\t\t\tvulnerable to DMA attacks.\n\t\tnobounce [Default off]\n\t\t\tDisable bounce buffer for untrusted devices such as\n\t\t\tthe Thunderbolt devices. This will treat the untrusted\n\t\t\tdevices as the trusted ones, hence might expose security\n\t\t\trisks of DMA attacks.\n\n\tintel_idle.max_cstate=\t[KNL,HW,ACPI,X86]\n\t\t\t0\tdisables intel_idle and fall back on acpi_idle.\n\t\t\t1 to 9\tspecify maximum depth of C-state.\n\n\tintel_pstate=\t[X86]\n\t\t\tdisable\n\t\t\t  Do not enable intel_pstate as the default\n\t\t\t  scaling driver for the supported processors\n\t\t\tpassive\n\t\t\t  Use intel_pstate as a scaling driver, but configure it\n\t\t\t  to work with generic cpufreq governors (instead of\n\t\t\t  enabling its internal governor).  This mode cannot be\n\t\t\t  used along with the hardware-managed P-states (HWP)\n\t\t\t  feature.\n\t\t\tforce\n\t\t\t  Enable intel_pstate on systems that prohibit it by default\n\t\t\t  in favor of acpi-cpufreq. Forcing the intel_pstate driver\n\t\t\t  instead of acpi-cpufreq may disable platform features, such\n\t\t\t  as thermal controls and power capping, that rely on ACPI\n\t\t\t  P-States information being indicated to OSPM and therefore\n\t\t\t  should be used with caution. This option does not work with\n\t\t\t  processors that aren't supported by the intel_pstate driver\n\t\t\t  or on platforms that use pcc-cpufreq instead of acpi-cpufreq.\n\t\t\tno_hwp\n\t\t\t  Do not enable hardware P state control (HWP)\n\t\t\t  if available.\n\t\t\thwp_only\n\t\t\t  Only load intel_pstate on systems which support\n\t\t\t  hardware P state control (HWP) if available.\n\t\t\tsupport_acpi_ppc\n\t\t\t  Enforce ACPI _PPC performance limits. If the Fixed ACPI\n\t\t\t  Description Table, specifies preferred power management\n\t\t\t  profile as \"Enterprise Server\" or \"Performance Server\",\n\t\t\t  then this feature is turned on by default.\n\t\t\tper_cpu_perf_limits\n\t\t\t  Allow per-logical-CPU P-State performance control limits using\n\t\t\t  cpufreq sysfs interface\n\n\tintremap=\t[X86-64, Intel-IOMMU]\n\t\t\ton\tenable Interrupt Remapping (default)\n\t\t\toff\tdisable Interrupt Remapping\n\t\t\tnosid\tdisable Source ID checking\n\t\t\tno_x2apic_optout\n\t\t\t\tBIOS x2APIC opt-out request will be ignored\n\t\t\tnopost\tdisable Interrupt Posting\n\n\tiomem=\t\tDisable strict checking of access to MMIO memory\n\t\tstrict\tregions from userspace.\n\t\trelaxed\n\n\tiommu=\t\t[X86]\n\t\toff\n\t\tforce\n\t\tnoforce\n\t\tbiomerge\n\t\tpanic\n\t\tnopanic\n\t\tmerge\n\t\tnomerge\n\t\tsoft\n\t\tpt\t\t[X86]\n\t\tnopt\t\t[X86]\n\t\tnobypass\t[PPC/POWERNV]\n\t\t\tDisable IOMMU bypass, using IOMMU for PCI devices.\n\n\tiommu.strict=\t[ARM64] Configure TLB invalidation behaviour\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 - Lazy mode.\n\t\t\t  Request that DMA unmap operations use deferred\n\t\t\t  invalidation of hardware TLBs, for increased\n\t\t\t  throughput at the cost of reduced device isolation.\n\t\t\t  Will fall back to strict mode if not supported by\n\t\t\t  the relevant IOMMU driver.\n\t\t\t1 - Strict mode (default).\n\t\t\t  DMA unmap operations invalidate IOMMU hardware TLBs\n\t\t\t  synchronously.\n\n\tiommu.passthrough=\n\t\t\t[ARM64, X86] Configure DMA to bypass the IOMMU by default.\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 - Use IOMMU translation for DMA.\n\t\t\t1 - Bypass the IOMMU for DMA.\n\t\t\tunset - Use value of CONFIG_IOMMU_DEFAULT_PASSTHROUGH.\n\n\tio7=\t\t[HW] IO7 for Marvel based alpha systems\n\t\t\tSee comment before marvel_specify_io7 in\n\t\t\tarch/alpha/kernel/core_marvel.c.\n\n\tio_delay=\t[X86] I/O delay method\n\t\t0x80\n\t\t\tStandard port 0x80 based delay\n\t\t0xed\n\t\t\tAlternate port 0xed based delay (needed on some systems)\n\t\tudelay\n\t\t\tSimple two microseconds delay\n\t\tnone\n\t\t\tNo delay\n\n\tip=\t\t[IP_PNP]\n\t\t\tSee Documentation/admin-guide/nfs/nfsroot.rst.\n\n\tipcmni_extend\t[KNL] Extend the maximum number of unique System V\n\t\t\tIPC identifiers from 32,768 to 16,777,216.\n\n\tirqaffinity=\t[SMP] Set the default irq affinity mask\n\t\t\tThe argument is a cpu list, as described above.\n\n\tirqchip.gicv2_force_probe=\n\t\t\t[ARM, ARM64]\n\t\t\tFormat: <bool>\n\t\t\tForce the kernel to look for the second 4kB page\n\t\t\tof a GICv2 controller even if the memory range\n\t\t\texposed by the device tree is too small.\n\n\tirqchip.gicv3_nolpi=\n\t\t\t[ARM, ARM64]\n\t\t\tForce the kernel to ignore the availability of\n\t\t\tLPIs (and by consequence ITSs). Intended for system\n\t\t\tthat use the kernel as a bootloader, and thus want\n\t\t\tto let secondary kernels in charge of setting up\n\t\t\tLPIs.\n\n\tirqchip.gicv3_pseudo_nmi= [ARM64]\n\t\t\tEnables support for pseudo-NMIs in the kernel. This\n\t\t\trequires the kernel to be built with\n\t\t\tCONFIG_ARM64_PSEUDO_NMI.\n\n\tirqfixup\t[HW]\n\t\t\tWhen an interrupt is not handled search all handlers\n\t\t\tfor it. Intended to get systems with badly broken\n\t\t\tfirmware running.\n\n\tirqpoll\t\t[HW]\n\t\t\tWhen an interrupt is not handled search all handlers\n\t\t\tfor it. Also check all handlers each timer\n\t\t\tinterrupt. Intended to get systems with badly broken\n\t\t\tfirmware running.\n\n\tisapnp=\t\t[ISAPNP]\n\t\t\tFormat: <RDP>,<reset>,<pci_scan>,<verbosity>\n\n\tisolcpus=\t[KNL,SMP,ISOL] Isolate a given set of CPUs from disturbance.\n\t\t\t[Deprecated - use cpusets instead]\n\t\t\tFormat: [flag-list,]<cpu-list>\n\n\t\t\tSpecify one or more CPUs to isolate from disturbances\n\t\t\tspecified in the flag list (default: domain):\n\n\t\t\tnohz\n\t\t\t  Disable the tick when a single task runs.\n\n\t\t\t  A residual 1Hz tick is offloaded to workqueues, which you\n\t\t\t  need to affine to housekeeping through the global\n\t\t\t  workqueue's affinity configured via the\n\t\t\t  /sys/devices/virtual/workqueue/cpumask sysfs file, or\n\t\t\t  by using the 'domain' flag described below.\n\n\t\t\t  NOTE: by default the global workqueue runs on all CPUs,\n\t\t\t  so to protect individual CPUs the 'cpumask' file has to\n\t\t\t  be configured manually after bootup.\n\n\t\t\tdomain\n\t\t\t  Isolate from the general SMP balancing and scheduling\n\t\t\t  algorithms. Note that performing domain isolation this way\n\t\t\t  is irreversible: it's not possible to bring back a CPU to\n\t\t\t  the domains once isolated through isolcpus. It's strongly\n\t\t\t  advised to use cpusets instead to disable scheduler load\n\t\t\t  balancing through the \"cpuset.sched_load_balance\" file.\n\t\t\t  It offers a much more flexible interface where CPUs can\n\t\t\t  move in and out of an isolated set anytime.\n\n\t\t\t  You can move a process onto or off an \"isolated\" CPU via\n\t\t\t  the CPU affinity syscalls or cpuset.\n\t\t\t  <cpu number> begins at 0 and the maximum value is\n\t\t\t  \"number of CPUs in system - 1\".\n\n\t\t\tmanaged_irq\n\n\t\t\t  Isolate from being targeted by managed interrupts\n\t\t\t  which have an interrupt mask containing isolated\n\t\t\t  CPUs. The affinity of managed interrupts is\n\t\t\t  handled by the kernel and cannot be changed via\n\t\t\t  the /proc/irq/* interfaces.\n\n\t\t\t  This isolation is best effort and only effective\n\t\t\t  if the automatically assigned interrupt mask of a\n\t\t\t  device queue contains isolated and housekeeping\n\t\t\t  CPUs. If housekeeping CPUs are online then such\n\t\t\t  interrupts are directed to the housekeeping CPU\n\t\t\t  so that IO submitted on the housekeeping CPU\n\t\t\t  cannot disturb the isolated CPU.\n\n\t\t\t  If a queue's affinity mask contains only isolated\n\t\t\t  CPUs then this parameter has no effect on the\n\t\t\t  interrupt routing decision, though interrupts are\n\t\t\t  only delivered when tasks running on those\n\t\t\t  isolated CPUs submit IO. IO submitted on\n\t\t\t  housekeeping CPUs has no influence on those\n\t\t\t  queues.\n\n\t\t\tThe format of <cpu-list> is described above.\n\n\tiucv=\t\t[HW,NET]\n\n\tivrs_ioapic\t[HW,X86-64]\n\t\t\tProvide an override to the IOAPIC-ID<->DEVICE-ID\n\t\t\tmapping provided in the IVRS ACPI table. For\n\t\t\texample, to map IOAPIC-ID decimal 10 to\n\t\t\tPCI device 00:14.0 write the parameter as:\n\t\t\t\tivrs_ioapic[10]=00:14.0\n\n\tivrs_hpet\t[HW,X86-64]\n\t\t\tProvide an override to the HPET-ID<->DEVICE-ID\n\t\t\tmapping provided in the IVRS ACPI table. For\n\t\t\texample, to map HPET-ID decimal 0 to\n\t\t\tPCI device 00:14.0 write the parameter as:\n\t\t\t\tivrs_hpet[0]=00:14.0\n\n\tivrs_acpihid\t[HW,X86-64]\n\t\t\tProvide an override to the ACPI-HID:UID<->DEVICE-ID\n\t\t\tmapping provided in the IVRS ACPI table. For\n\t\t\texample, to map UART-HID:UID AMD0020:0 to\n\t\t\tPCI device 00:14.5 write the parameter as:\n\t\t\t\tivrs_acpihid[00:14.5]=AMD0020:0\n\n\tjs=\t\t[HW,JOY] Analog joystick\n\t\t\tSee Documentation/input/joydev/joystick.rst.\n\n\tnokaslr\t\t[KNL]\n\t\t\tWhen CONFIG_RANDOMIZE_BASE is set, this disables\n\t\t\tkernel and module base offset ASLR (Address Space\n\t\t\tLayout Randomization).\n\n\tkasan_multi_shot\n\t\t\t[KNL] Enforce KASAN (Kernel Address Sanitizer) to print\n\t\t\treport on every invalid memory access. Without this\n\t\t\tparameter KASAN will print report only for the first\n\t\t\tinvalid access.\n\n\tkeepinitrd\t[HW,ARM]\n\n\tkernelcore=\t[KNL,X86,IA-64,PPC]\n\t\t\tFormat: nn[KMGTPE] | nn% | \"mirror\"\n\t\t\tThis parameter specifies the amount of memory usable by\n\t\t\tthe kernel for non-movable allocations.  The requested\n\t\t\tamount is spread evenly throughout all nodes in the\n\t\t\tsystem as ZONE_NORMAL.  The remaining memory is used for\n\t\t\tmovable memory in its own zone, ZONE_MOVABLE.  In the\n\t\t\tevent, a node is too small to have both ZONE_NORMAL and\n\t\t\tZONE_MOVABLE, kernelcore memory will take priority and\n\t\t\tother nodes will have a larger ZONE_MOVABLE.\n\n\t\t\tZONE_MOVABLE is used for the allocation of pages that\n\t\t\tmay be reclaimed or moved by the page migration\n\t\t\tsubsystem.  Note that allocations like PTEs-from-HighMem\n\t\t\tstill use the HighMem zone if it exists, and the Normal\n\t\t\tzone if it does not.\n\n\t\t\tIt is possible to specify the exact amount of memory in\n\t\t\tthe form of \"nn[KMGTPE]\", a percentage of total system\n\t\t\tmemory in the form of \"nn%\", or \"mirror\".  If \"mirror\"\n\t\t\toption is specified, mirrored (reliable) memory is used\n\t\t\tfor non-movable allocations and remaining memory is used\n\t\t\tfor Movable pages.  \"nn[KMGTPE]\", \"nn%\", and \"mirror\"\n\t\t\tare exclusive, so you cannot specify multiple forms.\n\n\tkgdbdbgp=\t[KGDB,HW] kgdb over EHCI usb debug port.\n\t\t\tFormat: <Controller#>[,poll interval]\n\t\t\tThe controller # is the number of the ehci usb debug\n\t\t\tport as it is probed via PCI.  The poll interval is\n\t\t\toptional and is the number seconds in between\n\t\t\teach poll cycle to the debug port in case you need\n\t\t\tthe functionality for interrupting the kernel with\n\t\t\tgdb or control-c on the dbgp connection.  When\n\t\t\tnot using this parameter you use sysrq-g to break into\n\t\t\tthe kernel debugger.\n\n\tkgdboc=\t\t[KGDB,HW] kgdb over consoles.\n\t\t\tRequires a tty driver that supports console polling,\n\t\t\tor a supported polling keyboard driver (non-usb).\n\t\t\t Serial only format: <serial_device>[,baud]\n\t\t\t keyboard only format: kbd\n\t\t\t keyboard and serial format: kbd,<serial_device>[,baud]\n\t\t\tOptional Kernel mode setting:\n\t\t\t kms, kbd format: kms,kbd\n\t\t\t kms, kbd and serial format: kms,kbd,<ser_dev>[,baud]\n\n\tkgdboc_earlycon=\t[KGDB,HW]\n\t\t\tIf the boot console provides the ability to read\n\t\t\tcharacters and can work in polling mode, you can use\n\t\t\tthis parameter to tell kgdb to use it as a backend\n\t\t\tuntil the normal console is registered. Intended to\n\t\t\tbe used together with the kgdboc parameter which\n\t\t\tspecifies the normal console to transition to.\n\n\t\t\tThe name of the early console should be specified\n\t\t\tas the value of this parameter. Note that the name of\n\t\t\tthe early console might be different than the tty\n\t\t\tname passed to kgdboc. It's OK to leave the value\n\t\t\tblank and the first boot console that implements\n\t\t\tread() will be picked.\n\n\tkgdbwait\t[KGDB] Stop kernel execution and enter the\n\t\t\tkernel debugger at the earliest opportunity.\n\n\tkmac=\t\t[MIPS] korina ethernet MAC address.\n\t\t\tConfigure the RouterBoard 532 series on-chip\n\t\t\tEthernet adapter MAC address.\n\n\tkmemleak=\t[KNL] Boot-time kmemleak enable/disable\n\t\t\tValid arguments: on, off\n\t\t\tDefault: on\n\t\t\tBuilt with CONFIG_DEBUG_KMEMLEAK_DEFAULT_OFF=y,\n\t\t\tthe default is off.\n\n\tkprobe_event=[probe-list]\n\t\t\t[FTRACE] Add kprobe events and enable at boot time.\n\t\t\tThe probe-list is a semicolon delimited list of probe\n\t\t\tdefinitions. Each definition is same as kprobe_events\n\t\t\tinterface, but the parameters are comma delimited.\n\t\t\tFor example, to add a kprobe event on vfs_read with\n\t\t\targ1 and arg2, add to the command line;\n\n\t\t\t      kprobe_event=p,vfs_read,$arg1,$arg2\n\n\t\t\tSee also Documentation/trace/kprobetrace.rst \"Kernel\n\t\t\tBoot Parameter\" section.\n\n\tkpti=\t\t[ARM64] Control page table isolation of user\n\t\t\tand kernel address spaces.\n\t\t\tDefault: enabled on cores which need mitigation.\n\t\t\t0: force disabled\n\t\t\t1: force enabled\n\n\tkvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.\n\t\t\tDefault is 0 (don't ignore, but inject #GP)\n\n\tkvm.enable_vmware_backdoor=[KVM] Support VMware backdoor PV interface.\n\t\t\t\t   Default is false (don't support).\n\n\tkvm.mmu_audit=\t[KVM] This is a R/W parameter which allows audit\n\t\t\tKVM MMU at runtime.\n\t\t\tDefault is 0 (off)\n\n\tkvm.nx_huge_pages=\n\t\t\t[KVM] Controls the software workaround for the\n\t\t\tX86_BUG_ITLB_MULTIHIT bug.\n\t\t\tforce\t: Always deploy workaround.\n\t\t\toff\t: Never deploy workaround.\n\t\t\tauto    : Deploy workaround based on the presence of\n\t\t\t\t  X86_BUG_ITLB_MULTIHIT.\n\n\t\t\tDefault is 'auto'.\n\n\t\t\tIf the software workaround is enabled for the host,\n\t\t\tguests do need not to enable it for nested guests.\n\n\tkvm.nx_huge_pages_recovery_ratio=\n\t\t\t[KVM] Controls how many 4KiB pages are periodically zapped\n\t\t\tback to huge pages.  0 disables the recovery, otherwise if\n\t\t\tthe value is N KVM will zap 1/Nth of the 4KiB pages every\n\t\t\tminute.  The default is 60.\n\n\tkvm-amd.nested=\t[KVM,AMD] Allow nested virtualization in KVM/SVM.\n\t\t\tDefault is 1 (enabled)\n\n\tkvm-amd.npt=\t[KVM,AMD] Disable nested paging (virtualized MMU)\n\t\t\tfor all guests.\n\t\t\tDefault is 1 (enabled) if in 64-bit or 32-bit PAE mode.\n\n\tkvm-arm.vgic_v3_group0_trap=\n\t\t\t[KVM,ARM] Trap guest accesses to GICv3 group-0\n\t\t\tsystem registers\n\n\tkvm-arm.vgic_v3_group1_trap=\n\t\t\t[KVM,ARM] Trap guest accesses to GICv3 group-1\n\t\t\tsystem registers\n\n\tkvm-arm.vgic_v3_common_trap=\n\t\t\t[KVM,ARM] Trap guest accesses to GICv3 common\n\t\t\tsystem registers\n\n\tkvm-arm.vgic_v4_enable=\n\t\t\t[KVM,ARM] Allow use of GICv4 for direct injection of\n\t\t\tLPIs.\n\n\tkvm-intel.ept=\t[KVM,Intel] Disable extended page tables\n\t\t\t(virtualized MMU) support on capable Intel chips.\n\t\t\tDefault is 1 (enabled)\n\n\tkvm-intel.emulate_invalid_guest_state=\n\t\t\t[KVM,Intel] Enable emulation of invalid guest states\n\t\t\tDefault is 0 (disabled)\n\n\tkvm-intel.flexpriority=\n\t\t\t[KVM,Intel] Disable FlexPriority feature (TPR shadow).\n\t\t\tDefault is 1 (enabled)\n\n\tkvm-intel.nested=\n\t\t\t[KVM,Intel] Enable VMX nesting (nVMX).\n\t\t\tDefault is 0 (disabled)\n\n\tkvm-intel.unrestricted_guest=\n\t\t\t[KVM,Intel] Disable unrestricted guest feature\n\t\t\t(virtualized real and unpaged mode) on capable\n\t\t\tIntel chips. Default is 1 (enabled)\n\n\tkvm-intel.vmentry_l1d_flush=[KVM,Intel] Mitigation for L1 Terminal Fault\n\t\t\tCVE-2018-3620.\n\n\t\t\tValid arguments: never, cond, always\n\n\t\t\talways: L1D cache flush on every VMENTER.\n\t\t\tcond:\tFlush L1D on VMENTER only when the code between\n\t\t\t\tVMEXIT and VMENTER can leak host memory.\n\t\t\tnever:\tDisables the mitigation\n\n\t\t\tDefault is cond (do L1 cache flush in specific instances)\n\n\tkvm-intel.vpid=\t[KVM,Intel] Disable Virtual Processor Identification\n\t\t\tfeature (tagged TLBs) on capable Intel chips.\n\t\t\tDefault is 1 (enabled)\n\n\tl1tf=           [X86] Control mitigation of the L1TF vulnerability on\n\t\t\t      affected CPUs\n\n\t\t\tThe kernel PTE inversion protection is unconditionally\n\t\t\tenabled and cannot be disabled.\n\n\t\t\tfull\n\t\t\t\tProvides all available mitigations for the\n\t\t\t\tL1TF vulnerability. Disables SMT and\n\t\t\t\tenables all mitigations in the\n\t\t\t\thypervisors, i.e. unconditional L1D flush.\n\n\t\t\t\tSMT control and L1D flush control via the\n\t\t\t\tsysfs interface is still possible after\n\t\t\t\tboot.  Hypervisors will issue a warning\n\t\t\t\twhen the first VM is started in a\n\t\t\t\tpotentially insecure configuration,\n\t\t\t\ti.e. SMT enabled or L1D flush disabled.\n\n\t\t\tfull,force\n\t\t\t\tSame as 'full', but disables SMT and L1D\n\t\t\t\tflush runtime control. Implies the\n\t\t\t\t'nosmt=force' command line option.\n\t\t\t\t(i.e. sysfs control of SMT is disabled.)\n\n\t\t\tflush\n\t\t\t\tLeaves SMT enabled and enables the default\n\t\t\t\thypervisor mitigation, i.e. conditional\n\t\t\t\tL1D flush.\n\n\t\t\t\tSMT control and L1D flush control via the\n\t\t\t\tsysfs interface is still possible after\n\t\t\t\tboot.  Hypervisors will issue a warning\n\t\t\t\twhen the first VM is started in a\n\t\t\t\tpotentially insecure configuration,\n\t\t\t\ti.e. SMT enabled or L1D flush disabled.\n\n\t\t\tflush,nosmt\n\n\t\t\t\tDisables SMT and enables the default\n\t\t\t\thypervisor mitigation.\n\n\t\t\t\tSMT control and L1D flush control via the\n\t\t\t\tsysfs interface is still possible after\n\t\t\t\tboot.  Hypervisors will issue a warning\n\t\t\t\twhen the first VM is started in a\n\t\t\t\tpotentially insecure configuration,\n\t\t\t\ti.e. SMT enabled or L1D flush disabled.\n\n\t\t\tflush,nowarn\n\t\t\t\tSame as 'flush', but hypervisors will not\n\t\t\t\twarn when a VM is started in a potentially\n\t\t\t\tinsecure configuration.\n\n\t\t\toff\n\t\t\t\tDisables hypervisor mitigations and doesn't\n\t\t\t\temit any warnings.\n\t\t\t\tIt also drops the swap size and available\n\t\t\t\tRAM limit restriction on both hypervisor and\n\t\t\t\tbare metal.\n\n\t\t\tDefault is 'flush'.\n\n\t\t\tFor details see: Documentation/admin-guide/hw-vuln/l1tf.rst\n\n\tl2cr=\t\t[PPC]\n\n\tl3cr=\t\t[PPC]\n\n\tlapic\t\t[X86-32,APIC] Enable the local APIC even if BIOS\n\t\t\tdisabled it.\n\n\tlapic=\t\t[X86,APIC] \"notscdeadline\" Do not use TSC deadline\n\t\t\tvalue for LAPIC timer one-shot implementation. Default\n\t\t\tback to the programmable timer unit in the LAPIC.\n\n\tlapic_timer_c2_ok\t[X86,APIC] trust the local apic timer\n\t\t\tin C2 power state.\n\n\tlibata.dma=\t[LIBATA] DMA control\n\t\t\tlibata.dma=0\t  Disable all PATA and SATA DMA\n\t\t\tlibata.dma=1\t  PATA and SATA Disk DMA only\n\t\t\tlibata.dma=2\t  ATAPI (CDROM) DMA only\n\t\t\tlibata.dma=4\t  Compact Flash DMA only\n\t\t\tCombinations also work, so libata.dma=3 enables DMA\n\t\t\tfor disks and CDROMs, but not CFs.\n\n\tlibata.ignore_hpa=\t[LIBATA] Ignore HPA limit\n\t\t\tlibata.ignore_hpa=0\t  keep BIOS limits (default)\n\t\t\tlibata.ignore_hpa=1\t  ignore limits, using full disk\n\n\tlibata.noacpi\t[LIBATA] Disables use of ACPI in libata suspend/resume\n\t\t\twhen set.\n\t\t\tFormat: <int>\n\n\tlibata.force=\t[LIBATA] Force configurations.  The format is comma\n\t\t\tseparated list of \"[ID:]VAL\" where ID is\n\t\t\tPORT[.DEVICE].  PORT and DEVICE are decimal numbers\n\t\t\tmatching port, link or device.  Basically, it matches\n\t\t\tthe ATA ID string printed on console by libata.  If\n\t\t\tthe whole ID part is omitted, the last PORT and DEVICE\n\t\t\tvalues are used.  If ID hasn't been specified yet, the\n\t\t\tconfiguration applies to all ports, links and devices.\n\n\t\t\tIf only DEVICE is omitted, the parameter applies to\n\t\t\tthe port and all links and devices behind it.  DEVICE\n\t\t\tnumber of 0 either selects the first device or the\n\t\t\tfirst fan-out link behind PMP device.  It does not\n\t\t\tselect the host link.  DEVICE number of 15 selects the\n\t\t\thost link and device attached to it.\n\n\t\t\tThe VAL specifies the configuration to force.  As long\n\t\t\tas there's no ambiguity shortcut notation is allowed.\n\t\t\tFor example, both 1.5 and 1.5G would work for 1.5Gbps.\n\t\t\tThe following configurations can be forced.\n\n\t\t\t* Cable type: 40c, 80c, short40c, unk, ign or sata.\n\t\t\t  Any ID with matching PORT is used.\n\n\t\t\t* SATA link speed limit: 1.5Gbps or 3.0Gbps.\n\n\t\t\t* Transfer mode: pio[0-7], mwdma[0-4] and udma[0-7].\n\t\t\t  udma[/][16,25,33,44,66,100,133] notation is also\n\t\t\t  allowed.\n\n\t\t\t* [no]ncq: Turn on or off NCQ.\n\n\t\t\t* [no]ncqtrim: Turn off queued DSM TRIM.\n\n\t\t\t* nohrst, nosrst, norst: suppress hard, soft\n\t\t\t  and both resets.\n\n\t\t\t* rstonce: only attempt one reset during\n\t\t\t  hot-unplug link recovery\n\n\t\t\t* dump_id: dump IDENTIFY data.\n\n\t\t\t* atapi_dmadir: Enable ATAPI DMADIR bridge support\n\n\t\t\t* disable: Disable this device.\n\n\t\t\tIf there are multiple matching configurations changing\n\t\t\tthe same attribute, the last one is used.\n\n\tmemblock=debug\t[KNL] Enable memblock debug messages.\n\n\tload_ramdisk=\t[RAM] List of ramdisks to load from floppy\n\t\t\tSee Documentation/admin-guide/blockdev/ramdisk.rst.\n\n\tlockd.nlm_grace_period=P  [NFS] Assign grace period.\n\t\t\tFormat: <integer>\n\n\tlockd.nlm_tcpport=N\t[NFS] Assign TCP port.\n\t\t\tFormat: <integer>\n\n\tlockd.nlm_timeout=T\t[NFS] Assign timeout value.\n\t\t\tFormat: <integer>\n\n\tlockd.nlm_udpport=M\t[NFS] Assign UDP port.\n\t\t\tFormat: <integer>\n\n\tlockdown=\t[SECURITY]\n\t\t\t{ integrity | confidentiality }\n\t\t\tEnable the kernel lockdown feature. If set to\n\t\t\tintegrity, kernel features that allow userland to\n\t\t\tmodify the running kernel are disabled. If set to\n\t\t\tconfidentiality, kernel features that allow userland\n\t\t\tto extract confidential information from the kernel\n\t\t\tare also disabled.\n\n\tlocktorture.nreaders_stress= [KNL]\n\t\t\tSet the number of locking read-acquisition kthreads.\n\t\t\tDefaults to being automatically set based on the\n\t\t\tnumber of online CPUs.\n\n\tlocktorture.nwriters_stress= [KNL]\n\t\t\tSet the number of locking write-acquisition kthreads.\n\n\tlocktorture.onoff_holdoff= [KNL]\n\t\t\tSet time (s) after boot for CPU-hotplug testing.\n\n\tlocktorture.onoff_interval= [KNL]\n\t\t\tSet time (s) between CPU-hotplug operations, or\n\t\t\tzero to disable CPU-hotplug testing.\n\n\tlocktorture.shuffle_interval= [KNL]\n\t\t\tSet task-shuffle interval (jiffies).  Shuffling\n\t\t\ttasks allows some CPUs to go into dyntick-idle\n\t\t\tmode during the locktorture test.\n\n\tlocktorture.shutdown_secs= [KNL]\n\t\t\tSet time (s) after boot system shutdown.  This\n\t\t\tis useful for hands-off automated testing.\n\n\tlocktorture.stat_interval= [KNL]\n\t\t\tTime (s) between statistics printk()s.\n\n\tlocktorture.stutter= [KNL]\n\t\t\tTime (s) to stutter testing, for example,\n\t\t\tspecifying five seconds causes the test to run for\n\t\t\tfive seconds, wait for five seconds, and so on.\n\t\t\tThis tests the locking primitive's ability to\n\t\t\ttransition abruptly to and from idle.\n\n\tlocktorture.torture_type= [KNL]\n\t\t\tSpecify the locking implementation to test.\n\n\tlocktorture.verbose= [KNL]\n\t\t\tEnable additional printk() statements.\n\n\tlogibm.irq=\t[HW,MOUSE] Logitech Bus Mouse Driver\n\t\t\tFormat: <irq>\n\n\tloglevel=\tAll Kernel Messages with a loglevel smaller than the\n\t\t\tconsole loglevel will be printed to the console. It can\n\t\t\talso be changed with klogd or other programs. The\n\t\t\tloglevels are defined as follows:\n\n\t\t\t0 (KERN_EMERG)\t\tsystem is unusable\n\t\t\t1 (KERN_ALERT)\t\taction must be taken immediately\n\t\t\t2 (KERN_CRIT)\t\tcritical conditions\n\t\t\t3 (KERN_ERR)\t\terror conditions\n\t\t\t4 (KERN_WARNING)\twarning conditions\n\t\t\t5 (KERN_NOTICE)\t\tnormal but significant condition\n\t\t\t6 (KERN_INFO)\t\tinformational\n\t\t\t7 (KERN_DEBUG)\t\tdebug-level messages\n\n\tlog_buf_len=n[KMG]\tSets the size of the printk ring buffer,\n\t\t\tin bytes.  n must be a power of two and greater\n\t\t\tthan the minimal size. The minimal size is defined\n\t\t\tby LOG_BUF_SHIFT kernel config parameter. There is\n\t\t\talso CONFIG_LOG_CPU_MAX_BUF_SHIFT config parameter\n\t\t\tthat allows to increase the default size depending on\n\t\t\tthe number of CPUs. See init/Kconfig for more details.\n\n\tlogo.nologo\t[FB] Disables display of the built-in Linux logo.\n\t\t\tThis may be used to provide more screen space for\n\t\t\tkernel log messages and is useful when debugging\n\t\t\tkernel boot problems.\n\n\tlp=0\t\t[LP]\tSpecify parallel ports to use, e.g,\n\tlp=port[,port...]\tlp=none,parport0 (lp0 not configured, lp1 uses\n\tlp=reset\t\tfirst parallel port). 'lp=0' disables the\n\tlp=auto\t\t\tprinter driver. 'lp=reset' (which can be\n\t\t\t\tspecified in addition to the ports) causes\n\t\t\t\tattached printers to be reset. Using\n\t\t\t\tlp=port1,port2,... specifies the parallel ports\n\t\t\t\tto associate lp devices with, starting with\n\t\t\t\tlp0. A port specification may be 'none' to skip\n\t\t\t\tthat lp device, or a parport name such as\n\t\t\t\t'parport0'. Specifying 'lp=auto' instead of a\n\t\t\t\tport specification list means that device IDs\n\t\t\t\tfrom each port should be examined, to see if\n\t\t\t\tan IEEE 1284-compliant printer is attached; if\n\t\t\t\tso, the driver will manage that printer.\n\t\t\t\tSee also header of drivers/char/lp.c.\n\n\tlpj=n\t\t[KNL]\n\t\t\tSets loops_per_jiffy to given constant, thus avoiding\n\t\t\ttime-consuming boot-time autodetection (up to 250 ms per\n\t\t\tCPU). 0 enables autodetection (default). To determine\n\t\t\tthe correct value for your kernel, boot with normal\n\t\t\tautodetection and see what value is printed. Note that\n\t\t\ton SMP systems the preset will be applied to all CPUs,\n\t\t\twhich is likely to cause problems if your CPUs need\n\t\t\tsignificantly divergent settings. An incorrect value\n\t\t\twill cause delays in the kernel to be wrong, leading to\n\t\t\tunpredictable I/O errors and other breakage. Although\n\t\t\tunlikely, in the extreme case this might damage your\n\t\t\thardware.\n\n\tltpc=\t\t[NET]\n\t\t\tFormat: <io>,<irq>,<dma>\n\n\tlsm.debug\t[SECURITY] Enable LSM initialization debugging output.\n\n\tlsm=lsm1,...,lsmN\n\t\t\t[SECURITY] Choose order of LSM initialization. This\n\t\t\toverrides CONFIG_LSM, and the \"security=\" parameter.\n\n\tmachvec=\t[IA-64] Force the use of a particular machine-vector\n\t\t\t(machvec) in a generic kernel.\n\t\t\tExample: machvec=hpzx1\n\n\tmachtype=\t[Loongson] Share the same kernel image file between different\n\t\t\t yeeloong laptop.\n\t\t\tExample: machtype=lemote-yeeloong-2f-7inch\n\n\tmax_addr=nn[KMG]\t[KNL,BOOT,ia64] All physical memory greater\n\t\t\tthan or equal to this physical address is ignored.\n\n\tmaxcpus=\t[SMP] Maximum number of processors that\tan SMP kernel\n\t\t\twill bring up during bootup.  maxcpus=n : n >= 0 limits\n\t\t\tthe kernel to bring up 'n' processors. Surely after\n\t\t\tbootup you can bring up the other plugged cpu by executing\n\t\t\t\"echo 1 > /sys/devices/system/cpu/cpuX/online\". So maxcpus\n\t\t\tonly takes effect during system bootup.\n\t\t\tWhile n=0 is a special case, it is equivalent to \"nosmp\",\n\t\t\twhich also disables the IO APIC.\n\n\tmax_loop=\t[LOOP] The number of loop block devices that get\n\t(loop.max_loop)\tunconditionally pre-created at init time. The default\n\t\t\tnumber is configured by BLK_DEV_LOOP_MIN_COUNT. Instead\n\t\t\tof statically allocating a predefined number, loop\n\t\t\tdevices can be requested on-demand with the\n\t\t\t/dev/loop-control interface.\n\n\tmce\t\t[X86-32] Machine Check Exception\n\n\tmce=option\t[X86-64] See Documentation/x86/x86_64/boot-options.rst\n\n\tmd=\t\t[HW] RAID subsystems devices and level\n\t\t\tSee Documentation/admin-guide/md.rst.\n\n\tmdacon=\t\t[MDA]\n\t\t\tFormat: <first>,<last>\n\t\t\tSpecifies range of consoles to be captured by the MDA.\n\n\tmds=\t\t[X86,INTEL]\n\t\t\tControl mitigation for the Micro-architectural Data\n\t\t\tSampling (MDS) vulnerability.\n\n\t\t\tCertain CPUs are vulnerable to an exploit against CPU\n\t\t\tinternal buffers which can forward information to a\n\t\t\tdisclosure gadget under certain conditions.\n\n\t\t\tIn vulnerable processors, the speculatively\n\t\t\tforwarded data can be used in a cache side channel\n\t\t\tattack, to access data to which the attacker does\n\t\t\tnot have direct access.\n\n\t\t\tThis parameter controls the MDS mitigation. The\n\t\t\toptions are:\n\n\t\t\tfull       - Enable MDS mitigation on vulnerable CPUs\n\t\t\tfull,nosmt - Enable MDS mitigation and disable\n\t\t\t\t     SMT on vulnerable CPUs\n\t\t\toff        - Unconditionally disable MDS mitigation\n\n\t\t\tOn TAA-affected machines, mds=off can be prevented by\n\t\t\tan active TAA mitigation as both vulnerabilities are\n\t\t\tmitigated with the same mechanism so in order to disable\n\t\t\tthis mitigation, you need to specify tsx_async_abort=off\n\t\t\ttoo.\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\tmds=full.\n\n\t\t\tFor details see: Documentation/admin-guide/hw-vuln/mds.rst\n\n\tmem=nn[KMG]\t[KNL,BOOT] Force usage of a specific amount of memory\n\t\t\tAmount of memory to be used in cases as follows:\n\n\t\t\t1 for test;\n\t\t\t2 when the kernel is not able to see the whole system memory;\n\t\t\t3 memory that lies after 'mem=' boundary is excluded from\n\t\t\t the hypervisor, then assigned to KVM guests.\n\n\t\t\t[X86] Work as limiting max address. Use together\n\t\t\twith memmap= to avoid physical address space collisions.\n\t\t\tWithout memmap= PCI devices could be placed at addresses\n\t\t\tbelonging to unused RAM.\n\n\t\t\tNote that this only takes effects during boot time since\n\t\t\tin above case 3, memory may need be hot added after boot\n\t\t\tif system memory of hypervisor is not sufficient.\n\n\tmem=nopentium\t[BUGS=X86-32] Disable usage of 4MB pages for kernel\n\t\t\tmemory.\n\n\tmemchunk=nn[KMG]\n\t\t\t[KNL,SH] Allow user to override the default size for\n\t\t\tper-device physically contiguous DMA buffers.\n\n\tmemhp_default_state=online/offline\n\t\t\t[KNL] Set the initial state for the memory hotplug\n\t\t\tonlining policy. If not specified, the default value is\n\t\t\tset according to the\n\t\t\tCONFIG_MEMORY_HOTPLUG_DEFAULT_ONLINE kernel config\n\t\t\toption.\n\t\t\tSee Documentation/admin-guide/mm/memory-hotplug.rst.\n\n\tmemmap=exactmap\t[KNL,X86] Enable setting of an exact\n\t\t\tE820 memory map, as specified by the user.\n\t\t\tSuch memmap=exactmap lines can be constructed based on\n\t\t\tBIOS output or other requirements. See the memmap=nn@ss\n\t\t\toption description.\n\n\tmemmap=nn[KMG]@ss[KMG]\n\t\t\t[KNL] Force usage of a specific region of memory.\n\t\t\tRegion of memory to be used is from ss to ss+nn.\n\t\t\tIf @ss[KMG] is omitted, it is equivalent to mem=nn[KMG],\n\t\t\twhich limits max address to nn[KMG].\n\t\t\tMultiple different regions can be specified,\n\t\t\tcomma delimited.\n\t\t\tExample:\n\t\t\t\tmemmap=100M@2G,100M#3G,1G!1024G\n\n\tmemmap=nn[KMG]#ss[KMG]\n\t\t\t[KNL,ACPI] Mark specific memory as ACPI data.\n\t\t\tRegion of memory to be marked is from ss to ss+nn.\n\n\tmemmap=nn[KMG]$ss[KMG]\n\t\t\t[KNL,ACPI] Mark specific memory as reserved.\n\t\t\tRegion of memory to be reserved is from ss to ss+nn.\n\t\t\tExample: Exclude memory from 0x18690000-0x1869ffff\n\t\t\t         memmap=64K$0x18690000\n\t\t\t         or\n\t\t\t         memmap=0x10000$0x18690000\n\t\t\tSome bootloaders may need an escape character before '$',\n\t\t\tlike Grub2, otherwise '$' and the following number\n\t\t\twill be eaten.\n\n\tmemmap=nn[KMG]!ss[KMG]\n\t\t\t[KNL,X86] Mark specific memory as protected.\n\t\t\tRegion of memory to be used, from ss to ss+nn.\n\t\t\tThe memory region may be marked as e820 type 12 (0xc)\n\t\t\tand is NVDIMM or ADR memory.\n\n\tmemmap=<size>%<offset>-<oldtype>+<newtype>\n\t\t\t[KNL,ACPI] Convert memory within the specified region\n\t\t\tfrom <oldtype> to <newtype>. If \"-<oldtype>\" is left\n\t\t\tout, the whole region will be marked as <newtype>,\n\t\t\teven if previously unavailable. If \"+<newtype>\" is left\n\t\t\tout, matching memory will be removed. Types are\n\t\t\tspecified as e820 types, e.g., 1 = RAM, 2 = reserved,\n\t\t\t3 = ACPI, 12 = PRAM.\n\n\tmemory_corruption_check=0/1 [X86]\n\t\t\tSome BIOSes seem to corrupt the first 64k of\n\t\t\tmemory when doing things like suspend/resume.\n\t\t\tSetting this option will scan the memory\n\t\t\tlooking for corruption.  Enabling this will\n\t\t\tboth detect corruption and prevent the kernel\n\t\t\tfrom using the memory being corrupted.\n\t\t\tHowever, its intended as a diagnostic tool; if\n\t\t\trepeatable BIOS-originated corruption always\n\t\t\taffects the same memory, you can use memmap=\n\t\t\tto prevent the kernel from using that memory.\n\n\tmemory_corruption_check_size=size [X86]\n\t\t\tBy default it checks for corruption in the low\n\t\t\t64k, making this memory unavailable for normal\n\t\t\tuse.  Use this parameter to scan for\n\t\t\tcorruption in more or less memory.\n\n\tmemory_corruption_check_period=seconds [X86]\n\t\t\tBy default it checks for corruption every 60\n\t\t\tseconds.  Use this parameter to check at some\n\t\t\tother rate.  0 disables periodic checking.\n\n\tmemtest=\t[KNL,X86,ARM,PPC] Enable memtest\n\t\t\tFormat: <integer>\n\t\t\tdefault : 0 <disable>\n\t\t\tSpecifies the number of memtest passes to be\n\t\t\tperformed. Each pass selects another test\n\t\t\tpattern from a given set of patterns. Memtest\n\t\t\tfills the memory with this pattern, validates\n\t\t\tmemory contents and reserves bad memory\n\t\t\tregions that are detected.\n\n\tmem_encrypt=\t[X86-64] AMD Secure Memory Encryption (SME) control\n\t\t\tValid arguments: on, off\n\t\t\tDefault (depends on kernel configuration option):\n\t\t\t  on  (CONFIG_AMD_MEM_ENCRYPT_ACTIVE_BY_DEFAULT=y)\n\t\t\t  off (CONFIG_AMD_MEM_ENCRYPT_ACTIVE_BY_DEFAULT=n)\n\t\t\tmem_encrypt=on:\t\tActivate SME\n\t\t\tmem_encrypt=off:\tDo not activate SME\n\n\t\t\tRefer to Documentation/virt/kvm/amd-memory-encryption.rst\n\t\t\tfor details on when memory encryption can be activated.\n\n\tmem_sleep_default=\t[SUSPEND] Default system suspend mode:\n\t\t\ts2idle  - Suspend-To-Idle\n\t\t\tshallow - Power-On Suspend or equivalent (if supported)\n\t\t\tdeep    - Suspend-To-RAM or equivalent (if supported)\n\t\t\tSee Documentation/admin-guide/pm/sleep-states.rst.\n\n\tmeye.*=\t\t[HW] Set MotionEye Camera parameters\n\t\t\tSee Documentation/admin-guide/media/meye.rst.\n\n\tmfgpt_irq=\t[IA-32] Specify the IRQ to use for the\n\t\t\tMulti-Function General Purpose Timers on AMD Geode\n\t\t\tplatforms.\n\n\tmfgptfix\t[X86-32] Fix MFGPT timers on AMD Geode platforms when\n\t\t\tthe BIOS has incorrectly applied a workaround. TinyBIOS\n\t\t\tversion 0.98 is known to be affected, 0.99 fixes the\n\t\t\tproblem by letting the user disable the workaround.\n\n\tmga=\t\t[HW,DRM]\n\n\tmin_addr=nn[KMG]\t[KNL,BOOT,ia64] All physical memory below this\n\t\t\tphysical address is ignored.\n\n\tmini2440=\t[ARM,HW,KNL]\n\t\t\tFormat:[0..2][b][c][t]\n\t\t\tDefault: \"0tb\"\n\t\t\tMINI2440 configuration specification:\n\t\t\t0 - The attached screen is the 3.5\" TFT\n\t\t\t1 - The attached screen is the 7\" TFT\n\t\t\t2 - The VGA Shield is attached (1024x768)\n\t\t\tLeaving out the screen size parameter will not load\n\t\t\tthe TFT driver, and the framebuffer will be left\n\t\t\tunconfigured.\n\t\t\tb - Enable backlight. The TFT backlight pin will be\n\t\t\tlinked to the kernel VESA blanking code and a GPIO\n\t\t\tLED. This parameter is not necessary when using the\n\t\t\tVGA shield.\n\t\t\tc - Enable the s3c camera interface.\n\t\t\tt - Reserved for enabling touchscreen support. The\n\t\t\ttouchscreen support is not enabled in the mainstream\n\t\t\tkernel as of 2.6.30, a preliminary port can be found\n\t\t\tin the \"bleeding edge\" mini2440 support kernel at\n\t\t\thttps://repo.or.cz/w/linux-2.6/mini2440.git\n\n\tmitigations=\n\t\t\t[X86,PPC,S390,ARM64] Control optional mitigations for\n\t\t\tCPU vulnerabilities.  This is a set of curated,\n\t\t\tarch-independent options, each of which is an\n\t\t\taggregation of existing arch-specific options.\n\n\t\t\toff\n\t\t\t\tDisable all optional CPU mitigations.  This\n\t\t\t\timproves system performance, but it may also\n\t\t\t\texpose users to several CPU vulnerabilities.\n\t\t\t\tEquivalent to: nopti [X86,PPC]\n\t\t\t\t\t       kpti=0 [ARM64]\n\t\t\t\t\t       nospectre_v1 [X86,PPC]\n\t\t\t\t\t       nobp=0 [S390]\n\t\t\t\t\t       nospectre_v2 [X86,PPC,S390,ARM64]\n\t\t\t\t\t       spectre_v2_user=off [X86]\n\t\t\t\t\t       spec_store_bypass_disable=off [X86,PPC]\n\t\t\t\t\t       ssbd=force-off [ARM64]\n\t\t\t\t\t       l1tf=off [X86]\n\t\t\t\t\t       mds=off [X86]\n\t\t\t\t\t       tsx_async_abort=off [X86]\n\t\t\t\t\t       kvm.nx_huge_pages=off [X86]\n\n\t\t\t\tExceptions:\n\t\t\t\t\t       This does not have any effect on\n\t\t\t\t\t       kvm.nx_huge_pages when\n\t\t\t\t\t       kvm.nx_huge_pages=force.\n\n\t\t\tauto (default)\n\t\t\t\tMitigate all CPU vulnerabilities, but leave SMT\n\t\t\t\tenabled, even if it's vulnerable.  This is for\n\t\t\t\tusers who don't want to be surprised by SMT\n\t\t\t\tgetting disabled across kernel upgrades, or who\n\t\t\t\thave other ways of avoiding SMT-based attacks.\n\t\t\t\tEquivalent to: (default behavior)\n\n\t\t\tauto,nosmt\n\t\t\t\tMitigate all CPU vulnerabilities, disabling SMT\n\t\t\t\tif needed.  This is for users who always want to\n\t\t\t\tbe fully mitigated, even if it means losing SMT.\n\t\t\t\tEquivalent to: l1tf=flush,nosmt [X86]\n\t\t\t\t\t       mds=full,nosmt [X86]\n\t\t\t\t\t       tsx_async_abort=full,nosmt [X86]\n\n\tmminit_loglevel=\n\t\t\t[KNL] When CONFIG_DEBUG_MEMORY_INIT is set, this\n\t\t\tparameter allows control of the logging verbosity for\n\t\t\tthe additional memory initialisation checks. A value\n\t\t\tof 0 disables mminit logging and a level of 4 will\n\t\t\tlog everything. Information is printed at KERN_DEBUG\n\t\t\tso loglevel=8 may also need to be specified.\n\n\tmodule.sig_enforce\n\t\t\t[KNL] When CONFIG_MODULE_SIG is set, this means that\n\t\t\tmodules without (valid) signatures will fail to load.\n\t\t\tNote that if CONFIG_MODULE_SIG_FORCE is set, that\n\t\t\tis always true, so this option does nothing.\n\n\tmodule_blacklist=  [KNL] Do not load a comma-separated list of\n\t\t\tmodules.  Useful for debugging problem modules.\n\n\tmousedev.tap_time=\n\t\t\t[MOUSE] Maximum time between finger touching and\n\t\t\tleaving touchpad surface for touch to be considered\n\t\t\ta tap and be reported as a left button click (for\n\t\t\ttouchpads working in absolute mode only).\n\t\t\tFormat: <msecs>\n\tmousedev.xres=\t[MOUSE] Horizontal screen resolution, used for devices\n\t\t\treporting absolute coordinates, such as tablets\n\tmousedev.yres=\t[MOUSE] Vertical screen resolution, used for devices\n\t\t\treporting absolute coordinates, such as tablets\n\n\tmovablecore=\t[KNL,X86,IA-64,PPC]\n\t\t\tFormat: nn[KMGTPE] | nn%\n\t\t\tThis parameter is the complement to kernelcore=, it\n\t\t\tspecifies the amount of memory used for migratable\n\t\t\tallocations.  If both kernelcore and movablecore is\n\t\t\tspecified, then kernelcore will be at *least* the\n\t\t\tspecified value but may be more.  If movablecore on its\n\t\t\town is specified, the administrator must be careful\n\t\t\tthat the amount of memory usable for all allocations\n\t\t\tis not too small.\n\n\tmovable_node\t[KNL] Boot-time switch to make hotplugable memory\n\t\t\tNUMA nodes to be movable. This means that the memory\n\t\t\tof such nodes will be usable only for movable\n\t\t\tallocations which rules out almost all kernel\n\t\t\tallocations. Use with caution!\n\n\tMTD_Partition=\t[MTD]\n\t\t\tFormat: <name>,<region-number>,<size>,<offset>\n\n\tMTD_Region=\t[MTD] Format:\n\t\t\t<name>,<region-number>[,<base>,<size>,<buswidth>,<altbuswidth>]\n\n\tmtdparts=\t[MTD]\n\t\t\tSee drivers/mtd/parsers/cmdlinepart.c\n\n\tmultitce=off\t[PPC]  This parameter disables the use of the pSeries\n\t\t\tfirmware feature for updating multiple TCE entries\n\t\t\tat a time.\n\n\tonenand.bdry=\t[HW,MTD] Flex-OneNAND Boundary Configuration\n\n\t\t\tFormat: [die0_boundary][,die0_lock][,die1_boundary][,die1_lock]\n\n\t\t\tboundary - index of last SLC block on Flex-OneNAND.\n\t\t\t\t   The remaining blocks are configured as MLC blocks.\n\t\t\tlock\t - Configure if Flex-OneNAND boundary should be locked.\n\t\t\t\t   Once locked, the boundary cannot be changed.\n\t\t\t\t   1 indicates lock status, 0 indicates unlock status.\n\n\tmtdset=\t\t[ARM]\n\t\t\tARM/S3C2412 JIVE boot control\n\n\t\t\tSee arch/arm/mach-s3c2412/mach-jive.c\n\n\tmtouchusb.raw_coordinates=\n\t\t\t[HW] Make the MicroTouch USB driver use raw coordinates\n\t\t\t('y', default) or cooked coordinates ('n')\n\n\tmtrr_chunk_size=nn[KMG] [X86]\n\t\t\tused for mtrr cleanup. It is largest continuous chunk\n\t\t\tthat could hold holes aka. UC entries.\n\n\tmtrr_gran_size=nn[KMG] [X86]\n\t\t\tUsed for mtrr cleanup. It is granularity of mtrr block.\n\t\t\tDefault is 1.\n\t\t\tLarge value could prevent small alignment from\n\t\t\tusing up MTRRs.\n\n\tmtrr_spare_reg_nr=n [X86]\n\t\t\tFormat: <integer>\n\t\t\tRange: 0,7 : spare reg number\n\t\t\tDefault : 1\n\t\t\tUsed for mtrr cleanup. It is spare mtrr entries number.\n\t\t\tSet to 2 or more if your graphical card needs more.\n\n\tn2=\t\t[NET] SDL Inc. RISCom/N2 synchronous serial card\n\n\tnetdev=\t\t[NET] Network devices parameters\n\t\t\tFormat: <irq>,<io>,<mem_start>,<mem_end>,<name>\n\t\t\tNote that mem_start is often overloaded to mean\n\t\t\tsomething different and driver-specific.\n\t\t\tThis usage is only documented in each driver source\n\t\t\tfile if at all.\n\n\tnf_conntrack.acct=\n\t\t\t[NETFILTER] Enable connection tracking flow accounting\n\t\t\t0 to disable accounting\n\t\t\t1 to enable accounting\n\t\t\tDefault value is 0.\n\n\tnfsaddrs=\t[NFS] Deprecated.  Use ip= instead.\n\t\t\tSee Documentation/admin-guide/nfs/nfsroot.rst.\n\n\tnfsroot=\t[NFS] nfs root filesystem for disk-less boxes.\n\t\t\tSee Documentation/admin-guide/nfs/nfsroot.rst.\n\n\tnfsrootdebug\t[NFS] enable nfsroot debugging messages.\n\t\t\tSee Documentation/admin-guide/nfs/nfsroot.rst.\n\n\tnfs.callback_nr_threads=\n\t\t\t[NFSv4] set the total number of threads that the\n\t\t\tNFS client will assign to service NFSv4 callback\n\t\t\trequests.\n\n\tnfs.callback_tcpport=\n\t\t\t[NFS] set the TCP port on which the NFSv4 callback\n\t\t\tchannel should listen.\n\n\tnfs.cache_getent=\n\t\t\t[NFS] sets the pathname to the program which is used\n\t\t\tto update the NFS client cache entries.\n\n\tnfs.cache_getent_timeout=\n\t\t\t[NFS] sets the timeout after which an attempt to\n\t\t\tupdate a cache entry is deemed to have failed.\n\n\tnfs.idmap_cache_timeout=\n\t\t\t[NFS] set the maximum lifetime for idmapper cache\n\t\t\tentries.\n\n\tnfs.enable_ino64=\n\t\t\t[NFS] enable 64-bit inode numbers.\n\t\t\tIf zero, the NFS client will fake up a 32-bit inode\n\t\t\tnumber for the readdir() and stat() syscalls instead\n\t\t\tof returning the full 64-bit number.\n\t\t\tThe default is to return 64-bit inode numbers.\n\n\tnfs.max_session_cb_slots=\n\t\t\t[NFSv4.1] Sets the maximum number of session\n\t\t\tslots the client will assign to the callback\n\t\t\tchannel. This determines the maximum number of\n\t\t\tcallbacks the client will process in parallel for\n\t\t\ta particular server.\n\n\tnfs.max_session_slots=\n\t\t\t[NFSv4.1] Sets the maximum number of session slots\n\t\t\tthe client will attempt to negotiate with the server.\n\t\t\tThis limits the number of simultaneous RPC requests\n\t\t\tthat the client can send to the NFSv4.1 server.\n\t\t\tNote that there is little point in setting this\n\t\t\tvalue higher than the max_tcp_slot_table_limit.\n\n\tnfs.nfs4_disable_idmapping=\n\t\t\t[NFSv4] When set to the default of '1', this option\n\t\t\tensures that both the RPC level authentication\n\t\t\tscheme and the NFS level operations agree to use\n\t\t\tnumeric uids/gids if the mount is using the\n\t\t\t'sec=sys' security flavour. In effect it is\n\t\t\tdisabling idmapping, which can make migration from\n\t\t\tlegacy NFSv2/v3 systems to NFSv4 easier.\n\t\t\tServers that do not support this mode of operation\n\t\t\twill be autodetected by the client, and it will fall\n\t\t\tback to using the idmapper.\n\t\t\tTo turn off this behaviour, set the value to '0'.\n\tnfs.nfs4_unique_id=\n\t\t\t[NFS4] Specify an additional fixed unique ident-\n\t\t\tification string that NFSv4 clients can insert into\n\t\t\ttheir nfs_client_id4 string.  This is typically a\n\t\t\tUUID that is generated at system install time.\n\n\tnfs.send_implementation_id =\n\t\t\t[NFSv4.1] Send client implementation identification\n\t\t\tinformation in exchange_id requests.\n\t\t\tIf zero, no implementation identification information\n\t\t\twill be sent.\n\t\t\tThe default is to send the implementation identification\n\t\t\tinformation.\n\n\tnfs.recover_lost_locks =\n\t\t\t[NFSv4] Attempt to recover locks that were lost due\n\t\t\tto a lease timeout on the server. Please note that\n\t\t\tdoing this risks data corruption, since there are\n\t\t\tno guarantees that the file will remain unchanged\n\t\t\tafter the locks are lost.\n\t\t\tIf you want to enable the kernel legacy behaviour of\n\t\t\tattempting to recover these locks, then set this\n\t\t\tparameter to '1'.\n\t\t\tThe default parameter value of '0' causes the kernel\n\t\t\tnot to attempt recovery of lost locks.\n\n\tnfs4.layoutstats_timer =\n\t\t\t[NFSv4.2] Change the rate at which the kernel sends\n\t\t\tlayoutstats to the pNFS metadata server.\n\n\t\t\tSetting this to value to 0 causes the kernel to use\n\t\t\twhatever value is the default set by the layout\n\t\t\tdriver. A non-zero value sets the minimum interval\n\t\t\tin seconds between layoutstats transmissions.\n\n\tnfsd.nfs4_disable_idmapping=\n\t\t\t[NFSv4] When set to the default of '1', the NFSv4\n\t\t\tserver will return only numeric uids and gids to\n\t\t\tclients using auth_sys, and will accept numeric uids\n\t\t\tand gids from such clients.  This is intended to ease\n\t\t\tmigration from NFSv2/v3.\n\n\tnmi_debug=\t[KNL,SH] Specify one or more actions to take\n\t\t\twhen a NMI is triggered.\n\t\t\tFormat: [state][,regs][,debounce][,die]\n\n\tnmi_watchdog=\t[KNL,BUGS=X86] Debugging features for SMP kernels\n\t\t\tFormat: [panic,][nopanic,][num]\n\t\t\tValid num: 0 or 1\n\t\t\t0 - turn hardlockup detector in nmi_watchdog off\n\t\t\t1 - turn hardlockup detector in nmi_watchdog on\n\t\t\tWhen panic is specified, panic when an NMI watchdog\n\t\t\ttimeout occurs (or 'nopanic' to not panic on an NMI\n\t\t\twatchdog, if CONFIG_BOOTPARAM_HARDLOCKUP_PANIC is set)\n\t\t\tTo disable both hard and soft lockup detectors,\n\t\t\tplease see 'nowatchdog'.\n\t\t\tThis is useful when you use a panic=... timeout and\n\t\t\tneed the box quickly up again.\n\n\t\t\tThese settings can be accessed at runtime via\n\t\t\tthe nmi_watchdog and hardlockup_panic sysctls.\n\n\tnetpoll.carrier_timeout=\n\t\t\t[NET] Specifies amount of time (in seconds) that\n\t\t\tnetpoll should wait for a carrier. By default netpoll\n\t\t\twaits 4 seconds.\n\n\tno387\t\t[BUGS=X86-32] Tells the kernel to use the 387 maths\n\t\t\temulation library even if a 387 maths coprocessor\n\t\t\tis present.\n\n\tno5lvl\t\t[X86-64] Disable 5-level paging mode. Forces\n\t\t\tkernel to use 4-level paging instead.\n\n\tnofsgsbase\t[X86] Disables FSGSBASE instructions.\n\n\tno_console_suspend\n\t\t\t[HW] Never suspend the console\n\t\t\tDisable suspending of consoles during suspend and\n\t\t\thibernate operations.  Once disabled, debugging\n\t\t\tmessages can reach various consoles while the rest\n\t\t\tof the system is being put to sleep (ie, while\n\t\t\tdebugging driver suspend/resume hooks).  This may\n\t\t\tnot work reliably with all consoles, but is known\n\t\t\tto work with serial and VGA consoles.\n\t\t\tTo facilitate more flexible debugging, we also add\n\t\t\tconsole_suspend, a printk module parameter to control\n\t\t\tit. Users could use console_suspend (usually\n\t\t\t/sys/module/printk/parameters/console_suspend) to\n\t\t\tturn on/off it dynamically.\n\n\tnovmcoredd\t[KNL,KDUMP]\n\t\t\tDisable device dump. Device dump allows drivers to\n\t\t\tappend dump data to vmcore so you can collect driver\n\t\t\tspecified debug info.  Drivers can append the data\n\t\t\twithout any limit and this data is stored in memory,\n\t\t\tso this may cause significant memory stress.  Disabling\n\t\t\tdevice dump can help save memory but the driver debug\n\t\t\tdata will be no longer available.  This parameter\n\t\t\tis only available when CONFIG_PROC_VMCORE_DEVICE_DUMP\n\t\t\tis set.\n\n\tnoaliencache\t[MM, NUMA, SLAB] Disables the allocation of alien\n\t\t\tcaches in the slab allocator.  Saves per-node memory,\n\t\t\tbut will impact performance.\n\n\tnoalign\t\t[KNL,ARM]\n\n\tnoaltinstr\t[S390] Disables alternative instructions patching\n\t\t\t(CPU alternatives feature).\n\n\tnoapic\t\t[SMP,APIC] Tells the kernel to not make use of any\n\t\t\tIOAPICs that may be present in the system.\n\n\tnoautogroup\tDisable scheduler automatic task group creation.\n\n\tnobats\t\t[PPC] Do not use BATs for mapping kernel lowmem\n\t\t\ton \"Classic\" PPC cores.\n\n\tnocache\t\t[ARM]\n\n\tnoclflush\t[BUGS=X86] Don't use the CLFLUSH instruction\n\n\tnodelayacct\t[KNL] Disable per-task delay accounting\n\n\tnodsp\t\t[SH] Disable hardware DSP at boot time.\n\n\tnoefi\t\tDisable EFI runtime services support.\n\n\tnoexec\t\t[IA-64]\n\n\tnoexec\t\t[X86]\n\t\t\tOn X86-32 available only on PAE configured kernels.\n\t\t\tnoexec=on: enable non-executable mappings (default)\n\t\t\tnoexec=off: disable non-executable mappings\n\n\tnosmap\t\t[X86,PPC]\n\t\t\tDisable SMAP (Supervisor Mode Access Prevention)\n\t\t\teven if it is supported by processor.\n\n\tnosmep\t\t[X86,PPC]\n\t\t\tDisable SMEP (Supervisor Mode Execution Prevention)\n\t\t\teven if it is supported by processor.\n\n\tnoexec32\t[X86-64]\n\t\t\tThis affects only 32-bit executables.\n\t\t\tnoexec32=on: enable non-executable mappings (default)\n\t\t\t\tread doesn't imply executable mappings\n\t\t\tnoexec32=off: disable non-executable mappings\n\t\t\t\tread implies executable mappings\n\n\tnofpu\t\t[MIPS,SH] Disable hardware FPU at boot time.\n\n\tnofxsr\t\t[BUGS=X86-32] Disables x86 floating point extended\n\t\t\tregister save and restore. The kernel will only save\n\t\t\tlegacy floating-point registers on task switch.\n\n\tnohugeiomap\t[KNL,X86,PPC] Disable kernel huge I/O mappings.\n\n\tnosmt\t\t[KNL,S390] Disable symmetric multithreading (SMT).\n\t\t\tEquivalent to smt=1.\n\n\t\t\t[KNL,X86] Disable symmetric multithreading (SMT).\n\t\t\tnosmt=force: Force disable SMT, cannot be undone\n\t\t\t\t     via the sysfs control file.\n\n\tnospectre_v1\t[X86,PPC] Disable mitigations for Spectre Variant 1\n\t\t\t(bounds check bypass). With this option data leaks are\n\t\t\tpossible in the system.\n\n\tnospectre_v2\t[X86,PPC_FSL_BOOK3E,ARM64] Disable all mitigations for\n\t\t\tthe Spectre variant 2 (indirect branch prediction)\n\t\t\tvulnerability. System may allow data leaks with this\n\t\t\toption.\n\n\tnospec_store_bypass_disable\n\t\t\t[HW] Disable all mitigations for the Speculative Store Bypass vulnerability\n\n\tnoxsave\t\t[BUGS=X86] Disables x86 extended register state save\n\t\t\tand restore using xsave. The kernel will fallback to\n\t\t\tenabling legacy floating-point and sse state.\n\n\tnoxsaveopt\t[X86] Disables xsaveopt used in saving x86 extended\n\t\t\tregister states. The kernel will fall back to use\n\t\t\txsave to save the states. By using this parameter,\n\t\t\tperformance of saving the states is degraded because\n\t\t\txsave doesn't support modified optimization while\n\t\t\txsaveopt supports it on xsaveopt enabled systems.\n\n\tnoxsaves\t[X86] Disables xsaves and xrstors used in saving and\n\t\t\trestoring x86 extended register state in compacted\n\t\t\tform of xsave area. The kernel will fall back to use\n\t\t\txsaveopt and xrstor to save and restore the states\n\t\t\tin standard form of xsave area. By using this\n\t\t\tparameter, xsave area per process might occupy more\n\t\t\tmemory on xsaves enabled systems.\n\n\tnohlt\t\t[BUGS=ARM,SH] Tells the kernel that the sleep(SH) or\n\t\t\twfi(ARM) instruction doesn't work correctly and not to\n\t\t\tuse it. This is also useful when using JTAG debugger.\n\n\tno_file_caps\tTells the kernel not to honor file capabilities.  The\n\t\t\tonly way then for a file to be executed with privilege\n\t\t\tis to be setuid root or executed by root.\n\n\tnohalt\t\t[IA-64] Tells the kernel not to use the power saving\n\t\t\tfunction PAL_HALT_LIGHT when idle. This increases\n\t\t\tpower-consumption. On the positive side, it reduces\n\t\t\tinterrupt wake-up latency, which may improve performance\n\t\t\tin certain environments such as networked servers or\n\t\t\treal-time systems.\n\n\tnohibernate\t[HIBERNATION] Disable hibernation and resume.\n\n\tnohz=\t\t[KNL] Boottime enable/disable dynamic ticks\n\t\t\tValid arguments: on, off\n\t\t\tDefault: on\n\n\tnohz_full=\t[KNL,BOOT,SMP,ISOL]\n\t\t\tThe argument is a cpu list, as described above.\n\t\t\tIn kernels built with CONFIG_NO_HZ_FULL=y, set\n\t\t\tthe specified list of CPUs whose tick will be stopped\n\t\t\twhenever possible. The boot CPU will be forced outside\n\t\t\tthe range to maintain the timekeeping.  Any CPUs\n\t\t\tin this list will have their RCU callbacks offloaded,\n\t\t\tjust as if they had also been called out in the\n\t\t\trcu_nocbs= boot parameter.\n\n\tnoiotrap\t[SH] Disables trapped I/O port accesses.\n\n\tnoirqdebug\t[X86-32] Disables the code which attempts to detect and\n\t\t\tdisable unhandled interrupt sources.\n\n\tno_timer_check\t[X86,APIC] Disables the code which tests for\n\t\t\tbroken timer IRQ sources.\n\n\tnoisapnp\t[ISAPNP] Disables ISA PnP code.\n\n\tnoinitrd\t[RAM] Tells the kernel not to load any configured\n\t\t\tinitial RAM disk.\n\n\tnointremap\t[X86-64, Intel-IOMMU] Do not enable interrupt\n\t\t\tremapping.\n\t\t\t[Deprecated - use intremap=off]\n\n\tnointroute\t[IA-64]\n\n\tnoinvpcid\t[X86] Disable the INVPCID cpu feature.\n\n\tnojitter\t[IA-64] Disables jitter checking for ITC timers.\n\n\tno-kvmclock\t[X86,KVM] Disable paravirtualized KVM clock driver\n\n\tno-kvmapf\t[X86,KVM] Disable paravirtualized asynchronous page\n\t\t\tfault handling.\n\n\tno-vmw-sched-clock\n\t\t\t[X86,PV_OPS] Disable paravirtualized VMware scheduler\n\t\t\tclock and use the default one.\n\n\tno-steal-acc\t[X86,PV_OPS,ARM64] Disable paravirtualized steal time\n\t\t\taccounting. steal time is computed, but won't\n\t\t\tinfluence scheduler behaviour\n\n\tnolapic\t\t[X86-32,APIC] Do not enable or use the local APIC.\n\n\tnolapic_timer\t[X86-32,APIC] Do not use the local APIC timer.\n\n\tnoltlbs\t\t[PPC] Do not use large page/tlb entries for kernel\n\t\t\tlowmem mapping on PPC40x and PPC8xx\n\n\tnomca\t\t[IA-64] Disable machine check abort handling\n\n\tnomce\t\t[X86-32] Disable Machine Check Exception\n\n\tnomfgpt\t\t[X86-32] Disable Multi-Function General Purpose\n\t\t\tTimer usage (for AMD Geode machines).\n\n\tnonmi_ipi\t[X86] Disable using NMI IPIs during panic/reboot to\n\t\t\tshutdown the other cpus.  Instead use the REBOOT_VECTOR\n\t\t\tirq.\n\n\tnomodule\tDisable module load\n\n\tnopat\t\t[X86] Disable PAT (page attribute table extension of\n\t\t\tpagetables) support.\n\n\tnopcid\t\t[X86-64] Disable the PCID cpu feature.\n\n\tnorandmaps\tDon't use address space randomization.  Equivalent to\n\t\t\techo 0 > /proc/sys/kernel/randomize_va_space\n\n\tnoreplace-smp\t[X86-32,SMP] Don't replace SMP instructions\n\t\t\twith UP alternatives\n\n\tnordrand\t[X86] Disable kernel use of the RDRAND and\n\t\t\tRDSEED instructions even if they are supported\n\t\t\tby the processor.  RDRAND and RDSEED are still\n\t\t\tavailable to user space applications.\n\n\tnoresume\t[SWSUSP] Disables resume and restores original swap\n\t\t\tspace.\n\n\tno-scroll\t[VGA] Disables scrollback.\n\t\t\tThis is required for the Braillex ib80-piezo Braille\n\t\t\treader made by F.H. Papenmeier (Germany).\n\n\tnosbagart\t[IA-64]\n\n\tnosep\t\t[BUGS=X86-32] Disables x86 SYSENTER/SYSEXIT support.\n\n\tnosmp\t\t[SMP] Tells an SMP kernel to act as a UP kernel,\n\t\t\tand disable the IO APIC.  legacy for \"maxcpus=0\".\n\n\tnosoftlockup\t[KNL] Disable the soft-lockup detector.\n\n\tnosync\t\t[HW,M68K] Disables sync negotiation for all devices.\n\n\tnowatchdog\t[KNL] Disable both lockup detectors, i.e.\n\t\t\tsoft-lockup and NMI watchdog (hard-lockup).\n\n\tnowb\t\t[ARM]\n\n\tnox2apic\t[X86-64,APIC] Do not enable x2APIC mode.\n\n\tcpu0_hotplug\t[X86] Turn on CPU0 hotplug feature when\n\t\t\tCONFIG_BOOTPARAM_HOTPLUG_CPU0 is off.\n\t\t\tSome features depend on CPU0. Known dependencies are:\n\t\t\t1. Resume from suspend/hibernate depends on CPU0.\n\t\t\tSuspend/hibernate will fail if CPU0 is offline and you\n\t\t\tneed to online CPU0 before suspend/hibernate.\n\t\t\t2. PIC interrupts also depend on CPU0. CPU0 can't be\n\t\t\tremoved if a PIC interrupt is detected.\n\t\t\tIt's said poweroff/reboot may depend on CPU0 on some\n\t\t\tmachines although I haven't seen such issues so far\n\t\t\tafter CPU0 is offline on a few tested machines.\n\t\t\tIf the dependencies are under your control, you can\n\t\t\tturn on cpu0_hotplug.\n\n\tnps_mtm_hs_ctr=\t[KNL,ARC]\n\t\t\tThis parameter sets the maximum duration, in\n\t\t\tcycles, each HW thread of the CTOP can run\n\t\t\twithout interruptions, before HW switches it.\n\t\t\tThe actual maximum duration is 16 times this\n\t\t\tparameter's value.\n\t\t\tFormat: integer between 1 and 255\n\t\t\tDefault: 255\n\n\tnptcg=\t\t[IA-64] Override max number of concurrent global TLB\n\t\t\tpurges which is reported from either PAL_VM_SUMMARY or\n\t\t\tSAL PALO.\n\n\tnr_cpus=\t[SMP] Maximum number of processors that\tan SMP kernel\n\t\t\tcould support.  nr_cpus=n : n >= 1 limits the kernel to\n\t\t\tsupport 'n' processors. It could be larger than the\n\t\t\tnumber of already plugged CPU during bootup, later in\n\t\t\truntime you can physically add extra cpu until it reaches\n\t\t\tn. So during boot up some boot time memory for per-cpu\n\t\t\tvariables need be pre-allocated for later physical cpu\n\t\t\thot plugging.\n\n\tnr_uarts=\t[SERIAL] maximum number of UARTs to be registered.\n\n\tnuma_balancing=\t[KNL,X86] Enable or disable automatic NUMA balancing.\n\t\t\tAllowed values are enable and disable\n\n\tnuma_zonelist_order= [KNL, BOOT] Select zonelist order for NUMA.\n\t\t\t'node', 'default' can be specified\n\t\t\tThis can be set from sysctl after boot.\n\t\t\tSee Documentation/admin-guide/sysctl/vm.rst for details.\n\n\tohci1394_dma=early\t[HW] enable debugging via the ohci1394 driver.\n\t\t\tSee Documentation/core-api/debugging-via-ohci1394.rst for more\n\t\t\tinfo.\n\n\tolpc_ec_timeout= [OLPC] ms delay when issuing EC commands\n\t\t\tRather than timing out after 20 ms if an EC\n\t\t\tcommand is not properly ACKed, override the length\n\t\t\tof the timeout.  We have interrupts disabled while\n\t\t\twaiting for the ACK, so if this is set too high\n\t\t\tinterrupts *may* be lost!\n\n\tomap_mux=\t[OMAP] Override bootloader pin multiplexing.\n\t\t\tFormat: <mux_mode0.mode_name=value>...\n\t\t\tFor example, to override I2C bus2:\n\t\t\tomap_mux=i2c2_scl.i2c2_scl=0x100,i2c2_sda.i2c2_sda=0x100\n\n\toprofile.timer=\t[HW]\n\t\t\tUse timer interrupt instead of performance counters\n\n\toprofile.cpu_type=\tForce an oprofile cpu type\n\t\t\tThis might be useful if you have an older oprofile\n\t\t\tuserland or if you want common events.\n\t\t\tFormat: { arch_perfmon }\n\t\t\tarch_perfmon: [X86] Force use of architectural\n\t\t\t\tperfmon on Intel CPUs instead of the\n\t\t\t\tCPU specific event set.\n\t\t\ttimer: [X86] Force use of architectural NMI\n\t\t\t\ttimer mode (see also oprofile.timer\n\t\t\t\tfor generic hr timer mode)\n\n\toops=panic\tAlways panic on oopses. Default is to just kill the\n\t\t\tprocess, but there is a small probability of\n\t\t\tdeadlocking the machine.\n\t\t\tThis will also cause panics on machine check exceptions.\n\t\t\tUseful together with panic=30 to trigger a reboot.\n\n\tpage_alloc.shuffle=\n\t\t\t[KNL] Boolean flag to control whether the page allocator\n\t\t\tshould randomize its free lists. The randomization may\n\t\t\tbe automatically enabled if the kernel detects it is\n\t\t\trunning on a platform with a direct-mapped memory-side\n\t\t\tcache, and this parameter can be used to\n\t\t\toverride/disable that behavior. The state of the flag\n\t\t\tcan be read from sysfs at:\n\t\t\t/sys/module/page_alloc/parameters/shuffle.\n\n\tpage_owner=\t[KNL] Boot-time page_owner enabling option.\n\t\t\tStorage of the information about who allocated\n\t\t\teach page is disabled in default. With this switch,\n\t\t\twe can turn it on.\n\t\t\ton: enable the feature\n\n\tpage_poison=\t[KNL] Boot-time parameter changing the state of\n\t\t\tpoisoning on the buddy allocator, available with\n\t\t\tCONFIG_PAGE_POISONING=y.\n\t\t\toff: turn off poisoning (default)\n\t\t\ton: turn on poisoning\n\n\tpanic=\t\t[KNL] Kernel behaviour on panic: delay <timeout>\n\t\t\ttimeout > 0: seconds before rebooting\n\t\t\ttimeout = 0: wait forever\n\t\t\ttimeout < 0: reboot immediately\n\t\t\tFormat: <timeout>\n\n\tpanic_print=\tBitmask for printing system info when panic happens.\n\t\t\tUser can chose combination of the following bits:\n\t\t\tbit 0: print all tasks info\n\t\t\tbit 1: print system memory info\n\t\t\tbit 2: print timer info\n\t\t\tbit 3: print locks info if CONFIG_LOCKDEP is on\n\t\t\tbit 4: print ftrace buffer\n\t\t\tbit 5: print all printk messages in buffer\n\n\tpanic_on_taint=\tBitmask for conditionally calling panic() in add_taint()\n\t\t\tFormat: <hex>[,nousertaint]\n\t\t\tHexadecimal bitmask representing the set of TAINT flags\n\t\t\tthat will cause the kernel to panic when add_taint() is\n\t\t\tcalled with any of the flags in this set.\n\t\t\tThe optional switch \"nousertaint\" can be utilized to\n\t\t\tprevent userspace forced crashes by writing to sysctl\n\t\t\t/proc/sys/kernel/tainted any flagset matching with the\n\t\t\tbitmask set on panic_on_taint.\n\t\t\tSee Documentation/admin-guide/tainted-kernels.rst for\n\t\t\textra details on the taint flags that users can pick\n\t\t\tto compose the bitmask to assign to panic_on_taint.\n\n\tpanic_on_warn\tpanic() instead of WARN().  Useful to cause kdump\n\t\t\ton a WARN().\n\n\tcrash_kexec_post_notifiers\n\t\t\tRun kdump after running panic-notifiers and dumping\n\t\t\tkmsg. This only for the users who doubt kdump always\n\t\t\tsucceeds in any situation.\n\t\t\tNote that this also increases risks of kdump failure,\n\t\t\tbecause some panic notifiers can make the crashed\n\t\t\tkernel more unstable.\n\n\tparkbd.port=\t[HW] Parallel port number the keyboard adapter is\n\t\t\tconnected to, default is 0.\n\t\t\tFormat: <parport#>\n\tparkbd.mode=\t[HW] Parallel port keyboard adapter mode of operation,\n\t\t\t0 for XT, 1 for AT (default is AT).\n\t\t\tFormat: <mode>\n\n\tparport=\t[HW,PPT] Specify parallel ports. 0 disables.\n\t\t\tFormat: { 0 | auto | 0xBBB[,IRQ[,DMA]] }\n\t\t\tUse 'auto' to force the driver to use any\n\t\t\tIRQ/DMA settings detected (the default is to\n\t\t\tignore detected IRQ/DMA settings because of\n\t\t\tpossible conflicts). You can specify the base\n\t\t\taddress, IRQ, and DMA settings; IRQ and DMA\n\t\t\tshould be numbers, or 'auto' (for using detected\n\t\t\tsettings on that particular port), or 'nofifo'\n\t\t\t(to avoid using a FIFO even if it is detected).\n\t\t\tParallel ports are assigned in the order they\n\t\t\tare specified on the command line, starting\n\t\t\twith parport0.\n\n\tparport_init_mode=\t[HW,PPT]\n\t\t\tConfigure VIA parallel port to operate in\n\t\t\ta specific mode. This is necessary on Pegasos\n\t\t\tcomputer where firmware has no options for setting\n\t\t\tup parallel port mode and sets it to spp.\n\t\t\tCurrently this function knows 686a and 8231 chips.\n\t\t\tFormat: [spp|ps2|epp|ecp|ecpepp]\n\n\tpause_on_oops=\n\t\t\tHalt all CPUs after the first oops has been printed for\n\t\t\tthe specified number of seconds.  This is to be used if\n\t\t\tyour oopses keep scrolling off the screen.\n\n\tpcbit=\t\t[HW,ISDN]\n\n\tpcd.\t\t[PARIDE]\n\t\t\tSee header of drivers/block/paride/pcd.c.\n\t\t\tSee also Documentation/admin-guide/blockdev/paride.rst.\n\n\tpci=option[,option...]\t[PCI] various PCI subsystem options.\n\n\t\t\t\tSome options herein operate on a specific device\n\t\t\t\tor a set of devices (<pci_dev>). These are\n\t\t\t\tspecified in one of the following formats:\n\n\t\t\t\t[<domain>:]<bus>:<dev>.<func>[/<dev>.<func>]*\n\t\t\t\tpci:<vendor>:<device>[:<subvendor>:<subdevice>]\n\n\t\t\t\tNote: the first format specifies a PCI\n\t\t\t\tbus/device/function address which may change\n\t\t\t\tif new hardware is inserted, if motherboard\n\t\t\t\tfirmware changes, or due to changes caused\n\t\t\t\tby other kernel parameters. If the\n\t\t\t\tdomain is left unspecified, it is\n\t\t\t\ttaken to be zero. Optionally, a path\n\t\t\t\tto a device through multiple device/function\n\t\t\t\taddresses can be specified after the base\n\t\t\t\taddress (this is more robust against\n\t\t\t\trenumbering issues).  The second format\n\t\t\t\tselects devices using IDs from the\n\t\t\t\tconfiguration space which may match multiple\n\t\t\t\tdevices in the system.\n\n\t\tearlydump\tdump PCI config space before the kernel\n\t\t\t\tchanges anything\n\t\toff\t\t[X86] don't probe for the PCI bus\n\t\tbios\t\t[X86-32] force use of PCI BIOS, don't access\n\t\t\t\tthe hardware directly. Use this if your machine\n\t\t\t\thas a non-standard PCI host bridge.\n\t\tnobios\t\t[X86-32] disallow use of PCI BIOS, only direct\n\t\t\t\thardware access methods are allowed. Use this\n\t\t\t\tif you experience crashes upon bootup and you\n\t\t\t\tsuspect they are caused by the BIOS.\n\t\tconf1\t\t[X86] Force use of PCI Configuration Access\n\t\t\t\tMechanism 1 (config address in IO port 0xCF8,\n\t\t\t\tdata in IO port 0xCFC, both 32-bit).\n\t\tconf2\t\t[X86] Force use of PCI Configuration Access\n\t\t\t\tMechanism 2 (IO port 0xCF8 is an 8-bit port for\n\t\t\t\tthe function, IO port 0xCFA, also 8-bit, sets\n\t\t\t\tbus number. The config space is then accessed\n\t\t\t\tthrough ports 0xC000-0xCFFF).\n\t\t\t\tSee http://wiki.osdev.org/PCI for more info\n\t\t\t\ton the configuration access mechanisms.\n\t\tnoaer\t\t[PCIE] If the PCIEAER kernel config parameter is\n\t\t\t\tenabled, this kernel boot option can be used to\n\t\t\t\tdisable the use of PCIE advanced error reporting.\n\t\tnodomains\t[PCI] Disable support for multiple PCI\n\t\t\t\troot domains (aka PCI segments, in ACPI-speak).\n\t\tnommconf\t[X86] Disable use of MMCONFIG for PCI\n\t\t\t\tConfiguration\n\t\tcheck_enable_amd_mmconf [X86] check for and enable\n\t\t\t\tproperly configured MMIO access to PCI\n\t\t\t\tconfig space on AMD family 10h CPU\n\t\tnomsi\t\t[MSI] If the PCI_MSI kernel config parameter is\n\t\t\t\tenabled, this kernel boot option can be used to\n\t\t\t\tdisable the use of MSI interrupts system-wide.\n\t\tnoioapicquirk\t[APIC] Disable all boot interrupt quirks.\n\t\t\t\tSafety option to keep boot IRQs enabled. This\n\t\t\t\tshould never be necessary.\n\t\tioapicreroute\t[APIC] Enable rerouting of boot IRQs to the\n\t\t\t\tprimary IO-APIC for bridges that cannot disable\n\t\t\t\tboot IRQs. This fixes a source of spurious IRQs\n\t\t\t\twhen the system masks IRQs.\n\t\tnoioapicreroute\t[APIC] Disable workaround that uses the\n\t\t\t\tboot IRQ equivalent of an IRQ that connects to\n\t\t\t\ta chipset where boot IRQs cannot be disabled.\n\t\t\t\tThe opposite of ioapicreroute.\n\t\tbiosirq\t\t[X86-32] Use PCI BIOS calls to get the interrupt\n\t\t\t\trouting table. These calls are known to be buggy\n\t\t\t\ton several machines and they hang the machine\n\t\t\t\twhen used, but on other computers it's the only\n\t\t\t\tway to get the interrupt routing table. Try\n\t\t\t\tthis option if the kernel is unable to allocate\n\t\t\t\tIRQs or discover secondary PCI buses on your\n\t\t\t\tmotherboard.\n\t\trom\t\t[X86] Assign address space to expansion ROMs.\n\t\t\t\tUse with caution as certain devices share\n\t\t\t\taddress decoders between ROMs and other\n\t\t\t\tresources.\n\t\tnorom\t\t[X86] Do not assign address space to\n\t\t\t\texpansion ROMs that do not already have\n\t\t\t\tBIOS assigned address ranges.\n\t\tnobar\t\t[X86] Do not assign address space to the\n\t\t\t\tBARs that weren't assigned by the BIOS.\n\t\tirqmask=0xMMMM\t[X86] Set a bit mask of IRQs allowed to be\n\t\t\t\tassigned automatically to PCI devices. You can\n\t\t\t\tmake the kernel exclude IRQs of your ISA cards\n\t\t\t\tthis way.\n\t\tpirqaddr=0xAAAAA\t[X86] Specify the physical address\n\t\t\t\tof the PIRQ table (normally generated\n\t\t\t\tby the BIOS) if it is outside the\n\t\t\t\tF0000h-100000h range.\n\t\tlastbus=N\t[X86] Scan all buses thru bus #N. Can be\n\t\t\t\tuseful if the kernel is unable to find your\n\t\t\t\tsecondary buses and you want to tell it\n\t\t\t\texplicitly which ones they are.\n\t\tassign-busses\t[X86] Always assign all PCI bus\n\t\t\t\tnumbers ourselves, overriding\n\t\t\t\twhatever the firmware may have done.\n\t\tusepirqmask\t[X86] Honor the possible IRQ mask stored\n\t\t\t\tin the BIOS $PIR table. This is needed on\n\t\t\t\tsome systems with broken BIOSes, notably\n\t\t\t\tsome HP Pavilion N5400 and Omnibook XE3\n\t\t\t\tnotebooks. This will have no effect if ACPI\n\t\t\t\tIRQ routing is enabled.\n\t\tnoacpi\t\t[X86] Do not use ACPI for IRQ routing\n\t\t\t\tor for PCI scanning.\n\t\tuse_crs\t\t[X86] Use PCI host bridge window information\n\t\t\t\tfrom ACPI.  On BIOSes from 2008 or later, this\n\t\t\t\tis enabled by default.  If you need to use this,\n\t\t\t\tplease report a bug.\n\t\tnocrs\t\t[X86] Ignore PCI host bridge windows from ACPI.\n\t\t\t\tIf you need to use this, please report a bug.\n\t\trouteirq\tDo IRQ routing for all PCI devices.\n\t\t\t\tThis is normally done in pci_enable_device(),\n\t\t\t\tso this option is a temporary workaround\n\t\t\t\tfor broken drivers that don't call it.\n\t\tskip_isa_align\t[X86] do not align io start addr, so can\n\t\t\t\thandle more pci cards\n\t\tnoearly\t\t[X86] Don't do any early type 1 scanning.\n\t\t\t\tThis might help on some broken boards which\n\t\t\t\tmachine check when some devices' config space\n\t\t\t\tis read. But various workarounds are disabled\n\t\t\t\tand some IOMMU drivers will not work.\n\t\tbfsort\t\tSort PCI devices into breadth-first order.\n\t\t\t\tThis sorting is done to get a device\n\t\t\t\torder compatible with older (<= 2.4) kernels.\n\t\tnobfsort\tDon't sort PCI devices into breadth-first order.\n\t\tpcie_bus_tune_off\tDisable PCIe MPS (Max Payload Size)\n\t\t\t\ttuning and use the BIOS-configured MPS defaults.\n\t\tpcie_bus_safe\tSet every device's MPS to the largest value\n\t\t\t\tsupported by all devices below the root complex.\n\t\tpcie_bus_perf\tSet device MPS to the largest allowable MPS\n\t\t\t\tbased on its parent bus. Also set MRRS (Max\n\t\t\t\tRead Request Size) to the largest supported\n\t\t\t\tvalue (no larger than the MPS that the device\n\t\t\t\tor bus can support) for best performance.\n\t\tpcie_bus_peer2peer\tSet every device's MPS to 128B, which\n\t\t\t\tevery device is guaranteed to support. This\n\t\t\t\tconfiguration allows peer-to-peer DMA between\n\t\t\t\tany pair of devices, possibly at the cost of\n\t\t\t\treduced performance.  This also guarantees\n\t\t\t\tthat hot-added devices will work.\n\t\tcbiosize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for the CardBus bridge's IO window.\n\t\t\t\tThe default value is 256 bytes.\n\t\tcbmemsize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for the CardBus bridge's memory\n\t\t\t\twindow. The default value is 64 megabytes.\n\t\tresource_alignment=\n\t\t\t\tFormat:\n\t\t\t\t[<order of align>@]<pci_dev>[; ...]\n\t\t\t\tSpecifies alignment and device to reassign\n\t\t\t\taligned memory resources. How to\n\t\t\t\tspecify the device is described above.\n\t\t\t\tIf <order of align> is not specified,\n\t\t\t\tPAGE_SIZE is used as alignment.\n\t\t\t\tA PCI-PCI bridge can be specified if resource\n\t\t\t\twindows need to be expanded.\n\t\t\t\tTo specify the alignment for several\n\t\t\t\tinstances of a device, the PCI vendor,\n\t\t\t\tdevice, subvendor, and subdevice may be\n\t\t\t\tspecified, e.g., 12@pci:8086:9c22:103c:198f\n\t\t\t\tfor 4096-byte alignment.\n\t\tecrc=\t\tEnable/disable PCIe ECRC (transaction layer\n\t\t\t\tend-to-end CRC checking).\n\t\t\t\tbios: Use BIOS/firmware settings. This is the\n\t\t\t\tthe default.\n\t\t\t\toff: Turn ECRC off\n\t\t\t\ton: Turn ECRC on.\n\t\thpiosize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for hotplug bridge's IO window.\n\t\t\t\tDefault size is 256 bytes.\n\t\thpmmiosize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for hotplug bridge's MMIO window.\n\t\t\t\tDefault size is 2 megabytes.\n\t\thpmmioprefsize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for hotplug bridge's MMIO_PREF window.\n\t\t\t\tDefault size is 2 megabytes.\n\t\thpmemsize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for hotplug bridge's MMIO and\n\t\t\t\tMMIO_PREF window.\n\t\t\t\tDefault size is 2 megabytes.\n\t\thpbussize=nn\tThe minimum amount of additional bus numbers\n\t\t\t\treserved for buses below a hotplug bridge.\n\t\t\t\tDefault is 1.\n\t\trealloc=\tEnable/disable reallocating PCI bridge resources\n\t\t\t\tif allocations done by BIOS are too small to\n\t\t\t\taccommodate resources required by all child\n\t\t\t\tdevices.\n\t\t\t\toff: Turn realloc off\n\t\t\t\ton: Turn realloc on\n\t\trealloc\t\tsame as realloc=on\n\t\tnoari\t\tdo not use PCIe ARI.\n\t\tnoats\t\t[PCIE, Intel-IOMMU, AMD-IOMMU]\n\t\t\t\tdo not use PCIe ATS (and IOMMU device IOTLB).\n\t\tpcie_scan_all\tScan all possible PCIe devices.  Otherwise we\n\t\t\t\tonly look for one device below a PCIe downstream\n\t\t\t\tport.\n\t\tbig_root_window\tTry to add a big 64bit memory window to the PCIe\n\t\t\t\troot complex on AMD CPUs. Some GFX hardware\n\t\t\t\tcan resize a BAR to allow access to all VRAM.\n\t\t\t\tAdding the window is slightly risky (it may\n\t\t\t\tconflict with unreported devices), so this\n\t\t\t\ttaints the kernel.\n\t\tdisable_acs_redir=<pci_dev>[; ...]\n\t\t\t\tSpecify one or more PCI devices (in the format\n\t\t\t\tspecified above) separated by semicolons.\n\t\t\t\tEach device specified will have the PCI ACS\n\t\t\t\tredirect capabilities forced off which will\n\t\t\t\tallow P2P traffic between devices through\n\t\t\t\tbridges without forcing it upstream. Note:\n\t\t\t\tthis removes isolation between devices and\n\t\t\t\tmay put more devices in an IOMMU group.\n\t\tforce_floating\t[S390] Force usage of floating interrupts.\n\t\tnomio\t\t[S390] Do not use MIO instructions.\n\t\tnorid\t\t[S390] ignore the RID field and force use of\n\t\t\t\tone PCI domain per PCI function\n\n\tpcie_aspm=\t[PCIE] Forcibly enable or disable PCIe Active State Power\n\t\t\tManagement.\n\t\toff\tDisable ASPM.\n\t\tforce\tEnable ASPM even on devices that claim not to support it.\n\t\t\tWARNING: Forcing ASPM on may cause system lockups.\n\n\tpcie_ports=\t[PCIE] PCIe port services handling:\n\t\tnative\tUse native PCIe services (PME, AER, DPC, PCIe hotplug)\n\t\t\teven if the platform doesn't give the OS permission to\n\t\t\tuse them.  This may cause conflicts if the platform\n\t\t\talso tries to use these services.\n\t\tdpc-native\tUse native PCIe service for DPC only.  May\n\t\t\t\tcause conflicts if firmware uses AER or DPC.\n\t\tcompat\tDisable native PCIe services (PME, AER, DPC, PCIe\n\t\t\thotplug).\n\n\tpcie_port_pm=\t[PCIE] PCIe port power management handling:\n\t\toff\tDisable power management of all PCIe ports\n\t\tforce\tForcibly enable power management of all PCIe ports\n\n\tpcie_pme=\t[PCIE,PM] Native PCIe PME signaling options:\n\t\tnomsi\tDo not use MSI for native PCIe PME signaling (this makes\n\t\t\tall PCIe root ports use INTx for all services).\n\n\tpcmv=\t\t[HW,PCMCIA] BadgePAD 4\n\n\tpd_ignore_unused\n\t\t\t[PM]\n\t\t\tKeep all power-domains already enabled by bootloader on,\n\t\t\teven if no driver has claimed them. This is useful\n\t\t\tfor debug and development, but should not be\n\t\t\tneeded on a platform with proper driver support.\n\n\tpd.\t\t[PARIDE]\n\t\t\tSee Documentation/admin-guide/blockdev/paride.rst.\n\n\tpdcchassis=\t[PARISC,HW] Disable/Enable PDC Chassis Status codes at\n\t\t\tboot time.\n\t\t\tFormat: { 0 | 1 }\n\t\t\tSee arch/parisc/kernel/pdc_chassis.c\n\n\tpercpu_alloc=\tSelect which percpu first chunk allocator to use.\n\t\t\tCurrently supported values are \"embed\" and \"page\".\n\t\t\tArchs may support subset or none of the\tselections.\n\t\t\tSee comments in mm/percpu.c for details on each\n\t\t\tallocator.  This parameter is primarily\tfor debugging\n\t\t\tand performance comparison.\n\n\tpf.\t\t[PARIDE]\n\t\t\tSee Documentation/admin-guide/blockdev/paride.rst.\n\n\tpg.\t\t[PARIDE]\n\t\t\tSee Documentation/admin-guide/blockdev/paride.rst.\n\n\tpirq=\t\t[SMP,APIC] Manual mp-table setup\n\t\t\tSee Documentation/x86/i386/IO-APIC.rst.\n\n\tplip=\t\t[PPT,NET] Parallel port network link\n\t\t\tFormat: { parport<nr> | timid | 0 }\n\t\t\tSee also Documentation/admin-guide/parport.rst.\n\n\tpmtmr=\t\t[X86] Manual setup of pmtmr I/O Port.\n\t\t\tOverride pmtimer IOPort with a hex value.\n\t\t\te.g. pmtmr=0x508\n\n\tpm_debug_messages\t[SUSPEND,KNL]\n\t\t\tEnable suspend/resume debug messages during boot up.\n\n\tpnp.debug=1\t[PNP]\n\t\t\tEnable PNP debug messages (depends on the\n\t\t\tCONFIG_PNP_DEBUG_MESSAGES option).  Change at run-time\n\t\t\tvia /sys/module/pnp/parameters/debug.  We always show\n\t\t\tcurrent resource usage; turning this on also shows\n\t\t\tpossible settings and some assignment information.\n\n\tpnpacpi=\t[ACPI]\n\t\t\t{ off }\n\n\tpnpbios=\t[ISAPNP]\n\t\t\t{ on | off | curr | res | no-curr | no-res }\n\n\tpnp_reserve_irq=\n\t\t\t[ISAPNP] Exclude IRQs for the autoconfiguration\n\n\tpnp_reserve_dma=\n\t\t\t[ISAPNP] Exclude DMAs for the autoconfiguration\n\n\tpnp_reserve_io=\t[ISAPNP] Exclude I/O ports for the autoconfiguration\n\t\t\tRanges are in pairs (I/O port base and size).\n\n\tpnp_reserve_mem=\n\t\t\t[ISAPNP] Exclude memory regions for the\n\t\t\tautoconfiguration.\n\t\t\tRanges are in pairs (memory base and size).\n\n\tports=\t\t[IP_VS_FTP] IPVS ftp helper module\n\t\t\tDefault is 21.\n\t\t\tUp to 8 (IP_VS_APP_MAX_PORTS) ports\n\t\t\tmay be specified.\n\t\t\tFormat: <port>,<port>....\n\n\tpowersave=off\t[PPC] This option disables power saving features.\n\t\t\tIt specifically disables cpuidle and sets the\n\t\t\tplatform machine description specific power_save\n\t\t\tfunction to NULL. On Idle the CPU just reduces\n\t\t\texecution priority.\n\n\tppc_strict_facility_enable\n\t\t\t[PPC] This option catches any kernel floating point,\n\t\t\tAltivec, VSX and SPE outside of regions specifically\n\t\t\tallowed (eg kernel_enable_fpu()/kernel_disable_fpu()).\n\t\t\tThere is some performance impact when enabling this.\n\n\tppc_tm=\t\t[PPC]\n\t\t\tFormat: {\"off\"}\n\t\t\tDisable Hardware Transactional Memory\n\n\tprint-fatal-signals=\n\t\t\t[KNL] debug: print fatal signals\n\n\t\t\tIf enabled, warn about various signal handling\n\t\t\trelated application anomalies: too many signals,\n\t\t\ttoo many POSIX.1 timers, fatal signals causing a\n\t\t\tcoredump - etc.\n\n\t\t\tIf you hit the warning due to signal overflow,\n\t\t\tyou might want to try \"ulimit -i unlimited\".\n\n\t\t\tdefault: off.\n\n\tprintk.always_kmsg_dump=\n\t\t\tTrigger kmsg_dump for cases other than kernel oops or\n\t\t\tpanics\n\t\t\tFormat: <bool>  (1/Y/y=enable, 0/N/n=disable)\n\t\t\tdefault: disabled\n\n\tprintk.devkmsg={on,off,ratelimit}\n\t\t\tControl writing to /dev/kmsg.\n\t\t\ton - unlimited logging to /dev/kmsg from userspace\n\t\t\toff - logging to /dev/kmsg disabled\n\t\t\tratelimit - ratelimit the logging\n\t\t\tDefault: ratelimit\n\n\tprintk.time=\tShow timing data prefixed to each printk message line\n\t\t\tFormat: <bool>  (1/Y/y=enable, 0/N/n=disable)\n\n\tprocessor.max_cstate=\t[HW,ACPI]\n\t\t\tLimit processor to maximum C-state\n\t\t\tmax_cstate=9 overrides any DMI blacklist limit.\n\n\tprocessor.nocst\t[HW,ACPI]\n\t\t\tIgnore the _CST method to determine C-states,\n\t\t\tinstead using the legacy FADT method\n\n\tprofile=\t[KNL] Enable kernel profiling via /proc/profile\n\t\t\tFormat: [<profiletype>,]<number>\n\t\t\tParam: <profiletype>: \"schedule\", \"sleep\", or \"kvm\"\n\t\t\t\t[defaults to kernel profiling]\n\t\t\tParam: \"schedule\" - profile schedule points.\n\t\t\tParam: \"sleep\" - profile D-state sleeping (millisecs).\n\t\t\t\tRequires CONFIG_SCHEDSTATS\n\t\t\tParam: \"kvm\" - profile VM exits.\n\t\t\tParam: <number> - step/bucket size as a power of 2 for\n\t\t\t\tstatistical time based profiling.\n\n\tprompt_ramdisk=\t[RAM] List of RAM disks to prompt for floppy disk\n\t\t\tbefore loading.\n\t\t\tSee Documentation/admin-guide/blockdev/ramdisk.rst.\n\n\tprot_virt=\t[S390] enable hosting protected virtual machines\n\t\t\tisolated from the hypervisor (if hardware supports\n\t\t\tthat).\n\t\t\tFormat: <bool>\n\n\tpsi=\t\t[KNL] Enable or disable pressure stall information\n\t\t\ttracking.\n\t\t\tFormat: <bool>\n\n\tpsmouse.proto=\t[HW,MOUSE] Highest PS2 mouse protocol extension to\n\t\t\tprobe for; one of (bare|imps|exps|lifebook|any).\n\tpsmouse.rate=\t[HW,MOUSE] Set desired mouse report rate, in reports\n\t\t\tper second.\n\tpsmouse.resetafter=\t[HW,MOUSE]\n\t\t\tTry to reset the device after so many bad packets\n\t\t\t(0 = never).\n\tpsmouse.resolution=\n\t\t\t[HW,MOUSE] Set desired mouse resolution, in dpi.\n\tpsmouse.smartscroll=\n\t\t\t[HW,MOUSE] Controls Logitech smartscroll autorepeat.\n\t\t\t0 = disabled, 1 = enabled (default).\n\n\tpstore.backend=\tSpecify the name of the pstore backend to use\n\n\tpt.\t\t[PARIDE]\n\t\t\tSee Documentation/admin-guide/blockdev/paride.rst.\n\n\tpti=\t\t[X86-64] Control Page Table Isolation of user and\n\t\t\tkernel address spaces.  Disabling this feature\n\t\t\tremoves hardening, but improves performance of\n\t\t\tsystem calls and interrupts.\n\n\t\t\ton   - unconditionally enable\n\t\t\toff  - unconditionally disable\n\t\t\tauto - kernel detects whether your CPU model is\n\t\t\t       vulnerable to issues that PTI mitigates\n\n\t\t\tNot specifying this option is equivalent to pti=auto.\n\n\tnopti\t\t[X86-64]\n\t\t\tEquivalent to pti=off\n\n\tpty.legacy_count=\n\t\t\t[KNL] Number of legacy pty's. Overwrites compiled-in\n\t\t\tdefault number.\n\n\tquiet\t\t[KNL] Disable most log messages\n\n\tr128=\t\t[HW,DRM]\n\n\traid=\t\t[HW,RAID]\n\t\t\tSee Documentation/admin-guide/md.rst.\n\n\tramdisk_size=\t[RAM] Sizes of RAM disks in kilobytes\n\t\t\tSee Documentation/admin-guide/blockdev/ramdisk.rst.\n\n\trandom.trust_cpu={on,off}\n\t\t\t[KNL] Enable or disable trusting the use of the\n\t\t\tCPU's random number generator (if available) to\n\t\t\tfully seed the kernel's CRNG. Default is controlled\n\t\t\tby CONFIG_RANDOM_TRUST_CPU.\n\n\tras=option[,option,...]\t[KNL] RAS-specific options\n\n\t\tcec_disable\t[X86]\n\t\t\t\tDisable the Correctable Errors Collector,\n\t\t\t\tsee CONFIG_RAS_CEC help text.\n\n\trcu_nocbs=\t[KNL]\n\t\t\tThe argument is a cpu list, as described above,\n\t\t\texcept that the string \"all\" can be used to\n\t\t\tspecify every CPU on the system.\n\n\t\t\tIn kernels built with CONFIG_RCU_NOCB_CPU=y, set\n\t\t\tthe specified list of CPUs to be no-callback CPUs.\n\t\t\tInvocation of these CPUs' RCU callbacks will be\n\t\t\toffloaded to \"rcuox/N\" kthreads created for that\n\t\t\tpurpose, where \"x\" is \"p\" for RCU-preempt, and\n\t\t\t\"s\" for RCU-sched, and \"N\" is the CPU number.\n\t\t\tThis reduces OS jitter on the offloaded CPUs,\n\t\t\twhich can be useful for HPC and real-time\n\t\t\tworkloads.  It can also improve energy efficiency\n\t\t\tfor asymmetric multiprocessors.\n\n\trcu_nocb_poll\t[KNL]\n\t\t\tRather than requiring that offloaded CPUs\n\t\t\t(specified by rcu_nocbs= above) explicitly\n\t\t\tawaken the corresponding \"rcuoN\" kthreads,\n\t\t\tmake these kthreads poll for callbacks.\n\t\t\tThis improves the real-time response for the\n\t\t\toffloaded CPUs by relieving them of the need to\n\t\t\twake up the corresponding kthread, but degrades\n\t\t\tenergy efficiency by requiring that the kthreads\n\t\t\tperiodically wake up to do the polling.\n\n\trcutree.blimit=\t[KNL]\n\t\t\tSet maximum number of finished RCU callbacks to\n\t\t\tprocess in one batch.\n\n\trcutree.dump_tree=\t[KNL]\n\t\t\tDump the structure of the rcu_node combining tree\n\t\t\tout at early boot.  This is used for diagnostic\n\t\t\tpurposes, to verify correct tree setup.\n\n\trcutree.gp_cleanup_delay=\t[KNL]\n\t\t\tSet the number of jiffies to delay each step of\n\t\t\tRCU grace-period cleanup.\n\n\trcutree.gp_init_delay=\t[KNL]\n\t\t\tSet the number of jiffies to delay each step of\n\t\t\tRCU grace-period initialization.\n\n\trcutree.gp_preinit_delay=\t[KNL]\n\t\t\tSet the number of jiffies to delay each step of\n\t\t\tRCU grace-period pre-initialization, that is,\n\t\t\tthe propagation of recent CPU-hotplug changes up\n\t\t\tthe rcu_node combining tree.\n\n\trcutree.use_softirq=\t[KNL]\n\t\t\tIf set to zero, move all RCU_SOFTIRQ processing to\n\t\t\tper-CPU rcuc kthreads.  Defaults to a non-zero\n\t\t\tvalue, meaning that RCU_SOFTIRQ is used by default.\n\t\t\tSpecify rcutree.use_softirq=0 to use rcuc kthreads.\n\n\trcutree.rcu_fanout_exact= [KNL]\n\t\t\tDisable autobalancing of the rcu_node combining\n\t\t\ttree.  This is used by rcutorture, and might\n\t\t\tpossibly be useful for architectures having high\n\t\t\tcache-to-cache transfer latencies.\n\n\trcutree.rcu_fanout_leaf= [KNL]\n\t\t\tChange the number of CPUs assigned to each\n\t\t\tleaf rcu_node structure.  Useful for very\n\t\t\tlarge systems, which will choose the value 64,\n\t\t\tand for NUMA systems with large remote-access\n\t\t\tlatencies, which will choose a value aligned\n\t\t\twith the appropriate hardware boundaries.\n\n\trcutree.rcu_min_cached_objs= [KNL]\n\t\t\tMinimum number of objects which are cached and\n\t\t\tmaintained per one CPU. Object size is equal\n\t\t\tto PAGE_SIZE. The cache allows to reduce the\n\t\t\tpressure to page allocator, also it makes the\n\t\t\twhole algorithm to behave better in low memory\n\t\t\tcondition.\n\n\trcutree.jiffies_till_first_fqs= [KNL]\n\t\t\tSet delay from grace-period initialization to\n\t\t\tfirst attempt to force quiescent states.\n\t\t\tUnits are jiffies, minimum value is zero,\n\t\t\tand maximum value is HZ.\n\n\trcutree.jiffies_till_next_fqs= [KNL]\n\t\t\tSet delay between subsequent attempts to force\n\t\t\tquiescent states.  Units are jiffies, minimum\n\t\t\tvalue is one, and maximum value is HZ.\n\n\trcutree.jiffies_till_sched_qs= [KNL]\n\t\t\tSet required age in jiffies for a\n\t\t\tgiven grace period before RCU starts\n\t\t\tsoliciting quiescent-state help from\n\t\t\trcu_note_context_switch() and cond_resched().\n\t\t\tIf not specified, the kernel will calculate\n\t\t\ta value based on the most recent settings\n\t\t\tof rcutree.jiffies_till_first_fqs\n\t\t\tand rcutree.jiffies_till_next_fqs.\n\t\t\tThis calculated value may be viewed in\n\t\t\trcutree.jiffies_to_sched_qs.  Any attempt to set\n\t\t\trcutree.jiffies_to_sched_qs will be cheerfully\n\t\t\toverwritten.\n\n\trcutree.kthread_prio= \t [KNL,BOOT]\n\t\t\tSet the SCHED_FIFO priority of the RCU per-CPU\n\t\t\tkthreads (rcuc/N). This value is also used for\n\t\t\tthe priority of the RCU boost threads (rcub/N)\n\t\t\tand for the RCU grace-period kthreads (rcu_bh,\n\t\t\trcu_preempt, and rcu_sched). If RCU_BOOST is\n\t\t\tset, valid values are 1-99 and the default is 1\n\t\t\t(the least-favored priority).  Otherwise, when\n\t\t\tRCU_BOOST is not set, valid values are 0-99 and\n\t\t\tthe default is zero (non-realtime operation).\n\n\trcutree.rcu_nocb_gp_stride= [KNL]\n\t\t\tSet the number of NOCB callback kthreads in\n\t\t\teach group, which defaults to the square root\n\t\t\tof the number of CPUs.\tLarger numbers reduce\n\t\t\tthe wakeup overhead on the global grace-period\n\t\t\tkthread, but increases that same overhead on\n\t\t\teach group's NOCB grace-period kthread.\n\n\trcutree.qhimark= [KNL]\n\t\t\tSet threshold of queued RCU callbacks beyond which\n\t\t\tbatch limiting is disabled.\n\n\trcutree.qlowmark= [KNL]\n\t\t\tSet threshold of queued RCU callbacks below which\n\t\t\tbatch limiting is re-enabled.\n\n\trcutree.qovld= [KNL]\n\t\t\tSet threshold of queued RCU callbacks beyond which\n\t\t\tRCU's force-quiescent-state scan will aggressively\n\t\t\tenlist help from cond_resched() and sched IPIs to\n\t\t\thelp CPUs more quickly reach quiescent states.\n\t\t\tSet to less than zero to make this be set based\n\t\t\ton rcutree.qhimark at boot time and to zero to\n\t\t\tdisable more aggressive help enlistment.\n\n\trcutree.rcu_idle_gp_delay= [KNL]\n\t\t\tSet wakeup interval for idle CPUs that have\n\t\t\tRCU callbacks (RCU_FAST_NO_HZ=y).\n\n\trcutree.rcu_idle_lazy_gp_delay= [KNL]\n\t\t\tSet wakeup interval for idle CPUs that have\n\t\t\tonly \"lazy\" RCU callbacks (RCU_FAST_NO_HZ=y).\n\t\t\tLazy RCU callbacks are those which RCU can\n\t\t\tprove do nothing more than free memory.\n\n\trcutree.rcu_kick_kthreads= [KNL]\n\t\t\tCause the grace-period kthread to get an extra\n\t\t\twake_up() if it sleeps three times longer than\n\t\t\tit should at force-quiescent-state time.\n\t\t\tThis wake_up() will be accompanied by a\n\t\t\tWARN_ONCE() splat and an ftrace_dump().\n\n\trcutree.sysrq_rcu= [KNL]\n\t\t\tCommandeer a sysrq key to dump out Tree RCU's\n\t\t\trcu_node tree with an eye towards determining\n\t\t\twhy a new grace period has not yet started.\n\n\trcuperf.gp_async= [KNL]\n\t\t\tMeasure performance of asynchronous\n\t\t\tgrace-period primitives such as call_rcu().\n\n\trcuperf.gp_async_max= [KNL]\n\t\t\tSpecify the maximum number of outstanding\n\t\t\tcallbacks per writer thread.  When a writer\n\t\t\tthread exceeds this limit, it invokes the\n\t\t\tcorresponding flavor of rcu_barrier() to allow\n\t\t\tpreviously posted callbacks to drain.\n\n\trcuperf.gp_exp= [KNL]\n\t\t\tMeasure performance of expedited synchronous\n\t\t\tgrace-period primitives.\n\n\trcuperf.holdoff= [KNL]\n\t\t\tSet test-start holdoff period.  The purpose of\n\t\t\tthis parameter is to delay the start of the\n\t\t\ttest until boot completes in order to avoid\n\t\t\tinterference.\n\n\trcuperf.kfree_rcu_test= [KNL]\n\t\t\tSet to measure performance of kfree_rcu() flooding.\n\n\trcuperf.kfree_nthreads= [KNL]\n\t\t\tThe number of threads running loops of kfree_rcu().\n\n\trcuperf.kfree_alloc_num= [KNL]\n\t\t\tNumber of allocations and frees done in an iteration.\n\n\trcuperf.kfree_loops= [KNL]\n\t\t\tNumber of loops doing rcuperf.kfree_alloc_num number\n\t\t\tof allocations and frees.\n\n\trcuperf.nreaders= [KNL]\n\t\t\tSet number of RCU readers.  The value -1 selects\n\t\t\tN, where N is the number of CPUs.  A value\n\t\t\t\"n\" less than -1 selects N-n+1, where N is again\n\t\t\tthe number of CPUs.  For example, -2 selects N\n\t\t\t(the number of CPUs), -3 selects N+1, and so on.\n\t\t\tA value of \"n\" less than or equal to -N selects\n\t\t\ta single reader.\n\n\trcuperf.nwriters= [KNL]\n\t\t\tSet number of RCU writers.  The values operate\n\t\t\tthe same as for rcuperf.nreaders.\n\t\t\tN, where N is the number of CPUs\n\n\trcuperf.perf_type= [KNL]\n\t\t\tSpecify the RCU implementation to test.\n\n\trcuperf.shutdown= [KNL]\n\t\t\tShut the system down after performance tests\n\t\t\tcomplete.  This is useful for hands-off automated\n\t\t\ttesting.\n\n\trcuperf.verbose= [KNL]\n\t\t\tEnable additional printk() statements.\n\n\trcuperf.writer_holdoff= [KNL]\n\t\t\tWrite-side holdoff between grace periods,\n\t\t\tin microseconds.  The default of zero says\n\t\t\tno holdoff.\n\n\trcutorture.fqs_duration= [KNL]\n\t\t\tSet duration of force_quiescent_state bursts\n\t\t\tin microseconds.\n\n\trcutorture.fqs_holdoff= [KNL]\n\t\t\tSet holdoff time within force_quiescent_state bursts\n\t\t\tin microseconds.\n\n\trcutorture.fqs_stutter= [KNL]\n\t\t\tSet wait time between force_quiescent_state bursts\n\t\t\tin seconds.\n\n\trcutorture.fwd_progress= [KNL]\n\t\t\tEnable RCU grace-period forward-progress testing\n\t\t\tfor the types of RCU supporting this notion.\n\n\trcutorture.fwd_progress_div= [KNL]\n\t\t\tSpecify the fraction of a CPU-stall-warning\n\t\t\tperiod to do tight-loop forward-progress testing.\n\n\trcutorture.fwd_progress_holdoff= [KNL]\n\t\t\tNumber of seconds to wait between successive\n\t\t\tforward-progress tests.\n\n\trcutorture.fwd_progress_need_resched= [KNL]\n\t\t\tEnclose cond_resched() calls within checks for\n\t\t\tneed_resched() during tight-loop forward-progress\n\t\t\ttesting.\n\n\trcutorture.gp_cond= [KNL]\n\t\t\tUse conditional/asynchronous update-side\n\t\t\tprimitives, if available.\n\n\trcutorture.gp_exp= [KNL]\n\t\t\tUse expedited update-side primitives, if available.\n\n\trcutorture.gp_normal= [KNL]\n\t\t\tUse normal (non-expedited) asynchronous\n\t\t\tupdate-side primitives, if available.\n\n\trcutorture.gp_sync= [KNL]\n\t\t\tUse normal (non-expedited) synchronous\n\t\t\tupdate-side primitives, if available.  If all\n\t\t\tof rcutorture.gp_cond=, rcutorture.gp_exp=,\n\t\t\trcutorture.gp_normal=, and rcutorture.gp_sync=\n\t\t\tare zero, rcutorture acts as if is interpreted\n\t\t\tthey are all non-zero.\n\n\trcutorture.n_barrier_cbs= [KNL]\n\t\t\tSet callbacks/threads for rcu_barrier() testing.\n\n\trcutorture.nfakewriters= [KNL]\n\t\t\tSet number of concurrent RCU writers.  These just\n\t\t\tstress RCU, they don't participate in the actual\n\t\t\ttest, hence the \"fake\".\n\n\trcutorture.nreaders= [KNL]\n\t\t\tSet number of RCU readers.  The value -1 selects\n\t\t\tN-1, where N is the number of CPUs.  A value\n\t\t\t\"n\" less than -1 selects N-n-2, where N is again\n\t\t\tthe number of CPUs.  For example, -2 selects N\n\t\t\t(the number of CPUs), -3 selects N+1, and so on.\n\n\trcutorture.object_debug= [KNL]\n\t\t\tEnable debug-object double-call_rcu() testing.\n\n\trcutorture.onoff_holdoff= [KNL]\n\t\t\tSet time (s) after boot for CPU-hotplug testing.\n\n\trcutorture.onoff_interval= [KNL]\n\t\t\tSet time (jiffies) between CPU-hotplug operations,\n\t\t\tor zero to disable CPU-hotplug testing.\n\n\trcutorture.read_exit= [KNL]\n\t\t\tSet the number of read-then-exit kthreads used\n\t\t\tto test the interaction of RCU updaters and\n\t\t\ttask-exit processing.\n\n\trcutorture.read_exit_burst= [KNL]\n\t\t\tThe number of times in a given read-then-exit\n\t\t\tepisode that a set of read-then-exit kthreads\n\t\t\tis spawned.\n\n\trcutorture.read_exit_delay= [KNL]\n\t\t\tThe delay, in seconds, between successive\n\t\t\tread-then-exit testing episodes.\n\n\trcutorture.shuffle_interval= [KNL]\n\t\t\tSet task-shuffle interval (s).  Shuffling tasks\n\t\t\tallows some CPUs to go into dyntick-idle mode\n\t\t\tduring the rcutorture test.\n\n\trcutorture.shutdown_secs= [KNL]\n\t\t\tSet time (s) after boot system shutdown.  This\n\t\t\tis useful for hands-off automated testing.\n\n\trcutorture.stall_cpu= [KNL]\n\t\t\tDuration of CPU stall (s) to test RCU CPU stall\n\t\t\twarnings, zero to disable.\n\n\trcutorture.stall_cpu_block= [KNL]\n\t\t\tSleep while stalling if set.  This will result\n\t\t\tin warnings from preemptible RCU in addition\n\t\t\tto any other stall-related activity.\n\n\trcutorture.stall_cpu_holdoff= [KNL]\n\t\t\tTime to wait (s) after boot before inducing stall.\n\n\trcutorture.stall_cpu_irqsoff= [KNL]\n\t\t\tDisable interrupts while stalling if set.\n\n\trcutorture.stall_gp_kthread= [KNL]\n\t\t\tDuration (s) of forced sleep within RCU\n\t\t\tgrace-period kthread to test RCU CPU stall\n\t\t\twarnings, zero to disable.  If both stall_cpu\n\t\t\tand stall_gp_kthread are specified, the\n\t\t\tkthread is starved first, then the CPU.\n\n\trcutorture.stat_interval= [KNL]\n\t\t\tTime (s) between statistics printk()s.\n\n\trcutorture.stutter= [KNL]\n\t\t\tTime (s) to stutter testing, for example, specifying\n\t\t\tfive seconds causes the test to run for five seconds,\n\t\t\twait for five seconds, and so on.  This tests RCU's\n\t\t\tability to transition abruptly to and from idle.\n\n\trcutorture.test_boost= [KNL]\n\t\t\tTest RCU priority boosting?  0=no, 1=maybe, 2=yes.\n\t\t\t\"Maybe\" means test if the RCU implementation\n\t\t\tunder test support RCU priority boosting.\n\n\trcutorture.test_boost_duration= [KNL]\n\t\t\tDuration (s) of each individual boost test.\n\n\trcutorture.test_boost_interval= [KNL]\n\t\t\tInterval (s) between each boost test.\n\n\trcutorture.test_no_idle_hz= [KNL]\n\t\t\tTest RCU's dyntick-idle handling.  See also the\n\t\t\trcutorture.shuffle_interval parameter.\n\n\trcutorture.torture_type= [KNL]\n\t\t\tSpecify the RCU implementation to test.\n\n\trcutorture.verbose= [KNL]\n\t\t\tEnable additional printk() statements.\n\n\trcupdate.rcu_cpu_stall_ftrace_dump= [KNL]\n\t\t\tDump ftrace buffer after reporting RCU CPU\n\t\t\tstall warning.\n\n\trcupdate.rcu_cpu_stall_suppress= [KNL]\n\t\t\tSuppress RCU CPU stall warning messages.\n\n\trcupdate.rcu_cpu_stall_suppress_at_boot= [KNL]\n\t\t\tSuppress RCU CPU stall warning messages and\n\t\t\trcutorture writer stall warnings that occur\n\t\t\tduring early boot, that is, during the time\n\t\t\tbefore the init task is spawned.\n\n\trcupdate.rcu_cpu_stall_timeout= [KNL]\n\t\t\tSet timeout for RCU CPU stall warning messages.\n\n\trcupdate.rcu_expedited= [KNL]\n\t\t\tUse expedited grace-period primitives, for\n\t\t\texample, synchronize_rcu_expedited() instead\n\t\t\tof synchronize_rcu().  This reduces latency,\n\t\t\tbut can increase CPU utilization, degrade\n\t\t\treal-time latency, and degrade energy efficiency.\n\t\t\tNo effect on CONFIG_TINY_RCU kernels.\n\n\trcupdate.rcu_normal= [KNL]\n\t\t\tUse only normal grace-period primitives,\n\t\t\tfor example, synchronize_rcu() instead of\n\t\t\tsynchronize_rcu_expedited().  This improves\n\t\t\treal-time latency, CPU utilization, and\n\t\t\tenergy efficiency, but can expose users to\n\t\t\tincreased grace-period latency.  This parameter\n\t\t\toverrides rcupdate.rcu_expedited.  No effect on\n\t\t\tCONFIG_TINY_RCU kernels.\n\n\trcupdate.rcu_normal_after_boot= [KNL]\n\t\t\tOnce boot has completed (that is, after\n\t\t\trcu_end_inkernel_boot() has been invoked), use\n\t\t\tonly normal grace-period primitives.  No effect\n\t\t\ton CONFIG_TINY_RCU kernels.\n\n\trcupdate.rcu_task_ipi_delay= [KNL]\n\t\t\tSet time in jiffies during which RCU tasks will\n\t\t\tavoid sending IPIs, starting with the beginning\n\t\t\tof a given grace period.  Setting a large\n\t\t\tnumber avoids disturbing real-time workloads,\n\t\t\tbut lengthens grace periods.\n\n\trcupdate.rcu_task_stall_timeout= [KNL]\n\t\t\tSet timeout in jiffies for RCU task stall warning\n\t\t\tmessages.  Disable with a value less than or equal\n\t\t\tto zero.\n\n\trcupdate.rcu_self_test= [KNL]\n\t\t\tRun the RCU early boot self tests\n\n\trdinit=\t\t[KNL]\n\t\t\tFormat: <full_path>\n\t\t\tRun specified binary instead of /init from the ramdisk,\n\t\t\tused for early userspace startup. See initrd.\n\n\trdrand=\t\t[X86]\n\t\t\tforce - Override the decision by the kernel to hide the\n\t\t\t\tadvertisement of RDRAND support (this affects\n\t\t\t\tcertain AMD processors because of buggy BIOS\n\t\t\t\tsupport, specifically around the suspend/resume\n\t\t\t\tpath).\n\n\trdt=\t\t[HW,X86,RDT]\n\t\t\tTurn on/off individual RDT features. List is:\n\t\t\tcmt, mbmtotal, mbmlocal, l3cat, l3cdp, l2cat, l2cdp,\n\t\t\tmba.\n\t\t\tE.g. to turn on cmt and turn off mba use:\n\t\t\t\trdt=cmt,!mba\n\n\treboot=\t\t[KNL]\n\t\t\tFormat (x86 or x86_64):\n\t\t\t\t[w[arm] | c[old] | h[ard] | s[oft] | g[pio]] \\\n\t\t\t\t[[,]s[mp]#### \\\n\t\t\t\t[[,]b[ios] | a[cpi] | k[bd] | t[riple] | e[fi] | p[ci]] \\\n\t\t\t\t[[,]f[orce]\n\t\t\tWhere reboot_mode is one of warm (soft) or cold (hard) or gpio\n\t\t\t\t\t(prefix with 'panic_' to set mode for panic\n\t\t\t\t\treboot only),\n\t\t\t      reboot_type is one of bios, acpi, kbd, triple, efi, or pci,\n\t\t\t      reboot_force is either force or not specified,\n\t\t\t      reboot_cpu is s[mp]#### with #### being the processor\n\t\t\t\t\tto be used for rebooting.\n\n\trefscale.holdoff= [KNL]\n\t\t\tSet test-start holdoff period.  The purpose of\n\t\t\tthis parameter is to delay the start of the\n\t\t\ttest until boot completes in order to avoid\n\t\t\tinterference.\n\n\trefscale.loops= [KNL]\n\t\t\tSet the number of loops over the synchronization\n\t\t\tprimitive under test.  Increasing this number\n\t\t\treduces noise due to loop start/end overhead,\n\t\t\tbut the default has already reduced the per-pass\n\t\t\tnoise to a handful of picoseconds on ca. 2020\n\t\t\tx86 laptops.\n\n\trefscale.nreaders= [KNL]\n\t\t\tSet number of readers.  The default value of -1\n\t\t\tselects N, where N is roughly 75% of the number\n\t\t\tof CPUs.  A value of zero is an interesting choice.\n\n\trefscale.nruns= [KNL]\n\t\t\tSet number of runs, each of which is dumped onto\n\t\t\tthe console log.\n\n\trefscale.readdelay= [KNL]\n\t\t\tSet the read-side critical-section duration,\n\t\t\tmeasured in microseconds.\n\n\trefscale.scale_type= [KNL]\n\t\t\tSpecify the read-protection implementation to test.\n\n\trefscale.shutdown= [KNL]\n\t\t\tShut down the system at the end of the performance\n\t\t\ttest.  This defaults to 1 (shut it down) when\n\t\t\trcuperf is built into the kernel and to 0 (leave\n\t\t\tit running) when rcuperf is built as a module.\n\n\trefscale.verbose= [KNL]\n\t\t\tEnable additional printk() statements.\n\n\trelax_domain_level=\n\t\t\t[KNL, SMP] Set scheduler's default relax_domain_level.\n\t\t\tSee Documentation/admin-guide/cgroup-v1/cpusets.rst.\n\n\treserve=\t[KNL,BUGS] Force kernel to ignore I/O ports or memory\n\t\t\tFormat: <base1>,<size1>[,<base2>,<size2>,...]\n\t\t\tReserve I/O ports or memory so the kernel won't use\n\t\t\tthem.  If <base> is less than 0x10000, the region\n\t\t\tis assumed to be I/O ports; otherwise it is memory.\n\n\treservetop=\t[X86-32]\n\t\t\tFormat: nn[KMG]\n\t\t\tReserves a hole at the top of the kernel virtual\n\t\t\taddress space.\n\n\treservelow=\t[X86]\n\t\t\tFormat: nn[K]\n\t\t\tSet the amount of memory to reserve for BIOS at\n\t\t\tthe bottom of the address space.\n\n\treset_devices\t[KNL] Force drivers to reset the underlying device\n\t\t\tduring initialization.\n\n\tresume=\t\t[SWSUSP]\n\t\t\tSpecify the partition device for software suspend\n\t\t\tFormat:\n\t\t\t{/dev/<dev> | PARTUUID=<uuid> | <int>:<int> | <hex>}\n\n\tresume_offset=\t[SWSUSP]\n\t\t\tSpecify the offset from the beginning of the partition\n\t\t\tgiven by \"resume=\" at which the swap header is located,\n\t\t\tin <PAGE_SIZE> units (needed only for swap files).\n\t\t\tSee  Documentation/power/swsusp-and-swap-files.rst\n\n\tresumedelay=\t[HIBERNATION] Delay (in seconds) to pause before attempting to\n\t\t\tread the resume files\n\n\tresumewait\t[HIBERNATION] Wait (indefinitely) for resume device to show up.\n\t\t\tUseful for devices that are detected asynchronously\n\t\t\t(e.g. USB and MMC devices).\n\n\thibernate=\t[HIBERNATION]\n\t\tnoresume\tDon't check if there's a hibernation image\n\t\t\t\tpresent during boot.\n\t\tnocompress\tDon't compress/decompress hibernation images.\n\t\tno\t\tDisable hibernation and resume.\n\t\tprotect_image\tTurn on image protection during restoration\n\t\t\t\t(that will set all pages holding image data\n\t\t\t\tduring restoration read-only).\n\n\tretain_initrd\t[RAM] Keep initrd memory after extraction\n\n\trfkill.default_state=\n\t\t0\t\"airplane mode\".  All wifi, bluetooth, wimax, gps, fm,\n\t\t\tetc. communication is blocked by default.\n\t\t1\tUnblocked.\n\n\trfkill.master_switch_mode=\n\t\t0\tThe \"airplane mode\" button does nothing.\n\t\t1\tThe \"airplane mode\" button toggles between everything\n\t\t\tblocked and the previous configuration.\n\t\t2\tThe \"airplane mode\" button toggles between everything\n\t\t\tblocked and everything unblocked.\n\n\trhash_entries=\t[KNL,NET]\n\t\t\tSet number of hash buckets for route cache\n\n\tring3mwait=disable\n\t\t\t[KNL] Disable ring 3 MONITOR/MWAIT feature on supported\n\t\t\tCPUs.\n\n\tro\t\t[KNL] Mount root device read-only on boot\n\n\trodata=\t\t[KNL]\n\t\ton\tMark read-only kernel memory as read-only (default).\n\t\toff\tLeave read-only kernel memory writable for debugging.\n\n\trockchip.usb_uart\n\t\t\tEnable the uart passthrough on the designated usb port\n\t\t\ton Rockchip SoCs. When active, the signals of the\n\t\t\tdebug-uart get routed to the D+ and D- pins of the usb\n\t\t\tport and the regular usb controller gets disabled.\n\n\troot=\t\t[KNL] Root filesystem\n\t\t\tSee name_to_dev_t comment in init/do_mounts.c.\n\n\trootdelay=\t[KNL] Delay (in seconds) to pause before attempting to\n\t\t\tmount the root filesystem\n\n\trootflags=\t[KNL] Set root filesystem mount option string\n\n\trootfstype=\t[KNL] Set root filesystem type\n\n\trootwait\t[KNL] Wait (indefinitely) for root device to show up.\n\t\t\tUseful for devices that are detected asynchronously\n\t\t\t(e.g. USB and MMC devices).\n\n\trproc_mem=nn[KMG][@address]\n\t\t\t[KNL,ARM,CMA] Remoteproc physical memory block.\n\t\t\tMemory area to be used by remote processor image,\n\t\t\tmanaged by CMA.\n\n\trw\t\t[KNL] Mount root device read-write on boot\n\n\tS\t\t[KNL] Run init in single mode\n\n\ts390_iommu=\t[HW,S390]\n\t\t\tSet s390 IOTLB flushing mode\n\t\tstrict\n\t\t\tWith strict flushing every unmap operation will result in\n\t\t\tan IOTLB flush. Default is lazy flushing before reuse,\n\t\t\twhich is faster.\n\n\tsa1100ir\t[NET]\n\t\t\tSee drivers/net/irda/sa1100_ir.c.\n\n\tsbni=\t\t[NET] Granch SBNI12 leased line adapter\n\n\tsched_debug\t[KNL] Enables verbose scheduler debug messages.\n\n\tschedstats=\t[KNL,X86] Enable or disable scheduled statistics.\n\t\t\tAllowed values are enable and disable. This feature\n\t\t\tincurs a small amount of overhead in the scheduler\n\t\t\tbut is useful for debugging and performance tuning.\n\n\tsched_thermal_decay_shift=\n\t\t\t[KNL, SMP] Set a decay shift for scheduler thermal\n\t\t\tpressure signal. Thermal pressure signal follows the\n\t\t\tdefault decay period of other scheduler pelt\n\t\t\tsignals(usually 32 ms but configurable). Setting\n\t\t\tsched_thermal_decay_shift will left shift the decay\n\t\t\tperiod for the thermal pressure signal by the shift\n\t\t\tvalue.\n\t\t\ti.e. with the default pelt decay period of 32 ms\n\t\t\tsched_thermal_decay_shift   thermal pressure decay pr\n\t\t\t\t1\t\t\t64 ms\n\t\t\t\t2\t\t\t128 ms\n\t\t\tand so on.\n\t\t\tFormat: integer between 0 and 10\n\t\t\tDefault is 0.\n\n\tskew_tick=\t[KNL] Offset the periodic timer tick per cpu to mitigate\n\t\t\txtime_lock contention on larger systems, and/or RCU lock\n\t\t\tcontention on all systems with CONFIG_MAXSMP set.\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 -- disable. (may be 1 via CONFIG_CMDLINE=\"skew_tick=1\"\n\t\t\t1 -- enable.\n\t\t\tNote: increases power consumption, thus should only be\n\t\t\tenabled if running jitter sensitive (HPC/RT) workloads.\n\n\tsecurity=\t[SECURITY] Choose a legacy \"major\" security module to\n\t\t\tenable at boot. This has been deprecated by the\n\t\t\t\"lsm=\" parameter.\n\n\tselinux=\t[SELINUX] Disable or enable SELinux at boot time.\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\tSee security/selinux/Kconfig help text.\n\t\t\t0 -- disable.\n\t\t\t1 -- enable.\n\t\t\tDefault value is 1.\n\n\tapparmor=\t[APPARMOR] Disable or enable AppArmor at boot time\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\tSee security/apparmor/Kconfig help text\n\t\t\t0 -- disable.\n\t\t\t1 -- enable.\n\t\t\tDefault value is set via kernel config option.\n\n\tserialnumber\t[BUGS=X86-32]\n\n\tshapers=\t[NET]\n\t\t\tMaximal number of shapers.\n\n\tsimeth=\t\t[IA-64]\n\tsimscsi=\n\n\tslram=\t\t[HW,MTD]\n\n\tslab_nomerge\t[MM]\n\t\t\tDisable merging of slabs with similar size. May be\n\t\t\tnecessary if there is some reason to distinguish\n\t\t\tallocs to different slabs, especially in hardened\n\t\t\tenvironments where the risk of heap overflows and\n\t\t\tlayout control by attackers can usually be\n\t\t\tfrustrated by disabling merging. This will reduce\n\t\t\tmost of the exposure of a heap attack to a single\n\t\t\tcache (risks via metadata attacks are mostly\n\t\t\tunchanged). Debug options disable merging on their\n\t\t\town.\n\t\t\tFor more information see Documentation/vm/slub.rst.\n\n\tslab_max_order=\t[MM, SLAB]\n\t\t\tDetermines the maximum allowed order for slabs.\n\t\t\tA high setting may cause OOMs due to memory\n\t\t\tfragmentation.  Defaults to 1 for systems with\n\t\t\tmore than 32MB of RAM, 0 otherwise.\n\n\tslub_debug[=options[,slabs][;[options[,slabs]]...]\t[MM, SLUB]\n\t\t\tEnabling slub_debug allows one to determine the\n\t\t\tculprit if slab objects become corrupted. Enabling\n\t\t\tslub_debug can create guard zones around objects and\n\t\t\tmay poison objects when not in use. Also tracks the\n\t\t\tlast alloc / free. For more information see\n\t\t\tDocumentation/vm/slub.rst.\n\n\tslub_memcg_sysfs=\t[MM, SLUB]\n\t\t\tDetermines whether to enable sysfs directories for\n\t\t\tmemory cgroup sub-caches. 1 to enable, 0 to disable.\n\t\t\tThe default is determined by CONFIG_SLUB_MEMCG_SYSFS_ON.\n\t\t\tEnabling this can lead to a very high number of\tdebug\n\t\t\tdirectories and files being created under\n\t\t\t/sys/kernel/slub.\n\n\tslub_max_order= [MM, SLUB]\n\t\t\tDetermines the maximum allowed order for slabs.\n\t\t\tA high setting may cause OOMs due to memory\n\t\t\tfragmentation. For more information see\n\t\t\tDocumentation/vm/slub.rst.\n\n\tslub_min_objects=\t[MM, SLUB]\n\t\t\tThe minimum number of objects per slab. SLUB will\n\t\t\tincrease the slab order up to slub_max_order to\n\t\t\tgenerate a sufficiently large slab able to contain\n\t\t\tthe number of objects indicated. The higher the number\n\t\t\tof objects the smaller the overhead of tracking slabs\n\t\t\tand the less frequently locks need to be acquired.\n\t\t\tFor more information see Documentation/vm/slub.rst.\n\n\tslub_min_order=\t[MM, SLUB]\n\t\t\tDetermines the minimum page order for slabs. Must be\n\t\t\tlower than slub_max_order.\n\t\t\tFor more information see Documentation/vm/slub.rst.\n\n\tslub_nomerge\t[MM, SLUB]\n\t\t\tSame with slab_nomerge. This is supported for legacy.\n\t\t\tSee slab_nomerge for more information.\n\n\tsmart2=\t\t[HW]\n\t\t\tFormat: <io1>[,<io2>[,...,<io8>]]\n\n\tsmsc-ircc2.nopnp\t[HW] Don't use PNP to discover SMC devices\n\tsmsc-ircc2.ircc_cfg=\t[HW] Device configuration I/O port\n\tsmsc-ircc2.ircc_sir=\t[HW] SIR base I/O port\n\tsmsc-ircc2.ircc_fir=\t[HW] FIR base I/O port\n\tsmsc-ircc2.ircc_irq=\t[HW] IRQ line\n\tsmsc-ircc2.ircc_dma=\t[HW] DMA channel\n\tsmsc-ircc2.ircc_transceiver= [HW] Transceiver type:\n\t\t\t\t0: Toshiba Satellite 1800 (GP data pin select)\n\t\t\t\t1: Fast pin select (default)\n\t\t\t\t2: ATC IRMode\n\n\tsmt\t\t[KNL,S390] Set the maximum number of threads (logical\n\t\t\tCPUs) to use per physical CPU on systems capable of\n\t\t\tsymmetric multithreading (SMT). Will be capped to the\n\t\t\tactual hardware limit.\n\t\t\tFormat: <integer>\n\t\t\tDefault: -1 (no limit)\n\n\tsoftlockup_panic=\n\t\t\t[KNL] Should the soft-lockup detector generate panics.\n\t\t\tFormat: 0 | 1\n\n\t\t\tA value of 1 instructs the soft-lockup detector\n\t\t\tto panic the machine when a soft-lockup occurs. It is\n\t\t\talso controlled by the kernel.softlockup_panic sysctl\n\t\t\tand CONFIG_BOOTPARAM_SOFTLOCKUP_PANIC, which is the\n\t\t\trespective build-time switch to that functionality.\n\n\tsoftlockup_all_cpu_backtrace=\n\t\t\t[KNL] Should the soft-lockup detector generate\n\t\t\tbacktraces on all cpus.\n\t\t\tFormat: 0 | 1\n\n\tsonypi.*=\t[HW] Sony Programmable I/O Control Device driver\n\t\t\tSee Documentation/admin-guide/laptops/sonypi.rst\n\n\tspectre_v2=\t[X86] Control mitigation of Spectre variant 2\n\t\t\t(indirect branch speculation) vulnerability.\n\t\t\tThe default operation protects the kernel from\n\t\t\tuser space attacks.\n\n\t\t\ton   - unconditionally enable, implies\n\t\t\t       spectre_v2_user=on\n\t\t\toff  - unconditionally disable, implies\n\t\t\t       spectre_v2_user=off\n\t\t\tauto - kernel detects whether your CPU model is\n\t\t\t       vulnerable\n\n\t\t\tSelecting 'on' will, and 'auto' may, choose a\n\t\t\tmitigation method at run time according to the\n\t\t\tCPU, the available microcode, the setting of the\n\t\t\tCONFIG_RETPOLINE configuration option, and the\n\t\t\tcompiler with which the kernel was built.\n\n\t\t\tSelecting 'on' will also enable the mitigation\n\t\t\tagainst user space to user space task attacks.\n\n\t\t\tSelecting 'off' will disable both the kernel and\n\t\t\tthe user space protections.\n\n\t\t\tSpecific mitigations can also be selected manually:\n\n\t\t\tretpoline\t  - replace indirect branches\n\t\t\tretpoline,generic - google's original retpoline\n\t\t\tretpoline,amd     - AMD-specific minimal thunk\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\tspectre_v2=auto.\n\n\tspectre_v2_user=\n\t\t\t[X86] Control mitigation of Spectre variant 2\n\t\t        (indirect branch speculation) vulnerability between\n\t\t        user space tasks\n\n\t\t\ton\t- Unconditionally enable mitigations. Is\n\t\t\t\t  enforced by spectre_v2=on\n\n\t\t\toff     - Unconditionally disable mitigations. Is\n\t\t\t\t  enforced by spectre_v2=off\n\n\t\t\tprctl   - Indirect branch speculation is enabled,\n\t\t\t\t  but mitigation can be enabled via prctl\n\t\t\t\t  per thread.  The mitigation control state\n\t\t\t\t  is inherited on fork.\n\n\t\t\tprctl,ibpb\n\t\t\t\t- Like \"prctl\" above, but only STIBP is\n\t\t\t\t  controlled per thread. IBPB is issued\n\t\t\t\t  always when switching between different user\n\t\t\t\t  space processes.\n\n\t\t\tseccomp\n\t\t\t\t- Same as \"prctl\" above, but all seccomp\n\t\t\t\t  threads will enable the mitigation unless\n\t\t\t\t  they explicitly opt out.\n\n\t\t\tseccomp,ibpb\n\t\t\t\t- Like \"seccomp\" above, but only STIBP is\n\t\t\t\t  controlled per thread. IBPB is issued\n\t\t\t\t  always when switching between different\n\t\t\t\t  user space processes.\n\n\t\t\tauto    - Kernel selects the mitigation depending on\n\t\t\t\t  the available CPU features and vulnerability.\n\n\t\t\tDefault mitigation:\n\t\t\tIf CONFIG_SECCOMP=y then \"seccomp\", otherwise \"prctl\"\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\tspectre_v2_user=auto.\n\n\tspec_store_bypass_disable=\n\t\t\t[HW] Control Speculative Store Bypass (SSB) Disable mitigation\n\t\t\t(Speculative Store Bypass vulnerability)\n\n\t\t\tCertain CPUs are vulnerable to an exploit against a\n\t\t\ta common industry wide performance optimization known\n\t\t\tas \"Speculative Store Bypass\" in which recent stores\n\t\t\tto the same memory location may not be observed by\n\t\t\tlater loads during speculative execution. The idea\n\t\t\tis that such stores are unlikely and that they can\n\t\t\tbe detected prior to instruction retirement at the\n\t\t\tend of a particular speculation execution window.\n\n\t\t\tIn vulnerable processors, the speculatively forwarded\n\t\t\tstore can be used in a cache side channel attack, for\n\t\t\texample to read memory to which the attacker does not\n\t\t\tdirectly have access (e.g. inside sandboxed code).\n\n\t\t\tThis parameter controls whether the Speculative Store\n\t\t\tBypass optimization is used.\n\n\t\t\tOn x86 the options are:\n\n\t\t\ton      - Unconditionally disable Speculative Store Bypass\n\t\t\toff     - Unconditionally enable Speculative Store Bypass\n\t\t\tauto    - Kernel detects whether the CPU model contains an\n\t\t\t\t  implementation of Speculative Store Bypass and\n\t\t\t\t  picks the most appropriate mitigation. If the\n\t\t\t\t  CPU is not vulnerable, \"off\" is selected. If the\n\t\t\t\t  CPU is vulnerable the default mitigation is\n\t\t\t\t  architecture and Kconfig dependent. See below.\n\t\t\tprctl   - Control Speculative Store Bypass per thread\n\t\t\t\t  via prctl. Speculative Store Bypass is enabled\n\t\t\t\t  for a process by default. The state of the control\n\t\t\t\t  is inherited on fork.\n\t\t\tseccomp - Same as \"prctl\" above, but all seccomp threads\n\t\t\t\t  will disable SSB unless they explicitly opt out.\n\n\t\t\tDefault mitigations:\n\t\t\tX86:\tIf CONFIG_SECCOMP=y \"seccomp\", otherwise \"prctl\"\n\n\t\t\tOn powerpc the options are:\n\n\t\t\ton,auto - On Power8 and Power9 insert a store-forwarding\n\t\t\t\t  barrier on kernel entry and exit. On Power7\n\t\t\t\t  perform a software flush on kernel entry and\n\t\t\t\t  exit.\n\t\t\toff\t- No action.\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\tspec_store_bypass_disable=auto.\n\n\tspia_io_base=\t[HW,MTD]\n\tspia_fio_base=\n\tspia_pedr=\n\tspia_peddr=\n\n\tsplit_lock_detect=\n\t\t\t[X86] Enable split lock detection\n\n\t\t\tWhen enabled (and if hardware support is present), atomic\n\t\t\tinstructions that access data across cache line\n\t\t\tboundaries will result in an alignment check exception.\n\n\t\t\toff\t- not enabled\n\n\t\t\twarn\t- the kernel will emit rate limited warnings\n\t\t\t\t  about applications triggering the #AC\n\t\t\t\t  exception. This mode is the default on CPUs\n\t\t\t\t  that supports split lock detection.\n\n\t\t\tfatal\t- the kernel will send SIGBUS to applications\n\t\t\t\t  that trigger the #AC exception.\n\n\t\t\tIf an #AC exception is hit in the kernel or in\n\t\t\tfirmware (i.e. not while executing in user mode)\n\t\t\tthe kernel will oops in either \"warn\" or \"fatal\"\n\t\t\tmode.\n\n\tsrbds=\t\t[X86,INTEL]\n\t\t\tControl the Special Register Buffer Data Sampling\n\t\t\t(SRBDS) mitigation.\n\n\t\t\tCertain CPUs are vulnerable to an MDS-like\n\t\t\texploit which can leak bits from the random\n\t\t\tnumber generator.\n\n\t\t\tBy default, this issue is mitigated by\n\t\t\tmicrocode.  However, the microcode fix can cause\n\t\t\tthe RDRAND and RDSEED instructions to become\n\t\t\tmuch slower.  Among other effects, this will\n\t\t\tresult in reduced throughput from /dev/urandom.\n\n\t\t\tThe microcode mitigation can be disabled with\n\t\t\tthe following option:\n\n\t\t\toff:    Disable mitigation and remove\n\t\t\t\tperformance impact to RDRAND and RDSEED\n\n\tsrcutree.counter_wrap_check [KNL]\n\t\t\tSpecifies how frequently to check for\n\t\t\tgrace-period sequence counter wrap for the\n\t\t\tsrcu_data structure's ->srcu_gp_seq_needed field.\n\t\t\tThe greater the number of bits set in this kernel\n\t\t\tparameter, the less frequently counter wrap will\n\t\t\tbe checked for.  Note that the bottom two bits\n\t\t\tare ignored.\n\n\tsrcutree.exp_holdoff [KNL]\n\t\t\tSpecifies how many nanoseconds must elapse\n\t\t\tsince the end of the last SRCU grace period for\n\t\t\ta given srcu_struct until the next normal SRCU\n\t\t\tgrace period will be considered for automatic\n\t\t\texpediting.  Set to zero to disable automatic\n\t\t\texpediting.\n\n\tssbd=\t\t[ARM64,HW]\n\t\t\tSpeculative Store Bypass Disable control\n\n\t\t\tOn CPUs that are vulnerable to the Speculative\n\t\t\tStore Bypass vulnerability and offer a\n\t\t\tfirmware based mitigation, this parameter\n\t\t\tindicates how the mitigation should be used:\n\n\t\t\tforce-on:  Unconditionally enable mitigation for\n\t\t\t\t   for both kernel and userspace\n\t\t\tforce-off: Unconditionally disable mitigation for\n\t\t\t\t   for both kernel and userspace\n\t\t\tkernel:    Always enable mitigation in the\n\t\t\t\t   kernel, and offer a prctl interface\n\t\t\t\t   to allow userspace to register its\n\t\t\t\t   interest in being mitigated too.\n\n\tstack_guard_gap=\t[MM]\n\t\t\toverride the default stack gap protection. The value\n\t\t\tis in page units and it defines how many pages prior\n\t\t\tto (for stacks growing down) resp. after (for stacks\n\t\t\tgrowing up) the main stack are reserved for no other\n\t\t\tmapping. Default value is 256 pages.\n\n\tstacktrace\t[FTRACE]\n\t\t\tEnabled the stack tracer on boot up.\n\n\tstacktrace_filter=[function-list]\n\t\t\t[FTRACE] Limit the functions that the stack tracer\n\t\t\twill trace at boot up. function-list is a comma separated\n\t\t\tlist of functions. This list can be changed at run\n\t\t\ttime by the stack_trace_filter file in the debugfs\n\t\t\ttracing directory. Note, this enables stack tracing\n\t\t\tand the stacktrace above is not needed.\n\n\tsti=\t\t[PARISC,HW]\n\t\t\tFormat: <num>\n\t\t\tSet the STI (builtin display/keyboard on the HP-PARISC\n\t\t\tmachines) console (graphic card) which should be used\n\t\t\tas the initial boot-console.\n\t\t\tSee also comment in drivers/video/console/sticore.c.\n\n\tsti_font=\t[HW]\n\t\t\tSee comment in drivers/video/console/sticore.c.\n\n\tstifb=\t\t[HW]\n\t\t\tFormat: bpp:<bpp1>[:<bpp2>[:<bpp3>...]]\n\n\tsunrpc.min_resvport=\n\tsunrpc.max_resvport=\n\t\t\t[NFS,SUNRPC]\n\t\t\tSunRPC servers often require that client requests\n\t\t\toriginate from a privileged port (i.e. a port in the\n\t\t\trange 0 < portnr < 1024).\n\t\t\tAn administrator who wishes to reserve some of these\n\t\t\tports for other uses may adjust the range that the\n\t\t\tkernel's sunrpc client considers to be privileged\n\t\t\tusing these two parameters to set the minimum and\n\t\t\tmaximum port values.\n\n\tsunrpc.svc_rpc_per_connection_limit=\n\t\t\t[NFS,SUNRPC]\n\t\t\tLimit the number of requests that the server will\n\t\t\tprocess in parallel from a single connection.\n\t\t\tThe default value is 0 (no limit).\n\n\tsunrpc.pool_mode=\n\t\t\t[NFS]\n\t\t\tControl how the NFS server code allocates CPUs to\n\t\t\tservice thread pools.  Depending on how many NICs\n\t\t\tyou have and where their interrupts are bound, this\n\t\t\toption will affect which CPUs will do NFS serving.\n\t\t\tNote: this parameter cannot be changed while the\n\t\t\tNFS server is running.\n\n\t\t\tauto\t    the server chooses an appropriate mode\n\t\t\t\t    automatically using heuristics\n\t\t\tglobal\t    a single global pool contains all CPUs\n\t\t\tpercpu\t    one pool for each CPU\n\t\t\tpernode\t    one pool for each NUMA node (equivalent\n\t\t\t\t    to global on non-NUMA machines)\n\n\tsunrpc.tcp_slot_table_entries=\n\tsunrpc.udp_slot_table_entries=\n\t\t\t[NFS,SUNRPC]\n\t\t\tSets the upper limit on the number of simultaneous\n\t\t\tRPC calls that can be sent from the client to a\n\t\t\tserver. Increasing these values may allow you to\n\t\t\timprove throughput, but will also increase the\n\t\t\tamount of memory reserved for use by the client.\n\n\tsuspend.pm_test_delay=\n\t\t\t[SUSPEND]\n\t\t\tSets the number of seconds to remain in a suspend test\n\t\t\tmode before resuming the system (see\n\t\t\t/sys/power/pm_test). Only available when CONFIG_PM_DEBUG\n\t\t\tis set. Default value is 5.\n\n\tsvm=\t\t[PPC]\n\t\t\tFormat: { on | off | y | n | 1 | 0 }\n\t\t\tThis parameter controls use of the Protected\n\t\t\tExecution Facility on pSeries.\n\n\tswapaccount=[0|1]\n\t\t\t[KNL] Enable accounting of swap in memory resource\n\t\t\tcontroller if no parameter or 1 is given or disable\n\t\t\tit if 0 is given (See Documentation/admin-guide/cgroup-v1/memory.rst)\n\n\tswiotlb=\t[ARM,IA-64,PPC,MIPS,X86]\n\t\t\tFormat: { <int> | force | noforce }\n\t\t\t<int> -- Number of I/O TLB slabs\n\t\t\tforce -- force using of bounce buffers even if they\n\t\t\t         wouldn't be automatically used by the kernel\n\t\t\tnoforce -- Never use bounce buffers (for debugging)\n\n\tswitches=\t[HW,M68k]\n\n\tsysctl.*=\t[KNL]\n\t\t\tSet a sysctl parameter, right before loading the init\n\t\t\tprocess, as if the value was written to the respective\n\t\t\t/proc/sys/... file. Both '.' and '/' are recognized as\n\t\t\tseparators. Unrecognized parameters and invalid values\n\t\t\tare reported in the kernel log. Sysctls registered\n\t\t\tlater by a loaded module cannot be set this way.\n\t\t\tExample: sysctl.vm.swappiness=40\n\n\tsysfs.deprecated=0|1 [KNL]\n\t\t\tEnable/disable old style sysfs layout for old udev\n\t\t\ton older distributions. When this option is enabled\n\t\t\tvery new udev will not work anymore. When this option\n\t\t\tis disabled (or CONFIG_SYSFS_DEPRECATED not compiled)\n\t\t\tin older udev will not work anymore.\n\t\t\tDefault depends on CONFIG_SYSFS_DEPRECATED_V2 set in\n\t\t\tthe kernel configuration.\n\n\tsysrq_always_enabled\n\t\t\t[KNL]\n\t\t\tIgnore sysrq setting - this boot parameter will\n\t\t\tneutralize any effect of /proc/sys/kernel/sysrq.\n\t\t\tUseful for debugging.\n\n\ttcpmhash_entries= [KNL,NET]\n\t\t\tSet the number of tcp_metrics_hash slots.\n\t\t\tDefault value is 8192 or 16384 depending on total\n\t\t\tram pages. This is used to specify the TCP metrics\n\t\t\tcache size. See Documentation/networking/ip-sysctl.rst\n\t\t\t\"tcp_no_metrics_save\" section for more details.\n\n\ttdfx=\t\t[HW,DRM]\n\n\ttest_suspend=\t[SUSPEND][,N]\n\t\t\tSpecify \"mem\" (for Suspend-to-RAM) or \"standby\" (for\n\t\t\tstandby suspend) or \"freeze\" (for suspend type freeze)\n\t\t\tas the system sleep state during system startup with\n\t\t\tthe optional capability to repeat N number of times.\n\t\t\tThe system is woken from this state using a\n\t\t\twakeup-capable RTC alarm.\n\n\tthash_entries=\t[KNL,NET]\n\t\t\tSet number of hash buckets for TCP connection\n\n\tthermal.act=\t[HW,ACPI]\n\t\t\t-1: disable all active trip points in all thermal zones\n\t\t\t<degrees C>: override all lowest active trip points\n\n\tthermal.crt=\t[HW,ACPI]\n\t\t\t-1: disable all critical trip points in all thermal zones\n\t\t\t<degrees C>: override all critical trip points\n\n\tthermal.nocrt=\t[HW,ACPI]\n\t\t\tSet to disable actions on ACPI thermal zone\n\t\t\tcritical and hot trip points.\n\n\tthermal.off=\t[HW,ACPI]\n\t\t\t1: disable ACPI thermal control\n\n\tthermal.psv=\t[HW,ACPI]\n\t\t\t-1: disable all passive trip points\n\t\t\t<degrees C>: override all passive trip points to this\n\t\t\tvalue\n\n\tthermal.tzp=\t[HW,ACPI]\n\t\t\tSpecify global default ACPI thermal zone polling rate\n\t\t\t<deci-seconds>: poll all this frequency\n\t\t\t0: no polling (default)\n\n\tthreadirqs\t[KNL]\n\t\t\tForce threading of all interrupt handlers except those\n\t\t\tmarked explicitly IRQF_NO_THREAD.\n\n\ttopology=\t[S390]\n\t\t\tFormat: {off | on}\n\t\t\tSpecify if the kernel should make use of the cpu\n\t\t\ttopology information if the hardware supports this.\n\t\t\tThe scheduler will make use of this information and\n\t\t\te.g. base its process migration decisions on it.\n\t\t\tDefault is on.\n\n\ttopology_updates= [KNL, PPC, NUMA]\n\t\t\tFormat: {off}\n\t\t\tSpecify if the kernel should ignore (off)\n\t\t\ttopology updates sent by the hypervisor to this\n\t\t\tLPAR.\n\n\ttorture.disable_onoff_at_boot= [KNL]\n\t\t\tPrevent the CPU-hotplug component of torturing\n\t\t\tuntil after init has spawned.\n\n\ttorture.ftrace_dump_at_shutdown= [KNL]\n\t\t\tDump the ftrace buffer at torture-test shutdown,\n\t\t\teven if there were no errors.  This can be a\n\t\t\tvery costly operation when many torture tests\n\t\t\tare running concurrently, especially on systems\n\t\t\twith rotating-rust storage.\n\n\ttp720=\t\t[HW,PS2]\n\n\ttpm_suspend_pcr=[HW,TPM]\n\t\t\tFormat: integer pcr id\n\t\t\tSpecify that at suspend time, the tpm driver\n\t\t\tshould extend the specified pcr with zeros,\n\t\t\tas a workaround for some chips which fail to\n\t\t\tflush the last written pcr on TPM_SaveState.\n\t\t\tThis will guarantee that all the other pcrs\n\t\t\tare saved.\n\n\ttrace_buf_size=nn[KMG]\n\t\t\t[FTRACE] will set tracing buffer size on each cpu.\n\n\ttrace_event=[event-list]\n\t\t\t[FTRACE] Set and start specified trace events in order\n\t\t\tto facilitate early boot debugging. The event-list is a\n\t\t\tcomma separated list of trace events to enable. See\n\t\t\talso Documentation/trace/events.rst\n\n\ttrace_options=[option-list]\n\t\t\t[FTRACE] Enable or disable tracer options at boot.\n\t\t\tThe option-list is a comma delimited list of options\n\t\t\tthat can be enabled or disabled just as if you were\n\t\t\tto echo the option name into\n\n\t\t\t    /sys/kernel/debug/tracing/trace_options\n\n\t\t\tFor example, to enable stacktrace option (to dump the\n\t\t\tstack trace of each event), add to the command line:\n\n\t\t\t      trace_options=stacktrace\n\n\t\t\tSee also Documentation/trace/ftrace.rst \"trace options\"\n\t\t\tsection.\n\n\ttp_printk[FTRACE]\n\t\t\tHave the tracepoints sent to printk as well as the\n\t\t\ttracing ring buffer. This is useful for early boot up\n\t\t\twhere the system hangs or reboots and does not give the\n\t\t\toption for reading the tracing buffer or performing a\n\t\t\tftrace_dump_on_oops.\n\n\t\t\tTo turn off having tracepoints sent to printk,\n\t\t\t echo 0 > /proc/sys/kernel/tracepoint_printk\n\t\t\tNote, echoing 1 into this file without the\n\t\t\ttracepoint_printk kernel cmdline option has no effect.\n\n\t\t\t** CAUTION **\n\n\t\t\tHaving tracepoints sent to printk() and activating high\n\t\t\tfrequency tracepoints such as irq or sched, can cause\n\t\t\tthe system to live lock.\n\n\ttraceoff_on_warning\n\t\t\t[FTRACE] enable this option to disable tracing when a\n\t\t\twarning is hit. This turns off \"tracing_on\". Tracing can\n\t\t\tbe enabled again by echoing '1' into the \"tracing_on\"\n\t\t\tfile located in /sys/kernel/debug/tracing/\n\n\t\t\tThis option is useful, as it disables the trace before\n\t\t\tthe WARNING dump is called, which prevents the trace to\n\t\t\tbe filled with content caused by the warning output.\n\n\t\t\tThis option can also be set at run time via the sysctl\n\t\t\toption:  kernel/traceoff_on_warning\n\n\ttransparent_hugepage=\n\t\t\t[KNL]\n\t\t\tFormat: [always|madvise|never]\n\t\t\tCan be used to control the default behavior of the system\n\t\t\twith respect to transparent hugepages.\n\t\t\tSee Documentation/admin-guide/mm/transhuge.rst\n\t\t\tfor more details.\n\n\ttsc=\t\tDisable clocksource stability checks for TSC.\n\t\t\tFormat: <string>\n\t\t\t[x86] reliable: mark tsc clocksource as reliable, this\n\t\t\tdisables clocksource verification at runtime, as well\n\t\t\tas the stability checks done at bootup.\tUsed to enable\n\t\t\thigh-resolution timer mode on older hardware, and in\n\t\t\tvirtualized environment.\n\t\t\t[x86] noirqtime: Do not use TSC to do irq accounting.\n\t\t\tUsed to run time disable IRQ_TIME_ACCOUNTING on any\n\t\t\tplatforms where RDTSC is slow and this accounting\n\t\t\tcan add overhead.\n\t\t\t[x86] unstable: mark the TSC clocksource as unstable, this\n\t\t\tmarks the TSC unconditionally unstable at bootup and\n\t\t\tavoids any further wobbles once the TSC watchdog notices.\n\t\t\t[x86] nowatchdog: disable clocksource watchdog. Used\n\t\t\tin situations with strict latency requirements (where\n\t\t\tinterruptions from clocksource watchdog are not\n\t\t\tacceptable).\n\n\ttsc_early_khz=  [X86] Skip early TSC calibration and use the given\n\t\t\tvalue instead. Useful when the early TSC frequency discovery\n\t\t\tprocedure is not reliable, such as on overclocked systems\n\t\t\twith CPUID.16h support and partial CPUID.15h support.\n\t\t\tFormat: <unsigned int>\n\n\ttsx=\t\t[X86] Control Transactional Synchronization\n\t\t\tExtensions (TSX) feature in Intel processors that\n\t\t\tsupport TSX control.\n\n\t\t\tThis parameter controls the TSX feature. The options are:\n\n\t\t\ton\t- Enable TSX on the system. Although there are\n\t\t\t\tmitigations for all known security vulnerabilities,\n\t\t\t\tTSX has been known to be an accelerator for\n\t\t\t\tseveral previous speculation-related CVEs, and\n\t\t\t\tso there may be unknown\tsecurity risks associated\n\t\t\t\twith leaving it enabled.\n\n\t\t\toff\t- Disable TSX on the system. (Note that this\n\t\t\t\toption takes effect only on newer CPUs which are\n\t\t\t\tnot vulnerable to MDS, i.e., have\n\t\t\t\tMSR_IA32_ARCH_CAPABILITIES.MDS_NO=1 and which get\n\t\t\t\tthe new IA32_TSX_CTRL MSR through a microcode\n\t\t\t\tupdate. This new MSR allows for the reliable\n\t\t\t\tdeactivation of the TSX functionality.)\n\n\t\t\tauto\t- Disable TSX if X86_BUG_TAA is present,\n\t\t\t\t  otherwise enable TSX on the system.\n\n\t\t\tNot specifying this option is equivalent to tsx=off.\n\n\t\t\tSee Documentation/admin-guide/hw-vuln/tsx_async_abort.rst\n\t\t\tfor more details.\n\n\ttsx_async_abort= [X86,INTEL] Control mitigation for the TSX Async\n\t\t\tAbort (TAA) vulnerability.\n\n\t\t\tSimilar to Micro-architectural Data Sampling (MDS)\n\t\t\tcertain CPUs that support Transactional\n\t\t\tSynchronization Extensions (TSX) are vulnerable to an\n\t\t\texploit against CPU internal buffers which can forward\n\t\t\tinformation to a disclosure gadget under certain\n\t\t\tconditions.\n\n\t\t\tIn vulnerable processors, the speculatively forwarded\n\t\t\tdata can be used in a cache side channel attack, to\n\t\t\taccess data to which the attacker does not have direct\n\t\t\taccess.\n\n\t\t\tThis parameter controls the TAA mitigation.  The\n\t\t\toptions are:\n\n\t\t\tfull       - Enable TAA mitigation on vulnerable CPUs\n\t\t\t\t     if TSX is enabled.\n\n\t\t\tfull,nosmt - Enable TAA mitigation and disable SMT on\n\t\t\t\t     vulnerable CPUs. If TSX is disabled, SMT\n\t\t\t\t     is not disabled because CPU is not\n\t\t\t\t     vulnerable to cross-thread TAA attacks.\n\t\t\toff        - Unconditionally disable TAA mitigation\n\n\t\t\tOn MDS-affected machines, tsx_async_abort=off can be\n\t\t\tprevented by an active MDS mitigation as both vulnerabilities\n\t\t\tare mitigated with the same mechanism so in order to disable\n\t\t\tthis mitigation, you need to specify mds=off too.\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\ttsx_async_abort=full.  On CPUs which are MDS affected\n\t\t\tand deploy MDS mitigation, TAA mitigation is not\n\t\t\trequired and doesn't provide any additional\n\t\t\tmitigation.\n\n\t\t\tFor details see:\n\t\t\tDocumentation/admin-guide/hw-vuln/tsx_async_abort.rst\n\n\tturbografx.map[2|3]=\t[HW,JOY]\n\t\t\tTurboGraFX parallel port interface\n\t\t\tFormat:\n\t\t\t<port#>,<js1>,<js2>,<js3>,<js4>,<js5>,<js6>,<js7>\n\t\t\tSee also Documentation/input/devices/joystick-parport.rst\n\n\tudbg-immortal\t[PPC] When debugging early kernel crashes that\n\t\t\thappen after console_init() and before a proper\n\t\t\tconsole driver takes over, this boot options might\n\t\t\thelp \"seeing\" what's going on.\n\n\tuhash_entries=\t[KNL,NET]\n\t\t\tSet number of hash buckets for UDP/UDP-Lite connections\n\n\tuhci-hcd.ignore_oc=\n\t\t\t[USB] Ignore overcurrent events (default N).\n\t\t\tSome badly-designed motherboards generate lots of\n\t\t\tbogus events, for ports that aren't wired to\n\t\t\tanything.  Set this parameter to avoid log spamming.\n\t\t\tNote that genuine overcurrent events won't be\n\t\t\treported either.\n\n\tunknown_nmi_panic\n\t\t\t[X86] Cause panic on unknown NMI.\n\n\tusbcore.authorized_default=\n\t\t\t[USB] Default USB device authorization:\n\t\t\t(default -1 = authorized except for wireless USB,\n\t\t\t0 = not authorized, 1 = authorized, 2 = authorized\n\t\t\tif device connected to internal port)\n\n\tusbcore.autosuspend=\n\t\t\t[USB] The autosuspend time delay (in seconds) used\n\t\t\tfor newly-detected USB devices (default 2).  This\n\t\t\tis the time required before an idle device will be\n\t\t\tautosuspended.  Devices for which the delay is set\n\t\t\tto a negative value won't be autosuspended at all.\n\n\tusbcore.usbfs_snoop=\n\t\t\t[USB] Set to log all usbfs traffic (default 0 = off).\n\n\tusbcore.usbfs_snoop_max=\n\t\t\t[USB] Maximum number of bytes to snoop in each URB\n\t\t\t(default = 65536).\n\n\tusbcore.blinkenlights=\n\t\t\t[USB] Set to cycle leds on hubs (default 0 = off).\n\n\tusbcore.old_scheme_first=\n\t\t\t[USB] Start with the old device initialization\n\t\t\tscheme (default 0 = off).\n\n\tusbcore.usbfs_memory_mb=\n\t\t\t[USB] Memory limit (in MB) for buffers allocated by\n\t\t\tusbfs (default = 16, 0 = max = 2047).\n\n\tusbcore.use_both_schemes=\n\t\t\t[USB] Try the other device initialization scheme\n\t\t\tif the first one fails (default 1 = enabled).\n\n\tusbcore.initial_descriptor_timeout=\n\t\t\t[USB] Specifies timeout for the initial 64-byte\n\t\t\tUSB_REQ_GET_DESCRIPTOR request in milliseconds\n\t\t\t(default 5000 = 5.0 seconds).\n\n\tusbcore.nousb\t[USB] Disable the USB subsystem\n\n\tusbcore.quirks=\n\t\t\t[USB] A list of quirk entries to augment the built-in\n\t\t\tusb core quirk list. List entries are separated by\n\t\t\tcommas. Each entry has the form\n\t\t\tVendorID:ProductID:Flags. The IDs are 4-digit hex\n\t\t\tnumbers and Flags is a set of letters. Each letter\n\t\t\twill change the built-in quirk; setting it if it is\n\t\t\tclear and clearing it if it is set. The letters have\n\t\t\tthe following meanings:\n\t\t\t\ta = USB_QUIRK_STRING_FETCH_255 (string\n\t\t\t\t\tdescriptors must not be fetched using\n\t\t\t\t\ta 255-byte read);\n\t\t\t\tb = USB_QUIRK_RESET_RESUME (device can't resume\n\t\t\t\t\tcorrectly so reset it instead);\n\t\t\t\tc = USB_QUIRK_NO_SET_INTF (device can't handle\n\t\t\t\t\tSet-Interface requests);\n\t\t\t\td = USB_QUIRK_CONFIG_INTF_STRINGS (device can't\n\t\t\t\t\thandle its Configuration or Interface\n\t\t\t\t\tstrings);\n\t\t\t\te = USB_QUIRK_RESET (device can't be reset\n\t\t\t\t\t(e.g morph devices), don't use reset);\n\t\t\t\tf = USB_QUIRK_HONOR_BNUMINTERFACES (device has\n\t\t\t\t\tmore interface descriptions than the\n\t\t\t\t\tbNumInterfaces count, and can't handle\n\t\t\t\t\ttalking to these interfaces);\n\t\t\t\tg = USB_QUIRK_DELAY_INIT (device needs a pause\n\t\t\t\t\tduring initialization, after we read\n\t\t\t\t\tthe device descriptor);\n\t\t\t\th = USB_QUIRK_LINEAR_UFRAME_INTR_BINTERVAL (For\n\t\t\t\t\thigh speed and super speed interrupt\n\t\t\t\t\tendpoints, the USB 2.0 and USB 3.0 spec\n\t\t\t\t\trequire the interval in microframes (1\n\t\t\t\t\tmicroframe = 125 microseconds) to be\n\t\t\t\t\tcalculated as interval = 2 ^\n\t\t\t\t\t(bInterval-1).\n\t\t\t\t\tDevices with this quirk report their\n\t\t\t\t\tbInterval as the result of this\n\t\t\t\t\tcalculation instead of the exponent\n\t\t\t\t\tvariable used in the calculation);\n\t\t\t\ti = USB_QUIRK_DEVICE_QUALIFIER (device can't\n\t\t\t\t\thandle device_qualifier descriptor\n\t\t\t\t\trequests);\n\t\t\t\tj = USB_QUIRK_IGNORE_REMOTE_WAKEUP (device\n\t\t\t\t\tgenerates spurious wakeup, ignore\n\t\t\t\t\tremote wakeup capability);\n\t\t\t\tk = USB_QUIRK_NO_LPM (device can't handle Link\n\t\t\t\t\tPower Management);\n\t\t\t\tl = USB_QUIRK_LINEAR_FRAME_INTR_BINTERVAL\n\t\t\t\t\t(Device reports its bInterval as linear\n\t\t\t\t\tframes instead of the USB 2.0\n\t\t\t\t\tcalculation);\n\t\t\t\tm = USB_QUIRK_DISCONNECT_SUSPEND (Device needs\n\t\t\t\t\tto be disconnected before suspend to\n\t\t\t\t\tprevent spurious wakeup);\n\t\t\t\tn = USB_QUIRK_DELAY_CTRL_MSG (Device needs a\n\t\t\t\t\tpause after every control message);\n\t\t\t\to = USB_QUIRK_HUB_SLOW_RESET (Hub needs extra\n\t\t\t\t\tdelay after resetting its port);\n\t\t\tExample: quirks=0781:5580:bk,0a5c:5834:gij\n\n\tusbhid.mousepoll=\n\t\t\t[USBHID] The interval which mice are to be polled at.\n\n\tusbhid.jspoll=\n\t\t\t[USBHID] The interval which joysticks are to be polled at.\n\n\tusbhid.kbpoll=\n\t\t\t[USBHID] The interval which keyboards are to be polled at.\n\n\tusb-storage.delay_use=\n\t\t\t[UMS] The delay in seconds before a new device is\n\t\t\tscanned for Logical Units (default 1).\n\n\tusb-storage.quirks=\n\t\t\t[UMS] A list of quirks entries to supplement or\n\t\t\toverride the built-in unusual_devs list.  List\n\t\t\tentries are separated by commas.  Each entry has\n\t\t\tthe form VID:PID:Flags where VID and PID are Vendor\n\t\t\tand Product ID values (4-digit hex numbers) and\n\t\t\tFlags is a set of characters, each corresponding\n\t\t\tto a common usb-storage quirk flag as follows:\n\t\t\t\ta = SANE_SENSE (collect more than 18 bytes\n\t\t\t\t\tof sense data, not on uas);\n\t\t\t\tb = BAD_SENSE (don't collect more than 18\n\t\t\t\t\tbytes of sense data, not on uas);\n\t\t\t\tc = FIX_CAPACITY (decrease the reported\n\t\t\t\t\tdevice capacity by one sector);\n\t\t\t\td = NO_READ_DISC_INFO (don't use\n\t\t\t\t\tREAD_DISC_INFO command, not on uas);\n\t\t\t\te = NO_READ_CAPACITY_16 (don't use\n\t\t\t\t\tREAD_CAPACITY_16 command);\n\t\t\t\tf = NO_REPORT_OPCODES (don't use report opcodes\n\t\t\t\t\tcommand, uas only);\n\t\t\t\tg = MAX_SECTORS_240 (don't transfer more than\n\t\t\t\t\t240 sectors at a time, uas only);\n\t\t\t\th = CAPACITY_HEURISTICS (decrease the\n\t\t\t\t\treported device capacity by one\n\t\t\t\t\tsector if the number is odd);\n\t\t\t\ti = IGNORE_DEVICE (don't bind to this\n\t\t\t\t\tdevice);\n\t\t\t\tj = NO_REPORT_LUNS (don't use report luns\n\t\t\t\t\tcommand, uas only);\n\t\t\t\tl = NOT_LOCKABLE (don't try to lock and\n\t\t\t\t\tunlock ejectable media, not on uas);\n\t\t\t\tm = MAX_SECTORS_64 (don't transfer more\n\t\t\t\t\tthan 64 sectors = 32 KB at a time,\n\t\t\t\t\tnot on uas);\n\t\t\t\tn = INITIAL_READ10 (force a retry of the\n\t\t\t\t\tinitial READ(10) command, not on uas);\n\t\t\t\to = CAPACITY_OK (accept the capacity\n\t\t\t\t\treported by the device, not on uas);\n\t\t\t\tp = WRITE_CACHE (the device cache is ON\n\t\t\t\t\tby default, not on uas);\n\t\t\t\tr = IGNORE_RESIDUE (the device reports\n\t\t\t\t\tbogus residue values, not on uas);\n\t\t\t\ts = SINGLE_LUN (the device has only one\n\t\t\t\t\tLogical Unit);\n\t\t\t\tt = NO_ATA_1X (don't allow ATA(12) and ATA(16)\n\t\t\t\t\tcommands, uas only);\n\t\t\t\tu = IGNORE_UAS (don't bind to the uas driver);\n\t\t\t\tw = NO_WP_DETECT (don't test whether the\n\t\t\t\t\tmedium is write-protected).\n\t\t\t\ty = ALWAYS_SYNC (issue a SYNCHRONIZE_CACHE\n\t\t\t\t\teven if the device claims no cache,\n\t\t\t\t\tnot on uas)\n\t\t\tExample: quirks=0419:aaf5:rl,0421:0433:rc\n\n\tuser_debug=\t[KNL,ARM]\n\t\t\tFormat: <int>\n\t\t\tSee arch/arm/Kconfig.debug help text.\n\t\t\t\t 1 - undefined instruction events\n\t\t\t\t 2 - system calls\n\t\t\t\t 4 - invalid data aborts\n\t\t\t\t 8 - SIGSEGV faults\n\t\t\t\t16 - SIGBUS faults\n\t\t\tExample: user_debug=31\n\n\tuserpte=\n\t\t\t[X86] Flags controlling user PTE allocations.\n\n\t\t\t\tnohigh = do not allocate PTE pages in\n\t\t\t\t\tHIGHMEM regardless of setting\n\t\t\t\t\tof CONFIG_HIGHPTE.\n\n\tvdso=\t\t[X86,SH]\n\t\t\tOn X86_32, this is an alias for vdso32=.  Otherwise:\n\n\t\t\tvdso=1: enable VDSO (the default)\n\t\t\tvdso=0: disable VDSO mapping\n\n\tvdso32=\t\t[X86] Control the 32-bit vDSO\n\t\t\tvdso32=1: enable 32-bit VDSO\n\t\t\tvdso32=0 or vdso32=2: disable 32-bit VDSO\n\n\t\t\tSee the help text for CONFIG_COMPAT_VDSO for more\n\t\t\tdetails.  If CONFIG_COMPAT_VDSO is set, the default is\n\t\t\tvdso32=0; otherwise, the default is vdso32=1.\n\n\t\t\tFor compatibility with older kernels, vdso32=2 is an\n\t\t\talias for vdso32=0.\n\n\t\t\tTry vdso32=0 if you encounter an error that says:\n\t\t\tdl_main: Assertion `(void *) ph->p_vaddr == _rtld_local._dl_sysinfo_dso' failed!\n\n\tvector=\t\t[IA-64,SMP]\n\t\t\tvector=percpu: enable percpu vector domain\n\n\tvideo=\t\t[FB] Frame buffer configuration\n\t\t\tSee Documentation/fb/modedb.rst.\n\n\tvideo.brightness_switch_enabled= [0,1]\n\t\t\tIf set to 1, on receiving an ACPI notify event\n\t\t\tgenerated by hotkey, video driver will adjust brightness\n\t\t\tlevel and then send out the event to user space through\n\t\t\tthe allocated input device; If set to 0, video driver\n\t\t\twill only send out the event without touching backlight\n\t\t\tbrightness level.\n\t\t\tdefault: 1\n\n\tvirtio_mmio.device=\n\t\t\t[VMMIO] Memory mapped virtio (platform) device.\n\n\t\t\t\t<size>@<baseaddr>:<irq>[:<id>]\n\t\t\twhere:\n\t\t\t\t<size>     := size (can use standard suffixes\n\t\t\t\t\t\tlike K, M and G)\n\t\t\t\t<baseaddr> := physical base address\n\t\t\t\t<irq>      := interrupt number (as passed to\n\t\t\t\t\t\trequest_irq())\n\t\t\t\t<id>       := (optional) platform device id\n\t\t\texample:\n\t\t\t\tvirtio_mmio.device=1K@0x100b0000:48:7\n\n\t\t\tCan be used multiple times for multiple devices.\n\n\tvga=\t\t[BOOT,X86-32] Select a particular video mode\n\t\t\tSee Documentation/x86/boot.rst and\n\t\t\tDocumentation/admin-guide/svga.rst.\n\t\t\tUse vga=ask for menu.\n\t\t\tThis is actually a boot loader parameter; the value is\n\t\t\tpassed to the kernel using a special protocol.\n\n\tvm_debug[=options]\t[KNL] Available with CONFIG_DEBUG_VM=y.\n\t\t\tMay slow down system boot speed, especially when\n\t\t\tenabled on systems with a large amount of memory.\n\t\t\tAll options are enabled by default, and this\n\t\t\tinterface is meant to allow for selectively\n\t\t\tenabling or disabling specific virtual memory\n\t\t\tdebugging features.\n\n\t\t\tAvailable options are:\n\t\t\t  P\tEnable page structure init time poisoning\n\t\t\t  -\tDisable all of the above options\n\n\tvmalloc=nn[KMG]\t[KNL,BOOT] Forces the vmalloc area to have an exact\n\t\t\tsize of <nn>. This can be used to increase the\n\t\t\tminimum size (128MB on x86). It can also be used to\n\t\t\tdecrease the size and leave more room for directly\n\t\t\tmapped kernel RAM.\n\n\tvmcp_cma=nn[MG]\t[KNL,S390]\n\t\t\tSets the memory size reserved for contiguous memory\n\t\t\tallocations for the vmcp device driver.\n\n\tvmhalt=\t\t[KNL,S390] Perform z/VM CP command after system halt.\n\t\t\tFormat: <command>\n\n\tvmpanic=\t[KNL,S390] Perform z/VM CP command after kernel panic.\n\t\t\tFormat: <command>\n\n\tvmpoff=\t\t[KNL,S390] Perform z/VM CP command after power off.\n\t\t\tFormat: <command>\n\n\tvsyscall=\t[X86-64]\n\t\t\tControls the behavior of vsyscalls (i.e. calls to\n\t\t\tfixed addresses of 0xffffffffff600x00 from legacy\n\t\t\tcode).  Most statically-linked binaries and older\n\t\t\tversions of glibc use these calls.  Because these\n\t\t\tfunctions are at fixed addresses, they make nice\n\t\t\ttargets for exploits that can control RIP.\n\n\t\t\temulate     [default] Vsyscalls turn into traps and are\n\t\t\t            emulated reasonably safely.  The vsyscall\n\t\t\t\t    page is readable.\n\n\t\t\txonly       Vsyscalls turn into traps and are\n\t\t\t            emulated reasonably safely.  The vsyscall\n\t\t\t\t    page is not readable.\n\n\t\t\tnone        Vsyscalls don't work at all.  This makes\n\t\t\t            them quite hard to use for exploits but\n\t\t\t            might break your system.\n\n\tvt.color=\t[VT] Default text color.\n\t\t\tFormat: 0xYX, X = foreground, Y = background.\n\t\t\tDefault: 0x07 = light gray on black.\n\n\tvt.cur_default=\t[VT] Default cursor shape.\n\t\t\tFormat: 0xCCBBAA, where AA, BB, and CC are the same as\n\t\t\tthe parameters of the <Esc>[?A;B;Cc escape sequence;\n\t\t\tsee VGA-softcursor.txt. Default: 2 = underline.\n\n\tvt.default_blu=\t[VT]\n\t\t\tFormat: <blue0>,<blue1>,<blue2>,...,<blue15>\n\t\t\tChange the default blue palette of the console.\n\t\t\tThis is a 16-member array composed of values\n\t\t\tranging from 0-255.\n\n\tvt.default_grn=\t[VT]\n\t\t\tFormat: <green0>,<green1>,<green2>,...,<green15>\n\t\t\tChange the default green palette of the console.\n\t\t\tThis is a 16-member array composed of values\n\t\t\tranging from 0-255.\n\n\tvt.default_red=\t[VT]\n\t\t\tFormat: <red0>,<red1>,<red2>,...,<red15>\n\t\t\tChange the default red palette of the console.\n\t\t\tThis is a 16-member array composed of values\n\t\t\tranging from 0-255.\n\n\tvt.default_utf8=\n\t\t\t[VT]\n\t\t\tFormat=<0|1>\n\t\t\tSet system-wide default UTF-8 mode for all tty's.\n\t\t\tDefault is 1, i.e. UTF-8 mode is enabled for all\n\t\t\tnewly opened terminals.\n\n\tvt.global_cursor_default=\n\t\t\t[VT]\n\t\t\tFormat=<-1|0|1>\n\t\t\tSet system-wide default for whether a cursor\n\t\t\tis shown on new VTs. Default is -1,\n\t\t\ti.e. cursors will be created by default unless\n\t\t\toverridden by individual drivers. 0 will hide\n\t\t\tcursors, 1 will display them.\n\n\tvt.italic=\t[VT] Default color for italic text; 0-15.\n\t\t\tDefault: 2 = green.\n\n\tvt.underline=\t[VT] Default color for underlined text; 0-15.\n\t\t\tDefault: 3 = cyan.\n\n\twatchdog timers\t[HW,WDT] For information on watchdog timers,\n\t\t\tsee Documentation/watchdog/watchdog-parameters.rst\n\t\t\tor other driver-specific files in the\n\t\t\tDocumentation/watchdog/ directory.\n\n\twatchdog_thresh=\n\t\t\t[KNL]\n\t\t\tSet the hard lockup detector stall duration\n\t\t\tthreshold in seconds. The soft lockup detector\n\t\t\tthreshold is set to twice the value. A value of 0\n\t\t\tdisables both lockup detectors. Default is 10\n\t\t\tseconds.\n\n\tworkqueue.watchdog_thresh=\n\t\t\tIf CONFIG_WQ_WATCHDOG is configured, workqueue can\n\t\t\twarn stall conditions and dump internal state to\n\t\t\thelp debugging.  0 disables workqueue stall\n\t\t\tdetection; otherwise, it's the stall threshold\n\t\t\tduration in seconds.  The default value is 30 and\n\t\t\tit can be updated at runtime by writing to the\n\t\t\tcorresponding sysfs file.\n\n\tworkqueue.disable_numa\n\t\t\tBy default, all work items queued to unbound\n\t\t\tworkqueues are affine to the NUMA nodes they're\n\t\t\tissued on, which results in better behavior in\n\t\t\tgeneral.  If NUMA affinity needs to be disabled for\n\t\t\twhatever reason, this option can be used.  Note\n\t\t\tthat this also can be controlled per-workqueue for\n\t\t\tworkqueues visible under /sys/bus/workqueue/.\n\n\tworkqueue.power_efficient\n\t\t\tPer-cpu workqueues are generally preferred because\n\t\t\tthey show better performance thanks to cache\n\t\t\tlocality; unfortunately, per-cpu workqueues tend to\n\t\t\tbe more power hungry than unbound workqueues.\n\n\t\t\tEnabling this makes the per-cpu workqueues which\n\t\t\twere observed to contribute significantly to power\n\t\t\tconsumption unbound, leading to measurably lower\n\t\t\tpower usage at the cost of small performance\n\t\t\toverhead.\n\n\t\t\tThe default value of this parameter is determined by\n\t\t\tthe config option CONFIG_WQ_POWER_EFFICIENT_DEFAULT.\n\n\tworkqueue.debug_force_rr_cpu\n\t\t\tWorkqueue used to implicitly guarantee that work\n\t\t\titems queued without explicit CPU specified are put\n\t\t\ton the local CPU.  This guarantee is no longer true\n\t\t\tand while local CPU is still preferred work items\n\t\t\tmay be put on foreign CPUs.  This debug option\n\t\t\tforces round-robin CPU selection to flush out\n\t\t\tusages which depend on the now broken guarantee.\n\t\t\tWhen enabled, memory and cache locality will be\n\t\t\timpacted.\n\n\tx2apic_phys\t[X86-64,APIC] Use x2apic physical mode instead of\n\t\t\tdefault x2apic cluster mode on platforms\n\t\t\tsupporting x2apic.\n\n\tx86_intel_mid_timer= [X86-32,APBT]\n\t\t\tChoose timer option for x86 Intel MID platform.\n\t\t\tTwo valid options are apbt timer only and lapic timer\n\t\t\tplus one apbt timer for broadcast timer.\n\t\t\tx86_intel_mid_timer=apbt_only | lapic_and_apbt\n\n\txen_512gb_limit\t\t[KNL,X86-64,XEN]\n\t\t\tRestricts the kernel running paravirtualized under Xen\n\t\t\tto use only up to 512 GB of RAM. The reason to do so is\n\t\t\tcrash analysis tools and Xen tools for doing domain\n\t\t\tsave/restore/migration must be enabled to handle larger\n\t\t\tdomains.\n\n\txen_emul_unplug=\t\t[HW,X86,XEN]\n\t\t\tUnplug Xen emulated devices\n\t\t\tFormat: [unplug0,][unplug1]\n\t\t\tide-disks -- unplug primary master IDE devices\n\t\t\taux-ide-disks -- unplug non-primary-master IDE devices\n\t\t\tnics -- unplug network devices\n\t\t\tall -- unplug all emulated devices (NICs and IDE disks)\n\t\t\tunnecessary -- unplugging emulated devices is\n\t\t\t\tunnecessary even if the host did not respond to\n\t\t\t\tthe unplug protocol\n\t\t\tnever -- do not unplug even if version check succeeds\n\n\txen_legacy_crash\t[X86,XEN]\n\t\t\tCrash from Xen panic notifier, without executing late\n\t\t\tpanic() code such as dumping handler.\n\n\txen_nopvspin\t[X86,XEN]\n\t\t\tDisables the qspinlock slowpath using Xen PV optimizations.\n\t\t\tThis parameter is obsoleted by \"nopvspin\" parameter, which\n\t\t\thas equivalent effect for XEN platform.\n\n\txen_nopv\t[X86]\n\t\t\tDisables the PV optimizations forcing the HVM guest to\n\t\t\trun as generic HVM guest with no PV drivers.\n\t\t\tThis option is obsoleted by the \"nopv\" option, which\n\t\t\thas equivalent effect for XEN platform.\n\n\txen_scrub_pages=\t[XEN]\n\t\t\tBoolean option to control scrubbing pages before giving them back\n\t\t\tto Xen, for use by other domains. Can be also changed at runtime\n\t\t\twith /sys/devices/system/xen_memory/xen_memory0/scrub_pages.\n\t\t\tDefault value controlled with CONFIG_XEN_SCRUB_PAGES_DEFAULT.\n\n\txen_timer_slop=\t[X86-64,XEN]\n\t\t\tSet the timer slop (in nanoseconds) for the virtual Xen\n\t\t\ttimers (default is 100000). This adjusts the minimum\n\t\t\tdelta of virtualized Xen timers, where lower values\n\t\t\timprove timer resolution at the expense of processing\n\t\t\tmore timer interrupts.\n\n\tnopv=\t\t[X86,XEN,KVM,HYPER_V,VMWARE]\n\t\t\tDisables the PV optimizations forcing the guest to run\n\t\t\tas generic guest with no PV drivers. Currently support\n\t\t\tXEN HVM, KVM, HYPER_V and VMWARE guest.\n\n\tnopvspin\t[X86,XEN,KVM]\n\t\t\tDisables the qspinlock slow path using PV optimizations\n\t\t\twhich allow the hypervisor to 'idle' the guest on lock\n\t\t\tcontention.\n\n\txirc2ps_cs=\t[NET,PCMCIA]\n\t\t\tFormat:\n\t\t\t<irq>,<irq_mask>,<io>,<full_duplex>,<do_sound>,<lockup_hack>[,<irq2>[,<irq3>[,<irq4>]]]\n\n\txive=\t\t[PPC]\n\t\t\tBy default on POWER9 and above, the kernel will\n\t\t\tnatively use the XIVE interrupt controller. This option\n\t\t\tallows the fallback firmware mode to be used:\n\n\t\t\toff       Fallback to firmware control of XIVE interrupt\n\t\t\t\t  controller on both pseries and powernv\n\t\t\t\t  platforms. Only useful on POWER9 and above.\n\n\txhci-hcd.quirks\t\t[USB,KNL]\n\t\t\tA hex value specifying bitmask with supplemental xhci\n\t\t\thost controller quirks. Meaning of each bit can be\n\t\t\tconsulted in header drivers/usb/host/xhci.h.\n\n\txmon\t\t[PPC]\n\t\t\tFormat: { early | on | rw | ro | off }\n\t\t\tControls if xmon debugger is enabled. Default is off.\n\t\t\tPassing only \"xmon\" is equivalent to \"xmon=early\".\n\t\t\tearly\tCall xmon as early as possible on boot; xmon\n\t\t\t\tdebugger is called from setup_arch().\n\t\t\ton\txmon debugger hooks will be installed so xmon\n\t\t\t\tis only called on a kernel crash. Default mode,\n\t\t\t\ti.e. either \"ro\" or \"rw\" mode, is controlled\n\t\t\t\twith CONFIG_XMON_DEFAULT_RO_MODE.\n\t\t\trw\txmon debugger hooks will be installed so xmon\n\t\t\t\tis called only on a kernel crash, mode is write,\n\t\t\t\tmeaning SPR registers, memory and, other data\n\t\t\t\tcan be written using xmon commands.\n\t\t\tro \tsame as \"rw\" option above but SPR registers,\n\t\t\t\tmemory, and other data can't be written using\n\t\t\t\txmon commands.\n\t\t\toff\txmon is disabled.\n", "// SPDX-License-Identifier: GPL-2.0\n/*\n * Xen event channels (2-level ABI)\n *\n * Jeremy Fitzhardinge <jeremy@xensource.com>, XenSource Inc, 2007\n */\n\n#define pr_fmt(fmt) \"xen:\" KBUILD_MODNAME \": \" fmt\n\n#include <linux/linkage.h>\n#include <linux/interrupt.h>\n#include <linux/irq.h>\n\n#include <asm/sync_bitops.h>\n#include <asm/xen/hypercall.h>\n#include <asm/xen/hypervisor.h>\n\n#include <xen/xen.h>\n#include <xen/xen-ops.h>\n#include <xen/events.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/event_channel.h>\n\n#include \"events_internal.h\"\n\n/*\n * Note sizeof(xen_ulong_t) can be more than sizeof(unsigned long). Be\n * careful to only use bitops which allow for this (e.g\n * test_bit/find_first_bit and friends but not __ffs) and to pass\n * BITS_PER_EVTCHN_WORD as the bitmask length.\n */\n#define BITS_PER_EVTCHN_WORD (sizeof(xen_ulong_t)*8)\n/*\n * Make a bitmask (i.e. unsigned long *) of a xen_ulong_t\n * array. Primarily to avoid long lines (hence the terse name).\n */\n#define BM(x) (unsigned long *)(x)\n/* Find the first set bit in a evtchn mask */\n#define EVTCHN_FIRST_BIT(w) find_first_bit(BM(&(w)), BITS_PER_EVTCHN_WORD)\n\n#define EVTCHN_MASK_SIZE (EVTCHN_2L_NR_CHANNELS/BITS_PER_EVTCHN_WORD)\n\nstatic DEFINE_PER_CPU(xen_ulong_t [EVTCHN_MASK_SIZE], cpu_evtchn_mask);\n\nstatic unsigned evtchn_2l_max_channels(void)\n{\n\treturn EVTCHN_2L_NR_CHANNELS;\n}\n\nstatic void evtchn_2l_bind_to_cpu(struct irq_info *info, unsigned cpu)\n{\n\tclear_bit(info->evtchn, BM(per_cpu(cpu_evtchn_mask, info->cpu)));\n\tset_bit(info->evtchn, BM(per_cpu(cpu_evtchn_mask, cpu)));\n}\n\nstatic void evtchn_2l_clear_pending(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tsync_clear_bit(port, BM(&s->evtchn_pending[0]));\n}\n\nstatic void evtchn_2l_set_pending(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tsync_set_bit(port, BM(&s->evtchn_pending[0]));\n}\n\nstatic bool evtchn_2l_is_pending(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\treturn sync_test_bit(port, BM(&s->evtchn_pending[0]));\n}\n\nstatic bool evtchn_2l_test_and_set_mask(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\treturn sync_test_and_set_bit(port, BM(&s->evtchn_mask[0]));\n}\n\nstatic void evtchn_2l_mask(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tsync_set_bit(port, BM(&s->evtchn_mask[0]));\n}\n\nstatic void evtchn_2l_unmask(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tunsigned int cpu = get_cpu();\n\tint do_hypercall = 0, evtchn_pending = 0;\n\n\tBUG_ON(!irqs_disabled());\n\n\tsmp_wmb();\t/* All writes before unmask must be visible. */\n\n\tif (unlikely((cpu != cpu_from_evtchn(port))))\n\t\tdo_hypercall = 1;\n\telse {\n\t\t/*\n\t\t * Need to clear the mask before checking pending to\n\t\t * avoid a race with an event becoming pending.\n\t\t *\n\t\t * EVTCHNOP_unmask will only trigger an upcall if the\n\t\t * mask bit was set, so if a hypercall is needed\n\t\t * remask the event.\n\t\t */\n\t\tsync_clear_bit(port, BM(&s->evtchn_mask[0]));\n\t\tevtchn_pending = sync_test_bit(port, BM(&s->evtchn_pending[0]));\n\n\t\tif (unlikely(evtchn_pending && xen_hvm_domain())) {\n\t\t\tsync_set_bit(port, BM(&s->evtchn_mask[0]));\n\t\t\tdo_hypercall = 1;\n\t\t}\n\t}\n\n\t/* Slow path (hypercall) if this is a non-local port or if this is\n\t * an hvm domain and an event is pending (hvm domains don't have\n\t * their own implementation of irq_enable). */\n\tif (do_hypercall) {\n\t\tstruct evtchn_unmask unmask = { .port = port };\n\t\t(void)HYPERVISOR_event_channel_op(EVTCHNOP_unmask, &unmask);\n\t} else {\n\t\tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n\n\t\t/*\n\t\t * The following is basically the equivalent of\n\t\t * 'hw_resend_irq'. Just like a real IO-APIC we 'lose\n\t\t * the interrupt edge' if the channel is masked.\n\t\t */\n\t\tif (evtchn_pending &&\n\t\t    !sync_test_and_set_bit(port / BITS_PER_EVTCHN_WORD,\n\t\t\t\t\t   BM(&vcpu_info->evtchn_pending_sel)))\n\t\t\tvcpu_info->evtchn_upcall_pending = 1;\n\t}\n\n\tput_cpu();\n}\n\nstatic DEFINE_PER_CPU(unsigned int, current_word_idx);\nstatic DEFINE_PER_CPU(unsigned int, current_bit_idx);\n\n/*\n * Mask out the i least significant bits of w\n */\n#define MASK_LSBS(w, i) (w & ((~((xen_ulong_t)0UL)) << i))\n\nstatic inline xen_ulong_t active_evtchns(unsigned int cpu,\n\t\t\t\t\t struct shared_info *sh,\n\t\t\t\t\t unsigned int idx)\n{\n\treturn sh->evtchn_pending[idx] &\n\t\tper_cpu(cpu_evtchn_mask, cpu)[idx] &\n\t\t~sh->evtchn_mask[idx];\n}\n\n/*\n * Search the CPU's pending events bitmasks.  For each one found, map\n * the event number to an irq, and feed it into do_IRQ() for handling.\n *\n * Xen uses a two-level bitmap to speed searching.  The first level is\n * a bitset of words which contain pending event bits.  The second\n * level is a bitset of pending events themselves.\n */\nstatic void evtchn_2l_handle_events(unsigned cpu)\n{\n\tint irq;\n\txen_ulong_t pending_words;\n\txen_ulong_t pending_bits;\n\tint start_word_idx, start_bit_idx;\n\tint word_idx, bit_idx;\n\tint i;\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n\n\t/* Timer interrupt has highest priority. */\n\tirq = irq_from_virq(cpu, VIRQ_TIMER);\n\tif (irq != -1) {\n\t\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\t\tword_idx = evtchn / BITS_PER_LONG;\n\t\tbit_idx = evtchn % BITS_PER_LONG;\n\t\tif (active_evtchns(cpu, s, word_idx) & (1ULL << bit_idx))\n\t\t\tgeneric_handle_irq(irq);\n\t}\n\n\t/*\n\t * Master flag must be cleared /before/ clearing\n\t * selector flag. xchg_xen_ulong must contain an\n\t * appropriate barrier.\n\t */\n\tpending_words = xchg_xen_ulong(&vcpu_info->evtchn_pending_sel, 0);\n\n\tstart_word_idx = __this_cpu_read(current_word_idx);\n\tstart_bit_idx = __this_cpu_read(current_bit_idx);\n\n\tword_idx = start_word_idx;\n\n\tfor (i = 0; pending_words != 0; i++) {\n\t\txen_ulong_t words;\n\n\t\twords = MASK_LSBS(pending_words, word_idx);\n\n\t\t/*\n\t\t * If we masked out all events, wrap to beginning.\n\t\t */\n\t\tif (words == 0) {\n\t\t\tword_idx = 0;\n\t\t\tbit_idx = 0;\n\t\t\tcontinue;\n\t\t}\n\t\tword_idx = EVTCHN_FIRST_BIT(words);\n\n\t\tpending_bits = active_evtchns(cpu, s, word_idx);\n\t\tbit_idx = 0; /* usually scan entire word from start */\n\t\t/*\n\t\t * We scan the starting word in two parts.\n\t\t *\n\t\t * 1st time: start in the middle, scanning the\n\t\t * upper bits.\n\t\t *\n\t\t * 2nd time: scan the whole word (not just the\n\t\t * parts skipped in the first pass) -- if an\n\t\t * event in the previously scanned bits is\n\t\t * pending again it would just be scanned on\n\t\t * the next loop anyway.\n\t\t */\n\t\tif (word_idx == start_word_idx) {\n\t\t\tif (i == 0)\n\t\t\t\tbit_idx = start_bit_idx;\n\t\t}\n\n\t\tdo {\n\t\t\txen_ulong_t bits;\n\t\t\tevtchn_port_t port;\n\n\t\t\tbits = MASK_LSBS(pending_bits, bit_idx);\n\n\t\t\t/* If we masked out all events, move on. */\n\t\t\tif (bits == 0)\n\t\t\t\tbreak;\n\n\t\t\tbit_idx = EVTCHN_FIRST_BIT(bits);\n\n\t\t\t/* Process port. */\n\t\t\tport = (word_idx * BITS_PER_EVTCHN_WORD) + bit_idx;\n\t\t\tirq = get_evtchn_to_irq(port);\n\n\t\t\tif (irq != -1)\n\t\t\t\tgeneric_handle_irq(irq);\n\n\t\t\tbit_idx = (bit_idx + 1) % BITS_PER_EVTCHN_WORD;\n\n\t\t\t/* Next caller starts at last processed + 1 */\n\t\t\t__this_cpu_write(current_word_idx,\n\t\t\t\t\t bit_idx ? word_idx :\n\t\t\t\t\t (word_idx+1) % BITS_PER_EVTCHN_WORD);\n\t\t\t__this_cpu_write(current_bit_idx, bit_idx);\n\t\t} while (bit_idx != 0);\n\n\t\t/* Scan start_l1i twice; all others once. */\n\t\tif ((word_idx != start_word_idx) || (i != 0))\n\t\t\tpending_words &= ~(1UL << word_idx);\n\n\t\tword_idx = (word_idx + 1) % BITS_PER_EVTCHN_WORD;\n\t}\n}\n\nirqreturn_t xen_debug_interrupt(int irq, void *dev_id)\n{\n\tstruct shared_info *sh = HYPERVISOR_shared_info;\n\tint cpu = smp_processor_id();\n\txen_ulong_t *cpu_evtchn = per_cpu(cpu_evtchn_mask, cpu);\n\tint i;\n\tunsigned long flags;\n\tstatic DEFINE_SPINLOCK(debug_lock);\n\tstruct vcpu_info *v;\n\n\tspin_lock_irqsave(&debug_lock, flags);\n\n\tprintk(\"\\nvcpu %d\\n  \", cpu);\n\n\tfor_each_online_cpu(i) {\n\t\tint pending;\n\t\tv = per_cpu(xen_vcpu, i);\n\t\tpending = (get_irq_regs() && i == cpu)\n\t\t\t? xen_irqs_disabled(get_irq_regs())\n\t\t\t: v->evtchn_upcall_mask;\n\t\tprintk(\"%d: masked=%d pending=%d event_sel %0*\"PRI_xen_ulong\"\\n  \", i,\n\t\t       pending, v->evtchn_upcall_pending,\n\t\t       (int)(sizeof(v->evtchn_pending_sel)*2),\n\t\t       v->evtchn_pending_sel);\n\t}\n\tv = per_cpu(xen_vcpu, cpu);\n\n\tprintk(\"\\npending:\\n   \");\n\tfor (i = ARRAY_SIZE(sh->evtchn_pending)-1; i >= 0; i--)\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\",\n\t\t       (int)sizeof(sh->evtchn_pending[0])*2,\n\t\t       sh->evtchn_pending[i],\n\t\t       i % 8 == 0 ? \"\\n   \" : \" \");\n\tprintk(\"\\nglobal mask:\\n   \");\n\tfor (i = ARRAY_SIZE(sh->evtchn_mask)-1; i >= 0; i--)\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\",\n\t\t       (int)(sizeof(sh->evtchn_mask[0])*2),\n\t\t       sh->evtchn_mask[i],\n\t\t       i % 8 == 0 ? \"\\n   \" : \" \");\n\n\tprintk(\"\\nglobally unmasked:\\n   \");\n\tfor (i = ARRAY_SIZE(sh->evtchn_mask)-1; i >= 0; i--)\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\",\n\t\t       (int)(sizeof(sh->evtchn_mask[0])*2),\n\t\t       sh->evtchn_pending[i] & ~sh->evtchn_mask[i],\n\t\t       i % 8 == 0 ? \"\\n   \" : \" \");\n\n\tprintk(\"\\nlocal cpu%d mask:\\n   \", cpu);\n\tfor (i = (EVTCHN_2L_NR_CHANNELS/BITS_PER_EVTCHN_WORD)-1; i >= 0; i--)\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\", (int)(sizeof(cpu_evtchn[0])*2),\n\t\t       cpu_evtchn[i],\n\t\t       i % 8 == 0 ? \"\\n   \" : \" \");\n\n\tprintk(\"\\nlocally unmasked:\\n   \");\n\tfor (i = ARRAY_SIZE(sh->evtchn_mask)-1; i >= 0; i--) {\n\t\txen_ulong_t pending = sh->evtchn_pending[i]\n\t\t\t& ~sh->evtchn_mask[i]\n\t\t\t& cpu_evtchn[i];\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\",\n\t\t       (int)(sizeof(sh->evtchn_mask[0])*2),\n\t\t       pending, i % 8 == 0 ? \"\\n   \" : \" \");\n\t}\n\n\tprintk(\"\\npending list:\\n\");\n\tfor (i = 0; i < EVTCHN_2L_NR_CHANNELS; i++) {\n\t\tif (sync_test_bit(i, BM(sh->evtchn_pending))) {\n\t\t\tint word_idx = i / BITS_PER_EVTCHN_WORD;\n\t\t\tprintk(\"  %d: event %d -> irq %d%s%s%s\\n\",\n\t\t\t       cpu_from_evtchn(i), i,\n\t\t\t       get_evtchn_to_irq(i),\n\t\t\t       sync_test_bit(word_idx, BM(&v->evtchn_pending_sel))\n\t\t\t       ? \"\" : \" l2-clear\",\n\t\t\t       !sync_test_bit(i, BM(sh->evtchn_mask))\n\t\t\t       ? \"\" : \" globally-masked\",\n\t\t\t       sync_test_bit(i, BM(cpu_evtchn))\n\t\t\t       ? \"\" : \" locally-masked\");\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&debug_lock, flags);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void evtchn_2l_resume(void)\n{\n\tint i;\n\n\tfor_each_online_cpu(i)\n\t\tmemset(per_cpu(cpu_evtchn_mask, i), 0, sizeof(xen_ulong_t) *\n\t\t\t\tEVTCHN_2L_NR_CHANNELS/BITS_PER_EVTCHN_WORD);\n}\n\nstatic const struct evtchn_ops evtchn_ops_2l = {\n\t.max_channels      = evtchn_2l_max_channels,\n\t.nr_channels       = evtchn_2l_max_channels,\n\t.bind_to_cpu       = evtchn_2l_bind_to_cpu,\n\t.clear_pending     = evtchn_2l_clear_pending,\n\t.set_pending       = evtchn_2l_set_pending,\n\t.is_pending        = evtchn_2l_is_pending,\n\t.test_and_set_mask = evtchn_2l_test_and_set_mask,\n\t.mask              = evtchn_2l_mask,\n\t.unmask            = evtchn_2l_unmask,\n\t.handle_events     = evtchn_2l_handle_events,\n\t.resume\t           = evtchn_2l_resume,\n};\n\nvoid __init xen_evtchn_2l_init(void)\n{\n\tpr_info(\"Using 2-level ABI\\n\");\n\tevtchn_ops = &evtchn_ops_2l;\n}\n", "// SPDX-License-Identifier: GPL-2.0-only\n/*\n * Xen event channels\n *\n * Xen models interrupts with abstract event channels.  Because each\n * domain gets 1024 event channels, but NR_IRQ is not that large, we\n * must dynamically map irqs<->event channels.  The event channels\n * interface with the rest of the kernel by defining a xen interrupt\n * chip.  When an event is received, it is mapped to an irq and sent\n * through the normal interrupt processing path.\n *\n * There are four kinds of events which can be mapped to an event\n * channel:\n *\n * 1. Inter-domain notifications.  This includes all the virtual\n *    device events, since they're driven by front-ends in another domain\n *    (typically dom0).\n * 2. VIRQs, typically used for timers.  These are per-cpu events.\n * 3. IPIs.\n * 4. PIRQs - Hardware interrupts.\n *\n * Jeremy Fitzhardinge <jeremy@xensource.com>, XenSource Inc, 2007\n */\n\n#define pr_fmt(fmt) \"xen:\" KBUILD_MODNAME \": \" fmt\n\n#include <linux/linkage.h>\n#include <linux/interrupt.h>\n#include <linux/irq.h>\n#include <linux/moduleparam.h>\n#include <linux/string.h>\n#include <linux/memblock.h>\n#include <linux/slab.h>\n#include <linux/irqnr.h>\n#include <linux/pci.h>\n#include <linux/spinlock.h>\n#include <linux/cpuhotplug.h>\n\n#ifdef CONFIG_X86\n#include <asm/desc.h>\n#include <asm/ptrace.h>\n#include <asm/idtentry.h>\n#include <asm/irq.h>\n#include <asm/io_apic.h>\n#include <asm/i8259.h>\n#include <asm/xen/pci.h>\n#endif\n#include <asm/sync_bitops.h>\n#include <asm/xen/hypercall.h>\n#include <asm/xen/hypervisor.h>\n#include <xen/page.h>\n\n#include <xen/xen.h>\n#include <xen/hvm.h>\n#include <xen/xen-ops.h>\n#include <xen/events.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/event_channel.h>\n#include <xen/interface/hvm/hvm_op.h>\n#include <xen/interface/hvm/params.h>\n#include <xen/interface/physdev.h>\n#include <xen/interface/sched.h>\n#include <xen/interface/vcpu.h>\n#include <asm/hw_irq.h>\n\n#include \"events_internal.h\"\n\nconst struct evtchn_ops *evtchn_ops;\n\n/*\n * This lock protects updates to the following mapping and reference-count\n * arrays. The lock does not need to be acquired to read the mapping tables.\n */\nstatic DEFINE_MUTEX(irq_mapping_update_lock);\n\n/*\n * Lock protecting event handling loop against removing event channels.\n * Adding of event channels is no issue as the associated IRQ becomes active\n * only after everything is setup (before request_[threaded_]irq() the handler\n * can't be entered for an event, as the event channel will be unmasked only\n * then).\n */\nstatic DEFINE_RWLOCK(evtchn_rwlock);\n\n/*\n * Lock hierarchy:\n *\n * irq_mapping_update_lock\n *   evtchn_rwlock\n *     IRQ-desc lock\n */\n\nstatic LIST_HEAD(xen_irq_list_head);\n\n/* IRQ <-> VIRQ mapping. */\nstatic DEFINE_PER_CPU(int [NR_VIRQS], virq_to_irq) = {[0 ... NR_VIRQS-1] = -1};\n\n/* IRQ <-> IPI mapping */\nstatic DEFINE_PER_CPU(int [XEN_NR_IPIS], ipi_to_irq) = {[0 ... XEN_NR_IPIS-1] = -1};\n\nint **evtchn_to_irq;\n#ifdef CONFIG_X86\nstatic unsigned long *pirq_eoi_map;\n#endif\nstatic bool (*pirq_needs_eoi)(unsigned irq);\n\n#define EVTCHN_ROW(e)  (e / (PAGE_SIZE/sizeof(**evtchn_to_irq)))\n#define EVTCHN_COL(e)  (e % (PAGE_SIZE/sizeof(**evtchn_to_irq)))\n#define EVTCHN_PER_ROW (PAGE_SIZE / sizeof(**evtchn_to_irq))\n\n/* Xen will never allocate port zero for any purpose. */\n#define VALID_EVTCHN(chn)\t((chn) != 0)\n\nstatic struct irq_info *legacy_info_ptrs[NR_IRQS_LEGACY];\n\nstatic struct irq_chip xen_dynamic_chip;\nstatic struct irq_chip xen_lateeoi_chip;\nstatic struct irq_chip xen_percpu_chip;\nstatic struct irq_chip xen_pirq_chip;\nstatic void enable_dynirq(struct irq_data *data);\nstatic void disable_dynirq(struct irq_data *data);\n\nstatic void clear_evtchn_to_irq_row(unsigned row)\n{\n\tunsigned col;\n\n\tfor (col = 0; col < EVTCHN_PER_ROW; col++)\n\t\tWRITE_ONCE(evtchn_to_irq[row][col], -1);\n}\n\nstatic void clear_evtchn_to_irq_all(void)\n{\n\tunsigned row;\n\n\tfor (row = 0; row < EVTCHN_ROW(xen_evtchn_max_channels()); row++) {\n\t\tif (evtchn_to_irq[row] == NULL)\n\t\t\tcontinue;\n\t\tclear_evtchn_to_irq_row(row);\n\t}\n}\n\nstatic int set_evtchn_to_irq(evtchn_port_t evtchn, unsigned int irq)\n{\n\tunsigned row;\n\tunsigned col;\n\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -EINVAL;\n\n\trow = EVTCHN_ROW(evtchn);\n\tcol = EVTCHN_COL(evtchn);\n\n\tif (evtchn_to_irq[row] == NULL) {\n\t\t/* Unallocated irq entries return -1 anyway */\n\t\tif (irq == -1)\n\t\t\treturn 0;\n\n\t\tevtchn_to_irq[row] = (int *)get_zeroed_page(GFP_KERNEL);\n\t\tif (evtchn_to_irq[row] == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tclear_evtchn_to_irq_row(row);\n\t}\n\n\tWRITE_ONCE(evtchn_to_irq[row][col], irq);\n\treturn 0;\n}\n\nint get_evtchn_to_irq(evtchn_port_t evtchn)\n{\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -1;\n\tif (evtchn_to_irq[EVTCHN_ROW(evtchn)] == NULL)\n\t\treturn -1;\n\treturn READ_ONCE(evtchn_to_irq[EVTCHN_ROW(evtchn)][EVTCHN_COL(evtchn)]);\n}\n\n/* Get info for IRQ */\nstruct irq_info *info_for_irq(unsigned irq)\n{\n\tif (irq < nr_legacy_irqs())\n\t\treturn legacy_info_ptrs[irq];\n\telse\n\t\treturn irq_get_chip_data(irq);\n}\n\nstatic void set_info_for_irq(unsigned int irq, struct irq_info *info)\n{\n\tif (irq < nr_legacy_irqs())\n\t\tlegacy_info_ptrs[irq] = info;\n\telse\n\t\tirq_set_chip_data(irq, info);\n}\n\n/* Constructors for packed IRQ information. */\nstatic int xen_irq_info_common_setup(struct irq_info *info,\n\t\t\t\t     unsigned irq,\n\t\t\t\t     enum xen_irq_type type,\n\t\t\t\t     evtchn_port_t evtchn,\n\t\t\t\t     unsigned short cpu)\n{\n\tint ret;\n\n\tBUG_ON(info->type != IRQT_UNBOUND && info->type != type);\n\n\tinfo->type = type;\n\tinfo->irq = irq;\n\tinfo->evtchn = evtchn;\n\tinfo->cpu = cpu;\n\n\tret = set_evtchn_to_irq(evtchn, irq);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tirq_clear_status_flags(irq, IRQ_NOREQUEST|IRQ_NOAUTOEN);\n\n\treturn xen_evtchn_port_setup(info);\n}\n\nstatic int xen_irq_info_evtchn_setup(unsigned irq,\n\t\t\t\t     evtchn_port_t evtchn)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\treturn xen_irq_info_common_setup(info, irq, IRQT_EVTCHN, evtchn, 0);\n}\n\nstatic int xen_irq_info_ipi_setup(unsigned cpu,\n\t\t\t\t  unsigned irq,\n\t\t\t\t  evtchn_port_t evtchn,\n\t\t\t\t  enum ipi_vector ipi)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tinfo->u.ipi = ipi;\n\n\tper_cpu(ipi_to_irq, cpu)[ipi] = irq;\n\n\treturn xen_irq_info_common_setup(info, irq, IRQT_IPI, evtchn, 0);\n}\n\nstatic int xen_irq_info_virq_setup(unsigned cpu,\n\t\t\t\t   unsigned irq,\n\t\t\t\t   evtchn_port_t evtchn,\n\t\t\t\t   unsigned virq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tinfo->u.virq = virq;\n\n\tper_cpu(virq_to_irq, cpu)[virq] = irq;\n\n\treturn xen_irq_info_common_setup(info, irq, IRQT_VIRQ, evtchn, 0);\n}\n\nstatic int xen_irq_info_pirq_setup(unsigned irq,\n\t\t\t\t   evtchn_port_t evtchn,\n\t\t\t\t   unsigned pirq,\n\t\t\t\t   unsigned gsi,\n\t\t\t\t   uint16_t domid,\n\t\t\t\t   unsigned char flags)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tinfo->u.pirq.pirq = pirq;\n\tinfo->u.pirq.gsi = gsi;\n\tinfo->u.pirq.domid = domid;\n\tinfo->u.pirq.flags = flags;\n\n\treturn xen_irq_info_common_setup(info, irq, IRQT_PIRQ, evtchn, 0);\n}\n\nstatic void xen_irq_info_cleanup(struct irq_info *info)\n{\n\tset_evtchn_to_irq(info->evtchn, -1);\n\tinfo->evtchn = 0;\n}\n\n/*\n * Accessors for packed IRQ information.\n */\nevtchn_port_t evtchn_from_irq(unsigned irq)\n{\n\tconst struct irq_info *info = NULL;\n\n\tif (likely(irq < nr_irqs))\n\t\tinfo = info_for_irq(irq);\n\tif (!info)\n\t\treturn 0;\n\n\treturn info->evtchn;\n}\n\nunsigned int irq_from_evtchn(evtchn_port_t evtchn)\n{\n\treturn get_evtchn_to_irq(evtchn);\n}\nEXPORT_SYMBOL_GPL(irq_from_evtchn);\n\nint irq_from_virq(unsigned int cpu, unsigned int virq)\n{\n\treturn per_cpu(virq_to_irq, cpu)[virq];\n}\n\nstatic enum ipi_vector ipi_from_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(info == NULL);\n\tBUG_ON(info->type != IRQT_IPI);\n\n\treturn info->u.ipi;\n}\n\nstatic unsigned virq_from_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(info == NULL);\n\tBUG_ON(info->type != IRQT_VIRQ);\n\n\treturn info->u.virq;\n}\n\nstatic unsigned pirq_from_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(info == NULL);\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\treturn info->u.pirq.pirq;\n}\n\nstatic enum xen_irq_type type_from_irq(unsigned irq)\n{\n\treturn info_for_irq(irq)->type;\n}\n\nunsigned cpu_from_irq(unsigned irq)\n{\n\treturn info_for_irq(irq)->cpu;\n}\n\nunsigned int cpu_from_evtchn(evtchn_port_t evtchn)\n{\n\tint irq = get_evtchn_to_irq(evtchn);\n\tunsigned ret = 0;\n\n\tif (irq != -1)\n\t\tret = cpu_from_irq(irq);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_X86\nstatic bool pirq_check_eoi_map(unsigned irq)\n{\n\treturn test_bit(pirq_from_irq(irq), pirq_eoi_map);\n}\n#endif\n\nstatic bool pirq_needs_eoi_flag(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\treturn info->u.pirq.flags & PIRQ_NEEDS_EOI;\n}\n\nstatic void bind_evtchn_to_cpu(evtchn_port_t evtchn, unsigned int cpu)\n{\n\tint irq = get_evtchn_to_irq(evtchn);\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(irq == -1);\n#ifdef CONFIG_SMP\n\tcpumask_copy(irq_get_affinity_mask(irq), cpumask_of(cpu));\n#endif\n\txen_evtchn_port_bind_to_cpu(info, cpu);\n\n\tinfo->cpu = cpu;\n}\n\n/**\n * notify_remote_via_irq - send event to remote end of event channel via irq\n * @irq: irq of event channel to send event to\n *\n * Unlike notify_remote_via_evtchn(), this is safe to use across\n * save/restore. Notifications on a broken connection are silently\n * dropped.\n */\nvoid notify_remote_via_irq(int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tnotify_remote_via_evtchn(evtchn);\n}\nEXPORT_SYMBOL_GPL(notify_remote_via_irq);\n\nstatic void xen_irq_lateeoi_locked(struct irq_info *info)\n{\n\tevtchn_port_t evtchn;\n\n\tevtchn = info->evtchn;\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn;\n\n\tunmask_evtchn(evtchn);\n}\n\nvoid xen_irq_lateeoi(unsigned int irq, unsigned int eoi_flags)\n{\n\tstruct irq_info *info;\n\tunsigned long flags;\n\n\tread_lock_irqsave(&evtchn_rwlock, flags);\n\n\tinfo = info_for_irq(irq);\n\n\tif (info)\n\t\txen_irq_lateeoi_locked(info);\n\n\tread_unlock_irqrestore(&evtchn_rwlock, flags);\n}\nEXPORT_SYMBOL_GPL(xen_irq_lateeoi);\n\nstatic void xen_irq_init(unsigned irq)\n{\n\tstruct irq_info *info;\n#ifdef CONFIG_SMP\n\t/* By default all event channels notify CPU#0. */\n\tcpumask_copy(irq_get_affinity_mask(irq), cpumask_of(0));\n#endif\n\n\tinfo = kzalloc(sizeof(*info), GFP_KERNEL);\n\tif (info == NULL)\n\t\tpanic(\"Unable to allocate metadata for IRQ%d\\n\", irq);\n\n\tinfo->type = IRQT_UNBOUND;\n\tinfo->refcnt = -1;\n\n\tset_info_for_irq(irq, info);\n\n\tlist_add_tail(&info->list, &xen_irq_list_head);\n}\n\nstatic int __must_check xen_allocate_irqs_dynamic(int nvec)\n{\n\tint i, irq = irq_alloc_descs(-1, 0, nvec, -1);\n\n\tif (irq >= 0) {\n\t\tfor (i = 0; i < nvec; i++)\n\t\t\txen_irq_init(irq + i);\n\t}\n\n\treturn irq;\n}\n\nstatic inline int __must_check xen_allocate_irq_dynamic(void)\n{\n\n\treturn xen_allocate_irqs_dynamic(1);\n}\n\nstatic int __must_check xen_allocate_irq_gsi(unsigned gsi)\n{\n\tint irq;\n\n\t/*\n\t * A PV guest has no concept of a GSI (since it has no ACPI\n\t * nor access to/knowledge of the physical APICs). Therefore\n\t * all IRQs are dynamically allocated from the entire IRQ\n\t * space.\n\t */\n\tif (xen_pv_domain() && !xen_initial_domain())\n\t\treturn xen_allocate_irq_dynamic();\n\n\t/* Legacy IRQ descriptors are already allocated by the arch. */\n\tif (gsi < nr_legacy_irqs())\n\t\tirq = gsi;\n\telse\n\t\tirq = irq_alloc_desc_at(gsi, -1);\n\n\txen_irq_init(irq);\n\n\treturn irq;\n}\n\nstatic void xen_free_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\tunsigned long flags;\n\n\tif (WARN_ON(!info))\n\t\treturn;\n\n\twrite_lock_irqsave(&evtchn_rwlock, flags);\n\n\tlist_del(&info->list);\n\n\tset_info_for_irq(irq, NULL);\n\n\tWARN_ON(info->refcnt > 0);\n\n\twrite_unlock_irqrestore(&evtchn_rwlock, flags);\n\n\tkfree(info);\n\n\t/* Legacy IRQ descriptors are managed by the arch. */\n\tif (irq < nr_legacy_irqs())\n\t\treturn;\n\n\tirq_free_desc(irq);\n}\n\nstatic void xen_evtchn_close(evtchn_port_t port)\n{\n\tstruct evtchn_close close;\n\n\tclose.port = port;\n\tif (HYPERVISOR_event_channel_op(EVTCHNOP_close, &close) != 0)\n\t\tBUG();\n}\n\nstatic void pirq_query_unmask(int irq)\n{\n\tstruct physdev_irq_status_query irq_status;\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\tirq_status.irq = pirq_from_irq(irq);\n\tif (HYPERVISOR_physdev_op(PHYSDEVOP_irq_status_query, &irq_status))\n\t\tirq_status.flags = 0;\n\n\tinfo->u.pirq.flags &= ~PIRQ_NEEDS_EOI;\n\tif (irq_status.flags & XENIRQSTAT_needs_eoi)\n\t\tinfo->u.pirq.flags |= PIRQ_NEEDS_EOI;\n}\n\nstatic void eoi_pirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\tstruct physdev_eoi eoi = { .irq = pirq_from_irq(data->irq) };\n\tint rc = 0;\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn;\n\n\tif (unlikely(irqd_is_setaffinity_pending(data)) &&\n\t    likely(!irqd_irq_disabled(data))) {\n\t\tint masked = test_and_set_mask(evtchn);\n\n\t\tclear_evtchn(evtchn);\n\n\t\tirq_move_masked_irq(data);\n\n\t\tif (!masked)\n\t\t\tunmask_evtchn(evtchn);\n\t} else\n\t\tclear_evtchn(evtchn);\n\n\tif (pirq_needs_eoi(data->irq)) {\n\t\trc = HYPERVISOR_physdev_op(PHYSDEVOP_eoi, &eoi);\n\t\tWARN_ON(rc);\n\t}\n}\n\nstatic void mask_ack_pirq(struct irq_data *data)\n{\n\tdisable_dynirq(data);\n\teoi_pirq(data);\n}\n\nstatic unsigned int __startup_pirq(unsigned int irq)\n{\n\tstruct evtchn_bind_pirq bind_pirq;\n\tstruct irq_info *info = info_for_irq(irq);\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\tint rc;\n\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tgoto out;\n\n\tbind_pirq.pirq = pirq_from_irq(irq);\n\t/* NB. We are happy to share unless we are probing. */\n\tbind_pirq.flags = info->u.pirq.flags & PIRQ_SHAREABLE ?\n\t\t\t\t\tBIND_PIRQ__WILL_SHARE : 0;\n\trc = HYPERVISOR_event_channel_op(EVTCHNOP_bind_pirq, &bind_pirq);\n\tif (rc != 0) {\n\t\tpr_warn(\"Failed to obtain physical IRQ %d\\n\", irq);\n\t\treturn 0;\n\t}\n\tevtchn = bind_pirq.port;\n\n\tpirq_query_unmask(irq);\n\n\trc = set_evtchn_to_irq(evtchn, irq);\n\tif (rc)\n\t\tgoto err;\n\n\tinfo->evtchn = evtchn;\n\tbind_evtchn_to_cpu(evtchn, 0);\n\n\trc = xen_evtchn_port_setup(info);\n\tif (rc)\n\t\tgoto err;\n\nout:\n\tunmask_evtchn(evtchn);\n\teoi_pirq(irq_get_irq_data(irq));\n\n\treturn 0;\n\nerr:\n\tpr_err(\"irq%d: Failed to set port to irq mapping (%d)\\n\", irq, rc);\n\txen_evtchn_close(evtchn);\n\treturn 0;\n}\n\nstatic unsigned int startup_pirq(struct irq_data *data)\n{\n\treturn __startup_pirq(data->irq);\n}\n\nstatic void shutdown_pirq(struct irq_data *data)\n{\n\tunsigned int irq = data->irq;\n\tstruct irq_info *info = info_for_irq(irq);\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn;\n\n\tmask_evtchn(evtchn);\n\txen_evtchn_close(evtchn);\n\txen_irq_info_cleanup(info);\n}\n\nstatic void enable_pirq(struct irq_data *data)\n{\n\tenable_dynirq(data);\n}\n\nstatic void disable_pirq(struct irq_data *data)\n{\n\tdisable_dynirq(data);\n}\n\nint xen_irq_from_gsi(unsigned gsi)\n{\n\tstruct irq_info *info;\n\n\tlist_for_each_entry(info, &xen_irq_list_head, list) {\n\t\tif (info->type != IRQT_PIRQ)\n\t\t\tcontinue;\n\n\t\tif (info->u.pirq.gsi == gsi)\n\t\t\treturn info->irq;\n\t}\n\n\treturn -1;\n}\nEXPORT_SYMBOL_GPL(xen_irq_from_gsi);\n\nstatic void __unbind_from_irq(unsigned int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tif (info->refcnt > 0) {\n\t\tinfo->refcnt--;\n\t\tif (info->refcnt != 0)\n\t\t\treturn;\n\t}\n\n\tif (VALID_EVTCHN(evtchn)) {\n\t\tunsigned int cpu = cpu_from_irq(irq);\n\n\t\txen_evtchn_close(evtchn);\n\n\t\tswitch (type_from_irq(irq)) {\n\t\tcase IRQT_VIRQ:\n\t\t\tper_cpu(virq_to_irq, cpu)[virq_from_irq(irq)] = -1;\n\t\t\tbreak;\n\t\tcase IRQT_IPI:\n\t\t\tper_cpu(ipi_to_irq, cpu)[ipi_from_irq(irq)] = -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\txen_irq_info_cleanup(info);\n\t}\n\n\txen_free_irq(irq);\n}\n\n/*\n * Do not make any assumptions regarding the relationship between the\n * IRQ number returned here and the Xen pirq argument.\n *\n * Note: We don't assign an event channel until the irq actually started\n * up.  Return an existing irq if we've already got one for the gsi.\n *\n * Shareable implies level triggered, not shareable implies edge\n * triggered here.\n */\nint xen_bind_pirq_gsi_to_irq(unsigned gsi,\n\t\t\t     unsigned pirq, int shareable, char *name)\n{\n\tint irq = -1;\n\tstruct physdev_irq irq_op;\n\tint ret;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = xen_irq_from_gsi(gsi);\n\tif (irq != -1) {\n\t\tpr_info(\"%s: returning irq %d for gsi %u\\n\",\n\t\t\t__func__, irq, gsi);\n\t\tgoto out;\n\t}\n\n\tirq = xen_allocate_irq_gsi(gsi);\n\tif (irq < 0)\n\t\tgoto out;\n\n\tirq_op.irq = irq;\n\tirq_op.vector = 0;\n\n\t/* Only the privileged domain can do this. For non-priv, the pcifront\n\t * driver provides a PCI bus that does the call to do exactly\n\t * this in the priv domain. */\n\tif (xen_initial_domain() &&\n\t    HYPERVISOR_physdev_op(PHYSDEVOP_alloc_irq_vector, &irq_op)) {\n\t\txen_free_irq(irq);\n\t\tirq = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\tret = xen_irq_info_pirq_setup(irq, 0, pirq, gsi, DOMID_SELF,\n\t\t\t       shareable ? PIRQ_SHAREABLE : 0);\n\tif (ret < 0) {\n\t\t__unbind_from_irq(irq);\n\t\tirq = ret;\n\t\tgoto out;\n\t}\n\n\tpirq_query_unmask(irq);\n\t/* We try to use the handler with the appropriate semantic for the\n\t * type of interrupt: if the interrupt is an edge triggered\n\t * interrupt we use handle_edge_irq.\n\t *\n\t * On the other hand if the interrupt is level triggered we use\n\t * handle_fasteoi_irq like the native code does for this kind of\n\t * interrupts.\n\t *\n\t * Depending on the Xen version, pirq_needs_eoi might return true\n\t * not only for level triggered interrupts but for edge triggered\n\t * interrupts too. In any case Xen always honors the eoi mechanism,\n\t * not injecting any more pirqs of the same kind if the first one\n\t * hasn't received an eoi yet. Therefore using the fasteoi handler\n\t * is the right choice either way.\n\t */\n\tif (shareable)\n\t\tirq_set_chip_and_handler_name(irq, &xen_pirq_chip,\n\t\t\t\thandle_fasteoi_irq, name);\n\telse\n\t\tirq_set_chip_and_handler_name(irq, &xen_pirq_chip,\n\t\t\t\thandle_edge_irq, name);\n\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn irq;\n}\n\n#ifdef CONFIG_PCI_MSI\nint xen_allocate_pirq_msi(struct pci_dev *dev, struct msi_desc *msidesc)\n{\n\tint rc;\n\tstruct physdev_get_free_pirq op_get_free_pirq;\n\n\top_get_free_pirq.type = MAP_PIRQ_TYPE_MSI;\n\trc = HYPERVISOR_physdev_op(PHYSDEVOP_get_free_pirq, &op_get_free_pirq);\n\n\tWARN_ONCE(rc == -ENOSYS,\n\t\t  \"hypervisor does not support the PHYSDEVOP_get_free_pirq interface\\n\");\n\n\treturn rc ? -1 : op_get_free_pirq.pirq;\n}\n\nint xen_bind_pirq_msi_to_irq(struct pci_dev *dev, struct msi_desc *msidesc,\n\t\t\t     int pirq, int nvec, const char *name, domid_t domid)\n{\n\tint i, irq, ret;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = xen_allocate_irqs_dynamic(nvec);\n\tif (irq < 0)\n\t\tgoto out;\n\n\tfor (i = 0; i < nvec; i++) {\n\t\tirq_set_chip_and_handler_name(irq + i, &xen_pirq_chip, handle_edge_irq, name);\n\n\t\tret = xen_irq_info_pirq_setup(irq + i, 0, pirq + i, 0, domid,\n\t\t\t\t\t      i == 0 ? 0 : PIRQ_MSI_GROUP);\n\t\tif (ret < 0)\n\t\t\tgoto error_irq;\n\t}\n\n\tret = irq_set_msi_desc(irq, msidesc);\n\tif (ret < 0)\n\t\tgoto error_irq;\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\treturn irq;\nerror_irq:\n\twhile (nvec--)\n\t\t__unbind_from_irq(irq + nvec);\n\tmutex_unlock(&irq_mapping_update_lock);\n\treturn ret;\n}\n#endif\n\nint xen_destroy_irq(int irq)\n{\n\tstruct physdev_unmap_pirq unmap_irq;\n\tstruct irq_info *info = info_for_irq(irq);\n\tint rc = -ENOENT;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\t/*\n\t * If trying to remove a vector in a MSI group different\n\t * than the first one skip the PIRQ unmap unless this vector\n\t * is the first one in the group.\n\t */\n\tif (xen_initial_domain() && !(info->u.pirq.flags & PIRQ_MSI_GROUP)) {\n\t\tunmap_irq.pirq = info->u.pirq.pirq;\n\t\tunmap_irq.domid = info->u.pirq.domid;\n\t\trc = HYPERVISOR_physdev_op(PHYSDEVOP_unmap_pirq, &unmap_irq);\n\t\t/* If another domain quits without making the pci_disable_msix\n\t\t * call, the Xen hypervisor takes care of freeing the PIRQs\n\t\t * (free_domain_pirqs).\n\t\t */\n\t\tif ((rc == -ESRCH && info->u.pirq.domid != DOMID_SELF))\n\t\t\tpr_info(\"domain %d does not have %d anymore\\n\",\n\t\t\t\tinfo->u.pirq.domid, info->u.pirq.pirq);\n\t\telse if (rc) {\n\t\t\tpr_warn(\"unmap irq failed %d\\n\", rc);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\txen_free_irq(irq);\n\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\treturn rc;\n}\n\nint xen_irq_from_pirq(unsigned pirq)\n{\n\tint irq;\n\n\tstruct irq_info *info;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tlist_for_each_entry(info, &xen_irq_list_head, list) {\n\t\tif (info->type != IRQT_PIRQ)\n\t\t\tcontinue;\n\t\tirq = info->irq;\n\t\tif (info->u.pirq.pirq == pirq)\n\t\t\tgoto out;\n\t}\n\tirq = -1;\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn irq;\n}\n\n\nint xen_pirq_from_irq(unsigned irq)\n{\n\treturn pirq_from_irq(irq);\n}\nEXPORT_SYMBOL_GPL(xen_pirq_from_irq);\n\nstatic int bind_evtchn_to_irq_chip(evtchn_port_t evtchn, struct irq_chip *chip)\n{\n\tint irq;\n\tint ret;\n\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = get_evtchn_to_irq(evtchn);\n\n\tif (irq == -1) {\n\t\tirq = xen_allocate_irq_dynamic();\n\t\tif (irq < 0)\n\t\t\tgoto out;\n\n\t\tirq_set_chip_and_handler_name(irq, chip,\n\t\t\t\t\t      handle_edge_irq, \"event\");\n\n\t\tret = xen_irq_info_evtchn_setup(irq, evtchn);\n\t\tif (ret < 0) {\n\t\t\t__unbind_from_irq(irq);\n\t\t\tirq = ret;\n\t\t\tgoto out;\n\t\t}\n\t\t/* New interdomain events are bound to VCPU 0. */\n\t\tbind_evtchn_to_cpu(evtchn, 0);\n\t} else {\n\t\tstruct irq_info *info = info_for_irq(irq);\n\t\tWARN_ON(info == NULL || info->type != IRQT_EVTCHN);\n\t}\n\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn irq;\n}\n\nint bind_evtchn_to_irq(evtchn_port_t evtchn)\n{\n\treturn bind_evtchn_to_irq_chip(evtchn, &xen_dynamic_chip);\n}\nEXPORT_SYMBOL_GPL(bind_evtchn_to_irq);\n\nint bind_evtchn_to_irq_lateeoi(evtchn_port_t evtchn)\n{\n\treturn bind_evtchn_to_irq_chip(evtchn, &xen_lateeoi_chip);\n}\nEXPORT_SYMBOL_GPL(bind_evtchn_to_irq_lateeoi);\n\nstatic int bind_ipi_to_irq(unsigned int ipi, unsigned int cpu)\n{\n\tstruct evtchn_bind_ipi bind_ipi;\n\tevtchn_port_t evtchn;\n\tint ret, irq;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = per_cpu(ipi_to_irq, cpu)[ipi];\n\n\tif (irq == -1) {\n\t\tirq = xen_allocate_irq_dynamic();\n\t\tif (irq < 0)\n\t\t\tgoto out;\n\n\t\tirq_set_chip_and_handler_name(irq, &xen_percpu_chip,\n\t\t\t\t\t      handle_percpu_irq, \"ipi\");\n\n\t\tbind_ipi.vcpu = xen_vcpu_nr(cpu);\n\t\tif (HYPERVISOR_event_channel_op(EVTCHNOP_bind_ipi,\n\t\t\t\t\t\t&bind_ipi) != 0)\n\t\t\tBUG();\n\t\tevtchn = bind_ipi.port;\n\n\t\tret = xen_irq_info_ipi_setup(cpu, irq, evtchn, ipi);\n\t\tif (ret < 0) {\n\t\t\t__unbind_from_irq(irq);\n\t\t\tirq = ret;\n\t\t\tgoto out;\n\t\t}\n\t\tbind_evtchn_to_cpu(evtchn, cpu);\n\t} else {\n\t\tstruct irq_info *info = info_for_irq(irq);\n\t\tWARN_ON(info == NULL || info->type != IRQT_IPI);\n\t}\n\n out:\n\tmutex_unlock(&irq_mapping_update_lock);\n\treturn irq;\n}\n\nstatic int bind_interdomain_evtchn_to_irq_chip(unsigned int remote_domain,\n\t\t\t\t\t       evtchn_port_t remote_port,\n\t\t\t\t\t       struct irq_chip *chip)\n{\n\tstruct evtchn_bind_interdomain bind_interdomain;\n\tint err;\n\n\tbind_interdomain.remote_dom  = remote_domain;\n\tbind_interdomain.remote_port = remote_port;\n\n\terr = HYPERVISOR_event_channel_op(EVTCHNOP_bind_interdomain,\n\t\t\t\t\t  &bind_interdomain);\n\n\treturn err ? : bind_evtchn_to_irq_chip(bind_interdomain.local_port,\n\t\t\t\t\t       chip);\n}\n\nint bind_interdomain_evtchn_to_irq(unsigned int remote_domain,\n\t\t\t\t   evtchn_port_t remote_port)\n{\n\treturn bind_interdomain_evtchn_to_irq_chip(remote_domain, remote_port,\n\t\t\t\t\t\t   &xen_dynamic_chip);\n}\nEXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irq);\n\nint bind_interdomain_evtchn_to_irq_lateeoi(unsigned int remote_domain,\n\t\t\t\t\t   evtchn_port_t remote_port)\n{\n\treturn bind_interdomain_evtchn_to_irq_chip(remote_domain, remote_port,\n\t\t\t\t\t\t   &xen_lateeoi_chip);\n}\nEXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irq_lateeoi);\n\nstatic int find_virq(unsigned int virq, unsigned int cpu, evtchn_port_t *evtchn)\n{\n\tstruct evtchn_status status;\n\tevtchn_port_t port;\n\tint rc = -ENOENT;\n\n\tmemset(&status, 0, sizeof(status));\n\tfor (port = 0; port < xen_evtchn_max_channels(); port++) {\n\t\tstatus.dom = DOMID_SELF;\n\t\tstatus.port = port;\n\t\trc = HYPERVISOR_event_channel_op(EVTCHNOP_status, &status);\n\t\tif (rc < 0)\n\t\t\tcontinue;\n\t\tif (status.status != EVTCHNSTAT_virq)\n\t\t\tcontinue;\n\t\tif (status.u.virq == virq && status.vcpu == xen_vcpu_nr(cpu)) {\n\t\t\t*evtchn = port;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn rc;\n}\n\n/**\n * xen_evtchn_nr_channels - number of usable event channel ports\n *\n * This may be less than the maximum supported by the current\n * hypervisor ABI. Use xen_evtchn_max_channels() for the maximum\n * supported.\n */\nunsigned xen_evtchn_nr_channels(void)\n{\n        return evtchn_ops->nr_channels();\n}\nEXPORT_SYMBOL_GPL(xen_evtchn_nr_channels);\n\nint bind_virq_to_irq(unsigned int virq, unsigned int cpu, bool percpu)\n{\n\tstruct evtchn_bind_virq bind_virq;\n\tevtchn_port_t evtchn = 0;\n\tint irq, ret;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = per_cpu(virq_to_irq, cpu)[virq];\n\n\tif (irq == -1) {\n\t\tirq = xen_allocate_irq_dynamic();\n\t\tif (irq < 0)\n\t\t\tgoto out;\n\n\t\tif (percpu)\n\t\t\tirq_set_chip_and_handler_name(irq, &xen_percpu_chip,\n\t\t\t\t\t\t      handle_percpu_irq, \"virq\");\n\t\telse\n\t\t\tirq_set_chip_and_handler_name(irq, &xen_dynamic_chip,\n\t\t\t\t\t\t      handle_edge_irq, \"virq\");\n\n\t\tbind_virq.virq = virq;\n\t\tbind_virq.vcpu = xen_vcpu_nr(cpu);\n\t\tret = HYPERVISOR_event_channel_op(EVTCHNOP_bind_virq,\n\t\t\t\t\t\t&bind_virq);\n\t\tif (ret == 0)\n\t\t\tevtchn = bind_virq.port;\n\t\telse {\n\t\t\tif (ret == -EEXIST)\n\t\t\t\tret = find_virq(virq, cpu, &evtchn);\n\t\t\tBUG_ON(ret < 0);\n\t\t}\n\n\t\tret = xen_irq_info_virq_setup(cpu, irq, evtchn, virq);\n\t\tif (ret < 0) {\n\t\t\t__unbind_from_irq(irq);\n\t\t\tirq = ret;\n\t\t\tgoto out;\n\t\t}\n\n\t\tbind_evtchn_to_cpu(evtchn, cpu);\n\t} else {\n\t\tstruct irq_info *info = info_for_irq(irq);\n\t\tWARN_ON(info == NULL || info->type != IRQT_VIRQ);\n\t}\n\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn irq;\n}\n\nstatic void unbind_from_irq(unsigned int irq)\n{\n\tmutex_lock(&irq_mapping_update_lock);\n\t__unbind_from_irq(irq);\n\tmutex_unlock(&irq_mapping_update_lock);\n}\n\nstatic int bind_evtchn_to_irqhandler_chip(evtchn_port_t evtchn,\n\t\t\t\t\t  irq_handler_t handler,\n\t\t\t\t\t  unsigned long irqflags,\n\t\t\t\t\t  const char *devname, void *dev_id,\n\t\t\t\t\t  struct irq_chip *chip)\n{\n\tint irq, retval;\n\n\tirq = bind_evtchn_to_irq_chip(evtchn, chip);\n\tif (irq < 0)\n\t\treturn irq;\n\tretval = request_irq(irq, handler, irqflags, devname, dev_id);\n\tif (retval != 0) {\n\t\tunbind_from_irq(irq);\n\t\treturn retval;\n\t}\n\n\treturn irq;\n}\n\nint bind_evtchn_to_irqhandler(evtchn_port_t evtchn,\n\t\t\t      irq_handler_t handler,\n\t\t\t      unsigned long irqflags,\n\t\t\t      const char *devname, void *dev_id)\n{\n\treturn bind_evtchn_to_irqhandler_chip(evtchn, handler, irqflags,\n\t\t\t\t\t      devname, dev_id,\n\t\t\t\t\t      &xen_dynamic_chip);\n}\nEXPORT_SYMBOL_GPL(bind_evtchn_to_irqhandler);\n\nint bind_evtchn_to_irqhandler_lateeoi(evtchn_port_t evtchn,\n\t\t\t\t      irq_handler_t handler,\n\t\t\t\t      unsigned long irqflags,\n\t\t\t\t      const char *devname, void *dev_id)\n{\n\treturn bind_evtchn_to_irqhandler_chip(evtchn, handler, irqflags,\n\t\t\t\t\t      devname, dev_id,\n\t\t\t\t\t      &xen_lateeoi_chip);\n}\nEXPORT_SYMBOL_GPL(bind_evtchn_to_irqhandler_lateeoi);\n\nstatic int bind_interdomain_evtchn_to_irqhandler_chip(\n\t\tunsigned int remote_domain, evtchn_port_t remote_port,\n\t\tirq_handler_t handler, unsigned long irqflags,\n\t\tconst char *devname, void *dev_id, struct irq_chip *chip)\n{\n\tint irq, retval;\n\n\tirq = bind_interdomain_evtchn_to_irq_chip(remote_domain, remote_port,\n\t\t\t\t\t\t  chip);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tretval = request_irq(irq, handler, irqflags, devname, dev_id);\n\tif (retval != 0) {\n\t\tunbind_from_irq(irq);\n\t\treturn retval;\n\t}\n\n\treturn irq;\n}\n\nint bind_interdomain_evtchn_to_irqhandler(unsigned int remote_domain,\n\t\t\t\t\t  evtchn_port_t remote_port,\n\t\t\t\t\t  irq_handler_t handler,\n\t\t\t\t\t  unsigned long irqflags,\n\t\t\t\t\t  const char *devname,\n\t\t\t\t\t  void *dev_id)\n{\n\treturn bind_interdomain_evtchn_to_irqhandler_chip(remote_domain,\n\t\t\t\tremote_port, handler, irqflags, devname,\n\t\t\t\tdev_id, &xen_dynamic_chip);\n}\nEXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irqhandler);\n\nint bind_interdomain_evtchn_to_irqhandler_lateeoi(unsigned int remote_domain,\n\t\t\t\t\t\t  evtchn_port_t remote_port,\n\t\t\t\t\t\t  irq_handler_t handler,\n\t\t\t\t\t\t  unsigned long irqflags,\n\t\t\t\t\t\t  const char *devname,\n\t\t\t\t\t\t  void *dev_id)\n{\n\treturn bind_interdomain_evtchn_to_irqhandler_chip(remote_domain,\n\t\t\t\tremote_port, handler, irqflags, devname,\n\t\t\t\tdev_id, &xen_lateeoi_chip);\n}\nEXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irqhandler_lateeoi);\n\nint bind_virq_to_irqhandler(unsigned int virq, unsigned int cpu,\n\t\t\t    irq_handler_t handler,\n\t\t\t    unsigned long irqflags, const char *devname, void *dev_id)\n{\n\tint irq, retval;\n\n\tirq = bind_virq_to_irq(virq, cpu, irqflags & IRQF_PERCPU);\n\tif (irq < 0)\n\t\treturn irq;\n\tretval = request_irq(irq, handler, irqflags, devname, dev_id);\n\tif (retval != 0) {\n\t\tunbind_from_irq(irq);\n\t\treturn retval;\n\t}\n\n\treturn irq;\n}\nEXPORT_SYMBOL_GPL(bind_virq_to_irqhandler);\n\nint bind_ipi_to_irqhandler(enum ipi_vector ipi,\n\t\t\t   unsigned int cpu,\n\t\t\t   irq_handler_t handler,\n\t\t\t   unsigned long irqflags,\n\t\t\t   const char *devname,\n\t\t\t   void *dev_id)\n{\n\tint irq, retval;\n\n\tirq = bind_ipi_to_irq(ipi, cpu);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tirqflags |= IRQF_NO_SUSPEND | IRQF_FORCE_RESUME | IRQF_EARLY_RESUME;\n\tretval = request_irq(irq, handler, irqflags, devname, dev_id);\n\tif (retval != 0) {\n\t\tunbind_from_irq(irq);\n\t\treturn retval;\n\t}\n\n\treturn irq;\n}\n\nvoid unbind_from_irqhandler(unsigned int irq, void *dev_id)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tif (WARN_ON(!info))\n\t\treturn;\n\tfree_irq(irq, dev_id);\n\tunbind_from_irq(irq);\n}\nEXPORT_SYMBOL_GPL(unbind_from_irqhandler);\n\n/**\n * xen_set_irq_priority() - set an event channel priority.\n * @irq:irq bound to an event channel.\n * @priority: priority between XEN_IRQ_PRIORITY_MAX and XEN_IRQ_PRIORITY_MIN.\n */\nint xen_set_irq_priority(unsigned irq, unsigned priority)\n{\n\tstruct evtchn_set_priority set_priority;\n\n\tset_priority.port = evtchn_from_irq(irq);\n\tset_priority.priority = priority;\n\n\treturn HYPERVISOR_event_channel_op(EVTCHNOP_set_priority,\n\t\t\t\t\t   &set_priority);\n}\nEXPORT_SYMBOL_GPL(xen_set_irq_priority);\n\nint evtchn_make_refcounted(evtchn_port_t evtchn)\n{\n\tint irq = get_evtchn_to_irq(evtchn);\n\tstruct irq_info *info;\n\n\tif (irq == -1)\n\t\treturn -ENOENT;\n\n\tinfo = info_for_irq(irq);\n\n\tif (!info)\n\t\treturn -ENOENT;\n\n\tWARN_ON(info->refcnt != -1);\n\n\tinfo->refcnt = 1;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(evtchn_make_refcounted);\n\nint evtchn_get(evtchn_port_t evtchn)\n{\n\tint irq;\n\tstruct irq_info *info;\n\tint err = -ENOENT;\n\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -EINVAL;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = get_evtchn_to_irq(evtchn);\n\tif (irq == -1)\n\t\tgoto done;\n\n\tinfo = info_for_irq(irq);\n\n\tif (!info)\n\t\tgoto done;\n\n\terr = -EINVAL;\n\tif (info->refcnt <= 0)\n\t\tgoto done;\n\n\tinfo->refcnt++;\n\terr = 0;\n done:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(evtchn_get);\n\nvoid evtchn_put(evtchn_port_t evtchn)\n{\n\tint irq = get_evtchn_to_irq(evtchn);\n\tif (WARN_ON(irq == -1))\n\t\treturn;\n\tunbind_from_irq(irq);\n}\nEXPORT_SYMBOL_GPL(evtchn_put);\n\nvoid xen_send_IPI_one(unsigned int cpu, enum ipi_vector vector)\n{\n\tint irq;\n\n#ifdef CONFIG_X86\n\tif (unlikely(vector == XEN_NMI_VECTOR)) {\n\t\tint rc =  HYPERVISOR_vcpu_op(VCPUOP_send_nmi, xen_vcpu_nr(cpu),\n\t\t\t\t\t     NULL);\n\t\tif (rc < 0)\n\t\t\tprintk(KERN_WARNING \"Sending nmi to CPU%d failed (rc:%d)\\n\", cpu, rc);\n\t\treturn;\n\t}\n#endif\n\tirq = per_cpu(ipi_to_irq, cpu)[vector];\n\tBUG_ON(irq < 0);\n\tnotify_remote_via_irq(irq);\n}\n\nstatic void __xen_evtchn_do_upcall(void)\n{\n\tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n\tint cpu = smp_processor_id();\n\n\tread_lock(&evtchn_rwlock);\n\n\tdo {\n\t\tvcpu_info->evtchn_upcall_pending = 0;\n\n\t\txen_evtchn_handle_events(cpu);\n\n\t\tBUG_ON(!irqs_disabled());\n\n\t\tvirt_rmb(); /* Hypervisor can set upcall pending. */\n\n\t} while (vcpu_info->evtchn_upcall_pending);\n\n\tread_unlock(&evtchn_rwlock);\n}\n\nvoid xen_evtchn_do_upcall(struct pt_regs *regs)\n{\n\tstruct pt_regs *old_regs = set_irq_regs(regs);\n\n\tirq_enter();\n\n\t__xen_evtchn_do_upcall();\n\n\tirq_exit();\n\tset_irq_regs(old_regs);\n}\n\nvoid xen_hvm_evtchn_do_upcall(void)\n{\n\t__xen_evtchn_do_upcall();\n}\nEXPORT_SYMBOL_GPL(xen_hvm_evtchn_do_upcall);\n\n/* Rebind a new event channel to an existing irq. */\nvoid rebind_evtchn_irq(evtchn_port_t evtchn, int irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tif (WARN_ON(!info))\n\t\treturn;\n\n\t/* Make sure the irq is masked, since the new event channel\n\t   will also be masked. */\n\tdisable_irq(irq);\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\t/* After resume the irq<->evtchn mappings are all cleared out */\n\tBUG_ON(get_evtchn_to_irq(evtchn) != -1);\n\t/* Expect irq to have been bound before,\n\t   so there should be a proper type */\n\tBUG_ON(info->type == IRQT_UNBOUND);\n\n\t(void)xen_irq_info_evtchn_setup(irq, evtchn);\n\n\tmutex_unlock(&irq_mapping_update_lock);\n\n        bind_evtchn_to_cpu(evtchn, info->cpu);\n\t/* This will be deferred until interrupt is processed */\n\tirq_set_affinity(irq, cpumask_of(info->cpu));\n\n\t/* Unmask the event channel. */\n\tenable_irq(irq);\n}\n\n/* Rebind an evtchn so that it gets delivered to a specific cpu */\nstatic int xen_rebind_evtchn_to_cpu(evtchn_port_t evtchn, unsigned int tcpu)\n{\n\tstruct evtchn_bind_vcpu bind_vcpu;\n\tint masked;\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn -1;\n\n\tif (!xen_support_evtchn_rebind())\n\t\treturn -1;\n\n\t/* Send future instances of this interrupt to other vcpu. */\n\tbind_vcpu.port = evtchn;\n\tbind_vcpu.vcpu = xen_vcpu_nr(tcpu);\n\n\t/*\n\t * Mask the event while changing the VCPU binding to prevent\n\t * it being delivered on an unexpected VCPU.\n\t */\n\tmasked = test_and_set_mask(evtchn);\n\n\t/*\n\t * If this fails, it usually just indicates that we're dealing with a\n\t * virq or IPI channel, which don't actually need to be rebound. Ignore\n\t * it, but don't do the xenlinux-level rebind in that case.\n\t */\n\tif (HYPERVISOR_event_channel_op(EVTCHNOP_bind_vcpu, &bind_vcpu) >= 0)\n\t\tbind_evtchn_to_cpu(evtchn, tcpu);\n\n\tif (!masked)\n\t\tunmask_evtchn(evtchn);\n\n\treturn 0;\n}\n\nstatic int set_affinity_irq(struct irq_data *data, const struct cpumask *dest,\n\t\t\t    bool force)\n{\n\tunsigned tcpu = cpumask_first_and(dest, cpu_online_mask);\n\tint ret = xen_rebind_evtchn_to_cpu(evtchn_from_irq(data->irq), tcpu);\n\n\tif (!ret)\n\t\tirq_data_update_effective_affinity(data, cpumask_of(tcpu));\n\n\treturn ret;\n}\n\n/* To be called with desc->lock held. */\nint xen_set_affinity_evtchn(struct irq_desc *desc, unsigned int tcpu)\n{\n\tstruct irq_data *d = irq_desc_get_irq_data(desc);\n\n\treturn set_affinity_irq(d, cpumask_of(tcpu), false);\n}\nEXPORT_SYMBOL_GPL(xen_set_affinity_evtchn);\n\nstatic void enable_dynirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tunmask_evtchn(evtchn);\n}\n\nstatic void disable_dynirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tmask_evtchn(evtchn);\n}\n\nstatic void ack_dynirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn;\n\n\tif (unlikely(irqd_is_setaffinity_pending(data)) &&\n\t    likely(!irqd_irq_disabled(data))) {\n\t\tint masked = test_and_set_mask(evtchn);\n\n\t\tclear_evtchn(evtchn);\n\n\t\tirq_move_masked_irq(data);\n\n\t\tif (!masked)\n\t\t\tunmask_evtchn(evtchn);\n\t} else\n\t\tclear_evtchn(evtchn);\n}\n\nstatic void mask_ack_dynirq(struct irq_data *data)\n{\n\tdisable_dynirq(data);\n\tack_dynirq(data);\n}\n\nstatic int retrigger_dynirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\tint masked;\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn 0;\n\n\tmasked = test_and_set_mask(evtchn);\n\tset_evtchn(evtchn);\n\tif (!masked)\n\t\tunmask_evtchn(evtchn);\n\n\treturn 1;\n}\n\nstatic void restore_pirqs(void)\n{\n\tint pirq, rc, irq, gsi;\n\tstruct physdev_map_pirq map_irq;\n\tstruct irq_info *info;\n\n\tlist_for_each_entry(info, &xen_irq_list_head, list) {\n\t\tif (info->type != IRQT_PIRQ)\n\t\t\tcontinue;\n\n\t\tpirq = info->u.pirq.pirq;\n\t\tgsi = info->u.pirq.gsi;\n\t\tirq = info->irq;\n\n\t\t/* save/restore of PT devices doesn't work, so at this point the\n\t\t * only devices present are GSI based emulated devices */\n\t\tif (!gsi)\n\t\t\tcontinue;\n\n\t\tmap_irq.domid = DOMID_SELF;\n\t\tmap_irq.type = MAP_PIRQ_TYPE_GSI;\n\t\tmap_irq.index = gsi;\n\t\tmap_irq.pirq = pirq;\n\n\t\trc = HYPERVISOR_physdev_op(PHYSDEVOP_map_pirq, &map_irq);\n\t\tif (rc) {\n\t\t\tpr_warn(\"xen map irq failed gsi=%d irq=%d pirq=%d rc=%d\\n\",\n\t\t\t\tgsi, irq, pirq, rc);\n\t\t\txen_free_irq(irq);\n\t\t\tcontinue;\n\t\t}\n\n\t\tprintk(KERN_DEBUG \"xen: --> irq=%d, pirq=%d\\n\", irq, map_irq.pirq);\n\n\t\t__startup_pirq(irq);\n\t}\n}\n\nstatic void restore_cpu_virqs(unsigned int cpu)\n{\n\tstruct evtchn_bind_virq bind_virq;\n\tevtchn_port_t evtchn;\n\tint virq, irq;\n\n\tfor (virq = 0; virq < NR_VIRQS; virq++) {\n\t\tif ((irq = per_cpu(virq_to_irq, cpu)[virq]) == -1)\n\t\t\tcontinue;\n\n\t\tBUG_ON(virq_from_irq(irq) != virq);\n\n\t\t/* Get a new binding from Xen. */\n\t\tbind_virq.virq = virq;\n\t\tbind_virq.vcpu = xen_vcpu_nr(cpu);\n\t\tif (HYPERVISOR_event_channel_op(EVTCHNOP_bind_virq,\n\t\t\t\t\t\t&bind_virq) != 0)\n\t\t\tBUG();\n\t\tevtchn = bind_virq.port;\n\n\t\t/* Record the new mapping. */\n\t\t(void)xen_irq_info_virq_setup(cpu, irq, evtchn, virq);\n\t\tbind_evtchn_to_cpu(evtchn, cpu);\n\t}\n}\n\nstatic void restore_cpu_ipis(unsigned int cpu)\n{\n\tstruct evtchn_bind_ipi bind_ipi;\n\tevtchn_port_t evtchn;\n\tint ipi, irq;\n\n\tfor (ipi = 0; ipi < XEN_NR_IPIS; ipi++) {\n\t\tif ((irq = per_cpu(ipi_to_irq, cpu)[ipi]) == -1)\n\t\t\tcontinue;\n\n\t\tBUG_ON(ipi_from_irq(irq) != ipi);\n\n\t\t/* Get a new binding from Xen. */\n\t\tbind_ipi.vcpu = xen_vcpu_nr(cpu);\n\t\tif (HYPERVISOR_event_channel_op(EVTCHNOP_bind_ipi,\n\t\t\t\t\t\t&bind_ipi) != 0)\n\t\t\tBUG();\n\t\tevtchn = bind_ipi.port;\n\n\t\t/* Record the new mapping. */\n\t\t(void)xen_irq_info_ipi_setup(cpu, irq, evtchn, ipi);\n\t\tbind_evtchn_to_cpu(evtchn, cpu);\n\t}\n}\n\n/* Clear an irq's pending state, in preparation for polling on it */\nvoid xen_clear_irq_pending(int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tclear_evtchn(evtchn);\n}\nEXPORT_SYMBOL(xen_clear_irq_pending);\nvoid xen_set_irq_pending(int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tset_evtchn(evtchn);\n}\n\nbool xen_test_irq_pending(int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\tbool ret = false;\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tret = test_evtchn(evtchn);\n\n\treturn ret;\n}\n\n/* Poll waiting for an irq to become pending with timeout.  In the usual case,\n * the irq will be disabled so it won't deliver an interrupt. */\nvoid xen_poll_irq_timeout(int irq, u64 timeout)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tif (VALID_EVTCHN(evtchn)) {\n\t\tstruct sched_poll poll;\n\n\t\tpoll.nr_ports = 1;\n\t\tpoll.timeout = timeout;\n\t\tset_xen_guest_handle(poll.ports, &evtchn);\n\n\t\tif (HYPERVISOR_sched_op(SCHEDOP_poll, &poll) != 0)\n\t\t\tBUG();\n\t}\n}\nEXPORT_SYMBOL(xen_poll_irq_timeout);\n/* Poll waiting for an irq to become pending.  In the usual case, the\n * irq will be disabled so it won't deliver an interrupt. */\nvoid xen_poll_irq(int irq)\n{\n\txen_poll_irq_timeout(irq, 0 /* no timeout */);\n}\n\n/* Check whether the IRQ line is shared with other guests. */\nint xen_test_irq_shared(int irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\tstruct physdev_irq_status_query irq_status;\n\n\tif (WARN_ON(!info))\n\t\treturn -ENOENT;\n\n\tirq_status.irq = info->u.pirq.pirq;\n\n\tif (HYPERVISOR_physdev_op(PHYSDEVOP_irq_status_query, &irq_status))\n\t\treturn 0;\n\treturn !(irq_status.flags & XENIRQSTAT_shared);\n}\nEXPORT_SYMBOL_GPL(xen_test_irq_shared);\n\nvoid xen_irq_resume(void)\n{\n\tunsigned int cpu;\n\tstruct irq_info *info;\n\n\t/* New event-channel space is not 'live' yet. */\n\txen_evtchn_resume();\n\n\t/* No IRQ <-> event-channel mappings. */\n\tlist_for_each_entry(info, &xen_irq_list_head, list)\n\t\tinfo->evtchn = 0; /* zap event-channel binding */\n\n\tclear_evtchn_to_irq_all();\n\n\tfor_each_possible_cpu(cpu) {\n\t\trestore_cpu_virqs(cpu);\n\t\trestore_cpu_ipis(cpu);\n\t}\n\n\trestore_pirqs();\n}\n\nstatic struct irq_chip xen_dynamic_chip __read_mostly = {\n\t.name\t\t\t= \"xen-dyn\",\n\n\t.irq_disable\t\t= disable_dynirq,\n\t.irq_mask\t\t= disable_dynirq,\n\t.irq_unmask\t\t= enable_dynirq,\n\n\t.irq_ack\t\t= ack_dynirq,\n\t.irq_mask_ack\t\t= mask_ack_dynirq,\n\n\t.irq_set_affinity\t= set_affinity_irq,\n\t.irq_retrigger\t\t= retrigger_dynirq,\n};\n\nstatic struct irq_chip xen_lateeoi_chip __read_mostly = {\n\t/* The chip name needs to contain \"xen-dyn\" for irqbalance to work. */\n\t.name\t\t\t= \"xen-dyn-lateeoi\",\n\n\t.irq_disable\t\t= disable_dynirq,\n\t.irq_mask\t\t= disable_dynirq,\n\t.irq_unmask\t\t= enable_dynirq,\n\n\t.irq_ack\t\t= mask_ack_dynirq,\n\t.irq_mask_ack\t\t= mask_ack_dynirq,\n\n\t.irq_set_affinity\t= set_affinity_irq,\n\t.irq_retrigger\t\t= retrigger_dynirq,\n};\n\nstatic struct irq_chip xen_pirq_chip __read_mostly = {\n\t.name\t\t\t= \"xen-pirq\",\n\n\t.irq_startup\t\t= startup_pirq,\n\t.irq_shutdown\t\t= shutdown_pirq,\n\t.irq_enable\t\t= enable_pirq,\n\t.irq_disable\t\t= disable_pirq,\n\n\t.irq_mask\t\t= disable_dynirq,\n\t.irq_unmask\t\t= enable_dynirq,\n\n\t.irq_ack\t\t= eoi_pirq,\n\t.irq_eoi\t\t= eoi_pirq,\n\t.irq_mask_ack\t\t= mask_ack_pirq,\n\n\t.irq_set_affinity\t= set_affinity_irq,\n\n\t.irq_retrigger\t\t= retrigger_dynirq,\n};\n\nstatic struct irq_chip xen_percpu_chip __read_mostly = {\n\t.name\t\t\t= \"xen-percpu\",\n\n\t.irq_disable\t\t= disable_dynirq,\n\t.irq_mask\t\t= disable_dynirq,\n\t.irq_unmask\t\t= enable_dynirq,\n\n\t.irq_ack\t\t= ack_dynirq,\n};\n\nint xen_set_callback_via(uint64_t via)\n{\n\tstruct xen_hvm_param a;\n\ta.domid = DOMID_SELF;\n\ta.index = HVM_PARAM_CALLBACK_IRQ;\n\ta.value = via;\n\treturn HYPERVISOR_hvm_op(HVMOP_set_param, &a);\n}\nEXPORT_SYMBOL_GPL(xen_set_callback_via);\n\n#ifdef CONFIG_XEN_PVHVM\n/* Vector callbacks are better than PCI interrupts to receive event\n * channel notifications because we can receive vector callbacks on any\n * vcpu and we don't need PCI support or APIC interactions. */\nvoid xen_setup_callback_vector(void)\n{\n\tuint64_t callback_via;\n\n\tif (xen_have_vector_callback) {\n\t\tcallback_via = HVM_CALLBACK_VECTOR(HYPERVISOR_CALLBACK_VECTOR);\n\t\tif (xen_set_callback_via(callback_via)) {\n\t\t\tpr_err(\"Request for Xen HVM callback vector failed\\n\");\n\t\t\txen_have_vector_callback = 0;\n\t\t}\n\t}\n}\n\nstatic __init void xen_alloc_callback_vector(void)\n{\n\tif (!xen_have_vector_callback)\n\t\treturn;\n\n\tpr_info(\"Xen HVM callback vector for event delivery is enabled\\n\");\n\talloc_intr_gate(HYPERVISOR_CALLBACK_VECTOR, asm_sysvec_xen_hvm_callback);\n}\n#else\nvoid xen_setup_callback_vector(void) {}\nstatic inline void xen_alloc_callback_vector(void) {}\n#endif\n\n#undef MODULE_PARAM_PREFIX\n#define MODULE_PARAM_PREFIX \"xen.\"\n\nstatic bool fifo_events = true;\nmodule_param(fifo_events, bool, 0);\n\nstatic int xen_evtchn_cpu_prepare(unsigned int cpu)\n{\n\tint ret = 0;\n\n\tif (evtchn_ops->percpu_init)\n\t\tret = evtchn_ops->percpu_init(cpu);\n\n\treturn ret;\n}\n\nstatic int xen_evtchn_cpu_dead(unsigned int cpu)\n{\n\tint ret = 0;\n\n\tif (evtchn_ops->percpu_deinit)\n\t\tret = evtchn_ops->percpu_deinit(cpu);\n\n\treturn ret;\n}\n\nvoid __init xen_init_IRQ(void)\n{\n\tint ret = -EINVAL;\n\tevtchn_port_t evtchn;\n\n\tif (fifo_events)\n\t\tret = xen_evtchn_fifo_init();\n\tif (ret < 0)\n\t\txen_evtchn_2l_init();\n\n\tcpuhp_setup_state_nocalls(CPUHP_XEN_EVTCHN_PREPARE,\n\t\t\t\t  \"xen/evtchn:prepare\",\n\t\t\t\t  xen_evtchn_cpu_prepare, xen_evtchn_cpu_dead);\n\n\tevtchn_to_irq = kcalloc(EVTCHN_ROW(xen_evtchn_max_channels()),\n\t\t\t\tsizeof(*evtchn_to_irq), GFP_KERNEL);\n\tBUG_ON(!evtchn_to_irq);\n\n\t/* No event channels are 'live' right now. */\n\tfor (evtchn = 0; evtchn < xen_evtchn_nr_channels(); evtchn++)\n\t\tmask_evtchn(evtchn);\n\n\tpirq_needs_eoi = pirq_needs_eoi_flag;\n\n#ifdef CONFIG_X86\n\tif (xen_pv_domain()) {\n\t\tif (xen_initial_domain())\n\t\t\tpci_xen_initial_domain();\n\t}\n\tif (xen_feature(XENFEAT_hvm_callback_vector)) {\n\t\txen_setup_callback_vector();\n\t\txen_alloc_callback_vector();\n\t}\n\n\tif (xen_hvm_domain()) {\n\t\tnative_init_IRQ();\n\t\t/* pci_xen_hvm_init must be called after native_init_IRQ so that\n\t\t * __acpi_register_gsi can point at the right function */\n\t\tpci_xen_hvm_init();\n\t} else {\n\t\tint rc;\n\t\tstruct physdev_pirq_eoi_gmfn eoi_gmfn;\n\n\t\tpirq_eoi_map = (void *)__get_free_page(GFP_KERNEL|__GFP_ZERO);\n\t\teoi_gmfn.gmfn = virt_to_gfn(pirq_eoi_map);\n\t\trc = HYPERVISOR_physdev_op(PHYSDEVOP_pirq_eoi_gmfn_v2, &eoi_gmfn);\n\t\tif (rc != 0) {\n\t\t\tfree_page((unsigned long) pirq_eoi_map);\n\t\t\tpirq_eoi_map = NULL;\n\t\t} else\n\t\t\tpirq_needs_eoi = pirq_check_eoi_map;\n\t}\n#endif\n}\n", "/*\n * Xen event channels (FIFO-based ABI)\n *\n * Copyright (C) 2013 Citrix Systems R&D ltd.\n *\n * This source code is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License as\n * published by the Free Software Foundation; either version 2 of the\n * License, or (at your option) any later version.\n *\n * Or, when distributed separately from the Linux kernel or\n * incorporated into other software packages, subject to the following\n * license:\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this source file (the \"Software\"), to deal in the Software without\n * restriction, including without limitation the rights to use, copy, modify,\n * merge, publish, distribute, sublicense, and/or sell copies of the Software,\n * and to permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n * IN THE SOFTWARE.\n */\n\n#define pr_fmt(fmt) \"xen:\" KBUILD_MODNAME \": \" fmt\n\n#include <linux/linkage.h>\n#include <linux/interrupt.h>\n#include <linux/irq.h>\n#include <linux/smp.h>\n#include <linux/percpu.h>\n#include <linux/cpu.h>\n\n#include <asm/barrier.h>\n#include <asm/sync_bitops.h>\n#include <asm/xen/hypercall.h>\n#include <asm/xen/hypervisor.h>\n\n#include <xen/xen.h>\n#include <xen/xen-ops.h>\n#include <xen/events.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/event_channel.h>\n#include <xen/page.h>\n\n#include \"events_internal.h\"\n\n#define EVENT_WORDS_PER_PAGE (XEN_PAGE_SIZE / sizeof(event_word_t))\n#define MAX_EVENT_ARRAY_PAGES (EVTCHN_FIFO_NR_CHANNELS / EVENT_WORDS_PER_PAGE)\n\nstruct evtchn_fifo_queue {\n\tuint32_t head[EVTCHN_FIFO_MAX_QUEUES];\n};\n\nstatic DEFINE_PER_CPU(struct evtchn_fifo_control_block *, cpu_control_block);\nstatic DEFINE_PER_CPU(struct evtchn_fifo_queue, cpu_queue);\nstatic event_word_t *event_array[MAX_EVENT_ARRAY_PAGES] __read_mostly;\nstatic unsigned event_array_pages __read_mostly;\n\n/*\n * sync_set_bit() and friends must be unsigned long aligned.\n */\n#if BITS_PER_LONG > 32\n\n#define BM(w) (unsigned long *)((unsigned long)w & ~0x7UL)\n#define EVTCHN_FIFO_BIT(b, w) \\\n    (((unsigned long)w & 0x4UL) ? (EVTCHN_FIFO_ ##b + 32) : EVTCHN_FIFO_ ##b)\n\n#else\n\n#define BM(w) ((unsigned long *)(w))\n#define EVTCHN_FIFO_BIT(b, w) EVTCHN_FIFO_ ##b\n\n#endif\n\nstatic inline event_word_t *event_word_from_port(evtchn_port_t port)\n{\n\tunsigned i = port / EVENT_WORDS_PER_PAGE;\n\n\treturn event_array[i] + port % EVENT_WORDS_PER_PAGE;\n}\n\nstatic unsigned evtchn_fifo_max_channels(void)\n{\n\treturn EVTCHN_FIFO_NR_CHANNELS;\n}\n\nstatic unsigned evtchn_fifo_nr_channels(void)\n{\n\treturn event_array_pages * EVENT_WORDS_PER_PAGE;\n}\n\nstatic int init_control_block(int cpu,\n                              struct evtchn_fifo_control_block *control_block)\n{\n\tstruct evtchn_fifo_queue *q = &per_cpu(cpu_queue, cpu);\n\tstruct evtchn_init_control init_control;\n\tunsigned int i;\n\n\t/* Reset the control block and the local HEADs. */\n\tclear_page(control_block);\n\tfor (i = 0; i < EVTCHN_FIFO_MAX_QUEUES; i++)\n\t\tq->head[i] = 0;\n\n\tinit_control.control_gfn = virt_to_gfn(control_block);\n\tinit_control.offset      = 0;\n\tinit_control.vcpu        = xen_vcpu_nr(cpu);\n\n\treturn HYPERVISOR_event_channel_op(EVTCHNOP_init_control, &init_control);\n}\n\nstatic void free_unused_array_pages(void)\n{\n\tunsigned i;\n\n\tfor (i = event_array_pages; i < MAX_EVENT_ARRAY_PAGES; i++) {\n\t\tif (!event_array[i])\n\t\t\tbreak;\n\t\tfree_page((unsigned long)event_array[i]);\n\t\tevent_array[i] = NULL;\n\t}\n}\n\nstatic void init_array_page(event_word_t *array_page)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < EVENT_WORDS_PER_PAGE; i++)\n\t\tarray_page[i] = 1 << EVTCHN_FIFO_MASKED;\n}\n\nstatic int evtchn_fifo_setup(struct irq_info *info)\n{\n\tevtchn_port_t port = info->evtchn;\n\tunsigned new_array_pages;\n\tint ret;\n\n\tnew_array_pages = port / EVENT_WORDS_PER_PAGE + 1;\n\n\tif (new_array_pages > MAX_EVENT_ARRAY_PAGES)\n\t\treturn -EINVAL;\n\n\twhile (event_array_pages < new_array_pages) {\n\t\tvoid *array_page;\n\t\tstruct evtchn_expand_array expand_array;\n\n\t\t/* Might already have a page if we've resumed. */\n\t\tarray_page = event_array[event_array_pages];\n\t\tif (!array_page) {\n\t\t\tarray_page = (void *)__get_free_page(GFP_KERNEL);\n\t\t\tif (array_page == NULL) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tevent_array[event_array_pages] = array_page;\n\t\t}\n\n\t\t/* Mask all events in this page before adding it. */\n\t\tinit_array_page(array_page);\n\n\t\texpand_array.array_gfn = virt_to_gfn(array_page);\n\n\t\tret = HYPERVISOR_event_channel_op(EVTCHNOP_expand_array, &expand_array);\n\t\tif (ret < 0)\n\t\t\tgoto error;\n\n\t\tevent_array_pages++;\n\t}\n\treturn 0;\n\n  error:\n\tif (event_array_pages == 0)\n\t\tpanic(\"xen: unable to expand event array with initial page (%d)\\n\", ret);\n\telse\n\t\tpr_err(\"unable to expand event array (%d)\\n\", ret);\n\tfree_unused_array_pages();\n\treturn ret;\n}\n\nstatic void evtchn_fifo_bind_to_cpu(struct irq_info *info, unsigned cpu)\n{\n\t/* no-op */\n}\n\nstatic void evtchn_fifo_clear_pending(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\tsync_clear_bit(EVTCHN_FIFO_BIT(PENDING, word), BM(word));\n}\n\nstatic void evtchn_fifo_set_pending(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\tsync_set_bit(EVTCHN_FIFO_BIT(PENDING, word), BM(word));\n}\n\nstatic bool evtchn_fifo_is_pending(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\treturn sync_test_bit(EVTCHN_FIFO_BIT(PENDING, word), BM(word));\n}\n\nstatic bool evtchn_fifo_test_and_set_mask(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\treturn sync_test_and_set_bit(EVTCHN_FIFO_BIT(MASKED, word), BM(word));\n}\n\nstatic void evtchn_fifo_mask(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\tsync_set_bit(EVTCHN_FIFO_BIT(MASKED, word), BM(word));\n}\n\nstatic bool evtchn_fifo_is_masked(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\treturn sync_test_bit(EVTCHN_FIFO_BIT(MASKED, word), BM(word));\n}\n/*\n * Clear MASKED if not PENDING, spinning if BUSY is set.\n * Return true if mask was cleared.\n */\nstatic bool clear_masked_cond(volatile event_word_t *word)\n{\n\tevent_word_t new, old, w;\n\n\tw = *word;\n\n\tdo {\n\t\tif (w & (1 << EVTCHN_FIFO_PENDING))\n\t\t\treturn false;\n\n\t\told = w & ~(1 << EVTCHN_FIFO_BUSY);\n\t\tnew = old & ~(1 << EVTCHN_FIFO_MASKED);\n\t\tw = sync_cmpxchg(word, old, new);\n\t} while (w != old);\n\n\treturn true;\n}\n\nstatic void evtchn_fifo_unmask(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\n\tBUG_ON(!irqs_disabled());\n\n\tif (!clear_masked_cond(word)) {\n\t\tstruct evtchn_unmask unmask = { .port = port };\n\t\t(void)HYPERVISOR_event_channel_op(EVTCHNOP_unmask, &unmask);\n\t}\n}\n\nstatic uint32_t clear_linked(volatile event_word_t *word)\n{\n\tevent_word_t new, old, w;\n\n\tw = *word;\n\n\tdo {\n\t\told = w;\n\t\tnew = (w & ~((1 << EVTCHN_FIFO_LINKED)\n\t\t\t     | EVTCHN_FIFO_LINK_MASK));\n\t} while ((w = sync_cmpxchg(word, old, new)) != old);\n\n\treturn w & EVTCHN_FIFO_LINK_MASK;\n}\n\nstatic void handle_irq_for_port(evtchn_port_t port)\n{\n\tint irq;\n\n\tirq = get_evtchn_to_irq(port);\n\tif (irq != -1)\n\t\tgeneric_handle_irq(irq);\n}\n\nstatic void consume_one_event(unsigned cpu,\n\t\t\t      struct evtchn_fifo_control_block *control_block,\n\t\t\t      unsigned priority, unsigned long *ready,\n\t\t\t      bool drop)\n{\n\tstruct evtchn_fifo_queue *q = &per_cpu(cpu_queue, cpu);\n\tuint32_t head;\n\tevtchn_port_t port;\n\tevent_word_t *word;\n\n\thead = q->head[priority];\n\n\t/*\n\t * Reached the tail last time?  Read the new HEAD from the\n\t * control block.\n\t */\n\tif (head == 0) {\n\t\tvirt_rmb(); /* Ensure word is up-to-date before reading head. */\n\t\thead = control_block->head[priority];\n\t}\n\n\tport = head;\n\tword = event_word_from_port(port);\n\thead = clear_linked(word);\n\n\t/*\n\t * If the link is non-zero, there are more events in the\n\t * queue, otherwise the queue is empty.\n\t *\n\t * If the queue is empty, clear this priority from our local\n\t * copy of the ready word.\n\t */\n\tif (head == 0)\n\t\tclear_bit(priority, ready);\n\n\tif (evtchn_fifo_is_pending(port) && !evtchn_fifo_is_masked(port)) {\n\t\tif (unlikely(drop))\n\t\t\tpr_warn(\"Dropping pending event for port %u\\n\", port);\n\t\telse\n\t\t\thandle_irq_for_port(port);\n\t}\n\n\tq->head[priority] = head;\n}\n\nstatic void __evtchn_fifo_handle_events(unsigned cpu, bool drop)\n{\n\tstruct evtchn_fifo_control_block *control_block;\n\tunsigned long ready;\n\tunsigned q;\n\n\tcontrol_block = per_cpu(cpu_control_block, cpu);\n\n\tready = xchg(&control_block->ready, 0);\n\n\twhile (ready) {\n\t\tq = find_first_bit(&ready, EVTCHN_FIFO_MAX_QUEUES);\n\t\tconsume_one_event(cpu, control_block, q, &ready, drop);\n\t\tready |= xchg(&control_block->ready, 0);\n\t}\n}\n\nstatic void evtchn_fifo_handle_events(unsigned cpu)\n{\n\t__evtchn_fifo_handle_events(cpu, false);\n}\n\nstatic void evtchn_fifo_resume(void)\n{\n\tunsigned cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tvoid *control_block = per_cpu(cpu_control_block, cpu);\n\t\tint ret;\n\n\t\tif (!control_block)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If this CPU is offline, take the opportunity to\n\t\t * free the control block while it is not being\n\t\t * used.\n\t\t */\n\t\tif (!cpu_online(cpu)) {\n\t\t\tfree_page((unsigned long)control_block);\n\t\t\tper_cpu(cpu_control_block, cpu) = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = init_control_block(cpu, control_block);\n\t\tBUG_ON(ret < 0);\n\t}\n\n\t/*\n\t * The event array starts out as empty again and is extended\n\t * as normal when events are bound.  The existing pages will\n\t * be reused.\n\t */\n\tevent_array_pages = 0;\n}\n\nstatic int evtchn_fifo_alloc_control_block(unsigned cpu)\n{\n\tvoid *control_block = NULL;\n\tint ret = -ENOMEM;\n\n\tcontrol_block = (void *)__get_free_page(GFP_KERNEL);\n\tif (control_block == NULL)\n\t\tgoto error;\n\n\tret = init_control_block(cpu, control_block);\n\tif (ret < 0)\n\t\tgoto error;\n\n\tper_cpu(cpu_control_block, cpu) = control_block;\n\n\treturn 0;\n\n  error:\n\tfree_page((unsigned long)control_block);\n\treturn ret;\n}\n\nstatic int evtchn_fifo_percpu_init(unsigned int cpu)\n{\n\tif (!per_cpu(cpu_control_block, cpu))\n\t\treturn evtchn_fifo_alloc_control_block(cpu);\n\treturn 0;\n}\n\nstatic int evtchn_fifo_percpu_deinit(unsigned int cpu)\n{\n\t__evtchn_fifo_handle_events(cpu, true);\n\treturn 0;\n}\n\nstatic const struct evtchn_ops evtchn_ops_fifo = {\n\t.max_channels      = evtchn_fifo_max_channels,\n\t.nr_channels       = evtchn_fifo_nr_channels,\n\t.setup             = evtchn_fifo_setup,\n\t.bind_to_cpu       = evtchn_fifo_bind_to_cpu,\n\t.clear_pending     = evtchn_fifo_clear_pending,\n\t.set_pending       = evtchn_fifo_set_pending,\n\t.is_pending        = evtchn_fifo_is_pending,\n\t.test_and_set_mask = evtchn_fifo_test_and_set_mask,\n\t.mask              = evtchn_fifo_mask,\n\t.unmask            = evtchn_fifo_unmask,\n\t.handle_events     = evtchn_fifo_handle_events,\n\t.resume            = evtchn_fifo_resume,\n\t.percpu_init       = evtchn_fifo_percpu_init,\n\t.percpu_deinit     = evtchn_fifo_percpu_deinit,\n};\n\nint __init xen_evtchn_fifo_init(void)\n{\n\tint cpu = smp_processor_id();\n\tint ret;\n\n\tret = evtchn_fifo_alloc_control_block(cpu);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tpr_info(\"Using FIFO-based ABI\\n\");\n\n\tevtchn_ops = &evtchn_ops_fifo;\n\n\treturn ret;\n}\n", "/* SPDX-License-Identifier: GPL-2.0-or-later */\n/*\n * Xen Event Channels (internal header)\n *\n * Copyright (C) 2013 Citrix Systems R&D Ltd.\n */\n#ifndef __EVENTS_INTERNAL_H__\n#define __EVENTS_INTERNAL_H__\n\n/* Interrupt types. */\nenum xen_irq_type {\n\tIRQT_UNBOUND = 0,\n\tIRQT_PIRQ,\n\tIRQT_VIRQ,\n\tIRQT_IPI,\n\tIRQT_EVTCHN\n};\n\n/*\n * Packed IRQ information:\n * type - enum xen_irq_type\n * event channel - irq->event channel mapping\n * cpu - cpu this event channel is bound to\n * index - type-specific information:\n *    PIRQ - vector, with MSB being \"needs EIO\", or physical IRQ of the HVM\n *           guest, or GSI (real passthrough IRQ) of the device.\n *    VIRQ - virq number\n *    IPI - IPI vector\n *    EVTCHN -\n */\nstruct irq_info {\n\tstruct list_head list;\n\tint refcnt;\n\tenum xen_irq_type type;\t/* type */\n\tunsigned irq;\n\tevtchn_port_t evtchn;\t/* event channel */\n\tunsigned short cpu;\t/* cpu bound */\n\n\tunion {\n\t\tunsigned short virq;\n\t\tenum ipi_vector ipi;\n\t\tstruct {\n\t\t\tunsigned short pirq;\n\t\t\tunsigned short gsi;\n\t\t\tunsigned char vector;\n\t\t\tunsigned char flags;\n\t\t\tuint16_t domid;\n\t\t} pirq;\n\t} u;\n};\n\n#define PIRQ_NEEDS_EOI\t(1 << 0)\n#define PIRQ_SHAREABLE\t(1 << 1)\n#define PIRQ_MSI_GROUP\t(1 << 2)\n\nstruct evtchn_ops {\n\tunsigned (*max_channels)(void);\n\tunsigned (*nr_channels)(void);\n\n\tint (*setup)(struct irq_info *info);\n\tvoid (*bind_to_cpu)(struct irq_info *info, unsigned cpu);\n\n\tvoid (*clear_pending)(evtchn_port_t port);\n\tvoid (*set_pending)(evtchn_port_t port);\n\tbool (*is_pending)(evtchn_port_t port);\n\tbool (*test_and_set_mask)(evtchn_port_t port);\n\tvoid (*mask)(evtchn_port_t port);\n\tvoid (*unmask)(evtchn_port_t port);\n\n\tvoid (*handle_events)(unsigned cpu);\n\tvoid (*resume)(void);\n\n\tint (*percpu_init)(unsigned int cpu);\n\tint (*percpu_deinit)(unsigned int cpu);\n};\n\nextern const struct evtchn_ops *evtchn_ops;\n\nextern int **evtchn_to_irq;\nint get_evtchn_to_irq(evtchn_port_t evtchn);\n\nstruct irq_info *info_for_irq(unsigned irq);\nunsigned cpu_from_irq(unsigned irq);\nunsigned int cpu_from_evtchn(evtchn_port_t evtchn);\n\nstatic inline unsigned xen_evtchn_max_channels(void)\n{\n\treturn evtchn_ops->max_channels();\n}\n\n/*\n * Do any ABI specific setup for a bound event channel before it can\n * be unmasked and used.\n */\nstatic inline int xen_evtchn_port_setup(struct irq_info *info)\n{\n\tif (evtchn_ops->setup)\n\t\treturn evtchn_ops->setup(info);\n\treturn 0;\n}\n\nstatic inline void xen_evtchn_port_bind_to_cpu(struct irq_info *info,\n\t\t\t\t\t       unsigned cpu)\n{\n\tevtchn_ops->bind_to_cpu(info, cpu);\n}\n\nstatic inline void clear_evtchn(evtchn_port_t port)\n{\n\tevtchn_ops->clear_pending(port);\n}\n\nstatic inline void set_evtchn(evtchn_port_t port)\n{\n\tevtchn_ops->set_pending(port);\n}\n\nstatic inline bool test_evtchn(evtchn_port_t port)\n{\n\treturn evtchn_ops->is_pending(port);\n}\n\nstatic inline bool test_and_set_mask(evtchn_port_t port)\n{\n\treturn evtchn_ops->test_and_set_mask(port);\n}\n\nstatic inline void mask_evtchn(evtchn_port_t port)\n{\n\treturn evtchn_ops->mask(port);\n}\n\nstatic inline void unmask_evtchn(evtchn_port_t port)\n{\n\treturn evtchn_ops->unmask(port);\n}\n\nstatic inline void xen_evtchn_handle_events(unsigned cpu)\n{\n\treturn evtchn_ops->handle_events(cpu);\n}\n\nstatic inline void xen_evtchn_resume(void)\n{\n\tif (evtchn_ops->resume)\n\t\tevtchn_ops->resume();\n}\n\nvoid xen_evtchn_2l_init(void);\nint xen_evtchn_fifo_init(void);\n\n#endif /* #ifndef __EVENTS_INTERNAL_H__ */\n"], "fixing_code": ["\tacpi=\t\t[HW,ACPI,X86,ARM64]\n\t\t\tAdvanced Configuration and Power Interface\n\t\t\tFormat: { force | on | off | strict | noirq | rsdt |\n\t\t\t\t  copy_dsdt }\n\t\t\tforce -- enable ACPI if default was off\n\t\t\ton -- enable ACPI but allow fallback to DT [arm64]\n\t\t\toff -- disable ACPI if default was on\n\t\t\tnoirq -- do not use ACPI for IRQ routing\n\t\t\tstrict -- Be less tolerant of platforms that are not\n\t\t\t\tstrictly ACPI specification compliant.\n\t\t\trsdt -- prefer RSDT over (default) XSDT\n\t\t\tcopy_dsdt -- copy DSDT to memory\n\t\t\tFor ARM64, ONLY \"acpi=off\", \"acpi=on\" or \"acpi=force\"\n\t\t\tare available\n\n\t\t\tSee also Documentation/power/runtime_pm.rst, pci=noacpi\n\n\tacpi_apic_instance=\t[ACPI, IOAPIC]\n\t\t\tFormat: <int>\n\t\t\t2: use 2nd APIC table, if available\n\t\t\t1,0: use 1st APIC table\n\t\t\tdefault: 0\n\n\tacpi_backlight=\t[HW,ACPI]\n\t\t\t{ vendor | video | native | none }\n\t\t\tIf set to vendor, prefer vendor-specific driver\n\t\t\t(e.g. thinkpad_acpi, sony_acpi, etc.) instead\n\t\t\tof the ACPI video.ko driver.\n\t\t\tIf set to video, use the ACPI video.ko driver.\n\t\t\tIf set to native, use the device's native backlight mode.\n\t\t\tIf set to none, disable the ACPI backlight interface.\n\n\tacpi_force_32bit_fadt_addr\n\t\t\tforce FADT to use 32 bit addresses rather than the\n\t\t\t64 bit X_* addresses. Some firmware have broken 64\n\t\t\tbit addresses for force ACPI ignore these and use\n\t\t\tthe older legacy 32 bit addresses.\n\n\tacpica_no_return_repair [HW, ACPI]\n\t\t\tDisable AML predefined validation mechanism\n\t\t\tThis mechanism can repair the evaluation result to make\n\t\t\tthe return objects more ACPI specification compliant.\n\t\t\tThis option is useful for developers to identify the\n\t\t\troot cause of an AML interpreter issue when the issue\n\t\t\thas something to do with the repair mechanism.\n\n\tacpi.debug_layer=\t[HW,ACPI,ACPI_DEBUG]\n\tacpi.debug_level=\t[HW,ACPI,ACPI_DEBUG]\n\t\t\tFormat: <int>\n\t\t\tCONFIG_ACPI_DEBUG must be enabled to produce any ACPI\n\t\t\tdebug output.  Bits in debug_layer correspond to a\n\t\t\t_COMPONENT in an ACPI source file, e.g.,\n\t\t\t    #define _COMPONENT ACPI_PCI_COMPONENT\n\t\t\tBits in debug_level correspond to a level in\n\t\t\tACPI_DEBUG_PRINT statements, e.g.,\n\t\t\t    ACPI_DEBUG_PRINT((ACPI_DB_INFO, ...\n\t\t\tThe debug_level mask defaults to \"info\".  See\n\t\t\tDocumentation/firmware-guide/acpi/debug.rst for more information about\n\t\t\tdebug layers and levels.\n\n\t\t\tEnable processor driver info messages:\n\t\t\t    acpi.debug_layer=0x20000000\n\t\t\tEnable PCI/PCI interrupt routing info messages:\n\t\t\t    acpi.debug_layer=0x400000\n\t\t\tEnable AML \"Debug\" output, i.e., stores to the Debug\n\t\t\tobject while interpreting AML:\n\t\t\t    acpi.debug_layer=0xffffffff acpi.debug_level=0x2\n\t\t\tEnable all messages related to ACPI hardware:\n\t\t\t    acpi.debug_layer=0x2 acpi.debug_level=0xffffffff\n\n\t\t\tSome values produce so much output that the system is\n\t\t\tunusable.  The \"log_buf_len\" parameter may be useful\n\t\t\tif you need to capture more output.\n\n\tacpi_enforce_resources=\t[ACPI]\n\t\t\t{ strict | lax | no }\n\t\t\tCheck for resource conflicts between native drivers\n\t\t\tand ACPI OperationRegions (SystemIO and SystemMemory\n\t\t\tonly). IO ports and memory declared in ACPI might be\n\t\t\tused by the ACPI subsystem in arbitrary AML code and\n\t\t\tcan interfere with legacy drivers.\n\t\t\tstrict (default): access to resources claimed by ACPI\n\t\t\tis denied; legacy drivers trying to access reserved\n\t\t\tresources will fail to bind to device using them.\n\t\t\tlax: access to resources claimed by ACPI is allowed;\n\t\t\tlegacy drivers trying to access reserved resources\n\t\t\twill bind successfully but a warning message is logged.\n\t\t\tno: ACPI OperationRegions are not marked as reserved,\n\t\t\tno further checks are performed.\n\n\tacpi_force_table_verification\t[HW,ACPI]\n\t\t\tEnable table checksum verification during early stage.\n\t\t\tBy default, this is disabled due to x86 early mapping\n\t\t\tsize limitation.\n\n\tacpi_irq_balance [HW,ACPI]\n\t\t\tACPI will balance active IRQs\n\t\t\tdefault in APIC mode\n\n\tacpi_irq_nobalance [HW,ACPI]\n\t\t\tACPI will not move active IRQs (default)\n\t\t\tdefault in PIC mode\n\n\tacpi_irq_isa=\t[HW,ACPI] If irq_balance, mark listed IRQs used by ISA\n\t\t\tFormat: <irq>,<irq>...\n\n\tacpi_irq_pci=\t[HW,ACPI] If irq_balance, clear listed IRQs for\n\t\t\tuse by PCI\n\t\t\tFormat: <irq>,<irq>...\n\n\tacpi_mask_gpe=\t[HW,ACPI]\n\t\t\tDue to the existence of _Lxx/_Exx, some GPEs triggered\n\t\t\tby unsupported hardware/firmware features can result in\n\t\t\tGPE floodings that cannot be automatically disabled by\n\t\t\tthe GPE dispatcher.\n\t\t\tThis facility can be used to prevent such uncontrolled\n\t\t\tGPE floodings.\n\t\t\tFormat: <byte>\n\n\tacpi_no_auto_serialize\t[HW,ACPI]\n\t\t\tDisable auto-serialization of AML methods\n\t\t\tAML control methods that contain the opcodes to create\n\t\t\tnamed objects will be marked as \"Serialized\" by the\n\t\t\tauto-serialization feature.\n\t\t\tThis feature is enabled by default.\n\t\t\tThis option allows to turn off the feature.\n\n\tacpi_no_memhotplug [ACPI] Disable memory hotplug.  Useful for kdump\n\t\t\t   kernels.\n\n\tacpi_no_static_ssdt\t[HW,ACPI]\n\t\t\tDisable installation of static SSDTs at early boot time\n\t\t\tBy default, SSDTs contained in the RSDT/XSDT will be\n\t\t\tinstalled automatically and they will appear under\n\t\t\t/sys/firmware/acpi/tables.\n\t\t\tThis option turns off this feature.\n\t\t\tNote that specifying this option does not affect\n\t\t\tdynamic table installation which will install SSDT\n\t\t\ttables to /sys/firmware/acpi/tables/dynamic.\n\n\tacpi_no_watchdog\t[HW,ACPI,WDT]\n\t\t\tIgnore the ACPI-based watchdog interface (WDAT) and let\n\t\t\ta native driver control the watchdog device instead.\n\n\tacpi_rsdp=\t[ACPI,EFI,KEXEC]\n\t\t\tPass the RSDP address to the kernel, mostly used\n\t\t\ton machines running EFI runtime service to boot the\n\t\t\tsecond kernel for kdump.\n\n\tacpi_os_name=\t[HW,ACPI] Tell ACPI BIOS the name of the OS\n\t\t\tFormat: To spoof as Windows 98: =\"Microsoft Windows\"\n\n\tacpi_rev_override [ACPI] Override the _REV object to return 5 (instead\n\t\t\tof 2 which is mandated by ACPI 6) as the supported ACPI\n\t\t\tspecification revision (when using this switch, it may\n\t\t\tbe necessary to carry out a cold reboot _twice_ in a\n\t\t\trow to make it take effect on the platform firmware).\n\n\tacpi_osi=\t[HW,ACPI] Modify list of supported OS interface strings\n\t\t\tacpi_osi=\"string1\"\t# add string1\n\t\t\tacpi_osi=\"!string2\"\t# remove string2\n\t\t\tacpi_osi=!*\t\t# remove all strings\n\t\t\tacpi_osi=!\t\t# disable all built-in OS vendor\n\t\t\t\t\t\t  strings\n\t\t\tacpi_osi=!!\t\t# enable all built-in OS vendor\n\t\t\t\t\t\t  strings\n\t\t\tacpi_osi=\t\t# disable all strings\n\n\t\t\t'acpi_osi=!' can be used in combination with single or\n\t\t\tmultiple 'acpi_osi=\"string1\"' to support specific OS\n\t\t\tvendor string(s).  Note that such command can only\n\t\t\taffect the default state of the OS vendor strings, thus\n\t\t\tit cannot affect the default state of the feature group\n\t\t\tstrings and the current state of the OS vendor strings,\n\t\t\tspecifying it multiple times through kernel command line\n\t\t\tis meaningless.  This command is useful when one do not\n\t\t\tcare about the state of the feature group strings which\n\t\t\tshould be controlled by the OSPM.\n\t\t\tExamples:\n\t\t\t  1. 'acpi_osi=! acpi_osi=\"Windows 2000\"' is equivalent\n\t\t\t     to 'acpi_osi=\"Windows 2000\" acpi_osi=!', they all\n\t\t\t     can make '_OSI(\"Windows 2000\")' TRUE.\n\n\t\t\t'acpi_osi=' cannot be used in combination with other\n\t\t\t'acpi_osi=' command lines, the _OSI method will not\n\t\t\texist in the ACPI namespace.  NOTE that such command can\n\t\t\tonly affect the _OSI support state, thus specifying it\n\t\t\tmultiple times through kernel command line is also\n\t\t\tmeaningless.\n\t\t\tExamples:\n\t\t\t  1. 'acpi_osi=' can make 'CondRefOf(_OSI, Local1)'\n\t\t\t     FALSE.\n\n\t\t\t'acpi_osi=!*' can be used in combination with single or\n\t\t\tmultiple 'acpi_osi=\"string1\"' to support specific\n\t\t\tstring(s).  Note that such command can affect the\n\t\t\tcurrent state of both the OS vendor strings and the\n\t\t\tfeature group strings, thus specifying it multiple times\n\t\t\tthrough kernel command line is meaningful.  But it may\n\t\t\tstill not able to affect the final state of a string if\n\t\t\tthere are quirks related to this string.  This command\n\t\t\tis useful when one want to control the state of the\n\t\t\tfeature group strings to debug BIOS issues related to\n\t\t\tthe OSPM features.\n\t\t\tExamples:\n\t\t\t  1. 'acpi_osi=\"Module Device\" acpi_osi=!*' can make\n\t\t\t     '_OSI(\"Module Device\")' FALSE.\n\t\t\t  2. 'acpi_osi=!* acpi_osi=\"Module Device\"' can make\n\t\t\t     '_OSI(\"Module Device\")' TRUE.\n\t\t\t  3. 'acpi_osi=! acpi_osi=!* acpi_osi=\"Windows 2000\"' is\n\t\t\t     equivalent to\n\t\t\t     'acpi_osi=!* acpi_osi=! acpi_osi=\"Windows 2000\"'\n\t\t\t     and\n\t\t\t     'acpi_osi=!* acpi_osi=\"Windows 2000\" acpi_osi=!',\n\t\t\t     they all will make '_OSI(\"Windows 2000\")' TRUE.\n\n\tacpi_pm_good\t[X86]\n\t\t\tOverride the pmtimer bug detection: force the kernel\n\t\t\tto assume that this machine's pmtimer latches its value\n\t\t\tand always returns good values.\n\n\tacpi_sci=\t[HW,ACPI] ACPI System Control Interrupt trigger mode\n\t\t\tFormat: { level | edge | high | low }\n\n\tacpi_skip_timer_override [HW,ACPI]\n\t\t\tRecognize and ignore IRQ0/pin2 Interrupt Override.\n\t\t\tFor broken nForce2 BIOS resulting in XT-PIC timer.\n\n\tacpi_sleep=\t[HW,ACPI] Sleep options\n\t\t\tFormat: { s3_bios, s3_mode, s3_beep, s4_nohwsig,\n\t\t\t\t  old_ordering, nonvs, sci_force_enable, nobl }\n\t\t\tSee Documentation/power/video.rst for information on\n\t\t\ts3_bios and s3_mode.\n\t\t\ts3_beep is for debugging; it makes the PC's speaker beep\n\t\t\tas soon as the kernel's real-mode entry point is called.\n\t\t\ts4_nohwsig prevents ACPI hardware signature from being\n\t\t\tused during resume from hibernation.\n\t\t\told_ordering causes the ACPI 1.0 ordering of the _PTS\n\t\t\tcontrol method, with respect to putting devices into\n\t\t\tlow power states, to be enforced (the ACPI 2.0 ordering\n\t\t\tof _PTS is used by default).\n\t\t\tnonvs prevents the kernel from saving/restoring the\n\t\t\tACPI NVS memory during suspend/hibernation and resume.\n\t\t\tsci_force_enable causes the kernel to set SCI_EN directly\n\t\t\ton resume from S1/S3 (which is against the ACPI spec,\n\t\t\tbut some broken systems don't work without it).\n\t\t\tnobl causes the internal blacklist of systems known to\n\t\t\tbehave incorrectly in some ways with respect to system\n\t\t\tsuspend and resume to be ignored (use wisely).\n\n\tacpi_use_timer_override [HW,ACPI]\n\t\t\tUse timer override. For some broken Nvidia NF5 boards\n\t\t\tthat require a timer override, but don't have HPET\n\n\tadd_efi_memmap\t[EFI; X86] Include EFI memory map in\n\t\t\tkernel's map of available physical RAM.\n\n\tagp=\t\t[AGP]\n\t\t\t{ off | try_unsupported }\n\t\t\toff: disable AGP support\n\t\t\ttry_unsupported: try to drive unsupported chipsets\n\t\t\t\t(may crash computer or cause data corruption)\n\n\tALSA\t\t[HW,ALSA]\n\t\t\tSee Documentation/sound/alsa-configuration.rst\n\n\talignment=\t[KNL,ARM]\n\t\t\tAllow the default userspace alignment fault handler\n\t\t\tbehaviour to be specified.  Bit 0 enables warnings,\n\t\t\tbit 1 enables fixups, and bit 2 sends a segfault.\n\n\talign_va_addr=\t[X86-64]\n\t\t\tAlign virtual addresses by clearing slice [14:12] when\n\t\t\tallocating a VMA at process creation time. This option\n\t\t\tgives you up to 3% performance improvement on AMD F15h\n\t\t\tmachines (where it is enabled by default) for a\n\t\t\tCPU-intensive style benchmark, and it can vary highly in\n\t\t\ta microbenchmark depending on workload and compiler.\n\n\t\t\t32: only for 32-bit processes\n\t\t\t64: only for 64-bit processes\n\t\t\ton: enable for both 32- and 64-bit processes\n\t\t\toff: disable for both 32- and 64-bit processes\n\n\talloc_snapshot\t[FTRACE]\n\t\t\tAllocate the ftrace snapshot buffer on boot up when the\n\t\t\tmain buffer is allocated. This is handy if debugging\n\t\t\tand you need to use tracing_snapshot() on boot up, and\n\t\t\tdo not want to use tracing_snapshot_alloc() as it needs\n\t\t\tto be done where GFP_KERNEL allocations are allowed.\n\n\tamd_iommu=\t[HW,X86-64]\n\t\t\tPass parameters to the AMD IOMMU driver in the system.\n\t\t\tPossible values are:\n\t\t\tfullflush - enable flushing of IO/TLB entries when\n\t\t\t\t    they are unmapped. Otherwise they are\n\t\t\t\t    flushed before they will be reused, which\n\t\t\t\t    is a lot of faster\n\t\t\toff\t  - do not initialize any AMD IOMMU found in\n\t\t\t\t    the system\n\t\t\tforce_isolation - Force device isolation for all\n\t\t\t\t\t  devices. The IOMMU driver is not\n\t\t\t\t\t  allowed anymore to lift isolation\n\t\t\t\t\t  requirements as needed. This option\n\t\t\t\t\t  does not override iommu=pt\n\n\tamd_iommu_dump=\t[HW,X86-64]\n\t\t\tEnable AMD IOMMU driver option to dump the ACPI table\n\t\t\tfor AMD IOMMU. With this option enabled, AMD IOMMU\n\t\t\tdriver will print ACPI tables for AMD IOMMU during\n\t\t\tIOMMU initialization.\n\n\tamd_iommu_intr=\t[HW,X86-64]\n\t\t\tSpecifies one of the following AMD IOMMU interrupt\n\t\t\tremapping modes:\n\t\t\tlegacy     - Use legacy interrupt remapping mode.\n\t\t\tvapic      - Use virtual APIC mode, which allows IOMMU\n\t\t\t             to inject interrupts directly into guest.\n\t\t\t             This mode requires kvm-amd.avic=1.\n\t\t\t             (Default when IOMMU HW support is present.)\n\n\tamijoy.map=\t[HW,JOY] Amiga joystick support\n\t\t\tMap of devices attached to JOY0DAT and JOY1DAT\n\t\t\tFormat: <a>,<b>\n\t\t\tSee also Documentation/input/joydev/joystick.rst\n\n\tanalog.map=\t[HW,JOY] Analog joystick and gamepad support\n\t\t\tSpecifies type or capabilities of an analog joystick\n\t\t\tconnected to one of 16 gameports\n\t\t\tFormat: <type1>,<type2>,..<type16>\n\n\tapc=\t\t[HW,SPARC]\n\t\t\tPower management functions (SPARCstation-4/5 + deriv.)\n\t\t\tFormat: noidle\n\t\t\tDisable APC CPU standby support. SPARCstation-Fox does\n\t\t\tnot play well with APC CPU idle - disable it if you have\n\t\t\tAPC and your system crashes randomly.\n\n\tapic=\t\t[APIC,X86] Advanced Programmable Interrupt Controller\n\t\t\tChange the output verbosity while booting\n\t\t\tFormat: { quiet (default) | verbose | debug }\n\t\t\tChange the amount of debugging information output\n\t\t\twhen initialising the APIC and IO-APIC components.\n\t\t\tFor X86-32, this can also be used to specify an APIC\n\t\t\tdriver name.\n\t\t\tFormat: apic=driver_name\n\t\t\tExamples: apic=bigsmp\n\n\tapic_extnmi=\t[APIC,X86] External NMI delivery setting\n\t\t\tFormat: { bsp (default) | all | none }\n\t\t\tbsp:  External NMI is delivered only to CPU 0\n\t\t\tall:  External NMIs are broadcast to all CPUs as a\n\t\t\t      backup of CPU 0\n\t\t\tnone: External NMI is masked for all CPUs. This is\n\t\t\t      useful so that a dump capture kernel won't be\n\t\t\t      shot down by NMI\n\n\tautoconf=\t[IPV6]\n\t\t\tSee Documentation/networking/ipv6.rst.\n\n\tshow_lapic=\t[APIC,X86] Advanced Programmable Interrupt Controller\n\t\t\tLimit apic dumping. The parameter defines the maximal\n\t\t\tnumber of local apics being dumped. Also it is possible\n\t\t\tto set it to \"all\" by meaning -- no limit here.\n\t\t\tFormat: { 1 (default) | 2 | ... | all }.\n\t\t\tThe parameter valid if only apic=debug or\n\t\t\tapic=verbose is specified.\n\t\t\tExample: apic=debug show_lapic=all\n\n\tapm=\t\t[APM] Advanced Power Management\n\t\t\tSee header of arch/x86/kernel/apm_32.c.\n\n\tarcrimi=\t[HW,NET] ARCnet - \"RIM I\" (entirely mem-mapped) cards\n\t\t\tFormat: <io>,<irq>,<nodeID>\n\n\tataflop=\t[HW,M68k]\n\n\tatarimouse=\t[HW,MOUSE] Atari Mouse\n\n\tatkbd.extra=\t[HW] Enable extra LEDs and keys on IBM RapidAccess,\n\t\t\tEzKey and similar keyboards\n\n\tatkbd.reset=\t[HW] Reset keyboard during initialization\n\n\tatkbd.set=\t[HW] Select keyboard code set\n\t\t\tFormat: <int> (2 = AT (default), 3 = PS/2)\n\n\tatkbd.scroll=\t[HW] Enable scroll wheel on MS Office and similar\n\t\t\tkeyboards\n\n\tatkbd.softraw=\t[HW] Choose between synthetic and real raw mode\n\t\t\tFormat: <bool> (0 = real, 1 = synthetic (default))\n\n\tatkbd.softrepeat= [HW]\n\t\t\tUse software keyboard repeat\n\n\taudit=\t\t[KNL] Enable the audit sub-system\n\t\t\tFormat: { \"0\" | \"1\" | \"off\" | \"on\" }\n\t\t\t0 | off - kernel audit is disabled and can not be\n\t\t\t    enabled until the next reboot\n\t\t\tunset - kernel audit is initialized but disabled and\n\t\t\t    will be fully enabled by the userspace auditd.\n\t\t\t1 | on - kernel audit is initialized and partially\n\t\t\t    enabled, storing at most audit_backlog_limit\n\t\t\t    messages in RAM until it is fully enabled by the\n\t\t\t    userspace auditd.\n\t\t\tDefault: unset\n\n\taudit_backlog_limit= [KNL] Set the audit queue size limit.\n\t\t\tFormat: <int> (must be >=0)\n\t\t\tDefault: 64\n\n\tbau=\t\t[X86_UV] Enable the BAU on SGI UV.  The default\n\t\t\tbehavior is to disable the BAU (i.e. bau=0).\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 - Disable the BAU.\n\t\t\t1 - Enable the BAU.\n\t\t\tunset - Disable the BAU.\n\n\tbaycom_epp=\t[HW,AX25]\n\t\t\tFormat: <io>,<mode>\n\n\tbaycom_par=\t[HW,AX25] BayCom Parallel Port AX.25 Modem\n\t\t\tFormat: <io>,<mode>\n\t\t\tSee header of drivers/net/hamradio/baycom_par.c.\n\n\tbaycom_ser_fdx=\t[HW,AX25]\n\t\t\tBayCom Serial Port AX.25 Modem (Full Duplex Mode)\n\t\t\tFormat: <io>,<irq>,<mode>[,<baud>]\n\t\t\tSee header of drivers/net/hamradio/baycom_ser_fdx.c.\n\n\tbaycom_ser_hdx=\t[HW,AX25]\n\t\t\tBayCom Serial Port AX.25 Modem (Half Duplex Mode)\n\t\t\tFormat: <io>,<irq>,<mode>\n\t\t\tSee header of drivers/net/hamradio/baycom_ser_hdx.c.\n\n\tblkdevparts=\tManual partition parsing of block device(s) for\n\t\t\tembedded devices based on command line input.\n\t\t\tSee Documentation/block/cmdline-partition.rst\n\n\tboot_delay=\tMilliseconds to delay each printk during boot.\n\t\t\tValues larger than 10 seconds (10000) are changed to\n\t\t\tno delay (0).\n\t\t\tFormat: integer\n\n\tbootconfig\t[KNL]\n\t\t\tExtended command line options can be added to an initrd\n\t\t\tand this will cause the kernel to look for it.\n\n\t\t\tSee Documentation/admin-guide/bootconfig.rst\n\n\tbert_disable\t[ACPI]\n\t\t\tDisable BERT OS support on buggy BIOSes.\n\n\tbgrt_disable\t[ACPI][X86]\n\t\t\tDisable BGRT to avoid flickering OEM logo.\n\n\tbttv.card=\t[HW,V4L] bttv (bt848 + bt878 based grabber cards)\n\tbttv.radio=\tMost important insmod options are available as\n\t\t\tkernel args too.\n\tbttv.pll=\tSee Documentation/admin-guide/media/bttv.rst\n\tbttv.tuner=\n\n\tbulk_remove=off\t[PPC]  This parameter disables the use of the pSeries\n\t\t\tfirmware feature for flushing multiple hpte entries\n\t\t\tat a time.\n\n\tc101=\t\t[NET] Moxa C101 synchronous serial card\n\n\tcachesize=\t[BUGS=X86-32] Override level 2 CPU cache size detection.\n\t\t\tSometimes CPU hardware bugs make them report the cache\n\t\t\tsize incorrectly. The kernel will attempt work arounds\n\t\t\tto fix known problems, but for some CPUs it is not\n\t\t\tpossible to determine what the correct size should be.\n\t\t\tThis option provides an override for these situations.\n\n\tcarrier_timeout=\n\t\t\t[NET] Specifies amount of time (in seconds) that\n\t\t\tthe kernel should wait for a network carrier. By default\n\t\t\tit waits 120 seconds.\n\n\tca_keys=\t[KEYS] This parameter identifies a specific key(s) on\n\t\t\tthe system trusted keyring to be used for certificate\n\t\t\ttrust validation.\n\t\t\tformat: { id:<keyid> | builtin }\n\n\tcca=\t\t[MIPS] Override the kernel pages' cache coherency\n\t\t\talgorithm.  Accepted values range from 0 to 7\n\t\t\tinclusive. See arch/mips/include/asm/pgtable-bits.h\n\t\t\tfor platform specific values (SB1, Loongson3 and\n\t\t\tothers).\n\n\tccw_timeout_log\t[S390]\n\t\t\tSee Documentation/s390/common_io.rst for details.\n\n\tcgroup_disable=\t[KNL] Disable a particular controller\n\t\t\tFormat: {name of the controller(s) to disable}\n\t\t\tThe effects of cgroup_disable=foo are:\n\t\t\t- foo isn't auto-mounted if you mount all cgroups in\n\t\t\t  a single hierarchy\n\t\t\t- foo isn't visible as an individually mountable\n\t\t\t  subsystem\n\t\t\t{Currently only \"memory\" controller deal with this and\n\t\t\tcut the overhead, others just disable the usage. So\n\t\t\tonly cgroup_disable=memory is actually worthy}\n\n\tcgroup_no_v1=\t[KNL] Disable cgroup controllers and named hierarchies in v1\n\t\t\tFormat: { { controller | \"all\" | \"named\" }\n\t\t\t          [,{ controller | \"all\" | \"named\" }...] }\n\t\t\tLike cgroup_disable, but only applies to cgroup v1;\n\t\t\tthe blacklisted controllers remain available in cgroup2.\n\t\t\t\"all\" blacklists all controllers and \"named\" disables\n\t\t\tnamed mounts. Specifying both \"all\" and \"named\" disables\n\t\t\tall v1 hierarchies.\n\n\tcgroup.memory=\t[KNL] Pass options to the cgroup memory controller.\n\t\t\tFormat: <string>\n\t\t\tnosocket -- Disable socket memory accounting.\n\t\t\tnokmem -- Disable kernel memory accounting.\n\n\tcheckreqprot\t[SELINUX] Set initial checkreqprot flag value.\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\tSee security/selinux/Kconfig help text.\n\t\t\t0 -- check protection applied by kernel (includes\n\t\t\t\tany implied execute protection).\n\t\t\t1 -- check protection requested by application.\n\t\t\tDefault value is set via a kernel config option.\n\t\t\tValue can be changed at runtime via\n\t\t\t\t/sys/fs/selinux/checkreqprot.\n\t\t\tSetting checkreqprot to 1 is deprecated.\n\n\tcio_ignore=\t[S390]\n\t\t\tSee Documentation/s390/common_io.rst for details.\n\tclk_ignore_unused\n\t\t\t[CLK]\n\t\t\tPrevents the clock framework from automatically gating\n\t\t\tclocks that have not been explicitly enabled by a Linux\n\t\t\tdevice driver but are enabled in hardware at reset or\n\t\t\tby the bootloader/firmware. Note that this does not\n\t\t\tforce such clocks to be always-on nor does it reserve\n\t\t\tthose clocks in any way. This parameter is useful for\n\t\t\tdebug and development, but should not be needed on a\n\t\t\tplatform with proper driver support.  For more\n\t\t\tinformation, see Documentation/driver-api/clk.rst.\n\n\tclock=\t\t[BUGS=X86-32, HW] gettimeofday clocksource override.\n\t\t\t[Deprecated]\n\t\t\tForces specified clocksource (if available) to be used\n\t\t\twhen calculating gettimeofday(). If specified\n\t\t\tclocksource is not available, it defaults to PIT.\n\t\t\tFormat: { pit | tsc | cyclone | pmtmr }\n\n\tclocksource=\tOverride the default clocksource\n\t\t\tFormat: <string>\n\t\t\tOverride the default clocksource and use the clocksource\n\t\t\twith the name specified.\n\t\t\tSome clocksource names to choose from, depending on\n\t\t\tthe platform:\n\t\t\t[all] jiffies (this is the base, fallback clocksource)\n\t\t\t[ACPI] acpi_pm\n\t\t\t[ARM] imx_timer1,OSTS,netx_timer,mpu_timer2,\n\t\t\t\tpxa_timer,timer3,32k_counter,timer0_1\n\t\t\t[X86-32] pit,hpet,tsc;\n\t\t\t\tscx200_hrt on Geode; cyclone on IBM x440\n\t\t\t[MIPS] MIPS\n\t\t\t[PARISC] cr16\n\t\t\t[S390] tod\n\t\t\t[SH] SuperH\n\t\t\t[SPARC64] tick\n\t\t\t[X86-64] hpet,tsc\n\n\tclocksource.arm_arch_timer.evtstrm=\n\t\t\t[ARM,ARM64]\n\t\t\tFormat: <bool>\n\t\t\tEnable/disable the eventstream feature of the ARM\n\t\t\tarchitected timer so that code using WFE-based polling\n\t\t\tloops can be debugged more effectively on production\n\t\t\tsystems.\n\n\tclearcpuid=BITNUM [X86]\n\t\t\tDisable CPUID feature X for the kernel. See\n\t\t\tarch/x86/include/asm/cpufeatures.h for the valid bit\n\t\t\tnumbers. Note the Linux specific bits are not necessarily\n\t\t\tstable over kernel options, but the vendor specific\n\t\t\tones should be.\n\t\t\tAlso note that user programs calling CPUID directly\n\t\t\tor using the feature without checking anything\n\t\t\twill still see it. This just prevents it from\n\t\t\tbeing used by the kernel or shown in /proc/cpuinfo.\n\t\t\tAlso note the kernel might malfunction if you disable\n\t\t\tsome critical bits.\n\n\tcma=nn[MG]@[start[MG][-end[MG]]]\n\t\t\t[ARM,X86,KNL]\n\t\t\tSets the size of kernel global memory area for\n\t\t\tcontiguous memory allocations and optionally the\n\t\t\tplacement constraint by the physical address range of\n\t\t\tmemory allocations. A value of 0 disables CMA\n\t\t\taltogether. For more information, see\n\t\t\tinclude/linux/dma-contiguous.h\n\n\tcmo_free_hint=\t[PPC] Format: { yes | no }\n\t\t\tSpecify whether pages are marked as being inactive\n\t\t\twhen they are freed.  This is used in CMO environments\n\t\t\tto determine OS memory pressure for page stealing by\n\t\t\ta hypervisor.\n\t\t\tDefault: yes\n\n\tcoherent_pool=nn[KMG]\t[ARM,KNL]\n\t\t\tSets the size of memory pool for coherent, atomic dma\n\t\t\tallocations, by default set to 256K.\n\n\tcom20020=\t[HW,NET] ARCnet - COM20020 chipset\n\t\t\tFormat:\n\t\t\t<io>[,<irq>[,<nodeID>[,<backplane>[,<ckp>[,<timeout>]]]]]\n\n\tcom90io=\t[HW,NET] ARCnet - COM90xx chipset (IO-mapped buffers)\n\t\t\tFormat: <io>[,<irq>]\n\n\tcom90xx=\t[HW,NET]\n\t\t\tARCnet - COM90xx chipset (memory-mapped buffers)\n\t\t\tFormat: <io>[,<irq>[,<memstart>]]\n\n\tcondev=\t\t[HW,S390] console device\n\tconmode=\n\n\tconsole=\t[KNL] Output console device and options.\n\n\t\ttty<n>\tUse the virtual console device <n>.\n\n\t\tttyS<n>[,options]\n\t\tttyUSB0[,options]\n\t\t\tUse the specified serial port.  The options are of\n\t\t\tthe form \"bbbbpnf\", where \"bbbb\" is the baud rate,\n\t\t\t\"p\" is parity (\"n\", \"o\", or \"e\"), \"n\" is number of\n\t\t\tbits, and \"f\" is flow control (\"r\" for RTS or\n\t\t\tomit it).  Default is \"9600n8\".\n\n\t\t\tSee Documentation/admin-guide/serial-console.rst for more\n\t\t\tinformation.  See\n\t\t\tDocumentation/networking/netconsole.rst for an\n\t\t\talternative.\n\n\t\tuart[8250],io,<addr>[,options]\n\t\tuart[8250],mmio,<addr>[,options]\n\t\tuart[8250],mmio16,<addr>[,options]\n\t\tuart[8250],mmio32,<addr>[,options]\n\t\tuart[8250],0x<addr>[,options]\n\t\t\tStart an early, polled-mode console on the 8250/16550\n\t\t\tUART at the specified I/O port or MMIO address,\n\t\t\tswitching to the matching ttyS device later.\n\t\t\tMMIO inter-register address stride is either 8-bit\n\t\t\t(mmio), 16-bit (mmio16), or 32-bit (mmio32).\n\t\t\tIf none of [io|mmio|mmio16|mmio32], <addr> is assumed\n\t\t\tto be equivalent to 'mmio'. 'options' are specified in\n\t\t\tthe same format described for ttyS above; if unspecified,\n\t\t\tthe h/w is not re-initialized.\n\n\t\thvc<n>\tUse the hypervisor console device <n>. This is for\n\t\t\tboth Xen and PowerPC hypervisors.\n\n\t\tIf the device connected to the port is not a TTY but a braille\n\t\tdevice, prepend \"brl,\" before the device type, for instance\n\t\t\tconsole=brl,ttyS0\n\t\tFor now, only VisioBraille is supported.\n\n\tconsole_msg_format=\n\t\t\t[KNL] Change console messages format\n\t\tdefault\n\t\t\tBy default we print messages on consoles in\n\t\t\t\"[time stamp] text\\n\" format (time stamp may not be\n\t\t\tprinted, depending on CONFIG_PRINTK_TIME or\n\t\t\t`printk_time' param).\n\t\tsyslog\n\t\t\tSwitch to syslog format: \"<%u>[time stamp] text\\n\"\n\t\t\tIOW, each message will have a facility and loglevel\n\t\t\tprefix. The format is similar to one used by syslog()\n\t\t\tsyscall, or to executing \"dmesg -S --raw\" or to reading\n\t\t\tfrom /proc/kmsg.\n\n\tconsoleblank=\t[KNL] The console blank (screen saver) timeout in\n\t\t\tseconds. A value of 0 disables the blank timer.\n\t\t\tDefaults to 0.\n\n\tcoredump_filter=\n\t\t\t[KNL] Change the default value for\n\t\t\t/proc/<pid>/coredump_filter.\n\t\t\tSee also Documentation/filesystems/proc.rst.\n\n\tcoresight_cpu_debug.enable\n\t\t\t[ARM,ARM64]\n\t\t\tFormat: <bool>\n\t\t\tEnable/disable the CPU sampling based debugging.\n\t\t\t0: default value, disable debugging\n\t\t\t1: enable debugging at boot time\n\n\tcpuidle.off=1\t[CPU_IDLE]\n\t\t\tdisable the cpuidle sub-system\n\n\tcpuidle.governor=\n\t\t\t[CPU_IDLE] Name of the cpuidle governor to use.\n\n\tcpufreq.off=1\t[CPU_FREQ]\n\t\t\tdisable the cpufreq sub-system\n\n\tcpufreq.default_governor=\n\t\t\t[CPU_FREQ] Name of the default cpufreq governor or\n\t\t\tpolicy to use. This governor must be registered in the\n\t\t\tkernel before the cpufreq driver probes.\n\n\tcpu_init_udelay=N\n\t\t\t[X86] Delay for N microsec between assert and de-assert\n\t\t\tof APIC INIT to start processors.  This delay occurs\n\t\t\ton every CPU online, such as boot, and resume from suspend.\n\t\t\tDefault: 10000\n\n\tcpcihp_generic=\t[HW,PCI] Generic port I/O CompactPCI driver\n\t\t\tFormat:\n\t\t\t<first_slot>,<last_slot>,<port>,<enum_bit>[,<debug>]\n\n\tcrashkernel=size[KMG][@offset[KMG]]\n\t\t\t[KNL] Using kexec, Linux can switch to a 'crash kernel'\n\t\t\tupon panic. This parameter reserves the physical\n\t\t\tmemory region [offset, offset + size] for that kernel\n\t\t\timage. If '@offset' is omitted, then a suitable offset\n\t\t\tis selected automatically.\n\t\t\t[KNL, X86-64] Select a region under 4G first, and\n\t\t\tfall back to reserve region above 4G when '@offset'\n\t\t\thasn't been specified.\n\t\t\tSee Documentation/admin-guide/kdump/kdump.rst for further details.\n\n\tcrashkernel=range1:size1[,range2:size2,...][@offset]\n\t\t\t[KNL] Same as above, but depends on the memory\n\t\t\tin the running system. The syntax of range is\n\t\t\tstart-[end] where start and end are both\n\t\t\ta memory unit (amount[KMG]). See also\n\t\t\tDocumentation/admin-guide/kdump/kdump.rst for an example.\n\n\tcrashkernel=size[KMG],high\n\t\t\t[KNL, X86-64] range could be above 4G. Allow kernel\n\t\t\tto allocate physical memory region from top, so could\n\t\t\tbe above 4G if system have more than 4G ram installed.\n\t\t\tOtherwise memory region will be allocated below 4G, if\n\t\t\tavailable.\n\t\t\tIt will be ignored if crashkernel=X is specified.\n\tcrashkernel=size[KMG],low\n\t\t\t[KNL, X86-64] range under 4G. When crashkernel=X,high\n\t\t\tis passed, kernel could allocate physical memory region\n\t\t\tabove 4G, that cause second kernel crash on system\n\t\t\tthat require some amount of low memory, e.g. swiotlb\n\t\t\trequires at least 64M+32K low memory, also enough extra\n\t\t\tlow memory is needed to make sure DMA buffers for 32-bit\n\t\t\tdevices won't run out. Kernel would try to allocate at\n\t\t\tat least 256M below 4G automatically.\n\t\t\tThis one let user to specify own low range under 4G\n\t\t\tfor second kernel instead.\n\t\t\t0: to disable low allocation.\n\t\t\tIt will be ignored when crashkernel=X,high is not used\n\t\t\tor memory reserved is below 4G.\n\n\tcryptomgr.notests\n\t\t\t[KNL] Disable crypto self-tests\n\n\tcs89x0_dma=\t[HW,NET]\n\t\t\tFormat: <dma>\n\n\tcs89x0_media=\t[HW,NET]\n\t\t\tFormat: { rj45 | aui | bnc }\n\n\tdasd=\t\t[HW,NET]\n\t\t\tSee header of drivers/s390/block/dasd_devmap.c.\n\n\tdb9.dev[2|3]=\t[HW,JOY] Multisystem joystick support via parallel port\n\t\t\t(one device per port)\n\t\t\tFormat: <port#>,<type>\n\t\t\tSee also Documentation/input/devices/joystick-parport.rst\n\n\tddebug_query=\t[KNL,DYNAMIC_DEBUG] Enable debug messages at early boot\n\t\t\ttime. See\n\t\t\tDocumentation/admin-guide/dynamic-debug-howto.rst for\n\t\t\tdetails.  Deprecated, see dyndbg.\n\n\tdebug\t\t[KNL] Enable kernel debugging (events log level).\n\n\tdebug_boot_weak_hash\n\t\t\t[KNL] Enable printing [hashed] pointers early in the\n\t\t\tboot sequence.  If enabled, we use a weak hash instead\n\t\t\tof siphash to hash pointers.  Use this option if you are\n\t\t\tseeing instances of '(___ptrval___)') and need to see a\n\t\t\tvalue (hashed pointer) instead. Cryptographically\n\t\t\tinsecure, please do not use on production kernels.\n\n\tdebug_locks_verbose=\n\t\t\t[KNL] verbose self-tests\n\t\t\tFormat=<0|1>\n\t\t\tPrint debugging info while doing the locking API\n\t\t\tself-tests.\n\t\t\tWe default to 0 (no extra messages), setting it to\n\t\t\t1 will print _a lot_ more information - normally\n\t\t\tonly useful to kernel developers.\n\n\tdebug_objects\t[KNL] Enable object debugging\n\n\tno_debug_objects\n\t\t\t[KNL] Disable object debugging\n\n\tdebug_guardpage_minorder=\n\t\t\t[KNL] When CONFIG_DEBUG_PAGEALLOC is set, this\n\t\t\tparameter allows control of the order of pages that will\n\t\t\tbe intentionally kept free (and hence protected) by the\n\t\t\tbuddy allocator. Bigger value increase the probability\n\t\t\tof catching random memory corruption, but reduce the\n\t\t\tamount of memory for normal system use. The maximum\n\t\t\tpossible value is MAX_ORDER/2.  Setting this parameter\n\t\t\tto 1 or 2 should be enough to identify most random\n\t\t\tmemory corruption problems caused by bugs in kernel or\n\t\t\tdriver code when a CPU writes to (or reads from) a\n\t\t\trandom memory location. Note that there exists a class\n\t\t\tof memory corruptions problems caused by buggy H/W or\n\t\t\tF/W or by drivers badly programing DMA (basically when\n\t\t\tmemory is written at bus level and the CPU MMU is\n\t\t\tbypassed) which are not detectable by\n\t\t\tCONFIG_DEBUG_PAGEALLOC, hence this option will not help\n\t\t\ttracking down these problems.\n\n\tdebug_pagealloc=\n\t\t\t[KNL] When CONFIG_DEBUG_PAGEALLOC is set, this parameter\n\t\t\tenables the feature at boot time. By default, it is\n\t\t\tdisabled and the system will work mostly the same as a\n\t\t\tkernel built without CONFIG_DEBUG_PAGEALLOC.\n\t\t\tNote: to get most of debug_pagealloc error reports, it's\n\t\t\tuseful to also enable the page_owner functionality.\n\t\t\ton: enable the feature\n\n\tdebugfs=    \t[KNL] This parameter enables what is exposed to userspace\n\t\t\tand debugfs internal clients.\n\t\t\tFormat: { on, no-mount, off }\n\t\t\ton: \tAll functions are enabled.\n\t\t\tno-mount:\n\t\t\t\tFilesystem is not registered but kernel clients can\n\t\t\t        access APIs and a crashkernel can be used to read\n\t\t\t\tits content. There is nothing to mount.\n\t\t\toff: \tFilesystem is not registered and clients\n\t\t\t        get a -EPERM as result when trying to register files\n\t\t\t\tor directories within debugfs.\n\t\t\t\tThis is equivalent of the runtime functionality if\n\t\t\t\tdebugfs was not enabled in the kernel at all.\n\t\t\tDefault value is set in build-time with a kernel configuration.\n\n\tdebugpat\t[X86] Enable PAT debugging\n\n\tdecnet.addr=\t[HW,NET]\n\t\t\tFormat: <area>[,<node>]\n\t\t\tSee also Documentation/networking/decnet.rst.\n\n\tdefault_hugepagesz=\n\t\t\t[HW] The size of the default HugeTLB page. This is\n\t\t\tthe size represented by the legacy /proc/ hugepages\n\t\t\tAPIs.  In addition, this is the default hugetlb size\n\t\t\tused for shmget(), mmap() and mounting hugetlbfs\n\t\t\tfilesystems.  If not specified, defaults to the\n\t\t\tarchitecture's default huge page size.  Huge page\n\t\t\tsizes are architecture dependent.  See also\n\t\t\tDocumentation/admin-guide/mm/hugetlbpage.rst.\n\t\t\tFormat: size[KMG]\n\n\tdeferred_probe_timeout=\n\t\t\t[KNL] Debugging option to set a timeout in seconds for\n\t\t\tdeferred probe to give up waiting on dependencies to\n\t\t\tprobe. Only specific dependencies (subsystems or\n\t\t\tdrivers) that have opted in will be ignored. A timeout of 0\n\t\t\twill timeout at the end of initcalls. This option will also\n\t\t\tdump out devices still on the deferred probe list after\n\t\t\tretrying.\n\n\tdfltcc=\t\t[HW,S390]\n\t\t\tFormat: { on | off | def_only | inf_only | always }\n\t\t\ton:       s390 zlib hardware support for compression on\n\t\t\t          level 1 and decompression (default)\n\t\t\toff:      No s390 zlib hardware support\n\t\t\tdef_only: s390 zlib hardware support for deflate\n\t\t\t          only (compression on level 1)\n\t\t\tinf_only: s390 zlib hardware support for inflate\n\t\t\t          only (decompression)\n\t\t\talways:   Same as 'on' but ignores the selected compression\n\t\t\t          level always using hardware support (used for debugging)\n\n\tdhash_entries=\t[KNL]\n\t\t\tSet number of hash buckets for dentry cache.\n\n\tdisable_1tb_segments [PPC]\n\t\t\tDisables the use of 1TB hash page table segments. This\n\t\t\tcauses the kernel to fall back to 256MB segments which\n\t\t\tcan be useful when debugging issues that require an SLB\n\t\t\tmiss to occur.\n\n\tstress_slb\t[PPC]\n\t\t\tLimits the number of kernel SLB entries, and flushes\n\t\t\tthem frequently to increase the rate of SLB faults\n\t\t\ton kernel addresses.\n\n\tdisable=\t[IPV6]\n\t\t\tSee Documentation/networking/ipv6.rst.\n\n\thardened_usercopy=\n                        [KNL] Under CONFIG_HARDENED_USERCOPY, whether\n                        hardening is enabled for this boot. Hardened\n                        usercopy checking is used to protect the kernel\n                        from reading or writing beyond known memory\n                        allocation boundaries as a proactive defense\n                        against bounds-checking flaws in the kernel's\n                        copy_to_user()/copy_from_user() interface.\n                on      Perform hardened usercopy checks (default).\n                off     Disable hardened usercopy checks.\n\n\tdisable_radix\t[PPC]\n\t\t\tDisable RADIX MMU mode on POWER9\n\n\tradix_hcall_invalidate=on  [PPC/PSERIES]\n\t\t\tDisable RADIX GTSE feature and use hcall for TLB\n\t\t\tinvalidate.\n\n\tdisable_tlbie\t[PPC]\n\t\t\tDisable TLBIE instruction. Currently does not work\n\t\t\twith KVM, with HASH MMU, or with coherent accelerators.\n\n\tdisable_cpu_apicid= [X86,APIC,SMP]\n\t\t\tFormat: <int>\n\t\t\tThe number of initial APIC ID for the\n\t\t\tcorresponding CPU to be disabled at boot,\n\t\t\tmostly used for the kdump 2nd kernel to\n\t\t\tdisable BSP to wake up multiple CPUs without\n\t\t\tcausing system reset or hang due to sending\n\t\t\tINIT from AP to BSP.\n\n\tperf_v4_pmi=\t[X86,INTEL]\n\t\t\tFormat: <bool>\n\t\t\tDisable Intel PMU counter freezing feature.\n\t\t\tThe feature only exists starting from\n\t\t\tArch Perfmon v4 (Skylake and newer).\n\n\tdisable_ddw\t[PPC/PSERIES]\n\t\t\tDisable Dynamic DMA Window support. Use this if\n\t\t\tto workaround buggy firmware.\n\n\tdisable_ipv6=\t[IPV6]\n\t\t\tSee Documentation/networking/ipv6.rst.\n\n\tdisable_mtrr_cleanup [X86]\n\t\t\tThe kernel tries to adjust MTRR layout from continuous\n\t\t\tto discrete, to make X server driver able to add WB\n\t\t\tentry later. This parameter disables that.\n\n\tdisable_mtrr_trim [X86, Intel and AMD only]\n\t\t\tBy default the kernel will trim any uncacheable\n\t\t\tmemory out of your available memory pool based on\n\t\t\tMTRR settings.  This parameter disables that behavior,\n\t\t\tpossibly causing your machine to run very slowly.\n\n\tdisable_timer_pin_1 [X86]\n\t\t\tDisable PIN 1 of APIC timer\n\t\t\tCan be useful to work around chipset bugs.\n\n\tdis_ucode_ldr\t[X86] Disable the microcode loader.\n\n\tdma_debug=off\tIf the kernel is compiled with DMA_API_DEBUG support,\n\t\t\tthis option disables the debugging code at boot.\n\n\tdma_debug_entries=<number>\n\t\t\tThis option allows to tune the number of preallocated\n\t\t\tentries for DMA-API debugging code. One entry is\n\t\t\trequired per DMA-API allocation. Use this if the\n\t\t\tDMA-API debugging code disables itself because the\n\t\t\tarchitectural default is too low.\n\n\tdma_debug_driver=<driver_name>\n\t\t\tWith this option the DMA-API debugging driver\n\t\t\tfilter feature can be enabled at boot time. Just\n\t\t\tpass the driver to filter for as the parameter.\n\t\t\tThe filter can be disabled or changed to another\n\t\t\tdriver later using sysfs.\n\n\tdriver_async_probe=  [KNL]\n\t\t\tList of driver names to be probed asynchronously.\n\t\t\tFormat: <driver_name1>,<driver_name2>...\n\n\tdrm.edid_firmware=[<connector>:]<file>[,[<connector>:]<file>]\n\t\t\tBroken monitors, graphic adapters, KVMs and EDIDless\n\t\t\tpanels may send no or incorrect EDID data sets.\n\t\t\tThis parameter allows to specify an EDID data sets\n\t\t\tin the /lib/firmware directory that are used instead.\n\t\t\tGeneric built-in EDID data sets are used, if one of\n\t\t\tedid/1024x768.bin, edid/1280x1024.bin,\n\t\t\tedid/1680x1050.bin, or edid/1920x1080.bin is given\n\t\t\tand no file with the same name exists. Details and\n\t\t\tinstructions how to build your own EDID data are\n\t\t\tavailable in Documentation/admin-guide/edid.rst. An EDID\n\t\t\tdata set will only be used for a particular connector,\n\t\t\tif its name and a colon are prepended to the EDID\n\t\t\tname. Each connector may use a unique EDID data\n\t\t\tset by separating the files with a comma.  An EDID\n\t\t\tdata set with no connector name will be used for\n\t\t\tany connectors not explicitly specified.\n\n\tdscc4.setup=\t[NET]\n\n\tdt_cpu_ftrs=\t[PPC]\n\t\t\tFormat: {\"off\" | \"known\"}\n\t\t\tControl how the dt_cpu_ftrs device-tree binding is\n\t\t\tused for CPU feature discovery and setup (if it\n\t\t\texists).\n\t\t\toff: Do not use it, fall back to legacy cpu table.\n\t\t\tknown: Do not pass through unknown features to guests\n\t\t\tor userspace, only those that the kernel is aware of.\n\n\tdump_apple_properties\t[X86]\n\t\t\tDump name and content of EFI device properties on\n\t\t\tx86 Macs.  Useful for driver authors to determine\n\t\t\twhat data is available or for reverse-engineering.\n\n\tdyndbg[=\"val\"]\t\t[KNL,DYNAMIC_DEBUG]\n\tmodule.dyndbg[=\"val\"]\n\t\t\tEnable debug messages at boot time.  See\n\t\t\tDocumentation/admin-guide/dynamic-debug-howto.rst\n\t\t\tfor details.\n\n\tnopku\t\t[X86] Disable Memory Protection Keys CPU feature found\n\t\t\tin some Intel CPUs.\n\n\tmodule.async_probe [KNL]\n\t\t\tEnable asynchronous probe on this module.\n\n\tearly_ioremap_debug [KNL]\n\t\t\tEnable debug messages in early_ioremap support. This\n\t\t\tis useful for tracking down temporary early mappings\n\t\t\twhich are not unmapped.\n\n\tearlycon=\t[KNL] Output early console device and options.\n\n\t\t\tWhen used with no options, the early console is\n\t\t\tdetermined by stdout-path property in device tree's\n\t\t\tchosen node or the ACPI SPCR table if supported by\n\t\t\tthe platform.\n\n\t\tcdns,<addr>[,options]\n\t\t\tStart an early, polled-mode console on a Cadence\n\t\t\t(xuartps) serial port at the specified address. Only\n\t\t\tsupported option is baud rate. If baud rate is not\n\t\t\tspecified, the serial port must already be setup and\n\t\t\tconfigured.\n\n\t\tuart[8250],io,<addr>[,options]\n\t\tuart[8250],mmio,<addr>[,options]\n\t\tuart[8250],mmio32,<addr>[,options]\n\t\tuart[8250],mmio32be,<addr>[,options]\n\t\tuart[8250],0x<addr>[,options]\n\t\t\tStart an early, polled-mode console on the 8250/16550\n\t\t\tUART at the specified I/O port or MMIO address.\n\t\t\tMMIO inter-register address stride is either 8-bit\n\t\t\t(mmio) or 32-bit (mmio32 or mmio32be).\n\t\t\tIf none of [io|mmio|mmio32|mmio32be], <addr> is assumed\n\t\t\tto be equivalent to 'mmio'. 'options' are specified\n\t\t\tin the same format described for \"console=ttyS<n>\"; if\n\t\t\tunspecified, the h/w is not initialized.\n\n\t\tpl011,<addr>\n\t\tpl011,mmio32,<addr>\n\t\t\tStart an early, polled-mode console on a pl011 serial\n\t\t\tport at the specified address. The pl011 serial port\n\t\t\tmust already be setup and configured. Options are not\n\t\t\tyet supported.  If 'mmio32' is specified, then only\n\t\t\tthe driver will use only 32-bit accessors to read/write\n\t\t\tthe device registers.\n\n\t\tmeson,<addr>\n\t\t\tStart an early, polled-mode console on a meson serial\n\t\t\tport at the specified address. The serial port must\n\t\t\talready be setup and configured. Options are not yet\n\t\t\tsupported.\n\n\t\tmsm_serial,<addr>\n\t\t\tStart an early, polled-mode console on an msm serial\n\t\t\tport at the specified address. The serial port\n\t\t\tmust already be setup and configured. Options are not\n\t\t\tyet supported.\n\n\t\tmsm_serial_dm,<addr>\n\t\t\tStart an early, polled-mode console on an msm serial\n\t\t\tdm port at the specified address. The serial port\n\t\t\tmust already be setup and configured. Options are not\n\t\t\tyet supported.\n\n\t\towl,<addr>\n\t\t\tStart an early, polled-mode console on a serial port\n\t\t\tof an Actions Semi SoC, such as S500 or S900, at the\n\t\t\tspecified address. The serial port must already be\n\t\t\tsetup and configured. Options are not yet supported.\n\n\t\trda,<addr>\n\t\t\tStart an early, polled-mode console on a serial port\n\t\t\tof an RDA Micro SoC, such as RDA8810PL, at the\n\t\t\tspecified address. The serial port must already be\n\t\t\tsetup and configured. Options are not yet supported.\n\n\t\tsbi\n\t\t\tUse RISC-V SBI (Supervisor Binary Interface) for early\n\t\t\tconsole.\n\n\t\tsmh\tUse ARM semihosting calls for early console.\n\n\t\ts3c2410,<addr>\n\t\ts3c2412,<addr>\n\t\ts3c2440,<addr>\n\t\ts3c6400,<addr>\n\t\ts5pv210,<addr>\n\t\texynos4210,<addr>\n\t\t\tUse early console provided by serial driver available\n\t\t\ton Samsung SoCs, requires selecting proper type and\n\t\t\ta correct base address of the selected UART port. The\n\t\t\tserial port must already be setup and configured.\n\t\t\tOptions are not yet supported.\n\n\t\tlantiq,<addr>\n\t\t\tStart an early, polled-mode console on a lantiq serial\n\t\t\t(lqasc) port at the specified address. The serial port\n\t\t\tmust already be setup and configured. Options are not\n\t\t\tyet supported.\n\n\t\tlpuart,<addr>\n\t\tlpuart32,<addr>\n\t\t\tUse early console provided by Freescale LP UART driver\n\t\t\tfound on Freescale Vybrid and QorIQ LS1021A processors.\n\t\t\tA valid base address must be provided, and the serial\n\t\t\tport must already be setup and configured.\n\n\t\tec_imx21,<addr>\n\t\tec_imx6q,<addr>\n\t\t\tStart an early, polled-mode, output-only console on the\n\t\t\tFreescale i.MX UART at the specified address. The UART\n\t\t\tmust already be setup and configured.\n\n\t\tar3700_uart,<addr>\n\t\t\tStart an early, polled-mode console on the\n\t\t\tArmada 3700 serial port at the specified\n\t\t\taddress. The serial port must already be setup\n\t\t\tand configured. Options are not yet supported.\n\n\t\tqcom_geni,<addr>\n\t\t\tStart an early, polled-mode console on a Qualcomm\n\t\t\tGeneric Interface (GENI) based serial port at the\n\t\t\tspecified address. The serial port must already be\n\t\t\tsetup and configured. Options are not yet supported.\n\n\t\tefifb,[options]\n\t\t\tStart an early, unaccelerated console on the EFI\n\t\t\tmemory mapped framebuffer (if available). On cache\n\t\t\tcoherent non-x86 systems that use system memory for\n\t\t\tthe framebuffer, pass the 'ram' option so that it is\n\t\t\tmapped with the correct attributes.\n\n\t\tlinflex,<addr>\n\t\t\tUse early console provided by Freescale LINFlexD UART\n\t\t\tserial driver for NXP S32V234 SoCs. A valid base\n\t\t\taddress must be provided, and the serial port must\n\t\t\talready be setup and configured.\n\n\tearlyprintk=\t[X86,SH,ARM,M68k,S390]\n\t\t\tearlyprintk=vga\n\t\t\tearlyprintk=sclp\n\t\t\tearlyprintk=xen\n\t\t\tearlyprintk=serial[,ttySn[,baudrate]]\n\t\t\tearlyprintk=serial[,0x...[,baudrate]]\n\t\t\tearlyprintk=ttySn[,baudrate]\n\t\t\tearlyprintk=dbgp[debugController#]\n\t\t\tearlyprintk=pciserial[,force],bus:device.function[,baudrate]\n\t\t\tearlyprintk=xdbc[xhciController#]\n\n\t\t\tearlyprintk is useful when the kernel crashes before\n\t\t\tthe normal console is initialized. It is not enabled by\n\t\t\tdefault because it has some cosmetic problems.\n\n\t\t\tAppend \",keep\" to not disable it when the real console\n\t\t\ttakes over.\n\n\t\t\tOnly one of vga, efi, serial, or usb debug port can\n\t\t\tbe used at a time.\n\n\t\t\tCurrently only ttyS0 and ttyS1 may be specified by\n\t\t\tname.  Other I/O ports may be explicitly specified\n\t\t\ton some architectures (x86 and arm at least) by\n\t\t\treplacing ttySn with an I/O port address, like this:\n\t\t\t\tearlyprintk=serial,0x1008,115200\n\t\t\tYou can find the port for a given device in\n\t\t\t/proc/tty/driver/serial:\n\t\t\t\t2: uart:ST16650V2 port:00001008 irq:18 ...\n\n\t\t\tInteraction with the standard serial driver is not\n\t\t\tvery good.\n\n\t\t\tThe VGA and EFI output is eventually overwritten by\n\t\t\tthe real console.\n\n\t\t\tThe xen output can only be used by Xen PV guests.\n\n\t\t\tThe sclp output can only be used on s390.\n\n\t\t\tThe optional \"force\" to \"pciserial\" enables use of a\n\t\t\tPCI device even when its classcode is not of the\n\t\t\tUART class.\n\n\tedac_report=\t[HW,EDAC] Control how to report EDAC event\n\t\t\tFormat: {\"on\" | \"off\" | \"force\"}\n\t\t\ton: enable EDAC to report H/W event. May be overridden\n\t\t\tby other higher priority error reporting module.\n\t\t\toff: disable H/W event reporting through EDAC.\n\t\t\tforce: enforce the use of EDAC to report H/W event.\n\t\t\tdefault: on.\n\n\tekgdboc=\t[X86,KGDB] Allow early kernel console debugging\n\t\t\tekgdboc=kbd\n\n\t\t\tThis is designed to be used in conjunction with\n\t\t\tthe boot argument: earlyprintk=vga\n\n\t\t\tThis parameter works in place of the kgdboc parameter\n\t\t\tbut can only be used if the backing tty is available\n\t\t\tvery early in the boot process. For early debugging\n\t\t\tvia a serial port see kgdboc_earlycon instead.\n\n\tedd=\t\t[EDD]\n\t\t\tFormat: {\"off\" | \"on\" | \"skip[mbr]\"}\n\n\tefi=\t\t[EFI]\n\t\t\tFormat: { \"debug\", \"disable_early_pci_dma\",\n\t\t\t\t  \"nochunk\", \"noruntime\", \"nosoftreserve\",\n\t\t\t\t  \"novamap\", \"no_disable_early_pci_dma\" }\n\t\t\tdebug: enable misc debug output.\n\t\t\tdisable_early_pci_dma: disable the busmaster bit on all\n\t\t\tPCI bridges while in the EFI boot stub.\n\t\t\tnochunk: disable reading files in \"chunks\" in the EFI\n\t\t\tboot stub, as chunking can cause problems with some\n\t\t\tfirmware implementations.\n\t\t\tnoruntime : disable EFI runtime services support\n\t\t\tnosoftreserve: The EFI_MEMORY_SP (Specific Purpose)\n\t\t\tattribute may cause the kernel to reserve the\n\t\t\tmemory range for a memory mapping driver to\n\t\t\tclaim. Specify efi=nosoftreserve to disable this\n\t\t\treservation and treat the memory by its base type\n\t\t\t(i.e. EFI_CONVENTIONAL_MEMORY / \"System RAM\").\n\t\t\tnovamap: do not call SetVirtualAddressMap().\n\t\t\tno_disable_early_pci_dma: Leave the busmaster bit set\n\t\t\ton all PCI bridges while in the EFI boot stub\n\n\tefi_no_storage_paranoia [EFI; X86]\n\t\t\tUsing this parameter you can use more than 50% of\n\t\t\tyour efi variable storage. Use this parameter only if\n\t\t\tyou are really sure that your UEFI does sane gc and\n\t\t\tfulfills the spec otherwise your board may brick.\n\n\tefi_fake_mem=\tnn[KMG]@ss[KMG]:aa[,nn[KMG]@ss[KMG]:aa,..] [EFI; X86]\n\t\t\tAdd arbitrary attribute to specific memory range by\n\t\t\tupdating original EFI memory map.\n\t\t\tRegion of memory which aa attribute is added to is\n\t\t\tfrom ss to ss+nn.\n\n\t\t\tIf efi_fake_mem=2G@4G:0x10000,2G@0x10a0000000:0x10000\n\t\t\tis specified, EFI_MEMORY_MORE_RELIABLE(0x10000)\n\t\t\tattribute is added to range 0x100000000-0x180000000 and\n\t\t\t0x10a0000000-0x1120000000.\n\n\t\t\tIf efi_fake_mem=8G@9G:0x40000 is specified, the\n\t\t\tEFI_MEMORY_SP(0x40000) attribute is added to\n\t\t\trange 0x240000000-0x43fffffff.\n\n\t\t\tUsing this parameter you can do debugging of EFI memmap\n\t\t\trelated features. For example, you can do debugging of\n\t\t\tAddress Range Mirroring feature even if your box\n\t\t\tdoesn't support it, or mark specific memory as\n\t\t\t\"soft reserved\".\n\n\tefivar_ssdt=\t[EFI; X86] Name of an EFI variable that contains an SSDT\n\t\t\tthat is to be dynamically loaded by Linux. If there are\n\t\t\tmultiple variables with the same name but with different\n\t\t\tvendor GUIDs, all of them will be loaded. See\n\t\t\tDocumentation/admin-guide/acpi/ssdt-overlays.rst for details.\n\n\n\teisa_irq_edge=\t[PARISC,HW]\n\t\t\tSee header of drivers/parisc/eisa.c.\n\n\telanfreq=\t[X86-32]\n\t\t\tSee comment before function elanfreq_setup() in\n\t\t\tarch/x86/kernel/cpu/cpufreq/elanfreq.c.\n\n\telfcorehdr=[size[KMG]@]offset[KMG] [IA64,PPC,SH,X86,S390]\n\t\t\tSpecifies physical address of start of kernel core\n\t\t\timage elf header and optionally the size. Generally\n\t\t\tkexec loader will pass this option to capture kernel.\n\t\t\tSee Documentation/admin-guide/kdump/kdump.rst for details.\n\n\tenable_mtrr_cleanup [X86]\n\t\t\tThe kernel tries to adjust MTRR layout from continuous\n\t\t\tto discrete, to make X server driver able to add WB\n\t\t\tentry later. This parameter enables that.\n\n\tenable_timer_pin_1 [X86]\n\t\t\tEnable PIN 1 of APIC timer\n\t\t\tCan be useful to work around chipset bugs\n\t\t\t(in particular on some ATI chipsets).\n\t\t\tThe kernel tries to set a reasonable default.\n\n\tenforcing\t[SELINUX] Set initial enforcing status.\n\t\t\tFormat: {\"0\" | \"1\"}\n\t\t\tSee security/selinux/Kconfig help text.\n\t\t\t0 -- permissive (log only, no denials).\n\t\t\t1 -- enforcing (deny and log).\n\t\t\tDefault value is 0.\n\t\t\tValue can be changed at runtime via\n\t\t\t/sys/fs/selinux/enforce.\n\n\terst_disable\t[ACPI]\n\t\t\tDisable Error Record Serialization Table (ERST)\n\t\t\tsupport.\n\n\tether=\t\t[HW,NET] Ethernet cards parameters\n\t\t\tThis option is obsoleted by the \"netdev=\" option, which\n\t\t\thas equivalent usage. See its documentation for details.\n\n\tevm=\t\t[EVM]\n\t\t\tFormat: { \"fix\" }\n\t\t\tPermit 'security.evm' to be updated regardless of\n\t\t\tcurrent integrity status.\n\n\tfailslab=\n\tfail_page_alloc=\n\tfail_make_request=[KNL]\n\t\t\tGeneral fault injection mechanism.\n\t\t\tFormat: <interval>,<probability>,<space>,<times>\n\t\t\tSee also Documentation/fault-injection/.\n\n\tfloppy=\t\t[HW]\n\t\t\tSee Documentation/admin-guide/blockdev/floppy.rst.\n\n\tforce_pal_cache_flush\n\t\t\t[IA-64] Avoid check_sal_cache_flush which may hang on\n\t\t\tbuggy SAL_CACHE_FLUSH implementations. Using this\n\t\t\tparameter will force ia64_sal_cache_flush to call\n\t\t\tia64_pal_cache_flush instead of SAL_CACHE_FLUSH.\n\n\tforcepae\t[X86-32]\n\t\t\tForcefully enable Physical Address Extension (PAE).\n\t\t\tMany Pentium M systems disable PAE but may have a\n\t\t\tfunctionally usable PAE implementation.\n\t\t\tWarning: use of this parameter will taint the kernel\n\t\t\tand may cause unknown problems.\n\n\tftrace=[tracer]\n\t\t\t[FTRACE] will set and start the specified tracer\n\t\t\tas early as possible in order to facilitate early\n\t\t\tboot debugging.\n\n\tftrace_dump_on_oops[=orig_cpu]\n\t\t\t[FTRACE] will dump the trace buffers on oops.\n\t\t\tIf no parameter is passed, ftrace will dump\n\t\t\tbuffers of all CPUs, but if you pass orig_cpu, it will\n\t\t\tdump only the buffer of the CPU that triggered the\n\t\t\toops.\n\n\tftrace_filter=[function-list]\n\t\t\t[FTRACE] Limit the functions traced by the function\n\t\t\ttracer at boot up. function-list is a comma separated\n\t\t\tlist of functions. This list can be changed at run\n\t\t\ttime by the set_ftrace_filter file in the debugfs\n\t\t\ttracing directory.\n\n\tftrace_notrace=[function-list]\n\t\t\t[FTRACE] Do not trace the functions specified in\n\t\t\tfunction-list. This list can be changed at run time\n\t\t\tby the set_ftrace_notrace file in the debugfs\n\t\t\ttracing directory.\n\n\tftrace_graph_filter=[function-list]\n\t\t\t[FTRACE] Limit the top level callers functions traced\n\t\t\tby the function graph tracer at boot up.\n\t\t\tfunction-list is a comma separated list of functions\n\t\t\tthat can be changed at run time by the\n\t\t\tset_graph_function file in the debugfs tracing directory.\n\n\tftrace_graph_notrace=[function-list]\n\t\t\t[FTRACE] Do not trace from the functions specified in\n\t\t\tfunction-list.  This list is a comma separated list of\n\t\t\tfunctions that can be changed at run time by the\n\t\t\tset_graph_notrace file in the debugfs tracing directory.\n\n\tftrace_graph_max_depth=<uint>\n\t\t\t[FTRACE] Used with the function graph tracer. This is\n\t\t\tthe max depth it will trace into a function. This value\n\t\t\tcan be changed at run time by the max_graph_depth file\n\t\t\tin the tracefs tracing directory. default: 0 (no limit)\n\n\tfw_devlink=\t[KNL] Create device links between consumer and supplier\n\t\t\tdevices by scanning the firmware to infer the\n\t\t\tconsumer/supplier relationships. This feature is\n\t\t\tespecially useful when drivers are loaded as modules as\n\t\t\tit ensures proper ordering of tasks like device probing\n\t\t\t(suppliers first, then consumers), supplier boot state\n\t\t\tclean up (only after all consumers have probed),\n\t\t\tsuspend/resume & runtime PM (consumers first, then\n\t\t\tsuppliers).\n\t\t\tFormat: { off | permissive | on | rpm }\n\t\t\toff --\tDon't create device links from firmware info.\n\t\t\tpermissive -- Create device links from firmware info\n\t\t\t\tbut use it only for ordering boot state clean\n\t\t\t\tup (sync_state() calls).\n\t\t\ton -- \tCreate device links from firmware info and use it\n\t\t\t\tto enforce probe and suspend/resume ordering.\n\t\t\trpm --\tLike \"on\", but also use to order runtime PM.\n\n\tgamecon.map[2|3]=\n\t\t\t[HW,JOY] Multisystem joystick and NES/SNES/PSX pad\n\t\t\tsupport via parallel port (up to 5 devices per port)\n\t\t\tFormat: <port#>,<pad1>,<pad2>,<pad3>,<pad4>,<pad5>\n\t\t\tSee also Documentation/input/devices/joystick-parport.rst\n\n\tgamma=\t\t[HW,DRM]\n\n\tgart_fix_e820=\t[X86-64] disable the fix e820 for K8 GART\n\t\t\tFormat: off | on\n\t\t\tdefault: on\n\n\tgcov_persist=\t[GCOV] When non-zero (default), profiling data for\n\t\t\tkernel modules is saved and remains accessible via\n\t\t\tdebugfs, even when the module is unloaded/reloaded.\n\t\t\tWhen zero, profiling data is discarded and associated\n\t\t\tdebugfs files are removed at module unload time.\n\n\tgoldfish\t[X86] Enable the goldfish android emulator platform.\n\t\t\tDon't use this when you are not running on the\n\t\t\tandroid emulator\n\n\tgpt\t\t[EFI] Forces disk with valid GPT signature but\n\t\t\tinvalid Protective MBR to be treated as GPT. If the\n\t\t\tprimary GPT is corrupted, it enables the backup/alternate\n\t\t\tGPT to be used instead.\n\n\tgrcan.enable0=\t[HW] Configuration of physical interface 0. Determines\n\t\t\tthe \"Enable 0\" bit of the configuration register.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault: 0\n\tgrcan.enable1=\t[HW] Configuration of physical interface 1. Determines\n\t\t\tthe \"Enable 0\" bit of the configuration register.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault: 0\n\tgrcan.select=\t[HW] Select which physical interface to use.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault: 0\n\tgrcan.txsize=\t[HW] Sets the size of the tx buffer.\n\t\t\tFormat: <unsigned int> such that (txsize & ~0x1fffc0) == 0.\n\t\t\tDefault: 1024\n\tgrcan.rxsize=\t[HW] Sets the size of the rx buffer.\n\t\t\tFormat: <unsigned int> such that (rxsize & ~0x1fffc0) == 0.\n\t\t\tDefault: 1024\n\n\tgpio-mockup.gpio_mockup_ranges\n\t\t\t[HW] Sets the ranges of gpiochip of for this device.\n\t\t\tFormat: <start1>,<end1>,<start2>,<end2>...\n\n\thardlockup_all_cpu_backtrace=\n\t\t\t[KNL] Should the hard-lockup detector generate\n\t\t\tbacktraces on all cpus.\n\t\t\tFormat: 0 | 1\n\n\thashdist=\t[KNL,NUMA] Large hashes allocated during boot\n\t\t\tare distributed across NUMA nodes.  Defaults on\n\t\t\tfor 64-bit NUMA, off otherwise.\n\t\t\tFormat: 0 | 1 (for off | on)\n\n\thcl=\t\t[IA-64] SGI's Hardware Graph compatibility layer\n\n\thd=\t\t[EIDE] (E)IDE hard drive subsystem geometry\n\t\t\tFormat: <cyl>,<head>,<sect>\n\n\thest_disable\t[ACPI]\n\t\t\tDisable Hardware Error Source Table (HEST) support;\n\t\t\tcorresponding firmware-first mode error processing\n\t\t\tlogic will be disabled.\n\n\thighmem=nn[KMG]\t[KNL,BOOT] forces the highmem zone to have an exact\n\t\t\tsize of <nn>. This works even on boxes that have no\n\t\t\thighmem otherwise. This also works to reduce highmem\n\t\t\tsize on bigger boxes.\n\n\thighres=\t[KNL] Enable/disable high resolution timer mode.\n\t\t\tValid parameters: \"on\", \"off\"\n\t\t\tDefault: \"on\"\n\n\thlt\t\t[BUGS=ARM,SH]\n\n\thpet=\t\t[X86-32,HPET] option to control HPET usage\n\t\t\tFormat: { enable (default) | disable | force |\n\t\t\t\tverbose }\n\t\t\tdisable: disable HPET and use PIT instead\n\t\t\tforce: allow force enabled of undocumented chips (ICH4,\n\t\t\t\tVIA, nVidia)\n\t\t\tverbose: show contents of HPET registers during setup\n\n\thpet_mmap=\t[X86, HPET_MMAP] Allow userspace to mmap HPET\n\t\t\tregisters.  Default set by CONFIG_HPET_MMAP_DEFAULT.\n\n\thugetlb_cma=\t[HW] The size of a cma area used for allocation\n\t\t\tof gigantic hugepages.\n\t\t\tFormat: nn[KMGTPE]\n\n\t\t\tReserve a cma area of given size and allocate gigantic\n\t\t\thugepages using the cma allocator. If enabled, the\n\t\t\tboot-time allocation of gigantic hugepages is skipped.\n\n\thugepages=\t[HW] Number of HugeTLB pages to allocate at boot.\n\t\t\tIf this follows hugepagesz (below), it specifies\n\t\t\tthe number of pages of hugepagesz to be allocated.\n\t\t\tIf this is the first HugeTLB parameter on the command\n\t\t\tline, it specifies the number of pages to allocate for\n\t\t\tthe default huge page size.  See also\n\t\t\tDocumentation/admin-guide/mm/hugetlbpage.rst.\n\t\t\tFormat: <integer>\n\n\thugepagesz=\n\t\t\t[HW] The size of the HugeTLB pages.  This is used in\n\t\t\tconjunction with hugepages (above) to allocate huge\n\t\t\tpages of a specific size at boot.  The pair\n\t\t\thugepagesz=X hugepages=Y can be specified once for\n\t\t\teach supported huge page size. Huge page sizes are\n\t\t\tarchitecture dependent.  See also\n\t\t\tDocumentation/admin-guide/mm/hugetlbpage.rst.\n\t\t\tFormat: size[KMG]\n\n\thung_task_panic=\n\t\t\t[KNL] Should the hung task detector generate panics.\n\t\t\tFormat: 0 | 1\n\n\t\t\tA value of 1 instructs the kernel to panic when a\n\t\t\thung task is detected. The default value is controlled\n\t\t\tby the CONFIG_BOOTPARAM_HUNG_TASK_PANIC build-time\n\t\t\toption. The value selected by this boot parameter can\n\t\t\tbe changed later by the kernel.hung_task_panic sysctl.\n\n\thvc_iucv=\t[S390]\tNumber of z/VM IUCV hypervisor console (HVC)\n\t\t\t\tterminal devices. Valid values: 0..8\n\thvc_iucv_allow=\t[S390]\tComma-separated list of z/VM user IDs.\n\t\t\t\tIf specified, z/VM IUCV HVC accepts connections\n\t\t\t\tfrom listed z/VM user IDs only.\n\n\thv_nopvspin\t[X86,HYPER_V] Disables the paravirt spinlock optimizations\n\t\t\t\t      which allow the hypervisor to 'idle' the\n\t\t\t\t      guest on lock contention.\n\n\tkeep_bootcon\t[KNL]\n\t\t\tDo not unregister boot console at start. This is only\n\t\t\tuseful for debugging when something happens in the window\n\t\t\tbetween unregistering the boot console and initializing\n\t\t\tthe real console.\n\n\ti2c_bus=\t[HW]\tOverride the default board specific I2C bus speed\n\t\t\t\tor register an additional I2C bus that is not\n\t\t\t\tregistered from board initialization code.\n\t\t\t\tFormat:\n\t\t\t\t<bus_id>,<clkrate>\n\n\ti8042.debug\t[HW] Toggle i8042 debug mode\n\ti8042.unmask_kbd_data\n\t\t\t[HW] Enable printing of interrupt data from the KBD port\n\t\t\t     (disabled by default, and as a pre-condition\n\t\t\t     requires that i8042.debug=1 be enabled)\n\ti8042.direct\t[HW] Put keyboard port into non-translated mode\n\ti8042.dumbkbd\t[HW] Pretend that controller can only read data from\n\t\t\t     keyboard and cannot control its state\n\t\t\t     (Don't attempt to blink the leds)\n\ti8042.noaux\t[HW] Don't check for auxiliary (== mouse) port\n\ti8042.nokbd\t[HW] Don't check/create keyboard port\n\ti8042.noloop\t[HW] Disable the AUX Loopback command while probing\n\t\t\t     for the AUX port\n\ti8042.nomux\t[HW] Don't check presence of an active multiplexing\n\t\t\t     controller\n\ti8042.nopnp\t[HW] Don't use ACPIPnP / PnPBIOS to discover KBD/AUX\n\t\t\t     controllers\n\ti8042.notimeout\t[HW] Ignore timeout condition signalled by controller\n\ti8042.reset\t[HW] Reset the controller during init, cleanup and\n\t\t\t     suspend-to-ram transitions, only during s2r\n\t\t\t     transitions, or never reset\n\t\t\tFormat: { 1 | Y | y | 0 | N | n }\n\t\t\t1, Y, y: always reset controller\n\t\t\t0, N, n: don't ever reset controller\n\t\t\tDefault: only on s2r transitions on x86; most other\n\t\t\tarchitectures force reset to be always executed\n\ti8042.unlock\t[HW] Unlock (ignore) the keylock\n\ti8042.kbdreset\t[HW] Reset device connected to KBD port\n\n\ti810=\t\t[HW,DRM]\n\n\ti8k.ignore_dmi\t[HW] Continue probing hardware even if DMI data\n\t\t\tindicates that the driver is running on unsupported\n\t\t\thardware.\n\ti8k.force\t[HW] Activate i8k driver even if SMM BIOS signature\n\t\t\tdoes not match list of supported models.\n\ti8k.power_status\n\t\t\t[HW] Report power status in /proc/i8k\n\t\t\t(disabled by default)\n\ti8k.restricted\t[HW] Allow controlling fans only if SYS_ADMIN\n\t\t\tcapability is set.\n\n\ti915.invert_brightness=\n\t\t\t[DRM] Invert the sense of the variable that is used to\n\t\t\tset the brightness of the panel backlight. Normally a\n\t\t\tbrightness value of 0 indicates backlight switched off,\n\t\t\tand the maximum of the brightness value sets the backlight\n\t\t\tto maximum brightness. If this parameter is set to 0\n\t\t\t(default) and the machine requires it, or this parameter\n\t\t\tis set to 1, a brightness value of 0 sets the backlight\n\t\t\tto maximum brightness, and the maximum of the brightness\n\t\t\tvalue switches the backlight off.\n\t\t\t-1 -- never invert brightness\n\t\t\t 0 -- machine default\n\t\t\t 1 -- force brightness inversion\n\n\ticn=\t\t[HW,ISDN]\n\t\t\tFormat: <io>[,<membase>[,<icn_id>[,<icn_id2>]]]\n\n\tide-core.nodma=\t[HW] (E)IDE subsystem\n\t\t\tFormat: =0.0 to prevent dma on hda, =0.1 hdb =1.0 hdc\n\t\t\t.vlb_clock .pci_clock .noflush .nohpa .noprobe .nowerr\n\t\t\t.cdrom .chs .ignore_cable are additional options\n\t\t\tSee Documentation/ide/ide.rst.\n\n\tide-generic.probe-mask= [HW] (E)IDE subsystem\n\t\t\tFormat: <int>\n\t\t\tProbe mask for legacy ISA IDE ports.  Depending on\n\t\t\tplatform up to 6 ports are supported, enabled by\n\t\t\tsetting corresponding bits in the mask to 1.  The\n\t\t\tdefault value is 0x0, which has a special meaning.\n\t\t\tOn systems that have PCI, it triggers scanning the\n\t\t\tPCI bus for the first and the second port, which\n\t\t\tare then probed.  On systems without PCI the value\n\t\t\tof 0x0 enables probing the two first ports as if it\n\t\t\twas 0x3.\n\n\tide-pci-generic.all-generic-ide [HW] (E)IDE subsystem\n\t\t\tClaim all unknown PCI IDE storage controllers.\n\n\tidle=\t\t[X86]\n\t\t\tFormat: idle=poll, idle=halt, idle=nomwait\n\t\t\tPoll forces a polling idle loop that can slightly\n\t\t\timprove the performance of waking up a idle CPU, but\n\t\t\twill use a lot of power and make the system run hot.\n\t\t\tNot recommended.\n\t\t\tidle=halt: Halt is forced to be used for CPU idle.\n\t\t\tIn such case C2/C3 won't be used again.\n\t\t\tidle=nomwait: Disable mwait for CPU C-states\n\n\tieee754=\t[MIPS] Select IEEE Std 754 conformance mode\n\t\t\tFormat: { strict | legacy | 2008 | relaxed }\n\t\t\tDefault: strict\n\n\t\t\tChoose which programs will be accepted for execution\n\t\t\tbased on the IEEE 754 NaN encoding(s) supported by\n\t\t\tthe FPU and the NaN encoding requested with the value\n\t\t\tof an ELF file header flag individually set by each\n\t\t\tbinary.  Hardware implementations are permitted to\n\t\t\tsupport either or both of the legacy and the 2008 NaN\n\t\t\tencoding mode.\n\n\t\t\tAvailable settings are as follows:\n\t\t\tstrict\taccept binaries that request a NaN encoding\n\t\t\t\tsupported by the FPU\n\t\t\tlegacy\tonly accept legacy-NaN binaries, if supported\n\t\t\t\tby the FPU\n\t\t\t2008\tonly accept 2008-NaN binaries, if supported\n\t\t\t\tby the FPU\n\t\t\trelaxed\taccept any binaries regardless of whether\n\t\t\t\tsupported by the FPU\n\n\t\t\tThe FPU emulator is always able to support both NaN\n\t\t\tencodings, so if no FPU hardware is present or it has\n\t\t\tbeen disabled with 'nofpu', then the settings of\n\t\t\t'legacy' and '2008' strap the emulator accordingly,\n\t\t\t'relaxed' straps the emulator for both legacy-NaN and\n\t\t\t2008-NaN, whereas 'strict' enables legacy-NaN only on\n\t\t\tlegacy processors and both NaN encodings on MIPS32 or\n\t\t\tMIPS64 CPUs.\n\n\t\t\tThe setting for ABS.fmt/NEG.fmt instruction execution\n\t\t\tmode generally follows that for the NaN encoding,\n\t\t\texcept where unsupported by hardware.\n\n\tignore_loglevel\t[KNL]\n\t\t\tIgnore loglevel setting - this will print /all/\n\t\t\tkernel messages to the console. Useful for debugging.\n\t\t\tWe also add it as printk module parameter, so users\n\t\t\tcould change it dynamically, usually by\n\t\t\t/sys/module/printk/parameters/ignore_loglevel.\n\n\tignore_rlimit_data\n\t\t\tIgnore RLIMIT_DATA setting for data mappings,\n\t\t\tprint warning at first misuse.  Can be changed via\n\t\t\t/sys/module/kernel/parameters/ignore_rlimit_data.\n\n\tihash_entries=\t[KNL]\n\t\t\tSet number of hash buckets for inode cache.\n\n\tima_appraise=\t[IMA] appraise integrity measurements\n\t\t\tFormat: { \"off\" | \"enforce\" | \"fix\" | \"log\" }\n\t\t\tdefault: \"enforce\"\n\n\tima_appraise_tcb [IMA] Deprecated.  Use ima_policy= instead.\n\t\t\tThe builtin appraise policy appraises all files\n\t\t\towned by uid=0.\n\n\tima_canonical_fmt [IMA]\n\t\t\tUse the canonical format for the binary runtime\n\t\t\tmeasurements, instead of host native format.\n\n\tima_hash=\t[IMA]\n\t\t\tFormat: { md5 | sha1 | rmd160 | sha256 | sha384\n\t\t\t\t   | sha512 | ... }\n\t\t\tdefault: \"sha1\"\n\n\t\t\tThe list of supported hash algorithms is defined\n\t\t\tin crypto/hash_info.h.\n\n\tima_policy=\t[IMA]\n\t\t\tThe builtin policies to load during IMA setup.\n\t\t\tFormat: \"tcb | appraise_tcb | secure_boot |\n\t\t\t\t fail_securely\"\n\n\t\t\tThe \"tcb\" policy measures all programs exec'd, files\n\t\t\tmmap'd for exec, and all files opened with the read\n\t\t\tmode bit set by either the effective uid (euid=0) or\n\t\t\tuid=0.\n\n\t\t\tThe \"appraise_tcb\" policy appraises the integrity of\n\t\t\tall files owned by root.\n\n\t\t\tThe \"secure_boot\" policy appraises the integrity\n\t\t\tof files (eg. kexec kernel image, kernel modules,\n\t\t\tfirmware, policy, etc) based on file signatures.\n\n\t\t\tThe \"fail_securely\" policy forces file signature\n\t\t\tverification failure also on privileged mounted\n\t\t\tfilesystems with the SB_I_UNVERIFIABLE_SIGNATURE\n\t\t\tflag.\n\n\tima_tcb\t\t[IMA] Deprecated.  Use ima_policy= instead.\n\t\t\tLoad a policy which meets the needs of the Trusted\n\t\t\tComputing Base.  This means IMA will measure all\n\t\t\tprograms exec'd, files mmap'd for exec, and all files\n\t\t\topened for read by uid=0.\n\n\tima_template=\t[IMA]\n\t\t\tSelect one of defined IMA measurements template formats.\n\t\t\tFormats: { \"ima\" | \"ima-ng\" | \"ima-sig\" }\n\t\t\tDefault: \"ima-ng\"\n\n\tima_template_fmt=\n\t\t\t[IMA] Define a custom template format.\n\t\t\tFormat: { \"field1|...|fieldN\" }\n\n\tima.ahash_minsize= [IMA] Minimum file size for asynchronous hash usage\n\t\t\tFormat: <min_file_size>\n\t\t\tSet the minimal file size for using asynchronous hash.\n\t\t\tIf left unspecified, ahash usage is disabled.\n\n\t\t\tahash performance varies for different data sizes on\n\t\t\tdifferent crypto accelerators. This option can be used\n\t\t\tto achieve the best performance for a particular HW.\n\n\tima.ahash_bufsize= [IMA] Asynchronous hash buffer size\n\t\t\tFormat: <bufsize>\n\t\t\tSet hashing buffer size. Default: 4k.\n\n\t\t\tahash performance varies for different chunk sizes on\n\t\t\tdifferent crypto accelerators. This option can be used\n\t\t\tto achieve best performance for particular HW.\n\n\tinit=\t\t[KNL]\n\t\t\tFormat: <full_path>\n\t\t\tRun specified binary instead of /sbin/init as init\n\t\t\tprocess.\n\n\tinitcall_debug\t[KNL] Trace initcalls as they are executed.  Useful\n\t\t\tfor working out where the kernel is dying during\n\t\t\tstartup.\n\n\tinitcall_blacklist=  [KNL] Do not execute a comma-separated list of\n\t\t\tinitcall functions.  Useful for debugging built-in\n\t\t\tmodules and initcalls.\n\n\tinitrd=\t\t[BOOT] Specify the location of the initial ramdisk\n\n\tinitrdmem=\t[KNL] Specify a physical address and size from which to\n\t\t\tload the initrd. If an initrd is compiled in or\n\t\t\tspecified in the bootparams, it takes priority over this\n\t\t\tsetting.\n\t\t\tFormat: ss[KMG],nn[KMG]\n\t\t\tDefault is 0, 0\n\n\tinit_on_alloc=\t[MM] Fill newly allocated pages and heap objects with\n\t\t\tzeroes.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault set by CONFIG_INIT_ON_ALLOC_DEFAULT_ON.\n\n\tinit_on_free=\t[MM] Fill freed pages and heap objects with zeroes.\n\t\t\tFormat: 0 | 1\n\t\t\tDefault set by CONFIG_INIT_ON_FREE_DEFAULT_ON.\n\n\tinit_pkru=\t[X86] Specify the default memory protection keys rights\n\t\t\tregister contents for all processes.  0x55555554 by\n\t\t\tdefault (disallow access to all but pkey 0).  Can\n\t\t\toverride in debugfs after boot.\n\n\tinport.irq=\t[HW] Inport (ATI XL and Microsoft) busmouse driver\n\t\t\tFormat: <irq>\n\n\tint_pln_enable\t[X86] Enable power limit notification interrupt\n\n\tintegrity_audit=[IMA]\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 -- basic integrity auditing messages. (Default)\n\t\t\t1 -- additional integrity auditing messages.\n\n\tintel_iommu=\t[DMAR] Intel IOMMU driver (DMAR) option\n\t\ton\n\t\t\tEnable intel iommu driver.\n\t\toff\n\t\t\tDisable intel iommu driver.\n\t\tigfx_off [Default Off]\n\t\t\tBy default, gfx is mapped as normal device. If a gfx\n\t\t\tdevice has a dedicated DMAR unit, the DMAR unit is\n\t\t\tbypassed by not enabling DMAR with this option. In\n\t\t\tthis case, gfx device will use physical address for\n\t\t\tDMA.\n\t\tforcedac [X86-64]\n\t\t\tWith this option iommu will not optimize to look\n\t\t\tfor io virtual address below 32-bit forcing dual\n\t\t\taddress cycle on pci bus for cards supporting greater\n\t\t\tthan 32-bit addressing. The default is to look\n\t\t\tfor translation below 32-bit and if not available\n\t\t\tthen look in the higher range.\n\t\tstrict [Default Off]\n\t\t\tWith this option on every unmap_single operation will\n\t\t\tresult in a hardware IOTLB flush operation as opposed\n\t\t\tto batching them for performance.\n\t\tsp_off [Default Off]\n\t\t\tBy default, super page will be supported if Intel IOMMU\n\t\t\thas the capability. With this option, super page will\n\t\t\tnot be supported.\n\t\tsm_on [Default Off]\n\t\t\tBy default, scalable mode will be disabled even if the\n\t\t\thardware advertises that it has support for the scalable\n\t\t\tmode translation. With this option set, scalable mode\n\t\t\twill be used on hardware which claims to support it.\n\t\ttboot_noforce [Default Off]\n\t\t\tDo not force the Intel IOMMU enabled under tboot.\n\t\t\tBy default, tboot will force Intel IOMMU on, which\n\t\t\tcould harm performance of some high-throughput\n\t\t\tdevices like 40GBit network cards, even if identity\n\t\t\tmapping is enabled.\n\t\t\tNote that using this option lowers the security\n\t\t\tprovided by tboot because it makes the system\n\t\t\tvulnerable to DMA attacks.\n\t\tnobounce [Default off]\n\t\t\tDisable bounce buffer for untrusted devices such as\n\t\t\tthe Thunderbolt devices. This will treat the untrusted\n\t\t\tdevices as the trusted ones, hence might expose security\n\t\t\trisks of DMA attacks.\n\n\tintel_idle.max_cstate=\t[KNL,HW,ACPI,X86]\n\t\t\t0\tdisables intel_idle and fall back on acpi_idle.\n\t\t\t1 to 9\tspecify maximum depth of C-state.\n\n\tintel_pstate=\t[X86]\n\t\t\tdisable\n\t\t\t  Do not enable intel_pstate as the default\n\t\t\t  scaling driver for the supported processors\n\t\t\tpassive\n\t\t\t  Use intel_pstate as a scaling driver, but configure it\n\t\t\t  to work with generic cpufreq governors (instead of\n\t\t\t  enabling its internal governor).  This mode cannot be\n\t\t\t  used along with the hardware-managed P-states (HWP)\n\t\t\t  feature.\n\t\t\tforce\n\t\t\t  Enable intel_pstate on systems that prohibit it by default\n\t\t\t  in favor of acpi-cpufreq. Forcing the intel_pstate driver\n\t\t\t  instead of acpi-cpufreq may disable platform features, such\n\t\t\t  as thermal controls and power capping, that rely on ACPI\n\t\t\t  P-States information being indicated to OSPM and therefore\n\t\t\t  should be used with caution. This option does not work with\n\t\t\t  processors that aren't supported by the intel_pstate driver\n\t\t\t  or on platforms that use pcc-cpufreq instead of acpi-cpufreq.\n\t\t\tno_hwp\n\t\t\t  Do not enable hardware P state control (HWP)\n\t\t\t  if available.\n\t\t\thwp_only\n\t\t\t  Only load intel_pstate on systems which support\n\t\t\t  hardware P state control (HWP) if available.\n\t\t\tsupport_acpi_ppc\n\t\t\t  Enforce ACPI _PPC performance limits. If the Fixed ACPI\n\t\t\t  Description Table, specifies preferred power management\n\t\t\t  profile as \"Enterprise Server\" or \"Performance Server\",\n\t\t\t  then this feature is turned on by default.\n\t\t\tper_cpu_perf_limits\n\t\t\t  Allow per-logical-CPU P-State performance control limits using\n\t\t\t  cpufreq sysfs interface\n\n\tintremap=\t[X86-64, Intel-IOMMU]\n\t\t\ton\tenable Interrupt Remapping (default)\n\t\t\toff\tdisable Interrupt Remapping\n\t\t\tnosid\tdisable Source ID checking\n\t\t\tno_x2apic_optout\n\t\t\t\tBIOS x2APIC opt-out request will be ignored\n\t\t\tnopost\tdisable Interrupt Posting\n\n\tiomem=\t\tDisable strict checking of access to MMIO memory\n\t\tstrict\tregions from userspace.\n\t\trelaxed\n\n\tiommu=\t\t[X86]\n\t\toff\n\t\tforce\n\t\tnoforce\n\t\tbiomerge\n\t\tpanic\n\t\tnopanic\n\t\tmerge\n\t\tnomerge\n\t\tsoft\n\t\tpt\t\t[X86]\n\t\tnopt\t\t[X86]\n\t\tnobypass\t[PPC/POWERNV]\n\t\t\tDisable IOMMU bypass, using IOMMU for PCI devices.\n\n\tiommu.strict=\t[ARM64] Configure TLB invalidation behaviour\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 - Lazy mode.\n\t\t\t  Request that DMA unmap operations use deferred\n\t\t\t  invalidation of hardware TLBs, for increased\n\t\t\t  throughput at the cost of reduced device isolation.\n\t\t\t  Will fall back to strict mode if not supported by\n\t\t\t  the relevant IOMMU driver.\n\t\t\t1 - Strict mode (default).\n\t\t\t  DMA unmap operations invalidate IOMMU hardware TLBs\n\t\t\t  synchronously.\n\n\tiommu.passthrough=\n\t\t\t[ARM64, X86] Configure DMA to bypass the IOMMU by default.\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 - Use IOMMU translation for DMA.\n\t\t\t1 - Bypass the IOMMU for DMA.\n\t\t\tunset - Use value of CONFIG_IOMMU_DEFAULT_PASSTHROUGH.\n\n\tio7=\t\t[HW] IO7 for Marvel based alpha systems\n\t\t\tSee comment before marvel_specify_io7 in\n\t\t\tarch/alpha/kernel/core_marvel.c.\n\n\tio_delay=\t[X86] I/O delay method\n\t\t0x80\n\t\t\tStandard port 0x80 based delay\n\t\t0xed\n\t\t\tAlternate port 0xed based delay (needed on some systems)\n\t\tudelay\n\t\t\tSimple two microseconds delay\n\t\tnone\n\t\t\tNo delay\n\n\tip=\t\t[IP_PNP]\n\t\t\tSee Documentation/admin-guide/nfs/nfsroot.rst.\n\n\tipcmni_extend\t[KNL] Extend the maximum number of unique System V\n\t\t\tIPC identifiers from 32,768 to 16,777,216.\n\n\tirqaffinity=\t[SMP] Set the default irq affinity mask\n\t\t\tThe argument is a cpu list, as described above.\n\n\tirqchip.gicv2_force_probe=\n\t\t\t[ARM, ARM64]\n\t\t\tFormat: <bool>\n\t\t\tForce the kernel to look for the second 4kB page\n\t\t\tof a GICv2 controller even if the memory range\n\t\t\texposed by the device tree is too small.\n\n\tirqchip.gicv3_nolpi=\n\t\t\t[ARM, ARM64]\n\t\t\tForce the kernel to ignore the availability of\n\t\t\tLPIs (and by consequence ITSs). Intended for system\n\t\t\tthat use the kernel as a bootloader, and thus want\n\t\t\tto let secondary kernels in charge of setting up\n\t\t\tLPIs.\n\n\tirqchip.gicv3_pseudo_nmi= [ARM64]\n\t\t\tEnables support for pseudo-NMIs in the kernel. This\n\t\t\trequires the kernel to be built with\n\t\t\tCONFIG_ARM64_PSEUDO_NMI.\n\n\tirqfixup\t[HW]\n\t\t\tWhen an interrupt is not handled search all handlers\n\t\t\tfor it. Intended to get systems with badly broken\n\t\t\tfirmware running.\n\n\tirqpoll\t\t[HW]\n\t\t\tWhen an interrupt is not handled search all handlers\n\t\t\tfor it. Also check all handlers each timer\n\t\t\tinterrupt. Intended to get systems with badly broken\n\t\t\tfirmware running.\n\n\tisapnp=\t\t[ISAPNP]\n\t\t\tFormat: <RDP>,<reset>,<pci_scan>,<verbosity>\n\n\tisolcpus=\t[KNL,SMP,ISOL] Isolate a given set of CPUs from disturbance.\n\t\t\t[Deprecated - use cpusets instead]\n\t\t\tFormat: [flag-list,]<cpu-list>\n\n\t\t\tSpecify one or more CPUs to isolate from disturbances\n\t\t\tspecified in the flag list (default: domain):\n\n\t\t\tnohz\n\t\t\t  Disable the tick when a single task runs.\n\n\t\t\t  A residual 1Hz tick is offloaded to workqueues, which you\n\t\t\t  need to affine to housekeeping through the global\n\t\t\t  workqueue's affinity configured via the\n\t\t\t  /sys/devices/virtual/workqueue/cpumask sysfs file, or\n\t\t\t  by using the 'domain' flag described below.\n\n\t\t\t  NOTE: by default the global workqueue runs on all CPUs,\n\t\t\t  so to protect individual CPUs the 'cpumask' file has to\n\t\t\t  be configured manually after bootup.\n\n\t\t\tdomain\n\t\t\t  Isolate from the general SMP balancing and scheduling\n\t\t\t  algorithms. Note that performing domain isolation this way\n\t\t\t  is irreversible: it's not possible to bring back a CPU to\n\t\t\t  the domains once isolated through isolcpus. It's strongly\n\t\t\t  advised to use cpusets instead to disable scheduler load\n\t\t\t  balancing through the \"cpuset.sched_load_balance\" file.\n\t\t\t  It offers a much more flexible interface where CPUs can\n\t\t\t  move in and out of an isolated set anytime.\n\n\t\t\t  You can move a process onto or off an \"isolated\" CPU via\n\t\t\t  the CPU affinity syscalls or cpuset.\n\t\t\t  <cpu number> begins at 0 and the maximum value is\n\t\t\t  \"number of CPUs in system - 1\".\n\n\t\t\tmanaged_irq\n\n\t\t\t  Isolate from being targeted by managed interrupts\n\t\t\t  which have an interrupt mask containing isolated\n\t\t\t  CPUs. The affinity of managed interrupts is\n\t\t\t  handled by the kernel and cannot be changed via\n\t\t\t  the /proc/irq/* interfaces.\n\n\t\t\t  This isolation is best effort and only effective\n\t\t\t  if the automatically assigned interrupt mask of a\n\t\t\t  device queue contains isolated and housekeeping\n\t\t\t  CPUs. If housekeeping CPUs are online then such\n\t\t\t  interrupts are directed to the housekeeping CPU\n\t\t\t  so that IO submitted on the housekeeping CPU\n\t\t\t  cannot disturb the isolated CPU.\n\n\t\t\t  If a queue's affinity mask contains only isolated\n\t\t\t  CPUs then this parameter has no effect on the\n\t\t\t  interrupt routing decision, though interrupts are\n\t\t\t  only delivered when tasks running on those\n\t\t\t  isolated CPUs submit IO. IO submitted on\n\t\t\t  housekeeping CPUs has no influence on those\n\t\t\t  queues.\n\n\t\t\tThe format of <cpu-list> is described above.\n\n\tiucv=\t\t[HW,NET]\n\n\tivrs_ioapic\t[HW,X86-64]\n\t\t\tProvide an override to the IOAPIC-ID<->DEVICE-ID\n\t\t\tmapping provided in the IVRS ACPI table. For\n\t\t\texample, to map IOAPIC-ID decimal 10 to\n\t\t\tPCI device 00:14.0 write the parameter as:\n\t\t\t\tivrs_ioapic[10]=00:14.0\n\n\tivrs_hpet\t[HW,X86-64]\n\t\t\tProvide an override to the HPET-ID<->DEVICE-ID\n\t\t\tmapping provided in the IVRS ACPI table. For\n\t\t\texample, to map HPET-ID decimal 0 to\n\t\t\tPCI device 00:14.0 write the parameter as:\n\t\t\t\tivrs_hpet[0]=00:14.0\n\n\tivrs_acpihid\t[HW,X86-64]\n\t\t\tProvide an override to the ACPI-HID:UID<->DEVICE-ID\n\t\t\tmapping provided in the IVRS ACPI table. For\n\t\t\texample, to map UART-HID:UID AMD0020:0 to\n\t\t\tPCI device 00:14.5 write the parameter as:\n\t\t\t\tivrs_acpihid[00:14.5]=AMD0020:0\n\n\tjs=\t\t[HW,JOY] Analog joystick\n\t\t\tSee Documentation/input/joydev/joystick.rst.\n\n\tnokaslr\t\t[KNL]\n\t\t\tWhen CONFIG_RANDOMIZE_BASE is set, this disables\n\t\t\tkernel and module base offset ASLR (Address Space\n\t\t\tLayout Randomization).\n\n\tkasan_multi_shot\n\t\t\t[KNL] Enforce KASAN (Kernel Address Sanitizer) to print\n\t\t\treport on every invalid memory access. Without this\n\t\t\tparameter KASAN will print report only for the first\n\t\t\tinvalid access.\n\n\tkeepinitrd\t[HW,ARM]\n\n\tkernelcore=\t[KNL,X86,IA-64,PPC]\n\t\t\tFormat: nn[KMGTPE] | nn% | \"mirror\"\n\t\t\tThis parameter specifies the amount of memory usable by\n\t\t\tthe kernel for non-movable allocations.  The requested\n\t\t\tamount is spread evenly throughout all nodes in the\n\t\t\tsystem as ZONE_NORMAL.  The remaining memory is used for\n\t\t\tmovable memory in its own zone, ZONE_MOVABLE.  In the\n\t\t\tevent, a node is too small to have both ZONE_NORMAL and\n\t\t\tZONE_MOVABLE, kernelcore memory will take priority and\n\t\t\tother nodes will have a larger ZONE_MOVABLE.\n\n\t\t\tZONE_MOVABLE is used for the allocation of pages that\n\t\t\tmay be reclaimed or moved by the page migration\n\t\t\tsubsystem.  Note that allocations like PTEs-from-HighMem\n\t\t\tstill use the HighMem zone if it exists, and the Normal\n\t\t\tzone if it does not.\n\n\t\t\tIt is possible to specify the exact amount of memory in\n\t\t\tthe form of \"nn[KMGTPE]\", a percentage of total system\n\t\t\tmemory in the form of \"nn%\", or \"mirror\".  If \"mirror\"\n\t\t\toption is specified, mirrored (reliable) memory is used\n\t\t\tfor non-movable allocations and remaining memory is used\n\t\t\tfor Movable pages.  \"nn[KMGTPE]\", \"nn%\", and \"mirror\"\n\t\t\tare exclusive, so you cannot specify multiple forms.\n\n\tkgdbdbgp=\t[KGDB,HW] kgdb over EHCI usb debug port.\n\t\t\tFormat: <Controller#>[,poll interval]\n\t\t\tThe controller # is the number of the ehci usb debug\n\t\t\tport as it is probed via PCI.  The poll interval is\n\t\t\toptional and is the number seconds in between\n\t\t\teach poll cycle to the debug port in case you need\n\t\t\tthe functionality for interrupting the kernel with\n\t\t\tgdb or control-c on the dbgp connection.  When\n\t\t\tnot using this parameter you use sysrq-g to break into\n\t\t\tthe kernel debugger.\n\n\tkgdboc=\t\t[KGDB,HW] kgdb over consoles.\n\t\t\tRequires a tty driver that supports console polling,\n\t\t\tor a supported polling keyboard driver (non-usb).\n\t\t\t Serial only format: <serial_device>[,baud]\n\t\t\t keyboard only format: kbd\n\t\t\t keyboard and serial format: kbd,<serial_device>[,baud]\n\t\t\tOptional Kernel mode setting:\n\t\t\t kms, kbd format: kms,kbd\n\t\t\t kms, kbd and serial format: kms,kbd,<ser_dev>[,baud]\n\n\tkgdboc_earlycon=\t[KGDB,HW]\n\t\t\tIf the boot console provides the ability to read\n\t\t\tcharacters and can work in polling mode, you can use\n\t\t\tthis parameter to tell kgdb to use it as a backend\n\t\t\tuntil the normal console is registered. Intended to\n\t\t\tbe used together with the kgdboc parameter which\n\t\t\tspecifies the normal console to transition to.\n\n\t\t\tThe name of the early console should be specified\n\t\t\tas the value of this parameter. Note that the name of\n\t\t\tthe early console might be different than the tty\n\t\t\tname passed to kgdboc. It's OK to leave the value\n\t\t\tblank and the first boot console that implements\n\t\t\tread() will be picked.\n\n\tkgdbwait\t[KGDB] Stop kernel execution and enter the\n\t\t\tkernel debugger at the earliest opportunity.\n\n\tkmac=\t\t[MIPS] korina ethernet MAC address.\n\t\t\tConfigure the RouterBoard 532 series on-chip\n\t\t\tEthernet adapter MAC address.\n\n\tkmemleak=\t[KNL] Boot-time kmemleak enable/disable\n\t\t\tValid arguments: on, off\n\t\t\tDefault: on\n\t\t\tBuilt with CONFIG_DEBUG_KMEMLEAK_DEFAULT_OFF=y,\n\t\t\tthe default is off.\n\n\tkprobe_event=[probe-list]\n\t\t\t[FTRACE] Add kprobe events and enable at boot time.\n\t\t\tThe probe-list is a semicolon delimited list of probe\n\t\t\tdefinitions. Each definition is same as kprobe_events\n\t\t\tinterface, but the parameters are comma delimited.\n\t\t\tFor example, to add a kprobe event on vfs_read with\n\t\t\targ1 and arg2, add to the command line;\n\n\t\t\t      kprobe_event=p,vfs_read,$arg1,$arg2\n\n\t\t\tSee also Documentation/trace/kprobetrace.rst \"Kernel\n\t\t\tBoot Parameter\" section.\n\n\tkpti=\t\t[ARM64] Control page table isolation of user\n\t\t\tand kernel address spaces.\n\t\t\tDefault: enabled on cores which need mitigation.\n\t\t\t0: force disabled\n\t\t\t1: force enabled\n\n\tkvm.ignore_msrs=[KVM] Ignore guest accesses to unhandled MSRs.\n\t\t\tDefault is 0 (don't ignore, but inject #GP)\n\n\tkvm.enable_vmware_backdoor=[KVM] Support VMware backdoor PV interface.\n\t\t\t\t   Default is false (don't support).\n\n\tkvm.mmu_audit=\t[KVM] This is a R/W parameter which allows audit\n\t\t\tKVM MMU at runtime.\n\t\t\tDefault is 0 (off)\n\n\tkvm.nx_huge_pages=\n\t\t\t[KVM] Controls the software workaround for the\n\t\t\tX86_BUG_ITLB_MULTIHIT bug.\n\t\t\tforce\t: Always deploy workaround.\n\t\t\toff\t: Never deploy workaround.\n\t\t\tauto    : Deploy workaround based on the presence of\n\t\t\t\t  X86_BUG_ITLB_MULTIHIT.\n\n\t\t\tDefault is 'auto'.\n\n\t\t\tIf the software workaround is enabled for the host,\n\t\t\tguests do need not to enable it for nested guests.\n\n\tkvm.nx_huge_pages_recovery_ratio=\n\t\t\t[KVM] Controls how many 4KiB pages are periodically zapped\n\t\t\tback to huge pages.  0 disables the recovery, otherwise if\n\t\t\tthe value is N KVM will zap 1/Nth of the 4KiB pages every\n\t\t\tminute.  The default is 60.\n\n\tkvm-amd.nested=\t[KVM,AMD] Allow nested virtualization in KVM/SVM.\n\t\t\tDefault is 1 (enabled)\n\n\tkvm-amd.npt=\t[KVM,AMD] Disable nested paging (virtualized MMU)\n\t\t\tfor all guests.\n\t\t\tDefault is 1 (enabled) if in 64-bit or 32-bit PAE mode.\n\n\tkvm-arm.vgic_v3_group0_trap=\n\t\t\t[KVM,ARM] Trap guest accesses to GICv3 group-0\n\t\t\tsystem registers\n\n\tkvm-arm.vgic_v3_group1_trap=\n\t\t\t[KVM,ARM] Trap guest accesses to GICv3 group-1\n\t\t\tsystem registers\n\n\tkvm-arm.vgic_v3_common_trap=\n\t\t\t[KVM,ARM] Trap guest accesses to GICv3 common\n\t\t\tsystem registers\n\n\tkvm-arm.vgic_v4_enable=\n\t\t\t[KVM,ARM] Allow use of GICv4 for direct injection of\n\t\t\tLPIs.\n\n\tkvm-intel.ept=\t[KVM,Intel] Disable extended page tables\n\t\t\t(virtualized MMU) support on capable Intel chips.\n\t\t\tDefault is 1 (enabled)\n\n\tkvm-intel.emulate_invalid_guest_state=\n\t\t\t[KVM,Intel] Enable emulation of invalid guest states\n\t\t\tDefault is 0 (disabled)\n\n\tkvm-intel.flexpriority=\n\t\t\t[KVM,Intel] Disable FlexPriority feature (TPR shadow).\n\t\t\tDefault is 1 (enabled)\n\n\tkvm-intel.nested=\n\t\t\t[KVM,Intel] Enable VMX nesting (nVMX).\n\t\t\tDefault is 0 (disabled)\n\n\tkvm-intel.unrestricted_guest=\n\t\t\t[KVM,Intel] Disable unrestricted guest feature\n\t\t\t(virtualized real and unpaged mode) on capable\n\t\t\tIntel chips. Default is 1 (enabled)\n\n\tkvm-intel.vmentry_l1d_flush=[KVM,Intel] Mitigation for L1 Terminal Fault\n\t\t\tCVE-2018-3620.\n\n\t\t\tValid arguments: never, cond, always\n\n\t\t\talways: L1D cache flush on every VMENTER.\n\t\t\tcond:\tFlush L1D on VMENTER only when the code between\n\t\t\t\tVMEXIT and VMENTER can leak host memory.\n\t\t\tnever:\tDisables the mitigation\n\n\t\t\tDefault is cond (do L1 cache flush in specific instances)\n\n\tkvm-intel.vpid=\t[KVM,Intel] Disable Virtual Processor Identification\n\t\t\tfeature (tagged TLBs) on capable Intel chips.\n\t\t\tDefault is 1 (enabled)\n\n\tl1tf=           [X86] Control mitigation of the L1TF vulnerability on\n\t\t\t      affected CPUs\n\n\t\t\tThe kernel PTE inversion protection is unconditionally\n\t\t\tenabled and cannot be disabled.\n\n\t\t\tfull\n\t\t\t\tProvides all available mitigations for the\n\t\t\t\tL1TF vulnerability. Disables SMT and\n\t\t\t\tenables all mitigations in the\n\t\t\t\thypervisors, i.e. unconditional L1D flush.\n\n\t\t\t\tSMT control and L1D flush control via the\n\t\t\t\tsysfs interface is still possible after\n\t\t\t\tboot.  Hypervisors will issue a warning\n\t\t\t\twhen the first VM is started in a\n\t\t\t\tpotentially insecure configuration,\n\t\t\t\ti.e. SMT enabled or L1D flush disabled.\n\n\t\t\tfull,force\n\t\t\t\tSame as 'full', but disables SMT and L1D\n\t\t\t\tflush runtime control. Implies the\n\t\t\t\t'nosmt=force' command line option.\n\t\t\t\t(i.e. sysfs control of SMT is disabled.)\n\n\t\t\tflush\n\t\t\t\tLeaves SMT enabled and enables the default\n\t\t\t\thypervisor mitigation, i.e. conditional\n\t\t\t\tL1D flush.\n\n\t\t\t\tSMT control and L1D flush control via the\n\t\t\t\tsysfs interface is still possible after\n\t\t\t\tboot.  Hypervisors will issue a warning\n\t\t\t\twhen the first VM is started in a\n\t\t\t\tpotentially insecure configuration,\n\t\t\t\ti.e. SMT enabled or L1D flush disabled.\n\n\t\t\tflush,nosmt\n\n\t\t\t\tDisables SMT and enables the default\n\t\t\t\thypervisor mitigation.\n\n\t\t\t\tSMT control and L1D flush control via the\n\t\t\t\tsysfs interface is still possible after\n\t\t\t\tboot.  Hypervisors will issue a warning\n\t\t\t\twhen the first VM is started in a\n\t\t\t\tpotentially insecure configuration,\n\t\t\t\ti.e. SMT enabled or L1D flush disabled.\n\n\t\t\tflush,nowarn\n\t\t\t\tSame as 'flush', but hypervisors will not\n\t\t\t\twarn when a VM is started in a potentially\n\t\t\t\tinsecure configuration.\n\n\t\t\toff\n\t\t\t\tDisables hypervisor mitigations and doesn't\n\t\t\t\temit any warnings.\n\t\t\t\tIt also drops the swap size and available\n\t\t\t\tRAM limit restriction on both hypervisor and\n\t\t\t\tbare metal.\n\n\t\t\tDefault is 'flush'.\n\n\t\t\tFor details see: Documentation/admin-guide/hw-vuln/l1tf.rst\n\n\tl2cr=\t\t[PPC]\n\n\tl3cr=\t\t[PPC]\n\n\tlapic\t\t[X86-32,APIC] Enable the local APIC even if BIOS\n\t\t\tdisabled it.\n\n\tlapic=\t\t[X86,APIC] \"notscdeadline\" Do not use TSC deadline\n\t\t\tvalue for LAPIC timer one-shot implementation. Default\n\t\t\tback to the programmable timer unit in the LAPIC.\n\n\tlapic_timer_c2_ok\t[X86,APIC] trust the local apic timer\n\t\t\tin C2 power state.\n\n\tlibata.dma=\t[LIBATA] DMA control\n\t\t\tlibata.dma=0\t  Disable all PATA and SATA DMA\n\t\t\tlibata.dma=1\t  PATA and SATA Disk DMA only\n\t\t\tlibata.dma=2\t  ATAPI (CDROM) DMA only\n\t\t\tlibata.dma=4\t  Compact Flash DMA only\n\t\t\tCombinations also work, so libata.dma=3 enables DMA\n\t\t\tfor disks and CDROMs, but not CFs.\n\n\tlibata.ignore_hpa=\t[LIBATA] Ignore HPA limit\n\t\t\tlibata.ignore_hpa=0\t  keep BIOS limits (default)\n\t\t\tlibata.ignore_hpa=1\t  ignore limits, using full disk\n\n\tlibata.noacpi\t[LIBATA] Disables use of ACPI in libata suspend/resume\n\t\t\twhen set.\n\t\t\tFormat: <int>\n\n\tlibata.force=\t[LIBATA] Force configurations.  The format is comma\n\t\t\tseparated list of \"[ID:]VAL\" where ID is\n\t\t\tPORT[.DEVICE].  PORT and DEVICE are decimal numbers\n\t\t\tmatching port, link or device.  Basically, it matches\n\t\t\tthe ATA ID string printed on console by libata.  If\n\t\t\tthe whole ID part is omitted, the last PORT and DEVICE\n\t\t\tvalues are used.  If ID hasn't been specified yet, the\n\t\t\tconfiguration applies to all ports, links and devices.\n\n\t\t\tIf only DEVICE is omitted, the parameter applies to\n\t\t\tthe port and all links and devices behind it.  DEVICE\n\t\t\tnumber of 0 either selects the first device or the\n\t\t\tfirst fan-out link behind PMP device.  It does not\n\t\t\tselect the host link.  DEVICE number of 15 selects the\n\t\t\thost link and device attached to it.\n\n\t\t\tThe VAL specifies the configuration to force.  As long\n\t\t\tas there's no ambiguity shortcut notation is allowed.\n\t\t\tFor example, both 1.5 and 1.5G would work for 1.5Gbps.\n\t\t\tThe following configurations can be forced.\n\n\t\t\t* Cable type: 40c, 80c, short40c, unk, ign or sata.\n\t\t\t  Any ID with matching PORT is used.\n\n\t\t\t* SATA link speed limit: 1.5Gbps or 3.0Gbps.\n\n\t\t\t* Transfer mode: pio[0-7], mwdma[0-4] and udma[0-7].\n\t\t\t  udma[/][16,25,33,44,66,100,133] notation is also\n\t\t\t  allowed.\n\n\t\t\t* [no]ncq: Turn on or off NCQ.\n\n\t\t\t* [no]ncqtrim: Turn off queued DSM TRIM.\n\n\t\t\t* nohrst, nosrst, norst: suppress hard, soft\n\t\t\t  and both resets.\n\n\t\t\t* rstonce: only attempt one reset during\n\t\t\t  hot-unplug link recovery\n\n\t\t\t* dump_id: dump IDENTIFY data.\n\n\t\t\t* atapi_dmadir: Enable ATAPI DMADIR bridge support\n\n\t\t\t* disable: Disable this device.\n\n\t\t\tIf there are multiple matching configurations changing\n\t\t\tthe same attribute, the last one is used.\n\n\tmemblock=debug\t[KNL] Enable memblock debug messages.\n\n\tload_ramdisk=\t[RAM] List of ramdisks to load from floppy\n\t\t\tSee Documentation/admin-guide/blockdev/ramdisk.rst.\n\n\tlockd.nlm_grace_period=P  [NFS] Assign grace period.\n\t\t\tFormat: <integer>\n\n\tlockd.nlm_tcpport=N\t[NFS] Assign TCP port.\n\t\t\tFormat: <integer>\n\n\tlockd.nlm_timeout=T\t[NFS] Assign timeout value.\n\t\t\tFormat: <integer>\n\n\tlockd.nlm_udpport=M\t[NFS] Assign UDP port.\n\t\t\tFormat: <integer>\n\n\tlockdown=\t[SECURITY]\n\t\t\t{ integrity | confidentiality }\n\t\t\tEnable the kernel lockdown feature. If set to\n\t\t\tintegrity, kernel features that allow userland to\n\t\t\tmodify the running kernel are disabled. If set to\n\t\t\tconfidentiality, kernel features that allow userland\n\t\t\tto extract confidential information from the kernel\n\t\t\tare also disabled.\n\n\tlocktorture.nreaders_stress= [KNL]\n\t\t\tSet the number of locking read-acquisition kthreads.\n\t\t\tDefaults to being automatically set based on the\n\t\t\tnumber of online CPUs.\n\n\tlocktorture.nwriters_stress= [KNL]\n\t\t\tSet the number of locking write-acquisition kthreads.\n\n\tlocktorture.onoff_holdoff= [KNL]\n\t\t\tSet time (s) after boot for CPU-hotplug testing.\n\n\tlocktorture.onoff_interval= [KNL]\n\t\t\tSet time (s) between CPU-hotplug operations, or\n\t\t\tzero to disable CPU-hotplug testing.\n\n\tlocktorture.shuffle_interval= [KNL]\n\t\t\tSet task-shuffle interval (jiffies).  Shuffling\n\t\t\ttasks allows some CPUs to go into dyntick-idle\n\t\t\tmode during the locktorture test.\n\n\tlocktorture.shutdown_secs= [KNL]\n\t\t\tSet time (s) after boot system shutdown.  This\n\t\t\tis useful for hands-off automated testing.\n\n\tlocktorture.stat_interval= [KNL]\n\t\t\tTime (s) between statistics printk()s.\n\n\tlocktorture.stutter= [KNL]\n\t\t\tTime (s) to stutter testing, for example,\n\t\t\tspecifying five seconds causes the test to run for\n\t\t\tfive seconds, wait for five seconds, and so on.\n\t\t\tThis tests the locking primitive's ability to\n\t\t\ttransition abruptly to and from idle.\n\n\tlocktorture.torture_type= [KNL]\n\t\t\tSpecify the locking implementation to test.\n\n\tlocktorture.verbose= [KNL]\n\t\t\tEnable additional printk() statements.\n\n\tlogibm.irq=\t[HW,MOUSE] Logitech Bus Mouse Driver\n\t\t\tFormat: <irq>\n\n\tloglevel=\tAll Kernel Messages with a loglevel smaller than the\n\t\t\tconsole loglevel will be printed to the console. It can\n\t\t\talso be changed with klogd or other programs. The\n\t\t\tloglevels are defined as follows:\n\n\t\t\t0 (KERN_EMERG)\t\tsystem is unusable\n\t\t\t1 (KERN_ALERT)\t\taction must be taken immediately\n\t\t\t2 (KERN_CRIT)\t\tcritical conditions\n\t\t\t3 (KERN_ERR)\t\terror conditions\n\t\t\t4 (KERN_WARNING)\twarning conditions\n\t\t\t5 (KERN_NOTICE)\t\tnormal but significant condition\n\t\t\t6 (KERN_INFO)\t\tinformational\n\t\t\t7 (KERN_DEBUG)\t\tdebug-level messages\n\n\tlog_buf_len=n[KMG]\tSets the size of the printk ring buffer,\n\t\t\tin bytes.  n must be a power of two and greater\n\t\t\tthan the minimal size. The minimal size is defined\n\t\t\tby LOG_BUF_SHIFT kernel config parameter. There is\n\t\t\talso CONFIG_LOG_CPU_MAX_BUF_SHIFT config parameter\n\t\t\tthat allows to increase the default size depending on\n\t\t\tthe number of CPUs. See init/Kconfig for more details.\n\n\tlogo.nologo\t[FB] Disables display of the built-in Linux logo.\n\t\t\tThis may be used to provide more screen space for\n\t\t\tkernel log messages and is useful when debugging\n\t\t\tkernel boot problems.\n\n\tlp=0\t\t[LP]\tSpecify parallel ports to use, e.g,\n\tlp=port[,port...]\tlp=none,parport0 (lp0 not configured, lp1 uses\n\tlp=reset\t\tfirst parallel port). 'lp=0' disables the\n\tlp=auto\t\t\tprinter driver. 'lp=reset' (which can be\n\t\t\t\tspecified in addition to the ports) causes\n\t\t\t\tattached printers to be reset. Using\n\t\t\t\tlp=port1,port2,... specifies the parallel ports\n\t\t\t\tto associate lp devices with, starting with\n\t\t\t\tlp0. A port specification may be 'none' to skip\n\t\t\t\tthat lp device, or a parport name such as\n\t\t\t\t'parport0'. Specifying 'lp=auto' instead of a\n\t\t\t\tport specification list means that device IDs\n\t\t\t\tfrom each port should be examined, to see if\n\t\t\t\tan IEEE 1284-compliant printer is attached; if\n\t\t\t\tso, the driver will manage that printer.\n\t\t\t\tSee also header of drivers/char/lp.c.\n\n\tlpj=n\t\t[KNL]\n\t\t\tSets loops_per_jiffy to given constant, thus avoiding\n\t\t\ttime-consuming boot-time autodetection (up to 250 ms per\n\t\t\tCPU). 0 enables autodetection (default). To determine\n\t\t\tthe correct value for your kernel, boot with normal\n\t\t\tautodetection and see what value is printed. Note that\n\t\t\ton SMP systems the preset will be applied to all CPUs,\n\t\t\twhich is likely to cause problems if your CPUs need\n\t\t\tsignificantly divergent settings. An incorrect value\n\t\t\twill cause delays in the kernel to be wrong, leading to\n\t\t\tunpredictable I/O errors and other breakage. Although\n\t\t\tunlikely, in the extreme case this might damage your\n\t\t\thardware.\n\n\tltpc=\t\t[NET]\n\t\t\tFormat: <io>,<irq>,<dma>\n\n\tlsm.debug\t[SECURITY] Enable LSM initialization debugging output.\n\n\tlsm=lsm1,...,lsmN\n\t\t\t[SECURITY] Choose order of LSM initialization. This\n\t\t\toverrides CONFIG_LSM, and the \"security=\" parameter.\n\n\tmachvec=\t[IA-64] Force the use of a particular machine-vector\n\t\t\t(machvec) in a generic kernel.\n\t\t\tExample: machvec=hpzx1\n\n\tmachtype=\t[Loongson] Share the same kernel image file between different\n\t\t\t yeeloong laptop.\n\t\t\tExample: machtype=lemote-yeeloong-2f-7inch\n\n\tmax_addr=nn[KMG]\t[KNL,BOOT,ia64] All physical memory greater\n\t\t\tthan or equal to this physical address is ignored.\n\n\tmaxcpus=\t[SMP] Maximum number of processors that\tan SMP kernel\n\t\t\twill bring up during bootup.  maxcpus=n : n >= 0 limits\n\t\t\tthe kernel to bring up 'n' processors. Surely after\n\t\t\tbootup you can bring up the other plugged cpu by executing\n\t\t\t\"echo 1 > /sys/devices/system/cpu/cpuX/online\". So maxcpus\n\t\t\tonly takes effect during system bootup.\n\t\t\tWhile n=0 is a special case, it is equivalent to \"nosmp\",\n\t\t\twhich also disables the IO APIC.\n\n\tmax_loop=\t[LOOP] The number of loop block devices that get\n\t(loop.max_loop)\tunconditionally pre-created at init time. The default\n\t\t\tnumber is configured by BLK_DEV_LOOP_MIN_COUNT. Instead\n\t\t\tof statically allocating a predefined number, loop\n\t\t\tdevices can be requested on-demand with the\n\t\t\t/dev/loop-control interface.\n\n\tmce\t\t[X86-32] Machine Check Exception\n\n\tmce=option\t[X86-64] See Documentation/x86/x86_64/boot-options.rst\n\n\tmd=\t\t[HW] RAID subsystems devices and level\n\t\t\tSee Documentation/admin-guide/md.rst.\n\n\tmdacon=\t\t[MDA]\n\t\t\tFormat: <first>,<last>\n\t\t\tSpecifies range of consoles to be captured by the MDA.\n\n\tmds=\t\t[X86,INTEL]\n\t\t\tControl mitigation for the Micro-architectural Data\n\t\t\tSampling (MDS) vulnerability.\n\n\t\t\tCertain CPUs are vulnerable to an exploit against CPU\n\t\t\tinternal buffers which can forward information to a\n\t\t\tdisclosure gadget under certain conditions.\n\n\t\t\tIn vulnerable processors, the speculatively\n\t\t\tforwarded data can be used in a cache side channel\n\t\t\tattack, to access data to which the attacker does\n\t\t\tnot have direct access.\n\n\t\t\tThis parameter controls the MDS mitigation. The\n\t\t\toptions are:\n\n\t\t\tfull       - Enable MDS mitigation on vulnerable CPUs\n\t\t\tfull,nosmt - Enable MDS mitigation and disable\n\t\t\t\t     SMT on vulnerable CPUs\n\t\t\toff        - Unconditionally disable MDS mitigation\n\n\t\t\tOn TAA-affected machines, mds=off can be prevented by\n\t\t\tan active TAA mitigation as both vulnerabilities are\n\t\t\tmitigated with the same mechanism so in order to disable\n\t\t\tthis mitigation, you need to specify tsx_async_abort=off\n\t\t\ttoo.\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\tmds=full.\n\n\t\t\tFor details see: Documentation/admin-guide/hw-vuln/mds.rst\n\n\tmem=nn[KMG]\t[KNL,BOOT] Force usage of a specific amount of memory\n\t\t\tAmount of memory to be used in cases as follows:\n\n\t\t\t1 for test;\n\t\t\t2 when the kernel is not able to see the whole system memory;\n\t\t\t3 memory that lies after 'mem=' boundary is excluded from\n\t\t\t the hypervisor, then assigned to KVM guests.\n\n\t\t\t[X86] Work as limiting max address. Use together\n\t\t\twith memmap= to avoid physical address space collisions.\n\t\t\tWithout memmap= PCI devices could be placed at addresses\n\t\t\tbelonging to unused RAM.\n\n\t\t\tNote that this only takes effects during boot time since\n\t\t\tin above case 3, memory may need be hot added after boot\n\t\t\tif system memory of hypervisor is not sufficient.\n\n\tmem=nopentium\t[BUGS=X86-32] Disable usage of 4MB pages for kernel\n\t\t\tmemory.\n\n\tmemchunk=nn[KMG]\n\t\t\t[KNL,SH] Allow user to override the default size for\n\t\t\tper-device physically contiguous DMA buffers.\n\n\tmemhp_default_state=online/offline\n\t\t\t[KNL] Set the initial state for the memory hotplug\n\t\t\tonlining policy. If not specified, the default value is\n\t\t\tset according to the\n\t\t\tCONFIG_MEMORY_HOTPLUG_DEFAULT_ONLINE kernel config\n\t\t\toption.\n\t\t\tSee Documentation/admin-guide/mm/memory-hotplug.rst.\n\n\tmemmap=exactmap\t[KNL,X86] Enable setting of an exact\n\t\t\tE820 memory map, as specified by the user.\n\t\t\tSuch memmap=exactmap lines can be constructed based on\n\t\t\tBIOS output or other requirements. See the memmap=nn@ss\n\t\t\toption description.\n\n\tmemmap=nn[KMG]@ss[KMG]\n\t\t\t[KNL] Force usage of a specific region of memory.\n\t\t\tRegion of memory to be used is from ss to ss+nn.\n\t\t\tIf @ss[KMG] is omitted, it is equivalent to mem=nn[KMG],\n\t\t\twhich limits max address to nn[KMG].\n\t\t\tMultiple different regions can be specified,\n\t\t\tcomma delimited.\n\t\t\tExample:\n\t\t\t\tmemmap=100M@2G,100M#3G,1G!1024G\n\n\tmemmap=nn[KMG]#ss[KMG]\n\t\t\t[KNL,ACPI] Mark specific memory as ACPI data.\n\t\t\tRegion of memory to be marked is from ss to ss+nn.\n\n\tmemmap=nn[KMG]$ss[KMG]\n\t\t\t[KNL,ACPI] Mark specific memory as reserved.\n\t\t\tRegion of memory to be reserved is from ss to ss+nn.\n\t\t\tExample: Exclude memory from 0x18690000-0x1869ffff\n\t\t\t         memmap=64K$0x18690000\n\t\t\t         or\n\t\t\t         memmap=0x10000$0x18690000\n\t\t\tSome bootloaders may need an escape character before '$',\n\t\t\tlike Grub2, otherwise '$' and the following number\n\t\t\twill be eaten.\n\n\tmemmap=nn[KMG]!ss[KMG]\n\t\t\t[KNL,X86] Mark specific memory as protected.\n\t\t\tRegion of memory to be used, from ss to ss+nn.\n\t\t\tThe memory region may be marked as e820 type 12 (0xc)\n\t\t\tand is NVDIMM or ADR memory.\n\n\tmemmap=<size>%<offset>-<oldtype>+<newtype>\n\t\t\t[KNL,ACPI] Convert memory within the specified region\n\t\t\tfrom <oldtype> to <newtype>. If \"-<oldtype>\" is left\n\t\t\tout, the whole region will be marked as <newtype>,\n\t\t\teven if previously unavailable. If \"+<newtype>\" is left\n\t\t\tout, matching memory will be removed. Types are\n\t\t\tspecified as e820 types, e.g., 1 = RAM, 2 = reserved,\n\t\t\t3 = ACPI, 12 = PRAM.\n\n\tmemory_corruption_check=0/1 [X86]\n\t\t\tSome BIOSes seem to corrupt the first 64k of\n\t\t\tmemory when doing things like suspend/resume.\n\t\t\tSetting this option will scan the memory\n\t\t\tlooking for corruption.  Enabling this will\n\t\t\tboth detect corruption and prevent the kernel\n\t\t\tfrom using the memory being corrupted.\n\t\t\tHowever, its intended as a diagnostic tool; if\n\t\t\trepeatable BIOS-originated corruption always\n\t\t\taffects the same memory, you can use memmap=\n\t\t\tto prevent the kernel from using that memory.\n\n\tmemory_corruption_check_size=size [X86]\n\t\t\tBy default it checks for corruption in the low\n\t\t\t64k, making this memory unavailable for normal\n\t\t\tuse.  Use this parameter to scan for\n\t\t\tcorruption in more or less memory.\n\n\tmemory_corruption_check_period=seconds [X86]\n\t\t\tBy default it checks for corruption every 60\n\t\t\tseconds.  Use this parameter to check at some\n\t\t\tother rate.  0 disables periodic checking.\n\n\tmemtest=\t[KNL,X86,ARM,PPC] Enable memtest\n\t\t\tFormat: <integer>\n\t\t\tdefault : 0 <disable>\n\t\t\tSpecifies the number of memtest passes to be\n\t\t\tperformed. Each pass selects another test\n\t\t\tpattern from a given set of patterns. Memtest\n\t\t\tfills the memory with this pattern, validates\n\t\t\tmemory contents and reserves bad memory\n\t\t\tregions that are detected.\n\n\tmem_encrypt=\t[X86-64] AMD Secure Memory Encryption (SME) control\n\t\t\tValid arguments: on, off\n\t\t\tDefault (depends on kernel configuration option):\n\t\t\t  on  (CONFIG_AMD_MEM_ENCRYPT_ACTIVE_BY_DEFAULT=y)\n\t\t\t  off (CONFIG_AMD_MEM_ENCRYPT_ACTIVE_BY_DEFAULT=n)\n\t\t\tmem_encrypt=on:\t\tActivate SME\n\t\t\tmem_encrypt=off:\tDo not activate SME\n\n\t\t\tRefer to Documentation/virt/kvm/amd-memory-encryption.rst\n\t\t\tfor details on when memory encryption can be activated.\n\n\tmem_sleep_default=\t[SUSPEND] Default system suspend mode:\n\t\t\ts2idle  - Suspend-To-Idle\n\t\t\tshallow - Power-On Suspend or equivalent (if supported)\n\t\t\tdeep    - Suspend-To-RAM or equivalent (if supported)\n\t\t\tSee Documentation/admin-guide/pm/sleep-states.rst.\n\n\tmeye.*=\t\t[HW] Set MotionEye Camera parameters\n\t\t\tSee Documentation/admin-guide/media/meye.rst.\n\n\tmfgpt_irq=\t[IA-32] Specify the IRQ to use for the\n\t\t\tMulti-Function General Purpose Timers on AMD Geode\n\t\t\tplatforms.\n\n\tmfgptfix\t[X86-32] Fix MFGPT timers on AMD Geode platforms when\n\t\t\tthe BIOS has incorrectly applied a workaround. TinyBIOS\n\t\t\tversion 0.98 is known to be affected, 0.99 fixes the\n\t\t\tproblem by letting the user disable the workaround.\n\n\tmga=\t\t[HW,DRM]\n\n\tmin_addr=nn[KMG]\t[KNL,BOOT,ia64] All physical memory below this\n\t\t\tphysical address is ignored.\n\n\tmini2440=\t[ARM,HW,KNL]\n\t\t\tFormat:[0..2][b][c][t]\n\t\t\tDefault: \"0tb\"\n\t\t\tMINI2440 configuration specification:\n\t\t\t0 - The attached screen is the 3.5\" TFT\n\t\t\t1 - The attached screen is the 7\" TFT\n\t\t\t2 - The VGA Shield is attached (1024x768)\n\t\t\tLeaving out the screen size parameter will not load\n\t\t\tthe TFT driver, and the framebuffer will be left\n\t\t\tunconfigured.\n\t\t\tb - Enable backlight. The TFT backlight pin will be\n\t\t\tlinked to the kernel VESA blanking code and a GPIO\n\t\t\tLED. This parameter is not necessary when using the\n\t\t\tVGA shield.\n\t\t\tc - Enable the s3c camera interface.\n\t\t\tt - Reserved for enabling touchscreen support. The\n\t\t\ttouchscreen support is not enabled in the mainstream\n\t\t\tkernel as of 2.6.30, a preliminary port can be found\n\t\t\tin the \"bleeding edge\" mini2440 support kernel at\n\t\t\thttps://repo.or.cz/w/linux-2.6/mini2440.git\n\n\tmitigations=\n\t\t\t[X86,PPC,S390,ARM64] Control optional mitigations for\n\t\t\tCPU vulnerabilities.  This is a set of curated,\n\t\t\tarch-independent options, each of which is an\n\t\t\taggregation of existing arch-specific options.\n\n\t\t\toff\n\t\t\t\tDisable all optional CPU mitigations.  This\n\t\t\t\timproves system performance, but it may also\n\t\t\t\texpose users to several CPU vulnerabilities.\n\t\t\t\tEquivalent to: nopti [X86,PPC]\n\t\t\t\t\t       kpti=0 [ARM64]\n\t\t\t\t\t       nospectre_v1 [X86,PPC]\n\t\t\t\t\t       nobp=0 [S390]\n\t\t\t\t\t       nospectre_v2 [X86,PPC,S390,ARM64]\n\t\t\t\t\t       spectre_v2_user=off [X86]\n\t\t\t\t\t       spec_store_bypass_disable=off [X86,PPC]\n\t\t\t\t\t       ssbd=force-off [ARM64]\n\t\t\t\t\t       l1tf=off [X86]\n\t\t\t\t\t       mds=off [X86]\n\t\t\t\t\t       tsx_async_abort=off [X86]\n\t\t\t\t\t       kvm.nx_huge_pages=off [X86]\n\n\t\t\t\tExceptions:\n\t\t\t\t\t       This does not have any effect on\n\t\t\t\t\t       kvm.nx_huge_pages when\n\t\t\t\t\t       kvm.nx_huge_pages=force.\n\n\t\t\tauto (default)\n\t\t\t\tMitigate all CPU vulnerabilities, but leave SMT\n\t\t\t\tenabled, even if it's vulnerable.  This is for\n\t\t\t\tusers who don't want to be surprised by SMT\n\t\t\t\tgetting disabled across kernel upgrades, or who\n\t\t\t\thave other ways of avoiding SMT-based attacks.\n\t\t\t\tEquivalent to: (default behavior)\n\n\t\t\tauto,nosmt\n\t\t\t\tMitigate all CPU vulnerabilities, disabling SMT\n\t\t\t\tif needed.  This is for users who always want to\n\t\t\t\tbe fully mitigated, even if it means losing SMT.\n\t\t\t\tEquivalent to: l1tf=flush,nosmt [X86]\n\t\t\t\t\t       mds=full,nosmt [X86]\n\t\t\t\t\t       tsx_async_abort=full,nosmt [X86]\n\n\tmminit_loglevel=\n\t\t\t[KNL] When CONFIG_DEBUG_MEMORY_INIT is set, this\n\t\t\tparameter allows control of the logging verbosity for\n\t\t\tthe additional memory initialisation checks. A value\n\t\t\tof 0 disables mminit logging and a level of 4 will\n\t\t\tlog everything. Information is printed at KERN_DEBUG\n\t\t\tso loglevel=8 may also need to be specified.\n\n\tmodule.sig_enforce\n\t\t\t[KNL] When CONFIG_MODULE_SIG is set, this means that\n\t\t\tmodules without (valid) signatures will fail to load.\n\t\t\tNote that if CONFIG_MODULE_SIG_FORCE is set, that\n\t\t\tis always true, so this option does nothing.\n\n\tmodule_blacklist=  [KNL] Do not load a comma-separated list of\n\t\t\tmodules.  Useful for debugging problem modules.\n\n\tmousedev.tap_time=\n\t\t\t[MOUSE] Maximum time between finger touching and\n\t\t\tleaving touchpad surface for touch to be considered\n\t\t\ta tap and be reported as a left button click (for\n\t\t\ttouchpads working in absolute mode only).\n\t\t\tFormat: <msecs>\n\tmousedev.xres=\t[MOUSE] Horizontal screen resolution, used for devices\n\t\t\treporting absolute coordinates, such as tablets\n\tmousedev.yres=\t[MOUSE] Vertical screen resolution, used for devices\n\t\t\treporting absolute coordinates, such as tablets\n\n\tmovablecore=\t[KNL,X86,IA-64,PPC]\n\t\t\tFormat: nn[KMGTPE] | nn%\n\t\t\tThis parameter is the complement to kernelcore=, it\n\t\t\tspecifies the amount of memory used for migratable\n\t\t\tallocations.  If both kernelcore and movablecore is\n\t\t\tspecified, then kernelcore will be at *least* the\n\t\t\tspecified value but may be more.  If movablecore on its\n\t\t\town is specified, the administrator must be careful\n\t\t\tthat the amount of memory usable for all allocations\n\t\t\tis not too small.\n\n\tmovable_node\t[KNL] Boot-time switch to make hotplugable memory\n\t\t\tNUMA nodes to be movable. This means that the memory\n\t\t\tof such nodes will be usable only for movable\n\t\t\tallocations which rules out almost all kernel\n\t\t\tallocations. Use with caution!\n\n\tMTD_Partition=\t[MTD]\n\t\t\tFormat: <name>,<region-number>,<size>,<offset>\n\n\tMTD_Region=\t[MTD] Format:\n\t\t\t<name>,<region-number>[,<base>,<size>,<buswidth>,<altbuswidth>]\n\n\tmtdparts=\t[MTD]\n\t\t\tSee drivers/mtd/parsers/cmdlinepart.c\n\n\tmultitce=off\t[PPC]  This parameter disables the use of the pSeries\n\t\t\tfirmware feature for updating multiple TCE entries\n\t\t\tat a time.\n\n\tonenand.bdry=\t[HW,MTD] Flex-OneNAND Boundary Configuration\n\n\t\t\tFormat: [die0_boundary][,die0_lock][,die1_boundary][,die1_lock]\n\n\t\t\tboundary - index of last SLC block on Flex-OneNAND.\n\t\t\t\t   The remaining blocks are configured as MLC blocks.\n\t\t\tlock\t - Configure if Flex-OneNAND boundary should be locked.\n\t\t\t\t   Once locked, the boundary cannot be changed.\n\t\t\t\t   1 indicates lock status, 0 indicates unlock status.\n\n\tmtdset=\t\t[ARM]\n\t\t\tARM/S3C2412 JIVE boot control\n\n\t\t\tSee arch/arm/mach-s3c2412/mach-jive.c\n\n\tmtouchusb.raw_coordinates=\n\t\t\t[HW] Make the MicroTouch USB driver use raw coordinates\n\t\t\t('y', default) or cooked coordinates ('n')\n\n\tmtrr_chunk_size=nn[KMG] [X86]\n\t\t\tused for mtrr cleanup. It is largest continuous chunk\n\t\t\tthat could hold holes aka. UC entries.\n\n\tmtrr_gran_size=nn[KMG] [X86]\n\t\t\tUsed for mtrr cleanup. It is granularity of mtrr block.\n\t\t\tDefault is 1.\n\t\t\tLarge value could prevent small alignment from\n\t\t\tusing up MTRRs.\n\n\tmtrr_spare_reg_nr=n [X86]\n\t\t\tFormat: <integer>\n\t\t\tRange: 0,7 : spare reg number\n\t\t\tDefault : 1\n\t\t\tUsed for mtrr cleanup. It is spare mtrr entries number.\n\t\t\tSet to 2 or more if your graphical card needs more.\n\n\tn2=\t\t[NET] SDL Inc. RISCom/N2 synchronous serial card\n\n\tnetdev=\t\t[NET] Network devices parameters\n\t\t\tFormat: <irq>,<io>,<mem_start>,<mem_end>,<name>\n\t\t\tNote that mem_start is often overloaded to mean\n\t\t\tsomething different and driver-specific.\n\t\t\tThis usage is only documented in each driver source\n\t\t\tfile if at all.\n\n\tnf_conntrack.acct=\n\t\t\t[NETFILTER] Enable connection tracking flow accounting\n\t\t\t0 to disable accounting\n\t\t\t1 to enable accounting\n\t\t\tDefault value is 0.\n\n\tnfsaddrs=\t[NFS] Deprecated.  Use ip= instead.\n\t\t\tSee Documentation/admin-guide/nfs/nfsroot.rst.\n\n\tnfsroot=\t[NFS] nfs root filesystem for disk-less boxes.\n\t\t\tSee Documentation/admin-guide/nfs/nfsroot.rst.\n\n\tnfsrootdebug\t[NFS] enable nfsroot debugging messages.\n\t\t\tSee Documentation/admin-guide/nfs/nfsroot.rst.\n\n\tnfs.callback_nr_threads=\n\t\t\t[NFSv4] set the total number of threads that the\n\t\t\tNFS client will assign to service NFSv4 callback\n\t\t\trequests.\n\n\tnfs.callback_tcpport=\n\t\t\t[NFS] set the TCP port on which the NFSv4 callback\n\t\t\tchannel should listen.\n\n\tnfs.cache_getent=\n\t\t\t[NFS] sets the pathname to the program which is used\n\t\t\tto update the NFS client cache entries.\n\n\tnfs.cache_getent_timeout=\n\t\t\t[NFS] sets the timeout after which an attempt to\n\t\t\tupdate a cache entry is deemed to have failed.\n\n\tnfs.idmap_cache_timeout=\n\t\t\t[NFS] set the maximum lifetime for idmapper cache\n\t\t\tentries.\n\n\tnfs.enable_ino64=\n\t\t\t[NFS] enable 64-bit inode numbers.\n\t\t\tIf zero, the NFS client will fake up a 32-bit inode\n\t\t\tnumber for the readdir() and stat() syscalls instead\n\t\t\tof returning the full 64-bit number.\n\t\t\tThe default is to return 64-bit inode numbers.\n\n\tnfs.max_session_cb_slots=\n\t\t\t[NFSv4.1] Sets the maximum number of session\n\t\t\tslots the client will assign to the callback\n\t\t\tchannel. This determines the maximum number of\n\t\t\tcallbacks the client will process in parallel for\n\t\t\ta particular server.\n\n\tnfs.max_session_slots=\n\t\t\t[NFSv4.1] Sets the maximum number of session slots\n\t\t\tthe client will attempt to negotiate with the server.\n\t\t\tThis limits the number of simultaneous RPC requests\n\t\t\tthat the client can send to the NFSv4.1 server.\n\t\t\tNote that there is little point in setting this\n\t\t\tvalue higher than the max_tcp_slot_table_limit.\n\n\tnfs.nfs4_disable_idmapping=\n\t\t\t[NFSv4] When set to the default of '1', this option\n\t\t\tensures that both the RPC level authentication\n\t\t\tscheme and the NFS level operations agree to use\n\t\t\tnumeric uids/gids if the mount is using the\n\t\t\t'sec=sys' security flavour. In effect it is\n\t\t\tdisabling idmapping, which can make migration from\n\t\t\tlegacy NFSv2/v3 systems to NFSv4 easier.\n\t\t\tServers that do not support this mode of operation\n\t\t\twill be autodetected by the client, and it will fall\n\t\t\tback to using the idmapper.\n\t\t\tTo turn off this behaviour, set the value to '0'.\n\tnfs.nfs4_unique_id=\n\t\t\t[NFS4] Specify an additional fixed unique ident-\n\t\t\tification string that NFSv4 clients can insert into\n\t\t\ttheir nfs_client_id4 string.  This is typically a\n\t\t\tUUID that is generated at system install time.\n\n\tnfs.send_implementation_id =\n\t\t\t[NFSv4.1] Send client implementation identification\n\t\t\tinformation in exchange_id requests.\n\t\t\tIf zero, no implementation identification information\n\t\t\twill be sent.\n\t\t\tThe default is to send the implementation identification\n\t\t\tinformation.\n\n\tnfs.recover_lost_locks =\n\t\t\t[NFSv4] Attempt to recover locks that were lost due\n\t\t\tto a lease timeout on the server. Please note that\n\t\t\tdoing this risks data corruption, since there are\n\t\t\tno guarantees that the file will remain unchanged\n\t\t\tafter the locks are lost.\n\t\t\tIf you want to enable the kernel legacy behaviour of\n\t\t\tattempting to recover these locks, then set this\n\t\t\tparameter to '1'.\n\t\t\tThe default parameter value of '0' causes the kernel\n\t\t\tnot to attempt recovery of lost locks.\n\n\tnfs4.layoutstats_timer =\n\t\t\t[NFSv4.2] Change the rate at which the kernel sends\n\t\t\tlayoutstats to the pNFS metadata server.\n\n\t\t\tSetting this to value to 0 causes the kernel to use\n\t\t\twhatever value is the default set by the layout\n\t\t\tdriver. A non-zero value sets the minimum interval\n\t\t\tin seconds between layoutstats transmissions.\n\n\tnfsd.nfs4_disable_idmapping=\n\t\t\t[NFSv4] When set to the default of '1', the NFSv4\n\t\t\tserver will return only numeric uids and gids to\n\t\t\tclients using auth_sys, and will accept numeric uids\n\t\t\tand gids from such clients.  This is intended to ease\n\t\t\tmigration from NFSv2/v3.\n\n\tnmi_debug=\t[KNL,SH] Specify one or more actions to take\n\t\t\twhen a NMI is triggered.\n\t\t\tFormat: [state][,regs][,debounce][,die]\n\n\tnmi_watchdog=\t[KNL,BUGS=X86] Debugging features for SMP kernels\n\t\t\tFormat: [panic,][nopanic,][num]\n\t\t\tValid num: 0 or 1\n\t\t\t0 - turn hardlockup detector in nmi_watchdog off\n\t\t\t1 - turn hardlockup detector in nmi_watchdog on\n\t\t\tWhen panic is specified, panic when an NMI watchdog\n\t\t\ttimeout occurs (or 'nopanic' to not panic on an NMI\n\t\t\twatchdog, if CONFIG_BOOTPARAM_HARDLOCKUP_PANIC is set)\n\t\t\tTo disable both hard and soft lockup detectors,\n\t\t\tplease see 'nowatchdog'.\n\t\t\tThis is useful when you use a panic=... timeout and\n\t\t\tneed the box quickly up again.\n\n\t\t\tThese settings can be accessed at runtime via\n\t\t\tthe nmi_watchdog and hardlockup_panic sysctls.\n\n\tnetpoll.carrier_timeout=\n\t\t\t[NET] Specifies amount of time (in seconds) that\n\t\t\tnetpoll should wait for a carrier. By default netpoll\n\t\t\twaits 4 seconds.\n\n\tno387\t\t[BUGS=X86-32] Tells the kernel to use the 387 maths\n\t\t\temulation library even if a 387 maths coprocessor\n\t\t\tis present.\n\n\tno5lvl\t\t[X86-64] Disable 5-level paging mode. Forces\n\t\t\tkernel to use 4-level paging instead.\n\n\tnofsgsbase\t[X86] Disables FSGSBASE instructions.\n\n\tno_console_suspend\n\t\t\t[HW] Never suspend the console\n\t\t\tDisable suspending of consoles during suspend and\n\t\t\thibernate operations.  Once disabled, debugging\n\t\t\tmessages can reach various consoles while the rest\n\t\t\tof the system is being put to sleep (ie, while\n\t\t\tdebugging driver suspend/resume hooks).  This may\n\t\t\tnot work reliably with all consoles, but is known\n\t\t\tto work with serial and VGA consoles.\n\t\t\tTo facilitate more flexible debugging, we also add\n\t\t\tconsole_suspend, a printk module parameter to control\n\t\t\tit. Users could use console_suspend (usually\n\t\t\t/sys/module/printk/parameters/console_suspend) to\n\t\t\tturn on/off it dynamically.\n\n\tnovmcoredd\t[KNL,KDUMP]\n\t\t\tDisable device dump. Device dump allows drivers to\n\t\t\tappend dump data to vmcore so you can collect driver\n\t\t\tspecified debug info.  Drivers can append the data\n\t\t\twithout any limit and this data is stored in memory,\n\t\t\tso this may cause significant memory stress.  Disabling\n\t\t\tdevice dump can help save memory but the driver debug\n\t\t\tdata will be no longer available.  This parameter\n\t\t\tis only available when CONFIG_PROC_VMCORE_DEVICE_DUMP\n\t\t\tis set.\n\n\tnoaliencache\t[MM, NUMA, SLAB] Disables the allocation of alien\n\t\t\tcaches in the slab allocator.  Saves per-node memory,\n\t\t\tbut will impact performance.\n\n\tnoalign\t\t[KNL,ARM]\n\n\tnoaltinstr\t[S390] Disables alternative instructions patching\n\t\t\t(CPU alternatives feature).\n\n\tnoapic\t\t[SMP,APIC] Tells the kernel to not make use of any\n\t\t\tIOAPICs that may be present in the system.\n\n\tnoautogroup\tDisable scheduler automatic task group creation.\n\n\tnobats\t\t[PPC] Do not use BATs for mapping kernel lowmem\n\t\t\ton \"Classic\" PPC cores.\n\n\tnocache\t\t[ARM]\n\n\tnoclflush\t[BUGS=X86] Don't use the CLFLUSH instruction\n\n\tnodelayacct\t[KNL] Disable per-task delay accounting\n\n\tnodsp\t\t[SH] Disable hardware DSP at boot time.\n\n\tnoefi\t\tDisable EFI runtime services support.\n\n\tnoexec\t\t[IA-64]\n\n\tnoexec\t\t[X86]\n\t\t\tOn X86-32 available only on PAE configured kernels.\n\t\t\tnoexec=on: enable non-executable mappings (default)\n\t\t\tnoexec=off: disable non-executable mappings\n\n\tnosmap\t\t[X86,PPC]\n\t\t\tDisable SMAP (Supervisor Mode Access Prevention)\n\t\t\teven if it is supported by processor.\n\n\tnosmep\t\t[X86,PPC]\n\t\t\tDisable SMEP (Supervisor Mode Execution Prevention)\n\t\t\teven if it is supported by processor.\n\n\tnoexec32\t[X86-64]\n\t\t\tThis affects only 32-bit executables.\n\t\t\tnoexec32=on: enable non-executable mappings (default)\n\t\t\t\tread doesn't imply executable mappings\n\t\t\tnoexec32=off: disable non-executable mappings\n\t\t\t\tread implies executable mappings\n\n\tnofpu\t\t[MIPS,SH] Disable hardware FPU at boot time.\n\n\tnofxsr\t\t[BUGS=X86-32] Disables x86 floating point extended\n\t\t\tregister save and restore. The kernel will only save\n\t\t\tlegacy floating-point registers on task switch.\n\n\tnohugeiomap\t[KNL,X86,PPC] Disable kernel huge I/O mappings.\n\n\tnosmt\t\t[KNL,S390] Disable symmetric multithreading (SMT).\n\t\t\tEquivalent to smt=1.\n\n\t\t\t[KNL,X86] Disable symmetric multithreading (SMT).\n\t\t\tnosmt=force: Force disable SMT, cannot be undone\n\t\t\t\t     via the sysfs control file.\n\n\tnospectre_v1\t[X86,PPC] Disable mitigations for Spectre Variant 1\n\t\t\t(bounds check bypass). With this option data leaks are\n\t\t\tpossible in the system.\n\n\tnospectre_v2\t[X86,PPC_FSL_BOOK3E,ARM64] Disable all mitigations for\n\t\t\tthe Spectre variant 2 (indirect branch prediction)\n\t\t\tvulnerability. System may allow data leaks with this\n\t\t\toption.\n\n\tnospec_store_bypass_disable\n\t\t\t[HW] Disable all mitigations for the Speculative Store Bypass vulnerability\n\n\tnoxsave\t\t[BUGS=X86] Disables x86 extended register state save\n\t\t\tand restore using xsave. The kernel will fallback to\n\t\t\tenabling legacy floating-point and sse state.\n\n\tnoxsaveopt\t[X86] Disables xsaveopt used in saving x86 extended\n\t\t\tregister states. The kernel will fall back to use\n\t\t\txsave to save the states. By using this parameter,\n\t\t\tperformance of saving the states is degraded because\n\t\t\txsave doesn't support modified optimization while\n\t\t\txsaveopt supports it on xsaveopt enabled systems.\n\n\tnoxsaves\t[X86] Disables xsaves and xrstors used in saving and\n\t\t\trestoring x86 extended register state in compacted\n\t\t\tform of xsave area. The kernel will fall back to use\n\t\t\txsaveopt and xrstor to save and restore the states\n\t\t\tin standard form of xsave area. By using this\n\t\t\tparameter, xsave area per process might occupy more\n\t\t\tmemory on xsaves enabled systems.\n\n\tnohlt\t\t[BUGS=ARM,SH] Tells the kernel that the sleep(SH) or\n\t\t\twfi(ARM) instruction doesn't work correctly and not to\n\t\t\tuse it. This is also useful when using JTAG debugger.\n\n\tno_file_caps\tTells the kernel not to honor file capabilities.  The\n\t\t\tonly way then for a file to be executed with privilege\n\t\t\tis to be setuid root or executed by root.\n\n\tnohalt\t\t[IA-64] Tells the kernel not to use the power saving\n\t\t\tfunction PAL_HALT_LIGHT when idle. This increases\n\t\t\tpower-consumption. On the positive side, it reduces\n\t\t\tinterrupt wake-up latency, which may improve performance\n\t\t\tin certain environments such as networked servers or\n\t\t\treal-time systems.\n\n\tnohibernate\t[HIBERNATION] Disable hibernation and resume.\n\n\tnohz=\t\t[KNL] Boottime enable/disable dynamic ticks\n\t\t\tValid arguments: on, off\n\t\t\tDefault: on\n\n\tnohz_full=\t[KNL,BOOT,SMP,ISOL]\n\t\t\tThe argument is a cpu list, as described above.\n\t\t\tIn kernels built with CONFIG_NO_HZ_FULL=y, set\n\t\t\tthe specified list of CPUs whose tick will be stopped\n\t\t\twhenever possible. The boot CPU will be forced outside\n\t\t\tthe range to maintain the timekeeping.  Any CPUs\n\t\t\tin this list will have their RCU callbacks offloaded,\n\t\t\tjust as if they had also been called out in the\n\t\t\trcu_nocbs= boot parameter.\n\n\tnoiotrap\t[SH] Disables trapped I/O port accesses.\n\n\tnoirqdebug\t[X86-32] Disables the code which attempts to detect and\n\t\t\tdisable unhandled interrupt sources.\n\n\tno_timer_check\t[X86,APIC] Disables the code which tests for\n\t\t\tbroken timer IRQ sources.\n\n\tnoisapnp\t[ISAPNP] Disables ISA PnP code.\n\n\tnoinitrd\t[RAM] Tells the kernel not to load any configured\n\t\t\tinitial RAM disk.\n\n\tnointremap\t[X86-64, Intel-IOMMU] Do not enable interrupt\n\t\t\tremapping.\n\t\t\t[Deprecated - use intremap=off]\n\n\tnointroute\t[IA-64]\n\n\tnoinvpcid\t[X86] Disable the INVPCID cpu feature.\n\n\tnojitter\t[IA-64] Disables jitter checking for ITC timers.\n\n\tno-kvmclock\t[X86,KVM] Disable paravirtualized KVM clock driver\n\n\tno-kvmapf\t[X86,KVM] Disable paravirtualized asynchronous page\n\t\t\tfault handling.\n\n\tno-vmw-sched-clock\n\t\t\t[X86,PV_OPS] Disable paravirtualized VMware scheduler\n\t\t\tclock and use the default one.\n\n\tno-steal-acc\t[X86,PV_OPS,ARM64] Disable paravirtualized steal time\n\t\t\taccounting. steal time is computed, but won't\n\t\t\tinfluence scheduler behaviour\n\n\tnolapic\t\t[X86-32,APIC] Do not enable or use the local APIC.\n\n\tnolapic_timer\t[X86-32,APIC] Do not use the local APIC timer.\n\n\tnoltlbs\t\t[PPC] Do not use large page/tlb entries for kernel\n\t\t\tlowmem mapping on PPC40x and PPC8xx\n\n\tnomca\t\t[IA-64] Disable machine check abort handling\n\n\tnomce\t\t[X86-32] Disable Machine Check Exception\n\n\tnomfgpt\t\t[X86-32] Disable Multi-Function General Purpose\n\t\t\tTimer usage (for AMD Geode machines).\n\n\tnonmi_ipi\t[X86] Disable using NMI IPIs during panic/reboot to\n\t\t\tshutdown the other cpus.  Instead use the REBOOT_VECTOR\n\t\t\tirq.\n\n\tnomodule\tDisable module load\n\n\tnopat\t\t[X86] Disable PAT (page attribute table extension of\n\t\t\tpagetables) support.\n\n\tnopcid\t\t[X86-64] Disable the PCID cpu feature.\n\n\tnorandmaps\tDon't use address space randomization.  Equivalent to\n\t\t\techo 0 > /proc/sys/kernel/randomize_va_space\n\n\tnoreplace-smp\t[X86-32,SMP] Don't replace SMP instructions\n\t\t\twith UP alternatives\n\n\tnordrand\t[X86] Disable kernel use of the RDRAND and\n\t\t\tRDSEED instructions even if they are supported\n\t\t\tby the processor.  RDRAND and RDSEED are still\n\t\t\tavailable to user space applications.\n\n\tnoresume\t[SWSUSP] Disables resume and restores original swap\n\t\t\tspace.\n\n\tno-scroll\t[VGA] Disables scrollback.\n\t\t\tThis is required for the Braillex ib80-piezo Braille\n\t\t\treader made by F.H. Papenmeier (Germany).\n\n\tnosbagart\t[IA-64]\n\n\tnosep\t\t[BUGS=X86-32] Disables x86 SYSENTER/SYSEXIT support.\n\n\tnosmp\t\t[SMP] Tells an SMP kernel to act as a UP kernel,\n\t\t\tand disable the IO APIC.  legacy for \"maxcpus=0\".\n\n\tnosoftlockup\t[KNL] Disable the soft-lockup detector.\n\n\tnosync\t\t[HW,M68K] Disables sync negotiation for all devices.\n\n\tnowatchdog\t[KNL] Disable both lockup detectors, i.e.\n\t\t\tsoft-lockup and NMI watchdog (hard-lockup).\n\n\tnowb\t\t[ARM]\n\n\tnox2apic\t[X86-64,APIC] Do not enable x2APIC mode.\n\n\tcpu0_hotplug\t[X86] Turn on CPU0 hotplug feature when\n\t\t\tCONFIG_BOOTPARAM_HOTPLUG_CPU0 is off.\n\t\t\tSome features depend on CPU0. Known dependencies are:\n\t\t\t1. Resume from suspend/hibernate depends on CPU0.\n\t\t\tSuspend/hibernate will fail if CPU0 is offline and you\n\t\t\tneed to online CPU0 before suspend/hibernate.\n\t\t\t2. PIC interrupts also depend on CPU0. CPU0 can't be\n\t\t\tremoved if a PIC interrupt is detected.\n\t\t\tIt's said poweroff/reboot may depend on CPU0 on some\n\t\t\tmachines although I haven't seen such issues so far\n\t\t\tafter CPU0 is offline on a few tested machines.\n\t\t\tIf the dependencies are under your control, you can\n\t\t\tturn on cpu0_hotplug.\n\n\tnps_mtm_hs_ctr=\t[KNL,ARC]\n\t\t\tThis parameter sets the maximum duration, in\n\t\t\tcycles, each HW thread of the CTOP can run\n\t\t\twithout interruptions, before HW switches it.\n\t\t\tThe actual maximum duration is 16 times this\n\t\t\tparameter's value.\n\t\t\tFormat: integer between 1 and 255\n\t\t\tDefault: 255\n\n\tnptcg=\t\t[IA-64] Override max number of concurrent global TLB\n\t\t\tpurges which is reported from either PAL_VM_SUMMARY or\n\t\t\tSAL PALO.\n\n\tnr_cpus=\t[SMP] Maximum number of processors that\tan SMP kernel\n\t\t\tcould support.  nr_cpus=n : n >= 1 limits the kernel to\n\t\t\tsupport 'n' processors. It could be larger than the\n\t\t\tnumber of already plugged CPU during bootup, later in\n\t\t\truntime you can physically add extra cpu until it reaches\n\t\t\tn. So during boot up some boot time memory for per-cpu\n\t\t\tvariables need be pre-allocated for later physical cpu\n\t\t\thot plugging.\n\n\tnr_uarts=\t[SERIAL] maximum number of UARTs to be registered.\n\n\tnuma_balancing=\t[KNL,X86] Enable or disable automatic NUMA balancing.\n\t\t\tAllowed values are enable and disable\n\n\tnuma_zonelist_order= [KNL, BOOT] Select zonelist order for NUMA.\n\t\t\t'node', 'default' can be specified\n\t\t\tThis can be set from sysctl after boot.\n\t\t\tSee Documentation/admin-guide/sysctl/vm.rst for details.\n\n\tohci1394_dma=early\t[HW] enable debugging via the ohci1394 driver.\n\t\t\tSee Documentation/core-api/debugging-via-ohci1394.rst for more\n\t\t\tinfo.\n\n\tolpc_ec_timeout= [OLPC] ms delay when issuing EC commands\n\t\t\tRather than timing out after 20 ms if an EC\n\t\t\tcommand is not properly ACKed, override the length\n\t\t\tof the timeout.  We have interrupts disabled while\n\t\t\twaiting for the ACK, so if this is set too high\n\t\t\tinterrupts *may* be lost!\n\n\tomap_mux=\t[OMAP] Override bootloader pin multiplexing.\n\t\t\tFormat: <mux_mode0.mode_name=value>...\n\t\t\tFor example, to override I2C bus2:\n\t\t\tomap_mux=i2c2_scl.i2c2_scl=0x100,i2c2_sda.i2c2_sda=0x100\n\n\toprofile.timer=\t[HW]\n\t\t\tUse timer interrupt instead of performance counters\n\n\toprofile.cpu_type=\tForce an oprofile cpu type\n\t\t\tThis might be useful if you have an older oprofile\n\t\t\tuserland or if you want common events.\n\t\t\tFormat: { arch_perfmon }\n\t\t\tarch_perfmon: [X86] Force use of architectural\n\t\t\t\tperfmon on Intel CPUs instead of the\n\t\t\t\tCPU specific event set.\n\t\t\ttimer: [X86] Force use of architectural NMI\n\t\t\t\ttimer mode (see also oprofile.timer\n\t\t\t\tfor generic hr timer mode)\n\n\toops=panic\tAlways panic on oopses. Default is to just kill the\n\t\t\tprocess, but there is a small probability of\n\t\t\tdeadlocking the machine.\n\t\t\tThis will also cause panics on machine check exceptions.\n\t\t\tUseful together with panic=30 to trigger a reboot.\n\n\tpage_alloc.shuffle=\n\t\t\t[KNL] Boolean flag to control whether the page allocator\n\t\t\tshould randomize its free lists. The randomization may\n\t\t\tbe automatically enabled if the kernel detects it is\n\t\t\trunning on a platform with a direct-mapped memory-side\n\t\t\tcache, and this parameter can be used to\n\t\t\toverride/disable that behavior. The state of the flag\n\t\t\tcan be read from sysfs at:\n\t\t\t/sys/module/page_alloc/parameters/shuffle.\n\n\tpage_owner=\t[KNL] Boot-time page_owner enabling option.\n\t\t\tStorage of the information about who allocated\n\t\t\teach page is disabled in default. With this switch,\n\t\t\twe can turn it on.\n\t\t\ton: enable the feature\n\n\tpage_poison=\t[KNL] Boot-time parameter changing the state of\n\t\t\tpoisoning on the buddy allocator, available with\n\t\t\tCONFIG_PAGE_POISONING=y.\n\t\t\toff: turn off poisoning (default)\n\t\t\ton: turn on poisoning\n\n\tpanic=\t\t[KNL] Kernel behaviour on panic: delay <timeout>\n\t\t\ttimeout > 0: seconds before rebooting\n\t\t\ttimeout = 0: wait forever\n\t\t\ttimeout < 0: reboot immediately\n\t\t\tFormat: <timeout>\n\n\tpanic_print=\tBitmask for printing system info when panic happens.\n\t\t\tUser can chose combination of the following bits:\n\t\t\tbit 0: print all tasks info\n\t\t\tbit 1: print system memory info\n\t\t\tbit 2: print timer info\n\t\t\tbit 3: print locks info if CONFIG_LOCKDEP is on\n\t\t\tbit 4: print ftrace buffer\n\t\t\tbit 5: print all printk messages in buffer\n\n\tpanic_on_taint=\tBitmask for conditionally calling panic() in add_taint()\n\t\t\tFormat: <hex>[,nousertaint]\n\t\t\tHexadecimal bitmask representing the set of TAINT flags\n\t\t\tthat will cause the kernel to panic when add_taint() is\n\t\t\tcalled with any of the flags in this set.\n\t\t\tThe optional switch \"nousertaint\" can be utilized to\n\t\t\tprevent userspace forced crashes by writing to sysctl\n\t\t\t/proc/sys/kernel/tainted any flagset matching with the\n\t\t\tbitmask set on panic_on_taint.\n\t\t\tSee Documentation/admin-guide/tainted-kernels.rst for\n\t\t\textra details on the taint flags that users can pick\n\t\t\tto compose the bitmask to assign to panic_on_taint.\n\n\tpanic_on_warn\tpanic() instead of WARN().  Useful to cause kdump\n\t\t\ton a WARN().\n\n\tcrash_kexec_post_notifiers\n\t\t\tRun kdump after running panic-notifiers and dumping\n\t\t\tkmsg. This only for the users who doubt kdump always\n\t\t\tsucceeds in any situation.\n\t\t\tNote that this also increases risks of kdump failure,\n\t\t\tbecause some panic notifiers can make the crashed\n\t\t\tkernel more unstable.\n\n\tparkbd.port=\t[HW] Parallel port number the keyboard adapter is\n\t\t\tconnected to, default is 0.\n\t\t\tFormat: <parport#>\n\tparkbd.mode=\t[HW] Parallel port keyboard adapter mode of operation,\n\t\t\t0 for XT, 1 for AT (default is AT).\n\t\t\tFormat: <mode>\n\n\tparport=\t[HW,PPT] Specify parallel ports. 0 disables.\n\t\t\tFormat: { 0 | auto | 0xBBB[,IRQ[,DMA]] }\n\t\t\tUse 'auto' to force the driver to use any\n\t\t\tIRQ/DMA settings detected (the default is to\n\t\t\tignore detected IRQ/DMA settings because of\n\t\t\tpossible conflicts). You can specify the base\n\t\t\taddress, IRQ, and DMA settings; IRQ and DMA\n\t\t\tshould be numbers, or 'auto' (for using detected\n\t\t\tsettings on that particular port), or 'nofifo'\n\t\t\t(to avoid using a FIFO even if it is detected).\n\t\t\tParallel ports are assigned in the order they\n\t\t\tare specified on the command line, starting\n\t\t\twith parport0.\n\n\tparport_init_mode=\t[HW,PPT]\n\t\t\tConfigure VIA parallel port to operate in\n\t\t\ta specific mode. This is necessary on Pegasos\n\t\t\tcomputer where firmware has no options for setting\n\t\t\tup parallel port mode and sets it to spp.\n\t\t\tCurrently this function knows 686a and 8231 chips.\n\t\t\tFormat: [spp|ps2|epp|ecp|ecpepp]\n\n\tpause_on_oops=\n\t\t\tHalt all CPUs after the first oops has been printed for\n\t\t\tthe specified number of seconds.  This is to be used if\n\t\t\tyour oopses keep scrolling off the screen.\n\n\tpcbit=\t\t[HW,ISDN]\n\n\tpcd.\t\t[PARIDE]\n\t\t\tSee header of drivers/block/paride/pcd.c.\n\t\t\tSee also Documentation/admin-guide/blockdev/paride.rst.\n\n\tpci=option[,option...]\t[PCI] various PCI subsystem options.\n\n\t\t\t\tSome options herein operate on a specific device\n\t\t\t\tor a set of devices (<pci_dev>). These are\n\t\t\t\tspecified in one of the following formats:\n\n\t\t\t\t[<domain>:]<bus>:<dev>.<func>[/<dev>.<func>]*\n\t\t\t\tpci:<vendor>:<device>[:<subvendor>:<subdevice>]\n\n\t\t\t\tNote: the first format specifies a PCI\n\t\t\t\tbus/device/function address which may change\n\t\t\t\tif new hardware is inserted, if motherboard\n\t\t\t\tfirmware changes, or due to changes caused\n\t\t\t\tby other kernel parameters. If the\n\t\t\t\tdomain is left unspecified, it is\n\t\t\t\ttaken to be zero. Optionally, a path\n\t\t\t\tto a device through multiple device/function\n\t\t\t\taddresses can be specified after the base\n\t\t\t\taddress (this is more robust against\n\t\t\t\trenumbering issues).  The second format\n\t\t\t\tselects devices using IDs from the\n\t\t\t\tconfiguration space which may match multiple\n\t\t\t\tdevices in the system.\n\n\t\tearlydump\tdump PCI config space before the kernel\n\t\t\t\tchanges anything\n\t\toff\t\t[X86] don't probe for the PCI bus\n\t\tbios\t\t[X86-32] force use of PCI BIOS, don't access\n\t\t\t\tthe hardware directly. Use this if your machine\n\t\t\t\thas a non-standard PCI host bridge.\n\t\tnobios\t\t[X86-32] disallow use of PCI BIOS, only direct\n\t\t\t\thardware access methods are allowed. Use this\n\t\t\t\tif you experience crashes upon bootup and you\n\t\t\t\tsuspect they are caused by the BIOS.\n\t\tconf1\t\t[X86] Force use of PCI Configuration Access\n\t\t\t\tMechanism 1 (config address in IO port 0xCF8,\n\t\t\t\tdata in IO port 0xCFC, both 32-bit).\n\t\tconf2\t\t[X86] Force use of PCI Configuration Access\n\t\t\t\tMechanism 2 (IO port 0xCF8 is an 8-bit port for\n\t\t\t\tthe function, IO port 0xCFA, also 8-bit, sets\n\t\t\t\tbus number. The config space is then accessed\n\t\t\t\tthrough ports 0xC000-0xCFFF).\n\t\t\t\tSee http://wiki.osdev.org/PCI for more info\n\t\t\t\ton the configuration access mechanisms.\n\t\tnoaer\t\t[PCIE] If the PCIEAER kernel config parameter is\n\t\t\t\tenabled, this kernel boot option can be used to\n\t\t\t\tdisable the use of PCIE advanced error reporting.\n\t\tnodomains\t[PCI] Disable support for multiple PCI\n\t\t\t\troot domains (aka PCI segments, in ACPI-speak).\n\t\tnommconf\t[X86] Disable use of MMCONFIG for PCI\n\t\t\t\tConfiguration\n\t\tcheck_enable_amd_mmconf [X86] check for and enable\n\t\t\t\tproperly configured MMIO access to PCI\n\t\t\t\tconfig space on AMD family 10h CPU\n\t\tnomsi\t\t[MSI] If the PCI_MSI kernel config parameter is\n\t\t\t\tenabled, this kernel boot option can be used to\n\t\t\t\tdisable the use of MSI interrupts system-wide.\n\t\tnoioapicquirk\t[APIC] Disable all boot interrupt quirks.\n\t\t\t\tSafety option to keep boot IRQs enabled. This\n\t\t\t\tshould never be necessary.\n\t\tioapicreroute\t[APIC] Enable rerouting of boot IRQs to the\n\t\t\t\tprimary IO-APIC for bridges that cannot disable\n\t\t\t\tboot IRQs. This fixes a source of spurious IRQs\n\t\t\t\twhen the system masks IRQs.\n\t\tnoioapicreroute\t[APIC] Disable workaround that uses the\n\t\t\t\tboot IRQ equivalent of an IRQ that connects to\n\t\t\t\ta chipset where boot IRQs cannot be disabled.\n\t\t\t\tThe opposite of ioapicreroute.\n\t\tbiosirq\t\t[X86-32] Use PCI BIOS calls to get the interrupt\n\t\t\t\trouting table. These calls are known to be buggy\n\t\t\t\ton several machines and they hang the machine\n\t\t\t\twhen used, but on other computers it's the only\n\t\t\t\tway to get the interrupt routing table. Try\n\t\t\t\tthis option if the kernel is unable to allocate\n\t\t\t\tIRQs or discover secondary PCI buses on your\n\t\t\t\tmotherboard.\n\t\trom\t\t[X86] Assign address space to expansion ROMs.\n\t\t\t\tUse with caution as certain devices share\n\t\t\t\taddress decoders between ROMs and other\n\t\t\t\tresources.\n\t\tnorom\t\t[X86] Do not assign address space to\n\t\t\t\texpansion ROMs that do not already have\n\t\t\t\tBIOS assigned address ranges.\n\t\tnobar\t\t[X86] Do not assign address space to the\n\t\t\t\tBARs that weren't assigned by the BIOS.\n\t\tirqmask=0xMMMM\t[X86] Set a bit mask of IRQs allowed to be\n\t\t\t\tassigned automatically to PCI devices. You can\n\t\t\t\tmake the kernel exclude IRQs of your ISA cards\n\t\t\t\tthis way.\n\t\tpirqaddr=0xAAAAA\t[X86] Specify the physical address\n\t\t\t\tof the PIRQ table (normally generated\n\t\t\t\tby the BIOS) if it is outside the\n\t\t\t\tF0000h-100000h range.\n\t\tlastbus=N\t[X86] Scan all buses thru bus #N. Can be\n\t\t\t\tuseful if the kernel is unable to find your\n\t\t\t\tsecondary buses and you want to tell it\n\t\t\t\texplicitly which ones they are.\n\t\tassign-busses\t[X86] Always assign all PCI bus\n\t\t\t\tnumbers ourselves, overriding\n\t\t\t\twhatever the firmware may have done.\n\t\tusepirqmask\t[X86] Honor the possible IRQ mask stored\n\t\t\t\tin the BIOS $PIR table. This is needed on\n\t\t\t\tsome systems with broken BIOSes, notably\n\t\t\t\tsome HP Pavilion N5400 and Omnibook XE3\n\t\t\t\tnotebooks. This will have no effect if ACPI\n\t\t\t\tIRQ routing is enabled.\n\t\tnoacpi\t\t[X86] Do not use ACPI for IRQ routing\n\t\t\t\tor for PCI scanning.\n\t\tuse_crs\t\t[X86] Use PCI host bridge window information\n\t\t\t\tfrom ACPI.  On BIOSes from 2008 or later, this\n\t\t\t\tis enabled by default.  If you need to use this,\n\t\t\t\tplease report a bug.\n\t\tnocrs\t\t[X86] Ignore PCI host bridge windows from ACPI.\n\t\t\t\tIf you need to use this, please report a bug.\n\t\trouteirq\tDo IRQ routing for all PCI devices.\n\t\t\t\tThis is normally done in pci_enable_device(),\n\t\t\t\tso this option is a temporary workaround\n\t\t\t\tfor broken drivers that don't call it.\n\t\tskip_isa_align\t[X86] do not align io start addr, so can\n\t\t\t\thandle more pci cards\n\t\tnoearly\t\t[X86] Don't do any early type 1 scanning.\n\t\t\t\tThis might help on some broken boards which\n\t\t\t\tmachine check when some devices' config space\n\t\t\t\tis read. But various workarounds are disabled\n\t\t\t\tand some IOMMU drivers will not work.\n\t\tbfsort\t\tSort PCI devices into breadth-first order.\n\t\t\t\tThis sorting is done to get a device\n\t\t\t\torder compatible with older (<= 2.4) kernels.\n\t\tnobfsort\tDon't sort PCI devices into breadth-first order.\n\t\tpcie_bus_tune_off\tDisable PCIe MPS (Max Payload Size)\n\t\t\t\ttuning and use the BIOS-configured MPS defaults.\n\t\tpcie_bus_safe\tSet every device's MPS to the largest value\n\t\t\t\tsupported by all devices below the root complex.\n\t\tpcie_bus_perf\tSet device MPS to the largest allowable MPS\n\t\t\t\tbased on its parent bus. Also set MRRS (Max\n\t\t\t\tRead Request Size) to the largest supported\n\t\t\t\tvalue (no larger than the MPS that the device\n\t\t\t\tor bus can support) for best performance.\n\t\tpcie_bus_peer2peer\tSet every device's MPS to 128B, which\n\t\t\t\tevery device is guaranteed to support. This\n\t\t\t\tconfiguration allows peer-to-peer DMA between\n\t\t\t\tany pair of devices, possibly at the cost of\n\t\t\t\treduced performance.  This also guarantees\n\t\t\t\tthat hot-added devices will work.\n\t\tcbiosize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for the CardBus bridge's IO window.\n\t\t\t\tThe default value is 256 bytes.\n\t\tcbmemsize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for the CardBus bridge's memory\n\t\t\t\twindow. The default value is 64 megabytes.\n\t\tresource_alignment=\n\t\t\t\tFormat:\n\t\t\t\t[<order of align>@]<pci_dev>[; ...]\n\t\t\t\tSpecifies alignment and device to reassign\n\t\t\t\taligned memory resources. How to\n\t\t\t\tspecify the device is described above.\n\t\t\t\tIf <order of align> is not specified,\n\t\t\t\tPAGE_SIZE is used as alignment.\n\t\t\t\tA PCI-PCI bridge can be specified if resource\n\t\t\t\twindows need to be expanded.\n\t\t\t\tTo specify the alignment for several\n\t\t\t\tinstances of a device, the PCI vendor,\n\t\t\t\tdevice, subvendor, and subdevice may be\n\t\t\t\tspecified, e.g., 12@pci:8086:9c22:103c:198f\n\t\t\t\tfor 4096-byte alignment.\n\t\tecrc=\t\tEnable/disable PCIe ECRC (transaction layer\n\t\t\t\tend-to-end CRC checking).\n\t\t\t\tbios: Use BIOS/firmware settings. This is the\n\t\t\t\tthe default.\n\t\t\t\toff: Turn ECRC off\n\t\t\t\ton: Turn ECRC on.\n\t\thpiosize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for hotplug bridge's IO window.\n\t\t\t\tDefault size is 256 bytes.\n\t\thpmmiosize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for hotplug bridge's MMIO window.\n\t\t\t\tDefault size is 2 megabytes.\n\t\thpmmioprefsize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for hotplug bridge's MMIO_PREF window.\n\t\t\t\tDefault size is 2 megabytes.\n\t\thpmemsize=nn[KMG]\tThe fixed amount of bus space which is\n\t\t\t\treserved for hotplug bridge's MMIO and\n\t\t\t\tMMIO_PREF window.\n\t\t\t\tDefault size is 2 megabytes.\n\t\thpbussize=nn\tThe minimum amount of additional bus numbers\n\t\t\t\treserved for buses below a hotplug bridge.\n\t\t\t\tDefault is 1.\n\t\trealloc=\tEnable/disable reallocating PCI bridge resources\n\t\t\t\tif allocations done by BIOS are too small to\n\t\t\t\taccommodate resources required by all child\n\t\t\t\tdevices.\n\t\t\t\toff: Turn realloc off\n\t\t\t\ton: Turn realloc on\n\t\trealloc\t\tsame as realloc=on\n\t\tnoari\t\tdo not use PCIe ARI.\n\t\tnoats\t\t[PCIE, Intel-IOMMU, AMD-IOMMU]\n\t\t\t\tdo not use PCIe ATS (and IOMMU device IOTLB).\n\t\tpcie_scan_all\tScan all possible PCIe devices.  Otherwise we\n\t\t\t\tonly look for one device below a PCIe downstream\n\t\t\t\tport.\n\t\tbig_root_window\tTry to add a big 64bit memory window to the PCIe\n\t\t\t\troot complex on AMD CPUs. Some GFX hardware\n\t\t\t\tcan resize a BAR to allow access to all VRAM.\n\t\t\t\tAdding the window is slightly risky (it may\n\t\t\t\tconflict with unreported devices), so this\n\t\t\t\ttaints the kernel.\n\t\tdisable_acs_redir=<pci_dev>[; ...]\n\t\t\t\tSpecify one or more PCI devices (in the format\n\t\t\t\tspecified above) separated by semicolons.\n\t\t\t\tEach device specified will have the PCI ACS\n\t\t\t\tredirect capabilities forced off which will\n\t\t\t\tallow P2P traffic between devices through\n\t\t\t\tbridges without forcing it upstream. Note:\n\t\t\t\tthis removes isolation between devices and\n\t\t\t\tmay put more devices in an IOMMU group.\n\t\tforce_floating\t[S390] Force usage of floating interrupts.\n\t\tnomio\t\t[S390] Do not use MIO instructions.\n\t\tnorid\t\t[S390] ignore the RID field and force use of\n\t\t\t\tone PCI domain per PCI function\n\n\tpcie_aspm=\t[PCIE] Forcibly enable or disable PCIe Active State Power\n\t\t\tManagement.\n\t\toff\tDisable ASPM.\n\t\tforce\tEnable ASPM even on devices that claim not to support it.\n\t\t\tWARNING: Forcing ASPM on may cause system lockups.\n\n\tpcie_ports=\t[PCIE] PCIe port services handling:\n\t\tnative\tUse native PCIe services (PME, AER, DPC, PCIe hotplug)\n\t\t\teven if the platform doesn't give the OS permission to\n\t\t\tuse them.  This may cause conflicts if the platform\n\t\t\talso tries to use these services.\n\t\tdpc-native\tUse native PCIe service for DPC only.  May\n\t\t\t\tcause conflicts if firmware uses AER or DPC.\n\t\tcompat\tDisable native PCIe services (PME, AER, DPC, PCIe\n\t\t\thotplug).\n\n\tpcie_port_pm=\t[PCIE] PCIe port power management handling:\n\t\toff\tDisable power management of all PCIe ports\n\t\tforce\tForcibly enable power management of all PCIe ports\n\n\tpcie_pme=\t[PCIE,PM] Native PCIe PME signaling options:\n\t\tnomsi\tDo not use MSI for native PCIe PME signaling (this makes\n\t\t\tall PCIe root ports use INTx for all services).\n\n\tpcmv=\t\t[HW,PCMCIA] BadgePAD 4\n\n\tpd_ignore_unused\n\t\t\t[PM]\n\t\t\tKeep all power-domains already enabled by bootloader on,\n\t\t\teven if no driver has claimed them. This is useful\n\t\t\tfor debug and development, but should not be\n\t\t\tneeded on a platform with proper driver support.\n\n\tpd.\t\t[PARIDE]\n\t\t\tSee Documentation/admin-guide/blockdev/paride.rst.\n\n\tpdcchassis=\t[PARISC,HW] Disable/Enable PDC Chassis Status codes at\n\t\t\tboot time.\n\t\t\tFormat: { 0 | 1 }\n\t\t\tSee arch/parisc/kernel/pdc_chassis.c\n\n\tpercpu_alloc=\tSelect which percpu first chunk allocator to use.\n\t\t\tCurrently supported values are \"embed\" and \"page\".\n\t\t\tArchs may support subset or none of the\tselections.\n\t\t\tSee comments in mm/percpu.c for details on each\n\t\t\tallocator.  This parameter is primarily\tfor debugging\n\t\t\tand performance comparison.\n\n\tpf.\t\t[PARIDE]\n\t\t\tSee Documentation/admin-guide/blockdev/paride.rst.\n\n\tpg.\t\t[PARIDE]\n\t\t\tSee Documentation/admin-guide/blockdev/paride.rst.\n\n\tpirq=\t\t[SMP,APIC] Manual mp-table setup\n\t\t\tSee Documentation/x86/i386/IO-APIC.rst.\n\n\tplip=\t\t[PPT,NET] Parallel port network link\n\t\t\tFormat: { parport<nr> | timid | 0 }\n\t\t\tSee also Documentation/admin-guide/parport.rst.\n\n\tpmtmr=\t\t[X86] Manual setup of pmtmr I/O Port.\n\t\t\tOverride pmtimer IOPort with a hex value.\n\t\t\te.g. pmtmr=0x508\n\n\tpm_debug_messages\t[SUSPEND,KNL]\n\t\t\tEnable suspend/resume debug messages during boot up.\n\n\tpnp.debug=1\t[PNP]\n\t\t\tEnable PNP debug messages (depends on the\n\t\t\tCONFIG_PNP_DEBUG_MESSAGES option).  Change at run-time\n\t\t\tvia /sys/module/pnp/parameters/debug.  We always show\n\t\t\tcurrent resource usage; turning this on also shows\n\t\t\tpossible settings and some assignment information.\n\n\tpnpacpi=\t[ACPI]\n\t\t\t{ off }\n\n\tpnpbios=\t[ISAPNP]\n\t\t\t{ on | off | curr | res | no-curr | no-res }\n\n\tpnp_reserve_irq=\n\t\t\t[ISAPNP] Exclude IRQs for the autoconfiguration\n\n\tpnp_reserve_dma=\n\t\t\t[ISAPNP] Exclude DMAs for the autoconfiguration\n\n\tpnp_reserve_io=\t[ISAPNP] Exclude I/O ports for the autoconfiguration\n\t\t\tRanges are in pairs (I/O port base and size).\n\n\tpnp_reserve_mem=\n\t\t\t[ISAPNP] Exclude memory regions for the\n\t\t\tautoconfiguration.\n\t\t\tRanges are in pairs (memory base and size).\n\n\tports=\t\t[IP_VS_FTP] IPVS ftp helper module\n\t\t\tDefault is 21.\n\t\t\tUp to 8 (IP_VS_APP_MAX_PORTS) ports\n\t\t\tmay be specified.\n\t\t\tFormat: <port>,<port>....\n\n\tpowersave=off\t[PPC] This option disables power saving features.\n\t\t\tIt specifically disables cpuidle and sets the\n\t\t\tplatform machine description specific power_save\n\t\t\tfunction to NULL. On Idle the CPU just reduces\n\t\t\texecution priority.\n\n\tppc_strict_facility_enable\n\t\t\t[PPC] This option catches any kernel floating point,\n\t\t\tAltivec, VSX and SPE outside of regions specifically\n\t\t\tallowed (eg kernel_enable_fpu()/kernel_disable_fpu()).\n\t\t\tThere is some performance impact when enabling this.\n\n\tppc_tm=\t\t[PPC]\n\t\t\tFormat: {\"off\"}\n\t\t\tDisable Hardware Transactional Memory\n\n\tprint-fatal-signals=\n\t\t\t[KNL] debug: print fatal signals\n\n\t\t\tIf enabled, warn about various signal handling\n\t\t\trelated application anomalies: too many signals,\n\t\t\ttoo many POSIX.1 timers, fatal signals causing a\n\t\t\tcoredump - etc.\n\n\t\t\tIf you hit the warning due to signal overflow,\n\t\t\tyou might want to try \"ulimit -i unlimited\".\n\n\t\t\tdefault: off.\n\n\tprintk.always_kmsg_dump=\n\t\t\tTrigger kmsg_dump for cases other than kernel oops or\n\t\t\tpanics\n\t\t\tFormat: <bool>  (1/Y/y=enable, 0/N/n=disable)\n\t\t\tdefault: disabled\n\n\tprintk.devkmsg={on,off,ratelimit}\n\t\t\tControl writing to /dev/kmsg.\n\t\t\ton - unlimited logging to /dev/kmsg from userspace\n\t\t\toff - logging to /dev/kmsg disabled\n\t\t\tratelimit - ratelimit the logging\n\t\t\tDefault: ratelimit\n\n\tprintk.time=\tShow timing data prefixed to each printk message line\n\t\t\tFormat: <bool>  (1/Y/y=enable, 0/N/n=disable)\n\n\tprocessor.max_cstate=\t[HW,ACPI]\n\t\t\tLimit processor to maximum C-state\n\t\t\tmax_cstate=9 overrides any DMI blacklist limit.\n\n\tprocessor.nocst\t[HW,ACPI]\n\t\t\tIgnore the _CST method to determine C-states,\n\t\t\tinstead using the legacy FADT method\n\n\tprofile=\t[KNL] Enable kernel profiling via /proc/profile\n\t\t\tFormat: [<profiletype>,]<number>\n\t\t\tParam: <profiletype>: \"schedule\", \"sleep\", or \"kvm\"\n\t\t\t\t[defaults to kernel profiling]\n\t\t\tParam: \"schedule\" - profile schedule points.\n\t\t\tParam: \"sleep\" - profile D-state sleeping (millisecs).\n\t\t\t\tRequires CONFIG_SCHEDSTATS\n\t\t\tParam: \"kvm\" - profile VM exits.\n\t\t\tParam: <number> - step/bucket size as a power of 2 for\n\t\t\t\tstatistical time based profiling.\n\n\tprompt_ramdisk=\t[RAM] List of RAM disks to prompt for floppy disk\n\t\t\tbefore loading.\n\t\t\tSee Documentation/admin-guide/blockdev/ramdisk.rst.\n\n\tprot_virt=\t[S390] enable hosting protected virtual machines\n\t\t\tisolated from the hypervisor (if hardware supports\n\t\t\tthat).\n\t\t\tFormat: <bool>\n\n\tpsi=\t\t[KNL] Enable or disable pressure stall information\n\t\t\ttracking.\n\t\t\tFormat: <bool>\n\n\tpsmouse.proto=\t[HW,MOUSE] Highest PS2 mouse protocol extension to\n\t\t\tprobe for; one of (bare|imps|exps|lifebook|any).\n\tpsmouse.rate=\t[HW,MOUSE] Set desired mouse report rate, in reports\n\t\t\tper second.\n\tpsmouse.resetafter=\t[HW,MOUSE]\n\t\t\tTry to reset the device after so many bad packets\n\t\t\t(0 = never).\n\tpsmouse.resolution=\n\t\t\t[HW,MOUSE] Set desired mouse resolution, in dpi.\n\tpsmouse.smartscroll=\n\t\t\t[HW,MOUSE] Controls Logitech smartscroll autorepeat.\n\t\t\t0 = disabled, 1 = enabled (default).\n\n\tpstore.backend=\tSpecify the name of the pstore backend to use\n\n\tpt.\t\t[PARIDE]\n\t\t\tSee Documentation/admin-guide/blockdev/paride.rst.\n\n\tpti=\t\t[X86-64] Control Page Table Isolation of user and\n\t\t\tkernel address spaces.  Disabling this feature\n\t\t\tremoves hardening, but improves performance of\n\t\t\tsystem calls and interrupts.\n\n\t\t\ton   - unconditionally enable\n\t\t\toff  - unconditionally disable\n\t\t\tauto - kernel detects whether your CPU model is\n\t\t\t       vulnerable to issues that PTI mitigates\n\n\t\t\tNot specifying this option is equivalent to pti=auto.\n\n\tnopti\t\t[X86-64]\n\t\t\tEquivalent to pti=off\n\n\tpty.legacy_count=\n\t\t\t[KNL] Number of legacy pty's. Overwrites compiled-in\n\t\t\tdefault number.\n\n\tquiet\t\t[KNL] Disable most log messages\n\n\tr128=\t\t[HW,DRM]\n\n\traid=\t\t[HW,RAID]\n\t\t\tSee Documentation/admin-guide/md.rst.\n\n\tramdisk_size=\t[RAM] Sizes of RAM disks in kilobytes\n\t\t\tSee Documentation/admin-guide/blockdev/ramdisk.rst.\n\n\trandom.trust_cpu={on,off}\n\t\t\t[KNL] Enable or disable trusting the use of the\n\t\t\tCPU's random number generator (if available) to\n\t\t\tfully seed the kernel's CRNG. Default is controlled\n\t\t\tby CONFIG_RANDOM_TRUST_CPU.\n\n\tras=option[,option,...]\t[KNL] RAS-specific options\n\n\t\tcec_disable\t[X86]\n\t\t\t\tDisable the Correctable Errors Collector,\n\t\t\t\tsee CONFIG_RAS_CEC help text.\n\n\trcu_nocbs=\t[KNL]\n\t\t\tThe argument is a cpu list, as described above,\n\t\t\texcept that the string \"all\" can be used to\n\t\t\tspecify every CPU on the system.\n\n\t\t\tIn kernels built with CONFIG_RCU_NOCB_CPU=y, set\n\t\t\tthe specified list of CPUs to be no-callback CPUs.\n\t\t\tInvocation of these CPUs' RCU callbacks will be\n\t\t\toffloaded to \"rcuox/N\" kthreads created for that\n\t\t\tpurpose, where \"x\" is \"p\" for RCU-preempt, and\n\t\t\t\"s\" for RCU-sched, and \"N\" is the CPU number.\n\t\t\tThis reduces OS jitter on the offloaded CPUs,\n\t\t\twhich can be useful for HPC and real-time\n\t\t\tworkloads.  It can also improve energy efficiency\n\t\t\tfor asymmetric multiprocessors.\n\n\trcu_nocb_poll\t[KNL]\n\t\t\tRather than requiring that offloaded CPUs\n\t\t\t(specified by rcu_nocbs= above) explicitly\n\t\t\tawaken the corresponding \"rcuoN\" kthreads,\n\t\t\tmake these kthreads poll for callbacks.\n\t\t\tThis improves the real-time response for the\n\t\t\toffloaded CPUs by relieving them of the need to\n\t\t\twake up the corresponding kthread, but degrades\n\t\t\tenergy efficiency by requiring that the kthreads\n\t\t\tperiodically wake up to do the polling.\n\n\trcutree.blimit=\t[KNL]\n\t\t\tSet maximum number of finished RCU callbacks to\n\t\t\tprocess in one batch.\n\n\trcutree.dump_tree=\t[KNL]\n\t\t\tDump the structure of the rcu_node combining tree\n\t\t\tout at early boot.  This is used for diagnostic\n\t\t\tpurposes, to verify correct tree setup.\n\n\trcutree.gp_cleanup_delay=\t[KNL]\n\t\t\tSet the number of jiffies to delay each step of\n\t\t\tRCU grace-period cleanup.\n\n\trcutree.gp_init_delay=\t[KNL]\n\t\t\tSet the number of jiffies to delay each step of\n\t\t\tRCU grace-period initialization.\n\n\trcutree.gp_preinit_delay=\t[KNL]\n\t\t\tSet the number of jiffies to delay each step of\n\t\t\tRCU grace-period pre-initialization, that is,\n\t\t\tthe propagation of recent CPU-hotplug changes up\n\t\t\tthe rcu_node combining tree.\n\n\trcutree.use_softirq=\t[KNL]\n\t\t\tIf set to zero, move all RCU_SOFTIRQ processing to\n\t\t\tper-CPU rcuc kthreads.  Defaults to a non-zero\n\t\t\tvalue, meaning that RCU_SOFTIRQ is used by default.\n\t\t\tSpecify rcutree.use_softirq=0 to use rcuc kthreads.\n\n\trcutree.rcu_fanout_exact= [KNL]\n\t\t\tDisable autobalancing of the rcu_node combining\n\t\t\ttree.  This is used by rcutorture, and might\n\t\t\tpossibly be useful for architectures having high\n\t\t\tcache-to-cache transfer latencies.\n\n\trcutree.rcu_fanout_leaf= [KNL]\n\t\t\tChange the number of CPUs assigned to each\n\t\t\tleaf rcu_node structure.  Useful for very\n\t\t\tlarge systems, which will choose the value 64,\n\t\t\tand for NUMA systems with large remote-access\n\t\t\tlatencies, which will choose a value aligned\n\t\t\twith the appropriate hardware boundaries.\n\n\trcutree.rcu_min_cached_objs= [KNL]\n\t\t\tMinimum number of objects which are cached and\n\t\t\tmaintained per one CPU. Object size is equal\n\t\t\tto PAGE_SIZE. The cache allows to reduce the\n\t\t\tpressure to page allocator, also it makes the\n\t\t\twhole algorithm to behave better in low memory\n\t\t\tcondition.\n\n\trcutree.jiffies_till_first_fqs= [KNL]\n\t\t\tSet delay from grace-period initialization to\n\t\t\tfirst attempt to force quiescent states.\n\t\t\tUnits are jiffies, minimum value is zero,\n\t\t\tand maximum value is HZ.\n\n\trcutree.jiffies_till_next_fqs= [KNL]\n\t\t\tSet delay between subsequent attempts to force\n\t\t\tquiescent states.  Units are jiffies, minimum\n\t\t\tvalue is one, and maximum value is HZ.\n\n\trcutree.jiffies_till_sched_qs= [KNL]\n\t\t\tSet required age in jiffies for a\n\t\t\tgiven grace period before RCU starts\n\t\t\tsoliciting quiescent-state help from\n\t\t\trcu_note_context_switch() and cond_resched().\n\t\t\tIf not specified, the kernel will calculate\n\t\t\ta value based on the most recent settings\n\t\t\tof rcutree.jiffies_till_first_fqs\n\t\t\tand rcutree.jiffies_till_next_fqs.\n\t\t\tThis calculated value may be viewed in\n\t\t\trcutree.jiffies_to_sched_qs.  Any attempt to set\n\t\t\trcutree.jiffies_to_sched_qs will be cheerfully\n\t\t\toverwritten.\n\n\trcutree.kthread_prio= \t [KNL,BOOT]\n\t\t\tSet the SCHED_FIFO priority of the RCU per-CPU\n\t\t\tkthreads (rcuc/N). This value is also used for\n\t\t\tthe priority of the RCU boost threads (rcub/N)\n\t\t\tand for the RCU grace-period kthreads (rcu_bh,\n\t\t\trcu_preempt, and rcu_sched). If RCU_BOOST is\n\t\t\tset, valid values are 1-99 and the default is 1\n\t\t\t(the least-favored priority).  Otherwise, when\n\t\t\tRCU_BOOST is not set, valid values are 0-99 and\n\t\t\tthe default is zero (non-realtime operation).\n\n\trcutree.rcu_nocb_gp_stride= [KNL]\n\t\t\tSet the number of NOCB callback kthreads in\n\t\t\teach group, which defaults to the square root\n\t\t\tof the number of CPUs.\tLarger numbers reduce\n\t\t\tthe wakeup overhead on the global grace-period\n\t\t\tkthread, but increases that same overhead on\n\t\t\teach group's NOCB grace-period kthread.\n\n\trcutree.qhimark= [KNL]\n\t\t\tSet threshold of queued RCU callbacks beyond which\n\t\t\tbatch limiting is disabled.\n\n\trcutree.qlowmark= [KNL]\n\t\t\tSet threshold of queued RCU callbacks below which\n\t\t\tbatch limiting is re-enabled.\n\n\trcutree.qovld= [KNL]\n\t\t\tSet threshold of queued RCU callbacks beyond which\n\t\t\tRCU's force-quiescent-state scan will aggressively\n\t\t\tenlist help from cond_resched() and sched IPIs to\n\t\t\thelp CPUs more quickly reach quiescent states.\n\t\t\tSet to less than zero to make this be set based\n\t\t\ton rcutree.qhimark at boot time and to zero to\n\t\t\tdisable more aggressive help enlistment.\n\n\trcutree.rcu_idle_gp_delay= [KNL]\n\t\t\tSet wakeup interval for idle CPUs that have\n\t\t\tRCU callbacks (RCU_FAST_NO_HZ=y).\n\n\trcutree.rcu_idle_lazy_gp_delay= [KNL]\n\t\t\tSet wakeup interval for idle CPUs that have\n\t\t\tonly \"lazy\" RCU callbacks (RCU_FAST_NO_HZ=y).\n\t\t\tLazy RCU callbacks are those which RCU can\n\t\t\tprove do nothing more than free memory.\n\n\trcutree.rcu_kick_kthreads= [KNL]\n\t\t\tCause the grace-period kthread to get an extra\n\t\t\twake_up() if it sleeps three times longer than\n\t\t\tit should at force-quiescent-state time.\n\t\t\tThis wake_up() will be accompanied by a\n\t\t\tWARN_ONCE() splat and an ftrace_dump().\n\n\trcutree.sysrq_rcu= [KNL]\n\t\t\tCommandeer a sysrq key to dump out Tree RCU's\n\t\t\trcu_node tree with an eye towards determining\n\t\t\twhy a new grace period has not yet started.\n\n\trcuperf.gp_async= [KNL]\n\t\t\tMeasure performance of asynchronous\n\t\t\tgrace-period primitives such as call_rcu().\n\n\trcuperf.gp_async_max= [KNL]\n\t\t\tSpecify the maximum number of outstanding\n\t\t\tcallbacks per writer thread.  When a writer\n\t\t\tthread exceeds this limit, it invokes the\n\t\t\tcorresponding flavor of rcu_barrier() to allow\n\t\t\tpreviously posted callbacks to drain.\n\n\trcuperf.gp_exp= [KNL]\n\t\t\tMeasure performance of expedited synchronous\n\t\t\tgrace-period primitives.\n\n\trcuperf.holdoff= [KNL]\n\t\t\tSet test-start holdoff period.  The purpose of\n\t\t\tthis parameter is to delay the start of the\n\t\t\ttest until boot completes in order to avoid\n\t\t\tinterference.\n\n\trcuperf.kfree_rcu_test= [KNL]\n\t\t\tSet to measure performance of kfree_rcu() flooding.\n\n\trcuperf.kfree_nthreads= [KNL]\n\t\t\tThe number of threads running loops of kfree_rcu().\n\n\trcuperf.kfree_alloc_num= [KNL]\n\t\t\tNumber of allocations and frees done in an iteration.\n\n\trcuperf.kfree_loops= [KNL]\n\t\t\tNumber of loops doing rcuperf.kfree_alloc_num number\n\t\t\tof allocations and frees.\n\n\trcuperf.nreaders= [KNL]\n\t\t\tSet number of RCU readers.  The value -1 selects\n\t\t\tN, where N is the number of CPUs.  A value\n\t\t\t\"n\" less than -1 selects N-n+1, where N is again\n\t\t\tthe number of CPUs.  For example, -2 selects N\n\t\t\t(the number of CPUs), -3 selects N+1, and so on.\n\t\t\tA value of \"n\" less than or equal to -N selects\n\t\t\ta single reader.\n\n\trcuperf.nwriters= [KNL]\n\t\t\tSet number of RCU writers.  The values operate\n\t\t\tthe same as for rcuperf.nreaders.\n\t\t\tN, where N is the number of CPUs\n\n\trcuperf.perf_type= [KNL]\n\t\t\tSpecify the RCU implementation to test.\n\n\trcuperf.shutdown= [KNL]\n\t\t\tShut the system down after performance tests\n\t\t\tcomplete.  This is useful for hands-off automated\n\t\t\ttesting.\n\n\trcuperf.verbose= [KNL]\n\t\t\tEnable additional printk() statements.\n\n\trcuperf.writer_holdoff= [KNL]\n\t\t\tWrite-side holdoff between grace periods,\n\t\t\tin microseconds.  The default of zero says\n\t\t\tno holdoff.\n\n\trcutorture.fqs_duration= [KNL]\n\t\t\tSet duration of force_quiescent_state bursts\n\t\t\tin microseconds.\n\n\trcutorture.fqs_holdoff= [KNL]\n\t\t\tSet holdoff time within force_quiescent_state bursts\n\t\t\tin microseconds.\n\n\trcutorture.fqs_stutter= [KNL]\n\t\t\tSet wait time between force_quiescent_state bursts\n\t\t\tin seconds.\n\n\trcutorture.fwd_progress= [KNL]\n\t\t\tEnable RCU grace-period forward-progress testing\n\t\t\tfor the types of RCU supporting this notion.\n\n\trcutorture.fwd_progress_div= [KNL]\n\t\t\tSpecify the fraction of a CPU-stall-warning\n\t\t\tperiod to do tight-loop forward-progress testing.\n\n\trcutorture.fwd_progress_holdoff= [KNL]\n\t\t\tNumber of seconds to wait between successive\n\t\t\tforward-progress tests.\n\n\trcutorture.fwd_progress_need_resched= [KNL]\n\t\t\tEnclose cond_resched() calls within checks for\n\t\t\tneed_resched() during tight-loop forward-progress\n\t\t\ttesting.\n\n\trcutorture.gp_cond= [KNL]\n\t\t\tUse conditional/asynchronous update-side\n\t\t\tprimitives, if available.\n\n\trcutorture.gp_exp= [KNL]\n\t\t\tUse expedited update-side primitives, if available.\n\n\trcutorture.gp_normal= [KNL]\n\t\t\tUse normal (non-expedited) asynchronous\n\t\t\tupdate-side primitives, if available.\n\n\trcutorture.gp_sync= [KNL]\n\t\t\tUse normal (non-expedited) synchronous\n\t\t\tupdate-side primitives, if available.  If all\n\t\t\tof rcutorture.gp_cond=, rcutorture.gp_exp=,\n\t\t\trcutorture.gp_normal=, and rcutorture.gp_sync=\n\t\t\tare zero, rcutorture acts as if is interpreted\n\t\t\tthey are all non-zero.\n\n\trcutorture.n_barrier_cbs= [KNL]\n\t\t\tSet callbacks/threads for rcu_barrier() testing.\n\n\trcutorture.nfakewriters= [KNL]\n\t\t\tSet number of concurrent RCU writers.  These just\n\t\t\tstress RCU, they don't participate in the actual\n\t\t\ttest, hence the \"fake\".\n\n\trcutorture.nreaders= [KNL]\n\t\t\tSet number of RCU readers.  The value -1 selects\n\t\t\tN-1, where N is the number of CPUs.  A value\n\t\t\t\"n\" less than -1 selects N-n-2, where N is again\n\t\t\tthe number of CPUs.  For example, -2 selects N\n\t\t\t(the number of CPUs), -3 selects N+1, and so on.\n\n\trcutorture.object_debug= [KNL]\n\t\t\tEnable debug-object double-call_rcu() testing.\n\n\trcutorture.onoff_holdoff= [KNL]\n\t\t\tSet time (s) after boot for CPU-hotplug testing.\n\n\trcutorture.onoff_interval= [KNL]\n\t\t\tSet time (jiffies) between CPU-hotplug operations,\n\t\t\tor zero to disable CPU-hotplug testing.\n\n\trcutorture.read_exit= [KNL]\n\t\t\tSet the number of read-then-exit kthreads used\n\t\t\tto test the interaction of RCU updaters and\n\t\t\ttask-exit processing.\n\n\trcutorture.read_exit_burst= [KNL]\n\t\t\tThe number of times in a given read-then-exit\n\t\t\tepisode that a set of read-then-exit kthreads\n\t\t\tis spawned.\n\n\trcutorture.read_exit_delay= [KNL]\n\t\t\tThe delay, in seconds, between successive\n\t\t\tread-then-exit testing episodes.\n\n\trcutorture.shuffle_interval= [KNL]\n\t\t\tSet task-shuffle interval (s).  Shuffling tasks\n\t\t\tallows some CPUs to go into dyntick-idle mode\n\t\t\tduring the rcutorture test.\n\n\trcutorture.shutdown_secs= [KNL]\n\t\t\tSet time (s) after boot system shutdown.  This\n\t\t\tis useful for hands-off automated testing.\n\n\trcutorture.stall_cpu= [KNL]\n\t\t\tDuration of CPU stall (s) to test RCU CPU stall\n\t\t\twarnings, zero to disable.\n\n\trcutorture.stall_cpu_block= [KNL]\n\t\t\tSleep while stalling if set.  This will result\n\t\t\tin warnings from preemptible RCU in addition\n\t\t\tto any other stall-related activity.\n\n\trcutorture.stall_cpu_holdoff= [KNL]\n\t\t\tTime to wait (s) after boot before inducing stall.\n\n\trcutorture.stall_cpu_irqsoff= [KNL]\n\t\t\tDisable interrupts while stalling if set.\n\n\trcutorture.stall_gp_kthread= [KNL]\n\t\t\tDuration (s) of forced sleep within RCU\n\t\t\tgrace-period kthread to test RCU CPU stall\n\t\t\twarnings, zero to disable.  If both stall_cpu\n\t\t\tand stall_gp_kthread are specified, the\n\t\t\tkthread is starved first, then the CPU.\n\n\trcutorture.stat_interval= [KNL]\n\t\t\tTime (s) between statistics printk()s.\n\n\trcutorture.stutter= [KNL]\n\t\t\tTime (s) to stutter testing, for example, specifying\n\t\t\tfive seconds causes the test to run for five seconds,\n\t\t\twait for five seconds, and so on.  This tests RCU's\n\t\t\tability to transition abruptly to and from idle.\n\n\trcutorture.test_boost= [KNL]\n\t\t\tTest RCU priority boosting?  0=no, 1=maybe, 2=yes.\n\t\t\t\"Maybe\" means test if the RCU implementation\n\t\t\tunder test support RCU priority boosting.\n\n\trcutorture.test_boost_duration= [KNL]\n\t\t\tDuration (s) of each individual boost test.\n\n\trcutorture.test_boost_interval= [KNL]\n\t\t\tInterval (s) between each boost test.\n\n\trcutorture.test_no_idle_hz= [KNL]\n\t\t\tTest RCU's dyntick-idle handling.  See also the\n\t\t\trcutorture.shuffle_interval parameter.\n\n\trcutorture.torture_type= [KNL]\n\t\t\tSpecify the RCU implementation to test.\n\n\trcutorture.verbose= [KNL]\n\t\t\tEnable additional printk() statements.\n\n\trcupdate.rcu_cpu_stall_ftrace_dump= [KNL]\n\t\t\tDump ftrace buffer after reporting RCU CPU\n\t\t\tstall warning.\n\n\trcupdate.rcu_cpu_stall_suppress= [KNL]\n\t\t\tSuppress RCU CPU stall warning messages.\n\n\trcupdate.rcu_cpu_stall_suppress_at_boot= [KNL]\n\t\t\tSuppress RCU CPU stall warning messages and\n\t\t\trcutorture writer stall warnings that occur\n\t\t\tduring early boot, that is, during the time\n\t\t\tbefore the init task is spawned.\n\n\trcupdate.rcu_cpu_stall_timeout= [KNL]\n\t\t\tSet timeout for RCU CPU stall warning messages.\n\n\trcupdate.rcu_expedited= [KNL]\n\t\t\tUse expedited grace-period primitives, for\n\t\t\texample, synchronize_rcu_expedited() instead\n\t\t\tof synchronize_rcu().  This reduces latency,\n\t\t\tbut can increase CPU utilization, degrade\n\t\t\treal-time latency, and degrade energy efficiency.\n\t\t\tNo effect on CONFIG_TINY_RCU kernels.\n\n\trcupdate.rcu_normal= [KNL]\n\t\t\tUse only normal grace-period primitives,\n\t\t\tfor example, synchronize_rcu() instead of\n\t\t\tsynchronize_rcu_expedited().  This improves\n\t\t\treal-time latency, CPU utilization, and\n\t\t\tenergy efficiency, but can expose users to\n\t\t\tincreased grace-period latency.  This parameter\n\t\t\toverrides rcupdate.rcu_expedited.  No effect on\n\t\t\tCONFIG_TINY_RCU kernels.\n\n\trcupdate.rcu_normal_after_boot= [KNL]\n\t\t\tOnce boot has completed (that is, after\n\t\t\trcu_end_inkernel_boot() has been invoked), use\n\t\t\tonly normal grace-period primitives.  No effect\n\t\t\ton CONFIG_TINY_RCU kernels.\n\n\trcupdate.rcu_task_ipi_delay= [KNL]\n\t\t\tSet time in jiffies during which RCU tasks will\n\t\t\tavoid sending IPIs, starting with the beginning\n\t\t\tof a given grace period.  Setting a large\n\t\t\tnumber avoids disturbing real-time workloads,\n\t\t\tbut lengthens grace periods.\n\n\trcupdate.rcu_task_stall_timeout= [KNL]\n\t\t\tSet timeout in jiffies for RCU task stall warning\n\t\t\tmessages.  Disable with a value less than or equal\n\t\t\tto zero.\n\n\trcupdate.rcu_self_test= [KNL]\n\t\t\tRun the RCU early boot self tests\n\n\trdinit=\t\t[KNL]\n\t\t\tFormat: <full_path>\n\t\t\tRun specified binary instead of /init from the ramdisk,\n\t\t\tused for early userspace startup. See initrd.\n\n\trdrand=\t\t[X86]\n\t\t\tforce - Override the decision by the kernel to hide the\n\t\t\t\tadvertisement of RDRAND support (this affects\n\t\t\t\tcertain AMD processors because of buggy BIOS\n\t\t\t\tsupport, specifically around the suspend/resume\n\t\t\t\tpath).\n\n\trdt=\t\t[HW,X86,RDT]\n\t\t\tTurn on/off individual RDT features. List is:\n\t\t\tcmt, mbmtotal, mbmlocal, l3cat, l3cdp, l2cat, l2cdp,\n\t\t\tmba.\n\t\t\tE.g. to turn on cmt and turn off mba use:\n\t\t\t\trdt=cmt,!mba\n\n\treboot=\t\t[KNL]\n\t\t\tFormat (x86 or x86_64):\n\t\t\t\t[w[arm] | c[old] | h[ard] | s[oft] | g[pio]] \\\n\t\t\t\t[[,]s[mp]#### \\\n\t\t\t\t[[,]b[ios] | a[cpi] | k[bd] | t[riple] | e[fi] | p[ci]] \\\n\t\t\t\t[[,]f[orce]\n\t\t\tWhere reboot_mode is one of warm (soft) or cold (hard) or gpio\n\t\t\t\t\t(prefix with 'panic_' to set mode for panic\n\t\t\t\t\treboot only),\n\t\t\t      reboot_type is one of bios, acpi, kbd, triple, efi, or pci,\n\t\t\t      reboot_force is either force or not specified,\n\t\t\t      reboot_cpu is s[mp]#### with #### being the processor\n\t\t\t\t\tto be used for rebooting.\n\n\trefscale.holdoff= [KNL]\n\t\t\tSet test-start holdoff period.  The purpose of\n\t\t\tthis parameter is to delay the start of the\n\t\t\ttest until boot completes in order to avoid\n\t\t\tinterference.\n\n\trefscale.loops= [KNL]\n\t\t\tSet the number of loops over the synchronization\n\t\t\tprimitive under test.  Increasing this number\n\t\t\treduces noise due to loop start/end overhead,\n\t\t\tbut the default has already reduced the per-pass\n\t\t\tnoise to a handful of picoseconds on ca. 2020\n\t\t\tx86 laptops.\n\n\trefscale.nreaders= [KNL]\n\t\t\tSet number of readers.  The default value of -1\n\t\t\tselects N, where N is roughly 75% of the number\n\t\t\tof CPUs.  A value of zero is an interesting choice.\n\n\trefscale.nruns= [KNL]\n\t\t\tSet number of runs, each of which is dumped onto\n\t\t\tthe console log.\n\n\trefscale.readdelay= [KNL]\n\t\t\tSet the read-side critical-section duration,\n\t\t\tmeasured in microseconds.\n\n\trefscale.scale_type= [KNL]\n\t\t\tSpecify the read-protection implementation to test.\n\n\trefscale.shutdown= [KNL]\n\t\t\tShut down the system at the end of the performance\n\t\t\ttest.  This defaults to 1 (shut it down) when\n\t\t\trcuperf is built into the kernel and to 0 (leave\n\t\t\tit running) when rcuperf is built as a module.\n\n\trefscale.verbose= [KNL]\n\t\t\tEnable additional printk() statements.\n\n\trelax_domain_level=\n\t\t\t[KNL, SMP] Set scheduler's default relax_domain_level.\n\t\t\tSee Documentation/admin-guide/cgroup-v1/cpusets.rst.\n\n\treserve=\t[KNL,BUGS] Force kernel to ignore I/O ports or memory\n\t\t\tFormat: <base1>,<size1>[,<base2>,<size2>,...]\n\t\t\tReserve I/O ports or memory so the kernel won't use\n\t\t\tthem.  If <base> is less than 0x10000, the region\n\t\t\tis assumed to be I/O ports; otherwise it is memory.\n\n\treservetop=\t[X86-32]\n\t\t\tFormat: nn[KMG]\n\t\t\tReserves a hole at the top of the kernel virtual\n\t\t\taddress space.\n\n\treservelow=\t[X86]\n\t\t\tFormat: nn[K]\n\t\t\tSet the amount of memory to reserve for BIOS at\n\t\t\tthe bottom of the address space.\n\n\treset_devices\t[KNL] Force drivers to reset the underlying device\n\t\t\tduring initialization.\n\n\tresume=\t\t[SWSUSP]\n\t\t\tSpecify the partition device for software suspend\n\t\t\tFormat:\n\t\t\t{/dev/<dev> | PARTUUID=<uuid> | <int>:<int> | <hex>}\n\n\tresume_offset=\t[SWSUSP]\n\t\t\tSpecify the offset from the beginning of the partition\n\t\t\tgiven by \"resume=\" at which the swap header is located,\n\t\t\tin <PAGE_SIZE> units (needed only for swap files).\n\t\t\tSee  Documentation/power/swsusp-and-swap-files.rst\n\n\tresumedelay=\t[HIBERNATION] Delay (in seconds) to pause before attempting to\n\t\t\tread the resume files\n\n\tresumewait\t[HIBERNATION] Wait (indefinitely) for resume device to show up.\n\t\t\tUseful for devices that are detected asynchronously\n\t\t\t(e.g. USB and MMC devices).\n\n\thibernate=\t[HIBERNATION]\n\t\tnoresume\tDon't check if there's a hibernation image\n\t\t\t\tpresent during boot.\n\t\tnocompress\tDon't compress/decompress hibernation images.\n\t\tno\t\tDisable hibernation and resume.\n\t\tprotect_image\tTurn on image protection during restoration\n\t\t\t\t(that will set all pages holding image data\n\t\t\t\tduring restoration read-only).\n\n\tretain_initrd\t[RAM] Keep initrd memory after extraction\n\n\trfkill.default_state=\n\t\t0\t\"airplane mode\".  All wifi, bluetooth, wimax, gps, fm,\n\t\t\tetc. communication is blocked by default.\n\t\t1\tUnblocked.\n\n\trfkill.master_switch_mode=\n\t\t0\tThe \"airplane mode\" button does nothing.\n\t\t1\tThe \"airplane mode\" button toggles between everything\n\t\t\tblocked and the previous configuration.\n\t\t2\tThe \"airplane mode\" button toggles between everything\n\t\t\tblocked and everything unblocked.\n\n\trhash_entries=\t[KNL,NET]\n\t\t\tSet number of hash buckets for route cache\n\n\tring3mwait=disable\n\t\t\t[KNL] Disable ring 3 MONITOR/MWAIT feature on supported\n\t\t\tCPUs.\n\n\tro\t\t[KNL] Mount root device read-only on boot\n\n\trodata=\t\t[KNL]\n\t\ton\tMark read-only kernel memory as read-only (default).\n\t\toff\tLeave read-only kernel memory writable for debugging.\n\n\trockchip.usb_uart\n\t\t\tEnable the uart passthrough on the designated usb port\n\t\t\ton Rockchip SoCs. When active, the signals of the\n\t\t\tdebug-uart get routed to the D+ and D- pins of the usb\n\t\t\tport and the regular usb controller gets disabled.\n\n\troot=\t\t[KNL] Root filesystem\n\t\t\tSee name_to_dev_t comment in init/do_mounts.c.\n\n\trootdelay=\t[KNL] Delay (in seconds) to pause before attempting to\n\t\t\tmount the root filesystem\n\n\trootflags=\t[KNL] Set root filesystem mount option string\n\n\trootfstype=\t[KNL] Set root filesystem type\n\n\trootwait\t[KNL] Wait (indefinitely) for root device to show up.\n\t\t\tUseful for devices that are detected asynchronously\n\t\t\t(e.g. USB and MMC devices).\n\n\trproc_mem=nn[KMG][@address]\n\t\t\t[KNL,ARM,CMA] Remoteproc physical memory block.\n\t\t\tMemory area to be used by remote processor image,\n\t\t\tmanaged by CMA.\n\n\trw\t\t[KNL] Mount root device read-write on boot\n\n\tS\t\t[KNL] Run init in single mode\n\n\ts390_iommu=\t[HW,S390]\n\t\t\tSet s390 IOTLB flushing mode\n\t\tstrict\n\t\t\tWith strict flushing every unmap operation will result in\n\t\t\tan IOTLB flush. Default is lazy flushing before reuse,\n\t\t\twhich is faster.\n\n\tsa1100ir\t[NET]\n\t\t\tSee drivers/net/irda/sa1100_ir.c.\n\n\tsbni=\t\t[NET] Granch SBNI12 leased line adapter\n\n\tsched_debug\t[KNL] Enables verbose scheduler debug messages.\n\n\tschedstats=\t[KNL,X86] Enable or disable scheduled statistics.\n\t\t\tAllowed values are enable and disable. This feature\n\t\t\tincurs a small amount of overhead in the scheduler\n\t\t\tbut is useful for debugging and performance tuning.\n\n\tsched_thermal_decay_shift=\n\t\t\t[KNL, SMP] Set a decay shift for scheduler thermal\n\t\t\tpressure signal. Thermal pressure signal follows the\n\t\t\tdefault decay period of other scheduler pelt\n\t\t\tsignals(usually 32 ms but configurable). Setting\n\t\t\tsched_thermal_decay_shift will left shift the decay\n\t\t\tperiod for the thermal pressure signal by the shift\n\t\t\tvalue.\n\t\t\ti.e. with the default pelt decay period of 32 ms\n\t\t\tsched_thermal_decay_shift   thermal pressure decay pr\n\t\t\t\t1\t\t\t64 ms\n\t\t\t\t2\t\t\t128 ms\n\t\t\tand so on.\n\t\t\tFormat: integer between 0 and 10\n\t\t\tDefault is 0.\n\n\tskew_tick=\t[KNL] Offset the periodic timer tick per cpu to mitigate\n\t\t\txtime_lock contention on larger systems, and/or RCU lock\n\t\t\tcontention on all systems with CONFIG_MAXSMP set.\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\t0 -- disable. (may be 1 via CONFIG_CMDLINE=\"skew_tick=1\"\n\t\t\t1 -- enable.\n\t\t\tNote: increases power consumption, thus should only be\n\t\t\tenabled if running jitter sensitive (HPC/RT) workloads.\n\n\tsecurity=\t[SECURITY] Choose a legacy \"major\" security module to\n\t\t\tenable at boot. This has been deprecated by the\n\t\t\t\"lsm=\" parameter.\n\n\tselinux=\t[SELINUX] Disable or enable SELinux at boot time.\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\tSee security/selinux/Kconfig help text.\n\t\t\t0 -- disable.\n\t\t\t1 -- enable.\n\t\t\tDefault value is 1.\n\n\tapparmor=\t[APPARMOR] Disable or enable AppArmor at boot time\n\t\t\tFormat: { \"0\" | \"1\" }\n\t\t\tSee security/apparmor/Kconfig help text\n\t\t\t0 -- disable.\n\t\t\t1 -- enable.\n\t\t\tDefault value is set via kernel config option.\n\n\tserialnumber\t[BUGS=X86-32]\n\n\tshapers=\t[NET]\n\t\t\tMaximal number of shapers.\n\n\tsimeth=\t\t[IA-64]\n\tsimscsi=\n\n\tslram=\t\t[HW,MTD]\n\n\tslab_nomerge\t[MM]\n\t\t\tDisable merging of slabs with similar size. May be\n\t\t\tnecessary if there is some reason to distinguish\n\t\t\tallocs to different slabs, especially in hardened\n\t\t\tenvironments where the risk of heap overflows and\n\t\t\tlayout control by attackers can usually be\n\t\t\tfrustrated by disabling merging. This will reduce\n\t\t\tmost of the exposure of a heap attack to a single\n\t\t\tcache (risks via metadata attacks are mostly\n\t\t\tunchanged). Debug options disable merging on their\n\t\t\town.\n\t\t\tFor more information see Documentation/vm/slub.rst.\n\n\tslab_max_order=\t[MM, SLAB]\n\t\t\tDetermines the maximum allowed order for slabs.\n\t\t\tA high setting may cause OOMs due to memory\n\t\t\tfragmentation.  Defaults to 1 for systems with\n\t\t\tmore than 32MB of RAM, 0 otherwise.\n\n\tslub_debug[=options[,slabs][;[options[,slabs]]...]\t[MM, SLUB]\n\t\t\tEnabling slub_debug allows one to determine the\n\t\t\tculprit if slab objects become corrupted. Enabling\n\t\t\tslub_debug can create guard zones around objects and\n\t\t\tmay poison objects when not in use. Also tracks the\n\t\t\tlast alloc / free. For more information see\n\t\t\tDocumentation/vm/slub.rst.\n\n\tslub_memcg_sysfs=\t[MM, SLUB]\n\t\t\tDetermines whether to enable sysfs directories for\n\t\t\tmemory cgroup sub-caches. 1 to enable, 0 to disable.\n\t\t\tThe default is determined by CONFIG_SLUB_MEMCG_SYSFS_ON.\n\t\t\tEnabling this can lead to a very high number of\tdebug\n\t\t\tdirectories and files being created under\n\t\t\t/sys/kernel/slub.\n\n\tslub_max_order= [MM, SLUB]\n\t\t\tDetermines the maximum allowed order for slabs.\n\t\t\tA high setting may cause OOMs due to memory\n\t\t\tfragmentation. For more information see\n\t\t\tDocumentation/vm/slub.rst.\n\n\tslub_min_objects=\t[MM, SLUB]\n\t\t\tThe minimum number of objects per slab. SLUB will\n\t\t\tincrease the slab order up to slub_max_order to\n\t\t\tgenerate a sufficiently large slab able to contain\n\t\t\tthe number of objects indicated. The higher the number\n\t\t\tof objects the smaller the overhead of tracking slabs\n\t\t\tand the less frequently locks need to be acquired.\n\t\t\tFor more information see Documentation/vm/slub.rst.\n\n\tslub_min_order=\t[MM, SLUB]\n\t\t\tDetermines the minimum page order for slabs. Must be\n\t\t\tlower than slub_max_order.\n\t\t\tFor more information see Documentation/vm/slub.rst.\n\n\tslub_nomerge\t[MM, SLUB]\n\t\t\tSame with slab_nomerge. This is supported for legacy.\n\t\t\tSee slab_nomerge for more information.\n\n\tsmart2=\t\t[HW]\n\t\t\tFormat: <io1>[,<io2>[,...,<io8>]]\n\n\tsmsc-ircc2.nopnp\t[HW] Don't use PNP to discover SMC devices\n\tsmsc-ircc2.ircc_cfg=\t[HW] Device configuration I/O port\n\tsmsc-ircc2.ircc_sir=\t[HW] SIR base I/O port\n\tsmsc-ircc2.ircc_fir=\t[HW] FIR base I/O port\n\tsmsc-ircc2.ircc_irq=\t[HW] IRQ line\n\tsmsc-ircc2.ircc_dma=\t[HW] DMA channel\n\tsmsc-ircc2.ircc_transceiver= [HW] Transceiver type:\n\t\t\t\t0: Toshiba Satellite 1800 (GP data pin select)\n\t\t\t\t1: Fast pin select (default)\n\t\t\t\t2: ATC IRMode\n\n\tsmt\t\t[KNL,S390] Set the maximum number of threads (logical\n\t\t\tCPUs) to use per physical CPU on systems capable of\n\t\t\tsymmetric multithreading (SMT). Will be capped to the\n\t\t\tactual hardware limit.\n\t\t\tFormat: <integer>\n\t\t\tDefault: -1 (no limit)\n\n\tsoftlockup_panic=\n\t\t\t[KNL] Should the soft-lockup detector generate panics.\n\t\t\tFormat: 0 | 1\n\n\t\t\tA value of 1 instructs the soft-lockup detector\n\t\t\tto panic the machine when a soft-lockup occurs. It is\n\t\t\talso controlled by the kernel.softlockup_panic sysctl\n\t\t\tand CONFIG_BOOTPARAM_SOFTLOCKUP_PANIC, which is the\n\t\t\trespective build-time switch to that functionality.\n\n\tsoftlockup_all_cpu_backtrace=\n\t\t\t[KNL] Should the soft-lockup detector generate\n\t\t\tbacktraces on all cpus.\n\t\t\tFormat: 0 | 1\n\n\tsonypi.*=\t[HW] Sony Programmable I/O Control Device driver\n\t\t\tSee Documentation/admin-guide/laptops/sonypi.rst\n\n\tspectre_v2=\t[X86] Control mitigation of Spectre variant 2\n\t\t\t(indirect branch speculation) vulnerability.\n\t\t\tThe default operation protects the kernel from\n\t\t\tuser space attacks.\n\n\t\t\ton   - unconditionally enable, implies\n\t\t\t       spectre_v2_user=on\n\t\t\toff  - unconditionally disable, implies\n\t\t\t       spectre_v2_user=off\n\t\t\tauto - kernel detects whether your CPU model is\n\t\t\t       vulnerable\n\n\t\t\tSelecting 'on' will, and 'auto' may, choose a\n\t\t\tmitigation method at run time according to the\n\t\t\tCPU, the available microcode, the setting of the\n\t\t\tCONFIG_RETPOLINE configuration option, and the\n\t\t\tcompiler with which the kernel was built.\n\n\t\t\tSelecting 'on' will also enable the mitigation\n\t\t\tagainst user space to user space task attacks.\n\n\t\t\tSelecting 'off' will disable both the kernel and\n\t\t\tthe user space protections.\n\n\t\t\tSpecific mitigations can also be selected manually:\n\n\t\t\tretpoline\t  - replace indirect branches\n\t\t\tretpoline,generic - google's original retpoline\n\t\t\tretpoline,amd     - AMD-specific minimal thunk\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\tspectre_v2=auto.\n\n\tspectre_v2_user=\n\t\t\t[X86] Control mitigation of Spectre variant 2\n\t\t        (indirect branch speculation) vulnerability between\n\t\t        user space tasks\n\n\t\t\ton\t- Unconditionally enable mitigations. Is\n\t\t\t\t  enforced by spectre_v2=on\n\n\t\t\toff     - Unconditionally disable mitigations. Is\n\t\t\t\t  enforced by spectre_v2=off\n\n\t\t\tprctl   - Indirect branch speculation is enabled,\n\t\t\t\t  but mitigation can be enabled via prctl\n\t\t\t\t  per thread.  The mitigation control state\n\t\t\t\t  is inherited on fork.\n\n\t\t\tprctl,ibpb\n\t\t\t\t- Like \"prctl\" above, but only STIBP is\n\t\t\t\t  controlled per thread. IBPB is issued\n\t\t\t\t  always when switching between different user\n\t\t\t\t  space processes.\n\n\t\t\tseccomp\n\t\t\t\t- Same as \"prctl\" above, but all seccomp\n\t\t\t\t  threads will enable the mitigation unless\n\t\t\t\t  they explicitly opt out.\n\n\t\t\tseccomp,ibpb\n\t\t\t\t- Like \"seccomp\" above, but only STIBP is\n\t\t\t\t  controlled per thread. IBPB is issued\n\t\t\t\t  always when switching between different\n\t\t\t\t  user space processes.\n\n\t\t\tauto    - Kernel selects the mitigation depending on\n\t\t\t\t  the available CPU features and vulnerability.\n\n\t\t\tDefault mitigation:\n\t\t\tIf CONFIG_SECCOMP=y then \"seccomp\", otherwise \"prctl\"\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\tspectre_v2_user=auto.\n\n\tspec_store_bypass_disable=\n\t\t\t[HW] Control Speculative Store Bypass (SSB) Disable mitigation\n\t\t\t(Speculative Store Bypass vulnerability)\n\n\t\t\tCertain CPUs are vulnerable to an exploit against a\n\t\t\ta common industry wide performance optimization known\n\t\t\tas \"Speculative Store Bypass\" in which recent stores\n\t\t\tto the same memory location may not be observed by\n\t\t\tlater loads during speculative execution. The idea\n\t\t\tis that such stores are unlikely and that they can\n\t\t\tbe detected prior to instruction retirement at the\n\t\t\tend of a particular speculation execution window.\n\n\t\t\tIn vulnerable processors, the speculatively forwarded\n\t\t\tstore can be used in a cache side channel attack, for\n\t\t\texample to read memory to which the attacker does not\n\t\t\tdirectly have access (e.g. inside sandboxed code).\n\n\t\t\tThis parameter controls whether the Speculative Store\n\t\t\tBypass optimization is used.\n\n\t\t\tOn x86 the options are:\n\n\t\t\ton      - Unconditionally disable Speculative Store Bypass\n\t\t\toff     - Unconditionally enable Speculative Store Bypass\n\t\t\tauto    - Kernel detects whether the CPU model contains an\n\t\t\t\t  implementation of Speculative Store Bypass and\n\t\t\t\t  picks the most appropriate mitigation. If the\n\t\t\t\t  CPU is not vulnerable, \"off\" is selected. If the\n\t\t\t\t  CPU is vulnerable the default mitigation is\n\t\t\t\t  architecture and Kconfig dependent. See below.\n\t\t\tprctl   - Control Speculative Store Bypass per thread\n\t\t\t\t  via prctl. Speculative Store Bypass is enabled\n\t\t\t\t  for a process by default. The state of the control\n\t\t\t\t  is inherited on fork.\n\t\t\tseccomp - Same as \"prctl\" above, but all seccomp threads\n\t\t\t\t  will disable SSB unless they explicitly opt out.\n\n\t\t\tDefault mitigations:\n\t\t\tX86:\tIf CONFIG_SECCOMP=y \"seccomp\", otherwise \"prctl\"\n\n\t\t\tOn powerpc the options are:\n\n\t\t\ton,auto - On Power8 and Power9 insert a store-forwarding\n\t\t\t\t  barrier on kernel entry and exit. On Power7\n\t\t\t\t  perform a software flush on kernel entry and\n\t\t\t\t  exit.\n\t\t\toff\t- No action.\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\tspec_store_bypass_disable=auto.\n\n\tspia_io_base=\t[HW,MTD]\n\tspia_fio_base=\n\tspia_pedr=\n\tspia_peddr=\n\n\tsplit_lock_detect=\n\t\t\t[X86] Enable split lock detection\n\n\t\t\tWhen enabled (and if hardware support is present), atomic\n\t\t\tinstructions that access data across cache line\n\t\t\tboundaries will result in an alignment check exception.\n\n\t\t\toff\t- not enabled\n\n\t\t\twarn\t- the kernel will emit rate limited warnings\n\t\t\t\t  about applications triggering the #AC\n\t\t\t\t  exception. This mode is the default on CPUs\n\t\t\t\t  that supports split lock detection.\n\n\t\t\tfatal\t- the kernel will send SIGBUS to applications\n\t\t\t\t  that trigger the #AC exception.\n\n\t\t\tIf an #AC exception is hit in the kernel or in\n\t\t\tfirmware (i.e. not while executing in user mode)\n\t\t\tthe kernel will oops in either \"warn\" or \"fatal\"\n\t\t\tmode.\n\n\tsrbds=\t\t[X86,INTEL]\n\t\t\tControl the Special Register Buffer Data Sampling\n\t\t\t(SRBDS) mitigation.\n\n\t\t\tCertain CPUs are vulnerable to an MDS-like\n\t\t\texploit which can leak bits from the random\n\t\t\tnumber generator.\n\n\t\t\tBy default, this issue is mitigated by\n\t\t\tmicrocode.  However, the microcode fix can cause\n\t\t\tthe RDRAND and RDSEED instructions to become\n\t\t\tmuch slower.  Among other effects, this will\n\t\t\tresult in reduced throughput from /dev/urandom.\n\n\t\t\tThe microcode mitigation can be disabled with\n\t\t\tthe following option:\n\n\t\t\toff:    Disable mitigation and remove\n\t\t\t\tperformance impact to RDRAND and RDSEED\n\n\tsrcutree.counter_wrap_check [KNL]\n\t\t\tSpecifies how frequently to check for\n\t\t\tgrace-period sequence counter wrap for the\n\t\t\tsrcu_data structure's ->srcu_gp_seq_needed field.\n\t\t\tThe greater the number of bits set in this kernel\n\t\t\tparameter, the less frequently counter wrap will\n\t\t\tbe checked for.  Note that the bottom two bits\n\t\t\tare ignored.\n\n\tsrcutree.exp_holdoff [KNL]\n\t\t\tSpecifies how many nanoseconds must elapse\n\t\t\tsince the end of the last SRCU grace period for\n\t\t\ta given srcu_struct until the next normal SRCU\n\t\t\tgrace period will be considered for automatic\n\t\t\texpediting.  Set to zero to disable automatic\n\t\t\texpediting.\n\n\tssbd=\t\t[ARM64,HW]\n\t\t\tSpeculative Store Bypass Disable control\n\n\t\t\tOn CPUs that are vulnerable to the Speculative\n\t\t\tStore Bypass vulnerability and offer a\n\t\t\tfirmware based mitigation, this parameter\n\t\t\tindicates how the mitigation should be used:\n\n\t\t\tforce-on:  Unconditionally enable mitigation for\n\t\t\t\t   for both kernel and userspace\n\t\t\tforce-off: Unconditionally disable mitigation for\n\t\t\t\t   for both kernel and userspace\n\t\t\tkernel:    Always enable mitigation in the\n\t\t\t\t   kernel, and offer a prctl interface\n\t\t\t\t   to allow userspace to register its\n\t\t\t\t   interest in being mitigated too.\n\n\tstack_guard_gap=\t[MM]\n\t\t\toverride the default stack gap protection. The value\n\t\t\tis in page units and it defines how many pages prior\n\t\t\tto (for stacks growing down) resp. after (for stacks\n\t\t\tgrowing up) the main stack are reserved for no other\n\t\t\tmapping. Default value is 256 pages.\n\n\tstacktrace\t[FTRACE]\n\t\t\tEnabled the stack tracer on boot up.\n\n\tstacktrace_filter=[function-list]\n\t\t\t[FTRACE] Limit the functions that the stack tracer\n\t\t\twill trace at boot up. function-list is a comma separated\n\t\t\tlist of functions. This list can be changed at run\n\t\t\ttime by the stack_trace_filter file in the debugfs\n\t\t\ttracing directory. Note, this enables stack tracing\n\t\t\tand the stacktrace above is not needed.\n\n\tsti=\t\t[PARISC,HW]\n\t\t\tFormat: <num>\n\t\t\tSet the STI (builtin display/keyboard on the HP-PARISC\n\t\t\tmachines) console (graphic card) which should be used\n\t\t\tas the initial boot-console.\n\t\t\tSee also comment in drivers/video/console/sticore.c.\n\n\tsti_font=\t[HW]\n\t\t\tSee comment in drivers/video/console/sticore.c.\n\n\tstifb=\t\t[HW]\n\t\t\tFormat: bpp:<bpp1>[:<bpp2>[:<bpp3>...]]\n\n\tsunrpc.min_resvport=\n\tsunrpc.max_resvport=\n\t\t\t[NFS,SUNRPC]\n\t\t\tSunRPC servers often require that client requests\n\t\t\toriginate from a privileged port (i.e. a port in the\n\t\t\trange 0 < portnr < 1024).\n\t\t\tAn administrator who wishes to reserve some of these\n\t\t\tports for other uses may adjust the range that the\n\t\t\tkernel's sunrpc client considers to be privileged\n\t\t\tusing these two parameters to set the minimum and\n\t\t\tmaximum port values.\n\n\tsunrpc.svc_rpc_per_connection_limit=\n\t\t\t[NFS,SUNRPC]\n\t\t\tLimit the number of requests that the server will\n\t\t\tprocess in parallel from a single connection.\n\t\t\tThe default value is 0 (no limit).\n\n\tsunrpc.pool_mode=\n\t\t\t[NFS]\n\t\t\tControl how the NFS server code allocates CPUs to\n\t\t\tservice thread pools.  Depending on how many NICs\n\t\t\tyou have and where their interrupts are bound, this\n\t\t\toption will affect which CPUs will do NFS serving.\n\t\t\tNote: this parameter cannot be changed while the\n\t\t\tNFS server is running.\n\n\t\t\tauto\t    the server chooses an appropriate mode\n\t\t\t\t    automatically using heuristics\n\t\t\tglobal\t    a single global pool contains all CPUs\n\t\t\tpercpu\t    one pool for each CPU\n\t\t\tpernode\t    one pool for each NUMA node (equivalent\n\t\t\t\t    to global on non-NUMA machines)\n\n\tsunrpc.tcp_slot_table_entries=\n\tsunrpc.udp_slot_table_entries=\n\t\t\t[NFS,SUNRPC]\n\t\t\tSets the upper limit on the number of simultaneous\n\t\t\tRPC calls that can be sent from the client to a\n\t\t\tserver. Increasing these values may allow you to\n\t\t\timprove throughput, but will also increase the\n\t\t\tamount of memory reserved for use by the client.\n\n\tsuspend.pm_test_delay=\n\t\t\t[SUSPEND]\n\t\t\tSets the number of seconds to remain in a suspend test\n\t\t\tmode before resuming the system (see\n\t\t\t/sys/power/pm_test). Only available when CONFIG_PM_DEBUG\n\t\t\tis set. Default value is 5.\n\n\tsvm=\t\t[PPC]\n\t\t\tFormat: { on | off | y | n | 1 | 0 }\n\t\t\tThis parameter controls use of the Protected\n\t\t\tExecution Facility on pSeries.\n\n\tswapaccount=[0|1]\n\t\t\t[KNL] Enable accounting of swap in memory resource\n\t\t\tcontroller if no parameter or 1 is given or disable\n\t\t\tit if 0 is given (See Documentation/admin-guide/cgroup-v1/memory.rst)\n\n\tswiotlb=\t[ARM,IA-64,PPC,MIPS,X86]\n\t\t\tFormat: { <int> | force | noforce }\n\t\t\t<int> -- Number of I/O TLB slabs\n\t\t\tforce -- force using of bounce buffers even if they\n\t\t\t         wouldn't be automatically used by the kernel\n\t\t\tnoforce -- Never use bounce buffers (for debugging)\n\n\tswitches=\t[HW,M68k]\n\n\tsysctl.*=\t[KNL]\n\t\t\tSet a sysctl parameter, right before loading the init\n\t\t\tprocess, as if the value was written to the respective\n\t\t\t/proc/sys/... file. Both '.' and '/' are recognized as\n\t\t\tseparators. Unrecognized parameters and invalid values\n\t\t\tare reported in the kernel log. Sysctls registered\n\t\t\tlater by a loaded module cannot be set this way.\n\t\t\tExample: sysctl.vm.swappiness=40\n\n\tsysfs.deprecated=0|1 [KNL]\n\t\t\tEnable/disable old style sysfs layout for old udev\n\t\t\ton older distributions. When this option is enabled\n\t\t\tvery new udev will not work anymore. When this option\n\t\t\tis disabled (or CONFIG_SYSFS_DEPRECATED not compiled)\n\t\t\tin older udev will not work anymore.\n\t\t\tDefault depends on CONFIG_SYSFS_DEPRECATED_V2 set in\n\t\t\tthe kernel configuration.\n\n\tsysrq_always_enabled\n\t\t\t[KNL]\n\t\t\tIgnore sysrq setting - this boot parameter will\n\t\t\tneutralize any effect of /proc/sys/kernel/sysrq.\n\t\t\tUseful for debugging.\n\n\ttcpmhash_entries= [KNL,NET]\n\t\t\tSet the number of tcp_metrics_hash slots.\n\t\t\tDefault value is 8192 or 16384 depending on total\n\t\t\tram pages. This is used to specify the TCP metrics\n\t\t\tcache size. See Documentation/networking/ip-sysctl.rst\n\t\t\t\"tcp_no_metrics_save\" section for more details.\n\n\ttdfx=\t\t[HW,DRM]\n\n\ttest_suspend=\t[SUSPEND][,N]\n\t\t\tSpecify \"mem\" (for Suspend-to-RAM) or \"standby\" (for\n\t\t\tstandby suspend) or \"freeze\" (for suspend type freeze)\n\t\t\tas the system sleep state during system startup with\n\t\t\tthe optional capability to repeat N number of times.\n\t\t\tThe system is woken from this state using a\n\t\t\twakeup-capable RTC alarm.\n\n\tthash_entries=\t[KNL,NET]\n\t\t\tSet number of hash buckets for TCP connection\n\n\tthermal.act=\t[HW,ACPI]\n\t\t\t-1: disable all active trip points in all thermal zones\n\t\t\t<degrees C>: override all lowest active trip points\n\n\tthermal.crt=\t[HW,ACPI]\n\t\t\t-1: disable all critical trip points in all thermal zones\n\t\t\t<degrees C>: override all critical trip points\n\n\tthermal.nocrt=\t[HW,ACPI]\n\t\t\tSet to disable actions on ACPI thermal zone\n\t\t\tcritical and hot trip points.\n\n\tthermal.off=\t[HW,ACPI]\n\t\t\t1: disable ACPI thermal control\n\n\tthermal.psv=\t[HW,ACPI]\n\t\t\t-1: disable all passive trip points\n\t\t\t<degrees C>: override all passive trip points to this\n\t\t\tvalue\n\n\tthermal.tzp=\t[HW,ACPI]\n\t\t\tSpecify global default ACPI thermal zone polling rate\n\t\t\t<deci-seconds>: poll all this frequency\n\t\t\t0: no polling (default)\n\n\tthreadirqs\t[KNL]\n\t\t\tForce threading of all interrupt handlers except those\n\t\t\tmarked explicitly IRQF_NO_THREAD.\n\n\ttopology=\t[S390]\n\t\t\tFormat: {off | on}\n\t\t\tSpecify if the kernel should make use of the cpu\n\t\t\ttopology information if the hardware supports this.\n\t\t\tThe scheduler will make use of this information and\n\t\t\te.g. base its process migration decisions on it.\n\t\t\tDefault is on.\n\n\ttopology_updates= [KNL, PPC, NUMA]\n\t\t\tFormat: {off}\n\t\t\tSpecify if the kernel should ignore (off)\n\t\t\ttopology updates sent by the hypervisor to this\n\t\t\tLPAR.\n\n\ttorture.disable_onoff_at_boot= [KNL]\n\t\t\tPrevent the CPU-hotplug component of torturing\n\t\t\tuntil after init has spawned.\n\n\ttorture.ftrace_dump_at_shutdown= [KNL]\n\t\t\tDump the ftrace buffer at torture-test shutdown,\n\t\t\teven if there were no errors.  This can be a\n\t\t\tvery costly operation when many torture tests\n\t\t\tare running concurrently, especially on systems\n\t\t\twith rotating-rust storage.\n\n\ttp720=\t\t[HW,PS2]\n\n\ttpm_suspend_pcr=[HW,TPM]\n\t\t\tFormat: integer pcr id\n\t\t\tSpecify that at suspend time, the tpm driver\n\t\t\tshould extend the specified pcr with zeros,\n\t\t\tas a workaround for some chips which fail to\n\t\t\tflush the last written pcr on TPM_SaveState.\n\t\t\tThis will guarantee that all the other pcrs\n\t\t\tare saved.\n\n\ttrace_buf_size=nn[KMG]\n\t\t\t[FTRACE] will set tracing buffer size on each cpu.\n\n\ttrace_event=[event-list]\n\t\t\t[FTRACE] Set and start specified trace events in order\n\t\t\tto facilitate early boot debugging. The event-list is a\n\t\t\tcomma separated list of trace events to enable. See\n\t\t\talso Documentation/trace/events.rst\n\n\ttrace_options=[option-list]\n\t\t\t[FTRACE] Enable or disable tracer options at boot.\n\t\t\tThe option-list is a comma delimited list of options\n\t\t\tthat can be enabled or disabled just as if you were\n\t\t\tto echo the option name into\n\n\t\t\t    /sys/kernel/debug/tracing/trace_options\n\n\t\t\tFor example, to enable stacktrace option (to dump the\n\t\t\tstack trace of each event), add to the command line:\n\n\t\t\t      trace_options=stacktrace\n\n\t\t\tSee also Documentation/trace/ftrace.rst \"trace options\"\n\t\t\tsection.\n\n\ttp_printk[FTRACE]\n\t\t\tHave the tracepoints sent to printk as well as the\n\t\t\ttracing ring buffer. This is useful for early boot up\n\t\t\twhere the system hangs or reboots and does not give the\n\t\t\toption for reading the tracing buffer or performing a\n\t\t\tftrace_dump_on_oops.\n\n\t\t\tTo turn off having tracepoints sent to printk,\n\t\t\t echo 0 > /proc/sys/kernel/tracepoint_printk\n\t\t\tNote, echoing 1 into this file without the\n\t\t\ttracepoint_printk kernel cmdline option has no effect.\n\n\t\t\t** CAUTION **\n\n\t\t\tHaving tracepoints sent to printk() and activating high\n\t\t\tfrequency tracepoints such as irq or sched, can cause\n\t\t\tthe system to live lock.\n\n\ttraceoff_on_warning\n\t\t\t[FTRACE] enable this option to disable tracing when a\n\t\t\twarning is hit. This turns off \"tracing_on\". Tracing can\n\t\t\tbe enabled again by echoing '1' into the \"tracing_on\"\n\t\t\tfile located in /sys/kernel/debug/tracing/\n\n\t\t\tThis option is useful, as it disables the trace before\n\t\t\tthe WARNING dump is called, which prevents the trace to\n\t\t\tbe filled with content caused by the warning output.\n\n\t\t\tThis option can also be set at run time via the sysctl\n\t\t\toption:  kernel/traceoff_on_warning\n\n\ttransparent_hugepage=\n\t\t\t[KNL]\n\t\t\tFormat: [always|madvise|never]\n\t\t\tCan be used to control the default behavior of the system\n\t\t\twith respect to transparent hugepages.\n\t\t\tSee Documentation/admin-guide/mm/transhuge.rst\n\t\t\tfor more details.\n\n\ttsc=\t\tDisable clocksource stability checks for TSC.\n\t\t\tFormat: <string>\n\t\t\t[x86] reliable: mark tsc clocksource as reliable, this\n\t\t\tdisables clocksource verification at runtime, as well\n\t\t\tas the stability checks done at bootup.\tUsed to enable\n\t\t\thigh-resolution timer mode on older hardware, and in\n\t\t\tvirtualized environment.\n\t\t\t[x86] noirqtime: Do not use TSC to do irq accounting.\n\t\t\tUsed to run time disable IRQ_TIME_ACCOUNTING on any\n\t\t\tplatforms where RDTSC is slow and this accounting\n\t\t\tcan add overhead.\n\t\t\t[x86] unstable: mark the TSC clocksource as unstable, this\n\t\t\tmarks the TSC unconditionally unstable at bootup and\n\t\t\tavoids any further wobbles once the TSC watchdog notices.\n\t\t\t[x86] nowatchdog: disable clocksource watchdog. Used\n\t\t\tin situations with strict latency requirements (where\n\t\t\tinterruptions from clocksource watchdog are not\n\t\t\tacceptable).\n\n\ttsc_early_khz=  [X86] Skip early TSC calibration and use the given\n\t\t\tvalue instead. Useful when the early TSC frequency discovery\n\t\t\tprocedure is not reliable, such as on overclocked systems\n\t\t\twith CPUID.16h support and partial CPUID.15h support.\n\t\t\tFormat: <unsigned int>\n\n\ttsx=\t\t[X86] Control Transactional Synchronization\n\t\t\tExtensions (TSX) feature in Intel processors that\n\t\t\tsupport TSX control.\n\n\t\t\tThis parameter controls the TSX feature. The options are:\n\n\t\t\ton\t- Enable TSX on the system. Although there are\n\t\t\t\tmitigations for all known security vulnerabilities,\n\t\t\t\tTSX has been known to be an accelerator for\n\t\t\t\tseveral previous speculation-related CVEs, and\n\t\t\t\tso there may be unknown\tsecurity risks associated\n\t\t\t\twith leaving it enabled.\n\n\t\t\toff\t- Disable TSX on the system. (Note that this\n\t\t\t\toption takes effect only on newer CPUs which are\n\t\t\t\tnot vulnerable to MDS, i.e., have\n\t\t\t\tMSR_IA32_ARCH_CAPABILITIES.MDS_NO=1 and which get\n\t\t\t\tthe new IA32_TSX_CTRL MSR through a microcode\n\t\t\t\tupdate. This new MSR allows for the reliable\n\t\t\t\tdeactivation of the TSX functionality.)\n\n\t\t\tauto\t- Disable TSX if X86_BUG_TAA is present,\n\t\t\t\t  otherwise enable TSX on the system.\n\n\t\t\tNot specifying this option is equivalent to tsx=off.\n\n\t\t\tSee Documentation/admin-guide/hw-vuln/tsx_async_abort.rst\n\t\t\tfor more details.\n\n\ttsx_async_abort= [X86,INTEL] Control mitigation for the TSX Async\n\t\t\tAbort (TAA) vulnerability.\n\n\t\t\tSimilar to Micro-architectural Data Sampling (MDS)\n\t\t\tcertain CPUs that support Transactional\n\t\t\tSynchronization Extensions (TSX) are vulnerable to an\n\t\t\texploit against CPU internal buffers which can forward\n\t\t\tinformation to a disclosure gadget under certain\n\t\t\tconditions.\n\n\t\t\tIn vulnerable processors, the speculatively forwarded\n\t\t\tdata can be used in a cache side channel attack, to\n\t\t\taccess data to which the attacker does not have direct\n\t\t\taccess.\n\n\t\t\tThis parameter controls the TAA mitigation.  The\n\t\t\toptions are:\n\n\t\t\tfull       - Enable TAA mitigation on vulnerable CPUs\n\t\t\t\t     if TSX is enabled.\n\n\t\t\tfull,nosmt - Enable TAA mitigation and disable SMT on\n\t\t\t\t     vulnerable CPUs. If TSX is disabled, SMT\n\t\t\t\t     is not disabled because CPU is not\n\t\t\t\t     vulnerable to cross-thread TAA attacks.\n\t\t\toff        - Unconditionally disable TAA mitigation\n\n\t\t\tOn MDS-affected machines, tsx_async_abort=off can be\n\t\t\tprevented by an active MDS mitigation as both vulnerabilities\n\t\t\tare mitigated with the same mechanism so in order to disable\n\t\t\tthis mitigation, you need to specify mds=off too.\n\n\t\t\tNot specifying this option is equivalent to\n\t\t\ttsx_async_abort=full.  On CPUs which are MDS affected\n\t\t\tand deploy MDS mitigation, TAA mitigation is not\n\t\t\trequired and doesn't provide any additional\n\t\t\tmitigation.\n\n\t\t\tFor details see:\n\t\t\tDocumentation/admin-guide/hw-vuln/tsx_async_abort.rst\n\n\tturbografx.map[2|3]=\t[HW,JOY]\n\t\t\tTurboGraFX parallel port interface\n\t\t\tFormat:\n\t\t\t<port#>,<js1>,<js2>,<js3>,<js4>,<js5>,<js6>,<js7>\n\t\t\tSee also Documentation/input/devices/joystick-parport.rst\n\n\tudbg-immortal\t[PPC] When debugging early kernel crashes that\n\t\t\thappen after console_init() and before a proper\n\t\t\tconsole driver takes over, this boot options might\n\t\t\thelp \"seeing\" what's going on.\n\n\tuhash_entries=\t[KNL,NET]\n\t\t\tSet number of hash buckets for UDP/UDP-Lite connections\n\n\tuhci-hcd.ignore_oc=\n\t\t\t[USB] Ignore overcurrent events (default N).\n\t\t\tSome badly-designed motherboards generate lots of\n\t\t\tbogus events, for ports that aren't wired to\n\t\t\tanything.  Set this parameter to avoid log spamming.\n\t\t\tNote that genuine overcurrent events won't be\n\t\t\treported either.\n\n\tunknown_nmi_panic\n\t\t\t[X86] Cause panic on unknown NMI.\n\n\tusbcore.authorized_default=\n\t\t\t[USB] Default USB device authorization:\n\t\t\t(default -1 = authorized except for wireless USB,\n\t\t\t0 = not authorized, 1 = authorized, 2 = authorized\n\t\t\tif device connected to internal port)\n\n\tusbcore.autosuspend=\n\t\t\t[USB] The autosuspend time delay (in seconds) used\n\t\t\tfor newly-detected USB devices (default 2).  This\n\t\t\tis the time required before an idle device will be\n\t\t\tautosuspended.  Devices for which the delay is set\n\t\t\tto a negative value won't be autosuspended at all.\n\n\tusbcore.usbfs_snoop=\n\t\t\t[USB] Set to log all usbfs traffic (default 0 = off).\n\n\tusbcore.usbfs_snoop_max=\n\t\t\t[USB] Maximum number of bytes to snoop in each URB\n\t\t\t(default = 65536).\n\n\tusbcore.blinkenlights=\n\t\t\t[USB] Set to cycle leds on hubs (default 0 = off).\n\n\tusbcore.old_scheme_first=\n\t\t\t[USB] Start with the old device initialization\n\t\t\tscheme (default 0 = off).\n\n\tusbcore.usbfs_memory_mb=\n\t\t\t[USB] Memory limit (in MB) for buffers allocated by\n\t\t\tusbfs (default = 16, 0 = max = 2047).\n\n\tusbcore.use_both_schemes=\n\t\t\t[USB] Try the other device initialization scheme\n\t\t\tif the first one fails (default 1 = enabled).\n\n\tusbcore.initial_descriptor_timeout=\n\t\t\t[USB] Specifies timeout for the initial 64-byte\n\t\t\tUSB_REQ_GET_DESCRIPTOR request in milliseconds\n\t\t\t(default 5000 = 5.0 seconds).\n\n\tusbcore.nousb\t[USB] Disable the USB subsystem\n\n\tusbcore.quirks=\n\t\t\t[USB] A list of quirk entries to augment the built-in\n\t\t\tusb core quirk list. List entries are separated by\n\t\t\tcommas. Each entry has the form\n\t\t\tVendorID:ProductID:Flags. The IDs are 4-digit hex\n\t\t\tnumbers and Flags is a set of letters. Each letter\n\t\t\twill change the built-in quirk; setting it if it is\n\t\t\tclear and clearing it if it is set. The letters have\n\t\t\tthe following meanings:\n\t\t\t\ta = USB_QUIRK_STRING_FETCH_255 (string\n\t\t\t\t\tdescriptors must not be fetched using\n\t\t\t\t\ta 255-byte read);\n\t\t\t\tb = USB_QUIRK_RESET_RESUME (device can't resume\n\t\t\t\t\tcorrectly so reset it instead);\n\t\t\t\tc = USB_QUIRK_NO_SET_INTF (device can't handle\n\t\t\t\t\tSet-Interface requests);\n\t\t\t\td = USB_QUIRK_CONFIG_INTF_STRINGS (device can't\n\t\t\t\t\thandle its Configuration or Interface\n\t\t\t\t\tstrings);\n\t\t\t\te = USB_QUIRK_RESET (device can't be reset\n\t\t\t\t\t(e.g morph devices), don't use reset);\n\t\t\t\tf = USB_QUIRK_HONOR_BNUMINTERFACES (device has\n\t\t\t\t\tmore interface descriptions than the\n\t\t\t\t\tbNumInterfaces count, and can't handle\n\t\t\t\t\ttalking to these interfaces);\n\t\t\t\tg = USB_QUIRK_DELAY_INIT (device needs a pause\n\t\t\t\t\tduring initialization, after we read\n\t\t\t\t\tthe device descriptor);\n\t\t\t\th = USB_QUIRK_LINEAR_UFRAME_INTR_BINTERVAL (For\n\t\t\t\t\thigh speed and super speed interrupt\n\t\t\t\t\tendpoints, the USB 2.0 and USB 3.0 spec\n\t\t\t\t\trequire the interval in microframes (1\n\t\t\t\t\tmicroframe = 125 microseconds) to be\n\t\t\t\t\tcalculated as interval = 2 ^\n\t\t\t\t\t(bInterval-1).\n\t\t\t\t\tDevices with this quirk report their\n\t\t\t\t\tbInterval as the result of this\n\t\t\t\t\tcalculation instead of the exponent\n\t\t\t\t\tvariable used in the calculation);\n\t\t\t\ti = USB_QUIRK_DEVICE_QUALIFIER (device can't\n\t\t\t\t\thandle device_qualifier descriptor\n\t\t\t\t\trequests);\n\t\t\t\tj = USB_QUIRK_IGNORE_REMOTE_WAKEUP (device\n\t\t\t\t\tgenerates spurious wakeup, ignore\n\t\t\t\t\tremote wakeup capability);\n\t\t\t\tk = USB_QUIRK_NO_LPM (device can't handle Link\n\t\t\t\t\tPower Management);\n\t\t\t\tl = USB_QUIRK_LINEAR_FRAME_INTR_BINTERVAL\n\t\t\t\t\t(Device reports its bInterval as linear\n\t\t\t\t\tframes instead of the USB 2.0\n\t\t\t\t\tcalculation);\n\t\t\t\tm = USB_QUIRK_DISCONNECT_SUSPEND (Device needs\n\t\t\t\t\tto be disconnected before suspend to\n\t\t\t\t\tprevent spurious wakeup);\n\t\t\t\tn = USB_QUIRK_DELAY_CTRL_MSG (Device needs a\n\t\t\t\t\tpause after every control message);\n\t\t\t\to = USB_QUIRK_HUB_SLOW_RESET (Hub needs extra\n\t\t\t\t\tdelay after resetting its port);\n\t\t\tExample: quirks=0781:5580:bk,0a5c:5834:gij\n\n\tusbhid.mousepoll=\n\t\t\t[USBHID] The interval which mice are to be polled at.\n\n\tusbhid.jspoll=\n\t\t\t[USBHID] The interval which joysticks are to be polled at.\n\n\tusbhid.kbpoll=\n\t\t\t[USBHID] The interval which keyboards are to be polled at.\n\n\tusb-storage.delay_use=\n\t\t\t[UMS] The delay in seconds before a new device is\n\t\t\tscanned for Logical Units (default 1).\n\n\tusb-storage.quirks=\n\t\t\t[UMS] A list of quirks entries to supplement or\n\t\t\toverride the built-in unusual_devs list.  List\n\t\t\tentries are separated by commas.  Each entry has\n\t\t\tthe form VID:PID:Flags where VID and PID are Vendor\n\t\t\tand Product ID values (4-digit hex numbers) and\n\t\t\tFlags is a set of characters, each corresponding\n\t\t\tto a common usb-storage quirk flag as follows:\n\t\t\t\ta = SANE_SENSE (collect more than 18 bytes\n\t\t\t\t\tof sense data, not on uas);\n\t\t\t\tb = BAD_SENSE (don't collect more than 18\n\t\t\t\t\tbytes of sense data, not on uas);\n\t\t\t\tc = FIX_CAPACITY (decrease the reported\n\t\t\t\t\tdevice capacity by one sector);\n\t\t\t\td = NO_READ_DISC_INFO (don't use\n\t\t\t\t\tREAD_DISC_INFO command, not on uas);\n\t\t\t\te = NO_READ_CAPACITY_16 (don't use\n\t\t\t\t\tREAD_CAPACITY_16 command);\n\t\t\t\tf = NO_REPORT_OPCODES (don't use report opcodes\n\t\t\t\t\tcommand, uas only);\n\t\t\t\tg = MAX_SECTORS_240 (don't transfer more than\n\t\t\t\t\t240 sectors at a time, uas only);\n\t\t\t\th = CAPACITY_HEURISTICS (decrease the\n\t\t\t\t\treported device capacity by one\n\t\t\t\t\tsector if the number is odd);\n\t\t\t\ti = IGNORE_DEVICE (don't bind to this\n\t\t\t\t\tdevice);\n\t\t\t\tj = NO_REPORT_LUNS (don't use report luns\n\t\t\t\t\tcommand, uas only);\n\t\t\t\tl = NOT_LOCKABLE (don't try to lock and\n\t\t\t\t\tunlock ejectable media, not on uas);\n\t\t\t\tm = MAX_SECTORS_64 (don't transfer more\n\t\t\t\t\tthan 64 sectors = 32 KB at a time,\n\t\t\t\t\tnot on uas);\n\t\t\t\tn = INITIAL_READ10 (force a retry of the\n\t\t\t\t\tinitial READ(10) command, not on uas);\n\t\t\t\to = CAPACITY_OK (accept the capacity\n\t\t\t\t\treported by the device, not on uas);\n\t\t\t\tp = WRITE_CACHE (the device cache is ON\n\t\t\t\t\tby default, not on uas);\n\t\t\t\tr = IGNORE_RESIDUE (the device reports\n\t\t\t\t\tbogus residue values, not on uas);\n\t\t\t\ts = SINGLE_LUN (the device has only one\n\t\t\t\t\tLogical Unit);\n\t\t\t\tt = NO_ATA_1X (don't allow ATA(12) and ATA(16)\n\t\t\t\t\tcommands, uas only);\n\t\t\t\tu = IGNORE_UAS (don't bind to the uas driver);\n\t\t\t\tw = NO_WP_DETECT (don't test whether the\n\t\t\t\t\tmedium is write-protected).\n\t\t\t\ty = ALWAYS_SYNC (issue a SYNCHRONIZE_CACHE\n\t\t\t\t\teven if the device claims no cache,\n\t\t\t\t\tnot on uas)\n\t\t\tExample: quirks=0419:aaf5:rl,0421:0433:rc\n\n\tuser_debug=\t[KNL,ARM]\n\t\t\tFormat: <int>\n\t\t\tSee arch/arm/Kconfig.debug help text.\n\t\t\t\t 1 - undefined instruction events\n\t\t\t\t 2 - system calls\n\t\t\t\t 4 - invalid data aborts\n\t\t\t\t 8 - SIGSEGV faults\n\t\t\t\t16 - SIGBUS faults\n\t\t\tExample: user_debug=31\n\n\tuserpte=\n\t\t\t[X86] Flags controlling user PTE allocations.\n\n\t\t\t\tnohigh = do not allocate PTE pages in\n\t\t\t\t\tHIGHMEM regardless of setting\n\t\t\t\t\tof CONFIG_HIGHPTE.\n\n\tvdso=\t\t[X86,SH]\n\t\t\tOn X86_32, this is an alias for vdso32=.  Otherwise:\n\n\t\t\tvdso=1: enable VDSO (the default)\n\t\t\tvdso=0: disable VDSO mapping\n\n\tvdso32=\t\t[X86] Control the 32-bit vDSO\n\t\t\tvdso32=1: enable 32-bit VDSO\n\t\t\tvdso32=0 or vdso32=2: disable 32-bit VDSO\n\n\t\t\tSee the help text for CONFIG_COMPAT_VDSO for more\n\t\t\tdetails.  If CONFIG_COMPAT_VDSO is set, the default is\n\t\t\tvdso32=0; otherwise, the default is vdso32=1.\n\n\t\t\tFor compatibility with older kernels, vdso32=2 is an\n\t\t\talias for vdso32=0.\n\n\t\t\tTry vdso32=0 if you encounter an error that says:\n\t\t\tdl_main: Assertion `(void *) ph->p_vaddr == _rtld_local._dl_sysinfo_dso' failed!\n\n\tvector=\t\t[IA-64,SMP]\n\t\t\tvector=percpu: enable percpu vector domain\n\n\tvideo=\t\t[FB] Frame buffer configuration\n\t\t\tSee Documentation/fb/modedb.rst.\n\n\tvideo.brightness_switch_enabled= [0,1]\n\t\t\tIf set to 1, on receiving an ACPI notify event\n\t\t\tgenerated by hotkey, video driver will adjust brightness\n\t\t\tlevel and then send out the event to user space through\n\t\t\tthe allocated input device; If set to 0, video driver\n\t\t\twill only send out the event without touching backlight\n\t\t\tbrightness level.\n\t\t\tdefault: 1\n\n\tvirtio_mmio.device=\n\t\t\t[VMMIO] Memory mapped virtio (platform) device.\n\n\t\t\t\t<size>@<baseaddr>:<irq>[:<id>]\n\t\t\twhere:\n\t\t\t\t<size>     := size (can use standard suffixes\n\t\t\t\t\t\tlike K, M and G)\n\t\t\t\t<baseaddr> := physical base address\n\t\t\t\t<irq>      := interrupt number (as passed to\n\t\t\t\t\t\trequest_irq())\n\t\t\t\t<id>       := (optional) platform device id\n\t\t\texample:\n\t\t\t\tvirtio_mmio.device=1K@0x100b0000:48:7\n\n\t\t\tCan be used multiple times for multiple devices.\n\n\tvga=\t\t[BOOT,X86-32] Select a particular video mode\n\t\t\tSee Documentation/x86/boot.rst and\n\t\t\tDocumentation/admin-guide/svga.rst.\n\t\t\tUse vga=ask for menu.\n\t\t\tThis is actually a boot loader parameter; the value is\n\t\t\tpassed to the kernel using a special protocol.\n\n\tvm_debug[=options]\t[KNL] Available with CONFIG_DEBUG_VM=y.\n\t\t\tMay slow down system boot speed, especially when\n\t\t\tenabled on systems with a large amount of memory.\n\t\t\tAll options are enabled by default, and this\n\t\t\tinterface is meant to allow for selectively\n\t\t\tenabling or disabling specific virtual memory\n\t\t\tdebugging features.\n\n\t\t\tAvailable options are:\n\t\t\t  P\tEnable page structure init time poisoning\n\t\t\t  -\tDisable all of the above options\n\n\tvmalloc=nn[KMG]\t[KNL,BOOT] Forces the vmalloc area to have an exact\n\t\t\tsize of <nn>. This can be used to increase the\n\t\t\tminimum size (128MB on x86). It can also be used to\n\t\t\tdecrease the size and leave more room for directly\n\t\t\tmapped kernel RAM.\n\n\tvmcp_cma=nn[MG]\t[KNL,S390]\n\t\t\tSets the memory size reserved for contiguous memory\n\t\t\tallocations for the vmcp device driver.\n\n\tvmhalt=\t\t[KNL,S390] Perform z/VM CP command after system halt.\n\t\t\tFormat: <command>\n\n\tvmpanic=\t[KNL,S390] Perform z/VM CP command after kernel panic.\n\t\t\tFormat: <command>\n\n\tvmpoff=\t\t[KNL,S390] Perform z/VM CP command after power off.\n\t\t\tFormat: <command>\n\n\tvsyscall=\t[X86-64]\n\t\t\tControls the behavior of vsyscalls (i.e. calls to\n\t\t\tfixed addresses of 0xffffffffff600x00 from legacy\n\t\t\tcode).  Most statically-linked binaries and older\n\t\t\tversions of glibc use these calls.  Because these\n\t\t\tfunctions are at fixed addresses, they make nice\n\t\t\ttargets for exploits that can control RIP.\n\n\t\t\temulate     [default] Vsyscalls turn into traps and are\n\t\t\t            emulated reasonably safely.  The vsyscall\n\t\t\t\t    page is readable.\n\n\t\t\txonly       Vsyscalls turn into traps and are\n\t\t\t            emulated reasonably safely.  The vsyscall\n\t\t\t\t    page is not readable.\n\n\t\t\tnone        Vsyscalls don't work at all.  This makes\n\t\t\t            them quite hard to use for exploits but\n\t\t\t            might break your system.\n\n\tvt.color=\t[VT] Default text color.\n\t\t\tFormat: 0xYX, X = foreground, Y = background.\n\t\t\tDefault: 0x07 = light gray on black.\n\n\tvt.cur_default=\t[VT] Default cursor shape.\n\t\t\tFormat: 0xCCBBAA, where AA, BB, and CC are the same as\n\t\t\tthe parameters of the <Esc>[?A;B;Cc escape sequence;\n\t\t\tsee VGA-softcursor.txt. Default: 2 = underline.\n\n\tvt.default_blu=\t[VT]\n\t\t\tFormat: <blue0>,<blue1>,<blue2>,...,<blue15>\n\t\t\tChange the default blue palette of the console.\n\t\t\tThis is a 16-member array composed of values\n\t\t\tranging from 0-255.\n\n\tvt.default_grn=\t[VT]\n\t\t\tFormat: <green0>,<green1>,<green2>,...,<green15>\n\t\t\tChange the default green palette of the console.\n\t\t\tThis is a 16-member array composed of values\n\t\t\tranging from 0-255.\n\n\tvt.default_red=\t[VT]\n\t\t\tFormat: <red0>,<red1>,<red2>,...,<red15>\n\t\t\tChange the default red palette of the console.\n\t\t\tThis is a 16-member array composed of values\n\t\t\tranging from 0-255.\n\n\tvt.default_utf8=\n\t\t\t[VT]\n\t\t\tFormat=<0|1>\n\t\t\tSet system-wide default UTF-8 mode for all tty's.\n\t\t\tDefault is 1, i.e. UTF-8 mode is enabled for all\n\t\t\tnewly opened terminals.\n\n\tvt.global_cursor_default=\n\t\t\t[VT]\n\t\t\tFormat=<-1|0|1>\n\t\t\tSet system-wide default for whether a cursor\n\t\t\tis shown on new VTs. Default is -1,\n\t\t\ti.e. cursors will be created by default unless\n\t\t\toverridden by individual drivers. 0 will hide\n\t\t\tcursors, 1 will display them.\n\n\tvt.italic=\t[VT] Default color for italic text; 0-15.\n\t\t\tDefault: 2 = green.\n\n\tvt.underline=\t[VT] Default color for underlined text; 0-15.\n\t\t\tDefault: 3 = cyan.\n\n\twatchdog timers\t[HW,WDT] For information on watchdog timers,\n\t\t\tsee Documentation/watchdog/watchdog-parameters.rst\n\t\t\tor other driver-specific files in the\n\t\t\tDocumentation/watchdog/ directory.\n\n\twatchdog_thresh=\n\t\t\t[KNL]\n\t\t\tSet the hard lockup detector stall duration\n\t\t\tthreshold in seconds. The soft lockup detector\n\t\t\tthreshold is set to twice the value. A value of 0\n\t\t\tdisables both lockup detectors. Default is 10\n\t\t\tseconds.\n\n\tworkqueue.watchdog_thresh=\n\t\t\tIf CONFIG_WQ_WATCHDOG is configured, workqueue can\n\t\t\twarn stall conditions and dump internal state to\n\t\t\thelp debugging.  0 disables workqueue stall\n\t\t\tdetection; otherwise, it's the stall threshold\n\t\t\tduration in seconds.  The default value is 30 and\n\t\t\tit can be updated at runtime by writing to the\n\t\t\tcorresponding sysfs file.\n\n\tworkqueue.disable_numa\n\t\t\tBy default, all work items queued to unbound\n\t\t\tworkqueues are affine to the NUMA nodes they're\n\t\t\tissued on, which results in better behavior in\n\t\t\tgeneral.  If NUMA affinity needs to be disabled for\n\t\t\twhatever reason, this option can be used.  Note\n\t\t\tthat this also can be controlled per-workqueue for\n\t\t\tworkqueues visible under /sys/bus/workqueue/.\n\n\tworkqueue.power_efficient\n\t\t\tPer-cpu workqueues are generally preferred because\n\t\t\tthey show better performance thanks to cache\n\t\t\tlocality; unfortunately, per-cpu workqueues tend to\n\t\t\tbe more power hungry than unbound workqueues.\n\n\t\t\tEnabling this makes the per-cpu workqueues which\n\t\t\twere observed to contribute significantly to power\n\t\t\tconsumption unbound, leading to measurably lower\n\t\t\tpower usage at the cost of small performance\n\t\t\toverhead.\n\n\t\t\tThe default value of this parameter is determined by\n\t\t\tthe config option CONFIG_WQ_POWER_EFFICIENT_DEFAULT.\n\n\tworkqueue.debug_force_rr_cpu\n\t\t\tWorkqueue used to implicitly guarantee that work\n\t\t\titems queued without explicit CPU specified are put\n\t\t\ton the local CPU.  This guarantee is no longer true\n\t\t\tand while local CPU is still preferred work items\n\t\t\tmay be put on foreign CPUs.  This debug option\n\t\t\tforces round-robin CPU selection to flush out\n\t\t\tusages which depend on the now broken guarantee.\n\t\t\tWhen enabled, memory and cache locality will be\n\t\t\timpacted.\n\n\tx2apic_phys\t[X86-64,APIC] Use x2apic physical mode instead of\n\t\t\tdefault x2apic cluster mode on platforms\n\t\t\tsupporting x2apic.\n\n\tx86_intel_mid_timer= [X86-32,APBT]\n\t\t\tChoose timer option for x86 Intel MID platform.\n\t\t\tTwo valid options are apbt timer only and lapic timer\n\t\t\tplus one apbt timer for broadcast timer.\n\t\t\tx86_intel_mid_timer=apbt_only | lapic_and_apbt\n\n\txen_512gb_limit\t\t[KNL,X86-64,XEN]\n\t\t\tRestricts the kernel running paravirtualized under Xen\n\t\t\tto use only up to 512 GB of RAM. The reason to do so is\n\t\t\tcrash analysis tools and Xen tools for doing domain\n\t\t\tsave/restore/migration must be enabled to handle larger\n\t\t\tdomains.\n\n\txen_emul_unplug=\t\t[HW,X86,XEN]\n\t\t\tUnplug Xen emulated devices\n\t\t\tFormat: [unplug0,][unplug1]\n\t\t\tide-disks -- unplug primary master IDE devices\n\t\t\taux-ide-disks -- unplug non-primary-master IDE devices\n\t\t\tnics -- unplug network devices\n\t\t\tall -- unplug all emulated devices (NICs and IDE disks)\n\t\t\tunnecessary -- unplugging emulated devices is\n\t\t\t\tunnecessary even if the host did not respond to\n\t\t\t\tthe unplug protocol\n\t\t\tnever -- do not unplug even if version check succeeds\n\n\txen_legacy_crash\t[X86,XEN]\n\t\t\tCrash from Xen panic notifier, without executing late\n\t\t\tpanic() code such as dumping handler.\n\n\txen_nopvspin\t[X86,XEN]\n\t\t\tDisables the qspinlock slowpath using Xen PV optimizations.\n\t\t\tThis parameter is obsoleted by \"nopvspin\" parameter, which\n\t\t\thas equivalent effect for XEN platform.\n\n\txen_nopv\t[X86]\n\t\t\tDisables the PV optimizations forcing the HVM guest to\n\t\t\trun as generic HVM guest with no PV drivers.\n\t\t\tThis option is obsoleted by the \"nopv\" option, which\n\t\t\thas equivalent effect for XEN platform.\n\n\txen_scrub_pages=\t[XEN]\n\t\t\tBoolean option to control scrubbing pages before giving them back\n\t\t\tto Xen, for use by other domains. Can be also changed at runtime\n\t\t\twith /sys/devices/system/xen_memory/xen_memory0/scrub_pages.\n\t\t\tDefault value controlled with CONFIG_XEN_SCRUB_PAGES_DEFAULT.\n\n\txen_timer_slop=\t[X86-64,XEN]\n\t\t\tSet the timer slop (in nanoseconds) for the virtual Xen\n\t\t\ttimers (default is 100000). This adjusts the minimum\n\t\t\tdelta of virtualized Xen timers, where lower values\n\t\t\timprove timer resolution at the expense of processing\n\t\t\tmore timer interrupts.\n\n\txen.event_eoi_delay=\t[XEN]\n\t\t\tHow long to delay EOI handling in case of event\n\t\t\tstorms (jiffies). Default is 10.\n\n\txen.event_loop_timeout=\t[XEN]\n\t\t\tAfter which time (jiffies) the event handling loop\n\t\t\tshould start to delay EOI handling. Default is 2.\n\n\tnopv=\t\t[X86,XEN,KVM,HYPER_V,VMWARE]\n\t\t\tDisables the PV optimizations forcing the guest to run\n\t\t\tas generic guest with no PV drivers. Currently support\n\t\t\tXEN HVM, KVM, HYPER_V and VMWARE guest.\n\n\tnopvspin\t[X86,XEN,KVM]\n\t\t\tDisables the qspinlock slow path using PV optimizations\n\t\t\twhich allow the hypervisor to 'idle' the guest on lock\n\t\t\tcontention.\n\n\txirc2ps_cs=\t[NET,PCMCIA]\n\t\t\tFormat:\n\t\t\t<irq>,<irq_mask>,<io>,<full_duplex>,<do_sound>,<lockup_hack>[,<irq2>[,<irq3>[,<irq4>]]]\n\n\txive=\t\t[PPC]\n\t\t\tBy default on POWER9 and above, the kernel will\n\t\t\tnatively use the XIVE interrupt controller. This option\n\t\t\tallows the fallback firmware mode to be used:\n\n\t\t\toff       Fallback to firmware control of XIVE interrupt\n\t\t\t\t  controller on both pseries and powernv\n\t\t\t\t  platforms. Only useful on POWER9 and above.\n\n\txhci-hcd.quirks\t\t[USB,KNL]\n\t\t\tA hex value specifying bitmask with supplemental xhci\n\t\t\thost controller quirks. Meaning of each bit can be\n\t\t\tconsulted in header drivers/usb/host/xhci.h.\n\n\txmon\t\t[PPC]\n\t\t\tFormat: { early | on | rw | ro | off }\n\t\t\tControls if xmon debugger is enabled. Default is off.\n\t\t\tPassing only \"xmon\" is equivalent to \"xmon=early\".\n\t\t\tearly\tCall xmon as early as possible on boot; xmon\n\t\t\t\tdebugger is called from setup_arch().\n\t\t\ton\txmon debugger hooks will be installed so xmon\n\t\t\t\tis only called on a kernel crash. Default mode,\n\t\t\t\ti.e. either \"ro\" or \"rw\" mode, is controlled\n\t\t\t\twith CONFIG_XMON_DEFAULT_RO_MODE.\n\t\t\trw\txmon debugger hooks will be installed so xmon\n\t\t\t\tis called only on a kernel crash, mode is write,\n\t\t\t\tmeaning SPR registers, memory and, other data\n\t\t\t\tcan be written using xmon commands.\n\t\t\tro \tsame as \"rw\" option above but SPR registers,\n\t\t\t\tmemory, and other data can't be written using\n\t\t\t\txmon commands.\n\t\t\toff\txmon is disabled.\n", "// SPDX-License-Identifier: GPL-2.0\n/*\n * Xen event channels (2-level ABI)\n *\n * Jeremy Fitzhardinge <jeremy@xensource.com>, XenSource Inc, 2007\n */\n\n#define pr_fmt(fmt) \"xen:\" KBUILD_MODNAME \": \" fmt\n\n#include <linux/linkage.h>\n#include <linux/interrupt.h>\n#include <linux/irq.h>\n\n#include <asm/sync_bitops.h>\n#include <asm/xen/hypercall.h>\n#include <asm/xen/hypervisor.h>\n\n#include <xen/xen.h>\n#include <xen/xen-ops.h>\n#include <xen/events.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/event_channel.h>\n\n#include \"events_internal.h\"\n\n/*\n * Note sizeof(xen_ulong_t) can be more than sizeof(unsigned long). Be\n * careful to only use bitops which allow for this (e.g\n * test_bit/find_first_bit and friends but not __ffs) and to pass\n * BITS_PER_EVTCHN_WORD as the bitmask length.\n */\n#define BITS_PER_EVTCHN_WORD (sizeof(xen_ulong_t)*8)\n/*\n * Make a bitmask (i.e. unsigned long *) of a xen_ulong_t\n * array. Primarily to avoid long lines (hence the terse name).\n */\n#define BM(x) (unsigned long *)(x)\n/* Find the first set bit in a evtchn mask */\n#define EVTCHN_FIRST_BIT(w) find_first_bit(BM(&(w)), BITS_PER_EVTCHN_WORD)\n\n#define EVTCHN_MASK_SIZE (EVTCHN_2L_NR_CHANNELS/BITS_PER_EVTCHN_WORD)\n\nstatic DEFINE_PER_CPU(xen_ulong_t [EVTCHN_MASK_SIZE], cpu_evtchn_mask);\n\nstatic unsigned evtchn_2l_max_channels(void)\n{\n\treturn EVTCHN_2L_NR_CHANNELS;\n}\n\nstatic void evtchn_2l_bind_to_cpu(struct irq_info *info, unsigned cpu)\n{\n\tclear_bit(info->evtchn, BM(per_cpu(cpu_evtchn_mask, info->cpu)));\n\tset_bit(info->evtchn, BM(per_cpu(cpu_evtchn_mask, cpu)));\n}\n\nstatic void evtchn_2l_clear_pending(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tsync_clear_bit(port, BM(&s->evtchn_pending[0]));\n}\n\nstatic void evtchn_2l_set_pending(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tsync_set_bit(port, BM(&s->evtchn_pending[0]));\n}\n\nstatic bool evtchn_2l_is_pending(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\treturn sync_test_bit(port, BM(&s->evtchn_pending[0]));\n}\n\nstatic bool evtchn_2l_test_and_set_mask(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\treturn sync_test_and_set_bit(port, BM(&s->evtchn_mask[0]));\n}\n\nstatic void evtchn_2l_mask(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tsync_set_bit(port, BM(&s->evtchn_mask[0]));\n}\n\nstatic void evtchn_2l_unmask(evtchn_port_t port)\n{\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tunsigned int cpu = get_cpu();\n\tint do_hypercall = 0, evtchn_pending = 0;\n\n\tBUG_ON(!irqs_disabled());\n\n\tsmp_wmb();\t/* All writes before unmask must be visible. */\n\n\tif (unlikely((cpu != cpu_from_evtchn(port))))\n\t\tdo_hypercall = 1;\n\telse {\n\t\t/*\n\t\t * Need to clear the mask before checking pending to\n\t\t * avoid a race with an event becoming pending.\n\t\t *\n\t\t * EVTCHNOP_unmask will only trigger an upcall if the\n\t\t * mask bit was set, so if a hypercall is needed\n\t\t * remask the event.\n\t\t */\n\t\tsync_clear_bit(port, BM(&s->evtchn_mask[0]));\n\t\tevtchn_pending = sync_test_bit(port, BM(&s->evtchn_pending[0]));\n\n\t\tif (unlikely(evtchn_pending && xen_hvm_domain())) {\n\t\t\tsync_set_bit(port, BM(&s->evtchn_mask[0]));\n\t\t\tdo_hypercall = 1;\n\t\t}\n\t}\n\n\t/* Slow path (hypercall) if this is a non-local port or if this is\n\t * an hvm domain and an event is pending (hvm domains don't have\n\t * their own implementation of irq_enable). */\n\tif (do_hypercall) {\n\t\tstruct evtchn_unmask unmask = { .port = port };\n\t\t(void)HYPERVISOR_event_channel_op(EVTCHNOP_unmask, &unmask);\n\t} else {\n\t\tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n\n\t\t/*\n\t\t * The following is basically the equivalent of\n\t\t * 'hw_resend_irq'. Just like a real IO-APIC we 'lose\n\t\t * the interrupt edge' if the channel is masked.\n\t\t */\n\t\tif (evtchn_pending &&\n\t\t    !sync_test_and_set_bit(port / BITS_PER_EVTCHN_WORD,\n\t\t\t\t\t   BM(&vcpu_info->evtchn_pending_sel)))\n\t\t\tvcpu_info->evtchn_upcall_pending = 1;\n\t}\n\n\tput_cpu();\n}\n\nstatic DEFINE_PER_CPU(unsigned int, current_word_idx);\nstatic DEFINE_PER_CPU(unsigned int, current_bit_idx);\n\n/*\n * Mask out the i least significant bits of w\n */\n#define MASK_LSBS(w, i) (w & ((~((xen_ulong_t)0UL)) << i))\n\nstatic inline xen_ulong_t active_evtchns(unsigned int cpu,\n\t\t\t\t\t struct shared_info *sh,\n\t\t\t\t\t unsigned int idx)\n{\n\treturn sh->evtchn_pending[idx] &\n\t\tper_cpu(cpu_evtchn_mask, cpu)[idx] &\n\t\t~sh->evtchn_mask[idx];\n}\n\n/*\n * Search the CPU's pending events bitmasks.  For each one found, map\n * the event number to an irq, and feed it into do_IRQ() for handling.\n *\n * Xen uses a two-level bitmap to speed searching.  The first level is\n * a bitset of words which contain pending event bits.  The second\n * level is a bitset of pending events themselves.\n */\nstatic void evtchn_2l_handle_events(unsigned cpu, struct evtchn_loop_ctrl *ctrl)\n{\n\tint irq;\n\txen_ulong_t pending_words;\n\txen_ulong_t pending_bits;\n\tint start_word_idx, start_bit_idx;\n\tint word_idx, bit_idx;\n\tint i;\n\tstruct shared_info *s = HYPERVISOR_shared_info;\n\tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n\n\t/* Timer interrupt has highest priority. */\n\tirq = irq_from_virq(cpu, VIRQ_TIMER);\n\tif (irq != -1) {\n\t\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\t\tword_idx = evtchn / BITS_PER_LONG;\n\t\tbit_idx = evtchn % BITS_PER_LONG;\n\t\tif (active_evtchns(cpu, s, word_idx) & (1ULL << bit_idx))\n\t\t\tgeneric_handle_irq(irq);\n\t}\n\n\t/*\n\t * Master flag must be cleared /before/ clearing\n\t * selector flag. xchg_xen_ulong must contain an\n\t * appropriate barrier.\n\t */\n\tpending_words = xchg_xen_ulong(&vcpu_info->evtchn_pending_sel, 0);\n\n\tstart_word_idx = __this_cpu_read(current_word_idx);\n\tstart_bit_idx = __this_cpu_read(current_bit_idx);\n\n\tword_idx = start_word_idx;\n\n\tfor (i = 0; pending_words != 0; i++) {\n\t\txen_ulong_t words;\n\n\t\twords = MASK_LSBS(pending_words, word_idx);\n\n\t\t/*\n\t\t * If we masked out all events, wrap to beginning.\n\t\t */\n\t\tif (words == 0) {\n\t\t\tword_idx = 0;\n\t\t\tbit_idx = 0;\n\t\t\tcontinue;\n\t\t}\n\t\tword_idx = EVTCHN_FIRST_BIT(words);\n\n\t\tpending_bits = active_evtchns(cpu, s, word_idx);\n\t\tbit_idx = 0; /* usually scan entire word from start */\n\t\t/*\n\t\t * We scan the starting word in two parts.\n\t\t *\n\t\t * 1st time: start in the middle, scanning the\n\t\t * upper bits.\n\t\t *\n\t\t * 2nd time: scan the whole word (not just the\n\t\t * parts skipped in the first pass) -- if an\n\t\t * event in the previously scanned bits is\n\t\t * pending again it would just be scanned on\n\t\t * the next loop anyway.\n\t\t */\n\t\tif (word_idx == start_word_idx) {\n\t\t\tif (i == 0)\n\t\t\t\tbit_idx = start_bit_idx;\n\t\t}\n\n\t\tdo {\n\t\t\txen_ulong_t bits;\n\t\t\tevtchn_port_t port;\n\n\t\t\tbits = MASK_LSBS(pending_bits, bit_idx);\n\n\t\t\t/* If we masked out all events, move on. */\n\t\t\tif (bits == 0)\n\t\t\t\tbreak;\n\n\t\t\tbit_idx = EVTCHN_FIRST_BIT(bits);\n\n\t\t\t/* Process port. */\n\t\t\tport = (word_idx * BITS_PER_EVTCHN_WORD) + bit_idx;\n\t\t\thandle_irq_for_port(port, ctrl);\n\n\t\t\tbit_idx = (bit_idx + 1) % BITS_PER_EVTCHN_WORD;\n\n\t\t\t/* Next caller starts at last processed + 1 */\n\t\t\t__this_cpu_write(current_word_idx,\n\t\t\t\t\t bit_idx ? word_idx :\n\t\t\t\t\t (word_idx+1) % BITS_PER_EVTCHN_WORD);\n\t\t\t__this_cpu_write(current_bit_idx, bit_idx);\n\t\t} while (bit_idx != 0);\n\n\t\t/* Scan start_l1i twice; all others once. */\n\t\tif ((word_idx != start_word_idx) || (i != 0))\n\t\t\tpending_words &= ~(1UL << word_idx);\n\n\t\tword_idx = (word_idx + 1) % BITS_PER_EVTCHN_WORD;\n\t}\n}\n\nirqreturn_t xen_debug_interrupt(int irq, void *dev_id)\n{\n\tstruct shared_info *sh = HYPERVISOR_shared_info;\n\tint cpu = smp_processor_id();\n\txen_ulong_t *cpu_evtchn = per_cpu(cpu_evtchn_mask, cpu);\n\tint i;\n\tunsigned long flags;\n\tstatic DEFINE_SPINLOCK(debug_lock);\n\tstruct vcpu_info *v;\n\n\tspin_lock_irqsave(&debug_lock, flags);\n\n\tprintk(\"\\nvcpu %d\\n  \", cpu);\n\n\tfor_each_online_cpu(i) {\n\t\tint pending;\n\t\tv = per_cpu(xen_vcpu, i);\n\t\tpending = (get_irq_regs() && i == cpu)\n\t\t\t? xen_irqs_disabled(get_irq_regs())\n\t\t\t: v->evtchn_upcall_mask;\n\t\tprintk(\"%d: masked=%d pending=%d event_sel %0*\"PRI_xen_ulong\"\\n  \", i,\n\t\t       pending, v->evtchn_upcall_pending,\n\t\t       (int)(sizeof(v->evtchn_pending_sel)*2),\n\t\t       v->evtchn_pending_sel);\n\t}\n\tv = per_cpu(xen_vcpu, cpu);\n\n\tprintk(\"\\npending:\\n   \");\n\tfor (i = ARRAY_SIZE(sh->evtchn_pending)-1; i >= 0; i--)\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\",\n\t\t       (int)sizeof(sh->evtchn_pending[0])*2,\n\t\t       sh->evtchn_pending[i],\n\t\t       i % 8 == 0 ? \"\\n   \" : \" \");\n\tprintk(\"\\nglobal mask:\\n   \");\n\tfor (i = ARRAY_SIZE(sh->evtchn_mask)-1; i >= 0; i--)\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\",\n\t\t       (int)(sizeof(sh->evtchn_mask[0])*2),\n\t\t       sh->evtchn_mask[i],\n\t\t       i % 8 == 0 ? \"\\n   \" : \" \");\n\n\tprintk(\"\\nglobally unmasked:\\n   \");\n\tfor (i = ARRAY_SIZE(sh->evtchn_mask)-1; i >= 0; i--)\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\",\n\t\t       (int)(sizeof(sh->evtchn_mask[0])*2),\n\t\t       sh->evtchn_pending[i] & ~sh->evtchn_mask[i],\n\t\t       i % 8 == 0 ? \"\\n   \" : \" \");\n\n\tprintk(\"\\nlocal cpu%d mask:\\n   \", cpu);\n\tfor (i = (EVTCHN_2L_NR_CHANNELS/BITS_PER_EVTCHN_WORD)-1; i >= 0; i--)\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\", (int)(sizeof(cpu_evtchn[0])*2),\n\t\t       cpu_evtchn[i],\n\t\t       i % 8 == 0 ? \"\\n   \" : \" \");\n\n\tprintk(\"\\nlocally unmasked:\\n   \");\n\tfor (i = ARRAY_SIZE(sh->evtchn_mask)-1; i >= 0; i--) {\n\t\txen_ulong_t pending = sh->evtchn_pending[i]\n\t\t\t& ~sh->evtchn_mask[i]\n\t\t\t& cpu_evtchn[i];\n\t\tprintk(\"%0*\"PRI_xen_ulong\"%s\",\n\t\t       (int)(sizeof(sh->evtchn_mask[0])*2),\n\t\t       pending, i % 8 == 0 ? \"\\n   \" : \" \");\n\t}\n\n\tprintk(\"\\npending list:\\n\");\n\tfor (i = 0; i < EVTCHN_2L_NR_CHANNELS; i++) {\n\t\tif (sync_test_bit(i, BM(sh->evtchn_pending))) {\n\t\t\tint word_idx = i / BITS_PER_EVTCHN_WORD;\n\t\t\tprintk(\"  %d: event %d -> irq %d%s%s%s\\n\",\n\t\t\t       cpu_from_evtchn(i), i,\n\t\t\t       get_evtchn_to_irq(i),\n\t\t\t       sync_test_bit(word_idx, BM(&v->evtchn_pending_sel))\n\t\t\t       ? \"\" : \" l2-clear\",\n\t\t\t       !sync_test_bit(i, BM(sh->evtchn_mask))\n\t\t\t       ? \"\" : \" globally-masked\",\n\t\t\t       sync_test_bit(i, BM(cpu_evtchn))\n\t\t\t       ? \"\" : \" locally-masked\");\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&debug_lock, flags);\n\n\treturn IRQ_HANDLED;\n}\n\nstatic void evtchn_2l_resume(void)\n{\n\tint i;\n\n\tfor_each_online_cpu(i)\n\t\tmemset(per_cpu(cpu_evtchn_mask, i), 0, sizeof(xen_ulong_t) *\n\t\t\t\tEVTCHN_2L_NR_CHANNELS/BITS_PER_EVTCHN_WORD);\n}\n\nstatic const struct evtchn_ops evtchn_ops_2l = {\n\t.max_channels      = evtchn_2l_max_channels,\n\t.nr_channels       = evtchn_2l_max_channels,\n\t.bind_to_cpu       = evtchn_2l_bind_to_cpu,\n\t.clear_pending     = evtchn_2l_clear_pending,\n\t.set_pending       = evtchn_2l_set_pending,\n\t.is_pending        = evtchn_2l_is_pending,\n\t.test_and_set_mask = evtchn_2l_test_and_set_mask,\n\t.mask              = evtchn_2l_mask,\n\t.unmask            = evtchn_2l_unmask,\n\t.handle_events     = evtchn_2l_handle_events,\n\t.resume\t           = evtchn_2l_resume,\n};\n\nvoid __init xen_evtchn_2l_init(void)\n{\n\tpr_info(\"Using 2-level ABI\\n\");\n\tevtchn_ops = &evtchn_ops_2l;\n}\n", "// SPDX-License-Identifier: GPL-2.0-only\n/*\n * Xen event channels\n *\n * Xen models interrupts with abstract event channels.  Because each\n * domain gets 1024 event channels, but NR_IRQ is not that large, we\n * must dynamically map irqs<->event channels.  The event channels\n * interface with the rest of the kernel by defining a xen interrupt\n * chip.  When an event is received, it is mapped to an irq and sent\n * through the normal interrupt processing path.\n *\n * There are four kinds of events which can be mapped to an event\n * channel:\n *\n * 1. Inter-domain notifications.  This includes all the virtual\n *    device events, since they're driven by front-ends in another domain\n *    (typically dom0).\n * 2. VIRQs, typically used for timers.  These are per-cpu events.\n * 3. IPIs.\n * 4. PIRQs - Hardware interrupts.\n *\n * Jeremy Fitzhardinge <jeremy@xensource.com>, XenSource Inc, 2007\n */\n\n#define pr_fmt(fmt) \"xen:\" KBUILD_MODNAME \": \" fmt\n\n#include <linux/linkage.h>\n#include <linux/interrupt.h>\n#include <linux/irq.h>\n#include <linux/moduleparam.h>\n#include <linux/string.h>\n#include <linux/memblock.h>\n#include <linux/slab.h>\n#include <linux/irqnr.h>\n#include <linux/pci.h>\n#include <linux/spinlock.h>\n#include <linux/cpuhotplug.h>\n#include <linux/atomic.h>\n#include <linux/ktime.h>\n\n#ifdef CONFIG_X86\n#include <asm/desc.h>\n#include <asm/ptrace.h>\n#include <asm/idtentry.h>\n#include <asm/irq.h>\n#include <asm/io_apic.h>\n#include <asm/i8259.h>\n#include <asm/xen/pci.h>\n#endif\n#include <asm/sync_bitops.h>\n#include <asm/xen/hypercall.h>\n#include <asm/xen/hypervisor.h>\n#include <xen/page.h>\n\n#include <xen/xen.h>\n#include <xen/hvm.h>\n#include <xen/xen-ops.h>\n#include <xen/events.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/event_channel.h>\n#include <xen/interface/hvm/hvm_op.h>\n#include <xen/interface/hvm/params.h>\n#include <xen/interface/physdev.h>\n#include <xen/interface/sched.h>\n#include <xen/interface/vcpu.h>\n#include <asm/hw_irq.h>\n\n#include \"events_internal.h\"\n\n#undef MODULE_PARAM_PREFIX\n#define MODULE_PARAM_PREFIX \"xen.\"\n\nstatic uint __read_mostly event_loop_timeout = 2;\nmodule_param(event_loop_timeout, uint, 0644);\n\nstatic uint __read_mostly event_eoi_delay = 10;\nmodule_param(event_eoi_delay, uint, 0644);\n\nconst struct evtchn_ops *evtchn_ops;\n\n/*\n * This lock protects updates to the following mapping and reference-count\n * arrays. The lock does not need to be acquired to read the mapping tables.\n */\nstatic DEFINE_MUTEX(irq_mapping_update_lock);\n\n/*\n * Lock protecting event handling loop against removing event channels.\n * Adding of event channels is no issue as the associated IRQ becomes active\n * only after everything is setup (before request_[threaded_]irq() the handler\n * can't be entered for an event, as the event channel will be unmasked only\n * then).\n */\nstatic DEFINE_RWLOCK(evtchn_rwlock);\n\n/*\n * Lock hierarchy:\n *\n * irq_mapping_update_lock\n *   evtchn_rwlock\n *     IRQ-desc lock\n *       percpu eoi_list_lock\n */\n\nstatic LIST_HEAD(xen_irq_list_head);\n\n/* IRQ <-> VIRQ mapping. */\nstatic DEFINE_PER_CPU(int [NR_VIRQS], virq_to_irq) = {[0 ... NR_VIRQS-1] = -1};\n\n/* IRQ <-> IPI mapping */\nstatic DEFINE_PER_CPU(int [XEN_NR_IPIS], ipi_to_irq) = {[0 ... XEN_NR_IPIS-1] = -1};\n\nint **evtchn_to_irq;\n#ifdef CONFIG_X86\nstatic unsigned long *pirq_eoi_map;\n#endif\nstatic bool (*pirq_needs_eoi)(unsigned irq);\n\n#define EVTCHN_ROW(e)  (e / (PAGE_SIZE/sizeof(**evtchn_to_irq)))\n#define EVTCHN_COL(e)  (e % (PAGE_SIZE/sizeof(**evtchn_to_irq)))\n#define EVTCHN_PER_ROW (PAGE_SIZE / sizeof(**evtchn_to_irq))\n\n/* Xen will never allocate port zero for any purpose. */\n#define VALID_EVTCHN(chn)\t((chn) != 0)\n\nstatic struct irq_info *legacy_info_ptrs[NR_IRQS_LEGACY];\n\nstatic struct irq_chip xen_dynamic_chip;\nstatic struct irq_chip xen_lateeoi_chip;\nstatic struct irq_chip xen_percpu_chip;\nstatic struct irq_chip xen_pirq_chip;\nstatic void enable_dynirq(struct irq_data *data);\nstatic void disable_dynirq(struct irq_data *data);\n\nstatic DEFINE_PER_CPU(unsigned int, irq_epoch);\n\nstatic void clear_evtchn_to_irq_row(unsigned row)\n{\n\tunsigned col;\n\n\tfor (col = 0; col < EVTCHN_PER_ROW; col++)\n\t\tWRITE_ONCE(evtchn_to_irq[row][col], -1);\n}\n\nstatic void clear_evtchn_to_irq_all(void)\n{\n\tunsigned row;\n\n\tfor (row = 0; row < EVTCHN_ROW(xen_evtchn_max_channels()); row++) {\n\t\tif (evtchn_to_irq[row] == NULL)\n\t\t\tcontinue;\n\t\tclear_evtchn_to_irq_row(row);\n\t}\n}\n\nstatic int set_evtchn_to_irq(evtchn_port_t evtchn, unsigned int irq)\n{\n\tunsigned row;\n\tunsigned col;\n\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -EINVAL;\n\n\trow = EVTCHN_ROW(evtchn);\n\tcol = EVTCHN_COL(evtchn);\n\n\tif (evtchn_to_irq[row] == NULL) {\n\t\t/* Unallocated irq entries return -1 anyway */\n\t\tif (irq == -1)\n\t\t\treturn 0;\n\n\t\tevtchn_to_irq[row] = (int *)get_zeroed_page(GFP_KERNEL);\n\t\tif (evtchn_to_irq[row] == NULL)\n\t\t\treturn -ENOMEM;\n\n\t\tclear_evtchn_to_irq_row(row);\n\t}\n\n\tWRITE_ONCE(evtchn_to_irq[row][col], irq);\n\treturn 0;\n}\n\nint get_evtchn_to_irq(evtchn_port_t evtchn)\n{\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -1;\n\tif (evtchn_to_irq[EVTCHN_ROW(evtchn)] == NULL)\n\t\treturn -1;\n\treturn READ_ONCE(evtchn_to_irq[EVTCHN_ROW(evtchn)][EVTCHN_COL(evtchn)]);\n}\n\n/* Get info for IRQ */\nstruct irq_info *info_for_irq(unsigned irq)\n{\n\tif (irq < nr_legacy_irqs())\n\t\treturn legacy_info_ptrs[irq];\n\telse\n\t\treturn irq_get_chip_data(irq);\n}\n\nstatic void set_info_for_irq(unsigned int irq, struct irq_info *info)\n{\n\tif (irq < nr_legacy_irqs())\n\t\tlegacy_info_ptrs[irq] = info;\n\telse\n\t\tirq_set_chip_data(irq, info);\n}\n\n/* Constructors for packed IRQ information. */\nstatic int xen_irq_info_common_setup(struct irq_info *info,\n\t\t\t\t     unsigned irq,\n\t\t\t\t     enum xen_irq_type type,\n\t\t\t\t     evtchn_port_t evtchn,\n\t\t\t\t     unsigned short cpu)\n{\n\tint ret;\n\n\tBUG_ON(info->type != IRQT_UNBOUND && info->type != type);\n\n\tinfo->type = type;\n\tinfo->irq = irq;\n\tinfo->evtchn = evtchn;\n\tinfo->cpu = cpu;\n\n\tret = set_evtchn_to_irq(evtchn, irq);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tirq_clear_status_flags(irq, IRQ_NOREQUEST|IRQ_NOAUTOEN);\n\n\treturn xen_evtchn_port_setup(info);\n}\n\nstatic int xen_irq_info_evtchn_setup(unsigned irq,\n\t\t\t\t     evtchn_port_t evtchn)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\treturn xen_irq_info_common_setup(info, irq, IRQT_EVTCHN, evtchn, 0);\n}\n\nstatic int xen_irq_info_ipi_setup(unsigned cpu,\n\t\t\t\t  unsigned irq,\n\t\t\t\t  evtchn_port_t evtchn,\n\t\t\t\t  enum ipi_vector ipi)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tinfo->u.ipi = ipi;\n\n\tper_cpu(ipi_to_irq, cpu)[ipi] = irq;\n\n\treturn xen_irq_info_common_setup(info, irq, IRQT_IPI, evtchn, 0);\n}\n\nstatic int xen_irq_info_virq_setup(unsigned cpu,\n\t\t\t\t   unsigned irq,\n\t\t\t\t   evtchn_port_t evtchn,\n\t\t\t\t   unsigned virq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tinfo->u.virq = virq;\n\n\tper_cpu(virq_to_irq, cpu)[virq] = irq;\n\n\treturn xen_irq_info_common_setup(info, irq, IRQT_VIRQ, evtchn, 0);\n}\n\nstatic int xen_irq_info_pirq_setup(unsigned irq,\n\t\t\t\t   evtchn_port_t evtchn,\n\t\t\t\t   unsigned pirq,\n\t\t\t\t   unsigned gsi,\n\t\t\t\t   uint16_t domid,\n\t\t\t\t   unsigned char flags)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tinfo->u.pirq.pirq = pirq;\n\tinfo->u.pirq.gsi = gsi;\n\tinfo->u.pirq.domid = domid;\n\tinfo->u.pirq.flags = flags;\n\n\treturn xen_irq_info_common_setup(info, irq, IRQT_PIRQ, evtchn, 0);\n}\n\nstatic void xen_irq_info_cleanup(struct irq_info *info)\n{\n\tset_evtchn_to_irq(info->evtchn, -1);\n\tinfo->evtchn = 0;\n}\n\n/*\n * Accessors for packed IRQ information.\n */\nevtchn_port_t evtchn_from_irq(unsigned irq)\n{\n\tconst struct irq_info *info = NULL;\n\n\tif (likely(irq < nr_irqs))\n\t\tinfo = info_for_irq(irq);\n\tif (!info)\n\t\treturn 0;\n\n\treturn info->evtchn;\n}\n\nunsigned int irq_from_evtchn(evtchn_port_t evtchn)\n{\n\treturn get_evtchn_to_irq(evtchn);\n}\nEXPORT_SYMBOL_GPL(irq_from_evtchn);\n\nint irq_from_virq(unsigned int cpu, unsigned int virq)\n{\n\treturn per_cpu(virq_to_irq, cpu)[virq];\n}\n\nstatic enum ipi_vector ipi_from_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(info == NULL);\n\tBUG_ON(info->type != IRQT_IPI);\n\n\treturn info->u.ipi;\n}\n\nstatic unsigned virq_from_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(info == NULL);\n\tBUG_ON(info->type != IRQT_VIRQ);\n\n\treturn info->u.virq;\n}\n\nstatic unsigned pirq_from_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(info == NULL);\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\treturn info->u.pirq.pirq;\n}\n\nstatic enum xen_irq_type type_from_irq(unsigned irq)\n{\n\treturn info_for_irq(irq)->type;\n}\n\nunsigned cpu_from_irq(unsigned irq)\n{\n\treturn info_for_irq(irq)->cpu;\n}\n\nunsigned int cpu_from_evtchn(evtchn_port_t evtchn)\n{\n\tint irq = get_evtchn_to_irq(evtchn);\n\tunsigned ret = 0;\n\n\tif (irq != -1)\n\t\tret = cpu_from_irq(irq);\n\n\treturn ret;\n}\n\n#ifdef CONFIG_X86\nstatic bool pirq_check_eoi_map(unsigned irq)\n{\n\treturn test_bit(pirq_from_irq(irq), pirq_eoi_map);\n}\n#endif\n\nstatic bool pirq_needs_eoi_flag(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\treturn info->u.pirq.flags & PIRQ_NEEDS_EOI;\n}\n\nstatic void bind_evtchn_to_cpu(evtchn_port_t evtchn, unsigned int cpu)\n{\n\tint irq = get_evtchn_to_irq(evtchn);\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(irq == -1);\n#ifdef CONFIG_SMP\n\tcpumask_copy(irq_get_affinity_mask(irq), cpumask_of(cpu));\n#endif\n\txen_evtchn_port_bind_to_cpu(info, cpu);\n\n\tinfo->cpu = cpu;\n}\n\n/**\n * notify_remote_via_irq - send event to remote end of event channel via irq\n * @irq: irq of event channel to send event to\n *\n * Unlike notify_remote_via_evtchn(), this is safe to use across\n * save/restore. Notifications on a broken connection are silently\n * dropped.\n */\nvoid notify_remote_via_irq(int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tnotify_remote_via_evtchn(evtchn);\n}\nEXPORT_SYMBOL_GPL(notify_remote_via_irq);\n\nstruct lateeoi_work {\n\tstruct delayed_work delayed;\n\tspinlock_t eoi_list_lock;\n\tstruct list_head eoi_list;\n};\n\nstatic DEFINE_PER_CPU(struct lateeoi_work, lateeoi);\n\nstatic void lateeoi_list_del(struct irq_info *info)\n{\n\tstruct lateeoi_work *eoi = &per_cpu(lateeoi, info->eoi_cpu);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&eoi->eoi_list_lock, flags);\n\tlist_del_init(&info->eoi_list);\n\tspin_unlock_irqrestore(&eoi->eoi_list_lock, flags);\n}\n\nstatic void lateeoi_list_add(struct irq_info *info)\n{\n\tstruct lateeoi_work *eoi = &per_cpu(lateeoi, info->eoi_cpu);\n\tstruct irq_info *elem;\n\tu64 now = get_jiffies_64();\n\tunsigned long delay;\n\tunsigned long flags;\n\n\tif (now < info->eoi_time)\n\t\tdelay = info->eoi_time - now;\n\telse\n\t\tdelay = 1;\n\n\tspin_lock_irqsave(&eoi->eoi_list_lock, flags);\n\n\tif (list_empty(&eoi->eoi_list)) {\n\t\tlist_add(&info->eoi_list, &eoi->eoi_list);\n\t\tmod_delayed_work_on(info->eoi_cpu, system_wq,\n\t\t\t\t    &eoi->delayed, delay);\n\t} else {\n\t\tlist_for_each_entry_reverse(elem, &eoi->eoi_list, eoi_list) {\n\t\t\tif (elem->eoi_time <= info->eoi_time)\n\t\t\t\tbreak;\n\t\t}\n\t\tlist_add(&info->eoi_list, &elem->eoi_list);\n\t}\n\n\tspin_unlock_irqrestore(&eoi->eoi_list_lock, flags);\n}\n\nstatic void xen_irq_lateeoi_locked(struct irq_info *info)\n{\n\tevtchn_port_t evtchn;\n\tunsigned int cpu;\n\n\tevtchn = info->evtchn;\n\tif (!VALID_EVTCHN(evtchn) || !list_empty(&info->eoi_list))\n\t\treturn;\n\n\tcpu = info->eoi_cpu;\n\tif (info->eoi_time && info->irq_epoch == per_cpu(irq_epoch, cpu)) {\n\t\tlateeoi_list_add(info);\n\t\treturn;\n\t}\n\n\tinfo->eoi_time = 0;\n\tunmask_evtchn(evtchn);\n}\n\nstatic void xen_irq_lateeoi_worker(struct work_struct *work)\n{\n\tstruct lateeoi_work *eoi;\n\tstruct irq_info *info;\n\tu64 now = get_jiffies_64();\n\tunsigned long flags;\n\n\teoi = container_of(to_delayed_work(work), struct lateeoi_work, delayed);\n\n\tread_lock_irqsave(&evtchn_rwlock, flags);\n\n\twhile (true) {\n\t\tspin_lock(&eoi->eoi_list_lock);\n\n\t\tinfo = list_first_entry_or_null(&eoi->eoi_list, struct irq_info,\n\t\t\t\t\t\teoi_list);\n\n\t\tif (info == NULL || now < info->eoi_time) {\n\t\t\tspin_unlock(&eoi->eoi_list_lock);\n\t\t\tbreak;\n\t\t}\n\n\t\tlist_del_init(&info->eoi_list);\n\n\t\tspin_unlock(&eoi->eoi_list_lock);\n\n\t\tinfo->eoi_time = 0;\n\n\t\txen_irq_lateeoi_locked(info);\n\t}\n\n\tif (info)\n\t\tmod_delayed_work_on(info->eoi_cpu, system_wq,\n\t\t\t\t    &eoi->delayed, info->eoi_time - now);\n\n\tread_unlock_irqrestore(&evtchn_rwlock, flags);\n}\n\nstatic void xen_cpu_init_eoi(unsigned int cpu)\n{\n\tstruct lateeoi_work *eoi = &per_cpu(lateeoi, cpu);\n\n\tINIT_DELAYED_WORK(&eoi->delayed, xen_irq_lateeoi_worker);\n\tspin_lock_init(&eoi->eoi_list_lock);\n\tINIT_LIST_HEAD(&eoi->eoi_list);\n}\n\nvoid xen_irq_lateeoi(unsigned int irq, unsigned int eoi_flags)\n{\n\tstruct irq_info *info;\n\tunsigned long flags;\n\n\tread_lock_irqsave(&evtchn_rwlock, flags);\n\n\tinfo = info_for_irq(irq);\n\n\tif (info)\n\t\txen_irq_lateeoi_locked(info);\n\n\tread_unlock_irqrestore(&evtchn_rwlock, flags);\n}\nEXPORT_SYMBOL_GPL(xen_irq_lateeoi);\n\nstatic void xen_irq_init(unsigned irq)\n{\n\tstruct irq_info *info;\n\n#ifdef CONFIG_SMP\n\t/* By default all event channels notify CPU#0. */\n\tcpumask_copy(irq_get_affinity_mask(irq), cpumask_of(0));\n#endif\n\n\tinfo = kzalloc(sizeof(*info), GFP_KERNEL);\n\tif (info == NULL)\n\t\tpanic(\"Unable to allocate metadata for IRQ%d\\n\", irq);\n\n\tinfo->type = IRQT_UNBOUND;\n\tinfo->refcnt = -1;\n\n\tset_info_for_irq(irq, info);\n\n\tINIT_LIST_HEAD(&info->eoi_list);\n\tlist_add_tail(&info->list, &xen_irq_list_head);\n}\n\nstatic int __must_check xen_allocate_irqs_dynamic(int nvec)\n{\n\tint i, irq = irq_alloc_descs(-1, 0, nvec, -1);\n\n\tif (irq >= 0) {\n\t\tfor (i = 0; i < nvec; i++)\n\t\t\txen_irq_init(irq + i);\n\t}\n\n\treturn irq;\n}\n\nstatic inline int __must_check xen_allocate_irq_dynamic(void)\n{\n\n\treturn xen_allocate_irqs_dynamic(1);\n}\n\nstatic int __must_check xen_allocate_irq_gsi(unsigned gsi)\n{\n\tint irq;\n\n\t/*\n\t * A PV guest has no concept of a GSI (since it has no ACPI\n\t * nor access to/knowledge of the physical APICs). Therefore\n\t * all IRQs are dynamically allocated from the entire IRQ\n\t * space.\n\t */\n\tif (xen_pv_domain() && !xen_initial_domain())\n\t\treturn xen_allocate_irq_dynamic();\n\n\t/* Legacy IRQ descriptors are already allocated by the arch. */\n\tif (gsi < nr_legacy_irqs())\n\t\tirq = gsi;\n\telse\n\t\tirq = irq_alloc_desc_at(gsi, -1);\n\n\txen_irq_init(irq);\n\n\treturn irq;\n}\n\nstatic void xen_free_irq(unsigned irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\tunsigned long flags;\n\n\tif (WARN_ON(!info))\n\t\treturn;\n\n\twrite_lock_irqsave(&evtchn_rwlock, flags);\n\n\tif (!list_empty(&info->eoi_list))\n\t\tlateeoi_list_del(info);\n\n\tlist_del(&info->list);\n\n\tset_info_for_irq(irq, NULL);\n\n\tWARN_ON(info->refcnt > 0);\n\n\twrite_unlock_irqrestore(&evtchn_rwlock, flags);\n\n\tkfree(info);\n\n\t/* Legacy IRQ descriptors are managed by the arch. */\n\tif (irq < nr_legacy_irqs())\n\t\treturn;\n\n\tirq_free_desc(irq);\n}\n\nstatic void xen_evtchn_close(evtchn_port_t port)\n{\n\tstruct evtchn_close close;\n\n\tclose.port = port;\n\tif (HYPERVISOR_event_channel_op(EVTCHNOP_close, &close) != 0)\n\t\tBUG();\n}\n\nstatic void pirq_query_unmask(int irq)\n{\n\tstruct physdev_irq_status_query irq_status;\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\tirq_status.irq = pirq_from_irq(irq);\n\tif (HYPERVISOR_physdev_op(PHYSDEVOP_irq_status_query, &irq_status))\n\t\tirq_status.flags = 0;\n\n\tinfo->u.pirq.flags &= ~PIRQ_NEEDS_EOI;\n\tif (irq_status.flags & XENIRQSTAT_needs_eoi)\n\t\tinfo->u.pirq.flags |= PIRQ_NEEDS_EOI;\n}\n\nstatic void eoi_pirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\tstruct physdev_eoi eoi = { .irq = pirq_from_irq(data->irq) };\n\tint rc = 0;\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn;\n\n\tif (unlikely(irqd_is_setaffinity_pending(data)) &&\n\t    likely(!irqd_irq_disabled(data))) {\n\t\tint masked = test_and_set_mask(evtchn);\n\n\t\tclear_evtchn(evtchn);\n\n\t\tirq_move_masked_irq(data);\n\n\t\tif (!masked)\n\t\t\tunmask_evtchn(evtchn);\n\t} else\n\t\tclear_evtchn(evtchn);\n\n\tif (pirq_needs_eoi(data->irq)) {\n\t\trc = HYPERVISOR_physdev_op(PHYSDEVOP_eoi, &eoi);\n\t\tWARN_ON(rc);\n\t}\n}\n\nstatic void mask_ack_pirq(struct irq_data *data)\n{\n\tdisable_dynirq(data);\n\teoi_pirq(data);\n}\n\nstatic unsigned int __startup_pirq(unsigned int irq)\n{\n\tstruct evtchn_bind_pirq bind_pirq;\n\tstruct irq_info *info = info_for_irq(irq);\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\tint rc;\n\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tgoto out;\n\n\tbind_pirq.pirq = pirq_from_irq(irq);\n\t/* NB. We are happy to share unless we are probing. */\n\tbind_pirq.flags = info->u.pirq.flags & PIRQ_SHAREABLE ?\n\t\t\t\t\tBIND_PIRQ__WILL_SHARE : 0;\n\trc = HYPERVISOR_event_channel_op(EVTCHNOP_bind_pirq, &bind_pirq);\n\tif (rc != 0) {\n\t\tpr_warn(\"Failed to obtain physical IRQ %d\\n\", irq);\n\t\treturn 0;\n\t}\n\tevtchn = bind_pirq.port;\n\n\tpirq_query_unmask(irq);\n\n\trc = set_evtchn_to_irq(evtchn, irq);\n\tif (rc)\n\t\tgoto err;\n\n\tinfo->evtchn = evtchn;\n\tbind_evtchn_to_cpu(evtchn, 0);\n\n\trc = xen_evtchn_port_setup(info);\n\tif (rc)\n\t\tgoto err;\n\nout:\n\tunmask_evtchn(evtchn);\n\teoi_pirq(irq_get_irq_data(irq));\n\n\treturn 0;\n\nerr:\n\tpr_err(\"irq%d: Failed to set port to irq mapping (%d)\\n\", irq, rc);\n\txen_evtchn_close(evtchn);\n\treturn 0;\n}\n\nstatic unsigned int startup_pirq(struct irq_data *data)\n{\n\treturn __startup_pirq(data->irq);\n}\n\nstatic void shutdown_pirq(struct irq_data *data)\n{\n\tunsigned int irq = data->irq;\n\tstruct irq_info *info = info_for_irq(irq);\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tBUG_ON(info->type != IRQT_PIRQ);\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn;\n\n\tmask_evtchn(evtchn);\n\txen_evtchn_close(evtchn);\n\txen_irq_info_cleanup(info);\n}\n\nstatic void enable_pirq(struct irq_data *data)\n{\n\tenable_dynirq(data);\n}\n\nstatic void disable_pirq(struct irq_data *data)\n{\n\tdisable_dynirq(data);\n}\n\nint xen_irq_from_gsi(unsigned gsi)\n{\n\tstruct irq_info *info;\n\n\tlist_for_each_entry(info, &xen_irq_list_head, list) {\n\t\tif (info->type != IRQT_PIRQ)\n\t\t\tcontinue;\n\n\t\tif (info->u.pirq.gsi == gsi)\n\t\t\treturn info->irq;\n\t}\n\n\treturn -1;\n}\nEXPORT_SYMBOL_GPL(xen_irq_from_gsi);\n\nstatic void __unbind_from_irq(unsigned int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tif (info->refcnt > 0) {\n\t\tinfo->refcnt--;\n\t\tif (info->refcnt != 0)\n\t\t\treturn;\n\t}\n\n\tif (VALID_EVTCHN(evtchn)) {\n\t\tunsigned int cpu = cpu_from_irq(irq);\n\n\t\txen_evtchn_close(evtchn);\n\n\t\tswitch (type_from_irq(irq)) {\n\t\tcase IRQT_VIRQ:\n\t\t\tper_cpu(virq_to_irq, cpu)[virq_from_irq(irq)] = -1;\n\t\t\tbreak;\n\t\tcase IRQT_IPI:\n\t\t\tper_cpu(ipi_to_irq, cpu)[ipi_from_irq(irq)] = -1;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\n\t\txen_irq_info_cleanup(info);\n\t}\n\n\txen_free_irq(irq);\n}\n\n/*\n * Do not make any assumptions regarding the relationship between the\n * IRQ number returned here and the Xen pirq argument.\n *\n * Note: We don't assign an event channel until the irq actually started\n * up.  Return an existing irq if we've already got one for the gsi.\n *\n * Shareable implies level triggered, not shareable implies edge\n * triggered here.\n */\nint xen_bind_pirq_gsi_to_irq(unsigned gsi,\n\t\t\t     unsigned pirq, int shareable, char *name)\n{\n\tint irq = -1;\n\tstruct physdev_irq irq_op;\n\tint ret;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = xen_irq_from_gsi(gsi);\n\tif (irq != -1) {\n\t\tpr_info(\"%s: returning irq %d for gsi %u\\n\",\n\t\t\t__func__, irq, gsi);\n\t\tgoto out;\n\t}\n\n\tirq = xen_allocate_irq_gsi(gsi);\n\tif (irq < 0)\n\t\tgoto out;\n\n\tirq_op.irq = irq;\n\tirq_op.vector = 0;\n\n\t/* Only the privileged domain can do this. For non-priv, the pcifront\n\t * driver provides a PCI bus that does the call to do exactly\n\t * this in the priv domain. */\n\tif (xen_initial_domain() &&\n\t    HYPERVISOR_physdev_op(PHYSDEVOP_alloc_irq_vector, &irq_op)) {\n\t\txen_free_irq(irq);\n\t\tirq = -ENOSPC;\n\t\tgoto out;\n\t}\n\n\tret = xen_irq_info_pirq_setup(irq, 0, pirq, gsi, DOMID_SELF,\n\t\t\t       shareable ? PIRQ_SHAREABLE : 0);\n\tif (ret < 0) {\n\t\t__unbind_from_irq(irq);\n\t\tirq = ret;\n\t\tgoto out;\n\t}\n\n\tpirq_query_unmask(irq);\n\t/* We try to use the handler with the appropriate semantic for the\n\t * type of interrupt: if the interrupt is an edge triggered\n\t * interrupt we use handle_edge_irq.\n\t *\n\t * On the other hand if the interrupt is level triggered we use\n\t * handle_fasteoi_irq like the native code does for this kind of\n\t * interrupts.\n\t *\n\t * Depending on the Xen version, pirq_needs_eoi might return true\n\t * not only for level triggered interrupts but for edge triggered\n\t * interrupts too. In any case Xen always honors the eoi mechanism,\n\t * not injecting any more pirqs of the same kind if the first one\n\t * hasn't received an eoi yet. Therefore using the fasteoi handler\n\t * is the right choice either way.\n\t */\n\tif (shareable)\n\t\tirq_set_chip_and_handler_name(irq, &xen_pirq_chip,\n\t\t\t\thandle_fasteoi_irq, name);\n\telse\n\t\tirq_set_chip_and_handler_name(irq, &xen_pirq_chip,\n\t\t\t\thandle_edge_irq, name);\n\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn irq;\n}\n\n#ifdef CONFIG_PCI_MSI\nint xen_allocate_pirq_msi(struct pci_dev *dev, struct msi_desc *msidesc)\n{\n\tint rc;\n\tstruct physdev_get_free_pirq op_get_free_pirq;\n\n\top_get_free_pirq.type = MAP_PIRQ_TYPE_MSI;\n\trc = HYPERVISOR_physdev_op(PHYSDEVOP_get_free_pirq, &op_get_free_pirq);\n\n\tWARN_ONCE(rc == -ENOSYS,\n\t\t  \"hypervisor does not support the PHYSDEVOP_get_free_pirq interface\\n\");\n\n\treturn rc ? -1 : op_get_free_pirq.pirq;\n}\n\nint xen_bind_pirq_msi_to_irq(struct pci_dev *dev, struct msi_desc *msidesc,\n\t\t\t     int pirq, int nvec, const char *name, domid_t domid)\n{\n\tint i, irq, ret;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = xen_allocate_irqs_dynamic(nvec);\n\tif (irq < 0)\n\t\tgoto out;\n\n\tfor (i = 0; i < nvec; i++) {\n\t\tirq_set_chip_and_handler_name(irq + i, &xen_pirq_chip, handle_edge_irq, name);\n\n\t\tret = xen_irq_info_pirq_setup(irq + i, 0, pirq + i, 0, domid,\n\t\t\t\t\t      i == 0 ? 0 : PIRQ_MSI_GROUP);\n\t\tif (ret < 0)\n\t\t\tgoto error_irq;\n\t}\n\n\tret = irq_set_msi_desc(irq, msidesc);\n\tif (ret < 0)\n\t\tgoto error_irq;\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\treturn irq;\nerror_irq:\n\twhile (nvec--)\n\t\t__unbind_from_irq(irq + nvec);\n\tmutex_unlock(&irq_mapping_update_lock);\n\treturn ret;\n}\n#endif\n\nint xen_destroy_irq(int irq)\n{\n\tstruct physdev_unmap_pirq unmap_irq;\n\tstruct irq_info *info = info_for_irq(irq);\n\tint rc = -ENOENT;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\t/*\n\t * If trying to remove a vector in a MSI group different\n\t * than the first one skip the PIRQ unmap unless this vector\n\t * is the first one in the group.\n\t */\n\tif (xen_initial_domain() && !(info->u.pirq.flags & PIRQ_MSI_GROUP)) {\n\t\tunmap_irq.pirq = info->u.pirq.pirq;\n\t\tunmap_irq.domid = info->u.pirq.domid;\n\t\trc = HYPERVISOR_physdev_op(PHYSDEVOP_unmap_pirq, &unmap_irq);\n\t\t/* If another domain quits without making the pci_disable_msix\n\t\t * call, the Xen hypervisor takes care of freeing the PIRQs\n\t\t * (free_domain_pirqs).\n\t\t */\n\t\tif ((rc == -ESRCH && info->u.pirq.domid != DOMID_SELF))\n\t\t\tpr_info(\"domain %d does not have %d anymore\\n\",\n\t\t\t\tinfo->u.pirq.domid, info->u.pirq.pirq);\n\t\telse if (rc) {\n\t\t\tpr_warn(\"unmap irq failed %d\\n\", rc);\n\t\t\tgoto out;\n\t\t}\n\t}\n\n\txen_free_irq(irq);\n\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\treturn rc;\n}\n\nint xen_irq_from_pirq(unsigned pirq)\n{\n\tint irq;\n\n\tstruct irq_info *info;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tlist_for_each_entry(info, &xen_irq_list_head, list) {\n\t\tif (info->type != IRQT_PIRQ)\n\t\t\tcontinue;\n\t\tirq = info->irq;\n\t\tif (info->u.pirq.pirq == pirq)\n\t\t\tgoto out;\n\t}\n\tirq = -1;\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn irq;\n}\n\n\nint xen_pirq_from_irq(unsigned irq)\n{\n\treturn pirq_from_irq(irq);\n}\nEXPORT_SYMBOL_GPL(xen_pirq_from_irq);\n\nstatic int bind_evtchn_to_irq_chip(evtchn_port_t evtchn, struct irq_chip *chip)\n{\n\tint irq;\n\tint ret;\n\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -ENOMEM;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = get_evtchn_to_irq(evtchn);\n\n\tif (irq == -1) {\n\t\tirq = xen_allocate_irq_dynamic();\n\t\tif (irq < 0)\n\t\t\tgoto out;\n\n\t\tirq_set_chip_and_handler_name(irq, chip,\n\t\t\t\t\t      handle_edge_irq, \"event\");\n\n\t\tret = xen_irq_info_evtchn_setup(irq, evtchn);\n\t\tif (ret < 0) {\n\t\t\t__unbind_from_irq(irq);\n\t\t\tirq = ret;\n\t\t\tgoto out;\n\t\t}\n\t\t/* New interdomain events are bound to VCPU 0. */\n\t\tbind_evtchn_to_cpu(evtchn, 0);\n\t} else {\n\t\tstruct irq_info *info = info_for_irq(irq);\n\t\tWARN_ON(info == NULL || info->type != IRQT_EVTCHN);\n\t}\n\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn irq;\n}\n\nint bind_evtchn_to_irq(evtchn_port_t evtchn)\n{\n\treturn bind_evtchn_to_irq_chip(evtchn, &xen_dynamic_chip);\n}\nEXPORT_SYMBOL_GPL(bind_evtchn_to_irq);\n\nint bind_evtchn_to_irq_lateeoi(evtchn_port_t evtchn)\n{\n\treturn bind_evtchn_to_irq_chip(evtchn, &xen_lateeoi_chip);\n}\nEXPORT_SYMBOL_GPL(bind_evtchn_to_irq_lateeoi);\n\nstatic int bind_ipi_to_irq(unsigned int ipi, unsigned int cpu)\n{\n\tstruct evtchn_bind_ipi bind_ipi;\n\tevtchn_port_t evtchn;\n\tint ret, irq;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = per_cpu(ipi_to_irq, cpu)[ipi];\n\n\tif (irq == -1) {\n\t\tirq = xen_allocate_irq_dynamic();\n\t\tif (irq < 0)\n\t\t\tgoto out;\n\n\t\tirq_set_chip_and_handler_name(irq, &xen_percpu_chip,\n\t\t\t\t\t      handle_percpu_irq, \"ipi\");\n\n\t\tbind_ipi.vcpu = xen_vcpu_nr(cpu);\n\t\tif (HYPERVISOR_event_channel_op(EVTCHNOP_bind_ipi,\n\t\t\t\t\t\t&bind_ipi) != 0)\n\t\t\tBUG();\n\t\tevtchn = bind_ipi.port;\n\n\t\tret = xen_irq_info_ipi_setup(cpu, irq, evtchn, ipi);\n\t\tif (ret < 0) {\n\t\t\t__unbind_from_irq(irq);\n\t\t\tirq = ret;\n\t\t\tgoto out;\n\t\t}\n\t\tbind_evtchn_to_cpu(evtchn, cpu);\n\t} else {\n\t\tstruct irq_info *info = info_for_irq(irq);\n\t\tWARN_ON(info == NULL || info->type != IRQT_IPI);\n\t}\n\n out:\n\tmutex_unlock(&irq_mapping_update_lock);\n\treturn irq;\n}\n\nstatic int bind_interdomain_evtchn_to_irq_chip(unsigned int remote_domain,\n\t\t\t\t\t       evtchn_port_t remote_port,\n\t\t\t\t\t       struct irq_chip *chip)\n{\n\tstruct evtchn_bind_interdomain bind_interdomain;\n\tint err;\n\n\tbind_interdomain.remote_dom  = remote_domain;\n\tbind_interdomain.remote_port = remote_port;\n\n\terr = HYPERVISOR_event_channel_op(EVTCHNOP_bind_interdomain,\n\t\t\t\t\t  &bind_interdomain);\n\n\treturn err ? : bind_evtchn_to_irq_chip(bind_interdomain.local_port,\n\t\t\t\t\t       chip);\n}\n\nint bind_interdomain_evtchn_to_irq(unsigned int remote_domain,\n\t\t\t\t   evtchn_port_t remote_port)\n{\n\treturn bind_interdomain_evtchn_to_irq_chip(remote_domain, remote_port,\n\t\t\t\t\t\t   &xen_dynamic_chip);\n}\nEXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irq);\n\nint bind_interdomain_evtchn_to_irq_lateeoi(unsigned int remote_domain,\n\t\t\t\t\t   evtchn_port_t remote_port)\n{\n\treturn bind_interdomain_evtchn_to_irq_chip(remote_domain, remote_port,\n\t\t\t\t\t\t   &xen_lateeoi_chip);\n}\nEXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irq_lateeoi);\n\nstatic int find_virq(unsigned int virq, unsigned int cpu, evtchn_port_t *evtchn)\n{\n\tstruct evtchn_status status;\n\tevtchn_port_t port;\n\tint rc = -ENOENT;\n\n\tmemset(&status, 0, sizeof(status));\n\tfor (port = 0; port < xen_evtchn_max_channels(); port++) {\n\t\tstatus.dom = DOMID_SELF;\n\t\tstatus.port = port;\n\t\trc = HYPERVISOR_event_channel_op(EVTCHNOP_status, &status);\n\t\tif (rc < 0)\n\t\t\tcontinue;\n\t\tif (status.status != EVTCHNSTAT_virq)\n\t\t\tcontinue;\n\t\tif (status.u.virq == virq && status.vcpu == xen_vcpu_nr(cpu)) {\n\t\t\t*evtchn = port;\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn rc;\n}\n\n/**\n * xen_evtchn_nr_channels - number of usable event channel ports\n *\n * This may be less than the maximum supported by the current\n * hypervisor ABI. Use xen_evtchn_max_channels() for the maximum\n * supported.\n */\nunsigned xen_evtchn_nr_channels(void)\n{\n        return evtchn_ops->nr_channels();\n}\nEXPORT_SYMBOL_GPL(xen_evtchn_nr_channels);\n\nint bind_virq_to_irq(unsigned int virq, unsigned int cpu, bool percpu)\n{\n\tstruct evtchn_bind_virq bind_virq;\n\tevtchn_port_t evtchn = 0;\n\tint irq, ret;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = per_cpu(virq_to_irq, cpu)[virq];\n\n\tif (irq == -1) {\n\t\tirq = xen_allocate_irq_dynamic();\n\t\tif (irq < 0)\n\t\t\tgoto out;\n\n\t\tif (percpu)\n\t\t\tirq_set_chip_and_handler_name(irq, &xen_percpu_chip,\n\t\t\t\t\t\t      handle_percpu_irq, \"virq\");\n\t\telse\n\t\t\tirq_set_chip_and_handler_name(irq, &xen_dynamic_chip,\n\t\t\t\t\t\t      handle_edge_irq, \"virq\");\n\n\t\tbind_virq.virq = virq;\n\t\tbind_virq.vcpu = xen_vcpu_nr(cpu);\n\t\tret = HYPERVISOR_event_channel_op(EVTCHNOP_bind_virq,\n\t\t\t\t\t\t&bind_virq);\n\t\tif (ret == 0)\n\t\t\tevtchn = bind_virq.port;\n\t\telse {\n\t\t\tif (ret == -EEXIST)\n\t\t\t\tret = find_virq(virq, cpu, &evtchn);\n\t\t\tBUG_ON(ret < 0);\n\t\t}\n\n\t\tret = xen_irq_info_virq_setup(cpu, irq, evtchn, virq);\n\t\tif (ret < 0) {\n\t\t\t__unbind_from_irq(irq);\n\t\t\tirq = ret;\n\t\t\tgoto out;\n\t\t}\n\n\t\tbind_evtchn_to_cpu(evtchn, cpu);\n\t} else {\n\t\tstruct irq_info *info = info_for_irq(irq);\n\t\tWARN_ON(info == NULL || info->type != IRQT_VIRQ);\n\t}\n\nout:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn irq;\n}\n\nstatic void unbind_from_irq(unsigned int irq)\n{\n\tmutex_lock(&irq_mapping_update_lock);\n\t__unbind_from_irq(irq);\n\tmutex_unlock(&irq_mapping_update_lock);\n}\n\nstatic int bind_evtchn_to_irqhandler_chip(evtchn_port_t evtchn,\n\t\t\t\t\t  irq_handler_t handler,\n\t\t\t\t\t  unsigned long irqflags,\n\t\t\t\t\t  const char *devname, void *dev_id,\n\t\t\t\t\t  struct irq_chip *chip)\n{\n\tint irq, retval;\n\n\tirq = bind_evtchn_to_irq_chip(evtchn, chip);\n\tif (irq < 0)\n\t\treturn irq;\n\tretval = request_irq(irq, handler, irqflags, devname, dev_id);\n\tif (retval != 0) {\n\t\tunbind_from_irq(irq);\n\t\treturn retval;\n\t}\n\n\treturn irq;\n}\n\nint bind_evtchn_to_irqhandler(evtchn_port_t evtchn,\n\t\t\t      irq_handler_t handler,\n\t\t\t      unsigned long irqflags,\n\t\t\t      const char *devname, void *dev_id)\n{\n\treturn bind_evtchn_to_irqhandler_chip(evtchn, handler, irqflags,\n\t\t\t\t\t      devname, dev_id,\n\t\t\t\t\t      &xen_dynamic_chip);\n}\nEXPORT_SYMBOL_GPL(bind_evtchn_to_irqhandler);\n\nint bind_evtchn_to_irqhandler_lateeoi(evtchn_port_t evtchn,\n\t\t\t\t      irq_handler_t handler,\n\t\t\t\t      unsigned long irqflags,\n\t\t\t\t      const char *devname, void *dev_id)\n{\n\treturn bind_evtchn_to_irqhandler_chip(evtchn, handler, irqflags,\n\t\t\t\t\t      devname, dev_id,\n\t\t\t\t\t      &xen_lateeoi_chip);\n}\nEXPORT_SYMBOL_GPL(bind_evtchn_to_irqhandler_lateeoi);\n\nstatic int bind_interdomain_evtchn_to_irqhandler_chip(\n\t\tunsigned int remote_domain, evtchn_port_t remote_port,\n\t\tirq_handler_t handler, unsigned long irqflags,\n\t\tconst char *devname, void *dev_id, struct irq_chip *chip)\n{\n\tint irq, retval;\n\n\tirq = bind_interdomain_evtchn_to_irq_chip(remote_domain, remote_port,\n\t\t\t\t\t\t  chip);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tretval = request_irq(irq, handler, irqflags, devname, dev_id);\n\tif (retval != 0) {\n\t\tunbind_from_irq(irq);\n\t\treturn retval;\n\t}\n\n\treturn irq;\n}\n\nint bind_interdomain_evtchn_to_irqhandler(unsigned int remote_domain,\n\t\t\t\t\t  evtchn_port_t remote_port,\n\t\t\t\t\t  irq_handler_t handler,\n\t\t\t\t\t  unsigned long irqflags,\n\t\t\t\t\t  const char *devname,\n\t\t\t\t\t  void *dev_id)\n{\n\treturn bind_interdomain_evtchn_to_irqhandler_chip(remote_domain,\n\t\t\t\tremote_port, handler, irqflags, devname,\n\t\t\t\tdev_id, &xen_dynamic_chip);\n}\nEXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irqhandler);\n\nint bind_interdomain_evtchn_to_irqhandler_lateeoi(unsigned int remote_domain,\n\t\t\t\t\t\t  evtchn_port_t remote_port,\n\t\t\t\t\t\t  irq_handler_t handler,\n\t\t\t\t\t\t  unsigned long irqflags,\n\t\t\t\t\t\t  const char *devname,\n\t\t\t\t\t\t  void *dev_id)\n{\n\treturn bind_interdomain_evtchn_to_irqhandler_chip(remote_domain,\n\t\t\t\tremote_port, handler, irqflags, devname,\n\t\t\t\tdev_id, &xen_lateeoi_chip);\n}\nEXPORT_SYMBOL_GPL(bind_interdomain_evtchn_to_irqhandler_lateeoi);\n\nint bind_virq_to_irqhandler(unsigned int virq, unsigned int cpu,\n\t\t\t    irq_handler_t handler,\n\t\t\t    unsigned long irqflags, const char *devname, void *dev_id)\n{\n\tint irq, retval;\n\n\tirq = bind_virq_to_irq(virq, cpu, irqflags & IRQF_PERCPU);\n\tif (irq < 0)\n\t\treturn irq;\n\tretval = request_irq(irq, handler, irqflags, devname, dev_id);\n\tif (retval != 0) {\n\t\tunbind_from_irq(irq);\n\t\treturn retval;\n\t}\n\n\treturn irq;\n}\nEXPORT_SYMBOL_GPL(bind_virq_to_irqhandler);\n\nint bind_ipi_to_irqhandler(enum ipi_vector ipi,\n\t\t\t   unsigned int cpu,\n\t\t\t   irq_handler_t handler,\n\t\t\t   unsigned long irqflags,\n\t\t\t   const char *devname,\n\t\t\t   void *dev_id)\n{\n\tint irq, retval;\n\n\tirq = bind_ipi_to_irq(ipi, cpu);\n\tif (irq < 0)\n\t\treturn irq;\n\n\tirqflags |= IRQF_NO_SUSPEND | IRQF_FORCE_RESUME | IRQF_EARLY_RESUME;\n\tretval = request_irq(irq, handler, irqflags, devname, dev_id);\n\tif (retval != 0) {\n\t\tunbind_from_irq(irq);\n\t\treturn retval;\n\t}\n\n\treturn irq;\n}\n\nvoid unbind_from_irqhandler(unsigned int irq, void *dev_id)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tif (WARN_ON(!info))\n\t\treturn;\n\tfree_irq(irq, dev_id);\n\tunbind_from_irq(irq);\n}\nEXPORT_SYMBOL_GPL(unbind_from_irqhandler);\n\n/**\n * xen_set_irq_priority() - set an event channel priority.\n * @irq:irq bound to an event channel.\n * @priority: priority between XEN_IRQ_PRIORITY_MAX and XEN_IRQ_PRIORITY_MIN.\n */\nint xen_set_irq_priority(unsigned irq, unsigned priority)\n{\n\tstruct evtchn_set_priority set_priority;\n\n\tset_priority.port = evtchn_from_irq(irq);\n\tset_priority.priority = priority;\n\n\treturn HYPERVISOR_event_channel_op(EVTCHNOP_set_priority,\n\t\t\t\t\t   &set_priority);\n}\nEXPORT_SYMBOL_GPL(xen_set_irq_priority);\n\nint evtchn_make_refcounted(evtchn_port_t evtchn)\n{\n\tint irq = get_evtchn_to_irq(evtchn);\n\tstruct irq_info *info;\n\n\tif (irq == -1)\n\t\treturn -ENOENT;\n\n\tinfo = info_for_irq(irq);\n\n\tif (!info)\n\t\treturn -ENOENT;\n\n\tWARN_ON(info->refcnt != -1);\n\n\tinfo->refcnt = 1;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(evtchn_make_refcounted);\n\nint evtchn_get(evtchn_port_t evtchn)\n{\n\tint irq;\n\tstruct irq_info *info;\n\tint err = -ENOENT;\n\n\tif (evtchn >= xen_evtchn_max_channels())\n\t\treturn -EINVAL;\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\tirq = get_evtchn_to_irq(evtchn);\n\tif (irq == -1)\n\t\tgoto done;\n\n\tinfo = info_for_irq(irq);\n\n\tif (!info)\n\t\tgoto done;\n\n\terr = -EINVAL;\n\tif (info->refcnt <= 0)\n\t\tgoto done;\n\n\tinfo->refcnt++;\n\terr = 0;\n done:\n\tmutex_unlock(&irq_mapping_update_lock);\n\n\treturn err;\n}\nEXPORT_SYMBOL_GPL(evtchn_get);\n\nvoid evtchn_put(evtchn_port_t evtchn)\n{\n\tint irq = get_evtchn_to_irq(evtchn);\n\tif (WARN_ON(irq == -1))\n\t\treturn;\n\tunbind_from_irq(irq);\n}\nEXPORT_SYMBOL_GPL(evtchn_put);\n\nvoid xen_send_IPI_one(unsigned int cpu, enum ipi_vector vector)\n{\n\tint irq;\n\n#ifdef CONFIG_X86\n\tif (unlikely(vector == XEN_NMI_VECTOR)) {\n\t\tint rc =  HYPERVISOR_vcpu_op(VCPUOP_send_nmi, xen_vcpu_nr(cpu),\n\t\t\t\t\t     NULL);\n\t\tif (rc < 0)\n\t\t\tprintk(KERN_WARNING \"Sending nmi to CPU%d failed (rc:%d)\\n\", cpu, rc);\n\t\treturn;\n\t}\n#endif\n\tirq = per_cpu(ipi_to_irq, cpu)[vector];\n\tBUG_ON(irq < 0);\n\tnotify_remote_via_irq(irq);\n}\n\nstruct evtchn_loop_ctrl {\n\tktime_t timeout;\n\tunsigned count;\n\tbool defer_eoi;\n};\n\nvoid handle_irq_for_port(evtchn_port_t port, struct evtchn_loop_ctrl *ctrl)\n{\n\tint irq;\n\tstruct irq_info *info;\n\n\tirq = get_evtchn_to_irq(port);\n\tif (irq == -1)\n\t\treturn;\n\n\t/*\n\t * Check for timeout every 256 events.\n\t * We are setting the timeout value only after the first 256\n\t * events in order to not hurt the common case of few loop\n\t * iterations. The 256 is basically an arbitrary value.\n\t *\n\t * In case we are hitting the timeout we need to defer all further\n\t * EOIs in order to ensure to leave the event handling loop rather\n\t * sooner than later.\n\t */\n\tif (!ctrl->defer_eoi && !(++ctrl->count & 0xff)) {\n\t\tktime_t kt = ktime_get();\n\n\t\tif (!ctrl->timeout) {\n\t\t\tkt = ktime_add_ms(kt,\n\t\t\t\t\t  jiffies_to_msecs(event_loop_timeout));\n\t\t\tctrl->timeout = kt;\n\t\t} else if (kt > ctrl->timeout) {\n\t\t\tctrl->defer_eoi = true;\n\t\t}\n\t}\n\n\tinfo = info_for_irq(irq);\n\n\tif (ctrl->defer_eoi) {\n\t\tinfo->eoi_cpu = smp_processor_id();\n\t\tinfo->irq_epoch = __this_cpu_read(irq_epoch);\n\t\tinfo->eoi_time = get_jiffies_64() + event_eoi_delay;\n\t}\n\n\tgeneric_handle_irq(irq);\n}\n\nstatic void __xen_evtchn_do_upcall(void)\n{\n\tstruct vcpu_info *vcpu_info = __this_cpu_read(xen_vcpu);\n\tint cpu = smp_processor_id();\n\tstruct evtchn_loop_ctrl ctrl = { 0 };\n\n\tread_lock(&evtchn_rwlock);\n\n\tdo {\n\t\tvcpu_info->evtchn_upcall_pending = 0;\n\n\t\txen_evtchn_handle_events(cpu, &ctrl);\n\n\t\tBUG_ON(!irqs_disabled());\n\n\t\tvirt_rmb(); /* Hypervisor can set upcall pending. */\n\n\t} while (vcpu_info->evtchn_upcall_pending);\n\n\tread_unlock(&evtchn_rwlock);\n\n\t/*\n\t * Increment irq_epoch only now to defer EOIs only for\n\t * xen_irq_lateeoi() invocations occurring from inside the loop\n\t * above.\n\t */\n\t__this_cpu_inc(irq_epoch);\n}\n\nvoid xen_evtchn_do_upcall(struct pt_regs *regs)\n{\n\tstruct pt_regs *old_regs = set_irq_regs(regs);\n\n\tirq_enter();\n\n\t__xen_evtchn_do_upcall();\n\n\tirq_exit();\n\tset_irq_regs(old_regs);\n}\n\nvoid xen_hvm_evtchn_do_upcall(void)\n{\n\t__xen_evtchn_do_upcall();\n}\nEXPORT_SYMBOL_GPL(xen_hvm_evtchn_do_upcall);\n\n/* Rebind a new event channel to an existing irq. */\nvoid rebind_evtchn_irq(evtchn_port_t evtchn, int irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\n\tif (WARN_ON(!info))\n\t\treturn;\n\n\t/* Make sure the irq is masked, since the new event channel\n\t   will also be masked. */\n\tdisable_irq(irq);\n\n\tmutex_lock(&irq_mapping_update_lock);\n\n\t/* After resume the irq<->evtchn mappings are all cleared out */\n\tBUG_ON(get_evtchn_to_irq(evtchn) != -1);\n\t/* Expect irq to have been bound before,\n\t   so there should be a proper type */\n\tBUG_ON(info->type == IRQT_UNBOUND);\n\n\t(void)xen_irq_info_evtchn_setup(irq, evtchn);\n\n\tmutex_unlock(&irq_mapping_update_lock);\n\n        bind_evtchn_to_cpu(evtchn, info->cpu);\n\t/* This will be deferred until interrupt is processed */\n\tirq_set_affinity(irq, cpumask_of(info->cpu));\n\n\t/* Unmask the event channel. */\n\tenable_irq(irq);\n}\n\n/* Rebind an evtchn so that it gets delivered to a specific cpu */\nstatic int xen_rebind_evtchn_to_cpu(evtchn_port_t evtchn, unsigned int tcpu)\n{\n\tstruct evtchn_bind_vcpu bind_vcpu;\n\tint masked;\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn -1;\n\n\tif (!xen_support_evtchn_rebind())\n\t\treturn -1;\n\n\t/* Send future instances of this interrupt to other vcpu. */\n\tbind_vcpu.port = evtchn;\n\tbind_vcpu.vcpu = xen_vcpu_nr(tcpu);\n\n\t/*\n\t * Mask the event while changing the VCPU binding to prevent\n\t * it being delivered on an unexpected VCPU.\n\t */\n\tmasked = test_and_set_mask(evtchn);\n\n\t/*\n\t * If this fails, it usually just indicates that we're dealing with a\n\t * virq or IPI channel, which don't actually need to be rebound. Ignore\n\t * it, but don't do the xenlinux-level rebind in that case.\n\t */\n\tif (HYPERVISOR_event_channel_op(EVTCHNOP_bind_vcpu, &bind_vcpu) >= 0)\n\t\tbind_evtchn_to_cpu(evtchn, tcpu);\n\n\tif (!masked)\n\t\tunmask_evtchn(evtchn);\n\n\treturn 0;\n}\n\nstatic int set_affinity_irq(struct irq_data *data, const struct cpumask *dest,\n\t\t\t    bool force)\n{\n\tunsigned tcpu = cpumask_first_and(dest, cpu_online_mask);\n\tint ret = xen_rebind_evtchn_to_cpu(evtchn_from_irq(data->irq), tcpu);\n\n\tif (!ret)\n\t\tirq_data_update_effective_affinity(data, cpumask_of(tcpu));\n\n\treturn ret;\n}\n\n/* To be called with desc->lock held. */\nint xen_set_affinity_evtchn(struct irq_desc *desc, unsigned int tcpu)\n{\n\tstruct irq_data *d = irq_desc_get_irq_data(desc);\n\n\treturn set_affinity_irq(d, cpumask_of(tcpu), false);\n}\nEXPORT_SYMBOL_GPL(xen_set_affinity_evtchn);\n\nstatic void enable_dynirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tunmask_evtchn(evtchn);\n}\n\nstatic void disable_dynirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tmask_evtchn(evtchn);\n}\n\nstatic void ack_dynirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn;\n\n\tif (unlikely(irqd_is_setaffinity_pending(data)) &&\n\t    likely(!irqd_irq_disabled(data))) {\n\t\tint masked = test_and_set_mask(evtchn);\n\n\t\tclear_evtchn(evtchn);\n\n\t\tirq_move_masked_irq(data);\n\n\t\tif (!masked)\n\t\t\tunmask_evtchn(evtchn);\n\t} else\n\t\tclear_evtchn(evtchn);\n}\n\nstatic void mask_ack_dynirq(struct irq_data *data)\n{\n\tdisable_dynirq(data);\n\tack_dynirq(data);\n}\n\nstatic int retrigger_dynirq(struct irq_data *data)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(data->irq);\n\tint masked;\n\n\tif (!VALID_EVTCHN(evtchn))\n\t\treturn 0;\n\n\tmasked = test_and_set_mask(evtchn);\n\tset_evtchn(evtchn);\n\tif (!masked)\n\t\tunmask_evtchn(evtchn);\n\n\treturn 1;\n}\n\nstatic void restore_pirqs(void)\n{\n\tint pirq, rc, irq, gsi;\n\tstruct physdev_map_pirq map_irq;\n\tstruct irq_info *info;\n\n\tlist_for_each_entry(info, &xen_irq_list_head, list) {\n\t\tif (info->type != IRQT_PIRQ)\n\t\t\tcontinue;\n\n\t\tpirq = info->u.pirq.pirq;\n\t\tgsi = info->u.pirq.gsi;\n\t\tirq = info->irq;\n\n\t\t/* save/restore of PT devices doesn't work, so at this point the\n\t\t * only devices present are GSI based emulated devices */\n\t\tif (!gsi)\n\t\t\tcontinue;\n\n\t\tmap_irq.domid = DOMID_SELF;\n\t\tmap_irq.type = MAP_PIRQ_TYPE_GSI;\n\t\tmap_irq.index = gsi;\n\t\tmap_irq.pirq = pirq;\n\n\t\trc = HYPERVISOR_physdev_op(PHYSDEVOP_map_pirq, &map_irq);\n\t\tif (rc) {\n\t\t\tpr_warn(\"xen map irq failed gsi=%d irq=%d pirq=%d rc=%d\\n\",\n\t\t\t\tgsi, irq, pirq, rc);\n\t\t\txen_free_irq(irq);\n\t\t\tcontinue;\n\t\t}\n\n\t\tprintk(KERN_DEBUG \"xen: --> irq=%d, pirq=%d\\n\", irq, map_irq.pirq);\n\n\t\t__startup_pirq(irq);\n\t}\n}\n\nstatic void restore_cpu_virqs(unsigned int cpu)\n{\n\tstruct evtchn_bind_virq bind_virq;\n\tevtchn_port_t evtchn;\n\tint virq, irq;\n\n\tfor (virq = 0; virq < NR_VIRQS; virq++) {\n\t\tif ((irq = per_cpu(virq_to_irq, cpu)[virq]) == -1)\n\t\t\tcontinue;\n\n\t\tBUG_ON(virq_from_irq(irq) != virq);\n\n\t\t/* Get a new binding from Xen. */\n\t\tbind_virq.virq = virq;\n\t\tbind_virq.vcpu = xen_vcpu_nr(cpu);\n\t\tif (HYPERVISOR_event_channel_op(EVTCHNOP_bind_virq,\n\t\t\t\t\t\t&bind_virq) != 0)\n\t\t\tBUG();\n\t\tevtchn = bind_virq.port;\n\n\t\t/* Record the new mapping. */\n\t\t(void)xen_irq_info_virq_setup(cpu, irq, evtchn, virq);\n\t\tbind_evtchn_to_cpu(evtchn, cpu);\n\t}\n}\n\nstatic void restore_cpu_ipis(unsigned int cpu)\n{\n\tstruct evtchn_bind_ipi bind_ipi;\n\tevtchn_port_t evtchn;\n\tint ipi, irq;\n\n\tfor (ipi = 0; ipi < XEN_NR_IPIS; ipi++) {\n\t\tif ((irq = per_cpu(ipi_to_irq, cpu)[ipi]) == -1)\n\t\t\tcontinue;\n\n\t\tBUG_ON(ipi_from_irq(irq) != ipi);\n\n\t\t/* Get a new binding from Xen. */\n\t\tbind_ipi.vcpu = xen_vcpu_nr(cpu);\n\t\tif (HYPERVISOR_event_channel_op(EVTCHNOP_bind_ipi,\n\t\t\t\t\t\t&bind_ipi) != 0)\n\t\t\tBUG();\n\t\tevtchn = bind_ipi.port;\n\n\t\t/* Record the new mapping. */\n\t\t(void)xen_irq_info_ipi_setup(cpu, irq, evtchn, ipi);\n\t\tbind_evtchn_to_cpu(evtchn, cpu);\n\t}\n}\n\n/* Clear an irq's pending state, in preparation for polling on it */\nvoid xen_clear_irq_pending(int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tclear_evtchn(evtchn);\n}\nEXPORT_SYMBOL(xen_clear_irq_pending);\nvoid xen_set_irq_pending(int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tset_evtchn(evtchn);\n}\n\nbool xen_test_irq_pending(int irq)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\tbool ret = false;\n\n\tif (VALID_EVTCHN(evtchn))\n\t\tret = test_evtchn(evtchn);\n\n\treturn ret;\n}\n\n/* Poll waiting for an irq to become pending with timeout.  In the usual case,\n * the irq will be disabled so it won't deliver an interrupt. */\nvoid xen_poll_irq_timeout(int irq, u64 timeout)\n{\n\tevtchn_port_t evtchn = evtchn_from_irq(irq);\n\n\tif (VALID_EVTCHN(evtchn)) {\n\t\tstruct sched_poll poll;\n\n\t\tpoll.nr_ports = 1;\n\t\tpoll.timeout = timeout;\n\t\tset_xen_guest_handle(poll.ports, &evtchn);\n\n\t\tif (HYPERVISOR_sched_op(SCHEDOP_poll, &poll) != 0)\n\t\t\tBUG();\n\t}\n}\nEXPORT_SYMBOL(xen_poll_irq_timeout);\n/* Poll waiting for an irq to become pending.  In the usual case, the\n * irq will be disabled so it won't deliver an interrupt. */\nvoid xen_poll_irq(int irq)\n{\n\txen_poll_irq_timeout(irq, 0 /* no timeout */);\n}\n\n/* Check whether the IRQ line is shared with other guests. */\nint xen_test_irq_shared(int irq)\n{\n\tstruct irq_info *info = info_for_irq(irq);\n\tstruct physdev_irq_status_query irq_status;\n\n\tif (WARN_ON(!info))\n\t\treturn -ENOENT;\n\n\tirq_status.irq = info->u.pirq.pirq;\n\n\tif (HYPERVISOR_physdev_op(PHYSDEVOP_irq_status_query, &irq_status))\n\t\treturn 0;\n\treturn !(irq_status.flags & XENIRQSTAT_shared);\n}\nEXPORT_SYMBOL_GPL(xen_test_irq_shared);\n\nvoid xen_irq_resume(void)\n{\n\tunsigned int cpu;\n\tstruct irq_info *info;\n\n\t/* New event-channel space is not 'live' yet. */\n\txen_evtchn_resume();\n\n\t/* No IRQ <-> event-channel mappings. */\n\tlist_for_each_entry(info, &xen_irq_list_head, list)\n\t\tinfo->evtchn = 0; /* zap event-channel binding */\n\n\tclear_evtchn_to_irq_all();\n\n\tfor_each_possible_cpu(cpu) {\n\t\trestore_cpu_virqs(cpu);\n\t\trestore_cpu_ipis(cpu);\n\t}\n\n\trestore_pirqs();\n}\n\nstatic struct irq_chip xen_dynamic_chip __read_mostly = {\n\t.name\t\t\t= \"xen-dyn\",\n\n\t.irq_disable\t\t= disable_dynirq,\n\t.irq_mask\t\t= disable_dynirq,\n\t.irq_unmask\t\t= enable_dynirq,\n\n\t.irq_ack\t\t= ack_dynirq,\n\t.irq_mask_ack\t\t= mask_ack_dynirq,\n\n\t.irq_set_affinity\t= set_affinity_irq,\n\t.irq_retrigger\t\t= retrigger_dynirq,\n};\n\nstatic struct irq_chip xen_lateeoi_chip __read_mostly = {\n\t/* The chip name needs to contain \"xen-dyn\" for irqbalance to work. */\n\t.name\t\t\t= \"xen-dyn-lateeoi\",\n\n\t.irq_disable\t\t= disable_dynirq,\n\t.irq_mask\t\t= disable_dynirq,\n\t.irq_unmask\t\t= enable_dynirq,\n\n\t.irq_ack\t\t= mask_ack_dynirq,\n\t.irq_mask_ack\t\t= mask_ack_dynirq,\n\n\t.irq_set_affinity\t= set_affinity_irq,\n\t.irq_retrigger\t\t= retrigger_dynirq,\n};\n\nstatic struct irq_chip xen_pirq_chip __read_mostly = {\n\t.name\t\t\t= \"xen-pirq\",\n\n\t.irq_startup\t\t= startup_pirq,\n\t.irq_shutdown\t\t= shutdown_pirq,\n\t.irq_enable\t\t= enable_pirq,\n\t.irq_disable\t\t= disable_pirq,\n\n\t.irq_mask\t\t= disable_dynirq,\n\t.irq_unmask\t\t= enable_dynirq,\n\n\t.irq_ack\t\t= eoi_pirq,\n\t.irq_eoi\t\t= eoi_pirq,\n\t.irq_mask_ack\t\t= mask_ack_pirq,\n\n\t.irq_set_affinity\t= set_affinity_irq,\n\n\t.irq_retrigger\t\t= retrigger_dynirq,\n};\n\nstatic struct irq_chip xen_percpu_chip __read_mostly = {\n\t.name\t\t\t= \"xen-percpu\",\n\n\t.irq_disable\t\t= disable_dynirq,\n\t.irq_mask\t\t= disable_dynirq,\n\t.irq_unmask\t\t= enable_dynirq,\n\n\t.irq_ack\t\t= ack_dynirq,\n};\n\nint xen_set_callback_via(uint64_t via)\n{\n\tstruct xen_hvm_param a;\n\ta.domid = DOMID_SELF;\n\ta.index = HVM_PARAM_CALLBACK_IRQ;\n\ta.value = via;\n\treturn HYPERVISOR_hvm_op(HVMOP_set_param, &a);\n}\nEXPORT_SYMBOL_GPL(xen_set_callback_via);\n\n#ifdef CONFIG_XEN_PVHVM\n/* Vector callbacks are better than PCI interrupts to receive event\n * channel notifications because we can receive vector callbacks on any\n * vcpu and we don't need PCI support or APIC interactions. */\nvoid xen_setup_callback_vector(void)\n{\n\tuint64_t callback_via;\n\n\tif (xen_have_vector_callback) {\n\t\tcallback_via = HVM_CALLBACK_VECTOR(HYPERVISOR_CALLBACK_VECTOR);\n\t\tif (xen_set_callback_via(callback_via)) {\n\t\t\tpr_err(\"Request for Xen HVM callback vector failed\\n\");\n\t\t\txen_have_vector_callback = 0;\n\t\t}\n\t}\n}\n\nstatic __init void xen_alloc_callback_vector(void)\n{\n\tif (!xen_have_vector_callback)\n\t\treturn;\n\n\tpr_info(\"Xen HVM callback vector for event delivery is enabled\\n\");\n\talloc_intr_gate(HYPERVISOR_CALLBACK_VECTOR, asm_sysvec_xen_hvm_callback);\n}\n#else\nvoid xen_setup_callback_vector(void) {}\nstatic inline void xen_alloc_callback_vector(void) {}\n#endif\n\nstatic bool fifo_events = true;\nmodule_param(fifo_events, bool, 0);\n\nstatic int xen_evtchn_cpu_prepare(unsigned int cpu)\n{\n\tint ret = 0;\n\n\txen_cpu_init_eoi(cpu);\n\n\tif (evtchn_ops->percpu_init)\n\t\tret = evtchn_ops->percpu_init(cpu);\n\n\treturn ret;\n}\n\nstatic int xen_evtchn_cpu_dead(unsigned int cpu)\n{\n\tint ret = 0;\n\n\tif (evtchn_ops->percpu_deinit)\n\t\tret = evtchn_ops->percpu_deinit(cpu);\n\n\treturn ret;\n}\n\nvoid __init xen_init_IRQ(void)\n{\n\tint ret = -EINVAL;\n\tevtchn_port_t evtchn;\n\n\tif (fifo_events)\n\t\tret = xen_evtchn_fifo_init();\n\tif (ret < 0)\n\t\txen_evtchn_2l_init();\n\n\txen_cpu_init_eoi(smp_processor_id());\n\n\tcpuhp_setup_state_nocalls(CPUHP_XEN_EVTCHN_PREPARE,\n\t\t\t\t  \"xen/evtchn:prepare\",\n\t\t\t\t  xen_evtchn_cpu_prepare, xen_evtchn_cpu_dead);\n\n\tevtchn_to_irq = kcalloc(EVTCHN_ROW(xen_evtchn_max_channels()),\n\t\t\t\tsizeof(*evtchn_to_irq), GFP_KERNEL);\n\tBUG_ON(!evtchn_to_irq);\n\n\t/* No event channels are 'live' right now. */\n\tfor (evtchn = 0; evtchn < xen_evtchn_nr_channels(); evtchn++)\n\t\tmask_evtchn(evtchn);\n\n\tpirq_needs_eoi = pirq_needs_eoi_flag;\n\n#ifdef CONFIG_X86\n\tif (xen_pv_domain()) {\n\t\tif (xen_initial_domain())\n\t\t\tpci_xen_initial_domain();\n\t}\n\tif (xen_feature(XENFEAT_hvm_callback_vector)) {\n\t\txen_setup_callback_vector();\n\t\txen_alloc_callback_vector();\n\t}\n\n\tif (xen_hvm_domain()) {\n\t\tnative_init_IRQ();\n\t\t/* pci_xen_hvm_init must be called after native_init_IRQ so that\n\t\t * __acpi_register_gsi can point at the right function */\n\t\tpci_xen_hvm_init();\n\t} else {\n\t\tint rc;\n\t\tstruct physdev_pirq_eoi_gmfn eoi_gmfn;\n\n\t\tpirq_eoi_map = (void *)__get_free_page(GFP_KERNEL|__GFP_ZERO);\n\t\teoi_gmfn.gmfn = virt_to_gfn(pirq_eoi_map);\n\t\trc = HYPERVISOR_physdev_op(PHYSDEVOP_pirq_eoi_gmfn_v2, &eoi_gmfn);\n\t\tif (rc != 0) {\n\t\t\tfree_page((unsigned long) pirq_eoi_map);\n\t\t\tpirq_eoi_map = NULL;\n\t\t} else\n\t\t\tpirq_needs_eoi = pirq_check_eoi_map;\n\t}\n#endif\n}\n", "/*\n * Xen event channels (FIFO-based ABI)\n *\n * Copyright (C) 2013 Citrix Systems R&D ltd.\n *\n * This source code is free software; you can redistribute it and/or\n * modify it under the terms of the GNU General Public License as\n * published by the Free Software Foundation; either version 2 of the\n * License, or (at your option) any later version.\n *\n * Or, when distributed separately from the Linux kernel or\n * incorporated into other software packages, subject to the following\n * license:\n *\n * Permission is hereby granted, free of charge, to any person obtaining a copy\n * of this source file (the \"Software\"), to deal in the Software without\n * restriction, including without limitation the rights to use, copy, modify,\n * merge, publish, distribute, sublicense, and/or sell copies of the Software,\n * and to permit persons to whom the Software is furnished to do so, subject to\n * the following conditions:\n *\n * The above copyright notice and this permission notice shall be included in\n * all copies or substantial portions of the Software.\n *\n * THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS\n * IN THE SOFTWARE.\n */\n\n#define pr_fmt(fmt) \"xen:\" KBUILD_MODNAME \": \" fmt\n\n#include <linux/linkage.h>\n#include <linux/interrupt.h>\n#include <linux/irq.h>\n#include <linux/smp.h>\n#include <linux/percpu.h>\n#include <linux/cpu.h>\n\n#include <asm/barrier.h>\n#include <asm/sync_bitops.h>\n#include <asm/xen/hypercall.h>\n#include <asm/xen/hypervisor.h>\n\n#include <xen/xen.h>\n#include <xen/xen-ops.h>\n#include <xen/events.h>\n#include <xen/interface/xen.h>\n#include <xen/interface/event_channel.h>\n#include <xen/page.h>\n\n#include \"events_internal.h\"\n\n#define EVENT_WORDS_PER_PAGE (XEN_PAGE_SIZE / sizeof(event_word_t))\n#define MAX_EVENT_ARRAY_PAGES (EVTCHN_FIFO_NR_CHANNELS / EVENT_WORDS_PER_PAGE)\n\nstruct evtchn_fifo_queue {\n\tuint32_t head[EVTCHN_FIFO_MAX_QUEUES];\n};\n\nstatic DEFINE_PER_CPU(struct evtchn_fifo_control_block *, cpu_control_block);\nstatic DEFINE_PER_CPU(struct evtchn_fifo_queue, cpu_queue);\nstatic event_word_t *event_array[MAX_EVENT_ARRAY_PAGES] __read_mostly;\nstatic unsigned event_array_pages __read_mostly;\n\n/*\n * sync_set_bit() and friends must be unsigned long aligned.\n */\n#if BITS_PER_LONG > 32\n\n#define BM(w) (unsigned long *)((unsigned long)w & ~0x7UL)\n#define EVTCHN_FIFO_BIT(b, w) \\\n    (((unsigned long)w & 0x4UL) ? (EVTCHN_FIFO_ ##b + 32) : EVTCHN_FIFO_ ##b)\n\n#else\n\n#define BM(w) ((unsigned long *)(w))\n#define EVTCHN_FIFO_BIT(b, w) EVTCHN_FIFO_ ##b\n\n#endif\n\nstatic inline event_word_t *event_word_from_port(evtchn_port_t port)\n{\n\tunsigned i = port / EVENT_WORDS_PER_PAGE;\n\n\treturn event_array[i] + port % EVENT_WORDS_PER_PAGE;\n}\n\nstatic unsigned evtchn_fifo_max_channels(void)\n{\n\treturn EVTCHN_FIFO_NR_CHANNELS;\n}\n\nstatic unsigned evtchn_fifo_nr_channels(void)\n{\n\treturn event_array_pages * EVENT_WORDS_PER_PAGE;\n}\n\nstatic int init_control_block(int cpu,\n                              struct evtchn_fifo_control_block *control_block)\n{\n\tstruct evtchn_fifo_queue *q = &per_cpu(cpu_queue, cpu);\n\tstruct evtchn_init_control init_control;\n\tunsigned int i;\n\n\t/* Reset the control block and the local HEADs. */\n\tclear_page(control_block);\n\tfor (i = 0; i < EVTCHN_FIFO_MAX_QUEUES; i++)\n\t\tq->head[i] = 0;\n\n\tinit_control.control_gfn = virt_to_gfn(control_block);\n\tinit_control.offset      = 0;\n\tinit_control.vcpu        = xen_vcpu_nr(cpu);\n\n\treturn HYPERVISOR_event_channel_op(EVTCHNOP_init_control, &init_control);\n}\n\nstatic void free_unused_array_pages(void)\n{\n\tunsigned i;\n\n\tfor (i = event_array_pages; i < MAX_EVENT_ARRAY_PAGES; i++) {\n\t\tif (!event_array[i])\n\t\t\tbreak;\n\t\tfree_page((unsigned long)event_array[i]);\n\t\tevent_array[i] = NULL;\n\t}\n}\n\nstatic void init_array_page(event_word_t *array_page)\n{\n\tunsigned i;\n\n\tfor (i = 0; i < EVENT_WORDS_PER_PAGE; i++)\n\t\tarray_page[i] = 1 << EVTCHN_FIFO_MASKED;\n}\n\nstatic int evtchn_fifo_setup(struct irq_info *info)\n{\n\tevtchn_port_t port = info->evtchn;\n\tunsigned new_array_pages;\n\tint ret;\n\n\tnew_array_pages = port / EVENT_WORDS_PER_PAGE + 1;\n\n\tif (new_array_pages > MAX_EVENT_ARRAY_PAGES)\n\t\treturn -EINVAL;\n\n\twhile (event_array_pages < new_array_pages) {\n\t\tvoid *array_page;\n\t\tstruct evtchn_expand_array expand_array;\n\n\t\t/* Might already have a page if we've resumed. */\n\t\tarray_page = event_array[event_array_pages];\n\t\tif (!array_page) {\n\t\t\tarray_page = (void *)__get_free_page(GFP_KERNEL);\n\t\t\tif (array_page == NULL) {\n\t\t\t\tret = -ENOMEM;\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t\tevent_array[event_array_pages] = array_page;\n\t\t}\n\n\t\t/* Mask all events in this page before adding it. */\n\t\tinit_array_page(array_page);\n\n\t\texpand_array.array_gfn = virt_to_gfn(array_page);\n\n\t\tret = HYPERVISOR_event_channel_op(EVTCHNOP_expand_array, &expand_array);\n\t\tif (ret < 0)\n\t\t\tgoto error;\n\n\t\tevent_array_pages++;\n\t}\n\treturn 0;\n\n  error:\n\tif (event_array_pages == 0)\n\t\tpanic(\"xen: unable to expand event array with initial page (%d)\\n\", ret);\n\telse\n\t\tpr_err(\"unable to expand event array (%d)\\n\", ret);\n\tfree_unused_array_pages();\n\treturn ret;\n}\n\nstatic void evtchn_fifo_bind_to_cpu(struct irq_info *info, unsigned cpu)\n{\n\t/* no-op */\n}\n\nstatic void evtchn_fifo_clear_pending(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\tsync_clear_bit(EVTCHN_FIFO_BIT(PENDING, word), BM(word));\n}\n\nstatic void evtchn_fifo_set_pending(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\tsync_set_bit(EVTCHN_FIFO_BIT(PENDING, word), BM(word));\n}\n\nstatic bool evtchn_fifo_is_pending(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\treturn sync_test_bit(EVTCHN_FIFO_BIT(PENDING, word), BM(word));\n}\n\nstatic bool evtchn_fifo_test_and_set_mask(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\treturn sync_test_and_set_bit(EVTCHN_FIFO_BIT(MASKED, word), BM(word));\n}\n\nstatic void evtchn_fifo_mask(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\tsync_set_bit(EVTCHN_FIFO_BIT(MASKED, word), BM(word));\n}\n\nstatic bool evtchn_fifo_is_masked(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\treturn sync_test_bit(EVTCHN_FIFO_BIT(MASKED, word), BM(word));\n}\n/*\n * Clear MASKED if not PENDING, spinning if BUSY is set.\n * Return true if mask was cleared.\n */\nstatic bool clear_masked_cond(volatile event_word_t *word)\n{\n\tevent_word_t new, old, w;\n\n\tw = *word;\n\n\tdo {\n\t\tif (w & (1 << EVTCHN_FIFO_PENDING))\n\t\t\treturn false;\n\n\t\told = w & ~(1 << EVTCHN_FIFO_BUSY);\n\t\tnew = old & ~(1 << EVTCHN_FIFO_MASKED);\n\t\tw = sync_cmpxchg(word, old, new);\n\t} while (w != old);\n\n\treturn true;\n}\n\nstatic void evtchn_fifo_unmask(evtchn_port_t port)\n{\n\tevent_word_t *word = event_word_from_port(port);\n\n\tBUG_ON(!irqs_disabled());\n\n\tif (!clear_masked_cond(word)) {\n\t\tstruct evtchn_unmask unmask = { .port = port };\n\t\t(void)HYPERVISOR_event_channel_op(EVTCHNOP_unmask, &unmask);\n\t}\n}\n\nstatic uint32_t clear_linked(volatile event_word_t *word)\n{\n\tevent_word_t new, old, w;\n\n\tw = *word;\n\n\tdo {\n\t\told = w;\n\t\tnew = (w & ~((1 << EVTCHN_FIFO_LINKED)\n\t\t\t     | EVTCHN_FIFO_LINK_MASK));\n\t} while ((w = sync_cmpxchg(word, old, new)) != old);\n\n\treturn w & EVTCHN_FIFO_LINK_MASK;\n}\n\nstatic void consume_one_event(unsigned cpu, struct evtchn_loop_ctrl *ctrl,\n\t\t\t      struct evtchn_fifo_control_block *control_block,\n\t\t\t      unsigned priority, unsigned long *ready)\n{\n\tstruct evtchn_fifo_queue *q = &per_cpu(cpu_queue, cpu);\n\tuint32_t head;\n\tevtchn_port_t port;\n\tevent_word_t *word;\n\n\thead = q->head[priority];\n\n\t/*\n\t * Reached the tail last time?  Read the new HEAD from the\n\t * control block.\n\t */\n\tif (head == 0) {\n\t\tvirt_rmb(); /* Ensure word is up-to-date before reading head. */\n\t\thead = control_block->head[priority];\n\t}\n\n\tport = head;\n\tword = event_word_from_port(port);\n\thead = clear_linked(word);\n\n\t/*\n\t * If the link is non-zero, there are more events in the\n\t * queue, otherwise the queue is empty.\n\t *\n\t * If the queue is empty, clear this priority from our local\n\t * copy of the ready word.\n\t */\n\tif (head == 0)\n\t\tclear_bit(priority, ready);\n\n\tif (evtchn_fifo_is_pending(port) && !evtchn_fifo_is_masked(port)) {\n\t\tif (unlikely(!ctrl))\n\t\t\tpr_warn(\"Dropping pending event for port %u\\n\", port);\n\t\telse\n\t\t\thandle_irq_for_port(port, ctrl);\n\t}\n\n\tq->head[priority] = head;\n}\n\nstatic void __evtchn_fifo_handle_events(unsigned cpu,\n\t\t\t\t\tstruct evtchn_loop_ctrl *ctrl)\n{\n\tstruct evtchn_fifo_control_block *control_block;\n\tunsigned long ready;\n\tunsigned q;\n\n\tcontrol_block = per_cpu(cpu_control_block, cpu);\n\n\tready = xchg(&control_block->ready, 0);\n\n\twhile (ready) {\n\t\tq = find_first_bit(&ready, EVTCHN_FIFO_MAX_QUEUES);\n\t\tconsume_one_event(cpu, ctrl, control_block, q, &ready);\n\t\tready |= xchg(&control_block->ready, 0);\n\t}\n}\n\nstatic void evtchn_fifo_handle_events(unsigned cpu,\n\t\t\t\t      struct evtchn_loop_ctrl *ctrl)\n{\n\t__evtchn_fifo_handle_events(cpu, ctrl);\n}\n\nstatic void evtchn_fifo_resume(void)\n{\n\tunsigned cpu;\n\n\tfor_each_possible_cpu(cpu) {\n\t\tvoid *control_block = per_cpu(cpu_control_block, cpu);\n\t\tint ret;\n\n\t\tif (!control_block)\n\t\t\tcontinue;\n\n\t\t/*\n\t\t * If this CPU is offline, take the opportunity to\n\t\t * free the control block while it is not being\n\t\t * used.\n\t\t */\n\t\tif (!cpu_online(cpu)) {\n\t\t\tfree_page((unsigned long)control_block);\n\t\t\tper_cpu(cpu_control_block, cpu) = NULL;\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = init_control_block(cpu, control_block);\n\t\tBUG_ON(ret < 0);\n\t}\n\n\t/*\n\t * The event array starts out as empty again and is extended\n\t * as normal when events are bound.  The existing pages will\n\t * be reused.\n\t */\n\tevent_array_pages = 0;\n}\n\nstatic int evtchn_fifo_alloc_control_block(unsigned cpu)\n{\n\tvoid *control_block = NULL;\n\tint ret = -ENOMEM;\n\n\tcontrol_block = (void *)__get_free_page(GFP_KERNEL);\n\tif (control_block == NULL)\n\t\tgoto error;\n\n\tret = init_control_block(cpu, control_block);\n\tif (ret < 0)\n\t\tgoto error;\n\n\tper_cpu(cpu_control_block, cpu) = control_block;\n\n\treturn 0;\n\n  error:\n\tfree_page((unsigned long)control_block);\n\treturn ret;\n}\n\nstatic int evtchn_fifo_percpu_init(unsigned int cpu)\n{\n\tif (!per_cpu(cpu_control_block, cpu))\n\t\treturn evtchn_fifo_alloc_control_block(cpu);\n\treturn 0;\n}\n\nstatic int evtchn_fifo_percpu_deinit(unsigned int cpu)\n{\n\t__evtchn_fifo_handle_events(cpu, NULL);\n\treturn 0;\n}\n\nstatic const struct evtchn_ops evtchn_ops_fifo = {\n\t.max_channels      = evtchn_fifo_max_channels,\n\t.nr_channels       = evtchn_fifo_nr_channels,\n\t.setup             = evtchn_fifo_setup,\n\t.bind_to_cpu       = evtchn_fifo_bind_to_cpu,\n\t.clear_pending     = evtchn_fifo_clear_pending,\n\t.set_pending       = evtchn_fifo_set_pending,\n\t.is_pending        = evtchn_fifo_is_pending,\n\t.test_and_set_mask = evtchn_fifo_test_and_set_mask,\n\t.mask              = evtchn_fifo_mask,\n\t.unmask            = evtchn_fifo_unmask,\n\t.handle_events     = evtchn_fifo_handle_events,\n\t.resume            = evtchn_fifo_resume,\n\t.percpu_init       = evtchn_fifo_percpu_init,\n\t.percpu_deinit     = evtchn_fifo_percpu_deinit,\n};\n\nint __init xen_evtchn_fifo_init(void)\n{\n\tint cpu = smp_processor_id();\n\tint ret;\n\n\tret = evtchn_fifo_alloc_control_block(cpu);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tpr_info(\"Using FIFO-based ABI\\n\");\n\n\tevtchn_ops = &evtchn_ops_fifo;\n\n\treturn ret;\n}\n", "/* SPDX-License-Identifier: GPL-2.0-or-later */\n/*\n * Xen Event Channels (internal header)\n *\n * Copyright (C) 2013 Citrix Systems R&D Ltd.\n */\n#ifndef __EVENTS_INTERNAL_H__\n#define __EVENTS_INTERNAL_H__\n\n/* Interrupt types. */\nenum xen_irq_type {\n\tIRQT_UNBOUND = 0,\n\tIRQT_PIRQ,\n\tIRQT_VIRQ,\n\tIRQT_IPI,\n\tIRQT_EVTCHN\n};\n\n/*\n * Packed IRQ information:\n * type - enum xen_irq_type\n * event channel - irq->event channel mapping\n * cpu - cpu this event channel is bound to\n * index - type-specific information:\n *    PIRQ - vector, with MSB being \"needs EIO\", or physical IRQ of the HVM\n *           guest, or GSI (real passthrough IRQ) of the device.\n *    VIRQ - virq number\n *    IPI - IPI vector\n *    EVTCHN -\n */\nstruct irq_info {\n\tstruct list_head list;\n\tstruct list_head eoi_list;\n\tint refcnt;\n\tenum xen_irq_type type;\t/* type */\n\tunsigned irq;\n\tevtchn_port_t evtchn;\t/* event channel */\n\tunsigned short cpu;\t/* cpu bound */\n\tunsigned short eoi_cpu;\t/* EOI must happen on this cpu */\n\tunsigned int irq_epoch;\t/* If eoi_cpu valid: irq_epoch of event */\n\tu64 eoi_time;\t\t/* Time in jiffies when to EOI. */\n\n\tunion {\n\t\tunsigned short virq;\n\t\tenum ipi_vector ipi;\n\t\tstruct {\n\t\t\tunsigned short pirq;\n\t\t\tunsigned short gsi;\n\t\t\tunsigned char vector;\n\t\t\tunsigned char flags;\n\t\t\tuint16_t domid;\n\t\t} pirq;\n\t} u;\n};\n\n#define PIRQ_NEEDS_EOI\t(1 << 0)\n#define PIRQ_SHAREABLE\t(1 << 1)\n#define PIRQ_MSI_GROUP\t(1 << 2)\n\nstruct evtchn_loop_ctrl;\n\nstruct evtchn_ops {\n\tunsigned (*max_channels)(void);\n\tunsigned (*nr_channels)(void);\n\n\tint (*setup)(struct irq_info *info);\n\tvoid (*bind_to_cpu)(struct irq_info *info, unsigned cpu);\n\n\tvoid (*clear_pending)(evtchn_port_t port);\n\tvoid (*set_pending)(evtchn_port_t port);\n\tbool (*is_pending)(evtchn_port_t port);\n\tbool (*test_and_set_mask)(evtchn_port_t port);\n\tvoid (*mask)(evtchn_port_t port);\n\tvoid (*unmask)(evtchn_port_t port);\n\n\tvoid (*handle_events)(unsigned cpu, struct evtchn_loop_ctrl *ctrl);\n\tvoid (*resume)(void);\n\n\tint (*percpu_init)(unsigned int cpu);\n\tint (*percpu_deinit)(unsigned int cpu);\n};\n\nextern const struct evtchn_ops *evtchn_ops;\n\nextern int **evtchn_to_irq;\nint get_evtchn_to_irq(evtchn_port_t evtchn);\nvoid handle_irq_for_port(evtchn_port_t port, struct evtchn_loop_ctrl *ctrl);\n\nstruct irq_info *info_for_irq(unsigned irq);\nunsigned cpu_from_irq(unsigned irq);\nunsigned int cpu_from_evtchn(evtchn_port_t evtchn);\n\nstatic inline unsigned xen_evtchn_max_channels(void)\n{\n\treturn evtchn_ops->max_channels();\n}\n\n/*\n * Do any ABI specific setup for a bound event channel before it can\n * be unmasked and used.\n */\nstatic inline int xen_evtchn_port_setup(struct irq_info *info)\n{\n\tif (evtchn_ops->setup)\n\t\treturn evtchn_ops->setup(info);\n\treturn 0;\n}\n\nstatic inline void xen_evtchn_port_bind_to_cpu(struct irq_info *info,\n\t\t\t\t\t       unsigned cpu)\n{\n\tevtchn_ops->bind_to_cpu(info, cpu);\n}\n\nstatic inline void clear_evtchn(evtchn_port_t port)\n{\n\tevtchn_ops->clear_pending(port);\n}\n\nstatic inline void set_evtchn(evtchn_port_t port)\n{\n\tevtchn_ops->set_pending(port);\n}\n\nstatic inline bool test_evtchn(evtchn_port_t port)\n{\n\treturn evtchn_ops->is_pending(port);\n}\n\nstatic inline bool test_and_set_mask(evtchn_port_t port)\n{\n\treturn evtchn_ops->test_and_set_mask(port);\n}\n\nstatic inline void mask_evtchn(evtchn_port_t port)\n{\n\treturn evtchn_ops->mask(port);\n}\n\nstatic inline void unmask_evtchn(evtchn_port_t port)\n{\n\treturn evtchn_ops->unmask(port);\n}\n\nstatic inline void xen_evtchn_handle_events(unsigned cpu,\n\t\t\t\t\t    struct evtchn_loop_ctrl *ctrl)\n{\n\treturn evtchn_ops->handle_events(cpu, ctrl);\n}\n\nstatic inline void xen_evtchn_resume(void)\n{\n\tif (evtchn_ops->resume)\n\t\tevtchn_ops->resume();\n}\n\nvoid xen_evtchn_2l_init(void);\nint xen_evtchn_fifo_init(void);\n\n#endif /* #ifndef __EVENTS_INTERNAL_H__ */\n"], "filenames": ["Documentation/admin-guide/kernel-parameters.txt", "drivers/xen/events/events_2l.c", "drivers/xen/events/events_base.c", "drivers/xen/events/events_fifo.c", "drivers/xen/events/events_internal.h"], "buggy_code_start_loc": [5830, 164, 37, 278, 32], "buggy_code_end_loc": [5830, 249, 1862, 420, 141], "fixing_code_start_loc": [5831, 164, 38, 278, 33], "fixing_code_end_loc": [5839, 246, 2042, 412, 149], "type": "NVD-CWE-noinfo", "message": "An issue was discovered in the Linux kernel through 5.9.1, as used with Xen through 4.14.x. Guest OS users can cause a denial of service (host OS hang) via a high rate of events to dom0, aka CID-e99502f76271.", "other": {"cve": {"id": "CVE-2020-27673", "sourceIdentifier": "cve@mitre.org", "published": "2020-10-22T21:15:14.013", "lastModified": "2022-04-26T16:23:21.007", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An issue was discovered in the Linux kernel through 5.9.1, as used with Xen through 4.14.x. Guest OS users can cause a denial of service (host OS hang) via a high rate of events to dom0, aka CID-e99502f76271."}, {"lang": "es", "value": "Se detect\u00f3 un problema en el kernel de Linux versiones hasta 5.9.1, como es usado con Xen versiones hasta 4.14.x.&#xa0;Los usuarios del Sistema Operativo invitado pueden causar una denegaci\u00f3n de servicio (suspensi\u00f3n del Sistema Operativo host) por medio de una alta tasa de eventos en dom0, tambi\u00e9n se conoce como CID-e99502f76271"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:N/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.9}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "NVD-CWE-noinfo"}]}], "configurations": [{"nodes": [{"operator": "AND", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "5.9.1", "matchCriteriaId": "C7E1EBA7-1B6D-4A6D-ADFF-2B556573F073"}, {"vulnerable": true, "criteria": "cpe:2.3:o:xen:xen:*:*:*:*:*:*:*:*", "versionEndIncluding": "4.14.0", "matchCriteriaId": "2D769F4A-98C6-4544-AC04-3D8600C17BBB"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.1:*:*:*:*:*:*:*", "matchCriteriaId": "B620311B-34A3-48A6-82DF-6F078D7A4493"}, {"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:leap:15.2:*:*:*:*:*:*:*", "matchCriteriaId": "B009C22E-30A4-4288-BCF6-C3E81DEAF45A"}]}]}], "references": [{"url": "http://lists.opensuse.org/opensuse-security-announce/2020-10/msg00075.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2020-11/msg00025.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "http://www.openwall.com/lists/oss-security/2021/01/19/6", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=e99502f76271d6bc4e374fe368c50c67a1fd3070", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/e99502f76271d6bc4e374fe368c50c67a1fd3070", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2020/12/msg00015.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2020/12/msg00027.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://security.gentoo.org/glsa/202011-06", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://xenbits.xen.org/xsa/advisory-332.html", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/e99502f76271d6bc4e374fe368c50c67a1fd3070"}}
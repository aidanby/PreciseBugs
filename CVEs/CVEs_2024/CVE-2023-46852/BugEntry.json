{"buggy_code": ["/* -*- Mode: C; tab-width: 4; c-basic-offset: 4; indent-tabs-mode: nil -*- */\n/*\n * Functions for handling the proxy layer. wraps text protocols\n *\n * NOTE: many lua functions generate pointers via \"lua_newuserdatauv\" or\n * similar. Normal memory checking isn't done as lua will throw a high level\n * error if malloc fails. Must keep this in mind while allocating data so any\n * manually malloc'ed information gets freed properly.\n */\n\n#include \"proxy.h\"\n\n#define PROCESS_MULTIGET true\n#define PROCESS_NORMAL false\nstatic void proxy_process_command(conn *c, char *command, size_t cmdlen, bool multiget);\nstatic void mcp_queue_io(conn *c, mc_resp *resp, int coro_ref, lua_State *Lc);\n\n/******** EXTERNAL FUNCTIONS ******/\n// functions starting with _ are breakouts for the public functions.\n\nbool proxy_bufmem_checkadd(LIBEVENT_THREAD *t, int len) {\n    bool oom = false;\n    pthread_mutex_lock(&t->proxy_limit_lock);\n    if (t->proxy_buffer_memory_used > t->proxy_buffer_memory_limit) {\n        oom = true;\n    } else {\n        t->proxy_buffer_memory_used += len;\n    }\n    pthread_mutex_unlock(&t->proxy_limit_lock);\n    return oom;\n}\n\n// see also: process_extstore_stats()\nvoid proxy_stats(void *arg, ADD_STAT add_stats, conn *c) {\n    if (arg == NULL) {\n       return;\n    }\n    proxy_ctx_t *ctx = arg;\n    STAT_L(ctx);\n\n    APPEND_STAT(\"proxy_config_reloads\", \"%llu\", (unsigned long long)ctx->global_stats.config_reloads);\n    APPEND_STAT(\"proxy_config_reload_fails\", \"%llu\", (unsigned long long)ctx->global_stats.config_reload_fails);\n    APPEND_STAT(\"proxy_backend_total\", \"%llu\", (unsigned long long)ctx->global_stats.backend_total);\n    APPEND_STAT(\"proxy_backend_marked_bad\", \"%llu\", (unsigned long long)ctx->global_stats.backend_marked_bad);\n    APPEND_STAT(\"proxy_backend_failed\", \"%llu\", (unsigned long long)ctx->global_stats.backend_failed);\n    STAT_UL(ctx);\n}\n\nvoid process_proxy_stats(void *arg, ADD_STAT add_stats, conn *c) {\n    char key_str[STAT_KEY_LEN];\n    struct proxy_int_stats istats = {0};\n    uint64_t req_limit = 0;\n    uint64_t buffer_memory_limit = 0;\n    uint64_t buffer_memory_used = 0;\n\n    if (!arg) {\n        return;\n    }\n    proxy_ctx_t *ctx = arg;\n    STAT_L(ctx);\n    req_limit = ctx->active_req_limit;\n    buffer_memory_limit = ctx->buffer_memory_limit;\n\n    // prepare aggregated counters.\n    struct proxy_user_stats *us = &ctx->user_stats;\n    uint64_t counters[us->num_stats];\n    memset(counters, 0, sizeof(counters));\n\n    // TODO (v3): more globals to remove and/or change API method.\n    // aggregate worker thread counters.\n    for (int x = 0; x < settings.num_threads; x++) {\n        LIBEVENT_THREAD *t = get_worker_thread(x);\n        struct proxy_user_stats *tus = t->proxy_user_stats;\n        struct proxy_int_stats *is = t->proxy_int_stats;\n        WSTAT_L(t);\n        for (int i = 0; i < CMD_FINAL; i++) {\n            istats.counters[i] += is->counters[i];\n        }\n        if (tus && tus->num_stats >= us->num_stats) {\n            for (int i = 0; i < us->num_stats; i++) {\n                counters[i] += tus->counters[i];\n            }\n        }\n        WSTAT_UL(t);\n        pthread_mutex_lock(&t->proxy_limit_lock);\n        buffer_memory_used += t->proxy_buffer_memory_used;\n        pthread_mutex_unlock(&t->proxy_limit_lock);\n    }\n\n    // return all of the user generated stats\n    for (int x = 0; x < us->num_stats; x++) {\n        if (us->names[x]) {\n            snprintf(key_str, STAT_KEY_LEN-1, \"user_%s\", us->names[x]);\n            APPEND_STAT(key_str, \"%llu\", (unsigned long long)counters[x]);\n        }\n    }\n\n    STAT_UL(ctx);\n\n    if (buffer_memory_limit == UINT64_MAX) {\n        buffer_memory_limit = 0;\n    } else {\n        buffer_memory_limit *= settings.num_threads;\n    }\n    if (req_limit == UINT64_MAX) {\n        req_limit = 0;\n    } else {\n        req_limit *= settings.num_threads;\n    }\n\n    // return proxy counters\n    APPEND_STAT(\"active_req_limit\", \"%llu\", (unsigned long long)req_limit);\n    APPEND_STAT(\"buffer_memory_limit\", \"%llu\", (unsigned long long)buffer_memory_limit);\n    APPEND_STAT(\"buffer_memory_used\", \"%llu\", (unsigned long long)buffer_memory_used);\n    APPEND_STAT(\"cmd_mg\", \"%llu\", (unsigned long long)istats.counters[CMD_MG]);\n    APPEND_STAT(\"cmd_ms\", \"%llu\", (unsigned long long)istats.counters[CMD_MS]);\n    APPEND_STAT(\"cmd_md\", \"%llu\", (unsigned long long)istats.counters[CMD_MD]);\n    APPEND_STAT(\"cmd_mn\", \"%llu\", (unsigned long long)istats.counters[CMD_MN]);\n    APPEND_STAT(\"cmd_ma\", \"%llu\", (unsigned long long)istats.counters[CMD_MA]);\n    APPEND_STAT(\"cmd_me\", \"%llu\", (unsigned long long)istats.counters[CMD_ME]);\n    APPEND_STAT(\"cmd_get\", \"%llu\", (unsigned long long)istats.counters[CMD_GET]);\n    APPEND_STAT(\"cmd_gat\", \"%llu\", (unsigned long long)istats.counters[CMD_GAT]);\n    APPEND_STAT(\"cmd_set\", \"%llu\", (unsigned long long)istats.counters[CMD_SET]);\n    APPEND_STAT(\"cmd_add\", \"%llu\", (unsigned long long)istats.counters[CMD_ADD]);\n    APPEND_STAT(\"cmd_cas\", \"%llu\", (unsigned long long)istats.counters[CMD_CAS]);\n    APPEND_STAT(\"cmd_gets\", \"%llu\", (unsigned long long)istats.counters[CMD_GETS]);\n    APPEND_STAT(\"cmd_gats\", \"%llu\", (unsigned long long)istats.counters[CMD_GATS]);\n    APPEND_STAT(\"cmd_incr\", \"%llu\", (unsigned long long)istats.counters[CMD_INCR]);\n    APPEND_STAT(\"cmd_decr\", \"%llu\", (unsigned long long)istats.counters[CMD_DECR]);\n    APPEND_STAT(\"cmd_touch\", \"%llu\", (unsigned long long)istats.counters[CMD_TOUCH]);\n    APPEND_STAT(\"cmd_append\", \"%llu\", (unsigned long long)istats.counters[CMD_APPEND]);\n    APPEND_STAT(\"cmd_prepend\", \"%llu\", (unsigned long long)istats.counters[CMD_PREPEND]);\n    APPEND_STAT(\"cmd_delete\", \"%llu\", (unsigned long long)istats.counters[CMD_DELETE]);\n    APPEND_STAT(\"cmd_replace\", \"%llu\", (unsigned long long)istats.counters[CMD_REPLACE]);\n}\n\n// start the centralized lua state and config thread.\nvoid *proxy_init(bool use_uring) {\n    proxy_ctx_t *ctx = calloc(1, sizeof(proxy_ctx_t));\n    ctx->use_uring = use_uring;\n\n    pthread_mutex_init(&ctx->config_lock, NULL);\n    pthread_cond_init(&ctx->config_cond, NULL);\n    pthread_mutex_init(&ctx->worker_lock, NULL);\n    pthread_cond_init(&ctx->worker_cond, NULL);\n    pthread_mutex_init(&ctx->manager_lock, NULL);\n    pthread_cond_init(&ctx->manager_cond, NULL);\n    pthread_mutex_init(&ctx->stats_lock, NULL);\n\n    ctx->active_req_limit = UINT64_MAX;\n    ctx->buffer_memory_limit = UINT64_MAX;\n\n    // FIXME (v2): default defines.\n    ctx->tunables.tcp_keepalive = false;\n    ctx->tunables.backend_failure_limit = 3;\n    ctx->tunables.connect.tv_sec = 5;\n    ctx->tunables.retry.tv_sec = 3;\n    ctx->tunables.read.tv_sec = 3;\n\n    STAILQ_INIT(&ctx->manager_head);\n    lua_State *L = luaL_newstate();\n    ctx->proxy_state = L;\n    luaL_openlibs(L);\n    // NOTE: might need to differentiate the libs yes?\n    proxy_register_libs(ctx, NULL, L);\n\n    // Create/start the IO thread, which we need before servers\n    // start getting created.\n    proxy_event_thread_t *t = calloc(1, sizeof(proxy_event_thread_t));\n    ctx->proxy_io_thread = t;\n    proxy_init_event_thread(t, ctx, NULL);\n\n    pthread_create(&t->thread_id, NULL, proxy_event_thread, t);\n    thread_setname(t->thread_id, \"mc-prx-io\");\n\n    _start_proxy_config_threads(ctx);\n    return ctx;\n}\n\n// Initialize the VM for an individual worker thread.\nvoid proxy_thread_init(void *ctx, LIBEVENT_THREAD *thr) {\n    assert(ctx != NULL);\n    assert(thr != NULL);\n\n    // Create the hook table.\n    thr->proxy_hooks = calloc(CMD_SIZE, sizeof(struct proxy_hook));\n    if (thr->proxy_hooks == NULL) {\n        fprintf(stderr, \"Failed to allocate proxy hooks\\n\");\n        exit(EXIT_FAILURE);\n    }\n    thr->proxy_int_stats = calloc(1, sizeof(struct proxy_int_stats));\n    if (thr->proxy_int_stats == NULL) {\n        fprintf(stderr, \"Failed to allocate proxy thread stats\\n\");\n        exit(EXIT_FAILURE);\n    }\n    pthread_mutex_init(&thr->proxy_limit_lock, NULL);\n    thr->proxy_ctx = ctx;\n\n    // Initialize the lua state.\n    lua_State *L = luaL_newstate();\n    thr->L = L;\n    luaL_openlibs(L);\n    proxy_register_libs(ctx, thr, L);\n    // TODO: srand on time? do we need to bother?\n    for (int x = 0; x < 3; x++) {\n        thr->proxy_rng[x] = rand();\n    }\n\n    // Create a proxy event thread structure to piggyback on the worker.\n    proxy_event_thread_t *t = calloc(1, sizeof(proxy_event_thread_t));\n    thr->proxy_event_thread = t;\n    proxy_init_event_thread(t, ctx, thr->base);\n}\n\n// ctx_stack is a stack of io_pending_proxy_t's.\n// head of q->s_ctx is the \"newest\" request so we must push into the head\n// of the next queue, as requests are dequeued from the head\nvoid proxy_submit_cb(io_queue_t *q) {\n    proxy_event_thread_t *e = ((proxy_ctx_t *)q->ctx)->proxy_io_thread;\n    io_pending_proxy_t *p = q->stack_ctx;\n    io_head_t head;\n    be_head_t w_head; // worker local stack.\n    STAILQ_INIT(&head);\n    STAILQ_INIT(&w_head);\n\n    // NOTE: responses get returned in the correct order no matter what, since\n    // mc_resp's are linked.\n    // we just need to ensure stuff is parsed off the backend in the correct\n    // order.\n    // So we can do with a single list here, but we need to repair the list as\n    // responses are parsed. (in the req_remaining-- section)\n    // TODO (v2):\n    // - except we can't do that because the deferred IO stack isn't\n    // compatible with queue.h.\n    // So for now we build the secondary list with an STAILQ, which\n    // can be transplanted/etc.\n    while (p) {\n        mcp_backend_t *be;\n        P_DEBUG(\"%s: queueing req for backend: %p\\n\", __func__, (void *)p);\n        if (p->is_await) {\n            // need to not count await objects multiple times.\n            if (p->await_background) {\n                P_DEBUG(\"%s: fast-returning await_background object: %p\\n\", __func__, (void *)p);\n                // intercept await backgrounds\n                // this call cannot recurse if we're on the worker thread,\n                // since the worker thread has to finish executing this\n                // function in order to pick up the returned IO.\n                q->count++;\n                return_io_pending((io_pending_t *)p);\n                p = p->next;\n                continue;\n            } else if (p->await_first) {\n                q->count++;\n            }\n            // funny workaround: awaiting IOP's don't count toward\n            // resuming a connection, only the completion of the await\n            // condition.\n        } else {\n            q->count++;\n        }\n        be = p->backend;\n\n        if (be->use_io_thread) {\n            STAILQ_INSERT_HEAD(&head, p, io_next);\n        } else {\n            // emulate some of handler_dequeue()\n            STAILQ_INSERT_TAIL(&be->io_head, p, io_next);\n            be->depth++;\n            if (!be->stacked) {\n                be->stacked = true;\n                be->be_next.stqe_next = NULL; // paranoia\n                STAILQ_INSERT_TAIL(&w_head, be, be_next);\n            }\n        }\n\n        p = p->next;\n    }\n\n    // clear out the submit queue so we can re-queue new IO's inline.\n    q->stack_ctx = NULL;\n\n    if (!STAILQ_EMPTY(&head)) {\n        P_DEBUG(\"%s: submitting queue to IO thread\\n\", __func__);\n        // Transfer request stack to event thread.\n        pthread_mutex_lock(&e->mutex);\n        STAILQ_CONCAT(&e->io_head_in, &head);\n        // No point in holding the lock since we're not doing a cond signal.\n        pthread_mutex_unlock(&e->mutex);\n\n        // Signal to check queue.\n#ifdef USE_EVENTFD\n        uint64_t u = 1;\n        // TODO (v2): check result? is it ever possible to get a short write/failure\n        // for an eventfd?\n        if (write(e->event_fd, &u, sizeof(uint64_t)) != sizeof(uint64_t)) {\n            assert(1 == 0);\n        }\n#else\n        if (write(e->notify_send_fd, \"w\", 1) <= 0) {\n            assert(1 == 0);\n        }\n#endif\n    }\n\n    if (!STAILQ_EMPTY(&w_head)) {\n        P_DEBUG(\"%s: running inline worker queue\\n\", __func__);\n        // emulating proxy_event_handler\n        proxy_run_backend_queue(&w_head);\n    }\n    return;\n}\n\n// called from worker thread after an individual IO has been returned back to\n// the worker thread. Do post-IO run and cleanup work.\nvoid proxy_return_cb(io_pending_t *pending) {\n    io_pending_proxy_t *p = (io_pending_proxy_t *)pending;\n    if (p->is_await) {\n        mcplib_await_return(p);\n    } else {\n        lua_State *Lc = p->coro;\n\n        // in order to resume we need to remove the objects that were\n        // originally returned\n        // what's currently on the top of the stack is what we want to keep.\n        lua_rotate(Lc, 1, 1);\n        // We kept the original results from the yield so lua would not\n        // collect them in the meantime. We can drop those now.\n        lua_settop(Lc, 1);\n\n        // p can be freed/changed from the call below, so fetch the queue now.\n        io_queue_t *q = conn_io_queue_get(p->c, p->io_queue_type);\n        conn *c = p->c;\n        proxy_run_coroutine(Lc, p->resp, p, c);\n\n        q->count--;\n        if (q->count == 0) {\n            // call re-add directly since we're already in the worker thread.\n            conn_worker_readd(c);\n        }\n    }\n}\n\n// called from the worker thread as an mc_resp is being freed.\n// must let go of the coroutine reference if there is one.\n// caller frees the pending IO.\nvoid proxy_finalize_cb(io_pending_t *pending) {\n    io_pending_proxy_t *p = (io_pending_proxy_t *)pending;\n\n    if (p->io_type == IO_PENDING_TYPE_EXTSTORE) {\n        if (p->hdr_it) {\n            // TODO: lock once, worst case this hashes/locks twice.\n            if (p->miss) {\n                item_unlink(p->hdr_it);\n            }\n            item_remove(p->hdr_it);\n        }\n    }\n\n    // release our coroutine reference.\n    // TODO (v2): coroutines are reusable in lua 5.4. we can stack this onto a freelist\n    // after a lua_resetthread(Lc) call.\n    if (p->coro_ref) {\n        // Note: lua registry is the same for main thread or a coroutine.\n        luaL_unref(p->coro, LUA_REGISTRYINDEX, p->coro_ref);\n    }\n\n    return;\n}\n\nint try_read_command_proxy(conn *c) {\n    char *el, *cont;\n\n    if (c->rbytes == 0)\n        return 0;\n\n    el = memchr(c->rcurr, '\\n', c->rbytes);\n    if (!el) {\n        if (c->rbytes > 1024) {\n            /*\n             * We didn't have a '\\n' in the first k. This _has_ to be a\n             * large multiget, if not we should just nuke the connection.\n             */\n            char *ptr = c->rcurr;\n            while (*ptr == ' ') { /* ignore leading whitespaces */\n                ++ptr;\n            }\n\n            if (ptr - c->rcurr > 100 ||\n                (strncmp(ptr, \"get \", 4) && strncmp(ptr, \"gets \", 5))) {\n\n                conn_set_state(c, conn_closing);\n                return 1;\n            }\n\n            // ASCII multigets are unbound, so our fixed size rbuf may not\n            // work for this particular workload... For backcompat we'll use a\n            // malloc/realloc/free routine just for this.\n            if (!c->rbuf_malloced) {\n                if (!rbuf_switch_to_malloc(c)) {\n                    conn_set_state(c, conn_closing);\n                    return 1;\n                }\n            }\n        }\n\n        return 0;\n    }\n    cont = el + 1;\n\n    assert(cont <= (c->rcurr + c->rbytes));\n\n    c->last_cmd_time = current_time;\n    proxy_process_command(c, c->rcurr, cont - c->rcurr, PROCESS_NORMAL);\n\n    c->rbytes -= (cont - c->rcurr);\n    c->rcurr = cont;\n\n    assert(c->rcurr <= (c->rbuf + c->rsize));\n\n    return 1;\n\n}\n\n// Called when a connection is closed while in nread state reading a set\n// Must only be called with an active coroutine.\nvoid proxy_cleanup_conn(conn *c) {\n    assert(c->proxy_coro_ref != 0);\n    LIBEVENT_THREAD *thr = c->thread;\n    lua_State *L = thr->L;\n    luaL_unref(L, LUA_REGISTRYINDEX, c->proxy_coro_ref);\n    c->proxy_coro_ref = 0;\n    WSTAT_DECR(thr, proxy_req_active, 1);\n}\n\n// we buffered a SET of some kind.\nvoid complete_nread_proxy(conn *c) {\n    assert(c != NULL);\n\n    LIBEVENT_THREAD *thr = c->thread;\n    lua_State *L = thr->L;\n\n    if (c->proxy_coro_ref == 0) {\n        complete_nread_ascii(c);\n        return;\n    }\n\n    conn_set_state(c, conn_new_cmd);\n\n    // Grab our coroutine.\n    // Leave the reference alone in case we error out, so the conn cleanup\n    // routine can handle it properly.\n    lua_rawgeti(L, LUA_REGISTRYINDEX, c->proxy_coro_ref);\n    lua_State *Lc = lua_tothread(L, -1);\n    mcp_request_t *rq = luaL_checkudata(Lc, -1, \"mcp.request\");\n\n    // validate the data chunk.\n    if (strncmp((char *)c->item + rq->pr.vlen - 2, \"\\r\\n\", 2) != 0) {\n        lua_settop(L, 0); // clear anything remaining on the main thread.\n        // FIXME (v2): need to set noreply false if mset_res, but that's kind\n        // of a weird hack to begin with. Evaluate how to best do that here.\n        out_string(c, \"CLIENT_ERROR bad data chunk\");\n        return;\n    }\n\n    // We move ownership of the c->item buffer from the connection to the\n    // request object here. Else we can double free if the conn closes while\n    // inside nread.\n    rq->pr.vbuf = c->item;\n    c->item = NULL;\n    c->item_malloced = false;\n    luaL_unref(L, LUA_REGISTRYINDEX, c->proxy_coro_ref);\n    c->proxy_coro_ref = 0;\n    pthread_mutex_lock(&thr->proxy_limit_lock);\n    thr->proxy_buffer_memory_used += rq->pr.vlen;\n    pthread_mutex_unlock(&thr->proxy_limit_lock);\n\n    proxy_run_coroutine(Lc, c->resp, NULL, c);\n\n    lua_settop(L, 0); // clear anything remaining on the main thread.\n\n    return;\n}\n\n// Simple error wrapper for common failures.\n// lua_error() is a jump so this function never returns\n// for clarity add a 'return' after calls to this.\nvoid proxy_lua_error(lua_State *L, const char *s) {\n    lua_pushstring(L, s);\n    lua_error(L);\n}\n\nvoid proxy_lua_ferror(lua_State *L, const char *fmt, ...) {\n    va_list ap;\n    va_start(ap, fmt);\n    lua_pushfstring(L, fmt, ap);\n    va_end(ap);\n    lua_error(L);\n}\n\n// Need a custom function so we can prefix lua strings easily.\nvoid proxy_out_errstring(mc_resp *resp, char *type, const char *str) {\n    size_t len;\n    size_t prefix_len = strlen(type);\n\n    assert(resp != NULL);\n\n    resp_reset(resp);\n    // avoid noreply since we're throwing important errors.\n\n    // Fill response object with static string.\n    len = strlen(str);\n    if ((len + prefix_len + 2) > WRITE_BUFFER_SIZE) {\n        /* ought to be always enough. just fail for simplicity */\n        str = \"SERVER_ERROR output line too long\";\n        len = strlen(str);\n    }\n\n    char *w = resp->wbuf;\n    memcpy(w, type, prefix_len);\n    w += prefix_len;\n\n    memcpy(w, str, len);\n    w += len;\n\n    memcpy(w, \"\\r\\n\", 2);\n    resp_add_iov(resp, resp->wbuf, len + prefix_len + 2);\n    return;\n}\n\n// NOTE: See notes in mcp_queue_io; the secondary problem with setting the\n// noreply mode from the response object is that the proxy can return strings\n// manually, so we have no way to obey what the original request wanted in\n// that case.\nstatic void _set_noreply_mode(mc_resp *resp, mcp_resp_t *r) {\n    switch (r->mode) {\n        case RESP_MODE_NORMAL:\n            break;\n        case RESP_MODE_NOREPLY:\n            // ascii noreply only threw egregious errors to client\n            if (r->status == MCMC_OK) {\n                resp->skip = true;\n            }\n            break;\n        case RESP_MODE_METAQUIET:\n            if (r->resp.code == MCMC_CODE_END) {\n                resp->skip = true;\n            } else if (r->cmd != CMD_MG && r->resp.code == MCMC_CODE_OK) {\n                // FIXME (v2): mcmc's parser needs to help us out a bit more\n                // here.\n                // This is a broken case in the protocol though; quiet mode\n                // ignores HD for mutations but not get.\n                resp->skip = true;\n            }\n            break;\n        default:\n            assert(1 == 0);\n    }\n}\n\n// this resumes every yielded coroutine (and re-resumes if necessary).\n// called from the worker thread after responses have been pulled from the\n// network.\n// Flow:\n// - the response object should already be on the coroutine stack.\n// - fix up the stack.\n// - run coroutine.\n// - if LUA_YIELD, we need to swap out the pending IO from its mc_resp then call for a queue\n// again.\n// - if LUA_OK finalize the response and return\n// - else set error into mc_resp.\nint proxy_run_coroutine(lua_State *Lc, mc_resp *resp, io_pending_proxy_t *p, conn *c) {\n    int nresults = 0;\n    int cores = lua_resume(Lc, NULL, 1, &nresults);\n    size_t rlen = 0;\n\n    if (cores == LUA_OK) {\n        WSTAT_DECR(c->thread, proxy_req_active, 1);\n        int type = lua_type(Lc, 1);\n        P_DEBUG(\"%s: coroutine completed. return type: %d\\n\", __func__, type);\n        if (type == LUA_TUSERDATA) {\n            mcp_resp_t *r = luaL_checkudata(Lc, 1, \"mcp.response\");\n            _set_noreply_mode(resp, r);\n            if (r->status != MCMC_OK && r->resp.type != MCMC_RESP_ERRMSG) {\n                proxy_out_errstring(resp, PROXY_SERVER_ERROR, \"backend failure\");\n            } else if (r->cresp) {\n                mc_resp *tresp = r->cresp;\n                // The internal cache handler has created a resp we want to swap in\n                // here. It would be fastest to swap *resp's position in the\n                // link but if the set is deep this would instead be slow, so\n                // we copy over details from this temporary resp instead.\n                assert(c != NULL);\n\n                // So far all we fill is the wbuf and some iov's? so just copy\n                // that + the UDP info?\n                memcpy(resp->wbuf, tresp->wbuf, tresp->iov[0].iov_len);\n                for (int x = 0; x < tresp->iovcnt; x++) {\n                    resp->iov[x] = tresp->iov[x];\n                }\n                // resp->iov[x].iov_base needs to be updated if it's\n                // pointing within its wbuf.\n                // FIXME: This is too fragile. we need to be able to\n                // inherit details and swap resp objects around.\n                if (tresp->iov[0].iov_base == tresp->wbuf) {\n                    resp->iov[0].iov_base = resp->wbuf;\n                }\n                resp->iovcnt = tresp->iovcnt;\n                resp->chunked_total = tresp->chunked_total;\n                resp->chunked_data_iov = tresp->chunked_data_iov;\n                // copy UDP headers...\n                resp->request_id = tresp->request_id;\n                resp->udp_sequence = tresp->udp_sequence;\n                resp->udp_total = tresp->udp_total;\n                resp->request_addr = tresp->request_addr;\n                resp->request_addr_size = tresp->request_addr_size;\n                resp->item = tresp->item; // will be populated if not extstore fetch\n                resp->skip = tresp->skip;\n\n                // we let the mcp_resp gc handler free up tresp and any\n                // associated io_pending's of its own later.\n            } else if (r->buf) {\n                // response set from C.\n                resp->write_and_free = r->buf;\n                resp_add_iov(resp, r->buf, r->blen);\n                r->buf = NULL;\n            } else if (lua_getiuservalue(Lc, 1, 1) != LUA_TNIL) {\n                // uservalue slot 1 is pre-created, so we get TNIL instead of\n                // TNONE when nothing was set into it.\n                const char *s = lua_tolstring(Lc, -1, &rlen);\n                size_t l = rlen > WRITE_BUFFER_SIZE ? WRITE_BUFFER_SIZE : rlen;\n                memcpy(resp->wbuf, s, l);\n                resp_add_iov(resp, resp->wbuf, l);\n                lua_pop(Lc, 1);\n            } else {\n                // Empty response: used for ascii multiget emulation.\n            }\n\n        } else if (type == LUA_TSTRING) {\n            // response is a raw string from lua.\n            const char *s = lua_tolstring(Lc, 1, &rlen);\n            size_t l = rlen > WRITE_BUFFER_SIZE ? WRITE_BUFFER_SIZE : rlen;\n            memcpy(resp->wbuf, s, l);\n            resp_add_iov(resp, resp->wbuf, l);\n            lua_pop(Lc, 1);\n        } else {\n            proxy_out_errstring(resp, PROXY_SERVER_ERROR, \"bad response\");\n        }\n\n    } else if (cores == LUA_YIELD) {\n        int coro_ref = 0;\n        int yield_type = lua_tointeger(Lc, -1);\n        P_DEBUG(\"%s: coroutine yielded. return type: %d\\n\", __func__, yield_type);\n        assert(yield_type != 0);\n        lua_pop(Lc, 1);\n\n        // need to remove and free the io_pending, since c->resp owns it.\n        // so we call mcp_queue_io() again and let it override the\n        // mc_resp's io_pending object.\n        //\n        // p is not null only when being called from proxy_return_cb(),\n        // a pending IO is returning to resume.\n        if (p != NULL) {\n            coro_ref = p->coro_ref;\n            assert((void *)p == (void *)resp->io_pending);\n            resp->io_pending = NULL;\n            c = p->c;\n            // *p is now dead.\n            do_cache_free(c->thread->io_cache, p);\n        } else {\n            // coroutine object sitting on the _main_ VM right now, so we grab\n            // the reference from there, which also pops it.\n            assert(c != NULL);\n            coro_ref = luaL_ref(c->thread->L, LUA_REGISTRYINDEX);\n        }\n\n        int res = 0;\n        switch (yield_type) {\n            case MCP_YIELD_AWAIT:\n                mcplib_await_run(c, resp, Lc, coro_ref);\n                break;\n            case MCP_YIELD_POOL:\n                // TODO (v2): c only used for cache alloc?\n                mcp_queue_io(c, resp, coro_ref, Lc);\n                break;\n            case MCP_YIELD_LOCAL:\n                // stack should be: rq, res\n                res = mcplib_internal_run(Lc, c, resp, coro_ref);\n                if (res == 0) {\n                    // stack should still be: rq, res\n                    // TODO: turn this function into a for loop that re-runs on\n                    // certain status codes, to avoid recursive depth here.\n                    //\n                    // FIXME: this dance with the coroutine reference is\n                    // annoying. In this case we immediately resume, so no *io\n                    // was generated, so we won't do the above coro_ref swap, so\n                    // we'll try to take the coro_ref again and fail.\n                    // The ref is only actually used in proxy_await\n                    // It should instead be stashed on the top mc_resp object\n                    // (ideally removing c->proxy_coro_ref at the same time)\n                    // and unref'ed when the resp is cleaned up.\n                    lua_rawgeti(c->thread->L, LUA_REGISTRYINDEX, coro_ref);\n                    luaL_unref(c->thread->L, LUA_REGISTRYINDEX, coro_ref);\n                    proxy_run_coroutine(Lc, resp, NULL, c);\n                } else if (res > 0) {\n                    // internal run queued for extstore.\n                } else {\n                    assert(res < 0);\n                    proxy_out_errstring(resp, PROXY_SERVER_ERROR, \"bad request\");\n                }\n                break;\n            default:\n                abort();\n        }\n\n    } else {\n        WSTAT_DECR(c->thread, proxy_req_active, 1);\n        P_DEBUG(\"%s: Failed to run coroutine: %s\\n\", __func__, lua_tostring(Lc, -1));\n        LOGGER_LOG(NULL, LOG_PROXYEVENTS, LOGGER_PROXY_ERROR, NULL, lua_tostring(Lc, -1));\n        proxy_out_errstring(resp, PROXY_SERVER_ERROR, \"lua failure\");\n    }\n\n    return 0;\n}\n\nstatic void proxy_process_command(conn *c, char *command, size_t cmdlen, bool multiget) {\n    assert(c != NULL);\n    LIBEVENT_THREAD *thr = c->thread;\n    struct proxy_hook *hooks = thr->proxy_hooks;\n    lua_State *L = thr->L;\n    proxy_ctx_t *ctx = thr->proxy_ctx;\n    mcp_parser_t pr = {0};\n\n    // Avoid doing resp_start() here, instead do it a bit later or as-needed.\n    // This allows us to hop over to the internal text protocol parser, which\n    // also calls resp_start().\n    // Tighter integration later should obviate the need for this, it is not a\n    // permanent solution.\n    int ret = process_request(&pr, command, cmdlen);\n    if (ret != 0) {\n        WSTAT_INCR(c->thread, proxy_conn_errors, 1);\n        if (!resp_start(c)) {\n            conn_set_state(c, conn_closing);\n            return;\n        }\n        proxy_out_errstring(c->resp, PROXY_CLIENT_ERROR, \"parsing request\");\n        if (ret == -2) {\n            // Kill connection on more critical parse failure.\n            conn_set_state(c, conn_closing);\n        }\n        return;\n    }\n\n    struct proxy_hook *hook = &hooks[pr.command];\n    int hook_ref = hook->lua_ref;\n    // if client came from a tagged listener, scan for a more specific hook.\n    // TODO: (v2) avoiding a hash table lookup here, but maybe some other\n    // datastructure would suffice. for 4-8 tags this is perfectly fast.\n    if (c->tag && hook->tagged) {\n        struct proxy_hook_tagged *pht = hook->tagged;\n        while (pht->lua_ref) {\n            if (c->tag == pht->tag) {\n                hook_ref = pht->lua_ref;\n                break;\n            }\n            pht++;\n        }\n    }\n\n    if (!hook_ref) {\n        // need to pass our command string into the internal handler.\n        // to minimize the code change, this means allowing it to tokenize the\n        // full command. The proxy's indirect parser should be built out to\n        // become common code for both proxy and ascii handlers.\n        // For now this means we have to null-terminate the command string,\n        // then call into text protocol handler.\n        // FIXME (v2): use a ptr or something; don't like this code.\n        if (cmdlen > 1 && command[cmdlen-2] == '\\r') {\n            command[cmdlen-2] = '\\0';\n        } else {\n            command[cmdlen-1] = '\\0';\n        }\n        // lets nread_proxy know we're in ascii mode.\n        c->proxy_coro_ref = 0;\n        process_command_ascii(c, command);\n        return;\n    }\n\n    // If ascii multiget, we turn this into a self-calling loop :(\n    // create new request with next key, call this func again, then advance\n    // original string.\n    // might be better to split this function; the below bits turn into a\n    // function call, then we don't re-process the above bits in the same way?\n    // The way this is detected/passed on is very fragile.\n    if (!multiget && pr.cmd_type == CMD_TYPE_GET && pr.has_space) {\n        uint32_t keyoff = pr.tokens[pr.keytoken];\n        while (pr.klen != 0) {\n            char temp[KEY_MAX_LENGTH + 30];\n            char *cur = temp;\n            // Core daemon can abort the entire command if one key is bad, but\n            // we cannot from the proxy. Instead we have to inject errors into\n            // the stream. This should, thankfully, be rare at least.\n            if (pr.klen > KEY_MAX_LENGTH) {\n                if (!resp_start(c)) {\n                    conn_set_state(c, conn_closing);\n                    return;\n                }\n                proxy_out_errstring(c->resp, PROXY_CLIENT_ERROR, \"key too long\");\n            } else {\n                // copy original request up until the original key token.\n                memcpy(cur, pr.request, pr.tokens[pr.keytoken]);\n                cur += pr.tokens[pr.keytoken];\n\n                // now copy in our \"current\" key.\n                memcpy(cur, &pr.request[keyoff], pr.klen);\n                cur += pr.klen;\n\n                memcpy(cur, \"\\r\\n\", 2);\n                cur += 2;\n\n                *cur = '\\0';\n                P_DEBUG(\"%s: new multiget sub request: %s [%u/%u]\\n\", __func__, temp, keyoff, pr.klen);\n                proxy_process_command(c, temp, cur - temp, PROCESS_MULTIGET);\n            }\n\n            // now advance to the next key.\n            keyoff = _process_request_next_key(&pr);\n        }\n\n        if (!resp_start(c)) {\n            conn_set_state(c, conn_closing);\n            return;\n        }\n\n        // The above recursions should have created c->resp's in dispatch\n        // order.\n        // So now we add another one at the end to create the capping END\n        // string.\n        memcpy(c->resp->wbuf, ENDSTR, ENDLEN);\n        resp_add_iov(c->resp, c->resp->wbuf, ENDLEN);\n\n        return;\n    }\n\n    // We test the command length all the way down here because multigets can\n    // be very long, and they're chopped up by now.\n    if (cmdlen >= MCP_REQUEST_MAXLEN) {\n        WSTAT_INCR(c->thread, proxy_conn_errors, 1);\n        if (!resp_start(c)) {\n            conn_set_state(c, conn_closing);\n            return;\n        }\n        proxy_out_errstring(c->resp, PROXY_CLIENT_ERROR, \"request too long\");\n        conn_set_state(c, conn_closing);\n        return;\n    }\n\n    if (!resp_start(c)) {\n        conn_set_state(c, conn_closing);\n        return;\n    }\n\n    // Count requests handled by proxy vs local.\n    // Also batch the counts down this far so we can lock once for the active\n    // counter instead of twice.\n    struct proxy_int_stats *istats = c->thread->proxy_int_stats;\n    uint64_t active_reqs = 0;\n    WSTAT_L(c->thread);\n    istats->counters[pr.command]++;\n    c->thread->stats.proxy_conn_requests++;\n    c->thread->stats.proxy_req_active++;\n    active_reqs = c->thread->stats.proxy_req_active;\n    WSTAT_UL(c->thread);\n\n    if (active_reqs > ctx->active_req_limit) {\n        proxy_out_errstring(c->resp, PROXY_SERVER_ERROR, \"active request limit reached\");\n        WSTAT_DECR(c->thread, proxy_req_active, 1);\n        if (pr.vlen != 0) {\n            c->sbytes = pr.vlen;\n            conn_set_state(c, conn_swallow);\n        }\n        return;\n    }\n\n    // start a coroutine.\n    // TODO (v2): This can pull a thread from a cache.\n    lua_newthread(L);\n    lua_State *Lc = lua_tothread(L, -1);\n    // leave the thread first on the stack, so we can reference it if needed.\n    // pull the lua hook function onto the stack.\n    lua_rawgeti(Lc, LUA_REGISTRYINDEX, hook_ref);\n\n    mcp_request_t *rq = mcp_new_request(Lc, &pr, command, cmdlen);\n    rq->ascii_multiget = multiget;\n    // NOTE: option 1) copy c->tag into rq->tag here.\n    // add req:listen_tag() to retrieve in top level route.\n\n    // TODO (v2): lift this to a post-processor?\n    if (rq->pr.vlen != 0) {\n        c->item = NULL;\n        // Need to add the used memory later due to needing an extra callback\n        // handler on error during nread.\n        bool oom = proxy_bufmem_checkadd(c->thread, 0);\n\n        // relying on temporary malloc's not having fragmentation\n        if (!oom) {\n            c->item = malloc(rq->pr.vlen);\n        }\n        if (c->item == NULL) {\n            lua_settop(L, 0);\n            proxy_out_errstring(c->resp, PROXY_SERVER_ERROR, \"out of memory\");\n            WSTAT_DECR(c->thread, proxy_req_active, 1);\n            c->sbytes = rq->pr.vlen;\n            conn_set_state(c, conn_swallow);\n            return;\n        }\n        c->item_malloced = true;\n        c->ritem = c->item;\n        c->rlbytes = rq->pr.vlen;\n        c->proxy_coro_ref = luaL_ref(L, LUA_REGISTRYINDEX); // pops coroutine.\n\n        conn_set_state(c, conn_nread);\n        return;\n    } else {\n        conn_set_state(c, conn_new_cmd);\n    }\n\n    proxy_run_coroutine(Lc, c->resp, NULL, c);\n\n    lua_settop(L, 0); // clear anything remaining on the main thread.\n}\n\n// analogue for storage_get_item(); add a deferred IO object to the current\n// connection's response object. stack enough information to write to the\n// server on the submit callback, and enough to resume the lua state on the\n// completion callback.\nstatic void mcp_queue_io(conn *c, mc_resp *resp, int coro_ref, lua_State *Lc) {\n    io_queue_t *q = conn_io_queue_get(c, IO_QUEUE_PROXY);\n\n    // stack: request, hash selector. latter just to hold a reference.\n\n    mcp_request_t *rq = luaL_checkudata(Lc, -1, \"mcp.request\");\n    mcp_backend_t *be = rq->be;\n\n    // Then we push a response object, which we'll re-use later.\n    // reserve one uservalue for a lua-supplied response.\n    mcp_resp_t *r = lua_newuserdatauv(Lc, sizeof(mcp_resp_t), 1);\n    // FIXME (v2): is this memset still necessary? I was using it for\n    // debugging.\n    memset(r, 0, sizeof(mcp_resp_t));\n    r->buf = NULL;\n    r->blen = 0;\n    r->thread = c->thread;\n    assert(r->thread != NULL);\n    gettimeofday(&r->start, NULL);\n    // Set noreply mode.\n    // TODO (v2): the response \"inherits\" the request's noreply mode, which isn't\n    // strictly correct; we should inherit based on the request that spawned\n    // the coroutine but the structure doesn't allow that yet.\n    // Should also be able to settle this exact mode from the parser so we\n    // don't have to re-branch here.\n    if (rq->pr.noreply) {\n        if (rq->pr.cmd_type == CMD_TYPE_META) {\n            r->mode = RESP_MODE_METAQUIET;\n            for (int x = 2; x < rq->pr.ntokens; x++) {\n                if (rq->request[rq->pr.tokens[x]] == 'q') {\n                    rq->request[rq->pr.tokens[x]] = ' ';\n                }\n            }\n        } else {\n            r->mode = RESP_MODE_NOREPLY;\n            rq->request[rq->pr.reqlen - 3] = 'Y';\n        }\n    } else {\n        r->mode = RESP_MODE_NORMAL;\n    }\n\n    r->cmd = rq->pr.command;\n\n    luaL_getmetatable(Lc, \"mcp.response\");\n    lua_setmetatable(Lc, -2);\n\n    io_pending_proxy_t *p = do_cache_alloc(c->thread->io_cache);\n    if (p == NULL) {\n        WSTAT_INCR(c->thread, proxy_conn_oom, 1);\n        proxy_lua_error(Lc, \"out of memory allocating from IO cache\");\n        return;\n    }\n\n    // this is a re-cast structure, so assert that we never outsize it.\n    assert(sizeof(io_pending_t) >= sizeof(io_pending_proxy_t));\n    memset(p, 0, sizeof(io_pending_proxy_t));\n    // set up back references.\n    p->io_queue_type = IO_QUEUE_PROXY;\n    p->thread = c->thread;\n    p->c = c;\n    p->resp = resp;\n    p->client_resp = r;\n    p->flushed = false;\n    p->ascii_multiget = rq->ascii_multiget;\n    p->return_cb = proxy_return_cb;\n    p->finalize_cb = proxy_finalize_cb;\n    resp->io_pending = (io_pending_t *)p;\n\n    // top of the main thread should be our coroutine.\n    // lets grab a reference to it and pop so it doesn't get gc'ed.\n    p->coro_ref = coro_ref;\n\n    // we'll drop the pointer to the coro on here to save some CPU\n    // on re-fetching it later. The pointer shouldn't change.\n    p->coro = Lc;\n\n    // The direct backend object. Lc is holding the reference in the stack\n    p->backend = be;\n    // See #887 for notes.\n    // TODO (v2): hopefully this can be optimized out.\n    strncpy(r->be_name, be->name, MAX_NAMELEN+1);\n    strncpy(r->be_port, be->port, MAX_PORTLEN+1);\n\n    mcp_request_attach(Lc, rq, p);\n\n    // link into the batch chain.\n    p->next = q->stack_ctx;\n    q->stack_ctx = p;\n\n    return;\n}\n\n// Common lua debug command.\n__attribute__((unused)) void dump_stack(lua_State *L) {\n    int top = lua_gettop(L);\n    int i = 1;\n    fprintf(stderr, \"--TOP OF STACK [%d]\\n\", top);\n    for (; i < top + 1; i++) {\n        int type = lua_type(L, i);\n        // lets find the metatable of this userdata to identify it.\n        if (lua_getmetatable(L, i) != 0) {\n            lua_pushstring(L, \"__name\");\n            if (lua_rawget(L, -2) != LUA_TNIL) {\n                fprintf(stderr, \"--|%d| [%s] (%s)\\n\", i, lua_typename(L, type), lua_tostring(L, -1));\n                lua_pop(L, 2);\n                continue;\n            }\n            lua_pop(L, 2);\n        }\n        if (type == LUA_TSTRING) {\n            fprintf(stderr, \"--|%d| [%s] | %s\\n\", i, lua_typename(L, type), lua_tostring(L, i));\n        } else {\n            fprintf(stderr, \"--|%d| [%s]\\n\", i, lua_typename(L, type));\n        }\n    }\n    fprintf(stderr, \"-----------------\\n\");\n}\n\n\n", "#!/usr/bin/env perl\n\nuse strict;\nuse warnings;\nuse Test::More;\nuse FindBin qw($Bin);\nuse lib \"$Bin/lib\";\nuse Carp qw(croak);\nuse MemcachedTest;\nuse IO::Socket qw(AF_INET SOCK_STREAM);\nuse IO::Select;\n\nif (!supports_proxy()) {\n    plan skip_all => 'proxy not enabled';\n    exit 0;\n}\n\n# Set up some server sockets.\nsub mock_server {\n    my $port = shift;\n    my $srv = IO::Socket->new(\n        Domain => AF_INET,\n        Type => SOCK_STREAM,\n        Proto => 'tcp',\n        LocalHost => '127.0.0.1',\n        LocalPort => $port,\n        ReusePort => 1,\n        Listen => 5) || die \"IO::Socket: $@\";\n    return $srv;\n}\n\n# Accept and validate a new backend connection.\nsub accept_backend {\n    my $srv = shift;\n    my $be = $srv->accept();\n    $be->autoflush(1);\n    ok(defined $be, \"mock backend created\");\n    like(<$be>, qr/version/, \"received version command\");\n    print $be \"VERSION 1.0.0-mock\\r\\n\";\n\n    return $be;\n}\n\nnote(\"Initialization:\" . __LINE__);\n\nmy @mocksrvs = ();\n#diag \"making mock servers\";\nfor my $port (11411, 11412, 11413) {\n    my $srv = mock_server($port);\n    ok(defined $srv, \"mock server created\");\n    push(@mocksrvs, $srv);\n}\n\nmy $p_srv = new_memcached('-o proxy_config=./t/proxyunits.lua');\nmy $ps = $p_srv->sock;\n$ps->autoflush(1);\n\nmy $pss = IO::Select->new();\n$pss->add($ps);\n\n# set up server backend sockets.\nmy @mbe = ();\n#diag \"accepting mock backends\";\nfor my $msrv (@mocksrvs) {\n    my $be = accept_backend($msrv);\n    push(@mbe, $be);\n}\n\n# Put a version command down the pipe to ensure the socket is clear.\n# client version commands skip the proxy code\nsub check_version {\n    my $ps = shift;\n    print $ps \"version\\r\\n\";\n    like(<$ps>, qr/VERSION /, \"version received\");\n}\n\n# Send a touch command to all backends, and verify response.\n# This makes sure socket buffers are clean between tests.\nsub check_sanity {\n    my $ps = shift;\n    my $cmd = \"touch /sanity/a 50\\r\\n\";\n    print $ps $cmd;\n    foreach my $idx (keys @mbe) {\n        my $be = $mbe[$idx];\n        is(scalar <$be>, $cmd, \"sanity check: touch cmd received for be \" . $idx);\n        print $be \"TOUCHED\\r\\n\";\n    }\n    is(scalar <$ps>, \"TOUCHED\\r\\n\", \"sanity check: TOUCHED response received.\");\n}\n\n# $ps_send : request to proxy\n# $be_recv : ref to a hashmap from be index to an array of received requests for validation.\n# $be_send : ref to a hashmap from be index to an array of responses to proxy.\n# $ps_recv : ref to response returned by proxy\n# backends in $be_recv and $be_send are vistied by looping through the @mbe.\nsub proxy_test {\n    my %args = @_;\n\n    my $ps_send = $args{ps_send};\n    my $be_recv = $args{be_recv} // {};\n    my $be_send = $args{be_send} // {};\n    my $ps_recv = $args{ps_recv};\n\n    # sends request to proxy\n    if ($ps_send) {\n        print $ps $ps_send;\n    }\n\n    # verify all backends received request\n    foreach my $idx (keys @mbe) {\n        if (exists $be_recv->{$idx}) {\n            my $be = $mbe[$idx];\n            foreach my $recv (@{$be_recv->{$idx}}) {\n                is(scalar <$be>, $recv, \"be \" . $idx . \" received expected response\");\n            }\n        }\n    }\n\n    # backends send responses\n    foreach my $idx (keys @mbe) {\n        if (exists $be_send->{$idx}) {\n            my $be = $mbe[$idx];\n            foreach my $send (@{$be_send->{$idx}}) {\n                print $be $send;\n            }\n        }\n    }\n\n    if (defined $ps_recv) {\n        if (scalar @{$ps_recv}) {\n            foreach my $recv (@{$ps_recv}) {\n                is(scalar <$ps>, $recv, \"ps returned expected response.\");\n            }\n            # makes sure nothing remains in $ps.\n            check_version($ps);\n        } else {\n            # when $ps_recv is empty, make sure it is not readable.\n            my @readable = $pss->can_read(0.1);\n            is(scalar @readable, 0, \"ps is expected to be non-readable\");\n        }\n    }\n}\n\n{\n    note(\"Bad syntax tests\");\n    # Write a request with bad syntax, and check the response.\n    print $ps \"set with the wrong number of tokens\\n\";\n    is(scalar <$ps>, \"CLIENT_ERROR parsing request\\r\\n\", \"got CLIENT_ERROR for bad syntax\");\n\n    for ('get', 'incr', 'decr', 'touch', 'gat', 'gats', 'mg', 'md', 'ma', 'ms') {\n        print $ps \"$_\\r\\n\";\n        is(scalar <$ps>, \"CLIENT_ERROR parsing request\\r\\n\", \"$_ got CLIENT_ERROR for too few tokens\");\n    }\n}\n\n# Basic test with a backend; write a request to the client socket, read it\n# from a backend socket, and write a response to the backend socket.\n#\n# The array @mbe holds references to our sockets for the backends listening on\n# the above mocked servers. In most tests we're only routing to the first\n# backend in the list ($mbe[0])\n#\n# In this case the client will receive an error and the backend gets closed,\n# so we have to re-establish it.\n{\n    note(\"Test missing END:\" . __LINE__);\n\n    # Test a fix for passing through partial read data if END ends up missing.\n    my $be = $mbe[0];\n    my $w = $p_srv->new_sock;\n    print $w \"watch proxyevents\\n\";\n    is(<$w>, \"OK\\r\\n\", \"watcher enabled\");\n\n    # write a request to proxy.\n    print $ps \"get /b/a\\r\\n\";\n\n    # verify request is received by backend.\n    is(scalar <$be>, \"get /b/a\\r\\n\", \"get passthrough\");\n\n    # write a response with partial data.\n    print $be \"VALUE /b/a 0 2\\r\\nhi\\r\\nEN\";\n\n    # verify the error response from proxy\n    is(scalar <$ps>, \"SERVER_ERROR backend failure\\r\\n\", \"backend failure error\");\n\n    # verify a particular proxy event logline is received\n    like(<$w>, qr/ts=(\\S+) gid=\\d+ type=proxy_backend error=timeout name=127.0.0.1 port=\\d+ depth=1 rbuf=EN/, \"got backend error log line\");\n\n    # backend is disconnected due to the error, so we have to re-establish it.\n    $mbe[0] = accept_backend($mocksrvs[0]);\n}\n\n# This test is similar to the above one, except we also establish a watcher to\n# check for appropriate log entries.\n{\n    note(\"Test trailingdata:\" . __LINE__);\n\n    # Test a log line with detailed data from backend failures.\n    my $be = $mbe[0];\n    my $w = $p_srv->new_sock;\n    print $w \"watch proxyevents\\n\";\n    is(<$w>, \"OK\\r\\n\", \"watcher enabled\");\n\n    print $ps \"get /b/c\\r\\n\";\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"get passthrough\");\n    # Set off a \"trailing data\" error\n    print $be \"VALUE /b/c 0 2\\r\\nok\\r\\nEND\\r\\ngarbage\";\n\n    is(scalar <$ps>, \"VALUE /b/c 0 2\\r\\n\", \"got value back\");\n    is(scalar <$ps>, \"ok\\r\\n\", \"got data back\");\n    is(scalar <$ps>, \"END\\r\\n\", \"got end string\");\n\n    like(<$w>, qr/ts=(\\S+) gid=\\d+ type=proxy_backend error=trailingdata name=127.0.0.1 port=\\d+ depth=0 rbuf=garbage/, \"got backend error log line\");\n\n    $mbe[0] = accept_backend($mocksrvs[0]);\n}\n\nnote(\"Test bugfix for missingend:\" . __LINE__);\n\n# This is an example of a test which will only pass before a bugfix is issued.\n# It's good practice where possible to write a failing test, then check it\n# against a code fix. We then leave the test in the file for reference.\n# Though noting when it was fixed is probably better than what I did here :)\nSKIP: {\n    skip \"Remove this skip line to demonstrate pre-patch bug\", 1;\n    # Test issue with finding response complete when read lands between value\n    # size and value + response line in size.\n    my $be = $mbe[0];\n    my $w = $p_srv->new_sock;\n    print $w \"watch proxyevents\\n\";\n    is(<$w>, \"OK\\r\\n\", \"watcher enabled\");\n\n    print $ps \"get /b/c\\r\\n\";\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"get passthrough\");\n\n    # Set off a \"missingend\" error.\n    # The server will wake up several times, thinking it has read the\n    # full size of response but it only read enough for the value portion.\n    print $be \"VALUE /b/c 0 5\\r\\nhe\";\n    sleep 0.1;\n    print $be \"llo\";\n    sleep 0.1;\n    print $be \"\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"SERVER_ERROR backend failure\\r\\n\");\n\n    like(<$w>, qr/ts=(\\S+) gid=\\d+ type=proxy_backend error=missingend name=127.0.0.1 port=\\d+ depth=1 rbuf=/, \"got missingend error log line\");\n\n    $mbe[0] = accept_backend($mocksrvs[0]);\n}\n\n{\n    # Test issue with finding response complete when read lands between value\n    # size and value + response line in size.\n    my $be = $mbe[0];\n\n    print $ps \"get /b/c\\r\\n\";\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"get passthrough\");\n\n    # Set off a \"missingend\" error.\n    # The server will wake up several times, thinking it has read the\n    # full size of response but it only read enough for the value portion.\n    print $be \"VALUE /b/c 0 5\\r\\nhe\";\n    sleep 0.1;\n    print $be \"llo\";\n    sleep 0.1;\n    print $be \"\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/c 0 5\\r\\n\", \"got value back\");\n    is(scalar <$ps>, \"hello\\r\\n\", \"got data back\");\n    is(scalar <$ps>, \"END\\r\\n\", \"got end string\");\n}\n\n#diag \"ready for main tests\";\n# Target a single backend, validating basic syntax.\n# Should test all command types.\n# uses /b/ path for \"basic\"\n{\n    note(\"Test all commands to a single backend:\" . __LINE__);\n\n    # Test invalid route.\n    print $ps \"set /invalid/a 0 0 2\\r\\nhi\\r\\n\";\n    is(scalar <$ps>, \"SERVER_ERROR no set route\\r\\n\");\n\n    # Testing against just one backend. Results should make sense despite our\n    # invalid request above.\n    my $be = $mbe[0];\n    my $cmd;\n\n    # TODO: add more tests for the varying response codes.\n\n    # Basic set.\n    $cmd = \"set /b/a 0 0 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"set passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"set value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from set\");\n\n    # Basic get\n    $cmd = \"get /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"get passthrough\");\n    print $be \"VALUE /b/a 0 2\\r\\nhi\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/a 0 2\\r\\n\", \"get rline\");\n    is(scalar <$ps>, \"hi\\r\\n\", \"get data\");\n    is(scalar <$ps>, \"END\\r\\n\", \"get end\");\n\n    # touch\n    $cmd = \"touch /b/a 50\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"touch passthrough\");\n    print $be \"TOUCHED\\r\\n\";\n\n    is(scalar <$ps>, \"TOUCHED\\r\\n\", \"got touch response\");\n\n    # gets\n    $cmd = \"gets /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"gets passthrough\");\n    print $be \"VALUE /b/a 0 2 2\\r\\nhi\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/a 0 2 2\\r\\n\", \"gets rline\");\n    is(scalar <$ps>, \"hi\\r\\n\", \"gets data\");\n    is(scalar <$ps>, \"END\\r\\n\", \"gets end\");\n\n    # gat\n    $cmd = \"gat 10 /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"gat passthrough\");\n    print $be \"VALUE /b/a 0 2\\r\\nhi\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/a 0 2\\r\\n\", \"gat rline\");\n    is(scalar <$ps>, \"hi\\r\\n\", \"gat data\");\n    is(scalar <$ps>, \"END\\r\\n\", \"gat end\");\n\n    # gats\n    $cmd = \"gats 11 /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"gats passthrough\");\n    print $be \"VALUE /b/a 0 2 1\\r\\nhi\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/a 0 2 1\\r\\n\", \"gats rline\");\n    is(scalar <$ps>, \"hi\\r\\n\", \"gats data\");\n    is(scalar <$ps>, \"END\\r\\n\", \"gats end\");\n\n    # cas\n    $cmd = \"cas /b/a 0 0 2 5\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"cas passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"cas value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from cas\");\n\n    # add\n    $cmd = \"add /b/a 0 0 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"add passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"add value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from add\");\n\n    # delete\n    $cmd = \"delete /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"delete passthrough\");\n    print $be \"DELETED\\r\\n\";\n\n    is(scalar <$ps>, \"DELETED\\r\\n\", \"got delete response\");\n\n    # incr\n    $cmd = \"incr /b/a 1\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"incr passthrough\");\n    print $be \"2\\r\\n\";\n\n    is(scalar <$ps>, \"2\\r\\n\", \"got incr response\");\n\n    # decr\n    $cmd = \"decr /b/a 1\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"decr passthrough\");\n    print $be \"10\\r\\n\";\n\n    is(scalar <$ps>, \"10\\r\\n\", \"got decr response\");\n\n    # append\n    $cmd = \"append /b/a 0 0 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"append passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"append value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from append\");\n\n    # prepend\n    $cmd = \"prepend /b/a 0 0 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"prepend passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"prepend value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from prepend\");\n\n    # [meta commands]\n    # testing the bare meta commands.\n    # TODO: add more tests for tokens and changing response codes.\n    # mg\n    $cmd = \"mg /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"mg passthrough\");\n    print $be \"HD\\r\\n\";\n\n    is(scalar <$ps>, \"HD\\r\\n\", \"got mg response\");\n    # ms\n    $cmd = \"ms /b/a 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"ms passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"ms value\");\n    print $be \"HD\\r\\n\";\n\n    is(scalar <$ps>, \"HD\\r\\n\", \"got HD from ms\");\n\n    # md\n    $cmd = \"md /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"md passthrough\");\n    print $be \"HD\\r\\n\";\n\n    is(scalar <$ps>, \"HD\\r\\n\", \"got HD from md\");\n    # ma\n    $cmd = \"ma /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"ma passthrough\");\n    print $be \"HD\\r\\n\";\n\n    is(scalar <$ps>, \"HD\\r\\n\", \"got HD from ma\");\n    # mn?\n    # me?\n}\n\n# run a cleanser check between each set of tests.\n# This ensures nothing was left in the client pipeline.\ncheck_sanity($ps);\n\n{\n    note(\"Test multiget:\" . __LINE__);\n\n    # multiget syntax\n    # - gets broken into individual gets on backend\n    my $be = $mbe[0];\n    my $cmd = \"get /b/a /b/b /b/c\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, \"get /b/a\\r\\n\", \"multiget breakdown a\");\n    is(scalar <$be>, \"get /b/b\\r\\n\", \"multiget breakdown b\");\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"multiget breakdown c\");\n\n    print $be \"VALUE /b/a 0 1\\r\\na\\r\\n\",\n              \"END\\r\\n\",\n              \"VALUE /b/b 0 1\\r\\nb\\r\\n\",\n              \"END\\r\\n\",\n              \"VALUE /b/c 0 1\\r\\nc\\r\\n\",\n              \"END\\r\\n\";\n\n    for my $key ('a', 'b', 'c') {\n        is(scalar <$ps>, \"VALUE /b/$key 0 1\\r\\n\", \"multiget res $key\");\n        is(scalar <$ps>, \"$key\\r\\n\", \"multiget value $key\");\n    }\n    is(scalar <$ps>, \"END\\r\\n\", \"final END from multiget\");\n\n    # Test multiget workaround with misses (known bug)\n    print $ps $cmd;\n    is(scalar <$be>, \"get /b/a\\r\\n\", \"multiget breakdown a\");\n    is(scalar <$be>, \"get /b/b\\r\\n\", \"multiget breakdown b\");\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"multiget breakdown c\");\n\n    print $be \"END\\r\\nEND\\r\\nEND\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"final END from multiget\");\n\n    # If bugged, the backend will have closed.\n    print $ps \"get /b/a\\r\\n\";\n    is(scalar <$be>, \"get /b/a\\r\\n\", \"get works after empty multiget\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"end after empty multiget\");\n}\n\ncheck_sanity($ps);\n\n{\n    note(\"Test noreply:\" . __LINE__);\n\n    # noreply tests.\n    # - backend should receive with noreply/q stripped or mangled\n    # - backend should reply as normal\n    # - frontend should get nothing; to test issue another command and ensure\n    # it only gets that response.\n    my $be = $mbe[0];\n    my $cmd = \"set /b/a 0 0 2 noreply\\r\\nhi\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, \"set /b/a 0 0 2 noreplY\\r\\n\", \"set received with broken noreply\");\n    is(scalar <$be>, \"hi\\r\\n\", \"set payload received\");\n\n    print $be \"STORED\\r\\n\";\n\n    # To ensure success, make another req and ensure res isn't STORED\n    $cmd = \"touch /b/a 50\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"canary touch received\");\n    print $be \"TOUCHED\\r\\n\";\n\n    is(scalar <$ps>, \"TOUCHED\\r\\n\", \"got TOUCHED instread of STORED\");\n}\n\ncheck_sanity($ps);\n\n{\n    subtest 'quiet flag: HD response' => sub {\n        # be_recv must receive a response with quiet flag replaced by a space.\n        # ps_recv must not receoved HD response.\n        proxy_test(\n            ps_send => \"ms /b/a 2 q\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /b/a 2  \\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [],\n        );\n    };\n\n    subtest 'quiet flag: EX response' => sub {\n        # be_recv must receive a response with quiet flag replaced by a space.\n        # ps_recv must return EX response from the backend.\n        proxy_test(\n            ps_send => \"ms /b/a 2 q\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /b/a 2  \\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"EX\\r\\n\"]},\n            ps_recv => [\"EX\\r\\n\"],\n        );\n    };\n\n    subtest 'quiet flag: backend failure' => sub {\n        # be_recv must receive a response with quiet flag replaced by a space.\n        # ps_recv must return backend failure response from the backend.\n        proxy_test(\n            ps_send => \"ms /b/a 2 q\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /b/a 2  \\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"garbage\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR backend failure\\r\\n\"],\n        );\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n}\n\ncheck_sanity($ps);\n\n# Test Lua request API\n{\n    note(\"Test Lua request APIs:\" . __LINE__);\n\n    my $be = $mbe[0];\n\n    # fetching the key.\n    print $ps \"get /getkey/testkey\\r\\n\";\n    # look for the key to be slightly different to ensure we hit lua.\n    is(scalar <$ps>, \"VALUE |/getkey/testkey 0 2\\r\\n\", \"request:key()\");\n    is(scalar <$ps>, \"ts\\r\\n\", \"request:key() value\");\n    is(scalar <$ps>, \"END\\r\\n\", \"request:key() END\");\n\n    # rtrimkey\n    # this overwrites part of the key with spaces, which should be skipped by\n    # a valid protocol parser.\n    print $ps \"get /rtrimkey/onehalf\\r\\n\";\n    is(scalar <$be>, \"get /rtrimkey/one    \\r\\n\", \"request:rtrimkey()\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"rtrimkey END\");\n\n    # ltrimkey\n    print $ps \"get /ltrimkey/test\\r\\n\";\n    is(scalar <$be>, \"get           test\\r\\n\", \"request:ltrimkey()\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"ltrimkey END\");\n\n    subtest 'request:ntokens()' => sub {\n        # ps_recv must return value that matches the number of tokens.\n        proxy_test(\n            ps_send => \"mg /ntokens/test c v\\r\\n\",\n            ps_recv => [\"VA 1 C123 v\\r\\n\", \"4\\r\\n\"],\n        );\n    };\n\n    subtest 'request:token() replacement' => sub {\n        # be_recv must received a response with replaced CAS token.\n        proxy_test(\n            ps_send => \"ms /token/replacement 2 C123\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /token/replacement 2 C456\\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"NF\\r\\n\"]},\n            ps_recv => [\"NF\\r\\n\"],\n        );\n    };\n\n    subtest 'request:token() remove' => sub {\n        # be_recv must received a response with CAS token removed.\n        proxy_test(\n            ps_send => \"ms /token/removal 2 C123\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /token/removal 2 \\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"NF\\r\\n\"]},\n            ps_recv => [\"NF\\r\\n\"],\n        );\n    };\n\n    subtest 'request:token() fetch' => sub {\n        # be_recv must received the key token in the P flag.\n        proxy_test(\n            ps_send => \"ms /token/fetch 2 C123 P\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /token/fetch 2 C123 P/token/fetch\\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    # # command() integer\n\n    subtest 'request:has_flag() meta positive 1' => sub {\n        # ps_recv must receive HD C123 for a successful hash_flag call.\n        proxy_test(\n            ps_send => \"mg /hasflag/test c\\r\\n\",\n            ps_recv => [\"HD C123\\r\\n\"],\n        );\n    };\n\n    subtest 'request:has_flag() meta positive 2' => sub {\n        # ps_recv must receive HD Oabc for a successful hash_flag call.\n        proxy_test(\n            ps_send => \"mg /hasflag/test Oabc T999\\r\\n\",\n            ps_recv => [\"HD Oabc\\r\\n\"],\n        );\n    };\n\n    subtest 'request:has_flag() meta negative' => sub {\n        # ps_recv must receive NF when has_flag returns false.\n        proxy_test(\n            ps_send => \"mg /hasflag/test T999\\r\\n\",\n            ps_recv => [\"NF\\r\\n\"],\n        );\n    };\n\n    subtest 'request:has_flag() none-meta ' => sub {\n        # ps_recv must receive END for a successful hash_flag call.\n        proxy_test(\n            ps_send => \"get /hasflag/test\\r\\n\",\n            ps_recv => [\"END\\r\\n\"],\n        );\n    };\n\n    subtest 'request:flag_token()' => sub {\n        # be_recv must receive expected flags after a series of flag_token() calls.\n        proxy_test(\n            ps_send => \"mg /flagtoken/a N10 k c R10\\r\\n\",\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n\n    subtest 'request edit' => sub {\n        # be_recv must receive the edited request.\n        proxy_test(\n            ps_send => \"ms /request/edit 2\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /request/edit 2\\r\\n\", \"ab\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    subtest 'request new' => sub {\n        # be_recv must receive the new request.\n        proxy_test(\n            ps_send => \"mg /request/old\\r\\n\",\n            be_recv => {0 => [\"mg /request/new c\\r\\n\"]},\n            be_send => {0 => [\"HD C123\\r\\n\"]},\n            ps_recv => [\"HD C123\\r\\n\"],\n        );\n    };\n\n    subtest 'request clone response' => sub {\n        # be must receive cloned meta-set from the previous meta-get.\n        my $be = $mbe[0];\n        print $ps \"mg /request/clone v\\r\\n\";\n        is(scalar <$be>, \"mg /request/clone v\\r\\n\", \"get passthrough\");\n        print $be \"VA 1 v\\r\\n4\\r\\n\";\n        is(scalar <$be>, \"ms /request/a 1\\r\\n\", \"received cloned meta-set\");\n        is(scalar <$be>, \"4\\r\\n\", \"received cloned meta-set value\");\n        print $be \"HD\\r\\n\";\n        is(scalar <$ps>, \"HD\\r\\n\", \"received HD\");\n    };\n}\n\ncheck_sanity($ps);\n\n# Test Lua response API\n{\n    subtest 'response:elapsed() >100000micros' => sub {\n        # ps_recv must not receive an error\n        my $be = $mbe[0];\n        my $cmd = \"mg /response/elapsed\\r\\n\";\n        print $ps $cmd;\n        is(scalar <$be>, $cmd, \"be received request.\");\n        sleep 0.1;\n        print $be \"HD\\r\\n\";\n        is(scalar <$ps>, \"HD\\r\\n\", \"proxy received HD\");\n    };\n\n\n    subtest 'response:ok()' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"mg /response/ok\\r\\n\",\n            be_recv => {0 => [\"mg /response/ok\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    subtest 'response:ok() false 1' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_ok\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_ok\\r\\n\"]},\n            be_send => {0 => [\"SERVER_ERROR\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n    };\n\n    subtest 'response:ok() false 2' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_ok\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_ok\\r\\n\"]},\n            be_send => {0 => [\"GARBAGE\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n\n        # test not_ok when backend is disconnected.\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_ok\\r\\n\",\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n\n        $mbe[0] = accept_backend($mocksrvs[0]);\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n\n    subtest 'response:ok() false 3' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_ok\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_ok\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n\n    subtest 'response:hit() mg' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"mg /response/hit\\r\\n\",\n            be_recv => {0 => [\"mg /response/hit\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    subtest 'response:hit() get' => sub {\n        # ps_recv must not receive an error\n        my $key = \"/response/hit\";\n        proxy_test(\n            ps_send => \"get $key\\r\\n\",\n            be_recv => {0 => [\"get $key\\r\\n\"]},\n            be_send => {0 => [\"VALUE $key 0 1\\r\\na\\r\\nEND\\r\\n\"]},\n            ps_recv => [\"VALUE $key 0 1\\r\\n\", \"a\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'response:hit() false 1' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_hit\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_hit\\r\\n\"]},\n            be_send => {0 => [\"EN\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n    };\n\n    subtest 'response:hit() false 2' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"get /response/not_hit\\r\\n\",\n            be_recv => {0 => [\"get /response/not_hit\\r\\n\"]},\n            be_send => {0 => [\"END\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n    };\n\n    subtest 'response:hit() false 3' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_hit\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_hit\\r\\n\"]},\n            be_send => {0 => [\"SERVER_ERROR\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n    };\n\n    subtest 'response:vlen()' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"mg /response/vlen v\\r\\n\",\n            be_recv => {0 => [\"mg /response/vlen v\\r\\n\"]},\n            be_send => {0 => [\"VA 1 v\\r\\n\", \"4\\r\\n\"]},\n            ps_recv => [\"VA 1 v\\r\\n\", \"4\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_OK' => sub {\n        # ps_recv must not receive an error\n        my $cmd = \"mg /response/code_ok v\\r\\n\";\n        proxy_test(\n            ps_send => $cmd,\n            be_recv => {0 => [$cmd]},\n            be_send => {0 => [\"VA 1 v\\r\\n\", \"4\\r\\n\"]},\n            ps_recv => [\"VA 1 v\\r\\n\", \"4\\r\\n\"],\n        );\n\n        proxy_test(\n            ps_send => \"ms /response/code_ok 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"ms /response/code_ok 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_MISS' => sub {\n        # ps_recv must not receive an error\n        my $cmd = \"mg /response/code_miss v\\r\\n\";\n        proxy_test(\n            ps_send => $cmd,\n            be_recv => {0 => [$cmd]},\n            be_send => {0 => [\"EN\\r\\n\"]},\n            ps_recv => [\"EN\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_STORED' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"set /response/code_stored 0 0 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"set /response/code_stored 0 0 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"STORED\\r\\n\"]},\n            ps_recv => [\"STORED\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_EXISTS' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"set /response/code_exists 0 0 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"set /response/code_exists 0 0 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"EXISTS\\r\\n\"]},\n            ps_recv => [\"EXISTS\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_NOT_STORED' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"set /response/code_not_stored 0 0 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"set /response/code_not_stored 0 0 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"NOT_STORED\\r\\n\"]},\n            ps_recv => [\"NOT_STORED\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_NOT_FOUND' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"set /response/code_not_found 0 0 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"set /response/code_not_found 0 0 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"NOT_FOUND\\r\\n\"]},\n            ps_recv => [\"NOT_FOUND\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_TOUCHED' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"touch /response/code_touched 50\\r\\n\",\n            be_recv => {0 => [\"touch /response/code_touched 50\\r\\n\"]},\n            be_send => {0 => [\"TOUCHED\\r\\n\"]},\n            ps_recv => [\"TOUCHED\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_DELETED' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"delete /response/code_deleted\\r\\n\",\n            be_recv => {0 => [\"delete /response/code_deleted\\r\\n\"]},\n            be_send => {0 => [\"DELETED\\r\\n\"]},\n            ps_recv => [\"DELETED\\r\\n\"],\n        );\n    };\n\n    SKIP: {\n        skip \"response:line() is broken\";\n        subtest 'response:line()' => sub {\n            # ps_recv must not receive an error\n            my $cmd = \"mg /response/line v\\r\\n\";\n            proxy_test(\n                ps_send => $cmd,\n                be_recv => {0 => [$cmd]},\n                be_send => {0 => [\"VA 1 v c123\\r\\n\", \"a\\r\\n\"]},\n                ps_recv => [\"VA 1 v c123\\r\\n\", \"a\\r\\n\"],\n            );\n\n            # ps_recv must not receive an error\n            proxy_test(\n                ps_send => \"ms /response/line 2\\r\\nab\\r\\n\",\n                be_recv => {0 => [\"ms /response/line 2\\r\\n\", \"ab\\r\\n\"]},\n                be_send => {0 => [\"HD O123 C123\\r\\n\"]},\n                ps_recv => [\"HD O123 C123\\r\\n\"],\n            );\n        };\n    };\n}\n\n\n# Test requests land in proper backend in basic scenarios\n{\n    note(\"Test routing by zone:\" . __LINE__);\n\n    # TODO: maybe should send values to ensure the right response?\n    # I don't think this test is very useful though; probably better to try\n    # harder when testing error conditions.\n    for my $tu (['a', $mbe[0]], ['b', $mbe[1]], ['c', $mbe[2]]) {\n        my $be = $tu->[1];\n        my $cmd = \"get /zonetest/\" . $tu->[0] . \"\\r\\n\";\n        print $ps $cmd;\n        is(scalar <$be>, $cmd, \"routed proper zone: \" . $tu->[0]);\n        print $be \"END\\r\\n\";\n        is(scalar <$ps>, \"END\\r\\n\", \"end from zone fetch\");\n    }\n    my $cmd = \"get /zonetest/invalid\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$ps>, \"END\\r\\n\", \"END from invalid route\");\n}\n\ncheck_sanity($ps);\n# Test re-requests in lua.\n# - fetch zones.z1() then fetch zones.z2()\n# - return z1 or z2 or netiher\n# - fetch all three zones\n# - hit the same zone multiple times\n\n# Test delayed read (timeout)\n\n# Test Lua logging (see t/watcher.t)\n{\n    note(\"Test Lua logging:\" . __LINE__);\n\n    my $be = $mbe[0];\n    my $watcher = $p_srv->new_sock;\n    print $watcher \"watch proxyuser proxyreqs\\n\";\n    is(<$watcher>, \"OK\\r\\n\", \"watcher enabled\");\n\n    # log(msg)\n    print $ps \"get /logtest/a\\r\\n\";\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_user msg=testing manual log messages/,\n        \"log a manual message\");\n    is(scalar <$ps>, \"END\\r\\n\", \"logtest END\");\n\n    # log_req(r, res)\n    my $cmd = \"get /logreqtest/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"got passthru for log\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"got END from log test\");\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_req elapsed=\\d+ type=105 code=17 status=0 be=127.0.0.1:11411 detail=logreqtest req=get \\/logreqtest\\/a/, \"found request log entry\");\n\n    # test log_req with nil res (should be 0's in places)\n    # log_reqsample()\n}\n\n# Basic proxy stats validation\n\n# Test user stats\n\ncheck_sanity($ps);\n# Test await arguments (may move to own file?)\n# TODO: the results table from mcp.await() contains all of the results so far,\n# regardless of the mode.\n# need some tests that show this.\n{\n    note(\"Test await argument:\" . __LINE__);\n\n    # DEFAULT MODE, i.e. AWAIT_GOOD\n\n    subtest 'await(r, p): send [h, h, h], recv 3 hits' => sub {\n        # be_recv must receive hit from all three backends\n        my $key = \"/awaitbasic/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my @be_send = [\"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\"];\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => @be_send, 1 => @be_send, 2 => @be_send},\n            ps_recv => [\"VALUE $key 0 11\\r\\n\", \"hit hit hit\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'await(r, p, 1): send [h], recv 1 response and 2 reconn' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [\"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\"]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"1:1:1\\r\\n\", \"END\\r\\n\"],\n        );\n        # reconnect due to timeout\n        $mbe[1] = accept_backend($mocksrvs[1]);\n        $mbe[2] = accept_backend($mocksrvs[2]);\n    };\n\n    subtest 'await(r, p, 1): send [h, m, m], recv 1 response' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"1:1:1\\r\\n\", \"END\\r\\n\"],\n        );\n        # send response to not timeout\n        $mbe[1]->send($be_miss);\n        $mbe[2]->send($be_miss);\n    };\n\n    subtest 'await(r, p, 1): send [m, m, h], recv 3 responses' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_miss], 1 => [$be_miss], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"3:3:1\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'await(r, p, 1): sent [m, h, m], recv 2 responses' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_miss], 1 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"2:2:1\\r\\n\", \"END\\r\\n\"],\n        );\n        $mbe[2]->send($be_miss);\n    };\n\n    subtest 'await(r, p, 1): sent [h, h, h], recv 1 response' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_hit], 1 => [$be_hit], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"1:1:1\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'await(r, p, 2): sent [h, h, h], recv 2 responses' => sub {\n        my $key = \"/awaitone/b\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_hit], 1 => [$be_hit], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"2:2:2\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'await(r, p, 1): send [e, m, h], recv 3 responses and 1 reconn' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        my $be_error = \"ERROR backend failure\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_error], 1 => [$be_miss], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"3:2:1\\r\\n\", \"END\\r\\n\"],\n        );\n        # reconnect due to ERROR\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n\n    subtest 'await(r, p, 1): send [e, m, e], recv 3 responses and 1 reconn' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        my $be_error = \"ERROR failure\\r\\n\";\n        my $be_server_error = \"SERVER_ERROR backend failure\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_error], 1 => [$be_miss], 2 => [$be_server_error]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"3:1:0\\r\\n\", \"END\\r\\n\"],\n        );\n        # reconnect due to ERROR\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n\n    subtest 'await(r, p, 1, mcp.AWAIT_GOOD): sent [h, h, h], recv 1 response' => sub {\n        # ps_recv must receive hit when one backend sent good response.\n        my $key = \"/awaitgood/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_hit], 1 => [$be_hit], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"1:1:1\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    my $cmd;\n    my $key;\n\n    # await(r, p, 2, mcp.AWAIT_ANY)\n    $key = \"/awaitany/a\";\n    $cmd = \"get $key\\r\\n\";\n    print $ps $cmd;\n    for my $be (@mbe) {\n        is(scalar <$be>, $cmd, \"awaitany backend req\");\n        print $be \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n    }\n    is(scalar <$ps>, \"VALUE $key 0 1\\r\\n\", \"response from await\");\n    is(scalar <$ps>, \"2\\r\\n\", \"looking for a two responses\");\n    is(scalar <$ps>, \"END\\r\\n\", \"end from await\");\n\n    # await(r, p, 2, mcp.AWAIT_OK)\n    # await(r, p, 1, mcp.AWAIT_FIRST)\n    # more AWAIT_FIRST tests? to see how much it waits on/etc.\n    # await(r, p, 2, mcp.AWAIT_FASTGOOD)\n    # - should return 1 res on good, else wait for N non-error responses\n    $key = \"/awaitfastgood/a\";\n    $cmd = \"get $key\\r\\n\";\n    print $ps $cmd;\n    my $fbe = $mbe[0];\n    is(scalar <$fbe>, $cmd, \"awaitfastgood backend req\");\n    print $fbe \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n    # Should have response after the first hit.\n    is(scalar <$ps>, \"VALUE $key 0 2\\r\\n\", \"response from await\");\n    is(scalar <$ps>, \"ok\\r\\n\", \"await value\");\n    is(scalar <$ps>, \"END\\r\\n\", \"end from await\");\n    for my $be ($mbe[1], $mbe[2]) {\n        is(scalar <$be>, $cmd, \"awaitfastgood backend req\");\n        print $be \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n    }\n\n    # test three pools, second response returns good. should have a hit.\n    print $ps $cmd;\n    for my $be (@mbe) {\n        is(scalar <$be>, $cmd, \"awaitfastgood backend req\");\n    }\n    $fbe = $mbe[0];\n    print $fbe \"END\\r\\n\";\n    $fbe = $mbe[1];\n    print $fbe \"VALUE $key 0 2\\r\\nun\\r\\nEND\\r\\n\";\n    is(scalar <$ps>, \"VALUE $key 0 2\\r\\n\", \"response from await\");\n    is(scalar <$ps>, \"un\\r\\n\", \"await value\");\n    is(scalar <$ps>, \"END\\r\\n\", \"end from await\");\n    $fbe = $mbe[2];\n    print $fbe \"END\\r\\n\";\n\n    # test three pools, but third returns good. should have returned already\n    print $ps $cmd;\n    for my $be ($mbe[0], $mbe[1]) {\n        is(scalar <$be>, $cmd, \"awaitfastgood backend req\");\n        print $be \"END\\r\\n\";\n    }\n    $fbe = $mbe[2];\n    is(scalar <$fbe>, $cmd, \"awaitfastgood backend req\");\n    print $fbe \"VALUE $key 0 2\\r\\nnu\\r\\nEND\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"miss from awaitfastgood\");\n\n    # Testing a set related to fastgood. waiting for two responses.\n    $cmd = \"set $key 0 0 2\\r\\nmo\\r\\n\";\n    print $ps $cmd;\n    for my $be ($mbe[0], $mbe[1]) {\n        is(scalar <$be>, \"set $key 0 0 2\\r\\n\", \"set backend req\");\n        is(scalar <$be>, \"mo\\r\\n\", \"set backend data\");\n        print $be \"STORED\\r\\n\";\n    }\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got stored from await\");\n    $fbe = $mbe[2];\n    is(scalar <$fbe>, \"set $key 0 0 2\\r\\n\", \"set backend req\");\n    is(scalar <$fbe>, \"mo\\r\\n\", \"set backend data\");\n    print $fbe \"STORED\\r\\n\";\n\n    # Testing another set; ensure it isn't returning early.\n    my $s = IO::Select->new();\n    $s->add($ps);\n    print $ps $cmd;\n    for my $be (@mbe) {\n        is(scalar <$be>, \"set $key 0 0 2\\r\\n\", \"set backend req\");\n        is(scalar <$be>, \"mo\\r\\n\", \"set backend data\");\n    }\n    $fbe = $mbe[0];\n    print $fbe \"STORED\\r\\n\";\n    my @readable = $s->can_read(0.25);\n    is(scalar @readable, 0, \"set doesn't return early\");\n    for my $be ($mbe[1], $mbe[2]) {\n        print $be \"STORED\\r\\n\";\n    }\n    is(scalar <$ps>, \"STORED\\r\\n\", \"set completed normally\");\n\n    # await(r, p, 1, mcp.AWAIT_BACKGROUND) - ensure res without waiting\n    $key = \"/awaitbg/a\";\n    $cmd = \"get $key\\r\\n\";\n    print $ps $cmd;\n    # check we can get a response _before_ the backends are consulted.\n    is(scalar <$ps>, \"VALUE $key 0 1\\r\\n\", \"response from await\");\n    is(scalar <$ps>, \"0\\r\\n\", \"looking for zero responses\");\n    is(scalar <$ps>, \"END\\r\\n\", \"end from await\");\n    for my $be (@mbe) {\n        is(scalar <$be>, $cmd, \"awaitbg backend req\");\n        print $be \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n    }\n\n    # test hitting a pool normally then hit mcp.await()\n    # test hitting mcp.await() then a pool normally\n}\n\ncheck_sanity($ps);\n\n{\n    note(\"Test await_logerrors:\" . __LINE__);\n\n    my $watcher = $p_srv->new_sock;\n    print $watcher \"watch proxyreqs\\n\";\n    is(<$watcher>, \"OK\\r\\n\", \"watcher enabled\");\n\n    # test logging errors from special await.\n    my $key = \"/awaitlogerr/a\";\n    my $cmd = \"set $key 0 0 5\\r\\n\";\n    print $ps $cmd . \"hello\\r\\n\";\n    # respond from the first backend normally, then other two with errors.\n    my $be = $mbe[0];\n    is(scalar <$be>, $cmd, \"await_logerrors backend req\");\n    is(scalar <$be>, \"hello\\r\\n\", \"await_logerrors set payload\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"block until await responded\");\n    # now ship some errors.\n    for my $be ($mbe[1], $mbe[2]) {\n        is(scalar <$be>, $cmd, \"await_logerrors backend req\");\n        is(scalar <$be>, \"hello\\r\\n\", \"await_logerrors set payload\");\n        print $be \"SERVER_ERROR out of memory\\r\\n\";\n    }\n\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_req elapsed=\\d+ type=\\d+ code=\\d+ status=-1 be=(\\S+) detail=write_failed req=set \\/awaitlogerr\\/a/, \"await_logerrors log entry 1\");\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_req elapsed=\\d+ type=\\d+ code=\\d+ status=-1 be=(\\S+) detail=write_failed req=set \\/awaitlogerr\\/a/, \"await_logerrors log entry 2\");\n\n    # Repeat the logreqtest to ensure we only got the log lines we expected.\n    $cmd = \"get /logreqtest/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"got passthru for log\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"got END from log test\");\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_req elapsed=\\d+ type=105 code=17 status=0 be=127.0.0.1:11411 detail=logreqtest req=get \\/logreqtest\\/a/, \"found request log entry\");\n}\n\ncheck_sanity($ps);\n\n# Test out of spec commands from client\n# - wrong # of tokens\n# - bad key size\n# - etc\n\n# Test errors/garbage from server\n# - certain errors pass through to the client, most close the backend.\n# - should be able to retrieve the error message\n{\n    note(\"Test error/garbage from backend:\" . __LINE__);\n\n    my $be = $mbe[0];\n    print $ps \"set /b/foo 0 0 2\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"set /b/foo 0 0 2\\r\\n\", \"received set cmd\");\n    is(scalar <$be>, \"hi\\r\\n\", \"received set data\");\n    # Send a classic back up the pipe.\n    my $msg = \"SERVER_ERROR object too large for cache\\r\\n\";\n    print $be $msg;\n    is(scalar <$ps>, $msg, \"client received error message\");\n\n    print $ps \"get /b/foo\\r\\n\";\n    is(scalar <$be>, \"get /b/foo\\r\\n\", \"backend still works\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"got end back\");\n\n    # ERROR and CLIENT_ERROR should both break the backend.\n    print $ps \"get /b/moo\\r\\n\";\n    is(scalar <$be>, \"get /b/moo\\r\\n\", \"received get command\");\n    $msg = \"CLIENT_ERROR bad command line format\\r\\n\";\n    my $data;\n    print $be $msg;\n    is(scalar <$ps>, $msg, \"client received error message\");\n    my $read = $be->read($data, 1);\n    is($read, 0, \"backend disconnected\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    print $ps \"get /b/too\\r\\n\";\n    is(scalar <$be>, \"get /b/too\\r\\n\", \"received get command\");\n    $msg = \"ERROR unhappy\\r\\n\";\n    print $be $msg;\n    is(scalar <$ps>, $msg, \"client received error message\");\n    $read = $be->read($data, 1);\n    is($read, 0, \"backend disconnected\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    # Sometimes blank ERRORS can be sent.\n    print $ps \"get /b/zoo\\r\\n\";\n    is(scalar <$be>, \"get /b/zoo\\r\\n\", \"received get command\");\n    $msg = \"ERROR\\r\\n\";\n    print $be $msg;\n    is(scalar <$ps>, $msg, \"client received error message\");\n    $read = $be->read($data, 1);\n    is($read, 0, \"backend disconnected\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    # Ensure garbage doesn't surface to client.\n    print $ps \"get /b/doo\\r\\n\";\n    is(scalar <$be>, \"get /b/doo\\r\\n\", \"received get command\");\n    print $be \"garbage\\r\\n\"; # don't need the \\r\\n but it makes tests easier\n    is(scalar <$ps>, \"SERVER_ERROR backend failure\\r\\n\", \"generic backend error\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    # Check errors from pipelined commands past a CLIENT_ERROR\n    print $ps \"get /b/quu\\r\\nget /b/muu\\r\\n\";\n    is(scalar <$be>, \"get /b/quu\\r\\n\", \"received get command\");\n    is(scalar <$be>, \"get /b/muu\\r\\n\", \"received next get command\");\n    print $be \"CLIENT_ERROR bad protocol\\r\\nEND\\r\\n\";\n    is(scalar <$ps>, \"CLIENT_ERROR bad protocol\\r\\n\", \"backend error\");\n    is(scalar <$ps>, \"SERVER_ERROR backend failure\\r\\n\", \"backend error\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    # Check that lua handles errors properly.\n    print $ps \"get /errcheck/a\\r\\n\";\n    is(scalar <$be>, \"get /errcheck/a\\r\\n\", \"received get command\");\n    print $be \"ERROR test1\\r\\n\";\n    is(scalar <$ps>, \"ERROR\\r\\n\", \"lua saw correct error code\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    print $ps \"get /errcheck/b\\r\\n\";\n    is(scalar <$be>, \"get /errcheck/b\\r\\n\", \"received get command\");\n    print $be \"CLIENT_ERROR test2\\r\\n\";\n    is(scalar <$ps>, \"CLIENT_ERROR\\r\\n\", \"lua saw correct error code\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    print $ps \"get /errcheck/c\\r\\n\";\n    is(scalar <$be>, \"get /errcheck/c\\r\\n\", \"received get command\");\n    print $be \"SERVER_ERROR test3\\r\\n\";\n    is(scalar <$ps>, \"SERVER_ERROR\\r\\n\", \"lua saw correct error code\");\n}\n\ncheck_sanity($ps);\ndone_testing();\n"], "fixing_code": ["/* -*- Mode: C; tab-width: 4; c-basic-offset: 4; indent-tabs-mode: nil -*- */\n/*\n * Functions for handling the proxy layer. wraps text protocols\n *\n * NOTE: many lua functions generate pointers via \"lua_newuserdatauv\" or\n * similar. Normal memory checking isn't done as lua will throw a high level\n * error if malloc fails. Must keep this in mind while allocating data so any\n * manually malloc'ed information gets freed properly.\n */\n\n#include \"proxy.h\"\n\n#define PROCESS_MULTIGET true\n#define PROCESS_NORMAL false\nstatic void proxy_process_command(conn *c, char *command, size_t cmdlen, bool multiget);\nstatic void mcp_queue_io(conn *c, mc_resp *resp, int coro_ref, lua_State *Lc);\n\n/******** EXTERNAL FUNCTIONS ******/\n// functions starting with _ are breakouts for the public functions.\n\nbool proxy_bufmem_checkadd(LIBEVENT_THREAD *t, int len) {\n    bool oom = false;\n    pthread_mutex_lock(&t->proxy_limit_lock);\n    if (t->proxy_buffer_memory_used > t->proxy_buffer_memory_limit) {\n        oom = true;\n    } else {\n        t->proxy_buffer_memory_used += len;\n    }\n    pthread_mutex_unlock(&t->proxy_limit_lock);\n    return oom;\n}\n\n// see also: process_extstore_stats()\nvoid proxy_stats(void *arg, ADD_STAT add_stats, conn *c) {\n    if (arg == NULL) {\n       return;\n    }\n    proxy_ctx_t *ctx = arg;\n    STAT_L(ctx);\n\n    APPEND_STAT(\"proxy_config_reloads\", \"%llu\", (unsigned long long)ctx->global_stats.config_reloads);\n    APPEND_STAT(\"proxy_config_reload_fails\", \"%llu\", (unsigned long long)ctx->global_stats.config_reload_fails);\n    APPEND_STAT(\"proxy_backend_total\", \"%llu\", (unsigned long long)ctx->global_stats.backend_total);\n    APPEND_STAT(\"proxy_backend_marked_bad\", \"%llu\", (unsigned long long)ctx->global_stats.backend_marked_bad);\n    APPEND_STAT(\"proxy_backend_failed\", \"%llu\", (unsigned long long)ctx->global_stats.backend_failed);\n    STAT_UL(ctx);\n}\n\nvoid process_proxy_stats(void *arg, ADD_STAT add_stats, conn *c) {\n    char key_str[STAT_KEY_LEN];\n    struct proxy_int_stats istats = {0};\n    uint64_t req_limit = 0;\n    uint64_t buffer_memory_limit = 0;\n    uint64_t buffer_memory_used = 0;\n\n    if (!arg) {\n        return;\n    }\n    proxy_ctx_t *ctx = arg;\n    STAT_L(ctx);\n    req_limit = ctx->active_req_limit;\n    buffer_memory_limit = ctx->buffer_memory_limit;\n\n    // prepare aggregated counters.\n    struct proxy_user_stats *us = &ctx->user_stats;\n    uint64_t counters[us->num_stats];\n    memset(counters, 0, sizeof(counters));\n\n    // TODO (v3): more globals to remove and/or change API method.\n    // aggregate worker thread counters.\n    for (int x = 0; x < settings.num_threads; x++) {\n        LIBEVENT_THREAD *t = get_worker_thread(x);\n        struct proxy_user_stats *tus = t->proxy_user_stats;\n        struct proxy_int_stats *is = t->proxy_int_stats;\n        WSTAT_L(t);\n        for (int i = 0; i < CMD_FINAL; i++) {\n            istats.counters[i] += is->counters[i];\n        }\n        if (tus && tus->num_stats >= us->num_stats) {\n            for (int i = 0; i < us->num_stats; i++) {\n                counters[i] += tus->counters[i];\n            }\n        }\n        WSTAT_UL(t);\n        pthread_mutex_lock(&t->proxy_limit_lock);\n        buffer_memory_used += t->proxy_buffer_memory_used;\n        pthread_mutex_unlock(&t->proxy_limit_lock);\n    }\n\n    // return all of the user generated stats\n    for (int x = 0; x < us->num_stats; x++) {\n        if (us->names[x]) {\n            snprintf(key_str, STAT_KEY_LEN-1, \"user_%s\", us->names[x]);\n            APPEND_STAT(key_str, \"%llu\", (unsigned long long)counters[x]);\n        }\n    }\n\n    STAT_UL(ctx);\n\n    if (buffer_memory_limit == UINT64_MAX) {\n        buffer_memory_limit = 0;\n    } else {\n        buffer_memory_limit *= settings.num_threads;\n    }\n    if (req_limit == UINT64_MAX) {\n        req_limit = 0;\n    } else {\n        req_limit *= settings.num_threads;\n    }\n\n    // return proxy counters\n    APPEND_STAT(\"active_req_limit\", \"%llu\", (unsigned long long)req_limit);\n    APPEND_STAT(\"buffer_memory_limit\", \"%llu\", (unsigned long long)buffer_memory_limit);\n    APPEND_STAT(\"buffer_memory_used\", \"%llu\", (unsigned long long)buffer_memory_used);\n    APPEND_STAT(\"cmd_mg\", \"%llu\", (unsigned long long)istats.counters[CMD_MG]);\n    APPEND_STAT(\"cmd_ms\", \"%llu\", (unsigned long long)istats.counters[CMD_MS]);\n    APPEND_STAT(\"cmd_md\", \"%llu\", (unsigned long long)istats.counters[CMD_MD]);\n    APPEND_STAT(\"cmd_mn\", \"%llu\", (unsigned long long)istats.counters[CMD_MN]);\n    APPEND_STAT(\"cmd_ma\", \"%llu\", (unsigned long long)istats.counters[CMD_MA]);\n    APPEND_STAT(\"cmd_me\", \"%llu\", (unsigned long long)istats.counters[CMD_ME]);\n    APPEND_STAT(\"cmd_get\", \"%llu\", (unsigned long long)istats.counters[CMD_GET]);\n    APPEND_STAT(\"cmd_gat\", \"%llu\", (unsigned long long)istats.counters[CMD_GAT]);\n    APPEND_STAT(\"cmd_set\", \"%llu\", (unsigned long long)istats.counters[CMD_SET]);\n    APPEND_STAT(\"cmd_add\", \"%llu\", (unsigned long long)istats.counters[CMD_ADD]);\n    APPEND_STAT(\"cmd_cas\", \"%llu\", (unsigned long long)istats.counters[CMD_CAS]);\n    APPEND_STAT(\"cmd_gets\", \"%llu\", (unsigned long long)istats.counters[CMD_GETS]);\n    APPEND_STAT(\"cmd_gats\", \"%llu\", (unsigned long long)istats.counters[CMD_GATS]);\n    APPEND_STAT(\"cmd_incr\", \"%llu\", (unsigned long long)istats.counters[CMD_INCR]);\n    APPEND_STAT(\"cmd_decr\", \"%llu\", (unsigned long long)istats.counters[CMD_DECR]);\n    APPEND_STAT(\"cmd_touch\", \"%llu\", (unsigned long long)istats.counters[CMD_TOUCH]);\n    APPEND_STAT(\"cmd_append\", \"%llu\", (unsigned long long)istats.counters[CMD_APPEND]);\n    APPEND_STAT(\"cmd_prepend\", \"%llu\", (unsigned long long)istats.counters[CMD_PREPEND]);\n    APPEND_STAT(\"cmd_delete\", \"%llu\", (unsigned long long)istats.counters[CMD_DELETE]);\n    APPEND_STAT(\"cmd_replace\", \"%llu\", (unsigned long long)istats.counters[CMD_REPLACE]);\n}\n\n// start the centralized lua state and config thread.\nvoid *proxy_init(bool use_uring) {\n    proxy_ctx_t *ctx = calloc(1, sizeof(proxy_ctx_t));\n    ctx->use_uring = use_uring;\n\n    pthread_mutex_init(&ctx->config_lock, NULL);\n    pthread_cond_init(&ctx->config_cond, NULL);\n    pthread_mutex_init(&ctx->worker_lock, NULL);\n    pthread_cond_init(&ctx->worker_cond, NULL);\n    pthread_mutex_init(&ctx->manager_lock, NULL);\n    pthread_cond_init(&ctx->manager_cond, NULL);\n    pthread_mutex_init(&ctx->stats_lock, NULL);\n\n    ctx->active_req_limit = UINT64_MAX;\n    ctx->buffer_memory_limit = UINT64_MAX;\n\n    // FIXME (v2): default defines.\n    ctx->tunables.tcp_keepalive = false;\n    ctx->tunables.backend_failure_limit = 3;\n    ctx->tunables.connect.tv_sec = 5;\n    ctx->tunables.retry.tv_sec = 3;\n    ctx->tunables.read.tv_sec = 3;\n\n    STAILQ_INIT(&ctx->manager_head);\n    lua_State *L = luaL_newstate();\n    ctx->proxy_state = L;\n    luaL_openlibs(L);\n    // NOTE: might need to differentiate the libs yes?\n    proxy_register_libs(ctx, NULL, L);\n\n    // Create/start the IO thread, which we need before servers\n    // start getting created.\n    proxy_event_thread_t *t = calloc(1, sizeof(proxy_event_thread_t));\n    ctx->proxy_io_thread = t;\n    proxy_init_event_thread(t, ctx, NULL);\n\n    pthread_create(&t->thread_id, NULL, proxy_event_thread, t);\n    thread_setname(t->thread_id, \"mc-prx-io\");\n\n    _start_proxy_config_threads(ctx);\n    return ctx;\n}\n\n// Initialize the VM for an individual worker thread.\nvoid proxy_thread_init(void *ctx, LIBEVENT_THREAD *thr) {\n    assert(ctx != NULL);\n    assert(thr != NULL);\n\n    // Create the hook table.\n    thr->proxy_hooks = calloc(CMD_SIZE, sizeof(struct proxy_hook));\n    if (thr->proxy_hooks == NULL) {\n        fprintf(stderr, \"Failed to allocate proxy hooks\\n\");\n        exit(EXIT_FAILURE);\n    }\n    thr->proxy_int_stats = calloc(1, sizeof(struct proxy_int_stats));\n    if (thr->proxy_int_stats == NULL) {\n        fprintf(stderr, \"Failed to allocate proxy thread stats\\n\");\n        exit(EXIT_FAILURE);\n    }\n    pthread_mutex_init(&thr->proxy_limit_lock, NULL);\n    thr->proxy_ctx = ctx;\n\n    // Initialize the lua state.\n    lua_State *L = luaL_newstate();\n    thr->L = L;\n    luaL_openlibs(L);\n    proxy_register_libs(ctx, thr, L);\n    // TODO: srand on time? do we need to bother?\n    for (int x = 0; x < 3; x++) {\n        thr->proxy_rng[x] = rand();\n    }\n\n    // Create a proxy event thread structure to piggyback on the worker.\n    proxy_event_thread_t *t = calloc(1, sizeof(proxy_event_thread_t));\n    thr->proxy_event_thread = t;\n    proxy_init_event_thread(t, ctx, thr->base);\n}\n\n// ctx_stack is a stack of io_pending_proxy_t's.\n// head of q->s_ctx is the \"newest\" request so we must push into the head\n// of the next queue, as requests are dequeued from the head\nvoid proxy_submit_cb(io_queue_t *q) {\n    proxy_event_thread_t *e = ((proxy_ctx_t *)q->ctx)->proxy_io_thread;\n    io_pending_proxy_t *p = q->stack_ctx;\n    io_head_t head;\n    be_head_t w_head; // worker local stack.\n    STAILQ_INIT(&head);\n    STAILQ_INIT(&w_head);\n\n    // NOTE: responses get returned in the correct order no matter what, since\n    // mc_resp's are linked.\n    // we just need to ensure stuff is parsed off the backend in the correct\n    // order.\n    // So we can do with a single list here, but we need to repair the list as\n    // responses are parsed. (in the req_remaining-- section)\n    // TODO (v2):\n    // - except we can't do that because the deferred IO stack isn't\n    // compatible with queue.h.\n    // So for now we build the secondary list with an STAILQ, which\n    // can be transplanted/etc.\n    while (p) {\n        mcp_backend_t *be;\n        P_DEBUG(\"%s: queueing req for backend: %p\\n\", __func__, (void *)p);\n        if (p->is_await) {\n            // need to not count await objects multiple times.\n            if (p->await_background) {\n                P_DEBUG(\"%s: fast-returning await_background object: %p\\n\", __func__, (void *)p);\n                // intercept await backgrounds\n                // this call cannot recurse if we're on the worker thread,\n                // since the worker thread has to finish executing this\n                // function in order to pick up the returned IO.\n                q->count++;\n                return_io_pending((io_pending_t *)p);\n                p = p->next;\n                continue;\n            } else if (p->await_first) {\n                q->count++;\n            }\n            // funny workaround: awaiting IOP's don't count toward\n            // resuming a connection, only the completion of the await\n            // condition.\n        } else {\n            q->count++;\n        }\n        be = p->backend;\n\n        if (be->use_io_thread) {\n            STAILQ_INSERT_HEAD(&head, p, io_next);\n        } else {\n            // emulate some of handler_dequeue()\n            STAILQ_INSERT_TAIL(&be->io_head, p, io_next);\n            be->depth++;\n            if (!be->stacked) {\n                be->stacked = true;\n                be->be_next.stqe_next = NULL; // paranoia\n                STAILQ_INSERT_TAIL(&w_head, be, be_next);\n            }\n        }\n\n        p = p->next;\n    }\n\n    // clear out the submit queue so we can re-queue new IO's inline.\n    q->stack_ctx = NULL;\n\n    if (!STAILQ_EMPTY(&head)) {\n        P_DEBUG(\"%s: submitting queue to IO thread\\n\", __func__);\n        // Transfer request stack to event thread.\n        pthread_mutex_lock(&e->mutex);\n        STAILQ_CONCAT(&e->io_head_in, &head);\n        // No point in holding the lock since we're not doing a cond signal.\n        pthread_mutex_unlock(&e->mutex);\n\n        // Signal to check queue.\n#ifdef USE_EVENTFD\n        uint64_t u = 1;\n        // TODO (v2): check result? is it ever possible to get a short write/failure\n        // for an eventfd?\n        if (write(e->event_fd, &u, sizeof(uint64_t)) != sizeof(uint64_t)) {\n            assert(1 == 0);\n        }\n#else\n        if (write(e->notify_send_fd, \"w\", 1) <= 0) {\n            assert(1 == 0);\n        }\n#endif\n    }\n\n    if (!STAILQ_EMPTY(&w_head)) {\n        P_DEBUG(\"%s: running inline worker queue\\n\", __func__);\n        // emulating proxy_event_handler\n        proxy_run_backend_queue(&w_head);\n    }\n    return;\n}\n\n// called from worker thread after an individual IO has been returned back to\n// the worker thread. Do post-IO run and cleanup work.\nvoid proxy_return_cb(io_pending_t *pending) {\n    io_pending_proxy_t *p = (io_pending_proxy_t *)pending;\n    if (p->is_await) {\n        mcplib_await_return(p);\n    } else {\n        lua_State *Lc = p->coro;\n\n        // in order to resume we need to remove the objects that were\n        // originally returned\n        // what's currently on the top of the stack is what we want to keep.\n        lua_rotate(Lc, 1, 1);\n        // We kept the original results from the yield so lua would not\n        // collect them in the meantime. We can drop those now.\n        lua_settop(Lc, 1);\n\n        // p can be freed/changed from the call below, so fetch the queue now.\n        io_queue_t *q = conn_io_queue_get(p->c, p->io_queue_type);\n        conn *c = p->c;\n        proxy_run_coroutine(Lc, p->resp, p, c);\n\n        q->count--;\n        if (q->count == 0) {\n            // call re-add directly since we're already in the worker thread.\n            conn_worker_readd(c);\n        }\n    }\n}\n\n// called from the worker thread as an mc_resp is being freed.\n// must let go of the coroutine reference if there is one.\n// caller frees the pending IO.\nvoid proxy_finalize_cb(io_pending_t *pending) {\n    io_pending_proxy_t *p = (io_pending_proxy_t *)pending;\n\n    if (p->io_type == IO_PENDING_TYPE_EXTSTORE) {\n        if (p->hdr_it) {\n            // TODO: lock once, worst case this hashes/locks twice.\n            if (p->miss) {\n                item_unlink(p->hdr_it);\n            }\n            item_remove(p->hdr_it);\n        }\n    }\n\n    // release our coroutine reference.\n    // TODO (v2): coroutines are reusable in lua 5.4. we can stack this onto a freelist\n    // after a lua_resetthread(Lc) call.\n    if (p->coro_ref) {\n        // Note: lua registry is the same for main thread or a coroutine.\n        luaL_unref(p->coro, LUA_REGISTRYINDEX, p->coro_ref);\n    }\n\n    return;\n}\n\nint try_read_command_proxy(conn *c) {\n    char *el, *cont;\n\n    if (c->rbytes == 0)\n        return 0;\n\n    el = memchr(c->rcurr, '\\n', c->rbytes);\n    if (!el) {\n        if (c->rbytes > 1024) {\n            /*\n             * We didn't have a '\\n' in the first k. This _has_ to be a\n             * large multiget, if not we should just nuke the connection.\n             */\n            char *ptr = c->rcurr;\n            while (*ptr == ' ') { /* ignore leading whitespaces */\n                ++ptr;\n            }\n\n            if (ptr - c->rcurr > 100 ||\n                (strncmp(ptr, \"get \", 4) && strncmp(ptr, \"gets \", 5))) {\n\n                conn_set_state(c, conn_closing);\n                return 1;\n            }\n\n            // ASCII multigets are unbound, so our fixed size rbuf may not\n            // work for this particular workload... For backcompat we'll use a\n            // malloc/realloc/free routine just for this.\n            if (!c->rbuf_malloced) {\n                if (!rbuf_switch_to_malloc(c)) {\n                    conn_set_state(c, conn_closing);\n                    return 1;\n                }\n            }\n        }\n\n        return 0;\n    }\n    cont = el + 1;\n\n    assert(cont <= (c->rcurr + c->rbytes));\n\n    c->last_cmd_time = current_time;\n    proxy_process_command(c, c->rcurr, cont - c->rcurr, PROCESS_NORMAL);\n\n    c->rbytes -= (cont - c->rcurr);\n    c->rcurr = cont;\n\n    assert(c->rcurr <= (c->rbuf + c->rsize));\n\n    return 1;\n\n}\n\n// Called when a connection is closed while in nread state reading a set\n// Must only be called with an active coroutine.\nvoid proxy_cleanup_conn(conn *c) {\n    assert(c->proxy_coro_ref != 0);\n    LIBEVENT_THREAD *thr = c->thread;\n    lua_State *L = thr->L;\n    luaL_unref(L, LUA_REGISTRYINDEX, c->proxy_coro_ref);\n    c->proxy_coro_ref = 0;\n    WSTAT_DECR(thr, proxy_req_active, 1);\n}\n\n// we buffered a SET of some kind.\nvoid complete_nread_proxy(conn *c) {\n    assert(c != NULL);\n\n    LIBEVENT_THREAD *thr = c->thread;\n    lua_State *L = thr->L;\n\n    if (c->proxy_coro_ref == 0) {\n        complete_nread_ascii(c);\n        return;\n    }\n\n    conn_set_state(c, conn_new_cmd);\n\n    // Grab our coroutine.\n    // Leave the reference alone in case we error out, so the conn cleanup\n    // routine can handle it properly.\n    lua_rawgeti(L, LUA_REGISTRYINDEX, c->proxy_coro_ref);\n    lua_State *Lc = lua_tothread(L, -1);\n    mcp_request_t *rq = luaL_checkudata(Lc, -1, \"mcp.request\");\n\n    // validate the data chunk.\n    if (strncmp((char *)c->item + rq->pr.vlen - 2, \"\\r\\n\", 2) != 0) {\n        lua_settop(L, 0); // clear anything remaining on the main thread.\n        // FIXME (v2): need to set noreply false if mset_res, but that's kind\n        // of a weird hack to begin with. Evaluate how to best do that here.\n        out_string(c, \"CLIENT_ERROR bad data chunk\");\n        return;\n    }\n\n    // We move ownership of the c->item buffer from the connection to the\n    // request object here. Else we can double free if the conn closes while\n    // inside nread.\n    rq->pr.vbuf = c->item;\n    c->item = NULL;\n    c->item_malloced = false;\n    luaL_unref(L, LUA_REGISTRYINDEX, c->proxy_coro_ref);\n    c->proxy_coro_ref = 0;\n    pthread_mutex_lock(&thr->proxy_limit_lock);\n    thr->proxy_buffer_memory_used += rq->pr.vlen;\n    pthread_mutex_unlock(&thr->proxy_limit_lock);\n\n    proxy_run_coroutine(Lc, c->resp, NULL, c);\n\n    lua_settop(L, 0); // clear anything remaining on the main thread.\n\n    return;\n}\n\n// Simple error wrapper for common failures.\n// lua_error() is a jump so this function never returns\n// for clarity add a 'return' after calls to this.\nvoid proxy_lua_error(lua_State *L, const char *s) {\n    lua_pushstring(L, s);\n    lua_error(L);\n}\n\nvoid proxy_lua_ferror(lua_State *L, const char *fmt, ...) {\n    va_list ap;\n    va_start(ap, fmt);\n    lua_pushfstring(L, fmt, ap);\n    va_end(ap);\n    lua_error(L);\n}\n\n// Need a custom function so we can prefix lua strings easily.\nvoid proxy_out_errstring(mc_resp *resp, char *type, const char *str) {\n    size_t len;\n    size_t prefix_len = strlen(type);\n\n    assert(resp != NULL);\n\n    resp_reset(resp);\n    // avoid noreply since we're throwing important errors.\n\n    // Fill response object with static string.\n    len = strlen(str);\n    if ((len + prefix_len + 2) > WRITE_BUFFER_SIZE) {\n        /* ought to be always enough. just fail for simplicity */\n        str = \"SERVER_ERROR output line too long\";\n        len = strlen(str);\n    }\n\n    char *w = resp->wbuf;\n    memcpy(w, type, prefix_len);\n    w += prefix_len;\n\n    memcpy(w, str, len);\n    w += len;\n\n    memcpy(w, \"\\r\\n\", 2);\n    resp_add_iov(resp, resp->wbuf, len + prefix_len + 2);\n    return;\n}\n\n// NOTE: See notes in mcp_queue_io; the secondary problem with setting the\n// noreply mode from the response object is that the proxy can return strings\n// manually, so we have no way to obey what the original request wanted in\n// that case.\nstatic void _set_noreply_mode(mc_resp *resp, mcp_resp_t *r) {\n    switch (r->mode) {\n        case RESP_MODE_NORMAL:\n            break;\n        case RESP_MODE_NOREPLY:\n            // ascii noreply only threw egregious errors to client\n            if (r->status == MCMC_OK) {\n                resp->skip = true;\n            }\n            break;\n        case RESP_MODE_METAQUIET:\n            if (r->resp.code == MCMC_CODE_END) {\n                resp->skip = true;\n            } else if (r->cmd != CMD_MG && r->resp.code == MCMC_CODE_OK) {\n                // FIXME (v2): mcmc's parser needs to help us out a bit more\n                // here.\n                // This is a broken case in the protocol though; quiet mode\n                // ignores HD for mutations but not get.\n                resp->skip = true;\n            }\n            break;\n        default:\n            assert(1 == 0);\n    }\n}\n\n// this resumes every yielded coroutine (and re-resumes if necessary).\n// called from the worker thread after responses have been pulled from the\n// network.\n// Flow:\n// - the response object should already be on the coroutine stack.\n// - fix up the stack.\n// - run coroutine.\n// - if LUA_YIELD, we need to swap out the pending IO from its mc_resp then call for a queue\n// again.\n// - if LUA_OK finalize the response and return\n// - else set error into mc_resp.\nint proxy_run_coroutine(lua_State *Lc, mc_resp *resp, io_pending_proxy_t *p, conn *c) {\n    int nresults = 0;\n    int cores = lua_resume(Lc, NULL, 1, &nresults);\n    size_t rlen = 0;\n\n    if (cores == LUA_OK) {\n        WSTAT_DECR(c->thread, proxy_req_active, 1);\n        int type = lua_type(Lc, 1);\n        P_DEBUG(\"%s: coroutine completed. return type: %d\\n\", __func__, type);\n        if (type == LUA_TUSERDATA) {\n            mcp_resp_t *r = luaL_checkudata(Lc, 1, \"mcp.response\");\n            _set_noreply_mode(resp, r);\n            if (r->status != MCMC_OK && r->resp.type != MCMC_RESP_ERRMSG) {\n                proxy_out_errstring(resp, PROXY_SERVER_ERROR, \"backend failure\");\n            } else if (r->cresp) {\n                mc_resp *tresp = r->cresp;\n                // The internal cache handler has created a resp we want to swap in\n                // here. It would be fastest to swap *resp's position in the\n                // link but if the set is deep this would instead be slow, so\n                // we copy over details from this temporary resp instead.\n                assert(c != NULL);\n\n                // So far all we fill is the wbuf and some iov's? so just copy\n                // that + the UDP info?\n                memcpy(resp->wbuf, tresp->wbuf, tresp->iov[0].iov_len);\n                for (int x = 0; x < tresp->iovcnt; x++) {\n                    resp->iov[x] = tresp->iov[x];\n                }\n                // resp->iov[x].iov_base needs to be updated if it's\n                // pointing within its wbuf.\n                // FIXME: This is too fragile. we need to be able to\n                // inherit details and swap resp objects around.\n                if (tresp->iov[0].iov_base == tresp->wbuf) {\n                    resp->iov[0].iov_base = resp->wbuf;\n                }\n                resp->iovcnt = tresp->iovcnt;\n                resp->chunked_total = tresp->chunked_total;\n                resp->chunked_data_iov = tresp->chunked_data_iov;\n                // copy UDP headers...\n                resp->request_id = tresp->request_id;\n                resp->udp_sequence = tresp->udp_sequence;\n                resp->udp_total = tresp->udp_total;\n                resp->request_addr = tresp->request_addr;\n                resp->request_addr_size = tresp->request_addr_size;\n                resp->item = tresp->item; // will be populated if not extstore fetch\n                resp->skip = tresp->skip;\n\n                // we let the mcp_resp gc handler free up tresp and any\n                // associated io_pending's of its own later.\n            } else if (r->buf) {\n                // response set from C.\n                resp->write_and_free = r->buf;\n                resp_add_iov(resp, r->buf, r->blen);\n                r->buf = NULL;\n            } else if (lua_getiuservalue(Lc, 1, 1) != LUA_TNIL) {\n                // uservalue slot 1 is pre-created, so we get TNIL instead of\n                // TNONE when nothing was set into it.\n                const char *s = lua_tolstring(Lc, -1, &rlen);\n                size_t l = rlen > WRITE_BUFFER_SIZE ? WRITE_BUFFER_SIZE : rlen;\n                memcpy(resp->wbuf, s, l);\n                resp_add_iov(resp, resp->wbuf, l);\n                lua_pop(Lc, 1);\n            } else {\n                // Empty response: used for ascii multiget emulation.\n            }\n\n        } else if (type == LUA_TSTRING) {\n            // response is a raw string from lua.\n            const char *s = lua_tolstring(Lc, 1, &rlen);\n            size_t l = rlen > WRITE_BUFFER_SIZE ? WRITE_BUFFER_SIZE : rlen;\n            memcpy(resp->wbuf, s, l);\n            resp_add_iov(resp, resp->wbuf, l);\n            lua_pop(Lc, 1);\n        } else {\n            proxy_out_errstring(resp, PROXY_SERVER_ERROR, \"bad response\");\n        }\n\n    } else if (cores == LUA_YIELD) {\n        int coro_ref = 0;\n        int yield_type = lua_tointeger(Lc, -1);\n        P_DEBUG(\"%s: coroutine yielded. return type: %d\\n\", __func__, yield_type);\n        assert(yield_type != 0);\n        lua_pop(Lc, 1);\n\n        // need to remove and free the io_pending, since c->resp owns it.\n        // so we call mcp_queue_io() again and let it override the\n        // mc_resp's io_pending object.\n        //\n        // p is not null only when being called from proxy_return_cb(),\n        // a pending IO is returning to resume.\n        if (p != NULL) {\n            coro_ref = p->coro_ref;\n            assert((void *)p == (void *)resp->io_pending);\n            resp->io_pending = NULL;\n            c = p->c;\n            // *p is now dead.\n            do_cache_free(c->thread->io_cache, p);\n        } else {\n            // coroutine object sitting on the _main_ VM right now, so we grab\n            // the reference from there, which also pops it.\n            assert(c != NULL);\n            coro_ref = luaL_ref(c->thread->L, LUA_REGISTRYINDEX);\n        }\n\n        int res = 0;\n        switch (yield_type) {\n            case MCP_YIELD_AWAIT:\n                mcplib_await_run(c, resp, Lc, coro_ref);\n                break;\n            case MCP_YIELD_POOL:\n                // TODO (v2): c only used for cache alloc?\n                mcp_queue_io(c, resp, coro_ref, Lc);\n                break;\n            case MCP_YIELD_LOCAL:\n                // stack should be: rq, res\n                res = mcplib_internal_run(Lc, c, resp, coro_ref);\n                if (res == 0) {\n                    // stack should still be: rq, res\n                    // TODO: turn this function into a for loop that re-runs on\n                    // certain status codes, to avoid recursive depth here.\n                    //\n                    // FIXME: this dance with the coroutine reference is\n                    // annoying. In this case we immediately resume, so no *io\n                    // was generated, so we won't do the above coro_ref swap, so\n                    // we'll try to take the coro_ref again and fail.\n                    // The ref is only actually used in proxy_await\n                    // It should instead be stashed on the top mc_resp object\n                    // (ideally removing c->proxy_coro_ref at the same time)\n                    // and unref'ed when the resp is cleaned up.\n                    lua_rawgeti(c->thread->L, LUA_REGISTRYINDEX, coro_ref);\n                    luaL_unref(c->thread->L, LUA_REGISTRYINDEX, coro_ref);\n                    proxy_run_coroutine(Lc, resp, NULL, c);\n                } else if (res > 0) {\n                    // internal run queued for extstore.\n                } else {\n                    assert(res < 0);\n                    proxy_out_errstring(resp, PROXY_SERVER_ERROR, \"bad request\");\n                }\n                break;\n            default:\n                abort();\n        }\n\n    } else {\n        WSTAT_DECR(c->thread, proxy_req_active, 1);\n        P_DEBUG(\"%s: Failed to run coroutine: %s\\n\", __func__, lua_tostring(Lc, -1));\n        LOGGER_LOG(NULL, LOG_PROXYEVENTS, LOGGER_PROXY_ERROR, NULL, lua_tostring(Lc, -1));\n        proxy_out_errstring(resp, PROXY_SERVER_ERROR, \"lua failure\");\n    }\n\n    return 0;\n}\n\n// basically any data before the first key.\n// max is like 15ish plus spaces. we can be more strict about how many spaces\n// to expect because any client spamming space is being deliberately stupid\n// anyway.\n#define MAX_CMD_PREFIX 20\n\nstatic void proxy_process_command(conn *c, char *command, size_t cmdlen, bool multiget) {\n    assert(c != NULL);\n    LIBEVENT_THREAD *thr = c->thread;\n    struct proxy_hook *hooks = thr->proxy_hooks;\n    lua_State *L = thr->L;\n    proxy_ctx_t *ctx = thr->proxy_ctx;\n    mcp_parser_t pr = {0};\n\n    // Avoid doing resp_start() here, instead do it a bit later or as-needed.\n    // This allows us to hop over to the internal text protocol parser, which\n    // also calls resp_start().\n    // Tighter integration later should obviate the need for this, it is not a\n    // permanent solution.\n    int ret = process_request(&pr, command, cmdlen);\n    if (ret != 0) {\n        WSTAT_INCR(c->thread, proxy_conn_errors, 1);\n        if (!resp_start(c)) {\n            conn_set_state(c, conn_closing);\n            return;\n        }\n        proxy_out_errstring(c->resp, PROXY_CLIENT_ERROR, \"parsing request\");\n        if (ret == -2) {\n            // Kill connection on more critical parse failure.\n            conn_set_state(c, conn_closing);\n        }\n        return;\n    }\n\n    struct proxy_hook *hook = &hooks[pr.command];\n    int hook_ref = hook->lua_ref;\n    // if client came from a tagged listener, scan for a more specific hook.\n    // TODO: (v2) avoiding a hash table lookup here, but maybe some other\n    // datastructure would suffice. for 4-8 tags this is perfectly fast.\n    if (c->tag && hook->tagged) {\n        struct proxy_hook_tagged *pht = hook->tagged;\n        while (pht->lua_ref) {\n            if (c->tag == pht->tag) {\n                hook_ref = pht->lua_ref;\n                break;\n            }\n            pht++;\n        }\n    }\n\n    if (!hook_ref) {\n        // need to pass our command string into the internal handler.\n        // to minimize the code change, this means allowing it to tokenize the\n        // full command. The proxy's indirect parser should be built out to\n        // become common code for both proxy and ascii handlers.\n        // For now this means we have to null-terminate the command string,\n        // then call into text protocol handler.\n        // FIXME (v2): use a ptr or something; don't like this code.\n        if (cmdlen > 1 && command[cmdlen-2] == '\\r') {\n            command[cmdlen-2] = '\\0';\n        } else {\n            command[cmdlen-1] = '\\0';\n        }\n        // lets nread_proxy know we're in ascii mode.\n        c->proxy_coro_ref = 0;\n        process_command_ascii(c, command);\n        return;\n    }\n\n    // If ascii multiget, we turn this into a self-calling loop :(\n    // create new request with next key, call this func again, then advance\n    // original string.\n    // might be better to split this function; the below bits turn into a\n    // function call, then we don't re-process the above bits in the same way?\n    // The way this is detected/passed on is very fragile.\n    if (!multiget && pr.cmd_type == CMD_TYPE_GET && pr.has_space) {\n        uint32_t keyoff = pr.tokens[pr.keytoken];\n        while (pr.klen != 0) {\n            char temp[KEY_MAX_LENGTH + MAX_CMD_PREFIX + 30];\n            char *cur = temp;\n            // Core daemon can abort the entire command if one key is bad, but\n            // we cannot from the proxy. Instead we have to inject errors into\n            // the stream. This should, thankfully, be rare at least.\n            if (pr.tokens[pr.keytoken] > MAX_CMD_PREFIX) {\n                if (!resp_start(c)) {\n                    conn_set_state(c, conn_closing);\n                    return;\n                }\n                proxy_out_errstring(c->resp, PROXY_CLIENT_ERROR, \"malformed request\");\n            } else if (pr.klen > KEY_MAX_LENGTH) {\n                if (!resp_start(c)) {\n                    conn_set_state(c, conn_closing);\n                    return;\n                }\n                proxy_out_errstring(c->resp, PROXY_CLIENT_ERROR, \"key too long\");\n            } else {\n                // copy original request up until the original key token.\n                memcpy(cur, pr.request, pr.tokens[pr.keytoken]);\n                cur += pr.tokens[pr.keytoken];\n\n                // now copy in our \"current\" key.\n                memcpy(cur, &pr.request[keyoff], pr.klen);\n                cur += pr.klen;\n\n                memcpy(cur, \"\\r\\n\", 2);\n                cur += 2;\n\n                *cur = '\\0';\n                P_DEBUG(\"%s: new multiget sub request: %s [%u/%u]\\n\", __func__, temp, keyoff, pr.klen);\n                proxy_process_command(c, temp, cur - temp, PROCESS_MULTIGET);\n            }\n\n            // now advance to the next key.\n            keyoff = _process_request_next_key(&pr);\n        }\n\n        if (!resp_start(c)) {\n            conn_set_state(c, conn_closing);\n            return;\n        }\n\n        // The above recursions should have created c->resp's in dispatch\n        // order.\n        // So now we add another one at the end to create the capping END\n        // string.\n        memcpy(c->resp->wbuf, ENDSTR, ENDLEN);\n        resp_add_iov(c->resp, c->resp->wbuf, ENDLEN);\n\n        return;\n    }\n\n    // We test the command length all the way down here because multigets can\n    // be very long, and they're chopped up by now.\n    if (cmdlen >= MCP_REQUEST_MAXLEN) {\n        WSTAT_INCR(c->thread, proxy_conn_errors, 1);\n        if (!resp_start(c)) {\n            conn_set_state(c, conn_closing);\n            return;\n        }\n        proxy_out_errstring(c->resp, PROXY_CLIENT_ERROR, \"request too long\");\n        conn_set_state(c, conn_closing);\n        return;\n    }\n\n    if (!resp_start(c)) {\n        conn_set_state(c, conn_closing);\n        return;\n    }\n\n    // Count requests handled by proxy vs local.\n    // Also batch the counts down this far so we can lock once for the active\n    // counter instead of twice.\n    struct proxy_int_stats *istats = c->thread->proxy_int_stats;\n    uint64_t active_reqs = 0;\n    WSTAT_L(c->thread);\n    istats->counters[pr.command]++;\n    c->thread->stats.proxy_conn_requests++;\n    c->thread->stats.proxy_req_active++;\n    active_reqs = c->thread->stats.proxy_req_active;\n    WSTAT_UL(c->thread);\n\n    if (active_reqs > ctx->active_req_limit) {\n        proxy_out_errstring(c->resp, PROXY_SERVER_ERROR, \"active request limit reached\");\n        WSTAT_DECR(c->thread, proxy_req_active, 1);\n        if (pr.vlen != 0) {\n            c->sbytes = pr.vlen;\n            conn_set_state(c, conn_swallow);\n        }\n        return;\n    }\n\n    // start a coroutine.\n    // TODO (v2): This can pull a thread from a cache.\n    lua_newthread(L);\n    lua_State *Lc = lua_tothread(L, -1);\n    // leave the thread first on the stack, so we can reference it if needed.\n    // pull the lua hook function onto the stack.\n    lua_rawgeti(Lc, LUA_REGISTRYINDEX, hook_ref);\n\n    mcp_request_t *rq = mcp_new_request(Lc, &pr, command, cmdlen);\n    rq->ascii_multiget = multiget;\n    // NOTE: option 1) copy c->tag into rq->tag here.\n    // add req:listen_tag() to retrieve in top level route.\n\n    // TODO (v2): lift this to a post-processor?\n    if (rq->pr.vlen != 0) {\n        c->item = NULL;\n        // Need to add the used memory later due to needing an extra callback\n        // handler on error during nread.\n        bool oom = proxy_bufmem_checkadd(c->thread, 0);\n\n        // relying on temporary malloc's not having fragmentation\n        if (!oom) {\n            c->item = malloc(rq->pr.vlen);\n        }\n        if (c->item == NULL) {\n            lua_settop(L, 0);\n            proxy_out_errstring(c->resp, PROXY_SERVER_ERROR, \"out of memory\");\n            WSTAT_DECR(c->thread, proxy_req_active, 1);\n            c->sbytes = rq->pr.vlen;\n            conn_set_state(c, conn_swallow);\n            return;\n        }\n        c->item_malloced = true;\n        c->ritem = c->item;\n        c->rlbytes = rq->pr.vlen;\n        c->proxy_coro_ref = luaL_ref(L, LUA_REGISTRYINDEX); // pops coroutine.\n\n        conn_set_state(c, conn_nread);\n        return;\n    } else {\n        conn_set_state(c, conn_new_cmd);\n    }\n\n    proxy_run_coroutine(Lc, c->resp, NULL, c);\n\n    lua_settop(L, 0); // clear anything remaining on the main thread.\n}\n\n// analogue for storage_get_item(); add a deferred IO object to the current\n// connection's response object. stack enough information to write to the\n// server on the submit callback, and enough to resume the lua state on the\n// completion callback.\nstatic void mcp_queue_io(conn *c, mc_resp *resp, int coro_ref, lua_State *Lc) {\n    io_queue_t *q = conn_io_queue_get(c, IO_QUEUE_PROXY);\n\n    // stack: request, hash selector. latter just to hold a reference.\n\n    mcp_request_t *rq = luaL_checkudata(Lc, -1, \"mcp.request\");\n    mcp_backend_t *be = rq->be;\n\n    // Then we push a response object, which we'll re-use later.\n    // reserve one uservalue for a lua-supplied response.\n    mcp_resp_t *r = lua_newuserdatauv(Lc, sizeof(mcp_resp_t), 1);\n    // FIXME (v2): is this memset still necessary? I was using it for\n    // debugging.\n    memset(r, 0, sizeof(mcp_resp_t));\n    r->buf = NULL;\n    r->blen = 0;\n    r->thread = c->thread;\n    assert(r->thread != NULL);\n    gettimeofday(&r->start, NULL);\n    // Set noreply mode.\n    // TODO (v2): the response \"inherits\" the request's noreply mode, which isn't\n    // strictly correct; we should inherit based on the request that spawned\n    // the coroutine but the structure doesn't allow that yet.\n    // Should also be able to settle this exact mode from the parser so we\n    // don't have to re-branch here.\n    if (rq->pr.noreply) {\n        if (rq->pr.cmd_type == CMD_TYPE_META) {\n            r->mode = RESP_MODE_METAQUIET;\n            for (int x = 2; x < rq->pr.ntokens; x++) {\n                if (rq->request[rq->pr.tokens[x]] == 'q') {\n                    rq->request[rq->pr.tokens[x]] = ' ';\n                }\n            }\n        } else {\n            r->mode = RESP_MODE_NOREPLY;\n            rq->request[rq->pr.reqlen - 3] = 'Y';\n        }\n    } else {\n        r->mode = RESP_MODE_NORMAL;\n    }\n\n    r->cmd = rq->pr.command;\n\n    luaL_getmetatable(Lc, \"mcp.response\");\n    lua_setmetatable(Lc, -2);\n\n    io_pending_proxy_t *p = do_cache_alloc(c->thread->io_cache);\n    if (p == NULL) {\n        WSTAT_INCR(c->thread, proxy_conn_oom, 1);\n        proxy_lua_error(Lc, \"out of memory allocating from IO cache\");\n        return;\n    }\n\n    // this is a re-cast structure, so assert that we never outsize it.\n    assert(sizeof(io_pending_t) >= sizeof(io_pending_proxy_t));\n    memset(p, 0, sizeof(io_pending_proxy_t));\n    // set up back references.\n    p->io_queue_type = IO_QUEUE_PROXY;\n    p->thread = c->thread;\n    p->c = c;\n    p->resp = resp;\n    p->client_resp = r;\n    p->flushed = false;\n    p->ascii_multiget = rq->ascii_multiget;\n    p->return_cb = proxy_return_cb;\n    p->finalize_cb = proxy_finalize_cb;\n    resp->io_pending = (io_pending_t *)p;\n\n    // top of the main thread should be our coroutine.\n    // lets grab a reference to it and pop so it doesn't get gc'ed.\n    p->coro_ref = coro_ref;\n\n    // we'll drop the pointer to the coro on here to save some CPU\n    // on re-fetching it later. The pointer shouldn't change.\n    p->coro = Lc;\n\n    // The direct backend object. Lc is holding the reference in the stack\n    p->backend = be;\n    // See #887 for notes.\n    // TODO (v2): hopefully this can be optimized out.\n    strncpy(r->be_name, be->name, MAX_NAMELEN+1);\n    strncpy(r->be_port, be->port, MAX_PORTLEN+1);\n\n    mcp_request_attach(Lc, rq, p);\n\n    // link into the batch chain.\n    p->next = q->stack_ctx;\n    q->stack_ctx = p;\n\n    return;\n}\n\n// Common lua debug command.\n__attribute__((unused)) void dump_stack(lua_State *L) {\n    int top = lua_gettop(L);\n    int i = 1;\n    fprintf(stderr, \"--TOP OF STACK [%d]\\n\", top);\n    for (; i < top + 1; i++) {\n        int type = lua_type(L, i);\n        // lets find the metatable of this userdata to identify it.\n        if (lua_getmetatable(L, i) != 0) {\n            lua_pushstring(L, \"__name\");\n            if (lua_rawget(L, -2) != LUA_TNIL) {\n                fprintf(stderr, \"--|%d| [%s] (%s)\\n\", i, lua_typename(L, type), lua_tostring(L, -1));\n                lua_pop(L, 2);\n                continue;\n            }\n            lua_pop(L, 2);\n        }\n        if (type == LUA_TSTRING) {\n            fprintf(stderr, \"--|%d| [%s] | %s\\n\", i, lua_typename(L, type), lua_tostring(L, i));\n        } else {\n            fprintf(stderr, \"--|%d| [%s]\\n\", i, lua_typename(L, type));\n        }\n    }\n    fprintf(stderr, \"-----------------\\n\");\n}\n\n\n", "#!/usr/bin/env perl\n\nuse strict;\nuse warnings;\nuse Test::More;\nuse FindBin qw($Bin);\nuse lib \"$Bin/lib\";\nuse Carp qw(croak);\nuse MemcachedTest;\nuse IO::Socket qw(AF_INET SOCK_STREAM);\nuse IO::Select;\n\nif (!supports_proxy()) {\n    plan skip_all => 'proxy not enabled';\n    exit 0;\n}\n\n# Set up some server sockets.\nsub mock_server {\n    my $port = shift;\n    my $srv = IO::Socket->new(\n        Domain => AF_INET,\n        Type => SOCK_STREAM,\n        Proto => 'tcp',\n        LocalHost => '127.0.0.1',\n        LocalPort => $port,\n        ReusePort => 1,\n        Listen => 5) || die \"IO::Socket: $@\";\n    return $srv;\n}\n\n# Accept and validate a new backend connection.\nsub accept_backend {\n    my $srv = shift;\n    my $be = $srv->accept();\n    $be->autoflush(1);\n    ok(defined $be, \"mock backend created\");\n    like(<$be>, qr/version/, \"received version command\");\n    print $be \"VERSION 1.0.0-mock\\r\\n\";\n\n    return $be;\n}\n\nnote(\"Initialization:\" . __LINE__);\n\nmy @mocksrvs = ();\n#diag \"making mock servers\";\nfor my $port (11411, 11412, 11413) {\n    my $srv = mock_server($port);\n    ok(defined $srv, \"mock server created\");\n    push(@mocksrvs, $srv);\n}\n\nmy $p_srv = new_memcached('-o proxy_config=./t/proxyunits.lua');\nmy $ps = $p_srv->sock;\n$ps->autoflush(1);\n\nmy $pss = IO::Select->new();\n$pss->add($ps);\n\n# set up server backend sockets.\nmy @mbe = ();\n#diag \"accepting mock backends\";\nfor my $msrv (@mocksrvs) {\n    my $be = accept_backend($msrv);\n    push(@mbe, $be);\n}\n\n# Put a version command down the pipe to ensure the socket is clear.\n# client version commands skip the proxy code\nsub check_version {\n    my $ps = shift;\n    print $ps \"version\\r\\n\";\n    like(<$ps>, qr/VERSION /, \"version received\");\n}\n\n# Send a touch command to all backends, and verify response.\n# This makes sure socket buffers are clean between tests.\nsub check_sanity {\n    my $ps = shift;\n    my $cmd = \"touch /sanity/a 50\\r\\n\";\n    print $ps $cmd;\n    foreach my $idx (keys @mbe) {\n        my $be = $mbe[$idx];\n        is(scalar <$be>, $cmd, \"sanity check: touch cmd received for be \" . $idx);\n        print $be \"TOUCHED\\r\\n\";\n    }\n    is(scalar <$ps>, \"TOUCHED\\r\\n\", \"sanity check: TOUCHED response received.\");\n}\n\n# $ps_send : request to proxy\n# $be_recv : ref to a hashmap from be index to an array of received requests for validation.\n# $be_send : ref to a hashmap from be index to an array of responses to proxy.\n# $ps_recv : ref to response returned by proxy\n# backends in $be_recv and $be_send are vistied by looping through the @mbe.\nsub proxy_test {\n    my %args = @_;\n\n    my $ps_send = $args{ps_send};\n    my $be_recv = $args{be_recv} // {};\n    my $be_send = $args{be_send} // {};\n    my $ps_recv = $args{ps_recv};\n\n    # sends request to proxy\n    if ($ps_send) {\n        print $ps $ps_send;\n    }\n\n    # verify all backends received request\n    foreach my $idx (keys @mbe) {\n        if (exists $be_recv->{$idx}) {\n            my $be = $mbe[$idx];\n            foreach my $recv (@{$be_recv->{$idx}}) {\n                is(scalar <$be>, $recv, \"be \" . $idx . \" received expected response\");\n            }\n        }\n    }\n\n    # backends send responses\n    foreach my $idx (keys @mbe) {\n        if (exists $be_send->{$idx}) {\n            my $be = $mbe[$idx];\n            foreach my $send (@{$be_send->{$idx}}) {\n                print $be $send;\n            }\n        }\n    }\n\n    if (defined $ps_recv) {\n        if (scalar @{$ps_recv}) {\n            foreach my $recv (@{$ps_recv}) {\n                is(scalar <$ps>, $recv, \"ps returned expected response.\");\n            }\n            # makes sure nothing remains in $ps.\n            check_version($ps);\n        } else {\n            # when $ps_recv is empty, make sure it is not readable.\n            my @readable = $pss->can_read(0.1);\n            is(scalar @readable, 0, \"ps is expected to be non-readable\");\n        }\n    }\n}\n\n{\n    note(\"Bad syntax tests\");\n    # Write a request with bad syntax, and check the response.\n    print $ps \"set with the wrong number of tokens\\n\";\n    is(scalar <$ps>, \"CLIENT_ERROR parsing request\\r\\n\", \"got CLIENT_ERROR for bad syntax\");\n\n    for ('get', 'incr', 'decr', 'touch', 'gat', 'gats', 'mg', 'md', 'ma', 'ms') {\n        print $ps \"$_\\r\\n\";\n        is(scalar <$ps>, \"CLIENT_ERROR parsing request\\r\\n\", \"$_ got CLIENT_ERROR for too few tokens\");\n    }\n\n    my $space = ' ' x 200;\n    print $ps \"get$space key key\\r\\n\";\n    is(scalar <$ps>, \"CLIENT_ERROR malformed request\\r\\n\");\n    is(scalar <$ps>, \"CLIENT_ERROR malformed request\\r\\n\");\n    is(scalar <$ps>, \"END\\r\\n\"); # god damn multiget syntax.\n}\n\n# Basic test with a backend; write a request to the client socket, read it\n# from a backend socket, and write a response to the backend socket.\n#\n# The array @mbe holds references to our sockets for the backends listening on\n# the above mocked servers. In most tests we're only routing to the first\n# backend in the list ($mbe[0])\n#\n# In this case the client will receive an error and the backend gets closed,\n# so we have to re-establish it.\n{\n    note(\"Test missing END:\" . __LINE__);\n\n    # Test a fix for passing through partial read data if END ends up missing.\n    my $be = $mbe[0];\n    my $w = $p_srv->new_sock;\n    print $w \"watch proxyevents\\n\";\n    is(<$w>, \"OK\\r\\n\", \"watcher enabled\");\n\n    # write a request to proxy.\n    print $ps \"get /b/a\\r\\n\";\n\n    # verify request is received by backend.\n    is(scalar <$be>, \"get /b/a\\r\\n\", \"get passthrough\");\n\n    # write a response with partial data.\n    print $be \"VALUE /b/a 0 2\\r\\nhi\\r\\nEN\";\n\n    # verify the error response from proxy\n    is(scalar <$ps>, \"SERVER_ERROR backend failure\\r\\n\", \"backend failure error\");\n\n    # verify a particular proxy event logline is received\n    like(<$w>, qr/ts=(\\S+) gid=\\d+ type=proxy_backend error=timeout name=127.0.0.1 port=\\d+ depth=1 rbuf=EN/, \"got backend error log line\");\n\n    # backend is disconnected due to the error, so we have to re-establish it.\n    $mbe[0] = accept_backend($mocksrvs[0]);\n}\n\n# This test is similar to the above one, except we also establish a watcher to\n# check for appropriate log entries.\n{\n    note(\"Test trailingdata:\" . __LINE__);\n\n    # Test a log line with detailed data from backend failures.\n    my $be = $mbe[0];\n    my $w = $p_srv->new_sock;\n    print $w \"watch proxyevents\\n\";\n    is(<$w>, \"OK\\r\\n\", \"watcher enabled\");\n\n    print $ps \"get /b/c\\r\\n\";\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"get passthrough\");\n    # Set off a \"trailing data\" error\n    print $be \"VALUE /b/c 0 2\\r\\nok\\r\\nEND\\r\\ngarbage\";\n\n    is(scalar <$ps>, \"VALUE /b/c 0 2\\r\\n\", \"got value back\");\n    is(scalar <$ps>, \"ok\\r\\n\", \"got data back\");\n    is(scalar <$ps>, \"END\\r\\n\", \"got end string\");\n\n    like(<$w>, qr/ts=(\\S+) gid=\\d+ type=proxy_backend error=trailingdata name=127.0.0.1 port=\\d+ depth=0 rbuf=garbage/, \"got backend error log line\");\n\n    $mbe[0] = accept_backend($mocksrvs[0]);\n}\n\nnote(\"Test bugfix for missingend:\" . __LINE__);\n\n# This is an example of a test which will only pass before a bugfix is issued.\n# It's good practice where possible to write a failing test, then check it\n# against a code fix. We then leave the test in the file for reference.\n# Though noting when it was fixed is probably better than what I did here :)\nSKIP: {\n    skip \"Remove this skip line to demonstrate pre-patch bug\", 1;\n    # Test issue with finding response complete when read lands between value\n    # size and value + response line in size.\n    my $be = $mbe[0];\n    my $w = $p_srv->new_sock;\n    print $w \"watch proxyevents\\n\";\n    is(<$w>, \"OK\\r\\n\", \"watcher enabled\");\n\n    print $ps \"get /b/c\\r\\n\";\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"get passthrough\");\n\n    # Set off a \"missingend\" error.\n    # The server will wake up several times, thinking it has read the\n    # full size of response but it only read enough for the value portion.\n    print $be \"VALUE /b/c 0 5\\r\\nhe\";\n    sleep 0.1;\n    print $be \"llo\";\n    sleep 0.1;\n    print $be \"\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"SERVER_ERROR backend failure\\r\\n\");\n\n    like(<$w>, qr/ts=(\\S+) gid=\\d+ type=proxy_backend error=missingend name=127.0.0.1 port=\\d+ depth=1 rbuf=/, \"got missingend error log line\");\n\n    $mbe[0] = accept_backend($mocksrvs[0]);\n}\n\n{\n    # Test issue with finding response complete when read lands between value\n    # size and value + response line in size.\n    my $be = $mbe[0];\n\n    print $ps \"get /b/c\\r\\n\";\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"get passthrough\");\n\n    # Set off a \"missingend\" error.\n    # The server will wake up several times, thinking it has read the\n    # full size of response but it only read enough for the value portion.\n    print $be \"VALUE /b/c 0 5\\r\\nhe\";\n    sleep 0.1;\n    print $be \"llo\";\n    sleep 0.1;\n    print $be \"\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/c 0 5\\r\\n\", \"got value back\");\n    is(scalar <$ps>, \"hello\\r\\n\", \"got data back\");\n    is(scalar <$ps>, \"END\\r\\n\", \"got end string\");\n}\n\n#diag \"ready for main tests\";\n# Target a single backend, validating basic syntax.\n# Should test all command types.\n# uses /b/ path for \"basic\"\n{\n    note(\"Test all commands to a single backend:\" . __LINE__);\n\n    # Test invalid route.\n    print $ps \"set /invalid/a 0 0 2\\r\\nhi\\r\\n\";\n    is(scalar <$ps>, \"SERVER_ERROR no set route\\r\\n\");\n\n    # Testing against just one backend. Results should make sense despite our\n    # invalid request above.\n    my $be = $mbe[0];\n    my $cmd;\n\n    # TODO: add more tests for the varying response codes.\n\n    # Basic set.\n    $cmd = \"set /b/a 0 0 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"set passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"set value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from set\");\n\n    # Basic get\n    $cmd = \"get /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"get passthrough\");\n    print $be \"VALUE /b/a 0 2\\r\\nhi\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/a 0 2\\r\\n\", \"get rline\");\n    is(scalar <$ps>, \"hi\\r\\n\", \"get data\");\n    is(scalar <$ps>, \"END\\r\\n\", \"get end\");\n\n    # touch\n    $cmd = \"touch /b/a 50\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"touch passthrough\");\n    print $be \"TOUCHED\\r\\n\";\n\n    is(scalar <$ps>, \"TOUCHED\\r\\n\", \"got touch response\");\n\n    # gets\n    $cmd = \"gets /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"gets passthrough\");\n    print $be \"VALUE /b/a 0 2 2\\r\\nhi\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/a 0 2 2\\r\\n\", \"gets rline\");\n    is(scalar <$ps>, \"hi\\r\\n\", \"gets data\");\n    is(scalar <$ps>, \"END\\r\\n\", \"gets end\");\n\n    # gat\n    $cmd = \"gat 10 /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"gat passthrough\");\n    print $be \"VALUE /b/a 0 2\\r\\nhi\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/a 0 2\\r\\n\", \"gat rline\");\n    is(scalar <$ps>, \"hi\\r\\n\", \"gat data\");\n    is(scalar <$ps>, \"END\\r\\n\", \"gat end\");\n\n    # gats\n    $cmd = \"gats 11 /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"gats passthrough\");\n    print $be \"VALUE /b/a 0 2 1\\r\\nhi\\r\\nEND\\r\\n\";\n\n    is(scalar <$ps>, \"VALUE /b/a 0 2 1\\r\\n\", \"gats rline\");\n    is(scalar <$ps>, \"hi\\r\\n\", \"gats data\");\n    is(scalar <$ps>, \"END\\r\\n\", \"gats end\");\n\n    # cas\n    $cmd = \"cas /b/a 0 0 2 5\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"cas passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"cas value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from cas\");\n\n    # add\n    $cmd = \"add /b/a 0 0 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"add passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"add value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from add\");\n\n    # delete\n    $cmd = \"delete /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"delete passthrough\");\n    print $be \"DELETED\\r\\n\";\n\n    is(scalar <$ps>, \"DELETED\\r\\n\", \"got delete response\");\n\n    # incr\n    $cmd = \"incr /b/a 1\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"incr passthrough\");\n    print $be \"2\\r\\n\";\n\n    is(scalar <$ps>, \"2\\r\\n\", \"got incr response\");\n\n    # decr\n    $cmd = \"decr /b/a 1\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"decr passthrough\");\n    print $be \"10\\r\\n\";\n\n    is(scalar <$ps>, \"10\\r\\n\", \"got decr response\");\n\n    # append\n    $cmd = \"append /b/a 0 0 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"append passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"append value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from append\");\n\n    # prepend\n    $cmd = \"prepend /b/a 0 0 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"prepend passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"prepend value\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got STORED from prepend\");\n\n    # [meta commands]\n    # testing the bare meta commands.\n    # TODO: add more tests for tokens and changing response codes.\n    # mg\n    $cmd = \"mg /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"mg passthrough\");\n    print $be \"HD\\r\\n\";\n\n    is(scalar <$ps>, \"HD\\r\\n\", \"got mg response\");\n    # ms\n    $cmd = \"ms /b/a 2\";\n    print $ps \"$cmd\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"$cmd\\r\\n\", \"ms passthrough\");\n    is(scalar <$be>, \"hi\\r\\n\", \"ms value\");\n    print $be \"HD\\r\\n\";\n\n    is(scalar <$ps>, \"HD\\r\\n\", \"got HD from ms\");\n\n    # md\n    $cmd = \"md /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"md passthrough\");\n    print $be \"HD\\r\\n\";\n\n    is(scalar <$ps>, \"HD\\r\\n\", \"got HD from md\");\n    # ma\n    $cmd = \"ma /b/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"ma passthrough\");\n    print $be \"HD\\r\\n\";\n\n    is(scalar <$ps>, \"HD\\r\\n\", \"got HD from ma\");\n    # mn?\n    # me?\n}\n\n# run a cleanser check between each set of tests.\n# This ensures nothing was left in the client pipeline.\ncheck_sanity($ps);\n\n{\n    note(\"Test multiget:\" . __LINE__);\n\n    # multiget syntax\n    # - gets broken into individual gets on backend\n    my $be = $mbe[0];\n    my $cmd = \"get /b/a /b/b /b/c\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, \"get /b/a\\r\\n\", \"multiget breakdown a\");\n    is(scalar <$be>, \"get /b/b\\r\\n\", \"multiget breakdown b\");\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"multiget breakdown c\");\n\n    print $be \"VALUE /b/a 0 1\\r\\na\\r\\n\",\n              \"END\\r\\n\",\n              \"VALUE /b/b 0 1\\r\\nb\\r\\n\",\n              \"END\\r\\n\",\n              \"VALUE /b/c 0 1\\r\\nc\\r\\n\",\n              \"END\\r\\n\";\n\n    for my $key ('a', 'b', 'c') {\n        is(scalar <$ps>, \"VALUE /b/$key 0 1\\r\\n\", \"multiget res $key\");\n        is(scalar <$ps>, \"$key\\r\\n\", \"multiget value $key\");\n    }\n    is(scalar <$ps>, \"END\\r\\n\", \"final END from multiget\");\n\n    # Test multiget workaround with misses (known bug)\n    print $ps $cmd;\n    is(scalar <$be>, \"get /b/a\\r\\n\", \"multiget breakdown a\");\n    is(scalar <$be>, \"get /b/b\\r\\n\", \"multiget breakdown b\");\n    is(scalar <$be>, \"get /b/c\\r\\n\", \"multiget breakdown c\");\n\n    print $be \"END\\r\\nEND\\r\\nEND\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"final END from multiget\");\n\n    # If bugged, the backend will have closed.\n    print $ps \"get /b/a\\r\\n\";\n    is(scalar <$be>, \"get /b/a\\r\\n\", \"get works after empty multiget\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"end after empty multiget\");\n}\n\ncheck_sanity($ps);\n\n{\n    note(\"Test noreply:\" . __LINE__);\n\n    # noreply tests.\n    # - backend should receive with noreply/q stripped or mangled\n    # - backend should reply as normal\n    # - frontend should get nothing; to test issue another command and ensure\n    # it only gets that response.\n    my $be = $mbe[0];\n    my $cmd = \"set /b/a 0 0 2 noreply\\r\\nhi\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, \"set /b/a 0 0 2 noreplY\\r\\n\", \"set received with broken noreply\");\n    is(scalar <$be>, \"hi\\r\\n\", \"set payload received\");\n\n    print $be \"STORED\\r\\n\";\n\n    # To ensure success, make another req and ensure res isn't STORED\n    $cmd = \"touch /b/a 50\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"canary touch received\");\n    print $be \"TOUCHED\\r\\n\";\n\n    is(scalar <$ps>, \"TOUCHED\\r\\n\", \"got TOUCHED instread of STORED\");\n}\n\ncheck_sanity($ps);\n\n{\n    subtest 'quiet flag: HD response' => sub {\n        # be_recv must receive a response with quiet flag replaced by a space.\n        # ps_recv must not receoved HD response.\n        proxy_test(\n            ps_send => \"ms /b/a 2 q\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /b/a 2  \\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [],\n        );\n    };\n\n    subtest 'quiet flag: EX response' => sub {\n        # be_recv must receive a response with quiet flag replaced by a space.\n        # ps_recv must return EX response from the backend.\n        proxy_test(\n            ps_send => \"ms /b/a 2 q\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /b/a 2  \\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"EX\\r\\n\"]},\n            ps_recv => [\"EX\\r\\n\"],\n        );\n    };\n\n    subtest 'quiet flag: backend failure' => sub {\n        # be_recv must receive a response with quiet flag replaced by a space.\n        # ps_recv must return backend failure response from the backend.\n        proxy_test(\n            ps_send => \"ms /b/a 2 q\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /b/a 2  \\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"garbage\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR backend failure\\r\\n\"],\n        );\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n}\n\ncheck_sanity($ps);\n\n# Test Lua request API\n{\n    note(\"Test Lua request APIs:\" . __LINE__);\n\n    my $be = $mbe[0];\n\n    # fetching the key.\n    print $ps \"get /getkey/testkey\\r\\n\";\n    # look for the key to be slightly different to ensure we hit lua.\n    is(scalar <$ps>, \"VALUE |/getkey/testkey 0 2\\r\\n\", \"request:key()\");\n    is(scalar <$ps>, \"ts\\r\\n\", \"request:key() value\");\n    is(scalar <$ps>, \"END\\r\\n\", \"request:key() END\");\n\n    # rtrimkey\n    # this overwrites part of the key with spaces, which should be skipped by\n    # a valid protocol parser.\n    print $ps \"get /rtrimkey/onehalf\\r\\n\";\n    is(scalar <$be>, \"get /rtrimkey/one    \\r\\n\", \"request:rtrimkey()\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"rtrimkey END\");\n\n    # ltrimkey\n    print $ps \"get /ltrimkey/test\\r\\n\";\n    is(scalar <$be>, \"get           test\\r\\n\", \"request:ltrimkey()\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"ltrimkey END\");\n\n    subtest 'request:ntokens()' => sub {\n        # ps_recv must return value that matches the number of tokens.\n        proxy_test(\n            ps_send => \"mg /ntokens/test c v\\r\\n\",\n            ps_recv => [\"VA 1 C123 v\\r\\n\", \"4\\r\\n\"],\n        );\n    };\n\n    subtest 'request:token() replacement' => sub {\n        # be_recv must received a response with replaced CAS token.\n        proxy_test(\n            ps_send => \"ms /token/replacement 2 C123\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /token/replacement 2 C456\\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"NF\\r\\n\"]},\n            ps_recv => [\"NF\\r\\n\"],\n        );\n    };\n\n    subtest 'request:token() remove' => sub {\n        # be_recv must received a response with CAS token removed.\n        proxy_test(\n            ps_send => \"ms /token/removal 2 C123\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /token/removal 2 \\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"NF\\r\\n\"]},\n            ps_recv => [\"NF\\r\\n\"],\n        );\n    };\n\n    subtest 'request:token() fetch' => sub {\n        # be_recv must received the key token in the P flag.\n        proxy_test(\n            ps_send => \"ms /token/fetch 2 C123 P\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /token/fetch 2 C123 P/token/fetch\\r\\n\", \"hi\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    # # command() integer\n\n    subtest 'request:has_flag() meta positive 1' => sub {\n        # ps_recv must receive HD C123 for a successful hash_flag call.\n        proxy_test(\n            ps_send => \"mg /hasflag/test c\\r\\n\",\n            ps_recv => [\"HD C123\\r\\n\"],\n        );\n    };\n\n    subtest 'request:has_flag() meta positive 2' => sub {\n        # ps_recv must receive HD Oabc for a successful hash_flag call.\n        proxy_test(\n            ps_send => \"mg /hasflag/test Oabc T999\\r\\n\",\n            ps_recv => [\"HD Oabc\\r\\n\"],\n        );\n    };\n\n    subtest 'request:has_flag() meta negative' => sub {\n        # ps_recv must receive NF when has_flag returns false.\n        proxy_test(\n            ps_send => \"mg /hasflag/test T999\\r\\n\",\n            ps_recv => [\"NF\\r\\n\"],\n        );\n    };\n\n    subtest 'request:has_flag() none-meta ' => sub {\n        # ps_recv must receive END for a successful hash_flag call.\n        proxy_test(\n            ps_send => \"get /hasflag/test\\r\\n\",\n            ps_recv => [\"END\\r\\n\"],\n        );\n    };\n\n    subtest 'request:flag_token()' => sub {\n        # be_recv must receive expected flags after a series of flag_token() calls.\n        proxy_test(\n            ps_send => \"mg /flagtoken/a N10 k c R10\\r\\n\",\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n\n    subtest 'request edit' => sub {\n        # be_recv must receive the edited request.\n        proxy_test(\n            ps_send => \"ms /request/edit 2\\r\\nhi\\r\\n\",\n            be_recv => {0 => [\"ms /request/edit 2\\r\\n\", \"ab\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    subtest 'request new' => sub {\n        # be_recv must receive the new request.\n        proxy_test(\n            ps_send => \"mg /request/old\\r\\n\",\n            be_recv => {0 => [\"mg /request/new c\\r\\n\"]},\n            be_send => {0 => [\"HD C123\\r\\n\"]},\n            ps_recv => [\"HD C123\\r\\n\"],\n        );\n    };\n\n    subtest 'request clone response' => sub {\n        # be must receive cloned meta-set from the previous meta-get.\n        my $be = $mbe[0];\n        print $ps \"mg /request/clone v\\r\\n\";\n        is(scalar <$be>, \"mg /request/clone v\\r\\n\", \"get passthrough\");\n        print $be \"VA 1 v\\r\\n4\\r\\n\";\n        is(scalar <$be>, \"ms /request/a 1\\r\\n\", \"received cloned meta-set\");\n        is(scalar <$be>, \"4\\r\\n\", \"received cloned meta-set value\");\n        print $be \"HD\\r\\n\";\n        is(scalar <$ps>, \"HD\\r\\n\", \"received HD\");\n    };\n}\n\ncheck_sanity($ps);\n\n# Test Lua response API\n{\n    subtest 'response:elapsed() >100000micros' => sub {\n        # ps_recv must not receive an error\n        my $be = $mbe[0];\n        my $cmd = \"mg /response/elapsed\\r\\n\";\n        print $ps $cmd;\n        is(scalar <$be>, $cmd, \"be received request.\");\n        sleep 0.1;\n        print $be \"HD\\r\\n\";\n        is(scalar <$ps>, \"HD\\r\\n\", \"proxy received HD\");\n    };\n\n\n    subtest 'response:ok()' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"mg /response/ok\\r\\n\",\n            be_recv => {0 => [\"mg /response/ok\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    subtest 'response:ok() false 1' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_ok\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_ok\\r\\n\"]},\n            be_send => {0 => [\"SERVER_ERROR\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n    };\n\n    subtest 'response:ok() false 2' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_ok\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_ok\\r\\n\"]},\n            be_send => {0 => [\"GARBAGE\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n\n        # test not_ok when backend is disconnected.\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_ok\\r\\n\",\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n\n        $mbe[0] = accept_backend($mocksrvs[0]);\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n\n    subtest 'response:ok() false 3' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_ok\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_ok\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n\n    subtest 'response:hit() mg' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"mg /response/hit\\r\\n\",\n            be_recv => {0 => [\"mg /response/hit\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    subtest 'response:hit() get' => sub {\n        # ps_recv must not receive an error\n        my $key = \"/response/hit\";\n        proxy_test(\n            ps_send => \"get $key\\r\\n\",\n            be_recv => {0 => [\"get $key\\r\\n\"]},\n            be_send => {0 => [\"VALUE $key 0 1\\r\\na\\r\\nEND\\r\\n\"]},\n            ps_recv => [\"VALUE $key 0 1\\r\\n\", \"a\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'response:hit() false 1' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_hit\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_hit\\r\\n\"]},\n            be_send => {0 => [\"EN\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n    };\n\n    subtest 'response:hit() false 2' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"get /response/not_hit\\r\\n\",\n            be_recv => {0 => [\"get /response/not_hit\\r\\n\"]},\n            be_send => {0 => [\"END\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n    };\n\n    subtest 'response:hit() false 3' => sub {\n        # ps_recv must receive an error\n        proxy_test(\n            ps_send => \"mg /response/not_hit\\r\\n\",\n            be_recv => {0 => [\"mg /response/not_hit\\r\\n\"]},\n            be_send => {0 => [\"SERVER_ERROR\\r\\n\"]},\n            ps_recv => [\"SERVER_ERROR\\r\\n\"],\n        );\n    };\n\n    subtest 'response:vlen()' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"mg /response/vlen v\\r\\n\",\n            be_recv => {0 => [\"mg /response/vlen v\\r\\n\"]},\n            be_send => {0 => [\"VA 1 v\\r\\n\", \"4\\r\\n\"]},\n            ps_recv => [\"VA 1 v\\r\\n\", \"4\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_OK' => sub {\n        # ps_recv must not receive an error\n        my $cmd = \"mg /response/code_ok v\\r\\n\";\n        proxy_test(\n            ps_send => $cmd,\n            be_recv => {0 => [$cmd]},\n            be_send => {0 => [\"VA 1 v\\r\\n\", \"4\\r\\n\"]},\n            ps_recv => [\"VA 1 v\\r\\n\", \"4\\r\\n\"],\n        );\n\n        proxy_test(\n            ps_send => \"ms /response/code_ok 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"ms /response/code_ok 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"HD\\r\\n\"]},\n            ps_recv => [\"HD\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_MISS' => sub {\n        # ps_recv must not receive an error\n        my $cmd = \"mg /response/code_miss v\\r\\n\";\n        proxy_test(\n            ps_send => $cmd,\n            be_recv => {0 => [$cmd]},\n            be_send => {0 => [\"EN\\r\\n\"]},\n            ps_recv => [\"EN\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_STORED' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"set /response/code_stored 0 0 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"set /response/code_stored 0 0 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"STORED\\r\\n\"]},\n            ps_recv => [\"STORED\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_EXISTS' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"set /response/code_exists 0 0 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"set /response/code_exists 0 0 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"EXISTS\\r\\n\"]},\n            ps_recv => [\"EXISTS\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_NOT_STORED' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"set /response/code_not_stored 0 0 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"set /response/code_not_stored 0 0 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"NOT_STORED\\r\\n\"]},\n            ps_recv => [\"NOT_STORED\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_NOT_FOUND' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"set /response/code_not_found 0 0 1\\r\\na\\r\\n\",\n            be_recv => {0 => [\"set /response/code_not_found 0 0 1\\r\\n\", \"a\\r\\n\"]},\n            be_send => {0 => [\"NOT_FOUND\\r\\n\"]},\n            ps_recv => [\"NOT_FOUND\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_TOUCHED' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"touch /response/code_touched 50\\r\\n\",\n            be_recv => {0 => [\"touch /response/code_touched 50\\r\\n\"]},\n            be_send => {0 => [\"TOUCHED\\r\\n\"]},\n            ps_recv => [\"TOUCHED\\r\\n\"],\n        );\n    };\n\n    subtest 'response:code() MCMC_CODE_DELETED' => sub {\n        # ps_recv must not receive an error\n        proxy_test(\n            ps_send => \"delete /response/code_deleted\\r\\n\",\n            be_recv => {0 => [\"delete /response/code_deleted\\r\\n\"]},\n            be_send => {0 => [\"DELETED\\r\\n\"]},\n            ps_recv => [\"DELETED\\r\\n\"],\n        );\n    };\n\n    SKIP: {\n        skip \"response:line() is broken\";\n        subtest 'response:line()' => sub {\n            # ps_recv must not receive an error\n            my $cmd = \"mg /response/line v\\r\\n\";\n            proxy_test(\n                ps_send => $cmd,\n                be_recv => {0 => [$cmd]},\n                be_send => {0 => [\"VA 1 v c123\\r\\n\", \"a\\r\\n\"]},\n                ps_recv => [\"VA 1 v c123\\r\\n\", \"a\\r\\n\"],\n            );\n\n            # ps_recv must not receive an error\n            proxy_test(\n                ps_send => \"ms /response/line 2\\r\\nab\\r\\n\",\n                be_recv => {0 => [\"ms /response/line 2\\r\\n\", \"ab\\r\\n\"]},\n                be_send => {0 => [\"HD O123 C123\\r\\n\"]},\n                ps_recv => [\"HD O123 C123\\r\\n\"],\n            );\n        };\n    };\n}\n\n\n# Test requests land in proper backend in basic scenarios\n{\n    note(\"Test routing by zone:\" . __LINE__);\n\n    # TODO: maybe should send values to ensure the right response?\n    # I don't think this test is very useful though; probably better to try\n    # harder when testing error conditions.\n    for my $tu (['a', $mbe[0]], ['b', $mbe[1]], ['c', $mbe[2]]) {\n        my $be = $tu->[1];\n        my $cmd = \"get /zonetest/\" . $tu->[0] . \"\\r\\n\";\n        print $ps $cmd;\n        is(scalar <$be>, $cmd, \"routed proper zone: \" . $tu->[0]);\n        print $be \"END\\r\\n\";\n        is(scalar <$ps>, \"END\\r\\n\", \"end from zone fetch\");\n    }\n    my $cmd = \"get /zonetest/invalid\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$ps>, \"END\\r\\n\", \"END from invalid route\");\n}\n\ncheck_sanity($ps);\n# Test re-requests in lua.\n# - fetch zones.z1() then fetch zones.z2()\n# - return z1 or z2 or netiher\n# - fetch all three zones\n# - hit the same zone multiple times\n\n# Test delayed read (timeout)\n\n# Test Lua logging (see t/watcher.t)\n{\n    note(\"Test Lua logging:\" . __LINE__);\n\n    my $be = $mbe[0];\n    my $watcher = $p_srv->new_sock;\n    print $watcher \"watch proxyuser proxyreqs\\n\";\n    is(<$watcher>, \"OK\\r\\n\", \"watcher enabled\");\n\n    # log(msg)\n    print $ps \"get /logtest/a\\r\\n\";\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_user msg=testing manual log messages/,\n        \"log a manual message\");\n    is(scalar <$ps>, \"END\\r\\n\", \"logtest END\");\n\n    # log_req(r, res)\n    my $cmd = \"get /logreqtest/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"got passthru for log\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"got END from log test\");\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_req elapsed=\\d+ type=105 code=17 status=0 be=127.0.0.1:11411 detail=logreqtest req=get \\/logreqtest\\/a/, \"found request log entry\");\n\n    # test log_req with nil res (should be 0's in places)\n    # log_reqsample()\n}\n\n# Basic proxy stats validation\n\n# Test user stats\n\ncheck_sanity($ps);\n# Test await arguments (may move to own file?)\n# TODO: the results table from mcp.await() contains all of the results so far,\n# regardless of the mode.\n# need some tests that show this.\n{\n    note(\"Test await argument:\" . __LINE__);\n\n    # DEFAULT MODE, i.e. AWAIT_GOOD\n\n    subtest 'await(r, p): send [h, h, h], recv 3 hits' => sub {\n        # be_recv must receive hit from all three backends\n        my $key = \"/awaitbasic/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my @be_send = [\"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\"];\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => @be_send, 1 => @be_send, 2 => @be_send},\n            ps_recv => [\"VALUE $key 0 11\\r\\n\", \"hit hit hit\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'await(r, p, 1): send [h], recv 1 response and 2 reconn' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [\"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\"]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"1:1:1\\r\\n\", \"END\\r\\n\"],\n        );\n        # reconnect due to timeout\n        $mbe[1] = accept_backend($mocksrvs[1]);\n        $mbe[2] = accept_backend($mocksrvs[2]);\n    };\n\n    subtest 'await(r, p, 1): send [h, m, m], recv 1 response' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"1:1:1\\r\\n\", \"END\\r\\n\"],\n        );\n        # send response to not timeout\n        $mbe[1]->send($be_miss);\n        $mbe[2]->send($be_miss);\n    };\n\n    subtest 'await(r, p, 1): send [m, m, h], recv 3 responses' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_miss], 1 => [$be_miss], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"3:3:1\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'await(r, p, 1): sent [m, h, m], recv 2 responses' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_miss], 1 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"2:2:1\\r\\n\", \"END\\r\\n\"],\n        );\n        $mbe[2]->send($be_miss);\n    };\n\n    subtest 'await(r, p, 1): sent [h, h, h], recv 1 response' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_hit], 1 => [$be_hit], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"1:1:1\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'await(r, p, 2): sent [h, h, h], recv 2 responses' => sub {\n        my $key = \"/awaitone/b\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_hit], 1 => [$be_hit], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"2:2:2\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    subtest 'await(r, p, 1): send [e, m, h], recv 3 responses and 1 reconn' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        my $be_error = \"ERROR backend failure\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_error], 1 => [$be_miss], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"3:2:1\\r\\n\", \"END\\r\\n\"],\n        );\n        # reconnect due to ERROR\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n\n    subtest 'await(r, p, 1): send [e, m, e], recv 3 responses and 1 reconn' => sub {\n        my $key = \"/awaitone/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        my $be_error = \"ERROR failure\\r\\n\";\n        my $be_server_error = \"SERVER_ERROR backend failure\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_error], 1 => [$be_miss], 2 => [$be_server_error]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"3:1:0\\r\\n\", \"END\\r\\n\"],\n        );\n        # reconnect due to ERROR\n        $mbe[0] = accept_backend($mocksrvs[0]);\n    };\n\n    subtest 'await(r, p, 1, mcp.AWAIT_GOOD): sent [h, h, h], recv 1 response' => sub {\n        # ps_recv must receive hit when one backend sent good response.\n        my $key = \"/awaitgood/a\";\n        my $ps_send = \"get $key\\r\\n\";\n        my $be_hit = \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n        my $be_miss = \"END\\r\\n\";\n        proxy_test(\n            ps_send => $ps_send,\n            be_recv => {0 => [$ps_send], 1 => [$ps_send], 2 => [$ps_send]},\n            be_send => {0 => [$be_hit], 1 => [$be_hit], 2 => [$be_hit]},\n            ps_recv => [\"VALUE $key 0 5\\r\\n\", \"1:1:1\\r\\n\", \"END\\r\\n\"],\n        );\n    };\n\n    my $cmd;\n    my $key;\n\n    # await(r, p, 2, mcp.AWAIT_ANY)\n    $key = \"/awaitany/a\";\n    $cmd = \"get $key\\r\\n\";\n    print $ps $cmd;\n    for my $be (@mbe) {\n        is(scalar <$be>, $cmd, \"awaitany backend req\");\n        print $be \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n    }\n    is(scalar <$ps>, \"VALUE $key 0 1\\r\\n\", \"response from await\");\n    is(scalar <$ps>, \"2\\r\\n\", \"looking for a two responses\");\n    is(scalar <$ps>, \"END\\r\\n\", \"end from await\");\n\n    # await(r, p, 2, mcp.AWAIT_OK)\n    # await(r, p, 1, mcp.AWAIT_FIRST)\n    # more AWAIT_FIRST tests? to see how much it waits on/etc.\n    # await(r, p, 2, mcp.AWAIT_FASTGOOD)\n    # - should return 1 res on good, else wait for N non-error responses\n    $key = \"/awaitfastgood/a\";\n    $cmd = \"get $key\\r\\n\";\n    print $ps $cmd;\n    my $fbe = $mbe[0];\n    is(scalar <$fbe>, $cmd, \"awaitfastgood backend req\");\n    print $fbe \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n    # Should have response after the first hit.\n    is(scalar <$ps>, \"VALUE $key 0 2\\r\\n\", \"response from await\");\n    is(scalar <$ps>, \"ok\\r\\n\", \"await value\");\n    is(scalar <$ps>, \"END\\r\\n\", \"end from await\");\n    for my $be ($mbe[1], $mbe[2]) {\n        is(scalar <$be>, $cmd, \"awaitfastgood backend req\");\n        print $be \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n    }\n\n    # test three pools, second response returns good. should have a hit.\n    print $ps $cmd;\n    for my $be (@mbe) {\n        is(scalar <$be>, $cmd, \"awaitfastgood backend req\");\n    }\n    $fbe = $mbe[0];\n    print $fbe \"END\\r\\n\";\n    $fbe = $mbe[1];\n    print $fbe \"VALUE $key 0 2\\r\\nun\\r\\nEND\\r\\n\";\n    is(scalar <$ps>, \"VALUE $key 0 2\\r\\n\", \"response from await\");\n    is(scalar <$ps>, \"un\\r\\n\", \"await value\");\n    is(scalar <$ps>, \"END\\r\\n\", \"end from await\");\n    $fbe = $mbe[2];\n    print $fbe \"END\\r\\n\";\n\n    # test three pools, but third returns good. should have returned already\n    print $ps $cmd;\n    for my $be ($mbe[0], $mbe[1]) {\n        is(scalar <$be>, $cmd, \"awaitfastgood backend req\");\n        print $be \"END\\r\\n\";\n    }\n    $fbe = $mbe[2];\n    is(scalar <$fbe>, $cmd, \"awaitfastgood backend req\");\n    print $fbe \"VALUE $key 0 2\\r\\nnu\\r\\nEND\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"miss from awaitfastgood\");\n\n    # Testing a set related to fastgood. waiting for two responses.\n    $cmd = \"set $key 0 0 2\\r\\nmo\\r\\n\";\n    print $ps $cmd;\n    for my $be ($mbe[0], $mbe[1]) {\n        is(scalar <$be>, \"set $key 0 0 2\\r\\n\", \"set backend req\");\n        is(scalar <$be>, \"mo\\r\\n\", \"set backend data\");\n        print $be \"STORED\\r\\n\";\n    }\n    is(scalar <$ps>, \"STORED\\r\\n\", \"got stored from await\");\n    $fbe = $mbe[2];\n    is(scalar <$fbe>, \"set $key 0 0 2\\r\\n\", \"set backend req\");\n    is(scalar <$fbe>, \"mo\\r\\n\", \"set backend data\");\n    print $fbe \"STORED\\r\\n\";\n\n    # Testing another set; ensure it isn't returning early.\n    my $s = IO::Select->new();\n    $s->add($ps);\n    print $ps $cmd;\n    for my $be (@mbe) {\n        is(scalar <$be>, \"set $key 0 0 2\\r\\n\", \"set backend req\");\n        is(scalar <$be>, \"mo\\r\\n\", \"set backend data\");\n    }\n    $fbe = $mbe[0];\n    print $fbe \"STORED\\r\\n\";\n    my @readable = $s->can_read(0.25);\n    is(scalar @readable, 0, \"set doesn't return early\");\n    for my $be ($mbe[1], $mbe[2]) {\n        print $be \"STORED\\r\\n\";\n    }\n    is(scalar <$ps>, \"STORED\\r\\n\", \"set completed normally\");\n\n    # await(r, p, 1, mcp.AWAIT_BACKGROUND) - ensure res without waiting\n    $key = \"/awaitbg/a\";\n    $cmd = \"get $key\\r\\n\";\n    print $ps $cmd;\n    # check we can get a response _before_ the backends are consulted.\n    is(scalar <$ps>, \"VALUE $key 0 1\\r\\n\", \"response from await\");\n    is(scalar <$ps>, \"0\\r\\n\", \"looking for zero responses\");\n    is(scalar <$ps>, \"END\\r\\n\", \"end from await\");\n    for my $be (@mbe) {\n        is(scalar <$be>, $cmd, \"awaitbg backend req\");\n        print $be \"VALUE $key 0 2\\r\\nok\\r\\nEND\\r\\n\";\n    }\n\n    # test hitting a pool normally then hit mcp.await()\n    # test hitting mcp.await() then a pool normally\n}\n\ncheck_sanity($ps);\n\n{\n    note(\"Test await_logerrors:\" . __LINE__);\n\n    my $watcher = $p_srv->new_sock;\n    print $watcher \"watch proxyreqs\\n\";\n    is(<$watcher>, \"OK\\r\\n\", \"watcher enabled\");\n\n    # test logging errors from special await.\n    my $key = \"/awaitlogerr/a\";\n    my $cmd = \"set $key 0 0 5\\r\\n\";\n    print $ps $cmd . \"hello\\r\\n\";\n    # respond from the first backend normally, then other two with errors.\n    my $be = $mbe[0];\n    is(scalar <$be>, $cmd, \"await_logerrors backend req\");\n    is(scalar <$be>, \"hello\\r\\n\", \"await_logerrors set payload\");\n    print $be \"STORED\\r\\n\";\n\n    is(scalar <$ps>, \"STORED\\r\\n\", \"block until await responded\");\n    # now ship some errors.\n    for my $be ($mbe[1], $mbe[2]) {\n        is(scalar <$be>, $cmd, \"await_logerrors backend req\");\n        is(scalar <$be>, \"hello\\r\\n\", \"await_logerrors set payload\");\n        print $be \"SERVER_ERROR out of memory\\r\\n\";\n    }\n\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_req elapsed=\\d+ type=\\d+ code=\\d+ status=-1 be=(\\S+) detail=write_failed req=set \\/awaitlogerr\\/a/, \"await_logerrors log entry 1\");\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_req elapsed=\\d+ type=\\d+ code=\\d+ status=-1 be=(\\S+) detail=write_failed req=set \\/awaitlogerr\\/a/, \"await_logerrors log entry 2\");\n\n    # Repeat the logreqtest to ensure we only got the log lines we expected.\n    $cmd = \"get /logreqtest/a\\r\\n\";\n    print $ps $cmd;\n    is(scalar <$be>, $cmd, \"got passthru for log\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"got END from log test\");\n    like(<$watcher>, qr/ts=(\\S+) gid=\\d+ type=proxy_req elapsed=\\d+ type=105 code=17 status=0 be=127.0.0.1:11411 detail=logreqtest req=get \\/logreqtest\\/a/, \"found request log entry\");\n}\n\ncheck_sanity($ps);\n\n# Test out of spec commands from client\n# - wrong # of tokens\n# - bad key size\n# - etc\n\n# Test errors/garbage from server\n# - certain errors pass through to the client, most close the backend.\n# - should be able to retrieve the error message\n{\n    note(\"Test error/garbage from backend:\" . __LINE__);\n\n    my $be = $mbe[0];\n    print $ps \"set /b/foo 0 0 2\\r\\nhi\\r\\n\";\n    is(scalar <$be>, \"set /b/foo 0 0 2\\r\\n\", \"received set cmd\");\n    is(scalar <$be>, \"hi\\r\\n\", \"received set data\");\n    # Send a classic back up the pipe.\n    my $msg = \"SERVER_ERROR object too large for cache\\r\\n\";\n    print $be $msg;\n    is(scalar <$ps>, $msg, \"client received error message\");\n\n    print $ps \"get /b/foo\\r\\n\";\n    is(scalar <$be>, \"get /b/foo\\r\\n\", \"backend still works\");\n    print $be \"END\\r\\n\";\n    is(scalar <$ps>, \"END\\r\\n\", \"got end back\");\n\n    # ERROR and CLIENT_ERROR should both break the backend.\n    print $ps \"get /b/moo\\r\\n\";\n    is(scalar <$be>, \"get /b/moo\\r\\n\", \"received get command\");\n    $msg = \"CLIENT_ERROR bad command line format\\r\\n\";\n    my $data;\n    print $be $msg;\n    is(scalar <$ps>, $msg, \"client received error message\");\n    my $read = $be->read($data, 1);\n    is($read, 0, \"backend disconnected\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    print $ps \"get /b/too\\r\\n\";\n    is(scalar <$be>, \"get /b/too\\r\\n\", \"received get command\");\n    $msg = \"ERROR unhappy\\r\\n\";\n    print $be $msg;\n    is(scalar <$ps>, $msg, \"client received error message\");\n    $read = $be->read($data, 1);\n    is($read, 0, \"backend disconnected\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    # Sometimes blank ERRORS can be sent.\n    print $ps \"get /b/zoo\\r\\n\";\n    is(scalar <$be>, \"get /b/zoo\\r\\n\", \"received get command\");\n    $msg = \"ERROR\\r\\n\";\n    print $be $msg;\n    is(scalar <$ps>, $msg, \"client received error message\");\n    $read = $be->read($data, 1);\n    is($read, 0, \"backend disconnected\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    # Ensure garbage doesn't surface to client.\n    print $ps \"get /b/doo\\r\\n\";\n    is(scalar <$be>, \"get /b/doo\\r\\n\", \"received get command\");\n    print $be \"garbage\\r\\n\"; # don't need the \\r\\n but it makes tests easier\n    is(scalar <$ps>, \"SERVER_ERROR backend failure\\r\\n\", \"generic backend error\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    # Check errors from pipelined commands past a CLIENT_ERROR\n    print $ps \"get /b/quu\\r\\nget /b/muu\\r\\n\";\n    is(scalar <$be>, \"get /b/quu\\r\\n\", \"received get command\");\n    is(scalar <$be>, \"get /b/muu\\r\\n\", \"received next get command\");\n    print $be \"CLIENT_ERROR bad protocol\\r\\nEND\\r\\n\";\n    is(scalar <$ps>, \"CLIENT_ERROR bad protocol\\r\\n\", \"backend error\");\n    is(scalar <$ps>, \"SERVER_ERROR backend failure\\r\\n\", \"backend error\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    # Check that lua handles errors properly.\n    print $ps \"get /errcheck/a\\r\\n\";\n    is(scalar <$be>, \"get /errcheck/a\\r\\n\", \"received get command\");\n    print $be \"ERROR test1\\r\\n\";\n    is(scalar <$ps>, \"ERROR\\r\\n\", \"lua saw correct error code\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    print $ps \"get /errcheck/b\\r\\n\";\n    is(scalar <$be>, \"get /errcheck/b\\r\\n\", \"received get command\");\n    print $be \"CLIENT_ERROR test2\\r\\n\";\n    is(scalar <$ps>, \"CLIENT_ERROR\\r\\n\", \"lua saw correct error code\");\n\n    $be = $mbe[0] = accept_backend($mocksrvs[0]);\n\n    print $ps \"get /errcheck/c\\r\\n\";\n    is(scalar <$be>, \"get /errcheck/c\\r\\n\", \"received get command\");\n    print $be \"SERVER_ERROR test3\\r\\n\";\n    is(scalar <$ps>, \"SERVER_ERROR\\r\\n\", \"lua saw correct error code\");\n}\n\ncheck_sanity($ps);\ndone_testing();\n"], "filenames": ["proto_proxy.c", "t/proxyunits.t"], "buggy_code_start_loc": [723, 153], "buggy_code_end_loc": [802, 153], "fixing_code_start_loc": [724, 154], "fixing_code_end_loc": [814, 160], "type": "CWE-120", "message": "In Memcached before 1.6.22, a buffer overflow exists when processing multiget requests in proxy mode, if there are many spaces after the \"get\" substring.", "other": {"cve": {"id": "CVE-2023-46852", "sourceIdentifier": "cve@mitre.org", "published": "2023-10-27T20:15:09.133", "lastModified": "2023-11-07T19:53:13.173", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "In Memcached before 1.6.22, a buffer overflow exists when processing multiget requests in proxy mode, if there are many spaces after the \"get\" substring."}, {"lang": "es", "value": "En Memcached anterior a 1.6.22, existe un desbordamiento del b\u00fafer al procesar solicitudes de obtenci\u00f3n m\u00faltiple en modo proxy, si hay muchos espacios despu\u00e9s de la subcadena \"get\"."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.5, "baseSeverity": "HIGH"}, "exploitabilityScore": 3.9, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-120"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:memcached:memcached:*:*:*:*:*:*:*:*", "versionEndExcluding": "1.6.22", "matchCriteriaId": "CEB5B313-3710-4308-933A-764A76E8D77A"}]}]}], "references": [{"url": "https://github.com/memcached/memcached/commit/76a6c363c18cfe7b6a1524ae64202ac9db330767", "source": "cve@mitre.org", "tags": ["Patch"]}, {"url": "https://github.com/memcached/memcached/compare/1.6.21...1.6.22", "source": "cve@mitre.org", "tags": ["Release Notes"]}]}, "github_commit_url": "https://github.com/memcached/memcached/commit/76a6c363c18cfe7b6a1524ae64202ac9db330767"}}
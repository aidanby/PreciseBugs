{"buggy_code": ["from operator import itemgetter\nfrom indy_common.util import getIndex\n\n\ndef test_getIndex():\n    items = [('a', {'key1': 1}), ('b', {'key2': 2})]\n    getDict = itemgetter(1)\n\n    def containsKey(key):\n        return lambda x: key in getDict(x)\n\n    assert 0 == getIndex(containsKey('key1'), items)\n    assert 1 == getIndex(containsKey('key2'), items)\n    assert -1 == getIndex(containsKey('key3'), items)\n", "import datetime\nimport os\nimport random\nfrom typing import Tuple, Union, TypeVar, List, Callable\n\nimport libnacl.secret\nfrom base58 import b58decode\nfrom common.serializers.serialization import serialize_msg_for_signing\nfrom plenum.common.types import f\nfrom plenum.common.util import isHex, cryptonymToHex\nfrom common.error import error\nfrom stp_core.crypto.nacl_wrappers import Verifier\n\n\ndef getMsgWithoutSig(msg, sigFieldName=f.SIG.nm):\n    msgWithoutSig = {}\n    for k, v in msg.items():\n        if k != sigFieldName:\n            msgWithoutSig[k] = v\n    return msgWithoutSig\n\n\ndef verifySig(identifier, signature, msg) -> bool:\n    key = cryptonymToHex(identifier) if not isHex(\n        identifier) else identifier\n    ser = serialize_msg_for_signing(msg)\n    b64sig = signature.encode('utf-8')\n    sig = b58decode(b64sig)\n    vr = Verifier(key)\n    return vr.verify(sig, ser)\n\n\ndef getSymmetricallyEncryptedVal(val, secretKey: Union[str, bytes] = None) -> \\\n        Tuple[str, str]:\n    \"\"\"\n    Encrypt the provided value with symmetric encryption\n\n    :param val: the value to encrypt\n    :param secretKey: Optional key, if provided should be either in hex or bytes\n    :return: Tuple of the encrypted value and secret key encoded in hex\n    \"\"\"\n\n    if isinstance(val, str):\n        val = val.encode(\"utf-8\")\n    if secretKey:\n        if isHex(secretKey):\n            secretKey = bytes(bytearray.fromhex(secretKey))\n        elif not isinstance(secretKey, bytes):\n            error(\"Secret key must be either in hex or bytes\")\n        box = libnacl.secret.SecretBox(secretKey)\n    else:\n        box = libnacl.secret.SecretBox()\n\n    return box.encrypt(val).hex(), box.sk.hex()\n\n\ndef getSymmetricallyDecryptedVal(val, secretKey: Union[str, bytes]) -> str:\n    if isHex(val):\n        val = bytes(bytearray.fromhex(val))\n    elif isinstance(val, str):\n        val = val.encode(\"utf-8\")\n    if isHex(secretKey):\n        secretKey = bytes(bytearray.fromhex(secretKey))\n    elif isinstance(secretKey, str):\n        secretKey = secretKey.encode()\n    box = libnacl.secret.SecretBox(secretKey)\n    return box.decrypt(val).decode()\n\n\ndef dateTimeEncoding(obj):\n    if isinstance(obj, datetime.datetime):\n        return int(obj.strftime('%s'))\n    raise TypeError('Not sure how to serialize %s' % (obj,))\n\n\ndef getNonce(length=32):\n    hexChars = [hex(i)[2:] for i in range(0, 16)]\n    return \"\".join([random.choice(hexChars) for i in range(length)])\n\n\ndef get_reply_if_confirmed(client, identifier, request_id: int):\n    reply, status = client.getReply(identifier, request_id)\n    if status == 'CONFIRMED':\n        return reply, None\n    _, errors = \\\n        client.reqRepStore.getAllReplies(identifier, request_id)\n    if not errors:\n        return None, None\n    sender, error_reason = errors.popitem()\n    return reply, error_reason\n\n\n# TODO: Should have a timeout, should not have kwargs\ndef ensureReqCompleted(\n        loop,\n        reqKey,\n        client,\n        clbk=None,\n        pargs=None,\n        kwargs=None,\n        cond=None):\n\n    reply, err = get_reply_if_confirmed(client, *reqKey)\n\n    if err is None and reply is None and (cond is None or not cond()):\n        loop.call_later(.2, ensureReqCompleted, loop,\n                        reqKey, client, clbk, pargs, kwargs, cond)\n    elif clbk:\n        # TODO: Do something which makes reply and error optional in the\n        # callback.\n        # TODO: This is kludgy, but will be resolved once we move away from\n        # this callback pattern\n        if pargs is not None and kwargs is not None:\n            clbk(reply, err, *pargs, **kwargs)\n        elif pargs is not None and kwargs is None:\n            clbk(reply, err, *pargs)\n        elif pargs is None and kwargs is not None:\n            clbk(reply, err, **kwargs)\n        else:\n            clbk(reply, err)\n\n\ndef getNonceForProof(nonce):\n    return int(nonce, 16)\n\n\nT = TypeVar('T')\n\n\ndef getIndex(predicateFn: Callable[[T], bool], items: List[T]) -> int:\n    \"\"\"\n    Finds the index of an item in list, which satisfies predicate\n    :param predicateFn: predicate function to run on items of list\n    :param items: list of tuples\n    :return: first index for which predicate function returns True\n    \"\"\"\n    try:\n        return next(i for i, v in enumerate(items) if predicateFn(v))\n    except StopIteration:\n        return -1\n\n\ndef compose_cmd(cmd):\n    if os.name != 'nt':\n        cmd = ' '.join(cmd)\n    return cmd\n\n\ndef invalidate_config_caches():\n    import stp_core.common.config.util\n    import plenum.common.config_util\n    import indy_common.config_util\n\n    # All 3 references must be nullified because all they reference\n    # the same object due to specific logic of getConfig methods\n    stp_core.common.config.util.CONFIG = None\n    plenum.common.config_util.CONFIG = None\n    indy_common.config_util.CONFIG = None\n", "from typing import Optional\n\nfrom indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit\n\nfrom indy_common.config_util import getConfig\n\nfrom indy_common.constants import CONFIG_LEDGER_ID, POOL_UPGRADE, \\\n    ACTION, CANCEL, START, SCHEDULE, PACKAGE, REINSTALL\n\nfrom indy_common.authorize.auth_request_validator import WriteRequestValidator\nfrom indy_node.server.upgrader import Upgrader\nfrom plenum.common.constants import FORCE, VERSION, NAME\nfrom plenum.common.exceptions import InvalidClientRequest\nfrom plenum.common.request import Request\nfrom plenum.common.txn_util import get_request_data, get_payload_data\nfrom plenum.server.database_manager import DatabaseManager\nfrom plenum.server.pool_manager import TxnPoolManager\nfrom plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler\n\n\nclass PoolUpgradeHandler(WriteRequestHandler):\n\n    def __init__(self, database_manager: DatabaseManager,\n                 upgrader: Upgrader,\n                 write_req_validator: WriteRequestValidator,\n                 pool_manager: TxnPoolManager):\n        super().__init__(database_manager, POOL_UPGRADE, CONFIG_LEDGER_ID)\n        self.upgrader = upgrader\n        self.write_req_validator = write_req_validator\n        self.pool_manager = pool_manager\n\n    def static_validation(self, request: Request):\n        self._validate_request_type(request)\n        identifier, req_id, operation = get_request_data(request)\n        action = operation.get(ACTION)\n        if action not in (START, CANCEL):\n            raise InvalidClientRequest(identifier, req_id,\n                                       \"{} not a valid action\".\n                                       format(action))\n        if action == START:\n            schedule = operation.get(SCHEDULE, {})\n            force = operation.get(FORCE)\n            force = str(force) == 'True'\n            isValid, msg = self.upgrader.isScheduleValid(\n                schedule, self.pool_manager.getNodesServices(), force)\n            if not isValid:\n                raise InvalidClientRequest(identifier, req_id,\n                                           \"{} not a valid schedule since {}\".\n                                           format(schedule, msg))\n\n    def additional_dynamic_validation(self, request: Request, req_pp_time: Optional[int]):\n        self._validate_request_type(request)\n        identifier, req_id, operation = get_request_data(request)\n        status = '*'\n\n        pkg_to_upgrade = operation.get(PACKAGE, getConfig().UPGRADE_ENTRY)\n        targetVersion = operation[VERSION]\n        reinstall = operation.get(REINSTALL, False)\n\n        if not pkg_to_upgrade:\n            raise InvalidClientRequest(identifier, req_id, \"Upgrade package name is empty\")\n\n        try:\n            res = self.upgrader.check_upgrade_possible(pkg_to_upgrade, targetVersion, reinstall)\n        except Exception as exc:\n            res = str(exc)\n\n        if res:\n            raise InvalidClientRequest(identifier, req_id, res)\n\n        action = operation.get(ACTION)\n        # TODO: Some validation needed for making sure name and version\n        # present\n        txn = self.upgrader.get_upgrade_txn(\n            lambda txn: get_payload_data(txn).get(\n                NAME,\n                None) == operation.get(\n                NAME,\n                None) and get_payload_data(txn).get(VERSION) == operation.get(VERSION),\n            reverse=True)\n        if txn:\n            status = get_payload_data(txn).get(ACTION, '*')\n\n        if status == START and action == START:\n            raise InvalidClientRequest(\n                identifier,\n                req_id,\n                \"Upgrade '{}' is already scheduled\".format(\n                    operation.get(NAME)))\n        if status == '*':\n            auth_action = AuthActionAdd(txn_type=POOL_UPGRADE,\n                                        field=ACTION,\n                                        value=action)\n        else:\n            auth_action = AuthActionEdit(txn_type=POOL_UPGRADE,\n                                         field=ACTION,\n                                         old_value=status,\n                                         new_value=action)\n        self.write_req_validator.validate(request,\n                                          [auth_action])\n\n    def apply_forced_request(self, req: Request):\n        super().apply_forced_request(req)\n        txn = self._req_to_txn(req)\n        self.upgrader.handleUpgradeTxn(txn)\n\n    # Config handler don't use state for any validation for now\n    def update_state(self, txn, prev_result, request, is_committed=False):\n        pass\n", "import pytest\nimport shutil\n\nfrom common.version import DigitDotVersion\n\nfrom indy_common.constants import APP_NAME\nfrom indy_common.version import src_version_cls\nfrom indy_node.utils.node_control_utils import (\n    NodeControlUtil, ShellError, DebianVersion\n)\n\n# TODO\n# - conditionally skip all tests for non-debian systems\n# - teste _parse_version_deps_from_pkg_mgr_output deeply\n\ngenerated_commands = []\n\n\n@pytest.fixture\ndef catch_generated_commands(monkeypatch):\n    generated_commands[:] = []\n\n    def _f(command, *args, **kwargs):\n        generated_commands.append(command)\n        return ''\n\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script', _f)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script_extended', _f)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_command', _f)\n\n\ndef test_generated_cmd_get_curr_info(catch_generated_commands):\n    pkg_name = 'some_package'\n    # TODO not an API for now\n    NodeControlUtil._get_curr_info(pkg_name)\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"dpkg -s {}\".format(pkg_name)\n\n\ndef test_generated_cmd_get_latest_pkg_version(catch_generated_commands):\n    pkg_name = 'some_package'\n    NodeControlUtil.get_latest_pkg_version(pkg_name)\n    assert len(generated_commands) == 2\n    assert generated_commands[0] == \"apt update\"\n    assert generated_commands[1] == (\n        \"apt-cache show {} | grep -E '^Version: '\"\n        .format(pkg_name)\n    )\n\n    generated_commands[:] = []\n    upstream = src_version_cls(pkg_name)('1.2.3')\n    NodeControlUtil.get_latest_pkg_version(\n        pkg_name, upstream=upstream, update_cache=False)\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == (\n        \"apt-cache show {} | grep -E '^Version: '\"\n        .format(pkg_name)\n    )\n\n\ndef test_generated_cmd_get_info_from_package_manager(catch_generated_commands):\n    packages = ['package1', 'package2']\n    # TODO not an API for now\n    NodeControlUtil._get_info_from_package_manager(*packages)\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt-cache show {}\".format(\" \".join(packages))\n\n\ndef test_generated_cmd_update_package_cache(catch_generated_commands):\n    NodeControlUtil.update_package_cache()\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt update\"\n\n\ndef test_generated_cmd_get_sys_holds(monkeypatch, catch_generated_commands):\n    monkeypatch.setattr(shutil, 'which', lambda *_: 'path')\n    NodeControlUtil.get_sys_holds()\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt-mark showhold\"\n\n\ndef test_generated_cmd_hold_packages(monkeypatch, catch_generated_commands):\n    packages = ['package1', 'package2']\n    monkeypatch.setattr(shutil, 'which', lambda *_: 'path')\n    NodeControlUtil.hold_packages(packages)\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt-mark hold {}\".format(' '.join(packages))\n\n\ndef test_get_latest_pkg_version_invalid_args():\n    pkg_name = 'any_package'\n    with pytest.raises(TypeError) as excinfo:\n        NodeControlUtil.get_latest_pkg_version(\n            pkg_name,\n            upstream=DigitDotVersion('1.2.3'),\n            update_cache=False\n        )\n    assert (\n        \"should be instance of {}\"\n        .format(src_version_cls(pkg_name)) in str(excinfo.value)\n    )\n\n\n@pytest.mark.parametrize(\n    'pkg_name,upstream,output,expected',\n    [\n        # some top level package\n        ('any_package', None, '', None),\n        ('any_package', None, 'Version: 1.2.3\\nVersion: 1.2.4', '1.2.4'),\n        ('any_package', None, 'Version: 1.2.4\\nVersion: 1.2.3', '1.2.4'),\n        # self package (APP_NAME)\n        (APP_NAME, None, 'Version: 1.2.3\\nVersion: 1.2.4', '1.2.4'),\n        (APP_NAME, None, 'Version: 1.2.4\\nVersion: 1.2.3', '1.2.4'),\n        (APP_NAME, None, 'Version: 1.2.4~dev1\\nVersion: 1.2.4~rc1', '1.2.4rc1'),\n        (APP_NAME, None, 'Version: 1.2.4~rc1\\nVersion: 1.2.4~dev1', '1.2.4rc1'),\n        (APP_NAME, None, 'Version: 1.2.4~dev1\\nVersion: 1.2.4', '1.2.4'),\n        (APP_NAME, None, 'Version: 1.2.4~rc2\\nVersion: 1.2.4', '1.2.4'),\n        (APP_NAME, '1.2.5', 'Version: 1.2.4', None),\n        (APP_NAME, '1.2.5', 'Version: 1.2.5~rc1', None),\n        (APP_NAME, '1.2.5', 'Version: 1.2.5~dev1', None),\n        # invalid versions from output\n        ('any_package', None, 'Version: 1.2.3.4.5', None),\n        (APP_NAME, None, 'Version: 1.2.3.4.5', None),\n        # combined cases\n        ('any_package', None, 'Version: 1.2.3\\nVersion: 1.2.4\\nVersion: 1.2.3.4.5', '1.2.4'),\n        ('any_package', '1.2.5', 'Version: 1.2.3\\nVersion: 1.2.4\\nVersion: 1.2.3.4.5', None),\n        (APP_NAME, None, 'Version: 1.2.3\\nVersion: 1.2.4\\nVersion: 1.2.5~rc1\\nVersion: 1.2.5~dev1\\nVersion: 1.2.3.4.5', '1.2.5rc1'),\n        (APP_NAME, '1.2.5', 'Version: 1.2.3\\nVersion: 1.2.4\\nVersion: 1.2.5~rc1\\nVersion: 1.2.5~dev1\\nVersion: 1.2.3.4.5', None),\n    ],\n    ids=lambda s: s.replace('\\n', '_').replace(' ', '_')\n)\ndef test_get_latest_pkg_version(\n        monkeypatch, pkg_name, upstream, output, expected):\n\n    def _f(command, *args, **kwargs):\n        if not output:\n            raise ShellError(1, command)\n        else:\n            return output\n\n    if upstream is not None:\n        upstream = src_version_cls(pkg_name)(upstream)\n\n    expected = None if expected is None else src_version_cls(pkg_name)(expected)\n\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script_extended', _f)\n    res = NodeControlUtil.get_latest_pkg_version(\n        pkg_name, upstream, update_cache=False)\n    assert expected == res if expected is None else res.upstream\n\n\ndef test_get_latest_pkg_version_for_unknown_package():\n    assert NodeControlUtil.get_latest_pkg_version(\n        'some-unknown-package-name', update_cache=False) is None\n\n\ndef test_curr_pkg_info_no_data(monkeypatch):\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_command', lambda *_: '')\n    assert (None, []) == NodeControlUtil.curr_pkg_info('any_package')\n\n\ndef test_curr_pkg_info(monkeypatch):\n    output = 'Version: 1.2.3\\nDepends: aaa (= 1.2.4), bbb (>= 1.2.5), ccc, aaa'\n    expected_deps = ['aaa=1.2.4', 'bbb=1.2.5', 'ccc']\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_command', lambda *_: output)\n\n    for pkg_name in [APP_NAME, 'any_package']:\n        upstream_cls = src_version_cls(pkg_name)\n        expected_version = DebianVersion(\n            '1.2.3', upstream_cls=upstream_cls)\n\n        pkg_info = NodeControlUtil.curr_pkg_info(pkg_name)\n\n        assert expected_version == pkg_info[0]\n        assert isinstance(expected_version, type(pkg_info[0]))\n        assert isinstance(expected_version.upstream, type(pkg_info[0].upstream))\n        assert expected_deps == pkg_info[1]\n", "import pytest\nfrom indy_common.constants import POOL_UPGRADE, ACTION, START, PACKAGE, APP_NAME, REINSTALL\nfrom indy_node.server.request_handlers.config_req_handlers.pool_upgrade_handler import PoolUpgradeHandler\nfrom plenum.common.constants import VERSION, TXN_PAYLOAD, TXN_PAYLOAD_DATA\nfrom plenum.common.exceptions import InvalidClientRequest\n\nfrom plenum.common.request import Request\nfrom plenum.common.util import randomString\nfrom plenum.test.testing_utils import FakeSomething\n\nfrom indy_common.version import src_version_cls\nfrom indy_node.server.upgrader import Upgrader\nfrom indy_node.utils.node_control_utils import NodeControlUtil, DebianVersion\n\n\n@pytest.fixture(scope='function')\ndef pool_upgrade_request():\n    return Request(identifier=randomString(),\n                   reqId=5,\n                   operation={\n                       'type': POOL_UPGRADE,\n                       ACTION: START,\n                       PACKAGE: 'smth',\n                       VERSION: '1.2.3'\n                   })\n\n\n@pytest.fixture(scope='function')\ndef pool_upgrade_handler(write_auth_req_validator):\n    return PoolUpgradeHandler(\n        None,\n        FakeSomething(check_upgrade_possible=Upgrader.check_upgrade_possible),\n        write_auth_req_validator,\n        FakeSomething()\n    )\n\n\n@pytest.fixture(scope='function')\ndef pkg_version(pool_upgrade_request):\n    return DebianVersion(\n        '1.1.1',\n        upstream_cls=src_version_cls(\n            pool_upgrade_request.operation[PACKAGE])\n    )\n\n\ndef test_pool_upgrade_static_validation_fails_action(pool_upgrade_handler,\n                                                     pool_upgrade_request):\n    pool_upgrade_request.operation[ACTION] = 'smth'\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.static_validation(pool_upgrade_request)\n    e.match('not a valid action')\n\n\ndef test_pool_upgrade_static_validation_fails_schedule(pool_upgrade_handler,\n                                                       pool_upgrade_request):\n    pool_upgrade_handler.pool_manager.getNodesServices = lambda: 1\n    pool_upgrade_handler.upgrader.isScheduleValid = lambda schedule, node_srvs, force: (False, '')\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.static_validation(pool_upgrade_request)\n    e.match('not a valid schedule since')\n\n\ndef test_pool_upgrade_static_validation_passes(pool_upgrade_handler,\n                                               pool_upgrade_request):\n    pool_upgrade_handler.pool_manager.getNodesServices = lambda: 1\n    pool_upgrade_handler.upgrader.isScheduleValid = lambda schedule, node_srvs, force: (True, '')\n    pool_upgrade_handler.static_validation(pool_upgrade_request)\n\n\ndef test_pool_upgrade_dynamic_validation_fails_pckg(pool_upgrade_handler,\n                                                    pool_upgrade_request,\n                                                    tconf):\n    pool_upgrade_request.operation[PACKAGE] = ''\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('Upgrade package name is empty')\n\n\ndef test_pool_upgrade_dynamic_validation_fails_not_installed(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        tconf):\n    monkeypatch.setattr(NodeControlUtil, 'curr_pkg_info',\n                        lambda *x: (None, None))\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('is not installed and cannot be upgraded')\n\n\ndef test_pool_upgrade_dynamic_validation_fails_belong(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        tconf):\n    monkeypatch.setattr(NodeControlUtil, 'curr_pkg_info',\n                        lambda *x: ('1.1.1', ['some_pkg']))\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('doesn\\'t belong to pool')\n\n\ndef test_pool_upgrade_dynamic_validation_fails_upgradable(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        pkg_version,\n        tconf):\n    monkeypatch.setattr(\n        NodeControlUtil, 'curr_pkg_info',\n        lambda *x: (pkg_version, [APP_NAME])\n    )\n    pool_upgrade_request.operation[VERSION] = pkg_version.upstream.full\n    pool_upgrade_request.operation[REINSTALL] = False\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('Version {} is not upgradable'.format(pkg_version.upstream.full))\n\n\ndef test_pool_upgrade_dynamic_validation_fails_scheduled(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        pkg_version,\n        tconf):\n    monkeypatch.setattr(\n        NodeControlUtil, 'curr_pkg_info',\n        lambda *x: (pkg_version, [APP_NAME])\n    )\n    monkeypatch.setattr(\n        NodeControlUtil, 'get_latest_pkg_version',\n        lambda *x, **y: pkg_version\n    )\n    pool_upgrade_request.operation[VERSION] = pkg_version.upstream.full\n    pool_upgrade_request.operation[REINSTALL] = True\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {ACTION: START}}}\n\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('is already scheduled')\n\n\ndef test_pool_upgrade_dynamic_validation_passes(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        pkg_version,\n        tconf):\n    monkeypatch.setattr(\n        NodeControlUtil, 'curr_pkg_info',\n        lambda *x: (pkg_version, [APP_NAME])\n    )\n    monkeypatch.setattr(\n        NodeControlUtil, 'get_latest_pkg_version',\n        lambda *x, **y: pkg_version\n    )\n    pool_upgrade_request.operation[VERSION] = pkg_version.upstream.full\n    pool_upgrade_request.operation[REINSTALL] = True\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {}}}\n    pool_upgrade_handler.write_req_validator.validate = lambda a, b: 0\n    pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n", "import subprocess\nimport shutil\nimport codecs\nimport locale\nimport re\nfrom typing import Iterable, Type, Tuple, List, Union\n\n\nfrom stp_core.common.log import getlogger\nfrom common.version import (\n    InvalidVersionError, SourceVersion, PackageVersion, GenericVersion\n)\n\nfrom indy_common.version import src_version_cls\nfrom indy_common.util import compose_cmd\n\n\n# Package manager command output could contain some utf-8 symbols\n# to handle such a case automatic stream parsing is prohibited,\n# decode error handler is added, proper decoder is selected\n\n# copied from validator-info from plenum\ndef decode_err_handler(error):\n    length = error.end - error.start\n    return length * ' ', error.end\n\n\n# copied from validator-info from plenum\ncodecs.register_error('decode_errors', decode_err_handler)\n\n\nlogger = getlogger()\nTIMEOUT = 600\nMAX_DEPS_DEPTH = 6\n\n\nclass ShellError(subprocess.CalledProcessError):\n    def __init__(self, *args, exc: subprocess.CalledProcessError = None, **kwargs):\n        if exc:\n            super().__init__(exc.returncode, exc.cmd, output=exc.output, stderr=exc.stderr)\n        else:\n            super().__init__(*args, **kwargs)\n\n    @property\n    def stdout_decoded(self):\n        return (self.stdout.decode(locale.getpreferredencoding(), 'decode_errors')\n                if self.stdout else \"\")\n\n    @property\n    def stderr_decoded(self):\n        return (self.stdout.decode(locale.getpreferredencoding(), 'decode_errors')\n                if self.stderr else \"\")\n\n\n# TODO use some library instead of dpkg fpr version routine\nclass DebianVersion(PackageVersion):\n    cache = {}  # seems not actually necessary\n    # https://www.debian.org/doc/debian-policy/ch-controlfields.html#version\n    re_version = re.compile(r'(?:([0-9]):)?([0-9][a-zA-Z0-9.+\\-~]*)')\n\n    @classmethod\n    def _cmp(cls, v1, v2):\n        if v1 == v2:\n            return 0\n        else:\n            cmd = compose_cmd(['dpkg', '--compare-versions', v1, 'gt', v2])\n            try:\n                NodeControlUtil.run_shell_script_extended(cmd)\n            except ShellError as exc:\n                if exc.stderr:\n                    raise\n                else:\n                    return -1\n            else:\n                return 1\n\n    @classmethod\n    def cmp(cls, v1, v2):\n        key = (v1.full, v2.full)\n        if key not in cls.cache:\n            cls.cache[key] = cls._cmp(*key)\n            cls.cache[key[::-1]] = cls.cache[key] * (-1)\n\n        return cls.cache[key]\n\n    @classmethod\n    def clear_cache(cls):\n        cls.cache.clear()\n\n    def __init__(\n        self,\n        version: str,\n        keep_tilde: bool = False,\n        upstream_cls: Type[Union[SourceVersion, None]] = GenericVersion\n    ):\n        parsed = self._parse(version, keep_tilde, upstream_cls)\n        if not parsed[1]:\n            raise InvalidVersionError(\n                \"{} is not a valid debian version\".format(version)\n            )\n\n        self._version = version\n        self._epoch, self._upstream, self._revision = parsed\n\n    def _parse(\n            self,\n            version: str,\n            keep_tilde: bool,\n            upstream_cls: Type[SourceVersion],\n    ):\n        epoch = None\n        upstream = None\n        revision = None\n\n        match = re.fullmatch(self.re_version, version)\n        if match:\n            epoch = match.group(1)\n            upstream = match.group(2)\n            if upstream:\n                if not keep_tilde:\n                    upstream = upstream.replace('~', '.')\n                # TODO improve regex instead\n                parts = upstream.split('-')\n                if len(parts) > 1:\n                    upstream = '-'.join(parts[:-1])\n                    revision = parts[-1]\n        return (\n            epoch,\n            upstream_cls(upstream) if upstream else None,\n            revision\n        )\n\n    @property\n    def full(self) -> str:\n        return self._version\n\n    @property\n    def parts(self) -> Iterable:\n        return (self.epoch, self.upstream, self.revision)\n\n    @property\n    def release(self) -> str:\n        return self.full\n\n    @property\n    def release_parts(self) -> Iterable:\n        return self.parts\n\n    @property\n    def epoch(self):\n        return self._epoch\n\n    @property\n    def upstream(self):\n        return self._upstream\n\n    @property\n    def revision(self):\n        return self._revision\n\n\nclass NodeControlUtil:\n    # Method is used in case we are interested in command output\n    # errors are ignored\n    # only critical errors are logged to journalctl\n    @classmethod\n    def run_shell_command(cls, command, timeout=TIMEOUT):\n        try:\n            ret = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, timeout=timeout)\n            ret_bytes = ret.stdout\n        except subprocess.CalledProcessError as ex:\n            ret_bytes = ex.output\n        except Exception as ex:\n            raise Exception(\"command {} failed with {}\".format(command, ex))\n        ret_msg = ret_bytes.decode(locale.getpreferredencoding(), 'decode_errors').strip() if ret_bytes else \"\"\n        return ret_msg\n\n    # Method is used in case we are NOT interested in command output\n    # everything: command, errors, output etc are logged to journalctl\n    @classmethod\n    def run_shell_script(cls, command, timeout=TIMEOUT):\n        subprocess.run(command, shell=True, timeout=timeout, check=True)\n\n    # TODO actually this should replace `run_shell_script` but it needs\n    # deep testing and verification since it impacts upgrade routine a lot\n    @classmethod\n    def run_shell_script_extended(\n            cls, command, stdout=False, stderr=False,\n            timeout=TIMEOUT, check=True):\n        try:\n            res = subprocess.run(\n                command, shell=True, timeout=timeout, check=check,\n                stdout=None if stdout else subprocess.PIPE,\n                stderr=None if stderr else subprocess.PIPE)\n        except subprocess.CalledProcessError as exc:\n            raise ShellError(exc=exc) from exc\n        else:\n            return res.stdout.decode(locale.getpreferredencoding(), 'decode_errors').strip() if res.stdout else \"\"\n\n    @classmethod\n    def _get_curr_info(cls, package):\n        cmd = compose_cmd(['dpkg', '-s', package])\n        return cls.run_shell_command(cmd)\n\n    @classmethod\n    def _parse_deps(cls, deps: str):\n        ret = []\n        deps = deps.replace(\"|\", \",\").replace(\"(\", \"\").replace(\")\", \"\")\n        pkgs = deps.split(\",\")\n        for pkg in pkgs:\n            if not pkg:\n                continue\n            name_ver = pkg.strip(\" \").split(\" \", maxsplit=1)\n            name = name_ver[0].strip(\" \\n\")\n            if len(name_ver) == 1:\n                ret.append(name)\n            else:\n                ver = name_ver[1].strip(\"()<>= \\n\")\n                # TODO generally wrong logic since it replaces any\n                # fuzzy (>=, < etc.) constraints with equality\n                ret.append(\"{}={}\".format(name, ver))\n        return ret\n\n    @classmethod\n    def _pkgs_dedup(cls, deps):\n        ret = []\n        processed = set()\n        for d in deps:\n            name_ver = d.split(\"=\", maxsplit=1)\n            if name_ver[0] not in processed:\n                ret.append(d)\n            processed.add(name_ver[0])\n        return ret\n\n    @classmethod\n    def _parse_version_deps_from_pkg_mgr_output(\n            cls,\n            output: str,\n            upstream_cls: Type[Union[SourceVersion, None]] = None\n    ):\n        out_lines = output.split(\"\\n\")\n        ver = None\n        ext_deps = []\n        num_pkgs = 0\n        for ln in out_lines:\n            act_line = ln.strip(\" \\n\")\n            if act_line.startswith(\"Version:\"):\n                # this method might be used for the dependnecy tree resolving\n                # when 'output' includes data for multiple packages,\n                # version info here doesn't make any sense in such a case\n                num_pkgs += 1\n                ver = (None if num_pkgs > 1 else\n                       act_line.split(\":\", maxsplit=1)[1].strip(\" \\n\"))\n            if act_line.startswith(\"Depends:\"):\n                ext_deps += cls._parse_deps(act_line.split(\":\", maxsplit=1)[1].strip(\" \\n\"))\n\n        if ver and upstream_cls:\n            try:\n                ver = DebianVersion(ver, upstream_cls=upstream_cls)\n            except InvalidVersionError as exc:\n                logger.warning(\n                    \"Failed to parse debian version {}: {}\"\n                    .format(ver, exc)\n                )\n                ver = None\n                ext_deps = []\n        else:\n            ver = None\n\n        return ver, cls._pkgs_dedup(ext_deps)\n\n    @classmethod\n    def curr_pkg_info(cls, pkg_name: str) -> Tuple[PackageVersion, List]:\n        package_info = cls._get_curr_info(pkg_name)\n        return cls._parse_version_deps_from_pkg_mgr_output(\n            package_info, upstream_cls=src_version_cls(pkg_name))\n\n    @classmethod\n    def get_latest_pkg_version(\n            cls,\n            pkg_name: str,\n            upstream: SourceVersion = None,\n            update_cache: bool = True) -> PackageVersion:\n\n        upstream_cls = src_version_cls(pkg_name)\n\n        if upstream and not isinstance(upstream, upstream_cls):\n            raise TypeError(\n                \"'upstream' should be instance of {}, got {}\"\n                .format(upstream_cls, type(upstream))\n            )\n\n        if update_cache:\n            cls.update_package_cache()\n\n        try:\n            cmd = compose_cmd(\n                ['apt-cache', 'show', pkg_name, '|', 'grep', '-E', \"'^Version: '\"]\n            )\n            output = cls.run_shell_script_extended(cmd).strip()\n        except ShellError as exc:\n            # will fail if either package not found or grep returns nothing\n            # the latter is unexpected and treated as no-data as well\n            logger.info(\n                \"no data for package '{}' found\".format(pkg_name)\n            )\n        else:\n            if output:\n                versions = []\n\n                for v in output.split('\\n'):\n                    try:\n                        dv = DebianVersion(v.split()[1], upstream_cls=upstream_cls)\n                    except InvalidVersionError as exc:\n                        logger.warning(\n                            \"ignoring invalid version from output {} for upstream class {}: {}\"\n                            .format(v.split()[1], upstream_cls, exc)\n                        )\n                    else:\n                        if not upstream or (dv.upstream == upstream):\n                            versions.append(dv)\n\n                try:\n                    return sorted(versions)[-1]\n                except IndexError:\n                    pass\n                except ShellError:\n                    logger.warning(\n                        \"version comparison failed unexpectedly for versions: {}\"\n                        .format(versions)\n                    )\n\n        return None\n\n    @classmethod\n    def _get_info_from_package_manager(cls, *package):\n        cmd_arg = \" \".join(list(package))\n        cmd = compose_cmd(['apt-cache', 'show', cmd_arg])\n        return cls.run_shell_command(cmd)\n\n    @classmethod\n    def update_package_cache(cls):\n        cmd = compose_cmd(['apt', 'update'])\n        cls.run_shell_script(cmd)\n\n    @classmethod\n    def get_deps_tree(cls, *package, depth=0):\n        ret = list(set(package))\n        if depth < MAX_DEPS_DEPTH:\n            package_info = cls._get_info_from_package_manager(*ret)\n            _, deps = cls._parse_version_deps_from_pkg_mgr_output(package_info)\n            deps_deps = []\n            deps = list(set(deps) - set(ret))\n            deps_deps.append(cls.get_deps_tree(*deps, depth=depth + 1))\n\n            ret.append(deps_deps)\n        return ret\n\n    @classmethod\n    def get_deps_tree_filtered(cls, *package, hold_list=[], depth=0, deps_map={}):\n        ret = list(set(package))\n        if depth < MAX_DEPS_DEPTH:\n            package_info = cls._get_info_from_package_manager(*ret)\n            _, deps = cls._parse_version_deps_from_pkg_mgr_output(package_info)\n            # Make deps list unique\n            deps = list(set(deps + ret))\n            for d in deps:\n                if \"=\" in d:\n                    p, v = d.split(\"=\")\n                else:\n                    p = d\n                    v = ''\n                if p in hold_list and \\\n                        (p not in deps_map or deps_map[p] == ''):\n                    deps_map[p] = v\n            cls.get_deps_tree_filtered(*deps, hold_list=hold_list, depth=depth + 1, deps_map=deps_map)\n\n        return [\"{}={}\".format(p, v) if v != '' else p for p, v in deps_map.items()]\n\n    @classmethod\n    def dep_tree_traverse(cls, dep_tree, deps_so_far):\n        if isinstance(dep_tree, str) and dep_tree not in deps_so_far:\n            deps_so_far.append(dep_tree)\n        elif isinstance(dep_tree, list) and dep_tree:\n            for d in reversed(dep_tree):\n                cls.dep_tree_traverse(d, deps_so_far)\n\n    @classmethod\n    def get_sys_holds(cls):\n        if shutil.which(\"apt-mark\"):\n            cmd = compose_cmd(['apt-mark', 'showhold'])\n            ret = cls.run_shell_command(cmd)\n\n            hlds = ret.strip().split(\"\\n\")\n            return [h for h in hlds if h]\n        else:\n            logger.info('apt-mark not found. Assume holds is empty.')\n            return []\n\n    @classmethod\n    def hold_packages(cls, packages):\n        if shutil.which(\"apt-mark\"):\n            packages_to_hold = ' '.join(packages)\n            cmd = compose_cmd(['apt-mark', 'hold', packages_to_hold])\n            cls.run_shell_script(cmd)\n            logger.info('Successfully put {} packages on hold'.format(packages_to_hold))\n        else:\n            logger.info('Skipping packages holding')\n"], "fixing_code": ["import pytest\n\nfrom operator import itemgetter\nfrom indy_common.util import getIndex\nfrom indy_common.util import compose_cmd\n\ndef test_getIndex():\n    items = [('a', {'key1': 1}), ('b', {'key2': 2})]\n    getDict = itemgetter(1)\n\n    def containsKey(key):\n        return lambda x: key in getDict(x)\n\n    assert 0 == getIndex(containsKey('key1'), items)\n    assert 1 == getIndex(containsKey('key2'), items)\n    assert -1 == getIndex(containsKey('key3'), items)\n\n@pytest.mark.parametrize(\n    'pkg_name,package',\n    [\n        pytest.param('some_package', 'some_package', id='some_package'),\n        pytest.param('package_1', 'package_1;echo \"hi\"&&echo \"hello\"\\necho \"hello world!\"', id='strips mixed cmd concat'),\n        pytest.param('package_3', 'package_3;echo \"hey\"', id='strips semi-colon cmd concat'),\n        pytest.param('package_4', 'package_4&&echo \"hey\"', id='strips and cmd concat'),\n        pytest.param('package_5', 'package_5\\necho \"hey\"', id='strips Cr cmd concat'),\n    ]\n)\ndef test_compose_cmd(pkg_name, package):\n    expected_cmd = f'dpkg -s {pkg_name}'\n\n    cmd = compose_cmd(['dpkg', '-s', package])\n    assert expected_cmd == cmd\n\ndef test_compose_cmd_allows_whitespace():\n    pkg_name = 'package_7 some_other_package'\n    expected_cmd = f'dpkg -s {pkg_name}'\n    cmd = compose_cmd(['dpkg', '-s', pkg_name])\n    assert expected_cmd == cmd\n\ndef test_compose_cmd_allows_pipe():\n    expected_cmd = 'dpkg --get-selections | grep -v deinstall | cut -f1'\n    cmd = compose_cmd(\n        ['dpkg', '--get-selections', '|', 'grep', '-v', 'deinstall', '|', 'cut', '-f1']\n    )\n    assert expected_cmd == cmd", "import datetime\nimport os\nimport random\nimport re\nfrom typing import Tuple, Union, TypeVar, List, Callable\n\nimport libnacl.secret\nfrom base58 import b58decode\nfrom common.serializers.serialization import serialize_msg_for_signing\nfrom plenum.common.types import f\nfrom plenum.common.util import isHex, cryptonymToHex\nfrom common.error import error\nfrom stp_core.crypto.nacl_wrappers import Verifier\n\n\ndef getMsgWithoutSig(msg, sigFieldName=f.SIG.nm):\n    msgWithoutSig = {}\n    for k, v in msg.items():\n        if k != sigFieldName:\n            msgWithoutSig[k] = v\n    return msgWithoutSig\n\n\ndef verifySig(identifier, signature, msg) -> bool:\n    key = cryptonymToHex(identifier) if not isHex(\n        identifier) else identifier\n    ser = serialize_msg_for_signing(msg)\n    b64sig = signature.encode('utf-8')\n    sig = b58decode(b64sig)\n    vr = Verifier(key)\n    return vr.verify(sig, ser)\n\n\ndef getSymmetricallyEncryptedVal(val, secretKey: Union[str, bytes] = None) -> \\\n        Tuple[str, str]:\n    \"\"\"\n    Encrypt the provided value with symmetric encryption\n\n    :param val: the value to encrypt\n    :param secretKey: Optional key, if provided should be either in hex or bytes\n    :return: Tuple of the encrypted value and secret key encoded in hex\n    \"\"\"\n\n    if isinstance(val, str):\n        val = val.encode(\"utf-8\")\n    if secretKey:\n        if isHex(secretKey):\n            secretKey = bytes(bytearray.fromhex(secretKey))\n        elif not isinstance(secretKey, bytes):\n            error(\"Secret key must be either in hex or bytes\")\n        box = libnacl.secret.SecretBox(secretKey)\n    else:\n        box = libnacl.secret.SecretBox()\n\n    return box.encrypt(val).hex(), box.sk.hex()\n\n\ndef getSymmetricallyDecryptedVal(val, secretKey: Union[str, bytes]) -> str:\n    if isHex(val):\n        val = bytes(bytearray.fromhex(val))\n    elif isinstance(val, str):\n        val = val.encode(\"utf-8\")\n    if isHex(secretKey):\n        secretKey = bytes(bytearray.fromhex(secretKey))\n    elif isinstance(secretKey, str):\n        secretKey = secretKey.encode()\n    box = libnacl.secret.SecretBox(secretKey)\n    return box.decrypt(val).decode()\n\n\ndef dateTimeEncoding(obj):\n    if isinstance(obj, datetime.datetime):\n        return int(obj.strftime('%s'))\n    raise TypeError('Not sure how to serialize %s' % (obj,))\n\n\ndef getNonce(length=32):\n    hexChars = [hex(i)[2:] for i in range(0, 16)]\n    return \"\".join([random.choice(hexChars) for i in range(length)])\n\n\ndef get_reply_if_confirmed(client, identifier, request_id: int):\n    reply, status = client.getReply(identifier, request_id)\n    if status == 'CONFIRMED':\n        return reply, None\n    _, errors = \\\n        client.reqRepStore.getAllReplies(identifier, request_id)\n    if not errors:\n        return None, None\n    sender, error_reason = errors.popitem()\n    return reply, error_reason\n\n\n# TODO: Should have a timeout, should not have kwargs\ndef ensureReqCompleted(\n        loop,\n        reqKey,\n        client,\n        clbk=None,\n        pargs=None,\n        kwargs=None,\n        cond=None):\n\n    reply, err = get_reply_if_confirmed(client, *reqKey)\n\n    if err is None and reply is None and (cond is None or not cond()):\n        loop.call_later(.2, ensureReqCompleted, loop,\n                        reqKey, client, clbk, pargs, kwargs, cond)\n    elif clbk:\n        # TODO: Do something which makes reply and error optional in the\n        # callback.\n        # TODO: This is kludgy, but will be resolved once we move away from\n        # this callback pattern\n        if pargs is not None and kwargs is not None:\n            clbk(reply, err, *pargs, **kwargs)\n        elif pargs is not None and kwargs is None:\n            clbk(reply, err, *pargs)\n        elif pargs is None and kwargs is not None:\n            clbk(reply, err, **kwargs)\n        else:\n            clbk(reply, err)\n\n\ndef getNonceForProof(nonce):\n    return int(nonce, 16)\n\n\nT = TypeVar('T')\n\n\ndef getIndex(predicateFn: Callable[[T], bool], items: List[T]) -> int:\n    \"\"\"\n    Finds the index of an item in list, which satisfies predicate\n    :param predicateFn: predicate function to run on items of list\n    :param items: list of tuples\n    :return: first index for which predicate function returns True\n    \"\"\"\n    try:\n        return next(i for i, v in enumerate(items) if predicateFn(v))\n    except StopIteration:\n        return -1\n\n\ndef compose_cmd(cmd):\n    if os.name != 'nt':\n        cmd = ' '.join(cmd)\n        cmd = re.split(\";|&&\", cmd.splitlines()[0], 1)[0].rstrip()\n    return cmd\n\n\ndef invalidate_config_caches():\n    import stp_core.common.config.util\n    import plenum.common.config_util\n    import indy_common.config_util\n\n    # All 3 references must be nullified because all they reference\n    # the same object due to specific logic of getConfig methods\n    stp_core.common.config.util.CONFIG = None\n    plenum.common.config_util.CONFIG = None\n    indy_common.config_util.CONFIG = None\n", "import re\n\nfrom typing import Optional\n\nfrom indy_common.authorize.auth_actions import AuthActionAdd, AuthActionEdit\n\nfrom indy_common.config_util import getConfig\n\nfrom indy_common.constants import CONFIG_LEDGER_ID, POOL_UPGRADE, \\\n    ACTION, CANCEL, START, SCHEDULE, PACKAGE, REINSTALL\n\nfrom indy_common.authorize.auth_request_validator import WriteRequestValidator\nfrom indy_node.server.upgrader import Upgrader\nfrom plenum.common.constants import FORCE, VERSION, NAME\nfrom plenum.common.exceptions import InvalidClientRequest\nfrom plenum.common.request import Request\nfrom plenum.common.txn_util import get_request_data, get_payload_data\nfrom plenum.server.database_manager import DatabaseManager\nfrom plenum.server.pool_manager import TxnPoolManager\nfrom plenum.server.request_handlers.handler_interfaces.write_request_handler import WriteRequestHandler\n\n\nclass PoolUpgradeHandler(WriteRequestHandler):\n\n    def __init__(self, database_manager: DatabaseManager,\n                 upgrader: Upgrader,\n                 write_req_validator: WriteRequestValidator,\n                 pool_manager: TxnPoolManager):\n        super().__init__(database_manager, POOL_UPGRADE, CONFIG_LEDGER_ID)\n        self.upgrader = upgrader\n        self.write_req_validator = write_req_validator\n        self.pool_manager = pool_manager\n\n    def static_validation(self, request: Request):\n        self._validate_request_type(request)\n        identifier, req_id, operation = get_request_data(request)\n        action = operation.get(ACTION)\n        if action not in (START, CANCEL):\n            raise InvalidClientRequest(identifier, req_id,\n                                       \"{} not a valid action\".\n                                       format(action))\n        if action == START:\n            schedule = operation.get(SCHEDULE, {})\n            force = operation.get(FORCE)\n            force = str(force) == 'True'\n            isValid, msg = self.upgrader.isScheduleValid(\n                schedule, self.pool_manager.getNodesServices(), force)\n            if not isValid:\n                raise InvalidClientRequest(identifier, req_id,\n                                           \"{} not a valid schedule since {}\".\n                                           format(schedule, msg))\n\n    def additional_dynamic_validation(self, request: Request, req_pp_time: Optional[int]):\n        self._validate_request_type(request)\n        identifier, req_id, operation = get_request_data(request)\n        status = '*'\n        action = operation.get(ACTION)\n        # TODO: Some validation needed for making sure name and version\n        # present\n        txn = self.upgrader.get_upgrade_txn(\n            lambda txn: get_payload_data(txn).get(\n                NAME,\n                None) == operation.get(\n                NAME,\n                None) and get_payload_data(txn).get(VERSION) == operation.get(VERSION),\n            reverse=True)\n        if txn:\n            status = get_payload_data(txn).get(ACTION, '*')\n\n        if status == START and action == START:\n            raise InvalidClientRequest(\n                identifier,\n                req_id,\n                \"Upgrade '{}' is already scheduled\".format(\n                    operation.get(NAME)))\n        if status == '*':\n            auth_action = AuthActionAdd(txn_type=POOL_UPGRADE,\n                                        field=ACTION,\n                                        value=action)\n        else:\n            auth_action = AuthActionEdit(txn_type=POOL_UPGRADE,\n                                         field=ACTION,\n                                         old_value=status,\n                                         new_value=action)\n        self.write_req_validator.validate(request,\n                                          [auth_action])\n\n        pkg_to_upgrade = operation.get(PACKAGE, getConfig().UPGRADE_ENTRY)\n        if not pkg_to_upgrade:\n            raise InvalidClientRequest(identifier, req_id, \"Upgrade package name is empty\")\n\n        # Only allow processing of a single package\n        pkg_to_upgrade = re.split(\"\\s+|;|&&|\\|\", pkg_to_upgrade.splitlines()[0], 1)[0].rstrip()\n        targetVersion = operation[VERSION]\n        reinstall = operation.get(REINSTALL, False)\n        try:\n            res = self.upgrader.check_upgrade_possible(pkg_to_upgrade, targetVersion, reinstall)\n        except Exception as exc:\n            res = str(exc)\n\n        if res:\n            raise InvalidClientRequest(identifier, req_id, res)\n\n    def apply_forced_request(self, req: Request):\n        super().apply_forced_request(req)\n        txn = self._req_to_txn(req)\n        self.upgrader.handleUpgradeTxn(txn)\n\n    # Config handler don't use state for any validation for now\n    def update_state(self, txn, prev_result, request, is_committed=False):\n        pass\n", "from ast import arg\nimport pytest\nimport shutil\nimport re\n\nfrom common.version import DigitDotVersion\n\nfrom indy_common.constants import APP_NAME\nfrom indy_common.version import src_version_cls\nfrom indy_node.utils.node_control_utils import (\n    NodeControlUtil, ShellError, DebianVersion\n)\n\n# TODO\n# - conditionally skip all tests for non-debian systems\n# - teste _parse_version_deps_from_pkg_mgr_output deeply\n\n\ngenerated_commands = []\n\n@pytest.fixture\ndef catch_generated_commands(monkeypatch):\n    generated_commands[:] = []\n\n    def _f(command, *args, **kwargs):\n        generated_commands.append(command)\n        return ''\n\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script', _f)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script_extended', _f)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_command', _f)\n\n\nsome_package_info = 'Package: some_package\\nVersion: 1.2.3\\nDepends: aaa (= 1.2.4), bbb (>= 1.2.5), ccc, aaa'\nsome_other_package_info = 'Package: some_other_package\\nVersion: 4.5.6\\nDepends: ddd (= 3.4.5), eee (>= 5.1.2), fff, ddd'\napp_package_info = 'Package: {}\\nVersion: 1.2.3\\nDepends: aaa (= 1.2.4), bbb (>= 1.2.5), ccc, aaa'.format(APP_NAME)\nany_package_info = 'Package: any_package\\nVersion: 1.2.3\\nDepends: aaa (= 1.2.4), bbb (>= 1.2.5), ccc, aaa'\n\n@pytest.fixture\ndef patch_run_shell_command(monkeypatch):\n    generated_commands[:] = []\n\n    pkg_list = 'openssl\\nsed\\ntar\\nsome_package\\nsome_other_package\\n{}\\nany_package'.format(APP_NAME)\n    pkg_info = '{}\\n\\n{}\\n\\n{}\\n\\n{}'.format(some_package_info, some_other_package_info, app_package_info, any_package_info)\n\n    def mock_run_shell_command(command, *args, **kwargs):\n        # Keep track of the generated commands\n        generated_commands.append(command)\n        if command == 'dpkg --get-selections | grep -v deinstall | cut -f1':\n            return pkg_list\n        else:\n            package_name = command.split()[-1]\n            packages = re.split(\"\\n\\n\", pkg_info)\n            for package in packages:\n                if package_name in package:\n                    return package\n\n            return ''\n\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_command', mock_run_shell_command)\n\n\n@pytest.mark.parametrize(\n    'pkg_name',\n    [\n        pytest.param('not_installed_package', id='not_installed_package'),\n        # Ensure partial matches don't work.\n        pytest.param('some', id='partial_name_match-some'),\n        pytest.param('package', id='partial_name_match-package'),\n    ]\n)\ndef test_generated_cmd_get_curr_info_pkg_not_installed(patch_run_shell_command, pkg_name):\n    pkg_name = 'not_installed_package'\n    # TODO not an API for now\n    NodeControlUtil._get_curr_info(pkg_name)\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == 'dpkg --get-selections | grep -v deinstall | cut -f1'\n\n\ndef test_generated_cmd_get_curr_info_pkg_installed(patch_run_shell_command):\n    pkg_name = 'some_package'\n    # TODO not an API for now\n    NodeControlUtil._get_curr_info(pkg_name)\n    assert len(generated_commands) == 2\n    assert generated_commands[0] == 'dpkg --get-selections | grep -v deinstall | cut -f1'\n    assert generated_commands[1] == \"dpkg -s {}\".format(pkg_name)\n\n\ndef test_generated_cmd_get_curr_info_accepts_single_pkg_only(patch_run_shell_command):\n    expected_pkg_name = 'some_other_package'\n    # The extra spaces between the package names is on purpose.\n    pkg_name = 'some_other_package   some_package'\n    # TODO not an API for now\n    NodeControlUtil._get_curr_info(pkg_name)\n    assert len(generated_commands) == 2\n    assert generated_commands[0] == 'dpkg --get-selections | grep -v deinstall | cut -f1'\n    assert generated_commands[1] == \"dpkg -s {}\".format(expected_pkg_name)\n\n\n@pytest.mark.parametrize(\n    'pkg_name,package',\n    [\n        pytest.param('some_package', 'some_package|echo \"hey\";echo \"hi\"&&echo \"hello\"|echo \"hello world\"\\necho \"hello world!\"', id='strips mixed cmd concat'),\n        pytest.param('some_package', 'some_package|echo \"hey\"', id='strips pipe cmd concat'),\n        pytest.param('some_package', 'some_package;echo \"hey\"', id='strips semi-colon cmd concat'),\n        pytest.param('some_package', 'some_package&&echo \"hey\"', id='strips AND cmd concat'),\n        pytest.param('some_package', 'some_package\\necho \"hey\"', id='strips Cr cmd concat'),\n        pytest.param('some_package', 'some_package echo \"hey\"', id='strips whitespace'),\n    ]\n)\ndef test_generated_cmd_get_curr_info_with_command_concat(patch_run_shell_command, pkg_name, package):\n    # TODO not an API for now\n    NodeControlUtil._get_curr_info(package)\n    assert len(generated_commands) == 2\n    assert generated_commands[0] == 'dpkg --get-selections | grep -v deinstall | cut -f1'\n    assert generated_commands[1] == \"dpkg -s {}\".format(pkg_name)\n\n\n@pytest.mark.parametrize(\n    'pkg_name,expected_output',\n    [\n        pytest.param('some_package', some_package_info, id='some_package'),\n        pytest.param('some_other_package', some_other_package_info, id='some_other_package'),\n        pytest.param(APP_NAME, app_package_info, id=APP_NAME),\n        pytest.param('any_package', any_package_info, id='any_package'),\n        pytest.param('not_installed_package', '', id='not_installed_package'),\n        # Ensure partial matches don't work.\n        pytest.param('some', '', id='partial_name_match-some'),\n        pytest.param('package', '', id='partial_name_match-package'),\n    ]\n)\ndef test_get_curr_info_output(patch_run_shell_command, pkg_name, expected_output):\n    pkg_info = NodeControlUtil._get_curr_info(pkg_name)\n    assert pkg_info == expected_output\n\n\ndef test_generated_cmd_get_latest_pkg_version(catch_generated_commands):\n    pkg_name = 'some_package'\n    NodeControlUtil.get_latest_pkg_version(pkg_name)\n    assert len(generated_commands) == 2\n    assert generated_commands[0] == \"apt update\"\n    assert generated_commands[1] == (\n        \"apt-cache show {} | grep -E '^Version: '\"\n        .format(pkg_name)\n    )\n\n    generated_commands[:] = []\n    upstream = src_version_cls(pkg_name)('1.2.3')\n    NodeControlUtil.get_latest_pkg_version(\n        pkg_name, upstream=upstream, update_cache=False)\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == (\n        \"apt-cache show {} | grep -E '^Version: '\"\n        .format(pkg_name)\n    )\n\n\ndef test_generated_cmd_get_info_from_package_manager(catch_generated_commands):\n    packages = ['package1', 'package2']\n    # TODO not an API for now\n    NodeControlUtil._get_info_from_package_manager(*packages)\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt-cache show {}\".format(\" \".join(packages))\n\n# apt update is successful\ndef test_generated_cmd_update_package_cache(catch_generated_commands):\n    NodeControlUtil.update_package_cache()\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt update\"\n\n# apt update fails\n# apt update dependencies don't need to be upgraded, i.e. only key update is performed.\ndef test_generated_cmd_update_package_cache_2(monkeypatch):\n    run_shell_script_counter = 0\n    commands = []\n\n    def _run_shell_script(command, *args, **kwargs):\n        nonlocal run_shell_script_counter\n        run_shell_script_counter += 1\n        commands.append(command)\n\n        if run_shell_script_counter == 1:\n            raise Exception(\"Command 'apt update' returned non-zero exit status\")\n\n        return ''\n\n    def _f(command, *args, **kwargs):\n        commands.append(command)\n        return ''\n\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script', _run_shell_script)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script_extended', _f)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_command', _f)\n\n    NodeControlUtil.update_package_cache()\n    assert len(commands) == 4\n    assert commands[0] == \"apt update\"\n    assert commands[1] == \"apt-key adv --keyserver keyserver.ubuntu.com --recv-keys CE7709D068DB5E88\"\n    assert commands[2] == \"apt list --upgradable\"\n    assert commands[3] == \"apt update\"\n\n\n# apt update fails\n# apt update dependencies need to be upgraded\ndef test_generated_cmd_update_package_cache_3(monkeypatch):\n    run_shell_script_counter = 0\n    commands = []\n\n    def _run_shell_script(command, *args, **kwargs):\n        nonlocal run_shell_script_counter\n        run_shell_script_counter += 1\n        commands.append(command)\n\n        if run_shell_script_counter == 1:\n            raise Exception(\"Command 'apt update' returned non-zero exit status\")\n\n        return ''\n\n    def _run_shell_command(command, *args, **kwargs):\n        commands.append(command)\n        return \"\"\"libgnutls-openssl27/xenial-updates 3.4.10-4ubuntu1.9 amd64 [upgradable from: 3.4.10-4ubuntu1.7]\nlibgnutls30/xenial-updates 3.4.10-4ubuntu1.9 amd64 [upgradable from: 3.4.10-4ubuntu1.7]\nliblxc1/xenial-updates 2.0.11-0ubuntu1~16.04.3 amd64 [upgradable from: 2.0.8-0ubuntu1~16.04.2]\"\"\"\n\n    def _f(command, *args, **kwargs):\n        commands.append(command)\n        return ''\n\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script', _run_shell_script)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script_extended', _f)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_command', _run_shell_command)\n\n    NodeControlUtil.update_package_cache()\n    assert len(commands) == 5\n    assert commands[0] == \"apt update\"\n    assert commands[1] == \"apt-key adv --keyserver keyserver.ubuntu.com --recv-keys CE7709D068DB5E88\"\n    assert commands[2] == \"apt list --upgradable\"\n    assert commands[3] == \"apt --only-upgrade install -y libgnutls30\"\n    assert commands[4] == \"apt update\"\n\n\ndef test_generated_cmd_update_repo_keys(catch_generated_commands):\n    NodeControlUtil.update_repo_keys()\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt-key adv --keyserver keyserver.ubuntu.com --recv-keys CE7709D068DB5E88\"\n\n\n# apt update dependencies don't need to be upgraded\ndef test_generated_cmd_update_apt_update_dependencies_1(catch_generated_commands):\n    NodeControlUtil.update_apt_update_dependencies()\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt list --upgradable\"\n\n\n# apt update dependencies need to be upgraded\ndef test_generated_cmd_update_apt_update_dependencies_2(monkeypatch):\n    commands = []\n\n    def _run_shell_command(command, *args, **kwargs):\n        commands.append(command)\n        return \"\"\"libgnutls-openssl27/xenial-updates 3.4.10-4ubuntu1.9 amd64 [upgradable from: 3.4.10-4ubuntu1.7]\nlibgnutls30/xenial-updates 3.4.10-4ubuntu1.9 amd64 [upgradable from: 3.4.10-4ubuntu1.7]\nliblxc1/xenial-updates 2.0.11-0ubuntu1~16.04.3 amd64 [upgradable from: 2.0.8-0ubuntu1~16.04.2]\"\"\"\n\n    def _f(command, *args, **kwargs):\n        commands.append(command)\n        return ''\n\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script', _f)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script_extended', _f)\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_command', _run_shell_command)\n\n    NodeControlUtil.update_apt_update_dependencies()\n    assert len(commands) == 2\n    assert commands[0] == \"apt list --upgradable\"\n    assert commands[1] == \"apt --only-upgrade install -y libgnutls30\"\n\n\ndef test_generated_cmd_get_sys_holds(monkeypatch, catch_generated_commands):\n    monkeypatch.setattr(shutil, 'which', lambda *_: 'path')\n    NodeControlUtil.get_sys_holds()\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt-mark showhold\"\n\n\ndef test_generated_cmd_hold_packages(monkeypatch, catch_generated_commands):\n    packages = ['package1', 'package2']\n    monkeypatch.setattr(shutil, 'which', lambda *_: 'path')\n    NodeControlUtil.hold_packages(packages)\n    assert len(generated_commands) == 1\n    assert generated_commands[0] == \"apt-mark hold {}\".format(' '.join(packages))\n\n\ndef test_get_latest_pkg_version_invalid_args():\n    pkg_name = 'any_package'\n    with pytest.raises(TypeError) as excinfo:\n        NodeControlUtil.get_latest_pkg_version(\n            pkg_name,\n            upstream=DigitDotVersion('1.2.3'),\n            update_cache=False\n        )\n    assert (\n        \"should be instance of {}\"\n        .format(src_version_cls(pkg_name)) in str(excinfo.value)\n    )\n\n\n@pytest.mark.parametrize(\n    'pkg_name,upstream,output,expected',\n    [\n        # some top level package\n        ('any_package', None, '', None),\n        ('any_package', None, 'Version: 1.2.3\\nVersion: 1.2.4', '1.2.4'),\n        ('any_package', None, 'Version: 1.2.4\\nVersion: 1.2.3', '1.2.4'),\n        # self package (APP_NAME)\n        (APP_NAME, None, 'Version: 1.2.3\\nVersion: 1.2.4', '1.2.4'),\n        (APP_NAME, None, 'Version: 1.2.4\\nVersion: 1.2.3', '1.2.4'),\n        (APP_NAME, None, 'Version: 1.2.4~dev1\\nVersion: 1.2.4~rc1', '1.2.4rc1'),\n        (APP_NAME, None, 'Version: 1.2.4~rc1\\nVersion: 1.2.4~dev1', '1.2.4rc1'),\n        (APP_NAME, None, 'Version: 1.2.4~dev1\\nVersion: 1.2.4', '1.2.4'),\n        (APP_NAME, None, 'Version: 1.2.4~rc2\\nVersion: 1.2.4', '1.2.4'),\n        (APP_NAME, '1.2.5', 'Version: 1.2.4', None),\n        (APP_NAME, '1.2.5', 'Version: 1.2.5~rc1', None),\n        (APP_NAME, '1.2.5', 'Version: 1.2.5~dev1', None),\n        # invalid versions from output\n        ('any_package', None, 'Version: 1.2.3.4.5', None),\n        (APP_NAME, None, 'Version: 1.2.3.4.5', None),\n        # combined cases\n        ('any_package', None, 'Version: 1.2.3\\nVersion: 1.2.4\\nVersion: 1.2.3.4.5', '1.2.4'),\n        ('any_package', '1.2.5', 'Version: 1.2.3\\nVersion: 1.2.4\\nVersion: 1.2.3.4.5', None),\n        (APP_NAME, None, 'Version: 1.2.3\\nVersion: 1.2.4\\nVersion: 1.2.5~rc1\\nVersion: 1.2.5~dev1\\nVersion: 1.2.3.4.5', '1.2.5rc1'),\n        (APP_NAME, '1.2.5', 'Version: 1.2.3\\nVersion: 1.2.4\\nVersion: 1.2.5~rc1\\nVersion: 1.2.5~dev1\\nVersion: 1.2.3.4.5', None),\n    ],\n    ids=lambda s: s.replace('\\n', '_').replace(' ', '_')\n)\ndef test_get_latest_pkg_version(\n        monkeypatch, pkg_name, upstream, output, expected):\n\n    def _f(command, *args, **kwargs):\n        if not output:\n            raise ShellError(1, command)\n        else:\n            return output\n\n    if upstream is not None:\n        upstream = src_version_cls(pkg_name)(upstream)\n\n    expected = None if expected is None else src_version_cls(pkg_name)(expected)\n\n    monkeypatch.setattr(NodeControlUtil, 'run_shell_script_extended', _f)\n    res = NodeControlUtil.get_latest_pkg_version(\n        pkg_name, upstream, update_cache=False)\n    assert expected == res if expected is None else res.upstream\n\n\ndef test_get_latest_pkg_version_for_unknown_package():\n    assert NodeControlUtil.get_latest_pkg_version(\n        'some-unknown-package-name', update_cache=False) is None\n\n\ndef test_curr_pkg_info_no_data(patch_run_shell_command):\n    assert (None, []) == NodeControlUtil.curr_pkg_info('some-unknown-package-name')\n\n\n@pytest.mark.parametrize(\n    'pkg_name,version,expected_deps',\n    [\n        pytest.param('some_package', '1.2.3', ['aaa=1.2.4', 'bbb=1.2.5', 'ccc'], id='some_package'),\n        pytest.param('some_other_package', '4.5.6', ['ddd=3.4.5', 'eee=5.1.2', 'fff'], id='some_other_package'),\n        pytest.param(APP_NAME, '1.2.3', ['aaa=1.2.4', 'bbb=1.2.5', 'ccc'], id=APP_NAME),\n        pytest.param('any_package', '1.2.3', ['aaa=1.2.4', 'bbb=1.2.5', 'ccc'], id='any_package'),\n    ]\n)\ndef test_curr_pkg_info(patch_run_shell_command, pkg_name, version, expected_deps):\n    upstream_cls = src_version_cls(pkg_name)\n    expected_version = DebianVersion(\n        version, upstream_cls=upstream_cls)\n\n    pkg_info = NodeControlUtil.curr_pkg_info(pkg_name)\n\n    assert expected_version == pkg_info[0]\n    assert isinstance(expected_version, type(pkg_info[0]))\n    assert isinstance(expected_version.upstream, type(pkg_info[0].upstream))\n    assert expected_deps == pkg_info[1]\n\n\n@pytest.mark.parametrize(\n    'pkg_name',\n    [\n        pytest.param('{} | echo \"hey\"; echo \"hi\" && echo \"hello\"|echo \"hello world\"'.format(APP_NAME), id='multiple'),\n        pytest.param('{}|echo \"hey\"'.format(APP_NAME), id='pipe'),\n        pytest.param('{};echo \"hey\"'.format(APP_NAME), id='semi-colon'),\n        pytest.param('{}&&echo \"hey\"'.format(APP_NAME), id='and'),\n        pytest.param('{}\\necho \"hey\"'.format(APP_NAME), id='Cr'),\n        pytest.param('{} echo \"hey\"'.format(APP_NAME), id='whitespace'),\n    ]\n)\ndef test_curr_pkg_info_with_command_concat(patch_run_shell_command, pkg_name):\n    expected_deps = ['aaa=1.2.4', 'bbb=1.2.5', 'ccc']\n    upstream_cls = src_version_cls(pkg_name)\n    expected_version = DebianVersion(\n        '1.2.3', upstream_cls=upstream_cls)\n\n    pkg_info = NodeControlUtil.curr_pkg_info(pkg_name)\n\n    assert expected_version == pkg_info[0]\n    assert isinstance(expected_version, type(pkg_info[0]))\n    assert isinstance(expected_version.upstream, type(pkg_info[0].upstream))\n    assert expected_deps == pkg_info[1]", "import pytest\nfrom indy_common.constants import POOL_UPGRADE, ACTION, START, PACKAGE, APP_NAME, REINSTALL\nfrom indy_node.server.request_handlers.config_req_handlers.pool_upgrade_handler import PoolUpgradeHandler\nfrom plenum.common.constants import VERSION, TXN_PAYLOAD, TXN_PAYLOAD_DATA\nfrom plenum.common.exceptions import InvalidClientRequest\n\nfrom plenum.common.request import Request\nfrom plenum.common.util import randomString\nfrom plenum.test.testing_utils import FakeSomething\n\nfrom indy_common.version import src_version_cls\nfrom indy_node.server.upgrader import Upgrader\nfrom indy_node.utils.node_control_utils import NodeControlUtil, DebianVersion\n\n\n@pytest.fixture(scope='function')\ndef pool_upgrade_request():\n    return Request(identifier=randomString(),\n                   reqId=5,\n                   operation={\n                       'type': POOL_UPGRADE,\n                       ACTION: START,\n                       PACKAGE: 'smth',\n                       VERSION: '1.2.3'\n                   })\n\n\n@pytest.fixture(scope='function')\ndef pool_upgrade_handler(write_auth_req_validator):\n    return PoolUpgradeHandler(\n        None,\n        FakeSomething(check_upgrade_possible=Upgrader.check_upgrade_possible),\n        write_auth_req_validator,\n        FakeSomething()\n    )\n\n\n@pytest.fixture(scope='function')\ndef pkg_version(pool_upgrade_request):\n    return DebianVersion(\n        '1.1.1',\n        upstream_cls=src_version_cls(\n            pool_upgrade_request.operation[PACKAGE])\n    )\n\n\ndef test_pool_upgrade_static_validation_fails_action(pool_upgrade_handler,\n                                                     pool_upgrade_request):\n    pool_upgrade_request.operation[ACTION] = 'smth'\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.static_validation(pool_upgrade_request)\n    e.match('not a valid action')\n\n\ndef test_pool_upgrade_static_validation_fails_schedule(pool_upgrade_handler,\n                                                       pool_upgrade_request):\n    pool_upgrade_handler.pool_manager.getNodesServices = lambda: 1\n    pool_upgrade_handler.upgrader.isScheduleValid = lambda schedule, node_srvs, force: (False, '')\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.static_validation(pool_upgrade_request)\n    e.match('not a valid schedule since')\n\n\ndef test_pool_upgrade_static_validation_passes(pool_upgrade_handler,\n                                               pool_upgrade_request):\n    pool_upgrade_handler.pool_manager.getNodesServices = lambda: 1\n    pool_upgrade_handler.upgrader.isScheduleValid = lambda schedule, node_srvs, force: (True, '')\n    pool_upgrade_handler.static_validation(pool_upgrade_request)\n\n\ndef test_pool_upgrade_dynamic_validation_fails_pckg(pool_upgrade_handler,\n                                                    pool_upgrade_request,\n                                                    tconf):\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {}}}\n    pool_upgrade_handler.write_req_validator.validate = lambda a, b: 0\n\n    pool_upgrade_request.operation[PACKAGE] = ''\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('Upgrade package name is empty')\n\n\ndef test_pool_upgrade_dynamic_validation_fails_not_installed(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        tconf):\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {}}}\n    pool_upgrade_handler.write_req_validator.validate = lambda a, b: 0\n\n    monkeypatch.setattr(NodeControlUtil, 'curr_pkg_info',\n                        lambda *x: (None, None))\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('{} is not installed and cannot be upgraded'.format(pool_upgrade_request.operation[PACKAGE]))\n\n\ndef test_pool_upgrade_dynamic_validation_fails_not_installed_mpr(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        tconf):\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {}}}\n    pool_upgrade_handler.write_req_validator.validate = lambda a, b: 0\n\n    monkeypatch.setattr(NodeControlUtil, 'curr_pkg_info',\n                        lambda *x: (None, None))\n\n    # When multiple packages are requested, only the first should be processed.\n    pool_upgrade_request.operation[PACKAGE] = 'some_package some_other_package'\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('some_package is not installed and cannot be upgraded')\n\n\ndef test_pool_upgrade_dynamic_validation_fails_belong(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        tconf):\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {}}}\n    pool_upgrade_handler.write_req_validator.validate = lambda a, b: 0\n\n    monkeypatch.setattr(NodeControlUtil, 'curr_pkg_info',\n                        lambda *x: ('1.1.1', ['some_pkg']))\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('{} doesn\\'t belong to pool'.format(pool_upgrade_request.operation[PACKAGE]))\n\n\ndef test_pool_upgrade_dynamic_validation_fails_upgradable(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        pkg_version,\n        tconf):\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {}}}\n    pool_upgrade_handler.write_req_validator.validate = lambda a, b: 0\n\n    monkeypatch.setattr(\n        NodeControlUtil, 'curr_pkg_info',\n        lambda *x: (pkg_version, [APP_NAME])\n    )\n    pool_upgrade_request.operation[VERSION] = pkg_version.upstream.full\n    pool_upgrade_request.operation[REINSTALL] = False\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('Version {} is not upgradable'.format(pkg_version.upstream.full))\n\n\ndef test_pool_upgrade_dynamic_validation_fails_scheduled(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        pkg_version,\n        tconf):\n    monkeypatch.setattr(\n        NodeControlUtil, 'curr_pkg_info',\n        lambda *x: (pkg_version, [APP_NAME])\n    )\n    monkeypatch.setattr(\n        NodeControlUtil, 'get_latest_pkg_version',\n        lambda *x, **y: pkg_version\n    )\n    pool_upgrade_request.operation[VERSION] = pkg_version.upstream.full\n    pool_upgrade_request.operation[REINSTALL] = True\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {ACTION: START}}}\n\n    with pytest.raises(InvalidClientRequest) as e:\n        pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n    e.match('is already scheduled')\n\n\ndef test_pool_upgrade_dynamic_validation_passes(\n        monkeypatch,\n        pool_upgrade_handler,\n        pool_upgrade_request,\n        pkg_version,\n        tconf):\n    monkeypatch.setattr(\n        NodeControlUtil, 'curr_pkg_info',\n        lambda *x: (pkg_version, [APP_NAME])\n    )\n    monkeypatch.setattr(\n        NodeControlUtil, 'get_latest_pkg_version',\n        lambda *x, **y: pkg_version\n    )\n    pool_upgrade_request.operation[VERSION] = pkg_version.upstream.full\n    pool_upgrade_request.operation[REINSTALL] = True\n    pool_upgrade_handler.upgrader.get_upgrade_txn = \\\n        lambda predicate, reverse: \\\n            {TXN_PAYLOAD: {TXN_PAYLOAD_DATA: {}}}\n    pool_upgrade_handler.write_req_validator.validate = lambda a, b: 0\n    pool_upgrade_handler.dynamic_validation(pool_upgrade_request, 0)\n", "import subprocess\nimport shutil\nimport codecs\nimport locale\nimport re\nfrom typing import Iterable, Type, Tuple, List, Union\n\n\nfrom stp_core.common.log import getlogger\nfrom common.version import (\n    InvalidVersionError, SourceVersion, PackageVersion, GenericVersion\n)\n\nfrom indy_common.version import src_version_cls\nfrom indy_common.util import compose_cmd\n\n\n# Package manager command output could contain some utf-8 symbols\n# to handle such a case automatic stream parsing is prohibited,\n# decode error handler is added, proper decoder is selected\n\n# copied from validator-info from plenum\ndef decode_err_handler(error):\n    length = error.end - error.start\n    return length * ' ', error.end\n\n\n# copied from validator-info from plenum\ncodecs.register_error('decode_errors', decode_err_handler)\n\n\nlogger = getlogger()\nTIMEOUT = 600\nMAX_DEPS_DEPTH = 6\n\n\nclass ShellError(subprocess.CalledProcessError):\n    def __init__(self, *args, exc: subprocess.CalledProcessError = None, **kwargs):\n        if exc:\n            super().__init__(exc.returncode, exc.cmd, output=exc.output, stderr=exc.stderr)\n        else:\n            super().__init__(*args, **kwargs)\n\n    @property\n    def stdout_decoded(self):\n        return (self.stdout.decode(locale.getpreferredencoding(), 'decode_errors')\n                if self.stdout else \"\")\n\n    @property\n    def stderr_decoded(self):\n        return (self.stdout.decode(locale.getpreferredencoding(), 'decode_errors')\n                if self.stderr else \"\")\n\n\n# TODO use some library instead of dpkg fpr version routine\nclass DebianVersion(PackageVersion):\n    cache = {}  # seems not actually necessary\n    # https://www.debian.org/doc/debian-policy/ch-controlfields.html#version\n    re_version = re.compile(r'(?:([0-9]):)?([0-9][a-zA-Z0-9.+\\-~]*)')\n\n    @classmethod\n    def _cmp(cls, v1, v2):\n        if v1 == v2:\n            return 0\n        else:\n            cmd = compose_cmd(['dpkg', '--compare-versions', v1, 'gt', v2])\n            try:\n                NodeControlUtil.run_shell_script_extended(cmd)\n            except ShellError as exc:\n                if exc.stderr:\n                    raise\n                else:\n                    return -1\n            else:\n                return 1\n\n    @classmethod\n    def cmp(cls, v1, v2):\n        key = (v1.full, v2.full)\n        if key not in cls.cache:\n            cls.cache[key] = cls._cmp(*key)\n            cls.cache[key[::-1]] = cls.cache[key] * (-1)\n\n        return cls.cache[key]\n\n    @classmethod\n    def clear_cache(cls):\n        cls.cache.clear()\n\n    def __init__(\n        self,\n        version: str,\n        keep_tilde: bool = False,\n        upstream_cls: Type[Union[SourceVersion, None]] = GenericVersion\n    ):\n        parsed = self._parse(version, keep_tilde, upstream_cls)\n        if not parsed[1]:\n            raise InvalidVersionError(\n                \"{} is not a valid debian version\".format(version)\n            )\n\n        self._version = version\n        self._epoch, self._upstream, self._revision = parsed\n\n    def _parse(\n            self,\n            version: str,\n            keep_tilde: bool,\n            upstream_cls: Type[SourceVersion],\n    ):\n        epoch = None\n        upstream = None\n        revision = None\n\n        match = re.fullmatch(self.re_version, version)\n        if match:\n            epoch = match.group(1)\n            upstream = match.group(2)\n            if upstream:\n                if not keep_tilde:\n                    upstream = upstream.replace('~', '.')\n                # TODO improve regex instead\n                parts = upstream.split('-')\n                if len(parts) > 1:\n                    upstream = '-'.join(parts[:-1])\n                    revision = parts[-1]\n        return (\n            epoch,\n            upstream_cls(upstream) if upstream else None,\n            revision\n        )\n\n    @property\n    def full(self) -> str:\n        return self._version\n\n    @property\n    def parts(self) -> Iterable:\n        return (self.epoch, self.upstream, self.revision)\n\n    @property\n    def release(self) -> str:\n        return self.full\n\n    @property\n    def release_parts(self) -> Iterable:\n        return self.parts\n\n    @property\n    def epoch(self):\n        return self._epoch\n\n    @property\n    def upstream(self):\n        return self._upstream\n\n    @property\n    def revision(self):\n        return self._revision\n\n\nclass NodeControlUtil:\n    # Method is used in case we are interested in command output\n    # errors are ignored\n    # only critical errors are logged to journalctl\n    @classmethod\n    def run_shell_command(cls, command, timeout=TIMEOUT):\n        try:\n            ret = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, timeout=timeout)\n            ret_bytes = ret.stdout\n        except subprocess.CalledProcessError as ex:\n            ret_bytes = ex.output\n        except Exception as ex:\n            raise Exception(\"command {} failed with {}\".format(command, ex))\n        ret_msg = ret_bytes.decode(locale.getpreferredencoding(), 'decode_errors').strip() if ret_bytes else \"\"\n        return ret_msg\n\n    # Method is used in case we are NOT interested in command output\n    # everything: command, errors, output etc are logged to journalctl\n    @classmethod\n    def run_shell_script(cls, command, timeout=TIMEOUT):\n        subprocess.run(command, shell=True, timeout=timeout, check=True)\n\n    # TODO actually this should replace `run_shell_script` but it needs\n    # deep testing and verification since it impacts upgrade routine a lot\n    @classmethod\n    def run_shell_script_extended(\n            cls, command, stdout=False, stderr=False,\n            timeout=TIMEOUT, check=True):\n        try:\n            res = subprocess.run(\n                command, shell=True, timeout=timeout, check=check,\n                stdout=None if stdout else subprocess.PIPE,\n                stderr=None if stderr else subprocess.PIPE)\n        except subprocess.CalledProcessError as exc:\n            raise ShellError(exc=exc) from exc\n        else:\n            return res.stdout.decode(locale.getpreferredencoding(), 'decode_errors').strip() if res.stdout else \"\"\n\n    @classmethod\n    def _get_curr_info(cls, package):\n        # Only allow processing of a single package\n        package = re.split(\"\\s+|;|&&|\\|\", package.splitlines()[0], 1)[0].rstrip()\n\n        # Ensure the package exists before fetching the details directly from dpkg\n        if not cls._package_exists(package):\n            return ''\n\n        cmd = compose_cmd(['dpkg', '-s', package])\n        return cls.run_shell_command(cmd)\n\n    @classmethod\n    def _package_exists(cls, package):\n        cmd = compose_cmd(\n            ['dpkg', '--get-selections', '|', 'grep', '-v', 'deinstall', '|', 'cut', '-f1']\n        )\n        installed_packages = cls.run_shell_command(cmd)\n\n        # Ensure full match of package names.\n        is_installed = True if package in installed_packages.split('\\n') else False\n        return is_installed\n\n    @classmethod\n    def _parse_deps(cls, deps: str):\n        ret = []\n        deps = deps.replace(\"|\", \",\").replace(\"(\", \"\").replace(\")\", \"\")\n        pkgs = deps.split(\",\")\n        for pkg in pkgs:\n            if not pkg:\n                continue\n            name_ver = pkg.strip(\" \").split(\" \", maxsplit=1)\n            name = name_ver[0].strip(\" \\n\")\n            if len(name_ver) == 1:\n                ret.append(name)\n            else:\n                ver = name_ver[1].strip(\"()<>= \\n\")\n                # TODO generally wrong logic since it replaces any\n                # fuzzy (>=, < etc.) constraints with equality\n                ret.append(\"{}={}\".format(name, ver))\n        return ret\n\n    @classmethod\n    def _pkgs_dedup(cls, deps):\n        ret = []\n        processed = set()\n        for d in deps:\n            name_ver = d.split(\"=\", maxsplit=1)\n            if name_ver[0] not in processed:\n                ret.append(d)\n            processed.add(name_ver[0])\n        return ret\n\n    @classmethod\n    def _parse_version_deps_from_pkg_mgr_output(\n            cls,\n            output: str,\n            upstream_cls: Type[Union[SourceVersion, None]] = None\n    ):\n        out_lines = output.split(\"\\n\")\n        ver = None\n        ext_deps = []\n        num_pkgs = 0\n        for ln in out_lines:\n            act_line = ln.strip(\" \\n\")\n            if act_line.startswith(\"Version:\"):\n                # this method might be used for the dependnecy tree resolving\n                # when 'output' includes data for multiple packages,\n                # version info here doesn't make any sense in such a case\n                num_pkgs += 1\n                ver = (None if num_pkgs > 1 else\n                       act_line.split(\":\", maxsplit=1)[1].strip(\" \\n\"))\n            if act_line.startswith(\"Depends:\"):\n                ext_deps += cls._parse_deps(act_line.split(\":\", maxsplit=1)[1].strip(\" \\n\"))\n\n        if ver and upstream_cls:\n            try:\n                ver = DebianVersion(ver, upstream_cls=upstream_cls)\n            except InvalidVersionError as exc:\n                logger.warning(\n                    \"Failed to parse debian version {}: {}\"\n                    .format(ver, exc)\n                )\n                ver = None\n                ext_deps = []\n        else:\n            ver = None\n\n        return ver, cls._pkgs_dedup(ext_deps)\n\n    @classmethod\n    def curr_pkg_info(cls, pkg_name: str) -> Tuple[PackageVersion, List]:\n        package_info = cls._get_curr_info(pkg_name)\n        return cls._parse_version_deps_from_pkg_mgr_output(\n            package_info, upstream_cls=src_version_cls(pkg_name))\n\n    @classmethod\n    def get_latest_pkg_version(\n            cls,\n            pkg_name: str,\n            upstream: SourceVersion = None,\n            update_cache: bool = True) -> PackageVersion:\n\n        upstream_cls = src_version_cls(pkg_name)\n\n        if upstream and not isinstance(upstream, upstream_cls):\n            raise TypeError(\n                \"'upstream' should be instance of {}, got {}\"\n                .format(upstream_cls, type(upstream))\n            )\n\n        if update_cache:\n            cls.update_package_cache()\n\n        try:\n            cmd = compose_cmd(\n                ['apt-cache', 'show', pkg_name, '|', 'grep', '-E', \"'^Version: '\"]\n            )\n            output = cls.run_shell_script_extended(cmd).strip()\n        except ShellError as exc:\n            # will fail if either package not found or grep returns nothing\n            # the latter is unexpected and treated as no-data as well\n            logger.info(\n                \"no data for package '{}' found\".format(pkg_name)\n            )\n        else:\n            if output:\n                versions = []\n\n                for v in output.split('\\n'):\n                    try:\n                        dv = DebianVersion(v.split()[1], upstream_cls=upstream_cls)\n                    except InvalidVersionError as exc:\n                        logger.warning(\n                            \"ignoring invalid version from output {} for upstream class {}: {}\"\n                            .format(v.split()[1], upstream_cls, exc)\n                        )\n                    else:\n                        if not upstream or (dv.upstream == upstream):\n                            versions.append(dv)\n\n                try:\n                    return sorted(versions)[-1]\n                except IndexError:\n                    pass\n                except ShellError:\n                    logger.warning(\n                        \"version comparison failed unexpectedly for versions: {}\"\n                        .format(versions)\n                    )\n\n        return None\n\n    @classmethod\n    def _get_info_from_package_manager(cls, *package):\n        cmd_arg = \" \".join(list(package))\n        cmd = compose_cmd(['apt-cache', 'show', cmd_arg])\n        return cls.run_shell_command(cmd)\n\n    @classmethod\n    def update_package_cache(cls):\n        cmd = compose_cmd(['apt', 'update'])\n        try:\n            cls.run_shell_script(cmd)\n        except Exception as e:\n            # Currently two issues can stop this from working.\n            # 1) The Sovrin Repo key needs to be updated\n            #    apt-key adv --keyserver keyserver.ubuntu.com --recv-keys CE7709D068DB5E88\n            # 2) The following certificate validation error occurs:\n            #       Err:6 https://repo.sovrin.org/deb xenial Release\n            #         server certificate verification failed. CAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none\n            #       Reading package lists... Done\n            #       E: The repository 'https://repo.sovrin.org/deb xenial Release' does not have a Release file.\n            #       N: Updating from such a repository can't be done securely, and is therefore disabled by default.\n            #       N: See apt-secure(8) manpage for repository creation and user configuration details.\n            #    This can be fixed by updating libgnutls30:\n            #    apt --only-upgrade install -y libgnutls30\n            logger.warning(\"Call to apt update failed in update_package_cache; {}\".format(e))\n            cls.update_repo_keys()\n            cls.update_apt_update_dependencies()\n\n            # Try again ...\n            logger.info(\"Trying apt update again ...\")\n            cls.run_shell_script(cmd)\n\n    @classmethod\n    def update_repo_keys(cls):\n        logger.info(\"Updating signing keys for the artifact repository ...\")\n        cmd = compose_cmd(['apt-key', 'adv', '--keyserver', 'keyserver.ubuntu.com', '--recv-keys', 'CE7709D068DB5E88'])\n        cls.run_shell_script(cmd)\n\n    @classmethod\n    def update_apt_update_dependencies(cls):\n        cmd = compose_cmd(['apt', 'list', '--upgradable'])\n        logger.info(\"Getting list of upgradable packages ...\")\n        upgradable_packages = cls.run_shell_command(cmd).split(\"\\n\")\n        libgnutls30 = next((x for x in upgradable_packages if x.find('libgnutls30') != -1), None)\n        if libgnutls30 is not None:\n            logger.info(\"Upgrading libgnutls30 ...\")\n            cmd = compose_cmd(['apt', '--only-upgrade', 'install', '-y', 'libgnutls30'])\n            cls.run_shell_script(cmd)\n        else:\n            logger.info(\"libgnutls30 is already up to date.\")\n\n    @classmethod\n    def get_deps_tree(cls, *package, depth=0):\n        ret = list(set(package))\n        if depth < MAX_DEPS_DEPTH:\n            package_info = cls._get_info_from_package_manager(*ret)\n            _, deps = cls._parse_version_deps_from_pkg_mgr_output(package_info)\n            deps_deps = []\n            deps = list(set(deps) - set(ret))\n            deps_deps.append(cls.get_deps_tree(*deps, depth=depth + 1))\n\n            ret.append(deps_deps)\n        return ret\n\n    @classmethod\n    def get_deps_tree_filtered(cls, *package, hold_list=[], depth=0, deps_map={}):\n        ret = list(set(package))\n        if depth < MAX_DEPS_DEPTH:\n            package_info = cls._get_info_from_package_manager(*ret)\n            _, deps = cls._parse_version_deps_from_pkg_mgr_output(package_info)\n            # Make deps list unique\n            deps = list(set(deps + ret))\n            for d in deps:\n                if \"=\" in d:\n                    p, v = d.split(\"=\")\n                else:\n                    p = d\n                    v = ''\n                if p in hold_list and \\\n                        (p not in deps_map or deps_map[p] == ''):\n                    deps_map[p] = v\n            cls.get_deps_tree_filtered(*deps, hold_list=hold_list, depth=depth + 1, deps_map=deps_map)\n\n        return [\"{}={}\".format(p, v) if v != '' else p for p, v in deps_map.items()]\n\n    @classmethod\n    def dep_tree_traverse(cls, dep_tree, deps_so_far):\n        if isinstance(dep_tree, str) and dep_tree not in deps_so_far:\n            deps_so_far.append(dep_tree)\n        elif isinstance(dep_tree, list) and dep_tree:\n            for d in reversed(dep_tree):\n                cls.dep_tree_traverse(d, deps_so_far)\n\n    @classmethod\n    def get_sys_holds(cls):\n        if shutil.which(\"apt-mark\"):\n            cmd = compose_cmd(['apt-mark', 'showhold'])\n            ret = cls.run_shell_command(cmd)\n\n            hlds = ret.strip().split(\"\\n\")\n            return [h for h in hlds if h]\n        else:\n            logger.info('apt-mark not found. Assume holds is empty.')\n            return []\n\n    @classmethod\n    def hold_packages(cls, packages):\n        if shutil.which(\"apt-mark\"):\n            packages_to_hold = ' '.join(packages)\n            cmd = compose_cmd(['apt-mark', 'hold', packages_to_hold])\n            cls.run_shell_script(cmd)\n            logger.info('Successfully put {} packages on hold'.format(packages_to_hold))\n        else:\n            logger.info('Skipping packages holding')\n"], "filenames": ["indy_common/test/test_util.py", "indy_common/util.py", "indy_node/server/request_handlers/config_req_handlers/pool_upgrade_handler.py", "indy_node/test/node_control_utils/test_node_control_util.py", "indy_node/test/request_handlers/test_pool_upgrade_handler.py", "indy_node/utils/node_control_utils.py"], "buggy_code_start_loc": [0, 3, 0, 0, 73, 201], "buggy_code_end_loc": [14, 145, 101, 178, 109, 344], "fixing_code_start_loc": [1, 4, 1, 1, 74, 202], "fixing_code_end_loc": [46, 148, 104, 410, 150, 403], "type": "CWE-20", "message": "Indy Node is the server portion of a distributed ledger purpose-built for decentralized identity. In versions 1.12.4 and prior, the `pool-upgrade` request handler in Indy-Node allows an improperly authenticated attacker to remotely execute code on nodes within the network. The `pool-upgrade` request handler in Indy-Node 1.12.5 has been updated to properly authenticate pool-upgrade transactions before any processing is performed by the request handler. The transactions are further sanitized to prevent remote code execution. As a workaround, endorsers should not create DIDs for untrusted users. A vulnerable ledger should configure `auth_rules` to prevent new DIDs from being written to the ledger until the network can be upgraded.", "other": {"cve": {"id": "CVE-2022-31020", "sourceIdentifier": "security-advisories@github.com", "published": "2022-09-06T17:15:08.220", "lastModified": "2022-09-13T14:23:14.737", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Indy Node is the server portion of a distributed ledger purpose-built for decentralized identity. In versions 1.12.4 and prior, the `pool-upgrade` request handler in Indy-Node allows an improperly authenticated attacker to remotely execute code on nodes within the network. The `pool-upgrade` request handler in Indy-Node 1.12.5 has been updated to properly authenticate pool-upgrade transactions before any processing is performed by the request handler. The transactions are further sanitized to prevent remote code execution. As a workaround, endorsers should not create DIDs for untrusted users. A vulnerable ledger should configure `auth_rules` to prevent new DIDs from being written to the ledger until the network can be upgraded."}, {"lang": "es", "value": "Indy Node es la parte del servidor de un libro mayor distribuido construido para la identidad descentralizada. En versiones 1.12.4 y anteriores, el administrador de peticiones \"pool-upgrade\" de Indy-Node permite a un atacante autenticado ejecutar c\u00f3digo de forma remota en nodos de la red. El administrador de peticiones \"pool-upgrade\" en Indy-Node versi\u00f3n 1.12.5, ha sido actualizado para autenticar apropiadamente las transacciones de pool-upgrade antes de que el administrador de peticiones las lleve a cabo. Las transacciones son saneadas adem\u00e1s para evitar una ejecuci\u00f3n de c\u00f3digo remota. Como mitigaci\u00f3n, los endosantes no deber\u00edan crear DIDs para usuarios no confiables. Un libro mayor vulnerable deber\u00eda configurar \"auth_rules\" para evitar que sean escritos nuevos DID en el libro mayor hasta que la red pueda ser actualizada.\n"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 8.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 2.8, "impactScore": 5.9}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}, {"lang": "en", "value": "CWE-287"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:indy-node:*:*:*:*:*:*:*:*", "versionEndIncluding": "1.12.4", "matchCriteriaId": "D7BDE3C0-0C97-4373-9BA4-EB3A9D1D177D"}]}]}], "references": [{"url": "https://github.com/hyperledger/indy-node/commit/fe507474f77084faef4539101e2bbb4d508a97f5", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/hyperledger/indy-node/releases/tag/v1.12.5", "source": "security-advisories@github.com", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "https://github.com/hyperledger/indy-node/security/advisories/GHSA-r6v9-p59m-gj2p", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/hyperledger/indy-node/commit/fe507474f77084faef4539101e2bbb4d508a97f5"}}
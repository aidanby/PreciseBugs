{"buggy_code": ["package prolod.common.config\n\nimport java.io.{File, FileNotFoundException}\nimport java.sql._\nimport java.{lang, util}\n\nimport com.ibm.db2.jcc.am.{SqlDataException, SqlException, SqlIntegrityConstraintViolationException, SqlSyntaxErrorException}\nimport com.typesafe.slick.driver.db2.DB2Driver.api._\nimport play.api.libs.json._\nimport prolod.common.models.PatternFormats.patternDBFormat\nimport prolod.common.models.{Dataset, Group, Pattern, PatternFromDB, _}\nimport slick.jdbc.{StaticQuery => Q}\nimport slick.profile.SqlStreamingAction\n\nimport scala.Function._\nimport scala.collection.JavaConverters._\nimport scala.collection.mutable\nimport scala.concurrent.Await\nimport scala.concurrent.duration.Duration\nimport scala.io.Source\n\n/*\ncase class Schemata(id : String, schema_name : String, entities : Int, tuples : Int)\n\nclass Schematas(tag: Tag)\nextends Table[Schemata](tag, \"PROLOD_MAIN.SCHEMATA\") {\n\ndef id = column[String](\"id\", O.PrimaryKey)\ndef schema_name = column[String](\"schema_name\", O.NotNull)\ndef entities = column[Int](\"entities\", O.NotNull)\ndef tuples = column[Int](\"tuples\", O.NotNull)\n\ndef * = (id, schema_name, entities, tuples) <> (Schemata.tupled, Schemata.unapply)\n}\n*/\n\nclass DatabaseConnection(config : Configuration) {\n\tvar driver = com.typesafe.slick.driver.db2.DB2Driver.api\n\n\tval url = \"jdbc:db2://\"+config.dbDb2Host+\":\"+config.dbDb2Port+\"/\"+config.dbDb2Database\n\tval username = config.dbDb2Username\n\tval password = config.dbDb2Password\n\t// Class.forName(\"com.typesafe.slick.driver.db2.DB2Driver\")\n\tClass.forName(\"com.ibm.db2.jcc.DB2Driver\")\n\t// DriverManager.getConnection(url, username, password)\n\n\tval db:Database = Database.forURL(url, username, password, driver=\"com.ibm.db2.jcc.DB2Driver\")\n\tvar connection:Connection = DriverManager.getConnection(url, username, password)\n\n\t/**\n\t * execute sql and convert async result to sync - http://slick.typesafe.com/doc/3.0.0/sql.html\n\t */\n\tdef execute[T](implicit sql: SqlStreamingAction[Vector[T], T, Effect]): Vector[T] = {\n\t\tval q = db.run(sql)\n\t\tAwait.result(q, Duration.Inf)\n\t\tval value = q.value.get\n\t\tvalue.get\n\t}\n\n\tdef dropTables(name : String): Unit = {\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"DROP TABLE \"+name+\".patterns\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"DROP TABLE \"+name+\".coloredpatterns\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"DROP TABLE \"+name+\".graphstatistics\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tvar createStatement = connection.createStatement()\n\t\t\tvar createResultSet = createStatement.execute(\"DROP TABLE \"+name+\".CLUSTERS\")\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\n\t\tval sqlDir = new File(\"prolod-preprocessing/sql/\")\n\t\tfor (file <- sqlDir.listFiles) {\n\t\t\ttry {\n\t\t\t\tval queryString = Source.fromFile(file.getPath).mkString\n\t\t\t\tval query = String.format(queryString, name)\n\t\t\t\ttry {\n\t\t\t\t\tgetTableNameFromStatement(queryString) match {\n\t\t\t\t\t\tcase tableName => {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tvar dropStatement = connection.createStatement()\n\t\t\t\t\t\t\t\tvar tableNamenormalized = tableName\n\t\t\t\t\t\t\t\tif (tableName.equals(\"\")) tableNamenormalized = file.getName.replace(\".sql\", \"\")\n\t\t\t\t\t\t\t\tdropStatement.execute(\"DROP TABLE \" + name + \".\" + tableNamenormalized)\n\t\t\t\t\t\t\t\tdropStatement.close()\n\t\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} catch {\n\t\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t\t\tcase e : FileNotFoundException =>  println(e.getMessage)\n\t\t\t}\n\t\t}\n\t}\n\n\tdef createTables(name : String): Unit = {\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tval createResultSet = createStatement.execute(\"CREATE SCHEMA \" + name)\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"CREATE TABLE \"+name+\".patterns (id INT, name VARCHAR(200), pattern CLOB, occurences INT, diameter FLOAT, nodedegreedistribution CLOB)\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"CREATE TABLE \"+name+\".coloredpatterns (id INT, pattern CLOB)\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tval createResultSet = createStatement.execute(\"CREATE TABLE \"+name+\".graphstatistics (nodedegreedistribution CLOB, averagelinks FLOAT, edges INT, connectedcomponents INT, stronglyconnectedcomponents INT, gcnodes INT, gcedges INT, highestIndegrees CLOB, highestOutdegrees CLOB)\")\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tvar createStatement = connection.createStatement()\n\t\t\tvar createResultSet = createStatement.execute(\"CREATE TABLE \"+name+\".CLUSTERS \"+\n\t\t\t\t\"(                                                                   \"+\n\t\t\t\t\"       ID INT NOT NULL GENERATED ALWAYS AS IDENTITY(START WITH 1 INCREMENT BY 1),    \"+\n\t\t\t\t\"USERNAME VARCHAR(50) DEFAULT 'default' NOT NULL,       \"+\n\t\t\t\t//\"SESSION_ID INT NOT NULL,                    \"+\n\t\t\t\t//\"SESSION_LOCAL_ID INT,                  \"+\n\t\t\t\t\"LABEL VARCHAR(255),                      \"+\n\t\t\t\t//\"CHILD_SESSION INT,                         \"+\n\t\t\t\t//\"AVG_ERROR FLOAT(53),                         \"+\n\t\t\t\t\"CLUSTER_SIZE INT,                              \"+\n\t\t\t\t//\"PARTITIONNAME VARCHAR(255) DEFAULT 'MAINTABLE', \"+\n\t\t\t\t\"PRIMARY KEY (ID, USERNAME)                                \"+\n\t\t\t\t\")\")\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\n\t\tval sqlDir = new File(\"prolod-preprocessing/sql/\")\n\t\tfor (file <- sqlDir.listFiles) {\n\t\t\ttry {\n\t\t\t\tval queryString = Source.fromFile(file.getPath).mkString\n\t\t\t\tval query = String.format(queryString, name)\n\t\t\t\ttry {\n\t\t\t\t\tval statement = connection.prepareStatement(query)\n\t\t\t\t\tstatement.execute\n\t\t\t\t\tstatement.close()\n\t\t\t\t} catch {\n\t\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t\t\tcase e : FileNotFoundException =>  println(e.getMessage)\n\t\t\t}\n\t\t}\n\t}\n\n\tdef createIndices(name: String) = {\n\t\tval sqlDir = new File(\"prolod-preprocessing/sql/indices/\")\n\t\tfor (file <- sqlDir.listFiles) {\n\t\t\ttry {\n\t\t\t\tval queryString = Source.fromFile(file.getPath).mkString\n\t\t\t\tval r = \"/\\\\*[\\\\s\\\\S]*?\\\\*/|--[^\\\\r\\\\n]*|;\"\n\t\t\t\tval queries = queryString.split(r)\n\t\t\t\tfor (queryString <- queries) {\n\t\t\t\t\tval query = String.format(queryString, name)\n\t\t\t\t\ttry {\n\t\t\t\t\t\tval statement = connection.prepareStatement(query)\n\t\t\t\t\t\tstatement.execute\n\t\t\t\t\t\tstatement.close()\n\t\t\t\t\t} catch {\n\t\t\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t\t\tcase e : FileNotFoundException =>  println(e.getMessage)\n\t\t\t}\n\t\t}\n\n\t}\n\n\tdef getTableNameFromStatement(s: String) : String = {\n\t\tval pattern = \"\"\"%s.(.*)\"\"\".r\n\n\t\ts match {\n\t\t\tcase pattern(group) => {\n\t\t\t\tprintln(group)\n\t\t\t\tgroup\n\t\t\t}\n\t\t\tcase _ => {\n\t\t\t\tprintln(\"\")\n\t\t\t\t\"\"\n\t\t\t}\n\t\t}\n\t\t/*\n\t\tvar result = pattern.findFirstIn(s).gro//for (m <- pattern findFirstIn s) yield m\n\t\tprintln(s + result)\n\t\tresult                */\n\t}\n\n\tdef getClusters(s: String, ontologyNamespace : String): Seq[Group] = {\n\t\tval table = s\n\t\tval sql = sql\"SELECT label, cluster_size FROM #${table}.CLUSTERS WHERE username = 'ontology' ORDER BY label\".as[(String, Int)]\n\t\tvar id : Int = -1\n\t\ttry {\n\t\t\tval result = execute(sql)\n\t\t\tresult map tupled((label, cluster_size) => {\n\t\t\t\tid += 1\n\t\t\t\tnew Group(id, removeOntologyNamespace(label, ontologyNamespace), cluster_size)\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(\"This dataset has no clusters: \" + s)\n\t\t\tNil\n\t\t}\n\t}\n\n\n\tprivate def removeOntologyNamespace(name: String, ontologyNamespace: String): String = {\n\t\tvar result = name\n\t\tif (ontologyNamespace != null) {\n\t\t\tif (ontologyNamespace.startsWith(\"\\\"group\\\":\\\"\")) {\n\t\t\t\tresult = result.replace(ontologyNamespace, \"\\\"group\\\":\\\"\")\n\t\t\t} else {\n\t\t\t\tresult = result.replace(ontologyNamespace, \"\")\n\t\t\t}\n\t\t}\n\t\tresult\n\t}\n\n\tdef getDatasetEntities(name : String) : Int = {\n\t\tval sql = sql\"SELECT entities FROM PROLOD_MAIN.SCHEMATA WHERE id = ${name}\".as[Int]\n\t\texecute(sql).headOption.getOrElse(-1)\n\t}\n\n\tdef getDatasets(): Seq[Dataset] = {\n\t\tvar datasets: List[Dataset] = Nil\n\n\t\tval sql = sql\"SELECT id, schema_name, entities, ontology_namespace FROM PROLOD_MAIN.SCHEMATA ORDER BY LOWER(schema_name)\".as[(String, String, Int, String)]\n\n\t\tval result = execute(sql) map tupled((id, schema, entities, ontology_namespace) => {\n\t\t\tnew Dataset(id, schema, entities, getClusters(id, ontology_namespace))\n\t\t})\n\t\tresult.filter(_.size > 0)\n\t}\n\n\n\tdef getStatistics(dataset: String) : mutable.Map[String, String] = {\n\t\tval statistics = mutable.Map[String, String]()\n\t\tval sql = sql\"SELECT nodedegreedistribution, averagelinks, edges, connectedcomponents, stronglyconnectedcomponents FROM #$dataset.graphstatistics\".as[(String, Float, Int, Int, Int)]\n\t\ttry {\n\t\t\tval result = execute(sql) map tupled((nodedegreedistribution, averagelinks, edges, connectedcomponents, stronglyconnectedcomponents) => {\n\t\t\t\tstatistics += (\"nodedegreedistribution\" -> nodedegreedistribution)\n\t\t\t\tstatistics += (\"averagelinks\" -> averagelinks.toString)\n\t\t\t\tstatistics += (\"edges\" -> edges.toString)\n\t\t\t\tstatistics += (\"connectedcomponents\" -> connectedcomponents.toString)\n\t\t\t\tstatistics += (\"stronglyconnectedcomponents\" -> stronglyconnectedcomponents.toString)\n\t\t\t})\n\t\t\tval sql2 = sql\"SELECT gcnodes, highestIndegrees, highestOutdegrees FROM #$dataset.graphstatistics\".as[(Int, String, String)]\n\t\t\tval result2 = execute(sql2) map tupled((gcnodes, highestIndegrees, highestOutdegrees) => {\n\t\t\t\tstatistics += (\"gcnodes\" -> gcnodes.toString)\n\t\t\t\tstatistics += (\"highestIndegrees\" -> highestIndegrees)\n\t\t\t\tstatistics += (\"highestOutdegrees\" -> highestOutdegrees)\n\t\t\t})\n\t\t\tval sql3 = sql\"SELECT gcedges FROM #$dataset.graphstatistics\".as[Int]\n\t\t\tval result3 = execute(sql3) map ((gcedges) => {\n\t\t\t\tstatistics += (\"gcedges\" -> gcedges.toString)\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e: SqlSyntaxErrorException => {\n\t\t\t\tval sql2 = sql\"SELECT gcnodes FROM #$dataset.graphstatistics\".as[(Int)]\n\t\t\t\tval result2 = execute(sql2) map ((gcnodes) => {\n\t\t\t\t\tstatistics += (\"gcnodes\" -> gcnodes.toString)\n\t\t\t\t})\n\t\t\t\tprintln(e.getMessage + System.lineSeparator() + sql.toString)\n\t\t\t}\n\t\t}\n\t\tstatistics\n\t}\n\n\tdef getColoredPatterns(dataset: String, id: Int): List[Pattern] = {\n\t\tvar patterns : List[Pattern] = Nil\n\t\tval sql = sql\"SELECT ontology_namespace FROM PROLOD_MAIN.SCHEMATA WHERE ID = ${dataset}\".as[String]\n\t\tval namespaces: Vector[String] = execute(sql) map (ontology_namespace => {\n\t\t\t\t\"\\\"group\\\":\\\"\" + ontology_namespace.replace(\"/\", \"\\\\/\")\n\t\t})\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.executeQuery(\"SELECT pattern FROM \"+ dataset+\".COLOREDPATTERNS WHERE id = \"+id)\n\t\t\twhile ( resultSet.next() ) {\n\t\t\t\tvar pattern = resultSet.getString(\"pattern\")\n\t\t\t\tnamespaces foreach (ontology_namespace => {\n\t\t\t\t\t pattern = removeOntologyNamespace(pattern, ontology_namespace)\n\t\t\t\t})\n\t\t\t\t// val occurences = resultSet.getInt(\"occurences\")\n\n\t\t\t\tval patternJsonT = Json.parse(pattern).validate[PatternFromDB]\n\t\t\t\tval patternsV = List(patternJsonT).filter(p => p.isSuccess).map(p => p.get)\n\t\t\t\tval errors = List(patternJsonT).filter(p => p.isError)\n\t\t\t\tif (errors.nonEmpty) {\n\t\t\t\t\tprintln(\"Could not validate \" + errors)\n\t\t\t\t}\n\t\t\t\tval patternJson = Json.parse(pattern).validate[PatternFromDB].get\n\t\t\t\tpatterns :::= List(new Pattern(id, \"\", -1, patternJson.nodes, patternJson.links)) // new Pattern(id, \"\", occurences, Nil, Nil)\n\t\t\t}\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(\"This dataset has no patterns: \" + dataset)\n\t\t}\n\t\tpatterns\n\t}\n\n\tdef getPatterns(s: String): List[Pattern] = {\n\t\tvar patterns : List[Pattern] = Nil\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.executeQuery(\"SELECT id, name, pattern, occurences FROM \"+ s+\".PATTERNS ORDER BY occurences ASC\")\n\t\t\twhile ( resultSet.next() ) {\n\t\t\t\tval id = resultSet.getInt(\"id\")\n\t\t\t\tval pattern = resultSet.getString(\"pattern\")\n\t\t\t\tval occurences = resultSet.getInt(\"occurences\")\n\t\t\t\tval name = resultSet.getString(\"name\")\n\t\t\t\t//val diameter = resultSet.getDouble(\"diameter\")\n\t\t\t\tval patternJson = Json.parse(pattern).validate[PatternFromDB].get\n\t\t\t\tpatterns :::= List(new Pattern(id, name, occurences, patternJson.nodes, patternJson.links)) // new Pattern(id, \"\", occurences, Nil, Nil)\n\t\t\t}\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(\"This dataset has no patterns: \" + s)\n\t\t}\n\t\tpatterns\n\t}\n\n\tdef getPatternDiameter(dataset: String, patternId: Int) : Int = {\n\t\tvar diameter : Int = 0\n\t\ttry {\n\t\t\tval sql = sql\"SELECT diameter FROM #${dataset}.patterns WHERE id = #${patternId}\".as[(Int)]\n\t\t\tval result = execute(sql)\n\t\t\tresult map ((diameterSql) => {\n\t\t\t\tdiameter = diameterSql\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\tdiameter\n\t}\n\n\tdef getEntityDetails(dataset: String, subjectId: Int): Entity = {\n\t\tvar triples : List[Triple] = Nil\n\t\tvar label : String = \"\"\n\t\tvar subjectUri = \"\"\n\t\tvar predicateUri = \"\"\n\t\tvar objectUri = \"\"\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.executeQuery(\"SELECT tuple_id, predicate_id FROM \"+ dataset+\".maintable WHERE subject_id = \"+subjectId)\n\t\t\twhile ( resultSet.next() ) {\n\t\t\t\tval objectId = resultSet.getString(\"tuple_id\")\n\t\t\t\tval predicateId = resultSet.getString(\"predicate_id\")\n\n\t\t\t\tval statement1 = connection.createStatement()\n\t\t\t\tval resultSet1 = statement1.executeQuery(\"SELECT subject FROM \"+ dataset+\".subjecttable WHERE id = \"+subjectId)\n\t\t\t\twhile ( resultSet1.next() ) {\n\t\t\t\t\tsubjectUri = resultSet1.getString(\"subject\")\n\t\t\t\t}\n\t\t\t\tstatement1.close()\n\n\t\t\t\tval statement2 = connection.createStatement()\n\t\t\t\tval resultSet2 = statement2.executeQuery(\"SELECT predicate FROM \"+ dataset+\".predicatetable WHERE id = \"+predicateId)\n\t\t\t\twhile ( resultSet2.next() ) {\n\t\t\t\t\tpredicateUri = resultSet2.getString(\"predicate\")\n\t\t\t\t}\n\t\t\t\tstatement2.close()\n\n\t\t\t\tval statement3 = connection.createStatement()\n\t\t\t\tval resultSet3 = statement3.executeQuery(\"SELECT object FROM \"+ dataset+\".objecttable WHERE tuple_id = \"+objectId)\n\t\t\t\twhile ( resultSet3.next() ) {\n\t\t\t\t\tobjectUri = resultSet3.getString(\"object\")\n\t\t\t\t\tif (predicateUri.equals(\"http://www.w3.org/2000/01/rdf-schema#label\")) {\n\t\t\t\t\t\tlabel = objectUri\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tstatement3.close()\n\n\t\t\t\ttriples :::= List(new Triple(subjectUri, predicateUri, objectUri))\n\t\t\t}\n\t\t\tstatement.close\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\n\t\tval entityDetails = new Entity(subjectId, subjectUri, label, triples)\n\t\tentityDetails\n\t}\n\n\tdef insert: DBIO[Unit] = DBIO.seq(\n\t\t// sqlu\"INSERT INTO PROLOD_MAIN.SCHEMATA ('ID', 'SCHEMA_NAME', 'TUPLES', 'ENTITIES') VALUES ('caterpillar','caterpillar',20,3)\"\n\t)\n\n\tdef replaceDatasetName(query: String, name: String) = {\n\t\tquery.replace(\"##dataset##\", name)\n\t}\n\n\tdef insertDataset(name : String, tuples: Int, entities: Int, ontologyNamespace : String, namespace : String) {\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.execute(\"INSERT INTO PROLOD_MAIN.SCHEMATA (ID, SCHEMA_NAME, TUPLES, ENTITIES, ONTOLOGY_NAMESPACE, NAMESPACE) VALUES ('\"+name+\"','\"+name+\"',\"+tuples+\",\"+entities+\",'\"+ontologyNamespace+\"','\"+namespace+\"')\")\n\t\t} catch {\n\t\t\tcase e : SqlIntegrityConstraintViolationException => println(\"Dataset already exists\")\n\t\t}\n\t}\n\n\tdef insertPatterns(name: String, patterns: util.HashMap[Integer, util.HashMap[String, Integer]], coloredPatterns: util.HashMap[Integer, util.List[String]], diameter: util.HashMap[Integer, lang.Double]) {\n\t\tval coloredPatternsMap = coloredPatterns.asScala.toMap\n\t\tval diameterMap = diameter.asScala.toMap\n\t\tval patternsMap = patterns.asScala.toMap\n\t\tpatternsMap.foreach {\n\t\t\tcase (id, patternHashMap) => {\n\t\t\t\tval patternHashMapScala = patternHashMap.asScala.toMap\n\t\t\t\tpatternHashMapScala.foreach {\n\t\t\t\t\tcase (pattern, occurences) => {\n\t\t\t\t\t\tval patternDiameter = diameterMap.get(id).get\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tval statement = connection.createStatement()\n\t\t\t\t\t\t\tval patternJson : PatternFromDB = Json.parse(pattern).validate[PatternFromDB].get\n\t\t\t\t\t\t\tval patternName = patternJson.name.getOrElse(\"\")\n\t\t\t\t\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".PATTERNS (ID, NAME, PATTERN, OCCURENCES, DIAMETER) VALUES (\" + id + \", '\" + patternName + \"',  '\" + pattern + \"',\" + occurences + \",\" + patternDiameter + \")\")\n\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\tcase e: SqlIntegrityConstraintViolationException => println(\"Pattern already exists\")\n\t\t\t\t\t\t\tcase e: SqlException => println(e.getMessage)\n\t\t\t\t\t\t\tcase e: SqlSyntaxErrorException => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".PATTERNS (ID, PATTERN, OCCURENCES, DIAMETER) VALUES (\" + id + \", '\" + pattern + \"',\" + occurences + \", \" + patternDiameter + \")\")\n\t\t\t\t\t\t}\n\t\t\t\t\t\tval cPattern = coloredPatternsMap.get(id).get.asScala.toList\n\t\t\t\t\t\tcPattern.foreach { case (coloredpattern) =>\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tval statement = connection.createStatement()\n\t\t\t\t\t\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".coloredpatterns (ID, PATTERN) VALUES (\" + id + \", '\" + coloredpattern + \"')\")\n\t\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\t\tcase e: SqlException => {\n\t\t\t\t\t\t\t\t\tprintln(e.getMessage)\n\t\t\t\t\t\t\t\t\tprintln(coloredpattern)\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tcase e: SqlSyntaxErrorException => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".coloredpatterns (ID, PATTERN) VALUES (\" + id + \", '\" + coloredpattern + \"')\")\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tclass RsIterator(rs: ResultSet) extends Iterator[ResultSet] {\n\t\tdef hasNext: Boolean = rs.next()\n\t\tdef next(): ResultSet = rs\n\t}\n\n\tdef performInsert(table: String, names: Seq[Any], values: Seq[Any]): Option[Int] = {\n\t\tval query = String.format(\"insert into %s (%s) values (%s)\",\n\t\t\ttable,\n\t\t\tcommaize(names.map(n => n.toString).toList),\n\t\t\tcommaize(values.map(v => \"'\" + v.toString.replace(\"'\", \"\") + \"'\").toList)\n\t\t)\n\t\ttry {\n\t\t\tval statement = connection.prepareStatement(query)\n\t\t\tstatement.execute\n\t\t\tval key = statement.getGeneratedKeys\n\t\t\tstatement.close()\n\t\t\tif(key.next) {\n\t\t\t\tkey.getInt(1)\n\t\t\t}\n\t\t} catch {\n\t\t\tcase e : SqlIntegrityConstraintViolationException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\tcase e : SqlDataException =>  println(e.getMessage +  System.lineSeparator() + query)\n\t\t}\n\t\tNone\n\t}\n\n\tprivate def commaize(list: List[_ <: Any]): String = list match {\n\t\tcase List()  => \"\"\n\t\tcase List(x) => x.toString\n\t\tcase _       => list.head + \", \" + commaize(list.tail)\n\t}\n\n\tdef insertSubject(name: String, s: String): Int = {\n\t\tperformInsert(name + \".subjecttable\", List(\"subject\"), List(s)) match {\n\t\t\tcase Some(i) => i\n\t\t\tcase None => getSubjectId(name, s)\n\t\t}\n\t}\n\n\tdef getSubjectId(dataset: String, s: String): Int = {\n\t\tvar result : Int = -1\n\t\tval statement = connection.createStatement()\n\t\ttry {\n\t\t\tval resultSet = statement.executeQuery(\"SELECT id FROM \" + dataset + \".subjecttable WHERE subject='\" + s + \"'\")\n\t\t\tresultSet.next()\n\t\t\tresult = resultSet.getInt(\"id\")\n\t\t} catch {\n\t\t\tcase e : SqlException => println(e.getMessage)\n\t\t\tcase e: SqlSyntaxErrorException  => println(e.getMessage)\n\t\t}\n\t\tstatement.close()\n\t\tresult\n\t}\n\n\tdef insertObject(name: String, s: String): Int = {\n\t\tperformInsert(name + \".objecttable\", List(\"object\"), List(s)) match {\n\t\t\tcase Some(i) => i\n\t\t\tcase None => {\n\t\t\t\ttry {\n\t\t\t\t\tgetObjectId(name, s)\n\t\t\t\t} catch {\n\t\t\t\t\tcase e: SqlSyntaxErrorException => {\n\t\t\t\t\t\tprintln(e.getMessage + System.lineSeparator() + s)\n\t\t\t\t\t\t-1\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tdef getObjectId(name: String, s: String): Int = {\n\t\tvar result : Int = -1\n\t\tval statement = connection.createStatement()\n\t\tval resultSet = statement.executeQuery(\"SELECT tuple_id FROM \" + name + \".objecttable WHERE object='\" + s.replace(\"'\", \"\") + \"'\")\n\t\tresultSet.next()\n\t\tresult = resultSet.getInt(\"tuple_id\")\n\t\tstatement.close()\n\t\tresult\n\t}\n\n\tdef getOntologyNamespace(s: String): String = {\n\t\tvar namespace :String = null\n\t\ttry {\n\t\t\tval sql = sql\"\"\"SELECT ONTOLOGY_NAMESPACE FROM PROLOD_MAIN.SCHEMATA WHERE SCHEMA_NAME = '#${s}'\"\"\".as[String]\n\t\t\tval result = execute(sql)\n\t\t\tresult map ((ns) => {\n\t\t\t\tnamespace = ns\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e: SqlException => println(e.getMessage + System.lineSeparator())\n\t\t\tcase e: SqlSyntaxErrorException   => println(e.getMessage + System.lineSeparator())\n\t\t}\n\t\tnamespace\n\t}\n\n\tdef getNamespace(s: String): String = {\n\t\tvar namespace :String = null\n\t\ttry {\n\t\t\tval sql = sql\"\"\"SELECT NAMESPACE FROM PROLOD_MAIN.SCHEMATA WHERE SCHEMA_NAME = '#${s}'\"\"\".as[String]\n\t\t\tval result = execute(sql)\n\t\t\tresult map ((ns) => {\n\t\t\t\tnamespace = ns\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e: SqlException => println(e.getMessage + System.lineSeparator())\n\t\t\tcase e: SqlSyntaxErrorException   => println(e.getMessage + System.lineSeparator())\n\t\t}\n\t\tnamespace\n\t}\n\n\tdef insertPredicate(name: String, s: String): Int = {\n\t\tperformInsert(name + \".predicatetable\", List(\"predicate\"), List(s)) match {\n\t\t\tcase Some(i) => i\n\t\t\tcase None => getPredicateId(name, s)\n\t\t}\n\t}\n\n\tdef getPredicateId(name: String, s: String): Int = {\n\t\tvar result : Int = -1\n\t\tval statement = connection.createStatement()\n\t\tval resultSet = statement.executeQuery(\"SELECT id FROM \" + name + \".predicatetable WHERE predicate='\" + s + \"'\")\n\t\tresultSet.next()\n\t\tresult = resultSet.getInt(\"id\")\n\t\tstatement.close()\n\t\tresult\n\t}\n\n\tdef insertTriples(name: String, s: Int, p: Int, o: Int): Unit = {\n\t\tperformInsert(name + \".maintable\", List(\"subject_id\", \"predicate_id\", \"tuple_id\"), List(s, p, o))\n\t\t/*\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".subjecttable (subject) VALUES ('\" + s + \"')\")\n\t\t\tprintln(resultSet)\n\t\t} catch {\n\t\t\tcase e: SqlIntegrityConstraintViolationException => println(e.getMessage)\n\t\t\tcase e: SqlException => println(e.getMessage)\n\t\t}\n\t\t*/\n\t}\n\n\tdef insertStatistics(name: String, nodes: String, links: Double, edges: Int, gcEdges : Int, gcNodes : Int, connectedcomponents : Int, stronglyconnectedcomponents : Int, highestIndegrees: String, highestOutdegrees: String) = {\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".graphstatistics (nodedegreedistribution, averagelinks, edges, gcnodes, gcedges, connectedcomponents, stronglyconnectedcomponents, highestIndegrees, highestOutdegrees) VALUES ('\" + nodes + \"',\" + links + \", \" + edges + \", \" + gcNodes + \", \" + gcEdges + \", \" + connectedcomponents + \", \" + stronglyconnectedcomponents + \",'\" + highestIndegrees + \"','\" + highestOutdegrees + \"')\")\n\t\t} catch {\n\t\t\tcase e: SqlIntegrityConstraintViolationException => println(e.getMessage)\n\t\t\tcase e: SqlException => println(e.getMessage)\n\t\t}\n\t}\n\n\tdef insertClasses(name: String, clusters: util.List[String]) = {\n\t\tval clusterUris = clusters.asScala.toList\n\t\tclusterUris.foreach {\n\t\t\tcase (cluster) =>\n\t\t\t\ttry {\n\t\t\t\t\tval statement = connection.createStatement()\n\t\t\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".clusters (label, cluster_size, username) VALUES ('\" + cluster + \"', 0 , 'ontology')\")\n\t\t\t\t} catch {\n\t\t\t\t\tcase e: SqlIntegrityConstraintViolationException => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".clusters (label, cluster_size, username) VALUES ('\" + cluster + \"', 0 , 'ontology')\")\n\t\t\t\t\tcase e: SqlException => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".clusters (label, cluster_size, username) VALUES ('\" + cluster + \"', 0 , 'ontology')\")\n\t\t\t\t\tcase e: SqlSyntaxErrorException   => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".clusters (label, cluster_size, username) VALUES ('\" + cluster + \"', 0 , 'ontology')\")\n\t\t\t\t}\n\t\t}\n\n\t}\n\n\tdef updateClusterSizes(dataset : String, ontologyNamespace : String) = {\n\t\tfor (cluster : Group <- getClusters(dataset, ontologyNamespace)) {\n\t\t\ttry {\n\t\t\t\tval sql = sql\"\"\"SELECT COUNT(*) FROM #${dataset}.MAINTABLE as m, #${dataset}.predicatetable as p, #${dataset}.objecttable as o WHERE m.predicate_id = p.id  AND o.tuple_id = m.tuple_id  AND p.predicate = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type' AND o.object = '#${ontologyNamespace}#${cluster.name}'\"\"\".as[(Int)]\n\t\t\t\tval result = execute(sql)\n\t\t\t\tvar clusterSize = 0\n\t\t\t\tresult map ((cluster_size) => {\n\t\t\t\t\tclusterSize = cluster_size\n\t\t\t\t})\n\n\t\t\t\tval statement = connection.createStatement()\n\t\t\t\tval resultSet = statement.execute(\"UPDATE \" + dataset + \".clusters SET cluster_size = \" + clusterSize + \" WHERE label = '\" + ontologyNamespace + cluster.name + \"'\")\n\t\t\t} catch {\n\t\t\t\tcase e: SqlIntegrityConstraintViolationException => println(e.getMessage)\n\t\t\t\tcase e: SqlException => println(e.getMessage + System.lineSeparator())\n\t\t\t\tcase e: SqlSyntaxErrorException   => println(e.getMessage + System.lineSeparator())\n\t\t\t}\n\t\t}\n\t}\n}\n", "package controllers.prolod.server\n\nimport play.api.libs.json._\nimport play.api.mvc.{Action, Controller}\nimport prolod.common.config.{Configuration, DatabaseConnection}\nimport prolod.common.models.GraphLodResultFormats.{graphLodResultFormat, mapIntIntFormat}\nimport prolod.common.models._\n\nobject GraphLod extends Controller {\n  def getGraphStatistics(datasetId: String, groups: List[String]) = Action {\n    val config = new Configuration()\n    val db = new DatabaseConnection(config)\n    val patternList: List[Pattern] = db.getPatterns(datasetId)\n    val data: GraphLodResult = GraphLodResult(datasetId)\n    val statistics = db.getStatistics(datasetId)\n\n    data.nodes = db.getDatasetEntities(datasetId)\n    data.edges = statistics.getOrElse(\"edges\", \"0\").toInt\n    data.averageLinks = statistics.getOrElse(\"averagelinks\", \"0\").toFloat\n    data.giantComponentNodes = statistics.getOrElse(\"gcnodes\", \"0\").toInt\n    data.giantComponentEdges = statistics.getOrElse(\"gcedges\", \"0\").toInt\n    data.patterns = patternList\n    data.connectedComponents = statistics.getOrElse(\"connectedcomponents\", \"0\").toInt\n    data.stronglyConnectedComponents = statistics.getOrElse(\"stronglyconnectedcomponents\", \"0\").toInt\n\n    statistics.get(\"nodedegreedistribution\") match {\n      case Some(ndd) => {\n        val nodeDegreeDistributionMap = Json.parse(statistics.get(\"nodedegreedistribution\").get).as[Map[Int, Int]]\n        data.nodeDegreeDistribution =  nodeDegreeDistributionMap\n      }\n      case None => println()\n    }\n\n    statistics.get(\"highestIndegrees\") match {\n      case Some(ndd) => {\n        val highestIndegreesMap = Json.parse(statistics.get(\"highestIndegrees\").get).as[Map[String, Int]]\n        var highestIndegreesCleanedMap : Map[String, Map[Int, Int]] = Map()\n        for ((key, value) <- highestIndegreesMap) {\n          var highestIndegreesInternalMap : Map[Int, Int] = Map()\n          highestIndegreesInternalMap += (db.getSubjectId(datasetId, key) -> value)\n          highestIndegreesCleanedMap += (key.replace(db.getNamespace(datasetId), datasetId + \":\") -> highestIndegreesInternalMap)\n        }\n        data.highestIndegrees = highestIndegreesCleanedMap\n      }\n      case None => println()\n    }\n\n    statistics.get(\"highestOutdegrees\") match {\n      case Some(ndd) => {\n        val highestOutdegreesMap = Json.parse(statistics.get(\"highestOutdegrees\").get).as[Map[String, Int]]\n        var highestOutdegreesCleanedMap : Map[String, Map[Int, Int]] = Map()\n        for ((key, value) <- highestOutdegreesMap) {\n          var highestOutdegreesInternalMap : Map[Int, Int] = Map()\n          highestOutdegreesInternalMap += (db.getSubjectId(datasetId, key) -> value)\n          highestOutdegreesCleanedMap += (key.replace(db.getNamespace(datasetId), datasetId + \":\") -> highestOutdegreesInternalMap)\n        }\n        data.highestOutdegrees =  highestOutdegreesCleanedMap\n      }\n      case None => println()\n    }\n\n    // TODO class distribution should go in here\n\n    val json = Json.obj(\"statistics\" -> data)\n    Ok(json)\n  }\n\n  def getGraphPatternStatistics(datasetId: String, groups: List[String], pattern: Int) = Action {\n    val config = new Configuration()\n    val db = new DatabaseConnection(config)\n    val data: GraphLodResult = GraphLodResult(datasetId)\n    val patternList: List[Pattern] = db.getColoredPatterns(datasetId, pattern)\n    var entitiesPerClass: Map[String, Int] = Map()\n    var entities = 0\n    data.connectedComponents = patternList.size\n    if (groups.nonEmpty) {\n      var newPatternList: List[Pattern] = Nil\n      for (pattern : Pattern <- patternList) {\n        var patternNotInGroups = false\n        var newNodes: List[Node] = Nil\n        var tempEntitiesPerClass: Map[String, Int] = Map()\n        for (node : Node <- pattern.nodes) {\n          var newNode : Node = node\n          val group = node.group.getOrElse(\"\")\n          if (!groups.contains(node.group.getOrElse(\"\"))) {\n            newNode = new Node(node.id, node.uri, None)\n          } else {\n            patternNotInGroups = true\n          }\n          if (group.length > 0) {\n            var entityCount = 0\n            if (tempEntitiesPerClass.contains(group)) {\n              entityCount = tempEntitiesPerClass.getOrElse(group, 0)\n            }\n            entityCount += 1\n            tempEntitiesPerClass += (group -> entityCount)\n          }\n          newNodes ::= newNode\n        }\n        if (groups.isEmpty || (groups.nonEmpty && patternNotInGroups)) {\n          newPatternList ::=new Pattern(pattern.id, pattern.name, pattern.occurences, newNodes, pattern.links)\n          entities += newNodes.size\n          for ((group, count) <- tempEntitiesPerClass) {\n            var entityCount = 0\n            if (entitiesPerClass.contains(group)) {\n              entityCount = entitiesPerClass.getOrElse(group, 0)\n            }\n            entityCount += count\n            entitiesPerClass += (group -> entityCount)\n          }\n        }\n      }\n      data.connectedComponents = newPatternList.size\n      data.patterns = newPatternList\n    } else {\n      data.patterns = patternList\n      for (pattern : Pattern <- patternList) {\n        var tempEntitiesPerClass: Map[String, Int] = Map()\n        for (node : Node <- pattern.nodes) {\n          val group = node.group.getOrElse(\"\")\n          if (group.length > 0) {\n            var entityCount = 0\n            if (tempEntitiesPerClass.contains(group)) {\n              entityCount = tempEntitiesPerClass.getOrElse(group, 0)\n            }\n            entityCount += 1\n            tempEntitiesPerClass += (group -> entityCount)\n          }\n        }\n        entities += pattern.nodes.size\n        for ((group, count) <- tempEntitiesPerClass) {\n          var entityCount = 0\n          if (entitiesPerClass.contains(group)) {\n            entityCount = entitiesPerClass.getOrElse(group, 0)\n          }\n          entityCount += count\n          entitiesPerClass += (group -> entityCount)\n        }\n      }\n    }\n\n    if (entities > 0) {\n      var classDistribution : Map[String, Double] = Map()\n      var entitiesUnknown = entities\n      for ((group, entityCount) <- entitiesPerClass) {\n         classDistribution += (group -> (entityCount.toDouble/entities))\n        entitiesUnknown -= entityCount\n      }\n      if (entitiesUnknown > 0) {\n        classDistribution += (\"unknown\" -> (entitiesUnknown.toDouble/entities))\n      }\n      data.nodes = entities\n      data.classDistribution =  classDistribution\n    }\n\n    val patternDiameter = db.getPatternDiameter(datasetId, data.patterns.last.id)\n    data.diameter = patternDiameter\n\n    val json = Json.obj(\"statistics\" -> data)\n    Ok(json)\n  }\n\n  def getBigComponent(dataset: String, groups: List[String], pattern: Int) = Action {\n    Ok(\"this is big!\")\n  }\n}\n"], "fixing_code": ["package prolod.common.config\n\nimport java.io.{File, FileNotFoundException}\nimport java.sql._\nimport java.{lang, util}\n\nimport com.ibm.db2.jcc.am.{SqlDataException, SqlException, SqlIntegrityConstraintViolationException, SqlSyntaxErrorException}\nimport com.typesafe.slick.driver.db2.DB2Driver.api._\nimport play.api.libs.json._\nimport prolod.common.models.PatternFormats.patternDBFormat\nimport prolod.common.models.{Dataset, Group, Pattern, PatternFromDB, _}\nimport slick.jdbc.{StaticQuery => Q}\nimport slick.profile.SqlStreamingAction\n\nimport scala.Function._\nimport scala.collection.JavaConverters._\nimport scala.collection.mutable\nimport scala.concurrent.Await\nimport scala.concurrent.duration.Duration\nimport scala.io.Source\n\n/*\ncase class Schemata(id : String, schema_name : String, entities : Int, tuples : Int)\n\nclass Schematas(tag: Tag)\nextends Table[Schemata](tag, \"PROLOD_MAIN.SCHEMATA\") {\n\ndef id = column[String](\"id\", O.PrimaryKey)\ndef schema_name = column[String](\"schema_name\", O.NotNull)\ndef entities = column[Int](\"entities\", O.NotNull)\ndef tuples = column[Int](\"tuples\", O.NotNull)\n\ndef * = (id, schema_name, entities, tuples) <> (Schemata.tupled, Schemata.unapply)\n}\n*/\n\nclass DatabaseConnection(config : Configuration) {\n\tvar driver = com.typesafe.slick.driver.db2.DB2Driver.api\n\n\tval url = \"jdbc:db2://\"+config.dbDb2Host+\":\"+config.dbDb2Port+\"/\"+config.dbDb2Database\n\tval username = config.dbDb2Username\n\tval password = config.dbDb2Password\n\t// Class.forName(\"com.typesafe.slick.driver.db2.DB2Driver\")\n\tClass.forName(\"com.ibm.db2.jcc.DB2Driver\")\n\t// DriverManager.getConnection(url, username, password)\n\n\tval db:Database = Database.forURL(url, username, password, driver=\"com.ibm.db2.jcc.DB2Driver\")\n\tvar connection:Connection = DriverManager.getConnection(url, username, password)\n\n\t/**\n\t * execute sql and convert async result to sync - http://slick.typesafe.com/doc/3.0.0/sql.html\n\t */\n\tdef execute[T](implicit sql: SqlStreamingAction[Vector[T], T, Effect]): Vector[T] = {\n\t\tval q = db.run(sql)\n\t\tAwait.result(q, Duration.Inf)\n\t\tval value = q.value.get\n\t\tvalue.get\n\t}\n\n\tdef dropTables(name : String): Unit = {\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"DROP TABLE \"+name+\".patterns\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"DROP TABLE \"+name+\".coloredpatterns\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"DROP TABLE \"+name+\".graphstatistics\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tvar createStatement = connection.createStatement()\n\t\t\tvar createResultSet = createStatement.execute(\"DROP TABLE \"+name+\".CLUSTERS\")\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\n\t\tval sqlDir = new File(\"prolod-preprocessing/sql/\")\n\t\tfor (file <- sqlDir.listFiles) {\n\t\t\ttry {\n\t\t\t\tval queryString = Source.fromFile(file.getPath).mkString\n\t\t\t\tval query = String.format(queryString, name)\n\t\t\t\ttry {\n\t\t\t\t\tgetTableNameFromStatement(queryString) match {\n\t\t\t\t\t\tcase tableName => {\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tvar dropStatement = connection.createStatement()\n\t\t\t\t\t\t\t\tvar tableNamenormalized = tableName\n\t\t\t\t\t\t\t\tif (tableName.equals(\"\")) tableNamenormalized = file.getName.replace(\".sql\", \"\")\n\t\t\t\t\t\t\t\tdropStatement.execute(\"DROP TABLE \" + name + \".\" + tableNamenormalized)\n\t\t\t\t\t\t\t\tdropStatement.close()\n\t\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} catch {\n\t\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t\t\tcase e : FileNotFoundException =>  println(e.getMessage)\n\t\t\t}\n\t\t}\n\t}\n\n\tdef createTables(name : String): Unit = {\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tval createResultSet = createStatement.execute(\"CREATE SCHEMA \" + name)\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"CREATE TABLE \"+name+\".patterns (id INT, name VARCHAR(200), pattern CLOB, occurences INT, diameter FLOAT, nodedegreedistribution CLOB)\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tcreateStatement.execute(\"CREATE TABLE \"+name+\".coloredpatterns (id INT, pattern CLOB)\")\n\t\t\tcreateStatement.close()\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tval createStatement = connection.createStatement()\n\t\t\tval createResultSet = createStatement.execute(\"CREATE TABLE \"+name+\".graphstatistics (nodedegreedistribution CLOB, averagelinks FLOAT, edges INT, connectedcomponents INT, stronglyconnectedcomponents INT, gcnodes INT, gcedges INT, highestIndegrees CLOB, highestOutdegrees CLOB)\")\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\t\ttry {\n\t\t\tvar createStatement = connection.createStatement()\n\t\t\tvar createResultSet = createStatement.execute(\"CREATE TABLE \"+name+\".CLUSTERS \"+\n\t\t\t\t\"(                                                                   \"+\n\t\t\t\t\"       ID INT NOT NULL GENERATED ALWAYS AS IDENTITY(START WITH 1 INCREMENT BY 1),    \"+\n\t\t\t\t\"USERNAME VARCHAR(50) DEFAULT 'default' NOT NULL,       \"+\n\t\t\t\t//\"SESSION_ID INT NOT NULL,                    \"+\n\t\t\t\t//\"SESSION_LOCAL_ID INT,                  \"+\n\t\t\t\t\"LABEL VARCHAR(255),                      \"+\n\t\t\t\t//\"CHILD_SESSION INT,                         \"+\n\t\t\t\t//\"AVG_ERROR FLOAT(53),                         \"+\n\t\t\t\t\"CLUSTER_SIZE INT,                              \"+\n\t\t\t\t//\"PARTITIONNAME VARCHAR(255) DEFAULT 'MAINTABLE', \"+\n\t\t\t\t\"PRIMARY KEY (ID, USERNAME)                                \"+\n\t\t\t\t\")\")\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t}\n\n\t\tval sqlDir = new File(\"prolod-preprocessing/sql/\")\n\t\tfor (file <- sqlDir.listFiles) {\n\t\t\ttry {\n\t\t\t\tval queryString = Source.fromFile(file.getPath).mkString\n\t\t\t\tval query = String.format(queryString, name)\n\t\t\t\ttry {\n\t\t\t\t\tval statement = connection.prepareStatement(query)\n\t\t\t\t\tstatement.execute\n\t\t\t\t\tstatement.close()\n\t\t\t\t} catch {\n\t\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t\t\tcase e : FileNotFoundException =>  println(e.getMessage)\n\t\t\t}\n\t\t}\n\t}\n\n\tdef createIndices(name: String) = {\n\t\tval sqlDir = new File(\"prolod-preprocessing/sql/indices/\")\n\t\tfor (file <- sqlDir.listFiles) {\n\t\t\ttry {\n\t\t\t\tval queryString = Source.fromFile(file.getPath).mkString\n\t\t\t\tval r = \"/\\\\*[\\\\s\\\\S]*?\\\\*/|--[^\\\\r\\\\n]*|;\"\n\t\t\t\tval queries = queryString.split(r)\n\t\t\t\tfor (queryString <- queries) {\n\t\t\t\t\tval query = String.format(queryString, name)\n\t\t\t\t\ttry {\n\t\t\t\t\t\tval statement = connection.prepareStatement(query)\n\t\t\t\t\t\tstatement.execute\n\t\t\t\t\t\tstatement.close()\n\t\t\t\t\t} catch {\n\t\t\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch {\n\t\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage)\n\t\t\t\tcase e : FileNotFoundException =>  println(e.getMessage)\n\t\t\t}\n\t\t}\n\n\t}\n\n\tdef getTableNameFromStatement(s: String) : String = {\n\t\tval pattern = \"\"\"%s.(.*)\"\"\".r\n\n\t\ts match {\n\t\t\tcase pattern(group) => {\n\t\t\t\tprintln(group)\n\t\t\t\tgroup\n\t\t\t}\n\t\t\tcase _ => {\n\t\t\t\tprintln(\"\")\n\t\t\t\t\"\"\n\t\t\t}\n\t\t}\n\t\t/*\n\t\tvar result = pattern.findFirstIn(s).gro//for (m <- pattern findFirstIn s) yield m\n\t\tprintln(s + result)\n\t\tresult                */\n\t}\n\n\tdef validateDatasetString(table: String) = {\n\t\tif(!table.matches(\"[A-Za-z]+\")) {\n\t\t\tthrow new RuntimeException(\"illegal table name: \" + table)\n\t\t}\n\t}\n\n\tdef getClusters(table: String, ontologyNamespace : String): Seq[Group] = {\n\t\tvalidateDatasetString(table)\n\t\tval sql = sql\"SELECT label, cluster_size FROM #${table}.CLUSTERS WHERE username = 'ontology' ORDER BY label\".as[(String, Int)]\n\t\tvar id : Int = -1\n\t\ttry {\n\t\t\tval result = execute(sql)\n\t\t\tresult map tupled((label, cluster_size) => {\n\t\t\t\tid += 1\n\t\t\t\tnew Group(id, removeOntologyNamespace(label, ontologyNamespace), cluster_size)\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(\"This dataset has no clusters: \" + table)\n\t\t\tNil\n\t\t}\n\t}\n\n\n\tprivate def removeOntologyNamespace(name: String, ontologyNamespace: String): String = {\n\t\tvar result = name\n\t\tif (ontologyNamespace != null) {\n\t\t\tif (ontologyNamespace.startsWith(\"\\\"group\\\":\\\"\")) {\n\t\t\t\tresult = result.replace(ontologyNamespace, \"\\\"group\\\":\\\"\")\n\t\t\t} else {\n\t\t\t\tresult = result.replace(ontologyNamespace, \"\")\n\t\t\t}\n\t\t}\n\t\tresult\n\t}\n\n\tdef getDatasetEntities(name : String) : Int = {\n\t\tval sql = sql\"SELECT entities FROM PROLOD_MAIN.SCHEMATA WHERE id = ${name}\".as[Int]\n\t\texecute(sql).headOption.getOrElse(-1)\n\t}\n\n\tdef getDatasets(): Seq[Dataset] = {\n\t\tvar datasets: List[Dataset] = Nil\n\n\t\tval sql = sql\"SELECT id, schema_name, entities, ontology_namespace FROM PROLOD_MAIN.SCHEMATA ORDER BY LOWER(schema_name)\".as[(String, String, Int, String)]\n\n\t\tval result = execute(sql) map tupled((id, schema, entities, ontology_namespace) => {\n\t\t\tnew Dataset(id, schema, entities, getClusters(id, ontology_namespace))\n\t\t})\n\t\tresult.filter(_.size > 0)\n\t}\n\n\n\tdef getStatistics(dataset: String) : mutable.Map[String, String] = {\n\t\tvalidateDatasetString(dataset)\n\t\tval statistics = mutable.Map[String, String]()\n\t\tval sql = sql\"SELECT nodedegreedistribution, averagelinks, edges, connectedcomponents, stronglyconnectedcomponents FROM #$dataset.graphstatistics\".as[(String, Float, Int, Int, Int)]\n\t\ttry {\n\t\t\tval result = execute(sql) map tupled((nodedegreedistribution, averagelinks, edges, connectedcomponents, stronglyconnectedcomponents) => {\n\t\t\t\tstatistics += (\"nodedegreedistribution\" -> nodedegreedistribution)\n\t\t\t\tstatistics += (\"averagelinks\" -> averagelinks.toString)\n\t\t\t\tstatistics += (\"edges\" -> edges.toString)\n\t\t\t\tstatistics += (\"connectedcomponents\" -> connectedcomponents.toString)\n\t\t\t\tstatistics += (\"stronglyconnectedcomponents\" -> stronglyconnectedcomponents.toString)\n\t\t\t})\n\t\t\tval sql2 = sql\"SELECT gcnodes, highestIndegrees, highestOutdegrees FROM #$dataset.graphstatistics\".as[(Int, String, String)]\n\t\t\tval result2 = execute(sql2) map tupled((gcnodes, highestIndegrees, highestOutdegrees) => {\n\t\t\t\tstatistics += (\"gcnodes\" -> gcnodes.toString)\n\t\t\t\tstatistics += (\"highestIndegrees\" -> highestIndegrees)\n\t\t\t\tstatistics += (\"highestOutdegrees\" -> highestOutdegrees)\n\t\t\t})\n\t\t\tval sql3 = sql\"SELECT gcedges FROM #$dataset.graphstatistics\".as[Int]\n\t\t\tval result3 = execute(sql3) map ((gcedges) => {\n\t\t\t\tstatistics += (\"gcedges\" -> gcedges.toString)\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e: SqlSyntaxErrorException => {\n\t\t\t\tval sql2 = sql\"SELECT gcnodes FROM #$dataset.graphstatistics\".as[(Int)]\n\t\t\t\tval result2 = execute(sql2) map ((gcnodes) => {\n\t\t\t\t\tstatistics += (\"gcnodes\" -> gcnodes.toString)\n\t\t\t\t})\n\t\t\t\tprintln(\"error getting stats: \" + e.getMessage + System.lineSeparator() + sql.toString)\n\t\t\t}\n\t\t}\n\t\tstatistics\n\t}\n\n\tdef getColoredPatterns(dataset: String, id: Int): List[Pattern] = {\n\t\tvar patterns : List[Pattern] = Nil\n\t\tval sql = sql\"SELECT ontology_namespace FROM PROLOD_MAIN.SCHEMATA WHERE ID = ${dataset}\".as[String]\n\t\tval namespaces: Vector[String] = execute(sql) map (ontology_namespace => {\n\t\t\t\t\"\\\"group\\\":\\\"\" + ontology_namespace.replace(\"/\", \"\\\\/\")\n\t\t})\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.executeQuery(\"SELECT pattern FROM \"+ dataset+\".COLOREDPATTERNS WHERE id = \"+id)\n\t\t\twhile ( resultSet.next() ) {\n\t\t\t\tvar pattern = resultSet.getString(\"pattern\")\n\t\t\t\tnamespaces foreach (ontology_namespace => {\n\t\t\t\t\t pattern = removeOntologyNamespace(pattern, ontology_namespace)\n\t\t\t\t})\n\t\t\t\t// val occurences = resultSet.getInt(\"occurences\")\n\n\t\t\t\tval patternJsonT = Json.parse(pattern).validate[PatternFromDB]\n\t\t\t\tval patternsV = List(patternJsonT).filter(p => p.isSuccess).map(p => p.get)\n\t\t\t\tval errors = List(patternJsonT).filter(p => p.isError)\n\t\t\t\tif (errors.nonEmpty) {\n\t\t\t\t\tprintln(\"Could not validate \" + errors)\n\t\t\t\t}\n\t\t\t\tval patternJson = Json.parse(pattern).validate[PatternFromDB].get\n\t\t\t\tpatterns :::= List(new Pattern(id, \"\", -1, patternJson.nodes, patternJson.links)) // new Pattern(id, \"\", occurences, Nil, Nil)\n\t\t\t}\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(\"This dataset has no patterns: \" + dataset)\n\t\t}\n\t\tpatterns\n\t}\n\n\tdef getPatterns(s: String): List[Pattern] = {\n\t\tvar patterns : List[Pattern] = Nil\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.executeQuery(\"SELECT id, name, pattern, occurences FROM \"+ s+\".PATTERNS ORDER BY occurences ASC\")\n\t\t\twhile ( resultSet.next() ) {\n\t\t\t\tval id = resultSet.getInt(\"id\")\n\t\t\t\tval pattern = resultSet.getString(\"pattern\")\n\t\t\t\tval occurences = resultSet.getInt(\"occurences\")\n\t\t\t\tval name = resultSet.getString(\"name\")\n\t\t\t\t//val diameter = resultSet.getDouble(\"diameter\")\n\t\t\t\tval patternJson = Json.parse(pattern).validate[PatternFromDB].get\n\t\t\t\tpatterns :::= List(new Pattern(id, name, occurences, patternJson.nodes, patternJson.links)) // new Pattern(id, \"\", occurences, Nil, Nil)\n\t\t\t}\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(\"This dataset has no patterns: \" + s)\n\t\t}\n\t\tpatterns\n\t}\n\n\tdef getPatternDiameter(dataset: String, patternId: Int) : Int = {\n\t\tvalidateDatasetString(dataset)\n\t\tvar diameter : Int = 0\n\t\ttry {\n\t\t\tval sql = sql\"SELECT diameter FROM #${dataset}.patterns WHERE id = #${patternId}\".as[(Int)]\n\t\t\tval result = execute(sql)\n\t\t\tresult map ((diameterSql) => {\n\t\t\t\tdiameter = diameterSql\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(\"error getting diameter\" + e.getMessage)\n\t\t}\n\t\tdiameter\n\t}\n\n\tdef getEntityDetails(dataset: String, subjectId: Int): Entity = {\n\t\tvalidateDatasetString(dataset)\n\t\tvar triples : List[Triple] = Nil\n\t\tvar label : String = \"\"\n\t\tvar subjectUri = \"\"\n\t\tvar predicateUri = \"\"\n\t\tvar objectUri = \"\"\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.executeQuery(\"SELECT tuple_id, predicate_id FROM \"+ dataset+\".maintable WHERE subject_id = \"+subjectId)\n\t\t\twhile ( resultSet.next() ) {\n\t\t\t\tval objectId = resultSet.getString(\"tuple_id\")\n\t\t\t\tval predicateId = resultSet.getString(\"predicate_id\")\n\n\t\t\t\tval statement1 = connection.createStatement()\n\t\t\t\tval resultSet1 = statement1.executeQuery(\"SELECT subject FROM \"+ dataset+\".subjecttable WHERE id = \"+subjectId)\n\t\t\t\twhile ( resultSet1.next() ) {\n\t\t\t\t\tsubjectUri = resultSet1.getString(\"subject\")\n\t\t\t\t}\n\t\t\t\tstatement1.close()\n\n\t\t\t\tval statement2 = connection.createStatement()\n\t\t\t\tval resultSet2 = statement2.executeQuery(\"SELECT predicate FROM \"+ dataset+\".predicatetable WHERE id = \"+predicateId)\n\t\t\t\twhile ( resultSet2.next() ) {\n\t\t\t\t\tpredicateUri = resultSet2.getString(\"predicate\")\n\t\t\t\t}\n\t\t\t\tstatement2.close()\n\n\t\t\t\tval statement3 = connection.createStatement()\n\t\t\t\tval resultSet3 = statement3.executeQuery(\"SELECT object FROM \"+ dataset+\".objecttable WHERE tuple_id = \"+objectId)\n\t\t\t\twhile ( resultSet3.next() ) {\n\t\t\t\t\tobjectUri = resultSet3.getString(\"object\")\n\t\t\t\t\tif (predicateUri.equals(\"http://www.w3.org/2000/01/rdf-schema#label\")) {\n\t\t\t\t\t\tlabel = objectUri\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tstatement3.close()\n\n\t\t\t\ttriples :::= List(new Triple(subjectUri, predicateUri, objectUri))\n\t\t\t}\n\t\t\tstatement.close\n\t\t} catch {\n\t\t\tcase e : SqlSyntaxErrorException => println(\"error getting entity details\" + e.getMessage)\n\t\t}\n\n\t\tval entityDetails = new Entity(subjectId, subjectUri, label, triples)\n\t\tentityDetails\n\t}\n\n\tdef insert: DBIO[Unit] = DBIO.seq(\n\t\t// sqlu\"INSERT INTO PROLOD_MAIN.SCHEMATA ('ID', 'SCHEMA_NAME', 'TUPLES', 'ENTITIES') VALUES ('caterpillar','caterpillar',20,3)\"\n\t)\n\n\tdef replaceDatasetName(query: String, name: String) = {\n\t\tquery.replace(\"##dataset##\", name)\n\t}\n\n\tdef insertDataset(name : String, tuples: Int, entities: Int, ontologyNamespace : String, namespace : String) {\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.execute(\"INSERT INTO PROLOD_MAIN.SCHEMATA (ID, SCHEMA_NAME, TUPLES, ENTITIES, ONTOLOGY_NAMESPACE, NAMESPACE) VALUES ('\"+name+\"','\"+name+\"',\"+tuples+\",\"+entities+\",'\"+ontologyNamespace+\"','\"+namespace+\"')\")\n\t\t} catch {\n\t\t\tcase e : SqlIntegrityConstraintViolationException => println(\"Dataset already exists\")\n\t\t}\n\t}\n\n\tdef insertPatterns(name: String, patterns: util.HashMap[Integer, util.HashMap[String, Integer]], coloredPatterns: util.HashMap[Integer, util.List[String]], diameter: util.HashMap[Integer, lang.Double]) {\n\t\tvalidateDatasetString(name)\n\t\tval coloredPatternsMap = coloredPatterns.asScala.toMap\n\t\tval diameterMap = diameter.asScala.toMap\n\t\tval patternsMap = patterns.asScala.toMap\n\t\tpatternsMap.foreach {\n\t\t\tcase (id, patternHashMap) => {\n\t\t\t\tval patternHashMapScala = patternHashMap.asScala.toMap\n\t\t\t\tpatternHashMapScala.foreach {\n\t\t\t\t\tcase (pattern, occurences) => {\n\t\t\t\t\t\tval patternDiameter = diameterMap.get(id).get\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tval statement = connection.createStatement()\n\t\t\t\t\t\t\tval patternJson : PatternFromDB = Json.parse(pattern).validate[PatternFromDB].get\n\t\t\t\t\t\t\tval patternName = patternJson.name.getOrElse(\"\")\n\t\t\t\t\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".PATTERNS (ID, NAME, PATTERN, OCCURENCES, DIAMETER) VALUES (\" + id + \", '\" + patternName + \"',  '\" + pattern + \"',\" + occurences + \",\" + patternDiameter + \")\")\n\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\tcase e: SqlIntegrityConstraintViolationException => println(\"Pattern already exists\")\n\t\t\t\t\t\t\tcase e: SqlException => println(\"error inserting pattern: \" + e.getMessage)\n\t\t\t\t\t\t\tcase e: SqlSyntaxErrorException => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".PATTERNS (ID, PATTERN, OCCURENCES, DIAMETER) VALUES (\" + id + \", '\" + pattern + \"',\" + occurences + \", \" + patternDiameter + \")\")\n\t\t\t\t\t\t}\n\t\t\t\t\t\tval cPattern = coloredPatternsMap.get(id).get.asScala.toList\n\t\t\t\t\t\tcPattern.foreach { case (coloredpattern) =>\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tval statement = connection.createStatement()\n\t\t\t\t\t\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".coloredpatterns (ID, PATTERN) VALUES (\" + id + \", '\" + coloredpattern + \"')\")\n\t\t\t\t\t\t\t} catch {\n\t\t\t\t\t\t\t\tcase e: SqlException => {\n\t\t\t\t\t\t\t\t\tprintln(\"error inserting pattern (2)\" + e.getMessage)\n\t\t\t\t\t\t\t\t\tprintln(coloredpattern)\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tcase e: SqlSyntaxErrorException => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".coloredpatterns (ID, PATTERN) VALUES (\" + id + \", '\" + coloredpattern + \"')\")\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tclass RsIterator(rs: ResultSet) extends Iterator[ResultSet] {\n\t\tdef hasNext: Boolean = rs.next()\n\t\tdef next(): ResultSet = rs\n\t}\n\n\tdef performInsert(table: String, names: Seq[Any], values: Seq[Any]): Option[Int] = {\n\t\tvalidateDatasetString(table)\n\t\tval query = String.format(\"insert into %s (%s) values (%s)\",\n\t\t\ttable,\n\t\t\tcommaize(names.map(n => n.toString).toList),\n\t\t\tcommaize(values.map(v => \"'\" + v.toString.replace(\"'\", \"\") + \"'\").toList)\n\t\t)\n\t\ttry {\n\t\t\tval statement = connection.prepareStatement(query)\n\t\t\tstatement.execute\n\t\t\tval key = statement.getGeneratedKeys\n\t\t\tstatement.close()\n\t\t\tif(key.next) {\n\t\t\t\tkey.getInt(1)\n\t\t\t}\n\t\t} catch {\n\t\t\tcase e : SqlIntegrityConstraintViolationException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\tcase e : SqlSyntaxErrorException => println(e.getMessage +  System.lineSeparator() + query)\n\t\t\tcase e : SqlDataException =>  println(e.getMessage +  System.lineSeparator() + query)\n\t\t}\n\t\tNone\n\t}\n\n\tprivate def commaize(list: List[_ <: Any]): String = list match {\n\t\tcase List()  => \"\"\n\t\tcase List(x) => x.toString\n\t\tcase _       => list.head + \", \" + commaize(list.tail)\n\t}\n\n\tdef insertSubject(name: String, s: String): Int = {\n\t\tperformInsert(name + \".subjecttable\", List(\"subject\"), List(s)) match {\n\t\t\tcase Some(i) => i\n\t\t\tcase None => getSubjectId(name, s)\n\t\t}\n\t}\n\n\tdef getSubjectId(dataset: String, s: String): Int = {\n\t\tvalidateDatasetString(dataset)\n\t\tvar result : Int = -1\n\t\tval statement = connection.createStatement()\n\t\ttry {\n\t\t\tval resultSet = statement.executeQuery(\"SELECT id FROM \" + dataset + \".subjecttable WHERE subject='\" + s + \"'\")\n\t\t\tresultSet.next()\n\t\t\tresult = resultSet.getInt(\"id\")\n\t\t} catch {\n\t\t\tcase e : SqlException => println(e.getMessage)\n\t\t\tcase e: SqlSyntaxErrorException  => println(e.getMessage)\n\t\t}\n\t\tstatement.close()\n\t\tresult\n\t}\n\n\tdef insertObject(name: String, s: String): Int = {\n\t\tperformInsert(name + \".objecttable\", List(\"object\"), List(s)) match {\n\t\t\tcase Some(i) => i\n\t\t\tcase None => {\n\t\t\t\ttry {\n\t\t\t\t\tgetObjectId(name, s)\n\t\t\t\t} catch {\n\t\t\t\t\tcase e: SqlSyntaxErrorException => {\n\t\t\t\t\t\tprintln(e.getMessage + System.lineSeparator() + s)\n\t\t\t\t\t\t-1\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tdef getObjectId(name: String, s: String): Int = {\n\t\tvalidateDatasetString(name)\n\t\tvar result : Int = -1\n\t\tval statement = connection.createStatement()\n\t\tval resultSet = statement.executeQuery(\"SELECT tuple_id FROM \" + name + \".objecttable WHERE object='\" + s.replace(\"'\", \"\") + \"'\")\n\t\tresultSet.next()\n\t\tresult = resultSet.getInt(\"tuple_id\")\n\t\tstatement.close()\n\t\tresult\n\t}\n\n\tdef getOntologyNamespace(s: String): String = {\n\t\tvar namespace :String = null\n\t\ttry {\n\t\t\tval sql = sql\"\"\"SELECT ONTOLOGY_NAMESPACE FROM PROLOD_MAIN.SCHEMATA WHERE SCHEMA_NAME = ${s}\"\"\".as[String]\n\t\t\tval result = execute(sql)\n\t\t\tresult map ((ns) => {\n\t\t\t\tnamespace = ns\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e: SqlException => println(\"error getting ontology namespace: \" + e.getMessage + System.lineSeparator())\n\t\t\tcase e: SqlSyntaxErrorException   => println(\"syntax in ontology namespace: \" + e.getMessage + System.lineSeparator())\n\t\t}\n\t\tnamespace\n\t}\n\n\tdef getNamespace(s: String): String = {\n\t\tvar namespace :String = null\n\t\ttry {\n\t\t\tval sql = sql\"\"\"SELECT NAMESPACE FROM PROLOD_MAIN.SCHEMATA WHERE SCHEMA_NAME = ${s}\"\"\".as[String]\n\t\t\tval result = execute(sql)\n\t\t\tresult map ((ns) => {\n\t\t\t\tnamespace = ns\n\t\t\t})\n\t\t} catch {\n\t\t\tcase e: SqlException => println(\"error getting namespace: \" + e.getMessage + System.lineSeparator())\n\t\t\tcase e: SqlSyntaxErrorException   => println(e.getMessage + System.lineSeparator())\n\t\t}\n\t\tnamespace\n\t}\n\n\tdef insertPredicate(name: String, s: String): Int = {\n\t\tperformInsert(name + \".predicatetable\", List(\"predicate\"), List(s)) match {\n\t\t\tcase Some(i) => i\n\t\t\tcase None => getPredicateId(name, s)\n\t\t}\n\t}\n\n\tdef getPredicateId(name: String, s: String): Int = {\n\t\tvalidateDatasetString(name)\n\t\tvar result : Int = -1\n\t\tval statement = connection.createStatement()\n\t\tval resultSet = statement.executeQuery(\"SELECT id FROM \" + name + \".predicatetable WHERE predicate='\" + s + \"'\")\n\t\tresultSet.next()\n\t\tresult = resultSet.getInt(\"id\")\n\t\tstatement.close()\n\t\tresult\n\t}\n\n\tdef insertTriples(name: String, s: Int, p: Int, o: Int): Unit = {\n\t\tperformInsert(name + \".maintable\", List(\"subject_id\", \"predicate_id\", \"tuple_id\"), List(s, p, o))\n\t\t/*\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".subjecttable (subject) VALUES ('\" + s + \"')\")\n\t\t\tprintln(resultSet)\n\t\t} catch {\n\t\t\tcase e: SqlIntegrityConstraintViolationException => println(e.getMessage)\n\t\t\tcase e: SqlException => println(e.getMessage)\n\t\t}\n\t\t*/\n\t}\n\n\tdef insertStatistics(name: String, nodes: String, links: Double, edges: Int, gcEdges : Int, gcNodes : Int, connectedcomponents : Int, stronglyconnectedcomponents : Int, highestIndegrees: String, highestOutdegrees: String) = {\n\t\ttry {\n\t\t\tval statement = connection.createStatement()\n\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".graphstatistics (nodedegreedistribution, averagelinks, edges, gcnodes, gcedges, connectedcomponents, stronglyconnectedcomponents, highestIndegrees, highestOutdegrees) VALUES ('\" + nodes + \"',\" + links + \", \" + edges + \", \" + gcNodes + \", \" + gcEdges + \", \" + connectedcomponents + \", \" + stronglyconnectedcomponents + \",'\" + highestIndegrees + \"','\" + highestOutdegrees + \"')\")\n\t\t} catch {\n\t\t\tcase e: SqlIntegrityConstraintViolationException => println(e.getMessage)\n\t\t\tcase e: SqlException => println(e.getMessage)\n\t\t}\n\t}\n\n\tdef insertClasses(name: String, clusters: util.List[String]) = {\n\t\tval clusterUris = clusters.asScala.toList\n\t\tclusterUris.foreach {\n\t\t\tcase (cluster) =>\n\t\t\t\ttry {\n\t\t\t\t\tval statement = connection.createStatement()\n\t\t\t\t\tval resultSet = statement.execute(\"INSERT INTO \" + name + \".clusters (label, cluster_size, username) VALUES ('\" + cluster + \"', 0 , 'ontology')\")\n\t\t\t\t} catch {\n\t\t\t\t\tcase e: SqlIntegrityConstraintViolationException => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".clusters (label, cluster_size, username) VALUES ('\" + cluster + \"', 0 , 'ontology')\")\n\t\t\t\t\tcase e: SqlException => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".clusters (label, cluster_size, username) VALUES ('\" + cluster + \"', 0 , 'ontology')\")\n\t\t\t\t\tcase e: SqlSyntaxErrorException   => println(e.getMessage + System.lineSeparator() + \"INSERT INTO \" + name + \".clusters (label, cluster_size, username) VALUES ('\" + cluster + \"', 0 , 'ontology')\")\n\t\t\t\t}\n\t\t}\n\n\t}\n\n\tdef updateClusterSizes(dataset : String, ontologyNamespace : String) = {\n\t\tvalidateDatasetString(dataset)\n\t\tfor (cluster : Group <- getClusters(dataset, ontologyNamespace)) {\n\t\t\ttry {\n\t\t\t\tval sql = sql\"\"\"SELECT COUNT(*) FROM #${dataset}.MAINTABLE as m, #${dataset}.predicatetable as p, #${dataset}.objecttable as o WHERE m.predicate_id = p.id  AND o.tuple_id = m.tuple_id  AND p.predicate = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type' AND o.object = ${ontologyNamespace + cluster.name}\"\"\".as[(Int)]\n\t\t\t\tval result = execute(sql)\n\t\t\t\tvar clusterSize = 0\n\t\t\t\tresult map ((cluster_size) => {\n\t\t\t\t\tclusterSize = cluster_size\n\t\t\t\t})\n\n\t\t\t\tval statement = connection.createStatement()\n\t\t\t\tval resultSet = statement.execute(\"UPDATE \" + dataset + \".clusters SET cluster_size = \" + clusterSize + \" WHERE label = '\" + ontologyNamespace + cluster.name + \"'\")\n\t\t\t} catch {\n\t\t\t\tcase e: SqlIntegrityConstraintViolationException => println(e.getMessage)\n\t\t\t\tcase e: SqlException => println(e.getMessage + System.lineSeparator())\n\t\t\t\tcase e: SqlSyntaxErrorException   => println(e.getMessage + System.lineSeparator())\n\t\t\t}\n\t\t}\n\t}\n}\n", "package controllers.prolod.server\n\nimport play.api.libs.json._\nimport play.api.mvc.{Action, Controller}\nimport prolod.common.config.{Configuration, DatabaseConnection}\nimport prolod.common.models.GraphLodResultFormats.{graphLodResultFormat, mapIntIntFormat}\nimport prolod.common.models._\n\nobject GraphLod extends Controller {\n  def getGraphStatistics(datasetId: String, groups: List[String]) = Action {\n    val config = new Configuration()\n    val db = new DatabaseConnection(config)\n    val patternList: List[Pattern] = db.getPatterns(datasetId)\n    val data: GraphLodResult = GraphLodResult(datasetId)\n    val statistics = db.getStatistics(datasetId)\n\n    data.nodes = db.getDatasetEntities(datasetId)\n    data.edges = statistics.getOrElse(\"edges\", \"0\").toInt\n    data.averageLinks = statistics.getOrElse(\"averagelinks\", \"0\").toFloat\n    data.giantComponentNodes = statistics.getOrElse(\"gcnodes\", \"0\").toInt\n    data.giantComponentEdges = statistics.getOrElse(\"gcedges\", \"0\").toInt\n    data.patterns = patternList\n    data.connectedComponents = statistics.getOrElse(\"connectedcomponents\", \"0\").toInt\n    data.stronglyConnectedComponents = statistics.getOrElse(\"stronglyconnectedcomponents\", \"0\").toInt\n\n    statistics.get(\"nodedegreedistribution\") match {\n      case Some(ndd) => {\n        val nodeDegreeDistributionMap = Json.parse(statistics.get(\"nodedegreedistribution\").get).as[Map[Int, Int]]\n        data.nodeDegreeDistribution =  nodeDegreeDistributionMap\n      }\n      case None => println()\n    }\n\n    statistics.get(\"highestIndegrees\") match {\n      case Some(ndd) => {\n        val highestIndegreesMap = Json.parse(statistics.get(\"highestIndegrees\").get).as[Map[String, Int]]\n        var highestIndegreesCleanedMap : Map[String, Map[Int, Int]] = Map()\n        for ((key, value) <- highestIndegreesMap) {\n          var highestIndegreesInternalMap : Map[Int, Int] = Map()\n          highestIndegreesInternalMap += (db.getSubjectId(datasetId, key) -> value)\n          highestIndegreesCleanedMap += (key.replace(db.getNamespace(datasetId), datasetId + \":\") -> highestIndegreesInternalMap)\n        }\n        data.highestIndegrees = highestIndegreesCleanedMap\n      }\n      case None => println()\n    }\n\n    statistics.get(\"highestOutdegrees\") match {\n      case Some(ndd) => {\n        val highestOutdegreesMap = Json.parse(statistics.get(\"highestOutdegrees\").get).as[Map[String, Int]]\n        var highestOutdegreesCleanedMap : Map[String, Map[Int, Int]] = Map()\n        for ((key, value) <- highestOutdegreesMap) {\n          var highestOutdegreesInternalMap : Map[Int, Int] = Map()\n          highestOutdegreesInternalMap += (db.getSubjectId(datasetId, key) -> value)\n          highestOutdegreesCleanedMap += (key.replace(db.getNamespace(datasetId), datasetId + \":\") -> highestOutdegreesInternalMap)\n        }\n        data.highestOutdegrees =  highestOutdegreesCleanedMap\n      }\n      case None => println()\n    }\n\n    // TODO class distribution should go in here\n\n    val json = Json.obj(\"statistics\" -> data)\n    Ok(json)\n  }\n\n  def getGraphPatternStatistics(datasetId: String, groups: List[String], pattern: Int) = Action {\n    val config = new Configuration()\n    val db = new DatabaseConnection(config)\n    val data: GraphLodResult = GraphLodResult(datasetId)\n    val patternList: List[Pattern] = db.getColoredPatterns(datasetId, pattern)\n    var entitiesPerClass: Map[String, Int] = Map()\n    var entities = 0\n    data.connectedComponents = patternList.size\n    if (groups.nonEmpty) {\n      var newPatternList: List[Pattern] = Nil\n      for (pattern : Pattern <- patternList) {\n        var patternNotInGroups = false\n        var newNodes: List[Node] = Nil\n        var tempEntitiesPerClass: Map[String, Int] = Map()\n        for (node : Node <- pattern.nodes) {\n          var newNode : Node = node\n          val group = node.group.getOrElse(\"\")\n          if (!groups.contains(node.group.getOrElse(\"\"))) {\n            newNode = new Node(node.id, node.uri, None)\n          } else {\n            patternNotInGroups = true\n          }\n          if (group.length > 0) {\n            var entityCount = 0\n            if (tempEntitiesPerClass.contains(group)) {\n              entityCount = tempEntitiesPerClass.getOrElse(group, 0)\n            }\n            entityCount += 1\n            tempEntitiesPerClass += (group -> entityCount)\n          }\n          newNodes ::= newNode\n        }\n        if (groups.isEmpty || (groups.nonEmpty && patternNotInGroups)) {\n          newPatternList ::=new Pattern(pattern.id, pattern.name, pattern.occurences, newNodes, pattern.links)\n          entities += newNodes.size\n          for ((group, count) <- tempEntitiesPerClass) {\n            var entityCount = 0\n            if (entitiesPerClass.contains(group)) {\n              entityCount = entitiesPerClass.getOrElse(group, 0)\n            }\n            entityCount += count\n            entitiesPerClass += (group -> entityCount)\n          }\n        }\n      }\n      data.connectedComponents = newPatternList.size\n      data.patterns = newPatternList\n    } else {\n      data.patterns = patternList\n      for (pattern : Pattern <- patternList) {\n        var tempEntitiesPerClass: Map[String, Int] = Map()\n        for (node : Node <- pattern.nodes) {\n          val group = node.group.getOrElse(\"\")\n          if (group.length > 0) {\n            var entityCount = 0\n            if (tempEntitiesPerClass.contains(group)) {\n              entityCount = tempEntitiesPerClass.getOrElse(group, 0)\n            }\n            entityCount += 1\n            tempEntitiesPerClass += (group -> entityCount)\n          }\n        }\n        entities += pattern.nodes.size\n        for ((group, count) <- tempEntitiesPerClass) {\n          var entityCount = 0\n          if (entitiesPerClass.contains(group)) {\n            entityCount = entitiesPerClass.getOrElse(group, 0)\n          }\n          entityCount += count\n          entitiesPerClass += (group -> entityCount)\n        }\n      }\n    }\n\n    if (entities > 0) {\n      var classDistribution : Map[String, Double] = Map()\n      var entitiesUnknown = entities\n      for ((group, entityCount) <- entitiesPerClass) {\n         classDistribution += (group -> (entityCount.toDouble/entities))\n        entitiesUnknown -= entityCount\n      }\n      if (entitiesUnknown > 0) {\n        classDistribution += (\"unknown\" -> (entitiesUnknown.toDouble/entities))\n      }\n      data.nodes = entities\n      data.classDistribution =  classDistribution\n    }\n\n    if(data.patterns.nonEmpty) {\n      val patternDiameter = db.getPatternDiameter(datasetId, data.patterns.last.id)\n      data.diameter = patternDiameter\n    }\n\n    val json = Json.obj(\"statistics\" -> data)\n    Ok(json)\n  }\n\n  def getBigComponent(dataset: String, groups: List[String], pattern: Int) = Action {\n    Ok(\"this is big!\")\n  }\n}\n"], "filenames": ["prolod-common/src/main/scala/prolod/common/config/DatabaseConnection.scala", "prolod-server/app/controllers/prolod/server/GraphLod.scala"], "buggy_code_start_loc": [227, 156], "buggy_code_end_loc": [647, 158], "fixing_code_start_loc": [227, 156], "fixing_code_end_loc": [662, 160], "type": "CWE-89", "message": "A vulnerability has been found in HPI-Information-Systems ProLOD and classified as critical. This vulnerability affects unknown code. The manipulation of the argument this leads to sql injection. The name of the patch is 3f710905458d49c77530bd3cbcd8960457566b73. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-217552.", "other": {"cve": {"id": "CVE-2015-10017", "sourceIdentifier": "cna@vuldb.com", "published": "2023-01-06T11:15:09.213", "lastModified": "2023-01-12T16:06:24.297", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A vulnerability has been found in HPI-Information-Systems ProLOD and classified as critical. This vulnerability affects unknown code. The manipulation of the argument this leads to sql injection. The name of the patch is 3f710905458d49c77530bd3cbcd8960457566b73. It is recommended to apply a patch to fix this issue. The identifier of this vulnerability is VDB-217552."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV30": [{"source": "cna@vuldb.com", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:A/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L", "attackVector": "ADJACENT_NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.1, "impactScore": 3.4}], "cvssMetricV2": [{"source": "cna@vuldb.com", "type": "Secondary", "cvssData": {"version": "2.0", "vectorString": "AV:A/AC:L/Au:S/C:P/I:P/A:P", "accessVector": "ADJACENT_NETWORK", "accessComplexity": "LOW", "authentication": "SINGLE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 5.2}, "baseSeverity": "MEDIUM", "exploitabilityScore": 5.1, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "cna@vuldb.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-89"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:hpi:prolod:*:*:*:*:*:*:*:*", "versionEndExcluding": "7-6-2015", "matchCriteriaId": "A62E9669-796B-4773-A821-26FB15DDE9D4"}]}]}], "references": [{"url": "https://github.com/HPI-Information-Systems/ProLOD/commit/3f710905458d49c77530bd3cbcd8960457566b73", "source": "cna@vuldb.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://vuldb.com/?ctiid.217552", "source": "cna@vuldb.com", "tags": ["Release Notes", "Third Party Advisory"]}, {"url": "https://vuldb.com/?id.217552", "source": "cna@vuldb.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/HPI-Information-Systems/ProLOD/commit/3f710905458d49c77530bd3cbcd8960457566b73"}}
{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0+\n/*\n * Copyright (C) 2015 Microchip Technology\n */\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/usb.h>\n#include <linux/crc32.h>\n#include <linux/signal.h>\n#include <linux/slab.h>\n#include <linux/if_vlan.h>\n#include <linux/uaccess.h>\n#include <linux/linkmode.h>\n#include <linux/list.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/mdio.h>\n#include <linux/phy.h>\n#include <net/ip6_checksum.h>\n#include <net/vxlan.h>\n#include <linux/interrupt.h>\n#include <linux/irqdomain.h>\n#include <linux/irq.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/microchipphy.h>\n#include <linux/phy_fixed.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n#include \"lan78xx.h\"\n\n#define DRIVER_AUTHOR\t\"WOOJUNG HUH <woojung.huh@microchip.com>\"\n#define DRIVER_DESC\t\"LAN78XX USB 3.0 Gigabit Ethernet Devices\"\n#define DRIVER_NAME\t\"lan78xx\"\n\n#define TX_TIMEOUT_JIFFIES\t\t(5 * HZ)\n#define THROTTLE_JIFFIES\t\t(HZ / 8)\n#define UNLINK_TIMEOUT_MS\t\t3\n\n#define RX_MAX_QUEUE_MEMORY\t\t(60 * 1518)\n\n#define SS_USB_PKT_SIZE\t\t\t(1024)\n#define HS_USB_PKT_SIZE\t\t\t(512)\n#define FS_USB_PKT_SIZE\t\t\t(64)\n\n#define MAX_RX_FIFO_SIZE\t\t(12 * 1024)\n#define MAX_TX_FIFO_SIZE\t\t(12 * 1024)\n\n#define FLOW_THRESHOLD(n)\t\t((((n) + 511) / 512) & 0x7F)\n#define FLOW_CTRL_THRESHOLD(on, off)\t((FLOW_THRESHOLD(on)  << 0) | \\\n\t\t\t\t\t (FLOW_THRESHOLD(off) << 8))\n\n/* Flow control turned on when Rx FIFO level rises above this level (bytes) */\n#define FLOW_ON_SS\t\t\t9216\n#define FLOW_ON_HS\t\t\t8704\n\n/* Flow control turned off when Rx FIFO level falls below this level (bytes) */\n#define FLOW_OFF_SS\t\t\t4096\n#define FLOW_OFF_HS\t\t\t1024\n\n#define DEFAULT_BURST_CAP_SIZE\t\t(MAX_TX_FIFO_SIZE)\n#define DEFAULT_BULK_IN_DELAY\t\t(0x0800)\n#define MAX_SINGLE_PACKET_SIZE\t\t(9000)\n#define DEFAULT_TX_CSUM_ENABLE\t\t(true)\n#define DEFAULT_RX_CSUM_ENABLE\t\t(true)\n#define DEFAULT_TSO_CSUM_ENABLE\t\t(true)\n#define DEFAULT_VLAN_FILTER_ENABLE\t(true)\n#define DEFAULT_VLAN_RX_OFFLOAD\t\t(true)\n#define TX_ALIGNMENT\t\t\t(4)\n#define RXW_PADDING\t\t\t2\n\n#define LAN78XX_USB_VENDOR_ID\t\t(0x0424)\n#define LAN7800_USB_PRODUCT_ID\t\t(0x7800)\n#define LAN7850_USB_PRODUCT_ID\t\t(0x7850)\n#define LAN7801_USB_PRODUCT_ID\t\t(0x7801)\n#define LAN78XX_EEPROM_MAGIC\t\t(0x78A5)\n#define LAN78XX_OTP_MAGIC\t\t(0x78F3)\n#define AT29M2AF_USB_VENDOR_ID\t\t(0x07C9)\n#define AT29M2AF_USB_PRODUCT_ID\t(0x0012)\n\n#define\tMII_READ\t\t\t1\n#define\tMII_WRITE\t\t\t0\n\n#define EEPROM_INDICATOR\t\t(0xA5)\n#define EEPROM_MAC_OFFSET\t\t(0x01)\n#define MAX_EEPROM_SIZE\t\t\t512\n#define OTP_INDICATOR_1\t\t\t(0xF3)\n#define OTP_INDICATOR_2\t\t\t(0xF7)\n\n#define WAKE_ALL\t\t\t(WAKE_PHY | WAKE_UCAST | \\\n\t\t\t\t\t WAKE_MCAST | WAKE_BCAST | \\\n\t\t\t\t\t WAKE_ARP | WAKE_MAGIC)\n\n#define TX_URB_NUM\t\t\t10\n#define TX_SS_URB_NUM\t\t\tTX_URB_NUM\n#define TX_HS_URB_NUM\t\t\tTX_URB_NUM\n#define TX_FS_URB_NUM\t\t\tTX_URB_NUM\n\n/* A single URB buffer must be large enough to hold a complete jumbo packet\n */\n#define TX_SS_URB_SIZE\t\t\t(32 * 1024)\n#define TX_HS_URB_SIZE\t\t\t(16 * 1024)\n#define TX_FS_URB_SIZE\t\t\t(10 * 1024)\n\n#define RX_SS_URB_NUM\t\t\t30\n#define RX_HS_URB_NUM\t\t\t10\n#define RX_FS_URB_NUM\t\t\t10\n#define RX_SS_URB_SIZE\t\t\tTX_SS_URB_SIZE\n#define RX_HS_URB_SIZE\t\t\tTX_HS_URB_SIZE\n#define RX_FS_URB_SIZE\t\t\tTX_FS_URB_SIZE\n\n#define SS_BURST_CAP_SIZE\t\tRX_SS_URB_SIZE\n#define SS_BULK_IN_DELAY\t\t0x2000\n#define HS_BURST_CAP_SIZE\t\tRX_HS_URB_SIZE\n#define HS_BULK_IN_DELAY\t\t0x2000\n#define FS_BURST_CAP_SIZE\t\tRX_FS_URB_SIZE\n#define FS_BULK_IN_DELAY\t\t0x2000\n\n#define TX_CMD_LEN\t\t\t8\n#define TX_SKB_MIN_LEN\t\t\t(TX_CMD_LEN + ETH_HLEN)\n#define LAN78XX_TSO_SIZE(dev)\t\t((dev)->tx_urb_size - TX_SKB_MIN_LEN)\n\n#define RX_CMD_LEN\t\t\t10\n#define RX_SKB_MIN_LEN\t\t\t(RX_CMD_LEN + ETH_HLEN)\n#define RX_MAX_FRAME_LEN(mtu)\t\t((mtu) + ETH_HLEN + VLAN_HLEN)\n\n/* USB related defines */\n#define BULK_IN_PIPE\t\t\t1\n#define BULK_OUT_PIPE\t\t\t2\n\n/* default autosuspend delay (mSec)*/\n#define DEFAULT_AUTOSUSPEND_DELAY\t(10 * 1000)\n\n/* statistic update interval (mSec) */\n#define STAT_UPDATE_TIMER\t\t(1 * 1000)\n\n/* time to wait for MAC or FCT to stop (jiffies) */\n#define HW_DISABLE_TIMEOUT\t\t(HZ / 10)\n\n/* time to wait between polling MAC or FCT state (ms) */\n#define HW_DISABLE_DELAY_MS\t\t1\n\n/* defines interrupts from interrupt EP */\n#define MAX_INT_EP\t\t\t(32)\n#define INT_EP_INTEP\t\t\t(31)\n#define INT_EP_OTP_WR_DONE\t\t(28)\n#define INT_EP_EEE_TX_LPI_START\t\t(26)\n#define INT_EP_EEE_TX_LPI_STOP\t\t(25)\n#define INT_EP_EEE_RX_LPI\t\t(24)\n#define INT_EP_MAC_RESET_TIMEOUT\t(23)\n#define INT_EP_RDFO\t\t\t(22)\n#define INT_EP_TXE\t\t\t(21)\n#define INT_EP_USB_STATUS\t\t(20)\n#define INT_EP_TX_DIS\t\t\t(19)\n#define INT_EP_RX_DIS\t\t\t(18)\n#define INT_EP_PHY\t\t\t(17)\n#define INT_EP_DP\t\t\t(16)\n#define INT_EP_MAC_ERR\t\t\t(15)\n#define INT_EP_TDFU\t\t\t(14)\n#define INT_EP_TDFO\t\t\t(13)\n#define INT_EP_UTX\t\t\t(12)\n#define INT_EP_GPIO_11\t\t\t(11)\n#define INT_EP_GPIO_10\t\t\t(10)\n#define INT_EP_GPIO_9\t\t\t(9)\n#define INT_EP_GPIO_8\t\t\t(8)\n#define INT_EP_GPIO_7\t\t\t(7)\n#define INT_EP_GPIO_6\t\t\t(6)\n#define INT_EP_GPIO_5\t\t\t(5)\n#define INT_EP_GPIO_4\t\t\t(4)\n#define INT_EP_GPIO_3\t\t\t(3)\n#define INT_EP_GPIO_2\t\t\t(2)\n#define INT_EP_GPIO_1\t\t\t(1)\n#define INT_EP_GPIO_0\t\t\t(0)\n\nstatic const char lan78xx_gstrings[][ETH_GSTRING_LEN] = {\n\t\"RX FCS Errors\",\n\t\"RX Alignment Errors\",\n\t\"Rx Fragment Errors\",\n\t\"RX Jabber Errors\",\n\t\"RX Undersize Frame Errors\",\n\t\"RX Oversize Frame Errors\",\n\t\"RX Dropped Frames\",\n\t\"RX Unicast Byte Count\",\n\t\"RX Broadcast Byte Count\",\n\t\"RX Multicast Byte Count\",\n\t\"RX Unicast Frames\",\n\t\"RX Broadcast Frames\",\n\t\"RX Multicast Frames\",\n\t\"RX Pause Frames\",\n\t\"RX 64 Byte Frames\",\n\t\"RX 65 - 127 Byte Frames\",\n\t\"RX 128 - 255 Byte Frames\",\n\t\"RX 256 - 511 Bytes Frames\",\n\t\"RX 512 - 1023 Byte Frames\",\n\t\"RX 1024 - 1518 Byte Frames\",\n\t\"RX Greater 1518 Byte Frames\",\n\t\"EEE RX LPI Transitions\",\n\t\"EEE RX LPI Time\",\n\t\"TX FCS Errors\",\n\t\"TX Excess Deferral Errors\",\n\t\"TX Carrier Errors\",\n\t\"TX Bad Byte Count\",\n\t\"TX Single Collisions\",\n\t\"TX Multiple Collisions\",\n\t\"TX Excessive Collision\",\n\t\"TX Late Collisions\",\n\t\"TX Unicast Byte Count\",\n\t\"TX Broadcast Byte Count\",\n\t\"TX Multicast Byte Count\",\n\t\"TX Unicast Frames\",\n\t\"TX Broadcast Frames\",\n\t\"TX Multicast Frames\",\n\t\"TX Pause Frames\",\n\t\"TX 64 Byte Frames\",\n\t\"TX 65 - 127 Byte Frames\",\n\t\"TX 128 - 255 Byte Frames\",\n\t\"TX 256 - 511 Bytes Frames\",\n\t\"TX 512 - 1023 Byte Frames\",\n\t\"TX 1024 - 1518 Byte Frames\",\n\t\"TX Greater 1518 Byte Frames\",\n\t\"EEE TX LPI Transitions\",\n\t\"EEE TX LPI Time\",\n};\n\nstruct lan78xx_statstage {\n\tu32 rx_fcs_errors;\n\tu32 rx_alignment_errors;\n\tu32 rx_fragment_errors;\n\tu32 rx_jabber_errors;\n\tu32 rx_undersize_frame_errors;\n\tu32 rx_oversize_frame_errors;\n\tu32 rx_dropped_frames;\n\tu32 rx_unicast_byte_count;\n\tu32 rx_broadcast_byte_count;\n\tu32 rx_multicast_byte_count;\n\tu32 rx_unicast_frames;\n\tu32 rx_broadcast_frames;\n\tu32 rx_multicast_frames;\n\tu32 rx_pause_frames;\n\tu32 rx_64_byte_frames;\n\tu32 rx_65_127_byte_frames;\n\tu32 rx_128_255_byte_frames;\n\tu32 rx_256_511_bytes_frames;\n\tu32 rx_512_1023_byte_frames;\n\tu32 rx_1024_1518_byte_frames;\n\tu32 rx_greater_1518_byte_frames;\n\tu32 eee_rx_lpi_transitions;\n\tu32 eee_rx_lpi_time;\n\tu32 tx_fcs_errors;\n\tu32 tx_excess_deferral_errors;\n\tu32 tx_carrier_errors;\n\tu32 tx_bad_byte_count;\n\tu32 tx_single_collisions;\n\tu32 tx_multiple_collisions;\n\tu32 tx_excessive_collision;\n\tu32 tx_late_collisions;\n\tu32 tx_unicast_byte_count;\n\tu32 tx_broadcast_byte_count;\n\tu32 tx_multicast_byte_count;\n\tu32 tx_unicast_frames;\n\tu32 tx_broadcast_frames;\n\tu32 tx_multicast_frames;\n\tu32 tx_pause_frames;\n\tu32 tx_64_byte_frames;\n\tu32 tx_65_127_byte_frames;\n\tu32 tx_128_255_byte_frames;\n\tu32 tx_256_511_bytes_frames;\n\tu32 tx_512_1023_byte_frames;\n\tu32 tx_1024_1518_byte_frames;\n\tu32 tx_greater_1518_byte_frames;\n\tu32 eee_tx_lpi_transitions;\n\tu32 eee_tx_lpi_time;\n};\n\nstruct lan78xx_statstage64 {\n\tu64 rx_fcs_errors;\n\tu64 rx_alignment_errors;\n\tu64 rx_fragment_errors;\n\tu64 rx_jabber_errors;\n\tu64 rx_undersize_frame_errors;\n\tu64 rx_oversize_frame_errors;\n\tu64 rx_dropped_frames;\n\tu64 rx_unicast_byte_count;\n\tu64 rx_broadcast_byte_count;\n\tu64 rx_multicast_byte_count;\n\tu64 rx_unicast_frames;\n\tu64 rx_broadcast_frames;\n\tu64 rx_multicast_frames;\n\tu64 rx_pause_frames;\n\tu64 rx_64_byte_frames;\n\tu64 rx_65_127_byte_frames;\n\tu64 rx_128_255_byte_frames;\n\tu64 rx_256_511_bytes_frames;\n\tu64 rx_512_1023_byte_frames;\n\tu64 rx_1024_1518_byte_frames;\n\tu64 rx_greater_1518_byte_frames;\n\tu64 eee_rx_lpi_transitions;\n\tu64 eee_rx_lpi_time;\n\tu64 tx_fcs_errors;\n\tu64 tx_excess_deferral_errors;\n\tu64 tx_carrier_errors;\n\tu64 tx_bad_byte_count;\n\tu64 tx_single_collisions;\n\tu64 tx_multiple_collisions;\n\tu64 tx_excessive_collision;\n\tu64 tx_late_collisions;\n\tu64 tx_unicast_byte_count;\n\tu64 tx_broadcast_byte_count;\n\tu64 tx_multicast_byte_count;\n\tu64 tx_unicast_frames;\n\tu64 tx_broadcast_frames;\n\tu64 tx_multicast_frames;\n\tu64 tx_pause_frames;\n\tu64 tx_64_byte_frames;\n\tu64 tx_65_127_byte_frames;\n\tu64 tx_128_255_byte_frames;\n\tu64 tx_256_511_bytes_frames;\n\tu64 tx_512_1023_byte_frames;\n\tu64 tx_1024_1518_byte_frames;\n\tu64 tx_greater_1518_byte_frames;\n\tu64 eee_tx_lpi_transitions;\n\tu64 eee_tx_lpi_time;\n};\n\nstatic u32 lan78xx_regs[] = {\n\tID_REV,\n\tINT_STS,\n\tHW_CFG,\n\tPMT_CTL,\n\tE2P_CMD,\n\tE2P_DATA,\n\tUSB_STATUS,\n\tVLAN_TYPE,\n\tMAC_CR,\n\tMAC_RX,\n\tMAC_TX,\n\tFLOW,\n\tERR_STS,\n\tMII_ACC,\n\tMII_DATA,\n\tEEE_TX_LPI_REQ_DLY,\n\tEEE_TW_TX_SYS,\n\tEEE_TX_LPI_REM_DLY,\n\tWUCSR\n};\n\n#define PHY_REG_SIZE (32 * sizeof(u32))\n\nstruct lan78xx_net;\n\nstruct lan78xx_priv {\n\tstruct lan78xx_net *dev;\n\tu32 rfe_ctl;\n\tu32 mchash_table[DP_SEL_VHF_HASH_LEN]; /* multicast hash table */\n\tu32 pfilter_table[NUM_OF_MAF][2]; /* perfect filter table */\n\tu32 vlan_table[DP_SEL_VHF_VLAN_LEN];\n\tstruct mutex dataport_mutex; /* for dataport access */\n\tspinlock_t rfe_ctl_lock; /* for rfe register access */\n\tstruct work_struct set_multicast;\n\tstruct work_struct set_vlan;\n\tu32 wol;\n};\n\nenum skb_state {\n\tillegal = 0,\n\ttx_start,\n\ttx_done,\n\trx_start,\n\trx_done,\n\trx_cleanup,\n\tunlink_start\n};\n\nstruct skb_data {\t\t/* skb->cb is one of these */\n\tstruct urb *urb;\n\tstruct lan78xx_net *dev;\n\tenum skb_state state;\n\tsize_t length;\n\tint num_of_packet;\n};\n\nstruct usb_context {\n\tstruct usb_ctrlrequest req;\n\tstruct lan78xx_net *dev;\n};\n\n#define EVENT_TX_HALT\t\t\t0\n#define EVENT_RX_HALT\t\t\t1\n#define EVENT_RX_MEMORY\t\t\t2\n#define EVENT_STS_SPLIT\t\t\t3\n#define EVENT_LINK_RESET\t\t4\n#define EVENT_RX_PAUSED\t\t\t5\n#define EVENT_DEV_WAKING\t\t6\n#define EVENT_DEV_ASLEEP\t\t7\n#define EVENT_DEV_OPEN\t\t\t8\n#define EVENT_STAT_UPDATE\t\t9\n#define EVENT_DEV_DISCONNECT\t\t10\n\nstruct statstage {\n\tstruct mutex\t\t\taccess_lock;\t/* for stats access */\n\tstruct lan78xx_statstage\tsaved;\n\tstruct lan78xx_statstage\trollover_count;\n\tstruct lan78xx_statstage\trollover_max;\n\tstruct lan78xx_statstage64\tcurr_stat;\n};\n\nstruct irq_domain_data {\n\tstruct irq_domain\t*irqdomain;\n\tunsigned int\t\tphyirq;\n\tstruct irq_chip\t\t*irqchip;\n\tirq_flow_handler_t\tirq_handler;\n\tu32\t\t\tirqenable;\n\tstruct mutex\t\tirq_lock;\t\t/* for irq bus access */\n};\n\nstruct lan78xx_net {\n\tstruct net_device\t*net;\n\tstruct usb_device\t*udev;\n\tstruct usb_interface\t*intf;\n\tvoid\t\t\t*driver_priv;\n\n\tunsigned int\t\ttx_pend_data_len;\n\tsize_t\t\t\tn_tx_urbs;\n\tsize_t\t\t\tn_rx_urbs;\n\tsize_t\t\t\ttx_urb_size;\n\tsize_t\t\t\trx_urb_size;\n\n\tstruct sk_buff_head\trxq_free;\n\tstruct sk_buff_head\trxq;\n\tstruct sk_buff_head\trxq_done;\n\tstruct sk_buff_head\trxq_overflow;\n\tstruct sk_buff_head\ttxq_free;\n\tstruct sk_buff_head\ttxq;\n\tstruct sk_buff_head\ttxq_pend;\n\n\tstruct napi_struct\tnapi;\n\n\tstruct delayed_work\twq;\n\n\tint\t\t\tmsg_enable;\n\n\tstruct urb\t\t*urb_intr;\n\tstruct usb_anchor\tdeferred;\n\n\tstruct mutex\t\tdev_mutex; /* serialise open/stop wrt suspend/resume */\n\tstruct mutex\t\tphy_mutex; /* for phy access */\n\tunsigned int\t\tpipe_in, pipe_out, pipe_intr;\n\n\tunsigned int\t\tbulk_in_delay;\n\tunsigned int\t\tburst_cap;\n\n\tunsigned long\t\tflags;\n\n\twait_queue_head_t\t*wait;\n\tunsigned char\t\tsuspend_count;\n\n\tunsigned int\t\tmaxpacket;\n\tstruct timer_list\tstat_monitor;\n\n\tunsigned long\t\tdata[5];\n\n\tint\t\t\tlink_on;\n\tu8\t\t\tmdix_ctrl;\n\n\tu32\t\t\tchipid;\n\tu32\t\t\tchiprev;\n\tstruct mii_bus\t\t*mdiobus;\n\tphy_interface_t\t\tinterface;\n\n\tint\t\t\tfc_autoneg;\n\tu8\t\t\tfc_request_control;\n\n\tint\t\t\tdelta;\n\tstruct statstage\tstats;\n\n\tstruct irq_domain_data\tdomain_data;\n};\n\n/* define external phy id */\n#define\tPHY_LAN8835\t\t\t(0x0007C130)\n#define\tPHY_KSZ9031RNX\t\t\t(0x00221620)\n\n/* use ethtool to change the level for any given device */\nstatic int msg_level = -1;\nmodule_param(msg_level, int, 0);\nMODULE_PARM_DESC(msg_level, \"Override default message level\");\n\nstatic struct sk_buff *lan78xx_get_buf(struct sk_buff_head *buf_pool)\n{\n\tif (skb_queue_empty(buf_pool))\n\t\treturn NULL;\n\n\treturn skb_dequeue(buf_pool);\n}\n\nstatic void lan78xx_release_buf(struct sk_buff_head *buf_pool,\n\t\t\t\tstruct sk_buff *buf)\n{\n\tbuf->data = buf->head;\n\tskb_reset_tail_pointer(buf);\n\n\tbuf->len = 0;\n\tbuf->data_len = 0;\n\n\tskb_queue_tail(buf_pool, buf);\n}\n\nstatic void lan78xx_free_buf_pool(struct sk_buff_head *buf_pool)\n{\n\tstruct skb_data *entry;\n\tstruct sk_buff *buf;\n\n\twhile (!skb_queue_empty(buf_pool)) {\n\t\tbuf = skb_dequeue(buf_pool);\n\t\tif (buf) {\n\t\t\tentry = (struct skb_data *)buf->cb;\n\t\t\tusb_free_urb(entry->urb);\n\t\t\tdev_kfree_skb_any(buf);\n\t\t}\n\t}\n}\n\nstatic int lan78xx_alloc_buf_pool(struct sk_buff_head *buf_pool,\n\t\t\t\t  size_t n_urbs, size_t urb_size,\n\t\t\t\t  struct lan78xx_net *dev)\n{\n\tstruct skb_data *entry;\n\tstruct sk_buff *buf;\n\tstruct urb *urb;\n\tint i;\n\n\tskb_queue_head_init(buf_pool);\n\n\tfor (i = 0; i < n_urbs; i++) {\n\t\tbuf = alloc_skb(urb_size, GFP_ATOMIC);\n\t\tif (!buf)\n\t\t\tgoto error;\n\n\t\tif (skb_linearize(buf) != 0) {\n\t\t\tdev_kfree_skb_any(buf);\n\t\t\tgoto error;\n\t\t}\n\n\t\turb = usb_alloc_urb(0, GFP_ATOMIC);\n\t\tif (!urb) {\n\t\t\tdev_kfree_skb_any(buf);\n\t\t\tgoto error;\n\t\t}\n\n\t\tentry = (struct skb_data *)buf->cb;\n\t\tentry->urb = urb;\n\t\tentry->dev = dev;\n\t\tentry->length = 0;\n\t\tentry->num_of_packet = 0;\n\n\t\tskb_queue_tail(buf_pool, buf);\n\t}\n\n\treturn 0;\n\nerror:\n\tlan78xx_free_buf_pool(buf_pool);\n\n\treturn -ENOMEM;\n}\n\nstatic struct sk_buff *lan78xx_get_rx_buf(struct lan78xx_net *dev)\n{\n\treturn lan78xx_get_buf(&dev->rxq_free);\n}\n\nstatic void lan78xx_release_rx_buf(struct lan78xx_net *dev,\n\t\t\t\t   struct sk_buff *rx_buf)\n{\n\tlan78xx_release_buf(&dev->rxq_free, rx_buf);\n}\n\nstatic void lan78xx_free_rx_resources(struct lan78xx_net *dev)\n{\n\tlan78xx_free_buf_pool(&dev->rxq_free);\n}\n\nstatic int lan78xx_alloc_rx_resources(struct lan78xx_net *dev)\n{\n\treturn lan78xx_alloc_buf_pool(&dev->rxq_free,\n\t\t\t\t      dev->n_rx_urbs, dev->rx_urb_size, dev);\n}\n\nstatic struct sk_buff *lan78xx_get_tx_buf(struct lan78xx_net *dev)\n{\n\treturn lan78xx_get_buf(&dev->txq_free);\n}\n\nstatic void lan78xx_release_tx_buf(struct lan78xx_net *dev,\n\t\t\t\t   struct sk_buff *tx_buf)\n{\n\tlan78xx_release_buf(&dev->txq_free, tx_buf);\n}\n\nstatic void lan78xx_free_tx_resources(struct lan78xx_net *dev)\n{\n\tlan78xx_free_buf_pool(&dev->txq_free);\n}\n\nstatic int lan78xx_alloc_tx_resources(struct lan78xx_net *dev)\n{\n\treturn lan78xx_alloc_buf_pool(&dev->txq_free,\n\t\t\t\t      dev->n_tx_urbs, dev->tx_urb_size, dev);\n}\n\nstatic int lan78xx_read_reg(struct lan78xx_net *dev, u32 index, u32 *data)\n{\n\tu32 *buf;\n\tint ret;\n\n\tif (test_bit(EVENT_DEV_DISCONNECT, &dev->flags))\n\t\treturn -ENODEV;\n\n\tbuf = kmalloc(sizeof(u32), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\n\t\t\t      USB_VENDOR_REQUEST_READ_REGISTER,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\n\t\t\t      0, index, buf, 4, USB_CTRL_GET_TIMEOUT);\n\tif (likely(ret >= 0)) {\n\t\tle32_to_cpus(buf);\n\t\t*data = *buf;\n\t} else if (net_ratelimit()) {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"Failed to read register index 0x%08x. ret = %d\",\n\t\t\t    index, ret);\n\t}\n\n\tkfree(buf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_write_reg(struct lan78xx_net *dev, u32 index, u32 data)\n{\n\tu32 *buf;\n\tint ret;\n\n\tif (test_bit(EVENT_DEV_DISCONNECT, &dev->flags))\n\t\treturn -ENODEV;\n\n\tbuf = kmalloc(sizeof(u32), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t*buf = data;\n\tcpu_to_le32s(buf);\n\n\tret = usb_control_msg(dev->udev, usb_sndctrlpipe(dev->udev, 0),\n\t\t\t      USB_VENDOR_REQUEST_WRITE_REGISTER,\n\t\t\t      USB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\n\t\t\t      0, index, buf, 4, USB_CTRL_SET_TIMEOUT);\n\tif (unlikely(ret < 0) &&\n\t    net_ratelimit()) {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"Failed to write register index 0x%08x. ret = %d\",\n\t\t\t    index, ret);\n\t}\n\n\tkfree(buf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_update_reg(struct lan78xx_net *dev, u32 reg, u32 mask,\n\t\t\t      u32 data)\n{\n\tint ret;\n\tu32 buf;\n\n\tret = lan78xx_read_reg(dev, reg, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf &= ~mask;\n\tbuf |= (mask & data);\n\n\tret = lan78xx_write_reg(dev, reg, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int lan78xx_read_stats(struct lan78xx_net *dev,\n\t\t\t      struct lan78xx_statstage *data)\n{\n\tint ret = 0;\n\tint i;\n\tstruct lan78xx_statstage *stats;\n\tu32 *src;\n\tu32 *dst;\n\n\tstats = kmalloc(sizeof(*stats), GFP_KERNEL);\n\tif (!stats)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(dev->udev,\n\t\t\t      usb_rcvctrlpipe(dev->udev, 0),\n\t\t\t      USB_VENDOR_REQUEST_GET_STATS,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\n\t\t\t      0,\n\t\t\t      0,\n\t\t\t      (void *)stats,\n\t\t\t      sizeof(*stats),\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (likely(ret >= 0)) {\n\t\tsrc = (u32 *)stats;\n\t\tdst = (u32 *)data;\n\t\tfor (i = 0; i < sizeof(*stats) / sizeof(u32); i++) {\n\t\t\tle32_to_cpus(&src[i]);\n\t\t\tdst[i] = src[i];\n\t\t}\n\t} else {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"Failed to read stat ret = %d\", ret);\n\t}\n\n\tkfree(stats);\n\n\treturn ret;\n}\n\n#define check_counter_rollover(struct1, dev_stats, member)\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif ((struct1)->member < (dev_stats).saved.member)\t\\\n\t\t\t(dev_stats).rollover_count.member++;\t\t\\\n\t} while (0)\n\nstatic void lan78xx_check_stat_rollover(struct lan78xx_net *dev,\n\t\t\t\t\tstruct lan78xx_statstage *stats)\n{\n\tcheck_counter_rollover(stats, dev->stats, rx_fcs_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_alignment_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_fragment_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_jabber_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_undersize_frame_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_oversize_frame_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_dropped_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_unicast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, rx_broadcast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, rx_multicast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, rx_unicast_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_broadcast_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_multicast_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_pause_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_64_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_65_127_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_128_255_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_256_511_bytes_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_512_1023_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_1024_1518_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_greater_1518_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, eee_rx_lpi_transitions);\n\tcheck_counter_rollover(stats, dev->stats, eee_rx_lpi_time);\n\tcheck_counter_rollover(stats, dev->stats, tx_fcs_errors);\n\tcheck_counter_rollover(stats, dev->stats, tx_excess_deferral_errors);\n\tcheck_counter_rollover(stats, dev->stats, tx_carrier_errors);\n\tcheck_counter_rollover(stats, dev->stats, tx_bad_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, tx_single_collisions);\n\tcheck_counter_rollover(stats, dev->stats, tx_multiple_collisions);\n\tcheck_counter_rollover(stats, dev->stats, tx_excessive_collision);\n\tcheck_counter_rollover(stats, dev->stats, tx_late_collisions);\n\tcheck_counter_rollover(stats, dev->stats, tx_unicast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, tx_broadcast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, tx_multicast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, tx_unicast_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_broadcast_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_multicast_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_pause_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_64_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_65_127_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_128_255_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_256_511_bytes_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_512_1023_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_1024_1518_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_greater_1518_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, eee_tx_lpi_transitions);\n\tcheck_counter_rollover(stats, dev->stats, eee_tx_lpi_time);\n\n\tmemcpy(&dev->stats.saved, stats, sizeof(struct lan78xx_statstage));\n}\n\nstatic void lan78xx_update_stats(struct lan78xx_net *dev)\n{\n\tu32 *p, *count, *max;\n\tu64 *data;\n\tint i;\n\tstruct lan78xx_statstage lan78xx_stats;\n\n\tif (usb_autopm_get_interface(dev->intf) < 0)\n\t\treturn;\n\n\tp = (u32 *)&lan78xx_stats;\n\tcount = (u32 *)&dev->stats.rollover_count;\n\tmax = (u32 *)&dev->stats.rollover_max;\n\tdata = (u64 *)&dev->stats.curr_stat;\n\n\tmutex_lock(&dev->stats.access_lock);\n\n\tif (lan78xx_read_stats(dev, &lan78xx_stats) > 0)\n\t\tlan78xx_check_stat_rollover(dev, &lan78xx_stats);\n\n\tfor (i = 0; i < (sizeof(lan78xx_stats) / (sizeof(u32))); i++)\n\t\tdata[i] = (u64)p[i] + ((u64)count[i] * ((u64)max[i] + 1));\n\n\tmutex_unlock(&dev->stats.access_lock);\n\n\tusb_autopm_put_interface(dev->intf);\n}\n\n/* Loop until the read is completed with timeout called with phy_mutex held */\nstatic int lan78xx_phy_wait_not_busy(struct lan78xx_net *dev)\n{\n\tunsigned long start_time = jiffies;\n\tu32 val;\n\tint ret;\n\n\tdo {\n\t\tret = lan78xx_read_reg(dev, MII_ACC, &val);\n\t\tif (unlikely(ret < 0))\n\t\t\treturn -EIO;\n\n\t\tif (!(val & MII_ACC_MII_BUSY_))\n\t\t\treturn 0;\n\t} while (!time_after(jiffies, start_time + HZ));\n\n\treturn -EIO;\n}\n\nstatic inline u32 mii_access(int id, int index, int read)\n{\n\tu32 ret;\n\n\tret = ((u32)id << MII_ACC_PHY_ADDR_SHIFT_) & MII_ACC_PHY_ADDR_MASK_;\n\tret |= ((u32)index << MII_ACC_MIIRINDA_SHIFT_) & MII_ACC_MIIRINDA_MASK_;\n\tif (read)\n\t\tret |= MII_ACC_MII_READ_;\n\telse\n\t\tret |= MII_ACC_MII_WRITE_;\n\tret |= MII_ACC_MII_BUSY_;\n\n\treturn ret;\n}\n\nstatic int lan78xx_wait_eeprom(struct lan78xx_net *dev)\n{\n\tunsigned long start_time = jiffies;\n\tu32 val;\n\tint ret;\n\n\tdo {\n\t\tret = lan78xx_read_reg(dev, E2P_CMD, &val);\n\t\tif (unlikely(ret < 0))\n\t\t\treturn -EIO;\n\n\t\tif (!(val & E2P_CMD_EPC_BUSY_) ||\n\t\t    (val & E2P_CMD_EPC_TIMEOUT_))\n\t\t\tbreak;\n\t\tusleep_range(40, 100);\n\t} while (!time_after(jiffies, start_time + HZ));\n\n\tif (val & (E2P_CMD_EPC_TIMEOUT_ | E2P_CMD_EPC_BUSY_)) {\n\t\tnetdev_warn(dev->net, \"EEPROM read operation timeout\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstatic int lan78xx_eeprom_confirm_not_busy(struct lan78xx_net *dev)\n{\n\tunsigned long start_time = jiffies;\n\tu32 val;\n\tint ret;\n\n\tdo {\n\t\tret = lan78xx_read_reg(dev, E2P_CMD, &val);\n\t\tif (unlikely(ret < 0))\n\t\t\treturn -EIO;\n\n\t\tif (!(val & E2P_CMD_EPC_BUSY_))\n\t\t\treturn 0;\n\n\t\tusleep_range(40, 100);\n\t} while (!time_after(jiffies, start_time + HZ));\n\n\tnetdev_warn(dev->net, \"EEPROM is busy\");\n\treturn -EIO;\n}\n\nstatic int lan78xx_read_raw_eeprom(struct lan78xx_net *dev, u32 offset,\n\t\t\t\t   u32 length, u8 *data)\n{\n\tu32 val;\n\tu32 saved;\n\tint i, ret;\n\tint retval;\n\n\t/* depends on chip, some EEPROM pins are muxed with LED function.\n\t * disable & restore LED function to access EEPROM.\n\t */\n\tret = lan78xx_read_reg(dev, HW_CFG, &val);\n\tsaved = val;\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_) {\n\t\tval &= ~(HW_CFG_LED1_EN_ | HW_CFG_LED0_EN_);\n\t\tret = lan78xx_write_reg(dev, HW_CFG, val);\n\t}\n\n\tretval = lan78xx_eeprom_confirm_not_busy(dev);\n\tif (retval)\n\t\treturn retval;\n\n\tfor (i = 0; i < length; i++) {\n\t\tval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_READ_;\n\t\tval |= (offset & E2P_CMD_EPC_ADDR_MASK_);\n\t\tret = lan78xx_write_reg(dev, E2P_CMD, val);\n\t\tif (unlikely(ret < 0)) {\n\t\t\tretval = -EIO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tretval = lan78xx_wait_eeprom(dev);\n\t\tif (retval < 0)\n\t\t\tgoto exit;\n\n\t\tret = lan78xx_read_reg(dev, E2P_DATA, &val);\n\t\tif (unlikely(ret < 0)) {\n\t\t\tretval = -EIO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tdata[i] = val & 0xFF;\n\t\toffset++;\n\t}\n\n\tretval = 0;\nexit:\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_)\n\t\tret = lan78xx_write_reg(dev, HW_CFG, saved);\n\n\treturn retval;\n}\n\nstatic int lan78xx_read_eeprom(struct lan78xx_net *dev, u32 offset,\n\t\t\t       u32 length, u8 *data)\n{\n\tu8 sig;\n\tint ret;\n\n\tret = lan78xx_read_raw_eeprom(dev, 0, 1, &sig);\n\tif ((ret == 0) && (sig == EEPROM_INDICATOR))\n\t\tret = lan78xx_read_raw_eeprom(dev, offset, length, data);\n\telse\n\t\tret = -EINVAL;\n\n\treturn ret;\n}\n\nstatic int lan78xx_write_raw_eeprom(struct lan78xx_net *dev, u32 offset,\n\t\t\t\t    u32 length, u8 *data)\n{\n\tu32 val;\n\tu32 saved;\n\tint i, ret;\n\tint retval;\n\n\t/* depends on chip, some EEPROM pins are muxed with LED function.\n\t * disable & restore LED function to access EEPROM.\n\t */\n\tret = lan78xx_read_reg(dev, HW_CFG, &val);\n\tsaved = val;\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_) {\n\t\tval &= ~(HW_CFG_LED1_EN_ | HW_CFG_LED0_EN_);\n\t\tret = lan78xx_write_reg(dev, HW_CFG, val);\n\t}\n\n\tretval = lan78xx_eeprom_confirm_not_busy(dev);\n\tif (retval)\n\t\tgoto exit;\n\n\t/* Issue write/erase enable command */\n\tval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_EWEN_;\n\tret = lan78xx_write_reg(dev, E2P_CMD, val);\n\tif (unlikely(ret < 0)) {\n\t\tretval = -EIO;\n\t\tgoto exit;\n\t}\n\n\tretval = lan78xx_wait_eeprom(dev);\n\tif (retval < 0)\n\t\tgoto exit;\n\n\tfor (i = 0; i < length; i++) {\n\t\t/* Fill data register */\n\t\tval = data[i];\n\t\tret = lan78xx_write_reg(dev, E2P_DATA, val);\n\t\tif (ret < 0) {\n\t\t\tretval = -EIO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\t/* Send \"write\" command */\n\t\tval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_WRITE_;\n\t\tval |= (offset & E2P_CMD_EPC_ADDR_MASK_);\n\t\tret = lan78xx_write_reg(dev, E2P_CMD, val);\n\t\tif (ret < 0) {\n\t\t\tretval = -EIO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tretval = lan78xx_wait_eeprom(dev);\n\t\tif (retval < 0)\n\t\t\tgoto exit;\n\n\t\toffset++;\n\t}\n\n\tretval = 0;\nexit:\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_)\n\t\tret = lan78xx_write_reg(dev, HW_CFG, saved);\n\n\treturn retval;\n}\n\nstatic int lan78xx_read_raw_otp(struct lan78xx_net *dev, u32 offset,\n\t\t\t\tu32 length, u8 *data)\n{\n\tint i;\n\tu32 buf;\n\tunsigned long timeout;\n\n\tlan78xx_read_reg(dev, OTP_PWR_DN, &buf);\n\n\tif (buf & OTP_PWR_DN_PWRDN_N_) {\n\t\t/* clear it and wait to be cleared */\n\t\tlan78xx_write_reg(dev, OTP_PWR_DN, 0);\n\n\t\ttimeout = jiffies + HZ;\n\t\tdo {\n\t\t\tusleep_range(1, 10);\n\t\t\tlan78xx_read_reg(dev, OTP_PWR_DN, &buf);\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tnetdev_warn(dev->net,\n\t\t\t\t\t    \"timeout on OTP_PWR_DN\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} while (buf & OTP_PWR_DN_PWRDN_N_);\n\t}\n\n\tfor (i = 0; i < length; i++) {\n\t\tlan78xx_write_reg(dev, OTP_ADDR1,\n\t\t\t\t  ((offset + i) >> 8) & OTP_ADDR1_15_11);\n\t\tlan78xx_write_reg(dev, OTP_ADDR2,\n\t\t\t\t  ((offset + i) & OTP_ADDR2_10_3));\n\n\t\tlan78xx_write_reg(dev, OTP_FUNC_CMD, OTP_FUNC_CMD_READ_);\n\t\tlan78xx_write_reg(dev, OTP_CMD_GO, OTP_CMD_GO_GO_);\n\n\t\ttimeout = jiffies + HZ;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t\tlan78xx_read_reg(dev, OTP_STATUS, &buf);\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tnetdev_warn(dev->net,\n\t\t\t\t\t    \"timeout on OTP_STATUS\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} while (buf & OTP_STATUS_BUSY_);\n\n\t\tlan78xx_read_reg(dev, OTP_RD_DATA, &buf);\n\n\t\tdata[i] = (u8)(buf & 0xFF);\n\t}\n\n\treturn 0;\n}\n\nstatic int lan78xx_write_raw_otp(struct lan78xx_net *dev, u32 offset,\n\t\t\t\t u32 length, u8 *data)\n{\n\tint i;\n\tu32 buf;\n\tunsigned long timeout;\n\n\tlan78xx_read_reg(dev, OTP_PWR_DN, &buf);\n\n\tif (buf & OTP_PWR_DN_PWRDN_N_) {\n\t\t/* clear it and wait to be cleared */\n\t\tlan78xx_write_reg(dev, OTP_PWR_DN, 0);\n\n\t\ttimeout = jiffies + HZ;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t\tlan78xx_read_reg(dev, OTP_PWR_DN, &buf);\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tnetdev_warn(dev->net,\n\t\t\t\t\t    \"timeout on OTP_PWR_DN completion\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} while (buf & OTP_PWR_DN_PWRDN_N_);\n\t}\n\n\t/* set to BYTE program mode */\n\tlan78xx_write_reg(dev, OTP_PRGM_MODE, OTP_PRGM_MODE_BYTE_);\n\n\tfor (i = 0; i < length; i++) {\n\t\tlan78xx_write_reg(dev, OTP_ADDR1,\n\t\t\t\t  ((offset + i) >> 8) & OTP_ADDR1_15_11);\n\t\tlan78xx_write_reg(dev, OTP_ADDR2,\n\t\t\t\t  ((offset + i) & OTP_ADDR2_10_3));\n\t\tlan78xx_write_reg(dev, OTP_PRGM_DATA, data[i]);\n\t\tlan78xx_write_reg(dev, OTP_TST_CMD, OTP_TST_CMD_PRGVRFY_);\n\t\tlan78xx_write_reg(dev, OTP_CMD_GO, OTP_CMD_GO_GO_);\n\n\t\ttimeout = jiffies + HZ;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t\tlan78xx_read_reg(dev, OTP_STATUS, &buf);\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tnetdev_warn(dev->net,\n\t\t\t\t\t    \"Timeout on OTP_STATUS completion\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} while (buf & OTP_STATUS_BUSY_);\n\t}\n\n\treturn 0;\n}\n\nstatic int lan78xx_read_otp(struct lan78xx_net *dev, u32 offset,\n\t\t\t    u32 length, u8 *data)\n{\n\tu8 sig;\n\tint ret;\n\n\tret = lan78xx_read_raw_otp(dev, 0, 1, &sig);\n\n\tif (ret == 0) {\n\t\tif (sig == OTP_INDICATOR_2)\n\t\t\toffset += 0x100;\n\t\telse if (sig != OTP_INDICATOR_1)\n\t\t\tret = -EINVAL;\n\t\tif (!ret)\n\t\t\tret = lan78xx_read_raw_otp(dev, offset, length, data);\n\t}\n\n\treturn ret;\n}\n\nstatic int lan78xx_dataport_wait_not_busy(struct lan78xx_net *dev)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < 100; i++) {\n\t\tu32 dp_sel;\n\n\t\tret = lan78xx_read_reg(dev, DP_SEL, &dp_sel);\n\t\tif (unlikely(ret < 0))\n\t\t\treturn -EIO;\n\n\t\tif (dp_sel & DP_SEL_DPRDY_)\n\t\t\treturn 0;\n\n\t\tusleep_range(40, 100);\n\t}\n\n\tnetdev_warn(dev->net, \"%s timed out\", __func__);\n\n\treturn -EIO;\n}\n\nstatic int lan78xx_dataport_write(struct lan78xx_net *dev, u32 ram_select,\n\t\t\t\t  u32 addr, u32 length, u32 *buf)\n{\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tu32 dp_sel;\n\tint i, ret;\n\n\tif (usb_autopm_get_interface(dev->intf) < 0)\n\t\treturn 0;\n\n\tmutex_lock(&pdata->dataport_mutex);\n\n\tret = lan78xx_dataport_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tret = lan78xx_read_reg(dev, DP_SEL, &dp_sel);\n\n\tdp_sel &= ~DP_SEL_RSEL_MASK_;\n\tdp_sel |= ram_select;\n\tret = lan78xx_write_reg(dev, DP_SEL, dp_sel);\n\n\tfor (i = 0; i < length; i++) {\n\t\tret = lan78xx_write_reg(dev, DP_ADDR, addr + i);\n\n\t\tret = lan78xx_write_reg(dev, DP_DATA, buf[i]);\n\n\t\tret = lan78xx_write_reg(dev, DP_CMD, DP_CMD_WRITE_);\n\n\t\tret = lan78xx_dataport_wait_not_busy(dev);\n\t\tif (ret < 0)\n\t\t\tgoto done;\n\t}\n\ndone:\n\tmutex_unlock(&pdata->dataport_mutex);\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic void lan78xx_set_addr_filter(struct lan78xx_priv *pdata,\n\t\t\t\t    int index, u8 addr[ETH_ALEN])\n{\n\tu32 temp;\n\n\tif ((pdata) && (index > 0) && (index < NUM_OF_MAF)) {\n\t\ttemp = addr[3];\n\t\ttemp = addr[2] | (temp << 8);\n\t\ttemp = addr[1] | (temp << 8);\n\t\ttemp = addr[0] | (temp << 8);\n\t\tpdata->pfilter_table[index][1] = temp;\n\t\ttemp = addr[5];\n\t\ttemp = addr[4] | (temp << 8);\n\t\ttemp |= MAF_HI_VALID_ | MAF_HI_TYPE_DST_;\n\t\tpdata->pfilter_table[index][0] = temp;\n\t}\n}\n\n/* returns hash bit number for given MAC address */\nstatic inline u32 lan78xx_hash(char addr[ETH_ALEN])\n{\n\treturn (ether_crc(ETH_ALEN, addr) >> 23) & 0x1ff;\n}\n\nstatic void lan78xx_deferred_multicast_write(struct work_struct *param)\n{\n\tstruct lan78xx_priv *pdata =\n\t\t\tcontainer_of(param, struct lan78xx_priv, set_multicast);\n\tstruct lan78xx_net *dev = pdata->dev;\n\tint i;\n\n\tnetif_dbg(dev, drv, dev->net, \"deferred multicast write 0x%08x\\n\",\n\t\t  pdata->rfe_ctl);\n\n\tlan78xx_dataport_write(dev, DP_SEL_RSEL_VLAN_DA_, DP_SEL_VHF_VLAN_LEN,\n\t\t\t       DP_SEL_VHF_HASH_LEN, pdata->mchash_table);\n\n\tfor (i = 1; i < NUM_OF_MAF; i++) {\n\t\tlan78xx_write_reg(dev, MAF_HI(i), 0);\n\t\tlan78xx_write_reg(dev, MAF_LO(i),\n\t\t\t\t  pdata->pfilter_table[i][1]);\n\t\tlan78xx_write_reg(dev, MAF_HI(i),\n\t\t\t\t  pdata->pfilter_table[i][0]);\n\t}\n\n\tlan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\n}\n\nstatic void lan78xx_set_multicast(struct net_device *netdev)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&pdata->rfe_ctl_lock, flags);\n\n\tpdata->rfe_ctl &= ~(RFE_CTL_UCAST_EN_ | RFE_CTL_MCAST_EN_ |\n\t\t\t    RFE_CTL_DA_PERFECT_ | RFE_CTL_MCAST_HASH_);\n\n\tfor (i = 0; i < DP_SEL_VHF_HASH_LEN; i++)\n\t\tpdata->mchash_table[i] = 0;\n\n\t/* pfilter_table[0] has own HW address */\n\tfor (i = 1; i < NUM_OF_MAF; i++) {\n\t\tpdata->pfilter_table[i][0] = 0;\n\t\tpdata->pfilter_table[i][1] = 0;\n\t}\n\n\tpdata->rfe_ctl |= RFE_CTL_BCAST_EN_;\n\n\tif (dev->net->flags & IFF_PROMISC) {\n\t\tnetif_dbg(dev, drv, dev->net, \"promiscuous mode enabled\");\n\t\tpdata->rfe_ctl |= RFE_CTL_MCAST_EN_ | RFE_CTL_UCAST_EN_;\n\t} else {\n\t\tif (dev->net->flags & IFF_ALLMULTI) {\n\t\t\tnetif_dbg(dev, drv, dev->net,\n\t\t\t\t  \"receive all multicast enabled\");\n\t\t\tpdata->rfe_ctl |= RFE_CTL_MCAST_EN_;\n\t\t}\n\t}\n\n\tif (netdev_mc_count(dev->net)) {\n\t\tstruct netdev_hw_addr *ha;\n\t\tint i;\n\n\t\tnetif_dbg(dev, drv, dev->net, \"receive multicast hash filter\");\n\n\t\tpdata->rfe_ctl |= RFE_CTL_DA_PERFECT_;\n\n\t\ti = 1;\n\t\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\t\t/* set first 32 into Perfect Filter */\n\t\t\tif (i < 33) {\n\t\t\t\tlan78xx_set_addr_filter(pdata, i, ha->addr);\n\t\t\t} else {\n\t\t\t\tu32 bitnum = lan78xx_hash(ha->addr);\n\n\t\t\t\tpdata->mchash_table[bitnum / 32] |=\n\t\t\t\t\t\t\t(1 << (bitnum % 32));\n\t\t\t\tpdata->rfe_ctl |= RFE_CTL_MCAST_HASH_;\n\t\t\t}\n\t\t\ti++;\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&pdata->rfe_ctl_lock, flags);\n\n\t/* defer register writes to a sleepable context */\n\tschedule_work(&pdata->set_multicast);\n}\n\nstatic int lan78xx_update_flowcontrol(struct lan78xx_net *dev, u8 duplex,\n\t\t\t\t      u16 lcladv, u16 rmtadv)\n{\n\tu32 flow = 0, fct_flow = 0;\n\tu8 cap;\n\n\tif (dev->fc_autoneg)\n\t\tcap = mii_resolve_flowctrl_fdx(lcladv, rmtadv);\n\telse\n\t\tcap = dev->fc_request_control;\n\n\tif (cap & FLOW_CTRL_TX)\n\t\tflow |= (FLOW_CR_TX_FCEN_ | 0xFFFF);\n\n\tif (cap & FLOW_CTRL_RX)\n\t\tflow |= FLOW_CR_RX_FCEN_;\n\n\tif (dev->udev->speed == USB_SPEED_SUPER)\n\t\tfct_flow = FLOW_CTRL_THRESHOLD(FLOW_ON_SS, FLOW_OFF_SS);\n\telse if (dev->udev->speed == USB_SPEED_HIGH)\n\t\tfct_flow = FLOW_CTRL_THRESHOLD(FLOW_ON_HS, FLOW_OFF_HS);\n\n\tnetif_dbg(dev, link, dev->net, \"rx pause %s, tx pause %s\",\n\t\t  (cap & FLOW_CTRL_RX ? \"enabled\" : \"disabled\"),\n\t\t  (cap & FLOW_CTRL_TX ? \"enabled\" : \"disabled\"));\n\n\tlan78xx_write_reg(dev, FCT_FLOW, fct_flow);\n\n\t/* threshold value should be set before enabling flow */\n\tlan78xx_write_reg(dev, FLOW, flow);\n\n\treturn 0;\n}\n\nstatic void lan78xx_rx_urb_submit_all(struct lan78xx_net *dev);\n\nstatic int lan78xx_mac_reset(struct lan78xx_net *dev)\n{\n\tunsigned long start_time = jiffies;\n\tu32 val;\n\tint ret;\n\n\tmutex_lock(&dev->phy_mutex);\n\n\t/* Resetting the device while there is activity on the MDIO\n\t * bus can result in the MAC interface locking up and not\n\t * completing register access transactions.\n\t */\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tret = lan78xx_read_reg(dev, MAC_CR, &val);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tval |= MAC_CR_RST_;\n\tret = lan78xx_write_reg(dev, MAC_CR, val);\n\tif (ret < 0)\n\t\tgoto done;\n\n\t/* Wait for the reset to complete before allowing any further\n\t * MAC register accesses otherwise the MAC may lock up.\n\t */\n\tdo {\n\t\tret = lan78xx_read_reg(dev, MAC_CR, &val);\n\t\tif (ret < 0)\n\t\t\tgoto done;\n\n\t\tif (!(val & MAC_CR_RST_)) {\n\t\t\tret = 0;\n\t\t\tgoto done;\n\t\t}\n\t} while (!time_after(jiffies, start_time + HZ));\n\n\tret = -ETIMEDOUT;\ndone:\n\tmutex_unlock(&dev->phy_mutex);\n\n\treturn ret;\n}\n\nstatic int lan78xx_link_reset(struct lan78xx_net *dev)\n{\n\tstruct phy_device *phydev = dev->net->phydev;\n\tstruct ethtool_link_ksettings ecmd;\n\tint ladv, radv, ret, link;\n\tu32 buf;\n\n\t/* clear LAN78xx interrupt status */\n\tret = lan78xx_write_reg(dev, INT_STS, INT_STS_PHY_INT_);\n\tif (unlikely(ret < 0))\n\t\treturn ret;\n\n\tmutex_lock(&phydev->lock);\n\tphy_read_status(phydev);\n\tlink = phydev->link;\n\tmutex_unlock(&phydev->lock);\n\n\tif (!link && dev->link_on) {\n\t\tdev->link_on = false;\n\n\t\t/* reset MAC */\n\t\tret = lan78xx_mac_reset(dev);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tdel_timer(&dev->stat_monitor);\n\t} else if (link && !dev->link_on) {\n\t\tdev->link_on = true;\n\n\t\tphy_ethtool_ksettings_get(phydev, &ecmd);\n\n\t\tif (dev->udev->speed == USB_SPEED_SUPER) {\n\t\t\tif (ecmd.base.speed == 1000) {\n\t\t\t\t/* disable U2 */\n\t\t\t\tret = lan78xx_read_reg(dev, USB_CFG1, &buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tbuf &= ~USB_CFG1_DEV_U2_INIT_EN_;\n\t\t\t\tret = lan78xx_write_reg(dev, USB_CFG1, buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\t/* enable U1 */\n\t\t\t\tret = lan78xx_read_reg(dev, USB_CFG1, &buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tbuf |= USB_CFG1_DEV_U1_INIT_EN_;\n\t\t\t\tret = lan78xx_write_reg(dev, USB_CFG1, buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t} else {\n\t\t\t\t/* enable U1 & U2 */\n\t\t\t\tret = lan78xx_read_reg(dev, USB_CFG1, &buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tbuf |= USB_CFG1_DEV_U2_INIT_EN_;\n\t\t\t\tbuf |= USB_CFG1_DEV_U1_INIT_EN_;\n\t\t\t\tret = lan78xx_write_reg(dev, USB_CFG1, buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t\tladv = phy_read(phydev, MII_ADVERTISE);\n\t\tif (ladv < 0)\n\t\t\treturn ladv;\n\n\t\tradv = phy_read(phydev, MII_LPA);\n\t\tif (radv < 0)\n\t\t\treturn radv;\n\n\t\tnetif_dbg(dev, link, dev->net,\n\t\t\t  \"speed: %u duplex: %d anadv: 0x%04x anlpa: 0x%04x\",\n\t\t\t  ecmd.base.speed, ecmd.base.duplex, ladv, radv);\n\n\t\tret = lan78xx_update_flowcontrol(dev, ecmd.base.duplex, ladv,\n\t\t\t\t\t\t radv);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (!timer_pending(&dev->stat_monitor)) {\n\t\t\tdev->delta = 1;\n\t\t\tmod_timer(&dev->stat_monitor,\n\t\t\t\t  jiffies + STAT_UPDATE_TIMER);\n\t\t}\n\n\t\tlan78xx_rx_urb_submit_all(dev);\n\n\t\tnapi_schedule(&dev->napi);\n\t}\n\n\treturn 0;\n}\n\n/* some work can't be done in tasklets, so we use keventd\n *\n * NOTE:  annoying asymmetry:  if it's active, schedule_work() fails,\n * but tasklet_schedule() doesn't.\thope the failure is rare.\n */\nstatic void lan78xx_defer_kevent(struct lan78xx_net *dev, int work)\n{\n\tset_bit(work, &dev->flags);\n\tif (!schedule_delayed_work(&dev->wq, 0))\n\t\tnetdev_err(dev->net, \"kevent %d may have been dropped\\n\", work);\n}\n\nstatic void lan78xx_status(struct lan78xx_net *dev, struct urb *urb)\n{\n\tu32 intdata;\n\n\tif (urb->actual_length != 4) {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"unexpected urb length %d\", urb->actual_length);\n\t\treturn;\n\t}\n\n\tintdata = get_unaligned_le32(urb->transfer_buffer);\n\n\tif (intdata & INT_ENP_PHY_INT) {\n\t\tnetif_dbg(dev, link, dev->net, \"PHY INTR: 0x%08x\\n\", intdata);\n\t\tlan78xx_defer_kevent(dev, EVENT_LINK_RESET);\n\n\t\tif (dev->domain_data.phyirq > 0)\n\t\t\tgeneric_handle_irq_safe(dev->domain_data.phyirq);\n\t} else {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"unexpected interrupt: 0x%08x\\n\", intdata);\n\t}\n}\n\nstatic int lan78xx_ethtool_get_eeprom_len(struct net_device *netdev)\n{\n\treturn MAX_EEPROM_SIZE;\n}\n\nstatic int lan78xx_ethtool_get_eeprom(struct net_device *netdev,\n\t\t\t\t      struct ethtool_eeprom *ee, u8 *data)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret)\n\t\treturn ret;\n\n\tee->magic = LAN78XX_EEPROM_MAGIC;\n\n\tret = lan78xx_read_raw_eeprom(dev, ee->offset, ee->len, data);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_ethtool_set_eeprom(struct net_device *netdev,\n\t\t\t\t      struct ethtool_eeprom *ee, u8 *data)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Invalid EEPROM_INDICATOR at offset zero will result in a failure\n\t * to load data from EEPROM\n\t */\n\tif (ee->magic == LAN78XX_EEPROM_MAGIC)\n\t\tret = lan78xx_write_raw_eeprom(dev, ee->offset, ee->len, data);\n\telse if ((ee->magic == LAN78XX_OTP_MAGIC) &&\n\t\t (ee->offset == 0) &&\n\t\t (ee->len == 512) &&\n\t\t (data[0] == OTP_INDICATOR_1))\n\t\tret = lan78xx_write_raw_otp(dev, ee->offset, ee->len, data);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic void lan78xx_get_strings(struct net_device *netdev, u32 stringset,\n\t\t\t\tu8 *data)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\tmemcpy(data, lan78xx_gstrings, sizeof(lan78xx_gstrings));\n}\n\nstatic int lan78xx_get_sset_count(struct net_device *netdev, int sset)\n{\n\tif (sset == ETH_SS_STATS)\n\t\treturn ARRAY_SIZE(lan78xx_gstrings);\n\telse\n\t\treturn -EOPNOTSUPP;\n}\n\nstatic void lan78xx_get_stats(struct net_device *netdev,\n\t\t\t      struct ethtool_stats *stats, u64 *data)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\n\tlan78xx_update_stats(dev);\n\n\tmutex_lock(&dev->stats.access_lock);\n\tmemcpy(data, &dev->stats.curr_stat, sizeof(dev->stats.curr_stat));\n\tmutex_unlock(&dev->stats.access_lock);\n}\n\nstatic void lan78xx_get_wol(struct net_device *netdev,\n\t\t\t    struct ethtool_wolinfo *wol)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tint ret;\n\tu32 buf;\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\n\tif (usb_autopm_get_interface(dev->intf) < 0)\n\t\treturn;\n\n\tret = lan78xx_read_reg(dev, USB_CFG0, &buf);\n\tif (unlikely(ret < 0)) {\n\t\twol->supported = 0;\n\t\twol->wolopts = 0;\n\t} else {\n\t\tif (buf & USB_CFG_RMT_WKP_) {\n\t\t\twol->supported = WAKE_ALL;\n\t\t\twol->wolopts = pdata->wol;\n\t\t} else {\n\t\t\twol->supported = 0;\n\t\t\twol->wolopts = 0;\n\t\t}\n\t}\n\n\tusb_autopm_put_interface(dev->intf);\n}\n\nstatic int lan78xx_set_wol(struct net_device *netdev,\n\t\t\t   struct ethtool_wolinfo *wol)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (wol->wolopts & ~WAKE_ALL)\n\t\treturn -EINVAL;\n\n\tpdata->wol = wol->wolopts;\n\n\tdevice_set_wakeup_enable(&dev->udev->dev, (bool)wol->wolopts);\n\n\tphy_ethtool_set_wol(netdev->phydev, wol);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_get_eee(struct net_device *net, struct ethtool_eee *edata)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tint ret;\n\tu32 buf;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = phy_ethtool_get_eee(phydev, edata);\n\tif (ret < 0)\n\t\tgoto exit;\n\n\tret = lan78xx_read_reg(dev, MAC_CR, &buf);\n\tif (buf & MAC_CR_EEE_EN_) {\n\t\tedata->eee_enabled = true;\n\t\tedata->eee_active = !!(edata->advertised &\n\t\t\t\t       edata->lp_advertised);\n\t\tedata->tx_lpi_enabled = true;\n\t\t/* EEE_TX_LPI_REQ_DLY & tx_lpi_timer are same uSec unit */\n\t\tret = lan78xx_read_reg(dev, EEE_TX_LPI_REQ_DLY, &buf);\n\t\tedata->tx_lpi_timer = buf;\n\t} else {\n\t\tedata->eee_enabled = false;\n\t\tedata->eee_active = false;\n\t\tedata->tx_lpi_enabled = false;\n\t\tedata->tx_lpi_timer = 0;\n\t}\n\n\tret = 0;\nexit:\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_set_eee(struct net_device *net, struct ethtool_eee *edata)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tint ret;\n\tu32 buf;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (edata->eee_enabled) {\n\t\tret = lan78xx_read_reg(dev, MAC_CR, &buf);\n\t\tbuf |= MAC_CR_EEE_EN_;\n\t\tret = lan78xx_write_reg(dev, MAC_CR, buf);\n\n\t\tphy_ethtool_set_eee(net->phydev, edata);\n\n\t\tbuf = (u32)edata->tx_lpi_timer;\n\t\tret = lan78xx_write_reg(dev, EEE_TX_LPI_REQ_DLY, buf);\n\t} else {\n\t\tret = lan78xx_read_reg(dev, MAC_CR, &buf);\n\t\tbuf &= ~MAC_CR_EEE_EN_;\n\t\tret = lan78xx_write_reg(dev, MAC_CR, buf);\n\t}\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn 0;\n}\n\nstatic u32 lan78xx_get_link(struct net_device *net)\n{\n\tu32 link;\n\n\tmutex_lock(&net->phydev->lock);\n\tphy_read_status(net->phydev);\n\tlink = net->phydev->link;\n\tmutex_unlock(&net->phydev->lock);\n\n\treturn link;\n}\n\nstatic void lan78xx_get_drvinfo(struct net_device *net,\n\t\t\t\tstruct ethtool_drvinfo *info)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\tstrncpy(info->driver, DRIVER_NAME, sizeof(info->driver));\n\tusb_make_path(dev->udev, info->bus_info, sizeof(info->bus_info));\n}\n\nstatic u32 lan78xx_get_msglevel(struct net_device *net)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\treturn dev->msg_enable;\n}\n\nstatic void lan78xx_set_msglevel(struct net_device *net, u32 level)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\tdev->msg_enable = level;\n}\n\nstatic int lan78xx_get_link_ksettings(struct net_device *net,\n\t\t\t\t      struct ethtool_link_ksettings *cmd)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tphy_ethtool_ksettings_get(phydev, cmd);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_set_link_ksettings(struct net_device *net,\n\t\t\t\t      const struct ethtool_link_ksettings *cmd)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tint ret = 0;\n\tint temp;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* change speed & duplex */\n\tret = phy_ethtool_ksettings_set(phydev, cmd);\n\n\tif (!cmd->base.autoneg) {\n\t\t/* force link down */\n\t\ttemp = phy_read(phydev, MII_BMCR);\n\t\tphy_write(phydev, MII_BMCR, temp | BMCR_LOOPBACK);\n\t\tmdelay(1);\n\t\tphy_write(phydev, MII_BMCR, temp);\n\t}\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic void lan78xx_get_pause(struct net_device *net,\n\t\t\t      struct ethtool_pauseparam *pause)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tstruct ethtool_link_ksettings ecmd;\n\n\tphy_ethtool_ksettings_get(phydev, &ecmd);\n\n\tpause->autoneg = dev->fc_autoneg;\n\n\tif (dev->fc_request_control & FLOW_CTRL_TX)\n\t\tpause->tx_pause = 1;\n\n\tif (dev->fc_request_control & FLOW_CTRL_RX)\n\t\tpause->rx_pause = 1;\n}\n\nstatic int lan78xx_set_pause(struct net_device *net,\n\t\t\t     struct ethtool_pauseparam *pause)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tstruct ethtool_link_ksettings ecmd;\n\tint ret;\n\n\tphy_ethtool_ksettings_get(phydev, &ecmd);\n\n\tif (pause->autoneg && !ecmd.base.autoneg) {\n\t\tret = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\tdev->fc_request_control = 0;\n\tif (pause->rx_pause)\n\t\tdev->fc_request_control |= FLOW_CTRL_RX;\n\n\tif (pause->tx_pause)\n\t\tdev->fc_request_control |= FLOW_CTRL_TX;\n\n\tif (ecmd.base.autoneg) {\n\t\t__ETHTOOL_DECLARE_LINK_MODE_MASK(fc) = { 0, };\n\t\tu32 mii_adv;\n\n\t\tlinkmode_clear_bit(ETHTOOL_LINK_MODE_Pause_BIT,\n\t\t\t\t   ecmd.link_modes.advertising);\n\t\tlinkmode_clear_bit(ETHTOOL_LINK_MODE_Asym_Pause_BIT,\n\t\t\t\t   ecmd.link_modes.advertising);\n\t\tmii_adv = (u32)mii_advertise_flowctrl(dev->fc_request_control);\n\t\tmii_adv_to_linkmode_adv_t(fc, mii_adv);\n\t\tlinkmode_or(ecmd.link_modes.advertising, fc,\n\t\t\t    ecmd.link_modes.advertising);\n\n\t\tphy_ethtool_ksettings_set(phydev, &ecmd);\n\t}\n\n\tdev->fc_autoneg = pause->autoneg;\n\n\tret = 0;\nexit:\n\treturn ret;\n}\n\nstatic int lan78xx_get_regs_len(struct net_device *netdev)\n{\n\tif (!netdev->phydev)\n\t\treturn (sizeof(lan78xx_regs));\n\telse\n\t\treturn (sizeof(lan78xx_regs) + PHY_REG_SIZE);\n}\n\nstatic void\nlan78xx_get_regs(struct net_device *netdev, struct ethtool_regs *regs,\n\t\t void *buf)\n{\n\tu32 *data = buf;\n\tint i, j;\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\n\t/* Read Device/MAC registers */\n\tfor (i = 0; i < ARRAY_SIZE(lan78xx_regs); i++)\n\t\tlan78xx_read_reg(dev, lan78xx_regs[i], &data[i]);\n\n\tif (!netdev->phydev)\n\t\treturn;\n\n\t/* Read PHY registers */\n\tfor (j = 0; j < 32; i++, j++)\n\t\tdata[i] = phy_read(netdev->phydev, j);\n}\n\nstatic const struct ethtool_ops lan78xx_ethtool_ops = {\n\t.get_link\t= lan78xx_get_link,\n\t.nway_reset\t= phy_ethtool_nway_reset,\n\t.get_drvinfo\t= lan78xx_get_drvinfo,\n\t.get_msglevel\t= lan78xx_get_msglevel,\n\t.set_msglevel\t= lan78xx_set_msglevel,\n\t.get_eeprom_len = lan78xx_ethtool_get_eeprom_len,\n\t.get_eeprom\t= lan78xx_ethtool_get_eeprom,\n\t.set_eeprom\t= lan78xx_ethtool_set_eeprom,\n\t.get_ethtool_stats = lan78xx_get_stats,\n\t.get_sset_count = lan78xx_get_sset_count,\n\t.get_strings\t= lan78xx_get_strings,\n\t.get_wol\t= lan78xx_get_wol,\n\t.set_wol\t= lan78xx_set_wol,\n\t.get_ts_info\t= ethtool_op_get_ts_info,\n\t.get_eee\t= lan78xx_get_eee,\n\t.set_eee\t= lan78xx_set_eee,\n\t.get_pauseparam\t= lan78xx_get_pause,\n\t.set_pauseparam\t= lan78xx_set_pause,\n\t.get_link_ksettings = lan78xx_get_link_ksettings,\n\t.set_link_ksettings = lan78xx_set_link_ksettings,\n\t.get_regs_len\t= lan78xx_get_regs_len,\n\t.get_regs\t= lan78xx_get_regs,\n};\n\nstatic void lan78xx_init_mac_address(struct lan78xx_net *dev)\n{\n\tu32 addr_lo, addr_hi;\n\tu8 addr[6];\n\n\tlan78xx_read_reg(dev, RX_ADDRL, &addr_lo);\n\tlan78xx_read_reg(dev, RX_ADDRH, &addr_hi);\n\n\taddr[0] = addr_lo & 0xFF;\n\taddr[1] = (addr_lo >> 8) & 0xFF;\n\taddr[2] = (addr_lo >> 16) & 0xFF;\n\taddr[3] = (addr_lo >> 24) & 0xFF;\n\taddr[4] = addr_hi & 0xFF;\n\taddr[5] = (addr_hi >> 8) & 0xFF;\n\n\tif (!is_valid_ether_addr(addr)) {\n\t\tif (!eth_platform_get_mac_address(&dev->udev->dev, addr)) {\n\t\t\t/* valid address present in Device Tree */\n\t\t\tnetif_dbg(dev, ifup, dev->net,\n\t\t\t\t  \"MAC address read from Device Tree\");\n\t\t} else if (((lan78xx_read_eeprom(dev, EEPROM_MAC_OFFSET,\n\t\t\t\t\t\t ETH_ALEN, addr) == 0) ||\n\t\t\t    (lan78xx_read_otp(dev, EEPROM_MAC_OFFSET,\n\t\t\t\t\t      ETH_ALEN, addr) == 0)) &&\n\t\t\t   is_valid_ether_addr(addr)) {\n\t\t\t/* eeprom values are valid so use them */\n\t\t\tnetif_dbg(dev, ifup, dev->net,\n\t\t\t\t  \"MAC address read from EEPROM\");\n\t\t} else {\n\t\t\t/* generate random MAC */\n\t\t\teth_random_addr(addr);\n\t\t\tnetif_dbg(dev, ifup, dev->net,\n\t\t\t\t  \"MAC address set to random addr\");\n\t\t}\n\n\t\taddr_lo = addr[0] | (addr[1] << 8) |\n\t\t\t  (addr[2] << 16) | (addr[3] << 24);\n\t\taddr_hi = addr[4] | (addr[5] << 8);\n\n\t\tlan78xx_write_reg(dev, RX_ADDRL, addr_lo);\n\t\tlan78xx_write_reg(dev, RX_ADDRH, addr_hi);\n\t}\n\n\tlan78xx_write_reg(dev, MAF_LO(0), addr_lo);\n\tlan78xx_write_reg(dev, MAF_HI(0), addr_hi | MAF_HI_VALID_);\n\n\teth_hw_addr_set(dev->net, addr);\n}\n\n/* MDIO read and write wrappers for phylib */\nstatic int lan78xx_mdiobus_read(struct mii_bus *bus, int phy_id, int idx)\n{\n\tstruct lan78xx_net *dev = bus->priv;\n\tu32 val, addr;\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&dev->phy_mutex);\n\n\t/* confirm MII not busy */\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\t/* set the address, index & direction (read from PHY) */\n\taddr = mii_access(phy_id, idx, MII_READ);\n\tret = lan78xx_write_reg(dev, MII_ACC, addr);\n\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tret = lan78xx_read_reg(dev, MII_DATA, &val);\n\n\tret = (int)(val & 0xFFFF);\n\ndone:\n\tmutex_unlock(&dev->phy_mutex);\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_mdiobus_write(struct mii_bus *bus, int phy_id, int idx,\n\t\t\t\t u16 regval)\n{\n\tstruct lan78xx_net *dev = bus->priv;\n\tu32 val, addr;\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&dev->phy_mutex);\n\n\t/* confirm MII not busy */\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tval = (u32)regval;\n\tret = lan78xx_write_reg(dev, MII_DATA, val);\n\n\t/* set the address, index & direction (write to PHY) */\n\taddr = mii_access(phy_id, idx, MII_WRITE);\n\tret = lan78xx_write_reg(dev, MII_ACC, addr);\n\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\ndone:\n\tmutex_unlock(&dev->phy_mutex);\n\tusb_autopm_put_interface(dev->intf);\n\treturn 0;\n}\n\nstatic int lan78xx_mdio_init(struct lan78xx_net *dev)\n{\n\tstruct device_node *node;\n\tint ret;\n\n\tdev->mdiobus = mdiobus_alloc();\n\tif (!dev->mdiobus) {\n\t\tnetdev_err(dev->net, \"can't allocate MDIO bus\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tdev->mdiobus->priv = (void *)dev;\n\tdev->mdiobus->read = lan78xx_mdiobus_read;\n\tdev->mdiobus->write = lan78xx_mdiobus_write;\n\tdev->mdiobus->name = \"lan78xx-mdiobus\";\n\tdev->mdiobus->parent = &dev->udev->dev;\n\n\tsnprintf(dev->mdiobus->id, MII_BUS_ID_SIZE, \"usb-%03d:%03d\",\n\t\t dev->udev->bus->busnum, dev->udev->devnum);\n\n\tswitch (dev->chipid) {\n\tcase ID_REV_CHIP_ID_7800_:\n\tcase ID_REV_CHIP_ID_7850_:\n\t\t/* set to internal PHY id */\n\t\tdev->mdiobus->phy_mask = ~(1 << 1);\n\t\tbreak;\n\tcase ID_REV_CHIP_ID_7801_:\n\t\t/* scan thru PHYAD[2..0] */\n\t\tdev->mdiobus->phy_mask = ~(0xFF);\n\t\tbreak;\n\t}\n\n\tnode = of_get_child_by_name(dev->udev->dev.of_node, \"mdio\");\n\tret = of_mdiobus_register(dev->mdiobus, node);\n\tof_node_put(node);\n\tif (ret) {\n\t\tnetdev_err(dev->net, \"can't register MDIO bus\\n\");\n\t\tgoto exit1;\n\t}\n\n\tnetdev_dbg(dev->net, \"registered mdiobus bus %s\\n\", dev->mdiobus->id);\n\treturn 0;\nexit1:\n\tmdiobus_free(dev->mdiobus);\n\treturn ret;\n}\n\nstatic void lan78xx_remove_mdio(struct lan78xx_net *dev)\n{\n\tmdiobus_unregister(dev->mdiobus);\n\tmdiobus_free(dev->mdiobus);\n}\n\nstatic void lan78xx_link_status_change(struct net_device *net)\n{\n\tstruct phy_device *phydev = net->phydev;\n\n\tphy_print_status(phydev);\n}\n\nstatic int irq_map(struct irq_domain *d, unsigned int irq,\n\t\t   irq_hw_number_t hwirq)\n{\n\tstruct irq_domain_data *data = d->host_data;\n\n\tirq_set_chip_data(irq, data);\n\tirq_set_chip_and_handler(irq, data->irqchip, data->irq_handler);\n\tirq_set_noprobe(irq);\n\n\treturn 0;\n}\n\nstatic void irq_unmap(struct irq_domain *d, unsigned int irq)\n{\n\tirq_set_chip_and_handler(irq, NULL, NULL);\n\tirq_set_chip_data(irq, NULL);\n}\n\nstatic const struct irq_domain_ops chip_domain_ops = {\n\t.map\t= irq_map,\n\t.unmap\t= irq_unmap,\n};\n\nstatic void lan78xx_irq_mask(struct irq_data *irqd)\n{\n\tstruct irq_domain_data *data = irq_data_get_irq_chip_data(irqd);\n\n\tdata->irqenable &= ~BIT(irqd_to_hwirq(irqd));\n}\n\nstatic void lan78xx_irq_unmask(struct irq_data *irqd)\n{\n\tstruct irq_domain_data *data = irq_data_get_irq_chip_data(irqd);\n\n\tdata->irqenable |= BIT(irqd_to_hwirq(irqd));\n}\n\nstatic void lan78xx_irq_bus_lock(struct irq_data *irqd)\n{\n\tstruct irq_domain_data *data = irq_data_get_irq_chip_data(irqd);\n\n\tmutex_lock(&data->irq_lock);\n}\n\nstatic void lan78xx_irq_bus_sync_unlock(struct irq_data *irqd)\n{\n\tstruct irq_domain_data *data = irq_data_get_irq_chip_data(irqd);\n\tstruct lan78xx_net *dev =\n\t\t\tcontainer_of(data, struct lan78xx_net, domain_data);\n\tu32 buf;\n\n\t/* call register access here because irq_bus_lock & irq_bus_sync_unlock\n\t * are only two callbacks executed in non-atomic contex.\n\t */\n\tlan78xx_read_reg(dev, INT_EP_CTL, &buf);\n\tif (buf != data->irqenable)\n\t\tlan78xx_write_reg(dev, INT_EP_CTL, data->irqenable);\n\n\tmutex_unlock(&data->irq_lock);\n}\n\nstatic struct irq_chip lan78xx_irqchip = {\n\t.name\t\t\t= \"lan78xx-irqs\",\n\t.irq_mask\t\t= lan78xx_irq_mask,\n\t.irq_unmask\t\t= lan78xx_irq_unmask,\n\t.irq_bus_lock\t\t= lan78xx_irq_bus_lock,\n\t.irq_bus_sync_unlock\t= lan78xx_irq_bus_sync_unlock,\n};\n\nstatic int lan78xx_setup_irq_domain(struct lan78xx_net *dev)\n{\n\tstruct device_node *of_node;\n\tstruct irq_domain *irqdomain;\n\tunsigned int irqmap = 0;\n\tu32 buf;\n\tint ret = 0;\n\n\tof_node = dev->udev->dev.parent->of_node;\n\n\tmutex_init(&dev->domain_data.irq_lock);\n\n\tlan78xx_read_reg(dev, INT_EP_CTL, &buf);\n\tdev->domain_data.irqenable = buf;\n\n\tdev->domain_data.irqchip = &lan78xx_irqchip;\n\tdev->domain_data.irq_handler = handle_simple_irq;\n\n\tirqdomain = irq_domain_add_simple(of_node, MAX_INT_EP, 0,\n\t\t\t\t\t  &chip_domain_ops, &dev->domain_data);\n\tif (irqdomain) {\n\t\t/* create mapping for PHY interrupt */\n\t\tirqmap = irq_create_mapping(irqdomain, INT_EP_PHY);\n\t\tif (!irqmap) {\n\t\t\tirq_domain_remove(irqdomain);\n\n\t\t\tirqdomain = NULL;\n\t\t\tret = -EINVAL;\n\t\t}\n\t} else {\n\t\tret = -EINVAL;\n\t}\n\n\tdev->domain_data.irqdomain = irqdomain;\n\tdev->domain_data.phyirq = irqmap;\n\n\treturn ret;\n}\n\nstatic void lan78xx_remove_irq_domain(struct lan78xx_net *dev)\n{\n\tif (dev->domain_data.phyirq > 0) {\n\t\tirq_dispose_mapping(dev->domain_data.phyirq);\n\n\t\tif (dev->domain_data.irqdomain)\n\t\t\tirq_domain_remove(dev->domain_data.irqdomain);\n\t}\n\tdev->domain_data.phyirq = 0;\n\tdev->domain_data.irqdomain = NULL;\n}\n\nstatic int lan8835_fixup(struct phy_device *phydev)\n{\n\tint buf;\n\tstruct lan78xx_net *dev = netdev_priv(phydev->attached_dev);\n\n\t/* LED2/PME_N/IRQ_N/RGMII_ID pin to IRQ_N mode */\n\tbuf = phy_read_mmd(phydev, MDIO_MMD_PCS, 0x8010);\n\tbuf &= ~0x1800;\n\tbuf |= 0x0800;\n\tphy_write_mmd(phydev, MDIO_MMD_PCS, 0x8010, buf);\n\n\t/* RGMII MAC TXC Delay Enable */\n\tlan78xx_write_reg(dev, MAC_RGMII_ID,\n\t\t\t  MAC_RGMII_ID_TXC_DELAY_EN_);\n\n\t/* RGMII TX DLL Tune Adjust */\n\tlan78xx_write_reg(dev, RGMII_TX_BYP_DLL, 0x3D00);\n\n\tdev->interface = PHY_INTERFACE_MODE_RGMII_TXID;\n\n\treturn 1;\n}\n\nstatic int ksz9031rnx_fixup(struct phy_device *phydev)\n{\n\tstruct lan78xx_net *dev = netdev_priv(phydev->attached_dev);\n\n\t/* Micrel9301RNX PHY configuration */\n\t/* RGMII Control Signal Pad Skew */\n\tphy_write_mmd(phydev, MDIO_MMD_WIS, 4, 0x0077);\n\t/* RGMII RX Data Pad Skew */\n\tphy_write_mmd(phydev, MDIO_MMD_WIS, 5, 0x7777);\n\t/* RGMII RX Clock Pad Skew */\n\tphy_write_mmd(phydev, MDIO_MMD_WIS, 8, 0x1FF);\n\n\tdev->interface = PHY_INTERFACE_MODE_RGMII_RXID;\n\n\treturn 1;\n}\n\nstatic struct phy_device *lan7801_phy_init(struct lan78xx_net *dev)\n{\n\tu32 buf;\n\tint ret;\n\tstruct fixed_phy_status fphy_status = {\n\t\t.link = 1,\n\t\t.speed = SPEED_1000,\n\t\t.duplex = DUPLEX_FULL,\n\t};\n\tstruct phy_device *phydev;\n\n\tphydev = phy_find_first(dev->mdiobus);\n\tif (!phydev) {\n\t\tnetdev_dbg(dev->net, \"PHY Not Found!! Registering Fixed PHY\\n\");\n\t\tphydev = fixed_phy_register(PHY_POLL, &fphy_status, NULL);\n\t\tif (IS_ERR(phydev)) {\n\t\t\tnetdev_err(dev->net, \"No PHY/fixed_PHY found\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\tnetdev_dbg(dev->net, \"Registered FIXED PHY\\n\");\n\t\tdev->interface = PHY_INTERFACE_MODE_RGMII;\n\t\tret = lan78xx_write_reg(dev, MAC_RGMII_ID,\n\t\t\t\t\tMAC_RGMII_ID_TXC_DELAY_EN_);\n\t\tret = lan78xx_write_reg(dev, RGMII_TX_BYP_DLL, 0x3D00);\n\t\tret = lan78xx_read_reg(dev, HW_CFG, &buf);\n\t\tbuf |= HW_CFG_CLK125_EN_;\n\t\tbuf |= HW_CFG_REFCLK25_EN_;\n\t\tret = lan78xx_write_reg(dev, HW_CFG, buf);\n\t} else {\n\t\tif (!phydev->drv) {\n\t\t\tnetdev_err(dev->net, \"no PHY driver found\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\tdev->interface = PHY_INTERFACE_MODE_RGMII;\n\t\t/* external PHY fixup for KSZ9031RNX */\n\t\tret = phy_register_fixup_for_uid(PHY_KSZ9031RNX, 0xfffffff0,\n\t\t\t\t\t\t ksz9031rnx_fixup);\n\t\tif (ret < 0) {\n\t\t\tnetdev_err(dev->net, \"Failed to register fixup for PHY_KSZ9031RNX\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\t/* external PHY fixup for LAN8835 */\n\t\tret = phy_register_fixup_for_uid(PHY_LAN8835, 0xfffffff0,\n\t\t\t\t\t\t lan8835_fixup);\n\t\tif (ret < 0) {\n\t\t\tnetdev_err(dev->net, \"Failed to register fixup for PHY_LAN8835\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\t/* add more external PHY fixup here if needed */\n\n\t\tphydev->is_internal = false;\n\t}\n\treturn phydev;\n}\n\nstatic int lan78xx_phy_init(struct lan78xx_net *dev)\n{\n\t__ETHTOOL_DECLARE_LINK_MODE_MASK(fc) = { 0, };\n\tint ret;\n\tu32 mii_adv;\n\tstruct phy_device *phydev;\n\n\tswitch (dev->chipid) {\n\tcase ID_REV_CHIP_ID_7801_:\n\t\tphydev = lan7801_phy_init(dev);\n\t\tif (!phydev) {\n\t\t\tnetdev_err(dev->net, \"lan7801: PHY Init Failed\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tbreak;\n\n\tcase ID_REV_CHIP_ID_7800_:\n\tcase ID_REV_CHIP_ID_7850_:\n\t\tphydev = phy_find_first(dev->mdiobus);\n\t\tif (!phydev) {\n\t\t\tnetdev_err(dev->net, \"no PHY found\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tphydev->is_internal = true;\n\t\tdev->interface = PHY_INTERFACE_MODE_GMII;\n\t\tbreak;\n\n\tdefault:\n\t\tnetdev_err(dev->net, \"Unknown CHIP ID found\\n\");\n\t\treturn -EIO;\n\t}\n\n\t/* if phyirq is not set, use polling mode in phylib */\n\tif (dev->domain_data.phyirq > 0)\n\t\tphydev->irq = dev->domain_data.phyirq;\n\telse\n\t\tphydev->irq = PHY_POLL;\n\tnetdev_dbg(dev->net, \"phydev->irq = %d\\n\", phydev->irq);\n\n\t/* set to AUTOMDIX */\n\tphydev->mdix = ETH_TP_MDI_AUTO;\n\n\tret = phy_connect_direct(dev->net, phydev,\n\t\t\t\t lan78xx_link_status_change,\n\t\t\t\t dev->interface);\n\tif (ret) {\n\t\tnetdev_err(dev->net, \"can't attach PHY to %s\\n\",\n\t\t\t   dev->mdiobus->id);\n\t\tif (dev->chipid == ID_REV_CHIP_ID_7801_) {\n\t\t\tif (phy_is_pseudo_fixed_link(phydev)) {\n\t\t\t\tfixed_phy_unregister(phydev);\n\t\t\t} else {\n\t\t\t\tphy_unregister_fixup_for_uid(PHY_KSZ9031RNX,\n\t\t\t\t\t\t\t     0xfffffff0);\n\t\t\t\tphy_unregister_fixup_for_uid(PHY_LAN8835,\n\t\t\t\t\t\t\t     0xfffffff0);\n\t\t\t}\n\t\t}\n\t\treturn -EIO;\n\t}\n\n\t/* MAC doesn't support 1000T Half */\n\tphy_remove_link_mode(phydev, ETHTOOL_LINK_MODE_1000baseT_Half_BIT);\n\n\t/* support both flow controls */\n\tdev->fc_request_control = (FLOW_CTRL_RX | FLOW_CTRL_TX);\n\tlinkmode_clear_bit(ETHTOOL_LINK_MODE_Pause_BIT,\n\t\t\t   phydev->advertising);\n\tlinkmode_clear_bit(ETHTOOL_LINK_MODE_Asym_Pause_BIT,\n\t\t\t   phydev->advertising);\n\tmii_adv = (u32)mii_advertise_flowctrl(dev->fc_request_control);\n\tmii_adv_to_linkmode_adv_t(fc, mii_adv);\n\tlinkmode_or(phydev->advertising, fc, phydev->advertising);\n\n\tif (phydev->mdio.dev.of_node) {\n\t\tu32 reg;\n\t\tint len;\n\n\t\tlen = of_property_count_elems_of_size(phydev->mdio.dev.of_node,\n\t\t\t\t\t\t      \"microchip,led-modes\",\n\t\t\t\t\t\t      sizeof(u32));\n\t\tif (len >= 0) {\n\t\t\t/* Ensure the appropriate LEDs are enabled */\n\t\t\tlan78xx_read_reg(dev, HW_CFG, &reg);\n\t\t\treg &= ~(HW_CFG_LED0_EN_ |\n\t\t\t\t HW_CFG_LED1_EN_ |\n\t\t\t\t HW_CFG_LED2_EN_ |\n\t\t\t\t HW_CFG_LED3_EN_);\n\t\t\treg |= (len > 0) * HW_CFG_LED0_EN_ |\n\t\t\t\t(len > 1) * HW_CFG_LED1_EN_ |\n\t\t\t\t(len > 2) * HW_CFG_LED2_EN_ |\n\t\t\t\t(len > 3) * HW_CFG_LED3_EN_;\n\t\t\tlan78xx_write_reg(dev, HW_CFG, reg);\n\t\t}\n\t}\n\n\tgenphy_config_aneg(phydev);\n\n\tdev->fc_autoneg = phydev->autoneg;\n\n\treturn 0;\n}\n\nstatic int lan78xx_set_rx_max_frame_length(struct lan78xx_net *dev, int size)\n{\n\tu32 buf;\n\tbool rxenabled;\n\n\tlan78xx_read_reg(dev, MAC_RX, &buf);\n\n\trxenabled = ((buf & MAC_RX_RXEN_) != 0);\n\n\tif (rxenabled) {\n\t\tbuf &= ~MAC_RX_RXEN_;\n\t\tlan78xx_write_reg(dev, MAC_RX, buf);\n\t}\n\n\t/* add 4 to size for FCS */\n\tbuf &= ~MAC_RX_MAX_SIZE_MASK_;\n\tbuf |= (((size + 4) << MAC_RX_MAX_SIZE_SHIFT_) & MAC_RX_MAX_SIZE_MASK_);\n\n\tlan78xx_write_reg(dev, MAC_RX, buf);\n\n\tif (rxenabled) {\n\t\tbuf |= MAC_RX_RXEN_;\n\t\tlan78xx_write_reg(dev, MAC_RX, buf);\n\t}\n\n\treturn 0;\n}\n\nstatic int unlink_urbs(struct lan78xx_net *dev, struct sk_buff_head *q)\n{\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\tint count = 0;\n\n\tspin_lock_irqsave(&q->lock, flags);\n\twhile (!skb_queue_empty(q)) {\n\t\tstruct skb_data\t*entry;\n\t\tstruct urb *urb;\n\t\tint ret;\n\n\t\tskb_queue_walk(q, skb) {\n\t\t\tentry = (struct skb_data *)skb->cb;\n\t\t\tif (entry->state != unlink_start)\n\t\t\t\tgoto found;\n\t\t}\n\t\tbreak;\nfound:\n\t\tentry->state = unlink_start;\n\t\turb = entry->urb;\n\n\t\t/* Get reference count of the URB to avoid it to be\n\t\t * freed during usb_unlink_urb, which may trigger\n\t\t * use-after-free problem inside usb_unlink_urb since\n\t\t * usb_unlink_urb is always racing with .complete\n\t\t * handler(include defer_bh).\n\t\t */\n\t\tusb_get_urb(urb);\n\t\tspin_unlock_irqrestore(&q->lock, flags);\n\t\t/* during some PM-driven resume scenarios,\n\t\t * these (async) unlinks complete immediately\n\t\t */\n\t\tret = usb_unlink_urb(urb);\n\t\tif (ret != -EINPROGRESS && ret != 0)\n\t\t\tnetdev_dbg(dev->net, \"unlink urb err, %d\\n\", ret);\n\t\telse\n\t\t\tcount++;\n\t\tusb_put_urb(urb);\n\t\tspin_lock_irqsave(&q->lock, flags);\n\t}\n\tspin_unlock_irqrestore(&q->lock, flags);\n\treturn count;\n}\n\nstatic int lan78xx_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tint max_frame_len = RX_MAX_FRAME_LEN(new_mtu);\n\tint ret;\n\n\t/* no second zero-length packet read wanted after mtu-sized packets */\n\tif ((max_frame_len % dev->maxpacket) == 0)\n\t\treturn -EDOM;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_set_rx_max_frame_length(dev, max_frame_len);\n\tif (!ret)\n\t\tnetdev->mtu = new_mtu;\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_set_mac_addr(struct net_device *netdev, void *p)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct sockaddr *addr = p;\n\tu32 addr_lo, addr_hi;\n\n\tif (netif_running(netdev))\n\t\treturn -EBUSY;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\teth_hw_addr_set(netdev, addr->sa_data);\n\n\taddr_lo = netdev->dev_addr[0] |\n\t\t  netdev->dev_addr[1] << 8 |\n\t\t  netdev->dev_addr[2] << 16 |\n\t\t  netdev->dev_addr[3] << 24;\n\taddr_hi = netdev->dev_addr[4] |\n\t\t  netdev->dev_addr[5] << 8;\n\n\tlan78xx_write_reg(dev, RX_ADDRL, addr_lo);\n\tlan78xx_write_reg(dev, RX_ADDRH, addr_hi);\n\n\t/* Added to support MAC address changes */\n\tlan78xx_write_reg(dev, MAF_LO(0), addr_lo);\n\tlan78xx_write_reg(dev, MAF_HI(0), addr_hi | MAF_HI_VALID_);\n\n\treturn 0;\n}\n\n/* Enable or disable Rx checksum offload engine */\nstatic int lan78xx_set_features(struct net_device *netdev,\n\t\t\t\tnetdev_features_t features)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pdata->rfe_ctl_lock, flags);\n\n\tif (features & NETIF_F_RXCSUM) {\n\t\tpdata->rfe_ctl |= RFE_CTL_TCPUDP_COE_ | RFE_CTL_IP_COE_;\n\t\tpdata->rfe_ctl |= RFE_CTL_ICMP_COE_ | RFE_CTL_IGMP_COE_;\n\t} else {\n\t\tpdata->rfe_ctl &= ~(RFE_CTL_TCPUDP_COE_ | RFE_CTL_IP_COE_);\n\t\tpdata->rfe_ctl &= ~(RFE_CTL_ICMP_COE_ | RFE_CTL_IGMP_COE_);\n\t}\n\n\tif (features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\tpdata->rfe_ctl |= RFE_CTL_VLAN_STRIP_;\n\telse\n\t\tpdata->rfe_ctl &= ~RFE_CTL_VLAN_STRIP_;\n\n\tif (features & NETIF_F_HW_VLAN_CTAG_FILTER)\n\t\tpdata->rfe_ctl |= RFE_CTL_VLAN_FILTER_;\n\telse\n\t\tpdata->rfe_ctl &= ~RFE_CTL_VLAN_FILTER_;\n\n\tspin_unlock_irqrestore(&pdata->rfe_ctl_lock, flags);\n\n\tlan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\n\n\treturn 0;\n}\n\nstatic void lan78xx_deferred_vlan_write(struct work_struct *param)\n{\n\tstruct lan78xx_priv *pdata =\n\t\t\tcontainer_of(param, struct lan78xx_priv, set_vlan);\n\tstruct lan78xx_net *dev = pdata->dev;\n\n\tlan78xx_dataport_write(dev, DP_SEL_RSEL_VLAN_DA_, 0,\n\t\t\t       DP_SEL_VHF_VLAN_LEN, pdata->vlan_table);\n}\n\nstatic int lan78xx_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t   __be16 proto, u16 vid)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tu16 vid_bit_index;\n\tu16 vid_dword_index;\n\n\tvid_dword_index = (vid >> 5) & 0x7F;\n\tvid_bit_index = vid & 0x1F;\n\n\tpdata->vlan_table[vid_dword_index] |= (1 << vid_bit_index);\n\n\t/* defer register writes to a sleepable context */\n\tschedule_work(&pdata->set_vlan);\n\n\treturn 0;\n}\n\nstatic int lan78xx_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t    __be16 proto, u16 vid)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tu16 vid_bit_index;\n\tu16 vid_dword_index;\n\n\tvid_dword_index = (vid >> 5) & 0x7F;\n\tvid_bit_index = vid & 0x1F;\n\n\tpdata->vlan_table[vid_dword_index] &= ~(1 << vid_bit_index);\n\n\t/* defer register writes to a sleepable context */\n\tschedule_work(&pdata->set_vlan);\n\n\treturn 0;\n}\n\nstatic void lan78xx_init_ltm(struct lan78xx_net *dev)\n{\n\tint ret;\n\tu32 buf;\n\tu32 regs[6] = { 0 };\n\n\tret = lan78xx_read_reg(dev, USB_CFG1, &buf);\n\tif (buf & USB_CFG1_LTM_ENABLE_) {\n\t\tu8 temp[2];\n\t\t/* Get values from EEPROM first */\n\t\tif (lan78xx_read_eeprom(dev, 0x3F, 2, temp) == 0) {\n\t\t\tif (temp[0] == 24) {\n\t\t\t\tret = lan78xx_read_raw_eeprom(dev,\n\t\t\t\t\t\t\t      temp[1] * 2,\n\t\t\t\t\t\t\t      24,\n\t\t\t\t\t\t\t      (u8 *)regs);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t} else if (lan78xx_read_otp(dev, 0x3F, 2, temp) == 0) {\n\t\t\tif (temp[0] == 24) {\n\t\t\t\tret = lan78xx_read_raw_otp(dev,\n\t\t\t\t\t\t\t   temp[1] * 2,\n\t\t\t\t\t\t\t   24,\n\t\t\t\t\t\t\t   (u8 *)regs);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\tlan78xx_write_reg(dev, LTM_BELT_IDLE0, regs[0]);\n\tlan78xx_write_reg(dev, LTM_BELT_IDLE1, regs[1]);\n\tlan78xx_write_reg(dev, LTM_BELT_ACT0, regs[2]);\n\tlan78xx_write_reg(dev, LTM_BELT_ACT1, regs[3]);\n\tlan78xx_write_reg(dev, LTM_INACTIVE0, regs[4]);\n\tlan78xx_write_reg(dev, LTM_INACTIVE1, regs[5]);\n}\n\nstatic int lan78xx_urb_config_init(struct lan78xx_net *dev)\n{\n\tint result = 0;\n\n\tswitch (dev->udev->speed) {\n\tcase USB_SPEED_SUPER:\n\t\tdev->rx_urb_size = RX_SS_URB_SIZE;\n\t\tdev->tx_urb_size = TX_SS_URB_SIZE;\n\t\tdev->n_rx_urbs = RX_SS_URB_NUM;\n\t\tdev->n_tx_urbs = TX_SS_URB_NUM;\n\t\tdev->bulk_in_delay = SS_BULK_IN_DELAY;\n\t\tdev->burst_cap = SS_BURST_CAP_SIZE / SS_USB_PKT_SIZE;\n\t\tbreak;\n\tcase USB_SPEED_HIGH:\n\t\tdev->rx_urb_size = RX_HS_URB_SIZE;\n\t\tdev->tx_urb_size = TX_HS_URB_SIZE;\n\t\tdev->n_rx_urbs = RX_HS_URB_NUM;\n\t\tdev->n_tx_urbs = TX_HS_URB_NUM;\n\t\tdev->bulk_in_delay = HS_BULK_IN_DELAY;\n\t\tdev->burst_cap = HS_BURST_CAP_SIZE / HS_USB_PKT_SIZE;\n\t\tbreak;\n\tcase USB_SPEED_FULL:\n\t\tdev->rx_urb_size = RX_FS_URB_SIZE;\n\t\tdev->tx_urb_size = TX_FS_URB_SIZE;\n\t\tdev->n_rx_urbs = RX_FS_URB_NUM;\n\t\tdev->n_tx_urbs = TX_FS_URB_NUM;\n\t\tdev->bulk_in_delay = FS_BULK_IN_DELAY;\n\t\tdev->burst_cap = FS_BURST_CAP_SIZE / FS_USB_PKT_SIZE;\n\t\tbreak;\n\tdefault:\n\t\tnetdev_warn(dev->net, \"USB bus speed not supported\\n\");\n\t\tresult = -EIO;\n\t\tbreak;\n\t}\n\n\treturn result;\n}\n\nstatic int lan78xx_start_hw(struct lan78xx_net *dev, u32 reg, u32 hw_enable)\n{\n\treturn lan78xx_update_reg(dev, reg, hw_enable, hw_enable);\n}\n\nstatic int lan78xx_stop_hw(struct lan78xx_net *dev, u32 reg, u32 hw_enabled,\n\t\t\t   u32 hw_disabled)\n{\n\tunsigned long timeout;\n\tbool stopped = true;\n\tint ret;\n\tu32 buf;\n\n\t/* Stop the h/w block (if not already stopped) */\n\n\tret = lan78xx_read_reg(dev, reg, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (buf & hw_enabled) {\n\t\tbuf &= ~hw_enabled;\n\n\t\tret = lan78xx_write_reg(dev, reg, buf);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tstopped = false;\n\t\ttimeout = jiffies + HW_DISABLE_TIMEOUT;\n\t\tdo  {\n\t\t\tret = lan78xx_read_reg(dev, reg, &buf);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\n\t\t\tif (buf & hw_disabled)\n\t\t\t\tstopped = true;\n\t\t\telse\n\t\t\t\tmsleep(HW_DISABLE_DELAY_MS);\n\t\t} while (!stopped && !time_after(jiffies, timeout));\n\t}\n\n\tret = stopped ? 0 : -ETIME;\n\n\treturn ret;\n}\n\nstatic int lan78xx_flush_fifo(struct lan78xx_net *dev, u32 reg, u32 fifo_flush)\n{\n\treturn lan78xx_update_reg(dev, reg, fifo_flush, fifo_flush);\n}\n\nstatic int lan78xx_start_tx_path(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\tnetif_dbg(dev, drv, dev->net, \"start tx path\");\n\n\t/* Start the MAC transmitter */\n\n\tret = lan78xx_start_hw(dev, MAC_TX, MAC_TX_TXEN_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Start the Tx FIFO */\n\n\tret = lan78xx_start_hw(dev, FCT_TX_CTL, FCT_TX_CTL_EN_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int lan78xx_stop_tx_path(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\tnetif_dbg(dev, drv, dev->net, \"stop tx path\");\n\n\t/* Stop the Tx FIFO */\n\n\tret = lan78xx_stop_hw(dev, FCT_TX_CTL, FCT_TX_CTL_EN_, FCT_TX_CTL_DIS_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Stop the MAC transmitter */\n\n\tret = lan78xx_stop_hw(dev, MAC_TX, MAC_TX_TXEN_, MAC_TX_TXD_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n/* The caller must ensure the Tx path is stopped before calling\n * lan78xx_flush_tx_fifo().\n */\nstatic int lan78xx_flush_tx_fifo(struct lan78xx_net *dev)\n{\n\treturn lan78xx_flush_fifo(dev, FCT_TX_CTL, FCT_TX_CTL_RST_);\n}\n\nstatic int lan78xx_start_rx_path(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\tnetif_dbg(dev, drv, dev->net, \"start rx path\");\n\n\t/* Start the Rx FIFO */\n\n\tret = lan78xx_start_hw(dev, FCT_RX_CTL, FCT_RX_CTL_EN_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Start the MAC receiver*/\n\n\tret = lan78xx_start_hw(dev, MAC_RX, MAC_RX_RXEN_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int lan78xx_stop_rx_path(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\tnetif_dbg(dev, drv, dev->net, \"stop rx path\");\n\n\t/* Stop the MAC receiver */\n\n\tret = lan78xx_stop_hw(dev, MAC_RX, MAC_RX_RXEN_, MAC_RX_RXD_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Stop the Rx FIFO */\n\n\tret = lan78xx_stop_hw(dev, FCT_RX_CTL, FCT_RX_CTL_EN_, FCT_RX_CTL_DIS_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n/* The caller must ensure the Rx path is stopped before calling\n * lan78xx_flush_rx_fifo().\n */\nstatic int lan78xx_flush_rx_fifo(struct lan78xx_net *dev)\n{\n\treturn lan78xx_flush_fifo(dev, FCT_RX_CTL, FCT_RX_CTL_RST_);\n}\n\nstatic int lan78xx_reset(struct lan78xx_net *dev)\n{\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tunsigned long timeout;\n\tint ret;\n\tu32 buf;\n\tu8 sig;\n\n\tret = lan78xx_read_reg(dev, HW_CFG, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= HW_CFG_LRST_;\n\n\tret = lan78xx_write_reg(dev, HW_CFG, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttimeout = jiffies + HZ;\n\tdo {\n\t\tmdelay(1);\n\t\tret = lan78xx_read_reg(dev, HW_CFG, &buf);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (time_after(jiffies, timeout)) {\n\t\t\tnetdev_warn(dev->net,\n\t\t\t\t    \"timeout on completion of LiteReset\");\n\t\t\tret = -ETIMEDOUT;\n\t\t\treturn ret;\n\t\t}\n\t} while (buf & HW_CFG_LRST_);\n\n\tlan78xx_init_mac_address(dev);\n\n\t/* save DEVID for later usage */\n\tret = lan78xx_read_reg(dev, ID_REV, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tdev->chipid = (buf & ID_REV_CHIP_ID_MASK_) >> 16;\n\tdev->chiprev = buf & ID_REV_CHIP_REV_MASK_;\n\n\t/* Respond to the IN token with a NAK */\n\tret = lan78xx_read_reg(dev, USB_CFG0, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= USB_CFG_BIR_;\n\n\tret = lan78xx_write_reg(dev, USB_CFG0, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Init LTM */\n\tlan78xx_init_ltm(dev);\n\n\tret = lan78xx_write_reg(dev, BURST_CAP, dev->burst_cap);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, BULK_IN_DLY, dev->bulk_in_delay);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_read_reg(dev, HW_CFG, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= HW_CFG_MEF_;\n\n\tret = lan78xx_write_reg(dev, HW_CFG, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_read_reg(dev, USB_CFG0, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= USB_CFG_BCE_;\n\n\tret = lan78xx_write_reg(dev, USB_CFG0, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* set FIFO sizes */\n\tbuf = (MAX_RX_FIFO_SIZE - 512) / 512;\n\n\tret = lan78xx_write_reg(dev, FCT_RX_FIFO_END, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf = (MAX_TX_FIFO_SIZE - 512) / 512;\n\n\tret = lan78xx_write_reg(dev, FCT_TX_FIFO_END, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, INT_STS, INT_STS_CLEAR_ALL_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, FLOW, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, FCT_FLOW, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Don't need rfe_ctl_lock during initialisation */\n\tret = lan78xx_read_reg(dev, RFE_CTL, &pdata->rfe_ctl);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tpdata->rfe_ctl |= RFE_CTL_BCAST_EN_ | RFE_CTL_DA_PERFECT_;\n\n\tret = lan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Enable or disable checksum offload engines */\n\tret = lan78xx_set_features(dev->net, dev->net->features);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tlan78xx_set_multicast(dev->net);\n\n\t/* reset PHY */\n\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= PMT_CTL_PHY_RST_;\n\n\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttimeout = jiffies + HZ;\n\tdo {\n\t\tmdelay(1);\n\t\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (time_after(jiffies, timeout)) {\n\t\t\tnetdev_warn(dev->net, \"timeout waiting for PHY Reset\");\n\t\t\tret = -ETIMEDOUT;\n\t\t\treturn ret;\n\t\t}\n\t} while ((buf & PMT_CTL_PHY_RST_) || !(buf & PMT_CTL_READY_));\n\n\tret = lan78xx_read_reg(dev, MAC_CR, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* LAN7801 only has RGMII mode */\n\tif (dev->chipid == ID_REV_CHIP_ID_7801_)\n\t\tbuf &= ~MAC_CR_GMII_EN_;\n\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_) {\n\t\tret = lan78xx_read_raw_eeprom(dev, 0, 1, &sig);\n\t\tif (!ret && sig != EEPROM_INDICATOR) {\n\t\t\t/* Implies there is no external eeprom. Set mac speed */\n\t\t\tnetdev_info(dev->net, \"No External EEPROM. Setting MAC Speed\\n\");\n\t\t\tbuf |= MAC_CR_AUTO_DUPLEX_ | MAC_CR_AUTO_SPEED_;\n\t\t}\n\t}\n\tret = lan78xx_write_reg(dev, MAC_CR, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_set_rx_max_frame_length(dev,\n\t\t\t\t\t      RX_MAX_FRAME_LEN(dev->net->mtu));\n\n\treturn ret;\n}\n\nstatic void lan78xx_init_stats(struct lan78xx_net *dev)\n{\n\tu32 *p;\n\tint i;\n\n\t/* initialize for stats update\n\t * some counters are 20bits and some are 32bits\n\t */\n\tp = (u32 *)&dev->stats.rollover_max;\n\tfor (i = 0; i < (sizeof(dev->stats.rollover_max) / (sizeof(u32))); i++)\n\t\tp[i] = 0xFFFFF;\n\n\tdev->stats.rollover_max.rx_unicast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.rx_broadcast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.rx_multicast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.eee_rx_lpi_transitions = 0xFFFFFFFF;\n\tdev->stats.rollover_max.eee_rx_lpi_time = 0xFFFFFFFF;\n\tdev->stats.rollover_max.tx_unicast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.tx_broadcast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.tx_multicast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.eee_tx_lpi_transitions = 0xFFFFFFFF;\n\tdev->stats.rollover_max.eee_tx_lpi_time = 0xFFFFFFFF;\n\n\tset_bit(EVENT_STAT_UPDATE, &dev->flags);\n}\n\nstatic int lan78xx_open(struct net_device *net)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tint ret;\n\n\tnetif_dbg(dev, ifup, dev->net, \"open device\");\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&dev->dev_mutex);\n\n\tphy_start(net->phydev);\n\n\tnetif_dbg(dev, ifup, dev->net, \"phy initialised successfully\");\n\n\t/* for Link Check */\n\tif (dev->urb_intr) {\n\t\tret = usb_submit_urb(dev->urb_intr, GFP_KERNEL);\n\t\tif (ret < 0) {\n\t\t\tnetif_err(dev, ifup, dev->net,\n\t\t\t\t  \"intr submit %d\\n\", ret);\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tret = lan78xx_flush_rx_fifo(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\tret = lan78xx_flush_tx_fifo(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tret = lan78xx_start_tx_path(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\tret = lan78xx_start_rx_path(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tlan78xx_init_stats(dev);\n\n\tset_bit(EVENT_DEV_OPEN, &dev->flags);\n\n\tnetif_start_queue(net);\n\n\tdev->link_on = false;\n\n\tnapi_enable(&dev->napi);\n\n\tlan78xx_defer_kevent(dev, EVENT_LINK_RESET);\ndone:\n\tmutex_unlock(&dev->dev_mutex);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic void lan78xx_terminate_urbs(struct lan78xx_net *dev)\n{\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(unlink_wakeup);\n\tDECLARE_WAITQUEUE(wait, current);\n\tint temp;\n\n\t/* ensure there are no more active urbs */\n\tadd_wait_queue(&unlink_wakeup, &wait);\n\tset_current_state(TASK_UNINTERRUPTIBLE);\n\tdev->wait = &unlink_wakeup;\n\ttemp = unlink_urbs(dev, &dev->txq) + unlink_urbs(dev, &dev->rxq);\n\n\t/* maybe wait for deletions to finish. */\n\twhile (!skb_queue_empty(&dev->rxq) ||\n\t       !skb_queue_empty(&dev->txq)) {\n\t\tschedule_timeout(msecs_to_jiffies(UNLINK_TIMEOUT_MS));\n\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\tnetif_dbg(dev, ifdown, dev->net,\n\t\t\t  \"waited for %d urb completions\", temp);\n\t}\n\tset_current_state(TASK_RUNNING);\n\tdev->wait = NULL;\n\tremove_wait_queue(&unlink_wakeup, &wait);\n\n\t/* empty Rx done, Rx overflow and Tx pend queues\n\t */\n\twhile (!skb_queue_empty(&dev->rxq_done)) {\n\t\tstruct sk_buff *skb = skb_dequeue(&dev->rxq_done);\n\n\t\tlan78xx_release_rx_buf(dev, skb);\n\t}\n\n\tskb_queue_purge(&dev->rxq_overflow);\n\tskb_queue_purge(&dev->txq_pend);\n}\n\nstatic int lan78xx_stop(struct net_device *net)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\tnetif_dbg(dev, ifup, dev->net, \"stop device\");\n\n\tmutex_lock(&dev->dev_mutex);\n\n\tif (timer_pending(&dev->stat_monitor))\n\t\tdel_timer_sync(&dev->stat_monitor);\n\n\tclear_bit(EVENT_DEV_OPEN, &dev->flags);\n\tnetif_stop_queue(net);\n\tnapi_disable(&dev->napi);\n\n\tlan78xx_terminate_urbs(dev);\n\n\tnetif_info(dev, ifdown, dev->net,\n\t\t   \"stop stats: rx/tx %lu/%lu, errs %lu/%lu\\n\",\n\t\t   net->stats.rx_packets, net->stats.tx_packets,\n\t\t   net->stats.rx_errors, net->stats.tx_errors);\n\n\t/* ignore errors that occur stopping the Tx and Rx data paths */\n\tlan78xx_stop_tx_path(dev);\n\tlan78xx_stop_rx_path(dev);\n\n\tif (net->phydev)\n\t\tphy_stop(net->phydev);\n\n\tusb_kill_urb(dev->urb_intr);\n\n\t/* deferred work (task, timer, softirq) must also stop.\n\t * can't flush_scheduled_work() until we drop rtnl (later),\n\t * else workers could deadlock; so make workers a NOP.\n\t */\n\tclear_bit(EVENT_TX_HALT, &dev->flags);\n\tclear_bit(EVENT_RX_HALT, &dev->flags);\n\tclear_bit(EVENT_LINK_RESET, &dev->flags);\n\tclear_bit(EVENT_STAT_UPDATE, &dev->flags);\n\n\tcancel_delayed_work_sync(&dev->wq);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\tmutex_unlock(&dev->dev_mutex);\n\n\treturn 0;\n}\n\nstatic enum skb_state defer_bh(struct lan78xx_net *dev, struct sk_buff *skb,\n\t\t\t       struct sk_buff_head *list, enum skb_state state)\n{\n\tunsigned long flags;\n\tenum skb_state old_state;\n\tstruct skb_data *entry = (struct skb_data *)skb->cb;\n\n\tspin_lock_irqsave(&list->lock, flags);\n\told_state = entry->state;\n\tentry->state = state;\n\n\t__skb_unlink(skb, list);\n\tspin_unlock(&list->lock);\n\tspin_lock(&dev->rxq_done.lock);\n\n\t__skb_queue_tail(&dev->rxq_done, skb);\n\tif (skb_queue_len(&dev->rxq_done) == 1)\n\t\tnapi_schedule(&dev->napi);\n\n\tspin_unlock_irqrestore(&dev->rxq_done.lock, flags);\n\n\treturn old_state;\n}\n\nstatic void tx_complete(struct urb *urb)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)urb->context;\n\tstruct skb_data *entry = (struct skb_data *)skb->cb;\n\tstruct lan78xx_net *dev = entry->dev;\n\n\tif (urb->status == 0) {\n\t\tdev->net->stats.tx_packets += entry->num_of_packet;\n\t\tdev->net->stats.tx_bytes += entry->length;\n\t} else {\n\t\tdev->net->stats.tx_errors += entry->num_of_packet;\n\n\t\tswitch (urb->status) {\n\t\tcase -EPIPE:\n\t\t\tlan78xx_defer_kevent(dev, EVENT_TX_HALT);\n\t\t\tbreak;\n\n\t\t/* software-driven interface shutdown */\n\t\tcase -ECONNRESET:\n\t\tcase -ESHUTDOWN:\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"tx err interface gone %d\\n\",\n\t\t\t\t  entry->urb->status);\n\t\t\tbreak;\n\n\t\tcase -EPROTO:\n\t\tcase -ETIME:\n\t\tcase -EILSEQ:\n\t\t\tnetif_stop_queue(dev->net);\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"tx err queue stopped %d\\n\",\n\t\t\t\t  entry->urb->status);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"unknown tx err %d\\n\",\n\t\t\t\t  entry->urb->status);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tusb_autopm_put_interface_async(dev->intf);\n\n\tskb_unlink(skb, &dev->txq);\n\n\tlan78xx_release_tx_buf(dev, skb);\n\n\t/* Re-schedule NAPI if Tx data pending but no URBs in progress.\n\t */\n\tif (skb_queue_empty(&dev->txq) &&\n\t    !skb_queue_empty(&dev->txq_pend))\n\t\tnapi_schedule(&dev->napi);\n}\n\nstatic void lan78xx_queue_skb(struct sk_buff_head *list,\n\t\t\t      struct sk_buff *newsk, enum skb_state state)\n{\n\tstruct skb_data *entry = (struct skb_data *)newsk->cb;\n\n\t__skb_queue_tail(list, newsk);\n\tentry->state = state;\n}\n\nstatic unsigned int lan78xx_tx_urb_space(struct lan78xx_net *dev)\n{\n\treturn skb_queue_len(&dev->txq_free) * dev->tx_urb_size;\n}\n\nstatic unsigned int lan78xx_tx_pend_data_len(struct lan78xx_net *dev)\n{\n\treturn dev->tx_pend_data_len;\n}\n\nstatic void lan78xx_tx_pend_skb_add(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff *skb,\n\t\t\t\t    unsigned int *tx_pend_data_len)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->txq_pend.lock, flags);\n\n\t__skb_queue_tail(&dev->txq_pend, skb);\n\n\tdev->tx_pend_data_len += skb->len;\n\t*tx_pend_data_len = dev->tx_pend_data_len;\n\n\tspin_unlock_irqrestore(&dev->txq_pend.lock, flags);\n}\n\nstatic void lan78xx_tx_pend_skb_head_add(struct lan78xx_net *dev,\n\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t unsigned int *tx_pend_data_len)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->txq_pend.lock, flags);\n\n\t__skb_queue_head(&dev->txq_pend, skb);\n\n\tdev->tx_pend_data_len += skb->len;\n\t*tx_pend_data_len = dev->tx_pend_data_len;\n\n\tspin_unlock_irqrestore(&dev->txq_pend.lock, flags);\n}\n\nstatic void lan78xx_tx_pend_skb_get(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff **skb,\n\t\t\t\t    unsigned int *tx_pend_data_len)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->txq_pend.lock, flags);\n\n\t*skb = __skb_dequeue(&dev->txq_pend);\n\tif (*skb)\n\t\tdev->tx_pend_data_len -= (*skb)->len;\n\t*tx_pend_data_len = dev->tx_pend_data_len;\n\n\tspin_unlock_irqrestore(&dev->txq_pend.lock, flags);\n}\n\nstatic netdev_tx_t\nlan78xx_start_xmit(struct sk_buff *skb, struct net_device *net)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tunsigned int tx_pend_data_len;\n\n\tif (test_bit(EVENT_DEV_ASLEEP, &dev->flags))\n\t\tschedule_delayed_work(&dev->wq, 0);\n\n\tskb_tx_timestamp(skb);\n\n\tlan78xx_tx_pend_skb_add(dev, skb, &tx_pend_data_len);\n\n\t/* Set up a Tx URB if none is in progress */\n\n\tif (skb_queue_empty(&dev->txq))\n\t\tnapi_schedule(&dev->napi);\n\n\t/* Stop stack Tx queue if we have enough data to fill\n\t * all the free Tx URBs.\n\t */\n\tif (tx_pend_data_len > lan78xx_tx_urb_space(dev)) {\n\t\tnetif_stop_queue(net);\n\n\t\tnetif_dbg(dev, hw, dev->net, \"tx data len: %u, urb space %u\",\n\t\t\t  tx_pend_data_len, lan78xx_tx_urb_space(dev));\n\n\t\t/* Kick off transmission of pending data */\n\n\t\tif (!skb_queue_empty(&dev->txq_free))\n\t\t\tnapi_schedule(&dev->napi);\n\t}\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic int lan78xx_bind(struct lan78xx_net *dev, struct usb_interface *intf)\n{\n\tstruct lan78xx_priv *pdata = NULL;\n\tint ret;\n\tint i;\n\n\tdev->data[0] = (unsigned long)kzalloc(sizeof(*pdata), GFP_KERNEL);\n\n\tpdata = (struct lan78xx_priv *)(dev->data[0]);\n\tif (!pdata) {\n\t\tnetdev_warn(dev->net, \"Unable to allocate lan78xx_priv\");\n\t\treturn -ENOMEM;\n\t}\n\n\tpdata->dev = dev;\n\n\tspin_lock_init(&pdata->rfe_ctl_lock);\n\tmutex_init(&pdata->dataport_mutex);\n\n\tINIT_WORK(&pdata->set_multicast, lan78xx_deferred_multicast_write);\n\n\tfor (i = 0; i < DP_SEL_VHF_VLAN_LEN; i++)\n\t\tpdata->vlan_table[i] = 0;\n\n\tINIT_WORK(&pdata->set_vlan, lan78xx_deferred_vlan_write);\n\n\tdev->net->features = 0;\n\n\tif (DEFAULT_TX_CSUM_ENABLE)\n\t\tdev->net->features |= NETIF_F_HW_CSUM;\n\n\tif (DEFAULT_RX_CSUM_ENABLE)\n\t\tdev->net->features |= NETIF_F_RXCSUM;\n\n\tif (DEFAULT_TSO_CSUM_ENABLE)\n\t\tdev->net->features |= NETIF_F_TSO | NETIF_F_TSO6 | NETIF_F_SG;\n\n\tif (DEFAULT_VLAN_RX_OFFLOAD)\n\t\tdev->net->features |= NETIF_F_HW_VLAN_CTAG_RX;\n\n\tif (DEFAULT_VLAN_FILTER_ENABLE)\n\t\tdev->net->features |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\n\tdev->net->hw_features = dev->net->features;\n\n\tret = lan78xx_setup_irq_domain(dev);\n\tif (ret < 0) {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"lan78xx_setup_irq_domain() failed : %d\", ret);\n\t\tgoto out1;\n\t}\n\n\t/* Init all registers */\n\tret = lan78xx_reset(dev);\n\tif (ret) {\n\t\tnetdev_warn(dev->net, \"Registers INIT FAILED....\");\n\t\tgoto out2;\n\t}\n\n\tret = lan78xx_mdio_init(dev);\n\tif (ret) {\n\t\tnetdev_warn(dev->net, \"MDIO INIT FAILED.....\");\n\t\tgoto out2;\n\t}\n\n\tdev->net->flags |= IFF_MULTICAST;\n\n\tpdata->wol = WAKE_MAGIC;\n\n\treturn ret;\n\nout2:\n\tlan78xx_remove_irq_domain(dev);\n\nout1:\n\tnetdev_warn(dev->net, \"Bind routine FAILED\");\n\tcancel_work_sync(&pdata->set_multicast);\n\tcancel_work_sync(&pdata->set_vlan);\n\tkfree(pdata);\n\treturn ret;\n}\n\nstatic void lan78xx_unbind(struct lan78xx_net *dev, struct usb_interface *intf)\n{\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\n\tlan78xx_remove_irq_domain(dev);\n\n\tlan78xx_remove_mdio(dev);\n\n\tif (pdata) {\n\t\tcancel_work_sync(&pdata->set_multicast);\n\t\tcancel_work_sync(&pdata->set_vlan);\n\t\tnetif_dbg(dev, ifdown, dev->net, \"free pdata\");\n\t\tkfree(pdata);\n\t\tpdata = NULL;\n\t\tdev->data[0] = 0;\n\t}\n}\n\nstatic void lan78xx_rx_csum_offload(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff *skb,\n\t\t\t\t    u32 rx_cmd_a, u32 rx_cmd_b)\n{\n\t/* HW Checksum offload appears to be flawed if used when not stripping\n\t * VLAN headers. Drop back to S/W checksums under these conditions.\n\t */\n\tif (!(dev->net->features & NETIF_F_RXCSUM) ||\n\t    unlikely(rx_cmd_a & RX_CMD_A_ICSM_) ||\n\t    ((rx_cmd_a & RX_CMD_A_FVTG_) &&\n\t     !(dev->net->features & NETIF_F_HW_VLAN_CTAG_RX))) {\n\t\tskb->ip_summed = CHECKSUM_NONE;\n\t} else {\n\t\tskb->csum = ntohs((u16)(rx_cmd_b >> RX_CMD_B_CSUM_SHIFT_));\n\t\tskb->ip_summed = CHECKSUM_COMPLETE;\n\t}\n}\n\nstatic void lan78xx_rx_vlan_offload(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff *skb,\n\t\t\t\t    u32 rx_cmd_a, u32 rx_cmd_b)\n{\n\tif ((dev->net->features & NETIF_F_HW_VLAN_CTAG_RX) &&\n\t    (rx_cmd_a & RX_CMD_A_FVTG_))\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),\n\t\t\t\t       (rx_cmd_b & 0xffff));\n}\n\nstatic void lan78xx_skb_return(struct lan78xx_net *dev, struct sk_buff *skb)\n{\n\tdev->net->stats.rx_packets++;\n\tdev->net->stats.rx_bytes += skb->len;\n\n\tskb->protocol = eth_type_trans(skb, dev->net);\n\n\tnetif_dbg(dev, rx_status, dev->net, \"< rx, len %zu, type 0x%x\\n\",\n\t\t  skb->len + sizeof(struct ethhdr), skb->protocol);\n\tmemset(skb->cb, 0, sizeof(struct skb_data));\n\n\tif (skb_defer_rx_timestamp(skb))\n\t\treturn;\n\n\tnapi_gro_receive(&dev->napi, skb);\n}\n\nstatic int lan78xx_rx(struct lan78xx_net *dev, struct sk_buff *skb,\n\t\t      int budget, int *work_done)\n{\n\tif (skb->len < RX_SKB_MIN_LEN)\n\t\treturn 0;\n\n\t/* Extract frames from the URB buffer and pass each one to\n\t * the stack in a new NAPI SKB.\n\t */\n\twhile (skb->len > 0) {\n\t\tu32 rx_cmd_a, rx_cmd_b, align_count, size;\n\t\tu16 rx_cmd_c;\n\t\tunsigned char *packet;\n\n\t\trx_cmd_a = get_unaligned_le32(skb->data);\n\t\tskb_pull(skb, sizeof(rx_cmd_a));\n\n\t\trx_cmd_b = get_unaligned_le32(skb->data);\n\t\tskb_pull(skb, sizeof(rx_cmd_b));\n\n\t\trx_cmd_c = get_unaligned_le16(skb->data);\n\t\tskb_pull(skb, sizeof(rx_cmd_c));\n\n\t\tpacket = skb->data;\n\n\t\t/* get the packet length */\n\t\tsize = (rx_cmd_a & RX_CMD_A_LEN_MASK_);\n\t\talign_count = (4 - ((size + RXW_PADDING) % 4)) % 4;\n\n\t\tif (unlikely(size > skb->len)) {\n\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t  \"size err rx_cmd_a=0x%08x\\n\",\n\t\t\t\t  rx_cmd_a);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (unlikely(rx_cmd_a & RX_CMD_A_RED_)) {\n\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t  \"Error rx_cmd_a=0x%08x\", rx_cmd_a);\n\t\t} else {\n\t\t\tu32 frame_len;\n\t\t\tstruct sk_buff *skb2;\n\n\t\t\tif (unlikely(size < ETH_FCS_LEN)) {\n\t\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t\t  \"size err rx_cmd_a=0x%08x\\n\",\n\t\t\t\t\t  rx_cmd_a);\n\t\t\t\treturn 0;\n\t\t\t}\n\n\t\t\tframe_len = size - ETH_FCS_LEN;\n\n\t\t\tskb2 = napi_alloc_skb(&dev->napi, frame_len);\n\t\t\tif (!skb2)\n\t\t\t\treturn 0;\n\n\t\t\tmemcpy(skb2->data, packet, frame_len);\n\n\t\t\tskb_put(skb2, frame_len);\n\n\t\t\tlan78xx_rx_csum_offload(dev, skb2, rx_cmd_a, rx_cmd_b);\n\t\t\tlan78xx_rx_vlan_offload(dev, skb2, rx_cmd_a, rx_cmd_b);\n\n\t\t\t/* Processing of the URB buffer must complete once\n\t\t\t * it has started. If the NAPI work budget is exhausted\n\t\t\t * while frames remain they are added to the overflow\n\t\t\t * queue for delivery in the next NAPI polling cycle.\n\t\t\t */\n\t\t\tif (*work_done < budget) {\n\t\t\t\tlan78xx_skb_return(dev, skb2);\n\t\t\t\t++(*work_done);\n\t\t\t} else {\n\t\t\t\tskb_queue_tail(&dev->rxq_overflow, skb2);\n\t\t\t}\n\t\t}\n\n\t\tskb_pull(skb, size);\n\n\t\t/* skip padding bytes before the next frame starts */\n\t\tif (skb->len)\n\t\t\tskb_pull(skb, align_count);\n\t}\n\n\treturn 1;\n}\n\nstatic inline void rx_process(struct lan78xx_net *dev, struct sk_buff *skb,\n\t\t\t      int budget, int *work_done)\n{\n\tif (!lan78xx_rx(dev, skb, budget, work_done)) {\n\t\tnetif_dbg(dev, rx_err, dev->net, \"drop\\n\");\n\t\tdev->net->stats.rx_errors++;\n\t}\n}\n\nstatic void rx_complete(struct urb *urb)\n{\n\tstruct sk_buff\t*skb = (struct sk_buff *)urb->context;\n\tstruct skb_data\t*entry = (struct skb_data *)skb->cb;\n\tstruct lan78xx_net *dev = entry->dev;\n\tint urb_status = urb->status;\n\tenum skb_state state;\n\n\tnetif_dbg(dev, rx_status, dev->net,\n\t\t  \"rx done: status %d\", urb->status);\n\n\tskb_put(skb, urb->actual_length);\n\tstate = rx_done;\n\n\tif (urb != entry->urb)\n\t\tnetif_warn(dev, rx_err, dev->net, \"URB pointer mismatch\");\n\n\tswitch (urb_status) {\n\tcase 0:\n\t\tif (skb->len < RX_SKB_MIN_LEN) {\n\t\t\tstate = rx_cleanup;\n\t\t\tdev->net->stats.rx_errors++;\n\t\t\tdev->net->stats.rx_length_errors++;\n\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t  \"rx length %d\\n\", skb->len);\n\t\t}\n\t\tusb_mark_last_busy(dev->udev);\n\t\tbreak;\n\tcase -EPIPE:\n\t\tdev->net->stats.rx_errors++;\n\t\tlan78xx_defer_kevent(dev, EVENT_RX_HALT);\n\t\tfallthrough;\n\tcase -ECONNRESET:\t\t\t\t/* async unlink */\n\tcase -ESHUTDOWN:\t\t\t\t/* hardware gone */\n\t\tnetif_dbg(dev, ifdown, dev->net,\n\t\t\t  \"rx shutdown, code %d\\n\", urb_status);\n\t\tstate = rx_cleanup;\n\t\tbreak;\n\tcase -EPROTO:\n\tcase -ETIME:\n\tcase -EILSEQ:\n\t\tdev->net->stats.rx_errors++;\n\t\tstate = rx_cleanup;\n\t\tbreak;\n\n\t/* data overrun ... flush fifo? */\n\tcase -EOVERFLOW:\n\t\tdev->net->stats.rx_over_errors++;\n\t\tfallthrough;\n\n\tdefault:\n\t\tstate = rx_cleanup;\n\t\tdev->net->stats.rx_errors++;\n\t\tnetif_dbg(dev, rx_err, dev->net, \"rx status %d\\n\", urb_status);\n\t\tbreak;\n\t}\n\n\tstate = defer_bh(dev, skb, &dev->rxq, state);\n}\n\nstatic int rx_submit(struct lan78xx_net *dev, struct sk_buff *skb, gfp_t flags)\n{\n\tstruct skb_data\t*entry = (struct skb_data *)skb->cb;\n\tsize_t size = dev->rx_urb_size;\n\tstruct urb *urb = entry->urb;\n\tunsigned long lockflags;\n\tint ret = 0;\n\n\tusb_fill_bulk_urb(urb, dev->udev, dev->pipe_in,\n\t\t\t  skb->data, size, rx_complete, skb);\n\n\tspin_lock_irqsave(&dev->rxq.lock, lockflags);\n\n\tif (netif_device_present(dev->net) &&\n\t    netif_running(dev->net) &&\n\t    !test_bit(EVENT_RX_HALT, &dev->flags) &&\n\t    !test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\n\t\tret = usb_submit_urb(urb, flags);\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\tlan78xx_queue_skb(&dev->rxq, skb, rx_start);\n\t\t\tbreak;\n\t\tcase -EPIPE:\n\t\t\tlan78xx_defer_kevent(dev, EVENT_RX_HALT);\n\t\t\tbreak;\n\t\tcase -ENODEV:\n\t\tcase -ENOENT:\n\t\t\tnetif_dbg(dev, ifdown, dev->net, \"device gone\\n\");\n\t\t\tnetif_device_detach(dev->net);\n\t\t\tbreak;\n\t\tcase -EHOSTUNREACH:\n\t\t\tret = -ENOLINK;\n\t\t\tnapi_schedule(&dev->napi);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t  \"rx submit, %d\\n\", ret);\n\t\t\tnapi_schedule(&dev->napi);\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tnetif_dbg(dev, ifdown, dev->net, \"rx: stopped\\n\");\n\t\tret = -ENOLINK;\n\t}\n\tspin_unlock_irqrestore(&dev->rxq.lock, lockflags);\n\n\tif (ret)\n\t\tlan78xx_release_rx_buf(dev, skb);\n\n\treturn ret;\n}\n\nstatic void lan78xx_rx_urb_submit_all(struct lan78xx_net *dev)\n{\n\tstruct sk_buff *rx_buf;\n\n\t/* Ensure the maximum number of Rx URBs is submitted\n\t */\n\twhile ((rx_buf = lan78xx_get_rx_buf(dev)) != NULL) {\n\t\tif (rx_submit(dev, rx_buf, GFP_ATOMIC) != 0)\n\t\t\tbreak;\n\t}\n}\n\nstatic void lan78xx_rx_urb_resubmit(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff *rx_buf)\n{\n\t/* reset SKB data pointers */\n\n\trx_buf->data = rx_buf->head;\n\tskb_reset_tail_pointer(rx_buf);\n\trx_buf->len = 0;\n\trx_buf->data_len = 0;\n\n\trx_submit(dev, rx_buf, GFP_ATOMIC);\n}\n\nstatic void lan78xx_fill_tx_cmd_words(struct sk_buff *skb, u8 *buffer)\n{\n\tu32 tx_cmd_a;\n\tu32 tx_cmd_b;\n\n\ttx_cmd_a = (u32)(skb->len & TX_CMD_A_LEN_MASK_) | TX_CMD_A_FCS_;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\ttx_cmd_a |= TX_CMD_A_IPE_ | TX_CMD_A_TPE_;\n\n\ttx_cmd_b = 0;\n\tif (skb_is_gso(skb)) {\n\t\tu16 mss = max(skb_shinfo(skb)->gso_size, TX_CMD_B_MSS_MIN_);\n\n\t\ttx_cmd_b = (mss << TX_CMD_B_MSS_SHIFT_) & TX_CMD_B_MSS_MASK_;\n\n\t\ttx_cmd_a |= TX_CMD_A_LSO_;\n\t}\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\ttx_cmd_a |= TX_CMD_A_IVTG_;\n\t\ttx_cmd_b |= skb_vlan_tag_get(skb) & TX_CMD_B_VTAG_MASK_;\n\t}\n\n\tput_unaligned_le32(tx_cmd_a, buffer);\n\tput_unaligned_le32(tx_cmd_b, buffer + 4);\n}\n\nstatic struct skb_data *lan78xx_tx_buf_fill(struct lan78xx_net *dev,\n\t\t\t\t\t    struct sk_buff *tx_buf)\n{\n\tstruct skb_data *entry = (struct skb_data *)tx_buf->cb;\n\tint remain = dev->tx_urb_size;\n\tu8 *tx_data = tx_buf->data;\n\tu32 urb_len = 0;\n\n\tentry->num_of_packet = 0;\n\tentry->length = 0;\n\n\t/* Work through the pending SKBs and copy the data of each SKB into\n\t * the URB buffer if there room for all the SKB data.\n\t *\n\t * There must be at least DST+SRC+TYPE in the SKB (with padding enabled)\n\t */\n\twhile (remain >= TX_SKB_MIN_LEN) {\n\t\tunsigned int pending_bytes;\n\t\tunsigned int align_bytes;\n\t\tstruct sk_buff *skb;\n\t\tunsigned int len;\n\n\t\tlan78xx_tx_pend_skb_get(dev, &skb, &pending_bytes);\n\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\talign_bytes = (TX_ALIGNMENT - (urb_len % TX_ALIGNMENT)) %\n\t\t\t      TX_ALIGNMENT;\n\t\tlen = align_bytes + TX_CMD_LEN + skb->len;\n\t\tif (len > remain) {\n\t\t\tlan78xx_tx_pend_skb_head_add(dev, skb, &pending_bytes);\n\t\t\tbreak;\n\t\t}\n\n\t\ttx_data += align_bytes;\n\n\t\tlan78xx_fill_tx_cmd_words(skb, tx_data);\n\t\ttx_data += TX_CMD_LEN;\n\n\t\tlen = skb->len;\n\t\tif (skb_copy_bits(skb, 0, tx_data, len) < 0) {\n\t\t\tstruct net_device_stats *stats = &dev->net->stats;\n\n\t\t\tstats->tx_dropped++;\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\ttx_data -= TX_CMD_LEN;\n\t\t\tcontinue;\n\t\t}\n\n\t\ttx_data += len;\n\t\tentry->length += len;\n\t\tentry->num_of_packet += skb_shinfo(skb)->gso_segs ?: 1;\n\n\t\tdev_kfree_skb_any(skb);\n\n\t\turb_len = (u32)(tx_data - (u8 *)tx_buf->data);\n\n\t\tremain = dev->tx_urb_size - urb_len;\n\t}\n\n\tskb_put(tx_buf, urb_len);\n\n\treturn entry;\n}\n\nstatic void lan78xx_tx_bh(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\t/* Start the stack Tx queue if it was stopped\n\t */\n\tnetif_tx_lock(dev->net);\n\tif (netif_queue_stopped(dev->net)) {\n\t\tif (lan78xx_tx_pend_data_len(dev) < lan78xx_tx_urb_space(dev))\n\t\t\tnetif_wake_queue(dev->net);\n\t}\n\tnetif_tx_unlock(dev->net);\n\n\t/* Go through the Tx pending queue and set up URBs to transfer\n\t * the data to the device. Stop if no more pending data or URBs,\n\t * or if an error occurs when a URB is submitted.\n\t */\n\tdo {\n\t\tstruct skb_data *entry;\n\t\tstruct sk_buff *tx_buf;\n\t\tunsigned long flags;\n\n\t\tif (skb_queue_empty(&dev->txq_pend))\n\t\t\tbreak;\n\n\t\ttx_buf = lan78xx_get_tx_buf(dev);\n\t\tif (!tx_buf)\n\t\t\tbreak;\n\n\t\tentry = lan78xx_tx_buf_fill(dev, tx_buf);\n\n\t\tspin_lock_irqsave(&dev->txq.lock, flags);\n\t\tret = usb_autopm_get_interface_async(dev->intf);\n\t\tif (ret < 0) {\n\t\t\tspin_unlock_irqrestore(&dev->txq.lock, flags);\n\t\t\tgoto out;\n\t\t}\n\n\t\tusb_fill_bulk_urb(entry->urb, dev->udev, dev->pipe_out,\n\t\t\t\t  tx_buf->data, tx_buf->len, tx_complete,\n\t\t\t\t  tx_buf);\n\n\t\tif (tx_buf->len % dev->maxpacket == 0) {\n\t\t\t/* send USB_ZERO_PACKET */\n\t\t\tentry->urb->transfer_flags |= URB_ZERO_PACKET;\n\t\t}\n\n#ifdef CONFIG_PM\n\t\t/* if device is asleep stop outgoing packet processing */\n\t\tif (test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\n\t\t\tusb_anchor_urb(entry->urb, &dev->deferred);\n\t\t\tnetif_stop_queue(dev->net);\n\t\t\tspin_unlock_irqrestore(&dev->txq.lock, flags);\n\t\t\tnetdev_dbg(dev->net,\n\t\t\t\t   \"Delaying transmission for resumption\\n\");\n\t\t\treturn;\n\t\t}\n#endif\n\t\tret = usb_submit_urb(entry->urb, GFP_ATOMIC);\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\tnetif_trans_update(dev->net);\n\t\t\tlan78xx_queue_skb(&dev->txq, tx_buf, tx_start);\n\t\t\tbreak;\n\t\tcase -EPIPE:\n\t\t\tnetif_stop_queue(dev->net);\n\t\t\tlan78xx_defer_kevent(dev, EVENT_TX_HALT);\n\t\t\tusb_autopm_put_interface_async(dev->intf);\n\t\t\tbreak;\n\t\tcase -ENODEV:\n\t\tcase -ENOENT:\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"tx submit urb err %d (disconnected?)\", ret);\n\t\t\tnetif_device_detach(dev->net);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusb_autopm_put_interface_async(dev->intf);\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"tx submit urb err %d\\n\", ret);\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&dev->txq.lock, flags);\n\n\t\tif (ret) {\n\t\t\tnetdev_warn(dev->net, \"failed to tx urb %d\\n\", ret);\nout:\n\t\t\tdev->net->stats.tx_dropped += entry->num_of_packet;\n\t\t\tlan78xx_release_tx_buf(dev, tx_buf);\n\t\t}\n\t} while (ret == 0);\n}\n\nstatic int lan78xx_bh(struct lan78xx_net *dev, int budget)\n{\n\tstruct sk_buff_head done;\n\tstruct sk_buff *rx_buf;\n\tstruct skb_data *entry;\n\tunsigned long flags;\n\tint work_done = 0;\n\n\t/* Pass frames received in the last NAPI cycle before\n\t * working on newly completed URBs.\n\t */\n\twhile (!skb_queue_empty(&dev->rxq_overflow)) {\n\t\tlan78xx_skb_return(dev, skb_dequeue(&dev->rxq_overflow));\n\t\t++work_done;\n\t}\n\n\t/* Take a snapshot of the done queue and move items to a\n\t * temporary queue. Rx URB completions will continue to add\n\t * to the done queue.\n\t */\n\t__skb_queue_head_init(&done);\n\n\tspin_lock_irqsave(&dev->rxq_done.lock, flags);\n\tskb_queue_splice_init(&dev->rxq_done, &done);\n\tspin_unlock_irqrestore(&dev->rxq_done.lock, flags);\n\n\t/* Extract receive frames from completed URBs and\n\t * pass them to the stack. Re-submit each completed URB.\n\t */\n\twhile ((work_done < budget) &&\n\t       (rx_buf = __skb_dequeue(&done))) {\n\t\tentry = (struct skb_data *)(rx_buf->cb);\n\t\tswitch (entry->state) {\n\t\tcase rx_done:\n\t\t\trx_process(dev, rx_buf, budget, &work_done);\n\t\t\tbreak;\n\t\tcase rx_cleanup:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_dbg(dev->net, \"rx buf state %d\\n\",\n\t\t\t\t   entry->state);\n\t\t\tbreak;\n\t\t}\n\n\t\tlan78xx_rx_urb_resubmit(dev, rx_buf);\n\t}\n\n\t/* If budget was consumed before processing all the URBs put them\n\t * back on the front of the done queue. They will be first to be\n\t * processed in the next NAPI cycle.\n\t */\n\tspin_lock_irqsave(&dev->rxq_done.lock, flags);\n\tskb_queue_splice(&done, &dev->rxq_done);\n\tspin_unlock_irqrestore(&dev->rxq_done.lock, flags);\n\n\tif (netif_device_present(dev->net) && netif_running(dev->net)) {\n\t\t/* reset update timer delta */\n\t\tif (timer_pending(&dev->stat_monitor) && (dev->delta != 1)) {\n\t\t\tdev->delta = 1;\n\t\t\tmod_timer(&dev->stat_monitor,\n\t\t\t\t  jiffies + STAT_UPDATE_TIMER);\n\t\t}\n\n\t\t/* Submit all free Rx URBs */\n\n\t\tif (!test_bit(EVENT_RX_HALT, &dev->flags))\n\t\t\tlan78xx_rx_urb_submit_all(dev);\n\n\t\t/* Submit new Tx URBs */\n\n\t\tlan78xx_tx_bh(dev);\n\t}\n\n\treturn work_done;\n}\n\nstatic int lan78xx_poll(struct napi_struct *napi, int budget)\n{\n\tstruct lan78xx_net *dev = container_of(napi, struct lan78xx_net, napi);\n\tint result = budget;\n\tint work_done;\n\n\t/* Don't do any work if the device is suspended */\n\n\tif (test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\n\t\tnapi_complete_done(napi, 0);\n\t\treturn 0;\n\t}\n\n\t/* Process completed URBs and submit new URBs */\n\n\twork_done = lan78xx_bh(dev, budget);\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(napi, work_done);\n\n\t\t/* Start a new polling cycle if data was received or\n\t\t * data is waiting to be transmitted.\n\t\t */\n\t\tif (!skb_queue_empty(&dev->rxq_done)) {\n\t\t\tnapi_schedule(napi);\n\t\t} else if (netif_carrier_ok(dev->net)) {\n\t\t\tif (skb_queue_empty(&dev->txq) &&\n\t\t\t    !skb_queue_empty(&dev->txq_pend)) {\n\t\t\t\tnapi_schedule(napi);\n\t\t\t} else {\n\t\t\t\tnetif_tx_lock(dev->net);\n\t\t\t\tif (netif_queue_stopped(dev->net)) {\n\t\t\t\t\tnetif_wake_queue(dev->net);\n\t\t\t\t\tnapi_schedule(napi);\n\t\t\t\t}\n\t\t\t\tnetif_tx_unlock(dev->net);\n\t\t\t}\n\t\t}\n\t\tresult = work_done;\n\t}\n\n\treturn result;\n}\n\nstatic void lan78xx_delayedwork(struct work_struct *work)\n{\n\tint status;\n\tstruct lan78xx_net *dev;\n\n\tdev = container_of(work, struct lan78xx_net, wq.work);\n\n\tif (test_bit(EVENT_DEV_DISCONNECT, &dev->flags))\n\t\treturn;\n\n\tif (usb_autopm_get_interface(dev->intf) < 0)\n\t\treturn;\n\n\tif (test_bit(EVENT_TX_HALT, &dev->flags)) {\n\t\tunlink_urbs(dev, &dev->txq);\n\n\t\tstatus = usb_clear_halt(dev->udev, dev->pipe_out);\n\t\tif (status < 0 &&\n\t\t    status != -EPIPE &&\n\t\t    status != -ESHUTDOWN) {\n\t\t\tif (netif_msg_tx_err(dev))\n\t\t\t\tnetdev_err(dev->net,\n\t\t\t\t\t   \"can't clear tx halt, status %d\\n\",\n\t\t\t\t\t   status);\n\t\t} else {\n\t\t\tclear_bit(EVENT_TX_HALT, &dev->flags);\n\t\t\tif (status != -ESHUTDOWN)\n\t\t\t\tnetif_wake_queue(dev->net);\n\t\t}\n\t}\n\n\tif (test_bit(EVENT_RX_HALT, &dev->flags)) {\n\t\tunlink_urbs(dev, &dev->rxq);\n\t\tstatus = usb_clear_halt(dev->udev, dev->pipe_in);\n\t\tif (status < 0 &&\n\t\t    status != -EPIPE &&\n\t\t    status != -ESHUTDOWN) {\n\t\t\tif (netif_msg_rx_err(dev))\n\t\t\t\tnetdev_err(dev->net,\n\t\t\t\t\t   \"can't clear rx halt, status %d\\n\",\n\t\t\t\t\t   status);\n\t\t} else {\n\t\t\tclear_bit(EVENT_RX_HALT, &dev->flags);\n\t\t\tnapi_schedule(&dev->napi);\n\t\t}\n\t}\n\n\tif (test_bit(EVENT_LINK_RESET, &dev->flags)) {\n\t\tint ret = 0;\n\n\t\tclear_bit(EVENT_LINK_RESET, &dev->flags);\n\t\tif (lan78xx_link_reset(dev) < 0) {\n\t\t\tnetdev_info(dev->net, \"link reset failed (%d)\\n\",\n\t\t\t\t    ret);\n\t\t}\n\t}\n\n\tif (test_bit(EVENT_STAT_UPDATE, &dev->flags)) {\n\t\tlan78xx_update_stats(dev);\n\n\t\tclear_bit(EVENT_STAT_UPDATE, &dev->flags);\n\n\t\tmod_timer(&dev->stat_monitor,\n\t\t\t  jiffies + (STAT_UPDATE_TIMER * dev->delta));\n\n\t\tdev->delta = min((dev->delta * 2), 50);\n\t}\n\n\tusb_autopm_put_interface(dev->intf);\n}\n\nstatic void intr_complete(struct urb *urb)\n{\n\tstruct lan78xx_net *dev = urb->context;\n\tint status = urb->status;\n\n\tswitch (status) {\n\t/* success */\n\tcase 0:\n\t\tlan78xx_status(dev, urb);\n\t\tbreak;\n\n\t/* software-driven interface shutdown */\n\tcase -ENOENT:\t\t\t/* urb killed */\n\tcase -ENODEV:\t\t\t/* hardware gone */\n\tcase -ESHUTDOWN:\t\t/* hardware gone */\n\t\tnetif_dbg(dev, ifdown, dev->net,\n\t\t\t  \"intr shutdown, code %d\\n\", status);\n\t\treturn;\n\n\t/* NOTE:  not throttling like RX/TX, since this endpoint\n\t * already polls infrequently\n\t */\n\tdefault:\n\t\tnetdev_dbg(dev->net, \"intr status %d\\n\", status);\n\t\tbreak;\n\t}\n\n\tif (!netif_device_present(dev->net) ||\n\t    !netif_running(dev->net)) {\n\t\tnetdev_warn(dev->net, \"not submitting new status URB\");\n\t\treturn;\n\t}\n\n\tmemset(urb->transfer_buffer, 0, urb->transfer_buffer_length);\n\tstatus = usb_submit_urb(urb, GFP_ATOMIC);\n\n\tswitch (status) {\n\tcase  0:\n\t\tbreak;\n\tcase -ENODEV:\n\tcase -ENOENT:\n\t\tnetif_dbg(dev, timer, dev->net,\n\t\t\t  \"intr resubmit %d (disconnect?)\", status);\n\t\tnetif_device_detach(dev->net);\n\t\tbreak;\n\tdefault:\n\t\tnetif_err(dev, timer, dev->net,\n\t\t\t  \"intr resubmit --> %d\\n\", status);\n\t\tbreak;\n\t}\n}\n\nstatic void lan78xx_disconnect(struct usb_interface *intf)\n{\n\tstruct lan78xx_net *dev;\n\tstruct usb_device *udev;\n\tstruct net_device *net;\n\tstruct phy_device *phydev;\n\n\tdev = usb_get_intfdata(intf);\n\tusb_set_intfdata(intf, NULL);\n\tif (!dev)\n\t\treturn;\n\n\tset_bit(EVENT_DEV_DISCONNECT, &dev->flags);\n\n\tnetif_napi_del(&dev->napi);\n\n\tudev = interface_to_usbdev(intf);\n\tnet = dev->net;\n\n\tunregister_netdev(net);\n\n\tcancel_delayed_work_sync(&dev->wq);\n\n\tphydev = net->phydev;\n\n\tphy_unregister_fixup_for_uid(PHY_KSZ9031RNX, 0xfffffff0);\n\tphy_unregister_fixup_for_uid(PHY_LAN8835, 0xfffffff0);\n\n\tphy_disconnect(net->phydev);\n\n\tif (phy_is_pseudo_fixed_link(phydev))\n\t\tfixed_phy_unregister(phydev);\n\n\tusb_scuttle_anchored_urbs(&dev->deferred);\n\n\tif (timer_pending(&dev->stat_monitor))\n\t\tdel_timer_sync(&dev->stat_monitor);\n\n\tlan78xx_unbind(dev, intf);\n\n\tlan78xx_free_tx_resources(dev);\n\tlan78xx_free_rx_resources(dev);\n\n\tusb_kill_urb(dev->urb_intr);\n\tusb_free_urb(dev->urb_intr);\n\n\tfree_netdev(net);\n\tusb_put_dev(udev);\n}\n\nstatic void lan78xx_tx_timeout(struct net_device *net, unsigned int txqueue)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\tunlink_urbs(dev, &dev->txq);\n\tnapi_schedule(&dev->napi);\n}\n\nstatic netdev_features_t lan78xx_features_check(struct sk_buff *skb,\n\t\t\t\t\t\tstruct net_device *netdev,\n\t\t\t\t\t\tnetdev_features_t features)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\n\tif (skb->len > LAN78XX_TSO_SIZE(dev))\n\t\tfeatures &= ~NETIF_F_GSO_MASK;\n\n\tfeatures = vlan_features_check(skb, features);\n\tfeatures = vxlan_features_check(skb, features);\n\n\treturn features;\n}\n\nstatic const struct net_device_ops lan78xx_netdev_ops = {\n\t.ndo_open\t\t= lan78xx_open,\n\t.ndo_stop\t\t= lan78xx_stop,\n\t.ndo_start_xmit\t\t= lan78xx_start_xmit,\n\t.ndo_tx_timeout\t\t= lan78xx_tx_timeout,\n\t.ndo_change_mtu\t\t= lan78xx_change_mtu,\n\t.ndo_set_mac_address\t= lan78xx_set_mac_addr,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_eth_ioctl\t\t= phy_do_ioctl_running,\n\t.ndo_set_rx_mode\t= lan78xx_set_multicast,\n\t.ndo_set_features\t= lan78xx_set_features,\n\t.ndo_vlan_rx_add_vid\t= lan78xx_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= lan78xx_vlan_rx_kill_vid,\n\t.ndo_features_check\t= lan78xx_features_check,\n};\n\nstatic void lan78xx_stat_monitor(struct timer_list *t)\n{\n\tstruct lan78xx_net *dev = from_timer(dev, t, stat_monitor);\n\n\tlan78xx_defer_kevent(dev, EVENT_STAT_UPDATE);\n}\n\nstatic int lan78xx_probe(struct usb_interface *intf,\n\t\t\t const struct usb_device_id *id)\n{\n\tstruct usb_host_endpoint *ep_blkin, *ep_blkout, *ep_intr;\n\tstruct lan78xx_net *dev;\n\tstruct net_device *netdev;\n\tstruct usb_device *udev;\n\tint ret;\n\tunsigned int maxp;\n\tunsigned int period;\n\tu8 *buf = NULL;\n\n\tudev = interface_to_usbdev(intf);\n\tudev = usb_get_dev(udev);\n\n\tnetdev = alloc_etherdev(sizeof(struct lan78xx_net));\n\tif (!netdev) {\n\t\tdev_err(&intf->dev, \"Error: OOM\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out1;\n\t}\n\n\t/* netdev_printk() needs this */\n\tSET_NETDEV_DEV(netdev, &intf->dev);\n\n\tdev = netdev_priv(netdev);\n\tdev->udev = udev;\n\tdev->intf = intf;\n\tdev->net = netdev;\n\tdev->msg_enable = netif_msg_init(msg_level, NETIF_MSG_DRV\n\t\t\t\t\t| NETIF_MSG_PROBE | NETIF_MSG_LINK);\n\n\tskb_queue_head_init(&dev->rxq);\n\tskb_queue_head_init(&dev->txq);\n\tskb_queue_head_init(&dev->rxq_done);\n\tskb_queue_head_init(&dev->txq_pend);\n\tskb_queue_head_init(&dev->rxq_overflow);\n\tmutex_init(&dev->phy_mutex);\n\tmutex_init(&dev->dev_mutex);\n\n\tret = lan78xx_urb_config_init(dev);\n\tif (ret < 0)\n\t\tgoto out2;\n\n\tret = lan78xx_alloc_tx_resources(dev);\n\tif (ret < 0)\n\t\tgoto out2;\n\n\tret = lan78xx_alloc_rx_resources(dev);\n\tif (ret < 0)\n\t\tgoto out3;\n\n\t/* MTU range: 68 - 9000 */\n\tnetdev->max_mtu = MAX_SINGLE_PACKET_SIZE;\n\n\tnetif_set_tso_max_size(netdev, LAN78XX_TSO_SIZE(dev));\n\n\tnetif_napi_add(netdev, &dev->napi, lan78xx_poll);\n\n\tINIT_DELAYED_WORK(&dev->wq, lan78xx_delayedwork);\n\tinit_usb_anchor(&dev->deferred);\n\n\tnetdev->netdev_ops = &lan78xx_netdev_ops;\n\tnetdev->watchdog_timeo = TX_TIMEOUT_JIFFIES;\n\tnetdev->ethtool_ops = &lan78xx_ethtool_ops;\n\n\tdev->delta = 1;\n\ttimer_setup(&dev->stat_monitor, lan78xx_stat_monitor, 0);\n\n\tmutex_init(&dev->stats.access_lock);\n\n\tif (intf->cur_altsetting->desc.bNumEndpoints < 3) {\n\t\tret = -ENODEV;\n\t\tgoto out4;\n\t}\n\n\tdev->pipe_in = usb_rcvbulkpipe(udev, BULK_IN_PIPE);\n\tep_blkin = usb_pipe_endpoint(udev, dev->pipe_in);\n\tif (!ep_blkin || !usb_endpoint_is_bulk_in(&ep_blkin->desc)) {\n\t\tret = -ENODEV;\n\t\tgoto out4;\n\t}\n\n\tdev->pipe_out = usb_sndbulkpipe(udev, BULK_OUT_PIPE);\n\tep_blkout = usb_pipe_endpoint(udev, dev->pipe_out);\n\tif (!ep_blkout || !usb_endpoint_is_bulk_out(&ep_blkout->desc)) {\n\t\tret = -ENODEV;\n\t\tgoto out4;\n\t}\n\n\tep_intr = &intf->cur_altsetting->endpoint[2];\n\tif (!usb_endpoint_is_int_in(&ep_intr->desc)) {\n\t\tret = -ENODEV;\n\t\tgoto out4;\n\t}\n\n\tdev->pipe_intr = usb_rcvintpipe(dev->udev,\n\t\t\t\t\tusb_endpoint_num(&ep_intr->desc));\n\n\tret = lan78xx_bind(dev, intf);\n\tif (ret < 0)\n\t\tgoto out4;\n\n\tperiod = ep_intr->desc.bInterval;\n\tmaxp = usb_maxpacket(dev->udev, dev->pipe_intr);\n\tbuf = kmalloc(maxp, GFP_KERNEL);\n\tif (!buf) {\n\t\tret = -ENOMEM;\n\t\tgoto out5;\n\t}\n\n\tdev->urb_intr = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!dev->urb_intr) {\n\t\tret = -ENOMEM;\n\t\tgoto out6;\n\t} else {\n\t\tusb_fill_int_urb(dev->urb_intr, dev->udev,\n\t\t\t\t dev->pipe_intr, buf, maxp,\n\t\t\t\t intr_complete, dev, period);\n\t\tdev->urb_intr->transfer_flags |= URB_FREE_BUFFER;\n\t}\n\n\tdev->maxpacket = usb_maxpacket(dev->udev, dev->pipe_out);\n\n\t/* Reject broken descriptors. */\n\tif (dev->maxpacket == 0) {\n\t\tret = -ENODEV;\n\t\tgoto out6;\n\t}\n\n\t/* driver requires remote-wakeup capability during autosuspend. */\n\tintf->needs_remote_wakeup = 1;\n\n\tret = lan78xx_phy_init(dev);\n\tif (ret < 0)\n\t\tgoto out7;\n\n\tret = register_netdev(netdev);\n\tif (ret != 0) {\n\t\tnetif_err(dev, probe, netdev, \"couldn't register the device\\n\");\n\t\tgoto out8;\n\t}\n\n\tusb_set_intfdata(intf, dev);\n\n\tret = device_set_wakeup_enable(&udev->dev, true);\n\n\t /* Default delay of 2sec has more overhead than advantage.\n\t  * Set to 10sec as default.\n\t  */\n\tpm_runtime_set_autosuspend_delay(&udev->dev,\n\t\t\t\t\t DEFAULT_AUTOSUSPEND_DELAY);\n\n\treturn 0;\n\nout8:\n\tphy_disconnect(netdev->phydev);\nout7:\n\tusb_free_urb(dev->urb_intr);\nout6:\n\tkfree(buf);\nout5:\n\tlan78xx_unbind(dev, intf);\nout4:\n\tnetif_napi_del(&dev->napi);\n\tlan78xx_free_rx_resources(dev);\nout3:\n\tlan78xx_free_tx_resources(dev);\nout2:\n\tfree_netdev(netdev);\nout1:\n\tusb_put_dev(udev);\n\n\treturn ret;\n}\n\nstatic u16 lan78xx_wakeframe_crc16(const u8 *buf, int len)\n{\n\tconst u16 crc16poly = 0x8005;\n\tint i;\n\tu16 bit, crc, msb;\n\tu8 data;\n\n\tcrc = 0xFFFF;\n\tfor (i = 0; i < len; i++) {\n\t\tdata = *buf++;\n\t\tfor (bit = 0; bit < 8; bit++) {\n\t\t\tmsb = crc >> 15;\n\t\t\tcrc <<= 1;\n\n\t\t\tif (msb ^ (u16)(data & 1)) {\n\t\t\t\tcrc ^= crc16poly;\n\t\t\t\tcrc |= (u16)0x0001U;\n\t\t\t}\n\t\t\tdata >>= 1;\n\t\t}\n\t}\n\n\treturn crc;\n}\n\nstatic int lan78xx_set_auto_suspend(struct lan78xx_net *dev)\n{\n\tu32 buf;\n\tint ret;\n\n\tret = lan78xx_stop_tx_path(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_stop_rx_path(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* auto suspend (selective suspend) */\n\n\tret = lan78xx_write_reg(dev, WUCSR, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_write_reg(dev, WUCSR2, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* set goodframe wakeup */\n\n\tret = lan78xx_read_reg(dev, WUCSR, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= WUCSR_RFE_WAKE_EN_;\n\tbuf |= WUCSR_STORE_WAKE_;\n\n\tret = lan78xx_write_reg(dev, WUCSR, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf &= ~PMT_CTL_RES_CLR_WKP_EN_;\n\tbuf |= PMT_CTL_RES_CLR_WKP_STS_;\n\tbuf |= PMT_CTL_PHY_WAKE_EN_;\n\tbuf |= PMT_CTL_WOL_EN_;\n\tbuf &= ~PMT_CTL_SUS_MODE_MASK_;\n\tbuf |= PMT_CTL_SUS_MODE_3_;\n\n\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= PMT_CTL_WUPS_MASK_;\n\n\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_start_rx_path(dev);\n\n\treturn ret;\n}\n\nstatic int lan78xx_set_suspend(struct lan78xx_net *dev, u32 wol)\n{\n\tconst u8 ipv4_multicast[3] = { 0x01, 0x00, 0x5E };\n\tconst u8 ipv6_multicast[3] = { 0x33, 0x33 };\n\tconst u8 arp_type[2] = { 0x08, 0x06 };\n\tu32 temp_pmt_ctl;\n\tint mask_index;\n\tu32 temp_wucsr;\n\tu32 buf;\n\tu16 crc;\n\tint ret;\n\n\tret = lan78xx_stop_tx_path(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_stop_rx_path(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, WUCSR, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_write_reg(dev, WUCSR2, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttemp_wucsr = 0;\n\n\ttemp_pmt_ctl = 0;\n\n\tret = lan78xx_read_reg(dev, PMT_CTL, &temp_pmt_ctl);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttemp_pmt_ctl &= ~PMT_CTL_RES_CLR_WKP_EN_;\n\ttemp_pmt_ctl |= PMT_CTL_RES_CLR_WKP_STS_;\n\n\tfor (mask_index = 0; mask_index < NUM_OF_WUF_CFG; mask_index++) {\n\t\tret = lan78xx_write_reg(dev, WUF_CFG(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tmask_index = 0;\n\tif (wol & WAKE_PHY) {\n\t\ttemp_pmt_ctl |= PMT_CTL_PHY_WAKE_EN_;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tif (wol & WAKE_MAGIC) {\n\t\ttemp_wucsr |= WUCSR_MPEN_;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_3_;\n\t}\n\tif (wol & WAKE_BCAST) {\n\t\ttemp_wucsr |= WUCSR_BCST_EN_;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tif (wol & WAKE_MCAST) {\n\t\ttemp_wucsr |= WUCSR_WAKE_EN_;\n\n\t\t/* set WUF_CFG & WUF_MASK for IPv4 Multicast */\n\t\tcrc = lan78xx_wakeframe_crc16(ipv4_multicast, 3);\n\t\tret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\n\t\t\t\t\tWUF_CFGX_EN_ |\n\t\t\t\t\tWUF_CFGX_TYPE_MCAST_ |\n\t\t\t\t\t(0 << WUF_CFGX_OFFSET_SHIFT_) |\n\t\t\t\t\t(crc & WUF_CFGX_CRC16_MASK_));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 7);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tmask_index++;\n\n\t\t/* for IPv6 Multicast */\n\t\tcrc = lan78xx_wakeframe_crc16(ipv6_multicast, 2);\n\t\tret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\n\t\t\t\t\tWUF_CFGX_EN_ |\n\t\t\t\t\tWUF_CFGX_TYPE_MCAST_ |\n\t\t\t\t\t(0 << WUF_CFGX_OFFSET_SHIFT_) |\n\t\t\t\t\t(crc & WUF_CFGX_CRC16_MASK_));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 3);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tmask_index++;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tif (wol & WAKE_UCAST) {\n\t\ttemp_wucsr |= WUCSR_PFDA_EN_;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tif (wol & WAKE_ARP) {\n\t\ttemp_wucsr |= WUCSR_WAKE_EN_;\n\n\t\t/* set WUF_CFG & WUF_MASK\n\t\t * for packettype (offset 12,13) = ARP (0x0806)\n\t\t */\n\t\tcrc = lan78xx_wakeframe_crc16(arp_type, 2);\n\t\tret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\n\t\t\t\t\tWUF_CFGX_EN_ |\n\t\t\t\t\tWUF_CFGX_TYPE_ALL_ |\n\t\t\t\t\t(0 << WUF_CFGX_OFFSET_SHIFT_) |\n\t\t\t\t\t(crc & WUF_CFGX_CRC16_MASK_));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 0x3000);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tmask_index++;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\n\tret = lan78xx_write_reg(dev, WUCSR, temp_wucsr);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* when multiple WOL bits are set */\n\tif (hweight_long((unsigned long)wol) > 1) {\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tret = lan78xx_write_reg(dev, PMT_CTL, temp_pmt_ctl);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* clear WUPS */\n\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= PMT_CTL_WUPS_MASK_;\n\n\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_start_rx_path(dev);\n\n\treturn ret;\n}\n\nstatic int lan78xx_suspend(struct usb_interface *intf, pm_message_t message)\n{\n\tstruct lan78xx_net *dev = usb_get_intfdata(intf);\n\tbool dev_open;\n\tint ret;\n\n\tmutex_lock(&dev->dev_mutex);\n\n\tnetif_dbg(dev, ifdown, dev->net,\n\t\t  \"suspending: pm event %#x\", message.event);\n\n\tdev_open = test_bit(EVENT_DEV_OPEN, &dev->flags);\n\n\tif (dev_open) {\n\t\tspin_lock_irq(&dev->txq.lock);\n\t\t/* don't autosuspend while transmitting */\n\t\tif ((skb_queue_len(&dev->txq) ||\n\t\t     skb_queue_len(&dev->txq_pend)) &&\n\t\t    PMSG_IS_AUTO(message)) {\n\t\t\tspin_unlock_irq(&dev->txq.lock);\n\t\t\tret = -EBUSY;\n\t\t\tgoto out;\n\t\t} else {\n\t\t\tset_bit(EVENT_DEV_ASLEEP, &dev->flags);\n\t\t\tspin_unlock_irq(&dev->txq.lock);\n\t\t}\n\n\t\t/* stop RX */\n\t\tret = lan78xx_stop_rx_path(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tret = lan78xx_flush_rx_fifo(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\t/* stop Tx */\n\t\tret = lan78xx_stop_tx_path(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\t/* empty out the Rx and Tx queues */\n\t\tnetif_device_detach(dev->net);\n\t\tlan78xx_terminate_urbs(dev);\n\t\tusb_kill_urb(dev->urb_intr);\n\n\t\t/* reattach */\n\t\tnetif_device_attach(dev->net);\n\n\t\tdel_timer(&dev->stat_monitor);\n\n\t\tif (PMSG_IS_AUTO(message)) {\n\t\t\tret = lan78xx_set_auto_suspend(dev);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t} else {\n\t\t\tstruct lan78xx_priv *pdata;\n\n\t\t\tpdata = (struct lan78xx_priv *)(dev->data[0]);\n\t\t\tnetif_carrier_off(dev->net);\n\t\t\tret = lan78xx_set_suspend(dev, pdata->wol);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t/* Interface is down; don't allow WOL and PHY\n\t\t * events to wake up the host\n\t\t */\n\t\tu32 buf;\n\n\t\tset_bit(EVENT_DEV_ASLEEP, &dev->flags);\n\n\t\tret = lan78xx_write_reg(dev, WUCSR, 0);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tret = lan78xx_write_reg(dev, WUCSR2, 0);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tbuf &= ~PMT_CTL_RES_CLR_WKP_EN_;\n\t\tbuf |= PMT_CTL_RES_CLR_WKP_STS_;\n\t\tbuf &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\tbuf |= PMT_CTL_SUS_MODE_3_;\n\n\t\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tbuf |= PMT_CTL_WUPS_MASK_;\n\n\t\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\n\n\tret = 0;\nout:\n\tmutex_unlock(&dev->dev_mutex);\n\n\treturn ret;\n}\n\nstatic bool lan78xx_submit_deferred_urbs(struct lan78xx_net *dev)\n{\n\tbool pipe_halted = false;\n\tstruct urb *urb;\n\n\twhile ((urb = usb_get_from_anchor(&dev->deferred))) {\n\t\tstruct sk_buff *skb = urb->context;\n\t\tint ret;\n\n\t\tif (!netif_device_present(dev->net) ||\n\t\t    !netif_carrier_ok(dev->net) ||\n\t\t    pipe_halted) {\n\t\t\tlan78xx_release_tx_buf(dev, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = usb_submit_urb(urb, GFP_ATOMIC);\n\n\t\tif (ret == 0) {\n\t\t\tnetif_trans_update(dev->net);\n\t\t\tlan78xx_queue_skb(&dev->txq, skb, tx_start);\n\t\t} else {\n\t\t\tif (ret == -EPIPE) {\n\t\t\t\tnetif_stop_queue(dev->net);\n\t\t\t\tpipe_halted = true;\n\t\t\t} else if (ret == -ENODEV) {\n\t\t\t\tnetif_device_detach(dev->net);\n\t\t\t}\n\n\t\t\tlan78xx_release_tx_buf(dev, skb);\n\t\t}\n\t}\n\n\treturn pipe_halted;\n}\n\nstatic int lan78xx_resume(struct usb_interface *intf)\n{\n\tstruct lan78xx_net *dev = usb_get_intfdata(intf);\n\tbool dev_open;\n\tint ret;\n\n\tmutex_lock(&dev->dev_mutex);\n\n\tnetif_dbg(dev, ifup, dev->net, \"resuming device\");\n\n\tdev_open = test_bit(EVENT_DEV_OPEN, &dev->flags);\n\n\tif (dev_open) {\n\t\tbool pipe_halted = false;\n\n\t\tret = lan78xx_flush_tx_fifo(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tif (dev->urb_intr) {\n\t\t\tint ret = usb_submit_urb(dev->urb_intr, GFP_KERNEL);\n\n\t\t\tif (ret < 0) {\n\t\t\t\tif (ret == -ENODEV)\n\t\t\t\t\tnetif_device_detach(dev->net);\n\t\t\t\tnetdev_warn(dev->net, \"Failed to submit intr URB\");\n\t\t\t}\n\t\t}\n\n\t\tspin_lock_irq(&dev->txq.lock);\n\n\t\tif (netif_device_present(dev->net)) {\n\t\t\tpipe_halted = lan78xx_submit_deferred_urbs(dev);\n\n\t\t\tif (pipe_halted)\n\t\t\t\tlan78xx_defer_kevent(dev, EVENT_TX_HALT);\n\t\t}\n\n\t\tclear_bit(EVENT_DEV_ASLEEP, &dev->flags);\n\n\t\tspin_unlock_irq(&dev->txq.lock);\n\n\t\tif (!pipe_halted &&\n\t\t    netif_device_present(dev->net) &&\n\t\t    (lan78xx_tx_pend_data_len(dev) < lan78xx_tx_urb_space(dev)))\n\t\t\tnetif_start_queue(dev->net);\n\n\t\tret = lan78xx_start_tx_path(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tnapi_schedule(&dev->napi);\n\n\t\tif (!timer_pending(&dev->stat_monitor)) {\n\t\t\tdev->delta = 1;\n\t\t\tmod_timer(&dev->stat_monitor,\n\t\t\t\t  jiffies + STAT_UPDATE_TIMER);\n\t\t}\n\n\t} else {\n\t\tclear_bit(EVENT_DEV_ASLEEP, &dev->flags);\n\t}\n\n\tret = lan78xx_write_reg(dev, WUCSR2, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = lan78xx_write_reg(dev, WUCSR, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = lan78xx_write_reg(dev, WUCSR2, WUCSR2_NS_RCD_ |\n\t\t\t\t\t     WUCSR2_ARP_RCD_ |\n\t\t\t\t\t     WUCSR2_IPV6_TCPSYN_RCD_ |\n\t\t\t\t\t     WUCSR2_IPV4_TCPSYN_RCD_);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = lan78xx_write_reg(dev, WUCSR, WUCSR_EEE_TX_WAKE_ |\n\t\t\t\t\t    WUCSR_EEE_RX_WAKE_ |\n\t\t\t\t\t    WUCSR_PFDA_FR_ |\n\t\t\t\t\t    WUCSR_RFE_WAKE_FR_ |\n\t\t\t\t\t    WUCSR_WUFR_ |\n\t\t\t\t\t    WUCSR_MPR_ |\n\t\t\t\t\t    WUCSR_BCST_FR_);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = 0;\nout:\n\tmutex_unlock(&dev->dev_mutex);\n\n\treturn ret;\n}\n\nstatic int lan78xx_reset_resume(struct usb_interface *intf)\n{\n\tstruct lan78xx_net *dev = usb_get_intfdata(intf);\n\tint ret;\n\n\tnetif_dbg(dev, ifup, dev->net, \"(reset) resuming device\");\n\n\tret = lan78xx_reset(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tphy_start(dev->net->phydev);\n\n\tret = lan78xx_resume(intf);\n\n\treturn ret;\n}\n\nstatic const struct usb_device_id products[] = {\n\t{\n\t/* LAN7800 USB Gigabit Ethernet Device */\n\tUSB_DEVICE(LAN78XX_USB_VENDOR_ID, LAN7800_USB_PRODUCT_ID),\n\t},\n\t{\n\t/* LAN7850 USB Gigabit Ethernet Device */\n\tUSB_DEVICE(LAN78XX_USB_VENDOR_ID, LAN7850_USB_PRODUCT_ID),\n\t},\n\t{\n\t/* LAN7801 USB Gigabit Ethernet Device */\n\tUSB_DEVICE(LAN78XX_USB_VENDOR_ID, LAN7801_USB_PRODUCT_ID),\n\t},\n\t{\n\t/* ATM2-AF USB Gigabit Ethernet Device */\n\tUSB_DEVICE(AT29M2AF_USB_VENDOR_ID, AT29M2AF_USB_PRODUCT_ID),\n\t},\n\t{},\n};\nMODULE_DEVICE_TABLE(usb, products);\n\nstatic struct usb_driver lan78xx_driver = {\n\t.name\t\t\t= DRIVER_NAME,\n\t.id_table\t\t= products,\n\t.probe\t\t\t= lan78xx_probe,\n\t.disconnect\t\t= lan78xx_disconnect,\n\t.suspend\t\t= lan78xx_suspend,\n\t.resume\t\t\t= lan78xx_resume,\n\t.reset_resume\t\t= lan78xx_reset_resume,\n\t.supports_autosuspend\t= 1,\n\t.disable_hub_initiated_lpm = 1,\n};\n\nmodule_usb_driver(lan78xx_driver);\n\nMODULE_AUTHOR(DRIVER_AUTHOR);\nMODULE_DESCRIPTION(DRIVER_DESC);\nMODULE_LICENSE(\"GPL\");\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0+\n/*\n * Copyright (C) 2015 Microchip Technology\n */\n#include <linux/module.h>\n#include <linux/netdevice.h>\n#include <linux/etherdevice.h>\n#include <linux/ethtool.h>\n#include <linux/usb.h>\n#include <linux/crc32.h>\n#include <linux/signal.h>\n#include <linux/slab.h>\n#include <linux/if_vlan.h>\n#include <linux/uaccess.h>\n#include <linux/linkmode.h>\n#include <linux/list.h>\n#include <linux/ip.h>\n#include <linux/ipv6.h>\n#include <linux/mdio.h>\n#include <linux/phy.h>\n#include <net/ip6_checksum.h>\n#include <net/vxlan.h>\n#include <linux/interrupt.h>\n#include <linux/irqdomain.h>\n#include <linux/irq.h>\n#include <linux/irqchip/chained_irq.h>\n#include <linux/microchipphy.h>\n#include <linux/phy_fixed.h>\n#include <linux/of_mdio.h>\n#include <linux/of_net.h>\n#include \"lan78xx.h\"\n\n#define DRIVER_AUTHOR\t\"WOOJUNG HUH <woojung.huh@microchip.com>\"\n#define DRIVER_DESC\t\"LAN78XX USB 3.0 Gigabit Ethernet Devices\"\n#define DRIVER_NAME\t\"lan78xx\"\n\n#define TX_TIMEOUT_JIFFIES\t\t(5 * HZ)\n#define THROTTLE_JIFFIES\t\t(HZ / 8)\n#define UNLINK_TIMEOUT_MS\t\t3\n\n#define RX_MAX_QUEUE_MEMORY\t\t(60 * 1518)\n\n#define SS_USB_PKT_SIZE\t\t\t(1024)\n#define HS_USB_PKT_SIZE\t\t\t(512)\n#define FS_USB_PKT_SIZE\t\t\t(64)\n\n#define MAX_RX_FIFO_SIZE\t\t(12 * 1024)\n#define MAX_TX_FIFO_SIZE\t\t(12 * 1024)\n\n#define FLOW_THRESHOLD(n)\t\t((((n) + 511) / 512) & 0x7F)\n#define FLOW_CTRL_THRESHOLD(on, off)\t((FLOW_THRESHOLD(on)  << 0) | \\\n\t\t\t\t\t (FLOW_THRESHOLD(off) << 8))\n\n/* Flow control turned on when Rx FIFO level rises above this level (bytes) */\n#define FLOW_ON_SS\t\t\t9216\n#define FLOW_ON_HS\t\t\t8704\n\n/* Flow control turned off when Rx FIFO level falls below this level (bytes) */\n#define FLOW_OFF_SS\t\t\t4096\n#define FLOW_OFF_HS\t\t\t1024\n\n#define DEFAULT_BURST_CAP_SIZE\t\t(MAX_TX_FIFO_SIZE)\n#define DEFAULT_BULK_IN_DELAY\t\t(0x0800)\n#define MAX_SINGLE_PACKET_SIZE\t\t(9000)\n#define DEFAULT_TX_CSUM_ENABLE\t\t(true)\n#define DEFAULT_RX_CSUM_ENABLE\t\t(true)\n#define DEFAULT_TSO_CSUM_ENABLE\t\t(true)\n#define DEFAULT_VLAN_FILTER_ENABLE\t(true)\n#define DEFAULT_VLAN_RX_OFFLOAD\t\t(true)\n#define TX_ALIGNMENT\t\t\t(4)\n#define RXW_PADDING\t\t\t2\n\n#define LAN78XX_USB_VENDOR_ID\t\t(0x0424)\n#define LAN7800_USB_PRODUCT_ID\t\t(0x7800)\n#define LAN7850_USB_PRODUCT_ID\t\t(0x7850)\n#define LAN7801_USB_PRODUCT_ID\t\t(0x7801)\n#define LAN78XX_EEPROM_MAGIC\t\t(0x78A5)\n#define LAN78XX_OTP_MAGIC\t\t(0x78F3)\n#define AT29M2AF_USB_VENDOR_ID\t\t(0x07C9)\n#define AT29M2AF_USB_PRODUCT_ID\t(0x0012)\n\n#define\tMII_READ\t\t\t1\n#define\tMII_WRITE\t\t\t0\n\n#define EEPROM_INDICATOR\t\t(0xA5)\n#define EEPROM_MAC_OFFSET\t\t(0x01)\n#define MAX_EEPROM_SIZE\t\t\t512\n#define OTP_INDICATOR_1\t\t\t(0xF3)\n#define OTP_INDICATOR_2\t\t\t(0xF7)\n\n#define WAKE_ALL\t\t\t(WAKE_PHY | WAKE_UCAST | \\\n\t\t\t\t\t WAKE_MCAST | WAKE_BCAST | \\\n\t\t\t\t\t WAKE_ARP | WAKE_MAGIC)\n\n#define TX_URB_NUM\t\t\t10\n#define TX_SS_URB_NUM\t\t\tTX_URB_NUM\n#define TX_HS_URB_NUM\t\t\tTX_URB_NUM\n#define TX_FS_URB_NUM\t\t\tTX_URB_NUM\n\n/* A single URB buffer must be large enough to hold a complete jumbo packet\n */\n#define TX_SS_URB_SIZE\t\t\t(32 * 1024)\n#define TX_HS_URB_SIZE\t\t\t(16 * 1024)\n#define TX_FS_URB_SIZE\t\t\t(10 * 1024)\n\n#define RX_SS_URB_NUM\t\t\t30\n#define RX_HS_URB_NUM\t\t\t10\n#define RX_FS_URB_NUM\t\t\t10\n#define RX_SS_URB_SIZE\t\t\tTX_SS_URB_SIZE\n#define RX_HS_URB_SIZE\t\t\tTX_HS_URB_SIZE\n#define RX_FS_URB_SIZE\t\t\tTX_FS_URB_SIZE\n\n#define SS_BURST_CAP_SIZE\t\tRX_SS_URB_SIZE\n#define SS_BULK_IN_DELAY\t\t0x2000\n#define HS_BURST_CAP_SIZE\t\tRX_HS_URB_SIZE\n#define HS_BULK_IN_DELAY\t\t0x2000\n#define FS_BURST_CAP_SIZE\t\tRX_FS_URB_SIZE\n#define FS_BULK_IN_DELAY\t\t0x2000\n\n#define TX_CMD_LEN\t\t\t8\n#define TX_SKB_MIN_LEN\t\t\t(TX_CMD_LEN + ETH_HLEN)\n#define LAN78XX_TSO_SIZE(dev)\t\t((dev)->tx_urb_size - TX_SKB_MIN_LEN)\n\n#define RX_CMD_LEN\t\t\t10\n#define RX_SKB_MIN_LEN\t\t\t(RX_CMD_LEN + ETH_HLEN)\n#define RX_MAX_FRAME_LEN(mtu)\t\t((mtu) + ETH_HLEN + VLAN_HLEN)\n\n/* USB related defines */\n#define BULK_IN_PIPE\t\t\t1\n#define BULK_OUT_PIPE\t\t\t2\n\n/* default autosuspend delay (mSec)*/\n#define DEFAULT_AUTOSUSPEND_DELAY\t(10 * 1000)\n\n/* statistic update interval (mSec) */\n#define STAT_UPDATE_TIMER\t\t(1 * 1000)\n\n/* time to wait for MAC or FCT to stop (jiffies) */\n#define HW_DISABLE_TIMEOUT\t\t(HZ / 10)\n\n/* time to wait between polling MAC or FCT state (ms) */\n#define HW_DISABLE_DELAY_MS\t\t1\n\n/* defines interrupts from interrupt EP */\n#define MAX_INT_EP\t\t\t(32)\n#define INT_EP_INTEP\t\t\t(31)\n#define INT_EP_OTP_WR_DONE\t\t(28)\n#define INT_EP_EEE_TX_LPI_START\t\t(26)\n#define INT_EP_EEE_TX_LPI_STOP\t\t(25)\n#define INT_EP_EEE_RX_LPI\t\t(24)\n#define INT_EP_MAC_RESET_TIMEOUT\t(23)\n#define INT_EP_RDFO\t\t\t(22)\n#define INT_EP_TXE\t\t\t(21)\n#define INT_EP_USB_STATUS\t\t(20)\n#define INT_EP_TX_DIS\t\t\t(19)\n#define INT_EP_RX_DIS\t\t\t(18)\n#define INT_EP_PHY\t\t\t(17)\n#define INT_EP_DP\t\t\t(16)\n#define INT_EP_MAC_ERR\t\t\t(15)\n#define INT_EP_TDFU\t\t\t(14)\n#define INT_EP_TDFO\t\t\t(13)\n#define INT_EP_UTX\t\t\t(12)\n#define INT_EP_GPIO_11\t\t\t(11)\n#define INT_EP_GPIO_10\t\t\t(10)\n#define INT_EP_GPIO_9\t\t\t(9)\n#define INT_EP_GPIO_8\t\t\t(8)\n#define INT_EP_GPIO_7\t\t\t(7)\n#define INT_EP_GPIO_6\t\t\t(6)\n#define INT_EP_GPIO_5\t\t\t(5)\n#define INT_EP_GPIO_4\t\t\t(4)\n#define INT_EP_GPIO_3\t\t\t(3)\n#define INT_EP_GPIO_2\t\t\t(2)\n#define INT_EP_GPIO_1\t\t\t(1)\n#define INT_EP_GPIO_0\t\t\t(0)\n\nstatic const char lan78xx_gstrings[][ETH_GSTRING_LEN] = {\n\t\"RX FCS Errors\",\n\t\"RX Alignment Errors\",\n\t\"Rx Fragment Errors\",\n\t\"RX Jabber Errors\",\n\t\"RX Undersize Frame Errors\",\n\t\"RX Oversize Frame Errors\",\n\t\"RX Dropped Frames\",\n\t\"RX Unicast Byte Count\",\n\t\"RX Broadcast Byte Count\",\n\t\"RX Multicast Byte Count\",\n\t\"RX Unicast Frames\",\n\t\"RX Broadcast Frames\",\n\t\"RX Multicast Frames\",\n\t\"RX Pause Frames\",\n\t\"RX 64 Byte Frames\",\n\t\"RX 65 - 127 Byte Frames\",\n\t\"RX 128 - 255 Byte Frames\",\n\t\"RX 256 - 511 Bytes Frames\",\n\t\"RX 512 - 1023 Byte Frames\",\n\t\"RX 1024 - 1518 Byte Frames\",\n\t\"RX Greater 1518 Byte Frames\",\n\t\"EEE RX LPI Transitions\",\n\t\"EEE RX LPI Time\",\n\t\"TX FCS Errors\",\n\t\"TX Excess Deferral Errors\",\n\t\"TX Carrier Errors\",\n\t\"TX Bad Byte Count\",\n\t\"TX Single Collisions\",\n\t\"TX Multiple Collisions\",\n\t\"TX Excessive Collision\",\n\t\"TX Late Collisions\",\n\t\"TX Unicast Byte Count\",\n\t\"TX Broadcast Byte Count\",\n\t\"TX Multicast Byte Count\",\n\t\"TX Unicast Frames\",\n\t\"TX Broadcast Frames\",\n\t\"TX Multicast Frames\",\n\t\"TX Pause Frames\",\n\t\"TX 64 Byte Frames\",\n\t\"TX 65 - 127 Byte Frames\",\n\t\"TX 128 - 255 Byte Frames\",\n\t\"TX 256 - 511 Bytes Frames\",\n\t\"TX 512 - 1023 Byte Frames\",\n\t\"TX 1024 - 1518 Byte Frames\",\n\t\"TX Greater 1518 Byte Frames\",\n\t\"EEE TX LPI Transitions\",\n\t\"EEE TX LPI Time\",\n};\n\nstruct lan78xx_statstage {\n\tu32 rx_fcs_errors;\n\tu32 rx_alignment_errors;\n\tu32 rx_fragment_errors;\n\tu32 rx_jabber_errors;\n\tu32 rx_undersize_frame_errors;\n\tu32 rx_oversize_frame_errors;\n\tu32 rx_dropped_frames;\n\tu32 rx_unicast_byte_count;\n\tu32 rx_broadcast_byte_count;\n\tu32 rx_multicast_byte_count;\n\tu32 rx_unicast_frames;\n\tu32 rx_broadcast_frames;\n\tu32 rx_multicast_frames;\n\tu32 rx_pause_frames;\n\tu32 rx_64_byte_frames;\n\tu32 rx_65_127_byte_frames;\n\tu32 rx_128_255_byte_frames;\n\tu32 rx_256_511_bytes_frames;\n\tu32 rx_512_1023_byte_frames;\n\tu32 rx_1024_1518_byte_frames;\n\tu32 rx_greater_1518_byte_frames;\n\tu32 eee_rx_lpi_transitions;\n\tu32 eee_rx_lpi_time;\n\tu32 tx_fcs_errors;\n\tu32 tx_excess_deferral_errors;\n\tu32 tx_carrier_errors;\n\tu32 tx_bad_byte_count;\n\tu32 tx_single_collisions;\n\tu32 tx_multiple_collisions;\n\tu32 tx_excessive_collision;\n\tu32 tx_late_collisions;\n\tu32 tx_unicast_byte_count;\n\tu32 tx_broadcast_byte_count;\n\tu32 tx_multicast_byte_count;\n\tu32 tx_unicast_frames;\n\tu32 tx_broadcast_frames;\n\tu32 tx_multicast_frames;\n\tu32 tx_pause_frames;\n\tu32 tx_64_byte_frames;\n\tu32 tx_65_127_byte_frames;\n\tu32 tx_128_255_byte_frames;\n\tu32 tx_256_511_bytes_frames;\n\tu32 tx_512_1023_byte_frames;\n\tu32 tx_1024_1518_byte_frames;\n\tu32 tx_greater_1518_byte_frames;\n\tu32 eee_tx_lpi_transitions;\n\tu32 eee_tx_lpi_time;\n};\n\nstruct lan78xx_statstage64 {\n\tu64 rx_fcs_errors;\n\tu64 rx_alignment_errors;\n\tu64 rx_fragment_errors;\n\tu64 rx_jabber_errors;\n\tu64 rx_undersize_frame_errors;\n\tu64 rx_oversize_frame_errors;\n\tu64 rx_dropped_frames;\n\tu64 rx_unicast_byte_count;\n\tu64 rx_broadcast_byte_count;\n\tu64 rx_multicast_byte_count;\n\tu64 rx_unicast_frames;\n\tu64 rx_broadcast_frames;\n\tu64 rx_multicast_frames;\n\tu64 rx_pause_frames;\n\tu64 rx_64_byte_frames;\n\tu64 rx_65_127_byte_frames;\n\tu64 rx_128_255_byte_frames;\n\tu64 rx_256_511_bytes_frames;\n\tu64 rx_512_1023_byte_frames;\n\tu64 rx_1024_1518_byte_frames;\n\tu64 rx_greater_1518_byte_frames;\n\tu64 eee_rx_lpi_transitions;\n\tu64 eee_rx_lpi_time;\n\tu64 tx_fcs_errors;\n\tu64 tx_excess_deferral_errors;\n\tu64 tx_carrier_errors;\n\tu64 tx_bad_byte_count;\n\tu64 tx_single_collisions;\n\tu64 tx_multiple_collisions;\n\tu64 tx_excessive_collision;\n\tu64 tx_late_collisions;\n\tu64 tx_unicast_byte_count;\n\tu64 tx_broadcast_byte_count;\n\tu64 tx_multicast_byte_count;\n\tu64 tx_unicast_frames;\n\tu64 tx_broadcast_frames;\n\tu64 tx_multicast_frames;\n\tu64 tx_pause_frames;\n\tu64 tx_64_byte_frames;\n\tu64 tx_65_127_byte_frames;\n\tu64 tx_128_255_byte_frames;\n\tu64 tx_256_511_bytes_frames;\n\tu64 tx_512_1023_byte_frames;\n\tu64 tx_1024_1518_byte_frames;\n\tu64 tx_greater_1518_byte_frames;\n\tu64 eee_tx_lpi_transitions;\n\tu64 eee_tx_lpi_time;\n};\n\nstatic u32 lan78xx_regs[] = {\n\tID_REV,\n\tINT_STS,\n\tHW_CFG,\n\tPMT_CTL,\n\tE2P_CMD,\n\tE2P_DATA,\n\tUSB_STATUS,\n\tVLAN_TYPE,\n\tMAC_CR,\n\tMAC_RX,\n\tMAC_TX,\n\tFLOW,\n\tERR_STS,\n\tMII_ACC,\n\tMII_DATA,\n\tEEE_TX_LPI_REQ_DLY,\n\tEEE_TW_TX_SYS,\n\tEEE_TX_LPI_REM_DLY,\n\tWUCSR\n};\n\n#define PHY_REG_SIZE (32 * sizeof(u32))\n\nstruct lan78xx_net;\n\nstruct lan78xx_priv {\n\tstruct lan78xx_net *dev;\n\tu32 rfe_ctl;\n\tu32 mchash_table[DP_SEL_VHF_HASH_LEN]; /* multicast hash table */\n\tu32 pfilter_table[NUM_OF_MAF][2]; /* perfect filter table */\n\tu32 vlan_table[DP_SEL_VHF_VLAN_LEN];\n\tstruct mutex dataport_mutex; /* for dataport access */\n\tspinlock_t rfe_ctl_lock; /* for rfe register access */\n\tstruct work_struct set_multicast;\n\tstruct work_struct set_vlan;\n\tu32 wol;\n};\n\nenum skb_state {\n\tillegal = 0,\n\ttx_start,\n\ttx_done,\n\trx_start,\n\trx_done,\n\trx_cleanup,\n\tunlink_start\n};\n\nstruct skb_data {\t\t/* skb->cb is one of these */\n\tstruct urb *urb;\n\tstruct lan78xx_net *dev;\n\tenum skb_state state;\n\tsize_t length;\n\tint num_of_packet;\n};\n\nstruct usb_context {\n\tstruct usb_ctrlrequest req;\n\tstruct lan78xx_net *dev;\n};\n\n#define EVENT_TX_HALT\t\t\t0\n#define EVENT_RX_HALT\t\t\t1\n#define EVENT_RX_MEMORY\t\t\t2\n#define EVENT_STS_SPLIT\t\t\t3\n#define EVENT_LINK_RESET\t\t4\n#define EVENT_RX_PAUSED\t\t\t5\n#define EVENT_DEV_WAKING\t\t6\n#define EVENT_DEV_ASLEEP\t\t7\n#define EVENT_DEV_OPEN\t\t\t8\n#define EVENT_STAT_UPDATE\t\t9\n#define EVENT_DEV_DISCONNECT\t\t10\n\nstruct statstage {\n\tstruct mutex\t\t\taccess_lock;\t/* for stats access */\n\tstruct lan78xx_statstage\tsaved;\n\tstruct lan78xx_statstage\trollover_count;\n\tstruct lan78xx_statstage\trollover_max;\n\tstruct lan78xx_statstage64\tcurr_stat;\n};\n\nstruct irq_domain_data {\n\tstruct irq_domain\t*irqdomain;\n\tunsigned int\t\tphyirq;\n\tstruct irq_chip\t\t*irqchip;\n\tirq_flow_handler_t\tirq_handler;\n\tu32\t\t\tirqenable;\n\tstruct mutex\t\tirq_lock;\t\t/* for irq bus access */\n};\n\nstruct lan78xx_net {\n\tstruct net_device\t*net;\n\tstruct usb_device\t*udev;\n\tstruct usb_interface\t*intf;\n\tvoid\t\t\t*driver_priv;\n\n\tunsigned int\t\ttx_pend_data_len;\n\tsize_t\t\t\tn_tx_urbs;\n\tsize_t\t\t\tn_rx_urbs;\n\tsize_t\t\t\ttx_urb_size;\n\tsize_t\t\t\trx_urb_size;\n\n\tstruct sk_buff_head\trxq_free;\n\tstruct sk_buff_head\trxq;\n\tstruct sk_buff_head\trxq_done;\n\tstruct sk_buff_head\trxq_overflow;\n\tstruct sk_buff_head\ttxq_free;\n\tstruct sk_buff_head\ttxq;\n\tstruct sk_buff_head\ttxq_pend;\n\n\tstruct napi_struct\tnapi;\n\n\tstruct delayed_work\twq;\n\n\tint\t\t\tmsg_enable;\n\n\tstruct urb\t\t*urb_intr;\n\tstruct usb_anchor\tdeferred;\n\n\tstruct mutex\t\tdev_mutex; /* serialise open/stop wrt suspend/resume */\n\tstruct mutex\t\tphy_mutex; /* for phy access */\n\tunsigned int\t\tpipe_in, pipe_out, pipe_intr;\n\n\tunsigned int\t\tbulk_in_delay;\n\tunsigned int\t\tburst_cap;\n\n\tunsigned long\t\tflags;\n\n\twait_queue_head_t\t*wait;\n\tunsigned char\t\tsuspend_count;\n\n\tunsigned int\t\tmaxpacket;\n\tstruct timer_list\tstat_monitor;\n\n\tunsigned long\t\tdata[5];\n\n\tint\t\t\tlink_on;\n\tu8\t\t\tmdix_ctrl;\n\n\tu32\t\t\tchipid;\n\tu32\t\t\tchiprev;\n\tstruct mii_bus\t\t*mdiobus;\n\tphy_interface_t\t\tinterface;\n\n\tint\t\t\tfc_autoneg;\n\tu8\t\t\tfc_request_control;\n\n\tint\t\t\tdelta;\n\tstruct statstage\tstats;\n\n\tstruct irq_domain_data\tdomain_data;\n};\n\n/* define external phy id */\n#define\tPHY_LAN8835\t\t\t(0x0007C130)\n#define\tPHY_KSZ9031RNX\t\t\t(0x00221620)\n\n/* use ethtool to change the level for any given device */\nstatic int msg_level = -1;\nmodule_param(msg_level, int, 0);\nMODULE_PARM_DESC(msg_level, \"Override default message level\");\n\nstatic struct sk_buff *lan78xx_get_buf(struct sk_buff_head *buf_pool)\n{\n\tif (skb_queue_empty(buf_pool))\n\t\treturn NULL;\n\n\treturn skb_dequeue(buf_pool);\n}\n\nstatic void lan78xx_release_buf(struct sk_buff_head *buf_pool,\n\t\t\t\tstruct sk_buff *buf)\n{\n\tbuf->data = buf->head;\n\tskb_reset_tail_pointer(buf);\n\n\tbuf->len = 0;\n\tbuf->data_len = 0;\n\n\tskb_queue_tail(buf_pool, buf);\n}\n\nstatic void lan78xx_free_buf_pool(struct sk_buff_head *buf_pool)\n{\n\tstruct skb_data *entry;\n\tstruct sk_buff *buf;\n\n\twhile (!skb_queue_empty(buf_pool)) {\n\t\tbuf = skb_dequeue(buf_pool);\n\t\tif (buf) {\n\t\t\tentry = (struct skb_data *)buf->cb;\n\t\t\tusb_free_urb(entry->urb);\n\t\t\tdev_kfree_skb_any(buf);\n\t\t}\n\t}\n}\n\nstatic int lan78xx_alloc_buf_pool(struct sk_buff_head *buf_pool,\n\t\t\t\t  size_t n_urbs, size_t urb_size,\n\t\t\t\t  struct lan78xx_net *dev)\n{\n\tstruct skb_data *entry;\n\tstruct sk_buff *buf;\n\tstruct urb *urb;\n\tint i;\n\n\tskb_queue_head_init(buf_pool);\n\n\tfor (i = 0; i < n_urbs; i++) {\n\t\tbuf = alloc_skb(urb_size, GFP_ATOMIC);\n\t\tif (!buf)\n\t\t\tgoto error;\n\n\t\tif (skb_linearize(buf) != 0) {\n\t\t\tdev_kfree_skb_any(buf);\n\t\t\tgoto error;\n\t\t}\n\n\t\turb = usb_alloc_urb(0, GFP_ATOMIC);\n\t\tif (!urb) {\n\t\t\tdev_kfree_skb_any(buf);\n\t\t\tgoto error;\n\t\t}\n\n\t\tentry = (struct skb_data *)buf->cb;\n\t\tentry->urb = urb;\n\t\tentry->dev = dev;\n\t\tentry->length = 0;\n\t\tentry->num_of_packet = 0;\n\n\t\tskb_queue_tail(buf_pool, buf);\n\t}\n\n\treturn 0;\n\nerror:\n\tlan78xx_free_buf_pool(buf_pool);\n\n\treturn -ENOMEM;\n}\n\nstatic struct sk_buff *lan78xx_get_rx_buf(struct lan78xx_net *dev)\n{\n\treturn lan78xx_get_buf(&dev->rxq_free);\n}\n\nstatic void lan78xx_release_rx_buf(struct lan78xx_net *dev,\n\t\t\t\t   struct sk_buff *rx_buf)\n{\n\tlan78xx_release_buf(&dev->rxq_free, rx_buf);\n}\n\nstatic void lan78xx_free_rx_resources(struct lan78xx_net *dev)\n{\n\tlan78xx_free_buf_pool(&dev->rxq_free);\n}\n\nstatic int lan78xx_alloc_rx_resources(struct lan78xx_net *dev)\n{\n\treturn lan78xx_alloc_buf_pool(&dev->rxq_free,\n\t\t\t\t      dev->n_rx_urbs, dev->rx_urb_size, dev);\n}\n\nstatic struct sk_buff *lan78xx_get_tx_buf(struct lan78xx_net *dev)\n{\n\treturn lan78xx_get_buf(&dev->txq_free);\n}\n\nstatic void lan78xx_release_tx_buf(struct lan78xx_net *dev,\n\t\t\t\t   struct sk_buff *tx_buf)\n{\n\tlan78xx_release_buf(&dev->txq_free, tx_buf);\n}\n\nstatic void lan78xx_free_tx_resources(struct lan78xx_net *dev)\n{\n\tlan78xx_free_buf_pool(&dev->txq_free);\n}\n\nstatic int lan78xx_alloc_tx_resources(struct lan78xx_net *dev)\n{\n\treturn lan78xx_alloc_buf_pool(&dev->txq_free,\n\t\t\t\t      dev->n_tx_urbs, dev->tx_urb_size, dev);\n}\n\nstatic int lan78xx_read_reg(struct lan78xx_net *dev, u32 index, u32 *data)\n{\n\tu32 *buf;\n\tint ret;\n\n\tif (test_bit(EVENT_DEV_DISCONNECT, &dev->flags))\n\t\treturn -ENODEV;\n\n\tbuf = kmalloc(sizeof(u32), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(dev->udev, usb_rcvctrlpipe(dev->udev, 0),\n\t\t\t      USB_VENDOR_REQUEST_READ_REGISTER,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\n\t\t\t      0, index, buf, 4, USB_CTRL_GET_TIMEOUT);\n\tif (likely(ret >= 0)) {\n\t\tle32_to_cpus(buf);\n\t\t*data = *buf;\n\t} else if (net_ratelimit()) {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"Failed to read register index 0x%08x. ret = %d\",\n\t\t\t    index, ret);\n\t}\n\n\tkfree(buf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_write_reg(struct lan78xx_net *dev, u32 index, u32 data)\n{\n\tu32 *buf;\n\tint ret;\n\n\tif (test_bit(EVENT_DEV_DISCONNECT, &dev->flags))\n\t\treturn -ENODEV;\n\n\tbuf = kmalloc(sizeof(u32), GFP_KERNEL);\n\tif (!buf)\n\t\treturn -ENOMEM;\n\n\t*buf = data;\n\tcpu_to_le32s(buf);\n\n\tret = usb_control_msg(dev->udev, usb_sndctrlpipe(dev->udev, 0),\n\t\t\t      USB_VENDOR_REQUEST_WRITE_REGISTER,\n\t\t\t      USB_DIR_OUT | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\n\t\t\t      0, index, buf, 4, USB_CTRL_SET_TIMEOUT);\n\tif (unlikely(ret < 0) &&\n\t    net_ratelimit()) {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"Failed to write register index 0x%08x. ret = %d\",\n\t\t\t    index, ret);\n\t}\n\n\tkfree(buf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_update_reg(struct lan78xx_net *dev, u32 reg, u32 mask,\n\t\t\t      u32 data)\n{\n\tint ret;\n\tu32 buf;\n\n\tret = lan78xx_read_reg(dev, reg, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf &= ~mask;\n\tbuf |= (mask & data);\n\n\tret = lan78xx_write_reg(dev, reg, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int lan78xx_read_stats(struct lan78xx_net *dev,\n\t\t\t      struct lan78xx_statstage *data)\n{\n\tint ret = 0;\n\tint i;\n\tstruct lan78xx_statstage *stats;\n\tu32 *src;\n\tu32 *dst;\n\n\tstats = kmalloc(sizeof(*stats), GFP_KERNEL);\n\tif (!stats)\n\t\treturn -ENOMEM;\n\n\tret = usb_control_msg(dev->udev,\n\t\t\t      usb_rcvctrlpipe(dev->udev, 0),\n\t\t\t      USB_VENDOR_REQUEST_GET_STATS,\n\t\t\t      USB_DIR_IN | USB_TYPE_VENDOR | USB_RECIP_DEVICE,\n\t\t\t      0,\n\t\t\t      0,\n\t\t\t      (void *)stats,\n\t\t\t      sizeof(*stats),\n\t\t\t      USB_CTRL_SET_TIMEOUT);\n\tif (likely(ret >= 0)) {\n\t\tsrc = (u32 *)stats;\n\t\tdst = (u32 *)data;\n\t\tfor (i = 0; i < sizeof(*stats) / sizeof(u32); i++) {\n\t\t\tle32_to_cpus(&src[i]);\n\t\t\tdst[i] = src[i];\n\t\t}\n\t} else {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"Failed to read stat ret = %d\", ret);\n\t}\n\n\tkfree(stats);\n\n\treturn ret;\n}\n\n#define check_counter_rollover(struct1, dev_stats, member)\t\t\\\n\tdo {\t\t\t\t\t\t\t\t\\\n\t\tif ((struct1)->member < (dev_stats).saved.member)\t\\\n\t\t\t(dev_stats).rollover_count.member++;\t\t\\\n\t} while (0)\n\nstatic void lan78xx_check_stat_rollover(struct lan78xx_net *dev,\n\t\t\t\t\tstruct lan78xx_statstage *stats)\n{\n\tcheck_counter_rollover(stats, dev->stats, rx_fcs_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_alignment_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_fragment_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_jabber_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_undersize_frame_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_oversize_frame_errors);\n\tcheck_counter_rollover(stats, dev->stats, rx_dropped_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_unicast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, rx_broadcast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, rx_multicast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, rx_unicast_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_broadcast_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_multicast_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_pause_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_64_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_65_127_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_128_255_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_256_511_bytes_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_512_1023_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_1024_1518_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, rx_greater_1518_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, eee_rx_lpi_transitions);\n\tcheck_counter_rollover(stats, dev->stats, eee_rx_lpi_time);\n\tcheck_counter_rollover(stats, dev->stats, tx_fcs_errors);\n\tcheck_counter_rollover(stats, dev->stats, tx_excess_deferral_errors);\n\tcheck_counter_rollover(stats, dev->stats, tx_carrier_errors);\n\tcheck_counter_rollover(stats, dev->stats, tx_bad_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, tx_single_collisions);\n\tcheck_counter_rollover(stats, dev->stats, tx_multiple_collisions);\n\tcheck_counter_rollover(stats, dev->stats, tx_excessive_collision);\n\tcheck_counter_rollover(stats, dev->stats, tx_late_collisions);\n\tcheck_counter_rollover(stats, dev->stats, tx_unicast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, tx_broadcast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, tx_multicast_byte_count);\n\tcheck_counter_rollover(stats, dev->stats, tx_unicast_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_broadcast_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_multicast_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_pause_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_64_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_65_127_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_128_255_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_256_511_bytes_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_512_1023_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_1024_1518_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, tx_greater_1518_byte_frames);\n\tcheck_counter_rollover(stats, dev->stats, eee_tx_lpi_transitions);\n\tcheck_counter_rollover(stats, dev->stats, eee_tx_lpi_time);\n\n\tmemcpy(&dev->stats.saved, stats, sizeof(struct lan78xx_statstage));\n}\n\nstatic void lan78xx_update_stats(struct lan78xx_net *dev)\n{\n\tu32 *p, *count, *max;\n\tu64 *data;\n\tint i;\n\tstruct lan78xx_statstage lan78xx_stats;\n\n\tif (usb_autopm_get_interface(dev->intf) < 0)\n\t\treturn;\n\n\tp = (u32 *)&lan78xx_stats;\n\tcount = (u32 *)&dev->stats.rollover_count;\n\tmax = (u32 *)&dev->stats.rollover_max;\n\tdata = (u64 *)&dev->stats.curr_stat;\n\n\tmutex_lock(&dev->stats.access_lock);\n\n\tif (lan78xx_read_stats(dev, &lan78xx_stats) > 0)\n\t\tlan78xx_check_stat_rollover(dev, &lan78xx_stats);\n\n\tfor (i = 0; i < (sizeof(lan78xx_stats) / (sizeof(u32))); i++)\n\t\tdata[i] = (u64)p[i] + ((u64)count[i] * ((u64)max[i] + 1));\n\n\tmutex_unlock(&dev->stats.access_lock);\n\n\tusb_autopm_put_interface(dev->intf);\n}\n\n/* Loop until the read is completed with timeout called with phy_mutex held */\nstatic int lan78xx_phy_wait_not_busy(struct lan78xx_net *dev)\n{\n\tunsigned long start_time = jiffies;\n\tu32 val;\n\tint ret;\n\n\tdo {\n\t\tret = lan78xx_read_reg(dev, MII_ACC, &val);\n\t\tif (unlikely(ret < 0))\n\t\t\treturn -EIO;\n\n\t\tif (!(val & MII_ACC_MII_BUSY_))\n\t\t\treturn 0;\n\t} while (!time_after(jiffies, start_time + HZ));\n\n\treturn -EIO;\n}\n\nstatic inline u32 mii_access(int id, int index, int read)\n{\n\tu32 ret;\n\n\tret = ((u32)id << MII_ACC_PHY_ADDR_SHIFT_) & MII_ACC_PHY_ADDR_MASK_;\n\tret |= ((u32)index << MII_ACC_MIIRINDA_SHIFT_) & MII_ACC_MIIRINDA_MASK_;\n\tif (read)\n\t\tret |= MII_ACC_MII_READ_;\n\telse\n\t\tret |= MII_ACC_MII_WRITE_;\n\tret |= MII_ACC_MII_BUSY_;\n\n\treturn ret;\n}\n\nstatic int lan78xx_wait_eeprom(struct lan78xx_net *dev)\n{\n\tunsigned long start_time = jiffies;\n\tu32 val;\n\tint ret;\n\n\tdo {\n\t\tret = lan78xx_read_reg(dev, E2P_CMD, &val);\n\t\tif (unlikely(ret < 0))\n\t\t\treturn -EIO;\n\n\t\tif (!(val & E2P_CMD_EPC_BUSY_) ||\n\t\t    (val & E2P_CMD_EPC_TIMEOUT_))\n\t\t\tbreak;\n\t\tusleep_range(40, 100);\n\t} while (!time_after(jiffies, start_time + HZ));\n\n\tif (val & (E2P_CMD_EPC_TIMEOUT_ | E2P_CMD_EPC_BUSY_)) {\n\t\tnetdev_warn(dev->net, \"EEPROM read operation timeout\");\n\t\treturn -EIO;\n\t}\n\n\treturn 0;\n}\n\nstatic int lan78xx_eeprom_confirm_not_busy(struct lan78xx_net *dev)\n{\n\tunsigned long start_time = jiffies;\n\tu32 val;\n\tint ret;\n\n\tdo {\n\t\tret = lan78xx_read_reg(dev, E2P_CMD, &val);\n\t\tif (unlikely(ret < 0))\n\t\t\treturn -EIO;\n\n\t\tif (!(val & E2P_CMD_EPC_BUSY_))\n\t\t\treturn 0;\n\n\t\tusleep_range(40, 100);\n\t} while (!time_after(jiffies, start_time + HZ));\n\n\tnetdev_warn(dev->net, \"EEPROM is busy\");\n\treturn -EIO;\n}\n\nstatic int lan78xx_read_raw_eeprom(struct lan78xx_net *dev, u32 offset,\n\t\t\t\t   u32 length, u8 *data)\n{\n\tu32 val;\n\tu32 saved;\n\tint i, ret;\n\tint retval;\n\n\t/* depends on chip, some EEPROM pins are muxed with LED function.\n\t * disable & restore LED function to access EEPROM.\n\t */\n\tret = lan78xx_read_reg(dev, HW_CFG, &val);\n\tsaved = val;\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_) {\n\t\tval &= ~(HW_CFG_LED1_EN_ | HW_CFG_LED0_EN_);\n\t\tret = lan78xx_write_reg(dev, HW_CFG, val);\n\t}\n\n\tretval = lan78xx_eeprom_confirm_not_busy(dev);\n\tif (retval)\n\t\treturn retval;\n\n\tfor (i = 0; i < length; i++) {\n\t\tval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_READ_;\n\t\tval |= (offset & E2P_CMD_EPC_ADDR_MASK_);\n\t\tret = lan78xx_write_reg(dev, E2P_CMD, val);\n\t\tif (unlikely(ret < 0)) {\n\t\t\tretval = -EIO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tretval = lan78xx_wait_eeprom(dev);\n\t\tif (retval < 0)\n\t\t\tgoto exit;\n\n\t\tret = lan78xx_read_reg(dev, E2P_DATA, &val);\n\t\tif (unlikely(ret < 0)) {\n\t\t\tretval = -EIO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tdata[i] = val & 0xFF;\n\t\toffset++;\n\t}\n\n\tretval = 0;\nexit:\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_)\n\t\tret = lan78xx_write_reg(dev, HW_CFG, saved);\n\n\treturn retval;\n}\n\nstatic int lan78xx_read_eeprom(struct lan78xx_net *dev, u32 offset,\n\t\t\t       u32 length, u8 *data)\n{\n\tu8 sig;\n\tint ret;\n\n\tret = lan78xx_read_raw_eeprom(dev, 0, 1, &sig);\n\tif ((ret == 0) && (sig == EEPROM_INDICATOR))\n\t\tret = lan78xx_read_raw_eeprom(dev, offset, length, data);\n\telse\n\t\tret = -EINVAL;\n\n\treturn ret;\n}\n\nstatic int lan78xx_write_raw_eeprom(struct lan78xx_net *dev, u32 offset,\n\t\t\t\t    u32 length, u8 *data)\n{\n\tu32 val;\n\tu32 saved;\n\tint i, ret;\n\tint retval;\n\n\t/* depends on chip, some EEPROM pins are muxed with LED function.\n\t * disable & restore LED function to access EEPROM.\n\t */\n\tret = lan78xx_read_reg(dev, HW_CFG, &val);\n\tsaved = val;\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_) {\n\t\tval &= ~(HW_CFG_LED1_EN_ | HW_CFG_LED0_EN_);\n\t\tret = lan78xx_write_reg(dev, HW_CFG, val);\n\t}\n\n\tretval = lan78xx_eeprom_confirm_not_busy(dev);\n\tif (retval)\n\t\tgoto exit;\n\n\t/* Issue write/erase enable command */\n\tval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_EWEN_;\n\tret = lan78xx_write_reg(dev, E2P_CMD, val);\n\tif (unlikely(ret < 0)) {\n\t\tretval = -EIO;\n\t\tgoto exit;\n\t}\n\n\tretval = lan78xx_wait_eeprom(dev);\n\tif (retval < 0)\n\t\tgoto exit;\n\n\tfor (i = 0; i < length; i++) {\n\t\t/* Fill data register */\n\t\tval = data[i];\n\t\tret = lan78xx_write_reg(dev, E2P_DATA, val);\n\t\tif (ret < 0) {\n\t\t\tretval = -EIO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\t/* Send \"write\" command */\n\t\tval = E2P_CMD_EPC_BUSY_ | E2P_CMD_EPC_CMD_WRITE_;\n\t\tval |= (offset & E2P_CMD_EPC_ADDR_MASK_);\n\t\tret = lan78xx_write_reg(dev, E2P_CMD, val);\n\t\tif (ret < 0) {\n\t\t\tretval = -EIO;\n\t\t\tgoto exit;\n\t\t}\n\n\t\tretval = lan78xx_wait_eeprom(dev);\n\t\tif (retval < 0)\n\t\t\tgoto exit;\n\n\t\toffset++;\n\t}\n\n\tretval = 0;\nexit:\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_)\n\t\tret = lan78xx_write_reg(dev, HW_CFG, saved);\n\n\treturn retval;\n}\n\nstatic int lan78xx_read_raw_otp(struct lan78xx_net *dev, u32 offset,\n\t\t\t\tu32 length, u8 *data)\n{\n\tint i;\n\tu32 buf;\n\tunsigned long timeout;\n\n\tlan78xx_read_reg(dev, OTP_PWR_DN, &buf);\n\n\tif (buf & OTP_PWR_DN_PWRDN_N_) {\n\t\t/* clear it and wait to be cleared */\n\t\tlan78xx_write_reg(dev, OTP_PWR_DN, 0);\n\n\t\ttimeout = jiffies + HZ;\n\t\tdo {\n\t\t\tusleep_range(1, 10);\n\t\t\tlan78xx_read_reg(dev, OTP_PWR_DN, &buf);\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tnetdev_warn(dev->net,\n\t\t\t\t\t    \"timeout on OTP_PWR_DN\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} while (buf & OTP_PWR_DN_PWRDN_N_);\n\t}\n\n\tfor (i = 0; i < length; i++) {\n\t\tlan78xx_write_reg(dev, OTP_ADDR1,\n\t\t\t\t  ((offset + i) >> 8) & OTP_ADDR1_15_11);\n\t\tlan78xx_write_reg(dev, OTP_ADDR2,\n\t\t\t\t  ((offset + i) & OTP_ADDR2_10_3));\n\n\t\tlan78xx_write_reg(dev, OTP_FUNC_CMD, OTP_FUNC_CMD_READ_);\n\t\tlan78xx_write_reg(dev, OTP_CMD_GO, OTP_CMD_GO_GO_);\n\n\t\ttimeout = jiffies + HZ;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t\tlan78xx_read_reg(dev, OTP_STATUS, &buf);\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tnetdev_warn(dev->net,\n\t\t\t\t\t    \"timeout on OTP_STATUS\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} while (buf & OTP_STATUS_BUSY_);\n\n\t\tlan78xx_read_reg(dev, OTP_RD_DATA, &buf);\n\n\t\tdata[i] = (u8)(buf & 0xFF);\n\t}\n\n\treturn 0;\n}\n\nstatic int lan78xx_write_raw_otp(struct lan78xx_net *dev, u32 offset,\n\t\t\t\t u32 length, u8 *data)\n{\n\tint i;\n\tu32 buf;\n\tunsigned long timeout;\n\n\tlan78xx_read_reg(dev, OTP_PWR_DN, &buf);\n\n\tif (buf & OTP_PWR_DN_PWRDN_N_) {\n\t\t/* clear it and wait to be cleared */\n\t\tlan78xx_write_reg(dev, OTP_PWR_DN, 0);\n\n\t\ttimeout = jiffies + HZ;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t\tlan78xx_read_reg(dev, OTP_PWR_DN, &buf);\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tnetdev_warn(dev->net,\n\t\t\t\t\t    \"timeout on OTP_PWR_DN completion\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} while (buf & OTP_PWR_DN_PWRDN_N_);\n\t}\n\n\t/* set to BYTE program mode */\n\tlan78xx_write_reg(dev, OTP_PRGM_MODE, OTP_PRGM_MODE_BYTE_);\n\n\tfor (i = 0; i < length; i++) {\n\t\tlan78xx_write_reg(dev, OTP_ADDR1,\n\t\t\t\t  ((offset + i) >> 8) & OTP_ADDR1_15_11);\n\t\tlan78xx_write_reg(dev, OTP_ADDR2,\n\t\t\t\t  ((offset + i) & OTP_ADDR2_10_3));\n\t\tlan78xx_write_reg(dev, OTP_PRGM_DATA, data[i]);\n\t\tlan78xx_write_reg(dev, OTP_TST_CMD, OTP_TST_CMD_PRGVRFY_);\n\t\tlan78xx_write_reg(dev, OTP_CMD_GO, OTP_CMD_GO_GO_);\n\n\t\ttimeout = jiffies + HZ;\n\t\tdo {\n\t\t\tudelay(1);\n\t\t\tlan78xx_read_reg(dev, OTP_STATUS, &buf);\n\t\t\tif (time_after(jiffies, timeout)) {\n\t\t\t\tnetdev_warn(dev->net,\n\t\t\t\t\t    \"Timeout on OTP_STATUS completion\");\n\t\t\t\treturn -EIO;\n\t\t\t}\n\t\t} while (buf & OTP_STATUS_BUSY_);\n\t}\n\n\treturn 0;\n}\n\nstatic int lan78xx_read_otp(struct lan78xx_net *dev, u32 offset,\n\t\t\t    u32 length, u8 *data)\n{\n\tu8 sig;\n\tint ret;\n\n\tret = lan78xx_read_raw_otp(dev, 0, 1, &sig);\n\n\tif (ret == 0) {\n\t\tif (sig == OTP_INDICATOR_2)\n\t\t\toffset += 0x100;\n\t\telse if (sig != OTP_INDICATOR_1)\n\t\t\tret = -EINVAL;\n\t\tif (!ret)\n\t\t\tret = lan78xx_read_raw_otp(dev, offset, length, data);\n\t}\n\n\treturn ret;\n}\n\nstatic int lan78xx_dataport_wait_not_busy(struct lan78xx_net *dev)\n{\n\tint i, ret;\n\n\tfor (i = 0; i < 100; i++) {\n\t\tu32 dp_sel;\n\n\t\tret = lan78xx_read_reg(dev, DP_SEL, &dp_sel);\n\t\tif (unlikely(ret < 0))\n\t\t\treturn -EIO;\n\n\t\tif (dp_sel & DP_SEL_DPRDY_)\n\t\t\treturn 0;\n\n\t\tusleep_range(40, 100);\n\t}\n\n\tnetdev_warn(dev->net, \"%s timed out\", __func__);\n\n\treturn -EIO;\n}\n\nstatic int lan78xx_dataport_write(struct lan78xx_net *dev, u32 ram_select,\n\t\t\t\t  u32 addr, u32 length, u32 *buf)\n{\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tu32 dp_sel;\n\tint i, ret;\n\n\tif (usb_autopm_get_interface(dev->intf) < 0)\n\t\treturn 0;\n\n\tmutex_lock(&pdata->dataport_mutex);\n\n\tret = lan78xx_dataport_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tret = lan78xx_read_reg(dev, DP_SEL, &dp_sel);\n\n\tdp_sel &= ~DP_SEL_RSEL_MASK_;\n\tdp_sel |= ram_select;\n\tret = lan78xx_write_reg(dev, DP_SEL, dp_sel);\n\n\tfor (i = 0; i < length; i++) {\n\t\tret = lan78xx_write_reg(dev, DP_ADDR, addr + i);\n\n\t\tret = lan78xx_write_reg(dev, DP_DATA, buf[i]);\n\n\t\tret = lan78xx_write_reg(dev, DP_CMD, DP_CMD_WRITE_);\n\n\t\tret = lan78xx_dataport_wait_not_busy(dev);\n\t\tif (ret < 0)\n\t\t\tgoto done;\n\t}\n\ndone:\n\tmutex_unlock(&pdata->dataport_mutex);\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic void lan78xx_set_addr_filter(struct lan78xx_priv *pdata,\n\t\t\t\t    int index, u8 addr[ETH_ALEN])\n{\n\tu32 temp;\n\n\tif ((pdata) && (index > 0) && (index < NUM_OF_MAF)) {\n\t\ttemp = addr[3];\n\t\ttemp = addr[2] | (temp << 8);\n\t\ttemp = addr[1] | (temp << 8);\n\t\ttemp = addr[0] | (temp << 8);\n\t\tpdata->pfilter_table[index][1] = temp;\n\t\ttemp = addr[5];\n\t\ttemp = addr[4] | (temp << 8);\n\t\ttemp |= MAF_HI_VALID_ | MAF_HI_TYPE_DST_;\n\t\tpdata->pfilter_table[index][0] = temp;\n\t}\n}\n\n/* returns hash bit number for given MAC address */\nstatic inline u32 lan78xx_hash(char addr[ETH_ALEN])\n{\n\treturn (ether_crc(ETH_ALEN, addr) >> 23) & 0x1ff;\n}\n\nstatic void lan78xx_deferred_multicast_write(struct work_struct *param)\n{\n\tstruct lan78xx_priv *pdata =\n\t\t\tcontainer_of(param, struct lan78xx_priv, set_multicast);\n\tstruct lan78xx_net *dev = pdata->dev;\n\tint i;\n\n\tnetif_dbg(dev, drv, dev->net, \"deferred multicast write 0x%08x\\n\",\n\t\t  pdata->rfe_ctl);\n\n\tlan78xx_dataport_write(dev, DP_SEL_RSEL_VLAN_DA_, DP_SEL_VHF_VLAN_LEN,\n\t\t\t       DP_SEL_VHF_HASH_LEN, pdata->mchash_table);\n\n\tfor (i = 1; i < NUM_OF_MAF; i++) {\n\t\tlan78xx_write_reg(dev, MAF_HI(i), 0);\n\t\tlan78xx_write_reg(dev, MAF_LO(i),\n\t\t\t\t  pdata->pfilter_table[i][1]);\n\t\tlan78xx_write_reg(dev, MAF_HI(i),\n\t\t\t\t  pdata->pfilter_table[i][0]);\n\t}\n\n\tlan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\n}\n\nstatic void lan78xx_set_multicast(struct net_device *netdev)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tunsigned long flags;\n\tint i;\n\n\tspin_lock_irqsave(&pdata->rfe_ctl_lock, flags);\n\n\tpdata->rfe_ctl &= ~(RFE_CTL_UCAST_EN_ | RFE_CTL_MCAST_EN_ |\n\t\t\t    RFE_CTL_DA_PERFECT_ | RFE_CTL_MCAST_HASH_);\n\n\tfor (i = 0; i < DP_SEL_VHF_HASH_LEN; i++)\n\t\tpdata->mchash_table[i] = 0;\n\n\t/* pfilter_table[0] has own HW address */\n\tfor (i = 1; i < NUM_OF_MAF; i++) {\n\t\tpdata->pfilter_table[i][0] = 0;\n\t\tpdata->pfilter_table[i][1] = 0;\n\t}\n\n\tpdata->rfe_ctl |= RFE_CTL_BCAST_EN_;\n\n\tif (dev->net->flags & IFF_PROMISC) {\n\t\tnetif_dbg(dev, drv, dev->net, \"promiscuous mode enabled\");\n\t\tpdata->rfe_ctl |= RFE_CTL_MCAST_EN_ | RFE_CTL_UCAST_EN_;\n\t} else {\n\t\tif (dev->net->flags & IFF_ALLMULTI) {\n\t\t\tnetif_dbg(dev, drv, dev->net,\n\t\t\t\t  \"receive all multicast enabled\");\n\t\t\tpdata->rfe_ctl |= RFE_CTL_MCAST_EN_;\n\t\t}\n\t}\n\n\tif (netdev_mc_count(dev->net)) {\n\t\tstruct netdev_hw_addr *ha;\n\t\tint i;\n\n\t\tnetif_dbg(dev, drv, dev->net, \"receive multicast hash filter\");\n\n\t\tpdata->rfe_ctl |= RFE_CTL_DA_PERFECT_;\n\n\t\ti = 1;\n\t\tnetdev_for_each_mc_addr(ha, netdev) {\n\t\t\t/* set first 32 into Perfect Filter */\n\t\t\tif (i < 33) {\n\t\t\t\tlan78xx_set_addr_filter(pdata, i, ha->addr);\n\t\t\t} else {\n\t\t\t\tu32 bitnum = lan78xx_hash(ha->addr);\n\n\t\t\t\tpdata->mchash_table[bitnum / 32] |=\n\t\t\t\t\t\t\t(1 << (bitnum % 32));\n\t\t\t\tpdata->rfe_ctl |= RFE_CTL_MCAST_HASH_;\n\t\t\t}\n\t\t\ti++;\n\t\t}\n\t}\n\n\tspin_unlock_irqrestore(&pdata->rfe_ctl_lock, flags);\n\n\t/* defer register writes to a sleepable context */\n\tschedule_work(&pdata->set_multicast);\n}\n\nstatic int lan78xx_update_flowcontrol(struct lan78xx_net *dev, u8 duplex,\n\t\t\t\t      u16 lcladv, u16 rmtadv)\n{\n\tu32 flow = 0, fct_flow = 0;\n\tu8 cap;\n\n\tif (dev->fc_autoneg)\n\t\tcap = mii_resolve_flowctrl_fdx(lcladv, rmtadv);\n\telse\n\t\tcap = dev->fc_request_control;\n\n\tif (cap & FLOW_CTRL_TX)\n\t\tflow |= (FLOW_CR_TX_FCEN_ | 0xFFFF);\n\n\tif (cap & FLOW_CTRL_RX)\n\t\tflow |= FLOW_CR_RX_FCEN_;\n\n\tif (dev->udev->speed == USB_SPEED_SUPER)\n\t\tfct_flow = FLOW_CTRL_THRESHOLD(FLOW_ON_SS, FLOW_OFF_SS);\n\telse if (dev->udev->speed == USB_SPEED_HIGH)\n\t\tfct_flow = FLOW_CTRL_THRESHOLD(FLOW_ON_HS, FLOW_OFF_HS);\n\n\tnetif_dbg(dev, link, dev->net, \"rx pause %s, tx pause %s\",\n\t\t  (cap & FLOW_CTRL_RX ? \"enabled\" : \"disabled\"),\n\t\t  (cap & FLOW_CTRL_TX ? \"enabled\" : \"disabled\"));\n\n\tlan78xx_write_reg(dev, FCT_FLOW, fct_flow);\n\n\t/* threshold value should be set before enabling flow */\n\tlan78xx_write_reg(dev, FLOW, flow);\n\n\treturn 0;\n}\n\nstatic void lan78xx_rx_urb_submit_all(struct lan78xx_net *dev);\n\nstatic int lan78xx_mac_reset(struct lan78xx_net *dev)\n{\n\tunsigned long start_time = jiffies;\n\tu32 val;\n\tint ret;\n\n\tmutex_lock(&dev->phy_mutex);\n\n\t/* Resetting the device while there is activity on the MDIO\n\t * bus can result in the MAC interface locking up and not\n\t * completing register access transactions.\n\t */\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tret = lan78xx_read_reg(dev, MAC_CR, &val);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tval |= MAC_CR_RST_;\n\tret = lan78xx_write_reg(dev, MAC_CR, val);\n\tif (ret < 0)\n\t\tgoto done;\n\n\t/* Wait for the reset to complete before allowing any further\n\t * MAC register accesses otherwise the MAC may lock up.\n\t */\n\tdo {\n\t\tret = lan78xx_read_reg(dev, MAC_CR, &val);\n\t\tif (ret < 0)\n\t\t\tgoto done;\n\n\t\tif (!(val & MAC_CR_RST_)) {\n\t\t\tret = 0;\n\t\t\tgoto done;\n\t\t}\n\t} while (!time_after(jiffies, start_time + HZ));\n\n\tret = -ETIMEDOUT;\ndone:\n\tmutex_unlock(&dev->phy_mutex);\n\n\treturn ret;\n}\n\nstatic int lan78xx_link_reset(struct lan78xx_net *dev)\n{\n\tstruct phy_device *phydev = dev->net->phydev;\n\tstruct ethtool_link_ksettings ecmd;\n\tint ladv, radv, ret, link;\n\tu32 buf;\n\n\t/* clear LAN78xx interrupt status */\n\tret = lan78xx_write_reg(dev, INT_STS, INT_STS_PHY_INT_);\n\tif (unlikely(ret < 0))\n\t\treturn ret;\n\n\tmutex_lock(&phydev->lock);\n\tphy_read_status(phydev);\n\tlink = phydev->link;\n\tmutex_unlock(&phydev->lock);\n\n\tif (!link && dev->link_on) {\n\t\tdev->link_on = false;\n\n\t\t/* reset MAC */\n\t\tret = lan78xx_mac_reset(dev);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tdel_timer(&dev->stat_monitor);\n\t} else if (link && !dev->link_on) {\n\t\tdev->link_on = true;\n\n\t\tphy_ethtool_ksettings_get(phydev, &ecmd);\n\n\t\tif (dev->udev->speed == USB_SPEED_SUPER) {\n\t\t\tif (ecmd.base.speed == 1000) {\n\t\t\t\t/* disable U2 */\n\t\t\t\tret = lan78xx_read_reg(dev, USB_CFG1, &buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tbuf &= ~USB_CFG1_DEV_U2_INIT_EN_;\n\t\t\t\tret = lan78xx_write_reg(dev, USB_CFG1, buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\t/* enable U1 */\n\t\t\t\tret = lan78xx_read_reg(dev, USB_CFG1, &buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tbuf |= USB_CFG1_DEV_U1_INIT_EN_;\n\t\t\t\tret = lan78xx_write_reg(dev, USB_CFG1, buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t} else {\n\t\t\t\t/* enable U1 & U2 */\n\t\t\t\tret = lan78xx_read_reg(dev, USB_CFG1, &buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t\tbuf |= USB_CFG1_DEV_U2_INIT_EN_;\n\t\t\t\tbuf |= USB_CFG1_DEV_U1_INIT_EN_;\n\t\t\t\tret = lan78xx_write_reg(dev, USB_CFG1, buf);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn ret;\n\t\t\t}\n\t\t}\n\n\t\tladv = phy_read(phydev, MII_ADVERTISE);\n\t\tif (ladv < 0)\n\t\t\treturn ladv;\n\n\t\tradv = phy_read(phydev, MII_LPA);\n\t\tif (radv < 0)\n\t\t\treturn radv;\n\n\t\tnetif_dbg(dev, link, dev->net,\n\t\t\t  \"speed: %u duplex: %d anadv: 0x%04x anlpa: 0x%04x\",\n\t\t\t  ecmd.base.speed, ecmd.base.duplex, ladv, radv);\n\n\t\tret = lan78xx_update_flowcontrol(dev, ecmd.base.duplex, ladv,\n\t\t\t\t\t\t radv);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (!timer_pending(&dev->stat_monitor)) {\n\t\t\tdev->delta = 1;\n\t\t\tmod_timer(&dev->stat_monitor,\n\t\t\t\t  jiffies + STAT_UPDATE_TIMER);\n\t\t}\n\n\t\tlan78xx_rx_urb_submit_all(dev);\n\n\t\tnapi_schedule(&dev->napi);\n\t}\n\n\treturn 0;\n}\n\n/* some work can't be done in tasklets, so we use keventd\n *\n * NOTE:  annoying asymmetry:  if it's active, schedule_work() fails,\n * but tasklet_schedule() doesn't.\thope the failure is rare.\n */\nstatic void lan78xx_defer_kevent(struct lan78xx_net *dev, int work)\n{\n\tset_bit(work, &dev->flags);\n\tif (!schedule_delayed_work(&dev->wq, 0))\n\t\tnetdev_err(dev->net, \"kevent %d may have been dropped\\n\", work);\n}\n\nstatic void lan78xx_status(struct lan78xx_net *dev, struct urb *urb)\n{\n\tu32 intdata;\n\n\tif (urb->actual_length != 4) {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"unexpected urb length %d\", urb->actual_length);\n\t\treturn;\n\t}\n\n\tintdata = get_unaligned_le32(urb->transfer_buffer);\n\n\tif (intdata & INT_ENP_PHY_INT) {\n\t\tnetif_dbg(dev, link, dev->net, \"PHY INTR: 0x%08x\\n\", intdata);\n\t\tlan78xx_defer_kevent(dev, EVENT_LINK_RESET);\n\n\t\tif (dev->domain_data.phyirq > 0)\n\t\t\tgeneric_handle_irq_safe(dev->domain_data.phyirq);\n\t} else {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"unexpected interrupt: 0x%08x\\n\", intdata);\n\t}\n}\n\nstatic int lan78xx_ethtool_get_eeprom_len(struct net_device *netdev)\n{\n\treturn MAX_EEPROM_SIZE;\n}\n\nstatic int lan78xx_ethtool_get_eeprom(struct net_device *netdev,\n\t\t\t\t      struct ethtool_eeprom *ee, u8 *data)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret)\n\t\treturn ret;\n\n\tee->magic = LAN78XX_EEPROM_MAGIC;\n\n\tret = lan78xx_read_raw_eeprom(dev, ee->offset, ee->len, data);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_ethtool_set_eeprom(struct net_device *netdev,\n\t\t\t\t      struct ethtool_eeprom *ee, u8 *data)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret)\n\t\treturn ret;\n\n\t/* Invalid EEPROM_INDICATOR at offset zero will result in a failure\n\t * to load data from EEPROM\n\t */\n\tif (ee->magic == LAN78XX_EEPROM_MAGIC)\n\t\tret = lan78xx_write_raw_eeprom(dev, ee->offset, ee->len, data);\n\telse if ((ee->magic == LAN78XX_OTP_MAGIC) &&\n\t\t (ee->offset == 0) &&\n\t\t (ee->len == 512) &&\n\t\t (data[0] == OTP_INDICATOR_1))\n\t\tret = lan78xx_write_raw_otp(dev, ee->offset, ee->len, data);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic void lan78xx_get_strings(struct net_device *netdev, u32 stringset,\n\t\t\t\tu8 *data)\n{\n\tif (stringset == ETH_SS_STATS)\n\t\tmemcpy(data, lan78xx_gstrings, sizeof(lan78xx_gstrings));\n}\n\nstatic int lan78xx_get_sset_count(struct net_device *netdev, int sset)\n{\n\tif (sset == ETH_SS_STATS)\n\t\treturn ARRAY_SIZE(lan78xx_gstrings);\n\telse\n\t\treturn -EOPNOTSUPP;\n}\n\nstatic void lan78xx_get_stats(struct net_device *netdev,\n\t\t\t      struct ethtool_stats *stats, u64 *data)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\n\tlan78xx_update_stats(dev);\n\n\tmutex_lock(&dev->stats.access_lock);\n\tmemcpy(data, &dev->stats.curr_stat, sizeof(dev->stats.curr_stat));\n\tmutex_unlock(&dev->stats.access_lock);\n}\n\nstatic void lan78xx_get_wol(struct net_device *netdev,\n\t\t\t    struct ethtool_wolinfo *wol)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tint ret;\n\tu32 buf;\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\n\tif (usb_autopm_get_interface(dev->intf) < 0)\n\t\treturn;\n\n\tret = lan78xx_read_reg(dev, USB_CFG0, &buf);\n\tif (unlikely(ret < 0)) {\n\t\twol->supported = 0;\n\t\twol->wolopts = 0;\n\t} else {\n\t\tif (buf & USB_CFG_RMT_WKP_) {\n\t\t\twol->supported = WAKE_ALL;\n\t\t\twol->wolopts = pdata->wol;\n\t\t} else {\n\t\t\twol->supported = 0;\n\t\t\twol->wolopts = 0;\n\t\t}\n\t}\n\n\tusb_autopm_put_interface(dev->intf);\n}\n\nstatic int lan78xx_set_wol(struct net_device *netdev,\n\t\t\t   struct ethtool_wolinfo *wol)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (wol->wolopts & ~WAKE_ALL)\n\t\treturn -EINVAL;\n\n\tpdata->wol = wol->wolopts;\n\n\tdevice_set_wakeup_enable(&dev->udev->dev, (bool)wol->wolopts);\n\n\tphy_ethtool_set_wol(netdev->phydev, wol);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_get_eee(struct net_device *net, struct ethtool_eee *edata)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tint ret;\n\tu32 buf;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = phy_ethtool_get_eee(phydev, edata);\n\tif (ret < 0)\n\t\tgoto exit;\n\n\tret = lan78xx_read_reg(dev, MAC_CR, &buf);\n\tif (buf & MAC_CR_EEE_EN_) {\n\t\tedata->eee_enabled = true;\n\t\tedata->eee_active = !!(edata->advertised &\n\t\t\t\t       edata->lp_advertised);\n\t\tedata->tx_lpi_enabled = true;\n\t\t/* EEE_TX_LPI_REQ_DLY & tx_lpi_timer are same uSec unit */\n\t\tret = lan78xx_read_reg(dev, EEE_TX_LPI_REQ_DLY, &buf);\n\t\tedata->tx_lpi_timer = buf;\n\t} else {\n\t\tedata->eee_enabled = false;\n\t\tedata->eee_active = false;\n\t\tedata->tx_lpi_enabled = false;\n\t\tedata->tx_lpi_timer = 0;\n\t}\n\n\tret = 0;\nexit:\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_set_eee(struct net_device *net, struct ethtool_eee *edata)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tint ret;\n\tu32 buf;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (edata->eee_enabled) {\n\t\tret = lan78xx_read_reg(dev, MAC_CR, &buf);\n\t\tbuf |= MAC_CR_EEE_EN_;\n\t\tret = lan78xx_write_reg(dev, MAC_CR, buf);\n\n\t\tphy_ethtool_set_eee(net->phydev, edata);\n\n\t\tbuf = (u32)edata->tx_lpi_timer;\n\t\tret = lan78xx_write_reg(dev, EEE_TX_LPI_REQ_DLY, buf);\n\t} else {\n\t\tret = lan78xx_read_reg(dev, MAC_CR, &buf);\n\t\tbuf &= ~MAC_CR_EEE_EN_;\n\t\tret = lan78xx_write_reg(dev, MAC_CR, buf);\n\t}\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn 0;\n}\n\nstatic u32 lan78xx_get_link(struct net_device *net)\n{\n\tu32 link;\n\n\tmutex_lock(&net->phydev->lock);\n\tphy_read_status(net->phydev);\n\tlink = net->phydev->link;\n\tmutex_unlock(&net->phydev->lock);\n\n\treturn link;\n}\n\nstatic void lan78xx_get_drvinfo(struct net_device *net,\n\t\t\t\tstruct ethtool_drvinfo *info)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\tstrncpy(info->driver, DRIVER_NAME, sizeof(info->driver));\n\tusb_make_path(dev->udev, info->bus_info, sizeof(info->bus_info));\n}\n\nstatic u32 lan78xx_get_msglevel(struct net_device *net)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\treturn dev->msg_enable;\n}\n\nstatic void lan78xx_set_msglevel(struct net_device *net, u32 level)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\tdev->msg_enable = level;\n}\n\nstatic int lan78xx_get_link_ksettings(struct net_device *net,\n\t\t\t\t      struct ethtool_link_ksettings *cmd)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tphy_ethtool_ksettings_get(phydev, cmd);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_set_link_ksettings(struct net_device *net,\n\t\t\t\t      const struct ethtool_link_ksettings *cmd)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tint ret = 0;\n\tint temp;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* change speed & duplex */\n\tret = phy_ethtool_ksettings_set(phydev, cmd);\n\n\tif (!cmd->base.autoneg) {\n\t\t/* force link down */\n\t\ttemp = phy_read(phydev, MII_BMCR);\n\t\tphy_write(phydev, MII_BMCR, temp | BMCR_LOOPBACK);\n\t\tmdelay(1);\n\t\tphy_write(phydev, MII_BMCR, temp);\n\t}\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic void lan78xx_get_pause(struct net_device *net,\n\t\t\t      struct ethtool_pauseparam *pause)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tstruct ethtool_link_ksettings ecmd;\n\n\tphy_ethtool_ksettings_get(phydev, &ecmd);\n\n\tpause->autoneg = dev->fc_autoneg;\n\n\tif (dev->fc_request_control & FLOW_CTRL_TX)\n\t\tpause->tx_pause = 1;\n\n\tif (dev->fc_request_control & FLOW_CTRL_RX)\n\t\tpause->rx_pause = 1;\n}\n\nstatic int lan78xx_set_pause(struct net_device *net,\n\t\t\t     struct ethtool_pauseparam *pause)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tstruct phy_device *phydev = net->phydev;\n\tstruct ethtool_link_ksettings ecmd;\n\tint ret;\n\n\tphy_ethtool_ksettings_get(phydev, &ecmd);\n\n\tif (pause->autoneg && !ecmd.base.autoneg) {\n\t\tret = -EINVAL;\n\t\tgoto exit;\n\t}\n\n\tdev->fc_request_control = 0;\n\tif (pause->rx_pause)\n\t\tdev->fc_request_control |= FLOW_CTRL_RX;\n\n\tif (pause->tx_pause)\n\t\tdev->fc_request_control |= FLOW_CTRL_TX;\n\n\tif (ecmd.base.autoneg) {\n\t\t__ETHTOOL_DECLARE_LINK_MODE_MASK(fc) = { 0, };\n\t\tu32 mii_adv;\n\n\t\tlinkmode_clear_bit(ETHTOOL_LINK_MODE_Pause_BIT,\n\t\t\t\t   ecmd.link_modes.advertising);\n\t\tlinkmode_clear_bit(ETHTOOL_LINK_MODE_Asym_Pause_BIT,\n\t\t\t\t   ecmd.link_modes.advertising);\n\t\tmii_adv = (u32)mii_advertise_flowctrl(dev->fc_request_control);\n\t\tmii_adv_to_linkmode_adv_t(fc, mii_adv);\n\t\tlinkmode_or(ecmd.link_modes.advertising, fc,\n\t\t\t    ecmd.link_modes.advertising);\n\n\t\tphy_ethtool_ksettings_set(phydev, &ecmd);\n\t}\n\n\tdev->fc_autoneg = pause->autoneg;\n\n\tret = 0;\nexit:\n\treturn ret;\n}\n\nstatic int lan78xx_get_regs_len(struct net_device *netdev)\n{\n\tif (!netdev->phydev)\n\t\treturn (sizeof(lan78xx_regs));\n\telse\n\t\treturn (sizeof(lan78xx_regs) + PHY_REG_SIZE);\n}\n\nstatic void\nlan78xx_get_regs(struct net_device *netdev, struct ethtool_regs *regs,\n\t\t void *buf)\n{\n\tu32 *data = buf;\n\tint i, j;\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\n\t/* Read Device/MAC registers */\n\tfor (i = 0; i < ARRAY_SIZE(lan78xx_regs); i++)\n\t\tlan78xx_read_reg(dev, lan78xx_regs[i], &data[i]);\n\n\tif (!netdev->phydev)\n\t\treturn;\n\n\t/* Read PHY registers */\n\tfor (j = 0; j < 32; i++, j++)\n\t\tdata[i] = phy_read(netdev->phydev, j);\n}\n\nstatic const struct ethtool_ops lan78xx_ethtool_ops = {\n\t.get_link\t= lan78xx_get_link,\n\t.nway_reset\t= phy_ethtool_nway_reset,\n\t.get_drvinfo\t= lan78xx_get_drvinfo,\n\t.get_msglevel\t= lan78xx_get_msglevel,\n\t.set_msglevel\t= lan78xx_set_msglevel,\n\t.get_eeprom_len = lan78xx_ethtool_get_eeprom_len,\n\t.get_eeprom\t= lan78xx_ethtool_get_eeprom,\n\t.set_eeprom\t= lan78xx_ethtool_set_eeprom,\n\t.get_ethtool_stats = lan78xx_get_stats,\n\t.get_sset_count = lan78xx_get_sset_count,\n\t.get_strings\t= lan78xx_get_strings,\n\t.get_wol\t= lan78xx_get_wol,\n\t.set_wol\t= lan78xx_set_wol,\n\t.get_ts_info\t= ethtool_op_get_ts_info,\n\t.get_eee\t= lan78xx_get_eee,\n\t.set_eee\t= lan78xx_set_eee,\n\t.get_pauseparam\t= lan78xx_get_pause,\n\t.set_pauseparam\t= lan78xx_set_pause,\n\t.get_link_ksettings = lan78xx_get_link_ksettings,\n\t.set_link_ksettings = lan78xx_set_link_ksettings,\n\t.get_regs_len\t= lan78xx_get_regs_len,\n\t.get_regs\t= lan78xx_get_regs,\n};\n\nstatic void lan78xx_init_mac_address(struct lan78xx_net *dev)\n{\n\tu32 addr_lo, addr_hi;\n\tu8 addr[6];\n\n\tlan78xx_read_reg(dev, RX_ADDRL, &addr_lo);\n\tlan78xx_read_reg(dev, RX_ADDRH, &addr_hi);\n\n\taddr[0] = addr_lo & 0xFF;\n\taddr[1] = (addr_lo >> 8) & 0xFF;\n\taddr[2] = (addr_lo >> 16) & 0xFF;\n\taddr[3] = (addr_lo >> 24) & 0xFF;\n\taddr[4] = addr_hi & 0xFF;\n\taddr[5] = (addr_hi >> 8) & 0xFF;\n\n\tif (!is_valid_ether_addr(addr)) {\n\t\tif (!eth_platform_get_mac_address(&dev->udev->dev, addr)) {\n\t\t\t/* valid address present in Device Tree */\n\t\t\tnetif_dbg(dev, ifup, dev->net,\n\t\t\t\t  \"MAC address read from Device Tree\");\n\t\t} else if (((lan78xx_read_eeprom(dev, EEPROM_MAC_OFFSET,\n\t\t\t\t\t\t ETH_ALEN, addr) == 0) ||\n\t\t\t    (lan78xx_read_otp(dev, EEPROM_MAC_OFFSET,\n\t\t\t\t\t      ETH_ALEN, addr) == 0)) &&\n\t\t\t   is_valid_ether_addr(addr)) {\n\t\t\t/* eeprom values are valid so use them */\n\t\t\tnetif_dbg(dev, ifup, dev->net,\n\t\t\t\t  \"MAC address read from EEPROM\");\n\t\t} else {\n\t\t\t/* generate random MAC */\n\t\t\teth_random_addr(addr);\n\t\t\tnetif_dbg(dev, ifup, dev->net,\n\t\t\t\t  \"MAC address set to random addr\");\n\t\t}\n\n\t\taddr_lo = addr[0] | (addr[1] << 8) |\n\t\t\t  (addr[2] << 16) | (addr[3] << 24);\n\t\taddr_hi = addr[4] | (addr[5] << 8);\n\n\t\tlan78xx_write_reg(dev, RX_ADDRL, addr_lo);\n\t\tlan78xx_write_reg(dev, RX_ADDRH, addr_hi);\n\t}\n\n\tlan78xx_write_reg(dev, MAF_LO(0), addr_lo);\n\tlan78xx_write_reg(dev, MAF_HI(0), addr_hi | MAF_HI_VALID_);\n\n\teth_hw_addr_set(dev->net, addr);\n}\n\n/* MDIO read and write wrappers for phylib */\nstatic int lan78xx_mdiobus_read(struct mii_bus *bus, int phy_id, int idx)\n{\n\tstruct lan78xx_net *dev = bus->priv;\n\tu32 val, addr;\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&dev->phy_mutex);\n\n\t/* confirm MII not busy */\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\t/* set the address, index & direction (read from PHY) */\n\taddr = mii_access(phy_id, idx, MII_READ);\n\tret = lan78xx_write_reg(dev, MII_ACC, addr);\n\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tret = lan78xx_read_reg(dev, MII_DATA, &val);\n\n\tret = (int)(val & 0xFFFF);\n\ndone:\n\tmutex_unlock(&dev->phy_mutex);\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_mdiobus_write(struct mii_bus *bus, int phy_id, int idx,\n\t\t\t\t u16 regval)\n{\n\tstruct lan78xx_net *dev = bus->priv;\n\tu32 val, addr;\n\tint ret;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&dev->phy_mutex);\n\n\t/* confirm MII not busy */\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tval = (u32)regval;\n\tret = lan78xx_write_reg(dev, MII_DATA, val);\n\n\t/* set the address, index & direction (write to PHY) */\n\taddr = mii_access(phy_id, idx, MII_WRITE);\n\tret = lan78xx_write_reg(dev, MII_ACC, addr);\n\n\tret = lan78xx_phy_wait_not_busy(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\ndone:\n\tmutex_unlock(&dev->phy_mutex);\n\tusb_autopm_put_interface(dev->intf);\n\treturn 0;\n}\n\nstatic int lan78xx_mdio_init(struct lan78xx_net *dev)\n{\n\tstruct device_node *node;\n\tint ret;\n\n\tdev->mdiobus = mdiobus_alloc();\n\tif (!dev->mdiobus) {\n\t\tnetdev_err(dev->net, \"can't allocate MDIO bus\\n\");\n\t\treturn -ENOMEM;\n\t}\n\n\tdev->mdiobus->priv = (void *)dev;\n\tdev->mdiobus->read = lan78xx_mdiobus_read;\n\tdev->mdiobus->write = lan78xx_mdiobus_write;\n\tdev->mdiobus->name = \"lan78xx-mdiobus\";\n\tdev->mdiobus->parent = &dev->udev->dev;\n\n\tsnprintf(dev->mdiobus->id, MII_BUS_ID_SIZE, \"usb-%03d:%03d\",\n\t\t dev->udev->bus->busnum, dev->udev->devnum);\n\n\tswitch (dev->chipid) {\n\tcase ID_REV_CHIP_ID_7800_:\n\tcase ID_REV_CHIP_ID_7850_:\n\t\t/* set to internal PHY id */\n\t\tdev->mdiobus->phy_mask = ~(1 << 1);\n\t\tbreak;\n\tcase ID_REV_CHIP_ID_7801_:\n\t\t/* scan thru PHYAD[2..0] */\n\t\tdev->mdiobus->phy_mask = ~(0xFF);\n\t\tbreak;\n\t}\n\n\tnode = of_get_child_by_name(dev->udev->dev.of_node, \"mdio\");\n\tret = of_mdiobus_register(dev->mdiobus, node);\n\tof_node_put(node);\n\tif (ret) {\n\t\tnetdev_err(dev->net, \"can't register MDIO bus\\n\");\n\t\tgoto exit1;\n\t}\n\n\tnetdev_dbg(dev->net, \"registered mdiobus bus %s\\n\", dev->mdiobus->id);\n\treturn 0;\nexit1:\n\tmdiobus_free(dev->mdiobus);\n\treturn ret;\n}\n\nstatic void lan78xx_remove_mdio(struct lan78xx_net *dev)\n{\n\tmdiobus_unregister(dev->mdiobus);\n\tmdiobus_free(dev->mdiobus);\n}\n\nstatic void lan78xx_link_status_change(struct net_device *net)\n{\n\tstruct phy_device *phydev = net->phydev;\n\n\tphy_print_status(phydev);\n}\n\nstatic int irq_map(struct irq_domain *d, unsigned int irq,\n\t\t   irq_hw_number_t hwirq)\n{\n\tstruct irq_domain_data *data = d->host_data;\n\n\tirq_set_chip_data(irq, data);\n\tirq_set_chip_and_handler(irq, data->irqchip, data->irq_handler);\n\tirq_set_noprobe(irq);\n\n\treturn 0;\n}\n\nstatic void irq_unmap(struct irq_domain *d, unsigned int irq)\n{\n\tirq_set_chip_and_handler(irq, NULL, NULL);\n\tirq_set_chip_data(irq, NULL);\n}\n\nstatic const struct irq_domain_ops chip_domain_ops = {\n\t.map\t= irq_map,\n\t.unmap\t= irq_unmap,\n};\n\nstatic void lan78xx_irq_mask(struct irq_data *irqd)\n{\n\tstruct irq_domain_data *data = irq_data_get_irq_chip_data(irqd);\n\n\tdata->irqenable &= ~BIT(irqd_to_hwirq(irqd));\n}\n\nstatic void lan78xx_irq_unmask(struct irq_data *irqd)\n{\n\tstruct irq_domain_data *data = irq_data_get_irq_chip_data(irqd);\n\n\tdata->irqenable |= BIT(irqd_to_hwirq(irqd));\n}\n\nstatic void lan78xx_irq_bus_lock(struct irq_data *irqd)\n{\n\tstruct irq_domain_data *data = irq_data_get_irq_chip_data(irqd);\n\n\tmutex_lock(&data->irq_lock);\n}\n\nstatic void lan78xx_irq_bus_sync_unlock(struct irq_data *irqd)\n{\n\tstruct irq_domain_data *data = irq_data_get_irq_chip_data(irqd);\n\tstruct lan78xx_net *dev =\n\t\t\tcontainer_of(data, struct lan78xx_net, domain_data);\n\tu32 buf;\n\n\t/* call register access here because irq_bus_lock & irq_bus_sync_unlock\n\t * are only two callbacks executed in non-atomic contex.\n\t */\n\tlan78xx_read_reg(dev, INT_EP_CTL, &buf);\n\tif (buf != data->irqenable)\n\t\tlan78xx_write_reg(dev, INT_EP_CTL, data->irqenable);\n\n\tmutex_unlock(&data->irq_lock);\n}\n\nstatic struct irq_chip lan78xx_irqchip = {\n\t.name\t\t\t= \"lan78xx-irqs\",\n\t.irq_mask\t\t= lan78xx_irq_mask,\n\t.irq_unmask\t\t= lan78xx_irq_unmask,\n\t.irq_bus_lock\t\t= lan78xx_irq_bus_lock,\n\t.irq_bus_sync_unlock\t= lan78xx_irq_bus_sync_unlock,\n};\n\nstatic int lan78xx_setup_irq_domain(struct lan78xx_net *dev)\n{\n\tstruct device_node *of_node;\n\tstruct irq_domain *irqdomain;\n\tunsigned int irqmap = 0;\n\tu32 buf;\n\tint ret = 0;\n\n\tof_node = dev->udev->dev.parent->of_node;\n\n\tmutex_init(&dev->domain_data.irq_lock);\n\n\tlan78xx_read_reg(dev, INT_EP_CTL, &buf);\n\tdev->domain_data.irqenable = buf;\n\n\tdev->domain_data.irqchip = &lan78xx_irqchip;\n\tdev->domain_data.irq_handler = handle_simple_irq;\n\n\tirqdomain = irq_domain_add_simple(of_node, MAX_INT_EP, 0,\n\t\t\t\t\t  &chip_domain_ops, &dev->domain_data);\n\tif (irqdomain) {\n\t\t/* create mapping for PHY interrupt */\n\t\tirqmap = irq_create_mapping(irqdomain, INT_EP_PHY);\n\t\tif (!irqmap) {\n\t\t\tirq_domain_remove(irqdomain);\n\n\t\t\tirqdomain = NULL;\n\t\t\tret = -EINVAL;\n\t\t}\n\t} else {\n\t\tret = -EINVAL;\n\t}\n\n\tdev->domain_data.irqdomain = irqdomain;\n\tdev->domain_data.phyirq = irqmap;\n\n\treturn ret;\n}\n\nstatic void lan78xx_remove_irq_domain(struct lan78xx_net *dev)\n{\n\tif (dev->domain_data.phyirq > 0) {\n\t\tirq_dispose_mapping(dev->domain_data.phyirq);\n\n\t\tif (dev->domain_data.irqdomain)\n\t\t\tirq_domain_remove(dev->domain_data.irqdomain);\n\t}\n\tdev->domain_data.phyirq = 0;\n\tdev->domain_data.irqdomain = NULL;\n}\n\nstatic int lan8835_fixup(struct phy_device *phydev)\n{\n\tint buf;\n\tstruct lan78xx_net *dev = netdev_priv(phydev->attached_dev);\n\n\t/* LED2/PME_N/IRQ_N/RGMII_ID pin to IRQ_N mode */\n\tbuf = phy_read_mmd(phydev, MDIO_MMD_PCS, 0x8010);\n\tbuf &= ~0x1800;\n\tbuf |= 0x0800;\n\tphy_write_mmd(phydev, MDIO_MMD_PCS, 0x8010, buf);\n\n\t/* RGMII MAC TXC Delay Enable */\n\tlan78xx_write_reg(dev, MAC_RGMII_ID,\n\t\t\t  MAC_RGMII_ID_TXC_DELAY_EN_);\n\n\t/* RGMII TX DLL Tune Adjust */\n\tlan78xx_write_reg(dev, RGMII_TX_BYP_DLL, 0x3D00);\n\n\tdev->interface = PHY_INTERFACE_MODE_RGMII_TXID;\n\n\treturn 1;\n}\n\nstatic int ksz9031rnx_fixup(struct phy_device *phydev)\n{\n\tstruct lan78xx_net *dev = netdev_priv(phydev->attached_dev);\n\n\t/* Micrel9301RNX PHY configuration */\n\t/* RGMII Control Signal Pad Skew */\n\tphy_write_mmd(phydev, MDIO_MMD_WIS, 4, 0x0077);\n\t/* RGMII RX Data Pad Skew */\n\tphy_write_mmd(phydev, MDIO_MMD_WIS, 5, 0x7777);\n\t/* RGMII RX Clock Pad Skew */\n\tphy_write_mmd(phydev, MDIO_MMD_WIS, 8, 0x1FF);\n\n\tdev->interface = PHY_INTERFACE_MODE_RGMII_RXID;\n\n\treturn 1;\n}\n\nstatic struct phy_device *lan7801_phy_init(struct lan78xx_net *dev)\n{\n\tu32 buf;\n\tint ret;\n\tstruct fixed_phy_status fphy_status = {\n\t\t.link = 1,\n\t\t.speed = SPEED_1000,\n\t\t.duplex = DUPLEX_FULL,\n\t};\n\tstruct phy_device *phydev;\n\n\tphydev = phy_find_first(dev->mdiobus);\n\tif (!phydev) {\n\t\tnetdev_dbg(dev->net, \"PHY Not Found!! Registering Fixed PHY\\n\");\n\t\tphydev = fixed_phy_register(PHY_POLL, &fphy_status, NULL);\n\t\tif (IS_ERR(phydev)) {\n\t\t\tnetdev_err(dev->net, \"No PHY/fixed_PHY found\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\tnetdev_dbg(dev->net, \"Registered FIXED PHY\\n\");\n\t\tdev->interface = PHY_INTERFACE_MODE_RGMII;\n\t\tret = lan78xx_write_reg(dev, MAC_RGMII_ID,\n\t\t\t\t\tMAC_RGMII_ID_TXC_DELAY_EN_);\n\t\tret = lan78xx_write_reg(dev, RGMII_TX_BYP_DLL, 0x3D00);\n\t\tret = lan78xx_read_reg(dev, HW_CFG, &buf);\n\t\tbuf |= HW_CFG_CLK125_EN_;\n\t\tbuf |= HW_CFG_REFCLK25_EN_;\n\t\tret = lan78xx_write_reg(dev, HW_CFG, buf);\n\t} else {\n\t\tif (!phydev->drv) {\n\t\t\tnetdev_err(dev->net, \"no PHY driver found\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\tdev->interface = PHY_INTERFACE_MODE_RGMII;\n\t\t/* external PHY fixup for KSZ9031RNX */\n\t\tret = phy_register_fixup_for_uid(PHY_KSZ9031RNX, 0xfffffff0,\n\t\t\t\t\t\t ksz9031rnx_fixup);\n\t\tif (ret < 0) {\n\t\t\tnetdev_err(dev->net, \"Failed to register fixup for PHY_KSZ9031RNX\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\t/* external PHY fixup for LAN8835 */\n\t\tret = phy_register_fixup_for_uid(PHY_LAN8835, 0xfffffff0,\n\t\t\t\t\t\t lan8835_fixup);\n\t\tif (ret < 0) {\n\t\t\tnetdev_err(dev->net, \"Failed to register fixup for PHY_LAN8835\\n\");\n\t\t\treturn NULL;\n\t\t}\n\t\t/* add more external PHY fixup here if needed */\n\n\t\tphydev->is_internal = false;\n\t}\n\treturn phydev;\n}\n\nstatic int lan78xx_phy_init(struct lan78xx_net *dev)\n{\n\t__ETHTOOL_DECLARE_LINK_MODE_MASK(fc) = { 0, };\n\tint ret;\n\tu32 mii_adv;\n\tstruct phy_device *phydev;\n\n\tswitch (dev->chipid) {\n\tcase ID_REV_CHIP_ID_7801_:\n\t\tphydev = lan7801_phy_init(dev);\n\t\tif (!phydev) {\n\t\t\tnetdev_err(dev->net, \"lan7801: PHY Init Failed\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tbreak;\n\n\tcase ID_REV_CHIP_ID_7800_:\n\tcase ID_REV_CHIP_ID_7850_:\n\t\tphydev = phy_find_first(dev->mdiobus);\n\t\tif (!phydev) {\n\t\t\tnetdev_err(dev->net, \"no PHY found\\n\");\n\t\t\treturn -EIO;\n\t\t}\n\t\tphydev->is_internal = true;\n\t\tdev->interface = PHY_INTERFACE_MODE_GMII;\n\t\tbreak;\n\n\tdefault:\n\t\tnetdev_err(dev->net, \"Unknown CHIP ID found\\n\");\n\t\treturn -EIO;\n\t}\n\n\t/* if phyirq is not set, use polling mode in phylib */\n\tif (dev->domain_data.phyirq > 0)\n\t\tphydev->irq = dev->domain_data.phyirq;\n\telse\n\t\tphydev->irq = PHY_POLL;\n\tnetdev_dbg(dev->net, \"phydev->irq = %d\\n\", phydev->irq);\n\n\t/* set to AUTOMDIX */\n\tphydev->mdix = ETH_TP_MDI_AUTO;\n\n\tret = phy_connect_direct(dev->net, phydev,\n\t\t\t\t lan78xx_link_status_change,\n\t\t\t\t dev->interface);\n\tif (ret) {\n\t\tnetdev_err(dev->net, \"can't attach PHY to %s\\n\",\n\t\t\t   dev->mdiobus->id);\n\t\tif (dev->chipid == ID_REV_CHIP_ID_7801_) {\n\t\t\tif (phy_is_pseudo_fixed_link(phydev)) {\n\t\t\t\tfixed_phy_unregister(phydev);\n\t\t\t} else {\n\t\t\t\tphy_unregister_fixup_for_uid(PHY_KSZ9031RNX,\n\t\t\t\t\t\t\t     0xfffffff0);\n\t\t\t\tphy_unregister_fixup_for_uid(PHY_LAN8835,\n\t\t\t\t\t\t\t     0xfffffff0);\n\t\t\t}\n\t\t}\n\t\treturn -EIO;\n\t}\n\n\t/* MAC doesn't support 1000T Half */\n\tphy_remove_link_mode(phydev, ETHTOOL_LINK_MODE_1000baseT_Half_BIT);\n\n\t/* support both flow controls */\n\tdev->fc_request_control = (FLOW_CTRL_RX | FLOW_CTRL_TX);\n\tlinkmode_clear_bit(ETHTOOL_LINK_MODE_Pause_BIT,\n\t\t\t   phydev->advertising);\n\tlinkmode_clear_bit(ETHTOOL_LINK_MODE_Asym_Pause_BIT,\n\t\t\t   phydev->advertising);\n\tmii_adv = (u32)mii_advertise_flowctrl(dev->fc_request_control);\n\tmii_adv_to_linkmode_adv_t(fc, mii_adv);\n\tlinkmode_or(phydev->advertising, fc, phydev->advertising);\n\n\tif (phydev->mdio.dev.of_node) {\n\t\tu32 reg;\n\t\tint len;\n\n\t\tlen = of_property_count_elems_of_size(phydev->mdio.dev.of_node,\n\t\t\t\t\t\t      \"microchip,led-modes\",\n\t\t\t\t\t\t      sizeof(u32));\n\t\tif (len >= 0) {\n\t\t\t/* Ensure the appropriate LEDs are enabled */\n\t\t\tlan78xx_read_reg(dev, HW_CFG, &reg);\n\t\t\treg &= ~(HW_CFG_LED0_EN_ |\n\t\t\t\t HW_CFG_LED1_EN_ |\n\t\t\t\t HW_CFG_LED2_EN_ |\n\t\t\t\t HW_CFG_LED3_EN_);\n\t\t\treg |= (len > 0) * HW_CFG_LED0_EN_ |\n\t\t\t\t(len > 1) * HW_CFG_LED1_EN_ |\n\t\t\t\t(len > 2) * HW_CFG_LED2_EN_ |\n\t\t\t\t(len > 3) * HW_CFG_LED3_EN_;\n\t\t\tlan78xx_write_reg(dev, HW_CFG, reg);\n\t\t}\n\t}\n\n\tgenphy_config_aneg(phydev);\n\n\tdev->fc_autoneg = phydev->autoneg;\n\n\treturn 0;\n}\n\nstatic int lan78xx_set_rx_max_frame_length(struct lan78xx_net *dev, int size)\n{\n\tu32 buf;\n\tbool rxenabled;\n\n\tlan78xx_read_reg(dev, MAC_RX, &buf);\n\n\trxenabled = ((buf & MAC_RX_RXEN_) != 0);\n\n\tif (rxenabled) {\n\t\tbuf &= ~MAC_RX_RXEN_;\n\t\tlan78xx_write_reg(dev, MAC_RX, buf);\n\t}\n\n\t/* add 4 to size for FCS */\n\tbuf &= ~MAC_RX_MAX_SIZE_MASK_;\n\tbuf |= (((size + 4) << MAC_RX_MAX_SIZE_SHIFT_) & MAC_RX_MAX_SIZE_MASK_);\n\n\tlan78xx_write_reg(dev, MAC_RX, buf);\n\n\tif (rxenabled) {\n\t\tbuf |= MAC_RX_RXEN_;\n\t\tlan78xx_write_reg(dev, MAC_RX, buf);\n\t}\n\n\treturn 0;\n}\n\nstatic int unlink_urbs(struct lan78xx_net *dev, struct sk_buff_head *q)\n{\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\tint count = 0;\n\n\tspin_lock_irqsave(&q->lock, flags);\n\twhile (!skb_queue_empty(q)) {\n\t\tstruct skb_data\t*entry;\n\t\tstruct urb *urb;\n\t\tint ret;\n\n\t\tskb_queue_walk(q, skb) {\n\t\t\tentry = (struct skb_data *)skb->cb;\n\t\t\tif (entry->state != unlink_start)\n\t\t\t\tgoto found;\n\t\t}\n\t\tbreak;\nfound:\n\t\tentry->state = unlink_start;\n\t\turb = entry->urb;\n\n\t\t/* Get reference count of the URB to avoid it to be\n\t\t * freed during usb_unlink_urb, which may trigger\n\t\t * use-after-free problem inside usb_unlink_urb since\n\t\t * usb_unlink_urb is always racing with .complete\n\t\t * handler(include defer_bh).\n\t\t */\n\t\tusb_get_urb(urb);\n\t\tspin_unlock_irqrestore(&q->lock, flags);\n\t\t/* during some PM-driven resume scenarios,\n\t\t * these (async) unlinks complete immediately\n\t\t */\n\t\tret = usb_unlink_urb(urb);\n\t\tif (ret != -EINPROGRESS && ret != 0)\n\t\t\tnetdev_dbg(dev->net, \"unlink urb err, %d\\n\", ret);\n\t\telse\n\t\t\tcount++;\n\t\tusb_put_urb(urb);\n\t\tspin_lock_irqsave(&q->lock, flags);\n\t}\n\tspin_unlock_irqrestore(&q->lock, flags);\n\treturn count;\n}\n\nstatic int lan78xx_change_mtu(struct net_device *netdev, int new_mtu)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tint max_frame_len = RX_MAX_FRAME_LEN(new_mtu);\n\tint ret;\n\n\t/* no second zero-length packet read wanted after mtu-sized packets */\n\tif ((max_frame_len % dev->maxpacket) == 0)\n\t\treturn -EDOM;\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_set_rx_max_frame_length(dev, max_frame_len);\n\tif (!ret)\n\t\tnetdev->mtu = new_mtu;\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic int lan78xx_set_mac_addr(struct net_device *netdev, void *p)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct sockaddr *addr = p;\n\tu32 addr_lo, addr_hi;\n\n\tif (netif_running(netdev))\n\t\treturn -EBUSY;\n\n\tif (!is_valid_ether_addr(addr->sa_data))\n\t\treturn -EADDRNOTAVAIL;\n\n\teth_hw_addr_set(netdev, addr->sa_data);\n\n\taddr_lo = netdev->dev_addr[0] |\n\t\t  netdev->dev_addr[1] << 8 |\n\t\t  netdev->dev_addr[2] << 16 |\n\t\t  netdev->dev_addr[3] << 24;\n\taddr_hi = netdev->dev_addr[4] |\n\t\t  netdev->dev_addr[5] << 8;\n\n\tlan78xx_write_reg(dev, RX_ADDRL, addr_lo);\n\tlan78xx_write_reg(dev, RX_ADDRH, addr_hi);\n\n\t/* Added to support MAC address changes */\n\tlan78xx_write_reg(dev, MAF_LO(0), addr_lo);\n\tlan78xx_write_reg(dev, MAF_HI(0), addr_hi | MAF_HI_VALID_);\n\n\treturn 0;\n}\n\n/* Enable or disable Rx checksum offload engine */\nstatic int lan78xx_set_features(struct net_device *netdev,\n\t\t\t\tnetdev_features_t features)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&pdata->rfe_ctl_lock, flags);\n\n\tif (features & NETIF_F_RXCSUM) {\n\t\tpdata->rfe_ctl |= RFE_CTL_TCPUDP_COE_ | RFE_CTL_IP_COE_;\n\t\tpdata->rfe_ctl |= RFE_CTL_ICMP_COE_ | RFE_CTL_IGMP_COE_;\n\t} else {\n\t\tpdata->rfe_ctl &= ~(RFE_CTL_TCPUDP_COE_ | RFE_CTL_IP_COE_);\n\t\tpdata->rfe_ctl &= ~(RFE_CTL_ICMP_COE_ | RFE_CTL_IGMP_COE_);\n\t}\n\n\tif (features & NETIF_F_HW_VLAN_CTAG_RX)\n\t\tpdata->rfe_ctl |= RFE_CTL_VLAN_STRIP_;\n\telse\n\t\tpdata->rfe_ctl &= ~RFE_CTL_VLAN_STRIP_;\n\n\tif (features & NETIF_F_HW_VLAN_CTAG_FILTER)\n\t\tpdata->rfe_ctl |= RFE_CTL_VLAN_FILTER_;\n\telse\n\t\tpdata->rfe_ctl &= ~RFE_CTL_VLAN_FILTER_;\n\n\tspin_unlock_irqrestore(&pdata->rfe_ctl_lock, flags);\n\n\tlan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\n\n\treturn 0;\n}\n\nstatic void lan78xx_deferred_vlan_write(struct work_struct *param)\n{\n\tstruct lan78xx_priv *pdata =\n\t\t\tcontainer_of(param, struct lan78xx_priv, set_vlan);\n\tstruct lan78xx_net *dev = pdata->dev;\n\n\tlan78xx_dataport_write(dev, DP_SEL_RSEL_VLAN_DA_, 0,\n\t\t\t       DP_SEL_VHF_VLAN_LEN, pdata->vlan_table);\n}\n\nstatic int lan78xx_vlan_rx_add_vid(struct net_device *netdev,\n\t\t\t\t   __be16 proto, u16 vid)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tu16 vid_bit_index;\n\tu16 vid_dword_index;\n\n\tvid_dword_index = (vid >> 5) & 0x7F;\n\tvid_bit_index = vid & 0x1F;\n\n\tpdata->vlan_table[vid_dword_index] |= (1 << vid_bit_index);\n\n\t/* defer register writes to a sleepable context */\n\tschedule_work(&pdata->set_vlan);\n\n\treturn 0;\n}\n\nstatic int lan78xx_vlan_rx_kill_vid(struct net_device *netdev,\n\t\t\t\t    __be16 proto, u16 vid)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tu16 vid_bit_index;\n\tu16 vid_dword_index;\n\n\tvid_dword_index = (vid >> 5) & 0x7F;\n\tvid_bit_index = vid & 0x1F;\n\n\tpdata->vlan_table[vid_dword_index] &= ~(1 << vid_bit_index);\n\n\t/* defer register writes to a sleepable context */\n\tschedule_work(&pdata->set_vlan);\n\n\treturn 0;\n}\n\nstatic void lan78xx_init_ltm(struct lan78xx_net *dev)\n{\n\tint ret;\n\tu32 buf;\n\tu32 regs[6] = { 0 };\n\n\tret = lan78xx_read_reg(dev, USB_CFG1, &buf);\n\tif (buf & USB_CFG1_LTM_ENABLE_) {\n\t\tu8 temp[2];\n\t\t/* Get values from EEPROM first */\n\t\tif (lan78xx_read_eeprom(dev, 0x3F, 2, temp) == 0) {\n\t\t\tif (temp[0] == 24) {\n\t\t\t\tret = lan78xx_read_raw_eeprom(dev,\n\t\t\t\t\t\t\t      temp[1] * 2,\n\t\t\t\t\t\t\t      24,\n\t\t\t\t\t\t\t      (u8 *)regs);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t} else if (lan78xx_read_otp(dev, 0x3F, 2, temp) == 0) {\n\t\t\tif (temp[0] == 24) {\n\t\t\t\tret = lan78xx_read_raw_otp(dev,\n\t\t\t\t\t\t\t   temp[1] * 2,\n\t\t\t\t\t\t\t   24,\n\t\t\t\t\t\t\t   (u8 *)regs);\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n\n\tlan78xx_write_reg(dev, LTM_BELT_IDLE0, regs[0]);\n\tlan78xx_write_reg(dev, LTM_BELT_IDLE1, regs[1]);\n\tlan78xx_write_reg(dev, LTM_BELT_ACT0, regs[2]);\n\tlan78xx_write_reg(dev, LTM_BELT_ACT1, regs[3]);\n\tlan78xx_write_reg(dev, LTM_INACTIVE0, regs[4]);\n\tlan78xx_write_reg(dev, LTM_INACTIVE1, regs[5]);\n}\n\nstatic int lan78xx_urb_config_init(struct lan78xx_net *dev)\n{\n\tint result = 0;\n\n\tswitch (dev->udev->speed) {\n\tcase USB_SPEED_SUPER:\n\t\tdev->rx_urb_size = RX_SS_URB_SIZE;\n\t\tdev->tx_urb_size = TX_SS_URB_SIZE;\n\t\tdev->n_rx_urbs = RX_SS_URB_NUM;\n\t\tdev->n_tx_urbs = TX_SS_URB_NUM;\n\t\tdev->bulk_in_delay = SS_BULK_IN_DELAY;\n\t\tdev->burst_cap = SS_BURST_CAP_SIZE / SS_USB_PKT_SIZE;\n\t\tbreak;\n\tcase USB_SPEED_HIGH:\n\t\tdev->rx_urb_size = RX_HS_URB_SIZE;\n\t\tdev->tx_urb_size = TX_HS_URB_SIZE;\n\t\tdev->n_rx_urbs = RX_HS_URB_NUM;\n\t\tdev->n_tx_urbs = TX_HS_URB_NUM;\n\t\tdev->bulk_in_delay = HS_BULK_IN_DELAY;\n\t\tdev->burst_cap = HS_BURST_CAP_SIZE / HS_USB_PKT_SIZE;\n\t\tbreak;\n\tcase USB_SPEED_FULL:\n\t\tdev->rx_urb_size = RX_FS_URB_SIZE;\n\t\tdev->tx_urb_size = TX_FS_URB_SIZE;\n\t\tdev->n_rx_urbs = RX_FS_URB_NUM;\n\t\tdev->n_tx_urbs = TX_FS_URB_NUM;\n\t\tdev->bulk_in_delay = FS_BULK_IN_DELAY;\n\t\tdev->burst_cap = FS_BURST_CAP_SIZE / FS_USB_PKT_SIZE;\n\t\tbreak;\n\tdefault:\n\t\tnetdev_warn(dev->net, \"USB bus speed not supported\\n\");\n\t\tresult = -EIO;\n\t\tbreak;\n\t}\n\n\treturn result;\n}\n\nstatic int lan78xx_start_hw(struct lan78xx_net *dev, u32 reg, u32 hw_enable)\n{\n\treturn lan78xx_update_reg(dev, reg, hw_enable, hw_enable);\n}\n\nstatic int lan78xx_stop_hw(struct lan78xx_net *dev, u32 reg, u32 hw_enabled,\n\t\t\t   u32 hw_disabled)\n{\n\tunsigned long timeout;\n\tbool stopped = true;\n\tint ret;\n\tu32 buf;\n\n\t/* Stop the h/w block (if not already stopped) */\n\n\tret = lan78xx_read_reg(dev, reg, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tif (buf & hw_enabled) {\n\t\tbuf &= ~hw_enabled;\n\n\t\tret = lan78xx_write_reg(dev, reg, buf);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tstopped = false;\n\t\ttimeout = jiffies + HW_DISABLE_TIMEOUT;\n\t\tdo  {\n\t\t\tret = lan78xx_read_reg(dev, reg, &buf);\n\t\t\tif (ret < 0)\n\t\t\t\treturn ret;\n\n\t\t\tif (buf & hw_disabled)\n\t\t\t\tstopped = true;\n\t\t\telse\n\t\t\t\tmsleep(HW_DISABLE_DELAY_MS);\n\t\t} while (!stopped && !time_after(jiffies, timeout));\n\t}\n\n\tret = stopped ? 0 : -ETIME;\n\n\treturn ret;\n}\n\nstatic int lan78xx_flush_fifo(struct lan78xx_net *dev, u32 reg, u32 fifo_flush)\n{\n\treturn lan78xx_update_reg(dev, reg, fifo_flush, fifo_flush);\n}\n\nstatic int lan78xx_start_tx_path(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\tnetif_dbg(dev, drv, dev->net, \"start tx path\");\n\n\t/* Start the MAC transmitter */\n\n\tret = lan78xx_start_hw(dev, MAC_TX, MAC_TX_TXEN_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Start the Tx FIFO */\n\n\tret = lan78xx_start_hw(dev, FCT_TX_CTL, FCT_TX_CTL_EN_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int lan78xx_stop_tx_path(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\tnetif_dbg(dev, drv, dev->net, \"stop tx path\");\n\n\t/* Stop the Tx FIFO */\n\n\tret = lan78xx_stop_hw(dev, FCT_TX_CTL, FCT_TX_CTL_EN_, FCT_TX_CTL_DIS_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Stop the MAC transmitter */\n\n\tret = lan78xx_stop_hw(dev, MAC_TX, MAC_TX_TXEN_, MAC_TX_TXD_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n/* The caller must ensure the Tx path is stopped before calling\n * lan78xx_flush_tx_fifo().\n */\nstatic int lan78xx_flush_tx_fifo(struct lan78xx_net *dev)\n{\n\treturn lan78xx_flush_fifo(dev, FCT_TX_CTL, FCT_TX_CTL_RST_);\n}\n\nstatic int lan78xx_start_rx_path(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\tnetif_dbg(dev, drv, dev->net, \"start rx path\");\n\n\t/* Start the Rx FIFO */\n\n\tret = lan78xx_start_hw(dev, FCT_RX_CTL, FCT_RX_CTL_EN_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Start the MAC receiver*/\n\n\tret = lan78xx_start_hw(dev, MAC_RX, MAC_RX_RXEN_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\nstatic int lan78xx_stop_rx_path(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\tnetif_dbg(dev, drv, dev->net, \"stop rx path\");\n\n\t/* Stop the MAC receiver */\n\n\tret = lan78xx_stop_hw(dev, MAC_RX, MAC_RX_RXEN_, MAC_RX_RXD_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Stop the Rx FIFO */\n\n\tret = lan78xx_stop_hw(dev, FCT_RX_CTL, FCT_RX_CTL_EN_, FCT_RX_CTL_DIS_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn 0;\n}\n\n/* The caller must ensure the Rx path is stopped before calling\n * lan78xx_flush_rx_fifo().\n */\nstatic int lan78xx_flush_rx_fifo(struct lan78xx_net *dev)\n{\n\treturn lan78xx_flush_fifo(dev, FCT_RX_CTL, FCT_RX_CTL_RST_);\n}\n\nstatic int lan78xx_reset(struct lan78xx_net *dev)\n{\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\tunsigned long timeout;\n\tint ret;\n\tu32 buf;\n\tu8 sig;\n\n\tret = lan78xx_read_reg(dev, HW_CFG, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= HW_CFG_LRST_;\n\n\tret = lan78xx_write_reg(dev, HW_CFG, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttimeout = jiffies + HZ;\n\tdo {\n\t\tmdelay(1);\n\t\tret = lan78xx_read_reg(dev, HW_CFG, &buf);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (time_after(jiffies, timeout)) {\n\t\t\tnetdev_warn(dev->net,\n\t\t\t\t    \"timeout on completion of LiteReset\");\n\t\t\tret = -ETIMEDOUT;\n\t\t\treturn ret;\n\t\t}\n\t} while (buf & HW_CFG_LRST_);\n\n\tlan78xx_init_mac_address(dev);\n\n\t/* save DEVID for later usage */\n\tret = lan78xx_read_reg(dev, ID_REV, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tdev->chipid = (buf & ID_REV_CHIP_ID_MASK_) >> 16;\n\tdev->chiprev = buf & ID_REV_CHIP_REV_MASK_;\n\n\t/* Respond to the IN token with a NAK */\n\tret = lan78xx_read_reg(dev, USB_CFG0, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= USB_CFG_BIR_;\n\n\tret = lan78xx_write_reg(dev, USB_CFG0, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Init LTM */\n\tlan78xx_init_ltm(dev);\n\n\tret = lan78xx_write_reg(dev, BURST_CAP, dev->burst_cap);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, BULK_IN_DLY, dev->bulk_in_delay);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_read_reg(dev, HW_CFG, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= HW_CFG_MEF_;\n\n\tret = lan78xx_write_reg(dev, HW_CFG, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_read_reg(dev, USB_CFG0, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= USB_CFG_BCE_;\n\n\tret = lan78xx_write_reg(dev, USB_CFG0, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* set FIFO sizes */\n\tbuf = (MAX_RX_FIFO_SIZE - 512) / 512;\n\n\tret = lan78xx_write_reg(dev, FCT_RX_FIFO_END, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf = (MAX_TX_FIFO_SIZE - 512) / 512;\n\n\tret = lan78xx_write_reg(dev, FCT_TX_FIFO_END, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, INT_STS, INT_STS_CLEAR_ALL_);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, FLOW, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, FCT_FLOW, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Don't need rfe_ctl_lock during initialisation */\n\tret = lan78xx_read_reg(dev, RFE_CTL, &pdata->rfe_ctl);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tpdata->rfe_ctl |= RFE_CTL_BCAST_EN_ | RFE_CTL_DA_PERFECT_;\n\n\tret = lan78xx_write_reg(dev, RFE_CTL, pdata->rfe_ctl);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* Enable or disable checksum offload engines */\n\tret = lan78xx_set_features(dev->net, dev->net->features);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tlan78xx_set_multicast(dev->net);\n\n\t/* reset PHY */\n\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= PMT_CTL_PHY_RST_;\n\n\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttimeout = jiffies + HZ;\n\tdo {\n\t\tmdelay(1);\n\t\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tif (time_after(jiffies, timeout)) {\n\t\t\tnetdev_warn(dev->net, \"timeout waiting for PHY Reset\");\n\t\t\tret = -ETIMEDOUT;\n\t\t\treturn ret;\n\t\t}\n\t} while ((buf & PMT_CTL_PHY_RST_) || !(buf & PMT_CTL_READY_));\n\n\tret = lan78xx_read_reg(dev, MAC_CR, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* LAN7801 only has RGMII mode */\n\tif (dev->chipid == ID_REV_CHIP_ID_7801_)\n\t\tbuf &= ~MAC_CR_GMII_EN_;\n\n\tif (dev->chipid == ID_REV_CHIP_ID_7800_) {\n\t\tret = lan78xx_read_raw_eeprom(dev, 0, 1, &sig);\n\t\tif (!ret && sig != EEPROM_INDICATOR) {\n\t\t\t/* Implies there is no external eeprom. Set mac speed */\n\t\t\tnetdev_info(dev->net, \"No External EEPROM. Setting MAC Speed\\n\");\n\t\t\tbuf |= MAC_CR_AUTO_DUPLEX_ | MAC_CR_AUTO_SPEED_;\n\t\t}\n\t}\n\tret = lan78xx_write_reg(dev, MAC_CR, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_set_rx_max_frame_length(dev,\n\t\t\t\t\t      RX_MAX_FRAME_LEN(dev->net->mtu));\n\n\treturn ret;\n}\n\nstatic void lan78xx_init_stats(struct lan78xx_net *dev)\n{\n\tu32 *p;\n\tint i;\n\n\t/* initialize for stats update\n\t * some counters are 20bits and some are 32bits\n\t */\n\tp = (u32 *)&dev->stats.rollover_max;\n\tfor (i = 0; i < (sizeof(dev->stats.rollover_max) / (sizeof(u32))); i++)\n\t\tp[i] = 0xFFFFF;\n\n\tdev->stats.rollover_max.rx_unicast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.rx_broadcast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.rx_multicast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.eee_rx_lpi_transitions = 0xFFFFFFFF;\n\tdev->stats.rollover_max.eee_rx_lpi_time = 0xFFFFFFFF;\n\tdev->stats.rollover_max.tx_unicast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.tx_broadcast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.tx_multicast_byte_count = 0xFFFFFFFF;\n\tdev->stats.rollover_max.eee_tx_lpi_transitions = 0xFFFFFFFF;\n\tdev->stats.rollover_max.eee_tx_lpi_time = 0xFFFFFFFF;\n\n\tset_bit(EVENT_STAT_UPDATE, &dev->flags);\n}\n\nstatic int lan78xx_open(struct net_device *net)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tint ret;\n\n\tnetif_dbg(dev, ifup, dev->net, \"open device\");\n\n\tret = usb_autopm_get_interface(dev->intf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tmutex_lock(&dev->dev_mutex);\n\n\tphy_start(net->phydev);\n\n\tnetif_dbg(dev, ifup, dev->net, \"phy initialised successfully\");\n\n\t/* for Link Check */\n\tif (dev->urb_intr) {\n\t\tret = usb_submit_urb(dev->urb_intr, GFP_KERNEL);\n\t\tif (ret < 0) {\n\t\t\tnetif_err(dev, ifup, dev->net,\n\t\t\t\t  \"intr submit %d\\n\", ret);\n\t\t\tgoto done;\n\t\t}\n\t}\n\n\tret = lan78xx_flush_rx_fifo(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\tret = lan78xx_flush_tx_fifo(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tret = lan78xx_start_tx_path(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\tret = lan78xx_start_rx_path(dev);\n\tif (ret < 0)\n\t\tgoto done;\n\n\tlan78xx_init_stats(dev);\n\n\tset_bit(EVENT_DEV_OPEN, &dev->flags);\n\n\tnetif_start_queue(net);\n\n\tdev->link_on = false;\n\n\tnapi_enable(&dev->napi);\n\n\tlan78xx_defer_kevent(dev, EVENT_LINK_RESET);\ndone:\n\tmutex_unlock(&dev->dev_mutex);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\treturn ret;\n}\n\nstatic void lan78xx_terminate_urbs(struct lan78xx_net *dev)\n{\n\tDECLARE_WAIT_QUEUE_HEAD_ONSTACK(unlink_wakeup);\n\tDECLARE_WAITQUEUE(wait, current);\n\tint temp;\n\n\t/* ensure there are no more active urbs */\n\tadd_wait_queue(&unlink_wakeup, &wait);\n\tset_current_state(TASK_UNINTERRUPTIBLE);\n\tdev->wait = &unlink_wakeup;\n\ttemp = unlink_urbs(dev, &dev->txq) + unlink_urbs(dev, &dev->rxq);\n\n\t/* maybe wait for deletions to finish. */\n\twhile (!skb_queue_empty(&dev->rxq) ||\n\t       !skb_queue_empty(&dev->txq)) {\n\t\tschedule_timeout(msecs_to_jiffies(UNLINK_TIMEOUT_MS));\n\t\tset_current_state(TASK_UNINTERRUPTIBLE);\n\t\tnetif_dbg(dev, ifdown, dev->net,\n\t\t\t  \"waited for %d urb completions\", temp);\n\t}\n\tset_current_state(TASK_RUNNING);\n\tdev->wait = NULL;\n\tremove_wait_queue(&unlink_wakeup, &wait);\n\n\t/* empty Rx done, Rx overflow and Tx pend queues\n\t */\n\twhile (!skb_queue_empty(&dev->rxq_done)) {\n\t\tstruct sk_buff *skb = skb_dequeue(&dev->rxq_done);\n\n\t\tlan78xx_release_rx_buf(dev, skb);\n\t}\n\n\tskb_queue_purge(&dev->rxq_overflow);\n\tskb_queue_purge(&dev->txq_pend);\n}\n\nstatic int lan78xx_stop(struct net_device *net)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\tnetif_dbg(dev, ifup, dev->net, \"stop device\");\n\n\tmutex_lock(&dev->dev_mutex);\n\n\tif (timer_pending(&dev->stat_monitor))\n\t\tdel_timer_sync(&dev->stat_monitor);\n\n\tclear_bit(EVENT_DEV_OPEN, &dev->flags);\n\tnetif_stop_queue(net);\n\tnapi_disable(&dev->napi);\n\n\tlan78xx_terminate_urbs(dev);\n\n\tnetif_info(dev, ifdown, dev->net,\n\t\t   \"stop stats: rx/tx %lu/%lu, errs %lu/%lu\\n\",\n\t\t   net->stats.rx_packets, net->stats.tx_packets,\n\t\t   net->stats.rx_errors, net->stats.tx_errors);\n\n\t/* ignore errors that occur stopping the Tx and Rx data paths */\n\tlan78xx_stop_tx_path(dev);\n\tlan78xx_stop_rx_path(dev);\n\n\tif (net->phydev)\n\t\tphy_stop(net->phydev);\n\n\tusb_kill_urb(dev->urb_intr);\n\n\t/* deferred work (task, timer, softirq) must also stop.\n\t * can't flush_scheduled_work() until we drop rtnl (later),\n\t * else workers could deadlock; so make workers a NOP.\n\t */\n\tclear_bit(EVENT_TX_HALT, &dev->flags);\n\tclear_bit(EVENT_RX_HALT, &dev->flags);\n\tclear_bit(EVENT_LINK_RESET, &dev->flags);\n\tclear_bit(EVENT_STAT_UPDATE, &dev->flags);\n\n\tcancel_delayed_work_sync(&dev->wq);\n\n\tusb_autopm_put_interface(dev->intf);\n\n\tmutex_unlock(&dev->dev_mutex);\n\n\treturn 0;\n}\n\nstatic enum skb_state defer_bh(struct lan78xx_net *dev, struct sk_buff *skb,\n\t\t\t       struct sk_buff_head *list, enum skb_state state)\n{\n\tunsigned long flags;\n\tenum skb_state old_state;\n\tstruct skb_data *entry = (struct skb_data *)skb->cb;\n\n\tspin_lock_irqsave(&list->lock, flags);\n\told_state = entry->state;\n\tentry->state = state;\n\n\t__skb_unlink(skb, list);\n\tspin_unlock(&list->lock);\n\tspin_lock(&dev->rxq_done.lock);\n\n\t__skb_queue_tail(&dev->rxq_done, skb);\n\tif (skb_queue_len(&dev->rxq_done) == 1)\n\t\tnapi_schedule(&dev->napi);\n\n\tspin_unlock_irqrestore(&dev->rxq_done.lock, flags);\n\n\treturn old_state;\n}\n\nstatic void tx_complete(struct urb *urb)\n{\n\tstruct sk_buff *skb = (struct sk_buff *)urb->context;\n\tstruct skb_data *entry = (struct skb_data *)skb->cb;\n\tstruct lan78xx_net *dev = entry->dev;\n\n\tif (urb->status == 0) {\n\t\tdev->net->stats.tx_packets += entry->num_of_packet;\n\t\tdev->net->stats.tx_bytes += entry->length;\n\t} else {\n\t\tdev->net->stats.tx_errors += entry->num_of_packet;\n\n\t\tswitch (urb->status) {\n\t\tcase -EPIPE:\n\t\t\tlan78xx_defer_kevent(dev, EVENT_TX_HALT);\n\t\t\tbreak;\n\n\t\t/* software-driven interface shutdown */\n\t\tcase -ECONNRESET:\n\t\tcase -ESHUTDOWN:\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"tx err interface gone %d\\n\",\n\t\t\t\t  entry->urb->status);\n\t\t\tbreak;\n\n\t\tcase -EPROTO:\n\t\tcase -ETIME:\n\t\tcase -EILSEQ:\n\t\t\tnetif_stop_queue(dev->net);\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"tx err queue stopped %d\\n\",\n\t\t\t\t  entry->urb->status);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"unknown tx err %d\\n\",\n\t\t\t\t  entry->urb->status);\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tusb_autopm_put_interface_async(dev->intf);\n\n\tskb_unlink(skb, &dev->txq);\n\n\tlan78xx_release_tx_buf(dev, skb);\n\n\t/* Re-schedule NAPI if Tx data pending but no URBs in progress.\n\t */\n\tif (skb_queue_empty(&dev->txq) &&\n\t    !skb_queue_empty(&dev->txq_pend))\n\t\tnapi_schedule(&dev->napi);\n}\n\nstatic void lan78xx_queue_skb(struct sk_buff_head *list,\n\t\t\t      struct sk_buff *newsk, enum skb_state state)\n{\n\tstruct skb_data *entry = (struct skb_data *)newsk->cb;\n\n\t__skb_queue_tail(list, newsk);\n\tentry->state = state;\n}\n\nstatic unsigned int lan78xx_tx_urb_space(struct lan78xx_net *dev)\n{\n\treturn skb_queue_len(&dev->txq_free) * dev->tx_urb_size;\n}\n\nstatic unsigned int lan78xx_tx_pend_data_len(struct lan78xx_net *dev)\n{\n\treturn dev->tx_pend_data_len;\n}\n\nstatic void lan78xx_tx_pend_skb_add(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff *skb,\n\t\t\t\t    unsigned int *tx_pend_data_len)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->txq_pend.lock, flags);\n\n\t__skb_queue_tail(&dev->txq_pend, skb);\n\n\tdev->tx_pend_data_len += skb->len;\n\t*tx_pend_data_len = dev->tx_pend_data_len;\n\n\tspin_unlock_irqrestore(&dev->txq_pend.lock, flags);\n}\n\nstatic void lan78xx_tx_pend_skb_head_add(struct lan78xx_net *dev,\n\t\t\t\t\t struct sk_buff *skb,\n\t\t\t\t\t unsigned int *tx_pend_data_len)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->txq_pend.lock, flags);\n\n\t__skb_queue_head(&dev->txq_pend, skb);\n\n\tdev->tx_pend_data_len += skb->len;\n\t*tx_pend_data_len = dev->tx_pend_data_len;\n\n\tspin_unlock_irqrestore(&dev->txq_pend.lock, flags);\n}\n\nstatic void lan78xx_tx_pend_skb_get(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff **skb,\n\t\t\t\t    unsigned int *tx_pend_data_len)\n{\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&dev->txq_pend.lock, flags);\n\n\t*skb = __skb_dequeue(&dev->txq_pend);\n\tif (*skb)\n\t\tdev->tx_pend_data_len -= (*skb)->len;\n\t*tx_pend_data_len = dev->tx_pend_data_len;\n\n\tspin_unlock_irqrestore(&dev->txq_pend.lock, flags);\n}\n\nstatic netdev_tx_t\nlan78xx_start_xmit(struct sk_buff *skb, struct net_device *net)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\tunsigned int tx_pend_data_len;\n\n\tif (test_bit(EVENT_DEV_ASLEEP, &dev->flags))\n\t\tschedule_delayed_work(&dev->wq, 0);\n\n\tskb_tx_timestamp(skb);\n\n\tlan78xx_tx_pend_skb_add(dev, skb, &tx_pend_data_len);\n\n\t/* Set up a Tx URB if none is in progress */\n\n\tif (skb_queue_empty(&dev->txq))\n\t\tnapi_schedule(&dev->napi);\n\n\t/* Stop stack Tx queue if we have enough data to fill\n\t * all the free Tx URBs.\n\t */\n\tif (tx_pend_data_len > lan78xx_tx_urb_space(dev)) {\n\t\tnetif_stop_queue(net);\n\n\t\tnetif_dbg(dev, hw, dev->net, \"tx data len: %u, urb space %u\",\n\t\t\t  tx_pend_data_len, lan78xx_tx_urb_space(dev));\n\n\t\t/* Kick off transmission of pending data */\n\n\t\tif (!skb_queue_empty(&dev->txq_free))\n\t\t\tnapi_schedule(&dev->napi);\n\t}\n\n\treturn NETDEV_TX_OK;\n}\n\nstatic int lan78xx_bind(struct lan78xx_net *dev, struct usb_interface *intf)\n{\n\tstruct lan78xx_priv *pdata = NULL;\n\tint ret;\n\tint i;\n\n\tdev->data[0] = (unsigned long)kzalloc(sizeof(*pdata), GFP_KERNEL);\n\n\tpdata = (struct lan78xx_priv *)(dev->data[0]);\n\tif (!pdata) {\n\t\tnetdev_warn(dev->net, \"Unable to allocate lan78xx_priv\");\n\t\treturn -ENOMEM;\n\t}\n\n\tpdata->dev = dev;\n\n\tspin_lock_init(&pdata->rfe_ctl_lock);\n\tmutex_init(&pdata->dataport_mutex);\n\n\tINIT_WORK(&pdata->set_multicast, lan78xx_deferred_multicast_write);\n\n\tfor (i = 0; i < DP_SEL_VHF_VLAN_LEN; i++)\n\t\tpdata->vlan_table[i] = 0;\n\n\tINIT_WORK(&pdata->set_vlan, lan78xx_deferred_vlan_write);\n\n\tdev->net->features = 0;\n\n\tif (DEFAULT_TX_CSUM_ENABLE)\n\t\tdev->net->features |= NETIF_F_HW_CSUM;\n\n\tif (DEFAULT_RX_CSUM_ENABLE)\n\t\tdev->net->features |= NETIF_F_RXCSUM;\n\n\tif (DEFAULT_TSO_CSUM_ENABLE)\n\t\tdev->net->features |= NETIF_F_TSO | NETIF_F_TSO6 | NETIF_F_SG;\n\n\tif (DEFAULT_VLAN_RX_OFFLOAD)\n\t\tdev->net->features |= NETIF_F_HW_VLAN_CTAG_RX;\n\n\tif (DEFAULT_VLAN_FILTER_ENABLE)\n\t\tdev->net->features |= NETIF_F_HW_VLAN_CTAG_FILTER;\n\n\tdev->net->hw_features = dev->net->features;\n\n\tret = lan78xx_setup_irq_domain(dev);\n\tif (ret < 0) {\n\t\tnetdev_warn(dev->net,\n\t\t\t    \"lan78xx_setup_irq_domain() failed : %d\", ret);\n\t\tgoto out1;\n\t}\n\n\t/* Init all registers */\n\tret = lan78xx_reset(dev);\n\tif (ret) {\n\t\tnetdev_warn(dev->net, \"Registers INIT FAILED....\");\n\t\tgoto out2;\n\t}\n\n\tret = lan78xx_mdio_init(dev);\n\tif (ret) {\n\t\tnetdev_warn(dev->net, \"MDIO INIT FAILED.....\");\n\t\tgoto out2;\n\t}\n\n\tdev->net->flags |= IFF_MULTICAST;\n\n\tpdata->wol = WAKE_MAGIC;\n\n\treturn ret;\n\nout2:\n\tlan78xx_remove_irq_domain(dev);\n\nout1:\n\tnetdev_warn(dev->net, \"Bind routine FAILED\");\n\tcancel_work_sync(&pdata->set_multicast);\n\tcancel_work_sync(&pdata->set_vlan);\n\tkfree(pdata);\n\treturn ret;\n}\n\nstatic void lan78xx_unbind(struct lan78xx_net *dev, struct usb_interface *intf)\n{\n\tstruct lan78xx_priv *pdata = (struct lan78xx_priv *)(dev->data[0]);\n\n\tlan78xx_remove_irq_domain(dev);\n\n\tlan78xx_remove_mdio(dev);\n\n\tif (pdata) {\n\t\tcancel_work_sync(&pdata->set_multicast);\n\t\tcancel_work_sync(&pdata->set_vlan);\n\t\tnetif_dbg(dev, ifdown, dev->net, \"free pdata\");\n\t\tkfree(pdata);\n\t\tpdata = NULL;\n\t\tdev->data[0] = 0;\n\t}\n}\n\nstatic void lan78xx_rx_csum_offload(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff *skb,\n\t\t\t\t    u32 rx_cmd_a, u32 rx_cmd_b)\n{\n\t/* HW Checksum offload appears to be flawed if used when not stripping\n\t * VLAN headers. Drop back to S/W checksums under these conditions.\n\t */\n\tif (!(dev->net->features & NETIF_F_RXCSUM) ||\n\t    unlikely(rx_cmd_a & RX_CMD_A_ICSM_) ||\n\t    ((rx_cmd_a & RX_CMD_A_FVTG_) &&\n\t     !(dev->net->features & NETIF_F_HW_VLAN_CTAG_RX))) {\n\t\tskb->ip_summed = CHECKSUM_NONE;\n\t} else {\n\t\tskb->csum = ntohs((u16)(rx_cmd_b >> RX_CMD_B_CSUM_SHIFT_));\n\t\tskb->ip_summed = CHECKSUM_COMPLETE;\n\t}\n}\n\nstatic void lan78xx_rx_vlan_offload(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff *skb,\n\t\t\t\t    u32 rx_cmd_a, u32 rx_cmd_b)\n{\n\tif ((dev->net->features & NETIF_F_HW_VLAN_CTAG_RX) &&\n\t    (rx_cmd_a & RX_CMD_A_FVTG_))\n\t\t__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q),\n\t\t\t\t       (rx_cmd_b & 0xffff));\n}\n\nstatic void lan78xx_skb_return(struct lan78xx_net *dev, struct sk_buff *skb)\n{\n\tdev->net->stats.rx_packets++;\n\tdev->net->stats.rx_bytes += skb->len;\n\n\tskb->protocol = eth_type_trans(skb, dev->net);\n\n\tnetif_dbg(dev, rx_status, dev->net, \"< rx, len %zu, type 0x%x\\n\",\n\t\t  skb->len + sizeof(struct ethhdr), skb->protocol);\n\tmemset(skb->cb, 0, sizeof(struct skb_data));\n\n\tif (skb_defer_rx_timestamp(skb))\n\t\treturn;\n\n\tnapi_gro_receive(&dev->napi, skb);\n}\n\nstatic int lan78xx_rx(struct lan78xx_net *dev, struct sk_buff *skb,\n\t\t      int budget, int *work_done)\n{\n\tif (skb->len < RX_SKB_MIN_LEN)\n\t\treturn 0;\n\n\t/* Extract frames from the URB buffer and pass each one to\n\t * the stack in a new NAPI SKB.\n\t */\n\twhile (skb->len > 0) {\n\t\tu32 rx_cmd_a, rx_cmd_b, align_count, size;\n\t\tu16 rx_cmd_c;\n\t\tunsigned char *packet;\n\n\t\trx_cmd_a = get_unaligned_le32(skb->data);\n\t\tskb_pull(skb, sizeof(rx_cmd_a));\n\n\t\trx_cmd_b = get_unaligned_le32(skb->data);\n\t\tskb_pull(skb, sizeof(rx_cmd_b));\n\n\t\trx_cmd_c = get_unaligned_le16(skb->data);\n\t\tskb_pull(skb, sizeof(rx_cmd_c));\n\n\t\tpacket = skb->data;\n\n\t\t/* get the packet length */\n\t\tsize = (rx_cmd_a & RX_CMD_A_LEN_MASK_);\n\t\talign_count = (4 - ((size + RXW_PADDING) % 4)) % 4;\n\n\t\tif (unlikely(size > skb->len)) {\n\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t  \"size err rx_cmd_a=0x%08x\\n\",\n\t\t\t\t  rx_cmd_a);\n\t\t\treturn 0;\n\t\t}\n\n\t\tif (unlikely(rx_cmd_a & RX_CMD_A_RED_)) {\n\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t  \"Error rx_cmd_a=0x%08x\", rx_cmd_a);\n\t\t} else {\n\t\t\tu32 frame_len;\n\t\t\tstruct sk_buff *skb2;\n\n\t\t\tif (unlikely(size < ETH_FCS_LEN)) {\n\t\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t\t  \"size err rx_cmd_a=0x%08x\\n\",\n\t\t\t\t\t  rx_cmd_a);\n\t\t\t\treturn 0;\n\t\t\t}\n\n\t\t\tframe_len = size - ETH_FCS_LEN;\n\n\t\t\tskb2 = napi_alloc_skb(&dev->napi, frame_len);\n\t\t\tif (!skb2)\n\t\t\t\treturn 0;\n\n\t\t\tmemcpy(skb2->data, packet, frame_len);\n\n\t\t\tskb_put(skb2, frame_len);\n\n\t\t\tlan78xx_rx_csum_offload(dev, skb2, rx_cmd_a, rx_cmd_b);\n\t\t\tlan78xx_rx_vlan_offload(dev, skb2, rx_cmd_a, rx_cmd_b);\n\n\t\t\t/* Processing of the URB buffer must complete once\n\t\t\t * it has started. If the NAPI work budget is exhausted\n\t\t\t * while frames remain they are added to the overflow\n\t\t\t * queue for delivery in the next NAPI polling cycle.\n\t\t\t */\n\t\t\tif (*work_done < budget) {\n\t\t\t\tlan78xx_skb_return(dev, skb2);\n\t\t\t\t++(*work_done);\n\t\t\t} else {\n\t\t\t\tskb_queue_tail(&dev->rxq_overflow, skb2);\n\t\t\t}\n\t\t}\n\n\t\tskb_pull(skb, size);\n\n\t\t/* skip padding bytes before the next frame starts */\n\t\tif (skb->len)\n\t\t\tskb_pull(skb, align_count);\n\t}\n\n\treturn 1;\n}\n\nstatic inline void rx_process(struct lan78xx_net *dev, struct sk_buff *skb,\n\t\t\t      int budget, int *work_done)\n{\n\tif (!lan78xx_rx(dev, skb, budget, work_done)) {\n\t\tnetif_dbg(dev, rx_err, dev->net, \"drop\\n\");\n\t\tdev->net->stats.rx_errors++;\n\t}\n}\n\nstatic void rx_complete(struct urb *urb)\n{\n\tstruct sk_buff\t*skb = (struct sk_buff *)urb->context;\n\tstruct skb_data\t*entry = (struct skb_data *)skb->cb;\n\tstruct lan78xx_net *dev = entry->dev;\n\tint urb_status = urb->status;\n\tenum skb_state state;\n\n\tnetif_dbg(dev, rx_status, dev->net,\n\t\t  \"rx done: status %d\", urb->status);\n\n\tskb_put(skb, urb->actual_length);\n\tstate = rx_done;\n\n\tif (urb != entry->urb)\n\t\tnetif_warn(dev, rx_err, dev->net, \"URB pointer mismatch\");\n\n\tswitch (urb_status) {\n\tcase 0:\n\t\tif (skb->len < RX_SKB_MIN_LEN) {\n\t\t\tstate = rx_cleanup;\n\t\t\tdev->net->stats.rx_errors++;\n\t\t\tdev->net->stats.rx_length_errors++;\n\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t  \"rx length %d\\n\", skb->len);\n\t\t}\n\t\tusb_mark_last_busy(dev->udev);\n\t\tbreak;\n\tcase -EPIPE:\n\t\tdev->net->stats.rx_errors++;\n\t\tlan78xx_defer_kevent(dev, EVENT_RX_HALT);\n\t\tfallthrough;\n\tcase -ECONNRESET:\t\t\t\t/* async unlink */\n\tcase -ESHUTDOWN:\t\t\t\t/* hardware gone */\n\t\tnetif_dbg(dev, ifdown, dev->net,\n\t\t\t  \"rx shutdown, code %d\\n\", urb_status);\n\t\tstate = rx_cleanup;\n\t\tbreak;\n\tcase -EPROTO:\n\tcase -ETIME:\n\tcase -EILSEQ:\n\t\tdev->net->stats.rx_errors++;\n\t\tstate = rx_cleanup;\n\t\tbreak;\n\n\t/* data overrun ... flush fifo? */\n\tcase -EOVERFLOW:\n\t\tdev->net->stats.rx_over_errors++;\n\t\tfallthrough;\n\n\tdefault:\n\t\tstate = rx_cleanup;\n\t\tdev->net->stats.rx_errors++;\n\t\tnetif_dbg(dev, rx_err, dev->net, \"rx status %d\\n\", urb_status);\n\t\tbreak;\n\t}\n\n\tstate = defer_bh(dev, skb, &dev->rxq, state);\n}\n\nstatic int rx_submit(struct lan78xx_net *dev, struct sk_buff *skb, gfp_t flags)\n{\n\tstruct skb_data\t*entry = (struct skb_data *)skb->cb;\n\tsize_t size = dev->rx_urb_size;\n\tstruct urb *urb = entry->urb;\n\tunsigned long lockflags;\n\tint ret = 0;\n\n\tusb_fill_bulk_urb(urb, dev->udev, dev->pipe_in,\n\t\t\t  skb->data, size, rx_complete, skb);\n\n\tspin_lock_irqsave(&dev->rxq.lock, lockflags);\n\n\tif (netif_device_present(dev->net) &&\n\t    netif_running(dev->net) &&\n\t    !test_bit(EVENT_RX_HALT, &dev->flags) &&\n\t    !test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\n\t\tret = usb_submit_urb(urb, flags);\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\tlan78xx_queue_skb(&dev->rxq, skb, rx_start);\n\t\t\tbreak;\n\t\tcase -EPIPE:\n\t\t\tlan78xx_defer_kevent(dev, EVENT_RX_HALT);\n\t\t\tbreak;\n\t\tcase -ENODEV:\n\t\tcase -ENOENT:\n\t\t\tnetif_dbg(dev, ifdown, dev->net, \"device gone\\n\");\n\t\t\tnetif_device_detach(dev->net);\n\t\t\tbreak;\n\t\tcase -EHOSTUNREACH:\n\t\t\tret = -ENOLINK;\n\t\t\tnapi_schedule(&dev->napi);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetif_dbg(dev, rx_err, dev->net,\n\t\t\t\t  \"rx submit, %d\\n\", ret);\n\t\t\tnapi_schedule(&dev->napi);\n\t\t\tbreak;\n\t\t}\n\t} else {\n\t\tnetif_dbg(dev, ifdown, dev->net, \"rx: stopped\\n\");\n\t\tret = -ENOLINK;\n\t}\n\tspin_unlock_irqrestore(&dev->rxq.lock, lockflags);\n\n\tif (ret)\n\t\tlan78xx_release_rx_buf(dev, skb);\n\n\treturn ret;\n}\n\nstatic void lan78xx_rx_urb_submit_all(struct lan78xx_net *dev)\n{\n\tstruct sk_buff *rx_buf;\n\n\t/* Ensure the maximum number of Rx URBs is submitted\n\t */\n\twhile ((rx_buf = lan78xx_get_rx_buf(dev)) != NULL) {\n\t\tif (rx_submit(dev, rx_buf, GFP_ATOMIC) != 0)\n\t\t\tbreak;\n\t}\n}\n\nstatic void lan78xx_rx_urb_resubmit(struct lan78xx_net *dev,\n\t\t\t\t    struct sk_buff *rx_buf)\n{\n\t/* reset SKB data pointers */\n\n\trx_buf->data = rx_buf->head;\n\tskb_reset_tail_pointer(rx_buf);\n\trx_buf->len = 0;\n\trx_buf->data_len = 0;\n\n\trx_submit(dev, rx_buf, GFP_ATOMIC);\n}\n\nstatic void lan78xx_fill_tx_cmd_words(struct sk_buff *skb, u8 *buffer)\n{\n\tu32 tx_cmd_a;\n\tu32 tx_cmd_b;\n\n\ttx_cmd_a = (u32)(skb->len & TX_CMD_A_LEN_MASK_) | TX_CMD_A_FCS_;\n\n\tif (skb->ip_summed == CHECKSUM_PARTIAL)\n\t\ttx_cmd_a |= TX_CMD_A_IPE_ | TX_CMD_A_TPE_;\n\n\ttx_cmd_b = 0;\n\tif (skb_is_gso(skb)) {\n\t\tu16 mss = max(skb_shinfo(skb)->gso_size, TX_CMD_B_MSS_MIN_);\n\n\t\ttx_cmd_b = (mss << TX_CMD_B_MSS_SHIFT_) & TX_CMD_B_MSS_MASK_;\n\n\t\ttx_cmd_a |= TX_CMD_A_LSO_;\n\t}\n\n\tif (skb_vlan_tag_present(skb)) {\n\t\ttx_cmd_a |= TX_CMD_A_IVTG_;\n\t\ttx_cmd_b |= skb_vlan_tag_get(skb) & TX_CMD_B_VTAG_MASK_;\n\t}\n\n\tput_unaligned_le32(tx_cmd_a, buffer);\n\tput_unaligned_le32(tx_cmd_b, buffer + 4);\n}\n\nstatic struct skb_data *lan78xx_tx_buf_fill(struct lan78xx_net *dev,\n\t\t\t\t\t    struct sk_buff *tx_buf)\n{\n\tstruct skb_data *entry = (struct skb_data *)tx_buf->cb;\n\tint remain = dev->tx_urb_size;\n\tu8 *tx_data = tx_buf->data;\n\tu32 urb_len = 0;\n\n\tentry->num_of_packet = 0;\n\tentry->length = 0;\n\n\t/* Work through the pending SKBs and copy the data of each SKB into\n\t * the URB buffer if there room for all the SKB data.\n\t *\n\t * There must be at least DST+SRC+TYPE in the SKB (with padding enabled)\n\t */\n\twhile (remain >= TX_SKB_MIN_LEN) {\n\t\tunsigned int pending_bytes;\n\t\tunsigned int align_bytes;\n\t\tstruct sk_buff *skb;\n\t\tunsigned int len;\n\n\t\tlan78xx_tx_pend_skb_get(dev, &skb, &pending_bytes);\n\n\t\tif (!skb)\n\t\t\tbreak;\n\n\t\talign_bytes = (TX_ALIGNMENT - (urb_len % TX_ALIGNMENT)) %\n\t\t\t      TX_ALIGNMENT;\n\t\tlen = align_bytes + TX_CMD_LEN + skb->len;\n\t\tif (len > remain) {\n\t\t\tlan78xx_tx_pend_skb_head_add(dev, skb, &pending_bytes);\n\t\t\tbreak;\n\t\t}\n\n\t\ttx_data += align_bytes;\n\n\t\tlan78xx_fill_tx_cmd_words(skb, tx_data);\n\t\ttx_data += TX_CMD_LEN;\n\n\t\tlen = skb->len;\n\t\tif (skb_copy_bits(skb, 0, tx_data, len) < 0) {\n\t\t\tstruct net_device_stats *stats = &dev->net->stats;\n\n\t\t\tstats->tx_dropped++;\n\t\t\tdev_kfree_skb_any(skb);\n\t\t\ttx_data -= TX_CMD_LEN;\n\t\t\tcontinue;\n\t\t}\n\n\t\ttx_data += len;\n\t\tentry->length += len;\n\t\tentry->num_of_packet += skb_shinfo(skb)->gso_segs ?: 1;\n\n\t\tdev_kfree_skb_any(skb);\n\n\t\turb_len = (u32)(tx_data - (u8 *)tx_buf->data);\n\n\t\tremain = dev->tx_urb_size - urb_len;\n\t}\n\n\tskb_put(tx_buf, urb_len);\n\n\treturn entry;\n}\n\nstatic void lan78xx_tx_bh(struct lan78xx_net *dev)\n{\n\tint ret;\n\n\t/* Start the stack Tx queue if it was stopped\n\t */\n\tnetif_tx_lock(dev->net);\n\tif (netif_queue_stopped(dev->net)) {\n\t\tif (lan78xx_tx_pend_data_len(dev) < lan78xx_tx_urb_space(dev))\n\t\t\tnetif_wake_queue(dev->net);\n\t}\n\tnetif_tx_unlock(dev->net);\n\n\t/* Go through the Tx pending queue and set up URBs to transfer\n\t * the data to the device. Stop if no more pending data or URBs,\n\t * or if an error occurs when a URB is submitted.\n\t */\n\tdo {\n\t\tstruct skb_data *entry;\n\t\tstruct sk_buff *tx_buf;\n\t\tunsigned long flags;\n\n\t\tif (skb_queue_empty(&dev->txq_pend))\n\t\t\tbreak;\n\n\t\ttx_buf = lan78xx_get_tx_buf(dev);\n\t\tif (!tx_buf)\n\t\t\tbreak;\n\n\t\tentry = lan78xx_tx_buf_fill(dev, tx_buf);\n\n\t\tspin_lock_irqsave(&dev->txq.lock, flags);\n\t\tret = usb_autopm_get_interface_async(dev->intf);\n\t\tif (ret < 0) {\n\t\t\tspin_unlock_irqrestore(&dev->txq.lock, flags);\n\t\t\tgoto out;\n\t\t}\n\n\t\tusb_fill_bulk_urb(entry->urb, dev->udev, dev->pipe_out,\n\t\t\t\t  tx_buf->data, tx_buf->len, tx_complete,\n\t\t\t\t  tx_buf);\n\n\t\tif (tx_buf->len % dev->maxpacket == 0) {\n\t\t\t/* send USB_ZERO_PACKET */\n\t\t\tentry->urb->transfer_flags |= URB_ZERO_PACKET;\n\t\t}\n\n#ifdef CONFIG_PM\n\t\t/* if device is asleep stop outgoing packet processing */\n\t\tif (test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\n\t\t\tusb_anchor_urb(entry->urb, &dev->deferred);\n\t\t\tnetif_stop_queue(dev->net);\n\t\t\tspin_unlock_irqrestore(&dev->txq.lock, flags);\n\t\t\tnetdev_dbg(dev->net,\n\t\t\t\t   \"Delaying transmission for resumption\\n\");\n\t\t\treturn;\n\t\t}\n#endif\n\t\tret = usb_submit_urb(entry->urb, GFP_ATOMIC);\n\t\tswitch (ret) {\n\t\tcase 0:\n\t\t\tnetif_trans_update(dev->net);\n\t\t\tlan78xx_queue_skb(&dev->txq, tx_buf, tx_start);\n\t\t\tbreak;\n\t\tcase -EPIPE:\n\t\t\tnetif_stop_queue(dev->net);\n\t\t\tlan78xx_defer_kevent(dev, EVENT_TX_HALT);\n\t\t\tusb_autopm_put_interface_async(dev->intf);\n\t\t\tbreak;\n\t\tcase -ENODEV:\n\t\tcase -ENOENT:\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"tx submit urb err %d (disconnected?)\", ret);\n\t\t\tnetif_device_detach(dev->net);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tusb_autopm_put_interface_async(dev->intf);\n\t\t\tnetif_dbg(dev, tx_err, dev->net,\n\t\t\t\t  \"tx submit urb err %d\\n\", ret);\n\t\t\tbreak;\n\t\t}\n\n\t\tspin_unlock_irqrestore(&dev->txq.lock, flags);\n\n\t\tif (ret) {\n\t\t\tnetdev_warn(dev->net, \"failed to tx urb %d\\n\", ret);\nout:\n\t\t\tdev->net->stats.tx_dropped += entry->num_of_packet;\n\t\t\tlan78xx_release_tx_buf(dev, tx_buf);\n\t\t}\n\t} while (ret == 0);\n}\n\nstatic int lan78xx_bh(struct lan78xx_net *dev, int budget)\n{\n\tstruct sk_buff_head done;\n\tstruct sk_buff *rx_buf;\n\tstruct skb_data *entry;\n\tunsigned long flags;\n\tint work_done = 0;\n\n\t/* Pass frames received in the last NAPI cycle before\n\t * working on newly completed URBs.\n\t */\n\twhile (!skb_queue_empty(&dev->rxq_overflow)) {\n\t\tlan78xx_skb_return(dev, skb_dequeue(&dev->rxq_overflow));\n\t\t++work_done;\n\t}\n\n\t/* Take a snapshot of the done queue and move items to a\n\t * temporary queue. Rx URB completions will continue to add\n\t * to the done queue.\n\t */\n\t__skb_queue_head_init(&done);\n\n\tspin_lock_irqsave(&dev->rxq_done.lock, flags);\n\tskb_queue_splice_init(&dev->rxq_done, &done);\n\tspin_unlock_irqrestore(&dev->rxq_done.lock, flags);\n\n\t/* Extract receive frames from completed URBs and\n\t * pass them to the stack. Re-submit each completed URB.\n\t */\n\twhile ((work_done < budget) &&\n\t       (rx_buf = __skb_dequeue(&done))) {\n\t\tentry = (struct skb_data *)(rx_buf->cb);\n\t\tswitch (entry->state) {\n\t\tcase rx_done:\n\t\t\trx_process(dev, rx_buf, budget, &work_done);\n\t\t\tbreak;\n\t\tcase rx_cleanup:\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tnetdev_dbg(dev->net, \"rx buf state %d\\n\",\n\t\t\t\t   entry->state);\n\t\t\tbreak;\n\t\t}\n\n\t\tlan78xx_rx_urb_resubmit(dev, rx_buf);\n\t}\n\n\t/* If budget was consumed before processing all the URBs put them\n\t * back on the front of the done queue. They will be first to be\n\t * processed in the next NAPI cycle.\n\t */\n\tspin_lock_irqsave(&dev->rxq_done.lock, flags);\n\tskb_queue_splice(&done, &dev->rxq_done);\n\tspin_unlock_irqrestore(&dev->rxq_done.lock, flags);\n\n\tif (netif_device_present(dev->net) && netif_running(dev->net)) {\n\t\t/* reset update timer delta */\n\t\tif (timer_pending(&dev->stat_monitor) && (dev->delta != 1)) {\n\t\t\tdev->delta = 1;\n\t\t\tmod_timer(&dev->stat_monitor,\n\t\t\t\t  jiffies + STAT_UPDATE_TIMER);\n\t\t}\n\n\t\t/* Submit all free Rx URBs */\n\n\t\tif (!test_bit(EVENT_RX_HALT, &dev->flags))\n\t\t\tlan78xx_rx_urb_submit_all(dev);\n\n\t\t/* Submit new Tx URBs */\n\n\t\tlan78xx_tx_bh(dev);\n\t}\n\n\treturn work_done;\n}\n\nstatic int lan78xx_poll(struct napi_struct *napi, int budget)\n{\n\tstruct lan78xx_net *dev = container_of(napi, struct lan78xx_net, napi);\n\tint result = budget;\n\tint work_done;\n\n\t/* Don't do any work if the device is suspended */\n\n\tif (test_bit(EVENT_DEV_ASLEEP, &dev->flags)) {\n\t\tnapi_complete_done(napi, 0);\n\t\treturn 0;\n\t}\n\n\t/* Process completed URBs and submit new URBs */\n\n\twork_done = lan78xx_bh(dev, budget);\n\n\tif (work_done < budget) {\n\t\tnapi_complete_done(napi, work_done);\n\n\t\t/* Start a new polling cycle if data was received or\n\t\t * data is waiting to be transmitted.\n\t\t */\n\t\tif (!skb_queue_empty(&dev->rxq_done)) {\n\t\t\tnapi_schedule(napi);\n\t\t} else if (netif_carrier_ok(dev->net)) {\n\t\t\tif (skb_queue_empty(&dev->txq) &&\n\t\t\t    !skb_queue_empty(&dev->txq_pend)) {\n\t\t\t\tnapi_schedule(napi);\n\t\t\t} else {\n\t\t\t\tnetif_tx_lock(dev->net);\n\t\t\t\tif (netif_queue_stopped(dev->net)) {\n\t\t\t\t\tnetif_wake_queue(dev->net);\n\t\t\t\t\tnapi_schedule(napi);\n\t\t\t\t}\n\t\t\t\tnetif_tx_unlock(dev->net);\n\t\t\t}\n\t\t}\n\t\tresult = work_done;\n\t}\n\n\treturn result;\n}\n\nstatic void lan78xx_delayedwork(struct work_struct *work)\n{\n\tint status;\n\tstruct lan78xx_net *dev;\n\n\tdev = container_of(work, struct lan78xx_net, wq.work);\n\n\tif (test_bit(EVENT_DEV_DISCONNECT, &dev->flags))\n\t\treturn;\n\n\tif (usb_autopm_get_interface(dev->intf) < 0)\n\t\treturn;\n\n\tif (test_bit(EVENT_TX_HALT, &dev->flags)) {\n\t\tunlink_urbs(dev, &dev->txq);\n\n\t\tstatus = usb_clear_halt(dev->udev, dev->pipe_out);\n\t\tif (status < 0 &&\n\t\t    status != -EPIPE &&\n\t\t    status != -ESHUTDOWN) {\n\t\t\tif (netif_msg_tx_err(dev))\n\t\t\t\tnetdev_err(dev->net,\n\t\t\t\t\t   \"can't clear tx halt, status %d\\n\",\n\t\t\t\t\t   status);\n\t\t} else {\n\t\t\tclear_bit(EVENT_TX_HALT, &dev->flags);\n\t\t\tif (status != -ESHUTDOWN)\n\t\t\t\tnetif_wake_queue(dev->net);\n\t\t}\n\t}\n\n\tif (test_bit(EVENT_RX_HALT, &dev->flags)) {\n\t\tunlink_urbs(dev, &dev->rxq);\n\t\tstatus = usb_clear_halt(dev->udev, dev->pipe_in);\n\t\tif (status < 0 &&\n\t\t    status != -EPIPE &&\n\t\t    status != -ESHUTDOWN) {\n\t\t\tif (netif_msg_rx_err(dev))\n\t\t\t\tnetdev_err(dev->net,\n\t\t\t\t\t   \"can't clear rx halt, status %d\\n\",\n\t\t\t\t\t   status);\n\t\t} else {\n\t\t\tclear_bit(EVENT_RX_HALT, &dev->flags);\n\t\t\tnapi_schedule(&dev->napi);\n\t\t}\n\t}\n\n\tif (test_bit(EVENT_LINK_RESET, &dev->flags)) {\n\t\tint ret = 0;\n\n\t\tclear_bit(EVENT_LINK_RESET, &dev->flags);\n\t\tif (lan78xx_link_reset(dev) < 0) {\n\t\t\tnetdev_info(dev->net, \"link reset failed (%d)\\n\",\n\t\t\t\t    ret);\n\t\t}\n\t}\n\n\tif (test_bit(EVENT_STAT_UPDATE, &dev->flags)) {\n\t\tlan78xx_update_stats(dev);\n\n\t\tclear_bit(EVENT_STAT_UPDATE, &dev->flags);\n\n\t\tmod_timer(&dev->stat_monitor,\n\t\t\t  jiffies + (STAT_UPDATE_TIMER * dev->delta));\n\n\t\tdev->delta = min((dev->delta * 2), 50);\n\t}\n\n\tusb_autopm_put_interface(dev->intf);\n}\n\nstatic void intr_complete(struct urb *urb)\n{\n\tstruct lan78xx_net *dev = urb->context;\n\tint status = urb->status;\n\n\tswitch (status) {\n\t/* success */\n\tcase 0:\n\t\tlan78xx_status(dev, urb);\n\t\tbreak;\n\n\t/* software-driven interface shutdown */\n\tcase -ENOENT:\t\t\t/* urb killed */\n\tcase -ENODEV:\t\t\t/* hardware gone */\n\tcase -ESHUTDOWN:\t\t/* hardware gone */\n\t\tnetif_dbg(dev, ifdown, dev->net,\n\t\t\t  \"intr shutdown, code %d\\n\", status);\n\t\treturn;\n\n\t/* NOTE:  not throttling like RX/TX, since this endpoint\n\t * already polls infrequently\n\t */\n\tdefault:\n\t\tnetdev_dbg(dev->net, \"intr status %d\\n\", status);\n\t\tbreak;\n\t}\n\n\tif (!netif_device_present(dev->net) ||\n\t    !netif_running(dev->net)) {\n\t\tnetdev_warn(dev->net, \"not submitting new status URB\");\n\t\treturn;\n\t}\n\n\tmemset(urb->transfer_buffer, 0, urb->transfer_buffer_length);\n\tstatus = usb_submit_urb(urb, GFP_ATOMIC);\n\n\tswitch (status) {\n\tcase  0:\n\t\tbreak;\n\tcase -ENODEV:\n\tcase -ENOENT:\n\t\tnetif_dbg(dev, timer, dev->net,\n\t\t\t  \"intr resubmit %d (disconnect?)\", status);\n\t\tnetif_device_detach(dev->net);\n\t\tbreak;\n\tdefault:\n\t\tnetif_err(dev, timer, dev->net,\n\t\t\t  \"intr resubmit --> %d\\n\", status);\n\t\tbreak;\n\t}\n}\n\nstatic void lan78xx_disconnect(struct usb_interface *intf)\n{\n\tstruct lan78xx_net *dev;\n\tstruct usb_device *udev;\n\tstruct net_device *net;\n\tstruct phy_device *phydev;\n\n\tdev = usb_get_intfdata(intf);\n\tusb_set_intfdata(intf, NULL);\n\tif (!dev)\n\t\treturn;\n\n\tnetif_napi_del(&dev->napi);\n\n\tudev = interface_to_usbdev(intf);\n\tnet = dev->net;\n\n\tunregister_netdev(net);\n\n\ttimer_shutdown_sync(&dev->stat_monitor);\n\tset_bit(EVENT_DEV_DISCONNECT, &dev->flags);\n\tcancel_delayed_work_sync(&dev->wq);\n\n\tphydev = net->phydev;\n\n\tphy_unregister_fixup_for_uid(PHY_KSZ9031RNX, 0xfffffff0);\n\tphy_unregister_fixup_for_uid(PHY_LAN8835, 0xfffffff0);\n\n\tphy_disconnect(net->phydev);\n\n\tif (phy_is_pseudo_fixed_link(phydev))\n\t\tfixed_phy_unregister(phydev);\n\n\tusb_scuttle_anchored_urbs(&dev->deferred);\n\n\tlan78xx_unbind(dev, intf);\n\n\tlan78xx_free_tx_resources(dev);\n\tlan78xx_free_rx_resources(dev);\n\n\tusb_kill_urb(dev->urb_intr);\n\tusb_free_urb(dev->urb_intr);\n\n\tfree_netdev(net);\n\tusb_put_dev(udev);\n}\n\nstatic void lan78xx_tx_timeout(struct net_device *net, unsigned int txqueue)\n{\n\tstruct lan78xx_net *dev = netdev_priv(net);\n\n\tunlink_urbs(dev, &dev->txq);\n\tnapi_schedule(&dev->napi);\n}\n\nstatic netdev_features_t lan78xx_features_check(struct sk_buff *skb,\n\t\t\t\t\t\tstruct net_device *netdev,\n\t\t\t\t\t\tnetdev_features_t features)\n{\n\tstruct lan78xx_net *dev = netdev_priv(netdev);\n\n\tif (skb->len > LAN78XX_TSO_SIZE(dev))\n\t\tfeatures &= ~NETIF_F_GSO_MASK;\n\n\tfeatures = vlan_features_check(skb, features);\n\tfeatures = vxlan_features_check(skb, features);\n\n\treturn features;\n}\n\nstatic const struct net_device_ops lan78xx_netdev_ops = {\n\t.ndo_open\t\t= lan78xx_open,\n\t.ndo_stop\t\t= lan78xx_stop,\n\t.ndo_start_xmit\t\t= lan78xx_start_xmit,\n\t.ndo_tx_timeout\t\t= lan78xx_tx_timeout,\n\t.ndo_change_mtu\t\t= lan78xx_change_mtu,\n\t.ndo_set_mac_address\t= lan78xx_set_mac_addr,\n\t.ndo_validate_addr\t= eth_validate_addr,\n\t.ndo_eth_ioctl\t\t= phy_do_ioctl_running,\n\t.ndo_set_rx_mode\t= lan78xx_set_multicast,\n\t.ndo_set_features\t= lan78xx_set_features,\n\t.ndo_vlan_rx_add_vid\t= lan78xx_vlan_rx_add_vid,\n\t.ndo_vlan_rx_kill_vid\t= lan78xx_vlan_rx_kill_vid,\n\t.ndo_features_check\t= lan78xx_features_check,\n};\n\nstatic void lan78xx_stat_monitor(struct timer_list *t)\n{\n\tstruct lan78xx_net *dev = from_timer(dev, t, stat_monitor);\n\n\tlan78xx_defer_kevent(dev, EVENT_STAT_UPDATE);\n}\n\nstatic int lan78xx_probe(struct usb_interface *intf,\n\t\t\t const struct usb_device_id *id)\n{\n\tstruct usb_host_endpoint *ep_blkin, *ep_blkout, *ep_intr;\n\tstruct lan78xx_net *dev;\n\tstruct net_device *netdev;\n\tstruct usb_device *udev;\n\tint ret;\n\tunsigned int maxp;\n\tunsigned int period;\n\tu8 *buf = NULL;\n\n\tudev = interface_to_usbdev(intf);\n\tudev = usb_get_dev(udev);\n\n\tnetdev = alloc_etherdev(sizeof(struct lan78xx_net));\n\tif (!netdev) {\n\t\tdev_err(&intf->dev, \"Error: OOM\\n\");\n\t\tret = -ENOMEM;\n\t\tgoto out1;\n\t}\n\n\t/* netdev_printk() needs this */\n\tSET_NETDEV_DEV(netdev, &intf->dev);\n\n\tdev = netdev_priv(netdev);\n\tdev->udev = udev;\n\tdev->intf = intf;\n\tdev->net = netdev;\n\tdev->msg_enable = netif_msg_init(msg_level, NETIF_MSG_DRV\n\t\t\t\t\t| NETIF_MSG_PROBE | NETIF_MSG_LINK);\n\n\tskb_queue_head_init(&dev->rxq);\n\tskb_queue_head_init(&dev->txq);\n\tskb_queue_head_init(&dev->rxq_done);\n\tskb_queue_head_init(&dev->txq_pend);\n\tskb_queue_head_init(&dev->rxq_overflow);\n\tmutex_init(&dev->phy_mutex);\n\tmutex_init(&dev->dev_mutex);\n\n\tret = lan78xx_urb_config_init(dev);\n\tif (ret < 0)\n\t\tgoto out2;\n\n\tret = lan78xx_alloc_tx_resources(dev);\n\tif (ret < 0)\n\t\tgoto out2;\n\n\tret = lan78xx_alloc_rx_resources(dev);\n\tif (ret < 0)\n\t\tgoto out3;\n\n\t/* MTU range: 68 - 9000 */\n\tnetdev->max_mtu = MAX_SINGLE_PACKET_SIZE;\n\n\tnetif_set_tso_max_size(netdev, LAN78XX_TSO_SIZE(dev));\n\n\tnetif_napi_add(netdev, &dev->napi, lan78xx_poll);\n\n\tINIT_DELAYED_WORK(&dev->wq, lan78xx_delayedwork);\n\tinit_usb_anchor(&dev->deferred);\n\n\tnetdev->netdev_ops = &lan78xx_netdev_ops;\n\tnetdev->watchdog_timeo = TX_TIMEOUT_JIFFIES;\n\tnetdev->ethtool_ops = &lan78xx_ethtool_ops;\n\n\tdev->delta = 1;\n\ttimer_setup(&dev->stat_monitor, lan78xx_stat_monitor, 0);\n\n\tmutex_init(&dev->stats.access_lock);\n\n\tif (intf->cur_altsetting->desc.bNumEndpoints < 3) {\n\t\tret = -ENODEV;\n\t\tgoto out4;\n\t}\n\n\tdev->pipe_in = usb_rcvbulkpipe(udev, BULK_IN_PIPE);\n\tep_blkin = usb_pipe_endpoint(udev, dev->pipe_in);\n\tif (!ep_blkin || !usb_endpoint_is_bulk_in(&ep_blkin->desc)) {\n\t\tret = -ENODEV;\n\t\tgoto out4;\n\t}\n\n\tdev->pipe_out = usb_sndbulkpipe(udev, BULK_OUT_PIPE);\n\tep_blkout = usb_pipe_endpoint(udev, dev->pipe_out);\n\tif (!ep_blkout || !usb_endpoint_is_bulk_out(&ep_blkout->desc)) {\n\t\tret = -ENODEV;\n\t\tgoto out4;\n\t}\n\n\tep_intr = &intf->cur_altsetting->endpoint[2];\n\tif (!usb_endpoint_is_int_in(&ep_intr->desc)) {\n\t\tret = -ENODEV;\n\t\tgoto out4;\n\t}\n\n\tdev->pipe_intr = usb_rcvintpipe(dev->udev,\n\t\t\t\t\tusb_endpoint_num(&ep_intr->desc));\n\n\tret = lan78xx_bind(dev, intf);\n\tif (ret < 0)\n\t\tgoto out4;\n\n\tperiod = ep_intr->desc.bInterval;\n\tmaxp = usb_maxpacket(dev->udev, dev->pipe_intr);\n\tbuf = kmalloc(maxp, GFP_KERNEL);\n\tif (!buf) {\n\t\tret = -ENOMEM;\n\t\tgoto out5;\n\t}\n\n\tdev->urb_intr = usb_alloc_urb(0, GFP_KERNEL);\n\tif (!dev->urb_intr) {\n\t\tret = -ENOMEM;\n\t\tgoto out6;\n\t} else {\n\t\tusb_fill_int_urb(dev->urb_intr, dev->udev,\n\t\t\t\t dev->pipe_intr, buf, maxp,\n\t\t\t\t intr_complete, dev, period);\n\t\tdev->urb_intr->transfer_flags |= URB_FREE_BUFFER;\n\t}\n\n\tdev->maxpacket = usb_maxpacket(dev->udev, dev->pipe_out);\n\n\t/* Reject broken descriptors. */\n\tif (dev->maxpacket == 0) {\n\t\tret = -ENODEV;\n\t\tgoto out6;\n\t}\n\n\t/* driver requires remote-wakeup capability during autosuspend. */\n\tintf->needs_remote_wakeup = 1;\n\n\tret = lan78xx_phy_init(dev);\n\tif (ret < 0)\n\t\tgoto out7;\n\n\tret = register_netdev(netdev);\n\tif (ret != 0) {\n\t\tnetif_err(dev, probe, netdev, \"couldn't register the device\\n\");\n\t\tgoto out8;\n\t}\n\n\tusb_set_intfdata(intf, dev);\n\n\tret = device_set_wakeup_enable(&udev->dev, true);\n\n\t /* Default delay of 2sec has more overhead than advantage.\n\t  * Set to 10sec as default.\n\t  */\n\tpm_runtime_set_autosuspend_delay(&udev->dev,\n\t\t\t\t\t DEFAULT_AUTOSUSPEND_DELAY);\n\n\treturn 0;\n\nout8:\n\tphy_disconnect(netdev->phydev);\nout7:\n\tusb_free_urb(dev->urb_intr);\nout6:\n\tkfree(buf);\nout5:\n\tlan78xx_unbind(dev, intf);\nout4:\n\tnetif_napi_del(&dev->napi);\n\tlan78xx_free_rx_resources(dev);\nout3:\n\tlan78xx_free_tx_resources(dev);\nout2:\n\tfree_netdev(netdev);\nout1:\n\tusb_put_dev(udev);\n\n\treturn ret;\n}\n\nstatic u16 lan78xx_wakeframe_crc16(const u8 *buf, int len)\n{\n\tconst u16 crc16poly = 0x8005;\n\tint i;\n\tu16 bit, crc, msb;\n\tu8 data;\n\n\tcrc = 0xFFFF;\n\tfor (i = 0; i < len; i++) {\n\t\tdata = *buf++;\n\t\tfor (bit = 0; bit < 8; bit++) {\n\t\t\tmsb = crc >> 15;\n\t\t\tcrc <<= 1;\n\n\t\t\tif (msb ^ (u16)(data & 1)) {\n\t\t\t\tcrc ^= crc16poly;\n\t\t\t\tcrc |= (u16)0x0001U;\n\t\t\t}\n\t\t\tdata >>= 1;\n\t\t}\n\t}\n\n\treturn crc;\n}\n\nstatic int lan78xx_set_auto_suspend(struct lan78xx_net *dev)\n{\n\tu32 buf;\n\tint ret;\n\n\tret = lan78xx_stop_tx_path(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_stop_rx_path(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* auto suspend (selective suspend) */\n\n\tret = lan78xx_write_reg(dev, WUCSR, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_write_reg(dev, WUCSR2, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* set goodframe wakeup */\n\n\tret = lan78xx_read_reg(dev, WUCSR, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= WUCSR_RFE_WAKE_EN_;\n\tbuf |= WUCSR_STORE_WAKE_;\n\n\tret = lan78xx_write_reg(dev, WUCSR, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf &= ~PMT_CTL_RES_CLR_WKP_EN_;\n\tbuf |= PMT_CTL_RES_CLR_WKP_STS_;\n\tbuf |= PMT_CTL_PHY_WAKE_EN_;\n\tbuf |= PMT_CTL_WOL_EN_;\n\tbuf &= ~PMT_CTL_SUS_MODE_MASK_;\n\tbuf |= PMT_CTL_SUS_MODE_3_;\n\n\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= PMT_CTL_WUPS_MASK_;\n\n\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_start_rx_path(dev);\n\n\treturn ret;\n}\n\nstatic int lan78xx_set_suspend(struct lan78xx_net *dev, u32 wol)\n{\n\tconst u8 ipv4_multicast[3] = { 0x01, 0x00, 0x5E };\n\tconst u8 ipv6_multicast[3] = { 0x33, 0x33 };\n\tconst u8 arp_type[2] = { 0x08, 0x06 };\n\tu32 temp_pmt_ctl;\n\tint mask_index;\n\tu32 temp_wucsr;\n\tu32 buf;\n\tu16 crc;\n\tint ret;\n\n\tret = lan78xx_stop_tx_path(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_stop_rx_path(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_write_reg(dev, WUCSR, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_write_reg(dev, WUCSR2, 0);\n\tif (ret < 0)\n\t\treturn ret;\n\tret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttemp_wucsr = 0;\n\n\ttemp_pmt_ctl = 0;\n\n\tret = lan78xx_read_reg(dev, PMT_CTL, &temp_pmt_ctl);\n\tif (ret < 0)\n\t\treturn ret;\n\n\ttemp_pmt_ctl &= ~PMT_CTL_RES_CLR_WKP_EN_;\n\ttemp_pmt_ctl |= PMT_CTL_RES_CLR_WKP_STS_;\n\n\tfor (mask_index = 0; mask_index < NUM_OF_WUF_CFG; mask_index++) {\n\t\tret = lan78xx_write_reg(dev, WUF_CFG(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t}\n\n\tmask_index = 0;\n\tif (wol & WAKE_PHY) {\n\t\ttemp_pmt_ctl |= PMT_CTL_PHY_WAKE_EN_;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tif (wol & WAKE_MAGIC) {\n\t\ttemp_wucsr |= WUCSR_MPEN_;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_3_;\n\t}\n\tif (wol & WAKE_BCAST) {\n\t\ttemp_wucsr |= WUCSR_BCST_EN_;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tif (wol & WAKE_MCAST) {\n\t\ttemp_wucsr |= WUCSR_WAKE_EN_;\n\n\t\t/* set WUF_CFG & WUF_MASK for IPv4 Multicast */\n\t\tcrc = lan78xx_wakeframe_crc16(ipv4_multicast, 3);\n\t\tret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\n\t\t\t\t\tWUF_CFGX_EN_ |\n\t\t\t\t\tWUF_CFGX_TYPE_MCAST_ |\n\t\t\t\t\t(0 << WUF_CFGX_OFFSET_SHIFT_) |\n\t\t\t\t\t(crc & WUF_CFGX_CRC16_MASK_));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 7);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tmask_index++;\n\n\t\t/* for IPv6 Multicast */\n\t\tcrc = lan78xx_wakeframe_crc16(ipv6_multicast, 2);\n\t\tret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\n\t\t\t\t\tWUF_CFGX_EN_ |\n\t\t\t\t\tWUF_CFGX_TYPE_MCAST_ |\n\t\t\t\t\t(0 << WUF_CFGX_OFFSET_SHIFT_) |\n\t\t\t\t\t(crc & WUF_CFGX_CRC16_MASK_));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 3);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tmask_index++;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tif (wol & WAKE_UCAST) {\n\t\ttemp_wucsr |= WUCSR_PFDA_EN_;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tif (wol & WAKE_ARP) {\n\t\ttemp_wucsr |= WUCSR_WAKE_EN_;\n\n\t\t/* set WUF_CFG & WUF_MASK\n\t\t * for packettype (offset 12,13) = ARP (0x0806)\n\t\t */\n\t\tcrc = lan78xx_wakeframe_crc16(arp_type, 2);\n\t\tret = lan78xx_write_reg(dev, WUF_CFG(mask_index),\n\t\t\t\t\tWUF_CFGX_EN_ |\n\t\t\t\t\tWUF_CFGX_TYPE_ALL_ |\n\t\t\t\t\t(0 << WUF_CFGX_OFFSET_SHIFT_) |\n\t\t\t\t\t(crc & WUF_CFGX_CRC16_MASK_));\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tret = lan78xx_write_reg(dev, WUF_MASK0(mask_index), 0x3000);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK1(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK2(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\t\tret = lan78xx_write_reg(dev, WUF_MASK3(mask_index), 0);\n\t\tif (ret < 0)\n\t\t\treturn ret;\n\n\t\tmask_index++;\n\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\n\tret = lan78xx_write_reg(dev, WUCSR, temp_wucsr);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* when multiple WOL bits are set */\n\tif (hweight_long((unsigned long)wol) > 1) {\n\t\ttemp_pmt_ctl |= PMT_CTL_WOL_EN_;\n\t\ttemp_pmt_ctl &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\ttemp_pmt_ctl |= PMT_CTL_SUS_MODE_0_;\n\t}\n\tret = lan78xx_write_reg(dev, PMT_CTL, temp_pmt_ctl);\n\tif (ret < 0)\n\t\treturn ret;\n\n\t/* clear WUPS */\n\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tbuf |= PMT_CTL_WUPS_MASK_;\n\n\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = lan78xx_start_rx_path(dev);\n\n\treturn ret;\n}\n\nstatic int lan78xx_suspend(struct usb_interface *intf, pm_message_t message)\n{\n\tstruct lan78xx_net *dev = usb_get_intfdata(intf);\n\tbool dev_open;\n\tint ret;\n\n\tmutex_lock(&dev->dev_mutex);\n\n\tnetif_dbg(dev, ifdown, dev->net,\n\t\t  \"suspending: pm event %#x\", message.event);\n\n\tdev_open = test_bit(EVENT_DEV_OPEN, &dev->flags);\n\n\tif (dev_open) {\n\t\tspin_lock_irq(&dev->txq.lock);\n\t\t/* don't autosuspend while transmitting */\n\t\tif ((skb_queue_len(&dev->txq) ||\n\t\t     skb_queue_len(&dev->txq_pend)) &&\n\t\t    PMSG_IS_AUTO(message)) {\n\t\t\tspin_unlock_irq(&dev->txq.lock);\n\t\t\tret = -EBUSY;\n\t\t\tgoto out;\n\t\t} else {\n\t\t\tset_bit(EVENT_DEV_ASLEEP, &dev->flags);\n\t\t\tspin_unlock_irq(&dev->txq.lock);\n\t\t}\n\n\t\t/* stop RX */\n\t\tret = lan78xx_stop_rx_path(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tret = lan78xx_flush_rx_fifo(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\t/* stop Tx */\n\t\tret = lan78xx_stop_tx_path(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\t/* empty out the Rx and Tx queues */\n\t\tnetif_device_detach(dev->net);\n\t\tlan78xx_terminate_urbs(dev);\n\t\tusb_kill_urb(dev->urb_intr);\n\n\t\t/* reattach */\n\t\tnetif_device_attach(dev->net);\n\n\t\tdel_timer(&dev->stat_monitor);\n\n\t\tif (PMSG_IS_AUTO(message)) {\n\t\t\tret = lan78xx_set_auto_suspend(dev);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t} else {\n\t\t\tstruct lan78xx_priv *pdata;\n\n\t\t\tpdata = (struct lan78xx_priv *)(dev->data[0]);\n\t\t\tnetif_carrier_off(dev->net);\n\t\t\tret = lan78xx_set_suspend(dev, pdata->wol);\n\t\t\tif (ret < 0)\n\t\t\t\tgoto out;\n\t\t}\n\t} else {\n\t\t/* Interface is down; don't allow WOL and PHY\n\t\t * events to wake up the host\n\t\t */\n\t\tu32 buf;\n\n\t\tset_bit(EVENT_DEV_ASLEEP, &dev->flags);\n\n\t\tret = lan78xx_write_reg(dev, WUCSR, 0);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t\tret = lan78xx_write_reg(dev, WUCSR2, 0);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tbuf &= ~PMT_CTL_RES_CLR_WKP_EN_;\n\t\tbuf |= PMT_CTL_RES_CLR_WKP_STS_;\n\t\tbuf &= ~PMT_CTL_SUS_MODE_MASK_;\n\t\tbuf |= PMT_CTL_SUS_MODE_3_;\n\n\t\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tret = lan78xx_read_reg(dev, PMT_CTL, &buf);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tbuf |= PMT_CTL_WUPS_MASK_;\n\n\t\tret = lan78xx_write_reg(dev, PMT_CTL, buf);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\t}\n\n\tret = 0;\nout:\n\tmutex_unlock(&dev->dev_mutex);\n\n\treturn ret;\n}\n\nstatic bool lan78xx_submit_deferred_urbs(struct lan78xx_net *dev)\n{\n\tbool pipe_halted = false;\n\tstruct urb *urb;\n\n\twhile ((urb = usb_get_from_anchor(&dev->deferred))) {\n\t\tstruct sk_buff *skb = urb->context;\n\t\tint ret;\n\n\t\tif (!netif_device_present(dev->net) ||\n\t\t    !netif_carrier_ok(dev->net) ||\n\t\t    pipe_halted) {\n\t\t\tlan78xx_release_tx_buf(dev, skb);\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = usb_submit_urb(urb, GFP_ATOMIC);\n\n\t\tif (ret == 0) {\n\t\t\tnetif_trans_update(dev->net);\n\t\t\tlan78xx_queue_skb(&dev->txq, skb, tx_start);\n\t\t} else {\n\t\t\tif (ret == -EPIPE) {\n\t\t\t\tnetif_stop_queue(dev->net);\n\t\t\t\tpipe_halted = true;\n\t\t\t} else if (ret == -ENODEV) {\n\t\t\t\tnetif_device_detach(dev->net);\n\t\t\t}\n\n\t\t\tlan78xx_release_tx_buf(dev, skb);\n\t\t}\n\t}\n\n\treturn pipe_halted;\n}\n\nstatic int lan78xx_resume(struct usb_interface *intf)\n{\n\tstruct lan78xx_net *dev = usb_get_intfdata(intf);\n\tbool dev_open;\n\tint ret;\n\n\tmutex_lock(&dev->dev_mutex);\n\n\tnetif_dbg(dev, ifup, dev->net, \"resuming device\");\n\n\tdev_open = test_bit(EVENT_DEV_OPEN, &dev->flags);\n\n\tif (dev_open) {\n\t\tbool pipe_halted = false;\n\n\t\tret = lan78xx_flush_tx_fifo(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tif (dev->urb_intr) {\n\t\t\tint ret = usb_submit_urb(dev->urb_intr, GFP_KERNEL);\n\n\t\t\tif (ret < 0) {\n\t\t\t\tif (ret == -ENODEV)\n\t\t\t\t\tnetif_device_detach(dev->net);\n\t\t\t\tnetdev_warn(dev->net, \"Failed to submit intr URB\");\n\t\t\t}\n\t\t}\n\n\t\tspin_lock_irq(&dev->txq.lock);\n\n\t\tif (netif_device_present(dev->net)) {\n\t\t\tpipe_halted = lan78xx_submit_deferred_urbs(dev);\n\n\t\t\tif (pipe_halted)\n\t\t\t\tlan78xx_defer_kevent(dev, EVENT_TX_HALT);\n\t\t}\n\n\t\tclear_bit(EVENT_DEV_ASLEEP, &dev->flags);\n\n\t\tspin_unlock_irq(&dev->txq.lock);\n\n\t\tif (!pipe_halted &&\n\t\t    netif_device_present(dev->net) &&\n\t\t    (lan78xx_tx_pend_data_len(dev) < lan78xx_tx_urb_space(dev)))\n\t\t\tnetif_start_queue(dev->net);\n\n\t\tret = lan78xx_start_tx_path(dev);\n\t\tif (ret < 0)\n\t\t\tgoto out;\n\n\t\tnapi_schedule(&dev->napi);\n\n\t\tif (!timer_pending(&dev->stat_monitor)) {\n\t\t\tdev->delta = 1;\n\t\t\tmod_timer(&dev->stat_monitor,\n\t\t\t\t  jiffies + STAT_UPDATE_TIMER);\n\t\t}\n\n\t} else {\n\t\tclear_bit(EVENT_DEV_ASLEEP, &dev->flags);\n\t}\n\n\tret = lan78xx_write_reg(dev, WUCSR2, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = lan78xx_write_reg(dev, WUCSR, 0);\n\tif (ret < 0)\n\t\tgoto out;\n\tret = lan78xx_write_reg(dev, WK_SRC, 0xFFF1FF1FUL);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = lan78xx_write_reg(dev, WUCSR2, WUCSR2_NS_RCD_ |\n\t\t\t\t\t     WUCSR2_ARP_RCD_ |\n\t\t\t\t\t     WUCSR2_IPV6_TCPSYN_RCD_ |\n\t\t\t\t\t     WUCSR2_IPV4_TCPSYN_RCD_);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = lan78xx_write_reg(dev, WUCSR, WUCSR_EEE_TX_WAKE_ |\n\t\t\t\t\t    WUCSR_EEE_RX_WAKE_ |\n\t\t\t\t\t    WUCSR_PFDA_FR_ |\n\t\t\t\t\t    WUCSR_RFE_WAKE_FR_ |\n\t\t\t\t\t    WUCSR_WUFR_ |\n\t\t\t\t\t    WUCSR_MPR_ |\n\t\t\t\t\t    WUCSR_BCST_FR_);\n\tif (ret < 0)\n\t\tgoto out;\n\n\tret = 0;\nout:\n\tmutex_unlock(&dev->dev_mutex);\n\n\treturn ret;\n}\n\nstatic int lan78xx_reset_resume(struct usb_interface *intf)\n{\n\tstruct lan78xx_net *dev = usb_get_intfdata(intf);\n\tint ret;\n\n\tnetif_dbg(dev, ifup, dev->net, \"(reset) resuming device\");\n\n\tret = lan78xx_reset(dev);\n\tif (ret < 0)\n\t\treturn ret;\n\n\tphy_start(dev->net->phydev);\n\n\tret = lan78xx_resume(intf);\n\n\treturn ret;\n}\n\nstatic const struct usb_device_id products[] = {\n\t{\n\t/* LAN7800 USB Gigabit Ethernet Device */\n\tUSB_DEVICE(LAN78XX_USB_VENDOR_ID, LAN7800_USB_PRODUCT_ID),\n\t},\n\t{\n\t/* LAN7850 USB Gigabit Ethernet Device */\n\tUSB_DEVICE(LAN78XX_USB_VENDOR_ID, LAN7850_USB_PRODUCT_ID),\n\t},\n\t{\n\t/* LAN7801 USB Gigabit Ethernet Device */\n\tUSB_DEVICE(LAN78XX_USB_VENDOR_ID, LAN7801_USB_PRODUCT_ID),\n\t},\n\t{\n\t/* ATM2-AF USB Gigabit Ethernet Device */\n\tUSB_DEVICE(AT29M2AF_USB_VENDOR_ID, AT29M2AF_USB_PRODUCT_ID),\n\t},\n\t{},\n};\nMODULE_DEVICE_TABLE(usb, products);\n\nstatic struct usb_driver lan78xx_driver = {\n\t.name\t\t\t= DRIVER_NAME,\n\t.id_table\t\t= products,\n\t.probe\t\t\t= lan78xx_probe,\n\t.disconnect\t\t= lan78xx_disconnect,\n\t.suspend\t\t= lan78xx_suspend,\n\t.resume\t\t\t= lan78xx_resume,\n\t.reset_resume\t\t= lan78xx_reset_resume,\n\t.supports_autosuspend\t= 1,\n\t.disable_hub_initiated_lpm = 1,\n};\n\nmodule_usb_driver(lan78xx_driver);\n\nMODULE_AUTHOR(DRIVER_AUTHOR);\nMODULE_DESCRIPTION(DRIVER_DESC);\nMODULE_LICENSE(\"GPL\");\n"], "filenames": ["drivers/net/usb/lan78xx.c"], "buggy_code_start_loc": [4227], "buggy_code_end_loc": [4252], "fixing_code_start_loc": [4226], "fixing_code_end_loc": [4248], "type": "CWE-416", "message": "A use-after-free flaw was found in lan78xx_disconnect in drivers/net/usb/lan78xx.c in the network sub-component, net/usb/lan78xx in the Linux Kernel. This flaw allows a local attacker to crash the system when the LAN78XX USB device detaches.", "other": {"cve": {"id": "CVE-2023-6039", "sourceIdentifier": "secalert@redhat.com", "published": "2023-11-09T15:15:09.133", "lastModified": "2023-11-16T17:59:48.420", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "A use-after-free flaw was found in lan78xx_disconnect in drivers/net/usb/lan78xx.c in the network sub-component, net/usb/lan78xx in the Linux Kernel. This flaw allows a local attacker to crash the system when the LAN78XX USB device detaches."}, {"lang": "es", "value": "Se encontr\u00f3 una falla de use-after-free en lan78xx_disconnect en drivers/net/usb/lan78xx.c en el subcomponente de red, net/usb/lan78xx en el kernel de Linux. Esta falla permite que un atacante local bloquee el sistema cuando el dispositivo USB LAN78XX se desconecta."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}, {"source": "secalert@redhat.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-416"}]}, {"source": "secalert@redhat.com", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-416"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndExcluding": "6.5", "matchCriteriaId": "98C491C7-598A-4D36-BA4F-3505A5727ED1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.5:rc1:*:*:*:*:*:*", "matchCriteriaId": "0B3E6E4D-E24E-4630-B00C-8C9901C597B0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.5:rc2:*:*:*:*:*:*", "matchCriteriaId": "E4A01A71-0F09-4DB2-A02F-7EFFBE27C98D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.5:rc3:*:*:*:*:*:*", "matchCriteriaId": "F5608371-157A-4318-8A2E-4104C3467EA1"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:6.5:rc4:*:*:*:*:*:*", "matchCriteriaId": "2226A776-DF8C-49E0-A030-0A7853BB018A"}]}]}], "references": [{"url": "https://access.redhat.com/security/cve/CVE-2023-6039", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=2248755", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/1e7417c188d0a83fb385ba2dbe35fd2563f2b6f3", "source": "secalert@redhat.com", "tags": ["Patch"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/1e7417c188d0a83fb385ba2dbe35fd2563f2b6f3"}}
{"buggy_code": ["/*\n * utils for libavcodec\n * Copyright (c) 2001 Fabrice Bellard\n * Copyright (c) 2002-2004 Michael Niedermayer <michaelni@gmx.at>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * utils.\n */\n\n#include \"config.h\"\n#include \"libavutil/atomic.h\"\n#include \"libavutil/attributes.h\"\n#include \"libavutil/avassert.h\"\n#include \"libavutil/avstring.h\"\n#include \"libavutil/bprint.h\"\n#include \"libavutil/channel_layout.h\"\n#include \"libavutil/crc.h\"\n#include \"libavutil/frame.h\"\n#include \"libavutil/hwcontext.h\"\n#include \"libavutil/internal.h\"\n#include \"libavutil/mathematics.h\"\n#include \"libavutil/mem_internal.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/samplefmt.h\"\n#include \"libavutil/dict.h\"\n#include \"libavutil/thread.h\"\n#include \"avcodec.h\"\n#include \"libavutil/opt.h\"\n#include \"me_cmp.h\"\n#include \"mpegvideo.h\"\n#include \"thread.h\"\n#include \"frame_thread_encoder.h\"\n#include \"internal.h\"\n#include \"raw.h\"\n#include \"bytestream.h\"\n#include \"version.h\"\n#include <stdlib.h>\n#include <stdarg.h>\n#include <limits.h>\n#include <float.h>\n#if CONFIG_ICONV\n# include <iconv.h>\n#endif\n\n#include \"libavutil/ffversion.h\"\nconst char av_codec_ffversion[] = \"FFmpeg version \" FFMPEG_VERSION;\n\n#if HAVE_PTHREADS || HAVE_W32THREADS || HAVE_OS2THREADS\nstatic int default_lockmgr_cb(void **arg, enum AVLockOp op)\n{\n    void * volatile * mutex = arg;\n    int err;\n\n    switch (op) {\n    case AV_LOCK_CREATE:\n        return 0;\n    case AV_LOCK_OBTAIN:\n        if (!*mutex) {\n            pthread_mutex_t *tmp = av_malloc(sizeof(pthread_mutex_t));\n            if (!tmp)\n                return AVERROR(ENOMEM);\n            if ((err = pthread_mutex_init(tmp, NULL))) {\n                av_free(tmp);\n                return AVERROR(err);\n            }\n            if (avpriv_atomic_ptr_cas(mutex, NULL, tmp)) {\n                pthread_mutex_destroy(tmp);\n                av_free(tmp);\n            }\n        }\n\n        if ((err = pthread_mutex_lock(*mutex)))\n            return AVERROR(err);\n\n        return 0;\n    case AV_LOCK_RELEASE:\n        if ((err = pthread_mutex_unlock(*mutex)))\n            return AVERROR(err);\n\n        return 0;\n    case AV_LOCK_DESTROY:\n        if (*mutex)\n            pthread_mutex_destroy(*mutex);\n        av_free(*mutex);\n        avpriv_atomic_ptr_cas(mutex, *mutex, NULL);\n        return 0;\n    }\n    return 1;\n}\nstatic int (*lockmgr_cb)(void **mutex, enum AVLockOp op) = default_lockmgr_cb;\n#else\nstatic int (*lockmgr_cb)(void **mutex, enum AVLockOp op) = NULL;\n#endif\n\n\nvolatile int ff_avcodec_locked;\nstatic int volatile entangled_thread_counter = 0;\nstatic void *codec_mutex;\nstatic void *avformat_mutex;\n\nvoid av_fast_padded_malloc(void *ptr, unsigned int *size, size_t min_size)\n{\n    uint8_t **p = ptr;\n    if (min_size > SIZE_MAX - AV_INPUT_BUFFER_PADDING_SIZE) {\n        av_freep(p);\n        *size = 0;\n        return;\n    }\n    if (!ff_fast_malloc(p, size, min_size + AV_INPUT_BUFFER_PADDING_SIZE, 1))\n        memset(*p + min_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n}\n\nvoid av_fast_padded_mallocz(void *ptr, unsigned int *size, size_t min_size)\n{\n    uint8_t **p = ptr;\n    if (min_size > SIZE_MAX - AV_INPUT_BUFFER_PADDING_SIZE) {\n        av_freep(p);\n        *size = 0;\n        return;\n    }\n    if (!ff_fast_malloc(p, size, min_size + AV_INPUT_BUFFER_PADDING_SIZE, 1))\n        memset(*p, 0, min_size + AV_INPUT_BUFFER_PADDING_SIZE);\n}\n\n/* encoder management */\nstatic AVCodec *first_avcodec = NULL;\nstatic AVCodec **last_avcodec = &first_avcodec;\n\nAVCodec *av_codec_next(const AVCodec *c)\n{\n    if (c)\n        return c->next;\n    else\n        return first_avcodec;\n}\n\nstatic av_cold void avcodec_init(void)\n{\n    static int initialized = 0;\n\n    if (initialized != 0)\n        return;\n    initialized = 1;\n\n    if (CONFIG_ME_CMP)\n        ff_me_cmp_init_static();\n}\n\nint av_codec_is_encoder(const AVCodec *codec)\n{\n    return codec && (codec->encode_sub || codec->encode2 ||codec->send_frame);\n}\n\nint av_codec_is_decoder(const AVCodec *codec)\n{\n    return codec && (codec->decode || codec->send_packet);\n}\n\nav_cold void avcodec_register(AVCodec *codec)\n{\n    AVCodec **p;\n    avcodec_init();\n    p = last_avcodec;\n    codec->next = NULL;\n\n    while(*p || avpriv_atomic_ptr_cas((void * volatile *)p, NULL, codec))\n        p = &(*p)->next;\n    last_avcodec = &codec->next;\n\n    if (codec->init_static_data)\n        codec->init_static_data(codec);\n}\n\n#if FF_API_EMU_EDGE\nunsigned avcodec_get_edge_width(void)\n{\n    return EDGE_WIDTH;\n}\n#endif\n\n#if FF_API_SET_DIMENSIONS\nvoid avcodec_set_dimensions(AVCodecContext *s, int width, int height)\n{\n    int ret = ff_set_dimensions(s, width, height);\n    if (ret < 0) {\n        av_log(s, AV_LOG_WARNING, \"Failed to set dimensions %d %d\\n\", width, height);\n    }\n}\n#endif\n\nint ff_set_dimensions(AVCodecContext *s, int width, int height)\n{\n    int ret = av_image_check_size2(width, height, s->max_pixels, AV_PIX_FMT_NONE, 0, s);\n\n    if (ret < 0)\n        width = height = 0;\n\n    s->coded_width  = width;\n    s->coded_height = height;\n    s->width        = AV_CEIL_RSHIFT(width,  s->lowres);\n    s->height       = AV_CEIL_RSHIFT(height, s->lowres);\n\n    return ret;\n}\n\nint ff_set_sar(AVCodecContext *avctx, AVRational sar)\n{\n    int ret = av_image_check_sar(avctx->width, avctx->height, sar);\n\n    if (ret < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %d/%d\\n\",\n               sar.num, sar.den);\n        avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        return ret;\n    } else {\n        avctx->sample_aspect_ratio = sar;\n    }\n    return 0;\n}\n\nint ff_side_data_update_matrix_encoding(AVFrame *frame,\n                                        enum AVMatrixEncoding matrix_encoding)\n{\n    AVFrameSideData *side_data;\n    enum AVMatrixEncoding *data;\n\n    side_data = av_frame_get_side_data(frame, AV_FRAME_DATA_MATRIXENCODING);\n    if (!side_data)\n        side_data = av_frame_new_side_data(frame, AV_FRAME_DATA_MATRIXENCODING,\n                                           sizeof(enum AVMatrixEncoding));\n\n    if (!side_data)\n        return AVERROR(ENOMEM);\n\n    data  = (enum AVMatrixEncoding*)side_data->data;\n    *data = matrix_encoding;\n\n    return 0;\n}\n\nvoid avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,\n                               int linesize_align[AV_NUM_DATA_POINTERS])\n{\n    int i;\n    int w_align = 1;\n    int h_align = 1;\n    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);\n\n    if (desc) {\n        w_align = 1 << desc->log2_chroma_w;\n        h_align = 1 << desc->log2_chroma_h;\n    }\n\n    switch (s->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUYV422:\n    case AV_PIX_FMT_YVYU422:\n    case AV_PIX_FMT_UYVY422:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_GBRP:\n    case AV_PIX_FMT_GBRAP:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_GRAY16BE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_YUVJ420P:\n    case AV_PIX_FMT_YUVJ422P:\n    case AV_PIX_FMT_YUVJ440P:\n    case AV_PIX_FMT_YUVJ444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9LE:\n    case AV_PIX_FMT_YUV420P9BE:\n    case AV_PIX_FMT_YUV420P10LE:\n    case AV_PIX_FMT_YUV420P10BE:\n    case AV_PIX_FMT_YUV420P12LE:\n    case AV_PIX_FMT_YUV420P12BE:\n    case AV_PIX_FMT_YUV420P14LE:\n    case AV_PIX_FMT_YUV420P14BE:\n    case AV_PIX_FMT_YUV420P16LE:\n    case AV_PIX_FMT_YUV420P16BE:\n    case AV_PIX_FMT_YUVA420P9LE:\n    case AV_PIX_FMT_YUVA420P9BE:\n    case AV_PIX_FMT_YUVA420P10LE:\n    case AV_PIX_FMT_YUVA420P10BE:\n    case AV_PIX_FMT_YUVA420P16LE:\n    case AV_PIX_FMT_YUVA420P16BE:\n    case AV_PIX_FMT_YUV422P9LE:\n    case AV_PIX_FMT_YUV422P9BE:\n    case AV_PIX_FMT_YUV422P10LE:\n    case AV_PIX_FMT_YUV422P10BE:\n    case AV_PIX_FMT_YUV422P12LE:\n    case AV_PIX_FMT_YUV422P12BE:\n    case AV_PIX_FMT_YUV422P14LE:\n    case AV_PIX_FMT_YUV422P14BE:\n    case AV_PIX_FMT_YUV422P16LE:\n    case AV_PIX_FMT_YUV422P16BE:\n    case AV_PIX_FMT_YUVA422P9LE:\n    case AV_PIX_FMT_YUVA422P9BE:\n    case AV_PIX_FMT_YUVA422P10LE:\n    case AV_PIX_FMT_YUVA422P10BE:\n    case AV_PIX_FMT_YUVA422P16LE:\n    case AV_PIX_FMT_YUVA422P16BE:\n    case AV_PIX_FMT_YUV440P10LE:\n    case AV_PIX_FMT_YUV440P10BE:\n    case AV_PIX_FMT_YUV440P12LE:\n    case AV_PIX_FMT_YUV440P12BE:\n    case AV_PIX_FMT_YUV444P9LE:\n    case AV_PIX_FMT_YUV444P9BE:\n    case AV_PIX_FMT_YUV444P10LE:\n    case AV_PIX_FMT_YUV444P10BE:\n    case AV_PIX_FMT_YUV444P12LE:\n    case AV_PIX_FMT_YUV444P12BE:\n    case AV_PIX_FMT_YUV444P14LE:\n    case AV_PIX_FMT_YUV444P14BE:\n    case AV_PIX_FMT_YUV444P16LE:\n    case AV_PIX_FMT_YUV444P16BE:\n    case AV_PIX_FMT_YUVA444P9LE:\n    case AV_PIX_FMT_YUVA444P9BE:\n    case AV_PIX_FMT_YUVA444P10LE:\n    case AV_PIX_FMT_YUVA444P10BE:\n    case AV_PIX_FMT_YUVA444P16LE:\n    case AV_PIX_FMT_YUVA444P16BE:\n    case AV_PIX_FMT_GBRP9LE:\n    case AV_PIX_FMT_GBRP9BE:\n    case AV_PIX_FMT_GBRP10LE:\n    case AV_PIX_FMT_GBRP10BE:\n    case AV_PIX_FMT_GBRP12LE:\n    case AV_PIX_FMT_GBRP12BE:\n    case AV_PIX_FMT_GBRP14LE:\n    case AV_PIX_FMT_GBRP14BE:\n    case AV_PIX_FMT_GBRP16LE:\n    case AV_PIX_FMT_GBRP16BE:\n    case AV_PIX_FMT_GBRAP12LE:\n    case AV_PIX_FMT_GBRAP12BE:\n    case AV_PIX_FMT_GBRAP16LE:\n    case AV_PIX_FMT_GBRAP16BE:\n        w_align = 16; //FIXME assume 16 pixel per macroblock\n        h_align = 16 * 2; // interlaced needs 2 macroblocks height\n        break;\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUVJ411P:\n    case AV_PIX_FMT_UYYVYY411:\n        w_align = 32;\n        h_align = 16 * 2;\n        break;\n    case AV_PIX_FMT_YUV410P:\n        if (s->codec_id == AV_CODEC_ID_SVQ1) {\n            w_align = 64;\n            h_align = 64;\n        }\n        break;\n    case AV_PIX_FMT_RGB555:\n        if (s->codec_id == AV_CODEC_ID_RPZA) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_PAL8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB8:\n        if (s->codec_id == AV_CODEC_ID_SMC ||\n            s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_JV) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_BGR24:\n        if ((s->codec_id == AV_CODEC_ID_MSZH) ||\n            (s->codec_id == AV_CODEC_ID_ZLIB)) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_RGB24:\n        if (s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    default:\n        break;\n    }\n\n    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {\n        w_align = FFMAX(w_align, 8);\n    }\n\n    *width  = FFALIGN(*width, w_align);\n    *height = FFALIGN(*height, h_align);\n    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres) {\n        // some of the optimized chroma MC reads one line too much\n        // which is also done in mpeg decoders with lowres > 0\n        *height += 2;\n\n        // H.264 uses edge emulation for out of frame motion vectors, for this\n        // it requires a temporary area large enough to hold a 21x21 block,\n        // increasing witdth ensure that the temporary area is large enough,\n        // the next rounded up width is 32\n        *width = FFMAX(*width, 32);\n    }\n\n    for (i = 0; i < 4; i++)\n        linesize_align[i] = STRIDE_ALIGN;\n}\n\nvoid avcodec_align_dimensions(AVCodecContext *s, int *width, int *height)\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(s->pix_fmt);\n    int chroma_shift = desc->log2_chroma_w;\n    int linesize_align[AV_NUM_DATA_POINTERS];\n    int align;\n\n    avcodec_align_dimensions2(s, width, height, linesize_align);\n    align               = FFMAX(linesize_align[0], linesize_align[3]);\n    linesize_align[1] <<= chroma_shift;\n    linesize_align[2] <<= chroma_shift;\n    align               = FFMAX3(align, linesize_align[1], linesize_align[2]);\n    *width              = FFALIGN(*width, align);\n}\n\nint avcodec_enum_to_chroma_pos(int *xpos, int *ypos, enum AVChromaLocation pos)\n{\n    if (pos <= AVCHROMA_LOC_UNSPECIFIED || pos >= AVCHROMA_LOC_NB)\n        return AVERROR(EINVAL);\n    pos--;\n\n    *xpos = (pos&1) * 128;\n    *ypos = ((pos>>1)^(pos<4)) * 128;\n\n    return 0;\n}\n\nenum AVChromaLocation avcodec_chroma_pos_to_enum(int xpos, int ypos)\n{\n    int pos, xout, yout;\n\n    for (pos = AVCHROMA_LOC_UNSPECIFIED + 1; pos < AVCHROMA_LOC_NB; pos++) {\n        if (avcodec_enum_to_chroma_pos(&xout, &yout, pos) == 0 && xout == xpos && yout == ypos)\n            return pos;\n    }\n    return AVCHROMA_LOC_UNSPECIFIED;\n}\n\nint avcodec_fill_audio_frame(AVFrame *frame, int nb_channels,\n                             enum AVSampleFormat sample_fmt, const uint8_t *buf,\n                             int buf_size, int align)\n{\n    int ch, planar, needed_size, ret = 0;\n\n    needed_size = av_samples_get_buffer_size(NULL, nb_channels,\n                                             frame->nb_samples, sample_fmt,\n                                             align);\n    if (buf_size < needed_size)\n        return AVERROR(EINVAL);\n\n    planar = av_sample_fmt_is_planar(sample_fmt);\n    if (planar && nb_channels > AV_NUM_DATA_POINTERS) {\n        if (!(frame->extended_data = av_mallocz_array(nb_channels,\n                                                sizeof(*frame->extended_data))))\n            return AVERROR(ENOMEM);\n    } else {\n        frame->extended_data = frame->data;\n    }\n\n    if ((ret = av_samples_fill_arrays(frame->extended_data, &frame->linesize[0],\n                                      (uint8_t *)(intptr_t)buf, nb_channels, frame->nb_samples,\n                                      sample_fmt, align)) < 0) {\n        if (frame->extended_data != frame->data)\n            av_freep(&frame->extended_data);\n        return ret;\n    }\n    if (frame->extended_data != frame->data) {\n        for (ch = 0; ch < AV_NUM_DATA_POINTERS; ch++)\n            frame->data[ch] = frame->extended_data[ch];\n    }\n\n    return ret;\n}\n\nstatic int update_frame_pool(AVCodecContext *avctx, AVFrame *frame)\n{\n    FramePool *pool = avctx->internal->pool;\n    int i, ret;\n\n    switch (avctx->codec_type) {\n    case AVMEDIA_TYPE_VIDEO: {\n        uint8_t *data[4];\n        int linesize[4];\n        int size[4] = { 0 };\n        int w = frame->width;\n        int h = frame->height;\n        int tmpsize, unaligned;\n\n        if (pool->format == frame->format &&\n            pool->width == frame->width && pool->height == frame->height)\n            return 0;\n\n        avcodec_align_dimensions2(avctx, &w, &h, pool->stride_align);\n\n        do {\n            // NOTE: do not align linesizes individually, this breaks e.g. assumptions\n            // that linesize[0] == 2*linesize[1] in the MPEG-encoder for 4:2:2\n            ret = av_image_fill_linesizes(linesize, avctx->pix_fmt, w);\n            if (ret < 0)\n                return ret;\n            // increase alignment of w for next try (rhs gives the lowest bit set in w)\n            w += w & ~(w - 1);\n\n            unaligned = 0;\n            for (i = 0; i < 4; i++)\n                unaligned |= linesize[i] % pool->stride_align[i];\n        } while (unaligned);\n\n        tmpsize = av_image_fill_pointers(data, avctx->pix_fmt, h,\n                                         NULL, linesize);\n        if (tmpsize < 0)\n            return -1;\n\n        for (i = 0; i < 3 && data[i + 1]; i++)\n            size[i] = data[i + 1] - data[i];\n        size[i] = tmpsize - (data[i] - data[0]);\n\n        for (i = 0; i < 4; i++) {\n            av_buffer_pool_uninit(&pool->pools[i]);\n            pool->linesize[i] = linesize[i];\n            if (size[i]) {\n                pool->pools[i] = av_buffer_pool_init(size[i] + 16 + STRIDE_ALIGN - 1,\n                                                     CONFIG_MEMORY_POISONING ?\n                                                        NULL :\n                                                        av_buffer_allocz);\n                if (!pool->pools[i]) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n            }\n        }\n        pool->format = frame->format;\n        pool->width  = frame->width;\n        pool->height = frame->height;\n\n        break;\n        }\n    case AVMEDIA_TYPE_AUDIO: {\n        int ch     = av_frame_get_channels(frame); //av_get_channel_layout_nb_channels(frame->channel_layout);\n        int planar = av_sample_fmt_is_planar(frame->format);\n        int planes = planar ? ch : 1;\n\n        if (pool->format == frame->format && pool->planes == planes &&\n            pool->channels == ch && frame->nb_samples == pool->samples)\n            return 0;\n\n        av_buffer_pool_uninit(&pool->pools[0]);\n        ret = av_samples_get_buffer_size(&pool->linesize[0], ch,\n                                         frame->nb_samples, frame->format, 0);\n        if (ret < 0)\n            goto fail;\n\n        pool->pools[0] = av_buffer_pool_init(pool->linesize[0], NULL);\n        if (!pool->pools[0]) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n\n        pool->format     = frame->format;\n        pool->planes     = planes;\n        pool->channels   = ch;\n        pool->samples = frame->nb_samples;\n        break;\n        }\n    default: av_assert0(0);\n    }\n    return 0;\nfail:\n    for (i = 0; i < 4; i++)\n        av_buffer_pool_uninit(&pool->pools[i]);\n    pool->format = -1;\n    pool->planes = pool->channels = pool->samples = 0;\n    pool->width  = pool->height = 0;\n    return ret;\n}\n\nstatic int audio_get_buffer(AVCodecContext *avctx, AVFrame *frame)\n{\n    FramePool *pool = avctx->internal->pool;\n    int planes = pool->planes;\n    int i;\n\n    frame->linesize[0] = pool->linesize[0];\n\n    if (planes > AV_NUM_DATA_POINTERS) {\n        frame->extended_data = av_mallocz_array(planes, sizeof(*frame->extended_data));\n        frame->nb_extended_buf = planes - AV_NUM_DATA_POINTERS;\n        frame->extended_buf  = av_mallocz_array(frame->nb_extended_buf,\n                                          sizeof(*frame->extended_buf));\n        if (!frame->extended_data || !frame->extended_buf) {\n            av_freep(&frame->extended_data);\n            av_freep(&frame->extended_buf);\n            return AVERROR(ENOMEM);\n        }\n    } else {\n        frame->extended_data = frame->data;\n        av_assert0(frame->nb_extended_buf == 0);\n    }\n\n    for (i = 0; i < FFMIN(planes, AV_NUM_DATA_POINTERS); i++) {\n        frame->buf[i] = av_buffer_pool_get(pool->pools[0]);\n        if (!frame->buf[i])\n            goto fail;\n        frame->extended_data[i] = frame->data[i] = frame->buf[i]->data;\n    }\n    for (i = 0; i < frame->nb_extended_buf; i++) {\n        frame->extended_buf[i] = av_buffer_pool_get(pool->pools[0]);\n        if (!frame->extended_buf[i])\n            goto fail;\n        frame->extended_data[i + AV_NUM_DATA_POINTERS] = frame->extended_buf[i]->data;\n    }\n\n    if (avctx->debug & FF_DEBUG_BUFFERS)\n        av_log(avctx, AV_LOG_DEBUG, \"default_get_buffer called on frame %p\", frame);\n\n    return 0;\nfail:\n    av_frame_unref(frame);\n    return AVERROR(ENOMEM);\n}\n\nstatic int video_get_buffer(AVCodecContext *s, AVFrame *pic)\n{\n    FramePool *pool = s->internal->pool;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(pic->format);\n    int i;\n\n    if (pic->data[0] || pic->data[1] || pic->data[2] || pic->data[3]) {\n        av_log(s, AV_LOG_ERROR, \"pic->data[*]!=NULL in avcodec_default_get_buffer\\n\");\n        return -1;\n    }\n\n    if (!desc) {\n        av_log(s, AV_LOG_ERROR,\n            \"Unable to get pixel format descriptor for format %s\\n\",\n            av_get_pix_fmt_name(pic->format));\n        return AVERROR(EINVAL);\n    }\n\n    memset(pic->data, 0, sizeof(pic->data));\n    pic->extended_data = pic->data;\n\n    for (i = 0; i < 4 && pool->pools[i]; i++) {\n        pic->linesize[i] = pool->linesize[i];\n\n        pic->buf[i] = av_buffer_pool_get(pool->pools[i]);\n        if (!pic->buf[i])\n            goto fail;\n\n        pic->data[i] = pic->buf[i]->data;\n    }\n    for (; i < AV_NUM_DATA_POINTERS; i++) {\n        pic->data[i] = NULL;\n        pic->linesize[i] = 0;\n    }\n    if (desc->flags & AV_PIX_FMT_FLAG_PAL ||\n        desc->flags & AV_PIX_FMT_FLAG_PSEUDOPAL)\n        avpriv_set_systematic_pal2((uint32_t *)pic->data[1], pic->format);\n\n    if (s->debug & FF_DEBUG_BUFFERS)\n        av_log(s, AV_LOG_DEBUG, \"default_get_buffer called on pic %p\\n\", pic);\n\n    return 0;\nfail:\n    av_frame_unref(pic);\n    return AVERROR(ENOMEM);\n}\n\nvoid ff_color_frame(AVFrame *frame, const int c[4])\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n    int p, y, x;\n\n    av_assert0(desc->flags & AV_PIX_FMT_FLAG_PLANAR);\n\n    for (p = 0; p<desc->nb_components; p++) {\n        uint8_t *dst = frame->data[p];\n        int is_chroma = p == 1 || p == 2;\n        int bytes  = is_chroma ? AV_CEIL_RSHIFT(frame->width,  desc->log2_chroma_w) : frame->width;\n        int height = is_chroma ? AV_CEIL_RSHIFT(frame->height, desc->log2_chroma_h) : frame->height;\n        for (y = 0; y < height; y++) {\n            if (desc->comp[0].depth >= 9) {\n                for (x = 0; x<bytes; x++)\n                    ((uint16_t*)dst)[x] = c[p];\n            }else\n                memset(dst, c[p], bytes);\n            dst += frame->linesize[p];\n        }\n    }\n}\n\nint avcodec_default_get_buffer2(AVCodecContext *avctx, AVFrame *frame, int flags)\n{\n    int ret;\n\n    if (avctx->hw_frames_ctx)\n        return av_hwframe_get_buffer(avctx->hw_frames_ctx, frame, 0);\n\n    if ((ret = update_frame_pool(avctx, frame)) < 0)\n        return ret;\n\n    switch (avctx->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        return video_get_buffer(avctx, frame);\n    case AVMEDIA_TYPE_AUDIO:\n        return audio_get_buffer(avctx, frame);\n    default:\n        return -1;\n    }\n}\n\nstatic int add_metadata_from_side_data(AVPacket *avpkt, AVFrame *frame)\n{\n    int size;\n    const uint8_t *side_metadata;\n\n    AVDictionary **frame_md = avpriv_frame_get_metadatap(frame);\n\n    side_metadata = av_packet_get_side_data(avpkt,\n                                            AV_PKT_DATA_STRINGS_METADATA, &size);\n    return av_packet_unpack_dictionary(side_metadata, size, frame_md);\n}\n\nint ff_init_buffer_info(AVCodecContext *avctx, AVFrame *frame)\n{\n    AVPacket *pkt = avctx->internal->pkt;\n    int i;\n    static const struct {\n        enum AVPacketSideDataType packet;\n        enum AVFrameSideDataType frame;\n    } sd[] = {\n        { AV_PKT_DATA_REPLAYGAIN ,                AV_FRAME_DATA_REPLAYGAIN },\n        { AV_PKT_DATA_DISPLAYMATRIX,              AV_FRAME_DATA_DISPLAYMATRIX },\n        { AV_PKT_DATA_SPHERICAL,                  AV_FRAME_DATA_SPHERICAL },\n        { AV_PKT_DATA_STEREO3D,                   AV_FRAME_DATA_STEREO3D },\n        { AV_PKT_DATA_AUDIO_SERVICE_TYPE,         AV_FRAME_DATA_AUDIO_SERVICE_TYPE },\n        { AV_PKT_DATA_MASTERING_DISPLAY_METADATA, AV_FRAME_DATA_MASTERING_DISPLAY_METADATA },\n    };\n\n    if (pkt) {\n        frame->pts = pkt->pts;\n#if FF_API_PKT_PTS\nFF_DISABLE_DEPRECATION_WARNINGS\n        frame->pkt_pts = pkt->pts;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n        av_frame_set_pkt_pos     (frame, pkt->pos);\n        av_frame_set_pkt_duration(frame, pkt->duration);\n        av_frame_set_pkt_size    (frame, pkt->size);\n\n        for (i = 0; i < FF_ARRAY_ELEMS(sd); i++) {\n            int size;\n            uint8_t *packet_sd = av_packet_get_side_data(pkt, sd[i].packet, &size);\n            if (packet_sd) {\n                AVFrameSideData *frame_sd = av_frame_new_side_data(frame,\n                                                                   sd[i].frame,\n                                                                   size);\n                if (!frame_sd)\n                    return AVERROR(ENOMEM);\n\n                memcpy(frame_sd->data, packet_sd, size);\n            }\n        }\n        add_metadata_from_side_data(pkt, frame);\n\n        if (pkt->flags & AV_PKT_FLAG_DISCARD) {\n            frame->flags |= AV_FRAME_FLAG_DISCARD;\n        } else {\n            frame->flags = (frame->flags & ~AV_FRAME_FLAG_DISCARD);\n        }\n    } else {\n        frame->pts = AV_NOPTS_VALUE;\n#if FF_API_PKT_PTS\nFF_DISABLE_DEPRECATION_WARNINGS\n        frame->pkt_pts = AV_NOPTS_VALUE;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n        av_frame_set_pkt_pos     (frame, -1);\n        av_frame_set_pkt_duration(frame, 0);\n        av_frame_set_pkt_size    (frame, -1);\n    }\n    frame->reordered_opaque = avctx->reordered_opaque;\n\n    if (frame->color_primaries == AVCOL_PRI_UNSPECIFIED)\n        frame->color_primaries = avctx->color_primaries;\n    if (frame->color_trc == AVCOL_TRC_UNSPECIFIED)\n        frame->color_trc = avctx->color_trc;\n    if (av_frame_get_colorspace(frame) == AVCOL_SPC_UNSPECIFIED)\n        av_frame_set_colorspace(frame, avctx->colorspace);\n    if (av_frame_get_color_range(frame) == AVCOL_RANGE_UNSPECIFIED)\n        av_frame_set_color_range(frame, avctx->color_range);\n    if (frame->chroma_location == AVCHROMA_LOC_UNSPECIFIED)\n        frame->chroma_location = avctx->chroma_sample_location;\n\n    switch (avctx->codec->type) {\n    case AVMEDIA_TYPE_VIDEO:\n        frame->format              = avctx->pix_fmt;\n        if (!frame->sample_aspect_ratio.num)\n            frame->sample_aspect_ratio = avctx->sample_aspect_ratio;\n\n        if (frame->width && frame->height &&\n            av_image_check_sar(frame->width, frame->height,\n                               frame->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   frame->sample_aspect_ratio.num,\n                   frame->sample_aspect_ratio.den);\n            frame->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        if (!frame->sample_rate)\n            frame->sample_rate    = avctx->sample_rate;\n        if (frame->format < 0)\n            frame->format         = avctx->sample_fmt;\n        if (!frame->channel_layout) {\n            if (avctx->channel_layout) {\n                 if (av_get_channel_layout_nb_channels(avctx->channel_layout) !=\n                     avctx->channels) {\n                     av_log(avctx, AV_LOG_ERROR, \"Inconsistent channel \"\n                            \"configuration.\\n\");\n                     return AVERROR(EINVAL);\n                 }\n\n                frame->channel_layout = avctx->channel_layout;\n            } else {\n                if (avctx->channels > FF_SANE_NB_CHANNELS) {\n                    av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d.\\n\",\n                           avctx->channels);\n                    return AVERROR(ENOSYS);\n                }\n            }\n        }\n        av_frame_set_channels(frame, avctx->channels);\n        break;\n    }\n    return 0;\n}\n\nint ff_decode_frame_props(AVCodecContext *avctx, AVFrame *frame)\n{\n    return ff_init_buffer_info(avctx, frame);\n}\n\nstatic void validate_avframe_allocation(AVCodecContext *avctx, AVFrame *frame)\n{\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n        int i;\n        int num_planes = av_pix_fmt_count_planes(frame->format);\n        const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n        int flags = desc ? desc->flags : 0;\n        if (num_planes == 1 && (flags & AV_PIX_FMT_FLAG_PAL))\n            num_planes = 2;\n        for (i = 0; i < num_planes; i++) {\n            av_assert0(frame->data[i]);\n        }\n        // For now do not enforce anything for palette of pseudopal formats\n        if (num_planes == 1 && (flags & AV_PIX_FMT_FLAG_PSEUDOPAL))\n            num_planes = 2;\n        // For formats without data like hwaccel allow unused pointers to be non-NULL.\n        for (i = num_planes; num_planes > 0 && i < FF_ARRAY_ELEMS(frame->data); i++) {\n            if (frame->data[i])\n                av_log(avctx, AV_LOG_ERROR, \"Buffer returned by get_buffer2() did not zero unused plane pointers\\n\");\n            frame->data[i] = NULL;\n        }\n    }\n}\n\nstatic int get_buffer_internal(AVCodecContext *avctx, AVFrame *frame, int flags)\n{\n    const AVHWAccel *hwaccel = avctx->hwaccel;\n    int override_dimensions = 1;\n    int ret;\n\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n        if ((ret = av_image_check_size2(avctx->width, avctx->height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx)) < 0 || avctx->pix_fmt<0) {\n            av_log(avctx, AV_LOG_ERROR, \"video_get_buffer: image parameters invalid\\n\");\n            return AVERROR(EINVAL);\n        }\n\n        if (frame->width <= 0 || frame->height <= 0) {\n            frame->width  = FFMAX(avctx->width,  AV_CEIL_RSHIFT(avctx->coded_width,  avctx->lowres));\n            frame->height = FFMAX(avctx->height, AV_CEIL_RSHIFT(avctx->coded_height, avctx->lowres));\n            override_dimensions = 0;\n        }\n\n        if (frame->data[0] || frame->data[1] || frame->data[2] || frame->data[3]) {\n            av_log(avctx, AV_LOG_ERROR, \"pic->data[*]!=NULL in get_buffer_internal\\n\");\n            return AVERROR(EINVAL);\n        }\n    }\n    ret = ff_decode_frame_props(avctx, frame);\n    if (ret < 0)\n        return ret;\n\n    if (hwaccel) {\n        if (hwaccel->alloc_frame) {\n            ret = hwaccel->alloc_frame(avctx, frame);\n            goto end;\n        }\n    } else\n        avctx->sw_pix_fmt = avctx->pix_fmt;\n\n    ret = avctx->get_buffer2(avctx, frame, flags);\n    if (ret >= 0)\n        validate_avframe_allocation(avctx, frame);\n\nend:\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO && !override_dimensions) {\n        frame->width  = avctx->width;\n        frame->height = avctx->height;\n    }\n\n    return ret;\n}\n\nint ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags)\n{\n    int ret = get_buffer_internal(avctx, frame, flags);\n    if (ret < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n        frame->width = frame->height = 0;\n    }\n    return ret;\n}\n\nstatic int reget_buffer_internal(AVCodecContext *avctx, AVFrame *frame)\n{\n    AVFrame *tmp;\n    int ret;\n\n    av_assert0(avctx->codec_type == AVMEDIA_TYPE_VIDEO);\n\n    if (frame->data[0] && (frame->width != avctx->width || frame->height != avctx->height || frame->format != avctx->pix_fmt)) {\n        av_log(avctx, AV_LOG_WARNING, \"Picture changed from size:%dx%d fmt:%s to size:%dx%d fmt:%s in reget buffer()\\n\",\n               frame->width, frame->height, av_get_pix_fmt_name(frame->format), avctx->width, avctx->height, av_get_pix_fmt_name(avctx->pix_fmt));\n        av_frame_unref(frame);\n    }\n\n    ff_init_buffer_info(avctx, frame);\n\n    if (!frame->data[0])\n        return ff_get_buffer(avctx, frame, AV_GET_BUFFER_FLAG_REF);\n\n    if (av_frame_is_writable(frame))\n        return ff_decode_frame_props(avctx, frame);\n\n    tmp = av_frame_alloc();\n    if (!tmp)\n        return AVERROR(ENOMEM);\n\n    av_frame_move_ref(tmp, frame);\n\n    ret = ff_get_buffer(avctx, frame, AV_GET_BUFFER_FLAG_REF);\n    if (ret < 0) {\n        av_frame_free(&tmp);\n        return ret;\n    }\n\n    av_frame_copy(frame, tmp);\n    av_frame_free(&tmp);\n\n    return 0;\n}\n\nint ff_reget_buffer(AVCodecContext *avctx, AVFrame *frame)\n{\n    int ret = reget_buffer_internal(avctx, frame);\n    if (ret < 0)\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n    return ret;\n}\n\nint avcodec_default_execute(AVCodecContext *c, int (*func)(AVCodecContext *c2, void *arg2), void *arg, int *ret, int count, int size)\n{\n    int i;\n\n    for (i = 0; i < count; i++) {\n        int r = func(c, (char *)arg + i * size);\n        if (ret)\n            ret[i] = r;\n    }\n    emms_c();\n    return 0;\n}\n\nint avcodec_default_execute2(AVCodecContext *c, int (*func)(AVCodecContext *c2, void *arg2, int jobnr, int threadnr), void *arg, int *ret, int count)\n{\n    int i;\n\n    for (i = 0; i < count; i++) {\n        int r = func(c, arg, i, 0);\n        if (ret)\n            ret[i] = r;\n    }\n    emms_c();\n    return 0;\n}\n\nenum AVPixelFormat avpriv_find_pix_fmt(const PixelFormatTag *tags,\n                                       unsigned int fourcc)\n{\n    while (tags->pix_fmt >= 0) {\n        if (tags->fourcc == fourcc)\n            return tags->pix_fmt;\n        tags++;\n    }\n    return AV_PIX_FMT_NONE;\n}\n\nstatic int is_hwaccel_pix_fmt(enum AVPixelFormat pix_fmt)\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(pix_fmt);\n    return desc->flags & AV_PIX_FMT_FLAG_HWACCEL;\n}\n\nenum AVPixelFormat avcodec_default_get_format(struct AVCodecContext *s, const enum AVPixelFormat *fmt)\n{\n    while (*fmt != AV_PIX_FMT_NONE && is_hwaccel_pix_fmt(*fmt))\n        ++fmt;\n    return fmt[0];\n}\n\nstatic AVHWAccel *find_hwaccel(enum AVCodecID codec_id,\n                               enum AVPixelFormat pix_fmt)\n{\n    AVHWAccel *hwaccel = NULL;\n\n    while ((hwaccel = av_hwaccel_next(hwaccel)))\n        if (hwaccel->id == codec_id\n            && hwaccel->pix_fmt == pix_fmt)\n            return hwaccel;\n    return NULL;\n}\n\nstatic int setup_hwaccel(AVCodecContext *avctx,\n                         const enum AVPixelFormat fmt,\n                         const char *name)\n{\n    AVHWAccel *hwa = find_hwaccel(avctx->codec_id, fmt);\n    int ret        = 0;\n\n    if (avctx->active_thread_type & FF_THREAD_FRAME) {\n        av_log(avctx, AV_LOG_WARNING,\n               \"Hardware accelerated decoding with frame threading is known to be unstable and its use is discouraged.\\n\");\n    }\n\n    if (!hwa) {\n        av_log(avctx, AV_LOG_ERROR,\n               \"Could not find an AVHWAccel for the pixel format: %s\",\n               name);\n        return AVERROR(ENOENT);\n    }\n\n    if (hwa->capabilities & HWACCEL_CODEC_CAP_EXPERIMENTAL &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring experimental hwaccel: %s\\n\",\n               hwa->name);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    if (hwa->priv_data_size) {\n        avctx->internal->hwaccel_priv_data = av_mallocz(hwa->priv_data_size);\n        if (!avctx->internal->hwaccel_priv_data)\n            return AVERROR(ENOMEM);\n    }\n\n    if (hwa->init) {\n        ret = hwa->init(avctx);\n        if (ret < 0) {\n            av_freep(&avctx->internal->hwaccel_priv_data);\n            return ret;\n        }\n    }\n\n    avctx->hwaccel = hwa;\n\n    return 0;\n}\n\nint ff_get_format(AVCodecContext *avctx, const enum AVPixelFormat *fmt)\n{\n    const AVPixFmtDescriptor *desc;\n    enum AVPixelFormat *choices;\n    enum AVPixelFormat ret;\n    unsigned n = 0;\n\n    while (fmt[n] != AV_PIX_FMT_NONE)\n        ++n;\n\n    av_assert0(n >= 1);\n    avctx->sw_pix_fmt = fmt[n - 1];\n    av_assert2(!is_hwaccel_pix_fmt(avctx->sw_pix_fmt));\n\n    choices = av_malloc_array(n + 1, sizeof(*choices));\n    if (!choices)\n        return AV_PIX_FMT_NONE;\n\n    memcpy(choices, fmt, (n + 1) * sizeof(*choices));\n\n    for (;;) {\n        if (avctx->hwaccel && avctx->hwaccel->uninit)\n            avctx->hwaccel->uninit(avctx);\n        av_freep(&avctx->internal->hwaccel_priv_data);\n        avctx->hwaccel = NULL;\n\n        av_buffer_unref(&avctx->hw_frames_ctx);\n\n        ret = avctx->get_format(avctx, choices);\n\n        desc = av_pix_fmt_desc_get(ret);\n        if (!desc) {\n            ret = AV_PIX_FMT_NONE;\n            break;\n        }\n\n        if (!(desc->flags & AV_PIX_FMT_FLAG_HWACCEL))\n            break;\n#if FF_API_CAP_VDPAU\n        if (avctx->codec->capabilities&AV_CODEC_CAP_HWACCEL_VDPAU)\n            break;\n#endif\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *hw_frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (hw_frames_ctx->format != ret) {\n                av_log(avctx, AV_LOG_ERROR, \"Format returned from get_buffer() \"\n                       \"does not match the format of provided AVHWFramesContext\\n\");\n                ret = AV_PIX_FMT_NONE;\n                break;\n            }\n        }\n\n        if (!setup_hwaccel(avctx, ret, desc->name))\n            break;\n\n        /* Remove failed hwaccel from choices */\n        for (n = 0; choices[n] != ret; n++)\n            av_assert0(choices[n] != AV_PIX_FMT_NONE);\n\n        do\n            choices[n] = choices[n + 1];\n        while (choices[n++] != AV_PIX_FMT_NONE);\n    }\n\n    av_freep(&choices);\n    return ret;\n}\n\nMAKE_ACCESSORS(AVCodecContext, codec, AVRational, pkt_timebase)\nMAKE_ACCESSORS(AVCodecContext, codec, const AVCodecDescriptor *, codec_descriptor)\nMAKE_ACCESSORS(AVCodecContext, codec, int, lowres)\nMAKE_ACCESSORS(AVCodecContext, codec, int, seek_preroll)\nMAKE_ACCESSORS(AVCodecContext, codec, uint16_t*, chroma_intra_matrix)\n\nunsigned av_codec_get_codec_properties(const AVCodecContext *codec)\n{\n    return codec->properties;\n}\n\nint av_codec_get_max_lowres(const AVCodec *codec)\n{\n    return codec->max_lowres;\n}\n\nint avpriv_codec_get_cap_skip_frame_fill_param(const AVCodec *codec){\n    return !!(codec->caps_internal & FF_CODEC_CAP_SKIP_FRAME_FILL_PARAM);\n}\n\nstatic void get_subtitle_defaults(AVSubtitle *sub)\n{\n    memset(sub, 0, sizeof(*sub));\n    sub->pts = AV_NOPTS_VALUE;\n}\n\nstatic int64_t get_bit_rate(AVCodecContext *ctx)\n{\n    int64_t bit_rate;\n    int bits_per_sample;\n\n    switch (ctx->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n    case AVMEDIA_TYPE_DATA:\n    case AVMEDIA_TYPE_SUBTITLE:\n    case AVMEDIA_TYPE_ATTACHMENT:\n        bit_rate = ctx->bit_rate;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        bits_per_sample = av_get_bits_per_sample(ctx->codec_id);\n        bit_rate = bits_per_sample ? ctx->sample_rate * (int64_t)ctx->channels * bits_per_sample : ctx->bit_rate;\n        break;\n    default:\n        bit_rate = 0;\n        break;\n    }\n    return bit_rate;\n}\n\nint attribute_align_arg ff_codec_open2_recursive(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n\n    ff_unlock_avcodec(codec);\n\n    ret = avcodec_open2(avctx, codec, options);\n\n    ff_lock_avcodec(avctx, codec);\n    return ret;\n}\n\nint attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ret = ff_lock_avcodec(avctx, codec);\n    if (ret < 0)\n        return ret;\n\n    avctx->internal = av_mallocz(sizeof(AVCodecInternal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n#if FF_API_VISMV\n    if (avctx->debug_mv)\n        av_log(avctx, AV_LOG_WARNING, \"The 'vismv' option is deprecated, \"\n               \"see the codecview filter instead.\\n\");\n#endif\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", (int64_t)avctx->bit_rate, (int64_t)avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3 / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n\n    ret=0;\n\n#if FF_API_AUDIOENC_DELAY\n    if (av_codec_is_encoder(avctx->codec))\n        avctx->delay = avctx->initial_padding;\n#endif\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec &&\n        (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_frame_free(&avctx->internal->to_free);\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}\n\nint ff_alloc_packet2(AVCodecContext *avctx, AVPacket *avpkt, int64_t size, int64_t min_size)\n{\n    if (avpkt->size < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid negative user packet size %d\\n\", avpkt->size);\n        return AVERROR(EINVAL);\n    }\n    if (size < 0 || size > INT_MAX - AV_INPUT_BUFFER_PADDING_SIZE) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid minimum required packet size %\"PRId64\" (max allowed is %d)\\n\",\n               size, INT_MAX - AV_INPUT_BUFFER_PADDING_SIZE);\n        return AVERROR(EINVAL);\n    }\n\n    if (avctx && 2*min_size < size) { // FIXME The factor needs to be finetuned\n        av_assert0(!avpkt->data || avpkt->data != avctx->internal->byte_buffer);\n        if (!avpkt->data || avpkt->size < size) {\n            av_fast_padded_malloc(&avctx->internal->byte_buffer, &avctx->internal->byte_buffer_size, size);\n            avpkt->data = avctx->internal->byte_buffer;\n            avpkt->size = avctx->internal->byte_buffer_size;\n        }\n    }\n\n    if (avpkt->data) {\n        AVBufferRef *buf = avpkt->buf;\n\n        if (avpkt->size < size) {\n            av_log(avctx, AV_LOG_ERROR, \"User packet is too small (%d < %\"PRId64\")\\n\", avpkt->size, size);\n            return AVERROR(EINVAL);\n        }\n\n        av_init_packet(avpkt);\n        avpkt->buf      = buf;\n        avpkt->size     = size;\n        return 0;\n    } else {\n        int ret = av_new_packet(avpkt, size);\n        if (ret < 0)\n            av_log(avctx, AV_LOG_ERROR, \"Failed to allocate packet of size %\"PRId64\"\\n\", size);\n        return ret;\n    }\n}\n\nint ff_alloc_packet(AVPacket *avpkt, int size)\n{\n    return ff_alloc_packet2(NULL, avpkt, size, 0);\n}\n\n/**\n * Pad last frame with silence.\n */\nstatic int pad_last_frame(AVCodecContext *s, AVFrame **dst, const AVFrame *src)\n{\n    AVFrame *frame = NULL;\n    int ret;\n\n    if (!(frame = av_frame_alloc()))\n        return AVERROR(ENOMEM);\n\n    frame->format         = src->format;\n    frame->channel_layout = src->channel_layout;\n    av_frame_set_channels(frame, av_frame_get_channels(src));\n    frame->nb_samples     = s->frame_size;\n    ret = av_frame_get_buffer(frame, 32);\n    if (ret < 0)\n        goto fail;\n\n    ret = av_frame_copy_props(frame, src);\n    if (ret < 0)\n        goto fail;\n\n    if ((ret = av_samples_copy(frame->extended_data, src->extended_data, 0, 0,\n                               src->nb_samples, s->channels, s->sample_fmt)) < 0)\n        goto fail;\n    if ((ret = av_samples_set_silence(frame->extended_data, src->nb_samples,\n                                      frame->nb_samples - src->nb_samples,\n                                      s->channels, s->sample_fmt)) < 0)\n        goto fail;\n\n    *dst = frame;\n\n    return 0;\n\nfail:\n    av_frame_free(&frame);\n    return ret;\n}\n\nint attribute_align_arg avcodec_encode_audio2(AVCodecContext *avctx,\n                                              AVPacket *avpkt,\n                                              const AVFrame *frame,\n                                              int *got_packet_ptr)\n{\n    AVFrame *extended_frame = NULL;\n    AVFrame *padded_frame = NULL;\n    int ret;\n    AVPacket user_pkt = *avpkt;\n    int needs_realloc = !user_pkt.data;\n\n    *got_packet_ptr = 0;\n\n    if (!avctx->codec->encode2) {\n        av_log(avctx, AV_LOG_ERROR, \"This encoder requires using the avcodec_send_frame() API.\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY) && !frame) {\n        av_packet_unref(avpkt);\n        av_init_packet(avpkt);\n        return 0;\n    }\n\n    /* ensure that extended_data is properly set */\n    if (frame && !frame->extended_data) {\n        if (av_sample_fmt_is_planar(avctx->sample_fmt) &&\n            avctx->channels > AV_NUM_DATA_POINTERS) {\n            av_log(avctx, AV_LOG_ERROR, \"Encoding to a planar sample format, \"\n                                        \"with more than %d channels, but extended_data is not set.\\n\",\n                   AV_NUM_DATA_POINTERS);\n            return AVERROR(EINVAL);\n        }\n        av_log(avctx, AV_LOG_WARNING, \"extended_data is not set.\\n\");\n\n        extended_frame = av_frame_alloc();\n        if (!extended_frame)\n            return AVERROR(ENOMEM);\n\n        memcpy(extended_frame, frame, sizeof(AVFrame));\n        extended_frame->extended_data = extended_frame->data;\n        frame = extended_frame;\n    }\n\n    /* extract audio service type metadata */\n    if (frame) {\n        AVFrameSideData *sd = av_frame_get_side_data(frame, AV_FRAME_DATA_AUDIO_SERVICE_TYPE);\n        if (sd && sd->size >= sizeof(enum AVAudioServiceType))\n            avctx->audio_service_type = *(enum AVAudioServiceType*)sd->data;\n    }\n\n    /* check for valid frame size */\n    if (frame) {\n        if (avctx->codec->capabilities & AV_CODEC_CAP_SMALL_LAST_FRAME) {\n            if (frame->nb_samples > avctx->frame_size) {\n                av_log(avctx, AV_LOG_ERROR, \"more samples than frame size (avcodec_encode_audio2)\\n\");\n                ret = AVERROR(EINVAL);\n                goto end;\n            }\n        } else if (!(avctx->codec->capabilities & AV_CODEC_CAP_VARIABLE_FRAME_SIZE)) {\n            if (frame->nb_samples < avctx->frame_size &&\n                !avctx->internal->last_audio_frame) {\n                ret = pad_last_frame(avctx, &padded_frame, frame);\n                if (ret < 0)\n                    goto end;\n\n                frame = padded_frame;\n                avctx->internal->last_audio_frame = 1;\n            }\n\n            if (frame->nb_samples != avctx->frame_size) {\n                av_log(avctx, AV_LOG_ERROR, \"nb_samples (%d) != frame_size (%d) (avcodec_encode_audio2)\\n\", frame->nb_samples, avctx->frame_size);\n                ret = AVERROR(EINVAL);\n                goto end;\n            }\n        }\n    }\n\n    av_assert0(avctx->codec->encode2);\n\n    ret = avctx->codec->encode2(avctx, avpkt, frame, got_packet_ptr);\n    if (!ret) {\n        if (*got_packet_ptr) {\n            if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY)) {\n                if (avpkt->pts == AV_NOPTS_VALUE)\n                    avpkt->pts = frame->pts;\n                if (!avpkt->duration)\n                    avpkt->duration = ff_samples_to_time_base(avctx,\n                                                              frame->nb_samples);\n            }\n            avpkt->dts = avpkt->pts;\n        } else {\n            avpkt->size = 0;\n        }\n    }\n    if (avpkt->data && avpkt->data == avctx->internal->byte_buffer) {\n        needs_realloc = 0;\n        if (user_pkt.data) {\n            if (user_pkt.size >= avpkt->size) {\n                memcpy(user_pkt.data, avpkt->data, avpkt->size);\n            } else {\n                av_log(avctx, AV_LOG_ERROR, \"Provided packet is too small, needs to be %d\\n\", avpkt->size);\n                avpkt->size = user_pkt.size;\n                ret = -1;\n            }\n            avpkt->buf      = user_pkt.buf;\n            avpkt->data     = user_pkt.data;\n        } else {\n            if (av_dup_packet(avpkt) < 0) {\n                ret = AVERROR(ENOMEM);\n            }\n        }\n    }\n\n    if (!ret) {\n        if (needs_realloc && avpkt->data) {\n            ret = av_buffer_realloc(&avpkt->buf, avpkt->size + AV_INPUT_BUFFER_PADDING_SIZE);\n            if (ret >= 0)\n                avpkt->data = avpkt->buf->data;\n        }\n\n        avctx->frame_number++;\n    }\n\n    if (ret < 0 || !*got_packet_ptr) {\n        av_packet_unref(avpkt);\n        av_init_packet(avpkt);\n        goto end;\n    }\n\n    /* NOTE: if we add any audio encoders which output non-keyframe packets,\n     *       this needs to be moved to the encoders, but for now we can do it\n     *       here to simplify things */\n    avpkt->flags |= AV_PKT_FLAG_KEY;\n\nend:\n    av_frame_free(&padded_frame);\n    av_free(extended_frame);\n\n#if FF_API_AUDIOENC_DELAY\n    avctx->delay = avctx->initial_padding;\n#endif\n\n    return ret;\n}\n\nint attribute_align_arg avcodec_encode_video2(AVCodecContext *avctx,\n                                              AVPacket *avpkt,\n                                              const AVFrame *frame,\n                                              int *got_packet_ptr)\n{\n    int ret;\n    AVPacket user_pkt = *avpkt;\n    int needs_realloc = !user_pkt.data;\n\n    *got_packet_ptr = 0;\n\n    if (!avctx->codec->encode2) {\n        av_log(avctx, AV_LOG_ERROR, \"This encoder requires using the avcodec_send_frame() API.\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    if(CONFIG_FRAME_THREAD_ENCODER &&\n       avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))\n        return ff_thread_video_encode_frame(avctx, avpkt, frame, got_packet_ptr);\n\n    if ((avctx->flags&AV_CODEC_FLAG_PASS1) && avctx->stats_out)\n        avctx->stats_out[0] = '\\0';\n\n    if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY) && !frame) {\n        av_packet_unref(avpkt);\n        av_init_packet(avpkt);\n        avpkt->size = 0;\n        return 0;\n    }\n\n    if (av_image_check_size2(avctx->width, avctx->height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx))\n        return AVERROR(EINVAL);\n\n    if (frame && frame->format == AV_PIX_FMT_NONE)\n        av_log(avctx, AV_LOG_WARNING, \"AVFrame.format is not set\\n\");\n    if (frame && (frame->width == 0 || frame->height == 0))\n        av_log(avctx, AV_LOG_WARNING, \"AVFrame.width or height is not set\\n\");\n\n    av_assert0(avctx->codec->encode2);\n\n    ret = avctx->codec->encode2(avctx, avpkt, frame, got_packet_ptr);\n    av_assert0(ret <= 0);\n\n    emms_c();\n\n    if (avpkt->data && avpkt->data == avctx->internal->byte_buffer) {\n        needs_realloc = 0;\n        if (user_pkt.data) {\n            if (user_pkt.size >= avpkt->size) {\n                memcpy(user_pkt.data, avpkt->data, avpkt->size);\n            } else {\n                av_log(avctx, AV_LOG_ERROR, \"Provided packet is too small, needs to be %d\\n\", avpkt->size);\n                avpkt->size = user_pkt.size;\n                ret = -1;\n            }\n            avpkt->buf      = user_pkt.buf;\n            avpkt->data     = user_pkt.data;\n        } else {\n            if (av_dup_packet(avpkt) < 0) {\n                ret = AVERROR(ENOMEM);\n            }\n        }\n    }\n\n    if (!ret) {\n        if (!*got_packet_ptr)\n            avpkt->size = 0;\n        else if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            avpkt->pts = avpkt->dts = frame->pts;\n\n        if (needs_realloc && avpkt->data) {\n            ret = av_buffer_realloc(&avpkt->buf, avpkt->size + AV_INPUT_BUFFER_PADDING_SIZE);\n            if (ret >= 0)\n                avpkt->data = avpkt->buf->data;\n        }\n\n        avctx->frame_number++;\n    }\n\n    if (ret < 0 || !*got_packet_ptr)\n        av_packet_unref(avpkt);\n\n    return ret;\n}\n\nint avcodec_encode_subtitle(AVCodecContext *avctx, uint8_t *buf, int buf_size,\n                            const AVSubtitle *sub)\n{\n    int ret;\n    if (sub->start_display_time) {\n        av_log(avctx, AV_LOG_ERROR, \"start_display_time must be 0.\\n\");\n        return -1;\n    }\n\n    ret = avctx->codec->encode_sub(avctx, buf, buf_size, sub);\n    avctx->frame_number++;\n    return ret;\n}\n\n/**\n * Attempt to guess proper monotonic timestamps for decoded video frames\n * which might have incorrect times. Input timestamps may wrap around, in\n * which case the output will as well.\n *\n * @param pts the pts field of the decoded AVPacket, as passed through\n * AVFrame.pts\n * @param dts the dts field of the decoded AVPacket\n * @return one of the input values, may be AV_NOPTS_VALUE\n */\nstatic int64_t guess_correct_pts(AVCodecContext *ctx,\n                                 int64_t reordered_pts, int64_t dts)\n{\n    int64_t pts = AV_NOPTS_VALUE;\n\n    if (dts != AV_NOPTS_VALUE) {\n        ctx->pts_correction_num_faulty_dts += dts <= ctx->pts_correction_last_dts;\n        ctx->pts_correction_last_dts = dts;\n    } else if (reordered_pts != AV_NOPTS_VALUE)\n        ctx->pts_correction_last_dts = reordered_pts;\n\n    if (reordered_pts != AV_NOPTS_VALUE) {\n        ctx->pts_correction_num_faulty_pts += reordered_pts <= ctx->pts_correction_last_pts;\n        ctx->pts_correction_last_pts = reordered_pts;\n    } else if(dts != AV_NOPTS_VALUE)\n        ctx->pts_correction_last_pts = dts;\n\n    if ((ctx->pts_correction_num_faulty_pts<=ctx->pts_correction_num_faulty_dts || dts == AV_NOPTS_VALUE)\n       && reordered_pts != AV_NOPTS_VALUE)\n        pts = reordered_pts;\n    else\n        pts = dts;\n\n    return pts;\n}\n\nstatic int apply_param_change(AVCodecContext *avctx, AVPacket *avpkt)\n{\n    int size = 0, ret;\n    const uint8_t *data;\n    uint32_t flags;\n    int64_t val;\n\n    data = av_packet_get_side_data(avpkt, AV_PKT_DATA_PARAM_CHANGE, &size);\n    if (!data)\n        return 0;\n\n    if (!(avctx->codec->capabilities & AV_CODEC_CAP_PARAM_CHANGE)) {\n        av_log(avctx, AV_LOG_ERROR, \"This decoder does not support parameter \"\n               \"changes, but PARAM_CHANGE side data was sent to it.\\n\");\n        ret = AVERROR(EINVAL);\n        goto fail2;\n    }\n\n    if (size < 4)\n        goto fail;\n\n    flags = bytestream_get_le32(&data);\n    size -= 4;\n\n    if (flags & AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_COUNT) {\n        if (size < 4)\n            goto fail;\n        val = bytestream_get_le32(&data);\n        if (val <= 0 || val > INT_MAX) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid channel count\");\n            ret = AVERROR_INVALIDDATA;\n            goto fail2;\n        }\n        avctx->channels = val;\n        size -= 4;\n    }\n    if (flags & AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_LAYOUT) {\n        if (size < 8)\n            goto fail;\n        avctx->channel_layout = bytestream_get_le64(&data);\n        size -= 8;\n    }\n    if (flags & AV_SIDE_DATA_PARAM_CHANGE_SAMPLE_RATE) {\n        if (size < 4)\n            goto fail;\n        val = bytestream_get_le32(&data);\n        if (val <= 0 || val > INT_MAX) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample rate\");\n            ret = AVERROR_INVALIDDATA;\n            goto fail2;\n        }\n        avctx->sample_rate = val;\n        size -= 4;\n    }\n    if (flags & AV_SIDE_DATA_PARAM_CHANGE_DIMENSIONS) {\n        if (size < 8)\n            goto fail;\n        avctx->width  = bytestream_get_le32(&data);\n        avctx->height = bytestream_get_le32(&data);\n        size -= 8;\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n        if (ret < 0)\n            goto fail2;\n    }\n\n    return 0;\nfail:\n    av_log(avctx, AV_LOG_ERROR, \"PARAM_CHANGE side data too small.\\n\");\n    ret = AVERROR_INVALIDDATA;\nfail2:\n    if (ret < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error applying parameter changes.\\n\");\n        if (avctx->err_recognition & AV_EF_EXPLODE)\n            return ret;\n    }\n    return 0;\n}\n\nstatic int unrefcount_frame(AVCodecInternal *avci, AVFrame *frame)\n{\n    int ret;\n\n    /* move the original frame to our backup */\n    av_frame_unref(avci->to_free);\n    av_frame_move_ref(avci->to_free, frame);\n\n    /* now copy everything except the AVBufferRefs back\n     * note that we make a COPY of the side data, so calling av_frame_free() on\n     * the caller's frame will work properly */\n    ret = av_frame_copy_props(frame, avci->to_free);\n    if (ret < 0)\n        return ret;\n\n    memcpy(frame->data,     avci->to_free->data,     sizeof(frame->data));\n    memcpy(frame->linesize, avci->to_free->linesize, sizeof(frame->linesize));\n    if (avci->to_free->extended_data != avci->to_free->data) {\n        int planes = av_frame_get_channels(avci->to_free);\n        int size   = planes * sizeof(*frame->extended_data);\n\n        if (!size) {\n            av_frame_unref(frame);\n            return AVERROR_BUG;\n        }\n\n        frame->extended_data = av_malloc(size);\n        if (!frame->extended_data) {\n            av_frame_unref(frame);\n            return AVERROR(ENOMEM);\n        }\n        memcpy(frame->extended_data, avci->to_free->extended_data,\n               size);\n    } else\n        frame->extended_data = frame->data;\n\n    frame->format         = avci->to_free->format;\n    frame->width          = avci->to_free->width;\n    frame->height         = avci->to_free->height;\n    frame->channel_layout = avci->to_free->channel_layout;\n    frame->nb_samples     = avci->to_free->nb_samples;\n    av_frame_set_channels(frame, av_frame_get_channels(avci->to_free));\n\n    return 0;\n}\n\nint attribute_align_arg avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,\n                                              int *got_picture_ptr,\n                                              const AVPacket *avpkt)\n{\n    AVCodecInternal *avci = avctx->internal;\n    int ret;\n    // copy to ensure we do not change avpkt\n    AVPacket tmp = *avpkt;\n\n    if (!avctx->codec)\n        return AVERROR(EINVAL);\n    if (avctx->codec->type != AVMEDIA_TYPE_VIDEO) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid media type for video\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (!avctx->codec->decode) {\n        av_log(avctx, AV_LOG_ERROR, \"This decoder requires using the avcodec_send_packet() API.\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    *got_picture_ptr = 0;\n    if ((avctx->coded_width || avctx->coded_height) && av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx))\n        return AVERROR(EINVAL);\n\n    avctx->internal->pkt = avpkt;\n    ret = apply_param_change(avctx, avpkt);\n    if (ret < 0)\n        return ret;\n\n    av_frame_unref(picture);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_DELAY) || avpkt->size ||\n        (avctx->active_thread_type & FF_THREAD_FRAME)) {\n        int did_split = av_packet_split_side_data(&tmp);\n        ret = apply_param_change(avctx, &tmp);\n        if (ret < 0)\n            goto fail;\n\n        avctx->internal->pkt = &tmp;\n        if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n            ret = ff_thread_decode_frame(avctx, picture, got_picture_ptr,\n                                         &tmp);\n        else {\n            ret = avctx->codec->decode(avctx, picture, got_picture_ptr,\n                                       &tmp);\n            if (!(avctx->codec->caps_internal & FF_CODEC_CAP_SETS_PKT_DTS))\n                picture->pkt_dts = avpkt->dts;\n\n            if(!avctx->has_b_frames){\n                av_frame_set_pkt_pos(picture, avpkt->pos);\n            }\n            //FIXME these should be under if(!avctx->has_b_frames)\n            /* get_buffer is supposed to set frame parameters */\n            if (!(avctx->codec->capabilities & AV_CODEC_CAP_DR1)) {\n                if (!picture->sample_aspect_ratio.num)    picture->sample_aspect_ratio = avctx->sample_aspect_ratio;\n                if (!picture->width)                      picture->width               = avctx->width;\n                if (!picture->height)                     picture->height              = avctx->height;\n                if (picture->format == AV_PIX_FMT_NONE)   picture->format              = avctx->pix_fmt;\n            }\n        }\n\nfail:\n        emms_c(); //needed to avoid an emms_c() call before every return;\n\n        avctx->internal->pkt = NULL;\n        if (did_split) {\n            av_packet_free_side_data(&tmp);\n            if(ret == tmp.size)\n                ret = avpkt->size;\n        }\n        if (picture->flags & AV_FRAME_FLAG_DISCARD) {\n            *got_picture_ptr = 0;\n        }\n        if (*got_picture_ptr) {\n            if (!avctx->refcounted_frames) {\n                int err = unrefcount_frame(avci, picture);\n                if (err < 0)\n                    return err;\n            }\n\n            avctx->frame_number++;\n            av_frame_set_best_effort_timestamp(picture,\n                                               guess_correct_pts(avctx,\n                                                                 picture->pts,\n                                                                 picture->pkt_dts));\n        } else\n            av_frame_unref(picture);\n    } else\n        ret = 0;\n\n    /* many decoders assign whole AVFrames, thus overwriting extended_data;\n     * make sure it's set correctly */\n    av_assert0(!picture->extended_data || picture->extended_data == picture->data);\n\n#if FF_API_AVCTX_TIMEBASE\n    if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n        avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n\n    return ret;\n}\n\nint attribute_align_arg avcodec_decode_audio4(AVCodecContext *avctx,\n                                              AVFrame *frame,\n                                              int *got_frame_ptr,\n                                              const AVPacket *avpkt)\n{\n    AVCodecInternal *avci = avctx->internal;\n    int ret = 0;\n\n    *got_frame_ptr = 0;\n\n    if (!avctx->codec)\n        return AVERROR(EINVAL);\n\n    if (!avctx->codec->decode) {\n        av_log(avctx, AV_LOG_ERROR, \"This decoder requires using the avcodec_send_packet() API.\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    if (!avpkt->data && avpkt->size) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid packet: NULL data, size != 0\\n\");\n        return AVERROR(EINVAL);\n    }\n    if (avctx->codec->type != AVMEDIA_TYPE_AUDIO) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid media type for audio\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    av_frame_unref(frame);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_DELAY) || avpkt->size || (avctx->active_thread_type & FF_THREAD_FRAME)) {\n        uint8_t *side;\n        int side_size;\n        uint32_t discard_padding = 0;\n        uint8_t skip_reason = 0;\n        uint8_t discard_reason = 0;\n        // copy to ensure we do not change avpkt\n        AVPacket tmp = *avpkt;\n        int did_split = av_packet_split_side_data(&tmp);\n        ret = apply_param_change(avctx, &tmp);\n        if (ret < 0)\n            goto fail;\n\n        avctx->internal->pkt = &tmp;\n        if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n            ret = ff_thread_decode_frame(avctx, frame, got_frame_ptr, &tmp);\n        else {\n            ret = avctx->codec->decode(avctx, frame, got_frame_ptr, &tmp);\n            av_assert0(ret <= tmp.size);\n            frame->pkt_dts = avpkt->dts;\n        }\n        if (ret >= 0 && *got_frame_ptr) {\n            avctx->frame_number++;\n            av_frame_set_best_effort_timestamp(frame,\n                                               guess_correct_pts(avctx,\n                                                                 frame->pts,\n                                                                 frame->pkt_dts));\n            if (frame->format == AV_SAMPLE_FMT_NONE)\n                frame->format = avctx->sample_fmt;\n            if (!frame->channel_layout)\n                frame->channel_layout = avctx->channel_layout;\n            if (!av_frame_get_channels(frame))\n                av_frame_set_channels(frame, avctx->channels);\n            if (!frame->sample_rate)\n                frame->sample_rate = avctx->sample_rate;\n        }\n\n        side= av_packet_get_side_data(avctx->internal->pkt, AV_PKT_DATA_SKIP_SAMPLES, &side_size);\n        if(side && side_size>=10) {\n            avctx->internal->skip_samples = AV_RL32(side);\n            discard_padding = AV_RL32(side + 4);\n            av_log(avctx, AV_LOG_DEBUG, \"skip %d / discard %d samples due to side data\\n\",\n                   avctx->internal->skip_samples, (int)discard_padding);\n            skip_reason = AV_RL8(side + 8);\n            discard_reason = AV_RL8(side + 9);\n        }\n\n        if ((frame->flags & AV_FRAME_FLAG_DISCARD) && *got_frame_ptr &&\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n            avctx->internal->skip_samples = FFMAX(0, avctx->internal->skip_samples - frame->nb_samples);\n            *got_frame_ptr = 0;\n        }\n\n        if (avctx->internal->skip_samples > 0 && *got_frame_ptr &&\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n            if(frame->nb_samples <= avctx->internal->skip_samples){\n                *got_frame_ptr = 0;\n                avctx->internal->skip_samples -= frame->nb_samples;\n                av_log(avctx, AV_LOG_DEBUG, \"skip whole frame, skip left: %d\\n\",\n                       avctx->internal->skip_samples);\n            } else {\n                av_samples_copy(frame->extended_data, frame->extended_data, 0, avctx->internal->skip_samples,\n                                frame->nb_samples - avctx->internal->skip_samples, avctx->channels, frame->format);\n                if(avctx->pkt_timebase.num && avctx->sample_rate) {\n                    int64_t diff_ts = av_rescale_q(avctx->internal->skip_samples,\n                                                   (AVRational){1, avctx->sample_rate},\n                                                   avctx->pkt_timebase);\n                    if(frame->pts!=AV_NOPTS_VALUE)\n                        frame->pts += diff_ts;\n#if FF_API_PKT_PTS\nFF_DISABLE_DEPRECATION_WARNINGS\n                    if(frame->pkt_pts!=AV_NOPTS_VALUE)\n                        frame->pkt_pts += diff_ts;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n                    if(frame->pkt_dts!=AV_NOPTS_VALUE)\n                        frame->pkt_dts += diff_ts;\n                    if (av_frame_get_pkt_duration(frame) >= diff_ts)\n                        av_frame_set_pkt_duration(frame, av_frame_get_pkt_duration(frame) - diff_ts);\n                } else {\n                    av_log(avctx, AV_LOG_WARNING, \"Could not update timestamps for skipped samples.\\n\");\n                }\n                av_log(avctx, AV_LOG_DEBUG, \"skip %d/%d samples\\n\",\n                       avctx->internal->skip_samples, frame->nb_samples);\n                frame->nb_samples -= avctx->internal->skip_samples;\n                avctx->internal->skip_samples = 0;\n            }\n        }\n\n        if (discard_padding > 0 && discard_padding <= frame->nb_samples && *got_frame_ptr &&\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n            if (discard_padding == frame->nb_samples) {\n                *got_frame_ptr = 0;\n            } else {\n                if(avctx->pkt_timebase.num && avctx->sample_rate) {\n                    int64_t diff_ts = av_rescale_q(frame->nb_samples - discard_padding,\n                                                   (AVRational){1, avctx->sample_rate},\n                                                   avctx->pkt_timebase);\n                    av_frame_set_pkt_duration(frame, diff_ts);\n                } else {\n                    av_log(avctx, AV_LOG_WARNING, \"Could not update timestamps for discarded samples.\\n\");\n                }\n                av_log(avctx, AV_LOG_DEBUG, \"discard %d/%d samples\\n\",\n                       (int)discard_padding, frame->nb_samples);\n                frame->nb_samples -= discard_padding;\n            }\n        }\n\n        if ((avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL) && *got_frame_ptr) {\n            AVFrameSideData *fside = av_frame_new_side_data(frame, AV_FRAME_DATA_SKIP_SAMPLES, 10);\n            if (fside) {\n                AV_WL32(fside->data, avctx->internal->skip_samples);\n                AV_WL32(fside->data + 4, discard_padding);\n                AV_WL8(fside->data + 8, skip_reason);\n                AV_WL8(fside->data + 9, discard_reason);\n                avctx->internal->skip_samples = 0;\n            }\n        }\nfail:\n        avctx->internal->pkt = NULL;\n        if (did_split) {\n            av_packet_free_side_data(&tmp);\n            if(ret == tmp.size)\n                ret = avpkt->size;\n        }\n\n        if (ret >= 0 && *got_frame_ptr) {\n            if (!avctx->refcounted_frames) {\n                int err = unrefcount_frame(avci, frame);\n                if (err < 0)\n                    return err;\n            }\n        } else\n            av_frame_unref(frame);\n    }\n\n    av_assert0(ret <= avpkt->size);\n\n    if (!avci->showed_multi_packet_warning &&\n        ret >= 0 && ret != avpkt->size && !(avctx->codec->capabilities & AV_CODEC_CAP_SUBFRAMES)) {\n            av_log(avctx, AV_LOG_WARNING, \"Multiple frames in a packet.\\n\");\n        avci->showed_multi_packet_warning = 1;\n    }\n\n    return ret;\n}\n\n#define UTF8_MAX_BYTES 4 /* 5 and 6 bytes sequences should not be used */\nstatic int recode_subtitle(AVCodecContext *avctx,\n                           AVPacket *outpkt, const AVPacket *inpkt)\n{\n#if CONFIG_ICONV\n    iconv_t cd = (iconv_t)-1;\n    int ret = 0;\n    char *inb, *outb;\n    size_t inl, outl;\n    AVPacket tmp;\n#endif\n\n    if (avctx->sub_charenc_mode != FF_SUB_CHARENC_MODE_PRE_DECODER || inpkt->size == 0)\n        return 0;\n\n#if CONFIG_ICONV\n    cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n    av_assert0(cd != (iconv_t)-1);\n\n    inb = inpkt->data;\n    inl = inpkt->size;\n\n    if (inl >= INT_MAX / UTF8_MAX_BYTES - AV_INPUT_BUFFER_PADDING_SIZE) {\n        av_log(avctx, AV_LOG_ERROR, \"Subtitles packet is too big for recoding\\n\");\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    ret = av_new_packet(&tmp, inl * UTF8_MAX_BYTES);\n    if (ret < 0)\n        goto end;\n    outpkt->buf  = tmp.buf;\n    outpkt->data = tmp.data;\n    outpkt->size = tmp.size;\n    outb = outpkt->data;\n    outl = outpkt->size;\n\n    if (iconv(cd, &inb, &inl, &outb, &outl) == (size_t)-1 ||\n        iconv(cd, NULL, NULL, &outb, &outl) == (size_t)-1 ||\n        outl >= outpkt->size || inl != 0) {\n        ret = FFMIN(AVERROR(errno), -1);\n        av_log(avctx, AV_LOG_ERROR, \"Unable to recode subtitle event \\\"%s\\\" \"\n               \"from %s to UTF-8\\n\", inpkt->data, avctx->sub_charenc);\n        av_packet_unref(&tmp);\n        goto end;\n    }\n    outpkt->size -= outl;\n    memset(outpkt->data + outpkt->size, 0, outl);\n\nend:\n    if (cd != (iconv_t)-1)\n        iconv_close(cd);\n    return ret;\n#else\n    av_log(avctx, AV_LOG_ERROR, \"requesting subtitles recoding without iconv\");\n    return AVERROR(EINVAL);\n#endif\n}\n\nstatic int utf8_check(const uint8_t *str)\n{\n    const uint8_t *byte;\n    uint32_t codepoint, min;\n\n    while (*str) {\n        byte = str;\n        GET_UTF8(codepoint, *(byte++), return 0;);\n        min = byte - str == 1 ? 0 : byte - str == 2 ? 0x80 :\n              1 << (5 * (byte - str) - 4);\n        if (codepoint < min || codepoint >= 0x110000 ||\n            codepoint == 0xFFFE /* BOM */ ||\n            codepoint >= 0xD800 && codepoint <= 0xDFFF /* surrogates */)\n            return 0;\n        str = byte;\n    }\n    return 1;\n}\n\n#if FF_API_ASS_TIMING\nstatic void insert_ts(AVBPrint *buf, int ts)\n{\n    if (ts == -1) {\n        av_bprintf(buf, \"9:59:59.99,\");\n    } else {\n        int h, m, s;\n\n        h = ts/360000;  ts -= 360000*h;\n        m = ts/  6000;  ts -=   6000*m;\n        s = ts/   100;  ts -=    100*s;\n        av_bprintf(buf, \"%d:%02d:%02d.%02d,\", h, m, s, ts);\n    }\n}\n\nstatic int convert_sub_to_old_ass_form(AVSubtitle *sub, const AVPacket *pkt, AVRational tb)\n{\n    int i;\n    AVBPrint buf;\n\n    av_bprint_init(&buf, 0, AV_BPRINT_SIZE_UNLIMITED);\n\n    for (i = 0; i < sub->num_rects; i++) {\n        char *final_dialog;\n        const char *dialog;\n        AVSubtitleRect *rect = sub->rects[i];\n        int ts_start, ts_duration = -1;\n        long int layer;\n\n        if (rect->type != SUBTITLE_ASS || !strncmp(rect->ass, \"Dialogue: \", 10))\n            continue;\n\n        av_bprint_clear(&buf);\n\n        /* skip ReadOrder */\n        dialog = strchr(rect->ass, ',');\n        if (!dialog)\n            continue;\n        dialog++;\n\n        /* extract Layer or Marked */\n        layer = strtol(dialog, (char**)&dialog, 10);\n        if (*dialog != ',')\n            continue;\n        dialog++;\n\n        /* rescale timing to ASS time base (ms) */\n        ts_start = av_rescale_q(pkt->pts, tb, av_make_q(1, 100));\n        if (pkt->duration != -1)\n            ts_duration = av_rescale_q(pkt->duration, tb, av_make_q(1, 100));\n        sub->end_display_time = FFMAX(sub->end_display_time, 10 * ts_duration);\n\n        /* construct ASS (standalone file form with timestamps) string */\n        av_bprintf(&buf, \"Dialogue: %ld,\", layer);\n        insert_ts(&buf, ts_start);\n        insert_ts(&buf, ts_duration == -1 ? -1 : ts_start + ts_duration);\n        av_bprintf(&buf, \"%s\\r\\n\", dialog);\n\n        final_dialog = av_strdup(buf.str);\n        if (!av_bprint_is_complete(&buf) || !final_dialog) {\n            av_freep(&final_dialog);\n            av_bprint_finalize(&buf, NULL);\n            return AVERROR(ENOMEM);\n        }\n        av_freep(&rect->ass);\n        rect->ass = final_dialog;\n    }\n\n    av_bprint_finalize(&buf, NULL);\n    return 0;\n}\n#endif\n\nint avcodec_decode_subtitle2(AVCodecContext *avctx, AVSubtitle *sub,\n                             int *got_sub_ptr,\n                             AVPacket *avpkt)\n{\n    int i, ret = 0;\n\n    if (!avpkt->data && avpkt->size) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid packet: NULL data, size != 0\\n\");\n        return AVERROR(EINVAL);\n    }\n    if (!avctx->codec)\n        return AVERROR(EINVAL);\n    if (avctx->codec->type != AVMEDIA_TYPE_SUBTITLE) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid media type for subtitles\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    *got_sub_ptr = 0;\n    get_subtitle_defaults(sub);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_DELAY) || avpkt->size) {\n        AVPacket pkt_recoded;\n        AVPacket tmp = *avpkt;\n        int did_split = av_packet_split_side_data(&tmp);\n        //apply_param_change(avctx, &tmp);\n\n        if (did_split) {\n            /* FFMIN() prevents overflow in case the packet wasn't allocated with\n             * proper padding.\n             * If the side data is smaller than the buffer padding size, the\n             * remaining bytes should have already been filled with zeros by the\n             * original packet allocation anyway. */\n            memset(tmp.data + tmp.size, 0,\n                   FFMIN(avpkt->size - tmp.size, AV_INPUT_BUFFER_PADDING_SIZE));\n        }\n\n        pkt_recoded = tmp;\n        ret = recode_subtitle(avctx, &pkt_recoded, &tmp);\n        if (ret < 0) {\n            *got_sub_ptr = 0;\n        } else {\n            avctx->internal->pkt = &pkt_recoded;\n\n            if (avctx->pkt_timebase.num && avpkt->pts != AV_NOPTS_VALUE)\n                sub->pts = av_rescale_q(avpkt->pts,\n                                        avctx->pkt_timebase, AV_TIME_BASE_Q);\n            ret = avctx->codec->decode(avctx, sub, got_sub_ptr, &pkt_recoded);\n            av_assert1((ret >= 0) >= !!*got_sub_ptr &&\n                       !!*got_sub_ptr >= !!sub->num_rects);\n\n#if FF_API_ASS_TIMING\n            if (avctx->sub_text_format == FF_SUB_TEXT_FMT_ASS_WITH_TIMINGS\n                && *got_sub_ptr && sub->num_rects) {\n                const AVRational tb = avctx->pkt_timebase.num ? avctx->pkt_timebase\n                                                              : avctx->time_base;\n                int err = convert_sub_to_old_ass_form(sub, avpkt, tb);\n                if (err < 0)\n                    ret = err;\n            }\n#endif\n\n            if (sub->num_rects && !sub->end_display_time && avpkt->duration &&\n                avctx->pkt_timebase.num) {\n                AVRational ms = { 1, 1000 };\n                sub->end_display_time = av_rescale_q(avpkt->duration,\n                                                     avctx->pkt_timebase, ms);\n            }\n\n            for (i = 0; i < sub->num_rects; i++) {\n                if (sub->rects[i]->ass && !utf8_check(sub->rects[i]->ass)) {\n                    av_log(avctx, AV_LOG_ERROR,\n                           \"Invalid UTF-8 in decoded subtitles text; \"\n                           \"maybe missing -sub_charenc option\\n\");\n                    avsubtitle_free(sub);\n                    return AVERROR_INVALIDDATA;\n                }\n            }\n\n            if (tmp.data != pkt_recoded.data) { // did we recode?\n                /* prevent from destroying side data from original packet */\n                pkt_recoded.side_data = NULL;\n                pkt_recoded.side_data_elems = 0;\n\n                av_packet_unref(&pkt_recoded);\n            }\n            if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB)\n                sub->format = 0;\n            else if (avctx->codec_descriptor->props & AV_CODEC_PROP_TEXT_SUB)\n                sub->format = 1;\n            avctx->internal->pkt = NULL;\n        }\n\n        if (did_split) {\n            av_packet_free_side_data(&tmp);\n            if(ret == tmp.size)\n                ret = avpkt->size;\n        }\n\n        if (*got_sub_ptr)\n            avctx->frame_number++;\n    }\n\n    return ret;\n}\n\nvoid avsubtitle_free(AVSubtitle *sub)\n{\n    int i;\n\n    for (i = 0; i < sub->num_rects; i++) {\n        av_freep(&sub->rects[i]->data[0]);\n        av_freep(&sub->rects[i]->data[1]);\n        av_freep(&sub->rects[i]->data[2]);\n        av_freep(&sub->rects[i]->data[3]);\n        av_freep(&sub->rects[i]->text);\n        av_freep(&sub->rects[i]->ass);\n        av_freep(&sub->rects[i]);\n    }\n\n    av_freep(&sub->rects);\n\n    memset(sub, 0, sizeof(AVSubtitle));\n}\n\nstatic int do_decode(AVCodecContext *avctx, AVPacket *pkt)\n{\n    int got_frame;\n    int ret;\n\n    av_assert0(!avctx->internal->buffer_frame->buf[0]);\n\n    if (!pkt)\n        pkt = avctx->internal->buffer_pkt;\n\n    // This is the lesser evil. The field is for compatibility with legacy users\n    // of the legacy API, and users using the new API should not be forced to\n    // even know about this field.\n    avctx->refcounted_frames = 1;\n\n    // Some codecs (at least wma lossless) will crash when feeding drain packets\n    // after EOF was signaled.\n    if (avctx->internal->draining_done)\n        return AVERROR_EOF;\n\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n        ret = avcodec_decode_video2(avctx, avctx->internal->buffer_frame,\n                                    &got_frame, pkt);\n        if (ret >= 0 && !(avctx->flags & AV_CODEC_FLAG_TRUNCATED))\n            ret = pkt->size;\n    } else if (avctx->codec_type == AVMEDIA_TYPE_AUDIO) {\n        ret = avcodec_decode_audio4(avctx, avctx->internal->buffer_frame,\n                                    &got_frame, pkt);\n    } else {\n        ret = AVERROR(EINVAL);\n    }\n\n    if (ret == AVERROR(EAGAIN))\n        ret = pkt->size;\n\n    if (ret < 0)\n        return ret;\n\n    if (avctx->internal->draining && !got_frame)\n        avctx->internal->draining_done = 1;\n\n    if (ret >= pkt->size) {\n        av_packet_unref(avctx->internal->buffer_pkt);\n    } else {\n        int consumed = ret;\n\n        if (pkt != avctx->internal->buffer_pkt) {\n            av_packet_unref(avctx->internal->buffer_pkt);\n            if ((ret = av_packet_ref(avctx->internal->buffer_pkt, pkt)) < 0)\n                return ret;\n        }\n\n        avctx->internal->buffer_pkt->data += consumed;\n        avctx->internal->buffer_pkt->size -= consumed;\n        avctx->internal->buffer_pkt->pts   = AV_NOPTS_VALUE;\n        avctx->internal->buffer_pkt->dts   = AV_NOPTS_VALUE;\n    }\n\n    if (got_frame)\n        av_assert0(avctx->internal->buffer_frame->buf[0]);\n\n    return 0;\n}\n\nint attribute_align_arg avcodec_send_packet(AVCodecContext *avctx, const AVPacket *avpkt)\n{\n    int ret;\n\n    if (!avcodec_is_open(avctx) || !av_codec_is_decoder(avctx->codec))\n        return AVERROR(EINVAL);\n\n    if (avctx->internal->draining)\n        return AVERROR_EOF;\n\n    if (avpkt && !avpkt->size && avpkt->data)\n        return AVERROR(EINVAL);\n\n    if (!avpkt || !avpkt->size) {\n        avctx->internal->draining = 1;\n        avpkt = NULL;\n\n        if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            return 0;\n    }\n\n    if (avctx->codec->send_packet) {\n        if (avpkt) {\n            AVPacket tmp = *avpkt;\n            int did_split = av_packet_split_side_data(&tmp);\n            ret = apply_param_change(avctx, &tmp);\n            if (ret >= 0)\n                ret = avctx->codec->send_packet(avctx, &tmp);\n            if (did_split)\n                av_packet_free_side_data(&tmp);\n            return ret;\n        } else {\n            return avctx->codec->send_packet(avctx, NULL);\n        }\n    }\n\n    // Emulation via old API. Assume avpkt is likely not refcounted, while\n    // decoder output is always refcounted, and avoid copying.\n\n    if (avctx->internal->buffer_pkt->size || avctx->internal->buffer_frame->buf[0])\n        return AVERROR(EAGAIN);\n\n    // The goal is decoding the first frame of the packet without using memcpy,\n    // because the common case is having only 1 frame per packet (especially\n    // with video, but audio too). In other cases, it can't be avoided, unless\n    // the user is feeding refcounted packets.\n    return do_decode(avctx, (AVPacket *)avpkt);\n}\n\nint attribute_align_arg avcodec_receive_frame(AVCodecContext *avctx, AVFrame *frame)\n{\n    int ret;\n\n    av_frame_unref(frame);\n\n    if (!avcodec_is_open(avctx) || !av_codec_is_decoder(avctx->codec))\n        return AVERROR(EINVAL);\n\n    if (avctx->codec->receive_frame) {\n        if (avctx->internal->draining && !(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            return AVERROR_EOF;\n        ret = avctx->codec->receive_frame(avctx, frame);\n        if (ret >= 0) {\n            if (av_frame_get_best_effort_timestamp(frame) == AV_NOPTS_VALUE) {\n                av_frame_set_best_effort_timestamp(frame,\n                    guess_correct_pts(avctx, frame->pts, frame->pkt_dts));\n            }\n        }\n        return ret;\n    }\n\n    // Emulation via old API.\n\n    if (!avctx->internal->buffer_frame->buf[0]) {\n        if (!avctx->internal->buffer_pkt->size && !avctx->internal->draining)\n            return AVERROR(EAGAIN);\n\n        while (1) {\n            if ((ret = do_decode(avctx, avctx->internal->buffer_pkt)) < 0) {\n                av_packet_unref(avctx->internal->buffer_pkt);\n                return ret;\n            }\n            // Some audio decoders may consume partial data without returning\n            // a frame (fate-wmapro-2ch). There is no way to make the caller\n            // call avcodec_receive_frame() again without returning a frame,\n            // so try to decode more in these cases.\n            if (avctx->internal->buffer_frame->buf[0] ||\n                !avctx->internal->buffer_pkt->size)\n                break;\n        }\n    }\n\n    if (!avctx->internal->buffer_frame->buf[0])\n        return avctx->internal->draining ? AVERROR_EOF : AVERROR(EAGAIN);\n\n    av_frame_move_ref(frame, avctx->internal->buffer_frame);\n    return 0;\n}\n\nstatic int do_encode(AVCodecContext *avctx, const AVFrame *frame, int *got_packet)\n{\n    int ret;\n    *got_packet = 0;\n\n    av_packet_unref(avctx->internal->buffer_pkt);\n    avctx->internal->buffer_pkt_valid = 0;\n\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n        ret = avcodec_encode_video2(avctx, avctx->internal->buffer_pkt,\n                                    frame, got_packet);\n    } else if (avctx->codec_type == AVMEDIA_TYPE_AUDIO) {\n        ret = avcodec_encode_audio2(avctx, avctx->internal->buffer_pkt,\n                                    frame, got_packet);\n    } else {\n        ret = AVERROR(EINVAL);\n    }\n\n    if (ret >= 0 && *got_packet) {\n        // Encoders must always return ref-counted buffers.\n        // Side-data only packets have no data and can be not ref-counted.\n        av_assert0(!avctx->internal->buffer_pkt->data || avctx->internal->buffer_pkt->buf);\n        avctx->internal->buffer_pkt_valid = 1;\n        ret = 0;\n    } else {\n        av_packet_unref(avctx->internal->buffer_pkt);\n    }\n\n    return ret;\n}\n\nint attribute_align_arg avcodec_send_frame(AVCodecContext *avctx, const AVFrame *frame)\n{\n    if (!avcodec_is_open(avctx) || !av_codec_is_encoder(avctx->codec))\n        return AVERROR(EINVAL);\n\n    if (avctx->internal->draining)\n        return AVERROR_EOF;\n\n    if (!frame) {\n        avctx->internal->draining = 1;\n\n        if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            return 0;\n    }\n\n    if (avctx->codec->send_frame)\n        return avctx->codec->send_frame(avctx, frame);\n\n    // Emulation via old API. Do it here instead of avcodec_receive_packet, because:\n    // 1. if the AVFrame is not refcounted, the copying will be much more\n    //    expensive than copying the packet data\n    // 2. assume few users use non-refcounted AVPackets, so usually no copy is\n    //    needed\n\n    if (avctx->internal->buffer_pkt_valid)\n        return AVERROR(EAGAIN);\n\n    return do_encode(avctx, frame, &(int){0});\n}\n\nint attribute_align_arg avcodec_receive_packet(AVCodecContext *avctx, AVPacket *avpkt)\n{\n    av_packet_unref(avpkt);\n\n    if (!avcodec_is_open(avctx) || !av_codec_is_encoder(avctx->codec))\n        return AVERROR(EINVAL);\n\n    if (avctx->codec->receive_packet) {\n        if (avctx->internal->draining && !(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            return AVERROR_EOF;\n        return avctx->codec->receive_packet(avctx, avpkt);\n    }\n\n    // Emulation via old API.\n\n    if (!avctx->internal->buffer_pkt_valid) {\n        int got_packet;\n        int ret;\n        if (!avctx->internal->draining)\n            return AVERROR(EAGAIN);\n        ret = do_encode(avctx, NULL, &got_packet);\n        if (ret < 0)\n            return ret;\n        if (ret >= 0 && !got_packet)\n            return AVERROR_EOF;\n    }\n\n    av_packet_move_ref(avpkt, avctx->internal->buffer_pkt);\n    avctx->internal->buffer_pkt_valid = 0;\n    return 0;\n}\n\nav_cold int avcodec_close(AVCodecContext *avctx)\n{\n    int i;\n\n    if (!avctx)\n        return 0;\n\n    if (avcodec_is_open(avctx)) {\n        FramePool *pool = avctx->internal->pool;\n        if (CONFIG_FRAME_THREAD_ENCODER &&\n            avctx->internal->frame_thread_encoder && avctx->thread_count > 1) {\n            ff_frame_thread_encoder_free(avctx);\n        }\n        if (HAVE_THREADS && avctx->internal->thread_ctx)\n            ff_thread_free(avctx);\n        if (avctx->codec && avctx->codec->close)\n            avctx->codec->close(avctx);\n        avctx->internal->byte_buffer_size = 0;\n        av_freep(&avctx->internal->byte_buffer);\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        for (i = 0; i < FF_ARRAY_ELEMS(pool->pools); i++)\n            av_buffer_pool_uninit(&pool->pools[i]);\n        av_freep(&avctx->internal->pool);\n\n        if (avctx->hwaccel && avctx->hwaccel->uninit)\n            avctx->hwaccel->uninit(avctx);\n        av_freep(&avctx->internal->hwaccel_priv_data);\n\n        av_freep(&avctx->internal);\n    }\n\n    for (i = 0; i < avctx->nb_coded_side_data; i++)\n        av_freep(&avctx->coded_side_data[i].data);\n    av_freep(&avctx->coded_side_data);\n    avctx->nb_coded_side_data = 0;\n\n    av_buffer_unref(&avctx->hw_frames_ctx);\n\n    if (avctx->priv_data && avctx->codec && avctx->codec->priv_class)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n    av_freep(&avctx->priv_data);\n    if (av_codec_is_encoder(avctx->codec)) {\n        av_freep(&avctx->extradata);\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n    }\n    avctx->codec = NULL;\n    avctx->active_thread_type = 0;\n\n    return 0;\n}\n\nstatic enum AVCodecID remap_deprecated_codec_id(enum AVCodecID id)\n{\n    switch(id){\n        //This is for future deprecatec codec ids, its empty since\n        //last major bump but will fill up again over time, please don't remove it\n        default                                         : return id;\n    }\n}\n\nstatic AVCodec *find_encdec(enum AVCodecID id, int encoder)\n{\n    AVCodec *p, *experimental = NULL;\n    p = first_avcodec;\n    id= remap_deprecated_codec_id(id);\n    while (p) {\n        if ((encoder ? av_codec_is_encoder(p) : av_codec_is_decoder(p)) &&\n            p->id == id) {\n            if (p->capabilities & AV_CODEC_CAP_EXPERIMENTAL && !experimental) {\n                experimental = p;\n            } else\n                return p;\n        }\n        p = p->next;\n    }\n    return experimental;\n}\n\nAVCodec *avcodec_find_encoder(enum AVCodecID id)\n{\n    return find_encdec(id, 1);\n}\n\nAVCodec *avcodec_find_encoder_by_name(const char *name)\n{\n    AVCodec *p;\n    if (!name)\n        return NULL;\n    p = first_avcodec;\n    while (p) {\n        if (av_codec_is_encoder(p) && strcmp(name, p->name) == 0)\n            return p;\n        p = p->next;\n    }\n    return NULL;\n}\n\nAVCodec *avcodec_find_decoder(enum AVCodecID id)\n{\n    return find_encdec(id, 0);\n}\n\nAVCodec *avcodec_find_decoder_by_name(const char *name)\n{\n    AVCodec *p;\n    if (!name)\n        return NULL;\n    p = first_avcodec;\n    while (p) {\n        if (av_codec_is_decoder(p) && strcmp(name, p->name) == 0)\n            return p;\n        p = p->next;\n    }\n    return NULL;\n}\n\nconst char *avcodec_get_name(enum AVCodecID id)\n{\n    const AVCodecDescriptor *cd;\n    AVCodec *codec;\n\n    if (id == AV_CODEC_ID_NONE)\n        return \"none\";\n    cd = avcodec_descriptor_get(id);\n    if (cd)\n        return cd->name;\n    av_log(NULL, AV_LOG_WARNING, \"Codec 0x%x is not in the full list.\\n\", id);\n    codec = avcodec_find_decoder(id);\n    if (codec)\n        return codec->name;\n    codec = avcodec_find_encoder(id);\n    if (codec)\n        return codec->name;\n    return \"unknown_codec\";\n}\n\nsize_t av_get_codec_tag_string(char *buf, size_t buf_size, unsigned int codec_tag)\n{\n    int i, len, ret = 0;\n\n#define TAG_PRINT(x)                                              \\\n    (((x) >= '0' && (x) <= '9') ||                                \\\n     ((x) >= 'a' && (x) <= 'z') || ((x) >= 'A' && (x) <= 'Z') ||  \\\n     ((x) == '.' || (x) == ' ' || (x) == '-' || (x) == '_'))\n\n    for (i = 0; i < 4; i++) {\n        len = snprintf(buf, buf_size,\n                       TAG_PRINT(codec_tag & 0xFF) ? \"%c\" : \"[%d]\", codec_tag & 0xFF);\n        buf        += len;\n        buf_size    = buf_size > len ? buf_size - len : 0;\n        ret        += len;\n        codec_tag >>= 8;\n    }\n    return ret;\n}\n\nvoid avcodec_string(char *buf, int buf_size, AVCodecContext *enc, int encode)\n{\n    const char *codec_type;\n    const char *codec_name;\n    const char *profile = NULL;\n    int64_t bitrate;\n    int new_line = 0;\n    AVRational display_aspect_ratio;\n    const char *separator = enc->dump_separator ? (const char *)enc->dump_separator : \", \";\n\n    if (!buf || buf_size <= 0)\n        return;\n    codec_type = av_get_media_type_string(enc->codec_type);\n    codec_name = avcodec_get_name(enc->codec_id);\n    profile = avcodec_profile_name(enc->codec_id, enc->profile);\n\n    snprintf(buf, buf_size, \"%s: %s\", codec_type ? codec_type : \"unknown\",\n             codec_name);\n    buf[0] ^= 'a' ^ 'A'; /* first letter in uppercase */\n\n    if (enc->codec && strcmp(enc->codec->name, codec_name))\n        snprintf(buf + strlen(buf), buf_size - strlen(buf), \" (%s)\", enc->codec->name);\n\n    if (profile)\n        snprintf(buf + strlen(buf), buf_size - strlen(buf), \" (%s)\", profile);\n    if (   enc->codec_type == AVMEDIA_TYPE_VIDEO\n        && av_log_get_level() >= AV_LOG_VERBOSE\n        && enc->refs)\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \", %d reference frame%s\",\n                 enc->refs, enc->refs > 1 ? \"s\" : \"\");\n\n    if (enc->codec_tag) {\n        char tag_buf[32];\n        av_get_codec_tag_string(tag_buf, sizeof(tag_buf), enc->codec_tag);\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \" (%s / 0x%04X)\", tag_buf, enc->codec_tag);\n    }\n\n    switch (enc->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        {\n            char detail[256] = \"(\";\n\n            av_strlcat(buf, separator, buf_size);\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \"%s\", enc->pix_fmt == AV_PIX_FMT_NONE ? \"none\" :\n                     av_get_pix_fmt_name(enc->pix_fmt));\n            if (enc->bits_per_raw_sample && enc->pix_fmt != AV_PIX_FMT_NONE &&\n                enc->bits_per_raw_sample < av_pix_fmt_desc_get(enc->pix_fmt)->comp[0].depth)\n                av_strlcatf(detail, sizeof(detail), \"%d bpc, \", enc->bits_per_raw_sample);\n            if (enc->color_range != AVCOL_RANGE_UNSPECIFIED)\n                av_strlcatf(detail, sizeof(detail), \"%s, \",\n                            av_color_range_name(enc->color_range));\n\n            if (enc->colorspace != AVCOL_SPC_UNSPECIFIED ||\n                enc->color_primaries != AVCOL_PRI_UNSPECIFIED ||\n                enc->color_trc != AVCOL_TRC_UNSPECIFIED) {\n                if (enc->colorspace != (int)enc->color_primaries ||\n                    enc->colorspace != (int)enc->color_trc) {\n                    new_line = 1;\n                    av_strlcatf(detail, sizeof(detail), \"%s/%s/%s, \",\n                                av_color_space_name(enc->colorspace),\n                                av_color_primaries_name(enc->color_primaries),\n                                av_color_transfer_name(enc->color_trc));\n                } else\n                    av_strlcatf(detail, sizeof(detail), \"%s, \",\n                                av_get_colorspace_name(enc->colorspace));\n            }\n\n            if (enc->field_order != AV_FIELD_UNKNOWN) {\n                const char *field_order = \"progressive\";\n                if (enc->field_order == AV_FIELD_TT)\n                    field_order = \"top first\";\n                else if (enc->field_order == AV_FIELD_BB)\n                    field_order = \"bottom first\";\n                else if (enc->field_order == AV_FIELD_TB)\n                    field_order = \"top coded first (swapped)\";\n                else if (enc->field_order == AV_FIELD_BT)\n                    field_order = \"bottom coded first (swapped)\";\n\n                av_strlcatf(detail, sizeof(detail), \"%s, \", field_order);\n            }\n\n            if (av_log_get_level() >= AV_LOG_VERBOSE &&\n                enc->chroma_sample_location != AVCHROMA_LOC_UNSPECIFIED)\n                av_strlcatf(detail, sizeof(detail), \"%s, \",\n                            av_chroma_location_name(enc->chroma_sample_location));\n\n            if (strlen(detail) > 1) {\n                detail[strlen(detail) - 2] = 0;\n                av_strlcatf(buf, buf_size, \"%s)\", detail);\n            }\n        }\n\n        if (enc->width) {\n            av_strlcat(buf, new_line ? separator : \", \", buf_size);\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \"%dx%d\",\n                     enc->width, enc->height);\n\n            if (av_log_get_level() >= AV_LOG_VERBOSE &&\n                (enc->width != enc->coded_width ||\n                 enc->height != enc->coded_height))\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \" (%dx%d)\", enc->coded_width, enc->coded_height);\n\n            if (enc->sample_aspect_ratio.num) {\n                av_reduce(&display_aspect_ratio.num, &display_aspect_ratio.den,\n                          enc->width * (int64_t)enc->sample_aspect_ratio.num,\n                          enc->height * (int64_t)enc->sample_aspect_ratio.den,\n                          1024 * 1024);\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \" [SAR %d:%d DAR %d:%d]\",\n                         enc->sample_aspect_ratio.num, enc->sample_aspect_ratio.den,\n                         display_aspect_ratio.num, display_aspect_ratio.den);\n            }\n            if (av_log_get_level() >= AV_LOG_DEBUG) {\n                int g = av_gcd(enc->time_base.num, enc->time_base.den);\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", %d/%d\",\n                         enc->time_base.num / g, enc->time_base.den / g);\n            }\n        }\n        if (encode) {\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", q=%d-%d\", enc->qmin, enc->qmax);\n        } else {\n            if (enc->properties & FF_CODEC_PROPERTY_CLOSED_CAPTIONS)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", Closed Captions\");\n            if (enc->properties & FF_CODEC_PROPERTY_LOSSLESS)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", lossless\");\n        }\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        av_strlcat(buf, separator, buf_size);\n\n        if (enc->sample_rate) {\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \"%d Hz, \", enc->sample_rate);\n        }\n        av_get_channel_layout_string(buf + strlen(buf), buf_size - strlen(buf), enc->channels, enc->channel_layout);\n        if (enc->sample_fmt != AV_SAMPLE_FMT_NONE) {\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", %s\", av_get_sample_fmt_name(enc->sample_fmt));\n        }\n        if (   enc->bits_per_raw_sample > 0\n            && enc->bits_per_raw_sample != av_get_bytes_per_sample(enc->sample_fmt) * 8)\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \" (%d bit)\", enc->bits_per_raw_sample);\n        if (av_log_get_level() >= AV_LOG_VERBOSE) {\n            if (enc->initial_padding)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", delay %d\", enc->initial_padding);\n            if (enc->trailing_padding)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", padding %d\", enc->trailing_padding);\n        }\n        break;\n    case AVMEDIA_TYPE_DATA:\n        if (av_log_get_level() >= AV_LOG_DEBUG) {\n            int g = av_gcd(enc->time_base.num, enc->time_base.den);\n            if (g)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", %d/%d\",\n                         enc->time_base.num / g, enc->time_base.den / g);\n        }\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        if (enc->width)\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", %dx%d\", enc->width, enc->height);\n        break;\n    default:\n        return;\n    }\n    if (encode) {\n        if (enc->flags & AV_CODEC_FLAG_PASS1)\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", pass 1\");\n        if (enc->flags & AV_CODEC_FLAG_PASS2)\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", pass 2\");\n    }\n    bitrate = get_bit_rate(enc);\n    if (bitrate != 0) {\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \", %\"PRId64\" kb/s\", bitrate / 1000);\n    } else if (enc->rc_max_rate > 0) {\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \", max. %\"PRId64\" kb/s\", (int64_t)enc->rc_max_rate / 1000);\n    }\n}\n\nconst char *av_get_profile_name(const AVCodec *codec, int profile)\n{\n    const AVProfile *p;\n    if (profile == FF_PROFILE_UNKNOWN || !codec->profiles)\n        return NULL;\n\n    for (p = codec->profiles; p->profile != FF_PROFILE_UNKNOWN; p++)\n        if (p->profile == profile)\n            return p->name;\n\n    return NULL;\n}\n\nconst char *avcodec_profile_name(enum AVCodecID codec_id, int profile)\n{\n    const AVCodecDescriptor *desc = avcodec_descriptor_get(codec_id);\n    const AVProfile *p;\n\n    if (profile == FF_PROFILE_UNKNOWN || !desc || !desc->profiles)\n        return NULL;\n\n    for (p = desc->profiles; p->profile != FF_PROFILE_UNKNOWN; p++)\n        if (p->profile == profile)\n            return p->name;\n\n    return NULL;\n}\n\nunsigned avcodec_version(void)\n{\n//    av_assert0(AV_CODEC_ID_V410==164);\n    av_assert0(AV_CODEC_ID_PCM_S8_PLANAR==65563);\n    av_assert0(AV_CODEC_ID_ADPCM_G722==69660);\n//     av_assert0(AV_CODEC_ID_BMV_AUDIO==86071);\n    av_assert0(AV_CODEC_ID_SRT==94216);\n    av_assert0(LIBAVCODEC_VERSION_MICRO >= 100);\n\n    return LIBAVCODEC_VERSION_INT;\n}\n\nconst char *avcodec_configuration(void)\n{\n    return FFMPEG_CONFIGURATION;\n}\n\nconst char *avcodec_license(void)\n{\n#define LICENSE_PREFIX \"libavcodec license: \"\n    return LICENSE_PREFIX FFMPEG_LICENSE + sizeof(LICENSE_PREFIX) - 1;\n}\n\nvoid avcodec_flush_buffers(AVCodecContext *avctx)\n{\n    avctx->internal->draining      = 0;\n    avctx->internal->draining_done = 0;\n    av_frame_unref(avctx->internal->buffer_frame);\n    av_packet_unref(avctx->internal->buffer_pkt);\n    avctx->internal->buffer_pkt_valid = 0;\n\n    if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n        ff_thread_flush(avctx);\n    else if (avctx->codec->flush)\n        avctx->codec->flush(avctx);\n\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (!avctx->refcounted_frames)\n        av_frame_unref(avctx->internal->to_free);\n}\n\nint av_get_exact_bits_per_sample(enum AVCodecID codec_id)\n{\n    switch (codec_id) {\n    case AV_CODEC_ID_8SVX_EXP:\n    case AV_CODEC_ID_8SVX_FIB:\n    case AV_CODEC_ID_ADPCM_CT:\n    case AV_CODEC_ID_ADPCM_IMA_APC:\n    case AV_CODEC_ID_ADPCM_IMA_EA_SEAD:\n    case AV_CODEC_ID_ADPCM_IMA_OKI:\n    case AV_CODEC_ID_ADPCM_IMA_WS:\n    case AV_CODEC_ID_ADPCM_G722:\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n    case AV_CODEC_ID_ADPCM_AICA:\n        return 4;\n    case AV_CODEC_ID_DSD_LSBF:\n    case AV_CODEC_ID_DSD_MSBF:\n    case AV_CODEC_ID_DSD_LSBF_PLANAR:\n    case AV_CODEC_ID_DSD_MSBF_PLANAR:\n    case AV_CODEC_ID_PCM_ALAW:\n    case AV_CODEC_ID_PCM_MULAW:\n    case AV_CODEC_ID_PCM_S8:\n    case AV_CODEC_ID_PCM_S8_PLANAR:\n    case AV_CODEC_ID_PCM_U8:\n    case AV_CODEC_ID_PCM_ZORK:\n    case AV_CODEC_ID_SDX2_DPCM:\n        return 8;\n    case AV_CODEC_ID_PCM_S16BE:\n    case AV_CODEC_ID_PCM_S16BE_PLANAR:\n    case AV_CODEC_ID_PCM_S16LE:\n    case AV_CODEC_ID_PCM_S16LE_PLANAR:\n    case AV_CODEC_ID_PCM_U16BE:\n    case AV_CODEC_ID_PCM_U16LE:\n        return 16;\n    case AV_CODEC_ID_PCM_S24DAUD:\n    case AV_CODEC_ID_PCM_S24BE:\n    case AV_CODEC_ID_PCM_S24LE:\n    case AV_CODEC_ID_PCM_S24LE_PLANAR:\n    case AV_CODEC_ID_PCM_U24BE:\n    case AV_CODEC_ID_PCM_U24LE:\n        return 24;\n    case AV_CODEC_ID_PCM_S32BE:\n    case AV_CODEC_ID_PCM_S32LE:\n    case AV_CODEC_ID_PCM_S32LE_PLANAR:\n    case AV_CODEC_ID_PCM_U32BE:\n    case AV_CODEC_ID_PCM_U32LE:\n    case AV_CODEC_ID_PCM_F32BE:\n    case AV_CODEC_ID_PCM_F32LE:\n    case AV_CODEC_ID_PCM_F24LE:\n    case AV_CODEC_ID_PCM_F16LE:\n        return 32;\n    case AV_CODEC_ID_PCM_F64BE:\n    case AV_CODEC_ID_PCM_F64LE:\n    case AV_CODEC_ID_PCM_S64BE:\n    case AV_CODEC_ID_PCM_S64LE:\n        return 64;\n    default:\n        return 0;\n    }\n}\n\nenum AVCodecID av_get_pcm_codec(enum AVSampleFormat fmt, int be)\n{\n    static const enum AVCodecID map[AV_SAMPLE_FMT_NB][2] = {\n        [AV_SAMPLE_FMT_U8  ] = { AV_CODEC_ID_PCM_U8,    AV_CODEC_ID_PCM_U8    },\n        [AV_SAMPLE_FMT_S16 ] = { AV_CODEC_ID_PCM_S16LE, AV_CODEC_ID_PCM_S16BE },\n        [AV_SAMPLE_FMT_S32 ] = { AV_CODEC_ID_PCM_S32LE, AV_CODEC_ID_PCM_S32BE },\n        [AV_SAMPLE_FMT_FLT ] = { AV_CODEC_ID_PCM_F32LE, AV_CODEC_ID_PCM_F32BE },\n        [AV_SAMPLE_FMT_DBL ] = { AV_CODEC_ID_PCM_F64LE, AV_CODEC_ID_PCM_F64BE },\n        [AV_SAMPLE_FMT_U8P ] = { AV_CODEC_ID_PCM_U8,    AV_CODEC_ID_PCM_U8    },\n        [AV_SAMPLE_FMT_S16P] = { AV_CODEC_ID_PCM_S16LE, AV_CODEC_ID_PCM_S16BE },\n        [AV_SAMPLE_FMT_S32P] = { AV_CODEC_ID_PCM_S32LE, AV_CODEC_ID_PCM_S32BE },\n        [AV_SAMPLE_FMT_S64P] = { AV_CODEC_ID_PCM_S64LE, AV_CODEC_ID_PCM_S64BE },\n        [AV_SAMPLE_FMT_FLTP] = { AV_CODEC_ID_PCM_F32LE, AV_CODEC_ID_PCM_F32BE },\n        [AV_SAMPLE_FMT_DBLP] = { AV_CODEC_ID_PCM_F64LE, AV_CODEC_ID_PCM_F64BE },\n    };\n    if (fmt < 0 || fmt >= AV_SAMPLE_FMT_NB)\n        return AV_CODEC_ID_NONE;\n    if (be < 0 || be > 1)\n        be = AV_NE(1, 0);\n    return map[fmt][be];\n}\n\nint av_get_bits_per_sample(enum AVCodecID codec_id)\n{\n    switch (codec_id) {\n    case AV_CODEC_ID_ADPCM_SBPRO_2:\n        return 2;\n    case AV_CODEC_ID_ADPCM_SBPRO_3:\n        return 3;\n    case AV_CODEC_ID_ADPCM_SBPRO_4:\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    case AV_CODEC_ID_ADPCM_SWF:\n    case AV_CODEC_ID_ADPCM_MS:\n        return 4;\n    default:\n        return av_get_exact_bits_per_sample(codec_id);\n    }\n}\n\nstatic int get_audio_frame_duration(enum AVCodecID id, int sr, int ch, int ba,\n                                    uint32_t tag, int bits_per_coded_sample, int64_t bitrate,\n                                    uint8_t * extradata, int frame_size, int frame_bytes)\n{\n    int bps = av_get_exact_bits_per_sample(id);\n    int framecount = (ba > 0 && frame_bytes / ba > 0) ? frame_bytes / ba : 1;\n\n    /* codecs with an exact constant bits per sample */\n    if (bps > 0 && ch > 0 && frame_bytes > 0 && ch < 32768 && bps < 32768)\n        return (frame_bytes * 8LL) / (bps * ch);\n    bps = bits_per_coded_sample;\n\n    /* codecs with a fixed packet duration */\n    switch (id) {\n    case AV_CODEC_ID_ADPCM_ADX:    return   32;\n    case AV_CODEC_ID_ADPCM_IMA_QT: return   64;\n    case AV_CODEC_ID_ADPCM_EA_XAS: return  128;\n    case AV_CODEC_ID_AMR_NB:\n    case AV_CODEC_ID_EVRC:\n    case AV_CODEC_ID_GSM:\n    case AV_CODEC_ID_QCELP:\n    case AV_CODEC_ID_RA_288:       return  160;\n    case AV_CODEC_ID_AMR_WB:\n    case AV_CODEC_ID_GSM_MS:       return  320;\n    case AV_CODEC_ID_MP1:          return  384;\n    case AV_CODEC_ID_ATRAC1:       return  512;\n    case AV_CODEC_ID_ATRAC3:       return 1024 * framecount;\n    case AV_CODEC_ID_ATRAC3P:      return 2048;\n    case AV_CODEC_ID_MP2:\n    case AV_CODEC_ID_MUSEPACK7:    return 1152;\n    case AV_CODEC_ID_AC3:          return 1536;\n    }\n\n    if (sr > 0) {\n        /* calc from sample rate */\n        if (id == AV_CODEC_ID_TTA)\n            return 256 * sr / 245;\n        else if (id == AV_CODEC_ID_DST)\n            return 588 * sr / 44100;\n\n        if (ch > 0) {\n            /* calc from sample rate and channels */\n            if (id == AV_CODEC_ID_BINKAUDIO_DCT)\n                return (480 << (sr / 22050)) / ch;\n        }\n    }\n\n    if (ba > 0) {\n        /* calc from block_align */\n        if (id == AV_CODEC_ID_SIPR) {\n            switch (ba) {\n            case 20: return 160;\n            case 19: return 144;\n            case 29: return 288;\n            case 37: return 480;\n            }\n        } else if (id == AV_CODEC_ID_ILBC) {\n            switch (ba) {\n            case 38: return 160;\n            case 50: return 240;\n            }\n        }\n    }\n\n    if (frame_bytes > 0) {\n        /* calc from frame_bytes only */\n        if (id == AV_CODEC_ID_TRUESPEECH)\n            return 240 * (frame_bytes / 32);\n        if (id == AV_CODEC_ID_NELLYMOSER)\n            return 256 * (frame_bytes / 64);\n        if (id == AV_CODEC_ID_RA_144)\n            return 160 * (frame_bytes / 20);\n        if (id == AV_CODEC_ID_G723_1)\n            return 240 * (frame_bytes / 24);\n\n        if (bps > 0) {\n            /* calc from frame_bytes and bits_per_coded_sample */\n            if (id == AV_CODEC_ID_ADPCM_G726)\n                return frame_bytes * 8 / bps;\n        }\n\n        if (ch > 0 && ch < INT_MAX/16) {\n            /* calc from frame_bytes and channels */\n            switch (id) {\n            case AV_CODEC_ID_ADPCM_AFC:\n                return frame_bytes / (9 * ch) * 16;\n            case AV_CODEC_ID_ADPCM_PSX:\n            case AV_CODEC_ID_ADPCM_DTK:\n                return frame_bytes / (16 * ch) * 28;\n            case AV_CODEC_ID_ADPCM_4XM:\n            case AV_CODEC_ID_ADPCM_IMA_DAT4:\n            case AV_CODEC_ID_ADPCM_IMA_ISS:\n                return (frame_bytes - 4 * ch) * 2 / ch;\n            case AV_CODEC_ID_ADPCM_IMA_SMJPEG:\n                return (frame_bytes - 4) * 2 / ch;\n            case AV_CODEC_ID_ADPCM_IMA_AMV:\n                return (frame_bytes - 8) * 2 / ch;\n            case AV_CODEC_ID_ADPCM_THP:\n            case AV_CODEC_ID_ADPCM_THP_LE:\n                if (extradata)\n                    return frame_bytes * 14 / (8 * ch);\n                break;\n            case AV_CODEC_ID_ADPCM_XA:\n                return (frame_bytes / 128) * 224 / ch;\n            case AV_CODEC_ID_INTERPLAY_DPCM:\n                return (frame_bytes - 6 - ch) / ch;\n            case AV_CODEC_ID_ROQ_DPCM:\n                return (frame_bytes - 8) / ch;\n            case AV_CODEC_ID_XAN_DPCM:\n                return (frame_bytes - 2 * ch) / ch;\n            case AV_CODEC_ID_MACE3:\n                return 3 * frame_bytes / ch;\n            case AV_CODEC_ID_MACE6:\n                return 6 * frame_bytes / ch;\n            case AV_CODEC_ID_PCM_LXF:\n                return 2 * (frame_bytes / (5 * ch));\n            case AV_CODEC_ID_IAC:\n            case AV_CODEC_ID_IMC:\n                return 4 * frame_bytes / ch;\n            }\n\n            if (tag) {\n                /* calc from frame_bytes, channels, and codec_tag */\n                if (id == AV_CODEC_ID_SOL_DPCM) {\n                    if (tag == 3)\n                        return frame_bytes / ch;\n                    else\n                        return frame_bytes * 2 / ch;\n                }\n            }\n\n            if (ba > 0) {\n                /* calc from frame_bytes, channels, and block_align */\n                int blocks = frame_bytes / ba;\n                switch (id) {\n                case AV_CODEC_ID_ADPCM_IMA_WAV:\n                    if (bps < 2 || bps > 5)\n                        return 0;\n                    return blocks * (1 + (ba - 4 * ch) / (bps * ch) * 8);\n                case AV_CODEC_ID_ADPCM_IMA_DK3:\n                    return blocks * (((ba - 16) * 2 / 3 * 4) / ch);\n                case AV_CODEC_ID_ADPCM_IMA_DK4:\n                    return blocks * (1 + (ba - 4 * ch) * 2 / ch);\n                case AV_CODEC_ID_ADPCM_IMA_RAD:\n                    return blocks * ((ba - 4 * ch) * 2 / ch);\n                case AV_CODEC_ID_ADPCM_MS:\n                    return blocks * (2 + (ba - 7 * ch) * 2 / ch);\n                case AV_CODEC_ID_ADPCM_MTAF:\n                    return blocks * (ba - 16) * 2 / ch;\n                }\n            }\n\n            if (bps > 0) {\n                /* calc from frame_bytes, channels, and bits_per_coded_sample */\n                switch (id) {\n                case AV_CODEC_ID_PCM_DVD:\n                    if(bps<4)\n                        return 0;\n                    return 2 * (frame_bytes / ((bps * 2 / 8) * ch));\n                case AV_CODEC_ID_PCM_BLURAY:\n                    if(bps<4)\n                        return 0;\n                    return frame_bytes / ((FFALIGN(ch, 2) * bps) / 8);\n                case AV_CODEC_ID_S302M:\n                    return 2 * (frame_bytes / ((bps + 4) / 4)) / ch;\n                }\n            }\n        }\n    }\n\n    /* Fall back on using frame_size */\n    if (frame_size > 1 && frame_bytes)\n        return frame_size;\n\n    //For WMA we currently have no other means to calculate duration thus we\n    //do it here by assuming CBR, which is true for all known cases.\n    if (bitrate > 0 && frame_bytes > 0 && sr > 0 && ba > 1) {\n        if (id == AV_CODEC_ID_WMAV1 || id == AV_CODEC_ID_WMAV2)\n            return  (frame_bytes * 8LL * sr) / bitrate;\n    }\n\n    return 0;\n}\n\nint av_get_audio_frame_duration(AVCodecContext *avctx, int frame_bytes)\n{\n    return get_audio_frame_duration(avctx->codec_id, avctx->sample_rate,\n                                    avctx->channels, avctx->block_align,\n                                    avctx->codec_tag, avctx->bits_per_coded_sample,\n                                    avctx->bit_rate, avctx->extradata, avctx->frame_size,\n                                    frame_bytes);\n}\n\nint av_get_audio_frame_duration2(AVCodecParameters *par, int frame_bytes)\n{\n    return get_audio_frame_duration(par->codec_id, par->sample_rate,\n                                    par->channels, par->block_align,\n                                    par->codec_tag, par->bits_per_coded_sample,\n                                    par->bit_rate, par->extradata, par->frame_size,\n                                    frame_bytes);\n}\n\n#if !HAVE_THREADS\nint ff_thread_init(AVCodecContext *s)\n{\n    return -1;\n}\n\n#endif\n\nunsigned int av_xiphlacing(unsigned char *s, unsigned int v)\n{\n    unsigned int n = 0;\n\n    while (v >= 0xff) {\n        *s++ = 0xff;\n        v -= 0xff;\n        n++;\n    }\n    *s = v;\n    n++;\n    return n;\n}\n\nint ff_match_2uint16(const uint16_t(*tab)[2], int size, int a, int b)\n{\n    int i;\n    for (i = 0; i < size && !(tab[i][0] == a && tab[i][1] == b); i++) ;\n    return i;\n}\n\n#if FF_API_MISSING_SAMPLE\nFF_DISABLE_DEPRECATION_WARNINGS\nvoid av_log_missing_feature(void *avc, const char *feature, int want_sample)\n{\n    av_log(avc, AV_LOG_WARNING, \"%s is not implemented. Update your FFmpeg \"\n            \"version to the newest one from Git. If the problem still \"\n            \"occurs, it means that your file has a feature which has not \"\n            \"been implemented.\\n\", feature);\n    if(want_sample)\n        av_log_ask_for_sample(avc, NULL);\n}\n\nvoid av_log_ask_for_sample(void *avc, const char *msg, ...)\n{\n    va_list argument_list;\n\n    va_start(argument_list, msg);\n\n    if (msg)\n        av_vlog(avc, AV_LOG_WARNING, msg, argument_list);\n    av_log(avc, AV_LOG_WARNING, \"If you want to help, upload a sample \"\n            \"of this file to ftp://upload.ffmpeg.org/incoming/ \"\n            \"and contact the ffmpeg-devel mailing list. (ffmpeg-devel@ffmpeg.org)\\n\");\n\n    va_end(argument_list);\n}\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif /* FF_API_MISSING_SAMPLE */\n\nstatic AVHWAccel *first_hwaccel = NULL;\nstatic AVHWAccel **last_hwaccel = &first_hwaccel;\n\nvoid av_register_hwaccel(AVHWAccel *hwaccel)\n{\n    AVHWAccel **p = last_hwaccel;\n    hwaccel->next = NULL;\n    while(*p || avpriv_atomic_ptr_cas((void * volatile *)p, NULL, hwaccel))\n        p = &(*p)->next;\n    last_hwaccel = &hwaccel->next;\n}\n\nAVHWAccel *av_hwaccel_next(const AVHWAccel *hwaccel)\n{\n    return hwaccel ? hwaccel->next : first_hwaccel;\n}\n\nint av_lockmgr_register(int (*cb)(void **mutex, enum AVLockOp op))\n{\n    if (lockmgr_cb) {\n        // There is no good way to rollback a failure to destroy the\n        // mutex, so we ignore failures.\n        lockmgr_cb(&codec_mutex,    AV_LOCK_DESTROY);\n        lockmgr_cb(&avformat_mutex, AV_LOCK_DESTROY);\n        lockmgr_cb     = NULL;\n        codec_mutex    = NULL;\n        avformat_mutex = NULL;\n    }\n\n    if (cb) {\n        void *new_codec_mutex    = NULL;\n        void *new_avformat_mutex = NULL;\n        int err;\n        if (err = cb(&new_codec_mutex, AV_LOCK_CREATE)) {\n            return err > 0 ? AVERROR_UNKNOWN : err;\n        }\n        if (err = cb(&new_avformat_mutex, AV_LOCK_CREATE)) {\n            // Ignore failures to destroy the newly created mutex.\n            cb(&new_codec_mutex, AV_LOCK_DESTROY);\n            return err > 0 ? AVERROR_UNKNOWN : err;\n        }\n        lockmgr_cb     = cb;\n        codec_mutex    = new_codec_mutex;\n        avformat_mutex = new_avformat_mutex;\n    }\n\n    return 0;\n}\n\nint ff_lock_avcodec(AVCodecContext *log_ctx, const AVCodec *codec)\n{\n    if (codec->caps_internal & FF_CODEC_CAP_INIT_THREADSAFE || !codec->init)\n        return 0;\n\n    if (lockmgr_cb) {\n        if ((*lockmgr_cb)(&codec_mutex, AV_LOCK_OBTAIN))\n            return -1;\n    }\n\n    if (avpriv_atomic_int_add_and_fetch(&entangled_thread_counter, 1) != 1) {\n        av_log(log_ctx, AV_LOG_ERROR,\n               \"Insufficient thread locking. At least %d threads are \"\n               \"calling avcodec_open2() at the same time right now.\\n\",\n               entangled_thread_counter);\n        if (!lockmgr_cb)\n            av_log(log_ctx, AV_LOG_ERROR, \"No lock manager is set, please see av_lockmgr_register()\\n\");\n        ff_avcodec_locked = 1;\n        ff_unlock_avcodec(codec);\n        return AVERROR(EINVAL);\n    }\n    av_assert0(!ff_avcodec_locked);\n    ff_avcodec_locked = 1;\n    return 0;\n}\n\nint ff_unlock_avcodec(const AVCodec *codec)\n{\n    if (codec->caps_internal & FF_CODEC_CAP_INIT_THREADSAFE || !codec->init)\n        return 0;\n\n    av_assert0(ff_avcodec_locked);\n    ff_avcodec_locked = 0;\n    avpriv_atomic_int_add_and_fetch(&entangled_thread_counter, -1);\n    if (lockmgr_cb) {\n        if ((*lockmgr_cb)(&codec_mutex, AV_LOCK_RELEASE))\n            return -1;\n    }\n\n    return 0;\n}\n\nint avpriv_lock_avformat(void)\n{\n    if (lockmgr_cb) {\n        if ((*lockmgr_cb)(&avformat_mutex, AV_LOCK_OBTAIN))\n            return -1;\n    }\n    return 0;\n}\n\nint avpriv_unlock_avformat(void)\n{\n    if (lockmgr_cb) {\n        if ((*lockmgr_cb)(&avformat_mutex, AV_LOCK_RELEASE))\n            return -1;\n    }\n    return 0;\n}\n\nunsigned int avpriv_toupper4(unsigned int x)\n{\n    return av_toupper(x & 0xFF) +\n          (av_toupper((x >>  8) & 0xFF) << 8)  +\n          (av_toupper((x >> 16) & 0xFF) << 16) +\n((unsigned)av_toupper((x >> 24) & 0xFF) << 24);\n}\n\nint ff_thread_ref_frame(ThreadFrame *dst, ThreadFrame *src)\n{\n    int ret;\n\n    dst->owner = src->owner;\n\n    ret = av_frame_ref(dst->f, src->f);\n    if (ret < 0)\n        return ret;\n\n    av_assert0(!dst->progress);\n\n    if (src->progress &&\n        !(dst->progress = av_buffer_ref(src->progress))) {\n        ff_thread_release_buffer(dst->owner, dst);\n        return AVERROR(ENOMEM);\n    }\n\n    return 0;\n}\n\n#if !HAVE_THREADS\n\nenum AVPixelFormat ff_thread_get_format(AVCodecContext *avctx, const enum AVPixelFormat *fmt)\n{\n    return ff_get_format(avctx, fmt);\n}\n\nint ff_thread_get_buffer(AVCodecContext *avctx, ThreadFrame *f, int flags)\n{\n    f->owner = avctx;\n    return ff_get_buffer(avctx, f->f, flags);\n}\n\nvoid ff_thread_release_buffer(AVCodecContext *avctx, ThreadFrame *f)\n{\n    if (f->f)\n        av_frame_unref(f->f);\n}\n\nvoid ff_thread_finish_setup(AVCodecContext *avctx)\n{\n}\n\nvoid ff_thread_report_progress(ThreadFrame *f, int progress, int field)\n{\n}\n\nvoid ff_thread_await_progress(ThreadFrame *f, int progress, int field)\n{\n}\n\nint ff_thread_can_start_frame(AVCodecContext *avctx)\n{\n    return 1;\n}\n\nint ff_alloc_entries(AVCodecContext *avctx, int count)\n{\n    return 0;\n}\n\nvoid ff_reset_entries(AVCodecContext *avctx)\n{\n}\n\nvoid ff_thread_await_progress2(AVCodecContext *avctx, int field, int thread, int shift)\n{\n}\n\nvoid ff_thread_report_progress2(AVCodecContext *avctx, int field, int thread, int n)\n{\n}\n\n#endif\n\nint avcodec_is_open(AVCodecContext *s)\n{\n    return !!s->internal;\n}\n\nint avpriv_bprint_to_extradata(AVCodecContext *avctx, struct AVBPrint *buf)\n{\n    int ret;\n    char *str;\n\n    ret = av_bprint_finalize(buf, &str);\n    if (ret < 0)\n        return ret;\n    if (!av_bprint_is_complete(buf)) {\n        av_free(str);\n        return AVERROR(ENOMEM);\n    }\n\n    avctx->extradata = str;\n    /* Note: the string is NUL terminated (so extradata can be read as a\n     * string), but the ending character is not accounted in the size (in\n     * binary formats you are likely not supposed to mux that character). When\n     * extradata is copied, it is also padded with AV_INPUT_BUFFER_PADDING_SIZE\n     * zeros. */\n    avctx->extradata_size = buf->len;\n    return 0;\n}\n\nconst uint8_t *avpriv_find_start_code(const uint8_t *av_restrict p,\n                                      const uint8_t *end,\n                                      uint32_t *av_restrict state)\n{\n    int i;\n\n    av_assert0(p <= end);\n    if (p >= end)\n        return end;\n\n    for (i = 0; i < 3; i++) {\n        uint32_t tmp = *state << 8;\n        *state = tmp + *(p++);\n        if (tmp == 0x100 || p == end)\n            return p;\n    }\n\n    while (p < end) {\n        if      (p[-1] > 1      ) p += 3;\n        else if (p[-2]          ) p += 2;\n        else if (p[-3]|(p[-1]-1)) p++;\n        else {\n            p++;\n            break;\n        }\n    }\n\n    p = FFMIN(p, end) - 4;\n    *state = AV_RB32(p);\n\n    return p + 4;\n}\n\nAVCPBProperties *av_cpb_properties_alloc(size_t *size)\n{\n    AVCPBProperties *props = av_mallocz(sizeof(AVCPBProperties));\n    if (!props)\n        return NULL;\n\n    if (size)\n        *size = sizeof(*props);\n\n    props->vbv_delay = UINT64_MAX;\n\n    return props;\n}\n\nAVCPBProperties *ff_add_cpb_side_data(AVCodecContext *avctx)\n{\n    AVPacketSideData *tmp;\n    AVCPBProperties  *props;\n    size_t size;\n\n    props = av_cpb_properties_alloc(&size);\n    if (!props)\n        return NULL;\n\n    tmp = av_realloc_array(avctx->coded_side_data, avctx->nb_coded_side_data + 1, sizeof(*tmp));\n    if (!tmp) {\n        av_freep(&props);\n        return NULL;\n    }\n\n    avctx->coded_side_data = tmp;\n    avctx->nb_coded_side_data++;\n\n    avctx->coded_side_data[avctx->nb_coded_side_data - 1].type = AV_PKT_DATA_CPB_PROPERTIES;\n    avctx->coded_side_data[avctx->nb_coded_side_data - 1].data = (uint8_t*)props;\n    avctx->coded_side_data[avctx->nb_coded_side_data - 1].size = size;\n\n    return props;\n}\n\nstatic void codec_parameters_reset(AVCodecParameters *par)\n{\n    av_freep(&par->extradata);\n\n    memset(par, 0, sizeof(*par));\n\n    par->codec_type          = AVMEDIA_TYPE_UNKNOWN;\n    par->codec_id            = AV_CODEC_ID_NONE;\n    par->format              = -1;\n    par->field_order         = AV_FIELD_UNKNOWN;\n    par->color_range         = AVCOL_RANGE_UNSPECIFIED;\n    par->color_primaries     = AVCOL_PRI_UNSPECIFIED;\n    par->color_trc           = AVCOL_TRC_UNSPECIFIED;\n    par->color_space         = AVCOL_SPC_UNSPECIFIED;\n    par->chroma_location     = AVCHROMA_LOC_UNSPECIFIED;\n    par->sample_aspect_ratio = (AVRational){ 0, 1 };\n    par->profile             = FF_PROFILE_UNKNOWN;\n    par->level               = FF_LEVEL_UNKNOWN;\n}\n\nAVCodecParameters *avcodec_parameters_alloc(void)\n{\n    AVCodecParameters *par = av_mallocz(sizeof(*par));\n\n    if (!par)\n        return NULL;\n    codec_parameters_reset(par);\n    return par;\n}\n\nvoid avcodec_parameters_free(AVCodecParameters **ppar)\n{\n    AVCodecParameters *par = *ppar;\n\n    if (!par)\n        return;\n    codec_parameters_reset(par);\n\n    av_freep(ppar);\n}\n\nint avcodec_parameters_copy(AVCodecParameters *dst, const AVCodecParameters *src)\n{\n    codec_parameters_reset(dst);\n    memcpy(dst, src, sizeof(*dst));\n\n    dst->extradata      = NULL;\n    dst->extradata_size = 0;\n    if (src->extradata) {\n        dst->extradata = av_mallocz(src->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n        if (!dst->extradata)\n            return AVERROR(ENOMEM);\n        memcpy(dst->extradata, src->extradata, src->extradata_size);\n        dst->extradata_size = src->extradata_size;\n    }\n\n    return 0;\n}\n\nint avcodec_parameters_from_context(AVCodecParameters *par,\n                                    const AVCodecContext *codec)\n{\n    codec_parameters_reset(par);\n\n    par->codec_type = codec->codec_type;\n    par->codec_id   = codec->codec_id;\n    par->codec_tag  = codec->codec_tag;\n\n    par->bit_rate              = codec->bit_rate;\n    par->bits_per_coded_sample = codec->bits_per_coded_sample;\n    par->bits_per_raw_sample   = codec->bits_per_raw_sample;\n    par->profile               = codec->profile;\n    par->level                 = codec->level;\n\n    switch (par->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        par->format              = codec->pix_fmt;\n        par->width               = codec->width;\n        par->height              = codec->height;\n        par->field_order         = codec->field_order;\n        par->color_range         = codec->color_range;\n        par->color_primaries     = codec->color_primaries;\n        par->color_trc           = codec->color_trc;\n        par->color_space         = codec->colorspace;\n        par->chroma_location     = codec->chroma_sample_location;\n        par->sample_aspect_ratio = codec->sample_aspect_ratio;\n        par->video_delay         = codec->has_b_frames;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        par->format           = codec->sample_fmt;\n        par->channel_layout   = codec->channel_layout;\n        par->channels         = codec->channels;\n        par->sample_rate      = codec->sample_rate;\n        par->block_align      = codec->block_align;\n        par->frame_size       = codec->frame_size;\n        par->initial_padding  = codec->initial_padding;\n        par->trailing_padding = codec->trailing_padding;\n        par->seek_preroll     = codec->seek_preroll;\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        par->width  = codec->width;\n        par->height = codec->height;\n        break;\n    }\n\n    if (codec->extradata) {\n        par->extradata = av_mallocz(codec->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n        if (!par->extradata)\n            return AVERROR(ENOMEM);\n        memcpy(par->extradata, codec->extradata, codec->extradata_size);\n        par->extradata_size = codec->extradata_size;\n    }\n\n    return 0;\n}\n\nint avcodec_parameters_to_context(AVCodecContext *codec,\n                                  const AVCodecParameters *par)\n{\n    codec->codec_type = par->codec_type;\n    codec->codec_id   = par->codec_id;\n    codec->codec_tag  = par->codec_tag;\n\n    codec->bit_rate              = par->bit_rate;\n    codec->bits_per_coded_sample = par->bits_per_coded_sample;\n    codec->bits_per_raw_sample   = par->bits_per_raw_sample;\n    codec->profile               = par->profile;\n    codec->level                 = par->level;\n\n    switch (par->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        codec->pix_fmt                = par->format;\n        codec->width                  = par->width;\n        codec->height                 = par->height;\n        codec->field_order            = par->field_order;\n        codec->color_range            = par->color_range;\n        codec->color_primaries        = par->color_primaries;\n        codec->color_trc              = par->color_trc;\n        codec->colorspace             = par->color_space;\n        codec->chroma_sample_location = par->chroma_location;\n        codec->sample_aspect_ratio    = par->sample_aspect_ratio;\n        codec->has_b_frames           = par->video_delay;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        codec->sample_fmt       = par->format;\n        codec->channel_layout   = par->channel_layout;\n        codec->channels         = par->channels;\n        codec->sample_rate      = par->sample_rate;\n        codec->block_align      = par->block_align;\n        codec->frame_size       = par->frame_size;\n        codec->delay            =\n        codec->initial_padding  = par->initial_padding;\n        codec->trailing_padding = par->trailing_padding;\n        codec->seek_preroll     = par->seek_preroll;\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        codec->width  = par->width;\n        codec->height = par->height;\n        break;\n    }\n\n    if (par->extradata) {\n        av_freep(&codec->extradata);\n        codec->extradata = av_mallocz(par->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n        if (!codec->extradata)\n            return AVERROR(ENOMEM);\n        memcpy(codec->extradata, par->extradata, par->extradata_size);\n        codec->extradata_size = par->extradata_size;\n    }\n\n    return 0;\n}\n\nint ff_alloc_a53_sei(const AVFrame *frame, size_t prefix_len,\n                     void **data, size_t *sei_size)\n{\n    AVFrameSideData *side_data = NULL;\n    uint8_t *sei_data;\n\n    if (frame)\n        side_data = av_frame_get_side_data(frame, AV_FRAME_DATA_A53_CC);\n\n    if (!side_data) {\n        *data = NULL;\n        return 0;\n    }\n\n    *sei_size = side_data->size + 11;\n    *data = av_mallocz(*sei_size + prefix_len);\n    if (!*data)\n        return AVERROR(ENOMEM);\n    sei_data = (uint8_t*)*data + prefix_len;\n\n    // country code\n    sei_data[0] = 181;\n    sei_data[1] = 0;\n    sei_data[2] = 49;\n\n    /**\n     * 'GA94' is standard in North America for ATSC, but hard coding\n     * this style may not be the right thing to do -- other formats\n     * do exist. This information is not available in the side_data\n     * so we are going with this right now.\n     */\n    AV_WL32(sei_data + 3, MKTAG('G', 'A', '9', '4'));\n    sei_data[7] = 3;\n    sei_data[8] = ((side_data->size/3) & 0x1f) | 0x40;\n    sei_data[9] = 0;\n\n    memcpy(sei_data + 10, side_data->data, side_data->size);\n\n    sei_data[side_data->size+10] = 255;\n\n    return 0;\n}\n"], "fixing_code": ["/*\n * utils for libavcodec\n * Copyright (c) 2001 Fabrice Bellard\n * Copyright (c) 2002-2004 Michael Niedermayer <michaelni@gmx.at>\n *\n * This file is part of FFmpeg.\n *\n * FFmpeg is free software; you can redistribute it and/or\n * modify it under the terms of the GNU Lesser General Public\n * License as published by the Free Software Foundation; either\n * version 2.1 of the License, or (at your option) any later version.\n *\n * FFmpeg is distributed in the hope that it will be useful,\n * but WITHOUT ANY WARRANTY; without even the implied warranty of\n * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU\n * Lesser General Public License for more details.\n *\n * You should have received a copy of the GNU Lesser General Public\n * License along with FFmpeg; if not, write to the Free Software\n * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA\n */\n\n/**\n * @file\n * utils.\n */\n\n#include \"config.h\"\n#include \"libavutil/atomic.h\"\n#include \"libavutil/attributes.h\"\n#include \"libavutil/avassert.h\"\n#include \"libavutil/avstring.h\"\n#include \"libavutil/bprint.h\"\n#include \"libavutil/channel_layout.h\"\n#include \"libavutil/crc.h\"\n#include \"libavutil/frame.h\"\n#include \"libavutil/hwcontext.h\"\n#include \"libavutil/internal.h\"\n#include \"libavutil/mathematics.h\"\n#include \"libavutil/mem_internal.h\"\n#include \"libavutil/pixdesc.h\"\n#include \"libavutil/imgutils.h\"\n#include \"libavutil/samplefmt.h\"\n#include \"libavutil/dict.h\"\n#include \"libavutil/thread.h\"\n#include \"avcodec.h\"\n#include \"libavutil/opt.h\"\n#include \"me_cmp.h\"\n#include \"mpegvideo.h\"\n#include \"thread.h\"\n#include \"frame_thread_encoder.h\"\n#include \"internal.h\"\n#include \"raw.h\"\n#include \"bytestream.h\"\n#include \"version.h\"\n#include <stdlib.h>\n#include <stdarg.h>\n#include <limits.h>\n#include <float.h>\n#if CONFIG_ICONV\n# include <iconv.h>\n#endif\n\n#include \"libavutil/ffversion.h\"\nconst char av_codec_ffversion[] = \"FFmpeg version \" FFMPEG_VERSION;\n\n#if HAVE_PTHREADS || HAVE_W32THREADS || HAVE_OS2THREADS\nstatic int default_lockmgr_cb(void **arg, enum AVLockOp op)\n{\n    void * volatile * mutex = arg;\n    int err;\n\n    switch (op) {\n    case AV_LOCK_CREATE:\n        return 0;\n    case AV_LOCK_OBTAIN:\n        if (!*mutex) {\n            pthread_mutex_t *tmp = av_malloc(sizeof(pthread_mutex_t));\n            if (!tmp)\n                return AVERROR(ENOMEM);\n            if ((err = pthread_mutex_init(tmp, NULL))) {\n                av_free(tmp);\n                return AVERROR(err);\n            }\n            if (avpriv_atomic_ptr_cas(mutex, NULL, tmp)) {\n                pthread_mutex_destroy(tmp);\n                av_free(tmp);\n            }\n        }\n\n        if ((err = pthread_mutex_lock(*mutex)))\n            return AVERROR(err);\n\n        return 0;\n    case AV_LOCK_RELEASE:\n        if ((err = pthread_mutex_unlock(*mutex)))\n            return AVERROR(err);\n\n        return 0;\n    case AV_LOCK_DESTROY:\n        if (*mutex)\n            pthread_mutex_destroy(*mutex);\n        av_free(*mutex);\n        avpriv_atomic_ptr_cas(mutex, *mutex, NULL);\n        return 0;\n    }\n    return 1;\n}\nstatic int (*lockmgr_cb)(void **mutex, enum AVLockOp op) = default_lockmgr_cb;\n#else\nstatic int (*lockmgr_cb)(void **mutex, enum AVLockOp op) = NULL;\n#endif\n\n\nvolatile int ff_avcodec_locked;\nstatic int volatile entangled_thread_counter = 0;\nstatic void *codec_mutex;\nstatic void *avformat_mutex;\n\nvoid av_fast_padded_malloc(void *ptr, unsigned int *size, size_t min_size)\n{\n    uint8_t **p = ptr;\n    if (min_size > SIZE_MAX - AV_INPUT_BUFFER_PADDING_SIZE) {\n        av_freep(p);\n        *size = 0;\n        return;\n    }\n    if (!ff_fast_malloc(p, size, min_size + AV_INPUT_BUFFER_PADDING_SIZE, 1))\n        memset(*p + min_size, 0, AV_INPUT_BUFFER_PADDING_SIZE);\n}\n\nvoid av_fast_padded_mallocz(void *ptr, unsigned int *size, size_t min_size)\n{\n    uint8_t **p = ptr;\n    if (min_size > SIZE_MAX - AV_INPUT_BUFFER_PADDING_SIZE) {\n        av_freep(p);\n        *size = 0;\n        return;\n    }\n    if (!ff_fast_malloc(p, size, min_size + AV_INPUT_BUFFER_PADDING_SIZE, 1))\n        memset(*p, 0, min_size + AV_INPUT_BUFFER_PADDING_SIZE);\n}\n\n/* encoder management */\nstatic AVCodec *first_avcodec = NULL;\nstatic AVCodec **last_avcodec = &first_avcodec;\n\nAVCodec *av_codec_next(const AVCodec *c)\n{\n    if (c)\n        return c->next;\n    else\n        return first_avcodec;\n}\n\nstatic av_cold void avcodec_init(void)\n{\n    static int initialized = 0;\n\n    if (initialized != 0)\n        return;\n    initialized = 1;\n\n    if (CONFIG_ME_CMP)\n        ff_me_cmp_init_static();\n}\n\nint av_codec_is_encoder(const AVCodec *codec)\n{\n    return codec && (codec->encode_sub || codec->encode2 ||codec->send_frame);\n}\n\nint av_codec_is_decoder(const AVCodec *codec)\n{\n    return codec && (codec->decode || codec->send_packet);\n}\n\nav_cold void avcodec_register(AVCodec *codec)\n{\n    AVCodec **p;\n    avcodec_init();\n    p = last_avcodec;\n    codec->next = NULL;\n\n    while(*p || avpriv_atomic_ptr_cas((void * volatile *)p, NULL, codec))\n        p = &(*p)->next;\n    last_avcodec = &codec->next;\n\n    if (codec->init_static_data)\n        codec->init_static_data(codec);\n}\n\n#if FF_API_EMU_EDGE\nunsigned avcodec_get_edge_width(void)\n{\n    return EDGE_WIDTH;\n}\n#endif\n\n#if FF_API_SET_DIMENSIONS\nvoid avcodec_set_dimensions(AVCodecContext *s, int width, int height)\n{\n    int ret = ff_set_dimensions(s, width, height);\n    if (ret < 0) {\n        av_log(s, AV_LOG_WARNING, \"Failed to set dimensions %d %d\\n\", width, height);\n    }\n}\n#endif\n\nint ff_set_dimensions(AVCodecContext *s, int width, int height)\n{\n    int ret = av_image_check_size2(width, height, s->max_pixels, AV_PIX_FMT_NONE, 0, s);\n\n    if (ret < 0)\n        width = height = 0;\n\n    s->coded_width  = width;\n    s->coded_height = height;\n    s->width        = AV_CEIL_RSHIFT(width,  s->lowres);\n    s->height       = AV_CEIL_RSHIFT(height, s->lowres);\n\n    return ret;\n}\n\nint ff_set_sar(AVCodecContext *avctx, AVRational sar)\n{\n    int ret = av_image_check_sar(avctx->width, avctx->height, sar);\n\n    if (ret < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %d/%d\\n\",\n               sar.num, sar.den);\n        avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        return ret;\n    } else {\n        avctx->sample_aspect_ratio = sar;\n    }\n    return 0;\n}\n\nint ff_side_data_update_matrix_encoding(AVFrame *frame,\n                                        enum AVMatrixEncoding matrix_encoding)\n{\n    AVFrameSideData *side_data;\n    enum AVMatrixEncoding *data;\n\n    side_data = av_frame_get_side_data(frame, AV_FRAME_DATA_MATRIXENCODING);\n    if (!side_data)\n        side_data = av_frame_new_side_data(frame, AV_FRAME_DATA_MATRIXENCODING,\n                                           sizeof(enum AVMatrixEncoding));\n\n    if (!side_data)\n        return AVERROR(ENOMEM);\n\n    data  = (enum AVMatrixEncoding*)side_data->data;\n    *data = matrix_encoding;\n\n    return 0;\n}\n\nvoid avcodec_align_dimensions2(AVCodecContext *s, int *width, int *height,\n                               int linesize_align[AV_NUM_DATA_POINTERS])\n{\n    int i;\n    int w_align = 1;\n    int h_align = 1;\n    AVPixFmtDescriptor const *desc = av_pix_fmt_desc_get(s->pix_fmt);\n\n    if (desc) {\n        w_align = 1 << desc->log2_chroma_w;\n        h_align = 1 << desc->log2_chroma_h;\n    }\n\n    switch (s->pix_fmt) {\n    case AV_PIX_FMT_YUV420P:\n    case AV_PIX_FMT_YUYV422:\n    case AV_PIX_FMT_YVYU422:\n    case AV_PIX_FMT_UYVY422:\n    case AV_PIX_FMT_YUV422P:\n    case AV_PIX_FMT_YUV440P:\n    case AV_PIX_FMT_YUV444P:\n    case AV_PIX_FMT_GBRP:\n    case AV_PIX_FMT_GBRAP:\n    case AV_PIX_FMT_GRAY8:\n    case AV_PIX_FMT_GRAY16BE:\n    case AV_PIX_FMT_GRAY16LE:\n    case AV_PIX_FMT_YUVJ420P:\n    case AV_PIX_FMT_YUVJ422P:\n    case AV_PIX_FMT_YUVJ440P:\n    case AV_PIX_FMT_YUVJ444P:\n    case AV_PIX_FMT_YUVA420P:\n    case AV_PIX_FMT_YUVA422P:\n    case AV_PIX_FMT_YUVA444P:\n    case AV_PIX_FMT_YUV420P9LE:\n    case AV_PIX_FMT_YUV420P9BE:\n    case AV_PIX_FMT_YUV420P10LE:\n    case AV_PIX_FMT_YUV420P10BE:\n    case AV_PIX_FMT_YUV420P12LE:\n    case AV_PIX_FMT_YUV420P12BE:\n    case AV_PIX_FMT_YUV420P14LE:\n    case AV_PIX_FMT_YUV420P14BE:\n    case AV_PIX_FMT_YUV420P16LE:\n    case AV_PIX_FMT_YUV420P16BE:\n    case AV_PIX_FMT_YUVA420P9LE:\n    case AV_PIX_FMT_YUVA420P9BE:\n    case AV_PIX_FMT_YUVA420P10LE:\n    case AV_PIX_FMT_YUVA420P10BE:\n    case AV_PIX_FMT_YUVA420P16LE:\n    case AV_PIX_FMT_YUVA420P16BE:\n    case AV_PIX_FMT_YUV422P9LE:\n    case AV_PIX_FMT_YUV422P9BE:\n    case AV_PIX_FMT_YUV422P10LE:\n    case AV_PIX_FMT_YUV422P10BE:\n    case AV_PIX_FMT_YUV422P12LE:\n    case AV_PIX_FMT_YUV422P12BE:\n    case AV_PIX_FMT_YUV422P14LE:\n    case AV_PIX_FMT_YUV422P14BE:\n    case AV_PIX_FMT_YUV422P16LE:\n    case AV_PIX_FMT_YUV422P16BE:\n    case AV_PIX_FMT_YUVA422P9LE:\n    case AV_PIX_FMT_YUVA422P9BE:\n    case AV_PIX_FMT_YUVA422P10LE:\n    case AV_PIX_FMT_YUVA422P10BE:\n    case AV_PIX_FMT_YUVA422P16LE:\n    case AV_PIX_FMT_YUVA422P16BE:\n    case AV_PIX_FMT_YUV440P10LE:\n    case AV_PIX_FMT_YUV440P10BE:\n    case AV_PIX_FMT_YUV440P12LE:\n    case AV_PIX_FMT_YUV440P12BE:\n    case AV_PIX_FMT_YUV444P9LE:\n    case AV_PIX_FMT_YUV444P9BE:\n    case AV_PIX_FMT_YUV444P10LE:\n    case AV_PIX_FMT_YUV444P10BE:\n    case AV_PIX_FMT_YUV444P12LE:\n    case AV_PIX_FMT_YUV444P12BE:\n    case AV_PIX_FMT_YUV444P14LE:\n    case AV_PIX_FMT_YUV444P14BE:\n    case AV_PIX_FMT_YUV444P16LE:\n    case AV_PIX_FMT_YUV444P16BE:\n    case AV_PIX_FMT_YUVA444P9LE:\n    case AV_PIX_FMT_YUVA444P9BE:\n    case AV_PIX_FMT_YUVA444P10LE:\n    case AV_PIX_FMT_YUVA444P10BE:\n    case AV_PIX_FMT_YUVA444P16LE:\n    case AV_PIX_FMT_YUVA444P16BE:\n    case AV_PIX_FMT_GBRP9LE:\n    case AV_PIX_FMT_GBRP9BE:\n    case AV_PIX_FMT_GBRP10LE:\n    case AV_PIX_FMT_GBRP10BE:\n    case AV_PIX_FMT_GBRP12LE:\n    case AV_PIX_FMT_GBRP12BE:\n    case AV_PIX_FMT_GBRP14LE:\n    case AV_PIX_FMT_GBRP14BE:\n    case AV_PIX_FMT_GBRP16LE:\n    case AV_PIX_FMT_GBRP16BE:\n    case AV_PIX_FMT_GBRAP12LE:\n    case AV_PIX_FMT_GBRAP12BE:\n    case AV_PIX_FMT_GBRAP16LE:\n    case AV_PIX_FMT_GBRAP16BE:\n        w_align = 16; //FIXME assume 16 pixel per macroblock\n        h_align = 16 * 2; // interlaced needs 2 macroblocks height\n        break;\n    case AV_PIX_FMT_YUV411P:\n    case AV_PIX_FMT_YUVJ411P:\n    case AV_PIX_FMT_UYYVYY411:\n        w_align = 32;\n        h_align = 16 * 2;\n        break;\n    case AV_PIX_FMT_YUV410P:\n        if (s->codec_id == AV_CODEC_ID_SVQ1) {\n            w_align = 64;\n            h_align = 64;\n        }\n        break;\n    case AV_PIX_FMT_RGB555:\n        if (s->codec_id == AV_CODEC_ID_RPZA) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_PAL8:\n    case AV_PIX_FMT_BGR8:\n    case AV_PIX_FMT_RGB8:\n        if (s->codec_id == AV_CODEC_ID_SMC ||\n            s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        if (s->codec_id == AV_CODEC_ID_JV ||\n            s->codec_id == AV_CODEC_ID_INTERPLAY_VIDEO) {\n            w_align = 8;\n            h_align = 8;\n        }\n        break;\n    case AV_PIX_FMT_BGR24:\n        if ((s->codec_id == AV_CODEC_ID_MSZH) ||\n            (s->codec_id == AV_CODEC_ID_ZLIB)) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    case AV_PIX_FMT_RGB24:\n        if (s->codec_id == AV_CODEC_ID_CINEPAK) {\n            w_align = 4;\n            h_align = 4;\n        }\n        break;\n    default:\n        break;\n    }\n\n    if (s->codec_id == AV_CODEC_ID_IFF_ILBM) {\n        w_align = FFMAX(w_align, 8);\n    }\n\n    *width  = FFALIGN(*width, w_align);\n    *height = FFALIGN(*height, h_align);\n    if (s->codec_id == AV_CODEC_ID_H264 || s->lowres) {\n        // some of the optimized chroma MC reads one line too much\n        // which is also done in mpeg decoders with lowres > 0\n        *height += 2;\n\n        // H.264 uses edge emulation for out of frame motion vectors, for this\n        // it requires a temporary area large enough to hold a 21x21 block,\n        // increasing witdth ensure that the temporary area is large enough,\n        // the next rounded up width is 32\n        *width = FFMAX(*width, 32);\n    }\n\n    for (i = 0; i < 4; i++)\n        linesize_align[i] = STRIDE_ALIGN;\n}\n\nvoid avcodec_align_dimensions(AVCodecContext *s, int *width, int *height)\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(s->pix_fmt);\n    int chroma_shift = desc->log2_chroma_w;\n    int linesize_align[AV_NUM_DATA_POINTERS];\n    int align;\n\n    avcodec_align_dimensions2(s, width, height, linesize_align);\n    align               = FFMAX(linesize_align[0], linesize_align[3]);\n    linesize_align[1] <<= chroma_shift;\n    linesize_align[2] <<= chroma_shift;\n    align               = FFMAX3(align, linesize_align[1], linesize_align[2]);\n    *width              = FFALIGN(*width, align);\n}\n\nint avcodec_enum_to_chroma_pos(int *xpos, int *ypos, enum AVChromaLocation pos)\n{\n    if (pos <= AVCHROMA_LOC_UNSPECIFIED || pos >= AVCHROMA_LOC_NB)\n        return AVERROR(EINVAL);\n    pos--;\n\n    *xpos = (pos&1) * 128;\n    *ypos = ((pos>>1)^(pos<4)) * 128;\n\n    return 0;\n}\n\nenum AVChromaLocation avcodec_chroma_pos_to_enum(int xpos, int ypos)\n{\n    int pos, xout, yout;\n\n    for (pos = AVCHROMA_LOC_UNSPECIFIED + 1; pos < AVCHROMA_LOC_NB; pos++) {\n        if (avcodec_enum_to_chroma_pos(&xout, &yout, pos) == 0 && xout == xpos && yout == ypos)\n            return pos;\n    }\n    return AVCHROMA_LOC_UNSPECIFIED;\n}\n\nint avcodec_fill_audio_frame(AVFrame *frame, int nb_channels,\n                             enum AVSampleFormat sample_fmt, const uint8_t *buf,\n                             int buf_size, int align)\n{\n    int ch, planar, needed_size, ret = 0;\n\n    needed_size = av_samples_get_buffer_size(NULL, nb_channels,\n                                             frame->nb_samples, sample_fmt,\n                                             align);\n    if (buf_size < needed_size)\n        return AVERROR(EINVAL);\n\n    planar = av_sample_fmt_is_planar(sample_fmt);\n    if (planar && nb_channels > AV_NUM_DATA_POINTERS) {\n        if (!(frame->extended_data = av_mallocz_array(nb_channels,\n                                                sizeof(*frame->extended_data))))\n            return AVERROR(ENOMEM);\n    } else {\n        frame->extended_data = frame->data;\n    }\n\n    if ((ret = av_samples_fill_arrays(frame->extended_data, &frame->linesize[0],\n                                      (uint8_t *)(intptr_t)buf, nb_channels, frame->nb_samples,\n                                      sample_fmt, align)) < 0) {\n        if (frame->extended_data != frame->data)\n            av_freep(&frame->extended_data);\n        return ret;\n    }\n    if (frame->extended_data != frame->data) {\n        for (ch = 0; ch < AV_NUM_DATA_POINTERS; ch++)\n            frame->data[ch] = frame->extended_data[ch];\n    }\n\n    return ret;\n}\n\nstatic int update_frame_pool(AVCodecContext *avctx, AVFrame *frame)\n{\n    FramePool *pool = avctx->internal->pool;\n    int i, ret;\n\n    switch (avctx->codec_type) {\n    case AVMEDIA_TYPE_VIDEO: {\n        uint8_t *data[4];\n        int linesize[4];\n        int size[4] = { 0 };\n        int w = frame->width;\n        int h = frame->height;\n        int tmpsize, unaligned;\n\n        if (pool->format == frame->format &&\n            pool->width == frame->width && pool->height == frame->height)\n            return 0;\n\n        avcodec_align_dimensions2(avctx, &w, &h, pool->stride_align);\n\n        do {\n            // NOTE: do not align linesizes individually, this breaks e.g. assumptions\n            // that linesize[0] == 2*linesize[1] in the MPEG-encoder for 4:2:2\n            ret = av_image_fill_linesizes(linesize, avctx->pix_fmt, w);\n            if (ret < 0)\n                return ret;\n            // increase alignment of w for next try (rhs gives the lowest bit set in w)\n            w += w & ~(w - 1);\n\n            unaligned = 0;\n            for (i = 0; i < 4; i++)\n                unaligned |= linesize[i] % pool->stride_align[i];\n        } while (unaligned);\n\n        tmpsize = av_image_fill_pointers(data, avctx->pix_fmt, h,\n                                         NULL, linesize);\n        if (tmpsize < 0)\n            return -1;\n\n        for (i = 0; i < 3 && data[i + 1]; i++)\n            size[i] = data[i + 1] - data[i];\n        size[i] = tmpsize - (data[i] - data[0]);\n\n        for (i = 0; i < 4; i++) {\n            av_buffer_pool_uninit(&pool->pools[i]);\n            pool->linesize[i] = linesize[i];\n            if (size[i]) {\n                pool->pools[i] = av_buffer_pool_init(size[i] + 16 + STRIDE_ALIGN - 1,\n                                                     CONFIG_MEMORY_POISONING ?\n                                                        NULL :\n                                                        av_buffer_allocz);\n                if (!pool->pools[i]) {\n                    ret = AVERROR(ENOMEM);\n                    goto fail;\n                }\n            }\n        }\n        pool->format = frame->format;\n        pool->width  = frame->width;\n        pool->height = frame->height;\n\n        break;\n        }\n    case AVMEDIA_TYPE_AUDIO: {\n        int ch     = av_frame_get_channels(frame); //av_get_channel_layout_nb_channels(frame->channel_layout);\n        int planar = av_sample_fmt_is_planar(frame->format);\n        int planes = planar ? ch : 1;\n\n        if (pool->format == frame->format && pool->planes == planes &&\n            pool->channels == ch && frame->nb_samples == pool->samples)\n            return 0;\n\n        av_buffer_pool_uninit(&pool->pools[0]);\n        ret = av_samples_get_buffer_size(&pool->linesize[0], ch,\n                                         frame->nb_samples, frame->format, 0);\n        if (ret < 0)\n            goto fail;\n\n        pool->pools[0] = av_buffer_pool_init(pool->linesize[0], NULL);\n        if (!pool->pools[0]) {\n            ret = AVERROR(ENOMEM);\n            goto fail;\n        }\n\n        pool->format     = frame->format;\n        pool->planes     = planes;\n        pool->channels   = ch;\n        pool->samples = frame->nb_samples;\n        break;\n        }\n    default: av_assert0(0);\n    }\n    return 0;\nfail:\n    for (i = 0; i < 4; i++)\n        av_buffer_pool_uninit(&pool->pools[i]);\n    pool->format = -1;\n    pool->planes = pool->channels = pool->samples = 0;\n    pool->width  = pool->height = 0;\n    return ret;\n}\n\nstatic int audio_get_buffer(AVCodecContext *avctx, AVFrame *frame)\n{\n    FramePool *pool = avctx->internal->pool;\n    int planes = pool->planes;\n    int i;\n\n    frame->linesize[0] = pool->linesize[0];\n\n    if (planes > AV_NUM_DATA_POINTERS) {\n        frame->extended_data = av_mallocz_array(planes, sizeof(*frame->extended_data));\n        frame->nb_extended_buf = planes - AV_NUM_DATA_POINTERS;\n        frame->extended_buf  = av_mallocz_array(frame->nb_extended_buf,\n                                          sizeof(*frame->extended_buf));\n        if (!frame->extended_data || !frame->extended_buf) {\n            av_freep(&frame->extended_data);\n            av_freep(&frame->extended_buf);\n            return AVERROR(ENOMEM);\n        }\n    } else {\n        frame->extended_data = frame->data;\n        av_assert0(frame->nb_extended_buf == 0);\n    }\n\n    for (i = 0; i < FFMIN(planes, AV_NUM_DATA_POINTERS); i++) {\n        frame->buf[i] = av_buffer_pool_get(pool->pools[0]);\n        if (!frame->buf[i])\n            goto fail;\n        frame->extended_data[i] = frame->data[i] = frame->buf[i]->data;\n    }\n    for (i = 0; i < frame->nb_extended_buf; i++) {\n        frame->extended_buf[i] = av_buffer_pool_get(pool->pools[0]);\n        if (!frame->extended_buf[i])\n            goto fail;\n        frame->extended_data[i + AV_NUM_DATA_POINTERS] = frame->extended_buf[i]->data;\n    }\n\n    if (avctx->debug & FF_DEBUG_BUFFERS)\n        av_log(avctx, AV_LOG_DEBUG, \"default_get_buffer called on frame %p\", frame);\n\n    return 0;\nfail:\n    av_frame_unref(frame);\n    return AVERROR(ENOMEM);\n}\n\nstatic int video_get_buffer(AVCodecContext *s, AVFrame *pic)\n{\n    FramePool *pool = s->internal->pool;\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(pic->format);\n    int i;\n\n    if (pic->data[0] || pic->data[1] || pic->data[2] || pic->data[3]) {\n        av_log(s, AV_LOG_ERROR, \"pic->data[*]!=NULL in avcodec_default_get_buffer\\n\");\n        return -1;\n    }\n\n    if (!desc) {\n        av_log(s, AV_LOG_ERROR,\n            \"Unable to get pixel format descriptor for format %s\\n\",\n            av_get_pix_fmt_name(pic->format));\n        return AVERROR(EINVAL);\n    }\n\n    memset(pic->data, 0, sizeof(pic->data));\n    pic->extended_data = pic->data;\n\n    for (i = 0; i < 4 && pool->pools[i]; i++) {\n        pic->linesize[i] = pool->linesize[i];\n\n        pic->buf[i] = av_buffer_pool_get(pool->pools[i]);\n        if (!pic->buf[i])\n            goto fail;\n\n        pic->data[i] = pic->buf[i]->data;\n    }\n    for (; i < AV_NUM_DATA_POINTERS; i++) {\n        pic->data[i] = NULL;\n        pic->linesize[i] = 0;\n    }\n    if (desc->flags & AV_PIX_FMT_FLAG_PAL ||\n        desc->flags & AV_PIX_FMT_FLAG_PSEUDOPAL)\n        avpriv_set_systematic_pal2((uint32_t *)pic->data[1], pic->format);\n\n    if (s->debug & FF_DEBUG_BUFFERS)\n        av_log(s, AV_LOG_DEBUG, \"default_get_buffer called on pic %p\\n\", pic);\n\n    return 0;\nfail:\n    av_frame_unref(pic);\n    return AVERROR(ENOMEM);\n}\n\nvoid ff_color_frame(AVFrame *frame, const int c[4])\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n    int p, y, x;\n\n    av_assert0(desc->flags & AV_PIX_FMT_FLAG_PLANAR);\n\n    for (p = 0; p<desc->nb_components; p++) {\n        uint8_t *dst = frame->data[p];\n        int is_chroma = p == 1 || p == 2;\n        int bytes  = is_chroma ? AV_CEIL_RSHIFT(frame->width,  desc->log2_chroma_w) : frame->width;\n        int height = is_chroma ? AV_CEIL_RSHIFT(frame->height, desc->log2_chroma_h) : frame->height;\n        for (y = 0; y < height; y++) {\n            if (desc->comp[0].depth >= 9) {\n                for (x = 0; x<bytes; x++)\n                    ((uint16_t*)dst)[x] = c[p];\n            }else\n                memset(dst, c[p], bytes);\n            dst += frame->linesize[p];\n        }\n    }\n}\n\nint avcodec_default_get_buffer2(AVCodecContext *avctx, AVFrame *frame, int flags)\n{\n    int ret;\n\n    if (avctx->hw_frames_ctx)\n        return av_hwframe_get_buffer(avctx->hw_frames_ctx, frame, 0);\n\n    if ((ret = update_frame_pool(avctx, frame)) < 0)\n        return ret;\n\n    switch (avctx->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        return video_get_buffer(avctx, frame);\n    case AVMEDIA_TYPE_AUDIO:\n        return audio_get_buffer(avctx, frame);\n    default:\n        return -1;\n    }\n}\n\nstatic int add_metadata_from_side_data(AVPacket *avpkt, AVFrame *frame)\n{\n    int size;\n    const uint8_t *side_metadata;\n\n    AVDictionary **frame_md = avpriv_frame_get_metadatap(frame);\n\n    side_metadata = av_packet_get_side_data(avpkt,\n                                            AV_PKT_DATA_STRINGS_METADATA, &size);\n    return av_packet_unpack_dictionary(side_metadata, size, frame_md);\n}\n\nint ff_init_buffer_info(AVCodecContext *avctx, AVFrame *frame)\n{\n    AVPacket *pkt = avctx->internal->pkt;\n    int i;\n    static const struct {\n        enum AVPacketSideDataType packet;\n        enum AVFrameSideDataType frame;\n    } sd[] = {\n        { AV_PKT_DATA_REPLAYGAIN ,                AV_FRAME_DATA_REPLAYGAIN },\n        { AV_PKT_DATA_DISPLAYMATRIX,              AV_FRAME_DATA_DISPLAYMATRIX },\n        { AV_PKT_DATA_SPHERICAL,                  AV_FRAME_DATA_SPHERICAL },\n        { AV_PKT_DATA_STEREO3D,                   AV_FRAME_DATA_STEREO3D },\n        { AV_PKT_DATA_AUDIO_SERVICE_TYPE,         AV_FRAME_DATA_AUDIO_SERVICE_TYPE },\n        { AV_PKT_DATA_MASTERING_DISPLAY_METADATA, AV_FRAME_DATA_MASTERING_DISPLAY_METADATA },\n    };\n\n    if (pkt) {\n        frame->pts = pkt->pts;\n#if FF_API_PKT_PTS\nFF_DISABLE_DEPRECATION_WARNINGS\n        frame->pkt_pts = pkt->pts;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n        av_frame_set_pkt_pos     (frame, pkt->pos);\n        av_frame_set_pkt_duration(frame, pkt->duration);\n        av_frame_set_pkt_size    (frame, pkt->size);\n\n        for (i = 0; i < FF_ARRAY_ELEMS(sd); i++) {\n            int size;\n            uint8_t *packet_sd = av_packet_get_side_data(pkt, sd[i].packet, &size);\n            if (packet_sd) {\n                AVFrameSideData *frame_sd = av_frame_new_side_data(frame,\n                                                                   sd[i].frame,\n                                                                   size);\n                if (!frame_sd)\n                    return AVERROR(ENOMEM);\n\n                memcpy(frame_sd->data, packet_sd, size);\n            }\n        }\n        add_metadata_from_side_data(pkt, frame);\n\n        if (pkt->flags & AV_PKT_FLAG_DISCARD) {\n            frame->flags |= AV_FRAME_FLAG_DISCARD;\n        } else {\n            frame->flags = (frame->flags & ~AV_FRAME_FLAG_DISCARD);\n        }\n    } else {\n        frame->pts = AV_NOPTS_VALUE;\n#if FF_API_PKT_PTS\nFF_DISABLE_DEPRECATION_WARNINGS\n        frame->pkt_pts = AV_NOPTS_VALUE;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n        av_frame_set_pkt_pos     (frame, -1);\n        av_frame_set_pkt_duration(frame, 0);\n        av_frame_set_pkt_size    (frame, -1);\n    }\n    frame->reordered_opaque = avctx->reordered_opaque;\n\n    if (frame->color_primaries == AVCOL_PRI_UNSPECIFIED)\n        frame->color_primaries = avctx->color_primaries;\n    if (frame->color_trc == AVCOL_TRC_UNSPECIFIED)\n        frame->color_trc = avctx->color_trc;\n    if (av_frame_get_colorspace(frame) == AVCOL_SPC_UNSPECIFIED)\n        av_frame_set_colorspace(frame, avctx->colorspace);\n    if (av_frame_get_color_range(frame) == AVCOL_RANGE_UNSPECIFIED)\n        av_frame_set_color_range(frame, avctx->color_range);\n    if (frame->chroma_location == AVCHROMA_LOC_UNSPECIFIED)\n        frame->chroma_location = avctx->chroma_sample_location;\n\n    switch (avctx->codec->type) {\n    case AVMEDIA_TYPE_VIDEO:\n        frame->format              = avctx->pix_fmt;\n        if (!frame->sample_aspect_ratio.num)\n            frame->sample_aspect_ratio = avctx->sample_aspect_ratio;\n\n        if (frame->width && frame->height &&\n            av_image_check_sar(frame->width, frame->height,\n                               frame->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   frame->sample_aspect_ratio.num,\n                   frame->sample_aspect_ratio.den);\n            frame->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        if (!frame->sample_rate)\n            frame->sample_rate    = avctx->sample_rate;\n        if (frame->format < 0)\n            frame->format         = avctx->sample_fmt;\n        if (!frame->channel_layout) {\n            if (avctx->channel_layout) {\n                 if (av_get_channel_layout_nb_channels(avctx->channel_layout) !=\n                     avctx->channels) {\n                     av_log(avctx, AV_LOG_ERROR, \"Inconsistent channel \"\n                            \"configuration.\\n\");\n                     return AVERROR(EINVAL);\n                 }\n\n                frame->channel_layout = avctx->channel_layout;\n            } else {\n                if (avctx->channels > FF_SANE_NB_CHANNELS) {\n                    av_log(avctx, AV_LOG_ERROR, \"Too many channels: %d.\\n\",\n                           avctx->channels);\n                    return AVERROR(ENOSYS);\n                }\n            }\n        }\n        av_frame_set_channels(frame, avctx->channels);\n        break;\n    }\n    return 0;\n}\n\nint ff_decode_frame_props(AVCodecContext *avctx, AVFrame *frame)\n{\n    return ff_init_buffer_info(avctx, frame);\n}\n\nstatic void validate_avframe_allocation(AVCodecContext *avctx, AVFrame *frame)\n{\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n        int i;\n        int num_planes = av_pix_fmt_count_planes(frame->format);\n        const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(frame->format);\n        int flags = desc ? desc->flags : 0;\n        if (num_planes == 1 && (flags & AV_PIX_FMT_FLAG_PAL))\n            num_planes = 2;\n        for (i = 0; i < num_planes; i++) {\n            av_assert0(frame->data[i]);\n        }\n        // For now do not enforce anything for palette of pseudopal formats\n        if (num_planes == 1 && (flags & AV_PIX_FMT_FLAG_PSEUDOPAL))\n            num_planes = 2;\n        // For formats without data like hwaccel allow unused pointers to be non-NULL.\n        for (i = num_planes; num_planes > 0 && i < FF_ARRAY_ELEMS(frame->data); i++) {\n            if (frame->data[i])\n                av_log(avctx, AV_LOG_ERROR, \"Buffer returned by get_buffer2() did not zero unused plane pointers\\n\");\n            frame->data[i] = NULL;\n        }\n    }\n}\n\nstatic int get_buffer_internal(AVCodecContext *avctx, AVFrame *frame, int flags)\n{\n    const AVHWAccel *hwaccel = avctx->hwaccel;\n    int override_dimensions = 1;\n    int ret;\n\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n        if ((ret = av_image_check_size2(avctx->width, avctx->height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx)) < 0 || avctx->pix_fmt<0) {\n            av_log(avctx, AV_LOG_ERROR, \"video_get_buffer: image parameters invalid\\n\");\n            return AVERROR(EINVAL);\n        }\n\n        if (frame->width <= 0 || frame->height <= 0) {\n            frame->width  = FFMAX(avctx->width,  AV_CEIL_RSHIFT(avctx->coded_width,  avctx->lowres));\n            frame->height = FFMAX(avctx->height, AV_CEIL_RSHIFT(avctx->coded_height, avctx->lowres));\n            override_dimensions = 0;\n        }\n\n        if (frame->data[0] || frame->data[1] || frame->data[2] || frame->data[3]) {\n            av_log(avctx, AV_LOG_ERROR, \"pic->data[*]!=NULL in get_buffer_internal\\n\");\n            return AVERROR(EINVAL);\n        }\n    }\n    ret = ff_decode_frame_props(avctx, frame);\n    if (ret < 0)\n        return ret;\n\n    if (hwaccel) {\n        if (hwaccel->alloc_frame) {\n            ret = hwaccel->alloc_frame(avctx, frame);\n            goto end;\n        }\n    } else\n        avctx->sw_pix_fmt = avctx->pix_fmt;\n\n    ret = avctx->get_buffer2(avctx, frame, flags);\n    if (ret >= 0)\n        validate_avframe_allocation(avctx, frame);\n\nend:\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO && !override_dimensions) {\n        frame->width  = avctx->width;\n        frame->height = avctx->height;\n    }\n\n    return ret;\n}\n\nint ff_get_buffer(AVCodecContext *avctx, AVFrame *frame, int flags)\n{\n    int ret = get_buffer_internal(avctx, frame, flags);\n    if (ret < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"get_buffer() failed\\n\");\n        frame->width = frame->height = 0;\n    }\n    return ret;\n}\n\nstatic int reget_buffer_internal(AVCodecContext *avctx, AVFrame *frame)\n{\n    AVFrame *tmp;\n    int ret;\n\n    av_assert0(avctx->codec_type == AVMEDIA_TYPE_VIDEO);\n\n    if (frame->data[0] && (frame->width != avctx->width || frame->height != avctx->height || frame->format != avctx->pix_fmt)) {\n        av_log(avctx, AV_LOG_WARNING, \"Picture changed from size:%dx%d fmt:%s to size:%dx%d fmt:%s in reget buffer()\\n\",\n               frame->width, frame->height, av_get_pix_fmt_name(frame->format), avctx->width, avctx->height, av_get_pix_fmt_name(avctx->pix_fmt));\n        av_frame_unref(frame);\n    }\n\n    ff_init_buffer_info(avctx, frame);\n\n    if (!frame->data[0])\n        return ff_get_buffer(avctx, frame, AV_GET_BUFFER_FLAG_REF);\n\n    if (av_frame_is_writable(frame))\n        return ff_decode_frame_props(avctx, frame);\n\n    tmp = av_frame_alloc();\n    if (!tmp)\n        return AVERROR(ENOMEM);\n\n    av_frame_move_ref(tmp, frame);\n\n    ret = ff_get_buffer(avctx, frame, AV_GET_BUFFER_FLAG_REF);\n    if (ret < 0) {\n        av_frame_free(&tmp);\n        return ret;\n    }\n\n    av_frame_copy(frame, tmp);\n    av_frame_free(&tmp);\n\n    return 0;\n}\n\nint ff_reget_buffer(AVCodecContext *avctx, AVFrame *frame)\n{\n    int ret = reget_buffer_internal(avctx, frame);\n    if (ret < 0)\n        av_log(avctx, AV_LOG_ERROR, \"reget_buffer() failed\\n\");\n    return ret;\n}\n\nint avcodec_default_execute(AVCodecContext *c, int (*func)(AVCodecContext *c2, void *arg2), void *arg, int *ret, int count, int size)\n{\n    int i;\n\n    for (i = 0; i < count; i++) {\n        int r = func(c, (char *)arg + i * size);\n        if (ret)\n            ret[i] = r;\n    }\n    emms_c();\n    return 0;\n}\n\nint avcodec_default_execute2(AVCodecContext *c, int (*func)(AVCodecContext *c2, void *arg2, int jobnr, int threadnr), void *arg, int *ret, int count)\n{\n    int i;\n\n    for (i = 0; i < count; i++) {\n        int r = func(c, arg, i, 0);\n        if (ret)\n            ret[i] = r;\n    }\n    emms_c();\n    return 0;\n}\n\nenum AVPixelFormat avpriv_find_pix_fmt(const PixelFormatTag *tags,\n                                       unsigned int fourcc)\n{\n    while (tags->pix_fmt >= 0) {\n        if (tags->fourcc == fourcc)\n            return tags->pix_fmt;\n        tags++;\n    }\n    return AV_PIX_FMT_NONE;\n}\n\nstatic int is_hwaccel_pix_fmt(enum AVPixelFormat pix_fmt)\n{\n    const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(pix_fmt);\n    return desc->flags & AV_PIX_FMT_FLAG_HWACCEL;\n}\n\nenum AVPixelFormat avcodec_default_get_format(struct AVCodecContext *s, const enum AVPixelFormat *fmt)\n{\n    while (*fmt != AV_PIX_FMT_NONE && is_hwaccel_pix_fmt(*fmt))\n        ++fmt;\n    return fmt[0];\n}\n\nstatic AVHWAccel *find_hwaccel(enum AVCodecID codec_id,\n                               enum AVPixelFormat pix_fmt)\n{\n    AVHWAccel *hwaccel = NULL;\n\n    while ((hwaccel = av_hwaccel_next(hwaccel)))\n        if (hwaccel->id == codec_id\n            && hwaccel->pix_fmt == pix_fmt)\n            return hwaccel;\n    return NULL;\n}\n\nstatic int setup_hwaccel(AVCodecContext *avctx,\n                         const enum AVPixelFormat fmt,\n                         const char *name)\n{\n    AVHWAccel *hwa = find_hwaccel(avctx->codec_id, fmt);\n    int ret        = 0;\n\n    if (avctx->active_thread_type & FF_THREAD_FRAME) {\n        av_log(avctx, AV_LOG_WARNING,\n               \"Hardware accelerated decoding with frame threading is known to be unstable and its use is discouraged.\\n\");\n    }\n\n    if (!hwa) {\n        av_log(avctx, AV_LOG_ERROR,\n               \"Could not find an AVHWAccel for the pixel format: %s\",\n               name);\n        return AVERROR(ENOENT);\n    }\n\n    if (hwa->capabilities & HWACCEL_CODEC_CAP_EXPERIMENTAL &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring experimental hwaccel: %s\\n\",\n               hwa->name);\n        return AVERROR_PATCHWELCOME;\n    }\n\n    if (hwa->priv_data_size) {\n        avctx->internal->hwaccel_priv_data = av_mallocz(hwa->priv_data_size);\n        if (!avctx->internal->hwaccel_priv_data)\n            return AVERROR(ENOMEM);\n    }\n\n    if (hwa->init) {\n        ret = hwa->init(avctx);\n        if (ret < 0) {\n            av_freep(&avctx->internal->hwaccel_priv_data);\n            return ret;\n        }\n    }\n\n    avctx->hwaccel = hwa;\n\n    return 0;\n}\n\nint ff_get_format(AVCodecContext *avctx, const enum AVPixelFormat *fmt)\n{\n    const AVPixFmtDescriptor *desc;\n    enum AVPixelFormat *choices;\n    enum AVPixelFormat ret;\n    unsigned n = 0;\n\n    while (fmt[n] != AV_PIX_FMT_NONE)\n        ++n;\n\n    av_assert0(n >= 1);\n    avctx->sw_pix_fmt = fmt[n - 1];\n    av_assert2(!is_hwaccel_pix_fmt(avctx->sw_pix_fmt));\n\n    choices = av_malloc_array(n + 1, sizeof(*choices));\n    if (!choices)\n        return AV_PIX_FMT_NONE;\n\n    memcpy(choices, fmt, (n + 1) * sizeof(*choices));\n\n    for (;;) {\n        if (avctx->hwaccel && avctx->hwaccel->uninit)\n            avctx->hwaccel->uninit(avctx);\n        av_freep(&avctx->internal->hwaccel_priv_data);\n        avctx->hwaccel = NULL;\n\n        av_buffer_unref(&avctx->hw_frames_ctx);\n\n        ret = avctx->get_format(avctx, choices);\n\n        desc = av_pix_fmt_desc_get(ret);\n        if (!desc) {\n            ret = AV_PIX_FMT_NONE;\n            break;\n        }\n\n        if (!(desc->flags & AV_PIX_FMT_FLAG_HWACCEL))\n            break;\n#if FF_API_CAP_VDPAU\n        if (avctx->codec->capabilities&AV_CODEC_CAP_HWACCEL_VDPAU)\n            break;\n#endif\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *hw_frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (hw_frames_ctx->format != ret) {\n                av_log(avctx, AV_LOG_ERROR, \"Format returned from get_buffer() \"\n                       \"does not match the format of provided AVHWFramesContext\\n\");\n                ret = AV_PIX_FMT_NONE;\n                break;\n            }\n        }\n\n        if (!setup_hwaccel(avctx, ret, desc->name))\n            break;\n\n        /* Remove failed hwaccel from choices */\n        for (n = 0; choices[n] != ret; n++)\n            av_assert0(choices[n] != AV_PIX_FMT_NONE);\n\n        do\n            choices[n] = choices[n + 1];\n        while (choices[n++] != AV_PIX_FMT_NONE);\n    }\n\n    av_freep(&choices);\n    return ret;\n}\n\nMAKE_ACCESSORS(AVCodecContext, codec, AVRational, pkt_timebase)\nMAKE_ACCESSORS(AVCodecContext, codec, const AVCodecDescriptor *, codec_descriptor)\nMAKE_ACCESSORS(AVCodecContext, codec, int, lowres)\nMAKE_ACCESSORS(AVCodecContext, codec, int, seek_preroll)\nMAKE_ACCESSORS(AVCodecContext, codec, uint16_t*, chroma_intra_matrix)\n\nunsigned av_codec_get_codec_properties(const AVCodecContext *codec)\n{\n    return codec->properties;\n}\n\nint av_codec_get_max_lowres(const AVCodec *codec)\n{\n    return codec->max_lowres;\n}\n\nint avpriv_codec_get_cap_skip_frame_fill_param(const AVCodec *codec){\n    return !!(codec->caps_internal & FF_CODEC_CAP_SKIP_FRAME_FILL_PARAM);\n}\n\nstatic void get_subtitle_defaults(AVSubtitle *sub)\n{\n    memset(sub, 0, sizeof(*sub));\n    sub->pts = AV_NOPTS_VALUE;\n}\n\nstatic int64_t get_bit_rate(AVCodecContext *ctx)\n{\n    int64_t bit_rate;\n    int bits_per_sample;\n\n    switch (ctx->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n    case AVMEDIA_TYPE_DATA:\n    case AVMEDIA_TYPE_SUBTITLE:\n    case AVMEDIA_TYPE_ATTACHMENT:\n        bit_rate = ctx->bit_rate;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        bits_per_sample = av_get_bits_per_sample(ctx->codec_id);\n        bit_rate = bits_per_sample ? ctx->sample_rate * (int64_t)ctx->channels * bits_per_sample : ctx->bit_rate;\n        break;\n    default:\n        bit_rate = 0;\n        break;\n    }\n    return bit_rate;\n}\n\nint attribute_align_arg ff_codec_open2_recursive(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n\n    ff_unlock_avcodec(codec);\n\n    ret = avcodec_open2(avctx, codec, options);\n\n    ff_lock_avcodec(avctx, codec);\n    return ret;\n}\n\nint attribute_align_arg avcodec_open2(AVCodecContext *avctx, const AVCodec *codec, AVDictionary **options)\n{\n    int ret = 0;\n    AVDictionary *tmp = NULL;\n    const AVPixFmtDescriptor *pixdesc;\n\n    if (avcodec_is_open(avctx))\n        return 0;\n\n    if ((!codec && !avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"No codec provided to avcodec_open2()\\n\");\n        return AVERROR(EINVAL);\n    }\n    if ((codec && avctx->codec && codec != avctx->codec)) {\n        av_log(avctx, AV_LOG_ERROR, \"This AVCodecContext was allocated for %s, \"\n                                    \"but %s passed to avcodec_open2()\\n\", avctx->codec->name, codec->name);\n        return AVERROR(EINVAL);\n    }\n    if (!codec)\n        codec = avctx->codec;\n\n    if (avctx->extradata_size < 0 || avctx->extradata_size >= FF_MAX_EXTRADATA_SIZE)\n        return AVERROR(EINVAL);\n\n    if (options)\n        av_dict_copy(&tmp, *options, 0);\n\n    ret = ff_lock_avcodec(avctx, codec);\n    if (ret < 0)\n        return ret;\n\n    avctx->internal = av_mallocz(sizeof(AVCodecInternal));\n    if (!avctx->internal) {\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    avctx->internal->pool = av_mallocz(sizeof(*avctx->internal->pool));\n    if (!avctx->internal->pool) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->to_free = av_frame_alloc();\n    if (!avctx->internal->to_free) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_frame = av_frame_alloc();\n    if (!avctx->internal->buffer_frame) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    avctx->internal->buffer_pkt = av_packet_alloc();\n    if (!avctx->internal->buffer_pkt) {\n        ret = AVERROR(ENOMEM);\n        goto free_and_end;\n    }\n\n    if (codec->priv_data_size > 0) {\n        if (!avctx->priv_data) {\n            avctx->priv_data = av_mallocz(codec->priv_data_size);\n            if (!avctx->priv_data) {\n                ret = AVERROR(ENOMEM);\n                goto end;\n            }\n            if (codec->priv_class) {\n                *(const AVClass **)avctx->priv_data = codec->priv_class;\n                av_opt_set_defaults(avctx->priv_data);\n            }\n        }\n        if (codec->priv_class && (ret = av_opt_set_dict(avctx->priv_data, &tmp)) < 0)\n            goto free_and_end;\n    } else {\n        avctx->priv_data = NULL;\n    }\n    if ((ret = av_opt_set_dict(avctx, &tmp)) < 0)\n        goto free_and_end;\n\n    if (avctx->codec_whitelist && av_match_list(codec->name, avctx->codec_whitelist, ',') <= 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec (%s) not on whitelist \\'%s\\'\\n\", codec->name, avctx->codec_whitelist);\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    // only call ff_set_dimensions() for non H.264/VP6F/DXV codecs so as not to overwrite previously setup dimensions\n    if (!(avctx->coded_width && avctx->coded_height && avctx->width && avctx->height &&\n          (avctx->codec_id == AV_CODEC_ID_H264 || avctx->codec_id == AV_CODEC_ID_VP6F || avctx->codec_id == AV_CODEC_ID_DXV))) {\n    if (avctx->coded_width && avctx->coded_height)\n        ret = ff_set_dimensions(avctx, avctx->coded_width, avctx->coded_height);\n    else if (avctx->width && avctx->height)\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n    if (ret < 0)\n        goto free_and_end;\n    }\n\n    if ((avctx->coded_width || avctx->coded_height || avctx->width || avctx->height)\n        && (  av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0\n           || av_image_check_size2(avctx->width,       avctx->height,       avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx) < 0)) {\n        av_log(avctx, AV_LOG_WARNING, \"Ignoring invalid width/height values\\n\");\n        ff_set_dimensions(avctx, 0, 0);\n    }\n\n    if (avctx->width > 0 && avctx->height > 0) {\n        if (av_image_check_sar(avctx->width, avctx->height,\n                               avctx->sample_aspect_ratio) < 0) {\n            av_log(avctx, AV_LOG_WARNING, \"ignoring invalid SAR: %u/%u\\n\",\n                   avctx->sample_aspect_ratio.num,\n                   avctx->sample_aspect_ratio.den);\n            avctx->sample_aspect_ratio = (AVRational){ 0, 1 };\n        }\n    }\n\n    /* if the decoder init function was already called previously,\n     * free the already allocated subtitle_header before overwriting it */\n    if (av_codec_is_decoder(codec))\n        av_freep(&avctx->subtitle_header);\n\n    if (avctx->channels > FF_SANE_NB_CHANNELS) {\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n\n    avctx->codec = codec;\n    if ((avctx->codec_type == AVMEDIA_TYPE_UNKNOWN || avctx->codec_type == codec->type) &&\n        avctx->codec_id == AV_CODEC_ID_NONE) {\n        avctx->codec_type = codec->type;\n        avctx->codec_id   = codec->id;\n    }\n    if (avctx->codec_id != codec->id || (avctx->codec_type != codec->type\n                                         && avctx->codec_type != AVMEDIA_TYPE_ATTACHMENT)) {\n        av_log(avctx, AV_LOG_ERROR, \"Codec type or id mismatches\\n\");\n        ret = AVERROR(EINVAL);\n        goto free_and_end;\n    }\n    avctx->frame_number = 0;\n    avctx->codec_descriptor = avcodec_descriptor_get(avctx->codec_id);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_EXPERIMENTAL) &&\n        avctx->strict_std_compliance > FF_COMPLIANCE_EXPERIMENTAL) {\n        const char *codec_string = av_codec_is_encoder(codec) ? \"encoder\" : \"decoder\";\n        AVCodec *codec2;\n        av_log(avctx, AV_LOG_ERROR,\n               \"The %s '%s' is experimental but experimental codecs are not enabled, \"\n               \"add '-strict %d' if you want to use it.\\n\",\n               codec_string, codec->name, FF_COMPLIANCE_EXPERIMENTAL);\n        codec2 = av_codec_is_encoder(codec) ? avcodec_find_encoder(codec->id) : avcodec_find_decoder(codec->id);\n        if (!(codec2->capabilities & AV_CODEC_CAP_EXPERIMENTAL))\n            av_log(avctx, AV_LOG_ERROR, \"Alternatively use the non experimental %s '%s'.\\n\",\n                codec_string, codec2->name);\n        ret = AVERROR_EXPERIMENTAL;\n        goto free_and_end;\n    }\n\n    if (avctx->codec_type == AVMEDIA_TYPE_AUDIO &&\n        (!avctx->time_base.num || !avctx->time_base.den)) {\n        avctx->time_base.num = 1;\n        avctx->time_base.den = avctx->sample_rate;\n    }\n\n    if (!HAVE_THREADS)\n        av_log(avctx, AV_LOG_WARNING, \"Warning: not compiled with thread support, using thread emulation\\n\");\n\n    if (CONFIG_FRAME_THREAD_ENCODER && av_codec_is_encoder(avctx->codec)) {\n        ff_unlock_avcodec(codec); //we will instantiate a few encoders thus kick the counter to prevent false detection of a problem\n        ret = ff_frame_thread_encoder_init(avctx, options ? *options : NULL);\n        ff_lock_avcodec(avctx, codec);\n        if (ret < 0)\n            goto free_and_end;\n    }\n\n    if (HAVE_THREADS\n        && !(avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))) {\n        ret = ff_thread_init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n    if (!HAVE_THREADS && !(codec->capabilities & AV_CODEC_CAP_AUTO_THREADS))\n        avctx->thread_count = 1;\n\n    if (avctx->codec->max_lowres < avctx->lowres || avctx->lowres < 0) {\n        av_log(avctx, AV_LOG_WARNING, \"The maximum value for lowres supported by the decoder is %d\\n\",\n               avctx->codec->max_lowres);\n        avctx->lowres = avctx->codec->max_lowres;\n    }\n\n#if FF_API_VISMV\n    if (avctx->debug_mv)\n        av_log(avctx, AV_LOG_WARNING, \"The 'vismv' option is deprecated, \"\n               \"see the codecview filter instead.\\n\");\n#endif\n\n    if (av_codec_is_encoder(avctx->codec)) {\n        int i;\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        avctx->coded_frame = av_frame_alloc();\n        if (!avctx->coded_frame) {\n            ret = AVERROR(ENOMEM);\n            goto free_and_end;\n        }\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n        if (avctx->time_base.num <= 0 || avctx->time_base.den <= 0) {\n            av_log(avctx, AV_LOG_ERROR, \"The encoder timebase is not set.\\n\");\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n\n        if (avctx->codec->sample_fmts) {\n            for (i = 0; avctx->codec->sample_fmts[i] != AV_SAMPLE_FMT_NONE; i++) {\n                if (avctx->sample_fmt == avctx->codec->sample_fmts[i])\n                    break;\n                if (avctx->channels == 1 &&\n                    av_get_planar_sample_fmt(avctx->sample_fmt) ==\n                    av_get_planar_sample_fmt(avctx->codec->sample_fmts[i])) {\n                    avctx->sample_fmt = avctx->codec->sample_fmts[i];\n                    break;\n                }\n            }\n            if (avctx->codec->sample_fmts[i] == AV_SAMPLE_FMT_NONE) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->sample_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_sample_fmt_name(avctx->sample_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->codec->pix_fmts) {\n            for (i = 0; avctx->codec->pix_fmts[i] != AV_PIX_FMT_NONE; i++)\n                if (avctx->pix_fmt == avctx->codec->pix_fmts[i])\n                    break;\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_NONE\n                && !((avctx->codec_id == AV_CODEC_ID_MJPEG || avctx->codec_id == AV_CODEC_ID_LJPEG)\n                     && avctx->strict_std_compliance <= FF_COMPLIANCE_UNOFFICIAL)) {\n                char buf[128];\n                snprintf(buf, sizeof(buf), \"%d\", avctx->pix_fmt);\n                av_log(avctx, AV_LOG_ERROR, \"Specified pixel format %s is invalid or not supported\\n\",\n                       (char *)av_x_if_null(av_get_pix_fmt_name(avctx->pix_fmt), buf));\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n            if (avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ420P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ411P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ422P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ440P ||\n                avctx->codec->pix_fmts[i] == AV_PIX_FMT_YUVJ444P)\n                avctx->color_range = AVCOL_RANGE_JPEG;\n        }\n        if (avctx->codec->supported_samplerates) {\n            for (i = 0; avctx->codec->supported_samplerates[i] != 0; i++)\n                if (avctx->sample_rate == avctx->codec->supported_samplerates[i])\n                    break;\n            if (avctx->codec->supported_samplerates[i] == 0) {\n                av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                       avctx->sample_rate);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (avctx->sample_rate < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified sample rate %d is not supported\\n\",\n                    avctx->sample_rate);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->codec->channel_layouts) {\n            if (!avctx->channel_layout) {\n                av_log(avctx, AV_LOG_WARNING, \"Channel layout not specified\\n\");\n            } else {\n                for (i = 0; avctx->codec->channel_layouts[i] != 0; i++)\n                    if (avctx->channel_layout == avctx->codec->channel_layouts[i])\n                        break;\n                if (avctx->codec->channel_layouts[i] == 0) {\n                    char buf[512];\n                    av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                    av_log(avctx, AV_LOG_ERROR, \"Specified channel layout '%s' is not supported\\n\", buf);\n                    ret = AVERROR(EINVAL);\n                    goto free_and_end;\n                }\n            }\n        }\n        if (avctx->channel_layout && avctx->channels) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Channel layout '%s' with %d channels does not match number of specified channels %d\\n\",\n                       buf, channels, avctx->channels);\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        } else if (avctx->channel_layout) {\n            avctx->channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n        }\n        if (avctx->channels < 0) {\n            av_log(avctx, AV_LOG_ERROR, \"Specified number of channels %d is not supported\\n\",\n                    avctx->channels);\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if(avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n            pixdesc = av_pix_fmt_desc_get(avctx->pix_fmt);\n            if (    avctx->bits_per_raw_sample < 0\n                || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {\n                av_log(avctx, AV_LOG_WARNING, \"Specified bit depth %d not possible with the specified pixel formats depth %d\\n\",\n                    avctx->bits_per_raw_sample, pixdesc->comp[0].depth);\n                avctx->bits_per_raw_sample = pixdesc->comp[0].depth;\n            }\n            if (avctx->width <= 0 || avctx->height <= 0) {\n                av_log(avctx, AV_LOG_ERROR, \"dimensions not set\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n        if (   (avctx->codec_type == AVMEDIA_TYPE_VIDEO || avctx->codec_type == AVMEDIA_TYPE_AUDIO)\n            && avctx->bit_rate>0 && avctx->bit_rate<1000) {\n            av_log(avctx, AV_LOG_WARNING, \"Bitrate %\"PRId64\" is extremely low, maybe you mean %\"PRId64\"k\\n\", (int64_t)avctx->bit_rate, (int64_t)avctx->bit_rate);\n        }\n\n        if (!avctx->rc_initial_buffer_occupancy)\n            avctx->rc_initial_buffer_occupancy = avctx->rc_buffer_size * 3 / 4;\n\n        if (avctx->ticks_per_frame && avctx->time_base.num &&\n            avctx->ticks_per_frame > INT_MAX / avctx->time_base.num) {\n            av_log(avctx, AV_LOG_ERROR,\n                   \"ticks_per_frame %d too large for the timebase %d/%d.\",\n                   avctx->ticks_per_frame,\n                   avctx->time_base.num,\n                   avctx->time_base.den);\n            goto free_and_end;\n        }\n\n        if (avctx->hw_frames_ctx) {\n            AVHWFramesContext *frames_ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;\n            if (frames_ctx->format != avctx->pix_fmt) {\n                av_log(avctx, AV_LOG_ERROR,\n                       \"Mismatching AVCodecContext.pix_fmt and AVHWFramesContext.format\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            }\n        }\n    }\n\n    avctx->pts_correction_num_faulty_pts =\n    avctx->pts_correction_num_faulty_dts = 0;\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (   !CONFIG_GRAY && avctx->flags & AV_CODEC_FLAG_GRAY\n        && avctx->codec_descriptor->type == AVMEDIA_TYPE_VIDEO)\n        av_log(avctx, AV_LOG_WARNING,\n               \"gray decoding requested but not enabled at configuration time\\n\");\n\n    if (   avctx->codec->init && (!(avctx->active_thread_type&FF_THREAD_FRAME)\n        || avctx->internal->frame_thread_encoder)) {\n        ret = avctx->codec->init(avctx);\n        if (ret < 0) {\n            goto free_and_end;\n        }\n    }\n\n    ret=0;\n\n#if FF_API_AUDIOENC_DELAY\n    if (av_codec_is_encoder(avctx->codec))\n        avctx->delay = avctx->initial_padding;\n#endif\n\n    if (av_codec_is_decoder(avctx->codec)) {\n        if (!avctx->bit_rate)\n            avctx->bit_rate = get_bit_rate(avctx);\n        /* validate channel layout from the decoder */\n        if (avctx->channel_layout) {\n            int channels = av_get_channel_layout_nb_channels(avctx->channel_layout);\n            if (!avctx->channels)\n                avctx->channels = channels;\n            else if (channels != avctx->channels) {\n                char buf[512];\n                av_get_channel_layout_string(buf, sizeof(buf), -1, avctx->channel_layout);\n                av_log(avctx, AV_LOG_WARNING,\n                       \"Channel layout '%s' with %d channels does not match specified number of channels %d: \"\n                       \"ignoring specified channel layout\\n\",\n                       buf, channels, avctx->channels);\n                avctx->channel_layout = 0;\n            }\n        }\n        if (avctx->channels && avctx->channels < 0 ||\n            avctx->channels > FF_SANE_NB_CHANNELS) {\n            ret = AVERROR(EINVAL);\n            goto free_and_end;\n        }\n        if (avctx->sub_charenc) {\n            if (avctx->codec_type != AVMEDIA_TYPE_SUBTITLE) {\n                av_log(avctx, AV_LOG_ERROR, \"Character encoding is only \"\n                       \"supported with subtitles codecs\\n\");\n                ret = AVERROR(EINVAL);\n                goto free_and_end;\n            } else if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB) {\n                av_log(avctx, AV_LOG_WARNING, \"Codec '%s' is bitmap-based, \"\n                       \"subtitles character encoding will be ignored\\n\",\n                       avctx->codec_descriptor->name);\n                avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_DO_NOTHING;\n            } else {\n                /* input character encoding is set for a text based subtitle\n                 * codec at this point */\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_AUTOMATIC)\n                    avctx->sub_charenc_mode = FF_SUB_CHARENC_MODE_PRE_DECODER;\n\n                if (avctx->sub_charenc_mode == FF_SUB_CHARENC_MODE_PRE_DECODER) {\n#if CONFIG_ICONV\n                    iconv_t cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n                    if (cd == (iconv_t)-1) {\n                        ret = AVERROR(errno);\n                        av_log(avctx, AV_LOG_ERROR, \"Unable to open iconv context \"\n                               \"with input character encoding \\\"%s\\\"\\n\", avctx->sub_charenc);\n                        goto free_and_end;\n                    }\n                    iconv_close(cd);\n#else\n                    av_log(avctx, AV_LOG_ERROR, \"Character encoding subtitles \"\n                           \"conversion needs a libavcodec built with iconv support \"\n                           \"for this codec\\n\");\n                    ret = AVERROR(ENOSYS);\n                    goto free_and_end;\n#endif\n                }\n            }\n        }\n\n#if FF_API_AVCTX_TIMEBASE\n        if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n            avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n    }\n    if (codec->priv_data_size > 0 && avctx->priv_data && codec->priv_class) {\n        av_assert0(*(const AVClass **)avctx->priv_data == codec->priv_class);\n    }\n\nend:\n    ff_unlock_avcodec(codec);\n    if (options) {\n        av_dict_free(options);\n        *options = tmp;\n    }\n\n    return ret;\nfree_and_end:\n    if (avctx->codec &&\n        (avctx->codec->caps_internal & FF_CODEC_CAP_INIT_CLEANUP))\n        avctx->codec->close(avctx);\n\n    if (codec->priv_class && codec->priv_data_size)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n    av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n\n    av_dict_free(&tmp);\n    av_freep(&avctx->priv_data);\n    if (avctx->internal) {\n        av_packet_free(&avctx->internal->buffer_pkt);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_frame_free(&avctx->internal->to_free);\n        av_freep(&avctx->internal->pool);\n    }\n    av_freep(&avctx->internal);\n    avctx->codec = NULL;\n    goto end;\n}\n\nint ff_alloc_packet2(AVCodecContext *avctx, AVPacket *avpkt, int64_t size, int64_t min_size)\n{\n    if (avpkt->size < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid negative user packet size %d\\n\", avpkt->size);\n        return AVERROR(EINVAL);\n    }\n    if (size < 0 || size > INT_MAX - AV_INPUT_BUFFER_PADDING_SIZE) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid minimum required packet size %\"PRId64\" (max allowed is %d)\\n\",\n               size, INT_MAX - AV_INPUT_BUFFER_PADDING_SIZE);\n        return AVERROR(EINVAL);\n    }\n\n    if (avctx && 2*min_size < size) { // FIXME The factor needs to be finetuned\n        av_assert0(!avpkt->data || avpkt->data != avctx->internal->byte_buffer);\n        if (!avpkt->data || avpkt->size < size) {\n            av_fast_padded_malloc(&avctx->internal->byte_buffer, &avctx->internal->byte_buffer_size, size);\n            avpkt->data = avctx->internal->byte_buffer;\n            avpkt->size = avctx->internal->byte_buffer_size;\n        }\n    }\n\n    if (avpkt->data) {\n        AVBufferRef *buf = avpkt->buf;\n\n        if (avpkt->size < size) {\n            av_log(avctx, AV_LOG_ERROR, \"User packet is too small (%d < %\"PRId64\")\\n\", avpkt->size, size);\n            return AVERROR(EINVAL);\n        }\n\n        av_init_packet(avpkt);\n        avpkt->buf      = buf;\n        avpkt->size     = size;\n        return 0;\n    } else {\n        int ret = av_new_packet(avpkt, size);\n        if (ret < 0)\n            av_log(avctx, AV_LOG_ERROR, \"Failed to allocate packet of size %\"PRId64\"\\n\", size);\n        return ret;\n    }\n}\n\nint ff_alloc_packet(AVPacket *avpkt, int size)\n{\n    return ff_alloc_packet2(NULL, avpkt, size, 0);\n}\n\n/**\n * Pad last frame with silence.\n */\nstatic int pad_last_frame(AVCodecContext *s, AVFrame **dst, const AVFrame *src)\n{\n    AVFrame *frame = NULL;\n    int ret;\n\n    if (!(frame = av_frame_alloc()))\n        return AVERROR(ENOMEM);\n\n    frame->format         = src->format;\n    frame->channel_layout = src->channel_layout;\n    av_frame_set_channels(frame, av_frame_get_channels(src));\n    frame->nb_samples     = s->frame_size;\n    ret = av_frame_get_buffer(frame, 32);\n    if (ret < 0)\n        goto fail;\n\n    ret = av_frame_copy_props(frame, src);\n    if (ret < 0)\n        goto fail;\n\n    if ((ret = av_samples_copy(frame->extended_data, src->extended_data, 0, 0,\n                               src->nb_samples, s->channels, s->sample_fmt)) < 0)\n        goto fail;\n    if ((ret = av_samples_set_silence(frame->extended_data, src->nb_samples,\n                                      frame->nb_samples - src->nb_samples,\n                                      s->channels, s->sample_fmt)) < 0)\n        goto fail;\n\n    *dst = frame;\n\n    return 0;\n\nfail:\n    av_frame_free(&frame);\n    return ret;\n}\n\nint attribute_align_arg avcodec_encode_audio2(AVCodecContext *avctx,\n                                              AVPacket *avpkt,\n                                              const AVFrame *frame,\n                                              int *got_packet_ptr)\n{\n    AVFrame *extended_frame = NULL;\n    AVFrame *padded_frame = NULL;\n    int ret;\n    AVPacket user_pkt = *avpkt;\n    int needs_realloc = !user_pkt.data;\n\n    *got_packet_ptr = 0;\n\n    if (!avctx->codec->encode2) {\n        av_log(avctx, AV_LOG_ERROR, \"This encoder requires using the avcodec_send_frame() API.\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY) && !frame) {\n        av_packet_unref(avpkt);\n        av_init_packet(avpkt);\n        return 0;\n    }\n\n    /* ensure that extended_data is properly set */\n    if (frame && !frame->extended_data) {\n        if (av_sample_fmt_is_planar(avctx->sample_fmt) &&\n            avctx->channels > AV_NUM_DATA_POINTERS) {\n            av_log(avctx, AV_LOG_ERROR, \"Encoding to a planar sample format, \"\n                                        \"with more than %d channels, but extended_data is not set.\\n\",\n                   AV_NUM_DATA_POINTERS);\n            return AVERROR(EINVAL);\n        }\n        av_log(avctx, AV_LOG_WARNING, \"extended_data is not set.\\n\");\n\n        extended_frame = av_frame_alloc();\n        if (!extended_frame)\n            return AVERROR(ENOMEM);\n\n        memcpy(extended_frame, frame, sizeof(AVFrame));\n        extended_frame->extended_data = extended_frame->data;\n        frame = extended_frame;\n    }\n\n    /* extract audio service type metadata */\n    if (frame) {\n        AVFrameSideData *sd = av_frame_get_side_data(frame, AV_FRAME_DATA_AUDIO_SERVICE_TYPE);\n        if (sd && sd->size >= sizeof(enum AVAudioServiceType))\n            avctx->audio_service_type = *(enum AVAudioServiceType*)sd->data;\n    }\n\n    /* check for valid frame size */\n    if (frame) {\n        if (avctx->codec->capabilities & AV_CODEC_CAP_SMALL_LAST_FRAME) {\n            if (frame->nb_samples > avctx->frame_size) {\n                av_log(avctx, AV_LOG_ERROR, \"more samples than frame size (avcodec_encode_audio2)\\n\");\n                ret = AVERROR(EINVAL);\n                goto end;\n            }\n        } else if (!(avctx->codec->capabilities & AV_CODEC_CAP_VARIABLE_FRAME_SIZE)) {\n            if (frame->nb_samples < avctx->frame_size &&\n                !avctx->internal->last_audio_frame) {\n                ret = pad_last_frame(avctx, &padded_frame, frame);\n                if (ret < 0)\n                    goto end;\n\n                frame = padded_frame;\n                avctx->internal->last_audio_frame = 1;\n            }\n\n            if (frame->nb_samples != avctx->frame_size) {\n                av_log(avctx, AV_LOG_ERROR, \"nb_samples (%d) != frame_size (%d) (avcodec_encode_audio2)\\n\", frame->nb_samples, avctx->frame_size);\n                ret = AVERROR(EINVAL);\n                goto end;\n            }\n        }\n    }\n\n    av_assert0(avctx->codec->encode2);\n\n    ret = avctx->codec->encode2(avctx, avpkt, frame, got_packet_ptr);\n    if (!ret) {\n        if (*got_packet_ptr) {\n            if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY)) {\n                if (avpkt->pts == AV_NOPTS_VALUE)\n                    avpkt->pts = frame->pts;\n                if (!avpkt->duration)\n                    avpkt->duration = ff_samples_to_time_base(avctx,\n                                                              frame->nb_samples);\n            }\n            avpkt->dts = avpkt->pts;\n        } else {\n            avpkt->size = 0;\n        }\n    }\n    if (avpkt->data && avpkt->data == avctx->internal->byte_buffer) {\n        needs_realloc = 0;\n        if (user_pkt.data) {\n            if (user_pkt.size >= avpkt->size) {\n                memcpy(user_pkt.data, avpkt->data, avpkt->size);\n            } else {\n                av_log(avctx, AV_LOG_ERROR, \"Provided packet is too small, needs to be %d\\n\", avpkt->size);\n                avpkt->size = user_pkt.size;\n                ret = -1;\n            }\n            avpkt->buf      = user_pkt.buf;\n            avpkt->data     = user_pkt.data;\n        } else {\n            if (av_dup_packet(avpkt) < 0) {\n                ret = AVERROR(ENOMEM);\n            }\n        }\n    }\n\n    if (!ret) {\n        if (needs_realloc && avpkt->data) {\n            ret = av_buffer_realloc(&avpkt->buf, avpkt->size + AV_INPUT_BUFFER_PADDING_SIZE);\n            if (ret >= 0)\n                avpkt->data = avpkt->buf->data;\n        }\n\n        avctx->frame_number++;\n    }\n\n    if (ret < 0 || !*got_packet_ptr) {\n        av_packet_unref(avpkt);\n        av_init_packet(avpkt);\n        goto end;\n    }\n\n    /* NOTE: if we add any audio encoders which output non-keyframe packets,\n     *       this needs to be moved to the encoders, but for now we can do it\n     *       here to simplify things */\n    avpkt->flags |= AV_PKT_FLAG_KEY;\n\nend:\n    av_frame_free(&padded_frame);\n    av_free(extended_frame);\n\n#if FF_API_AUDIOENC_DELAY\n    avctx->delay = avctx->initial_padding;\n#endif\n\n    return ret;\n}\n\nint attribute_align_arg avcodec_encode_video2(AVCodecContext *avctx,\n                                              AVPacket *avpkt,\n                                              const AVFrame *frame,\n                                              int *got_packet_ptr)\n{\n    int ret;\n    AVPacket user_pkt = *avpkt;\n    int needs_realloc = !user_pkt.data;\n\n    *got_packet_ptr = 0;\n\n    if (!avctx->codec->encode2) {\n        av_log(avctx, AV_LOG_ERROR, \"This encoder requires using the avcodec_send_frame() API.\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    if(CONFIG_FRAME_THREAD_ENCODER &&\n       avctx->internal->frame_thread_encoder && (avctx->active_thread_type&FF_THREAD_FRAME))\n        return ff_thread_video_encode_frame(avctx, avpkt, frame, got_packet_ptr);\n\n    if ((avctx->flags&AV_CODEC_FLAG_PASS1) && avctx->stats_out)\n        avctx->stats_out[0] = '\\0';\n\n    if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY) && !frame) {\n        av_packet_unref(avpkt);\n        av_init_packet(avpkt);\n        avpkt->size = 0;\n        return 0;\n    }\n\n    if (av_image_check_size2(avctx->width, avctx->height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx))\n        return AVERROR(EINVAL);\n\n    if (frame && frame->format == AV_PIX_FMT_NONE)\n        av_log(avctx, AV_LOG_WARNING, \"AVFrame.format is not set\\n\");\n    if (frame && (frame->width == 0 || frame->height == 0))\n        av_log(avctx, AV_LOG_WARNING, \"AVFrame.width or height is not set\\n\");\n\n    av_assert0(avctx->codec->encode2);\n\n    ret = avctx->codec->encode2(avctx, avpkt, frame, got_packet_ptr);\n    av_assert0(ret <= 0);\n\n    emms_c();\n\n    if (avpkt->data && avpkt->data == avctx->internal->byte_buffer) {\n        needs_realloc = 0;\n        if (user_pkt.data) {\n            if (user_pkt.size >= avpkt->size) {\n                memcpy(user_pkt.data, avpkt->data, avpkt->size);\n            } else {\n                av_log(avctx, AV_LOG_ERROR, \"Provided packet is too small, needs to be %d\\n\", avpkt->size);\n                avpkt->size = user_pkt.size;\n                ret = -1;\n            }\n            avpkt->buf      = user_pkt.buf;\n            avpkt->data     = user_pkt.data;\n        } else {\n            if (av_dup_packet(avpkt) < 0) {\n                ret = AVERROR(ENOMEM);\n            }\n        }\n    }\n\n    if (!ret) {\n        if (!*got_packet_ptr)\n            avpkt->size = 0;\n        else if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            avpkt->pts = avpkt->dts = frame->pts;\n\n        if (needs_realloc && avpkt->data) {\n            ret = av_buffer_realloc(&avpkt->buf, avpkt->size + AV_INPUT_BUFFER_PADDING_SIZE);\n            if (ret >= 0)\n                avpkt->data = avpkt->buf->data;\n        }\n\n        avctx->frame_number++;\n    }\n\n    if (ret < 0 || !*got_packet_ptr)\n        av_packet_unref(avpkt);\n\n    return ret;\n}\n\nint avcodec_encode_subtitle(AVCodecContext *avctx, uint8_t *buf, int buf_size,\n                            const AVSubtitle *sub)\n{\n    int ret;\n    if (sub->start_display_time) {\n        av_log(avctx, AV_LOG_ERROR, \"start_display_time must be 0.\\n\");\n        return -1;\n    }\n\n    ret = avctx->codec->encode_sub(avctx, buf, buf_size, sub);\n    avctx->frame_number++;\n    return ret;\n}\n\n/**\n * Attempt to guess proper monotonic timestamps for decoded video frames\n * which might have incorrect times. Input timestamps may wrap around, in\n * which case the output will as well.\n *\n * @param pts the pts field of the decoded AVPacket, as passed through\n * AVFrame.pts\n * @param dts the dts field of the decoded AVPacket\n * @return one of the input values, may be AV_NOPTS_VALUE\n */\nstatic int64_t guess_correct_pts(AVCodecContext *ctx,\n                                 int64_t reordered_pts, int64_t dts)\n{\n    int64_t pts = AV_NOPTS_VALUE;\n\n    if (dts != AV_NOPTS_VALUE) {\n        ctx->pts_correction_num_faulty_dts += dts <= ctx->pts_correction_last_dts;\n        ctx->pts_correction_last_dts = dts;\n    } else if (reordered_pts != AV_NOPTS_VALUE)\n        ctx->pts_correction_last_dts = reordered_pts;\n\n    if (reordered_pts != AV_NOPTS_VALUE) {\n        ctx->pts_correction_num_faulty_pts += reordered_pts <= ctx->pts_correction_last_pts;\n        ctx->pts_correction_last_pts = reordered_pts;\n    } else if(dts != AV_NOPTS_VALUE)\n        ctx->pts_correction_last_pts = dts;\n\n    if ((ctx->pts_correction_num_faulty_pts<=ctx->pts_correction_num_faulty_dts || dts == AV_NOPTS_VALUE)\n       && reordered_pts != AV_NOPTS_VALUE)\n        pts = reordered_pts;\n    else\n        pts = dts;\n\n    return pts;\n}\n\nstatic int apply_param_change(AVCodecContext *avctx, AVPacket *avpkt)\n{\n    int size = 0, ret;\n    const uint8_t *data;\n    uint32_t flags;\n    int64_t val;\n\n    data = av_packet_get_side_data(avpkt, AV_PKT_DATA_PARAM_CHANGE, &size);\n    if (!data)\n        return 0;\n\n    if (!(avctx->codec->capabilities & AV_CODEC_CAP_PARAM_CHANGE)) {\n        av_log(avctx, AV_LOG_ERROR, \"This decoder does not support parameter \"\n               \"changes, but PARAM_CHANGE side data was sent to it.\\n\");\n        ret = AVERROR(EINVAL);\n        goto fail2;\n    }\n\n    if (size < 4)\n        goto fail;\n\n    flags = bytestream_get_le32(&data);\n    size -= 4;\n\n    if (flags & AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_COUNT) {\n        if (size < 4)\n            goto fail;\n        val = bytestream_get_le32(&data);\n        if (val <= 0 || val > INT_MAX) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid channel count\");\n            ret = AVERROR_INVALIDDATA;\n            goto fail2;\n        }\n        avctx->channels = val;\n        size -= 4;\n    }\n    if (flags & AV_SIDE_DATA_PARAM_CHANGE_CHANNEL_LAYOUT) {\n        if (size < 8)\n            goto fail;\n        avctx->channel_layout = bytestream_get_le64(&data);\n        size -= 8;\n    }\n    if (flags & AV_SIDE_DATA_PARAM_CHANGE_SAMPLE_RATE) {\n        if (size < 4)\n            goto fail;\n        val = bytestream_get_le32(&data);\n        if (val <= 0 || val > INT_MAX) {\n            av_log(avctx, AV_LOG_ERROR, \"Invalid sample rate\");\n            ret = AVERROR_INVALIDDATA;\n            goto fail2;\n        }\n        avctx->sample_rate = val;\n        size -= 4;\n    }\n    if (flags & AV_SIDE_DATA_PARAM_CHANGE_DIMENSIONS) {\n        if (size < 8)\n            goto fail;\n        avctx->width  = bytestream_get_le32(&data);\n        avctx->height = bytestream_get_le32(&data);\n        size -= 8;\n        ret = ff_set_dimensions(avctx, avctx->width, avctx->height);\n        if (ret < 0)\n            goto fail2;\n    }\n\n    return 0;\nfail:\n    av_log(avctx, AV_LOG_ERROR, \"PARAM_CHANGE side data too small.\\n\");\n    ret = AVERROR_INVALIDDATA;\nfail2:\n    if (ret < 0) {\n        av_log(avctx, AV_LOG_ERROR, \"Error applying parameter changes.\\n\");\n        if (avctx->err_recognition & AV_EF_EXPLODE)\n            return ret;\n    }\n    return 0;\n}\n\nstatic int unrefcount_frame(AVCodecInternal *avci, AVFrame *frame)\n{\n    int ret;\n\n    /* move the original frame to our backup */\n    av_frame_unref(avci->to_free);\n    av_frame_move_ref(avci->to_free, frame);\n\n    /* now copy everything except the AVBufferRefs back\n     * note that we make a COPY of the side data, so calling av_frame_free() on\n     * the caller's frame will work properly */\n    ret = av_frame_copy_props(frame, avci->to_free);\n    if (ret < 0)\n        return ret;\n\n    memcpy(frame->data,     avci->to_free->data,     sizeof(frame->data));\n    memcpy(frame->linesize, avci->to_free->linesize, sizeof(frame->linesize));\n    if (avci->to_free->extended_data != avci->to_free->data) {\n        int planes = av_frame_get_channels(avci->to_free);\n        int size   = planes * sizeof(*frame->extended_data);\n\n        if (!size) {\n            av_frame_unref(frame);\n            return AVERROR_BUG;\n        }\n\n        frame->extended_data = av_malloc(size);\n        if (!frame->extended_data) {\n            av_frame_unref(frame);\n            return AVERROR(ENOMEM);\n        }\n        memcpy(frame->extended_data, avci->to_free->extended_data,\n               size);\n    } else\n        frame->extended_data = frame->data;\n\n    frame->format         = avci->to_free->format;\n    frame->width          = avci->to_free->width;\n    frame->height         = avci->to_free->height;\n    frame->channel_layout = avci->to_free->channel_layout;\n    frame->nb_samples     = avci->to_free->nb_samples;\n    av_frame_set_channels(frame, av_frame_get_channels(avci->to_free));\n\n    return 0;\n}\n\nint attribute_align_arg avcodec_decode_video2(AVCodecContext *avctx, AVFrame *picture,\n                                              int *got_picture_ptr,\n                                              const AVPacket *avpkt)\n{\n    AVCodecInternal *avci = avctx->internal;\n    int ret;\n    // copy to ensure we do not change avpkt\n    AVPacket tmp = *avpkt;\n\n    if (!avctx->codec)\n        return AVERROR(EINVAL);\n    if (avctx->codec->type != AVMEDIA_TYPE_VIDEO) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid media type for video\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    if (!avctx->codec->decode) {\n        av_log(avctx, AV_LOG_ERROR, \"This decoder requires using the avcodec_send_packet() API.\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    *got_picture_ptr = 0;\n    if ((avctx->coded_width || avctx->coded_height) && av_image_check_size2(avctx->coded_width, avctx->coded_height, avctx->max_pixels, AV_PIX_FMT_NONE, 0, avctx))\n        return AVERROR(EINVAL);\n\n    avctx->internal->pkt = avpkt;\n    ret = apply_param_change(avctx, avpkt);\n    if (ret < 0)\n        return ret;\n\n    av_frame_unref(picture);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_DELAY) || avpkt->size ||\n        (avctx->active_thread_type & FF_THREAD_FRAME)) {\n        int did_split = av_packet_split_side_data(&tmp);\n        ret = apply_param_change(avctx, &tmp);\n        if (ret < 0)\n            goto fail;\n\n        avctx->internal->pkt = &tmp;\n        if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n            ret = ff_thread_decode_frame(avctx, picture, got_picture_ptr,\n                                         &tmp);\n        else {\n            ret = avctx->codec->decode(avctx, picture, got_picture_ptr,\n                                       &tmp);\n            if (!(avctx->codec->caps_internal & FF_CODEC_CAP_SETS_PKT_DTS))\n                picture->pkt_dts = avpkt->dts;\n\n            if(!avctx->has_b_frames){\n                av_frame_set_pkt_pos(picture, avpkt->pos);\n            }\n            //FIXME these should be under if(!avctx->has_b_frames)\n            /* get_buffer is supposed to set frame parameters */\n            if (!(avctx->codec->capabilities & AV_CODEC_CAP_DR1)) {\n                if (!picture->sample_aspect_ratio.num)    picture->sample_aspect_ratio = avctx->sample_aspect_ratio;\n                if (!picture->width)                      picture->width               = avctx->width;\n                if (!picture->height)                     picture->height              = avctx->height;\n                if (picture->format == AV_PIX_FMT_NONE)   picture->format              = avctx->pix_fmt;\n            }\n        }\n\nfail:\n        emms_c(); //needed to avoid an emms_c() call before every return;\n\n        avctx->internal->pkt = NULL;\n        if (did_split) {\n            av_packet_free_side_data(&tmp);\n            if(ret == tmp.size)\n                ret = avpkt->size;\n        }\n        if (picture->flags & AV_FRAME_FLAG_DISCARD) {\n            *got_picture_ptr = 0;\n        }\n        if (*got_picture_ptr) {\n            if (!avctx->refcounted_frames) {\n                int err = unrefcount_frame(avci, picture);\n                if (err < 0)\n                    return err;\n            }\n\n            avctx->frame_number++;\n            av_frame_set_best_effort_timestamp(picture,\n                                               guess_correct_pts(avctx,\n                                                                 picture->pts,\n                                                                 picture->pkt_dts));\n        } else\n            av_frame_unref(picture);\n    } else\n        ret = 0;\n\n    /* many decoders assign whole AVFrames, thus overwriting extended_data;\n     * make sure it's set correctly */\n    av_assert0(!picture->extended_data || picture->extended_data == picture->data);\n\n#if FF_API_AVCTX_TIMEBASE\n    if (avctx->framerate.num > 0 && avctx->framerate.den > 0)\n        avctx->time_base = av_inv_q(av_mul_q(avctx->framerate, (AVRational){avctx->ticks_per_frame, 1}));\n#endif\n\n    return ret;\n}\n\nint attribute_align_arg avcodec_decode_audio4(AVCodecContext *avctx,\n                                              AVFrame *frame,\n                                              int *got_frame_ptr,\n                                              const AVPacket *avpkt)\n{\n    AVCodecInternal *avci = avctx->internal;\n    int ret = 0;\n\n    *got_frame_ptr = 0;\n\n    if (!avctx->codec)\n        return AVERROR(EINVAL);\n\n    if (!avctx->codec->decode) {\n        av_log(avctx, AV_LOG_ERROR, \"This decoder requires using the avcodec_send_packet() API.\\n\");\n        return AVERROR(ENOSYS);\n    }\n\n    if (!avpkt->data && avpkt->size) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid packet: NULL data, size != 0\\n\");\n        return AVERROR(EINVAL);\n    }\n    if (avctx->codec->type != AVMEDIA_TYPE_AUDIO) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid media type for audio\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    av_frame_unref(frame);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_DELAY) || avpkt->size || (avctx->active_thread_type & FF_THREAD_FRAME)) {\n        uint8_t *side;\n        int side_size;\n        uint32_t discard_padding = 0;\n        uint8_t skip_reason = 0;\n        uint8_t discard_reason = 0;\n        // copy to ensure we do not change avpkt\n        AVPacket tmp = *avpkt;\n        int did_split = av_packet_split_side_data(&tmp);\n        ret = apply_param_change(avctx, &tmp);\n        if (ret < 0)\n            goto fail;\n\n        avctx->internal->pkt = &tmp;\n        if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n            ret = ff_thread_decode_frame(avctx, frame, got_frame_ptr, &tmp);\n        else {\n            ret = avctx->codec->decode(avctx, frame, got_frame_ptr, &tmp);\n            av_assert0(ret <= tmp.size);\n            frame->pkt_dts = avpkt->dts;\n        }\n        if (ret >= 0 && *got_frame_ptr) {\n            avctx->frame_number++;\n            av_frame_set_best_effort_timestamp(frame,\n                                               guess_correct_pts(avctx,\n                                                                 frame->pts,\n                                                                 frame->pkt_dts));\n            if (frame->format == AV_SAMPLE_FMT_NONE)\n                frame->format = avctx->sample_fmt;\n            if (!frame->channel_layout)\n                frame->channel_layout = avctx->channel_layout;\n            if (!av_frame_get_channels(frame))\n                av_frame_set_channels(frame, avctx->channels);\n            if (!frame->sample_rate)\n                frame->sample_rate = avctx->sample_rate;\n        }\n\n        side= av_packet_get_side_data(avctx->internal->pkt, AV_PKT_DATA_SKIP_SAMPLES, &side_size);\n        if(side && side_size>=10) {\n            avctx->internal->skip_samples = AV_RL32(side);\n            discard_padding = AV_RL32(side + 4);\n            av_log(avctx, AV_LOG_DEBUG, \"skip %d / discard %d samples due to side data\\n\",\n                   avctx->internal->skip_samples, (int)discard_padding);\n            skip_reason = AV_RL8(side + 8);\n            discard_reason = AV_RL8(side + 9);\n        }\n\n        if ((frame->flags & AV_FRAME_FLAG_DISCARD) && *got_frame_ptr &&\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n            avctx->internal->skip_samples = FFMAX(0, avctx->internal->skip_samples - frame->nb_samples);\n            *got_frame_ptr = 0;\n        }\n\n        if (avctx->internal->skip_samples > 0 && *got_frame_ptr &&\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n            if(frame->nb_samples <= avctx->internal->skip_samples){\n                *got_frame_ptr = 0;\n                avctx->internal->skip_samples -= frame->nb_samples;\n                av_log(avctx, AV_LOG_DEBUG, \"skip whole frame, skip left: %d\\n\",\n                       avctx->internal->skip_samples);\n            } else {\n                av_samples_copy(frame->extended_data, frame->extended_data, 0, avctx->internal->skip_samples,\n                                frame->nb_samples - avctx->internal->skip_samples, avctx->channels, frame->format);\n                if(avctx->pkt_timebase.num && avctx->sample_rate) {\n                    int64_t diff_ts = av_rescale_q(avctx->internal->skip_samples,\n                                                   (AVRational){1, avctx->sample_rate},\n                                                   avctx->pkt_timebase);\n                    if(frame->pts!=AV_NOPTS_VALUE)\n                        frame->pts += diff_ts;\n#if FF_API_PKT_PTS\nFF_DISABLE_DEPRECATION_WARNINGS\n                    if(frame->pkt_pts!=AV_NOPTS_VALUE)\n                        frame->pkt_pts += diff_ts;\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n                    if(frame->pkt_dts!=AV_NOPTS_VALUE)\n                        frame->pkt_dts += diff_ts;\n                    if (av_frame_get_pkt_duration(frame) >= diff_ts)\n                        av_frame_set_pkt_duration(frame, av_frame_get_pkt_duration(frame) - diff_ts);\n                } else {\n                    av_log(avctx, AV_LOG_WARNING, \"Could not update timestamps for skipped samples.\\n\");\n                }\n                av_log(avctx, AV_LOG_DEBUG, \"skip %d/%d samples\\n\",\n                       avctx->internal->skip_samples, frame->nb_samples);\n                frame->nb_samples -= avctx->internal->skip_samples;\n                avctx->internal->skip_samples = 0;\n            }\n        }\n\n        if (discard_padding > 0 && discard_padding <= frame->nb_samples && *got_frame_ptr &&\n            !(avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL)) {\n            if (discard_padding == frame->nb_samples) {\n                *got_frame_ptr = 0;\n            } else {\n                if(avctx->pkt_timebase.num && avctx->sample_rate) {\n                    int64_t diff_ts = av_rescale_q(frame->nb_samples - discard_padding,\n                                                   (AVRational){1, avctx->sample_rate},\n                                                   avctx->pkt_timebase);\n                    av_frame_set_pkt_duration(frame, diff_ts);\n                } else {\n                    av_log(avctx, AV_LOG_WARNING, \"Could not update timestamps for discarded samples.\\n\");\n                }\n                av_log(avctx, AV_LOG_DEBUG, \"discard %d/%d samples\\n\",\n                       (int)discard_padding, frame->nb_samples);\n                frame->nb_samples -= discard_padding;\n            }\n        }\n\n        if ((avctx->flags2 & AV_CODEC_FLAG2_SKIP_MANUAL) && *got_frame_ptr) {\n            AVFrameSideData *fside = av_frame_new_side_data(frame, AV_FRAME_DATA_SKIP_SAMPLES, 10);\n            if (fside) {\n                AV_WL32(fside->data, avctx->internal->skip_samples);\n                AV_WL32(fside->data + 4, discard_padding);\n                AV_WL8(fside->data + 8, skip_reason);\n                AV_WL8(fside->data + 9, discard_reason);\n                avctx->internal->skip_samples = 0;\n            }\n        }\nfail:\n        avctx->internal->pkt = NULL;\n        if (did_split) {\n            av_packet_free_side_data(&tmp);\n            if(ret == tmp.size)\n                ret = avpkt->size;\n        }\n\n        if (ret >= 0 && *got_frame_ptr) {\n            if (!avctx->refcounted_frames) {\n                int err = unrefcount_frame(avci, frame);\n                if (err < 0)\n                    return err;\n            }\n        } else\n            av_frame_unref(frame);\n    }\n\n    av_assert0(ret <= avpkt->size);\n\n    if (!avci->showed_multi_packet_warning &&\n        ret >= 0 && ret != avpkt->size && !(avctx->codec->capabilities & AV_CODEC_CAP_SUBFRAMES)) {\n            av_log(avctx, AV_LOG_WARNING, \"Multiple frames in a packet.\\n\");\n        avci->showed_multi_packet_warning = 1;\n    }\n\n    return ret;\n}\n\n#define UTF8_MAX_BYTES 4 /* 5 and 6 bytes sequences should not be used */\nstatic int recode_subtitle(AVCodecContext *avctx,\n                           AVPacket *outpkt, const AVPacket *inpkt)\n{\n#if CONFIG_ICONV\n    iconv_t cd = (iconv_t)-1;\n    int ret = 0;\n    char *inb, *outb;\n    size_t inl, outl;\n    AVPacket tmp;\n#endif\n\n    if (avctx->sub_charenc_mode != FF_SUB_CHARENC_MODE_PRE_DECODER || inpkt->size == 0)\n        return 0;\n\n#if CONFIG_ICONV\n    cd = iconv_open(\"UTF-8\", avctx->sub_charenc);\n    av_assert0(cd != (iconv_t)-1);\n\n    inb = inpkt->data;\n    inl = inpkt->size;\n\n    if (inl >= INT_MAX / UTF8_MAX_BYTES - AV_INPUT_BUFFER_PADDING_SIZE) {\n        av_log(avctx, AV_LOG_ERROR, \"Subtitles packet is too big for recoding\\n\");\n        ret = AVERROR(ENOMEM);\n        goto end;\n    }\n\n    ret = av_new_packet(&tmp, inl * UTF8_MAX_BYTES);\n    if (ret < 0)\n        goto end;\n    outpkt->buf  = tmp.buf;\n    outpkt->data = tmp.data;\n    outpkt->size = tmp.size;\n    outb = outpkt->data;\n    outl = outpkt->size;\n\n    if (iconv(cd, &inb, &inl, &outb, &outl) == (size_t)-1 ||\n        iconv(cd, NULL, NULL, &outb, &outl) == (size_t)-1 ||\n        outl >= outpkt->size || inl != 0) {\n        ret = FFMIN(AVERROR(errno), -1);\n        av_log(avctx, AV_LOG_ERROR, \"Unable to recode subtitle event \\\"%s\\\" \"\n               \"from %s to UTF-8\\n\", inpkt->data, avctx->sub_charenc);\n        av_packet_unref(&tmp);\n        goto end;\n    }\n    outpkt->size -= outl;\n    memset(outpkt->data + outpkt->size, 0, outl);\n\nend:\n    if (cd != (iconv_t)-1)\n        iconv_close(cd);\n    return ret;\n#else\n    av_log(avctx, AV_LOG_ERROR, \"requesting subtitles recoding without iconv\");\n    return AVERROR(EINVAL);\n#endif\n}\n\nstatic int utf8_check(const uint8_t *str)\n{\n    const uint8_t *byte;\n    uint32_t codepoint, min;\n\n    while (*str) {\n        byte = str;\n        GET_UTF8(codepoint, *(byte++), return 0;);\n        min = byte - str == 1 ? 0 : byte - str == 2 ? 0x80 :\n              1 << (5 * (byte - str) - 4);\n        if (codepoint < min || codepoint >= 0x110000 ||\n            codepoint == 0xFFFE /* BOM */ ||\n            codepoint >= 0xD800 && codepoint <= 0xDFFF /* surrogates */)\n            return 0;\n        str = byte;\n    }\n    return 1;\n}\n\n#if FF_API_ASS_TIMING\nstatic void insert_ts(AVBPrint *buf, int ts)\n{\n    if (ts == -1) {\n        av_bprintf(buf, \"9:59:59.99,\");\n    } else {\n        int h, m, s;\n\n        h = ts/360000;  ts -= 360000*h;\n        m = ts/  6000;  ts -=   6000*m;\n        s = ts/   100;  ts -=    100*s;\n        av_bprintf(buf, \"%d:%02d:%02d.%02d,\", h, m, s, ts);\n    }\n}\n\nstatic int convert_sub_to_old_ass_form(AVSubtitle *sub, const AVPacket *pkt, AVRational tb)\n{\n    int i;\n    AVBPrint buf;\n\n    av_bprint_init(&buf, 0, AV_BPRINT_SIZE_UNLIMITED);\n\n    for (i = 0; i < sub->num_rects; i++) {\n        char *final_dialog;\n        const char *dialog;\n        AVSubtitleRect *rect = sub->rects[i];\n        int ts_start, ts_duration = -1;\n        long int layer;\n\n        if (rect->type != SUBTITLE_ASS || !strncmp(rect->ass, \"Dialogue: \", 10))\n            continue;\n\n        av_bprint_clear(&buf);\n\n        /* skip ReadOrder */\n        dialog = strchr(rect->ass, ',');\n        if (!dialog)\n            continue;\n        dialog++;\n\n        /* extract Layer or Marked */\n        layer = strtol(dialog, (char**)&dialog, 10);\n        if (*dialog != ',')\n            continue;\n        dialog++;\n\n        /* rescale timing to ASS time base (ms) */\n        ts_start = av_rescale_q(pkt->pts, tb, av_make_q(1, 100));\n        if (pkt->duration != -1)\n            ts_duration = av_rescale_q(pkt->duration, tb, av_make_q(1, 100));\n        sub->end_display_time = FFMAX(sub->end_display_time, 10 * ts_duration);\n\n        /* construct ASS (standalone file form with timestamps) string */\n        av_bprintf(&buf, \"Dialogue: %ld,\", layer);\n        insert_ts(&buf, ts_start);\n        insert_ts(&buf, ts_duration == -1 ? -1 : ts_start + ts_duration);\n        av_bprintf(&buf, \"%s\\r\\n\", dialog);\n\n        final_dialog = av_strdup(buf.str);\n        if (!av_bprint_is_complete(&buf) || !final_dialog) {\n            av_freep(&final_dialog);\n            av_bprint_finalize(&buf, NULL);\n            return AVERROR(ENOMEM);\n        }\n        av_freep(&rect->ass);\n        rect->ass = final_dialog;\n    }\n\n    av_bprint_finalize(&buf, NULL);\n    return 0;\n}\n#endif\n\nint avcodec_decode_subtitle2(AVCodecContext *avctx, AVSubtitle *sub,\n                             int *got_sub_ptr,\n                             AVPacket *avpkt)\n{\n    int i, ret = 0;\n\n    if (!avpkt->data && avpkt->size) {\n        av_log(avctx, AV_LOG_ERROR, \"invalid packet: NULL data, size != 0\\n\");\n        return AVERROR(EINVAL);\n    }\n    if (!avctx->codec)\n        return AVERROR(EINVAL);\n    if (avctx->codec->type != AVMEDIA_TYPE_SUBTITLE) {\n        av_log(avctx, AV_LOG_ERROR, \"Invalid media type for subtitles\\n\");\n        return AVERROR(EINVAL);\n    }\n\n    *got_sub_ptr = 0;\n    get_subtitle_defaults(sub);\n\n    if ((avctx->codec->capabilities & AV_CODEC_CAP_DELAY) || avpkt->size) {\n        AVPacket pkt_recoded;\n        AVPacket tmp = *avpkt;\n        int did_split = av_packet_split_side_data(&tmp);\n        //apply_param_change(avctx, &tmp);\n\n        if (did_split) {\n            /* FFMIN() prevents overflow in case the packet wasn't allocated with\n             * proper padding.\n             * If the side data is smaller than the buffer padding size, the\n             * remaining bytes should have already been filled with zeros by the\n             * original packet allocation anyway. */\n            memset(tmp.data + tmp.size, 0,\n                   FFMIN(avpkt->size - tmp.size, AV_INPUT_BUFFER_PADDING_SIZE));\n        }\n\n        pkt_recoded = tmp;\n        ret = recode_subtitle(avctx, &pkt_recoded, &tmp);\n        if (ret < 0) {\n            *got_sub_ptr = 0;\n        } else {\n            avctx->internal->pkt = &pkt_recoded;\n\n            if (avctx->pkt_timebase.num && avpkt->pts != AV_NOPTS_VALUE)\n                sub->pts = av_rescale_q(avpkt->pts,\n                                        avctx->pkt_timebase, AV_TIME_BASE_Q);\n            ret = avctx->codec->decode(avctx, sub, got_sub_ptr, &pkt_recoded);\n            av_assert1((ret >= 0) >= !!*got_sub_ptr &&\n                       !!*got_sub_ptr >= !!sub->num_rects);\n\n#if FF_API_ASS_TIMING\n            if (avctx->sub_text_format == FF_SUB_TEXT_FMT_ASS_WITH_TIMINGS\n                && *got_sub_ptr && sub->num_rects) {\n                const AVRational tb = avctx->pkt_timebase.num ? avctx->pkt_timebase\n                                                              : avctx->time_base;\n                int err = convert_sub_to_old_ass_form(sub, avpkt, tb);\n                if (err < 0)\n                    ret = err;\n            }\n#endif\n\n            if (sub->num_rects && !sub->end_display_time && avpkt->duration &&\n                avctx->pkt_timebase.num) {\n                AVRational ms = { 1, 1000 };\n                sub->end_display_time = av_rescale_q(avpkt->duration,\n                                                     avctx->pkt_timebase, ms);\n            }\n\n            for (i = 0; i < sub->num_rects; i++) {\n                if (sub->rects[i]->ass && !utf8_check(sub->rects[i]->ass)) {\n                    av_log(avctx, AV_LOG_ERROR,\n                           \"Invalid UTF-8 in decoded subtitles text; \"\n                           \"maybe missing -sub_charenc option\\n\");\n                    avsubtitle_free(sub);\n                    return AVERROR_INVALIDDATA;\n                }\n            }\n\n            if (tmp.data != pkt_recoded.data) { // did we recode?\n                /* prevent from destroying side data from original packet */\n                pkt_recoded.side_data = NULL;\n                pkt_recoded.side_data_elems = 0;\n\n                av_packet_unref(&pkt_recoded);\n            }\n            if (avctx->codec_descriptor->props & AV_CODEC_PROP_BITMAP_SUB)\n                sub->format = 0;\n            else if (avctx->codec_descriptor->props & AV_CODEC_PROP_TEXT_SUB)\n                sub->format = 1;\n            avctx->internal->pkt = NULL;\n        }\n\n        if (did_split) {\n            av_packet_free_side_data(&tmp);\n            if(ret == tmp.size)\n                ret = avpkt->size;\n        }\n\n        if (*got_sub_ptr)\n            avctx->frame_number++;\n    }\n\n    return ret;\n}\n\nvoid avsubtitle_free(AVSubtitle *sub)\n{\n    int i;\n\n    for (i = 0; i < sub->num_rects; i++) {\n        av_freep(&sub->rects[i]->data[0]);\n        av_freep(&sub->rects[i]->data[1]);\n        av_freep(&sub->rects[i]->data[2]);\n        av_freep(&sub->rects[i]->data[3]);\n        av_freep(&sub->rects[i]->text);\n        av_freep(&sub->rects[i]->ass);\n        av_freep(&sub->rects[i]);\n    }\n\n    av_freep(&sub->rects);\n\n    memset(sub, 0, sizeof(AVSubtitle));\n}\n\nstatic int do_decode(AVCodecContext *avctx, AVPacket *pkt)\n{\n    int got_frame;\n    int ret;\n\n    av_assert0(!avctx->internal->buffer_frame->buf[0]);\n\n    if (!pkt)\n        pkt = avctx->internal->buffer_pkt;\n\n    // This is the lesser evil. The field is for compatibility with legacy users\n    // of the legacy API, and users using the new API should not be forced to\n    // even know about this field.\n    avctx->refcounted_frames = 1;\n\n    // Some codecs (at least wma lossless) will crash when feeding drain packets\n    // after EOF was signaled.\n    if (avctx->internal->draining_done)\n        return AVERROR_EOF;\n\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n        ret = avcodec_decode_video2(avctx, avctx->internal->buffer_frame,\n                                    &got_frame, pkt);\n        if (ret >= 0 && !(avctx->flags & AV_CODEC_FLAG_TRUNCATED))\n            ret = pkt->size;\n    } else if (avctx->codec_type == AVMEDIA_TYPE_AUDIO) {\n        ret = avcodec_decode_audio4(avctx, avctx->internal->buffer_frame,\n                                    &got_frame, pkt);\n    } else {\n        ret = AVERROR(EINVAL);\n    }\n\n    if (ret == AVERROR(EAGAIN))\n        ret = pkt->size;\n\n    if (ret < 0)\n        return ret;\n\n    if (avctx->internal->draining && !got_frame)\n        avctx->internal->draining_done = 1;\n\n    if (ret >= pkt->size) {\n        av_packet_unref(avctx->internal->buffer_pkt);\n    } else {\n        int consumed = ret;\n\n        if (pkt != avctx->internal->buffer_pkt) {\n            av_packet_unref(avctx->internal->buffer_pkt);\n            if ((ret = av_packet_ref(avctx->internal->buffer_pkt, pkt)) < 0)\n                return ret;\n        }\n\n        avctx->internal->buffer_pkt->data += consumed;\n        avctx->internal->buffer_pkt->size -= consumed;\n        avctx->internal->buffer_pkt->pts   = AV_NOPTS_VALUE;\n        avctx->internal->buffer_pkt->dts   = AV_NOPTS_VALUE;\n    }\n\n    if (got_frame)\n        av_assert0(avctx->internal->buffer_frame->buf[0]);\n\n    return 0;\n}\n\nint attribute_align_arg avcodec_send_packet(AVCodecContext *avctx, const AVPacket *avpkt)\n{\n    int ret;\n\n    if (!avcodec_is_open(avctx) || !av_codec_is_decoder(avctx->codec))\n        return AVERROR(EINVAL);\n\n    if (avctx->internal->draining)\n        return AVERROR_EOF;\n\n    if (avpkt && !avpkt->size && avpkt->data)\n        return AVERROR(EINVAL);\n\n    if (!avpkt || !avpkt->size) {\n        avctx->internal->draining = 1;\n        avpkt = NULL;\n\n        if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            return 0;\n    }\n\n    if (avctx->codec->send_packet) {\n        if (avpkt) {\n            AVPacket tmp = *avpkt;\n            int did_split = av_packet_split_side_data(&tmp);\n            ret = apply_param_change(avctx, &tmp);\n            if (ret >= 0)\n                ret = avctx->codec->send_packet(avctx, &tmp);\n            if (did_split)\n                av_packet_free_side_data(&tmp);\n            return ret;\n        } else {\n            return avctx->codec->send_packet(avctx, NULL);\n        }\n    }\n\n    // Emulation via old API. Assume avpkt is likely not refcounted, while\n    // decoder output is always refcounted, and avoid copying.\n\n    if (avctx->internal->buffer_pkt->size || avctx->internal->buffer_frame->buf[0])\n        return AVERROR(EAGAIN);\n\n    // The goal is decoding the first frame of the packet without using memcpy,\n    // because the common case is having only 1 frame per packet (especially\n    // with video, but audio too). In other cases, it can't be avoided, unless\n    // the user is feeding refcounted packets.\n    return do_decode(avctx, (AVPacket *)avpkt);\n}\n\nint attribute_align_arg avcodec_receive_frame(AVCodecContext *avctx, AVFrame *frame)\n{\n    int ret;\n\n    av_frame_unref(frame);\n\n    if (!avcodec_is_open(avctx) || !av_codec_is_decoder(avctx->codec))\n        return AVERROR(EINVAL);\n\n    if (avctx->codec->receive_frame) {\n        if (avctx->internal->draining && !(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            return AVERROR_EOF;\n        ret = avctx->codec->receive_frame(avctx, frame);\n        if (ret >= 0) {\n            if (av_frame_get_best_effort_timestamp(frame) == AV_NOPTS_VALUE) {\n                av_frame_set_best_effort_timestamp(frame,\n                    guess_correct_pts(avctx, frame->pts, frame->pkt_dts));\n            }\n        }\n        return ret;\n    }\n\n    // Emulation via old API.\n\n    if (!avctx->internal->buffer_frame->buf[0]) {\n        if (!avctx->internal->buffer_pkt->size && !avctx->internal->draining)\n            return AVERROR(EAGAIN);\n\n        while (1) {\n            if ((ret = do_decode(avctx, avctx->internal->buffer_pkt)) < 0) {\n                av_packet_unref(avctx->internal->buffer_pkt);\n                return ret;\n            }\n            // Some audio decoders may consume partial data without returning\n            // a frame (fate-wmapro-2ch). There is no way to make the caller\n            // call avcodec_receive_frame() again without returning a frame,\n            // so try to decode more in these cases.\n            if (avctx->internal->buffer_frame->buf[0] ||\n                !avctx->internal->buffer_pkt->size)\n                break;\n        }\n    }\n\n    if (!avctx->internal->buffer_frame->buf[0])\n        return avctx->internal->draining ? AVERROR_EOF : AVERROR(EAGAIN);\n\n    av_frame_move_ref(frame, avctx->internal->buffer_frame);\n    return 0;\n}\n\nstatic int do_encode(AVCodecContext *avctx, const AVFrame *frame, int *got_packet)\n{\n    int ret;\n    *got_packet = 0;\n\n    av_packet_unref(avctx->internal->buffer_pkt);\n    avctx->internal->buffer_pkt_valid = 0;\n\n    if (avctx->codec_type == AVMEDIA_TYPE_VIDEO) {\n        ret = avcodec_encode_video2(avctx, avctx->internal->buffer_pkt,\n                                    frame, got_packet);\n    } else if (avctx->codec_type == AVMEDIA_TYPE_AUDIO) {\n        ret = avcodec_encode_audio2(avctx, avctx->internal->buffer_pkt,\n                                    frame, got_packet);\n    } else {\n        ret = AVERROR(EINVAL);\n    }\n\n    if (ret >= 0 && *got_packet) {\n        // Encoders must always return ref-counted buffers.\n        // Side-data only packets have no data and can be not ref-counted.\n        av_assert0(!avctx->internal->buffer_pkt->data || avctx->internal->buffer_pkt->buf);\n        avctx->internal->buffer_pkt_valid = 1;\n        ret = 0;\n    } else {\n        av_packet_unref(avctx->internal->buffer_pkt);\n    }\n\n    return ret;\n}\n\nint attribute_align_arg avcodec_send_frame(AVCodecContext *avctx, const AVFrame *frame)\n{\n    if (!avcodec_is_open(avctx) || !av_codec_is_encoder(avctx->codec))\n        return AVERROR(EINVAL);\n\n    if (avctx->internal->draining)\n        return AVERROR_EOF;\n\n    if (!frame) {\n        avctx->internal->draining = 1;\n\n        if (!(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            return 0;\n    }\n\n    if (avctx->codec->send_frame)\n        return avctx->codec->send_frame(avctx, frame);\n\n    // Emulation via old API. Do it here instead of avcodec_receive_packet, because:\n    // 1. if the AVFrame is not refcounted, the copying will be much more\n    //    expensive than copying the packet data\n    // 2. assume few users use non-refcounted AVPackets, so usually no copy is\n    //    needed\n\n    if (avctx->internal->buffer_pkt_valid)\n        return AVERROR(EAGAIN);\n\n    return do_encode(avctx, frame, &(int){0});\n}\n\nint attribute_align_arg avcodec_receive_packet(AVCodecContext *avctx, AVPacket *avpkt)\n{\n    av_packet_unref(avpkt);\n\n    if (!avcodec_is_open(avctx) || !av_codec_is_encoder(avctx->codec))\n        return AVERROR(EINVAL);\n\n    if (avctx->codec->receive_packet) {\n        if (avctx->internal->draining && !(avctx->codec->capabilities & AV_CODEC_CAP_DELAY))\n            return AVERROR_EOF;\n        return avctx->codec->receive_packet(avctx, avpkt);\n    }\n\n    // Emulation via old API.\n\n    if (!avctx->internal->buffer_pkt_valid) {\n        int got_packet;\n        int ret;\n        if (!avctx->internal->draining)\n            return AVERROR(EAGAIN);\n        ret = do_encode(avctx, NULL, &got_packet);\n        if (ret < 0)\n            return ret;\n        if (ret >= 0 && !got_packet)\n            return AVERROR_EOF;\n    }\n\n    av_packet_move_ref(avpkt, avctx->internal->buffer_pkt);\n    avctx->internal->buffer_pkt_valid = 0;\n    return 0;\n}\n\nav_cold int avcodec_close(AVCodecContext *avctx)\n{\n    int i;\n\n    if (!avctx)\n        return 0;\n\n    if (avcodec_is_open(avctx)) {\n        FramePool *pool = avctx->internal->pool;\n        if (CONFIG_FRAME_THREAD_ENCODER &&\n            avctx->internal->frame_thread_encoder && avctx->thread_count > 1) {\n            ff_frame_thread_encoder_free(avctx);\n        }\n        if (HAVE_THREADS && avctx->internal->thread_ctx)\n            ff_thread_free(avctx);\n        if (avctx->codec && avctx->codec->close)\n            avctx->codec->close(avctx);\n        avctx->internal->byte_buffer_size = 0;\n        av_freep(&avctx->internal->byte_buffer);\n        av_frame_free(&avctx->internal->to_free);\n        av_frame_free(&avctx->internal->buffer_frame);\n        av_packet_free(&avctx->internal->buffer_pkt);\n        for (i = 0; i < FF_ARRAY_ELEMS(pool->pools); i++)\n            av_buffer_pool_uninit(&pool->pools[i]);\n        av_freep(&avctx->internal->pool);\n\n        if (avctx->hwaccel && avctx->hwaccel->uninit)\n            avctx->hwaccel->uninit(avctx);\n        av_freep(&avctx->internal->hwaccel_priv_data);\n\n        av_freep(&avctx->internal);\n    }\n\n    for (i = 0; i < avctx->nb_coded_side_data; i++)\n        av_freep(&avctx->coded_side_data[i].data);\n    av_freep(&avctx->coded_side_data);\n    avctx->nb_coded_side_data = 0;\n\n    av_buffer_unref(&avctx->hw_frames_ctx);\n\n    if (avctx->priv_data && avctx->codec && avctx->codec->priv_class)\n        av_opt_free(avctx->priv_data);\n    av_opt_free(avctx);\n    av_freep(&avctx->priv_data);\n    if (av_codec_is_encoder(avctx->codec)) {\n        av_freep(&avctx->extradata);\n#if FF_API_CODED_FRAME\nFF_DISABLE_DEPRECATION_WARNINGS\n        av_frame_free(&avctx->coded_frame);\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif\n    }\n    avctx->codec = NULL;\n    avctx->active_thread_type = 0;\n\n    return 0;\n}\n\nstatic enum AVCodecID remap_deprecated_codec_id(enum AVCodecID id)\n{\n    switch(id){\n        //This is for future deprecatec codec ids, its empty since\n        //last major bump but will fill up again over time, please don't remove it\n        default                                         : return id;\n    }\n}\n\nstatic AVCodec *find_encdec(enum AVCodecID id, int encoder)\n{\n    AVCodec *p, *experimental = NULL;\n    p = first_avcodec;\n    id= remap_deprecated_codec_id(id);\n    while (p) {\n        if ((encoder ? av_codec_is_encoder(p) : av_codec_is_decoder(p)) &&\n            p->id == id) {\n            if (p->capabilities & AV_CODEC_CAP_EXPERIMENTAL && !experimental) {\n                experimental = p;\n            } else\n                return p;\n        }\n        p = p->next;\n    }\n    return experimental;\n}\n\nAVCodec *avcodec_find_encoder(enum AVCodecID id)\n{\n    return find_encdec(id, 1);\n}\n\nAVCodec *avcodec_find_encoder_by_name(const char *name)\n{\n    AVCodec *p;\n    if (!name)\n        return NULL;\n    p = first_avcodec;\n    while (p) {\n        if (av_codec_is_encoder(p) && strcmp(name, p->name) == 0)\n            return p;\n        p = p->next;\n    }\n    return NULL;\n}\n\nAVCodec *avcodec_find_decoder(enum AVCodecID id)\n{\n    return find_encdec(id, 0);\n}\n\nAVCodec *avcodec_find_decoder_by_name(const char *name)\n{\n    AVCodec *p;\n    if (!name)\n        return NULL;\n    p = first_avcodec;\n    while (p) {\n        if (av_codec_is_decoder(p) && strcmp(name, p->name) == 0)\n            return p;\n        p = p->next;\n    }\n    return NULL;\n}\n\nconst char *avcodec_get_name(enum AVCodecID id)\n{\n    const AVCodecDescriptor *cd;\n    AVCodec *codec;\n\n    if (id == AV_CODEC_ID_NONE)\n        return \"none\";\n    cd = avcodec_descriptor_get(id);\n    if (cd)\n        return cd->name;\n    av_log(NULL, AV_LOG_WARNING, \"Codec 0x%x is not in the full list.\\n\", id);\n    codec = avcodec_find_decoder(id);\n    if (codec)\n        return codec->name;\n    codec = avcodec_find_encoder(id);\n    if (codec)\n        return codec->name;\n    return \"unknown_codec\";\n}\n\nsize_t av_get_codec_tag_string(char *buf, size_t buf_size, unsigned int codec_tag)\n{\n    int i, len, ret = 0;\n\n#define TAG_PRINT(x)                                              \\\n    (((x) >= '0' && (x) <= '9') ||                                \\\n     ((x) >= 'a' && (x) <= 'z') || ((x) >= 'A' && (x) <= 'Z') ||  \\\n     ((x) == '.' || (x) == ' ' || (x) == '-' || (x) == '_'))\n\n    for (i = 0; i < 4; i++) {\n        len = snprintf(buf, buf_size,\n                       TAG_PRINT(codec_tag & 0xFF) ? \"%c\" : \"[%d]\", codec_tag & 0xFF);\n        buf        += len;\n        buf_size    = buf_size > len ? buf_size - len : 0;\n        ret        += len;\n        codec_tag >>= 8;\n    }\n    return ret;\n}\n\nvoid avcodec_string(char *buf, int buf_size, AVCodecContext *enc, int encode)\n{\n    const char *codec_type;\n    const char *codec_name;\n    const char *profile = NULL;\n    int64_t bitrate;\n    int new_line = 0;\n    AVRational display_aspect_ratio;\n    const char *separator = enc->dump_separator ? (const char *)enc->dump_separator : \", \";\n\n    if (!buf || buf_size <= 0)\n        return;\n    codec_type = av_get_media_type_string(enc->codec_type);\n    codec_name = avcodec_get_name(enc->codec_id);\n    profile = avcodec_profile_name(enc->codec_id, enc->profile);\n\n    snprintf(buf, buf_size, \"%s: %s\", codec_type ? codec_type : \"unknown\",\n             codec_name);\n    buf[0] ^= 'a' ^ 'A'; /* first letter in uppercase */\n\n    if (enc->codec && strcmp(enc->codec->name, codec_name))\n        snprintf(buf + strlen(buf), buf_size - strlen(buf), \" (%s)\", enc->codec->name);\n\n    if (profile)\n        snprintf(buf + strlen(buf), buf_size - strlen(buf), \" (%s)\", profile);\n    if (   enc->codec_type == AVMEDIA_TYPE_VIDEO\n        && av_log_get_level() >= AV_LOG_VERBOSE\n        && enc->refs)\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \", %d reference frame%s\",\n                 enc->refs, enc->refs > 1 ? \"s\" : \"\");\n\n    if (enc->codec_tag) {\n        char tag_buf[32];\n        av_get_codec_tag_string(tag_buf, sizeof(tag_buf), enc->codec_tag);\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \" (%s / 0x%04X)\", tag_buf, enc->codec_tag);\n    }\n\n    switch (enc->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        {\n            char detail[256] = \"(\";\n\n            av_strlcat(buf, separator, buf_size);\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \"%s\", enc->pix_fmt == AV_PIX_FMT_NONE ? \"none\" :\n                     av_get_pix_fmt_name(enc->pix_fmt));\n            if (enc->bits_per_raw_sample && enc->pix_fmt != AV_PIX_FMT_NONE &&\n                enc->bits_per_raw_sample < av_pix_fmt_desc_get(enc->pix_fmt)->comp[0].depth)\n                av_strlcatf(detail, sizeof(detail), \"%d bpc, \", enc->bits_per_raw_sample);\n            if (enc->color_range != AVCOL_RANGE_UNSPECIFIED)\n                av_strlcatf(detail, sizeof(detail), \"%s, \",\n                            av_color_range_name(enc->color_range));\n\n            if (enc->colorspace != AVCOL_SPC_UNSPECIFIED ||\n                enc->color_primaries != AVCOL_PRI_UNSPECIFIED ||\n                enc->color_trc != AVCOL_TRC_UNSPECIFIED) {\n                if (enc->colorspace != (int)enc->color_primaries ||\n                    enc->colorspace != (int)enc->color_trc) {\n                    new_line = 1;\n                    av_strlcatf(detail, sizeof(detail), \"%s/%s/%s, \",\n                                av_color_space_name(enc->colorspace),\n                                av_color_primaries_name(enc->color_primaries),\n                                av_color_transfer_name(enc->color_trc));\n                } else\n                    av_strlcatf(detail, sizeof(detail), \"%s, \",\n                                av_get_colorspace_name(enc->colorspace));\n            }\n\n            if (enc->field_order != AV_FIELD_UNKNOWN) {\n                const char *field_order = \"progressive\";\n                if (enc->field_order == AV_FIELD_TT)\n                    field_order = \"top first\";\n                else if (enc->field_order == AV_FIELD_BB)\n                    field_order = \"bottom first\";\n                else if (enc->field_order == AV_FIELD_TB)\n                    field_order = \"top coded first (swapped)\";\n                else if (enc->field_order == AV_FIELD_BT)\n                    field_order = \"bottom coded first (swapped)\";\n\n                av_strlcatf(detail, sizeof(detail), \"%s, \", field_order);\n            }\n\n            if (av_log_get_level() >= AV_LOG_VERBOSE &&\n                enc->chroma_sample_location != AVCHROMA_LOC_UNSPECIFIED)\n                av_strlcatf(detail, sizeof(detail), \"%s, \",\n                            av_chroma_location_name(enc->chroma_sample_location));\n\n            if (strlen(detail) > 1) {\n                detail[strlen(detail) - 2] = 0;\n                av_strlcatf(buf, buf_size, \"%s)\", detail);\n            }\n        }\n\n        if (enc->width) {\n            av_strlcat(buf, new_line ? separator : \", \", buf_size);\n\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \"%dx%d\",\n                     enc->width, enc->height);\n\n            if (av_log_get_level() >= AV_LOG_VERBOSE &&\n                (enc->width != enc->coded_width ||\n                 enc->height != enc->coded_height))\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \" (%dx%d)\", enc->coded_width, enc->coded_height);\n\n            if (enc->sample_aspect_ratio.num) {\n                av_reduce(&display_aspect_ratio.num, &display_aspect_ratio.den,\n                          enc->width * (int64_t)enc->sample_aspect_ratio.num,\n                          enc->height * (int64_t)enc->sample_aspect_ratio.den,\n                          1024 * 1024);\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \" [SAR %d:%d DAR %d:%d]\",\n                         enc->sample_aspect_ratio.num, enc->sample_aspect_ratio.den,\n                         display_aspect_ratio.num, display_aspect_ratio.den);\n            }\n            if (av_log_get_level() >= AV_LOG_DEBUG) {\n                int g = av_gcd(enc->time_base.num, enc->time_base.den);\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", %d/%d\",\n                         enc->time_base.num / g, enc->time_base.den / g);\n            }\n        }\n        if (encode) {\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", q=%d-%d\", enc->qmin, enc->qmax);\n        } else {\n            if (enc->properties & FF_CODEC_PROPERTY_CLOSED_CAPTIONS)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", Closed Captions\");\n            if (enc->properties & FF_CODEC_PROPERTY_LOSSLESS)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", lossless\");\n        }\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        av_strlcat(buf, separator, buf_size);\n\n        if (enc->sample_rate) {\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \"%d Hz, \", enc->sample_rate);\n        }\n        av_get_channel_layout_string(buf + strlen(buf), buf_size - strlen(buf), enc->channels, enc->channel_layout);\n        if (enc->sample_fmt != AV_SAMPLE_FMT_NONE) {\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", %s\", av_get_sample_fmt_name(enc->sample_fmt));\n        }\n        if (   enc->bits_per_raw_sample > 0\n            && enc->bits_per_raw_sample != av_get_bytes_per_sample(enc->sample_fmt) * 8)\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \" (%d bit)\", enc->bits_per_raw_sample);\n        if (av_log_get_level() >= AV_LOG_VERBOSE) {\n            if (enc->initial_padding)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", delay %d\", enc->initial_padding);\n            if (enc->trailing_padding)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", padding %d\", enc->trailing_padding);\n        }\n        break;\n    case AVMEDIA_TYPE_DATA:\n        if (av_log_get_level() >= AV_LOG_DEBUG) {\n            int g = av_gcd(enc->time_base.num, enc->time_base.den);\n            if (g)\n                snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                         \", %d/%d\",\n                         enc->time_base.num / g, enc->time_base.den / g);\n        }\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        if (enc->width)\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", %dx%d\", enc->width, enc->height);\n        break;\n    default:\n        return;\n    }\n    if (encode) {\n        if (enc->flags & AV_CODEC_FLAG_PASS1)\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", pass 1\");\n        if (enc->flags & AV_CODEC_FLAG_PASS2)\n            snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                     \", pass 2\");\n    }\n    bitrate = get_bit_rate(enc);\n    if (bitrate != 0) {\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \", %\"PRId64\" kb/s\", bitrate / 1000);\n    } else if (enc->rc_max_rate > 0) {\n        snprintf(buf + strlen(buf), buf_size - strlen(buf),\n                 \", max. %\"PRId64\" kb/s\", (int64_t)enc->rc_max_rate / 1000);\n    }\n}\n\nconst char *av_get_profile_name(const AVCodec *codec, int profile)\n{\n    const AVProfile *p;\n    if (profile == FF_PROFILE_UNKNOWN || !codec->profiles)\n        return NULL;\n\n    for (p = codec->profiles; p->profile != FF_PROFILE_UNKNOWN; p++)\n        if (p->profile == profile)\n            return p->name;\n\n    return NULL;\n}\n\nconst char *avcodec_profile_name(enum AVCodecID codec_id, int profile)\n{\n    const AVCodecDescriptor *desc = avcodec_descriptor_get(codec_id);\n    const AVProfile *p;\n\n    if (profile == FF_PROFILE_UNKNOWN || !desc || !desc->profiles)\n        return NULL;\n\n    for (p = desc->profiles; p->profile != FF_PROFILE_UNKNOWN; p++)\n        if (p->profile == profile)\n            return p->name;\n\n    return NULL;\n}\n\nunsigned avcodec_version(void)\n{\n//    av_assert0(AV_CODEC_ID_V410==164);\n    av_assert0(AV_CODEC_ID_PCM_S8_PLANAR==65563);\n    av_assert0(AV_CODEC_ID_ADPCM_G722==69660);\n//     av_assert0(AV_CODEC_ID_BMV_AUDIO==86071);\n    av_assert0(AV_CODEC_ID_SRT==94216);\n    av_assert0(LIBAVCODEC_VERSION_MICRO >= 100);\n\n    return LIBAVCODEC_VERSION_INT;\n}\n\nconst char *avcodec_configuration(void)\n{\n    return FFMPEG_CONFIGURATION;\n}\n\nconst char *avcodec_license(void)\n{\n#define LICENSE_PREFIX \"libavcodec license: \"\n    return LICENSE_PREFIX FFMPEG_LICENSE + sizeof(LICENSE_PREFIX) - 1;\n}\n\nvoid avcodec_flush_buffers(AVCodecContext *avctx)\n{\n    avctx->internal->draining      = 0;\n    avctx->internal->draining_done = 0;\n    av_frame_unref(avctx->internal->buffer_frame);\n    av_packet_unref(avctx->internal->buffer_pkt);\n    avctx->internal->buffer_pkt_valid = 0;\n\n    if (HAVE_THREADS && avctx->active_thread_type & FF_THREAD_FRAME)\n        ff_thread_flush(avctx);\n    else if (avctx->codec->flush)\n        avctx->codec->flush(avctx);\n\n    avctx->pts_correction_last_pts =\n    avctx->pts_correction_last_dts = INT64_MIN;\n\n    if (!avctx->refcounted_frames)\n        av_frame_unref(avctx->internal->to_free);\n}\n\nint av_get_exact_bits_per_sample(enum AVCodecID codec_id)\n{\n    switch (codec_id) {\n    case AV_CODEC_ID_8SVX_EXP:\n    case AV_CODEC_ID_8SVX_FIB:\n    case AV_CODEC_ID_ADPCM_CT:\n    case AV_CODEC_ID_ADPCM_IMA_APC:\n    case AV_CODEC_ID_ADPCM_IMA_EA_SEAD:\n    case AV_CODEC_ID_ADPCM_IMA_OKI:\n    case AV_CODEC_ID_ADPCM_IMA_WS:\n    case AV_CODEC_ID_ADPCM_G722:\n    case AV_CODEC_ID_ADPCM_YAMAHA:\n    case AV_CODEC_ID_ADPCM_AICA:\n        return 4;\n    case AV_CODEC_ID_DSD_LSBF:\n    case AV_CODEC_ID_DSD_MSBF:\n    case AV_CODEC_ID_DSD_LSBF_PLANAR:\n    case AV_CODEC_ID_DSD_MSBF_PLANAR:\n    case AV_CODEC_ID_PCM_ALAW:\n    case AV_CODEC_ID_PCM_MULAW:\n    case AV_CODEC_ID_PCM_S8:\n    case AV_CODEC_ID_PCM_S8_PLANAR:\n    case AV_CODEC_ID_PCM_U8:\n    case AV_CODEC_ID_PCM_ZORK:\n    case AV_CODEC_ID_SDX2_DPCM:\n        return 8;\n    case AV_CODEC_ID_PCM_S16BE:\n    case AV_CODEC_ID_PCM_S16BE_PLANAR:\n    case AV_CODEC_ID_PCM_S16LE:\n    case AV_CODEC_ID_PCM_S16LE_PLANAR:\n    case AV_CODEC_ID_PCM_U16BE:\n    case AV_CODEC_ID_PCM_U16LE:\n        return 16;\n    case AV_CODEC_ID_PCM_S24DAUD:\n    case AV_CODEC_ID_PCM_S24BE:\n    case AV_CODEC_ID_PCM_S24LE:\n    case AV_CODEC_ID_PCM_S24LE_PLANAR:\n    case AV_CODEC_ID_PCM_U24BE:\n    case AV_CODEC_ID_PCM_U24LE:\n        return 24;\n    case AV_CODEC_ID_PCM_S32BE:\n    case AV_CODEC_ID_PCM_S32LE:\n    case AV_CODEC_ID_PCM_S32LE_PLANAR:\n    case AV_CODEC_ID_PCM_U32BE:\n    case AV_CODEC_ID_PCM_U32LE:\n    case AV_CODEC_ID_PCM_F32BE:\n    case AV_CODEC_ID_PCM_F32LE:\n    case AV_CODEC_ID_PCM_F24LE:\n    case AV_CODEC_ID_PCM_F16LE:\n        return 32;\n    case AV_CODEC_ID_PCM_F64BE:\n    case AV_CODEC_ID_PCM_F64LE:\n    case AV_CODEC_ID_PCM_S64BE:\n    case AV_CODEC_ID_PCM_S64LE:\n        return 64;\n    default:\n        return 0;\n    }\n}\n\nenum AVCodecID av_get_pcm_codec(enum AVSampleFormat fmt, int be)\n{\n    static const enum AVCodecID map[AV_SAMPLE_FMT_NB][2] = {\n        [AV_SAMPLE_FMT_U8  ] = { AV_CODEC_ID_PCM_U8,    AV_CODEC_ID_PCM_U8    },\n        [AV_SAMPLE_FMT_S16 ] = { AV_CODEC_ID_PCM_S16LE, AV_CODEC_ID_PCM_S16BE },\n        [AV_SAMPLE_FMT_S32 ] = { AV_CODEC_ID_PCM_S32LE, AV_CODEC_ID_PCM_S32BE },\n        [AV_SAMPLE_FMT_FLT ] = { AV_CODEC_ID_PCM_F32LE, AV_CODEC_ID_PCM_F32BE },\n        [AV_SAMPLE_FMT_DBL ] = { AV_CODEC_ID_PCM_F64LE, AV_CODEC_ID_PCM_F64BE },\n        [AV_SAMPLE_FMT_U8P ] = { AV_CODEC_ID_PCM_U8,    AV_CODEC_ID_PCM_U8    },\n        [AV_SAMPLE_FMT_S16P] = { AV_CODEC_ID_PCM_S16LE, AV_CODEC_ID_PCM_S16BE },\n        [AV_SAMPLE_FMT_S32P] = { AV_CODEC_ID_PCM_S32LE, AV_CODEC_ID_PCM_S32BE },\n        [AV_SAMPLE_FMT_S64P] = { AV_CODEC_ID_PCM_S64LE, AV_CODEC_ID_PCM_S64BE },\n        [AV_SAMPLE_FMT_FLTP] = { AV_CODEC_ID_PCM_F32LE, AV_CODEC_ID_PCM_F32BE },\n        [AV_SAMPLE_FMT_DBLP] = { AV_CODEC_ID_PCM_F64LE, AV_CODEC_ID_PCM_F64BE },\n    };\n    if (fmt < 0 || fmt >= AV_SAMPLE_FMT_NB)\n        return AV_CODEC_ID_NONE;\n    if (be < 0 || be > 1)\n        be = AV_NE(1, 0);\n    return map[fmt][be];\n}\n\nint av_get_bits_per_sample(enum AVCodecID codec_id)\n{\n    switch (codec_id) {\n    case AV_CODEC_ID_ADPCM_SBPRO_2:\n        return 2;\n    case AV_CODEC_ID_ADPCM_SBPRO_3:\n        return 3;\n    case AV_CODEC_ID_ADPCM_SBPRO_4:\n    case AV_CODEC_ID_ADPCM_IMA_WAV:\n    case AV_CODEC_ID_ADPCM_IMA_QT:\n    case AV_CODEC_ID_ADPCM_SWF:\n    case AV_CODEC_ID_ADPCM_MS:\n        return 4;\n    default:\n        return av_get_exact_bits_per_sample(codec_id);\n    }\n}\n\nstatic int get_audio_frame_duration(enum AVCodecID id, int sr, int ch, int ba,\n                                    uint32_t tag, int bits_per_coded_sample, int64_t bitrate,\n                                    uint8_t * extradata, int frame_size, int frame_bytes)\n{\n    int bps = av_get_exact_bits_per_sample(id);\n    int framecount = (ba > 0 && frame_bytes / ba > 0) ? frame_bytes / ba : 1;\n\n    /* codecs with an exact constant bits per sample */\n    if (bps > 0 && ch > 0 && frame_bytes > 0 && ch < 32768 && bps < 32768)\n        return (frame_bytes * 8LL) / (bps * ch);\n    bps = bits_per_coded_sample;\n\n    /* codecs with a fixed packet duration */\n    switch (id) {\n    case AV_CODEC_ID_ADPCM_ADX:    return   32;\n    case AV_CODEC_ID_ADPCM_IMA_QT: return   64;\n    case AV_CODEC_ID_ADPCM_EA_XAS: return  128;\n    case AV_CODEC_ID_AMR_NB:\n    case AV_CODEC_ID_EVRC:\n    case AV_CODEC_ID_GSM:\n    case AV_CODEC_ID_QCELP:\n    case AV_CODEC_ID_RA_288:       return  160;\n    case AV_CODEC_ID_AMR_WB:\n    case AV_CODEC_ID_GSM_MS:       return  320;\n    case AV_CODEC_ID_MP1:          return  384;\n    case AV_CODEC_ID_ATRAC1:       return  512;\n    case AV_CODEC_ID_ATRAC3:       return 1024 * framecount;\n    case AV_CODEC_ID_ATRAC3P:      return 2048;\n    case AV_CODEC_ID_MP2:\n    case AV_CODEC_ID_MUSEPACK7:    return 1152;\n    case AV_CODEC_ID_AC3:          return 1536;\n    }\n\n    if (sr > 0) {\n        /* calc from sample rate */\n        if (id == AV_CODEC_ID_TTA)\n            return 256 * sr / 245;\n        else if (id == AV_CODEC_ID_DST)\n            return 588 * sr / 44100;\n\n        if (ch > 0) {\n            /* calc from sample rate and channels */\n            if (id == AV_CODEC_ID_BINKAUDIO_DCT)\n                return (480 << (sr / 22050)) / ch;\n        }\n    }\n\n    if (ba > 0) {\n        /* calc from block_align */\n        if (id == AV_CODEC_ID_SIPR) {\n            switch (ba) {\n            case 20: return 160;\n            case 19: return 144;\n            case 29: return 288;\n            case 37: return 480;\n            }\n        } else if (id == AV_CODEC_ID_ILBC) {\n            switch (ba) {\n            case 38: return 160;\n            case 50: return 240;\n            }\n        }\n    }\n\n    if (frame_bytes > 0) {\n        /* calc from frame_bytes only */\n        if (id == AV_CODEC_ID_TRUESPEECH)\n            return 240 * (frame_bytes / 32);\n        if (id == AV_CODEC_ID_NELLYMOSER)\n            return 256 * (frame_bytes / 64);\n        if (id == AV_CODEC_ID_RA_144)\n            return 160 * (frame_bytes / 20);\n        if (id == AV_CODEC_ID_G723_1)\n            return 240 * (frame_bytes / 24);\n\n        if (bps > 0) {\n            /* calc from frame_bytes and bits_per_coded_sample */\n            if (id == AV_CODEC_ID_ADPCM_G726)\n                return frame_bytes * 8 / bps;\n        }\n\n        if (ch > 0 && ch < INT_MAX/16) {\n            /* calc from frame_bytes and channels */\n            switch (id) {\n            case AV_CODEC_ID_ADPCM_AFC:\n                return frame_bytes / (9 * ch) * 16;\n            case AV_CODEC_ID_ADPCM_PSX:\n            case AV_CODEC_ID_ADPCM_DTK:\n                return frame_bytes / (16 * ch) * 28;\n            case AV_CODEC_ID_ADPCM_4XM:\n            case AV_CODEC_ID_ADPCM_IMA_DAT4:\n            case AV_CODEC_ID_ADPCM_IMA_ISS:\n                return (frame_bytes - 4 * ch) * 2 / ch;\n            case AV_CODEC_ID_ADPCM_IMA_SMJPEG:\n                return (frame_bytes - 4) * 2 / ch;\n            case AV_CODEC_ID_ADPCM_IMA_AMV:\n                return (frame_bytes - 8) * 2 / ch;\n            case AV_CODEC_ID_ADPCM_THP:\n            case AV_CODEC_ID_ADPCM_THP_LE:\n                if (extradata)\n                    return frame_bytes * 14 / (8 * ch);\n                break;\n            case AV_CODEC_ID_ADPCM_XA:\n                return (frame_bytes / 128) * 224 / ch;\n            case AV_CODEC_ID_INTERPLAY_DPCM:\n                return (frame_bytes - 6 - ch) / ch;\n            case AV_CODEC_ID_ROQ_DPCM:\n                return (frame_bytes - 8) / ch;\n            case AV_CODEC_ID_XAN_DPCM:\n                return (frame_bytes - 2 * ch) / ch;\n            case AV_CODEC_ID_MACE3:\n                return 3 * frame_bytes / ch;\n            case AV_CODEC_ID_MACE6:\n                return 6 * frame_bytes / ch;\n            case AV_CODEC_ID_PCM_LXF:\n                return 2 * (frame_bytes / (5 * ch));\n            case AV_CODEC_ID_IAC:\n            case AV_CODEC_ID_IMC:\n                return 4 * frame_bytes / ch;\n            }\n\n            if (tag) {\n                /* calc from frame_bytes, channels, and codec_tag */\n                if (id == AV_CODEC_ID_SOL_DPCM) {\n                    if (tag == 3)\n                        return frame_bytes / ch;\n                    else\n                        return frame_bytes * 2 / ch;\n                }\n            }\n\n            if (ba > 0) {\n                /* calc from frame_bytes, channels, and block_align */\n                int blocks = frame_bytes / ba;\n                switch (id) {\n                case AV_CODEC_ID_ADPCM_IMA_WAV:\n                    if (bps < 2 || bps > 5)\n                        return 0;\n                    return blocks * (1 + (ba - 4 * ch) / (bps * ch) * 8);\n                case AV_CODEC_ID_ADPCM_IMA_DK3:\n                    return blocks * (((ba - 16) * 2 / 3 * 4) / ch);\n                case AV_CODEC_ID_ADPCM_IMA_DK4:\n                    return blocks * (1 + (ba - 4 * ch) * 2 / ch);\n                case AV_CODEC_ID_ADPCM_IMA_RAD:\n                    return blocks * ((ba - 4 * ch) * 2 / ch);\n                case AV_CODEC_ID_ADPCM_MS:\n                    return blocks * (2 + (ba - 7 * ch) * 2 / ch);\n                case AV_CODEC_ID_ADPCM_MTAF:\n                    return blocks * (ba - 16) * 2 / ch;\n                }\n            }\n\n            if (bps > 0) {\n                /* calc from frame_bytes, channels, and bits_per_coded_sample */\n                switch (id) {\n                case AV_CODEC_ID_PCM_DVD:\n                    if(bps<4)\n                        return 0;\n                    return 2 * (frame_bytes / ((bps * 2 / 8) * ch));\n                case AV_CODEC_ID_PCM_BLURAY:\n                    if(bps<4)\n                        return 0;\n                    return frame_bytes / ((FFALIGN(ch, 2) * bps) / 8);\n                case AV_CODEC_ID_S302M:\n                    return 2 * (frame_bytes / ((bps + 4) / 4)) / ch;\n                }\n            }\n        }\n    }\n\n    /* Fall back on using frame_size */\n    if (frame_size > 1 && frame_bytes)\n        return frame_size;\n\n    //For WMA we currently have no other means to calculate duration thus we\n    //do it here by assuming CBR, which is true for all known cases.\n    if (bitrate > 0 && frame_bytes > 0 && sr > 0 && ba > 1) {\n        if (id == AV_CODEC_ID_WMAV1 || id == AV_CODEC_ID_WMAV2)\n            return  (frame_bytes * 8LL * sr) / bitrate;\n    }\n\n    return 0;\n}\n\nint av_get_audio_frame_duration(AVCodecContext *avctx, int frame_bytes)\n{\n    return get_audio_frame_duration(avctx->codec_id, avctx->sample_rate,\n                                    avctx->channels, avctx->block_align,\n                                    avctx->codec_tag, avctx->bits_per_coded_sample,\n                                    avctx->bit_rate, avctx->extradata, avctx->frame_size,\n                                    frame_bytes);\n}\n\nint av_get_audio_frame_duration2(AVCodecParameters *par, int frame_bytes)\n{\n    return get_audio_frame_duration(par->codec_id, par->sample_rate,\n                                    par->channels, par->block_align,\n                                    par->codec_tag, par->bits_per_coded_sample,\n                                    par->bit_rate, par->extradata, par->frame_size,\n                                    frame_bytes);\n}\n\n#if !HAVE_THREADS\nint ff_thread_init(AVCodecContext *s)\n{\n    return -1;\n}\n\n#endif\n\nunsigned int av_xiphlacing(unsigned char *s, unsigned int v)\n{\n    unsigned int n = 0;\n\n    while (v >= 0xff) {\n        *s++ = 0xff;\n        v -= 0xff;\n        n++;\n    }\n    *s = v;\n    n++;\n    return n;\n}\n\nint ff_match_2uint16(const uint16_t(*tab)[2], int size, int a, int b)\n{\n    int i;\n    for (i = 0; i < size && !(tab[i][0] == a && tab[i][1] == b); i++) ;\n    return i;\n}\n\n#if FF_API_MISSING_SAMPLE\nFF_DISABLE_DEPRECATION_WARNINGS\nvoid av_log_missing_feature(void *avc, const char *feature, int want_sample)\n{\n    av_log(avc, AV_LOG_WARNING, \"%s is not implemented. Update your FFmpeg \"\n            \"version to the newest one from Git. If the problem still \"\n            \"occurs, it means that your file has a feature which has not \"\n            \"been implemented.\\n\", feature);\n    if(want_sample)\n        av_log_ask_for_sample(avc, NULL);\n}\n\nvoid av_log_ask_for_sample(void *avc, const char *msg, ...)\n{\n    va_list argument_list;\n\n    va_start(argument_list, msg);\n\n    if (msg)\n        av_vlog(avc, AV_LOG_WARNING, msg, argument_list);\n    av_log(avc, AV_LOG_WARNING, \"If you want to help, upload a sample \"\n            \"of this file to ftp://upload.ffmpeg.org/incoming/ \"\n            \"and contact the ffmpeg-devel mailing list. (ffmpeg-devel@ffmpeg.org)\\n\");\n\n    va_end(argument_list);\n}\nFF_ENABLE_DEPRECATION_WARNINGS\n#endif /* FF_API_MISSING_SAMPLE */\n\nstatic AVHWAccel *first_hwaccel = NULL;\nstatic AVHWAccel **last_hwaccel = &first_hwaccel;\n\nvoid av_register_hwaccel(AVHWAccel *hwaccel)\n{\n    AVHWAccel **p = last_hwaccel;\n    hwaccel->next = NULL;\n    while(*p || avpriv_atomic_ptr_cas((void * volatile *)p, NULL, hwaccel))\n        p = &(*p)->next;\n    last_hwaccel = &hwaccel->next;\n}\n\nAVHWAccel *av_hwaccel_next(const AVHWAccel *hwaccel)\n{\n    return hwaccel ? hwaccel->next : first_hwaccel;\n}\n\nint av_lockmgr_register(int (*cb)(void **mutex, enum AVLockOp op))\n{\n    if (lockmgr_cb) {\n        // There is no good way to rollback a failure to destroy the\n        // mutex, so we ignore failures.\n        lockmgr_cb(&codec_mutex,    AV_LOCK_DESTROY);\n        lockmgr_cb(&avformat_mutex, AV_LOCK_DESTROY);\n        lockmgr_cb     = NULL;\n        codec_mutex    = NULL;\n        avformat_mutex = NULL;\n    }\n\n    if (cb) {\n        void *new_codec_mutex    = NULL;\n        void *new_avformat_mutex = NULL;\n        int err;\n        if (err = cb(&new_codec_mutex, AV_LOCK_CREATE)) {\n            return err > 0 ? AVERROR_UNKNOWN : err;\n        }\n        if (err = cb(&new_avformat_mutex, AV_LOCK_CREATE)) {\n            // Ignore failures to destroy the newly created mutex.\n            cb(&new_codec_mutex, AV_LOCK_DESTROY);\n            return err > 0 ? AVERROR_UNKNOWN : err;\n        }\n        lockmgr_cb     = cb;\n        codec_mutex    = new_codec_mutex;\n        avformat_mutex = new_avformat_mutex;\n    }\n\n    return 0;\n}\n\nint ff_lock_avcodec(AVCodecContext *log_ctx, const AVCodec *codec)\n{\n    if (codec->caps_internal & FF_CODEC_CAP_INIT_THREADSAFE || !codec->init)\n        return 0;\n\n    if (lockmgr_cb) {\n        if ((*lockmgr_cb)(&codec_mutex, AV_LOCK_OBTAIN))\n            return -1;\n    }\n\n    if (avpriv_atomic_int_add_and_fetch(&entangled_thread_counter, 1) != 1) {\n        av_log(log_ctx, AV_LOG_ERROR,\n               \"Insufficient thread locking. At least %d threads are \"\n               \"calling avcodec_open2() at the same time right now.\\n\",\n               entangled_thread_counter);\n        if (!lockmgr_cb)\n            av_log(log_ctx, AV_LOG_ERROR, \"No lock manager is set, please see av_lockmgr_register()\\n\");\n        ff_avcodec_locked = 1;\n        ff_unlock_avcodec(codec);\n        return AVERROR(EINVAL);\n    }\n    av_assert0(!ff_avcodec_locked);\n    ff_avcodec_locked = 1;\n    return 0;\n}\n\nint ff_unlock_avcodec(const AVCodec *codec)\n{\n    if (codec->caps_internal & FF_CODEC_CAP_INIT_THREADSAFE || !codec->init)\n        return 0;\n\n    av_assert0(ff_avcodec_locked);\n    ff_avcodec_locked = 0;\n    avpriv_atomic_int_add_and_fetch(&entangled_thread_counter, -1);\n    if (lockmgr_cb) {\n        if ((*lockmgr_cb)(&codec_mutex, AV_LOCK_RELEASE))\n            return -1;\n    }\n\n    return 0;\n}\n\nint avpriv_lock_avformat(void)\n{\n    if (lockmgr_cb) {\n        if ((*lockmgr_cb)(&avformat_mutex, AV_LOCK_OBTAIN))\n            return -1;\n    }\n    return 0;\n}\n\nint avpriv_unlock_avformat(void)\n{\n    if (lockmgr_cb) {\n        if ((*lockmgr_cb)(&avformat_mutex, AV_LOCK_RELEASE))\n            return -1;\n    }\n    return 0;\n}\n\nunsigned int avpriv_toupper4(unsigned int x)\n{\n    return av_toupper(x & 0xFF) +\n          (av_toupper((x >>  8) & 0xFF) << 8)  +\n          (av_toupper((x >> 16) & 0xFF) << 16) +\n((unsigned)av_toupper((x >> 24) & 0xFF) << 24);\n}\n\nint ff_thread_ref_frame(ThreadFrame *dst, ThreadFrame *src)\n{\n    int ret;\n\n    dst->owner = src->owner;\n\n    ret = av_frame_ref(dst->f, src->f);\n    if (ret < 0)\n        return ret;\n\n    av_assert0(!dst->progress);\n\n    if (src->progress &&\n        !(dst->progress = av_buffer_ref(src->progress))) {\n        ff_thread_release_buffer(dst->owner, dst);\n        return AVERROR(ENOMEM);\n    }\n\n    return 0;\n}\n\n#if !HAVE_THREADS\n\nenum AVPixelFormat ff_thread_get_format(AVCodecContext *avctx, const enum AVPixelFormat *fmt)\n{\n    return ff_get_format(avctx, fmt);\n}\n\nint ff_thread_get_buffer(AVCodecContext *avctx, ThreadFrame *f, int flags)\n{\n    f->owner = avctx;\n    return ff_get_buffer(avctx, f->f, flags);\n}\n\nvoid ff_thread_release_buffer(AVCodecContext *avctx, ThreadFrame *f)\n{\n    if (f->f)\n        av_frame_unref(f->f);\n}\n\nvoid ff_thread_finish_setup(AVCodecContext *avctx)\n{\n}\n\nvoid ff_thread_report_progress(ThreadFrame *f, int progress, int field)\n{\n}\n\nvoid ff_thread_await_progress(ThreadFrame *f, int progress, int field)\n{\n}\n\nint ff_thread_can_start_frame(AVCodecContext *avctx)\n{\n    return 1;\n}\n\nint ff_alloc_entries(AVCodecContext *avctx, int count)\n{\n    return 0;\n}\n\nvoid ff_reset_entries(AVCodecContext *avctx)\n{\n}\n\nvoid ff_thread_await_progress2(AVCodecContext *avctx, int field, int thread, int shift)\n{\n}\n\nvoid ff_thread_report_progress2(AVCodecContext *avctx, int field, int thread, int n)\n{\n}\n\n#endif\n\nint avcodec_is_open(AVCodecContext *s)\n{\n    return !!s->internal;\n}\n\nint avpriv_bprint_to_extradata(AVCodecContext *avctx, struct AVBPrint *buf)\n{\n    int ret;\n    char *str;\n\n    ret = av_bprint_finalize(buf, &str);\n    if (ret < 0)\n        return ret;\n    if (!av_bprint_is_complete(buf)) {\n        av_free(str);\n        return AVERROR(ENOMEM);\n    }\n\n    avctx->extradata = str;\n    /* Note: the string is NUL terminated (so extradata can be read as a\n     * string), but the ending character is not accounted in the size (in\n     * binary formats you are likely not supposed to mux that character). When\n     * extradata is copied, it is also padded with AV_INPUT_BUFFER_PADDING_SIZE\n     * zeros. */\n    avctx->extradata_size = buf->len;\n    return 0;\n}\n\nconst uint8_t *avpriv_find_start_code(const uint8_t *av_restrict p,\n                                      const uint8_t *end,\n                                      uint32_t *av_restrict state)\n{\n    int i;\n\n    av_assert0(p <= end);\n    if (p >= end)\n        return end;\n\n    for (i = 0; i < 3; i++) {\n        uint32_t tmp = *state << 8;\n        *state = tmp + *(p++);\n        if (tmp == 0x100 || p == end)\n            return p;\n    }\n\n    while (p < end) {\n        if      (p[-1] > 1      ) p += 3;\n        else if (p[-2]          ) p += 2;\n        else if (p[-3]|(p[-1]-1)) p++;\n        else {\n            p++;\n            break;\n        }\n    }\n\n    p = FFMIN(p, end) - 4;\n    *state = AV_RB32(p);\n\n    return p + 4;\n}\n\nAVCPBProperties *av_cpb_properties_alloc(size_t *size)\n{\n    AVCPBProperties *props = av_mallocz(sizeof(AVCPBProperties));\n    if (!props)\n        return NULL;\n\n    if (size)\n        *size = sizeof(*props);\n\n    props->vbv_delay = UINT64_MAX;\n\n    return props;\n}\n\nAVCPBProperties *ff_add_cpb_side_data(AVCodecContext *avctx)\n{\n    AVPacketSideData *tmp;\n    AVCPBProperties  *props;\n    size_t size;\n\n    props = av_cpb_properties_alloc(&size);\n    if (!props)\n        return NULL;\n\n    tmp = av_realloc_array(avctx->coded_side_data, avctx->nb_coded_side_data + 1, sizeof(*tmp));\n    if (!tmp) {\n        av_freep(&props);\n        return NULL;\n    }\n\n    avctx->coded_side_data = tmp;\n    avctx->nb_coded_side_data++;\n\n    avctx->coded_side_data[avctx->nb_coded_side_data - 1].type = AV_PKT_DATA_CPB_PROPERTIES;\n    avctx->coded_side_data[avctx->nb_coded_side_data - 1].data = (uint8_t*)props;\n    avctx->coded_side_data[avctx->nb_coded_side_data - 1].size = size;\n\n    return props;\n}\n\nstatic void codec_parameters_reset(AVCodecParameters *par)\n{\n    av_freep(&par->extradata);\n\n    memset(par, 0, sizeof(*par));\n\n    par->codec_type          = AVMEDIA_TYPE_UNKNOWN;\n    par->codec_id            = AV_CODEC_ID_NONE;\n    par->format              = -1;\n    par->field_order         = AV_FIELD_UNKNOWN;\n    par->color_range         = AVCOL_RANGE_UNSPECIFIED;\n    par->color_primaries     = AVCOL_PRI_UNSPECIFIED;\n    par->color_trc           = AVCOL_TRC_UNSPECIFIED;\n    par->color_space         = AVCOL_SPC_UNSPECIFIED;\n    par->chroma_location     = AVCHROMA_LOC_UNSPECIFIED;\n    par->sample_aspect_ratio = (AVRational){ 0, 1 };\n    par->profile             = FF_PROFILE_UNKNOWN;\n    par->level               = FF_LEVEL_UNKNOWN;\n}\n\nAVCodecParameters *avcodec_parameters_alloc(void)\n{\n    AVCodecParameters *par = av_mallocz(sizeof(*par));\n\n    if (!par)\n        return NULL;\n    codec_parameters_reset(par);\n    return par;\n}\n\nvoid avcodec_parameters_free(AVCodecParameters **ppar)\n{\n    AVCodecParameters *par = *ppar;\n\n    if (!par)\n        return;\n    codec_parameters_reset(par);\n\n    av_freep(ppar);\n}\n\nint avcodec_parameters_copy(AVCodecParameters *dst, const AVCodecParameters *src)\n{\n    codec_parameters_reset(dst);\n    memcpy(dst, src, sizeof(*dst));\n\n    dst->extradata      = NULL;\n    dst->extradata_size = 0;\n    if (src->extradata) {\n        dst->extradata = av_mallocz(src->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n        if (!dst->extradata)\n            return AVERROR(ENOMEM);\n        memcpy(dst->extradata, src->extradata, src->extradata_size);\n        dst->extradata_size = src->extradata_size;\n    }\n\n    return 0;\n}\n\nint avcodec_parameters_from_context(AVCodecParameters *par,\n                                    const AVCodecContext *codec)\n{\n    codec_parameters_reset(par);\n\n    par->codec_type = codec->codec_type;\n    par->codec_id   = codec->codec_id;\n    par->codec_tag  = codec->codec_tag;\n\n    par->bit_rate              = codec->bit_rate;\n    par->bits_per_coded_sample = codec->bits_per_coded_sample;\n    par->bits_per_raw_sample   = codec->bits_per_raw_sample;\n    par->profile               = codec->profile;\n    par->level                 = codec->level;\n\n    switch (par->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        par->format              = codec->pix_fmt;\n        par->width               = codec->width;\n        par->height              = codec->height;\n        par->field_order         = codec->field_order;\n        par->color_range         = codec->color_range;\n        par->color_primaries     = codec->color_primaries;\n        par->color_trc           = codec->color_trc;\n        par->color_space         = codec->colorspace;\n        par->chroma_location     = codec->chroma_sample_location;\n        par->sample_aspect_ratio = codec->sample_aspect_ratio;\n        par->video_delay         = codec->has_b_frames;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        par->format           = codec->sample_fmt;\n        par->channel_layout   = codec->channel_layout;\n        par->channels         = codec->channels;\n        par->sample_rate      = codec->sample_rate;\n        par->block_align      = codec->block_align;\n        par->frame_size       = codec->frame_size;\n        par->initial_padding  = codec->initial_padding;\n        par->trailing_padding = codec->trailing_padding;\n        par->seek_preroll     = codec->seek_preroll;\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        par->width  = codec->width;\n        par->height = codec->height;\n        break;\n    }\n\n    if (codec->extradata) {\n        par->extradata = av_mallocz(codec->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n        if (!par->extradata)\n            return AVERROR(ENOMEM);\n        memcpy(par->extradata, codec->extradata, codec->extradata_size);\n        par->extradata_size = codec->extradata_size;\n    }\n\n    return 0;\n}\n\nint avcodec_parameters_to_context(AVCodecContext *codec,\n                                  const AVCodecParameters *par)\n{\n    codec->codec_type = par->codec_type;\n    codec->codec_id   = par->codec_id;\n    codec->codec_tag  = par->codec_tag;\n\n    codec->bit_rate              = par->bit_rate;\n    codec->bits_per_coded_sample = par->bits_per_coded_sample;\n    codec->bits_per_raw_sample   = par->bits_per_raw_sample;\n    codec->profile               = par->profile;\n    codec->level                 = par->level;\n\n    switch (par->codec_type) {\n    case AVMEDIA_TYPE_VIDEO:\n        codec->pix_fmt                = par->format;\n        codec->width                  = par->width;\n        codec->height                 = par->height;\n        codec->field_order            = par->field_order;\n        codec->color_range            = par->color_range;\n        codec->color_primaries        = par->color_primaries;\n        codec->color_trc              = par->color_trc;\n        codec->colorspace             = par->color_space;\n        codec->chroma_sample_location = par->chroma_location;\n        codec->sample_aspect_ratio    = par->sample_aspect_ratio;\n        codec->has_b_frames           = par->video_delay;\n        break;\n    case AVMEDIA_TYPE_AUDIO:\n        codec->sample_fmt       = par->format;\n        codec->channel_layout   = par->channel_layout;\n        codec->channels         = par->channels;\n        codec->sample_rate      = par->sample_rate;\n        codec->block_align      = par->block_align;\n        codec->frame_size       = par->frame_size;\n        codec->delay            =\n        codec->initial_padding  = par->initial_padding;\n        codec->trailing_padding = par->trailing_padding;\n        codec->seek_preroll     = par->seek_preroll;\n        break;\n    case AVMEDIA_TYPE_SUBTITLE:\n        codec->width  = par->width;\n        codec->height = par->height;\n        break;\n    }\n\n    if (par->extradata) {\n        av_freep(&codec->extradata);\n        codec->extradata = av_mallocz(par->extradata_size + AV_INPUT_BUFFER_PADDING_SIZE);\n        if (!codec->extradata)\n            return AVERROR(ENOMEM);\n        memcpy(codec->extradata, par->extradata, par->extradata_size);\n        codec->extradata_size = par->extradata_size;\n    }\n\n    return 0;\n}\n\nint ff_alloc_a53_sei(const AVFrame *frame, size_t prefix_len,\n                     void **data, size_t *sei_size)\n{\n    AVFrameSideData *side_data = NULL;\n    uint8_t *sei_data;\n\n    if (frame)\n        side_data = av_frame_get_side_data(frame, AV_FRAME_DATA_A53_CC);\n\n    if (!side_data) {\n        *data = NULL;\n        return 0;\n    }\n\n    *sei_size = side_data->size + 11;\n    *data = av_mallocz(*sei_size + prefix_len);\n    if (!*data)\n        return AVERROR(ENOMEM);\n    sei_data = (uint8_t*)*data + prefix_len;\n\n    // country code\n    sei_data[0] = 181;\n    sei_data[1] = 0;\n    sei_data[2] = 49;\n\n    /**\n     * 'GA94' is standard in North America for ATSC, but hard coding\n     * this style may not be the right thing to do -- other formats\n     * do exist. This information is not available in the side_data\n     * so we are going with this right now.\n     */\n    AV_WL32(sei_data + 3, MKTAG('G', 'A', '9', '4'));\n    sei_data[7] = 3;\n    sei_data[8] = ((side_data->size/3) & 0x1f) | 0x40;\n    sei_data[9] = 0;\n\n    memcpy(sei_data + 10, side_data->data, side_data->size);\n\n    sei_data[side_data->size+10] = 255;\n\n    return 0;\n}\n"], "filenames": ["libavcodec/utils.c"], "buggy_code_start_loc": [378], "buggy_code_end_loc": [389], "fixing_code_start_loc": [379], "fixing_code_end_loc": [394], "type": "CWE-787", "message": "FFmpeg before 2017-01-24 has an out-of-bounds write caused by a heap-based buffer overflow related to the ipvideo_decode_block_opcode_0xA function in libavcodec/interplayvideo.c and the avcodec_align_dimensions2 function in libavcodec/utils.c.", "other": {"cve": {"id": "CVE-2017-7865", "sourceIdentifier": "cve@mitre.org", "published": "2017-04-14T04:59:00.587", "lastModified": "2019-03-05T17:00:27.387", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "FFmpeg before 2017-01-24 has an out-of-bounds write caused by a heap-based buffer overflow related to the ipvideo_decode_block_opcode_0xA function in libavcodec/interplayvideo.c and the avcodec_align_dimensions2 function in libavcodec/utils.c."}, {"lang": "es", "value": "FFmpeg en versiones anteriores a 24-01-2017 tiene una escritura fuera de l\u00edmites provocado por un desbordamiento de b\u00fafer basado en memoria din\u00e1mica en relaci\u00f3n con la funci\u00f3n ipvideo_decode_block_opcode_0xA en libavcodec/interplayvideo.c unad la funci\u00f3n avcodec_align_dimensions2 en libavcodec/utils.c."}], "metrics": {"cvssMetricV30": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "NETWORK", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 7.5}, "baseSeverity": "HIGH", "exploitabilityScore": 10.0, "impactScore": 6.4, "acInsufInfo": true, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-787"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:ffmpeg:ffmpeg:*:*:*:*:*:*:*:*", "versionEndIncluding": "2.8.9", "matchCriteriaId": "BB8F94CB-75BE-4D48-A4A6-4CE03A3D60B7"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}]}]}], "references": [{"url": "http://www.securityfocus.com/bid/97685", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=452", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://github.com/FFmpeg/FFmpeg/commit/2080bc33717955a0e4268e738acf8c1eeddbf8cb", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2019/02/msg00005.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/FFmpeg/FFmpeg/commit/2080bc33717955a0e4268e738acf8c1eeddbf8cb"}}
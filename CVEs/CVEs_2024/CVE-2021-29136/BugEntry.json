{"buggy_code": ["/*\n * umoci: Umoci Modifies Open Containers' Images\n * Copyright (C) 2016-2020 SUSE LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage layer\n\nimport (\n\t\"archive/tar\"\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/apex/log\"\n\tsecurejoin \"github.com/cyphar/filepath-securejoin\"\n\t\"github.com/opencontainers/umoci/pkg/fseval\"\n\t\"github.com/opencontainers/umoci/pkg/system\"\n\t\"github.com/opencontainers/umoci/third_party/shared\"\n\t\"github.com/pkg/errors\"\n\t\"golang.org/x/sys/unix\"\n)\n\n// inUserNamespace is a cached return value of shared.RunningInUserNS(). We\n// compute this once globally rather than for each unpack. It won't change (we\n// would hope) after we check it the first time.\nvar inUserNamespace = shared.RunningInUserNS()\n\n// TarExtractor represents a tar file to be extracted.\ntype TarExtractor struct {\n\t// mapOptions is the set of mapping options to use when extracting\n\t// filesystem layers.\n\tmapOptions MapOptions\n\n\t// partialRootless indicates whether \"partial rootless\" tricks should be\n\t// applied in our extraction. Rootless and userns execution have some\n\t// similar tricks necessary, but not all rootless tricks should be applied\n\t// when running in a userns -- hence the term \"partial rootless\" tricks.\n\tpartialRootless bool\n\n\t// fsEval is an fseval.FsEval used for extraction.\n\tfsEval fseval.FsEval\n\n\t// upperPaths are paths that have either been extracted in the execution of\n\t// this TarExtractor or are ancestors of paths extracted. The purpose of\n\t// having this stored in-memory is to be able to handle opaque whiteouts as\n\t// well as some other possible ordering issues with malformed archives (the\n\t// downside of this approach is that it takes up memory -- we could switch\n\t// to a trie if necessary). These paths are relative to the tar root but\n\t// are fully symlink-expanded so no need to worry about that line noise.\n\tupperPaths map[string]struct{}\n\n\t// enotsupWarned is a flag set when we encounter the first ENOTSUP error\n\t// dealing with xattrs. This is used to ensure extraction to a destination\n\t// file system that does not support xattrs raises a single warning, rather\n\t// than a warning for every file, which can amount to 1000s of messages that\n\t// scroll a terminal, and may obscure other more important warnings.\n\tenotsupWarned bool\n\n\t// keepDirlinks is the corresponding flag from the UnpackOptions\n\t// supplied when this TarExtractor was constructed.\n\tkeepDirlinks bool\n\n\t// whiteoutMode indicates how this TarExtractor will handle whiteouts.\n\twhiteoutMode WhiteoutMode\n}\n\n// NewTarExtractor creates a new TarExtractor.\nfunc NewTarExtractor(opt UnpackOptions) *TarExtractor {\n\tfsEval := fseval.Default\n\tif opt.MapOptions.Rootless {\n\t\tfsEval = fseval.Rootless\n\t}\n\n\treturn &TarExtractor{\n\t\tmapOptions:      opt.MapOptions,\n\t\tpartialRootless: opt.MapOptions.Rootless || inUserNamespace,\n\t\tfsEval:          fsEval,\n\t\tupperPaths:      make(map[string]struct{}),\n\t\tenotsupWarned:   false,\n\t\tkeepDirlinks:    opt.KeepDirlinks,\n\t\twhiteoutMode:    opt.WhiteoutMode,\n\t}\n}\n\n// restoreMetadata applies the state described in tar.Header to the filesystem\n// at the given path. No sanity checking is done of the tar.Header's pathname\n// or other information. In addition, no mapping is done of the header.\nfunc (te *TarExtractor) restoreMetadata(path string, hdr *tar.Header) error {\n\t// Some of the tar.Header fields don't match the OS API.\n\tfi := hdr.FileInfo()\n\n\t// Get the _actual_ file info to figure out if the path is a symlink.\n\tisSymlink := hdr.Typeflag == tar.TypeSymlink\n\tif realFi, err := te.fsEval.Lstat(path); err == nil {\n\t\tisSymlink = realFi.Mode()&os.ModeSymlink == os.ModeSymlink\n\t}\n\n\t// Apply the owner. If we are rootless then \"user.rootlesscontainers\" has\n\t// already been set up by unmapHeader, so nothing to do here.\n\tif !te.mapOptions.Rootless {\n\t\t// NOTE: This is not done through fsEval.\n\t\tif err := os.Lchown(path, hdr.Uid, hdr.Gid); err != nil {\n\t\t\treturn errors.Wrapf(err, \"restore chown metadata: %s\", path)\n\t\t}\n\t}\n\n\t// We cannot apply hdr.Mode to symlinks, because symlinks don't have a mode\n\t// of their own (they're special in that way). We have to apply this after\n\t// we've applied the owner because setuid bits are cleared when changing\n\t// owner (in rootless we don't care because we're always the owner).\n\tif !isSymlink {\n\t\tif err := te.fsEval.Chmod(path, fi.Mode()); err != nil {\n\t\t\treturn errors.Wrapf(err, \"restore chmod metadata: %s\", path)\n\t\t}\n\t}\n\n\t// Apply access and modified time. Note that some archives won't fill the\n\t// atime and mtime fields, so we have to set them to a more sane value.\n\t// Otherwise Linux will start screaming at us, and nobody wants that.\n\tmtime := hdr.ModTime\n\tif mtime.IsZero() {\n\t\t// XXX: Should we instead default to atime if it's non-zero?\n\t\tmtime = time.Now()\n\t}\n\tatime := hdr.AccessTime\n\tif atime.IsZero() {\n\t\t// Default to the mtime.\n\t\tatime = mtime\n\t}\n\n\t// Apply xattrs. In order to make sure that we *only* have the xattr set we\n\t// want, we first clear the set of xattrs from the file then apply the ones\n\t// set in the tar.Header.\n\terr := te.fsEval.Lclearxattrs(path, ignoreXattrs)\n\tif err != nil {\n\t\tif errors.Cause(err) != unix.ENOTSUP {\n\t\t\treturn errors.Wrapf(err, \"clear xattr metadata: %s\", path)\n\t\t}\n\t\tif !te.enotsupWarned {\n\t\t\tlog.Warnf(\"xattr{%s} ignoring ENOTSUP on clearxattrs\", path)\n\t\t\tlog.Warnf(\"xattr{%s} destination filesystem does not support xattrs, further warnings will be suppressed\", path)\n\t\t\tte.enotsupWarned = true\n\t\t} else {\n\t\t\tlog.Debugf(\"xattr{%s} ignoring ENOTSUP on clearxattrs\", path)\n\t\t}\n\t}\n\n\tfor name, value := range hdr.Xattrs {\n\t\tvalue := []byte(value)\n\n\t\t// Forbidden xattrs should never be touched.\n\t\tif _, skip := ignoreXattrs[name]; skip {\n\t\t\t// If the xattr is already set to the requested value, don't bail.\n\t\t\t// The reason for this logic is kinda convoluted, but effectively\n\t\t\t// because restoreMetadata is called with the *on-disk* metadata we\n\t\t\t// run the risk of things like \"security.selinux\" being included in\n\t\t\t// that metadata (and thus tripping the forbidden xattr error). By\n\t\t\t// only touching xattrs that have a different value we are somewhat\n\t\t\t// more efficient and we don't have to special case parent restore.\n\t\t\t// Of course this will only ever impact ignoreXattrs.\n\t\t\tif oldValue, err := te.fsEval.Lgetxattr(path, name); err == nil {\n\t\t\t\tif bytes.Equal(value, oldValue) {\n\t\t\t\t\tlog.Debugf(\"restore xattr metadata: skipping already-set xattr %q: %s\", name, hdr.Name)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\tlog.Warnf(\"xattr{%s} ignoring forbidden xattr: %q\", hdr.Name, name)\n\t\t\tcontinue\n\t\t}\n\t\tif err := te.fsEval.Lsetxattr(path, name, value, 0); err != nil {\n\t\t\t// In rootless mode, some xattrs will fail (security.capability).\n\t\t\t// This is _fine_ as long as we're not running as root (in which\n\t\t\t// case we shouldn't be ignoring xattrs that we were told to set).\n\t\t\t//\n\t\t\t// TODO: We should translate all security.capability capabilities\n\t\t\t//       into v3 capabilities, which allow us to write them as\n\t\t\t//       unprivileged users (we also would need to translate them\n\t\t\t//       back when creating archives).\n\t\t\tif te.partialRootless && os.IsPermission(errors.Cause(err)) {\n\t\t\t\tlog.Warnf(\"rootless{%s} ignoring (usually) harmless EPERM on setxattr %q\", hdr.Name, name)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// We cannot do much if we get an ENOTSUP -- this usually means\n\t\t\t// that extended attributes are simply unsupported by the\n\t\t\t// underlying filesystem (such as AUFS or NFS).\n\t\t\tif errors.Cause(err) == unix.ENOTSUP {\n\t\t\t\tif !te.enotsupWarned {\n\t\t\t\t\tlog.Warnf(\"xattr{%s} ignoring ENOTSUP on setxattr %q\", hdr.Name, name)\n\t\t\t\t\tlog.Warnf(\"xattr{%s} destination filesystem does not support xattrs, further warnings will be suppressed\", path)\n\t\t\t\t\tte.enotsupWarned = true\n\t\t\t\t} else {\n\t\t\t\t\tlog.Debugf(\"xattr{%s} ignoring ENOTSUP on clearxattrs\", path)\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn errors.Wrapf(err, \"restore xattr metadata: %s\", path)\n\t\t}\n\t}\n\n\tif err := te.fsEval.Lutimes(path, atime, mtime); err != nil {\n\t\treturn errors.Wrapf(err, \"restore lutimes metadata: %s\", path)\n\t}\n\n\treturn nil\n}\n\n// applyMetadata applies the state described in tar.Header to the filesystem at\n// the given path, using the state of the TarExtractor to remap information\n// within the header. This should only be used with headers from a tar layer\n// (not from the filesystem). No sanity checking is done of the tar.Header's\n// pathname or other information.\nfunc (te *TarExtractor) applyMetadata(path string, hdr *tar.Header) error {\n\t// Modify the header.\n\tif err := unmapHeader(hdr, te.mapOptions); err != nil {\n\t\treturn errors.Wrap(err, \"unmap header\")\n\t}\n\n\t// Restore it on the filesystme.\n\treturn te.restoreMetadata(path, hdr)\n}\n\n// isDirlink returns whether the given path is a link to a directory (or a\n// dirlink in rsync(1) parlance) which is used by --keep-dirlink to see whether\n// we should extract through the link or clobber the link with a directory (in\n// the case where we see a directory to extract and a symlink already exists\n// there).\nfunc (te *TarExtractor) isDirlink(root string, path string) (bool, error) {\n\t// Make sure it exists and is a symlink.\n\tif _, err := te.fsEval.Readlink(path); err != nil {\n\t\treturn false, errors.Wrap(err, \"read dirlink\")\n\t}\n\n\t// Technically a string.TrimPrefix would also work...\n\tunsafePath, err := filepath.Rel(root, path)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"get relative-to-root path\")\n\t}\n\n\t// It should be noted that SecureJoin will evaluate all symlinks in the\n\t// path, so we don't need to loop over it or anything like that. It'll just\n\t// be done for us (in UnpackEntry only the dirname(3) is evaluated but here\n\t// we evaluate the whole thing).\n\ttargetPath, err := securejoin.SecureJoinVFS(root, unsafePath, te.fsEval)\n\tif err != nil {\n\t\t// We hit a symlink loop -- which is fine but that means that this\n\t\t// cannot be considered a dirlink.\n\t\tif errno := InnerErrno(err); errno == unix.ELOOP {\n\t\t\terr = nil\n\t\t}\n\t\treturn false, errors.Wrap(err, \"sanitize old target\")\n\t}\n\n\ttargetInfo, err := te.fsEval.Lstat(targetPath)\n\tif err != nil {\n\t\t// ENOENT or similar just means that it's a broken symlink, which\n\t\t// means we have to overwrite it (but it's an allowed case).\n\t\tif securejoin.IsNotExist(err) {\n\t\t\terr = nil\n\t\t}\n\t\treturn false, err\n\t}\n\n\treturn targetInfo.IsDir(), nil\n}\n\nfunc (te *TarExtractor) ociWhiteout(root string, dir string, file string) error {\n\tisOpaque := file == whOpaque\n\tfile = strings.TrimPrefix(file, whPrefix)\n\n\t// We have to be quite careful here. While the most intuitive way of\n\t// handling whiteouts would be to just RemoveAll without prejudice, We\n\t// have to be careful here. If there is a whiteout entry for a file\n\t// *after* a normal entry (in the same layer) then the whiteout must\n\t// not remove the new entry. We handle this by keeping track of\n\t// whichpaths have been touched by this layer's extraction (these form\n\t// the \"upperdir\"). We also have to handle cases where a directory has\n\t// been marked for deletion, but a child has been extracted in this\n\t// layer.\n\n\tpath := filepath.Join(dir, file)\n\tif isOpaque {\n\t\tpath = dir\n\t}\n\n\t// If the root doesn't exist we've got nothing to do.\n\t// XXX: We currently cannot error out if a layer asks us to remove a\n\t//      non-existent path with this implementation (because we don't\n\t//      know if it was implicitly removed by another whiteout). In\n\t//      future we could add lowerPaths that would help track whether\n\t//      another whiteout caused the removal to \"fail\" or if the path\n\t//      was actually missing -- which would allow us to actually error\n\t//      out here if the layer is invalid).\n\tif _, err := te.fsEval.Lstat(path); err != nil {\n\t\t// Need to use securejoin.IsNotExist to handle ENOTDIR.\n\t\tif securejoin.IsNotExist(err) {\n\t\t\terr = nil\n\t\t}\n\t\treturn errors.Wrap(err, \"check whiteout target\")\n\t}\n\n\t// Walk over the path to remove it. We remove a given path as soon as\n\t// it isn't present in upperPaths (which includes ancestors of paths\n\t// we've extracted so we only need to look up the one path). Otherwise\n\t// we iterate over any children and try again. The only difference\n\t// between opaque whiteouts and regular whiteouts is that we don't\n\t// delete the directory itself with opaque whiteouts.\n\terr := te.fsEval.Walk(path, func(subpath string, info os.FileInfo, err error) error {\n\t\t// If we are passed an error, bail unless it's ENOENT.\n\t\tif err != nil {\n\t\t\t// If something was deleted outside of our knowledge it's not\n\t\t\t// the end of the world. In principle this shouldn't happen\n\t\t\t// though, so we log it for posterity.\n\t\t\tif os.IsNotExist(errors.Cause(err)) {\n\t\t\t\tlog.Debugf(\"whiteout removal hit already-deleted path: %s\", subpath)\n\t\t\t\terr = filepath.SkipDir\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\n\t\t// Get the relative form of subpath to root to match\n\t\t// te.upperPaths.\n\t\tupperPath, err := filepath.Rel(root, subpath)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"find relative-to-root [should never happen]\")\n\t\t}\n\n\t\t// Remove the path only if it hasn't been touched.\n\t\tif _, ok := te.upperPaths[upperPath]; !ok {\n\t\t\t// Opaque whiteouts don't remove the directory itself, so skip\n\t\t\t// the top-level directory.\n\t\t\tif isOpaque && CleanPath(path) == CleanPath(subpath) {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// Purge the path. We skip anything underneath (if it's a\n\t\t\t// directory) since we just purged it -- and we don't want to\n\t\t\t// hit ENOENT during iteration for no good reason.\n\t\t\terr := errors.Wrap(te.fsEval.RemoveAll(subpath), \"whiteout subpath\")\n\t\t\tif err == nil && info.IsDir() {\n\t\t\t\terr = filepath.SkipDir\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n\treturn errors.Wrap(err, \"whiteout remove\")\n}\n\nfunc (te *TarExtractor) overlayFSWhiteout(dir string, file string) error {\n\tisOpaque := file == whOpaque\n\n\t// if this is an opaque whiteout, whiteout the directory\n\tif isOpaque {\n\t\terr := te.fsEval.Lsetxattr(dir, \"trusted.overlay.opaque\", []byte(\"y\"), 0)\n\t\treturn errors.Wrapf(err, \"couldn't set overlayfs whiteout attr for %s\", dir)\n\t}\n\n\t// otherwise, white out the file itself.\n\tp := filepath.Join(dir, strings.TrimPrefix(file, whPrefix))\n\tif err := os.RemoveAll(p); err != nil && !os.IsNotExist(err) {\n\t\treturn errors.Wrapf(err, \"couldn't create overlayfs whiteout for %s\", p)\n\t}\n\n\terr := te.fsEval.Mknod(p, unix.S_IFCHR|0666, unix.Mkdev(0, 0))\n\treturn errors.Wrapf(err, \"couldn't create overlayfs whiteout for %s\", p)\n}\n\n// UnpackEntry extracts the given tar.Header to the provided root, ensuring\n// that the layer state is consistent with the layer state that produced the\n// tar archive being iterated over. This does handle whiteouts, so a tar.Header\n// that represents a whiteout will result in the path being removed.\nfunc (te *TarExtractor) UnpackEntry(root string, hdr *tar.Header, r io.Reader) (Err error) {\n\t// Make the paths safe.\n\thdr.Name = CleanPath(hdr.Name)\n\troot = filepath.Clean(root)\n\n\tlog.WithFields(log.Fields{\n\t\t\"root\": root,\n\t\t\"path\": hdr.Name,\n\t\t\"type\": hdr.Typeflag,\n\t}).Debugf(\"unpacking entry\")\n\n\t// Get directory and filename, but we have to safely get the directory\n\t// component of the path. SecureJoinVFS will evaluate the path itself,\n\t// which we don't want (we're clever enough to handle the actual path being\n\t// a symlink).\n\tunsafeDir, file := filepath.Split(hdr.Name)\n\tif filepath.Join(\"/\", hdr.Name) == \"/\" {\n\t\t// If we got an entry for the root, then unsafeDir is the full path.\n\t\tunsafeDir, file = hdr.Name, \".\"\n\t}\n\tdir, err := securejoin.SecureJoinVFS(root, unsafeDir, te.fsEval)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"sanitise symlinks in root\")\n\t}\n\tpath := filepath.Join(dir, file)\n\n\t// Before we do anything, get the state of dir. Because we might be adding\n\t// or removing files, our parent directory might be modified in the\n\t// process. As a result, we want to be able to restore the old state\n\t// (because we only apply state that we find in the archive we're iterating\n\t// over). We can safely ignore an error here, because a non-existent\n\t// directory will be fixed by later archive entries.\n\tif dirFi, err := te.fsEval.Lstat(dir); err == nil && path != dir {\n\t\t// FIXME: This is really stupid.\n\t\t// #nosec G104\n\t\tlink, _ := te.fsEval.Readlink(dir)\n\t\tdirHdr, err := tar.FileInfoHeader(dirFi, link)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"convert dirFi to dirHdr\")\n\t\t}\n\n\t\t// More faking to trick restoreMetadata to actually restore the directory.\n\t\tdirHdr.Typeflag = tar.TypeDir\n\t\tdirHdr.Linkname = \"\"\n\n\t\t// os.Lstat doesn't get the list of xattrs by default. We need to fill\n\t\t// this explicitly. Note that while Go's \"archive/tar\" takes strings,\n\t\t// in Go strings can be arbitrary byte sequences so this doesn't\n\t\t// restrict the possible values.\n\t\t// TODO: Move this to a separate function so we can share it with\n\t\t//       tar_generate.go.\n\t\txattrs, err := te.fsEval.Llistxattr(dir)\n\t\tif err != nil {\n\t\t\tif errors.Cause(err) != unix.ENOTSUP {\n\t\t\t\treturn errors.Wrap(err, \"get dirHdr.Xattrs\")\n\t\t\t}\n\t\t\tif !te.enotsupWarned {\n\t\t\t\tlog.Warnf(\"xattr{%s} ignoring ENOTSUP on llistxattr\", dir)\n\t\t\t\tlog.Warnf(\"xattr{%s} destination filesystem does not support xattrs, further warnings will be suppressed\", path)\n\t\t\t\tte.enotsupWarned = true\n\t\t\t} else {\n\t\t\t\tlog.Debugf(\"xattr{%s} ignoring ENOTSUP on clearxattrs\", path)\n\t\t\t}\n\t\t}\n\t\tif len(xattrs) > 0 {\n\t\t\tdirHdr.Xattrs = map[string]string{}\n\t\t\tfor _, xattr := range xattrs {\n\t\t\t\tvalue, err := te.fsEval.Lgetxattr(dir, xattr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn errors.Wrap(err, \"get xattr\")\n\t\t\t\t}\n\t\t\t\tdirHdr.Xattrs[xattr] = string(value)\n\t\t\t}\n\t\t}\n\n\t\t// Ensure that after everything we correctly re-apply the old metadata.\n\t\t// We don't map this header because we're restoring files that already\n\t\t// existed on the filesystem, not from a tar layer.\n\t\tdefer func() {\n\t\t\t// Only overwrite the error if there wasn't one already.\n\t\t\tif err := te.restoreMetadata(dir, dirHdr); err != nil {\n\t\t\t\tif Err == nil {\n\t\t\t\t\tErr = errors.Wrap(err, \"restore parent directory\")\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\t// Currently the spec doesn't specify what the hdr.Typeflag of whiteout\n\t// files is meant to be. We specifically only produce regular files\n\t// ('\\x00') but it could be possible that someone produces a different\n\t// Typeflag, expecting that the path is the only thing that matters in a\n\t// whiteout entry.\n\tif strings.HasPrefix(file, whPrefix) {\n\t\tswitch te.whiteoutMode {\n\t\tcase OCIStandardWhiteout:\n\t\t\treturn te.ociWhiteout(root, dir, file)\n\t\tcase OverlayFSWhiteout:\n\t\t\treturn te.overlayFSWhiteout(dir, file)\n\t\tdefault:\n\t\t\treturn errors.Errorf(\"unknown whiteout mode %d\", te.whiteoutMode)\n\t\t}\n\t}\n\n\t// Get information about the path. This has to be done after we've dealt\n\t// with whiteouts because it turns out that lstat(2) will return EPERM if\n\t// you try to stat a whiteout on AUFS.\n\tfi, err := te.fsEval.Lstat(path)\n\tif err != nil {\n\t\t// File doesn't exist, just switch fi to the file header.\n\t\tfi = hdr.FileInfo()\n\t}\n\n\t// Attempt to create the parent directory of the path we're unpacking.\n\t// We do a MkdirAll here because even though you need to have a tar entry\n\t// for every component of a new path, applyMetadata will correct any\n\t// inconsistencies.\n\t// FIXME: We have to make this consistent, since if the tar archive doesn't\n\t//        have entries for some of these components we won't be able to\n\t//        verify that we have consistent results during unpacking.\n\tif err := te.fsEval.MkdirAll(dir, 0777); err != nil {\n\t\treturn errors.Wrap(err, \"mkdir parent\")\n\t}\n\n\tisDirlink := false\n\t// We remove whatever existed at the old path to clobber it so that\n\t// creating a new path will not break. The only exception is if the path is\n\t// a directory in both the layer and the current filesystem, in which case\n\t// we don't delete it for obvious reasons. In all other cases we clobber.\n\t//\n\t// Note that this will cause hard-links in the \"lower\" layer to not be able\n\t// to point to \"upper\" layer inodes even if the extracted type is the same\n\t// as the old one, however it is not clear whether this is something a user\n\t// would expect anyway. In addition, this will incorrectly deal with a\n\t// TarLink that is present before the \"upper\" entry in the layer but the\n\t// \"lower\" file still exists (so the hard-link would point to the old\n\t// inode). It's not clear if such an archive is actually valid though.\n\tif !fi.IsDir() || hdr.Typeflag != tar.TypeDir {\n\t\t// If we are in --keep-dirlinks mode and the existing fs object is a\n\t\t// symlink to a directory (with the pending object is a directory), we\n\t\t// don't remove the symlink (and instead allow subsequent objects to be\n\t\t// just written through the symlink into the directory). This is a very\n\t\t// specific usecase where layers that were generated independently from\n\t\t// each other (on different base filesystems) end up with weird things\n\t\t// like /lib64 being a symlink only sometimes but you never want to\n\t\t// delete libraries (not just the ones that were under the \"real\"\n\t\t// directory).\n\t\t//\n\t\t// TODO: This code should also handle a pending symlink entry where the\n\t\t//       existing object is a directory. I'm not sure how we could\n\t\t//       disambiguate this from a symlink-to-a-file but I imagine that\n\t\t//       this is something that would also be useful in the same vein\n\t\t//       as --keep-dirlinks (which currently only prevents clobbering\n\t\t//       in the opposite case).\n\t\tif te.keepDirlinks &&\n\t\t\tfi.Mode()&os.ModeSymlink == os.ModeSymlink && hdr.Typeflag == tar.TypeDir {\n\t\t\tisDirlink, err = te.isDirlink(root, path)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"check is dirlink\")\n\t\t\t}\n\t\t}\n\t\tif !(isDirlink && te.keepDirlinks) {\n\t\t\tif err := te.fsEval.RemoveAll(path); err != nil {\n\t\t\t\treturn errors.Wrap(err, \"clobber old path\")\n\t\t\t}\n\t\t}\n\t}\n\n\t// Now create or otherwise modify the state of the path. Right now, either\n\t// the type of path matches hdr or the path doesn't exist. Note that we\n\t// don't care about umasks or the initial mode here, since applyMetadata\n\t// will fix all of that for us.\n\tswitch hdr.Typeflag {\n\t// regular file\n\tcase tar.TypeReg, tar.TypeRegA:\n\t\t// Create a new file, then just copy the data.\n\t\tfh, err := te.fsEval.Create(path)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"create regular\")\n\t\t}\n\t\tdefer fh.Close()\n\n\t\t// We need to make sure that we copy all of the bytes.\n\t\tn, err := io.Copy(fh, r)\n\t\tif int64(n) != hdr.Size {\n\t\t\tif err != nil {\n\t\t\t\terr = errors.Wrapf(err, \"short write\")\n\t\t\t} else {\n\t\t\t\terr = io.ErrShortWrite\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"unpack to regular file\")\n\t\t}\n\n\t\t// Force close here so that we don't affect the metadata.\n\t\tif err := fh.Close(); err != nil {\n\t\t\treturn errors.Wrap(err, \"close unpacked regular file\")\n\t\t}\n\n\t// directory\n\tcase tar.TypeDir:\n\t\tif isDirlink {\n\t\t\tbreak\n\t\t}\n\n\t\t// Attempt to create the directory. We do a MkdirAll here because even\n\t\t// though you need to have a tar entry for every component of a new\n\t\t// path, applyMetadata will correct any inconsistencies.\n\t\tif err := te.fsEval.MkdirAll(path, 0777); err != nil {\n\t\t\treturn errors.Wrap(err, \"mkdirall\")\n\t\t}\n\n\t// hard link, symbolic link\n\tcase tar.TypeLink, tar.TypeSymlink:\n\t\tlinkname := hdr.Linkname\n\n\t\t// Hardlinks and symlinks act differently when it comes to the scoping.\n\t\t// In both cases, we have to just unlink and then re-link the given\n\t\t// path. But the function used and the argument are slightly different.\n\t\tvar linkFn func(string, string) error\n\t\tswitch hdr.Typeflag {\n\t\tcase tar.TypeLink:\n\t\t\tlinkFn = te.fsEval.Link\n\t\t\t// Because hardlinks are inode-based we need to scope the link to\n\t\t\t// the rootfs using SecureJoinVFS. As before, we need to be careful\n\t\t\t// that we don't resolve the last part of the link path (in case\n\t\t\t// the user actually wanted to hardlink to a symlink).\n\t\t\tunsafeLinkDir, linkFile := filepath.Split(CleanPath(linkname))\n\t\t\tlinkDir, err := securejoin.SecureJoinVFS(root, unsafeLinkDir, te.fsEval)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"sanitise hardlink target in root\")\n\t\t\t}\n\t\t\tlinkname = filepath.Join(linkDir, linkFile)\n\t\tcase tar.TypeSymlink:\n\t\t\tlinkFn = te.fsEval.Symlink\n\t\t}\n\n\t\t// Link the new one.\n\t\tif err := linkFn(linkname, path); err != nil {\n\t\t\t// FIXME: Currently this can break if tar hardlink entries occur\n\t\t\t//        before we hit the entry those hardlinks link to. I have a\n\t\t\t//        feeling that such archives are invalid, but the correct\n\t\t\t//        way of handling this is to delay link creation until the\n\t\t\t//        very end. Unfortunately this won't work with symlinks\n\t\t\t//        (which can link to directories).\n\t\t\treturn errors.Wrap(err, \"link\")\n\t\t}\n\n\t// character device node, block device node\n\tcase tar.TypeChar, tar.TypeBlock:\n\t\t// In rootless mode we have no choice but to fake this, since mknod(2)\n\t\t// doesn't work as an unprivileged user here.\n\t\t//\n\t\t// TODO: We need to add the concept of a fake block device in\n\t\t//       \"user.rootlesscontainers\", because this workaround suffers\n\t\t//       from the obvious issue that if the file is touched (even the\n\t\t//       metadata) then it will be incorrectly copied into the layer.\n\t\t//       This would break distribution images fairly badly.\n\t\tif te.partialRootless {\n\t\t\tlog.Warnf(\"rootless{%s} creating empty file in place of device %d:%d\", hdr.Name, hdr.Devmajor, hdr.Devminor)\n\t\t\tfh, err := te.fsEval.Create(path)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"create rootless block\")\n\t\t\t}\n\t\t\tdefer fh.Close()\n\t\t\tif err := fh.Chmod(0); err != nil {\n\t\t\t\treturn errors.Wrap(err, \"chmod 0 rootless block\")\n\t\t\t}\n\t\t\tgoto out\n\t\t}\n\n\t\t// Otherwise the handling is the same as a FIFO.\n\t\tfallthrough\n\t// fifo node\n\tcase tar.TypeFifo:\n\t\t// We have to remove and then create the device. In the FIFO case we\n\t\t// could choose not to do so, but we do it anyway just to be on the\n\t\t// safe side.\n\n\t\tmode := system.Tarmode(hdr.Typeflag)\n\t\tdev := unix.Mkdev(uint32(hdr.Devmajor), uint32(hdr.Devminor))\n\n\t\t// Create the node.\n\t\tif err := te.fsEval.Mknod(path, os.FileMode(int64(mode)|hdr.Mode), dev); err != nil {\n\t\t\treturn errors.Wrap(err, \"mknod\")\n\t\t}\n\n\t// We should never hit any other headers (Go abstracts them away from us),\n\t// and we can't handle any custom Tar extensions. So just error out.\n\tdefault:\n\t\treturn fmt.Errorf(\"unpack entry: %s: unknown typeflag '\\\\x%x'\", hdr.Name, hdr.Typeflag)\n\t}\n\nout:\n\t// Apply the metadata, which will apply any mappings necessary. We don't\n\t// apply metadata for hardlinks, because hardlinks don't have any separate\n\t// metadata from their link (and the tar headers might not be filled).\n\tif hdr.Typeflag != tar.TypeLink {\n\t\tif err := te.applyMetadata(path, hdr); err != nil {\n\t\t\treturn errors.Wrap(err, \"apply hdr metadata\")\n\t\t}\n\t}\n\n\t// Everything is done -- the path now exists. Add it (and all its\n\t// ancestors) to the set of upper paths. We first have to figure out the\n\t// proper path corresponding to hdr.Name though.\n\tupperPath, err := filepath.Rel(root, path)\n\tif err != nil {\n\t\t// Really shouldn't happen because of the guarantees of SecureJoinVFS.\n\t\treturn errors.Wrap(err, \"find relative-to-root [should never happen]\")\n\t}\n\tfor pth := upperPath; pth != filepath.Dir(pth); pth = filepath.Dir(pth) {\n\t\tte.upperPaths[pth] = struct{}{}\n\t}\n\treturn nil\n}\n"], "fixing_code": ["/*\n * umoci: Umoci Modifies Open Containers' Images\n * Copyright (C) 2016-2020 SUSE LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage layer\n\nimport (\n\t\"archive/tar\"\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/apex/log\"\n\tsecurejoin \"github.com/cyphar/filepath-securejoin\"\n\t\"github.com/opencontainers/umoci/pkg/fseval\"\n\t\"github.com/opencontainers/umoci/pkg/system\"\n\t\"github.com/opencontainers/umoci/third_party/shared\"\n\t\"github.com/pkg/errors\"\n\t\"golang.org/x/sys/unix\"\n)\n\n// inUserNamespace is a cached return value of shared.RunningInUserNS(). We\n// compute this once globally rather than for each unpack. It won't change (we\n// would hope) after we check it the first time.\nvar inUserNamespace = shared.RunningInUserNS()\n\n// TarExtractor represents a tar file to be extracted.\ntype TarExtractor struct {\n\t// mapOptions is the set of mapping options to use when extracting\n\t// filesystem layers.\n\tmapOptions MapOptions\n\n\t// partialRootless indicates whether \"partial rootless\" tricks should be\n\t// applied in our extraction. Rootless and userns execution have some\n\t// similar tricks necessary, but not all rootless tricks should be applied\n\t// when running in a userns -- hence the term \"partial rootless\" tricks.\n\tpartialRootless bool\n\n\t// fsEval is an fseval.FsEval used for extraction.\n\tfsEval fseval.FsEval\n\n\t// upperPaths are paths that have either been extracted in the execution of\n\t// this TarExtractor or are ancestors of paths extracted. The purpose of\n\t// having this stored in-memory is to be able to handle opaque whiteouts as\n\t// well as some other possible ordering issues with malformed archives (the\n\t// downside of this approach is that it takes up memory -- we could switch\n\t// to a trie if necessary). These paths are relative to the tar root but\n\t// are fully symlink-expanded so no need to worry about that line noise.\n\tupperPaths map[string]struct{}\n\n\t// enotsupWarned is a flag set when we encounter the first ENOTSUP error\n\t// dealing with xattrs. This is used to ensure extraction to a destination\n\t// file system that does not support xattrs raises a single warning, rather\n\t// than a warning for every file, which can amount to 1000s of messages that\n\t// scroll a terminal, and may obscure other more important warnings.\n\tenotsupWarned bool\n\n\t// keepDirlinks is the corresponding flag from the UnpackOptions\n\t// supplied when this TarExtractor was constructed.\n\tkeepDirlinks bool\n\n\t// whiteoutMode indicates how this TarExtractor will handle whiteouts.\n\twhiteoutMode WhiteoutMode\n}\n\n// NewTarExtractor creates a new TarExtractor.\nfunc NewTarExtractor(opt UnpackOptions) *TarExtractor {\n\tfsEval := fseval.Default\n\tif opt.MapOptions.Rootless {\n\t\tfsEval = fseval.Rootless\n\t}\n\n\treturn &TarExtractor{\n\t\tmapOptions:      opt.MapOptions,\n\t\tpartialRootless: opt.MapOptions.Rootless || inUserNamespace,\n\t\tfsEval:          fsEval,\n\t\tupperPaths:      make(map[string]struct{}),\n\t\tenotsupWarned:   false,\n\t\tkeepDirlinks:    opt.KeepDirlinks,\n\t\twhiteoutMode:    opt.WhiteoutMode,\n\t}\n}\n\n// restoreMetadata applies the state described in tar.Header to the filesystem\n// at the given path. No sanity checking is done of the tar.Header's pathname\n// or other information. In addition, no mapping is done of the header.\nfunc (te *TarExtractor) restoreMetadata(path string, hdr *tar.Header) error {\n\t// Some of the tar.Header fields don't match the OS API.\n\tfi := hdr.FileInfo()\n\n\t// Get the _actual_ file info to figure out if the path is a symlink.\n\tisSymlink := hdr.Typeflag == tar.TypeSymlink\n\tif realFi, err := te.fsEval.Lstat(path); err == nil {\n\t\tisSymlink = realFi.Mode()&os.ModeSymlink == os.ModeSymlink\n\t}\n\n\t// Apply the owner. If we are rootless then \"user.rootlesscontainers\" has\n\t// already been set up by unmapHeader, so nothing to do here.\n\tif !te.mapOptions.Rootless {\n\t\t// NOTE: This is not done through fsEval.\n\t\tif err := os.Lchown(path, hdr.Uid, hdr.Gid); err != nil {\n\t\t\treturn errors.Wrapf(err, \"restore chown metadata: %s\", path)\n\t\t}\n\t}\n\n\t// We cannot apply hdr.Mode to symlinks, because symlinks don't have a mode\n\t// of their own (they're special in that way). We have to apply this after\n\t// we've applied the owner because setuid bits are cleared when changing\n\t// owner (in rootless we don't care because we're always the owner).\n\tif !isSymlink {\n\t\tif err := te.fsEval.Chmod(path, fi.Mode()); err != nil {\n\t\t\treturn errors.Wrapf(err, \"restore chmod metadata: %s\", path)\n\t\t}\n\t}\n\n\t// Apply access and modified time. Note that some archives won't fill the\n\t// atime and mtime fields, so we have to set them to a more sane value.\n\t// Otherwise Linux will start screaming at us, and nobody wants that.\n\tmtime := hdr.ModTime\n\tif mtime.IsZero() {\n\t\t// XXX: Should we instead default to atime if it's non-zero?\n\t\tmtime = time.Now()\n\t}\n\tatime := hdr.AccessTime\n\tif atime.IsZero() {\n\t\t// Default to the mtime.\n\t\tatime = mtime\n\t}\n\n\t// Apply xattrs. In order to make sure that we *only* have the xattr set we\n\t// want, we first clear the set of xattrs from the file then apply the ones\n\t// set in the tar.Header.\n\terr := te.fsEval.Lclearxattrs(path, ignoreXattrs)\n\tif err != nil {\n\t\tif errors.Cause(err) != unix.ENOTSUP {\n\t\t\treturn errors.Wrapf(err, \"clear xattr metadata: %s\", path)\n\t\t}\n\t\tif !te.enotsupWarned {\n\t\t\tlog.Warnf(\"xattr{%s} ignoring ENOTSUP on clearxattrs\", path)\n\t\t\tlog.Warnf(\"xattr{%s} destination filesystem does not support xattrs, further warnings will be suppressed\", path)\n\t\t\tte.enotsupWarned = true\n\t\t} else {\n\t\t\tlog.Debugf(\"xattr{%s} ignoring ENOTSUP on clearxattrs\", path)\n\t\t}\n\t}\n\n\tfor name, value := range hdr.Xattrs {\n\t\tvalue := []byte(value)\n\n\t\t// Forbidden xattrs should never be touched.\n\t\tif _, skip := ignoreXattrs[name]; skip {\n\t\t\t// If the xattr is already set to the requested value, don't bail.\n\t\t\t// The reason for this logic is kinda convoluted, but effectively\n\t\t\t// because restoreMetadata is called with the *on-disk* metadata we\n\t\t\t// run the risk of things like \"security.selinux\" being included in\n\t\t\t// that metadata (and thus tripping the forbidden xattr error). By\n\t\t\t// only touching xattrs that have a different value we are somewhat\n\t\t\t// more efficient and we don't have to special case parent restore.\n\t\t\t// Of course this will only ever impact ignoreXattrs.\n\t\t\tif oldValue, err := te.fsEval.Lgetxattr(path, name); err == nil {\n\t\t\t\tif bytes.Equal(value, oldValue) {\n\t\t\t\t\tlog.Debugf(\"restore xattr metadata: skipping already-set xattr %q: %s\", name, hdr.Name)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\tlog.Warnf(\"xattr{%s} ignoring forbidden xattr: %q\", hdr.Name, name)\n\t\t\tcontinue\n\t\t}\n\t\tif err := te.fsEval.Lsetxattr(path, name, value, 0); err != nil {\n\t\t\t// In rootless mode, some xattrs will fail (security.capability).\n\t\t\t// This is _fine_ as long as we're not running as root (in which\n\t\t\t// case we shouldn't be ignoring xattrs that we were told to set).\n\t\t\t//\n\t\t\t// TODO: We should translate all security.capability capabilities\n\t\t\t//       into v3 capabilities, which allow us to write them as\n\t\t\t//       unprivileged users (we also would need to translate them\n\t\t\t//       back when creating archives).\n\t\t\tif te.partialRootless && os.IsPermission(errors.Cause(err)) {\n\t\t\t\tlog.Warnf(\"rootless{%s} ignoring (usually) harmless EPERM on setxattr %q\", hdr.Name, name)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// We cannot do much if we get an ENOTSUP -- this usually means\n\t\t\t// that extended attributes are simply unsupported by the\n\t\t\t// underlying filesystem (such as AUFS or NFS).\n\t\t\tif errors.Cause(err) == unix.ENOTSUP {\n\t\t\t\tif !te.enotsupWarned {\n\t\t\t\t\tlog.Warnf(\"xattr{%s} ignoring ENOTSUP on setxattr %q\", hdr.Name, name)\n\t\t\t\t\tlog.Warnf(\"xattr{%s} destination filesystem does not support xattrs, further warnings will be suppressed\", path)\n\t\t\t\t\tte.enotsupWarned = true\n\t\t\t\t} else {\n\t\t\t\t\tlog.Debugf(\"xattr{%s} ignoring ENOTSUP on clearxattrs\", path)\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn errors.Wrapf(err, \"restore xattr metadata: %s\", path)\n\t\t}\n\t}\n\n\tif err := te.fsEval.Lutimes(path, atime, mtime); err != nil {\n\t\treturn errors.Wrapf(err, \"restore lutimes metadata: %s\", path)\n\t}\n\n\treturn nil\n}\n\n// applyMetadata applies the state described in tar.Header to the filesystem at\n// the given path, using the state of the TarExtractor to remap information\n// within the header. This should only be used with headers from a tar layer\n// (not from the filesystem). No sanity checking is done of the tar.Header's\n// pathname or other information.\nfunc (te *TarExtractor) applyMetadata(path string, hdr *tar.Header) error {\n\t// Modify the header.\n\tif err := unmapHeader(hdr, te.mapOptions); err != nil {\n\t\treturn errors.Wrap(err, \"unmap header\")\n\t}\n\n\t// Restore it on the filesystme.\n\treturn te.restoreMetadata(path, hdr)\n}\n\n// isDirlink returns whether the given path is a link to a directory (or a\n// dirlink in rsync(1) parlance) which is used by --keep-dirlink to see whether\n// we should extract through the link or clobber the link with a directory (in\n// the case where we see a directory to extract and a symlink already exists\n// there).\nfunc (te *TarExtractor) isDirlink(root string, path string) (bool, error) {\n\t// Make sure it exists and is a symlink.\n\tif _, err := te.fsEval.Readlink(path); err != nil {\n\t\treturn false, errors.Wrap(err, \"read dirlink\")\n\t}\n\n\t// Technically a string.TrimPrefix would also work...\n\tunsafePath, err := filepath.Rel(root, path)\n\tif err != nil {\n\t\treturn false, errors.Wrap(err, \"get relative-to-root path\")\n\t}\n\n\t// It should be noted that SecureJoin will evaluate all symlinks in the\n\t// path, so we don't need to loop over it or anything like that. It'll just\n\t// be done for us (in UnpackEntry only the dirname(3) is evaluated but here\n\t// we evaluate the whole thing).\n\ttargetPath, err := securejoin.SecureJoinVFS(root, unsafePath, te.fsEval)\n\tif err != nil {\n\t\t// We hit a symlink loop -- which is fine but that means that this\n\t\t// cannot be considered a dirlink.\n\t\tif errno := InnerErrno(err); errno == unix.ELOOP {\n\t\t\terr = nil\n\t\t}\n\t\treturn false, errors.Wrap(err, \"sanitize old target\")\n\t}\n\n\ttargetInfo, err := te.fsEval.Lstat(targetPath)\n\tif err != nil {\n\t\t// ENOENT or similar just means that it's a broken symlink, which\n\t\t// means we have to overwrite it (but it's an allowed case).\n\t\tif securejoin.IsNotExist(err) {\n\t\t\terr = nil\n\t\t}\n\t\treturn false, err\n\t}\n\n\treturn targetInfo.IsDir(), nil\n}\n\nfunc (te *TarExtractor) ociWhiteout(root string, dir string, file string) error {\n\tisOpaque := file == whOpaque\n\tfile = strings.TrimPrefix(file, whPrefix)\n\n\t// We have to be quite careful here. While the most intuitive way of\n\t// handling whiteouts would be to just RemoveAll without prejudice, We\n\t// have to be careful here. If there is a whiteout entry for a file\n\t// *after* a normal entry (in the same layer) then the whiteout must\n\t// not remove the new entry. We handle this by keeping track of\n\t// whichpaths have been touched by this layer's extraction (these form\n\t// the \"upperdir\"). We also have to handle cases where a directory has\n\t// been marked for deletion, but a child has been extracted in this\n\t// layer.\n\n\tpath := filepath.Join(dir, file)\n\tif isOpaque {\n\t\tpath = dir\n\t}\n\n\t// If the root doesn't exist we've got nothing to do.\n\t// XXX: We currently cannot error out if a layer asks us to remove a\n\t//      non-existent path with this implementation (because we don't\n\t//      know if it was implicitly removed by another whiteout). In\n\t//      future we could add lowerPaths that would help track whether\n\t//      another whiteout caused the removal to \"fail\" or if the path\n\t//      was actually missing -- which would allow us to actually error\n\t//      out here if the layer is invalid).\n\tif _, err := te.fsEval.Lstat(path); err != nil {\n\t\t// Need to use securejoin.IsNotExist to handle ENOTDIR.\n\t\tif securejoin.IsNotExist(err) {\n\t\t\terr = nil\n\t\t}\n\t\treturn errors.Wrap(err, \"check whiteout target\")\n\t}\n\n\t// Walk over the path to remove it. We remove a given path as soon as\n\t// it isn't present in upperPaths (which includes ancestors of paths\n\t// we've extracted so we only need to look up the one path). Otherwise\n\t// we iterate over any children and try again. The only difference\n\t// between opaque whiteouts and regular whiteouts is that we don't\n\t// delete the directory itself with opaque whiteouts.\n\terr := te.fsEval.Walk(path, func(subpath string, info os.FileInfo, err error) error {\n\t\t// If we are passed an error, bail unless it's ENOENT.\n\t\tif err != nil {\n\t\t\t// If something was deleted outside of our knowledge it's not\n\t\t\t// the end of the world. In principle this shouldn't happen\n\t\t\t// though, so we log it for posterity.\n\t\t\tif os.IsNotExist(errors.Cause(err)) {\n\t\t\t\tlog.Debugf(\"whiteout removal hit already-deleted path: %s\", subpath)\n\t\t\t\terr = filepath.SkipDir\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\n\t\t// Get the relative form of subpath to root to match\n\t\t// te.upperPaths.\n\t\tupperPath, err := filepath.Rel(root, subpath)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"find relative-to-root [should never happen]\")\n\t\t}\n\n\t\t// Remove the path only if it hasn't been touched.\n\t\tif _, ok := te.upperPaths[upperPath]; !ok {\n\t\t\t// Opaque whiteouts don't remove the directory itself, so skip\n\t\t\t// the top-level directory.\n\t\t\tif isOpaque && CleanPath(path) == CleanPath(subpath) {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// Purge the path. We skip anything underneath (if it's a\n\t\t\t// directory) since we just purged it -- and we don't want to\n\t\t\t// hit ENOENT during iteration for no good reason.\n\t\t\terr := errors.Wrap(te.fsEval.RemoveAll(subpath), \"whiteout subpath\")\n\t\t\tif err == nil && info.IsDir() {\n\t\t\t\terr = filepath.SkipDir\n\t\t\t}\n\t\t\treturn err\n\t\t}\n\t\treturn nil\n\t})\n\treturn errors.Wrap(err, \"whiteout remove\")\n}\n\nfunc (te *TarExtractor) overlayFSWhiteout(dir string, file string) error {\n\tisOpaque := file == whOpaque\n\n\t// if this is an opaque whiteout, whiteout the directory\n\tif isOpaque {\n\t\terr := te.fsEval.Lsetxattr(dir, \"trusted.overlay.opaque\", []byte(\"y\"), 0)\n\t\treturn errors.Wrapf(err, \"couldn't set overlayfs whiteout attr for %s\", dir)\n\t}\n\n\t// otherwise, white out the file itself.\n\tp := filepath.Join(dir, strings.TrimPrefix(file, whPrefix))\n\tif err := os.RemoveAll(p); err != nil && !os.IsNotExist(err) {\n\t\treturn errors.Wrapf(err, \"couldn't create overlayfs whiteout for %s\", p)\n\t}\n\n\terr := te.fsEval.Mknod(p, unix.S_IFCHR|0666, unix.Mkdev(0, 0))\n\treturn errors.Wrapf(err, \"couldn't create overlayfs whiteout for %s\", p)\n}\n\n// UnpackEntry extracts the given tar.Header to the provided root, ensuring\n// that the layer state is consistent with the layer state that produced the\n// tar archive being iterated over. This does handle whiteouts, so a tar.Header\n// that represents a whiteout will result in the path being removed.\nfunc (te *TarExtractor) UnpackEntry(root string, hdr *tar.Header, r io.Reader) (Err error) {\n\t// Make the paths safe.\n\thdr.Name = CleanPath(hdr.Name)\n\troot = filepath.Clean(root)\n\n\tlog.WithFields(log.Fields{\n\t\t\"root\": root,\n\t\t\"path\": hdr.Name,\n\t\t\"type\": hdr.Typeflag,\n\t}).Debugf(\"unpacking entry\")\n\n\t// Get directory and filename, but we have to safely get the directory\n\t// component of the path. SecureJoinVFS will evaluate the path itself,\n\t// which we don't want (we're clever enough to handle the actual path being\n\t// a symlink).\n\tunsafeDir, file := filepath.Split(hdr.Name)\n\tif filepath.Join(\"/\", hdr.Name) == \"/\" {\n\t\t// If we got an entry for the root, then unsafeDir is the full path.\n\t\tunsafeDir, file = hdr.Name, \".\"\n\t\t// If we're being asked to change the root type, bail because they may\n\t\t// change it to a symlink which we could inadvertently follow.\n\t\tif hdr.Typeflag != tar.TypeDir {\n\t\t\treturn errors.New(\"malicious tar entry -- refusing to change type of root directory\")\n\t\t}\n\t}\n\tdir, err := securejoin.SecureJoinVFS(root, unsafeDir, te.fsEval)\n\tif err != nil {\n\t\treturn errors.Wrap(err, \"sanitise symlinks in root\")\n\t}\n\tpath := filepath.Join(dir, file)\n\n\t// Before we do anything, get the state of dir. Because we might be adding\n\t// or removing files, our parent directory might be modified in the\n\t// process. As a result, we want to be able to restore the old state\n\t// (because we only apply state that we find in the archive we're iterating\n\t// over). We can safely ignore an error here, because a non-existent\n\t// directory will be fixed by later archive entries.\n\tif dirFi, err := te.fsEval.Lstat(dir); err == nil && path != dir {\n\t\t// FIXME: This is really stupid.\n\t\t// #nosec G104\n\t\tlink, _ := te.fsEval.Readlink(dir)\n\t\tdirHdr, err := tar.FileInfoHeader(dirFi, link)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"convert dirFi to dirHdr\")\n\t\t}\n\n\t\t// More faking to trick restoreMetadata to actually restore the directory.\n\t\tdirHdr.Typeflag = tar.TypeDir\n\t\tdirHdr.Linkname = \"\"\n\n\t\t// os.Lstat doesn't get the list of xattrs by default. We need to fill\n\t\t// this explicitly. Note that while Go's \"archive/tar\" takes strings,\n\t\t// in Go strings can be arbitrary byte sequences so this doesn't\n\t\t// restrict the possible values.\n\t\t// TODO: Move this to a separate function so we can share it with\n\t\t//       tar_generate.go.\n\t\txattrs, err := te.fsEval.Llistxattr(dir)\n\t\tif err != nil {\n\t\t\tif errors.Cause(err) != unix.ENOTSUP {\n\t\t\t\treturn errors.Wrap(err, \"get dirHdr.Xattrs\")\n\t\t\t}\n\t\t\tif !te.enotsupWarned {\n\t\t\t\tlog.Warnf(\"xattr{%s} ignoring ENOTSUP on llistxattr\", dir)\n\t\t\t\tlog.Warnf(\"xattr{%s} destination filesystem does not support xattrs, further warnings will be suppressed\", path)\n\t\t\t\tte.enotsupWarned = true\n\t\t\t} else {\n\t\t\t\tlog.Debugf(\"xattr{%s} ignoring ENOTSUP on clearxattrs\", path)\n\t\t\t}\n\t\t}\n\t\tif len(xattrs) > 0 {\n\t\t\tdirHdr.Xattrs = map[string]string{}\n\t\t\tfor _, xattr := range xattrs {\n\t\t\t\tvalue, err := te.fsEval.Lgetxattr(dir, xattr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn errors.Wrap(err, \"get xattr\")\n\t\t\t\t}\n\t\t\t\tdirHdr.Xattrs[xattr] = string(value)\n\t\t\t}\n\t\t}\n\n\t\t// Ensure that after everything we correctly re-apply the old metadata.\n\t\t// We don't map this header because we're restoring files that already\n\t\t// existed on the filesystem, not from a tar layer.\n\t\tdefer func() {\n\t\t\t// Only overwrite the error if there wasn't one already.\n\t\t\tif err := te.restoreMetadata(dir, dirHdr); err != nil {\n\t\t\t\tif Err == nil {\n\t\t\t\t\tErr = errors.Wrap(err, \"restore parent directory\")\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t}\n\n\t// Currently the spec doesn't specify what the hdr.Typeflag of whiteout\n\t// files is meant to be. We specifically only produce regular files\n\t// ('\\x00') but it could be possible that someone produces a different\n\t// Typeflag, expecting that the path is the only thing that matters in a\n\t// whiteout entry.\n\tif strings.HasPrefix(file, whPrefix) {\n\t\tswitch te.whiteoutMode {\n\t\tcase OCIStandardWhiteout:\n\t\t\treturn te.ociWhiteout(root, dir, file)\n\t\tcase OverlayFSWhiteout:\n\t\t\treturn te.overlayFSWhiteout(dir, file)\n\t\tdefault:\n\t\t\treturn errors.Errorf(\"unknown whiteout mode %d\", te.whiteoutMode)\n\t\t}\n\t}\n\n\t// Get information about the path. This has to be done after we've dealt\n\t// with whiteouts because it turns out that lstat(2) will return EPERM if\n\t// you try to stat a whiteout on AUFS.\n\tfi, err := te.fsEval.Lstat(path)\n\tif err != nil {\n\t\t// File doesn't exist, just switch fi to the file header.\n\t\tfi = hdr.FileInfo()\n\t}\n\n\t// Attempt to create the parent directory of the path we're unpacking.\n\t// We do a MkdirAll here because even though you need to have a tar entry\n\t// for every component of a new path, applyMetadata will correct any\n\t// inconsistencies.\n\t// FIXME: We have to make this consistent, since if the tar archive doesn't\n\t//        have entries for some of these components we won't be able to\n\t//        verify that we have consistent results during unpacking.\n\tif err := te.fsEval.MkdirAll(dir, 0777); err != nil {\n\t\treturn errors.Wrap(err, \"mkdir parent\")\n\t}\n\n\tisDirlink := false\n\t// We remove whatever existed at the old path to clobber it so that\n\t// creating a new path will not break. The only exception is if the path is\n\t// a directory in both the layer and the current filesystem, in which case\n\t// we don't delete it for obvious reasons. In all other cases we clobber.\n\t//\n\t// Note that this will cause hard-links in the \"lower\" layer to not be able\n\t// to point to \"upper\" layer inodes even if the extracted type is the same\n\t// as the old one, however it is not clear whether this is something a user\n\t// would expect anyway. In addition, this will incorrectly deal with a\n\t// TarLink that is present before the \"upper\" entry in the layer but the\n\t// \"lower\" file still exists (so the hard-link would point to the old\n\t// inode). It's not clear if such an archive is actually valid though.\n\tif !fi.IsDir() || hdr.Typeflag != tar.TypeDir {\n\t\t// If we are in --keep-dirlinks mode and the existing fs object is a\n\t\t// symlink to a directory (with the pending object is a directory), we\n\t\t// don't remove the symlink (and instead allow subsequent objects to be\n\t\t// just written through the symlink into the directory). This is a very\n\t\t// specific usecase where layers that were generated independently from\n\t\t// each other (on different base filesystems) end up with weird things\n\t\t// like /lib64 being a symlink only sometimes but you never want to\n\t\t// delete libraries (not just the ones that were under the \"real\"\n\t\t// directory).\n\t\t//\n\t\t// TODO: This code should also handle a pending symlink entry where the\n\t\t//       existing object is a directory. I'm not sure how we could\n\t\t//       disambiguate this from a symlink-to-a-file but I imagine that\n\t\t//       this is something that would also be useful in the same vein\n\t\t//       as --keep-dirlinks (which currently only prevents clobbering\n\t\t//       in the opposite case).\n\t\tif te.keepDirlinks &&\n\t\t\tfi.Mode()&os.ModeSymlink == os.ModeSymlink && hdr.Typeflag == tar.TypeDir {\n\t\t\tisDirlink, err = te.isDirlink(root, path)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"check is dirlink\")\n\t\t\t}\n\t\t}\n\t\tif !(isDirlink && te.keepDirlinks) {\n\t\t\tif err := te.fsEval.RemoveAll(path); err != nil {\n\t\t\t\treturn errors.Wrap(err, \"clobber old path\")\n\t\t\t}\n\t\t}\n\t}\n\n\t// Now create or otherwise modify the state of the path. Right now, either\n\t// the type of path matches hdr or the path doesn't exist. Note that we\n\t// don't care about umasks or the initial mode here, since applyMetadata\n\t// will fix all of that for us.\n\tswitch hdr.Typeflag {\n\t// regular file\n\tcase tar.TypeReg, tar.TypeRegA:\n\t\t// Create a new file, then just copy the data.\n\t\tfh, err := te.fsEval.Create(path)\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"create regular\")\n\t\t}\n\t\tdefer fh.Close()\n\n\t\t// We need to make sure that we copy all of the bytes.\n\t\tn, err := io.Copy(fh, r)\n\t\tif int64(n) != hdr.Size {\n\t\t\tif err != nil {\n\t\t\t\terr = errors.Wrapf(err, \"short write\")\n\t\t\t} else {\n\t\t\t\terr = io.ErrShortWrite\n\t\t\t}\n\t\t}\n\t\tif err != nil {\n\t\t\treturn errors.Wrap(err, \"unpack to regular file\")\n\t\t}\n\n\t\t// Force close here so that we don't affect the metadata.\n\t\tif err := fh.Close(); err != nil {\n\t\t\treturn errors.Wrap(err, \"close unpacked regular file\")\n\t\t}\n\n\t// directory\n\tcase tar.TypeDir:\n\t\tif isDirlink {\n\t\t\tbreak\n\t\t}\n\n\t\t// Attempt to create the directory. We do a MkdirAll here because even\n\t\t// though you need to have a tar entry for every component of a new\n\t\t// path, applyMetadata will correct any inconsistencies.\n\t\tif err := te.fsEval.MkdirAll(path, 0777); err != nil {\n\t\t\treturn errors.Wrap(err, \"mkdirall\")\n\t\t}\n\n\t// hard link, symbolic link\n\tcase tar.TypeLink, tar.TypeSymlink:\n\t\tlinkname := hdr.Linkname\n\n\t\t// Hardlinks and symlinks act differently when it comes to the scoping.\n\t\t// In both cases, we have to just unlink and then re-link the given\n\t\t// path. But the function used and the argument are slightly different.\n\t\tvar linkFn func(string, string) error\n\t\tswitch hdr.Typeflag {\n\t\tcase tar.TypeLink:\n\t\t\tlinkFn = te.fsEval.Link\n\t\t\t// Because hardlinks are inode-based we need to scope the link to\n\t\t\t// the rootfs using SecureJoinVFS. As before, we need to be careful\n\t\t\t// that we don't resolve the last part of the link path (in case\n\t\t\t// the user actually wanted to hardlink to a symlink).\n\t\t\tunsafeLinkDir, linkFile := filepath.Split(CleanPath(linkname))\n\t\t\tlinkDir, err := securejoin.SecureJoinVFS(root, unsafeLinkDir, te.fsEval)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"sanitise hardlink target in root\")\n\t\t\t}\n\t\t\tlinkname = filepath.Join(linkDir, linkFile)\n\t\tcase tar.TypeSymlink:\n\t\t\tlinkFn = te.fsEval.Symlink\n\t\t}\n\n\t\t// Link the new one.\n\t\tif err := linkFn(linkname, path); err != nil {\n\t\t\t// FIXME: Currently this can break if tar hardlink entries occur\n\t\t\t//        before we hit the entry those hardlinks link to. I have a\n\t\t\t//        feeling that such archives are invalid, but the correct\n\t\t\t//        way of handling this is to delay link creation until the\n\t\t\t//        very end. Unfortunately this won't work with symlinks\n\t\t\t//        (which can link to directories).\n\t\t\treturn errors.Wrap(err, \"link\")\n\t\t}\n\n\t// character device node, block device node\n\tcase tar.TypeChar, tar.TypeBlock:\n\t\t// In rootless mode we have no choice but to fake this, since mknod(2)\n\t\t// doesn't work as an unprivileged user here.\n\t\t//\n\t\t// TODO: We need to add the concept of a fake block device in\n\t\t//       \"user.rootlesscontainers\", because this workaround suffers\n\t\t//       from the obvious issue that if the file is touched (even the\n\t\t//       metadata) then it will be incorrectly copied into the layer.\n\t\t//       This would break distribution images fairly badly.\n\t\tif te.partialRootless {\n\t\t\tlog.Warnf(\"rootless{%s} creating empty file in place of device %d:%d\", hdr.Name, hdr.Devmajor, hdr.Devminor)\n\t\t\tfh, err := te.fsEval.Create(path)\n\t\t\tif err != nil {\n\t\t\t\treturn errors.Wrap(err, \"create rootless block\")\n\t\t\t}\n\t\t\tdefer fh.Close()\n\t\t\tif err := fh.Chmod(0); err != nil {\n\t\t\t\treturn errors.Wrap(err, \"chmod 0 rootless block\")\n\t\t\t}\n\t\t\tgoto out\n\t\t}\n\n\t\t// Otherwise the handling is the same as a FIFO.\n\t\tfallthrough\n\t// fifo node\n\tcase tar.TypeFifo:\n\t\t// We have to remove and then create the device. In the FIFO case we\n\t\t// could choose not to do so, but we do it anyway just to be on the\n\t\t// safe side.\n\n\t\tmode := system.Tarmode(hdr.Typeflag)\n\t\tdev := unix.Mkdev(uint32(hdr.Devmajor), uint32(hdr.Devminor))\n\n\t\t// Create the node.\n\t\tif err := te.fsEval.Mknod(path, os.FileMode(int64(mode)|hdr.Mode), dev); err != nil {\n\t\t\treturn errors.Wrap(err, \"mknod\")\n\t\t}\n\n\t// We should never hit any other headers (Go abstracts them away from us),\n\t// and we can't handle any custom Tar extensions. So just error out.\n\tdefault:\n\t\treturn fmt.Errorf(\"unpack entry: %s: unknown typeflag '\\\\x%x'\", hdr.Name, hdr.Typeflag)\n\t}\n\nout:\n\t// Apply the metadata, which will apply any mappings necessary. We don't\n\t// apply metadata for hardlinks, because hardlinks don't have any separate\n\t// metadata from their link (and the tar headers might not be filled).\n\tif hdr.Typeflag != tar.TypeLink {\n\t\tif err := te.applyMetadata(path, hdr); err != nil {\n\t\t\treturn errors.Wrap(err, \"apply hdr metadata\")\n\t\t}\n\t}\n\n\t// Everything is done -- the path now exists. Add it (and all its\n\t// ancestors) to the set of upper paths. We first have to figure out the\n\t// proper path corresponding to hdr.Name though.\n\tupperPath, err := filepath.Rel(root, path)\n\tif err != nil {\n\t\t// Really shouldn't happen because of the guarantees of SecureJoinVFS.\n\t\treturn errors.Wrap(err, \"find relative-to-root [should never happen]\")\n\t}\n\tfor pth := upperPath; pth != filepath.Dir(pth); pth = filepath.Dir(pth) {\n\t\tte.upperPaths[pth] = struct{}{}\n\t}\n\treturn nil\n}\n"], "filenames": ["oci/layer/tar_extract.go"], "buggy_code_start_loc": [406], "buggy_code_end_loc": [406], "fixing_code_start_loc": [407], "fixing_code_end_loc": [412], "type": "CWE-20", "message": "Open Container Initiative umoci before 0.4.7 allows attackers to overwrite arbitrary host paths via a crafted image that causes symlink traversal when \"umoci unpack\" or \"umoci raw unpack\" is used.", "other": {"cve": {"id": "CVE-2021-29136", "sourceIdentifier": "cve@mitre.org", "published": "2021-04-06T16:15:16.520", "lastModified": "2021-05-20T14:32:14.863", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Open Container Initiative umoci before 0.4.7 allows attackers to overwrite arbitrary host paths via a crafted image that causes symlink traversal when \"umoci unpack\" or \"umoci raw unpack\" is used."}, {"lang": "es", "value": "Open Container Initiative umoci versiones anteriores a 0.4.7, permite a atacantes sobrescribir rutas de host arbitrarias por medio de una imagen dise\u00f1ada que causa un salto de enlace simb\u00f3lico cuando es usado \"umoci unpack\" o \"umoci raw unpack\""}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:H/A:N", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "NONE", "baseScore": 5.5, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 1.8, "impactScore": 3.6}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:N/I:P/A:N", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 2.1}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-20"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:linuxfoundation:umoci:*:*:*:*:*:*:*:*", "versionEndExcluding": "0.4.7", "matchCriteriaId": "DD17F3AC-63F8-41CA-8A85-C880F8704C8D"}, {"vulnerable": true, "criteria": "cpe:2.3:a:sylabs:singularity:*:*:*:*:*:*:*:*", "versionEndExcluding": "3.7.3", "matchCriteriaId": "3F33F771-2B43-432C-9EC5-1639E19D5F72"}]}]}], "references": [{"url": "http://www.openwall.com/lists/oss-security/2021/04/06/2", "source": "cve@mitre.org", "tags": ["Mailing List", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/opencontainers/umoci/commit/d9efc31daf2206f7d3fdb839863cf7a576a2eb57", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/opencontainers/umoci/security/advisories/GHSA-9m95-8hx6-7p9v", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/opencontainers/umoci/commit/d9efc31daf2206f7d3fdb839863cf7a576a2eb57"}}
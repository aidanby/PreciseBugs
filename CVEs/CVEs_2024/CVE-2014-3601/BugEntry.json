{"buggy_code": ["/*\n * Copyright (c) 2006, Intel Corporation.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms and conditions of the GNU General Public License,\n * version 2, as published by the Free Software Foundation.\n *\n * This program is distributed in the hope it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc., 59 Temple\n * Place - Suite 330, Boston, MA 02111-1307 USA.\n *\n * Copyright (C) 2006-2008 Intel Corporation\n * Copyright IBM Corporation, 2008\n * Copyright 2010 Red Hat, Inc. and/or its affiliates.\n *\n * Author: Allen M. Kay <allen.m.kay@intel.com>\n * Author: Weidong Han <weidong.han@intel.com>\n * Author: Ben-Ami Yassour <benami@il.ibm.com>\n */\n\n#include <linux/list.h>\n#include <linux/kvm_host.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/stat.h>\n#include <linux/dmar.h>\n#include <linux/iommu.h>\n#include <linux/intel-iommu.h>\n\nstatic bool allow_unsafe_assigned_interrupts;\nmodule_param_named(allow_unsafe_assigned_interrupts,\n\t\t   allow_unsafe_assigned_interrupts, bool, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(allow_unsafe_assigned_interrupts,\n \"Enable device assignment on platforms without interrupt remapping support.\");\n\nstatic int kvm_iommu_unmap_memslots(struct kvm *kvm);\nstatic void kvm_iommu_put_pages(struct kvm *kvm,\n\t\t\t\tgfn_t base_gfn, unsigned long npages);\n\nstatic pfn_t kvm_pin_pages(struct kvm_memory_slot *slot, gfn_t gfn,\n\t\t\t   unsigned long size)\n{\n\tgfn_t end_gfn;\n\tpfn_t pfn;\n\n\tpfn     = gfn_to_pfn_memslot(slot, gfn);\n\tend_gfn = gfn + (size >> PAGE_SHIFT);\n\tgfn    += 1;\n\n\tif (is_error_noslot_pfn(pfn))\n\t\treturn pfn;\n\n\twhile (gfn < end_gfn)\n\t\tgfn_to_pfn_memslot(slot, gfn++);\n\n\treturn pfn;\n}\n\nint kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\n\tgfn_t gfn, end_gfn;\n\tpfn_t pfn;\n\tint r = 0;\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tint flags;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tgfn     = slot->base_gfn;\n\tend_gfn = gfn + slot->npages;\n\n\tflags = IOMMU_READ;\n\tif (!(slot->flags & KVM_MEM_READONLY))\n\t\tflags |= IOMMU_WRITE;\n\tif (!kvm->arch.iommu_noncoherent)\n\t\tflags |= IOMMU_CACHE;\n\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long page_size;\n\n\t\t/* Check if already mapped */\n\t\tif (iommu_iova_to_phys(domain, gfn_to_gpa(gfn))) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get the page size we could use to map */\n\t\tpage_size = kvm_host_page_size(kvm, gfn);\n\n\t\t/* Make sure the page_size does not exceed the memslot */\n\t\twhile ((gfn + (page_size >> PAGE_SHIFT)) > end_gfn)\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure gfn is aligned to the page size we want to map */\n\t\twhile ((gfn << PAGE_SHIFT) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure hva is aligned to the page size we want to map */\n\t\twhile (__gfn_to_hva_memslot(slot, gfn) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/*\n\t\t * Pin all pages we are about to map in memory. This is\n\t\t * important because we unmap and unpin in 4kb steps later.\n\t\t */\n\t\tpfn = kvm_pin_pages(slot, gfn, page_size);\n\t\tif (is_error_noslot_pfn(pfn)) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Map into IO address space */\n\t\tr = iommu_map(domain, gfn_to_gpa(gfn), pfn_to_hpa(pfn),\n\t\t\t      page_size, flags);\n\t\tif (r) {\n\t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\t\t\t       \"iommu failed to map pfn=%llx\\n\", pfn);\n\t\t\tgoto unmap_pages;\n\t\t}\n\n\t\tgfn += page_size >> PAGE_SHIFT;\n\n\n\t}\n\n\treturn 0;\n\nunmap_pages:\n\tkvm_iommu_put_pages(kvm, slot->base_gfn, gfn);\n\treturn r;\n}\n\nstatic int kvm_iommu_map_memslots(struct kvm *kvm)\n{\n\tint idx, r = 0;\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\n\tif (kvm->arch.iommu_noncoherent)\n\t\tkvm_arch_register_noncoherent_dma(kvm);\n\n\tidx = srcu_read_lock(&kvm->srcu);\n\tslots = kvm_memslots(kvm);\n\n\tkvm_for_each_memslot(memslot, slots) {\n\t\tr = kvm_iommu_map_pages(kvm, memslot);\n\t\tif (r)\n\t\t\tbreak;\n\t}\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\n\treturn r;\n}\n\nint kvm_assign_device(struct kvm *kvm,\n\t\t      struct kvm_assigned_dev_kernel *assigned_dev)\n{\n\tstruct pci_dev *pdev = NULL;\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tint r;\n\tbool noncoherent;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tpdev = assigned_dev->dev;\n\tif (pdev == NULL)\n\t\treturn -ENODEV;\n\n\tr = iommu_attach_device(domain, &pdev->dev);\n\tif (r) {\n\t\tdev_err(&pdev->dev, \"kvm assign device failed ret %d\", r);\n\t\treturn r;\n\t}\n\n\tnoncoherent = !iommu_domain_has_cap(kvm->arch.iommu_domain,\n\t\t\t\t\t    IOMMU_CAP_CACHE_COHERENCY);\n\n\t/* Check if need to update IOMMU page table for guest memory */\n\tif (noncoherent != kvm->arch.iommu_noncoherent) {\n\t\tkvm_iommu_unmap_memslots(kvm);\n\t\tkvm->arch.iommu_noncoherent = noncoherent;\n\t\tr = kvm_iommu_map_memslots(kvm);\n\t\tif (r)\n\t\t\tgoto out_unmap;\n\t}\n\n\tpdev->dev_flags |= PCI_DEV_FLAGS_ASSIGNED;\n\n\tdev_info(&pdev->dev, \"kvm assign device\\n\");\n\n\treturn 0;\nout_unmap:\n\tkvm_iommu_unmap_memslots(kvm);\n\treturn r;\n}\n\nint kvm_deassign_device(struct kvm *kvm,\n\t\t\tstruct kvm_assigned_dev_kernel *assigned_dev)\n{\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tstruct pci_dev *pdev = NULL;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tpdev = assigned_dev->dev;\n\tif (pdev == NULL)\n\t\treturn -ENODEV;\n\n\tiommu_detach_device(domain, &pdev->dev);\n\n\tpdev->dev_flags &= ~PCI_DEV_FLAGS_ASSIGNED;\n\n\tdev_info(&pdev->dev, \"kvm deassign device\\n\");\n\n\treturn 0;\n}\n\nint kvm_iommu_map_guest(struct kvm *kvm)\n{\n\tint r;\n\n\tif (!iommu_present(&pci_bus_type)) {\n\t\tprintk(KERN_ERR \"%s: iommu not found\\n\", __func__);\n\t\treturn -ENODEV;\n\t}\n\n\tmutex_lock(&kvm->slots_lock);\n\n\tkvm->arch.iommu_domain = iommu_domain_alloc(&pci_bus_type);\n\tif (!kvm->arch.iommu_domain) {\n\t\tr = -ENOMEM;\n\t\tgoto out_unlock;\n\t}\n\n\tif (!allow_unsafe_assigned_interrupts &&\n\t    !iommu_domain_has_cap(kvm->arch.iommu_domain,\n\t\t\t\t  IOMMU_CAP_INTR_REMAP)) {\n\t\tprintk(KERN_WARNING \"%s: No interrupt remapping support,\"\n\t\t       \" disallowing device assignment.\"\n\t\t       \" Re-enble with \\\"allow_unsafe_assigned_interrupts=1\\\"\"\n\t\t       \" module option.\\n\", __func__);\n\t\tiommu_domain_free(kvm->arch.iommu_domain);\n\t\tkvm->arch.iommu_domain = NULL;\n\t\tr = -EPERM;\n\t\tgoto out_unlock;\n\t}\n\n\tr = kvm_iommu_map_memslots(kvm);\n\tif (r)\n\t\tkvm_iommu_unmap_memslots(kvm);\n\nout_unlock:\n\tmutex_unlock(&kvm->slots_lock);\n\treturn r;\n}\n\nstatic void kvm_unpin_pages(struct kvm *kvm, pfn_t pfn, unsigned long npages)\n{\n\tunsigned long i;\n\n\tfor (i = 0; i < npages; ++i)\n\t\tkvm_release_pfn_clean(pfn + i);\n}\n\nstatic void kvm_iommu_put_pages(struct kvm *kvm,\n\t\t\t\tgfn_t base_gfn, unsigned long npages)\n{\n\tstruct iommu_domain *domain;\n\tgfn_t end_gfn, gfn;\n\tpfn_t pfn;\n\tu64 phys;\n\n\tdomain  = kvm->arch.iommu_domain;\n\tend_gfn = base_gfn + npages;\n\tgfn     = base_gfn;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn;\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long unmap_pages;\n\t\tsize_t size;\n\n\t\t/* Get physical address */\n\t\tphys = iommu_iova_to_phys(domain, gfn_to_gpa(gfn));\n\n\t\tif (!phys) {\n\t\t\tgfn++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpfn  = phys >> PAGE_SHIFT;\n\n\t\t/* Unmap address from IO address space */\n\t\tsize       = iommu_unmap(domain, gfn_to_gpa(gfn), PAGE_SIZE);\n\t\tunmap_pages = 1ULL << get_order(size);\n\n\t\t/* Unpin all pages we just unmapped to not leak any memory */\n\t\tkvm_unpin_pages(kvm, pfn, unmap_pages);\n\n\t\tgfn += unmap_pages;\n\t}\n}\n\nvoid kvm_iommu_unmap_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\n\tkvm_iommu_put_pages(kvm, slot->base_gfn, slot->npages);\n}\n\nstatic int kvm_iommu_unmap_memslots(struct kvm *kvm)\n{\n\tint idx;\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\n\tidx = srcu_read_lock(&kvm->srcu);\n\tslots = kvm_memslots(kvm);\n\n\tkvm_for_each_memslot(memslot, slots)\n\t\tkvm_iommu_unmap_pages(kvm, memslot);\n\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\n\tif (kvm->arch.iommu_noncoherent)\n\t\tkvm_arch_unregister_noncoherent_dma(kvm);\n\n\treturn 0;\n}\n\nint kvm_iommu_unmap_guest(struct kvm *kvm)\n{\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tmutex_lock(&kvm->slots_lock);\n\tkvm_iommu_unmap_memslots(kvm);\n\tkvm->arch.iommu_domain = NULL;\n\tkvm->arch.iommu_noncoherent = false;\n\tmutex_unlock(&kvm->slots_lock);\n\n\tiommu_domain_free(domain);\n\treturn 0;\n}\n"], "fixing_code": ["/*\n * Copyright (c) 2006, Intel Corporation.\n *\n * This program is free software; you can redistribute it and/or modify it\n * under the terms and conditions of the GNU General Public License,\n * version 2, as published by the Free Software Foundation.\n *\n * This program is distributed in the hope it will be useful, but WITHOUT\n * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or\n * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for\n * more details.\n *\n * You should have received a copy of the GNU General Public License along with\n * this program; if not, write to the Free Software Foundation, Inc., 59 Temple\n * Place - Suite 330, Boston, MA 02111-1307 USA.\n *\n * Copyright (C) 2006-2008 Intel Corporation\n * Copyright IBM Corporation, 2008\n * Copyright 2010 Red Hat, Inc. and/or its affiliates.\n *\n * Author: Allen M. Kay <allen.m.kay@intel.com>\n * Author: Weidong Han <weidong.han@intel.com>\n * Author: Ben-Ami Yassour <benami@il.ibm.com>\n */\n\n#include <linux/list.h>\n#include <linux/kvm_host.h>\n#include <linux/module.h>\n#include <linux/pci.h>\n#include <linux/stat.h>\n#include <linux/dmar.h>\n#include <linux/iommu.h>\n#include <linux/intel-iommu.h>\n\nstatic bool allow_unsafe_assigned_interrupts;\nmodule_param_named(allow_unsafe_assigned_interrupts,\n\t\t   allow_unsafe_assigned_interrupts, bool, S_IRUGO | S_IWUSR);\nMODULE_PARM_DESC(allow_unsafe_assigned_interrupts,\n \"Enable device assignment on platforms without interrupt remapping support.\");\n\nstatic int kvm_iommu_unmap_memslots(struct kvm *kvm);\nstatic void kvm_iommu_put_pages(struct kvm *kvm,\n\t\t\t\tgfn_t base_gfn, unsigned long npages);\n\nstatic pfn_t kvm_pin_pages(struct kvm_memory_slot *slot, gfn_t gfn,\n\t\t\t   unsigned long size)\n{\n\tgfn_t end_gfn;\n\tpfn_t pfn;\n\n\tpfn     = gfn_to_pfn_memslot(slot, gfn);\n\tend_gfn = gfn + (size >> PAGE_SHIFT);\n\tgfn    += 1;\n\n\tif (is_error_noslot_pfn(pfn))\n\t\treturn pfn;\n\n\twhile (gfn < end_gfn)\n\t\tgfn_to_pfn_memslot(slot, gfn++);\n\n\treturn pfn;\n}\n\nstatic void kvm_unpin_pages(struct kvm *kvm, pfn_t pfn, unsigned long npages)\n{\n\tunsigned long i;\n\n\tfor (i = 0; i < npages; ++i)\n\t\tkvm_release_pfn_clean(pfn + i);\n}\n\nint kvm_iommu_map_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\n\tgfn_t gfn, end_gfn;\n\tpfn_t pfn;\n\tint r = 0;\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tint flags;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tgfn     = slot->base_gfn;\n\tend_gfn = gfn + slot->npages;\n\n\tflags = IOMMU_READ;\n\tif (!(slot->flags & KVM_MEM_READONLY))\n\t\tflags |= IOMMU_WRITE;\n\tif (!kvm->arch.iommu_noncoherent)\n\t\tflags |= IOMMU_CACHE;\n\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long page_size;\n\n\t\t/* Check if already mapped */\n\t\tif (iommu_iova_to_phys(domain, gfn_to_gpa(gfn))) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Get the page size we could use to map */\n\t\tpage_size = kvm_host_page_size(kvm, gfn);\n\n\t\t/* Make sure the page_size does not exceed the memslot */\n\t\twhile ((gfn + (page_size >> PAGE_SHIFT)) > end_gfn)\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure gfn is aligned to the page size we want to map */\n\t\twhile ((gfn << PAGE_SHIFT) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/* Make sure hva is aligned to the page size we want to map */\n\t\twhile (__gfn_to_hva_memslot(slot, gfn) & (page_size - 1))\n\t\t\tpage_size >>= 1;\n\n\t\t/*\n\t\t * Pin all pages we are about to map in memory. This is\n\t\t * important because we unmap and unpin in 4kb steps later.\n\t\t */\n\t\tpfn = kvm_pin_pages(slot, gfn, page_size);\n\t\tif (is_error_noslot_pfn(pfn)) {\n\t\t\tgfn += 1;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Map into IO address space */\n\t\tr = iommu_map(domain, gfn_to_gpa(gfn), pfn_to_hpa(pfn),\n\t\t\t      page_size, flags);\n\t\tif (r) {\n\t\t\tprintk(KERN_ERR \"kvm_iommu_map_address:\"\n\t\t\t       \"iommu failed to map pfn=%llx\\n\", pfn);\n\t\t\tkvm_unpin_pages(kvm, pfn, page_size);\n\t\t\tgoto unmap_pages;\n\t\t}\n\n\t\tgfn += page_size >> PAGE_SHIFT;\n\n\n\t}\n\n\treturn 0;\n\nunmap_pages:\n\tkvm_iommu_put_pages(kvm, slot->base_gfn, gfn - slot->base_gfn);\n\treturn r;\n}\n\nstatic int kvm_iommu_map_memslots(struct kvm *kvm)\n{\n\tint idx, r = 0;\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\n\tif (kvm->arch.iommu_noncoherent)\n\t\tkvm_arch_register_noncoherent_dma(kvm);\n\n\tidx = srcu_read_lock(&kvm->srcu);\n\tslots = kvm_memslots(kvm);\n\n\tkvm_for_each_memslot(memslot, slots) {\n\t\tr = kvm_iommu_map_pages(kvm, memslot);\n\t\tif (r)\n\t\t\tbreak;\n\t}\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\n\treturn r;\n}\n\nint kvm_assign_device(struct kvm *kvm,\n\t\t      struct kvm_assigned_dev_kernel *assigned_dev)\n{\n\tstruct pci_dev *pdev = NULL;\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tint r;\n\tbool noncoherent;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tpdev = assigned_dev->dev;\n\tif (pdev == NULL)\n\t\treturn -ENODEV;\n\n\tr = iommu_attach_device(domain, &pdev->dev);\n\tif (r) {\n\t\tdev_err(&pdev->dev, \"kvm assign device failed ret %d\", r);\n\t\treturn r;\n\t}\n\n\tnoncoherent = !iommu_domain_has_cap(kvm->arch.iommu_domain,\n\t\t\t\t\t    IOMMU_CAP_CACHE_COHERENCY);\n\n\t/* Check if need to update IOMMU page table for guest memory */\n\tif (noncoherent != kvm->arch.iommu_noncoherent) {\n\t\tkvm_iommu_unmap_memslots(kvm);\n\t\tkvm->arch.iommu_noncoherent = noncoherent;\n\t\tr = kvm_iommu_map_memslots(kvm);\n\t\tif (r)\n\t\t\tgoto out_unmap;\n\t}\n\n\tpdev->dev_flags |= PCI_DEV_FLAGS_ASSIGNED;\n\n\tdev_info(&pdev->dev, \"kvm assign device\\n\");\n\n\treturn 0;\nout_unmap:\n\tkvm_iommu_unmap_memslots(kvm);\n\treturn r;\n}\n\nint kvm_deassign_device(struct kvm *kvm,\n\t\t\tstruct kvm_assigned_dev_kernel *assigned_dev)\n{\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\tstruct pci_dev *pdev = NULL;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tpdev = assigned_dev->dev;\n\tif (pdev == NULL)\n\t\treturn -ENODEV;\n\n\tiommu_detach_device(domain, &pdev->dev);\n\n\tpdev->dev_flags &= ~PCI_DEV_FLAGS_ASSIGNED;\n\n\tdev_info(&pdev->dev, \"kvm deassign device\\n\");\n\n\treturn 0;\n}\n\nint kvm_iommu_map_guest(struct kvm *kvm)\n{\n\tint r;\n\n\tif (!iommu_present(&pci_bus_type)) {\n\t\tprintk(KERN_ERR \"%s: iommu not found\\n\", __func__);\n\t\treturn -ENODEV;\n\t}\n\n\tmutex_lock(&kvm->slots_lock);\n\n\tkvm->arch.iommu_domain = iommu_domain_alloc(&pci_bus_type);\n\tif (!kvm->arch.iommu_domain) {\n\t\tr = -ENOMEM;\n\t\tgoto out_unlock;\n\t}\n\n\tif (!allow_unsafe_assigned_interrupts &&\n\t    !iommu_domain_has_cap(kvm->arch.iommu_domain,\n\t\t\t\t  IOMMU_CAP_INTR_REMAP)) {\n\t\tprintk(KERN_WARNING \"%s: No interrupt remapping support,\"\n\t\t       \" disallowing device assignment.\"\n\t\t       \" Re-enble with \\\"allow_unsafe_assigned_interrupts=1\\\"\"\n\t\t       \" module option.\\n\", __func__);\n\t\tiommu_domain_free(kvm->arch.iommu_domain);\n\t\tkvm->arch.iommu_domain = NULL;\n\t\tr = -EPERM;\n\t\tgoto out_unlock;\n\t}\n\n\tr = kvm_iommu_map_memslots(kvm);\n\tif (r)\n\t\tkvm_iommu_unmap_memslots(kvm);\n\nout_unlock:\n\tmutex_unlock(&kvm->slots_lock);\n\treturn r;\n}\n\nstatic void kvm_iommu_put_pages(struct kvm *kvm,\n\t\t\t\tgfn_t base_gfn, unsigned long npages)\n{\n\tstruct iommu_domain *domain;\n\tgfn_t end_gfn, gfn;\n\tpfn_t pfn;\n\tu64 phys;\n\n\tdomain  = kvm->arch.iommu_domain;\n\tend_gfn = base_gfn + npages;\n\tgfn     = base_gfn;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn;\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long unmap_pages;\n\t\tsize_t size;\n\n\t\t/* Get physical address */\n\t\tphys = iommu_iova_to_phys(domain, gfn_to_gpa(gfn));\n\n\t\tif (!phys) {\n\t\t\tgfn++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpfn  = phys >> PAGE_SHIFT;\n\n\t\t/* Unmap address from IO address space */\n\t\tsize       = iommu_unmap(domain, gfn_to_gpa(gfn), PAGE_SIZE);\n\t\tunmap_pages = 1ULL << get_order(size);\n\n\t\t/* Unpin all pages we just unmapped to not leak any memory */\n\t\tkvm_unpin_pages(kvm, pfn, unmap_pages);\n\n\t\tgfn += unmap_pages;\n\t}\n}\n\nvoid kvm_iommu_unmap_pages(struct kvm *kvm, struct kvm_memory_slot *slot)\n{\n\tkvm_iommu_put_pages(kvm, slot->base_gfn, slot->npages);\n}\n\nstatic int kvm_iommu_unmap_memslots(struct kvm *kvm)\n{\n\tint idx;\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\n\tidx = srcu_read_lock(&kvm->srcu);\n\tslots = kvm_memslots(kvm);\n\n\tkvm_for_each_memslot(memslot, slots)\n\t\tkvm_iommu_unmap_pages(kvm, memslot);\n\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\n\tif (kvm->arch.iommu_noncoherent)\n\t\tkvm_arch_unregister_noncoherent_dma(kvm);\n\n\treturn 0;\n}\n\nint kvm_iommu_unmap_guest(struct kvm *kvm)\n{\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tmutex_lock(&kvm->slots_lock);\n\tkvm_iommu_unmap_memslots(kvm);\n\tkvm->arch.iommu_domain = NULL;\n\tkvm->arch.iommu_noncoherent = false;\n\tmutex_unlock(&kvm->slots_lock);\n\n\tiommu_domain_free(domain);\n\treturn 0;\n}\n"], "filenames": ["virt/kvm/iommu.c"], "buggy_code_start_loc": [61], "buggy_code_end_loc": [277], "fixing_code_start_loc": [62], "fixing_code_end_loc": [277], "type": "CWE-189", "message": "The kvm_iommu_map_pages function in virt/kvm/iommu.c in the Linux kernel through 3.16.1 miscalculates the number of pages during the handling of a mapping failure, which allows guest OS users to (1) cause a denial of service (host OS memory corruption) or possibly have unspecified other impact by triggering a large gfn value or (2) cause a denial of service (host OS memory consumption) by triggering a small gfn value that leads to permanently pinned pages.", "other": {"cve": {"id": "CVE-2014-3601", "sourceIdentifier": "secalert@redhat.com", "published": "2014-09-01T01:55:18.250", "lastModified": "2023-02-13T00:40:55.857", "vulnStatus": "Modified", "descriptions": [{"lang": "en", "value": "The kvm_iommu_map_pages function in virt/kvm/iommu.c in the Linux kernel through 3.16.1 miscalculates the number of pages during the handling of a mapping failure, which allows guest OS users to (1) cause a denial of service (host OS memory corruption) or possibly have unspecified other impact by triggering a large gfn value or (2) cause a denial of service (host OS memory consumption) by triggering a small gfn value that leads to permanently pinned pages."}, {"lang": "es", "value": "La funci\u00f3n kvm_iommu_map_pages en virt/kvm/iommu.c en el kernel de Linux hasta 3.16.1 calcula err\u00f3neamente el n\u00famero de las p\u00e1ginas durante el manejo de un fallo en las asignaciones, lo que permite a usuarios del sistema operativo invitado (1) causar una denegaci\u00f3n de servicio (corrupci\u00f3n de la memoria del sistema operativo anfitri\u00f3n) o posiblemente tener otro impacto no especificado mediante la provocaci\u00f3n de un valor gfn grande o (2) causar una denegaci\u00f3n de servicio (corrupci\u00f3n de la memoria del sistema operativo anfitri\u00f3n) mediante la provocaci\u00f3n de un valor gfn peque\u00f1o que conduce a p\u00e1ginas fijadas (pinned) permanentemente."}], "metrics": {"cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:A/AC:H/Au:S/C:N/I:N/A:C", "accessVector": "ADJACENT_NETWORK", "accessComplexity": "HIGH", "authentication": "SINGLE", "confidentialityImpact": "NONE", "integrityImpact": "NONE", "availabilityImpact": "COMPLETE", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 2.5, "impactScore": 6.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-189"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:suse:linux_enterprise_real_time_extension:11.0:sp3:*:*:*:*:*:*", "matchCriteriaId": "DC669C65-54A4-4C5B-ADFC-E0550285DE16"}, {"vulnerable": true, "criteria": "cpe:2.3:o:opensuse:evergreen:11.4:*:*:*:*:*:*:*", "matchCriteriaId": "CCE4D64E-8C4B-4F21-A9B0-90637C85C1D0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:linux_enterprise_server:11:sp2:*:*:ltss:*:*:*", "matchCriteriaId": "CB6476C7-03F2-4939-AB85-69AA524516D9"}, {"vulnerable": true, "criteria": "cpe:2.3:o:suse:suse_linux_enterprise_server:11:*:*:*:*:*:*:*", "matchCriteriaId": "93AD897C-C9F7-4B4D-BC39-5E13920383D4"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:12.04:*:*:*:lts:*:*:*", "matchCriteriaId": "B6B7CAD7-9D4E-4FDB-88E3-1E583210A01F"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:14.04:*:*:*:lts:*:*:*", "matchCriteriaId": "B5A6F2F3-4894-4392-8296-3B8DD2679084"}]}]}, {"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionEndIncluding": "3.16.1", "matchCriteriaId": "8452407A-5074-4385-B9A1-9E49042CCAEB"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:3.16.0:*:*:*:*:*:*:*", "matchCriteriaId": "3CFFCDFC-AE4F-47EE-B1DA-05A6865D1745"}]}]}], "references": [{"url": "http://git.kernel.org/?p=linux/kernel/git/torvalds/linux-2.6.git%3Ba=commit%3Bh=350b8bdd689cd2ab2c67c8a86a0be86cfa0751a7", "source": "secalert@redhat.com"}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2015-03/msg00010.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2015-03/msg00025.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://lists.opensuse.org/opensuse-security-announce/2015-04/msg00015.html", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://secunia.com/advisories/60830", "source": "secalert@redhat.com"}, {"url": "http://www.securityfocus.com/bid/69489", "source": "secalert@redhat.com"}, {"url": "http://www.ubuntu.com/usn/USN-2356-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-2357-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-2358-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "http://www.ubuntu.com/usn/USN-2359-1", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1131951", "source": "secalert@redhat.com", "tags": ["Issue Tracking"]}, {"url": "https://exchange.xforce.ibmcloud.com/vulnerabilities/95689", "source": "secalert@redhat.com"}, {"url": "https://github.com/torvalds/linux/commit/350b8bdd689cd2ab2c67c8a86a0be86cfa0751a7", "source": "secalert@redhat.com", "tags": ["Exploit", "Patch"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/350b8bdd689cd2ab2c67c8a86a0be86cfa0751a7"}}
{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0-only\n/*\n * linux/kernel/ptrace.c\n *\n * (C) Copyright 1999 Linus Torvalds\n *\n * Common interfaces for \"ptrace()\" which we do not want\n * to continually duplicate across every architecture.\n */\n\n#include <linux/capability.h>\n#include <linux/export.h>\n#include <linux/sched.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/task.h>\n#include <linux/errno.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/pagemap.h>\n#include <linux/ptrace.h>\n#include <linux/security.h>\n#include <linux/signal.h>\n#include <linux/uio.h>\n#include <linux/audit.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/regset.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/cn_proc.h>\n#include <linux/compat.h>\n#include <linux/sched/signal.h>\n\n/*\n * Access another process' address space via ptrace.\n * Source/target buffer must be kernel space,\n * Do not walk the page table directly, use get_user_pages\n */\nint ptrace_access_vm(struct task_struct *tsk, unsigned long addr,\n\t\t     void *buf, int len, unsigned int gup_flags)\n{\n\tstruct mm_struct *mm;\n\tint ret;\n\n\tmm = get_task_mm(tsk);\n\tif (!mm)\n\t\treturn 0;\n\n\tif (!tsk->ptrace ||\n\t    (current != tsk->parent) ||\n\t    ((get_dumpable(mm) != SUID_DUMP_USER) &&\n\t     !ptracer_capable(tsk, mm->user_ns))) {\n\t\tmmput(mm);\n\t\treturn 0;\n\t}\n\n\tret = __access_remote_vm(tsk, mm, addr, buf, len, gup_flags);\n\tmmput(mm);\n\n\treturn ret;\n}\n\n\nvoid __ptrace_link(struct task_struct *child, struct task_struct *new_parent,\n\t\t   const struct cred *ptracer_cred)\n{\n\tBUG_ON(!list_empty(&child->ptrace_entry));\n\tlist_add(&child->ptrace_entry, &new_parent->ptraced);\n\tchild->parent = new_parent;\n\tchild->ptracer_cred = get_cred(ptracer_cred);\n}\n\n/*\n * ptrace a task: make the debugger its new parent and\n * move it to the ptrace list.\n *\n * Must be called with the tasklist lock write-held.\n */\nstatic void ptrace_link(struct task_struct *child, struct task_struct *new_parent)\n{\n\trcu_read_lock();\n\t__ptrace_link(child, new_parent, __task_cred(new_parent));\n\trcu_read_unlock();\n}\n\n/**\n * __ptrace_unlink - unlink ptracee and restore its execution state\n * @child: ptracee to be unlinked\n *\n * Remove @child from the ptrace list, move it back to the original parent,\n * and restore the execution state so that it conforms to the group stop\n * state.\n *\n * Unlinking can happen via two paths - explicit PTRACE_DETACH or ptracer\n * exiting.  For PTRACE_DETACH, unless the ptracee has been killed between\n * ptrace_check_attach() and here, it's guaranteed to be in TASK_TRACED.\n * If the ptracer is exiting, the ptracee can be in any state.\n *\n * After detach, the ptracee should be in a state which conforms to the\n * group stop.  If the group is stopped or in the process of stopping, the\n * ptracee should be put into TASK_STOPPED; otherwise, it should be woken\n * up from TASK_TRACED.\n *\n * If the ptracee is in TASK_TRACED and needs to be moved to TASK_STOPPED,\n * it goes through TRACED -> RUNNING -> STOPPED transition which is similar\n * to but in the opposite direction of what happens while attaching to a\n * stopped task.  However, in this direction, the intermediate RUNNING\n * state is not hidden even from the current ptracer and if it immediately\n * re-attaches and performs a WNOHANG wait(2), it may fail.\n *\n * CONTEXT:\n * write_lock_irq(tasklist_lock)\n */\nvoid __ptrace_unlink(struct task_struct *child)\n{\n\tconst struct cred *old_cred;\n\tBUG_ON(!child->ptrace);\n\n\tclear_tsk_thread_flag(child, TIF_SYSCALL_TRACE);\n\n\tchild->parent = child->real_parent;\n\tlist_del_init(&child->ptrace_entry);\n\told_cred = child->ptracer_cred;\n\tchild->ptracer_cred = NULL;\n\tput_cred(old_cred);\n\n\tspin_lock(&child->sighand->siglock);\n\tchild->ptrace = 0;\n\t/*\n\t * Clear all pending traps and TRAPPING.  TRAPPING should be\n\t * cleared regardless of JOBCTL_STOP_PENDING.  Do it explicitly.\n\t */\n\ttask_clear_jobctl_pending(child, JOBCTL_TRAP_MASK);\n\ttask_clear_jobctl_trapping(child);\n\n\t/*\n\t * Reinstate JOBCTL_STOP_PENDING if group stop is in effect and\n\t * @child isn't dead.\n\t */\n\tif (!(child->flags & PF_EXITING) &&\n\t    (child->signal->flags & SIGNAL_STOP_STOPPED ||\n\t     child->signal->group_stop_count)) {\n\t\tchild->jobctl |= JOBCTL_STOP_PENDING;\n\n\t\t/*\n\t\t * This is only possible if this thread was cloned by the\n\t\t * traced task running in the stopped group, set the signal\n\t\t * for the future reports.\n\t\t * FIXME: we should change ptrace_init_task() to handle this\n\t\t * case.\n\t\t */\n\t\tif (!(child->jobctl & JOBCTL_STOP_SIGMASK))\n\t\t\tchild->jobctl |= SIGSTOP;\n\t}\n\n\t/*\n\t * If transition to TASK_STOPPED is pending or in TASK_TRACED, kick\n\t * @child in the butt.  Note that @resume should be used iff @child\n\t * is in TASK_TRACED; otherwise, we might unduly disrupt\n\t * TASK_KILLABLE sleeps.\n\t */\n\tif (child->jobctl & JOBCTL_STOP_PENDING || task_is_traced(child))\n\t\tptrace_signal_wake_up(child, true);\n\n\tspin_unlock(&child->sighand->siglock);\n}\n\n/* Ensure that nothing can wake it up, even SIGKILL */\nstatic bool ptrace_freeze_traced(struct task_struct *task)\n{\n\tbool ret = false;\n\n\t/* Lockless, nobody but us can set this flag */\n\tif (task->jobctl & JOBCTL_LISTENING)\n\t\treturn ret;\n\n\tspin_lock_irq(&task->sighand->siglock);\n\tif (task_is_traced(task) && !__fatal_signal_pending(task)) {\n\t\ttask->state = __TASK_TRACED;\n\t\tret = true;\n\t}\n\tspin_unlock_irq(&task->sighand->siglock);\n\n\treturn ret;\n}\n\nstatic void ptrace_unfreeze_traced(struct task_struct *task)\n{\n\tif (task->state != __TASK_TRACED)\n\t\treturn;\n\n\tWARN_ON(!task->ptrace || task->parent != current);\n\n\t/*\n\t * PTRACE_LISTEN can allow ptrace_trap_notify to wake us up remotely.\n\t * Recheck state under the lock to close this race.\n\t */\n\tspin_lock_irq(&task->sighand->siglock);\n\tif (task->state == __TASK_TRACED) {\n\t\tif (__fatal_signal_pending(task))\n\t\t\twake_up_state(task, __TASK_TRACED);\n\t\telse\n\t\t\ttask->state = TASK_TRACED;\n\t}\n\tspin_unlock_irq(&task->sighand->siglock);\n}\n\n/**\n * ptrace_check_attach - check whether ptracee is ready for ptrace operation\n * @child: ptracee to check for\n * @ignore_state: don't check whether @child is currently %TASK_TRACED\n *\n * Check whether @child is being ptraced by %current and ready for further\n * ptrace operations.  If @ignore_state is %false, @child also should be in\n * %TASK_TRACED state and on return the child is guaranteed to be traced\n * and not executing.  If @ignore_state is %true, @child can be in any\n * state.\n *\n * CONTEXT:\n * Grabs and releases tasklist_lock and @child->sighand->siglock.\n *\n * RETURNS:\n * 0 on success, -ESRCH if %child is not ready.\n */\nstatic int ptrace_check_attach(struct task_struct *child, bool ignore_state)\n{\n\tint ret = -ESRCH;\n\n\t/*\n\t * We take the read lock around doing both checks to close a\n\t * possible race where someone else was tracing our child and\n\t * detached between these two checks.  After this locked check,\n\t * we are sure that this is our traced child and that can only\n\t * be changed by us so it's not changing right after this.\n\t */\n\tread_lock(&tasklist_lock);\n\tif (child->ptrace && child->parent == current) {\n\t\tWARN_ON(child->state == __TASK_TRACED);\n\t\t/*\n\t\t * child->sighand can't be NULL, release_task()\n\t\t * does ptrace_unlink() before __exit_signal().\n\t\t */\n\t\tif (ignore_state || ptrace_freeze_traced(child))\n\t\t\tret = 0;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\tif (!ret && !ignore_state) {\n\t\tif (!wait_task_inactive(child, __TASK_TRACED)) {\n\t\t\t/*\n\t\t\t * This can only happen if may_ptrace_stop() fails and\n\t\t\t * ptrace_stop() changes ->state back to TASK_RUNNING,\n\t\t\t * so we should not worry about leaking __TASK_TRACED.\n\t\t\t */\n\t\t\tWARN_ON(child->state == __TASK_TRACED);\n\t\t\tret = -ESRCH;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int ptrace_has_cap(struct user_namespace *ns, unsigned int mode)\n{\n\tif (mode & PTRACE_MODE_NOAUDIT)\n\t\treturn has_ns_capability_noaudit(current, ns, CAP_SYS_PTRACE);\n\telse\n\t\treturn has_ns_capability(current, ns, CAP_SYS_PTRACE);\n}\n\n/* Returns 0 on success, -errno on denial. */\nstatic int __ptrace_may_access(struct task_struct *task, unsigned int mode)\n{\n\tconst struct cred *cred = current_cred(), *tcred;\n\tstruct mm_struct *mm;\n\tkuid_t caller_uid;\n\tkgid_t caller_gid;\n\n\tif (!(mode & PTRACE_MODE_FSCREDS) == !(mode & PTRACE_MODE_REALCREDS)) {\n\t\tWARN(1, \"denying ptrace access check without PTRACE_MODE_*CREDS\\n\");\n\t\treturn -EPERM;\n\t}\n\n\t/* May we inspect the given task?\n\t * This check is used both for attaching with ptrace\n\t * and for allowing access to sensitive information in /proc.\n\t *\n\t * ptrace_attach denies several cases that /proc allows\n\t * because setting up the necessary parent/child relationship\n\t * or halting the specified task is impossible.\n\t */\n\n\t/* Don't let security modules deny introspection */\n\tif (same_thread_group(task, current))\n\t\treturn 0;\n\trcu_read_lock();\n\tif (mode & PTRACE_MODE_FSCREDS) {\n\t\tcaller_uid = cred->fsuid;\n\t\tcaller_gid = cred->fsgid;\n\t} else {\n\t\t/*\n\t\t * Using the euid would make more sense here, but something\n\t\t * in userland might rely on the old behavior, and this\n\t\t * shouldn't be a security problem since\n\t\t * PTRACE_MODE_REALCREDS implies that the caller explicitly\n\t\t * used a syscall that requests access to another process\n\t\t * (and not a filesystem syscall to procfs).\n\t\t */\n\t\tcaller_uid = cred->uid;\n\t\tcaller_gid = cred->gid;\n\t}\n\ttcred = __task_cred(task);\n\tif (uid_eq(caller_uid, tcred->euid) &&\n\t    uid_eq(caller_uid, tcred->suid) &&\n\t    uid_eq(caller_uid, tcred->uid)  &&\n\t    gid_eq(caller_gid, tcred->egid) &&\n\t    gid_eq(caller_gid, tcred->sgid) &&\n\t    gid_eq(caller_gid, tcred->gid))\n\t\tgoto ok;\n\tif (ptrace_has_cap(tcred->user_ns, mode))\n\t\tgoto ok;\n\trcu_read_unlock();\n\treturn -EPERM;\nok:\n\trcu_read_unlock();\n\t/*\n\t * If a task drops privileges and becomes nondumpable (through a syscall\n\t * like setresuid()) while we are trying to access it, we must ensure\n\t * that the dumpability is read after the credentials; otherwise,\n\t * we may be able to attach to a task that we shouldn't be able to\n\t * attach to (as if the task had dropped privileges without becoming\n\t * nondumpable).\n\t * Pairs with a write barrier in commit_creds().\n\t */\n\tsmp_rmb();\n\tmm = task->mm;\n\tif (mm &&\n\t    ((get_dumpable(mm) != SUID_DUMP_USER) &&\n\t     !ptrace_has_cap(mm->user_ns, mode)))\n\t    return -EPERM;\n\n\treturn security_ptrace_access_check(task, mode);\n}\n\nbool ptrace_may_access(struct task_struct *task, unsigned int mode)\n{\n\tint err;\n\ttask_lock(task);\n\terr = __ptrace_may_access(task, mode);\n\ttask_unlock(task);\n\treturn !err;\n}\n\nstatic int ptrace_attach(struct task_struct *task, long request,\n\t\t\t unsigned long addr,\n\t\t\t unsigned long flags)\n{\n\tbool seize = (request == PTRACE_SEIZE);\n\tint retval;\n\n\tretval = -EIO;\n\tif (seize) {\n\t\tif (addr != 0)\n\t\t\tgoto out;\n\t\tif (flags & ~(unsigned long)PTRACE_O_MASK)\n\t\t\tgoto out;\n\t\tflags = PT_PTRACED | PT_SEIZED | (flags << PT_OPT_FLAG_SHIFT);\n\t} else {\n\t\tflags = PT_PTRACED;\n\t}\n\n\taudit_ptrace(task);\n\n\tretval = -EPERM;\n\tif (unlikely(task->flags & PF_KTHREAD))\n\t\tgoto out;\n\tif (same_thread_group(task, current))\n\t\tgoto out;\n\n\t/*\n\t * Protect exec's credential calculations against our interference;\n\t * SUID, SGID and LSM creds get determined differently\n\t * under ptrace.\n\t */\n\tretval = -ERESTARTNOINTR;\n\tif (mutex_lock_interruptible(&task->signal->cred_guard_mutex))\n\t\tgoto out;\n\n\ttask_lock(task);\n\tretval = __ptrace_may_access(task, PTRACE_MODE_ATTACH_REALCREDS);\n\ttask_unlock(task);\n\tif (retval)\n\t\tgoto unlock_creds;\n\n\twrite_lock_irq(&tasklist_lock);\n\tretval = -EPERM;\n\tif (unlikely(task->exit_state))\n\t\tgoto unlock_tasklist;\n\tif (task->ptrace)\n\t\tgoto unlock_tasklist;\n\n\tif (seize)\n\t\tflags |= PT_SEIZED;\n\ttask->ptrace = flags;\n\n\tptrace_link(task, current);\n\n\t/* SEIZE doesn't trap tracee on attach */\n\tif (!seize)\n\t\tsend_sig_info(SIGSTOP, SEND_SIG_PRIV, task);\n\n\tspin_lock(&task->sighand->siglock);\n\n\t/*\n\t * If the task is already STOPPED, set JOBCTL_TRAP_STOP and\n\t * TRAPPING, and kick it so that it transits to TRACED.  TRAPPING\n\t * will be cleared if the child completes the transition or any\n\t * event which clears the group stop states happens.  We'll wait\n\t * for the transition to complete before returning from this\n\t * function.\n\t *\n\t * This hides STOPPED -> RUNNING -> TRACED transition from the\n\t * attaching thread but a different thread in the same group can\n\t * still observe the transient RUNNING state.  IOW, if another\n\t * thread's WNOHANG wait(2) on the stopped tracee races against\n\t * ATTACH, the wait(2) may fail due to the transient RUNNING.\n\t *\n\t * The following task_is_stopped() test is safe as both transitions\n\t * in and out of STOPPED are protected by siglock.\n\t */\n\tif (task_is_stopped(task) &&\n\t    task_set_jobctl_pending(task, JOBCTL_TRAP_STOP | JOBCTL_TRAPPING))\n\t\tsignal_wake_up_state(task, __TASK_STOPPED);\n\n\tspin_unlock(&task->sighand->siglock);\n\n\tretval = 0;\nunlock_tasklist:\n\twrite_unlock_irq(&tasklist_lock);\nunlock_creds:\n\tmutex_unlock(&task->signal->cred_guard_mutex);\nout:\n\tif (!retval) {\n\t\t/*\n\t\t * We do not bother to change retval or clear JOBCTL_TRAPPING\n\t\t * if wait_on_bit() was interrupted by SIGKILL. The tracer will\n\t\t * not return to user-mode, it will exit and clear this bit in\n\t\t * __ptrace_unlink() if it wasn't already cleared by the tracee;\n\t\t * and until then nobody can ptrace this task.\n\t\t */\n\t\twait_on_bit(&task->jobctl, JOBCTL_TRAPPING_BIT, TASK_KILLABLE);\n\t\tproc_ptrace_connector(task, PTRACE_ATTACH);\n\t}\n\n\treturn retval;\n}\n\n/**\n * ptrace_traceme  --  helper for PTRACE_TRACEME\n *\n * Performs checks and sets PT_PTRACED.\n * Should be used by all ptrace implementations for PTRACE_TRACEME.\n */\nstatic int ptrace_traceme(void)\n{\n\tint ret = -EPERM;\n\n\twrite_lock_irq(&tasklist_lock);\n\t/* Are we already being traced? */\n\tif (!current->ptrace) {\n\t\tret = security_ptrace_traceme(current->parent);\n\t\t/*\n\t\t * Check PF_EXITING to ensure ->real_parent has not passed\n\t\t * exit_ptrace(). Otherwise we don't report the error but\n\t\t * pretend ->real_parent untraces us right after return.\n\t\t */\n\t\tif (!ret && !(current->real_parent->flags & PF_EXITING)) {\n\t\t\tcurrent->ptrace = PT_PTRACED;\n\t\t\tptrace_link(current, current->real_parent);\n\t\t}\n\t}\n\twrite_unlock_irq(&tasklist_lock);\n\n\treturn ret;\n}\n\n/*\n * Called with irqs disabled, returns true if childs should reap themselves.\n */\nstatic int ignoring_children(struct sighand_struct *sigh)\n{\n\tint ret;\n\tspin_lock(&sigh->siglock);\n\tret = (sigh->action[SIGCHLD-1].sa.sa_handler == SIG_IGN) ||\n\t      (sigh->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT);\n\tspin_unlock(&sigh->siglock);\n\treturn ret;\n}\n\n/*\n * Called with tasklist_lock held for writing.\n * Unlink a traced task, and clean it up if it was a traced zombie.\n * Return true if it needs to be reaped with release_task().\n * (We can't call release_task() here because we already hold tasklist_lock.)\n *\n * If it's a zombie, our attachedness prevented normal parent notification\n * or self-reaping.  Do notification now if it would have happened earlier.\n * If it should reap itself, return true.\n *\n * If it's our own child, there is no notification to do. But if our normal\n * children self-reap, then this child was prevented by ptrace and we must\n * reap it now, in that case we must also wake up sub-threads sleeping in\n * do_wait().\n */\nstatic bool __ptrace_detach(struct task_struct *tracer, struct task_struct *p)\n{\n\tbool dead;\n\n\t__ptrace_unlink(p);\n\n\tif (p->exit_state != EXIT_ZOMBIE)\n\t\treturn false;\n\n\tdead = !thread_group_leader(p);\n\n\tif (!dead && thread_group_empty(p)) {\n\t\tif (!same_thread_group(p->real_parent, tracer))\n\t\t\tdead = do_notify_parent(p, p->exit_signal);\n\t\telse if (ignoring_children(tracer->sighand)) {\n\t\t\t__wake_up_parent(p, tracer);\n\t\t\tdead = true;\n\t\t}\n\t}\n\t/* Mark it as in the process of being reaped. */\n\tif (dead)\n\t\tp->exit_state = EXIT_DEAD;\n\treturn dead;\n}\n\nstatic int ptrace_detach(struct task_struct *child, unsigned int data)\n{\n\tif (!valid_signal(data))\n\t\treturn -EIO;\n\n\t/* Architecture-specific hardware disable .. */\n\tptrace_disable(child);\n\n\twrite_lock_irq(&tasklist_lock);\n\t/*\n\t * We rely on ptrace_freeze_traced(). It can't be killed and\n\t * untraced by another thread, it can't be a zombie.\n\t */\n\tWARN_ON(!child->ptrace || child->exit_state);\n\t/*\n\t * tasklist_lock avoids the race with wait_task_stopped(), see\n\t * the comment in ptrace_resume().\n\t */\n\tchild->exit_code = data;\n\t__ptrace_detach(current, child);\n\twrite_unlock_irq(&tasklist_lock);\n\n\tproc_ptrace_connector(child, PTRACE_DETACH);\n\n\treturn 0;\n}\n\n/*\n * Detach all tasks we were using ptrace on. Called with tasklist held\n * for writing.\n */\nvoid exit_ptrace(struct task_struct *tracer, struct list_head *dead)\n{\n\tstruct task_struct *p, *n;\n\n\tlist_for_each_entry_safe(p, n, &tracer->ptraced, ptrace_entry) {\n\t\tif (unlikely(p->ptrace & PT_EXITKILL))\n\t\t\tsend_sig_info(SIGKILL, SEND_SIG_PRIV, p);\n\n\t\tif (__ptrace_detach(tracer, p))\n\t\t\tlist_add(&p->ptrace_entry, dead);\n\t}\n}\n\nint ptrace_readdata(struct task_struct *tsk, unsigned long src, char __user *dst, int len)\n{\n\tint copied = 0;\n\n\twhile (len > 0) {\n\t\tchar buf[128];\n\t\tint this_len, retval;\n\n\t\tthis_len = (len > sizeof(buf)) ? sizeof(buf) : len;\n\t\tretval = ptrace_access_vm(tsk, src, buf, this_len, FOLL_FORCE);\n\n\t\tif (!retval) {\n\t\t\tif (copied)\n\t\t\t\tbreak;\n\t\t\treturn -EIO;\n\t\t}\n\t\tif (copy_to_user(dst, buf, retval))\n\t\t\treturn -EFAULT;\n\t\tcopied += retval;\n\t\tsrc += retval;\n\t\tdst += retval;\n\t\tlen -= retval;\n\t}\n\treturn copied;\n}\n\nint ptrace_writedata(struct task_struct *tsk, char __user *src, unsigned long dst, int len)\n{\n\tint copied = 0;\n\n\twhile (len > 0) {\n\t\tchar buf[128];\n\t\tint this_len, retval;\n\n\t\tthis_len = (len > sizeof(buf)) ? sizeof(buf) : len;\n\t\tif (copy_from_user(buf, src, this_len))\n\t\t\treturn -EFAULT;\n\t\tretval = ptrace_access_vm(tsk, dst, buf, this_len,\n\t\t\t\tFOLL_FORCE | FOLL_WRITE);\n\t\tif (!retval) {\n\t\t\tif (copied)\n\t\t\t\tbreak;\n\t\t\treturn -EIO;\n\t\t}\n\t\tcopied += retval;\n\t\tsrc += retval;\n\t\tdst += retval;\n\t\tlen -= retval;\n\t}\n\treturn copied;\n}\n\nstatic int ptrace_setoptions(struct task_struct *child, unsigned long data)\n{\n\tunsigned flags;\n\n\tif (data & ~(unsigned long)PTRACE_O_MASK)\n\t\treturn -EINVAL;\n\n\tif (unlikely(data & PTRACE_O_SUSPEND_SECCOMP)) {\n\t\tif (!IS_ENABLED(CONFIG_CHECKPOINT_RESTORE) ||\n\t\t    !IS_ENABLED(CONFIG_SECCOMP))\n\t\t\treturn -EINVAL;\n\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\n\t\tif (seccomp_mode(&current->seccomp) != SECCOMP_MODE_DISABLED ||\n\t\t    current->ptrace & PT_SUSPEND_SECCOMP)\n\t\t\treturn -EPERM;\n\t}\n\n\t/* Avoid intermediate state when all opts are cleared */\n\tflags = child->ptrace;\n\tflags &= ~(PTRACE_O_MASK << PT_OPT_FLAG_SHIFT);\n\tflags |= (data << PT_OPT_FLAG_SHIFT);\n\tchild->ptrace = flags;\n\n\treturn 0;\n}\n\nstatic int ptrace_getsiginfo(struct task_struct *child, kernel_siginfo_t *info)\n{\n\tunsigned long flags;\n\tint error = -ESRCH;\n\n\tif (lock_task_sighand(child, &flags)) {\n\t\terror = -EINVAL;\n\t\tif (likely(child->last_siginfo != NULL)) {\n\t\t\tcopy_siginfo(info, child->last_siginfo);\n\t\t\terror = 0;\n\t\t}\n\t\tunlock_task_sighand(child, &flags);\n\t}\n\treturn error;\n}\n\nstatic int ptrace_setsiginfo(struct task_struct *child, const kernel_siginfo_t *info)\n{\n\tunsigned long flags;\n\tint error = -ESRCH;\n\n\tif (lock_task_sighand(child, &flags)) {\n\t\terror = -EINVAL;\n\t\tif (likely(child->last_siginfo != NULL)) {\n\t\t\tcopy_siginfo(child->last_siginfo, info);\n\t\t\terror = 0;\n\t\t}\n\t\tunlock_task_sighand(child, &flags);\n\t}\n\treturn error;\n}\n\nstatic int ptrace_peek_siginfo(struct task_struct *child,\n\t\t\t\tunsigned long addr,\n\t\t\t\tunsigned long data)\n{\n\tstruct ptrace_peeksiginfo_args arg;\n\tstruct sigpending *pending;\n\tstruct sigqueue *q;\n\tint ret, i;\n\n\tret = copy_from_user(&arg, (void __user *) addr,\n\t\t\t\tsizeof(struct ptrace_peeksiginfo_args));\n\tif (ret)\n\t\treturn -EFAULT;\n\n\tif (arg.flags & ~PTRACE_PEEKSIGINFO_SHARED)\n\t\treturn -EINVAL; /* unknown flags */\n\n\tif (arg.nr < 0)\n\t\treturn -EINVAL;\n\n\t/* Ensure arg.off fits in an unsigned long */\n\tif (arg.off > ULONG_MAX)\n\t\treturn 0;\n\n\tif (arg.flags & PTRACE_PEEKSIGINFO_SHARED)\n\t\tpending = &child->signal->shared_pending;\n\telse\n\t\tpending = &child->pending;\n\n\tfor (i = 0; i < arg.nr; ) {\n\t\tkernel_siginfo_t info;\n\t\tunsigned long off = arg.off + i;\n\t\tbool found = false;\n\n\t\tspin_lock_irq(&child->sighand->siglock);\n\t\tlist_for_each_entry(q, &pending->list, list) {\n\t\t\tif (!off--) {\n\t\t\t\tfound = true;\n\t\t\t\tcopy_siginfo(&info, &q->info);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irq(&child->sighand->siglock);\n\n\t\tif (!found) /* beyond the end of the list */\n\t\t\tbreak;\n\n#ifdef CONFIG_COMPAT\n\t\tif (unlikely(in_compat_syscall())) {\n\t\t\tcompat_siginfo_t __user *uinfo = compat_ptr(data);\n\n\t\t\tif (copy_siginfo_to_user32(uinfo, &info)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t} else\n#endif\n\t\t{\n\t\t\tsiginfo_t __user *uinfo = (siginfo_t __user *) data;\n\n\t\t\tif (copy_siginfo_to_user(uinfo, &info)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tdata += sizeof(siginfo_t);\n\t\ti++;\n\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\n\t\tcond_resched();\n\t}\n\n\tif (i > 0)\n\t\treturn i;\n\n\treturn ret;\n}\n\n#ifdef PTRACE_SINGLESTEP\n#define is_singlestep(request)\t\t((request) == PTRACE_SINGLESTEP)\n#else\n#define is_singlestep(request)\t\t0\n#endif\n\n#ifdef PTRACE_SINGLEBLOCK\n#define is_singleblock(request)\t\t((request) == PTRACE_SINGLEBLOCK)\n#else\n#define is_singleblock(request)\t\t0\n#endif\n\n#ifdef PTRACE_SYSEMU\n#define is_sysemu_singlestep(request)\t((request) == PTRACE_SYSEMU_SINGLESTEP)\n#else\n#define is_sysemu_singlestep(request)\t0\n#endif\n\nstatic int ptrace_resume(struct task_struct *child, long request,\n\t\t\t unsigned long data)\n{\n\tbool need_siglock;\n\n\tif (!valid_signal(data))\n\t\treturn -EIO;\n\n\tif (request == PTRACE_SYSCALL)\n\t\tset_tsk_thread_flag(child, TIF_SYSCALL_TRACE);\n\telse\n\t\tclear_tsk_thread_flag(child, TIF_SYSCALL_TRACE);\n\n#ifdef TIF_SYSCALL_EMU\n\tif (request == PTRACE_SYSEMU || request == PTRACE_SYSEMU_SINGLESTEP)\n\t\tset_tsk_thread_flag(child, TIF_SYSCALL_EMU);\n\telse\n\t\tclear_tsk_thread_flag(child, TIF_SYSCALL_EMU);\n#endif\n\n\tif (is_singleblock(request)) {\n\t\tif (unlikely(!arch_has_block_step()))\n\t\t\treturn -EIO;\n\t\tuser_enable_block_step(child);\n\t} else if (is_singlestep(request) || is_sysemu_singlestep(request)) {\n\t\tif (unlikely(!arch_has_single_step()))\n\t\t\treturn -EIO;\n\t\tuser_enable_single_step(child);\n\t} else {\n\t\tuser_disable_single_step(child);\n\t}\n\n\t/*\n\t * Change ->exit_code and ->state under siglock to avoid the race\n\t * with wait_task_stopped() in between; a non-zero ->exit_code will\n\t * wrongly look like another report from tracee.\n\t *\n\t * Note that we need siglock even if ->exit_code == data and/or this\n\t * status was not reported yet, the new status must not be cleared by\n\t * wait_task_stopped() after resume.\n\t *\n\t * If data == 0 we do not care if wait_task_stopped() reports the old\n\t * status and clears the code too; this can't race with the tracee, it\n\t * takes siglock after resume.\n\t */\n\tneed_siglock = data && !thread_group_empty(current);\n\tif (need_siglock)\n\t\tspin_lock_irq(&child->sighand->siglock);\n\tchild->exit_code = data;\n\twake_up_state(child, __TASK_TRACED);\n\tif (need_siglock)\n\t\tspin_unlock_irq(&child->sighand->siglock);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_HAVE_ARCH_TRACEHOOK\n\nstatic const struct user_regset *\nfind_regset(const struct user_regset_view *view, unsigned int type)\n{\n\tconst struct user_regset *regset;\n\tint n;\n\n\tfor (n = 0; n < view->n; ++n) {\n\t\tregset = view->regsets + n;\n\t\tif (regset->core_note_type == type)\n\t\t\treturn regset;\n\t}\n\n\treturn NULL;\n}\n\nstatic int ptrace_regset(struct task_struct *task, int req, unsigned int type,\n\t\t\t struct iovec *kiov)\n{\n\tconst struct user_regset_view *view = task_user_regset_view(task);\n\tconst struct user_regset *regset = find_regset(view, type);\n\tint regset_no;\n\n\tif (!regset || (kiov->iov_len % regset->size) != 0)\n\t\treturn -EINVAL;\n\n\tregset_no = regset - view->regsets;\n\tkiov->iov_len = min(kiov->iov_len,\n\t\t\t    (__kernel_size_t) (regset->n * regset->size));\n\n\tif (req == PTRACE_GETREGSET)\n\t\treturn copy_regset_to_user(task, view, regset_no, 0,\n\t\t\t\t\t   kiov->iov_len, kiov->iov_base);\n\telse\n\t\treturn copy_regset_from_user(task, view, regset_no, 0,\n\t\t\t\t\t     kiov->iov_len, kiov->iov_base);\n}\n\n/*\n * This is declared in linux/regset.h and defined in machine-dependent\n * code.  We put the export here, near the primary machine-neutral use,\n * to ensure no machine forgets it.\n */\nEXPORT_SYMBOL_GPL(task_user_regset_view);\n#endif\n\nint ptrace_request(struct task_struct *child, long request,\n\t\t   unsigned long addr, unsigned long data)\n{\n\tbool seized = child->ptrace & PT_SEIZED;\n\tint ret = -EIO;\n\tkernel_siginfo_t siginfo, *si;\n\tvoid __user *datavp = (void __user *) data;\n\tunsigned long __user *datalp = datavp;\n\tunsigned long flags;\n\n\tswitch (request) {\n\tcase PTRACE_PEEKTEXT:\n\tcase PTRACE_PEEKDATA:\n\t\treturn generic_ptrace_peekdata(child, addr, data);\n\tcase PTRACE_POKETEXT:\n\tcase PTRACE_POKEDATA:\n\t\treturn generic_ptrace_pokedata(child, addr, data);\n\n#ifdef PTRACE_OLDSETOPTIONS\n\tcase PTRACE_OLDSETOPTIONS:\n#endif\n\tcase PTRACE_SETOPTIONS:\n\t\tret = ptrace_setoptions(child, data);\n\t\tbreak;\n\tcase PTRACE_GETEVENTMSG:\n\t\tret = put_user(child->ptrace_message, datalp);\n\t\tbreak;\n\n\tcase PTRACE_PEEKSIGINFO:\n\t\tret = ptrace_peek_siginfo(child, addr, data);\n\t\tbreak;\n\n\tcase PTRACE_GETSIGINFO:\n\t\tret = ptrace_getsiginfo(child, &siginfo);\n\t\tif (!ret)\n\t\t\tret = copy_siginfo_to_user(datavp, &siginfo);\n\t\tbreak;\n\n\tcase PTRACE_SETSIGINFO:\n\t\tret = copy_siginfo_from_user(&siginfo, datavp);\n\t\tif (!ret)\n\t\t\tret = ptrace_setsiginfo(child, &siginfo);\n\t\tbreak;\n\n\tcase PTRACE_GETSIGMASK: {\n\t\tsigset_t *mask;\n\n\t\tif (addr != sizeof(sigset_t)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (test_tsk_restore_sigmask(child))\n\t\t\tmask = &child->saved_sigmask;\n\t\telse\n\t\t\tmask = &child->blocked;\n\n\t\tif (copy_to_user(datavp, mask, sizeof(sigset_t)))\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = 0;\n\n\t\tbreak;\n\t}\n\n\tcase PTRACE_SETSIGMASK: {\n\t\tsigset_t new_set;\n\n\t\tif (addr != sizeof(sigset_t)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (copy_from_user(&new_set, datavp, sizeof(sigset_t))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tsigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));\n\n\t\t/*\n\t\t * Every thread does recalc_sigpending() after resume, so\n\t\t * retarget_shared_pending() and recalc_sigpending() are not\n\t\t * called here.\n\t\t */\n\t\tspin_lock_irq(&child->sighand->siglock);\n\t\tchild->blocked = new_set;\n\t\tspin_unlock_irq(&child->sighand->siglock);\n\n\t\tclear_tsk_restore_sigmask(child);\n\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n\tcase PTRACE_INTERRUPT:\n\t\t/*\n\t\t * Stop tracee without any side-effect on signal or job\n\t\t * control.  At least one trap is guaranteed to happen\n\t\t * after this request.  If @child is already trapped, the\n\t\t * current trap is not disturbed and another trap will\n\t\t * happen after the current trap is ended with PTRACE_CONT.\n\t\t *\n\t\t * The actual trap might not be PTRACE_EVENT_STOP trap but\n\t\t * the pending condition is cleared regardless.\n\t\t */\n\t\tif (unlikely(!seized || !lock_task_sighand(child, &flags)))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * INTERRUPT doesn't disturb existing trap sans one\n\t\t * exception.  If ptracer issued LISTEN for the current\n\t\t * STOP, this INTERRUPT should clear LISTEN and re-trap\n\t\t * tracee into STOP.\n\t\t */\n\t\tif (likely(task_set_jobctl_pending(child, JOBCTL_TRAP_STOP)))\n\t\t\tptrace_signal_wake_up(child, child->jobctl & JOBCTL_LISTENING);\n\n\t\tunlock_task_sighand(child, &flags);\n\t\tret = 0;\n\t\tbreak;\n\n\tcase PTRACE_LISTEN:\n\t\t/*\n\t\t * Listen for events.  Tracee must be in STOP.  It's not\n\t\t * resumed per-se but is not considered to be in TRACED by\n\t\t * wait(2) or ptrace(2).  If an async event (e.g. group\n\t\t * stop state change) happens, tracee will enter STOP trap\n\t\t * again.  Alternatively, ptracer can issue INTERRUPT to\n\t\t * finish listening and re-trap tracee into STOP.\n\t\t */\n\t\tif (unlikely(!seized || !lock_task_sighand(child, &flags)))\n\t\t\tbreak;\n\n\t\tsi = child->last_siginfo;\n\t\tif (likely(si && (si->si_code >> 8) == PTRACE_EVENT_STOP)) {\n\t\t\tchild->jobctl |= JOBCTL_LISTENING;\n\t\t\t/*\n\t\t\t * If NOTIFY is set, it means event happened between\n\t\t\t * start of this trap and now.  Trigger re-trap.\n\t\t\t */\n\t\t\tif (child->jobctl & JOBCTL_TRAP_NOTIFY)\n\t\t\t\tptrace_signal_wake_up(child, true);\n\t\t\tret = 0;\n\t\t}\n\t\tunlock_task_sighand(child, &flags);\n\t\tbreak;\n\n\tcase PTRACE_DETACH:\t /* detach a process that was attached. */\n\t\tret = ptrace_detach(child, data);\n\t\tbreak;\n\n#ifdef CONFIG_BINFMT_ELF_FDPIC\n\tcase PTRACE_GETFDPIC: {\n\t\tstruct mm_struct *mm = get_task_mm(child);\n\t\tunsigned long tmp = 0;\n\n\t\tret = -ESRCH;\n\t\tif (!mm)\n\t\t\tbreak;\n\n\t\tswitch (addr) {\n\t\tcase PTRACE_GETFDPIC_EXEC:\n\t\t\ttmp = mm->context.exec_fdpic_loadmap;\n\t\t\tbreak;\n\t\tcase PTRACE_GETFDPIC_INTERP:\n\t\t\ttmp = mm->context.interp_fdpic_loadmap;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tmmput(mm);\n\n\t\tret = put_user(tmp, datalp);\n\t\tbreak;\n\t}\n#endif\n\n#ifdef PTRACE_SINGLESTEP\n\tcase PTRACE_SINGLESTEP:\n#endif\n#ifdef PTRACE_SINGLEBLOCK\n\tcase PTRACE_SINGLEBLOCK:\n#endif\n#ifdef PTRACE_SYSEMU\n\tcase PTRACE_SYSEMU:\n\tcase PTRACE_SYSEMU_SINGLESTEP:\n#endif\n\tcase PTRACE_SYSCALL:\n\tcase PTRACE_CONT:\n\t\treturn ptrace_resume(child, request, data);\n\n\tcase PTRACE_KILL:\n\t\tif (child->exit_state)\t/* already dead */\n\t\t\treturn 0;\n\t\treturn ptrace_resume(child, request, SIGKILL);\n\n#ifdef CONFIG_HAVE_ARCH_TRACEHOOK\n\tcase PTRACE_GETREGSET:\n\tcase PTRACE_SETREGSET: {\n\t\tstruct iovec kiov;\n\t\tstruct iovec __user *uiov = datavp;\n\n\t\tif (!access_ok(uiov, sizeof(*uiov)))\n\t\t\treturn -EFAULT;\n\n\t\tif (__get_user(kiov.iov_base, &uiov->iov_base) ||\n\t\t    __get_user(kiov.iov_len, &uiov->iov_len))\n\t\t\treturn -EFAULT;\n\n\t\tret = ptrace_regset(child, request, addr, &kiov);\n\t\tif (!ret)\n\t\t\tret = __put_user(kiov.iov_len, &uiov->iov_len);\n\t\tbreak;\n\t}\n#endif\n\n\tcase PTRACE_SECCOMP_GET_FILTER:\n\t\tret = seccomp_get_filter(child, addr, datavp);\n\t\tbreak;\n\n\tcase PTRACE_SECCOMP_GET_METADATA:\n\t\tret = seccomp_get_metadata(child, addr, datavp);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n#ifndef arch_ptrace_attach\n#define arch_ptrace_attach(child)\tdo { } while (0)\n#endif\n\nSYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr,\n\t\tunsigned long, data)\n{\n\tstruct task_struct *child;\n\tlong ret;\n\n\tif (request == PTRACE_TRACEME) {\n\t\tret = ptrace_traceme();\n\t\tif (!ret)\n\t\t\tarch_ptrace_attach(current);\n\t\tgoto out;\n\t}\n\n\tchild = find_get_task_by_vpid(pid);\n\tif (!child) {\n\t\tret = -ESRCH;\n\t\tgoto out;\n\t}\n\n\tif (request == PTRACE_ATTACH || request == PTRACE_SEIZE) {\n\t\tret = ptrace_attach(child, request, addr, data);\n\t\t/*\n\t\t * Some architectures need to do book-keeping after\n\t\t * a ptrace attach.\n\t\t */\n\t\tif (!ret)\n\t\t\tarch_ptrace_attach(child);\n\t\tgoto out_put_task_struct;\n\t}\n\n\tret = ptrace_check_attach(child, request == PTRACE_KILL ||\n\t\t\t\t  request == PTRACE_INTERRUPT);\n\tif (ret < 0)\n\t\tgoto out_put_task_struct;\n\n\tret = arch_ptrace(child, request, addr, data);\n\tif (ret || request != PTRACE_DETACH)\n\t\tptrace_unfreeze_traced(child);\n\n out_put_task_struct:\n\tput_task_struct(child);\n out:\n\treturn ret;\n}\n\nint generic_ptrace_peekdata(struct task_struct *tsk, unsigned long addr,\n\t\t\t    unsigned long data)\n{\n\tunsigned long tmp;\n\tint copied;\n\n\tcopied = ptrace_access_vm(tsk, addr, &tmp, sizeof(tmp), FOLL_FORCE);\n\tif (copied != sizeof(tmp))\n\t\treturn -EIO;\n\treturn put_user(tmp, (unsigned long __user *)data);\n}\n\nint generic_ptrace_pokedata(struct task_struct *tsk, unsigned long addr,\n\t\t\t    unsigned long data)\n{\n\tint copied;\n\n\tcopied = ptrace_access_vm(tsk, addr, &data, sizeof(data),\n\t\t\tFOLL_FORCE | FOLL_WRITE);\n\treturn (copied == sizeof(data)) ? 0 : -EIO;\n}\n\n#if defined CONFIG_COMPAT\n\nint compat_ptrace_request(struct task_struct *child, compat_long_t request,\n\t\t\t  compat_ulong_t addr, compat_ulong_t data)\n{\n\tcompat_ulong_t __user *datap = compat_ptr(data);\n\tcompat_ulong_t word;\n\tkernel_siginfo_t siginfo;\n\tint ret;\n\n\tswitch (request) {\n\tcase PTRACE_PEEKTEXT:\n\tcase PTRACE_PEEKDATA:\n\t\tret = ptrace_access_vm(child, addr, &word, sizeof(word),\n\t\t\t\tFOLL_FORCE);\n\t\tif (ret != sizeof(word))\n\t\t\tret = -EIO;\n\t\telse\n\t\t\tret = put_user(word, datap);\n\t\tbreak;\n\n\tcase PTRACE_POKETEXT:\n\tcase PTRACE_POKEDATA:\n\t\tret = ptrace_access_vm(child, addr, &data, sizeof(data),\n\t\t\t\tFOLL_FORCE | FOLL_WRITE);\n\t\tret = (ret != sizeof(data) ? -EIO : 0);\n\t\tbreak;\n\n\tcase PTRACE_GETEVENTMSG:\n\t\tret = put_user((compat_ulong_t) child->ptrace_message, datap);\n\t\tbreak;\n\n\tcase PTRACE_GETSIGINFO:\n\t\tret = ptrace_getsiginfo(child, &siginfo);\n\t\tif (!ret)\n\t\t\tret = copy_siginfo_to_user32(\n\t\t\t\t(struct compat_siginfo __user *) datap,\n\t\t\t\t&siginfo);\n\t\tbreak;\n\n\tcase PTRACE_SETSIGINFO:\n\t\tret = copy_siginfo_from_user32(\n\t\t\t&siginfo, (struct compat_siginfo __user *) datap);\n\t\tif (!ret)\n\t\t\tret = ptrace_setsiginfo(child, &siginfo);\n\t\tbreak;\n#ifdef CONFIG_HAVE_ARCH_TRACEHOOK\n\tcase PTRACE_GETREGSET:\n\tcase PTRACE_SETREGSET:\n\t{\n\t\tstruct iovec kiov;\n\t\tstruct compat_iovec __user *uiov =\n\t\t\t(struct compat_iovec __user *) datap;\n\t\tcompat_uptr_t ptr;\n\t\tcompat_size_t len;\n\n\t\tif (!access_ok(uiov, sizeof(*uiov)))\n\t\t\treturn -EFAULT;\n\n\t\tif (__get_user(ptr, &uiov->iov_base) ||\n\t\t    __get_user(len, &uiov->iov_len))\n\t\t\treturn -EFAULT;\n\n\t\tkiov.iov_base = compat_ptr(ptr);\n\t\tkiov.iov_len = len;\n\n\t\tret = ptrace_regset(child, request, addr, &kiov);\n\t\tif (!ret)\n\t\t\tret = __put_user(kiov.iov_len, &uiov->iov_len);\n\t\tbreak;\n\t}\n#endif\n\n\tdefault:\n\t\tret = ptrace_request(child, request, addr, data);\n\t}\n\n\treturn ret;\n}\n\nCOMPAT_SYSCALL_DEFINE4(ptrace, compat_long_t, request, compat_long_t, pid,\n\t\t       compat_long_t, addr, compat_long_t, data)\n{\n\tstruct task_struct *child;\n\tlong ret;\n\n\tif (request == PTRACE_TRACEME) {\n\t\tret = ptrace_traceme();\n\t\tgoto out;\n\t}\n\n\tchild = find_get_task_by_vpid(pid);\n\tif (!child) {\n\t\tret = -ESRCH;\n\t\tgoto out;\n\t}\n\n\tif (request == PTRACE_ATTACH || request == PTRACE_SEIZE) {\n\t\tret = ptrace_attach(child, request, addr, data);\n\t\t/*\n\t\t * Some architectures need to do book-keeping after\n\t\t * a ptrace attach.\n\t\t */\n\t\tif (!ret)\n\t\t\tarch_ptrace_attach(child);\n\t\tgoto out_put_task_struct;\n\t}\n\n\tret = ptrace_check_attach(child, request == PTRACE_KILL ||\n\t\t\t\t  request == PTRACE_INTERRUPT);\n\tif (!ret) {\n\t\tret = compat_arch_ptrace(child, request, addr, data);\n\t\tif (ret || request != PTRACE_DETACH)\n\t\t\tptrace_unfreeze_traced(child);\n\t}\n\n out_put_task_struct:\n\tput_task_struct(child);\n out:\n\treturn ret;\n}\n#endif\t/* CONFIG_COMPAT */\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0-only\n/*\n * linux/kernel/ptrace.c\n *\n * (C) Copyright 1999 Linus Torvalds\n *\n * Common interfaces for \"ptrace()\" which we do not want\n * to continually duplicate across every architecture.\n */\n\n#include <linux/capability.h>\n#include <linux/export.h>\n#include <linux/sched.h>\n#include <linux/sched/mm.h>\n#include <linux/sched/coredump.h>\n#include <linux/sched/task.h>\n#include <linux/errno.h>\n#include <linux/mm.h>\n#include <linux/highmem.h>\n#include <linux/pagemap.h>\n#include <linux/ptrace.h>\n#include <linux/security.h>\n#include <linux/signal.h>\n#include <linux/uio.h>\n#include <linux/audit.h>\n#include <linux/pid_namespace.h>\n#include <linux/syscalls.h>\n#include <linux/uaccess.h>\n#include <linux/regset.h>\n#include <linux/hw_breakpoint.h>\n#include <linux/cn_proc.h>\n#include <linux/compat.h>\n#include <linux/sched/signal.h>\n\n/*\n * Access another process' address space via ptrace.\n * Source/target buffer must be kernel space,\n * Do not walk the page table directly, use get_user_pages\n */\nint ptrace_access_vm(struct task_struct *tsk, unsigned long addr,\n\t\t     void *buf, int len, unsigned int gup_flags)\n{\n\tstruct mm_struct *mm;\n\tint ret;\n\n\tmm = get_task_mm(tsk);\n\tif (!mm)\n\t\treturn 0;\n\n\tif (!tsk->ptrace ||\n\t    (current != tsk->parent) ||\n\t    ((get_dumpable(mm) != SUID_DUMP_USER) &&\n\t     !ptracer_capable(tsk, mm->user_ns))) {\n\t\tmmput(mm);\n\t\treturn 0;\n\t}\n\n\tret = __access_remote_vm(tsk, mm, addr, buf, len, gup_flags);\n\tmmput(mm);\n\n\treturn ret;\n}\n\n\nvoid __ptrace_link(struct task_struct *child, struct task_struct *new_parent,\n\t\t   const struct cred *ptracer_cred)\n{\n\tBUG_ON(!list_empty(&child->ptrace_entry));\n\tlist_add(&child->ptrace_entry, &new_parent->ptraced);\n\tchild->parent = new_parent;\n\tchild->ptracer_cred = get_cred(ptracer_cred);\n}\n\n/*\n * ptrace a task: make the debugger its new parent and\n * move it to the ptrace list.\n *\n * Must be called with the tasklist lock write-held.\n */\nstatic void ptrace_link(struct task_struct *child, struct task_struct *new_parent)\n{\n\t__ptrace_link(child, new_parent, current_cred());\n}\n\n/**\n * __ptrace_unlink - unlink ptracee and restore its execution state\n * @child: ptracee to be unlinked\n *\n * Remove @child from the ptrace list, move it back to the original parent,\n * and restore the execution state so that it conforms to the group stop\n * state.\n *\n * Unlinking can happen via two paths - explicit PTRACE_DETACH or ptracer\n * exiting.  For PTRACE_DETACH, unless the ptracee has been killed between\n * ptrace_check_attach() and here, it's guaranteed to be in TASK_TRACED.\n * If the ptracer is exiting, the ptracee can be in any state.\n *\n * After detach, the ptracee should be in a state which conforms to the\n * group stop.  If the group is stopped or in the process of stopping, the\n * ptracee should be put into TASK_STOPPED; otherwise, it should be woken\n * up from TASK_TRACED.\n *\n * If the ptracee is in TASK_TRACED and needs to be moved to TASK_STOPPED,\n * it goes through TRACED -> RUNNING -> STOPPED transition which is similar\n * to but in the opposite direction of what happens while attaching to a\n * stopped task.  However, in this direction, the intermediate RUNNING\n * state is not hidden even from the current ptracer and if it immediately\n * re-attaches and performs a WNOHANG wait(2), it may fail.\n *\n * CONTEXT:\n * write_lock_irq(tasklist_lock)\n */\nvoid __ptrace_unlink(struct task_struct *child)\n{\n\tconst struct cred *old_cred;\n\tBUG_ON(!child->ptrace);\n\n\tclear_tsk_thread_flag(child, TIF_SYSCALL_TRACE);\n\n\tchild->parent = child->real_parent;\n\tlist_del_init(&child->ptrace_entry);\n\told_cred = child->ptracer_cred;\n\tchild->ptracer_cred = NULL;\n\tput_cred(old_cred);\n\n\tspin_lock(&child->sighand->siglock);\n\tchild->ptrace = 0;\n\t/*\n\t * Clear all pending traps and TRAPPING.  TRAPPING should be\n\t * cleared regardless of JOBCTL_STOP_PENDING.  Do it explicitly.\n\t */\n\ttask_clear_jobctl_pending(child, JOBCTL_TRAP_MASK);\n\ttask_clear_jobctl_trapping(child);\n\n\t/*\n\t * Reinstate JOBCTL_STOP_PENDING if group stop is in effect and\n\t * @child isn't dead.\n\t */\n\tif (!(child->flags & PF_EXITING) &&\n\t    (child->signal->flags & SIGNAL_STOP_STOPPED ||\n\t     child->signal->group_stop_count)) {\n\t\tchild->jobctl |= JOBCTL_STOP_PENDING;\n\n\t\t/*\n\t\t * This is only possible if this thread was cloned by the\n\t\t * traced task running in the stopped group, set the signal\n\t\t * for the future reports.\n\t\t * FIXME: we should change ptrace_init_task() to handle this\n\t\t * case.\n\t\t */\n\t\tif (!(child->jobctl & JOBCTL_STOP_SIGMASK))\n\t\t\tchild->jobctl |= SIGSTOP;\n\t}\n\n\t/*\n\t * If transition to TASK_STOPPED is pending or in TASK_TRACED, kick\n\t * @child in the butt.  Note that @resume should be used iff @child\n\t * is in TASK_TRACED; otherwise, we might unduly disrupt\n\t * TASK_KILLABLE sleeps.\n\t */\n\tif (child->jobctl & JOBCTL_STOP_PENDING || task_is_traced(child))\n\t\tptrace_signal_wake_up(child, true);\n\n\tspin_unlock(&child->sighand->siglock);\n}\n\n/* Ensure that nothing can wake it up, even SIGKILL */\nstatic bool ptrace_freeze_traced(struct task_struct *task)\n{\n\tbool ret = false;\n\n\t/* Lockless, nobody but us can set this flag */\n\tif (task->jobctl & JOBCTL_LISTENING)\n\t\treturn ret;\n\n\tspin_lock_irq(&task->sighand->siglock);\n\tif (task_is_traced(task) && !__fatal_signal_pending(task)) {\n\t\ttask->state = __TASK_TRACED;\n\t\tret = true;\n\t}\n\tspin_unlock_irq(&task->sighand->siglock);\n\n\treturn ret;\n}\n\nstatic void ptrace_unfreeze_traced(struct task_struct *task)\n{\n\tif (task->state != __TASK_TRACED)\n\t\treturn;\n\n\tWARN_ON(!task->ptrace || task->parent != current);\n\n\t/*\n\t * PTRACE_LISTEN can allow ptrace_trap_notify to wake us up remotely.\n\t * Recheck state under the lock to close this race.\n\t */\n\tspin_lock_irq(&task->sighand->siglock);\n\tif (task->state == __TASK_TRACED) {\n\t\tif (__fatal_signal_pending(task))\n\t\t\twake_up_state(task, __TASK_TRACED);\n\t\telse\n\t\t\ttask->state = TASK_TRACED;\n\t}\n\tspin_unlock_irq(&task->sighand->siglock);\n}\n\n/**\n * ptrace_check_attach - check whether ptracee is ready for ptrace operation\n * @child: ptracee to check for\n * @ignore_state: don't check whether @child is currently %TASK_TRACED\n *\n * Check whether @child is being ptraced by %current and ready for further\n * ptrace operations.  If @ignore_state is %false, @child also should be in\n * %TASK_TRACED state and on return the child is guaranteed to be traced\n * and not executing.  If @ignore_state is %true, @child can be in any\n * state.\n *\n * CONTEXT:\n * Grabs and releases tasklist_lock and @child->sighand->siglock.\n *\n * RETURNS:\n * 0 on success, -ESRCH if %child is not ready.\n */\nstatic int ptrace_check_attach(struct task_struct *child, bool ignore_state)\n{\n\tint ret = -ESRCH;\n\n\t/*\n\t * We take the read lock around doing both checks to close a\n\t * possible race where someone else was tracing our child and\n\t * detached between these two checks.  After this locked check,\n\t * we are sure that this is our traced child and that can only\n\t * be changed by us so it's not changing right after this.\n\t */\n\tread_lock(&tasklist_lock);\n\tif (child->ptrace && child->parent == current) {\n\t\tWARN_ON(child->state == __TASK_TRACED);\n\t\t/*\n\t\t * child->sighand can't be NULL, release_task()\n\t\t * does ptrace_unlink() before __exit_signal().\n\t\t */\n\t\tif (ignore_state || ptrace_freeze_traced(child))\n\t\t\tret = 0;\n\t}\n\tread_unlock(&tasklist_lock);\n\n\tif (!ret && !ignore_state) {\n\t\tif (!wait_task_inactive(child, __TASK_TRACED)) {\n\t\t\t/*\n\t\t\t * This can only happen if may_ptrace_stop() fails and\n\t\t\t * ptrace_stop() changes ->state back to TASK_RUNNING,\n\t\t\t * so we should not worry about leaking __TASK_TRACED.\n\t\t\t */\n\t\t\tWARN_ON(child->state == __TASK_TRACED);\n\t\t\tret = -ESRCH;\n\t\t}\n\t}\n\n\treturn ret;\n}\n\nstatic int ptrace_has_cap(struct user_namespace *ns, unsigned int mode)\n{\n\tif (mode & PTRACE_MODE_NOAUDIT)\n\t\treturn has_ns_capability_noaudit(current, ns, CAP_SYS_PTRACE);\n\telse\n\t\treturn has_ns_capability(current, ns, CAP_SYS_PTRACE);\n}\n\n/* Returns 0 on success, -errno on denial. */\nstatic int __ptrace_may_access(struct task_struct *task, unsigned int mode)\n{\n\tconst struct cred *cred = current_cred(), *tcred;\n\tstruct mm_struct *mm;\n\tkuid_t caller_uid;\n\tkgid_t caller_gid;\n\n\tif (!(mode & PTRACE_MODE_FSCREDS) == !(mode & PTRACE_MODE_REALCREDS)) {\n\t\tWARN(1, \"denying ptrace access check without PTRACE_MODE_*CREDS\\n\");\n\t\treturn -EPERM;\n\t}\n\n\t/* May we inspect the given task?\n\t * This check is used both for attaching with ptrace\n\t * and for allowing access to sensitive information in /proc.\n\t *\n\t * ptrace_attach denies several cases that /proc allows\n\t * because setting up the necessary parent/child relationship\n\t * or halting the specified task is impossible.\n\t */\n\n\t/* Don't let security modules deny introspection */\n\tif (same_thread_group(task, current))\n\t\treturn 0;\n\trcu_read_lock();\n\tif (mode & PTRACE_MODE_FSCREDS) {\n\t\tcaller_uid = cred->fsuid;\n\t\tcaller_gid = cred->fsgid;\n\t} else {\n\t\t/*\n\t\t * Using the euid would make more sense here, but something\n\t\t * in userland might rely on the old behavior, and this\n\t\t * shouldn't be a security problem since\n\t\t * PTRACE_MODE_REALCREDS implies that the caller explicitly\n\t\t * used a syscall that requests access to another process\n\t\t * (and not a filesystem syscall to procfs).\n\t\t */\n\t\tcaller_uid = cred->uid;\n\t\tcaller_gid = cred->gid;\n\t}\n\ttcred = __task_cred(task);\n\tif (uid_eq(caller_uid, tcred->euid) &&\n\t    uid_eq(caller_uid, tcred->suid) &&\n\t    uid_eq(caller_uid, tcred->uid)  &&\n\t    gid_eq(caller_gid, tcred->egid) &&\n\t    gid_eq(caller_gid, tcred->sgid) &&\n\t    gid_eq(caller_gid, tcred->gid))\n\t\tgoto ok;\n\tif (ptrace_has_cap(tcred->user_ns, mode))\n\t\tgoto ok;\n\trcu_read_unlock();\n\treturn -EPERM;\nok:\n\trcu_read_unlock();\n\t/*\n\t * If a task drops privileges and becomes nondumpable (through a syscall\n\t * like setresuid()) while we are trying to access it, we must ensure\n\t * that the dumpability is read after the credentials; otherwise,\n\t * we may be able to attach to a task that we shouldn't be able to\n\t * attach to (as if the task had dropped privileges without becoming\n\t * nondumpable).\n\t * Pairs with a write barrier in commit_creds().\n\t */\n\tsmp_rmb();\n\tmm = task->mm;\n\tif (mm &&\n\t    ((get_dumpable(mm) != SUID_DUMP_USER) &&\n\t     !ptrace_has_cap(mm->user_ns, mode)))\n\t    return -EPERM;\n\n\treturn security_ptrace_access_check(task, mode);\n}\n\nbool ptrace_may_access(struct task_struct *task, unsigned int mode)\n{\n\tint err;\n\ttask_lock(task);\n\terr = __ptrace_may_access(task, mode);\n\ttask_unlock(task);\n\treturn !err;\n}\n\nstatic int ptrace_attach(struct task_struct *task, long request,\n\t\t\t unsigned long addr,\n\t\t\t unsigned long flags)\n{\n\tbool seize = (request == PTRACE_SEIZE);\n\tint retval;\n\n\tretval = -EIO;\n\tif (seize) {\n\t\tif (addr != 0)\n\t\t\tgoto out;\n\t\tif (flags & ~(unsigned long)PTRACE_O_MASK)\n\t\t\tgoto out;\n\t\tflags = PT_PTRACED | PT_SEIZED | (flags << PT_OPT_FLAG_SHIFT);\n\t} else {\n\t\tflags = PT_PTRACED;\n\t}\n\n\taudit_ptrace(task);\n\n\tretval = -EPERM;\n\tif (unlikely(task->flags & PF_KTHREAD))\n\t\tgoto out;\n\tif (same_thread_group(task, current))\n\t\tgoto out;\n\n\t/*\n\t * Protect exec's credential calculations against our interference;\n\t * SUID, SGID and LSM creds get determined differently\n\t * under ptrace.\n\t */\n\tretval = -ERESTARTNOINTR;\n\tif (mutex_lock_interruptible(&task->signal->cred_guard_mutex))\n\t\tgoto out;\n\n\ttask_lock(task);\n\tretval = __ptrace_may_access(task, PTRACE_MODE_ATTACH_REALCREDS);\n\ttask_unlock(task);\n\tif (retval)\n\t\tgoto unlock_creds;\n\n\twrite_lock_irq(&tasklist_lock);\n\tretval = -EPERM;\n\tif (unlikely(task->exit_state))\n\t\tgoto unlock_tasklist;\n\tif (task->ptrace)\n\t\tgoto unlock_tasklist;\n\n\tif (seize)\n\t\tflags |= PT_SEIZED;\n\ttask->ptrace = flags;\n\n\tptrace_link(task, current);\n\n\t/* SEIZE doesn't trap tracee on attach */\n\tif (!seize)\n\t\tsend_sig_info(SIGSTOP, SEND_SIG_PRIV, task);\n\n\tspin_lock(&task->sighand->siglock);\n\n\t/*\n\t * If the task is already STOPPED, set JOBCTL_TRAP_STOP and\n\t * TRAPPING, and kick it so that it transits to TRACED.  TRAPPING\n\t * will be cleared if the child completes the transition or any\n\t * event which clears the group stop states happens.  We'll wait\n\t * for the transition to complete before returning from this\n\t * function.\n\t *\n\t * This hides STOPPED -> RUNNING -> TRACED transition from the\n\t * attaching thread but a different thread in the same group can\n\t * still observe the transient RUNNING state.  IOW, if another\n\t * thread's WNOHANG wait(2) on the stopped tracee races against\n\t * ATTACH, the wait(2) may fail due to the transient RUNNING.\n\t *\n\t * The following task_is_stopped() test is safe as both transitions\n\t * in and out of STOPPED are protected by siglock.\n\t */\n\tif (task_is_stopped(task) &&\n\t    task_set_jobctl_pending(task, JOBCTL_TRAP_STOP | JOBCTL_TRAPPING))\n\t\tsignal_wake_up_state(task, __TASK_STOPPED);\n\n\tspin_unlock(&task->sighand->siglock);\n\n\tretval = 0;\nunlock_tasklist:\n\twrite_unlock_irq(&tasklist_lock);\nunlock_creds:\n\tmutex_unlock(&task->signal->cred_guard_mutex);\nout:\n\tif (!retval) {\n\t\t/*\n\t\t * We do not bother to change retval or clear JOBCTL_TRAPPING\n\t\t * if wait_on_bit() was interrupted by SIGKILL. The tracer will\n\t\t * not return to user-mode, it will exit and clear this bit in\n\t\t * __ptrace_unlink() if it wasn't already cleared by the tracee;\n\t\t * and until then nobody can ptrace this task.\n\t\t */\n\t\twait_on_bit(&task->jobctl, JOBCTL_TRAPPING_BIT, TASK_KILLABLE);\n\t\tproc_ptrace_connector(task, PTRACE_ATTACH);\n\t}\n\n\treturn retval;\n}\n\n/**\n * ptrace_traceme  --  helper for PTRACE_TRACEME\n *\n * Performs checks and sets PT_PTRACED.\n * Should be used by all ptrace implementations for PTRACE_TRACEME.\n */\nstatic int ptrace_traceme(void)\n{\n\tint ret = -EPERM;\n\n\twrite_lock_irq(&tasklist_lock);\n\t/* Are we already being traced? */\n\tif (!current->ptrace) {\n\t\tret = security_ptrace_traceme(current->parent);\n\t\t/*\n\t\t * Check PF_EXITING to ensure ->real_parent has not passed\n\t\t * exit_ptrace(). Otherwise we don't report the error but\n\t\t * pretend ->real_parent untraces us right after return.\n\t\t */\n\t\tif (!ret && !(current->real_parent->flags & PF_EXITING)) {\n\t\t\tcurrent->ptrace = PT_PTRACED;\n\t\t\tptrace_link(current, current->real_parent);\n\t\t}\n\t}\n\twrite_unlock_irq(&tasklist_lock);\n\n\treturn ret;\n}\n\n/*\n * Called with irqs disabled, returns true if childs should reap themselves.\n */\nstatic int ignoring_children(struct sighand_struct *sigh)\n{\n\tint ret;\n\tspin_lock(&sigh->siglock);\n\tret = (sigh->action[SIGCHLD-1].sa.sa_handler == SIG_IGN) ||\n\t      (sigh->action[SIGCHLD-1].sa.sa_flags & SA_NOCLDWAIT);\n\tspin_unlock(&sigh->siglock);\n\treturn ret;\n}\n\n/*\n * Called with tasklist_lock held for writing.\n * Unlink a traced task, and clean it up if it was a traced zombie.\n * Return true if it needs to be reaped with release_task().\n * (We can't call release_task() here because we already hold tasklist_lock.)\n *\n * If it's a zombie, our attachedness prevented normal parent notification\n * or self-reaping.  Do notification now if it would have happened earlier.\n * If it should reap itself, return true.\n *\n * If it's our own child, there is no notification to do. But if our normal\n * children self-reap, then this child was prevented by ptrace and we must\n * reap it now, in that case we must also wake up sub-threads sleeping in\n * do_wait().\n */\nstatic bool __ptrace_detach(struct task_struct *tracer, struct task_struct *p)\n{\n\tbool dead;\n\n\t__ptrace_unlink(p);\n\n\tif (p->exit_state != EXIT_ZOMBIE)\n\t\treturn false;\n\n\tdead = !thread_group_leader(p);\n\n\tif (!dead && thread_group_empty(p)) {\n\t\tif (!same_thread_group(p->real_parent, tracer))\n\t\t\tdead = do_notify_parent(p, p->exit_signal);\n\t\telse if (ignoring_children(tracer->sighand)) {\n\t\t\t__wake_up_parent(p, tracer);\n\t\t\tdead = true;\n\t\t}\n\t}\n\t/* Mark it as in the process of being reaped. */\n\tif (dead)\n\t\tp->exit_state = EXIT_DEAD;\n\treturn dead;\n}\n\nstatic int ptrace_detach(struct task_struct *child, unsigned int data)\n{\n\tif (!valid_signal(data))\n\t\treturn -EIO;\n\n\t/* Architecture-specific hardware disable .. */\n\tptrace_disable(child);\n\n\twrite_lock_irq(&tasklist_lock);\n\t/*\n\t * We rely on ptrace_freeze_traced(). It can't be killed and\n\t * untraced by another thread, it can't be a zombie.\n\t */\n\tWARN_ON(!child->ptrace || child->exit_state);\n\t/*\n\t * tasklist_lock avoids the race with wait_task_stopped(), see\n\t * the comment in ptrace_resume().\n\t */\n\tchild->exit_code = data;\n\t__ptrace_detach(current, child);\n\twrite_unlock_irq(&tasklist_lock);\n\n\tproc_ptrace_connector(child, PTRACE_DETACH);\n\n\treturn 0;\n}\n\n/*\n * Detach all tasks we were using ptrace on. Called with tasklist held\n * for writing.\n */\nvoid exit_ptrace(struct task_struct *tracer, struct list_head *dead)\n{\n\tstruct task_struct *p, *n;\n\n\tlist_for_each_entry_safe(p, n, &tracer->ptraced, ptrace_entry) {\n\t\tif (unlikely(p->ptrace & PT_EXITKILL))\n\t\t\tsend_sig_info(SIGKILL, SEND_SIG_PRIV, p);\n\n\t\tif (__ptrace_detach(tracer, p))\n\t\t\tlist_add(&p->ptrace_entry, dead);\n\t}\n}\n\nint ptrace_readdata(struct task_struct *tsk, unsigned long src, char __user *dst, int len)\n{\n\tint copied = 0;\n\n\twhile (len > 0) {\n\t\tchar buf[128];\n\t\tint this_len, retval;\n\n\t\tthis_len = (len > sizeof(buf)) ? sizeof(buf) : len;\n\t\tretval = ptrace_access_vm(tsk, src, buf, this_len, FOLL_FORCE);\n\n\t\tif (!retval) {\n\t\t\tif (copied)\n\t\t\t\tbreak;\n\t\t\treturn -EIO;\n\t\t}\n\t\tif (copy_to_user(dst, buf, retval))\n\t\t\treturn -EFAULT;\n\t\tcopied += retval;\n\t\tsrc += retval;\n\t\tdst += retval;\n\t\tlen -= retval;\n\t}\n\treturn copied;\n}\n\nint ptrace_writedata(struct task_struct *tsk, char __user *src, unsigned long dst, int len)\n{\n\tint copied = 0;\n\n\twhile (len > 0) {\n\t\tchar buf[128];\n\t\tint this_len, retval;\n\n\t\tthis_len = (len > sizeof(buf)) ? sizeof(buf) : len;\n\t\tif (copy_from_user(buf, src, this_len))\n\t\t\treturn -EFAULT;\n\t\tretval = ptrace_access_vm(tsk, dst, buf, this_len,\n\t\t\t\tFOLL_FORCE | FOLL_WRITE);\n\t\tif (!retval) {\n\t\t\tif (copied)\n\t\t\t\tbreak;\n\t\t\treturn -EIO;\n\t\t}\n\t\tcopied += retval;\n\t\tsrc += retval;\n\t\tdst += retval;\n\t\tlen -= retval;\n\t}\n\treturn copied;\n}\n\nstatic int ptrace_setoptions(struct task_struct *child, unsigned long data)\n{\n\tunsigned flags;\n\n\tif (data & ~(unsigned long)PTRACE_O_MASK)\n\t\treturn -EINVAL;\n\n\tif (unlikely(data & PTRACE_O_SUSPEND_SECCOMP)) {\n\t\tif (!IS_ENABLED(CONFIG_CHECKPOINT_RESTORE) ||\n\t\t    !IS_ENABLED(CONFIG_SECCOMP))\n\t\t\treturn -EINVAL;\n\n\t\tif (!capable(CAP_SYS_ADMIN))\n\t\t\treturn -EPERM;\n\n\t\tif (seccomp_mode(&current->seccomp) != SECCOMP_MODE_DISABLED ||\n\t\t    current->ptrace & PT_SUSPEND_SECCOMP)\n\t\t\treturn -EPERM;\n\t}\n\n\t/* Avoid intermediate state when all opts are cleared */\n\tflags = child->ptrace;\n\tflags &= ~(PTRACE_O_MASK << PT_OPT_FLAG_SHIFT);\n\tflags |= (data << PT_OPT_FLAG_SHIFT);\n\tchild->ptrace = flags;\n\n\treturn 0;\n}\n\nstatic int ptrace_getsiginfo(struct task_struct *child, kernel_siginfo_t *info)\n{\n\tunsigned long flags;\n\tint error = -ESRCH;\n\n\tif (lock_task_sighand(child, &flags)) {\n\t\terror = -EINVAL;\n\t\tif (likely(child->last_siginfo != NULL)) {\n\t\t\tcopy_siginfo(info, child->last_siginfo);\n\t\t\terror = 0;\n\t\t}\n\t\tunlock_task_sighand(child, &flags);\n\t}\n\treturn error;\n}\n\nstatic int ptrace_setsiginfo(struct task_struct *child, const kernel_siginfo_t *info)\n{\n\tunsigned long flags;\n\tint error = -ESRCH;\n\n\tif (lock_task_sighand(child, &flags)) {\n\t\terror = -EINVAL;\n\t\tif (likely(child->last_siginfo != NULL)) {\n\t\t\tcopy_siginfo(child->last_siginfo, info);\n\t\t\terror = 0;\n\t\t}\n\t\tunlock_task_sighand(child, &flags);\n\t}\n\treturn error;\n}\n\nstatic int ptrace_peek_siginfo(struct task_struct *child,\n\t\t\t\tunsigned long addr,\n\t\t\t\tunsigned long data)\n{\n\tstruct ptrace_peeksiginfo_args arg;\n\tstruct sigpending *pending;\n\tstruct sigqueue *q;\n\tint ret, i;\n\n\tret = copy_from_user(&arg, (void __user *) addr,\n\t\t\t\tsizeof(struct ptrace_peeksiginfo_args));\n\tif (ret)\n\t\treturn -EFAULT;\n\n\tif (arg.flags & ~PTRACE_PEEKSIGINFO_SHARED)\n\t\treturn -EINVAL; /* unknown flags */\n\n\tif (arg.nr < 0)\n\t\treturn -EINVAL;\n\n\t/* Ensure arg.off fits in an unsigned long */\n\tif (arg.off > ULONG_MAX)\n\t\treturn 0;\n\n\tif (arg.flags & PTRACE_PEEKSIGINFO_SHARED)\n\t\tpending = &child->signal->shared_pending;\n\telse\n\t\tpending = &child->pending;\n\n\tfor (i = 0; i < arg.nr; ) {\n\t\tkernel_siginfo_t info;\n\t\tunsigned long off = arg.off + i;\n\t\tbool found = false;\n\n\t\tspin_lock_irq(&child->sighand->siglock);\n\t\tlist_for_each_entry(q, &pending->list, list) {\n\t\t\tif (!off--) {\n\t\t\t\tfound = true;\n\t\t\t\tcopy_siginfo(&info, &q->info);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tspin_unlock_irq(&child->sighand->siglock);\n\n\t\tif (!found) /* beyond the end of the list */\n\t\t\tbreak;\n\n#ifdef CONFIG_COMPAT\n\t\tif (unlikely(in_compat_syscall())) {\n\t\t\tcompat_siginfo_t __user *uinfo = compat_ptr(data);\n\n\t\t\tif (copy_siginfo_to_user32(uinfo, &info)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t} else\n#endif\n\t\t{\n\t\t\tsiginfo_t __user *uinfo = (siginfo_t __user *) data;\n\n\t\t\tif (copy_siginfo_to_user(uinfo, &info)) {\n\t\t\t\tret = -EFAULT;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tdata += sizeof(siginfo_t);\n\t\ti++;\n\n\t\tif (signal_pending(current))\n\t\t\tbreak;\n\n\t\tcond_resched();\n\t}\n\n\tif (i > 0)\n\t\treturn i;\n\n\treturn ret;\n}\n\n#ifdef PTRACE_SINGLESTEP\n#define is_singlestep(request)\t\t((request) == PTRACE_SINGLESTEP)\n#else\n#define is_singlestep(request)\t\t0\n#endif\n\n#ifdef PTRACE_SINGLEBLOCK\n#define is_singleblock(request)\t\t((request) == PTRACE_SINGLEBLOCK)\n#else\n#define is_singleblock(request)\t\t0\n#endif\n\n#ifdef PTRACE_SYSEMU\n#define is_sysemu_singlestep(request)\t((request) == PTRACE_SYSEMU_SINGLESTEP)\n#else\n#define is_sysemu_singlestep(request)\t0\n#endif\n\nstatic int ptrace_resume(struct task_struct *child, long request,\n\t\t\t unsigned long data)\n{\n\tbool need_siglock;\n\n\tif (!valid_signal(data))\n\t\treturn -EIO;\n\n\tif (request == PTRACE_SYSCALL)\n\t\tset_tsk_thread_flag(child, TIF_SYSCALL_TRACE);\n\telse\n\t\tclear_tsk_thread_flag(child, TIF_SYSCALL_TRACE);\n\n#ifdef TIF_SYSCALL_EMU\n\tif (request == PTRACE_SYSEMU || request == PTRACE_SYSEMU_SINGLESTEP)\n\t\tset_tsk_thread_flag(child, TIF_SYSCALL_EMU);\n\telse\n\t\tclear_tsk_thread_flag(child, TIF_SYSCALL_EMU);\n#endif\n\n\tif (is_singleblock(request)) {\n\t\tif (unlikely(!arch_has_block_step()))\n\t\t\treturn -EIO;\n\t\tuser_enable_block_step(child);\n\t} else if (is_singlestep(request) || is_sysemu_singlestep(request)) {\n\t\tif (unlikely(!arch_has_single_step()))\n\t\t\treturn -EIO;\n\t\tuser_enable_single_step(child);\n\t} else {\n\t\tuser_disable_single_step(child);\n\t}\n\n\t/*\n\t * Change ->exit_code and ->state under siglock to avoid the race\n\t * with wait_task_stopped() in between; a non-zero ->exit_code will\n\t * wrongly look like another report from tracee.\n\t *\n\t * Note that we need siglock even if ->exit_code == data and/or this\n\t * status was not reported yet, the new status must not be cleared by\n\t * wait_task_stopped() after resume.\n\t *\n\t * If data == 0 we do not care if wait_task_stopped() reports the old\n\t * status and clears the code too; this can't race with the tracee, it\n\t * takes siglock after resume.\n\t */\n\tneed_siglock = data && !thread_group_empty(current);\n\tif (need_siglock)\n\t\tspin_lock_irq(&child->sighand->siglock);\n\tchild->exit_code = data;\n\twake_up_state(child, __TASK_TRACED);\n\tif (need_siglock)\n\t\tspin_unlock_irq(&child->sighand->siglock);\n\n\treturn 0;\n}\n\n#ifdef CONFIG_HAVE_ARCH_TRACEHOOK\n\nstatic const struct user_regset *\nfind_regset(const struct user_regset_view *view, unsigned int type)\n{\n\tconst struct user_regset *regset;\n\tint n;\n\n\tfor (n = 0; n < view->n; ++n) {\n\t\tregset = view->regsets + n;\n\t\tif (regset->core_note_type == type)\n\t\t\treturn regset;\n\t}\n\n\treturn NULL;\n}\n\nstatic int ptrace_regset(struct task_struct *task, int req, unsigned int type,\n\t\t\t struct iovec *kiov)\n{\n\tconst struct user_regset_view *view = task_user_regset_view(task);\n\tconst struct user_regset *regset = find_regset(view, type);\n\tint regset_no;\n\n\tif (!regset || (kiov->iov_len % regset->size) != 0)\n\t\treturn -EINVAL;\n\n\tregset_no = regset - view->regsets;\n\tkiov->iov_len = min(kiov->iov_len,\n\t\t\t    (__kernel_size_t) (regset->n * regset->size));\n\n\tif (req == PTRACE_GETREGSET)\n\t\treturn copy_regset_to_user(task, view, regset_no, 0,\n\t\t\t\t\t   kiov->iov_len, kiov->iov_base);\n\telse\n\t\treturn copy_regset_from_user(task, view, regset_no, 0,\n\t\t\t\t\t     kiov->iov_len, kiov->iov_base);\n}\n\n/*\n * This is declared in linux/regset.h and defined in machine-dependent\n * code.  We put the export here, near the primary machine-neutral use,\n * to ensure no machine forgets it.\n */\nEXPORT_SYMBOL_GPL(task_user_regset_view);\n#endif\n\nint ptrace_request(struct task_struct *child, long request,\n\t\t   unsigned long addr, unsigned long data)\n{\n\tbool seized = child->ptrace & PT_SEIZED;\n\tint ret = -EIO;\n\tkernel_siginfo_t siginfo, *si;\n\tvoid __user *datavp = (void __user *) data;\n\tunsigned long __user *datalp = datavp;\n\tunsigned long flags;\n\n\tswitch (request) {\n\tcase PTRACE_PEEKTEXT:\n\tcase PTRACE_PEEKDATA:\n\t\treturn generic_ptrace_peekdata(child, addr, data);\n\tcase PTRACE_POKETEXT:\n\tcase PTRACE_POKEDATA:\n\t\treturn generic_ptrace_pokedata(child, addr, data);\n\n#ifdef PTRACE_OLDSETOPTIONS\n\tcase PTRACE_OLDSETOPTIONS:\n#endif\n\tcase PTRACE_SETOPTIONS:\n\t\tret = ptrace_setoptions(child, data);\n\t\tbreak;\n\tcase PTRACE_GETEVENTMSG:\n\t\tret = put_user(child->ptrace_message, datalp);\n\t\tbreak;\n\n\tcase PTRACE_PEEKSIGINFO:\n\t\tret = ptrace_peek_siginfo(child, addr, data);\n\t\tbreak;\n\n\tcase PTRACE_GETSIGINFO:\n\t\tret = ptrace_getsiginfo(child, &siginfo);\n\t\tif (!ret)\n\t\t\tret = copy_siginfo_to_user(datavp, &siginfo);\n\t\tbreak;\n\n\tcase PTRACE_SETSIGINFO:\n\t\tret = copy_siginfo_from_user(&siginfo, datavp);\n\t\tif (!ret)\n\t\t\tret = ptrace_setsiginfo(child, &siginfo);\n\t\tbreak;\n\n\tcase PTRACE_GETSIGMASK: {\n\t\tsigset_t *mask;\n\n\t\tif (addr != sizeof(sigset_t)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (test_tsk_restore_sigmask(child))\n\t\t\tmask = &child->saved_sigmask;\n\t\telse\n\t\t\tmask = &child->blocked;\n\n\t\tif (copy_to_user(datavp, mask, sizeof(sigset_t)))\n\t\t\tret = -EFAULT;\n\t\telse\n\t\t\tret = 0;\n\n\t\tbreak;\n\t}\n\n\tcase PTRACE_SETSIGMASK: {\n\t\tsigset_t new_set;\n\n\t\tif (addr != sizeof(sigset_t)) {\n\t\t\tret = -EINVAL;\n\t\t\tbreak;\n\t\t}\n\n\t\tif (copy_from_user(&new_set, datavp, sizeof(sigset_t))) {\n\t\t\tret = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tsigdelsetmask(&new_set, sigmask(SIGKILL)|sigmask(SIGSTOP));\n\n\t\t/*\n\t\t * Every thread does recalc_sigpending() after resume, so\n\t\t * retarget_shared_pending() and recalc_sigpending() are not\n\t\t * called here.\n\t\t */\n\t\tspin_lock_irq(&child->sighand->siglock);\n\t\tchild->blocked = new_set;\n\t\tspin_unlock_irq(&child->sighand->siglock);\n\n\t\tclear_tsk_restore_sigmask(child);\n\n\t\tret = 0;\n\t\tbreak;\n\t}\n\n\tcase PTRACE_INTERRUPT:\n\t\t/*\n\t\t * Stop tracee without any side-effect on signal or job\n\t\t * control.  At least one trap is guaranteed to happen\n\t\t * after this request.  If @child is already trapped, the\n\t\t * current trap is not disturbed and another trap will\n\t\t * happen after the current trap is ended with PTRACE_CONT.\n\t\t *\n\t\t * The actual trap might not be PTRACE_EVENT_STOP trap but\n\t\t * the pending condition is cleared regardless.\n\t\t */\n\t\tif (unlikely(!seized || !lock_task_sighand(child, &flags)))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * INTERRUPT doesn't disturb existing trap sans one\n\t\t * exception.  If ptracer issued LISTEN for the current\n\t\t * STOP, this INTERRUPT should clear LISTEN and re-trap\n\t\t * tracee into STOP.\n\t\t */\n\t\tif (likely(task_set_jobctl_pending(child, JOBCTL_TRAP_STOP)))\n\t\t\tptrace_signal_wake_up(child, child->jobctl & JOBCTL_LISTENING);\n\n\t\tunlock_task_sighand(child, &flags);\n\t\tret = 0;\n\t\tbreak;\n\n\tcase PTRACE_LISTEN:\n\t\t/*\n\t\t * Listen for events.  Tracee must be in STOP.  It's not\n\t\t * resumed per-se but is not considered to be in TRACED by\n\t\t * wait(2) or ptrace(2).  If an async event (e.g. group\n\t\t * stop state change) happens, tracee will enter STOP trap\n\t\t * again.  Alternatively, ptracer can issue INTERRUPT to\n\t\t * finish listening and re-trap tracee into STOP.\n\t\t */\n\t\tif (unlikely(!seized || !lock_task_sighand(child, &flags)))\n\t\t\tbreak;\n\n\t\tsi = child->last_siginfo;\n\t\tif (likely(si && (si->si_code >> 8) == PTRACE_EVENT_STOP)) {\n\t\t\tchild->jobctl |= JOBCTL_LISTENING;\n\t\t\t/*\n\t\t\t * If NOTIFY is set, it means event happened between\n\t\t\t * start of this trap and now.  Trigger re-trap.\n\t\t\t */\n\t\t\tif (child->jobctl & JOBCTL_TRAP_NOTIFY)\n\t\t\t\tptrace_signal_wake_up(child, true);\n\t\t\tret = 0;\n\t\t}\n\t\tunlock_task_sighand(child, &flags);\n\t\tbreak;\n\n\tcase PTRACE_DETACH:\t /* detach a process that was attached. */\n\t\tret = ptrace_detach(child, data);\n\t\tbreak;\n\n#ifdef CONFIG_BINFMT_ELF_FDPIC\n\tcase PTRACE_GETFDPIC: {\n\t\tstruct mm_struct *mm = get_task_mm(child);\n\t\tunsigned long tmp = 0;\n\n\t\tret = -ESRCH;\n\t\tif (!mm)\n\t\t\tbreak;\n\n\t\tswitch (addr) {\n\t\tcase PTRACE_GETFDPIC_EXEC:\n\t\t\ttmp = mm->context.exec_fdpic_loadmap;\n\t\t\tbreak;\n\t\tcase PTRACE_GETFDPIC_INTERP:\n\t\t\ttmp = mm->context.interp_fdpic_loadmap;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tbreak;\n\t\t}\n\t\tmmput(mm);\n\n\t\tret = put_user(tmp, datalp);\n\t\tbreak;\n\t}\n#endif\n\n#ifdef PTRACE_SINGLESTEP\n\tcase PTRACE_SINGLESTEP:\n#endif\n#ifdef PTRACE_SINGLEBLOCK\n\tcase PTRACE_SINGLEBLOCK:\n#endif\n#ifdef PTRACE_SYSEMU\n\tcase PTRACE_SYSEMU:\n\tcase PTRACE_SYSEMU_SINGLESTEP:\n#endif\n\tcase PTRACE_SYSCALL:\n\tcase PTRACE_CONT:\n\t\treturn ptrace_resume(child, request, data);\n\n\tcase PTRACE_KILL:\n\t\tif (child->exit_state)\t/* already dead */\n\t\t\treturn 0;\n\t\treturn ptrace_resume(child, request, SIGKILL);\n\n#ifdef CONFIG_HAVE_ARCH_TRACEHOOK\n\tcase PTRACE_GETREGSET:\n\tcase PTRACE_SETREGSET: {\n\t\tstruct iovec kiov;\n\t\tstruct iovec __user *uiov = datavp;\n\n\t\tif (!access_ok(uiov, sizeof(*uiov)))\n\t\t\treturn -EFAULT;\n\n\t\tif (__get_user(kiov.iov_base, &uiov->iov_base) ||\n\t\t    __get_user(kiov.iov_len, &uiov->iov_len))\n\t\t\treturn -EFAULT;\n\n\t\tret = ptrace_regset(child, request, addr, &kiov);\n\t\tif (!ret)\n\t\t\tret = __put_user(kiov.iov_len, &uiov->iov_len);\n\t\tbreak;\n\t}\n#endif\n\n\tcase PTRACE_SECCOMP_GET_FILTER:\n\t\tret = seccomp_get_filter(child, addr, datavp);\n\t\tbreak;\n\n\tcase PTRACE_SECCOMP_GET_METADATA:\n\t\tret = seccomp_get_metadata(child, addr, datavp);\n\t\tbreak;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\treturn ret;\n}\n\n#ifndef arch_ptrace_attach\n#define arch_ptrace_attach(child)\tdo { } while (0)\n#endif\n\nSYSCALL_DEFINE4(ptrace, long, request, long, pid, unsigned long, addr,\n\t\tunsigned long, data)\n{\n\tstruct task_struct *child;\n\tlong ret;\n\n\tif (request == PTRACE_TRACEME) {\n\t\tret = ptrace_traceme();\n\t\tif (!ret)\n\t\t\tarch_ptrace_attach(current);\n\t\tgoto out;\n\t}\n\n\tchild = find_get_task_by_vpid(pid);\n\tif (!child) {\n\t\tret = -ESRCH;\n\t\tgoto out;\n\t}\n\n\tif (request == PTRACE_ATTACH || request == PTRACE_SEIZE) {\n\t\tret = ptrace_attach(child, request, addr, data);\n\t\t/*\n\t\t * Some architectures need to do book-keeping after\n\t\t * a ptrace attach.\n\t\t */\n\t\tif (!ret)\n\t\t\tarch_ptrace_attach(child);\n\t\tgoto out_put_task_struct;\n\t}\n\n\tret = ptrace_check_attach(child, request == PTRACE_KILL ||\n\t\t\t\t  request == PTRACE_INTERRUPT);\n\tif (ret < 0)\n\t\tgoto out_put_task_struct;\n\n\tret = arch_ptrace(child, request, addr, data);\n\tif (ret || request != PTRACE_DETACH)\n\t\tptrace_unfreeze_traced(child);\n\n out_put_task_struct:\n\tput_task_struct(child);\n out:\n\treturn ret;\n}\n\nint generic_ptrace_peekdata(struct task_struct *tsk, unsigned long addr,\n\t\t\t    unsigned long data)\n{\n\tunsigned long tmp;\n\tint copied;\n\n\tcopied = ptrace_access_vm(tsk, addr, &tmp, sizeof(tmp), FOLL_FORCE);\n\tif (copied != sizeof(tmp))\n\t\treturn -EIO;\n\treturn put_user(tmp, (unsigned long __user *)data);\n}\n\nint generic_ptrace_pokedata(struct task_struct *tsk, unsigned long addr,\n\t\t\t    unsigned long data)\n{\n\tint copied;\n\n\tcopied = ptrace_access_vm(tsk, addr, &data, sizeof(data),\n\t\t\tFOLL_FORCE | FOLL_WRITE);\n\treturn (copied == sizeof(data)) ? 0 : -EIO;\n}\n\n#if defined CONFIG_COMPAT\n\nint compat_ptrace_request(struct task_struct *child, compat_long_t request,\n\t\t\t  compat_ulong_t addr, compat_ulong_t data)\n{\n\tcompat_ulong_t __user *datap = compat_ptr(data);\n\tcompat_ulong_t word;\n\tkernel_siginfo_t siginfo;\n\tint ret;\n\n\tswitch (request) {\n\tcase PTRACE_PEEKTEXT:\n\tcase PTRACE_PEEKDATA:\n\t\tret = ptrace_access_vm(child, addr, &word, sizeof(word),\n\t\t\t\tFOLL_FORCE);\n\t\tif (ret != sizeof(word))\n\t\t\tret = -EIO;\n\t\telse\n\t\t\tret = put_user(word, datap);\n\t\tbreak;\n\n\tcase PTRACE_POKETEXT:\n\tcase PTRACE_POKEDATA:\n\t\tret = ptrace_access_vm(child, addr, &data, sizeof(data),\n\t\t\t\tFOLL_FORCE | FOLL_WRITE);\n\t\tret = (ret != sizeof(data) ? -EIO : 0);\n\t\tbreak;\n\n\tcase PTRACE_GETEVENTMSG:\n\t\tret = put_user((compat_ulong_t) child->ptrace_message, datap);\n\t\tbreak;\n\n\tcase PTRACE_GETSIGINFO:\n\t\tret = ptrace_getsiginfo(child, &siginfo);\n\t\tif (!ret)\n\t\t\tret = copy_siginfo_to_user32(\n\t\t\t\t(struct compat_siginfo __user *) datap,\n\t\t\t\t&siginfo);\n\t\tbreak;\n\n\tcase PTRACE_SETSIGINFO:\n\t\tret = copy_siginfo_from_user32(\n\t\t\t&siginfo, (struct compat_siginfo __user *) datap);\n\t\tif (!ret)\n\t\t\tret = ptrace_setsiginfo(child, &siginfo);\n\t\tbreak;\n#ifdef CONFIG_HAVE_ARCH_TRACEHOOK\n\tcase PTRACE_GETREGSET:\n\tcase PTRACE_SETREGSET:\n\t{\n\t\tstruct iovec kiov;\n\t\tstruct compat_iovec __user *uiov =\n\t\t\t(struct compat_iovec __user *) datap;\n\t\tcompat_uptr_t ptr;\n\t\tcompat_size_t len;\n\n\t\tif (!access_ok(uiov, sizeof(*uiov)))\n\t\t\treturn -EFAULT;\n\n\t\tif (__get_user(ptr, &uiov->iov_base) ||\n\t\t    __get_user(len, &uiov->iov_len))\n\t\t\treturn -EFAULT;\n\n\t\tkiov.iov_base = compat_ptr(ptr);\n\t\tkiov.iov_len = len;\n\n\t\tret = ptrace_regset(child, request, addr, &kiov);\n\t\tif (!ret)\n\t\t\tret = __put_user(kiov.iov_len, &uiov->iov_len);\n\t\tbreak;\n\t}\n#endif\n\n\tdefault:\n\t\tret = ptrace_request(child, request, addr, data);\n\t}\n\n\treturn ret;\n}\n\nCOMPAT_SYSCALL_DEFINE4(ptrace, compat_long_t, request, compat_long_t, pid,\n\t\t       compat_long_t, addr, compat_long_t, data)\n{\n\tstruct task_struct *child;\n\tlong ret;\n\n\tif (request == PTRACE_TRACEME) {\n\t\tret = ptrace_traceme();\n\t\tgoto out;\n\t}\n\n\tchild = find_get_task_by_vpid(pid);\n\tif (!child) {\n\t\tret = -ESRCH;\n\t\tgoto out;\n\t}\n\n\tif (request == PTRACE_ATTACH || request == PTRACE_SEIZE) {\n\t\tret = ptrace_attach(child, request, addr, data);\n\t\t/*\n\t\t * Some architectures need to do book-keeping after\n\t\t * a ptrace attach.\n\t\t */\n\t\tif (!ret)\n\t\t\tarch_ptrace_attach(child);\n\t\tgoto out_put_task_struct;\n\t}\n\n\tret = ptrace_check_attach(child, request == PTRACE_KILL ||\n\t\t\t\t  request == PTRACE_INTERRUPT);\n\tif (!ret) {\n\t\tret = compat_arch_ptrace(child, request, addr, data);\n\t\tif (ret || request != PTRACE_DETACH)\n\t\t\tptrace_unfreeze_traced(child);\n\t}\n\n out_put_task_struct:\n\tput_task_struct(child);\n out:\n\treturn ret;\n}\n#endif\t/* CONFIG_COMPAT */\n"], "filenames": ["kernel/ptrace.c"], "buggy_code_start_loc": [82], "buggy_code_end_loc": [85], "fixing_code_start_loc": [82], "fixing_code_end_loc": [83], "type": "CWE-269", "message": "In the Linux kernel before 5.1.17, ptrace_link in kernel/ptrace.c mishandles the recording of the credentials of a process that wants to create a ptrace relationship, which allows local users to obtain root access by leveraging certain scenarios with a parent-child process relationship, where a parent drops privileges and calls execve (potentially allowing control by an attacker). One contributing factor is an object lifetime issue (which can also cause a panic). Another contributing factor is incorrect marking of a ptrace relationship as privileged, which is exploitable through (for example) Polkit's pkexec helper with PTRACE_TRACEME. NOTE: SELinux deny_ptrace might be a usable workaround in some environments.", "other": {"cve": {"id": "CVE-2019-13272", "sourceIdentifier": "cve@mitre.org", "published": "2019-07-17T13:15:10.687", "lastModified": "2023-01-17T21:25:07.200", "vulnStatus": "Analyzed", "cisaExploitAdd": "2021-12-10", "cisaActionDue": "2022-06-10", "cisaRequiredAction": "Apply updates per vendor instructions.", "cisaVulnerabilityName": "Linux Kernel Improper Privilege Management Vulnerability", "descriptions": [{"lang": "en", "value": "In the Linux kernel before 5.1.17, ptrace_link in kernel/ptrace.c mishandles the recording of the credentials of a process that wants to create a ptrace relationship, which allows local users to obtain root access by leveraging certain scenarios with a parent-child process relationship, where a parent drops privileges and calls execve (potentially allowing control by an attacker). One contributing factor is an object lifetime issue (which can also cause a panic). Another contributing factor is incorrect marking of a ptrace relationship as privileged, which is exploitable through (for example) Polkit's pkexec helper with PTRACE_TRACEME. NOTE: SELinux deny_ptrace might be a usable workaround in some environments."}, {"lang": "es", "value": "En el kernel de Linux anterior a versi\u00f3n 5.1.17, ptrace_link en el archivo kernel/ptrace.c maneja inapropiadamente la grabaci\u00f3n de las credenciales de un proceso que desea crear una relaci\u00f3n de ptrace, que permite a los usuarios locales obtener acceso de root aprovechando determinados escenarios con un relaci\u00f3n de proceso padre-hijo, donde un padre elimina los privilegios y llama a execve (permitiendo potencialmente el control por parte de un atacante). Un factor que contribuye es un problema de vida \u00fatil del objeto (que tambi\u00e9n puede causar un p\u00e1nico). Otro factor que contribuye es el marcado incorrecto de una relaci\u00f3n de ptrace como privilegiada, que puede ser explotada mediante (por ejemplo) el ayudante pkexec de Polkit con PTRACE_TRACEME. NOTA: deny_ptrace de SELinux puede ser una soluci\u00f3n \u00fatil en algunos entornos."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:C/I:C/A:C", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "COMPLETE", "integrityImpact": "COMPLETE", "availabilityImpact": "COMPLETE", "baseScore": 7.2}, "baseSeverity": "HIGH", "exploitabilityScore": 3.9, "impactScore": 10.0, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "nvd@nist.gov", "type": "Primary", "description": [{"lang": "en", "value": "CWE-269"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "3.16.52", "versionEndExcluding": "3.16.71", "matchCriteriaId": "AA88B130-CD8A-4E14-A1F5-4D1DB031D60E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.1.39", "versionEndExcluding": "4.2", "matchCriteriaId": "CD709672-0E6A-4086-8700-B6C2FDD8599C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.4.40", "versionEndExcluding": "4.4.185", "matchCriteriaId": "19FB5FC5-740B-418F-B83A-3EA6095270C0"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.8.16", "versionEndExcluding": "4.9", "matchCriteriaId": "66431BA1-01B5-476A-B483-AE4E7B830BA7"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.9.1", "versionEndExcluding": "4.9.185", "matchCriteriaId": "8A719867-AEB7-4E95-A1DE-B96EA092D9FE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.10", "versionEndExcluding": "4.14.133", "matchCriteriaId": "00D95A2F-5B17-46D9-80D7-2E0D1779C2CE"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.15", "versionEndExcluding": "4.19.58", "matchCriteriaId": "F921620B-E2A7-421F-8C89-016C51723C17"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartIncluding": "4.20", "versionEndExcluding": "5.1.17", "matchCriteriaId": "7049E422-0D4B-45FD-8B06-04BACD44A66E"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "C11E6FB0-C8C0-4527-9AA0-CB9B316F8F43"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:9.0:*:*:*:*:*:*:*", "matchCriteriaId": "DEECE5FC-CACF-4496-A3E7-164736409252"}, {"vulnerable": true, "criteria": "cpe:2.3:o:debian:debian_linux:10.0:*:*:*:*:*:*:*", "matchCriteriaId": "07B237A9-69A3-4A9C-9DA0-4E06BD37AE73"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:29:*:*:*:*:*:*:*", "matchCriteriaId": "D100F7CE-FC64-4CC6-852A-6136D72DA419"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:16.04:*:*:*:esm:*:*:*", "matchCriteriaId": "7A5301BF-1402-4BE0-A0F8-69FBE79BC6D6"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:18.04:*:*:*:lts:*:*:*", "matchCriteriaId": "23A7C53F-B80F-4E6A-AFA9-58EEA84BE11D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:canonical:ubuntu_linux:19.04:*:*:*:*:*:*:*", "matchCriteriaId": "CD783B0C-9246-47D9-A937-6144FE8BFF0F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:7.0:*:*:*:*:*:*:*", "matchCriteriaId": "142AD0DD-4CF3-4D74-9442-459CE3347E3A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux:8.0:*:*:*:*:*:*:*", "matchCriteriaId": "F4CFF558-3C47-480D-A2F0-BABF26042943"}, {"vulnerable": true, "criteria": "cpe:2.3:o:redhat:enterprise_linux_for_real_time:8:*:*:*:*:*:*:*", "matchCriteriaId": "CBF9BCF3-187F-410A-96CA-9C47D3ED6924"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:aff_a700s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "952F55C9-7E7C-4539-9D08-E736B3488569"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:aff_a700s:-:*:*:*:*:*:*:*", "matchCriteriaId": "9FED1B0D-F901-413A-85D9-05D4C427570D"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h410c_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "234DEFE0-5CE5-4B0A-96B8-5D227CB8ED31"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h410c:-:*:*:*:*:*:*:*", "matchCriteriaId": "CDDF61B7-EC5C-467C-B710-B89F502CD04F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:h610s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "FD7CFE0E-9D1E-4495-B302-89C3096FC0DF"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:h610s:-:*:*:*:*:*:*:*", "matchCriteriaId": "F63A3FA7-AAED-4A9D-9FDE-6195302DA0F6"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:netapp:active_iq_unified_manager:-:*:*:*:*:vmware_vsphere:*:*", "matchCriteriaId": "3A756737-1CC4-42C2-A4DF-E1C893B4E2D5"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:e-series_performance_analyzer:-:*:*:*:*:*:*:*", "matchCriteriaId": "24B8DB06-590A-4008-B0AB-FCD1401C77C6"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:e-series_santricity_os_controller:*:*:*:*:*:*:*:*", "versionStartIncluding": "11.0.0", "versionEndIncluding": "11.60.3", "matchCriteriaId": "BD1E9594-C46F-40D1-8BC2-6B16635B55C4"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:hci_management_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "A3C19813-E823-456A-B1CE-EC0684CE1953"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:service_processor:-:*:*:*:*:*:*:*", "matchCriteriaId": "146A767F-DC04-454B-9913-17D3A2B5AAA4"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:solidfire:-:*:*:*:*:*:*:*", "matchCriteriaId": "A6E9EF0C-AFA8-4F7B-9FDC-1E0F7C26E737"}, {"vulnerable": true, "criteria": "cpe:2.3:a:netapp:steelstore_cloud_integrated_storage:-:*:*:*:*:*:*:*", "matchCriteriaId": "E94F7F59-1785-493F-91A7-5F5EA5E87E4D"}, {"vulnerable": true, "criteria": "cpe:2.3:h:netapp:hci_compute_node:-:*:*:*:*:*:*:*", "matchCriteriaId": "AD7447BC-F315-4298-A822-549942FC118B"}]}]}], "references": [{"url": "http://packetstormsecurity.com/files/153663/Linux-PTRACE_TRACEME-Broken-Permission-Object-Lifetime-Handling.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://packetstormsecurity.com/files/153702/Slackware-Security-Advisory-Slackware-14.2-kernel-Updates.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://packetstormsecurity.com/files/154245/Kernel-Live-Patch-Security-Notice-LSN-0054-1.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "http://packetstormsecurity.com/files/154957/Linux-Polkit-pkexec-Helper-PTRACE_TRACEME-Local-Root.html", "source": "cve@mitre.org", "tags": ["Exploit", "Third Party Advisory", "VDB Entry"]}, {"url": "http://packetstormsecurity.com/files/156929/Linux-PTRACE_TRACEME-Local-Root.html", "source": "cve@mitre.org", "tags": ["Exploit", "Third Party Advisory", "VDB Entry"]}, {"url": "http://packetstormsecurity.com/files/165051/Linux-Kernel-5.1.x-PTRACE_TRACEME-pkexec-Local-Privilege-Escalation.html", "source": "cve@mitre.org", "tags": ["Third Party Advisory", "VDB Entry"]}, {"url": "https://access.redhat.com/errata/RHSA-2019:2405", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2019:2411", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://access.redhat.com/errata/RHSA-2019:2809", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://bugs.chromium.org/p/project-zero/issues/detail?id=1903", "source": "cve@mitre.org", "tags": ["Exploit", "Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1730895", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://bugzilla.suse.com/show_bug.cgi?id=1140671", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://cdn.kernel.org/pub/linux/kernel/v5.x/ChangeLog-5.1.17", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://git.kernel.org/cgit/linux/kernel/git/torvalds/linux.git/commit/?id=6994eefb0053799d2e07cd140df6c2ea106c41ee", "source": "cve@mitre.org", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/6994eefb0053799d2e07cd140df6c2ea106c41ee", "source": "cve@mitre.org", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2019/07/msg00022.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.debian.org/debian-lts-announce/2019/07/msg00023.html", "source": "cve@mitre.org", "tags": ["Mailing List", "Third Party Advisory"]}, {"url": "https://lists.fedoraproject.org/archives/list/package-announce@lists.fedoraproject.org/message/OGRK5LYWBJ4E4SRI4DKX367NHYSI3VOH/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://seclists.org/bugtraq/2019/Jul/30", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Mailing List", "Third Party Advisory"]}, {"url": "https://seclists.org/bugtraq/2019/Jul/33", "source": "cve@mitre.org", "tags": ["Issue Tracking", "Mailing List", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20190806-0001/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://support.f5.com/csp/article/K91025336", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://support.f5.com/csp/article/K91025336?utm_source=f5support&amp;utm_medium=RSS", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4093-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4094-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4095-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4117-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://usn.ubuntu.com/4118-1/", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}, {"url": "https://www.debian.org/security/2019/dsa-4484", "source": "cve@mitre.org", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/6994eefb0053799d2e07cd140df6c2ea106c41ee"}}
{"buggy_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/array_ops.cc.\n\n#define EIGEN_USE_THREADS\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n#define EIGEN_USE_GPU\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#include \"tensorflow/core/kernels/linalg/matrix_set_diag_op.h\"\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/linalg/matrix_diag_op.h\"\n#include \"tensorflow/core/lib/core/threadpool.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/macros.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\n\ntemplate <typename Device, typename T>\nclass MatrixSetDiagOp : public OpKernel {\n public:\n  explicit MatrixSetDiagOp(OpKernelConstruction* context) : OpKernel(context) {\n    // MatrixSetDiagV3-specific.\n    if (context->HasAttr(\"align\")) {\n      functor::ReadAlignment(context, &left_align_superdiagonal_,\n                             &left_align_subdiagonal_);\n    }\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& diag = context->input(1);\n\n    // MatrixSetDiag and MatrixSetDiagV2 both use this OpKernel. MatrixSetDiag\n    // only has two inputs, so we have to check the number of inputs before\n    // reading additional parameters in MatrixSetDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n\n    // MatrixSetDiagV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(2);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n    }\n\n    const TensorShape& input_shape = input.shape();\n    const TensorShape& diag_shape = diag.shape();\n    const int input_rank = input_shape.dims();\n\n    // Preliminary validation of sizes.\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),\n                errors::InvalidArgument(\n                    \"input must be at least 2-dim, received shape: \",\n                    input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diag_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diag_shape.DebugString()));\n\n    // Make sure lower_diag_index and upper_diag_index is valid.\n    const Eigen::Index num_rows = input_shape.dim_size(input_rank - 2);\n    const Eigen::Index num_cols = input_shape.dim_size(input_rank - 1);\n    OP_REQUIRES(  // Checks lower_diag_index == 0 for when matrix shape = 0.\n        context,\n        (-num_rows < lower_diag_index && lower_diag_index < num_cols) ||\n            lower_diag_index == 0,\n        errors::InvalidArgument(\n            \"lower_diag_index is out of bound: \", lower_diag_index,\n            \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(context,\n                (-num_rows < upper_diag_index && upper_diag_index < num_cols) ||\n                    upper_diag_index == 0,\n                errors::InvalidArgument(\n                    \"upper_diag_index is out of bound: \", upper_diag_index,\n                    \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n\n    // Check if diag size is consistent with input.\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(\n        context,\n        lower_diag_index == upper_diag_index ||\n            (diag_shape.dim_size(input_rank - 2) == num_diags),\n        errors::InvalidArgument(\"The number of diagonals provided in `diag` \"\n                                \"is not consistent with `lower_diag_index` and \"\n                                \"`upper_diag_index`\"));\n\n    TensorShape expected_diag_shape = input_shape;\n    expected_diag_shape.RemoveLastDims(2);\n    if (num_diags > 1) expected_diag_shape.AddDim(num_diags);\n    const int32_t max_diag_len =\n        std::min(num_rows + std::min(upper_diag_index, 0),\n                 num_cols - std::max(lower_diag_index, 0));\n    expected_diag_shape.AddDim(max_diag_len);\n    OP_REQUIRES(\n        context, expected_diag_shape == diag_shape,\n        errors::InvalidArgument(\n            \"Either first dimensions of diagonal don't match input.shape[:-2], \"\n            \"or diagonal.shape[:-1] is not equal to the longests diagonal in \"\n            \"range [lower_diag_index:upper_diag_index].\\nInput shape: \",\n            input_shape.DebugString(),\n            \"\\nDiagonal shape: \", diag_shape.DebugString(),\n            \"\\nExpected diagonal shape: \", expected_diag_shape.DebugString()));\n\n    if (input.NumElements() == 0) {\n      // This is a no-op.\n      context->set_output(0, input);\n      return;\n    }\n\n    auto input_reshaped = input.flat_inner_dims<T, 3>();\n    auto diag_reshaped = diag.flat<T>();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, input_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    functor::MatrixSetDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), input_reshaped, diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n\n private:\n  bool left_align_superdiagonal_ = true;\n  bool left_align_subdiagonal_ = true;\n  static constexpr int kNumV1Inputs = 2;\n  TF_DISALLOW_COPY_AND_ASSIGN(MatrixSetDiagOp);\n};\n\n#define REGISTER_MATRIX_SET_DIAG(type)                                      \\\n  REGISTER_KERNEL_BUILDER(                                                  \\\n      Name(\"MatrixSetDiag\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"),   \\\n      MatrixSetDiagOp<CPUDevice, type>);                                    \\\n  REGISTER_KERNEL_BUILDER(                                                  \\\n      Name(\"MatrixSetDiagV2\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<CPUDevice, type>);                                    \\\n  REGISTER_KERNEL_BUILDER(                                                  \\\n      Name(\"MatrixSetDiagV3\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<CPUDevice, type>);\n\nTF_CALL_POD_TYPES(REGISTER_MATRIX_SET_DIAG);\n#undef REGISTER_MATRIX_SET_DIAG\n\n// Registration of the deprecated kernel.\n// Delete after 10mar2017.\n#define REGISTER_BATCH_MATRIX_SET_DIAG(type)                                   \\\n  REGISTER_KERNEL_BUILDER(                                                     \\\n      Name(\"BatchMatrixSetDiag\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<CPUDevice, type>);\nTF_CALL_POD_TYPES(REGISTER_BATCH_MATRIX_SET_DIAG);\n#undef REGISTER_BATCH_MATRIX_SET_DIAG\n\nnamespace functor {\n\n// Implementation of the functor specialization for CPU.\ntemplate <typename T>\nstruct MatrixSetDiag<CPUDevice, T> {\n  static void Compute(OpKernelContext* context, const CPUDevice& device,\n                      typename TTypes<T, 3>::ConstTensor& input,\n                      typename TTypes<T>::ConstTensor& diag,\n                      typename TTypes<T, 3>::Tensor& output,\n                      const Eigen::Index lower_diag_index,\n                      const Eigen::Index upper_diag_index,\n                      const Eigen::Index max_diag_len,\n                      const bool left_align_superdiagonal,\n                      const bool left_align_subdiagonal) {\n    if (input.data() != output.data()) {\n      output.device(device) = input;\n    }\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    auto compute_shard = [&output, &diag, &upper_diag_index, &max_diag_len,\n                          &num_diags, &left_align_superdiagonal,\n                          &left_align_subdiagonal](Eigen::Index begin,\n                                                   Eigen::Index end) {\n      const Eigen::Index num_rows = output.dimension(1);\n      const Eigen::Index num_cols = output.dimension(2);\n      Eigen::Index diag_base_index = begin * num_diags * max_diag_len;\n      for (Eigen::Index batch = begin; batch < end; ++batch) {\n        for (Eigen::Index m = 0; m < num_diags; ++m) {\n          const Eigen::Index diag_index = upper_diag_index - m;\n          int diag_len, content_offset;\n          std::tie(diag_len, content_offset) = ComputeDiagLenAndContentOffset(\n              diag_index, max_diag_len, num_rows, num_cols,\n              left_align_superdiagonal, left_align_subdiagonal);\n\n          // Make two separate cases to save some index calculations.\n          if (diag_index >= 0) {\n            for (Eigen::Index n = 0; n < diag_len; ++n) {\n              output(batch, n, n + diag_index) =\n                  diag(diag_base_index + n + content_offset);\n            }\n          } else {\n            for (Eigen::Index n = 0; n < diag_len; ++n) {\n              output(batch, n - diag_index, n) =\n                  diag(diag_base_index + n + content_offset);\n            }\n          }\n          diag_base_index += max_diag_len;\n        }\n      }\n    };\n    auto thread_pool =\n        context->device()->tensorflow_cpu_worker_threads()->workers;\n    // TODO(penporn): Tune for the best constant in cost_per_batch.\n    const Eigen::Index cost_per_batch = 10 * num_diags * max_diag_len;\n    thread_pool->ParallelFor(output.dimension(0), cost_per_batch,\n                             std::move(compute_shard));\n  }\n};\n\n}  // namespace functor\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n// Forward declarations of the functor specializations for GPU.\nnamespace functor {\n#define DECLARE_GPU_SPEC(T)                                                    \\\n  template <>                                                                  \\\n  void MatrixSetDiag<GPUDevice, T>::Compute(                                   \\\n      OpKernelContext* context, const GPUDevice& device,                       \\\n      typename TTypes<T, 3>::ConstTensor& input,                               \\\n      typename TTypes<T>::ConstTensor& diag,                                   \\\n      typename TTypes<T, 3>::Tensor& output,                                   \\\n      const Eigen::Index lower_diag_index,                                     \\\n      const Eigen::Index upper_diag_index, const Eigen::Index max_diag_len,    \\\n      const bool left_align_superdiagonal, const bool left_align_subdiagonal); \\\n  extern template struct MatrixSetDiag<GPUDevice, T>;\n\nTF_CALL_GPU_ALL_TYPES(DECLARE_GPU_SPEC);\n\n}  // namespace functor\n\n// Registration of the GPU implementations.\n#define REGISTER_MATRIX_SET_DIAG_GPU(type)                                \\\n  REGISTER_KERNEL_BUILDER(                                                \\\n      Name(\"MatrixSetDiag\").Device(DEVICE_GPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<GPUDevice, type>);                                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"MatrixSetDiagV2\")                         \\\n                              .Device(DEVICE_GPU)                         \\\n                              .TypeConstraint<type>(\"T\")                  \\\n                              .HostMemory(\"k\"),                           \\\n                          MatrixSetDiagOp<GPUDevice, type>);              \\\n  REGISTER_KERNEL_BUILDER(Name(\"MatrixSetDiagV3\")                         \\\n                              .Device(DEVICE_GPU)                         \\\n                              .TypeConstraint<type>(\"T\")                  \\\n                              .HostMemory(\"k\"),                           \\\n                          MatrixSetDiagOp<GPUDevice, type>);\n\nTF_CALL_GPU_ALL_TYPES(REGISTER_MATRIX_SET_DIAG_GPU);\n#undef REGISTER_MATRIX_SET_DIAG_GPU\n\n// Registration of the deprecated kernel.\n// Delete after 10mar2017.\n#define REGISTER_BATCH_MATRIX_SET_DIAG_GPU(type)                               \\\n  REGISTER_KERNEL_BUILDER(                                                     \\\n      Name(\"BatchMatrixSetDiag\").Device(DEVICE_GPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<GPUDevice, type>);\nTF_CALL_GPU_NUMBER_TYPES(REGISTER_BATCH_MATRIX_SET_DIAG_GPU);\n#undef REGISTER_BATCH_MATRIX_SET_DIAG_GPU\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n}  // namespace tensorflow\n"], "fixing_code": ["/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n\nLicensed under the Apache License, Version 2.0 (the \"License\");\nyou may not use this file except in compliance with the License.\nYou may obtain a copy of the License at\n\n    http://www.apache.org/licenses/LICENSE-2.0\n\nUnless required by applicable law or agreed to in writing, software\ndistributed under the License is distributed on an \"AS IS\" BASIS,\nWITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\nSee the License for the specific language governing permissions and\nlimitations under the License.\n==============================================================================*/\n\n// See docs in ../ops/array_ops.cc.\n\n#define EIGEN_USE_THREADS\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n#define EIGEN_USE_GPU\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n#include \"tensorflow/core/kernels/linalg/matrix_set_diag_op.h\"\n\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/register_types.h\"\n#include \"tensorflow/core/framework/tensor.h\"\n#include \"tensorflow/core/framework/tensor_shape.h\"\n#include \"tensorflow/core/framework/tensor_types.h\"\n#include \"tensorflow/core/framework/types.h\"\n#include \"tensorflow/core/kernels/linalg/matrix_diag_op.h\"\n#include \"tensorflow/core/lib/core/threadpool.h\"\n#include \"tensorflow/core/platform/logging.h\"\n#include \"tensorflow/core/platform/macros.h\"\n\nnamespace tensorflow {\n\ntypedef Eigen::ThreadPoolDevice CPUDevice;\ntypedef Eigen::GpuDevice GPUDevice;\n\ntemplate <typename Device, typename T>\nclass MatrixSetDiagOp : public OpKernel {\n public:\n  explicit MatrixSetDiagOp(OpKernelConstruction* context) : OpKernel(context) {\n    // MatrixSetDiagV3-specific.\n    if (context->HasAttr(\"align\")) {\n      functor::ReadAlignment(context, &left_align_superdiagonal_,\n                             &left_align_subdiagonal_);\n    }\n  }\n\n  void Compute(OpKernelContext* context) override {\n    const Tensor& input = context->input(0);\n    const Tensor& diag = context->input(1);\n\n    // MatrixSetDiag and MatrixSetDiagV2 both use this OpKernel. MatrixSetDiag\n    // only has two inputs, so we have to check the number of inputs before\n    // reading additional parameters in MatrixSetDiagV2.\n    int32_t lower_diag_index = 0;\n    int32_t upper_diag_index = 0;\n\n    // MatrixSetDiagV2-specific.\n    if (context->num_inputs() > kNumV1Inputs) {\n      auto& diag_index = context->input(2);\n      OP_REQUIRES(context,\n                  TensorShapeUtils::IsScalar(diag_index.shape()) ||\n                      TensorShapeUtils::IsVector(diag_index.shape()),\n                  errors::InvalidArgument(\n                      \"diag_index must be a scalar or vector, received shape: \",\n                      diag_index.shape().DebugString()));\n      OP_REQUIRES(\n          context, diag_index.NumElements() > 0,\n          errors::InvalidArgument(\"diag_index must have at least one element\"));\n      lower_diag_index = diag_index.flat<int32>()(0);\n      upper_diag_index = lower_diag_index;\n      if (TensorShapeUtils::IsVector(diag_index.shape())) {\n        auto diag_index_size = diag_index.dim_size(0);\n        OP_REQUIRES(\n            context, 0 < diag_index_size && diag_index_size <= 2,\n            errors::InvalidArgument(\n                \"diag_index must have only one or two elements, received \",\n                diag_index_size, \" elements.\"));\n        if (diag_index_size > 1) {\n          upper_diag_index = diag_index.flat<int32>()(1);\n        }\n      }\n    }\n\n    const TensorShape& input_shape = input.shape();\n    const TensorShape& diag_shape = diag.shape();\n    const int input_rank = input_shape.dims();\n\n    // Preliminary validation of sizes.\n    OP_REQUIRES(context, TensorShapeUtils::IsMatrixOrHigher(input_shape),\n                errors::InvalidArgument(\n                    \"input must be at least 2-dim, received shape: \",\n                    input.shape().DebugString()));\n    OP_REQUIRES(context, TensorShapeUtils::IsVectorOrHigher(diag_shape),\n                errors::InvalidArgument(\n                    \"diagonal must be at least 1-dim, received shape: \",\n                    diag_shape.DebugString()));\n\n    // Make sure lower_diag_index and upper_diag_index is valid.\n    const Eigen::Index num_rows = input_shape.dim_size(input_rank - 2);\n    const Eigen::Index num_cols = input_shape.dim_size(input_rank - 1);\n    OP_REQUIRES(  // Checks lower_diag_index == 0 for when matrix shape = 0.\n        context,\n        (-num_rows < lower_diag_index && lower_diag_index < num_cols) ||\n            lower_diag_index == 0,\n        errors::InvalidArgument(\n            \"lower_diag_index is out of bound: \", lower_diag_index,\n            \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(context,\n                (-num_rows < upper_diag_index && upper_diag_index < num_cols) ||\n                    upper_diag_index == 0,\n                errors::InvalidArgument(\n                    \"upper_diag_index is out of bound: \", upper_diag_index,\n                    \" It must be between \", -num_rows, \" and \", num_cols));\n    OP_REQUIRES(\n        context, lower_diag_index <= upper_diag_index,\n        errors::InvalidArgument(\n            \"lower_diag_index must not be larger than upper_diag_index: \",\n            lower_diag_index, \" > \", upper_diag_index));\n\n    // Check if diag size is consistent with input.\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    OP_REQUIRES(\n        context,\n        lower_diag_index == upper_diag_index ||\n            (diag_shape.dim_size(input_rank - 2) == num_diags),\n        errors::InvalidArgument(\"The number of diagonals provided in `diag` \"\n                                \"is not consistent with `lower_diag_index` and \"\n                                \"`upper_diag_index`\"));\n\n    TensorShape expected_diag_shape = input_shape;\n    expected_diag_shape.RemoveLastDims(2);\n    if (num_diags > 1) expected_diag_shape.AddDim(num_diags);\n    const int32_t max_diag_len =\n        std::min(num_rows + std::min(upper_diag_index, 0),\n                 num_cols - std::max(lower_diag_index, 0));\n    expected_diag_shape.AddDim(max_diag_len);\n    OP_REQUIRES(\n        context, expected_diag_shape == diag_shape,\n        errors::InvalidArgument(\n            \"Either first dimensions of diagonal don't match input.shape[:-2], \"\n            \"or diagonal.shape[:-1] is not equal to the longests diagonal in \"\n            \"range [lower_diag_index:upper_diag_index].\\nInput shape: \",\n            input_shape.DebugString(),\n            \"\\nDiagonal shape: \", diag_shape.DebugString(),\n            \"\\nExpected diagonal shape: \", expected_diag_shape.DebugString()));\n\n    if (input.NumElements() == 0) {\n      // This is a no-op.\n      context->set_output(0, input);\n      return;\n    }\n\n    auto input_reshaped = input.flat_inner_dims<T, 3>();\n    auto diag_reshaped = diag.flat<T>();\n    Tensor* output = nullptr;\n    OP_REQUIRES_OK(context, context->forward_input_or_allocate_output(\n                                {0}, 0, input_shape, &output));\n    auto output_reshaped = output->flat_inner_dims<T, 3>();\n    functor::MatrixSetDiag<Device, T>::Compute(\n        context, context->eigen_device<Device>(), input_reshaped, diag_reshaped,\n        output_reshaped, lower_diag_index, upper_diag_index, max_diag_len,\n        left_align_superdiagonal_, left_align_subdiagonal_);\n  }\n\n private:\n  bool left_align_superdiagonal_ = true;\n  bool left_align_subdiagonal_ = true;\n  static constexpr int kNumV1Inputs = 2;\n  TF_DISALLOW_COPY_AND_ASSIGN(MatrixSetDiagOp);\n};\n\n#define REGISTER_MATRIX_SET_DIAG(type)                                      \\\n  REGISTER_KERNEL_BUILDER(                                                  \\\n      Name(\"MatrixSetDiag\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"),   \\\n      MatrixSetDiagOp<CPUDevice, type>);                                    \\\n  REGISTER_KERNEL_BUILDER(                                                  \\\n      Name(\"MatrixSetDiagV2\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<CPUDevice, type>);                                    \\\n  REGISTER_KERNEL_BUILDER(                                                  \\\n      Name(\"MatrixSetDiagV3\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<CPUDevice, type>);\n\nTF_CALL_POD_TYPES(REGISTER_MATRIX_SET_DIAG);\n#undef REGISTER_MATRIX_SET_DIAG\n\n// Registration of the deprecated kernel.\n// Delete after 10mar2017.\n#define REGISTER_BATCH_MATRIX_SET_DIAG(type)                                   \\\n  REGISTER_KERNEL_BUILDER(                                                     \\\n      Name(\"BatchMatrixSetDiag\").Device(DEVICE_CPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<CPUDevice, type>);\nTF_CALL_POD_TYPES(REGISTER_BATCH_MATRIX_SET_DIAG);\n#undef REGISTER_BATCH_MATRIX_SET_DIAG\n\nnamespace functor {\n\n// Implementation of the functor specialization for CPU.\ntemplate <typename T>\nstruct MatrixSetDiag<CPUDevice, T> {\n  static void Compute(OpKernelContext* context, const CPUDevice& device,\n                      typename TTypes<T, 3>::ConstTensor& input,\n                      typename TTypes<T>::ConstTensor& diag,\n                      typename TTypes<T, 3>::Tensor& output,\n                      const Eigen::Index lower_diag_index,\n                      const Eigen::Index upper_diag_index,\n                      const Eigen::Index max_diag_len,\n                      const bool left_align_superdiagonal,\n                      const bool left_align_subdiagonal) {\n    if (input.data() != output.data()) {\n      output.device(device) = input;\n    }\n    const Eigen::Index num_diags = upper_diag_index - lower_diag_index + 1;\n    auto compute_shard = [&output, &diag, &upper_diag_index, &max_diag_len,\n                          &num_diags, &left_align_superdiagonal,\n                          &left_align_subdiagonal](Eigen::Index begin,\n                                                   Eigen::Index end) {\n      const Eigen::Index num_rows = output.dimension(1);\n      const Eigen::Index num_cols = output.dimension(2);\n      Eigen::Index diag_base_index = begin * num_diags * max_diag_len;\n      for (Eigen::Index batch = begin; batch < end; ++batch) {\n        for (Eigen::Index m = 0; m < num_diags; ++m) {\n          const Eigen::Index diag_index = upper_diag_index - m;\n          int diag_len, content_offset;\n          std::tie(diag_len, content_offset) = ComputeDiagLenAndContentOffset(\n              diag_index, max_diag_len, num_rows, num_cols,\n              left_align_superdiagonal, left_align_subdiagonal);\n\n          // Make two separate cases to save some index calculations.\n          if (diag_index >= 0) {\n            for (Eigen::Index n = 0; n < diag_len; ++n) {\n              output(batch, n, n + diag_index) =\n                  diag(diag_base_index + n + content_offset);\n            }\n          } else {\n            for (Eigen::Index n = 0; n < diag_len; ++n) {\n              output(batch, n - diag_index, n) =\n                  diag(diag_base_index + n + content_offset);\n            }\n          }\n          diag_base_index += max_diag_len;\n        }\n      }\n    };\n    auto thread_pool =\n        context->device()->tensorflow_cpu_worker_threads()->workers;\n    // TODO(penporn): Tune for the best constant in cost_per_batch.\n    const Eigen::Index cost_per_batch = 10 * num_diags * max_diag_len;\n    thread_pool->ParallelFor(output.dimension(0), cost_per_batch,\n                             std::move(compute_shard));\n  }\n};\n\n}  // namespace functor\n\n#if GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n// Forward declarations of the functor specializations for GPU.\nnamespace functor {\n#define DECLARE_GPU_SPEC(T)                                                    \\\n  template <>                                                                  \\\n  void MatrixSetDiag<GPUDevice, T>::Compute(                                   \\\n      OpKernelContext* context, const GPUDevice& device,                       \\\n      typename TTypes<T, 3>::ConstTensor& input,                               \\\n      typename TTypes<T>::ConstTensor& diag,                                   \\\n      typename TTypes<T, 3>::Tensor& output,                                   \\\n      const Eigen::Index lower_diag_index,                                     \\\n      const Eigen::Index upper_diag_index, const Eigen::Index max_diag_len,    \\\n      const bool left_align_superdiagonal, const bool left_align_subdiagonal); \\\n  extern template struct MatrixSetDiag<GPUDevice, T>;\n\nTF_CALL_GPU_ALL_TYPES(DECLARE_GPU_SPEC);\n\n}  // namespace functor\n\n// Registration of the GPU implementations.\n#define REGISTER_MATRIX_SET_DIAG_GPU(type)                                \\\n  REGISTER_KERNEL_BUILDER(                                                \\\n      Name(\"MatrixSetDiag\").Device(DEVICE_GPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<GPUDevice, type>);                                  \\\n  REGISTER_KERNEL_BUILDER(Name(\"MatrixSetDiagV2\")                         \\\n                              .Device(DEVICE_GPU)                         \\\n                              .TypeConstraint<type>(\"T\")                  \\\n                              .HostMemory(\"k\"),                           \\\n                          MatrixSetDiagOp<GPUDevice, type>);              \\\n  REGISTER_KERNEL_BUILDER(Name(\"MatrixSetDiagV3\")                         \\\n                              .Device(DEVICE_GPU)                         \\\n                              .TypeConstraint<type>(\"T\")                  \\\n                              .HostMemory(\"k\"),                           \\\n                          MatrixSetDiagOp<GPUDevice, type>);\n\nTF_CALL_GPU_ALL_TYPES(REGISTER_MATRIX_SET_DIAG_GPU);\n#undef REGISTER_MATRIX_SET_DIAG_GPU\n\n// Registration of the deprecated kernel.\n// Delete after 10mar2017.\n#define REGISTER_BATCH_MATRIX_SET_DIAG_GPU(type)                               \\\n  REGISTER_KERNEL_BUILDER(                                                     \\\n      Name(\"BatchMatrixSetDiag\").Device(DEVICE_GPU).TypeConstraint<type>(\"T\"), \\\n      MatrixSetDiagOp<GPUDevice, type>);\nTF_CALL_GPU_NUMBER_TYPES(REGISTER_BATCH_MATRIX_SET_DIAG_GPU);\n#undef REGISTER_BATCH_MATRIX_SET_DIAG_GPU\n\n#endif  // GOOGLE_CUDA || TENSORFLOW_USE_ROCM\n\n}  // namespace tensorflow\n"], "filenames": ["tensorflow/core/kernels/linalg/matrix_set_diag_op.cc"], "buggy_code_start_loc": [72], "buggy_code_end_loc": [72], "fixing_code_start_loc": [73], "fixing_code_end_loc": [76], "type": "CWE-824", "message": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in all operations of type `tf.raw_ops.MatrixSetDiagV*`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/linalg/matrix_diag_op.cc) has incomplete validation that the value of `k` is a valid tensor. We have check that this value is either a scalar or a vector, but there is no check for the number of elements. If this is an empty tensor, then code that accesses the first element of the tensor is wrong. We have patched the issue in GitHub commit ff8894044dfae5568ecbf2ed514c1a37dc394f1b. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range.", "other": {"cve": {"id": "CVE-2021-37658", "sourceIdentifier": "security-advisories@github.com", "published": "2021-08-12T21:15:08.667", "lastModified": "2021-08-18T21:10:03.590", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "TensorFlow is an end-to-end open source platform for machine learning. In affected versions an attacker can cause undefined behavior via binding a reference to null pointer in all operations of type `tf.raw_ops.MatrixSetDiagV*`. The [implementation](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/linalg/matrix_diag_op.cc) has incomplete validation that the value of `k` is a valid tensor. We have check that this value is either a scalar or a vector, but there is no check for the number of elements. If this is an empty tensor, then code that accesses the first element of the tensor is wrong. We have patched the issue in GitHub commit ff8894044dfae5568ecbf2ed514c1a37dc394f1b. The fix will be included in TensorFlow 2.6.0. We will also cherrypick this commit on TensorFlow 2.5.1, TensorFlow 2.4.3, and TensorFlow 2.3.4, as these are also affected and still in supported range."}, {"lang": "es", "value": "TensorFlow es una plataforma de c\u00f3digo abierto de extremo a extremo para el aprendizaje autom\u00e1tico. En las versiones afectadas un atacante puede causar un comportamiento indefinido por medio de la vinculaci\u00f3n de una referencia a un puntero null en todas las operaciones de tipo \"tf.raw_ops.MatrixSetDiagV*\". La [implementaci\u00f3n](https://github.com/tensorflow/tensorflow/blob/84d053187cb80d975ef2b9684d4b61981bca0c41/tensorflow/core/kernels/linalg/matrix_diag_op.cc) presenta una comprobaci\u00f3n incompleta de que el valor de \"k\" es un tensor v\u00e1lido. Se comprueba que este valor es un escalar o un vector, pero no se comprueba el n\u00famero de elementos. Si se trata de un tensor vac\u00edo, el c\u00f3digo que accede al primer elemento del tensor es err\u00f3neo. Hemos parcheado el problema en el commit ff8894044dfae5568ecbf2ed514c1a37dc394f1b de GitHub. La correcci\u00f3n ser\u00e1 incluida en TensorFlow versi\u00f3n 2.6.0. Tambi\u00e9n seleccionaremos este commit en TensorFlow 2.5.1, TensorFlow 2.4.3 y TensorFlow 2.3.4, ya que estos tambi\u00e9n est\u00e1n afectados y todav\u00eda est\u00e1n en el rango de soporte."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.8, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.9}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:N/I:H/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:P/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "PARTIAL", "availabilityImpact": "PARTIAL", "baseScore": 4.6}, "baseSeverity": "MEDIUM", "exploitabilityScore": 3.9, "impactScore": 6.4, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-824"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.3.0", "versionEndExcluding": "2.3.4", "matchCriteriaId": "0F83C081-51CC-415F-A8C0-0A44C75E2CD6"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:*:*:*:*:*:*:*:*", "versionStartIncluding": "2.4.0", "versionEndExcluding": "2.4.3", "matchCriteriaId": "BD3F2BF8-EBA9-42BF-8F9B-D918B880B15A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.5.0:*:*:*:*:*:*:*", "matchCriteriaId": "D03E99A7-4E3D-427D-A156-C0713E9FB02A"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc0:*:*:*:*:*:*", "matchCriteriaId": "70FA6E48-6C57-40CA-809F-4E3D07CBF348"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc1:*:*:*:*:*:*", "matchCriteriaId": "42187561-E491-434D-828C-F36701446634"}, {"vulnerable": true, "criteria": "cpe:2.3:a:google:tensorflow:2.6.0:rc2:*:*:*:*:*:*", "matchCriteriaId": "C66B61C8-450A-4C5E-9174-F970D6DEE778"}]}]}], "references": [{"url": "https://github.com/tensorflow/tensorflow/commit/ff8894044dfae5568ecbf2ed514c1a37dc394f1b", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/tensorflow/tensorflow/security/advisories/GHSA-6p5r-g9mq-ggh2", "source": "security-advisories@github.com", "tags": ["Third Party Advisory"]}]}, "github_commit_url": "https://github.com/tensorflow/tensorflow/commit/ff8894044dfae5568ecbf2ed514c1a37dc394f1b"}}
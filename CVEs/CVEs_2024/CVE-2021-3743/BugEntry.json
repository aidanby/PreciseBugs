{"buggy_code": ["// SPDX-License-Identifier: GPL-2.0-only\n/*\n * Copyright (c) 2015, Sony Mobile Communications Inc.\n * Copyright (c) 2013, The Linux Foundation. All rights reserved.\n */\n#include <linux/module.h>\n#include <linux/netlink.h>\n#include <linux/qrtr.h>\n#include <linux/termios.h>\t/* For TIOCINQ/OUTQ */\n#include <linux/spinlock.h>\n#include <linux/wait.h>\n\n#include <net/sock.h>\n\n#include \"qrtr.h\"\n\n#define QRTR_PROTO_VER_1 1\n#define QRTR_PROTO_VER_2 3\n\n/* auto-bind range */\n#define QRTR_MIN_EPH_SOCKET 0x4000\n#define QRTR_MAX_EPH_SOCKET 0x7fff\n#define QRTR_EPH_PORT_RANGE \\\n\t\tXA_LIMIT(QRTR_MIN_EPH_SOCKET, QRTR_MAX_EPH_SOCKET)\n\n/**\n * struct qrtr_hdr_v1 - (I|R)PCrouter packet header version 1\n * @version: protocol version\n * @type: packet type; one of QRTR_TYPE_*\n * @src_node_id: source node\n * @src_port_id: source port\n * @confirm_rx: boolean; whether a resume-tx packet should be send in reply\n * @size: length of packet, excluding this header\n * @dst_node_id: destination node\n * @dst_port_id: destination port\n */\nstruct qrtr_hdr_v1 {\n\t__le32 version;\n\t__le32 type;\n\t__le32 src_node_id;\n\t__le32 src_port_id;\n\t__le32 confirm_rx;\n\t__le32 size;\n\t__le32 dst_node_id;\n\t__le32 dst_port_id;\n} __packed;\n\n/**\n * struct qrtr_hdr_v2 - (I|R)PCrouter packet header later versions\n * @version: protocol version\n * @type: packet type; one of QRTR_TYPE_*\n * @flags: bitmask of QRTR_FLAGS_*\n * @optlen: length of optional header data\n * @size: length of packet, excluding this header and optlen\n * @src_node_id: source node\n * @src_port_id: source port\n * @dst_node_id: destination node\n * @dst_port_id: destination port\n */\nstruct qrtr_hdr_v2 {\n\tu8 version;\n\tu8 type;\n\tu8 flags;\n\tu8 optlen;\n\t__le32 size;\n\t__le16 src_node_id;\n\t__le16 src_port_id;\n\t__le16 dst_node_id;\n\t__le16 dst_port_id;\n};\n\n#define QRTR_FLAGS_CONFIRM_RX\tBIT(0)\n\nstruct qrtr_cb {\n\tu32 src_node;\n\tu32 src_port;\n\tu32 dst_node;\n\tu32 dst_port;\n\n\tu8 type;\n\tu8 confirm_rx;\n};\n\n#define QRTR_HDR_MAX_SIZE max_t(size_t, sizeof(struct qrtr_hdr_v1), \\\n\t\t\t\t\tsizeof(struct qrtr_hdr_v2))\n\nstruct qrtr_sock {\n\t/* WARNING: sk must be the first member */\n\tstruct sock sk;\n\tstruct sockaddr_qrtr us;\n\tstruct sockaddr_qrtr peer;\n};\n\nstatic inline struct qrtr_sock *qrtr_sk(struct sock *sk)\n{\n\tBUILD_BUG_ON(offsetof(struct qrtr_sock, sk) != 0);\n\treturn container_of(sk, struct qrtr_sock, sk);\n}\n\nstatic unsigned int qrtr_local_nid = 1;\n\n/* for node ids */\nstatic RADIX_TREE(qrtr_nodes, GFP_ATOMIC);\nstatic DEFINE_SPINLOCK(qrtr_nodes_lock);\n/* broadcast list */\nstatic LIST_HEAD(qrtr_all_nodes);\n/* lock for qrtr_all_nodes and node reference */\nstatic DEFINE_MUTEX(qrtr_node_lock);\n\n/* local port allocation management */\nstatic DEFINE_XARRAY_ALLOC(qrtr_ports);\n\n/**\n * struct qrtr_node - endpoint node\n * @ep_lock: lock for endpoint management and callbacks\n * @ep: endpoint\n * @ref: reference count for node\n * @nid: node id\n * @qrtr_tx_flow: tree of qrtr_tx_flow, keyed by node << 32 | port\n * @qrtr_tx_lock: lock for qrtr_tx_flow inserts\n * @rx_queue: receive queue\n * @item: list item for broadcast list\n */\nstruct qrtr_node {\n\tstruct mutex ep_lock;\n\tstruct qrtr_endpoint *ep;\n\tstruct kref ref;\n\tunsigned int nid;\n\n\tstruct radix_tree_root qrtr_tx_flow;\n\tstruct mutex qrtr_tx_lock; /* for qrtr_tx_flow */\n\n\tstruct sk_buff_head rx_queue;\n\tstruct list_head item;\n};\n\n/**\n * struct qrtr_tx_flow - tx flow control\n * @resume_tx: waiters for a resume tx from the remote\n * @pending: number of waiting senders\n * @tx_failed: indicates that a message with confirm_rx flag was lost\n */\nstruct qrtr_tx_flow {\n\tstruct wait_queue_head resume_tx;\n\tint pending;\n\tint tx_failed;\n};\n\n#define QRTR_TX_FLOW_HIGH\t10\n#define QRTR_TX_FLOW_LOW\t5\n\nstatic int qrtr_local_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t      int type, struct sockaddr_qrtr *from,\n\t\t\t      struct sockaddr_qrtr *to);\nstatic int qrtr_bcast_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t      int type, struct sockaddr_qrtr *from,\n\t\t\t      struct sockaddr_qrtr *to);\nstatic struct qrtr_sock *qrtr_port_lookup(int port);\nstatic void qrtr_port_put(struct qrtr_sock *ipc);\n\n/* Release node resources and free the node.\n *\n * Do not call directly, use qrtr_node_release.  To be used with\n * kref_put_mutex.  As such, the node mutex is expected to be locked on call.\n */\nstatic void __qrtr_node_release(struct kref *kref)\n{\n\tstruct qrtr_node *node = container_of(kref, struct qrtr_node, ref);\n\tstruct radix_tree_iter iter;\n\tstruct qrtr_tx_flow *flow;\n\tunsigned long flags;\n\tvoid __rcu **slot;\n\n\tspin_lock_irqsave(&qrtr_nodes_lock, flags);\n\t/* If the node is a bridge for other nodes, there are possibly\n\t * multiple entries pointing to our released node, delete them all.\n\t */\n\tradix_tree_for_each_slot(slot, &qrtr_nodes, &iter, 0) {\n\t\tif (*slot == node)\n\t\t\tradix_tree_iter_delete(&qrtr_nodes, &iter, slot);\n\t}\n\tspin_unlock_irqrestore(&qrtr_nodes_lock, flags);\n\n\tlist_del(&node->item);\n\tmutex_unlock(&qrtr_node_lock);\n\n\tskb_queue_purge(&node->rx_queue);\n\n\t/* Free tx flow counters */\n\tradix_tree_for_each_slot(slot, &node->qrtr_tx_flow, &iter, 0) {\n\t\tflow = *slot;\n\t\tradix_tree_iter_delete(&node->qrtr_tx_flow, &iter, slot);\n\t\tkfree(flow);\n\t}\n\tkfree(node);\n}\n\n/* Increment reference to node. */\nstatic struct qrtr_node *qrtr_node_acquire(struct qrtr_node *node)\n{\n\tif (node)\n\t\tkref_get(&node->ref);\n\treturn node;\n}\n\n/* Decrement reference to node and release as necessary. */\nstatic void qrtr_node_release(struct qrtr_node *node)\n{\n\tif (!node)\n\t\treturn;\n\tkref_put_mutex(&node->ref, __qrtr_node_release, &qrtr_node_lock);\n}\n\n/**\n * qrtr_tx_resume() - reset flow control counter\n * @node:\tqrtr_node that the QRTR_TYPE_RESUME_TX packet arrived on\n * @skb:\tresume_tx packet\n */\nstatic void qrtr_tx_resume(struct qrtr_node *node, struct sk_buff *skb)\n{\n\tstruct qrtr_ctrl_pkt *pkt = (struct qrtr_ctrl_pkt *)skb->data;\n\tu64 remote_node = le32_to_cpu(pkt->client.node);\n\tu32 remote_port = le32_to_cpu(pkt->client.port);\n\tstruct qrtr_tx_flow *flow;\n\tunsigned long key;\n\n\tkey = remote_node << 32 | remote_port;\n\n\trcu_read_lock();\n\tflow = radix_tree_lookup(&node->qrtr_tx_flow, key);\n\trcu_read_unlock();\n\tif (flow) {\n\t\tspin_lock(&flow->resume_tx.lock);\n\t\tflow->pending = 0;\n\t\tspin_unlock(&flow->resume_tx.lock);\n\t\twake_up_interruptible_all(&flow->resume_tx);\n\t}\n\n\tconsume_skb(skb);\n}\n\n/**\n * qrtr_tx_wait() - flow control for outgoing packets\n * @node:\tqrtr_node that the packet is to be send to\n * @dest_node:\tnode id of the destination\n * @dest_port:\tport number of the destination\n * @type:\ttype of message\n *\n * The flow control scheme is based around the low and high \"watermarks\". When\n * the low watermark is passed the confirm_rx flag is set on the outgoing\n * message, which will trigger the remote to send a control message of the type\n * QRTR_TYPE_RESUME_TX to reset the counter. If the high watermark is hit\n * further transmision should be paused.\n *\n * Return: 1 if confirm_rx should be set, 0 otherwise or errno failure\n */\nstatic int qrtr_tx_wait(struct qrtr_node *node, int dest_node, int dest_port,\n\t\t\tint type)\n{\n\tunsigned long key = (u64)dest_node << 32 | dest_port;\n\tstruct qrtr_tx_flow *flow;\n\tint confirm_rx = 0;\n\tint ret;\n\n\t/* Never set confirm_rx on non-data packets */\n\tif (type != QRTR_TYPE_DATA)\n\t\treturn 0;\n\n\tmutex_lock(&node->qrtr_tx_lock);\n\tflow = radix_tree_lookup(&node->qrtr_tx_flow, key);\n\tif (!flow) {\n\t\tflow = kzalloc(sizeof(*flow), GFP_KERNEL);\n\t\tif (flow) {\n\t\t\tinit_waitqueue_head(&flow->resume_tx);\n\t\t\tif (radix_tree_insert(&node->qrtr_tx_flow, key, flow)) {\n\t\t\t\tkfree(flow);\n\t\t\t\tflow = NULL;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&node->qrtr_tx_lock);\n\n\t/* Set confirm_rx if we where unable to find and allocate a flow */\n\tif (!flow)\n\t\treturn 1;\n\n\tspin_lock_irq(&flow->resume_tx.lock);\n\tret = wait_event_interruptible_locked_irq(flow->resume_tx,\n\t\t\t\t\t\t  flow->pending < QRTR_TX_FLOW_HIGH ||\n\t\t\t\t\t\t  flow->tx_failed ||\n\t\t\t\t\t\t  !node->ep);\n\tif (ret < 0) {\n\t\tconfirm_rx = ret;\n\t} else if (!node->ep) {\n\t\tconfirm_rx = -EPIPE;\n\t} else if (flow->tx_failed) {\n\t\tflow->tx_failed = 0;\n\t\tconfirm_rx = 1;\n\t} else {\n\t\tflow->pending++;\n\t\tconfirm_rx = flow->pending == QRTR_TX_FLOW_LOW;\n\t}\n\tspin_unlock_irq(&flow->resume_tx.lock);\n\n\treturn confirm_rx;\n}\n\n/**\n * qrtr_tx_flow_failed() - flag that tx of confirm_rx flagged messages failed\n * @node:\tqrtr_node that the packet is to be send to\n * @dest_node:\tnode id of the destination\n * @dest_port:\tport number of the destination\n *\n * Signal that the transmission of a message with confirm_rx flag failed. The\n * flow's \"pending\" counter will keep incrementing towards QRTR_TX_FLOW_HIGH,\n * at which point transmission would stall forever waiting for the resume TX\n * message associated with the dropped confirm_rx message.\n * Work around this by marking the flow as having a failed transmission and\n * cause the next transmission attempt to be sent with the confirm_rx.\n */\nstatic void qrtr_tx_flow_failed(struct qrtr_node *node, int dest_node,\n\t\t\t\tint dest_port)\n{\n\tunsigned long key = (u64)dest_node << 32 | dest_port;\n\tstruct qrtr_tx_flow *flow;\n\n\trcu_read_lock();\n\tflow = radix_tree_lookup(&node->qrtr_tx_flow, key);\n\trcu_read_unlock();\n\tif (flow) {\n\t\tspin_lock_irq(&flow->resume_tx.lock);\n\t\tflow->tx_failed = 1;\n\t\tspin_unlock_irq(&flow->resume_tx.lock);\n\t}\n}\n\n/* Pass an outgoing packet socket buffer to the endpoint driver. */\nstatic int qrtr_node_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t     int type, struct sockaddr_qrtr *from,\n\t\t\t     struct sockaddr_qrtr *to)\n{\n\tstruct qrtr_hdr_v1 *hdr;\n\tsize_t len = skb->len;\n\tint rc, confirm_rx;\n\n\tconfirm_rx = qrtr_tx_wait(node, to->sq_node, to->sq_port, type);\n\tif (confirm_rx < 0) {\n\t\tkfree_skb(skb);\n\t\treturn confirm_rx;\n\t}\n\n\thdr = skb_push(skb, sizeof(*hdr));\n\thdr->version = cpu_to_le32(QRTR_PROTO_VER_1);\n\thdr->type = cpu_to_le32(type);\n\thdr->src_node_id = cpu_to_le32(from->sq_node);\n\thdr->src_port_id = cpu_to_le32(from->sq_port);\n\tif (to->sq_port == QRTR_PORT_CTRL) {\n\t\thdr->dst_node_id = cpu_to_le32(node->nid);\n\t\thdr->dst_port_id = cpu_to_le32(QRTR_PORT_CTRL);\n\t} else {\n\t\thdr->dst_node_id = cpu_to_le32(to->sq_node);\n\t\thdr->dst_port_id = cpu_to_le32(to->sq_port);\n\t}\n\n\thdr->size = cpu_to_le32(len);\n\thdr->confirm_rx = !!confirm_rx;\n\n\trc = skb_put_padto(skb, ALIGN(len, 4) + sizeof(*hdr));\n\n\tif (!rc) {\n\t\tmutex_lock(&node->ep_lock);\n\t\trc = -ENODEV;\n\t\tif (node->ep)\n\t\t\trc = node->ep->xmit(node->ep, skb);\n\t\telse\n\t\t\tkfree_skb(skb);\n\t\tmutex_unlock(&node->ep_lock);\n\t}\n\t/* Need to ensure that a subsequent message carries the otherwise lost\n\t * confirm_rx flag if we dropped this one */\n\tif (rc && confirm_rx)\n\t\tqrtr_tx_flow_failed(node, to->sq_node, to->sq_port);\n\n\treturn rc;\n}\n\n/* Lookup node by id.\n *\n * callers must release with qrtr_node_release()\n */\nstatic struct qrtr_node *qrtr_node_lookup(unsigned int nid)\n{\n\tstruct qrtr_node *node;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&qrtr_nodes_lock, flags);\n\tnode = radix_tree_lookup(&qrtr_nodes, nid);\n\tnode = qrtr_node_acquire(node);\n\tspin_unlock_irqrestore(&qrtr_nodes_lock, flags);\n\n\treturn node;\n}\n\n/* Assign node id to node.\n *\n * This is mostly useful for automatic node id assignment, based on\n * the source id in the incoming packet.\n */\nstatic void qrtr_node_assign(struct qrtr_node *node, unsigned int nid)\n{\n\tunsigned long flags;\n\n\tif (nid == QRTR_EP_NID_AUTO)\n\t\treturn;\n\n\tspin_lock_irqsave(&qrtr_nodes_lock, flags);\n\tradix_tree_insert(&qrtr_nodes, nid, node);\n\tif (node->nid == QRTR_EP_NID_AUTO)\n\t\tnode->nid = nid;\n\tspin_unlock_irqrestore(&qrtr_nodes_lock, flags);\n}\n\n/**\n * qrtr_endpoint_post() - post incoming data\n * @ep: endpoint handle\n * @data: data pointer\n * @len: size of data in bytes\n *\n * Return: 0 on success; negative error code on failure\n */\nint qrtr_endpoint_post(struct qrtr_endpoint *ep, const void *data, size_t len)\n{\n\tstruct qrtr_node *node = ep->node;\n\tconst struct qrtr_hdr_v1 *v1;\n\tconst struct qrtr_hdr_v2 *v2;\n\tstruct qrtr_sock *ipc;\n\tstruct sk_buff *skb;\n\tstruct qrtr_cb *cb;\n\tsize_t size;\n\tunsigned int ver;\n\tsize_t hdrlen;\n\n\tif (len == 0 || len & 3)\n\t\treturn -EINVAL;\n\n\tskb = __netdev_alloc_skb(NULL, len, GFP_ATOMIC | __GFP_NOWARN);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcb = (struct qrtr_cb *)skb->cb;\n\n\t/* Version field in v1 is little endian, so this works for both cases */\n\tver = *(u8*)data;\n\n\tswitch (ver) {\n\tcase QRTR_PROTO_VER_1:\n\t\tif (len < sizeof(*v1))\n\t\t\tgoto err;\n\t\tv1 = data;\n\t\thdrlen = sizeof(*v1);\n\n\t\tcb->type = le32_to_cpu(v1->type);\n\t\tcb->src_node = le32_to_cpu(v1->src_node_id);\n\t\tcb->src_port = le32_to_cpu(v1->src_port_id);\n\t\tcb->confirm_rx = !!v1->confirm_rx;\n\t\tcb->dst_node = le32_to_cpu(v1->dst_node_id);\n\t\tcb->dst_port = le32_to_cpu(v1->dst_port_id);\n\n\t\tsize = le32_to_cpu(v1->size);\n\t\tbreak;\n\tcase QRTR_PROTO_VER_2:\n\t\tif (len < sizeof(*v2))\n\t\t\tgoto err;\n\t\tv2 = data;\n\t\thdrlen = sizeof(*v2) + v2->optlen;\n\n\t\tcb->type = v2->type;\n\t\tcb->confirm_rx = !!(v2->flags & QRTR_FLAGS_CONFIRM_RX);\n\t\tcb->src_node = le16_to_cpu(v2->src_node_id);\n\t\tcb->src_port = le16_to_cpu(v2->src_port_id);\n\t\tcb->dst_node = le16_to_cpu(v2->dst_node_id);\n\t\tcb->dst_port = le16_to_cpu(v2->dst_port_id);\n\n\t\tif (cb->src_port == (u16)QRTR_PORT_CTRL)\n\t\t\tcb->src_port = QRTR_PORT_CTRL;\n\t\tif (cb->dst_port == (u16)QRTR_PORT_CTRL)\n\t\t\tcb->dst_port = QRTR_PORT_CTRL;\n\n\t\tsize = le32_to_cpu(v2->size);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"qrtr: Invalid version %d\\n\", ver);\n\t\tgoto err;\n\t}\n\n\tif (len != ALIGN(size, 4) + hdrlen)\n\t\tgoto err;\n\n\tif (cb->dst_port != QRTR_PORT_CTRL && cb->type != QRTR_TYPE_DATA &&\n\t    cb->type != QRTR_TYPE_RESUME_TX)\n\t\tgoto err;\n\n\tskb_put_data(skb, data + hdrlen, size);\n\n\tqrtr_node_assign(node, cb->src_node);\n\n\tif (cb->type == QRTR_TYPE_NEW_SERVER) {\n\t\t/* Remote node endpoint can bridge other distant nodes */\n\t\tconst struct qrtr_ctrl_pkt *pkt = data + hdrlen;\n\n\t\tqrtr_node_assign(node, le32_to_cpu(pkt->server.node));\n\t}\n\n\tif (cb->type == QRTR_TYPE_RESUME_TX) {\n\t\tqrtr_tx_resume(node, skb);\n\t} else {\n\t\tipc = qrtr_port_lookup(cb->dst_port);\n\t\tif (!ipc)\n\t\t\tgoto err;\n\n\t\tif (sock_queue_rcv_skb(&ipc->sk, skb)) {\n\t\t\tqrtr_port_put(ipc);\n\t\t\tgoto err;\n\t\t}\n\n\t\tqrtr_port_put(ipc);\n\t}\n\n\treturn 0;\n\nerr:\n\tkfree_skb(skb);\n\treturn -EINVAL;\n\n}\nEXPORT_SYMBOL_GPL(qrtr_endpoint_post);\n\n/**\n * qrtr_alloc_ctrl_packet() - allocate control packet skb\n * @pkt: reference to qrtr_ctrl_pkt pointer\n * @flags: the type of memory to allocate\n *\n * Returns newly allocated sk_buff, or NULL on failure\n *\n * This function allocates a sk_buff large enough to carry a qrtr_ctrl_pkt and\n * on success returns a reference to the control packet in @pkt.\n */\nstatic struct sk_buff *qrtr_alloc_ctrl_packet(struct qrtr_ctrl_pkt **pkt,\n\t\t\t\t\t      gfp_t flags)\n{\n\tconst int pkt_len = sizeof(struct qrtr_ctrl_pkt);\n\tstruct sk_buff *skb;\n\n\tskb = alloc_skb(QRTR_HDR_MAX_SIZE + pkt_len, flags);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, QRTR_HDR_MAX_SIZE);\n\t*pkt = skb_put_zero(skb, pkt_len);\n\n\treturn skb;\n}\n\n/**\n * qrtr_endpoint_register() - register a new endpoint\n * @ep: endpoint to register\n * @nid: desired node id; may be QRTR_EP_NID_AUTO for auto-assignment\n * Return: 0 on success; negative error code on failure\n *\n * The specified endpoint must have the xmit function pointer set on call.\n */\nint qrtr_endpoint_register(struct qrtr_endpoint *ep, unsigned int nid)\n{\n\tstruct qrtr_node *node;\n\n\tif (!ep || !ep->xmit)\n\t\treturn -EINVAL;\n\n\tnode = kzalloc(sizeof(*node), GFP_KERNEL);\n\tif (!node)\n\t\treturn -ENOMEM;\n\n\tkref_init(&node->ref);\n\tmutex_init(&node->ep_lock);\n\tskb_queue_head_init(&node->rx_queue);\n\tnode->nid = QRTR_EP_NID_AUTO;\n\tnode->ep = ep;\n\n\tINIT_RADIX_TREE(&node->qrtr_tx_flow, GFP_KERNEL);\n\tmutex_init(&node->qrtr_tx_lock);\n\n\tqrtr_node_assign(node, nid);\n\n\tmutex_lock(&qrtr_node_lock);\n\tlist_add(&node->item, &qrtr_all_nodes);\n\tmutex_unlock(&qrtr_node_lock);\n\tep->node = node;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(qrtr_endpoint_register);\n\n/**\n * qrtr_endpoint_unregister - unregister endpoint\n * @ep: endpoint to unregister\n */\nvoid qrtr_endpoint_unregister(struct qrtr_endpoint *ep)\n{\n\tstruct qrtr_node *node = ep->node;\n\tstruct sockaddr_qrtr src = {AF_QIPCRTR, node->nid, QRTR_PORT_CTRL};\n\tstruct sockaddr_qrtr dst = {AF_QIPCRTR, qrtr_local_nid, QRTR_PORT_CTRL};\n\tstruct radix_tree_iter iter;\n\tstruct qrtr_ctrl_pkt *pkt;\n\tstruct qrtr_tx_flow *flow;\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\tvoid __rcu **slot;\n\n\tmutex_lock(&node->ep_lock);\n\tnode->ep = NULL;\n\tmutex_unlock(&node->ep_lock);\n\n\t/* Notify the local controller about the event */\n\tspin_lock_irqsave(&qrtr_nodes_lock, flags);\n\tradix_tree_for_each_slot(slot, &qrtr_nodes, &iter, 0) {\n\t\tif (*slot != node)\n\t\t\tcontinue;\n\t\tsrc.sq_node = iter.index;\n\t\tskb = qrtr_alloc_ctrl_packet(&pkt, GFP_ATOMIC);\n\t\tif (skb) {\n\t\t\tpkt->cmd = cpu_to_le32(QRTR_TYPE_BYE);\n\t\t\tqrtr_local_enqueue(NULL, skb, QRTR_TYPE_BYE, &src, &dst);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&qrtr_nodes_lock, flags);\n\n\t/* Wake up any transmitters waiting for resume-tx from the node */\n\tmutex_lock(&node->qrtr_tx_lock);\n\tradix_tree_for_each_slot(slot, &node->qrtr_tx_flow, &iter, 0) {\n\t\tflow = *slot;\n\t\twake_up_interruptible_all(&flow->resume_tx);\n\t}\n\tmutex_unlock(&node->qrtr_tx_lock);\n\n\tqrtr_node_release(node);\n\tep->node = NULL;\n}\nEXPORT_SYMBOL_GPL(qrtr_endpoint_unregister);\n\n/* Lookup socket by port.\n *\n * Callers must release with qrtr_port_put()\n */\nstatic struct qrtr_sock *qrtr_port_lookup(int port)\n{\n\tstruct qrtr_sock *ipc;\n\n\tif (port == QRTR_PORT_CTRL)\n\t\tport = 0;\n\n\trcu_read_lock();\n\tipc = xa_load(&qrtr_ports, port);\n\tif (ipc)\n\t\tsock_hold(&ipc->sk);\n\trcu_read_unlock();\n\n\treturn ipc;\n}\n\n/* Release acquired socket. */\nstatic void qrtr_port_put(struct qrtr_sock *ipc)\n{\n\tsock_put(&ipc->sk);\n}\n\n/* Remove port assignment. */\nstatic void qrtr_port_remove(struct qrtr_sock *ipc)\n{\n\tstruct qrtr_ctrl_pkt *pkt;\n\tstruct sk_buff *skb;\n\tint port = ipc->us.sq_port;\n\tstruct sockaddr_qrtr to;\n\n\tto.sq_family = AF_QIPCRTR;\n\tto.sq_node = QRTR_NODE_BCAST;\n\tto.sq_port = QRTR_PORT_CTRL;\n\n\tskb = qrtr_alloc_ctrl_packet(&pkt, GFP_KERNEL);\n\tif (skb) {\n\t\tpkt->cmd = cpu_to_le32(QRTR_TYPE_DEL_CLIENT);\n\t\tpkt->client.node = cpu_to_le32(ipc->us.sq_node);\n\t\tpkt->client.port = cpu_to_le32(ipc->us.sq_port);\n\n\t\tskb_set_owner_w(skb, &ipc->sk);\n\t\tqrtr_bcast_enqueue(NULL, skb, QRTR_TYPE_DEL_CLIENT, &ipc->us,\n\t\t\t\t   &to);\n\t}\n\n\tif (port == QRTR_PORT_CTRL)\n\t\tport = 0;\n\n\t__sock_put(&ipc->sk);\n\n\txa_erase(&qrtr_ports, port);\n\n\t/* Ensure that if qrtr_port_lookup() did enter the RCU read section we\n\t * wait for it to up increment the refcount */\n\tsynchronize_rcu();\n}\n\n/* Assign port number to socket.\n *\n * Specify port in the integer pointed to by port, and it will be adjusted\n * on return as necesssary.\n *\n * Port may be:\n *   0: Assign ephemeral port in [QRTR_MIN_EPH_SOCKET, QRTR_MAX_EPH_SOCKET]\n *   <QRTR_MIN_EPH_SOCKET: Specified; requires CAP_NET_ADMIN\n *   >QRTR_MIN_EPH_SOCKET: Specified; available to all\n */\nstatic int qrtr_port_assign(struct qrtr_sock *ipc, int *port)\n{\n\tint rc;\n\n\tif (!*port) {\n\t\trc = xa_alloc(&qrtr_ports, port, ipc, QRTR_EPH_PORT_RANGE,\n\t\t\t\tGFP_KERNEL);\n\t} else if (*port < QRTR_MIN_EPH_SOCKET && !capable(CAP_NET_ADMIN)) {\n\t\trc = -EACCES;\n\t} else if (*port == QRTR_PORT_CTRL) {\n\t\trc = xa_insert(&qrtr_ports, 0, ipc, GFP_KERNEL);\n\t} else {\n\t\trc = xa_insert(&qrtr_ports, *port, ipc, GFP_KERNEL);\n\t}\n\n\tif (rc == -EBUSY)\n\t\treturn -EADDRINUSE;\n\telse if (rc < 0)\n\t\treturn rc;\n\n\tsock_hold(&ipc->sk);\n\n\treturn 0;\n}\n\n/* Reset all non-control ports */\nstatic void qrtr_reset_ports(void)\n{\n\tstruct qrtr_sock *ipc;\n\tunsigned long index;\n\n\trcu_read_lock();\n\txa_for_each_start(&qrtr_ports, index, ipc, 1) {\n\t\tsock_hold(&ipc->sk);\n\t\tipc->sk.sk_err = ENETRESET;\n\t\tsk_error_report(&ipc->sk);\n\t\tsock_put(&ipc->sk);\n\t}\n\trcu_read_unlock();\n}\n\n/* Bind socket to address.\n *\n * Socket should be locked upon call.\n */\nstatic int __qrtr_bind(struct socket *sock,\n\t\t       const struct sockaddr_qrtr *addr, int zapped)\n{\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tint port;\n\tint rc;\n\n\t/* rebinding ok */\n\tif (!zapped && addr->sq_port == ipc->us.sq_port)\n\t\treturn 0;\n\n\tport = addr->sq_port;\n\trc = qrtr_port_assign(ipc, &port);\n\tif (rc)\n\t\treturn rc;\n\n\t/* unbind previous, if any */\n\tif (!zapped)\n\t\tqrtr_port_remove(ipc);\n\tipc->us.sq_port = port;\n\n\tsock_reset_flag(sk, SOCK_ZAPPED);\n\n\t/* Notify all open ports about the new controller */\n\tif (port == QRTR_PORT_CTRL)\n\t\tqrtr_reset_ports();\n\n\treturn 0;\n}\n\n/* Auto bind to an ephemeral port. */\nstatic int qrtr_autobind(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct sockaddr_qrtr addr;\n\n\tif (!sock_flag(sk, SOCK_ZAPPED))\n\t\treturn 0;\n\n\taddr.sq_family = AF_QIPCRTR;\n\taddr.sq_node = qrtr_local_nid;\n\taddr.sq_port = 0;\n\n\treturn __qrtr_bind(sock, &addr, 1);\n}\n\n/* Bind socket to specified sockaddr. */\nstatic int qrtr_bind(struct socket *sock, struct sockaddr *saddr, int len)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_qrtr *, addr, saddr);\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tint rc;\n\n\tif (len < sizeof(*addr) || addr->sq_family != AF_QIPCRTR)\n\t\treturn -EINVAL;\n\n\tif (addr->sq_node != ipc->us.sq_node)\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\trc = __qrtr_bind(sock, addr, sock_flag(sk, SOCK_ZAPPED));\n\trelease_sock(sk);\n\n\treturn rc;\n}\n\n/* Queue packet to local peer socket. */\nstatic int qrtr_local_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t      int type, struct sockaddr_qrtr *from,\n\t\t\t      struct sockaddr_qrtr *to)\n{\n\tstruct qrtr_sock *ipc;\n\tstruct qrtr_cb *cb;\n\n\tipc = qrtr_port_lookup(to->sq_port);\n\tif (!ipc || &ipc->sk == skb->sk) { /* do not send to self */\n\t\tif (ipc)\n\t\t\tqrtr_port_put(ipc);\n\t\tkfree_skb(skb);\n\t\treturn -ENODEV;\n\t}\n\n\tcb = (struct qrtr_cb *)skb->cb;\n\tcb->src_node = from->sq_node;\n\tcb->src_port = from->sq_port;\n\n\tif (sock_queue_rcv_skb(&ipc->sk, skb)) {\n\t\tqrtr_port_put(ipc);\n\t\tkfree_skb(skb);\n\t\treturn -ENOSPC;\n\t}\n\n\tqrtr_port_put(ipc);\n\n\treturn 0;\n}\n\n/* Queue packet for broadcast. */\nstatic int qrtr_bcast_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t      int type, struct sockaddr_qrtr *from,\n\t\t\t      struct sockaddr_qrtr *to)\n{\n\tstruct sk_buff *skbn;\n\n\tmutex_lock(&qrtr_node_lock);\n\tlist_for_each_entry(node, &qrtr_all_nodes, item) {\n\t\tskbn = skb_clone(skb, GFP_KERNEL);\n\t\tif (!skbn)\n\t\t\tbreak;\n\t\tskb_set_owner_w(skbn, skb->sk);\n\t\tqrtr_node_enqueue(node, skbn, type, from, to);\n\t}\n\tmutex_unlock(&qrtr_node_lock);\n\n\tqrtr_local_enqueue(NULL, skb, type, from, to);\n\n\treturn 0;\n}\n\nstatic int qrtr_sendmsg(struct socket *sock, struct msghdr *msg, size_t len)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_qrtr *, addr, msg->msg_name);\n\tint (*enqueue_fn)(struct qrtr_node *, struct sk_buff *, int,\n\t\t\t  struct sockaddr_qrtr *, struct sockaddr_qrtr *);\n\t__le32 qrtr_type = cpu_to_le32(QRTR_TYPE_DATA);\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tstruct qrtr_node *node;\n\tstruct sk_buff *skb;\n\tsize_t plen;\n\tu32 type;\n\tint rc;\n\n\tif (msg->msg_flags & ~(MSG_DONTWAIT))\n\t\treturn -EINVAL;\n\n\tif (len > 65535)\n\t\treturn -EMSGSIZE;\n\n\tlock_sock(sk);\n\n\tif (addr) {\n\t\tif (msg->msg_namelen < sizeof(*addr)) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (addr->sq_family != AF_QIPCRTR) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\trc = qrtr_autobind(sock);\n\t\tif (rc) {\n\t\t\trelease_sock(sk);\n\t\t\treturn rc;\n\t\t}\n\t} else if (sk->sk_state == TCP_ESTABLISHED) {\n\t\taddr = &ipc->peer;\n\t} else {\n\t\trelease_sock(sk);\n\t\treturn -ENOTCONN;\n\t}\n\n\tnode = NULL;\n\tif (addr->sq_node == QRTR_NODE_BCAST) {\n\t\tif (addr->sq_port != QRTR_PORT_CTRL &&\n\t\t    qrtr_local_nid != QRTR_NODE_BCAST) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -ENOTCONN;\n\t\t}\n\t\tenqueue_fn = qrtr_bcast_enqueue;\n\t} else if (addr->sq_node == ipc->us.sq_node) {\n\t\tenqueue_fn = qrtr_local_enqueue;\n\t} else {\n\t\tnode = qrtr_node_lookup(addr->sq_node);\n\t\tif (!node) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -ECONNRESET;\n\t\t}\n\t\tenqueue_fn = qrtr_node_enqueue;\n\t}\n\n\tplen = (len + 3) & ~3;\n\tskb = sock_alloc_send_skb(sk, plen + QRTR_HDR_MAX_SIZE,\n\t\t\t\t  msg->msg_flags & MSG_DONTWAIT, &rc);\n\tif (!skb) {\n\t\trc = -ENOMEM;\n\t\tgoto out_node;\n\t}\n\n\tskb_reserve(skb, QRTR_HDR_MAX_SIZE);\n\n\trc = memcpy_from_msg(skb_put(skb, len), msg, len);\n\tif (rc) {\n\t\tkfree_skb(skb);\n\t\tgoto out_node;\n\t}\n\n\tif (ipc->us.sq_port == QRTR_PORT_CTRL) {\n\t\tif (len < 4) {\n\t\t\trc = -EINVAL;\n\t\t\tkfree_skb(skb);\n\t\t\tgoto out_node;\n\t\t}\n\n\t\t/* control messages already require the type as 'command' */\n\t\tskb_copy_bits(skb, 0, &qrtr_type, 4);\n\t}\n\n\ttype = le32_to_cpu(qrtr_type);\n\trc = enqueue_fn(node, skb, type, &ipc->us, addr);\n\tif (rc >= 0)\n\t\trc = len;\n\nout_node:\n\tqrtr_node_release(node);\n\trelease_sock(sk);\n\n\treturn rc;\n}\n\nstatic int qrtr_send_resume_tx(struct qrtr_cb *cb)\n{\n\tstruct sockaddr_qrtr remote = { AF_QIPCRTR, cb->src_node, cb->src_port };\n\tstruct sockaddr_qrtr local = { AF_QIPCRTR, cb->dst_node, cb->dst_port };\n\tstruct qrtr_ctrl_pkt *pkt;\n\tstruct qrtr_node *node;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tnode = qrtr_node_lookup(remote.sq_node);\n\tif (!node)\n\t\treturn -EINVAL;\n\n\tskb = qrtr_alloc_ctrl_packet(&pkt, GFP_KERNEL);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tpkt->cmd = cpu_to_le32(QRTR_TYPE_RESUME_TX);\n\tpkt->client.node = cpu_to_le32(cb->dst_node);\n\tpkt->client.port = cpu_to_le32(cb->dst_port);\n\n\tret = qrtr_node_enqueue(node, skb, QRTR_TYPE_RESUME_TX, &local, &remote);\n\n\tqrtr_node_release(node);\n\n\treturn ret;\n}\n\nstatic int qrtr_recvmsg(struct socket *sock, struct msghdr *msg,\n\t\t\tsize_t size, int flags)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_qrtr *, addr, msg->msg_name);\n\tstruct sock *sk = sock->sk;\n\tstruct sk_buff *skb;\n\tstruct qrtr_cb *cb;\n\tint copied, rc;\n\n\tlock_sock(sk);\n\n\tif (sock_flag(sk, SOCK_ZAPPED)) {\n\t\trelease_sock(sk);\n\t\treturn -EADDRNOTAVAIL;\n\t}\n\n\tskb = skb_recv_datagram(sk, flags & ~MSG_DONTWAIT,\n\t\t\t\tflags & MSG_DONTWAIT, &rc);\n\tif (!skb) {\n\t\trelease_sock(sk);\n\t\treturn rc;\n\t}\n\tcb = (struct qrtr_cb *)skb->cb;\n\n\tcopied = skb->len;\n\tif (copied > size) {\n\t\tcopied = size;\n\t\tmsg->msg_flags |= MSG_TRUNC;\n\t}\n\n\trc = skb_copy_datagram_msg(skb, 0, msg, copied);\n\tif (rc < 0)\n\t\tgoto out;\n\trc = copied;\n\n\tif (addr) {\n\t\t/* There is an anonymous 2-byte hole after sq_family,\n\t\t * make sure to clear it.\n\t\t */\n\t\tmemset(addr, 0, sizeof(*addr));\n\n\t\taddr->sq_family = AF_QIPCRTR;\n\t\taddr->sq_node = cb->src_node;\n\t\taddr->sq_port = cb->src_port;\n\t\tmsg->msg_namelen = sizeof(*addr);\n\t}\n\nout:\n\tif (cb->confirm_rx)\n\t\tqrtr_send_resume_tx(cb);\n\n\tskb_free_datagram(sk, skb);\n\trelease_sock(sk);\n\n\treturn rc;\n}\n\nstatic int qrtr_connect(struct socket *sock, struct sockaddr *saddr,\n\t\t\tint len, int flags)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_qrtr *, addr, saddr);\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tint rc;\n\n\tif (len < sizeof(*addr) || addr->sq_family != AF_QIPCRTR)\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\tsk->sk_state = TCP_CLOSE;\n\tsock->state = SS_UNCONNECTED;\n\n\trc = qrtr_autobind(sock);\n\tif (rc) {\n\t\trelease_sock(sk);\n\t\treturn rc;\n\t}\n\n\tipc->peer = *addr;\n\tsock->state = SS_CONNECTED;\n\tsk->sk_state = TCP_ESTABLISHED;\n\n\trelease_sock(sk);\n\n\treturn 0;\n}\n\nstatic int qrtr_getname(struct socket *sock, struct sockaddr *saddr,\n\t\t\tint peer)\n{\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sockaddr_qrtr qaddr;\n\tstruct sock *sk = sock->sk;\n\n\tlock_sock(sk);\n\tif (peer) {\n\t\tif (sk->sk_state != TCP_ESTABLISHED) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -ENOTCONN;\n\t\t}\n\n\t\tqaddr = ipc->peer;\n\t} else {\n\t\tqaddr = ipc->us;\n\t}\n\trelease_sock(sk);\n\n\tqaddr.sq_family = AF_QIPCRTR;\n\n\tmemcpy(saddr, &qaddr, sizeof(qaddr));\n\n\treturn sizeof(qaddr);\n}\n\nstatic int qrtr_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)\n{\n\tvoid __user *argp = (void __user *)arg;\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tstruct sockaddr_qrtr *sq;\n\tstruct sk_buff *skb;\n\tstruct ifreq ifr;\n\tlong len = 0;\n\tint rc = 0;\n\n\tlock_sock(sk);\n\n\tswitch (cmd) {\n\tcase TIOCOUTQ:\n\t\tlen = sk->sk_sndbuf - sk_wmem_alloc_get(sk);\n\t\tif (len < 0)\n\t\t\tlen = 0;\n\t\trc = put_user(len, (int __user *)argp);\n\t\tbreak;\n\tcase TIOCINQ:\n\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\tif (skb)\n\t\t\tlen = skb->len;\n\t\trc = put_user(len, (int __user *)argp);\n\t\tbreak;\n\tcase SIOCGIFADDR:\n\t\tif (copy_from_user(&ifr, argp, sizeof(ifr))) {\n\t\t\trc = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tsq = (struct sockaddr_qrtr *)&ifr.ifr_addr;\n\t\t*sq = ipc->us;\n\t\tif (copy_to_user(argp, &ifr, sizeof(ifr))) {\n\t\t\trc = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase SIOCADDRT:\n\tcase SIOCDELRT:\n\tcase SIOCSIFADDR:\n\tcase SIOCGIFDSTADDR:\n\tcase SIOCSIFDSTADDR:\n\tcase SIOCGIFBRDADDR:\n\tcase SIOCSIFBRDADDR:\n\tcase SIOCGIFNETMASK:\n\tcase SIOCSIFNETMASK:\n\t\trc = -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\trc = -ENOIOCTLCMD;\n\t\tbreak;\n\t}\n\n\trelease_sock(sk);\n\n\treturn rc;\n}\n\nstatic int qrtr_release(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct qrtr_sock *ipc;\n\n\tif (!sk)\n\t\treturn 0;\n\n\tlock_sock(sk);\n\n\tipc = qrtr_sk(sk);\n\tsk->sk_shutdown = SHUTDOWN_MASK;\n\tif (!sock_flag(sk, SOCK_DEAD))\n\t\tsk->sk_state_change(sk);\n\n\tsock_set_flag(sk, SOCK_DEAD);\n\tsock_orphan(sk);\n\tsock->sk = NULL;\n\n\tif (!sock_flag(sk, SOCK_ZAPPED))\n\t\tqrtr_port_remove(ipc);\n\n\tskb_queue_purge(&sk->sk_receive_queue);\n\n\trelease_sock(sk);\n\tsock_put(sk);\n\n\treturn 0;\n}\n\nstatic const struct proto_ops qrtr_proto_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_QIPCRTR,\n\t.bind\t\t= qrtr_bind,\n\t.connect\t= qrtr_connect,\n\t.socketpair\t= sock_no_socketpair,\n\t.accept\t\t= sock_no_accept,\n\t.listen\t\t= sock_no_listen,\n\t.sendmsg\t= qrtr_sendmsg,\n\t.recvmsg\t= qrtr_recvmsg,\n\t.getname\t= qrtr_getname,\n\t.ioctl\t\t= qrtr_ioctl,\n\t.gettstamp\t= sock_gettstamp,\n\t.poll\t\t= datagram_poll,\n\t.shutdown\t= sock_no_shutdown,\n\t.release\t= qrtr_release,\n\t.mmap\t\t= sock_no_mmap,\n\t.sendpage\t= sock_no_sendpage,\n};\n\nstatic struct proto qrtr_proto = {\n\t.name\t\t= \"QIPCRTR\",\n\t.owner\t\t= THIS_MODULE,\n\t.obj_size\t= sizeof(struct qrtr_sock),\n};\n\nstatic int qrtr_create(struct net *net, struct socket *sock,\n\t\t       int protocol, int kern)\n{\n\tstruct qrtr_sock *ipc;\n\tstruct sock *sk;\n\n\tif (sock->type != SOCK_DGRAM)\n\t\treturn -EPROTOTYPE;\n\n\tsk = sk_alloc(net, AF_QIPCRTR, GFP_KERNEL, &qrtr_proto, kern);\n\tif (!sk)\n\t\treturn -ENOMEM;\n\n\tsock_set_flag(sk, SOCK_ZAPPED);\n\n\tsock_init_data(sock, sk);\n\tsock->ops = &qrtr_proto_ops;\n\n\tipc = qrtr_sk(sk);\n\tipc->us.sq_family = AF_QIPCRTR;\n\tipc->us.sq_node = qrtr_local_nid;\n\tipc->us.sq_port = 0;\n\n\treturn 0;\n}\n\nstatic const struct net_proto_family qrtr_family = {\n\t.owner\t= THIS_MODULE,\n\t.family\t= AF_QIPCRTR,\n\t.create\t= qrtr_create,\n};\n\nstatic int __init qrtr_proto_init(void)\n{\n\tint rc;\n\n\trc = proto_register(&qrtr_proto, 1);\n\tif (rc)\n\t\treturn rc;\n\n\trc = sock_register(&qrtr_family);\n\tif (rc)\n\t\tgoto err_proto;\n\n\trc = qrtr_ns_init();\n\tif (rc)\n\t\tgoto err_sock;\n\n\treturn 0;\n\nerr_sock:\n\tsock_unregister(qrtr_family.family);\nerr_proto:\n\tproto_unregister(&qrtr_proto);\n\treturn rc;\n}\npostcore_initcall(qrtr_proto_init);\n\nstatic void __exit qrtr_proto_fini(void)\n{\n\tqrtr_ns_remove();\n\tsock_unregister(qrtr_family.family);\n\tproto_unregister(&qrtr_proto);\n}\nmodule_exit(qrtr_proto_fini);\n\nMODULE_DESCRIPTION(\"Qualcomm IPC-router driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS_NETPROTO(PF_QIPCRTR);\n"], "fixing_code": ["// SPDX-License-Identifier: GPL-2.0-only\n/*\n * Copyright (c) 2015, Sony Mobile Communications Inc.\n * Copyright (c) 2013, The Linux Foundation. All rights reserved.\n */\n#include <linux/module.h>\n#include <linux/netlink.h>\n#include <linux/qrtr.h>\n#include <linux/termios.h>\t/* For TIOCINQ/OUTQ */\n#include <linux/spinlock.h>\n#include <linux/wait.h>\n\n#include <net/sock.h>\n\n#include \"qrtr.h\"\n\n#define QRTR_PROTO_VER_1 1\n#define QRTR_PROTO_VER_2 3\n\n/* auto-bind range */\n#define QRTR_MIN_EPH_SOCKET 0x4000\n#define QRTR_MAX_EPH_SOCKET 0x7fff\n#define QRTR_EPH_PORT_RANGE \\\n\t\tXA_LIMIT(QRTR_MIN_EPH_SOCKET, QRTR_MAX_EPH_SOCKET)\n\n/**\n * struct qrtr_hdr_v1 - (I|R)PCrouter packet header version 1\n * @version: protocol version\n * @type: packet type; one of QRTR_TYPE_*\n * @src_node_id: source node\n * @src_port_id: source port\n * @confirm_rx: boolean; whether a resume-tx packet should be send in reply\n * @size: length of packet, excluding this header\n * @dst_node_id: destination node\n * @dst_port_id: destination port\n */\nstruct qrtr_hdr_v1 {\n\t__le32 version;\n\t__le32 type;\n\t__le32 src_node_id;\n\t__le32 src_port_id;\n\t__le32 confirm_rx;\n\t__le32 size;\n\t__le32 dst_node_id;\n\t__le32 dst_port_id;\n} __packed;\n\n/**\n * struct qrtr_hdr_v2 - (I|R)PCrouter packet header later versions\n * @version: protocol version\n * @type: packet type; one of QRTR_TYPE_*\n * @flags: bitmask of QRTR_FLAGS_*\n * @optlen: length of optional header data\n * @size: length of packet, excluding this header and optlen\n * @src_node_id: source node\n * @src_port_id: source port\n * @dst_node_id: destination node\n * @dst_port_id: destination port\n */\nstruct qrtr_hdr_v2 {\n\tu8 version;\n\tu8 type;\n\tu8 flags;\n\tu8 optlen;\n\t__le32 size;\n\t__le16 src_node_id;\n\t__le16 src_port_id;\n\t__le16 dst_node_id;\n\t__le16 dst_port_id;\n};\n\n#define QRTR_FLAGS_CONFIRM_RX\tBIT(0)\n\nstruct qrtr_cb {\n\tu32 src_node;\n\tu32 src_port;\n\tu32 dst_node;\n\tu32 dst_port;\n\n\tu8 type;\n\tu8 confirm_rx;\n};\n\n#define QRTR_HDR_MAX_SIZE max_t(size_t, sizeof(struct qrtr_hdr_v1), \\\n\t\t\t\t\tsizeof(struct qrtr_hdr_v2))\n\nstruct qrtr_sock {\n\t/* WARNING: sk must be the first member */\n\tstruct sock sk;\n\tstruct sockaddr_qrtr us;\n\tstruct sockaddr_qrtr peer;\n};\n\nstatic inline struct qrtr_sock *qrtr_sk(struct sock *sk)\n{\n\tBUILD_BUG_ON(offsetof(struct qrtr_sock, sk) != 0);\n\treturn container_of(sk, struct qrtr_sock, sk);\n}\n\nstatic unsigned int qrtr_local_nid = 1;\n\n/* for node ids */\nstatic RADIX_TREE(qrtr_nodes, GFP_ATOMIC);\nstatic DEFINE_SPINLOCK(qrtr_nodes_lock);\n/* broadcast list */\nstatic LIST_HEAD(qrtr_all_nodes);\n/* lock for qrtr_all_nodes and node reference */\nstatic DEFINE_MUTEX(qrtr_node_lock);\n\n/* local port allocation management */\nstatic DEFINE_XARRAY_ALLOC(qrtr_ports);\n\n/**\n * struct qrtr_node - endpoint node\n * @ep_lock: lock for endpoint management and callbacks\n * @ep: endpoint\n * @ref: reference count for node\n * @nid: node id\n * @qrtr_tx_flow: tree of qrtr_tx_flow, keyed by node << 32 | port\n * @qrtr_tx_lock: lock for qrtr_tx_flow inserts\n * @rx_queue: receive queue\n * @item: list item for broadcast list\n */\nstruct qrtr_node {\n\tstruct mutex ep_lock;\n\tstruct qrtr_endpoint *ep;\n\tstruct kref ref;\n\tunsigned int nid;\n\n\tstruct radix_tree_root qrtr_tx_flow;\n\tstruct mutex qrtr_tx_lock; /* for qrtr_tx_flow */\n\n\tstruct sk_buff_head rx_queue;\n\tstruct list_head item;\n};\n\n/**\n * struct qrtr_tx_flow - tx flow control\n * @resume_tx: waiters for a resume tx from the remote\n * @pending: number of waiting senders\n * @tx_failed: indicates that a message with confirm_rx flag was lost\n */\nstruct qrtr_tx_flow {\n\tstruct wait_queue_head resume_tx;\n\tint pending;\n\tint tx_failed;\n};\n\n#define QRTR_TX_FLOW_HIGH\t10\n#define QRTR_TX_FLOW_LOW\t5\n\nstatic int qrtr_local_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t      int type, struct sockaddr_qrtr *from,\n\t\t\t      struct sockaddr_qrtr *to);\nstatic int qrtr_bcast_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t      int type, struct sockaddr_qrtr *from,\n\t\t\t      struct sockaddr_qrtr *to);\nstatic struct qrtr_sock *qrtr_port_lookup(int port);\nstatic void qrtr_port_put(struct qrtr_sock *ipc);\n\n/* Release node resources and free the node.\n *\n * Do not call directly, use qrtr_node_release.  To be used with\n * kref_put_mutex.  As such, the node mutex is expected to be locked on call.\n */\nstatic void __qrtr_node_release(struct kref *kref)\n{\n\tstruct qrtr_node *node = container_of(kref, struct qrtr_node, ref);\n\tstruct radix_tree_iter iter;\n\tstruct qrtr_tx_flow *flow;\n\tunsigned long flags;\n\tvoid __rcu **slot;\n\n\tspin_lock_irqsave(&qrtr_nodes_lock, flags);\n\t/* If the node is a bridge for other nodes, there are possibly\n\t * multiple entries pointing to our released node, delete them all.\n\t */\n\tradix_tree_for_each_slot(slot, &qrtr_nodes, &iter, 0) {\n\t\tif (*slot == node)\n\t\t\tradix_tree_iter_delete(&qrtr_nodes, &iter, slot);\n\t}\n\tspin_unlock_irqrestore(&qrtr_nodes_lock, flags);\n\n\tlist_del(&node->item);\n\tmutex_unlock(&qrtr_node_lock);\n\n\tskb_queue_purge(&node->rx_queue);\n\n\t/* Free tx flow counters */\n\tradix_tree_for_each_slot(slot, &node->qrtr_tx_flow, &iter, 0) {\n\t\tflow = *slot;\n\t\tradix_tree_iter_delete(&node->qrtr_tx_flow, &iter, slot);\n\t\tkfree(flow);\n\t}\n\tkfree(node);\n}\n\n/* Increment reference to node. */\nstatic struct qrtr_node *qrtr_node_acquire(struct qrtr_node *node)\n{\n\tif (node)\n\t\tkref_get(&node->ref);\n\treturn node;\n}\n\n/* Decrement reference to node and release as necessary. */\nstatic void qrtr_node_release(struct qrtr_node *node)\n{\n\tif (!node)\n\t\treturn;\n\tkref_put_mutex(&node->ref, __qrtr_node_release, &qrtr_node_lock);\n}\n\n/**\n * qrtr_tx_resume() - reset flow control counter\n * @node:\tqrtr_node that the QRTR_TYPE_RESUME_TX packet arrived on\n * @skb:\tresume_tx packet\n */\nstatic void qrtr_tx_resume(struct qrtr_node *node, struct sk_buff *skb)\n{\n\tstruct qrtr_ctrl_pkt *pkt = (struct qrtr_ctrl_pkt *)skb->data;\n\tu64 remote_node = le32_to_cpu(pkt->client.node);\n\tu32 remote_port = le32_to_cpu(pkt->client.port);\n\tstruct qrtr_tx_flow *flow;\n\tunsigned long key;\n\n\tkey = remote_node << 32 | remote_port;\n\n\trcu_read_lock();\n\tflow = radix_tree_lookup(&node->qrtr_tx_flow, key);\n\trcu_read_unlock();\n\tif (flow) {\n\t\tspin_lock(&flow->resume_tx.lock);\n\t\tflow->pending = 0;\n\t\tspin_unlock(&flow->resume_tx.lock);\n\t\twake_up_interruptible_all(&flow->resume_tx);\n\t}\n\n\tconsume_skb(skb);\n}\n\n/**\n * qrtr_tx_wait() - flow control for outgoing packets\n * @node:\tqrtr_node that the packet is to be send to\n * @dest_node:\tnode id of the destination\n * @dest_port:\tport number of the destination\n * @type:\ttype of message\n *\n * The flow control scheme is based around the low and high \"watermarks\". When\n * the low watermark is passed the confirm_rx flag is set on the outgoing\n * message, which will trigger the remote to send a control message of the type\n * QRTR_TYPE_RESUME_TX to reset the counter. If the high watermark is hit\n * further transmision should be paused.\n *\n * Return: 1 if confirm_rx should be set, 0 otherwise or errno failure\n */\nstatic int qrtr_tx_wait(struct qrtr_node *node, int dest_node, int dest_port,\n\t\t\tint type)\n{\n\tunsigned long key = (u64)dest_node << 32 | dest_port;\n\tstruct qrtr_tx_flow *flow;\n\tint confirm_rx = 0;\n\tint ret;\n\n\t/* Never set confirm_rx on non-data packets */\n\tif (type != QRTR_TYPE_DATA)\n\t\treturn 0;\n\n\tmutex_lock(&node->qrtr_tx_lock);\n\tflow = radix_tree_lookup(&node->qrtr_tx_flow, key);\n\tif (!flow) {\n\t\tflow = kzalloc(sizeof(*flow), GFP_KERNEL);\n\t\tif (flow) {\n\t\t\tinit_waitqueue_head(&flow->resume_tx);\n\t\t\tif (radix_tree_insert(&node->qrtr_tx_flow, key, flow)) {\n\t\t\t\tkfree(flow);\n\t\t\t\tflow = NULL;\n\t\t\t}\n\t\t}\n\t}\n\tmutex_unlock(&node->qrtr_tx_lock);\n\n\t/* Set confirm_rx if we where unable to find and allocate a flow */\n\tif (!flow)\n\t\treturn 1;\n\n\tspin_lock_irq(&flow->resume_tx.lock);\n\tret = wait_event_interruptible_locked_irq(flow->resume_tx,\n\t\t\t\t\t\t  flow->pending < QRTR_TX_FLOW_HIGH ||\n\t\t\t\t\t\t  flow->tx_failed ||\n\t\t\t\t\t\t  !node->ep);\n\tif (ret < 0) {\n\t\tconfirm_rx = ret;\n\t} else if (!node->ep) {\n\t\tconfirm_rx = -EPIPE;\n\t} else if (flow->tx_failed) {\n\t\tflow->tx_failed = 0;\n\t\tconfirm_rx = 1;\n\t} else {\n\t\tflow->pending++;\n\t\tconfirm_rx = flow->pending == QRTR_TX_FLOW_LOW;\n\t}\n\tspin_unlock_irq(&flow->resume_tx.lock);\n\n\treturn confirm_rx;\n}\n\n/**\n * qrtr_tx_flow_failed() - flag that tx of confirm_rx flagged messages failed\n * @node:\tqrtr_node that the packet is to be send to\n * @dest_node:\tnode id of the destination\n * @dest_port:\tport number of the destination\n *\n * Signal that the transmission of a message with confirm_rx flag failed. The\n * flow's \"pending\" counter will keep incrementing towards QRTR_TX_FLOW_HIGH,\n * at which point transmission would stall forever waiting for the resume TX\n * message associated with the dropped confirm_rx message.\n * Work around this by marking the flow as having a failed transmission and\n * cause the next transmission attempt to be sent with the confirm_rx.\n */\nstatic void qrtr_tx_flow_failed(struct qrtr_node *node, int dest_node,\n\t\t\t\tint dest_port)\n{\n\tunsigned long key = (u64)dest_node << 32 | dest_port;\n\tstruct qrtr_tx_flow *flow;\n\n\trcu_read_lock();\n\tflow = radix_tree_lookup(&node->qrtr_tx_flow, key);\n\trcu_read_unlock();\n\tif (flow) {\n\t\tspin_lock_irq(&flow->resume_tx.lock);\n\t\tflow->tx_failed = 1;\n\t\tspin_unlock_irq(&flow->resume_tx.lock);\n\t}\n}\n\n/* Pass an outgoing packet socket buffer to the endpoint driver. */\nstatic int qrtr_node_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t     int type, struct sockaddr_qrtr *from,\n\t\t\t     struct sockaddr_qrtr *to)\n{\n\tstruct qrtr_hdr_v1 *hdr;\n\tsize_t len = skb->len;\n\tint rc, confirm_rx;\n\n\tconfirm_rx = qrtr_tx_wait(node, to->sq_node, to->sq_port, type);\n\tif (confirm_rx < 0) {\n\t\tkfree_skb(skb);\n\t\treturn confirm_rx;\n\t}\n\n\thdr = skb_push(skb, sizeof(*hdr));\n\thdr->version = cpu_to_le32(QRTR_PROTO_VER_1);\n\thdr->type = cpu_to_le32(type);\n\thdr->src_node_id = cpu_to_le32(from->sq_node);\n\thdr->src_port_id = cpu_to_le32(from->sq_port);\n\tif (to->sq_port == QRTR_PORT_CTRL) {\n\t\thdr->dst_node_id = cpu_to_le32(node->nid);\n\t\thdr->dst_port_id = cpu_to_le32(QRTR_PORT_CTRL);\n\t} else {\n\t\thdr->dst_node_id = cpu_to_le32(to->sq_node);\n\t\thdr->dst_port_id = cpu_to_le32(to->sq_port);\n\t}\n\n\thdr->size = cpu_to_le32(len);\n\thdr->confirm_rx = !!confirm_rx;\n\n\trc = skb_put_padto(skb, ALIGN(len, 4) + sizeof(*hdr));\n\n\tif (!rc) {\n\t\tmutex_lock(&node->ep_lock);\n\t\trc = -ENODEV;\n\t\tif (node->ep)\n\t\t\trc = node->ep->xmit(node->ep, skb);\n\t\telse\n\t\t\tkfree_skb(skb);\n\t\tmutex_unlock(&node->ep_lock);\n\t}\n\t/* Need to ensure that a subsequent message carries the otherwise lost\n\t * confirm_rx flag if we dropped this one */\n\tif (rc && confirm_rx)\n\t\tqrtr_tx_flow_failed(node, to->sq_node, to->sq_port);\n\n\treturn rc;\n}\n\n/* Lookup node by id.\n *\n * callers must release with qrtr_node_release()\n */\nstatic struct qrtr_node *qrtr_node_lookup(unsigned int nid)\n{\n\tstruct qrtr_node *node;\n\tunsigned long flags;\n\n\tspin_lock_irqsave(&qrtr_nodes_lock, flags);\n\tnode = radix_tree_lookup(&qrtr_nodes, nid);\n\tnode = qrtr_node_acquire(node);\n\tspin_unlock_irqrestore(&qrtr_nodes_lock, flags);\n\n\treturn node;\n}\n\n/* Assign node id to node.\n *\n * This is mostly useful for automatic node id assignment, based on\n * the source id in the incoming packet.\n */\nstatic void qrtr_node_assign(struct qrtr_node *node, unsigned int nid)\n{\n\tunsigned long flags;\n\n\tif (nid == QRTR_EP_NID_AUTO)\n\t\treturn;\n\n\tspin_lock_irqsave(&qrtr_nodes_lock, flags);\n\tradix_tree_insert(&qrtr_nodes, nid, node);\n\tif (node->nid == QRTR_EP_NID_AUTO)\n\t\tnode->nid = nid;\n\tspin_unlock_irqrestore(&qrtr_nodes_lock, flags);\n}\n\n/**\n * qrtr_endpoint_post() - post incoming data\n * @ep: endpoint handle\n * @data: data pointer\n * @len: size of data in bytes\n *\n * Return: 0 on success; negative error code on failure\n */\nint qrtr_endpoint_post(struct qrtr_endpoint *ep, const void *data, size_t len)\n{\n\tstruct qrtr_node *node = ep->node;\n\tconst struct qrtr_hdr_v1 *v1;\n\tconst struct qrtr_hdr_v2 *v2;\n\tstruct qrtr_sock *ipc;\n\tstruct sk_buff *skb;\n\tstruct qrtr_cb *cb;\n\tsize_t size;\n\tunsigned int ver;\n\tsize_t hdrlen;\n\n\tif (len == 0 || len & 3)\n\t\treturn -EINVAL;\n\n\tskb = __netdev_alloc_skb(NULL, len, GFP_ATOMIC | __GFP_NOWARN);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tcb = (struct qrtr_cb *)skb->cb;\n\n\t/* Version field in v1 is little endian, so this works for both cases */\n\tver = *(u8*)data;\n\n\tswitch (ver) {\n\tcase QRTR_PROTO_VER_1:\n\t\tif (len < sizeof(*v1))\n\t\t\tgoto err;\n\t\tv1 = data;\n\t\thdrlen = sizeof(*v1);\n\n\t\tcb->type = le32_to_cpu(v1->type);\n\t\tcb->src_node = le32_to_cpu(v1->src_node_id);\n\t\tcb->src_port = le32_to_cpu(v1->src_port_id);\n\t\tcb->confirm_rx = !!v1->confirm_rx;\n\t\tcb->dst_node = le32_to_cpu(v1->dst_node_id);\n\t\tcb->dst_port = le32_to_cpu(v1->dst_port_id);\n\n\t\tsize = le32_to_cpu(v1->size);\n\t\tbreak;\n\tcase QRTR_PROTO_VER_2:\n\t\tif (len < sizeof(*v2))\n\t\t\tgoto err;\n\t\tv2 = data;\n\t\thdrlen = sizeof(*v2) + v2->optlen;\n\n\t\tcb->type = v2->type;\n\t\tcb->confirm_rx = !!(v2->flags & QRTR_FLAGS_CONFIRM_RX);\n\t\tcb->src_node = le16_to_cpu(v2->src_node_id);\n\t\tcb->src_port = le16_to_cpu(v2->src_port_id);\n\t\tcb->dst_node = le16_to_cpu(v2->dst_node_id);\n\t\tcb->dst_port = le16_to_cpu(v2->dst_port_id);\n\n\t\tif (cb->src_port == (u16)QRTR_PORT_CTRL)\n\t\t\tcb->src_port = QRTR_PORT_CTRL;\n\t\tif (cb->dst_port == (u16)QRTR_PORT_CTRL)\n\t\t\tcb->dst_port = QRTR_PORT_CTRL;\n\n\t\tsize = le32_to_cpu(v2->size);\n\t\tbreak;\n\tdefault:\n\t\tpr_err(\"qrtr: Invalid version %d\\n\", ver);\n\t\tgoto err;\n\t}\n\n\tif (!size || len != ALIGN(size, 4) + hdrlen)\n\t\tgoto err;\n\n\tif (cb->dst_port != QRTR_PORT_CTRL && cb->type != QRTR_TYPE_DATA &&\n\t    cb->type != QRTR_TYPE_RESUME_TX)\n\t\tgoto err;\n\n\tskb_put_data(skb, data + hdrlen, size);\n\n\tqrtr_node_assign(node, cb->src_node);\n\n\tif (cb->type == QRTR_TYPE_NEW_SERVER) {\n\t\t/* Remote node endpoint can bridge other distant nodes */\n\t\tconst struct qrtr_ctrl_pkt *pkt = data + hdrlen;\n\n\t\tqrtr_node_assign(node, le32_to_cpu(pkt->server.node));\n\t}\n\n\tif (cb->type == QRTR_TYPE_RESUME_TX) {\n\t\tqrtr_tx_resume(node, skb);\n\t} else {\n\t\tipc = qrtr_port_lookup(cb->dst_port);\n\t\tif (!ipc)\n\t\t\tgoto err;\n\n\t\tif (sock_queue_rcv_skb(&ipc->sk, skb)) {\n\t\t\tqrtr_port_put(ipc);\n\t\t\tgoto err;\n\t\t}\n\n\t\tqrtr_port_put(ipc);\n\t}\n\n\treturn 0;\n\nerr:\n\tkfree_skb(skb);\n\treturn -EINVAL;\n\n}\nEXPORT_SYMBOL_GPL(qrtr_endpoint_post);\n\n/**\n * qrtr_alloc_ctrl_packet() - allocate control packet skb\n * @pkt: reference to qrtr_ctrl_pkt pointer\n * @flags: the type of memory to allocate\n *\n * Returns newly allocated sk_buff, or NULL on failure\n *\n * This function allocates a sk_buff large enough to carry a qrtr_ctrl_pkt and\n * on success returns a reference to the control packet in @pkt.\n */\nstatic struct sk_buff *qrtr_alloc_ctrl_packet(struct qrtr_ctrl_pkt **pkt,\n\t\t\t\t\t      gfp_t flags)\n{\n\tconst int pkt_len = sizeof(struct qrtr_ctrl_pkt);\n\tstruct sk_buff *skb;\n\n\tskb = alloc_skb(QRTR_HDR_MAX_SIZE + pkt_len, flags);\n\tif (!skb)\n\t\treturn NULL;\n\n\tskb_reserve(skb, QRTR_HDR_MAX_SIZE);\n\t*pkt = skb_put_zero(skb, pkt_len);\n\n\treturn skb;\n}\n\n/**\n * qrtr_endpoint_register() - register a new endpoint\n * @ep: endpoint to register\n * @nid: desired node id; may be QRTR_EP_NID_AUTO for auto-assignment\n * Return: 0 on success; negative error code on failure\n *\n * The specified endpoint must have the xmit function pointer set on call.\n */\nint qrtr_endpoint_register(struct qrtr_endpoint *ep, unsigned int nid)\n{\n\tstruct qrtr_node *node;\n\n\tif (!ep || !ep->xmit)\n\t\treturn -EINVAL;\n\n\tnode = kzalloc(sizeof(*node), GFP_KERNEL);\n\tif (!node)\n\t\treturn -ENOMEM;\n\n\tkref_init(&node->ref);\n\tmutex_init(&node->ep_lock);\n\tskb_queue_head_init(&node->rx_queue);\n\tnode->nid = QRTR_EP_NID_AUTO;\n\tnode->ep = ep;\n\n\tINIT_RADIX_TREE(&node->qrtr_tx_flow, GFP_KERNEL);\n\tmutex_init(&node->qrtr_tx_lock);\n\n\tqrtr_node_assign(node, nid);\n\n\tmutex_lock(&qrtr_node_lock);\n\tlist_add(&node->item, &qrtr_all_nodes);\n\tmutex_unlock(&qrtr_node_lock);\n\tep->node = node;\n\n\treturn 0;\n}\nEXPORT_SYMBOL_GPL(qrtr_endpoint_register);\n\n/**\n * qrtr_endpoint_unregister - unregister endpoint\n * @ep: endpoint to unregister\n */\nvoid qrtr_endpoint_unregister(struct qrtr_endpoint *ep)\n{\n\tstruct qrtr_node *node = ep->node;\n\tstruct sockaddr_qrtr src = {AF_QIPCRTR, node->nid, QRTR_PORT_CTRL};\n\tstruct sockaddr_qrtr dst = {AF_QIPCRTR, qrtr_local_nid, QRTR_PORT_CTRL};\n\tstruct radix_tree_iter iter;\n\tstruct qrtr_ctrl_pkt *pkt;\n\tstruct qrtr_tx_flow *flow;\n\tstruct sk_buff *skb;\n\tunsigned long flags;\n\tvoid __rcu **slot;\n\n\tmutex_lock(&node->ep_lock);\n\tnode->ep = NULL;\n\tmutex_unlock(&node->ep_lock);\n\n\t/* Notify the local controller about the event */\n\tspin_lock_irqsave(&qrtr_nodes_lock, flags);\n\tradix_tree_for_each_slot(slot, &qrtr_nodes, &iter, 0) {\n\t\tif (*slot != node)\n\t\t\tcontinue;\n\t\tsrc.sq_node = iter.index;\n\t\tskb = qrtr_alloc_ctrl_packet(&pkt, GFP_ATOMIC);\n\t\tif (skb) {\n\t\t\tpkt->cmd = cpu_to_le32(QRTR_TYPE_BYE);\n\t\t\tqrtr_local_enqueue(NULL, skb, QRTR_TYPE_BYE, &src, &dst);\n\t\t}\n\t}\n\tspin_unlock_irqrestore(&qrtr_nodes_lock, flags);\n\n\t/* Wake up any transmitters waiting for resume-tx from the node */\n\tmutex_lock(&node->qrtr_tx_lock);\n\tradix_tree_for_each_slot(slot, &node->qrtr_tx_flow, &iter, 0) {\n\t\tflow = *slot;\n\t\twake_up_interruptible_all(&flow->resume_tx);\n\t}\n\tmutex_unlock(&node->qrtr_tx_lock);\n\n\tqrtr_node_release(node);\n\tep->node = NULL;\n}\nEXPORT_SYMBOL_GPL(qrtr_endpoint_unregister);\n\n/* Lookup socket by port.\n *\n * Callers must release with qrtr_port_put()\n */\nstatic struct qrtr_sock *qrtr_port_lookup(int port)\n{\n\tstruct qrtr_sock *ipc;\n\n\tif (port == QRTR_PORT_CTRL)\n\t\tport = 0;\n\n\trcu_read_lock();\n\tipc = xa_load(&qrtr_ports, port);\n\tif (ipc)\n\t\tsock_hold(&ipc->sk);\n\trcu_read_unlock();\n\n\treturn ipc;\n}\n\n/* Release acquired socket. */\nstatic void qrtr_port_put(struct qrtr_sock *ipc)\n{\n\tsock_put(&ipc->sk);\n}\n\n/* Remove port assignment. */\nstatic void qrtr_port_remove(struct qrtr_sock *ipc)\n{\n\tstruct qrtr_ctrl_pkt *pkt;\n\tstruct sk_buff *skb;\n\tint port = ipc->us.sq_port;\n\tstruct sockaddr_qrtr to;\n\n\tto.sq_family = AF_QIPCRTR;\n\tto.sq_node = QRTR_NODE_BCAST;\n\tto.sq_port = QRTR_PORT_CTRL;\n\n\tskb = qrtr_alloc_ctrl_packet(&pkt, GFP_KERNEL);\n\tif (skb) {\n\t\tpkt->cmd = cpu_to_le32(QRTR_TYPE_DEL_CLIENT);\n\t\tpkt->client.node = cpu_to_le32(ipc->us.sq_node);\n\t\tpkt->client.port = cpu_to_le32(ipc->us.sq_port);\n\n\t\tskb_set_owner_w(skb, &ipc->sk);\n\t\tqrtr_bcast_enqueue(NULL, skb, QRTR_TYPE_DEL_CLIENT, &ipc->us,\n\t\t\t\t   &to);\n\t}\n\n\tif (port == QRTR_PORT_CTRL)\n\t\tport = 0;\n\n\t__sock_put(&ipc->sk);\n\n\txa_erase(&qrtr_ports, port);\n\n\t/* Ensure that if qrtr_port_lookup() did enter the RCU read section we\n\t * wait for it to up increment the refcount */\n\tsynchronize_rcu();\n}\n\n/* Assign port number to socket.\n *\n * Specify port in the integer pointed to by port, and it will be adjusted\n * on return as necesssary.\n *\n * Port may be:\n *   0: Assign ephemeral port in [QRTR_MIN_EPH_SOCKET, QRTR_MAX_EPH_SOCKET]\n *   <QRTR_MIN_EPH_SOCKET: Specified; requires CAP_NET_ADMIN\n *   >QRTR_MIN_EPH_SOCKET: Specified; available to all\n */\nstatic int qrtr_port_assign(struct qrtr_sock *ipc, int *port)\n{\n\tint rc;\n\n\tif (!*port) {\n\t\trc = xa_alloc(&qrtr_ports, port, ipc, QRTR_EPH_PORT_RANGE,\n\t\t\t\tGFP_KERNEL);\n\t} else if (*port < QRTR_MIN_EPH_SOCKET && !capable(CAP_NET_ADMIN)) {\n\t\trc = -EACCES;\n\t} else if (*port == QRTR_PORT_CTRL) {\n\t\trc = xa_insert(&qrtr_ports, 0, ipc, GFP_KERNEL);\n\t} else {\n\t\trc = xa_insert(&qrtr_ports, *port, ipc, GFP_KERNEL);\n\t}\n\n\tif (rc == -EBUSY)\n\t\treturn -EADDRINUSE;\n\telse if (rc < 0)\n\t\treturn rc;\n\n\tsock_hold(&ipc->sk);\n\n\treturn 0;\n}\n\n/* Reset all non-control ports */\nstatic void qrtr_reset_ports(void)\n{\n\tstruct qrtr_sock *ipc;\n\tunsigned long index;\n\n\trcu_read_lock();\n\txa_for_each_start(&qrtr_ports, index, ipc, 1) {\n\t\tsock_hold(&ipc->sk);\n\t\tipc->sk.sk_err = ENETRESET;\n\t\tsk_error_report(&ipc->sk);\n\t\tsock_put(&ipc->sk);\n\t}\n\trcu_read_unlock();\n}\n\n/* Bind socket to address.\n *\n * Socket should be locked upon call.\n */\nstatic int __qrtr_bind(struct socket *sock,\n\t\t       const struct sockaddr_qrtr *addr, int zapped)\n{\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tint port;\n\tint rc;\n\n\t/* rebinding ok */\n\tif (!zapped && addr->sq_port == ipc->us.sq_port)\n\t\treturn 0;\n\n\tport = addr->sq_port;\n\trc = qrtr_port_assign(ipc, &port);\n\tif (rc)\n\t\treturn rc;\n\n\t/* unbind previous, if any */\n\tif (!zapped)\n\t\tqrtr_port_remove(ipc);\n\tipc->us.sq_port = port;\n\n\tsock_reset_flag(sk, SOCK_ZAPPED);\n\n\t/* Notify all open ports about the new controller */\n\tif (port == QRTR_PORT_CTRL)\n\t\tqrtr_reset_ports();\n\n\treturn 0;\n}\n\n/* Auto bind to an ephemeral port. */\nstatic int qrtr_autobind(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct sockaddr_qrtr addr;\n\n\tif (!sock_flag(sk, SOCK_ZAPPED))\n\t\treturn 0;\n\n\taddr.sq_family = AF_QIPCRTR;\n\taddr.sq_node = qrtr_local_nid;\n\taddr.sq_port = 0;\n\n\treturn __qrtr_bind(sock, &addr, 1);\n}\n\n/* Bind socket to specified sockaddr. */\nstatic int qrtr_bind(struct socket *sock, struct sockaddr *saddr, int len)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_qrtr *, addr, saddr);\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tint rc;\n\n\tif (len < sizeof(*addr) || addr->sq_family != AF_QIPCRTR)\n\t\treturn -EINVAL;\n\n\tif (addr->sq_node != ipc->us.sq_node)\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\trc = __qrtr_bind(sock, addr, sock_flag(sk, SOCK_ZAPPED));\n\trelease_sock(sk);\n\n\treturn rc;\n}\n\n/* Queue packet to local peer socket. */\nstatic int qrtr_local_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t      int type, struct sockaddr_qrtr *from,\n\t\t\t      struct sockaddr_qrtr *to)\n{\n\tstruct qrtr_sock *ipc;\n\tstruct qrtr_cb *cb;\n\n\tipc = qrtr_port_lookup(to->sq_port);\n\tif (!ipc || &ipc->sk == skb->sk) { /* do not send to self */\n\t\tif (ipc)\n\t\t\tqrtr_port_put(ipc);\n\t\tkfree_skb(skb);\n\t\treturn -ENODEV;\n\t}\n\n\tcb = (struct qrtr_cb *)skb->cb;\n\tcb->src_node = from->sq_node;\n\tcb->src_port = from->sq_port;\n\n\tif (sock_queue_rcv_skb(&ipc->sk, skb)) {\n\t\tqrtr_port_put(ipc);\n\t\tkfree_skb(skb);\n\t\treturn -ENOSPC;\n\t}\n\n\tqrtr_port_put(ipc);\n\n\treturn 0;\n}\n\n/* Queue packet for broadcast. */\nstatic int qrtr_bcast_enqueue(struct qrtr_node *node, struct sk_buff *skb,\n\t\t\t      int type, struct sockaddr_qrtr *from,\n\t\t\t      struct sockaddr_qrtr *to)\n{\n\tstruct sk_buff *skbn;\n\n\tmutex_lock(&qrtr_node_lock);\n\tlist_for_each_entry(node, &qrtr_all_nodes, item) {\n\t\tskbn = skb_clone(skb, GFP_KERNEL);\n\t\tif (!skbn)\n\t\t\tbreak;\n\t\tskb_set_owner_w(skbn, skb->sk);\n\t\tqrtr_node_enqueue(node, skbn, type, from, to);\n\t}\n\tmutex_unlock(&qrtr_node_lock);\n\n\tqrtr_local_enqueue(NULL, skb, type, from, to);\n\n\treturn 0;\n}\n\nstatic int qrtr_sendmsg(struct socket *sock, struct msghdr *msg, size_t len)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_qrtr *, addr, msg->msg_name);\n\tint (*enqueue_fn)(struct qrtr_node *, struct sk_buff *, int,\n\t\t\t  struct sockaddr_qrtr *, struct sockaddr_qrtr *);\n\t__le32 qrtr_type = cpu_to_le32(QRTR_TYPE_DATA);\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tstruct qrtr_node *node;\n\tstruct sk_buff *skb;\n\tsize_t plen;\n\tu32 type;\n\tint rc;\n\n\tif (msg->msg_flags & ~(MSG_DONTWAIT))\n\t\treturn -EINVAL;\n\n\tif (len > 65535)\n\t\treturn -EMSGSIZE;\n\n\tlock_sock(sk);\n\n\tif (addr) {\n\t\tif (msg->msg_namelen < sizeof(*addr)) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif (addr->sq_family != AF_QIPCRTR) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\trc = qrtr_autobind(sock);\n\t\tif (rc) {\n\t\t\trelease_sock(sk);\n\t\t\treturn rc;\n\t\t}\n\t} else if (sk->sk_state == TCP_ESTABLISHED) {\n\t\taddr = &ipc->peer;\n\t} else {\n\t\trelease_sock(sk);\n\t\treturn -ENOTCONN;\n\t}\n\n\tnode = NULL;\n\tif (addr->sq_node == QRTR_NODE_BCAST) {\n\t\tif (addr->sq_port != QRTR_PORT_CTRL &&\n\t\t    qrtr_local_nid != QRTR_NODE_BCAST) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -ENOTCONN;\n\t\t}\n\t\tenqueue_fn = qrtr_bcast_enqueue;\n\t} else if (addr->sq_node == ipc->us.sq_node) {\n\t\tenqueue_fn = qrtr_local_enqueue;\n\t} else {\n\t\tnode = qrtr_node_lookup(addr->sq_node);\n\t\tif (!node) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -ECONNRESET;\n\t\t}\n\t\tenqueue_fn = qrtr_node_enqueue;\n\t}\n\n\tplen = (len + 3) & ~3;\n\tskb = sock_alloc_send_skb(sk, plen + QRTR_HDR_MAX_SIZE,\n\t\t\t\t  msg->msg_flags & MSG_DONTWAIT, &rc);\n\tif (!skb) {\n\t\trc = -ENOMEM;\n\t\tgoto out_node;\n\t}\n\n\tskb_reserve(skb, QRTR_HDR_MAX_SIZE);\n\n\trc = memcpy_from_msg(skb_put(skb, len), msg, len);\n\tif (rc) {\n\t\tkfree_skb(skb);\n\t\tgoto out_node;\n\t}\n\n\tif (ipc->us.sq_port == QRTR_PORT_CTRL) {\n\t\tif (len < 4) {\n\t\t\trc = -EINVAL;\n\t\t\tkfree_skb(skb);\n\t\t\tgoto out_node;\n\t\t}\n\n\t\t/* control messages already require the type as 'command' */\n\t\tskb_copy_bits(skb, 0, &qrtr_type, 4);\n\t}\n\n\ttype = le32_to_cpu(qrtr_type);\n\trc = enqueue_fn(node, skb, type, &ipc->us, addr);\n\tif (rc >= 0)\n\t\trc = len;\n\nout_node:\n\tqrtr_node_release(node);\n\trelease_sock(sk);\n\n\treturn rc;\n}\n\nstatic int qrtr_send_resume_tx(struct qrtr_cb *cb)\n{\n\tstruct sockaddr_qrtr remote = { AF_QIPCRTR, cb->src_node, cb->src_port };\n\tstruct sockaddr_qrtr local = { AF_QIPCRTR, cb->dst_node, cb->dst_port };\n\tstruct qrtr_ctrl_pkt *pkt;\n\tstruct qrtr_node *node;\n\tstruct sk_buff *skb;\n\tint ret;\n\n\tnode = qrtr_node_lookup(remote.sq_node);\n\tif (!node)\n\t\treturn -EINVAL;\n\n\tskb = qrtr_alloc_ctrl_packet(&pkt, GFP_KERNEL);\n\tif (!skb)\n\t\treturn -ENOMEM;\n\n\tpkt->cmd = cpu_to_le32(QRTR_TYPE_RESUME_TX);\n\tpkt->client.node = cpu_to_le32(cb->dst_node);\n\tpkt->client.port = cpu_to_le32(cb->dst_port);\n\n\tret = qrtr_node_enqueue(node, skb, QRTR_TYPE_RESUME_TX, &local, &remote);\n\n\tqrtr_node_release(node);\n\n\treturn ret;\n}\n\nstatic int qrtr_recvmsg(struct socket *sock, struct msghdr *msg,\n\t\t\tsize_t size, int flags)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_qrtr *, addr, msg->msg_name);\n\tstruct sock *sk = sock->sk;\n\tstruct sk_buff *skb;\n\tstruct qrtr_cb *cb;\n\tint copied, rc;\n\n\tlock_sock(sk);\n\n\tif (sock_flag(sk, SOCK_ZAPPED)) {\n\t\trelease_sock(sk);\n\t\treturn -EADDRNOTAVAIL;\n\t}\n\n\tskb = skb_recv_datagram(sk, flags & ~MSG_DONTWAIT,\n\t\t\t\tflags & MSG_DONTWAIT, &rc);\n\tif (!skb) {\n\t\trelease_sock(sk);\n\t\treturn rc;\n\t}\n\tcb = (struct qrtr_cb *)skb->cb;\n\n\tcopied = skb->len;\n\tif (copied > size) {\n\t\tcopied = size;\n\t\tmsg->msg_flags |= MSG_TRUNC;\n\t}\n\n\trc = skb_copy_datagram_msg(skb, 0, msg, copied);\n\tif (rc < 0)\n\t\tgoto out;\n\trc = copied;\n\n\tif (addr) {\n\t\t/* There is an anonymous 2-byte hole after sq_family,\n\t\t * make sure to clear it.\n\t\t */\n\t\tmemset(addr, 0, sizeof(*addr));\n\n\t\taddr->sq_family = AF_QIPCRTR;\n\t\taddr->sq_node = cb->src_node;\n\t\taddr->sq_port = cb->src_port;\n\t\tmsg->msg_namelen = sizeof(*addr);\n\t}\n\nout:\n\tif (cb->confirm_rx)\n\t\tqrtr_send_resume_tx(cb);\n\n\tskb_free_datagram(sk, skb);\n\trelease_sock(sk);\n\n\treturn rc;\n}\n\nstatic int qrtr_connect(struct socket *sock, struct sockaddr *saddr,\n\t\t\tint len, int flags)\n{\n\tDECLARE_SOCKADDR(struct sockaddr_qrtr *, addr, saddr);\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tint rc;\n\n\tif (len < sizeof(*addr) || addr->sq_family != AF_QIPCRTR)\n\t\treturn -EINVAL;\n\n\tlock_sock(sk);\n\n\tsk->sk_state = TCP_CLOSE;\n\tsock->state = SS_UNCONNECTED;\n\n\trc = qrtr_autobind(sock);\n\tif (rc) {\n\t\trelease_sock(sk);\n\t\treturn rc;\n\t}\n\n\tipc->peer = *addr;\n\tsock->state = SS_CONNECTED;\n\tsk->sk_state = TCP_ESTABLISHED;\n\n\trelease_sock(sk);\n\n\treturn 0;\n}\n\nstatic int qrtr_getname(struct socket *sock, struct sockaddr *saddr,\n\t\t\tint peer)\n{\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sockaddr_qrtr qaddr;\n\tstruct sock *sk = sock->sk;\n\n\tlock_sock(sk);\n\tif (peer) {\n\t\tif (sk->sk_state != TCP_ESTABLISHED) {\n\t\t\trelease_sock(sk);\n\t\t\treturn -ENOTCONN;\n\t\t}\n\n\t\tqaddr = ipc->peer;\n\t} else {\n\t\tqaddr = ipc->us;\n\t}\n\trelease_sock(sk);\n\n\tqaddr.sq_family = AF_QIPCRTR;\n\n\tmemcpy(saddr, &qaddr, sizeof(qaddr));\n\n\treturn sizeof(qaddr);\n}\n\nstatic int qrtr_ioctl(struct socket *sock, unsigned int cmd, unsigned long arg)\n{\n\tvoid __user *argp = (void __user *)arg;\n\tstruct qrtr_sock *ipc = qrtr_sk(sock->sk);\n\tstruct sock *sk = sock->sk;\n\tstruct sockaddr_qrtr *sq;\n\tstruct sk_buff *skb;\n\tstruct ifreq ifr;\n\tlong len = 0;\n\tint rc = 0;\n\n\tlock_sock(sk);\n\n\tswitch (cmd) {\n\tcase TIOCOUTQ:\n\t\tlen = sk->sk_sndbuf - sk_wmem_alloc_get(sk);\n\t\tif (len < 0)\n\t\t\tlen = 0;\n\t\trc = put_user(len, (int __user *)argp);\n\t\tbreak;\n\tcase TIOCINQ:\n\t\tskb = skb_peek(&sk->sk_receive_queue);\n\t\tif (skb)\n\t\t\tlen = skb->len;\n\t\trc = put_user(len, (int __user *)argp);\n\t\tbreak;\n\tcase SIOCGIFADDR:\n\t\tif (copy_from_user(&ifr, argp, sizeof(ifr))) {\n\t\t\trc = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\n\t\tsq = (struct sockaddr_qrtr *)&ifr.ifr_addr;\n\t\t*sq = ipc->us;\n\t\tif (copy_to_user(argp, &ifr, sizeof(ifr))) {\n\t\t\trc = -EFAULT;\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\tcase SIOCADDRT:\n\tcase SIOCDELRT:\n\tcase SIOCSIFADDR:\n\tcase SIOCGIFDSTADDR:\n\tcase SIOCSIFDSTADDR:\n\tcase SIOCGIFBRDADDR:\n\tcase SIOCSIFBRDADDR:\n\tcase SIOCGIFNETMASK:\n\tcase SIOCSIFNETMASK:\n\t\trc = -EINVAL;\n\t\tbreak;\n\tdefault:\n\t\trc = -ENOIOCTLCMD;\n\t\tbreak;\n\t}\n\n\trelease_sock(sk);\n\n\treturn rc;\n}\n\nstatic int qrtr_release(struct socket *sock)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct qrtr_sock *ipc;\n\n\tif (!sk)\n\t\treturn 0;\n\n\tlock_sock(sk);\n\n\tipc = qrtr_sk(sk);\n\tsk->sk_shutdown = SHUTDOWN_MASK;\n\tif (!sock_flag(sk, SOCK_DEAD))\n\t\tsk->sk_state_change(sk);\n\n\tsock_set_flag(sk, SOCK_DEAD);\n\tsock_orphan(sk);\n\tsock->sk = NULL;\n\n\tif (!sock_flag(sk, SOCK_ZAPPED))\n\t\tqrtr_port_remove(ipc);\n\n\tskb_queue_purge(&sk->sk_receive_queue);\n\n\trelease_sock(sk);\n\tsock_put(sk);\n\n\treturn 0;\n}\n\nstatic const struct proto_ops qrtr_proto_ops = {\n\t.owner\t\t= THIS_MODULE,\n\t.family\t\t= AF_QIPCRTR,\n\t.bind\t\t= qrtr_bind,\n\t.connect\t= qrtr_connect,\n\t.socketpair\t= sock_no_socketpair,\n\t.accept\t\t= sock_no_accept,\n\t.listen\t\t= sock_no_listen,\n\t.sendmsg\t= qrtr_sendmsg,\n\t.recvmsg\t= qrtr_recvmsg,\n\t.getname\t= qrtr_getname,\n\t.ioctl\t\t= qrtr_ioctl,\n\t.gettstamp\t= sock_gettstamp,\n\t.poll\t\t= datagram_poll,\n\t.shutdown\t= sock_no_shutdown,\n\t.release\t= qrtr_release,\n\t.mmap\t\t= sock_no_mmap,\n\t.sendpage\t= sock_no_sendpage,\n};\n\nstatic struct proto qrtr_proto = {\n\t.name\t\t= \"QIPCRTR\",\n\t.owner\t\t= THIS_MODULE,\n\t.obj_size\t= sizeof(struct qrtr_sock),\n};\n\nstatic int qrtr_create(struct net *net, struct socket *sock,\n\t\t       int protocol, int kern)\n{\n\tstruct qrtr_sock *ipc;\n\tstruct sock *sk;\n\n\tif (sock->type != SOCK_DGRAM)\n\t\treturn -EPROTOTYPE;\n\n\tsk = sk_alloc(net, AF_QIPCRTR, GFP_KERNEL, &qrtr_proto, kern);\n\tif (!sk)\n\t\treturn -ENOMEM;\n\n\tsock_set_flag(sk, SOCK_ZAPPED);\n\n\tsock_init_data(sock, sk);\n\tsock->ops = &qrtr_proto_ops;\n\n\tipc = qrtr_sk(sk);\n\tipc->us.sq_family = AF_QIPCRTR;\n\tipc->us.sq_node = qrtr_local_nid;\n\tipc->us.sq_port = 0;\n\n\treturn 0;\n}\n\nstatic const struct net_proto_family qrtr_family = {\n\t.owner\t= THIS_MODULE,\n\t.family\t= AF_QIPCRTR,\n\t.create\t= qrtr_create,\n};\n\nstatic int __init qrtr_proto_init(void)\n{\n\tint rc;\n\n\trc = proto_register(&qrtr_proto, 1);\n\tif (rc)\n\t\treturn rc;\n\n\trc = sock_register(&qrtr_family);\n\tif (rc)\n\t\tgoto err_proto;\n\n\trc = qrtr_ns_init();\n\tif (rc)\n\t\tgoto err_sock;\n\n\treturn 0;\n\nerr_sock:\n\tsock_unregister(qrtr_family.family);\nerr_proto:\n\tproto_unregister(&qrtr_proto);\n\treturn rc;\n}\npostcore_initcall(qrtr_proto_init);\n\nstatic void __exit qrtr_proto_fini(void)\n{\n\tqrtr_ns_remove();\n\tsock_unregister(qrtr_family.family);\n\tproto_unregister(&qrtr_proto);\n}\nmodule_exit(qrtr_proto_fini);\n\nMODULE_DESCRIPTION(\"Qualcomm IPC-router driver\");\nMODULE_LICENSE(\"GPL v2\");\nMODULE_ALIAS_NETPROTO(PF_QIPCRTR);\n"], "filenames": ["net/qrtr/qrtr.c"], "buggy_code_start_loc": [496], "buggy_code_end_loc": [497], "fixing_code_start_loc": [496], "fixing_code_end_loc": [497], "type": "CWE-125", "message": "An out-of-bounds (OOB) memory read flaw was found in the Qualcomm IPC router protocol in the Linux kernel. A missing sanity check allows a local attacker to gain access to out-of-bounds memory, leading to a system crash or a leak of internal kernel information. The highest threat from this vulnerability is to system availability.", "other": {"cve": {"id": "CVE-2021-3743", "sourceIdentifier": "secalert@redhat.com", "published": "2022-03-04T16:15:08.547", "lastModified": "2023-02-24T15:14:26.857", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "An out-of-bounds (OOB) memory read flaw was found in the Qualcomm IPC router protocol in the Linux kernel. A missing sanity check allows a local attacker to gain access to out-of-bounds memory, leading to a system crash or a leak of internal kernel information. The highest threat from this vulnerability is to system availability."}, {"lang": "es", "value": "Se ha encontrado un defecto de lectura de memoria fuera de l\u00edmites (OOB) en el protocolo de router Qualcomm IPC en el kernel de Linux. Una falta de comprobaci\u00f3n de saneo permite a un atacante local conseguir acceso de memoria fuera de l\u00edmites, conllevando a un bloqueo del sistema o un filtrado de informaci\u00f3n interna del kernel. La mayor amenaza de esta vulnerabilidad es la disponibilidad del sistema"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:L/AC:L/PR:L/UI:N/S:U/C:H/I:N/A:H", "attackVector": "LOCAL", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "NONE", "availabilityImpact": "HIGH", "baseScore": 7.1, "baseSeverity": "HIGH"}, "exploitabilityScore": 1.8, "impactScore": 5.2}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:L/AC:L/Au:N/C:P/I:N/A:P", "accessVector": "LOCAL", "accessComplexity": "LOW", "authentication": "NONE", "confidentialityImpact": "PARTIAL", "integrityImpact": "NONE", "availabilityImpact": "PARTIAL", "baseScore": 3.6}, "baseSeverity": "LOW", "exploitabilityScore": 3.9, "impactScore": 4.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "secalert@redhat.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-125"}]}, {"source": "nvd@nist.gov", "type": "Secondary", "description": [{"lang": "en", "value": "CWE-125"}]}], "configurations": [{"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:*:*:*:*:*:*:*:*", "versionStartExcluding": "5.14.1", "versionEndExcluding": "5.17", "matchCriteriaId": "922F737F-0C17-48D2-AA8C-7388C792B55E"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.14:rc6:*:*:*:*:*:*", "matchCriteriaId": "15013998-4AF0-4CDC-AB13-829ECD8A8E66"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.17:-:*:*:*:*:*:*", "matchCriteriaId": "A59F7FD3-F505-48BD-8875-F07A33F42F6C"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.17:rc1:*:*:*:*:*:*", "matchCriteriaId": "7BD5F8D9-54FA-4CB0-B4F0-CB0471FDDB2D"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.17:rc2:*:*:*:*:*:*", "matchCriteriaId": "E6E34B23-78B4-4516-9BD8-61B33F4AC49A"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.17:rc3:*:*:*:*:*:*", "matchCriteriaId": "C030FA3D-03F4-4FB9-9DBF-D08E5CAC51AA"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.17:rc4:*:*:*:*:*:*", "matchCriteriaId": "B2D2677C-5389-4AE9-869D-0F881E80D923"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.17:rc5:*:*:*:*:*:*", "matchCriteriaId": "EFA3917C-C322-4D92-912D-ECE45B2E7416"}, {"vulnerable": true, "criteria": "cpe:2.3:o:linux:linux_kernel:5.17:rc6:*:*:*:*:*:*", "matchCriteriaId": "BED18363-5ABC-4639-8BBA-68E771E5BB3F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:fedoraproject:fedora:34:*:*:*:*:*:*:*", "matchCriteriaId": "A930E247-0B43-43CB-98FF-6CE7B8189835"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:baseboard_management_controller_h300s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "1746E116-3B82-4F65-B540-63D4058BD471"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:baseboard_management_controller_h300s:-:*:*:*:*:*:*:*", "matchCriteriaId": "04FD1F9A-8F43-4509-9A49-714C54C4783C"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:baseboard_management_controller_h500s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "BAFC49B0-FC63-4F06-A9DC-B853186003A9"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:baseboard_management_controller_h500s:-:*:*:*:*:*:*:*", "matchCriteriaId": "504201E4-04CD-4224-9264-C1AEAD480E36"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:baseboard_management_controller_h700s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "9BFAB819-0951-4D57-9B86-3CF590E50E7A"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:baseboard_management_controller_h700s:-:*:*:*:*:*:*:*", "matchCriteriaId": "BDDA0D1D-3A1E-4CF5-BD6A-F05AE4E8CDDA"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:baseboard_management_controller_h300e_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "806D1842-64F5-4F4C-B728-AFD0B99CE6EB"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:baseboard_management_controller_h300e:-:*:*:*:*:*:*:*", "matchCriteriaId": "266DDF39-2707-401F-88AF-3761D1045202"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:baseboard_management_controller_h500e_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "4ED4148B-73E9-48DA-BB54-F5A43B21FD56"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:baseboard_management_controller_h500e:-:*:*:*:*:*:*:*", "matchCriteriaId": "B09AB46C-8B35-4085-AD86-56EC06F665CB"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:baseboard_management_controller_h700e_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "46BB915A-F2AE-4041-89F1-03547F819DFF"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:baseboard_management_controller_h700e:-:*:*:*:*:*:*:*", "matchCriteriaId": "A33DCDCD-58EC-495A-BD5E-BB612F5B8A39"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:baseboard_management_controller_h410s_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "88A6EDE4-DD97-45A9-8366-E999525AA68F"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:baseboard_management_controller_h410s:-:*:*:*:*:*:*:*", "matchCriteriaId": "C2934495-6D4D-4C21-89E3-A2414ABDD5CE"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:o:netapp:baseboard_management_controller_h410c_firmware:-:*:*:*:*:*:*:*", "matchCriteriaId": "8665C148-3C9E-4EC9-A281-293D2352B8B9"}]}, {"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": false, "criteria": "cpe:2.3:h:netapp:baseboard_management_controller_h410c:-:*:*:*:*:*:*:*", "matchCriteriaId": "1A0CE664-32E5-4917-8319-7D2A31DCD72F"}]}]}, {"operator": "AND", "nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:oracle:communications_cloud_native_core_binding_support_function:22.1.3:*:*:*:*:*:*:*", "matchCriteriaId": "6EDB6772-7FDB-45FF-8D72-952902A7EE56"}, {"vulnerable": true, "criteria": "cpe:2.3:a:oracle:communications_cloud_native_core_network_exposure_function:22.1.1:*:*:*:*:*:*:*", "matchCriteriaId": "9955F62A-75D3-4347-9AD3-5947FC365838"}, {"vulnerable": true, "criteria": "cpe:2.3:a:oracle:communications_cloud_native_core_policy:22.2.0:*:*:*:*:*:*:*", "matchCriteriaId": "7A6D77C7-A2F4-4700-AB5A-3EC853496ECA"}]}]}], "references": [{"url": "https://bugzilla.redhat.com/show_bug.cgi?id=1997961", "source": "secalert@redhat.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://git.kernel.org/pub/scm/linux/kernel/git/netdev/net.git/commit/?id=7e78c597c3eb", "source": "secalert@redhat.com", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=7e78c597c3ebfd0cb329aa09a838734147e4f117", "source": "secalert@redhat.com", "tags": ["Patch", "Vendor Advisory"]}, {"url": "https://github.com/torvalds/linux/commit/7e78c597c3ebfd0cb329aa09a838734147e4f117", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://lists.openwall.net/netdev/2021/08/17/124", "source": "secalert@redhat.com", "tags": ["Exploit", "Mailing List", "Third Party Advisory"]}, {"url": "https://security.netapp.com/advisory/ntap-20220407-0007/", "source": "secalert@redhat.com", "tags": ["Third Party Advisory"]}, {"url": "https://www.openwall.com/lists/oss-security/2021/08/27/2", "source": "secalert@redhat.com", "tags": ["Exploit", "Mailing List", "Patch", "Third Party Advisory"]}, {"url": "https://www.oracle.com/security-alerts/cpujul2022.html", "source": "secalert@redhat.com", "tags": ["Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/torvalds/linux/commit/7e78c597c3ebfd0cb329aa09a838734147e4f117"}}
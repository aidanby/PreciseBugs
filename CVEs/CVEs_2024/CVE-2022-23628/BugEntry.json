{"buggy_code": ["// Copyright 2017 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\n// Package format implements formatting of Rego source files.\npackage format\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"sort\"\n\n\t\"github.com/open-policy-agent/opa/ast\"\n)\n\n// Source formats a Rego source file. The bytes provided must describe a complete\n// Rego module. If they don't, Source will return an error resulting from the attempt\n// to parse the bytes.\nfunc Source(filename string, src []byte) ([]byte, error) {\n\tmodule, err := ast.ParseModule(filename, string(src))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tformatted, err := Ast(module)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"%s: %v\", filename, err)\n\t}\n\treturn formatted, nil\n}\n\n// MustAst is a helper function to format a Rego AST element. If any errors\n// occurs this function will panic. This is mostly used for test\nfunc MustAst(x interface{}) []byte {\n\tbs, err := Ast(x)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn bs\n}\n\n// Ast formats a Rego AST element. If the passed value is not a valid AST\n// element, Ast returns nil and an error. If AST nodes are missing locations\n// an arbitrary location will be used.\nfunc Ast(x interface{}) ([]byte, error) {\n\n\t// The node has to be deep copied because it may be mutated below. Alternatively,\n\t// we could avoid the copy by checking if mutation will occur first. For now,\n\t// since format is not latency sensitive, just deep copy in all cases.\n\tx = ast.Copy(x)\n\n\twildcards := map[ast.Var]*ast.Term{}\n\n\t// NOTE(sr): When the formatter encounters a call to internal.member_2\n\t// or internal.member_3, it will sugarize them into usage of the `in`\n\t// operator. It has to ensure that the proper future keyword import is\n\t// present.\n\textraFutureKeywordImports := map[string]bool{}\n\n\t// Preprocess the AST. Set any required defaults and calculate\n\t// values required for printing the formatted output.\n\tast.WalkNodes(x, func(x ast.Node) bool {\n\t\tswitch n := x.(type) {\n\t\tcase ast.Body:\n\t\t\tif len(n) == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase *ast.Term:\n\t\t\tunmangleWildcardVar(wildcards, n)\n\n\t\tcase *ast.Expr:\n\t\t\tif n.IsCall() &&\n\t\t\t\tast.Member.Ref().Equal(n.Operator()) ||\n\t\t\t\tast.MemberWithKey.Ref().Equal(n.Operator()) {\n\t\t\t\textraFutureKeywordImports[\"in\"] = true\n\t\t\t}\n\t\t}\n\t\tif x.Loc() == nil {\n\t\t\tx.SetLoc(defaultLocation(x))\n\t\t}\n\t\treturn false\n\t})\n\n\tw := &writer{\n\t\tindent: \"\\t\",\n\t}\n\n\tswitch x := x.(type) {\n\tcase *ast.Module:\n\t\tfor kw := range extraFutureKeywordImports {\n\t\t\tx.Imports = ensureFutureKeywordImport(x.Imports, kw)\n\t\t}\n\t\tw.writeModule(x)\n\tcase *ast.Package:\n\t\tw.writePackage(x, nil)\n\tcase *ast.Import:\n\t\tw.writeImports([]*ast.Import{x}, nil)\n\tcase *ast.Rule:\n\t\tw.writeRule(x, false, nil)\n\tcase *ast.Head:\n\t\tw.writeHead(x, false, false, nil)\n\tcase ast.Body:\n\t\tw.writeBody(x, nil)\n\tcase *ast.Expr:\n\t\tw.writeExpr(x, nil)\n\tcase *ast.With:\n\t\tw.writeWith(x, nil)\n\tcase *ast.Term:\n\t\tw.writeTerm(x, nil)\n\tcase ast.Value:\n\t\tw.writeTerm(&ast.Term{Value: x, Location: &ast.Location{}}, nil)\n\tcase *ast.Comment:\n\t\tw.writeComments([]*ast.Comment{x})\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"not an ast element: %v\", x)\n\t}\n\n\treturn squashTrailingNewlines(w.buf.Bytes()), nil\n}\n\nfunc unmangleWildcardVar(wildcards map[ast.Var]*ast.Term, n *ast.Term) {\n\n\tv, ok := n.Value.(ast.Var)\n\tif !ok || !v.IsWildcard() {\n\t\treturn\n\t}\n\n\tfirst, ok := wildcards[v]\n\tif !ok {\n\t\twildcards[v] = n\n\t\treturn\n\t}\n\n\tw := v[len(ast.WildcardPrefix):]\n\n\t// Prepend an underscore to ensure the variable will parse.\n\tif len(w) == 0 || w[0] != '_' {\n\t\tw = \"_\" + w\n\t}\n\n\tif first != nil {\n\t\tfirst.Value = w\n\t\twildcards[v] = nil\n\t}\n\n\tn.Value = w\n}\n\nfunc squashTrailingNewlines(bs []byte) []byte {\n\tif bytes.HasSuffix(bs, []byte(\"\\n\")) {\n\t\treturn append(bytes.TrimRight(bs, \"\\n\"), '\\n')\n\t}\n\treturn bs\n}\n\nfunc defaultLocation(x ast.Node) *ast.Location {\n\treturn ast.NewLocation([]byte(x.String()), \"\", 1, 1)\n}\n\ntype writer struct {\n\tbuf bytes.Buffer\n\n\tindent    string\n\tlevel     int\n\tinline    bool\n\tbeforeEnd *ast.Comment\n\tdelay     bool\n}\n\nfunc (w *writer) writeModule(module *ast.Module) {\n\tvar pkg *ast.Package\n\tvar others []interface{}\n\tvar comments []*ast.Comment\n\tvisitor := ast.NewGenericVisitor(func(x interface{}) bool {\n\t\tswitch x := x.(type) {\n\t\tcase *ast.Comment:\n\t\t\tcomments = append(comments, x)\n\t\t\treturn true\n\t\tcase *ast.Import, *ast.Rule:\n\t\t\tothers = append(others, x)\n\t\t\treturn true\n\t\tcase *ast.Package:\n\t\t\tpkg = x\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t})\n\tvisitor.Walk(module)\n\n\tsort.Slice(comments, func(i, j int) bool {\n\t\treturn locLess(comments[i], comments[j])\n\t})\n\n\t// XXX: The parser currently duplicates comments for some reason, so we need\n\t// to remove duplicates here.\n\tcomments = dedupComments(comments)\n\tsort.Slice(others, func(i, j int) bool {\n\t\treturn locLess(others[i], others[j])\n\t})\n\n\tcomments = w.writePackage(pkg, comments)\n\tvar imports []*ast.Import\n\tvar rules []*ast.Rule\n\tfor len(others) > 0 {\n\t\timports, others = gatherImports(others)\n\t\tcomments = w.writeImports(imports, comments)\n\t\trules, others = gatherRules(others)\n\t\tcomments = w.writeRules(rules, comments)\n\t}\n\n\tfor i, c := range comments {\n\t\tw.writeLine(c.String())\n\t\tif i == len(comments)-1 {\n\t\t\tw.write(\"\\n\")\n\t\t}\n\t}\n}\n\nfunc (w *writer) writePackage(pkg *ast.Package, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, pkg.Location)\n\n\tw.startLine()\n\tw.write(pkg.String())\n\tw.blankLine()\n\n\treturn comments\n}\n\nfunc (w *writer) writeComments(comments []*ast.Comment) {\n\tfor i := 0; i < len(comments); i++ {\n\t\tif i > 0 && locCmp(comments[i], comments[i-1]) > 1 {\n\t\t\tw.blankLine()\n\t\t}\n\t\tw.writeLine(comments[i].String())\n\t}\n}\n\nfunc (w *writer) writeRules(rules []*ast.Rule, comments []*ast.Comment) []*ast.Comment {\n\tfor _, rule := range rules {\n\t\tcomments = w.insertComments(comments, rule.Location)\n\t\tcomments = w.writeRule(rule, false, comments)\n\t\tw.blankLine()\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeRule(rule *ast.Rule, isElse bool, comments []*ast.Comment) []*ast.Comment {\n\tif rule == nil {\n\t\treturn comments\n\t}\n\n\tif !isElse {\n\t\tw.startLine()\n\t}\n\n\tif rule.Default {\n\t\tw.write(\"default \")\n\t}\n\n\t// OPA transforms lone bodies like `foo = {\"a\": \"b\"}` into rules of the form\n\t// `foo = {\"a\": \"b\"} { true }` in the AST. We want to preserve that notation\n\t// in the formatted code instead of expanding the bodies into rules, so we\n\t// pretend that the rule has no body in this case.\n\tisExpandedConst := rule.Body.Equal(ast.NewBody(ast.NewExpr(ast.BooleanTerm(true)))) && rule.Else == nil\n\n\tcomments = w.writeHead(rule.Head, rule.Default, isExpandedConst, comments)\n\n\tif (len(rule.Body) == 0 || isExpandedConst) && !isElse {\n\t\tw.endLine()\n\t\treturn comments\n\t}\n\n\tw.write(\" {\")\n\tw.endLine()\n\tw.up()\n\n\tcomments = w.writeBody(rule.Body, comments)\n\n\tvar closeLoc *ast.Location\n\n\tif len(rule.Head.Args) > 0 {\n\t\tcloseLoc = closingLoc('(', ')', '{', '}', rule.Location)\n\t} else {\n\t\tcloseLoc = closingLoc('[', ']', '{', '}', rule.Location)\n\t}\n\n\tcomments = w.insertComments(comments, closeLoc)\n\n\tw.down()\n\tw.startLine()\n\tw.write(\"}\")\n\tif rule.Else != nil {\n\t\tcomments = w.writeElse(rule, comments)\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeElse(rule *ast.Rule, comments []*ast.Comment) []*ast.Comment {\n\t// If there was nothing else on the line before the \"else\" starts\n\t// then preserve this style of else block, otherwise it will be\n\t// started as an \"inline\" else eg:\n\t//\n\t//     p {\n\t//     \t...\n\t//     }\n\t//\n\t//     else {\n\t//     \t...\n\t//     }\n\t//\n\t// versus\n\t//\n\t//     p {\n\t// \t    ...\n\t//     } else {\n\t//     \t...\n\t//     }\n\t//\n\t// Note: This doesn't use the `close` as it currently isn't accurate for all\n\t// types of values. Checking the actual line text is the most consistent approach.\n\twasInline := false\n\truleLines := bytes.Split(rule.Location.Text, []byte(\"\\n\"))\n\trelativeElseRow := rule.Else.Location.Row - rule.Location.Row\n\tif relativeElseRow > 0 && relativeElseRow < len(ruleLines) {\n\t\telseLine := ruleLines[relativeElseRow]\n\t\tif !bytes.HasPrefix(bytes.TrimSpace(elseLine), []byte(\"else\")) {\n\t\t\twasInline = true\n\t\t}\n\t}\n\n\t// If there are any comments between the closing brace of the previous rule and the start\n\t// of the else block we will always insert a new blank line between them.\n\thasCommentAbove := len(comments) > 0 && comments[0].Location.Row-rule.Else.Head.Location.Row < 0 || w.beforeEnd != nil\n\n\tif !hasCommentAbove && wasInline {\n\t\tw.write(\" \")\n\t} else {\n\t\tw.blankLine()\n\t\tw.startLine()\n\t}\n\n\trule.Else.Head.Name = \"else\"\n\trule.Else.Head.Args = nil\n\tcomments = w.insertComments(comments, rule.Else.Head.Location)\n\n\tif hasCommentAbove && !wasInline {\n\t\t// The comments would have ended the line, be sure to start one again\n\t\t// before writing the rest of the \"else\" rule.\n\t\tw.startLine()\n\t}\n\n\t// For backwards compatibility adjust the rule head value location\n\t// TODO: Refactor the logic for inserting comments, or special\n\t// case comments in a rule head value so this can be removed\n\tif rule.Else.Head.Value != nil {\n\t\trule.Else.Head.Value.Location = rule.Else.Head.Location\n\t}\n\n\treturn w.writeRule(rule.Else, true, comments)\n}\n\nfunc (w *writer) writeHead(head *ast.Head, isDefault bool, isExpandedConst bool, comments []*ast.Comment) []*ast.Comment {\n\tw.write(head.Name.String())\n\tif len(head.Args) > 0 {\n\t\tw.write(\"(\")\n\t\tvar args []interface{}\n\t\tfor _, arg := range head.Args {\n\t\t\targs = append(args, arg)\n\t\t}\n\t\tcomments = w.writeIterable(args, head.Location, closingLoc(0, 0, '(', ')', head.Location), comments, w.listWriter())\n\t\tw.write(\")\")\n\t}\n\tif head.Key != nil {\n\t\tw.write(\"[\")\n\t\tcomments = w.writeTerm(head.Key, comments)\n\t\tw.write(\"]\")\n\t}\n\tif head.Value != nil && (head.Key != nil || ast.Compare(head.Value, ast.BooleanTerm(true)) != 0 || isExpandedConst || isDefault) {\n\t\tif head.Assign {\n\t\t\tw.write(\" := \")\n\t\t} else {\n\t\t\tw.write(\" = \")\n\t\t}\n\t\tcomments = w.writeTerm(head.Value, comments)\n\t}\n\treturn comments\n}\n\nfunc (w *writer) insertComments(comments []*ast.Comment, loc *ast.Location) []*ast.Comment {\n\tbefore, at, comments := partitionComments(comments, loc)\n\tw.writeComments(before)\n\tif len(before) > 0 && loc.Row-before[len(before)-1].Location.Row > 1 {\n\t\tw.blankLine()\n\t}\n\n\tw.beforeLineEnd(at)\n\treturn comments\n}\n\nfunc (w *writer) writeBody(body ast.Body, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, body.Loc())\n\toffset := 0\n\tfor i, expr := range body {\n\t\tif i > 0 && expr.Location.Row-body[i-1].Location.Row-offset > 1 {\n\t\t\tw.blankLine()\n\t\t}\n\t\tw.startLine()\n\n\t\tcomments = w.writeExpr(expr, comments)\n\t\tw.endLine()\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeExpr(expr *ast.Expr, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, expr.Location)\n\tif !w.inline {\n\t\tw.startLine()\n\t}\n\n\tif expr.Negated {\n\t\tw.write(\"not \")\n\t}\n\n\tswitch t := expr.Terms.(type) {\n\tcase *ast.SomeDecl:\n\t\tcomments = w.writeSomeDecl(t, comments)\n\tcase *ast.Every:\n\t\tcomments = w.writeEvery(t, comments)\n\tcase []*ast.Term:\n\t\tcomments = w.writeFunctionCall(expr, comments)\n\tcase *ast.Term:\n\t\tcomments = w.writeTerm(t, comments)\n\t}\n\n\tvar indented bool\n\tfor i, with := range expr.With {\n\t\tif i > 0 && with.Location.Row-expr.With[i-1].Location.Row > 0 {\n\t\t\tif !indented {\n\t\t\t\tindented = true\n\n\t\t\t\tw.up()\n\t\t\t\tdefer w.down()\n\t\t\t}\n\t\t\tw.endLine()\n\t\t\tw.startLine()\n\t\t}\n\t\tcomments = w.writeWith(with, comments)\n\t}\n\n\treturn comments\n}\n\nfunc (w *writer) writeSomeDecl(decl *ast.SomeDecl, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, decl.Location)\n\tw.write(\"some \")\n\n\trow := decl.Location.Row\n\n\tfor i, term := range decl.Symbols {\n\t\tswitch val := term.Value.(type) {\n\t\tcase ast.Var:\n\t\t\tif term.Location.Row > row {\n\t\t\t\tw.endLine()\n\t\t\t\tw.startLine()\n\t\t\t\tw.write(w.indent)\n\t\t\t\trow = term.Location.Row\n\t\t\t} else if i > 0 {\n\t\t\t\tw.write(\" \")\n\t\t\t}\n\n\t\t\tcomments = w.writeTerm(term, comments)\n\n\t\t\tif i < len(decl.Symbols)-1 {\n\t\t\t\tw.write(\",\")\n\t\t\t}\n\t\tcase ast.Call:\n\t\t\tcomments = w.writeInOperator(false, val[1:], comments)\n\t\t}\n\t}\n\n\treturn comments\n}\n\nfunc (w *writer) writeEvery(every *ast.Every, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, every.Location)\n\tw.write(\"every \")\n\tif every.Key != nil {\n\t\tcomments = w.writeTerm(every.Key, comments)\n\t\tw.write(\", \")\n\t}\n\tcomments = w.writeTerm(every.Value, comments)\n\tw.write(\" in \")\n\tcomments = w.writeTerm(every.Domain, comments)\n\tw.write(\" {\")\n\tcomments = w.writeComprehensionBody('{', '}', every.Body, every.Loc(), every.Loc(), comments)\n\n\tif len(every.Body) == 1 &&\n\t\tevery.Body[0].Location.Row == every.Location.Row {\n\t\tw.write(\" \")\n\t}\n\tw.write(\"}\")\n\treturn comments\n}\n\nfunc (w *writer) writeFunctionCall(expr *ast.Expr, comments []*ast.Comment) []*ast.Comment {\n\n\tterms := expr.Terms.([]*ast.Term)\n\toperator := terms[0].Value.String()\n\n\tswitch operator {\n\tcase ast.Member.Name, ast.MemberWithKey.Name:\n\t\treturn w.writeInOperator(false, terms[1:], comments)\n\t}\n\n\tbi, ok := ast.BuiltinMap[operator]\n\tif !ok || bi.Infix == \"\" {\n\t\treturn w.writeFunctionCallPlain(terms, comments)\n\t}\n\n\tnumDeclArgs := len(bi.Decl.Args())\n\tnumCallArgs := len(terms) - 1\n\n\tswitch numCallArgs {\n\tcase numDeclArgs: // Print infix where result is unassigned (e.g., x != y)\n\t\tcomments = w.writeTerm(terms[1], comments)\n\t\tw.write(\" \" + bi.Infix + \" \")\n\t\treturn w.writeTerm(terms[2], comments)\n\n\tcase numDeclArgs + 1: // Print infix where result is assigned (e.g., z = x + y)\n\t\tcomments = w.writeTerm(terms[3], comments)\n\t\tw.write(\" \" + ast.Equality.Infix + \" \")\n\t\tcomments = w.writeTerm(terms[1], comments)\n\t\tw.write(\" \" + bi.Infix + \" \")\n\t\tcomments = w.writeTerm(terms[2], comments)\n\t\treturn comments\n\t}\n\treturn w.writeFunctionCallPlain(terms, comments)\n}\n\nfunc (w *writer) writeFunctionCallPlain(terms []*ast.Term, comments []*ast.Comment) []*ast.Comment {\n\tw.write(terms[0].String() + \"(\")\n\tdefer w.write(\")\")\n\targs := make([]interface{}, len(terms)-1)\n\tfor i, t := range terms[1:] {\n\t\targs[i] = t\n\t}\n\tloc := terms[0].Location\n\treturn w.writeIterable(args, loc, closingLoc(0, 0, '(', ')', loc), comments, w.listWriter())\n}\n\nfunc (w *writer) writeWith(with *ast.With, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, with.Location)\n\tw.write(\" with \")\n\tcomments = w.writeTerm(with.Target, comments)\n\tw.write(\" as \")\n\treturn w.writeTerm(with.Value, comments)\n}\n\nfunc (w *writer) writeTerm(term *ast.Term, comments []*ast.Comment) []*ast.Comment {\n\treturn w.writeTermParens(false, term, comments)\n}\n\nfunc (w *writer) writeTermParens(parens bool, term *ast.Term, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, term.Location)\n\tif !w.inline {\n\t\tw.startLine()\n\t}\n\n\tswitch x := term.Value.(type) {\n\tcase ast.Ref:\n\t\tw.writeRef(x)\n\tcase ast.Object:\n\t\tcomments = w.writeObject(x, term.Location, comments)\n\tcase *ast.Array:\n\t\tcomments = w.writeArray(x, term.Location, comments)\n\tcase ast.Set:\n\t\tcomments = w.writeSet(x, term.Location, comments)\n\tcase *ast.ArrayComprehension:\n\t\tcomments = w.writeArrayComprehension(x, term.Location, comments)\n\tcase *ast.ObjectComprehension:\n\t\tcomments = w.writeObjectComprehension(x, term.Location, comments)\n\tcase *ast.SetComprehension:\n\t\tcomments = w.writeSetComprehension(x, term.Location, comments)\n\tcase ast.String:\n\t\tif term.Location.Text[0] == '`' {\n\t\t\t// To preserve raw strings, we need to output the original text,\n\t\t\t// not what x.String() would give us.\n\t\t\tw.write(string(term.Location.Text))\n\t\t} else {\n\t\t\tw.write(x.String())\n\t\t}\n\tcase ast.Var:\n\t\tw.write(w.formatVar(x))\n\tcase ast.Call:\n\t\tcomments = w.writeCall(parens, x, comments)\n\tcase fmt.Stringer:\n\t\tw.write(x.String())\n\t}\n\n\tif !w.inline {\n\t\tw.startLine()\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeRef(x ast.Ref) {\n\tif len(x) > 0 {\n\t\tw.writeTerm(x[0], nil)\n\t\tpath := x[1:]\n\t\tfor _, t := range path {\n\t\t\tswitch p := t.Value.(type) {\n\t\t\tcase ast.String:\n\t\t\t\tw.writeRefStringPath(p)\n\t\t\tcase ast.Var:\n\t\t\t\tw.writeBracketed(w.formatVar(p))\n\t\t\tdefault:\n\t\t\t\tw.write(\"[\")\n\t\t\t\tw.writeTerm(t, nil)\n\t\t\t\tw.write(\"]\")\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (w *writer) writeBracketed(str string) {\n\tw.write(\"[\" + str + \"]\")\n}\n\nvar varRegexp = regexp.MustCompile(\"^[[:alpha:]_][[:alpha:][:digit:]_]*$\")\n\nfunc (w *writer) writeRefStringPath(s ast.String) {\n\tstr := string(s)\n\tif varRegexp.MatchString(str) && !ast.IsKeyword(str) {\n\t\tw.write(\".\" + str)\n\t} else {\n\t\tw.writeBracketed(s.String())\n\t}\n}\n\nfunc (w *writer) formatVar(v ast.Var) string {\n\tif v.IsWildcard() {\n\t\treturn ast.Wildcard.String()\n\t}\n\treturn v.String()\n}\n\nfunc (w *writer) writeCall(parens bool, x ast.Call, comments []*ast.Comment) []*ast.Comment {\n\tbi, ok := ast.BuiltinMap[x[0].String()]\n\tif !ok || bi.Infix == \"\" {\n\t\treturn w.writeFunctionCallPlain(x, comments)\n\t}\n\n\tif bi.Infix == \"in\" {\n\t\t// NOTE(sr): `in` requires special handling, mirroring what happens in the parser,\n\t\t// since there can be one or two lhs arguments.\n\t\treturn w.writeInOperator(true, x[1:], comments)\n\t}\n\n\t// TODO(tsandall): improve to consider precedence?\n\tif parens {\n\t\tw.write(\"(\")\n\t}\n\tcomments = w.writeTermParens(true, x[1], comments)\n\tw.write(\" \" + bi.Infix + \" \")\n\tcomments = w.writeTermParens(true, x[2], comments)\n\tif parens {\n\t\tw.write(\")\")\n\t}\n\n\treturn comments\n}\n\nfunc (w *writer) writeInOperator(parens bool, operands []*ast.Term, comments []*ast.Comment) []*ast.Comment {\n\tkw := \"in\"\n\tswitch len(operands) {\n\tcase 2:\n\t\tcomments = w.writeTermParens(true, operands[0], comments)\n\t\tw.write(\" \")\n\t\tw.write(kw)\n\t\tw.write(\" \")\n\t\tcomments = w.writeTermParens(true, operands[1], comments)\n\tcase 3:\n\t\tif parens {\n\t\t\tw.write(\"(\")\n\t\t\tdefer w.write(\")\")\n\t\t}\n\t\tcomments = w.writeTermParens(true, operands[0], comments)\n\t\tw.write(\", \")\n\t\tcomments = w.writeTermParens(true, operands[1], comments)\n\t\tw.write(\" \")\n\t\tw.write(kw)\n\t\tw.write(\" \")\n\t\tcomments = w.writeTermParens(true, operands[2], comments)\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeObject(obj ast.Object, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"{\")\n\tdefer w.write(\"}\")\n\n\tvar s []interface{}\n\tobj.Foreach(func(k, v *ast.Term) {\n\t\ts = append(s, ast.Item(k, v))\n\t})\n\treturn w.writeIterable(s, loc, closingLoc(0, 0, '{', '}', loc), comments, w.objectWriter())\n}\n\nfunc (w *writer) writeArray(arr *ast.Array, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"[\")\n\tdefer w.write(\"]\")\n\n\tvar s []interface{}\n\tarr.Foreach(func(t *ast.Term) {\n\t\ts = append(s, t)\n\t})\n\treturn w.writeIterable(s, loc, closingLoc(0, 0, '[', ']', loc), comments, w.listWriter())\n}\n\nfunc (w *writer) writeSet(set ast.Set, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\n\tif set.Len() == 0 {\n\t\tw.write(\"set()\")\n\t\treturn w.insertComments(comments, closingLoc(0, 0, '(', ')', loc))\n\t}\n\n\tw.write(\"{\")\n\tdefer w.write(\"}\")\n\n\tvar s []interface{}\n\tset.Foreach(func(t *ast.Term) {\n\t\ts = append(s, t)\n\t})\n\treturn w.writeIterable(s, loc, closingLoc(0, 0, '{', '}', loc), comments, w.listWriter())\n}\n\nfunc (w *writer) writeArrayComprehension(arr *ast.ArrayComprehension, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"[\")\n\tdefer w.write(\"]\")\n\n\treturn w.writeComprehension('[', ']', arr.Term, arr.Body, loc, comments)\n}\n\nfunc (w *writer) writeSetComprehension(set *ast.SetComprehension, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"{\")\n\tdefer w.write(\"}\")\n\n\treturn w.writeComprehension('{', '}', set.Term, set.Body, loc, comments)\n}\n\nfunc (w *writer) writeObjectComprehension(object *ast.ObjectComprehension, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"{\")\n\tdefer w.write(\"}\")\n\n\tobject.Value.Location = object.Key.Location // Ensure the value is not written on the next line.\n\tif object.Key.Location.Row-loc.Row > 1 {\n\t\tw.endLine()\n\t\tw.startLine()\n\t}\n\n\tcomments = w.writeTerm(object.Key, comments)\n\tw.write(\": \")\n\treturn w.writeComprehension('{', '}', object.Value, object.Body, loc, comments)\n}\n\nfunc (w *writer) writeComprehension(open, close byte, term *ast.Term, body ast.Body, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tif term.Location.Row-loc.Row > 1 {\n\t\tw.endLine()\n\t\tw.startLine()\n\t}\n\n\tcomments = w.writeTerm(term, comments)\n\tw.write(\" |\")\n\n\treturn w.writeComprehensionBody(open, close, body, term.Location, loc, comments)\n}\n\nfunc (w *writer) writeComprehensionBody(open, close byte, body ast.Body, term, compr *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tvar exprs []interface{}\n\tfor _, expr := range body {\n\t\texprs = append(exprs, expr)\n\t}\n\tlines := groupIterable(exprs, term)\n\n\tif body.Loc().Row-term.Row > 0 || len(lines) > 1 {\n\t\tw.endLine()\n\t\tw.up()\n\t\tdefer w.startLine()\n\t\tdefer w.down()\n\n\t\tcomments = w.writeBody(body, comments)\n\t} else {\n\t\tw.write(\" \")\n\t\ti := 0\n\t\tfor ; i < len(body)-1; i++ {\n\t\t\tcomments = w.writeExpr(body[i], comments)\n\t\t\tw.write(\"; \")\n\t\t}\n\t\tcomments = w.writeExpr(body[i], comments)\n\t}\n\n\treturn w.insertComments(comments, closingLoc(0, 0, open, close, compr))\n}\n\nfunc (w *writer) writeImports(imports []*ast.Import, comments []*ast.Comment) []*ast.Comment {\n\tm, comments := mapImportsToComments(imports, comments)\n\n\tgroups := groupImports(imports)\n\tfor _, group := range groups {\n\t\tcomments = w.insertComments(comments, group[0].Loc())\n\n\t\t// Sort imports within a newline grouping.\n\t\tsort.Slice(group, func(i, j int) bool {\n\t\t\ta := group[i]\n\t\t\tb := group[j]\n\t\t\treturn a.Compare(b) < 0\n\t\t})\n\t\tfor _, i := range group {\n\t\t\tw.startLine()\n\t\t\tw.write(i.String())\n\t\t\tif c, ok := m[i]; ok {\n\t\t\t\tw.write(\" \" + c.String())\n\t\t\t}\n\t\t\tw.endLine()\n\t\t}\n\t\tw.blankLine()\n\t}\n\n\treturn comments\n}\n\ntype entryWriter func(interface{}, []*ast.Comment) []*ast.Comment\n\nfunc (w *writer) writeIterable(elements []interface{}, last *ast.Location, close *ast.Location, comments []*ast.Comment, fn entryWriter) []*ast.Comment {\n\tlines := groupIterable(elements, last)\n\tif len(lines) > 1 {\n\t\tw.delayBeforeEnd()\n\t\tw.startMultilineSeq()\n\t}\n\n\ti := 0\n\tfor ; i < len(lines)-1; i++ {\n\t\tcomments = w.writeIterableLine(lines[i], comments, fn)\n\t\tw.write(\",\")\n\n\t\tw.endLine()\n\t\tw.startLine()\n\t}\n\n\tcomments = w.writeIterableLine(lines[i], comments, fn)\n\n\tif len(lines) > 1 {\n\t\tw.write(\",\")\n\t\tw.endLine()\n\t\tcomments = w.insertComments(comments, close)\n\t\tw.down()\n\t\tw.startLine()\n\t}\n\n\treturn comments\n}\n\nfunc (w *writer) writeIterableLine(elements []interface{}, comments []*ast.Comment, fn entryWriter) []*ast.Comment {\n\tif len(elements) == 0 {\n\t\treturn comments\n\t}\n\n\ti := 0\n\tfor ; i < len(elements)-1; i++ {\n\t\tcomments = fn(elements[i], comments)\n\t\tw.write(\", \")\n\t}\n\n\treturn fn(elements[i], comments)\n}\n\nfunc (w *writer) objectWriter() entryWriter {\n\treturn func(x interface{}, comments []*ast.Comment) []*ast.Comment {\n\t\tentry := x.([2]*ast.Term)\n\t\tcomments = w.writeTerm(entry[0], comments)\n\t\tw.write(\": \")\n\t\treturn w.writeTerm(entry[1], comments)\n\t}\n}\n\nfunc (w *writer) listWriter() entryWriter {\n\treturn func(x interface{}, comments []*ast.Comment) []*ast.Comment {\n\t\treturn w.writeTerm(x.(*ast.Term), comments)\n\t}\n}\n\n// groupIterable will group the `elements` slice into slices according to their\n// location: anything on the same line will be put into a slice.\nfunc groupIterable(elements []interface{}, last *ast.Location) [][]interface{} {\n\t// Generated vars occur in the AST when we're rendering the result of\n\t// partial evaluation in a bundle build with optimization. For those vars,\n\t// there is no location, and the grouping based on source location will\n\t// yield a bad result. So if there's a generated variable among elements,\n\t// we'll render the elements all in one line.\n\tvis := ast.NewVarVisitor()\n\tfor _, elem := range elements {\n\t\tvis.Walk(elem)\n\t}\n\tfor v := range vis.Vars() {\n\t\tif v.IsGenerated() {\n\t\t\treturn [][]interface{}{elements}\n\t\t}\n\t}\n\tsort.Slice(elements, func(i, j int) bool {\n\t\treturn locLess(elements[i], elements[j])\n\t})\n\tvar lines [][]interface{}\n\tvar cur []interface{}\n\tfor i, t := range elements {\n\t\telem := t\n\t\tloc := getLoc(elem)\n\t\tlineDiff := loc.Row - last.Row\n\t\tif lineDiff > 0 && i > 0 {\n\t\t\tlines = append(lines, cur)\n\t\t\tcur = nil\n\t\t}\n\n\t\tlast = loc\n\t\tcur = append(cur, elem)\n\t}\n\treturn append(lines, cur)\n}\n\nfunc mapImportsToComments(imports []*ast.Import, comments []*ast.Comment) (map[*ast.Import]*ast.Comment, []*ast.Comment) {\n\tvar leftovers []*ast.Comment\n\tm := map[*ast.Import]*ast.Comment{}\n\n\tfor _, c := range comments {\n\t\tmatched := false\n\t\tfor _, i := range imports {\n\t\t\tif c.Loc().Row == i.Loc().Row {\n\t\t\t\tm[i] = c\n\t\t\t\tmatched = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !matched {\n\t\t\tleftovers = append(leftovers, c)\n\t\t}\n\t}\n\n\treturn m, leftovers\n}\n\nfunc groupImports(imports []*ast.Import) [][]*ast.Import {\n\tswitch len(imports) { // shortcuts\n\tcase 0:\n\t\treturn nil\n\tcase 1:\n\t\treturn [][]*ast.Import{imports}\n\t}\n\t// there are >=2 imports to group\n\n\tvar groups [][]*ast.Import\n\tgroup := []*ast.Import{imports[0]}\n\n\tfor _, i := range imports[1:] {\n\t\tlast := group[len(group)-1]\n\n\t\t// nil-location imports have been sorted up to come first\n\t\tif i.Loc() != nil && last.Loc() != nil && // first import with a location, or\n\t\t\ti.Loc().Row-last.Loc().Row > 1 { // more than one row apart from previous import\n\n\t\t\t// start a new group\n\t\t\tgroups = append(groups, group)\n\t\t\tgroup = []*ast.Import{}\n\t\t}\n\t\tgroup = append(group, i)\n\t}\n\tif len(group) > 0 {\n\t\tgroups = append(groups, group)\n\t}\n\n\treturn groups\n}\n\nfunc partitionComments(comments []*ast.Comment, l *ast.Location) (before []*ast.Comment, at *ast.Comment, after []*ast.Comment) {\n\tfor _, c := range comments {\n\t\tswitch cmp := c.Location.Row - l.Row; {\n\t\tcase cmp < 0:\n\t\t\tbefore = append(before, c)\n\t\tcase cmp > 0:\n\t\t\tafter = append(after, c)\n\t\tcase cmp == 0:\n\t\t\tat = c\n\t\t}\n\t}\n\n\treturn before, at, after\n}\n\nfunc gatherImports(others []interface{}) (imports []*ast.Import, rest []interface{}) {\n\ti := 0\nloop:\n\tfor ; i < len(others); i++ {\n\t\tswitch x := others[i].(type) {\n\t\tcase *ast.Import:\n\t\t\timports = append(imports, x)\n\t\tcase *ast.Rule:\n\t\t\tbreak loop\n\t\t}\n\t}\n\treturn imports, others[i:]\n}\n\nfunc gatherRules(others []interface{}) (rules []*ast.Rule, rest []interface{}) {\n\ti := 0\nloop:\n\tfor ; i < len(others); i++ {\n\t\tswitch x := others[i].(type) {\n\t\tcase *ast.Rule:\n\t\t\trules = append(rules, x)\n\t\tcase *ast.Import:\n\t\t\tbreak loop\n\t\t}\n\t}\n\treturn rules, others[i:]\n}\n\nfunc locLess(a, b interface{}) bool {\n\treturn locCmp(a, b) < 0\n}\n\nfunc locCmp(a, b interface{}) int {\n\tal := getLoc(a)\n\tbl := getLoc(b)\n\tswitch {\n\tcase al == nil && bl == nil:\n\t\treturn 0\n\tcase al == nil:\n\t\treturn -1\n\tcase bl == nil:\n\t\treturn 1\n\t}\n\n\tif cmp := al.Row - bl.Row; cmp != 0 {\n\t\treturn cmp\n\n\t}\n\treturn al.Col - bl.Col\n}\n\nfunc getLoc(x interface{}) *ast.Location {\n\tswitch x := x.(type) {\n\tcase ast.Node: // *ast.Head, *ast.Expr, *ast.With, *ast.Term\n\t\treturn x.Loc()\n\tcase *ast.Location:\n\t\treturn x\n\tcase [2]*ast.Term: // Special case to allow for easy printing of objects.\n\t\treturn x[0].Location\n\tdefault:\n\t\tpanic(\"Not reached\")\n\t}\n}\n\nfunc closingLoc(skipOpen, skipClose, open, close byte, loc *ast.Location) *ast.Location {\n\ti, offset := 0, 0\n\n\t// Skip past parens/brackets/braces in rule heads.\n\tif skipOpen > 0 {\n\t\ti, offset = skipPast(skipOpen, skipClose, loc)\n\t}\n\n\tfor ; i < len(loc.Text) && loc.Text[i] != open; i++ {\n\t}\n\n\tif i >= len(loc.Text) {\n\t\treturn &ast.Location{Row: -1}\n\t}\n\n\tstate := 1\n\tfor state > 0 {\n\t\ti++\n\t\tif i >= len(loc.Text) {\n\t\t\treturn &ast.Location{Row: -1}\n\t\t}\n\n\t\tswitch loc.Text[i] {\n\t\tcase open:\n\t\t\tstate++\n\t\tcase close:\n\t\t\tstate--\n\t\tcase '\\n':\n\t\t\toffset++\n\t\t}\n\t}\n\n\treturn &ast.Location{Row: loc.Row + offset}\n}\n\nfunc skipPast(open, close byte, loc *ast.Location) (int, int) {\n\ti := 0\n\tfor ; i < len(loc.Text) && loc.Text[i] != open; i++ {\n\t}\n\n\tstate := 1\n\toffset := 0\n\tfor state > 0 {\n\t\ti++\n\t\tif i >= len(loc.Text) {\n\t\t\treturn i, offset\n\t\t}\n\n\t\tswitch loc.Text[i] {\n\t\tcase open:\n\t\t\tstate++\n\t\tcase close:\n\t\t\tstate--\n\t\tcase '\\n':\n\t\t\toffset++\n\t\t}\n\t}\n\n\treturn i, offset\n}\n\nfunc dedupComments(comments []*ast.Comment) []*ast.Comment {\n\tif len(comments) == 0 {\n\t\treturn nil\n\t}\n\n\tfiltered := []*ast.Comment{comments[0]}\n\tfor i := 1; i < len(comments); i++ {\n\t\tif comments[i].Location.Equal(comments[i-1].Location) {\n\t\t\tcontinue\n\t\t}\n\t\tfiltered = append(filtered, comments[i])\n\t}\n\treturn filtered\n}\n\n// startLine begins a line with the current indentation level.\nfunc (w *writer) startLine() {\n\tw.inline = true\n\tfor i := 0; i < w.level; i++ {\n\t\tw.write(w.indent)\n\t}\n}\n\n// endLine ends a line with a newline.\nfunc (w *writer) endLine() {\n\tw.inline = false\n\tif w.beforeEnd != nil && !w.delay {\n\t\tw.write(\" \" + w.beforeEnd.String())\n\t\tw.beforeEnd = nil\n\t}\n\tw.delay = false\n\tw.write(\"\\n\")\n}\n\n// beforeLineEnd registers a comment to be printed at the end of the current line.\nfunc (w *writer) beforeLineEnd(c *ast.Comment) {\n\tif w.beforeEnd != nil {\n\t\tif c == nil {\n\t\t\treturn\n\t\t}\n\t\tpanic(\"overwriting non-nil beforeEnd\")\n\t}\n\tw.beforeEnd = c\n}\n\nfunc (w *writer) delayBeforeEnd() {\n\tw.delay = true\n}\n\n// line prints a blank line. If the writer is currently in the middle of a line,\n// line ends it and then prints a blank one.\nfunc (w *writer) blankLine() {\n\tif w.inline {\n\t\tw.endLine()\n\t}\n\tw.write(\"\\n\")\n}\n\n// write the input string and writes it to the buffer.\nfunc (w *writer) write(s string) {\n\tw.buf.WriteString(s)\n}\n\n// writeLine writes the string on a newly started line, then terminate the line.\nfunc (w *writer) writeLine(s string) {\n\tif !w.inline {\n\t\tw.startLine()\n\t}\n\tw.write(s)\n\tw.endLine()\n}\n\nfunc (w *writer) startMultilineSeq() {\n\tw.endLine()\n\tw.up()\n\tw.startLine()\n}\n\n// up increases the indentation level\nfunc (w *writer) up() {\n\tw.level++\n}\n\n// down decreases the indentation level\nfunc (w *writer) down() {\n\tif w.level == 0 {\n\t\tpanic(\"negative indentation level\")\n\t}\n\tw.level--\n}\n\nfunc ensureFutureKeywordImport(imps []*ast.Import, kw string) []*ast.Import {\n\tallKeywords := ast.MustParseTerm(\"future.keywords\")\n\tkwPath := ast.MustParseTerm(\"future.keywords.\" + kw)\n\tfor _, imp := range imps {\n\t\tif allKeywords.Equal(imp.Path) || imp.Path.Equal(kwPath) {\n\t\t\treturn imps\n\t\t}\n\t}\n\treturn append(imps, &ast.Import{Path: kwPath})\n}\n", "// Copyright 2017 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\npackage format\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/open-policy-agent/opa/ast\"\n\t\"github.com/open-policy-agent/opa/ast/location\"\n)\n\nfunc TestFormatNilLocation(t *testing.T) {\n\trule := ast.MustParseRule(`r = y { y = \"foo\" }`)\n\trule.Head.Location = nil\n\n\tbs, err := Ast(rule)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := strings.Trim(`\nr = y {\n\ty = \"foo\"\n}`, \" \\n\")\n\n\tif string(bs) != exp {\n\t\tt.Fatalf(\"Expected %q but got %q\", exp, string(bs))\n\t}\n}\n\nfunc TestFormatNilLocationEmptyBody(t *testing.T) {\n\tb := ast.NewBody()\n\tx, err := Ast(b)\n\tif len(x) != 0 || err != nil {\n\t\tt.Fatalf(\"Expected empty result but got: %q, err: %v\", string(x), err)\n\t}\n}\n\nfunc TestFormatNilLocationFunctionArgs(t *testing.T) {\n\tb := ast.NewBody()\n\ts := ast.StringTerm(\" \")\n\ts.SetLocation(location.NewLocation([]byte(\"foo\"), \"p.rego\", 2, 2))\n\tb.Append(ast.Split.Expr(ast.NewTerm(ast.Var(\"__local1__\")), s, ast.NewTerm(ast.Var(\"__local2__\"))))\n\texp := \"split(__local1__, \\\" \\\", __local2__)\\n\"\n\tbs, err := Ast(b)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif string(bs) != exp {\n\t\tt.Fatalf(\"Expected %q but got %q\", exp, string(bs))\n\t}\n}\n\nfunc TestFormatSourceError(t *testing.T) {\n\trego := \"testfiles/test.rego.error\"\n\tcontents, err := ioutil.ReadFile(rego)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to read rego source: %v\", err)\n\t}\n\n\t_, err = Source(rego, contents)\n\tif err == nil {\n\t\tt.Fatal(\"Expected parsing error, not nil\")\n\t}\n\n\texp := \"1 error occurred: testfiles/test.rego.error:27: rego_parse_error: unexpected eof token\"\n\n\tif !strings.HasPrefix(err.Error(), exp) {\n\t\tt.Fatalf(\"Expected error message '%s', got '%s'\", exp, err.Error())\n\t}\n}\n\nfunc TestFormatSource(t *testing.T) {\n\tregoFiles, err := filepath.Glob(\"testfiles/*.rego\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tfor _, rego := range regoFiles {\n\t\tt.Run(rego, func(t *testing.T) {\n\t\t\tcontents, err := ioutil.ReadFile(rego)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to read rego source: %v\", err)\n\t\t\t}\n\t\t\tif bytes.Contains(contents, []byte(`import future.keywords.every`)) {\n\t\t\t\tt.Skip(\"TODO: uncomment 'every' tests\")\n\t\t\t}\n\n\t\t\texpected, err := ioutil.ReadFile(rego + \".formatted\")\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to read expected rego source: %v\", err)\n\t\t\t}\n\n\t\t\tformatted, err := Source(rego, contents)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to format file: %v\", err)\n\t\t\t}\n\n\t\t\tif ln, at := differsAt(formatted, expected); ln != 0 {\n\t\t\t\tt.Fatalf(\"Expected formatted bytes to equal expected bytes but differed near line %d / byte %d (got: %q, expected: %q):\\n%s\", ln, at, formatted[at], expected[at], prefixWithLineNumbers(formatted))\n\t\t\t}\n\n\t\t\tif _, err := ast.ParseModule(rego+\".tmp\", string(formatted)); err != nil {\n\t\t\t\tt.Fatalf(\"Failed to parse formatted bytes: %v\", err)\n\t\t\t}\n\n\t\t\tformatted, err = Source(rego, formatted)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to double format file\")\n\t\t\t}\n\n\t\t\tif ln, at := differsAt(formatted, expected); ln != 0 {\n\t\t\t\tt.Fatalf(\"Expected roundtripped bytes to equal expected bytes but differed near line %d / byte %d:\\n%s\", ln, at, prefixWithLineNumbers(formatted))\n\t\t\t}\n\n\t\t})\n\t}\n}\n\nfunc TestFormatAST(t *testing.T) {\n\tcases := []struct {\n\t\tnote     string\n\t\ttoFmt    interface{}\n\t\texpected string\n\t}{\n\t\t{\n\t\t\tnote:     \"var\",\n\t\t\ttoFmt:    ast.Var(`foo`),\n\t\t\texpected: \"foo\",\n\t\t},\n\t\t{\n\t\t\tnote: \"string\",\n\t\t\ttoFmt: &ast.Term{\n\t\t\t\tValue:    ast.String(\"foo\"),\n\t\t\t\tLocation: &ast.Location{Text: []byte(`\"foo\"`)},\n\t\t\t},\n\t\t\texpected: `\"foo\"`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"var wildcard\",\n\t\t\ttoFmt:    ast.Var(`$12`),\n\t\t\texpected: \"_\",\n\t\t},\n\t\t{\n\t\t\tnote: \"string with wildcard prefix\",\n\t\t\ttoFmt: &ast.Term{\n\t\t\t\tValue:    ast.String(\"$01\"),\n\t\t\t\tLocation: &ast.Location{Text: []byte(`\"$01\"`)},\n\t\t\t},\n\t\t\texpected: `\"$01\"`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref var only\",\n\t\t\ttoFmt:    ast.MustParseRef(`data.foo`),\n\t\t\texpected: \"data.foo\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref multi vars\",\n\t\t\ttoFmt:    ast.MustParseRef(`data.foo.bar.baz`),\n\t\t\texpected: \"data.foo.bar.baz\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref with string\",\n\t\t\ttoFmt:    ast.MustParseRef(`data[\"foo\"]`),\n\t\t\texpected: `data.foo`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref multi string\",\n\t\t\ttoFmt:    ast.MustParseRef(`data[\"foo\"][\"bar\"][\"baz\"]`),\n\t\t\texpected: `data.foo.bar.baz`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref with string needs brackets\",\n\t\t\ttoFmt:    ast.MustParseRef(`data[\"foo my-var\\nbar\"]`),\n\t\t\texpected: `data[\"foo my-var\\nbar\"]`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref multi string needs brackets\",\n\t\t\ttoFmt:    ast.MustParseRef(`data[\"foo my-var\"][\"bar\"][\"almost.baz\"]`),\n\t\t\texpected: `data[\"foo my-var\"].bar[\"almost.baz\"]`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref var wildcard\",\n\t\t\ttoFmt:    ast.MustParseRef(`data.foo[_]`),\n\t\t\texpected: \"data.foo[_]\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref var wildcard\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[_]`),\n\t\t\texpected: \"foo[_]\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref string with wildcard prefix\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[\"$01\"]`),\n\t\t\texpected: `foo[\"$01\"]`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"nested ref var wildcard\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[bar[baz[_]]]`),\n\t\t\texpected: \"foo[bar[baz[_]]]\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref mixed\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[\"bar\"].baz[_][\"bar-2\"].qux`),\n\t\t\texpected: `foo.bar.baz[_][\"bar-2\"].qux`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref empty\",\n\t\t\ttoFmt:    ast.Ref{},\n\t\t\texpected: ``,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref nil\",\n\t\t\ttoFmt:    ast.Ref(nil),\n\t\t\texpected: ``,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref operator\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[count(foo) - 1]`),\n\t\t\texpected: `foo[count(foo) - 1]`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"x in xs\",\n\t\t\ttoFmt:    ast.Member.Call(ast.VarTerm(\"x\"), ast.VarTerm(\"xs\")),\n\t\t\texpected: `x in xs`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"x, y in xs\",\n\t\t\ttoFmt:    ast.MemberWithKey.Call(ast.VarTerm(\"x\"), ast.VarTerm(\"y\"), ast.VarTerm(\"xs\")),\n\t\t\texpected: `(x, y in xs)`,\n\t\t},\n\t\t{\n\t\t\tnote: \"some x in xs\",\n\t\t\ttoFmt: ast.NewExpr(&ast.SomeDecl{Symbols: []*ast.Term{\n\t\t\t\tast.Member.Call(ast.VarTerm(\"x\"), ast.VarTerm(\"xs\")),\n\t\t\t}}),\n\t\t\texpected: `some x in xs`,\n\t\t},\n\t\t{\n\t\t\tnote: \"some x, y in xs\",\n\t\t\ttoFmt: ast.NewExpr(&ast.SomeDecl{Symbols: []*ast.Term{\n\t\t\t\tast.MemberWithKey.Call(ast.VarTerm(\"x\"), ast.VarTerm(\"y\"), ast.VarTerm(\"xs\")),\n\t\t\t}}),\n\t\t\texpected: `some x, y in xs`,\n\t\t},\n\t\t{\n\t\t\tnote: \"body shared wildcard\",\n\t\t\ttoFmt: ast.Body{\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tTerms: []*ast.Term{\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"eq\")),\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"input\"), ast.StringTerm(\"arr\"), ast.VarTerm(\"$01\"), ast.StringTerm(\"some key\"), ast.VarTerm(\"$02\")),\n\t\t\t\t\t\tast.VarTerm(\"bar\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tLocation: &ast.Location{\n\t\t\t\t\t\tRow: 2,\n\t\t\t\t\t\tCol: 1,\n\t\t\t\t\t},\n\t\t\t\t\tTerms: []*ast.Term{\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"eq\")),\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"input\"), ast.StringTerm(\"arr\"), ast.VarTerm(\"$01\"), ast.StringTerm(\"bar\")),\n\t\t\t\t\t\tast.VarTerm(\"qux\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tLocation: &ast.Location{\n\t\t\t\t\t\tRow: 2,\n\t\t\t\t\t\tCol: 1,\n\t\t\t\t\t},\n\t\t\t\t\tTerms: []*ast.Term{\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"eq\")),\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"foo\"), ast.VarTerm(\"$03\"), ast.VarTerm(\"$01\"), ast.StringTerm(\"bar\")),\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"bar\"), ast.VarTerm(\"$03\"), ast.VarTerm(\"$04\"), ast.VarTerm(\"$01\"), ast.StringTerm(\"bar\")),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: `input.arr[_01][\"some key\"][_] = bar\ninput.arr[_01].bar = qux\nfoo[_03][_01].bar = bar[_03][_][_01].bar\n`,\n\t\t},\n\t\t{\n\t\t\tnote: \"body shared wildcard - ref head\",\n\t\t\ttoFmt: ast.Body{\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tTerms: ast.VarTerm(\"$x\"),\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tTerms: ast.RefTerm(ast.VarTerm(\"$x\"), ast.VarTerm(\"y\")),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: `_x\n_x[y]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"body shared wildcard - nested ref\",\n\t\t\ttoFmt: ast.Body{\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tTerms: ast.VarTerm(\"$x\"),\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tTerms: ast.RefTerm(ast.VarTerm(\"a\"), ast.RefTerm(ast.VarTerm(\"$x\"), ast.VarTerm(\"y\"))),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: `_x\na[_x[y]]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"body shared wildcard - nested ref array\",\n\t\t\ttoFmt: ast.Body{\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tTerms: ast.VarTerm(\"$x\"),\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tTerms: ast.RefTerm(ast.VarTerm(\"a\"), ast.RefTerm(ast.VarTerm(\"$x\"), ast.VarTerm(\"y\"), ast.ArrayTerm(ast.VarTerm(\"z\"), ast.VarTerm(\"w\")))),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: `_x\na[_x[y][[z, w]]]`,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tbs, err := Ast(tc.toFmt)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t\t}\n\t\t\texpected := strings.TrimSpace(tc.expected)\n\t\t\tactual := strings.TrimSpace(string(bs))\n\t\t\tif actual != expected {\n\t\t\t\tt.Fatalf(\"Expected:\\n\\n%s\\n\\nGot:\\n\\n%s\\n\\n\", expected, actual)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestFormatDeepCopy(t *testing.T) {\n\n\toriginal := ast.Body{\n\t\t&ast.Expr{\n\t\t\tIndex: 0,\n\t\t\tTerms: ast.VarTerm(\"$x\"),\n\t\t},\n\t\t&ast.Expr{\n\t\t\tIndex: 1,\n\t\t\tTerms: ast.RefTerm(ast.VarTerm(\"$x\"), ast.VarTerm(\"y\")),\n\t\t},\n\t}\n\n\tcpy := original.Copy()\n\n\t_, err := Ast(original)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif !cpy.Equal(original) {\n\t\tt.Fatal(\"expected original to be unmodified\")\n\t}\n\n}\n\nfunc differsAt(a, b []byte) (int, int) {\n\tif bytes.Equal(a, b) {\n\t\treturn 0, 0\n\t}\n\tminLen := len(a)\n\tif minLen > len(b) {\n\t\tminLen = len(b)\n\t}\n\tln := 1\n\tfor i := 0; i < minLen; i++ {\n\t\tif a[i] == '\\n' {\n\t\t\tln++\n\t\t}\n\t\tif a[i] != b[i] {\n\t\t\treturn ln, i\n\t\t}\n\t}\n\treturn ln, minLen - 1\n}\n\nfunc prefixWithLineNumbers(bs []byte) []byte {\n\traw := string(bs)\n\tlines := strings.Split(raw, \"\\n\")\n\tformat := fmt.Sprintf(\"%%%dd %%s\", len(fmt.Sprint(len(lines)+1)))\n\tfor i, line := range lines {\n\t\tlines[i] = fmt.Sprintf(format, i+1, line)\n\t}\n\treturn []byte(strings.Join(lines, \"\\n\"))\n}\n"], "fixing_code": ["// Copyright 2017 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\n// Package format implements formatting of Rego source files.\npackage format\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"sort\"\n\n\t\"github.com/open-policy-agent/opa/ast\"\n)\n\n// defaultLocationFile is the file name used in `Ast()` for terms\n// without a location, as could happen when pretty-printing the\n// results of partial eval.\nconst defaultLocationFile = \"__format_default__\"\n\n// Source formats a Rego source file. The bytes provided must describe a complete\n// Rego module. If they don't, Source will return an error resulting from the attempt\n// to parse the bytes.\nfunc Source(filename string, src []byte) ([]byte, error) {\n\tmodule, err := ast.ParseModule(filename, string(src))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tformatted, err := Ast(module)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"%s: %v\", filename, err)\n\t}\n\treturn formatted, nil\n}\n\n// MustAst is a helper function to format a Rego AST element. If any errors\n// occurs this function will panic. This is mostly used for test\nfunc MustAst(x interface{}) []byte {\n\tbs, err := Ast(x)\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\treturn bs\n}\n\n// Ast formats a Rego AST element. If the passed value is not a valid AST\n// element, Ast returns nil and an error. If AST nodes are missing locations\n// an arbitrary location will be used.\nfunc Ast(x interface{}) ([]byte, error) {\n\n\t// The node has to be deep copied because it may be mutated below. Alternatively,\n\t// we could avoid the copy by checking if mutation will occur first. For now,\n\t// since format is not latency sensitive, just deep copy in all cases.\n\tx = ast.Copy(x)\n\n\twildcards := map[ast.Var]*ast.Term{}\n\n\t// NOTE(sr): When the formatter encounters a call to internal.member_2\n\t// or internal.member_3, it will sugarize them into usage of the `in`\n\t// operator. It has to ensure that the proper future keyword import is\n\t// present.\n\textraFutureKeywordImports := map[string]bool{}\n\n\t// Preprocess the AST. Set any required defaults and calculate\n\t// values required for printing the formatted output.\n\tast.WalkNodes(x, func(x ast.Node) bool {\n\t\tswitch n := x.(type) {\n\t\tcase ast.Body:\n\t\t\tif len(n) == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\tcase *ast.Term:\n\t\t\tunmangleWildcardVar(wildcards, n)\n\n\t\tcase *ast.Expr:\n\t\t\tif n.IsCall() &&\n\t\t\t\tast.Member.Ref().Equal(n.Operator()) ||\n\t\t\t\tast.MemberWithKey.Ref().Equal(n.Operator()) {\n\t\t\t\textraFutureKeywordImports[\"in\"] = true\n\t\t\t}\n\t\t}\n\t\tif x.Loc() == nil {\n\t\t\tx.SetLoc(defaultLocation(x))\n\t\t}\n\t\treturn false\n\t})\n\n\tw := &writer{\n\t\tindent: \"\\t\",\n\t}\n\n\tswitch x := x.(type) {\n\tcase *ast.Module:\n\t\tfor kw := range extraFutureKeywordImports {\n\t\t\tx.Imports = ensureFutureKeywordImport(x.Imports, kw)\n\t\t}\n\t\tw.writeModule(x)\n\tcase *ast.Package:\n\t\tw.writePackage(x, nil)\n\tcase *ast.Import:\n\t\tw.writeImports([]*ast.Import{x}, nil)\n\tcase *ast.Rule:\n\t\tw.writeRule(x, false, nil)\n\tcase *ast.Head:\n\t\tw.writeHead(x, false, false, nil)\n\tcase ast.Body:\n\t\tw.writeBody(x, nil)\n\tcase *ast.Expr:\n\t\tw.writeExpr(x, nil)\n\tcase *ast.With:\n\t\tw.writeWith(x, nil)\n\tcase *ast.Term:\n\t\tw.writeTerm(x, nil)\n\tcase ast.Value:\n\t\tw.writeTerm(&ast.Term{Value: x, Location: &ast.Location{}}, nil)\n\tcase *ast.Comment:\n\t\tw.writeComments([]*ast.Comment{x})\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"not an ast element: %v\", x)\n\t}\n\n\treturn squashTrailingNewlines(w.buf.Bytes()), nil\n}\n\nfunc unmangleWildcardVar(wildcards map[ast.Var]*ast.Term, n *ast.Term) {\n\n\tv, ok := n.Value.(ast.Var)\n\tif !ok || !v.IsWildcard() {\n\t\treturn\n\t}\n\n\tfirst, ok := wildcards[v]\n\tif !ok {\n\t\twildcards[v] = n\n\t\treturn\n\t}\n\n\tw := v[len(ast.WildcardPrefix):]\n\n\t// Prepend an underscore to ensure the variable will parse.\n\tif len(w) == 0 || w[0] != '_' {\n\t\tw = \"_\" + w\n\t}\n\n\tif first != nil {\n\t\tfirst.Value = w\n\t\twildcards[v] = nil\n\t}\n\n\tn.Value = w\n}\n\nfunc squashTrailingNewlines(bs []byte) []byte {\n\tif bytes.HasSuffix(bs, []byte(\"\\n\")) {\n\t\treturn append(bytes.TrimRight(bs, \"\\n\"), '\\n')\n\t}\n\treturn bs\n}\n\nfunc defaultLocation(x ast.Node) *ast.Location {\n\treturn ast.NewLocation([]byte(x.String()), defaultLocationFile, 1, 1)\n}\n\ntype writer struct {\n\tbuf bytes.Buffer\n\n\tindent    string\n\tlevel     int\n\tinline    bool\n\tbeforeEnd *ast.Comment\n\tdelay     bool\n}\n\nfunc (w *writer) writeModule(module *ast.Module) {\n\tvar pkg *ast.Package\n\tvar others []interface{}\n\tvar comments []*ast.Comment\n\tvisitor := ast.NewGenericVisitor(func(x interface{}) bool {\n\t\tswitch x := x.(type) {\n\t\tcase *ast.Comment:\n\t\t\tcomments = append(comments, x)\n\t\t\treturn true\n\t\tcase *ast.Import, *ast.Rule:\n\t\t\tothers = append(others, x)\n\t\t\treturn true\n\t\tcase *ast.Package:\n\t\t\tpkg = x\n\t\t\treturn true\n\t\tdefault:\n\t\t\treturn false\n\t\t}\n\t})\n\tvisitor.Walk(module)\n\n\tsort.Slice(comments, func(i, j int) bool {\n\t\treturn locLess(comments[i], comments[j])\n\t})\n\n\t// XXX: The parser currently duplicates comments for some reason, so we need\n\t// to remove duplicates here.\n\tcomments = dedupComments(comments)\n\tsort.Slice(others, func(i, j int) bool {\n\t\treturn locLess(others[i], others[j])\n\t})\n\n\tcomments = w.writePackage(pkg, comments)\n\tvar imports []*ast.Import\n\tvar rules []*ast.Rule\n\tfor len(others) > 0 {\n\t\timports, others = gatherImports(others)\n\t\tcomments = w.writeImports(imports, comments)\n\t\trules, others = gatherRules(others)\n\t\tcomments = w.writeRules(rules, comments)\n\t}\n\n\tfor i, c := range comments {\n\t\tw.writeLine(c.String())\n\t\tif i == len(comments)-1 {\n\t\t\tw.write(\"\\n\")\n\t\t}\n\t}\n}\n\nfunc (w *writer) writePackage(pkg *ast.Package, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, pkg.Location)\n\n\tw.startLine()\n\tw.write(pkg.String())\n\tw.blankLine()\n\n\treturn comments\n}\n\nfunc (w *writer) writeComments(comments []*ast.Comment) {\n\tfor i := 0; i < len(comments); i++ {\n\t\tif i > 0 && locCmp(comments[i], comments[i-1]) > 1 {\n\t\t\tw.blankLine()\n\t\t}\n\t\tw.writeLine(comments[i].String())\n\t}\n}\n\nfunc (w *writer) writeRules(rules []*ast.Rule, comments []*ast.Comment) []*ast.Comment {\n\tfor _, rule := range rules {\n\t\tcomments = w.insertComments(comments, rule.Location)\n\t\tcomments = w.writeRule(rule, false, comments)\n\t\tw.blankLine()\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeRule(rule *ast.Rule, isElse bool, comments []*ast.Comment) []*ast.Comment {\n\tif rule == nil {\n\t\treturn comments\n\t}\n\n\tif !isElse {\n\t\tw.startLine()\n\t}\n\n\tif rule.Default {\n\t\tw.write(\"default \")\n\t}\n\n\t// OPA transforms lone bodies like `foo = {\"a\": \"b\"}` into rules of the form\n\t// `foo = {\"a\": \"b\"} { true }` in the AST. We want to preserve that notation\n\t// in the formatted code instead of expanding the bodies into rules, so we\n\t// pretend that the rule has no body in this case.\n\tisExpandedConst := rule.Body.Equal(ast.NewBody(ast.NewExpr(ast.BooleanTerm(true)))) && rule.Else == nil\n\n\tcomments = w.writeHead(rule.Head, rule.Default, isExpandedConst, comments)\n\n\tif (len(rule.Body) == 0 || isExpandedConst) && !isElse {\n\t\tw.endLine()\n\t\treturn comments\n\t}\n\n\tw.write(\" {\")\n\tw.endLine()\n\tw.up()\n\n\tcomments = w.writeBody(rule.Body, comments)\n\n\tvar closeLoc *ast.Location\n\n\tif len(rule.Head.Args) > 0 {\n\t\tcloseLoc = closingLoc('(', ')', '{', '}', rule.Location)\n\t} else {\n\t\tcloseLoc = closingLoc('[', ']', '{', '}', rule.Location)\n\t}\n\n\tcomments = w.insertComments(comments, closeLoc)\n\n\tw.down()\n\tw.startLine()\n\tw.write(\"}\")\n\tif rule.Else != nil {\n\t\tcomments = w.writeElse(rule, comments)\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeElse(rule *ast.Rule, comments []*ast.Comment) []*ast.Comment {\n\t// If there was nothing else on the line before the \"else\" starts\n\t// then preserve this style of else block, otherwise it will be\n\t// started as an \"inline\" else eg:\n\t//\n\t//     p {\n\t//     \t...\n\t//     }\n\t//\n\t//     else {\n\t//     \t...\n\t//     }\n\t//\n\t// versus\n\t//\n\t//     p {\n\t// \t    ...\n\t//     } else {\n\t//     \t...\n\t//     }\n\t//\n\t// Note: This doesn't use the `close` as it currently isn't accurate for all\n\t// types of values. Checking the actual line text is the most consistent approach.\n\twasInline := false\n\truleLines := bytes.Split(rule.Location.Text, []byte(\"\\n\"))\n\trelativeElseRow := rule.Else.Location.Row - rule.Location.Row\n\tif relativeElseRow > 0 && relativeElseRow < len(ruleLines) {\n\t\telseLine := ruleLines[relativeElseRow]\n\t\tif !bytes.HasPrefix(bytes.TrimSpace(elseLine), []byte(\"else\")) {\n\t\t\twasInline = true\n\t\t}\n\t}\n\n\t// If there are any comments between the closing brace of the previous rule and the start\n\t// of the else block we will always insert a new blank line between them.\n\thasCommentAbove := len(comments) > 0 && comments[0].Location.Row-rule.Else.Head.Location.Row < 0 || w.beforeEnd != nil\n\n\tif !hasCommentAbove && wasInline {\n\t\tw.write(\" \")\n\t} else {\n\t\tw.blankLine()\n\t\tw.startLine()\n\t}\n\n\trule.Else.Head.Name = \"else\"\n\trule.Else.Head.Args = nil\n\tcomments = w.insertComments(comments, rule.Else.Head.Location)\n\n\tif hasCommentAbove && !wasInline {\n\t\t// The comments would have ended the line, be sure to start one again\n\t\t// before writing the rest of the \"else\" rule.\n\t\tw.startLine()\n\t}\n\n\t// For backwards compatibility adjust the rule head value location\n\t// TODO: Refactor the logic for inserting comments, or special\n\t// case comments in a rule head value so this can be removed\n\tif rule.Else.Head.Value != nil {\n\t\trule.Else.Head.Value.Location = rule.Else.Head.Location\n\t}\n\n\treturn w.writeRule(rule.Else, true, comments)\n}\n\nfunc (w *writer) writeHead(head *ast.Head, isDefault bool, isExpandedConst bool, comments []*ast.Comment) []*ast.Comment {\n\tw.write(head.Name.String())\n\tif len(head.Args) > 0 {\n\t\tw.write(\"(\")\n\t\tvar args []interface{}\n\t\tfor _, arg := range head.Args {\n\t\t\targs = append(args, arg)\n\t\t}\n\t\tcomments = w.writeIterable(args, head.Location, closingLoc(0, 0, '(', ')', head.Location), comments, w.listWriter())\n\t\tw.write(\")\")\n\t}\n\tif head.Key != nil {\n\t\tw.write(\"[\")\n\t\tcomments = w.writeTerm(head.Key, comments)\n\t\tw.write(\"]\")\n\t}\n\tif head.Value != nil && (head.Key != nil || ast.Compare(head.Value, ast.BooleanTerm(true)) != 0 || isExpandedConst || isDefault) {\n\t\tif head.Assign {\n\t\t\tw.write(\" := \")\n\t\t} else {\n\t\t\tw.write(\" = \")\n\t\t}\n\t\tcomments = w.writeTerm(head.Value, comments)\n\t}\n\treturn comments\n}\n\nfunc (w *writer) insertComments(comments []*ast.Comment, loc *ast.Location) []*ast.Comment {\n\tbefore, at, comments := partitionComments(comments, loc)\n\tw.writeComments(before)\n\tif len(before) > 0 && loc.Row-before[len(before)-1].Location.Row > 1 {\n\t\tw.blankLine()\n\t}\n\n\tw.beforeLineEnd(at)\n\treturn comments\n}\n\nfunc (w *writer) writeBody(body ast.Body, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, body.Loc())\n\toffset := 0\n\tfor i, expr := range body {\n\t\tif i > 0 && expr.Location.Row-body[i-1].Location.Row-offset > 1 {\n\t\t\tw.blankLine()\n\t\t}\n\t\tw.startLine()\n\n\t\tcomments = w.writeExpr(expr, comments)\n\t\tw.endLine()\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeExpr(expr *ast.Expr, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, expr.Location)\n\tif !w.inline {\n\t\tw.startLine()\n\t}\n\n\tif expr.Negated {\n\t\tw.write(\"not \")\n\t}\n\n\tswitch t := expr.Terms.(type) {\n\tcase *ast.SomeDecl:\n\t\tcomments = w.writeSomeDecl(t, comments)\n\tcase *ast.Every:\n\t\tcomments = w.writeEvery(t, comments)\n\tcase []*ast.Term:\n\t\tcomments = w.writeFunctionCall(expr, comments)\n\tcase *ast.Term:\n\t\tcomments = w.writeTerm(t, comments)\n\t}\n\n\tvar indented bool\n\tfor i, with := range expr.With {\n\t\tif i > 0 && with.Location.Row-expr.With[i-1].Location.Row > 0 {\n\t\t\tif !indented {\n\t\t\t\tindented = true\n\n\t\t\t\tw.up()\n\t\t\t\tdefer w.down()\n\t\t\t}\n\t\t\tw.endLine()\n\t\t\tw.startLine()\n\t\t}\n\t\tcomments = w.writeWith(with, comments)\n\t}\n\n\treturn comments\n}\n\nfunc (w *writer) writeSomeDecl(decl *ast.SomeDecl, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, decl.Location)\n\tw.write(\"some \")\n\n\trow := decl.Location.Row\n\n\tfor i, term := range decl.Symbols {\n\t\tswitch val := term.Value.(type) {\n\t\tcase ast.Var:\n\t\t\tif term.Location.Row > row {\n\t\t\t\tw.endLine()\n\t\t\t\tw.startLine()\n\t\t\t\tw.write(w.indent)\n\t\t\t\trow = term.Location.Row\n\t\t\t} else if i > 0 {\n\t\t\t\tw.write(\" \")\n\t\t\t}\n\n\t\t\tcomments = w.writeTerm(term, comments)\n\n\t\t\tif i < len(decl.Symbols)-1 {\n\t\t\t\tw.write(\",\")\n\t\t\t}\n\t\tcase ast.Call:\n\t\t\tcomments = w.writeInOperator(false, val[1:], comments)\n\t\t}\n\t}\n\n\treturn comments\n}\n\nfunc (w *writer) writeEvery(every *ast.Every, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, every.Location)\n\tw.write(\"every \")\n\tif every.Key != nil {\n\t\tcomments = w.writeTerm(every.Key, comments)\n\t\tw.write(\", \")\n\t}\n\tcomments = w.writeTerm(every.Value, comments)\n\tw.write(\" in \")\n\tcomments = w.writeTerm(every.Domain, comments)\n\tw.write(\" {\")\n\tcomments = w.writeComprehensionBody('{', '}', every.Body, every.Loc(), every.Loc(), comments)\n\n\tif len(every.Body) == 1 &&\n\t\tevery.Body[0].Location.Row == every.Location.Row {\n\t\tw.write(\" \")\n\t}\n\tw.write(\"}\")\n\treturn comments\n}\n\nfunc (w *writer) writeFunctionCall(expr *ast.Expr, comments []*ast.Comment) []*ast.Comment {\n\n\tterms := expr.Terms.([]*ast.Term)\n\toperator := terms[0].Value.String()\n\n\tswitch operator {\n\tcase ast.Member.Name, ast.MemberWithKey.Name:\n\t\treturn w.writeInOperator(false, terms[1:], comments)\n\t}\n\n\tbi, ok := ast.BuiltinMap[operator]\n\tif !ok || bi.Infix == \"\" {\n\t\treturn w.writeFunctionCallPlain(terms, comments)\n\t}\n\n\tnumDeclArgs := len(bi.Decl.Args())\n\tnumCallArgs := len(terms) - 1\n\n\tswitch numCallArgs {\n\tcase numDeclArgs: // Print infix where result is unassigned (e.g., x != y)\n\t\tcomments = w.writeTerm(terms[1], comments)\n\t\tw.write(\" \" + bi.Infix + \" \")\n\t\treturn w.writeTerm(terms[2], comments)\n\n\tcase numDeclArgs + 1: // Print infix where result is assigned (e.g., z = x + y)\n\t\tcomments = w.writeTerm(terms[3], comments)\n\t\tw.write(\" \" + ast.Equality.Infix + \" \")\n\t\tcomments = w.writeTerm(terms[1], comments)\n\t\tw.write(\" \" + bi.Infix + \" \")\n\t\tcomments = w.writeTerm(terms[2], comments)\n\t\treturn comments\n\t}\n\treturn w.writeFunctionCallPlain(terms, comments)\n}\n\nfunc (w *writer) writeFunctionCallPlain(terms []*ast.Term, comments []*ast.Comment) []*ast.Comment {\n\tw.write(terms[0].String() + \"(\")\n\tdefer w.write(\")\")\n\targs := make([]interface{}, len(terms)-1)\n\tfor i, t := range terms[1:] {\n\t\targs[i] = t\n\t}\n\tloc := terms[0].Location\n\treturn w.writeIterable(args, loc, closingLoc(0, 0, '(', ')', loc), comments, w.listWriter())\n}\n\nfunc (w *writer) writeWith(with *ast.With, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, with.Location)\n\tw.write(\" with \")\n\tcomments = w.writeTerm(with.Target, comments)\n\tw.write(\" as \")\n\treturn w.writeTerm(with.Value, comments)\n}\n\nfunc (w *writer) writeTerm(term *ast.Term, comments []*ast.Comment) []*ast.Comment {\n\treturn w.writeTermParens(false, term, comments)\n}\n\nfunc (w *writer) writeTermParens(parens bool, term *ast.Term, comments []*ast.Comment) []*ast.Comment {\n\tcomments = w.insertComments(comments, term.Location)\n\tif !w.inline {\n\t\tw.startLine()\n\t}\n\n\tswitch x := term.Value.(type) {\n\tcase ast.Ref:\n\t\tw.writeRef(x)\n\tcase ast.Object:\n\t\tcomments = w.writeObject(x, term.Location, comments)\n\tcase *ast.Array:\n\t\tcomments = w.writeArray(x, term.Location, comments)\n\tcase ast.Set:\n\t\tcomments = w.writeSet(x, term.Location, comments)\n\tcase *ast.ArrayComprehension:\n\t\tcomments = w.writeArrayComprehension(x, term.Location, comments)\n\tcase *ast.ObjectComprehension:\n\t\tcomments = w.writeObjectComprehension(x, term.Location, comments)\n\tcase *ast.SetComprehension:\n\t\tcomments = w.writeSetComprehension(x, term.Location, comments)\n\tcase ast.String:\n\t\tif term.Location.Text[0] == '`' {\n\t\t\t// To preserve raw strings, we need to output the original text,\n\t\t\t// not what x.String() would give us.\n\t\t\tw.write(string(term.Location.Text))\n\t\t} else {\n\t\t\tw.write(x.String())\n\t\t}\n\tcase ast.Var:\n\t\tw.write(w.formatVar(x))\n\tcase ast.Call:\n\t\tcomments = w.writeCall(parens, x, comments)\n\tcase fmt.Stringer:\n\t\tw.write(x.String())\n\t}\n\n\tif !w.inline {\n\t\tw.startLine()\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeRef(x ast.Ref) {\n\tif len(x) > 0 {\n\t\tw.writeTerm(x[0], nil)\n\t\tpath := x[1:]\n\t\tfor _, t := range path {\n\t\t\tswitch p := t.Value.(type) {\n\t\t\tcase ast.String:\n\t\t\t\tw.writeRefStringPath(p)\n\t\t\tcase ast.Var:\n\t\t\t\tw.writeBracketed(w.formatVar(p))\n\t\t\tdefault:\n\t\t\t\tw.write(\"[\")\n\t\t\t\tw.writeTerm(t, nil)\n\t\t\t\tw.write(\"]\")\n\t\t\t}\n\t\t}\n\t}\n}\n\nfunc (w *writer) writeBracketed(str string) {\n\tw.write(\"[\" + str + \"]\")\n}\n\nvar varRegexp = regexp.MustCompile(\"^[[:alpha:]_][[:alpha:][:digit:]_]*$\")\n\nfunc (w *writer) writeRefStringPath(s ast.String) {\n\tstr := string(s)\n\tif varRegexp.MatchString(str) && !ast.IsKeyword(str) {\n\t\tw.write(\".\" + str)\n\t} else {\n\t\tw.writeBracketed(s.String())\n\t}\n}\n\nfunc (w *writer) formatVar(v ast.Var) string {\n\tif v.IsWildcard() {\n\t\treturn ast.Wildcard.String()\n\t}\n\treturn v.String()\n}\n\nfunc (w *writer) writeCall(parens bool, x ast.Call, comments []*ast.Comment) []*ast.Comment {\n\tbi, ok := ast.BuiltinMap[x[0].String()]\n\tif !ok || bi.Infix == \"\" {\n\t\treturn w.writeFunctionCallPlain(x, comments)\n\t}\n\n\tif bi.Infix == \"in\" {\n\t\t// NOTE(sr): `in` requires special handling, mirroring what happens in the parser,\n\t\t// since there can be one or two lhs arguments.\n\t\treturn w.writeInOperator(true, x[1:], comments)\n\t}\n\n\t// TODO(tsandall): improve to consider precedence?\n\tif parens {\n\t\tw.write(\"(\")\n\t}\n\tcomments = w.writeTermParens(true, x[1], comments)\n\tw.write(\" \" + bi.Infix + \" \")\n\tcomments = w.writeTermParens(true, x[2], comments)\n\tif parens {\n\t\tw.write(\")\")\n\t}\n\n\treturn comments\n}\n\nfunc (w *writer) writeInOperator(parens bool, operands []*ast.Term, comments []*ast.Comment) []*ast.Comment {\n\tkw := \"in\"\n\tswitch len(operands) {\n\tcase 2:\n\t\tcomments = w.writeTermParens(true, operands[0], comments)\n\t\tw.write(\" \")\n\t\tw.write(kw)\n\t\tw.write(\" \")\n\t\tcomments = w.writeTermParens(true, operands[1], comments)\n\tcase 3:\n\t\tif parens {\n\t\t\tw.write(\"(\")\n\t\t\tdefer w.write(\")\")\n\t\t}\n\t\tcomments = w.writeTermParens(true, operands[0], comments)\n\t\tw.write(\", \")\n\t\tcomments = w.writeTermParens(true, operands[1], comments)\n\t\tw.write(\" \")\n\t\tw.write(kw)\n\t\tw.write(\" \")\n\t\tcomments = w.writeTermParens(true, operands[2], comments)\n\t}\n\treturn comments\n}\n\nfunc (w *writer) writeObject(obj ast.Object, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"{\")\n\tdefer w.write(\"}\")\n\n\tvar s []interface{}\n\tobj.Foreach(func(k, v *ast.Term) {\n\t\ts = append(s, ast.Item(k, v))\n\t})\n\treturn w.writeIterable(s, loc, closingLoc(0, 0, '{', '}', loc), comments, w.objectWriter())\n}\n\nfunc (w *writer) writeArray(arr *ast.Array, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"[\")\n\tdefer w.write(\"]\")\n\n\tvar s []interface{}\n\tarr.Foreach(func(t *ast.Term) {\n\t\ts = append(s, t)\n\t})\n\treturn w.writeIterable(s, loc, closingLoc(0, 0, '[', ']', loc), comments, w.listWriter())\n}\n\nfunc (w *writer) writeSet(set ast.Set, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\n\tif set.Len() == 0 {\n\t\tw.write(\"set()\")\n\t\treturn w.insertComments(comments, closingLoc(0, 0, '(', ')', loc))\n\t}\n\n\tw.write(\"{\")\n\tdefer w.write(\"}\")\n\n\tvar s []interface{}\n\tset.Foreach(func(t *ast.Term) {\n\t\ts = append(s, t)\n\t})\n\treturn w.writeIterable(s, loc, closingLoc(0, 0, '{', '}', loc), comments, w.listWriter())\n}\n\nfunc (w *writer) writeArrayComprehension(arr *ast.ArrayComprehension, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"[\")\n\tdefer w.write(\"]\")\n\n\treturn w.writeComprehension('[', ']', arr.Term, arr.Body, loc, comments)\n}\n\nfunc (w *writer) writeSetComprehension(set *ast.SetComprehension, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"{\")\n\tdefer w.write(\"}\")\n\n\treturn w.writeComprehension('{', '}', set.Term, set.Body, loc, comments)\n}\n\nfunc (w *writer) writeObjectComprehension(object *ast.ObjectComprehension, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tw.write(\"{\")\n\tdefer w.write(\"}\")\n\n\tobject.Value.Location = object.Key.Location // Ensure the value is not written on the next line.\n\tif object.Key.Location.Row-loc.Row > 1 {\n\t\tw.endLine()\n\t\tw.startLine()\n\t}\n\n\tcomments = w.writeTerm(object.Key, comments)\n\tw.write(\": \")\n\treturn w.writeComprehension('{', '}', object.Value, object.Body, loc, comments)\n}\n\nfunc (w *writer) writeComprehension(open, close byte, term *ast.Term, body ast.Body, loc *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tif term.Location.Row-loc.Row > 1 {\n\t\tw.endLine()\n\t\tw.startLine()\n\t}\n\n\tcomments = w.writeTerm(term, comments)\n\tw.write(\" |\")\n\n\treturn w.writeComprehensionBody(open, close, body, term.Location, loc, comments)\n}\n\nfunc (w *writer) writeComprehensionBody(open, close byte, body ast.Body, term, compr *ast.Location, comments []*ast.Comment) []*ast.Comment {\n\tvar exprs []interface{}\n\tfor _, expr := range body {\n\t\texprs = append(exprs, expr)\n\t}\n\tlines := groupIterable(exprs, term)\n\n\tif body.Loc().Row-term.Row > 0 || len(lines) > 1 {\n\t\tw.endLine()\n\t\tw.up()\n\t\tdefer w.startLine()\n\t\tdefer w.down()\n\n\t\tcomments = w.writeBody(body, comments)\n\t} else {\n\t\tw.write(\" \")\n\t\ti := 0\n\t\tfor ; i < len(body)-1; i++ {\n\t\t\tcomments = w.writeExpr(body[i], comments)\n\t\t\tw.write(\"; \")\n\t\t}\n\t\tcomments = w.writeExpr(body[i], comments)\n\t}\n\n\treturn w.insertComments(comments, closingLoc(0, 0, open, close, compr))\n}\n\nfunc (w *writer) writeImports(imports []*ast.Import, comments []*ast.Comment) []*ast.Comment {\n\tm, comments := mapImportsToComments(imports, comments)\n\n\tgroups := groupImports(imports)\n\tfor _, group := range groups {\n\t\tcomments = w.insertComments(comments, group[0].Loc())\n\n\t\t// Sort imports within a newline grouping.\n\t\tsort.Slice(group, func(i, j int) bool {\n\t\t\ta := group[i]\n\t\t\tb := group[j]\n\t\t\treturn a.Compare(b) < 0\n\t\t})\n\t\tfor _, i := range group {\n\t\t\tw.startLine()\n\t\t\tw.write(i.String())\n\t\t\tif c, ok := m[i]; ok {\n\t\t\t\tw.write(\" \" + c.String())\n\t\t\t}\n\t\t\tw.endLine()\n\t\t}\n\t\tw.blankLine()\n\t}\n\n\treturn comments\n}\n\ntype entryWriter func(interface{}, []*ast.Comment) []*ast.Comment\n\nfunc (w *writer) writeIterable(elements []interface{}, last *ast.Location, close *ast.Location, comments []*ast.Comment, fn entryWriter) []*ast.Comment {\n\tlines := groupIterable(elements, last)\n\tif len(lines) > 1 {\n\t\tw.delayBeforeEnd()\n\t\tw.startMultilineSeq()\n\t}\n\n\ti := 0\n\tfor ; i < len(lines)-1; i++ {\n\t\tcomments = w.writeIterableLine(lines[i], comments, fn)\n\t\tw.write(\",\")\n\n\t\tw.endLine()\n\t\tw.startLine()\n\t}\n\n\tcomments = w.writeIterableLine(lines[i], comments, fn)\n\n\tif len(lines) > 1 {\n\t\tw.write(\",\")\n\t\tw.endLine()\n\t\tcomments = w.insertComments(comments, close)\n\t\tw.down()\n\t\tw.startLine()\n\t}\n\n\treturn comments\n}\n\nfunc (w *writer) writeIterableLine(elements []interface{}, comments []*ast.Comment, fn entryWriter) []*ast.Comment {\n\tif len(elements) == 0 {\n\t\treturn comments\n\t}\n\n\ti := 0\n\tfor ; i < len(elements)-1; i++ {\n\t\tcomments = fn(elements[i], comments)\n\t\tw.write(\", \")\n\t}\n\n\treturn fn(elements[i], comments)\n}\n\nfunc (w *writer) objectWriter() entryWriter {\n\treturn func(x interface{}, comments []*ast.Comment) []*ast.Comment {\n\t\tentry := x.([2]*ast.Term)\n\t\tcomments = w.writeTerm(entry[0], comments)\n\t\tw.write(\": \")\n\t\treturn w.writeTerm(entry[1], comments)\n\t}\n}\n\nfunc (w *writer) listWriter() entryWriter {\n\treturn func(x interface{}, comments []*ast.Comment) []*ast.Comment {\n\t\treturn w.writeTerm(x.(*ast.Term), comments)\n\t}\n}\n\n// groupIterable will group the `elements` slice into slices according to their\n// location: anything on the same line will be put into a slice.\nfunc groupIterable(elements []interface{}, last *ast.Location) [][]interface{} {\n\t// Generated vars occur in the AST when we're rendering the result of\n\t// partial evaluation in a bundle build with optimization.\n\t// Those variables, and wildcard variables have the \"default location\",\n\t// set in `Ast()`). That is no proper file location, and the grouping\n\t// based on source location will yield a bad result.\n\tdef := false // default location found?\n\tfor _, elem := range elements {\n\t\tast.WalkTerms(elem, func(t *ast.Term) bool {\n\t\t\tif t.Location.File == defaultLocationFile {\n\t\t\t\tdef = true\n\t\t\t\treturn true\n\t\t\t}\n\t\t\treturn false\n\t\t})\n\t\tif def { // return as-is\n\t\t\treturn [][]interface{}{elements}\n\t\t}\n\t}\n\tsort.Slice(elements, func(i, j int) bool {\n\t\treturn locLess(elements[i], elements[j])\n\t})\n\n\tvar lines [][]interface{}\n\tvar cur []interface{}\n\tfor i, t := range elements {\n\t\telem := t\n\t\tloc := getLoc(elem)\n\t\tlineDiff := loc.Row - last.Row\n\t\tif lineDiff > 0 && i > 0 {\n\t\t\tlines = append(lines, cur)\n\t\t\tcur = nil\n\t\t}\n\n\t\tlast = loc\n\t\tcur = append(cur, elem)\n\t}\n\treturn append(lines, cur)\n}\n\nfunc mapImportsToComments(imports []*ast.Import, comments []*ast.Comment) (map[*ast.Import]*ast.Comment, []*ast.Comment) {\n\tvar leftovers []*ast.Comment\n\tm := map[*ast.Import]*ast.Comment{}\n\n\tfor _, c := range comments {\n\t\tmatched := false\n\t\tfor _, i := range imports {\n\t\t\tif c.Loc().Row == i.Loc().Row {\n\t\t\t\tm[i] = c\n\t\t\t\tmatched = true\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif !matched {\n\t\t\tleftovers = append(leftovers, c)\n\t\t}\n\t}\n\n\treturn m, leftovers\n}\n\nfunc groupImports(imports []*ast.Import) [][]*ast.Import {\n\tswitch len(imports) { // shortcuts\n\tcase 0:\n\t\treturn nil\n\tcase 1:\n\t\treturn [][]*ast.Import{imports}\n\t}\n\t// there are >=2 imports to group\n\n\tvar groups [][]*ast.Import\n\tgroup := []*ast.Import{imports[0]}\n\n\tfor _, i := range imports[1:] {\n\t\tlast := group[len(group)-1]\n\n\t\t// nil-location imports have been sorted up to come first\n\t\tif i.Loc() != nil && last.Loc() != nil && // first import with a location, or\n\t\t\ti.Loc().Row-last.Loc().Row > 1 { // more than one row apart from previous import\n\n\t\t\t// start a new group\n\t\t\tgroups = append(groups, group)\n\t\t\tgroup = []*ast.Import{}\n\t\t}\n\t\tgroup = append(group, i)\n\t}\n\tif len(group) > 0 {\n\t\tgroups = append(groups, group)\n\t}\n\n\treturn groups\n}\n\nfunc partitionComments(comments []*ast.Comment, l *ast.Location) (before []*ast.Comment, at *ast.Comment, after []*ast.Comment) {\n\tfor _, c := range comments {\n\t\tswitch cmp := c.Location.Row - l.Row; {\n\t\tcase cmp < 0:\n\t\t\tbefore = append(before, c)\n\t\tcase cmp > 0:\n\t\t\tafter = append(after, c)\n\t\tcase cmp == 0:\n\t\t\tat = c\n\t\t}\n\t}\n\n\treturn before, at, after\n}\n\nfunc gatherImports(others []interface{}) (imports []*ast.Import, rest []interface{}) {\n\ti := 0\nloop:\n\tfor ; i < len(others); i++ {\n\t\tswitch x := others[i].(type) {\n\t\tcase *ast.Import:\n\t\t\timports = append(imports, x)\n\t\tcase *ast.Rule:\n\t\t\tbreak loop\n\t\t}\n\t}\n\treturn imports, others[i:]\n}\n\nfunc gatherRules(others []interface{}) (rules []*ast.Rule, rest []interface{}) {\n\ti := 0\nloop:\n\tfor ; i < len(others); i++ {\n\t\tswitch x := others[i].(type) {\n\t\tcase *ast.Rule:\n\t\t\trules = append(rules, x)\n\t\tcase *ast.Import:\n\t\t\tbreak loop\n\t\t}\n\t}\n\treturn rules, others[i:]\n}\n\nfunc locLess(a, b interface{}) bool {\n\treturn locCmp(a, b) < 0\n}\n\nfunc locCmp(a, b interface{}) int {\n\tal := getLoc(a)\n\tbl := getLoc(b)\n\tswitch {\n\tcase al == nil && bl == nil:\n\t\treturn 0\n\tcase al == nil:\n\t\treturn -1\n\tcase bl == nil:\n\t\treturn 1\n\t}\n\n\tif cmp := al.Row - bl.Row; cmp != 0 {\n\t\treturn cmp\n\n\t}\n\treturn al.Col - bl.Col\n}\n\nfunc getLoc(x interface{}) *ast.Location {\n\tswitch x := x.(type) {\n\tcase ast.Node: // *ast.Head, *ast.Expr, *ast.With, *ast.Term\n\t\treturn x.Loc()\n\tcase *ast.Location:\n\t\treturn x\n\tcase [2]*ast.Term: // Special case to allow for easy printing of objects.\n\t\treturn x[0].Location\n\tdefault:\n\t\tpanic(\"Not reached\")\n\t}\n}\n\nfunc closingLoc(skipOpen, skipClose, open, close byte, loc *ast.Location) *ast.Location {\n\ti, offset := 0, 0\n\n\t// Skip past parens/brackets/braces in rule heads.\n\tif skipOpen > 0 {\n\t\ti, offset = skipPast(skipOpen, skipClose, loc)\n\t}\n\n\tfor ; i < len(loc.Text) && loc.Text[i] != open; i++ {\n\t}\n\n\tif i >= len(loc.Text) {\n\t\treturn &ast.Location{Row: -1}\n\t}\n\n\tstate := 1\n\tfor state > 0 {\n\t\ti++\n\t\tif i >= len(loc.Text) {\n\t\t\treturn &ast.Location{Row: -1}\n\t\t}\n\n\t\tswitch loc.Text[i] {\n\t\tcase open:\n\t\t\tstate++\n\t\tcase close:\n\t\t\tstate--\n\t\tcase '\\n':\n\t\t\toffset++\n\t\t}\n\t}\n\n\treturn &ast.Location{Row: loc.Row + offset}\n}\n\nfunc skipPast(open, close byte, loc *ast.Location) (int, int) {\n\ti := 0\n\tfor ; i < len(loc.Text) && loc.Text[i] != open; i++ {\n\t}\n\n\tstate := 1\n\toffset := 0\n\tfor state > 0 {\n\t\ti++\n\t\tif i >= len(loc.Text) {\n\t\t\treturn i, offset\n\t\t}\n\n\t\tswitch loc.Text[i] {\n\t\tcase open:\n\t\t\tstate++\n\t\tcase close:\n\t\t\tstate--\n\t\tcase '\\n':\n\t\t\toffset++\n\t\t}\n\t}\n\n\treturn i, offset\n}\n\nfunc dedupComments(comments []*ast.Comment) []*ast.Comment {\n\tif len(comments) == 0 {\n\t\treturn nil\n\t}\n\n\tfiltered := []*ast.Comment{comments[0]}\n\tfor i := 1; i < len(comments); i++ {\n\t\tif comments[i].Location.Equal(comments[i-1].Location) {\n\t\t\tcontinue\n\t\t}\n\t\tfiltered = append(filtered, comments[i])\n\t}\n\treturn filtered\n}\n\n// startLine begins a line with the current indentation level.\nfunc (w *writer) startLine() {\n\tw.inline = true\n\tfor i := 0; i < w.level; i++ {\n\t\tw.write(w.indent)\n\t}\n}\n\n// endLine ends a line with a newline.\nfunc (w *writer) endLine() {\n\tw.inline = false\n\tif w.beforeEnd != nil && !w.delay {\n\t\tw.write(\" \" + w.beforeEnd.String())\n\t\tw.beforeEnd = nil\n\t}\n\tw.delay = false\n\tw.write(\"\\n\")\n}\n\n// beforeLineEnd registers a comment to be printed at the end of the current line.\nfunc (w *writer) beforeLineEnd(c *ast.Comment) {\n\tif w.beforeEnd != nil {\n\t\tif c == nil {\n\t\t\treturn\n\t\t}\n\t\tpanic(\"overwriting non-nil beforeEnd\")\n\t}\n\tw.beforeEnd = c\n}\n\nfunc (w *writer) delayBeforeEnd() {\n\tw.delay = true\n}\n\n// line prints a blank line. If the writer is currently in the middle of a line,\n// line ends it and then prints a blank one.\nfunc (w *writer) blankLine() {\n\tif w.inline {\n\t\tw.endLine()\n\t}\n\tw.write(\"\\n\")\n}\n\n// write the input string and writes it to the buffer.\nfunc (w *writer) write(s string) {\n\tw.buf.WriteString(s)\n}\n\n// writeLine writes the string on a newly started line, then terminate the line.\nfunc (w *writer) writeLine(s string) {\n\tif !w.inline {\n\t\tw.startLine()\n\t}\n\tw.write(s)\n\tw.endLine()\n}\n\nfunc (w *writer) startMultilineSeq() {\n\tw.endLine()\n\tw.up()\n\tw.startLine()\n}\n\n// up increases the indentation level\nfunc (w *writer) up() {\n\tw.level++\n}\n\n// down decreases the indentation level\nfunc (w *writer) down() {\n\tif w.level == 0 {\n\t\tpanic(\"negative indentation level\")\n\t}\n\tw.level--\n}\n\nfunc ensureFutureKeywordImport(imps []*ast.Import, kw string) []*ast.Import {\n\tallKeywords := ast.MustParseTerm(\"future.keywords\")\n\tkwPath := ast.MustParseTerm(\"future.keywords.\" + kw)\n\tfor _, imp := range imps {\n\t\tif allKeywords.Equal(imp.Path) || imp.Path.Equal(kwPath) {\n\t\t\treturn imps\n\t\t}\n\t}\n\treturn append(imps, &ast.Import{Path: kwPath})\n}\n", "// Copyright 2017 The OPA Authors.  All rights reserved.\n// Use of this source code is governed by an Apache2\n// license that can be found in the LICENSE file.\n\npackage format\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io/ioutil\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"testing\"\n\n\t\"github.com/open-policy-agent/opa/ast\"\n\t\"github.com/open-policy-agent/opa/ast/location\"\n)\n\nfunc TestFormatNilLocation(t *testing.T) {\n\trule := ast.MustParseRule(`r = y { y = \"foo\" }`)\n\trule.Head.Location = nil\n\n\tbs, err := Ast(rule)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\texp := strings.Trim(`\nr = y {\n\ty = \"foo\"\n}`, \" \\n\")\n\n\tif string(bs) != exp {\n\t\tt.Fatalf(\"Expected %q but got %q\", exp, string(bs))\n\t}\n}\n\nfunc TestFormatNilLocationEmptyBody(t *testing.T) {\n\tb := ast.NewBody()\n\tx, err := Ast(b)\n\tif len(x) != 0 || err != nil {\n\t\tt.Fatalf(\"Expected empty result but got: %q, err: %v\", string(x), err)\n\t}\n}\n\nfunc TestFormatNilLocationFunctionArgs(t *testing.T) {\n\tb := ast.NewBody()\n\ts := ast.StringTerm(\" \")\n\ts.SetLocation(location.NewLocation([]byte(\"foo\"), \"p.rego\", 2, 2))\n\tb.Append(ast.Split.Expr(ast.NewTerm(ast.Var(\"__local1__\")), s, ast.NewTerm(ast.Var(\"__local2__\"))))\n\texp := \"split(__local1__, \\\" \\\", __local2__)\\n\"\n\tbs, err := Ast(b)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\tif string(bs) != exp {\n\t\tt.Fatalf(\"Expected %q but got %q\", exp, string(bs))\n\t}\n}\n\nfunc TestFormatSourceError(t *testing.T) {\n\trego := \"testfiles/test.rego.error\"\n\tcontents, err := ioutil.ReadFile(rego)\n\tif err != nil {\n\t\tt.Fatalf(\"Failed to read rego source: %v\", err)\n\t}\n\n\t_, err = Source(rego, contents)\n\tif err == nil {\n\t\tt.Fatal(\"Expected parsing error, not nil\")\n\t}\n\n\texp := \"1 error occurred: testfiles/test.rego.error:27: rego_parse_error: unexpected eof token\"\n\n\tif !strings.HasPrefix(err.Error(), exp) {\n\t\tt.Fatalf(\"Expected error message '%s', got '%s'\", exp, err.Error())\n\t}\n}\n\nfunc TestFormatSource(t *testing.T) {\n\tregoFiles, err := filepath.Glob(\"testfiles/*.rego\")\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tfor _, rego := range regoFiles {\n\t\tt.Run(rego, func(t *testing.T) {\n\t\t\tcontents, err := ioutil.ReadFile(rego)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to read rego source: %v\", err)\n\t\t\t}\n\t\t\tif bytes.Contains(contents, []byte(`import future.keywords.every`)) {\n\t\t\t\tt.Skip(\"TODO: uncomment 'every' tests\")\n\t\t\t}\n\n\t\t\texpected, err := ioutil.ReadFile(rego + \".formatted\")\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to read expected rego source: %v\", err)\n\t\t\t}\n\n\t\t\tformatted, err := Source(rego, contents)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to format file: %v\", err)\n\t\t\t}\n\n\t\t\tif ln, at := differsAt(formatted, expected); ln != 0 {\n\t\t\t\tt.Fatalf(\"Expected formatted bytes to equal expected bytes but differed near line %d / byte %d (got: %q, expected: %q):\\n%s\", ln, at, formatted[at], expected[at], prefixWithLineNumbers(formatted))\n\t\t\t}\n\n\t\t\tif _, err := ast.ParseModule(rego+\".tmp\", string(formatted)); err != nil {\n\t\t\t\tt.Fatalf(\"Failed to parse formatted bytes: %v\", err)\n\t\t\t}\n\n\t\t\tformatted, err = Source(rego, formatted)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Failed to double format file\")\n\t\t\t}\n\n\t\t\tif ln, at := differsAt(formatted, expected); ln != 0 {\n\t\t\t\tt.Fatalf(\"Expected roundtripped bytes to equal expected bytes but differed near line %d / byte %d:\\n%s\", ln, at, prefixWithLineNumbers(formatted))\n\t\t\t}\n\n\t\t})\n\t}\n}\n\nfunc TestFormatAST(t *testing.T) {\n\tcases := []struct {\n\t\tnote     string\n\t\ttoFmt    interface{}\n\t\texpected string\n\t}{\n\t\t{\n\t\t\tnote:     \"var\",\n\t\t\ttoFmt:    ast.Var(`foo`),\n\t\t\texpected: \"foo\",\n\t\t},\n\t\t{\n\t\t\tnote: \"string\",\n\t\t\ttoFmt: &ast.Term{\n\t\t\t\tValue:    ast.String(\"foo\"),\n\t\t\t\tLocation: &ast.Location{Text: []byte(`\"foo\"`)},\n\t\t\t},\n\t\t\texpected: `\"foo\"`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"var wildcard\",\n\t\t\ttoFmt:    ast.Var(`$12`),\n\t\t\texpected: \"_\",\n\t\t},\n\t\t{\n\t\t\tnote: \"string with wildcard prefix\",\n\t\t\ttoFmt: &ast.Term{\n\t\t\t\tValue:    ast.String(\"$01\"),\n\t\t\t\tLocation: &ast.Location{Text: []byte(`\"$01\"`)},\n\t\t\t},\n\t\t\texpected: `\"$01\"`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref var only\",\n\t\t\ttoFmt:    ast.MustParseRef(`data.foo`),\n\t\t\texpected: \"data.foo\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref multi vars\",\n\t\t\ttoFmt:    ast.MustParseRef(`data.foo.bar.baz`),\n\t\t\texpected: \"data.foo.bar.baz\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref with string\",\n\t\t\ttoFmt:    ast.MustParseRef(`data[\"foo\"]`),\n\t\t\texpected: `data.foo`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref multi string\",\n\t\t\ttoFmt:    ast.MustParseRef(`data[\"foo\"][\"bar\"][\"baz\"]`),\n\t\t\texpected: `data.foo.bar.baz`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref with string needs brackets\",\n\t\t\ttoFmt:    ast.MustParseRef(`data[\"foo my-var\\nbar\"]`),\n\t\t\texpected: `data[\"foo my-var\\nbar\"]`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref multi string needs brackets\",\n\t\t\ttoFmt:    ast.MustParseRef(`data[\"foo my-var\"][\"bar\"][\"almost.baz\"]`),\n\t\t\texpected: `data[\"foo my-var\"].bar[\"almost.baz\"]`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref var wildcard\",\n\t\t\ttoFmt:    ast.MustParseRef(`data.foo[_]`),\n\t\t\texpected: \"data.foo[_]\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref var wildcard\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[_]`),\n\t\t\texpected: \"foo[_]\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref string with wildcard prefix\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[\"$01\"]`),\n\t\t\texpected: `foo[\"$01\"]`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"nested ref var wildcard\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[bar[baz[_]]]`),\n\t\t\texpected: \"foo[bar[baz[_]]]\",\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref mixed\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[\"bar\"].baz[_][\"bar-2\"].qux`),\n\t\t\texpected: `foo.bar.baz[_][\"bar-2\"].qux`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref empty\",\n\t\t\ttoFmt:    ast.Ref{},\n\t\t\texpected: ``,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref nil\",\n\t\t\ttoFmt:    ast.Ref(nil),\n\t\t\texpected: ``,\n\t\t},\n\t\t{\n\t\t\tnote:     \"ref operator\",\n\t\t\ttoFmt:    ast.MustParseRef(`foo[count(foo) - 1]`),\n\t\t\texpected: `foo[count(foo) - 1]`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"x in xs\",\n\t\t\ttoFmt:    ast.Member.Call(ast.VarTerm(\"x\"), ast.VarTerm(\"xs\")),\n\t\t\texpected: `x in xs`,\n\t\t},\n\t\t{\n\t\t\tnote:     \"x, y in xs\",\n\t\t\ttoFmt:    ast.MemberWithKey.Call(ast.VarTerm(\"x\"), ast.VarTerm(\"y\"), ast.VarTerm(\"xs\")),\n\t\t\texpected: `(x, y in xs)`,\n\t\t},\n\t\t{\n\t\t\tnote: \"some x in xs\",\n\t\t\ttoFmt: ast.NewExpr(&ast.SomeDecl{Symbols: []*ast.Term{\n\t\t\t\tast.Member.Call(ast.VarTerm(\"x\"), ast.VarTerm(\"xs\")),\n\t\t\t}}),\n\t\t\texpected: `some x in xs`,\n\t\t},\n\t\t{\n\t\t\tnote: \"some x, y in xs\",\n\t\t\ttoFmt: ast.NewExpr(&ast.SomeDecl{Symbols: []*ast.Term{\n\t\t\t\tast.MemberWithKey.Call(ast.VarTerm(\"x\"), ast.VarTerm(\"y\"), ast.VarTerm(\"xs\")),\n\t\t\t}}),\n\t\t\texpected: `some x, y in xs`,\n\t\t},\n\t\t{\n\t\t\tnote: \"body shared wildcard\",\n\t\t\ttoFmt: ast.Body{\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tTerms: []*ast.Term{\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"eq\")),\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"input\"), ast.StringTerm(\"arr\"), ast.VarTerm(\"$01\"), ast.StringTerm(\"some key\"), ast.VarTerm(\"$02\")),\n\t\t\t\t\t\tast.VarTerm(\"bar\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tLocation: &ast.Location{\n\t\t\t\t\t\tRow: 2,\n\t\t\t\t\t\tCol: 1,\n\t\t\t\t\t},\n\t\t\t\t\tTerms: []*ast.Term{\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"eq\")),\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"input\"), ast.StringTerm(\"arr\"), ast.VarTerm(\"$01\"), ast.StringTerm(\"bar\")),\n\t\t\t\t\t\tast.VarTerm(\"qux\"),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tLocation: &ast.Location{\n\t\t\t\t\t\tRow: 2,\n\t\t\t\t\t\tCol: 1,\n\t\t\t\t\t},\n\t\t\t\t\tTerms: []*ast.Term{\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"eq\")),\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"foo\"), ast.VarTerm(\"$03\"), ast.VarTerm(\"$01\"), ast.StringTerm(\"bar\")),\n\t\t\t\t\t\tast.RefTerm(ast.VarTerm(\"bar\"), ast.VarTerm(\"$03\"), ast.VarTerm(\"$04\"), ast.VarTerm(\"$01\"), ast.StringTerm(\"bar\")),\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: `input.arr[_01][\"some key\"][_] = bar\ninput.arr[_01].bar = qux\nfoo[_03][_01].bar = bar[_03][_][_01].bar\n`,\n\t\t},\n\t\t{\n\t\t\tnote: \"body shared wildcard - ref head\",\n\t\t\ttoFmt: ast.Body{\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tTerms: ast.VarTerm(\"$x\"),\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tTerms: ast.RefTerm(ast.VarTerm(\"$x\"), ast.VarTerm(\"y\")),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: `_x\n_x[y]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"body shared wildcard - nested ref\",\n\t\t\ttoFmt: ast.Body{\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tTerms: ast.VarTerm(\"$x\"),\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tTerms: ast.RefTerm(ast.VarTerm(\"a\"), ast.RefTerm(ast.VarTerm(\"$x\"), ast.VarTerm(\"y\"))),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: `_x\na[_x[y]]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"body shared wildcard - nested ref array\",\n\t\t\ttoFmt: ast.Body{\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 0,\n\t\t\t\t\tTerms: ast.VarTerm(\"$x\"),\n\t\t\t\t},\n\t\t\t\t&ast.Expr{\n\t\t\t\t\tIndex: 1,\n\t\t\t\t\tTerms: ast.RefTerm(ast.VarTerm(\"a\"), ast.RefTerm(ast.VarTerm(\"$x\"), ast.VarTerm(\"y\"), ast.ArrayTerm(ast.VarTerm(\"z\"), ast.VarTerm(\"w\")))),\n\t\t\t\t},\n\t\t\t},\n\t\t\texpected: `_x\na[_x[y][[z, w]]]`,\n\t\t},\n\t\t{\n\t\t\tnote: \"expr with wildcard that has a default location\",\n\t\t\ttoFmt: func() *ast.Expr {\n\t\t\t\texpr := ast.MustParseExpr(`[\"foo\", _] = split(input.foo, \":\")`)\n\t\t\t\tast.WalkTerms(expr, func(term *ast.Term) bool {\n\t\t\t\t\tv, ok := term.Value.(ast.Var)\n\t\t\t\t\tif ok && v.IsWildcard() {\n\t\t\t\t\t\tterm.Location = defaultLocation(term)\n\t\t\t\t\t\treturn true\n\t\t\t\t\t}\n\t\t\t\t\tterm.Location.File = \"foo.rego\"\n\t\t\t\t\tterm.Location.Row = 2\n\t\t\t\t\treturn false\n\t\t\t\t})\n\t\t\t\treturn expr\n\t\t\t}(),\n\t\t\texpected: `[\"foo\", _] = split(input.foo, \":\")`,\n\t\t},\n\t\t{\n\t\t\tnote: \"expr all terms having empty-file locations\",\n\t\t\ttoFmt: ast.MustParseExpr(`[\n\t\t\t\t\t\"foo\",\n\t\t\t\t\t_\n\t\t\t\t\t] = split(input.foo, \":\")`),\n\t\t\texpected: `\n[\n\t\"foo\",\n\t_,\n] = split(input.foo, \":\")`,\n\t\t},\n\t\t{\n\t\t\tnote: \"expr where all terms having empty-file locations, and one is a default location\",\n\t\t\ttoFmt: func() *ast.Expr {\n\t\t\t\texpr := ast.MustParseExpr(`\n[\"foo\", __local1__] = split(input.foo, \":\")`)\n\t\t\t\tast.WalkTerms(expr, func(term *ast.Term) bool {\n\t\t\t\t\tif ast.VarTerm(\"__local1__\").Equal(term) {\n\t\t\t\t\t\tterm.Location = defaultLocation(term)\n\t\t\t\t\t\treturn true\n\t\t\t\t\t}\n\t\t\t\t\treturn false\n\t\t\t\t})\n\t\t\t\treturn expr\n\t\t\t}(),\n\t\t\texpected: `[\"foo\", __local1__] = split(input.foo, \":\")`,\n\t\t},\n\t}\n\n\tfor _, tc := range cases {\n\t\tt.Run(tc.note, func(t *testing.T) {\n\t\t\tbs, err := Ast(tc.toFmt)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"Unexpected error: %s\", err)\n\t\t\t}\n\t\t\texpected := strings.TrimSpace(tc.expected)\n\t\t\tactual := strings.TrimSpace(string(bs))\n\t\t\tif actual != expected {\n\t\t\t\tt.Fatalf(\"Expected:\\n\\n%q\\n\\nGot:\\n\\n%q\\n\\n\", expected, actual)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestFormatDeepCopy(t *testing.T) {\n\n\toriginal := ast.Body{\n\t\t&ast.Expr{\n\t\t\tIndex: 0,\n\t\t\tTerms: ast.VarTerm(\"$x\"),\n\t\t},\n\t\t&ast.Expr{\n\t\t\tIndex: 1,\n\t\t\tTerms: ast.RefTerm(ast.VarTerm(\"$x\"), ast.VarTerm(\"y\")),\n\t\t},\n\t}\n\n\tcpy := original.Copy()\n\n\t_, err := Ast(original)\n\tif err != nil {\n\t\tt.Fatal(err)\n\t}\n\n\tif !cpy.Equal(original) {\n\t\tt.Fatal(\"expected original to be unmodified\")\n\t}\n\n}\n\nfunc differsAt(a, b []byte) (int, int) {\n\tif bytes.Equal(a, b) {\n\t\treturn 0, 0\n\t}\n\tminLen := len(a)\n\tif minLen > len(b) {\n\t\tminLen = len(b)\n\t}\n\tln := 1\n\tfor i := 0; i < minLen; i++ {\n\t\tif a[i] == '\\n' {\n\t\t\tln++\n\t\t}\n\t\tif a[i] != b[i] {\n\t\t\treturn ln, i\n\t\t}\n\t}\n\treturn ln, minLen - 1\n}\n\nfunc prefixWithLineNumbers(bs []byte) []byte {\n\traw := string(bs)\n\tlines := strings.Split(raw, \"\\n\")\n\tformat := fmt.Sprintf(\"%%%dd %%s\", len(fmt.Sprint(len(lines)+1)))\n\tfor i, line := range lines {\n\t\tlines[i] = fmt.Sprintf(format, i+1, line)\n\t}\n\treturn []byte(strings.Join(lines, \"\\n\"))\n}\n"], "filenames": ["format/format.go", "format/format_test.go"], "buggy_code_start_loc": [15, 338], "buggy_code_end_loc": [913, 351], "fixing_code_start_loc": [16, 339], "fixing_code_end_loc": [924, 397], "type": "CWE-682", "message": "OPA is an open source, general-purpose policy engine. Under certain conditions, pretty-printing an abstract syntax tree (AST) that contains synthetic nodes could change the logic of some statements by reordering array literals. Example of policies impacted are those that parse and compare web paths. **All of these** three conditions have to be met to create an adverse effect: 1. An AST of Rego had to be **created programmatically** such that it ends up containing terms without a location (such as wildcard variables). 2. The AST had to be **pretty-printed** using the `github.com/open-policy-agent/opa/format` package. 3. The result of the pretty-printing had to be **parsed and evaluated again** via an OPA instance using the bundles, or the Golang packages. If any of these three conditions are not met, you are not affected. Notably, all three would be true if using **optimized bundles**, i.e. bundles created with `opa build -O=1` or higher. In that case, the optimizer would fulfil condition (1.), the result of that would be pretty-printed when writing the bundle to disk, fulfilling (2.). When the bundle was then used, we'd satisfy (3.). As a workaround users may disable optimization when creating bundles.", "other": {"cve": {"id": "CVE-2022-23628", "sourceIdentifier": "security-advisories@github.com", "published": "2022-02-09T22:15:07.597", "lastModified": "2022-02-17T02:37:15.663", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "OPA is an open source, general-purpose policy engine. Under certain conditions, pretty-printing an abstract syntax tree (AST) that contains synthetic nodes could change the logic of some statements by reordering array literals. Example of policies impacted are those that parse and compare web paths. **All of these** three conditions have to be met to create an adverse effect: 1. An AST of Rego had to be **created programmatically** such that it ends up containing terms without a location (such as wildcard variables). 2. The AST had to be **pretty-printed** using the `github.com/open-policy-agent/opa/format` package. 3. The result of the pretty-printing had to be **parsed and evaluated again** via an OPA instance using the bundles, or the Golang packages. If any of these three conditions are not met, you are not affected. Notably, all three would be true if using **optimized bundles**, i.e. bundles created with `opa build -O=1` or higher. In that case, the optimizer would fulfil condition (1.), the result of that would be pretty-printed when writing the bundle to disk, fulfilling (2.). When the bundle was then used, we'd satisfy (3.). As a workaround users may disable optimization when creating bundles."}, {"lang": "es", "value": "OPA es un motor de pol\u00edticas de prop\u00f3sito general y de c\u00f3digo abierto. Bajo determinadas condiciones, la impresi\u00f3n bonita de un \u00e1rbol de sintaxis abstracta (AST) que contiene nodos sint\u00e9ticos podr\u00eda cambiar la l\u00f3gica de algunas sentencias al reordenar los literales del array. Un ejemplo de pol\u00edticas afectadas son las que analizan y comparan las rutas web. **Todas estas** tres condiciones tienen que cumplirse para crear un efecto adverso: 1. Un AST de Rego tuvo que ser **creado program\u00e1ticamente** de tal manera que termina conteniendo t\u00e9rminos sin ubicaci\u00f3n (como variables comod\u00edn). 2. El AST tuvo que ser **impreso** usando el paquete \"github.com/open-policy-agent/opa/format\". 3. El resultado de la impresi\u00f3n bonita tuvo que ser **analizado y evaluado de nuevo** por medio de una instancia OPA usando los paquetes, o los paquetes Golang. Si alguna de estas tres condiciones no es cumplida, no est\u00e1 afectado. En particular, las tres condiciones son cumplidas si son usados **paquetes optimizados**, es decir, paquetes creados con \"opa build -O=1\" o superior. En ese caso, el optimizador cumplir\u00eda la condici\u00f3n (1.), cuyo resultado ser\u00eda impreso al escribir el bundle en el disco, cumpliendo (2.). Cuando es usado el paquete, se cumplir\u00eda (3.). Como medida de mitigaci\u00f3n soluci\u00f3n, los usuarios pueden deshabilitar la optimizaci\u00f3n cuando son creados los paquetes"}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:N", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "LOW", "availabilityImpact": "NONE", "baseScore": 5.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 3.9, "impactScore": 1.4}, {"source": "security-advisories@github.com", "type": "Secondary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:L/UI:N/S:U/C:L/I:L/A:L", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "LOW", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "LOW", "integrityImpact": "LOW", "availabilityImpact": "LOW", "baseScore": 6.3, "baseSeverity": "MEDIUM"}, "exploitabilityScore": 2.8, "impactScore": 3.4}], "cvssMetricV2": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "2.0", "vectorString": "AV:N/AC:M/Au:N/C:N/I:P/A:N", "accessVector": "NETWORK", "accessComplexity": "MEDIUM", "authentication": "NONE", "confidentialityImpact": "NONE", "integrityImpact": "PARTIAL", "availabilityImpact": "NONE", "baseScore": 4.3}, "baseSeverity": "MEDIUM", "exploitabilityScore": 8.6, "impactScore": 2.9, "acInsufInfo": false, "obtainAllPrivilege": false, "obtainUserPrivilege": false, "obtainOtherPrivilege": false, "userInteractionRequired": false}]}, "weaknesses": [{"source": "security-advisories@github.com", "type": "Primary", "description": [{"lang": "en", "value": "CWE-682"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:openpolicyagent:open_policy_agent:*:*:*:*:*:*:*:*", "versionStartIncluding": "0.33.1", "versionEndExcluding": "0.37.0", "matchCriteriaId": "31E0CE8B-C614-4F87-81DB-D24E321F81FF"}]}]}], "references": [{"url": "https://github.com/open-policy-agent/opa/commit/932e4ffc37a590ace79e9b75ca4340288c220239", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/open-policy-agent/opa/commit/bfd984ddf93ef2c4963a08d4fdadae0bcf1a3717", "source": "security-advisories@github.com", "tags": ["Patch", "Third Party Advisory"]}, {"url": "https://github.com/open-policy-agent/opa/pull/3851", "source": "security-advisories@github.com", "tags": ["Issue Tracking", "Patch", "Third Party Advisory"]}, {"url": "https://github.com/open-policy-agent/opa/security/advisories/GHSA-hcw3-j74m-qc58", "source": "security-advisories@github.com", "tags": ["Exploit", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/open-policy-agent/opa/commit/932e4ffc37a590ace79e9b75ca4340288c220239"}}
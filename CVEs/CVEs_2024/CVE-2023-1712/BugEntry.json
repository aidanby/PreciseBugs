{"buggy_code": ["# Annotation Tool\n\n- Create labels with different techniques: Come up with questions (+ answers) while reading passages (SQuAD style) or have a set of predefined questions and look for answers in the document (~ Natural Questions).\n- Structure your work via organizations, projects, users\n- Upload your documents or import a predefined list of questions\n- Export your labels in SQuAD Format\n\n![image](../docs/img/annotation_tool.png)\n\n# Hosted version\n Signup here: [Haystack Annotation Tool](https://annotate.deepset.ai/login)\n\n# Local version  (Docker)\n\n1. Configure credentials & database in the [`docker-compose.yml`](https://github.com/deepset-ai/haystack/blob/main/annotation_tool/docker-compose.yml):\n\nThe credentials should match in database image and application configuration.\n\n    DEFAULT_ADMIN_EMAIL: \"example@example.com\"\n    DEFAULT_ADMIN_PASSWORD: \"DEMO-PASSWORD\"\n\n    PROD_DB_NAME: \"databasename\"\n    PROD_DB_USERNAME: \"somesafeuser\"\n    PROD_DB_PASSWORD: \"somesafepassword\"\n\n\n    POSTGRES_USER: \"somesafeuser\"\n    POSTGRES_PASSWORD: \"somesafepassword\"\n    POSTGRES_DB: \"databasename\"\n\n\n2. Run docker-compose by executing `docker-compose up`.\n\n\n3. The UI should be available at `localhost:7001`.\n\n# Usage\nThe manual (of a slightly earlier version) can be found [here](https://drive.google.com/file/d/1Wv3OIC0Z7ibHIzOm9Xw_r0gjTFmpl-33/view). While it doesn't include all latest features, the basic workflow and tips for label quality are still the same.\n\n# Annotation FAQ\n\n1. What is a good question?\n- A good question is a fact-seeking question that can be answered with an entity (person, organisation, location, etc.) or explanation. A bad question is ambiguous, incomprehensible, dependent on clear false presuppositions, opinion seeking, or not clearly a request for factual information.\n- The question should ask about information present in the text passage given. It should not be answerable only with additional knowledge or your interpretation.\n-  Do not copy paste answer text into the question. Good questions do not contain the exact same words as the answer or the context around the answer. The question should be a reformulation with synonyms and in different order as the context of the answer.\n- Questions should be very precise natural questions you would ask when you want information from another person.\n2. How many questions should you ask per text passage?\n- Maximally ask 20 questions per passage\n- Some text passages are not suited for 20 questions. Do not make up very constructed and complicated questions just to fill up the 20 - move on to the next text.\n- Try to ask questions covering the whole passage and focus on questions covering important information. Do not only ask questions about a single sentence in that passage.\n3. What is a good answer span?\n- Always mark whole words. Do not start or end the answer within a word.\n- For short answers: The answer should be as short and as close to a spoken human answer as possible. Do not include punctuation.\n- For long answers: Please mark whole sentences with punctuation. The sentences can also pick up parts of the question, or mark even whole text passages. Mark passages only if they are not too large (e.g. not more than 8-10 sentences).\n4. How do I differentiate long vs short answers?\n- If there is a short answer possible you should always select short answer over long answer.\n- Short precise answers like numbers or a few words are short answers.\n- Long answers include lists of possibilities or multiple sentences are needed to answer the question correctly.\n5. How to handle multiple possible answers to a single question?\n- As of now there is no functionality to mark multiple answers per single question.\n- Workaround: You can add a question with the same text but different answer selection by using the button below the question list (Button reads \u201ccustom question\u201d)\n6. What to do with grammatically wrong or incorrectly spelled questions?\n- Include them. When users use the tool and ask questions they will likely contain grammar and spelling errors, too.\n- Exception: The question needs to be understandable without reading and interpretation of the corresponding text passage. If you do not understand the question, please mark the question as \u201cI don\u2019t understand the question\u201d.\n7. What to do with text passages that are not properly converted or contain (in part) information that cannot be labelled (e.g. just lists or garbage text)?\n- Please do not annotate this text\n- You can write down what is missing, or the cause why you cannot label the text + the text number and title.\n8. Which browser to use?\n- Please use the Chrome browser. The tool is not tested for other browsers.\n", "version: \"3\"\nservices:\n  backend:\n    image: deepset/haystack-annotation:latest\n    environment:\n      DEFAULT_ADMIN_EMAIL: \"example@example.com\"\n      DEFAULT_ADMIN_PASSWORD: \"DEMO_PASSWORD\"\n      NODE_ENV: \"production\"\n      PROD_DB_HOSTNAME: \"db\"\n      PROD_DB_NAME: \"databasename\"\n      PROD_DB_USERNAME: \"somesafeuser\"\n      PROD_DB_PASSWORD: \"somesafepassword\"\n    ports:\n      - \"7001:7001\"\n    links:\n      - \"db:database\"\n    depends_on:\n      - db\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  db:\n    image: \"postgres:12\"\n    environment:\n      POSTGRES_USER: \"somesafeuser\"\n      POSTGRES_PASSWORD: \"somesafepassword\"\n      POSTGRES_DB: \"databasename\"\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - ./postgres-data:/var/lib/postgresql/data\n    networks:\n      - app-network\n    healthcheck:\n      test: \"pg_isready --username=somesafeuser --dbname=databasename && psql --username=somesafeuser --list\"\n      timeout: 3s\n      retries: 5\n    restart: unless-stopped\n\nnetworks:\n  app-network:\n    driver: bridge\n"], "fixing_code": ["# Annotation Tool\n\n- Create labels with different techniques: Come up with questions (+ answers) while reading passages (SQuAD style) or have a set of predefined questions and look for answers in the document (~ Natural Questions).\n- Structure your work via organizations, projects, users\n- Upload your documents or import a predefined list of questions\n- Export your labels in SQuAD Format\n\n![image](../docs/img/annotation_tool.png)\n\n# Hosted version\n Signup here: [Haystack Annotation Tool](https://annotate.deepset.ai/login)\n\n# Local version  (Docker)\n\n1. Configure credentials & database in the [`docker-compose.yml`](https://github.com/deepset-ai/haystack/blob/main/annotation_tool/docker-compose.yml):\n\nThe credentials should match in database image and application configuration.\n\n    DEFAULT_ADMIN_EMAIL: \"example@example.com\"\n    DEFAULT_ADMIN_PASSWORD: \"DEMO-PASSWORD\"\n\n    DB_HOSTNAME: \"db\"\n    DB_NAME: \"databasename\"\n    DB_USERNAME: \"somesafeuser\"\n    DB_PASSWORD: \"somesafepassword\"\n\n    POSTGRES_USER: \"somesafeuser\"\n    POSTGRES_PASSWORD: \"somesafepassword\"\n    POSTGRES_DB: \"databasename\"\n    \n    COOKIE_KEYS: \"somesafecookiekeys\"\n    JWT_SECRET: \"somesafesecret\"\n\n\n2. Run docker-compose by executing `docker-compose up`.\n\n\n3. The UI should be available at `localhost:7001`.\n\n# Usage\nThe manual (of a slightly earlier version) can be found [here](https://drive.google.com/file/d/1Wv3OIC0Z7ibHIzOm9Xw_r0gjTFmpl-33/view). While it doesn't include all latest features, the basic workflow and tips for label quality are still the same.\n\n# Annotation FAQ\n\n1. What is a good question?\n- A good question is a fact-seeking question that can be answered with an entity (person, organisation, location, etc.) or explanation. A bad question is ambiguous, incomprehensible, dependent on clear false presuppositions, opinion seeking, or not clearly a request for factual information.\n- The question should ask about information present in the text passage given. It should not be answerable only with additional knowledge or your interpretation.\n-  Do not copy paste answer text into the question. Good questions do not contain the exact same words as the answer or the context around the answer. The question should be a reformulation with synonyms and in different order as the context of the answer.\n- Questions should be very precise natural questions you would ask when you want information from another person.\n2. How many questions should you ask per text passage?\n- Maximally ask 20 questions per passage\n- Some text passages are not suited for 20 questions. Do not make up very constructed and complicated questions just to fill up the 20 - move on to the next text.\n- Try to ask questions covering the whole passage and focus on questions covering important information. Do not only ask questions about a single sentence in that passage.\n3. What is a good answer span?\n- Always mark whole words. Do not start or end the answer within a word.\n- For short answers: The answer should be as short and as close to a spoken human answer as possible. Do not include punctuation.\n- For long answers: Please mark whole sentences with punctuation. The sentences can also pick up parts of the question, or mark even whole text passages. Mark passages only if they are not too large (e.g. not more than 8-10 sentences).\n4. How do I differentiate long vs short answers?\n- If there is a short answer possible you should always select short answer over long answer.\n- Short precise answers like numbers or a few words are short answers.\n- Long answers include lists of possibilities or multiple sentences are needed to answer the question correctly.\n5. How to handle multiple possible answers to a single question?\n- As of now there is no functionality to mark multiple answers per single question.\n- Workaround: You can add a question with the same text but different answer selection by using the button below the question list (Button reads \u201ccustom question\u201d)\n6. What to do with grammatically wrong or incorrectly spelled questions?\n- Include them. When users use the tool and ask questions they will likely contain grammar and spelling errors, too.\n- Exception: The question needs to be understandable without reading and interpretation of the corresponding text passage. If you do not understand the question, please mark the question as \u201cI don\u2019t understand the question\u201d.\n7. What to do with text passages that are not properly converted or contain (in part) information that cannot be labelled (e.g. just lists or garbage text)?\n- Please do not annotate this text\n- You can write down what is missing, or the cause why you cannot label the text + the text number and title.\n8. Which browser to use?\n- Please use the Chrome browser. The tool is not tested for other browsers.\n", "version: \"3\"\nservices:\n  backend:\n    image: deepset/haystack-annotation:latest\n    environment:\n      NODE_ENV: \"production\"\n      DB_HOSTNAME: \"db\"\n      DB_NAME: \"databasename\"\n      DB_USERNAME: \"somesafeuser\"\n      DB_PASSWORD: \"somesafepassword\"\n      # IMPORTANT: please configure credentials with secure strings.\n      # DEFAULT_ADMIN_EMAIL: \"example@example.com\"\n      # DEFAULT_ADMIN_PASSWORD: \"DEMO_PASSWORD\"\n      # COOKIE_KEYS: \"somesafecookiekeys\"\n      # JWT_SECRET: \"somesafesecret\"\n    ports:\n      - \"7001:7001\"\n    links:\n      - \"db:database\"\n    depends_on:\n      - db\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  db:\n    image: \"postgres:12\"\n    environment:\n      POSTGRES_USER: \"somesafeuser\"\n      POSTGRES_PASSWORD: \"somesafepassword\"\n      POSTGRES_DB: \"databasename\"\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - ./postgres-data:/var/lib/postgresql/data\n    networks:\n      - app-network\n    healthcheck:\n      test: \"pg_isready --username=somesafeuser --dbname=databasename && psql --username=somesafeuser --list\"\n      timeout: 3s\n      retries: 5\n    restart: unless-stopped\n\nnetworks:\n  app-network:\n    driver: bridge\n"], "filenames": ["annotation_tool/README.md", "annotation_tool/docker-compose.yml"], "buggy_code_start_loc": [22, 6], "buggy_code_end_loc": [29, 13], "fixing_code_start_loc": [22, 5], "fixing_code_end_loc": [33, 16], "type": "CWE-547", "message": "Use of Hard-coded, Security-relevant Constants in GitHub repository deepset-ai/haystack prior to 0.1.30.", "other": {"cve": {"id": "CVE-2023-1712", "sourceIdentifier": "security@huntr.dev", "published": "2023-03-30T10:15:07.217", "lastModified": "2023-04-05T13:37:27.220", "vulnStatus": "Analyzed", "descriptions": [{"lang": "en", "value": "Use of Hard-coded, Security-relevant Constants in GitHub repository deepset-ai/haystack prior to 0.1.30."}], "metrics": {"cvssMetricV31": [{"source": "nvd@nist.gov", "type": "Primary", "cvssData": {"version": "3.1", "vectorString": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "HIGH", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.8, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.9}], "cvssMetricV30": [{"source": "security@huntr.dev", "type": "Secondary", "cvssData": {"version": "3.0", "vectorString": "CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:H/A:H", "attackVector": "NETWORK", "attackComplexity": "LOW", "privilegesRequired": "NONE", "userInteraction": "NONE", "scope": "UNCHANGED", "confidentialityImpact": "NONE", "integrityImpact": "HIGH", "availabilityImpact": "HIGH", "baseScore": 9.1, "baseSeverity": "CRITICAL"}, "exploitabilityScore": 3.9, "impactScore": 5.2}]}, "weaknesses": [{"source": "security@huntr.dev", "type": "Primary", "description": [{"lang": "en", "value": "CWE-547"}]}], "configurations": [{"nodes": [{"operator": "OR", "negate": false, "cpeMatch": [{"vulnerable": true, "criteria": "cpe:2.3:a:deepset:haystack:*:*:*:*:*:*:*:*", "versionEndExcluding": "2023-03-29", "matchCriteriaId": "1CEC8E1C-85B8-47CA-BCED-7AB8C5511D6E"}]}]}], "references": [{"url": "https://github.com/deepset-ai/haystack/commit/5fc84904f198de661d5b933fde756aa922bf09f1", "source": "security@huntr.dev", "tags": ["Patch"]}, {"url": "https://huntr.dev/bounties/9a6b1fb4-ec9b-4cfa-af1e-9ce304924829", "source": "security@huntr.dev", "tags": ["Exploit", "Issue Tracking", "Patch", "Third Party Advisory"]}]}, "github_commit_url": "https://github.com/deepset-ai/haystack/commit/5fc84904f198de661d5b933fde756aa922bf09f1"}}